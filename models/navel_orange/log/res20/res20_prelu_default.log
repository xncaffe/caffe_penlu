I1023 15:05:26.667367  4985 caffe.cpp:218] Using GPUs 0
I1023 15:05:26.685765  4985 caffe.cpp:223] GPU 0: GeForce GTX 1080
I1023 15:05:26.896246  4985 solver.cpp:44] Initializing solver from parameters: 
test_iter: 64
test_interval: 200
base_lr: 0.01
display: 100
max_iter: 30000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 30000
snapshot_prefix: "xn/English_orange/snapshot/res20/res20_prelu_default"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/English_orange/neural/res20/res20_prelu_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 10000
stepvalue: 20000
I1023 15:05:26.896397  4985 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/English_orange/neural/res20/res20_prelu_train_test.prototxt
I1023 15:05:26.897621  4985 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/English_orange/neural/res20/res20_prelu_train_test.prototxt
I1023 15:05:26.897631  4985 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1023 15:05:26.897765  4985 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I1023 15:05:26.897825  4985 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I1023 15:05:26.898217  4985 net.cpp:51] Initializing net from parameters: 
name: "resnet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_file: "/home/x306/caffe/xn/English_orange/data/orange1_mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/English_orange/data/train1_lmdb"
    batch_size: 8
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU1"
  type: "PReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU2"
  type: "PReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU3"
  type: "PReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU4"
  type: "PReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU5"
  type: "PReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU6"
  type: "PReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU7"
  type: "PReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU8"
  type: "PReLU"
  bottom: "Convolution9"
  top: "Convolution9"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU9"
  type: "PReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU10"
  type: "PReLU"
  bottom: "Convolution11"
  top: "Convolution11"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU11"
  type: "PReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU12"
  type: "PReLU"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU13"
  type: "PReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU14"
  type: "PReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU15"
  type: "PReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU16"
  type: "PReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU17"
  type: "PReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU18"
  type: "PReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU19"
  type: "PReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
I1023 15:05:26.898499  4985 layer_factory.hpp:77] Creating layer Data1
I1023 15:05:26.898577  4985 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/English_orange/data/train1_lmdb
I1023 15:05:26.898596  4985 net.cpp:84] Creating Layer Data1
I1023 15:05:26.898602  4985 net.cpp:380] Data1 -> Data1
I1023 15:05:26.898617  4985 net.cpp:380] Data1 -> Data2
I1023 15:05:26.898625  4985 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/English_orange/data/orange1_mean.binaryproto
I1023 15:05:26.901130  4985 data_layer.cpp:45] output data size: 8,3,224,224
I1023 15:05:26.908972  4985 net.cpp:122] Setting up Data1
I1023 15:05:26.909003  4985 net.cpp:129] Top shape: 8 3 224 224 (1204224)
I1023 15:05:26.909008  4985 net.cpp:129] Top shape: 8 (8)
I1023 15:05:26.909011  4985 net.cpp:137] Memory required for data: 4816928
I1023 15:05:26.909027  4985 layer_factory.hpp:77] Creating layer Convolution1
I1023 15:05:26.909060  4985 net.cpp:84] Creating Layer Convolution1
I1023 15:05:26.909065  4985 net.cpp:406] Convolution1 <- Data1
I1023 15:05:26.909082  4985 net.cpp:380] Convolution1 -> Convolution1
I1023 15:05:27.057572  4985 net.cpp:122] Setting up Convolution1
I1023 15:05:27.057597  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.057601  4985 net.cpp:137] Memory required for data: 30507040
I1023 15:05:27.057615  4985 layer_factory.hpp:77] Creating layer BatchNorm1
I1023 15:05:27.057637  4985 net.cpp:84] Creating Layer BatchNorm1
I1023 15:05:27.057651  4985 net.cpp:406] BatchNorm1 <- Convolution1
I1023 15:05:27.057657  4985 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1023 15:05:27.057821  4985 net.cpp:122] Setting up BatchNorm1
I1023 15:05:27.057826  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.057828  4985 net.cpp:137] Memory required for data: 56197152
I1023 15:05:27.057835  4985 layer_factory.hpp:77] Creating layer Scale1
I1023 15:05:27.057844  4985 net.cpp:84] Creating Layer Scale1
I1023 15:05:27.057857  4985 net.cpp:406] Scale1 <- Convolution1
I1023 15:05:27.057862  4985 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1023 15:05:27.057914  4985 layer_factory.hpp:77] Creating layer Scale1
I1023 15:05:27.058084  4985 net.cpp:122] Setting up Scale1
I1023 15:05:27.058090  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.058094  4985 net.cpp:137] Memory required for data: 81887264
I1023 15:05:27.058097  4985 layer_factory.hpp:77] Creating layer PReLU1
I1023 15:05:27.058101  4985 net.cpp:84] Creating Layer PReLU1
I1023 15:05:27.058104  4985 net.cpp:406] PReLU1 <- Convolution1
I1023 15:05:27.058107  4985 net.cpp:367] PReLU1 -> Convolution1 (in-place)
I1023 15:05:27.059257  4985 net.cpp:122] Setting up PReLU1
I1023 15:05:27.059267  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.059270  4985 net.cpp:137] Memory required for data: 107577376
I1023 15:05:27.059274  4985 layer_factory.hpp:77] Creating layer Convolution1_PReLU1_0_split
I1023 15:05:27.059279  4985 net.cpp:84] Creating Layer Convolution1_PReLU1_0_split
I1023 15:05:27.059283  4985 net.cpp:406] Convolution1_PReLU1_0_split <- Convolution1
I1023 15:05:27.059286  4985 net.cpp:380] Convolution1_PReLU1_0_split -> Convolution1_PReLU1_0_split_0
I1023 15:05:27.059301  4985 net.cpp:380] Convolution1_PReLU1_0_split -> Convolution1_PReLU1_0_split_1
I1023 15:05:27.059350  4985 net.cpp:122] Setting up Convolution1_PReLU1_0_split
I1023 15:05:27.059355  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.059370  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.059371  4985 net.cpp:137] Memory required for data: 158957600
I1023 15:05:27.059373  4985 layer_factory.hpp:77] Creating layer Convolution2
I1023 15:05:27.059392  4985 net.cpp:84] Creating Layer Convolution2
I1023 15:05:27.059396  4985 net.cpp:406] Convolution2 <- Convolution1_PReLU1_0_split_0
I1023 15:05:27.059399  4985 net.cpp:380] Convolution2 -> Convolution2
I1023 15:05:27.060853  4985 net.cpp:122] Setting up Convolution2
I1023 15:05:27.060876  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.060879  4985 net.cpp:137] Memory required for data: 184647712
I1023 15:05:27.060889  4985 layer_factory.hpp:77] Creating layer BatchNorm2
I1023 15:05:27.060904  4985 net.cpp:84] Creating Layer BatchNorm2
I1023 15:05:27.060907  4985 net.cpp:406] BatchNorm2 <- Convolution2
I1023 15:05:27.060911  4985 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1023 15:05:27.061074  4985 net.cpp:122] Setting up BatchNorm2
I1023 15:05:27.061080  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.061092  4985 net.cpp:137] Memory required for data: 210337824
I1023 15:05:27.061098  4985 layer_factory.hpp:77] Creating layer Scale2
I1023 15:05:27.061103  4985 net.cpp:84] Creating Layer Scale2
I1023 15:05:27.061116  4985 net.cpp:406] Scale2 <- Convolution2
I1023 15:05:27.061121  4985 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1023 15:05:27.061158  4985 layer_factory.hpp:77] Creating layer Scale2
I1023 15:05:27.061357  4985 net.cpp:122] Setting up Scale2
I1023 15:05:27.061362  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.061364  4985 net.cpp:137] Memory required for data: 236027936
I1023 15:05:27.061368  4985 layer_factory.hpp:77] Creating layer PReLU2
I1023 15:05:27.061372  4985 net.cpp:84] Creating Layer PReLU2
I1023 15:05:27.061374  4985 net.cpp:406] PReLU2 <- Convolution2
I1023 15:05:27.061378  4985 net.cpp:367] PReLU2 -> Convolution2 (in-place)
I1023 15:05:27.062485  4985 net.cpp:122] Setting up PReLU2
I1023 15:05:27.062495  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.062499  4985 net.cpp:137] Memory required for data: 261718048
I1023 15:05:27.062502  4985 layer_factory.hpp:77] Creating layer Convolution3
I1023 15:05:27.062510  4985 net.cpp:84] Creating Layer Convolution3
I1023 15:05:27.062523  4985 net.cpp:406] Convolution3 <- Convolution2
I1023 15:05:27.062530  4985 net.cpp:380] Convolution3 -> Convolution3
I1023 15:05:27.063416  4985 net.cpp:122] Setting up Convolution3
I1023 15:05:27.063427  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.063431  4985 net.cpp:137] Memory required for data: 287408160
I1023 15:05:27.063437  4985 layer_factory.hpp:77] Creating layer BatchNorm3
I1023 15:05:27.063454  4985 net.cpp:84] Creating Layer BatchNorm3
I1023 15:05:27.063457  4985 net.cpp:406] BatchNorm3 <- Convolution3
I1023 15:05:27.063462  4985 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1023 15:05:27.063619  4985 net.cpp:122] Setting up BatchNorm3
I1023 15:05:27.063624  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.063627  4985 net.cpp:137] Memory required for data: 313098272
I1023 15:05:27.063658  4985 layer_factory.hpp:77] Creating layer Scale3
I1023 15:05:27.063678  4985 net.cpp:84] Creating Layer Scale3
I1023 15:05:27.063679  4985 net.cpp:406] Scale3 <- Convolution3
I1023 15:05:27.063683  4985 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1023 15:05:27.063719  4985 layer_factory.hpp:77] Creating layer Scale3
I1023 15:05:27.064365  4985 net.cpp:122] Setting up Scale3
I1023 15:05:27.064375  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.064378  4985 net.cpp:137] Memory required for data: 338788384
I1023 15:05:27.064383  4985 layer_factory.hpp:77] Creating layer Eltwise1
I1023 15:05:27.064388  4985 net.cpp:84] Creating Layer Eltwise1
I1023 15:05:27.064402  4985 net.cpp:406] Eltwise1 <- Convolution1_PReLU1_0_split_1
I1023 15:05:27.064406  4985 net.cpp:406] Eltwise1 <- Convolution3
I1023 15:05:27.064410  4985 net.cpp:380] Eltwise1 -> Eltwise1
I1023 15:05:27.064430  4985 net.cpp:122] Setting up Eltwise1
I1023 15:05:27.064436  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.064440  4985 net.cpp:137] Memory required for data: 364478496
I1023 15:05:27.064441  4985 layer_factory.hpp:77] Creating layer PReLU3
I1023 15:05:27.064445  4985 net.cpp:84] Creating Layer PReLU3
I1023 15:05:27.064448  4985 net.cpp:406] PReLU3 <- Eltwise1
I1023 15:05:27.064452  4985 net.cpp:367] PReLU3 -> Eltwise1 (in-place)
I1023 15:05:27.065531  4985 net.cpp:122] Setting up PReLU3
I1023 15:05:27.065541  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.065544  4985 net.cpp:137] Memory required for data: 390168608
I1023 15:05:27.065548  4985 layer_factory.hpp:77] Creating layer Eltwise1_PReLU3_0_split
I1023 15:05:27.065554  4985 net.cpp:84] Creating Layer Eltwise1_PReLU3_0_split
I1023 15:05:27.065557  4985 net.cpp:406] Eltwise1_PReLU3_0_split <- Eltwise1
I1023 15:05:27.065562  4985 net.cpp:380] Eltwise1_PReLU3_0_split -> Eltwise1_PReLU3_0_split_0
I1023 15:05:27.065568  4985 net.cpp:380] Eltwise1_PReLU3_0_split -> Eltwise1_PReLU3_0_split_1
I1023 15:05:27.065592  4985 net.cpp:122] Setting up Eltwise1_PReLU3_0_split
I1023 15:05:27.065596  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.065600  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.065603  4985 net.cpp:137] Memory required for data: 441548832
I1023 15:05:27.065604  4985 layer_factory.hpp:77] Creating layer Convolution4
I1023 15:05:27.065614  4985 net.cpp:84] Creating Layer Convolution4
I1023 15:05:27.065618  4985 net.cpp:406] Convolution4 <- Eltwise1_PReLU3_0_split_0
I1023 15:05:27.065621  4985 net.cpp:380] Convolution4 -> Convolution4
I1023 15:05:27.066545  4985 net.cpp:122] Setting up Convolution4
I1023 15:05:27.066555  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.066558  4985 net.cpp:137] Memory required for data: 467238944
I1023 15:05:27.066563  4985 layer_factory.hpp:77] Creating layer BatchNorm4
I1023 15:05:27.066570  4985 net.cpp:84] Creating Layer BatchNorm4
I1023 15:05:27.066572  4985 net.cpp:406] BatchNorm4 <- Convolution4
I1023 15:05:27.066576  4985 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1023 15:05:27.066730  4985 net.cpp:122] Setting up BatchNorm4
I1023 15:05:27.066735  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.066738  4985 net.cpp:137] Memory required for data: 492929056
I1023 15:05:27.066745  4985 layer_factory.hpp:77] Creating layer Scale4
I1023 15:05:27.066750  4985 net.cpp:84] Creating Layer Scale4
I1023 15:05:27.066753  4985 net.cpp:406] Scale4 <- Convolution4
I1023 15:05:27.066756  4985 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1023 15:05:27.066783  4985 layer_factory.hpp:77] Creating layer Scale4
I1023 15:05:27.066908  4985 net.cpp:122] Setting up Scale4
I1023 15:05:27.066913  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.066916  4985 net.cpp:137] Memory required for data: 518619168
I1023 15:05:27.066921  4985 layer_factory.hpp:77] Creating layer PReLU4
I1023 15:05:27.066926  4985 net.cpp:84] Creating Layer PReLU4
I1023 15:05:27.066928  4985 net.cpp:406] PReLU4 <- Convolution4
I1023 15:05:27.066941  4985 net.cpp:367] PReLU4 -> Convolution4 (in-place)
I1023 15:05:27.068074  4985 net.cpp:122] Setting up PReLU4
I1023 15:05:27.068086  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.068089  4985 net.cpp:137] Memory required for data: 544309280
I1023 15:05:27.068094  4985 layer_factory.hpp:77] Creating layer Convolution5
I1023 15:05:27.068102  4985 net.cpp:84] Creating Layer Convolution5
I1023 15:05:27.068106  4985 net.cpp:406] Convolution5 <- Convolution4
I1023 15:05:27.068111  4985 net.cpp:380] Convolution5 -> Convolution5
I1023 15:05:27.069417  4985 net.cpp:122] Setting up Convolution5
I1023 15:05:27.069430  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.069433  4985 net.cpp:137] Memory required for data: 569999392
I1023 15:05:27.069443  4985 layer_factory.hpp:77] Creating layer BatchNorm5
I1023 15:05:27.069449  4985 net.cpp:84] Creating Layer BatchNorm5
I1023 15:05:27.069453  4985 net.cpp:406] BatchNorm5 <- Convolution5
I1023 15:05:27.069458  4985 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1023 15:05:27.069640  4985 net.cpp:122] Setting up BatchNorm5
I1023 15:05:27.069651  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.069656  4985 net.cpp:137] Memory required for data: 595689504
I1023 15:05:27.069666  4985 layer_factory.hpp:77] Creating layer Scale5
I1023 15:05:27.069676  4985 net.cpp:84] Creating Layer Scale5
I1023 15:05:27.069681  4985 net.cpp:406] Scale5 <- Convolution5
I1023 15:05:27.069689  4985 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1023 15:05:27.069722  4985 layer_factory.hpp:77] Creating layer Scale5
I1023 15:05:27.069877  4985 net.cpp:122] Setting up Scale5
I1023 15:05:27.069885  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.069890  4985 net.cpp:137] Memory required for data: 621379616
I1023 15:05:27.069910  4985 layer_factory.hpp:77] Creating layer Eltwise2
I1023 15:05:27.069916  4985 net.cpp:84] Creating Layer Eltwise2
I1023 15:05:27.069922  4985 net.cpp:406] Eltwise2 <- Eltwise1_PReLU3_0_split_1
I1023 15:05:27.069928  4985 net.cpp:406] Eltwise2 <- Convolution5
I1023 15:05:27.069936  4985 net.cpp:380] Eltwise2 -> Eltwise2
I1023 15:05:27.069957  4985 net.cpp:122] Setting up Eltwise2
I1023 15:05:27.069963  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.069977  4985 net.cpp:137] Memory required for data: 647069728
I1023 15:05:27.069983  4985 layer_factory.hpp:77] Creating layer PReLU5
I1023 15:05:27.069999  4985 net.cpp:84] Creating Layer PReLU5
I1023 15:05:27.070004  4985 net.cpp:406] PReLU5 <- Eltwise2
I1023 15:05:27.070011  4985 net.cpp:367] PReLU5 -> Eltwise2 (in-place)
I1023 15:05:27.071190  4985 net.cpp:122] Setting up PReLU5
I1023 15:05:27.071204  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.071209  4985 net.cpp:137] Memory required for data: 672759840
I1023 15:05:27.071218  4985 layer_factory.hpp:77] Creating layer Eltwise2_PReLU5_0_split
I1023 15:05:27.071228  4985 net.cpp:84] Creating Layer Eltwise2_PReLU5_0_split
I1023 15:05:27.071233  4985 net.cpp:406] Eltwise2_PReLU5_0_split <- Eltwise2
I1023 15:05:27.071239  4985 net.cpp:380] Eltwise2_PReLU5_0_split -> Eltwise2_PReLU5_0_split_0
I1023 15:05:27.071249  4985 net.cpp:380] Eltwise2_PReLU5_0_split -> Eltwise2_PReLU5_0_split_1
I1023 15:05:27.071277  4985 net.cpp:122] Setting up Eltwise2_PReLU5_0_split
I1023 15:05:27.071285  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.071291  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.071296  4985 net.cpp:137] Memory required for data: 724140064
I1023 15:05:27.071302  4985 layer_factory.hpp:77] Creating layer Convolution6
I1023 15:05:27.071313  4985 net.cpp:84] Creating Layer Convolution6
I1023 15:05:27.071318  4985 net.cpp:406] Convolution6 <- Eltwise2_PReLU5_0_split_0
I1023 15:05:27.071326  4985 net.cpp:380] Convolution6 -> Convolution6
I1023 15:05:27.072829  4985 net.cpp:122] Setting up Convolution6
I1023 15:05:27.072844  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.072849  4985 net.cpp:137] Memory required for data: 749830176
I1023 15:05:27.072870  4985 layer_factory.hpp:77] Creating layer BatchNorm6
I1023 15:05:27.072878  4985 net.cpp:84] Creating Layer BatchNorm6
I1023 15:05:27.072885  4985 net.cpp:406] BatchNorm6 <- Convolution6
I1023 15:05:27.072891  4985 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1023 15:05:27.073043  4985 net.cpp:122] Setting up BatchNorm6
I1023 15:05:27.073051  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.073055  4985 net.cpp:137] Memory required for data: 775520288
I1023 15:05:27.073065  4985 layer_factory.hpp:77] Creating layer Scale6
I1023 15:05:27.073073  4985 net.cpp:84] Creating Layer Scale6
I1023 15:05:27.073078  4985 net.cpp:406] Scale6 <- Convolution6
I1023 15:05:27.073084  4985 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1023 15:05:27.073117  4985 layer_factory.hpp:77] Creating layer Scale6
I1023 15:05:27.073232  4985 net.cpp:122] Setting up Scale6
I1023 15:05:27.073240  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.073246  4985 net.cpp:137] Memory required for data: 801210400
I1023 15:05:27.073254  4985 layer_factory.hpp:77] Creating layer PReLU6
I1023 15:05:27.073261  4985 net.cpp:84] Creating Layer PReLU6
I1023 15:05:27.073266  4985 net.cpp:406] PReLU6 <- Convolution6
I1023 15:05:27.073272  4985 net.cpp:367] PReLU6 -> Convolution6 (in-place)
I1023 15:05:27.074378  4985 net.cpp:122] Setting up PReLU6
I1023 15:05:27.074389  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.074394  4985 net.cpp:137] Memory required for data: 826900512
I1023 15:05:27.074401  4985 layer_factory.hpp:77] Creating layer Convolution7
I1023 15:05:27.074414  4985 net.cpp:84] Creating Layer Convolution7
I1023 15:05:27.074419  4985 net.cpp:406] Convolution7 <- Convolution6
I1023 15:05:27.074426  4985 net.cpp:380] Convolution7 -> Convolution7
I1023 15:05:27.075348  4985 net.cpp:122] Setting up Convolution7
I1023 15:05:27.075361  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.075366  4985 net.cpp:137] Memory required for data: 852590624
I1023 15:05:27.075376  4985 layer_factory.hpp:77] Creating layer BatchNorm7
I1023 15:05:27.075384  4985 net.cpp:84] Creating Layer BatchNorm7
I1023 15:05:27.075389  4985 net.cpp:406] BatchNorm7 <- Convolution7
I1023 15:05:27.075397  4985 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1023 15:05:27.075546  4985 net.cpp:122] Setting up BatchNorm7
I1023 15:05:27.075554  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.075559  4985 net.cpp:137] Memory required for data: 878280736
I1023 15:05:27.075569  4985 layer_factory.hpp:77] Creating layer Scale7
I1023 15:05:27.075579  4985 net.cpp:84] Creating Layer Scale7
I1023 15:05:27.075583  4985 net.cpp:406] Scale7 <- Convolution7
I1023 15:05:27.075590  4985 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1023 15:05:27.075620  4985 layer_factory.hpp:77] Creating layer Scale7
I1023 15:05:27.075744  4985 net.cpp:122] Setting up Scale7
I1023 15:05:27.075752  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.075757  4985 net.cpp:137] Memory required for data: 903970848
I1023 15:05:27.075767  4985 layer_factory.hpp:77] Creating layer Eltwise3
I1023 15:05:27.075773  4985 net.cpp:84] Creating Layer Eltwise3
I1023 15:05:27.075778  4985 net.cpp:406] Eltwise3 <- Eltwise2_PReLU5_0_split_1
I1023 15:05:27.075784  4985 net.cpp:406] Eltwise3 <- Convolution7
I1023 15:05:27.075791  4985 net.cpp:380] Eltwise3 -> Eltwise3
I1023 15:05:27.075812  4985 net.cpp:122] Setting up Eltwise3
I1023 15:05:27.075819  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.075824  4985 net.cpp:137] Memory required for data: 929660960
I1023 15:05:27.075829  4985 layer_factory.hpp:77] Creating layer PReLU7
I1023 15:05:27.075835  4985 net.cpp:84] Creating Layer PReLU7
I1023 15:05:27.075840  4985 net.cpp:406] PReLU7 <- Eltwise3
I1023 15:05:27.075847  4985 net.cpp:367] PReLU7 -> Eltwise3 (in-place)
I1023 15:05:27.076992  4985 net.cpp:122] Setting up PReLU7
I1023 15:05:27.077006  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.077025  4985 net.cpp:137] Memory required for data: 955351072
I1023 15:05:27.077035  4985 layer_factory.hpp:77] Creating layer Eltwise3_PReLU7_0_split
I1023 15:05:27.077044  4985 net.cpp:84] Creating Layer Eltwise3_PReLU7_0_split
I1023 15:05:27.077049  4985 net.cpp:406] Eltwise3_PReLU7_0_split <- Eltwise3
I1023 15:05:27.077055  4985 net.cpp:380] Eltwise3_PReLU7_0_split -> Eltwise3_PReLU7_0_split_0
I1023 15:05:27.077064  4985 net.cpp:380] Eltwise3_PReLU7_0_split -> Eltwise3_PReLU7_0_split_1
I1023 15:05:27.077092  4985 net.cpp:122] Setting up Eltwise3_PReLU7_0_split
I1023 15:05:27.077100  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.077106  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.077111  4985 net.cpp:137] Memory required for data: 1006731296
I1023 15:05:27.077116  4985 layer_factory.hpp:77] Creating layer Convolution8
I1023 15:05:27.077127  4985 net.cpp:84] Creating Layer Convolution8
I1023 15:05:27.077132  4985 net.cpp:406] Convolution8 <- Eltwise3_PReLU7_0_split_0
I1023 15:05:27.077141  4985 net.cpp:380] Convolution8 -> Convolution8
I1023 15:05:27.078841  4985 net.cpp:122] Setting up Convolution8
I1023 15:05:27.078853  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.078858  4985 net.cpp:137] Memory required for data: 1019576352
I1023 15:05:27.078867  4985 layer_factory.hpp:77] Creating layer BatchNorm8
I1023 15:05:27.078876  4985 net.cpp:84] Creating Layer BatchNorm8
I1023 15:05:27.078881  4985 net.cpp:406] BatchNorm8 <- Convolution8
I1023 15:05:27.078889  4985 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1023 15:05:27.079026  4985 net.cpp:122] Setting up BatchNorm8
I1023 15:05:27.079035  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.079040  4985 net.cpp:137] Memory required for data: 1032421408
I1023 15:05:27.079049  4985 layer_factory.hpp:77] Creating layer Scale8
I1023 15:05:27.079056  4985 net.cpp:84] Creating Layer Scale8
I1023 15:05:27.079061  4985 net.cpp:406] Scale8 <- Convolution8
I1023 15:05:27.079068  4985 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1023 15:05:27.079102  4985 layer_factory.hpp:77] Creating layer Scale8
I1023 15:05:27.079185  4985 net.cpp:122] Setting up Scale8
I1023 15:05:27.079193  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.079198  4985 net.cpp:137] Memory required for data: 1045266464
I1023 15:05:27.079206  4985 layer_factory.hpp:77] Creating layer Convolution9
I1023 15:05:27.079216  4985 net.cpp:84] Creating Layer Convolution9
I1023 15:05:27.079221  4985 net.cpp:406] Convolution9 <- Eltwise3_PReLU7_0_split_1
I1023 15:05:27.079229  4985 net.cpp:380] Convolution9 -> Convolution9
I1023 15:05:27.080162  4985 net.cpp:122] Setting up Convolution9
I1023 15:05:27.080173  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.080179  4985 net.cpp:137] Memory required for data: 1058111520
I1023 15:05:27.080193  4985 layer_factory.hpp:77] Creating layer BatchNorm9
I1023 15:05:27.080201  4985 net.cpp:84] Creating Layer BatchNorm9
I1023 15:05:27.080207  4985 net.cpp:406] BatchNorm9 <- Convolution9
I1023 15:05:27.080214  4985 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1023 15:05:27.080341  4985 net.cpp:122] Setting up BatchNorm9
I1023 15:05:27.080349  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.080354  4985 net.cpp:137] Memory required for data: 1070956576
I1023 15:05:27.080364  4985 layer_factory.hpp:77] Creating layer Scale9
I1023 15:05:27.080371  4985 net.cpp:84] Creating Layer Scale9
I1023 15:05:27.080377  4985 net.cpp:406] Scale9 <- Convolution9
I1023 15:05:27.080384  4985 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1023 15:05:27.080413  4985 layer_factory.hpp:77] Creating layer Scale9
I1023 15:05:27.080492  4985 net.cpp:122] Setting up Scale9
I1023 15:05:27.080499  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.080504  4985 net.cpp:137] Memory required for data: 1083801632
I1023 15:05:27.080513  4985 layer_factory.hpp:77] Creating layer PReLU8
I1023 15:05:27.080519  4985 net.cpp:84] Creating Layer PReLU8
I1023 15:05:27.080533  4985 net.cpp:406] PReLU8 <- Convolution9
I1023 15:05:27.080540  4985 net.cpp:367] PReLU8 -> Convolution9 (in-place)
I1023 15:05:27.081281  4985 net.cpp:122] Setting up PReLU8
I1023 15:05:27.081293  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.081298  4985 net.cpp:137] Memory required for data: 1096646688
I1023 15:05:27.081305  4985 layer_factory.hpp:77] Creating layer Convolution10
I1023 15:05:27.081316  4985 net.cpp:84] Creating Layer Convolution10
I1023 15:05:27.081321  4985 net.cpp:406] Convolution10 <- Convolution9
I1023 15:05:27.081329  4985 net.cpp:380] Convolution10 -> Convolution10
I1023 15:05:27.082356  4985 net.cpp:122] Setting up Convolution10
I1023 15:05:27.082368  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.082373  4985 net.cpp:137] Memory required for data: 1109491744
I1023 15:05:27.082381  4985 layer_factory.hpp:77] Creating layer BatchNorm10
I1023 15:05:27.082389  4985 net.cpp:84] Creating Layer BatchNorm10
I1023 15:05:27.082394  4985 net.cpp:406] BatchNorm10 <- Convolution10
I1023 15:05:27.082402  4985 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1023 15:05:27.082530  4985 net.cpp:122] Setting up BatchNorm10
I1023 15:05:27.082537  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.082542  4985 net.cpp:137] Memory required for data: 1122336800
I1023 15:05:27.082552  4985 layer_factory.hpp:77] Creating layer Scale10
I1023 15:05:27.082558  4985 net.cpp:84] Creating Layer Scale10
I1023 15:05:27.082563  4985 net.cpp:406] Scale10 <- Convolution10
I1023 15:05:27.082571  4985 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1023 15:05:27.082600  4985 layer_factory.hpp:77] Creating layer Scale10
I1023 15:05:27.082684  4985 net.cpp:122] Setting up Scale10
I1023 15:05:27.082690  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.082695  4985 net.cpp:137] Memory required for data: 1135181856
I1023 15:05:27.082705  4985 layer_factory.hpp:77] Creating layer Eltwise4
I1023 15:05:27.082711  4985 net.cpp:84] Creating Layer Eltwise4
I1023 15:05:27.082716  4985 net.cpp:406] Eltwise4 <- Convolution8
I1023 15:05:27.082722  4985 net.cpp:406] Eltwise4 <- Convolution10
I1023 15:05:27.082729  4985 net.cpp:380] Eltwise4 -> Eltwise4
I1023 15:05:27.082751  4985 net.cpp:122] Setting up Eltwise4
I1023 15:05:27.082757  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.082762  4985 net.cpp:137] Memory required for data: 1148026912
I1023 15:05:27.082767  4985 layer_factory.hpp:77] Creating layer PReLU9
I1023 15:05:27.082773  4985 net.cpp:84] Creating Layer PReLU9
I1023 15:05:27.082778  4985 net.cpp:406] PReLU9 <- Eltwise4
I1023 15:05:27.082785  4985 net.cpp:367] PReLU9 -> Eltwise4 (in-place)
I1023 15:05:27.083529  4985 net.cpp:122] Setting up PReLU9
I1023 15:05:27.083540  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.083545  4985 net.cpp:137] Memory required for data: 1160871968
I1023 15:05:27.083552  4985 layer_factory.hpp:77] Creating layer Eltwise4_PReLU9_0_split
I1023 15:05:27.083560  4985 net.cpp:84] Creating Layer Eltwise4_PReLU9_0_split
I1023 15:05:27.083565  4985 net.cpp:406] Eltwise4_PReLU9_0_split <- Eltwise4
I1023 15:05:27.083573  4985 net.cpp:380] Eltwise4_PReLU9_0_split -> Eltwise4_PReLU9_0_split_0
I1023 15:05:27.083581  4985 net.cpp:380] Eltwise4_PReLU9_0_split -> Eltwise4_PReLU9_0_split_1
I1023 15:05:27.083609  4985 net.cpp:122] Setting up Eltwise4_PReLU9_0_split
I1023 15:05:27.083616  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.083623  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.083627  4985 net.cpp:137] Memory required for data: 1186562080
I1023 15:05:27.083633  4985 layer_factory.hpp:77] Creating layer Convolution11
I1023 15:05:27.083643  4985 net.cpp:84] Creating Layer Convolution11
I1023 15:05:27.083647  4985 net.cpp:406] Convolution11 <- Eltwise4_PReLU9_0_split_0
I1023 15:05:27.083657  4985 net.cpp:380] Convolution11 -> Convolution11
I1023 15:05:27.084703  4985 net.cpp:122] Setting up Convolution11
I1023 15:05:27.084723  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.084729  4985 net.cpp:137] Memory required for data: 1199407136
I1023 15:05:27.084738  4985 layer_factory.hpp:77] Creating layer BatchNorm11
I1023 15:05:27.084746  4985 net.cpp:84] Creating Layer BatchNorm11
I1023 15:05:27.084751  4985 net.cpp:406] BatchNorm11 <- Convolution11
I1023 15:05:27.084759  4985 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1023 15:05:27.084905  4985 net.cpp:122] Setting up BatchNorm11
I1023 15:05:27.084914  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.084919  4985 net.cpp:137] Memory required for data: 1212252192
I1023 15:05:27.084929  4985 layer_factory.hpp:77] Creating layer Scale11
I1023 15:05:27.084938  4985 net.cpp:84] Creating Layer Scale11
I1023 15:05:27.084942  4985 net.cpp:406] Scale11 <- Convolution11
I1023 15:05:27.084949  4985 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1023 15:05:27.084980  4985 layer_factory.hpp:77] Creating layer Scale11
I1023 15:05:27.085098  4985 net.cpp:122] Setting up Scale11
I1023 15:05:27.085109  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.085124  4985 net.cpp:137] Memory required for data: 1225097248
I1023 15:05:27.085131  4985 layer_factory.hpp:77] Creating layer PReLU10
I1023 15:05:27.085137  4985 net.cpp:84] Creating Layer PReLU10
I1023 15:05:27.085142  4985 net.cpp:406] PReLU10 <- Convolution11
I1023 15:05:27.085149  4985 net.cpp:367] PReLU10 -> Convolution11 (in-place)
I1023 15:05:27.086001  4985 net.cpp:122] Setting up PReLU10
I1023 15:05:27.086011  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.086025  4985 net.cpp:137] Memory required for data: 1237942304
I1023 15:05:27.086030  4985 layer_factory.hpp:77] Creating layer Convolution12
I1023 15:05:27.086037  4985 net.cpp:84] Creating Layer Convolution12
I1023 15:05:27.086040  4985 net.cpp:406] Convolution12 <- Convolution11
I1023 15:05:27.086047  4985 net.cpp:380] Convolution12 -> Convolution12
I1023 15:05:27.087128  4985 net.cpp:122] Setting up Convolution12
I1023 15:05:27.087138  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.087152  4985 net.cpp:137] Memory required for data: 1250787360
I1023 15:05:27.087157  4985 layer_factory.hpp:77] Creating layer BatchNorm12
I1023 15:05:27.087162  4985 net.cpp:84] Creating Layer BatchNorm12
I1023 15:05:27.087164  4985 net.cpp:406] BatchNorm12 <- Convolution12
I1023 15:05:27.087168  4985 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1023 15:05:27.087301  4985 net.cpp:122] Setting up BatchNorm12
I1023 15:05:27.087306  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.087309  4985 net.cpp:137] Memory required for data: 1263632416
I1023 15:05:27.087314  4985 layer_factory.hpp:77] Creating layer Scale12
I1023 15:05:27.087319  4985 net.cpp:84] Creating Layer Scale12
I1023 15:05:27.087321  4985 net.cpp:406] Scale12 <- Convolution12
I1023 15:05:27.087326  4985 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1023 15:05:27.087352  4985 layer_factory.hpp:77] Creating layer Scale12
I1023 15:05:27.087435  4985 net.cpp:122] Setting up Scale12
I1023 15:05:27.087440  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.087442  4985 net.cpp:137] Memory required for data: 1276477472
I1023 15:05:27.087446  4985 layer_factory.hpp:77] Creating layer Eltwise5
I1023 15:05:27.087451  4985 net.cpp:84] Creating Layer Eltwise5
I1023 15:05:27.087455  4985 net.cpp:406] Eltwise5 <- Eltwise4_PReLU9_0_split_1
I1023 15:05:27.087458  4985 net.cpp:406] Eltwise5 <- Convolution12
I1023 15:05:27.087461  4985 net.cpp:380] Eltwise5 -> Eltwise5
I1023 15:05:27.087478  4985 net.cpp:122] Setting up Eltwise5
I1023 15:05:27.087483  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.087486  4985 net.cpp:137] Memory required for data: 1289322528
I1023 15:05:27.087487  4985 layer_factory.hpp:77] Creating layer PReLU11
I1023 15:05:27.087491  4985 net.cpp:84] Creating Layer PReLU11
I1023 15:05:27.087493  4985 net.cpp:406] PReLU11 <- Eltwise5
I1023 15:05:27.087496  4985 net.cpp:367] PReLU11 -> Eltwise5 (in-place)
I1023 15:05:27.088376  4985 net.cpp:122] Setting up PReLU11
I1023 15:05:27.088388  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.088392  4985 net.cpp:137] Memory required for data: 1302167584
I1023 15:05:27.088397  4985 layer_factory.hpp:77] Creating layer Eltwise5_PReLU11_0_split
I1023 15:05:27.088402  4985 net.cpp:84] Creating Layer Eltwise5_PReLU11_0_split
I1023 15:05:27.088405  4985 net.cpp:406] Eltwise5_PReLU11_0_split <- Eltwise5
I1023 15:05:27.088409  4985 net.cpp:380] Eltwise5_PReLU11_0_split -> Eltwise5_PReLU11_0_split_0
I1023 15:05:27.088415  4985 net.cpp:380] Eltwise5_PReLU11_0_split -> Eltwise5_PReLU11_0_split_1
I1023 15:05:27.088441  4985 net.cpp:122] Setting up Eltwise5_PReLU11_0_split
I1023 15:05:27.088446  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.088450  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.088452  4985 net.cpp:137] Memory required for data: 1327857696
I1023 15:05:27.088455  4985 layer_factory.hpp:77] Creating layer Convolution13
I1023 15:05:27.088462  4985 net.cpp:84] Creating Layer Convolution13
I1023 15:05:27.088465  4985 net.cpp:406] Convolution13 <- Eltwise5_PReLU11_0_split_0
I1023 15:05:27.088470  4985 net.cpp:380] Convolution13 -> Convolution13
I1023 15:05:27.089570  4985 net.cpp:122] Setting up Convolution13
I1023 15:05:27.089581  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.089584  4985 net.cpp:137] Memory required for data: 1340702752
I1023 15:05:27.089589  4985 layer_factory.hpp:77] Creating layer BatchNorm13
I1023 15:05:27.089596  4985 net.cpp:84] Creating Layer BatchNorm13
I1023 15:05:27.089598  4985 net.cpp:406] BatchNorm13 <- Convolution13
I1023 15:05:27.089602  4985 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1023 15:05:27.089733  4985 net.cpp:122] Setting up BatchNorm13
I1023 15:05:27.089738  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.089741  4985 net.cpp:137] Memory required for data: 1353547808
I1023 15:05:27.089747  4985 layer_factory.hpp:77] Creating layer Scale13
I1023 15:05:27.089752  4985 net.cpp:84] Creating Layer Scale13
I1023 15:05:27.089756  4985 net.cpp:406] Scale13 <- Convolution13
I1023 15:05:27.089758  4985 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1023 15:05:27.089785  4985 layer_factory.hpp:77] Creating layer Scale13
I1023 15:05:27.089867  4985 net.cpp:122] Setting up Scale13
I1023 15:05:27.089874  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.089876  4985 net.cpp:137] Memory required for data: 1366392864
I1023 15:05:27.089880  4985 layer_factory.hpp:77] Creating layer PReLU12
I1023 15:05:27.089885  4985 net.cpp:84] Creating Layer PReLU12
I1023 15:05:27.089889  4985 net.cpp:406] PReLU12 <- Convolution13
I1023 15:05:27.089891  4985 net.cpp:367] PReLU12 -> Convolution13 (in-place)
I1023 15:05:27.090643  4985 net.cpp:122] Setting up PReLU12
I1023 15:05:27.090653  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.090657  4985 net.cpp:137] Memory required for data: 1379237920
I1023 15:05:27.090662  4985 layer_factory.hpp:77] Creating layer Convolution14
I1023 15:05:27.090670  4985 net.cpp:84] Creating Layer Convolution14
I1023 15:05:27.090674  4985 net.cpp:406] Convolution14 <- Convolution13
I1023 15:05:27.090678  4985 net.cpp:380] Convolution14 -> Convolution14
I1023 15:05:27.091737  4985 net.cpp:122] Setting up Convolution14
I1023 15:05:27.091747  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.091751  4985 net.cpp:137] Memory required for data: 1392082976
I1023 15:05:27.091756  4985 layer_factory.hpp:77] Creating layer BatchNorm14
I1023 15:05:27.091765  4985 net.cpp:84] Creating Layer BatchNorm14
I1023 15:05:27.091769  4985 net.cpp:406] BatchNorm14 <- Convolution14
I1023 15:05:27.091773  4985 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1023 15:05:27.091902  4985 net.cpp:122] Setting up BatchNorm14
I1023 15:05:27.091907  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.091910  4985 net.cpp:137] Memory required for data: 1404928032
I1023 15:05:27.091926  4985 layer_factory.hpp:77] Creating layer Scale14
I1023 15:05:27.091933  4985 net.cpp:84] Creating Layer Scale14
I1023 15:05:27.091935  4985 net.cpp:406] Scale14 <- Convolution14
I1023 15:05:27.091939  4985 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1023 15:05:27.091985  4985 layer_factory.hpp:77] Creating layer Scale14
I1023 15:05:27.092072  4985 net.cpp:122] Setting up Scale14
I1023 15:05:27.092077  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.092080  4985 net.cpp:137] Memory required for data: 1417773088
I1023 15:05:27.092085  4985 layer_factory.hpp:77] Creating layer Eltwise6
I1023 15:05:27.092090  4985 net.cpp:84] Creating Layer Eltwise6
I1023 15:05:27.092094  4985 net.cpp:406] Eltwise6 <- Eltwise5_PReLU11_0_split_1
I1023 15:05:27.092097  4985 net.cpp:406] Eltwise6 <- Convolution14
I1023 15:05:27.092102  4985 net.cpp:380] Eltwise6 -> Eltwise6
I1023 15:05:27.092118  4985 net.cpp:122] Setting up Eltwise6
I1023 15:05:27.092123  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.092125  4985 net.cpp:137] Memory required for data: 1430618144
I1023 15:05:27.092128  4985 layer_factory.hpp:77] Creating layer PReLU13
I1023 15:05:27.092131  4985 net.cpp:84] Creating Layer PReLU13
I1023 15:05:27.092134  4985 net.cpp:406] PReLU13 <- Eltwise6
I1023 15:05:27.092137  4985 net.cpp:367] PReLU13 -> Eltwise6 (in-place)
I1023 15:05:27.092895  4985 net.cpp:122] Setting up PReLU13
I1023 15:05:27.092905  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.092907  4985 net.cpp:137] Memory required for data: 1443463200
I1023 15:05:27.092911  4985 layer_factory.hpp:77] Creating layer Eltwise6_PReLU13_0_split
I1023 15:05:27.092917  4985 net.cpp:84] Creating Layer Eltwise6_PReLU13_0_split
I1023 15:05:27.092921  4985 net.cpp:406] Eltwise6_PReLU13_0_split <- Eltwise6
I1023 15:05:27.092924  4985 net.cpp:380] Eltwise6_PReLU13_0_split -> Eltwise6_PReLU13_0_split_0
I1023 15:05:27.092931  4985 net.cpp:380] Eltwise6_PReLU13_0_split -> Eltwise6_PReLU13_0_split_1
I1023 15:05:27.092955  4985 net.cpp:122] Setting up Eltwise6_PReLU13_0_split
I1023 15:05:27.092960  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.092963  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.092967  4985 net.cpp:137] Memory required for data: 1469153312
I1023 15:05:27.092968  4985 layer_factory.hpp:77] Creating layer Convolution15
I1023 15:05:27.092975  4985 net.cpp:84] Creating Layer Convolution15
I1023 15:05:27.092978  4985 net.cpp:406] Convolution15 <- Eltwise6_PReLU13_0_split_0
I1023 15:05:27.092983  4985 net.cpp:380] Convolution15 -> Convolution15
I1023 15:05:27.093880  4985 net.cpp:122] Setting up Convolution15
I1023 15:05:27.093891  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.093894  4985 net.cpp:137] Memory required for data: 1475575840
I1023 15:05:27.093899  4985 layer_factory.hpp:77] Creating layer BatchNorm15
I1023 15:05:27.093905  4985 net.cpp:84] Creating Layer BatchNorm15
I1023 15:05:27.093909  4985 net.cpp:406] BatchNorm15 <- Convolution15
I1023 15:05:27.093912  4985 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1023 15:05:27.094041  4985 net.cpp:122] Setting up BatchNorm15
I1023 15:05:27.094048  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.094050  4985 net.cpp:137] Memory required for data: 1481998368
I1023 15:05:27.094055  4985 layer_factory.hpp:77] Creating layer Scale15
I1023 15:05:27.094060  4985 net.cpp:84] Creating Layer Scale15
I1023 15:05:27.094063  4985 net.cpp:406] Scale15 <- Convolution15
I1023 15:05:27.094066  4985 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1023 15:05:27.094094  4985 layer_factory.hpp:77] Creating layer Scale15
I1023 15:05:27.094171  4985 net.cpp:122] Setting up Scale15
I1023 15:05:27.094175  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.094178  4985 net.cpp:137] Memory required for data: 1488420896
I1023 15:05:27.094182  4985 layer_factory.hpp:77] Creating layer Convolution16
I1023 15:05:27.094189  4985 net.cpp:84] Creating Layer Convolution16
I1023 15:05:27.094200  4985 net.cpp:406] Convolution16 <- Eltwise6_PReLU13_0_split_1
I1023 15:05:27.094207  4985 net.cpp:380] Convolution16 -> Convolution16
I1023 15:05:27.095444  4985 net.cpp:122] Setting up Convolution16
I1023 15:05:27.095455  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.095459  4985 net.cpp:137] Memory required for data: 1494843424
I1023 15:05:27.095464  4985 layer_factory.hpp:77] Creating layer BatchNorm16
I1023 15:05:27.095469  4985 net.cpp:84] Creating Layer BatchNorm16
I1023 15:05:27.095474  4985 net.cpp:406] BatchNorm16 <- Convolution16
I1023 15:05:27.095477  4985 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1023 15:05:27.095605  4985 net.cpp:122] Setting up BatchNorm16
I1023 15:05:27.095610  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.095614  4985 net.cpp:137] Memory required for data: 1501265952
I1023 15:05:27.095619  4985 layer_factory.hpp:77] Creating layer Scale16
I1023 15:05:27.095624  4985 net.cpp:84] Creating Layer Scale16
I1023 15:05:27.095628  4985 net.cpp:406] Scale16 <- Convolution16
I1023 15:05:27.095630  4985 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1023 15:05:27.095656  4985 layer_factory.hpp:77] Creating layer Scale16
I1023 15:05:27.095733  4985 net.cpp:122] Setting up Scale16
I1023 15:05:27.095738  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.095741  4985 net.cpp:137] Memory required for data: 1507688480
I1023 15:05:27.095746  4985 layer_factory.hpp:77] Creating layer PReLU14
I1023 15:05:27.095751  4985 net.cpp:84] Creating Layer PReLU14
I1023 15:05:27.095754  4985 net.cpp:406] PReLU14 <- Convolution16
I1023 15:05:27.095757  4985 net.cpp:367] PReLU14 -> Convolution16 (in-place)
I1023 15:05:27.095948  4985 net.cpp:122] Setting up PReLU14
I1023 15:05:27.095953  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.095964  4985 net.cpp:137] Memory required for data: 1514111008
I1023 15:05:27.095971  4985 layer_factory.hpp:77] Creating layer Convolution17
I1023 15:05:27.095980  4985 net.cpp:84] Creating Layer Convolution17
I1023 15:05:27.095983  4985 net.cpp:406] Convolution17 <- Convolution16
I1023 15:05:27.095988  4985 net.cpp:380] Convolution17 -> Convolution17
I1023 15:05:27.097286  4985 net.cpp:122] Setting up Convolution17
I1023 15:05:27.097295  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.097298  4985 net.cpp:137] Memory required for data: 1520533536
I1023 15:05:27.097302  4985 layer_factory.hpp:77] Creating layer BatchNorm17
I1023 15:05:27.097308  4985 net.cpp:84] Creating Layer BatchNorm17
I1023 15:05:27.097311  4985 net.cpp:406] BatchNorm17 <- Convolution17
I1023 15:05:27.097314  4985 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1023 15:05:27.097445  4985 net.cpp:122] Setting up BatchNorm17
I1023 15:05:27.097450  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.097453  4985 net.cpp:137] Memory required for data: 1526956064
I1023 15:05:27.097467  4985 layer_factory.hpp:77] Creating layer Scale17
I1023 15:05:27.097473  4985 net.cpp:84] Creating Layer Scale17
I1023 15:05:27.097477  4985 net.cpp:406] Scale17 <- Convolution17
I1023 15:05:27.097481  4985 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1023 15:05:27.097507  4985 layer_factory.hpp:77] Creating layer Scale17
I1023 15:05:27.097584  4985 net.cpp:122] Setting up Scale17
I1023 15:05:27.097589  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.097592  4985 net.cpp:137] Memory required for data: 1533378592
I1023 15:05:27.097596  4985 layer_factory.hpp:77] Creating layer Eltwise7
I1023 15:05:27.097602  4985 net.cpp:84] Creating Layer Eltwise7
I1023 15:05:27.097605  4985 net.cpp:406] Eltwise7 <- Convolution15
I1023 15:05:27.097609  4985 net.cpp:406] Eltwise7 <- Convolution17
I1023 15:05:27.097611  4985 net.cpp:380] Eltwise7 -> Eltwise7
I1023 15:05:27.097628  4985 net.cpp:122] Setting up Eltwise7
I1023 15:05:27.097633  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.097636  4985 net.cpp:137] Memory required for data: 1539801120
I1023 15:05:27.097645  4985 layer_factory.hpp:77] Creating layer PReLU15
I1023 15:05:27.097651  4985 net.cpp:84] Creating Layer PReLU15
I1023 15:05:27.097652  4985 net.cpp:406] PReLU15 <- Eltwise7
I1023 15:05:27.097656  4985 net.cpp:367] PReLU15 -> Eltwise7 (in-place)
I1023 15:05:27.098322  4985 net.cpp:122] Setting up PReLU15
I1023 15:05:27.098331  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.098335  4985 net.cpp:137] Memory required for data: 1546223648
I1023 15:05:27.098337  4985 layer_factory.hpp:77] Creating layer Eltwise7_PReLU15_0_split
I1023 15:05:27.098342  4985 net.cpp:84] Creating Layer Eltwise7_PReLU15_0_split
I1023 15:05:27.098345  4985 net.cpp:406] Eltwise7_PReLU15_0_split <- Eltwise7
I1023 15:05:27.098348  4985 net.cpp:380] Eltwise7_PReLU15_0_split -> Eltwise7_PReLU15_0_split_0
I1023 15:05:27.098353  4985 net.cpp:380] Eltwise7_PReLU15_0_split -> Eltwise7_PReLU15_0_split_1
I1023 15:05:27.098377  4985 net.cpp:122] Setting up Eltwise7_PReLU15_0_split
I1023 15:05:27.098381  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.098384  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.098387  4985 net.cpp:137] Memory required for data: 1559068704
I1023 15:05:27.098388  4985 layer_factory.hpp:77] Creating layer Convolution18
I1023 15:05:27.098394  4985 net.cpp:84] Creating Layer Convolution18
I1023 15:05:27.098397  4985 net.cpp:406] Convolution18 <- Eltwise7_PReLU15_0_split_0
I1023 15:05:27.098402  4985 net.cpp:380] Convolution18 -> Convolution18
I1023 15:05:27.100388  4985 net.cpp:122] Setting up Convolution18
I1023 15:05:27.100396  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.100399  4985 net.cpp:137] Memory required for data: 1565491232
I1023 15:05:27.100404  4985 layer_factory.hpp:77] Creating layer BatchNorm18
I1023 15:05:27.100409  4985 net.cpp:84] Creating Layer BatchNorm18
I1023 15:05:27.100412  4985 net.cpp:406] BatchNorm18 <- Convolution18
I1023 15:05:27.100416  4985 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1023 15:05:27.100549  4985 net.cpp:122] Setting up BatchNorm18
I1023 15:05:27.100553  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.100556  4985 net.cpp:137] Memory required for data: 1571913760
I1023 15:05:27.100561  4985 layer_factory.hpp:77] Creating layer Scale18
I1023 15:05:27.100565  4985 net.cpp:84] Creating Layer Scale18
I1023 15:05:27.100569  4985 net.cpp:406] Scale18 <- Convolution18
I1023 15:05:27.100571  4985 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1023 15:05:27.100596  4985 layer_factory.hpp:77] Creating layer Scale18
I1023 15:05:27.100672  4985 net.cpp:122] Setting up Scale18
I1023 15:05:27.100677  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.100678  4985 net.cpp:137] Memory required for data: 1578336288
I1023 15:05:27.100682  4985 layer_factory.hpp:77] Creating layer PReLU16
I1023 15:05:27.100687  4985 net.cpp:84] Creating Layer PReLU16
I1023 15:05:27.100688  4985 net.cpp:406] PReLU16 <- Convolution18
I1023 15:05:27.100692  4985 net.cpp:367] PReLU16 -> Convolution18 (in-place)
I1023 15:05:27.100836  4985 net.cpp:122] Setting up PReLU16
I1023 15:05:27.100839  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.100841  4985 net.cpp:137] Memory required for data: 1584758816
I1023 15:05:27.100845  4985 layer_factory.hpp:77] Creating layer Convolution19
I1023 15:05:27.100852  4985 net.cpp:84] Creating Layer Convolution19
I1023 15:05:27.100854  4985 net.cpp:406] Convolution19 <- Convolution18
I1023 15:05:27.100858  4985 net.cpp:380] Convolution19 -> Convolution19
I1023 15:05:27.103036  4985 net.cpp:122] Setting up Convolution19
I1023 15:05:27.103046  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.103049  4985 net.cpp:137] Memory required for data: 1591181344
I1023 15:05:27.103055  4985 layer_factory.hpp:77] Creating layer BatchNorm19
I1023 15:05:27.103060  4985 net.cpp:84] Creating Layer BatchNorm19
I1023 15:05:27.103062  4985 net.cpp:406] BatchNorm19 <- Convolution19
I1023 15:05:27.103066  4985 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1023 15:05:27.103206  4985 net.cpp:122] Setting up BatchNorm19
I1023 15:05:27.103211  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.103214  4985 net.cpp:137] Memory required for data: 1597603872
I1023 15:05:27.103219  4985 layer_factory.hpp:77] Creating layer Scale19
I1023 15:05:27.103224  4985 net.cpp:84] Creating Layer Scale19
I1023 15:05:27.103226  4985 net.cpp:406] Scale19 <- Convolution19
I1023 15:05:27.103229  4985 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1023 15:05:27.103256  4985 layer_factory.hpp:77] Creating layer Scale19
I1023 15:05:27.103334  4985 net.cpp:122] Setting up Scale19
I1023 15:05:27.103338  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.103340  4985 net.cpp:137] Memory required for data: 1604026400
I1023 15:05:27.103344  4985 layer_factory.hpp:77] Creating layer Eltwise8
I1023 15:05:27.103348  4985 net.cpp:84] Creating Layer Eltwise8
I1023 15:05:27.103351  4985 net.cpp:406] Eltwise8 <- Eltwise7_PReLU15_0_split_1
I1023 15:05:27.103354  4985 net.cpp:406] Eltwise8 <- Convolution19
I1023 15:05:27.103358  4985 net.cpp:380] Eltwise8 -> Eltwise8
I1023 15:05:27.103373  4985 net.cpp:122] Setting up Eltwise8
I1023 15:05:27.103376  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.103379  4985 net.cpp:137] Memory required for data: 1610448928
I1023 15:05:27.103380  4985 layer_factory.hpp:77] Creating layer PReLU17
I1023 15:05:27.103384  4985 net.cpp:84] Creating Layer PReLU17
I1023 15:05:27.103386  4985 net.cpp:406] PReLU17 <- Eltwise8
I1023 15:05:27.103389  4985 net.cpp:367] PReLU17 -> Eltwise8 (in-place)
I1023 15:05:27.104066  4985 net.cpp:122] Setting up PReLU17
I1023 15:05:27.104075  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.104079  4985 net.cpp:137] Memory required for data: 1616871456
I1023 15:05:27.104082  4985 layer_factory.hpp:77] Creating layer Eltwise8_PReLU17_0_split
I1023 15:05:27.104086  4985 net.cpp:84] Creating Layer Eltwise8_PReLU17_0_split
I1023 15:05:27.104089  4985 net.cpp:406] Eltwise8_PReLU17_0_split <- Eltwise8
I1023 15:05:27.104094  4985 net.cpp:380] Eltwise8_PReLU17_0_split -> Eltwise8_PReLU17_0_split_0
I1023 15:05:27.104099  4985 net.cpp:380] Eltwise8_PReLU17_0_split -> Eltwise8_PReLU17_0_split_1
I1023 15:05:27.104122  4985 net.cpp:122] Setting up Eltwise8_PReLU17_0_split
I1023 15:05:27.104126  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.104130  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.104131  4985 net.cpp:137] Memory required for data: 1629716512
I1023 15:05:27.104135  4985 layer_factory.hpp:77] Creating layer Convolution20
I1023 15:05:27.104140  4985 net.cpp:84] Creating Layer Convolution20
I1023 15:05:27.104143  4985 net.cpp:406] Convolution20 <- Eltwise8_PReLU17_0_split_0
I1023 15:05:27.104147  4985 net.cpp:380] Convolution20 -> Convolution20
I1023 15:05:27.106483  4985 net.cpp:122] Setting up Convolution20
I1023 15:05:27.106492  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.106495  4985 net.cpp:137] Memory required for data: 1636139040
I1023 15:05:27.106500  4985 layer_factory.hpp:77] Creating layer BatchNorm20
I1023 15:05:27.106505  4985 net.cpp:84] Creating Layer BatchNorm20
I1023 15:05:27.106508  4985 net.cpp:406] BatchNorm20 <- Convolution20
I1023 15:05:27.106513  4985 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1023 15:05:27.106647  4985 net.cpp:122] Setting up BatchNorm20
I1023 15:05:27.106652  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.106654  4985 net.cpp:137] Memory required for data: 1642561568
I1023 15:05:27.106659  4985 layer_factory.hpp:77] Creating layer Scale20
I1023 15:05:27.106663  4985 net.cpp:84] Creating Layer Scale20
I1023 15:05:27.106667  4985 net.cpp:406] Scale20 <- Convolution20
I1023 15:05:27.106669  4985 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1023 15:05:27.106695  4985 layer_factory.hpp:77] Creating layer Scale20
I1023 15:05:27.106775  4985 net.cpp:122] Setting up Scale20
I1023 15:05:27.106778  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.106788  4985 net.cpp:137] Memory required for data: 1648984096
I1023 15:05:27.106793  4985 layer_factory.hpp:77] Creating layer PReLU18
I1023 15:05:27.106797  4985 net.cpp:84] Creating Layer PReLU18
I1023 15:05:27.106801  4985 net.cpp:406] PReLU18 <- Convolution20
I1023 15:05:27.106803  4985 net.cpp:367] PReLU18 -> Convolution20 (in-place)
I1023 15:05:27.106950  4985 net.cpp:122] Setting up PReLU18
I1023 15:05:27.106954  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.106956  4985 net.cpp:137] Memory required for data: 1655406624
I1023 15:05:27.106959  4985 layer_factory.hpp:77] Creating layer Convolution21
I1023 15:05:27.106966  4985 net.cpp:84] Creating Layer Convolution21
I1023 15:05:27.106968  4985 net.cpp:406] Convolution21 <- Convolution20
I1023 15:05:27.106972  4985 net.cpp:380] Convolution21 -> Convolution21
I1023 15:05:27.108634  4985 net.cpp:122] Setting up Convolution21
I1023 15:05:27.108644  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.108646  4985 net.cpp:137] Memory required for data: 1661829152
I1023 15:05:27.108651  4985 layer_factory.hpp:77] Creating layer BatchNorm21
I1023 15:05:27.108656  4985 net.cpp:84] Creating Layer BatchNorm21
I1023 15:05:27.108659  4985 net.cpp:406] BatchNorm21 <- Convolution21
I1023 15:05:27.108664  4985 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1023 15:05:27.108793  4985 net.cpp:122] Setting up BatchNorm21
I1023 15:05:27.108798  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.108799  4985 net.cpp:137] Memory required for data: 1668251680
I1023 15:05:27.108804  4985 layer_factory.hpp:77] Creating layer Scale21
I1023 15:05:27.108809  4985 net.cpp:84] Creating Layer Scale21
I1023 15:05:27.108811  4985 net.cpp:406] Scale21 <- Convolution21
I1023 15:05:27.108814  4985 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1023 15:05:27.108840  4985 layer_factory.hpp:77] Creating layer Scale21
I1023 15:05:27.108917  4985 net.cpp:122] Setting up Scale21
I1023 15:05:27.108922  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.108923  4985 net.cpp:137] Memory required for data: 1674674208
I1023 15:05:27.108927  4985 layer_factory.hpp:77] Creating layer Eltwise9
I1023 15:05:27.108932  4985 net.cpp:84] Creating Layer Eltwise9
I1023 15:05:27.108934  4985 net.cpp:406] Eltwise9 <- Eltwise8_PReLU17_0_split_1
I1023 15:05:27.108937  4985 net.cpp:406] Eltwise9 <- Convolution21
I1023 15:05:27.108940  4985 net.cpp:380] Eltwise9 -> Eltwise9
I1023 15:05:27.108955  4985 net.cpp:122] Setting up Eltwise9
I1023 15:05:27.108959  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.108961  4985 net.cpp:137] Memory required for data: 1681096736
I1023 15:05:27.108963  4985 layer_factory.hpp:77] Creating layer PReLU19
I1023 15:05:27.108968  4985 net.cpp:84] Creating Layer PReLU19
I1023 15:05:27.108969  4985 net.cpp:406] PReLU19 <- Eltwise9
I1023 15:05:27.108973  4985 net.cpp:367] PReLU19 -> Eltwise9 (in-place)
I1023 15:05:27.109627  4985 net.cpp:122] Setting up PReLU19
I1023 15:05:27.109634  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.109637  4985 net.cpp:137] Memory required for data: 1687519264
I1023 15:05:27.109642  4985 layer_factory.hpp:77] Creating layer Pooling1
I1023 15:05:27.109647  4985 net.cpp:84] Creating Layer Pooling1
I1023 15:05:27.109649  4985 net.cpp:406] Pooling1 <- Eltwise9
I1023 15:05:27.109652  4985 net.cpp:380] Pooling1 -> Pooling1
I1023 15:05:27.109797  4985 net.cpp:122] Setting up Pooling1
I1023 15:05:27.109804  4985 net.cpp:129] Top shape: 8 64 1 1 (512)
I1023 15:05:27.109807  4985 net.cpp:137] Memory required for data: 1687521312
I1023 15:05:27.109809  4985 layer_factory.hpp:77] Creating layer InnerProduct1
I1023 15:05:27.109817  4985 net.cpp:84] Creating Layer InnerProduct1
I1023 15:05:27.109819  4985 net.cpp:406] InnerProduct1 <- Pooling1
I1023 15:05:27.109823  4985 net.cpp:380] InnerProduct1 -> InnerProduct1
I1023 15:05:27.109899  4985 net.cpp:122] Setting up InnerProduct1
I1023 15:05:27.109905  4985 net.cpp:129] Top shape: 8 4 (32)
I1023 15:05:27.109906  4985 net.cpp:137] Memory required for data: 1687521440
I1023 15:05:27.109918  4985 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1023 15:05:27.109923  4985 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1023 15:05:27.109926  4985 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I1023 15:05:27.109930  4985 net.cpp:406] SoftmaxWithLoss1 <- Data2
I1023 15:05:27.109933  4985 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1023 15:05:27.109939  4985 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1023 15:05:27.110471  4985 net.cpp:122] Setting up SoftmaxWithLoss1
I1023 15:05:27.110479  4985 net.cpp:129] Top shape: (1)
I1023 15:05:27.110482  4985 net.cpp:132]     with loss weight 1
I1023 15:05:27.110496  4985 net.cpp:137] Memory required for data: 1687521444
I1023 15:05:27.110498  4985 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1023 15:05:27.110500  4985 net.cpp:198] InnerProduct1 needs backward computation.
I1023 15:05:27.110503  4985 net.cpp:198] Pooling1 needs backward computation.
I1023 15:05:27.110505  4985 net.cpp:198] PReLU19 needs backward computation.
I1023 15:05:27.110507  4985 net.cpp:198] Eltwise9 needs backward computation.
I1023 15:05:27.110510  4985 net.cpp:198] Scale21 needs backward computation.
I1023 15:05:27.110512  4985 net.cpp:198] BatchNorm21 needs backward computation.
I1023 15:05:27.110514  4985 net.cpp:198] Convolution21 needs backward computation.
I1023 15:05:27.110517  4985 net.cpp:198] PReLU18 needs backward computation.
I1023 15:05:27.110518  4985 net.cpp:198] Scale20 needs backward computation.
I1023 15:05:27.110520  4985 net.cpp:198] BatchNorm20 needs backward computation.
I1023 15:05:27.110522  4985 net.cpp:198] Convolution20 needs backward computation.
I1023 15:05:27.110524  4985 net.cpp:198] Eltwise8_PReLU17_0_split needs backward computation.
I1023 15:05:27.110527  4985 net.cpp:198] PReLU17 needs backward computation.
I1023 15:05:27.110529  4985 net.cpp:198] Eltwise8 needs backward computation.
I1023 15:05:27.110532  4985 net.cpp:198] Scale19 needs backward computation.
I1023 15:05:27.110533  4985 net.cpp:198] BatchNorm19 needs backward computation.
I1023 15:05:27.110535  4985 net.cpp:198] Convolution19 needs backward computation.
I1023 15:05:27.110538  4985 net.cpp:198] PReLU16 needs backward computation.
I1023 15:05:27.110540  4985 net.cpp:198] Scale18 needs backward computation.
I1023 15:05:27.110543  4985 net.cpp:198] BatchNorm18 needs backward computation.
I1023 15:05:27.110544  4985 net.cpp:198] Convolution18 needs backward computation.
I1023 15:05:27.110548  4985 net.cpp:198] Eltwise7_PReLU15_0_split needs backward computation.
I1023 15:05:27.110549  4985 net.cpp:198] PReLU15 needs backward computation.
I1023 15:05:27.110551  4985 net.cpp:198] Eltwise7 needs backward computation.
I1023 15:05:27.110554  4985 net.cpp:198] Scale17 needs backward computation.
I1023 15:05:27.110558  4985 net.cpp:198] BatchNorm17 needs backward computation.
I1023 15:05:27.110559  4985 net.cpp:198] Convolution17 needs backward computation.
I1023 15:05:27.110561  4985 net.cpp:198] PReLU14 needs backward computation.
I1023 15:05:27.110564  4985 net.cpp:198] Scale16 needs backward computation.
I1023 15:05:27.110566  4985 net.cpp:198] BatchNorm16 needs backward computation.
I1023 15:05:27.110569  4985 net.cpp:198] Convolution16 needs backward computation.
I1023 15:05:27.110571  4985 net.cpp:198] Scale15 needs backward computation.
I1023 15:05:27.110574  4985 net.cpp:198] BatchNorm15 needs backward computation.
I1023 15:05:27.110575  4985 net.cpp:198] Convolution15 needs backward computation.
I1023 15:05:27.110579  4985 net.cpp:198] Eltwise6_PReLU13_0_split needs backward computation.
I1023 15:05:27.110580  4985 net.cpp:198] PReLU13 needs backward computation.
I1023 15:05:27.110584  4985 net.cpp:198] Eltwise6 needs backward computation.
I1023 15:05:27.110585  4985 net.cpp:198] Scale14 needs backward computation.
I1023 15:05:27.110587  4985 net.cpp:198] BatchNorm14 needs backward computation.
I1023 15:05:27.110590  4985 net.cpp:198] Convolution14 needs backward computation.
I1023 15:05:27.110592  4985 net.cpp:198] PReLU12 needs backward computation.
I1023 15:05:27.110601  4985 net.cpp:198] Scale13 needs backward computation.
I1023 15:05:27.110605  4985 net.cpp:198] BatchNorm13 needs backward computation.
I1023 15:05:27.110606  4985 net.cpp:198] Convolution13 needs backward computation.
I1023 15:05:27.110610  4985 net.cpp:198] Eltwise5_PReLU11_0_split needs backward computation.
I1023 15:05:27.110611  4985 net.cpp:198] PReLU11 needs backward computation.
I1023 15:05:27.110615  4985 net.cpp:198] Eltwise5 needs backward computation.
I1023 15:05:27.110617  4985 net.cpp:198] Scale12 needs backward computation.
I1023 15:05:27.110620  4985 net.cpp:198] BatchNorm12 needs backward computation.
I1023 15:05:27.110621  4985 net.cpp:198] Convolution12 needs backward computation.
I1023 15:05:27.110625  4985 net.cpp:198] PReLU10 needs backward computation.
I1023 15:05:27.110626  4985 net.cpp:198] Scale11 needs backward computation.
I1023 15:05:27.110628  4985 net.cpp:198] BatchNorm11 needs backward computation.
I1023 15:05:27.110631  4985 net.cpp:198] Convolution11 needs backward computation.
I1023 15:05:27.110633  4985 net.cpp:198] Eltwise4_PReLU9_0_split needs backward computation.
I1023 15:05:27.110636  4985 net.cpp:198] PReLU9 needs backward computation.
I1023 15:05:27.110638  4985 net.cpp:198] Eltwise4 needs backward computation.
I1023 15:05:27.110641  4985 net.cpp:198] Scale10 needs backward computation.
I1023 15:05:27.110643  4985 net.cpp:198] BatchNorm10 needs backward computation.
I1023 15:05:27.110646  4985 net.cpp:198] Convolution10 needs backward computation.
I1023 15:05:27.110648  4985 net.cpp:198] PReLU8 needs backward computation.
I1023 15:05:27.110651  4985 net.cpp:198] Scale9 needs backward computation.
I1023 15:05:27.110653  4985 net.cpp:198] BatchNorm9 needs backward computation.
I1023 15:05:27.110656  4985 net.cpp:198] Convolution9 needs backward computation.
I1023 15:05:27.110658  4985 net.cpp:198] Scale8 needs backward computation.
I1023 15:05:27.110661  4985 net.cpp:198] BatchNorm8 needs backward computation.
I1023 15:05:27.110662  4985 net.cpp:198] Convolution8 needs backward computation.
I1023 15:05:27.110666  4985 net.cpp:198] Eltwise3_PReLU7_0_split needs backward computation.
I1023 15:05:27.110668  4985 net.cpp:198] PReLU7 needs backward computation.
I1023 15:05:27.110671  4985 net.cpp:198] Eltwise3 needs backward computation.
I1023 15:05:27.110673  4985 net.cpp:198] Scale7 needs backward computation.
I1023 15:05:27.110676  4985 net.cpp:198] BatchNorm7 needs backward computation.
I1023 15:05:27.110678  4985 net.cpp:198] Convolution7 needs backward computation.
I1023 15:05:27.110680  4985 net.cpp:198] PReLU6 needs backward computation.
I1023 15:05:27.110682  4985 net.cpp:198] Scale6 needs backward computation.
I1023 15:05:27.110684  4985 net.cpp:198] BatchNorm6 needs backward computation.
I1023 15:05:27.110687  4985 net.cpp:198] Convolution6 needs backward computation.
I1023 15:05:27.110689  4985 net.cpp:198] Eltwise2_PReLU5_0_split needs backward computation.
I1023 15:05:27.110692  4985 net.cpp:198] PReLU5 needs backward computation.
I1023 15:05:27.110694  4985 net.cpp:198] Eltwise2 needs backward computation.
I1023 15:05:27.110697  4985 net.cpp:198] Scale5 needs backward computation.
I1023 15:05:27.110699  4985 net.cpp:198] BatchNorm5 needs backward computation.
I1023 15:05:27.110702  4985 net.cpp:198] Convolution5 needs backward computation.
I1023 15:05:27.110704  4985 net.cpp:198] PReLU4 needs backward computation.
I1023 15:05:27.110707  4985 net.cpp:198] Scale4 needs backward computation.
I1023 15:05:27.110709  4985 net.cpp:198] BatchNorm4 needs backward computation.
I1023 15:05:27.110711  4985 net.cpp:198] Convolution4 needs backward computation.
I1023 15:05:27.110714  4985 net.cpp:198] Eltwise1_PReLU3_0_split needs backward computation.
I1023 15:05:27.110716  4985 net.cpp:198] PReLU3 needs backward computation.
I1023 15:05:27.110719  4985 net.cpp:198] Eltwise1 needs backward computation.
I1023 15:05:27.110721  4985 net.cpp:198] Scale3 needs backward computation.
I1023 15:05:27.110724  4985 net.cpp:198] BatchNorm3 needs backward computation.
I1023 15:05:27.110729  4985 net.cpp:198] Convolution3 needs backward computation.
I1023 15:05:27.110733  4985 net.cpp:198] PReLU2 needs backward computation.
I1023 15:05:27.110735  4985 net.cpp:198] Scale2 needs backward computation.
I1023 15:05:27.110738  4985 net.cpp:198] BatchNorm2 needs backward computation.
I1023 15:05:27.110739  4985 net.cpp:198] Convolution2 needs backward computation.
I1023 15:05:27.110743  4985 net.cpp:198] Convolution1_PReLU1_0_split needs backward computation.
I1023 15:05:27.110745  4985 net.cpp:198] PReLU1 needs backward computation.
I1023 15:05:27.110747  4985 net.cpp:198] Scale1 needs backward computation.
I1023 15:05:27.110749  4985 net.cpp:198] BatchNorm1 needs backward computation.
I1023 15:05:27.110751  4985 net.cpp:198] Convolution1 needs backward computation.
I1023 15:05:27.110754  4985 net.cpp:200] Data1 does not need backward computation.
I1023 15:05:27.110756  4985 net.cpp:242] This network produces output SoftmaxWithLoss1
I1023 15:05:27.110787  4985 net.cpp:255] Network initialization done.
I1023 15:05:27.112128  4985 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/English_orange/neural/res20/res20_prelu_train_test.prototxt
I1023 15:05:27.112136  4985 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1023 15:05:27.112141  4985 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/English_orange/neural/res20/res20_prelu_train_test.prototxt
I1023 15:05:27.112208  4985 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I1023 15:05:27.112571  4985 net.cpp:51] Initializing net from parameters: 
name: "resnet"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_file: "/home/x306/caffe/xn/English_orange/data/orange1_mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/English_orange/data/val1_lmdb"
    batch_size: 8
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU1"
  type: "PReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU2"
  type: "PReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU3"
  type: "PReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU4"
  type: "PReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU5"
  type: "PReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU6"
  type: "PReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU7"
  type: "PReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU8"
  type: "PReLU"
  bottom: "Convolution9"
  top: "Convolution9"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU9"
  type: "PReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU10"
  type: "PReLU"
  bottom: "Convolution11"
  top: "Convolution11"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU11"
  type: "PReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU12"
  type: "PReLU"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU13"
  type: "PReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU14"
  type: "PReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU15"
  type: "PReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU16"
  type: "PReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU17"
  type: "PReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU18"
  type: "PReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU19"
  type: "PReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
layer {
  name: "Accuracy1"
  type: "Accuracy"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "Accuracy1"
  include {
    phase: TEST
  }
}
I1023 15:05:27.112797  4985 layer_factory.hpp:77] Creating layer Data1
I1023 15:05:27.112834  4985 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/English_orange/data/val1_lmdb
I1023 15:05:27.112845  4985 net.cpp:84] Creating Layer Data1
I1023 15:05:27.112849  4985 net.cpp:380] Data1 -> Data1
I1023 15:05:27.112856  4985 net.cpp:380] Data1 -> Data2
I1023 15:05:27.112861  4985 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/English_orange/data/orange1_mean.binaryproto
I1023 15:05:27.113981  4985 data_layer.cpp:45] output data size: 8,3,224,224
I1023 15:05:27.122858  4985 net.cpp:122] Setting up Data1
I1023 15:05:27.122877  4985 net.cpp:129] Top shape: 8 3 224 224 (1204224)
I1023 15:05:27.122881  4985 net.cpp:129] Top shape: 8 (8)
I1023 15:05:27.122884  4985 net.cpp:137] Memory required for data: 4816928
I1023 15:05:27.122889  4985 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I1023 15:05:27.122897  4985 net.cpp:84] Creating Layer Data2_Data1_1_split
I1023 15:05:27.122900  4985 net.cpp:406] Data2_Data1_1_split <- Data2
I1023 15:05:27.122905  4985 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I1023 15:05:27.122912  4985 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I1023 15:05:27.122958  4985 net.cpp:122] Setting up Data2_Data1_1_split
I1023 15:05:27.122962  4985 net.cpp:129] Top shape: 8 (8)
I1023 15:05:27.122965  4985 net.cpp:129] Top shape: 8 (8)
I1023 15:05:27.122967  4985 net.cpp:137] Memory required for data: 4816992
I1023 15:05:27.122969  4985 layer_factory.hpp:77] Creating layer Convolution1
I1023 15:05:27.122978  4985 net.cpp:84] Creating Layer Convolution1
I1023 15:05:27.122982  4985 net.cpp:406] Convolution1 <- Data1
I1023 15:05:27.122984  4985 net.cpp:380] Convolution1 -> Convolution1
I1023 15:05:27.124403  4985 net.cpp:122] Setting up Convolution1
I1023 15:05:27.124413  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.124416  4985 net.cpp:137] Memory required for data: 30507104
I1023 15:05:27.124425  4985 layer_factory.hpp:77] Creating layer BatchNorm1
I1023 15:05:27.124445  4985 net.cpp:84] Creating Layer BatchNorm1
I1023 15:05:27.124449  4985 net.cpp:406] BatchNorm1 <- Convolution1
I1023 15:05:27.124454  4985 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1023 15:05:27.124635  4985 net.cpp:122] Setting up BatchNorm1
I1023 15:05:27.124640  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.124642  4985 net.cpp:137] Memory required for data: 56197216
I1023 15:05:27.124650  4985 layer_factory.hpp:77] Creating layer Scale1
I1023 15:05:27.124657  4985 net.cpp:84] Creating Layer Scale1
I1023 15:05:27.124660  4985 net.cpp:406] Scale1 <- Convolution1
I1023 15:05:27.124663  4985 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1023 15:05:27.124693  4985 layer_factory.hpp:77] Creating layer Scale1
I1023 15:05:27.124843  4985 net.cpp:122] Setting up Scale1
I1023 15:05:27.124848  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.124851  4985 net.cpp:137] Memory required for data: 81887328
I1023 15:05:27.124855  4985 layer_factory.hpp:77] Creating layer PReLU1
I1023 15:05:27.124861  4985 net.cpp:84] Creating Layer PReLU1
I1023 15:05:27.124863  4985 net.cpp:406] PReLU1 <- Convolution1
I1023 15:05:27.124866  4985 net.cpp:367] PReLU1 -> Convolution1 (in-place)
I1023 15:05:27.126080  4985 net.cpp:122] Setting up PReLU1
I1023 15:05:27.126092  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.126096  4985 net.cpp:137] Memory required for data: 107577440
I1023 15:05:27.126101  4985 layer_factory.hpp:77] Creating layer Convolution1_PReLU1_0_split
I1023 15:05:27.126106  4985 net.cpp:84] Creating Layer Convolution1_PReLU1_0_split
I1023 15:05:27.126109  4985 net.cpp:406] Convolution1_PReLU1_0_split <- Convolution1
I1023 15:05:27.126113  4985 net.cpp:380] Convolution1_PReLU1_0_split -> Convolution1_PReLU1_0_split_0
I1023 15:05:27.126119  4985 net.cpp:380] Convolution1_PReLU1_0_split -> Convolution1_PReLU1_0_split_1
I1023 15:05:27.126147  4985 net.cpp:122] Setting up Convolution1_PReLU1_0_split
I1023 15:05:27.126152  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.126154  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.126157  4985 net.cpp:137] Memory required for data: 158957664
I1023 15:05:27.126158  4985 layer_factory.hpp:77] Creating layer Convolution2
I1023 15:05:27.126166  4985 net.cpp:84] Creating Layer Convolution2
I1023 15:05:27.126168  4985 net.cpp:406] Convolution2 <- Convolution1_PReLU1_0_split_0
I1023 15:05:27.126173  4985 net.cpp:380] Convolution2 -> Convolution2
I1023 15:05:27.126832  4985 net.cpp:122] Setting up Convolution2
I1023 15:05:27.126840  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.126843  4985 net.cpp:137] Memory required for data: 184647776
I1023 15:05:27.126850  4985 layer_factory.hpp:77] Creating layer BatchNorm2
I1023 15:05:27.126857  4985 net.cpp:84] Creating Layer BatchNorm2
I1023 15:05:27.126859  4985 net.cpp:406] BatchNorm2 <- Convolution2
I1023 15:05:27.126863  4985 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1023 15:05:27.127033  4985 net.cpp:122] Setting up BatchNorm2
I1023 15:05:27.127038  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.127039  4985 net.cpp:137] Memory required for data: 210337888
I1023 15:05:27.127044  4985 layer_factory.hpp:77] Creating layer Scale2
I1023 15:05:27.127049  4985 net.cpp:84] Creating Layer Scale2
I1023 15:05:27.127053  4985 net.cpp:406] Scale2 <- Convolution2
I1023 15:05:27.127055  4985 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1023 15:05:27.127084  4985 layer_factory.hpp:77] Creating layer Scale2
I1023 15:05:27.127225  4985 net.cpp:122] Setting up Scale2
I1023 15:05:27.127230  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.127233  4985 net.cpp:137] Memory required for data: 236028000
I1023 15:05:27.127236  4985 layer_factory.hpp:77] Creating layer PReLU2
I1023 15:05:27.127240  4985 net.cpp:84] Creating Layer PReLU2
I1023 15:05:27.127243  4985 net.cpp:406] PReLU2 <- Convolution2
I1023 15:05:27.127246  4985 net.cpp:367] PReLU2 -> Convolution2 (in-place)
I1023 15:05:27.128504  4985 net.cpp:122] Setting up PReLU2
I1023 15:05:27.128545  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.128548  4985 net.cpp:137] Memory required for data: 261718112
I1023 15:05:27.128553  4985 layer_factory.hpp:77] Creating layer Convolution3
I1023 15:05:27.128566  4985 net.cpp:84] Creating Layer Convolution3
I1023 15:05:27.128571  4985 net.cpp:406] Convolution3 <- Convolution2
I1023 15:05:27.128576  4985 net.cpp:380] Convolution3 -> Convolution3
I1023 15:05:27.130550  4985 net.cpp:122] Setting up Convolution3
I1023 15:05:27.130564  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.130568  4985 net.cpp:137] Memory required for data: 287408224
I1023 15:05:27.130578  4985 layer_factory.hpp:77] Creating layer BatchNorm3
I1023 15:05:27.130584  4985 net.cpp:84] Creating Layer BatchNorm3
I1023 15:05:27.130587  4985 net.cpp:406] BatchNorm3 <- Convolution3
I1023 15:05:27.130591  4985 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1023 15:05:27.130759  4985 net.cpp:122] Setting up BatchNorm3
I1023 15:05:27.130764  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.130765  4985 net.cpp:137] Memory required for data: 313098336
I1023 15:05:27.130770  4985 layer_factory.hpp:77] Creating layer Scale3
I1023 15:05:27.130775  4985 net.cpp:84] Creating Layer Scale3
I1023 15:05:27.130779  4985 net.cpp:406] Scale3 <- Convolution3
I1023 15:05:27.130781  4985 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1023 15:05:27.130815  4985 layer_factory.hpp:77] Creating layer Scale3
I1023 15:05:27.130930  4985 net.cpp:122] Setting up Scale3
I1023 15:05:27.130935  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.130937  4985 net.cpp:137] Memory required for data: 338788448
I1023 15:05:27.130941  4985 layer_factory.hpp:77] Creating layer Eltwise1
I1023 15:05:27.130946  4985 net.cpp:84] Creating Layer Eltwise1
I1023 15:05:27.130949  4985 net.cpp:406] Eltwise1 <- Convolution1_PReLU1_0_split_1
I1023 15:05:27.130952  4985 net.cpp:406] Eltwise1 <- Convolution3
I1023 15:05:27.130956  4985 net.cpp:380] Eltwise1 -> Eltwise1
I1023 15:05:27.130975  4985 net.cpp:122] Setting up Eltwise1
I1023 15:05:27.130978  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.130980  4985 net.cpp:137] Memory required for data: 364478560
I1023 15:05:27.130982  4985 layer_factory.hpp:77] Creating layer PReLU3
I1023 15:05:27.130987  4985 net.cpp:84] Creating Layer PReLU3
I1023 15:05:27.130990  4985 net.cpp:406] PReLU3 <- Eltwise1
I1023 15:05:27.130992  4985 net.cpp:367] PReLU3 -> Eltwise1 (in-place)
I1023 15:05:27.132217  4985 net.cpp:122] Setting up PReLU3
I1023 15:05:27.132232  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.132236  4985 net.cpp:137] Memory required for data: 390168672
I1023 15:05:27.132241  4985 layer_factory.hpp:77] Creating layer Eltwise1_PReLU3_0_split
I1023 15:05:27.132247  4985 net.cpp:84] Creating Layer Eltwise1_PReLU3_0_split
I1023 15:05:27.132251  4985 net.cpp:406] Eltwise1_PReLU3_0_split <- Eltwise1
I1023 15:05:27.132254  4985 net.cpp:380] Eltwise1_PReLU3_0_split -> Eltwise1_PReLU3_0_split_0
I1023 15:05:27.132259  4985 net.cpp:380] Eltwise1_PReLU3_0_split -> Eltwise1_PReLU3_0_split_1
I1023 15:05:27.132287  4985 net.cpp:122] Setting up Eltwise1_PReLU3_0_split
I1023 15:05:27.132292  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.132294  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.132297  4985 net.cpp:137] Memory required for data: 441548896
I1023 15:05:27.132298  4985 layer_factory.hpp:77] Creating layer Convolution4
I1023 15:05:27.132306  4985 net.cpp:84] Creating Layer Convolution4
I1023 15:05:27.132309  4985 net.cpp:406] Convolution4 <- Eltwise1_PReLU3_0_split_0
I1023 15:05:27.132313  4985 net.cpp:380] Convolution4 -> Convolution4
I1023 15:05:27.133448  4985 net.cpp:122] Setting up Convolution4
I1023 15:05:27.133458  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.133461  4985 net.cpp:137] Memory required for data: 467239008
I1023 15:05:27.133466  4985 layer_factory.hpp:77] Creating layer BatchNorm4
I1023 15:05:27.133487  4985 net.cpp:84] Creating Layer BatchNorm4
I1023 15:05:27.133491  4985 net.cpp:406] BatchNorm4 <- Convolution4
I1023 15:05:27.133494  4985 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1023 15:05:27.134052  4985 net.cpp:122] Setting up BatchNorm4
I1023 15:05:27.134057  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.134060  4985 net.cpp:137] Memory required for data: 492929120
I1023 15:05:27.134065  4985 layer_factory.hpp:77] Creating layer Scale4
I1023 15:05:27.134069  4985 net.cpp:84] Creating Layer Scale4
I1023 15:05:27.134073  4985 net.cpp:406] Scale4 <- Convolution4
I1023 15:05:27.134075  4985 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1023 15:05:27.134106  4985 layer_factory.hpp:77] Creating layer Scale4
I1023 15:05:27.134253  4985 net.cpp:122] Setting up Scale4
I1023 15:05:27.134258  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.134259  4985 net.cpp:137] Memory required for data: 518619232
I1023 15:05:27.134263  4985 layer_factory.hpp:77] Creating layer PReLU4
I1023 15:05:27.134268  4985 net.cpp:84] Creating Layer PReLU4
I1023 15:05:27.134269  4985 net.cpp:406] PReLU4 <- Convolution4
I1023 15:05:27.134272  4985 net.cpp:367] PReLU4 -> Convolution4 (in-place)
I1023 15:05:27.135434  4985 net.cpp:122] Setting up PReLU4
I1023 15:05:27.135447  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.135450  4985 net.cpp:137] Memory required for data: 544309344
I1023 15:05:27.135454  4985 layer_factory.hpp:77] Creating layer Convolution5
I1023 15:05:27.135463  4985 net.cpp:84] Creating Layer Convolution5
I1023 15:05:27.135466  4985 net.cpp:406] Convolution5 <- Convolution4
I1023 15:05:27.135471  4985 net.cpp:380] Convolution5 -> Convolution5
I1023 15:05:27.136906  4985 net.cpp:122] Setting up Convolution5
I1023 15:05:27.136919  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.136921  4985 net.cpp:137] Memory required for data: 569999456
I1023 15:05:27.136932  4985 layer_factory.hpp:77] Creating layer BatchNorm5
I1023 15:05:27.136937  4985 net.cpp:84] Creating Layer BatchNorm5
I1023 15:05:27.136940  4985 net.cpp:406] BatchNorm5 <- Convolution5
I1023 15:05:27.136945  4985 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1023 15:05:27.137156  4985 net.cpp:122] Setting up BatchNorm5
I1023 15:05:27.137162  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.137164  4985 net.cpp:137] Memory required for data: 595689568
I1023 15:05:27.137169  4985 layer_factory.hpp:77] Creating layer Scale5
I1023 15:05:27.137174  4985 net.cpp:84] Creating Layer Scale5
I1023 15:05:27.137177  4985 net.cpp:406] Scale5 <- Convolution5
I1023 15:05:27.137181  4985 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1023 15:05:27.137212  4985 layer_factory.hpp:77] Creating layer Scale5
I1023 15:05:27.137878  4985 net.cpp:122] Setting up Scale5
I1023 15:05:27.137887  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.137888  4985 net.cpp:137] Memory required for data: 621379680
I1023 15:05:27.137893  4985 layer_factory.hpp:77] Creating layer Eltwise2
I1023 15:05:27.137899  4985 net.cpp:84] Creating Layer Eltwise2
I1023 15:05:27.137902  4985 net.cpp:406] Eltwise2 <- Eltwise1_PReLU3_0_split_1
I1023 15:05:27.137904  4985 net.cpp:406] Eltwise2 <- Convolution5
I1023 15:05:27.137908  4985 net.cpp:380] Eltwise2 -> Eltwise2
I1023 15:05:27.137928  4985 net.cpp:122] Setting up Eltwise2
I1023 15:05:27.137933  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.137934  4985 net.cpp:137] Memory required for data: 647069792
I1023 15:05:27.137936  4985 layer_factory.hpp:77] Creating layer PReLU5
I1023 15:05:27.137940  4985 net.cpp:84] Creating Layer PReLU5
I1023 15:05:27.137943  4985 net.cpp:406] PReLU5 <- Eltwise2
I1023 15:05:27.137945  4985 net.cpp:367] PReLU5 -> Eltwise2 (in-place)
I1023 15:05:27.139057  4985 net.cpp:122] Setting up PReLU5
I1023 15:05:27.139067  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.139070  4985 net.cpp:137] Memory required for data: 672759904
I1023 15:05:27.139101  4985 layer_factory.hpp:77] Creating layer Eltwise2_PReLU5_0_split
I1023 15:05:27.139107  4985 net.cpp:84] Creating Layer Eltwise2_PReLU5_0_split
I1023 15:05:27.139111  4985 net.cpp:406] Eltwise2_PReLU5_0_split <- Eltwise2
I1023 15:05:27.139114  4985 net.cpp:380] Eltwise2_PReLU5_0_split -> Eltwise2_PReLU5_0_split_0
I1023 15:05:27.139118  4985 net.cpp:380] Eltwise2_PReLU5_0_split -> Eltwise2_PReLU5_0_split_1
I1023 15:05:27.139148  4985 net.cpp:122] Setting up Eltwise2_PReLU5_0_split
I1023 15:05:27.139153  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.139156  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.139158  4985 net.cpp:137] Memory required for data: 724140128
I1023 15:05:27.139160  4985 layer_factory.hpp:77] Creating layer Convolution6
I1023 15:05:27.139168  4985 net.cpp:84] Creating Layer Convolution6
I1023 15:05:27.139170  4985 net.cpp:406] Convolution6 <- Eltwise2_PReLU5_0_split_0
I1023 15:05:27.139174  4985 net.cpp:380] Convolution6 -> Convolution6
I1023 15:05:27.140674  4985 net.cpp:122] Setting up Convolution6
I1023 15:05:27.140684  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.140687  4985 net.cpp:137] Memory required for data: 749830240
I1023 15:05:27.140692  4985 layer_factory.hpp:77] Creating layer BatchNorm6
I1023 15:05:27.140697  4985 net.cpp:84] Creating Layer BatchNorm6
I1023 15:05:27.140700  4985 net.cpp:406] BatchNorm6 <- Convolution6
I1023 15:05:27.140704  4985 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1023 15:05:27.140878  4985 net.cpp:122] Setting up BatchNorm6
I1023 15:05:27.140882  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.140884  4985 net.cpp:137] Memory required for data: 775520352
I1023 15:05:27.140889  4985 layer_factory.hpp:77] Creating layer Scale6
I1023 15:05:27.140894  4985 net.cpp:84] Creating Layer Scale6
I1023 15:05:27.140897  4985 net.cpp:406] Scale6 <- Convolution6
I1023 15:05:27.140902  4985 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1023 15:05:27.140933  4985 layer_factory.hpp:77] Creating layer Scale6
I1023 15:05:27.141074  4985 net.cpp:122] Setting up Scale6
I1023 15:05:27.141078  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.141080  4985 net.cpp:137] Memory required for data: 801210464
I1023 15:05:27.141084  4985 layer_factory.hpp:77] Creating layer PReLU6
I1023 15:05:27.141089  4985 net.cpp:84] Creating Layer PReLU6
I1023 15:05:27.141091  4985 net.cpp:406] PReLU6 <- Convolution6
I1023 15:05:27.141094  4985 net.cpp:367] PReLU6 -> Convolution6 (in-place)
I1023 15:05:27.142266  4985 net.cpp:122] Setting up PReLU6
I1023 15:05:27.142279  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.142282  4985 net.cpp:137] Memory required for data: 826900576
I1023 15:05:27.142287  4985 layer_factory.hpp:77] Creating layer Convolution7
I1023 15:05:27.142297  4985 net.cpp:84] Creating Layer Convolution7
I1023 15:05:27.142300  4985 net.cpp:406] Convolution7 <- Convolution6
I1023 15:05:27.142305  4985 net.cpp:380] Convolution7 -> Convolution7
I1023 15:05:27.143748  4985 net.cpp:122] Setting up Convolution7
I1023 15:05:27.143759  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.143761  4985 net.cpp:137] Memory required for data: 852590688
I1023 15:05:27.143767  4985 layer_factory.hpp:77] Creating layer BatchNorm7
I1023 15:05:27.143776  4985 net.cpp:84] Creating Layer BatchNorm7
I1023 15:05:27.143779  4985 net.cpp:406] BatchNorm7 <- Convolution7
I1023 15:05:27.143784  4985 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1023 15:05:27.144004  4985 net.cpp:122] Setting up BatchNorm7
I1023 15:05:27.144011  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.144012  4985 net.cpp:137] Memory required for data: 878280800
I1023 15:05:27.144017  4985 layer_factory.hpp:77] Creating layer Scale7
I1023 15:05:27.144024  4985 net.cpp:84] Creating Layer Scale7
I1023 15:05:27.144027  4985 net.cpp:406] Scale7 <- Convolution7
I1023 15:05:27.144031  4985 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1023 15:05:27.144068  4985 layer_factory.hpp:77] Creating layer Scale7
I1023 15:05:27.144255  4985 net.cpp:122] Setting up Scale7
I1023 15:05:27.144260  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.144263  4985 net.cpp:137] Memory required for data: 903970912
I1023 15:05:27.144266  4985 layer_factory.hpp:77] Creating layer Eltwise3
I1023 15:05:27.144271  4985 net.cpp:84] Creating Layer Eltwise3
I1023 15:05:27.144274  4985 net.cpp:406] Eltwise3 <- Eltwise2_PReLU5_0_split_1
I1023 15:05:27.144278  4985 net.cpp:406] Eltwise3 <- Convolution7
I1023 15:05:27.144280  4985 net.cpp:380] Eltwise3 -> Eltwise3
I1023 15:05:27.144299  4985 net.cpp:122] Setting up Eltwise3
I1023 15:05:27.144304  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.144305  4985 net.cpp:137] Memory required for data: 929661024
I1023 15:05:27.144307  4985 layer_factory.hpp:77] Creating layer PReLU7
I1023 15:05:27.144310  4985 net.cpp:84] Creating Layer PReLU7
I1023 15:05:27.144312  4985 net.cpp:406] PReLU7 <- Eltwise3
I1023 15:05:27.144315  4985 net.cpp:367] PReLU7 -> Eltwise3 (in-place)
I1023 15:05:27.145442  4985 net.cpp:122] Setting up PReLU7
I1023 15:05:27.145450  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.145453  4985 net.cpp:137] Memory required for data: 955351136
I1023 15:05:27.145457  4985 layer_factory.hpp:77] Creating layer Eltwise3_PReLU7_0_split
I1023 15:05:27.145462  4985 net.cpp:84] Creating Layer Eltwise3_PReLU7_0_split
I1023 15:05:27.145464  4985 net.cpp:406] Eltwise3_PReLU7_0_split <- Eltwise3
I1023 15:05:27.145468  4985 net.cpp:380] Eltwise3_PReLU7_0_split -> Eltwise3_PReLU7_0_split_0
I1023 15:05:27.145473  4985 net.cpp:380] Eltwise3_PReLU7_0_split -> Eltwise3_PReLU7_0_split_1
I1023 15:05:27.145500  4985 net.cpp:122] Setting up Eltwise3_PReLU7_0_split
I1023 15:05:27.145504  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.145506  4985 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 15:05:27.145509  4985 net.cpp:137] Memory required for data: 1006731360
I1023 15:05:27.145511  4985 layer_factory.hpp:77] Creating layer Convolution8
I1023 15:05:27.145519  4985 net.cpp:84] Creating Layer Convolution8
I1023 15:05:27.145521  4985 net.cpp:406] Convolution8 <- Eltwise3_PReLU7_0_split_0
I1023 15:05:27.145525  4985 net.cpp:380] Convolution8 -> Convolution8
I1023 15:05:27.146481  4985 net.cpp:122] Setting up Convolution8
I1023 15:05:27.146491  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.146493  4985 net.cpp:137] Memory required for data: 1019576416
I1023 15:05:27.146497  4985 layer_factory.hpp:77] Creating layer BatchNorm8
I1023 15:05:27.146502  4985 net.cpp:84] Creating Layer BatchNorm8
I1023 15:05:27.146505  4985 net.cpp:406] BatchNorm8 <- Convolution8
I1023 15:05:27.146518  4985 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1023 15:05:27.146703  4985 net.cpp:122] Setting up BatchNorm8
I1023 15:05:27.146706  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.146708  4985 net.cpp:137] Memory required for data: 1032421472
I1023 15:05:27.146714  4985 layer_factory.hpp:77] Creating layer Scale8
I1023 15:05:27.146718  4985 net.cpp:84] Creating Layer Scale8
I1023 15:05:27.146721  4985 net.cpp:406] Scale8 <- Convolution8
I1023 15:05:27.146724  4985 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1023 15:05:27.146754  4985 layer_factory.hpp:77] Creating layer Scale8
I1023 15:05:27.146849  4985 net.cpp:122] Setting up Scale8
I1023 15:05:27.146853  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.146855  4985 net.cpp:137] Memory required for data: 1045266528
I1023 15:05:27.146859  4985 layer_factory.hpp:77] Creating layer Convolution9
I1023 15:05:27.146867  4985 net.cpp:84] Creating Layer Convolution9
I1023 15:05:27.146868  4985 net.cpp:406] Convolution9 <- Eltwise3_PReLU7_0_split_1
I1023 15:05:27.146872  4985 net.cpp:380] Convolution9 -> Convolution9
I1023 15:05:27.147922  4985 net.cpp:122] Setting up Convolution9
I1023 15:05:27.147931  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.147934  4985 net.cpp:137] Memory required for data: 1058111584
I1023 15:05:27.147953  4985 layer_factory.hpp:77] Creating layer BatchNorm9
I1023 15:05:27.147967  4985 net.cpp:84] Creating Layer BatchNorm9
I1023 15:05:27.147970  4985 net.cpp:406] BatchNorm9 <- Convolution9
I1023 15:05:27.147974  4985 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1023 15:05:27.148157  4985 net.cpp:122] Setting up BatchNorm9
I1023 15:05:27.148164  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.148167  4985 net.cpp:137] Memory required for data: 1070956640
I1023 15:05:27.148172  4985 layer_factory.hpp:77] Creating layer Scale9
I1023 15:05:27.148177  4985 net.cpp:84] Creating Layer Scale9
I1023 15:05:27.148180  4985 net.cpp:406] Scale9 <- Convolution9
I1023 15:05:27.148185  4985 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1023 15:05:27.148216  4985 layer_factory.hpp:77] Creating layer Scale9
I1023 15:05:27.148332  4985 net.cpp:122] Setting up Scale9
I1023 15:05:27.148336  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.148339  4985 net.cpp:137] Memory required for data: 1083801696
I1023 15:05:27.148352  4985 layer_factory.hpp:77] Creating layer PReLU8
I1023 15:05:27.148356  4985 net.cpp:84] Creating Layer PReLU8
I1023 15:05:27.148358  4985 net.cpp:406] PReLU8 <- Convolution9
I1023 15:05:27.148361  4985 net.cpp:367] PReLU8 -> Convolution9 (in-place)
I1023 15:05:27.149207  4985 net.cpp:122] Setting up PReLU8
I1023 15:05:27.149216  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.149219  4985 net.cpp:137] Memory required for data: 1096646752
I1023 15:05:27.149224  4985 layer_factory.hpp:77] Creating layer Convolution10
I1023 15:05:27.149231  4985 net.cpp:84] Creating Layer Convolution10
I1023 15:05:27.149235  4985 net.cpp:406] Convolution10 <- Convolution9
I1023 15:05:27.149238  4985 net.cpp:380] Convolution10 -> Convolution10
I1023 15:05:27.151322  4985 net.cpp:122] Setting up Convolution10
I1023 15:05:27.151334  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.151336  4985 net.cpp:137] Memory required for data: 1109491808
I1023 15:05:27.151343  4985 layer_factory.hpp:77] Creating layer BatchNorm10
I1023 15:05:27.151348  4985 net.cpp:84] Creating Layer BatchNorm10
I1023 15:05:27.151351  4985 net.cpp:406] BatchNorm10 <- Convolution10
I1023 15:05:27.151355  4985 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1023 15:05:27.151520  4985 net.cpp:122] Setting up BatchNorm10
I1023 15:05:27.151525  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.151526  4985 net.cpp:137] Memory required for data: 1122336864
I1023 15:05:27.151531  4985 layer_factory.hpp:77] Creating layer Scale10
I1023 15:05:27.151536  4985 net.cpp:84] Creating Layer Scale10
I1023 15:05:27.151540  4985 net.cpp:406] Scale10 <- Convolution10
I1023 15:05:27.151542  4985 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1023 15:05:27.151577  4985 layer_factory.hpp:77] Creating layer Scale10
I1023 15:05:27.151667  4985 net.cpp:122] Setting up Scale10
I1023 15:05:27.151672  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.151674  4985 net.cpp:137] Memory required for data: 1135181920
I1023 15:05:27.151679  4985 layer_factory.hpp:77] Creating layer Eltwise4
I1023 15:05:27.151684  4985 net.cpp:84] Creating Layer Eltwise4
I1023 15:05:27.151687  4985 net.cpp:406] Eltwise4 <- Convolution8
I1023 15:05:27.151690  4985 net.cpp:406] Eltwise4 <- Convolution10
I1023 15:05:27.151695  4985 net.cpp:380] Eltwise4 -> Eltwise4
I1023 15:05:27.151712  4985 net.cpp:122] Setting up Eltwise4
I1023 15:05:27.151716  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.151718  4985 net.cpp:137] Memory required for data: 1148026976
I1023 15:05:27.151721  4985 layer_factory.hpp:77] Creating layer PReLU9
I1023 15:05:27.151726  4985 net.cpp:84] Creating Layer PReLU9
I1023 15:05:27.151728  4985 net.cpp:406] PReLU9 <- Eltwise4
I1023 15:05:27.151731  4985 net.cpp:367] PReLU9 -> Eltwise4 (in-place)
I1023 15:05:27.152511  4985 net.cpp:122] Setting up PReLU9
I1023 15:05:27.152520  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.152535  4985 net.cpp:137] Memory required for data: 1160872032
I1023 15:05:27.152539  4985 layer_factory.hpp:77] Creating layer Eltwise4_PReLU9_0_split
I1023 15:05:27.152545  4985 net.cpp:84] Creating Layer Eltwise4_PReLU9_0_split
I1023 15:05:27.152549  4985 net.cpp:406] Eltwise4_PReLU9_0_split <- Eltwise4
I1023 15:05:27.152552  4985 net.cpp:380] Eltwise4_PReLU9_0_split -> Eltwise4_PReLU9_0_split_0
I1023 15:05:27.152557  4985 net.cpp:380] Eltwise4_PReLU9_0_split -> Eltwise4_PReLU9_0_split_1
I1023 15:05:27.152587  4985 net.cpp:122] Setting up Eltwise4_PReLU9_0_split
I1023 15:05:27.152591  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.152595  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.152596  4985 net.cpp:137] Memory required for data: 1186562144
I1023 15:05:27.152598  4985 layer_factory.hpp:77] Creating layer Convolution11
I1023 15:05:27.152606  4985 net.cpp:84] Creating Layer Convolution11
I1023 15:05:27.152609  4985 net.cpp:406] Convolution11 <- Eltwise4_PReLU9_0_split_0
I1023 15:05:27.152613  4985 net.cpp:380] Convolution11 -> Convolution11
I1023 15:05:27.153805  4985 net.cpp:122] Setting up Convolution11
I1023 15:05:27.153813  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.153816  4985 net.cpp:137] Memory required for data: 1199407200
I1023 15:05:27.153820  4985 layer_factory.hpp:77] Creating layer BatchNorm11
I1023 15:05:27.153826  4985 net.cpp:84] Creating Layer BatchNorm11
I1023 15:05:27.153829  4985 net.cpp:406] BatchNorm11 <- Convolution11
I1023 15:05:27.153833  4985 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1023 15:05:27.153986  4985 net.cpp:122] Setting up BatchNorm11
I1023 15:05:27.153991  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.153993  4985 net.cpp:137] Memory required for data: 1212252256
I1023 15:05:27.153998  4985 layer_factory.hpp:77] Creating layer Scale11
I1023 15:05:27.154003  4985 net.cpp:84] Creating Layer Scale11
I1023 15:05:27.154006  4985 net.cpp:406] Scale11 <- Convolution11
I1023 15:05:27.154009  4985 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1023 15:05:27.154039  4985 layer_factory.hpp:77] Creating layer Scale11
I1023 15:05:27.154130  4985 net.cpp:122] Setting up Scale11
I1023 15:05:27.154134  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.154136  4985 net.cpp:137] Memory required for data: 1225097312
I1023 15:05:27.154140  4985 layer_factory.hpp:77] Creating layer PReLU10
I1023 15:05:27.154145  4985 net.cpp:84] Creating Layer PReLU10
I1023 15:05:27.154148  4985 net.cpp:406] PReLU10 <- Convolution11
I1023 15:05:27.154150  4985 net.cpp:367] PReLU10 -> Convolution11 (in-place)
I1023 15:05:27.154937  4985 net.cpp:122] Setting up PReLU10
I1023 15:05:27.154945  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.154948  4985 net.cpp:137] Memory required for data: 1237942368
I1023 15:05:27.154952  4985 layer_factory.hpp:77] Creating layer Convolution12
I1023 15:05:27.154960  4985 net.cpp:84] Creating Layer Convolution12
I1023 15:05:27.154963  4985 net.cpp:406] Convolution12 <- Convolution11
I1023 15:05:27.154968  4985 net.cpp:380] Convolution12 -> Convolution12
I1023 15:05:27.155743  4985 net.cpp:122] Setting up Convolution12
I1023 15:05:27.155751  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.155755  4985 net.cpp:137] Memory required for data: 1250787424
I1023 15:05:27.155758  4985 layer_factory.hpp:77] Creating layer BatchNorm12
I1023 15:05:27.155764  4985 net.cpp:84] Creating Layer BatchNorm12
I1023 15:05:27.155766  4985 net.cpp:406] BatchNorm12 <- Convolution12
I1023 15:05:27.155771  4985 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1023 15:05:27.155926  4985 net.cpp:122] Setting up BatchNorm12
I1023 15:05:27.155931  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.155933  4985 net.cpp:137] Memory required for data: 1263632480
I1023 15:05:27.155938  4985 layer_factory.hpp:77] Creating layer Scale12
I1023 15:05:27.155942  4985 net.cpp:84] Creating Layer Scale12
I1023 15:05:27.155951  4985 net.cpp:406] Scale12 <- Convolution12
I1023 15:05:27.155961  4985 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1023 15:05:27.155997  4985 layer_factory.hpp:77] Creating layer Scale12
I1023 15:05:27.156092  4985 net.cpp:122] Setting up Scale12
I1023 15:05:27.156097  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.156100  4985 net.cpp:137] Memory required for data: 1276477536
I1023 15:05:27.156103  4985 layer_factory.hpp:77] Creating layer Eltwise5
I1023 15:05:27.156108  4985 net.cpp:84] Creating Layer Eltwise5
I1023 15:05:27.156111  4985 net.cpp:406] Eltwise5 <- Eltwise4_PReLU9_0_split_1
I1023 15:05:27.156114  4985 net.cpp:406] Eltwise5 <- Convolution12
I1023 15:05:27.156117  4985 net.cpp:380] Eltwise5 -> Eltwise5
I1023 15:05:27.156136  4985 net.cpp:122] Setting up Eltwise5
I1023 15:05:27.156141  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.156142  4985 net.cpp:137] Memory required for data: 1289322592
I1023 15:05:27.156144  4985 layer_factory.hpp:77] Creating layer PReLU11
I1023 15:05:27.156147  4985 net.cpp:84] Creating Layer PReLU11
I1023 15:05:27.156150  4985 net.cpp:406] PReLU11 <- Eltwise5
I1023 15:05:27.156155  4985 net.cpp:367] PReLU11 -> Eltwise5 (in-place)
I1023 15:05:27.156934  4985 net.cpp:122] Setting up PReLU11
I1023 15:05:27.156944  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.156946  4985 net.cpp:137] Memory required for data: 1302167648
I1023 15:05:27.156949  4985 layer_factory.hpp:77] Creating layer Eltwise5_PReLU11_0_split
I1023 15:05:27.156955  4985 net.cpp:84] Creating Layer Eltwise5_PReLU11_0_split
I1023 15:05:27.156958  4985 net.cpp:406] Eltwise5_PReLU11_0_split <- Eltwise5
I1023 15:05:27.156961  4985 net.cpp:380] Eltwise5_PReLU11_0_split -> Eltwise5_PReLU11_0_split_0
I1023 15:05:27.156966  4985 net.cpp:380] Eltwise5_PReLU11_0_split -> Eltwise5_PReLU11_0_split_1
I1023 15:05:27.156998  4985 net.cpp:122] Setting up Eltwise5_PReLU11_0_split
I1023 15:05:27.157003  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.157006  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.157008  4985 net.cpp:137] Memory required for data: 1327857760
I1023 15:05:27.157011  4985 layer_factory.hpp:77] Creating layer Convolution13
I1023 15:05:27.157017  4985 net.cpp:84] Creating Layer Convolution13
I1023 15:05:27.157021  4985 net.cpp:406] Convolution13 <- Eltwise5_PReLU11_0_split_0
I1023 15:05:27.157024  4985 net.cpp:380] Convolution13 -> Convolution13
I1023 15:05:27.158166  4985 net.cpp:122] Setting up Convolution13
I1023 15:05:27.158175  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.158177  4985 net.cpp:137] Memory required for data: 1340702816
I1023 15:05:27.158182  4985 layer_factory.hpp:77] Creating layer BatchNorm13
I1023 15:05:27.158188  4985 net.cpp:84] Creating Layer BatchNorm13
I1023 15:05:27.158190  4985 net.cpp:406] BatchNorm13 <- Convolution13
I1023 15:05:27.158195  4985 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1023 15:05:27.158354  4985 net.cpp:122] Setting up BatchNorm13
I1023 15:05:27.158359  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.158360  4985 net.cpp:137] Memory required for data: 1353547872
I1023 15:05:27.158365  4985 layer_factory.hpp:77] Creating layer Scale13
I1023 15:05:27.158370  4985 net.cpp:84] Creating Layer Scale13
I1023 15:05:27.158372  4985 net.cpp:406] Scale13 <- Convolution13
I1023 15:05:27.158376  4985 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1023 15:05:27.158406  4985 layer_factory.hpp:77] Creating layer Scale13
I1023 15:05:27.158502  4985 net.cpp:122] Setting up Scale13
I1023 15:05:27.158506  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.158509  4985 net.cpp:137] Memory required for data: 1366392928
I1023 15:05:27.158514  4985 layer_factory.hpp:77] Creating layer PReLU12
I1023 15:05:27.158516  4985 net.cpp:84] Creating Layer PReLU12
I1023 15:05:27.158519  4985 net.cpp:406] PReLU12 <- Convolution13
I1023 15:05:27.158522  4985 net.cpp:367] PReLU12 -> Convolution13 (in-place)
I1023 15:05:27.159317  4985 net.cpp:122] Setting up PReLU12
I1023 15:05:27.159324  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.159327  4985 net.cpp:137] Memory required for data: 1379237984
I1023 15:05:27.159330  4985 layer_factory.hpp:77] Creating layer Convolution14
I1023 15:05:27.159345  4985 net.cpp:84] Creating Layer Convolution14
I1023 15:05:27.159348  4985 net.cpp:406] Convolution14 <- Convolution13
I1023 15:05:27.159353  4985 net.cpp:380] Convolution14 -> Convolution14
I1023 15:05:27.160517  4985 net.cpp:122] Setting up Convolution14
I1023 15:05:27.160526  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.160529  4985 net.cpp:137] Memory required for data: 1392083040
I1023 15:05:27.160534  4985 layer_factory.hpp:77] Creating layer BatchNorm14
I1023 15:05:27.160540  4985 net.cpp:84] Creating Layer BatchNorm14
I1023 15:05:27.160542  4985 net.cpp:406] BatchNorm14 <- Convolution14
I1023 15:05:27.160547  4985 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1023 15:05:27.160707  4985 net.cpp:122] Setting up BatchNorm14
I1023 15:05:27.160712  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.160714  4985 net.cpp:137] Memory required for data: 1404928096
I1023 15:05:27.160719  4985 layer_factory.hpp:77] Creating layer Scale14
I1023 15:05:27.160723  4985 net.cpp:84] Creating Layer Scale14
I1023 15:05:27.160725  4985 net.cpp:406] Scale14 <- Convolution14
I1023 15:05:27.160729  4985 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1023 15:05:27.160760  4985 layer_factory.hpp:77] Creating layer Scale14
I1023 15:05:27.160857  4985 net.cpp:122] Setting up Scale14
I1023 15:05:27.160861  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.160864  4985 net.cpp:137] Memory required for data: 1417773152
I1023 15:05:27.160868  4985 layer_factory.hpp:77] Creating layer Eltwise6
I1023 15:05:27.160873  4985 net.cpp:84] Creating Layer Eltwise6
I1023 15:05:27.160876  4985 net.cpp:406] Eltwise6 <- Eltwise5_PReLU11_0_split_1
I1023 15:05:27.160879  4985 net.cpp:406] Eltwise6 <- Convolution14
I1023 15:05:27.160882  4985 net.cpp:380] Eltwise6 -> Eltwise6
I1023 15:05:27.160902  4985 net.cpp:122] Setting up Eltwise6
I1023 15:05:27.160905  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.160907  4985 net.cpp:137] Memory required for data: 1430618208
I1023 15:05:27.160910  4985 layer_factory.hpp:77] Creating layer PReLU13
I1023 15:05:27.160913  4985 net.cpp:84] Creating Layer PReLU13
I1023 15:05:27.160915  4985 net.cpp:406] PReLU13 <- Eltwise6
I1023 15:05:27.160919  4985 net.cpp:367] PReLU13 -> Eltwise6 (in-place)
I1023 15:05:27.161702  4985 net.cpp:122] Setting up PReLU13
I1023 15:05:27.161710  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.161713  4985 net.cpp:137] Memory required for data: 1443463264
I1023 15:05:27.161717  4985 layer_factory.hpp:77] Creating layer Eltwise6_PReLU13_0_split
I1023 15:05:27.161722  4985 net.cpp:84] Creating Layer Eltwise6_PReLU13_0_split
I1023 15:05:27.161725  4985 net.cpp:406] Eltwise6_PReLU13_0_split <- Eltwise6
I1023 15:05:27.161729  4985 net.cpp:380] Eltwise6_PReLU13_0_split -> Eltwise6_PReLU13_0_split_0
I1023 15:05:27.161734  4985 net.cpp:380] Eltwise6_PReLU13_0_split -> Eltwise6_PReLU13_0_split_1
I1023 15:05:27.161763  4985 net.cpp:122] Setting up Eltwise6_PReLU13_0_split
I1023 15:05:27.161768  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.161770  4985 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 15:05:27.161773  4985 net.cpp:137] Memory required for data: 1469153376
I1023 15:05:27.161775  4985 layer_factory.hpp:77] Creating layer Convolution15
I1023 15:05:27.161782  4985 net.cpp:84] Creating Layer Convolution15
I1023 15:05:27.161785  4985 net.cpp:406] Convolution15 <- Eltwise6_PReLU13_0_split_0
I1023 15:05:27.161789  4985 net.cpp:380] Convolution15 -> Convolution15
I1023 15:05:27.162786  4985 net.cpp:122] Setting up Convolution15
I1023 15:05:27.162796  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.162798  4985 net.cpp:137] Memory required for data: 1475575904
I1023 15:05:27.162812  4985 layer_factory.hpp:77] Creating layer BatchNorm15
I1023 15:05:27.162817  4985 net.cpp:84] Creating Layer BatchNorm15
I1023 15:05:27.162820  4985 net.cpp:406] BatchNorm15 <- Convolution15
I1023 15:05:27.162825  4985 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1023 15:05:27.162984  4985 net.cpp:122] Setting up BatchNorm15
I1023 15:05:27.162989  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.162992  4985 net.cpp:137] Memory required for data: 1481998432
I1023 15:05:27.162997  4985 layer_factory.hpp:77] Creating layer Scale15
I1023 15:05:27.163000  4985 net.cpp:84] Creating Layer Scale15
I1023 15:05:27.163003  4985 net.cpp:406] Scale15 <- Convolution15
I1023 15:05:27.163007  4985 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1023 15:05:27.163038  4985 layer_factory.hpp:77] Creating layer Scale15
I1023 15:05:27.163130  4985 net.cpp:122] Setting up Scale15
I1023 15:05:27.163134  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.163136  4985 net.cpp:137] Memory required for data: 1488420960
I1023 15:05:27.163141  4985 layer_factory.hpp:77] Creating layer Convolution16
I1023 15:05:27.163148  4985 net.cpp:84] Creating Layer Convolution16
I1023 15:05:27.163151  4985 net.cpp:406] Convolution16 <- Eltwise6_PReLU13_0_split_1
I1023 15:05:27.163156  4985 net.cpp:380] Convolution16 -> Convolution16
I1023 15:05:27.164520  4985 net.cpp:122] Setting up Convolution16
I1023 15:05:27.164530  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.164531  4985 net.cpp:137] Memory required for data: 1494843488
I1023 15:05:27.164536  4985 layer_factory.hpp:77] Creating layer BatchNorm16
I1023 15:05:27.164541  4985 net.cpp:84] Creating Layer BatchNorm16
I1023 15:05:27.164544  4985 net.cpp:406] BatchNorm16 <- Convolution16
I1023 15:05:27.164549  4985 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1023 15:05:27.164705  4985 net.cpp:122] Setting up BatchNorm16
I1023 15:05:27.164710  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.164712  4985 net.cpp:137] Memory required for data: 1501266016
I1023 15:05:27.164717  4985 layer_factory.hpp:77] Creating layer Scale16
I1023 15:05:27.164722  4985 net.cpp:84] Creating Layer Scale16
I1023 15:05:27.164726  4985 net.cpp:406] Scale16 <- Convolution16
I1023 15:05:27.164728  4985 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1023 15:05:27.164758  4985 layer_factory.hpp:77] Creating layer Scale16
I1023 15:05:27.164850  4985 net.cpp:122] Setting up Scale16
I1023 15:05:27.164855  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.164856  4985 net.cpp:137] Memory required for data: 1507688544
I1023 15:05:27.164861  4985 layer_factory.hpp:77] Creating layer PReLU14
I1023 15:05:27.164865  4985 net.cpp:84] Creating Layer PReLU14
I1023 15:05:27.164867  4985 net.cpp:406] PReLU14 <- Convolution16
I1023 15:05:27.164870  4985 net.cpp:367] PReLU14 -> Convolution16 (in-place)
I1023 15:05:27.165570  4985 net.cpp:122] Setting up PReLU14
I1023 15:05:27.165577  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.165580  4985 net.cpp:137] Memory required for data: 1514111072
I1023 15:05:27.165585  4985 layer_factory.hpp:77] Creating layer Convolution17
I1023 15:05:27.165591  4985 net.cpp:84] Creating Layer Convolution17
I1023 15:05:27.165594  4985 net.cpp:406] Convolution17 <- Convolution16
I1023 15:05:27.165599  4985 net.cpp:380] Convolution17 -> Convolution17
I1023 15:05:27.167949  4985 net.cpp:122] Setting up Convolution17
I1023 15:05:27.167966  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.167969  4985 net.cpp:137] Memory required for data: 1520533600
I1023 15:05:27.167974  4985 layer_factory.hpp:77] Creating layer BatchNorm17
I1023 15:05:27.167980  4985 net.cpp:84] Creating Layer BatchNorm17
I1023 15:05:27.167984  4985 net.cpp:406] BatchNorm17 <- Convolution17
I1023 15:05:27.167986  4985 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1023 15:05:27.168144  4985 net.cpp:122] Setting up BatchNorm17
I1023 15:05:27.168149  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.168161  4985 net.cpp:137] Memory required for data: 1526956128
I1023 15:05:27.168181  4985 layer_factory.hpp:77] Creating layer Scale17
I1023 15:05:27.168186  4985 net.cpp:84] Creating Layer Scale17
I1023 15:05:27.168190  4985 net.cpp:406] Scale17 <- Convolution17
I1023 15:05:27.168192  4985 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1023 15:05:27.168228  4985 layer_factory.hpp:77] Creating layer Scale17
I1023 15:05:27.168326  4985 net.cpp:122] Setting up Scale17
I1023 15:05:27.168331  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.168334  4985 net.cpp:137] Memory required for data: 1533378656
I1023 15:05:27.168337  4985 layer_factory.hpp:77] Creating layer Eltwise7
I1023 15:05:27.168344  4985 net.cpp:84] Creating Layer Eltwise7
I1023 15:05:27.168346  4985 net.cpp:406] Eltwise7 <- Convolution15
I1023 15:05:27.168349  4985 net.cpp:406] Eltwise7 <- Convolution17
I1023 15:05:27.168354  4985 net.cpp:380] Eltwise7 -> Eltwise7
I1023 15:05:27.168371  4985 net.cpp:122] Setting up Eltwise7
I1023 15:05:27.168375  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.168377  4985 net.cpp:137] Memory required for data: 1539801184
I1023 15:05:27.168380  4985 layer_factory.hpp:77] Creating layer PReLU15
I1023 15:05:27.168385  4985 net.cpp:84] Creating Layer PReLU15
I1023 15:05:27.168386  4985 net.cpp:406] PReLU15 <- Eltwise7
I1023 15:05:27.168390  4985 net.cpp:367] PReLU15 -> Eltwise7 (in-place)
I1023 15:05:27.168565  4985 net.cpp:122] Setting up PReLU15
I1023 15:05:27.168568  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.168570  4985 net.cpp:137] Memory required for data: 1546223712
I1023 15:05:27.168575  4985 layer_factory.hpp:77] Creating layer Eltwise7_PReLU15_0_split
I1023 15:05:27.168578  4985 net.cpp:84] Creating Layer Eltwise7_PReLU15_0_split
I1023 15:05:27.168581  4985 net.cpp:406] Eltwise7_PReLU15_0_split <- Eltwise7
I1023 15:05:27.168586  4985 net.cpp:380] Eltwise7_PReLU15_0_split -> Eltwise7_PReLU15_0_split_0
I1023 15:05:27.168589  4985 net.cpp:380] Eltwise7_PReLU15_0_split -> Eltwise7_PReLU15_0_split_1
I1023 15:05:27.168617  4985 net.cpp:122] Setting up Eltwise7_PReLU15_0_split
I1023 15:05:27.168622  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.168624  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.168627  4985 net.cpp:137] Memory required for data: 1559068768
I1023 15:05:27.168628  4985 layer_factory.hpp:77] Creating layer Convolution18
I1023 15:05:27.168635  4985 net.cpp:84] Creating Layer Convolution18
I1023 15:05:27.168638  4985 net.cpp:406] Convolution18 <- Eltwise7_PReLU15_0_split_0
I1023 15:05:27.168642  4985 net.cpp:380] Convolution18 -> Convolution18
I1023 15:05:27.171181  4985 net.cpp:122] Setting up Convolution18
I1023 15:05:27.171190  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.171193  4985 net.cpp:137] Memory required for data: 1565491296
I1023 15:05:27.171198  4985 layer_factory.hpp:77] Creating layer BatchNorm18
I1023 15:05:27.171205  4985 net.cpp:84] Creating Layer BatchNorm18
I1023 15:05:27.171207  4985 net.cpp:406] BatchNorm18 <- Convolution18
I1023 15:05:27.171211  4985 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1023 15:05:27.171373  4985 net.cpp:122] Setting up BatchNorm18
I1023 15:05:27.171378  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.171380  4985 net.cpp:137] Memory required for data: 1571913824
I1023 15:05:27.171386  4985 layer_factory.hpp:77] Creating layer Scale18
I1023 15:05:27.171391  4985 net.cpp:84] Creating Layer Scale18
I1023 15:05:27.171392  4985 net.cpp:406] Scale18 <- Convolution18
I1023 15:05:27.171396  4985 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1023 15:05:27.171427  4985 layer_factory.hpp:77] Creating layer Scale18
I1023 15:05:27.171521  4985 net.cpp:122] Setting up Scale18
I1023 15:05:27.171527  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.171530  4985 net.cpp:137] Memory required for data: 1578336352
I1023 15:05:27.171533  4985 layer_factory.hpp:77] Creating layer PReLU16
I1023 15:05:27.171537  4985 net.cpp:84] Creating Layer PReLU16
I1023 15:05:27.171546  4985 net.cpp:406] PReLU16 <- Convolution18
I1023 15:05:27.171550  4985 net.cpp:367] PReLU16 -> Convolution18 (in-place)
I1023 15:05:27.172269  4985 net.cpp:122] Setting up PReLU16
I1023 15:05:27.172278  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.172281  4985 net.cpp:137] Memory required for data: 1584758880
I1023 15:05:27.172284  4985 layer_factory.hpp:77] Creating layer Convolution19
I1023 15:05:27.172293  4985 net.cpp:84] Creating Layer Convolution19
I1023 15:05:27.172297  4985 net.cpp:406] Convolution19 <- Convolution18
I1023 15:05:27.172302  4985 net.cpp:380] Convolution19 -> Convolution19
I1023 15:05:27.174087  4985 net.cpp:122] Setting up Convolution19
I1023 15:05:27.174095  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.174098  4985 net.cpp:137] Memory required for data: 1591181408
I1023 15:05:27.174103  4985 layer_factory.hpp:77] Creating layer BatchNorm19
I1023 15:05:27.174108  4985 net.cpp:84] Creating Layer BatchNorm19
I1023 15:05:27.174111  4985 net.cpp:406] BatchNorm19 <- Convolution19
I1023 15:05:27.174115  4985 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1023 15:05:27.174274  4985 net.cpp:122] Setting up BatchNorm19
I1023 15:05:27.174279  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.174281  4985 net.cpp:137] Memory required for data: 1597603936
I1023 15:05:27.174286  4985 layer_factory.hpp:77] Creating layer Scale19
I1023 15:05:27.174291  4985 net.cpp:84] Creating Layer Scale19
I1023 15:05:27.174294  4985 net.cpp:406] Scale19 <- Convolution19
I1023 15:05:27.174298  4985 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1023 15:05:27.174329  4985 layer_factory.hpp:77] Creating layer Scale19
I1023 15:05:27.174425  4985 net.cpp:122] Setting up Scale19
I1023 15:05:27.174429  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.174432  4985 net.cpp:137] Memory required for data: 1604026464
I1023 15:05:27.174435  4985 layer_factory.hpp:77] Creating layer Eltwise8
I1023 15:05:27.174440  4985 net.cpp:84] Creating Layer Eltwise8
I1023 15:05:27.174443  4985 net.cpp:406] Eltwise8 <- Eltwise7_PReLU15_0_split_1
I1023 15:05:27.174445  4985 net.cpp:406] Eltwise8 <- Convolution19
I1023 15:05:27.174450  4985 net.cpp:380] Eltwise8 -> Eltwise8
I1023 15:05:27.174468  4985 net.cpp:122] Setting up Eltwise8
I1023 15:05:27.174473  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.174474  4985 net.cpp:137] Memory required for data: 1610448992
I1023 15:05:27.174476  4985 layer_factory.hpp:77] Creating layer PReLU17
I1023 15:05:27.174480  4985 net.cpp:84] Creating Layer PReLU17
I1023 15:05:27.174484  4985 net.cpp:406] PReLU17 <- Eltwise8
I1023 15:05:27.174485  4985 net.cpp:367] PReLU17 -> Eltwise8 (in-place)
I1023 15:05:27.174639  4985 net.cpp:122] Setting up PReLU17
I1023 15:05:27.174644  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.174646  4985 net.cpp:137] Memory required for data: 1616871520
I1023 15:05:27.174649  4985 layer_factory.hpp:77] Creating layer Eltwise8_PReLU17_0_split
I1023 15:05:27.174652  4985 net.cpp:84] Creating Layer Eltwise8_PReLU17_0_split
I1023 15:05:27.174655  4985 net.cpp:406] Eltwise8_PReLU17_0_split <- Eltwise8
I1023 15:05:27.174659  4985 net.cpp:380] Eltwise8_PReLU17_0_split -> Eltwise8_PReLU17_0_split_0
I1023 15:05:27.174664  4985 net.cpp:380] Eltwise8_PReLU17_0_split -> Eltwise8_PReLU17_0_split_1
I1023 15:05:27.174690  4985 net.cpp:122] Setting up Eltwise8_PReLU17_0_split
I1023 15:05:27.174695  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.174697  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.174700  4985 net.cpp:137] Memory required for data: 1629716576
I1023 15:05:27.174701  4985 layer_factory.hpp:77] Creating layer Convolution20
I1023 15:05:27.174708  4985 net.cpp:84] Creating Layer Convolution20
I1023 15:05:27.174711  4985 net.cpp:406] Convolution20 <- Eltwise8_PReLU17_0_split_0
I1023 15:05:27.174715  4985 net.cpp:380] Convolution20 -> Convolution20
I1023 15:05:27.176844  4985 net.cpp:122] Setting up Convolution20
I1023 15:05:27.176861  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.176864  4985 net.cpp:137] Memory required for data: 1636139104
I1023 15:05:27.176869  4985 layer_factory.hpp:77] Creating layer BatchNorm20
I1023 15:05:27.176873  4985 net.cpp:84] Creating Layer BatchNorm20
I1023 15:05:27.176877  4985 net.cpp:406] BatchNorm20 <- Convolution20
I1023 15:05:27.176882  4985 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1023 15:05:27.177078  4985 net.cpp:122] Setting up BatchNorm20
I1023 15:05:27.177083  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.177084  4985 net.cpp:137] Memory required for data: 1642561632
I1023 15:05:27.177089  4985 layer_factory.hpp:77] Creating layer Scale20
I1023 15:05:27.177094  4985 net.cpp:84] Creating Layer Scale20
I1023 15:05:27.177096  4985 net.cpp:406] Scale20 <- Convolution20
I1023 15:05:27.177100  4985 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1023 15:05:27.177132  4985 layer_factory.hpp:77] Creating layer Scale20
I1023 15:05:27.177232  4985 net.cpp:122] Setting up Scale20
I1023 15:05:27.177237  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.177239  4985 net.cpp:137] Memory required for data: 1648984160
I1023 15:05:27.177243  4985 layer_factory.hpp:77] Creating layer PReLU18
I1023 15:05:27.177248  4985 net.cpp:84] Creating Layer PReLU18
I1023 15:05:27.177250  4985 net.cpp:406] PReLU18 <- Convolution20
I1023 15:05:27.177254  4985 net.cpp:367] PReLU18 -> Convolution20 (in-place)
I1023 15:05:27.177985  4985 net.cpp:122] Setting up PReLU18
I1023 15:05:27.177994  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.177996  4985 net.cpp:137] Memory required for data: 1655406688
I1023 15:05:27.178000  4985 layer_factory.hpp:77] Creating layer Convolution21
I1023 15:05:27.178009  4985 net.cpp:84] Creating Layer Convolution21
I1023 15:05:27.178012  4985 net.cpp:406] Convolution21 <- Convolution20
I1023 15:05:27.178017  4985 net.cpp:380] Convolution21 -> Convolution21
I1023 15:05:27.180373  4985 net.cpp:122] Setting up Convolution21
I1023 15:05:27.180383  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.180387  4985 net.cpp:137] Memory required for data: 1661829216
I1023 15:05:27.180392  4985 layer_factory.hpp:77] Creating layer BatchNorm21
I1023 15:05:27.180397  4985 net.cpp:84] Creating Layer BatchNorm21
I1023 15:05:27.180400  4985 net.cpp:406] BatchNorm21 <- Convolution21
I1023 15:05:27.180404  4985 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1023 15:05:27.180568  4985 net.cpp:122] Setting up BatchNorm21
I1023 15:05:27.180573  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.180575  4985 net.cpp:137] Memory required for data: 1668251744
I1023 15:05:27.180580  4985 layer_factory.hpp:77] Creating layer Scale21
I1023 15:05:27.180584  4985 net.cpp:84] Creating Layer Scale21
I1023 15:05:27.180588  4985 net.cpp:406] Scale21 <- Convolution21
I1023 15:05:27.180590  4985 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1023 15:05:27.180635  4985 layer_factory.hpp:77] Creating layer Scale21
I1023 15:05:27.180778  4985 net.cpp:122] Setting up Scale21
I1023 15:05:27.180784  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.180786  4985 net.cpp:137] Memory required for data: 1674674272
I1023 15:05:27.180790  4985 layer_factory.hpp:77] Creating layer Eltwise9
I1023 15:05:27.180796  4985 net.cpp:84] Creating Layer Eltwise9
I1023 15:05:27.180799  4985 net.cpp:406] Eltwise9 <- Eltwise8_PReLU17_0_split_1
I1023 15:05:27.180802  4985 net.cpp:406] Eltwise9 <- Convolution21
I1023 15:05:27.180805  4985 net.cpp:380] Eltwise9 -> Eltwise9
I1023 15:05:27.180825  4985 net.cpp:122] Setting up Eltwise9
I1023 15:05:27.180830  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.180831  4985 net.cpp:137] Memory required for data: 1681096800
I1023 15:05:27.180833  4985 layer_factory.hpp:77] Creating layer PReLU19
I1023 15:05:27.180837  4985 net.cpp:84] Creating Layer PReLU19
I1023 15:05:27.180840  4985 net.cpp:406] PReLU19 <- Eltwise9
I1023 15:05:27.180852  4985 net.cpp:367] PReLU19 -> Eltwise9 (in-place)
I1023 15:05:27.181071  4985 net.cpp:122] Setting up PReLU19
I1023 15:05:27.181077  4985 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 15:05:27.181078  4985 net.cpp:137] Memory required for data: 1687519328
I1023 15:05:27.181082  4985 layer_factory.hpp:77] Creating layer Pooling1
I1023 15:05:27.181088  4985 net.cpp:84] Creating Layer Pooling1
I1023 15:05:27.181092  4985 net.cpp:406] Pooling1 <- Eltwise9
I1023 15:05:27.181095  4985 net.cpp:380] Pooling1 -> Pooling1
I1023 15:05:27.181237  4985 net.cpp:122] Setting up Pooling1
I1023 15:05:27.181244  4985 net.cpp:129] Top shape: 8 64 1 1 (512)
I1023 15:05:27.181246  4985 net.cpp:137] Memory required for data: 1687521376
I1023 15:05:27.181249  4985 layer_factory.hpp:77] Creating layer InnerProduct1
I1023 15:05:27.181255  4985 net.cpp:84] Creating Layer InnerProduct1
I1023 15:05:27.181257  4985 net.cpp:406] InnerProduct1 <- Pooling1
I1023 15:05:27.181262  4985 net.cpp:380] InnerProduct1 -> InnerProduct1
I1023 15:05:27.181380  4985 net.cpp:122] Setting up InnerProduct1
I1023 15:05:27.181388  4985 net.cpp:129] Top shape: 8 4 (32)
I1023 15:05:27.181391  4985 net.cpp:137] Memory required for data: 1687521504
I1023 15:05:27.181397  4985 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I1023 15:05:27.181402  4985 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I1023 15:05:27.181406  4985 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I1023 15:05:27.181408  4985 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I1023 15:05:27.181414  4985 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I1023 15:05:27.181447  4985 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I1023 15:05:27.181450  4985 net.cpp:129] Top shape: 8 4 (32)
I1023 15:05:27.181453  4985 net.cpp:129] Top shape: 8 4 (32)
I1023 15:05:27.181455  4985 net.cpp:137] Memory required for data: 1687521760
I1023 15:05:27.181457  4985 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1023 15:05:27.181463  4985 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1023 15:05:27.181464  4985 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I1023 15:05:27.181468  4985 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I1023 15:05:27.181471  4985 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1023 15:05:27.181476  4985 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1023 15:05:27.181674  4985 net.cpp:122] Setting up SoftmaxWithLoss1
I1023 15:05:27.181680  4985 net.cpp:129] Top shape: (1)
I1023 15:05:27.181682  4985 net.cpp:132]     with loss weight 1
I1023 15:05:27.181689  4985 net.cpp:137] Memory required for data: 1687521764
I1023 15:05:27.181691  4985 layer_factory.hpp:77] Creating layer Accuracy1
I1023 15:05:27.181697  4985 net.cpp:84] Creating Layer Accuracy1
I1023 15:05:27.181699  4985 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I1023 15:05:27.181702  4985 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I1023 15:05:27.181706  4985 net.cpp:380] Accuracy1 -> Accuracy1
I1023 15:05:27.181711  4985 net.cpp:122] Setting up Accuracy1
I1023 15:05:27.181715  4985 net.cpp:129] Top shape: (1)
I1023 15:05:27.181717  4985 net.cpp:137] Memory required for data: 1687521768
I1023 15:05:27.181720  4985 net.cpp:200] Accuracy1 does not need backward computation.
I1023 15:05:27.181721  4985 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1023 15:05:27.181725  4985 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I1023 15:05:27.181726  4985 net.cpp:198] InnerProduct1 needs backward computation.
I1023 15:05:27.181728  4985 net.cpp:198] Pooling1 needs backward computation.
I1023 15:05:27.181731  4985 net.cpp:198] PReLU19 needs backward computation.
I1023 15:05:27.181733  4985 net.cpp:198] Eltwise9 needs backward computation.
I1023 15:05:27.181735  4985 net.cpp:198] Scale21 needs backward computation.
I1023 15:05:27.181737  4985 net.cpp:198] BatchNorm21 needs backward computation.
I1023 15:05:27.181746  4985 net.cpp:198] Convolution21 needs backward computation.
I1023 15:05:27.181749  4985 net.cpp:198] PReLU18 needs backward computation.
I1023 15:05:27.181751  4985 net.cpp:198] Scale20 needs backward computation.
I1023 15:05:27.181753  4985 net.cpp:198] BatchNorm20 needs backward computation.
I1023 15:05:27.181756  4985 net.cpp:198] Convolution20 needs backward computation.
I1023 15:05:27.181757  4985 net.cpp:198] Eltwise8_PReLU17_0_split needs backward computation.
I1023 15:05:27.181761  4985 net.cpp:198] PReLU17 needs backward computation.
I1023 15:05:27.181762  4985 net.cpp:198] Eltwise8 needs backward computation.
I1023 15:05:27.181764  4985 net.cpp:198] Scale19 needs backward computation.
I1023 15:05:27.181767  4985 net.cpp:198] BatchNorm19 needs backward computation.
I1023 15:05:27.181769  4985 net.cpp:198] Convolution19 needs backward computation.
I1023 15:05:27.181771  4985 net.cpp:198] PReLU16 needs backward computation.
I1023 15:05:27.181773  4985 net.cpp:198] Scale18 needs backward computation.
I1023 15:05:27.181776  4985 net.cpp:198] BatchNorm18 needs backward computation.
I1023 15:05:27.181777  4985 net.cpp:198] Convolution18 needs backward computation.
I1023 15:05:27.181780  4985 net.cpp:198] Eltwise7_PReLU15_0_split needs backward computation.
I1023 15:05:27.181782  4985 net.cpp:198] PReLU15 needs backward computation.
I1023 15:05:27.181784  4985 net.cpp:198] Eltwise7 needs backward computation.
I1023 15:05:27.181787  4985 net.cpp:198] Scale17 needs backward computation.
I1023 15:05:27.181790  4985 net.cpp:198] BatchNorm17 needs backward computation.
I1023 15:05:27.181792  4985 net.cpp:198] Convolution17 needs backward computation.
I1023 15:05:27.181794  4985 net.cpp:198] PReLU14 needs backward computation.
I1023 15:05:27.181797  4985 net.cpp:198] Scale16 needs backward computation.
I1023 15:05:27.181799  4985 net.cpp:198] BatchNorm16 needs backward computation.
I1023 15:05:27.181802  4985 net.cpp:198] Convolution16 needs backward computation.
I1023 15:05:27.181803  4985 net.cpp:198] Scale15 needs backward computation.
I1023 15:05:27.181805  4985 net.cpp:198] BatchNorm15 needs backward computation.
I1023 15:05:27.181808  4985 net.cpp:198] Convolution15 needs backward computation.
I1023 15:05:27.181810  4985 net.cpp:198] Eltwise6_PReLU13_0_split needs backward computation.
I1023 15:05:27.181813  4985 net.cpp:198] PReLU13 needs backward computation.
I1023 15:05:27.181815  4985 net.cpp:198] Eltwise6 needs backward computation.
I1023 15:05:27.181818  4985 net.cpp:198] Scale14 needs backward computation.
I1023 15:05:27.181820  4985 net.cpp:198] BatchNorm14 needs backward computation.
I1023 15:05:27.181823  4985 net.cpp:198] Convolution14 needs backward computation.
I1023 15:05:27.181824  4985 net.cpp:198] PReLU12 needs backward computation.
I1023 15:05:27.181828  4985 net.cpp:198] Scale13 needs backward computation.
I1023 15:05:27.181829  4985 net.cpp:198] BatchNorm13 needs backward computation.
I1023 15:05:27.181831  4985 net.cpp:198] Convolution13 needs backward computation.
I1023 15:05:27.181833  4985 net.cpp:198] Eltwise5_PReLU11_0_split needs backward computation.
I1023 15:05:27.181838  4985 net.cpp:198] PReLU11 needs backward computation.
I1023 15:05:27.181839  4985 net.cpp:198] Eltwise5 needs backward computation.
I1023 15:05:27.181843  4985 net.cpp:198] Scale12 needs backward computation.
I1023 15:05:27.181844  4985 net.cpp:198] BatchNorm12 needs backward computation.
I1023 15:05:27.181848  4985 net.cpp:198] Convolution12 needs backward computation.
I1023 15:05:27.181849  4985 net.cpp:198] PReLU10 needs backward computation.
I1023 15:05:27.181851  4985 net.cpp:198] Scale11 needs backward computation.
I1023 15:05:27.181854  4985 net.cpp:198] BatchNorm11 needs backward computation.
I1023 15:05:27.181855  4985 net.cpp:198] Convolution11 needs backward computation.
I1023 15:05:27.181859  4985 net.cpp:198] Eltwise4_PReLU9_0_split needs backward computation.
I1023 15:05:27.181860  4985 net.cpp:198] PReLU9 needs backward computation.
I1023 15:05:27.181862  4985 net.cpp:198] Eltwise4 needs backward computation.
I1023 15:05:27.181869  4985 net.cpp:198] Scale10 needs backward computation.
I1023 15:05:27.181871  4985 net.cpp:198] BatchNorm10 needs backward computation.
I1023 15:05:27.181874  4985 net.cpp:198] Convolution10 needs backward computation.
I1023 15:05:27.181876  4985 net.cpp:198] PReLU8 needs backward computation.
I1023 15:05:27.181879  4985 net.cpp:198] Scale9 needs backward computation.
I1023 15:05:27.181881  4985 net.cpp:198] BatchNorm9 needs backward computation.
I1023 15:05:27.181884  4985 net.cpp:198] Convolution9 needs backward computation.
I1023 15:05:27.181885  4985 net.cpp:198] Scale8 needs backward computation.
I1023 15:05:27.181888  4985 net.cpp:198] BatchNorm8 needs backward computation.
I1023 15:05:27.181890  4985 net.cpp:198] Convolution8 needs backward computation.
I1023 15:05:27.181893  4985 net.cpp:198] Eltwise3_PReLU7_0_split needs backward computation.
I1023 15:05:27.181895  4985 net.cpp:198] PReLU7 needs backward computation.
I1023 15:05:27.181897  4985 net.cpp:198] Eltwise3 needs backward computation.
I1023 15:05:27.181900  4985 net.cpp:198] Scale7 needs backward computation.
I1023 15:05:27.181902  4985 net.cpp:198] BatchNorm7 needs backward computation.
I1023 15:05:27.181905  4985 net.cpp:198] Convolution7 needs backward computation.
I1023 15:05:27.181907  4985 net.cpp:198] PReLU6 needs backward computation.
I1023 15:05:27.181910  4985 net.cpp:198] Scale6 needs backward computation.
I1023 15:05:27.181911  4985 net.cpp:198] BatchNorm6 needs backward computation.
I1023 15:05:27.181915  4985 net.cpp:198] Convolution6 needs backward computation.
I1023 15:05:27.181916  4985 net.cpp:198] Eltwise2_PReLU5_0_split needs backward computation.
I1023 15:05:27.181918  4985 net.cpp:198] PReLU5 needs backward computation.
I1023 15:05:27.181921  4985 net.cpp:198] Eltwise2 needs backward computation.
I1023 15:05:27.181923  4985 net.cpp:198] Scale5 needs backward computation.
I1023 15:05:27.181926  4985 net.cpp:198] BatchNorm5 needs backward computation.
I1023 15:05:27.181928  4985 net.cpp:198] Convolution5 needs backward computation.
I1023 15:05:27.181931  4985 net.cpp:198] PReLU4 needs backward computation.
I1023 15:05:27.181932  4985 net.cpp:198] Scale4 needs backward computation.
I1023 15:05:27.181936  4985 net.cpp:198] BatchNorm4 needs backward computation.
I1023 15:05:27.181937  4985 net.cpp:198] Convolution4 needs backward computation.
I1023 15:05:27.181939  4985 net.cpp:198] Eltwise1_PReLU3_0_split needs backward computation.
I1023 15:05:27.181942  4985 net.cpp:198] PReLU3 needs backward computation.
I1023 15:05:27.181944  4985 net.cpp:198] Eltwise1 needs backward computation.
I1023 15:05:27.181947  4985 net.cpp:198] Scale3 needs backward computation.
I1023 15:05:27.181949  4985 net.cpp:198] BatchNorm3 needs backward computation.
I1023 15:05:27.181951  4985 net.cpp:198] Convolution3 needs backward computation.
I1023 15:05:27.181953  4985 net.cpp:198] PReLU2 needs backward computation.
I1023 15:05:27.181955  4985 net.cpp:198] Scale2 needs backward computation.
I1023 15:05:27.181958  4985 net.cpp:198] BatchNorm2 needs backward computation.
I1023 15:05:27.181960  4985 net.cpp:198] Convolution2 needs backward computation.
I1023 15:05:27.181962  4985 net.cpp:198] Convolution1_PReLU1_0_split needs backward computation.
I1023 15:05:27.181965  4985 net.cpp:198] PReLU1 needs backward computation.
I1023 15:05:27.181967  4985 net.cpp:198] Scale1 needs backward computation.
I1023 15:05:27.181969  4985 net.cpp:198] BatchNorm1 needs backward computation.
I1023 15:05:27.181972  4985 net.cpp:198] Convolution1 needs backward computation.
I1023 15:05:27.181974  4985 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I1023 15:05:27.181977  4985 net.cpp:200] Data1 does not need backward computation.
I1023 15:05:27.181979  4985 net.cpp:242] This network produces output Accuracy1
I1023 15:05:27.181982  4985 net.cpp:242] This network produces output SoftmaxWithLoss1
I1023 15:05:27.182018  4985 net.cpp:255] Network initialization done.
I1023 15:05:27.182235  4985 solver.cpp:56] Solver scaffolding done.
I1023 15:05:27.186923  4985 caffe.cpp:248] Starting Optimization
I1023 15:05:27.186929  4985 solver.cpp:272] Solving resnet
I1023 15:05:27.186931  4985 solver.cpp:273] Learning Rate Policy: multistep
I1023 15:05:27.189406  4985 solver.cpp:330] Iteration 0, Testing net (#0)
I1023 15:05:29.603641  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:05:29.737323  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.119141
I1023 15:05:29.737385  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I1023 15:05:29.957916  4985 solver.cpp:218] Iteration 0 (-2.41198e-33 iter/s, 2.77094s/100 iters), loss = 1.38862
I1023 15:05:29.957949  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.38862 (* 1 = 1.38862 loss)
I1023 15:05:29.957960  4985 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I1023 15:05:48.806141  4985 solver.cpp:218] Iteration 100 (5.3056 iter/s, 18.848s/100 iters), loss = 0.77473
I1023 15:05:48.806182  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.77473 (* 1 = 0.77473 loss)
I1023 15:05:48.806190  4985 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I1023 15:06:07.482039  4985 solver.cpp:330] Iteration 200, Testing net (#0)
I1023 15:06:09.851300  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:06:09.986270  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.154297
I1023 15:06:09.986326  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 6.69959 (* 1 = 6.69959 loss)
I1023 15:06:10.175819  4985 solver.cpp:218] Iteration 200 (4.67958 iter/s, 21.3694s/100 iters), loss = 0.8905
I1023 15:06:10.175848  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.8905 (* 1 = 0.8905 loss)
I1023 15:06:10.175855  4985 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I1023 15:06:29.055408  4985 solver.cpp:218] Iteration 300 (5.29679 iter/s, 18.8794s/100 iters), loss = 1.97407
I1023 15:06:29.055440  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.97407 (* 1 = 1.97407 loss)
I1023 15:06:29.055449  4985 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I1023 15:06:36.068123  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:06:47.751802  4985 solver.cpp:330] Iteration 400, Testing net (#0)
I1023 15:06:50.118943  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:06:50.254118  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.25
I1023 15:06:50.254185  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 16.8575 (* 1 = 16.8575 loss)
I1023 15:06:50.444092  4985 solver.cpp:218] Iteration 400 (4.67542 iter/s, 21.3885s/100 iters), loss = 0.947965
I1023 15:06:50.444125  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.947965 (* 1 = 0.947965 loss)
I1023 15:06:50.444133  4985 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I1023 15:07:09.353178  4985 solver.cpp:218] Iteration 500 (5.28852 iter/s, 18.9089s/100 iters), loss = 0.772752
I1023 15:07:09.353210  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.772752 (* 1 = 0.772752 loss)
I1023 15:07:09.353216  4985 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I1023 15:07:28.076359  4985 solver.cpp:330] Iteration 600, Testing net (#0)
I1023 15:07:30.408643  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:07:30.579838  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.201172
I1023 15:07:30.579891  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 7.12838 (* 1 = 7.12838 loss)
I1023 15:07:30.769595  4985 solver.cpp:218] Iteration 600 (4.66936 iter/s, 21.4162s/100 iters), loss = 1.4017
I1023 15:07:30.769629  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.4017 (* 1 = 1.4017 loss)
I1023 15:07:30.769636  4985 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I1023 15:07:45.538473  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:07:49.676285  4985 solver.cpp:218] Iteration 700 (5.28919 iter/s, 18.9065s/100 iters), loss = 0.707135
I1023 15:07:49.676316  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.707135 (* 1 = 0.707135 loss)
I1023 15:07:49.676323  4985 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I1023 15:08:08.391801  4985 solver.cpp:330] Iteration 800, Testing net (#0)
I1023 15:08:10.723228  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:08:10.896209  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.294922
I1023 15:08:10.896267  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 5.51335 (* 1 = 5.51335 loss)
I1023 15:08:11.086326  4985 solver.cpp:218] Iteration 800 (4.67075 iter/s, 21.4098s/100 iters), loss = 0.417195
I1023 15:08:11.086362  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.417195 (* 1 = 0.417195 loss)
I1023 15:08:11.086369  4985 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I1023 15:08:29.993322  4985 solver.cpp:218] Iteration 900 (5.2891 iter/s, 18.9068s/100 iters), loss = 0.584237
I1023 15:08:29.993356  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.584238 (* 1 = 0.584238 loss)
I1023 15:08:29.993363  4985 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I1023 15:08:48.715709  4985 solver.cpp:330] Iteration 1000, Testing net (#0)
I1023 15:08:51.046279  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:08:51.219769  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.599609
I1023 15:08:51.219830  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.10316 (* 1 = 1.10316 loss)
I1023 15:08:51.409970  4985 solver.cpp:218] Iteration 1000 (4.66931 iter/s, 21.4165s/100 iters), loss = 0.327435
I1023 15:08:51.409999  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327435 (* 1 = 0.327435 loss)
I1023 15:08:51.410006  4985 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I1023 15:08:55.031733  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:09:10.324967  4985 solver.cpp:218] Iteration 1100 (5.28685 iter/s, 18.9149s/100 iters), loss = 0.106302
I1023 15:09:10.324998  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106302 (* 1 = 0.106302 loss)
I1023 15:09:10.325006  4985 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I1023 15:09:29.050247  4985 solver.cpp:330] Iteration 1200, Testing net (#0)
I1023 15:09:31.380453  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:09:31.554858  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.669922
I1023 15:09:31.554918  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.910982 (* 1 = 0.910982 loss)
I1023 15:09:31.744809  4985 solver.cpp:218] Iteration 1200 (4.6686 iter/s, 21.4197s/100 iters), loss = 1.58909
I1023 15:09:31.744838  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.58909 (* 1 = 1.58909 loss)
I1023 15:09:31.744845  4985 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I1023 15:09:50.653772  4985 solver.cpp:218] Iteration 1300 (5.28853 iter/s, 18.9088s/100 iters), loss = 0.58947
I1023 15:09:50.653805  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.589471 (* 1 = 0.589471 loss)
I1023 15:09:50.653813  4985 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I1023 15:10:02.029954  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:10:09.383394  4985 solver.cpp:330] Iteration 1400, Testing net (#0)
I1023 15:10:11.676105  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:10:11.886361  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5625
I1023 15:10:11.886420  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.48157 (* 1 = 1.48157 loss)
I1023 15:10:12.076177  4985 solver.cpp:218] Iteration 1400 (4.66804 iter/s, 21.4223s/100 iters), loss = 0.622617
I1023 15:10:12.076212  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.622618 (* 1 = 0.622618 loss)
I1023 15:10:12.076220  4985 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I1023 15:10:30.976357  4985 solver.cpp:218] Iteration 1500 (5.29099 iter/s, 18.9001s/100 iters), loss = 0.437712
I1023 15:10:30.976390  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.437713 (* 1 = 0.437713 loss)
I1023 15:10:30.976398  4985 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I1023 15:10:49.701027  4985 solver.cpp:330] Iteration 1600, Testing net (#0)
I1023 15:10:52.032531  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:10:52.205384  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.505859
I1023 15:10:52.205451  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.67143 (* 1 = 1.67143 loss)
I1023 15:10:52.396387  4985 solver.cpp:218] Iteration 1600 (4.66855 iter/s, 21.4199s/100 iters), loss = 1.15935
I1023 15:10:52.396419  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.15935 (* 1 = 1.15935 loss)
I1023 15:10:52.396425  4985 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I1023 15:11:11.305925  4985 solver.cpp:218] Iteration 1700 (5.28837 iter/s, 18.9094s/100 iters), loss = 0.699722
I1023 15:11:11.305956  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.699722 (* 1 = 0.699722 loss)
I1023 15:11:11.305963  4985 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I1023 15:11:11.709451  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:11:30.030587  4985 solver.cpp:330] Iteration 1800, Testing net (#0)
I1023 15:11:32.322546  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:11:32.534847  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.613281
I1023 15:11:32.534909  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.992155 (* 1 = 0.992155 loss)
I1023 15:11:32.724931  4985 solver.cpp:218] Iteration 1800 (4.66878 iter/s, 21.4189s/100 iters), loss = 0.410589
I1023 15:11:32.724966  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.41059 (* 1 = 0.41059 loss)
I1023 15:11:32.724972  4985 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I1023 15:11:51.625778  4985 solver.cpp:218] Iteration 1900 (5.2908 iter/s, 18.9007s/100 iters), loss = 0.75958
I1023 15:11:51.625811  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.759581 (* 1 = 0.759581 loss)
I1023 15:11:51.625818  4985 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I1023 15:12:10.343902  4985 solver.cpp:330] Iteration 2000, Testing net (#0)
I1023 15:12:12.634871  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:12:12.848215  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.689453
I1023 15:12:12.848261  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.07681 (* 1 = 1.07681 loss)
I1023 15:12:13.038184  4985 solver.cpp:218] Iteration 2000 (4.67022 iter/s, 21.4123s/100 iters), loss = 0.0342824
I1023 15:12:13.038219  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0342832 (* 1 = 0.0342832 loss)
I1023 15:12:13.038228  4985 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I1023 15:12:21.199717  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:12:31.958603  4985 solver.cpp:218] Iteration 2100 (5.28533 iter/s, 18.9203s/100 iters), loss = 0.641315
I1023 15:12:31.958636  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.641316 (* 1 = 0.641316 loss)
I1023 15:12:31.958642  4985 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I1023 15:12:50.675649  4985 solver.cpp:330] Iteration 2200, Testing net (#0)
I1023 15:12:52.933584  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:12:53.184250  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.767578
I1023 15:12:53.184311  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.820097 (* 1 = 0.820097 loss)
I1023 15:12:53.374620  4985 solver.cpp:218] Iteration 2200 (4.66943 iter/s, 21.4159s/100 iters), loss = 0.524286
I1023 15:12:53.374651  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.524287 (* 1 = 0.524287 loss)
I1023 15:12:53.374660  4985 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I1023 15:13:12.339560  4985 solver.cpp:218] Iteration 2300 (5.27292 iter/s, 18.9648s/100 iters), loss = 0.0599238
I1023 15:13:12.339593  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0599246 (* 1 = 0.0599246 loss)
I1023 15:13:12.339599  4985 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I1023 15:13:28.297894  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:13:31.120385  4985 solver.cpp:330] Iteration 2400, Testing net (#0)
I1023 15:13:33.378350  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:13:33.629240  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.585938
I1023 15:13:33.629302  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.19167 (* 1 = 2.19167 loss)
I1023 15:13:33.820021  4985 solver.cpp:218] Iteration 2400 (4.65542 iter/s, 21.4803s/100 iters), loss = 0.191532
I1023 15:13:33.820053  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191533 (* 1 = 0.191533 loss)
I1023 15:13:33.820060  4985 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I1023 15:13:52.776933  4985 solver.cpp:218] Iteration 2500 (5.27515 iter/s, 18.9568s/100 iters), loss = 0.371077
I1023 15:13:52.776964  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371078 (* 1 = 0.371078 loss)
I1023 15:13:52.776971  4985 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I1023 15:14:11.549806  4985 solver.cpp:330] Iteration 2600, Testing net (#0)
I1023 15:14:13.806917  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:14:14.058156  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.585938
I1023 15:14:14.058218  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.6458 (* 1 = 1.6458 loss)
I1023 15:14:14.248540  4985 solver.cpp:218] Iteration 2600 (4.65734 iter/s, 21.4715s/100 iters), loss = 0.0989113
I1023 15:14:14.248570  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0989121 (* 1 = 0.0989121 loss)
I1023 15:14:14.248577  4985 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I1023 15:14:33.209830  4985 solver.cpp:218] Iteration 2700 (5.27393 iter/s, 18.9612s/100 iters), loss = 0.883026
I1023 15:14:33.209861  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.883027 (* 1 = 0.883027 loss)
I1023 15:14:33.209868  4985 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I1023 15:14:37.980332  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:14:51.986866  4985 solver.cpp:330] Iteration 2800, Testing net (#0)
I1023 15:14:54.243551  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:14:54.495883  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.638672
I1023 15:14:54.495939  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.48011 (* 1 = 1.48011 loss)
I1023 15:14:54.686610  4985 solver.cpp:218] Iteration 2800 (4.65622 iter/s, 21.4767s/100 iters), loss = 0.0614772
I1023 15:14:54.686640  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0614783 (* 1 = 0.0614783 loss)
I1023 15:14:54.686647  4985 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I1023 15:15:13.651587  4985 solver.cpp:218] Iteration 2900 (5.27291 iter/s, 18.9649s/100 iters), loss = 0.386619
I1023 15:15:13.651619  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.38662 (* 1 = 0.38662 loss)
I1023 15:15:13.651626  4985 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I1023 15:15:32.427808  4985 solver.cpp:330] Iteration 3000, Testing net (#0)
I1023 15:15:34.647132  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:15:34.936206  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.671875
I1023 15:15:34.936275  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.961251 (* 1 = 0.961251 loss)
I1023 15:15:35.126688  4985 solver.cpp:218] Iteration 3000 (4.65658 iter/s, 21.475s/100 iters), loss = 1.04473
I1023 15:15:35.126718  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.04473 (* 1 = 1.04473 loss)
I1023 15:15:35.126725  4985 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I1023 15:15:47.854286  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:15:54.091121  4985 solver.cpp:218] Iteration 3100 (5.27306 iter/s, 18.9643s/100 iters), loss = 0.788705
I1023 15:15:54.091153  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.788707 (* 1 = 0.788707 loss)
I1023 15:15:54.091161  4985 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I1023 15:16:12.856772  4985 solver.cpp:330] Iteration 3200, Testing net (#0)
I1023 15:16:15.076622  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:16:15.366004  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.632812
I1023 15:16:15.366065  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.22127 (* 1 = 2.22127 loss)
I1023 15:16:15.556553  4985 solver.cpp:218] Iteration 3200 (4.65868 iter/s, 21.4653s/100 iters), loss = 0.0981571
I1023 15:16:15.556586  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0981581 (* 1 = 0.0981581 loss)
I1023 15:16:15.556592  4985 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I1023 15:16:34.520673  4985 solver.cpp:218] Iteration 3300 (5.27314 iter/s, 18.964s/100 iters), loss = 0.534758
I1023 15:16:34.520704  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.534759 (* 1 = 0.534759 loss)
I1023 15:16:34.520710  4985 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I1023 15:16:53.299808  4985 solver.cpp:330] Iteration 3400, Testing net (#0)
I1023 15:16:55.517431  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:16:55.808101  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.707031
I1023 15:16:55.808166  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.03928 (* 1 = 1.03928 loss)
I1023 15:16:55.998587  4985 solver.cpp:218] Iteration 3400 (4.65597 iter/s, 21.4778s/100 iters), loss = 0.0458203
I1023 15:16:55.998617  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0458216 (* 1 = 0.0458216 loss)
I1023 15:16:55.998623  4985 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I1023 15:16:57.542924  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:17:14.966903  4985 solver.cpp:218] Iteration 3500 (5.27198 iter/s, 18.9682s/100 iters), loss = 0.52051
I1023 15:17:14.966933  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.520512 (* 1 = 0.520512 loss)
I1023 15:17:14.966940  4985 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I1023 15:17:33.742784  4985 solver.cpp:330] Iteration 3600, Testing net (#0)
I1023 15:17:35.960315  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:17:36.252512  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.712891
I1023 15:17:36.252583  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.01823 (* 1 = 1.01823 loss)
I1023 15:17:36.442961  4985 solver.cpp:218] Iteration 3600 (4.65637 iter/s, 21.476s/100 iters), loss = 0.0578274
I1023 15:17:36.442992  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.057829 (* 1 = 0.057829 loss)
I1023 15:17:36.442999  4985 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I1023 15:17:55.403482  4985 solver.cpp:218] Iteration 3700 (5.27414 iter/s, 18.9604s/100 iters), loss = 0.0206556
I1023 15:17:55.403513  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0206572 (* 1 = 0.0206572 loss)
I1023 15:17:55.403519  4985 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I1023 15:18:04.724862  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:18:14.179114  4985 solver.cpp:330] Iteration 3800, Testing net (#0)
I1023 15:18:16.359140  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:18:16.687544  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.648438
I1023 15:18:16.687605  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.0196 (* 1 = 1.0196 loss)
I1023 15:18:16.877923  4985 solver.cpp:218] Iteration 3800 (4.65672 iter/s, 21.4743s/100 iters), loss = 0.491682
I1023 15:18:16.877954  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.491683 (* 1 = 0.491683 loss)
I1023 15:18:16.877961  4985 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I1023 15:18:35.839242  4985 solver.cpp:218] Iteration 3900 (5.27392 iter/s, 18.9612s/100 iters), loss = 0.0401866
I1023 15:18:35.839361  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0401883 (* 1 = 0.0401883 loss)
I1023 15:18:35.839370  4985 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I1023 15:18:54.614383  4985 solver.cpp:330] Iteration 4000, Testing net (#0)
I1023 15:18:56.793819  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:18:57.122225  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.832031
I1023 15:18:57.122292  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.506579 (* 1 = 0.506579 loss)
I1023 15:18:57.312762  4985 solver.cpp:218] Iteration 4000 (4.65694 iter/s, 21.4733s/100 iters), loss = 0.070762
I1023 15:18:57.312793  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0707637 (* 1 = 0.0707637 loss)
I1023 15:18:57.312799  4985 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I1023 15:19:14.406127  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:19:16.278959  4985 solver.cpp:218] Iteration 4100 (5.27256 iter/s, 18.9661s/100 iters), loss = 0.0934872
I1023 15:19:16.278992  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0934889 (* 1 = 0.0934889 loss)
I1023 15:19:16.278998  4985 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I1023 15:19:35.053417  4985 solver.cpp:330] Iteration 4200, Testing net (#0)
I1023 15:19:37.232795  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:19:37.562151  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.808594
I1023 15:19:37.562214  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.53346 (* 1 = 0.53346 loss)
I1023 15:19:37.752620  4985 solver.cpp:218] Iteration 4200 (4.65689 iter/s, 21.4736s/100 iters), loss = 0.160626
I1023 15:19:37.752652  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160628 (* 1 = 0.160628 loss)
I1023 15:19:37.752660  4985 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I1023 15:19:56.708853  4985 solver.cpp:218] Iteration 4300 (5.27534 iter/s, 18.9561s/100 iters), loss = 0.349348
I1023 15:19:56.708986  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34935 (* 1 = 0.34935 loss)
I1023 15:19:56.708995  4985 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I1023 15:20:15.480608  4985 solver.cpp:330] Iteration 4400, Testing net (#0)
I1023 15:20:17.658424  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:20:17.988181  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.787109
I1023 15:20:17.988245  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.612805 (* 1 = 0.612805 loss)
I1023 15:20:18.178810  4985 solver.cpp:218] Iteration 4400 (4.65771 iter/s, 21.4698s/100 iters), loss = 0.00765628
I1023 15:20:18.178843  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00765783 (* 1 = 0.00765783 loss)
I1023 15:20:18.178849  4985 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I1023 15:20:24.276813  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:20:37.148159  4985 solver.cpp:218] Iteration 4500 (5.27169 iter/s, 18.9693s/100 iters), loss = 0.171267
I1023 15:20:37.148300  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171269 (* 1 = 0.171269 loss)
I1023 15:20:37.148309  4985 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I1023 15:20:55.925516  4985 solver.cpp:330] Iteration 4600, Testing net (#0)
I1023 15:20:58.066970  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:20:58.434046  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.890625
I1023 15:20:58.434108  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328817 (* 1 = 0.328817 loss)
I1023 15:20:58.624557  4985 solver.cpp:218] Iteration 4600 (4.65632 iter/s, 21.4762s/100 iters), loss = 0.0249447
I1023 15:20:58.624589  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0249462 (* 1 = 0.0249462 loss)
I1023 15:20:58.624595  4985 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I1023 15:21:17.592629  4985 solver.cpp:218] Iteration 4700 (5.27204 iter/s, 18.968s/100 iters), loss = 0.692842
I1023 15:21:17.592804  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.692844 (* 1 = 0.692844 loss)
I1023 15:21:17.592814  4985 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I1023 15:21:31.466980  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:21:36.378141  4985 solver.cpp:330] Iteration 4800, Testing net (#0)
I1023 15:21:38.517949  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:21:38.886101  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.832031
I1023 15:21:38.886162  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.492873 (* 1 = 0.492873 loss)
I1023 15:21:39.076647  4985 solver.cpp:218] Iteration 4800 (4.65467 iter/s, 21.4838s/100 iters), loss = 0.311278
I1023 15:21:39.076679  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311279 (* 1 = 0.311279 loss)
I1023 15:21:39.076686  4985 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I1023 15:21:58.031170  4985 solver.cpp:218] Iteration 4900 (5.27581 iter/s, 18.9544s/100 iters), loss = 0.0185929
I1023 15:21:58.031327  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0185939 (* 1 = 0.0185939 loss)
I1023 15:21:58.031337  4985 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I1023 15:22:16.806504  4985 solver.cpp:330] Iteration 5000, Testing net (#0)
I1023 15:22:18.946838  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:22:19.315223  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.912109
I1023 15:22:19.315285  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31165 (* 1 = 0.31165 loss)
I1023 15:22:19.505440  4985 solver.cpp:218] Iteration 5000 (4.65678 iter/s, 21.4741s/100 iters), loss = 0.215577
I1023 15:22:19.505470  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215578 (* 1 = 0.215578 loss)
I1023 15:22:19.505477  4985 sgd_solver.cpp:105] Iteration 5000, lr = 0.01
I1023 15:22:38.468097  4985 solver.cpp:218] Iteration 5100 (5.27355 iter/s, 18.9626s/100 iters), loss = 0.022722
I1023 15:22:38.468240  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227229 (* 1 = 0.0227229 loss)
I1023 15:22:38.468248  4985 sgd_solver.cpp:105] Iteration 5100, lr = 0.01
I1023 15:22:41.150781  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:22:57.244704  4985 solver.cpp:330] Iteration 5200, Testing net (#0)
I1023 15:22:59.383517  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:22:59.752918  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.724609
I1023 15:22:59.752970  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.80403 (* 1 = 0.80403 loss)
I1023 15:22:59.943863  4985 solver.cpp:218] Iteration 5200 (4.65645 iter/s, 21.4756s/100 iters), loss = 0.364514
I1023 15:22:59.943897  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.364514 (* 1 = 0.364514 loss)
I1023 15:22:59.943903  4985 sgd_solver.cpp:105] Iteration 5200, lr = 0.01
I1023 15:23:18.908416  4985 solver.cpp:218] Iteration 5300 (5.27302 iter/s, 18.9645s/100 iters), loss = 0.541307
I1023 15:23:18.908556  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.541308 (* 1 = 0.541308 loss)
I1023 15:23:18.908565  4985 sgd_solver.cpp:105] Iteration 5300, lr = 0.01
I1023 15:23:37.685088  4985 solver.cpp:330] Iteration 5400, Testing net (#0)
I1023 15:23:39.787552  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:23:40.193549  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.884766
I1023 15:23:40.193614  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328197 (* 1 = 0.328197 loss)
I1023 15:23:40.383898  4985 solver.cpp:218] Iteration 5400 (4.65652 iter/s, 21.4753s/100 iters), loss = 0.194874
I1023 15:23:40.383929  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194874 (* 1 = 0.194874 loss)
I1023 15:23:40.383936  4985 sgd_solver.cpp:105] Iteration 5400, lr = 0.01
I1023 15:23:50.839562  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:23:59.349135  4985 solver.cpp:218] Iteration 5500 (5.27283 iter/s, 18.9652s/100 iters), loss = 0.290006
I1023 15:23:59.349167  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290007 (* 1 = 0.290007 loss)
I1023 15:23:59.349174  4985 sgd_solver.cpp:105] Iteration 5500, lr = 0.01
I1023 15:24:18.113078  4985 solver.cpp:330] Iteration 5600, Testing net (#0)
I1023 15:24:20.214720  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:24:20.621301  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.824219
I1023 15:24:20.621363  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.653 (* 1 = 0.653 loss)
I1023 15:24:20.811872  4985 solver.cpp:218] Iteration 5600 (4.65926 iter/s, 21.4626s/100 iters), loss = 0.0565656
I1023 15:24:20.811903  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0565662 (* 1 = 0.0565662 loss)
I1023 15:24:20.811911  4985 sgd_solver.cpp:105] Iteration 5600, lr = 0.01
I1023 15:24:39.775324  4985 solver.cpp:218] Iteration 5700 (5.27333 iter/s, 18.9634s/100 iters), loss = 0.00836313
I1023 15:24:39.775467  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00836357 (* 1 = 0.00836357 loss)
I1023 15:24:39.775476  4985 sgd_solver.cpp:105] Iteration 5700, lr = 0.01
I1023 15:24:58.194413  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:24:58.553066  4985 solver.cpp:330] Iteration 5800, Testing net (#0)
I1023 15:25:00.654253  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:25:01.061583  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.951172
I1023 15:25:01.061648  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.143418 (* 1 = 0.143418 loss)
I1023 15:25:01.252827  4985 solver.cpp:218] Iteration 5800 (4.65608 iter/s, 21.4773s/100 iters), loss = 0.038219
I1023 15:25:01.252859  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0382194 (* 1 = 0.0382194 loss)
I1023 15:25:01.252866  4985 sgd_solver.cpp:105] Iteration 5800, lr = 0.01
I1023 15:25:20.214069  4985 solver.cpp:218] Iteration 5900 (5.27394 iter/s, 18.9612s/100 iters), loss = 0.589522
I1023 15:25:20.214215  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.589522 (* 1 = 0.589522 loss)
I1023 15:25:20.214223  4985 sgd_solver.cpp:105] Iteration 5900, lr = 0.01
I1023 15:25:38.989259  4985 solver.cpp:330] Iteration 6000, Testing net (#0)
I1023 15:25:41.087339  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:25:41.496567  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.785156
I1023 15:25:41.496624  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.600089 (* 1 = 0.600089 loss)
I1023 15:25:41.687053  4985 solver.cpp:218] Iteration 6000 (4.65706 iter/s, 21.4728s/100 iters), loss = 0.105434
I1023 15:25:41.687086  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.105434 (* 1 = 0.105434 loss)
I1023 15:25:41.687093  4985 sgd_solver.cpp:105] Iteration 6000, lr = 0.01
I1023 15:26:00.645589  4985 solver.cpp:218] Iteration 6100 (5.27469 iter/s, 18.9584s/100 iters), loss = 0.0832857
I1023 15:26:00.645710  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0832863 (* 1 = 0.0832863 loss)
I1023 15:26:00.645718  4985 sgd_solver.cpp:105] Iteration 6100, lr = 0.01
I1023 15:26:07.880331  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:26:19.419916  4985 solver.cpp:330] Iteration 6200, Testing net (#0)
I1023 15:26:21.481845  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:26:21.926641  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.710938
I1023 15:26:21.926700  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.95351 (* 1 = 0.95351 loss)
I1023 15:26:22.117034  4985 solver.cpp:218] Iteration 6200 (4.65739 iter/s, 21.4713s/100 iters), loss = 0.0965445
I1023 15:26:22.117069  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.096545 (* 1 = 0.096545 loss)
I1023 15:26:22.117075  4985 sgd_solver.cpp:105] Iteration 6200, lr = 0.01
I1023 15:26:41.078780  4985 solver.cpp:218] Iteration 6300 (5.2738 iter/s, 18.9617s/100 iters), loss = 0.0138947
I1023 15:26:41.078953  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138953 (* 1 = 0.0138953 loss)
I1023 15:26:41.078974  4985 sgd_solver.cpp:105] Iteration 6300, lr = 0.01
I1023 15:26:59.851719  4985 solver.cpp:330] Iteration 6400, Testing net (#0)
I1023 15:27:01.914965  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:27:02.360702  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.816406
I1023 15:27:02.360759  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.588658 (* 1 = 0.588658 loss)
I1023 15:27:02.551337  4985 solver.cpp:218] Iteration 6400 (4.65716 iter/s, 21.4723s/100 iters), loss = 0.0162973
I1023 15:27:02.551368  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0162978 (* 1 = 0.0162978 loss)
I1023 15:27:02.551374  4985 sgd_solver.cpp:105] Iteration 6400, lr = 0.01
I1023 15:27:17.558725  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:27:21.518560  4985 solver.cpp:218] Iteration 6500 (5.27228 iter/s, 18.9671s/100 iters), loss = 0.182884
I1023 15:27:21.518592  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182885 (* 1 = 0.182885 loss)
I1023 15:27:21.518599  4985 sgd_solver.cpp:105] Iteration 6500, lr = 0.01
I1023 15:27:40.292009  4985 solver.cpp:330] Iteration 6600, Testing net (#0)
I1023 15:27:42.352548  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:27:42.799365  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.919922
I1023 15:27:42.799427  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.198953 (* 1 = 0.198953 loss)
I1023 15:27:42.989529  4985 solver.cpp:218] Iteration 6600 (4.65747 iter/s, 21.4709s/100 iters), loss = 0.0205336
I1023 15:27:42.989563  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0205341 (* 1 = 0.0205341 loss)
I1023 15:27:42.989570  4985 sgd_solver.cpp:105] Iteration 6600, lr = 0.01
I1023 15:28:01.945200  4985 solver.cpp:218] Iteration 6700 (5.27549 iter/s, 18.9556s/100 iters), loss = 0.0445662
I1023 15:28:01.945343  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0445666 (* 1 = 0.0445666 loss)
I1023 15:28:01.945353  4985 sgd_solver.cpp:105] Iteration 6700, lr = 0.01
I1023 15:28:20.715960  4985 solver.cpp:330] Iteration 6800, Testing net (#0)
I1023 15:28:22.775710  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:28:23.223713  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.849609
I1023 15:28:23.223783  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.532985 (* 1 = 0.532985 loss)
I1023 15:28:23.414479  4985 solver.cpp:218] Iteration 6800 (4.65786 iter/s, 21.4691s/100 iters), loss = 0.102074
I1023 15:28:23.414511  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102074 (* 1 = 0.102074 loss)
I1023 15:28:23.414517  4985 sgd_solver.cpp:105] Iteration 6800, lr = 0.01
I1023 15:28:27.235157  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:28:42.380282  4985 solver.cpp:218] Iteration 6900 (5.27267 iter/s, 18.9657s/100 iters), loss = 0.173962
I1023 15:28:42.380435  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173962 (* 1 = 0.173962 loss)
I1023 15:28:42.380446  4985 sgd_solver.cpp:105] Iteration 6900, lr = 0.01
I1023 15:29:01.161113  4985 solver.cpp:330] Iteration 7000, Testing net (#0)
I1023 15:29:03.184797  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:29:03.669145  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.912109
I1023 15:29:03.669208  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.251164 (* 1 = 0.251164 loss)
I1023 15:29:03.859519  4985 solver.cpp:218] Iteration 7000 (4.6557 iter/s, 21.479s/100 iters), loss = 0.0204907
I1023 15:29:03.859551  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.020491 (* 1 = 0.020491 loss)
I1023 15:29:03.859558  4985 sgd_solver.cpp:105] Iteration 7000, lr = 0.01
I1023 15:29:22.825928  4985 solver.cpp:218] Iteration 7100 (5.2725 iter/s, 18.9663s/100 iters), loss = 0.149873
I1023 15:29:22.826102  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149873 (* 1 = 0.149873 loss)
I1023 15:29:22.826122  4985 sgd_solver.cpp:105] Iteration 7100, lr = 0.01
I1023 15:29:34.611681  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:29:41.613153  4985 solver.cpp:330] Iteration 7200, Testing net (#0)
I1023 15:29:43.635929  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:29:44.121150  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.791016
I1023 15:29:44.121212  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.566044 (* 1 = 0.566044 loss)
I1023 15:29:44.312290  4985 solver.cpp:218] Iteration 7200 (4.65416 iter/s, 21.4861s/100 iters), loss = 0.480262
I1023 15:29:44.312320  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.480262 (* 1 = 0.480262 loss)
I1023 15:29:44.312327  4985 sgd_solver.cpp:105] Iteration 7200, lr = 0.01
I1023 15:30:03.264197  4985 solver.cpp:218] Iteration 7300 (5.27654 iter/s, 18.9518s/100 iters), loss = 0.270691
I1023 15:30:03.264339  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270691 (* 1 = 0.270691 loss)
I1023 15:30:03.264348  4985 sgd_solver.cpp:105] Iteration 7300, lr = 0.01
I1023 15:30:22.036229  4985 solver.cpp:330] Iteration 7400, Testing net (#0)
I1023 15:30:24.057103  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:30:24.543344  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.832031
I1023 15:30:24.543395  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.531059 (* 1 = 0.531059 loss)
I1023 15:30:24.733929  4985 solver.cpp:218] Iteration 7400 (4.65776 iter/s, 21.4695s/100 iters), loss = 0.135826
I1023 15:30:24.733961  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135826 (* 1 = 0.135826 loss)
I1023 15:30:24.733968  4985 sgd_solver.cpp:105] Iteration 7400, lr = 0.01
I1023 15:30:43.697654  4985 solver.cpp:218] Iteration 7500 (5.27325 iter/s, 18.9636s/100 iters), loss = 0.152116
I1023 15:30:43.697775  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152116 (* 1 = 0.152116 loss)
I1023 15:30:43.697794  4985 sgd_solver.cpp:105] Iteration 7500, lr = 0.01
I1023 15:30:44.292402  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:31:02.476573  4985 solver.cpp:330] Iteration 7600, Testing net (#0)
I1023 15:31:04.498145  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:31:04.984797  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.869141
I1023 15:31:04.984863  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.341493 (* 1 = 0.341493 loss)
I1023 15:31:05.175616  4985 solver.cpp:218] Iteration 7600 (4.65597 iter/s, 21.4778s/100 iters), loss = 0.333196
I1023 15:31:05.175647  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333196 (* 1 = 0.333196 loss)
I1023 15:31:05.175654  4985 sgd_solver.cpp:105] Iteration 7600, lr = 0.01
I1023 15:31:24.139557  4985 solver.cpp:218] Iteration 7700 (5.27319 iter/s, 18.9639s/100 iters), loss = 0.0522271
I1023 15:31:24.139698  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0522274 (* 1 = 0.0522274 loss)
I1023 15:31:24.139708  4985 sgd_solver.cpp:105] Iteration 7700, lr = 0.01
I1023 15:31:42.918334  4985 solver.cpp:330] Iteration 7800, Testing net (#0)
I1023 15:31:44.903439  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:31:45.426805  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.861328
I1023 15:31:45.426870  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.67896 (* 1 = 0.67896 loss)
I1023 15:31:45.617537  4985 solver.cpp:218] Iteration 7800 (4.65597 iter/s, 21.4778s/100 iters), loss = 0.00624416
I1023 15:31:45.617568  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00624476 (* 1 = 0.00624476 loss)
I1023 15:31:45.617575  4985 sgd_solver.cpp:105] Iteration 7800, lr = 0.01
I1023 15:31:53.990206  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:32:04.587132  4985 solver.cpp:218] Iteration 7900 (5.27162 iter/s, 18.9695s/100 iters), loss = 0.107127
I1023 15:32:04.587294  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.107127 (* 1 = 0.107127 loss)
I1023 15:32:04.587304  4985 sgd_solver.cpp:105] Iteration 7900, lr = 0.01
I1023 15:32:23.346773  4985 solver.cpp:330] Iteration 8000, Testing net (#0)
I1023 15:32:25.331002  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:32:25.855279  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.941406
I1023 15:32:25.855340  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.16918 (* 1 = 0.16918 loss)
I1023 15:32:26.046152  4985 solver.cpp:218] Iteration 8000 (4.66009 iter/s, 21.4588s/100 iters), loss = 0.293187
I1023 15:32:26.046187  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293187 (* 1 = 0.293187 loss)
I1023 15:32:26.046195  4985 sgd_solver.cpp:105] Iteration 8000, lr = 0.01
I1023 15:32:45.009644  4985 solver.cpp:218] Iteration 8100 (5.27331 iter/s, 18.9634s/100 iters), loss = 0.0723809
I1023 15:32:45.009794  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0723813 (* 1 = 0.0723813 loss)
I1023 15:32:45.009804  4985 sgd_solver.cpp:105] Iteration 8100, lr = 0.01
I1023 15:33:01.159942  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:33:03.791924  4985 solver.cpp:330] Iteration 8200, Testing net (#0)
I1023 15:33:05.774101  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:33:06.298351  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.927734
I1023 15:33:06.298422  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.197435 (* 1 = 0.197435 loss)
I1023 15:33:06.489109  4985 solver.cpp:218] Iteration 8200 (4.65565 iter/s, 21.4793s/100 iters), loss = 0.113113
I1023 15:33:06.489140  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.113114 (* 1 = 0.113114 loss)
I1023 15:33:06.489146  4985 sgd_solver.cpp:105] Iteration 8200, lr = 0.01
I1023 15:33:25.450996  4985 solver.cpp:218] Iteration 8300 (5.27376 iter/s, 18.9618s/100 iters), loss = 0.0354844
I1023 15:33:25.451104  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0354849 (* 1 = 0.0354849 loss)
I1023 15:33:25.451112  4985 sgd_solver.cpp:105] Iteration 8300, lr = 0.01
I1023 15:33:44.229317  4985 solver.cpp:330] Iteration 8400, Testing net (#0)
I1023 15:33:46.211326  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:33:46.736999  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.90625
I1023 15:33:46.737064  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.258798 (* 1 = 0.258798 loss)
I1023 15:33:46.927367  4985 solver.cpp:218] Iteration 8400 (4.65631 iter/s, 21.4762s/100 iters), loss = 0.459296
I1023 15:33:46.927398  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.459296 (* 1 = 0.459296 loss)
I1023 15:33:46.927404  4985 sgd_solver.cpp:105] Iteration 8400, lr = 0.01
I1023 15:34:05.886816  4985 solver.cpp:218] Iteration 8500 (5.27444 iter/s, 18.9594s/100 iters), loss = 0.0204304
I1023 15:34:05.886970  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.020431 (* 1 = 0.020431 loss)
I1023 15:34:05.886979  4985 sgd_solver.cpp:105] Iteration 8500, lr = 0.01
I1023 15:34:11.034119  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:34:24.660413  4985 solver.cpp:330] Iteration 8600, Testing net (#0)
I1023 15:34:26.606112  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:34:27.167948  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.875
I1023 15:34:27.168016  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.363667 (* 1 = 0.363667 loss)
I1023 15:34:27.358496  4985 solver.cpp:218] Iteration 8600 (4.65734 iter/s, 21.4715s/100 iters), loss = 0.218265
I1023 15:34:27.358526  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218265 (* 1 = 0.218265 loss)
I1023 15:34:27.358532  4985 sgd_solver.cpp:105] Iteration 8600, lr = 0.01
I1023 15:34:46.318841  4985 solver.cpp:218] Iteration 8700 (5.27419 iter/s, 18.9603s/100 iters), loss = 0.503333
I1023 15:34:46.319016  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.503334 (* 1 = 0.503334 loss)
I1023 15:34:46.319026  4985 sgd_solver.cpp:105] Iteration 8700, lr = 0.01
I1023 15:35:05.091668  4985 solver.cpp:330] Iteration 8800, Testing net (#0)
I1023 15:35:07.036898  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:35:07.600368  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.822266
I1023 15:35:07.600425  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.826294 (* 1 = 0.826294 loss)
I1023 15:35:07.790990  4985 solver.cpp:218] Iteration 8800 (4.65724 iter/s, 21.4719s/100 iters), loss = 0.0181605
I1023 15:35:07.791026  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181609 (* 1 = 0.0181609 loss)
I1023 15:35:07.791033  4985 sgd_solver.cpp:105] Iteration 8800, lr = 0.01
I1023 15:35:20.710443  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:35:26.758487  4985 solver.cpp:218] Iteration 8900 (5.2722 iter/s, 18.9674s/100 iters), loss = 0.0492847
I1023 15:35:26.758520  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0492851 (* 1 = 0.0492851 loss)
I1023 15:35:26.758527  4985 sgd_solver.cpp:105] Iteration 8900, lr = 0.01
I1023 15:35:45.528307  4985 solver.cpp:330] Iteration 9000, Testing net (#0)
I1023 15:35:47.471709  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:35:48.035467  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.876953
I1023 15:35:48.035533  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.525941 (* 1 = 0.525941 loss)
I1023 15:35:48.225806  4985 solver.cpp:218] Iteration 9000 (4.65826 iter/s, 21.4672s/100 iters), loss = 0.0457762
I1023 15:35:48.225837  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0457766 (* 1 = 0.0457766 loss)
I1023 15:35:48.225844  4985 sgd_solver.cpp:105] Iteration 9000, lr = 0.01
I1023 15:36:07.181681  4985 solver.cpp:218] Iteration 9100 (5.27543 iter/s, 18.9558s/100 iters), loss = 0.0969561
I1023 15:36:07.181830  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0969564 (* 1 = 0.0969564 loss)
I1023 15:36:07.181839  4985 sgd_solver.cpp:105] Iteration 9100, lr = 0.01
I1023 15:36:25.950906  4985 solver.cpp:330] Iteration 9200, Testing net (#0)
I1023 15:36:27.893199  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:36:28.459177  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.884766
I1023 15:36:28.459247  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366282 (* 1 = 0.366282 loss)
I1023 15:36:28.650259  4985 solver.cpp:218] Iteration 9200 (4.65801 iter/s, 21.4684s/100 iters), loss = 0.123408
I1023 15:36:28.650292  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123409 (* 1 = 0.123409 loss)
I1023 15:36:28.650300  4985 sgd_solver.cpp:105] Iteration 9200, lr = 0.01
I1023 15:36:30.384683  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:36:47.613677  4985 solver.cpp:218] Iteration 9300 (5.27333 iter/s, 18.9633s/100 iters), loss = 0.0983684
I1023 15:36:47.613824  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0983687 (* 1 = 0.0983687 loss)
I1023 15:36:47.613833  4985 sgd_solver.cpp:105] Iteration 9300, lr = 0.01
I1023 15:37:06.391715  4985 solver.cpp:330] Iteration 9400, Testing net (#0)
I1023 15:37:08.297724  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:37:08.899664  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9375
I1023 15:37:08.899735  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.20022 (* 1 = 0.20022 loss)
I1023 15:37:09.090387  4985 solver.cpp:218] Iteration 9400 (4.65625 iter/s, 21.4765s/100 iters), loss = 0.141
I1023 15:37:09.090420  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.141001 (* 1 = 0.141001 loss)
I1023 15:37:09.090425  4985 sgd_solver.cpp:105] Iteration 9400, lr = 0.01
I1023 15:37:28.052532  4985 solver.cpp:218] Iteration 9500 (5.27369 iter/s, 18.9621s/100 iters), loss = 0.10407
I1023 15:37:28.052675  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.104071 (* 1 = 0.104071 loss)
I1023 15:37:28.052683  4985 sgd_solver.cpp:105] Iteration 9500, lr = 0.01
I1023 15:37:37.567090  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:37:46.832617  4985 solver.cpp:330] Iteration 9600, Testing net (#0)
I1023 15:37:48.738222  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:37:49.340956  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.517578
I1023 15:37:49.341013  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.39228 (* 1 = 2.39228 loss)
I1023 15:37:49.531349  4985 solver.cpp:218] Iteration 9600 (4.65579 iter/s, 21.4786s/100 iters), loss = 0.0391386
I1023 15:37:49.531380  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0391389 (* 1 = 0.0391389 loss)
I1023 15:37:49.531388  4985 sgd_solver.cpp:105] Iteration 9600, lr = 0.01
I1023 15:38:08.490957  4985 solver.cpp:218] Iteration 9700 (5.27439 iter/s, 18.9595s/100 iters), loss = 0.0135889
I1023 15:38:08.491109  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0135892 (* 1 = 0.0135892 loss)
I1023 15:38:08.491119  4985 sgd_solver.cpp:105] Iteration 9700, lr = 0.01
I1023 15:38:27.264251  4985 solver.cpp:330] Iteration 9800, Testing net (#0)
I1023 15:38:29.169242  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:38:29.772634  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 15:38:29.772692  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0826217 (* 1 = 0.0826217 loss)
I1023 15:38:29.963057  4985 solver.cpp:218] Iteration 9800 (4.65725 iter/s, 21.4719s/100 iters), loss = 0.0253816
I1023 15:38:29.963090  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0253818 (* 1 = 0.0253818 loss)
I1023 15:38:29.963098  4985 sgd_solver.cpp:105] Iteration 9800, lr = 0.01
I1023 15:38:47.432157  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:38:48.928035  4985 solver.cpp:218] Iteration 9900 (5.2729 iter/s, 18.9649s/100 iters), loss = 0.000847317
I1023 15:38:48.928076  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000847506 (* 1 = 0.000847506 loss)
I1023 15:38:48.928084  4985 sgd_solver.cpp:105] Iteration 9900, lr = 0.01
I1023 15:39:07.702309  4985 solver.cpp:330] Iteration 10000, Testing net (#0)
I1023 15:39:09.605475  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:39:10.210253  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.792969
I1023 15:39:10.210314  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.22676 (* 1 = 1.22676 loss)
I1023 15:39:10.401015  4985 solver.cpp:218] Iteration 10000 (4.65704 iter/s, 21.4729s/100 iters), loss = 0.217595
I1023 15:39:10.401047  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217595 (* 1 = 0.217595 loss)
I1023 15:39:10.401053  4985 sgd_solver.cpp:46] MultiStep Status: Iteration 10000, step = 1
I1023 15:39:10.401057  4985 sgd_solver.cpp:105] Iteration 10000, lr = 0.001
I1023 15:39:29.362716  4985 solver.cpp:218] Iteration 10100 (5.27381 iter/s, 18.9616s/100 iters), loss = 0.00791181
I1023 15:39:29.362857  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00791209 (* 1 = 0.00791209 loss)
I1023 15:39:29.362866  4985 sgd_solver.cpp:105] Iteration 10100, lr = 0.001
I1023 15:39:48.137459  4985 solver.cpp:330] Iteration 10200, Testing net (#0)
I1023 15:39:50.004657  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:39:50.646188  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.863281
I1023 15:39:50.646244  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.406596 (* 1 = 0.406596 loss)
I1023 15:39:50.836571  4985 solver.cpp:218] Iteration 10200 (4.65687 iter/s, 21.4737s/100 iters), loss = 0.0221326
I1023 15:39:50.836602  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0221329 (* 1 = 0.0221329 loss)
I1023 15:39:50.836609  4985 sgd_solver.cpp:105] Iteration 10200, lr = 0.001
I1023 15:39:57.121105  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:40:09.794605  4985 solver.cpp:218] Iteration 10300 (5.27483 iter/s, 18.958s/100 iters), loss = 0.00515554
I1023 15:40:09.794783  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00515588 (* 1 = 0.00515588 loss)
I1023 15:40:09.794793  4985 sgd_solver.cpp:105] Iteration 10300, lr = 0.001
I1023 15:40:28.564292  4985 solver.cpp:330] Iteration 10400, Testing net (#0)
I1023 15:40:30.430789  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:40:31.073434  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.914062
I1023 15:40:31.073488  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.221882 (* 1 = 0.221882 loss)
I1023 15:40:31.264196  4985 solver.cpp:218] Iteration 10400 (4.6578 iter/s, 21.4694s/100 iters), loss = 0.0120491
I1023 15:40:31.264231  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0120494 (* 1 = 0.0120494 loss)
I1023 15:40:31.264241  4985 sgd_solver.cpp:105] Iteration 10400, lr = 0.001
I1023 15:40:50.225996  4985 solver.cpp:218] Iteration 10500 (5.27378 iter/s, 18.9617s/100 iters), loss = 0.00589472
I1023 15:40:50.226142  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00589513 (* 1 = 0.00589513 loss)
I1023 15:40:50.226150  4985 sgd_solver.cpp:105] Iteration 10500, lr = 0.001
I1023 15:41:04.290132  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:41:09.010594  4985 solver.cpp:330] Iteration 10600, Testing net (#0)
I1023 15:41:10.876397  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:41:11.519512  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.931641
I1023 15:41:11.519546  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.183274 (* 1 = 0.183274 loss)
I1023 15:41:11.710398  4985 solver.cpp:218] Iteration 10600 (4.65458 iter/s, 21.4842s/100 iters), loss = 0.0164606
I1023 15:41:11.710430  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.016461 (* 1 = 0.016461 loss)
I1023 15:41:11.710438  4985 sgd_solver.cpp:105] Iteration 10600, lr = 0.001
I1023 15:41:30.669739  4985 solver.cpp:218] Iteration 10700 (5.27447 iter/s, 18.9593s/100 iters), loss = 0.00335827
I1023 15:41:30.669874  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00335867 (* 1 = 0.00335867 loss)
I1023 15:41:30.669885  4985 sgd_solver.cpp:105] Iteration 10700, lr = 0.001
I1023 15:41:49.445868  4985 solver.cpp:330] Iteration 10800, Testing net (#0)
I1023 15:41:51.311044  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:41:51.954879  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.949219
I1023 15:41:51.954946  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.140371 (* 1 = 0.140371 loss)
I1023 15:41:52.145198  4985 solver.cpp:218] Iteration 10800 (4.65652 iter/s, 21.4753s/100 iters), loss = 0.00517597
I1023 15:41:52.145231  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00517635 (* 1 = 0.00517635 loss)
I1023 15:41:52.145238  4985 sgd_solver.cpp:105] Iteration 10800, lr = 0.001
I1023 15:42:11.106434  4985 solver.cpp:218] Iteration 10900 (5.27394 iter/s, 18.9612s/100 iters), loss = 0.00614387
I1023 15:42:11.106590  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0061443 (* 1 = 0.0061443 loss)
I1023 15:42:11.106600  4985 sgd_solver.cpp:105] Iteration 10900, lr = 0.001
I1023 15:42:13.979276  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:42:29.882220  4985 solver.cpp:330] Iteration 11000, Testing net (#0)
I1023 15:42:31.710458  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:42:32.390322  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.951172
I1023 15:42:32.390388  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.122941 (* 1 = 0.122941 loss)
I1023 15:42:32.581022  4985 solver.cpp:218] Iteration 11000 (4.65671 iter/s, 21.4744s/100 iters), loss = 0.22114
I1023 15:42:32.581053  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221141 (* 1 = 0.221141 loss)
I1023 15:42:32.581059  4985 sgd_solver.cpp:105] Iteration 11000, lr = 0.001
I1023 15:42:51.542672  4985 solver.cpp:218] Iteration 11100 (5.27382 iter/s, 18.9616s/100 iters), loss = 0.0460842
I1023 15:42:51.542814  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0460846 (* 1 = 0.0460846 loss)
I1023 15:42:51.542822  4985 sgd_solver.cpp:105] Iteration 11100, lr = 0.001
I1023 15:43:10.315593  4985 solver.cpp:330] Iteration 11200, Testing net (#0)
I1023 15:43:12.142938  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:43:12.823524  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.958984
I1023 15:43:12.823581  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.109968 (* 1 = 0.109968 loss)
I1023 15:43:13.014276  4985 solver.cpp:218] Iteration 11200 (4.65735 iter/s, 21.4714s/100 iters), loss = 0.00263844
I1023 15:43:13.014310  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00263884 (* 1 = 0.00263884 loss)
I1023 15:43:13.014317  4985 sgd_solver.cpp:105] Iteration 11200, lr = 0.001
I1023 15:43:23.850538  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:43:31.985715  4985 solver.cpp:218] Iteration 11300 (5.2711 iter/s, 18.9714s/100 iters), loss = 0.279315
I1023 15:43:31.985749  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279315 (* 1 = 0.279315 loss)
I1023 15:43:31.985754  4985 sgd_solver.cpp:105] Iteration 11300, lr = 0.001
I1023 15:43:50.755745  4985 solver.cpp:330] Iteration 11400, Testing net (#0)
I1023 15:43:52.581290  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:43:53.262307  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.955078
I1023 15:43:53.262370  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.110795 (* 1 = 0.110795 loss)
I1023 15:43:53.452980  4985 solver.cpp:218] Iteration 11400 (4.65827 iter/s, 21.4672s/100 iters), loss = 0.0150178
I1023 15:43:53.453024  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0150182 (* 1 = 0.0150182 loss)
I1023 15:43:53.453032  4985 sgd_solver.cpp:105] Iteration 11400, lr = 0.001
I1023 15:44:12.409590  4985 solver.cpp:218] Iteration 11500 (5.27523 iter/s, 18.9565s/100 iters), loss = 0.070279
I1023 15:44:12.409732  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0702795 (* 1 = 0.0702795 loss)
I1023 15:44:12.409741  4985 sgd_solver.cpp:105] Iteration 11500, lr = 0.001
I1023 15:44:31.011317  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:44:31.179544  4985 solver.cpp:330] Iteration 11600, Testing net (#0)
I1023 15:44:33.005234  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:44:33.687242  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.960938
I1023 15:44:33.687304  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.106365 (* 1 = 0.106365 loss)
I1023 15:44:33.877627  4985 solver.cpp:218] Iteration 11600 (4.65813 iter/s, 21.4678s/100 iters), loss = 0.00464975
I1023 15:44:33.877658  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00465019 (* 1 = 0.00465019 loss)
I1023 15:44:33.877665  4985 sgd_solver.cpp:105] Iteration 11600, lr = 0.001
I1023 15:44:52.842293  4985 solver.cpp:218] Iteration 11700 (5.27299 iter/s, 18.9646s/100 iters), loss = 0.0437903
I1023 15:44:52.842438  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0437908 (* 1 = 0.0437908 loss)
I1023 15:44:52.842447  4985 sgd_solver.cpp:105] Iteration 11700, lr = 0.001
I1023 15:45:11.621045  4985 solver.cpp:330] Iteration 11800, Testing net (#0)
I1023 15:45:13.409082  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:45:14.127851  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 15:45:14.127914  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0916736 (* 1 = 0.0916736 loss)
I1023 15:45:14.318269  4985 solver.cpp:218] Iteration 11800 (4.65641 iter/s, 21.4758s/100 iters), loss = 0.00305748
I1023 15:45:14.318300  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00305796 (* 1 = 0.00305796 loss)
I1023 15:45:14.318306  4985 sgd_solver.cpp:105] Iteration 11800, lr = 0.001
I1023 15:45:33.282775  4985 solver.cpp:218] Iteration 11900 (5.27303 iter/s, 18.9644s/100 iters), loss = 0.117396
I1023 15:45:33.282948  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.117396 (* 1 = 0.117396 loss)
I1023 15:45:33.282958  4985 sgd_solver.cpp:105] Iteration 11900, lr = 0.001
I1023 15:45:40.709159  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:45:52.063364  4985 solver.cpp:330] Iteration 12000, Testing net (#0)
I1023 15:45:53.850445  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:45:54.571238  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 15:45:54.571295  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0890314 (* 1 = 0.0890314 loss)
I1023 15:45:54.761307  4985 solver.cpp:218] Iteration 12000 (4.65586 iter/s, 21.4783s/100 iters), loss = 0.0364705
I1023 15:45:54.761338  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.036471 (* 1 = 0.036471 loss)
I1023 15:45:54.761345  4985 sgd_solver.cpp:105] Iteration 12000, lr = 0.001
I1023 15:46:13.721887  4985 solver.cpp:218] Iteration 12100 (5.27412 iter/s, 18.9605s/100 iters), loss = 0.0260939
I1023 15:46:13.722028  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0260943 (* 1 = 0.0260943 loss)
I1023 15:46:13.722038  4985 sgd_solver.cpp:105] Iteration 12100, lr = 0.001
I1023 15:46:32.495460  4985 solver.cpp:330] Iteration 12200, Testing net (#0)
I1023 15:46:34.281954  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:46:35.003353  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 15:46:35.003418  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0794242 (* 1 = 0.0794242 loss)
I1023 15:46:35.193619  4985 solver.cpp:218] Iteration 12200 (4.65733 iter/s, 21.4715s/100 iters), loss = 0.00755078
I1023 15:46:35.193650  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00755126 (* 1 = 0.00755126 loss)
I1023 15:46:35.193657  4985 sgd_solver.cpp:105] Iteration 12200, lr = 0.001
I1023 15:46:50.390524  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:46:54.159606  4985 solver.cpp:218] Iteration 12300 (5.27262 iter/s, 18.9659s/100 iters), loss = 0.00812968
I1023 15:46:54.159638  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00813017 (* 1 = 0.00813017 loss)
I1023 15:46:54.159644  4985 sgd_solver.cpp:105] Iteration 12300, lr = 0.001
I1023 15:47:12.933779  4985 solver.cpp:330] Iteration 12400, Testing net (#0)
I1023 15:47:14.720322  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:47:15.442064  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 15:47:15.442126  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0913894 (* 1 = 0.0913894 loss)
I1023 15:47:15.633117  4985 solver.cpp:218] Iteration 12400 (4.65692 iter/s, 21.4734s/100 iters), loss = 0.00462317
I1023 15:47:15.633149  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0046237 (* 1 = 0.0046237 loss)
I1023 15:47:15.633155  4985 sgd_solver.cpp:105] Iteration 12400, lr = 0.001
I1023 15:47:34.594683  4985 solver.cpp:218] Iteration 12500 (5.27385 iter/s, 18.9615s/100 iters), loss = 0.0266436
I1023 15:47:34.594844  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0266442 (* 1 = 0.0266442 loss)
I1023 15:47:34.594854  4985 sgd_solver.cpp:105] Iteration 12500, lr = 0.001
I1023 15:47:53.368993  4985 solver.cpp:330] Iteration 12600, Testing net (#0)
I1023 15:47:55.118667  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:47:55.876638  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 15:47:55.876708  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0901256 (* 1 = 0.0901256 loss)
I1023 15:47:56.067472  4985 solver.cpp:218] Iteration 12600 (4.6571 iter/s, 21.4726s/100 iters), loss = 0.0641193
I1023 15:47:56.067503  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0641199 (* 1 = 0.0641199 loss)
I1023 15:47:56.067510  4985 sgd_solver.cpp:105] Iteration 12600, lr = 0.001
I1023 15:48:00.266162  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:48:15.026151  4985 solver.cpp:218] Iteration 12700 (5.27465 iter/s, 18.9586s/100 iters), loss = 0.000754199
I1023 15:48:15.026289  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000754736 (* 1 = 0.000754736 loss)
I1023 15:48:15.026298  4985 sgd_solver.cpp:105] Iteration 12700, lr = 0.001
I1023 15:48:33.794612  4985 solver.cpp:330] Iteration 12800, Testing net (#0)
I1023 15:48:35.543867  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:48:36.302574  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 15:48:36.302640  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0860581 (* 1 = 0.0860581 loss)
I1023 15:48:36.493474  4985 solver.cpp:218] Iteration 12800 (4.65828 iter/s, 21.4671s/100 iters), loss = 0.0434075
I1023 15:48:36.493507  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.043408 (* 1 = 0.043408 loss)
I1023 15:48:36.493515  4985 sgd_solver.cpp:105] Iteration 12800, lr = 0.001
I1023 15:48:55.478874  4985 solver.cpp:218] Iteration 12900 (5.26723 iter/s, 18.9853s/100 iters), loss = 0.00950135
I1023 15:48:55.479023  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00950186 (* 1 = 0.00950186 loss)
I1023 15:48:55.479032  4985 sgd_solver.cpp:105] Iteration 12900, lr = 0.001
I1023 15:49:07.470854  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:49:14.288446  4985 solver.cpp:330] Iteration 13000, Testing net (#0)
I1023 15:49:16.038228  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:49:16.799471  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 15:49:16.799535  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0846952 (* 1 = 0.0846952 loss)
I1023 15:49:16.990416  4985 solver.cpp:218] Iteration 13000 (4.64871 iter/s, 21.5113s/100 iters), loss = 0.0122658
I1023 15:49:16.990447  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122664 (* 1 = 0.0122664 loss)
I1023 15:49:16.990453  4985 sgd_solver.cpp:105] Iteration 13000, lr = 0.001
I1023 15:49:35.971385  4985 solver.cpp:218] Iteration 13100 (5.26846 iter/s, 18.9809s/100 iters), loss = 0.0141872
I1023 15:49:35.971529  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141878 (* 1 = 0.0141878 loss)
I1023 15:49:35.971539  4985 sgd_solver.cpp:105] Iteration 13100, lr = 0.001
I1023 15:49:54.772203  4985 solver.cpp:330] Iteration 13200, Testing net (#0)
I1023 15:49:56.521210  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:49:57.283298  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1023 15:49:57.283365  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0883098 (* 1 = 0.0883098 loss)
I1023 15:49:57.473866  4985 solver.cpp:218] Iteration 13200 (4.65067 iter/s, 21.5023s/100 iters), loss = 0.00460963
I1023 15:49:57.473901  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00461026 (* 1 = 0.00461026 loss)
I1023 15:49:57.473908  4985 sgd_solver.cpp:105] Iteration 13200, lr = 0.001
I1023 15:50:16.457686  4985 solver.cpp:218] Iteration 13300 (5.26767 iter/s, 18.9837s/100 iters), loss = 0.00179882
I1023 15:50:16.457799  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00179949 (* 1 = 0.00179949 loss)
I1023 15:50:16.457819  4985 sgd_solver.cpp:105] Iteration 13300, lr = 0.001
I1023 15:50:17.245211  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:50:35.256678  4985 solver.cpp:330] Iteration 13400, Testing net (#0)
I1023 15:50:36.968482  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:50:37.767747  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 15:50:37.767809  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0999257 (* 1 = 0.0999257 loss)
I1023 15:50:37.958307  4985 solver.cpp:218] Iteration 13400 (4.65106 iter/s, 21.5005s/100 iters), loss = 0.0155254
I1023 15:50:37.958338  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155261 (* 1 = 0.0155261 loss)
I1023 15:50:37.958345  4985 sgd_solver.cpp:105] Iteration 13400, lr = 0.001
I1023 15:50:56.942286  4985 solver.cpp:218] Iteration 13500 (5.26762 iter/s, 18.9839s/100 iters), loss = 0.00548736
I1023 15:50:56.942430  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00548802 (* 1 = 0.00548802 loss)
I1023 15:50:56.942440  4985 sgd_solver.cpp:105] Iteration 13500, lr = 0.001
I1023 15:51:15.739059  4985 solver.cpp:330] Iteration 13600, Testing net (#0)
I1023 15:51:17.450881  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:51:18.250246  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 15:51:18.250309  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.101815 (* 1 = 0.101815 loss)
I1023 15:51:18.441289  4985 solver.cpp:218] Iteration 13600 (4.65142 iter/s, 21.4988s/100 iters), loss = 0.00833818
I1023 15:51:18.441319  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00833883 (* 1 = 0.00833883 loss)
I1023 15:51:18.441326  4985 sgd_solver.cpp:105] Iteration 13600, lr = 0.001
I1023 15:51:27.015614  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:51:37.437937  4985 solver.cpp:218] Iteration 13700 (5.26411 iter/s, 18.9966s/100 iters), loss = 0.00547115
I1023 15:51:37.437968  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0054718 (* 1 = 0.0054718 loss)
I1023 15:51:37.437974  4985 sgd_solver.cpp:105] Iteration 13700, lr = 0.001
I1023 15:51:56.227881  4985 solver.cpp:330] Iteration 13800, Testing net (#0)
I1023 15:51:57.937741  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:51:58.738411  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 15:51:58.738476  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0986659 (* 1 = 0.0986659 loss)
I1023 15:51:58.928916  4985 solver.cpp:218] Iteration 13800 (4.65313 iter/s, 21.4909s/100 iters), loss = 0.0207029
I1023 15:51:58.928948  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0207036 (* 1 = 0.0207036 loss)
I1023 15:51:58.928954  4985 sgd_solver.cpp:105] Iteration 13800, lr = 0.001
I1023 15:52:17.910130  4985 solver.cpp:218] Iteration 13900 (5.26839 iter/s, 18.9811s/100 iters), loss = 0.00693367
I1023 15:52:17.910162  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00693436 (* 1 = 0.00693436 loss)
I1023 15:52:17.910169  4985 sgd_solver.cpp:105] Iteration 13900, lr = 0.001
I1023 15:52:34.447999  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:52:36.705895  4985 solver.cpp:330] Iteration 14000, Testing net (#0)
I1023 15:52:38.415891  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:52:39.216603  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 15:52:39.216671  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.106408 (* 1 = 0.106408 loss)
I1023 15:52:39.407927  4985 solver.cpp:218] Iteration 14000 (4.65166 iter/s, 21.4977s/100 iters), loss = 0.0222427
I1023 15:52:39.407959  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0222434 (* 1 = 0.0222434 loss)
I1023 15:52:39.407966  4985 sgd_solver.cpp:105] Iteration 14000, lr = 0.001
I1023 15:52:58.392087  4985 solver.cpp:218] Iteration 14100 (5.26757 iter/s, 18.9841s/100 iters), loss = 0.125915
I1023 15:52:58.392118  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.125916 (* 1 = 0.125916 loss)
I1023 15:52:58.392125  4985 sgd_solver.cpp:105] Iteration 14100, lr = 0.001
I1023 15:53:17.192895  4985 solver.cpp:330] Iteration 14200, Testing net (#0)
I1023 15:53:18.866983  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:53:19.703764  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.962891
I1023 15:53:19.703830  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.097197 (* 1 = 0.097197 loss)
I1023 15:53:19.894659  4985 solver.cpp:218] Iteration 14200 (4.65062 iter/s, 21.5025s/100 iters), loss = 0.00365905
I1023 15:53:19.894688  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00365974 (* 1 = 0.00365974 loss)
I1023 15:53:19.894695  4985 sgd_solver.cpp:105] Iteration 14200, lr = 0.001
I1023 15:53:38.882957  4985 solver.cpp:218] Iteration 14300 (5.26642 iter/s, 18.9882s/100 iters), loss = 0.00755274
I1023 15:53:38.882989  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00755342 (* 1 = 0.00755342 loss)
I1023 15:53:38.882995  4985 sgd_solver.cpp:105] Iteration 14300, lr = 0.001
I1023 15:53:44.227463  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:53:57.685886  4985 solver.cpp:330] Iteration 14400, Testing net (#0)
I1023 15:53:59.358849  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:54:00.198055  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1023 15:54:00.198101  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.091279 (* 1 = 0.091279 loss)
I1023 15:54:00.388475  4985 solver.cpp:218] Iteration 14400 (4.64999 iter/s, 21.5054s/100 iters), loss = 0.0125107
I1023 15:54:00.388507  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125115 (* 1 = 0.0125115 loss)
I1023 15:54:00.388514  4985 sgd_solver.cpp:105] Iteration 14400, lr = 0.001
I1023 15:54:19.372407  4985 solver.cpp:218] Iteration 14500 (5.26763 iter/s, 18.9839s/100 iters), loss = 0.00328055
I1023 15:54:19.372439  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00328129 (* 1 = 0.00328129 loss)
I1023 15:54:19.372445  4985 sgd_solver.cpp:105] Iteration 14500, lr = 0.001
I1023 15:54:38.165500  4985 solver.cpp:330] Iteration 14600, Testing net (#0)
I1023 15:54:39.837237  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:54:40.675469  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1023 15:54:40.675534  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0885759 (* 1 = 0.0885759 loss)
I1023 15:54:40.866235  4985 solver.cpp:218] Iteration 14600 (4.65252 iter/s, 21.4937s/100 iters), loss = 0.00746773
I1023 15:54:40.866268  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00746847 (* 1 = 0.00746847 loss)
I1023 15:54:40.866276  4985 sgd_solver.cpp:105] Iteration 14600, lr = 0.001
I1023 15:54:53.994570  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:54:59.859772  4985 solver.cpp:218] Iteration 14700 (5.26497 iter/s, 18.9935s/100 iters), loss = 0.0178241
I1023 15:54:59.859807  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0178248 (* 1 = 0.0178248 loss)
I1023 15:54:59.859813  4985 sgd_solver.cpp:105] Iteration 14700, lr = 0.001
I1023 15:55:18.654861  4985 solver.cpp:330] Iteration 14800, Testing net (#0)
I1023 15:55:20.325867  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:55:21.166199  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 15:55:21.166265  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0976742 (* 1 = 0.0976742 loss)
I1023 15:55:21.356901  4985 solver.cpp:218] Iteration 14800 (4.6518 iter/s, 21.497s/100 iters), loss = 0.0205674
I1023 15:55:21.356937  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0205681 (* 1 = 0.0205681 loss)
I1023 15:55:21.356945  4985 sgd_solver.cpp:105] Iteration 14800, lr = 0.001
I1023 15:55:40.342021  4985 solver.cpp:218] Iteration 14900 (5.2673 iter/s, 18.985s/100 iters), loss = 0.0106997
I1023 15:55:40.342054  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107005 (* 1 = 0.0107005 loss)
I1023 15:55:40.342061  4985 sgd_solver.cpp:105] Iteration 14900, lr = 0.001
I1023 15:55:59.140036  4985 solver.cpp:330] Iteration 15000, Testing net (#0)
I1023 15:56:00.775990  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:56:01.652529  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 15:56:01.652592  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0976509 (* 1 = 0.0976509 loss)
I1023 15:56:01.843088  4985 solver.cpp:218] Iteration 15000 (4.65095 iter/s, 21.501s/100 iters), loss = 0.00318224
I1023 15:56:01.843118  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00318297 (* 1 = 0.00318297 loss)
I1023 15:56:01.843125  4985 sgd_solver.cpp:105] Iteration 15000, lr = 0.001
I1023 15:56:03.769942  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:56:20.824964  4985 solver.cpp:218] Iteration 15100 (5.26821 iter/s, 18.9818s/100 iters), loss = 0.0229121
I1023 15:56:20.824995  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0229129 (* 1 = 0.0229129 loss)
I1023 15:56:20.825002  4985 sgd_solver.cpp:105] Iteration 15100, lr = 0.001
I1023 15:56:39.620275  4985 solver.cpp:330] Iteration 15200, Testing net (#0)
I1023 15:56:41.252893  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:56:42.130892  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.962891
I1023 15:56:42.130955  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0998719 (* 1 = 0.0998719 loss)
I1023 15:56:42.321785  4985 solver.cpp:218] Iteration 15200 (4.65187 iter/s, 21.4967s/100 iters), loss = 0.00567838
I1023 15:56:42.321816  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00567913 (* 1 = 0.00567913 loss)
I1023 15:56:42.321822  4985 sgd_solver.cpp:105] Iteration 15200, lr = 0.001
I1023 15:57:01.309948  4985 solver.cpp:218] Iteration 15300 (5.26646 iter/s, 18.9881s/100 iters), loss = 0.0065718
I1023 15:57:01.309979  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00657253 (* 1 = 0.00657253 loss)
I1023 15:57:01.309985  4985 sgd_solver.cpp:105] Iteration 15300, lr = 0.001
I1023 15:57:11.211827  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:57:20.112129  4985 solver.cpp:330] Iteration 15400, Testing net (#0)
I1023 15:57:21.745007  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:57:22.623685  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 15:57:22.623751  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.117803 (* 1 = 0.117803 loss)
I1023 15:57:22.814322  4985 solver.cpp:218] Iteration 15400 (4.65023 iter/s, 21.5043s/100 iters), loss = 0.00413031
I1023 15:57:22.814352  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00413103 (* 1 = 0.00413103 loss)
I1023 15:57:22.814359  4985 sgd_solver.cpp:105] Iteration 15400, lr = 0.001
I1023 15:57:41.803175  4985 solver.cpp:218] Iteration 15500 (5.26627 iter/s, 18.9888s/100 iters), loss = 0.00207492
I1023 15:57:41.803318  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00207565 (* 1 = 0.00207565 loss)
I1023 15:57:41.803328  4985 sgd_solver.cpp:105] Iteration 15500, lr = 0.001
I1023 15:58:00.604307  4985 solver.cpp:330] Iteration 15600, Testing net (#0)
I1023 15:58:02.236301  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:58:03.115087  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.962891
I1023 15:58:03.115156  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.109768 (* 1 = 0.109768 loss)
I1023 15:58:03.305548  4985 solver.cpp:218] Iteration 15600 (4.65069 iter/s, 21.5022s/100 iters), loss = 0.000329804
I1023 15:58:03.305579  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000330526 (* 1 = 0.000330526 loss)
I1023 15:58:03.305586  4985 sgd_solver.cpp:105] Iteration 15600, lr = 0.001
I1023 15:58:20.984478  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:58:22.291316  4985 solver.cpp:218] Iteration 15700 (5.26713 iter/s, 18.9857s/100 iters), loss = 0.00359002
I1023 15:58:22.291350  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00359074 (* 1 = 0.00359074 loss)
I1023 15:58:22.291357  4985 sgd_solver.cpp:105] Iteration 15700, lr = 0.001
I1023 15:58:41.088002  4985 solver.cpp:330] Iteration 15800, Testing net (#0)
I1023 15:58:42.682641  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:58:43.598857  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 15:58:43.598924  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0940414 (* 1 = 0.0940414 loss)
I1023 15:58:43.789700  4985 solver.cpp:218] Iteration 15800 (4.65153 iter/s, 21.4983s/100 iters), loss = 0.00776392
I1023 15:58:43.789732  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00776463 (* 1 = 0.00776463 loss)
I1023 15:58:43.789739  4985 sgd_solver.cpp:105] Iteration 15800, lr = 0.001
I1023 15:59:02.780459  4985 solver.cpp:218] Iteration 15900 (5.26574 iter/s, 18.9907s/100 iters), loss = 0.00108874
I1023 15:59:02.780601  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108943 (* 1 = 0.00108943 loss)
I1023 15:59:02.780611  4985 sgd_solver.cpp:105] Iteration 15900, lr = 0.001
I1023 15:59:21.579872  4985 solver.cpp:330] Iteration 16000, Testing net (#0)
I1023 15:59:23.174429  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:59:24.090699  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 15:59:24.090766  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.101852 (* 1 = 0.101852 loss)
I1023 15:59:24.281924  4985 solver.cpp:218] Iteration 16000 (4.65089 iter/s, 21.5013s/100 iters), loss = 0.0408874
I1023 15:59:24.281955  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0408881 (* 1 = 0.0408881 loss)
I1023 15:59:24.281960  4985 sgd_solver.cpp:105] Iteration 16000, lr = 0.001
I1023 15:59:30.766969  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 15:59:43.269644  4985 solver.cpp:218] Iteration 16100 (5.26658 iter/s, 18.9876s/100 iters), loss = 0.000722729
I1023 15:59:43.269788  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000723398 (* 1 = 0.000723398 loss)
I1023 15:59:43.269798  4985 sgd_solver.cpp:105] Iteration 16100, lr = 0.001
I1023 16:00:02.071347  4985 solver.cpp:330] Iteration 16200, Testing net (#0)
I1023 16:00:03.663689  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:00:04.581548  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.962891
I1023 16:00:04.581621  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.114975 (* 1 = 0.114975 loss)
I1023 16:00:04.772387  4985 solver.cpp:218] Iteration 16200 (4.65061 iter/s, 21.5026s/100 iters), loss = 0.00713009
I1023 16:00:04.772421  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00713077 (* 1 = 0.00713077 loss)
I1023 16:00:04.772428  4985 sgd_solver.cpp:105] Iteration 16200, lr = 0.001
I1023 16:00:23.752468  4985 solver.cpp:218] Iteration 16300 (5.2687 iter/s, 18.98s/100 iters), loss = 0.0276082
I1023 16:00:23.752609  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0276089 (* 1 = 0.0276089 loss)
I1023 16:00:23.752619  4985 sgd_solver.cpp:105] Iteration 16300, lr = 0.001
I1023 16:00:38.018308  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:00:42.551487  4985 solver.cpp:330] Iteration 16400, Testing net (#0)
I1023 16:00:44.144130  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:00:45.061993  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:00:45.062057  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.110773 (* 1 = 0.110773 loss)
I1023 16:00:45.253219  4985 solver.cpp:218] Iteration 16400 (4.65104 iter/s, 21.5006s/100 iters), loss = 0.0332131
I1023 16:00:45.253250  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0332138 (* 1 = 0.0332138 loss)
I1023 16:00:45.253257  4985 sgd_solver.cpp:105] Iteration 16400, lr = 0.001
I1023 16:01:04.238332  4985 solver.cpp:218] Iteration 16500 (5.26731 iter/s, 18.985s/100 iters), loss = 0.0876946
I1023 16:01:04.238454  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0876953 (* 1 = 0.0876953 loss)
I1023 16:01:04.238462  4985 sgd_solver.cpp:105] Iteration 16500, lr = 0.001
I1023 16:01:23.038877  4985 solver.cpp:330] Iteration 16600, Testing net (#0)
I1023 16:01:24.594700  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:01:25.549779  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.958984
I1023 16:01:25.549835  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.133815 (* 1 = 0.133815 loss)
I1023 16:01:25.741027  4985 solver.cpp:218] Iteration 16600 (4.65062 iter/s, 21.5025s/100 iters), loss = 0.00202169
I1023 16:01:25.741057  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00202236 (* 1 = 0.00202236 loss)
I1023 16:01:25.741065  4985 sgd_solver.cpp:105] Iteration 16600, lr = 0.001
I1023 16:01:44.730533  4985 solver.cpp:218] Iteration 16700 (5.26609 iter/s, 18.9894s/100 iters), loss = 0.00978203
I1023 16:01:44.730644  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0097827 (* 1 = 0.0097827 loss)
I1023 16:01:44.730653  4985 sgd_solver.cpp:105] Iteration 16700, lr = 0.001
I1023 16:01:47.984696  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:02:03.533838  4985 solver.cpp:330] Iteration 16800, Testing net (#0)
I1023 16:02:05.088721  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:02:06.044383  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 16:02:06.044440  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.11081 (* 1 = 0.11081 loss)
I1023 16:02:06.234961  4985 solver.cpp:218] Iteration 16800 (4.65024 iter/s, 21.5043s/100 iters), loss = 0.00326976
I1023 16:02:06.234989  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00327049 (* 1 = 0.00327049 loss)
I1023 16:02:06.234995  4985 sgd_solver.cpp:105] Iteration 16800, lr = 0.001
I1023 16:02:25.218767  4985 solver.cpp:218] Iteration 16900 (5.26767 iter/s, 18.9837s/100 iters), loss = 0.00925742
I1023 16:02:25.218829  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00925815 (* 1 = 0.00925815 loss)
I1023 16:02:25.218837  4985 sgd_solver.cpp:105] Iteration 16900, lr = 0.001
I1023 16:02:44.019177  4985 solver.cpp:330] Iteration 17000, Testing net (#0)
I1023 16:02:45.572824  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:02:46.536819  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 16:02:46.536862  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.10131 (* 1 = 0.10131 loss)
I1023 16:02:46.727546  4985 solver.cpp:218] Iteration 17000 (4.64929 iter/s, 21.5087s/100 iters), loss = 0.00104209
I1023 16:02:46.727581  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00104281 (* 1 = 0.00104281 loss)
I1023 16:02:46.727587  4985 sgd_solver.cpp:105] Iteration 17000, lr = 0.001
I1023 16:02:57.768934  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:03:05.725102  4985 solver.cpp:218] Iteration 17100 (5.26386 iter/s, 18.9975s/100 iters), loss = 0.0400609
I1023 16:03:05.725133  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0400616 (* 1 = 0.0400616 loss)
I1023 16:03:05.725139  4985 sgd_solver.cpp:105] Iteration 17100, lr = 0.001
I1023 16:03:24.519824  4985 solver.cpp:330] Iteration 17200, Testing net (#0)
I1023 16:03:26.071795  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:03:27.030257  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 16:03:27.030314  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.094203 (* 1 = 0.094203 loss)
I1023 16:03:27.221065  4985 solver.cpp:218] Iteration 17200 (4.65205 iter/s, 21.4959s/100 iters), loss = 0.001662
I1023 16:03:27.221097  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00166273 (* 1 = 0.00166273 loss)
I1023 16:03:27.221104  4985 sgd_solver.cpp:105] Iteration 17200, lr = 0.001
I1023 16:03:46.209519  4985 solver.cpp:218] Iteration 17300 (5.26638 iter/s, 18.9884s/100 iters), loss = 0.00307254
I1023 16:03:46.209627  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00307324 (* 1 = 0.00307324 loss)
I1023 16:03:46.209647  4985 sgd_solver.cpp:105] Iteration 17300, lr = 0.001
I1023 16:04:05.011164  4985 solver.cpp:330] Iteration 17400, Testing net (#0)
I1023 16:04:06.527387  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:04:07.520761  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 16:04:07.520823  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0964156 (* 1 = 0.0964156 loss)
I1023 16:04:07.545665  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:04:07.711531  4985 solver.cpp:218] Iteration 17400 (4.65076 iter/s, 21.5019s/100 iters), loss = 0.188713
I1023 16:04:07.711565  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188714 (* 1 = 0.188714 loss)
I1023 16:04:07.711582  4985 sgd_solver.cpp:105] Iteration 17400, lr = 0.001
I1023 16:04:26.691772  4985 solver.cpp:218] Iteration 17500 (5.26866 iter/s, 18.9802s/100 iters), loss = 0.0838425
I1023 16:04:26.691876  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0838432 (* 1 = 0.0838432 loss)
I1023 16:04:26.691885  4985 sgd_solver.cpp:105] Iteration 17500, lr = 0.001
I1023 16:04:45.483944  4985 solver.cpp:330] Iteration 17600, Testing net (#0)
I1023 16:04:46.999843  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:04:47.994633  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 16:04:47.994699  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.10003 (* 1 = 0.10003 loss)
I1023 16:04:48.185485  4985 solver.cpp:218] Iteration 17600 (4.65255 iter/s, 21.4936s/100 iters), loss = 0.0157554
I1023 16:04:48.185518  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0157561 (* 1 = 0.0157561 loss)
I1023 16:04:48.185524  4985 sgd_solver.cpp:105] Iteration 17600, lr = 0.001
I1023 16:05:07.173779  4985 solver.cpp:218] Iteration 17700 (5.26643 iter/s, 18.9882s/100 iters), loss = 0.0771292
I1023 16:05:07.173923  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0771299 (* 1 = 0.0771299 loss)
I1023 16:05:07.173931  4985 sgd_solver.cpp:105] Iteration 17700, lr = 0.001
I1023 16:05:14.797740  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:05:25.976189  4985 solver.cpp:330] Iteration 17800, Testing net (#0)
I1023 16:05:27.491590  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:05:28.487264  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 16:05:28.487324  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.102927 (* 1 = 0.102927 loss)
I1023 16:05:28.678097  4985 solver.cpp:218] Iteration 17800 (4.65027 iter/s, 21.5041s/100 iters), loss = 0.0335056
I1023 16:05:28.678130  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0335063 (* 1 = 0.0335063 loss)
I1023 16:05:28.678138  4985 sgd_solver.cpp:105] Iteration 17800, lr = 0.001
I1023 16:05:47.665513  4985 solver.cpp:218] Iteration 17900 (5.26667 iter/s, 18.9873s/100 iters), loss = 0.0536706
I1023 16:05:47.665663  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0536713 (* 1 = 0.0536713 loss)
I1023 16:05:47.665671  4985 sgd_solver.cpp:105] Iteration 17900, lr = 0.001
I1023 16:06:06.468538  4985 solver.cpp:330] Iteration 18000, Testing net (#0)
I1023 16:06:07.982923  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:06:08.979496  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 16:06:08.979562  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.110522 (* 1 = 0.110522 loss)
I1023 16:06:09.170018  4985 solver.cpp:218] Iteration 18000 (4.65023 iter/s, 21.5043s/100 iters), loss = 0.017827
I1023 16:06:09.170050  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0178276 (* 1 = 0.0178276 loss)
I1023 16:06:09.170056  4985 sgd_solver.cpp:105] Iteration 18000, lr = 0.001
I1023 16:06:24.762814  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:06:28.159581  4985 solver.cpp:218] Iteration 18100 (5.26607 iter/s, 18.9895s/100 iters), loss = 0.0103179
I1023 16:06:28.159613  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103186 (* 1 = 0.0103186 loss)
I1023 16:06:28.159621  4985 sgd_solver.cpp:105] Iteration 18100, lr = 0.001
I1023 16:06:46.952136  4985 solver.cpp:330] Iteration 18200, Testing net (#0)
I1023 16:06:48.430167  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:06:49.462860  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:06:49.462931  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.115026 (* 1 = 0.115026 loss)
I1023 16:06:49.653502  4985 solver.cpp:218] Iteration 18200 (4.6525 iter/s, 21.4938s/100 iters), loss = 0.00971449
I1023 16:06:49.653534  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00971522 (* 1 = 0.00971522 loss)
I1023 16:06:49.653542  4985 sgd_solver.cpp:105] Iteration 18200, lr = 0.001
I1023 16:07:08.640485  4985 solver.cpp:218] Iteration 18300 (5.26679 iter/s, 18.9869s/100 iters), loss = 0.0124691
I1023 16:07:08.640588  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124698 (* 1 = 0.0124698 loss)
I1023 16:07:08.640606  4985 sgd_solver.cpp:105] Iteration 18300, lr = 0.001
I1023 16:07:27.440940  4985 solver.cpp:330] Iteration 18400, Testing net (#0)
I1023 16:07:28.917613  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:07:29.951665  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.960938
I1023 16:07:29.951728  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.122057 (* 1 = 0.122057 loss)
I1023 16:07:30.142607  4985 solver.cpp:218] Iteration 18400 (4.65074 iter/s, 21.502s/100 iters), loss = 0.00325072
I1023 16:07:30.142642  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00325143 (* 1 = 0.00325143 loss)
I1023 16:07:30.142649  4985 sgd_solver.cpp:105] Iteration 18400, lr = 0.001
I1023 16:07:34.538053  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:07:49.130250  4985 solver.cpp:218] Iteration 18500 (5.26661 iter/s, 18.9876s/100 iters), loss = 0.0060522
I1023 16:07:49.130396  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00605294 (* 1 = 0.00605294 loss)
I1023 16:07:49.130406  4985 sgd_solver.cpp:105] Iteration 18500, lr = 0.001
I1023 16:08:07.932615  4985 solver.cpp:330] Iteration 18600, Testing net (#0)
I1023 16:08:09.407876  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:08:10.443038  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1023 16:08:10.443105  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0933095 (* 1 = 0.0933095 loss)
I1023 16:08:10.633849  4985 solver.cpp:218] Iteration 18600 (4.65043 iter/s, 21.5034s/100 iters), loss = 0.0180976
I1023 16:08:10.633888  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0180983 (* 1 = 0.0180983 loss)
I1023 16:08:10.633894  4985 sgd_solver.cpp:105] Iteration 18600, lr = 0.001
I1023 16:08:29.611414  4985 solver.cpp:218] Iteration 18700 (5.2694 iter/s, 18.9775s/100 iters), loss = 0.00374767
I1023 16:08:29.611541  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00374837 (* 1 = 0.00374837 loss)
I1023 16:08:29.611548  4985 sgd_solver.cpp:105] Iteration 18700, lr = 0.001
I1023 16:08:41.789386  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:08:48.413110  4985 solver.cpp:330] Iteration 18800, Testing net (#0)
I1023 16:08:49.888615  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:08:50.923848  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1023 16:08:50.923924  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0971434 (* 1 = 0.0971434 loss)
I1023 16:08:51.114827  4985 solver.cpp:218] Iteration 18800 (4.65046 iter/s, 21.5032s/100 iters), loss = 0.0285378
I1023 16:08:51.114863  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0285385 (* 1 = 0.0285385 loss)
I1023 16:08:51.114871  4985 sgd_solver.cpp:105] Iteration 18800, lr = 0.001
I1023 16:09:10.096530  4985 solver.cpp:218] Iteration 18900 (5.26825 iter/s, 18.9816s/100 iters), loss = 0.00110089
I1023 16:09:10.096698  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00110155 (* 1 = 0.00110155 loss)
I1023 16:09:10.096706  4985 sgd_solver.cpp:105] Iteration 18900, lr = 0.001
I1023 16:09:28.898272  4985 solver.cpp:330] Iteration 19000, Testing net (#0)
I1023 16:09:30.336077  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:09:31.409374  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:09:31.409435  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.106598 (* 1 = 0.106598 loss)
I1023 16:09:31.600340  4985 solver.cpp:218] Iteration 19000 (4.65039 iter/s, 21.5036s/100 iters), loss = 0.0164929
I1023 16:09:31.600373  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0164936 (* 1 = 0.0164936 loss)
I1023 16:09:31.600379  4985 sgd_solver.cpp:105] Iteration 19000, lr = 0.001
I1023 16:09:50.587643  4985 solver.cpp:218] Iteration 19100 (5.2667 iter/s, 18.9872s/100 iters), loss = 0.000649204
I1023 16:09:50.587805  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000649882 (* 1 = 0.000649882 loss)
I1023 16:09:50.587813  4985 sgd_solver.cpp:105] Iteration 19100, lr = 0.001
I1023 16:09:51.565274  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:10:09.392519  4985 solver.cpp:330] Iteration 19200, Testing net (#0)
I1023 16:10:10.829345  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:10:11.903223  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.958984
I1023 16:10:11.903265  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.120784 (* 1 = 0.120784 loss)
I1023 16:10:12.093668  4985 solver.cpp:218] Iteration 19200 (4.64991 iter/s, 21.5058s/100 iters), loss = 0.0014752
I1023 16:10:12.093699  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00147588 (* 1 = 0.00147588 loss)
I1023 16:10:12.093706  4985 sgd_solver.cpp:105] Iteration 19200, lr = 0.001
I1023 16:10:31.079563  4985 solver.cpp:218] Iteration 19300 (5.26709 iter/s, 18.9858s/100 iters), loss = 0.00770949
I1023 16:10:31.079671  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00771016 (* 1 = 0.00771016 loss)
I1023 16:10:31.079679  4985 sgd_solver.cpp:105] Iteration 19300, lr = 0.001
I1023 16:10:49.875597  4985 solver.cpp:330] Iteration 19400, Testing net (#0)
I1023 16:10:51.311673  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:10:52.386294  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 16:10:52.386361  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.113908 (* 1 = 0.113908 loss)
I1023 16:10:52.577071  4985 solver.cpp:218] Iteration 19400 (4.65174 iter/s, 21.4974s/100 iters), loss = 0.000314389
I1023 16:10:52.577105  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000315072 (* 1 = 0.000315072 loss)
I1023 16:10:52.577112  4985 sgd_solver.cpp:105] Iteration 19400, lr = 0.001
I1023 16:11:01.530145  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:11:11.573184  4985 solver.cpp:218] Iteration 19500 (5.26426 iter/s, 18.996s/100 iters), loss = 0.0437417
I1023 16:11:11.573215  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0437424 (* 1 = 0.0437424 loss)
I1023 16:11:11.573222  4985 sgd_solver.cpp:105] Iteration 19500, lr = 0.001
I1023 16:11:30.362519  4985 solver.cpp:330] Iteration 19600, Testing net (#0)
I1023 16:11:31.798425  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:11:32.873450  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:11:32.873502  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.106224 (* 1 = 0.106224 loss)
I1023 16:11:33.064522  4985 solver.cpp:218] Iteration 19600 (4.65306 iter/s, 21.4913s/100 iters), loss = 0.0193739
I1023 16:11:33.064555  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0193746 (* 1 = 0.0193746 loss)
I1023 16:11:33.064573  4985 sgd_solver.cpp:105] Iteration 19600, lr = 0.001
I1023 16:11:52.053560  4985 solver.cpp:218] Iteration 19700 (5.26622 iter/s, 18.989s/100 iters), loss = 0.00374325
I1023 16:11:52.053592  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0037439 (* 1 = 0.0037439 loss)
I1023 16:11:52.053609  4985 sgd_solver.cpp:105] Iteration 19700, lr = 0.001
I1023 16:12:08.788761  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:12:10.856626  4985 solver.cpp:330] Iteration 19800, Testing net (#0)
I1023 16:12:12.256242  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:12:13.368023  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 16:12:13.368085  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.112448 (* 1 = 0.112448 loss)
I1023 16:12:13.558750  4985 solver.cpp:218] Iteration 19800 (4.65006 iter/s, 21.5051s/100 iters), loss = 0.00158319
I1023 16:12:13.558796  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00158384 (* 1 = 0.00158384 loss)
I1023 16:12:13.558804  4985 sgd_solver.cpp:105] Iteration 19800, lr = 0.001
I1023 16:12:32.537264  4985 solver.cpp:218] Iteration 19900 (5.26914 iter/s, 18.9784s/100 iters), loss = 0.00161194
I1023 16:12:32.537295  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00161262 (* 1 = 0.00161262 loss)
I1023 16:12:32.537302  4985 sgd_solver.cpp:105] Iteration 19900, lr = 0.001
I1023 16:12:51.332805  4985 solver.cpp:330] Iteration 20000, Testing net (#0)
I1023 16:12:52.731163  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:12:53.843925  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:12:53.844004  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.106822 (* 1 = 0.106822 loss)
I1023 16:12:54.034886  4985 solver.cpp:218] Iteration 20000 (4.6517 iter/s, 21.4975s/100 iters), loss = 0.0253319
I1023 16:12:54.034917  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0253326 (* 1 = 0.0253326 loss)
I1023 16:12:54.034924  4985 sgd_solver.cpp:46] MultiStep Status: Iteration 20000, step = 2
I1023 16:12:54.034926  4985 sgd_solver.cpp:105] Iteration 20000, lr = 0.0001
I1023 16:13:13.021963  4985 solver.cpp:218] Iteration 20100 (5.26676 iter/s, 18.987s/100 iters), loss = 0.00129241
I1023 16:13:13.021998  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0012931 (* 1 = 0.0012931 loss)
I1023 16:13:13.022006  4985 sgd_solver.cpp:105] Iteration 20100, lr = 0.0001
I1023 16:13:18.558353  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:13:31.825696  4985 solver.cpp:330] Iteration 20200, Testing net (#0)
I1023 16:13:33.223397  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:13:34.336526  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:13:34.336585  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.110888 (* 1 = 0.110888 loss)
I1023 16:13:34.527443  4985 solver.cpp:218] Iteration 20200 (4.65 iter/s, 21.5054s/100 iters), loss = 0.00175392
I1023 16:13:34.527477  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00175465 (* 1 = 0.00175465 loss)
I1023 16:13:34.527483  4985 sgd_solver.cpp:105] Iteration 20200, lr = 0.0001
I1023 16:13:53.518273  4985 solver.cpp:218] Iteration 20300 (5.26572 iter/s, 18.9907s/100 iters), loss = 0.0108387
I1023 16:13:53.518306  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108395 (* 1 = 0.0108395 loss)
I1023 16:13:53.518312  4985 sgd_solver.cpp:105] Iteration 20300, lr = 0.0001
I1023 16:14:12.323529  4985 solver.cpp:330] Iteration 20400, Testing net (#0)
I1023 16:14:13.720052  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:14:14.834620  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 16:14:14.834676  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.105132 (* 1 = 0.105132 loss)
I1023 16:14:15.025504  4985 solver.cpp:218] Iteration 20400 (4.64962 iter/s, 21.5071s/100 iters), loss = 0.00290684
I1023 16:14:15.025534  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00290754 (* 1 = 0.00290754 loss)
I1023 16:14:15.025542  4985 sgd_solver.cpp:105] Iteration 20400, lr = 0.0001
I1023 16:14:28.347278  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:14:34.030983  4985 solver.cpp:218] Iteration 20500 (5.26166 iter/s, 19.0054s/100 iters), loss = 0.020931
I1023 16:14:34.031014  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0209317 (* 1 = 0.0209317 loss)
I1023 16:14:34.031021  4985 sgd_solver.cpp:105] Iteration 20500, lr = 0.0001
I1023 16:14:52.837369  4985 solver.cpp:330] Iteration 20600, Testing net (#0)
I1023 16:14:54.197355  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:14:55.347615  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 16:14:55.347679  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.107856 (* 1 = 0.107856 loss)
I1023 16:14:55.538452  4985 solver.cpp:218] Iteration 20600 (4.64957 iter/s, 21.5074s/100 iters), loss = 0.0382146
I1023 16:14:55.538485  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0382153 (* 1 = 0.0382153 loss)
I1023 16:14:55.538491  4985 sgd_solver.cpp:105] Iteration 20600, lr = 0.0001
I1023 16:15:14.524170  4985 solver.cpp:218] Iteration 20700 (5.26714 iter/s, 18.9856s/100 iters), loss = 0.00261858
I1023 16:15:14.524201  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00261927 (* 1 = 0.00261927 loss)
I1023 16:15:14.524219  4985 sgd_solver.cpp:105] Iteration 20700, lr = 0.0001
I1023 16:15:33.321985  4985 solver.cpp:330] Iteration 20800, Testing net (#0)
I1023 16:15:34.680733  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:15:35.832556  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 16:15:35.832615  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.112555 (* 1 = 0.112555 loss)
I1023 16:15:36.023509  4985 solver.cpp:218] Iteration 20800 (4.65132 iter/s, 21.4993s/100 iters), loss = 0.00245272
I1023 16:15:36.023540  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00245342 (* 1 = 0.00245342 loss)
I1023 16:15:36.023547  4985 sgd_solver.cpp:105] Iteration 20800, lr = 0.0001
I1023 16:15:38.326575  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:15:55.012259  4985 solver.cpp:218] Iteration 20900 (5.2663 iter/s, 18.9887s/100 iters), loss = 0.0398445
I1023 16:15:55.012291  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0398452 (* 1 = 0.0398452 loss)
I1023 16:15:55.012298  4985 sgd_solver.cpp:105] Iteration 20900, lr = 0.0001
I1023 16:16:13.810410  4985 solver.cpp:330] Iteration 21000, Testing net (#0)
I1023 16:16:15.168710  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:16:16.320631  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 16:16:16.320688  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.112893 (* 1 = 0.112893 loss)
I1023 16:16:16.511168  4985 solver.cpp:218] Iteration 21000 (4.65142 iter/s, 21.4988s/100 iters), loss = 0.00204959
I1023 16:16:16.511203  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00205031 (* 1 = 0.00205031 loss)
I1023 16:16:16.511210  4985 sgd_solver.cpp:105] Iteration 21000, lr = 0.0001
I1023 16:16:35.490018  4985 solver.cpp:218] Iteration 21100 (5.26905 iter/s, 18.9788s/100 iters), loss = 0.00150857
I1023 16:16:35.490049  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0015093 (* 1 = 0.0015093 loss)
I1023 16:16:35.490056  4985 sgd_solver.cpp:105] Iteration 21100, lr = 0.0001
I1023 16:16:45.581053  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:16:54.286777  4985 solver.cpp:330] Iteration 21200, Testing net (#0)
I1023 16:16:55.644402  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:16:56.797472  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 16:16:56.797536  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.112653 (* 1 = 0.112653 loss)
I1023 16:16:56.988325  4985 solver.cpp:218] Iteration 21200 (4.65155 iter/s, 21.4982s/100 iters), loss = 0.0194035
I1023 16:16:56.988361  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0194043 (* 1 = 0.0194043 loss)
I1023 16:16:56.988369  4985 sgd_solver.cpp:105] Iteration 21200, lr = 0.0001
I1023 16:17:15.976580  4985 solver.cpp:218] Iteration 21300 (5.26644 iter/s, 18.9882s/100 iters), loss = 0.00492295
I1023 16:17:15.976727  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00492369 (* 1 = 0.00492369 loss)
I1023 16:17:15.976737  4985 sgd_solver.cpp:105] Iteration 21300, lr = 0.0001
I1023 16:17:34.778448  4985 solver.cpp:330] Iteration 21400, Testing net (#0)
I1023 16:17:36.098986  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:17:37.289067  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 16:17:37.289134  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.114139 (* 1 = 0.114139 loss)
I1023 16:17:37.480118  4985 solver.cpp:218] Iteration 21400 (4.65044 iter/s, 21.5033s/100 iters), loss = 0.00327916
I1023 16:17:37.480149  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00327988 (* 1 = 0.00327988 loss)
I1023 16:17:37.480155  4985 sgd_solver.cpp:105] Iteration 21400, lr = 0.0001
I1023 16:17:55.356793  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:17:56.472589  4985 solver.cpp:218] Iteration 21500 (5.26527 iter/s, 18.9924s/100 iters), loss = 0.00494227
I1023 16:17:56.472620  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00494299 (* 1 = 0.00494299 loss)
I1023 16:17:56.472626  4985 sgd_solver.cpp:105] Iteration 21500, lr = 0.0001
I1023 16:18:15.272439  4985 solver.cpp:330] Iteration 21600, Testing net (#0)
I1023 16:18:16.592273  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:18:17.783527  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 16:18:17.783587  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.113323 (* 1 = 0.113323 loss)
I1023 16:18:17.974078  4985 solver.cpp:218] Iteration 21600 (4.65086 iter/s, 21.5014s/100 iters), loss = 0.0194849
I1023 16:18:17.974114  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0194856 (* 1 = 0.0194856 loss)
I1023 16:18:17.974123  4985 sgd_solver.cpp:105] Iteration 21600, lr = 0.0001
I1023 16:18:36.958039  4985 solver.cpp:218] Iteration 21700 (5.26763 iter/s, 18.9839s/100 iters), loss = 0.00242882
I1023 16:18:36.958149  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00242955 (* 1 = 0.00242955 loss)
I1023 16:18:36.958158  4985 sgd_solver.cpp:105] Iteration 21700, lr = 0.0001
I1023 16:18:55.754477  4985 solver.cpp:330] Iteration 21800, Testing net (#0)
I1023 16:18:57.073678  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:18:58.265143  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 16:18:58.265208  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.110552 (* 1 = 0.110552 loss)
I1023 16:18:58.456007  4985 solver.cpp:218] Iteration 21800 (4.65164 iter/s, 21.4978s/100 iters), loss = 0.00270398
I1023 16:18:58.456040  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00270471 (* 1 = 0.00270471 loss)
I1023 16:18:58.456048  4985 sgd_solver.cpp:105] Iteration 21800, lr = 0.0001
I1023 16:19:05.133709  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:19:17.443747  4985 solver.cpp:218] Iteration 21900 (5.26658 iter/s, 18.9877s/100 iters), loss = 0.0308694
I1023 16:19:17.443922  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0308701 (* 1 = 0.0308701 loss)
I1023 16:19:17.443931  4985 sgd_solver.cpp:105] Iteration 21900, lr = 0.0001
I1023 16:19:36.242910  4985 solver.cpp:330] Iteration 22000, Testing net (#0)
I1023 16:19:37.561154  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:19:38.753739  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:19:38.753798  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.114181 (* 1 = 0.114181 loss)
I1023 16:19:38.944486  4985 solver.cpp:218] Iteration 22000 (4.65105 iter/s, 21.5005s/100 iters), loss = 0.000729763
I1023 16:19:38.944516  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000730484 (* 1 = 0.000730484 loss)
I1023 16:19:38.944524  4985 sgd_solver.cpp:105] Iteration 22000, lr = 0.0001
I1023 16:19:57.930752  4985 solver.cpp:218] Iteration 22100 (5.26699 iter/s, 18.9862s/100 iters), loss = 0.0210983
I1023 16:19:57.930915  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.021099 (* 1 = 0.021099 loss)
I1023 16:19:57.930935  4985 sgd_solver.cpp:105] Iteration 22100, lr = 0.0001
I1023 16:20:12.578976  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:20:16.737488  4985 solver.cpp:330] Iteration 22200, Testing net (#0)
I1023 16:20:18.020167  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:20:19.249517  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.962891
I1023 16:20:19.249572  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.115482 (* 1 = 0.115482 loss)
I1023 16:20:19.440428  4985 solver.cpp:218] Iteration 22200 (4.64912 iter/s, 21.5095s/100 iters), loss = 0.0139648
I1023 16:20:19.440459  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139655 (* 1 = 0.0139655 loss)
I1023 16:20:19.440465  4985 sgd_solver.cpp:105] Iteration 22200, lr = 0.0001
I1023 16:20:38.414485  4985 solver.cpp:218] Iteration 22300 (5.27038 iter/s, 18.974s/100 iters), loss = 0.0265358
I1023 16:20:38.414630  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0265366 (* 1 = 0.0265366 loss)
I1023 16:20:38.414640  4985 sgd_solver.cpp:105] Iteration 22300, lr = 0.0001
I1023 16:20:57.207602  4985 solver.cpp:330] Iteration 22400, Testing net (#0)
I1023 16:20:58.488826  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:20:59.718739  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.960938
I1023 16:20:59.718797  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.118154 (* 1 = 0.118154 loss)
I1023 16:20:59.909796  4985 solver.cpp:218] Iteration 22400 (4.65222 iter/s, 21.4951s/100 iters), loss = 0.00126938
I1023 16:20:59.909831  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00127014 (* 1 = 0.00127014 loss)
I1023 16:20:59.909837  4985 sgd_solver.cpp:105] Iteration 22400, lr = 0.0001
I1023 16:21:18.895483  4985 solver.cpp:218] Iteration 22500 (5.26715 iter/s, 18.9856s/100 iters), loss = 0.00248265
I1023 16:21:18.895625  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00248342 (* 1 = 0.00248342 loss)
I1023 16:21:18.895635  4985 sgd_solver.cpp:105] Iteration 22500, lr = 0.0001
I1023 16:21:22.340158  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:21:37.696372  4985 solver.cpp:330] Iteration 22600, Testing net (#0)
I1023 16:21:38.976869  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:21:40.207741  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.960938
I1023 16:21:40.207806  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.114944 (* 1 = 0.114944 loss)
I1023 16:21:40.398459  4985 solver.cpp:218] Iteration 22600 (4.65056 iter/s, 21.5028s/100 iters), loss = 0.0243933
I1023 16:21:40.398492  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0243941 (* 1 = 0.0243941 loss)
I1023 16:21:40.398499  4985 sgd_solver.cpp:105] Iteration 22600, lr = 0.0001
I1023 16:21:59.388656  4985 solver.cpp:218] Iteration 22700 (5.2659 iter/s, 18.9901s/100 iters), loss = 0.0310504
I1023 16:21:59.388808  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0310512 (* 1 = 0.0310512 loss)
I1023 16:21:59.388819  4985 sgd_solver.cpp:105] Iteration 22700, lr = 0.0001
I1023 16:22:18.189561  4985 solver.cpp:330] Iteration 22800, Testing net (#0)
I1023 16:22:19.469260  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:22:20.700345  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.962891
I1023 16:22:20.700408  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.11549 (* 1 = 0.11549 loss)
I1023 16:22:20.890954  4985 solver.cpp:218] Iteration 22800 (4.65071 iter/s, 21.5021s/100 iters), loss = 0.00130381
I1023 16:22:20.890990  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0013046 (* 1 = 0.0013046 loss)
I1023 16:22:20.890997  4985 sgd_solver.cpp:105] Iteration 22800, lr = 0.0001
I1023 16:22:32.120627  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:22:39.882915  4985 solver.cpp:218] Iteration 22900 (5.26541 iter/s, 18.9919s/100 iters), loss = 0.00335396
I1023 16:22:39.882947  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00335478 (* 1 = 0.00335478 loss)
I1023 16:22:39.882953  4985 sgd_solver.cpp:105] Iteration 22900, lr = 0.0001
I1023 16:22:58.674492  4985 solver.cpp:330] Iteration 23000, Testing net (#0)
I1023 16:22:59.911133  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:23:01.186009  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.962891
I1023 16:23:01.186074  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.116049 (* 1 = 0.116049 loss)
I1023 16:23:01.376512  4985 solver.cpp:218] Iteration 23000 (4.65257 iter/s, 21.4935s/100 iters), loss = 0.0145229
I1023 16:23:01.376543  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145238 (* 1 = 0.0145238 loss)
I1023 16:23:01.376549  4985 sgd_solver.cpp:105] Iteration 23000, lr = 0.0001
I1023 16:23:20.363485  4985 solver.cpp:218] Iteration 23100 (5.26679 iter/s, 18.9869s/100 iters), loss = 0.00254418
I1023 16:23:20.363626  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.002545 (* 1 = 0.002545 loss)
I1023 16:23:20.363636  4985 sgd_solver.cpp:105] Iteration 23100, lr = 0.0001
I1023 16:23:39.163800  4985 solver.cpp:330] Iteration 23200, Testing net (#0)
I1023 16:23:40.398000  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:23:41.674412  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.962891
I1023 16:23:41.674479  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.11399 (* 1 = 0.11399 loss)
I1023 16:23:41.865514  4985 solver.cpp:218] Iteration 23200 (4.65076 iter/s, 21.5018s/100 iters), loss = 0.0164492
I1023 16:23:41.865546  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01645 (* 1 = 0.01645 loss)
I1023 16:23:41.865553  4985 sgd_solver.cpp:105] Iteration 23200, lr = 0.0001
I1023 16:23:41.892848  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:24:00.852459  4985 solver.cpp:218] Iteration 23300 (5.2668 iter/s, 18.9869s/100 iters), loss = 0.00532139
I1023 16:24:00.852607  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0053222 (* 1 = 0.0053222 loss)
I1023 16:24:00.852617  4985 sgd_solver.cpp:105] Iteration 23300, lr = 0.0001
I1023 16:24:19.653256  4985 solver.cpp:330] Iteration 23400, Testing net (#0)
I1023 16:24:20.888535  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:24:22.162653  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.960938
I1023 16:24:22.162724  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.118786 (* 1 = 0.118786 loss)
I1023 16:24:22.353466  4985 solver.cpp:218] Iteration 23400 (4.65099 iter/s, 21.5008s/100 iters), loss = 0.00306337
I1023 16:24:22.353495  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00306421 (* 1 = 0.00306421 loss)
I1023 16:24:22.353502  4985 sgd_solver.cpp:105] Iteration 23400, lr = 0.0001
I1023 16:24:41.335041  4985 solver.cpp:218] Iteration 23500 (5.26829 iter/s, 18.9815s/100 iters), loss = 0.0228323
I1023 16:24:41.335207  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0228332 (* 1 = 0.0228332 loss)
I1023 16:24:41.335230  4985 sgd_solver.cpp:105] Iteration 23500, lr = 0.0001
I1023 16:24:49.336405  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:25:00.131049  4985 solver.cpp:330] Iteration 23600, Testing net (#0)
I1023 16:25:01.371538  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:25:02.643194  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.960938
I1023 16:25:02.643260  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.120768 (* 1 = 0.120768 loss)
I1023 16:25:02.833834  4985 solver.cpp:218] Iteration 23600 (4.65147 iter/s, 21.4986s/100 iters), loss = 0.00143751
I1023 16:25:02.833866  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00143831 (* 1 = 0.00143831 loss)
I1023 16:25:02.833873  4985 sgd_solver.cpp:105] Iteration 23600, lr = 0.0001
I1023 16:25:21.821583  4985 solver.cpp:218] Iteration 23700 (5.26658 iter/s, 18.9877s/100 iters), loss = 0.000857373
I1023 16:25:21.821725  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000858173 (* 1 = 0.000858173 loss)
I1023 16:25:21.821734  4985 sgd_solver.cpp:105] Iteration 23700, lr = 0.0001
I1023 16:25:40.623291  4985 solver.cpp:330] Iteration 23800, Testing net (#0)
I1023 16:25:41.826412  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:25:43.132601  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.960938
I1023 16:25:43.132659  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.126302 (* 1 = 0.126302 loss)
I1023 16:25:43.323554  4985 solver.cpp:218] Iteration 23800 (4.65078 iter/s, 21.5018s/100 iters), loss = 0.0227702
I1023 16:25:43.323585  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.022771 (* 1 = 0.022771 loss)
I1023 16:25:43.323591  4985 sgd_solver.cpp:105] Iteration 23800, lr = 0.0001
I1023 16:25:59.111361  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:26:02.319908  4985 solver.cpp:218] Iteration 23900 (5.26419 iter/s, 18.9963s/100 iters), loss = 0.0723408
I1023 16:26:02.319941  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0723416 (* 1 = 0.0723416 loss)
I1023 16:26:02.319948  4985 sgd_solver.cpp:105] Iteration 23900, lr = 0.0001
I1023 16:26:21.117453  4985 solver.cpp:330] Iteration 24000, Testing net (#0)
I1023 16:26:22.319890  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:26:23.627424  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.960938
I1023 16:26:23.627485  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.117635 (* 1 = 0.117635 loss)
I1023 16:26:23.818114  4985 solver.cpp:218] Iteration 24000 (4.65157 iter/s, 21.4981s/100 iters), loss = 0.00191133
I1023 16:26:23.818145  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00191211 (* 1 = 0.00191211 loss)
I1023 16:26:23.818151  4985 sgd_solver.cpp:105] Iteration 24000, lr = 0.0001
I1023 16:26:42.799953  4985 solver.cpp:218] Iteration 24100 (5.26822 iter/s, 18.9818s/100 iters), loss = 0.00116638
I1023 16:26:42.800104  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00116716 (* 1 = 0.00116716 loss)
I1023 16:26:42.800113  4985 sgd_solver.cpp:105] Iteration 24100, lr = 0.0001
I1023 16:27:01.596782  4985 solver.cpp:330] Iteration 24200, Testing net (#0)
I1023 16:27:02.798341  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:27:04.106739  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:27:04.106797  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.115599 (* 1 = 0.115599 loss)
I1023 16:27:04.297333  4985 solver.cpp:218] Iteration 24200 (4.65177 iter/s, 21.4972s/100 iters), loss = 0.00222918
I1023 16:27:04.297365  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00222996 (* 1 = 0.00222996 loss)
I1023 16:27:04.297374  4985 sgd_solver.cpp:105] Iteration 24200, lr = 0.0001
I1023 16:27:08.882477  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:27:23.285492  4985 solver.cpp:218] Iteration 24300 (5.26646 iter/s, 18.9881s/100 iters), loss = 0.00809176
I1023 16:27:23.285660  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00809257 (* 1 = 0.00809257 loss)
I1023 16:27:23.285682  4985 sgd_solver.cpp:105] Iteration 24300, lr = 0.0001
I1023 16:27:42.086052  4985 solver.cpp:330] Iteration 24400, Testing net (#0)
I1023 16:27:43.287070  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:27:44.597098  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:27:44.597158  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.116597 (* 1 = 0.116597 loss)
I1023 16:27:44.788055  4985 solver.cpp:218] Iteration 24400 (4.65065 iter/s, 21.5023s/100 iters), loss = 0.00756527
I1023 16:27:44.788087  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00756606 (* 1 = 0.00756606 loss)
I1023 16:27:44.788094  4985 sgd_solver.cpp:105] Iteration 24400, lr = 0.0001
I1023 16:28:03.776933  4985 solver.cpp:218] Iteration 24500 (5.26626 iter/s, 18.9888s/100 iters), loss = 0.00056264
I1023 16:28:03.777040  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000563441 (* 1 = 0.000563441 loss)
I1023 16:28:03.777048  4985 sgd_solver.cpp:105] Iteration 24500, lr = 0.0001
I1023 16:28:16.149953  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:28:22.584344  4985 solver.cpp:330] Iteration 24600, Testing net (#0)
I1023 16:28:23.748100  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:28:25.095124  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.962891
I1023 16:28:25.095183  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.113991 (* 1 = 0.113991 loss)
I1023 16:28:25.286372  4985 solver.cpp:218] Iteration 24600 (4.64915 iter/s, 21.5093s/100 iters), loss = 0.149547
I1023 16:28:25.286406  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149548 (* 1 = 0.149548 loss)
I1023 16:28:25.286413  4985 sgd_solver.cpp:105] Iteration 24600, lr = 0.0001
I1023 16:28:44.261493  4985 solver.cpp:218] Iteration 24700 (5.27008 iter/s, 18.975s/100 iters), loss = 0.00445372
I1023 16:28:44.261637  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00445452 (* 1 = 0.00445452 loss)
I1023 16:28:44.261646  4985 sgd_solver.cpp:105] Iteration 24700, lr = 0.0001
I1023 16:29:03.054208  4985 solver.cpp:330] Iteration 24800, Testing net (#0)
I1023 16:29:04.216964  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:29:05.564379  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:29:05.564438  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.121042 (* 1 = 0.121042 loss)
I1023 16:29:05.755342  4985 solver.cpp:218] Iteration 24800 (4.65254 iter/s, 21.4937s/100 iters), loss = 0.00987668
I1023 16:29:05.755373  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00987748 (* 1 = 0.00987748 loss)
I1023 16:29:05.755379  4985 sgd_solver.cpp:105] Iteration 24800, lr = 0.0001
I1023 16:29:24.742255  4985 solver.cpp:218] Iteration 24900 (5.26681 iter/s, 18.9868s/100 iters), loss = 0.0214237
I1023 16:29:24.742396  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0214245 (* 1 = 0.0214245 loss)
I1023 16:29:24.742405  4985 sgd_solver.cpp:105] Iteration 24900, lr = 0.0001
I1023 16:29:26.097175  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:29:43.545497  4985 solver.cpp:330] Iteration 25000, Testing net (#0)
I1023 16:29:44.708118  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:29:46.056370  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.962891
I1023 16:29:46.056435  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.121444 (* 1 = 0.121444 loss)
I1023 16:29:46.247442  4985 solver.cpp:218] Iteration 25000 (4.65008 iter/s, 21.505s/100 iters), loss = 0.00416307
I1023 16:29:46.247473  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00416385 (* 1 = 0.00416385 loss)
I1023 16:29:46.247479  4985 sgd_solver.cpp:105] Iteration 25000, lr = 0.0001
I1023 16:30:05.235929  4985 solver.cpp:218] Iteration 25100 (5.26637 iter/s, 18.9884s/100 iters), loss = 0.000942407
I1023 16:30:05.236049  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000943184 (* 1 = 0.000943184 loss)
I1023 16:30:05.236057  4985 sgd_solver.cpp:105] Iteration 25100, lr = 0.0001
I1023 16:30:24.038028  4985 solver.cpp:330] Iteration 25200, Testing net (#0)
I1023 16:30:25.199745  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:30:26.548655  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:30:26.548712  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.120742 (* 1 = 0.120742 loss)
I1023 16:30:26.739540  4985 solver.cpp:218] Iteration 25200 (4.65042 iter/s, 21.5034s/100 iters), loss = 0.0028503
I1023 16:30:26.739570  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00285108 (* 1 = 0.00285108 loss)
I1023 16:30:26.739578  4985 sgd_solver.cpp:105] Iteration 25200, lr = 0.0001
I1023 16:30:35.882699  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:30:45.735662  4985 solver.cpp:218] Iteration 25300 (5.26425 iter/s, 18.996s/100 iters), loss = 0.0329515
I1023 16:30:45.735694  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0329523 (* 1 = 0.0329523 loss)
I1023 16:30:45.735700  4985 sgd_solver.cpp:105] Iteration 25300, lr = 0.0001
I1023 16:31:04.524787  4985 solver.cpp:330] Iteration 25400, Testing net (#0)
I1023 16:31:05.649857  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:31:07.035351  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.962891
I1023 16:31:07.035485  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.120145 (* 1 = 0.120145 loss)
I1023 16:31:07.226286  4985 solver.cpp:218] Iteration 25400 (4.65321 iter/s, 21.4905s/100 iters), loss = 0.0393168
I1023 16:31:07.226330  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0393176 (* 1 = 0.0393176 loss)
I1023 16:31:07.226338  4985 sgd_solver.cpp:105] Iteration 25400, lr = 0.0001
I1023 16:31:26.211650  4985 solver.cpp:218] Iteration 25500 (5.26724 iter/s, 18.9853s/100 iters), loss = 0.00370097
I1023 16:31:26.211683  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00370173 (* 1 = 0.00370173 loss)
I1023 16:31:26.211689  4985 sgd_solver.cpp:105] Iteration 25500, lr = 0.0001
I1023 16:31:43.135730  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:31:45.014753  4985 solver.cpp:330] Iteration 25600, Testing net (#0)
I1023 16:31:46.139354  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:31:47.526094  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:31:47.526152  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.120483 (* 1 = 0.120483 loss)
I1023 16:31:47.716706  4985 solver.cpp:218] Iteration 25600 (4.65009 iter/s, 21.505s/100 iters), loss = 0.00184772
I1023 16:31:47.716737  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00184848 (* 1 = 0.00184848 loss)
I1023 16:31:47.716743  4985 sgd_solver.cpp:105] Iteration 25600, lr = 0.0001
I1023 16:32:06.699678  4985 solver.cpp:218] Iteration 25700 (5.2679 iter/s, 18.9829s/100 iters), loss = 0.00356428
I1023 16:32:06.699710  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00356504 (* 1 = 0.00356504 loss)
I1023 16:32:06.699717  4985 sgd_solver.cpp:105] Iteration 25700, lr = 0.0001
I1023 16:32:25.498414  4985 solver.cpp:330] Iteration 25800, Testing net (#0)
I1023 16:32:26.622077  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:32:28.009382  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:32:28.009433  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.119494 (* 1 = 0.119494 loss)
I1023 16:32:28.200106  4985 solver.cpp:218] Iteration 25800 (4.65109 iter/s, 21.5003s/100 iters), loss = 0.0260116
I1023 16:32:28.200139  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0260123 (* 1 = 0.0260123 loss)
I1023 16:32:28.200146  4985 sgd_solver.cpp:105] Iteration 25800, lr = 0.0001
I1023 16:32:47.180836  4985 solver.cpp:218] Iteration 25900 (5.26852 iter/s, 18.9806s/100 iters), loss = 0.00124182
I1023 16:32:47.180868  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0012426 (* 1 = 0.0012426 loss)
I1023 16:32:47.180876  4985 sgd_solver.cpp:105] Iteration 25900, lr = 0.0001
I1023 16:32:52.904889  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:33:05.974519  4985 solver.cpp:330] Iteration 26000, Testing net (#0)
I1023 16:33:07.096460  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:33:08.486065  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:33:08.486121  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.117154 (* 1 = 0.117154 loss)
I1023 16:33:08.676681  4985 solver.cpp:218] Iteration 26000 (4.65208 iter/s, 21.4958s/100 iters), loss = 0.00134847
I1023 16:33:08.676712  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00134924 (* 1 = 0.00134924 loss)
I1023 16:33:08.676719  4985 sgd_solver.cpp:105] Iteration 26000, lr = 0.0001
I1023 16:33:27.663899  4985 solver.cpp:218] Iteration 26100 (5.26672 iter/s, 18.9871s/100 iters), loss = 0.00197663
I1023 16:33:27.663930  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00197739 (* 1 = 0.00197739 loss)
I1023 16:33:27.663936  4985 sgd_solver.cpp:105] Iteration 26100, lr = 0.0001
I1023 16:33:46.464704  4985 solver.cpp:330] Iteration 26200, Testing net (#0)
I1023 16:33:47.549652  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:33:48.975677  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:33:48.975740  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.119092 (* 1 = 0.119092 loss)
I1023 16:33:49.166386  4985 solver.cpp:218] Iteration 26200 (4.65064 iter/s, 21.5024s/100 iters), loss = 0.0191708
I1023 16:33:49.166417  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0191716 (* 1 = 0.0191716 loss)
I1023 16:33:49.166424  4985 sgd_solver.cpp:105] Iteration 26200, lr = 0.0001
I1023 16:34:02.867549  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:34:08.162773  4985 solver.cpp:218] Iteration 26300 (5.26418 iter/s, 18.9963s/100 iters), loss = 0.00844347
I1023 16:34:08.162803  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00844427 (* 1 = 0.00844427 loss)
I1023 16:34:08.162809  4985 sgd_solver.cpp:105] Iteration 26300, lr = 0.0001
I1023 16:34:26.957479  4985 solver.cpp:330] Iteration 26400, Testing net (#0)
I1023 16:34:28.042490  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:34:29.468483  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.958984
I1023 16:34:29.468551  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.119639 (* 1 = 0.119639 loss)
I1023 16:34:29.659107  4985 solver.cpp:218] Iteration 26400 (4.65197 iter/s, 21.4963s/100 iters), loss = 0.014599
I1023 16:34:29.659138  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145998 (* 1 = 0.0145998 loss)
I1023 16:34:29.659145  4985 sgd_solver.cpp:105] Iteration 26400, lr = 0.0001
I1023 16:34:48.644062  4985 solver.cpp:218] Iteration 26500 (5.26735 iter/s, 18.9849s/100 iters), loss = 0.00291067
I1023 16:34:48.644093  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0029115 (* 1 = 0.0029115 loss)
I1023 16:34:48.644099  4985 sgd_solver.cpp:105] Iteration 26500, lr = 0.0001
I1023 16:35:07.441944  4985 solver.cpp:330] Iteration 26600, Testing net (#0)
I1023 16:35:08.526592  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:35:09.952540  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:35:09.952606  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.119044 (* 1 = 0.119044 loss)
I1023 16:35:10.143262  4985 solver.cpp:218] Iteration 26600 (4.65135 iter/s, 21.4991s/100 iters), loss = 0.000439441
I1023 16:35:10.143293  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000440287 (* 1 = 0.000440287 loss)
I1023 16:35:10.143301  4985 sgd_solver.cpp:105] Iteration 26600, lr = 0.0001
I1023 16:35:12.636229  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:35:29.129714  4985 solver.cpp:218] Iteration 26700 (5.26694 iter/s, 18.9864s/100 iters), loss = 0.0265763
I1023 16:35:29.129745  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0265771 (* 1 = 0.0265771 loss)
I1023 16:35:29.129750  4985 sgd_solver.cpp:105] Iteration 26700, lr = 0.0001
I1023 16:35:47.931255  4985 solver.cpp:330] Iteration 26800, Testing net (#0)
I1023 16:35:49.014276  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:35:50.441666  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:35:50.441717  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.118212 (* 1 = 0.118212 loss)
I1023 16:35:50.632820  4985 solver.cpp:218] Iteration 26800 (4.65051 iter/s, 21.503s/100 iters), loss = 0.0010018
I1023 16:35:50.632853  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100263 (* 1 = 0.00100263 loss)
I1023 16:35:50.632859  4985 sgd_solver.cpp:105] Iteration 26800, lr = 0.0001
I1023 16:36:09.633957  4985 solver.cpp:218] Iteration 26900 (5.26287 iter/s, 19.0011s/100 iters), loss = 0.000441334
I1023 16:36:09.633987  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000442181 (* 1 = 0.000442181 loss)
I1023 16:36:09.633994  4985 sgd_solver.cpp:105] Iteration 26900, lr = 0.0001
I1023 16:36:19.919313  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:36:28.448761  4985 solver.cpp:330] Iteration 27000, Testing net (#0)
I1023 16:36:29.495553  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:36:30.959281  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:36:30.959333  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.117768 (* 1 = 0.117768 loss)
I1023 16:36:31.150122  4985 solver.cpp:218] Iteration 27000 (4.64769 iter/s, 21.5161s/100 iters), loss = 0.0140561
I1023 16:36:31.150151  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0140569 (* 1 = 0.0140569 loss)
I1023 16:36:31.150158  4985 sgd_solver.cpp:105] Iteration 27000, lr = 0.0001
I1023 16:36:50.144388  4985 solver.cpp:218] Iteration 27100 (5.26477 iter/s, 18.9942s/100 iters), loss = 0.00101268
I1023 16:36:50.144536  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00101353 (* 1 = 0.00101353 loss)
I1023 16:36:50.144544  4985 sgd_solver.cpp:105] Iteration 27100, lr = 0.0001
I1023 16:37:08.953145  4985 solver.cpp:330] Iteration 27200, Testing net (#0)
I1023 16:37:09.999366  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:37:11.463440  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.962891
I1023 16:37:11.463490  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.124662 (* 1 = 0.124662 loss)
I1023 16:37:11.654539  4985 solver.cpp:218] Iteration 27200 (4.64901 iter/s, 21.51s/100 iters), loss = 0.000902544
I1023 16:37:11.654569  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000903372 (* 1 = 0.000903372 loss)
I1023 16:37:11.654577  4985 sgd_solver.cpp:105] Iteration 27200, lr = 0.0001
I1023 16:37:29.726177  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:37:30.657678  4985 solver.cpp:218] Iteration 27300 (5.26231 iter/s, 19.0031s/100 iters), loss = 0.000533465
I1023 16:37:30.657708  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000534299 (* 1 = 0.000534299 loss)
I1023 16:37:30.657714  4985 sgd_solver.cpp:105] Iteration 27300, lr = 0.0001
I1023 16:37:49.473075  4985 solver.cpp:330] Iteration 27400, Testing net (#0)
I1023 16:37:50.517204  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:37:51.982501  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:37:51.982558  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.121577 (* 1 = 0.121577 loss)
I1023 16:37:52.173715  4985 solver.cpp:218] Iteration 27400 (4.64771 iter/s, 21.516s/100 iters), loss = 0.00281993
I1023 16:37:52.173748  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00282077 (* 1 = 0.00282077 loss)
I1023 16:37:52.173755  4985 sgd_solver.cpp:105] Iteration 27400, lr = 0.0001
I1023 16:38:11.177821  4985 solver.cpp:218] Iteration 27500 (5.26204 iter/s, 19.004s/100 iters), loss = 0.000662385
I1023 16:38:11.177964  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000663219 (* 1 = 0.000663219 loss)
I1023 16:38:11.177974  4985 sgd_solver.cpp:105] Iteration 27500, lr = 0.0001
I1023 16:38:29.992750  4985 solver.cpp:330] Iteration 27600, Testing net (#0)
I1023 16:38:31.036710  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:38:32.503218  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:38:32.503267  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.123566 (* 1 = 0.123566 loss)
I1023 16:38:32.693970  4985 solver.cpp:218] Iteration 27600 (4.64771 iter/s, 21.516s/100 iters), loss = 0.00184516
I1023 16:38:32.694015  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.001846 (* 1 = 0.001846 loss)
I1023 16:38:32.694021  4985 sgd_solver.cpp:105] Iteration 27600, lr = 0.0001
I1023 16:38:39.746908  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:38:51.693131  4985 solver.cpp:218] Iteration 27700 (5.26342 iter/s, 18.9991s/100 iters), loss = 0.0940225
I1023 16:38:51.693274  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0940233 (* 1 = 0.0940233 loss)
I1023 16:38:51.693284  4985 sgd_solver.cpp:105] Iteration 27700, lr = 0.0001
I1023 16:39:10.503053  4985 solver.cpp:330] Iteration 27800, Testing net (#0)
I1023 16:39:11.509793  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:39:13.013288  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.962891
I1023 16:39:13.013345  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.12286 (* 1 = 0.12286 loss)
I1023 16:39:13.204327  4985 solver.cpp:218] Iteration 27800 (4.64878 iter/s, 21.511s/100 iters), loss = 0.0122375
I1023 16:39:13.204360  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122384 (* 1 = 0.0122384 loss)
I1023 16:39:13.204367  4985 sgd_solver.cpp:105] Iteration 27800, lr = 0.0001
I1023 16:39:32.202802  4985 solver.cpp:218] Iteration 27900 (5.2636 iter/s, 18.9984s/100 iters), loss = 0.0348045
I1023 16:39:32.202958  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0348054 (* 1 = 0.0348054 loss)
I1023 16:39:32.202967  4985 sgd_solver.cpp:105] Iteration 27900, lr = 0.0001
I1023 16:39:47.043519  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:39:51.019666  4985 solver.cpp:330] Iteration 28000, Testing net (#0)
I1023 16:39:52.026608  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:39:53.530022  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:39:53.530086  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.123287 (* 1 = 0.123287 loss)
I1023 16:39:53.722013  4985 solver.cpp:218] Iteration 28000 (4.64706 iter/s, 21.519s/100 iters), loss = 0.019007
I1023 16:39:53.722059  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0190078 (* 1 = 0.0190078 loss)
I1023 16:39:53.722080  4985 sgd_solver.cpp:105] Iteration 28000, lr = 0.0001
I1023 16:40:12.717216  4985 solver.cpp:218] Iteration 28100 (5.26451 iter/s, 18.9951s/100 iters), loss = 0.00116221
I1023 16:40:12.717376  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00116305 (* 1 = 0.00116305 loss)
I1023 16:40:12.717384  4985 sgd_solver.cpp:105] Iteration 28100, lr = 0.0001
I1023 16:40:31.532265  4985 solver.cpp:330] Iteration 28200, Testing net (#0)
I1023 16:40:32.538321  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:40:34.042140  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:40:34.042199  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.118839 (* 1 = 0.118839 loss)
I1023 16:40:34.232833  4985 solver.cpp:218] Iteration 28200 (4.64783 iter/s, 21.5154s/100 iters), loss = 0.0400633
I1023 16:40:34.232862  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0400642 (* 1 = 0.0400642 loss)
I1023 16:40:34.232869  4985 sgd_solver.cpp:105] Iteration 28200, lr = 0.0001
I1023 16:40:53.226639  4985 solver.cpp:218] Iteration 28300 (5.26489 iter/s, 18.9937s/100 iters), loss = 0.00895977
I1023 16:40:53.226786  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00896062 (* 1 = 0.00896062 loss)
I1023 16:40:53.226795  4985 sgd_solver.cpp:105] Iteration 28300, lr = 0.0001
I1023 16:40:56.859019  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:41:12.037219  4985 solver.cpp:330] Iteration 28400, Testing net (#0)
I1023 16:41:13.042131  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:41:14.547394  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:41:14.547461  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.11803 (* 1 = 0.11803 loss)
I1023 16:41:14.738184  4985 solver.cpp:218] Iteration 28400 (4.64871 iter/s, 21.5113s/100 iters), loss = 0.0035804
I1023 16:41:14.738214  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00358129 (* 1 = 0.00358129 loss)
I1023 16:41:14.738220  4985 sgd_solver.cpp:105] Iteration 28400, lr = 0.0001
I1023 16:41:33.739400  4985 solver.cpp:218] Iteration 28500 (5.26284 iter/s, 19.0011s/100 iters), loss = 0.00878933
I1023 16:41:33.739547  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00879022 (* 1 = 0.00879022 loss)
I1023 16:41:33.739557  4985 sgd_solver.cpp:105] Iteration 28500, lr = 0.0001
I1023 16:41:52.554618  4985 solver.cpp:330] Iteration 28600, Testing net (#0)
I1023 16:41:53.522732  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:41:55.064577  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:41:55.064646  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.115432 (* 1 = 0.115432 loss)
I1023 16:41:55.255491  4985 solver.cpp:218] Iteration 28600 (4.64773 iter/s, 21.5159s/100 iters), loss = 0.0384882
I1023 16:41:55.255520  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0384891 (* 1 = 0.0384891 loss)
I1023 16:41:55.255527  4985 sgd_solver.cpp:105] Iteration 28600, lr = 0.0001
I1023 16:42:06.681665  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:42:14.266311  4985 solver.cpp:218] Iteration 28700 (5.26018 iter/s, 19.0107s/100 iters), loss = 0.00233756
I1023 16:42:14.266342  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00233845 (* 1 = 0.00233845 loss)
I1023 16:42:14.266350  4985 sgd_solver.cpp:105] Iteration 28700, lr = 0.0001
I1023 16:42:33.074542  4985 solver.cpp:330] Iteration 28800, Testing net (#0)
I1023 16:42:34.041306  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:42:35.584964  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.962891
I1023 16:42:35.585023  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.126926 (* 1 = 0.126926 loss)
I1023 16:42:35.775701  4985 solver.cpp:218] Iteration 28800 (4.64915 iter/s, 21.5093s/100 iters), loss = 0.00296732
I1023 16:42:35.775732  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00296819 (* 1 = 0.00296819 loss)
I1023 16:42:35.775738  4985 sgd_solver.cpp:105] Iteration 28800, lr = 0.0001
I1023 16:42:54.772925  4985 solver.cpp:218] Iteration 28900 (5.26395 iter/s, 18.9971s/100 iters), loss = 0.0892999
I1023 16:42:54.773088  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0893007 (* 1 = 0.0893007 loss)
I1023 16:42:54.773097  4985 sgd_solver.cpp:105] Iteration 28900, lr = 0.0001
I1023 16:43:13.583334  4985 solver.cpp:330] Iteration 29000, Testing net (#0)
I1023 16:43:14.549703  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:43:16.093662  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:43:16.093719  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.120888 (* 1 = 0.120888 loss)
I1023 16:43:16.284605  4985 solver.cpp:218] Iteration 29000 (4.64868 iter/s, 21.5115s/100 iters), loss = 0.0127117
I1023 16:43:16.284636  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127125 (* 1 = 0.0127125 loss)
I1023 16:43:16.284642  4985 sgd_solver.cpp:105] Iteration 29000, lr = 0.0001
I1023 16:43:16.684348  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:43:35.286315  4985 solver.cpp:218] Iteration 29100 (5.26271 iter/s, 19.0016s/100 iters), loss = 0.0297123
I1023 16:43:35.286461  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0297131 (* 1 = 0.0297131 loss)
I1023 16:43:35.286470  4985 sgd_solver.cpp:105] Iteration 29100, lr = 0.0001
I1023 16:43:54.100306  4985 solver.cpp:330] Iteration 29200, Testing net (#0)
I1023 16:43:55.065402  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:43:56.611359  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:43:56.611418  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.119605 (* 1 = 0.119605 loss)
I1023 16:43:56.802381  4985 solver.cpp:218] Iteration 29200 (4.64773 iter/s, 21.5159s/100 iters), loss = 0.0202758
I1023 16:43:56.802409  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0202766 (* 1 = 0.0202766 loss)
I1023 16:43:56.802417  4985 sgd_solver.cpp:105] Iteration 29200, lr = 0.0001
I1023 16:44:15.802047  4985 solver.cpp:218] Iteration 29300 (5.26327 iter/s, 18.9996s/100 iters), loss = 0.00648248
I1023 16:44:15.802188  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0064833 (* 1 = 0.0064833 loss)
I1023 16:44:15.802197  4985 sgd_solver.cpp:105] Iteration 29300, lr = 0.0001
I1023 16:44:23.994946  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:44:34.616343  4985 solver.cpp:330] Iteration 29400, Testing net (#0)
I1023 16:44:35.545061  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:44:37.126806  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:44:37.126870  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.117316 (* 1 = 0.117316 loss)
I1023 16:44:37.317423  4985 solver.cpp:218] Iteration 29400 (4.64788 iter/s, 21.5152s/100 iters), loss = 0.0189691
I1023 16:44:37.317451  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0189699 (* 1 = 0.0189699 loss)
I1023 16:44:37.317458  4985 sgd_solver.cpp:105] Iteration 29400, lr = 0.0001
I1023 16:44:56.312432  4985 solver.cpp:218] Iteration 29500 (5.26456 iter/s, 18.9949s/100 iters), loss = 0.00381848
I1023 16:44:56.312520  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00381926 (* 1 = 0.00381926 loss)
I1023 16:44:56.312536  4985 sgd_solver.cpp:105] Iteration 29500, lr = 0.0001
I1023 16:45:15.120347  4985 solver.cpp:330] Iteration 29600, Testing net (#0)
I1023 16:45:16.049141  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:45:17.630970  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:45:17.631032  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.116573 (* 1 = 0.116573 loss)
I1023 16:45:17.822083  4985 solver.cpp:218] Iteration 29600 (4.64911 iter/s, 21.5095s/100 iters), loss = 0.00273589
I1023 16:45:17.822113  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00273668 (* 1 = 0.00273668 loss)
I1023 16:45:17.822119  4985 sgd_solver.cpp:105] Iteration 29600, lr = 0.0001
I1023 16:45:33.804846  4994 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:45:36.828972  4985 solver.cpp:218] Iteration 29700 (5.26127 iter/s, 19.0068s/100 iters), loss = 0.00261948
I1023 16:45:36.829001  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00262027 (* 1 = 0.00262027 loss)
I1023 16:45:36.829007  4985 sgd_solver.cpp:105] Iteration 29700, lr = 0.0001
I1023 16:45:55.641710  4985 solver.cpp:330] Iteration 29800, Testing net (#0)
I1023 16:45:56.569473  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:45:58.152261  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:45:58.152319  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.117633 (* 1 = 0.117633 loss)
I1023 16:45:58.343659  4985 solver.cpp:218] Iteration 29800 (4.64801 iter/s, 21.5146s/100 iters), loss = 0.023075
I1023 16:45:58.343689  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0230758 (* 1 = 0.0230758 loss)
I1023 16:45:58.343695  4985 sgd_solver.cpp:105] Iteration 29800, lr = 0.0001
I1023 16:46:17.344677  4985 solver.cpp:218] Iteration 29900 (5.2629 iter/s, 19.0009s/100 iters), loss = 0.0110777
I1023 16:46:17.344826  4985 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110785 (* 1 = 0.0110785 loss)
I1023 16:46:17.344835  4985 sgd_solver.cpp:105] Iteration 29900, lr = 0.0001
I1023 16:46:36.160420  4985 solver.cpp:447] Snapshotting to binary proto file xn/English_orange/snapshot/res20/res20_prelu_default_iter_30000.caffemodel
I1023 16:46:36.168794  4985 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/English_orange/snapshot/res20/res20_prelu_default_iter_30000.solverstate
I1023 16:46:36.224649  4985 solver.cpp:310] Iteration 30000, loss = 0.00685527
I1023 16:46:36.224686  4985 solver.cpp:330] Iteration 30000, Testing net (#0)
I1023 16:46:37.150913  4995 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:46:38.736187  4985 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 16:46:38.736239  4985 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.11903 (* 1 = 0.11903 loss)
I1023 16:46:38.736245  4985 solver.cpp:315] Optimization Done.
I1023 16:46:38.736249  4985 caffe.cpp:259] Optimization Done.
