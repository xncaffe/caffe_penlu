I1023 09:39:13.825074  4519 caffe.cpp:218] Using GPUs 0
I1023 09:39:13.854766  4519 caffe.cpp:223] GPU 0: GeForce GTX 1080
I1023 09:39:14.091516  4519 solver.cpp:44] Initializing solver from parameters: 
test_iter: 64
test_interval: 200
base_lr: 0.01
display: 100
max_iter: 30000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 30000
snapshot_prefix: "xn/English_orange/snapshot/res20/res20_penlu_alpha1_etanostudy_2study_2decay"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/English_orange/neural/res20/res20_penlu_gauss.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 10000
stepvalue: 20000
I1023 09:39:14.091647  4519 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/English_orange/neural/res20/res20_penlu_gauss.prototxt
I1023 09:39:14.093168  4519 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/English_orange/neural/res20/res20_penlu_gauss.prototxt
I1023 09:39:14.093176  4519 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1023 09:39:14.093312  4519 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I1023 09:39:14.093375  4519 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I1023 09:39:14.093858  4519 net.cpp:51] Initializing net from parameters: 
name: "resnet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_file: "/home/x306/caffe/xn/English_orange/data/orange1_mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/English_orange/data/train1_lmdb"
    batch_size: 8
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
I1023 09:39:14.094158  4519 layer_factory.hpp:77] Creating layer Data1
I1023 09:39:14.094234  4519 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/English_orange/data/train1_lmdb
I1023 09:39:14.094256  4519 net.cpp:84] Creating Layer Data1
I1023 09:39:14.094262  4519 net.cpp:380] Data1 -> Data1
I1023 09:39:14.094280  4519 net.cpp:380] Data1 -> Data2
I1023 09:39:14.094290  4519 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/English_orange/data/orange1_mean.binaryproto
I1023 09:39:14.096735  4519 data_layer.cpp:45] output data size: 8,3,224,224
I1023 09:39:14.104696  4519 net.cpp:122] Setting up Data1
I1023 09:39:14.104728  4519 net.cpp:129] Top shape: 8 3 224 224 (1204224)
I1023 09:39:14.104733  4519 net.cpp:129] Top shape: 8 (8)
I1023 09:39:14.104737  4519 net.cpp:137] Memory required for data: 4816928
I1023 09:39:14.104743  4519 layer_factory.hpp:77] Creating layer Convolution1
I1023 09:39:14.104774  4519 net.cpp:84] Creating Layer Convolution1
I1023 09:39:14.104779  4519 net.cpp:406] Convolution1 <- Data1
I1023 09:39:14.104797  4519 net.cpp:380] Convolution1 -> Convolution1
I1023 09:39:14.253505  4519 net.cpp:122] Setting up Convolution1
I1023 09:39:14.253530  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.253535  4519 net.cpp:137] Memory required for data: 30507040
I1023 09:39:14.253548  4519 layer_factory.hpp:77] Creating layer BatchNorm1
I1023 09:39:14.253572  4519 net.cpp:84] Creating Layer BatchNorm1
I1023 09:39:14.253581  4519 net.cpp:406] BatchNorm1 <- Convolution1
I1023 09:39:14.253588  4519 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1023 09:39:14.253743  4519 net.cpp:122] Setting up BatchNorm1
I1023 09:39:14.253749  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.253751  4519 net.cpp:137] Memory required for data: 56197152
I1023 09:39:14.253759  4519 layer_factory.hpp:77] Creating layer Scale1
I1023 09:39:14.253769  4519 net.cpp:84] Creating Layer Scale1
I1023 09:39:14.253784  4519 net.cpp:406] Scale1 <- Convolution1
I1023 09:39:14.253789  4519 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1023 09:39:14.253831  4519 layer_factory.hpp:77] Creating layer Scale1
I1023 09:39:14.253962  4519 net.cpp:122] Setting up Scale1
I1023 09:39:14.253968  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.253970  4519 net.cpp:137] Memory required for data: 81887264
I1023 09:39:14.253974  4519 layer_factory.hpp:77] Creating layer penlu1
I1023 09:39:14.253984  4519 net.cpp:84] Creating Layer penlu1
I1023 09:39:14.253988  4519 net.cpp:406] penlu1 <- Convolution1
I1023 09:39:14.254005  4519 net.cpp:367] penlu1 -> Convolution1 (in-place)
I1023 09:39:14.255125  4519 net.cpp:122] Setting up penlu1
I1023 09:39:14.255136  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.255138  4519 net.cpp:137] Memory required for data: 107577376
I1023 09:39:14.255146  4519 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I1023 09:39:14.255156  4519 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I1023 09:39:14.255170  4519 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I1023 09:39:14.255177  4519 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I1023 09:39:14.255185  4519 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I1023 09:39:14.255220  4519 net.cpp:122] Setting up Convolution1_penlu1_0_split
I1023 09:39:14.255225  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.255229  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.255231  4519 net.cpp:137] Memory required for data: 158957600
I1023 09:39:14.255234  4519 layer_factory.hpp:77] Creating layer Convolution2
I1023 09:39:14.255241  4519 net.cpp:84] Creating Layer Convolution2
I1023 09:39:14.255244  4519 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I1023 09:39:14.255249  4519 net.cpp:380] Convolution2 -> Convolution2
I1023 09:39:14.256727  4519 net.cpp:122] Setting up Convolution2
I1023 09:39:14.256739  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.256744  4519 net.cpp:137] Memory required for data: 184647712
I1023 09:39:14.256762  4519 layer_factory.hpp:77] Creating layer BatchNorm2
I1023 09:39:14.256781  4519 net.cpp:84] Creating Layer BatchNorm2
I1023 09:39:14.256785  4519 net.cpp:406] BatchNorm2 <- Convolution2
I1023 09:39:14.256791  4519 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1023 09:39:14.256979  4519 net.cpp:122] Setting up BatchNorm2
I1023 09:39:14.256985  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.256989  4519 net.cpp:137] Memory required for data: 210337824
I1023 09:39:14.257004  4519 layer_factory.hpp:77] Creating layer Scale2
I1023 09:39:14.257025  4519 net.cpp:84] Creating Layer Scale2
I1023 09:39:14.257027  4519 net.cpp:406] Scale2 <- Convolution2
I1023 09:39:14.257032  4519 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1023 09:39:14.257067  4519 layer_factory.hpp:77] Creating layer Scale2
I1023 09:39:14.257252  4519 net.cpp:122] Setting up Scale2
I1023 09:39:14.257258  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.257261  4519 net.cpp:137] Memory required for data: 236027936
I1023 09:39:14.257277  4519 layer_factory.hpp:77] Creating layer penlu2
I1023 09:39:14.257299  4519 net.cpp:84] Creating Layer penlu2
I1023 09:39:14.257302  4519 net.cpp:406] penlu2 <- Convolution2
I1023 09:39:14.257308  4519 net.cpp:367] penlu2 -> Convolution2 (in-place)
I1023 09:39:14.258460  4519 net.cpp:122] Setting up penlu2
I1023 09:39:14.258471  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.258474  4519 net.cpp:137] Memory required for data: 261718048
I1023 09:39:14.258479  4519 layer_factory.hpp:77] Creating layer Convolution3
I1023 09:39:14.258489  4519 net.cpp:84] Creating Layer Convolution3
I1023 09:39:14.258492  4519 net.cpp:406] Convolution3 <- Convolution2
I1023 09:39:14.258497  4519 net.cpp:380] Convolution3 -> Convolution3
I1023 09:39:14.259429  4519 net.cpp:122] Setting up Convolution3
I1023 09:39:14.259440  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.259444  4519 net.cpp:137] Memory required for data: 287408160
I1023 09:39:14.259449  4519 layer_factory.hpp:77] Creating layer BatchNorm3
I1023 09:39:14.259454  4519 net.cpp:84] Creating Layer BatchNorm3
I1023 09:39:14.259457  4519 net.cpp:406] BatchNorm3 <- Convolution3
I1023 09:39:14.259462  4519 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1023 09:39:14.259618  4519 net.cpp:122] Setting up BatchNorm3
I1023 09:39:14.259624  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.259626  4519 net.cpp:137] Memory required for data: 313098272
I1023 09:39:14.259631  4519 layer_factory.hpp:77] Creating layer Scale3
I1023 09:39:14.259635  4519 net.cpp:84] Creating Layer Scale3
I1023 09:39:14.259639  4519 net.cpp:406] Scale3 <- Convolution3
I1023 09:39:14.259642  4519 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1023 09:39:14.259670  4519 layer_factory.hpp:77] Creating layer Scale3
I1023 09:39:14.260298  4519 net.cpp:122] Setting up Scale3
I1023 09:39:14.260308  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.260310  4519 net.cpp:137] Memory required for data: 338788384
I1023 09:39:14.260315  4519 layer_factory.hpp:77] Creating layer Eltwise1
I1023 09:39:14.260321  4519 net.cpp:84] Creating Layer Eltwise1
I1023 09:39:14.260324  4519 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I1023 09:39:14.260329  4519 net.cpp:406] Eltwise1 <- Convolution3
I1023 09:39:14.260332  4519 net.cpp:380] Eltwise1 -> Eltwise1
I1023 09:39:14.260352  4519 net.cpp:122] Setting up Eltwise1
I1023 09:39:14.260357  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.260360  4519 net.cpp:137] Memory required for data: 364478496
I1023 09:39:14.260362  4519 layer_factory.hpp:77] Creating layer penlu3
I1023 09:39:14.260370  4519 net.cpp:84] Creating Layer penlu3
I1023 09:39:14.260372  4519 net.cpp:406] penlu3 <- Eltwise1
I1023 09:39:14.260375  4519 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I1023 09:39:14.261497  4519 net.cpp:122] Setting up penlu3
I1023 09:39:14.261505  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.261508  4519 net.cpp:137] Memory required for data: 390168608
I1023 09:39:14.261524  4519 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I1023 09:39:14.261531  4519 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I1023 09:39:14.261534  4519 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I1023 09:39:14.261538  4519 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I1023 09:39:14.261544  4519 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I1023 09:39:14.261569  4519 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I1023 09:39:14.261574  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.261579  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.261580  4519 net.cpp:137] Memory required for data: 441548832
I1023 09:39:14.261582  4519 layer_factory.hpp:77] Creating layer Convolution4
I1023 09:39:14.261590  4519 net.cpp:84] Creating Layer Convolution4
I1023 09:39:14.261595  4519 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I1023 09:39:14.261598  4519 net.cpp:380] Convolution4 -> Convolution4
I1023 09:39:14.262553  4519 net.cpp:122] Setting up Convolution4
I1023 09:39:14.262563  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.262567  4519 net.cpp:137] Memory required for data: 467238944
I1023 09:39:14.262572  4519 layer_factory.hpp:77] Creating layer BatchNorm4
I1023 09:39:14.262578  4519 net.cpp:84] Creating Layer BatchNorm4
I1023 09:39:14.262583  4519 net.cpp:406] BatchNorm4 <- Convolution4
I1023 09:39:14.262586  4519 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1023 09:39:14.262745  4519 net.cpp:122] Setting up BatchNorm4
I1023 09:39:14.262750  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.262753  4519 net.cpp:137] Memory required for data: 492929056
I1023 09:39:14.262764  4519 layer_factory.hpp:77] Creating layer Scale4
I1023 09:39:14.262770  4519 net.cpp:84] Creating Layer Scale4
I1023 09:39:14.262773  4519 net.cpp:406] Scale4 <- Convolution4
I1023 09:39:14.262776  4519 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1023 09:39:14.262806  4519 layer_factory.hpp:77] Creating layer Scale4
I1023 09:39:14.262938  4519 net.cpp:122] Setting up Scale4
I1023 09:39:14.262944  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.262946  4519 net.cpp:137] Memory required for data: 518619168
I1023 09:39:14.262950  4519 layer_factory.hpp:77] Creating layer penlu4
I1023 09:39:14.262958  4519 net.cpp:84] Creating Layer penlu4
I1023 09:39:14.262960  4519 net.cpp:406] penlu4 <- Convolution4
I1023 09:39:14.262964  4519 net.cpp:367] penlu4 -> Convolution4 (in-place)
I1023 09:39:14.264119  4519 net.cpp:122] Setting up penlu4
I1023 09:39:14.264132  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.264133  4519 net.cpp:137] Memory required for data: 544309280
I1023 09:39:14.264139  4519 layer_factory.hpp:77] Creating layer Convolution5
I1023 09:39:14.264148  4519 net.cpp:84] Creating Layer Convolution5
I1023 09:39:14.264152  4519 net.cpp:406] Convolution5 <- Convolution4
I1023 09:39:14.264156  4519 net.cpp:380] Convolution5 -> Convolution5
I1023 09:39:14.265517  4519 net.cpp:122] Setting up Convolution5
I1023 09:39:14.265528  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.265533  4519 net.cpp:137] Memory required for data: 569999392
I1023 09:39:14.265540  4519 layer_factory.hpp:77] Creating layer BatchNorm5
I1023 09:39:14.265550  4519 net.cpp:84] Creating Layer BatchNorm5
I1023 09:39:14.265557  4519 net.cpp:406] BatchNorm5 <- Convolution5
I1023 09:39:14.265563  4519 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1023 09:39:14.265774  4519 net.cpp:122] Setting up BatchNorm5
I1023 09:39:14.265784  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.265786  4519 net.cpp:137] Memory required for data: 595689504
I1023 09:39:14.265792  4519 layer_factory.hpp:77] Creating layer Scale5
I1023 09:39:14.265810  4519 net.cpp:84] Creating Layer Scale5
I1023 09:39:14.265812  4519 net.cpp:406] Scale5 <- Convolution5
I1023 09:39:14.265816  4519 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1023 09:39:14.265857  4519 layer_factory.hpp:77] Creating layer Scale5
I1023 09:39:14.265997  4519 net.cpp:122] Setting up Scale5
I1023 09:39:14.266002  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.266006  4519 net.cpp:137] Memory required for data: 621379616
I1023 09:39:14.266010  4519 layer_factory.hpp:77] Creating layer Eltwise2
I1023 09:39:14.266017  4519 net.cpp:84] Creating Layer Eltwise2
I1023 09:39:14.266021  4519 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I1023 09:39:14.266023  4519 net.cpp:406] Eltwise2 <- Convolution5
I1023 09:39:14.266027  4519 net.cpp:380] Eltwise2 -> Eltwise2
I1023 09:39:14.266046  4519 net.cpp:122] Setting up Eltwise2
I1023 09:39:14.266050  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.266052  4519 net.cpp:137] Memory required for data: 647069728
I1023 09:39:14.266055  4519 layer_factory.hpp:77] Creating layer penlu5
I1023 09:39:14.266062  4519 net.cpp:84] Creating Layer penlu5
I1023 09:39:14.266064  4519 net.cpp:406] penlu5 <- Eltwise2
I1023 09:39:14.266067  4519 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I1023 09:39:14.267338  4519 net.cpp:122] Setting up penlu5
I1023 09:39:14.267352  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.267355  4519 net.cpp:137] Memory required for data: 672759840
I1023 09:39:14.267361  4519 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I1023 09:39:14.267369  4519 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I1023 09:39:14.267371  4519 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I1023 09:39:14.267376  4519 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I1023 09:39:14.267382  4519 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I1023 09:39:14.267411  4519 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I1023 09:39:14.267416  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.267419  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.267422  4519 net.cpp:137] Memory required for data: 724140064
I1023 09:39:14.267426  4519 layer_factory.hpp:77] Creating layer Convolution6
I1023 09:39:14.267433  4519 net.cpp:84] Creating Layer Convolution6
I1023 09:39:14.267437  4519 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I1023 09:39:14.267442  4519 net.cpp:380] Convolution6 -> Convolution6
I1023 09:39:14.268995  4519 net.cpp:122] Setting up Convolution6
I1023 09:39:14.269006  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.269011  4519 net.cpp:137] Memory required for data: 749830176
I1023 09:39:14.269016  4519 layer_factory.hpp:77] Creating layer BatchNorm6
I1023 09:39:14.269022  4519 net.cpp:84] Creating Layer BatchNorm6
I1023 09:39:14.269026  4519 net.cpp:406] BatchNorm6 <- Convolution6
I1023 09:39:14.269031  4519 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1023 09:39:14.269189  4519 net.cpp:122] Setting up BatchNorm6
I1023 09:39:14.269196  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.269198  4519 net.cpp:137] Memory required for data: 775520288
I1023 09:39:14.269203  4519 layer_factory.hpp:77] Creating layer Scale6
I1023 09:39:14.269209  4519 net.cpp:84] Creating Layer Scale6
I1023 09:39:14.269212  4519 net.cpp:406] Scale6 <- Convolution6
I1023 09:39:14.269217  4519 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1023 09:39:14.269244  4519 layer_factory.hpp:77] Creating layer Scale6
I1023 09:39:14.269361  4519 net.cpp:122] Setting up Scale6
I1023 09:39:14.269367  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.269371  4519 net.cpp:137] Memory required for data: 801210400
I1023 09:39:14.269374  4519 layer_factory.hpp:77] Creating layer penlu6
I1023 09:39:14.269381  4519 net.cpp:84] Creating Layer penlu6
I1023 09:39:14.269383  4519 net.cpp:406] penlu6 <- Convolution6
I1023 09:39:14.269388  4519 net.cpp:367] penlu6 -> Convolution6 (in-place)
I1023 09:39:14.270575  4519 net.cpp:122] Setting up penlu6
I1023 09:39:14.270586  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.270588  4519 net.cpp:137] Memory required for data: 826900512
I1023 09:39:14.270604  4519 layer_factory.hpp:77] Creating layer Convolution7
I1023 09:39:14.270614  4519 net.cpp:84] Creating Layer Convolution7
I1023 09:39:14.270618  4519 net.cpp:406] Convolution7 <- Convolution6
I1023 09:39:14.270623  4519 net.cpp:380] Convolution7 -> Convolution7
I1023 09:39:14.271617  4519 net.cpp:122] Setting up Convolution7
I1023 09:39:14.271627  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.271631  4519 net.cpp:137] Memory required for data: 852590624
I1023 09:39:14.271636  4519 layer_factory.hpp:77] Creating layer BatchNorm7
I1023 09:39:14.271644  4519 net.cpp:84] Creating Layer BatchNorm7
I1023 09:39:14.271648  4519 net.cpp:406] BatchNorm7 <- Convolution7
I1023 09:39:14.271652  4519 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1023 09:39:14.271813  4519 net.cpp:122] Setting up BatchNorm7
I1023 09:39:14.271819  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.271822  4519 net.cpp:137] Memory required for data: 878280736
I1023 09:39:14.271834  4519 layer_factory.hpp:77] Creating layer Scale7
I1023 09:39:14.271842  4519 net.cpp:84] Creating Layer Scale7
I1023 09:39:14.271847  4519 net.cpp:406] Scale7 <- Convolution7
I1023 09:39:14.271850  4519 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1023 09:39:14.271879  4519 layer_factory.hpp:77] Creating layer Scale7
I1023 09:39:14.272013  4519 net.cpp:122] Setting up Scale7
I1023 09:39:14.272020  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.272022  4519 net.cpp:137] Memory required for data: 903970848
I1023 09:39:14.272027  4519 layer_factory.hpp:77] Creating layer Eltwise3
I1023 09:39:14.272032  4519 net.cpp:84] Creating Layer Eltwise3
I1023 09:39:14.272035  4519 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I1023 09:39:14.272038  4519 net.cpp:406] Eltwise3 <- Convolution7
I1023 09:39:14.272044  4519 net.cpp:380] Eltwise3 -> Eltwise3
I1023 09:39:14.272061  4519 net.cpp:122] Setting up Eltwise3
I1023 09:39:14.272066  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.272069  4519 net.cpp:137] Memory required for data: 929660960
I1023 09:39:14.272071  4519 layer_factory.hpp:77] Creating layer penlu7
I1023 09:39:14.272076  4519 net.cpp:84] Creating Layer penlu7
I1023 09:39:14.272080  4519 net.cpp:406] penlu7 <- Eltwise3
I1023 09:39:14.272084  4519 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I1023 09:39:14.273284  4519 net.cpp:122] Setting up penlu7
I1023 09:39:14.273296  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.273298  4519 net.cpp:137] Memory required for data: 955351072
I1023 09:39:14.273303  4519 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I1023 09:39:14.273309  4519 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I1023 09:39:14.273313  4519 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I1023 09:39:14.273319  4519 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I1023 09:39:14.273324  4519 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I1023 09:39:14.273350  4519 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I1023 09:39:14.273355  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.273357  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.273360  4519 net.cpp:137] Memory required for data: 1006731296
I1023 09:39:14.273362  4519 layer_factory.hpp:77] Creating layer Convolution8
I1023 09:39:14.273370  4519 net.cpp:84] Creating Layer Convolution8
I1023 09:39:14.273375  4519 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I1023 09:39:14.273378  4519 net.cpp:380] Convolution8 -> Convolution8
I1023 09:39:14.275146  4519 net.cpp:122] Setting up Convolution8
I1023 09:39:14.275159  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.275162  4519 net.cpp:137] Memory required for data: 1019576352
I1023 09:39:14.275167  4519 layer_factory.hpp:77] Creating layer BatchNorm8
I1023 09:39:14.275173  4519 net.cpp:84] Creating Layer BatchNorm8
I1023 09:39:14.275177  4519 net.cpp:406] BatchNorm8 <- Convolution8
I1023 09:39:14.275182  4519 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1023 09:39:14.275349  4519 net.cpp:122] Setting up BatchNorm8
I1023 09:39:14.275355  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.275358  4519 net.cpp:137] Memory required for data: 1032421408
I1023 09:39:14.275363  4519 layer_factory.hpp:77] Creating layer Scale8
I1023 09:39:14.275369  4519 net.cpp:84] Creating Layer Scale8
I1023 09:39:14.275372  4519 net.cpp:406] Scale8 <- Convolution8
I1023 09:39:14.275375  4519 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1023 09:39:14.275405  4519 layer_factory.hpp:77] Creating layer Scale8
I1023 09:39:14.275491  4519 net.cpp:122] Setting up Scale8
I1023 09:39:14.275496  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.275499  4519 net.cpp:137] Memory required for data: 1045266464
I1023 09:39:14.275503  4519 layer_factory.hpp:77] Creating layer Convolution9
I1023 09:39:14.275511  4519 net.cpp:84] Creating Layer Convolution9
I1023 09:39:14.275514  4519 net.cpp:406] Convolution9 <- Eltwise3_penlu7_0_split_1
I1023 09:39:14.275521  4519 net.cpp:380] Convolution9 -> Convolution9
I1023 09:39:14.276486  4519 net.cpp:122] Setting up Convolution9
I1023 09:39:14.276496  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.276500  4519 net.cpp:137] Memory required for data: 1058111520
I1023 09:39:14.276504  4519 layer_factory.hpp:77] Creating layer BatchNorm9
I1023 09:39:14.276511  4519 net.cpp:84] Creating Layer BatchNorm9
I1023 09:39:14.276515  4519 net.cpp:406] BatchNorm9 <- Convolution9
I1023 09:39:14.276518  4519 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1023 09:39:14.276651  4519 net.cpp:122] Setting up BatchNorm9
I1023 09:39:14.276657  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.276660  4519 net.cpp:137] Memory required for data: 1070956576
I1023 09:39:14.276665  4519 layer_factory.hpp:77] Creating layer Scale9
I1023 09:39:14.276670  4519 net.cpp:84] Creating Layer Scale9
I1023 09:39:14.276674  4519 net.cpp:406] Scale9 <- Convolution9
I1023 09:39:14.276677  4519 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1023 09:39:14.276703  4519 layer_factory.hpp:77] Creating layer Scale9
I1023 09:39:14.276787  4519 net.cpp:122] Setting up Scale9
I1023 09:39:14.276793  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.276795  4519 net.cpp:137] Memory required for data: 1083801632
I1023 09:39:14.276799  4519 layer_factory.hpp:77] Creating layer penlu8
I1023 09:39:14.276806  4519 net.cpp:84] Creating Layer penlu8
I1023 09:39:14.276809  4519 net.cpp:406] penlu8 <- Convolution9
I1023 09:39:14.276813  4519 net.cpp:367] penlu8 -> Convolution9 (in-place)
I1023 09:39:14.277598  4519 net.cpp:122] Setting up penlu8
I1023 09:39:14.277607  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.277611  4519 net.cpp:137] Memory required for data: 1096646688
I1023 09:39:14.277616  4519 layer_factory.hpp:77] Creating layer Convolution10
I1023 09:39:14.277626  4519 net.cpp:84] Creating Layer Convolution10
I1023 09:39:14.277628  4519 net.cpp:406] Convolution10 <- Convolution9
I1023 09:39:14.277633  4519 net.cpp:380] Convolution10 -> Convolution10
I1023 09:39:14.278702  4519 net.cpp:122] Setting up Convolution10
I1023 09:39:14.278712  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.278717  4519 net.cpp:137] Memory required for data: 1109491744
I1023 09:39:14.278722  4519 layer_factory.hpp:77] Creating layer BatchNorm10
I1023 09:39:14.278728  4519 net.cpp:84] Creating Layer BatchNorm10
I1023 09:39:14.278731  4519 net.cpp:406] BatchNorm10 <- Convolution10
I1023 09:39:14.278735  4519 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1023 09:39:14.278870  4519 net.cpp:122] Setting up BatchNorm10
I1023 09:39:14.278877  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.278879  4519 net.cpp:137] Memory required for data: 1122336800
I1023 09:39:14.278884  4519 layer_factory.hpp:77] Creating layer Scale10
I1023 09:39:14.278889  4519 net.cpp:84] Creating Layer Scale10
I1023 09:39:14.278893  4519 net.cpp:406] Scale10 <- Convolution10
I1023 09:39:14.278904  4519 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1023 09:39:14.278935  4519 layer_factory.hpp:77] Creating layer Scale10
I1023 09:39:14.279023  4519 net.cpp:122] Setting up Scale10
I1023 09:39:14.279029  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.279032  4519 net.cpp:137] Memory required for data: 1135181856
I1023 09:39:14.279036  4519 layer_factory.hpp:77] Creating layer Eltwise4
I1023 09:39:14.279042  4519 net.cpp:84] Creating Layer Eltwise4
I1023 09:39:14.279045  4519 net.cpp:406] Eltwise4 <- Convolution8
I1023 09:39:14.279048  4519 net.cpp:406] Eltwise4 <- Convolution10
I1023 09:39:14.279052  4519 net.cpp:380] Eltwise4 -> Eltwise4
I1023 09:39:14.279070  4519 net.cpp:122] Setting up Eltwise4
I1023 09:39:14.279075  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.279078  4519 net.cpp:137] Memory required for data: 1148026912
I1023 09:39:14.279079  4519 layer_factory.hpp:77] Creating layer penlu9
I1023 09:39:14.279085  4519 net.cpp:84] Creating Layer penlu9
I1023 09:39:14.279088  4519 net.cpp:406] penlu9 <- Eltwise4
I1023 09:39:14.279091  4519 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I1023 09:39:14.279870  4519 net.cpp:122] Setting up penlu9
I1023 09:39:14.279880  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.279881  4519 net.cpp:137] Memory required for data: 1160871968
I1023 09:39:14.279886  4519 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I1023 09:39:14.279893  4519 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I1023 09:39:14.279896  4519 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I1023 09:39:14.279899  4519 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I1023 09:39:14.279906  4519 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I1023 09:39:14.279932  4519 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I1023 09:39:14.279937  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.279939  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.279942  4519 net.cpp:137] Memory required for data: 1186562080
I1023 09:39:14.279944  4519 layer_factory.hpp:77] Creating layer Convolution11
I1023 09:39:14.279950  4519 net.cpp:84] Creating Layer Convolution11
I1023 09:39:14.279953  4519 net.cpp:406] Convolution11 <- Eltwise4_penlu9_0_split_0
I1023 09:39:14.279966  4519 net.cpp:380] Convolution11 -> Convolution11
I1023 09:39:14.281064  4519 net.cpp:122] Setting up Convolution11
I1023 09:39:14.281076  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.281080  4519 net.cpp:137] Memory required for data: 1199407136
I1023 09:39:14.281083  4519 layer_factory.hpp:77] Creating layer BatchNorm11
I1023 09:39:14.281090  4519 net.cpp:84] Creating Layer BatchNorm11
I1023 09:39:14.281092  4519 net.cpp:406] BatchNorm11 <- Convolution11
I1023 09:39:14.281096  4519 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1023 09:39:14.281241  4519 net.cpp:122] Setting up BatchNorm11
I1023 09:39:14.281250  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.281253  4519 net.cpp:137] Memory required for data: 1212252192
I1023 09:39:14.281261  4519 layer_factory.hpp:77] Creating layer Scale11
I1023 09:39:14.281270  4519 net.cpp:84] Creating Layer Scale11
I1023 09:39:14.281275  4519 net.cpp:406] Scale11 <- Convolution11
I1023 09:39:14.281281  4519 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1023 09:39:14.281327  4519 layer_factory.hpp:77] Creating layer Scale11
I1023 09:39:14.281447  4519 net.cpp:122] Setting up Scale11
I1023 09:39:14.281455  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.281457  4519 net.cpp:137] Memory required for data: 1225097248
I1023 09:39:14.281462  4519 layer_factory.hpp:77] Creating layer penlu10
I1023 09:39:14.281469  4519 net.cpp:84] Creating Layer penlu10
I1023 09:39:14.281473  4519 net.cpp:406] penlu10 <- Convolution11
I1023 09:39:14.281478  4519 net.cpp:367] penlu10 -> Convolution11 (in-place)
I1023 09:39:14.282306  4519 net.cpp:122] Setting up penlu10
I1023 09:39:14.282315  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.282327  4519 net.cpp:137] Memory required for data: 1237942304
I1023 09:39:14.282332  4519 layer_factory.hpp:77] Creating layer Convolution12
I1023 09:39:14.282341  4519 net.cpp:84] Creating Layer Convolution12
I1023 09:39:14.282344  4519 net.cpp:406] Convolution12 <- Convolution11
I1023 09:39:14.282349  4519 net.cpp:380] Convolution12 -> Convolution12
I1023 09:39:14.283567  4519 net.cpp:122] Setting up Convolution12
I1023 09:39:14.283577  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.283581  4519 net.cpp:137] Memory required for data: 1250787360
I1023 09:39:14.283584  4519 layer_factory.hpp:77] Creating layer BatchNorm12
I1023 09:39:14.283591  4519 net.cpp:84] Creating Layer BatchNorm12
I1023 09:39:14.283596  4519 net.cpp:406] BatchNorm12 <- Convolution12
I1023 09:39:14.283598  4519 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1023 09:39:14.283762  4519 net.cpp:122] Setting up BatchNorm12
I1023 09:39:14.283768  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.283771  4519 net.cpp:137] Memory required for data: 1263632416
I1023 09:39:14.283776  4519 layer_factory.hpp:77] Creating layer Scale12
I1023 09:39:14.283780  4519 net.cpp:84] Creating Layer Scale12
I1023 09:39:14.283784  4519 net.cpp:406] Scale12 <- Convolution12
I1023 09:39:14.283787  4519 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1023 09:39:14.283816  4519 layer_factory.hpp:77] Creating layer Scale12
I1023 09:39:14.283907  4519 net.cpp:122] Setting up Scale12
I1023 09:39:14.283912  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.283915  4519 net.cpp:137] Memory required for data: 1276477472
I1023 09:39:14.283920  4519 layer_factory.hpp:77] Creating layer Eltwise5
I1023 09:39:14.283926  4519 net.cpp:84] Creating Layer Eltwise5
I1023 09:39:14.283928  4519 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I1023 09:39:14.283931  4519 net.cpp:406] Eltwise5 <- Convolution12
I1023 09:39:14.283936  4519 net.cpp:380] Eltwise5 -> Eltwise5
I1023 09:39:14.283953  4519 net.cpp:122] Setting up Eltwise5
I1023 09:39:14.283970  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.283972  4519 net.cpp:137] Memory required for data: 1289322528
I1023 09:39:14.283974  4519 layer_factory.hpp:77] Creating layer penlu11
I1023 09:39:14.283982  4519 net.cpp:84] Creating Layer penlu11
I1023 09:39:14.283985  4519 net.cpp:406] penlu11 <- Eltwise5
I1023 09:39:14.283989  4519 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I1023 09:39:14.284796  4519 net.cpp:122] Setting up penlu11
I1023 09:39:14.284806  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.284809  4519 net.cpp:137] Memory required for data: 1302167584
I1023 09:39:14.284814  4519 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I1023 09:39:14.284821  4519 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I1023 09:39:14.284824  4519 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I1023 09:39:14.284827  4519 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I1023 09:39:14.284833  4519 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I1023 09:39:14.284859  4519 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I1023 09:39:14.284864  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.284868  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.284870  4519 net.cpp:137] Memory required for data: 1327857696
I1023 09:39:14.284873  4519 layer_factory.hpp:77] Creating layer Convolution13
I1023 09:39:14.284879  4519 net.cpp:84] Creating Layer Convolution13
I1023 09:39:14.284883  4519 net.cpp:406] Convolution13 <- Eltwise5_penlu11_0_split_0
I1023 09:39:14.284888  4519 net.cpp:380] Convolution13 -> Convolution13
I1023 09:39:14.286000  4519 net.cpp:122] Setting up Convolution13
I1023 09:39:14.286010  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.286015  4519 net.cpp:137] Memory required for data: 1340702752
I1023 09:39:14.286031  4519 layer_factory.hpp:77] Creating layer BatchNorm13
I1023 09:39:14.286044  4519 net.cpp:84] Creating Layer BatchNorm13
I1023 09:39:14.286048  4519 net.cpp:406] BatchNorm13 <- Convolution13
I1023 09:39:14.286053  4519 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1023 09:39:14.286206  4519 net.cpp:122] Setting up BatchNorm13
I1023 09:39:14.286212  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.286216  4519 net.cpp:137] Memory required for data: 1353547808
I1023 09:39:14.286221  4519 layer_factory.hpp:77] Creating layer Scale13
I1023 09:39:14.286226  4519 net.cpp:84] Creating Layer Scale13
I1023 09:39:14.286228  4519 net.cpp:406] Scale13 <- Convolution13
I1023 09:39:14.286231  4519 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1023 09:39:14.286260  4519 layer_factory.hpp:77] Creating layer Scale13
I1023 09:39:14.286350  4519 net.cpp:122] Setting up Scale13
I1023 09:39:14.286356  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.286360  4519 net.cpp:137] Memory required for data: 1366392864
I1023 09:39:14.286363  4519 layer_factory.hpp:77] Creating layer penlu12
I1023 09:39:14.286370  4519 net.cpp:84] Creating Layer penlu12
I1023 09:39:14.286372  4519 net.cpp:406] penlu12 <- Convolution13
I1023 09:39:14.286376  4519 net.cpp:367] penlu12 -> Convolution13 (in-place)
I1023 09:39:14.287170  4519 net.cpp:122] Setting up penlu12
I1023 09:39:14.287180  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.287183  4519 net.cpp:137] Memory required for data: 1379237920
I1023 09:39:14.287189  4519 layer_factory.hpp:77] Creating layer Convolution14
I1023 09:39:14.287196  4519 net.cpp:84] Creating Layer Convolution14
I1023 09:39:14.287200  4519 net.cpp:406] Convolution14 <- Convolution13
I1023 09:39:14.287204  4519 net.cpp:380] Convolution14 -> Convolution14
I1023 09:39:14.288321  4519 net.cpp:122] Setting up Convolution14
I1023 09:39:14.288333  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.288337  4519 net.cpp:137] Memory required for data: 1392082976
I1023 09:39:14.288353  4519 layer_factory.hpp:77] Creating layer BatchNorm14
I1023 09:39:14.288373  4519 net.cpp:84] Creating Layer BatchNorm14
I1023 09:39:14.288378  4519 net.cpp:406] BatchNorm14 <- Convolution14
I1023 09:39:14.288390  4519 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1023 09:39:14.288540  4519 net.cpp:122] Setting up BatchNorm14
I1023 09:39:14.288545  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.288558  4519 net.cpp:137] Memory required for data: 1404928032
I1023 09:39:14.288563  4519 layer_factory.hpp:77] Creating layer Scale14
I1023 09:39:14.288568  4519 net.cpp:84] Creating Layer Scale14
I1023 09:39:14.288570  4519 net.cpp:406] Scale14 <- Convolution14
I1023 09:39:14.288574  4519 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1023 09:39:14.288610  4519 layer_factory.hpp:77] Creating layer Scale14
I1023 09:39:14.288720  4519 net.cpp:122] Setting up Scale14
I1023 09:39:14.288725  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.288738  4519 net.cpp:137] Memory required for data: 1417773088
I1023 09:39:14.288741  4519 layer_factory.hpp:77] Creating layer Eltwise6
I1023 09:39:14.288746  4519 net.cpp:84] Creating Layer Eltwise6
I1023 09:39:14.288750  4519 net.cpp:406] Eltwise6 <- Eltwise5_penlu11_0_split_1
I1023 09:39:14.288753  4519 net.cpp:406] Eltwise6 <- Convolution14
I1023 09:39:14.288756  4519 net.cpp:380] Eltwise6 -> Eltwise6
I1023 09:39:14.288782  4519 net.cpp:122] Setting up Eltwise6
I1023 09:39:14.288786  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.288789  4519 net.cpp:137] Memory required for data: 1430618144
I1023 09:39:14.288790  4519 layer_factory.hpp:77] Creating layer penlu13
I1023 09:39:14.288805  4519 net.cpp:84] Creating Layer penlu13
I1023 09:39:14.288808  4519 net.cpp:406] penlu13 <- Eltwise6
I1023 09:39:14.288811  4519 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I1023 09:39:14.289635  4519 net.cpp:122] Setting up penlu13
I1023 09:39:14.289644  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.289649  4519 net.cpp:137] Memory required for data: 1443463200
I1023 09:39:14.289664  4519 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I1023 09:39:14.289669  4519 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I1023 09:39:14.289672  4519 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I1023 09:39:14.289676  4519 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I1023 09:39:14.289681  4519 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I1023 09:39:14.289710  4519 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I1023 09:39:14.289714  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.289718  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.289721  4519 net.cpp:137] Memory required for data: 1469153312
I1023 09:39:14.289723  4519 layer_factory.hpp:77] Creating layer Convolution15
I1023 09:39:14.289731  4519 net.cpp:84] Creating Layer Convolution15
I1023 09:39:14.289734  4519 net.cpp:406] Convolution15 <- Eltwise6_penlu13_0_split_0
I1023 09:39:14.289739  4519 net.cpp:380] Convolution15 -> Convolution15
I1023 09:39:14.290689  4519 net.cpp:122] Setting up Convolution15
I1023 09:39:14.290699  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.290702  4519 net.cpp:137] Memory required for data: 1475575840
I1023 09:39:14.290707  4519 layer_factory.hpp:77] Creating layer BatchNorm15
I1023 09:39:14.290714  4519 net.cpp:84] Creating Layer BatchNorm15
I1023 09:39:14.290717  4519 net.cpp:406] BatchNorm15 <- Convolution15
I1023 09:39:14.290721  4519 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1023 09:39:14.290865  4519 net.cpp:122] Setting up BatchNorm15
I1023 09:39:14.290870  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.290874  4519 net.cpp:137] Memory required for data: 1481998368
I1023 09:39:14.290879  4519 layer_factory.hpp:77] Creating layer Scale15
I1023 09:39:14.290884  4519 net.cpp:84] Creating Layer Scale15
I1023 09:39:14.290886  4519 net.cpp:406] Scale15 <- Convolution15
I1023 09:39:14.290890  4519 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1023 09:39:14.290918  4519 layer_factory.hpp:77] Creating layer Scale15
I1023 09:39:14.291002  4519 net.cpp:122] Setting up Scale15
I1023 09:39:14.291007  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.291010  4519 net.cpp:137] Memory required for data: 1488420896
I1023 09:39:14.291014  4519 layer_factory.hpp:77] Creating layer Convolution16
I1023 09:39:14.291023  4519 net.cpp:84] Creating Layer Convolution16
I1023 09:39:14.291026  4519 net.cpp:406] Convolution16 <- Eltwise6_penlu13_0_split_1
I1023 09:39:14.291030  4519 net.cpp:380] Convolution16 -> Convolution16
I1023 09:39:14.292321  4519 net.cpp:122] Setting up Convolution16
I1023 09:39:14.292332  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.292335  4519 net.cpp:137] Memory required for data: 1494843424
I1023 09:39:14.292341  4519 layer_factory.hpp:77] Creating layer BatchNorm16
I1023 09:39:14.292346  4519 net.cpp:84] Creating Layer BatchNorm16
I1023 09:39:14.292351  4519 net.cpp:406] BatchNorm16 <- Convolution16
I1023 09:39:14.292354  4519 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1023 09:39:14.292495  4519 net.cpp:122] Setting up BatchNorm16
I1023 09:39:14.292501  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.292503  4519 net.cpp:137] Memory required for data: 1501265952
I1023 09:39:14.292508  4519 layer_factory.hpp:77] Creating layer Scale16
I1023 09:39:14.292513  4519 net.cpp:84] Creating Layer Scale16
I1023 09:39:14.292516  4519 net.cpp:406] Scale16 <- Convolution16
I1023 09:39:14.292520  4519 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1023 09:39:14.292548  4519 layer_factory.hpp:77] Creating layer Scale16
I1023 09:39:14.292634  4519 net.cpp:122] Setting up Scale16
I1023 09:39:14.292639  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.292641  4519 net.cpp:137] Memory required for data: 1507688480
I1023 09:39:14.292645  4519 layer_factory.hpp:77] Creating layer penlu14
I1023 09:39:14.292651  4519 net.cpp:84] Creating Layer penlu14
I1023 09:39:14.292660  4519 net.cpp:406] penlu14 <- Convolution16
I1023 09:39:14.292665  4519 net.cpp:367] penlu14 -> Convolution16 (in-place)
I1023 09:39:14.292912  4519 net.cpp:122] Setting up penlu14
I1023 09:39:14.292917  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.292920  4519 net.cpp:137] Memory required for data: 1514111008
I1023 09:39:14.292925  4519 layer_factory.hpp:77] Creating layer Convolution17
I1023 09:39:14.292933  4519 net.cpp:84] Creating Layer Convolution17
I1023 09:39:14.292937  4519 net.cpp:406] Convolution17 <- Convolution16
I1023 09:39:14.292940  4519 net.cpp:380] Convolution17 -> Convolution17
I1023 09:39:14.294288  4519 net.cpp:122] Setting up Convolution17
I1023 09:39:14.294296  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.294301  4519 net.cpp:137] Memory required for data: 1520533536
I1023 09:39:14.294304  4519 layer_factory.hpp:77] Creating layer BatchNorm17
I1023 09:39:14.294309  4519 net.cpp:84] Creating Layer BatchNorm17
I1023 09:39:14.294312  4519 net.cpp:406] BatchNorm17 <- Convolution17
I1023 09:39:14.294317  4519 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1023 09:39:14.294458  4519 net.cpp:122] Setting up BatchNorm17
I1023 09:39:14.294463  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.294466  4519 net.cpp:137] Memory required for data: 1526956064
I1023 09:39:14.294471  4519 layer_factory.hpp:77] Creating layer Scale17
I1023 09:39:14.294476  4519 net.cpp:84] Creating Layer Scale17
I1023 09:39:14.294479  4519 net.cpp:406] Scale17 <- Convolution17
I1023 09:39:14.294483  4519 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1023 09:39:14.294510  4519 layer_factory.hpp:77] Creating layer Scale17
I1023 09:39:14.294595  4519 net.cpp:122] Setting up Scale17
I1023 09:39:14.294600  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.294602  4519 net.cpp:137] Memory required for data: 1533378592
I1023 09:39:14.294606  4519 layer_factory.hpp:77] Creating layer Eltwise7
I1023 09:39:14.294610  4519 net.cpp:84] Creating Layer Eltwise7
I1023 09:39:14.294615  4519 net.cpp:406] Eltwise7 <- Convolution15
I1023 09:39:14.294616  4519 net.cpp:406] Eltwise7 <- Convolution17
I1023 09:39:14.294620  4519 net.cpp:380] Eltwise7 -> Eltwise7
I1023 09:39:14.294638  4519 net.cpp:122] Setting up Eltwise7
I1023 09:39:14.294643  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.294646  4519 net.cpp:137] Memory required for data: 1539801120
I1023 09:39:14.294648  4519 layer_factory.hpp:77] Creating layer penlu15
I1023 09:39:14.294653  4519 net.cpp:84] Creating Layer penlu15
I1023 09:39:14.294656  4519 net.cpp:406] penlu15 <- Eltwise7
I1023 09:39:14.294661  4519 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I1023 09:39:14.295378  4519 net.cpp:122] Setting up penlu15
I1023 09:39:14.295387  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.295389  4519 net.cpp:137] Memory required for data: 1546223648
I1023 09:39:14.295394  4519 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I1023 09:39:14.295399  4519 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I1023 09:39:14.295402  4519 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I1023 09:39:14.295405  4519 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I1023 09:39:14.295410  4519 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I1023 09:39:14.295435  4519 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I1023 09:39:14.295439  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.295442  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.295444  4519 net.cpp:137] Memory required for data: 1559068704
I1023 09:39:14.295447  4519 layer_factory.hpp:77] Creating layer Convolution18
I1023 09:39:14.295452  4519 net.cpp:84] Creating Layer Convolution18
I1023 09:39:14.295455  4519 net.cpp:406] Convolution18 <- Eltwise7_penlu15_0_split_0
I1023 09:39:14.295459  4519 net.cpp:380] Convolution18 -> Convolution18
I1023 09:39:14.297518  4519 net.cpp:122] Setting up Convolution18
I1023 09:39:14.297535  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.297538  4519 net.cpp:137] Memory required for data: 1565491232
I1023 09:39:14.297544  4519 layer_factory.hpp:77] Creating layer BatchNorm18
I1023 09:39:14.297549  4519 net.cpp:84] Creating Layer BatchNorm18
I1023 09:39:14.297551  4519 net.cpp:406] BatchNorm18 <- Convolution18
I1023 09:39:14.297555  4519 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1023 09:39:14.297703  4519 net.cpp:122] Setting up BatchNorm18
I1023 09:39:14.297708  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.297709  4519 net.cpp:137] Memory required for data: 1571913760
I1023 09:39:14.297714  4519 layer_factory.hpp:77] Creating layer Scale18
I1023 09:39:14.297720  4519 net.cpp:84] Creating Layer Scale18
I1023 09:39:14.297722  4519 net.cpp:406] Scale18 <- Convolution18
I1023 09:39:14.297725  4519 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1023 09:39:14.297754  4519 layer_factory.hpp:77] Creating layer Scale18
I1023 09:39:14.297840  4519 net.cpp:122] Setting up Scale18
I1023 09:39:14.297844  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.297847  4519 net.cpp:137] Memory required for data: 1578336288
I1023 09:39:14.297850  4519 layer_factory.hpp:77] Creating layer penlu16
I1023 09:39:14.297855  4519 net.cpp:84] Creating Layer penlu16
I1023 09:39:14.297858  4519 net.cpp:406] penlu16 <- Convolution18
I1023 09:39:14.297863  4519 net.cpp:367] penlu16 -> Convolution18 (in-place)
I1023 09:39:14.298060  4519 net.cpp:122] Setting up penlu16
I1023 09:39:14.298064  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.298066  4519 net.cpp:137] Memory required for data: 1584758816
I1023 09:39:14.298071  4519 layer_factory.hpp:77] Creating layer Convolution19
I1023 09:39:14.298077  4519 net.cpp:84] Creating Layer Convolution19
I1023 09:39:14.298080  4519 net.cpp:406] Convolution19 <- Convolution18
I1023 09:39:14.298084  4519 net.cpp:380] Convolution19 -> Convolution19
I1023 09:39:14.300310  4519 net.cpp:122] Setting up Convolution19
I1023 09:39:14.300320  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.300323  4519 net.cpp:137] Memory required for data: 1591181344
I1023 09:39:14.300328  4519 layer_factory.hpp:77] Creating layer BatchNorm19
I1023 09:39:14.300333  4519 net.cpp:84] Creating Layer BatchNorm19
I1023 09:39:14.300335  4519 net.cpp:406] BatchNorm19 <- Convolution19
I1023 09:39:14.300339  4519 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1023 09:39:14.300482  4519 net.cpp:122] Setting up BatchNorm19
I1023 09:39:14.300485  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.300488  4519 net.cpp:137] Memory required for data: 1597603872
I1023 09:39:14.300493  4519 layer_factory.hpp:77] Creating layer Scale19
I1023 09:39:14.300496  4519 net.cpp:84] Creating Layer Scale19
I1023 09:39:14.300499  4519 net.cpp:406] Scale19 <- Convolution19
I1023 09:39:14.300503  4519 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1023 09:39:14.300531  4519 layer_factory.hpp:77] Creating layer Scale19
I1023 09:39:14.300616  4519 net.cpp:122] Setting up Scale19
I1023 09:39:14.300621  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.300622  4519 net.cpp:137] Memory required for data: 1604026400
I1023 09:39:14.300626  4519 layer_factory.hpp:77] Creating layer Eltwise8
I1023 09:39:14.300631  4519 net.cpp:84] Creating Layer Eltwise8
I1023 09:39:14.300632  4519 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I1023 09:39:14.300635  4519 net.cpp:406] Eltwise8 <- Convolution19
I1023 09:39:14.300638  4519 net.cpp:380] Eltwise8 -> Eltwise8
I1023 09:39:14.300655  4519 net.cpp:122] Setting up Eltwise8
I1023 09:39:14.300659  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.300660  4519 net.cpp:137] Memory required for data: 1610448928
I1023 09:39:14.300663  4519 layer_factory.hpp:77] Creating layer penlu17
I1023 09:39:14.300668  4519 net.cpp:84] Creating Layer penlu17
I1023 09:39:14.300670  4519 net.cpp:406] penlu17 <- Eltwise8
I1023 09:39:14.300674  4519 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I1023 09:39:14.301396  4519 net.cpp:122] Setting up penlu17
I1023 09:39:14.301404  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.301406  4519 net.cpp:137] Memory required for data: 1616871456
I1023 09:39:14.301411  4519 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I1023 09:39:14.301416  4519 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I1023 09:39:14.301419  4519 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I1023 09:39:14.301422  4519 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I1023 09:39:14.301427  4519 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I1023 09:39:14.301453  4519 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I1023 09:39:14.301457  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.301460  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.301462  4519 net.cpp:137] Memory required for data: 1629716512
I1023 09:39:14.301465  4519 layer_factory.hpp:77] Creating layer Convolution20
I1023 09:39:14.301471  4519 net.cpp:84] Creating Layer Convolution20
I1023 09:39:14.301475  4519 net.cpp:406] Convolution20 <- Eltwise8_penlu17_0_split_0
I1023 09:39:14.301478  4519 net.cpp:380] Convolution20 -> Convolution20
I1023 09:39:14.303871  4519 net.cpp:122] Setting up Convolution20
I1023 09:39:14.303880  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.303882  4519 net.cpp:137] Memory required for data: 1636139040
I1023 09:39:14.303887  4519 layer_factory.hpp:77] Creating layer BatchNorm20
I1023 09:39:14.303894  4519 net.cpp:84] Creating Layer BatchNorm20
I1023 09:39:14.303895  4519 net.cpp:406] BatchNorm20 <- Convolution20
I1023 09:39:14.303900  4519 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1023 09:39:14.304064  4519 net.cpp:122] Setting up BatchNorm20
I1023 09:39:14.304069  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.304070  4519 net.cpp:137] Memory required for data: 1642561568
I1023 09:39:14.304075  4519 layer_factory.hpp:77] Creating layer Scale20
I1023 09:39:14.304080  4519 net.cpp:84] Creating Layer Scale20
I1023 09:39:14.304082  4519 net.cpp:406] Scale20 <- Convolution20
I1023 09:39:14.304085  4519 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1023 09:39:14.304113  4519 layer_factory.hpp:77] Creating layer Scale20
I1023 09:39:14.304198  4519 net.cpp:122] Setting up Scale20
I1023 09:39:14.304203  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.304204  4519 net.cpp:137] Memory required for data: 1648984096
I1023 09:39:14.304208  4519 layer_factory.hpp:77] Creating layer penlu18
I1023 09:39:14.304214  4519 net.cpp:84] Creating Layer penlu18
I1023 09:39:14.304216  4519 net.cpp:406] penlu18 <- Convolution20
I1023 09:39:14.304219  4519 net.cpp:367] penlu18 -> Convolution20 (in-place)
I1023 09:39:14.304411  4519 net.cpp:122] Setting up penlu18
I1023 09:39:14.304416  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.304419  4519 net.cpp:137] Memory required for data: 1655406624
I1023 09:39:14.304422  4519 layer_factory.hpp:77] Creating layer Convolution21
I1023 09:39:14.304430  4519 net.cpp:84] Creating Layer Convolution21
I1023 09:39:14.304431  4519 net.cpp:406] Convolution21 <- Convolution20
I1023 09:39:14.304435  4519 net.cpp:380] Convolution21 -> Convolution21
I1023 09:39:14.306103  4519 net.cpp:122] Setting up Convolution21
I1023 09:39:14.306113  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.306114  4519 net.cpp:137] Memory required for data: 1661829152
I1023 09:39:14.306119  4519 layer_factory.hpp:77] Creating layer BatchNorm21
I1023 09:39:14.306124  4519 net.cpp:84] Creating Layer BatchNorm21
I1023 09:39:14.306128  4519 net.cpp:406] BatchNorm21 <- Convolution21
I1023 09:39:14.306131  4519 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1023 09:39:14.306274  4519 net.cpp:122] Setting up BatchNorm21
I1023 09:39:14.306279  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.306282  4519 net.cpp:137] Memory required for data: 1668251680
I1023 09:39:14.306285  4519 layer_factory.hpp:77] Creating layer Scale21
I1023 09:39:14.306298  4519 net.cpp:84] Creating Layer Scale21
I1023 09:39:14.306300  4519 net.cpp:406] Scale21 <- Convolution21
I1023 09:39:14.306303  4519 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1023 09:39:14.306332  4519 layer_factory.hpp:77] Creating layer Scale21
I1023 09:39:14.306416  4519 net.cpp:122] Setting up Scale21
I1023 09:39:14.306421  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.306422  4519 net.cpp:137] Memory required for data: 1674674208
I1023 09:39:14.306427  4519 layer_factory.hpp:77] Creating layer Eltwise9
I1023 09:39:14.306432  4519 net.cpp:84] Creating Layer Eltwise9
I1023 09:39:14.306433  4519 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I1023 09:39:14.306437  4519 net.cpp:406] Eltwise9 <- Convolution21
I1023 09:39:14.306440  4519 net.cpp:380] Eltwise9 -> Eltwise9
I1023 09:39:14.306455  4519 net.cpp:122] Setting up Eltwise9
I1023 09:39:14.306459  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.306462  4519 net.cpp:137] Memory required for data: 1681096736
I1023 09:39:14.306463  4519 layer_factory.hpp:77] Creating layer penlu19
I1023 09:39:14.306468  4519 net.cpp:84] Creating Layer penlu19
I1023 09:39:14.306471  4519 net.cpp:406] penlu19 <- Eltwise9
I1023 09:39:14.306474  4519 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I1023 09:39:14.307169  4519 net.cpp:122] Setting up penlu19
I1023 09:39:14.307178  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.307179  4519 net.cpp:137] Memory required for data: 1687519264
I1023 09:39:14.307184  4519 layer_factory.hpp:77] Creating layer Pooling1
I1023 09:39:14.307189  4519 net.cpp:84] Creating Layer Pooling1
I1023 09:39:14.307193  4519 net.cpp:406] Pooling1 <- Eltwise9
I1023 09:39:14.307195  4519 net.cpp:380] Pooling1 -> Pooling1
I1023 09:39:14.307346  4519 net.cpp:122] Setting up Pooling1
I1023 09:39:14.307353  4519 net.cpp:129] Top shape: 8 64 1 1 (512)
I1023 09:39:14.307354  4519 net.cpp:137] Memory required for data: 1687521312
I1023 09:39:14.307356  4519 layer_factory.hpp:77] Creating layer InnerProduct1
I1023 09:39:14.307365  4519 net.cpp:84] Creating Layer InnerProduct1
I1023 09:39:14.307368  4519 net.cpp:406] InnerProduct1 <- Pooling1
I1023 09:39:14.307371  4519 net.cpp:380] InnerProduct1 -> InnerProduct1
I1023 09:39:14.307469  4519 net.cpp:122] Setting up InnerProduct1
I1023 09:39:14.307473  4519 net.cpp:129] Top shape: 8 10 (80)
I1023 09:39:14.307476  4519 net.cpp:137] Memory required for data: 1687521632
I1023 09:39:14.307479  4519 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1023 09:39:14.307483  4519 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1023 09:39:14.307485  4519 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I1023 09:39:14.307488  4519 net.cpp:406] SoftmaxWithLoss1 <- Data2
I1023 09:39:14.307493  4519 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1023 09:39:14.307498  4519 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1023 09:39:14.308058  4519 net.cpp:122] Setting up SoftmaxWithLoss1
I1023 09:39:14.308065  4519 net.cpp:129] Top shape: (1)
I1023 09:39:14.308068  4519 net.cpp:132]     with loss weight 1
I1023 09:39:14.308080  4519 net.cpp:137] Memory required for data: 1687521636
I1023 09:39:14.308084  4519 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1023 09:39:14.308085  4519 net.cpp:198] InnerProduct1 needs backward computation.
I1023 09:39:14.308087  4519 net.cpp:198] Pooling1 needs backward computation.
I1023 09:39:14.308090  4519 net.cpp:198] penlu19 needs backward computation.
I1023 09:39:14.308091  4519 net.cpp:198] Eltwise9 needs backward computation.
I1023 09:39:14.308094  4519 net.cpp:198] Scale21 needs backward computation.
I1023 09:39:14.308096  4519 net.cpp:198] BatchNorm21 needs backward computation.
I1023 09:39:14.308099  4519 net.cpp:198] Convolution21 needs backward computation.
I1023 09:39:14.308100  4519 net.cpp:198] penlu18 needs backward computation.
I1023 09:39:14.308102  4519 net.cpp:198] Scale20 needs backward computation.
I1023 09:39:14.308104  4519 net.cpp:198] BatchNorm20 needs backward computation.
I1023 09:39:14.308113  4519 net.cpp:198] Convolution20 needs backward computation.
I1023 09:39:14.308116  4519 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I1023 09:39:14.308118  4519 net.cpp:198] penlu17 needs backward computation.
I1023 09:39:14.308120  4519 net.cpp:198] Eltwise8 needs backward computation.
I1023 09:39:14.308122  4519 net.cpp:198] Scale19 needs backward computation.
I1023 09:39:14.308125  4519 net.cpp:198] BatchNorm19 needs backward computation.
I1023 09:39:14.308126  4519 net.cpp:198] Convolution19 needs backward computation.
I1023 09:39:14.308130  4519 net.cpp:198] penlu16 needs backward computation.
I1023 09:39:14.308131  4519 net.cpp:198] Scale18 needs backward computation.
I1023 09:39:14.308133  4519 net.cpp:198] BatchNorm18 needs backward computation.
I1023 09:39:14.308135  4519 net.cpp:198] Convolution18 needs backward computation.
I1023 09:39:14.308137  4519 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I1023 09:39:14.308140  4519 net.cpp:198] penlu15 needs backward computation.
I1023 09:39:14.308142  4519 net.cpp:198] Eltwise7 needs backward computation.
I1023 09:39:14.308145  4519 net.cpp:198] Scale17 needs backward computation.
I1023 09:39:14.308147  4519 net.cpp:198] BatchNorm17 needs backward computation.
I1023 09:39:14.308149  4519 net.cpp:198] Convolution17 needs backward computation.
I1023 09:39:14.308151  4519 net.cpp:198] penlu14 needs backward computation.
I1023 09:39:14.308153  4519 net.cpp:198] Scale16 needs backward computation.
I1023 09:39:14.308156  4519 net.cpp:198] BatchNorm16 needs backward computation.
I1023 09:39:14.308157  4519 net.cpp:198] Convolution16 needs backward computation.
I1023 09:39:14.308161  4519 net.cpp:198] Scale15 needs backward computation.
I1023 09:39:14.308162  4519 net.cpp:198] BatchNorm15 needs backward computation.
I1023 09:39:14.308164  4519 net.cpp:198] Convolution15 needs backward computation.
I1023 09:39:14.308166  4519 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I1023 09:39:14.308169  4519 net.cpp:198] penlu13 needs backward computation.
I1023 09:39:14.308171  4519 net.cpp:198] Eltwise6 needs backward computation.
I1023 09:39:14.308174  4519 net.cpp:198] Scale14 needs backward computation.
I1023 09:39:14.308176  4519 net.cpp:198] BatchNorm14 needs backward computation.
I1023 09:39:14.308178  4519 net.cpp:198] Convolution14 needs backward computation.
I1023 09:39:14.308181  4519 net.cpp:198] penlu12 needs backward computation.
I1023 09:39:14.308183  4519 net.cpp:198] Scale13 needs backward computation.
I1023 09:39:14.308185  4519 net.cpp:198] BatchNorm13 needs backward computation.
I1023 09:39:14.308187  4519 net.cpp:198] Convolution13 needs backward computation.
I1023 09:39:14.308189  4519 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I1023 09:39:14.308192  4519 net.cpp:198] penlu11 needs backward computation.
I1023 09:39:14.308194  4519 net.cpp:198] Eltwise5 needs backward computation.
I1023 09:39:14.308197  4519 net.cpp:198] Scale12 needs backward computation.
I1023 09:39:14.308199  4519 net.cpp:198] BatchNorm12 needs backward computation.
I1023 09:39:14.308202  4519 net.cpp:198] Convolution12 needs backward computation.
I1023 09:39:14.308203  4519 net.cpp:198] penlu10 needs backward computation.
I1023 09:39:14.308205  4519 net.cpp:198] Scale11 needs backward computation.
I1023 09:39:14.308208  4519 net.cpp:198] BatchNorm11 needs backward computation.
I1023 09:39:14.308210  4519 net.cpp:198] Convolution11 needs backward computation.
I1023 09:39:14.308212  4519 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I1023 09:39:14.308215  4519 net.cpp:198] penlu9 needs backward computation.
I1023 09:39:14.308218  4519 net.cpp:198] Eltwise4 needs backward computation.
I1023 09:39:14.308220  4519 net.cpp:198] Scale10 needs backward computation.
I1023 09:39:14.308223  4519 net.cpp:198] BatchNorm10 needs backward computation.
I1023 09:39:14.308224  4519 net.cpp:198] Convolution10 needs backward computation.
I1023 09:39:14.308230  4519 net.cpp:198] penlu8 needs backward computation.
I1023 09:39:14.308233  4519 net.cpp:198] Scale9 needs backward computation.
I1023 09:39:14.308234  4519 net.cpp:198] BatchNorm9 needs backward computation.
I1023 09:39:14.308238  4519 net.cpp:198] Convolution9 needs backward computation.
I1023 09:39:14.308239  4519 net.cpp:198] Scale8 needs backward computation.
I1023 09:39:14.308241  4519 net.cpp:198] BatchNorm8 needs backward computation.
I1023 09:39:14.308243  4519 net.cpp:198] Convolution8 needs backward computation.
I1023 09:39:14.308248  4519 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I1023 09:39:14.308249  4519 net.cpp:198] penlu7 needs backward computation.
I1023 09:39:14.308253  4519 net.cpp:198] Eltwise3 needs backward computation.
I1023 09:39:14.308254  4519 net.cpp:198] Scale7 needs backward computation.
I1023 09:39:14.308257  4519 net.cpp:198] BatchNorm7 needs backward computation.
I1023 09:39:14.308259  4519 net.cpp:198] Convolution7 needs backward computation.
I1023 09:39:14.308261  4519 net.cpp:198] penlu6 needs backward computation.
I1023 09:39:14.308264  4519 net.cpp:198] Scale6 needs backward computation.
I1023 09:39:14.308266  4519 net.cpp:198] BatchNorm6 needs backward computation.
I1023 09:39:14.308269  4519 net.cpp:198] Convolution6 needs backward computation.
I1023 09:39:14.308270  4519 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I1023 09:39:14.308274  4519 net.cpp:198] penlu5 needs backward computation.
I1023 09:39:14.308275  4519 net.cpp:198] Eltwise2 needs backward computation.
I1023 09:39:14.308277  4519 net.cpp:198] Scale5 needs backward computation.
I1023 09:39:14.308280  4519 net.cpp:198] BatchNorm5 needs backward computation.
I1023 09:39:14.308282  4519 net.cpp:198] Convolution5 needs backward computation.
I1023 09:39:14.308284  4519 net.cpp:198] penlu4 needs backward computation.
I1023 09:39:14.308286  4519 net.cpp:198] Scale4 needs backward computation.
I1023 09:39:14.308288  4519 net.cpp:198] BatchNorm4 needs backward computation.
I1023 09:39:14.308290  4519 net.cpp:198] Convolution4 needs backward computation.
I1023 09:39:14.308293  4519 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I1023 09:39:14.308295  4519 net.cpp:198] penlu3 needs backward computation.
I1023 09:39:14.308297  4519 net.cpp:198] Eltwise1 needs backward computation.
I1023 09:39:14.308300  4519 net.cpp:198] Scale3 needs backward computation.
I1023 09:39:14.308302  4519 net.cpp:198] BatchNorm3 needs backward computation.
I1023 09:39:14.308305  4519 net.cpp:198] Convolution3 needs backward computation.
I1023 09:39:14.308307  4519 net.cpp:198] penlu2 needs backward computation.
I1023 09:39:14.308310  4519 net.cpp:198] Scale2 needs backward computation.
I1023 09:39:14.308311  4519 net.cpp:198] BatchNorm2 needs backward computation.
I1023 09:39:14.308313  4519 net.cpp:198] Convolution2 needs backward computation.
I1023 09:39:14.308316  4519 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I1023 09:39:14.308318  4519 net.cpp:198] penlu1 needs backward computation.
I1023 09:39:14.308321  4519 net.cpp:198] Scale1 needs backward computation.
I1023 09:39:14.308323  4519 net.cpp:198] BatchNorm1 needs backward computation.
I1023 09:39:14.308326  4519 net.cpp:198] Convolution1 needs backward computation.
I1023 09:39:14.308327  4519 net.cpp:200] Data1 does not need backward computation.
I1023 09:39:14.308329  4519 net.cpp:242] This network produces output SoftmaxWithLoss1
I1023 09:39:14.308362  4519 net.cpp:255] Network initialization done.
I1023 09:39:14.310034  4519 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/English_orange/neural/res20/res20_penlu_gauss.prototxt
I1023 09:39:14.310040  4519 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1023 09:39:14.310045  4519 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/English_orange/neural/res20/res20_penlu_gauss.prototxt
I1023 09:39:14.310117  4519 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I1023 09:39:14.310591  4519 net.cpp:51] Initializing net from parameters: 
name: "resnet"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_file: "/home/x306/caffe/xn/English_orange/data/orange1_mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/English_orange/data/val1_lmdb"
    batch_size: 8
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
layer {
  name: "Accuracy1"
  type: "Accuracy"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "Accuracy1"
  include {
    phase: TEST
  }
}
I1023 09:39:14.310838  4519 layer_factory.hpp:77] Creating layer Data1
I1023 09:39:14.310875  4519 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/English_orange/data/val1_lmdb
I1023 09:39:14.310886  4519 net.cpp:84] Creating Layer Data1
I1023 09:39:14.310889  4519 net.cpp:380] Data1 -> Data1
I1023 09:39:14.310896  4519 net.cpp:380] Data1 -> Data2
I1023 09:39:14.310901  4519 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/English_orange/data/orange1_mean.binaryproto
I1023 09:39:14.312132  4519 data_layer.cpp:45] output data size: 8,3,224,224
I1023 09:39:14.320947  4519 net.cpp:122] Setting up Data1
I1023 09:39:14.320967  4519 net.cpp:129] Top shape: 8 3 224 224 (1204224)
I1023 09:39:14.320972  4519 net.cpp:129] Top shape: 8 (8)
I1023 09:39:14.320974  4519 net.cpp:137] Memory required for data: 4816928
I1023 09:39:14.320979  4519 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I1023 09:39:14.320988  4519 net.cpp:84] Creating Layer Data2_Data1_1_split
I1023 09:39:14.320991  4519 net.cpp:406] Data2_Data1_1_split <- Data2
I1023 09:39:14.320996  4519 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I1023 09:39:14.321002  4519 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I1023 09:39:14.321072  4519 net.cpp:122] Setting up Data2_Data1_1_split
I1023 09:39:14.321079  4519 net.cpp:129] Top shape: 8 (8)
I1023 09:39:14.321080  4519 net.cpp:129] Top shape: 8 (8)
I1023 09:39:14.321082  4519 net.cpp:137] Memory required for data: 4816992
I1023 09:39:14.321084  4519 layer_factory.hpp:77] Creating layer Convolution1
I1023 09:39:14.321094  4519 net.cpp:84] Creating Layer Convolution1
I1023 09:39:14.321096  4519 net.cpp:406] Convolution1 <- Data1
I1023 09:39:14.321100  4519 net.cpp:380] Convolution1 -> Convolution1
I1023 09:39:14.322507  4519 net.cpp:122] Setting up Convolution1
I1023 09:39:14.322517  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.322520  4519 net.cpp:137] Memory required for data: 30507104
I1023 09:39:14.322526  4519 layer_factory.hpp:77] Creating layer BatchNorm1
I1023 09:39:14.322532  4519 net.cpp:84] Creating Layer BatchNorm1
I1023 09:39:14.322535  4519 net.cpp:406] BatchNorm1 <- Convolution1
I1023 09:39:14.322538  4519 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1023 09:39:14.322715  4519 net.cpp:122] Setting up BatchNorm1
I1023 09:39:14.322720  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.322721  4519 net.cpp:137] Memory required for data: 56197216
I1023 09:39:14.322728  4519 layer_factory.hpp:77] Creating layer Scale1
I1023 09:39:14.322734  4519 net.cpp:84] Creating Layer Scale1
I1023 09:39:14.322736  4519 net.cpp:406] Scale1 <- Convolution1
I1023 09:39:14.322741  4519 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1023 09:39:14.322768  4519 layer_factory.hpp:77] Creating layer Scale1
I1023 09:39:14.322912  4519 net.cpp:122] Setting up Scale1
I1023 09:39:14.322917  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.322919  4519 net.cpp:137] Memory required for data: 81887328
I1023 09:39:14.322923  4519 layer_factory.hpp:77] Creating layer penlu1
I1023 09:39:14.322929  4519 net.cpp:84] Creating Layer penlu1
I1023 09:39:14.322932  4519 net.cpp:406] penlu1 <- Convolution1
I1023 09:39:14.322935  4519 net.cpp:367] penlu1 -> Convolution1 (in-place)
I1023 09:39:14.324318  4519 net.cpp:122] Setting up penlu1
I1023 09:39:14.324331  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.324334  4519 net.cpp:137] Memory required for data: 107577440
I1023 09:39:14.324343  4519 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I1023 09:39:14.324349  4519 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I1023 09:39:14.324352  4519 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I1023 09:39:14.324357  4519 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I1023 09:39:14.324362  4519 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I1023 09:39:14.324391  4519 net.cpp:122] Setting up Convolution1_penlu1_0_split
I1023 09:39:14.324395  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.324398  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.324400  4519 net.cpp:137] Memory required for data: 158957664
I1023 09:39:14.324403  4519 layer_factory.hpp:77] Creating layer Convolution2
I1023 09:39:14.324410  4519 net.cpp:84] Creating Layer Convolution2
I1023 09:39:14.324412  4519 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I1023 09:39:14.324416  4519 net.cpp:380] Convolution2 -> Convolution2
I1023 09:39:14.325093  4519 net.cpp:122] Setting up Convolution2
I1023 09:39:14.325101  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.325103  4519 net.cpp:137] Memory required for data: 184647776
I1023 09:39:14.325107  4519 layer_factory.hpp:77] Creating layer BatchNorm2
I1023 09:39:14.325114  4519 net.cpp:84] Creating Layer BatchNorm2
I1023 09:39:14.325116  4519 net.cpp:406] BatchNorm2 <- Convolution2
I1023 09:39:14.325120  4519 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1023 09:39:14.325301  4519 net.cpp:122] Setting up BatchNorm2
I1023 09:39:14.325306  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.325309  4519 net.cpp:137] Memory required for data: 210337888
I1023 09:39:14.325330  4519 layer_factory.hpp:77] Creating layer Scale2
I1023 09:39:14.325335  4519 net.cpp:84] Creating Layer Scale2
I1023 09:39:14.325338  4519 net.cpp:406] Scale2 <- Convolution2
I1023 09:39:14.325341  4519 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1023 09:39:14.325376  4519 layer_factory.hpp:77] Creating layer Scale2
I1023 09:39:14.325520  4519 net.cpp:122] Setting up Scale2
I1023 09:39:14.325525  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.325526  4519 net.cpp:137] Memory required for data: 236028000
I1023 09:39:14.325532  4519 layer_factory.hpp:77] Creating layer penlu2
I1023 09:39:14.325538  4519 net.cpp:84] Creating Layer penlu2
I1023 09:39:14.325541  4519 net.cpp:406] penlu2 <- Convolution2
I1023 09:39:14.325544  4519 net.cpp:367] penlu2 -> Convolution2 (in-place)
I1023 09:39:14.326840  4519 net.cpp:122] Setting up penlu2
I1023 09:39:14.326853  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.326855  4519 net.cpp:137] Memory required for data: 261718112
I1023 09:39:14.326860  4519 layer_factory.hpp:77] Creating layer Convolution3
I1023 09:39:14.326869  4519 net.cpp:84] Creating Layer Convolution3
I1023 09:39:14.326872  4519 net.cpp:406] Convolution3 <- Convolution2
I1023 09:39:14.326876  4519 net.cpp:380] Convolution3 -> Convolution3
I1023 09:39:14.328893  4519 net.cpp:122] Setting up Convolution3
I1023 09:39:14.328908  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.328912  4519 net.cpp:137] Memory required for data: 287408224
I1023 09:39:14.328917  4519 layer_factory.hpp:77] Creating layer BatchNorm3
I1023 09:39:14.328924  4519 net.cpp:84] Creating Layer BatchNorm3
I1023 09:39:14.328928  4519 net.cpp:406] BatchNorm3 <- Convolution3
I1023 09:39:14.328933  4519 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1023 09:39:14.329109  4519 net.cpp:122] Setting up BatchNorm3
I1023 09:39:14.329114  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.329116  4519 net.cpp:137] Memory required for data: 313098336
I1023 09:39:14.329123  4519 layer_factory.hpp:77] Creating layer Scale3
I1023 09:39:14.329128  4519 net.cpp:84] Creating Layer Scale3
I1023 09:39:14.329129  4519 net.cpp:406] Scale3 <- Convolution3
I1023 09:39:14.329133  4519 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1023 09:39:14.329166  4519 layer_factory.hpp:77] Creating layer Scale3
I1023 09:39:14.329288  4519 net.cpp:122] Setting up Scale3
I1023 09:39:14.329291  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.329293  4519 net.cpp:137] Memory required for data: 338788448
I1023 09:39:14.329298  4519 layer_factory.hpp:77] Creating layer Eltwise1
I1023 09:39:14.329303  4519 net.cpp:84] Creating Layer Eltwise1
I1023 09:39:14.329305  4519 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I1023 09:39:14.329308  4519 net.cpp:406] Eltwise1 <- Convolution3
I1023 09:39:14.329311  4519 net.cpp:380] Eltwise1 -> Eltwise1
I1023 09:39:14.329330  4519 net.cpp:122] Setting up Eltwise1
I1023 09:39:14.329334  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.329335  4519 net.cpp:137] Memory required for data: 364478560
I1023 09:39:14.329337  4519 layer_factory.hpp:77] Creating layer penlu3
I1023 09:39:14.329344  4519 net.cpp:84] Creating Layer penlu3
I1023 09:39:14.329345  4519 net.cpp:406] penlu3 <- Eltwise1
I1023 09:39:14.329349  4519 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I1023 09:39:14.330603  4519 net.cpp:122] Setting up penlu3
I1023 09:39:14.330618  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.330621  4519 net.cpp:137] Memory required for data: 390168672
I1023 09:39:14.330626  4519 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I1023 09:39:14.330634  4519 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I1023 09:39:14.330636  4519 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I1023 09:39:14.330641  4519 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I1023 09:39:14.330646  4519 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I1023 09:39:14.330693  4519 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I1023 09:39:14.330698  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.330701  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.330703  4519 net.cpp:137] Memory required for data: 441548896
I1023 09:39:14.330705  4519 layer_factory.hpp:77] Creating layer Convolution4
I1023 09:39:14.330713  4519 net.cpp:84] Creating Layer Convolution4
I1023 09:39:14.330715  4519 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I1023 09:39:14.330719  4519 net.cpp:380] Convolution4 -> Convolution4
I1023 09:39:14.331892  4519 net.cpp:122] Setting up Convolution4
I1023 09:39:14.331902  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.331904  4519 net.cpp:137] Memory required for data: 467239008
I1023 09:39:14.331909  4519 layer_factory.hpp:77] Creating layer BatchNorm4
I1023 09:39:14.331914  4519 net.cpp:84] Creating Layer BatchNorm4
I1023 09:39:14.331918  4519 net.cpp:406] BatchNorm4 <- Convolution4
I1023 09:39:14.331921  4519 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1023 09:39:14.332548  4519 net.cpp:122] Setting up BatchNorm4
I1023 09:39:14.332558  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.332561  4519 net.cpp:137] Memory required for data: 492929120
I1023 09:39:14.332571  4519 layer_factory.hpp:77] Creating layer Scale4
I1023 09:39:14.332576  4519 net.cpp:84] Creating Layer Scale4
I1023 09:39:14.332579  4519 net.cpp:406] Scale4 <- Convolution4
I1023 09:39:14.332582  4519 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1023 09:39:14.332617  4519 layer_factory.hpp:77] Creating layer Scale4
I1023 09:39:14.332759  4519 net.cpp:122] Setting up Scale4
I1023 09:39:14.332764  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.332767  4519 net.cpp:137] Memory required for data: 518619232
I1023 09:39:14.332770  4519 layer_factory.hpp:77] Creating layer penlu4
I1023 09:39:14.332777  4519 net.cpp:84] Creating Layer penlu4
I1023 09:39:14.332778  4519 net.cpp:406] penlu4 <- Convolution4
I1023 09:39:14.332782  4519 net.cpp:367] penlu4 -> Convolution4 (in-place)
I1023 09:39:14.334074  4519 net.cpp:122] Setting up penlu4
I1023 09:39:14.334086  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.334089  4519 net.cpp:137] Memory required for data: 544309344
I1023 09:39:14.334095  4519 layer_factory.hpp:77] Creating layer Convolution5
I1023 09:39:14.334105  4519 net.cpp:84] Creating Layer Convolution5
I1023 09:39:14.334107  4519 net.cpp:406] Convolution5 <- Convolution4
I1023 09:39:14.334112  4519 net.cpp:380] Convolution5 -> Convolution5
I1023 09:39:14.335593  4519 net.cpp:122] Setting up Convolution5
I1023 09:39:14.335604  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.335608  4519 net.cpp:137] Memory required for data: 569999456
I1023 09:39:14.335613  4519 layer_factory.hpp:77] Creating layer BatchNorm5
I1023 09:39:14.335618  4519 net.cpp:84] Creating Layer BatchNorm5
I1023 09:39:14.335623  4519 net.cpp:406] BatchNorm5 <- Convolution5
I1023 09:39:14.335625  4519 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1023 09:39:14.335813  4519 net.cpp:122] Setting up BatchNorm5
I1023 09:39:14.335817  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.335819  4519 net.cpp:137] Memory required for data: 595689568
I1023 09:39:14.335824  4519 layer_factory.hpp:77] Creating layer Scale5
I1023 09:39:14.335829  4519 net.cpp:84] Creating Layer Scale5
I1023 09:39:14.335831  4519 net.cpp:406] Scale5 <- Convolution5
I1023 09:39:14.335835  4519 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1023 09:39:14.335868  4519 layer_factory.hpp:77] Creating layer Scale5
I1023 09:39:14.336580  4519 net.cpp:122] Setting up Scale5
I1023 09:39:14.336588  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.336591  4519 net.cpp:137] Memory required for data: 621379680
I1023 09:39:14.336596  4519 layer_factory.hpp:77] Creating layer Eltwise2
I1023 09:39:14.336601  4519 net.cpp:84] Creating Layer Eltwise2
I1023 09:39:14.336632  4519 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I1023 09:39:14.336635  4519 net.cpp:406] Eltwise2 <- Convolution5
I1023 09:39:14.336639  4519 net.cpp:380] Eltwise2 -> Eltwise2
I1023 09:39:14.336660  4519 net.cpp:122] Setting up Eltwise2
I1023 09:39:14.336664  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.336666  4519 net.cpp:137] Memory required for data: 647069792
I1023 09:39:14.336668  4519 layer_factory.hpp:77] Creating layer penlu5
I1023 09:39:14.336674  4519 net.cpp:84] Creating Layer penlu5
I1023 09:39:14.336676  4519 net.cpp:406] penlu5 <- Eltwise2
I1023 09:39:14.336680  4519 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I1023 09:39:14.337954  4519 net.cpp:122] Setting up penlu5
I1023 09:39:14.337962  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.337965  4519 net.cpp:137] Memory required for data: 672759904
I1023 09:39:14.337970  4519 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I1023 09:39:14.337975  4519 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I1023 09:39:14.337977  4519 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I1023 09:39:14.337981  4519 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I1023 09:39:14.337985  4519 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I1023 09:39:14.338014  4519 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I1023 09:39:14.338018  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.338022  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.338024  4519 net.cpp:137] Memory required for data: 724140128
I1023 09:39:14.338027  4519 layer_factory.hpp:77] Creating layer Convolution6
I1023 09:39:14.338033  4519 net.cpp:84] Creating Layer Convolution6
I1023 09:39:14.338035  4519 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I1023 09:39:14.338039  4519 net.cpp:380] Convolution6 -> Convolution6
I1023 09:39:14.339136  4519 net.cpp:122] Setting up Convolution6
I1023 09:39:14.339146  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.339149  4519 net.cpp:137] Memory required for data: 749830240
I1023 09:39:14.339154  4519 layer_factory.hpp:77] Creating layer BatchNorm6
I1023 09:39:14.339159  4519 net.cpp:84] Creating Layer BatchNorm6
I1023 09:39:14.339162  4519 net.cpp:406] BatchNorm6 <- Convolution6
I1023 09:39:14.339166  4519 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1023 09:39:14.339351  4519 net.cpp:122] Setting up BatchNorm6
I1023 09:39:14.339355  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.339357  4519 net.cpp:137] Memory required for data: 775520352
I1023 09:39:14.339362  4519 layer_factory.hpp:77] Creating layer Scale6
I1023 09:39:14.339367  4519 net.cpp:84] Creating Layer Scale6
I1023 09:39:14.339370  4519 net.cpp:406] Scale6 <- Convolution6
I1023 09:39:14.339372  4519 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1023 09:39:14.339404  4519 layer_factory.hpp:77] Creating layer Scale6
I1023 09:39:14.339551  4519 net.cpp:122] Setting up Scale6
I1023 09:39:14.339556  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.339558  4519 net.cpp:137] Memory required for data: 801210464
I1023 09:39:14.339561  4519 layer_factory.hpp:77] Creating layer penlu6
I1023 09:39:14.339567  4519 net.cpp:84] Creating Layer penlu6
I1023 09:39:14.339570  4519 net.cpp:406] penlu6 <- Convolution6
I1023 09:39:14.339573  4519 net.cpp:367] penlu6 -> Convolution6 (in-place)
I1023 09:39:14.340879  4519 net.cpp:122] Setting up penlu6
I1023 09:39:14.340893  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.340895  4519 net.cpp:137] Memory required for data: 826900576
I1023 09:39:14.340901  4519 layer_factory.hpp:77] Creating layer Convolution7
I1023 09:39:14.340910  4519 net.cpp:84] Creating Layer Convolution7
I1023 09:39:14.340914  4519 net.cpp:406] Convolution7 <- Convolution6
I1023 09:39:14.340919  4519 net.cpp:380] Convolution7 -> Convolution7
I1023 09:39:14.342432  4519 net.cpp:122] Setting up Convolution7
I1023 09:39:14.342442  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.342458  4519 net.cpp:137] Memory required for data: 852590688
I1023 09:39:14.342464  4519 layer_factory.hpp:77] Creating layer BatchNorm7
I1023 09:39:14.342473  4519 net.cpp:84] Creating Layer BatchNorm7
I1023 09:39:14.342475  4519 net.cpp:406] BatchNorm7 <- Convolution7
I1023 09:39:14.342479  4519 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1023 09:39:14.342706  4519 net.cpp:122] Setting up BatchNorm7
I1023 09:39:14.342711  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.342715  4519 net.cpp:137] Memory required for data: 878280800
I1023 09:39:14.342725  4519 layer_factory.hpp:77] Creating layer Scale7
I1023 09:39:14.342730  4519 net.cpp:84] Creating Layer Scale7
I1023 09:39:14.342733  4519 net.cpp:406] Scale7 <- Convolution7
I1023 09:39:14.342736  4519 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1023 09:39:14.342779  4519 layer_factory.hpp:77] Creating layer Scale7
I1023 09:39:14.342923  4519 net.cpp:122] Setting up Scale7
I1023 09:39:14.342928  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.342931  4519 net.cpp:137] Memory required for data: 903970912
I1023 09:39:14.342934  4519 layer_factory.hpp:77] Creating layer Eltwise3
I1023 09:39:14.342939  4519 net.cpp:84] Creating Layer Eltwise3
I1023 09:39:14.342941  4519 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I1023 09:39:14.342944  4519 net.cpp:406] Eltwise3 <- Convolution7
I1023 09:39:14.342948  4519 net.cpp:380] Eltwise3 -> Eltwise3
I1023 09:39:14.342967  4519 net.cpp:122] Setting up Eltwise3
I1023 09:39:14.342970  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.342972  4519 net.cpp:137] Memory required for data: 929661024
I1023 09:39:14.342974  4519 layer_factory.hpp:77] Creating layer penlu7
I1023 09:39:14.342980  4519 net.cpp:84] Creating Layer penlu7
I1023 09:39:14.342983  4519 net.cpp:406] penlu7 <- Eltwise3
I1023 09:39:14.342986  4519 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I1023 09:39:14.344347  4519 net.cpp:122] Setting up penlu7
I1023 09:39:14.344362  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.344364  4519 net.cpp:137] Memory required for data: 955351136
I1023 09:39:14.344370  4519 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I1023 09:39:14.344377  4519 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I1023 09:39:14.344379  4519 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I1023 09:39:14.344384  4519 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I1023 09:39:14.344393  4519 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I1023 09:39:14.344449  4519 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I1023 09:39:14.344454  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.344456  4519 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 09:39:14.344458  4519 net.cpp:137] Memory required for data: 1006731360
I1023 09:39:14.344461  4519 layer_factory.hpp:77] Creating layer Convolution8
I1023 09:39:14.344468  4519 net.cpp:84] Creating Layer Convolution8
I1023 09:39:14.344471  4519 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I1023 09:39:14.344475  4519 net.cpp:380] Convolution8 -> Convolution8
I1023 09:39:14.345607  4519 net.cpp:122] Setting up Convolution8
I1023 09:39:14.345616  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.345619  4519 net.cpp:137] Memory required for data: 1019576416
I1023 09:39:14.345623  4519 layer_factory.hpp:77] Creating layer BatchNorm8
I1023 09:39:14.345629  4519 net.cpp:84] Creating Layer BatchNorm8
I1023 09:39:14.345633  4519 net.cpp:406] BatchNorm8 <- Convolution8
I1023 09:39:14.345636  4519 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1023 09:39:14.345796  4519 net.cpp:122] Setting up BatchNorm8
I1023 09:39:14.345801  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.345803  4519 net.cpp:137] Memory required for data: 1032421472
I1023 09:39:14.345808  4519 layer_factory.hpp:77] Creating layer Scale8
I1023 09:39:14.345813  4519 net.cpp:84] Creating Layer Scale8
I1023 09:39:14.345824  4519 net.cpp:406] Scale8 <- Convolution8
I1023 09:39:14.345829  4519 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1023 09:39:14.345860  4519 layer_factory.hpp:77] Creating layer Scale8
I1023 09:39:14.345971  4519 net.cpp:122] Setting up Scale8
I1023 09:39:14.345976  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.345978  4519 net.cpp:137] Memory required for data: 1045266528
I1023 09:39:14.345983  4519 layer_factory.hpp:77] Creating layer Convolution9
I1023 09:39:14.345989  4519 net.cpp:84] Creating Layer Convolution9
I1023 09:39:14.345993  4519 net.cpp:406] Convolution9 <- Eltwise3_penlu7_0_split_1
I1023 09:39:14.345998  4519 net.cpp:380] Convolution9 -> Convolution9
I1023 09:39:14.347143  4519 net.cpp:122] Setting up Convolution9
I1023 09:39:14.347152  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.347154  4519 net.cpp:137] Memory required for data: 1058111584
I1023 09:39:14.347158  4519 layer_factory.hpp:77] Creating layer BatchNorm9
I1023 09:39:14.347164  4519 net.cpp:84] Creating Layer BatchNorm9
I1023 09:39:14.347167  4519 net.cpp:406] BatchNorm9 <- Convolution9
I1023 09:39:14.347170  4519 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1023 09:39:14.347332  4519 net.cpp:122] Setting up BatchNorm9
I1023 09:39:14.347337  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.347338  4519 net.cpp:137] Memory required for data: 1070956640
I1023 09:39:14.347343  4519 layer_factory.hpp:77] Creating layer Scale9
I1023 09:39:14.347347  4519 net.cpp:84] Creating Layer Scale9
I1023 09:39:14.347350  4519 net.cpp:406] Scale9 <- Convolution9
I1023 09:39:14.347353  4519 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1023 09:39:14.347383  4519 layer_factory.hpp:77] Creating layer Scale9
I1023 09:39:14.347481  4519 net.cpp:122] Setting up Scale9
I1023 09:39:14.347486  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.347487  4519 net.cpp:137] Memory required for data: 1083801696
I1023 09:39:14.347491  4519 layer_factory.hpp:77] Creating layer penlu8
I1023 09:39:14.347497  4519 net.cpp:84] Creating Layer penlu8
I1023 09:39:14.347499  4519 net.cpp:406] penlu8 <- Convolution9
I1023 09:39:14.347503  4519 net.cpp:367] penlu8 -> Convolution9 (in-place)
I1023 09:39:14.348373  4519 net.cpp:122] Setting up penlu8
I1023 09:39:14.348382  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.348386  4519 net.cpp:137] Memory required for data: 1096646752
I1023 09:39:14.348390  4519 layer_factory.hpp:77] Creating layer Convolution10
I1023 09:39:14.348397  4519 net.cpp:84] Creating Layer Convolution10
I1023 09:39:14.348400  4519 net.cpp:406] Convolution10 <- Convolution9
I1023 09:39:14.348407  4519 net.cpp:380] Convolution10 -> Convolution10
I1023 09:39:14.350491  4519 net.cpp:122] Setting up Convolution10
I1023 09:39:14.350500  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.350503  4519 net.cpp:137] Memory required for data: 1109491808
I1023 09:39:14.350508  4519 layer_factory.hpp:77] Creating layer BatchNorm10
I1023 09:39:14.350513  4519 net.cpp:84] Creating Layer BatchNorm10
I1023 09:39:14.350517  4519 net.cpp:406] BatchNorm10 <- Convolution10
I1023 09:39:14.350520  4519 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1023 09:39:14.350685  4519 net.cpp:122] Setting up BatchNorm10
I1023 09:39:14.350690  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.350692  4519 net.cpp:137] Memory required for data: 1122336864
I1023 09:39:14.350697  4519 layer_factory.hpp:77] Creating layer Scale10
I1023 09:39:14.350702  4519 net.cpp:84] Creating Layer Scale10
I1023 09:39:14.350703  4519 net.cpp:406] Scale10 <- Convolution10
I1023 09:39:14.350706  4519 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1023 09:39:14.350739  4519 layer_factory.hpp:77] Creating layer Scale10
I1023 09:39:14.350831  4519 net.cpp:122] Setting up Scale10
I1023 09:39:14.350836  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.350837  4519 net.cpp:137] Memory required for data: 1135181920
I1023 09:39:14.350842  4519 layer_factory.hpp:77] Creating layer Eltwise4
I1023 09:39:14.350858  4519 net.cpp:84] Creating Layer Eltwise4
I1023 09:39:14.350862  4519 net.cpp:406] Eltwise4 <- Convolution8
I1023 09:39:14.350864  4519 net.cpp:406] Eltwise4 <- Convolution10
I1023 09:39:14.350868  4519 net.cpp:380] Eltwise4 -> Eltwise4
I1023 09:39:14.350888  4519 net.cpp:122] Setting up Eltwise4
I1023 09:39:14.350891  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.350893  4519 net.cpp:137] Memory required for data: 1148026976
I1023 09:39:14.350895  4519 layer_factory.hpp:77] Creating layer penlu9
I1023 09:39:14.350901  4519 net.cpp:84] Creating Layer penlu9
I1023 09:39:14.350903  4519 net.cpp:406] penlu9 <- Eltwise4
I1023 09:39:14.350908  4519 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I1023 09:39:14.351745  4519 net.cpp:122] Setting up penlu9
I1023 09:39:14.351753  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.351755  4519 net.cpp:137] Memory required for data: 1160872032
I1023 09:39:14.351760  4519 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I1023 09:39:14.351765  4519 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I1023 09:39:14.351768  4519 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I1023 09:39:14.351771  4519 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I1023 09:39:14.351776  4519 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I1023 09:39:14.351804  4519 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I1023 09:39:14.351809  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.351811  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.351814  4519 net.cpp:137] Memory required for data: 1186562144
I1023 09:39:14.351815  4519 layer_factory.hpp:77] Creating layer Convolution11
I1023 09:39:14.351822  4519 net.cpp:84] Creating Layer Convolution11
I1023 09:39:14.351825  4519 net.cpp:406] Convolution11 <- Eltwise4_penlu9_0_split_0
I1023 09:39:14.351830  4519 net.cpp:380] Convolution11 -> Convolution11
I1023 09:39:14.353024  4519 net.cpp:122] Setting up Convolution11
I1023 09:39:14.353032  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.353035  4519 net.cpp:137] Memory required for data: 1199407200
I1023 09:39:14.353039  4519 layer_factory.hpp:77] Creating layer BatchNorm11
I1023 09:39:14.353044  4519 net.cpp:84] Creating Layer BatchNorm11
I1023 09:39:14.353046  4519 net.cpp:406] BatchNorm11 <- Convolution11
I1023 09:39:14.353051  4519 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1023 09:39:14.353209  4519 net.cpp:122] Setting up BatchNorm11
I1023 09:39:14.353212  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.353214  4519 net.cpp:137] Memory required for data: 1212252256
I1023 09:39:14.353219  4519 layer_factory.hpp:77] Creating layer Scale11
I1023 09:39:14.353224  4519 net.cpp:84] Creating Layer Scale11
I1023 09:39:14.353226  4519 net.cpp:406] Scale11 <- Convolution11
I1023 09:39:14.353229  4519 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1023 09:39:14.353258  4519 layer_factory.hpp:77] Creating layer Scale11
I1023 09:39:14.353351  4519 net.cpp:122] Setting up Scale11
I1023 09:39:14.353355  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.353358  4519 net.cpp:137] Memory required for data: 1225097312
I1023 09:39:14.353361  4519 layer_factory.hpp:77] Creating layer penlu10
I1023 09:39:14.353368  4519 net.cpp:84] Creating Layer penlu10
I1023 09:39:14.353370  4519 net.cpp:406] penlu10 <- Convolution11
I1023 09:39:14.353374  4519 net.cpp:367] penlu10 -> Convolution11 (in-place)
I1023 09:39:14.354208  4519 net.cpp:122] Setting up penlu10
I1023 09:39:14.354216  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.354219  4519 net.cpp:137] Memory required for data: 1237942368
I1023 09:39:14.354224  4519 layer_factory.hpp:77] Creating layer Convolution12
I1023 09:39:14.354233  4519 net.cpp:84] Creating Layer Convolution12
I1023 09:39:14.354235  4519 net.cpp:406] Convolution12 <- Convolution11
I1023 09:39:14.354239  4519 net.cpp:380] Convolution12 -> Convolution12
I1023 09:39:14.355041  4519 net.cpp:122] Setting up Convolution12
I1023 09:39:14.355049  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.355052  4519 net.cpp:137] Memory required for data: 1250787424
I1023 09:39:14.355057  4519 layer_factory.hpp:77] Creating layer BatchNorm12
I1023 09:39:14.355063  4519 net.cpp:84] Creating Layer BatchNorm12
I1023 09:39:14.355067  4519 net.cpp:406] BatchNorm12 <- Convolution12
I1023 09:39:14.355069  4519 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1023 09:39:14.355228  4519 net.cpp:122] Setting up BatchNorm12
I1023 09:39:14.355233  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.355235  4519 net.cpp:137] Memory required for data: 1263632480
I1023 09:39:14.355239  4519 layer_factory.hpp:77] Creating layer Scale12
I1023 09:39:14.355244  4519 net.cpp:84] Creating Layer Scale12
I1023 09:39:14.355247  4519 net.cpp:406] Scale12 <- Convolution12
I1023 09:39:14.355250  4519 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1023 09:39:14.355280  4519 layer_factory.hpp:77] Creating layer Scale12
I1023 09:39:14.355381  4519 net.cpp:122] Setting up Scale12
I1023 09:39:14.355386  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.355387  4519 net.cpp:137] Memory required for data: 1276477536
I1023 09:39:14.355391  4519 layer_factory.hpp:77] Creating layer Eltwise5
I1023 09:39:14.355396  4519 net.cpp:84] Creating Layer Eltwise5
I1023 09:39:14.355397  4519 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I1023 09:39:14.355401  4519 net.cpp:406] Eltwise5 <- Convolution12
I1023 09:39:14.355404  4519 net.cpp:380] Eltwise5 -> Eltwise5
I1023 09:39:14.355423  4519 net.cpp:122] Setting up Eltwise5
I1023 09:39:14.355427  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.355429  4519 net.cpp:137] Memory required for data: 1289322592
I1023 09:39:14.355432  4519 layer_factory.hpp:77] Creating layer penlu11
I1023 09:39:14.355435  4519 net.cpp:84] Creating Layer penlu11
I1023 09:39:14.355438  4519 net.cpp:406] penlu11 <- Eltwise5
I1023 09:39:14.355443  4519 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I1023 09:39:14.356289  4519 net.cpp:122] Setting up penlu11
I1023 09:39:14.356297  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.356300  4519 net.cpp:137] Memory required for data: 1302167648
I1023 09:39:14.356305  4519 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I1023 09:39:14.356310  4519 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I1023 09:39:14.356313  4519 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I1023 09:39:14.356317  4519 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I1023 09:39:14.356322  4519 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I1023 09:39:14.356353  4519 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I1023 09:39:14.356356  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.356359  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.356361  4519 net.cpp:137] Memory required for data: 1327857760
I1023 09:39:14.356364  4519 layer_factory.hpp:77] Creating layer Convolution13
I1023 09:39:14.356371  4519 net.cpp:84] Creating Layer Convolution13
I1023 09:39:14.356374  4519 net.cpp:406] Convolution13 <- Eltwise5_penlu11_0_split_0
I1023 09:39:14.356377  4519 net.cpp:380] Convolution13 -> Convolution13
I1023 09:39:14.357534  4519 net.cpp:122] Setting up Convolution13
I1023 09:39:14.357543  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.357547  4519 net.cpp:137] Memory required for data: 1340702816
I1023 09:39:14.357550  4519 layer_factory.hpp:77] Creating layer BatchNorm13
I1023 09:39:14.357555  4519 net.cpp:84] Creating Layer BatchNorm13
I1023 09:39:14.357558  4519 net.cpp:406] BatchNorm13 <- Convolution13
I1023 09:39:14.357563  4519 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1023 09:39:14.357725  4519 net.cpp:122] Setting up BatchNorm13
I1023 09:39:14.357730  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.357733  4519 net.cpp:137] Memory required for data: 1353547872
I1023 09:39:14.357745  4519 layer_factory.hpp:77] Creating layer Scale13
I1023 09:39:14.357750  4519 net.cpp:84] Creating Layer Scale13
I1023 09:39:14.357753  4519 net.cpp:406] Scale13 <- Convolution13
I1023 09:39:14.357756  4519 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1023 09:39:14.357789  4519 layer_factory.hpp:77] Creating layer Scale13
I1023 09:39:14.357889  4519 net.cpp:122] Setting up Scale13
I1023 09:39:14.357894  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.357897  4519 net.cpp:137] Memory required for data: 1366392928
I1023 09:39:14.357900  4519 layer_factory.hpp:77] Creating layer penlu12
I1023 09:39:14.357905  4519 net.cpp:84] Creating Layer penlu12
I1023 09:39:14.357908  4519 net.cpp:406] penlu12 <- Convolution13
I1023 09:39:14.357911  4519 net.cpp:367] penlu12 -> Convolution13 (in-place)
I1023 09:39:14.358755  4519 net.cpp:122] Setting up penlu12
I1023 09:39:14.358764  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.358767  4519 net.cpp:137] Memory required for data: 1379237984
I1023 09:39:14.358772  4519 layer_factory.hpp:77] Creating layer Convolution14
I1023 09:39:14.358783  4519 net.cpp:84] Creating Layer Convolution14
I1023 09:39:14.358785  4519 net.cpp:406] Convolution14 <- Convolution13
I1023 09:39:14.358790  4519 net.cpp:380] Convolution14 -> Convolution14
I1023 09:39:14.359977  4519 net.cpp:122] Setting up Convolution14
I1023 09:39:14.359984  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.359987  4519 net.cpp:137] Memory required for data: 1392083040
I1023 09:39:14.360011  4519 layer_factory.hpp:77] Creating layer BatchNorm14
I1023 09:39:14.360018  4519 net.cpp:84] Creating Layer BatchNorm14
I1023 09:39:14.360020  4519 net.cpp:406] BatchNorm14 <- Convolution14
I1023 09:39:14.360024  4519 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1023 09:39:14.360185  4519 net.cpp:122] Setting up BatchNorm14
I1023 09:39:14.360190  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.360193  4519 net.cpp:137] Memory required for data: 1404928096
I1023 09:39:14.360198  4519 layer_factory.hpp:77] Creating layer Scale14
I1023 09:39:14.360201  4519 net.cpp:84] Creating Layer Scale14
I1023 09:39:14.360203  4519 net.cpp:406] Scale14 <- Convolution14
I1023 09:39:14.360206  4519 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1023 09:39:14.360236  4519 layer_factory.hpp:77] Creating layer Scale14
I1023 09:39:14.360334  4519 net.cpp:122] Setting up Scale14
I1023 09:39:14.360338  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.360340  4519 net.cpp:137] Memory required for data: 1417773152
I1023 09:39:14.360344  4519 layer_factory.hpp:77] Creating layer Eltwise6
I1023 09:39:14.360348  4519 net.cpp:84] Creating Layer Eltwise6
I1023 09:39:14.360352  4519 net.cpp:406] Eltwise6 <- Eltwise5_penlu11_0_split_1
I1023 09:39:14.360354  4519 net.cpp:406] Eltwise6 <- Convolution14
I1023 09:39:14.360357  4519 net.cpp:380] Eltwise6 -> Eltwise6
I1023 09:39:14.360375  4519 net.cpp:122] Setting up Eltwise6
I1023 09:39:14.360379  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.360381  4519 net.cpp:137] Memory required for data: 1430618208
I1023 09:39:14.360383  4519 layer_factory.hpp:77] Creating layer penlu13
I1023 09:39:14.360389  4519 net.cpp:84] Creating Layer penlu13
I1023 09:39:14.360391  4519 net.cpp:406] penlu13 <- Eltwise6
I1023 09:39:14.360394  4519 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I1023 09:39:14.361232  4519 net.cpp:122] Setting up penlu13
I1023 09:39:14.361240  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.361243  4519 net.cpp:137] Memory required for data: 1443463264
I1023 09:39:14.361248  4519 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I1023 09:39:14.361253  4519 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I1023 09:39:14.361255  4519 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I1023 09:39:14.361259  4519 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I1023 09:39:14.361263  4519 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I1023 09:39:14.361304  4519 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I1023 09:39:14.361308  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.361310  4519 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 09:39:14.361312  4519 net.cpp:137] Memory required for data: 1469153376
I1023 09:39:14.361315  4519 layer_factory.hpp:77] Creating layer Convolution15
I1023 09:39:14.361322  4519 net.cpp:84] Creating Layer Convolution15
I1023 09:39:14.361325  4519 net.cpp:406] Convolution15 <- Eltwise6_penlu13_0_split_0
I1023 09:39:14.361330  4519 net.cpp:380] Convolution15 -> Convolution15
I1023 09:39:14.362330  4519 net.cpp:122] Setting up Convolution15
I1023 09:39:14.362339  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.362342  4519 net.cpp:137] Memory required for data: 1475575904
I1023 09:39:14.362346  4519 layer_factory.hpp:77] Creating layer BatchNorm15
I1023 09:39:14.362350  4519 net.cpp:84] Creating Layer BatchNorm15
I1023 09:39:14.362354  4519 net.cpp:406] BatchNorm15 <- Convolution15
I1023 09:39:14.362359  4519 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1023 09:39:14.362519  4519 net.cpp:122] Setting up BatchNorm15
I1023 09:39:14.362524  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.362526  4519 net.cpp:137] Memory required for data: 1481998432
I1023 09:39:14.362530  4519 layer_factory.hpp:77] Creating layer Scale15
I1023 09:39:14.362534  4519 net.cpp:84] Creating Layer Scale15
I1023 09:39:14.362537  4519 net.cpp:406] Scale15 <- Convolution15
I1023 09:39:14.362541  4519 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1023 09:39:14.362571  4519 layer_factory.hpp:77] Creating layer Scale15
I1023 09:39:14.362664  4519 net.cpp:122] Setting up Scale15
I1023 09:39:14.362668  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.362670  4519 net.cpp:137] Memory required for data: 1488420960
I1023 09:39:14.362674  4519 layer_factory.hpp:77] Creating layer Convolution16
I1023 09:39:14.362681  4519 net.cpp:84] Creating Layer Convolution16
I1023 09:39:14.362684  4519 net.cpp:406] Convolution16 <- Eltwise6_penlu13_0_split_1
I1023 09:39:14.362689  4519 net.cpp:380] Convolution16 -> Convolution16
I1023 09:39:14.364053  4519 net.cpp:122] Setting up Convolution16
I1023 09:39:14.364061  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.364063  4519 net.cpp:137] Memory required for data: 1494843488
I1023 09:39:14.364068  4519 layer_factory.hpp:77] Creating layer BatchNorm16
I1023 09:39:14.364073  4519 net.cpp:84] Creating Layer BatchNorm16
I1023 09:39:14.364076  4519 net.cpp:406] BatchNorm16 <- Convolution16
I1023 09:39:14.364080  4519 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1023 09:39:14.364235  4519 net.cpp:122] Setting up BatchNorm16
I1023 09:39:14.364239  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.364243  4519 net.cpp:137] Memory required for data: 1501266016
I1023 09:39:14.364246  4519 layer_factory.hpp:77] Creating layer Scale16
I1023 09:39:14.364253  4519 net.cpp:84] Creating Layer Scale16
I1023 09:39:14.364254  4519 net.cpp:406] Scale16 <- Convolution16
I1023 09:39:14.364258  4519 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1023 09:39:14.364287  4519 layer_factory.hpp:77] Creating layer Scale16
I1023 09:39:14.364378  4519 net.cpp:122] Setting up Scale16
I1023 09:39:14.364383  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.364385  4519 net.cpp:137] Memory required for data: 1507688544
I1023 09:39:14.364388  4519 layer_factory.hpp:77] Creating layer penlu14
I1023 09:39:14.364394  4519 net.cpp:84] Creating Layer penlu14
I1023 09:39:14.364398  4519 net.cpp:406] penlu14 <- Convolution16
I1023 09:39:14.364400  4519 net.cpp:367] penlu14 -> Convolution16 (in-place)
I1023 09:39:14.365149  4519 net.cpp:122] Setting up penlu14
I1023 09:39:14.365157  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.365160  4519 net.cpp:137] Memory required for data: 1514111072
I1023 09:39:14.365165  4519 layer_factory.hpp:77] Creating layer Convolution17
I1023 09:39:14.365180  4519 net.cpp:84] Creating Layer Convolution17
I1023 09:39:14.365183  4519 net.cpp:406] Convolution17 <- Convolution16
I1023 09:39:14.365188  4519 net.cpp:380] Convolution17 -> Convolution17
I1023 09:39:14.367509  4519 net.cpp:122] Setting up Convolution17
I1023 09:39:14.367518  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.367522  4519 net.cpp:137] Memory required for data: 1520533600
I1023 09:39:14.367525  4519 layer_factory.hpp:77] Creating layer BatchNorm17
I1023 09:39:14.367532  4519 net.cpp:84] Creating Layer BatchNorm17
I1023 09:39:14.367534  4519 net.cpp:406] BatchNorm17 <- Convolution17
I1023 09:39:14.367537  4519 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1023 09:39:14.367699  4519 net.cpp:122] Setting up BatchNorm17
I1023 09:39:14.367704  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.367707  4519 net.cpp:137] Memory required for data: 1526956128
I1023 09:39:14.367712  4519 layer_factory.hpp:77] Creating layer Scale17
I1023 09:39:14.367715  4519 net.cpp:84] Creating Layer Scale17
I1023 09:39:14.367717  4519 net.cpp:406] Scale17 <- Convolution17
I1023 09:39:14.367720  4519 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1023 09:39:14.367753  4519 layer_factory.hpp:77] Creating layer Scale17
I1023 09:39:14.367846  4519 net.cpp:122] Setting up Scale17
I1023 09:39:14.367851  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.367853  4519 net.cpp:137] Memory required for data: 1533378656
I1023 09:39:14.367857  4519 layer_factory.hpp:77] Creating layer Eltwise7
I1023 09:39:14.367862  4519 net.cpp:84] Creating Layer Eltwise7
I1023 09:39:14.367866  4519 net.cpp:406] Eltwise7 <- Convolution15
I1023 09:39:14.367867  4519 net.cpp:406] Eltwise7 <- Convolution17
I1023 09:39:14.367871  4519 net.cpp:380] Eltwise7 -> Eltwise7
I1023 09:39:14.367889  4519 net.cpp:122] Setting up Eltwise7
I1023 09:39:14.367893  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.367895  4519 net.cpp:137] Memory required for data: 1539801184
I1023 09:39:14.367897  4519 layer_factory.hpp:77] Creating layer penlu15
I1023 09:39:14.367902  4519 net.cpp:84] Creating Layer penlu15
I1023 09:39:14.367904  4519 net.cpp:406] penlu15 <- Eltwise7
I1023 09:39:14.367908  4519 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I1023 09:39:14.368175  4519 net.cpp:122] Setting up penlu15
I1023 09:39:14.368180  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.368181  4519 net.cpp:137] Memory required for data: 1546223712
I1023 09:39:14.368186  4519 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I1023 09:39:14.368191  4519 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I1023 09:39:14.368192  4519 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I1023 09:39:14.368197  4519 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I1023 09:39:14.368201  4519 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I1023 09:39:14.368228  4519 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I1023 09:39:14.368232  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.368234  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.368237  4519 net.cpp:137] Memory required for data: 1559068768
I1023 09:39:14.368238  4519 layer_factory.hpp:77] Creating layer Convolution18
I1023 09:39:14.368245  4519 net.cpp:84] Creating Layer Convolution18
I1023 09:39:14.368248  4519 net.cpp:406] Convolution18 <- Eltwise7_penlu15_0_split_0
I1023 09:39:14.368252  4519 net.cpp:380] Convolution18 -> Convolution18
I1023 09:39:14.370707  4519 net.cpp:122] Setting up Convolution18
I1023 09:39:14.370714  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.370717  4519 net.cpp:137] Memory required for data: 1565491296
I1023 09:39:14.370723  4519 layer_factory.hpp:77] Creating layer BatchNorm18
I1023 09:39:14.373112  4519 net.cpp:84] Creating Layer BatchNorm18
I1023 09:39:14.373121  4519 net.cpp:406] BatchNorm18 <- Convolution18
I1023 09:39:14.373124  4519 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1023 09:39:14.373322  4519 net.cpp:122] Setting up BatchNorm18
I1023 09:39:14.373328  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.373332  4519 net.cpp:137] Memory required for data: 1571913824
I1023 09:39:14.373337  4519 layer_factory.hpp:77] Creating layer Scale18
I1023 09:39:14.373342  4519 net.cpp:84] Creating Layer Scale18
I1023 09:39:14.373344  4519 net.cpp:406] Scale18 <- Convolution18
I1023 09:39:14.373347  4519 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1023 09:39:14.373383  4519 layer_factory.hpp:77] Creating layer Scale18
I1023 09:39:14.373488  4519 net.cpp:122] Setting up Scale18
I1023 09:39:14.373493  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.373497  4519 net.cpp:137] Memory required for data: 1578336352
I1023 09:39:14.373500  4519 layer_factory.hpp:77] Creating layer penlu16
I1023 09:39:14.373505  4519 net.cpp:84] Creating Layer penlu16
I1023 09:39:14.373508  4519 net.cpp:406] penlu16 <- Convolution18
I1023 09:39:14.373512  4519 net.cpp:367] penlu16 -> Convolution18 (in-place)
I1023 09:39:14.374349  4519 net.cpp:122] Setting up penlu16
I1023 09:39:14.374358  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.374361  4519 net.cpp:137] Memory required for data: 1584758880
I1023 09:39:14.374366  4519 layer_factory.hpp:77] Creating layer Convolution19
I1023 09:39:14.374375  4519 net.cpp:84] Creating Layer Convolution19
I1023 09:39:14.374378  4519 net.cpp:406] Convolution19 <- Convolution18
I1023 09:39:14.374383  4519 net.cpp:380] Convolution19 -> Convolution19
I1023 09:39:14.376430  4519 net.cpp:122] Setting up Convolution19
I1023 09:39:14.376438  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.376441  4519 net.cpp:137] Memory required for data: 1591181408
I1023 09:39:14.376446  4519 layer_factory.hpp:77] Creating layer BatchNorm19
I1023 09:39:14.376452  4519 net.cpp:84] Creating Layer BatchNorm19
I1023 09:39:14.376456  4519 net.cpp:406] BatchNorm19 <- Convolution19
I1023 09:39:14.376459  4519 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1023 09:39:14.376628  4519 net.cpp:122] Setting up BatchNorm19
I1023 09:39:14.376642  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.376646  4519 net.cpp:137] Memory required for data: 1597603936
I1023 09:39:14.376651  4519 layer_factory.hpp:77] Creating layer Scale19
I1023 09:39:14.376655  4519 net.cpp:84] Creating Layer Scale19
I1023 09:39:14.376658  4519 net.cpp:406] Scale19 <- Convolution19
I1023 09:39:14.376662  4519 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1023 09:39:14.376695  4519 layer_factory.hpp:77] Creating layer Scale19
I1023 09:39:14.376816  4519 net.cpp:122] Setting up Scale19
I1023 09:39:14.376821  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.376822  4519 net.cpp:137] Memory required for data: 1604026464
I1023 09:39:14.376827  4519 layer_factory.hpp:77] Creating layer Eltwise8
I1023 09:39:14.376832  4519 net.cpp:84] Creating Layer Eltwise8
I1023 09:39:14.376834  4519 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I1023 09:39:14.376837  4519 net.cpp:406] Eltwise8 <- Convolution19
I1023 09:39:14.376842  4519 net.cpp:380] Eltwise8 -> Eltwise8
I1023 09:39:14.376862  4519 net.cpp:122] Setting up Eltwise8
I1023 09:39:14.376865  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.376868  4519 net.cpp:137] Memory required for data: 1610448992
I1023 09:39:14.376869  4519 layer_factory.hpp:77] Creating layer penlu17
I1023 09:39:14.376875  4519 net.cpp:84] Creating Layer penlu17
I1023 09:39:14.376878  4519 net.cpp:406] penlu17 <- Eltwise8
I1023 09:39:14.376881  4519 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I1023 09:39:14.377148  4519 net.cpp:122] Setting up penlu17
I1023 09:39:14.377152  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.377154  4519 net.cpp:137] Memory required for data: 1616871520
I1023 09:39:14.377159  4519 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I1023 09:39:14.377163  4519 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I1023 09:39:14.377174  4519 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I1023 09:39:14.377179  4519 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I1023 09:39:14.377183  4519 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I1023 09:39:14.377213  4519 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I1023 09:39:14.377218  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.377221  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.377223  4519 net.cpp:137] Memory required for data: 1629716576
I1023 09:39:14.377225  4519 layer_factory.hpp:77] Creating layer Convolution20
I1023 09:39:14.377233  4519 net.cpp:84] Creating Layer Convolution20
I1023 09:39:14.377235  4519 net.cpp:406] Convolution20 <- Eltwise8_penlu17_0_split_0
I1023 09:39:14.377239  4519 net.cpp:380] Convolution20 -> Convolution20
I1023 09:39:14.379420  4519 net.cpp:122] Setting up Convolution20
I1023 09:39:14.379429  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.379432  4519 net.cpp:137] Memory required for data: 1636139104
I1023 09:39:14.379437  4519 layer_factory.hpp:77] Creating layer BatchNorm20
I1023 09:39:14.379442  4519 net.cpp:84] Creating Layer BatchNorm20
I1023 09:39:14.379446  4519 net.cpp:406] BatchNorm20 <- Convolution20
I1023 09:39:14.379449  4519 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1023 09:39:14.379621  4519 net.cpp:122] Setting up BatchNorm20
I1023 09:39:14.379626  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.379628  4519 net.cpp:137] Memory required for data: 1642561632
I1023 09:39:14.379632  4519 layer_factory.hpp:77] Creating layer Scale20
I1023 09:39:14.379637  4519 net.cpp:84] Creating Layer Scale20
I1023 09:39:14.379639  4519 net.cpp:406] Scale20 <- Convolution20
I1023 09:39:14.379642  4519 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1023 09:39:14.379676  4519 layer_factory.hpp:77] Creating layer Scale20
I1023 09:39:14.379778  4519 net.cpp:122] Setting up Scale20
I1023 09:39:14.379783  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.379786  4519 net.cpp:137] Memory required for data: 1648984160
I1023 09:39:14.379789  4519 layer_factory.hpp:77] Creating layer penlu18
I1023 09:39:14.379794  4519 net.cpp:84] Creating Layer penlu18
I1023 09:39:14.379797  4519 net.cpp:406] penlu18 <- Convolution20
I1023 09:39:14.379801  4519 net.cpp:367] penlu18 -> Convolution20 (in-place)
I1023 09:39:14.380578  4519 net.cpp:122] Setting up penlu18
I1023 09:39:14.380586  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.380589  4519 net.cpp:137] Memory required for data: 1655406688
I1023 09:39:14.380594  4519 layer_factory.hpp:77] Creating layer Convolution21
I1023 09:39:14.380601  4519 net.cpp:84] Creating Layer Convolution21
I1023 09:39:14.380604  4519 net.cpp:406] Convolution21 <- Convolution20
I1023 09:39:14.380609  4519 net.cpp:380] Convolution21 -> Convolution21
I1023 09:39:14.382417  4519 net.cpp:122] Setting up Convolution21
I1023 09:39:14.382426  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.382429  4519 net.cpp:137] Memory required for data: 1661829216
I1023 09:39:14.382433  4519 layer_factory.hpp:77] Creating layer BatchNorm21
I1023 09:39:14.382439  4519 net.cpp:84] Creating Layer BatchNorm21
I1023 09:39:14.382442  4519 net.cpp:406] BatchNorm21 <- Convolution21
I1023 09:39:14.382447  4519 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1023 09:39:14.382613  4519 net.cpp:122] Setting up BatchNorm21
I1023 09:39:14.382617  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.382621  4519 net.cpp:137] Memory required for data: 1668251744
I1023 09:39:14.382624  4519 layer_factory.hpp:77] Creating layer Scale21
I1023 09:39:14.382629  4519 net.cpp:84] Creating Layer Scale21
I1023 09:39:14.382632  4519 net.cpp:406] Scale21 <- Convolution21
I1023 09:39:14.382635  4519 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1023 09:39:14.382668  4519 layer_factory.hpp:77] Creating layer Scale21
I1023 09:39:14.382766  4519 net.cpp:122] Setting up Scale21
I1023 09:39:14.382779  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.382781  4519 net.cpp:137] Memory required for data: 1674674272
I1023 09:39:14.382786  4519 layer_factory.hpp:77] Creating layer Eltwise9
I1023 09:39:14.382791  4519 net.cpp:84] Creating Layer Eltwise9
I1023 09:39:14.382794  4519 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I1023 09:39:14.382797  4519 net.cpp:406] Eltwise9 <- Convolution21
I1023 09:39:14.382800  4519 net.cpp:380] Eltwise9 -> Eltwise9
I1023 09:39:14.382820  4519 net.cpp:122] Setting up Eltwise9
I1023 09:39:14.382824  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.382827  4519 net.cpp:137] Memory required for data: 1681096800
I1023 09:39:14.382828  4519 layer_factory.hpp:77] Creating layer penlu19
I1023 09:39:14.382833  4519 net.cpp:84] Creating Layer penlu19
I1023 09:39:14.382836  4519 net.cpp:406] penlu19 <- Eltwise9
I1023 09:39:14.382839  4519 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I1023 09:39:14.383057  4519 net.cpp:122] Setting up penlu19
I1023 09:39:14.383062  4519 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 09:39:14.383064  4519 net.cpp:137] Memory required for data: 1687519328
I1023 09:39:14.383069  4519 layer_factory.hpp:77] Creating layer Pooling1
I1023 09:39:14.383074  4519 net.cpp:84] Creating Layer Pooling1
I1023 09:39:14.383076  4519 net.cpp:406] Pooling1 <- Eltwise9
I1023 09:39:14.383080  4519 net.cpp:380] Pooling1 -> Pooling1
I1023 09:39:14.383224  4519 net.cpp:122] Setting up Pooling1
I1023 09:39:14.383230  4519 net.cpp:129] Top shape: 8 64 1 1 (512)
I1023 09:39:14.383232  4519 net.cpp:137] Memory required for data: 1687521376
I1023 09:39:14.383235  4519 layer_factory.hpp:77] Creating layer InnerProduct1
I1023 09:39:14.383240  4519 net.cpp:84] Creating Layer InnerProduct1
I1023 09:39:14.383242  4519 net.cpp:406] InnerProduct1 <- Pooling1
I1023 09:39:14.383247  4519 net.cpp:380] InnerProduct1 -> InnerProduct1
I1023 09:39:14.383358  4519 net.cpp:122] Setting up InnerProduct1
I1023 09:39:14.383361  4519 net.cpp:129] Top shape: 8 10 (80)
I1023 09:39:14.383364  4519 net.cpp:137] Memory required for data: 1687521696
I1023 09:39:14.383368  4519 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I1023 09:39:14.383371  4519 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I1023 09:39:14.383374  4519 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I1023 09:39:14.383378  4519 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I1023 09:39:14.383381  4519 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I1023 09:39:14.383411  4519 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I1023 09:39:14.383415  4519 net.cpp:129] Top shape: 8 10 (80)
I1023 09:39:14.383419  4519 net.cpp:129] Top shape: 8 10 (80)
I1023 09:39:14.383420  4519 net.cpp:137] Memory required for data: 1687522336
I1023 09:39:14.383422  4519 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1023 09:39:14.383426  4519 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1023 09:39:14.383429  4519 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I1023 09:39:14.383431  4519 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I1023 09:39:14.383435  4519 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1023 09:39:14.383440  4519 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1023 09:39:14.383638  4519 net.cpp:122] Setting up SoftmaxWithLoss1
I1023 09:39:14.383644  4519 net.cpp:129] Top shape: (1)
I1023 09:39:14.383646  4519 net.cpp:132]     with loss weight 1
I1023 09:39:14.383653  4519 net.cpp:137] Memory required for data: 1687522340
I1023 09:39:14.383656  4519 layer_factory.hpp:77] Creating layer Accuracy1
I1023 09:39:14.383661  4519 net.cpp:84] Creating Layer Accuracy1
I1023 09:39:14.383664  4519 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I1023 09:39:14.383667  4519 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I1023 09:39:14.383671  4519 net.cpp:380] Accuracy1 -> Accuracy1
I1023 09:39:14.383682  4519 net.cpp:122] Setting up Accuracy1
I1023 09:39:14.383685  4519 net.cpp:129] Top shape: (1)
I1023 09:39:14.383688  4519 net.cpp:137] Memory required for data: 1687522344
I1023 09:39:14.383690  4519 net.cpp:200] Accuracy1 does not need backward computation.
I1023 09:39:14.383692  4519 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1023 09:39:14.383695  4519 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I1023 09:39:14.383697  4519 net.cpp:198] InnerProduct1 needs backward computation.
I1023 09:39:14.383700  4519 net.cpp:198] Pooling1 needs backward computation.
I1023 09:39:14.383702  4519 net.cpp:198] penlu19 needs backward computation.
I1023 09:39:14.383704  4519 net.cpp:198] Eltwise9 needs backward computation.
I1023 09:39:14.383707  4519 net.cpp:198] Scale21 needs backward computation.
I1023 09:39:14.383709  4519 net.cpp:198] BatchNorm21 needs backward computation.
I1023 09:39:14.383710  4519 net.cpp:198] Convolution21 needs backward computation.
I1023 09:39:14.383713  4519 net.cpp:198] penlu18 needs backward computation.
I1023 09:39:14.383715  4519 net.cpp:198] Scale20 needs backward computation.
I1023 09:39:14.383718  4519 net.cpp:198] BatchNorm20 needs backward computation.
I1023 09:39:14.383719  4519 net.cpp:198] Convolution20 needs backward computation.
I1023 09:39:14.383721  4519 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I1023 09:39:14.383723  4519 net.cpp:198] penlu17 needs backward computation.
I1023 09:39:14.383725  4519 net.cpp:198] Eltwise8 needs backward computation.
I1023 09:39:14.383728  4519 net.cpp:198] Scale19 needs backward computation.
I1023 09:39:14.383730  4519 net.cpp:198] BatchNorm19 needs backward computation.
I1023 09:39:14.383733  4519 net.cpp:198] Convolution19 needs backward computation.
I1023 09:39:14.383735  4519 net.cpp:198] penlu16 needs backward computation.
I1023 09:39:14.383738  4519 net.cpp:198] Scale18 needs backward computation.
I1023 09:39:14.383739  4519 net.cpp:198] BatchNorm18 needs backward computation.
I1023 09:39:14.383741  4519 net.cpp:198] Convolution18 needs backward computation.
I1023 09:39:14.383744  4519 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I1023 09:39:14.383746  4519 net.cpp:198] penlu15 needs backward computation.
I1023 09:39:14.383749  4519 net.cpp:198] Eltwise7 needs backward computation.
I1023 09:39:14.383751  4519 net.cpp:198] Scale17 needs backward computation.
I1023 09:39:14.383754  4519 net.cpp:198] BatchNorm17 needs backward computation.
I1023 09:39:14.383755  4519 net.cpp:198] Convolution17 needs backward computation.
I1023 09:39:14.383757  4519 net.cpp:198] penlu14 needs backward computation.
I1023 09:39:14.383760  4519 net.cpp:198] Scale16 needs backward computation.
I1023 09:39:14.383762  4519 net.cpp:198] BatchNorm16 needs backward computation.
I1023 09:39:14.383764  4519 net.cpp:198] Convolution16 needs backward computation.
I1023 09:39:14.383766  4519 net.cpp:198] Scale15 needs backward computation.
I1023 09:39:14.383770  4519 net.cpp:198] BatchNorm15 needs backward computation.
I1023 09:39:14.383772  4519 net.cpp:198] Convolution15 needs backward computation.
I1023 09:39:14.383775  4519 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I1023 09:39:14.383777  4519 net.cpp:198] penlu13 needs backward computation.
I1023 09:39:14.383780  4519 net.cpp:198] Eltwise6 needs backward computation.
I1023 09:39:14.383782  4519 net.cpp:198] Scale14 needs backward computation.
I1023 09:39:14.383785  4519 net.cpp:198] BatchNorm14 needs backward computation.
I1023 09:39:14.383786  4519 net.cpp:198] Convolution14 needs backward computation.
I1023 09:39:14.383790  4519 net.cpp:198] penlu12 needs backward computation.
I1023 09:39:14.403883  4519 net.cpp:198] Scale13 needs backward computation.
I1023 09:39:14.403890  4519 net.cpp:198] BatchNorm13 needs backward computation.
I1023 09:39:14.403893  4519 net.cpp:198] Convolution13 needs backward computation.
I1023 09:39:14.403897  4519 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I1023 09:39:14.403908  4519 net.cpp:198] penlu11 needs backward computation.
I1023 09:39:14.403910  4519 net.cpp:198] Eltwise5 needs backward computation.
I1023 09:39:14.403913  4519 net.cpp:198] Scale12 needs backward computation.
I1023 09:39:14.403915  4519 net.cpp:198] BatchNorm12 needs backward computation.
I1023 09:39:14.403918  4519 net.cpp:198] Convolution12 needs backward computation.
I1023 09:39:14.403920  4519 net.cpp:198] penlu10 needs backward computation.
I1023 09:39:14.403923  4519 net.cpp:198] Scale11 needs backward computation.
I1023 09:39:14.403925  4519 net.cpp:198] BatchNorm11 needs backward computation.
I1023 09:39:14.403928  4519 net.cpp:198] Convolution11 needs backward computation.
I1023 09:39:14.403930  4519 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I1023 09:39:14.403934  4519 net.cpp:198] penlu9 needs backward computation.
I1023 09:39:14.403935  4519 net.cpp:198] Eltwise4 needs backward computation.
I1023 09:39:14.403939  4519 net.cpp:198] Scale10 needs backward computation.
I1023 09:39:14.403941  4519 net.cpp:198] BatchNorm10 needs backward computation.
I1023 09:39:14.403944  4519 net.cpp:198] Convolution10 needs backward computation.
I1023 09:39:14.403946  4519 net.cpp:198] penlu8 needs backward computation.
I1023 09:39:14.403949  4519 net.cpp:198] Scale9 needs backward computation.
I1023 09:39:14.403951  4519 net.cpp:198] BatchNorm9 needs backward computation.
I1023 09:39:14.403954  4519 net.cpp:198] Convolution9 needs backward computation.
I1023 09:39:14.403964  4519 net.cpp:198] Scale8 needs backward computation.
I1023 09:39:14.403966  4519 net.cpp:198] BatchNorm8 needs backward computation.
I1023 09:39:14.403970  4519 net.cpp:198] Convolution8 needs backward computation.
I1023 09:39:14.403971  4519 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I1023 09:39:14.403975  4519 net.cpp:198] penlu7 needs backward computation.
I1023 09:39:14.403977  4519 net.cpp:198] Eltwise3 needs backward computation.
I1023 09:39:14.403980  4519 net.cpp:198] Scale7 needs backward computation.
I1023 09:39:14.403982  4519 net.cpp:198] BatchNorm7 needs backward computation.
I1023 09:39:14.403985  4519 net.cpp:198] Convolution7 needs backward computation.
I1023 09:39:14.403987  4519 net.cpp:198] penlu6 needs backward computation.
I1023 09:39:14.403990  4519 net.cpp:198] Scale6 needs backward computation.
I1023 09:39:14.403992  4519 net.cpp:198] BatchNorm6 needs backward computation.
I1023 09:39:14.403995  4519 net.cpp:198] Convolution6 needs backward computation.
I1023 09:39:14.403997  4519 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I1023 09:39:14.404000  4519 net.cpp:198] penlu5 needs backward computation.
I1023 09:39:14.404002  4519 net.cpp:198] Eltwise2 needs backward computation.
I1023 09:39:14.404006  4519 net.cpp:198] Scale5 needs backward computation.
I1023 09:39:14.404007  4519 net.cpp:198] BatchNorm5 needs backward computation.
I1023 09:39:14.404011  4519 net.cpp:198] Convolution5 needs backward computation.
I1023 09:39:14.404012  4519 net.cpp:198] penlu4 needs backward computation.
I1023 09:39:14.404016  4519 net.cpp:198] Scale4 needs backward computation.
I1023 09:39:14.404017  4519 net.cpp:198] BatchNorm4 needs backward computation.
I1023 09:39:14.404019  4519 net.cpp:198] Convolution4 needs backward computation.
I1023 09:39:14.404022  4519 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I1023 09:39:14.404026  4519 net.cpp:198] penlu3 needs backward computation.
I1023 09:39:14.404027  4519 net.cpp:198] Eltwise1 needs backward computation.
I1023 09:39:14.404031  4519 net.cpp:198] Scale3 needs backward computation.
I1023 09:39:14.404033  4519 net.cpp:198] BatchNorm3 needs backward computation.
I1023 09:39:14.404036  4519 net.cpp:198] Convolution3 needs backward computation.
I1023 09:39:14.404039  4519 net.cpp:198] penlu2 needs backward computation.
I1023 09:39:14.404042  4519 net.cpp:198] Scale2 needs backward computation.
I1023 09:39:14.404043  4519 net.cpp:198] BatchNorm2 needs backward computation.
I1023 09:39:14.404047  4519 net.cpp:198] Convolution2 needs backward computation.
I1023 09:39:14.404053  4519 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I1023 09:39:14.404057  4519 net.cpp:198] penlu1 needs backward computation.
I1023 09:39:14.404058  4519 net.cpp:198] Scale1 needs backward computation.
I1023 09:39:14.404062  4519 net.cpp:198] BatchNorm1 needs backward computation.
I1023 09:39:14.404063  4519 net.cpp:198] Convolution1 needs backward computation.
I1023 09:39:14.404067  4519 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I1023 09:39:14.404070  4519 net.cpp:200] Data1 does not need backward computation.
I1023 09:39:14.404072  4519 net.cpp:242] This network produces output Accuracy1
I1023 09:39:14.404075  4519 net.cpp:242] This network produces output SoftmaxWithLoss1
I1023 09:39:14.404114  4519 net.cpp:255] Network initialization done.
I1023 09:39:14.404412  4519 solver.cpp:56] Solver scaffolding done.
I1023 09:39:14.410619  4519 caffe.cpp:248] Starting Optimization
I1023 09:39:14.410629  4519 solver.cpp:272] Solving resnet
I1023 09:39:14.410630  4519 solver.cpp:273] Learning Rate Policy: multistep
I1023 09:39:14.413544  4519 solver.cpp:330] Iteration 0, Testing net (#0)
I1023 09:39:16.878706  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:39:17.014127  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0
I1023 09:39:17.014194  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I1023 09:39:17.245322  4519 solver.cpp:218] Iteration 0 (0 iter/s, 2.8346s/100 iters), loss = 2.27178
I1023 09:39:17.245352  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.27178 (* 1 = 2.27178 loss)
I1023 09:39:17.245365  4519 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I1023 09:39:37.229169  4519 solver.cpp:218] Iteration 100 (5.0041 iter/s, 19.9836s/100 iters), loss = 0.554724
I1023 09:39:37.229212  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.554724 (* 1 = 0.554724 loss)
I1023 09:39:37.229219  4519 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I1023 09:39:57.034137  4519 solver.cpp:330] Iteration 200, Testing net (#0)
I1023 09:39:59.454216  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:39:59.591305  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.294922
I1023 09:39:59.591361  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.46453 (* 1 = 3.46453 loss)
I1023 09:39:59.791975  4519 solver.cpp:218] Iteration 200 (4.43212 iter/s, 22.5625s/100 iters), loss = 0.705729
I1023 09:39:59.792006  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.705729 (* 1 = 0.705729 loss)
I1023 09:39:59.792013  4519 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I1023 09:40:19.809777  4519 solver.cpp:218] Iteration 300 (4.99561 iter/s, 20.0176s/100 iters), loss = 1.90122
I1023 09:40:19.809805  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.90122 (* 1 = 1.90122 loss)
I1023 09:40:19.809811  4519 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I1023 09:40:27.234576  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:40:39.624227  4519 solver.cpp:330] Iteration 400, Testing net (#0)
I1023 09:40:42.043005  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:40:42.181201  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.419922
I1023 09:40:42.181262  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 4.11675 (* 1 = 4.11675 loss)
I1023 09:40:42.382390  4519 solver.cpp:218] Iteration 400 (4.4302 iter/s, 22.5724s/100 iters), loss = 1.12301
I1023 09:40:42.382418  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.12301 (* 1 = 1.12301 loss)
I1023 09:40:42.382424  4519 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I1023 09:41:02.459210  4519 solver.cpp:218] Iteration 500 (4.98093 iter/s, 20.0766s/100 iters), loss = 0.518856
I1023 09:41:02.459385  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.518856 (* 1 = 0.518856 loss)
I1023 09:41:02.459396  4519 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I1023 09:41:22.335161  4519 solver.cpp:330] Iteration 600, Testing net (#0)
I1023 09:41:24.720358  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:41:24.895974  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.246094
I1023 09:41:24.896039  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.67974 (* 1 = 3.67974 loss)
I1023 09:41:25.097270  4519 solver.cpp:218] Iteration 600 (4.41741 iter/s, 22.6377s/100 iters), loss = 1.3023
I1023 09:41:25.097301  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.3023 (* 1 = 1.3023 loss)
I1023 09:41:25.097309  4519 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I1023 09:41:40.774293  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:41:45.173779  4519 solver.cpp:218] Iteration 700 (4.981 iter/s, 20.0763s/100 iters), loss = 0.457892
I1023 09:41:45.173807  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.457892 (* 1 = 0.457892 loss)
I1023 09:41:45.173815  4519 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I1023 09:42:05.038652  4519 solver.cpp:330] Iteration 800, Testing net (#0)
I1023 09:42:07.423516  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:42:07.600479  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.59375
I1023 09:42:07.600540  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.96282 (* 1 = 2.96282 loss)
I1023 09:42:07.801972  4519 solver.cpp:218] Iteration 800 (4.41931 iter/s, 22.628s/100 iters), loss = 0.54941
I1023 09:42:07.802000  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.549411 (* 1 = 0.549411 loss)
I1023 09:42:07.802007  4519 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I1023 09:42:27.878860  4519 solver.cpp:218] Iteration 900 (4.9809 iter/s, 20.0767s/100 iters), loss = 0.785816
I1023 09:42:27.879004  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.785816 (* 1 = 0.785816 loss)
I1023 09:42:27.879014  4519 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I1023 09:42:47.757014  4519 solver.cpp:330] Iteration 1000, Testing net (#0)
I1023 09:42:50.141000  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:42:50.318183  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.550781
I1023 09:42:50.318243  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.61393 (* 1 = 1.61393 loss)
I1023 09:42:50.519793  4519 solver.cpp:218] Iteration 1000 (4.41684 iter/s, 22.6406s/100 iters), loss = 0.427563
I1023 09:42:50.519821  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.427564 (* 1 = 0.427564 loss)
I1023 09:42:50.519829  4519 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I1023 09:42:54.358845  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:43:10.599320  4519 solver.cpp:218] Iteration 1100 (4.98025 iter/s, 20.0793s/100 iters), loss = 0.103059
I1023 09:43:10.599457  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103059 (* 1 = 0.103059 loss)
I1023 09:43:10.599465  4519 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I1023 09:43:30.476709  4519 solver.cpp:330] Iteration 1200, Testing net (#0)
I1023 09:43:32.859738  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:43:33.038930  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.556641
I1023 09:43:33.038995  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.344 (* 1 = 2.344 loss)
I1023 09:43:33.240334  4519 solver.cpp:218] Iteration 1200 (4.41682 iter/s, 22.6407s/100 iters), loss = 2.20107
I1023 09:43:33.240362  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.20107 (* 1 = 2.20107 loss)
I1023 09:43:33.240370  4519 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I1023 09:43:53.316417  4519 solver.cpp:218] Iteration 1300 (4.98109 iter/s, 20.0759s/100 iters), loss = 0.505982
I1023 09:43:53.316583  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.505983 (* 1 = 0.505983 loss)
I1023 09:43:53.316604  4519 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I1023 09:44:05.388753  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:44:13.203331  4519 solver.cpp:330] Iteration 1400, Testing net (#0)
I1023 09:44:15.548714  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:44:15.764674  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.462891
I1023 09:44:15.764732  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.68308 (* 1 = 2.68308 loss)
I1023 09:44:15.966089  4519 solver.cpp:218] Iteration 1400 (4.41514 iter/s, 22.6494s/100 iters), loss = 0.583279
I1023 09:44:15.966117  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.58328 (* 1 = 0.58328 loss)
I1023 09:44:15.966125  4519 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I1023 09:44:36.037629  4519 solver.cpp:218] Iteration 1500 (4.98222 iter/s, 20.0714s/100 iters), loss = 0.400549
I1023 09:44:36.037781  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.400549 (* 1 = 0.400549 loss)
I1023 09:44:36.037789  4519 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I1023 09:44:55.916970  4519 solver.cpp:330] Iteration 1600, Testing net (#0)
I1023 09:44:58.262171  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:44:58.479238  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.390625
I1023 09:44:58.479292  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.3047 (* 1 = 2.3047 loss)
I1023 09:44:58.681115  4519 solver.cpp:218] Iteration 1600 (4.41633 iter/s, 22.6432s/100 iters), loss = 1.23809
I1023 09:44:58.681144  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.23809 (* 1 = 1.23809 loss)
I1023 09:44:58.681151  4519 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I1023 09:45:18.761147  4519 solver.cpp:218] Iteration 1700 (4.9801 iter/s, 20.0799s/100 iters), loss = 1.05965
I1023 09:45:18.761291  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.05965 (* 1 = 1.05965 loss)
I1023 09:45:18.761309  4519 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I1023 09:45:19.182335  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:45:38.643708  4519 solver.cpp:330] Iteration 1800, Testing net (#0)
I1023 09:45:40.987825  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:45:41.205591  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.572266
I1023 09:45:41.205654  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.32958 (* 1 = 1.32958 loss)
I1023 09:45:41.406827  4519 solver.cpp:218] Iteration 1800 (4.4159 iter/s, 22.6454s/100 iters), loss = 0.472557
I1023 09:45:41.406857  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.472557 (* 1 = 0.472557 loss)
I1023 09:45:41.406863  4519 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I1023 09:46:01.480716  4519 solver.cpp:218] Iteration 1900 (4.98163 iter/s, 20.0738s/100 iters), loss = 0.707456
I1023 09:46:01.480862  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.707457 (* 1 = 0.707457 loss)
I1023 09:46:01.480872  4519 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I1023 09:46:21.353642  4519 solver.cpp:330] Iteration 2000, Testing net (#0)
I1023 09:46:23.698971  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:46:23.917527  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.59375
I1023 09:46:23.917589  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.56684 (* 1 = 1.56684 loss)
I1023 09:46:24.118863  4519 solver.cpp:218] Iteration 2000 (4.41737 iter/s, 22.6379s/100 iters), loss = 0.0466243
I1023 09:46:24.118896  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0466254 (* 1 = 0.0466254 loss)
I1023 09:46:24.118913  4519 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I1023 09:46:32.777953  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:46:44.198149  4519 solver.cpp:218] Iteration 2100 (4.98029 iter/s, 20.0792s/100 iters), loss = 0.58005
I1023 09:46:44.198181  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.580051 (* 1 = 0.580051 loss)
I1023 09:46:44.198199  4519 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I1023 09:47:04.068827  4519 solver.cpp:330] Iteration 2200, Testing net (#0)
I1023 09:47:06.377605  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:47:06.633723  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.648438
I1023 09:47:06.633777  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.976736 (* 1 = 0.976736 loss)
I1023 09:47:06.835996  4519 solver.cpp:218] Iteration 2200 (4.41741 iter/s, 22.6377s/100 iters), loss = 0.472748
I1023 09:47:06.836027  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.472749 (* 1 = 0.472749 loss)
I1023 09:47:06.836035  4519 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I1023 09:47:26.938547  4519 solver.cpp:218] Iteration 2300 (4.97452 iter/s, 20.1024s/100 iters), loss = 0.132196
I1023 09:47:26.938578  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132197 (* 1 = 0.132197 loss)
I1023 09:47:26.938585  4519 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I1023 09:47:43.853108  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:47:46.846139  4519 solver.cpp:330] Iteration 2400, Testing net (#0)
I1023 09:47:49.155490  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:47:49.412518  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.667969
I1023 09:47:49.412575  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.12728 (* 1 = 1.12728 loss)
I1023 09:47:49.613898  4519 solver.cpp:218] Iteration 2400 (4.4101 iter/s, 22.6752s/100 iters), loss = 0.217241
I1023 09:47:49.613930  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217242 (* 1 = 0.217242 loss)
I1023 09:47:49.613937  4519 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I1023 09:48:09.704234  4519 solver.cpp:218] Iteration 2500 (4.97755 iter/s, 20.0902s/100 iters), loss = 0.227489
I1023 09:48:09.704265  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22749 (* 1 = 0.22749 loss)
I1023 09:48:09.704272  4519 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I1023 09:48:29.599175  4519 solver.cpp:330] Iteration 2600, Testing net (#0)
I1023 09:48:31.908300  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:48:32.165869  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.662109
I1023 09:48:32.165930  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.19138 (* 1 = 1.19138 loss)
I1023 09:48:32.367620  4519 solver.cpp:218] Iteration 2600 (4.41243 iter/s, 22.6633s/100 iters), loss = 0.093211
I1023 09:48:32.367652  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.093212 (* 1 = 0.093212 loss)
I1023 09:48:32.367660  4519 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I1023 09:48:52.467006  4519 solver.cpp:218] Iteration 2700 (4.97531 iter/s, 20.0993s/100 iters), loss = 0.955898
I1023 09:48:52.467036  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.955899 (* 1 = 0.955899 loss)
I1023 09:48:52.467043  4519 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I1023 09:48:57.522526  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:49:12.369355  4519 solver.cpp:330] Iteration 2800, Testing net (#0)
I1023 09:49:14.678391  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:49:14.936945  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.675781
I1023 09:49:14.937006  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.06632 (* 1 = 1.06632 loss)
I1023 09:49:15.138689  4519 solver.cpp:218] Iteration 2800 (4.41081 iter/s, 22.6716s/100 iters), loss = 0.098282
I1023 09:49:15.138725  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0982832 (* 1 = 0.0982832 loss)
I1023 09:49:15.138731  4519 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I1023 09:49:35.240991  4519 solver.cpp:218] Iteration 2900 (4.97459 iter/s, 20.1022s/100 iters), loss = 0.302288
I1023 09:49:35.241024  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30229 (* 1 = 0.30229 loss)
I1023 09:49:35.241041  4519 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I1023 09:49:55.143738  4519 solver.cpp:330] Iteration 3000, Testing net (#0)
I1023 09:49:57.415546  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:49:57.712015  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.578125
I1023 09:49:57.712080  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.2024 (* 1 = 1.2024 loss)
I1023 09:49:57.913461  4519 solver.cpp:218] Iteration 3000 (4.41066 iter/s, 22.6723s/100 iters), loss = 0.69592
I1023 09:49:57.913494  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.695922 (* 1 = 0.695922 loss)
I1023 09:49:57.913501  4519 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I1023 09:50:11.404151  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:50:18.013391  4519 solver.cpp:218] Iteration 3100 (4.97517 iter/s, 20.0998s/100 iters), loss = 1.03373
I1023 09:50:18.013422  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.03373 (* 1 = 1.03373 loss)
I1023 09:50:18.013428  4519 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I1023 09:50:37.900460  4519 solver.cpp:330] Iteration 3200, Testing net (#0)
I1023 09:50:40.170392  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:50:40.468113  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.716797
I1023 09:50:40.468179  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.975699 (* 1 = 0.975699 loss)
I1023 09:50:40.669890  4519 solver.cpp:218] Iteration 3200 (4.41377 iter/s, 22.6564s/100 iters), loss = 0.148521
I1023 09:50:40.669922  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148523 (* 1 = 0.148523 loss)
I1023 09:50:40.669930  4519 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I1023 09:51:00.770686  4519 solver.cpp:218] Iteration 3300 (4.97496 iter/s, 20.1007s/100 iters), loss = 0.386015
I1023 09:51:00.770720  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.386016 (* 1 = 0.386016 loss)
I1023 09:51:00.770727  4519 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I1023 09:51:20.672662  4519 solver.cpp:330] Iteration 3400, Testing net (#0)
I1023 09:51:22.941833  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:51:23.240092  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.794922
I1023 09:51:23.240151  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.546409 (* 1 = 0.546409 loss)
I1023 09:51:23.441715  4519 solver.cpp:218] Iteration 3400 (4.41094 iter/s, 22.6709s/100 iters), loss = 0.0561669
I1023 09:51:23.441746  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0561685 (* 1 = 0.0561685 loss)
I1023 09:51:23.441753  4519 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I1023 09:51:25.076750  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:51:43.548261  4519 solver.cpp:218] Iteration 3500 (4.97353 iter/s, 20.1064s/100 iters), loss = 0.528289
I1023 09:51:43.548292  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.52829 (* 1 = 0.52829 loss)
I1023 09:51:43.548300  4519 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I1023 09:52:03.452263  4519 solver.cpp:330] Iteration 3600, Testing net (#0)
I1023 09:52:05.721274  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:52:06.019961  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.800781
I1023 09:52:06.020022  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.564521 (* 1 = 0.564521 loss)
I1023 09:52:06.221431  4519 solver.cpp:218] Iteration 3600 (4.41052 iter/s, 22.673s/100 iters), loss = 0.182869
I1023 09:52:06.221462  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182871 (* 1 = 0.182871 loss)
I1023 09:52:06.221469  4519 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I1023 09:52:26.316368  4519 solver.cpp:218] Iteration 3700 (4.97641 iter/s, 20.0948s/100 iters), loss = 0.0981487
I1023 09:52:26.316411  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.09815 (* 1 = 0.09815 loss)
I1023 09:52:26.316417  4519 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I1023 09:52:36.193974  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:52:46.217872  4519 solver.cpp:330] Iteration 3800, Testing net (#0)
I1023 09:52:48.448899  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:52:48.785224  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.792969
I1023 09:52:48.785287  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.535345 (* 1 = 0.535345 loss)
I1023 09:52:48.986755  4519 solver.cpp:218] Iteration 3800 (4.41107 iter/s, 22.6703s/100 iters), loss = 0.378555
I1023 09:52:48.986786  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378556 (* 1 = 0.378556 loss)
I1023 09:52:48.986793  4519 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I1023 09:53:09.090663  4519 solver.cpp:218] Iteration 3900 (4.97418 iter/s, 20.1038s/100 iters), loss = 0.0158641
I1023 09:53:09.090807  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0158652 (* 1 = 0.0158652 loss)
I1023 09:53:09.090817  4519 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I1023 09:53:28.991745  4519 solver.cpp:330] Iteration 4000, Testing net (#0)
I1023 09:53:31.222458  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:53:31.559149  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.824219
I1023 09:53:31.559208  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.450536 (* 1 = 0.450536 loss)
I1023 09:53:31.760931  4519 solver.cpp:218] Iteration 4000 (4.41111 iter/s, 22.67s/100 iters), loss = 0.183842
I1023 09:53:31.760963  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183844 (* 1 = 0.183844 loss)
I1023 09:53:31.760970  4519 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I1023 09:53:49.880360  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:53:51.867127  4519 solver.cpp:218] Iteration 4100 (4.97362 iter/s, 20.1061s/100 iters), loss = 0.198731
I1023 09:53:51.867158  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198732 (* 1 = 0.198732 loss)
I1023 09:53:51.867166  4519 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I1023 09:54:11.767518  4519 solver.cpp:330] Iteration 4200, Testing net (#0)
I1023 09:54:13.996016  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:54:14.334022  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.839844
I1023 09:54:14.334080  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.565522 (* 1 = 0.565522 loss)
I1023 09:54:14.535691  4519 solver.cpp:218] Iteration 4200 (4.41142 iter/s, 22.6684s/100 iters), loss = 0.143635
I1023 09:54:14.535723  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143636 (* 1 = 0.143636 loss)
I1023 09:54:14.535740  4519 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I1023 09:54:34.632032  4519 solver.cpp:218] Iteration 4300 (4.97606 iter/s, 20.0962s/100 iters), loss = 0.788837
I1023 09:54:34.632136  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.788838 (* 1 = 0.788838 loss)
I1023 09:54:34.632145  4519 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I1023 09:54:54.526187  4519 solver.cpp:330] Iteration 4400, Testing net (#0)
I1023 09:54:56.755115  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:54:57.093866  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.882812
I1023 09:54:57.093927  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311451 (* 1 = 0.311451 loss)
I1023 09:54:57.295647  4519 solver.cpp:218] Iteration 4400 (4.41239 iter/s, 22.6634s/100 iters), loss = 0.0392513
I1023 09:54:57.295680  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0392523 (* 1 = 0.0392523 loss)
I1023 09:54:57.295687  4519 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I1023 09:55:03.759191  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:55:17.399734  4519 solver.cpp:218] Iteration 4500 (4.97414 iter/s, 20.104s/100 iters), loss = 0.163572
I1023 09:55:17.399914  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163573 (* 1 = 0.163573 loss)
I1023 09:55:17.399924  4519 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I1023 09:55:37.301229  4519 solver.cpp:330] Iteration 4600, Testing net (#0)
I1023 09:55:39.492630  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:55:39.868789  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.777344
I1023 09:55:39.868850  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.61794 (* 1 = 0.61794 loss)
I1023 09:55:40.070654  4519 solver.cpp:218] Iteration 4600 (4.41099 iter/s, 22.6707s/100 iters), loss = 0.0198918
I1023 09:55:40.070688  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0198926 (* 1 = 0.0198926 loss)
I1023 09:55:40.070694  4519 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I1023 09:56:00.174104  4519 solver.cpp:218] Iteration 4700 (4.9743 iter/s, 20.1033s/100 iters), loss = 0.486643
I1023 09:56:00.174226  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.486644 (* 1 = 0.486644 loss)
I1023 09:56:00.174244  4519 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I1023 09:56:14.875905  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:56:20.085223  4519 solver.cpp:330] Iteration 4800, Testing net (#0)
I1023 09:56:22.276284  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:56:22.653038  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.810547
I1023 09:56:22.653100  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.489374 (* 1 = 0.489374 loss)
I1023 09:56:22.854910  4519 solver.cpp:218] Iteration 4800 (4.40905 iter/s, 22.6806s/100 iters), loss = 0.216462
I1023 09:56:22.854941  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216463 (* 1 = 0.216463 loss)
I1023 09:56:22.854948  4519 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I1023 09:56:42.951051  4519 solver.cpp:218] Iteration 4900 (4.97611 iter/s, 20.096s/100 iters), loss = 0.0443157
I1023 09:56:42.951198  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0443162 (* 1 = 0.0443162 loss)
I1023 09:56:42.951208  4519 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I1023 09:57:02.850729  4519 solver.cpp:330] Iteration 5000, Testing net (#0)
I1023 09:57:05.041460  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:57:05.419802  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.878906
I1023 09:57:05.419867  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.36219 (* 1 = 0.36219 loss)
I1023 09:57:05.621089  4519 solver.cpp:218] Iteration 5000 (4.41115 iter/s, 22.6698s/100 iters), loss = 0.21514
I1023 09:57:05.621120  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215141 (* 1 = 0.215141 loss)
I1023 09:57:05.621129  4519 sgd_solver.cpp:105] Iteration 5000, lr = 0.01
I1023 09:57:25.726373  4519 solver.cpp:218] Iteration 5100 (4.97384 iter/s, 20.1052s/100 iters), loss = 0.0306829
I1023 09:57:25.726517  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0306836 (* 1 = 0.0306836 loss)
I1023 09:57:25.726527  4519 sgd_solver.cpp:105] Iteration 5100, lr = 0.01
I1023 09:57:28.566793  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:57:45.629499  4519 solver.cpp:330] Iteration 5200, Testing net (#0)
I1023 09:57:47.819265  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:57:48.197852  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.894531
I1023 09:57:48.197913  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309722 (* 1 = 0.309722 loss)
I1023 09:57:48.399446  4519 solver.cpp:218] Iteration 5200 (4.41056 iter/s, 22.6729s/100 iters), loss = 0.0386631
I1023 09:57:48.399477  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0386639 (* 1 = 0.0386639 loss)
I1023 09:57:48.399484  4519 sgd_solver.cpp:105] Iteration 5200, lr = 0.01
I1023 09:58:08.506309  4519 solver.cpp:218] Iteration 5300 (4.97345 iter/s, 20.1068s/100 iters), loss = 0.347066
I1023 09:58:08.506450  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.347067 (* 1 = 0.347067 loss)
I1023 09:58:08.506459  4519 sgd_solver.cpp:105] Iteration 5300, lr = 0.01
I1023 09:58:28.408020  4519 solver.cpp:330] Iteration 5400, Testing net (#0)
I1023 09:58:30.560178  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:58:30.976771  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.765625
I1023 09:58:30.976821  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.83181 (* 1 = 0.83181 loss)
I1023 09:58:31.178155  4519 solver.cpp:218] Iteration 5400 (4.4108 iter/s, 22.6716s/100 iters), loss = 0.142406
I1023 09:58:31.178186  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142407 (* 1 = 0.142407 loss)
I1023 09:58:31.178194  4519 sgd_solver.cpp:105] Iteration 5400, lr = 0.01
I1023 09:58:42.259699  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:58:51.282222  4519 solver.cpp:218] Iteration 5500 (4.97414 iter/s, 20.104s/100 iters), loss = 0.229963
I1023 09:58:51.282251  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229964 (* 1 = 0.229964 loss)
I1023 09:58:51.282258  4519 sgd_solver.cpp:105] Iteration 5500, lr = 0.01
I1023 09:59:11.165885  4519 solver.cpp:330] Iteration 5600, Testing net (#0)
I1023 09:59:13.317735  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:59:13.735138  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.857422
I1023 09:59:13.735203  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.417768 (* 1 = 0.417768 loss)
I1023 09:59:13.936900  4519 solver.cpp:218] Iteration 5600 (4.41412 iter/s, 22.6546s/100 iters), loss = 0.0942735
I1023 09:59:13.936933  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0942746 (* 1 = 0.0942746 loss)
I1023 09:59:13.936939  4519 sgd_solver.cpp:105] Iteration 5600, lr = 0.01
I1023 09:59:34.036391  4519 solver.cpp:218] Iteration 5700 (4.97528 iter/s, 20.0994s/100 iters), loss = 0.0110209
I1023 09:59:34.036422  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110221 (* 1 = 0.0110221 loss)
I1023 09:59:34.036429  4519 sgd_solver.cpp:105] Iteration 5700, lr = 0.01
I1023 09:59:53.557368  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:59:53.939486  4519 solver.cpp:330] Iteration 5800, Testing net (#0)
I1023 09:59:56.090010  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 09:59:56.507848  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.919922
I1023 09:59:56.507900  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.207316 (* 1 = 0.207316 loss)
I1023 09:59:56.710083  4519 solver.cpp:218] Iteration 5800 (4.41042 iter/s, 22.6736s/100 iters), loss = 0.187853
I1023 09:59:56.710114  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187854 (* 1 = 0.187854 loss)
I1023 09:59:56.710121  4519 sgd_solver.cpp:105] Iteration 5800, lr = 0.01
I1023 10:00:16.814503  4519 solver.cpp:218] Iteration 5900 (4.97406 iter/s, 20.1043s/100 iters), loss = 0.41329
I1023 10:00:16.814534  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.413291 (* 1 = 0.413291 loss)
I1023 10:00:16.814541  4519 sgd_solver.cpp:105] Iteration 5900, lr = 0.01
I1023 10:00:36.715149  4519 solver.cpp:330] Iteration 6000, Testing net (#0)
I1023 10:00:38.864420  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:00:39.283156  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.904297
I1023 10:00:39.283215  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.278094 (* 1 = 0.278094 loss)
I1023 10:00:39.484658  4519 solver.cpp:218] Iteration 6000 (4.41111 iter/s, 22.6701s/100 iters), loss = 0.212757
I1023 10:00:39.484704  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212758 (* 1 = 0.212758 loss)
I1023 10:00:39.484711  4519 sgd_solver.cpp:105] Iteration 6000, lr = 0.01
I1023 10:00:59.582864  4519 solver.cpp:218] Iteration 6100 (4.97559 iter/s, 20.0981s/100 iters), loss = 0.132395
I1023 10:00:59.582895  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132396 (* 1 = 0.132396 loss)
I1023 10:00:59.582902  4519 sgd_solver.cpp:105] Iteration 6100, lr = 0.01
I1023 10:01:07.249491  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:01:19.480587  4519 solver.cpp:330] Iteration 6200, Testing net (#0)
I1023 10:01:21.592072  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:01:22.048323  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.851562
I1023 10:01:22.048383  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.465722 (* 1 = 0.465722 loss)
I1023 10:01:22.250180  4519 solver.cpp:218] Iteration 6200 (4.41166 iter/s, 22.6672s/100 iters), loss = 0.0660914
I1023 10:01:22.250210  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0660924 (* 1 = 0.0660924 loss)
I1023 10:01:22.250216  4519 sgd_solver.cpp:105] Iteration 6200, lr = 0.01
I1023 10:01:42.361613  4519 solver.cpp:218] Iteration 6300 (4.97232 iter/s, 20.1113s/100 iters), loss = 0.0885583
I1023 10:01:42.361765  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0885593 (* 1 = 0.0885593 loss)
I1023 10:01:42.361775  4519 sgd_solver.cpp:105] Iteration 6300, lr = 0.01
I1023 10:02:02.277814  4519 solver.cpp:330] Iteration 6400, Testing net (#0)
I1023 10:02:04.389230  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:02:04.846510  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.931641
I1023 10:02:04.846575  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.194062 (* 1 = 0.194062 loss)
I1023 10:02:05.048333  4519 solver.cpp:218] Iteration 6400 (4.40791 iter/s, 22.6865s/100 iters), loss = 0.0221686
I1023 10:02:05.048374  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0221696 (* 1 = 0.0221696 loss)
I1023 10:02:05.048382  4519 sgd_solver.cpp:105] Iteration 6400, lr = 0.01
I1023 10:02:20.953212  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:02:25.153921  4519 solver.cpp:218] Iteration 6500 (4.97377 iter/s, 20.1055s/100 iters), loss = 0.0501576
I1023 10:02:25.153954  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0501589 (* 1 = 0.0501589 loss)
I1023 10:02:25.153962  4519 sgd_solver.cpp:105] Iteration 6500, lr = 0.01
I1023 10:02:45.065026  4519 solver.cpp:330] Iteration 6600, Testing net (#0)
I1023 10:02:47.175451  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:02:47.632361  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.945312
I1023 10:02:47.632426  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.150092 (* 1 = 0.150092 loss)
I1023 10:02:47.834138  4519 solver.cpp:218] Iteration 6600 (4.40915 iter/s, 22.6801s/100 iters), loss = 0.0169934
I1023 10:02:47.834167  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0169947 (* 1 = 0.0169947 loss)
I1023 10:02:47.834173  4519 sgd_solver.cpp:105] Iteration 6600, lr = 0.01
I1023 10:03:07.940789  4519 solver.cpp:218] Iteration 6700 (4.9735 iter/s, 20.1066s/100 iters), loss = 0.130603
I1023 10:03:07.940935  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.130604 (* 1 = 0.130604 loss)
I1023 10:03:07.940945  4519 sgd_solver.cpp:105] Iteration 6700, lr = 0.01
I1023 10:03:27.847095  4519 solver.cpp:330] Iteration 6800, Testing net (#0)
I1023 10:03:29.957243  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:03:30.416344  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.830078
I1023 10:03:30.416409  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.663507 (* 1 = 0.663507 loss)
I1023 10:03:30.618403  4519 solver.cpp:218] Iteration 6800 (4.40968 iter/s, 22.6774s/100 iters), loss = 0.0932884
I1023 10:03:30.618432  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0932897 (* 1 = 0.0932897 loss)
I1023 10:03:30.618440  4519 sgd_solver.cpp:105] Iteration 6800, lr = 0.01
I1023 10:03:34.666730  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:03:50.733131  4519 solver.cpp:218] Iteration 6900 (4.97151 iter/s, 20.1146s/100 iters), loss = 0.311756
I1023 10:03:50.733310  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311757 (* 1 = 0.311757 loss)
I1023 10:03:50.733320  4519 sgd_solver.cpp:105] Iteration 6900, lr = 0.01
I1023 10:04:10.649075  4519 solver.cpp:330] Iteration 7000, Testing net (#0)
I1023 10:04:12.720484  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:04:13.217558  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.861328
I1023 10:04:13.217617  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.454378 (* 1 = 0.454378 loss)
I1023 10:04:13.419602  4519 solver.cpp:218] Iteration 7000 (4.40796 iter/s, 22.6862s/100 iters), loss = 0.0866566
I1023 10:04:13.419631  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.086658 (* 1 = 0.086658 loss)
I1023 10:04:13.419637  4519 sgd_solver.cpp:105] Iteration 7000, lr = 0.01
I1023 10:04:33.518690  4519 solver.cpp:218] Iteration 7100 (4.97537 iter/s, 20.099s/100 iters), loss = 0.129618
I1023 10:04:33.518837  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.129619 (* 1 = 0.129619 loss)
I1023 10:04:33.518847  4519 sgd_solver.cpp:105] Iteration 7100, lr = 0.01
I1023 10:04:46.006904  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:04:53.422583  4519 solver.cpp:330] Iteration 7200, Testing net (#0)
I1023 10:04:55.494026  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:04:55.991612  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.849609
I1023 10:04:55.991670  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.426506 (* 1 = 0.426506 loss)
I1023 10:04:56.193078  4519 solver.cpp:218] Iteration 7200 (4.41031 iter/s, 22.6742s/100 iters), loss = 0.36096
I1023 10:04:56.193109  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.360961 (* 1 = 0.360961 loss)
I1023 10:04:56.193115  4519 sgd_solver.cpp:105] Iteration 7200, lr = 0.01
I1023 10:05:16.279486  4519 solver.cpp:218] Iteration 7300 (4.97851 iter/s, 20.0863s/100 iters), loss = 0.534492
I1023 10:05:16.279623  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.534494 (* 1 = 0.534494 loss)
I1023 10:05:16.279631  4519 sgd_solver.cpp:105] Iteration 7300, lr = 0.01
I1023 10:05:36.172127  4519 solver.cpp:330] Iteration 7400, Testing net (#0)
I1023 10:05:38.241780  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:05:38.738948  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9375
I1023 10:05:38.739006  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.175454 (* 1 = 0.175454 loss)
I1023 10:05:38.940641  4519 solver.cpp:218] Iteration 7400 (4.41288 iter/s, 22.6609s/100 iters), loss = 0.536893
I1023 10:05:38.940670  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.536895 (* 1 = 0.536895 loss)
I1023 10:05:38.940677  4519 sgd_solver.cpp:105] Iteration 7400, lr = 0.01
I1023 10:05:59.038523  4519 solver.cpp:218] Iteration 7500 (4.97567 iter/s, 20.0978s/100 iters), loss = 0.0980678
I1023 10:05:59.038671  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0980695 (* 1 = 0.0980695 loss)
I1023 10:05:59.038679  4519 sgd_solver.cpp:105] Iteration 7500, lr = 0.01
I1023 10:05:59.668244  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:06:18.938108  4519 solver.cpp:330] Iteration 7600, Testing net (#0)
I1023 10:06:21.008188  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:06:21.507164  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.816406
I1023 10:06:21.507222  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.52829 (* 1 = 0.52829 loss)
I1023 10:06:21.709071  4519 solver.cpp:218] Iteration 7600 (4.41105 iter/s, 22.6703s/100 iters), loss = 0.191
I1023 10:06:21.709105  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191002 (* 1 = 0.191002 loss)
I1023 10:06:21.709112  4519 sgd_solver.cpp:105] Iteration 7600, lr = 0.01
I1023 10:06:41.806247  4519 solver.cpp:218] Iteration 7700 (4.97585 iter/s, 20.0971s/100 iters), loss = 0.0428363
I1023 10:06:41.806422  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0428378 (* 1 = 0.0428378 loss)
I1023 10:06:41.806433  4519 sgd_solver.cpp:105] Iteration 7700, lr = 0.01
I1023 10:07:01.706969  4519 solver.cpp:330] Iteration 7800, Testing net (#0)
I1023 10:07:03.739056  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:07:04.275125  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.875
I1023 10:07:04.275183  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373857 (* 1 = 0.373857 loss)
I1023 10:07:04.476506  4519 solver.cpp:218] Iteration 7800 (4.41111 iter/s, 22.67s/100 iters), loss = 0.0387386
I1023 10:07:04.476537  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0387402 (* 1 = 0.0387402 loss)
I1023 10:07:04.476544  4519 sgd_solver.cpp:105] Iteration 7800, lr = 0.01
I1023 10:07:13.346292  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:07:24.576102  4519 solver.cpp:218] Iteration 7900 (4.97525 iter/s, 20.0995s/100 iters), loss = 0.0249343
I1023 10:07:24.576133  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0249358 (* 1 = 0.0249358 loss)
I1023 10:07:24.576139  4519 sgd_solver.cpp:105] Iteration 7900, lr = 0.01
I1023 10:07:44.465651  4519 solver.cpp:330] Iteration 8000, Testing net (#0)
I1023 10:07:46.497300  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:07:47.034754  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923828
I1023 10:07:47.034811  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.177797 (* 1 = 0.177797 loss)
I1023 10:07:47.236578  4519 solver.cpp:218] Iteration 8000 (4.41299 iter/s, 22.6604s/100 iters), loss = 0.232794
I1023 10:07:47.236610  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232796 (* 1 = 0.232796 loss)
I1023 10:07:47.236618  4519 sgd_solver.cpp:105] Iteration 8000, lr = 0.01
I1023 10:08:07.337996  4519 solver.cpp:218] Iteration 8100 (4.9748 iter/s, 20.1013s/100 iters), loss = 0.199121
I1023 10:08:07.338029  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199122 (* 1 = 0.199122 loss)
I1023 10:08:07.338037  4519 sgd_solver.cpp:105] Iteration 8100, lr = 0.01
I1023 10:08:24.448952  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:08:27.241257  4519 solver.cpp:330] Iteration 8200, Testing net (#0)
I1023 10:08:29.271782  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:08:29.809551  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.929688
I1023 10:08:29.809612  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.163145 (* 1 = 0.163145 loss)
I1023 10:08:30.011945  4519 solver.cpp:218] Iteration 8200 (4.41037 iter/s, 22.6738s/100 iters), loss = 0.179668
I1023 10:08:30.011988  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17967 (* 1 = 0.17967 loss)
I1023 10:08:30.011996  4519 sgd_solver.cpp:105] Iteration 8200, lr = 0.01
I1023 10:08:50.111162  4519 solver.cpp:218] Iteration 8300 (4.97534 iter/s, 20.0991s/100 iters), loss = 0.046644
I1023 10:08:50.111194  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0466456 (* 1 = 0.0466456 loss)
I1023 10:08:50.111202  4519 sgd_solver.cpp:105] Iteration 8300, lr = 0.01
I1023 10:09:10.012949  4519 solver.cpp:330] Iteration 8400, Testing net (#0)
I1023 10:09:12.043952  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:09:12.582104  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.894531
I1023 10:09:12.582162  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.284246 (* 1 = 0.284246 loss)
I1023 10:09:12.783380  4519 solver.cpp:218] Iteration 8400 (4.4107 iter/s, 22.6721s/100 iters), loss = 0.493094
I1023 10:09:12.783416  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.493095 (* 1 = 0.493095 loss)
I1023 10:09:12.783422  4519 sgd_solver.cpp:105] Iteration 8400, lr = 0.01
I1023 10:09:32.875645  4519 solver.cpp:218] Iteration 8500 (4.97706 iter/s, 20.0922s/100 iters), loss = 0.00659893
I1023 10:09:32.875677  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00660053 (* 1 = 0.00660053 loss)
I1023 10:09:32.875684  4519 sgd_solver.cpp:105] Iteration 8500, lr = 0.01
I1023 10:09:38.325976  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:09:52.774977  4519 solver.cpp:330] Iteration 8600, Testing net (#0)
I1023 10:09:54.766791  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:09:55.342823  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9375
I1023 10:09:55.342881  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.203844 (* 1 = 0.203844 loss)
I1023 10:09:55.544668  4519 solver.cpp:218] Iteration 8600 (4.41133 iter/s, 22.6689s/100 iters), loss = 0.0658186
I1023 10:09:55.544699  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0658202 (* 1 = 0.0658202 loss)
I1023 10:09:55.544706  4519 sgd_solver.cpp:105] Iteration 8600, lr = 0.01
I1023 10:10:15.638679  4519 solver.cpp:218] Iteration 8700 (4.97663 iter/s, 20.0939s/100 iters), loss = 0.52593
I1023 10:10:15.638710  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.525931 (* 1 = 0.525931 loss)
I1023 10:10:15.638716  4519 sgd_solver.cpp:105] Iteration 8700, lr = 0.01
I1023 10:10:35.542520  4519 solver.cpp:330] Iteration 8800, Testing net (#0)
I1023 10:10:37.533192  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:10:38.110798  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.949219
I1023 10:10:38.110854  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.150199 (* 1 = 0.150199 loss)
I1023 10:10:38.312407  4519 solver.cpp:218] Iteration 8800 (4.41041 iter/s, 22.6736s/100 iters), loss = 0.0251805
I1023 10:10:38.312440  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.025182 (* 1 = 0.025182 loss)
I1023 10:10:38.312448  4519 sgd_solver.cpp:105] Iteration 8800, lr = 0.01
I1023 10:10:52.004503  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:10:58.418263  4519 solver.cpp:218] Iteration 8900 (4.9737 iter/s, 20.1058s/100 iters), loss = 0.02048
I1023 10:10:58.418298  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0204815 (* 1 = 0.0204815 loss)
I1023 10:10:58.418305  4519 sgd_solver.cpp:105] Iteration 8900, lr = 0.01
I1023 10:11:18.315294  4519 solver.cpp:330] Iteration 9000, Testing net (#0)
I1023 10:11:20.306154  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:11:20.883239  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.894531
I1023 10:11:20.883302  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334812 (* 1 = 0.334812 loss)
I1023 10:11:21.084805  4519 solver.cpp:218] Iteration 9000 (4.41181 iter/s, 22.6664s/100 iters), loss = 0.0260595
I1023 10:11:21.084834  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.026061 (* 1 = 0.026061 loss)
I1023 10:11:21.084841  4519 sgd_solver.cpp:105] Iteration 9000, lr = 0.01
I1023 10:11:41.176316  4519 solver.cpp:218] Iteration 9100 (4.97725 iter/s, 20.0914s/100 iters), loss = 0.0652599
I1023 10:11:41.176347  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0652613 (* 1 = 0.0652613 loss)
I1023 10:11:41.176355  4519 sgd_solver.cpp:105] Iteration 9100, lr = 0.01
I1023 10:12:01.070843  4519 solver.cpp:330] Iteration 9200, Testing net (#0)
I1023 10:12:03.061360  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:12:03.640370  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.935547
I1023 10:12:03.640415  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.187784 (* 1 = 0.187784 loss)
I1023 10:12:03.842768  4519 solver.cpp:218] Iteration 9200 (4.41183 iter/s, 22.6664s/100 iters), loss = 0.0783259
I1023 10:12:03.842800  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0783272 (* 1 = 0.0783272 loss)
I1023 10:12:03.842808  4519 sgd_solver.cpp:105] Iteration 9200, lr = 0.01
I1023 10:12:05.679452  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:12:23.943953  4519 solver.cpp:218] Iteration 9300 (4.97486 iter/s, 20.1011s/100 iters), loss = 0.109342
I1023 10:12:23.943995  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.109343 (* 1 = 0.109343 loss)
I1023 10:12:23.944002  4519 sgd_solver.cpp:105] Iteration 9300, lr = 0.01
I1023 10:12:43.846391  4519 solver.cpp:330] Iteration 9400, Testing net (#0)
I1023 10:12:45.799307  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:12:46.416409  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.943359
I1023 10:12:46.416474  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.158935 (* 1 = 0.158935 loss)
I1023 10:12:46.618438  4519 solver.cpp:218] Iteration 9400 (4.41026 iter/s, 22.6744s/100 iters), loss = 0.0269405
I1023 10:12:46.618468  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0269418 (* 1 = 0.0269418 loss)
I1023 10:12:46.618475  4519 sgd_solver.cpp:105] Iteration 9400, lr = 0.01
I1023 10:13:06.722690  4519 solver.cpp:218] Iteration 9500 (4.97409 iter/s, 20.1042s/100 iters), loss = 0.0850843
I1023 10:13:06.722723  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0850856 (* 1 = 0.0850856 loss)
I1023 10:13:06.722729  4519 sgd_solver.cpp:105] Iteration 9500, lr = 0.01
I1023 10:13:16.803043  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:13:26.622385  4519 solver.cpp:330] Iteration 9600, Testing net (#0)
I1023 10:13:28.575461  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:13:29.193006  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.869141
I1023 10:13:29.193068  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.392192 (* 1 = 0.392192 loss)
I1023 10:13:29.394412  4519 solver.cpp:218] Iteration 9600 (4.4108 iter/s, 22.6716s/100 iters), loss = 0.0442401
I1023 10:13:29.394455  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0442414 (* 1 = 0.0442414 loss)
I1023 10:13:29.394464  4519 sgd_solver.cpp:105] Iteration 9600, lr = 0.01
I1023 10:13:49.485862  4519 solver.cpp:218] Iteration 9700 (4.97727 iter/s, 20.0913s/100 iters), loss = 0.0198539
I1023 10:13:49.486004  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0198553 (* 1 = 0.0198553 loss)
I1023 10:13:49.486014  4519 sgd_solver.cpp:105] Iteration 9700, lr = 0.01
I1023 10:14:09.379042  4519 solver.cpp:330] Iteration 9800, Testing net (#0)
I1023 10:14:11.329512  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:14:11.946998  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.962891
I1023 10:14:11.947053  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.10637 (* 1 = 0.10637 loss)
I1023 10:14:12.148782  4519 solver.cpp:218] Iteration 9800 (4.41253 iter/s, 22.6627s/100 iters), loss = 0.166682
I1023 10:14:12.148813  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166683 (* 1 = 0.166683 loss)
I1023 10:14:12.148818  4519 sgd_solver.cpp:105] Iteration 9800, lr = 0.01
I1023 10:14:30.661232  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:14:32.246958  4519 solver.cpp:218] Iteration 9900 (4.9756 iter/s, 20.0981s/100 iters), loss = 0.00776523
I1023 10:14:32.246989  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00776671 (* 1 = 0.00776671 loss)
I1023 10:14:32.246995  4519 sgd_solver.cpp:105] Iteration 9900, lr = 0.01
I1023 10:14:52.144408  4519 solver.cpp:330] Iteration 10000, Testing net (#0)
I1023 10:14:54.093693  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:14:54.713743  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.925781
I1023 10:14:54.713802  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.188822 (* 1 = 0.188822 loss)
I1023 10:14:54.915539  4519 solver.cpp:218] Iteration 10000 (4.41141 iter/s, 22.6685s/100 iters), loss = 0.0775732
I1023 10:14:54.915570  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0775747 (* 1 = 0.0775747 loss)
I1023 10:14:54.915576  4519 sgd_solver.cpp:46] MultiStep Status: Iteration 10000, step = 1
I1023 10:14:54.915580  4519 sgd_solver.cpp:105] Iteration 10000, lr = 0.001
I1023 10:15:15.013664  4519 solver.cpp:218] Iteration 10100 (4.97561 iter/s, 20.098s/100 iters), loss = 0.00847961
I1023 10:15:15.013809  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00848115 (* 1 = 0.00848115 loss)
I1023 10:15:15.013830  4519 sgd_solver.cpp:105] Iteration 10100, lr = 0.001
I1023 10:15:34.911144  4519 solver.cpp:330] Iteration 10200, Testing net (#0)
I1023 10:15:36.823439  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:15:37.480478  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9375
I1023 10:15:37.480540  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.178053 (* 1 = 0.178053 loss)
I1023 10:15:37.681879  4519 solver.cpp:218] Iteration 10200 (4.4115 iter/s, 22.668s/100 iters), loss = 0.00877225
I1023 10:15:37.681912  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00877384 (* 1 = 0.00877384 loss)
I1023 10:15:37.681919  4519 sgd_solver.cpp:105] Iteration 10200, lr = 0.001
I1023 10:15:44.340706  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:15:57.772496  4519 solver.cpp:218] Iteration 10300 (4.97747 iter/s, 20.0905s/100 iters), loss = 0.022793
I1023 10:15:57.772614  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227947 (* 1 = 0.0227947 loss)
I1023 10:15:57.772622  4519 sgd_solver.cpp:105] Iteration 10300, lr = 0.001
I1023 10:16:17.663359  4519 solver.cpp:330] Iteration 10400, Testing net (#0)
I1023 10:16:19.574864  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:16:20.232555  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.953125
I1023 10:16:20.232615  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.143184 (* 1 = 0.143184 loss)
I1023 10:16:20.434293  4519 solver.cpp:218] Iteration 10400 (4.41275 iter/s, 22.6616s/100 iters), loss = 0.0443519
I1023 10:16:20.434324  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0443536 (* 1 = 0.0443536 loss)
I1023 10:16:20.434331  4519 sgd_solver.cpp:105] Iteration 10400, lr = 0.001
I1023 10:16:40.530892  4519 solver.cpp:218] Iteration 10500 (4.97599 iter/s, 20.0965s/100 iters), loss = 0.0236922
I1023 10:16:40.530997  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0236939 (* 1 = 0.0236939 loss)
I1023 10:16:40.531014  4519 sgd_solver.cpp:105] Iteration 10500, lr = 0.001
I1023 10:16:55.431167  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:17:00.438541  4519 solver.cpp:330] Iteration 10600, Testing net (#0)
I1023 10:17:02.349004  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:17:03.008066  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.949219
I1023 10:17:03.008121  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.137242 (* 1 = 0.137242 loss)
I1023 10:17:03.209967  4519 solver.cpp:218] Iteration 10600 (4.40938 iter/s, 22.6789s/100 iters), loss = 0.0423849
I1023 10:17:03.209997  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0423866 (* 1 = 0.0423866 loss)
I1023 10:17:03.210005  4519 sgd_solver.cpp:105] Iteration 10600, lr = 0.001
I1023 10:17:23.304221  4519 solver.cpp:218] Iteration 10700 (4.97657 iter/s, 20.0942s/100 iters), loss = 0.00285384
I1023 10:17:23.304355  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00285546 (* 1 = 0.00285546 loss)
I1023 10:17:23.304365  4519 sgd_solver.cpp:105] Iteration 10700, lr = 0.001
I1023 10:17:43.203200  4519 solver.cpp:330] Iteration 10800, Testing net (#0)
I1023 10:17:45.113682  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:17:45.773399  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.953125
I1023 10:17:45.773458  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.138562 (* 1 = 0.138562 loss)
I1023 10:17:45.974897  4519 solver.cpp:218] Iteration 10800 (4.41102 iter/s, 22.6705s/100 iters), loss = 0.00325549
I1023 10:17:45.974930  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00325716 (* 1 = 0.00325716 loss)
I1023 10:17:45.974936  4519 sgd_solver.cpp:105] Iteration 10800, lr = 0.001
I1023 10:18:06.066843  4519 solver.cpp:218] Iteration 10900 (4.97714 iter/s, 20.0919s/100 iters), loss = 0.0283676
I1023 10:18:06.067018  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0283692 (* 1 = 0.0283692 loss)
I1023 10:18:06.067041  4519 sgd_solver.cpp:105] Iteration 10900, lr = 0.001
I1023 10:18:09.110234  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:18:25.961616  4519 solver.cpp:330] Iteration 11000, Testing net (#0)
I1023 10:18:27.834296  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:18:28.531503  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.953125
I1023 10:18:28.531563  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.137388 (* 1 = 0.137388 loss)
I1023 10:18:28.732842  4519 solver.cpp:218] Iteration 11000 (4.41194 iter/s, 22.6658s/100 iters), loss = 0.338412
I1023 10:18:28.732877  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338413 (* 1 = 0.338413 loss)
I1023 10:18:28.732883  4519 sgd_solver.cpp:105] Iteration 11000, lr = 0.001
I1023 10:18:48.830179  4519 solver.cpp:218] Iteration 11100 (4.97581 iter/s, 20.0972s/100 iters), loss = 0.0642435
I1023 10:18:48.830325  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0642451 (* 1 = 0.0642451 loss)
I1023 10:18:48.830335  4519 sgd_solver.cpp:105] Iteration 11100, lr = 0.001
I1023 10:19:08.731441  4519 solver.cpp:330] Iteration 11200, Testing net (#0)
I1023 10:19:10.602455  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:19:11.300194  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.955078
I1023 10:19:11.300261  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.116275 (* 1 = 0.116275 loss)
I1023 10:19:11.501910  4519 solver.cpp:218] Iteration 11200 (4.41082 iter/s, 22.6715s/100 iters), loss = 0.00381459
I1023 10:19:11.501940  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00381619 (* 1 = 0.00381619 loss)
I1023 10:19:11.501947  4519 sgd_solver.cpp:105] Iteration 11200, lr = 0.001
I1023 10:19:22.983213  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:19:31.607445  4519 solver.cpp:218] Iteration 11300 (4.97378 iter/s, 20.1054s/100 iters), loss = 0.075396
I1023 10:19:31.607476  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0753977 (* 1 = 0.0753977 loss)
I1023 10:19:31.607483  4519 sgd_solver.cpp:105] Iteration 11300, lr = 0.001
I1023 10:19:51.498750  4519 solver.cpp:330] Iteration 11400, Testing net (#0)
I1023 10:19:53.369513  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:19:54.068400  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.955078
I1023 10:19:54.068455  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.122623 (* 1 = 0.122623 loss)
I1023 10:19:54.270463  4519 solver.cpp:218] Iteration 11400 (4.41249 iter/s, 22.6629s/100 iters), loss = 0.0770113
I1023 10:19:54.270494  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.077013 (* 1 = 0.077013 loss)
I1023 10:19:54.270501  4519 sgd_solver.cpp:105] Iteration 11400, lr = 0.001
I1023 10:20:14.391747  4519 solver.cpp:218] Iteration 11500 (4.96989 iter/s, 20.1212s/100 iters), loss = 0.0115946
I1023 10:20:14.391778  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115963 (* 1 = 0.0115963 loss)
I1023 10:20:14.391785  4519 sgd_solver.cpp:105] Iteration 11500, lr = 0.001
I1023 10:20:34.134871  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:20:34.315029  4519 solver.cpp:330] Iteration 11600, Testing net (#0)
I1023 10:20:36.187968  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:20:36.887584  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.955078
I1023 10:20:36.887653  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.134847 (* 1 = 0.134847 loss)
I1023 10:20:37.089615  4519 solver.cpp:218] Iteration 11600 (4.40572 iter/s, 22.6978s/100 iters), loss = 0.00387883
I1023 10:20:37.089648  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00388051 (* 1 = 0.00388051 loss)
I1023 10:20:37.089654  4519 sgd_solver.cpp:105] Iteration 11600, lr = 0.001
I1023 10:20:57.217308  4519 solver.cpp:218] Iteration 11700 (4.9683 iter/s, 20.1276s/100 iters), loss = 0.0523553
I1023 10:20:57.217340  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.052357 (* 1 = 0.052357 loss)
I1023 10:20:57.217346  4519 sgd_solver.cpp:105] Iteration 11700, lr = 0.001
I1023 10:21:17.148780  4519 solver.cpp:330] Iteration 11800, Testing net (#0)
I1023 10:21:18.983119  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:21:19.720551  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.955078
I1023 10:21:19.720620  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.119126 (* 1 = 0.119126 loss)
I1023 10:21:19.923105  4519 solver.cpp:218] Iteration 11800 (4.40418 iter/s, 22.7057s/100 iters), loss = 0.0111933
I1023 10:21:19.923135  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111949 (* 1 = 0.0111949 loss)
I1023 10:21:19.923142  4519 sgd_solver.cpp:105] Iteration 11800, lr = 0.001
I1023 10:21:40.052512  4519 solver.cpp:218] Iteration 11900 (4.96788 iter/s, 20.1293s/100 iters), loss = 0.0313891
I1023 10:21:40.052543  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0313907 (* 1 = 0.0313907 loss)
I1023 10:21:40.052551  4519 sgd_solver.cpp:105] Iteration 11900, lr = 0.001
I1023 10:21:47.932261  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:21:59.984397  4519 solver.cpp:330] Iteration 12000, Testing net (#0)
I1023 10:22:01.818661  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:22:02.556556  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.957031
I1023 10:22:02.556620  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.11838 (* 1 = 0.11838 loss)
I1023 10:22:02.758114  4519 solver.cpp:218] Iteration 12000 (4.40422 iter/s, 22.7055s/100 iters), loss = 0.0139275
I1023 10:22:02.758146  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139291 (* 1 = 0.0139291 loss)
I1023 10:22:02.758152  4519 sgd_solver.cpp:105] Iteration 12000, lr = 0.001
I1023 10:22:22.881884  4519 solver.cpp:218] Iteration 12100 (4.96927 iter/s, 20.1237s/100 iters), loss = 0.0913963
I1023 10:22:22.882030  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0913979 (* 1 = 0.0913979 loss)
I1023 10:22:22.882040  4519 sgd_solver.cpp:105] Iteration 12100, lr = 0.001
I1023 10:22:42.806296  4519 solver.cpp:330] Iteration 12200, Testing net (#0)
I1023 10:22:44.639871  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:22:45.378772  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.960938
I1023 10:22:45.378835  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0985334 (* 1 = 0.0985334 loss)
I1023 10:22:45.580657  4519 solver.cpp:218] Iteration 12200 (4.40556 iter/s, 22.6986s/100 iters), loss = 0.0062389
I1023 10:22:45.580700  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00624047 (* 1 = 0.00624047 loss)
I1023 10:22:45.580708  4519 sgd_solver.cpp:105] Iteration 12200, lr = 0.001
I1023 10:23:01.714051  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:23:05.715761  4519 solver.cpp:218] Iteration 12300 (4.96648 iter/s, 20.135s/100 iters), loss = 0.0489547
I1023 10:23:05.715795  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0489563 (* 1 = 0.0489563 loss)
I1023 10:23:05.715802  4519 sgd_solver.cpp:105] Iteration 12300, lr = 0.001
I1023 10:23:25.640836  4519 solver.cpp:330] Iteration 12400, Testing net (#0)
I1023 10:23:27.472088  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:23:28.212904  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.958984
I1023 10:23:28.212966  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.119446 (* 1 = 0.119446 loss)
I1023 10:23:28.415061  4519 solver.cpp:218] Iteration 12400 (4.40544 iter/s, 22.6992s/100 iters), loss = 0.00998832
I1023 10:23:28.415099  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00998988 (* 1 = 0.00998988 loss)
I1023 10:23:28.415107  4519 sgd_solver.cpp:105] Iteration 12400, lr = 0.001
I1023 10:23:48.539091  4519 solver.cpp:218] Iteration 12500 (4.96921 iter/s, 20.1239s/100 iters), loss = 0.0805786
I1023 10:23:48.539257  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0805802 (* 1 = 0.0805802 loss)
I1023 10:23:48.539266  4519 sgd_solver.cpp:105] Iteration 12500, lr = 0.001
I1023 10:24:08.467242  4519 solver.cpp:330] Iteration 12600, Testing net (#0)
I1023 10:24:10.260491  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:24:11.038194  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.960938
I1023 10:24:11.038261  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0983099 (* 1 = 0.0983099 loss)
I1023 10:24:11.240267  4519 solver.cpp:218] Iteration 12600 (4.4051 iter/s, 22.7009s/100 iters), loss = 0.0150012
I1023 10:24:11.240298  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0150027 (* 1 = 0.0150027 loss)
I1023 10:24:11.240304  4519 sgd_solver.cpp:105] Iteration 12600, lr = 0.001
I1023 10:24:15.694350  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:24:31.362891  4519 solver.cpp:218] Iteration 12700 (4.96955 iter/s, 20.1225s/100 iters), loss = 0.00213872
I1023 10:24:31.363013  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00214023 (* 1 = 0.00214023 loss)
I1023 10:24:31.363021  4519 sgd_solver.cpp:105] Iteration 12700, lr = 0.001
I1023 10:24:51.284787  4519 solver.cpp:330] Iteration 12800, Testing net (#0)
I1023 10:24:53.077978  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:24:53.856856  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.955078
I1023 10:24:53.856909  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.104046 (* 1 = 0.104046 loss)
I1023 10:24:54.059161  4519 solver.cpp:218] Iteration 12800 (4.40605 iter/s, 22.6961s/100 iters), loss = 0.0547284
I1023 10:24:54.059193  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0547299 (* 1 = 0.0547299 loss)
I1023 10:24:54.059201  4519 sgd_solver.cpp:105] Iteration 12800, lr = 0.001
I1023 10:25:14.188835  4519 solver.cpp:218] Iteration 12900 (4.96781 iter/s, 20.1296s/100 iters), loss = 0.0108119
I1023 10:25:14.188978  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108134 (* 1 = 0.0108134 loss)
I1023 10:25:14.188988  4519 sgd_solver.cpp:105] Iteration 12900, lr = 0.001
I1023 10:25:26.900367  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:25:34.128187  4519 solver.cpp:330] Iteration 13000, Testing net (#0)
I1023 10:25:35.920449  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:25:36.699388  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.958984
I1023 10:25:36.699448  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.133402 (* 1 = 0.133402 loss)
I1023 10:25:36.901592  4519 solver.cpp:218] Iteration 13000 (4.40285 iter/s, 22.7126s/100 iters), loss = 0.00647251
I1023 10:25:36.901628  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00647408 (* 1 = 0.00647408 loss)
I1023 10:25:36.901635  4519 sgd_solver.cpp:105] Iteration 13000, lr = 0.001
I1023 10:25:57.021608  4519 solver.cpp:218] Iteration 13100 (4.9702 iter/s, 20.1199s/100 iters), loss = 0.00292435
I1023 10:25:57.021754  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00292595 (* 1 = 0.00292595 loss)
I1023 10:25:57.021764  4519 sgd_solver.cpp:105] Iteration 13100, lr = 0.001
I1023 10:26:16.949904  4519 solver.cpp:330] Iteration 13200, Testing net (#0)
I1023 10:26:18.740969  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:26:19.521397  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.955078
I1023 10:26:19.521446  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.11083 (* 1 = 0.11083 loss)
I1023 10:26:19.723222  4519 solver.cpp:218] Iteration 13200 (4.40501 iter/s, 22.7014s/100 iters), loss = 0.00357722
I1023 10:26:19.723256  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00357885 (* 1 = 0.00357885 loss)
I1023 10:26:19.723263  4519 sgd_solver.cpp:105] Iteration 13200, lr = 0.001
I1023 10:26:39.847029  4519 solver.cpp:218] Iteration 13300 (4.96926 iter/s, 20.1237s/100 iters), loss = 0.00148461
I1023 10:26:39.847151  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00148626 (* 1 = 0.00148626 loss)
I1023 10:26:39.847159  4519 sgd_solver.cpp:105] Iteration 13300, lr = 0.001
I1023 10:26:40.679913  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:26:59.772891  4519 solver.cpp:330] Iteration 13400, Testing net (#0)
I1023 10:27:01.527580  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:27:02.346469  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.957031
I1023 10:27:02.346524  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.127464 (* 1 = 0.127464 loss)
I1023 10:27:02.548424  4519 solver.cpp:218] Iteration 13400 (4.40505 iter/s, 22.7012s/100 iters), loss = 0.0103604
I1023 10:27:02.548456  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103621 (* 1 = 0.0103621 loss)
I1023 10:27:02.548463  4519 sgd_solver.cpp:105] Iteration 13400, lr = 0.001
I1023 10:27:22.674468  4519 solver.cpp:218] Iteration 13500 (4.96871 iter/s, 20.126s/100 iters), loss = 0.0100065
I1023 10:27:22.674590  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100082 (* 1 = 0.0100082 loss)
I1023 10:27:22.674599  4519 sgd_solver.cpp:105] Iteration 13500, lr = 0.001
I1023 10:27:42.602821  4519 solver.cpp:330] Iteration 13600, Testing net (#0)
I1023 10:27:44.355566  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:27:45.175781  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.960938
I1023 10:27:45.175842  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.109641 (* 1 = 0.109641 loss)
I1023 10:27:45.377717  4519 solver.cpp:218] Iteration 13600 (4.40469 iter/s, 22.7031s/100 iters), loss = 0.00492777
I1023 10:27:45.377751  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00492944 (* 1 = 0.00492944 loss)
I1023 10:27:45.377758  4519 sgd_solver.cpp:105] Iteration 13600, lr = 0.001
I1023 10:27:54.464074  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:28:05.515553  4519 solver.cpp:218] Iteration 13700 (4.9658 iter/s, 20.1377s/100 iters), loss = 0.0114626
I1023 10:28:05.515585  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114643 (* 1 = 0.0114643 loss)
I1023 10:28:05.515592  4519 sgd_solver.cpp:105] Iteration 13700, lr = 0.001
I1023 10:28:25.440965  4519 solver.cpp:330] Iteration 13800, Testing net (#0)
I1023 10:28:27.193127  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:28:28.013562  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.955078
I1023 10:28:28.013620  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.10232 (* 1 = 0.10232 loss)
I1023 10:28:28.215410  4519 solver.cpp:218] Iteration 13800 (4.40533 iter/s, 22.6998s/100 iters), loss = 0.0217638
I1023 10:28:28.215445  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0217655 (* 1 = 0.0217655 loss)
I1023 10:28:28.215451  4519 sgd_solver.cpp:105] Iteration 13800, lr = 0.001
I1023 10:28:48.332541  4519 solver.cpp:218] Iteration 13900 (4.97091 iter/s, 20.117s/100 iters), loss = 0.0406054
I1023 10:28:48.332572  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0406071 (* 1 = 0.0406071 loss)
I1023 10:28:48.332579  4519 sgd_solver.cpp:105] Iteration 13900, lr = 0.001
I1023 10:29:05.863066  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:29:08.257493  4519 solver.cpp:330] Iteration 14000, Testing net (#0)
I1023 10:29:10.008436  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:29:10.829674  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 10:29:10.829732  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.101469 (* 1 = 0.101469 loss)
I1023 10:29:11.032064  4519 solver.cpp:218] Iteration 14000 (4.4054 iter/s, 22.6994s/100 iters), loss = 0.015484
I1023 10:29:11.032095  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0154857 (* 1 = 0.0154857 loss)
I1023 10:29:11.032102  4519 sgd_solver.cpp:105] Iteration 14000, lr = 0.001
I1023 10:29:31.157694  4519 solver.cpp:218] Iteration 14100 (4.96881 iter/s, 20.1255s/100 iters), loss = 0.0732695
I1023 10:29:31.157726  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0732713 (* 1 = 0.0732713 loss)
I1023 10:29:31.157732  4519 sgd_solver.cpp:105] Iteration 14100, lr = 0.001
I1023 10:29:51.091305  4519 solver.cpp:330] Iteration 14200, Testing net (#0)
I1023 10:29:52.805133  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:29:53.662981  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.958984
I1023 10:29:53.663043  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.107496 (* 1 = 0.107496 loss)
I1023 10:29:53.865375  4519 solver.cpp:218] Iteration 14200 (4.40381 iter/s, 22.7076s/100 iters), loss = 0.0714423
I1023 10:29:53.865407  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0714441 (* 1 = 0.0714441 loss)
I1023 10:29:53.865413  4519 sgd_solver.cpp:105] Iteration 14200, lr = 0.001
I1023 10:30:13.996474  4519 solver.cpp:218] Iteration 14300 (4.96746 iter/s, 20.131s/100 iters), loss = 0.00560919
I1023 10:30:13.996503  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00561091 (* 1 = 0.00561091 loss)
I1023 10:30:13.996510  4519 sgd_solver.cpp:105] Iteration 14300, lr = 0.001
I1023 10:30:19.661602  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:30:33.929906  4519 solver.cpp:330] Iteration 14400, Testing net (#0)
I1023 10:30:35.643084  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:30:36.502869  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.960938
I1023 10:30:36.502919  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0920642 (* 1 = 0.0920642 loss)
I1023 10:30:36.704802  4519 solver.cpp:218] Iteration 14400 (4.40369 iter/s, 22.7082s/100 iters), loss = 0.024924
I1023 10:30:36.704834  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0249257 (* 1 = 0.0249257 loss)
I1023 10:30:36.704843  4519 sgd_solver.cpp:105] Iteration 14400, lr = 0.001
I1023 10:30:56.829622  4519 solver.cpp:218] Iteration 14500 (4.96901 iter/s, 20.1247s/100 iters), loss = 0.0244756
I1023 10:30:56.829653  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0244773 (* 1 = 0.0244773 loss)
I1023 10:30:56.829661  4519 sgd_solver.cpp:105] Iteration 14500, lr = 0.001
I1023 10:31:16.752830  4519 solver.cpp:330] Iteration 14600, Testing net (#0)
I1023 10:31:18.464715  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:31:19.324875  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.958984
I1023 10:31:19.324939  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0860082 (* 1 = 0.0860082 loss)
I1023 10:31:19.526835  4519 solver.cpp:218] Iteration 14600 (4.40585 iter/s, 22.6971s/100 iters), loss = 0.00854642
I1023 10:31:19.526867  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00854812 (* 1 = 0.00854812 loss)
I1023 10:31:19.526875  4519 sgd_solver.cpp:105] Iteration 14600, lr = 0.001
I1023 10:31:33.445453  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:31:39.664600  4519 solver.cpp:218] Iteration 14700 (4.96582 iter/s, 20.1377s/100 iters), loss = 0.0180189
I1023 10:31:39.664631  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0180206 (* 1 = 0.0180206 loss)
I1023 10:31:39.664638  4519 sgd_solver.cpp:105] Iteration 14700, lr = 0.001
I1023 10:31:59.591269  4519 solver.cpp:330] Iteration 14800, Testing net (#0)
I1023 10:32:01.304306  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:32:02.164386  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 10:32:02.164446  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0831563 (* 1 = 0.0831563 loss)
I1023 10:32:02.366783  4519 solver.cpp:218] Iteration 14800 (4.40488 iter/s, 22.7021s/100 iters), loss = 0.0246793
I1023 10:32:02.366814  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.024681 (* 1 = 0.024681 loss)
I1023 10:32:02.366822  4519 sgd_solver.cpp:105] Iteration 14800, lr = 0.001
I1023 10:32:22.494627  4519 solver.cpp:218] Iteration 14900 (4.96826 iter/s, 20.1278s/100 iters), loss = 0.120431
I1023 10:32:22.494657  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120432 (* 1 = 0.120432 loss)
I1023 10:32:22.494664  4519 sgd_solver.cpp:105] Iteration 14900, lr = 0.001
I1023 10:32:42.425226  4519 solver.cpp:330] Iteration 15000, Testing net (#0)
I1023 10:32:44.098686  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:32:44.997305  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 10:32:44.997370  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0879623 (* 1 = 0.0879623 loss)
I1023 10:32:45.199089  4519 solver.cpp:218] Iteration 15000 (4.40444 iter/s, 22.7044s/100 iters), loss = 0.0182067
I1023 10:32:45.199120  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0182084 (* 1 = 0.0182084 loss)
I1023 10:32:45.199127  4519 sgd_solver.cpp:105] Iteration 15000, lr = 0.001
I1023 10:32:47.241513  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:33:05.320442  4519 solver.cpp:218] Iteration 15100 (4.96987 iter/s, 20.1213s/100 iters), loss = 0.0191632
I1023 10:33:05.320474  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.019165 (* 1 = 0.019165 loss)
I1023 10:33:05.320482  4519 sgd_solver.cpp:105] Iteration 15100, lr = 0.001
I1023 10:33:25.244734  4519 solver.cpp:330] Iteration 15200, Testing net (#0)
I1023 10:33:26.917279  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:33:27.816886  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 10:33:27.816944  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0871176 (* 1 = 0.0871176 loss)
I1023 10:33:28.018878  4519 solver.cpp:218] Iteration 15200 (4.40561 iter/s, 22.6983s/100 iters), loss = 0.0106159
I1023 10:33:28.018909  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106177 (* 1 = 0.0106177 loss)
I1023 10:33:28.018918  4519 sgd_solver.cpp:105] Iteration 15200, lr = 0.001
I1023 10:33:48.148766  4519 solver.cpp:218] Iteration 15300 (4.96776 iter/s, 20.1298s/100 iters), loss = 0.0122856
I1023 10:33:48.148799  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122874 (* 1 = 0.0122874 loss)
I1023 10:33:48.148807  4519 sgd_solver.cpp:105] Iteration 15300, lr = 0.001
I1023 10:33:58.644314  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:34:08.082075  4519 solver.cpp:330] Iteration 15400, Testing net (#0)
I1023 10:34:09.753895  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:34:10.654193  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 10:34:10.654251  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0920126 (* 1 = 0.0920126 loss)
I1023 10:34:10.856510  4519 solver.cpp:218] Iteration 15400 (4.4038 iter/s, 22.7076s/100 iters), loss = 0.00362898
I1023 10:34:10.856555  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00363072 (* 1 = 0.00363072 loss)
I1023 10:34:10.856564  4519 sgd_solver.cpp:105] Iteration 15400, lr = 0.001
I1023 10:34:30.985672  4519 solver.cpp:218] Iteration 15500 (4.96794 iter/s, 20.1291s/100 iters), loss = 0.00123881
I1023 10:34:30.985832  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00124052 (* 1 = 0.00124052 loss)
I1023 10:34:30.985842  4519 sgd_solver.cpp:105] Iteration 15500, lr = 0.001
I1023 10:34:50.920882  4519 solver.cpp:330] Iteration 15600, Testing net (#0)
I1023 10:34:52.591543  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:34:53.493242  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.960938
I1023 10:34:53.493301  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.101658 (* 1 = 0.101658 loss)
I1023 10:34:53.694947  4519 solver.cpp:218] Iteration 15600 (4.40353 iter/s, 22.7091s/100 iters), loss = 0.000412371
I1023 10:34:53.694981  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000414089 (* 1 = 0.000414089 loss)
I1023 10:34:53.694989  4519 sgd_solver.cpp:105] Iteration 15600, lr = 0.001
I1023 10:35:12.438060  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:35:13.825430  4519 solver.cpp:218] Iteration 15700 (4.96761 iter/s, 20.1304s/100 iters), loss = 0.0240717
I1023 10:35:13.825462  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0240734 (* 1 = 0.0240734 loss)
I1023 10:35:13.825469  4519 sgd_solver.cpp:105] Iteration 15700, lr = 0.001
I1023 10:35:33.748939  4519 solver.cpp:330] Iteration 15800, Testing net (#0)
I1023 10:35:35.381659  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:35:36.319593  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.957031
I1023 10:35:36.319651  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.115252 (* 1 = 0.115252 loss)
I1023 10:35:36.521648  4519 solver.cpp:218] Iteration 15800 (4.40604 iter/s, 22.6961s/100 iters), loss = 0.000464315
I1023 10:35:36.521680  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000466055 (* 1 = 0.000466055 loss)
I1023 10:35:36.521687  4519 sgd_solver.cpp:105] Iteration 15800, lr = 0.001
I1023 10:35:56.650126  4519 solver.cpp:218] Iteration 15900 (4.96811 iter/s, 20.1284s/100 iters), loss = 0.00107032
I1023 10:35:56.650255  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00107205 (* 1 = 0.00107205 loss)
I1023 10:35:56.650264  4519 sgd_solver.cpp:105] Iteration 15900, lr = 0.001
I1023 10:36:16.579427  4519 solver.cpp:330] Iteration 16000, Testing net (#0)
I1023 10:36:18.211175  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:36:19.150739  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 10:36:19.150799  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0875328 (* 1 = 0.0875328 loss)
I1023 10:36:19.352519  4519 solver.cpp:218] Iteration 16000 (4.40486 iter/s, 22.7022s/100 iters), loss = 0.0318152
I1023 10:36:19.352550  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.031817 (* 1 = 0.031817 loss)
I1023 10:36:19.352556  4519 sgd_solver.cpp:105] Iteration 16000, lr = 0.001
I1023 10:36:26.226191  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:36:39.479676  4519 solver.cpp:218] Iteration 16100 (4.96843 iter/s, 20.1271s/100 iters), loss = 0.00280301
I1023 10:36:39.479787  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00280481 (* 1 = 0.00280481 loss)
I1023 10:36:39.479795  4519 sgd_solver.cpp:105] Iteration 16100, lr = 0.001
I1023 10:36:59.408782  4519 solver.cpp:330] Iteration 16200, Testing net (#0)
I1023 10:37:01.041160  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:37:01.981464  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 10:37:01.981523  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0982626 (* 1 = 0.0982626 loss)
I1023 10:37:02.183352  4519 solver.cpp:218] Iteration 16200 (4.4046 iter/s, 22.7035s/100 iters), loss = 0.00822524
I1023 10:37:02.183382  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00822705 (* 1 = 0.00822705 loss)
I1023 10:37:02.183389  4519 sgd_solver.cpp:105] Iteration 16200, lr = 0.001
I1023 10:37:22.301748  4519 solver.cpp:218] Iteration 16300 (4.9706 iter/s, 20.1183s/100 iters), loss = 0.0449726
I1023 10:37:22.301888  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0449744 (* 1 = 0.0449744 loss)
I1023 10:37:22.301897  4519 sgd_solver.cpp:105] Iteration 16300, lr = 0.001
I1023 10:37:37.421510  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:37:42.227855  4519 solver.cpp:330] Iteration 16400, Testing net (#0)
I1023 10:37:43.858683  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:37:44.800037  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 10:37:44.800096  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0949943 (* 1 = 0.0949943 loss)
I1023 10:37:45.001929  4519 solver.cpp:218] Iteration 16400 (4.40529 iter/s, 22.7s/100 iters), loss = 0.0183444
I1023 10:37:45.001960  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0183461 (* 1 = 0.0183461 loss)
I1023 10:37:45.001966  4519 sgd_solver.cpp:105] Iteration 16400, lr = 0.001
I1023 10:38:05.127933  4519 solver.cpp:218] Iteration 16500 (4.96872 iter/s, 20.1259s/100 iters), loss = 0.0767544
I1023 10:38:05.128080  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0767561 (* 1 = 0.0767561 loss)
I1023 10:38:05.128089  4519 sgd_solver.cpp:105] Iteration 16500, lr = 0.001
I1023 10:38:25.058315  4519 solver.cpp:330] Iteration 16600, Testing net (#0)
I1023 10:38:26.651619  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:38:27.630120  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 10:38:27.630164  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0881394 (* 1 = 0.0881394 loss)
I1023 10:38:27.832119  4519 solver.cpp:218] Iteration 16600 (4.40452 iter/s, 22.704s/100 iters), loss = 0.00450614
I1023 10:38:27.832150  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00450787 (* 1 = 0.00450787 loss)
I1023 10:38:27.832157  4519 sgd_solver.cpp:105] Iteration 16600, lr = 0.001
I1023 10:38:47.960844  4519 solver.cpp:218] Iteration 16700 (4.96805 iter/s, 20.1286s/100 iters), loss = 0.00950879
I1023 10:38:47.960986  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00951051 (* 1 = 0.00951051 loss)
I1023 10:38:47.960995  4519 sgd_solver.cpp:105] Iteration 16700, lr = 0.001
I1023 10:38:51.408515  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:39:07.892202  4519 solver.cpp:330] Iteration 16800, Testing net (#0)
I1023 10:39:09.484714  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:39:10.464432  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.962891
I1023 10:39:10.464495  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.100264 (* 1 = 0.100264 loss)
I1023 10:39:10.666100  4519 solver.cpp:218] Iteration 16800 (4.40431 iter/s, 22.7051s/100 iters), loss = 0.00143787
I1023 10:39:10.666132  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00143965 (* 1 = 0.00143965 loss)
I1023 10:39:10.666139  4519 sgd_solver.cpp:105] Iteration 16800, lr = 0.001
I1023 10:39:30.789353  4519 solver.cpp:218] Iteration 16900 (4.9694 iter/s, 20.1232s/100 iters), loss = 0.0711982
I1023 10:39:30.789476  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0712 (* 1 = 0.0712 loss)
I1023 10:39:30.789485  4519 sgd_solver.cpp:105] Iteration 16900, lr = 0.001
I1023 10:39:50.715035  4519 solver.cpp:330] Iteration 17000, Testing net (#0)
I1023 10:39:52.305783  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:39:53.285102  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 10:39:53.285158  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0851104 (* 1 = 0.0851104 loss)
I1023 10:39:53.487087  4519 solver.cpp:218] Iteration 17000 (4.40576 iter/s, 22.6975s/100 iters), loss = 0.00192388
I1023 10:39:53.487118  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00192561 (* 1 = 0.00192561 loss)
I1023 10:39:53.487125  4519 sgd_solver.cpp:105] Iteration 17000, lr = 0.001
I1023 10:40:05.192292  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:40:13.625833  4519 solver.cpp:218] Iteration 17100 (4.96557 iter/s, 20.1387s/100 iters), loss = 0.0646201
I1023 10:40:13.625864  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0646218 (* 1 = 0.0646218 loss)
I1023 10:40:13.625871  4519 sgd_solver.cpp:105] Iteration 17100, lr = 0.001
I1023 10:40:33.547755  4519 solver.cpp:330] Iteration 17200, Testing net (#0)
I1023 10:40:35.138643  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:40:36.118793  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.962891
I1023 10:40:36.118948  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0890846 (* 1 = 0.0890846 loss)
I1023 10:40:36.321077  4519 solver.cpp:218] Iteration 17200 (4.40623 iter/s, 22.6952s/100 iters), loss = 0.00348648
I1023 10:40:36.321108  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0034882 (* 1 = 0.0034882 loss)
I1023 10:40:36.321115  4519 sgd_solver.cpp:105] Iteration 17200, lr = 0.001
I1023 10:40:56.447639  4519 solver.cpp:218] Iteration 17300 (4.96858 iter/s, 20.1265s/100 iters), loss = 0.0277072
I1023 10:40:56.447671  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0277089 (* 1 = 0.0277089 loss)
I1023 10:40:56.447679  4519 sgd_solver.cpp:105] Iteration 17300, lr = 0.001
I1023 10:41:16.378810  4519 solver.cpp:330] Iteration 17400, Testing net (#0)
I1023 10:41:17.932729  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:41:18.948678  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 10:41:18.948741  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0850359 (* 1 = 0.0850359 loss)
I1023 10:41:18.973337  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:41:19.150423  4519 solver.cpp:218] Iteration 17400 (4.40476 iter/s, 22.7027s/100 iters), loss = 0.0652356
I1023 10:41:19.150450  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0652373 (* 1 = 0.0652373 loss)
I1023 10:41:19.150457  4519 sgd_solver.cpp:105] Iteration 17400, lr = 0.001
I1023 10:41:39.269192  4519 solver.cpp:218] Iteration 17500 (4.9705 iter/s, 20.1187s/100 iters), loss = 0.243422
I1023 10:41:39.269225  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243423 (* 1 = 0.243423 loss)
I1023 10:41:39.269232  4519 sgd_solver.cpp:105] Iteration 17500, lr = 0.001
I1023 10:41:59.188454  4519 solver.cpp:330] Iteration 17600, Testing net (#0)
I1023 10:42:00.741899  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:42:01.762161  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 10:42:01.762221  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0904876 (* 1 = 0.0904876 loss)
I1023 10:42:01.964138  4519 solver.cpp:218] Iteration 17600 (4.40629 iter/s, 22.6949s/100 iters), loss = 0.011397
I1023 10:42:01.964167  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113987 (* 1 = 0.0113987 loss)
I1023 10:42:01.964174  4519 sgd_solver.cpp:105] Iteration 17600, lr = 0.001
I1023 10:42:22.091591  4519 solver.cpp:218] Iteration 17700 (4.96836 iter/s, 20.1274s/100 iters), loss = 0.326578
I1023 10:42:22.091625  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32658 (* 1 = 0.32658 loss)
I1023 10:42:22.091632  4519 sgd_solver.cpp:105] Iteration 17700, lr = 0.001
I1023 10:42:30.174454  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:42:42.023344  4519 solver.cpp:330] Iteration 17800, Testing net (#0)
I1023 10:42:43.575227  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:42:44.595279  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 10:42:44.595335  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0830834 (* 1 = 0.0830834 loss)
I1023 10:42:44.797750  4519 solver.cpp:218] Iteration 17800 (4.40411 iter/s, 22.7061s/100 iters), loss = 0.0892802
I1023 10:42:44.797782  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0892819 (* 1 = 0.0892819 loss)
I1023 10:42:44.797790  4519 sgd_solver.cpp:105] Iteration 17800, lr = 0.001
I1023 10:43:04.926697  4519 solver.cpp:218] Iteration 17900 (4.96799 iter/s, 20.1289s/100 iters), loss = 0.0342683
I1023 10:43:04.926862  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.03427 (* 1 = 0.03427 loss)
I1023 10:43:04.926872  4519 sgd_solver.cpp:105] Iteration 17900, lr = 0.001
I1023 10:43:24.855268  4519 solver.cpp:330] Iteration 18000, Testing net (#0)
I1023 10:43:26.405019  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:43:27.426744  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1023 10:43:27.426805  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0778869 (* 1 = 0.0778869 loss)
I1023 10:43:27.628432  4519 solver.cpp:218] Iteration 18000 (4.40499 iter/s, 22.7015s/100 iters), loss = 0.0115025
I1023 10:43:27.628466  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115043 (* 1 = 0.0115043 loss)
I1023 10:43:27.628473  4519 sgd_solver.cpp:105] Iteration 18000, lr = 0.001
I1023 10:43:44.153224  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:43:47.753032  4519 solver.cpp:218] Iteration 18100 (4.96907 iter/s, 20.1245s/100 iters), loss = 0.00851013
I1023 10:43:47.753065  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00851186 (* 1 = 0.00851186 loss)
I1023 10:43:47.753072  4519 sgd_solver.cpp:105] Iteration 18100, lr = 0.001
I1023 10:44:07.671337  4519 solver.cpp:330] Iteration 18200, Testing net (#0)
I1023 10:44:09.185128  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:44:10.243021  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.960938
I1023 10:44:10.243083  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.087384 (* 1 = 0.087384 loss)
I1023 10:44:10.444983  4519 solver.cpp:218] Iteration 18200 (4.40687 iter/s, 22.6919s/100 iters), loss = 0.00806672
I1023 10:44:10.445014  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00806848 (* 1 = 0.00806848 loss)
I1023 10:44:10.445020  4519 sgd_solver.cpp:105] Iteration 18200, lr = 0.001
I1023 10:44:30.569676  4519 solver.cpp:218] Iteration 18300 (4.96904 iter/s, 20.1246s/100 iters), loss = 0.0368918
I1023 10:44:30.569823  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0368936 (* 1 = 0.0368936 loss)
I1023 10:44:30.569833  4519 sgd_solver.cpp:105] Iteration 18300, lr = 0.001
I1023 10:44:50.494081  4519 solver.cpp:330] Iteration 18400, Testing net (#0)
I1023 10:44:52.006048  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:44:53.065703  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 10:44:53.065758  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0845436 (* 1 = 0.0845436 loss)
I1023 10:44:53.268054  4519 solver.cpp:218] Iteration 18400 (4.40564 iter/s, 22.6982s/100 iters), loss = 0.00125738
I1023 10:44:53.268085  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00125912 (* 1 = 0.00125912 loss)
I1023 10:44:53.268091  4519 sgd_solver.cpp:105] Iteration 18400, lr = 0.001
I1023 10:44:57.924273  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:45:13.398221  4519 solver.cpp:218] Iteration 18500 (4.96769 iter/s, 20.1301s/100 iters), loss = 0.00304215
I1023 10:45:13.398344  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00304392 (* 1 = 0.00304392 loss)
I1023 10:45:13.398363  4519 sgd_solver.cpp:105] Iteration 18500, lr = 0.001
I1023 10:45:33.325875  4519 solver.cpp:330] Iteration 18600, Testing net (#0)
I1023 10:45:34.836774  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:45:35.897598  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.962891
I1023 10:45:35.897655  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0941443 (* 1 = 0.0941443 loss)
I1023 10:45:36.099407  4519 solver.cpp:218] Iteration 18600 (4.40509 iter/s, 22.701s/100 iters), loss = 0.0138937
I1023 10:45:36.099438  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138955 (* 1 = 0.0138955 loss)
I1023 10:45:36.099445  4519 sgd_solver.cpp:105] Iteration 18600, lr = 0.001
I1023 10:45:56.217079  4519 solver.cpp:218] Iteration 18700 (4.97078 iter/s, 20.1176s/100 iters), loss = 0.0732911
I1023 10:45:56.217214  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0732929 (* 1 = 0.0732929 loss)
I1023 10:45:56.217234  4519 sgd_solver.cpp:105] Iteration 18700, lr = 0.001
I1023 10:46:09.125142  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:46:16.147439  4519 solver.cpp:330] Iteration 18800, Testing net (#0)
I1023 10:46:17.657675  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:46:18.719525  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1023 10:46:18.719583  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0740261 (* 1 = 0.0740261 loss)
I1023 10:46:18.922222  4519 solver.cpp:218] Iteration 18800 (4.40433 iter/s, 22.705s/100 iters), loss = 0.0482862
I1023 10:46:18.922256  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0482879 (* 1 = 0.0482879 loss)
I1023 10:46:18.922272  4519 sgd_solver.cpp:105] Iteration 18800, lr = 0.001
I1023 10:46:39.043088  4519 solver.cpp:218] Iteration 18900 (4.96999 iter/s, 20.1208s/100 iters), loss = 0.00457405
I1023 10:46:39.043236  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00457583 (* 1 = 0.00457583 loss)
I1023 10:46:39.043246  4519 sgd_solver.cpp:105] Iteration 18900, lr = 0.001
I1023 10:46:58.974249  4519 solver.cpp:330] Iteration 19000, Testing net (#0)
I1023 10:47:00.448113  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:47:01.547993  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 10:47:01.548051  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0863519 (* 1 = 0.0863519 loss)
I1023 10:47:01.750432  4519 solver.cpp:218] Iteration 19000 (4.4039 iter/s, 22.7071s/100 iters), loss = 0.0561015
I1023 10:47:01.750463  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0561033 (* 1 = 0.0561033 loss)
I1023 10:47:01.750470  4519 sgd_solver.cpp:105] Iteration 19000, lr = 0.001
I1023 10:47:21.877503  4519 solver.cpp:218] Iteration 19100 (4.96846 iter/s, 20.127s/100 iters), loss = 0.000775713
I1023 10:47:21.884806  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00077748 (* 1 = 0.00077748 loss)
I1023 10:47:21.884822  4519 sgd_solver.cpp:105] Iteration 19100, lr = 0.001
I1023 10:47:22.917537  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:47:41.818393  4519 solver.cpp:330] Iteration 19200, Testing net (#0)
I1023 10:47:43.291679  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:47:44.391409  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 10:47:44.391468  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0967568 (* 1 = 0.0967568 loss)
I1023 10:47:44.592965  4519 solver.cpp:218] Iteration 19200 (4.40371 iter/s, 22.7081s/100 iters), loss = 0.00342192
I1023 10:47:44.592998  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00342368 (* 1 = 0.00342368 loss)
I1023 10:47:44.593004  4519 sgd_solver.cpp:105] Iteration 19200, lr = 0.001
I1023 10:48:04.718855  4519 solver.cpp:218] Iteration 19300 (4.96875 iter/s, 20.1258s/100 iters), loss = 0.00601962
I1023 10:48:04.719004  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00602138 (* 1 = 0.00602138 loss)
I1023 10:48:04.719014  4519 sgd_solver.cpp:105] Iteration 19300, lr = 0.001
I1023 10:48:24.642426  4519 solver.cpp:330] Iteration 19400, Testing net (#0)
I1023 10:48:26.113010  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:48:27.213614  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 10:48:27.213670  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0799895 (* 1 = 0.0799895 loss)
I1023 10:48:27.415812  4519 solver.cpp:218] Iteration 19400 (4.40592 iter/s, 22.6967s/100 iters), loss = 0.00243798
I1023 10:48:27.415843  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0024397 (* 1 = 0.0024397 loss)
I1023 10:48:27.415850  4519 sgd_solver.cpp:105] Iteration 19400, lr = 0.001
I1023 10:48:36.902554  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:48:47.553937  4519 solver.cpp:218] Iteration 19500 (4.96573 iter/s, 20.138s/100 iters), loss = 0.331868
I1023 10:48:47.553970  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.33187 (* 1 = 0.33187 loss)
I1023 10:48:47.553977  4519 sgd_solver.cpp:105] Iteration 19500, lr = 0.001
I1023 10:49:07.474503  4519 solver.cpp:330] Iteration 19600, Testing net (#0)
I1023 10:49:08.944897  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:49:10.047230  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 10:49:10.047287  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0816433 (* 1 = 0.0816433 loss)
I1023 10:49:10.249182  4519 solver.cpp:218] Iteration 19600 (4.40623 iter/s, 22.6951s/100 iters), loss = 0.130317
I1023 10:49:10.249217  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.130318 (* 1 = 0.130318 loss)
I1023 10:49:10.249225  4519 sgd_solver.cpp:105] Iteration 19600, lr = 0.001
I1023 10:49:30.374722  4519 solver.cpp:218] Iteration 19700 (4.96883 iter/s, 20.1254s/100 iters), loss = 0.00267153
I1023 10:49:30.374763  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00267322 (* 1 = 0.00267322 loss)
I1023 10:49:30.374771  4519 sgd_solver.cpp:105] Iteration 19700, lr = 0.001
I1023 10:49:48.113533  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:49:50.306859  4519 solver.cpp:330] Iteration 19800, Testing net (#0)
I1023 10:49:51.740833  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:49:52.878759  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.960938
I1023 10:49:52.878818  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.104347 (* 1 = 0.104347 loss)
I1023 10:49:53.080984  4519 solver.cpp:218] Iteration 19800 (4.40409 iter/s, 22.7062s/100 iters), loss = 0.00793071
I1023 10:49:53.081015  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00793242 (* 1 = 0.00793242 loss)
I1023 10:49:53.081023  4519 sgd_solver.cpp:105] Iteration 19800, lr = 0.001
I1023 10:50:13.199862  4519 solver.cpp:218] Iteration 19900 (4.97048 iter/s, 20.1188s/100 iters), loss = 0.00118703
I1023 10:50:13.199905  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00118876 (* 1 = 0.00118876 loss)
I1023 10:50:13.199913  4519 sgd_solver.cpp:105] Iteration 19900, lr = 0.001
I1023 10:50:33.119412  4519 solver.cpp:330] Iteration 20000, Testing net (#0)
I1023 10:50:34.551049  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:50:35.691473  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.962891
I1023 10:50:35.691536  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0872466 (* 1 = 0.0872466 loss)
I1023 10:50:35.893666  4519 solver.cpp:218] Iteration 20000 (4.40651 iter/s, 22.6937s/100 iters), loss = 0.0218784
I1023 10:50:35.893697  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0218802 (* 1 = 0.0218802 loss)
I1023 10:50:35.893703  4519 sgd_solver.cpp:46] MultiStep Status: Iteration 20000, step = 2
I1023 10:50:35.893707  4519 sgd_solver.cpp:105] Iteration 20000, lr = 0.0001
I1023 10:50:56.022331  4519 solver.cpp:218] Iteration 20100 (4.96806 iter/s, 20.1286s/100 iters), loss = 0.00562533
I1023 10:50:56.022364  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00562708 (* 1 = 0.00562708 loss)
I1023 10:50:56.022372  4519 sgd_solver.cpp:105] Iteration 20100, lr = 0.0001
I1023 10:51:01.889544  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:51:15.953133  4519 solver.cpp:330] Iteration 20200, Testing net (#0)
I1023 10:51:17.384161  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:51:18.525630  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.962891
I1023 10:51:18.525687  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0902578 (* 1 = 0.0902578 loss)
I1023 10:51:18.727910  4519 solver.cpp:218] Iteration 20200 (4.40422 iter/s, 22.7055s/100 iters), loss = 0.00279875
I1023 10:51:18.727943  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00280046 (* 1 = 0.00280046 loss)
I1023 10:51:18.727951  4519 sgd_solver.cpp:105] Iteration 20200, lr = 0.0001
I1023 10:51:38.856952  4519 solver.cpp:218] Iteration 20300 (4.96797 iter/s, 20.129s/100 iters), loss = 0.0226725
I1023 10:51:38.856983  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0226742 (* 1 = 0.0226742 loss)
I1023 10:51:38.856990  4519 sgd_solver.cpp:105] Iteration 20300, lr = 0.0001
I1023 10:51:58.787494  4519 solver.cpp:330] Iteration 20400, Testing net (#0)
I1023 10:52:00.218870  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:52:01.359918  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 10:52:01.359992  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0844849 (* 1 = 0.0844849 loss)
I1023 10:52:01.561990  4519 solver.cpp:218] Iteration 20400 (4.40433 iter/s, 22.7049s/100 iters), loss = 0.0141162
I1023 10:52:01.562018  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014118 (* 1 = 0.014118 loss)
I1023 10:52:01.562026  4519 sgd_solver.cpp:105] Iteration 20400, lr = 0.0001
I1023 10:52:15.675794  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:52:21.689059  4519 solver.cpp:218] Iteration 20500 (4.96845 iter/s, 20.127s/100 iters), loss = 0.0595525
I1023 10:52:21.689091  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0595543 (* 1 = 0.0595543 loss)
I1023 10:52:21.689098  4519 sgd_solver.cpp:105] Iteration 20500, lr = 0.0001
I1023 10:52:41.606048  4519 solver.cpp:330] Iteration 20600, Testing net (#0)
I1023 10:52:42.998461  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:52:44.177495  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 10:52:44.177557  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0834531 (* 1 = 0.0834531 loss)
I1023 10:52:44.379737  4519 solver.cpp:218] Iteration 20600 (4.40711 iter/s, 22.6906s/100 iters), loss = 0.00937139
I1023 10:52:44.379770  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0093732 (* 1 = 0.0093732 loss)
I1023 10:52:44.379787  4519 sgd_solver.cpp:105] Iteration 20600, lr = 0.0001
I1023 10:53:04.511551  4519 solver.cpp:218] Iteration 20700 (4.96728 iter/s, 20.1317s/100 iters), loss = 0.00296184
I1023 10:53:04.511584  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00296364 (* 1 = 0.00296364 loss)
I1023 10:53:04.511590  4519 sgd_solver.cpp:105] Iteration 20700, lr = 0.0001
I1023 10:53:24.441769  4519 solver.cpp:330] Iteration 20800, Testing net (#0)
I1023 10:53:25.833909  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:53:27.013432  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 10:53:27.013494  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0818887 (* 1 = 0.0818887 loss)
I1023 10:53:27.215731  4519 solver.cpp:218] Iteration 20800 (4.40449 iter/s, 22.7041s/100 iters), loss = 0.00452667
I1023 10:53:27.215760  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00452848 (* 1 = 0.00452848 loss)
I1023 10:53:27.215767  4519 sgd_solver.cpp:105] Iteration 20800, lr = 0.0001
I1023 10:53:29.653681  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:53:47.361709  4519 solver.cpp:218] Iteration 20900 (4.96379 iter/s, 20.1459s/100 iters), loss = 0.0395857
I1023 10:53:47.361738  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0395875 (* 1 = 0.0395875 loss)
I1023 10:53:47.361745  4519 sgd_solver.cpp:105] Iteration 20900, lr = 0.0001
I1023 10:54:07.307173  4519 solver.cpp:330] Iteration 21000, Testing net (#0)
I1023 10:54:08.698209  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:54:09.879125  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 10:54:09.879185  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0817237 (* 1 = 0.0817237 loss)
I1023 10:54:10.081239  4519 solver.cpp:218] Iteration 21000 (4.40152 iter/s, 22.7194s/100 iters), loss = 0.00661712
I1023 10:54:10.081272  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00661894 (* 1 = 0.00661894 loss)
I1023 10:54:10.081279  4519 sgd_solver.cpp:105] Iteration 21000, lr = 0.0001
I1023 10:54:30.215816  4519 solver.cpp:218] Iteration 21100 (4.9666 iter/s, 20.1345s/100 iters), loss = 0.00203882
I1023 10:54:30.215845  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00204064 (* 1 = 0.00204064 loss)
I1023 10:54:30.215852  4519 sgd_solver.cpp:105] Iteration 21100, lr = 0.0001
I1023 10:54:40.911504  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:54:50.152936  4519 solver.cpp:330] Iteration 21200, Testing net (#0)
I1023 10:54:51.542590  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:54:52.724400  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 10:54:52.724462  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0797785 (* 1 = 0.0797785 loss)
I1023 10:54:52.926708  4519 solver.cpp:218] Iteration 21200 (4.40319 iter/s, 22.7108s/100 iters), loss = 0.0200549
I1023 10:54:52.926740  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0200567 (* 1 = 0.0200567 loss)
I1023 10:54:52.926748  4519 sgd_solver.cpp:105] Iteration 21200, lr = 0.0001
I1023 10:55:13.068441  4519 solver.cpp:218] Iteration 21300 (4.96484 iter/s, 20.1416s/100 iters), loss = 0.00698363
I1023 10:55:13.068588  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00698546 (* 1 = 0.00698546 loss)
I1023 10:55:13.068598  4519 sgd_solver.cpp:105] Iteration 21300, lr = 0.0001
I1023 10:55:33.015559  4519 solver.cpp:330] Iteration 21400, Testing net (#0)
I1023 10:55:34.367159  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:55:35.586020  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 10:55:35.586082  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0775879 (* 1 = 0.0775879 loss)
I1023 10:55:35.788265  4519 solver.cpp:218] Iteration 21400 (4.40148 iter/s, 22.7196s/100 iters), loss = 0.00470662
I1023 10:55:35.788297  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00470844 (* 1 = 0.00470844 loss)
I1023 10:55:35.788303  4519 sgd_solver.cpp:105] Iteration 21400, lr = 0.0001
I1023 10:55:54.741343  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:55:55.931638  4519 solver.cpp:218] Iteration 21500 (4.96443 iter/s, 20.1433s/100 iters), loss = 0.0291892
I1023 10:55:55.931668  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.029191 (* 1 = 0.029191 loss)
I1023 10:55:55.931674  4519 sgd_solver.cpp:105] Iteration 21500, lr = 0.0001
I1023 10:56:15.873942  4519 solver.cpp:330] Iteration 21600, Testing net (#0)
I1023 10:56:17.225772  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:56:18.446295  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 10:56:18.446353  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0785355 (* 1 = 0.0785355 loss)
I1023 10:56:18.648440  4519 solver.cpp:218] Iteration 21600 (4.40205 iter/s, 22.7167s/100 iters), loss = 0.0355777
I1023 10:56:18.648470  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0355795 (* 1 = 0.0355795 loss)
I1023 10:56:18.648476  4519 sgd_solver.cpp:105] Iteration 21600, lr = 0.0001
I1023 10:56:38.786170  4519 solver.cpp:218] Iteration 21700 (4.96582 iter/s, 20.1376s/100 iters), loss = 0.00382686
I1023 10:56:38.786350  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00382866 (* 1 = 0.00382866 loss)
I1023 10:56:38.786360  4519 sgd_solver.cpp:105] Iteration 21700, lr = 0.0001
I1023 10:56:58.725363  4519 solver.cpp:330] Iteration 21800, Testing net (#0)
I1023 10:57:00.076817  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:57:01.299401  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 10:57:01.299463  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0760085 (* 1 = 0.0760085 loss)
I1023 10:57:01.501588  4519 solver.cpp:218] Iteration 21800 (4.40234 iter/s, 22.7152s/100 iters), loss = 0.00633796
I1023 10:57:01.501619  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00633976 (* 1 = 0.00633976 loss)
I1023 10:57:01.501626  4519 sgd_solver.cpp:105] Iteration 21800, lr = 0.0001
I1023 10:57:08.576233  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:57:21.630657  4519 solver.cpp:218] Iteration 21900 (4.96796 iter/s, 20.129s/100 iters), loss = 0.0144293
I1023 10:57:21.630808  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0144311 (* 1 = 0.0144311 loss)
I1023 10:57:21.630818  4519 sgd_solver.cpp:105] Iteration 21900, lr = 0.0001
I1023 10:57:41.559650  4519 solver.cpp:330] Iteration 22000, Testing net (#0)
I1023 10:57:42.909415  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:57:44.131525  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 10:57:44.131589  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0799071 (* 1 = 0.0799071 loss)
I1023 10:57:44.333613  4519 solver.cpp:218] Iteration 22000 (4.40475 iter/s, 22.7027s/100 iters), loss = 0.00360618
I1023 10:57:44.333644  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00360799 (* 1 = 0.00360799 loss)
I1023 10:57:44.333652  4519 sgd_solver.cpp:105] Iteration 22000, lr = 0.0001
I1023 10:58:04.462754  4519 solver.cpp:218] Iteration 22100 (4.96794 iter/s, 20.1291s/100 iters), loss = 0.0880046
I1023 10:58:04.462901  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0880065 (* 1 = 0.0880065 loss)
I1023 10:58:04.462911  4519 sgd_solver.cpp:105] Iteration 22100, lr = 0.0001
I1023 10:58:19.988400  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:58:24.397166  4519 solver.cpp:330] Iteration 22200, Testing net (#0)
I1023 10:58:25.709839  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:58:26.969277  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 10:58:26.969339  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.078248 (* 1 = 0.078248 loss)
I1023 10:58:27.170900  4519 solver.cpp:218] Iteration 22200 (4.40375 iter/s, 22.7079s/100 iters), loss = 0.05102
I1023 10:58:27.170931  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0510217 (* 1 = 0.0510217 loss)
I1023 10:58:27.170939  4519 sgd_solver.cpp:105] Iteration 22200, lr = 0.0001
I1023 10:58:47.284870  4519 solver.cpp:218] Iteration 22300 (4.97169 iter/s, 20.1139s/100 iters), loss = 0.0105883
I1023 10:58:47.285023  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105901 (* 1 = 0.0105901 loss)
I1023 10:58:47.285033  4519 sgd_solver.cpp:105] Iteration 22300, lr = 0.0001
I1023 10:59:07.207676  4519 solver.cpp:330] Iteration 22400, Testing net (#0)
I1023 10:59:08.519125  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:59:09.779186  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 10:59:09.779240  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0778358 (* 1 = 0.0778358 loss)
I1023 10:59:09.981341  4519 solver.cpp:218] Iteration 22400 (4.40601 iter/s, 22.6963s/100 iters), loss = 0.000722674
I1023 10:59:09.981372  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000724445 (* 1 = 0.000724445 loss)
I1023 10:59:09.981379  4519 sgd_solver.cpp:105] Iteration 22400, lr = 0.0001
I1023 10:59:30.105612  4519 solver.cpp:218] Iteration 22500 (4.96915 iter/s, 20.1242s/100 iters), loss = 0.00272605
I1023 10:59:30.105756  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00272781 (* 1 = 0.00272781 loss)
I1023 10:59:30.105775  4519 sgd_solver.cpp:105] Iteration 22500, lr = 0.0001
I1023 10:59:33.755753  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:59:50.036535  4519 solver.cpp:330] Iteration 22600, Testing net (#0)
I1023 10:59:51.347214  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 10:59:52.608526  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 10:59:52.608584  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0776157 (* 1 = 0.0776157 loss)
I1023 10:59:52.810557  4519 solver.cpp:218] Iteration 22600 (4.40437 iter/s, 22.7047s/100 iters), loss = 0.0793562
I1023 10:59:52.810590  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.079358 (* 1 = 0.079358 loss)
I1023 10:59:52.810598  4519 sgd_solver.cpp:105] Iteration 22600, lr = 0.0001
I1023 11:00:12.938901  4519 solver.cpp:218] Iteration 22700 (4.96814 iter/s, 20.1283s/100 iters), loss = 0.0538791
I1023 11:00:12.939049  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0538809 (* 1 = 0.0538809 loss)
I1023 11:00:12.939060  4519 sgd_solver.cpp:105] Iteration 22700, lr = 0.0001
I1023 11:00:32.866394  4519 solver.cpp:330] Iteration 22800, Testing net (#0)
I1023 11:00:34.177121  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:00:35.440433  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 11:00:35.440491  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0780828 (* 1 = 0.0780828 loss)
I1023 11:00:35.642161  4519 solver.cpp:218] Iteration 22800 (4.40469 iter/s, 22.7031s/100 iters), loss = 0.00952506
I1023 11:00:35.642194  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00952678 (* 1 = 0.00952678 loss)
I1023 11:00:35.642201  4519 sgd_solver.cpp:105] Iteration 22800, lr = 0.0001
I1023 11:00:47.542331  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:00:55.773267  4519 solver.cpp:218] Iteration 22900 (4.96746 iter/s, 20.131s/100 iters), loss = 0.00432914
I1023 11:00:55.773300  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00433081 (* 1 = 0.00433081 loss)
I1023 11:00:55.773308  4519 sgd_solver.cpp:105] Iteration 22900, lr = 0.0001
I1023 11:01:15.691092  4519 solver.cpp:330] Iteration 23000, Testing net (#0)
I1023 11:01:16.963416  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:01:18.263134  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 11:01:18.263309  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0780479 (* 1 = 0.0780479 loss)
I1023 11:01:18.465025  4519 solver.cpp:218] Iteration 23000 (4.40691 iter/s, 22.6917s/100 iters), loss = 0.0127772
I1023 11:01:18.465057  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127789 (* 1 = 0.0127789 loss)
I1023 11:01:18.465065  4519 sgd_solver.cpp:105] Iteration 23000, lr = 0.0001
I1023 11:01:38.591189  4519 solver.cpp:218] Iteration 23100 (4.96868 iter/s, 20.1261s/100 iters), loss = 0.00237057
I1023 11:01:38.591231  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00237229 (* 1 = 0.00237229 loss)
I1023 11:01:38.591238  4519 sgd_solver.cpp:105] Iteration 23100, lr = 0.0001
I1023 11:01:58.521075  4519 solver.cpp:330] Iteration 23200, Testing net (#0)
I1023 11:01:59.792747  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:02:01.094842  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 11:02:01.094903  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0773643 (* 1 = 0.0773643 loss)
I1023 11:02:01.296952  4519 solver.cpp:218] Iteration 23200 (4.40419 iter/s, 22.7057s/100 iters), loss = 0.00720009
I1023 11:02:01.296985  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00720179 (* 1 = 0.00720179 loss)
I1023 11:02:01.296993  4519 sgd_solver.cpp:105] Iteration 23200, lr = 0.0001
I1023 11:02:01.324928  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:02:21.423882  4519 solver.cpp:218] Iteration 23300 (4.96849 iter/s, 20.1268s/100 iters), loss = 0.00207664
I1023 11:02:21.423916  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00207834 (* 1 = 0.00207834 loss)
I1023 11:02:21.423923  4519 sgd_solver.cpp:105] Iteration 23300, lr = 0.0001
I1023 11:02:41.353351  4519 solver.cpp:330] Iteration 23400, Testing net (#0)
I1023 11:02:42.623157  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:02:43.924907  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 11:02:43.924968  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0793336 (* 1 = 0.0793336 loss)
I1023 11:02:44.126641  4519 solver.cpp:218] Iteration 23400 (4.40477 iter/s, 22.7027s/100 iters), loss = 0.001717
I1023 11:02:44.126672  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00171867 (* 1 = 0.00171867 loss)
I1023 11:02:44.126678  4519 sgd_solver.cpp:105] Iteration 23400, lr = 0.0001
I1023 11:03:04.248100  4519 solver.cpp:218] Iteration 23500 (4.96984 iter/s, 20.1214s/100 iters), loss = 0.0210375
I1023 11:03:04.248132  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0210392 (* 1 = 0.0210392 loss)
I1023 11:03:04.248141  4519 sgd_solver.cpp:105] Iteration 23500, lr = 0.0001
I1023 11:03:12.724680  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:03:24.171095  4519 solver.cpp:330] Iteration 23600, Testing net (#0)
I1023 11:03:25.441278  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:03:26.743660  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 11:03:26.743708  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0807783 (* 1 = 0.0807783 loss)
I1023 11:03:26.945752  4519 solver.cpp:218] Iteration 23600 (4.40576 iter/s, 22.6976s/100 iters), loss = 0.00665342
I1023 11:03:26.945782  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00665508 (* 1 = 0.00665508 loss)
I1023 11:03:26.945788  4519 sgd_solver.cpp:105] Iteration 23600, lr = 0.0001
I1023 11:03:47.071379  4519 solver.cpp:218] Iteration 23700 (4.96881 iter/s, 20.1255s/100 iters), loss = 0.00981908
I1023 11:03:47.071498  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0098208 (* 1 = 0.0098208 loss)
I1023 11:03:47.071506  4519 sgd_solver.cpp:105] Iteration 23700, lr = 0.0001
I1023 11:04:06.999598  4519 solver.cpp:330] Iteration 23800, Testing net (#0)
I1023 11:04:08.231673  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:04:09.571629  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1023 11:04:09.571679  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0843509 (* 1 = 0.0843509 loss)
I1023 11:04:09.773963  4519 solver.cpp:218] Iteration 23800 (4.40482 iter/s, 22.7024s/100 iters), loss = 0.0318889
I1023 11:04:09.773995  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0318906 (* 1 = 0.0318906 loss)
I1023 11:04:09.774001  4519 sgd_solver.cpp:105] Iteration 23800, lr = 0.0001
I1023 11:04:26.504942  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:04:29.905069  4519 solver.cpp:218] Iteration 23900 (4.96746 iter/s, 20.131s/100 iters), loss = 0.105478
I1023 11:04:29.905102  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10548 (* 1 = 0.10548 loss)
I1023 11:04:29.905109  4519 sgd_solver.cpp:105] Iteration 23900, lr = 0.0001
I1023 11:04:49.831604  4519 solver.cpp:330] Iteration 24000, Testing net (#0)
I1023 11:04:51.063182  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:04:52.404078  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 11:04:52.404134  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0782991 (* 1 = 0.0782991 loss)
I1023 11:04:52.605820  4519 solver.cpp:218] Iteration 24000 (4.40516 iter/s, 22.7007s/100 iters), loss = 0.002069
I1023 11:04:52.605852  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00207071 (* 1 = 0.00207071 loss)
I1023 11:04:52.605859  4519 sgd_solver.cpp:105] Iteration 24000, lr = 0.0001
I1023 11:05:12.727612  4519 solver.cpp:218] Iteration 24100 (4.96976 iter/s, 20.1217s/100 iters), loss = 0.00235604
I1023 11:05:12.727794  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00235775 (* 1 = 0.00235775 loss)
I1023 11:05:12.727815  4519 sgd_solver.cpp:105] Iteration 24100, lr = 0.0001
I1023 11:05:32.650354  4519 solver.cpp:330] Iteration 24200, Testing net (#0)
I1023 11:05:33.881587  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:05:35.223373  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 11:05:35.223431  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0749735 (* 1 = 0.0749735 loss)
I1023 11:05:35.425148  4519 solver.cpp:218] Iteration 24200 (4.40581 iter/s, 22.6973s/100 iters), loss = 0.00360023
I1023 11:05:35.425179  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00360195 (* 1 = 0.00360195 loss)
I1023 11:05:35.425186  4519 sgd_solver.cpp:105] Iteration 24200, lr = 0.0001
I1023 11:05:40.285761  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:05:55.552294  4519 solver.cpp:218] Iteration 24300 (4.96844 iter/s, 20.1271s/100 iters), loss = 0.0126451
I1023 11:05:55.552428  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126468 (* 1 = 0.0126468 loss)
I1023 11:05:55.552436  4519 sgd_solver.cpp:105] Iteration 24300, lr = 0.0001
I1023 11:06:15.480330  4519 solver.cpp:330] Iteration 24400, Testing net (#0)
I1023 11:06:16.711900  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:06:18.052738  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 11:06:18.052801  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0776233 (* 1 = 0.0776233 loss)
I1023 11:06:18.254535  4519 solver.cpp:218] Iteration 24400 (4.40489 iter/s, 22.7021s/100 iters), loss = 0.00481143
I1023 11:06:18.254568  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00481314 (* 1 = 0.00481314 loss)
I1023 11:06:18.254575  4519 sgd_solver.cpp:105] Iteration 24400, lr = 0.0001
I1023 11:06:38.378716  4519 solver.cpp:218] Iteration 24500 (4.96917 iter/s, 20.1241s/100 iters), loss = 0.00107762
I1023 11:06:38.378872  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00107933 (* 1 = 0.00107933 loss)
I1023 11:06:38.378883  4519 sgd_solver.cpp:105] Iteration 24500, lr = 0.0001
I1023 11:06:51.492791  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:06:58.316318  4519 solver.cpp:330] Iteration 24600, Testing net (#0)
I1023 11:06:59.508666  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:07:00.889897  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 11:07:00.889958  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0770429 (* 1 = 0.0770429 loss)
I1023 11:07:01.091730  4519 solver.cpp:218] Iteration 24600 (4.4028 iter/s, 22.7128s/100 iters), loss = 0.0237497
I1023 11:07:01.091765  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0237514 (* 1 = 0.0237514 loss)
I1023 11:07:01.091773  4519 sgd_solver.cpp:105] Iteration 24600, lr = 0.0001
I1023 11:07:21.204033  4519 solver.cpp:218] Iteration 24700 (4.9721 iter/s, 20.1122s/100 iters), loss = 0.00523748
I1023 11:07:21.204114  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00523918 (* 1 = 0.00523918 loss)
I1023 11:07:21.204133  4519 sgd_solver.cpp:105] Iteration 24700, lr = 0.0001
I1023 11:07:41.124732  4519 solver.cpp:330] Iteration 24800, Testing net (#0)
I1023 11:07:42.316013  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:07:43.696784  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 11:07:43.696846  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0788057 (* 1 = 0.0788057 loss)
I1023 11:07:43.899014  4519 solver.cpp:218] Iteration 24800 (4.40629 iter/s, 22.6948s/100 iters), loss = 0.043648
I1023 11:07:43.899045  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0436497 (* 1 = 0.0436497 loss)
I1023 11:07:43.899052  4519 sgd_solver.cpp:105] Iteration 24800, lr = 0.0001
I1023 11:08:04.028192  4519 solver.cpp:218] Iteration 24900 (4.96794 iter/s, 20.1291s/100 iters), loss = 0.0238917
I1023 11:08:04.028352  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0238934 (* 1 = 0.0238934 loss)
I1023 11:08:04.028362  4519 sgd_solver.cpp:105] Iteration 24900, lr = 0.0001
I1023 11:08:05.463445  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:08:23.957528  4519 solver.cpp:330] Iteration 25000, Testing net (#0)
I1023 11:08:25.148059  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:08:26.528815  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 11:08:26.528875  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0779352 (* 1 = 0.0779352 loss)
I1023 11:08:26.730768  4519 solver.cpp:218] Iteration 25000 (4.40483 iter/s, 22.7024s/100 iters), loss = 0.0806963
I1023 11:08:26.730801  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.080698 (* 1 = 0.080698 loss)
I1023 11:08:26.730808  4519 sgd_solver.cpp:105] Iteration 25000, lr = 0.0001
I1023 11:08:46.860018  4519 solver.cpp:218] Iteration 25100 (4.96792 iter/s, 20.1292s/100 iters), loss = 0.00151952
I1023 11:08:46.860162  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0015212 (* 1 = 0.0015212 loss)
I1023 11:08:46.860172  4519 sgd_solver.cpp:105] Iteration 25100, lr = 0.0001
I1023 11:09:06.789934  4519 solver.cpp:330] Iteration 25200, Testing net (#0)
I1023 11:09:07.979326  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:09:09.361138  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 11:09:09.361191  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0781429 (* 1 = 0.0781429 loss)
I1023 11:09:09.563091  4519 solver.cpp:218] Iteration 25200 (4.40473 iter/s, 22.7029s/100 iters), loss = 0.00253874
I1023 11:09:09.563122  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00254041 (* 1 = 0.00254041 loss)
I1023 11:09:09.563129  4519 sgd_solver.cpp:105] Iteration 25200, lr = 0.0001
I1023 11:09:19.250751  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:09:29.695701  4519 solver.cpp:218] Iteration 25300 (4.96709 iter/s, 20.1325s/100 iters), loss = 0.0367672
I1023 11:09:29.695732  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0367688 (* 1 = 0.0367688 loss)
I1023 11:09:29.695739  4519 sgd_solver.cpp:105] Iteration 25300, lr = 0.0001
I1023 11:09:49.610105  4519 solver.cpp:330] Iteration 25400, Testing net (#0)
I1023 11:09:50.761438  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:09:52.181046  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 11:09:52.181107  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0781592 (* 1 = 0.0781592 loss)
I1023 11:09:52.383054  4519 solver.cpp:218] Iteration 25400 (4.40776 iter/s, 22.6873s/100 iters), loss = 0.0468565
I1023 11:09:52.383085  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0468582 (* 1 = 0.0468582 loss)
I1023 11:09:52.383091  4519 sgd_solver.cpp:105] Iteration 25400, lr = 0.0001
I1023 11:10:12.509474  4519 solver.cpp:218] Iteration 25500 (4.96862 iter/s, 20.1263s/100 iters), loss = 0.0301627
I1023 11:10:12.509505  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0301644 (* 1 = 0.0301644 loss)
I1023 11:10:12.509512  4519 sgd_solver.cpp:105] Iteration 25500, lr = 0.0001
I1023 11:10:30.451094  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:10:32.441874  4519 solver.cpp:330] Iteration 25600, Testing net (#0)
I1023 11:10:33.593582  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:10:35.014281  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 11:10:35.014346  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0751638 (* 1 = 0.0751638 loss)
I1023 11:10:35.216589  4519 solver.cpp:218] Iteration 25600 (4.40392 iter/s, 22.707s/100 iters), loss = 0.0124417
I1023 11:10:35.216621  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124434 (* 1 = 0.0124434 loss)
I1023 11:10:35.216629  4519 sgd_solver.cpp:105] Iteration 25600, lr = 0.0001
I1023 11:10:55.339898  4519 solver.cpp:218] Iteration 25700 (4.96938 iter/s, 20.1232s/100 iters), loss = 0.00234337
I1023 11:10:55.339927  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00234503 (* 1 = 0.00234503 loss)
I1023 11:10:55.339933  4519 sgd_solver.cpp:105] Iteration 25700, lr = 0.0001
I1023 11:11:15.268553  4519 solver.cpp:330] Iteration 25800, Testing net (#0)
I1023 11:11:16.419359  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:11:17.840453  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 11:11:17.840509  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0744787 (* 1 = 0.0744787 loss)
I1023 11:11:18.042356  4519 solver.cpp:218] Iteration 25800 (4.40483 iter/s, 22.7024s/100 iters), loss = 0.0907903
I1023 11:11:18.042388  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.090792 (* 1 = 0.090792 loss)
I1023 11:11:18.042394  4519 sgd_solver.cpp:105] Iteration 25800, lr = 0.0001
I1023 11:11:38.159142  4519 solver.cpp:218] Iteration 25900 (4.97099 iter/s, 20.1167s/100 iters), loss = 0.00269644
I1023 11:11:38.159173  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00269809 (* 1 = 0.00269809 loss)
I1023 11:11:38.159179  4519 sgd_solver.cpp:105] Iteration 25900, lr = 0.0001
I1023 11:11:44.224283  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:11:58.081151  4519 solver.cpp:330] Iteration 26000, Testing net (#0)
I1023 11:11:59.230651  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:12:00.654753  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 11:12:00.654808  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0754419 (* 1 = 0.0754419 loss)
I1023 11:12:00.856673  4519 solver.cpp:218] Iteration 26000 (4.40578 iter/s, 22.6974s/100 iters), loss = 0.00224885
I1023 11:12:00.856708  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00225052 (* 1 = 0.00225052 loss)
I1023 11:12:00.856715  4519 sgd_solver.cpp:105] Iteration 26000, lr = 0.0001
I1023 11:12:20.982864  4519 solver.cpp:218] Iteration 26100 (4.96867 iter/s, 20.1261s/100 iters), loss = 0.00374362
I1023 11:12:20.982898  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00374533 (* 1 = 0.00374533 loss)
I1023 11:12:20.982904  4519 sgd_solver.cpp:105] Iteration 26100, lr = 0.0001
I1023 11:12:40.912878  4519 solver.cpp:330] Iteration 26200, Testing net (#0)
I1023 11:12:42.023933  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:12:43.483940  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 11:12:43.483994  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.075818 (* 1 = 0.075818 loss)
I1023 11:12:43.686179  4519 solver.cpp:218] Iteration 26200 (4.40466 iter/s, 22.7032s/100 iters), loss = 0.0275219
I1023 11:12:43.686214  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0275236 (* 1 = 0.0275236 loss)
I1023 11:12:43.686221  4519 sgd_solver.cpp:105] Iteration 26200, lr = 0.0001
I1023 11:12:58.204318  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:13:03.824323  4519 solver.cpp:218] Iteration 26300 (4.96572 iter/s, 20.1381s/100 iters), loss = 0.00891233
I1023 11:13:03.824355  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.008914 (* 1 = 0.008914 loss)
I1023 11:13:03.824362  4519 sgd_solver.cpp:105] Iteration 26300, lr = 0.0001
I1023 11:13:23.747403  4519 solver.cpp:330] Iteration 26400, Testing net (#0)
I1023 11:13:24.865162  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:13:26.333655  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 11:13:26.333710  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0771944 (* 1 = 0.0771944 loss)
I1023 11:13:26.538669  4519 solver.cpp:218] Iteration 26400 (4.40252 iter/s, 22.7143s/100 iters), loss = 0.021739
I1023 11:13:26.538707  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0217406 (* 1 = 0.0217406 loss)
I1023 11:13:26.538714  4519 sgd_solver.cpp:105] Iteration 26400, lr = 0.0001
I1023 11:13:46.695992  4519 solver.cpp:218] Iteration 26500 (4.961 iter/s, 20.1572s/100 iters), loss = 0.00338117
I1023 11:13:46.696024  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00338283 (* 1 = 0.00338283 loss)
I1023 11:13:46.696030  4519 sgd_solver.cpp:105] Iteration 26500, lr = 0.0001
I1023 11:14:06.621413  4519 solver.cpp:330] Iteration 26600, Testing net (#0)
I1023 11:14:07.731616  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:14:09.194108  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 11:14:09.194169  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0749673 (* 1 = 0.0749673 loss)
I1023 11:14:09.396131  4519 solver.cpp:218] Iteration 26600 (4.40528 iter/s, 22.7s/100 iters), loss = 0.000599224
I1023 11:14:09.396163  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000600878 (* 1 = 0.000600878 loss)
I1023 11:14:09.396170  4519 sgd_solver.cpp:105] Iteration 26600, lr = 0.0001
I1023 11:14:12.042557  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:14:29.524849  4519 solver.cpp:218] Iteration 26700 (4.96805 iter/s, 20.1286s/100 iters), loss = 0.0190819
I1023 11:14:29.524893  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0190836 (* 1 = 0.0190836 loss)
I1023 11:14:29.524899  4519 sgd_solver.cpp:105] Iteration 26700, lr = 0.0001
I1023 11:14:49.454546  4519 solver.cpp:330] Iteration 26800, Testing net (#0)
I1023 11:14:50.563362  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:14:52.026502  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 11:14:52.026566  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0735968 (* 1 = 0.0735968 loss)
I1023 11:14:52.228642  4519 solver.cpp:218] Iteration 26800 (4.40457 iter/s, 22.7037s/100 iters), loss = 0.00412381
I1023 11:14:52.228672  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00412544 (* 1 = 0.00412544 loss)
I1023 11:14:52.228679  4519 sgd_solver.cpp:105] Iteration 26800, lr = 0.0001
I1023 11:15:12.356019  4519 solver.cpp:218] Iteration 26900 (4.96838 iter/s, 20.1273s/100 iters), loss = 0.000785538
I1023 11:15:12.356060  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000787186 (* 1 = 0.000787186 loss)
I1023 11:15:12.356068  4519 sgd_solver.cpp:105] Iteration 26900, lr = 0.0001
I1023 11:15:23.258407  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:15:32.297219  4519 solver.cpp:330] Iteration 27000, Testing net (#0)
I1023 11:15:33.368427  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:15:34.869251  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 11:15:34.869312  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0719328 (* 1 = 0.0719328 loss)
I1023 11:15:35.071059  4519 solver.cpp:218] Iteration 27000 (4.40239 iter/s, 22.7149s/100 iters), loss = 0.00687069
I1023 11:15:35.071090  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00687234 (* 1 = 0.00687234 loss)
I1023 11:15:35.071097  4519 sgd_solver.cpp:105] Iteration 27000, lr = 0.0001
I1023 11:15:55.192797  4519 solver.cpp:218] Iteration 27100 (4.96977 iter/s, 20.1217s/100 iters), loss = 0.00920528
I1023 11:15:55.192940  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00920695 (* 1 = 0.00920695 loss)
I1023 11:15:55.192950  4519 sgd_solver.cpp:105] Iteration 27100, lr = 0.0001
I1023 11:16:15.118762  4519 solver.cpp:330] Iteration 27200, Testing net (#0)
I1023 11:16:16.190171  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:16:17.691746  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 11:16:17.691812  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0750744 (* 1 = 0.0750744 loss)
I1023 11:16:17.893636  4519 solver.cpp:218] Iteration 27200 (4.40516 iter/s, 22.7006s/100 iters), loss = 0.00521134
I1023 11:16:17.893672  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00521302 (* 1 = 0.00521302 loss)
I1023 11:16:17.893689  4519 sgd_solver.cpp:105] Iteration 27200, lr = 0.0001
I1023 11:16:37.040338  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:16:38.021519  4519 solver.cpp:218] Iteration 27300 (4.96826 iter/s, 20.1278s/100 iters), loss = 0.0030826
I1023 11:16:38.021551  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00308428 (* 1 = 0.00308428 loss)
I1023 11:16:38.021558  4519 sgd_solver.cpp:105] Iteration 27300, lr = 0.0001
I1023 11:16:57.951594  4519 solver.cpp:330] Iteration 27400, Testing net (#0)
I1023 11:16:59.022110  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:17:00.524679  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 11:17:00.524739  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0762893 (* 1 = 0.0762893 loss)
I1023 11:17:00.726747  4519 solver.cpp:218] Iteration 27400 (4.40429 iter/s, 22.7051s/100 iters), loss = 0.0132188
I1023 11:17:00.726779  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132205 (* 1 = 0.0132205 loss)
I1023 11:17:00.726786  4519 sgd_solver.cpp:105] Iteration 27400, lr = 0.0001
I1023 11:17:20.854137  4519 solver.cpp:218] Iteration 27500 (4.96838 iter/s, 20.1273s/100 iters), loss = 0.000549782
I1023 11:17:20.854281  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00055149 (* 1 = 0.00055149 loss)
I1023 11:17:20.854291  4519 sgd_solver.cpp:105] Iteration 27500, lr = 0.0001
I1023 11:17:40.784859  4519 solver.cpp:330] Iteration 27600, Testing net (#0)
I1023 11:17:41.854004  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:17:43.356361  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 11:17:43.356423  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.075318 (* 1 = 0.075318 loss)
I1023 11:17:43.558161  4519 solver.cpp:218] Iteration 27600 (4.40454 iter/s, 22.7038s/100 iters), loss = 0.0240383
I1023 11:17:43.558195  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.02404 (* 1 = 0.02404 loss)
I1023 11:17:43.558202  4519 sgd_solver.cpp:105] Iteration 27600, lr = 0.0001
I1023 11:17:51.034755  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:18:03.683004  4519 solver.cpp:218] Iteration 27700 (4.969 iter/s, 20.1248s/100 iters), loss = 0.0646488
I1023 11:18:03.683050  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0646505 (* 1 = 0.0646505 loss)
I1023 11:18:03.683058  4519 sgd_solver.cpp:105] Iteration 27700, lr = 0.0001
I1023 11:18:23.606672  4519 solver.cpp:330] Iteration 27800, Testing net (#0)
I1023 11:18:24.637434  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:18:26.177561  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 11:18:26.177621  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0765765 (* 1 = 0.0765765 loss)
I1023 11:18:26.379555  4519 solver.cpp:218] Iteration 27800 (4.40598 iter/s, 22.6964s/100 iters), loss = 0.0252183
I1023 11:18:26.379587  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.02522 (* 1 = 0.02522 loss)
I1023 11:18:26.379593  4519 sgd_solver.cpp:105] Iteration 27800, lr = 0.0001
I1023 11:18:46.509429  4519 solver.cpp:218] Iteration 27900 (4.96776 iter/s, 20.1298s/100 iters), loss = 0.0161301
I1023 11:18:46.509460  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0161318 (* 1 = 0.0161318 loss)
I1023 11:18:46.509467  4519 sgd_solver.cpp:105] Iteration 27900, lr = 0.0001
I1023 11:19:02.240985  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:19:06.448074  4519 solver.cpp:330] Iteration 28000, Testing net (#0)
I1023 11:19:07.479024  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:19:09.019923  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 11:19:09.019989  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0760507 (* 1 = 0.0760507 loss)
I1023 11:19:09.222326  4519 solver.cpp:218] Iteration 28000 (4.4028 iter/s, 22.7128s/100 iters), loss = 0.0556232
I1023 11:19:09.222357  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0556249 (* 1 = 0.0556249 loss)
I1023 11:19:09.222364  4519 sgd_solver.cpp:105] Iteration 28000, lr = 0.0001
I1023 11:19:29.346427  4519 solver.cpp:218] Iteration 28100 (4.96919 iter/s, 20.124s/100 iters), loss = 0.00146847
I1023 11:19:29.346458  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00147019 (* 1 = 0.00147019 loss)
I1023 11:19:29.346465  4519 sgd_solver.cpp:105] Iteration 28100, lr = 0.0001
I1023 11:19:49.277501  4519 solver.cpp:330] Iteration 28200, Testing net (#0)
I1023 11:19:50.307752  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:19:51.848685  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 11:19:51.848726  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0743522 (* 1 = 0.0743522 loss)
I1023 11:19:52.050544  4519 solver.cpp:218] Iteration 28200 (4.4045 iter/s, 22.704s/100 iters), loss = 0.00641072
I1023 11:19:52.050578  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00641245 (* 1 = 0.00641245 loss)
I1023 11:19:52.050585  4519 sgd_solver.cpp:105] Iteration 28200, lr = 0.0001
I1023 11:20:12.171108  4519 solver.cpp:218] Iteration 28300 (4.97006 iter/s, 20.1205s/100 iters), loss = 0.00290451
I1023 11:20:12.171139  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00290626 (* 1 = 0.00290626 loss)
I1023 11:20:12.171146  4519 sgd_solver.cpp:105] Iteration 28300, lr = 0.0001
I1023 11:20:16.023175  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:20:32.095752  4519 solver.cpp:330] Iteration 28400, Testing net (#0)
I1023 11:20:33.124721  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:20:34.668325  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 11:20:34.668383  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0750932 (* 1 = 0.0750932 loss)
I1023 11:20:34.870380  4519 solver.cpp:218] Iteration 28400 (4.40545 iter/s, 22.6992s/100 iters), loss = 0.0117717
I1023 11:20:34.870412  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117735 (* 1 = 0.0117735 loss)
I1023 11:20:34.870419  4519 sgd_solver.cpp:105] Iteration 28400, lr = 0.0001
I1023 11:20:55.000792  4519 solver.cpp:218] Iteration 28500 (4.96763 iter/s, 20.1303s/100 iters), loss = 0.0253414
I1023 11:20:55.000825  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0253432 (* 1 = 0.0253432 loss)
I1023 11:20:55.000844  4519 sgd_solver.cpp:105] Iteration 28500, lr = 0.0001
I1023 11:21:14.933094  4519 solver.cpp:330] Iteration 28600, Testing net (#0)
I1023 11:21:15.924885  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:21:17.505587  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 11:21:17.505645  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0731523 (* 1 = 0.0731523 loss)
I1023 11:21:17.707687  4519 solver.cpp:218] Iteration 28600 (4.40397 iter/s, 22.7068s/100 iters), loss = 0.0440488
I1023 11:21:17.707738  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0440506 (* 1 = 0.0440506 loss)
I1023 11:21:17.707746  4519 sgd_solver.cpp:105] Iteration 28600, lr = 0.0001
I1023 11:21:29.817495  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:21:37.848630  4519 solver.cpp:218] Iteration 28700 (4.96503 iter/s, 20.1409s/100 iters), loss = 0.00918002
I1023 11:21:37.848664  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0091818 (* 1 = 0.0091818 loss)
I1023 11:21:37.848670  4519 sgd_solver.cpp:105] Iteration 28700, lr = 0.0001
I1023 11:21:57.773195  4519 solver.cpp:330] Iteration 28800, Testing net (#0)
I1023 11:21:58.764904  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:22:00.346927  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 11:22:00.346987  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0768248 (* 1 = 0.0768248 loss)
I1023 11:22:00.548559  4519 solver.cpp:218] Iteration 28800 (4.40532 iter/s, 22.6998s/100 iters), loss = 0.00735368
I1023 11:22:00.548590  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00735546 (* 1 = 0.00735546 loss)
I1023 11:22:00.548597  4519 sgd_solver.cpp:105] Iteration 28800, lr = 0.0001
I1023 11:22:20.673893  4519 solver.cpp:218] Iteration 28900 (4.96888 iter/s, 20.1252s/100 iters), loss = 0.141357
I1023 11:22:20.673926  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.141359 (* 1 = 0.141359 loss)
I1023 11:22:20.673933  4519 sgd_solver.cpp:105] Iteration 28900, lr = 0.0001
I1023 11:22:40.601269  4519 solver.cpp:330] Iteration 29000, Testing net (#0)
I1023 11:22:41.591975  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:22:43.172910  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 11:22:43.172972  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0767767 (* 1 = 0.0767767 loss)
I1023 11:22:43.374861  4519 solver.cpp:218] Iteration 29000 (4.40512 iter/s, 22.7009s/100 iters), loss = 0.0288903
I1023 11:22:43.374891  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0288921 (* 1 = 0.0288921 loss)
I1023 11:22:43.374898  4519 sgd_solver.cpp:105] Iteration 29000, lr = 0.0001
I1023 11:22:43.802830  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:23:03.506511  4519 solver.cpp:218] Iteration 29100 (4.96732 iter/s, 20.1316s/100 iters), loss = 0.0416435
I1023 11:23:03.506553  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0416453 (* 1 = 0.0416453 loss)
I1023 11:23:03.506561  4519 sgd_solver.cpp:105] Iteration 29100, lr = 0.0001
I1023 11:23:23.437726  4519 solver.cpp:330] Iteration 29200, Testing net (#0)
I1023 11:23:24.427178  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:23:26.010128  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 11:23:26.010169  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0767708 (* 1 = 0.0767708 loss)
I1023 11:23:26.212280  4519 solver.cpp:218] Iteration 29200 (4.40419 iter/s, 22.7057s/100 iters), loss = 0.0739337
I1023 11:23:26.212312  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0739355 (* 1 = 0.0739355 loss)
I1023 11:23:26.212318  4519 sgd_solver.cpp:105] Iteration 29200, lr = 0.0001
I1023 11:23:46.340636  4519 solver.cpp:218] Iteration 29300 (4.96814 iter/s, 20.1283s/100 iters), loss = 0.00211324
I1023 11:23:46.340667  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00211506 (* 1 = 0.00211506 loss)
I1023 11:23:46.340672  4519 sgd_solver.cpp:105] Iteration 29300, lr = 0.0001
I1023 11:23:55.024986  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:24:06.272092  4519 solver.cpp:330] Iteration 29400, Testing net (#0)
I1023 11:24:07.223244  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:24:08.844275  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 11:24:08.844331  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0762096 (* 1 = 0.0762096 loss)
I1023 11:24:09.046222  4519 solver.cpp:218] Iteration 29400 (4.40422 iter/s, 22.7055s/100 iters), loss = 0.0366487
I1023 11:24:09.046254  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0366505 (* 1 = 0.0366505 loss)
I1023 11:24:09.046260  4519 sgd_solver.cpp:105] Iteration 29400, lr = 0.0001
I1023 11:24:29.167059  4519 solver.cpp:218] Iteration 29500 (4.96999 iter/s, 20.1208s/100 iters), loss = 0.00247495
I1023 11:24:29.167212  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00247676 (* 1 = 0.00247676 loss)
I1023 11:24:29.167222  4519 sgd_solver.cpp:105] Iteration 29500, lr = 0.0001
I1023 11:24:49.087852  4519 solver.cpp:330] Iteration 29600, Testing net (#0)
I1023 11:24:50.038633  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:24:51.660248  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 11:24:51.660306  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0750322 (* 1 = 0.0750322 loss)
I1023 11:24:51.862541  4519 solver.cpp:218] Iteration 29600 (4.4062 iter/s, 22.6953s/100 iters), loss = 0.00374775
I1023 11:24:51.862576  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00374958 (* 1 = 0.00374958 loss)
I1023 11:24:51.862581  4519 sgd_solver.cpp:105] Iteration 29600, lr = 0.0001
I1023 11:25:08.797062  4528 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:25:11.994848  4519 solver.cpp:218] Iteration 29700 (4.96716 iter/s, 20.1322s/100 iters), loss = 0.00595095
I1023 11:25:11.994889  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00595277 (* 1 = 0.00595277 loss)
I1023 11:25:11.994896  4519 sgd_solver.cpp:105] Iteration 29700, lr = 0.0001
I1023 11:25:31.925088  4519 solver.cpp:330] Iteration 29800, Testing net (#0)
I1023 11:25:32.874344  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:25:34.496465  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 11:25:34.496521  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0752775 (* 1 = 0.0752775 loss)
I1023 11:25:34.698921  4519 solver.cpp:218] Iteration 29800 (4.40452 iter/s, 22.704s/100 iters), loss = 0.00436803
I1023 11:25:34.698951  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00436984 (* 1 = 0.00436984 loss)
I1023 11:25:34.698957  4519 sgd_solver.cpp:105] Iteration 29800, lr = 0.0001
I1023 11:25:54.828542  4519 solver.cpp:218] Iteration 29900 (4.96782 iter/s, 20.1295s/100 iters), loss = 0.0142793
I1023 11:25:54.828691  4519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142811 (* 1 = 0.0142811 loss)
I1023 11:25:54.828701  4519 sgd_solver.cpp:105] Iteration 29900, lr = 0.0001
I1023 11:26:14.760076  4519 solver.cpp:447] Snapshotting to binary proto file xn/English_orange/snapshot/res20/res20_penlu_alpha1_etanostudy_2study_2decay_iter_30000.caffemodel
I1023 11:26:14.769769  4519 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/English_orange/snapshot/res20/res20_penlu_alpha1_etanostudy_2study_2decay_iter_30000.solverstate
I1023 11:26:14.826565  4519 solver.cpp:310] Iteration 30000, loss = 0.0135702
I1023 11:26:14.826613  4519 solver.cpp:330] Iteration 30000, Testing net (#0)
I1023 11:26:15.776038  4529 data_layer.cpp:73] Restarting data prefetching from start.
I1023 11:26:17.398914  4519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 11:26:17.398974  4519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0733842 (* 1 = 0.0733842 loss)
I1023 11:26:17.398979  4519 solver.cpp:315] Optimization Done.
I1023 11:26:17.398983  4519 caffe.cpp:259] Optimization Done.
