I1022 19:29:08.891405  3845 caffe.cpp:218] Using GPUs 0
I1022 19:29:08.929549  3845 caffe.cpp:223] GPU 0: GeForce GTX 1080
I1022 19:29:09.155967  3845 solver.cpp:44] Initializing solver from parameters: 
test_iter: 64
test_interval: 200
base_lr: 0.01
display: 100
max_iter: 30000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 30000
snapshot_prefix: "xn/English_orange/snapshot/res20/res20_relu"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/English_orange/neural/res20/res20_relu_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 10000
stepvalue: 20000
I1022 19:29:09.156102  3845 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/English_orange/neural/res20/res20_relu_train_test.prototxt
I1022 19:29:09.157263  3845 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/English_orange/neural/res20/res20_relu_train_test.prototxt
I1022 19:29:09.157272  3845 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1022 19:29:09.157382  3845 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I1022 19:29:09.157428  3845 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I1022 19:29:09.157793  3845 net.cpp:51] Initializing net from parameters: 
name: "resnet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_file: "/home/x306/caffe/xn/English_orange/data/orange1_mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/English_orange/data/train1_lmdb"
    batch_size: 8
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution9"
  top: "Convolution9"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution11"
  top: "Convolution11"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
I1022 19:29:09.158174  3845 layer_factory.hpp:77] Creating layer Data1
I1022 19:29:09.158265  3845 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/English_orange/data/train1_lmdb
I1022 19:29:09.158288  3845 net.cpp:84] Creating Layer Data1
I1022 19:29:09.158294  3845 net.cpp:380] Data1 -> Data1
I1022 19:29:09.158314  3845 net.cpp:380] Data1 -> Data2
I1022 19:29:09.158325  3845 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/English_orange/data/orange1_mean.binaryproto
I1022 19:29:09.160650  3845 data_layer.cpp:45] output data size: 8,3,224,224
I1022 19:29:09.168411  3845 net.cpp:122] Setting up Data1
I1022 19:29:09.168443  3845 net.cpp:129] Top shape: 8 3 224 224 (1204224)
I1022 19:29:09.168448  3845 net.cpp:129] Top shape: 8 (8)
I1022 19:29:09.168452  3845 net.cpp:137] Memory required for data: 4816928
I1022 19:29:09.168462  3845 layer_factory.hpp:77] Creating layer Convolution1
I1022 19:29:09.168485  3845 net.cpp:84] Creating Layer Convolution1
I1022 19:29:09.168500  3845 net.cpp:406] Convolution1 <- Data1
I1022 19:29:09.168519  3845 net.cpp:380] Convolution1 -> Convolution1
I1022 19:29:09.316658  3845 net.cpp:122] Setting up Convolution1
I1022 19:29:09.316682  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.316686  3845 net.cpp:137] Memory required for data: 30507040
I1022 19:29:09.316701  3845 layer_factory.hpp:77] Creating layer BatchNorm1
I1022 19:29:09.316725  3845 net.cpp:84] Creating Layer BatchNorm1
I1022 19:29:09.316730  3845 net.cpp:406] BatchNorm1 <- Convolution1
I1022 19:29:09.316735  3845 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1022 19:29:09.316901  3845 net.cpp:122] Setting up BatchNorm1
I1022 19:29:09.316907  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.316910  3845 net.cpp:137] Memory required for data: 56197152
I1022 19:29:09.316917  3845 layer_factory.hpp:77] Creating layer Scale1
I1022 19:29:09.316928  3845 net.cpp:84] Creating Layer Scale1
I1022 19:29:09.316943  3845 net.cpp:406] Scale1 <- Convolution1
I1022 19:29:09.316947  3845 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1022 19:29:09.316989  3845 layer_factory.hpp:77] Creating layer Scale1
I1022 19:29:09.317131  3845 net.cpp:122] Setting up Scale1
I1022 19:29:09.317137  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.317139  3845 net.cpp:137] Memory required for data: 81887264
I1022 19:29:09.317143  3845 layer_factory.hpp:77] Creating layer ReLU1
I1022 19:29:09.317149  3845 net.cpp:84] Creating Layer ReLU1
I1022 19:29:09.317152  3845 net.cpp:406] ReLU1 <- Convolution1
I1022 19:29:09.317157  3845 net.cpp:367] ReLU1 -> Convolution1 (in-place)
I1022 19:29:09.317353  3845 net.cpp:122] Setting up ReLU1
I1022 19:29:09.317361  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.317364  3845 net.cpp:137] Memory required for data: 107577376
I1022 19:29:09.317366  3845 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I1022 19:29:09.317371  3845 net.cpp:84] Creating Layer Convolution1_ReLU1_0_split
I1022 19:29:09.317373  3845 net.cpp:406] Convolution1_ReLU1_0_split <- Convolution1
I1022 19:29:09.317379  3845 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I1022 19:29:09.317399  3845 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I1022 19:29:09.317430  3845 net.cpp:122] Setting up Convolution1_ReLU1_0_split
I1022 19:29:09.317445  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.317448  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.317451  3845 net.cpp:137] Memory required for data: 158957600
I1022 19:29:09.317452  3845 layer_factory.hpp:77] Creating layer Convolution2
I1022 19:29:09.317461  3845 net.cpp:84] Creating Layer Convolution2
I1022 19:29:09.317474  3845 net.cpp:406] Convolution2 <- Convolution1_ReLU1_0_split_0
I1022 19:29:09.317481  3845 net.cpp:380] Convolution2 -> Convolution2
I1022 19:29:09.318953  3845 net.cpp:122] Setting up Convolution2
I1022 19:29:09.318964  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.318981  3845 net.cpp:137] Memory required for data: 184647712
I1022 19:29:09.318987  3845 layer_factory.hpp:77] Creating layer BatchNorm2
I1022 19:29:09.319002  3845 net.cpp:84] Creating Layer BatchNorm2
I1022 19:29:09.319005  3845 net.cpp:406] BatchNorm2 <- Convolution2
I1022 19:29:09.319018  3845 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1022 19:29:09.319200  3845 net.cpp:122] Setting up BatchNorm2
I1022 19:29:09.319206  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.319209  3845 net.cpp:137] Memory required for data: 210337824
I1022 19:29:09.319229  3845 layer_factory.hpp:77] Creating layer Scale2
I1022 19:29:09.319252  3845 net.cpp:84] Creating Layer Scale2
I1022 19:29:09.319255  3845 net.cpp:406] Scale2 <- Convolution2
I1022 19:29:09.319272  3845 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1022 19:29:09.319303  3845 layer_factory.hpp:77] Creating layer Scale2
I1022 19:29:09.319455  3845 net.cpp:122] Setting up Scale2
I1022 19:29:09.319464  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.319478  3845 net.cpp:137] Memory required for data: 236027936
I1022 19:29:09.319485  3845 layer_factory.hpp:77] Creating layer ReLU2
I1022 19:29:09.319492  3845 net.cpp:84] Creating Layer ReLU2
I1022 19:29:09.319496  3845 net.cpp:406] ReLU2 <- Convolution2
I1022 19:29:09.319502  3845 net.cpp:367] ReLU2 -> Convolution2 (in-place)
I1022 19:29:09.319983  3845 net.cpp:122] Setting up ReLU2
I1022 19:29:09.320001  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.320004  3845 net.cpp:137] Memory required for data: 261718048
I1022 19:29:09.320008  3845 layer_factory.hpp:77] Creating layer Convolution3
I1022 19:29:09.320025  3845 net.cpp:84] Creating Layer Convolution3
I1022 19:29:09.320029  3845 net.cpp:406] Convolution3 <- Convolution2
I1022 19:29:09.320035  3845 net.cpp:380] Convolution3 -> Convolution3
I1022 19:29:09.320605  3845 net.cpp:122] Setting up Convolution3
I1022 19:29:09.320624  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.320627  3845 net.cpp:137] Memory required for data: 287408160
I1022 19:29:09.320631  3845 layer_factory.hpp:77] Creating layer BatchNorm3
I1022 19:29:09.320638  3845 net.cpp:84] Creating Layer BatchNorm3
I1022 19:29:09.320642  3845 net.cpp:406] BatchNorm3 <- Convolution3
I1022 19:29:09.320648  3845 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1022 19:29:09.320807  3845 net.cpp:122] Setting up BatchNorm3
I1022 19:29:09.320813  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.320825  3845 net.cpp:137] Memory required for data: 313098272
I1022 19:29:09.320832  3845 layer_factory.hpp:77] Creating layer Scale3
I1022 19:29:09.320847  3845 net.cpp:84] Creating Layer Scale3
I1022 19:29:09.320852  3845 net.cpp:406] Scale3 <- Convolution3
I1022 19:29:09.320859  3845 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1022 19:29:09.320896  3845 layer_factory.hpp:77] Creating layer Scale3
I1022 19:29:09.321521  3845 net.cpp:122] Setting up Scale3
I1022 19:29:09.321532  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.321538  3845 net.cpp:137] Memory required for data: 338788384
I1022 19:29:09.321543  3845 layer_factory.hpp:77] Creating layer Eltwise1
I1022 19:29:09.321552  3845 net.cpp:84] Creating Layer Eltwise1
I1022 19:29:09.321557  3845 net.cpp:406] Eltwise1 <- Convolution1_ReLU1_0_split_1
I1022 19:29:09.321563  3845 net.cpp:406] Eltwise1 <- Convolution3
I1022 19:29:09.321568  3845 net.cpp:380] Eltwise1 -> Eltwise1
I1022 19:29:09.321590  3845 net.cpp:122] Setting up Eltwise1
I1022 19:29:09.321596  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.321601  3845 net.cpp:137] Memory required for data: 364478496
I1022 19:29:09.321605  3845 layer_factory.hpp:77] Creating layer ReLU3
I1022 19:29:09.321612  3845 net.cpp:84] Creating Layer ReLU3
I1022 19:29:09.321616  3845 net.cpp:406] ReLU3 <- Eltwise1
I1022 19:29:09.321624  3845 net.cpp:367] ReLU3 -> Eltwise1 (in-place)
I1022 19:29:09.322068  3845 net.cpp:122] Setting up ReLU3
I1022 19:29:09.322079  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.322084  3845 net.cpp:137] Memory required for data: 390168608
I1022 19:29:09.322089  3845 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I1022 19:29:09.322098  3845 net.cpp:84] Creating Layer Eltwise1_ReLU3_0_split
I1022 19:29:09.322101  3845 net.cpp:406] Eltwise1_ReLU3_0_split <- Eltwise1
I1022 19:29:09.322108  3845 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I1022 19:29:09.322116  3845 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I1022 19:29:09.322145  3845 net.cpp:122] Setting up Eltwise1_ReLU3_0_split
I1022 19:29:09.322152  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.322157  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.322162  3845 net.cpp:137] Memory required for data: 441548832
I1022 19:29:09.322166  3845 layer_factory.hpp:77] Creating layer Convolution4
I1022 19:29:09.322178  3845 net.cpp:84] Creating Layer Convolution4
I1022 19:29:09.322182  3845 net.cpp:406] Convolution4 <- Eltwise1_ReLU3_0_split_0
I1022 19:29:09.322190  3845 net.cpp:380] Convolution4 -> Convolution4
I1022 19:29:09.323093  3845 net.cpp:122] Setting up Convolution4
I1022 19:29:09.323104  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.323109  3845 net.cpp:137] Memory required for data: 467238944
I1022 19:29:09.323118  3845 layer_factory.hpp:77] Creating layer BatchNorm4
I1022 19:29:09.323125  3845 net.cpp:84] Creating Layer BatchNorm4
I1022 19:29:09.323129  3845 net.cpp:406] BatchNorm4 <- Convolution4
I1022 19:29:09.323137  3845 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1022 19:29:09.323282  3845 net.cpp:122] Setting up BatchNorm4
I1022 19:29:09.323288  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.323293  3845 net.cpp:137] Memory required for data: 492929056
I1022 19:29:09.323302  3845 layer_factory.hpp:77] Creating layer Scale4
I1022 19:29:09.323307  3845 net.cpp:84] Creating Layer Scale4
I1022 19:29:09.323312  3845 net.cpp:406] Scale4 <- Convolution4
I1022 19:29:09.323318  3845 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1022 19:29:09.323346  3845 layer_factory.hpp:77] Creating layer Scale4
I1022 19:29:09.323460  3845 net.cpp:122] Setting up Scale4
I1022 19:29:09.323467  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.323472  3845 net.cpp:137] Memory required for data: 518619168
I1022 19:29:09.323479  3845 layer_factory.hpp:77] Creating layer ReLU4
I1022 19:29:09.323487  3845 net.cpp:84] Creating Layer ReLU4
I1022 19:29:09.323490  3845 net.cpp:406] ReLU4 <- Convolution4
I1022 19:29:09.323495  3845 net.cpp:367] ReLU4 -> Convolution4 (in-place)
I1022 19:29:09.323621  3845 net.cpp:122] Setting up ReLU4
I1022 19:29:09.323628  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.323633  3845 net.cpp:137] Memory required for data: 544309280
I1022 19:29:09.323638  3845 layer_factory.hpp:77] Creating layer Convolution5
I1022 19:29:09.323648  3845 net.cpp:84] Creating Layer Convolution5
I1022 19:29:09.323652  3845 net.cpp:406] Convolution5 <- Convolution4
I1022 19:29:09.323660  3845 net.cpp:380] Convolution5 -> Convolution5
I1022 19:29:09.324925  3845 net.cpp:122] Setting up Convolution5
I1022 19:29:09.324936  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.324942  3845 net.cpp:137] Memory required for data: 569999392
I1022 19:29:09.324950  3845 layer_factory.hpp:77] Creating layer BatchNorm5
I1022 19:29:09.324959  3845 net.cpp:84] Creating Layer BatchNorm5
I1022 19:29:09.324964  3845 net.cpp:406] BatchNorm5 <- Convolution5
I1022 19:29:09.324970  3845 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1022 19:29:09.325119  3845 net.cpp:122] Setting up BatchNorm5
I1022 19:29:09.325125  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.325130  3845 net.cpp:137] Memory required for data: 595689504
I1022 19:29:09.325142  3845 layer_factory.hpp:77] Creating layer Scale5
I1022 19:29:09.325148  3845 net.cpp:84] Creating Layer Scale5
I1022 19:29:09.325152  3845 net.cpp:406] Scale5 <- Convolution5
I1022 19:29:09.325158  3845 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1022 19:29:09.325188  3845 layer_factory.hpp:77] Creating layer Scale5
I1022 19:29:09.325302  3845 net.cpp:122] Setting up Scale5
I1022 19:29:09.325309  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.325314  3845 net.cpp:137] Memory required for data: 621379616
I1022 19:29:09.325320  3845 layer_factory.hpp:77] Creating layer Eltwise2
I1022 19:29:09.325327  3845 net.cpp:84] Creating Layer Eltwise2
I1022 19:29:09.325331  3845 net.cpp:406] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I1022 19:29:09.325336  3845 net.cpp:406] Eltwise2 <- Convolution5
I1022 19:29:09.325343  3845 net.cpp:380] Eltwise2 -> Eltwise2
I1022 19:29:09.325361  3845 net.cpp:122] Setting up Eltwise2
I1022 19:29:09.325367  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.325371  3845 net.cpp:137] Memory required for data: 647069728
I1022 19:29:09.325376  3845 layer_factory.hpp:77] Creating layer ReLU5
I1022 19:29:09.325383  3845 net.cpp:84] Creating Layer ReLU5
I1022 19:29:09.325387  3845 net.cpp:406] ReLU5 <- Eltwise2
I1022 19:29:09.325392  3845 net.cpp:367] ReLU5 -> Eltwise2 (in-place)
I1022 19:29:09.325516  3845 net.cpp:122] Setting up ReLU5
I1022 19:29:09.325525  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.325529  3845 net.cpp:137] Memory required for data: 672759840
I1022 19:29:09.325534  3845 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I1022 19:29:09.325541  3845 net.cpp:84] Creating Layer Eltwise2_ReLU5_0_split
I1022 19:29:09.325546  3845 net.cpp:406] Eltwise2_ReLU5_0_split <- Eltwise2
I1022 19:29:09.325551  3845 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I1022 19:29:09.325558  3845 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I1022 19:29:09.325587  3845 net.cpp:122] Setting up Eltwise2_ReLU5_0_split
I1022 19:29:09.325593  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.325598  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.325603  3845 net.cpp:137] Memory required for data: 724140064
I1022 19:29:09.325608  3845 layer_factory.hpp:77] Creating layer Convolution6
I1022 19:29:09.325618  3845 net.cpp:84] Creating Layer Convolution6
I1022 19:29:09.325621  3845 net.cpp:406] Convolution6 <- Eltwise2_ReLU5_0_split_0
I1022 19:29:09.325629  3845 net.cpp:380] Convolution6 -> Convolution6
I1022 19:29:09.327038  3845 net.cpp:122] Setting up Convolution6
I1022 19:29:09.327049  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.327054  3845 net.cpp:137] Memory required for data: 749830176
I1022 19:29:09.327064  3845 layer_factory.hpp:77] Creating layer BatchNorm6
I1022 19:29:09.327077  3845 net.cpp:84] Creating Layer BatchNorm6
I1022 19:29:09.327082  3845 net.cpp:406] BatchNorm6 <- Convolution6
I1022 19:29:09.327090  3845 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1022 19:29:09.327239  3845 net.cpp:122] Setting up BatchNorm6
I1022 19:29:09.327247  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.327251  3845 net.cpp:137] Memory required for data: 775520288
I1022 19:29:09.327260  3845 layer_factory.hpp:77] Creating layer Scale6
I1022 19:29:09.327266  3845 net.cpp:84] Creating Layer Scale6
I1022 19:29:09.327270  3845 net.cpp:406] Scale6 <- Convolution6
I1022 19:29:09.327277  3845 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1022 19:29:09.327306  3845 layer_factory.hpp:77] Creating layer Scale6
I1022 19:29:09.327419  3845 net.cpp:122] Setting up Scale6
I1022 19:29:09.327430  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.327432  3845 net.cpp:137] Memory required for data: 801210400
I1022 19:29:09.327440  3845 layer_factory.hpp:77] Creating layer ReLU6
I1022 19:29:09.327445  3845 net.cpp:84] Creating Layer ReLU6
I1022 19:29:09.327450  3845 net.cpp:406] ReLU6 <- Convolution6
I1022 19:29:09.327455  3845 net.cpp:367] ReLU6 -> Convolution6 (in-place)
I1022 19:29:09.327581  3845 net.cpp:122] Setting up ReLU6
I1022 19:29:09.327590  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.327594  3845 net.cpp:137] Memory required for data: 826900512
I1022 19:29:09.327597  3845 layer_factory.hpp:77] Creating layer Convolution7
I1022 19:29:09.327607  3845 net.cpp:84] Creating Layer Convolution7
I1022 19:29:09.327611  3845 net.cpp:406] Convolution7 <- Convolution6
I1022 19:29:09.327618  3845 net.cpp:380] Convolution7 -> Convolution7
I1022 19:29:09.328977  3845 net.cpp:122] Setting up Convolution7
I1022 19:29:09.328997  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.329001  3845 net.cpp:137] Memory required for data: 852590624
I1022 19:29:09.329007  3845 layer_factory.hpp:77] Creating layer BatchNorm7
I1022 19:29:09.329016  3845 net.cpp:84] Creating Layer BatchNorm7
I1022 19:29:09.329020  3845 net.cpp:406] BatchNorm7 <- Convolution7
I1022 19:29:09.329025  3845 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1022 19:29:09.329188  3845 net.cpp:122] Setting up BatchNorm7
I1022 19:29:09.329195  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.329206  3845 net.cpp:137] Memory required for data: 878280736
I1022 19:29:09.329213  3845 layer_factory.hpp:77] Creating layer Scale7
I1022 19:29:09.329223  3845 net.cpp:84] Creating Layer Scale7
I1022 19:29:09.329227  3845 net.cpp:406] Scale7 <- Convolution7
I1022 19:29:09.329233  3845 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1022 19:29:09.329265  3845 layer_factory.hpp:77] Creating layer Scale7
I1022 19:29:09.329391  3845 net.cpp:122] Setting up Scale7
I1022 19:29:09.329398  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.329402  3845 net.cpp:137] Memory required for data: 903970848
I1022 19:29:09.329411  3845 layer_factory.hpp:77] Creating layer Eltwise3
I1022 19:29:09.329416  3845 net.cpp:84] Creating Layer Eltwise3
I1022 19:29:09.329421  3845 net.cpp:406] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I1022 19:29:09.329427  3845 net.cpp:406] Eltwise3 <- Convolution7
I1022 19:29:09.329433  3845 net.cpp:380] Eltwise3 -> Eltwise3
I1022 19:29:09.329452  3845 net.cpp:122] Setting up Eltwise3
I1022 19:29:09.329458  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.329463  3845 net.cpp:137] Memory required for data: 929660960
I1022 19:29:09.329468  3845 layer_factory.hpp:77] Creating layer ReLU7
I1022 19:29:09.329476  3845 net.cpp:84] Creating Layer ReLU7
I1022 19:29:09.329480  3845 net.cpp:406] ReLU7 <- Eltwise3
I1022 19:29:09.329485  3845 net.cpp:367] ReLU7 -> Eltwise3 (in-place)
I1022 19:29:09.329605  3845 net.cpp:122] Setting up ReLU7
I1022 19:29:09.329613  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.329618  3845 net.cpp:137] Memory required for data: 955351072
I1022 19:29:09.329622  3845 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I1022 19:29:09.329638  3845 net.cpp:84] Creating Layer Eltwise3_ReLU7_0_split
I1022 19:29:09.329643  3845 net.cpp:406] Eltwise3_ReLU7_0_split <- Eltwise3
I1022 19:29:09.329649  3845 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I1022 19:29:09.329655  3845 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I1022 19:29:09.329686  3845 net.cpp:122] Setting up Eltwise3_ReLU7_0_split
I1022 19:29:09.329692  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.329697  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.329702  3845 net.cpp:137] Memory required for data: 1006731296
I1022 19:29:09.329706  3845 layer_factory.hpp:77] Creating layer Convolution8
I1022 19:29:09.329717  3845 net.cpp:84] Creating Layer Convolution8
I1022 19:29:09.329720  3845 net.cpp:406] Convolution8 <- Eltwise3_ReLU7_0_split_0
I1022 19:29:09.329730  3845 net.cpp:380] Convolution8 -> Convolution8
I1022 19:29:09.331544  3845 net.cpp:122] Setting up Convolution8
I1022 19:29:09.331555  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.331560  3845 net.cpp:137] Memory required for data: 1019576352
I1022 19:29:09.331568  3845 layer_factory.hpp:77] Creating layer BatchNorm8
I1022 19:29:09.331584  3845 net.cpp:84] Creating Layer BatchNorm8
I1022 19:29:09.331588  3845 net.cpp:406] BatchNorm8 <- Convolution8
I1022 19:29:09.331594  3845 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1022 19:29:09.331738  3845 net.cpp:122] Setting up BatchNorm8
I1022 19:29:09.331744  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.331748  3845 net.cpp:137] Memory required for data: 1032421408
I1022 19:29:09.331763  3845 layer_factory.hpp:77] Creating layer Scale8
I1022 19:29:09.331768  3845 net.cpp:84] Creating Layer Scale8
I1022 19:29:09.331773  3845 net.cpp:406] Scale8 <- Convolution8
I1022 19:29:09.331775  3845 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1022 19:29:09.331804  3845 layer_factory.hpp:77] Creating layer Scale8
I1022 19:29:09.331887  3845 net.cpp:122] Setting up Scale8
I1022 19:29:09.331892  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.331895  3845 net.cpp:137] Memory required for data: 1045266464
I1022 19:29:09.331899  3845 layer_factory.hpp:77] Creating layer Convolution9
I1022 19:29:09.331907  3845 net.cpp:84] Creating Layer Convolution9
I1022 19:29:09.331912  3845 net.cpp:406] Convolution9 <- Eltwise3_ReLU7_0_split_1
I1022 19:29:09.331917  3845 net.cpp:380] Convolution9 -> Convolution9
I1022 19:29:09.332880  3845 net.cpp:122] Setting up Convolution9
I1022 19:29:09.332890  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.332895  3845 net.cpp:137] Memory required for data: 1058111520
I1022 19:29:09.332900  3845 layer_factory.hpp:77] Creating layer BatchNorm9
I1022 19:29:09.332906  3845 net.cpp:84] Creating Layer BatchNorm9
I1022 19:29:09.332909  3845 net.cpp:406] BatchNorm9 <- Convolution9
I1022 19:29:09.332913  3845 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1022 19:29:09.333041  3845 net.cpp:122] Setting up BatchNorm9
I1022 19:29:09.333047  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.333051  3845 net.cpp:137] Memory required for data: 1070956576
I1022 19:29:09.333056  3845 layer_factory.hpp:77] Creating layer Scale9
I1022 19:29:09.333061  3845 net.cpp:84] Creating Layer Scale9
I1022 19:29:09.333065  3845 net.cpp:406] Scale9 <- Convolution9
I1022 19:29:09.333068  3845 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1022 19:29:09.333094  3845 layer_factory.hpp:77] Creating layer Scale9
I1022 19:29:09.333175  3845 net.cpp:122] Setting up Scale9
I1022 19:29:09.333181  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.333184  3845 net.cpp:137] Memory required for data: 1083801632
I1022 19:29:09.333189  3845 layer_factory.hpp:77] Creating layer ReLU8
I1022 19:29:09.333194  3845 net.cpp:84] Creating Layer ReLU8
I1022 19:29:09.333197  3845 net.cpp:406] ReLU8 <- Convolution9
I1022 19:29:09.333200  3845 net.cpp:367] ReLU8 -> Convolution9 (in-place)
I1022 19:29:09.333343  3845 net.cpp:122] Setting up ReLU8
I1022 19:29:09.333350  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.333353  3845 net.cpp:137] Memory required for data: 1096646688
I1022 19:29:09.333356  3845 layer_factory.hpp:77] Creating layer Convolution10
I1022 19:29:09.333364  3845 net.cpp:84] Creating Layer Convolution10
I1022 19:29:09.333369  3845 net.cpp:406] Convolution10 <- Convolution9
I1022 19:29:09.333372  3845 net.cpp:380] Convolution10 -> Convolution10
I1022 19:29:09.334414  3845 net.cpp:122] Setting up Convolution10
I1022 19:29:09.334424  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.334429  3845 net.cpp:137] Memory required for data: 1109491744
I1022 19:29:09.334440  3845 layer_factory.hpp:77] Creating layer BatchNorm10
I1022 19:29:09.334447  3845 net.cpp:84] Creating Layer BatchNorm10
I1022 19:29:09.334450  3845 net.cpp:406] BatchNorm10 <- Convolution10
I1022 19:29:09.334455  3845 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1022 19:29:09.334584  3845 net.cpp:122] Setting up BatchNorm10
I1022 19:29:09.334591  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.334594  3845 net.cpp:137] Memory required for data: 1122336800
I1022 19:29:09.334599  3845 layer_factory.hpp:77] Creating layer Scale10
I1022 19:29:09.334605  3845 net.cpp:84] Creating Layer Scale10
I1022 19:29:09.334609  3845 net.cpp:406] Scale10 <- Convolution10
I1022 19:29:09.334611  3845 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1022 19:29:09.334638  3845 layer_factory.hpp:77] Creating layer Scale10
I1022 19:29:09.334718  3845 net.cpp:122] Setting up Scale10
I1022 19:29:09.334724  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.334728  3845 net.cpp:137] Memory required for data: 1135181856
I1022 19:29:09.334733  3845 layer_factory.hpp:77] Creating layer Eltwise4
I1022 19:29:09.334736  3845 net.cpp:84] Creating Layer Eltwise4
I1022 19:29:09.334740  3845 net.cpp:406] Eltwise4 <- Convolution8
I1022 19:29:09.334743  3845 net.cpp:406] Eltwise4 <- Convolution10
I1022 19:29:09.334748  3845 net.cpp:380] Eltwise4 -> Eltwise4
I1022 19:29:09.334764  3845 net.cpp:122] Setting up Eltwise4
I1022 19:29:09.334770  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.334774  3845 net.cpp:137] Memory required for data: 1148026912
I1022 19:29:09.334775  3845 layer_factory.hpp:77] Creating layer ReLU9
I1022 19:29:09.334779  3845 net.cpp:84] Creating Layer ReLU9
I1022 19:29:09.334782  3845 net.cpp:406] ReLU9 <- Eltwise4
I1022 19:29:09.334785  3845 net.cpp:367] ReLU9 -> Eltwise4 (in-place)
I1022 19:29:09.335227  3845 net.cpp:122] Setting up ReLU9
I1022 19:29:09.335237  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.335240  3845 net.cpp:137] Memory required for data: 1160871968
I1022 19:29:09.335243  3845 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I1022 19:29:09.335249  3845 net.cpp:84] Creating Layer Eltwise4_ReLU9_0_split
I1022 19:29:09.335253  3845 net.cpp:406] Eltwise4_ReLU9_0_split <- Eltwise4
I1022 19:29:09.335256  3845 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I1022 19:29:09.335261  3845 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I1022 19:29:09.335290  3845 net.cpp:122] Setting up Eltwise4_ReLU9_0_split
I1022 19:29:09.335295  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.335299  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.335302  3845 net.cpp:137] Memory required for data: 1186562080
I1022 19:29:09.335304  3845 layer_factory.hpp:77] Creating layer Convolution11
I1022 19:29:09.335311  3845 net.cpp:84] Creating Layer Convolution11
I1022 19:29:09.335314  3845 net.cpp:406] Convolution11 <- Eltwise4_ReLU9_0_split_0
I1022 19:29:09.335319  3845 net.cpp:380] Convolution11 -> Convolution11
I1022 19:29:09.336032  3845 net.cpp:122] Setting up Convolution11
I1022 19:29:09.336041  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.336045  3845 net.cpp:137] Memory required for data: 1199407136
I1022 19:29:09.336057  3845 layer_factory.hpp:77] Creating layer BatchNorm11
I1022 19:29:09.336064  3845 net.cpp:84] Creating Layer BatchNorm11
I1022 19:29:09.336067  3845 net.cpp:406] BatchNorm11 <- Convolution11
I1022 19:29:09.336072  3845 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1022 19:29:09.336203  3845 net.cpp:122] Setting up BatchNorm11
I1022 19:29:09.336210  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.336212  3845 net.cpp:137] Memory required for data: 1212252192
I1022 19:29:09.336218  3845 layer_factory.hpp:77] Creating layer Scale11
I1022 19:29:09.336222  3845 net.cpp:84] Creating Layer Scale11
I1022 19:29:09.336226  3845 net.cpp:406] Scale11 <- Convolution11
I1022 19:29:09.336230  3845 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1022 19:29:09.336256  3845 layer_factory.hpp:77] Creating layer Scale11
I1022 19:29:09.336338  3845 net.cpp:122] Setting up Scale11
I1022 19:29:09.336344  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.336347  3845 net.cpp:137] Memory required for data: 1225097248
I1022 19:29:09.336351  3845 layer_factory.hpp:77] Creating layer ReLU10
I1022 19:29:09.336355  3845 net.cpp:84] Creating Layer ReLU10
I1022 19:29:09.336359  3845 net.cpp:406] ReLU10 <- Convolution11
I1022 19:29:09.336361  3845 net.cpp:367] ReLU10 -> Convolution11 (in-place)
I1022 19:29:09.336802  3845 net.cpp:122] Setting up ReLU10
I1022 19:29:09.336812  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.336817  3845 net.cpp:137] Memory required for data: 1237942304
I1022 19:29:09.336818  3845 layer_factory.hpp:77] Creating layer Convolution12
I1022 19:29:09.336827  3845 net.cpp:84] Creating Layer Convolution12
I1022 19:29:09.336832  3845 net.cpp:406] Convolution12 <- Convolution11
I1022 19:29:09.336835  3845 net.cpp:380] Convolution12 -> Convolution12
I1022 19:29:09.337879  3845 net.cpp:122] Setting up Convolution12
I1022 19:29:09.337890  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.337894  3845 net.cpp:137] Memory required for data: 1250787360
I1022 19:29:09.337898  3845 layer_factory.hpp:77] Creating layer BatchNorm12
I1022 19:29:09.337905  3845 net.cpp:84] Creating Layer BatchNorm12
I1022 19:29:09.337909  3845 net.cpp:406] BatchNorm12 <- Convolution12
I1022 19:29:09.337913  3845 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1022 19:29:09.338045  3845 net.cpp:122] Setting up BatchNorm12
I1022 19:29:09.338052  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.338054  3845 net.cpp:137] Memory required for data: 1263632416
I1022 19:29:09.338059  3845 layer_factory.hpp:77] Creating layer Scale12
I1022 19:29:09.338065  3845 net.cpp:84] Creating Layer Scale12
I1022 19:29:09.338068  3845 net.cpp:406] Scale12 <- Convolution12
I1022 19:29:09.338071  3845 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1022 19:29:09.338099  3845 layer_factory.hpp:77] Creating layer Scale12
I1022 19:29:09.338178  3845 net.cpp:122] Setting up Scale12
I1022 19:29:09.338184  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.338187  3845 net.cpp:137] Memory required for data: 1276477472
I1022 19:29:09.338191  3845 layer_factory.hpp:77] Creating layer Eltwise5
I1022 19:29:09.338196  3845 net.cpp:84] Creating Layer Eltwise5
I1022 19:29:09.338199  3845 net.cpp:406] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I1022 19:29:09.338202  3845 net.cpp:406] Eltwise5 <- Convolution12
I1022 19:29:09.338207  3845 net.cpp:380] Eltwise5 -> Eltwise5
I1022 19:29:09.338223  3845 net.cpp:122] Setting up Eltwise5
I1022 19:29:09.338228  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.338232  3845 net.cpp:137] Memory required for data: 1289322528
I1022 19:29:09.338234  3845 layer_factory.hpp:77] Creating layer ReLU11
I1022 19:29:09.338238  3845 net.cpp:84] Creating Layer ReLU11
I1022 19:29:09.338240  3845 net.cpp:406] ReLU11 <- Eltwise5
I1022 19:29:09.338243  3845 net.cpp:367] ReLU11 -> Eltwise5 (in-place)
I1022 19:29:09.338361  3845 net.cpp:122] Setting up ReLU11
I1022 19:29:09.338367  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.338376  3845 net.cpp:137] Memory required for data: 1302167584
I1022 19:29:09.338379  3845 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I1022 19:29:09.338384  3845 net.cpp:84] Creating Layer Eltwise5_ReLU11_0_split
I1022 19:29:09.338387  3845 net.cpp:406] Eltwise5_ReLU11_0_split <- Eltwise5
I1022 19:29:09.338392  3845 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I1022 19:29:09.338397  3845 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I1022 19:29:09.338424  3845 net.cpp:122] Setting up Eltwise5_ReLU11_0_split
I1022 19:29:09.338429  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.338433  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.338436  3845 net.cpp:137] Memory required for data: 1327857696
I1022 19:29:09.338438  3845 layer_factory.hpp:77] Creating layer Convolution13
I1022 19:29:09.338446  3845 net.cpp:84] Creating Layer Convolution13
I1022 19:29:09.338449  3845 net.cpp:406] Convolution13 <- Eltwise5_ReLU11_0_split_0
I1022 19:29:09.338454  3845 net.cpp:380] Convolution13 -> Convolution13
I1022 19:29:09.339499  3845 net.cpp:122] Setting up Convolution13
I1022 19:29:09.339509  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.339514  3845 net.cpp:137] Memory required for data: 1340702752
I1022 19:29:09.339519  3845 layer_factory.hpp:77] Creating layer BatchNorm13
I1022 19:29:09.339524  3845 net.cpp:84] Creating Layer BatchNorm13
I1022 19:29:09.339527  3845 net.cpp:406] BatchNorm13 <- Convolution13
I1022 19:29:09.339534  3845 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1022 19:29:09.339668  3845 net.cpp:122] Setting up BatchNorm13
I1022 19:29:09.339674  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.339678  3845 net.cpp:137] Memory required for data: 1353547808
I1022 19:29:09.339682  3845 layer_factory.hpp:77] Creating layer Scale13
I1022 19:29:09.339687  3845 net.cpp:84] Creating Layer Scale13
I1022 19:29:09.339691  3845 net.cpp:406] Scale13 <- Convolution13
I1022 19:29:09.339694  3845 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1022 19:29:09.339721  3845 layer_factory.hpp:77] Creating layer Scale13
I1022 19:29:09.339807  3845 net.cpp:122] Setting up Scale13
I1022 19:29:09.339812  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.339817  3845 net.cpp:137] Memory required for data: 1366392864
I1022 19:29:09.339819  3845 layer_factory.hpp:77] Creating layer ReLU12
I1022 19:29:09.339824  3845 net.cpp:84] Creating Layer ReLU12
I1022 19:29:09.339828  3845 net.cpp:406] ReLU12 <- Convolution13
I1022 19:29:09.339830  3845 net.cpp:367] ReLU12 -> Convolution13 (in-place)
I1022 19:29:09.339947  3845 net.cpp:122] Setting up ReLU12
I1022 19:29:09.339954  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.339962  3845 net.cpp:137] Memory required for data: 1379237920
I1022 19:29:09.339965  3845 layer_factory.hpp:77] Creating layer Convolution14
I1022 19:29:09.339973  3845 net.cpp:84] Creating Layer Convolution14
I1022 19:29:09.339977  3845 net.cpp:406] Convolution14 <- Convolution13
I1022 19:29:09.339982  3845 net.cpp:380] Convolution14 -> Convolution14
I1022 19:29:09.341042  3845 net.cpp:122] Setting up Convolution14
I1022 19:29:09.341051  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.341055  3845 net.cpp:137] Memory required for data: 1392082976
I1022 19:29:09.341060  3845 layer_factory.hpp:77] Creating layer BatchNorm14
I1022 19:29:09.341071  3845 net.cpp:84] Creating Layer BatchNorm14
I1022 19:29:09.341074  3845 net.cpp:406] BatchNorm14 <- Convolution14
I1022 19:29:09.341078  3845 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1022 19:29:09.341235  3845 net.cpp:122] Setting up BatchNorm14
I1022 19:29:09.341241  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.341243  3845 net.cpp:137] Memory required for data: 1404928032
I1022 19:29:09.341248  3845 layer_factory.hpp:77] Creating layer Scale14
I1022 19:29:09.341253  3845 net.cpp:84] Creating Layer Scale14
I1022 19:29:09.341262  3845 net.cpp:406] Scale14 <- Convolution14
I1022 19:29:09.341266  3845 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1022 19:29:09.341294  3845 layer_factory.hpp:77] Creating layer Scale14
I1022 19:29:09.341374  3845 net.cpp:122] Setting up Scale14
I1022 19:29:09.341379  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.341382  3845 net.cpp:137] Memory required for data: 1417773088
I1022 19:29:09.341385  3845 layer_factory.hpp:77] Creating layer Eltwise6
I1022 19:29:09.341390  3845 net.cpp:84] Creating Layer Eltwise6
I1022 19:29:09.341392  3845 net.cpp:406] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I1022 19:29:09.341395  3845 net.cpp:406] Eltwise6 <- Convolution14
I1022 19:29:09.341398  3845 net.cpp:380] Eltwise6 -> Eltwise6
I1022 19:29:09.341414  3845 net.cpp:122] Setting up Eltwise6
I1022 19:29:09.341418  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.341420  3845 net.cpp:137] Memory required for data: 1430618144
I1022 19:29:09.341423  3845 layer_factory.hpp:77] Creating layer ReLU13
I1022 19:29:09.341426  3845 net.cpp:84] Creating Layer ReLU13
I1022 19:29:09.341428  3845 net.cpp:406] ReLU13 <- Eltwise6
I1022 19:29:09.341431  3845 net.cpp:367] ReLU13 -> Eltwise6 (in-place)
I1022 19:29:09.341545  3845 net.cpp:122] Setting up ReLU13
I1022 19:29:09.341552  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.341553  3845 net.cpp:137] Memory required for data: 1443463200
I1022 19:29:09.341557  3845 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I1022 19:29:09.341559  3845 net.cpp:84] Creating Layer Eltwise6_ReLU13_0_split
I1022 19:29:09.341562  3845 net.cpp:406] Eltwise6_ReLU13_0_split <- Eltwise6
I1022 19:29:09.341567  3845 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I1022 19:29:09.341570  3845 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I1022 19:29:09.341596  3845 net.cpp:122] Setting up Eltwise6_ReLU13_0_split
I1022 19:29:09.341600  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.341603  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.341604  3845 net.cpp:137] Memory required for data: 1469153312
I1022 19:29:09.341608  3845 layer_factory.hpp:77] Creating layer Convolution15
I1022 19:29:09.341614  3845 net.cpp:84] Creating Layer Convolution15
I1022 19:29:09.341616  3845 net.cpp:406] Convolution15 <- Eltwise6_ReLU13_0_split_0
I1022 19:29:09.341620  3845 net.cpp:380] Convolution15 -> Convolution15
I1022 19:29:09.342519  3845 net.cpp:122] Setting up Convolution15
I1022 19:29:09.342527  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.342530  3845 net.cpp:137] Memory required for data: 1475575840
I1022 19:29:09.342535  3845 layer_factory.hpp:77] Creating layer BatchNorm15
I1022 19:29:09.342540  3845 net.cpp:84] Creating Layer BatchNorm15
I1022 19:29:09.342542  3845 net.cpp:406] BatchNorm15 <- Convolution15
I1022 19:29:09.342548  3845 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1022 19:29:09.342681  3845 net.cpp:122] Setting up BatchNorm15
I1022 19:29:09.342686  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.342689  3845 net.cpp:137] Memory required for data: 1481998368
I1022 19:29:09.342694  3845 layer_factory.hpp:77] Creating layer Scale15
I1022 19:29:09.342699  3845 net.cpp:84] Creating Layer Scale15
I1022 19:29:09.342701  3845 net.cpp:406] Scale15 <- Convolution15
I1022 19:29:09.342705  3845 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1022 19:29:09.342730  3845 layer_factory.hpp:77] Creating layer Scale15
I1022 19:29:09.342811  3845 net.cpp:122] Setting up Scale15
I1022 19:29:09.342815  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.342818  3845 net.cpp:137] Memory required for data: 1488420896
I1022 19:29:09.342821  3845 layer_factory.hpp:77] Creating layer Convolution16
I1022 19:29:09.342828  3845 net.cpp:84] Creating Layer Convolution16
I1022 19:29:09.342845  3845 net.cpp:406] Convolution16 <- Eltwise6_ReLU13_0_split_1
I1022 19:29:09.342849  3845 net.cpp:380] Convolution16 -> Convolution16
I1022 19:29:09.344555  3845 net.cpp:122] Setting up Convolution16
I1022 19:29:09.344576  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.344590  3845 net.cpp:137] Memory required for data: 1494843424
I1022 19:29:09.344595  3845 layer_factory.hpp:77] Creating layer BatchNorm16
I1022 19:29:09.344600  3845 net.cpp:84] Creating Layer BatchNorm16
I1022 19:29:09.344604  3845 net.cpp:406] BatchNorm16 <- Convolution16
I1022 19:29:09.344609  3845 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1022 19:29:09.344753  3845 net.cpp:122] Setting up BatchNorm16
I1022 19:29:09.344758  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.344761  3845 net.cpp:137] Memory required for data: 1501265952
I1022 19:29:09.344766  3845 layer_factory.hpp:77] Creating layer Scale16
I1022 19:29:09.344772  3845 net.cpp:84] Creating Layer Scale16
I1022 19:29:09.344775  3845 net.cpp:406] Scale16 <- Convolution16
I1022 19:29:09.344779  3845 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1022 19:29:09.344806  3845 layer_factory.hpp:77] Creating layer Scale16
I1022 19:29:09.344889  3845 net.cpp:122] Setting up Scale16
I1022 19:29:09.344895  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.344898  3845 net.cpp:137] Memory required for data: 1507688480
I1022 19:29:09.344913  3845 layer_factory.hpp:77] Creating layer ReLU14
I1022 19:29:09.344918  3845 net.cpp:84] Creating Layer ReLU14
I1022 19:29:09.344921  3845 net.cpp:406] ReLU14 <- Convolution16
I1022 19:29:09.344924  3845 net.cpp:367] ReLU14 -> Convolution16 (in-place)
I1022 19:29:09.345067  3845 net.cpp:122] Setting up ReLU14
I1022 19:29:09.345072  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.345075  3845 net.cpp:137] Memory required for data: 1514111008
I1022 19:29:09.345078  3845 layer_factory.hpp:77] Creating layer Convolution17
I1022 19:29:09.345084  3845 net.cpp:84] Creating Layer Convolution17
I1022 19:29:09.345088  3845 net.cpp:406] Convolution17 <- Convolution16
I1022 19:29:09.345094  3845 net.cpp:380] Convolution17 -> Convolution17
I1022 19:29:09.346966  3845 net.cpp:122] Setting up Convolution17
I1022 19:29:09.346976  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.346981  3845 net.cpp:137] Memory required for data: 1520533536
I1022 19:29:09.346985  3845 layer_factory.hpp:77] Creating layer BatchNorm17
I1022 19:29:09.346992  3845 net.cpp:84] Creating Layer BatchNorm17
I1022 19:29:09.346994  3845 net.cpp:406] BatchNorm17 <- Convolution17
I1022 19:29:09.346998  3845 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1022 19:29:09.347141  3845 net.cpp:122] Setting up BatchNorm17
I1022 19:29:09.347147  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.347149  3845 net.cpp:137] Memory required for data: 1526956064
I1022 19:29:09.347164  3845 layer_factory.hpp:77] Creating layer Scale17
I1022 19:29:09.347168  3845 net.cpp:84] Creating Layer Scale17
I1022 19:29:09.347172  3845 net.cpp:406] Scale17 <- Convolution17
I1022 19:29:09.347175  3845 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1022 19:29:09.347203  3845 layer_factory.hpp:77] Creating layer Scale17
I1022 19:29:09.347283  3845 net.cpp:122] Setting up Scale17
I1022 19:29:09.347290  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.347292  3845 net.cpp:137] Memory required for data: 1533378592
I1022 19:29:09.347296  3845 layer_factory.hpp:77] Creating layer Eltwise7
I1022 19:29:09.347301  3845 net.cpp:84] Creating Layer Eltwise7
I1022 19:29:09.347306  3845 net.cpp:406] Eltwise7 <- Convolution15
I1022 19:29:09.347308  3845 net.cpp:406] Eltwise7 <- Convolution17
I1022 19:29:09.347311  3845 net.cpp:380] Eltwise7 -> Eltwise7
I1022 19:29:09.347328  3845 net.cpp:122] Setting up Eltwise7
I1022 19:29:09.347333  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.347337  3845 net.cpp:137] Memory required for data: 1539801120
I1022 19:29:09.347338  3845 layer_factory.hpp:77] Creating layer ReLU15
I1022 19:29:09.347342  3845 net.cpp:84] Creating Layer ReLU15
I1022 19:29:09.347344  3845 net.cpp:406] ReLU15 <- Eltwise7
I1022 19:29:09.347355  3845 net.cpp:367] ReLU15 -> Eltwise7 (in-place)
I1022 19:29:09.347473  3845 net.cpp:122] Setting up ReLU15
I1022 19:29:09.347481  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.347483  3845 net.cpp:137] Memory required for data: 1546223648
I1022 19:29:09.347486  3845 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I1022 19:29:09.347489  3845 net.cpp:84] Creating Layer Eltwise7_ReLU15_0_split
I1022 19:29:09.347493  3845 net.cpp:406] Eltwise7_ReLU15_0_split <- Eltwise7
I1022 19:29:09.347497  3845 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I1022 19:29:09.347501  3845 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I1022 19:29:09.347528  3845 net.cpp:122] Setting up Eltwise7_ReLU15_0_split
I1022 19:29:09.347534  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.347538  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.347540  3845 net.cpp:137] Memory required for data: 1559068704
I1022 19:29:09.347543  3845 layer_factory.hpp:77] Creating layer Convolution18
I1022 19:29:09.347549  3845 net.cpp:84] Creating Layer Convolution18
I1022 19:29:09.347553  3845 net.cpp:406] Convolution18 <- Eltwise7_ReLU15_0_split_0
I1022 19:29:09.347556  3845 net.cpp:380] Convolution18 -> Convolution18
I1022 19:29:09.349563  3845 net.cpp:122] Setting up Convolution18
I1022 19:29:09.349573  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.349577  3845 net.cpp:137] Memory required for data: 1565491232
I1022 19:29:09.349582  3845 layer_factory.hpp:77] Creating layer BatchNorm18
I1022 19:29:09.349588  3845 net.cpp:84] Creating Layer BatchNorm18
I1022 19:29:09.349592  3845 net.cpp:406] BatchNorm18 <- Convolution18
I1022 19:29:09.349596  3845 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1022 19:29:09.349737  3845 net.cpp:122] Setting up BatchNorm18
I1022 19:29:09.349743  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.349746  3845 net.cpp:137] Memory required for data: 1571913760
I1022 19:29:09.349751  3845 layer_factory.hpp:77] Creating layer Scale18
I1022 19:29:09.349756  3845 net.cpp:84] Creating Layer Scale18
I1022 19:29:09.349759  3845 net.cpp:406] Scale18 <- Convolution18
I1022 19:29:09.349763  3845 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1022 19:29:09.349792  3845 layer_factory.hpp:77] Creating layer Scale18
I1022 19:29:09.349876  3845 net.cpp:122] Setting up Scale18
I1022 19:29:09.349882  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.349885  3845 net.cpp:137] Memory required for data: 1578336288
I1022 19:29:09.349889  3845 layer_factory.hpp:77] Creating layer ReLU16
I1022 19:29:09.349895  3845 net.cpp:84] Creating Layer ReLU16
I1022 19:29:09.349897  3845 net.cpp:406] ReLU16 <- Convolution18
I1022 19:29:09.349901  3845 net.cpp:367] ReLU16 -> Convolution18 (in-place)
I1022 19:29:09.350348  3845 net.cpp:122] Setting up ReLU16
I1022 19:29:09.350358  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.350361  3845 net.cpp:137] Memory required for data: 1584758816
I1022 19:29:09.350364  3845 layer_factory.hpp:77] Creating layer Convolution19
I1022 19:29:09.350373  3845 net.cpp:84] Creating Layer Convolution19
I1022 19:29:09.350375  3845 net.cpp:406] Convolution19 <- Convolution18
I1022 19:29:09.350380  3845 net.cpp:380] Convolution19 -> Convolution19
I1022 19:29:09.352587  3845 net.cpp:122] Setting up Convolution19
I1022 19:29:09.352598  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.352602  3845 net.cpp:137] Memory required for data: 1591181344
I1022 19:29:09.352607  3845 layer_factory.hpp:77] Creating layer BatchNorm19
I1022 19:29:09.352612  3845 net.cpp:84] Creating Layer BatchNorm19
I1022 19:29:09.352617  3845 net.cpp:406] BatchNorm19 <- Convolution19
I1022 19:29:09.352622  3845 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1022 19:29:09.352761  3845 net.cpp:122] Setting up BatchNorm19
I1022 19:29:09.352767  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.352771  3845 net.cpp:137] Memory required for data: 1597603872
I1022 19:29:09.352797  3845 layer_factory.hpp:77] Creating layer Scale19
I1022 19:29:09.352804  3845 net.cpp:84] Creating Layer Scale19
I1022 19:29:09.352808  3845 net.cpp:406] Scale19 <- Convolution19
I1022 19:29:09.352811  3845 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1022 19:29:09.352843  3845 layer_factory.hpp:77] Creating layer Scale19
I1022 19:29:09.352926  3845 net.cpp:122] Setting up Scale19
I1022 19:29:09.352932  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.352936  3845 net.cpp:137] Memory required for data: 1604026400
I1022 19:29:09.352939  3845 layer_factory.hpp:77] Creating layer Eltwise8
I1022 19:29:09.352944  3845 net.cpp:84] Creating Layer Eltwise8
I1022 19:29:09.352948  3845 net.cpp:406] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I1022 19:29:09.352952  3845 net.cpp:406] Eltwise8 <- Convolution19
I1022 19:29:09.352954  3845 net.cpp:380] Eltwise8 -> Eltwise8
I1022 19:29:09.352972  3845 net.cpp:122] Setting up Eltwise8
I1022 19:29:09.352977  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.352979  3845 net.cpp:137] Memory required for data: 1610448928
I1022 19:29:09.352982  3845 layer_factory.hpp:77] Creating layer ReLU17
I1022 19:29:09.352986  3845 net.cpp:84] Creating Layer ReLU17
I1022 19:29:09.352989  3845 net.cpp:406] ReLU17 <- Eltwise8
I1022 19:29:09.352993  3845 net.cpp:367] ReLU17 -> Eltwise8 (in-place)
I1022 19:29:09.353111  3845 net.cpp:122] Setting up ReLU17
I1022 19:29:09.353117  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.353121  3845 net.cpp:137] Memory required for data: 1616871456
I1022 19:29:09.353123  3845 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I1022 19:29:09.353127  3845 net.cpp:84] Creating Layer Eltwise8_ReLU17_0_split
I1022 19:29:09.353132  3845 net.cpp:406] Eltwise8_ReLU17_0_split <- Eltwise8
I1022 19:29:09.353134  3845 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I1022 19:29:09.353139  3845 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I1022 19:29:09.353168  3845 net.cpp:122] Setting up Eltwise8_ReLU17_0_split
I1022 19:29:09.353173  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.353178  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.353179  3845 net.cpp:137] Memory required for data: 1629716512
I1022 19:29:09.353183  3845 layer_factory.hpp:77] Creating layer Convolution20
I1022 19:29:09.353188  3845 net.cpp:84] Creating Layer Convolution20
I1022 19:29:09.353191  3845 net.cpp:406] Convolution20 <- Eltwise8_ReLU17_0_split_0
I1022 19:29:09.353196  3845 net.cpp:380] Convolution20 -> Convolution20
I1022 19:29:09.355188  3845 net.cpp:122] Setting up Convolution20
I1022 19:29:09.355199  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.355203  3845 net.cpp:137] Memory required for data: 1636139040
I1022 19:29:09.355208  3845 layer_factory.hpp:77] Creating layer BatchNorm20
I1022 19:29:09.355214  3845 net.cpp:84] Creating Layer BatchNorm20
I1022 19:29:09.355217  3845 net.cpp:406] BatchNorm20 <- Convolution20
I1022 19:29:09.355221  3845 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1022 19:29:09.355365  3845 net.cpp:122] Setting up BatchNorm20
I1022 19:29:09.355370  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.355373  3845 net.cpp:137] Memory required for data: 1642561568
I1022 19:29:09.355378  3845 layer_factory.hpp:77] Creating layer Scale20
I1022 19:29:09.355383  3845 net.cpp:84] Creating Layer Scale20
I1022 19:29:09.355387  3845 net.cpp:406] Scale20 <- Convolution20
I1022 19:29:09.355391  3845 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1022 19:29:09.355419  3845 layer_factory.hpp:77] Creating layer Scale20
I1022 19:29:09.355501  3845 net.cpp:122] Setting up Scale20
I1022 19:29:09.355506  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.355509  3845 net.cpp:137] Memory required for data: 1648984096
I1022 19:29:09.355512  3845 layer_factory.hpp:77] Creating layer ReLU18
I1022 19:29:09.355516  3845 net.cpp:84] Creating Layer ReLU18
I1022 19:29:09.355518  3845 net.cpp:406] ReLU18 <- Convolution20
I1022 19:29:09.355528  3845 net.cpp:367] ReLU18 -> Convolution20 (in-place)
I1022 19:29:09.355651  3845 net.cpp:122] Setting up ReLU18
I1022 19:29:09.355657  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.355660  3845 net.cpp:137] Memory required for data: 1655406624
I1022 19:29:09.355662  3845 layer_factory.hpp:77] Creating layer Convolution21
I1022 19:29:09.355669  3845 net.cpp:84] Creating Layer Convolution21
I1022 19:29:09.355672  3845 net.cpp:406] Convolution21 <- Convolution20
I1022 19:29:09.355676  3845 net.cpp:380] Convolution21 -> Convolution21
I1022 19:29:09.357424  3845 net.cpp:122] Setting up Convolution21
I1022 19:29:09.357434  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.357436  3845 net.cpp:137] Memory required for data: 1661829152
I1022 19:29:09.357441  3845 layer_factory.hpp:77] Creating layer BatchNorm21
I1022 19:29:09.357445  3845 net.cpp:84] Creating Layer BatchNorm21
I1022 19:29:09.357448  3845 net.cpp:406] BatchNorm21 <- Convolution21
I1022 19:29:09.357452  3845 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1022 19:29:09.357590  3845 net.cpp:122] Setting up BatchNorm21
I1022 19:29:09.357595  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.357597  3845 net.cpp:137] Memory required for data: 1668251680
I1022 19:29:09.357602  3845 layer_factory.hpp:77] Creating layer Scale21
I1022 19:29:09.357606  3845 net.cpp:84] Creating Layer Scale21
I1022 19:29:09.357609  3845 net.cpp:406] Scale21 <- Convolution21
I1022 19:29:09.357611  3845 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1022 19:29:09.357638  3845 layer_factory.hpp:77] Creating layer Scale21
I1022 19:29:09.357720  3845 net.cpp:122] Setting up Scale21
I1022 19:29:09.357724  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.357728  3845 net.cpp:137] Memory required for data: 1674674208
I1022 19:29:09.357730  3845 layer_factory.hpp:77] Creating layer Eltwise9
I1022 19:29:09.357734  3845 net.cpp:84] Creating Layer Eltwise9
I1022 19:29:09.357738  3845 net.cpp:406] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I1022 19:29:09.357739  3845 net.cpp:406] Eltwise9 <- Convolution21
I1022 19:29:09.357743  3845 net.cpp:380] Eltwise9 -> Eltwise9
I1022 19:29:09.357758  3845 net.cpp:122] Setting up Eltwise9
I1022 19:29:09.357764  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.357765  3845 net.cpp:137] Memory required for data: 1681096736
I1022 19:29:09.357767  3845 layer_factory.hpp:77] Creating layer ReLU19
I1022 19:29:09.357770  3845 net.cpp:84] Creating Layer ReLU19
I1022 19:29:09.357772  3845 net.cpp:406] ReLU19 <- Eltwise9
I1022 19:29:09.357775  3845 net.cpp:367] ReLU19 -> Eltwise9 (in-place)
I1022 19:29:09.357892  3845 net.cpp:122] Setting up ReLU19
I1022 19:29:09.357897  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.357900  3845 net.cpp:137] Memory required for data: 1687519264
I1022 19:29:09.357903  3845 layer_factory.hpp:77] Creating layer Pooling1
I1022 19:29:09.357908  3845 net.cpp:84] Creating Layer Pooling1
I1022 19:29:09.357909  3845 net.cpp:406] Pooling1 <- Eltwise9
I1022 19:29:09.357913  3845 net.cpp:380] Pooling1 -> Pooling1
I1022 19:29:09.358057  3845 net.cpp:122] Setting up Pooling1
I1022 19:29:09.358063  3845 net.cpp:129] Top shape: 8 64 1 1 (512)
I1022 19:29:09.358065  3845 net.cpp:137] Memory required for data: 1687521312
I1022 19:29:09.358068  3845 layer_factory.hpp:77] Creating layer InnerProduct1
I1022 19:29:09.358075  3845 net.cpp:84] Creating Layer InnerProduct1
I1022 19:29:09.358078  3845 net.cpp:406] InnerProduct1 <- Pooling1
I1022 19:29:09.358083  3845 net.cpp:380] InnerProduct1 -> InnerProduct1
I1022 19:29:09.358165  3845 net.cpp:122] Setting up InnerProduct1
I1022 19:29:09.358170  3845 net.cpp:129] Top shape: 8 4 (32)
I1022 19:29:09.358171  3845 net.cpp:137] Memory required for data: 1687521440
I1022 19:29:09.358175  3845 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1022 19:29:09.358180  3845 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1022 19:29:09.358182  3845 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I1022 19:29:09.358192  3845 net.cpp:406] SoftmaxWithLoss1 <- Data2
I1022 19:29:09.358196  3845 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1022 19:29:09.358202  3845 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1022 19:29:09.358723  3845 net.cpp:122] Setting up SoftmaxWithLoss1
I1022 19:29:09.358731  3845 net.cpp:129] Top shape: (1)
I1022 19:29:09.358734  3845 net.cpp:132]     with loss weight 1
I1022 19:29:09.358745  3845 net.cpp:137] Memory required for data: 1687521444
I1022 19:29:09.358748  3845 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1022 19:29:09.358752  3845 net.cpp:198] InnerProduct1 needs backward computation.
I1022 19:29:09.358753  3845 net.cpp:198] Pooling1 needs backward computation.
I1022 19:29:09.358755  3845 net.cpp:198] ReLU19 needs backward computation.
I1022 19:29:09.358757  3845 net.cpp:198] Eltwise9 needs backward computation.
I1022 19:29:09.358760  3845 net.cpp:198] Scale21 needs backward computation.
I1022 19:29:09.358762  3845 net.cpp:198] BatchNorm21 needs backward computation.
I1022 19:29:09.358764  3845 net.cpp:198] Convolution21 needs backward computation.
I1022 19:29:09.358767  3845 net.cpp:198] ReLU18 needs backward computation.
I1022 19:29:09.358769  3845 net.cpp:198] Scale20 needs backward computation.
I1022 19:29:09.358772  3845 net.cpp:198] BatchNorm20 needs backward computation.
I1022 19:29:09.358773  3845 net.cpp:198] Convolution20 needs backward computation.
I1022 19:29:09.358775  3845 net.cpp:198] Eltwise8_ReLU17_0_split needs backward computation.
I1022 19:29:09.358777  3845 net.cpp:198] ReLU17 needs backward computation.
I1022 19:29:09.358779  3845 net.cpp:198] Eltwise8 needs backward computation.
I1022 19:29:09.358781  3845 net.cpp:198] Scale19 needs backward computation.
I1022 19:29:09.358783  3845 net.cpp:198] BatchNorm19 needs backward computation.
I1022 19:29:09.358785  3845 net.cpp:198] Convolution19 needs backward computation.
I1022 19:29:09.358788  3845 net.cpp:198] ReLU16 needs backward computation.
I1022 19:29:09.358789  3845 net.cpp:198] Scale18 needs backward computation.
I1022 19:29:09.358791  3845 net.cpp:198] BatchNorm18 needs backward computation.
I1022 19:29:09.358793  3845 net.cpp:198] Convolution18 needs backward computation.
I1022 19:29:09.358796  3845 net.cpp:198] Eltwise7_ReLU15_0_split needs backward computation.
I1022 19:29:09.358798  3845 net.cpp:198] ReLU15 needs backward computation.
I1022 19:29:09.358800  3845 net.cpp:198] Eltwise7 needs backward computation.
I1022 19:29:09.358803  3845 net.cpp:198] Scale17 needs backward computation.
I1022 19:29:09.358804  3845 net.cpp:198] BatchNorm17 needs backward computation.
I1022 19:29:09.358806  3845 net.cpp:198] Convolution17 needs backward computation.
I1022 19:29:09.358809  3845 net.cpp:198] ReLU14 needs backward computation.
I1022 19:29:09.358811  3845 net.cpp:198] Scale16 needs backward computation.
I1022 19:29:09.358814  3845 net.cpp:198] BatchNorm16 needs backward computation.
I1022 19:29:09.358815  3845 net.cpp:198] Convolution16 needs backward computation.
I1022 19:29:09.358819  3845 net.cpp:198] Scale15 needs backward computation.
I1022 19:29:09.358820  3845 net.cpp:198] BatchNorm15 needs backward computation.
I1022 19:29:09.358822  3845 net.cpp:198] Convolution15 needs backward computation.
I1022 19:29:09.358824  3845 net.cpp:198] Eltwise6_ReLU13_0_split needs backward computation.
I1022 19:29:09.358827  3845 net.cpp:198] ReLU13 needs backward computation.
I1022 19:29:09.358829  3845 net.cpp:198] Eltwise6 needs backward computation.
I1022 19:29:09.358832  3845 net.cpp:198] Scale14 needs backward computation.
I1022 19:29:09.358834  3845 net.cpp:198] BatchNorm14 needs backward computation.
I1022 19:29:09.358836  3845 net.cpp:198] Convolution14 needs backward computation.
I1022 19:29:09.358839  3845 net.cpp:198] ReLU12 needs backward computation.
I1022 19:29:09.358841  3845 net.cpp:198] Scale13 needs backward computation.
I1022 19:29:09.358844  3845 net.cpp:198] BatchNorm13 needs backward computation.
I1022 19:29:09.358845  3845 net.cpp:198] Convolution13 needs backward computation.
I1022 19:29:09.358855  3845 net.cpp:198] Eltwise5_ReLU11_0_split needs backward computation.
I1022 19:29:09.358856  3845 net.cpp:198] ReLU11 needs backward computation.
I1022 19:29:09.358860  3845 net.cpp:198] Eltwise5 needs backward computation.
I1022 19:29:09.358861  3845 net.cpp:198] Scale12 needs backward computation.
I1022 19:29:09.358865  3845 net.cpp:198] BatchNorm12 needs backward computation.
I1022 19:29:09.358866  3845 net.cpp:198] Convolution12 needs backward computation.
I1022 19:29:09.358868  3845 net.cpp:198] ReLU10 needs backward computation.
I1022 19:29:09.358870  3845 net.cpp:198] Scale11 needs backward computation.
I1022 19:29:09.358872  3845 net.cpp:198] BatchNorm11 needs backward computation.
I1022 19:29:09.358875  3845 net.cpp:198] Convolution11 needs backward computation.
I1022 19:29:09.358877  3845 net.cpp:198] Eltwise4_ReLU9_0_split needs backward computation.
I1022 19:29:09.358880  3845 net.cpp:198] ReLU9 needs backward computation.
I1022 19:29:09.358882  3845 net.cpp:198] Eltwise4 needs backward computation.
I1022 19:29:09.358886  3845 net.cpp:198] Scale10 needs backward computation.
I1022 19:29:09.358887  3845 net.cpp:198] BatchNorm10 needs backward computation.
I1022 19:29:09.358889  3845 net.cpp:198] Convolution10 needs backward computation.
I1022 19:29:09.358891  3845 net.cpp:198] ReLU8 needs backward computation.
I1022 19:29:09.358894  3845 net.cpp:198] Scale9 needs backward computation.
I1022 19:29:09.358896  3845 net.cpp:198] BatchNorm9 needs backward computation.
I1022 19:29:09.358898  3845 net.cpp:198] Convolution9 needs backward computation.
I1022 19:29:09.358901  3845 net.cpp:198] Scale8 needs backward computation.
I1022 19:29:09.358903  3845 net.cpp:198] BatchNorm8 needs backward computation.
I1022 19:29:09.358906  3845 net.cpp:198] Convolution8 needs backward computation.
I1022 19:29:09.358908  3845 net.cpp:198] Eltwise3_ReLU7_0_split needs backward computation.
I1022 19:29:09.358911  3845 net.cpp:198] ReLU7 needs backward computation.
I1022 19:29:09.358912  3845 net.cpp:198] Eltwise3 needs backward computation.
I1022 19:29:09.358916  3845 net.cpp:198] Scale7 needs backward computation.
I1022 19:29:09.358918  3845 net.cpp:198] BatchNorm7 needs backward computation.
I1022 19:29:09.358920  3845 net.cpp:198] Convolution7 needs backward computation.
I1022 19:29:09.358922  3845 net.cpp:198] ReLU6 needs backward computation.
I1022 19:29:09.358924  3845 net.cpp:198] Scale6 needs backward computation.
I1022 19:29:09.358927  3845 net.cpp:198] BatchNorm6 needs backward computation.
I1022 19:29:09.358929  3845 net.cpp:198] Convolution6 needs backward computation.
I1022 19:29:09.358932  3845 net.cpp:198] Eltwise2_ReLU5_0_split needs backward computation.
I1022 19:29:09.358933  3845 net.cpp:198] ReLU5 needs backward computation.
I1022 19:29:09.358937  3845 net.cpp:198] Eltwise2 needs backward computation.
I1022 19:29:09.358939  3845 net.cpp:198] Scale5 needs backward computation.
I1022 19:29:09.358942  3845 net.cpp:198] BatchNorm5 needs backward computation.
I1022 19:29:09.358944  3845 net.cpp:198] Convolution5 needs backward computation.
I1022 19:29:09.358947  3845 net.cpp:198] ReLU4 needs backward computation.
I1022 19:29:09.358948  3845 net.cpp:198] Scale4 needs backward computation.
I1022 19:29:09.358950  3845 net.cpp:198] BatchNorm4 needs backward computation.
I1022 19:29:09.358952  3845 net.cpp:198] Convolution4 needs backward computation.
I1022 19:29:09.358956  3845 net.cpp:198] Eltwise1_ReLU3_0_split needs backward computation.
I1022 19:29:09.358958  3845 net.cpp:198] ReLU3 needs backward computation.
I1022 19:29:09.358961  3845 net.cpp:198] Eltwise1 needs backward computation.
I1022 19:29:09.358963  3845 net.cpp:198] Scale3 needs backward computation.
I1022 19:29:09.358965  3845 net.cpp:198] BatchNorm3 needs backward computation.
I1022 19:29:09.358968  3845 net.cpp:198] Convolution3 needs backward computation.
I1022 19:29:09.358970  3845 net.cpp:198] ReLU2 needs backward computation.
I1022 19:29:09.358973  3845 net.cpp:198] Scale2 needs backward computation.
I1022 19:29:09.358978  3845 net.cpp:198] BatchNorm2 needs backward computation.
I1022 19:29:09.358980  3845 net.cpp:198] Convolution2 needs backward computation.
I1022 19:29:09.358983  3845 net.cpp:198] Convolution1_ReLU1_0_split needs backward computation.
I1022 19:29:09.358985  3845 net.cpp:198] ReLU1 needs backward computation.
I1022 19:29:09.358988  3845 net.cpp:198] Scale1 needs backward computation.
I1022 19:29:09.358989  3845 net.cpp:198] BatchNorm1 needs backward computation.
I1022 19:29:09.358991  3845 net.cpp:198] Convolution1 needs backward computation.
I1022 19:29:09.358994  3845 net.cpp:200] Data1 does not need backward computation.
I1022 19:29:09.358996  3845 net.cpp:242] This network produces output SoftmaxWithLoss1
I1022 19:29:09.359030  3845 net.cpp:255] Network initialization done.
I1022 19:29:09.360383  3845 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/English_orange/neural/res20/res20_relu_train_test.prototxt
I1022 19:29:09.360390  3845 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1022 19:29:09.360395  3845 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/English_orange/neural/res20/res20_relu_train_test.prototxt
I1022 19:29:09.360461  3845 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I1022 19:29:09.360826  3845 net.cpp:51] Initializing net from parameters: 
name: "resnet"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_file: "/home/x306/caffe/xn/English_orange/data/orange1_mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/English_orange/data/val1_lmdb"
    batch_size: 8
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution9"
  top: "Convolution9"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution11"
  top: "Convolution11"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
layer {
  name: "Accuracy1"
  type: "Accuracy"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "Accuracy1"
  include {
    phase: TEST
  }
}
I1022 19:29:09.361057  3845 layer_factory.hpp:77] Creating layer Data1
I1022 19:29:09.361093  3845 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/English_orange/data/val1_lmdb
I1022 19:29:09.361102  3845 net.cpp:84] Creating Layer Data1
I1022 19:29:09.361106  3845 net.cpp:380] Data1 -> Data1
I1022 19:29:09.361112  3845 net.cpp:380] Data1 -> Data2
I1022 19:29:09.361117  3845 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/English_orange/data/orange1_mean.binaryproto
I1022 19:29:09.362309  3845 data_layer.cpp:45] output data size: 8,3,224,224
I1022 19:29:09.370290  3845 net.cpp:122] Setting up Data1
I1022 19:29:09.370311  3845 net.cpp:129] Top shape: 8 3 224 224 (1204224)
I1022 19:29:09.370316  3845 net.cpp:129] Top shape: 8 (8)
I1022 19:29:09.370317  3845 net.cpp:137] Memory required for data: 4816928
I1022 19:29:09.370322  3845 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I1022 19:29:09.370332  3845 net.cpp:84] Creating Layer Data2_Data1_1_split
I1022 19:29:09.370335  3845 net.cpp:406] Data2_Data1_1_split <- Data2
I1022 19:29:09.370340  3845 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I1022 19:29:09.370347  3845 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I1022 19:29:09.370398  3845 net.cpp:122] Setting up Data2_Data1_1_split
I1022 19:29:09.370402  3845 net.cpp:129] Top shape: 8 (8)
I1022 19:29:09.370405  3845 net.cpp:129] Top shape: 8 (8)
I1022 19:29:09.370407  3845 net.cpp:137] Memory required for data: 4816992
I1022 19:29:09.370410  3845 layer_factory.hpp:77] Creating layer Convolution1
I1022 19:29:09.370419  3845 net.cpp:84] Creating Layer Convolution1
I1022 19:29:09.370421  3845 net.cpp:406] Convolution1 <- Data1
I1022 19:29:09.370425  3845 net.cpp:380] Convolution1 -> Convolution1
I1022 19:29:09.371814  3845 net.cpp:122] Setting up Convolution1
I1022 19:29:09.371824  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.371826  3845 net.cpp:137] Memory required for data: 30507104
I1022 19:29:09.371834  3845 layer_factory.hpp:77] Creating layer BatchNorm1
I1022 19:29:09.371840  3845 net.cpp:84] Creating Layer BatchNorm1
I1022 19:29:09.371842  3845 net.cpp:406] BatchNorm1 <- Convolution1
I1022 19:29:09.371846  3845 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1022 19:29:09.372035  3845 net.cpp:122] Setting up BatchNorm1
I1022 19:29:09.372042  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.372058  3845 net.cpp:137] Memory required for data: 56197216
I1022 19:29:09.372067  3845 layer_factory.hpp:77] Creating layer Scale1
I1022 19:29:09.372073  3845 net.cpp:84] Creating Layer Scale1
I1022 19:29:09.372076  3845 net.cpp:406] Scale1 <- Convolution1
I1022 19:29:09.372081  3845 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1022 19:29:09.372112  3845 layer_factory.hpp:77] Creating layer Scale1
I1022 19:29:09.372256  3845 net.cpp:122] Setting up Scale1
I1022 19:29:09.372261  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.372262  3845 net.cpp:137] Memory required for data: 81887328
I1022 19:29:09.372267  3845 layer_factory.hpp:77] Creating layer ReLU1
I1022 19:29:09.372272  3845 net.cpp:84] Creating Layer ReLU1
I1022 19:29:09.372274  3845 net.cpp:406] ReLU1 <- Convolution1
I1022 19:29:09.372277  3845 net.cpp:367] ReLU1 -> Convolution1 (in-place)
I1022 19:29:09.372421  3845 net.cpp:122] Setting up ReLU1
I1022 19:29:09.372428  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.372431  3845 net.cpp:137] Memory required for data: 107577440
I1022 19:29:09.372433  3845 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I1022 19:29:09.372437  3845 net.cpp:84] Creating Layer Convolution1_ReLU1_0_split
I1022 19:29:09.372440  3845 net.cpp:406] Convolution1_ReLU1_0_split <- Convolution1
I1022 19:29:09.372443  3845 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I1022 19:29:09.372448  3845 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I1022 19:29:09.372478  3845 net.cpp:122] Setting up Convolution1_ReLU1_0_split
I1022 19:29:09.372483  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.372486  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.372488  3845 net.cpp:137] Memory required for data: 158957664
I1022 19:29:09.372490  3845 layer_factory.hpp:77] Creating layer Convolution2
I1022 19:29:09.372498  3845 net.cpp:84] Creating Layer Convolution2
I1022 19:29:09.372500  3845 net.cpp:406] Convolution2 <- Convolution1_ReLU1_0_split_0
I1022 19:29:09.372504  3845 net.cpp:380] Convolution2 -> Convolution2
I1022 19:29:09.373477  3845 net.cpp:122] Setting up Convolution2
I1022 19:29:09.373486  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.373488  3845 net.cpp:137] Memory required for data: 184647776
I1022 19:29:09.373495  3845 layer_factory.hpp:77] Creating layer BatchNorm2
I1022 19:29:09.373500  3845 net.cpp:84] Creating Layer BatchNorm2
I1022 19:29:09.373503  3845 net.cpp:406] BatchNorm2 <- Convolution2
I1022 19:29:09.373507  3845 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1022 19:29:09.373669  3845 net.cpp:122] Setting up BatchNorm2
I1022 19:29:09.373674  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.373677  3845 net.cpp:137] Memory required for data: 210337888
I1022 19:29:09.373682  3845 layer_factory.hpp:77] Creating layer Scale2
I1022 19:29:09.373685  3845 net.cpp:84] Creating Layer Scale2
I1022 19:29:09.373687  3845 net.cpp:406] Scale2 <- Convolution2
I1022 19:29:09.373692  3845 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1022 19:29:09.373718  3845 layer_factory.hpp:77] Creating layer Scale2
I1022 19:29:09.373857  3845 net.cpp:122] Setting up Scale2
I1022 19:29:09.373862  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.373864  3845 net.cpp:137] Memory required for data: 236028000
I1022 19:29:09.373868  3845 layer_factory.hpp:77] Creating layer ReLU2
I1022 19:29:09.373872  3845 net.cpp:84] Creating Layer ReLU2
I1022 19:29:09.373874  3845 net.cpp:406] ReLU2 <- Convolution2
I1022 19:29:09.373878  3845 net.cpp:367] ReLU2 -> Convolution2 (in-place)
I1022 19:29:09.373993  3845 net.cpp:122] Setting up ReLU2
I1022 19:29:09.373999  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.374001  3845 net.cpp:137] Memory required for data: 261718112
I1022 19:29:09.374003  3845 layer_factory.hpp:77] Creating layer Convolution3
I1022 19:29:09.374009  3845 net.cpp:84] Creating Layer Convolution3
I1022 19:29:09.374020  3845 net.cpp:406] Convolution3 <- Convolution2
I1022 19:29:09.374024  3845 net.cpp:380] Convolution3 -> Convolution3
I1022 19:29:09.375598  3845 net.cpp:122] Setting up Convolution3
I1022 19:29:09.375610  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.375612  3845 net.cpp:137] Memory required for data: 287408224
I1022 19:29:09.375618  3845 layer_factory.hpp:77] Creating layer BatchNorm3
I1022 19:29:09.375624  3845 net.cpp:84] Creating Layer BatchNorm3
I1022 19:29:09.375627  3845 net.cpp:406] BatchNorm3 <- Convolution3
I1022 19:29:09.375630  3845 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1022 19:29:09.375809  3845 net.cpp:122] Setting up BatchNorm3
I1022 19:29:09.375814  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.375816  3845 net.cpp:137] Memory required for data: 313098336
I1022 19:29:09.375825  3845 layer_factory.hpp:77] Creating layer Scale3
I1022 19:29:09.375830  3845 net.cpp:84] Creating Layer Scale3
I1022 19:29:09.375833  3845 net.cpp:406] Scale3 <- Convolution3
I1022 19:29:09.375835  3845 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1022 19:29:09.375867  3845 layer_factory.hpp:77] Creating layer Scale3
I1022 19:29:09.376013  3845 net.cpp:122] Setting up Scale3
I1022 19:29:09.376019  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.376021  3845 net.cpp:137] Memory required for data: 338788448
I1022 19:29:09.376025  3845 layer_factory.hpp:77] Creating layer Eltwise1
I1022 19:29:09.376030  3845 net.cpp:84] Creating Layer Eltwise1
I1022 19:29:09.376034  3845 net.cpp:406] Eltwise1 <- Convolution1_ReLU1_0_split_1
I1022 19:29:09.376036  3845 net.cpp:406] Eltwise1 <- Convolution3
I1022 19:29:09.376040  3845 net.cpp:380] Eltwise1 -> Eltwise1
I1022 19:29:09.376060  3845 net.cpp:122] Setting up Eltwise1
I1022 19:29:09.376063  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.376065  3845 net.cpp:137] Memory required for data: 364478560
I1022 19:29:09.376067  3845 layer_factory.hpp:77] Creating layer ReLU3
I1022 19:29:09.376071  3845 net.cpp:84] Creating Layer ReLU3
I1022 19:29:09.376075  3845 net.cpp:406] ReLU3 <- Eltwise1
I1022 19:29:09.376077  3845 net.cpp:367] ReLU3 -> Eltwise1 (in-place)
I1022 19:29:09.376221  3845 net.cpp:122] Setting up ReLU3
I1022 19:29:09.376227  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.376230  3845 net.cpp:137] Memory required for data: 390168672
I1022 19:29:09.376231  3845 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I1022 19:29:09.376238  3845 net.cpp:84] Creating Layer Eltwise1_ReLU3_0_split
I1022 19:29:09.376241  3845 net.cpp:406] Eltwise1_ReLU3_0_split <- Eltwise1
I1022 19:29:09.376245  3845 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I1022 19:29:09.376255  3845 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I1022 19:29:09.376284  3845 net.cpp:122] Setting up Eltwise1_ReLU3_0_split
I1022 19:29:09.376288  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.376291  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.376293  3845 net.cpp:137] Memory required for data: 441548896
I1022 19:29:09.376296  3845 layer_factory.hpp:77] Creating layer Convolution4
I1022 19:29:09.376302  3845 net.cpp:84] Creating Layer Convolution4
I1022 19:29:09.376305  3845 net.cpp:406] Convolution4 <- Eltwise1_ReLU3_0_split_0
I1022 19:29:09.376315  3845 net.cpp:380] Convolution4 -> Convolution4
I1022 19:29:09.377825  3845 net.cpp:122] Setting up Convolution4
I1022 19:29:09.377835  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.377837  3845 net.cpp:137] Memory required for data: 467239008
I1022 19:29:09.377842  3845 layer_factory.hpp:77] Creating layer BatchNorm4
I1022 19:29:09.377847  3845 net.cpp:84] Creating Layer BatchNorm4
I1022 19:29:09.377851  3845 net.cpp:406] BatchNorm4 <- Convolution4
I1022 19:29:09.377854  3845 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1022 19:29:09.378026  3845 net.cpp:122] Setting up BatchNorm4
I1022 19:29:09.378031  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.378042  3845 net.cpp:137] Memory required for data: 492929120
I1022 19:29:09.378048  3845 layer_factory.hpp:77] Creating layer Scale4
I1022 19:29:09.378052  3845 net.cpp:84] Creating Layer Scale4
I1022 19:29:09.378056  3845 net.cpp:406] Scale4 <- Convolution4
I1022 19:29:09.378058  3845 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1022 19:29:09.378090  3845 layer_factory.hpp:77] Creating layer Scale4
I1022 19:29:09.378229  3845 net.cpp:122] Setting up Scale4
I1022 19:29:09.378234  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.378237  3845 net.cpp:137] Memory required for data: 518619232
I1022 19:29:09.378240  3845 layer_factory.hpp:77] Creating layer ReLU4
I1022 19:29:09.378243  3845 net.cpp:84] Creating Layer ReLU4
I1022 19:29:09.378247  3845 net.cpp:406] ReLU4 <- Convolution4
I1022 19:29:09.378249  3845 net.cpp:367] ReLU4 -> Convolution4 (in-place)
I1022 19:29:09.378366  3845 net.cpp:122] Setting up ReLU4
I1022 19:29:09.378372  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.378374  3845 net.cpp:137] Memory required for data: 544309344
I1022 19:29:09.378377  3845 layer_factory.hpp:77] Creating layer Convolution5
I1022 19:29:09.378389  3845 net.cpp:84] Creating Layer Convolution5
I1022 19:29:09.378391  3845 net.cpp:406] Convolution5 <- Convolution4
I1022 19:29:09.378407  3845 net.cpp:380] Convolution5 -> Convolution5
I1022 19:29:09.379854  3845 net.cpp:122] Setting up Convolution5
I1022 19:29:09.379865  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.379868  3845 net.cpp:137] Memory required for data: 569999456
I1022 19:29:09.379873  3845 layer_factory.hpp:77] Creating layer BatchNorm5
I1022 19:29:09.379878  3845 net.cpp:84] Creating Layer BatchNorm5
I1022 19:29:09.379881  3845 net.cpp:406] BatchNorm5 <- Convolution5
I1022 19:29:09.379885  3845 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1022 19:29:09.380098  3845 net.cpp:122] Setting up BatchNorm5
I1022 19:29:09.380105  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.380107  3845 net.cpp:137] Memory required for data: 595689568
I1022 19:29:09.380117  3845 layer_factory.hpp:77] Creating layer Scale5
I1022 19:29:09.380122  3845 net.cpp:84] Creating Layer Scale5
I1022 19:29:09.380125  3845 net.cpp:406] Scale5 <- Convolution5
I1022 19:29:09.380128  3845 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1022 19:29:09.380161  3845 layer_factory.hpp:77] Creating layer Scale5
I1022 19:29:09.380818  3845 net.cpp:122] Setting up Scale5
I1022 19:29:09.380827  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.380831  3845 net.cpp:137] Memory required for data: 621379680
I1022 19:29:09.380834  3845 layer_factory.hpp:77] Creating layer Eltwise2
I1022 19:29:09.380841  3845 net.cpp:84] Creating Layer Eltwise2
I1022 19:29:09.380842  3845 net.cpp:406] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I1022 19:29:09.380846  3845 net.cpp:406] Eltwise2 <- Convolution5
I1022 19:29:09.380849  3845 net.cpp:380] Eltwise2 -> Eltwise2
I1022 19:29:09.380869  3845 net.cpp:122] Setting up Eltwise2
I1022 19:29:09.380873  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.380875  3845 net.cpp:137] Memory required for data: 647069792
I1022 19:29:09.380877  3845 layer_factory.hpp:77] Creating layer ReLU5
I1022 19:29:09.380882  3845 net.cpp:84] Creating Layer ReLU5
I1022 19:29:09.380883  3845 net.cpp:406] ReLU5 <- Eltwise2
I1022 19:29:09.380887  3845 net.cpp:367] ReLU5 -> Eltwise2 (in-place)
I1022 19:29:09.381407  3845 net.cpp:122] Setting up ReLU5
I1022 19:29:09.381415  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.381417  3845 net.cpp:137] Memory required for data: 672759904
I1022 19:29:09.381420  3845 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I1022 19:29:09.381425  3845 net.cpp:84] Creating Layer Eltwise2_ReLU5_0_split
I1022 19:29:09.381428  3845 net.cpp:406] Eltwise2_ReLU5_0_split <- Eltwise2
I1022 19:29:09.381431  3845 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I1022 19:29:09.381435  3845 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I1022 19:29:09.381484  3845 net.cpp:122] Setting up Eltwise2_ReLU5_0_split
I1022 19:29:09.381489  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.381491  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.381494  3845 net.cpp:137] Memory required for data: 724140128
I1022 19:29:09.381496  3845 layer_factory.hpp:77] Creating layer Convolution6
I1022 19:29:09.381503  3845 net.cpp:84] Creating Layer Convolution6
I1022 19:29:09.381506  3845 net.cpp:406] Convolution6 <- Eltwise2_ReLU5_0_split_0
I1022 19:29:09.381510  3845 net.cpp:380] Convolution6 -> Convolution6
I1022 19:29:09.382539  3845 net.cpp:122] Setting up Convolution6
I1022 19:29:09.382546  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.382549  3845 net.cpp:137] Memory required for data: 749830240
I1022 19:29:09.382553  3845 layer_factory.hpp:77] Creating layer BatchNorm6
I1022 19:29:09.382558  3845 net.cpp:84] Creating Layer BatchNorm6
I1022 19:29:09.382560  3845 net.cpp:406] BatchNorm6 <- Convolution6
I1022 19:29:09.382565  3845 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1022 19:29:09.382730  3845 net.cpp:122] Setting up BatchNorm6
I1022 19:29:09.382735  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.382737  3845 net.cpp:137] Memory required for data: 775520352
I1022 19:29:09.382742  3845 layer_factory.hpp:77] Creating layer Scale6
I1022 19:29:09.382746  3845 net.cpp:84] Creating Layer Scale6
I1022 19:29:09.382750  3845 net.cpp:406] Scale6 <- Convolution6
I1022 19:29:09.382753  3845 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1022 19:29:09.382786  3845 layer_factory.hpp:77] Creating layer Scale6
I1022 19:29:09.382912  3845 net.cpp:122] Setting up Scale6
I1022 19:29:09.382917  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.382920  3845 net.cpp:137] Memory required for data: 801210464
I1022 19:29:09.382923  3845 layer_factory.hpp:77] Creating layer ReLU6
I1022 19:29:09.382927  3845 net.cpp:84] Creating Layer ReLU6
I1022 19:29:09.382930  3845 net.cpp:406] ReLU6 <- Convolution6
I1022 19:29:09.382932  3845 net.cpp:367] ReLU6 -> Convolution6 (in-place)
I1022 19:29:09.383397  3845 net.cpp:122] Setting up ReLU6
I1022 19:29:09.383405  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.383407  3845 net.cpp:137] Memory required for data: 826900576
I1022 19:29:09.383410  3845 layer_factory.hpp:77] Creating layer Convolution7
I1022 19:29:09.383416  3845 net.cpp:84] Creating Layer Convolution7
I1022 19:29:09.383419  3845 net.cpp:406] Convolution7 <- Convolution6
I1022 19:29:09.383424  3845 net.cpp:380] Convolution7 -> Convolution7
I1022 19:29:09.384743  3845 net.cpp:122] Setting up Convolution7
I1022 19:29:09.384752  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.384755  3845 net.cpp:137] Memory required for data: 852590688
I1022 19:29:09.384760  3845 layer_factory.hpp:77] Creating layer BatchNorm7
I1022 19:29:09.384768  3845 net.cpp:84] Creating Layer BatchNorm7
I1022 19:29:09.384770  3845 net.cpp:406] BatchNorm7 <- Convolution7
I1022 19:29:09.384774  3845 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1022 19:29:09.384950  3845 net.cpp:122] Setting up BatchNorm7
I1022 19:29:09.384955  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.384958  3845 net.cpp:137] Memory required for data: 878280800
I1022 19:29:09.384963  3845 layer_factory.hpp:77] Creating layer Scale7
I1022 19:29:09.384966  3845 net.cpp:84] Creating Layer Scale7
I1022 19:29:09.384969  3845 net.cpp:406] Scale7 <- Convolution7
I1022 19:29:09.384973  3845 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1022 19:29:09.385001  3845 layer_factory.hpp:77] Creating layer Scale7
I1022 19:29:09.385146  3845 net.cpp:122] Setting up Scale7
I1022 19:29:09.385151  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.385154  3845 net.cpp:137] Memory required for data: 903970912
I1022 19:29:09.385157  3845 layer_factory.hpp:77] Creating layer Eltwise3
I1022 19:29:09.385161  3845 net.cpp:84] Creating Layer Eltwise3
I1022 19:29:09.385175  3845 net.cpp:406] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I1022 19:29:09.385179  3845 net.cpp:406] Eltwise3 <- Convolution7
I1022 19:29:09.385182  3845 net.cpp:380] Eltwise3 -> Eltwise3
I1022 19:29:09.385200  3845 net.cpp:122] Setting up Eltwise3
I1022 19:29:09.385205  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.385206  3845 net.cpp:137] Memory required for data: 929661024
I1022 19:29:09.385210  3845 layer_factory.hpp:77] Creating layer ReLU7
I1022 19:29:09.385212  3845 net.cpp:84] Creating Layer ReLU7
I1022 19:29:09.385215  3845 net.cpp:406] ReLU7 <- Eltwise3
I1022 19:29:09.385217  3845 net.cpp:367] ReLU7 -> Eltwise3 (in-place)
I1022 19:29:09.385342  3845 net.cpp:122] Setting up ReLU7
I1022 19:29:09.385347  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.385350  3845 net.cpp:137] Memory required for data: 955351136
I1022 19:29:09.385352  3845 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I1022 19:29:09.385356  3845 net.cpp:84] Creating Layer Eltwise3_ReLU7_0_split
I1022 19:29:09.385359  3845 net.cpp:406] Eltwise3_ReLU7_0_split <- Eltwise3
I1022 19:29:09.385362  3845 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I1022 19:29:09.385366  3845 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I1022 19:29:09.385395  3845 net.cpp:122] Setting up Eltwise3_ReLU7_0_split
I1022 19:29:09.385398  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.385401  3845 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1022 19:29:09.385403  3845 net.cpp:137] Memory required for data: 1006731360
I1022 19:29:09.385406  3845 layer_factory.hpp:77] Creating layer Convolution8
I1022 19:29:09.385412  3845 net.cpp:84] Creating Layer Convolution8
I1022 19:29:09.385414  3845 net.cpp:406] Convolution8 <- Eltwise3_ReLU7_0_split_0
I1022 19:29:09.385418  3845 net.cpp:380] Convolution8 -> Convolution8
I1022 19:29:09.386409  3845 net.cpp:122] Setting up Convolution8
I1022 19:29:09.386417  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.386420  3845 net.cpp:137] Memory required for data: 1019576416
I1022 19:29:09.386425  3845 layer_factory.hpp:77] Creating layer BatchNorm8
I1022 19:29:09.386431  3845 net.cpp:84] Creating Layer BatchNorm8
I1022 19:29:09.386435  3845 net.cpp:406] BatchNorm8 <- Convolution8
I1022 19:29:09.386440  3845 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1022 19:29:09.386602  3845 net.cpp:122] Setting up BatchNorm8
I1022 19:29:09.386606  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.386608  3845 net.cpp:137] Memory required for data: 1032421472
I1022 19:29:09.386613  3845 layer_factory.hpp:77] Creating layer Scale8
I1022 19:29:09.386618  3845 net.cpp:84] Creating Layer Scale8
I1022 19:29:09.386621  3845 net.cpp:406] Scale8 <- Convolution8
I1022 19:29:09.386624  3845 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1022 19:29:09.386656  3845 layer_factory.hpp:77] Creating layer Scale8
I1022 19:29:09.386765  3845 net.cpp:122] Setting up Scale8
I1022 19:29:09.386770  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.386772  3845 net.cpp:137] Memory required for data: 1045266528
I1022 19:29:09.386776  3845 layer_factory.hpp:77] Creating layer Convolution9
I1022 19:29:09.386785  3845 net.cpp:84] Creating Layer Convolution9
I1022 19:29:09.386786  3845 net.cpp:406] Convolution9 <- Eltwise3_ReLU7_0_split_1
I1022 19:29:09.386791  3845 net.cpp:380] Convolution9 -> Convolution9
I1022 19:29:09.388219  3845 net.cpp:122] Setting up Convolution9
I1022 19:29:09.388229  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.388232  3845 net.cpp:137] Memory required for data: 1058111584
I1022 19:29:09.388236  3845 layer_factory.hpp:77] Creating layer BatchNorm9
I1022 19:29:09.388242  3845 net.cpp:84] Creating Layer BatchNorm9
I1022 19:29:09.388244  3845 net.cpp:406] BatchNorm9 <- Convolution9
I1022 19:29:09.388248  3845 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1022 19:29:09.388404  3845 net.cpp:122] Setting up BatchNorm9
I1022 19:29:09.388417  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.388419  3845 net.cpp:137] Memory required for data: 1070956640
I1022 19:29:09.388424  3845 layer_factory.hpp:77] Creating layer Scale9
I1022 19:29:09.388428  3845 net.cpp:84] Creating Layer Scale9
I1022 19:29:09.388430  3845 net.cpp:406] Scale9 <- Convolution9
I1022 19:29:09.388434  3845 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1022 19:29:09.388464  3845 layer_factory.hpp:77] Creating layer Scale9
I1022 19:29:09.388562  3845 net.cpp:122] Setting up Scale9
I1022 19:29:09.388567  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.388569  3845 net.cpp:137] Memory required for data: 1083801696
I1022 19:29:09.388573  3845 layer_factory.hpp:77] Creating layer ReLU8
I1022 19:29:09.388577  3845 net.cpp:84] Creating Layer ReLU8
I1022 19:29:09.388579  3845 net.cpp:406] ReLU8 <- Convolution9
I1022 19:29:09.388583  3845 net.cpp:367] ReLU8 -> Convolution9 (in-place)
I1022 19:29:09.388708  3845 net.cpp:122] Setting up ReLU8
I1022 19:29:09.388715  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.388716  3845 net.cpp:137] Memory required for data: 1096646752
I1022 19:29:09.388718  3845 layer_factory.hpp:77] Creating layer Convolution10
I1022 19:29:09.388725  3845 net.cpp:84] Creating Layer Convolution10
I1022 19:29:09.388727  3845 net.cpp:406] Convolution10 <- Convolution9
I1022 19:29:09.388732  3845 net.cpp:380] Convolution10 -> Convolution10
I1022 19:29:09.391058  3845 net.cpp:122] Setting up Convolution10
I1022 19:29:09.391070  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.391073  3845 net.cpp:137] Memory required for data: 1109491808
I1022 19:29:09.391088  3845 layer_factory.hpp:77] Creating layer BatchNorm10
I1022 19:29:09.391096  3845 net.cpp:84] Creating Layer BatchNorm10
I1022 19:29:09.391099  3845 net.cpp:406] BatchNorm10 <- Convolution10
I1022 19:29:09.391103  3845 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1022 19:29:09.391269  3845 net.cpp:122] Setting up BatchNorm10
I1022 19:29:09.391274  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.391276  3845 net.cpp:137] Memory required for data: 1122336864
I1022 19:29:09.391281  3845 layer_factory.hpp:77] Creating layer Scale10
I1022 19:29:09.391288  3845 net.cpp:84] Creating Layer Scale10
I1022 19:29:09.391290  3845 net.cpp:406] Scale10 <- Convolution10
I1022 19:29:09.391294  3845 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1022 19:29:09.391330  3845 layer_factory.hpp:77] Creating layer Scale10
I1022 19:29:09.391429  3845 net.cpp:122] Setting up Scale10
I1022 19:29:09.391434  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.391436  3845 net.cpp:137] Memory required for data: 1135181920
I1022 19:29:09.391439  3845 layer_factory.hpp:77] Creating layer Eltwise4
I1022 19:29:09.391445  3845 net.cpp:84] Creating Layer Eltwise4
I1022 19:29:09.391448  3845 net.cpp:406] Eltwise4 <- Convolution8
I1022 19:29:09.391450  3845 net.cpp:406] Eltwise4 <- Convolution10
I1022 19:29:09.391455  3845 net.cpp:380] Eltwise4 -> Eltwise4
I1022 19:29:09.391474  3845 net.cpp:122] Setting up Eltwise4
I1022 19:29:09.391479  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.391481  3845 net.cpp:137] Memory required for data: 1148026976
I1022 19:29:09.391484  3845 layer_factory.hpp:77] Creating layer ReLU9
I1022 19:29:09.391487  3845 net.cpp:84] Creating Layer ReLU9
I1022 19:29:09.391489  3845 net.cpp:406] ReLU9 <- Eltwise4
I1022 19:29:09.391492  3845 net.cpp:367] ReLU9 -> Eltwise4 (in-place)
I1022 19:29:09.391626  3845 net.cpp:122] Setting up ReLU9
I1022 19:29:09.391633  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.391635  3845 net.cpp:137] Memory required for data: 1160872032
I1022 19:29:09.391638  3845 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I1022 19:29:09.391643  3845 net.cpp:84] Creating Layer Eltwise4_ReLU9_0_split
I1022 19:29:09.391644  3845 net.cpp:406] Eltwise4_ReLU9_0_split <- Eltwise4
I1022 19:29:09.391647  3845 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I1022 19:29:09.391662  3845 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I1022 19:29:09.391695  3845 net.cpp:122] Setting up Eltwise4_ReLU9_0_split
I1022 19:29:09.391700  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.391702  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.391705  3845 net.cpp:137] Memory required for data: 1186562144
I1022 19:29:09.391706  3845 layer_factory.hpp:77] Creating layer Convolution11
I1022 19:29:09.391715  3845 net.cpp:84] Creating Layer Convolution11
I1022 19:29:09.391717  3845 net.cpp:406] Convolution11 <- Eltwise4_ReLU9_0_split_0
I1022 19:29:09.391721  3845 net.cpp:380] Convolution11 -> Convolution11
I1022 19:29:09.392881  3845 net.cpp:122] Setting up Convolution11
I1022 19:29:09.392890  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.392894  3845 net.cpp:137] Memory required for data: 1199407200
I1022 19:29:09.392897  3845 layer_factory.hpp:77] Creating layer BatchNorm11
I1022 19:29:09.392904  3845 net.cpp:84] Creating Layer BatchNorm11
I1022 19:29:09.392905  3845 net.cpp:406] BatchNorm11 <- Convolution11
I1022 19:29:09.392910  3845 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1022 19:29:09.393064  3845 net.cpp:122] Setting up BatchNorm11
I1022 19:29:09.393069  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.393070  3845 net.cpp:137] Memory required for data: 1212252256
I1022 19:29:09.393075  3845 layer_factory.hpp:77] Creating layer Scale11
I1022 19:29:09.393080  3845 net.cpp:84] Creating Layer Scale11
I1022 19:29:09.393084  3845 net.cpp:406] Scale11 <- Convolution11
I1022 19:29:09.393086  3845 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1022 19:29:09.393115  3845 layer_factory.hpp:77] Creating layer Scale11
I1022 19:29:09.393209  3845 net.cpp:122] Setting up Scale11
I1022 19:29:09.393213  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.393215  3845 net.cpp:137] Memory required for data: 1225097312
I1022 19:29:09.393219  3845 layer_factory.hpp:77] Creating layer ReLU10
I1022 19:29:09.393224  3845 net.cpp:84] Creating Layer ReLU10
I1022 19:29:09.393225  3845 net.cpp:406] ReLU10 <- Convolution11
I1022 19:29:09.393229  3845 net.cpp:367] ReLU10 -> Convolution11 (in-place)
I1022 19:29:09.393352  3845 net.cpp:122] Setting up ReLU10
I1022 19:29:09.393357  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.393358  3845 net.cpp:137] Memory required for data: 1237942368
I1022 19:29:09.393362  3845 layer_factory.hpp:77] Creating layer Convolution12
I1022 19:29:09.393368  3845 net.cpp:84] Creating Layer Convolution12
I1022 19:29:09.393370  3845 net.cpp:406] Convolution12 <- Convolution11
I1022 19:29:09.393375  3845 net.cpp:380] Convolution12 -> Convolution12
I1022 19:29:09.394484  3845 net.cpp:122] Setting up Convolution12
I1022 19:29:09.394495  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.394497  3845 net.cpp:137] Memory required for data: 1250787424
I1022 19:29:09.394501  3845 layer_factory.hpp:77] Creating layer BatchNorm12
I1022 19:29:09.394506  3845 net.cpp:84] Creating Layer BatchNorm12
I1022 19:29:09.394508  3845 net.cpp:406] BatchNorm12 <- Convolution12
I1022 19:29:09.394513  3845 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1022 19:29:09.394666  3845 net.cpp:122] Setting up BatchNorm12
I1022 19:29:09.394671  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.394675  3845 net.cpp:137] Memory required for data: 1263632480
I1022 19:29:09.394678  3845 layer_factory.hpp:77] Creating layer Scale12
I1022 19:29:09.394682  3845 net.cpp:84] Creating Layer Scale12
I1022 19:29:09.394685  3845 net.cpp:406] Scale12 <- Convolution12
I1022 19:29:09.394688  3845 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1022 19:29:09.394717  3845 layer_factory.hpp:77] Creating layer Scale12
I1022 19:29:09.394810  3845 net.cpp:122] Setting up Scale12
I1022 19:29:09.394815  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.394817  3845 net.cpp:137] Memory required for data: 1276477536
I1022 19:29:09.394829  3845 layer_factory.hpp:77] Creating layer Eltwise5
I1022 19:29:09.394832  3845 net.cpp:84] Creating Layer Eltwise5
I1022 19:29:09.394835  3845 net.cpp:406] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I1022 19:29:09.394839  3845 net.cpp:406] Eltwise5 <- Convolution12
I1022 19:29:09.394842  3845 net.cpp:380] Eltwise5 -> Eltwise5
I1022 19:29:09.394860  3845 net.cpp:122] Setting up Eltwise5
I1022 19:29:09.394865  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.394866  3845 net.cpp:137] Memory required for data: 1289322592
I1022 19:29:09.394868  3845 layer_factory.hpp:77] Creating layer ReLU11
I1022 19:29:09.394872  3845 net.cpp:84] Creating Layer ReLU11
I1022 19:29:09.394876  3845 net.cpp:406] ReLU11 <- Eltwise5
I1022 19:29:09.394878  3845 net.cpp:367] ReLU11 -> Eltwise5 (in-place)
I1022 19:29:09.394999  3845 net.cpp:122] Setting up ReLU11
I1022 19:29:09.395005  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.395007  3845 net.cpp:137] Memory required for data: 1302167648
I1022 19:29:09.395009  3845 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I1022 19:29:09.395015  3845 net.cpp:84] Creating Layer Eltwise5_ReLU11_0_split
I1022 19:29:09.395016  3845 net.cpp:406] Eltwise5_ReLU11_0_split <- Eltwise5
I1022 19:29:09.395020  3845 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I1022 19:29:09.395025  3845 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I1022 19:29:09.395056  3845 net.cpp:122] Setting up Eltwise5_ReLU11_0_split
I1022 19:29:09.395061  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.395063  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.395066  3845 net.cpp:137] Memory required for data: 1327857760
I1022 19:29:09.395067  3845 layer_factory.hpp:77] Creating layer Convolution13
I1022 19:29:09.395074  3845 net.cpp:84] Creating Layer Convolution13
I1022 19:29:09.395076  3845 net.cpp:406] Convolution13 <- Eltwise5_ReLU11_0_split_0
I1022 19:29:09.395082  3845 net.cpp:380] Convolution13 -> Convolution13
I1022 19:29:09.396208  3845 net.cpp:122] Setting up Convolution13
I1022 19:29:09.396216  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.396219  3845 net.cpp:137] Memory required for data: 1340702816
I1022 19:29:09.396224  3845 layer_factory.hpp:77] Creating layer BatchNorm13
I1022 19:29:09.396229  3845 net.cpp:84] Creating Layer BatchNorm13
I1022 19:29:09.396232  3845 net.cpp:406] BatchNorm13 <- Convolution13
I1022 19:29:09.396235  3845 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1022 19:29:09.396389  3845 net.cpp:122] Setting up BatchNorm13
I1022 19:29:09.396394  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.396395  3845 net.cpp:137] Memory required for data: 1353547872
I1022 19:29:09.396400  3845 layer_factory.hpp:77] Creating layer Scale13
I1022 19:29:09.396404  3845 net.cpp:84] Creating Layer Scale13
I1022 19:29:09.396406  3845 net.cpp:406] Scale13 <- Convolution13
I1022 19:29:09.396410  3845 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1022 19:29:09.396438  3845 layer_factory.hpp:77] Creating layer Scale13
I1022 19:29:09.396528  3845 net.cpp:122] Setting up Scale13
I1022 19:29:09.396533  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.396535  3845 net.cpp:137] Memory required for data: 1366392928
I1022 19:29:09.396539  3845 layer_factory.hpp:77] Creating layer ReLU12
I1022 19:29:09.396544  3845 net.cpp:84] Creating Layer ReLU12
I1022 19:29:09.396546  3845 net.cpp:406] ReLU12 <- Convolution13
I1022 19:29:09.396549  3845 net.cpp:367] ReLU12 -> Convolution13 (in-place)
I1022 19:29:09.397016  3845 net.cpp:122] Setting up ReLU12
I1022 19:29:09.397023  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.397027  3845 net.cpp:137] Memory required for data: 1379237984
I1022 19:29:09.397028  3845 layer_factory.hpp:77] Creating layer Convolution14
I1022 19:29:09.397040  3845 net.cpp:84] Creating Layer Convolution14
I1022 19:29:09.397043  3845 net.cpp:406] Convolution14 <- Convolution13
I1022 19:29:09.397055  3845 net.cpp:380] Convolution14 -> Convolution14
I1022 19:29:09.398164  3845 net.cpp:122] Setting up Convolution14
I1022 19:29:09.398172  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.398175  3845 net.cpp:137] Memory required for data: 1392083040
I1022 19:29:09.398180  3845 layer_factory.hpp:77] Creating layer BatchNorm14
I1022 19:29:09.398185  3845 net.cpp:84] Creating Layer BatchNorm14
I1022 19:29:09.398188  3845 net.cpp:406] BatchNorm14 <- Convolution14
I1022 19:29:09.398191  3845 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1022 19:29:09.398344  3845 net.cpp:122] Setting up BatchNorm14
I1022 19:29:09.398349  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.398350  3845 net.cpp:137] Memory required for data: 1404928096
I1022 19:29:09.398355  3845 layer_factory.hpp:77] Creating layer Scale14
I1022 19:29:09.398360  3845 net.cpp:84] Creating Layer Scale14
I1022 19:29:09.398363  3845 net.cpp:406] Scale14 <- Convolution14
I1022 19:29:09.398366  3845 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1022 19:29:09.398396  3845 layer_factory.hpp:77] Creating layer Scale14
I1022 19:29:09.398485  3845 net.cpp:122] Setting up Scale14
I1022 19:29:09.398490  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.398492  3845 net.cpp:137] Memory required for data: 1417773152
I1022 19:29:09.398496  3845 layer_factory.hpp:77] Creating layer Eltwise6
I1022 19:29:09.398501  3845 net.cpp:84] Creating Layer Eltwise6
I1022 19:29:09.398504  3845 net.cpp:406] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I1022 19:29:09.398506  3845 net.cpp:406] Eltwise6 <- Convolution14
I1022 19:29:09.398509  3845 net.cpp:380] Eltwise6 -> Eltwise6
I1022 19:29:09.398527  3845 net.cpp:122] Setting up Eltwise6
I1022 19:29:09.398531  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.398533  3845 net.cpp:137] Memory required for data: 1430618208
I1022 19:29:09.398535  3845 layer_factory.hpp:77] Creating layer ReLU13
I1022 19:29:09.398540  3845 net.cpp:84] Creating Layer ReLU13
I1022 19:29:09.398541  3845 net.cpp:406] ReLU13 <- Eltwise6
I1022 19:29:09.398545  3845 net.cpp:367] ReLU13 -> Eltwise6 (in-place)
I1022 19:29:09.398665  3845 net.cpp:122] Setting up ReLU13
I1022 19:29:09.398671  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.398674  3845 net.cpp:137] Memory required for data: 1443463264
I1022 19:29:09.398675  3845 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I1022 19:29:09.398679  3845 net.cpp:84] Creating Layer Eltwise6_ReLU13_0_split
I1022 19:29:09.398681  3845 net.cpp:406] Eltwise6_ReLU13_0_split <- Eltwise6
I1022 19:29:09.398685  3845 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I1022 19:29:09.398689  3845 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I1022 19:29:09.398720  3845 net.cpp:122] Setting up Eltwise6_ReLU13_0_split
I1022 19:29:09.398723  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.398726  3845 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1022 19:29:09.398728  3845 net.cpp:137] Memory required for data: 1469153376
I1022 19:29:09.398730  3845 layer_factory.hpp:77] Creating layer Convolution15
I1022 19:29:09.398737  3845 net.cpp:84] Creating Layer Convolution15
I1022 19:29:09.398741  3845 net.cpp:406] Convolution15 <- Eltwise6_ReLU13_0_split_0
I1022 19:29:09.398744  3845 net.cpp:380] Convolution15 -> Convolution15
I1022 19:29:09.399691  3845 net.cpp:122] Setting up Convolution15
I1022 19:29:09.399700  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.399703  3845 net.cpp:137] Memory required for data: 1475575904
I1022 19:29:09.399708  3845 layer_factory.hpp:77] Creating layer BatchNorm15
I1022 19:29:09.399713  3845 net.cpp:84] Creating Layer BatchNorm15
I1022 19:29:09.399715  3845 net.cpp:406] BatchNorm15 <- Convolution15
I1022 19:29:09.399720  3845 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1022 19:29:09.399876  3845 net.cpp:122] Setting up BatchNorm15
I1022 19:29:09.399881  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.399889  3845 net.cpp:137] Memory required for data: 1481998432
I1022 19:29:09.399894  3845 layer_factory.hpp:77] Creating layer Scale15
I1022 19:29:09.399899  3845 net.cpp:84] Creating Layer Scale15
I1022 19:29:09.399902  3845 net.cpp:406] Scale15 <- Convolution15
I1022 19:29:09.399905  3845 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1022 19:29:09.399936  3845 layer_factory.hpp:77] Creating layer Scale15
I1022 19:29:09.400053  3845 net.cpp:122] Setting up Scale15
I1022 19:29:09.400058  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.400060  3845 net.cpp:137] Memory required for data: 1488420960
I1022 19:29:09.400064  3845 layer_factory.hpp:77] Creating layer Convolution16
I1022 19:29:09.400071  3845 net.cpp:84] Creating Layer Convolution16
I1022 19:29:09.400074  3845 net.cpp:406] Convolution16 <- Eltwise6_ReLU13_0_split_1
I1022 19:29:09.400079  3845 net.cpp:380] Convolution16 -> Convolution16
I1022 19:29:09.401396  3845 net.cpp:122] Setting up Convolution16
I1022 19:29:09.401404  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.401407  3845 net.cpp:137] Memory required for data: 1494843488
I1022 19:29:09.401412  3845 layer_factory.hpp:77] Creating layer BatchNorm16
I1022 19:29:09.401417  3845 net.cpp:84] Creating Layer BatchNorm16
I1022 19:29:09.401420  3845 net.cpp:406] BatchNorm16 <- Convolution16
I1022 19:29:09.401424  3845 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1022 19:29:09.401577  3845 net.cpp:122] Setting up BatchNorm16
I1022 19:29:09.401582  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.401584  3845 net.cpp:137] Memory required for data: 1501266016
I1022 19:29:09.401589  3845 layer_factory.hpp:77] Creating layer Scale16
I1022 19:29:09.401593  3845 net.cpp:84] Creating Layer Scale16
I1022 19:29:09.401597  3845 net.cpp:406] Scale16 <- Convolution16
I1022 19:29:09.401598  3845 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1022 19:29:09.401629  3845 layer_factory.hpp:77] Creating layer Scale16
I1022 19:29:09.401720  3845 net.cpp:122] Setting up Scale16
I1022 19:29:09.401724  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.401726  3845 net.cpp:137] Memory required for data: 1507688544
I1022 19:29:09.401731  3845 layer_factory.hpp:77] Creating layer ReLU14
I1022 19:29:09.401733  3845 net.cpp:84] Creating Layer ReLU14
I1022 19:29:09.401736  3845 net.cpp:406] ReLU14 <- Convolution16
I1022 19:29:09.401738  3845 net.cpp:367] ReLU14 -> Convolution16 (in-place)
I1022 19:29:09.401866  3845 net.cpp:122] Setting up ReLU14
I1022 19:29:09.401872  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.401875  3845 net.cpp:137] Memory required for data: 1514111072
I1022 19:29:09.401876  3845 layer_factory.hpp:77] Creating layer Convolution17
I1022 19:29:09.401883  3845 net.cpp:84] Creating Layer Convolution17
I1022 19:29:09.401886  3845 net.cpp:406] Convolution17 <- Convolution16
I1022 19:29:09.401890  3845 net.cpp:380] Convolution17 -> Convolution17
I1022 19:29:09.404145  3845 net.cpp:122] Setting up Convolution17
I1022 19:29:09.404155  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.404157  3845 net.cpp:137] Memory required for data: 1520533600
I1022 19:29:09.404162  3845 layer_factory.hpp:77] Creating layer BatchNorm17
I1022 19:29:09.404167  3845 net.cpp:84] Creating Layer BatchNorm17
I1022 19:29:09.404170  3845 net.cpp:406] BatchNorm17 <- Convolution17
I1022 19:29:09.404173  3845 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1022 19:29:09.404327  3845 net.cpp:122] Setting up BatchNorm17
I1022 19:29:09.404332  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.404335  3845 net.cpp:137] Memory required for data: 1526956128
I1022 19:29:09.404340  3845 layer_factory.hpp:77] Creating layer Scale17
I1022 19:29:09.404343  3845 net.cpp:84] Creating Layer Scale17
I1022 19:29:09.404346  3845 net.cpp:406] Scale17 <- Convolution17
I1022 19:29:09.404350  3845 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1022 19:29:09.404379  3845 layer_factory.hpp:77] Creating layer Scale17
I1022 19:29:09.404479  3845 net.cpp:122] Setting up Scale17
I1022 19:29:09.404486  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.404489  3845 net.cpp:137] Memory required for data: 1533378656
I1022 19:29:09.404492  3845 layer_factory.hpp:77] Creating layer Eltwise7
I1022 19:29:09.404496  3845 net.cpp:84] Creating Layer Eltwise7
I1022 19:29:09.404498  3845 net.cpp:406] Eltwise7 <- Convolution15
I1022 19:29:09.404501  3845 net.cpp:406] Eltwise7 <- Convolution17
I1022 19:29:09.404505  3845 net.cpp:380] Eltwise7 -> Eltwise7
I1022 19:29:09.404522  3845 net.cpp:122] Setting up Eltwise7
I1022 19:29:09.404526  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.404528  3845 net.cpp:137] Memory required for data: 1539801184
I1022 19:29:09.404531  3845 layer_factory.hpp:77] Creating layer ReLU15
I1022 19:29:09.404534  3845 net.cpp:84] Creating Layer ReLU15
I1022 19:29:09.404536  3845 net.cpp:406] ReLU15 <- Eltwise7
I1022 19:29:09.404541  3845 net.cpp:367] ReLU15 -> Eltwise7 (in-place)
I1022 19:29:09.404662  3845 net.cpp:122] Setting up ReLU15
I1022 19:29:09.404669  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.404670  3845 net.cpp:137] Memory required for data: 1546223712
I1022 19:29:09.404673  3845 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I1022 19:29:09.404677  3845 net.cpp:84] Creating Layer Eltwise7_ReLU15_0_split
I1022 19:29:09.404680  3845 net.cpp:406] Eltwise7_ReLU15_0_split <- Eltwise7
I1022 19:29:09.404683  3845 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I1022 19:29:09.404687  3845 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I1022 19:29:09.404717  3845 net.cpp:122] Setting up Eltwise7_ReLU15_0_split
I1022 19:29:09.404721  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.404724  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.404726  3845 net.cpp:137] Memory required for data: 1559068768
I1022 19:29:09.404728  3845 layer_factory.hpp:77] Creating layer Convolution18
I1022 19:29:09.404734  3845 net.cpp:84] Creating Layer Convolution18
I1022 19:29:09.404737  3845 net.cpp:406] Convolution18 <- Eltwise7_ReLU15_0_split_0
I1022 19:29:09.404742  3845 net.cpp:380] Convolution18 -> Convolution18
I1022 19:29:09.406908  3845 net.cpp:122] Setting up Convolution18
I1022 19:29:09.406918  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.406920  3845 net.cpp:137] Memory required for data: 1565491296
I1022 19:29:09.406925  3845 layer_factory.hpp:77] Creating layer BatchNorm18
I1022 19:29:09.406931  3845 net.cpp:84] Creating Layer BatchNorm18
I1022 19:29:09.406934  3845 net.cpp:406] BatchNorm18 <- Convolution18
I1022 19:29:09.406937  3845 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1022 19:29:09.407131  3845 net.cpp:122] Setting up BatchNorm18
I1022 19:29:09.407140  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.407141  3845 net.cpp:137] Memory required for data: 1571913824
I1022 19:29:09.407147  3845 layer_factory.hpp:77] Creating layer Scale18
I1022 19:29:09.407151  3845 net.cpp:84] Creating Layer Scale18
I1022 19:29:09.407155  3845 net.cpp:406] Scale18 <- Convolution18
I1022 19:29:09.407158  3845 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1022 19:29:09.407191  3845 layer_factory.hpp:77] Creating layer Scale18
I1022 19:29:09.407285  3845 net.cpp:122] Setting up Scale18
I1022 19:29:09.407290  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.407292  3845 net.cpp:137] Memory required for data: 1578336352
I1022 19:29:09.407296  3845 layer_factory.hpp:77] Creating layer ReLU16
I1022 19:29:09.407300  3845 net.cpp:84] Creating Layer ReLU16
I1022 19:29:09.407304  3845 net.cpp:406] ReLU16 <- Convolution18
I1022 19:29:09.407306  3845 net.cpp:367] ReLU16 -> Convolution18 (in-place)
I1022 19:29:09.407441  3845 net.cpp:122] Setting up ReLU16
I1022 19:29:09.407449  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.407450  3845 net.cpp:137] Memory required for data: 1584758880
I1022 19:29:09.407454  3845 layer_factory.hpp:77] Creating layer Convolution19
I1022 19:29:09.407467  3845 net.cpp:84] Creating Layer Convolution19
I1022 19:29:09.407470  3845 net.cpp:406] Convolution19 <- Convolution18
I1022 19:29:09.407474  3845 net.cpp:380] Convolution19 -> Convolution19
I1022 19:29:09.409404  3845 net.cpp:122] Setting up Convolution19
I1022 19:29:09.409412  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.409415  3845 net.cpp:137] Memory required for data: 1591181408
I1022 19:29:09.409420  3845 layer_factory.hpp:77] Creating layer BatchNorm19
I1022 19:29:09.409433  3845 net.cpp:84] Creating Layer BatchNorm19
I1022 19:29:09.409436  3845 net.cpp:406] BatchNorm19 <- Convolution19
I1022 19:29:09.409440  3845 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1022 19:29:09.409592  3845 net.cpp:122] Setting up BatchNorm19
I1022 19:29:09.409597  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.409600  3845 net.cpp:137] Memory required for data: 1597603936
I1022 19:29:09.409616  3845 layer_factory.hpp:77] Creating layer Scale19
I1022 19:29:09.409621  3845 net.cpp:84] Creating Layer Scale19
I1022 19:29:09.409624  3845 net.cpp:406] Scale19 <- Convolution19
I1022 19:29:09.409627  3845 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1022 19:29:09.409658  3845 layer_factory.hpp:77] Creating layer Scale19
I1022 19:29:09.409747  3845 net.cpp:122] Setting up Scale19
I1022 19:29:09.409752  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.409754  3845 net.cpp:137] Memory required for data: 1604026464
I1022 19:29:09.409757  3845 layer_factory.hpp:77] Creating layer Eltwise8
I1022 19:29:09.409761  3845 net.cpp:84] Creating Layer Eltwise8
I1022 19:29:09.409765  3845 net.cpp:406] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I1022 19:29:09.409767  3845 net.cpp:406] Eltwise8 <- Convolution19
I1022 19:29:09.409770  3845 net.cpp:380] Eltwise8 -> Eltwise8
I1022 19:29:09.409790  3845 net.cpp:122] Setting up Eltwise8
I1022 19:29:09.409793  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.409795  3845 net.cpp:137] Memory required for data: 1610448992
I1022 19:29:09.409797  3845 layer_factory.hpp:77] Creating layer ReLU17
I1022 19:29:09.409801  3845 net.cpp:84] Creating Layer ReLU17
I1022 19:29:09.409802  3845 net.cpp:406] ReLU17 <- Eltwise8
I1022 19:29:09.409806  3845 net.cpp:367] ReLU17 -> Eltwise8 (in-place)
I1022 19:29:09.409925  3845 net.cpp:122] Setting up ReLU17
I1022 19:29:09.409931  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.409934  3845 net.cpp:137] Memory required for data: 1616871520
I1022 19:29:09.409935  3845 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I1022 19:29:09.409940  3845 net.cpp:84] Creating Layer Eltwise8_ReLU17_0_split
I1022 19:29:09.409942  3845 net.cpp:406] Eltwise8_ReLU17_0_split <- Eltwise8
I1022 19:29:09.409945  3845 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I1022 19:29:09.409950  3845 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I1022 19:29:09.409978  3845 net.cpp:122] Setting up Eltwise8_ReLU17_0_split
I1022 19:29:09.409982  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.409986  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.409987  3845 net.cpp:137] Memory required for data: 1629716576
I1022 19:29:09.409989  3845 layer_factory.hpp:77] Creating layer Convolution20
I1022 19:29:09.409996  3845 net.cpp:84] Creating Layer Convolution20
I1022 19:29:09.409998  3845 net.cpp:406] Convolution20 <- Eltwise8_ReLU17_0_split_0
I1022 19:29:09.410003  3845 net.cpp:380] Convolution20 -> Convolution20
I1022 19:29:09.412029  3845 net.cpp:122] Setting up Convolution20
I1022 19:29:09.412040  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.412044  3845 net.cpp:137] Memory required for data: 1636139104
I1022 19:29:09.412047  3845 layer_factory.hpp:77] Creating layer BatchNorm20
I1022 19:29:09.412052  3845 net.cpp:84] Creating Layer BatchNorm20
I1022 19:29:09.412055  3845 net.cpp:406] BatchNorm20 <- Convolution20
I1022 19:29:09.412058  3845 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1022 19:29:09.412220  3845 net.cpp:122] Setting up BatchNorm20
I1022 19:29:09.412226  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.412228  3845 net.cpp:137] Memory required for data: 1642561632
I1022 19:29:09.412233  3845 layer_factory.hpp:77] Creating layer Scale20
I1022 19:29:09.412237  3845 net.cpp:84] Creating Layer Scale20
I1022 19:29:09.412240  3845 net.cpp:406] Scale20 <- Convolution20
I1022 19:29:09.412242  3845 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1022 19:29:09.412272  3845 layer_factory.hpp:77] Creating layer Scale20
I1022 19:29:09.412361  3845 net.cpp:122] Setting up Scale20
I1022 19:29:09.412365  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.412367  3845 net.cpp:137] Memory required for data: 1648984160
I1022 19:29:09.412371  3845 layer_factory.hpp:77] Creating layer ReLU18
I1022 19:29:09.412375  3845 net.cpp:84] Creating Layer ReLU18
I1022 19:29:09.412377  3845 net.cpp:406] ReLU18 <- Convolution20
I1022 19:29:09.412380  3845 net.cpp:367] ReLU18 -> Convolution20 (in-place)
I1022 19:29:09.412835  3845 net.cpp:122] Setting up ReLU18
I1022 19:29:09.412843  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.412845  3845 net.cpp:137] Memory required for data: 1655406688
I1022 19:29:09.412848  3845 layer_factory.hpp:77] Creating layer Convolution21
I1022 19:29:09.412855  3845 net.cpp:84] Creating Layer Convolution21
I1022 19:29:09.412858  3845 net.cpp:406] Convolution21 <- Convolution20
I1022 19:29:09.412863  3845 net.cpp:380] Convolution21 -> Convolution21
I1022 19:29:09.414206  3845 net.cpp:122] Setting up Convolution21
I1022 19:29:09.414214  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.414216  3845 net.cpp:137] Memory required for data: 1661829216
I1022 19:29:09.414221  3845 layer_factory.hpp:77] Creating layer BatchNorm21
I1022 19:29:09.414225  3845 net.cpp:84] Creating Layer BatchNorm21
I1022 19:29:09.414228  3845 net.cpp:406] BatchNorm21 <- Convolution21
I1022 19:29:09.414232  3845 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1022 19:29:09.414386  3845 net.cpp:122] Setting up BatchNorm21
I1022 19:29:09.414389  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.414391  3845 net.cpp:137] Memory required for data: 1668251744
I1022 19:29:09.414397  3845 layer_factory.hpp:77] Creating layer Scale21
I1022 19:29:09.414400  3845 net.cpp:84] Creating Layer Scale21
I1022 19:29:09.414403  3845 net.cpp:406] Scale21 <- Convolution21
I1022 19:29:09.414407  3845 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1022 19:29:09.414435  3845 layer_factory.hpp:77] Creating layer Scale21
I1022 19:29:09.414525  3845 net.cpp:122] Setting up Scale21
I1022 19:29:09.414528  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.414530  3845 net.cpp:137] Memory required for data: 1674674272
I1022 19:29:09.414535  3845 layer_factory.hpp:77] Creating layer Eltwise9
I1022 19:29:09.414538  3845 net.cpp:84] Creating Layer Eltwise9
I1022 19:29:09.414541  3845 net.cpp:406] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I1022 19:29:09.414543  3845 net.cpp:406] Eltwise9 <- Convolution21
I1022 19:29:09.414546  3845 net.cpp:380] Eltwise9 -> Eltwise9
I1022 19:29:09.414563  3845 net.cpp:122] Setting up Eltwise9
I1022 19:29:09.414567  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.414569  3845 net.cpp:137] Memory required for data: 1681096800
I1022 19:29:09.414572  3845 layer_factory.hpp:77] Creating layer ReLU19
I1022 19:29:09.414577  3845 net.cpp:84] Creating Layer ReLU19
I1022 19:29:09.414578  3845 net.cpp:406] ReLU19 <- Eltwise9
I1022 19:29:09.414582  3845 net.cpp:367] ReLU19 -> Eltwise9 (in-place)
I1022 19:29:09.415031  3845 net.cpp:122] Setting up ReLU19
I1022 19:29:09.415040  3845 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1022 19:29:09.415042  3845 net.cpp:137] Memory required for data: 1687519328
I1022 19:29:09.415045  3845 layer_factory.hpp:77] Creating layer Pooling1
I1022 19:29:09.415050  3845 net.cpp:84] Creating Layer Pooling1
I1022 19:29:09.415052  3845 net.cpp:406] Pooling1 <- Eltwise9
I1022 19:29:09.415062  3845 net.cpp:380] Pooling1 -> Pooling1
I1022 19:29:09.415195  3845 net.cpp:122] Setting up Pooling1
I1022 19:29:09.415201  3845 net.cpp:129] Top shape: 8 64 1 1 (512)
I1022 19:29:09.415205  3845 net.cpp:137] Memory required for data: 1687521376
I1022 19:29:09.415206  3845 layer_factory.hpp:77] Creating layer InnerProduct1
I1022 19:29:09.415211  3845 net.cpp:84] Creating Layer InnerProduct1
I1022 19:29:09.415213  3845 net.cpp:406] InnerProduct1 <- Pooling1
I1022 19:29:09.415220  3845 net.cpp:380] InnerProduct1 -> InnerProduct1
I1022 19:29:09.415307  3845 net.cpp:122] Setting up InnerProduct1
I1022 19:29:09.415313  3845 net.cpp:129] Top shape: 8 4 (32)
I1022 19:29:09.415314  3845 net.cpp:137] Memory required for data: 1687521504
I1022 19:29:09.415318  3845 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I1022 19:29:09.415323  3845 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I1022 19:29:09.415325  3845 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I1022 19:29:09.415328  3845 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I1022 19:29:09.415333  3845 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I1022 19:29:09.415361  3845 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I1022 19:29:09.415364  3845 net.cpp:129] Top shape: 8 4 (32)
I1022 19:29:09.415367  3845 net.cpp:129] Top shape: 8 4 (32)
I1022 19:29:09.415369  3845 net.cpp:137] Memory required for data: 1687521760
I1022 19:29:09.415371  3845 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1022 19:29:09.415375  3845 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1022 19:29:09.415377  3845 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I1022 19:29:09.415380  3845 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I1022 19:29:09.415385  3845 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1022 19:29:09.415390  3845 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1022 19:29:09.415580  3845 net.cpp:122] Setting up SoftmaxWithLoss1
I1022 19:29:09.415585  3845 net.cpp:129] Top shape: (1)
I1022 19:29:09.415587  3845 net.cpp:132]     with loss weight 1
I1022 19:29:09.415594  3845 net.cpp:137] Memory required for data: 1687521764
I1022 19:29:09.415596  3845 layer_factory.hpp:77] Creating layer Accuracy1
I1022 19:29:09.415601  3845 net.cpp:84] Creating Layer Accuracy1
I1022 19:29:09.415604  3845 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I1022 19:29:09.415607  3845 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I1022 19:29:09.415611  3845 net.cpp:380] Accuracy1 -> Accuracy1
I1022 19:29:09.415616  3845 net.cpp:122] Setting up Accuracy1
I1022 19:29:09.415619  3845 net.cpp:129] Top shape: (1)
I1022 19:29:09.415621  3845 net.cpp:137] Memory required for data: 1687521768
I1022 19:29:09.415623  3845 net.cpp:200] Accuracy1 does not need backward computation.
I1022 19:29:09.415626  3845 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1022 19:29:09.415628  3845 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I1022 19:29:09.415630  3845 net.cpp:198] InnerProduct1 needs backward computation.
I1022 19:29:09.415632  3845 net.cpp:198] Pooling1 needs backward computation.
I1022 19:29:09.415634  3845 net.cpp:198] ReLU19 needs backward computation.
I1022 19:29:09.415637  3845 net.cpp:198] Eltwise9 needs backward computation.
I1022 19:29:09.415639  3845 net.cpp:198] Scale21 needs backward computation.
I1022 19:29:09.415642  3845 net.cpp:198] BatchNorm21 needs backward computation.
I1022 19:29:09.415643  3845 net.cpp:198] Convolution21 needs backward computation.
I1022 19:29:09.415645  3845 net.cpp:198] ReLU18 needs backward computation.
I1022 19:29:09.415647  3845 net.cpp:198] Scale20 needs backward computation.
I1022 19:29:09.415649  3845 net.cpp:198] BatchNorm20 needs backward computation.
I1022 19:29:09.415652  3845 net.cpp:198] Convolution20 needs backward computation.
I1022 19:29:09.415653  3845 net.cpp:198] Eltwise8_ReLU17_0_split needs backward computation.
I1022 19:29:09.415662  3845 net.cpp:198] ReLU17 needs backward computation.
I1022 19:29:09.415663  3845 net.cpp:198] Eltwise8 needs backward computation.
I1022 19:29:09.415665  3845 net.cpp:198] Scale19 needs backward computation.
I1022 19:29:09.415668  3845 net.cpp:198] BatchNorm19 needs backward computation.
I1022 19:29:09.415669  3845 net.cpp:198] Convolution19 needs backward computation.
I1022 19:29:09.415671  3845 net.cpp:198] ReLU16 needs backward computation.
I1022 19:29:09.415673  3845 net.cpp:198] Scale18 needs backward computation.
I1022 19:29:09.415675  3845 net.cpp:198] BatchNorm18 needs backward computation.
I1022 19:29:09.415678  3845 net.cpp:198] Convolution18 needs backward computation.
I1022 19:29:09.415680  3845 net.cpp:198] Eltwise7_ReLU15_0_split needs backward computation.
I1022 19:29:09.415683  3845 net.cpp:198] ReLU15 needs backward computation.
I1022 19:29:09.415684  3845 net.cpp:198] Eltwise7 needs backward computation.
I1022 19:29:09.415688  3845 net.cpp:198] Scale17 needs backward computation.
I1022 19:29:09.435868  3845 net.cpp:198] BatchNorm17 needs backward computation.
I1022 19:29:09.435875  3845 net.cpp:198] Convolution17 needs backward computation.
I1022 19:29:09.435879  3845 net.cpp:198] ReLU14 needs backward computation.
I1022 19:29:09.435883  3845 net.cpp:198] Scale16 needs backward computation.
I1022 19:29:09.435887  3845 net.cpp:198] BatchNorm16 needs backward computation.
I1022 19:29:09.435891  3845 net.cpp:198] Convolution16 needs backward computation.
I1022 19:29:09.435895  3845 net.cpp:198] Scale15 needs backward computation.
I1022 19:29:09.435899  3845 net.cpp:198] BatchNorm15 needs backward computation.
I1022 19:29:09.435904  3845 net.cpp:198] Convolution15 needs backward computation.
I1022 19:29:09.435907  3845 net.cpp:198] Eltwise6_ReLU13_0_split needs backward computation.
I1022 19:29:09.435911  3845 net.cpp:198] ReLU13 needs backward computation.
I1022 19:29:09.435914  3845 net.cpp:198] Eltwise6 needs backward computation.
I1022 19:29:09.435920  3845 net.cpp:198] Scale14 needs backward computation.
I1022 19:29:09.435922  3845 net.cpp:198] BatchNorm14 needs backward computation.
I1022 19:29:09.435926  3845 net.cpp:198] Convolution14 needs backward computation.
I1022 19:29:09.435930  3845 net.cpp:198] ReLU12 needs backward computation.
I1022 19:29:09.435933  3845 net.cpp:198] Scale13 needs backward computation.
I1022 19:29:09.435937  3845 net.cpp:198] BatchNorm13 needs backward computation.
I1022 19:29:09.435941  3845 net.cpp:198] Convolution13 needs backward computation.
I1022 19:29:09.435945  3845 net.cpp:198] Eltwise5_ReLU11_0_split needs backward computation.
I1022 19:29:09.435950  3845 net.cpp:198] ReLU11 needs backward computation.
I1022 19:29:09.435953  3845 net.cpp:198] Eltwise5 needs backward computation.
I1022 19:29:09.435963  3845 net.cpp:198] Scale12 needs backward computation.
I1022 19:29:09.435967  3845 net.cpp:198] BatchNorm12 needs backward computation.
I1022 19:29:09.435971  3845 net.cpp:198] Convolution12 needs backward computation.
I1022 19:29:09.435976  3845 net.cpp:198] ReLU10 needs backward computation.
I1022 19:29:09.435979  3845 net.cpp:198] Scale11 needs backward computation.
I1022 19:29:09.435983  3845 net.cpp:198] BatchNorm11 needs backward computation.
I1022 19:29:09.435986  3845 net.cpp:198] Convolution11 needs backward computation.
I1022 19:29:09.435992  3845 net.cpp:198] Eltwise4_ReLU9_0_split needs backward computation.
I1022 19:29:09.435995  3845 net.cpp:198] ReLU9 needs backward computation.
I1022 19:29:09.435998  3845 net.cpp:198] Eltwise4 needs backward computation.
I1022 19:29:09.436000  3845 net.cpp:198] Scale10 needs backward computation.
I1022 19:29:09.436003  3845 net.cpp:198] BatchNorm10 needs backward computation.
I1022 19:29:09.436005  3845 net.cpp:198] Convolution10 needs backward computation.
I1022 19:29:09.436009  3845 net.cpp:198] ReLU8 needs backward computation.
I1022 19:29:09.436012  3845 net.cpp:198] Scale9 needs backward computation.
I1022 19:29:09.436015  3845 net.cpp:198] BatchNorm9 needs backward computation.
I1022 19:29:09.436022  3845 net.cpp:198] Convolution9 needs backward computation.
I1022 19:29:09.436025  3845 net.cpp:198] Scale8 needs backward computation.
I1022 19:29:09.436028  3845 net.cpp:198] BatchNorm8 needs backward computation.
I1022 19:29:09.436030  3845 net.cpp:198] Convolution8 needs backward computation.
I1022 19:29:09.436033  3845 net.cpp:198] Eltwise3_ReLU7_0_split needs backward computation.
I1022 19:29:09.436036  3845 net.cpp:198] ReLU7 needs backward computation.
I1022 19:29:09.436038  3845 net.cpp:198] Eltwise3 needs backward computation.
I1022 19:29:09.436041  3845 net.cpp:198] Scale7 needs backward computation.
I1022 19:29:09.436043  3845 net.cpp:198] BatchNorm7 needs backward computation.
I1022 19:29:09.436046  3845 net.cpp:198] Convolution7 needs backward computation.
I1022 19:29:09.436048  3845 net.cpp:198] ReLU6 needs backward computation.
I1022 19:29:09.436050  3845 net.cpp:198] Scale6 needs backward computation.
I1022 19:29:09.436053  3845 net.cpp:198] BatchNorm6 needs backward computation.
I1022 19:29:09.436055  3845 net.cpp:198] Convolution6 needs backward computation.
I1022 19:29:09.436058  3845 net.cpp:198] Eltwise2_ReLU5_0_split needs backward computation.
I1022 19:29:09.436061  3845 net.cpp:198] ReLU5 needs backward computation.
I1022 19:29:09.436064  3845 net.cpp:198] Eltwise2 needs backward computation.
I1022 19:29:09.436066  3845 net.cpp:198] Scale5 needs backward computation.
I1022 19:29:09.436069  3845 net.cpp:198] BatchNorm5 needs backward computation.
I1022 19:29:09.436071  3845 net.cpp:198] Convolution5 needs backward computation.
I1022 19:29:09.436074  3845 net.cpp:198] ReLU4 needs backward computation.
I1022 19:29:09.436076  3845 net.cpp:198] Scale4 needs backward computation.
I1022 19:29:09.436079  3845 net.cpp:198] BatchNorm4 needs backward computation.
I1022 19:29:09.436081  3845 net.cpp:198] Convolution4 needs backward computation.
I1022 19:29:09.436084  3845 net.cpp:198] Eltwise1_ReLU3_0_split needs backward computation.
I1022 19:29:09.436086  3845 net.cpp:198] ReLU3 needs backward computation.
I1022 19:29:09.436089  3845 net.cpp:198] Eltwise1 needs backward computation.
I1022 19:29:09.436091  3845 net.cpp:198] Scale3 needs backward computation.
I1022 19:29:09.436094  3845 net.cpp:198] BatchNorm3 needs backward computation.
I1022 19:29:09.436096  3845 net.cpp:198] Convolution3 needs backward computation.
I1022 19:29:09.436100  3845 net.cpp:198] ReLU2 needs backward computation.
I1022 19:29:09.436101  3845 net.cpp:198] Scale2 needs backward computation.
I1022 19:29:09.436103  3845 net.cpp:198] BatchNorm2 needs backward computation.
I1022 19:29:09.436106  3845 net.cpp:198] Convolution2 needs backward computation.
I1022 19:29:09.436108  3845 net.cpp:198] Convolution1_ReLU1_0_split needs backward computation.
I1022 19:29:09.436111  3845 net.cpp:198] ReLU1 needs backward computation.
I1022 19:29:09.436113  3845 net.cpp:198] Scale1 needs backward computation.
I1022 19:29:09.436116  3845 net.cpp:198] BatchNorm1 needs backward computation.
I1022 19:29:09.436118  3845 net.cpp:198] Convolution1 needs backward computation.
I1022 19:29:09.436121  3845 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I1022 19:29:09.436125  3845 net.cpp:200] Data1 does not need backward computation.
I1022 19:29:09.436126  3845 net.cpp:242] This network produces output Accuracy1
I1022 19:29:09.436130  3845 net.cpp:242] This network produces output SoftmaxWithLoss1
I1022 19:29:09.436167  3845 net.cpp:255] Network initialization done.
I1022 19:29:09.436393  3845 solver.cpp:56] Solver scaffolding done.
I1022 19:29:09.440557  3845 caffe.cpp:248] Starting Optimization
I1022 19:29:09.440567  3845 solver.cpp:272] Solving resnet
I1022 19:29:09.440569  3845 solver.cpp:273] Learning Rate Policy: multistep
I1022 19:29:09.442754  3845 solver.cpp:330] Iteration 0, Testing net (#0)
I1022 19:29:11.667686  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:29:11.789839  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.119141
I1022 19:29:11.789901  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I1022 19:29:11.990559  3845 solver.cpp:218] Iteration 0 (2.43861e+09 iter/s, 2.5499s/100 iters), loss = 1.39281
I1022 19:29:11.990589  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.39281 (* 1 = 1.39281 loss)
I1022 19:29:11.990600  3845 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I1022 19:29:29.815286  3845 solver.cpp:218] Iteration 100 (5.61025 iter/s, 17.8245s/100 iters), loss = 0.856035
I1022 19:29:29.815320  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.856035 (* 1 = 0.856035 loss)
I1022 19:29:29.815326  3845 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I1022 19:29:47.496232  3845 solver.cpp:330] Iteration 200, Testing net (#0)
I1022 19:29:49.680168  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:29:49.802390  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.136719
I1022 19:29:49.802454  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 23.9044 (* 1 = 23.9044 loss)
I1022 19:29:49.980515  3845 solver.cpp:218] Iteration 200 (4.95909 iter/s, 20.165s/100 iters), loss = 0.632423
I1022 19:29:49.980545  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.632423 (* 1 = 0.632423 loss)
I1022 19:29:49.980552  3845 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I1022 19:30:07.820325  3845 solver.cpp:218] Iteration 300 (5.6055 iter/s, 17.8396s/100 iters), loss = 1.55518
I1022 19:30:07.820356  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.55518 (* 1 = 1.55518 loss)
I1022 19:30:07.820363  3845 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I1022 19:30:14.443295  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:30:25.493758  3845 solver.cpp:330] Iteration 400, Testing net (#0)
I1022 19:30:27.711222  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:30:27.835492  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.443359
I1022 19:30:27.835539  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.99444 (* 1 = 3.99444 loss)
I1022 19:30:28.015709  3845 solver.cpp:218] Iteration 400 (4.95168 iter/s, 20.1952s/100 iters), loss = 0.924209
I1022 19:30:28.015738  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.924209 (* 1 = 0.924209 loss)
I1022 19:30:28.015746  3845 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I1022 19:30:46.013814  3845 solver.cpp:218] Iteration 500 (5.5562 iter/s, 17.9979s/100 iters), loss = 0.592267
I1022 19:30:46.013846  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.592267 (* 1 = 0.592267 loss)
I1022 19:30:46.013854  3845 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I1022 19:31:04.096488  3845 solver.cpp:330] Iteration 600, Testing net (#0)
I1022 19:31:06.292701  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:31:06.450357  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.251953
I1022 19:31:06.450422  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.02723 (* 1 = 3.02723 loss)
I1022 19:31:06.629827  3845 solver.cpp:218] Iteration 600 (4.85065 iter/s, 20.6158s/100 iters), loss = 1.52976
I1022 19:31:06.629860  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.52976 (* 1 = 1.52976 loss)
I1022 19:31:06.629868  3845 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I1022 19:31:20.781738  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:31:24.700342  3845 solver.cpp:218] Iteration 700 (5.53394 iter/s, 18.0703s/100 iters), loss = 0.722487
I1022 19:31:24.700374  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.722488 (* 1 = 0.722488 loss)
I1022 19:31:24.700381  3845 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I1022 19:31:42.530012  3845 solver.cpp:330] Iteration 800, Testing net (#0)
I1022 19:31:44.691479  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:31:44.849853  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.193359
I1022 19:31:44.849912  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 5.18991 (* 1 = 5.18991 loss)
I1022 19:31:45.029639  3845 solver.cpp:218] Iteration 800 (4.91906 iter/s, 20.3291s/100 iters), loss = 0.281297
I1022 19:31:45.029671  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281297 (* 1 = 0.281297 loss)
I1022 19:31:45.029678  3845 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I1022 19:32:03.055387  3845 solver.cpp:218] Iteration 900 (5.54768 iter/s, 18.0256s/100 iters), loss = 0.673604
I1022 19:32:03.055418  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.673604 (* 1 = 0.673604 loss)
I1022 19:32:03.055426  3845 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I1022 19:32:21.136931  3845 solver.cpp:330] Iteration 1000, Testing net (#0)
I1022 19:32:23.298440  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:32:23.456409  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.439453
I1022 19:32:23.456466  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.17047 (* 1 = 2.17047 loss)
I1022 19:32:23.636556  3845 solver.cpp:218] Iteration 1000 (4.85886 iter/s, 20.581s/100 iters), loss = 0.237389
I1022 19:32:23.636590  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237389 (* 1 = 0.237389 loss)
I1022 19:32:23.636598  3845 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I1022 19:32:27.084380  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:32:41.560971  3845 solver.cpp:218] Iteration 1100 (5.57904 iter/s, 17.9242s/100 iters), loss = 0.0750087
I1022 19:32:41.561003  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0750092 (* 1 = 0.0750092 loss)
I1022 19:32:41.561010  3845 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I1022 19:32:59.287533  3845 solver.cpp:330] Iteration 1200, Testing net (#0)
I1022 19:33:01.441249  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:33:01.601153  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.453125
I1022 19:33:01.601219  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.16705 (* 1 = 2.16705 loss)
I1022 19:33:01.781375  3845 solver.cpp:218] Iteration 1200 (4.94554 iter/s, 20.2202s/100 iters), loss = 1.99582
I1022 19:33:01.781406  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.99582 (* 1 = 1.99582 loss)
I1022 19:33:01.781414  3845 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I1022 19:33:19.675390  3845 solver.cpp:218] Iteration 1300 (5.58851 iter/s, 17.8939s/100 iters), loss = 0.734116
I1022 19:33:19.675434  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.734117 (* 1 = 0.734117 loss)
I1022 19:33:19.675442  3845 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I1022 19:33:30.444630  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:33:37.399652  3845 solver.cpp:330] Iteration 1400, Testing net (#0)
I1022 19:33:39.518692  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:33:39.711424  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.632812
I1022 19:33:39.711491  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.977468 (* 1 = 0.977468 loss)
I1022 19:33:39.891933  3845 solver.cpp:218] Iteration 1400 (4.94648 iter/s, 20.2164s/100 iters), loss = 0.653578
I1022 19:33:39.891970  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.653578 (* 1 = 0.653578 loss)
I1022 19:33:39.891978  3845 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I1022 19:33:57.793444  3845 solver.cpp:218] Iteration 1500 (5.58616 iter/s, 17.9014s/100 iters), loss = 0.484819
I1022 19:33:57.793478  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.48482 (* 1 = 0.48482 loss)
I1022 19:33:57.793484  3845 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I1022 19:34:15.520767  3845 solver.cpp:330] Iteration 1600, Testing net (#0)
I1022 19:34:17.639225  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:34:17.832936  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.289062
I1022 19:34:17.832998  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 7.16428 (* 1 = 7.16428 loss)
I1022 19:34:18.013772  3845 solver.cpp:218] Iteration 1600 (4.94555 iter/s, 20.2202s/100 iters), loss = 1.0782
I1022 19:34:18.013801  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.0782 (* 1 = 1.0782 loss)
I1022 19:34:18.013808  3845 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I1022 19:34:35.915674  3845 solver.cpp:218] Iteration 1700 (5.58603 iter/s, 17.9018s/100 iters), loss = 0.926108
I1022 19:34:35.915706  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.926109 (* 1 = 0.926109 loss)
I1022 19:34:35.915714  3845 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I1022 19:34:36.297063  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:34:53.643931  3845 solver.cpp:330] Iteration 1800, Testing net (#0)
I1022 19:34:55.761658  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:34:55.956450  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8125
I1022 19:34:55.956516  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.619901 (* 1 = 0.619901 loss)
I1022 19:34:56.136971  3845 solver.cpp:218] Iteration 1800 (4.94531 iter/s, 20.2212s/100 iters), loss = 0.551764
I1022 19:34:56.137006  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.551765 (* 1 = 0.551765 loss)
I1022 19:34:56.137012  3845 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I1022 19:35:14.030812  3845 solver.cpp:218] Iteration 1900 (5.58855 iter/s, 17.8937s/100 iters), loss = 0.554496
I1022 19:35:14.030843  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.554496 (* 1 = 0.554496 loss)
I1022 19:35:14.030850  3845 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I1022 19:35:31.748039  3845 solver.cpp:330] Iteration 2000, Testing net (#0)
I1022 19:35:33.865120  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:35:34.061619  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.396484
I1022 19:35:34.061679  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 6.04325 (* 1 = 6.04325 loss)
I1022 19:35:34.242394  3845 solver.cpp:218] Iteration 2000 (4.94769 iter/s, 20.2115s/100 iters), loss = 0.0508714
I1022 19:35:34.242430  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0508718 (* 1 = 0.0508718 loss)
I1022 19:35:34.242437  3845 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I1022 19:35:41.978152  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:35:52.169560  3845 solver.cpp:218] Iteration 2100 (5.57816 iter/s, 17.9271s/100 iters), loss = 0.336415
I1022 19:35:52.169595  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336416 (* 1 = 0.336416 loss)
I1022 19:35:52.169601  3845 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I1022 19:36:09.923096  3845 solver.cpp:330] Iteration 2200, Testing net (#0)
I1022 19:36:12.008469  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:36:12.237781  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.724609
I1022 19:36:12.237839  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.777126 (* 1 = 0.777126 loss)
I1022 19:36:12.418885  3845 solver.cpp:218] Iteration 2200 (4.93846 iter/s, 20.2492s/100 iters), loss = 0.329575
I1022 19:36:12.418918  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329575 (* 1 = 0.329575 loss)
I1022 19:36:12.418926  3845 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I1022 19:36:30.343029  3845 solver.cpp:218] Iteration 2300 (5.5791 iter/s, 17.924s/100 iters), loss = 0.119433
I1022 19:36:30.343060  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119434 (* 1 = 0.119434 loss)
I1022 19:36:30.343066  3845 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I1022 19:36:45.426396  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:36:48.093832  3845 solver.cpp:330] Iteration 2400, Testing net (#0)
I1022 19:36:50.178169  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:36:50.408877  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.824219
I1022 19:36:50.408946  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.456735 (* 1 = 0.456735 loss)
I1022 19:36:50.589011  3845 solver.cpp:218] Iteration 2400 (4.93928 iter/s, 20.2459s/100 iters), loss = 0.162331
I1022 19:36:50.589043  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162331 (* 1 = 0.162331 loss)
I1022 19:36:50.589051  3845 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I1022 19:37:08.502926  3845 solver.cpp:218] Iteration 2500 (5.58229 iter/s, 17.9138s/100 iters), loss = 0.325953
I1022 19:37:08.502959  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325953 (* 1 = 0.325953 loss)
I1022 19:37:08.502965  3845 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I1022 19:37:26.248095  3845 solver.cpp:330] Iteration 2600, Testing net (#0)
I1022 19:37:28.331560  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:37:28.563917  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.769531
I1022 19:37:28.563988  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.783164 (* 1 = 0.783164 loss)
I1022 19:37:28.744319  3845 solver.cpp:218] Iteration 2600 (4.9404 iter/s, 20.2413s/100 iters), loss = 0.175504
I1022 19:37:28.744352  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175505 (* 1 = 0.175505 loss)
I1022 19:37:28.744360  3845 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I1022 19:37:46.667783  3845 solver.cpp:218] Iteration 2700 (5.57931 iter/s, 17.9234s/100 iters), loss = 1.00689
I1022 19:37:46.667814  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.00689 (* 1 = 1.00689 loss)
I1022 19:37:46.667821  3845 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I1022 19:37:51.176980  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:38:04.418429  3845 solver.cpp:330] Iteration 2800, Testing net (#0)
I1022 19:38:06.501109  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:38:06.733438  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.849609
I1022 19:38:06.733491  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.391665 (* 1 = 0.391665 loss)
I1022 19:38:06.914516  3845 solver.cpp:218] Iteration 2800 (4.9391 iter/s, 20.2466s/100 iters), loss = 0.0395517
I1022 19:38:06.914548  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0395525 (* 1 = 0.0395525 loss)
I1022 19:38:06.914556  3845 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I1022 19:38:24.837056  3845 solver.cpp:218] Iteration 2900 (5.5796 iter/s, 17.9224s/100 iters), loss = 0.604086
I1022 19:38:24.837088  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.604087 (* 1 = 0.604087 loss)
I1022 19:38:24.837095  3845 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I1022 19:38:42.583138  3845 solver.cpp:330] Iteration 3000, Testing net (#0)
I1022 19:38:44.631333  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:38:44.896740  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.707031
I1022 19:38:44.896800  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.36695 (* 1 = 1.36695 loss)
I1022 19:38:45.077270  3845 solver.cpp:218] Iteration 3000 (4.94069 iter/s, 20.2401s/100 iters), loss = 1.42782
I1022 19:38:45.077299  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.42783 (* 1 = 1.42783 loss)
I1022 19:38:45.077307  3845 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I1022 19:38:57.105459  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:39:03.000147  3845 solver.cpp:218] Iteration 3100 (5.57949 iter/s, 17.9228s/100 iters), loss = 0.32488
I1022 19:39:03.000180  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324881 (* 1 = 0.324881 loss)
I1022 19:39:03.000187  3845 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I1022 19:39:20.732333  3845 solver.cpp:330] Iteration 3200, Testing net (#0)
I1022 19:39:22.781379  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:39:23.048038  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.658203
I1022 19:39:23.048106  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.05731 (* 1 = 1.05731 loss)
I1022 19:39:23.229085  3845 solver.cpp:218] Iteration 3200 (4.94344 iter/s, 20.2288s/100 iters), loss = 0.168144
I1022 19:39:23.229116  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168144 (* 1 = 0.168144 loss)
I1022 19:39:23.229123  3845 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I1022 19:39:41.218730  3845 solver.cpp:218] Iteration 3300 (5.55878 iter/s, 17.9895s/100 iters), loss = 0.315818
I1022 19:39:41.218762  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315818 (* 1 = 0.315818 loss)
I1022 19:39:41.218770  3845 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I1022 19:39:59.119905  3845 solver.cpp:330] Iteration 3400, Testing net (#0)
I1022 19:40:01.187582  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:40:01.455708  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.755859
I1022 19:40:01.455772  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.831134 (* 1 = 0.831134 loss)
I1022 19:40:01.637585  3845 solver.cpp:218] Iteration 3400 (4.89746 iter/s, 20.4187s/100 iters), loss = 0.0124938
I1022 19:40:01.637620  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124943 (* 1 = 0.0124943 loss)
I1022 19:40:01.637627  3845 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I1022 19:40:03.136456  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:40:19.877490  3845 solver.cpp:218] Iteration 3500 (5.48252 iter/s, 18.2398s/100 iters), loss = 0.558196
I1022 19:40:19.877522  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.558196 (* 1 = 0.558196 loss)
I1022 19:40:19.877529  3845 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I1022 19:40:37.687403  3845 solver.cpp:330] Iteration 3600, Testing net (#0)
I1022 19:40:39.737182  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:40:40.005910  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.830078
I1022 19:40:40.005980  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.514049 (* 1 = 0.514049 loss)
I1022 19:40:40.186516  3845 solver.cpp:218] Iteration 3600 (4.92394 iter/s, 20.3089s/100 iters), loss = 0.174896
I1022 19:40:40.186547  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174897 (* 1 = 0.174897 loss)
I1022 19:40:40.186553  3845 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I1022 19:40:58.105244  3845 solver.cpp:218] Iteration 3700 (5.58078 iter/s, 17.9186s/100 iters), loss = 0.0181701
I1022 19:40:58.105279  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181709 (* 1 = 0.0181709 loss)
I1022 19:40:58.105288  3845 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I1022 19:41:06.915933  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:41:15.852763  3845 solver.cpp:330] Iteration 3800, Testing net (#0)
I1022 19:41:17.865211  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:41:18.166287  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.572266
I1022 19:41:18.166357  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.61578 (* 1 = 1.61578 loss)
I1022 19:41:18.346725  3845 solver.cpp:218] Iteration 3800 (4.94038 iter/s, 20.2414s/100 iters), loss = 0.391469
I1022 19:41:18.346757  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.391469 (* 1 = 0.391469 loss)
I1022 19:41:18.346765  3845 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I1022 19:41:36.273375  3845 solver.cpp:218] Iteration 3900 (5.57832 iter/s, 17.9266s/100 iters), loss = 0.0230841
I1022 19:41:36.273407  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0230845 (* 1 = 0.0230845 loss)
I1022 19:41:36.273414  3845 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I1022 19:41:54.019202  3845 solver.cpp:330] Iteration 4000, Testing net (#0)
I1022 19:41:56.030478  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:41:56.333345  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.841797
I1022 19:41:56.333405  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.833398 (* 1 = 0.833398 loss)
I1022 19:41:56.514116  3845 solver.cpp:218] Iteration 4000 (4.94055 iter/s, 20.2406s/100 iters), loss = 0.245344
I1022 19:41:56.514153  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245344 (* 1 = 0.245344 loss)
I1022 19:41:56.514159  3845 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I1022 19:42:12.670779  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:42:14.440253  3845 solver.cpp:218] Iteration 4100 (5.57848 iter/s, 17.926s/100 iters), loss = 0.455505
I1022 19:42:14.440294  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.455506 (* 1 = 0.455506 loss)
I1022 19:42:14.440302  3845 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I1022 19:42:32.187727  3845 solver.cpp:330] Iteration 4200, Testing net (#0)
I1022 19:42:34.198096  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:42:34.501417  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.908203
I1022 19:42:34.501477  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300702 (* 1 = 0.300702 loss)
I1022 19:42:34.682016  3845 solver.cpp:218] Iteration 4200 (4.94031 iter/s, 20.2417s/100 iters), loss = 0.0809878
I1022 19:42:34.682049  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0809879 (* 1 = 0.0809879 loss)
I1022 19:42:34.682055  3845 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I1022 19:42:52.596894  3845 solver.cpp:218] Iteration 4300 (5.58198 iter/s, 17.9148s/100 iters), loss = 0.524425
I1022 19:42:52.596926  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.524425 (* 1 = 0.524425 loss)
I1022 19:42:52.596933  3845 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I1022 19:43:10.336426  3845 solver.cpp:330] Iteration 4400, Testing net (#0)
I1022 19:43:12.346603  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:43:12.651134  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.933594
I1022 19:43:12.651195  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.218197 (* 1 = 0.218197 loss)
I1022 19:43:12.831926  3845 solver.cpp:218] Iteration 4400 (4.94195 iter/s, 20.2349s/100 iters), loss = 0.0174231
I1022 19:43:12.831964  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0174235 (* 1 = 0.0174235 loss)
I1022 19:43:12.831971  3845 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I1022 19:43:18.595909  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:43:30.761982  3845 solver.cpp:218] Iteration 4500 (5.57726 iter/s, 17.93s/100 iters), loss = 0.0524873
I1022 19:43:30.762014  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0524876 (* 1 = 0.0524876 loss)
I1022 19:43:30.762022  3845 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I1022 19:43:48.511927  3845 solver.cpp:330] Iteration 4600, Testing net (#0)
I1022 19:43:50.488071  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:43:50.826046  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.833984
I1022 19:43:50.826117  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.652193 (* 1 = 0.652193 loss)
I1022 19:43:51.007079  3845 solver.cpp:218] Iteration 4600 (4.93949 iter/s, 20.245s/100 iters), loss = 0.0171274
I1022 19:43:51.007112  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0171277 (* 1 = 0.0171277 loss)
I1022 19:43:51.007119  3845 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I1022 19:44:08.935539  3845 solver.cpp:218] Iteration 4700 (5.57775 iter/s, 17.9284s/100 iters), loss = 0.180392
I1022 19:44:08.935570  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180392 (* 1 = 0.180392 loss)
I1022 19:44:08.935576  3845 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I1022 19:44:22.045589  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:44:26.687721  3845 solver.cpp:330] Iteration 4800, Testing net (#0)
I1022 19:44:28.664310  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:44:29.001646  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.888672
I1022 19:44:29.001711  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.346734 (* 1 = 0.346734 loss)
I1022 19:44:29.181668  3845 solver.cpp:218] Iteration 4800 (4.93924 iter/s, 20.246s/100 iters), loss = 0.637071
I1022 19:44:29.181699  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.637071 (* 1 = 0.637071 loss)
I1022 19:44:29.181705  3845 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I1022 19:44:47.096197  3845 solver.cpp:218] Iteration 4900 (5.58209 iter/s, 17.9144s/100 iters), loss = 0.00923624
I1022 19:44:47.096228  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00923662 (* 1 = 0.00923662 loss)
I1022 19:44:47.096235  3845 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I1022 19:45:04.840436  3845 solver.cpp:330] Iteration 5000, Testing net (#0)
I1022 19:45:06.815557  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:45:07.154834  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.814453
I1022 19:45:07.154898  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.592 (* 1 = 0.592 loss)
I1022 19:45:07.335441  3845 solver.cpp:218] Iteration 5000 (4.94092 iter/s, 20.2391s/100 iters), loss = 0.0604222
I1022 19:45:07.335476  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0604226 (* 1 = 0.0604226 loss)
I1022 19:45:07.335484  3845 sgd_solver.cpp:105] Iteration 5000, lr = 0.01
I1022 19:45:25.259228  3845 solver.cpp:218] Iteration 5100 (5.57921 iter/s, 17.9237s/100 iters), loss = 0.0367625
I1022 19:45:25.259260  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0367629 (* 1 = 0.0367629 loss)
I1022 19:45:25.259268  3845 sgd_solver.cpp:105] Iteration 5100, lr = 0.01
I1022 19:45:27.795385  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:45:43.007879  3845 solver.cpp:330] Iteration 5200, Testing net (#0)
I1022 19:45:44.981508  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:45:45.322785  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.675781
I1022 19:45:45.322844  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.39138 (* 1 = 1.39138 loss)
I1022 19:45:45.504246  3845 solver.cpp:218] Iteration 5200 (4.93951 iter/s, 20.2449s/100 iters), loss = 0.328417
I1022 19:45:45.504282  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328417 (* 1 = 0.328417 loss)
I1022 19:45:45.504290  3845 sgd_solver.cpp:105] Iteration 5200, lr = 0.01
I1022 19:46:03.425343  3845 solver.cpp:218] Iteration 5300 (5.58004 iter/s, 17.921s/100 iters), loss = 0.279546
I1022 19:46:03.425374  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279546 (* 1 = 0.279546 loss)
I1022 19:46:03.425380  3845 sgd_solver.cpp:105] Iteration 5300, lr = 0.01
I1022 19:46:21.171481  3845 solver.cpp:330] Iteration 5400, Testing net (#0)
I1022 19:46:23.111306  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:46:23.484691  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.892578
I1022 19:46:23.484757  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.362318 (* 1 = 0.362318 loss)
I1022 19:46:23.665174  3845 solver.cpp:218] Iteration 5400 (4.94078 iter/s, 20.2397s/100 iters), loss = 0.0447293
I1022 19:46:23.665210  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0447295 (* 1 = 0.0447295 loss)
I1022 19:46:23.665218  3845 sgd_solver.cpp:105] Iteration 5400, lr = 0.01
I1022 19:46:33.545404  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:46:41.586457  3845 solver.cpp:218] Iteration 5500 (5.57998 iter/s, 17.9212s/100 iters), loss = 0.450359
I1022 19:46:41.586489  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.450359 (* 1 = 0.450359 loss)
I1022 19:46:41.586496  3845 sgd_solver.cpp:105] Iteration 5500, lr = 0.01
I1022 19:46:59.319252  3845 solver.cpp:330] Iteration 5600, Testing net (#0)
I1022 19:47:01.259477  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:47:01.635550  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.626953
I1022 19:47:01.635612  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.03841 (* 1 = 2.03841 loss)
I1022 19:47:01.815783  3845 solver.cpp:218] Iteration 5600 (4.94334 iter/s, 20.2292s/100 iters), loss = 0.0837993
I1022 19:47:01.815816  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0837995 (* 1 = 0.0837995 loss)
I1022 19:47:01.815824  3845 sgd_solver.cpp:105] Iteration 5600, lr = 0.01
I1022 19:47:19.741575  3845 solver.cpp:218] Iteration 5700 (5.57858 iter/s, 17.9257s/100 iters), loss = 0.00511122
I1022 19:47:19.741608  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00511127 (* 1 = 0.00511127 loss)
I1022 19:47:19.741616  3845 sgd_solver.cpp:105] Iteration 5700, lr = 0.01
I1022 19:47:37.155586  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:47:37.494550  3845 solver.cpp:330] Iteration 5800, Testing net (#0)
I1022 19:47:39.434646  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:47:39.810187  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.841797
I1022 19:47:39.810252  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.473135 (* 1 = 0.473135 loss)
I1022 19:47:39.990906  3845 solver.cpp:218] Iteration 5800 (4.93846 iter/s, 20.2492s/100 iters), loss = 0.0505685
I1022 19:47:39.990937  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0505686 (* 1 = 0.0505686 loss)
I1022 19:47:39.990945  3845 sgd_solver.cpp:105] Iteration 5800, lr = 0.01
I1022 19:47:57.913569  3845 solver.cpp:218] Iteration 5900 (5.57956 iter/s, 17.9226s/100 iters), loss = 0.410314
I1022 19:47:57.913602  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.410314 (* 1 = 0.410314 loss)
I1022 19:47:57.913609  3845 sgd_solver.cpp:105] Iteration 5900, lr = 0.01
I1022 19:48:15.663053  3845 solver.cpp:330] Iteration 6000, Testing net (#0)
I1022 19:48:17.600464  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:48:17.977192  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.835938
I1022 19:48:17.977252  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.388021 (* 1 = 0.388021 loss)
I1022 19:48:18.158067  3845 solver.cpp:218] Iteration 6000 (4.93964 iter/s, 20.2444s/100 iters), loss = 0.29231
I1022 19:48:18.158099  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29231 (* 1 = 0.29231 loss)
I1022 19:48:18.158107  3845 sgd_solver.cpp:105] Iteration 6000, lr = 0.01
I1022 19:48:36.077929  3845 solver.cpp:218] Iteration 6100 (5.58043 iter/s, 17.9198s/100 iters), loss = 0.15592
I1022 19:48:36.077961  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15592 (* 1 = 0.15592 loss)
I1022 19:48:36.077968  3845 sgd_solver.cpp:105] Iteration 6100, lr = 0.01
I1022 19:48:42.914121  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:48:53.823977  3845 solver.cpp:330] Iteration 6200, Testing net (#0)
I1022 19:48:55.728391  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:48:56.138280  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.884766
I1022 19:48:56.138337  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34673 (* 1 = 0.34673 loss)
I1022 19:48:56.318876  3845 solver.cpp:218] Iteration 6200 (4.9405 iter/s, 20.2409s/100 iters), loss = 0.0357163
I1022 19:48:56.318910  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0357163 (* 1 = 0.0357163 loss)
I1022 19:48:56.318918  3845 sgd_solver.cpp:105] Iteration 6200, lr = 0.01
I1022 19:49:14.267496  3845 solver.cpp:218] Iteration 6300 (5.57149 iter/s, 17.9485s/100 iters), loss = 0.0719772
I1022 19:49:14.267530  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0719773 (* 1 = 0.0719773 loss)
I1022 19:49:14.267539  3845 sgd_solver.cpp:105] Iteration 6300, lr = 0.01
I1022 19:49:32.038002  3845 solver.cpp:330] Iteration 6400, Testing net (#0)
I1022 19:49:33.942281  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:49:34.352782  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.941406
I1022 19:49:34.352831  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.21309 (* 1 = 0.21309 loss)
I1022 19:49:34.533475  3845 solver.cpp:218] Iteration 6400 (4.9344 iter/s, 20.2659s/100 iters), loss = 0.0105145
I1022 19:49:34.533507  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105146 (* 1 = 0.0105146 loss)
I1022 19:49:34.533515  3845 sgd_solver.cpp:105] Iteration 6400, lr = 0.01
I1022 19:49:48.736369  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:49:52.484414  3845 solver.cpp:218] Iteration 6500 (5.57077 iter/s, 17.9508s/100 iters), loss = 0.0285312
I1022 19:49:52.484447  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0285314 (* 1 = 0.0285314 loss)
I1022 19:49:52.484453  3845 sgd_solver.cpp:105] Iteration 6500, lr = 0.01
I1022 19:50:10.252161  3845 solver.cpp:330] Iteration 6600, Testing net (#0)
I1022 19:50:12.153827  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:50:12.564869  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.730469
I1022 19:50:12.564930  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.49933 (* 1 = 1.49933 loss)
I1022 19:50:12.745564  3845 solver.cpp:218] Iteration 6600 (4.93558 iter/s, 20.2611s/100 iters), loss = 0.0460803
I1022 19:50:12.745597  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0460806 (* 1 = 0.0460806 loss)
I1022 19:50:12.745605  3845 sgd_solver.cpp:105] Iteration 6600, lr = 0.01
I1022 19:50:30.683748  3845 solver.cpp:218] Iteration 6700 (5.57473 iter/s, 17.9381s/100 iters), loss = 0.0634246
I1022 19:50:30.683790  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0634249 (* 1 = 0.0634249 loss)
I1022 19:50:30.683797  3845 sgd_solver.cpp:105] Iteration 6700, lr = 0.01
I1022 19:50:48.443377  3845 solver.cpp:330] Iteration 6800, Testing net (#0)
I1022 19:50:50.344938  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:50:50.758232  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.947266
I1022 19:50:50.758297  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.172882 (* 1 = 0.172882 loss)
I1022 19:50:50.939472  3845 solver.cpp:218] Iteration 6800 (4.9369 iter/s, 20.2556s/100 iters), loss = 0.0237734
I1022 19:50:50.939504  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0237738 (* 1 = 0.0237738 loss)
I1022 19:50:50.939512  3845 sgd_solver.cpp:105] Iteration 6800, lr = 0.01
I1022 19:50:54.557307  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:51:08.891876  3845 solver.cpp:218] Iteration 6900 (5.57031 iter/s, 17.9523s/100 iters), loss = 0.238287
I1022 19:51:08.891917  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238288 (* 1 = 0.238288 loss)
I1022 19:51:08.891924  3845 sgd_solver.cpp:105] Iteration 6900, lr = 0.01
I1022 19:51:26.664409  3845 solver.cpp:330] Iteration 7000, Testing net (#0)
I1022 19:51:28.532148  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:51:28.979137  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.888672
I1022 19:51:28.979199  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.353387 (* 1 = 0.353387 loss)
I1022 19:51:29.160657  3845 solver.cpp:218] Iteration 7000 (4.93372 iter/s, 20.2687s/100 iters), loss = 0.104975
I1022 19:51:29.160691  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.104975 (* 1 = 0.104975 loss)
I1022 19:51:29.160699  3845 sgd_solver.cpp:105] Iteration 7000, lr = 0.01
I1022 19:51:47.107301  3845 solver.cpp:218] Iteration 7100 (5.5721 iter/s, 17.9466s/100 iters), loss = 0.0296875
I1022 19:51:47.107332  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0296878 (* 1 = 0.0296878 loss)
I1022 19:51:47.107339  3845 sgd_solver.cpp:105] Iteration 7100, lr = 0.01
I1022 19:51:58.262389  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:52:04.887255  3845 solver.cpp:330] Iteration 7200, Testing net (#0)
I1022 19:52:06.755240  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:52:07.202061  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.691406
I1022 19:52:07.202127  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.13093 (* 1 = 1.13093 loss)
I1022 19:52:07.382932  3845 solver.cpp:218] Iteration 7200 (4.93205 iter/s, 20.2755s/100 iters), loss = 0.211123
I1022 19:52:07.382968  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211123 (* 1 = 0.211123 loss)
I1022 19:52:07.382977  3845 sgd_solver.cpp:105] Iteration 7200, lr = 0.01
I1022 19:52:25.319176  3845 solver.cpp:218] Iteration 7300 (5.57533 iter/s, 17.9362s/100 iters), loss = 0.0230108
I1022 19:52:25.319209  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.023011 (* 1 = 0.023011 loss)
I1022 19:52:25.319217  3845 sgd_solver.cpp:105] Iteration 7300, lr = 0.01
I1022 19:52:43.082687  3845 solver.cpp:330] Iteration 7400, Testing net (#0)
I1022 19:52:44.949568  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:52:45.397819  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.892578
I1022 19:52:45.397886  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.282007 (* 1 = 0.282007 loss)
I1022 19:52:45.578543  3845 solver.cpp:218] Iteration 7400 (4.93601 iter/s, 20.2593s/100 iters), loss = 0.0261036
I1022 19:52:45.578577  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0261038 (* 1 = 0.0261038 loss)
I1022 19:52:45.578584  3845 sgd_solver.cpp:105] Iteration 7400, lr = 0.01
I1022 19:53:03.525394  3845 solver.cpp:218] Iteration 7500 (5.57203 iter/s, 17.9468s/100 iters), loss = 0.583566
I1022 19:53:03.525426  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.583567 (* 1 = 0.583567 loss)
I1022 19:53:03.525434  3845 sgd_solver.cpp:105] Iteration 7500, lr = 0.01
I1022 19:53:04.088517  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:53:21.298038  3845 solver.cpp:330] Iteration 7600, Testing net (#0)
I1022 19:53:23.163290  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:53:23.612936  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.929688
I1022 19:53:23.612996  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.208941 (* 1 = 0.208941 loss)
I1022 19:53:23.793933  3845 solver.cpp:218] Iteration 7600 (4.93378 iter/s, 20.2684s/100 iters), loss = 0.0372695
I1022 19:53:23.793965  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0372697 (* 1 = 0.0372697 loss)
I1022 19:53:23.793973  3845 sgd_solver.cpp:105] Iteration 7600, lr = 0.01
I1022 19:53:41.739722  3845 solver.cpp:218] Iteration 7700 (5.57236 iter/s, 17.9457s/100 iters), loss = 0.0215588
I1022 19:53:41.739754  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0215589 (* 1 = 0.0215589 loss)
I1022 19:53:41.739761  3845 sgd_solver.cpp:105] Iteration 7700, lr = 0.01
I1022 19:53:59.507220  3845 solver.cpp:330] Iteration 7800, Testing net (#0)
I1022 19:54:01.339474  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:54:01.823055  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.837891
I1022 19:54:01.823123  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.508007 (* 1 = 0.508007 loss)
I1022 19:54:02.004294  3845 solver.cpp:218] Iteration 7800 (4.93474 iter/s, 20.2645s/100 iters), loss = 0.0505049
I1022 19:54:02.004328  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0505051 (* 1 = 0.0505051 loss)
I1022 19:54:02.004336  3845 sgd_solver.cpp:105] Iteration 7800, lr = 0.01
I1022 19:54:09.925590  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:54:19.944856  3845 solver.cpp:218] Iteration 7900 (5.57399 iter/s, 17.9405s/100 iters), loss = 0.10701
I1022 19:54:19.944887  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10701 (* 1 = 0.10701 loss)
I1022 19:54:19.944895  3845 sgd_solver.cpp:105] Iteration 7900, lr = 0.01
I1022 19:54:37.706008  3845 solver.cpp:330] Iteration 8000, Testing net (#0)
I1022 19:54:39.537964  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:54:40.021438  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.847656
I1022 19:54:40.021503  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.649136 (* 1 = 0.649136 loss)
I1022 19:54:40.202493  3845 solver.cpp:218] Iteration 8000 (4.93643 iter/s, 20.2575s/100 iters), loss = 0.0992579
I1022 19:54:40.202527  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.099258 (* 1 = 0.099258 loss)
I1022 19:54:40.202534  3845 sgd_solver.cpp:105] Iteration 8000, lr = 0.01
I1022 19:54:58.148372  3845 solver.cpp:218] Iteration 8100 (5.57234 iter/s, 17.9458s/100 iters), loss = 0.0495364
I1022 19:54:58.148406  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0495365 (* 1 = 0.0495365 loss)
I1022 19:54:58.148412  3845 sgd_solver.cpp:105] Iteration 8100, lr = 0.01
I1022 19:55:13.433238  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:55:15.923868  3845 solver.cpp:330] Iteration 8200, Testing net (#0)
I1022 19:55:17.754752  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:55:18.238585  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.847656
I1022 19:55:18.238638  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.563434 (* 1 = 0.563434 loss)
I1022 19:55:18.419484  3845 solver.cpp:218] Iteration 8200 (4.93315 iter/s, 20.271s/100 iters), loss = 0.352173
I1022 19:55:18.419515  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.352173 (* 1 = 0.352173 loss)
I1022 19:55:18.419523  3845 sgd_solver.cpp:105] Iteration 8200, lr = 0.01
I1022 19:55:36.363348  3845 solver.cpp:218] Iteration 8300 (5.57296 iter/s, 17.9438s/100 iters), loss = 0.0796378
I1022 19:55:36.363379  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0796376 (* 1 = 0.0796376 loss)
I1022 19:55:36.363386  3845 sgd_solver.cpp:105] Iteration 8300, lr = 0.01
I1022 19:55:54.133692  3845 solver.cpp:330] Iteration 8400, Testing net (#0)
I1022 19:55:55.963706  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:55:56.449064  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.955078
I1022 19:55:56.449129  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.118104 (* 1 = 0.118104 loss)
I1022 19:55:56.630265  3845 solver.cpp:218] Iteration 8400 (4.93417 iter/s, 20.2668s/100 iters), loss = 0.298809
I1022 19:55:56.630297  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298809 (* 1 = 0.298809 loss)
I1022 19:55:56.630304  3845 sgd_solver.cpp:105] Iteration 8400, lr = 0.01
I1022 19:56:14.570636  3845 solver.cpp:218] Iteration 8500 (5.57405 iter/s, 17.9403s/100 iters), loss = 0.0233542
I1022 19:56:14.570665  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0233541 (* 1 = 0.0233541 loss)
I1022 19:56:14.570672  3845 sgd_solver.cpp:105] Iteration 8500, lr = 0.01
I1022 19:56:19.440084  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:56:32.336190  3845 solver.cpp:330] Iteration 8600, Testing net (#0)
I1022 19:56:34.132021  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:56:34.650234  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.955078
I1022 19:56:34.650300  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.126955 (* 1 = 0.126955 loss)
I1022 19:56:34.831205  3845 solver.cpp:218] Iteration 8600 (4.93572 iter/s, 20.2605s/100 iters), loss = 0.0591304
I1022 19:56:34.831238  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0591303 (* 1 = 0.0591303 loss)
I1022 19:56:34.831246  3845 sgd_solver.cpp:105] Iteration 8600, lr = 0.01
I1022 19:56:52.777099  3845 solver.cpp:218] Iteration 8700 (5.57233 iter/s, 17.9458s/100 iters), loss = 0.0910694
I1022 19:56:52.777132  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0910694 (* 1 = 0.0910694 loss)
I1022 19:56:52.777138  3845 sgd_solver.cpp:105] Iteration 8700, lr = 0.01
I1022 19:57:10.548387  3845 solver.cpp:330] Iteration 8800, Testing net (#0)
I1022 19:57:12.343928  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:57:12.863867  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.90625
I1022 19:57:12.863931  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.278996 (* 1 = 0.278996 loss)
I1022 19:57:13.044925  3845 solver.cpp:218] Iteration 8800 (4.93395 iter/s, 20.2677s/100 iters), loss = 0.0410595
I1022 19:57:13.044958  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0410594 (* 1 = 0.0410594 loss)
I1022 19:57:13.044966  3845 sgd_solver.cpp:105] Iteration 8800, lr = 0.01
I1022 19:57:25.272892  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:57:30.996958  3845 solver.cpp:218] Iteration 8900 (5.57043 iter/s, 17.952s/100 iters), loss = 0.146193
I1022 19:57:30.996990  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146193 (* 1 = 0.146193 loss)
I1022 19:57:30.996997  3845 sgd_solver.cpp:105] Iteration 8900, lr = 0.01
I1022 19:57:48.760176  3845 solver.cpp:330] Iteration 9000, Testing net (#0)
I1022 19:57:50.554729  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:57:51.074568  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.908203
I1022 19:57:51.074637  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.299751 (* 1 = 0.299751 loss)
I1022 19:57:51.255461  3845 solver.cpp:218] Iteration 9000 (4.93622 iter/s, 20.2584s/100 iters), loss = 0.0156957
I1022 19:57:51.255498  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156956 (* 1 = 0.0156956 loss)
I1022 19:57:51.255506  3845 sgd_solver.cpp:105] Iteration 9000, lr = 0.01
I1022 19:58:09.195060  3845 solver.cpp:218] Iteration 9100 (5.57429 iter/s, 17.9395s/100 iters), loss = 0.0929066
I1022 19:58:09.195092  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0929064 (* 1 = 0.0929064 loss)
I1022 19:58:09.195098  3845 sgd_solver.cpp:105] Iteration 9100, lr = 0.01
I1022 19:58:26.954345  3845 solver.cpp:330] Iteration 9200, Testing net (#0)
I1022 19:58:28.748366  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:58:29.269894  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.919922
I1022 19:58:29.269955  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.200046 (* 1 = 0.200046 loss)
I1022 19:58:29.450768  3845 solver.cpp:218] Iteration 9200 (4.9369 iter/s, 20.2556s/100 iters), loss = 0.0422896
I1022 19:58:29.450800  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0422895 (* 1 = 0.0422895 loss)
I1022 19:58:29.450808  3845 sgd_solver.cpp:105] Iteration 9200, lr = 0.01
I1022 19:58:31.091913  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:58:47.401073  3845 solver.cpp:218] Iteration 9300 (5.57096 iter/s, 17.9502s/100 iters), loss = 0.169022
I1022 19:58:47.401105  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169021 (* 1 = 0.169021 loss)
I1022 19:58:47.401113  3845 sgd_solver.cpp:105] Iteration 9300, lr = 0.01
I1022 19:59:05.175420  3845 solver.cpp:330] Iteration 9400, Testing net (#0)
I1022 19:59:06.934569  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:59:07.490274  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.929688
I1022 19:59:07.490334  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.205753 (* 1 = 0.205753 loss)
I1022 19:59:07.671376  3845 solver.cpp:218] Iteration 9400 (4.93335 iter/s, 20.2702s/100 iters), loss = 0.00601895
I1022 19:59:07.671408  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00601861 (* 1 = 0.00601861 loss)
I1022 19:59:07.671416  3845 sgd_solver.cpp:105] Iteration 9400, lr = 0.01
I1022 19:59:25.618451  3845 solver.cpp:218] Iteration 9500 (5.57196 iter/s, 17.947s/100 iters), loss = 0.00428543
I1022 19:59:25.618482  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00428507 (* 1 = 0.00428507 loss)
I1022 19:59:25.618490  3845 sgd_solver.cpp:105] Iteration 9500, lr = 0.01
I1022 19:59:34.622901  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:59:43.390122  3845 solver.cpp:330] Iteration 9600, Testing net (#0)
I1022 19:59:45.149864  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 19:59:45.705431  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.929688
I1022 19:59:45.705492  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.185565 (* 1 = 0.185565 loss)
I1022 19:59:45.886314  3845 solver.cpp:218] Iteration 9600 (4.93394 iter/s, 20.2678s/100 iters), loss = 0.00196607
I1022 19:59:45.886348  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00196567 (* 1 = 0.00196567 loss)
I1022 19:59:45.886354  3845 sgd_solver.cpp:105] Iteration 9600, lr = 0.01
I1022 20:00:03.829394  3845 solver.cpp:218] Iteration 9700 (5.5732 iter/s, 17.943s/100 iters), loss = 0.0109106
I1022 20:00:03.829427  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109103 (* 1 = 0.0109103 loss)
I1022 20:00:03.829433  3845 sgd_solver.cpp:105] Iteration 9700, lr = 0.01
I1022 20:00:21.595502  3845 solver.cpp:330] Iteration 9800, Testing net (#0)
I1022 20:00:23.353765  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:00:23.910732  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.955078
I1022 20:00:23.910794  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.110205 (* 1 = 0.110205 loss)
I1022 20:00:24.091357  3845 solver.cpp:218] Iteration 9800 (4.93538 iter/s, 20.2619s/100 iters), loss = 0.0716027
I1022 20:00:24.091389  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0716024 (* 1 = 0.0716024 loss)
I1022 20:00:24.091398  3845 sgd_solver.cpp:105] Iteration 9800, lr = 0.01
I1022 20:00:40.625134  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:00:42.041043  3845 solver.cpp:218] Iteration 9900 (5.57115 iter/s, 17.9496s/100 iters), loss = 0.00460945
I1022 20:00:42.041076  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00460906 (* 1 = 0.00460906 loss)
I1022 20:00:42.041085  3845 sgd_solver.cpp:105] Iteration 9900, lr = 0.01
I1022 20:00:59.809062  3845 solver.cpp:330] Iteration 10000, Testing net (#0)
I1022 20:01:01.568591  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:01:02.126343  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.900391
I1022 20:01:02.126410  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.27818 (* 1 = 0.27818 loss)
I1022 20:01:02.307530  3845 solver.cpp:218] Iteration 10000 (4.93428 iter/s, 20.2664s/100 iters), loss = 0.0682491
I1022 20:01:02.307564  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0682487 (* 1 = 0.0682487 loss)
I1022 20:01:02.307570  3845 sgd_solver.cpp:46] MultiStep Status: Iteration 10000, step = 1
I1022 20:01:02.307574  3845 sgd_solver.cpp:105] Iteration 10000, lr = 0.001
I1022 20:01:20.252053  3845 solver.cpp:218] Iteration 10100 (5.57276 iter/s, 17.9444s/100 iters), loss = 0.0159395
I1022 20:01:20.252087  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015939 (* 1 = 0.015939 loss)
I1022 20:01:20.252094  3845 sgd_solver.cpp:105] Iteration 10100, lr = 0.001
I1022 20:01:38.020131  3845 solver.cpp:330] Iteration 10200, Testing net (#0)
I1022 20:01:39.743672  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:01:40.334251  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.947266
I1022 20:01:40.334311  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.132284 (* 1 = 0.132284 loss)
I1022 20:01:40.515089  3845 solver.cpp:218] Iteration 10200 (4.93512 iter/s, 20.2629s/100 iters), loss = 0.0129267
I1022 20:01:40.515122  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0129262 (* 1 = 0.0129262 loss)
I1022 20:01:40.515130  3845 sgd_solver.cpp:105] Iteration 10200, lr = 0.001
I1022 20:01:46.462106  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:01:58.456984  3845 solver.cpp:218] Iteration 10300 (5.57357 iter/s, 17.9418s/100 iters), loss = 0.00535708
I1022 20:01:58.457017  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0053566 (* 1 = 0.0053566 loss)
I1022 20:01:58.457024  3845 sgd_solver.cpp:105] Iteration 10300, lr = 0.001
I1022 20:02:16.218155  3845 solver.cpp:330] Iteration 10400, Testing net (#0)
I1022 20:02:17.940800  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:02:18.533113  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1022 20:02:18.533161  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0883568 (* 1 = 0.0883568 loss)
I1022 20:02:18.714174  3845 solver.cpp:218] Iteration 10400 (4.93654 iter/s, 20.2571s/100 iters), loss = 0.00725982
I1022 20:02:18.714205  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00725936 (* 1 = 0.00725936 loss)
I1022 20:02:18.714213  3845 sgd_solver.cpp:105] Iteration 10400, lr = 0.001
I1022 20:02:36.662806  3845 solver.cpp:218] Iteration 10500 (5.57148 iter/s, 17.9486s/100 iters), loss = 0.00793289
I1022 20:02:36.662837  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00793242 (* 1 = 0.00793242 loss)
I1022 20:02:36.662844  3845 sgd_solver.cpp:105] Iteration 10500, lr = 0.001
I1022 20:02:49.974234  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:02:54.441978  3845 solver.cpp:330] Iteration 10600, Testing net (#0)
I1022 20:02:56.164430  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:02:56.757572  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.962891
I1022 20:02:56.757637  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.092513 (* 1 = 0.092513 loss)
I1022 20:02:56.938127  3845 solver.cpp:218] Iteration 10600 (4.93212 iter/s, 20.2752s/100 iters), loss = 0.0225336
I1022 20:02:56.938161  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0225331 (* 1 = 0.0225331 loss)
I1022 20:02:56.938169  3845 sgd_solver.cpp:105] Iteration 10600, lr = 0.001
I1022 20:03:14.883106  3845 solver.cpp:218] Iteration 10700 (5.57262 iter/s, 17.9449s/100 iters), loss = 0.00222903
I1022 20:03:14.883138  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00222865 (* 1 = 0.00222865 loss)
I1022 20:03:14.883146  3845 sgd_solver.cpp:105] Iteration 10700, lr = 0.001
I1022 20:03:32.656260  3845 solver.cpp:330] Iteration 10800, Testing net (#0)
I1022 20:03:34.377912  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:03:34.971554  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1022 20:03:34.971606  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0857562 (* 1 = 0.0857562 loss)
I1022 20:03:35.152410  3845 solver.cpp:218] Iteration 10800 (4.93359 iter/s, 20.2692s/100 iters), loss = 0.00123412
I1022 20:03:35.152448  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00123374 (* 1 = 0.00123374 loss)
I1022 20:03:35.152456  3845 sgd_solver.cpp:105] Iteration 10800, lr = 0.001
I1022 20:03:53.092192  3845 solver.cpp:218] Iteration 10900 (5.57423 iter/s, 17.9397s/100 iters), loss = 0.00416059
I1022 20:03:53.092226  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00416025 (* 1 = 0.00416025 loss)
I1022 20:03:53.092232  3845 sgd_solver.cpp:105] Iteration 10900, lr = 0.001
I1022 20:03:55.811031  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:04:10.858381  3845 solver.cpp:330] Iteration 11000, Testing net (#0)
I1022 20:04:12.546761  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:04:13.173101  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.958984
I1022 20:04:13.173158  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0859782 (* 1 = 0.0859782 loss)
I1022 20:04:13.353961  3845 solver.cpp:218] Iteration 11000 (4.93543 iter/s, 20.2617s/100 iters), loss = 0.189575
I1022 20:04:13.353993  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189574 (* 1 = 0.189574 loss)
I1022 20:04:13.354001  3845 sgd_solver.cpp:105] Iteration 11000, lr = 0.001
I1022 20:04:31.300618  3845 solver.cpp:218] Iteration 11100 (5.57209 iter/s, 17.9466s/100 iters), loss = 0.0281335
I1022 20:04:31.300652  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0281332 (* 1 = 0.0281332 loss)
I1022 20:04:31.300658  3845 sgd_solver.cpp:105] Iteration 11100, lr = 0.001
I1022 20:04:49.070266  3845 solver.cpp:330] Iteration 11200, Testing net (#0)
I1022 20:04:50.757468  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:04:51.385527  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.980469
I1022 20:04:51.385594  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0578427 (* 1 = 0.0578427 loss)
I1022 20:04:51.566493  3845 solver.cpp:218] Iteration 11200 (4.93442 iter/s, 20.2658s/100 iters), loss = 0.00302151
I1022 20:04:51.566524  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00302125 (* 1 = 0.00302125 loss)
I1022 20:04:51.566531  3845 sgd_solver.cpp:105] Iteration 11200, lr = 0.001
I1022 20:05:01.822113  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:05:09.520969  3845 solver.cpp:218] Iteration 11300 (5.56967 iter/s, 17.9544s/100 iters), loss = 0.0338538
I1022 20:05:09.521001  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0338535 (* 1 = 0.0338535 loss)
I1022 20:05:09.521008  3845 sgd_solver.cpp:105] Iteration 11300, lr = 0.001
I1022 20:05:27.282411  3845 solver.cpp:330] Iteration 11400, Testing net (#0)
I1022 20:05:28.969130  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:05:29.597833  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.980469
I1022 20:05:29.597894  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0679394 (* 1 = 0.0679394 loss)
I1022 20:05:29.778517  3845 solver.cpp:218] Iteration 11400 (4.93645 iter/s, 20.2575s/100 iters), loss = 0.0227651
I1022 20:05:29.778550  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227649 (* 1 = 0.0227649 loss)
I1022 20:05:29.778558  3845 sgd_solver.cpp:105] Iteration 11400, lr = 0.001
I1022 20:05:47.715222  3845 solver.cpp:218] Iteration 11500 (5.57519 iter/s, 17.9366s/100 iters), loss = 0.0139933
I1022 20:05:47.715255  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139931 (* 1 = 0.0139931 loss)
I1022 20:05:47.715261  3845 sgd_solver.cpp:105] Iteration 11500, lr = 0.001
I1022 20:06:05.318711  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:06:05.477782  3845 solver.cpp:330] Iteration 11600, Testing net (#0)
I1022 20:06:07.162802  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:06:07.793076  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1022 20:06:07.793134  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0807841 (* 1 = 0.0807841 loss)
I1022 20:06:07.973590  3845 solver.cpp:218] Iteration 11600 (4.93625 iter/s, 20.2583s/100 iters), loss = 0.0218393
I1022 20:06:07.973621  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0218391 (* 1 = 0.0218391 loss)
I1022 20:06:07.973628  3845 sgd_solver.cpp:105] Iteration 11600, lr = 0.001
I1022 20:06:25.919993  3845 solver.cpp:218] Iteration 11700 (5.57217 iter/s, 17.9463s/100 iters), loss = 0.00563095
I1022 20:06:25.920027  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00563072 (* 1 = 0.00563072 loss)
I1022 20:06:25.920033  3845 sgd_solver.cpp:105] Iteration 11700, lr = 0.001
I1022 20:06:43.695207  3845 solver.cpp:330] Iteration 11800, Testing net (#0)
I1022 20:06:45.346349  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:06:46.010468  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.984375
I1022 20:06:46.010529  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0590734 (* 1 = 0.0590734 loss)
I1022 20:06:46.191902  3845 solver.cpp:218] Iteration 11800 (4.93296 iter/s, 20.2718s/100 iters), loss = 0.00628309
I1022 20:06:46.191936  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00628285 (* 1 = 0.00628285 loss)
I1022 20:06:46.191944  3845 sgd_solver.cpp:105] Iteration 11800, lr = 0.001
I1022 20:07:04.140547  3845 solver.cpp:218] Iteration 11900 (5.57148 iter/s, 17.9486s/100 iters), loss = 0.0244877
I1022 20:07:04.140578  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0244875 (* 1 = 0.0244875 loss)
I1022 20:07:04.140584  3845 sgd_solver.cpp:105] Iteration 11900, lr = 0.001
I1022 20:07:11.167075  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:07:21.912295  3845 solver.cpp:330] Iteration 12000, Testing net (#0)
I1022 20:07:23.563199  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:07:24.226900  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.964844
I1022 20:07:24.226966  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0745881 (* 1 = 0.0745881 loss)
I1022 20:07:24.407817  3845 solver.cpp:218] Iteration 12000 (4.93408 iter/s, 20.2672s/100 iters), loss = 0.0114271
I1022 20:07:24.407853  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114269 (* 1 = 0.0114269 loss)
I1022 20:07:24.407860  3845 sgd_solver.cpp:105] Iteration 12000, lr = 0.001
I1022 20:07:42.350363  3845 solver.cpp:218] Iteration 12100 (5.57337 iter/s, 17.9425s/100 iters), loss = 0.0096851
I1022 20:07:42.350394  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00968491 (* 1 = 0.00968491 loss)
I1022 20:07:42.350400  3845 sgd_solver.cpp:105] Iteration 12100, lr = 0.001
I1022 20:08:00.116966  3845 solver.cpp:330] Iteration 12200, Testing net (#0)
I1022 20:08:01.769057  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:08:02.433454  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.976562
I1022 20:08:02.433516  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0653058 (* 1 = 0.0653058 loss)
I1022 20:08:02.614408  3845 solver.cpp:218] Iteration 12200 (4.93487 iter/s, 20.264s/100 iters), loss = 0.00893452
I1022 20:08:02.614441  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00893434 (* 1 = 0.00893434 loss)
I1022 20:08:02.614449  3845 sgd_solver.cpp:105] Iteration 12200, lr = 0.001
I1022 20:08:16.998500  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:08:20.565538  3845 solver.cpp:218] Iteration 12300 (5.57071 iter/s, 17.951s/100 iters), loss = 0.013463
I1022 20:08:20.565572  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134628 (* 1 = 0.0134628 loss)
I1022 20:08:20.565577  3845 sgd_solver.cpp:105] Iteration 12300, lr = 0.001
I1022 20:08:38.332309  3845 solver.cpp:330] Iteration 12400, Testing net (#0)
I1022 20:08:39.981427  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:08:40.647061  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.980469
I1022 20:08:40.647126  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0569333 (* 1 = 0.0569333 loss)
I1022 20:08:40.828222  3845 solver.cpp:218] Iteration 12400 (4.9352 iter/s, 20.2626s/100 iters), loss = 0.00101541
I1022 20:08:40.828255  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00101521 (* 1 = 0.00101521 loss)
I1022 20:08:40.828263  3845 sgd_solver.cpp:105] Iteration 12400, lr = 0.001
I1022 20:08:58.770742  3845 solver.cpp:218] Iteration 12500 (5.57338 iter/s, 17.9424s/100 iters), loss = 0.0206634
I1022 20:08:58.770773  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0206632 (* 1 = 0.0206632 loss)
I1022 20:08:58.770779  3845 sgd_solver.cpp:105] Iteration 12500, lr = 0.001
I1022 20:09:16.540339  3845 solver.cpp:330] Iteration 12600, Testing net (#0)
I1022 20:09:18.154765  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:09:18.854717  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.982422
I1022 20:09:18.854775  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0510014 (* 1 = 0.0510014 loss)
I1022 20:09:19.035346  3845 solver.cpp:218] Iteration 12600 (4.93473 iter/s, 20.2645s/100 iters), loss = 0.360619
I1022 20:09:19.035380  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.360618 (* 1 = 0.360618 loss)
I1022 20:09:19.035387  3845 sgd_solver.cpp:105] Iteration 12600, lr = 0.001
I1022 20:09:23.006990  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:09:36.973940  3845 solver.cpp:218] Iteration 12700 (5.5746 iter/s, 17.9385s/100 iters), loss = 0.000494003
I1022 20:09:36.973971  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000493863 (* 1 = 0.000493863 loss)
I1022 20:09:36.973978  3845 sgd_solver.cpp:105] Iteration 12700, lr = 0.001
I1022 20:09:54.736956  3845 solver.cpp:330] Iteration 12800, Testing net (#0)
I1022 20:09:56.352684  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:09:57.052718  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.982422
I1022 20:09:57.052779  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0510098 (* 1 = 0.0510098 loss)
I1022 20:09:57.233867  3845 solver.cpp:218] Iteration 12800 (4.93587 iter/s, 20.2598s/100 iters), loss = 0.019342
I1022 20:09:57.233901  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0193418 (* 1 = 0.0193418 loss)
I1022 20:09:57.233909  3845 sgd_solver.cpp:105] Iteration 12800, lr = 0.001
I1022 20:10:15.182157  3845 solver.cpp:218] Iteration 12900 (5.57159 iter/s, 17.9482s/100 iters), loss = 0.0059524
I1022 20:10:15.182188  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00595222 (* 1 = 0.00595222 loss)
I1022 20:10:15.182195  3845 sgd_solver.cpp:105] Iteration 12900, lr = 0.001
I1022 20:10:26.517438  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:10:32.960700  3845 solver.cpp:330] Iteration 13000, Testing net (#0)
I1022 20:10:34.576666  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:10:35.277993  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1022 20:10:35.278059  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0684443 (* 1 = 0.0684443 loss)
I1022 20:10:35.458406  3845 solver.cpp:218] Iteration 13000 (4.9319 iter/s, 20.2762s/100 iters), loss = 0.00243333
I1022 20:10:35.458436  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00243314 (* 1 = 0.00243314 loss)
I1022 20:10:35.458442  3845 sgd_solver.cpp:105] Iteration 13000, lr = 0.001
I1022 20:10:53.399106  3845 solver.cpp:218] Iteration 13100 (5.57394 iter/s, 17.9406s/100 iters), loss = 0.00222097
I1022 20:10:53.399137  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00222077 (* 1 = 0.00222077 loss)
I1022 20:10:53.399144  3845 sgd_solver.cpp:105] Iteration 13100, lr = 0.001
I1022 20:11:11.171058  3845 solver.cpp:330] Iteration 13200, Testing net (#0)
I1022 20:11:12.783794  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:11:13.486091  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1022 20:11:13.486156  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0594133 (* 1 = 0.0594133 loss)
I1022 20:11:13.666963  3845 solver.cpp:218] Iteration 13200 (4.93394 iter/s, 20.2678s/100 iters), loss = 0.00707319
I1022 20:11:13.666996  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00707303 (* 1 = 0.00707303 loss)
I1022 20:11:13.667003  3845 sgd_solver.cpp:105] Iteration 13200, lr = 0.001
I1022 20:11:31.608770  3845 solver.cpp:218] Iteration 13300 (5.5736 iter/s, 17.9417s/100 iters), loss = 0.00152
I1022 20:11:31.608801  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00151979 (* 1 = 0.00151979 loss)
I1022 20:11:31.608808  3845 sgd_solver.cpp:105] Iteration 13300, lr = 0.001
I1022 20:11:32.352512  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:11:49.377001  3845 solver.cpp:330] Iteration 13400, Testing net (#0)
I1022 20:11:50.956321  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:11:51.691673  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1022 20:11:51.691740  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0707325 (* 1 = 0.0707325 loss)
I1022 20:11:51.872656  3845 solver.cpp:218] Iteration 13400 (4.93491 iter/s, 20.2638s/100 iters), loss = 0.00642703
I1022 20:11:51.872689  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00642676 (* 1 = 0.00642676 loss)
I1022 20:11:51.872696  3845 sgd_solver.cpp:105] Iteration 13400, lr = 0.001
I1022 20:12:09.819962  3845 solver.cpp:218] Iteration 13500 (5.57189 iter/s, 17.9472s/100 iters), loss = 0.0211653
I1022 20:12:09.819993  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.021165 (* 1 = 0.021165 loss)
I1022 20:12:09.819999  3845 sgd_solver.cpp:105] Iteration 13500, lr = 0.001
I1022 20:12:27.589992  3845 solver.cpp:330] Iteration 13600, Testing net (#0)
I1022 20:12:29.168656  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:12:29.905356  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1022 20:12:29.905414  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0758786 (* 1 = 0.0758786 loss)
I1022 20:12:30.086465  3845 solver.cpp:218] Iteration 13600 (4.93427 iter/s, 20.2664s/100 iters), loss = 0.0484304
I1022 20:12:30.086503  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0484302 (* 1 = 0.0484302 loss)
I1022 20:12:30.086511  3845 sgd_solver.cpp:105] Iteration 13600, lr = 0.001
I1022 20:12:38.192852  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:12:48.033994  3845 solver.cpp:218] Iteration 13700 (5.57182 iter/s, 17.9474s/100 iters), loss = 0.0090226
I1022 20:12:48.034026  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00902235 (* 1 = 0.00902235 loss)
I1022 20:12:48.034034  3845 sgd_solver.cpp:105] Iteration 13700, lr = 0.001
I1022 20:13:05.804649  3845 solver.cpp:330] Iteration 13800, Testing net (#0)
I1022 20:13:07.381734  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:13:08.117969  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1022 20:13:08.118032  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0607313 (* 1 = 0.0607313 loss)
I1022 20:13:08.299037  3845 solver.cpp:218] Iteration 13800 (4.93463 iter/s, 20.265s/100 iters), loss = 0.00412407
I1022 20:13:08.299074  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00412381 (* 1 = 0.00412381 loss)
I1022 20:13:08.299082  3845 sgd_solver.cpp:105] Iteration 13800, lr = 0.001
I1022 20:13:26.237532  3845 solver.cpp:218] Iteration 13900 (5.57463 iter/s, 17.9384s/100 iters), loss = 0.00419307
I1022 20:13:26.237565  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00419282 (* 1 = 0.00419282 loss)
I1022 20:13:26.237572  3845 sgd_solver.cpp:105] Iteration 13900, lr = 0.001
I1022 20:13:41.867810  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:13:44.002120  3845 solver.cpp:330] Iteration 14000, Testing net (#0)
I1022 20:13:45.579381  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:13:46.318138  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1022 20:13:46.318204  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0676726 (* 1 = 0.0676726 loss)
I1022 20:13:46.498653  3845 solver.cpp:218] Iteration 14000 (4.93558 iter/s, 20.261s/100 iters), loss = 0.0325513
I1022 20:13:46.498685  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0325511 (* 1 = 0.0325511 loss)
I1022 20:13:46.498692  3845 sgd_solver.cpp:105] Iteration 14000, lr = 0.001
I1022 20:14:04.445868  3845 solver.cpp:218] Iteration 14100 (5.57192 iter/s, 17.9471s/100 iters), loss = 0.115763
I1022 20:14:04.445899  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115762 (* 1 = 0.115762 loss)
I1022 20:14:04.445906  3845 sgd_solver.cpp:105] Iteration 14100, lr = 0.001
I1022 20:14:22.215559  3845 solver.cpp:330] Iteration 14200, Testing net (#0)
I1022 20:14:23.759619  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:14:24.530573  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.980469
I1022 20:14:24.530632  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0525835 (* 1 = 0.0525835 loss)
I1022 20:14:24.711804  3845 solver.cpp:218] Iteration 14200 (4.93441 iter/s, 20.2658s/100 iters), loss = 0.0010265
I1022 20:14:24.711838  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102627 (* 1 = 0.00102627 loss)
I1022 20:14:24.711846  3845 sgd_solver.cpp:105] Iteration 14200, lr = 0.001
I1022 20:14:42.658864  3845 solver.cpp:218] Iteration 14300 (5.57197 iter/s, 17.947s/100 iters), loss = 0.00772522
I1022 20:14:42.658897  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00772498 (* 1 = 0.00772498 loss)
I1022 20:14:42.658905  3845 sgd_solver.cpp:105] Iteration 14300, lr = 0.001
I1022 20:14:47.710606  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:15:00.430269  3845 solver.cpp:330] Iteration 14400, Testing net (#0)
I1022 20:15:01.972084  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:15:02.745369  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1022 20:15:02.745429  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0586929 (* 1 = 0.0586929 loss)
I1022 20:15:02.925992  3845 solver.cpp:218] Iteration 14400 (4.93412 iter/s, 20.267s/100 iters), loss = 0.00654603
I1022 20:15:02.926024  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0065458 (* 1 = 0.0065458 loss)
I1022 20:15:02.926033  3845 sgd_solver.cpp:105] Iteration 14400, lr = 0.001
I1022 20:15:20.868331  3845 solver.cpp:218] Iteration 14500 (5.57343 iter/s, 17.9423s/100 iters), loss = 0.00378772
I1022 20:15:20.868363  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00378749 (* 1 = 0.00378749 loss)
I1022 20:15:20.868371  3845 sgd_solver.cpp:105] Iteration 14500, lr = 0.001
I1022 20:15:38.633600  3845 solver.cpp:330] Iteration 14600, Testing net (#0)
I1022 20:15:40.175812  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:15:40.948994  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.978516
I1022 20:15:40.949055  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0566583 (* 1 = 0.0566583 loss)
I1022 20:15:41.129729  3845 solver.cpp:218] Iteration 14600 (4.93551 iter/s, 20.2613s/100 iters), loss = 0.00397165
I1022 20:15:41.129760  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0039714 (* 1 = 0.0039714 loss)
I1022 20:15:41.129768  3845 sgd_solver.cpp:105] Iteration 14600, lr = 0.001
I1022 20:15:53.540542  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:15:59.085753  3845 solver.cpp:218] Iteration 14700 (5.56919 iter/s, 17.9559s/100 iters), loss = 0.00961574
I1022 20:15:59.085786  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00961551 (* 1 = 0.00961551 loss)
I1022 20:15:59.085794  3845 sgd_solver.cpp:105] Iteration 14700, lr = 0.001
I1022 20:16:16.852401  3845 solver.cpp:330] Iteration 14800, Testing net (#0)
I1022 20:16:18.393175  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:16:19.168190  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1022 20:16:19.168254  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0610168 (* 1 = 0.0610168 loss)
I1022 20:16:19.349095  3845 solver.cpp:218] Iteration 14800 (4.93504 iter/s, 20.2633s/100 iters), loss = 0.00688176
I1022 20:16:19.349129  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00688153 (* 1 = 0.00688153 loss)
I1022 20:16:19.349138  3845 sgd_solver.cpp:105] Iteration 14800, lr = 0.001
I1022 20:16:37.294767  3845 solver.cpp:218] Iteration 14900 (5.5724 iter/s, 17.9456s/100 iters), loss = 0.00690216
I1022 20:16:37.294801  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0069019 (* 1 = 0.0069019 loss)
I1022 20:16:37.294809  3845 sgd_solver.cpp:105] Iteration 14900, lr = 0.001
I1022 20:16:55.063563  3845 solver.cpp:330] Iteration 15000, Testing net (#0)
I1022 20:16:56.570667  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:16:57.378283  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.976562
I1022 20:16:57.378347  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0655973 (* 1 = 0.0655973 loss)
I1022 20:16:57.559193  3845 solver.cpp:218] Iteration 15000 (4.93478 iter/s, 20.2643s/100 iters), loss = 0.00262796
I1022 20:16:57.559226  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00262768 (* 1 = 0.00262768 loss)
I1022 20:16:57.559232  3845 sgd_solver.cpp:105] Iteration 15000, lr = 0.001
I1022 20:16:59.381207  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:17:15.498565  3845 solver.cpp:218] Iteration 15100 (5.57436 iter/s, 17.9393s/100 iters), loss = 0.0309418
I1022 20:17:15.498598  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0309415 (* 1 = 0.0309415 loss)
I1022 20:17:15.498605  3845 sgd_solver.cpp:105] Iteration 15100, lr = 0.001
I1022 20:17:33.260429  3845 solver.cpp:330] Iteration 15200, Testing net (#0)
I1022 20:17:34.767463  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:17:35.575860  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:17:35.575918  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0549872 (* 1 = 0.0549872 loss)
I1022 20:17:35.757097  3845 solver.cpp:218] Iteration 15200 (4.93621 iter/s, 20.2584s/100 iters), loss = 0.0040783
I1022 20:17:35.757129  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00407807 (* 1 = 0.00407807 loss)
I1022 20:17:35.757138  3845 sgd_solver.cpp:105] Iteration 15200, lr = 0.001
I1022 20:17:53.703387  3845 solver.cpp:218] Iteration 15300 (5.57221 iter/s, 17.9462s/100 iters), loss = 0.011988
I1022 20:17:53.703419  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0119877 (* 1 = 0.0119877 loss)
I1022 20:17:53.703425  3845 sgd_solver.cpp:105] Iteration 15300, lr = 0.001
I1022 20:18:03.065366  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:18:11.478322  3845 solver.cpp:330] Iteration 15400, Testing net (#0)
I1022 20:18:12.984145  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:18:13.793859  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1022 20:18:13.793925  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0739788 (* 1 = 0.0739788 loss)
I1022 20:18:13.975239  3845 solver.cpp:218] Iteration 15400 (4.93297 iter/s, 20.2718s/100 iters), loss = 0.0014772
I1022 20:18:13.975272  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00147704 (* 1 = 0.00147704 loss)
I1022 20:18:13.975280  3845 sgd_solver.cpp:105] Iteration 15400, lr = 0.001
I1022 20:18:31.922197  3845 solver.cpp:218] Iteration 15500 (5.572 iter/s, 17.9469s/100 iters), loss = 0.0031776
I1022 20:18:31.922226  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00317748 (* 1 = 0.00317748 loss)
I1022 20:18:31.922233  3845 sgd_solver.cpp:105] Iteration 15500, lr = 0.001
I1022 20:18:49.693989  3845 solver.cpp:330] Iteration 15600, Testing net (#0)
I1022 20:18:51.198741  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:18:52.009068  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1022 20:18:52.009124  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0627382 (* 1 = 0.0627382 loss)
I1022 20:18:52.189848  3845 solver.cpp:218] Iteration 15600 (4.93399 iter/s, 20.2676s/100 iters), loss = 0.00141048
I1022 20:18:52.189882  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00141037 (* 1 = 0.00141037 loss)
I1022 20:18:52.189890  3845 sgd_solver.cpp:105] Iteration 15600, lr = 0.001
I1022 20:19:08.899566  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:19:10.134392  3845 solver.cpp:218] Iteration 15700 (5.57275 iter/s, 17.9445s/100 iters), loss = 0.0054432
I1022 20:19:10.134425  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00544309 (* 1 = 0.00544309 loss)
I1022 20:19:10.134433  3845 sgd_solver.cpp:105] Iteration 15700, lr = 0.001
I1022 20:19:27.899277  3845 solver.cpp:330] Iteration 15800, Testing net (#0)
I1022 20:19:29.372076  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:19:30.215306  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.978516
I1022 20:19:30.215360  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0555858 (* 1 = 0.0555858 loss)
I1022 20:19:30.396103  3845 solver.cpp:218] Iteration 15800 (4.93544 iter/s, 20.2616s/100 iters), loss = 0.000941146
I1022 20:19:30.396138  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000941057 (* 1 = 0.000941057 loss)
I1022 20:19:30.396147  3845 sgd_solver.cpp:105] Iteration 15800, lr = 0.001
I1022 20:19:48.341748  3845 solver.cpp:218] Iteration 15900 (5.57241 iter/s, 17.9456s/100 iters), loss = 0.00080715
I1022 20:19:48.341779  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000807075 (* 1 = 0.000807075 loss)
I1022 20:19:48.341787  3845 sgd_solver.cpp:105] Iteration 15900, lr = 0.001
I1022 20:20:06.113687  3845 solver.cpp:330] Iteration 16000, Testing net (#0)
I1022 20:20:07.584727  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:20:08.429178  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1022 20:20:08.429237  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0654856 (* 1 = 0.0654856 loss)
I1022 20:20:08.610414  3845 solver.cpp:218] Iteration 16000 (4.93374 iter/s, 20.2686s/100 iters), loss = 0.0236285
I1022 20:20:08.610446  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0236285 (* 1 = 0.0236285 loss)
I1022 20:20:08.610455  3845 sgd_solver.cpp:105] Iteration 16000, lr = 0.001
I1022 20:20:14.738767  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:20:26.556177  3845 solver.cpp:218] Iteration 16100 (5.57237 iter/s, 17.9457s/100 iters), loss = 0.00382957
I1022 20:20:26.556208  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00382951 (* 1 = 0.00382951 loss)
I1022 20:20:26.556216  3845 sgd_solver.cpp:105] Iteration 16100, lr = 0.001
I1022 20:20:44.327015  3845 solver.cpp:330] Iteration 16200, Testing net (#0)
I1022 20:20:45.797368  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:20:46.642462  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1022 20:20:46.642525  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0766347 (* 1 = 0.0766347 loss)
I1022 20:20:46.823552  3845 solver.cpp:218] Iteration 16200 (4.93406 iter/s, 20.2673s/100 iters), loss = 0.00591047
I1022 20:20:46.823586  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00591044 (* 1 = 0.00591044 loss)
I1022 20:20:46.823593  3845 sgd_solver.cpp:105] Iteration 16200, lr = 0.001
I1022 20:21:04.761282  3845 solver.cpp:218] Iteration 16300 (5.57487 iter/s, 17.9376s/100 iters), loss = 0.0263872
I1022 20:21:04.761314  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0263872 (* 1 = 0.0263872 loss)
I1022 20:21:04.761322  3845 sgd_solver.cpp:105] Iteration 16300, lr = 0.001
I1022 20:21:18.242048  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:21:22.527180  3845 solver.cpp:330] Iteration 16400, Testing net (#0)
I1022 20:21:23.996371  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:21:24.843189  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1022 20:21:24.843255  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0718955 (* 1 = 0.0718955 loss)
I1022 20:21:25.023793  3845 solver.cpp:218] Iteration 16400 (4.93524 iter/s, 20.2624s/100 iters), loss = 0.0047382
I1022 20:21:25.023829  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00473816 (* 1 = 0.00473816 loss)
I1022 20:21:25.023838  3845 sgd_solver.cpp:105] Iteration 16400, lr = 0.001
I1022 20:21:42.966796  3845 solver.cpp:218] Iteration 16500 (5.57323 iter/s, 17.9429s/100 iters), loss = 0.0663209
I1022 20:21:42.966827  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0663208 (* 1 = 0.0663208 loss)
I1022 20:21:42.966835  3845 sgd_solver.cpp:105] Iteration 16500, lr = 0.001
I1022 20:22:00.736256  3845 solver.cpp:330] Iteration 16600, Testing net (#0)
I1022 20:22:02.171221  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:22:03.050642  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1022 20:22:03.050709  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.073706 (* 1 = 0.073706 loss)
I1022 20:22:03.231674  3845 solver.cpp:218] Iteration 16600 (4.93467 iter/s, 20.2648s/100 iters), loss = 0.00349492
I1022 20:22:03.231710  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00349492 (* 1 = 0.00349492 loss)
I1022 20:22:03.231719  3845 sgd_solver.cpp:105] Iteration 16600, lr = 0.001
I1022 20:22:21.180294  3845 solver.cpp:218] Iteration 16700 (5.57148 iter/s, 17.9485s/100 iters), loss = 0.0137759
I1022 20:22:21.180325  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013776 (* 1 = 0.013776 loss)
I1022 20:22:21.180331  3845 sgd_solver.cpp:105] Iteration 16700, lr = 0.001
I1022 20:22:24.256273  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:22:38.954391  3845 solver.cpp:330] Iteration 16800, Testing net (#0)
I1022 20:22:40.389497  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:22:41.270090  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1022 20:22:41.270154  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0723 (* 1 = 0.0723 loss)
I1022 20:22:41.451068  3845 solver.cpp:218] Iteration 16800 (4.93323 iter/s, 20.2707s/100 iters), loss = 0.00535957
I1022 20:22:41.451102  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00535955 (* 1 = 0.00535955 loss)
I1022 20:22:41.451109  3845 sgd_solver.cpp:105] Iteration 16800, lr = 0.001
I1022 20:22:59.391415  3845 solver.cpp:218] Iteration 16900 (5.57405 iter/s, 17.9403s/100 iters), loss = 0.0064221
I1022 20:22:59.391448  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00642205 (* 1 = 0.00642205 loss)
I1022 20:22:59.391456  3845 sgd_solver.cpp:105] Iteration 16900, lr = 0.001
I1022 20:23:17.156651  3845 solver.cpp:330] Iteration 17000, Testing net (#0)
I1022 20:23:18.590529  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:23:19.472040  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1022 20:23:19.472110  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0806035 (* 1 = 0.0806035 loss)
I1022 20:23:19.652964  3845 solver.cpp:218] Iteration 17000 (4.93548 iter/s, 20.2615s/100 iters), loss = 0.00281794
I1022 20:23:19.652998  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00281791 (* 1 = 0.00281791 loss)
I1022 20:23:19.653007  3845 sgd_solver.cpp:105] Iteration 17000, lr = 0.001
I1022 20:23:30.089892  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:23:37.608928  3845 solver.cpp:218] Iteration 17100 (5.56921 iter/s, 17.9559s/100 iters), loss = 0.0376655
I1022 20:23:37.608963  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0376654 (* 1 = 0.0376654 loss)
I1022 20:23:37.608969  3845 sgd_solver.cpp:105] Iteration 17100, lr = 0.001
I1022 20:23:55.371670  3845 solver.cpp:330] Iteration 17200, Testing net (#0)
I1022 20:23:56.803797  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:23:57.686478  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:23:57.686545  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0620678 (* 1 = 0.0620678 loss)
I1022 20:23:57.867528  3845 solver.cpp:218] Iteration 17200 (4.9362 iter/s, 20.2585s/100 iters), loss = 0.00238791
I1022 20:23:57.867563  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00238787 (* 1 = 0.00238787 loss)
I1022 20:23:57.867571  3845 sgd_solver.cpp:105] Iteration 17200, lr = 0.001
I1022 20:24:15.813910  3845 solver.cpp:218] Iteration 17300 (5.57218 iter/s, 17.9463s/100 iters), loss = 0.0168704
I1022 20:24:15.813942  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0168703 (* 1 = 0.0168703 loss)
I1022 20:24:15.813949  3845 sgd_solver.cpp:105] Iteration 17300, lr = 0.001
I1022 20:24:33.582742  3845 solver.cpp:330] Iteration 17400, Testing net (#0)
I1022 20:24:34.982951  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:24:35.898545  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1022 20:24:35.898603  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0804696 (* 1 = 0.0804696 loss)
I1022 20:24:35.922324  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:24:36.079373  3845 solver.cpp:218] Iteration 17400 (4.93452 iter/s, 20.2654s/100 iters), loss = 0.0207434
I1022 20:24:36.079402  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0207434 (* 1 = 0.0207434 loss)
I1022 20:24:36.079409  3845 sgd_solver.cpp:105] Iteration 17400, lr = 0.001
I1022 20:24:54.017953  3845 solver.cpp:218] Iteration 17500 (5.5746 iter/s, 17.9385s/100 iters), loss = 0.0612712
I1022 20:24:54.017984  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0612712 (* 1 = 0.0612712 loss)
I1022 20:24:54.017992  3845 sgd_solver.cpp:105] Iteration 17500, lr = 0.001
I1022 20:25:11.778842  3845 solver.cpp:330] Iteration 17600, Testing net (#0)
I1022 20:25:13.177691  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:25:14.094606  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1022 20:25:14.094671  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0836939 (* 1 = 0.0836939 loss)
I1022 20:25:14.275727  3845 solver.cpp:218] Iteration 17600 (4.9364 iter/s, 20.2577s/100 iters), loss = 0.0212039
I1022 20:25:14.275759  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0212038 (* 1 = 0.0212038 loss)
I1022 20:25:14.275766  3845 sgd_solver.cpp:105] Iteration 17600, lr = 0.001
I1022 20:25:32.222204  3845 solver.cpp:218] Iteration 17700 (5.57215 iter/s, 17.9464s/100 iters), loss = 0.0584234
I1022 20:25:32.222236  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0584234 (* 1 = 0.0584234 loss)
I1022 20:25:32.222244  3845 sgd_solver.cpp:105] Iteration 17700, lr = 0.001
I1022 20:25:39.430981  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:25:49.995285  3845 solver.cpp:330] Iteration 17800, Testing net (#0)
I1022 20:25:51.392577  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:25:52.310488  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:25:52.310554  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0805931 (* 1 = 0.0805931 loss)
I1022 20:25:52.491647  3845 solver.cpp:218] Iteration 17800 (4.93356 iter/s, 20.2694s/100 iters), loss = 0.109226
I1022 20:25:52.491680  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.109226 (* 1 = 0.109226 loss)
I1022 20:25:52.491688  3845 sgd_solver.cpp:105] Iteration 17800, lr = 0.001
I1022 20:26:10.440570  3845 solver.cpp:218] Iteration 17900 (5.57139 iter/s, 17.9488s/100 iters), loss = 0.0371281
I1022 20:26:10.440601  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0371281 (* 1 = 0.0371281 loss)
I1022 20:26:10.440608  3845 sgd_solver.cpp:105] Iteration 17900, lr = 0.001
I1022 20:26:28.211320  3845 solver.cpp:330] Iteration 18000, Testing net (#0)
I1022 20:26:29.608620  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:26:30.526640  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1022 20:26:30.526703  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0814119 (* 1 = 0.0814119 loss)
I1022 20:26:30.707593  3845 solver.cpp:218] Iteration 18000 (4.93414 iter/s, 20.2669s/100 iters), loss = 0.0334648
I1022 20:26:30.707628  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0334648 (* 1 = 0.0334648 loss)
I1022 20:26:30.707635  3845 sgd_solver.cpp:105] Iteration 18000, lr = 0.001
I1022 20:26:45.444108  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:26:48.654140  3845 solver.cpp:218] Iteration 18100 (5.57213 iter/s, 17.9465s/100 iters), loss = 0.0308457
I1022 20:26:48.654171  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0308457 (* 1 = 0.0308457 loss)
I1022 20:26:48.654180  3845 sgd_solver.cpp:105] Iteration 18100, lr = 0.001
I1022 20:27:06.415271  3845 solver.cpp:330] Iteration 18200, Testing net (#0)
I1022 20:27:07.778632  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:27:08.729900  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.976562
I1022 20:27:08.729965  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0607687 (* 1 = 0.0607687 loss)
I1022 20:27:08.910939  3845 solver.cpp:218] Iteration 18200 (4.93664 iter/s, 20.2567s/100 iters), loss = 0.00230405
I1022 20:27:08.910972  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00230399 (* 1 = 0.00230399 loss)
I1022 20:27:08.910980  3845 sgd_solver.cpp:105] Iteration 18200, lr = 0.001
I1022 20:27:26.859285  3845 solver.cpp:218] Iteration 18300 (5.57157 iter/s, 17.9483s/100 iters), loss = 0.00931964
I1022 20:27:26.859318  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0093196 (* 1 = 0.0093196 loss)
I1022 20:27:26.859323  3845 sgd_solver.cpp:105] Iteration 18300, lr = 0.001
I1022 20:27:44.629634  3845 solver.cpp:330] Iteration 18400, Testing net (#0)
I1022 20:27:45.992310  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:27:46.944665  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:27:46.944731  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0718996 (* 1 = 0.0718996 loss)
I1022 20:27:47.126255  3845 solver.cpp:218] Iteration 18400 (4.93416 iter/s, 20.2669s/100 iters), loss = 0.00246084
I1022 20:27:47.126287  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00246079 (* 1 = 0.00246079 loss)
I1022 20:27:47.126296  3845 sgd_solver.cpp:105] Iteration 18400, lr = 0.001
I1022 20:27:51.279983  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:28:05.075594  3845 solver.cpp:218] Iteration 18500 (5.57126 iter/s, 17.9493s/100 iters), loss = 0.00727937
I1022 20:28:05.075626  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00727931 (* 1 = 0.00727931 loss)
I1022 20:28:05.075634  3845 sgd_solver.cpp:105] Iteration 18500, lr = 0.001
I1022 20:28:22.843730  3845 solver.cpp:330] Iteration 18600, Testing net (#0)
I1022 20:28:24.204701  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:28:25.158751  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:28:25.158818  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0576889 (* 1 = 0.0576889 loss)
I1022 20:28:25.339644  3845 solver.cpp:218] Iteration 18600 (4.93487 iter/s, 20.264s/100 iters), loss = 0.064745
I1022 20:28:25.339679  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.064745 (* 1 = 0.064745 loss)
I1022 20:28:25.339685  3845 sgd_solver.cpp:105] Iteration 18600, lr = 0.001
I1022 20:28:43.276950  3845 solver.cpp:218] Iteration 18700 (5.575 iter/s, 17.9372s/100 iters), loss = 0.107006
I1022 20:28:43.276983  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.107006 (* 1 = 0.107006 loss)
I1022 20:28:43.276990  3845 sgd_solver.cpp:105] Iteration 18700, lr = 0.001
I1022 20:28:54.789294  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:29:01.045867  3845 solver.cpp:330] Iteration 18800, Testing net (#0)
I1022 20:29:02.406348  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:29:03.361495  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1022 20:29:03.361555  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0698329 (* 1 = 0.0698329 loss)
I1022 20:29:03.542368  3845 solver.cpp:218] Iteration 18800 (4.93454 iter/s, 20.2653s/100 iters), loss = 0.0240922
I1022 20:29:03.542402  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0240922 (* 1 = 0.0240922 loss)
I1022 20:29:03.542409  3845 sgd_solver.cpp:105] Iteration 18800, lr = 0.001
I1022 20:29:21.484840  3845 solver.cpp:218] Iteration 18900 (5.57339 iter/s, 17.9424s/100 iters), loss = 0.00252751
I1022 20:29:21.484872  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00252754 (* 1 = 0.00252754 loss)
I1022 20:29:21.484879  3845 sgd_solver.cpp:105] Iteration 18900, lr = 0.001
I1022 20:29:39.257846  3845 solver.cpp:330] Iteration 19000, Testing net (#0)
I1022 20:29:40.585081  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:29:41.572538  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1022 20:29:41.572595  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0783243 (* 1 = 0.0783243 loss)
I1022 20:29:41.753734  3845 solver.cpp:218] Iteration 19000 (4.93369 iter/s, 20.2688s/100 iters), loss = 0.00338544
I1022 20:29:41.753767  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00338547 (* 1 = 0.00338547 loss)
I1022 20:29:41.753773  3845 sgd_solver.cpp:105] Iteration 19000, lr = 0.001
I1022 20:29:59.699743  3845 solver.cpp:218] Iteration 19100 (5.5723 iter/s, 17.9459s/100 iters), loss = 0.00100138
I1022 20:29:59.699774  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100138 (* 1 = 0.00100138 loss)
I1022 20:29:59.699780  3845 sgd_solver.cpp:105] Iteration 19100, lr = 0.001
I1022 20:30:00.623996  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:30:17.471942  3845 solver.cpp:330] Iteration 19200, Testing net (#0)
I1022 20:30:18.797917  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:30:19.786322  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1022 20:30:19.786383  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0733367 (* 1 = 0.0733367 loss)
I1022 20:30:19.967190  3845 solver.cpp:218] Iteration 19200 (4.93404 iter/s, 20.2674s/100 iters), loss = 0.000636848
I1022 20:30:19.967223  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000636835 (* 1 = 0.000636835 loss)
I1022 20:30:19.967231  3845 sgd_solver.cpp:105] Iteration 19200, lr = 0.001
I1022 20:30:37.907857  3845 solver.cpp:218] Iteration 19300 (5.57395 iter/s, 17.9406s/100 iters), loss = 0.0125452
I1022 20:30:37.907889  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125452 (* 1 = 0.0125452 loss)
I1022 20:30:37.907896  3845 sgd_solver.cpp:105] Iteration 19300, lr = 0.001
I1022 20:30:55.674948  3845 solver.cpp:330] Iteration 19400, Testing net (#0)
I1022 20:30:56.999600  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:30:57.989156  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1022 20:30:57.989214  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0722742 (* 1 = 0.0722742 loss)
I1022 20:30:58.169886  3845 solver.cpp:218] Iteration 19400 (4.93536 iter/s, 20.2619s/100 iters), loss = 0.00561124
I1022 20:30:58.169919  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00561122 (* 1 = 0.00561122 loss)
I1022 20:30:58.169925  3845 sgd_solver.cpp:105] Iteration 19400, lr = 0.001
I1022 20:31:06.634181  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:31:16.129385  3845 solver.cpp:218] Iteration 19500 (5.56811 iter/s, 17.9594s/100 iters), loss = 0.0158839
I1022 20:31:16.129417  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0158839 (* 1 = 0.0158839 loss)
I1022 20:31:16.129425  3845 sgd_solver.cpp:105] Iteration 19500, lr = 0.001
I1022 20:31:33.890516  3845 solver.cpp:330] Iteration 19600, Testing net (#0)
I1022 20:31:35.214180  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:31:36.205824  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.976562
I1022 20:31:36.205883  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0599517 (* 1 = 0.0599517 loss)
I1022 20:31:36.386978  3845 solver.cpp:218] Iteration 19600 (4.93644 iter/s, 20.2575s/100 iters), loss = 0.0171611
I1022 20:31:36.387010  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0171611 (* 1 = 0.0171611 loss)
I1022 20:31:36.387017  3845 sgd_solver.cpp:105] Iteration 19600, lr = 0.001
I1022 20:31:54.332120  3845 solver.cpp:218] Iteration 19700 (5.57256 iter/s, 17.9451s/100 iters), loss = 0.00448925
I1022 20:31:54.332154  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00448925 (* 1 = 0.00448925 loss)
I1022 20:31:54.332160  3845 sgd_solver.cpp:105] Iteration 19700, lr = 0.001
I1022 20:32:10.152426  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:32:12.106485  3845 solver.cpp:330] Iteration 19800, Testing net (#0)
I1022 20:32:13.397627  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:32:14.421742  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1022 20:32:14.421808  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0718486 (* 1 = 0.0718486 loss)
I1022 20:32:14.601935  3845 solver.cpp:218] Iteration 19800 (4.93347 iter/s, 20.2697s/100 iters), loss = 0.00264191
I1022 20:32:14.601968  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00264191 (* 1 = 0.00264191 loss)
I1022 20:32:14.601974  3845 sgd_solver.cpp:105] Iteration 19800, lr = 0.001
I1022 20:32:32.537147  3845 solver.cpp:218] Iteration 19900 (5.57565 iter/s, 17.9351s/100 iters), loss = 0.00289982
I1022 20:32:32.537179  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00289981 (* 1 = 0.00289981 loss)
I1022 20:32:32.537186  3845 sgd_solver.cpp:105] Iteration 19900, lr = 0.001
I1022 20:32:50.300096  3845 solver.cpp:330] Iteration 20000, Testing net (#0)
I1022 20:32:51.590132  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:32:52.614986  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.976562
I1022 20:32:52.615051  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0535956 (* 1 = 0.0535956 loss)
I1022 20:32:52.796001  3845 solver.cpp:218] Iteration 20000 (4.93613 iter/s, 20.2588s/100 iters), loss = 0.0501138
I1022 20:32:52.796032  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0501138 (* 1 = 0.0501138 loss)
I1022 20:32:52.796038  3845 sgd_solver.cpp:46] MultiStep Status: Iteration 20000, step = 2
I1022 20:32:52.796041  3845 sgd_solver.cpp:105] Iteration 20000, lr = 0.0001
I1022 20:33:10.743827  3845 solver.cpp:218] Iteration 20100 (5.57173 iter/s, 17.9477s/100 iters), loss = 0.00515497
I1022 20:33:10.743861  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00515498 (* 1 = 0.00515498 loss)
I1022 20:33:10.743870  3845 sgd_solver.cpp:105] Iteration 20100, lr = 0.0001
I1022 20:33:15.976511  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:33:28.518585  3845 solver.cpp:330] Iteration 20200, Testing net (#0)
I1022 20:33:29.807204  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:33:30.834026  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1022 20:33:30.834095  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0579088 (* 1 = 0.0579088 loss)
I1022 20:33:31.015199  3845 solver.cpp:218] Iteration 20200 (4.93309 iter/s, 20.2713s/100 iters), loss = 0.00130081
I1022 20:33:31.015231  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00130081 (* 1 = 0.00130081 loss)
I1022 20:33:31.015239  3845 sgd_solver.cpp:105] Iteration 20200, lr = 0.0001
I1022 20:33:48.961999  3845 solver.cpp:218] Iteration 20300 (5.57205 iter/s, 17.9467s/100 iters), loss = 0.00186103
I1022 20:33:48.962040  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00186103 (* 1 = 0.00186103 loss)
I1022 20:33:48.962049  3845 sgd_solver.cpp:105] Iteration 20300, lr = 0.0001
I1022 20:34:06.734503  3845 solver.cpp:330] Iteration 20400, Testing net (#0)
I1022 20:34:08.023092  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:34:09.050813  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.976562
I1022 20:34:09.050873  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0578272 (* 1 = 0.0578272 loss)
I1022 20:34:09.231711  3845 solver.cpp:218] Iteration 20400 (4.93349 iter/s, 20.2696s/100 iters), loss = 0.00120674
I1022 20:34:09.231747  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00120674 (* 1 = 0.00120674 loss)
I1022 20:34:09.231755  3845 sgd_solver.cpp:105] Iteration 20400, lr = 0.0001
I1022 20:34:21.819870  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:34:27.181303  3845 solver.cpp:218] Iteration 20500 (5.57118 iter/s, 17.9495s/100 iters), loss = 0.0147361
I1022 20:34:27.181336  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0147361 (* 1 = 0.0147361 loss)
I1022 20:34:27.181344  3845 sgd_solver.cpp:105] Iteration 20500, lr = 0.0001
I1022 20:34:44.941084  3845 solver.cpp:330] Iteration 20600, Testing net (#0)
I1022 20:34:46.195472  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:34:47.256686  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.976562
I1022 20:34:47.256744  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0602437 (* 1 = 0.0602437 loss)
I1022 20:34:47.437300  3845 solver.cpp:218] Iteration 20600 (4.93683 iter/s, 20.2559s/100 iters), loss = 0.00613434
I1022 20:34:47.437332  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00613435 (* 1 = 0.00613435 loss)
I1022 20:34:47.437340  3845 sgd_solver.cpp:105] Iteration 20600, lr = 0.0001
I1022 20:35:05.385198  3845 solver.cpp:218] Iteration 20700 (5.57171 iter/s, 17.9478s/100 iters), loss = 0.00627344
I1022 20:35:05.385231  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00627345 (* 1 = 0.00627345 loss)
I1022 20:35:05.385237  3845 sgd_solver.cpp:105] Iteration 20700, lr = 0.0001
I1022 20:35:23.156558  3845 solver.cpp:330] Iteration 20800, Testing net (#0)
I1022 20:35:24.408061  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:35:25.473336  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1022 20:35:25.473403  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0631595 (* 1 = 0.0631595 loss)
I1022 20:35:25.654484  3845 solver.cpp:218] Iteration 20800 (4.93359 iter/s, 20.2692s/100 iters), loss = 0.00234772
I1022 20:35:25.654515  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00234774 (* 1 = 0.00234774 loss)
I1022 20:35:25.654523  3845 sgd_solver.cpp:105] Iteration 20800, lr = 0.0001
I1022 20:35:27.832224  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:35:43.599256  3845 solver.cpp:218] Iteration 20900 (5.57268 iter/s, 17.9447s/100 iters), loss = 0.0117201
I1022 20:35:43.599287  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117201 (* 1 = 0.0117201 loss)
I1022 20:35:43.599294  3845 sgd_solver.cpp:105] Iteration 20900, lr = 0.0001
I1022 20:36:01.369920  3845 solver.cpp:330] Iteration 21000, Testing net (#0)
I1022 20:36:02.621971  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:36:03.684927  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:36:03.684984  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0666448 (* 1 = 0.0666448 loss)
I1022 20:36:03.865725  3845 solver.cpp:218] Iteration 21000 (4.93428 iter/s, 20.2664s/100 iters), loss = 0.0010787
I1022 20:36:03.865757  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010787 (* 1 = 0.0010787 loss)
I1022 20:36:03.865764  3845 sgd_solver.cpp:105] Iteration 21000, lr = 0.0001
I1022 20:36:21.803794  3845 solver.cpp:218] Iteration 21100 (5.57476 iter/s, 17.938s/100 iters), loss = 0.000587704
I1022 20:36:21.803825  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000587703 (* 1 = 0.000587703 loss)
I1022 20:36:21.803833  3845 sgd_solver.cpp:105] Iteration 21100, lr = 0.0001
I1022 20:36:31.338728  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:36:39.567286  3845 solver.cpp:330] Iteration 21200, Testing net (#0)
I1022 20:36:40.819641  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:36:41.882800  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1022 20:36:41.882859  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0644696 (* 1 = 0.0644696 loss)
I1022 20:36:42.064054  3845 solver.cpp:218] Iteration 21200 (4.93579 iter/s, 20.2602s/100 iters), loss = 0.0106029
I1022 20:36:42.064088  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106029 (* 1 = 0.0106029 loss)
I1022 20:36:42.064096  3845 sgd_solver.cpp:105] Iteration 21200, lr = 0.0001
I1022 20:37:00.009743  3845 solver.cpp:218] Iteration 21300 (5.57239 iter/s, 17.9456s/100 iters), loss = 0.00181927
I1022 20:37:00.009776  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00181926 (* 1 = 0.00181926 loss)
I1022 20:37:00.009783  3845 sgd_solver.cpp:105] Iteration 21300, lr = 0.0001
I1022 20:37:17.782570  3845 solver.cpp:330] Iteration 21400, Testing net (#0)
I1022 20:37:19.001654  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:37:20.098260  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1022 20:37:20.098325  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0649501 (* 1 = 0.0649501 loss)
I1022 20:37:20.279253  3845 solver.cpp:218] Iteration 21400 (4.93354 iter/s, 20.2694s/100 iters), loss = 0.00297119
I1022 20:37:20.279287  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00297119 (* 1 = 0.00297119 loss)
I1022 20:37:20.279295  3845 sgd_solver.cpp:105] Iteration 21400, lr = 0.0001
I1022 20:37:37.176517  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:37:38.231530  3845 solver.cpp:218] Iteration 21500 (5.57035 iter/s, 17.9522s/100 iters), loss = 0.0121658
I1022 20:37:38.231561  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121658 (* 1 = 0.0121658 loss)
I1022 20:37:38.231568  3845 sgd_solver.cpp:105] Iteration 21500, lr = 0.0001
I1022 20:37:56.004168  3845 solver.cpp:330] Iteration 21600, Testing net (#0)
I1022 20:37:57.221546  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:37:58.318984  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1022 20:37:58.319046  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0655006 (* 1 = 0.0655006 loss)
I1022 20:37:58.499817  3845 solver.cpp:218] Iteration 21600 (4.93384 iter/s, 20.2682s/100 iters), loss = 0.0269413
I1022 20:37:58.499852  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0269413 (* 1 = 0.0269413 loss)
I1022 20:37:58.499861  3845 sgd_solver.cpp:105] Iteration 21600, lr = 0.0001
I1022 20:38:16.442751  3845 solver.cpp:218] Iteration 21700 (5.57325 iter/s, 17.9429s/100 iters), loss = 0.000750048
I1022 20:38:16.442783  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00075004 (* 1 = 0.00075004 loss)
I1022 20:38:16.442790  3845 sgd_solver.cpp:105] Iteration 21700, lr = 0.0001
I1022 20:38:34.209738  3845 solver.cpp:330] Iteration 21800, Testing net (#0)
I1022 20:38:35.426970  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:38:36.525250  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:38:36.525311  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.067496 (* 1 = 0.067496 loss)
I1022 20:38:36.705883  3845 solver.cpp:218] Iteration 21800 (4.93509 iter/s, 20.263s/100 iters), loss = 0.00100096
I1022 20:38:36.705915  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100094 (* 1 = 0.00100094 loss)
I1022 20:38:36.705924  3845 sgd_solver.cpp:105] Iteration 21800, lr = 0.0001
I1022 20:38:43.017496  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:38:54.656366  3845 solver.cpp:218] Iteration 21900 (5.57091 iter/s, 17.9504s/100 iters), loss = 0.00348186
I1022 20:38:54.656399  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00348184 (* 1 = 0.00348184 loss)
I1022 20:38:54.656405  3845 sgd_solver.cpp:105] Iteration 21900, lr = 0.0001
I1022 20:39:12.428247  3845 solver.cpp:330] Iteration 22000, Testing net (#0)
I1022 20:39:13.643847  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:39:14.743851  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:39:14.743918  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0681231 (* 1 = 0.0681231 loss)
I1022 20:39:14.925055  3845 solver.cpp:218] Iteration 22000 (4.93374 iter/s, 20.2686s/100 iters), loss = 0.00145071
I1022 20:39:14.925087  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00145068 (* 1 = 0.00145068 loss)
I1022 20:39:14.925094  3845 sgd_solver.cpp:105] Iteration 22000, lr = 0.0001
I1022 20:39:32.870944  3845 solver.cpp:218] Iteration 22100 (5.57233 iter/s, 17.9458s/100 iters), loss = 0.0603768
I1022 20:39:32.870975  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0603768 (* 1 = 0.0603768 loss)
I1022 20:39:32.870981  3845 sgd_solver.cpp:105] Iteration 22100, lr = 0.0001
I1022 20:39:46.715503  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:39:50.644732  3845 solver.cpp:330] Iteration 22200, Testing net (#0)
I1022 20:39:51.827148  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:39:52.960177  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:39:52.960242  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0693535 (* 1 = 0.0693535 loss)
I1022 20:39:53.140343  3845 solver.cpp:218] Iteration 22200 (4.93357 iter/s, 20.2693s/100 iters), loss = 0.00701704
I1022 20:39:53.140375  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00701698 (* 1 = 0.00701698 loss)
I1022 20:39:53.140383  3845 sgd_solver.cpp:105] Iteration 22200, lr = 0.0001
I1022 20:40:11.074651  3845 solver.cpp:218] Iteration 22300 (5.57593 iter/s, 17.9342s/100 iters), loss = 0.0126862
I1022 20:40:11.074683  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126861 (* 1 = 0.0126861 loss)
I1022 20:40:11.074690  3845 sgd_solver.cpp:105] Iteration 22300, lr = 0.0001
I1022 20:40:28.835386  3845 solver.cpp:330] Iteration 22400, Testing net (#0)
I1022 20:40:30.017087  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:40:31.150876  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:40:31.150934  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0698239 (* 1 = 0.0698239 loss)
I1022 20:40:31.332247  3845 solver.cpp:218] Iteration 22400 (4.93644 iter/s, 20.2575s/100 iters), loss = 0.000635916
I1022 20:40:31.332280  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000635837 (* 1 = 0.000635837 loss)
I1022 20:40:31.332288  3845 sgd_solver.cpp:105] Iteration 22400, lr = 0.0001
I1022 20:40:49.282017  3845 solver.cpp:218] Iteration 22500 (5.57113 iter/s, 17.9497s/100 iters), loss = 0.00627698
I1022 20:40:49.282050  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0062769 (* 1 = 0.0062769 loss)
I1022 20:40:49.282058  3845 sgd_solver.cpp:105] Iteration 22500, lr = 0.0001
I1022 20:40:52.539326  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:41:07.058213  3845 solver.cpp:330] Iteration 22600, Testing net (#0)
I1022 20:41:08.238282  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:41:09.374013  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:41:09.374070  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0677532 (* 1 = 0.0677532 loss)
I1022 20:41:09.554986  3845 solver.cpp:218] Iteration 22600 (4.9327 iter/s, 20.2729s/100 iters), loss = 0.0373348
I1022 20:41:09.555018  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0373348 (* 1 = 0.0373348 loss)
I1022 20:41:09.555027  3845 sgd_solver.cpp:105] Iteration 22600, lr = 0.0001
I1022 20:41:27.503024  3845 solver.cpp:218] Iteration 22700 (5.57167 iter/s, 17.948s/100 iters), loss = 0.0344913
I1022 20:41:27.503056  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0344912 (* 1 = 0.0344912 loss)
I1022 20:41:27.503062  3845 sgd_solver.cpp:105] Iteration 22700, lr = 0.0001
I1022 20:41:45.277732  3845 solver.cpp:330] Iteration 22800, Testing net (#0)
I1022 20:41:46.456907  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:41:47.592880  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:41:47.592945  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0677068 (* 1 = 0.0677068 loss)
I1022 20:41:47.773329  3845 solver.cpp:218] Iteration 22800 (4.93335 iter/s, 20.2702s/100 iters), loss = 0.00116455
I1022 20:41:47.773362  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0011645 (* 1 = 0.0011645 loss)
I1022 20:41:47.773370  3845 sgd_solver.cpp:105] Iteration 22800, lr = 0.0001
I1022 20:41:58.387625  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:42:05.724970  3845 solver.cpp:218] Iteration 22900 (5.57055 iter/s, 17.9516s/100 iters), loss = 0.00947967
I1022 20:42:05.725003  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00947957 (* 1 = 0.00947957 loss)
I1022 20:42:05.725009  3845 sgd_solver.cpp:105] Iteration 22900, lr = 0.0001
I1022 20:42:23.484169  3845 solver.cpp:330] Iteration 23000, Testing net (#0)
I1022 20:42:24.630713  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:42:25.799562  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:42:25.799623  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0683057 (* 1 = 0.0683057 loss)
I1022 20:42:25.980281  3845 solver.cpp:218] Iteration 23000 (4.937 iter/s, 20.2552s/100 iters), loss = 0.00702319
I1022 20:42:25.980315  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00702309 (* 1 = 0.00702309 loss)
I1022 20:42:25.980324  3845 sgd_solver.cpp:105] Iteration 23000, lr = 0.0001
I1022 20:42:43.927630  3845 solver.cpp:218] Iteration 23100 (5.57188 iter/s, 17.9473s/100 iters), loss = 0.0079982
I1022 20:42:43.927661  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00799811 (* 1 = 0.00799811 loss)
I1022 20:42:43.927669  3845 sgd_solver.cpp:105] Iteration 23100, lr = 0.0001
I1022 20:43:01.700841  3845 solver.cpp:330] Iteration 23200, Testing net (#0)
I1022 20:43:02.846002  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:43:04.016141  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:43:04.016202  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0695833 (* 1 = 0.0695833 loss)
I1022 20:43:04.197728  3845 solver.cpp:218] Iteration 23200 (4.9334 iter/s, 20.27s/100 iters), loss = 0.0144818
I1022 20:43:04.197764  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0144816 (* 1 = 0.0144816 loss)
I1022 20:43:04.197772  3845 sgd_solver.cpp:105] Iteration 23200, lr = 0.0001
I1022 20:43:04.223302  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:43:22.145457  3845 solver.cpp:218] Iteration 23300 (5.57176 iter/s, 17.9476s/100 iters), loss = 0.00474225
I1022 20:43:22.145488  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00474216 (* 1 = 0.00474216 loss)
I1022 20:43:22.145495  3845 sgd_solver.cpp:105] Iteration 23300, lr = 0.0001
I1022 20:43:39.913982  3845 solver.cpp:330] Iteration 23400, Testing net (#0)
I1022 20:43:41.057988  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:43:42.228356  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:43:42.228415  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0698376 (* 1 = 0.0698376 loss)
I1022 20:43:42.409168  3845 solver.cpp:218] Iteration 23400 (4.93495 iter/s, 20.2636s/100 iters), loss = 0.00504639
I1022 20:43:42.409198  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0050463 (* 1 = 0.0050463 loss)
I1022 20:43:42.409205  3845 sgd_solver.cpp:105] Iteration 23400, lr = 0.0001
I1022 20:44:00.359226  3845 solver.cpp:218] Iteration 23500 (5.57104 iter/s, 17.95s/100 iters), loss = 0.0231575
I1022 20:44:00.359256  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0231574 (* 1 = 0.0231574 loss)
I1022 20:44:00.359263  3845 sgd_solver.cpp:105] Iteration 23500, lr = 0.0001
I1022 20:44:07.919100  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:44:18.132781  3845 solver.cpp:330] Iteration 23600, Testing net (#0)
I1022 20:44:19.277151  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:44:20.448485  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1022 20:44:20.448534  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0676895 (* 1 = 0.0676895 loss)
I1022 20:44:20.630013  3845 solver.cpp:218] Iteration 23600 (4.93323 iter/s, 20.2707s/100 iters), loss = 0.00100611
I1022 20:44:20.630044  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100604 (* 1 = 0.00100604 loss)
I1022 20:44:20.630051  3845 sgd_solver.cpp:105] Iteration 23600, lr = 0.0001
I1022 20:44:38.587352  3845 solver.cpp:218] Iteration 23700 (5.56878 iter/s, 17.9573s/100 iters), loss = 0.0340533
I1022 20:44:38.587383  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0340532 (* 1 = 0.0340532 loss)
I1022 20:44:38.587388  3845 sgd_solver.cpp:105] Iteration 23700, lr = 0.0001
I1022 20:44:56.371896  3845 solver.cpp:330] Iteration 23800, Testing net (#0)
I1022 20:44:57.481747  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:44:58.687062  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:44:58.687124  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0710109 (* 1 = 0.0710109 loss)
I1022 20:44:58.868160  3845 solver.cpp:218] Iteration 23800 (4.93079 iter/s, 20.2807s/100 iters), loss = 0.0430949
I1022 20:44:58.868203  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0430949 (* 1 = 0.0430949 loss)
I1022 20:44:58.868211  3845 sgd_solver.cpp:105] Iteration 23800, lr = 0.0001
I1022 20:45:13.795336  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:45:16.832576  3845 solver.cpp:218] Iteration 23900 (5.56659 iter/s, 17.9643s/100 iters), loss = 0.00935537
I1022 20:45:16.832607  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00935528 (* 1 = 0.00935528 loss)
I1022 20:45:16.832612  3845 sgd_solver.cpp:105] Iteration 23900, lr = 0.0001
I1022 20:45:34.614367  3845 solver.cpp:330] Iteration 24000, Testing net (#0)
I1022 20:45:35.723616  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:45:36.929708  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1022 20:45:36.929776  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0668203 (* 1 = 0.0668203 loss)
I1022 20:45:37.110424  3845 solver.cpp:218] Iteration 24000 (4.93151 iter/s, 20.2778s/100 iters), loss = 0.00313991
I1022 20:45:37.110456  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00313981 (* 1 = 0.00313981 loss)
I1022 20:45:37.110465  3845 sgd_solver.cpp:105] Iteration 24000, lr = 0.0001
I1022 20:45:55.049691  3845 solver.cpp:218] Iteration 24100 (5.57439 iter/s, 17.9392s/100 iters), loss = 0.0035494
I1022 20:45:55.049723  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0035493 (* 1 = 0.0035493 loss)
I1022 20:45:55.049729  3845 sgd_solver.cpp:105] Iteration 24100, lr = 0.0001
I1022 20:46:12.815309  3845 solver.cpp:330] Iteration 24200, Testing net (#0)
I1022 20:46:13.924641  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:46:15.130913  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1022 20:46:15.130967  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0665622 (* 1 = 0.0665622 loss)
I1022 20:46:15.312204  3845 solver.cpp:218] Iteration 24200 (4.93524 iter/s, 20.2624s/100 iters), loss = 0.00231457
I1022 20:46:15.312238  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00231446 (* 1 = 0.00231446 loss)
I1022 20:46:15.312245  3845 sgd_solver.cpp:105] Iteration 24200, lr = 0.0001
I1022 20:46:19.647629  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:46:33.261262  3845 solver.cpp:218] Iteration 24300 (5.57135 iter/s, 17.949s/100 iters), loss = 0.00726856
I1022 20:46:33.261298  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00726848 (* 1 = 0.00726848 loss)
I1022 20:46:33.261307  3845 sgd_solver.cpp:105] Iteration 24300, lr = 0.0001
I1022 20:46:51.032054  3845 solver.cpp:330] Iteration 24400, Testing net (#0)
I1022 20:46:52.140029  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:46:53.349031  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1022 20:46:53.349097  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0678387 (* 1 = 0.0678387 loss)
I1022 20:46:53.530383  3845 solver.cpp:218] Iteration 24400 (4.93363 iter/s, 20.269s/100 iters), loss = 0.0134994
I1022 20:46:53.530416  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134993 (* 1 = 0.0134993 loss)
I1022 20:46:53.530424  3845 sgd_solver.cpp:105] Iteration 24400, lr = 0.0001
I1022 20:47:11.476418  3845 solver.cpp:218] Iteration 24500 (5.57229 iter/s, 17.9459s/100 iters), loss = 0.000839699
I1022 20:47:11.476450  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000839635 (* 1 = 0.000839635 loss)
I1022 20:47:11.476459  3845 sgd_solver.cpp:105] Iteration 24500, lr = 0.0001
I1022 20:47:23.170878  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:47:29.251976  3845 solver.cpp:330] Iteration 24600, Testing net (#0)
I1022 20:47:30.326416  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:47:31.567600  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:47:31.567648  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0681985 (* 1 = 0.0681985 loss)
I1022 20:47:31.747788  3845 solver.cpp:218] Iteration 24600 (4.93309 iter/s, 20.2713s/100 iters), loss = 0.00644071
I1022 20:47:31.747820  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00644066 (* 1 = 0.00644066 loss)
I1022 20:47:31.747828  3845 sgd_solver.cpp:105] Iteration 24600, lr = 0.0001
I1022 20:47:49.678867  3845 solver.cpp:218] Iteration 24700 (5.57694 iter/s, 17.931s/100 iters), loss = 0.00359571
I1022 20:47:49.678915  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00359565 (* 1 = 0.00359565 loss)
I1022 20:47:49.678922  3845 sgd_solver.cpp:105] Iteration 24700, lr = 0.0001
I1022 20:48:07.440963  3845 solver.cpp:330] Iteration 24800, Testing net (#0)
I1022 20:48:08.513890  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:48:09.756652  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:48:09.756717  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0712606 (* 1 = 0.0712606 loss)
I1022 20:48:09.937783  3845 solver.cpp:218] Iteration 24800 (4.93612 iter/s, 20.2588s/100 iters), loss = 0.0118356
I1022 20:48:09.937818  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118356 (* 1 = 0.0118356 loss)
I1022 20:48:09.937824  3845 sgd_solver.cpp:105] Iteration 24800, lr = 0.0001
I1022 20:48:27.885942  3845 solver.cpp:218] Iteration 24900 (5.57163 iter/s, 17.9481s/100 iters), loss = 0.022862
I1022 20:48:27.885974  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.022862 (* 1 = 0.022862 loss)
I1022 20:48:27.885982  3845 sgd_solver.cpp:105] Iteration 24900, lr = 0.0001
I1022 20:48:29.166937  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:48:45.660370  3845 solver.cpp:330] Iteration 25000, Testing net (#0)
I1022 20:48:46.732861  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:48:47.975432  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:48:47.975488  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0693004 (* 1 = 0.0693004 loss)
I1022 20:48:48.156646  3845 solver.cpp:218] Iteration 25000 (4.93325 iter/s, 20.2706s/100 iters), loss = 0.0027892
I1022 20:48:48.156677  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00278918 (* 1 = 0.00278918 loss)
I1022 20:48:48.156683  3845 sgd_solver.cpp:105] Iteration 25000, lr = 0.0001
I1022 20:49:06.106004  3845 solver.cpp:218] Iteration 25100 (5.57125 iter/s, 17.9493s/100 iters), loss = 0.000442825
I1022 20:49:06.106048  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000442792 (* 1 = 0.000442792 loss)
I1022 20:49:06.106055  3845 sgd_solver.cpp:105] Iteration 25100, lr = 0.0001
I1022 20:49:23.875986  3845 solver.cpp:330] Iteration 25200, Testing net (#0)
I1022 20:49:24.946442  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:49:26.191148  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:49:26.191213  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0690823 (* 1 = 0.0690823 loss)
I1022 20:49:26.371929  3845 solver.cpp:218] Iteration 25200 (4.93442 iter/s, 20.2658s/100 iters), loss = 0.00233631
I1022 20:49:26.371964  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00233629 (* 1 = 0.00233629 loss)
I1022 20:49:26.371971  3845 sgd_solver.cpp:105] Iteration 25200, lr = 0.0001
I1022 20:49:35.012706  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:49:44.324199  3845 solver.cpp:218] Iteration 25300 (5.57035 iter/s, 17.9522s/100 iters), loss = 0.0148302
I1022 20:49:44.324231  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148302 (* 1 = 0.0148302 loss)
I1022 20:49:44.324239  3845 sgd_solver.cpp:105] Iteration 25300, lr = 0.0001
I1022 20:50:02.082099  3845 solver.cpp:330] Iteration 25400, Testing net (#0)
I1022 20:50:03.120548  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:50:04.398012  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:50:04.398073  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0686372 (* 1 = 0.0686372 loss)
I1022 20:50:04.579179  3845 solver.cpp:218] Iteration 25400 (4.93708 iter/s, 20.2549s/100 iters), loss = 0.0354064
I1022 20:50:04.579211  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0354064 (* 1 = 0.0354064 loss)
I1022 20:50:04.579218  3845 sgd_solver.cpp:105] Iteration 25400, lr = 0.0001
I1022 20:50:22.526317  3845 solver.cpp:218] Iteration 25500 (5.57194 iter/s, 17.9471s/100 iters), loss = 0.00258031
I1022 20:50:22.526361  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00258028 (* 1 = 0.00258028 loss)
I1022 20:50:22.526370  3845 sgd_solver.cpp:105] Iteration 25500, lr = 0.0001
I1022 20:50:38.529217  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:50:40.302570  3845 solver.cpp:330] Iteration 25600, Testing net (#0)
I1022 20:50:41.339861  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:50:42.618507  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:50:42.618567  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0678499 (* 1 = 0.0678499 loss)
I1022 20:50:42.799686  3845 solver.cpp:218] Iteration 25600 (4.9326 iter/s, 20.2733s/100 iters), loss = 0.0430176
I1022 20:50:42.799718  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0430176 (* 1 = 0.0430176 loss)
I1022 20:50:42.799726  3845 sgd_solver.cpp:105] Iteration 25600, lr = 0.0001
I1022 20:51:00.743702  3845 solver.cpp:218] Iteration 25700 (5.57291 iter/s, 17.9439s/100 iters), loss = 0.00521455
I1022 20:51:00.743733  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00521453 (* 1 = 0.00521453 loss)
I1022 20:51:00.743741  3845 sgd_solver.cpp:105] Iteration 25700, lr = 0.0001
I1022 20:51:18.515014  3845 solver.cpp:330] Iteration 25800, Testing net (#0)
I1022 20:51:19.551915  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:51:20.831316  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:51:20.831377  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0694947 (* 1 = 0.0694947 loss)
I1022 20:51:21.012293  3845 solver.cpp:218] Iteration 25800 (4.93376 iter/s, 20.2685s/100 iters), loss = 0.00601207
I1022 20:51:21.012327  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00601206 (* 1 = 0.00601206 loss)
I1022 20:51:21.012346  3845 sgd_solver.cpp:105] Iteration 25800, lr = 0.0001
I1022 20:51:38.948972  3845 solver.cpp:218] Iteration 25900 (5.57519 iter/s, 17.9366s/100 iters), loss = 0.00112557
I1022 20:51:38.949004  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00112556 (* 1 = 0.00112556 loss)
I1022 20:51:38.949012  3845 sgd_solver.cpp:105] Iteration 25900, lr = 0.0001
I1022 20:51:44.358736  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:51:56.711225  3845 solver.cpp:330] Iteration 26000, Testing net (#0)
I1022 20:51:57.746759  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:51:59.026688  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:51:59.026757  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0706365 (* 1 = 0.0706365 loss)
I1022 20:51:59.207705  3845 solver.cpp:218] Iteration 26000 (4.93616 iter/s, 20.2586s/100 iters), loss = 0.00135066
I1022 20:51:59.207744  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00135062 (* 1 = 0.00135062 loss)
I1022 20:51:59.207752  3845 sgd_solver.cpp:105] Iteration 26000, lr = 0.0001
I1022 20:52:17.155652  3845 solver.cpp:218] Iteration 26100 (5.57169 iter/s, 17.9479s/100 iters), loss = 0.00542546
I1022 20:52:17.155683  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00542541 (* 1 = 0.00542541 loss)
I1022 20:52:17.155690  3845 sgd_solver.cpp:105] Iteration 26100, lr = 0.0001
I1022 20:52:34.926545  3845 solver.cpp:330] Iteration 26200, Testing net (#0)
I1022 20:52:35.928967  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:52:37.241956  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:52:37.242020  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0731597 (* 1 = 0.0731597 loss)
I1022 20:52:37.423279  3845 solver.cpp:218] Iteration 26200 (4.934 iter/s, 20.2675s/100 iters), loss = 0.00849323
I1022 20:52:37.423315  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00849318 (* 1 = 0.00849318 loss)
I1022 20:52:37.423321  3845 sgd_solver.cpp:105] Iteration 26200, lr = 0.0001
I1022 20:52:50.371309  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:52:55.377957  3845 solver.cpp:218] Iteration 26300 (5.5696 iter/s, 17.9546s/100 iters), loss = 0.0254201
I1022 20:52:55.377990  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0254201 (* 1 = 0.0254201 loss)
I1022 20:52:55.377997  3845 sgd_solver.cpp:105] Iteration 26300, lr = 0.0001
I1022 20:53:13.144901  3845 solver.cpp:330] Iteration 26400, Testing net (#0)
I1022 20:53:14.146212  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:53:15.460041  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:53:15.460101  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0718912 (* 1 = 0.0718912 loss)
I1022 20:53:15.640771  3845 solver.cpp:218] Iteration 26400 (4.93517 iter/s, 20.2627s/100 iters), loss = 0.0330577
I1022 20:53:15.640803  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0330577 (* 1 = 0.0330577 loss)
I1022 20:53:15.640811  3845 sgd_solver.cpp:105] Iteration 26400, lr = 0.0001
I1022 20:53:33.582669  3845 solver.cpp:218] Iteration 26500 (5.57357 iter/s, 17.9418s/100 iters), loss = 0.0268508
I1022 20:53:33.582702  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0268508 (* 1 = 0.0268508 loss)
I1022 20:53:33.582710  3845 sgd_solver.cpp:105] Iteration 26500, lr = 0.0001
I1022 20:53:51.346395  3845 solver.cpp:330] Iteration 26600, Testing net (#0)
I1022 20:53:52.345155  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:53:53.660753  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:53:53.660815  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0701573 (* 1 = 0.0701573 loss)
I1022 20:53:53.841387  3845 solver.cpp:218] Iteration 26600 (4.93617 iter/s, 20.2586s/100 iters), loss = 0.000231086
I1022 20:53:53.841420  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000231057 (* 1 = 0.000231057 loss)
I1022 20:53:53.841428  3845 sgd_solver.cpp:105] Iteration 26600, lr = 0.0001
I1022 20:53:56.200598  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:54:11.792392  3845 solver.cpp:218] Iteration 26700 (5.57074 iter/s, 17.9509s/100 iters), loss = 0.0173145
I1022 20:54:11.792423  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0173145 (* 1 = 0.0173145 loss)
I1022 20:54:11.792429  3845 sgd_solver.cpp:105] Iteration 26700, lr = 0.0001
I1022 20:54:29.562826  3845 solver.cpp:330] Iteration 26800, Testing net (#0)
I1022 20:54:30.561635  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:54:31.878341  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:54:31.878404  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0687844 (* 1 = 0.0687844 loss)
I1022 20:54:32.059181  3845 solver.cpp:218] Iteration 26800 (4.9342 iter/s, 20.2667s/100 iters), loss = 0.0113702
I1022 20:54:32.059214  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113702 (* 1 = 0.0113702 loss)
I1022 20:54:32.059221  3845 sgd_solver.cpp:105] Iteration 26800, lr = 0.0001
I1022 20:54:50.006641  3845 solver.cpp:218] Iteration 26900 (5.57184 iter/s, 17.9474s/100 iters), loss = 0.000747181
I1022 20:54:50.006673  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000747163 (* 1 = 0.000747163 loss)
I1022 20:54:50.006681  3845 sgd_solver.cpp:105] Iteration 26900, lr = 0.0001
I1022 20:54:59.762759  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:55:07.857992  3845 solver.cpp:330] Iteration 27000, Testing net (#0)
I1022 20:55:08.823197  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:55:10.171974  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:55:10.172022  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0677541 (* 1 = 0.0677541 loss)
I1022 20:55:10.351119  3845 solver.cpp:218] Iteration 27000 (4.91536 iter/s, 20.3444s/100 iters), loss = 0.00927603
I1022 20:55:10.351151  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00927599 (* 1 = 0.00927599 loss)
I1022 20:55:10.351158  3845 sgd_solver.cpp:105] Iteration 27000, lr = 0.0001
I1022 20:55:28.335371  3845 solver.cpp:218] Iteration 27100 (5.56044 iter/s, 17.9842s/100 iters), loss = 0.00142382
I1022 20:55:28.335403  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00142379 (* 1 = 0.00142379 loss)
I1022 20:55:28.335410  3845 sgd_solver.cpp:105] Iteration 27100, lr = 0.0001
I1022 20:55:46.095337  3845 solver.cpp:330] Iteration 27200, Testing net (#0)
I1022 20:55:47.060549  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:55:48.410907  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1022 20:55:48.410969  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.074055 (* 1 = 0.074055 loss)
I1022 20:55:48.591977  3845 solver.cpp:218] Iteration 27200 (4.93668 iter/s, 20.2565s/100 iters), loss = 0.000942325
I1022 20:55:48.592008  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000942277 (* 1 = 0.000942277 loss)
I1022 20:55:48.592015  3845 sgd_solver.cpp:105] Iteration 27200, lr = 0.0001
I1022 20:56:05.677460  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:56:06.557539  3845 solver.cpp:218] Iteration 27300 (5.56623 iter/s, 17.9655s/100 iters), loss = 0.00435964
I1022 20:56:06.557569  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0043596 (* 1 = 0.0043596 loss)
I1022 20:56:06.557575  3845 sgd_solver.cpp:105] Iteration 27300, lr = 0.0001
I1022 20:56:24.338806  3845 solver.cpp:330] Iteration 27400, Testing net (#0)
I1022 20:56:25.303393  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:56:26.655138  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:56:26.655195  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0719564 (* 1 = 0.0719564 loss)
I1022 20:56:26.836391  3845 solver.cpp:218] Iteration 27400 (4.93126 iter/s, 20.2788s/100 iters), loss = 0.0114019
I1022 20:56:26.836421  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114018 (* 1 = 0.0114018 loss)
I1022 20:56:26.836427  3845 sgd_solver.cpp:105] Iteration 27400, lr = 0.0001
I1022 20:56:44.797073  3845 solver.cpp:218] Iteration 27500 (5.56774 iter/s, 17.9606s/100 iters), loss = 0.000240631
I1022 20:56:44.797116  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000240576 (* 1 = 0.000240576 loss)
I1022 20:56:44.797122  3845 sgd_solver.cpp:105] Iteration 27500, lr = 0.0001
I1022 20:57:02.581516  3845 solver.cpp:330] Iteration 27600, Testing net (#0)
I1022 20:57:03.544744  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:57:04.897761  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:57:04.897830  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0701331 (* 1 = 0.0701331 loss)
I1022 20:57:05.078454  3845 solver.cpp:218] Iteration 27600 (4.93065 iter/s, 20.2813s/100 iters), loss = 0.00181462
I1022 20:57:05.078486  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00181459 (* 1 = 0.00181459 loss)
I1022 20:57:05.078493  3845 sgd_solver.cpp:105] Iteration 27600, lr = 0.0001
I1022 20:57:11.742928  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:57:23.033844  3845 solver.cpp:218] Iteration 27700 (5.56938 iter/s, 17.9553s/100 iters), loss = 0.0180434
I1022 20:57:23.033874  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0180434 (* 1 = 0.0180434 loss)
I1022 20:57:23.033880  3845 sgd_solver.cpp:105] Iteration 27700, lr = 0.0001
I1022 20:57:40.812871  3845 solver.cpp:330] Iteration 27800, Testing net (#0)
I1022 20:57:41.743031  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:57:43.128402  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:57:43.128470  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0688093 (* 1 = 0.0688093 loss)
I1022 20:57:43.309149  3845 solver.cpp:218] Iteration 27800 (4.93213 iter/s, 20.2752s/100 iters), loss = 0.0115712
I1022 20:57:43.309181  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115712 (* 1 = 0.0115712 loss)
I1022 20:57:43.309188  3845 sgd_solver.cpp:105] Iteration 27800, lr = 0.0001
I1022 20:58:01.268712  3845 solver.cpp:218] Iteration 27900 (5.56809 iter/s, 17.9595s/100 iters), loss = 0.0105639
I1022 20:58:01.268740  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105639 (* 1 = 0.0105639 loss)
I1022 20:58:01.268748  3845 sgd_solver.cpp:105] Iteration 27900, lr = 0.0001
I1022 20:58:15.298902  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:58:19.057287  3845 solver.cpp:330] Iteration 28000, Testing net (#0)
I1022 20:58:19.986817  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:58:21.373672  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:58:21.373728  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0669977 (* 1 = 0.0669977 loss)
I1022 20:58:21.554153  3845 solver.cpp:218] Iteration 28000 (4.92966 iter/s, 20.2854s/100 iters), loss = 0.000471126
I1022 20:58:21.554183  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000471098 (* 1 = 0.000471098 loss)
I1022 20:58:21.554189  3845 sgd_solver.cpp:105] Iteration 28000, lr = 0.0001
I1022 20:58:39.508925  3845 solver.cpp:218] Iteration 28100 (5.56957 iter/s, 17.9547s/100 iters), loss = 0.000859862
I1022 20:58:39.508955  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000859828 (* 1 = 0.000859828 loss)
I1022 20:58:39.508961  3845 sgd_solver.cpp:105] Iteration 28100, lr = 0.0001
I1022 20:58:57.289616  3845 solver.cpp:330] Iteration 28200, Testing net (#0)
I1022 20:58:58.218094  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:58:59.605147  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:58:59.605213  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0674241 (* 1 = 0.0674241 loss)
I1022 20:58:59.786301  3845 solver.cpp:218] Iteration 28200 (4.93162 iter/s, 20.2773s/100 iters), loss = 0.00583821
I1022 20:58:59.786337  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00583819 (* 1 = 0.00583819 loss)
I1022 20:58:59.786345  3845 sgd_solver.cpp:105] Iteration 28200, lr = 0.0001
I1022 20:59:17.736553  3845 solver.cpp:218] Iteration 28300 (5.57098 iter/s, 17.9502s/100 iters), loss = 0.00266527
I1022 20:59:17.736583  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00266526 (* 1 = 0.00266526 loss)
I1022 20:59:17.736589  3845 sgd_solver.cpp:105] Iteration 28300, lr = 0.0001
I1022 20:59:21.169421  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:59:35.513029  3845 solver.cpp:330] Iteration 28400, Testing net (#0)
I1022 20:59:36.440466  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 20:59:37.829319  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 20:59:37.829383  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0688553 (* 1 = 0.0688553 loss)
I1022 20:59:38.010190  3845 solver.cpp:218] Iteration 28400 (4.93253 iter/s, 20.2736s/100 iters), loss = 0.00149395
I1022 20:59:38.010221  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00149393 (* 1 = 0.00149393 loss)
I1022 20:59:38.010229  3845 sgd_solver.cpp:105] Iteration 28400, lr = 0.0001
I1022 20:59:55.969002  3845 solver.cpp:218] Iteration 28500 (5.56832 iter/s, 17.9587s/100 iters), loss = 0.0054369
I1022 20:59:55.969033  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00543686 (* 1 = 0.00543686 loss)
I1022 20:59:55.969038  3845 sgd_solver.cpp:105] Iteration 28500, lr = 0.0001
I1022 21:00:13.755450  3845 solver.cpp:330] Iteration 28600, Testing net (#0)
I1022 21:00:14.649389  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 21:00:16.070631  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 21:00:16.070696  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0699504 (* 1 = 0.0699504 loss)
I1022 21:00:16.251987  3845 solver.cpp:218] Iteration 28600 (4.93026 iter/s, 20.2829s/100 iters), loss = 0.0232938
I1022 21:00:16.252022  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0232937 (* 1 = 0.0232937 loss)
I1022 21:00:16.252029  3845 sgd_solver.cpp:105] Iteration 28600, lr = 0.0001
I1022 21:00:27.052918  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 21:00:34.222209  3845 solver.cpp:218] Iteration 28700 (5.56479 iter/s, 17.9701s/100 iters), loss = 0.00732325
I1022 21:00:34.222239  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00732324 (* 1 = 0.00732324 loss)
I1022 21:00:34.222245  3845 sgd_solver.cpp:105] Iteration 28700, lr = 0.0001
I1022 21:00:51.999560  3845 solver.cpp:330] Iteration 28800, Testing net (#0)
I1022 21:00:52.891927  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 21:00:54.315160  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1022 21:00:54.315232  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0740771 (* 1 = 0.0740771 loss)
I1022 21:00:54.495965  3845 solver.cpp:218] Iteration 28800 (4.9325 iter/s, 20.2737s/100 iters), loss = 0.0014329
I1022 21:00:54.495995  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00143288 (* 1 = 0.00143288 loss)
I1022 21:00:54.496002  3845 sgd_solver.cpp:105] Iteration 28800, lr = 0.0001
I1022 21:01:12.449445  3845 solver.cpp:218] Iteration 28900 (5.56997 iter/s, 17.9534s/100 iters), loss = 0.0323278
I1022 21:01:12.449477  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0323278 (* 1 = 0.0323278 loss)
I1022 21:01:12.449483  3845 sgd_solver.cpp:105] Iteration 28900, lr = 0.0001
I1022 21:01:30.226871  3845 solver.cpp:330] Iteration 29000, Testing net (#0)
I1022 21:01:31.118980  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 21:01:32.542739  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 21:01:32.542803  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0701243 (* 1 = 0.0701243 loss)
I1022 21:01:32.723470  3845 solver.cpp:218] Iteration 29000 (4.93244 iter/s, 20.2739s/100 iters), loss = 0.00643551
I1022 21:01:32.723500  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0064355 (* 1 = 0.0064355 loss)
I1022 21:01:32.723508  3845 sgd_solver.cpp:105] Iteration 29000, lr = 0.0001
I1022 21:01:33.101816  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 21:01:50.683779  3845 solver.cpp:218] Iteration 29100 (5.56786 iter/s, 17.9602s/100 iters), loss = 0.0484604
I1022 21:01:50.683807  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0484604 (* 1 = 0.0484604 loss)
I1022 21:01:50.683815  3845 sgd_solver.cpp:105] Iteration 29100, lr = 0.0001
I1022 21:02:08.466802  3845 solver.cpp:330] Iteration 29200, Testing net (#0)
I1022 21:02:09.358666  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 21:02:10.782965  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 21:02:10.783022  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0683557 (* 1 = 0.0683557 loss)
I1022 21:02:10.964589  3845 solver.cpp:218] Iteration 29200 (4.93079 iter/s, 20.2807s/100 iters), loss = 0.00599033
I1022 21:02:10.964619  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00599034 (* 1 = 0.00599034 loss)
I1022 21:02:10.964627  3845 sgd_solver.cpp:105] Iteration 29200, lr = 0.0001
I1022 21:02:28.923365  3845 solver.cpp:218] Iteration 29300 (5.56833 iter/s, 17.9587s/100 iters), loss = 0.00300143
I1022 21:02:28.923394  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00300145 (* 1 = 0.00300145 loss)
I1022 21:02:28.923401  3845 sgd_solver.cpp:105] Iteration 29300, lr = 0.0001
I1022 21:02:36.670459  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 21:02:46.696772  3845 solver.cpp:330] Iteration 29400, Testing net (#0)
I1022 21:02:47.554600  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 21:02:49.012253  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 21:02:49.012315  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0666381 (* 1 = 0.0666381 loss)
I1022 21:02:49.193001  3845 solver.cpp:218] Iteration 29400 (4.93351 iter/s, 20.2696s/100 iters), loss = 0.0155532
I1022 21:02:49.193048  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155532 (* 1 = 0.0155532 loss)
I1022 21:02:49.193058  3845 sgd_solver.cpp:105] Iteration 29400, lr = 0.0001
I1022 21:03:07.134861  3845 solver.cpp:218] Iteration 29500 (5.57359 iter/s, 17.9418s/100 iters), loss = 0.00250274
I1022 21:03:07.134904  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00250276 (* 1 = 0.00250276 loss)
I1022 21:03:07.134910  3845 sgd_solver.cpp:105] Iteration 29500, lr = 0.0001
I1022 21:03:24.895726  3845 solver.cpp:330] Iteration 29600, Testing net (#0)
I1022 21:03:25.751655  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 21:03:27.210409  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 21:03:27.210469  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0672852 (* 1 = 0.0672852 loss)
I1022 21:03:27.391413  3845 solver.cpp:218] Iteration 29600 (4.9367 iter/s, 20.2565s/100 iters), loss = 0.00096526
I1022 21:03:27.391445  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000965297 (* 1 = 0.000965297 loss)
I1022 21:03:27.391453  3845 sgd_solver.cpp:105] Iteration 29600, lr = 0.0001
I1022 21:03:42.495193  3854 data_layer.cpp:73] Restarting data prefetching from start.
I1022 21:03:45.344350  3845 solver.cpp:218] Iteration 29700 (5.57014 iter/s, 17.9529s/100 iters), loss = 0.00117056
I1022 21:03:45.344382  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0011706 (* 1 = 0.0011706 loss)
I1022 21:03:45.344388  3845 sgd_solver.cpp:105] Iteration 29700, lr = 0.0001
I1022 21:04:03.114043  3845 solver.cpp:330] Iteration 29800, Testing net (#0)
I1022 21:04:03.969480  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 21:04:05.429299  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 21:04:05.429363  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0677774 (* 1 = 0.0677774 loss)
I1022 21:04:05.610419  3845 solver.cpp:218] Iteration 29800 (4.93438 iter/s, 20.266s/100 iters), loss = 0.00874161
I1022 21:04:05.610455  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00874165 (* 1 = 0.00874165 loss)
I1022 21:04:05.610462  3845 sgd_solver.cpp:105] Iteration 29800, lr = 0.0001
I1022 21:04:23.557384  3845 solver.cpp:218] Iteration 29900 (5.572 iter/s, 17.9469s/100 iters), loss = 0.0295245
I1022 21:04:23.557415  3845 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0295246 (* 1 = 0.0295246 loss)
I1022 21:04:23.557423  3845 sgd_solver.cpp:105] Iteration 29900, lr = 0.0001
I1022 21:04:41.327072  3845 solver.cpp:447] Snapshotting to binary proto file xn/English_orange/snapshot/res20/res20_relu_iter_30000.caffemodel
I1022 21:04:41.334534  3845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/English_orange/snapshot/res20/res20_relu_iter_30000.solverstate
I1022 21:04:41.387125  3845 solver.cpp:310] Iteration 30000, loss = 0.00928328
I1022 21:04:41.387164  3845 solver.cpp:330] Iteration 30000, Testing net (#0)
I1022 21:04:42.241874  3855 data_layer.cpp:73] Restarting data prefetching from start.
I1022 21:04:43.702906  3845 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1022 21:04:43.702971  3845 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0687029 (* 1 = 0.0687029 loss)
I1022 21:04:43.702980  3845 solver.cpp:315] Optimization Done.
I1022 21:04:43.702982  3845 caffe.cpp:259] Optimization Done.
