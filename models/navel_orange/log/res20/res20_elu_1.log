I1023 16:54:37.526839  5058 caffe.cpp:218] Using GPUs 0
I1023 16:54:37.561043  5058 caffe.cpp:223] GPU 0: GeForce GTX 1080
I1023 16:54:37.789863  5058 solver.cpp:44] Initializing solver from parameters: 
test_iter: 64
test_interval: 200
base_lr: 0.01
display: 100
max_iter: 30000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 30000
snapshot_prefix: "xn/English_orange/snapshot/res20/res20_elu_1"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/English_orange/neural/res20/res20_elu_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 10000
stepvalue: 20000
I1023 16:54:37.789997  5058 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/English_orange/neural/res20/res20_elu_train_test.prototxt
I1023 16:54:37.791189  5058 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/English_orange/neural/res20/res20_elu_train_test.prototxt
I1023 16:54:37.791199  5058 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1023 16:54:37.791316  5058 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I1023 16:54:37.791375  5058 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I1023 16:54:37.791743  5058 net.cpp:51] Initializing net from parameters: 
name: "resnet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_file: "/home/x306/caffe/xn/English_orange/data/orange1_mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/English_orange/data/train1_lmdb"
    batch_size: 8
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu1"
  type: "ELU"
  bottom: "Convolution1"
  top: "Convolution1"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu2"
  type: "ELU"
  bottom: "Convolution2"
  top: "Convolution2"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu3"
  type: "ELU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu4"
  type: "ELU"
  bottom: "Convolution4"
  top: "Convolution4"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu5"
  type: "ELU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu6"
  type: "ELU"
  bottom: "Convolution6"
  top: "Convolution6"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu7"
  type: "ELU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu8"
  type: "ELU"
  bottom: "Convolution9"
  top: "Convolution9"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu9"
  type: "ELU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu10"
  type: "ELU"
  bottom: "Convolution11"
  top: "Convolution11"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu11"
  type: "ELU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu12"
  type: "ELU"
  bottom: "Convolution13"
  top: "Convolution13"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu13"
  type: "ELU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu14"
  type: "ELU"
  bottom: "Convolution16"
  top: "Convolution16"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu15"
  type: "ELU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu16"
  type: "ELU"
  bottom: "Convolution18"
  top: "Convolution18"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu17"
  type: "ELU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu18"
  type: "ELU"
  bottom: "Convolution20"
  top: "Convolution20"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu19"
  type: "ELU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
I1023 16:54:37.792114  5058 layer_factory.hpp:77] Creating layer Data1
I1023 16:54:37.792188  5058 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/English_orange/data/train1_lmdb
I1023 16:54:37.792207  5058 net.cpp:84] Creating Layer Data1
I1023 16:54:37.792212  5058 net.cpp:380] Data1 -> Data1
I1023 16:54:37.792227  5058 net.cpp:380] Data1 -> Data2
I1023 16:54:37.792237  5058 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/English_orange/data/orange1_mean.binaryproto
I1023 16:54:37.794540  5058 data_layer.cpp:45] output data size: 8,3,224,224
I1023 16:54:37.802798  5058 net.cpp:122] Setting up Data1
I1023 16:54:37.802829  5058 net.cpp:129] Top shape: 8 3 224 224 (1204224)
I1023 16:54:37.802837  5058 net.cpp:129] Top shape: 8 (8)
I1023 16:54:37.802841  5058 net.cpp:137] Memory required for data: 4816928
I1023 16:54:37.802855  5058 layer_factory.hpp:77] Creating layer Convolution1
I1023 16:54:37.802883  5058 net.cpp:84] Creating Layer Convolution1
I1023 16:54:37.802893  5058 net.cpp:406] Convolution1 <- Data1
I1023 16:54:37.802908  5058 net.cpp:380] Convolution1 -> Convolution1
I1023 16:54:37.950670  5058 net.cpp:122] Setting up Convolution1
I1023 16:54:37.950696  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.950700  5058 net.cpp:137] Memory required for data: 30507040
I1023 16:54:37.950716  5058 layer_factory.hpp:77] Creating layer BatchNorm1
I1023 16:54:37.950736  5058 net.cpp:84] Creating Layer BatchNorm1
I1023 16:54:37.950750  5058 net.cpp:406] BatchNorm1 <- Convolution1
I1023 16:54:37.950758  5058 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1023 16:54:37.950934  5058 net.cpp:122] Setting up BatchNorm1
I1023 16:54:37.950942  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.950943  5058 net.cpp:137] Memory required for data: 56197152
I1023 16:54:37.950951  5058 layer_factory.hpp:77] Creating layer Scale1
I1023 16:54:37.950971  5058 net.cpp:84] Creating Layer Scale1
I1023 16:54:37.950974  5058 net.cpp:406] Scale1 <- Convolution1
I1023 16:54:37.950979  5058 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1023 16:54:37.951063  5058 layer_factory.hpp:77] Creating layer Scale1
I1023 16:54:37.951210  5058 net.cpp:122] Setting up Scale1
I1023 16:54:37.951216  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.951220  5058 net.cpp:137] Memory required for data: 81887264
I1023 16:54:37.951223  5058 layer_factory.hpp:77] Creating layer elu1
I1023 16:54:37.951247  5058 net.cpp:84] Creating Layer elu1
I1023 16:54:37.951251  5058 net.cpp:406] elu1 <- Convolution1
I1023 16:54:37.951264  5058 net.cpp:367] elu1 -> Convolution1 (in-place)
I1023 16:54:37.951284  5058 net.cpp:122] Setting up elu1
I1023 16:54:37.951300  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.951303  5058 net.cpp:137] Memory required for data: 107577376
I1023 16:54:37.951306  5058 layer_factory.hpp:77] Creating layer Convolution1_elu1_0_split
I1023 16:54:37.951321  5058 net.cpp:84] Creating Layer Convolution1_elu1_0_split
I1023 16:54:37.951324  5058 net.cpp:406] Convolution1_elu1_0_split <- Convolution1
I1023 16:54:37.951340  5058 net.cpp:380] Convolution1_elu1_0_split -> Convolution1_elu1_0_split_0
I1023 16:54:37.951349  5058 net.cpp:380] Convolution1_elu1_0_split -> Convolution1_elu1_0_split_1
I1023 16:54:37.951400  5058 net.cpp:122] Setting up Convolution1_elu1_0_split
I1023 16:54:37.951417  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.951424  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.951437  5058 net.cpp:137] Memory required for data: 158957600
I1023 16:54:37.951441  5058 layer_factory.hpp:77] Creating layer Convolution2
I1023 16:54:37.951450  5058 net.cpp:84] Creating Layer Convolution2
I1023 16:54:37.951465  5058 net.cpp:406] Convolution2 <- Convolution1_elu1_0_split_0
I1023 16:54:37.951473  5058 net.cpp:380] Convolution2 -> Convolution2
I1023 16:54:37.952888  5058 net.cpp:122] Setting up Convolution2
I1023 16:54:37.952898  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.952913  5058 net.cpp:137] Memory required for data: 184647712
I1023 16:54:37.952931  5058 layer_factory.hpp:77] Creating layer BatchNorm2
I1023 16:54:37.952940  5058 net.cpp:84] Creating Layer BatchNorm2
I1023 16:54:37.952955  5058 net.cpp:406] BatchNorm2 <- Convolution2
I1023 16:54:37.952973  5058 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1023 16:54:37.953138  5058 net.cpp:122] Setting up BatchNorm2
I1023 16:54:37.953145  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.953158  5058 net.cpp:137] Memory required for data: 210337824
I1023 16:54:37.953166  5058 layer_factory.hpp:77] Creating layer Scale2
I1023 16:54:37.953186  5058 net.cpp:84] Creating Layer Scale2
I1023 16:54:37.953191  5058 net.cpp:406] Scale2 <- Convolution2
I1023 16:54:37.953198  5058 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1023 16:54:37.953233  5058 layer_factory.hpp:77] Creating layer Scale2
I1023 16:54:37.953356  5058 net.cpp:122] Setting up Scale2
I1023 16:54:37.953362  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.953367  5058 net.cpp:137] Memory required for data: 236027936
I1023 16:54:37.953375  5058 layer_factory.hpp:77] Creating layer elu2
I1023 16:54:37.953383  5058 net.cpp:84] Creating Layer elu2
I1023 16:54:37.953389  5058 net.cpp:406] elu2 <- Convolution2
I1023 16:54:37.953395  5058 net.cpp:367] elu2 -> Convolution2 (in-place)
I1023 16:54:37.953400  5058 net.cpp:122] Setting up elu2
I1023 16:54:37.953404  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.953408  5058 net.cpp:137] Memory required for data: 261718048
I1023 16:54:37.953410  5058 layer_factory.hpp:77] Creating layer Convolution3
I1023 16:54:37.953416  5058 net.cpp:84] Creating Layer Convolution3
I1023 16:54:37.953419  5058 net.cpp:406] Convolution3 <- Convolution2
I1023 16:54:37.953423  5058 net.cpp:380] Convolution3 -> Convolution3
I1023 16:54:37.954322  5058 net.cpp:122] Setting up Convolution3
I1023 16:54:37.954334  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.954336  5058 net.cpp:137] Memory required for data: 287408160
I1023 16:54:37.954341  5058 layer_factory.hpp:77] Creating layer BatchNorm3
I1023 16:54:37.954355  5058 net.cpp:84] Creating Layer BatchNorm3
I1023 16:54:37.954358  5058 net.cpp:406] BatchNorm3 <- Convolution3
I1023 16:54:37.954362  5058 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1023 16:54:37.954507  5058 net.cpp:122] Setting up BatchNorm3
I1023 16:54:37.954514  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.954516  5058 net.cpp:137] Memory required for data: 313098272
I1023 16:54:37.954524  5058 layer_factory.hpp:77] Creating layer Scale3
I1023 16:54:37.954530  5058 net.cpp:84] Creating Layer Scale3
I1023 16:54:37.954532  5058 net.cpp:406] Scale3 <- Convolution3
I1023 16:54:37.954535  5058 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1023 16:54:37.954561  5058 layer_factory.hpp:77] Creating layer Scale3
I1023 16:54:37.955178  5058 net.cpp:122] Setting up Scale3
I1023 16:54:37.955188  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.955190  5058 net.cpp:137] Memory required for data: 338788384
I1023 16:54:37.955195  5058 layer_factory.hpp:77] Creating layer Eltwise1
I1023 16:54:37.955201  5058 net.cpp:84] Creating Layer Eltwise1
I1023 16:54:37.955204  5058 net.cpp:406] Eltwise1 <- Convolution1_elu1_0_split_1
I1023 16:54:37.955209  5058 net.cpp:406] Eltwise1 <- Convolution3
I1023 16:54:37.955212  5058 net.cpp:380] Eltwise1 -> Eltwise1
I1023 16:54:37.955232  5058 net.cpp:122] Setting up Eltwise1
I1023 16:54:37.955237  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.955240  5058 net.cpp:137] Memory required for data: 364478496
I1023 16:54:37.955243  5058 layer_factory.hpp:77] Creating layer elu3
I1023 16:54:37.955246  5058 net.cpp:84] Creating Layer elu3
I1023 16:54:37.955250  5058 net.cpp:406] elu3 <- Eltwise1
I1023 16:54:37.955253  5058 net.cpp:367] elu3 -> Eltwise1 (in-place)
I1023 16:54:37.955258  5058 net.cpp:122] Setting up elu3
I1023 16:54:37.955261  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.955265  5058 net.cpp:137] Memory required for data: 390168608
I1023 16:54:37.955267  5058 layer_factory.hpp:77] Creating layer Eltwise1_elu3_0_split
I1023 16:54:37.955271  5058 net.cpp:84] Creating Layer Eltwise1_elu3_0_split
I1023 16:54:37.955274  5058 net.cpp:406] Eltwise1_elu3_0_split <- Eltwise1
I1023 16:54:37.955277  5058 net.cpp:380] Eltwise1_elu3_0_split -> Eltwise1_elu3_0_split_0
I1023 16:54:37.955282  5058 net.cpp:380] Eltwise1_elu3_0_split -> Eltwise1_elu3_0_split_1
I1023 16:54:37.955304  5058 net.cpp:122] Setting up Eltwise1_elu3_0_split
I1023 16:54:37.955309  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.955313  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.955317  5058 net.cpp:137] Memory required for data: 441548832
I1023 16:54:37.955318  5058 layer_factory.hpp:77] Creating layer Convolution4
I1023 16:54:37.955327  5058 net.cpp:84] Creating Layer Convolution4
I1023 16:54:37.955329  5058 net.cpp:406] Convolution4 <- Eltwise1_elu3_0_split_0
I1023 16:54:37.955333  5058 net.cpp:380] Convolution4 -> Convolution4
I1023 16:54:37.956238  5058 net.cpp:122] Setting up Convolution4
I1023 16:54:37.956249  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.956252  5058 net.cpp:137] Memory required for data: 467238944
I1023 16:54:37.956257  5058 layer_factory.hpp:77] Creating layer BatchNorm4
I1023 16:54:37.956264  5058 net.cpp:84] Creating Layer BatchNorm4
I1023 16:54:37.956267  5058 net.cpp:406] BatchNorm4 <- Convolution4
I1023 16:54:37.956271  5058 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1023 16:54:37.956414  5058 net.cpp:122] Setting up BatchNorm4
I1023 16:54:37.956420  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.956423  5058 net.cpp:137] Memory required for data: 492929056
I1023 16:54:37.956429  5058 layer_factory.hpp:77] Creating layer Scale4
I1023 16:54:37.956434  5058 net.cpp:84] Creating Layer Scale4
I1023 16:54:37.956435  5058 net.cpp:406] Scale4 <- Convolution4
I1023 16:54:37.956439  5058 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1023 16:54:37.956465  5058 layer_factory.hpp:77] Creating layer Scale4
I1023 16:54:37.956583  5058 net.cpp:122] Setting up Scale4
I1023 16:54:37.956590  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.956593  5058 net.cpp:137] Memory required for data: 518619168
I1023 16:54:37.956598  5058 layer_factory.hpp:77] Creating layer elu4
I1023 16:54:37.956603  5058 net.cpp:84] Creating Layer elu4
I1023 16:54:37.956605  5058 net.cpp:406] elu4 <- Convolution4
I1023 16:54:37.956609  5058 net.cpp:367] elu4 -> Convolution4 (in-place)
I1023 16:54:37.956614  5058 net.cpp:122] Setting up elu4
I1023 16:54:37.956619  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.956621  5058 net.cpp:137] Memory required for data: 544309280
I1023 16:54:37.956624  5058 layer_factory.hpp:77] Creating layer Convolution5
I1023 16:54:37.956629  5058 net.cpp:84] Creating Layer Convolution5
I1023 16:54:37.956632  5058 net.cpp:406] Convolution5 <- Convolution4
I1023 16:54:37.956636  5058 net.cpp:380] Convolution5 -> Convolution5
I1023 16:54:37.957860  5058 net.cpp:122] Setting up Convolution5
I1023 16:54:37.957871  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.957875  5058 net.cpp:137] Memory required for data: 569999392
I1023 16:54:37.957880  5058 layer_factory.hpp:77] Creating layer BatchNorm5
I1023 16:54:37.957885  5058 net.cpp:84] Creating Layer BatchNorm5
I1023 16:54:37.957890  5058 net.cpp:406] BatchNorm5 <- Convolution5
I1023 16:54:37.957893  5058 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1023 16:54:37.958039  5058 net.cpp:122] Setting up BatchNorm5
I1023 16:54:37.958045  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.958048  5058 net.cpp:137] Memory required for data: 595689504
I1023 16:54:37.958056  5058 layer_factory.hpp:77] Creating layer Scale5
I1023 16:54:37.958061  5058 net.cpp:84] Creating Layer Scale5
I1023 16:54:37.958065  5058 net.cpp:406] Scale5 <- Convolution5
I1023 16:54:37.958068  5058 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1023 16:54:37.958093  5058 layer_factory.hpp:77] Creating layer Scale5
I1023 16:54:37.958202  5058 net.cpp:122] Setting up Scale5
I1023 16:54:37.958209  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.958211  5058 net.cpp:137] Memory required for data: 621379616
I1023 16:54:37.958215  5058 layer_factory.hpp:77] Creating layer Eltwise2
I1023 16:54:37.958220  5058 net.cpp:84] Creating Layer Eltwise2
I1023 16:54:37.958223  5058 net.cpp:406] Eltwise2 <- Eltwise1_elu3_0_split_1
I1023 16:54:37.958227  5058 net.cpp:406] Eltwise2 <- Convolution5
I1023 16:54:37.958231  5058 net.cpp:380] Eltwise2 -> Eltwise2
I1023 16:54:37.958247  5058 net.cpp:122] Setting up Eltwise2
I1023 16:54:37.958252  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.958256  5058 net.cpp:137] Memory required for data: 647069728
I1023 16:54:37.958257  5058 layer_factory.hpp:77] Creating layer elu5
I1023 16:54:37.958261  5058 net.cpp:84] Creating Layer elu5
I1023 16:54:37.958264  5058 net.cpp:406] elu5 <- Eltwise2
I1023 16:54:37.958267  5058 net.cpp:367] elu5 -> Eltwise2 (in-place)
I1023 16:54:37.958272  5058 net.cpp:122] Setting up elu5
I1023 16:54:37.958276  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.958279  5058 net.cpp:137] Memory required for data: 672759840
I1023 16:54:37.958281  5058 layer_factory.hpp:77] Creating layer Eltwise2_elu5_0_split
I1023 16:54:37.958284  5058 net.cpp:84] Creating Layer Eltwise2_elu5_0_split
I1023 16:54:37.958287  5058 net.cpp:406] Eltwise2_elu5_0_split <- Eltwise2
I1023 16:54:37.958290  5058 net.cpp:380] Eltwise2_elu5_0_split -> Eltwise2_elu5_0_split_0
I1023 16:54:37.958295  5058 net.cpp:380] Eltwise2_elu5_0_split -> Eltwise2_elu5_0_split_1
I1023 16:54:37.958317  5058 net.cpp:122] Setting up Eltwise2_elu5_0_split
I1023 16:54:37.958322  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.958325  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.958328  5058 net.cpp:137] Memory required for data: 724140064
I1023 16:54:37.958330  5058 layer_factory.hpp:77] Creating layer Convolution6
I1023 16:54:37.958344  5058 net.cpp:84] Creating Layer Convolution6
I1023 16:54:37.958348  5058 net.cpp:406] Convolution6 <- Eltwise2_elu5_0_split_0
I1023 16:54:37.958353  5058 net.cpp:380] Convolution6 -> Convolution6
I1023 16:54:37.959754  5058 net.cpp:122] Setting up Convolution6
I1023 16:54:37.959765  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.959769  5058 net.cpp:137] Memory required for data: 749830176
I1023 16:54:37.959774  5058 layer_factory.hpp:77] Creating layer BatchNorm6
I1023 16:54:37.959780  5058 net.cpp:84] Creating Layer BatchNorm6
I1023 16:54:37.959784  5058 net.cpp:406] BatchNorm6 <- Convolution6
I1023 16:54:37.959789  5058 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1023 16:54:37.959935  5058 net.cpp:122] Setting up BatchNorm6
I1023 16:54:37.959941  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.959944  5058 net.cpp:137] Memory required for data: 775520288
I1023 16:54:37.959949  5058 layer_factory.hpp:77] Creating layer Scale6
I1023 16:54:37.959954  5058 net.cpp:84] Creating Layer Scale6
I1023 16:54:37.959964  5058 net.cpp:406] Scale6 <- Convolution6
I1023 16:54:37.959969  5058 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1023 16:54:37.959995  5058 layer_factory.hpp:77] Creating layer Scale6
I1023 16:54:37.960111  5058 net.cpp:122] Setting up Scale6
I1023 16:54:37.960117  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.960120  5058 net.cpp:137] Memory required for data: 801210400
I1023 16:54:37.960124  5058 layer_factory.hpp:77] Creating layer elu6
I1023 16:54:37.960129  5058 net.cpp:84] Creating Layer elu6
I1023 16:54:37.960132  5058 net.cpp:406] elu6 <- Convolution6
I1023 16:54:37.960135  5058 net.cpp:367] elu6 -> Convolution6 (in-place)
I1023 16:54:37.960139  5058 net.cpp:122] Setting up elu6
I1023 16:54:37.960144  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.960146  5058 net.cpp:137] Memory required for data: 826900512
I1023 16:54:37.960149  5058 layer_factory.hpp:77] Creating layer Convolution7
I1023 16:54:37.960155  5058 net.cpp:84] Creating Layer Convolution7
I1023 16:54:37.960157  5058 net.cpp:406] Convolution7 <- Convolution6
I1023 16:54:37.960161  5058 net.cpp:380] Convolution7 -> Convolution7
I1023 16:54:37.961074  5058 net.cpp:122] Setting up Convolution7
I1023 16:54:37.961086  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.961088  5058 net.cpp:137] Memory required for data: 852590624
I1023 16:54:37.961093  5058 layer_factory.hpp:77] Creating layer BatchNorm7
I1023 16:54:37.961099  5058 net.cpp:84] Creating Layer BatchNorm7
I1023 16:54:37.961103  5058 net.cpp:406] BatchNorm7 <- Convolution7
I1023 16:54:37.961107  5058 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1023 16:54:37.961256  5058 net.cpp:122] Setting up BatchNorm7
I1023 16:54:37.961261  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.961263  5058 net.cpp:137] Memory required for data: 878280736
I1023 16:54:37.961268  5058 layer_factory.hpp:77] Creating layer Scale7
I1023 16:54:37.961275  5058 net.cpp:84] Creating Layer Scale7
I1023 16:54:37.961278  5058 net.cpp:406] Scale7 <- Convolution7
I1023 16:54:37.961282  5058 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1023 16:54:37.961308  5058 layer_factory.hpp:77] Creating layer Scale7
I1023 16:54:37.961418  5058 net.cpp:122] Setting up Scale7
I1023 16:54:37.961424  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.961427  5058 net.cpp:137] Memory required for data: 903970848
I1023 16:54:37.961431  5058 layer_factory.hpp:77] Creating layer Eltwise3
I1023 16:54:37.961436  5058 net.cpp:84] Creating Layer Eltwise3
I1023 16:54:37.961441  5058 net.cpp:406] Eltwise3 <- Eltwise2_elu5_0_split_1
I1023 16:54:37.961446  5058 net.cpp:406] Eltwise3 <- Convolution7
I1023 16:54:37.961452  5058 net.cpp:380] Eltwise3 -> Eltwise3
I1023 16:54:37.961475  5058 net.cpp:122] Setting up Eltwise3
I1023 16:54:37.961483  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.961488  5058 net.cpp:137] Memory required for data: 929660960
I1023 16:54:37.961503  5058 layer_factory.hpp:77] Creating layer elu7
I1023 16:54:37.961509  5058 net.cpp:84] Creating Layer elu7
I1023 16:54:37.961514  5058 net.cpp:406] elu7 <- Eltwise3
I1023 16:54:37.961521  5058 net.cpp:367] elu7 -> Eltwise3 (in-place)
I1023 16:54:37.961529  5058 net.cpp:122] Setting up elu7
I1023 16:54:37.961534  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.961539  5058 net.cpp:137] Memory required for data: 955351072
I1023 16:54:37.961544  5058 layer_factory.hpp:77] Creating layer Eltwise3_elu7_0_split
I1023 16:54:37.961550  5058 net.cpp:84] Creating Layer Eltwise3_elu7_0_split
I1023 16:54:37.961555  5058 net.cpp:406] Eltwise3_elu7_0_split <- Eltwise3
I1023 16:54:37.961561  5058 net.cpp:380] Eltwise3_elu7_0_split -> Eltwise3_elu7_0_split_0
I1023 16:54:37.961570  5058 net.cpp:380] Eltwise3_elu7_0_split -> Eltwise3_elu7_0_split_1
I1023 16:54:37.961602  5058 net.cpp:122] Setting up Eltwise3_elu7_0_split
I1023 16:54:37.961609  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.961616  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:37.961621  5058 net.cpp:137] Memory required for data: 1006731296
I1023 16:54:37.961627  5058 layer_factory.hpp:77] Creating layer Convolution8
I1023 16:54:37.961637  5058 net.cpp:84] Creating Layer Convolution8
I1023 16:54:37.961642  5058 net.cpp:406] Convolution8 <- Eltwise3_elu7_0_split_0
I1023 16:54:37.961648  5058 net.cpp:380] Convolution8 -> Convolution8
I1023 16:54:37.963826  5058 net.cpp:122] Setting up Convolution8
I1023 16:54:37.963840  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.963843  5058 net.cpp:137] Memory required for data: 1019576352
I1023 16:54:37.963850  5058 layer_factory.hpp:77] Creating layer BatchNorm8
I1023 16:54:37.963856  5058 net.cpp:84] Creating Layer BatchNorm8
I1023 16:54:37.963860  5058 net.cpp:406] BatchNorm8 <- Convolution8
I1023 16:54:37.963865  5058 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1023 16:54:37.964027  5058 net.cpp:122] Setting up BatchNorm8
I1023 16:54:37.964035  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.964037  5058 net.cpp:137] Memory required for data: 1032421408
I1023 16:54:37.964043  5058 layer_factory.hpp:77] Creating layer Scale8
I1023 16:54:37.964048  5058 net.cpp:84] Creating Layer Scale8
I1023 16:54:37.964051  5058 net.cpp:406] Scale8 <- Convolution8
I1023 16:54:37.964056  5058 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1023 16:54:37.964083  5058 layer_factory.hpp:77] Creating layer Scale8
I1023 16:54:37.964171  5058 net.cpp:122] Setting up Scale8
I1023 16:54:37.964177  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.964180  5058 net.cpp:137] Memory required for data: 1045266464
I1023 16:54:37.964195  5058 layer_factory.hpp:77] Creating layer Convolution9
I1023 16:54:37.964202  5058 net.cpp:84] Creating Layer Convolution9
I1023 16:54:37.964205  5058 net.cpp:406] Convolution9 <- Eltwise3_elu7_0_split_1
I1023 16:54:37.964210  5058 net.cpp:380] Convolution9 -> Convolution9
I1023 16:54:37.965306  5058 net.cpp:122] Setting up Convolution9
I1023 16:54:37.965317  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.965320  5058 net.cpp:137] Memory required for data: 1058111520
I1023 16:54:37.965325  5058 layer_factory.hpp:77] Creating layer BatchNorm9
I1023 16:54:37.965340  5058 net.cpp:84] Creating Layer BatchNorm9
I1023 16:54:37.965344  5058 net.cpp:406] BatchNorm9 <- Convolution9
I1023 16:54:37.965349  5058 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1023 16:54:37.965487  5058 net.cpp:122] Setting up BatchNorm9
I1023 16:54:37.965493  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.965497  5058 net.cpp:137] Memory required for data: 1070956576
I1023 16:54:37.965502  5058 layer_factory.hpp:77] Creating layer Scale9
I1023 16:54:37.965507  5058 net.cpp:84] Creating Layer Scale9
I1023 16:54:37.965509  5058 net.cpp:406] Scale9 <- Convolution9
I1023 16:54:37.965512  5058 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1023 16:54:37.965538  5058 layer_factory.hpp:77] Creating layer Scale9
I1023 16:54:37.965633  5058 net.cpp:122] Setting up Scale9
I1023 16:54:37.965639  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.965642  5058 net.cpp:137] Memory required for data: 1083801632
I1023 16:54:37.965646  5058 layer_factory.hpp:77] Creating layer elu8
I1023 16:54:37.965651  5058 net.cpp:84] Creating Layer elu8
I1023 16:54:37.965654  5058 net.cpp:406] elu8 <- Convolution9
I1023 16:54:37.965658  5058 net.cpp:367] elu8 -> Convolution9 (in-place)
I1023 16:54:37.965663  5058 net.cpp:122] Setting up elu8
I1023 16:54:37.965667  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.965670  5058 net.cpp:137] Memory required for data: 1096646688
I1023 16:54:37.965672  5058 layer_factory.hpp:77] Creating layer Convolution10
I1023 16:54:37.965679  5058 net.cpp:84] Creating Layer Convolution10
I1023 16:54:37.965682  5058 net.cpp:406] Convolution10 <- Convolution9
I1023 16:54:37.965687  5058 net.cpp:380] Convolution10 -> Convolution10
I1023 16:54:37.966744  5058 net.cpp:122] Setting up Convolution10
I1023 16:54:37.966755  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.966758  5058 net.cpp:137] Memory required for data: 1109491744
I1023 16:54:37.966771  5058 layer_factory.hpp:77] Creating layer BatchNorm10
I1023 16:54:37.966778  5058 net.cpp:84] Creating Layer BatchNorm10
I1023 16:54:37.966780  5058 net.cpp:406] BatchNorm10 <- Convolution10
I1023 16:54:37.966784  5058 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1023 16:54:37.966918  5058 net.cpp:122] Setting up BatchNorm10
I1023 16:54:37.966924  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.966928  5058 net.cpp:137] Memory required for data: 1122336800
I1023 16:54:37.966933  5058 layer_factory.hpp:77] Creating layer Scale10
I1023 16:54:37.966936  5058 net.cpp:84] Creating Layer Scale10
I1023 16:54:37.966940  5058 net.cpp:406] Scale10 <- Convolution10
I1023 16:54:37.966943  5058 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1023 16:54:37.966969  5058 layer_factory.hpp:77] Creating layer Scale10
I1023 16:54:37.967051  5058 net.cpp:122] Setting up Scale10
I1023 16:54:37.967057  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.967061  5058 net.cpp:137] Memory required for data: 1135181856
I1023 16:54:37.967064  5058 layer_factory.hpp:77] Creating layer Eltwise4
I1023 16:54:37.967069  5058 net.cpp:84] Creating Layer Eltwise4
I1023 16:54:37.967072  5058 net.cpp:406] Eltwise4 <- Convolution8
I1023 16:54:37.967075  5058 net.cpp:406] Eltwise4 <- Convolution10
I1023 16:54:37.967080  5058 net.cpp:380] Eltwise4 -> Eltwise4
I1023 16:54:37.967097  5058 net.cpp:122] Setting up Eltwise4
I1023 16:54:37.967102  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.967104  5058 net.cpp:137] Memory required for data: 1148026912
I1023 16:54:37.967106  5058 layer_factory.hpp:77] Creating layer elu9
I1023 16:54:37.967111  5058 net.cpp:84] Creating Layer elu9
I1023 16:54:37.967114  5058 net.cpp:406] elu9 <- Eltwise4
I1023 16:54:37.967118  5058 net.cpp:367] elu9 -> Eltwise4 (in-place)
I1023 16:54:37.967121  5058 net.cpp:122] Setting up elu9
I1023 16:54:37.967125  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.967128  5058 net.cpp:137] Memory required for data: 1160871968
I1023 16:54:37.967130  5058 layer_factory.hpp:77] Creating layer Eltwise4_elu9_0_split
I1023 16:54:37.967134  5058 net.cpp:84] Creating Layer Eltwise4_elu9_0_split
I1023 16:54:37.967137  5058 net.cpp:406] Eltwise4_elu9_0_split <- Eltwise4
I1023 16:54:37.967140  5058 net.cpp:380] Eltwise4_elu9_0_split -> Eltwise4_elu9_0_split_0
I1023 16:54:37.967145  5058 net.cpp:380] Eltwise4_elu9_0_split -> Eltwise4_elu9_0_split_1
I1023 16:54:37.967170  5058 net.cpp:122] Setting up Eltwise4_elu9_0_split
I1023 16:54:37.967175  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.967178  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.967181  5058 net.cpp:137] Memory required for data: 1186562080
I1023 16:54:37.967185  5058 layer_factory.hpp:77] Creating layer Convolution11
I1023 16:54:37.967197  5058 net.cpp:84] Creating Layer Convolution11
I1023 16:54:37.967201  5058 net.cpp:406] Convolution11 <- Eltwise4_elu9_0_split_0
I1023 16:54:37.967206  5058 net.cpp:380] Convolution11 -> Convolution11
I1023 16:54:37.968274  5058 net.cpp:122] Setting up Convolution11
I1023 16:54:37.968286  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.968289  5058 net.cpp:137] Memory required for data: 1199407136
I1023 16:54:37.968293  5058 layer_factory.hpp:77] Creating layer BatchNorm11
I1023 16:54:37.968298  5058 net.cpp:84] Creating Layer BatchNorm11
I1023 16:54:37.968302  5058 net.cpp:406] BatchNorm11 <- Convolution11
I1023 16:54:37.968307  5058 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1023 16:54:37.968439  5058 net.cpp:122] Setting up BatchNorm11
I1023 16:54:37.968444  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.968447  5058 net.cpp:137] Memory required for data: 1212252192
I1023 16:54:37.968452  5058 layer_factory.hpp:77] Creating layer Scale11
I1023 16:54:37.968457  5058 net.cpp:84] Creating Layer Scale11
I1023 16:54:37.968461  5058 net.cpp:406] Scale11 <- Convolution11
I1023 16:54:37.968464  5058 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1023 16:54:37.968490  5058 layer_factory.hpp:77] Creating layer Scale11
I1023 16:54:37.968575  5058 net.cpp:122] Setting up Scale11
I1023 16:54:37.968581  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.968585  5058 net.cpp:137] Memory required for data: 1225097248
I1023 16:54:37.968588  5058 layer_factory.hpp:77] Creating layer elu10
I1023 16:54:37.968592  5058 net.cpp:84] Creating Layer elu10
I1023 16:54:37.968596  5058 net.cpp:406] elu10 <- Convolution11
I1023 16:54:37.968600  5058 net.cpp:367] elu10 -> Convolution11 (in-place)
I1023 16:54:37.968605  5058 net.cpp:122] Setting up elu10
I1023 16:54:37.968608  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.968611  5058 net.cpp:137] Memory required for data: 1237942304
I1023 16:54:37.968613  5058 layer_factory.hpp:77] Creating layer Convolution12
I1023 16:54:37.968621  5058 net.cpp:84] Creating Layer Convolution12
I1023 16:54:37.968623  5058 net.cpp:406] Convolution12 <- Convolution11
I1023 16:54:37.968629  5058 net.cpp:380] Convolution12 -> Convolution12
I1023 16:54:37.969677  5058 net.cpp:122] Setting up Convolution12
I1023 16:54:37.969688  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.969691  5058 net.cpp:137] Memory required for data: 1250787360
I1023 16:54:37.969696  5058 layer_factory.hpp:77] Creating layer BatchNorm12
I1023 16:54:37.969702  5058 net.cpp:84] Creating Layer BatchNorm12
I1023 16:54:37.969705  5058 net.cpp:406] BatchNorm12 <- Convolution12
I1023 16:54:37.969709  5058 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1023 16:54:37.969843  5058 net.cpp:122] Setting up BatchNorm12
I1023 16:54:37.969849  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.969852  5058 net.cpp:137] Memory required for data: 1263632416
I1023 16:54:37.969856  5058 layer_factory.hpp:77] Creating layer Scale12
I1023 16:54:37.969861  5058 net.cpp:84] Creating Layer Scale12
I1023 16:54:37.969864  5058 net.cpp:406] Scale12 <- Convolution12
I1023 16:54:37.969867  5058 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1023 16:54:37.969894  5058 layer_factory.hpp:77] Creating layer Scale12
I1023 16:54:37.969976  5058 net.cpp:122] Setting up Scale12
I1023 16:54:37.969982  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.969985  5058 net.cpp:137] Memory required for data: 1276477472
I1023 16:54:37.969990  5058 layer_factory.hpp:77] Creating layer Eltwise5
I1023 16:54:37.969993  5058 net.cpp:84] Creating Layer Eltwise5
I1023 16:54:37.969997  5058 net.cpp:406] Eltwise5 <- Eltwise4_elu9_0_split_1
I1023 16:54:37.970000  5058 net.cpp:406] Eltwise5 <- Convolution12
I1023 16:54:37.970005  5058 net.cpp:380] Eltwise5 -> Eltwise5
I1023 16:54:37.970021  5058 net.cpp:122] Setting up Eltwise5
I1023 16:54:37.970026  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.970034  5058 net.cpp:137] Memory required for data: 1289322528
I1023 16:54:37.970037  5058 layer_factory.hpp:77] Creating layer elu11
I1023 16:54:37.970042  5058 net.cpp:84] Creating Layer elu11
I1023 16:54:37.970046  5058 net.cpp:406] elu11 <- Eltwise5
I1023 16:54:37.970048  5058 net.cpp:367] elu11 -> Eltwise5 (in-place)
I1023 16:54:37.970053  5058 net.cpp:122] Setting up elu11
I1023 16:54:37.970057  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.970059  5058 net.cpp:137] Memory required for data: 1302167584
I1023 16:54:37.970062  5058 layer_factory.hpp:77] Creating layer Eltwise5_elu11_0_split
I1023 16:54:37.970065  5058 net.cpp:84] Creating Layer Eltwise5_elu11_0_split
I1023 16:54:37.970069  5058 net.cpp:406] Eltwise5_elu11_0_split <- Eltwise5
I1023 16:54:37.970072  5058 net.cpp:380] Eltwise5_elu11_0_split -> Eltwise5_elu11_0_split_0
I1023 16:54:37.970077  5058 net.cpp:380] Eltwise5_elu11_0_split -> Eltwise5_elu11_0_split_1
I1023 16:54:37.970100  5058 net.cpp:122] Setting up Eltwise5_elu11_0_split
I1023 16:54:37.970105  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.970108  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.970113  5058 net.cpp:137] Memory required for data: 1327857696
I1023 16:54:37.970114  5058 layer_factory.hpp:77] Creating layer Convolution13
I1023 16:54:37.970120  5058 net.cpp:84] Creating Layer Convolution13
I1023 16:54:37.970124  5058 net.cpp:406] Convolution13 <- Eltwise5_elu11_0_split_0
I1023 16:54:37.970129  5058 net.cpp:380] Convolution13 -> Convolution13
I1023 16:54:37.971179  5058 net.cpp:122] Setting up Convolution13
I1023 16:54:37.971189  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.971192  5058 net.cpp:137] Memory required for data: 1340702752
I1023 16:54:37.971197  5058 layer_factory.hpp:77] Creating layer BatchNorm13
I1023 16:54:37.971202  5058 net.cpp:84] Creating Layer BatchNorm13
I1023 16:54:37.971205  5058 net.cpp:406] BatchNorm13 <- Convolution13
I1023 16:54:37.971210  5058 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1023 16:54:37.971348  5058 net.cpp:122] Setting up BatchNorm13
I1023 16:54:37.971352  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.971355  5058 net.cpp:137] Memory required for data: 1353547808
I1023 16:54:37.971360  5058 layer_factory.hpp:77] Creating layer Scale13
I1023 16:54:37.971365  5058 net.cpp:84] Creating Layer Scale13
I1023 16:54:37.971369  5058 net.cpp:406] Scale13 <- Convolution13
I1023 16:54:37.971371  5058 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1023 16:54:37.971398  5058 layer_factory.hpp:77] Creating layer Scale13
I1023 16:54:37.971485  5058 net.cpp:122] Setting up Scale13
I1023 16:54:37.971491  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.971494  5058 net.cpp:137] Memory required for data: 1366392864
I1023 16:54:37.971498  5058 layer_factory.hpp:77] Creating layer elu12
I1023 16:54:37.971503  5058 net.cpp:84] Creating Layer elu12
I1023 16:54:37.971506  5058 net.cpp:406] elu12 <- Convolution13
I1023 16:54:37.971509  5058 net.cpp:367] elu12 -> Convolution13 (in-place)
I1023 16:54:37.971514  5058 net.cpp:122] Setting up elu12
I1023 16:54:37.971518  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.971520  5058 net.cpp:137] Memory required for data: 1379237920
I1023 16:54:37.971524  5058 layer_factory.hpp:77] Creating layer Convolution14
I1023 16:54:37.971529  5058 net.cpp:84] Creating Layer Convolution14
I1023 16:54:37.971532  5058 net.cpp:406] Convolution14 <- Convolution13
I1023 16:54:37.971537  5058 net.cpp:380] Convolution14 -> Convolution14
I1023 16:54:37.972623  5058 net.cpp:122] Setting up Convolution14
I1023 16:54:37.972635  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.972637  5058 net.cpp:137] Memory required for data: 1392082976
I1023 16:54:37.972642  5058 layer_factory.hpp:77] Creating layer BatchNorm14
I1023 16:54:37.972652  5058 net.cpp:84] Creating Layer BatchNorm14
I1023 16:54:37.972656  5058 net.cpp:406] BatchNorm14 <- Convolution14
I1023 16:54:37.972661  5058 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1023 16:54:37.972805  5058 net.cpp:122] Setting up BatchNorm14
I1023 16:54:37.972811  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.972815  5058 net.cpp:137] Memory required for data: 1404928032
I1023 16:54:37.972820  5058 layer_factory.hpp:77] Creating layer Scale14
I1023 16:54:37.972826  5058 net.cpp:84] Creating Layer Scale14
I1023 16:54:37.972828  5058 net.cpp:406] Scale14 <- Convolution14
I1023 16:54:37.972832  5058 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1023 16:54:37.972859  5058 layer_factory.hpp:77] Creating layer Scale14
I1023 16:54:37.972947  5058 net.cpp:122] Setting up Scale14
I1023 16:54:37.972954  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.972955  5058 net.cpp:137] Memory required for data: 1417773088
I1023 16:54:37.972959  5058 layer_factory.hpp:77] Creating layer Eltwise6
I1023 16:54:37.972965  5058 net.cpp:84] Creating Layer Eltwise6
I1023 16:54:37.972967  5058 net.cpp:406] Eltwise6 <- Eltwise5_elu11_0_split_1
I1023 16:54:37.972971  5058 net.cpp:406] Eltwise6 <- Convolution14
I1023 16:54:37.972975  5058 net.cpp:380] Eltwise6 -> Eltwise6
I1023 16:54:37.972992  5058 net.cpp:122] Setting up Eltwise6
I1023 16:54:37.972997  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.973001  5058 net.cpp:137] Memory required for data: 1430618144
I1023 16:54:37.973002  5058 layer_factory.hpp:77] Creating layer elu13
I1023 16:54:37.973006  5058 net.cpp:84] Creating Layer elu13
I1023 16:54:37.973008  5058 net.cpp:406] elu13 <- Eltwise6
I1023 16:54:37.973012  5058 net.cpp:367] elu13 -> Eltwise6 (in-place)
I1023 16:54:37.973016  5058 net.cpp:122] Setting up elu13
I1023 16:54:37.973019  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.973022  5058 net.cpp:137] Memory required for data: 1443463200
I1023 16:54:37.973024  5058 layer_factory.hpp:77] Creating layer Eltwise6_elu13_0_split
I1023 16:54:37.973027  5058 net.cpp:84] Creating Layer Eltwise6_elu13_0_split
I1023 16:54:37.973029  5058 net.cpp:406] Eltwise6_elu13_0_split <- Eltwise6
I1023 16:54:37.973032  5058 net.cpp:380] Eltwise6_elu13_0_split -> Eltwise6_elu13_0_split_0
I1023 16:54:37.973037  5058 net.cpp:380] Eltwise6_elu13_0_split -> Eltwise6_elu13_0_split_1
I1023 16:54:37.973058  5058 net.cpp:122] Setting up Eltwise6_elu13_0_split
I1023 16:54:37.973062  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.973065  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:37.973067  5058 net.cpp:137] Memory required for data: 1469153312
I1023 16:54:37.973069  5058 layer_factory.hpp:77] Creating layer Convolution15
I1023 16:54:37.973074  5058 net.cpp:84] Creating Layer Convolution15
I1023 16:54:37.973078  5058 net.cpp:406] Convolution15 <- Eltwise6_elu13_0_split_0
I1023 16:54:37.973083  5058 net.cpp:380] Convolution15 -> Convolution15
I1023 16:54:37.973974  5058 net.cpp:122] Setting up Convolution15
I1023 16:54:37.973983  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.973985  5058 net.cpp:137] Memory required for data: 1475575840
I1023 16:54:37.973989  5058 layer_factory.hpp:77] Creating layer BatchNorm15
I1023 16:54:37.973994  5058 net.cpp:84] Creating Layer BatchNorm15
I1023 16:54:37.973997  5058 net.cpp:406] BatchNorm15 <- Convolution15
I1023 16:54:37.974001  5058 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1023 16:54:37.974138  5058 net.cpp:122] Setting up BatchNorm15
I1023 16:54:37.974143  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.974144  5058 net.cpp:137] Memory required for data: 1481998368
I1023 16:54:37.974149  5058 layer_factory.hpp:77] Creating layer Scale15
I1023 16:54:37.974153  5058 net.cpp:84] Creating Layer Scale15
I1023 16:54:37.974155  5058 net.cpp:406] Scale15 <- Convolution15
I1023 16:54:37.974159  5058 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1023 16:54:37.974185  5058 layer_factory.hpp:77] Creating layer Scale15
I1023 16:54:37.974267  5058 net.cpp:122] Setting up Scale15
I1023 16:54:37.974272  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.974279  5058 net.cpp:137] Memory required for data: 1488420896
I1023 16:54:37.974283  5058 layer_factory.hpp:77] Creating layer Convolution16
I1023 16:54:37.974290  5058 net.cpp:84] Creating Layer Convolution16
I1023 16:54:37.974293  5058 net.cpp:406] Convolution16 <- Eltwise6_elu13_0_split_1
I1023 16:54:37.974298  5058 net.cpp:380] Convolution16 -> Convolution16
I1023 16:54:37.975559  5058 net.cpp:122] Setting up Convolution16
I1023 16:54:37.975569  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.975571  5058 net.cpp:137] Memory required for data: 1494843424
I1023 16:54:37.975575  5058 layer_factory.hpp:77] Creating layer BatchNorm16
I1023 16:54:37.975580  5058 net.cpp:84] Creating Layer BatchNorm16
I1023 16:54:37.975582  5058 net.cpp:406] BatchNorm16 <- Convolution16
I1023 16:54:37.975587  5058 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1023 16:54:37.975724  5058 net.cpp:122] Setting up BatchNorm16
I1023 16:54:37.975728  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.975730  5058 net.cpp:137] Memory required for data: 1501265952
I1023 16:54:37.975735  5058 layer_factory.hpp:77] Creating layer Scale16
I1023 16:54:37.975739  5058 net.cpp:84] Creating Layer Scale16
I1023 16:54:37.975741  5058 net.cpp:406] Scale16 <- Convolution16
I1023 16:54:37.975746  5058 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1023 16:54:37.975772  5058 layer_factory.hpp:77] Creating layer Scale16
I1023 16:54:37.975855  5058 net.cpp:122] Setting up Scale16
I1023 16:54:37.975859  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.975862  5058 net.cpp:137] Memory required for data: 1507688480
I1023 16:54:37.975865  5058 layer_factory.hpp:77] Creating layer elu14
I1023 16:54:37.975869  5058 net.cpp:84] Creating Layer elu14
I1023 16:54:37.975872  5058 net.cpp:406] elu14 <- Convolution16
I1023 16:54:37.975874  5058 net.cpp:367] elu14 -> Convolution16 (in-place)
I1023 16:54:37.975878  5058 net.cpp:122] Setting up elu14
I1023 16:54:37.975881  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.975883  5058 net.cpp:137] Memory required for data: 1514111008
I1023 16:54:37.975885  5058 layer_factory.hpp:77] Creating layer Convolution17
I1023 16:54:37.975893  5058 net.cpp:84] Creating Layer Convolution17
I1023 16:54:37.975894  5058 net.cpp:406] Convolution17 <- Convolution16
I1023 16:54:37.975898  5058 net.cpp:380] Convolution17 -> Convolution17
I1023 16:54:37.977262  5058 net.cpp:122] Setting up Convolution17
I1023 16:54:37.977269  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.977272  5058 net.cpp:137] Memory required for data: 1520533536
I1023 16:54:37.977277  5058 layer_factory.hpp:77] Creating layer BatchNorm17
I1023 16:54:37.977282  5058 net.cpp:84] Creating Layer BatchNorm17
I1023 16:54:37.977283  5058 net.cpp:406] BatchNorm17 <- Convolution17
I1023 16:54:37.977288  5058 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1023 16:54:37.977483  5058 net.cpp:122] Setting up BatchNorm17
I1023 16:54:37.977494  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.977499  5058 net.cpp:137] Memory required for data: 1526956064
I1023 16:54:37.977507  5058 layer_factory.hpp:77] Creating layer Scale17
I1023 16:54:37.977514  5058 net.cpp:84] Creating Layer Scale17
I1023 16:54:37.977519  5058 net.cpp:406] Scale17 <- Convolution17
I1023 16:54:37.977527  5058 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1023 16:54:37.977565  5058 layer_factory.hpp:77] Creating layer Scale17
I1023 16:54:37.977681  5058 net.cpp:122] Setting up Scale17
I1023 16:54:37.977690  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.977695  5058 net.cpp:137] Memory required for data: 1533378592
I1023 16:54:37.977702  5058 layer_factory.hpp:77] Creating layer Eltwise7
I1023 16:54:37.977710  5058 net.cpp:84] Creating Layer Eltwise7
I1023 16:54:37.977715  5058 net.cpp:406] Eltwise7 <- Convolution15
I1023 16:54:37.977720  5058 net.cpp:406] Eltwise7 <- Convolution17
I1023 16:54:37.977727  5058 net.cpp:380] Eltwise7 -> Eltwise7
I1023 16:54:37.977761  5058 net.cpp:122] Setting up Eltwise7
I1023 16:54:37.977769  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.977774  5058 net.cpp:137] Memory required for data: 1539801120
I1023 16:54:37.977778  5058 layer_factory.hpp:77] Creating layer elu15
I1023 16:54:37.977785  5058 net.cpp:84] Creating Layer elu15
I1023 16:54:37.977790  5058 net.cpp:406] elu15 <- Eltwise7
I1023 16:54:37.977797  5058 net.cpp:367] elu15 -> Eltwise7 (in-place)
I1023 16:54:37.977803  5058 net.cpp:122] Setting up elu15
I1023 16:54:37.977810  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.977814  5058 net.cpp:137] Memory required for data: 1546223648
I1023 16:54:37.977819  5058 layer_factory.hpp:77] Creating layer Eltwise7_elu15_0_split
I1023 16:54:37.977825  5058 net.cpp:84] Creating Layer Eltwise7_elu15_0_split
I1023 16:54:37.977830  5058 net.cpp:406] Eltwise7_elu15_0_split <- Eltwise7
I1023 16:54:37.977836  5058 net.cpp:380] Eltwise7_elu15_0_split -> Eltwise7_elu15_0_split_0
I1023 16:54:37.977843  5058 net.cpp:380] Eltwise7_elu15_0_split -> Eltwise7_elu15_0_split_1
I1023 16:54:37.977874  5058 net.cpp:122] Setting up Eltwise7_elu15_0_split
I1023 16:54:37.977880  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.977885  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.977890  5058 net.cpp:137] Memory required for data: 1559068704
I1023 16:54:37.977892  5058 layer_factory.hpp:77] Creating layer Convolution18
I1023 16:54:37.977902  5058 net.cpp:84] Creating Layer Convolution18
I1023 16:54:37.977906  5058 net.cpp:406] Convolution18 <- Eltwise7_elu15_0_split_0
I1023 16:54:37.977913  5058 net.cpp:380] Convolution18 -> Convolution18
I1023 16:54:37.980631  5058 net.cpp:122] Setting up Convolution18
I1023 16:54:37.980643  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.980656  5058 net.cpp:137] Memory required for data: 1565491232
I1023 16:54:37.980662  5058 layer_factory.hpp:77] Creating layer BatchNorm18
I1023 16:54:37.980669  5058 net.cpp:84] Creating Layer BatchNorm18
I1023 16:54:37.980674  5058 net.cpp:406] BatchNorm18 <- Convolution18
I1023 16:54:37.980677  5058 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1023 16:54:37.980829  5058 net.cpp:122] Setting up BatchNorm18
I1023 16:54:37.980834  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.980837  5058 net.cpp:137] Memory required for data: 1571913760
I1023 16:54:37.980854  5058 layer_factory.hpp:77] Creating layer Scale18
I1023 16:54:37.980859  5058 net.cpp:84] Creating Layer Scale18
I1023 16:54:37.980862  5058 net.cpp:406] Scale18 <- Convolution18
I1023 16:54:37.980865  5058 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1023 16:54:37.980895  5058 layer_factory.hpp:77] Creating layer Scale18
I1023 16:54:37.980980  5058 net.cpp:122] Setting up Scale18
I1023 16:54:37.980986  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.980989  5058 net.cpp:137] Memory required for data: 1578336288
I1023 16:54:37.980993  5058 layer_factory.hpp:77] Creating layer elu16
I1023 16:54:37.980998  5058 net.cpp:84] Creating Layer elu16
I1023 16:54:37.981003  5058 net.cpp:406] elu16 <- Convolution18
I1023 16:54:37.981005  5058 net.cpp:367] elu16 -> Convolution18 (in-place)
I1023 16:54:37.981009  5058 net.cpp:122] Setting up elu16
I1023 16:54:37.981014  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.981016  5058 net.cpp:137] Memory required for data: 1584758816
I1023 16:54:37.981019  5058 layer_factory.hpp:77] Creating layer Convolution19
I1023 16:54:37.981025  5058 net.cpp:84] Creating Layer Convolution19
I1023 16:54:37.981029  5058 net.cpp:406] Convolution19 <- Convolution18
I1023 16:54:37.981035  5058 net.cpp:380] Convolution19 -> Convolution19
I1023 16:54:37.983335  5058 net.cpp:122] Setting up Convolution19
I1023 16:54:37.983345  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.983350  5058 net.cpp:137] Memory required for data: 1591181344
I1023 16:54:37.983355  5058 layer_factory.hpp:77] Creating layer BatchNorm19
I1023 16:54:37.983361  5058 net.cpp:84] Creating Layer BatchNorm19
I1023 16:54:37.983373  5058 net.cpp:406] BatchNorm19 <- Convolution19
I1023 16:54:37.983379  5058 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1023 16:54:37.983520  5058 net.cpp:122] Setting up BatchNorm19
I1023 16:54:37.983525  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.983527  5058 net.cpp:137] Memory required for data: 1597603872
I1023 16:54:37.983546  5058 layer_factory.hpp:77] Creating layer Scale19
I1023 16:54:37.983551  5058 net.cpp:84] Creating Layer Scale19
I1023 16:54:37.983556  5058 net.cpp:406] Scale19 <- Convolution19
I1023 16:54:37.983558  5058 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1023 16:54:37.983590  5058 layer_factory.hpp:77] Creating layer Scale19
I1023 16:54:37.983675  5058 net.cpp:122] Setting up Scale19
I1023 16:54:37.983680  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.983682  5058 net.cpp:137] Memory required for data: 1604026400
I1023 16:54:37.983686  5058 layer_factory.hpp:77] Creating layer Eltwise8
I1023 16:54:37.983691  5058 net.cpp:84] Creating Layer Eltwise8
I1023 16:54:37.983695  5058 net.cpp:406] Eltwise8 <- Eltwise7_elu15_0_split_1
I1023 16:54:37.983698  5058 net.cpp:406] Eltwise8 <- Convolution19
I1023 16:54:37.983703  5058 net.cpp:380] Eltwise8 -> Eltwise8
I1023 16:54:37.983721  5058 net.cpp:122] Setting up Eltwise8
I1023 16:54:37.983726  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.983728  5058 net.cpp:137] Memory required for data: 1610448928
I1023 16:54:37.983731  5058 layer_factory.hpp:77] Creating layer elu17
I1023 16:54:37.983734  5058 net.cpp:84] Creating Layer elu17
I1023 16:54:37.983737  5058 net.cpp:406] elu17 <- Eltwise8
I1023 16:54:37.983741  5058 net.cpp:367] elu17 -> Eltwise8 (in-place)
I1023 16:54:37.983747  5058 net.cpp:122] Setting up elu17
I1023 16:54:37.983749  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.983752  5058 net.cpp:137] Memory required for data: 1616871456
I1023 16:54:37.983754  5058 layer_factory.hpp:77] Creating layer Eltwise8_elu17_0_split
I1023 16:54:37.983758  5058 net.cpp:84] Creating Layer Eltwise8_elu17_0_split
I1023 16:54:37.983762  5058 net.cpp:406] Eltwise8_elu17_0_split <- Eltwise8
I1023 16:54:37.983764  5058 net.cpp:380] Eltwise8_elu17_0_split -> Eltwise8_elu17_0_split_0
I1023 16:54:37.983769  5058 net.cpp:380] Eltwise8_elu17_0_split -> Eltwise8_elu17_0_split_1
I1023 16:54:37.983794  5058 net.cpp:122] Setting up Eltwise8_elu17_0_split
I1023 16:54:37.983798  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.983803  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.983804  5058 net.cpp:137] Memory required for data: 1629716512
I1023 16:54:37.983808  5058 layer_factory.hpp:77] Creating layer Convolution20
I1023 16:54:37.983814  5058 net.cpp:84] Creating Layer Convolution20
I1023 16:54:37.983816  5058 net.cpp:406] Convolution20 <- Eltwise8_elu17_0_split_0
I1023 16:54:37.983821  5058 net.cpp:380] Convolution20 -> Convolution20
I1023 16:54:37.986165  5058 net.cpp:122] Setting up Convolution20
I1023 16:54:37.986174  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.986178  5058 net.cpp:137] Memory required for data: 1636139040
I1023 16:54:37.986184  5058 layer_factory.hpp:77] Creating layer BatchNorm20
I1023 16:54:37.986189  5058 net.cpp:84] Creating Layer BatchNorm20
I1023 16:54:37.986192  5058 net.cpp:406] BatchNorm20 <- Convolution20
I1023 16:54:37.986196  5058 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1023 16:54:37.986341  5058 net.cpp:122] Setting up BatchNorm20
I1023 16:54:37.986346  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.986349  5058 net.cpp:137] Memory required for data: 1642561568
I1023 16:54:37.986354  5058 layer_factory.hpp:77] Creating layer Scale20
I1023 16:54:37.986359  5058 net.cpp:84] Creating Layer Scale20
I1023 16:54:37.986362  5058 net.cpp:406] Scale20 <- Convolution20
I1023 16:54:37.986366  5058 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1023 16:54:37.986395  5058 layer_factory.hpp:77] Creating layer Scale20
I1023 16:54:37.986488  5058 net.cpp:122] Setting up Scale20
I1023 16:54:37.986495  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.986498  5058 net.cpp:137] Memory required for data: 1648984096
I1023 16:54:37.986502  5058 layer_factory.hpp:77] Creating layer elu18
I1023 16:54:37.986506  5058 net.cpp:84] Creating Layer elu18
I1023 16:54:37.986510  5058 net.cpp:406] elu18 <- Convolution20
I1023 16:54:37.986513  5058 net.cpp:367] elu18 -> Convolution20 (in-place)
I1023 16:54:37.986517  5058 net.cpp:122] Setting up elu18
I1023 16:54:37.986521  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.986524  5058 net.cpp:137] Memory required for data: 1655406624
I1023 16:54:37.986526  5058 layer_factory.hpp:77] Creating layer Convolution21
I1023 16:54:37.986533  5058 net.cpp:84] Creating Layer Convolution21
I1023 16:54:37.986536  5058 net.cpp:406] Convolution21 <- Convolution20
I1023 16:54:37.986541  5058 net.cpp:380] Convolution21 -> Convolution21
I1023 16:54:37.988226  5058 net.cpp:122] Setting up Convolution21
I1023 16:54:37.988235  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.988239  5058 net.cpp:137] Memory required for data: 1661829152
I1023 16:54:37.988242  5058 layer_factory.hpp:77] Creating layer BatchNorm21
I1023 16:54:37.988247  5058 net.cpp:84] Creating Layer BatchNorm21
I1023 16:54:37.988250  5058 net.cpp:406] BatchNorm21 <- Convolution21
I1023 16:54:37.988255  5058 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1023 16:54:37.988394  5058 net.cpp:122] Setting up BatchNorm21
I1023 16:54:37.988399  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.988401  5058 net.cpp:137] Memory required for data: 1668251680
I1023 16:54:37.988406  5058 layer_factory.hpp:77] Creating layer Scale21
I1023 16:54:37.988411  5058 net.cpp:84] Creating Layer Scale21
I1023 16:54:37.988414  5058 net.cpp:406] Scale21 <- Convolution21
I1023 16:54:37.988416  5058 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1023 16:54:37.988443  5058 layer_factory.hpp:77] Creating layer Scale21
I1023 16:54:37.988525  5058 net.cpp:122] Setting up Scale21
I1023 16:54:37.988530  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.988533  5058 net.cpp:137] Memory required for data: 1674674208
I1023 16:54:37.988536  5058 layer_factory.hpp:77] Creating layer Eltwise9
I1023 16:54:37.988540  5058 net.cpp:84] Creating Layer Eltwise9
I1023 16:54:37.988543  5058 net.cpp:406] Eltwise9 <- Eltwise8_elu17_0_split_1
I1023 16:54:37.988546  5058 net.cpp:406] Eltwise9 <- Convolution21
I1023 16:54:37.988549  5058 net.cpp:380] Eltwise9 -> Eltwise9
I1023 16:54:37.988565  5058 net.cpp:122] Setting up Eltwise9
I1023 16:54:37.988569  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.988571  5058 net.cpp:137] Memory required for data: 1681096736
I1023 16:54:37.988574  5058 layer_factory.hpp:77] Creating layer elu19
I1023 16:54:37.988577  5058 net.cpp:84] Creating Layer elu19
I1023 16:54:37.988579  5058 net.cpp:406] elu19 <- Eltwise9
I1023 16:54:37.988582  5058 net.cpp:367] elu19 -> Eltwise9 (in-place)
I1023 16:54:37.988586  5058 net.cpp:122] Setting up elu19
I1023 16:54:37.988590  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:37.988592  5058 net.cpp:137] Memory required for data: 1687519264
I1023 16:54:37.988595  5058 layer_factory.hpp:77] Creating layer Pooling1
I1023 16:54:37.988598  5058 net.cpp:84] Creating Layer Pooling1
I1023 16:54:37.988600  5058 net.cpp:406] Pooling1 <- Eltwise9
I1023 16:54:37.988603  5058 net.cpp:380] Pooling1 -> Pooling1
I1023 16:54:37.988746  5058 net.cpp:122] Setting up Pooling1
I1023 16:54:37.988754  5058 net.cpp:129] Top shape: 8 64 1 1 (512)
I1023 16:54:37.988755  5058 net.cpp:137] Memory required for data: 1687521312
I1023 16:54:37.988757  5058 layer_factory.hpp:77] Creating layer InnerProduct1
I1023 16:54:37.988766  5058 net.cpp:84] Creating Layer InnerProduct1
I1023 16:54:37.988770  5058 net.cpp:406] InnerProduct1 <- Pooling1
I1023 16:54:37.988775  5058 net.cpp:380] InnerProduct1 -> InnerProduct1
I1023 16:54:37.988855  5058 net.cpp:122] Setting up InnerProduct1
I1023 16:54:37.988867  5058 net.cpp:129] Top shape: 8 4 (32)
I1023 16:54:37.988868  5058 net.cpp:137] Memory required for data: 1687521440
I1023 16:54:37.988873  5058 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1023 16:54:37.988876  5058 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1023 16:54:37.988879  5058 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I1023 16:54:37.988883  5058 net.cpp:406] SoftmaxWithLoss1 <- Data2
I1023 16:54:37.988888  5058 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1023 16:54:37.988894  5058 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1023 16:54:37.989413  5058 net.cpp:122] Setting up SoftmaxWithLoss1
I1023 16:54:37.989420  5058 net.cpp:129] Top shape: (1)
I1023 16:54:37.989423  5058 net.cpp:132]     with loss weight 1
I1023 16:54:37.989434  5058 net.cpp:137] Memory required for data: 1687521444
I1023 16:54:37.989437  5058 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1023 16:54:37.989440  5058 net.cpp:198] InnerProduct1 needs backward computation.
I1023 16:54:37.989442  5058 net.cpp:198] Pooling1 needs backward computation.
I1023 16:54:37.989444  5058 net.cpp:198] elu19 needs backward computation.
I1023 16:54:37.989446  5058 net.cpp:198] Eltwise9 needs backward computation.
I1023 16:54:37.989449  5058 net.cpp:198] Scale21 needs backward computation.
I1023 16:54:37.989451  5058 net.cpp:198] BatchNorm21 needs backward computation.
I1023 16:54:37.989454  5058 net.cpp:198] Convolution21 needs backward computation.
I1023 16:54:37.989455  5058 net.cpp:198] elu18 needs backward computation.
I1023 16:54:37.989457  5058 net.cpp:198] Scale20 needs backward computation.
I1023 16:54:37.989459  5058 net.cpp:198] BatchNorm20 needs backward computation.
I1023 16:54:37.989460  5058 net.cpp:198] Convolution20 needs backward computation.
I1023 16:54:37.989462  5058 net.cpp:198] Eltwise8_elu17_0_split needs backward computation.
I1023 16:54:37.989465  5058 net.cpp:198] elu17 needs backward computation.
I1023 16:54:37.989467  5058 net.cpp:198] Eltwise8 needs backward computation.
I1023 16:54:37.989470  5058 net.cpp:198] Scale19 needs backward computation.
I1023 16:54:37.989471  5058 net.cpp:198] BatchNorm19 needs backward computation.
I1023 16:54:37.989473  5058 net.cpp:198] Convolution19 needs backward computation.
I1023 16:54:37.989475  5058 net.cpp:198] elu16 needs backward computation.
I1023 16:54:37.989477  5058 net.cpp:198] Scale18 needs backward computation.
I1023 16:54:37.989480  5058 net.cpp:198] BatchNorm18 needs backward computation.
I1023 16:54:37.989481  5058 net.cpp:198] Convolution18 needs backward computation.
I1023 16:54:37.989483  5058 net.cpp:198] Eltwise7_elu15_0_split needs backward computation.
I1023 16:54:37.989485  5058 net.cpp:198] elu15 needs backward computation.
I1023 16:54:37.989487  5058 net.cpp:198] Eltwise7 needs backward computation.
I1023 16:54:37.989490  5058 net.cpp:198] Scale17 needs backward computation.
I1023 16:54:37.989492  5058 net.cpp:198] BatchNorm17 needs backward computation.
I1023 16:54:37.989495  5058 net.cpp:198] Convolution17 needs backward computation.
I1023 16:54:37.989497  5058 net.cpp:198] elu14 needs backward computation.
I1023 16:54:37.989500  5058 net.cpp:198] Scale16 needs backward computation.
I1023 16:54:37.989501  5058 net.cpp:198] BatchNorm16 needs backward computation.
I1023 16:54:37.989503  5058 net.cpp:198] Convolution16 needs backward computation.
I1023 16:54:37.989506  5058 net.cpp:198] Scale15 needs backward computation.
I1023 16:54:37.989507  5058 net.cpp:198] BatchNorm15 needs backward computation.
I1023 16:54:37.989509  5058 net.cpp:198] Convolution15 needs backward computation.
I1023 16:54:37.989512  5058 net.cpp:198] Eltwise6_elu13_0_split needs backward computation.
I1023 16:54:37.989514  5058 net.cpp:198] elu13 needs backward computation.
I1023 16:54:37.989516  5058 net.cpp:198] Eltwise6 needs backward computation.
I1023 16:54:37.989519  5058 net.cpp:198] Scale14 needs backward computation.
I1023 16:54:37.989521  5058 net.cpp:198] BatchNorm14 needs backward computation.
I1023 16:54:37.989529  5058 net.cpp:198] Convolution14 needs backward computation.
I1023 16:54:37.989532  5058 net.cpp:198] elu12 needs backward computation.
I1023 16:54:37.989534  5058 net.cpp:198] Scale13 needs backward computation.
I1023 16:54:37.989537  5058 net.cpp:198] BatchNorm13 needs backward computation.
I1023 16:54:37.989538  5058 net.cpp:198] Convolution13 needs backward computation.
I1023 16:54:37.989540  5058 net.cpp:198] Eltwise5_elu11_0_split needs backward computation.
I1023 16:54:37.989543  5058 net.cpp:198] elu11 needs backward computation.
I1023 16:54:37.989554  5058 net.cpp:198] Eltwise5 needs backward computation.
I1023 16:54:37.989557  5058 net.cpp:198] Scale12 needs backward computation.
I1023 16:54:37.989558  5058 net.cpp:198] BatchNorm12 needs backward computation.
I1023 16:54:37.989560  5058 net.cpp:198] Convolution12 needs backward computation.
I1023 16:54:37.989563  5058 net.cpp:198] elu10 needs backward computation.
I1023 16:54:37.989565  5058 net.cpp:198] Scale11 needs backward computation.
I1023 16:54:37.989567  5058 net.cpp:198] BatchNorm11 needs backward computation.
I1023 16:54:37.989569  5058 net.cpp:198] Convolution11 needs backward computation.
I1023 16:54:37.989572  5058 net.cpp:198] Eltwise4_elu9_0_split needs backward computation.
I1023 16:54:37.989574  5058 net.cpp:198] elu9 needs backward computation.
I1023 16:54:37.989576  5058 net.cpp:198] Eltwise4 needs backward computation.
I1023 16:54:37.989578  5058 net.cpp:198] Scale10 needs backward computation.
I1023 16:54:37.989581  5058 net.cpp:198] BatchNorm10 needs backward computation.
I1023 16:54:37.989583  5058 net.cpp:198] Convolution10 needs backward computation.
I1023 16:54:37.989585  5058 net.cpp:198] elu8 needs backward computation.
I1023 16:54:37.989588  5058 net.cpp:198] Scale9 needs backward computation.
I1023 16:54:37.989590  5058 net.cpp:198] BatchNorm9 needs backward computation.
I1023 16:54:37.989593  5058 net.cpp:198] Convolution9 needs backward computation.
I1023 16:54:37.989594  5058 net.cpp:198] Scale8 needs backward computation.
I1023 16:54:37.989596  5058 net.cpp:198] BatchNorm8 needs backward computation.
I1023 16:54:37.989598  5058 net.cpp:198] Convolution8 needs backward computation.
I1023 16:54:37.989601  5058 net.cpp:198] Eltwise3_elu7_0_split needs backward computation.
I1023 16:54:37.989603  5058 net.cpp:198] elu7 needs backward computation.
I1023 16:54:37.989605  5058 net.cpp:198] Eltwise3 needs backward computation.
I1023 16:54:37.989609  5058 net.cpp:198] Scale7 needs backward computation.
I1023 16:54:37.989610  5058 net.cpp:198] BatchNorm7 needs backward computation.
I1023 16:54:37.989612  5058 net.cpp:198] Convolution7 needs backward computation.
I1023 16:54:37.989614  5058 net.cpp:198] elu6 needs backward computation.
I1023 16:54:37.989616  5058 net.cpp:198] Scale6 needs backward computation.
I1023 16:54:37.989619  5058 net.cpp:198] BatchNorm6 needs backward computation.
I1023 16:54:37.989620  5058 net.cpp:198] Convolution6 needs backward computation.
I1023 16:54:37.989624  5058 net.cpp:198] Eltwise2_elu5_0_split needs backward computation.
I1023 16:54:37.989626  5058 net.cpp:198] elu5 needs backward computation.
I1023 16:54:37.989629  5058 net.cpp:198] Eltwise2 needs backward computation.
I1023 16:54:37.989631  5058 net.cpp:198] Scale5 needs backward computation.
I1023 16:54:37.989634  5058 net.cpp:198] BatchNorm5 needs backward computation.
I1023 16:54:37.989635  5058 net.cpp:198] Convolution5 needs backward computation.
I1023 16:54:37.989637  5058 net.cpp:198] elu4 needs backward computation.
I1023 16:54:37.989639  5058 net.cpp:198] Scale4 needs backward computation.
I1023 16:54:37.989641  5058 net.cpp:198] BatchNorm4 needs backward computation.
I1023 16:54:37.989644  5058 net.cpp:198] Convolution4 needs backward computation.
I1023 16:54:37.989646  5058 net.cpp:198] Eltwise1_elu3_0_split needs backward computation.
I1023 16:54:37.989648  5058 net.cpp:198] elu3 needs backward computation.
I1023 16:54:37.989650  5058 net.cpp:198] Eltwise1 needs backward computation.
I1023 16:54:37.989653  5058 net.cpp:198] Scale3 needs backward computation.
I1023 16:54:37.989658  5058 net.cpp:198] BatchNorm3 needs backward computation.
I1023 16:54:37.989660  5058 net.cpp:198] Convolution3 needs backward computation.
I1023 16:54:37.989662  5058 net.cpp:198] elu2 needs backward computation.
I1023 16:54:37.989665  5058 net.cpp:198] Scale2 needs backward computation.
I1023 16:54:37.989667  5058 net.cpp:198] BatchNorm2 needs backward computation.
I1023 16:54:37.989670  5058 net.cpp:198] Convolution2 needs backward computation.
I1023 16:54:37.989671  5058 net.cpp:198] Convolution1_elu1_0_split needs backward computation.
I1023 16:54:37.989673  5058 net.cpp:198] elu1 needs backward computation.
I1023 16:54:37.989675  5058 net.cpp:198] Scale1 needs backward computation.
I1023 16:54:37.989677  5058 net.cpp:198] BatchNorm1 needs backward computation.
I1023 16:54:37.989679  5058 net.cpp:198] Convolution1 needs backward computation.
I1023 16:54:37.989682  5058 net.cpp:200] Data1 does not need backward computation.
I1023 16:54:37.989684  5058 net.cpp:242] This network produces output SoftmaxWithLoss1
I1023 16:54:37.989717  5058 net.cpp:255] Network initialization done.
I1023 16:54:37.991101  5058 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/English_orange/neural/res20/res20_elu_train_test.prototxt
I1023 16:54:37.991109  5058 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1023 16:54:37.991113  5058 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/English_orange/neural/res20/res20_elu_train_test.prototxt
I1023 16:54:37.991179  5058 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I1023 16:54:37.991559  5058 net.cpp:51] Initializing net from parameters: 
name: "resnet"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_file: "/home/x306/caffe/xn/English_orange/data/orange1_mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/English_orange/data/val1_lmdb"
    batch_size: 8
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu1"
  type: "ELU"
  bottom: "Convolution1"
  top: "Convolution1"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu2"
  type: "ELU"
  bottom: "Convolution2"
  top: "Convolution2"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu3"
  type: "ELU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu4"
  type: "ELU"
  bottom: "Convolution4"
  top: "Convolution4"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu5"
  type: "ELU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu6"
  type: "ELU"
  bottom: "Convolution6"
  top: "Convolution6"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu7"
  type: "ELU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu8"
  type: "ELU"
  bottom: "Convolution9"
  top: "Convolution9"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu9"
  type: "ELU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu10"
  type: "ELU"
  bottom: "Convolution11"
  top: "Convolution11"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu11"
  type: "ELU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu12"
  type: "ELU"
  bottom: "Convolution13"
  top: "Convolution13"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu13"
  type: "ELU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu14"
  type: "ELU"
  bottom: "Convolution16"
  top: "Convolution16"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu15"
  type: "ELU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu16"
  type: "ELU"
  bottom: "Convolution18"
  top: "Convolution18"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu17"
  type: "ELU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu18"
  type: "ELU"
  bottom: "Convolution20"
  top: "Convolution20"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu19"
  type: "ELU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
layer {
  name: "Accuracy1"
  type: "Accuracy"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "Accuracy1"
  include {
    phase: TEST
  }
}
I1023 16:54:37.991793  5058 layer_factory.hpp:77] Creating layer Data1
I1023 16:54:37.991828  5058 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/English_orange/data/val1_lmdb
I1023 16:54:37.991839  5058 net.cpp:84] Creating Layer Data1
I1023 16:54:37.991842  5058 net.cpp:380] Data1 -> Data1
I1023 16:54:37.991848  5058 net.cpp:380] Data1 -> Data2
I1023 16:54:37.991853  5058 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/English_orange/data/orange1_mean.binaryproto
I1023 16:54:37.993039  5058 data_layer.cpp:45] output data size: 8,3,224,224
I1023 16:54:38.000993  5058 net.cpp:122] Setting up Data1
I1023 16:54:38.001013  5058 net.cpp:129] Top shape: 8 3 224 224 (1204224)
I1023 16:54:38.001018  5058 net.cpp:129] Top shape: 8 (8)
I1023 16:54:38.001020  5058 net.cpp:137] Memory required for data: 4816928
I1023 16:54:38.001024  5058 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I1023 16:54:38.001034  5058 net.cpp:84] Creating Layer Data2_Data1_1_split
I1023 16:54:38.001036  5058 net.cpp:406] Data2_Data1_1_split <- Data2
I1023 16:54:38.001041  5058 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I1023 16:54:38.001049  5058 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I1023 16:54:38.001117  5058 net.cpp:122] Setting up Data2_Data1_1_split
I1023 16:54:38.001122  5058 net.cpp:129] Top shape: 8 (8)
I1023 16:54:38.001125  5058 net.cpp:129] Top shape: 8 (8)
I1023 16:54:38.001127  5058 net.cpp:137] Memory required for data: 4816992
I1023 16:54:38.001142  5058 layer_factory.hpp:77] Creating layer Convolution1
I1023 16:54:38.001152  5058 net.cpp:84] Creating Layer Convolution1
I1023 16:54:38.001154  5058 net.cpp:406] Convolution1 <- Data1
I1023 16:54:38.001158  5058 net.cpp:380] Convolution1 -> Convolution1
I1023 16:54:38.002570  5058 net.cpp:122] Setting up Convolution1
I1023 16:54:38.002580  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.002583  5058 net.cpp:137] Memory required for data: 30507104
I1023 16:54:38.002591  5058 layer_factory.hpp:77] Creating layer BatchNorm1
I1023 16:54:38.002596  5058 net.cpp:84] Creating Layer BatchNorm1
I1023 16:54:38.002599  5058 net.cpp:406] BatchNorm1 <- Convolution1
I1023 16:54:38.002602  5058 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1023 16:54:38.002782  5058 net.cpp:122] Setting up BatchNorm1
I1023 16:54:38.002787  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.002789  5058 net.cpp:137] Memory required for data: 56197216
I1023 16:54:38.002797  5058 layer_factory.hpp:77] Creating layer Scale1
I1023 16:54:38.002804  5058 net.cpp:84] Creating Layer Scale1
I1023 16:54:38.002805  5058 net.cpp:406] Scale1 <- Convolution1
I1023 16:54:38.002809  5058 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1023 16:54:38.002838  5058 layer_factory.hpp:77] Creating layer Scale1
I1023 16:54:38.002981  5058 net.cpp:122] Setting up Scale1
I1023 16:54:38.002986  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.002990  5058 net.cpp:137] Memory required for data: 81887328
I1023 16:54:38.002993  5058 layer_factory.hpp:77] Creating layer elu1
I1023 16:54:38.002998  5058 net.cpp:84] Creating Layer elu1
I1023 16:54:38.003000  5058 net.cpp:406] elu1 <- Convolution1
I1023 16:54:38.003003  5058 net.cpp:367] elu1 -> Convolution1 (in-place)
I1023 16:54:38.003008  5058 net.cpp:122] Setting up elu1
I1023 16:54:38.003011  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.003013  5058 net.cpp:137] Memory required for data: 107577440
I1023 16:54:38.003016  5058 layer_factory.hpp:77] Creating layer Convolution1_elu1_0_split
I1023 16:54:38.003020  5058 net.cpp:84] Creating Layer Convolution1_elu1_0_split
I1023 16:54:38.003021  5058 net.cpp:406] Convolution1_elu1_0_split <- Convolution1
I1023 16:54:38.003026  5058 net.cpp:380] Convolution1_elu1_0_split -> Convolution1_elu1_0_split_0
I1023 16:54:38.003029  5058 net.cpp:380] Convolution1_elu1_0_split -> Convolution1_elu1_0_split_1
I1023 16:54:38.003059  5058 net.cpp:122] Setting up Convolution1_elu1_0_split
I1023 16:54:38.003064  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.003067  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.003070  5058 net.cpp:137] Memory required for data: 158957664
I1023 16:54:38.003072  5058 layer_factory.hpp:77] Creating layer Convolution2
I1023 16:54:38.003079  5058 net.cpp:84] Creating Layer Convolution2
I1023 16:54:38.003082  5058 net.cpp:406] Convolution2 <- Convolution1_elu1_0_split_0
I1023 16:54:38.003087  5058 net.cpp:380] Convolution2 -> Convolution2
I1023 16:54:38.003718  5058 net.cpp:122] Setting up Convolution2
I1023 16:54:38.003726  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.003728  5058 net.cpp:137] Memory required for data: 184647776
I1023 16:54:38.003734  5058 layer_factory.hpp:77] Creating layer BatchNorm2
I1023 16:54:38.003739  5058 net.cpp:84] Creating Layer BatchNorm2
I1023 16:54:38.003741  5058 net.cpp:406] BatchNorm2 <- Convolution2
I1023 16:54:38.003746  5058 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1023 16:54:38.003909  5058 net.cpp:122] Setting up BatchNorm2
I1023 16:54:38.003914  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.003916  5058 net.cpp:137] Memory required for data: 210337888
I1023 16:54:38.003921  5058 layer_factory.hpp:77] Creating layer Scale2
I1023 16:54:38.003926  5058 net.cpp:84] Creating Layer Scale2
I1023 16:54:38.003927  5058 net.cpp:406] Scale2 <- Convolution2
I1023 16:54:38.003931  5058 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1023 16:54:38.003969  5058 layer_factory.hpp:77] Creating layer Scale2
I1023 16:54:38.004119  5058 net.cpp:122] Setting up Scale2
I1023 16:54:38.004124  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.004127  5058 net.cpp:137] Memory required for data: 236028000
I1023 16:54:38.004130  5058 layer_factory.hpp:77] Creating layer elu2
I1023 16:54:38.004134  5058 net.cpp:84] Creating Layer elu2
I1023 16:54:38.004137  5058 net.cpp:406] elu2 <- Convolution2
I1023 16:54:38.004139  5058 net.cpp:367] elu2 -> Convolution2 (in-place)
I1023 16:54:38.004143  5058 net.cpp:122] Setting up elu2
I1023 16:54:38.004146  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.004148  5058 net.cpp:137] Memory required for data: 261718112
I1023 16:54:38.004151  5058 layer_factory.hpp:77] Creating layer Convolution3
I1023 16:54:38.004156  5058 net.cpp:84] Creating Layer Convolution3
I1023 16:54:38.004159  5058 net.cpp:406] Convolution3 <- Convolution2
I1023 16:54:38.004163  5058 net.cpp:380] Convolution3 -> Convolution3
I1023 16:54:38.005640  5058 net.cpp:122] Setting up Convolution3
I1023 16:54:38.005651  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.005655  5058 net.cpp:137] Memory required for data: 287408224
I1023 16:54:38.005659  5058 layer_factory.hpp:77] Creating layer BatchNorm3
I1023 16:54:38.005664  5058 net.cpp:84] Creating Layer BatchNorm3
I1023 16:54:38.005667  5058 net.cpp:406] BatchNorm3 <- Convolution3
I1023 16:54:38.005671  5058 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1023 16:54:38.005836  5058 net.cpp:122] Setting up BatchNorm3
I1023 16:54:38.005841  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.005842  5058 net.cpp:137] Memory required for data: 313098336
I1023 16:54:38.005851  5058 layer_factory.hpp:77] Creating layer Scale3
I1023 16:54:38.005854  5058 net.cpp:84] Creating Layer Scale3
I1023 16:54:38.005856  5058 net.cpp:406] Scale3 <- Convolution3
I1023 16:54:38.005859  5058 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1023 16:54:38.005887  5058 layer_factory.hpp:77] Creating layer Scale3
I1023 16:54:38.006003  5058 net.cpp:122] Setting up Scale3
I1023 16:54:38.006008  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.006011  5058 net.cpp:137] Memory required for data: 338788448
I1023 16:54:38.006014  5058 layer_factory.hpp:77] Creating layer Eltwise1
I1023 16:54:38.006018  5058 net.cpp:84] Creating Layer Eltwise1
I1023 16:54:38.006021  5058 net.cpp:406] Eltwise1 <- Convolution1_elu1_0_split_1
I1023 16:54:38.006024  5058 net.cpp:406] Eltwise1 <- Convolution3
I1023 16:54:38.006027  5058 net.cpp:380] Eltwise1 -> Eltwise1
I1023 16:54:38.006045  5058 net.cpp:122] Setting up Eltwise1
I1023 16:54:38.006049  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.006052  5058 net.cpp:137] Memory required for data: 364478560
I1023 16:54:38.006053  5058 layer_factory.hpp:77] Creating layer elu3
I1023 16:54:38.006057  5058 net.cpp:84] Creating Layer elu3
I1023 16:54:38.006059  5058 net.cpp:406] elu3 <- Eltwise1
I1023 16:54:38.006062  5058 net.cpp:367] elu3 -> Eltwise1 (in-place)
I1023 16:54:38.006067  5058 net.cpp:122] Setting up elu3
I1023 16:54:38.006069  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.006072  5058 net.cpp:137] Memory required for data: 390168672
I1023 16:54:38.006073  5058 layer_factory.hpp:77] Creating layer Eltwise1_elu3_0_split
I1023 16:54:38.006078  5058 net.cpp:84] Creating Layer Eltwise1_elu3_0_split
I1023 16:54:38.006080  5058 net.cpp:406] Eltwise1_elu3_0_split <- Eltwise1
I1023 16:54:38.006083  5058 net.cpp:380] Eltwise1_elu3_0_split -> Eltwise1_elu3_0_split_0
I1023 16:54:38.006088  5058 net.cpp:380] Eltwise1_elu3_0_split -> Eltwise1_elu3_0_split_1
I1023 16:54:38.006110  5058 net.cpp:122] Setting up Eltwise1_elu3_0_split
I1023 16:54:38.006114  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.006117  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.006119  5058 net.cpp:137] Memory required for data: 441548896
I1023 16:54:38.006121  5058 layer_factory.hpp:77] Creating layer Convolution4
I1023 16:54:38.006139  5058 net.cpp:84] Creating Layer Convolution4
I1023 16:54:38.006141  5058 net.cpp:406] Convolution4 <- Eltwise1_elu3_0_split_0
I1023 16:54:38.006145  5058 net.cpp:380] Convolution4 -> Convolution4
I1023 16:54:38.007161  5058 net.cpp:122] Setting up Convolution4
I1023 16:54:38.007171  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.007174  5058 net.cpp:137] Memory required for data: 467239008
I1023 16:54:38.007179  5058 layer_factory.hpp:77] Creating layer BatchNorm4
I1023 16:54:38.007184  5058 net.cpp:84] Creating Layer BatchNorm4
I1023 16:54:38.007187  5058 net.cpp:406] BatchNorm4 <- Convolution4
I1023 16:54:38.007191  5058 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1023 16:54:38.007371  5058 net.cpp:122] Setting up BatchNorm4
I1023 16:54:38.007376  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.007380  5058 net.cpp:137] Memory required for data: 492929120
I1023 16:54:38.007385  5058 layer_factory.hpp:77] Creating layer Scale4
I1023 16:54:38.007388  5058 net.cpp:84] Creating Layer Scale4
I1023 16:54:38.007390  5058 net.cpp:406] Scale4 <- Convolution4
I1023 16:54:38.007395  5058 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1023 16:54:38.007796  5058 layer_factory.hpp:77] Creating layer Scale4
I1023 16:54:38.007916  5058 net.cpp:122] Setting up Scale4
I1023 16:54:38.007920  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.007922  5058 net.cpp:137] Memory required for data: 518619232
I1023 16:54:38.007926  5058 layer_factory.hpp:77] Creating layer elu4
I1023 16:54:38.007930  5058 net.cpp:84] Creating Layer elu4
I1023 16:54:38.007932  5058 net.cpp:406] elu4 <- Convolution4
I1023 16:54:38.007936  5058 net.cpp:367] elu4 -> Convolution4 (in-place)
I1023 16:54:38.007939  5058 net.cpp:122] Setting up elu4
I1023 16:54:38.007943  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.007946  5058 net.cpp:137] Memory required for data: 544309344
I1023 16:54:38.007947  5058 layer_factory.hpp:77] Creating layer Convolution5
I1023 16:54:38.007953  5058 net.cpp:84] Creating Layer Convolution5
I1023 16:54:38.007967  5058 net.cpp:406] Convolution5 <- Convolution4
I1023 16:54:38.007972  5058 net.cpp:380] Convolution5 -> Convolution5
I1023 16:54:38.009279  5058 net.cpp:122] Setting up Convolution5
I1023 16:54:38.009287  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.009290  5058 net.cpp:137] Memory required for data: 569999456
I1023 16:54:38.009294  5058 layer_factory.hpp:77] Creating layer BatchNorm5
I1023 16:54:38.009300  5058 net.cpp:84] Creating Layer BatchNorm5
I1023 16:54:38.009302  5058 net.cpp:406] BatchNorm5 <- Convolution5
I1023 16:54:38.009306  5058 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1023 16:54:38.009481  5058 net.cpp:122] Setting up BatchNorm5
I1023 16:54:38.009486  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.009488  5058 net.cpp:137] Memory required for data: 595689568
I1023 16:54:38.009497  5058 layer_factory.hpp:77] Creating layer Scale5
I1023 16:54:38.009501  5058 net.cpp:84] Creating Layer Scale5
I1023 16:54:38.009503  5058 net.cpp:406] Scale5 <- Convolution5
I1023 16:54:38.009507  5058 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1023 16:54:38.009536  5058 layer_factory.hpp:77] Creating layer Scale5
I1023 16:54:38.010184  5058 net.cpp:122] Setting up Scale5
I1023 16:54:38.010192  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.010195  5058 net.cpp:137] Memory required for data: 621379680
I1023 16:54:38.010200  5058 layer_factory.hpp:77] Creating layer Eltwise2
I1023 16:54:38.010205  5058 net.cpp:84] Creating Layer Eltwise2
I1023 16:54:38.010207  5058 net.cpp:406] Eltwise2 <- Eltwise1_elu3_0_split_1
I1023 16:54:38.010210  5058 net.cpp:406] Eltwise2 <- Convolution5
I1023 16:54:38.010213  5058 net.cpp:380] Eltwise2 -> Eltwise2
I1023 16:54:38.010232  5058 net.cpp:122] Setting up Eltwise2
I1023 16:54:38.010236  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.010238  5058 net.cpp:137] Memory required for data: 647069792
I1023 16:54:38.010252  5058 layer_factory.hpp:77] Creating layer elu5
I1023 16:54:38.010257  5058 net.cpp:84] Creating Layer elu5
I1023 16:54:38.010259  5058 net.cpp:406] elu5 <- Eltwise2
I1023 16:54:38.010262  5058 net.cpp:367] elu5 -> Eltwise2 (in-place)
I1023 16:54:38.010267  5058 net.cpp:122] Setting up elu5
I1023 16:54:38.010269  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.010272  5058 net.cpp:137] Memory required for data: 672759904
I1023 16:54:38.010274  5058 layer_factory.hpp:77] Creating layer Eltwise2_elu5_0_split
I1023 16:54:38.010278  5058 net.cpp:84] Creating Layer Eltwise2_elu5_0_split
I1023 16:54:38.010280  5058 net.cpp:406] Eltwise2_elu5_0_split <- Eltwise2
I1023 16:54:38.010282  5058 net.cpp:380] Eltwise2_elu5_0_split -> Eltwise2_elu5_0_split_0
I1023 16:54:38.010287  5058 net.cpp:380] Eltwise2_elu5_0_split -> Eltwise2_elu5_0_split_1
I1023 16:54:38.010313  5058 net.cpp:122] Setting up Eltwise2_elu5_0_split
I1023 16:54:38.010318  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.010320  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.010323  5058 net.cpp:137] Memory required for data: 724140128
I1023 16:54:38.010324  5058 layer_factory.hpp:77] Creating layer Convolution6
I1023 16:54:38.010331  5058 net.cpp:84] Creating Layer Convolution6
I1023 16:54:38.010334  5058 net.cpp:406] Convolution6 <- Eltwise2_elu5_0_split_0
I1023 16:54:38.010337  5058 net.cpp:380] Convolution6 -> Convolution6
I1023 16:54:38.011667  5058 net.cpp:122] Setting up Convolution6
I1023 16:54:38.011680  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.011684  5058 net.cpp:137] Memory required for data: 749830240
I1023 16:54:38.011693  5058 layer_factory.hpp:77] Creating layer BatchNorm6
I1023 16:54:38.011699  5058 net.cpp:84] Creating Layer BatchNorm6
I1023 16:54:38.011704  5058 net.cpp:406] BatchNorm6 <- Convolution6
I1023 16:54:38.011710  5058 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1023 16:54:38.011968  5058 net.cpp:122] Setting up BatchNorm6
I1023 16:54:38.011978  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.011982  5058 net.cpp:137] Memory required for data: 775520352
I1023 16:54:38.011991  5058 layer_factory.hpp:77] Creating layer Scale6
I1023 16:54:38.012001  5058 net.cpp:84] Creating Layer Scale6
I1023 16:54:38.012006  5058 net.cpp:406] Scale6 <- Convolution6
I1023 16:54:38.012010  5058 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1023 16:54:38.012056  5058 layer_factory.hpp:77] Creating layer Scale6
I1023 16:54:38.012264  5058 net.cpp:122] Setting up Scale6
I1023 16:54:38.012271  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.012275  5058 net.cpp:137] Memory required for data: 801210464
I1023 16:54:38.012282  5058 layer_factory.hpp:77] Creating layer elu6
I1023 16:54:38.012290  5058 net.cpp:84] Creating Layer elu6
I1023 16:54:38.012293  5058 net.cpp:406] elu6 <- Convolution6
I1023 16:54:38.012298  5058 net.cpp:367] elu6 -> Convolution6 (in-place)
I1023 16:54:38.012305  5058 net.cpp:122] Setting up elu6
I1023 16:54:38.012310  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.012315  5058 net.cpp:137] Memory required for data: 826900576
I1023 16:54:38.012318  5058 layer_factory.hpp:77] Creating layer Convolution7
I1023 16:54:38.012331  5058 net.cpp:84] Creating Layer Convolution7
I1023 16:54:38.012336  5058 net.cpp:406] Convolution7 <- Convolution6
I1023 16:54:38.012341  5058 net.cpp:380] Convolution7 -> Convolution7
I1023 16:54:38.014505  5058 net.cpp:122] Setting up Convolution7
I1023 16:54:38.014518  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.014520  5058 net.cpp:137] Memory required for data: 852590688
I1023 16:54:38.014525  5058 layer_factory.hpp:77] Creating layer BatchNorm7
I1023 16:54:38.014534  5058 net.cpp:84] Creating Layer BatchNorm7
I1023 16:54:38.014538  5058 net.cpp:406] BatchNorm7 <- Convolution7
I1023 16:54:38.014542  5058 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1023 16:54:38.014720  5058 net.cpp:122] Setting up BatchNorm7
I1023 16:54:38.014734  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.014736  5058 net.cpp:137] Memory required for data: 878280800
I1023 16:54:38.014741  5058 layer_factory.hpp:77] Creating layer Scale7
I1023 16:54:38.014746  5058 net.cpp:84] Creating Layer Scale7
I1023 16:54:38.014750  5058 net.cpp:406] Scale7 <- Convolution7
I1023 16:54:38.014752  5058 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1023 16:54:38.014783  5058 layer_factory.hpp:77] Creating layer Scale7
I1023 16:54:38.014925  5058 net.cpp:122] Setting up Scale7
I1023 16:54:38.014930  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.014932  5058 net.cpp:137] Memory required for data: 903970912
I1023 16:54:38.014936  5058 layer_factory.hpp:77] Creating layer Eltwise3
I1023 16:54:38.014940  5058 net.cpp:84] Creating Layer Eltwise3
I1023 16:54:38.014943  5058 net.cpp:406] Eltwise3 <- Eltwise2_elu5_0_split_1
I1023 16:54:38.014946  5058 net.cpp:406] Eltwise3 <- Convolution7
I1023 16:54:38.014950  5058 net.cpp:380] Eltwise3 -> Eltwise3
I1023 16:54:38.014968  5058 net.cpp:122] Setting up Eltwise3
I1023 16:54:38.014971  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.014973  5058 net.cpp:137] Memory required for data: 929661024
I1023 16:54:38.014976  5058 layer_factory.hpp:77] Creating layer elu7
I1023 16:54:38.014979  5058 net.cpp:84] Creating Layer elu7
I1023 16:54:38.014982  5058 net.cpp:406] elu7 <- Eltwise3
I1023 16:54:38.014986  5058 net.cpp:367] elu7 -> Eltwise3 (in-place)
I1023 16:54:38.014988  5058 net.cpp:122] Setting up elu7
I1023 16:54:38.014992  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.014994  5058 net.cpp:137] Memory required for data: 955351136
I1023 16:54:38.014997  5058 layer_factory.hpp:77] Creating layer Eltwise3_elu7_0_split
I1023 16:54:38.015000  5058 net.cpp:84] Creating Layer Eltwise3_elu7_0_split
I1023 16:54:38.015002  5058 net.cpp:406] Eltwise3_elu7_0_split <- Eltwise3
I1023 16:54:38.015005  5058 net.cpp:380] Eltwise3_elu7_0_split -> Eltwise3_elu7_0_split_0
I1023 16:54:38.015009  5058 net.cpp:380] Eltwise3_elu7_0_split -> Eltwise3_elu7_0_split_1
I1023 16:54:38.015038  5058 net.cpp:122] Setting up Eltwise3_elu7_0_split
I1023 16:54:38.015043  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.015046  5058 net.cpp:129] Top shape: 8 16 224 224 (6422528)
I1023 16:54:38.015048  5058 net.cpp:137] Memory required for data: 1006731360
I1023 16:54:38.015050  5058 layer_factory.hpp:77] Creating layer Convolution8
I1023 16:54:38.015058  5058 net.cpp:84] Creating Layer Convolution8
I1023 16:54:38.015060  5058 net.cpp:406] Convolution8 <- Eltwise3_elu7_0_split_0
I1023 16:54:38.015064  5058 net.cpp:380] Convolution8 -> Convolution8
I1023 16:54:38.016088  5058 net.cpp:122] Setting up Convolution8
I1023 16:54:38.016098  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.016100  5058 net.cpp:137] Memory required for data: 1019576416
I1023 16:54:38.016104  5058 layer_factory.hpp:77] Creating layer BatchNorm8
I1023 16:54:38.016109  5058 net.cpp:84] Creating Layer BatchNorm8
I1023 16:54:38.016113  5058 net.cpp:406] BatchNorm8 <- Convolution8
I1023 16:54:38.016115  5058 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1023 16:54:38.016266  5058 net.cpp:122] Setting up BatchNorm8
I1023 16:54:38.016270  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.016273  5058 net.cpp:137] Memory required for data: 1032421472
I1023 16:54:38.016278  5058 layer_factory.hpp:77] Creating layer Scale8
I1023 16:54:38.016283  5058 net.cpp:84] Creating Layer Scale8
I1023 16:54:38.016284  5058 net.cpp:406] Scale8 <- Convolution8
I1023 16:54:38.016288  5058 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1023 16:54:38.016317  5058 layer_factory.hpp:77] Creating layer Scale8
I1023 16:54:38.016407  5058 net.cpp:122] Setting up Scale8
I1023 16:54:38.016412  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.016414  5058 net.cpp:137] Memory required for data: 1045266528
I1023 16:54:38.016418  5058 layer_factory.hpp:77] Creating layer Convolution9
I1023 16:54:38.016435  5058 net.cpp:84] Creating Layer Convolution9
I1023 16:54:38.016438  5058 net.cpp:406] Convolution9 <- Eltwise3_elu7_0_split_1
I1023 16:54:38.016443  5058 net.cpp:380] Convolution9 -> Convolution9
I1023 16:54:38.017485  5058 net.cpp:122] Setting up Convolution9
I1023 16:54:38.017494  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.017498  5058 net.cpp:137] Memory required for data: 1058111584
I1023 16:54:38.017503  5058 layer_factory.hpp:77] Creating layer BatchNorm9
I1023 16:54:38.017508  5058 net.cpp:84] Creating Layer BatchNorm9
I1023 16:54:38.017510  5058 net.cpp:406] BatchNorm9 <- Convolution9
I1023 16:54:38.017513  5058 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1023 16:54:38.017676  5058 net.cpp:122] Setting up BatchNorm9
I1023 16:54:38.017681  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.017683  5058 net.cpp:137] Memory required for data: 1070956640
I1023 16:54:38.017688  5058 layer_factory.hpp:77] Creating layer Scale9
I1023 16:54:38.017693  5058 net.cpp:84] Creating Layer Scale9
I1023 16:54:38.017695  5058 net.cpp:406] Scale9 <- Convolution9
I1023 16:54:38.017699  5058 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1023 16:54:38.017729  5058 layer_factory.hpp:77] Creating layer Scale9
I1023 16:54:38.017827  5058 net.cpp:122] Setting up Scale9
I1023 16:54:38.017832  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.017835  5058 net.cpp:137] Memory required for data: 1083801696
I1023 16:54:38.017839  5058 layer_factory.hpp:77] Creating layer elu8
I1023 16:54:38.017843  5058 net.cpp:84] Creating Layer elu8
I1023 16:54:38.017846  5058 net.cpp:406] elu8 <- Convolution9
I1023 16:54:38.017849  5058 net.cpp:367] elu8 -> Convolution9 (in-place)
I1023 16:54:38.017853  5058 net.cpp:122] Setting up elu8
I1023 16:54:38.017856  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.017858  5058 net.cpp:137] Memory required for data: 1096646752
I1023 16:54:38.017860  5058 layer_factory.hpp:77] Creating layer Convolution10
I1023 16:54:38.017868  5058 net.cpp:84] Creating Layer Convolution10
I1023 16:54:38.017869  5058 net.cpp:406] Convolution10 <- Convolution9
I1023 16:54:38.017874  5058 net.cpp:380] Convolution10 -> Convolution10
I1023 16:54:38.020197  5058 net.cpp:122] Setting up Convolution10
I1023 16:54:38.020210  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.020212  5058 net.cpp:137] Memory required for data: 1109491808
I1023 16:54:38.020227  5058 layer_factory.hpp:77] Creating layer BatchNorm10
I1023 16:54:38.020234  5058 net.cpp:84] Creating Layer BatchNorm10
I1023 16:54:38.020237  5058 net.cpp:406] BatchNorm10 <- Convolution10
I1023 16:54:38.020241  5058 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1023 16:54:38.020400  5058 net.cpp:122] Setting up BatchNorm10
I1023 16:54:38.020404  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.020406  5058 net.cpp:137] Memory required for data: 1122336864
I1023 16:54:38.020411  5058 layer_factory.hpp:77] Creating layer Scale10
I1023 16:54:38.020416  5058 net.cpp:84] Creating Layer Scale10
I1023 16:54:38.020418  5058 net.cpp:406] Scale10 <- Convolution10
I1023 16:54:38.020422  5058 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1023 16:54:38.020454  5058 layer_factory.hpp:77] Creating layer Scale10
I1023 16:54:38.020545  5058 net.cpp:122] Setting up Scale10
I1023 16:54:38.020550  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.020552  5058 net.cpp:137] Memory required for data: 1135181920
I1023 16:54:38.020556  5058 layer_factory.hpp:77] Creating layer Eltwise4
I1023 16:54:38.020560  5058 net.cpp:84] Creating Layer Eltwise4
I1023 16:54:38.020563  5058 net.cpp:406] Eltwise4 <- Convolution8
I1023 16:54:38.020566  5058 net.cpp:406] Eltwise4 <- Convolution10
I1023 16:54:38.020570  5058 net.cpp:380] Eltwise4 -> Eltwise4
I1023 16:54:38.020589  5058 net.cpp:122] Setting up Eltwise4
I1023 16:54:38.020593  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.020596  5058 net.cpp:137] Memory required for data: 1148026976
I1023 16:54:38.020611  5058 layer_factory.hpp:77] Creating layer elu9
I1023 16:54:38.020615  5058 net.cpp:84] Creating Layer elu9
I1023 16:54:38.020618  5058 net.cpp:406] elu9 <- Eltwise4
I1023 16:54:38.020622  5058 net.cpp:367] elu9 -> Eltwise4 (in-place)
I1023 16:54:38.020625  5058 net.cpp:122] Setting up elu9
I1023 16:54:38.020628  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.020632  5058 net.cpp:137] Memory required for data: 1160872032
I1023 16:54:38.020633  5058 layer_factory.hpp:77] Creating layer Eltwise4_elu9_0_split
I1023 16:54:38.020637  5058 net.cpp:84] Creating Layer Eltwise4_elu9_0_split
I1023 16:54:38.020639  5058 net.cpp:406] Eltwise4_elu9_0_split <- Eltwise4
I1023 16:54:38.020642  5058 net.cpp:380] Eltwise4_elu9_0_split -> Eltwise4_elu9_0_split_0
I1023 16:54:38.020647  5058 net.cpp:380] Eltwise4_elu9_0_split -> Eltwise4_elu9_0_split_1
I1023 16:54:38.020673  5058 net.cpp:122] Setting up Eltwise4_elu9_0_split
I1023 16:54:38.020675  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.020678  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.020681  5058 net.cpp:137] Memory required for data: 1186562144
I1023 16:54:38.020684  5058 layer_factory.hpp:77] Creating layer Convolution11
I1023 16:54:38.020690  5058 net.cpp:84] Creating Layer Convolution11
I1023 16:54:38.020694  5058 net.cpp:406] Convolution11 <- Eltwise4_elu9_0_split_0
I1023 16:54:38.020697  5058 net.cpp:380] Convolution11 -> Convolution11
I1023 16:54:38.021852  5058 net.cpp:122] Setting up Convolution11
I1023 16:54:38.021862  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.021864  5058 net.cpp:137] Memory required for data: 1199407200
I1023 16:54:38.021868  5058 layer_factory.hpp:77] Creating layer BatchNorm11
I1023 16:54:38.021873  5058 net.cpp:84] Creating Layer BatchNorm11
I1023 16:54:38.021877  5058 net.cpp:406] BatchNorm11 <- Convolution11
I1023 16:54:38.021881  5058 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1023 16:54:38.022047  5058 net.cpp:122] Setting up BatchNorm11
I1023 16:54:38.022053  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.022055  5058 net.cpp:137] Memory required for data: 1212252256
I1023 16:54:38.022060  5058 layer_factory.hpp:77] Creating layer Scale11
I1023 16:54:38.022065  5058 net.cpp:84] Creating Layer Scale11
I1023 16:54:38.022068  5058 net.cpp:406] Scale11 <- Convolution11
I1023 16:54:38.022071  5058 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1023 16:54:38.022101  5058 layer_factory.hpp:77] Creating layer Scale11
I1023 16:54:38.022205  5058 net.cpp:122] Setting up Scale11
I1023 16:54:38.022210  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.022212  5058 net.cpp:137] Memory required for data: 1225097312
I1023 16:54:38.022217  5058 layer_factory.hpp:77] Creating layer elu10
I1023 16:54:38.022222  5058 net.cpp:84] Creating Layer elu10
I1023 16:54:38.022223  5058 net.cpp:406] elu10 <- Convolution11
I1023 16:54:38.022227  5058 net.cpp:367] elu10 -> Convolution11 (in-place)
I1023 16:54:38.022231  5058 net.cpp:122] Setting up elu10
I1023 16:54:38.022234  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.022236  5058 net.cpp:137] Memory required for data: 1237942368
I1023 16:54:38.022238  5058 layer_factory.hpp:77] Creating layer Convolution12
I1023 16:54:38.022248  5058 net.cpp:84] Creating Layer Convolution12
I1023 16:54:38.022250  5058 net.cpp:406] Convolution12 <- Convolution11
I1023 16:54:38.022254  5058 net.cpp:380] Convolution12 -> Convolution12
I1023 16:54:38.023013  5058 net.cpp:122] Setting up Convolution12
I1023 16:54:38.023021  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.023023  5058 net.cpp:137] Memory required for data: 1250787424
I1023 16:54:38.023027  5058 layer_factory.hpp:77] Creating layer BatchNorm12
I1023 16:54:38.023032  5058 net.cpp:84] Creating Layer BatchNorm12
I1023 16:54:38.023036  5058 net.cpp:406] BatchNorm12 <- Convolution12
I1023 16:54:38.023039  5058 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1023 16:54:38.023198  5058 net.cpp:122] Setting up BatchNorm12
I1023 16:54:38.023203  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.023205  5058 net.cpp:137] Memory required for data: 1263632480
I1023 16:54:38.023211  5058 layer_factory.hpp:77] Creating layer Scale12
I1023 16:54:38.023213  5058 net.cpp:84] Creating Layer Scale12
I1023 16:54:38.023216  5058 net.cpp:406] Scale12 <- Convolution12
I1023 16:54:38.023219  5058 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1023 16:54:38.023248  5058 layer_factory.hpp:77] Creating layer Scale12
I1023 16:54:38.023342  5058 net.cpp:122] Setting up Scale12
I1023 16:54:38.023347  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.023350  5058 net.cpp:137] Memory required for data: 1276477536
I1023 16:54:38.023353  5058 layer_factory.hpp:77] Creating layer Eltwise5
I1023 16:54:38.023357  5058 net.cpp:84] Creating Layer Eltwise5
I1023 16:54:38.023360  5058 net.cpp:406] Eltwise5 <- Eltwise4_elu9_0_split_1
I1023 16:54:38.023362  5058 net.cpp:406] Eltwise5 <- Convolution12
I1023 16:54:38.023366  5058 net.cpp:380] Eltwise5 -> Eltwise5
I1023 16:54:38.023385  5058 net.cpp:122] Setting up Eltwise5
I1023 16:54:38.023387  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.023389  5058 net.cpp:137] Memory required for data: 1289322592
I1023 16:54:38.023392  5058 layer_factory.hpp:77] Creating layer elu11
I1023 16:54:38.023396  5058 net.cpp:84] Creating Layer elu11
I1023 16:54:38.023399  5058 net.cpp:406] elu11 <- Eltwise5
I1023 16:54:38.023401  5058 net.cpp:367] elu11 -> Eltwise5 (in-place)
I1023 16:54:38.023406  5058 net.cpp:122] Setting up elu11
I1023 16:54:38.023408  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.023411  5058 net.cpp:137] Memory required for data: 1302167648
I1023 16:54:38.023412  5058 layer_factory.hpp:77] Creating layer Eltwise5_elu11_0_split
I1023 16:54:38.023416  5058 net.cpp:84] Creating Layer Eltwise5_elu11_0_split
I1023 16:54:38.023418  5058 net.cpp:406] Eltwise5_elu11_0_split <- Eltwise5
I1023 16:54:38.023422  5058 net.cpp:380] Eltwise5_elu11_0_split -> Eltwise5_elu11_0_split_0
I1023 16:54:38.023425  5058 net.cpp:380] Eltwise5_elu11_0_split -> Eltwise5_elu11_0_split_1
I1023 16:54:38.023452  5058 net.cpp:122] Setting up Eltwise5_elu11_0_split
I1023 16:54:38.023457  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.023461  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.023463  5058 net.cpp:137] Memory required for data: 1327857760
I1023 16:54:38.023466  5058 layer_factory.hpp:77] Creating layer Convolution13
I1023 16:54:38.023473  5058 net.cpp:84] Creating Layer Convolution13
I1023 16:54:38.023475  5058 net.cpp:406] Convolution13 <- Eltwise5_elu11_0_split_0
I1023 16:54:38.023479  5058 net.cpp:380] Convolution13 -> Convolution13
I1023 16:54:38.024591  5058 net.cpp:122] Setting up Convolution13
I1023 16:54:38.024600  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.024603  5058 net.cpp:137] Memory required for data: 1340702816
I1023 16:54:38.024608  5058 layer_factory.hpp:77] Creating layer BatchNorm13
I1023 16:54:38.024613  5058 net.cpp:84] Creating Layer BatchNorm13
I1023 16:54:38.024616  5058 net.cpp:406] BatchNorm13 <- Convolution13
I1023 16:54:38.024619  5058 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1023 16:54:38.024773  5058 net.cpp:122] Setting up BatchNorm13
I1023 16:54:38.024778  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.024780  5058 net.cpp:137] Memory required for data: 1353547872
I1023 16:54:38.024785  5058 layer_factory.hpp:77] Creating layer Scale13
I1023 16:54:38.024790  5058 net.cpp:84] Creating Layer Scale13
I1023 16:54:38.024791  5058 net.cpp:406] Scale13 <- Convolution13
I1023 16:54:38.024796  5058 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1023 16:54:38.024824  5058 layer_factory.hpp:77] Creating layer Scale13
I1023 16:54:38.024917  5058 net.cpp:122] Setting up Scale13
I1023 16:54:38.024922  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.024924  5058 net.cpp:137] Memory required for data: 1366392928
I1023 16:54:38.024935  5058 layer_factory.hpp:77] Creating layer elu12
I1023 16:54:38.024940  5058 net.cpp:84] Creating Layer elu12
I1023 16:54:38.024942  5058 net.cpp:406] elu12 <- Convolution13
I1023 16:54:38.024945  5058 net.cpp:367] elu12 -> Convolution13 (in-place)
I1023 16:54:38.024950  5058 net.cpp:122] Setting up elu12
I1023 16:54:38.024952  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.024955  5058 net.cpp:137] Memory required for data: 1379237984
I1023 16:54:38.024956  5058 layer_factory.hpp:77] Creating layer Convolution14
I1023 16:54:38.024967  5058 net.cpp:84] Creating Layer Convolution14
I1023 16:54:38.024971  5058 net.cpp:406] Convolution14 <- Convolution13
I1023 16:54:38.024974  5058 net.cpp:380] Convolution14 -> Convolution14
I1023 16:54:38.026083  5058 net.cpp:122] Setting up Convolution14
I1023 16:54:38.026093  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.026094  5058 net.cpp:137] Memory required for data: 1392083040
I1023 16:54:38.026099  5058 layer_factory.hpp:77] Creating layer BatchNorm14
I1023 16:54:38.026105  5058 net.cpp:84] Creating Layer BatchNorm14
I1023 16:54:38.026108  5058 net.cpp:406] BatchNorm14 <- Convolution14
I1023 16:54:38.026111  5058 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1023 16:54:38.026263  5058 net.cpp:122] Setting up BatchNorm14
I1023 16:54:38.026268  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.026270  5058 net.cpp:137] Memory required for data: 1404928096
I1023 16:54:38.026275  5058 layer_factory.hpp:77] Creating layer Scale14
I1023 16:54:38.026280  5058 net.cpp:84] Creating Layer Scale14
I1023 16:54:38.026283  5058 net.cpp:406] Scale14 <- Convolution14
I1023 16:54:38.026286  5058 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1023 16:54:38.026315  5058 layer_factory.hpp:77] Creating layer Scale14
I1023 16:54:38.026412  5058 net.cpp:122] Setting up Scale14
I1023 16:54:38.026417  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.026418  5058 net.cpp:137] Memory required for data: 1417773152
I1023 16:54:38.026422  5058 layer_factory.hpp:77] Creating layer Eltwise6
I1023 16:54:38.026425  5058 net.cpp:84] Creating Layer Eltwise6
I1023 16:54:38.026428  5058 net.cpp:406] Eltwise6 <- Eltwise5_elu11_0_split_1
I1023 16:54:38.026432  5058 net.cpp:406] Eltwise6 <- Convolution14
I1023 16:54:38.026435  5058 net.cpp:380] Eltwise6 -> Eltwise6
I1023 16:54:38.026453  5058 net.cpp:122] Setting up Eltwise6
I1023 16:54:38.026458  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.026459  5058 net.cpp:137] Memory required for data: 1430618208
I1023 16:54:38.026461  5058 layer_factory.hpp:77] Creating layer elu13
I1023 16:54:38.026464  5058 net.cpp:84] Creating Layer elu13
I1023 16:54:38.026468  5058 net.cpp:406] elu13 <- Eltwise6
I1023 16:54:38.026470  5058 net.cpp:367] elu13 -> Eltwise6 (in-place)
I1023 16:54:38.026473  5058 net.cpp:122] Setting up elu13
I1023 16:54:38.026476  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.026479  5058 net.cpp:137] Memory required for data: 1443463264
I1023 16:54:38.026480  5058 layer_factory.hpp:77] Creating layer Eltwise6_elu13_0_split
I1023 16:54:38.026484  5058 net.cpp:84] Creating Layer Eltwise6_elu13_0_split
I1023 16:54:38.026487  5058 net.cpp:406] Eltwise6_elu13_0_split <- Eltwise6
I1023 16:54:38.026490  5058 net.cpp:380] Eltwise6_elu13_0_split -> Eltwise6_elu13_0_split_0
I1023 16:54:38.026494  5058 net.cpp:380] Eltwise6_elu13_0_split -> Eltwise6_elu13_0_split_1
I1023 16:54:38.026520  5058 net.cpp:122] Setting up Eltwise6_elu13_0_split
I1023 16:54:38.026523  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.026526  5058 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I1023 16:54:38.026528  5058 net.cpp:137] Memory required for data: 1469153376
I1023 16:54:38.026530  5058 layer_factory.hpp:77] Creating layer Convolution15
I1023 16:54:38.026535  5058 net.cpp:84] Creating Layer Convolution15
I1023 16:54:38.026538  5058 net.cpp:406] Convolution15 <- Eltwise6_elu13_0_split_0
I1023 16:54:38.026549  5058 net.cpp:380] Convolution15 -> Convolution15
I1023 16:54:38.027501  5058 net.cpp:122] Setting up Convolution15
I1023 16:54:38.027509  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.027513  5058 net.cpp:137] Memory required for data: 1475575904
I1023 16:54:38.027518  5058 layer_factory.hpp:77] Creating layer BatchNorm15
I1023 16:54:38.027523  5058 net.cpp:84] Creating Layer BatchNorm15
I1023 16:54:38.027526  5058 net.cpp:406] BatchNorm15 <- Convolution15
I1023 16:54:38.027529  5058 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1023 16:54:38.027681  5058 net.cpp:122] Setting up BatchNorm15
I1023 16:54:38.027685  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.027688  5058 net.cpp:137] Memory required for data: 1481998432
I1023 16:54:38.027693  5058 layer_factory.hpp:77] Creating layer Scale15
I1023 16:54:38.027696  5058 net.cpp:84] Creating Layer Scale15
I1023 16:54:38.027699  5058 net.cpp:406] Scale15 <- Convolution15
I1023 16:54:38.027703  5058 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1023 16:54:38.027731  5058 layer_factory.hpp:77] Creating layer Scale15
I1023 16:54:38.027819  5058 net.cpp:122] Setting up Scale15
I1023 16:54:38.027824  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.027827  5058 net.cpp:137] Memory required for data: 1488420960
I1023 16:54:38.027830  5058 layer_factory.hpp:77] Creating layer Convolution16
I1023 16:54:38.027837  5058 net.cpp:84] Creating Layer Convolution16
I1023 16:54:38.027839  5058 net.cpp:406] Convolution16 <- Eltwise6_elu13_0_split_1
I1023 16:54:38.027844  5058 net.cpp:380] Convolution16 -> Convolution16
I1023 16:54:38.029141  5058 net.cpp:122] Setting up Convolution16
I1023 16:54:38.029150  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.029153  5058 net.cpp:137] Memory required for data: 1494843488
I1023 16:54:38.029158  5058 layer_factory.hpp:77] Creating layer BatchNorm16
I1023 16:54:38.029162  5058 net.cpp:84] Creating Layer BatchNorm16
I1023 16:54:38.029165  5058 net.cpp:406] BatchNorm16 <- Convolution16
I1023 16:54:38.029170  5058 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1023 16:54:38.029320  5058 net.cpp:122] Setting up BatchNorm16
I1023 16:54:38.029325  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.029327  5058 net.cpp:137] Memory required for data: 1501266016
I1023 16:54:38.029331  5058 layer_factory.hpp:77] Creating layer Scale16
I1023 16:54:38.029335  5058 net.cpp:84] Creating Layer Scale16
I1023 16:54:38.029338  5058 net.cpp:406] Scale16 <- Convolution16
I1023 16:54:38.029341  5058 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1023 16:54:38.029371  5058 layer_factory.hpp:77] Creating layer Scale16
I1023 16:54:38.029460  5058 net.cpp:122] Setting up Scale16
I1023 16:54:38.029465  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.029467  5058 net.cpp:137] Memory required for data: 1507688544
I1023 16:54:38.029471  5058 layer_factory.hpp:77] Creating layer elu14
I1023 16:54:38.029474  5058 net.cpp:84] Creating Layer elu14
I1023 16:54:38.029477  5058 net.cpp:406] elu14 <- Convolution16
I1023 16:54:38.029479  5058 net.cpp:367] elu14 -> Convolution16 (in-place)
I1023 16:54:38.029484  5058 net.cpp:122] Setting up elu14
I1023 16:54:38.029486  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.029489  5058 net.cpp:137] Memory required for data: 1514111072
I1023 16:54:38.029490  5058 layer_factory.hpp:77] Creating layer Convolution17
I1023 16:54:38.029497  5058 net.cpp:84] Creating Layer Convolution17
I1023 16:54:38.029500  5058 net.cpp:406] Convolution17 <- Convolution16
I1023 16:54:38.029503  5058 net.cpp:380] Convolution17 -> Convolution17
I1023 16:54:38.031766  5058 net.cpp:122] Setting up Convolution17
I1023 16:54:38.031775  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.031777  5058 net.cpp:137] Memory required for data: 1520533600
I1023 16:54:38.031782  5058 layer_factory.hpp:77] Creating layer BatchNorm17
I1023 16:54:38.031788  5058 net.cpp:84] Creating Layer BatchNorm17
I1023 16:54:38.031797  5058 net.cpp:406] BatchNorm17 <- Convolution17
I1023 16:54:38.031801  5058 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1023 16:54:38.031965  5058 net.cpp:122] Setting up BatchNorm17
I1023 16:54:38.031971  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.031973  5058 net.cpp:137] Memory required for data: 1526956128
I1023 16:54:38.031978  5058 layer_factory.hpp:77] Creating layer Scale17
I1023 16:54:38.031982  5058 net.cpp:84] Creating Layer Scale17
I1023 16:54:38.031985  5058 net.cpp:406] Scale17 <- Convolution17
I1023 16:54:38.031989  5058 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1023 16:54:38.032019  5058 layer_factory.hpp:77] Creating layer Scale17
I1023 16:54:38.032111  5058 net.cpp:122] Setting up Scale17
I1023 16:54:38.032116  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.032119  5058 net.cpp:137] Memory required for data: 1533378656
I1023 16:54:38.032122  5058 layer_factory.hpp:77] Creating layer Eltwise7
I1023 16:54:38.032126  5058 net.cpp:84] Creating Layer Eltwise7
I1023 16:54:38.032129  5058 net.cpp:406] Eltwise7 <- Convolution15
I1023 16:54:38.032131  5058 net.cpp:406] Eltwise7 <- Convolution17
I1023 16:54:38.032135  5058 net.cpp:380] Eltwise7 -> Eltwise7
I1023 16:54:38.032155  5058 net.cpp:122] Setting up Eltwise7
I1023 16:54:38.032157  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.032160  5058 net.cpp:137] Memory required for data: 1539801184
I1023 16:54:38.032162  5058 layer_factory.hpp:77] Creating layer elu15
I1023 16:54:38.032166  5058 net.cpp:84] Creating Layer elu15
I1023 16:54:38.032167  5058 net.cpp:406] elu15 <- Eltwise7
I1023 16:54:38.032171  5058 net.cpp:367] elu15 -> Eltwise7 (in-place)
I1023 16:54:38.032174  5058 net.cpp:122] Setting up elu15
I1023 16:54:38.032177  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.032179  5058 net.cpp:137] Memory required for data: 1546223712
I1023 16:54:38.032181  5058 layer_factory.hpp:77] Creating layer Eltwise7_elu15_0_split
I1023 16:54:38.032186  5058 net.cpp:84] Creating Layer Eltwise7_elu15_0_split
I1023 16:54:38.032187  5058 net.cpp:406] Eltwise7_elu15_0_split <- Eltwise7
I1023 16:54:38.032191  5058 net.cpp:380] Eltwise7_elu15_0_split -> Eltwise7_elu15_0_split_0
I1023 16:54:38.041184  5058 net.cpp:380] Eltwise7_elu15_0_split -> Eltwise7_elu15_0_split_1
I1023 16:54:38.041241  5058 net.cpp:122] Setting up Eltwise7_elu15_0_split
I1023 16:54:38.041249  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.041255  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.041260  5058 net.cpp:137] Memory required for data: 1559068768
I1023 16:54:38.041263  5058 layer_factory.hpp:77] Creating layer Convolution18
I1023 16:54:38.041273  5058 net.cpp:84] Creating Layer Convolution18
I1023 16:54:38.041277  5058 net.cpp:406] Convolution18 <- Eltwise7_elu15_0_split_0
I1023 16:54:38.041286  5058 net.cpp:380] Convolution18 -> Convolution18
I1023 16:54:38.044714  5058 net.cpp:122] Setting up Convolution18
I1023 16:54:38.044725  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.044729  5058 net.cpp:137] Memory required for data: 1565491296
I1023 16:54:38.044734  5058 layer_factory.hpp:77] Creating layer BatchNorm18
I1023 16:54:38.044739  5058 net.cpp:84] Creating Layer BatchNorm18
I1023 16:54:38.044742  5058 net.cpp:406] BatchNorm18 <- Convolution18
I1023 16:54:38.044746  5058 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1023 16:54:38.044919  5058 net.cpp:122] Setting up BatchNorm18
I1023 16:54:38.044924  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.044925  5058 net.cpp:137] Memory required for data: 1571913824
I1023 16:54:38.044930  5058 layer_factory.hpp:77] Creating layer Scale18
I1023 16:54:38.044934  5058 net.cpp:84] Creating Layer Scale18
I1023 16:54:38.044936  5058 net.cpp:406] Scale18 <- Convolution18
I1023 16:54:38.044940  5058 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1023 16:54:38.044970  5058 layer_factory.hpp:77] Creating layer Scale18
I1023 16:54:38.045061  5058 net.cpp:122] Setting up Scale18
I1023 16:54:38.045073  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.045075  5058 net.cpp:137] Memory required for data: 1578336352
I1023 16:54:38.045079  5058 layer_factory.hpp:77] Creating layer elu16
I1023 16:54:38.045083  5058 net.cpp:84] Creating Layer elu16
I1023 16:54:38.045085  5058 net.cpp:406] elu16 <- Convolution18
I1023 16:54:38.045089  5058 net.cpp:367] elu16 -> Convolution18 (in-place)
I1023 16:54:38.045092  5058 net.cpp:122] Setting up elu16
I1023 16:54:38.045095  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.045097  5058 net.cpp:137] Memory required for data: 1584758880
I1023 16:54:38.045100  5058 layer_factory.hpp:77] Creating layer Convolution19
I1023 16:54:38.045107  5058 net.cpp:84] Creating Layer Convolution19
I1023 16:54:38.045109  5058 net.cpp:406] Convolution19 <- Convolution18
I1023 16:54:38.045114  5058 net.cpp:380] Convolution19 -> Convolution19
I1023 16:54:38.046877  5058 net.cpp:122] Setting up Convolution19
I1023 16:54:38.046885  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.046888  5058 net.cpp:137] Memory required for data: 1591181408
I1023 16:54:38.046892  5058 layer_factory.hpp:77] Creating layer BatchNorm19
I1023 16:54:38.046898  5058 net.cpp:84] Creating Layer BatchNorm19
I1023 16:54:38.046901  5058 net.cpp:406] BatchNorm19 <- Convolution19
I1023 16:54:38.046905  5058 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1023 16:54:38.047056  5058 net.cpp:122] Setting up BatchNorm19
I1023 16:54:38.047061  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.047063  5058 net.cpp:137] Memory required for data: 1597603936
I1023 16:54:38.047080  5058 layer_factory.hpp:77] Creating layer Scale19
I1023 16:54:38.047086  5058 net.cpp:84] Creating Layer Scale19
I1023 16:54:38.047088  5058 net.cpp:406] Scale19 <- Convolution19
I1023 16:54:38.047091  5058 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1023 16:54:38.047123  5058 layer_factory.hpp:77] Creating layer Scale19
I1023 16:54:38.047210  5058 net.cpp:122] Setting up Scale19
I1023 16:54:38.047215  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.047217  5058 net.cpp:137] Memory required for data: 1604026464
I1023 16:54:38.047221  5058 layer_factory.hpp:77] Creating layer Eltwise8
I1023 16:54:38.047226  5058 net.cpp:84] Creating Layer Eltwise8
I1023 16:54:38.047228  5058 net.cpp:406] Eltwise8 <- Eltwise7_elu15_0_split_1
I1023 16:54:38.047231  5058 net.cpp:406] Eltwise8 <- Convolution19
I1023 16:54:38.047235  5058 net.cpp:380] Eltwise8 -> Eltwise8
I1023 16:54:38.047253  5058 net.cpp:122] Setting up Eltwise8
I1023 16:54:38.047256  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.047258  5058 net.cpp:137] Memory required for data: 1610448992
I1023 16:54:38.047260  5058 layer_factory.hpp:77] Creating layer elu17
I1023 16:54:38.047264  5058 net.cpp:84] Creating Layer elu17
I1023 16:54:38.047266  5058 net.cpp:406] elu17 <- Eltwise8
I1023 16:54:38.047271  5058 net.cpp:367] elu17 -> Eltwise8 (in-place)
I1023 16:54:38.047273  5058 net.cpp:122] Setting up elu17
I1023 16:54:38.047276  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.047278  5058 net.cpp:137] Memory required for data: 1616871520
I1023 16:54:38.047281  5058 layer_factory.hpp:77] Creating layer Eltwise8_elu17_0_split
I1023 16:54:38.047284  5058 net.cpp:84] Creating Layer Eltwise8_elu17_0_split
I1023 16:54:38.047286  5058 net.cpp:406] Eltwise8_elu17_0_split <- Eltwise8
I1023 16:54:38.047289  5058 net.cpp:380] Eltwise8_elu17_0_split -> Eltwise8_elu17_0_split_0
I1023 16:54:38.047292  5058 net.cpp:380] Eltwise8_elu17_0_split -> Eltwise8_elu17_0_split_1
I1023 16:54:38.047318  5058 net.cpp:122] Setting up Eltwise8_elu17_0_split
I1023 16:54:38.047322  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.047324  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.047327  5058 net.cpp:137] Memory required for data: 1629716576
I1023 16:54:38.047328  5058 layer_factory.hpp:77] Creating layer Convolution20
I1023 16:54:38.047334  5058 net.cpp:84] Creating Layer Convolution20
I1023 16:54:38.047343  5058 net.cpp:406] Convolution20 <- Eltwise8_elu17_0_split_0
I1023 16:54:38.047348  5058 net.cpp:380] Convolution20 -> Convolution20
I1023 16:54:38.049381  5058 net.cpp:122] Setting up Convolution20
I1023 16:54:38.049391  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.049392  5058 net.cpp:137] Memory required for data: 1636139104
I1023 16:54:38.049397  5058 layer_factory.hpp:77] Creating layer BatchNorm20
I1023 16:54:38.049402  5058 net.cpp:84] Creating Layer BatchNorm20
I1023 16:54:38.049405  5058 net.cpp:406] BatchNorm20 <- Convolution20
I1023 16:54:38.049409  5058 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1023 16:54:38.049561  5058 net.cpp:122] Setting up BatchNorm20
I1023 16:54:38.049566  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.049567  5058 net.cpp:137] Memory required for data: 1642561632
I1023 16:54:38.049572  5058 layer_factory.hpp:77] Creating layer Scale20
I1023 16:54:38.049577  5058 net.cpp:84] Creating Layer Scale20
I1023 16:54:38.049579  5058 net.cpp:406] Scale20 <- Convolution20
I1023 16:54:38.049583  5058 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1023 16:54:38.049612  5058 layer_factory.hpp:77] Creating layer Scale20
I1023 16:54:38.049702  5058 net.cpp:122] Setting up Scale20
I1023 16:54:38.049706  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.049708  5058 net.cpp:137] Memory required for data: 1648984160
I1023 16:54:38.049712  5058 layer_factory.hpp:77] Creating layer elu18
I1023 16:54:38.049716  5058 net.cpp:84] Creating Layer elu18
I1023 16:54:38.049720  5058 net.cpp:406] elu18 <- Convolution20
I1023 16:54:38.049721  5058 net.cpp:367] elu18 -> Convolution20 (in-place)
I1023 16:54:38.049726  5058 net.cpp:122] Setting up elu18
I1023 16:54:38.049728  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.049731  5058 net.cpp:137] Memory required for data: 1655406688
I1023 16:54:38.049732  5058 layer_factory.hpp:77] Creating layer Convolution21
I1023 16:54:38.049739  5058 net.cpp:84] Creating Layer Convolution21
I1023 16:54:38.049741  5058 net.cpp:406] Convolution21 <- Convolution20
I1023 16:54:38.049746  5058 net.cpp:380] Convolution21 -> Convolution21
I1023 16:54:38.051434  5058 net.cpp:122] Setting up Convolution21
I1023 16:54:38.051443  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.051445  5058 net.cpp:137] Memory required for data: 1661829216
I1023 16:54:38.051450  5058 layer_factory.hpp:77] Creating layer BatchNorm21
I1023 16:54:38.051455  5058 net.cpp:84] Creating Layer BatchNorm21
I1023 16:54:38.051458  5058 net.cpp:406] BatchNorm21 <- Convolution21
I1023 16:54:38.051461  5058 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1023 16:54:38.051615  5058 net.cpp:122] Setting up BatchNorm21
I1023 16:54:38.051620  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.051622  5058 net.cpp:137] Memory required for data: 1668251744
I1023 16:54:38.051627  5058 layer_factory.hpp:77] Creating layer Scale21
I1023 16:54:38.051631  5058 net.cpp:84] Creating Layer Scale21
I1023 16:54:38.051633  5058 net.cpp:406] Scale21 <- Convolution21
I1023 16:54:38.051636  5058 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1023 16:54:38.051667  5058 layer_factory.hpp:77] Creating layer Scale21
I1023 16:54:38.051756  5058 net.cpp:122] Setting up Scale21
I1023 16:54:38.051760  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.051764  5058 net.cpp:137] Memory required for data: 1674674272
I1023 16:54:38.051766  5058 layer_factory.hpp:77] Creating layer Eltwise9
I1023 16:54:38.051771  5058 net.cpp:84] Creating Layer Eltwise9
I1023 16:54:38.051774  5058 net.cpp:406] Eltwise9 <- Eltwise8_elu17_0_split_1
I1023 16:54:38.051777  5058 net.cpp:406] Eltwise9 <- Convolution21
I1023 16:54:38.051780  5058 net.cpp:380] Eltwise9 -> Eltwise9
I1023 16:54:38.051797  5058 net.cpp:122] Setting up Eltwise9
I1023 16:54:38.051801  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.051803  5058 net.cpp:137] Memory required for data: 1681096800
I1023 16:54:38.051811  5058 layer_factory.hpp:77] Creating layer elu19
I1023 16:54:38.051815  5058 net.cpp:84] Creating Layer elu19
I1023 16:54:38.051817  5058 net.cpp:406] elu19 <- Eltwise9
I1023 16:54:38.051821  5058 net.cpp:367] elu19 -> Eltwise9 (in-place)
I1023 16:54:38.051826  5058 net.cpp:122] Setting up elu19
I1023 16:54:38.051828  5058 net.cpp:129] Top shape: 8 64 56 56 (1605632)
I1023 16:54:38.051831  5058 net.cpp:137] Memory required for data: 1687519328
I1023 16:54:38.051832  5058 layer_factory.hpp:77] Creating layer Pooling1
I1023 16:54:38.051836  5058 net.cpp:84] Creating Layer Pooling1
I1023 16:54:38.051838  5058 net.cpp:406] Pooling1 <- Eltwise9
I1023 16:54:38.051841  5058 net.cpp:380] Pooling1 -> Pooling1
I1023 16:54:38.052004  5058 net.cpp:122] Setting up Pooling1
I1023 16:54:38.052011  5058 net.cpp:129] Top shape: 8 64 1 1 (512)
I1023 16:54:38.052014  5058 net.cpp:137] Memory required for data: 1687521376
I1023 16:54:38.052016  5058 layer_factory.hpp:77] Creating layer InnerProduct1
I1023 16:54:38.052022  5058 net.cpp:84] Creating Layer InnerProduct1
I1023 16:54:38.052026  5058 net.cpp:406] InnerProduct1 <- Pooling1
I1023 16:54:38.052029  5058 net.cpp:380] InnerProduct1 -> InnerProduct1
I1023 16:54:38.052114  5058 net.cpp:122] Setting up InnerProduct1
I1023 16:54:38.052119  5058 net.cpp:129] Top shape: 8 4 (32)
I1023 16:54:38.052120  5058 net.cpp:137] Memory required for data: 1687521504
I1023 16:54:38.052124  5058 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I1023 16:54:38.052129  5058 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I1023 16:54:38.052130  5058 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I1023 16:54:38.052134  5058 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I1023 16:54:38.052137  5058 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I1023 16:54:38.052165  5058 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I1023 16:54:38.052170  5058 net.cpp:129] Top shape: 8 4 (32)
I1023 16:54:38.052171  5058 net.cpp:129] Top shape: 8 4 (32)
I1023 16:54:38.052175  5058 net.cpp:137] Memory required for data: 1687521760
I1023 16:54:38.052176  5058 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1023 16:54:38.052179  5058 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1023 16:54:38.052182  5058 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I1023 16:54:38.052186  5058 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I1023 16:54:38.052188  5058 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1023 16:54:38.052193  5058 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1023 16:54:38.052383  5058 net.cpp:122] Setting up SoftmaxWithLoss1
I1023 16:54:38.052389  5058 net.cpp:129] Top shape: (1)
I1023 16:54:38.052392  5058 net.cpp:132]     with loss weight 1
I1023 16:54:38.052398  5058 net.cpp:137] Memory required for data: 1687521764
I1023 16:54:38.052400  5058 layer_factory.hpp:77] Creating layer Accuracy1
I1023 16:54:38.052407  5058 net.cpp:84] Creating Layer Accuracy1
I1023 16:54:38.052409  5058 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I1023 16:54:38.052413  5058 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I1023 16:54:38.052417  5058 net.cpp:380] Accuracy1 -> Accuracy1
I1023 16:54:38.052422  5058 net.cpp:122] Setting up Accuracy1
I1023 16:54:38.052424  5058 net.cpp:129] Top shape: (1)
I1023 16:54:38.052426  5058 net.cpp:137] Memory required for data: 1687521768
I1023 16:54:38.052429  5058 net.cpp:200] Accuracy1 does not need backward computation.
I1023 16:54:38.052431  5058 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1023 16:54:38.052433  5058 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I1023 16:54:38.052436  5058 net.cpp:198] InnerProduct1 needs backward computation.
I1023 16:54:38.052438  5058 net.cpp:198] Pooling1 needs backward computation.
I1023 16:54:38.052440  5058 net.cpp:198] elu19 needs backward computation.
I1023 16:54:38.052448  5058 net.cpp:198] Eltwise9 needs backward computation.
I1023 16:54:38.052451  5058 net.cpp:198] Scale21 needs backward computation.
I1023 16:54:38.052453  5058 net.cpp:198] BatchNorm21 needs backward computation.
I1023 16:54:38.052455  5058 net.cpp:198] Convolution21 needs backward computation.
I1023 16:54:38.052458  5058 net.cpp:198] elu18 needs backward computation.
I1023 16:54:38.052459  5058 net.cpp:198] Scale20 needs backward computation.
I1023 16:54:38.052461  5058 net.cpp:198] BatchNorm20 needs backward computation.
I1023 16:54:38.052462  5058 net.cpp:198] Convolution20 needs backward computation.
I1023 16:54:38.052465  5058 net.cpp:198] Eltwise8_elu17_0_split needs backward computation.
I1023 16:54:38.052467  5058 net.cpp:198] elu17 needs backward computation.
I1023 16:54:38.052469  5058 net.cpp:198] Eltwise8 needs backward computation.
I1023 16:54:38.052471  5058 net.cpp:198] Scale19 needs backward computation.
I1023 16:54:38.052474  5058 net.cpp:198] BatchNorm19 needs backward computation.
I1023 16:54:38.052475  5058 net.cpp:198] Convolution19 needs backward computation.
I1023 16:54:38.052477  5058 net.cpp:198] elu16 needs backward computation.
I1023 16:54:38.052479  5058 net.cpp:198] Scale18 needs backward computation.
I1023 16:54:38.052481  5058 net.cpp:198] BatchNorm18 needs backward computation.
I1023 16:54:38.052484  5058 net.cpp:198] Convolution18 needs backward computation.
I1023 16:54:38.052485  5058 net.cpp:198] Eltwise7_elu15_0_split needs backward computation.
I1023 16:54:38.052487  5058 net.cpp:198] elu15 needs backward computation.
I1023 16:54:38.052489  5058 net.cpp:198] Eltwise7 needs backward computation.
I1023 16:54:38.052492  5058 net.cpp:198] Scale17 needs backward computation.
I1023 16:54:38.052495  5058 net.cpp:198] BatchNorm17 needs backward computation.
I1023 16:54:38.052497  5058 net.cpp:198] Convolution17 needs backward computation.
I1023 16:54:38.052500  5058 net.cpp:198] elu14 needs backward computation.
I1023 16:54:38.052501  5058 net.cpp:198] Scale16 needs backward computation.
I1023 16:54:38.052503  5058 net.cpp:198] BatchNorm16 needs backward computation.
I1023 16:54:38.071720  5058 net.cpp:198] Convolution16 needs backward computation.
I1023 16:54:38.071732  5058 net.cpp:198] Scale15 needs backward computation.
I1023 16:54:38.071736  5058 net.cpp:198] BatchNorm15 needs backward computation.
I1023 16:54:38.071740  5058 net.cpp:198] Convolution15 needs backward computation.
I1023 16:54:38.071745  5058 net.cpp:198] Eltwise6_elu13_0_split needs backward computation.
I1023 16:54:38.071750  5058 net.cpp:198] elu13 needs backward computation.
I1023 16:54:38.071754  5058 net.cpp:198] Eltwise6 needs backward computation.
I1023 16:54:38.071759  5058 net.cpp:198] Scale14 needs backward computation.
I1023 16:54:38.071763  5058 net.cpp:198] BatchNorm14 needs backward computation.
I1023 16:54:38.071768  5058 net.cpp:198] Convolution14 needs backward computation.
I1023 16:54:38.071772  5058 net.cpp:198] elu12 needs backward computation.
I1023 16:54:38.071776  5058 net.cpp:198] Scale13 needs backward computation.
I1023 16:54:38.071780  5058 net.cpp:198] BatchNorm13 needs backward computation.
I1023 16:54:38.071784  5058 net.cpp:198] Convolution13 needs backward computation.
I1023 16:54:38.071789  5058 net.cpp:198] Eltwise5_elu11_0_split needs backward computation.
I1023 16:54:38.071794  5058 net.cpp:198] elu11 needs backward computation.
I1023 16:54:38.071799  5058 net.cpp:198] Eltwise5 needs backward computation.
I1023 16:54:38.071804  5058 net.cpp:198] Scale12 needs backward computation.
I1023 16:54:38.071807  5058 net.cpp:198] BatchNorm12 needs backward computation.
I1023 16:54:38.071811  5058 net.cpp:198] Convolution12 needs backward computation.
I1023 16:54:38.071815  5058 net.cpp:198] elu10 needs backward computation.
I1023 16:54:38.071820  5058 net.cpp:198] Scale11 needs backward computation.
I1023 16:54:38.071823  5058 net.cpp:198] BatchNorm11 needs backward computation.
I1023 16:54:38.071828  5058 net.cpp:198] Convolution11 needs backward computation.
I1023 16:54:38.071842  5058 net.cpp:198] Eltwise4_elu9_0_split needs backward computation.
I1023 16:54:38.071847  5058 net.cpp:198] elu9 needs backward computation.
I1023 16:54:38.071851  5058 net.cpp:198] Eltwise4 needs backward computation.
I1023 16:54:38.071856  5058 net.cpp:198] Scale10 needs backward computation.
I1023 16:54:38.071861  5058 net.cpp:198] BatchNorm10 needs backward computation.
I1023 16:54:38.071866  5058 net.cpp:198] Convolution10 needs backward computation.
I1023 16:54:38.071869  5058 net.cpp:198] elu8 needs backward computation.
I1023 16:54:38.071874  5058 net.cpp:198] Scale9 needs backward computation.
I1023 16:54:38.071878  5058 net.cpp:198] BatchNorm9 needs backward computation.
I1023 16:54:38.071882  5058 net.cpp:198] Convolution9 needs backward computation.
I1023 16:54:38.071887  5058 net.cpp:198] Scale8 needs backward computation.
I1023 16:54:38.071892  5058 net.cpp:198] BatchNorm8 needs backward computation.
I1023 16:54:38.071897  5058 net.cpp:198] Convolution8 needs backward computation.
I1023 16:54:38.071900  5058 net.cpp:198] Eltwise3_elu7_0_split needs backward computation.
I1023 16:54:38.071905  5058 net.cpp:198] elu7 needs backward computation.
I1023 16:54:38.071909  5058 net.cpp:198] Eltwise3 needs backward computation.
I1023 16:54:38.071914  5058 net.cpp:198] Scale7 needs backward computation.
I1023 16:54:38.071918  5058 net.cpp:198] BatchNorm7 needs backward computation.
I1023 16:54:38.071923  5058 net.cpp:198] Convolution7 needs backward computation.
I1023 16:54:38.071926  5058 net.cpp:198] elu6 needs backward computation.
I1023 16:54:38.071930  5058 net.cpp:198] Scale6 needs backward computation.
I1023 16:54:38.071934  5058 net.cpp:198] BatchNorm6 needs backward computation.
I1023 16:54:38.071939  5058 net.cpp:198] Convolution6 needs backward computation.
I1023 16:54:38.071943  5058 net.cpp:198] Eltwise2_elu5_0_split needs backward computation.
I1023 16:54:38.071949  5058 net.cpp:198] elu5 needs backward computation.
I1023 16:54:38.071952  5058 net.cpp:198] Eltwise2 needs backward computation.
I1023 16:54:38.071965  5058 net.cpp:198] Scale5 needs backward computation.
I1023 16:54:38.071971  5058 net.cpp:198] BatchNorm5 needs backward computation.
I1023 16:54:38.071975  5058 net.cpp:198] Convolution5 needs backward computation.
I1023 16:54:38.071980  5058 net.cpp:198] elu4 needs backward computation.
I1023 16:54:38.071985  5058 net.cpp:198] Scale4 needs backward computation.
I1023 16:54:38.071988  5058 net.cpp:198] BatchNorm4 needs backward computation.
I1023 16:54:38.071992  5058 net.cpp:198] Convolution4 needs backward computation.
I1023 16:54:38.071997  5058 net.cpp:198] Eltwise1_elu3_0_split needs backward computation.
I1023 16:54:38.072002  5058 net.cpp:198] elu3 needs backward computation.
I1023 16:54:38.072006  5058 net.cpp:198] Eltwise1 needs backward computation.
I1023 16:54:38.072011  5058 net.cpp:198] Scale3 needs backward computation.
I1023 16:54:38.072016  5058 net.cpp:198] BatchNorm3 needs backward computation.
I1023 16:54:38.072019  5058 net.cpp:198] Convolution3 needs backward computation.
I1023 16:54:38.072024  5058 net.cpp:198] elu2 needs backward computation.
I1023 16:54:38.072028  5058 net.cpp:198] Scale2 needs backward computation.
I1023 16:54:38.072032  5058 net.cpp:198] BatchNorm2 needs backward computation.
I1023 16:54:38.072037  5058 net.cpp:198] Convolution2 needs backward computation.
I1023 16:54:38.072042  5058 net.cpp:198] Convolution1_elu1_0_split needs backward computation.
I1023 16:54:38.072046  5058 net.cpp:198] elu1 needs backward computation.
I1023 16:54:38.072051  5058 net.cpp:198] Scale1 needs backward computation.
I1023 16:54:38.072054  5058 net.cpp:198] BatchNorm1 needs backward computation.
I1023 16:54:38.072059  5058 net.cpp:198] Convolution1 needs backward computation.
I1023 16:54:38.072064  5058 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I1023 16:54:38.072069  5058 net.cpp:200] Data1 does not need backward computation.
I1023 16:54:38.072073  5058 net.cpp:242] This network produces output Accuracy1
I1023 16:54:38.072078  5058 net.cpp:242] This network produces output SoftmaxWithLoss1
I1023 16:54:38.072144  5058 net.cpp:255] Network initialization done.
I1023 16:54:38.072474  5058 solver.cpp:56] Solver scaffolding done.
I1023 16:54:38.077278  5058 caffe.cpp:248] Starting Optimization
I1023 16:54:38.077289  5058 solver.cpp:272] Solving resnet
I1023 16:54:38.077291  5058 solver.cpp:273] Learning Rate Policy: multistep
I1023 16:54:38.079411  5058 solver.cpp:330] Iteration 0, Testing net (#0)
I1023 16:54:40.291056  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:54:40.412811  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.119141
I1023 16:54:40.412875  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I1023 16:54:40.613236  5058 solver.cpp:218] Iteration 0 (-1.79295e-32 iter/s, 2.53586s/100 iters), loss = 1.39692
I1023 16:54:40.613266  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.39692 (* 1 = 1.39692 loss)
I1023 16:54:40.613278  5058 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I1023 16:54:58.420425  5058 solver.cpp:218] Iteration 100 (5.61576 iter/s, 17.807s/100 iters), loss = 0.792157
I1023 16:54:58.420457  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.792157 (* 1 = 0.792157 loss)
I1023 16:54:58.420464  5058 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I1023 16:55:16.064427  5058 solver.cpp:330] Iteration 200, Testing net (#0)
I1023 16:55:18.239120  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:55:18.361945  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.386719
I1023 16:55:18.362006  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 4.22017 (* 1 = 4.22017 loss)
I1023 16:55:18.541419  5058 solver.cpp:218] Iteration 200 (4.96998 iter/s, 20.1208s/100 iters), loss = 0.783583
I1023 16:55:18.541450  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.783583 (* 1 = 0.783583 loss)
I1023 16:55:18.541456  5058 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I1023 16:55:36.385947  5058 solver.cpp:218] Iteration 300 (5.60401 iter/s, 17.8444s/100 iters), loss = 1.72916
I1023 16:55:36.385978  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.72917 (* 1 = 1.72917 loss)
I1023 16:55:36.385984  5058 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I1023 16:55:43.013942  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:55:54.058878  5058 solver.cpp:330] Iteration 400, Testing net (#0)
I1023 16:55:56.233577  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:55:56.356355  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.511719
I1023 16:55:56.356406  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.1423 (* 1 = 3.1423 loss)
I1023 16:55:56.536519  5058 solver.cpp:218] Iteration 400 (4.96268 iter/s, 20.1504s/100 iters), loss = 0.860432
I1023 16:55:56.536552  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.860432 (* 1 = 0.860432 loss)
I1023 16:55:56.536559  5058 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I1023 16:56:14.383074  5058 solver.cpp:218] Iteration 500 (5.60337 iter/s, 17.8464s/100 iters), loss = 0.676794
I1023 16:56:14.383106  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.676794 (* 1 = 0.676794 loss)
I1023 16:56:14.383112  5058 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I1023 16:56:32.053344  5058 solver.cpp:330] Iteration 600, Testing net (#0)
I1023 16:56:34.195175  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:56:34.350689  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.404297
I1023 16:56:34.350746  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.64842 (* 1 = 3.64842 loss)
I1023 16:56:34.530377  5058 solver.cpp:218] Iteration 600 (4.96348 iter/s, 20.1471s/100 iters), loss = 1.38019
I1023 16:56:34.530409  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.38019 (* 1 = 1.38019 loss)
I1023 16:56:34.530416  5058 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I1023 16:56:48.478471  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:56:52.384734  5058 solver.cpp:218] Iteration 700 (5.60092 iter/s, 17.8542s/100 iters), loss = 0.433063
I1023 16:56:52.384765  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.433063 (* 1 = 0.433063 loss)
I1023 16:56:52.384773  5058 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I1023 16:57:10.053346  5058 solver.cpp:330] Iteration 800, Testing net (#0)
I1023 16:57:12.194094  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:57:12.350471  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.605469
I1023 16:57:12.350533  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.82603 (* 1 = 1.82603 loss)
I1023 16:57:12.530570  5058 solver.cpp:218] Iteration 800 (4.96384 iter/s, 20.1457s/100 iters), loss = 0.408704
I1023 16:57:12.530601  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.408705 (* 1 = 0.408705 loss)
I1023 16:57:12.530607  5058 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I1023 16:57:30.384189  5058 solver.cpp:218] Iteration 900 (5.60114 iter/s, 17.8535s/100 iters), loss = 0.577425
I1023 16:57:30.384220  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.577426 (* 1 = 0.577426 loss)
I1023 16:57:30.384227  5058 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I1023 16:57:48.065310  5058 solver.cpp:330] Iteration 1000, Testing net (#0)
I1023 16:57:50.204334  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:57:50.362300  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.509766
I1023 16:57:50.362361  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.96819 (* 1 = 1.96819 loss)
I1023 16:57:50.542515  5058 solver.cpp:218] Iteration 1000 (4.96076 iter/s, 20.1582s/100 iters), loss = 0.477855
I1023 16:57:50.542546  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.477856 (* 1 = 0.477856 loss)
I1023 16:57:50.542552  5058 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I1023 16:57:53.962477  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:58:08.400187  5058 solver.cpp:218] Iteration 1100 (5.59987 iter/s, 17.8576s/100 iters), loss = 0.0788131
I1023 16:58:08.400218  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0788136 (* 1 = 0.0788136 loss)
I1023 16:58:08.400225  5058 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I1023 16:58:26.078665  5058 solver.cpp:330] Iteration 1200, Testing net (#0)
I1023 16:58:28.217555  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:58:28.376648  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.603516
I1023 16:58:28.376708  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.25381 (* 1 = 1.25381 loss)
I1023 16:58:28.556352  5058 solver.cpp:218] Iteration 1200 (4.96129 iter/s, 20.1561s/100 iters), loss = 1.41292
I1023 16:58:28.556383  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.41292 (* 1 = 1.41292 loss)
I1023 16:58:28.556390  5058 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I1023 16:58:46.408686  5058 solver.cpp:218] Iteration 1300 (5.60154 iter/s, 17.8522s/100 iters), loss = 0.490122
I1023 16:58:46.408717  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.490122 (* 1 = 0.490122 loss)
I1023 16:58:46.408725  5058 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I1023 16:58:57.151068  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:59:04.089223  5058 solver.cpp:330] Iteration 1400, Testing net (#0)
I1023 16:59:06.195775  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:59:06.387707  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.529297
I1023 16:59:06.387766  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.26942 (* 1 = 1.26942 loss)
I1023 16:59:06.567842  5058 solver.cpp:218] Iteration 1400 (4.96055 iter/s, 20.159s/100 iters), loss = 0.663235
I1023 16:59:06.567873  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.663235 (* 1 = 0.663235 loss)
I1023 16:59:06.567879  5058 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I1023 16:59:24.418982  5058 solver.cpp:218] Iteration 1500 (5.60191 iter/s, 17.851s/100 iters), loss = 0.360169
I1023 16:59:24.419015  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.360169 (* 1 = 0.360169 loss)
I1023 16:59:24.419021  5058 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I1023 16:59:42.097622  5058 solver.cpp:330] Iteration 1600, Testing net (#0)
I1023 16:59:44.204424  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 16:59:44.397323  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.570312
I1023 16:59:44.397383  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.50348 (* 1 = 1.50348 loss)
I1023 16:59:44.577904  5058 solver.cpp:218] Iteration 1600 (4.96061 iter/s, 20.1588s/100 iters), loss = 1.21693
I1023 16:59:44.577936  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.21693 (* 1 = 1.21693 loss)
I1023 16:59:44.577942  5058 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I1023 17:00:02.478565  5058 solver.cpp:218] Iteration 1700 (5.58642 iter/s, 17.9006s/100 iters), loss = 1.37591
I1023 17:00:02.478598  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.37591 (* 1 = 1.37591 loss)
I1023 17:00:02.478605  5058 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I1023 17:00:02.859938  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:00:20.202221  5058 solver.cpp:330] Iteration 1800, Testing net (#0)
I1023 17:00:22.309963  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:00:22.503976  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.650391
I1023 17:00:22.504040  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.829507 (* 1 = 0.829507 loss)
I1023 17:00:22.684357  5058 solver.cpp:218] Iteration 1800 (4.9491 iter/s, 20.2057s/100 iters), loss = 0.455922
I1023 17:00:22.684389  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.455923 (* 1 = 0.455923 loss)
I1023 17:00:22.684396  5058 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I1023 17:00:40.578032  5058 solver.cpp:218] Iteration 1900 (5.5886 iter/s, 17.8936s/100 iters), loss = 0.60328
I1023 17:00:40.578075  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.603281 (* 1 = 0.603281 loss)
I1023 17:00:40.578083  5058 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I1023 17:00:58.297521  5058 solver.cpp:330] Iteration 2000, Testing net (#0)
I1023 17:01:00.404528  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:01:00.600507  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.859375
I1023 17:01:00.600556  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.394782 (* 1 = 0.394782 loss)
I1023 17:01:00.781190  5058 solver.cpp:218] Iteration 2000 (4.94975 iter/s, 20.203s/100 iters), loss = 0.0985521
I1023 17:01:00.781225  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0985523 (* 1 = 0.0985523 loss)
I1023 17:01:00.781234  5058 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I1023 17:01:08.505554  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:01:18.682133  5058 solver.cpp:218] Iteration 2100 (5.58633 iter/s, 17.9008s/100 iters), loss = 0.458003
I1023 17:01:18.682168  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.458003 (* 1 = 0.458003 loss)
I1023 17:01:18.682176  5058 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I1023 17:01:36.408176  5058 solver.cpp:330] Iteration 2200, Testing net (#0)
I1023 17:01:38.482326  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:01:38.710294  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.828125
I1023 17:01:38.710343  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.502405 (* 1 = 0.502405 loss)
I1023 17:01:38.890930  5058 solver.cpp:218] Iteration 2200 (4.94837 iter/s, 20.2087s/100 iters), loss = 0.468737
I1023 17:01:38.890964  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.468737 (* 1 = 0.468737 loss)
I1023 17:01:38.890974  5058 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I1023 17:01:56.795243  5058 solver.cpp:218] Iteration 2300 (5.58528 iter/s, 17.9042s/100 iters), loss = 0.0972426
I1023 17:01:56.795277  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.097243 (* 1 = 0.097243 loss)
I1023 17:01:56.795286  5058 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I1023 17:02:11.859897  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:02:14.525092  5058 solver.cpp:330] Iteration 2400, Testing net (#0)
I1023 17:02:16.597926  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:02:16.827111  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.701172
I1023 17:02:16.827168  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.666432 (* 1 = 0.666432 loss)
I1023 17:02:17.006611  5058 solver.cpp:218] Iteration 2400 (4.94774 iter/s, 20.2113s/100 iters), loss = 0.335634
I1023 17:02:17.006644  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335634 (* 1 = 0.335634 loss)
I1023 17:02:17.006650  5058 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I1023 17:02:34.900943  5058 solver.cpp:218] Iteration 2500 (5.58839 iter/s, 17.8942s/100 iters), loss = 0.208215
I1023 17:02:34.900975  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208215 (* 1 = 0.208215 loss)
I1023 17:02:34.900982  5058 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I1023 17:02:52.622733  5058 solver.cpp:330] Iteration 2600, Testing net (#0)
I1023 17:02:54.695125  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:02:54.925160  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.748047
I1023 17:02:54.925211  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.550271 (* 1 = 0.550271 loss)
I1023 17:02:55.105537  5058 solver.cpp:218] Iteration 2600 (4.94939 iter/s, 20.2045s/100 iters), loss = 0.0598012
I1023 17:02:55.105569  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0598015 (* 1 = 0.0598015 loss)
I1023 17:02:55.105576  5058 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I1023 17:03:13.007242  5058 solver.cpp:218] Iteration 2700 (5.58609 iter/s, 17.9016s/100 iters), loss = 0.625534
I1023 17:03:13.007273  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.625534 (* 1 = 0.625534 loss)
I1023 17:03:13.007280  5058 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I1023 17:03:17.510679  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:03:30.734712  5058 solver.cpp:330] Iteration 2800, Testing net (#0)
I1023 17:03:32.804985  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:03:33.037156  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.763672
I1023 17:03:33.037212  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.668117 (* 1 = 0.668117 loss)
I1023 17:03:33.218246  5058 solver.cpp:218] Iteration 2800 (4.94782 iter/s, 20.2109s/100 iters), loss = 0.062822
I1023 17:03:33.218281  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0628226 (* 1 = 0.0628226 loss)
I1023 17:03:33.218288  5058 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I1023 17:03:51.118913  5058 solver.cpp:218] Iteration 2900 (5.58641 iter/s, 17.9006s/100 iters), loss = 0.237096
I1023 17:03:51.118945  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237096 (* 1 = 0.237096 loss)
I1023 17:03:51.118952  5058 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I1023 17:04:08.847203  5058 solver.cpp:330] Iteration 3000, Testing net (#0)
I1023 17:04:10.884141  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:04:11.148252  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.828125
I1023 17:04:11.148316  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.466893 (* 1 = 0.466893 loss)
I1023 17:04:11.328326  5058 solver.cpp:218] Iteration 3000 (4.94821 iter/s, 20.2093s/100 iters), loss = 1.20972
I1023 17:04:11.328358  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.20972 (* 1 = 1.20972 loss)
I1023 17:04:11.328366  5058 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I1023 17:04:23.341565  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:04:29.229197  5058 solver.cpp:218] Iteration 3100 (5.58635 iter/s, 17.9008s/100 iters), loss = 0.689444
I1023 17:04:29.229229  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.689444 (* 1 = 0.689444 loss)
I1023 17:04:29.229238  5058 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I1023 17:04:46.943420  5058 solver.cpp:330] Iteration 3200, Testing net (#0)
I1023 17:04:48.980396  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:04:49.245328  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.851562
I1023 17:04:49.245389  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.438781 (* 1 = 0.438781 loss)
I1023 17:04:49.425467  5058 solver.cpp:218] Iteration 3200 (4.95143 iter/s, 20.1962s/100 iters), loss = 0.126613
I1023 17:04:49.425503  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126613 (* 1 = 0.126613 loss)
I1023 17:04:49.425510  5058 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I1023 17:05:07.328286  5058 solver.cpp:218] Iteration 3300 (5.58574 iter/s, 17.9027s/100 iters), loss = 0.288654
I1023 17:05:07.328317  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288655 (* 1 = 0.288655 loss)
I1023 17:05:07.328325  5058 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I1023 17:05:25.052861  5058 solver.cpp:330] Iteration 3400, Testing net (#0)
I1023 17:05:27.088840  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:05:27.354887  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.90625
I1023 17:05:27.354948  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311333 (* 1 = 0.311333 loss)
I1023 17:05:27.535451  5058 solver.cpp:218] Iteration 3400 (4.94876 iter/s, 20.2071s/100 iters), loss = 0.022074
I1023 17:05:27.535485  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0220747 (* 1 = 0.0220747 loss)
I1023 17:05:27.535491  5058 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I1023 17:05:28.994356  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:05:45.440580  5058 solver.cpp:218] Iteration 3500 (5.58502 iter/s, 17.905s/100 iters), loss = 0.634796
I1023 17:05:45.440613  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.634796 (* 1 = 0.634796 loss)
I1023 17:05:45.440619  5058 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I1023 17:06:03.167122  5058 solver.cpp:330] Iteration 3600, Testing net (#0)
I1023 17:06:05.201203  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:06:05.467738  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.914062
I1023 17:06:05.467792  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.264016 (* 1 = 0.264016 loss)
I1023 17:06:05.648100  5058 solver.cpp:218] Iteration 3600 (4.94868 iter/s, 20.2074s/100 iters), loss = 0.11177
I1023 17:06:05.648134  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.11177 (* 1 = 0.11177 loss)
I1023 17:06:05.648141  5058 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I1023 17:06:23.546891  5058 solver.cpp:218] Iteration 3700 (5.587 iter/s, 17.8987s/100 iters), loss = 0.0683161
I1023 17:06:23.546924  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0683168 (* 1 = 0.0683168 loss)
I1023 17:06:23.546932  5058 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I1023 17:06:32.344663  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:06:41.268635  5058 solver.cpp:330] Iteration 3800, Testing net (#0)
I1023 17:06:43.269625  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:06:43.570092  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.888672
I1023 17:06:43.570147  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32222 (* 1 = 0.32222 loss)
I1023 17:06:43.750499  5058 solver.cpp:218] Iteration 3800 (4.94964 iter/s, 20.2035s/100 iters), loss = 0.469138
I1023 17:06:43.750531  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.469139 (* 1 = 0.469139 loss)
I1023 17:06:43.750538  5058 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I1023 17:07:01.650620  5058 solver.cpp:218] Iteration 3900 (5.58658 iter/s, 17.9s/100 iters), loss = 0.0171452
I1023 17:07:01.650652  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0171459 (* 1 = 0.0171459 loss)
I1023 17:07:01.650660  5058 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I1023 17:07:19.375952  5058 solver.cpp:330] Iteration 4000, Testing net (#0)
I1023 17:07:21.377095  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:07:21.677238  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.847656
I1023 17:07:21.677299  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.385888 (* 1 = 0.385888 loss)
I1023 17:07:21.857885  5058 solver.cpp:218] Iteration 4000 (4.94874 iter/s, 20.2072s/100 iters), loss = 0.362147
I1023 17:07:21.857918  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362148 (* 1 = 0.362148 loss)
I1023 17:07:21.857924  5058 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I1023 17:07:37.992233  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:07:39.760766  5058 solver.cpp:218] Iteration 4100 (5.58572 iter/s, 17.9028s/100 iters), loss = 0.192502
I1023 17:07:39.760797  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192503 (* 1 = 0.192503 loss)
I1023 17:07:39.760804  5058 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I1023 17:07:57.484176  5058 solver.cpp:330] Iteration 4200, Testing net (#0)
I1023 17:07:59.484079  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:07:59.785243  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.849609
I1023 17:07:59.785297  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.501121 (* 1 = 0.501121 loss)
I1023 17:07:59.965647  5058 solver.cpp:218] Iteration 4200 (4.94932 iter/s, 20.2048s/100 iters), loss = 0.285915
I1023 17:07:59.965680  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285916 (* 1 = 0.285916 loss)
I1023 17:07:59.965687  5058 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I1023 17:08:17.861264  5058 solver.cpp:218] Iteration 4300 (5.58799 iter/s, 17.8955s/100 iters), loss = 0.808401
I1023 17:08:17.861297  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.808402 (* 1 = 0.808402 loss)
I1023 17:08:17.861304  5058 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I1023 17:08:35.578621  5058 solver.cpp:330] Iteration 4400, Testing net (#0)
I1023 17:08:37.576957  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:08:37.880451  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.888672
I1023 17:08:37.880504  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295803 (* 1 = 0.295803 loss)
I1023 17:08:38.060873  5058 solver.cpp:218] Iteration 4400 (4.95061 iter/s, 20.1995s/100 iters), loss = 0.079318
I1023 17:08:38.060907  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.079319 (* 1 = 0.079319 loss)
I1023 17:08:38.060915  5058 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I1023 17:08:43.814803  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:08:55.963971  5058 solver.cpp:218] Iteration 4500 (5.58565 iter/s, 17.903s/100 iters), loss = 0.0894728
I1023 17:08:55.964004  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0894738 (* 1 = 0.0894738 loss)
I1023 17:08:55.964013  5058 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I1023 17:09:13.693361  5058 solver.cpp:330] Iteration 4600, Testing net (#0)
I1023 17:09:15.658459  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:09:15.995143  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.898438
I1023 17:09:15.995193  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.241284 (* 1 = 0.241284 loss)
I1023 17:09:16.175714  5058 solver.cpp:218] Iteration 4600 (4.94764 iter/s, 20.2117s/100 iters), loss = 0.00983212
I1023 17:09:16.175748  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00983313 (* 1 = 0.00983313 loss)
I1023 17:09:16.175757  5058 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I1023 17:09:34.080379  5058 solver.cpp:218] Iteration 4700 (5.58516 iter/s, 17.9046s/100 iters), loss = 0.313804
I1023 17:09:34.080415  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313805 (* 1 = 0.313805 loss)
I1023 17:09:34.080425  5058 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I1023 17:09:47.176859  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:09:51.812515  5058 solver.cpp:330] Iteration 4800, Testing net (#0)
I1023 17:09:53.776507  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:09:54.113204  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.869141
I1023 17:09:54.113261  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.349509 (* 1 = 0.349509 loss)
I1023 17:09:54.293011  5058 solver.cpp:218] Iteration 4800 (4.94742 iter/s, 20.2125s/100 iters), loss = 0.189942
I1023 17:09:54.293041  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189943 (* 1 = 0.189943 loss)
I1023 17:09:54.293048  5058 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I1023 17:10:12.187201  5058 solver.cpp:218] Iteration 4900 (5.58843 iter/s, 17.8941s/100 iters), loss = 0.0265295
I1023 17:10:12.187232  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0265306 (* 1 = 0.0265306 loss)
I1023 17:10:12.187238  5058 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I1023 17:10:29.910482  5058 solver.cpp:330] Iteration 5000, Testing net (#0)
I1023 17:10:31.874251  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:10:32.211719  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.904297
I1023 17:10:32.211778  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.289543 (* 1 = 0.289543 loss)
I1023 17:10:32.392204  5058 solver.cpp:218] Iteration 5000 (4.94929 iter/s, 20.2049s/100 iters), loss = 0.110225
I1023 17:10:32.392240  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.110226 (* 1 = 0.110226 loss)
I1023 17:10:32.392246  5058 sgd_solver.cpp:105] Iteration 5000, lr = 0.01
I1023 17:10:50.292057  5058 solver.cpp:218] Iteration 5100 (5.58666 iter/s, 17.8998s/100 iters), loss = 0.152285
I1023 17:10:50.292090  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152286 (* 1 = 0.152286 loss)
I1023 17:10:50.292100  5058 sgd_solver.cpp:105] Iteration 5100, lr = 0.01
I1023 17:10:52.824507  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:11:08.018476  5058 solver.cpp:330] Iteration 5200, Testing net (#0)
I1023 17:11:09.982477  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:11:10.320755  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.939453
I1023 17:11:10.320799  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.177457 (* 1 = 0.177457 loss)
I1023 17:11:10.501241  5058 solver.cpp:218] Iteration 5200 (4.94827 iter/s, 20.2091s/100 iters), loss = 0.0662003
I1023 17:11:10.501276  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0662014 (* 1 = 0.0662014 loss)
I1023 17:11:10.501286  5058 sgd_solver.cpp:105] Iteration 5200, lr = 0.01
I1023 17:11:28.400890  5058 solver.cpp:218] Iteration 5300 (5.58673 iter/s, 17.8996s/100 iters), loss = 0.468317
I1023 17:11:28.400925  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.468318 (* 1 = 0.468318 loss)
I1023 17:11:28.400934  5058 sgd_solver.cpp:105] Iteration 5300, lr = 0.01
I1023 17:11:46.126844  5058 solver.cpp:330] Iteration 5400, Testing net (#0)
I1023 17:11:48.056340  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:11:48.427980  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.943359
I1023 17:11:48.428030  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.201332 (* 1 = 0.201332 loss)
I1023 17:11:48.608351  5058 solver.cpp:218] Iteration 5400 (4.94869 iter/s, 20.2074s/100 iters), loss = 0.0293063
I1023 17:11:48.608386  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0293073 (* 1 = 0.0293073 loss)
I1023 17:11:48.608395  5058 sgd_solver.cpp:105] Iteration 5400, lr = 0.01
I1023 17:11:58.480442  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:12:06.515568  5058 solver.cpp:218] Iteration 5500 (5.58437 iter/s, 17.9071s/100 iters), loss = 0.174596
I1023 17:12:06.515604  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174597 (* 1 = 0.174597 loss)
I1023 17:12:06.515614  5058 sgd_solver.cpp:105] Iteration 5500, lr = 0.01
I1023 17:12:24.226809  5058 solver.cpp:330] Iteration 5600, Testing net (#0)
I1023 17:12:26.155567  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:12:26.527590  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.888672
I1023 17:12:26.527639  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.282195 (* 1 = 0.282195 loss)
I1023 17:12:26.708196  5058 solver.cpp:218] Iteration 5600 (4.95232 iter/s, 20.1925s/100 iters), loss = 0.104584
I1023 17:12:26.708232  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.104585 (* 1 = 0.104585 loss)
I1023 17:12:26.708245  5058 sgd_solver.cpp:105] Iteration 5600, lr = 0.01
I1023 17:12:44.608487  5058 solver.cpp:218] Iteration 5700 (5.58653 iter/s, 17.9002s/100 iters), loss = 0.0110215
I1023 17:12:44.608522  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110225 (* 1 = 0.0110225 loss)
I1023 17:12:44.608532  5058 sgd_solver.cpp:105] Iteration 5700, lr = 0.01
I1023 17:13:02.000365  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:13:02.338737  5058 solver.cpp:330] Iteration 5800, Testing net (#0)
I1023 17:13:04.266317  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:13:04.640992  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.931641
I1023 17:13:04.641046  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.161723 (* 1 = 0.161723 loss)
I1023 17:13:04.821038  5058 solver.cpp:218] Iteration 5800 (4.94744 iter/s, 20.2125s/100 iters), loss = 0.077577
I1023 17:13:04.821071  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0775778 (* 1 = 0.0775778 loss)
I1023 17:13:04.821080  5058 sgd_solver.cpp:105] Iteration 5800, lr = 0.01
I1023 17:13:22.723476  5058 solver.cpp:218] Iteration 5900 (5.58586 iter/s, 17.9024s/100 iters), loss = 0.128254
I1023 17:13:22.723508  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128255 (* 1 = 0.128255 loss)
I1023 17:13:22.723517  5058 sgd_solver.cpp:105] Iteration 5900, lr = 0.01
I1023 17:13:40.452431  5058 solver.cpp:330] Iteration 6000, Testing net (#0)
I1023 17:13:42.379777  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:13:42.754148  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.830078
I1023 17:13:42.754201  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.494977 (* 1 = 0.494977 loss)
I1023 17:13:42.934725  5058 solver.cpp:218] Iteration 6000 (4.94776 iter/s, 20.2112s/100 iters), loss = 0.0914525
I1023 17:13:42.934761  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0914533 (* 1 = 0.0914533 loss)
I1023 17:13:42.934767  5058 sgd_solver.cpp:105] Iteration 6000, lr = 0.01
I1023 17:14:00.832952  5058 solver.cpp:218] Iteration 6100 (5.58717 iter/s, 17.8981s/100 iters), loss = 0.264624
I1023 17:14:00.832994  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264625 (* 1 = 0.264625 loss)
I1023 17:14:00.833001  5058 sgd_solver.cpp:105] Iteration 6100, lr = 0.01
I1023 17:14:07.662672  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:14:18.558625  5058 solver.cpp:330] Iteration 6200, Testing net (#0)
I1023 17:14:20.452311  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:14:20.859405  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 17:14:20.859465  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.107262 (* 1 = 0.107262 loss)
I1023 17:14:21.039911  5058 solver.cpp:218] Iteration 6200 (4.94881 iter/s, 20.2069s/100 iters), loss = 0.062469
I1023 17:14:21.039942  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0624693 (* 1 = 0.0624693 loss)
I1023 17:14:21.039948  5058 sgd_solver.cpp:105] Iteration 6200, lr = 0.01
I1023 17:14:38.940268  5058 solver.cpp:218] Iteration 6300 (5.58651 iter/s, 17.9003s/100 iters), loss = 0.0371681
I1023 17:14:38.940310  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0371685 (* 1 = 0.0371685 loss)
I1023 17:14:38.940317  5058 sgd_solver.cpp:105] Iteration 6300, lr = 0.01
I1023 17:14:56.663432  5058 solver.cpp:330] Iteration 6400, Testing net (#0)
I1023 17:14:58.555502  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:14:58.964473  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.908203
I1023 17:14:58.964534  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.23869 (* 1 = 0.23869 loss)
I1023 17:14:59.144785  5058 solver.cpp:218] Iteration 6400 (4.94941 iter/s, 20.2044s/100 iters), loss = 0.00866329
I1023 17:14:59.144816  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00866383 (* 1 = 0.00866383 loss)
I1023 17:14:59.144824  5058 sgd_solver.cpp:105] Iteration 6400, lr = 0.01
I1023 17:15:13.313282  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:15:17.052132  5058 solver.cpp:218] Iteration 6500 (5.58433 iter/s, 17.9073s/100 iters), loss = 0.00884802
I1023 17:15:17.052165  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00884845 (* 1 = 0.00884845 loss)
I1023 17:15:17.052171  5058 sgd_solver.cpp:105] Iteration 6500, lr = 0.01
I1023 17:15:34.774310  5058 solver.cpp:330] Iteration 6600, Testing net (#0)
I1023 17:15:36.666435  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:15:37.075505  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 17:15:37.075563  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0939755 (* 1 = 0.0939755 loss)
I1023 17:15:37.255659  5058 solver.cpp:218] Iteration 6600 (4.94965 iter/s, 20.2034s/100 iters), loss = 0.0239353
I1023 17:15:37.255692  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0239358 (* 1 = 0.0239358 loss)
I1023 17:15:37.255698  5058 sgd_solver.cpp:105] Iteration 6600, lr = 0.01
I1023 17:15:55.150454  5058 solver.cpp:218] Iteration 6700 (5.58824 iter/s, 17.8947s/100 iters), loss = 0.160384
I1023 17:15:55.150485  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160385 (* 1 = 0.160385 loss)
I1023 17:15:55.150492  5058 sgd_solver.cpp:105] Iteration 6700, lr = 0.01
I1023 17:16:12.868350  5058 solver.cpp:330] Iteration 6800, Testing net (#0)
I1023 17:16:14.759529  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:16:15.170667  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.935547
I1023 17:16:15.170723  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.206557 (* 1 = 0.206557 loss)
I1023 17:16:15.351152  5058 solver.cpp:218] Iteration 6800 (4.95034 iter/s, 20.2006s/100 iters), loss = 0.0518449
I1023 17:16:15.351188  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0518453 (* 1 = 0.0518453 loss)
I1023 17:16:15.351196  5058 sgd_solver.cpp:105] Iteration 6800, lr = 0.01
I1023 17:16:18.957900  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:16:33.253525  5058 solver.cpp:218] Iteration 6900 (5.58588 iter/s, 17.9023s/100 iters), loss = 0.282737
I1023 17:16:33.253556  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282738 (* 1 = 0.282738 loss)
I1023 17:16:33.253563  5058 sgd_solver.cpp:105] Iteration 6900, lr = 0.01
I1023 17:16:50.979817  5058 solver.cpp:330] Iteration 7000, Testing net (#0)
I1023 17:16:52.836761  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:16:53.280879  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.933594
I1023 17:16:53.280927  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.19129 (* 1 = 0.19129 loss)
I1023 17:16:53.461202  5058 solver.cpp:218] Iteration 7000 (4.94863 iter/s, 20.2076s/100 iters), loss = 0.0433676
I1023 17:16:53.461236  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0433681 (* 1 = 0.0433681 loss)
I1023 17:16:53.461242  5058 sgd_solver.cpp:105] Iteration 7000, lr = 0.01
I1023 17:17:11.365329  5058 solver.cpp:218] Iteration 7100 (5.58533 iter/s, 17.904s/100 iters), loss = 0.0388681
I1023 17:17:11.365360  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0388686 (* 1 = 0.0388686 loss)
I1023 17:17:11.365367  5058 sgd_solver.cpp:105] Iteration 7100, lr = 0.01
I1023 17:17:22.492985  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:17:29.099689  5058 solver.cpp:330] Iteration 7200, Testing net (#0)
I1023 17:17:30.956235  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:17:31.401157  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.953125
I1023 17:17:31.401211  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.134167 (* 1 = 0.134167 loss)
I1023 17:17:31.581585  5058 solver.cpp:218] Iteration 7200 (4.94654 iter/s, 20.2162s/100 iters), loss = 0.245162
I1023 17:17:31.581620  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245162 (* 1 = 0.245162 loss)
I1023 17:17:31.581629  5058 sgd_solver.cpp:105] Iteration 7200, lr = 0.01
I1023 17:17:49.472482  5058 solver.cpp:218] Iteration 7300 (5.58946 iter/s, 17.8908s/100 iters), loss = 0.461631
I1023 17:17:49.472517  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.461631 (* 1 = 0.461631 loss)
I1023 17:17:49.472525  5058 sgd_solver.cpp:105] Iteration 7300, lr = 0.01
I1023 17:18:07.197242  5058 solver.cpp:330] Iteration 7400, Testing net (#0)
I1023 17:18:09.053100  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:18:09.499085  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.953125
I1023 17:18:09.499135  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.107674 (* 1 = 0.107674 loss)
I1023 17:18:09.679356  5058 solver.cpp:218] Iteration 7400 (4.94883 iter/s, 20.2068s/100 iters), loss = 0.311633
I1023 17:18:09.679391  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311633 (* 1 = 0.311633 loss)
I1023 17:18:09.679400  5058 sgd_solver.cpp:105] Iteration 7400, lr = 0.01
I1023 17:18:27.581311  5058 solver.cpp:218] Iteration 7500 (5.58601 iter/s, 17.9019s/100 iters), loss = 0.14049
I1023 17:18:27.581342  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140491 (* 1 = 0.140491 loss)
I1023 17:18:27.581349  5058 sgd_solver.cpp:105] Iteration 7500, lr = 0.01
I1023 17:18:28.142851  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:18:45.307407  5058 solver.cpp:330] Iteration 7600, Testing net (#0)
I1023 17:18:47.162348  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:18:47.609082  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.951172
I1023 17:18:47.609143  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.1382 (* 1 = 0.1382 loss)
I1023 17:18:47.789773  5058 solver.cpp:218] Iteration 7600 (4.94844 iter/s, 20.2084s/100 iters), loss = 0.28913
I1023 17:18:47.789805  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28913 (* 1 = 0.28913 loss)
I1023 17:18:47.789813  5058 sgd_solver.cpp:105] Iteration 7600, lr = 0.01
I1023 17:19:05.691378  5058 solver.cpp:218] Iteration 7700 (5.58612 iter/s, 17.9015s/100 iters), loss = 0.0432951
I1023 17:19:05.691409  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0432957 (* 1 = 0.0432957 loss)
I1023 17:19:05.691416  5058 sgd_solver.cpp:105] Iteration 7700, lr = 0.01
I1023 17:19:23.414685  5058 solver.cpp:330] Iteration 7800, Testing net (#0)
I1023 17:19:25.237475  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:19:25.715517  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 17:19:25.715570  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0793294 (* 1 = 0.0793294 loss)
I1023 17:19:25.895596  5058 solver.cpp:218] Iteration 7800 (4.94948 iter/s, 20.2041s/100 iters), loss = 0.0647843
I1023 17:19:25.895629  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0647848 (* 1 = 0.0647848 loss)
I1023 17:19:25.895637  5058 sgd_solver.cpp:105] Iteration 7800, lr = 0.01
I1023 17:19:33.797832  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:19:43.792568  5058 solver.cpp:218] Iteration 7900 (5.58756 iter/s, 17.8969s/100 iters), loss = 0.0132378
I1023 17:19:43.792600  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132385 (* 1 = 0.0132385 loss)
I1023 17:19:43.792608  5058 sgd_solver.cpp:105] Iteration 7900, lr = 0.01
I1023 17:20:01.511554  5058 solver.cpp:330] Iteration 8000, Testing net (#0)
I1023 17:20:03.333122  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:20:03.813380  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.943359
I1023 17:20:03.813439  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.158927 (* 1 = 0.158927 loss)
I1023 17:20:03.993717  5058 solver.cpp:218] Iteration 8000 (4.95023 iter/s, 20.2011s/100 iters), loss = 0.314974
I1023 17:20:03.993751  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314975 (* 1 = 0.314975 loss)
I1023 17:20:03.993757  5058 sgd_solver.cpp:105] Iteration 8000, lr = 0.01
I1023 17:20:21.894629  5058 solver.cpp:218] Iteration 8100 (5.58633 iter/s, 17.9008s/100 iters), loss = 0.244573
I1023 17:20:21.894659  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244574 (* 1 = 0.244574 loss)
I1023 17:20:21.894665  5058 sgd_solver.cpp:105] Iteration 8100, lr = 0.01
I1023 17:20:37.141744  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:20:39.625749  5058 solver.cpp:330] Iteration 8200, Testing net (#0)
I1023 17:20:41.445953  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:20:41.926939  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.935547
I1023 17:20:41.926987  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.172011 (* 1 = 0.172011 loss)
I1023 17:20:42.107911  5058 solver.cpp:218] Iteration 8200 (4.94726 iter/s, 20.2132s/100 iters), loss = 0.868058
I1023 17:20:42.107944  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.868059 (* 1 = 0.868059 loss)
I1023 17:20:42.107950  5058 sgd_solver.cpp:105] Iteration 8200, lr = 0.01
I1023 17:21:00.009192  5058 solver.cpp:218] Iteration 8300 (5.58622 iter/s, 17.9012s/100 iters), loss = 0.0755811
I1023 17:21:00.009223  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0755817 (* 1 = 0.0755817 loss)
I1023 17:21:00.009229  5058 sgd_solver.cpp:105] Iteration 8300, lr = 0.01
I1023 17:21:17.737287  5058 solver.cpp:330] Iteration 8400, Testing net (#0)
I1023 17:21:19.557168  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:21:20.039891  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.90625
I1023 17:21:20.039963  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.232307 (* 1 = 0.232307 loss)
I1023 17:21:20.220206  5058 solver.cpp:218] Iteration 8400 (4.94782 iter/s, 20.2109s/100 iters), loss = 0.209777
I1023 17:21:20.220237  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209777 (* 1 = 0.209777 loss)
I1023 17:21:20.220244  5058 sgd_solver.cpp:105] Iteration 8400, lr = 0.01
I1023 17:21:38.119127  5058 solver.cpp:218] Iteration 8500 (5.58695 iter/s, 17.8988s/100 iters), loss = 0.0308123
I1023 17:21:38.119159  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0308129 (* 1 = 0.0308129 loss)
I1023 17:21:38.119165  5058 sgd_solver.cpp:105] Iteration 8500, lr = 0.01
I1023 17:21:42.976791  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:21:55.843019  5058 solver.cpp:330] Iteration 8600, Testing net (#0)
I1023 17:21:57.628823  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:21:58.144974  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.953125
I1023 17:21:58.145033  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.149066 (* 1 = 0.149066 loss)
I1023 17:21:58.325315  5058 solver.cpp:218] Iteration 8600 (4.949 iter/s, 20.2061s/100 iters), loss = 0.0686236
I1023 17:21:58.325348  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0686242 (* 1 = 0.0686242 loss)
I1023 17:21:58.325356  5058 sgd_solver.cpp:105] Iteration 8600, lr = 0.01
I1023 17:22:16.227836  5058 solver.cpp:218] Iteration 8700 (5.58583 iter/s, 17.9024s/100 iters), loss = 0.386967
I1023 17:22:16.227869  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.386967 (* 1 = 0.386967 loss)
I1023 17:22:16.227875  5058 sgd_solver.cpp:105] Iteration 8700, lr = 0.01
I1023 17:22:33.952131  5058 solver.cpp:330] Iteration 8800, Testing net (#0)
I1023 17:22:35.737417  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:22:36.254354  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.925781
I1023 17:22:36.254415  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.197633 (* 1 = 0.197633 loss)
I1023 17:22:36.434816  5058 solver.cpp:218] Iteration 8800 (4.94881 iter/s, 20.2069s/100 iters), loss = 0.0100481
I1023 17:22:36.434849  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100488 (* 1 = 0.0100488 loss)
I1023 17:22:36.434854  5058 sgd_solver.cpp:105] Iteration 8800, lr = 0.01
I1023 17:22:48.633451  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:22:54.344203  5058 solver.cpp:218] Iteration 8900 (5.58369 iter/s, 17.9093s/100 iters), loss = 0.0422316
I1023 17:22:54.344234  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0422323 (* 1 = 0.0422323 loss)
I1023 17:22:54.344240  5058 sgd_solver.cpp:105] Iteration 8900, lr = 0.01
I1023 17:23:12.063808  5058 solver.cpp:330] Iteration 9000, Testing net (#0)
I1023 17:23:13.846880  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:23:14.364856  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.953125
I1023 17:23:14.364914  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.1299 (* 1 = 0.1299 loss)
I1023 17:23:14.545047  5058 solver.cpp:218] Iteration 9000 (4.95031 iter/s, 20.2008s/100 iters), loss = 0.0500918
I1023 17:23:14.545083  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0500926 (* 1 = 0.0500926 loss)
I1023 17:23:14.545089  5058 sgd_solver.cpp:105] Iteration 9000, lr = 0.01
I1023 17:23:32.440279  5058 solver.cpp:218] Iteration 9100 (5.58811 iter/s, 17.8952s/100 iters), loss = 0.194571
I1023 17:23:32.440309  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194571 (* 1 = 0.194571 loss)
I1023 17:23:32.440315  5058 sgd_solver.cpp:105] Iteration 9100, lr = 0.01
I1023 17:23:50.159502  5058 solver.cpp:330] Iteration 9200, Testing net (#0)
I1023 17:23:51.942494  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:23:52.460566  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.958984
I1023 17:23:52.460623  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.110221 (* 1 = 0.110221 loss)
I1023 17:23:52.640967  5058 solver.cpp:218] Iteration 9200 (4.95035 iter/s, 20.2006s/100 iters), loss = 0.0489821
I1023 17:23:52.641000  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0489829 (* 1 = 0.0489829 loss)
I1023 17:23:52.641005  5058 sgd_solver.cpp:105] Iteration 9200, lr = 0.01
I1023 17:23:54.277319  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:24:10.545404  5058 solver.cpp:218] Iteration 9300 (5.58523 iter/s, 17.9044s/100 iters), loss = 0.11678
I1023 17:24:10.545435  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116781 (* 1 = 0.116781 loss)
I1023 17:24:10.545441  5058 sgd_solver.cpp:105] Iteration 9300, lr = 0.01
I1023 17:24:28.272063  5058 solver.cpp:330] Iteration 9400, Testing net (#0)
I1023 17:24:30.021164  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:24:30.573838  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 17:24:30.573899  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0868278 (* 1 = 0.0868278 loss)
I1023 17:24:30.754333  5058 solver.cpp:218] Iteration 9400 (4.94833 iter/s, 20.2088s/100 iters), loss = 0.0143082
I1023 17:24:30.754364  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014309 (* 1 = 0.014309 loss)
I1023 17:24:30.754370  5058 sgd_solver.cpp:105] Iteration 9400, lr = 0.01
I1023 17:24:48.655362  5058 solver.cpp:218] Iteration 9500 (5.5863 iter/s, 17.901s/100 iters), loss = 0.0786648
I1023 17:24:48.655395  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0786656 (* 1 = 0.0786656 loss)
I1023 17:24:48.655401  5058 sgd_solver.cpp:105] Iteration 9500, lr = 0.01
I1023 17:24:57.634526  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:25:06.382609  5058 solver.cpp:330] Iteration 9600, Testing net (#0)
I1023 17:25:08.130748  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:25:08.683830  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.894531
I1023 17:25:08.683881  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.2559 (* 1 = 0.2559 loss)
I1023 17:25:08.864145  5058 solver.cpp:218] Iteration 9600 (4.94836 iter/s, 20.2087s/100 iters), loss = 0.029008
I1023 17:25:08.864178  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0290088 (* 1 = 0.0290088 loss)
I1023 17:25:08.864186  5058 sgd_solver.cpp:105] Iteration 9600, lr = 0.01
I1023 17:25:26.762949  5058 solver.cpp:218] Iteration 9700 (5.58699 iter/s, 17.8987s/100 iters), loss = 0.046471
I1023 17:25:26.762980  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0464718 (* 1 = 0.0464718 loss)
I1023 17:25:26.762986  5058 sgd_solver.cpp:105] Iteration 9700, lr = 0.01
I1023 17:25:44.483139  5058 solver.cpp:330] Iteration 9800, Testing net (#0)
I1023 17:25:46.230892  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:25:46.783771  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.919922
I1023 17:25:46.783829  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.191941 (* 1 = 0.191941 loss)
I1023 17:25:46.964102  5058 solver.cpp:218] Iteration 9800 (4.95023 iter/s, 20.2011s/100 iters), loss = 0.0840313
I1023 17:25:46.964134  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.084032 (* 1 = 0.084032 loss)
I1023 17:25:46.964141  5058 sgd_solver.cpp:105] Iteration 9800, lr = 0.01
I1023 17:26:03.456454  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:26:04.869515  5058 solver.cpp:218] Iteration 9900 (5.58493 iter/s, 17.9053s/100 iters), loss = 0.0122586
I1023 17:26:04.869547  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122595 (* 1 = 0.0122595 loss)
I1023 17:26:04.869554  5058 sgd_solver.cpp:105] Iteration 9900, lr = 0.01
I1023 17:26:22.595585  5058 solver.cpp:330] Iteration 10000, Testing net (#0)
I1023 17:26:24.342314  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:26:24.897485  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.951172
I1023 17:26:24.897547  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.185238 (* 1 = 0.185238 loss)
I1023 17:26:25.077877  5058 solver.cpp:218] Iteration 10000 (4.94847 iter/s, 20.2083s/100 iters), loss = 0.0700302
I1023 17:26:25.077913  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0700312 (* 1 = 0.0700312 loss)
I1023 17:26:25.077919  5058 sgd_solver.cpp:46] MultiStep Status: Iteration 10000, step = 1
I1023 17:26:25.077922  5058 sgd_solver.cpp:105] Iteration 10000, lr = 0.001
I1023 17:26:42.978766  5058 solver.cpp:218] Iteration 10100 (5.58634 iter/s, 17.9008s/100 iters), loss = 0.0233299
I1023 17:26:42.978798  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0233307 (* 1 = 0.0233307 loss)
I1023 17:26:42.978806  5058 sgd_solver.cpp:105] Iteration 10100, lr = 0.001
I1023 17:27:00.704349  5058 solver.cpp:330] Iteration 10200, Testing net (#0)
I1023 17:27:02.417675  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:27:03.005491  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1023 17:27:03.005556  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0825292 (* 1 = 0.0825292 loss)
I1023 17:27:03.185863  5058 solver.cpp:218] Iteration 10200 (4.94878 iter/s, 20.207s/100 iters), loss = 0.0249861
I1023 17:27:03.185894  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.024987 (* 1 = 0.024987 loss)
I1023 17:27:03.185900  5058 sgd_solver.cpp:105] Iteration 10200, lr = 0.001
I1023 17:27:09.118315  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:27:21.083333  5058 solver.cpp:218] Iteration 10300 (5.58741 iter/s, 17.8974s/100 iters), loss = 0.00693916
I1023 17:27:21.083366  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00694006 (* 1 = 0.00694006 loss)
I1023 17:27:21.083374  5058 sgd_solver.cpp:105] Iteration 10300, lr = 0.001
I1023 17:27:38.802690  5058 solver.cpp:330] Iteration 10400, Testing net (#0)
I1023 17:27:40.515215  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:27:41.104364  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1023 17:27:41.104413  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0723211 (* 1 = 0.0723211 loss)
I1023 17:27:41.285053  5058 solver.cpp:218] Iteration 10400 (4.95009 iter/s, 20.2016s/100 iters), loss = 0.005963
I1023 17:27:41.285086  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00596394 (* 1 = 0.00596394 loss)
I1023 17:27:41.285094  5058 sgd_solver.cpp:105] Iteration 10400, lr = 0.001
I1023 17:27:59.186542  5058 solver.cpp:218] Iteration 10500 (5.58615 iter/s, 17.9014s/100 iters), loss = 0.00923817
I1023 17:27:59.186573  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00923911 (* 1 = 0.00923911 loss)
I1023 17:27:59.186579  5058 sgd_solver.cpp:105] Iteration 10500, lr = 0.001
I1023 17:28:12.461985  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:28:16.918262  5058 solver.cpp:330] Iteration 10600, Testing net (#0)
I1023 17:28:18.630995  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:28:19.220727  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 17:28:19.220787  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0880229 (* 1 = 0.0880229 loss)
I1023 17:28:19.400753  5058 solver.cpp:218] Iteration 10600 (4.94703 iter/s, 20.2141s/100 iters), loss = 0.0830401
I1023 17:28:19.400784  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.083041 (* 1 = 0.083041 loss)
I1023 17:28:19.400790  5058 sgd_solver.cpp:105] Iteration 10600, lr = 0.001
I1023 17:28:37.297384  5058 solver.cpp:218] Iteration 10700 (5.58767 iter/s, 17.8966s/100 iters), loss = 0.00322837
I1023 17:28:37.297415  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00322925 (* 1 = 0.00322925 loss)
I1023 17:28:37.297422  5058 sgd_solver.cpp:105] Iteration 10700, lr = 0.001
I1023 17:28:55.022367  5058 solver.cpp:330] Iteration 10800, Testing net (#0)
I1023 17:28:56.734715  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:28:57.325418  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 17:28:57.325476  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0903582 (* 1 = 0.0903582 loss)
I1023 17:28:57.505702  5058 solver.cpp:218] Iteration 10800 (4.94848 iter/s, 20.2082s/100 iters), loss = 0.00478632
I1023 17:28:57.505738  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00478721 (* 1 = 0.00478721 loss)
I1023 17:28:57.505744  5058 sgd_solver.cpp:105] Iteration 10800, lr = 0.001
I1023 17:29:15.405766  5058 solver.cpp:218] Iteration 10900 (5.5866 iter/s, 17.9s/100 iters), loss = 0.0262838
I1023 17:29:15.405797  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0262847 (* 1 = 0.0262847 loss)
I1023 17:29:15.405803  5058 sgd_solver.cpp:105] Iteration 10900, lr = 0.001
I1023 17:29:18.117854  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:29:33.130322  5058 solver.cpp:330] Iteration 11000, Testing net (#0)
I1023 17:29:34.809092  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:29:35.432199  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 17:29:35.432257  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0841542 (* 1 = 0.0841542 loss)
I1023 17:29:35.612359  5058 solver.cpp:218] Iteration 11000 (4.9489 iter/s, 20.2065s/100 iters), loss = 0.366586
I1023 17:29:35.612391  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366587 (* 1 = 0.366587 loss)
I1023 17:29:35.612397  5058 sgd_solver.cpp:105] Iteration 11000, lr = 0.001
I1023 17:29:53.512203  5058 solver.cpp:218] Iteration 11100 (5.58667 iter/s, 17.8998s/100 iters), loss = 0.0397766
I1023 17:29:53.512234  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0397775 (* 1 = 0.0397775 loss)
I1023 17:29:53.512241  5058 sgd_solver.cpp:105] Iteration 11100, lr = 0.001
I1023 17:30:11.236667  5058 solver.cpp:330] Iteration 11200, Testing net (#0)
I1023 17:30:12.914641  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:30:13.538688  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.982422
I1023 17:30:13.538748  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0667115 (* 1 = 0.0667115 loss)
I1023 17:30:13.719218  5058 solver.cpp:218] Iteration 11200 (4.9488 iter/s, 20.2069s/100 iters), loss = 0.00688987
I1023 17:30:13.719250  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00689081 (* 1 = 0.00689081 loss)
I1023 17:30:13.719257  5058 sgd_solver.cpp:105] Iteration 11200, lr = 0.001
I1023 17:30:23.948304  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:30:31.628350  5058 solver.cpp:218] Iteration 11300 (5.58377 iter/s, 17.9091s/100 iters), loss = 0.130264
I1023 17:30:31.628381  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.130265 (* 1 = 0.130265 loss)
I1023 17:30:31.628388  5058 sgd_solver.cpp:105] Iteration 11300, lr = 0.001
I1023 17:30:49.345204  5058 solver.cpp:330] Iteration 11400, Testing net (#0)
I1023 17:30:51.021659  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:30:51.646968  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.976562
I1023 17:30:51.647027  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0698679 (* 1 = 0.0698679 loss)
I1023 17:30:51.827287  5058 solver.cpp:218] Iteration 11400 (4.95077 iter/s, 20.1989s/100 iters), loss = 0.0326086
I1023 17:30:51.827319  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0326097 (* 1 = 0.0326097 loss)
I1023 17:30:51.827327  5058 sgd_solver.cpp:105] Iteration 11400, lr = 0.001
I1023 17:31:09.723526  5058 solver.cpp:218] Iteration 11500 (5.58779 iter/s, 17.8962s/100 iters), loss = 0.00383
I1023 17:31:09.723558  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00383105 (* 1 = 0.00383105 loss)
I1023 17:31:09.723564  5058 sgd_solver.cpp:105] Iteration 11500, lr = 0.001
I1023 17:31:27.285722  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:31:27.444468  5058 solver.cpp:330] Iteration 11600, Testing net (#0)
I1023 17:31:29.121351  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:31:29.747231  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 17:31:29.747289  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0780709 (* 1 = 0.0780709 loss)
I1023 17:31:29.927093  5058 solver.cpp:218] Iteration 11600 (4.94964 iter/s, 20.2035s/100 iters), loss = 0.0255439
I1023 17:31:29.927129  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0255449 (* 1 = 0.0255449 loss)
I1023 17:31:29.927135  5058 sgd_solver.cpp:105] Iteration 11600, lr = 0.001
I1023 17:31:47.830114  5058 solver.cpp:218] Iteration 11700 (5.58567 iter/s, 17.9029s/100 iters), loss = 0.0255629
I1023 17:31:47.830144  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.025564 (* 1 = 0.025564 loss)
I1023 17:31:47.830152  5058 sgd_solver.cpp:105] Iteration 11700, lr = 0.001
I1023 17:32:05.555851  5058 solver.cpp:330] Iteration 11800, Testing net (#0)
I1023 17:32:07.198734  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:32:07.858065  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.976562
I1023 17:32:07.858121  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0696485 (* 1 = 0.0696485 loss)
I1023 17:32:08.038818  5058 solver.cpp:218] Iteration 11800 (4.94838 iter/s, 20.2086s/100 iters), loss = 0.025812
I1023 17:32:08.038852  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0258132 (* 1 = 0.0258132 loss)
I1023 17:32:08.038859  5058 sgd_solver.cpp:105] Iteration 11800, lr = 0.001
I1023 17:32:25.943325  5058 solver.cpp:218] Iteration 11900 (5.58521 iter/s, 17.9044s/100 iters), loss = 0.0457635
I1023 17:32:25.943356  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0457647 (* 1 = 0.0457647 loss)
I1023 17:32:25.943362  5058 sgd_solver.cpp:105] Iteration 11900, lr = 0.001
I1023 17:32:32.953225  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:32:43.673836  5058 solver.cpp:330] Iteration 12000, Testing net (#0)
I1023 17:32:45.315853  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:32:45.975898  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1023 17:32:45.975952  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0691434 (* 1 = 0.0691434 loss)
I1023 17:32:46.156146  5058 solver.cpp:218] Iteration 12000 (4.94737 iter/s, 20.2127s/100 iters), loss = 0.0186297
I1023 17:32:46.156182  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0186309 (* 1 = 0.0186309 loss)
I1023 17:32:46.156189  5058 sgd_solver.cpp:105] Iteration 12000, lr = 0.001
I1023 17:33:04.055965  5058 solver.cpp:218] Iteration 12100 (5.58667 iter/s, 17.8997s/100 iters), loss = 0.0094101
I1023 17:33:04.055995  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00941125 (* 1 = 0.00941125 loss)
I1023 17:33:04.056002  5058 sgd_solver.cpp:105] Iteration 12100, lr = 0.001
I1023 17:33:21.779254  5058 solver.cpp:330] Iteration 12200, Testing net (#0)
I1023 17:33:23.419606  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:33:24.081641  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.978516
I1023 17:33:24.081698  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0619116 (* 1 = 0.0619116 loss)
I1023 17:33:24.262015  5058 solver.cpp:218] Iteration 12200 (4.94903 iter/s, 20.206s/100 iters), loss = 0.00391708
I1023 17:33:24.262048  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00391823 (* 1 = 0.00391823 loss)
I1023 17:33:24.262054  5058 sgd_solver.cpp:105] Iteration 12200, lr = 0.001
I1023 17:33:38.608636  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:33:42.166203  5058 solver.cpp:218] Iteration 12300 (5.58531 iter/s, 17.9041s/100 iters), loss = 0.011737
I1023 17:33:42.166234  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117382 (* 1 = 0.0117382 loss)
I1023 17:33:42.166242  5058 sgd_solver.cpp:105] Iteration 12300, lr = 0.001
I1023 17:33:59.888366  5058 solver.cpp:330] Iteration 12400, Testing net (#0)
I1023 17:34:01.530478  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:34:02.192811  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1023 17:34:02.192873  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0601065 (* 1 = 0.0601065 loss)
I1023 17:34:02.373338  5058 solver.cpp:218] Iteration 12400 (4.94877 iter/s, 20.2071s/100 iters), loss = 0.0137699
I1023 17:34:02.373370  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0137712 (* 1 = 0.0137712 loss)
I1023 17:34:02.373378  5058 sgd_solver.cpp:105] Iteration 12400, lr = 0.001
I1023 17:34:20.273269  5058 solver.cpp:218] Iteration 12500 (5.58664 iter/s, 17.8999s/100 iters), loss = 0.172282
I1023 17:34:20.273299  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172284 (* 1 = 0.172284 loss)
I1023 17:34:20.273305  5058 sgd_solver.cpp:105] Iteration 12500, lr = 0.001
I1023 17:34:38.000293  5058 solver.cpp:330] Iteration 12600, Testing net (#0)
I1023 17:34:39.606415  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:34:40.301822  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.976562
I1023 17:34:40.301885  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0650109 (* 1 = 0.0650109 loss)
I1023 17:34:40.482146  5058 solver.cpp:218] Iteration 12600 (4.94834 iter/s, 20.2088s/100 iters), loss = 0.0387208
I1023 17:34:40.482177  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0387221 (* 1 = 0.0387221 loss)
I1023 17:34:40.482183  5058 sgd_solver.cpp:105] Iteration 12600, lr = 0.001
I1023 17:34:44.442950  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:34:58.379631  5058 solver.cpp:218] Iteration 12700 (5.5874 iter/s, 17.8974s/100 iters), loss = 0.0052044
I1023 17:34:58.379663  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00520566 (* 1 = 0.00520566 loss)
I1023 17:34:58.379681  5058 sgd_solver.cpp:105] Iteration 12700, lr = 0.001
I1023 17:35:16.098507  5058 solver.cpp:330] Iteration 12800, Testing net (#0)
I1023 17:35:17.703586  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:35:18.400054  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.976562
I1023 17:35:18.400115  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0635926 (* 1 = 0.0635926 loss)
I1023 17:35:18.580454  5058 solver.cpp:218] Iteration 12800 (4.95031 iter/s, 20.2007s/100 iters), loss = 0.190266
I1023 17:35:18.580488  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190267 (* 1 = 0.190267 loss)
I1023 17:35:18.580497  5058 sgd_solver.cpp:105] Iteration 12800, lr = 0.001
I1023 17:35:36.481729  5058 solver.cpp:218] Iteration 12900 (5.58622 iter/s, 17.9012s/100 iters), loss = 0.0208552
I1023 17:35:36.481760  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0208564 (* 1 = 0.0208564 loss)
I1023 17:35:36.481766  5058 sgd_solver.cpp:105] Iteration 12900, lr = 0.001
I1023 17:35:47.788874  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:35:54.215984  5058 solver.cpp:330] Iteration 13000, Testing net (#0)
I1023 17:35:55.820864  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:35:56.518863  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1023 17:35:56.518925  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0680268 (* 1 = 0.0680268 loss)
I1023 17:35:56.699000  5058 solver.cpp:218] Iteration 13000 (4.94629 iter/s, 20.2172s/100 iters), loss = 0.00334193
I1023 17:35:56.699033  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00334325 (* 1 = 0.00334325 loss)
I1023 17:35:56.699040  5058 sgd_solver.cpp:105] Iteration 13000, lr = 0.001
I1023 17:36:14.594179  5058 solver.cpp:218] Iteration 13100 (5.58812 iter/s, 17.8951s/100 iters), loss = 0.0042285
I1023 17:36:14.594211  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0042298 (* 1 = 0.0042298 loss)
I1023 17:36:14.594218  5058 sgd_solver.cpp:105] Iteration 13100, lr = 0.001
I1023 17:36:32.320780  5058 solver.cpp:330] Iteration 13200, Testing net (#0)
I1023 17:36:33.924087  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:36:34.622278  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1023 17:36:34.622337  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0672765 (* 1 = 0.0672765 loss)
I1023 17:36:34.802613  5058 solver.cpp:218] Iteration 13200 (4.94845 iter/s, 20.2084s/100 iters), loss = 0.009811
I1023 17:36:34.802650  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00981231 (* 1 = 0.00981231 loss)
I1023 17:36:34.802657  5058 sgd_solver.cpp:105] Iteration 13200, lr = 0.001
I1023 17:36:52.700193  5058 solver.cpp:218] Iteration 13300 (5.58737 iter/s, 17.8975s/100 iters), loss = 0.00401882
I1023 17:36:52.700224  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00402012 (* 1 = 0.00402012 loss)
I1023 17:36:52.700230  5058 sgd_solver.cpp:105] Iteration 13300, lr = 0.001
I1023 17:36:53.441983  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:37:10.425643  5058 solver.cpp:330] Iteration 13400, Testing net (#0)
I1023 17:37:11.996249  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:37:12.727494  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 17:37:12.727555  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0708861 (* 1 = 0.0708861 loss)
I1023 17:37:12.908033  5058 solver.cpp:218] Iteration 13400 (4.94859 iter/s, 20.2078s/100 iters), loss = 0.00959747
I1023 17:37:12.908067  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00959872 (* 1 = 0.00959872 loss)
I1023 17:37:12.908074  5058 sgd_solver.cpp:105] Iteration 13400, lr = 0.001
I1023 17:37:30.810320  5058 solver.cpp:218] Iteration 13500 (5.5859 iter/s, 17.9022s/100 iters), loss = 0.0080984
I1023 17:37:30.810353  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00809967 (* 1 = 0.00809967 loss)
I1023 17:37:30.810359  5058 sgd_solver.cpp:105] Iteration 13500, lr = 0.001
I1023 17:37:48.537817  5058 solver.cpp:330] Iteration 13600, Testing net (#0)
I1023 17:37:50.106858  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:37:50.839579  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1023 17:37:50.839627  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0669141 (* 1 = 0.0669141 loss)
I1023 17:37:51.020247  5058 solver.cpp:218] Iteration 13600 (4.94808 iter/s, 20.2098s/100 iters), loss = 0.00541766
I1023 17:37:51.020278  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00541894 (* 1 = 0.00541894 loss)
I1023 17:37:51.020285  5058 sgd_solver.cpp:105] Iteration 13600, lr = 0.001
I1023 17:37:59.107425  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:38:08.925007  5058 solver.cpp:218] Iteration 13700 (5.58513 iter/s, 17.9047s/100 iters), loss = 0.0114858
I1023 17:38:08.925040  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114871 (* 1 = 0.0114871 loss)
I1023 17:38:08.925046  5058 sgd_solver.cpp:105] Iteration 13700, lr = 0.001
I1023 17:38:26.651294  5058 solver.cpp:330] Iteration 13800, Testing net (#0)
I1023 17:38:28.219391  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:38:28.951925  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1023 17:38:28.951993  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0597477 (* 1 = 0.0597477 loss)
I1023 17:38:29.132122  5058 solver.cpp:218] Iteration 13800 (4.94877 iter/s, 20.207s/100 iters), loss = 0.0218115
I1023 17:38:29.132151  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0218128 (* 1 = 0.0218128 loss)
I1023 17:38:29.132158  5058 sgd_solver.cpp:105] Iteration 13800, lr = 0.001
I1023 17:38:47.028133  5058 solver.cpp:218] Iteration 13900 (5.58786 iter/s, 17.8959s/100 iters), loss = 0.039348
I1023 17:38:47.028164  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0393493 (* 1 = 0.0393493 loss)
I1023 17:38:47.028172  5058 sgd_solver.cpp:105] Iteration 13900, lr = 0.001
I1023 17:39:02.622665  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:39:04.751189  5058 solver.cpp:330] Iteration 14000, Testing net (#0)
I1023 17:39:06.320317  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:39:07.055855  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.980469
I1023 17:39:07.055912  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.061639 (* 1 = 0.061639 loss)
I1023 17:39:07.235847  5058 solver.cpp:218] Iteration 14000 (4.94863 iter/s, 20.2076s/100 iters), loss = 0.0139561
I1023 17:39:07.235880  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139574 (* 1 = 0.0139574 loss)
I1023 17:39:07.235888  5058 sgd_solver.cpp:105] Iteration 14000, lr = 0.001
I1023 17:39:25.136968  5058 solver.cpp:218] Iteration 14100 (5.58627 iter/s, 17.901s/100 iters), loss = 0.198513
I1023 17:39:25.137001  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198514 (* 1 = 0.198514 loss)
I1023 17:39:25.137007  5058 sgd_solver.cpp:105] Iteration 14100, lr = 0.001
I1023 17:39:42.865129  5058 solver.cpp:330] Iteration 14200, Testing net (#0)
I1023 17:39:44.400132  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:39:45.167141  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1023 17:39:45.167202  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0670462 (* 1 = 0.0670462 loss)
I1023 17:39:45.347271  5058 solver.cpp:218] Iteration 14200 (4.94799 iter/s, 20.2102s/100 iters), loss = 0.0173977
I1023 17:39:45.347317  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0173989 (* 1 = 0.0173989 loss)
I1023 17:39:45.347326  5058 sgd_solver.cpp:105] Iteration 14200, lr = 0.001
I1023 17:40:03.251922  5058 solver.cpp:218] Iteration 14300 (5.58517 iter/s, 17.9046s/100 iters), loss = 0.00397955
I1023 17:40:03.251955  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00398083 (* 1 = 0.00398083 loss)
I1023 17:40:03.251962  5058 sgd_solver.cpp:105] Iteration 14300, lr = 0.001
I1023 17:40:08.291175  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:40:20.978159  5058 solver.cpp:330] Iteration 14400, Testing net (#0)
I1023 17:40:22.512697  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:40:23.280469  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 17:40:23.280532  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0809 (* 1 = 0.0809 loss)
I1023 17:40:23.460831  5058 solver.cpp:218] Iteration 14400 (4.94833 iter/s, 20.2088s/100 iters), loss = 0.0793511
I1023 17:40:23.460865  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0793524 (* 1 = 0.0793524 loss)
I1023 17:40:23.460872  5058 sgd_solver.cpp:105] Iteration 14400, lr = 0.001
I1023 17:40:41.359851  5058 solver.cpp:218] Iteration 14500 (5.58692 iter/s, 17.8989s/100 iters), loss = 0.00740315
I1023 17:40:41.359882  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00740443 (* 1 = 0.00740443 loss)
I1023 17:40:41.359889  5058 sgd_solver.cpp:105] Iteration 14500, lr = 0.001
I1023 17:40:59.080936  5058 solver.cpp:330] Iteration 14600, Testing net (#0)
I1023 17:41:00.614456  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:41:01.383527  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 17:41:01.383590  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0707083 (* 1 = 0.0707083 loss)
I1023 17:41:01.563935  5058 solver.cpp:218] Iteration 14600 (4.94951 iter/s, 20.204s/100 iters), loss = 0.0142986
I1023 17:41:01.563983  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142999 (* 1 = 0.0142999 loss)
I1023 17:41:01.563990  5058 sgd_solver.cpp:105] Iteration 14600, lr = 0.001
I1023 17:41:13.942049  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:41:19.471583  5058 solver.cpp:218] Iteration 14700 (5.58423 iter/s, 17.9076s/100 iters), loss = 0.00529025
I1023 17:41:19.471616  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00529157 (* 1 = 0.00529157 loss)
I1023 17:41:19.471622  5058 sgd_solver.cpp:105] Iteration 14700, lr = 0.001
I1023 17:41:37.190929  5058 solver.cpp:330] Iteration 14800, Testing net (#0)
I1023 17:41:38.723465  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:41:39.493144  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.978516
I1023 17:41:39.493188  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0606547 (* 1 = 0.0606547 loss)
I1023 17:41:39.673916  5058 solver.cpp:218] Iteration 14800 (4.94994 iter/s, 20.2022s/100 iters), loss = 0.0201029
I1023 17:41:39.673948  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0201041 (* 1 = 0.0201041 loss)
I1023 17:41:39.673954  5058 sgd_solver.cpp:105] Iteration 14800, lr = 0.001
I1023 17:41:57.574344  5058 solver.cpp:218] Iteration 14900 (5.58648 iter/s, 17.9004s/100 iters), loss = 0.0748729
I1023 17:41:57.574375  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0748742 (* 1 = 0.0748742 loss)
I1023 17:41:57.574383  5058 sgd_solver.cpp:105] Iteration 14900, lr = 0.001
I1023 17:42:15.298681  5058 solver.cpp:330] Iteration 15000, Testing net (#0)
I1023 17:42:16.796851  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:42:17.600034  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 17:42:17.600095  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0746011 (* 1 = 0.0746011 loss)
I1023 17:42:17.780457  5058 solver.cpp:218] Iteration 15000 (4.94902 iter/s, 20.206s/100 iters), loss = 0.0149843
I1023 17:42:17.780488  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149856 (* 1 = 0.0149856 loss)
I1023 17:42:17.780495  5058 sgd_solver.cpp:105] Iteration 15000, lr = 0.001
I1023 17:42:19.597239  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:42:35.676249  5058 solver.cpp:218] Iteration 15100 (5.58793 iter/s, 17.8957s/100 iters), loss = 0.0132483
I1023 17:42:35.676280  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132496 (* 1 = 0.0132496 loss)
I1023 17:42:35.676286  5058 sgd_solver.cpp:105] Iteration 15100, lr = 0.001
I1023 17:42:53.396740  5058 solver.cpp:330] Iteration 15200, Testing net (#0)
I1023 17:42:54.895164  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:42:55.699283  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1023 17:42:55.699347  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0623414 (* 1 = 0.0623414 loss)
I1023 17:42:55.880012  5058 solver.cpp:218] Iteration 15200 (4.94959 iter/s, 20.2037s/100 iters), loss = 0.00527102
I1023 17:42:55.880049  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00527231 (* 1 = 0.00527231 loss)
I1023 17:42:55.880058  5058 sgd_solver.cpp:105] Iteration 15200, lr = 0.001
I1023 17:43:13.783249  5058 solver.cpp:218] Iteration 15300 (5.58561 iter/s, 17.9032s/100 iters), loss = 0.0574821
I1023 17:43:13.783280  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0574834 (* 1 = 0.0574834 loss)
I1023 17:43:13.783288  5058 sgd_solver.cpp:105] Iteration 15300, lr = 0.001
I1023 17:43:23.118132  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:43:31.510040  5058 solver.cpp:330] Iteration 15400, Testing net (#0)
I1023 17:43:33.006387  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:43:33.812105  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1023 17:43:33.812168  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0782814 (* 1 = 0.0782814 loss)
I1023 17:43:33.992981  5058 solver.cpp:218] Iteration 15400 (4.94813 iter/s, 20.2097s/100 iters), loss = 0.00319698
I1023 17:43:33.993028  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00319821 (* 1 = 0.00319821 loss)
I1023 17:43:33.993046  5058 sgd_solver.cpp:105] Iteration 15400, lr = 0.001
I1023 17:43:51.893682  5058 solver.cpp:218] Iteration 15500 (5.5864 iter/s, 17.9006s/100 iters), loss = 0.000621155
I1023 17:43:51.893714  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000622355 (* 1 = 0.000622355 loss)
I1023 17:43:51.893720  5058 sgd_solver.cpp:105] Iteration 15500, lr = 0.001
I1023 17:44:09.621673  5058 solver.cpp:330] Iteration 15600, Testing net (#0)
I1023 17:44:11.117938  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:44:11.923537  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 17:44:11.923593  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0707926 (* 1 = 0.0707926 loss)
I1023 17:44:12.103869  5058 solver.cpp:218] Iteration 15600 (4.94802 iter/s, 20.2101s/100 iters), loss = 0.000960967
I1023 17:44:12.103901  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000962159 (* 1 = 0.000962159 loss)
I1023 17:44:12.103909  5058 sgd_solver.cpp:105] Iteration 15600, lr = 0.001
I1023 17:44:28.771330  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:44:30.004647  5058 solver.cpp:218] Iteration 15700 (5.58637 iter/s, 17.9007s/100 iters), loss = 0.00916139
I1023 17:44:30.004683  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00916259 (* 1 = 0.00916259 loss)
I1023 17:44:30.004690  5058 sgd_solver.cpp:105] Iteration 15700, lr = 0.001
I1023 17:44:47.726913  5058 solver.cpp:330] Iteration 15800, Testing net (#0)
I1023 17:44:49.189848  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:44:50.029090  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 17:44:50.029166  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0711589 (* 1 = 0.0711589 loss)
I1023 17:44:50.209599  5058 solver.cpp:218] Iteration 15800 (4.9493 iter/s, 20.2049s/100 iters), loss = 0.0239608
I1023 17:44:50.209631  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0239621 (* 1 = 0.0239621 loss)
I1023 17:44:50.209640  5058 sgd_solver.cpp:105] Iteration 15800, lr = 0.001
I1023 17:45:08.159942  5058 solver.cpp:218] Iteration 15900 (5.57095 iter/s, 17.9503s/100 iters), loss = 0.00604612
I1023 17:45:08.159986  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00604734 (* 1 = 0.00604734 loss)
I1023 17:45:08.159993  5058 sgd_solver.cpp:105] Iteration 15900, lr = 0.001
I1023 17:45:25.885855  5058 solver.cpp:330] Iteration 16000, Testing net (#0)
I1023 17:45:27.348299  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:45:28.187702  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96875
I1023 17:45:28.187768  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.065127 (* 1 = 0.065127 loss)
I1023 17:45:28.368418  5058 solver.cpp:218] Iteration 16000 (4.94844 iter/s, 20.2084s/100 iters), loss = 0.0275292
I1023 17:45:28.368449  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0275304 (* 1 = 0.0275304 loss)
I1023 17:45:28.368456  5058 sgd_solver.cpp:105] Iteration 16000, lr = 0.001
I1023 17:45:34.483117  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:45:46.270289  5058 solver.cpp:218] Iteration 16100 (5.58603 iter/s, 17.9018s/100 iters), loss = 0.00109335
I1023 17:45:46.270321  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00109453 (* 1 = 0.00109453 loss)
I1023 17:45:46.270328  5058 sgd_solver.cpp:105] Iteration 16100, lr = 0.001
I1023 17:46:03.997216  5058 solver.cpp:330] Iteration 16200, Testing net (#0)
I1023 17:46:05.458354  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:46:06.298810  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.978516
I1023 17:46:06.298873  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0585075 (* 1 = 0.0585075 loss)
I1023 17:46:06.479384  5058 solver.cpp:218] Iteration 16200 (4.94829 iter/s, 20.209s/100 iters), loss = 0.0341677
I1023 17:46:06.479415  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0341688 (* 1 = 0.0341688 loss)
I1023 17:46:06.479423  5058 sgd_solver.cpp:105] Iteration 16200, lr = 0.001
I1023 17:46:24.373083  5058 solver.cpp:218] Iteration 16300 (5.58858 iter/s, 17.8936s/100 iters), loss = 0.0981288
I1023 17:46:24.373116  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.09813 (* 1 = 0.09813 loss)
I1023 17:46:24.373122  5058 sgd_solver.cpp:105] Iteration 16300, lr = 0.001
I1023 17:46:37.824497  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:46:42.098098  5058 solver.cpp:330] Iteration 16400, Testing net (#0)
I1023 17:46:43.559303  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:46:44.400547  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1023 17:46:44.400609  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0713621 (* 1 = 0.0713621 loss)
I1023 17:46:44.581270  5058 solver.cpp:218] Iteration 16400 (4.94851 iter/s, 20.2081s/100 iters), loss = 0.01149
I1023 17:46:44.581302  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114911 (* 1 = 0.0114911 loss)
I1023 17:46:44.581310  5058 sgd_solver.cpp:105] Iteration 16400, lr = 0.001
I1023 17:47:02.477138  5058 solver.cpp:218] Iteration 16500 (5.58791 iter/s, 17.8958s/100 iters), loss = 0.0393413
I1023 17:47:02.477169  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0393425 (* 1 = 0.0393425 loss)
I1023 17:47:02.477175  5058 sgd_solver.cpp:105] Iteration 16500, lr = 0.001
I1023 17:47:20.203541  5058 solver.cpp:330] Iteration 16600, Testing net (#0)
I1023 17:47:21.630774  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:47:22.504634  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1023 17:47:22.504689  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0717307 (* 1 = 0.0717307 loss)
I1023 17:47:22.685158  5058 solver.cpp:218] Iteration 16600 (4.94855 iter/s, 20.2079s/100 iters), loss = 0.00179315
I1023 17:47:22.685189  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00179427 (* 1 = 0.00179427 loss)
I1023 17:47:22.685196  5058 sgd_solver.cpp:105] Iteration 16600, lr = 0.001
I1023 17:47:40.585623  5058 solver.cpp:218] Iteration 16700 (5.58647 iter/s, 17.9004s/100 iters), loss = 0.00561044
I1023 17:47:40.585654  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00561152 (* 1 = 0.00561152 loss)
I1023 17:47:40.585661  5058 sgd_solver.cpp:105] Iteration 16700, lr = 0.001
I1023 17:47:43.653753  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:47:58.314097  5058 solver.cpp:330] Iteration 16800, Testing net (#0)
I1023 17:47:59.740540  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:48:00.616611  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 17:48:00.616667  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0745418 (* 1 = 0.0745418 loss)
I1023 17:48:00.796636  5058 solver.cpp:218] Iteration 16800 (4.94782 iter/s, 20.2109s/100 iters), loss = 0.00660876
I1023 17:48:00.796666  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00660986 (* 1 = 0.00660986 loss)
I1023 17:48:00.796672  5058 sgd_solver.cpp:105] Iteration 16800, lr = 0.001
I1023 17:48:18.693963  5058 solver.cpp:218] Iteration 16900 (5.58745 iter/s, 17.8972s/100 iters), loss = 0.0406469
I1023 17:48:18.693996  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0406481 (* 1 = 0.0406481 loss)
I1023 17:48:18.694013  5058 sgd_solver.cpp:105] Iteration 16900, lr = 0.001
I1023 17:48:36.416004  5058 solver.cpp:330] Iteration 17000, Testing net (#0)
I1023 17:48:37.841792  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:48:38.717288  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1023 17:48:38.717329  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0711957 (* 1 = 0.0711957 loss)
I1023 17:48:38.897603  5058 solver.cpp:218] Iteration 17000 (4.94962 iter/s, 20.2036s/100 iters), loss = 0.00244015
I1023 17:48:38.897637  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00244127 (* 1 = 0.00244127 loss)
I1023 17:48:38.897644  5058 sgd_solver.cpp:105] Iteration 17000, lr = 0.001
I1023 17:48:49.306161  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:48:56.804574  5058 solver.cpp:218] Iteration 17100 (5.58444 iter/s, 17.9069s/100 iters), loss = 0.0107686
I1023 17:48:56.804603  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107697 (* 1 = 0.0107697 loss)
I1023 17:48:56.804610  5058 sgd_solver.cpp:105] Iteration 17100, lr = 0.001
I1023 17:49:14.522714  5058 solver.cpp:330] Iteration 17200, Testing net (#0)
I1023 17:49:15.947259  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:49:16.827989  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.978516
I1023 17:49:16.828050  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0576784 (* 1 = 0.0576784 loss)
I1023 17:49:17.008524  5058 solver.cpp:218] Iteration 17200 (4.94955 iter/s, 20.2039s/100 iters), loss = 0.0030359
I1023 17:49:17.008556  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00303699 (* 1 = 0.00303699 loss)
I1023 17:49:17.008563  5058 sgd_solver.cpp:105] Iteration 17200, lr = 0.001
I1023 17:49:34.909725  5058 solver.cpp:218] Iteration 17300 (5.58624 iter/s, 17.9011s/100 iters), loss = 0.00348105
I1023 17:49:34.909757  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00348213 (* 1 = 0.00348213 loss)
I1023 17:49:34.909765  5058 sgd_solver.cpp:105] Iteration 17300, lr = 0.001
I1023 17:49:52.634152  5058 solver.cpp:330] Iteration 17400, Testing net (#0)
I1023 17:49:54.025801  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:49:54.936132  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.970703
I1023 17:49:54.936189  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.064686 (* 1 = 0.064686 loss)
I1023 17:49:54.959565  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:49:55.116251  5058 solver.cpp:218] Iteration 17400 (4.94891 iter/s, 20.2065s/100 iters), loss = 0.0370182
I1023 17:49:55.116283  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0370193 (* 1 = 0.0370193 loss)
I1023 17:49:55.116291  5058 sgd_solver.cpp:105] Iteration 17400, lr = 0.001
I1023 17:50:13.011975  5058 solver.cpp:218] Iteration 17500 (5.58795 iter/s, 17.8956s/100 iters), loss = 0.161392
I1023 17:50:13.012012  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161393 (* 1 = 0.161393 loss)
I1023 17:50:13.012019  5058 sgd_solver.cpp:105] Iteration 17500, lr = 0.001
I1023 17:50:30.732007  5058 solver.cpp:330] Iteration 17600, Testing net (#0)
I1023 17:50:32.122325  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:50:33.034282  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.976562
I1023 17:50:33.034339  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0552956 (* 1 = 0.0552956 loss)
I1023 17:50:33.214622  5058 solver.cpp:218] Iteration 17600 (4.94987 iter/s, 20.2026s/100 iters), loss = 0.0329736
I1023 17:50:33.214655  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0329747 (* 1 = 0.0329747 loss)
I1023 17:50:33.214661  5058 sgd_solver.cpp:105] Iteration 17600, lr = 0.001
I1023 17:50:51.117210  5058 solver.cpp:218] Iteration 17700 (5.58581 iter/s, 17.9025s/100 iters), loss = 0.226565
I1023 17:50:51.117242  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226566 (* 1 = 0.226566 loss)
I1023 17:50:51.117249  5058 sgd_solver.cpp:105] Iteration 17700, lr = 0.001
I1023 17:50:58.305910  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:51:08.844310  5058 solver.cpp:330] Iteration 17800, Testing net (#0)
I1023 17:51:10.232815  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:51:11.145869  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1023 17:51:11.145927  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.068365 (* 1 = 0.068365 loss)
I1023 17:51:11.326653  5058 solver.cpp:218] Iteration 17800 (4.9482 iter/s, 20.2094s/100 iters), loss = 0.0966303
I1023 17:51:11.326684  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0966315 (* 1 = 0.0966315 loss)
I1023 17:51:11.326691  5058 sgd_solver.cpp:105] Iteration 17800, lr = 0.001
I1023 17:51:29.231298  5058 solver.cpp:218] Iteration 17900 (5.58517 iter/s, 17.9046s/100 iters), loss = 0.115912
I1023 17:51:29.231328  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115914 (* 1 = 0.115914 loss)
I1023 17:51:29.231335  5058 sgd_solver.cpp:105] Iteration 17900, lr = 0.001
I1023 17:51:46.956480  5058 solver.cpp:330] Iteration 18000, Testing net (#0)
I1023 17:51:48.345268  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:51:49.257483  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.984375
I1023 17:51:49.257546  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0530965 (* 1 = 0.0530965 loss)
I1023 17:51:49.437593  5058 solver.cpp:218] Iteration 18000 (4.94897 iter/s, 20.2062s/100 iters), loss = 0.0228214
I1023 17:51:49.437624  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0228226 (* 1 = 0.0228226 loss)
I1023 17:51:49.437631  5058 sgd_solver.cpp:105] Iteration 18000, lr = 0.001
I1023 17:52:04.138664  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:52:07.341258  5058 solver.cpp:218] Iteration 18100 (5.58547 iter/s, 17.9036s/100 iters), loss = 0.00422527
I1023 17:52:07.341292  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00422643 (* 1 = 0.00422643 loss)
I1023 17:52:07.341300  5058 sgd_solver.cpp:105] Iteration 18100, lr = 0.001
I1023 17:52:25.059096  5058 solver.cpp:330] Iteration 18200, Testing net (#0)
I1023 17:52:26.414569  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:52:27.360568  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.976562
I1023 17:52:27.360630  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.058792 (* 1 = 0.058792 loss)
I1023 17:52:27.541083  5058 solver.cpp:218] Iteration 18200 (4.95056 iter/s, 20.1997s/100 iters), loss = 0.0227014
I1023 17:52:27.541116  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227025 (* 1 = 0.0227025 loss)
I1023 17:52:27.541123  5058 sgd_solver.cpp:105] Iteration 18200, lr = 0.001
I1023 17:52:45.443552  5058 solver.cpp:218] Iteration 18300 (5.58585 iter/s, 17.9024s/100 iters), loss = 0.011605
I1023 17:52:45.443584  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116061 (* 1 = 0.0116061 loss)
I1023 17:52:45.443591  5058 sgd_solver.cpp:105] Iteration 18300, lr = 0.001
I1023 17:53:03.170648  5058 solver.cpp:330] Iteration 18400, Testing net (#0)
I1023 17:53:04.524816  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:53:05.472717  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.966797
I1023 17:53:05.472777  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0770607 (* 1 = 0.0770607 loss)
I1023 17:53:05.653246  5058 solver.cpp:218] Iteration 18400 (4.94814 iter/s, 20.2096s/100 iters), loss = 0.0280949
I1023 17:53:05.653278  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.028096 (* 1 = 0.028096 loss)
I1023 17:53:05.653285  5058 sgd_solver.cpp:105] Iteration 18400, lr = 0.001
I1023 17:53:09.796439  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:53:23.553953  5058 solver.cpp:218] Iteration 18500 (5.5864 iter/s, 17.9006s/100 iters), loss = 0.00273561
I1023 17:53:23.553984  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00273677 (* 1 = 0.00273677 loss)
I1023 17:53:23.553990  5058 sgd_solver.cpp:105] Iteration 18500, lr = 0.001
I1023 17:53:41.277768  5058 solver.cpp:330] Iteration 18600, Testing net (#0)
I1023 17:53:42.631356  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:53:43.579556  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1023 17:53:43.579614  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0589985 (* 1 = 0.0589985 loss)
I1023 17:53:43.760113  5058 solver.cpp:218] Iteration 18600 (4.94901 iter/s, 20.2061s/100 iters), loss = 0.0111827
I1023 17:53:43.760143  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111838 (* 1 = 0.0111838 loss)
I1023 17:53:43.760149  5058 sgd_solver.cpp:105] Iteration 18600, lr = 0.001
I1023 17:54:01.657843  5058 solver.cpp:218] Iteration 18700 (5.58732 iter/s, 17.8977s/100 iters), loss = 0.0560613
I1023 17:54:01.657874  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0560624 (* 1 = 0.0560624 loss)
I1023 17:54:01.657882  5058 sgd_solver.cpp:105] Iteration 18700, lr = 0.001
I1023 17:54:13.140128  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:54:19.384600  5058 solver.cpp:330] Iteration 18800, Testing net (#0)
I1023 17:54:20.737411  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:54:21.686894  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.976562
I1023 17:54:21.686954  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0605703 (* 1 = 0.0605703 loss)
I1023 17:54:21.866627  5058 solver.cpp:218] Iteration 18800 (4.94836 iter/s, 20.2087s/100 iters), loss = 0.051247
I1023 17:54:21.866663  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0512482 (* 1 = 0.0512482 loss)
I1023 17:54:21.866672  5058 sgd_solver.cpp:105] Iteration 18800, lr = 0.001
I1023 17:54:39.763964  5058 solver.cpp:218] Iteration 18900 (5.58745 iter/s, 17.8973s/100 iters), loss = 0.00239309
I1023 17:54:39.763995  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00239435 (* 1 = 0.00239435 loss)
I1023 17:54:39.764003  5058 sgd_solver.cpp:105] Iteration 18900, lr = 0.001
I1023 17:54:57.491032  5058 solver.cpp:330] Iteration 19000, Testing net (#0)
I1023 17:54:58.809995  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:54:59.791378  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.976562
I1023 17:54:59.791437  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0589389 (* 1 = 0.0589389 loss)
I1023 17:54:59.972128  5058 solver.cpp:218] Iteration 19000 (4.94851 iter/s, 20.2081s/100 iters), loss = 0.00937494
I1023 17:54:59.972160  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00937622 (* 1 = 0.00937622 loss)
I1023 17:54:59.972167  5058 sgd_solver.cpp:105] Iteration 19000, lr = 0.001
I1023 17:55:17.876783  5058 solver.cpp:218] Iteration 19100 (5.58516 iter/s, 17.9046s/100 iters), loss = 0.00198923
I1023 17:55:17.876814  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00199051 (* 1 = 0.00199051 loss)
I1023 17:55:17.876821  5058 sgd_solver.cpp:105] Iteration 19100, lr = 0.001
I1023 17:55:18.798817  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:55:35.605681  5058 solver.cpp:330] Iteration 19200, Testing net (#0)
I1023 17:55:36.924204  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:55:37.908244  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.976562
I1023 17:55:37.908300  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0610309 (* 1 = 0.0610309 loss)
I1023 17:55:38.088527  5058 solver.cpp:218] Iteration 19200 (4.94764 iter/s, 20.2117s/100 iters), loss = 0.00256859
I1023 17:55:38.088559  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00256985 (* 1 = 0.00256985 loss)
I1023 17:55:38.088567  5058 sgd_solver.cpp:105] Iteration 19200, lr = 0.001
I1023 17:55:55.985741  5058 solver.cpp:218] Iteration 19300 (5.58749 iter/s, 17.8971s/100 iters), loss = 0.0277991
I1023 17:55:55.985772  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0278003 (* 1 = 0.0278003 loss)
I1023 17:55:55.985780  5058 sgd_solver.cpp:105] Iteration 19300, lr = 0.001
I1023 17:56:13.708948  5058 solver.cpp:330] Iteration 19400, Testing net (#0)
I1023 17:56:15.026854  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:56:16.010852  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.980469
I1023 17:56:16.010911  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.067532 (* 1 = 0.067532 loss)
I1023 17:56:16.191509  5058 solver.cpp:218] Iteration 19400 (4.9491 iter/s, 20.2057s/100 iters), loss = 0.00192623
I1023 17:56:16.191541  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00192745 (* 1 = 0.00192745 loss)
I1023 17:56:16.191547  5058 sgd_solver.cpp:105] Iteration 19400, lr = 0.001
I1023 17:56:24.631453  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:56:34.101985  5058 solver.cpp:218] Iteration 19500 (5.58335 iter/s, 17.9104s/100 iters), loss = 0.177119
I1023 17:56:34.102018  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17712 (* 1 = 0.17712 loss)
I1023 17:56:34.102025  5058 sgd_solver.cpp:105] Iteration 19500, lr = 0.001
I1023 17:56:51.817462  5058 solver.cpp:330] Iteration 19600, Testing net (#0)
I1023 17:56:53.133961  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:56:54.119153  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.976562
I1023 17:56:54.119216  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0575767 (* 1 = 0.0575767 loss)
I1023 17:56:54.299765  5058 solver.cpp:218] Iteration 19600 (4.95106 iter/s, 20.1977s/100 iters), loss = 0.0194863
I1023 17:56:54.299796  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0194875 (* 1 = 0.0194875 loss)
I1023 17:56:54.299803  5058 sgd_solver.cpp:105] Iteration 19600, lr = 0.001
I1023 17:57:12.201848  5058 solver.cpp:218] Iteration 19700 (5.58597 iter/s, 17.902s/100 iters), loss = 0.00289999
I1023 17:57:12.201879  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00290128 (* 1 = 0.00290128 loss)
I1023 17:57:12.201884  5058 sgd_solver.cpp:105] Iteration 19700, lr = 0.001
I1023 17:57:27.983006  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:57:29.933396  5058 solver.cpp:330] Iteration 19800, Testing net (#0)
I1023 17:57:31.216912  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:57:32.235479  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.972656
I1023 17:57:32.235543  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0798771 (* 1 = 0.0798771 loss)
I1023 17:57:32.415181  5058 solver.cpp:218] Iteration 19800 (4.94725 iter/s, 20.2133s/100 iters), loss = 0.00948285
I1023 17:57:32.415212  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00948415 (* 1 = 0.00948415 loss)
I1023 17:57:32.415220  5058 sgd_solver.cpp:105] Iteration 19800, lr = 0.001
I1023 17:57:50.308087  5058 solver.cpp:218] Iteration 19900 (5.58883 iter/s, 17.8928s/100 iters), loss = 0.00388975
I1023 17:57:50.308118  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00389105 (* 1 = 0.00389105 loss)
I1023 17:57:50.308125  5058 sgd_solver.cpp:105] Iteration 19900, lr = 0.001
I1023 17:58:08.025809  5058 solver.cpp:330] Iteration 20000, Testing net (#0)
I1023 17:58:09.307862  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:58:10.326902  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.976562
I1023 17:58:10.326957  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0609222 (* 1 = 0.0609222 loss)
I1023 17:58:10.507565  5058 solver.cpp:218] Iteration 20000 (4.95064 iter/s, 20.1994s/100 iters), loss = 0.0228832
I1023 17:58:10.507596  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0228845 (* 1 = 0.0228845 loss)
I1023 17:58:10.507602  5058 sgd_solver.cpp:46] MultiStep Status: Iteration 20000, step = 2
I1023 17:58:10.507606  5058 sgd_solver.cpp:105] Iteration 20000, lr = 0.0001
I1023 17:58:28.407099  5058 solver.cpp:218] Iteration 20100 (5.58676 iter/s, 17.8995s/100 iters), loss = 0.0188082
I1023 17:58:28.407132  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0188095 (* 1 = 0.0188095 loss)
I1023 17:58:28.407140  5058 sgd_solver.cpp:105] Iteration 20100, lr = 0.0001
I1023 17:58:33.625277  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:58:46.135329  5058 solver.cpp:330] Iteration 20200, Testing net (#0)
I1023 17:58:47.416657  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:58:48.436539  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.976562
I1023 17:58:48.436600  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.063831 (* 1 = 0.063831 loss)
I1023 17:58:48.616845  5058 solver.cpp:218] Iteration 20200 (4.94813 iter/s, 20.2097s/100 iters), loss = 0.0054476
I1023 17:58:48.616878  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00544884 (* 1 = 0.00544884 loss)
I1023 17:58:48.616885  5058 sgd_solver.cpp:105] Iteration 20200, lr = 0.0001
I1023 17:59:06.519773  5058 solver.cpp:218] Iteration 20300 (5.5857 iter/s, 17.9028s/100 iters), loss = 0.0140146
I1023 17:59:06.519804  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0140158 (* 1 = 0.0140158 loss)
I1023 17:59:06.519810  5058 sgd_solver.cpp:105] Iteration 20300, lr = 0.0001
I1023 17:59:24.245621  5058 solver.cpp:330] Iteration 20400, Testing net (#0)
I1023 17:59:25.526716  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:59:26.547250  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.978516
I1023 17:59:26.547310  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0626022 (* 1 = 0.0626022 loss)
I1023 17:59:26.727641  5058 solver.cpp:218] Iteration 20400 (4.94859 iter/s, 20.2078s/100 iters), loss = 0.00195761
I1023 17:59:26.727674  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00195883 (* 1 = 0.00195883 loss)
I1023 17:59:26.727681  5058 sgd_solver.cpp:105] Iteration 20400, lr = 0.0001
I1023 17:59:39.283824  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 17:59:44.631865  5058 solver.cpp:218] Iteration 20500 (5.5853 iter/s, 17.9041s/100 iters), loss = 0.0451595
I1023 17:59:44.631896  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0451608 (* 1 = 0.0451608 loss)
I1023 17:59:44.631902  5058 sgd_solver.cpp:105] Iteration 20500, lr = 0.0001
I1023 18:00:02.350318  5058 solver.cpp:330] Iteration 20600, Testing net (#0)
I1023 18:00:03.597254  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:00:04.650916  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1023 18:00:04.650979  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0644667 (* 1 = 0.0644667 loss)
I1023 18:00:04.831174  5058 solver.cpp:218] Iteration 20600 (4.95068 iter/s, 20.1992s/100 iters), loss = 0.00893799
I1023 18:00:04.831208  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00893921 (* 1 = 0.00893921 loss)
I1023 18:00:04.831215  5058 sgd_solver.cpp:105] Iteration 20600, lr = 0.0001
I1023 18:00:22.731444  5058 solver.cpp:218] Iteration 20700 (5.58653 iter/s, 17.9002s/100 iters), loss = 0.0104641
I1023 18:00:22.731480  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104653 (* 1 = 0.0104653 loss)
I1023 18:00:22.731487  5058 sgd_solver.cpp:105] Iteration 20700, lr = 0.0001
I1023 18:00:40.455518  5058 solver.cpp:330] Iteration 20800, Testing net (#0)
I1023 18:00:41.701746  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:00:42.757444  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.976562
I1023 18:00:42.757503  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0652083 (* 1 = 0.0652083 loss)
I1023 18:00:42.938097  5058 solver.cpp:218] Iteration 20800 (4.94889 iter/s, 20.2066s/100 iters), loss = 0.00550221
I1023 18:00:42.938129  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00550345 (* 1 = 0.00550345 loss)
I1023 18:00:42.938136  5058 sgd_solver.cpp:105] Iteration 20800, lr = 0.0001
I1023 18:00:45.111152  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:01:00.845419  5058 solver.cpp:218] Iteration 20900 (5.58433 iter/s, 17.9072s/100 iters), loss = 0.0220738
I1023 18:01:00.845453  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.022075 (* 1 = 0.022075 loss)
I1023 18:01:00.845459  5058 sgd_solver.cpp:105] Iteration 20900, lr = 0.0001
I1023 18:01:18.570063  5058 solver.cpp:330] Iteration 21000, Testing net (#0)
I1023 18:01:19.814631  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:01:20.870555  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.974609
I1023 18:01:20.870615  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0648288 (* 1 = 0.0648288 loss)
I1023 18:01:21.050765  5058 solver.cpp:218] Iteration 21000 (4.94921 iter/s, 20.2053s/100 iters), loss = 0.00285485
I1023 18:01:21.050801  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00285605 (* 1 = 0.00285605 loss)
I1023 18:01:21.050807  5058 sgd_solver.cpp:105] Iteration 21000, lr = 0.0001
I1023 18:01:38.945919  5058 solver.cpp:218] Iteration 21100 (5.58813 iter/s, 17.8951s/100 iters), loss = 0.00213456
I1023 18:01:38.945952  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00213577 (* 1 = 0.00213577 loss)
I1023 18:01:38.945960  5058 sgd_solver.cpp:105] Iteration 21100, lr = 0.0001
I1023 18:01:48.456769  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:01:56.663126  5058 solver.cpp:330] Iteration 21200, Testing net (#0)
I1023 18:01:57.906860  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:01:58.964298  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.978516
I1023 18:01:58.964355  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0633417 (* 1 = 0.0633417 loss)
I1023 18:01:59.145140  5058 solver.cpp:218] Iteration 21200 (4.95071 iter/s, 20.1991s/100 iters), loss = 0.0240871
I1023 18:01:59.145174  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0240883 (* 1 = 0.0240883 loss)
I1023 18:01:59.145179  5058 sgd_solver.cpp:105] Iteration 21200, lr = 0.0001
I1023 18:02:17.046561  5058 solver.cpp:218] Iteration 21300 (5.58617 iter/s, 17.9013s/100 iters), loss = 0.0133684
I1023 18:02:17.046593  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0133696 (* 1 = 0.0133696 loss)
I1023 18:02:17.046600  5058 sgd_solver.cpp:105] Iteration 21300, lr = 0.0001
I1023 18:02:34.774338  5058 solver.cpp:330] Iteration 21400, Testing net (#0)
I1023 18:02:35.985215  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:02:37.073802  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.980469
I1023 18:02:37.073863  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0602424 (* 1 = 0.0602424 loss)
I1023 18:02:37.254724  5058 solver.cpp:218] Iteration 21400 (4.94852 iter/s, 20.2081s/100 iters), loss = 0.00180623
I1023 18:02:37.254755  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00180745 (* 1 = 0.00180745 loss)
I1023 18:02:37.254761  5058 sgd_solver.cpp:105] Iteration 21400, lr = 0.0001
I1023 18:02:54.106333  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:02:55.158860  5058 solver.cpp:218] Iteration 21500 (5.58533 iter/s, 17.9041s/100 iters), loss = 0.039103
I1023 18:02:55.158891  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0391042 (* 1 = 0.0391042 loss)
I1023 18:02:55.158907  5058 sgd_solver.cpp:105] Iteration 21500, lr = 0.0001
I1023 18:03:12.884223  5058 solver.cpp:330] Iteration 21600, Testing net (#0)
I1023 18:03:14.094221  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:03:15.184957  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.982422
I1023 18:03:15.185017  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0593993 (* 1 = 0.0593993 loss)
I1023 18:03:15.365252  5058 solver.cpp:218] Iteration 21600 (4.94895 iter/s, 20.2063s/100 iters), loss = 0.0406819
I1023 18:03:15.365286  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0406831 (* 1 = 0.0406831 loss)
I1023 18:03:15.365293  5058 sgd_solver.cpp:105] Iteration 21600, lr = 0.0001
I1023 18:03:33.262104  5058 solver.cpp:218] Iteration 21700 (5.5876 iter/s, 17.8968s/100 iters), loss = 0.00221858
I1023 18:03:33.262136  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00221975 (* 1 = 0.00221975 loss)
I1023 18:03:33.262142  5058 sgd_solver.cpp:105] Iteration 21700, lr = 0.0001
I1023 18:03:50.982070  5058 solver.cpp:330] Iteration 21800, Testing net (#0)
I1023 18:03:52.191102  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:03:53.282856  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.982422
I1023 18:03:53.282920  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0585896 (* 1 = 0.0585896 loss)
I1023 18:03:53.463258  5058 solver.cpp:218] Iteration 21800 (4.95023 iter/s, 20.2011s/100 iters), loss = 0.00349842
I1023 18:03:53.463291  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00349958 (* 1 = 0.00349958 loss)
I1023 18:03:53.463299  5058 sgd_solver.cpp:105] Iteration 21800, lr = 0.0001
I1023 18:03:59.755568  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:04:11.364289  5058 solver.cpp:218] Iteration 21900 (5.5863 iter/s, 17.901s/100 iters), loss = 0.0347996
I1023 18:04:11.364320  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0348007 (* 1 = 0.0348007 loss)
I1023 18:04:11.364326  5058 sgd_solver.cpp:105] Iteration 21900, lr = 0.0001
I1023 18:04:29.089745  5058 solver.cpp:330] Iteration 22000, Testing net (#0)
I1023 18:04:30.298513  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:04:31.390031  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.984375
I1023 18:04:31.390094  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0590173 (* 1 = 0.0590173 loss)
I1023 18:04:31.570672  5058 solver.cpp:218] Iteration 22000 (4.94895 iter/s, 20.2063s/100 iters), loss = 0.00254295
I1023 18:04:31.570705  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00254414 (* 1 = 0.00254414 loss)
I1023 18:04:31.570713  5058 sgd_solver.cpp:105] Iteration 22000, lr = 0.0001
I1023 18:04:49.471562  5058 solver.cpp:218] Iteration 22100 (5.58634 iter/s, 17.9008s/100 iters), loss = 0.0922545
I1023 18:04:49.471593  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0922557 (* 1 = 0.0922557 loss)
I1023 18:04:49.471601  5058 sgd_solver.cpp:105] Iteration 22100, lr = 0.0001
I1023 18:05:03.282588  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:05:07.202342  5058 solver.cpp:330] Iteration 22200, Testing net (#0)
I1023 18:05:08.378522  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:05:09.504796  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.980469
I1023 18:05:09.504861  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.060244 (* 1 = 0.060244 loss)
I1023 18:05:09.684514  5058 solver.cpp:218] Iteration 22200 (4.94734 iter/s, 20.2129s/100 iters), loss = 0.129989
I1023 18:05:09.684546  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12999 (* 1 = 0.12999 loss)
I1023 18:05:09.684553  5058 sgd_solver.cpp:105] Iteration 22200, lr = 0.0001
I1023 18:05:27.575551  5058 solver.cpp:218] Iteration 22300 (5.58941 iter/s, 17.891s/100 iters), loss = 0.00703792
I1023 18:05:27.575584  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00703914 (* 1 = 0.00703914 loss)
I1023 18:05:27.575592  5058 sgd_solver.cpp:105] Iteration 22300, lr = 0.0001
I1023 18:05:45.295353  5058 solver.cpp:330] Iteration 22400, Testing net (#0)
I1023 18:05:46.469033  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:05:47.596364  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.980469
I1023 18:05:47.596423  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0588058 (* 1 = 0.0588058 loss)
I1023 18:05:47.776720  5058 solver.cpp:218] Iteration 22400 (4.95023 iter/s, 20.2011s/100 iters), loss = 0.00119838
I1023 18:05:47.776777  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00119957 (* 1 = 0.00119957 loss)
I1023 18:05:47.776789  5058 sgd_solver.cpp:105] Iteration 22400, lr = 0.0001
I1023 18:06:05.682346  5058 solver.cpp:218] Iteration 22500 (5.58486 iter/s, 17.9055s/100 iters), loss = 0.00649313
I1023 18:06:05.682380  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00649433 (* 1 = 0.00649433 loss)
I1023 18:06:05.682387  5058 sgd_solver.cpp:105] Iteration 22500, lr = 0.0001
I1023 18:06:08.931565  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:06:23.412744  5058 solver.cpp:330] Iteration 22600, Testing net (#0)
I1023 18:06:24.586017  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:06:25.714592  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.984375
I1023 18:06:25.714653  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0588675 (* 1 = 0.0588675 loss)
I1023 18:06:25.894935  5058 solver.cpp:218] Iteration 22600 (4.94743 iter/s, 20.2125s/100 iters), loss = 0.0757595
I1023 18:06:25.894965  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0757607 (* 1 = 0.0757607 loss)
I1023 18:06:25.894973  5058 sgd_solver.cpp:105] Iteration 22600, lr = 0.0001
I1023 18:06:43.798933  5058 solver.cpp:218] Iteration 22700 (5.58537 iter/s, 17.9039s/100 iters), loss = 0.0330496
I1023 18:06:43.798965  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0330508 (* 1 = 0.0330508 loss)
I1023 18:06:43.798972  5058 sgd_solver.cpp:105] Iteration 22700, lr = 0.0001
I1023 18:07:01.526911  5058 solver.cpp:330] Iteration 22800, Testing net (#0)
I1023 18:07:02.700750  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:07:03.828234  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.984375
I1023 18:07:03.828299  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.058019 (* 1 = 0.058019 loss)
I1023 18:07:04.008664  5058 solver.cpp:218] Iteration 22800 (4.94813 iter/s, 20.2097s/100 iters), loss = 0.0079974
I1023 18:07:04.008695  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00799859 (* 1 = 0.00799859 loss)
I1023 18:07:04.008702  5058 sgd_solver.cpp:105] Iteration 22800, lr = 0.0001
I1023 18:07:14.595856  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:07:21.914357  5058 solver.cpp:218] Iteration 22900 (5.58484 iter/s, 17.9056s/100 iters), loss = 0.00627613
I1023 18:07:21.914391  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00627732 (* 1 = 0.00627732 loss)
I1023 18:07:21.914398  5058 sgd_solver.cpp:105] Iteration 22900, lr = 0.0001
I1023 18:07:39.628442  5058 solver.cpp:330] Iteration 23000, Testing net (#0)
I1023 18:07:40.768045  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:07:41.930291  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.986328
I1023 18:07:41.930347  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0565417 (* 1 = 0.0565417 loss)
I1023 18:07:42.110630  5058 solver.cpp:218] Iteration 23000 (4.95143 iter/s, 20.1962s/100 iters), loss = 0.137779
I1023 18:07:42.110666  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13778 (* 1 = 0.13778 loss)
I1023 18:07:42.110673  5058 sgd_solver.cpp:105] Iteration 23000, lr = 0.0001
I1023 18:08:00.008853  5058 solver.cpp:218] Iteration 23100 (5.58717 iter/s, 17.8981s/100 iters), loss = 0.00526423
I1023 18:08:00.008885  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00526545 (* 1 = 0.00526545 loss)
I1023 18:08:00.008893  5058 sgd_solver.cpp:105] Iteration 23100, lr = 0.0001
I1023 18:08:17.732342  5058 solver.cpp:330] Iteration 23200, Testing net (#0)
I1023 18:08:18.871057  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:08:20.033772  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.984375
I1023 18:08:20.033839  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0575191 (* 1 = 0.0575191 loss)
I1023 18:08:20.213971  5058 solver.cpp:218] Iteration 23200 (4.94926 iter/s, 20.205s/100 iters), loss = 0.0117986
I1023 18:08:20.214004  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117999 (* 1 = 0.0117999 loss)
I1023 18:08:20.214011  5058 sgd_solver.cpp:105] Iteration 23200, lr = 0.0001
I1023 18:08:20.239513  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:08:38.117527  5058 solver.cpp:218] Iteration 23300 (5.58551 iter/s, 17.9035s/100 iters), loss = 0.0068085
I1023 18:08:38.117558  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00680971 (* 1 = 0.00680971 loss)
I1023 18:08:38.117563  5058 sgd_solver.cpp:105] Iteration 23300, lr = 0.0001
I1023 18:08:55.842120  5058 solver.cpp:330] Iteration 23400, Testing net (#0)
I1023 18:08:56.979248  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:08:58.143991  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.984375
I1023 18:08:58.144050  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0574708 (* 1 = 0.0574708 loss)
I1023 18:08:58.324380  5058 solver.cpp:218] Iteration 23400 (4.94883 iter/s, 20.2068s/100 iters), loss = 0.00652237
I1023 18:08:58.324412  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00652357 (* 1 = 0.00652357 loss)
I1023 18:08:58.324420  5058 sgd_solver.cpp:105] Iteration 23400, lr = 0.0001
I1023 18:09:16.218971  5058 solver.cpp:218] Iteration 23500 (5.5883 iter/s, 17.8945s/100 iters), loss = 0.0261964
I1023 18:09:16.219003  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0261975 (* 1 = 0.0261975 loss)
I1023 18:09:16.219010  5058 sgd_solver.cpp:105] Iteration 23500, lr = 0.0001
I1023 18:09:23.760989  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:09:33.938285  5058 solver.cpp:330] Iteration 23600, Testing net (#0)
I1023 18:09:35.075759  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:09:36.240741  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.980469
I1023 18:09:36.240802  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0589869 (* 1 = 0.0589869 loss)
I1023 18:09:36.421319  5058 solver.cpp:218] Iteration 23600 (4.94994 iter/s, 20.2023s/100 iters), loss = 0.016433
I1023 18:09:36.421350  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0164342 (* 1 = 0.0164342 loss)
I1023 18:09:36.421356  5058 sgd_solver.cpp:105] Iteration 23600, lr = 0.0001
I1023 18:09:54.322777  5058 solver.cpp:218] Iteration 23700 (5.58616 iter/s, 17.9014s/100 iters), loss = 0.0161014
I1023 18:09:54.322818  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0161026 (* 1 = 0.0161026 loss)
I1023 18:09:54.322824  5058 sgd_solver.cpp:105] Iteration 23700, lr = 0.0001
I1023 18:10:12.048698  5058 solver.cpp:330] Iteration 23800, Testing net (#0)
I1023 18:10:13.152791  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:10:14.350353  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.982422
I1023 18:10:14.350409  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0618506 (* 1 = 0.0618506 loss)
I1023 18:10:14.531117  5058 solver.cpp:218] Iteration 23800 (4.94847 iter/s, 20.2083s/100 iters), loss = 0.0992508
I1023 18:10:14.531149  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.099252 (* 1 = 0.099252 loss)
I1023 18:10:14.531155  5058 sgd_solver.cpp:105] Iteration 23800, lr = 0.0001
I1023 18:10:29.414113  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:10:32.438264  5058 solver.cpp:218] Iteration 23900 (5.58439 iter/s, 17.9071s/100 iters), loss = 0.187096
I1023 18:10:32.438297  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187098 (* 1 = 0.187098 loss)
I1023 18:10:32.438304  5058 sgd_solver.cpp:105] Iteration 23900, lr = 0.0001
I1023 18:10:50.166152  5058 solver.cpp:330] Iteration 24000, Testing net (#0)
I1023 18:10:51.269006  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:10:52.467169  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.978516
I1023 18:10:52.467228  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0576298 (* 1 = 0.0576298 loss)
I1023 18:10:52.647671  5058 solver.cpp:218] Iteration 24000 (4.94821 iter/s, 20.2093s/100 iters), loss = 0.00288207
I1023 18:10:52.647704  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00288325 (* 1 = 0.00288325 loss)
I1023 18:10:52.647711  5058 sgd_solver.cpp:105] Iteration 24000, lr = 0.0001
I1023 18:11:10.547751  5058 solver.cpp:218] Iteration 24100 (5.58659 iter/s, 17.9s/100 iters), loss = 0.00114975
I1023 18:11:10.547783  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00115096 (* 1 = 0.00115096 loss)
I1023 18:11:10.547790  5058 sgd_solver.cpp:105] Iteration 24100, lr = 0.0001
I1023 18:11:28.268146  5058 solver.cpp:330] Iteration 24200, Testing net (#0)
I1023 18:11:29.370218  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:11:30.570246  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.982422
I1023 18:11:30.570304  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0568167 (* 1 = 0.0568167 loss)
I1023 18:11:30.750735  5058 solver.cpp:218] Iteration 24200 (4.94978 iter/s, 20.2029s/100 iters), loss = 0.00214081
I1023 18:11:30.750768  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00214203 (* 1 = 0.00214203 loss)
I1023 18:11:30.750775  5058 sgd_solver.cpp:105] Iteration 24200, lr = 0.0001
I1023 18:11:35.074234  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:11:48.652568  5058 solver.cpp:218] Iteration 24300 (5.58604 iter/s, 17.9018s/100 iters), loss = 0.0654835
I1023 18:11:48.652601  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0654846 (* 1 = 0.0654846 loss)
I1023 18:11:48.652608  5058 sgd_solver.cpp:105] Iteration 24300, lr = 0.0001
I1023 18:12:06.380820  5058 solver.cpp:330] Iteration 24400, Testing net (#0)
I1023 18:12:07.482414  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:12:08.682232  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.980469
I1023 18:12:08.682291  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0559116 (* 1 = 0.0559116 loss)
I1023 18:12:08.862853  5058 solver.cpp:218] Iteration 24400 (4.948 iter/s, 20.2102s/100 iters), loss = 0.0130584
I1023 18:12:08.862886  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130596 (* 1 = 0.0130596 loss)
I1023 18:12:08.862893  5058 sgd_solver.cpp:105] Iteration 24400, lr = 0.0001
I1023 18:12:26.762321  5058 solver.cpp:218] Iteration 24500 (5.58678 iter/s, 17.8994s/100 iters), loss = 0.00222027
I1023 18:12:26.762352  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00222144 (* 1 = 0.00222144 loss)
I1023 18:12:26.762359  5058 sgd_solver.cpp:105] Iteration 24500, lr = 0.0001
I1023 18:12:38.428779  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:12:44.496078  5058 solver.cpp:330] Iteration 24600, Testing net (#0)
I1023 18:12:45.563810  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:12:46.797669  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.978516
I1023 18:12:46.797729  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0577962 (* 1 = 0.0577962 loss)
I1023 18:12:46.978271  5058 solver.cpp:218] Iteration 24600 (4.94661 iter/s, 20.2159s/100 iters), loss = 0.0383021
I1023 18:12:46.978302  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0383033 (* 1 = 0.0383033 loss)
I1023 18:12:46.978308  5058 sgd_solver.cpp:105] Iteration 24600, lr = 0.0001
I1023 18:13:04.867808  5058 solver.cpp:218] Iteration 24700 (5.58988 iter/s, 17.8895s/100 iters), loss = 0.00227737
I1023 18:13:04.867839  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00227851 (* 1 = 0.00227851 loss)
I1023 18:13:04.867846  5058 sgd_solver.cpp:105] Iteration 24700, lr = 0.0001
I1023 18:13:22.586495  5058 solver.cpp:330] Iteration 24800, Testing net (#0)
I1023 18:13:23.653195  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:13:24.887154  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.980469
I1023 18:13:24.887200  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0574577 (* 1 = 0.0574577 loss)
I1023 18:13:25.067720  5058 solver.cpp:218] Iteration 24800 (4.95054 iter/s, 20.1998s/100 iters), loss = 0.265783
I1023 18:13:25.067757  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265785 (* 1 = 0.265785 loss)
I1023 18:13:25.067764  5058 sgd_solver.cpp:105] Iteration 24800, lr = 0.0001
I1023 18:13:42.967641  5058 solver.cpp:218] Iteration 24900 (5.58664 iter/s, 17.8998s/100 iters), loss = 0.0228417
I1023 18:13:42.967672  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0228428 (* 1 = 0.0228428 loss)
I1023 18:13:42.967679  5058 sgd_solver.cpp:105] Iteration 24900, lr = 0.0001
I1023 18:13:44.245663  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:14:00.698431  5058 solver.cpp:330] Iteration 25000, Testing net (#0)
I1023 18:14:01.764153  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:14:02.999819  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.980469
I1023 18:14:02.999877  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0584531 (* 1 = 0.0584531 loss)
I1023 18:14:03.180299  5058 solver.cpp:218] Iteration 25000 (4.94741 iter/s, 20.2126s/100 iters), loss = 0.0443361
I1023 18:14:03.180330  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0443373 (* 1 = 0.0443373 loss)
I1023 18:14:03.180335  5058 sgd_solver.cpp:105] Iteration 25000, lr = 0.0001
I1023 18:14:21.084311  5058 solver.cpp:218] Iteration 25100 (5.58536 iter/s, 17.9039s/100 iters), loss = 0.00239155
I1023 18:14:21.084342  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00239271 (* 1 = 0.00239271 loss)
I1023 18:14:21.084349  5058 sgd_solver.cpp:105] Iteration 25100, lr = 0.0001
I1023 18:14:38.810195  5058 solver.cpp:330] Iteration 25200, Testing net (#0)
I1023 18:14:39.874819  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:14:41.111584  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.978516
I1023 18:14:41.111646  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0597211 (* 1 = 0.0597211 loss)
I1023 18:14:41.291762  5058 solver.cpp:218] Iteration 25200 (4.94869 iter/s, 20.2074s/100 iters), loss = 0.00219967
I1023 18:14:41.291793  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0022008 (* 1 = 0.0022008 loss)
I1023 18:14:41.291800  5058 sgd_solver.cpp:105] Iteration 25200, lr = 0.0001
I1023 18:14:49.910907  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:14:59.200687  5058 solver.cpp:218] Iteration 25300 (5.58383 iter/s, 17.9088s/100 iters), loss = 0.0136848
I1023 18:14:59.200721  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136859 (* 1 = 0.0136859 loss)
I1023 18:14:59.200727  5058 sgd_solver.cpp:105] Iteration 25300, lr = 0.0001
I1023 18:15:16.913357  5058 solver.cpp:330] Iteration 25400, Testing net (#0)
I1023 18:15:17.944185  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:15:19.214212  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.980469
I1023 18:15:19.214274  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0566151 (* 1 = 0.0566151 loss)
I1023 18:15:19.394656  5058 solver.cpp:218] Iteration 25400 (4.95199 iter/s, 20.1939s/100 iters), loss = 0.037533
I1023 18:15:19.394688  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0375341 (* 1 = 0.0375341 loss)
I1023 18:15:19.394695  5058 sgd_solver.cpp:105] Iteration 25400, lr = 0.0001
I1023 18:15:37.293828  5058 solver.cpp:218] Iteration 25500 (5.58687 iter/s, 17.8991s/100 iters), loss = 0.0398303
I1023 18:15:37.293859  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0398314 (* 1 = 0.0398314 loss)
I1023 18:15:37.293865  5058 sgd_solver.cpp:105] Iteration 25500, lr = 0.0001
I1023 18:15:53.252910  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:15:55.022297  5058 solver.cpp:330] Iteration 25600, Testing net (#0)
I1023 18:15:56.054426  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:15:57.324873  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.980469
I1023 18:15:57.324929  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0562792 (* 1 = 0.0562792 loss)
I1023 18:15:57.505468  5058 solver.cpp:218] Iteration 25600 (4.94766 iter/s, 20.2116s/100 iters), loss = 0.00659002
I1023 18:15:57.505501  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00659113 (* 1 = 0.00659113 loss)
I1023 18:15:57.505508  5058 sgd_solver.cpp:105] Iteration 25600, lr = 0.0001
I1023 18:16:15.404796  5058 solver.cpp:218] Iteration 25700 (5.58683 iter/s, 17.8992s/100 iters), loss = 0.00517794
I1023 18:16:15.404827  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00517905 (* 1 = 0.00517905 loss)
I1023 18:16:15.404834  5058 sgd_solver.cpp:105] Iteration 25700, lr = 0.0001
I1023 18:16:33.130568  5058 solver.cpp:330] Iteration 25800, Testing net (#0)
I1023 18:16:34.160554  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:16:35.431658  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.982422
I1023 18:16:35.431720  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0547173 (* 1 = 0.0547173 loss)
I1023 18:16:35.612340  5058 solver.cpp:218] Iteration 25800 (4.94867 iter/s, 20.2075s/100 iters), loss = 0.152886
I1023 18:16:35.612372  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152887 (* 1 = 0.152887 loss)
I1023 18:16:35.612378  5058 sgd_solver.cpp:105] Iteration 25800, lr = 0.0001
I1023 18:16:53.506685  5058 solver.cpp:218] Iteration 25900 (5.58838 iter/s, 17.8943s/100 iters), loss = 0.000768757
I1023 18:16:53.506716  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000769809 (* 1 = 0.000769809 loss)
I1023 18:16:53.506722  5058 sgd_solver.cpp:105] Iteration 25900, lr = 0.0001
I1023 18:16:58.902696  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:17:11.227537  5058 solver.cpp:330] Iteration 26000, Testing net (#0)
I1023 18:17:12.256882  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:17:13.528551  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.978516
I1023 18:17:13.528610  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0574281 (* 1 = 0.0574281 loss)
I1023 18:17:13.709260  5058 solver.cpp:218] Iteration 26000 (4.94988 iter/s, 20.2025s/100 iters), loss = 0.00416464
I1023 18:17:13.709290  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00416568 (* 1 = 0.00416568 loss)
I1023 18:17:13.709297  5058 sgd_solver.cpp:105] Iteration 26000, lr = 0.0001
I1023 18:17:31.610756  5058 solver.cpp:218] Iteration 26100 (5.58615 iter/s, 17.9014s/100 iters), loss = 0.000853239
I1023 18:17:31.610788  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000854269 (* 1 = 0.000854269 loss)
I1023 18:17:31.610795  5058 sgd_solver.cpp:105] Iteration 26100, lr = 0.0001
I1023 18:17:49.337234  5058 solver.cpp:330] Iteration 26200, Testing net (#0)
I1023 18:17:50.333202  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:17:51.637851  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.980469
I1023 18:17:51.637905  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0568228 (* 1 = 0.0568228 loss)
I1023 18:17:51.818344  5058 solver.cpp:218] Iteration 26200 (4.94866 iter/s, 20.2075s/100 iters), loss = 0.0156327
I1023 18:17:51.818374  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156338 (* 1 = 0.0156338 loss)
I1023 18:17:51.818395  5058 sgd_solver.cpp:105] Iteration 26200, lr = 0.0001
I1023 18:18:04.735121  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:18:09.729648  5058 solver.cpp:218] Iteration 26300 (5.58309 iter/s, 17.9112s/100 iters), loss = 0.00191362
I1023 18:18:09.729681  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00191472 (* 1 = 0.00191472 loss)
I1023 18:18:09.729687  5058 sgd_solver.cpp:105] Iteration 26300, lr = 0.0001
I1023 18:18:27.450979  5058 solver.cpp:330] Iteration 26400, Testing net (#0)
I1023 18:18:28.445922  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:18:29.753196  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.982422
I1023 18:18:29.753254  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0587593 (* 1 = 0.0587593 loss)
I1023 18:18:29.933485  5058 solver.cpp:218] Iteration 26400 (4.94958 iter/s, 20.2038s/100 iters), loss = 0.0159552
I1023 18:18:29.933516  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0159563 (* 1 = 0.0159563 loss)
I1023 18:18:29.933523  5058 sgd_solver.cpp:105] Iteration 26400, lr = 0.0001
I1023 18:18:47.831593  5058 solver.cpp:218] Iteration 26500 (5.58721 iter/s, 17.898s/100 iters), loss = 0.00366478
I1023 18:18:47.831624  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00366587 (* 1 = 0.00366587 loss)
I1023 18:18:47.831630  5058 sgd_solver.cpp:105] Iteration 26500, lr = 0.0001
I1023 18:19:05.556269  5058 solver.cpp:330] Iteration 26600, Testing net (#0)
I1023 18:19:06.549989  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:19:07.857267  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.980469
I1023 18:19:07.857319  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0585755 (* 1 = 0.0585755 loss)
I1023 18:19:08.037776  5058 solver.cpp:218] Iteration 26600 (4.949 iter/s, 20.2061s/100 iters), loss = 0.00238844
I1023 18:19:08.037811  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00238952 (* 1 = 0.00238952 loss)
I1023 18:19:08.037817  5058 sgd_solver.cpp:105] Iteration 26600, lr = 0.0001
I1023 18:19:10.389192  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:19:25.941609  5058 solver.cpp:218] Iteration 26700 (5.58542 iter/s, 17.9038s/100 iters), loss = 0.0330671
I1023 18:19:25.941640  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0330682 (* 1 = 0.0330682 loss)
I1023 18:19:25.941646  5058 sgd_solver.cpp:105] Iteration 26700, lr = 0.0001
I1023 18:19:43.666422  5058 solver.cpp:330] Iteration 26800, Testing net (#0)
I1023 18:19:44.659883  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:19:45.967489  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.980469
I1023 18:19:45.967550  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0560667 (* 1 = 0.0560667 loss)
I1023 18:19:46.148161  5058 solver.cpp:218] Iteration 26800 (4.94891 iter/s, 20.2065s/100 iters), loss = 0.0116047
I1023 18:19:46.148193  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116058 (* 1 = 0.0116058 loss)
I1023 18:19:46.148200  5058 sgd_solver.cpp:105] Iteration 26800, lr = 0.0001
I1023 18:20:04.048589  5058 solver.cpp:218] Iteration 26900 (5.58648 iter/s, 17.9003s/100 iters), loss = 0.000785762
I1023 18:20:04.048620  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00078688 (* 1 = 0.00078688 loss)
I1023 18:20:04.048627  5058 sgd_solver.cpp:105] Iteration 26900, lr = 0.0001
I1023 18:20:13.745851  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:20:21.776584  5058 solver.cpp:330] Iteration 27000, Testing net (#0)
I1023 18:20:22.735460  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:20:24.083319  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.980469
I1023 18:20:24.083386  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0560103 (* 1 = 0.0560103 loss)
I1023 18:20:24.263859  5058 solver.cpp:218] Iteration 27000 (4.94678 iter/s, 20.2152s/100 iters), loss = 0.0294713
I1023 18:20:24.263892  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0294724 (* 1 = 0.0294724 loss)
I1023 18:20:24.263900  5058 sgd_solver.cpp:105] Iteration 27000, lr = 0.0001
I1023 18:20:42.159795  5058 solver.cpp:218] Iteration 27100 (5.58789 iter/s, 17.8959s/100 iters), loss = 0.00299861
I1023 18:20:42.159828  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00299977 (* 1 = 0.00299977 loss)
I1023 18:20:42.159835  5058 sgd_solver.cpp:105] Iteration 27100, lr = 0.0001
I1023 18:20:59.879477  5058 solver.cpp:330] Iteration 27200, Testing net (#0)
I1023 18:21:00.839674  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:21:02.182606  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.982422
I1023 18:21:02.182668  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0569727 (* 1 = 0.0569727 loss)
I1023 18:21:02.363481  5058 solver.cpp:218] Iteration 27200 (4.94961 iter/s, 20.2036s/100 iters), loss = 0.00240025
I1023 18:21:02.363513  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00240139 (* 1 = 0.00240139 loss)
I1023 18:21:02.363520  5058 sgd_solver.cpp:105] Iteration 27200, lr = 0.0001
I1023 18:21:19.394593  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:21:20.266566  5058 solver.cpp:218] Iteration 27300 (5.58565 iter/s, 17.903s/100 iters), loss = 0.000663863
I1023 18:21:20.266598  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000665032 (* 1 = 0.000665032 loss)
I1023 18:21:20.266607  5058 sgd_solver.cpp:105] Iteration 27300, lr = 0.0001
I1023 18:21:37.992375  5058 solver.cpp:330] Iteration 27400, Testing net (#0)
I1023 18:21:38.951433  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:21:40.294373  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.978516
I1023 18:21:40.294435  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0572623 (* 1 = 0.0572623 loss)
I1023 18:21:40.475286  5058 solver.cpp:218] Iteration 27400 (4.94838 iter/s, 20.2086s/100 iters), loss = 0.0171751
I1023 18:21:40.475318  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0171763 (* 1 = 0.0171763 loss)
I1023 18:21:40.475325  5058 sgd_solver.cpp:105] Iteration 27400, lr = 0.0001
I1023 18:21:58.380712  5058 solver.cpp:218] Iteration 27500 (5.58492 iter/s, 17.9053s/100 iters), loss = 0.000543608
I1023 18:21:58.380755  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000544749 (* 1 = 0.000544749 loss)
I1023 18:21:58.380762  5058 sgd_solver.cpp:105] Iteration 27500, lr = 0.0001
I1023 18:22:16.106686  5058 solver.cpp:330] Iteration 27600, Testing net (#0)
I1023 18:22:17.064373  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:22:18.409296  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.982422
I1023 18:22:18.409353  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0572138 (* 1 = 0.0572138 loss)
I1023 18:22:18.589550  5058 solver.cpp:218] Iteration 27600 (4.94835 iter/s, 20.2087s/100 iters), loss = 0.0111121
I1023 18:22:18.589582  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111132 (* 1 = 0.0111132 loss)
I1023 18:22:18.589589  5058 sgd_solver.cpp:105] Iteration 27600, lr = 0.0001
I1023 18:22:25.238381  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:22:36.488950  5058 solver.cpp:218] Iteration 27700 (5.5868 iter/s, 17.8993s/100 iters), loss = 0.0514124
I1023 18:22:36.488981  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0514136 (* 1 = 0.0514136 loss)
I1023 18:22:36.488987  5058 sgd_solver.cpp:105] Iteration 27700, lr = 0.0001
I1023 18:22:54.211617  5058 solver.cpp:330] Iteration 27800, Testing net (#0)
I1023 18:22:55.135752  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:22:56.514058  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.980469
I1023 18:22:56.514117  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0576444 (* 1 = 0.0576444 loss)
I1023 18:22:56.694509  5058 solver.cpp:218] Iteration 27800 (4.94915 iter/s, 20.2055s/100 iters), loss = 0.00388738
I1023 18:22:56.694540  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00388851 (* 1 = 0.00388851 loss)
I1023 18:22:56.694547  5058 sgd_solver.cpp:105] Iteration 27800, lr = 0.0001
I1023 18:23:14.594357  5058 solver.cpp:218] Iteration 27900 (5.58666 iter/s, 17.8998s/100 iters), loss = 0.0473634
I1023 18:23:14.594388  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0473645 (* 1 = 0.0473645 loss)
I1023 18:23:14.594395  5058 sgd_solver.cpp:105] Iteration 27900, lr = 0.0001
I1023 18:23:28.583886  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:23:32.324223  5058 solver.cpp:330] Iteration 28000, Testing net (#0)
I1023 18:23:33.247489  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:23:34.627130  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.980469
I1023 18:23:34.627193  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0593076 (* 1 = 0.0593076 loss)
I1023 18:23:34.807018  5058 solver.cpp:218] Iteration 28000 (4.94741 iter/s, 20.2126s/100 iters), loss = 0.00376906
I1023 18:23:34.807052  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00377017 (* 1 = 0.00377017 loss)
I1023 18:23:34.807060  5058 sgd_solver.cpp:105] Iteration 28000, lr = 0.0001
I1023 18:23:52.704222  5058 solver.cpp:218] Iteration 28100 (5.58749 iter/s, 17.8971s/100 iters), loss = 0.00155447
I1023 18:23:52.704255  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00155557 (* 1 = 0.00155557 loss)
I1023 18:23:52.704262  5058 sgd_solver.cpp:105] Iteration 28100, lr = 0.0001
I1023 18:24:10.428833  5058 solver.cpp:330] Iteration 28200, Testing net (#0)
I1023 18:24:11.351397  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:24:12.730937  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.980469
I1023 18:24:12.730999  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0578724 (* 1 = 0.0578724 loss)
I1023 18:24:12.911217  5058 solver.cpp:218] Iteration 28200 (4.9488 iter/s, 20.2069s/100 iters), loss = 0.0115308
I1023 18:24:12.911252  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115319 (* 1 = 0.0115319 loss)
I1023 18:24:12.911259  5058 sgd_solver.cpp:105] Iteration 28200, lr = 0.0001
I1023 18:24:30.817749  5058 solver.cpp:218] Iteration 28300 (5.58458 iter/s, 17.9065s/100 iters), loss = 0.00390614
I1023 18:24:30.817782  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00390725 (* 1 = 0.00390725 loss)
I1023 18:24:30.817790  5058 sgd_solver.cpp:105] Iteration 28300, lr = 0.0001
I1023 18:24:34.244415  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:24:48.538187  5058 solver.cpp:330] Iteration 28400, Testing net (#0)
I1023 18:24:49.459640  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:24:50.839742  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.980469
I1023 18:24:50.839804  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.057859 (* 1 = 0.057859 loss)
I1023 18:24:51.020143  5058 solver.cpp:218] Iteration 28400 (4.94993 iter/s, 20.2023s/100 iters), loss = 0.0181567
I1023 18:24:51.020172  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181578 (* 1 = 0.0181578 loss)
I1023 18:24:51.020179  5058 sgd_solver.cpp:105] Iteration 28400, lr = 0.0001
I1023 18:25:08.922333  5058 solver.cpp:218] Iteration 28500 (5.58593 iter/s, 17.9021s/100 iters), loss = 0.0334915
I1023 18:25:08.922364  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0334926 (* 1 = 0.0334926 loss)
I1023 18:25:08.922370  5058 sgd_solver.cpp:105] Iteration 28500, lr = 0.0001
I1023 18:25:26.647985  5058 solver.cpp:330] Iteration 28600, Testing net (#0)
I1023 18:25:27.536725  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:25:28.950289  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.984375
I1023 18:25:28.950350  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0565182 (* 1 = 0.0565182 loss)
I1023 18:25:29.130759  5058 solver.cpp:218] Iteration 28600 (4.94845 iter/s, 20.2083s/100 iters), loss = 0.0124518
I1023 18:25:29.130791  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124529 (* 1 = 0.0124529 loss)
I1023 18:25:29.130798  5058 sgd_solver.cpp:105] Iteration 28600, lr = 0.0001
I1023 18:25:39.900650  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:25:47.041121  5058 solver.cpp:218] Iteration 28700 (5.58338 iter/s, 17.9103s/100 iters), loss = 0.0074463
I1023 18:25:47.041152  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0074474 (* 1 = 0.0074474 loss)
I1023 18:25:47.041158  5058 sgd_solver.cpp:105] Iteration 28700, lr = 0.0001
I1023 18:26:04.760900  5058 solver.cpp:330] Iteration 28800, Testing net (#0)
I1023 18:26:05.648195  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:26:07.062235  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.980469
I1023 18:26:07.062295  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0586 (* 1 = 0.0586 loss)
I1023 18:26:07.242373  5058 solver.cpp:218] Iteration 28800 (4.95021 iter/s, 20.2012s/100 iters), loss = 0.00994907
I1023 18:26:07.242410  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00995014 (* 1 = 0.00995014 loss)
I1023 18:26:07.242418  5058 sgd_solver.cpp:105] Iteration 28800, lr = 0.0001
I1023 18:26:25.138945  5058 solver.cpp:218] Iteration 28900 (5.58769 iter/s, 17.8965s/100 iters), loss = 0.0901977
I1023 18:26:25.138978  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0901988 (* 1 = 0.0901988 loss)
I1023 18:26:25.138984  5058 sgd_solver.cpp:105] Iteration 28900, lr = 0.0001
I1023 18:26:42.860544  5058 solver.cpp:330] Iteration 29000, Testing net (#0)
I1023 18:26:43.745847  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:26:45.161358  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.980469
I1023 18:26:45.161420  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0593101 (* 1 = 0.0593101 loss)
I1023 18:26:45.341799  5058 solver.cpp:218] Iteration 29000 (4.94981 iter/s, 20.2028s/100 iters), loss = 0.0977568
I1023 18:26:45.341830  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0977578 (* 1 = 0.0977578 loss)
I1023 18:26:45.341836  5058 sgd_solver.cpp:105] Iteration 29000, lr = 0.0001
I1023 18:26:45.723860  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:27:03.244740  5058 solver.cpp:218] Iteration 29100 (5.5857 iter/s, 17.9029s/100 iters), loss = 0.0216548
I1023 18:27:03.244771  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0216559 (* 1 = 0.0216559 loss)
I1023 18:27:03.244786  5058 sgd_solver.cpp:105] Iteration 29100, lr = 0.0001
I1023 18:27:20.965986  5058 solver.cpp:330] Iteration 29200, Testing net (#0)
I1023 18:27:21.851775  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:27:23.267791  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.980469
I1023 18:27:23.267838  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0597797 (* 1 = 0.0597797 loss)
I1023 18:27:23.448621  5058 solver.cpp:218] Iteration 29200 (4.94956 iter/s, 20.2038s/100 iters), loss = 0.0100144
I1023 18:27:23.448652  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100154 (* 1 = 0.0100154 loss)
I1023 18:27:23.448659  5058 sgd_solver.cpp:105] Iteration 29200, lr = 0.0001
I1023 18:27:41.347210  5058 solver.cpp:218] Iteration 29300 (5.58706 iter/s, 17.8985s/100 iters), loss = 0.0011424
I1023 18:27:41.347241  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00114345 (* 1 = 0.00114345 loss)
I1023 18:27:41.347249  5058 sgd_solver.cpp:105] Iteration 29300, lr = 0.0001
I1023 18:27:49.073539  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:27:59.076334  5058 solver.cpp:330] Iteration 29400, Testing net (#0)
I1023 18:27:59.928202  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:28:01.379309  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.982422
I1023 18:28:01.379371  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0601895 (* 1 = 0.0601895 loss)
I1023 18:28:01.559453  5058 solver.cpp:218] Iteration 29400 (4.94752 iter/s, 20.2122s/100 iters), loss = 0.0236814
I1023 18:28:01.559486  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0236824 (* 1 = 0.0236824 loss)
I1023 18:28:01.559494  5058 sgd_solver.cpp:105] Iteration 29400, lr = 0.0001
I1023 18:28:19.452374  5058 solver.cpp:218] Iteration 29500 (5.58883 iter/s, 17.8928s/100 iters), loss = 0.0025149
I1023 18:28:19.452404  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00251593 (* 1 = 0.00251593 loss)
I1023 18:28:19.452410  5058 sgd_solver.cpp:105] Iteration 29500, lr = 0.0001
I1023 18:28:37.171664  5058 solver.cpp:330] Iteration 29600, Testing net (#0)
I1023 18:28:38.022974  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:28:39.473086  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.984375
I1023 18:28:39.473143  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0584742 (* 1 = 0.0584742 loss)
I1023 18:28:39.653357  5058 solver.cpp:218] Iteration 29600 (4.95027 iter/s, 20.2009s/100 iters), loss = 0.00106554
I1023 18:28:39.653388  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00106658 (* 1 = 0.00106658 loss)
I1023 18:28:39.653394  5058 sgd_solver.cpp:105] Iteration 29600, lr = 0.0001
I1023 18:28:54.715451  5067 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:28:57.557294  5058 solver.cpp:218] Iteration 29700 (5.58539 iter/s, 17.9039s/100 iters), loss = 0.0081074
I1023 18:28:57.557327  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00810844 (* 1 = 0.00810844 loss)
I1023 18:28:57.557334  5058 sgd_solver.cpp:105] Iteration 29700, lr = 0.0001
I1023 18:29:15.279547  5058 solver.cpp:330] Iteration 29800, Testing net (#0)
I1023 18:29:16.130242  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:29:17.581490  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.982422
I1023 18:29:17.581552  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0581597 (* 1 = 0.0581597 loss)
I1023 18:29:17.762327  5058 solver.cpp:218] Iteration 29800 (4.94928 iter/s, 20.205s/100 iters), loss = 0.00692188
I1023 18:29:17.762361  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0069229 (* 1 = 0.0069229 loss)
I1023 18:29:17.762367  5058 sgd_solver.cpp:105] Iteration 29800, lr = 0.0001
I1023 18:29:35.665398  5058 solver.cpp:218] Iteration 29900 (5.58566 iter/s, 17.903s/100 iters), loss = 0.0304413
I1023 18:29:35.665429  5058 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0304423 (* 1 = 0.0304423 loss)
I1023 18:29:35.665436  5058 sgd_solver.cpp:105] Iteration 29900, lr = 0.0001
I1023 18:29:53.391732  5058 solver.cpp:447] Snapshotting to binary proto file xn/English_orange/snapshot/res20/res20_elu_1_iter_30000.caffemodel
I1023 18:29:53.399444  5058 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/English_orange/snapshot/res20/res20_elu_1_iter_30000.solverstate
I1023 18:29:53.451683  5058 solver.cpp:310] Iteration 30000, loss = 0.00761759
I1023 18:29:53.451715  5058 solver.cpp:330] Iteration 30000, Testing net (#0)
I1023 18:29:54.301115  5068 data_layer.cpp:73] Restarting data prefetching from start.
I1023 18:29:55.754462  5058 solver.cpp:397]     Test net output #0: Accuracy1 = 0.984375
I1023 18:29:55.754519  5058 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0567181 (* 1 = 0.0567181 loss)
I1023 18:29:55.754526  5058 solver.cpp:315] Optimization Done.
I1023 18:29:55.754530  5058 caffe.cpp:259] Optimization Done.
