I0928 13:46:48.153090  4581 caffe.cpp:218] Using GPUs 0
I0928 13:46:48.186856  4581 caffe.cpp:223] GPU 0: GeForce GTX 1080
I0928 13:46:48.415303  4581 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 120000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 120000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res56_mpelu_alpha0.25_beta1_nodecay12_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res56_mpelu_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
stepvalue: 100000
I0928 13:46:48.415446  4581 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56_mpelu_train_test.prototxt
I0928 13:46:48.419072  4581 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56_mpelu_train_test.prototxt
I0928 13:46:48.419086  4581 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0928 13:46:48.419312  4581 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I0928 13:46:48.419432  4581 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I0928 13:46:48.420498  4581 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU1"
  type: "M2PELU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU2"
  type: "M2PELU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU3"
  type: "M2PELU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU4"
  type: "M2PELU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU5"
  type: "M2PELU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU6"
  type: "M2PELU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU7"
  type: "M2PELU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU8"
  type: "M2PELU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU9"
  type: "M2PELU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU10"
  type: "M2PELU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU11"
  type: "M2PELU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU12"
  type: "M2PELU"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU13"
  type: "M2PELU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU14"
  type: "M2PELU"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU15"
  type: "M2PELU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU16"
  type: "M2PELU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU17"
  type: "M2PELU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU18"
  type: "M2PELU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU19"
  type: "M2PELU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU20"
  type: "M2PELU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU21"
  type: "M2PELU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU22"
  type: "M2PELU"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution24"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU23"
  type: "M2PELU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU24"
  type: "M2PELU"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
 
I0928 13:46:48.421262  4581 layer_factory.hpp:77] Creating layer Data1
I0928 13:46:48.421342  4581 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I0928 13:46:48.421362  4581 net.cpp:84] Creating Layer Data1
I0928 13:46:48.421368  4581 net.cpp:380] Data1 -> Data1
I0928 13:46:48.421394  4581 net.cpp:380] Data1 -> Data2
I0928 13:46:48.421403  4581 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0928 13:46:48.422825  4581 data_layer.cpp:45] output data size: 100,3,28,28
I0928 13:46:48.425174  4581 net.cpp:122] Setting up Data1
I0928 13:46:48.425191  4581 net.cpp:129] Top shape: 100 3 28 28 (235200)
I0928 13:46:48.425195  4581 net.cpp:129] Top shape: 100 (100)
I0928 13:46:48.425197  4581 net.cpp:137] Memory required for data: 941200
I0928 13:46:48.425204  4581 layer_factory.hpp:77] Creating layer Convolution1
I0928 13:46:48.425225  4581 net.cpp:84] Creating Layer Convolution1
I0928 13:46:48.425230  4581 net.cpp:406] Convolution1 <- Data1
I0928 13:46:48.425238  4581 net.cpp:380] Convolution1 -> Convolution1
I0928 13:46:48.570149  4581 net.cpp:122] Setting up Convolution1
I0928 13:46:48.570174  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.570179  4581 net.cpp:137] Memory required for data: 5958800
I0928 13:46:48.570199  4581 layer_factory.hpp:77] Creating layer BatchNorm1
I0928 13:46:48.570224  4581 net.cpp:84] Creating Layer BatchNorm1
I0928 13:46:48.570248  4581 net.cpp:406] BatchNorm1 <- Convolution1
I0928 13:46:48.570268  4581 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0928 13:46:48.570405  4581 net.cpp:122] Setting up BatchNorm1
I0928 13:46:48.570413  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.570417  4581 net.cpp:137] Memory required for data: 10976400
I0928 13:46:48.570430  4581 layer_factory.hpp:77] Creating layer Scale1
I0928 13:46:48.570456  4581 net.cpp:84] Creating Layer Scale1
I0928 13:46:48.570468  4581 net.cpp:406] Scale1 <- Convolution1
I0928 13:46:48.570474  4581 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0928 13:46:48.570569  4581 layer_factory.hpp:77] Creating layer Scale1
I0928 13:46:48.570700  4581 net.cpp:122] Setting up Scale1
I0928 13:46:48.570708  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.570711  4581 net.cpp:137] Memory required for data: 15994000
I0928 13:46:48.570720  4581 layer_factory.hpp:77] Creating layer M2PELU1
I0928 13:46:48.570747  4581 net.cpp:84] Creating Layer M2PELU1
I0928 13:46:48.570751  4581 net.cpp:406] M2PELU1 <- Convolution1
I0928 13:46:48.570767  4581 net.cpp:367] M2PELU1 -> Convolution1 (in-place)
I0928 13:46:48.571389  4581 net.cpp:122] Setting up M2PELU1
I0928 13:46:48.571399  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.571404  4581 net.cpp:137] Memory required for data: 21011600
I0928 13:46:48.571414  4581 layer_factory.hpp:77] Creating layer Convolution1_M2PELU1_0_split
I0928 13:46:48.571439  4581 net.cpp:84] Creating Layer Convolution1_M2PELU1_0_split
I0928 13:46:48.571452  4581 net.cpp:406] Convolution1_M2PELU1_0_split <- Convolution1
I0928 13:46:48.571458  4581 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_0
I0928 13:46:48.571480  4581 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_1
I0928 13:46:48.571535  4581 net.cpp:122] Setting up Convolution1_M2PELU1_0_split
I0928 13:46:48.571542  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.571560  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.571564  4581 net.cpp:137] Memory required for data: 31046800
I0928 13:46:48.571578  4581 layer_factory.hpp:77] Creating layer Convolution2
I0928 13:46:48.571599  4581 net.cpp:84] Creating Layer Convolution2
I0928 13:46:48.571602  4581 net.cpp:406] Convolution2 <- Convolution1_M2PELU1_0_split_0
I0928 13:46:48.571609  4581 net.cpp:380] Convolution2 -> Convolution2
I0928 13:46:48.572465  4581 net.cpp:122] Setting up Convolution2
I0928 13:46:48.572476  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.572481  4581 net.cpp:137] Memory required for data: 36064400
I0928 13:46:48.572489  4581 layer_factory.hpp:77] Creating layer BatchNorm2
I0928 13:46:48.572499  4581 net.cpp:84] Creating Layer BatchNorm2
I0928 13:46:48.572504  4581 net.cpp:406] BatchNorm2 <- Convolution2
I0928 13:46:48.572510  4581 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0928 13:46:48.572639  4581 net.cpp:122] Setting up BatchNorm2
I0928 13:46:48.572646  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.572650  4581 net.cpp:137] Memory required for data: 41082000
I0928 13:46:48.572670  4581 layer_factory.hpp:77] Creating layer Scale2
I0928 13:46:48.572677  4581 net.cpp:84] Creating Layer Scale2
I0928 13:46:48.572682  4581 net.cpp:406] Scale2 <- Convolution2
I0928 13:46:48.572688  4581 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0928 13:46:48.572720  4581 layer_factory.hpp:77] Creating layer Scale2
I0928 13:46:48.572796  4581 net.cpp:122] Setting up Scale2
I0928 13:46:48.572803  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.572808  4581 net.cpp:137] Memory required for data: 46099600
I0928 13:46:48.572815  4581 layer_factory.hpp:77] Creating layer M2PELU2
I0928 13:46:48.572824  4581 net.cpp:84] Creating Layer M2PELU2
I0928 13:46:48.572829  4581 net.cpp:406] M2PELU2 <- Convolution2
I0928 13:46:48.572835  4581 net.cpp:367] M2PELU2 -> Convolution2 (in-place)
I0928 13:46:48.572917  4581 net.cpp:122] Setting up M2PELU2
I0928 13:46:48.572932  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.572937  4581 net.cpp:137] Memory required for data: 51117200
I0928 13:46:48.572948  4581 layer_factory.hpp:77] Creating layer Convolution3
I0928 13:46:48.572958  4581 net.cpp:84] Creating Layer Convolution3
I0928 13:46:48.572962  4581 net.cpp:406] Convolution3 <- Convolution2
I0928 13:46:48.572969  4581 net.cpp:380] Convolution3 -> Convolution3
I0928 13:46:48.573824  4581 net.cpp:122] Setting up Convolution3
I0928 13:46:48.573835  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.573840  4581 net.cpp:137] Memory required for data: 56134800
I0928 13:46:48.573848  4581 layer_factory.hpp:77] Creating layer BatchNorm3
I0928 13:46:48.573858  4581 net.cpp:84] Creating Layer BatchNorm3
I0928 13:46:48.573863  4581 net.cpp:406] BatchNorm3 <- Convolution3
I0928 13:46:48.573870  4581 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0928 13:46:48.573997  4581 net.cpp:122] Setting up BatchNorm3
I0928 13:46:48.574004  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.574008  4581 net.cpp:137] Memory required for data: 61152400
I0928 13:46:48.574018  4581 layer_factory.hpp:77] Creating layer Scale3
I0928 13:46:48.574026  4581 net.cpp:84] Creating Layer Scale3
I0928 13:46:48.574031  4581 net.cpp:406] Scale3 <- Convolution3
I0928 13:46:48.574038  4581 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0928 13:46:48.574069  4581 layer_factory.hpp:77] Creating layer Scale3
I0928 13:46:48.574147  4581 net.cpp:122] Setting up Scale3
I0928 13:46:48.574154  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.574158  4581 net.cpp:137] Memory required for data: 66170000
I0928 13:46:48.574167  4581 layer_factory.hpp:77] Creating layer Eltwise1
I0928 13:46:48.574175  4581 net.cpp:84] Creating Layer Eltwise1
I0928 13:46:48.574180  4581 net.cpp:406] Eltwise1 <- Convolution1_M2PELU1_0_split_1
I0928 13:46:48.574185  4581 net.cpp:406] Eltwise1 <- Convolution3
I0928 13:46:48.574193  4581 net.cpp:380] Eltwise1 -> Eltwise1
I0928 13:46:48.574214  4581 net.cpp:122] Setting up Eltwise1
I0928 13:46:48.574220  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.574224  4581 net.cpp:137] Memory required for data: 71187600
I0928 13:46:48.574229  4581 layer_factory.hpp:77] Creating layer M2PELU3
I0928 13:46:48.574239  4581 net.cpp:84] Creating Layer M2PELU3
I0928 13:46:48.574242  4581 net.cpp:406] M2PELU3 <- Eltwise1
I0928 13:46:48.574249  4581 net.cpp:367] M2PELU3 -> Eltwise1 (in-place)
I0928 13:46:48.574332  4581 net.cpp:122] Setting up M2PELU3
I0928 13:46:48.574339  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.574343  4581 net.cpp:137] Memory required for data: 76205200
I0928 13:46:48.574352  4581 layer_factory.hpp:77] Creating layer Eltwise1_M2PELU3_0_split
I0928 13:46:48.574357  4581 net.cpp:84] Creating Layer Eltwise1_M2PELU3_0_split
I0928 13:46:48.574362  4581 net.cpp:406] Eltwise1_M2PELU3_0_split <- Eltwise1
I0928 13:46:48.574370  4581 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_0
I0928 13:46:48.574378  4581 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_1
I0928 13:46:48.574405  4581 net.cpp:122] Setting up Eltwise1_M2PELU3_0_split
I0928 13:46:48.574412  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.574419  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.574424  4581 net.cpp:137] Memory required for data: 86240400
I0928 13:46:48.574427  4581 layer_factory.hpp:77] Creating layer Convolution4
I0928 13:46:48.574440  4581 net.cpp:84] Creating Layer Convolution4
I0928 13:46:48.574445  4581 net.cpp:406] Convolution4 <- Eltwise1_M2PELU3_0_split_0
I0928 13:46:48.574451  4581 net.cpp:380] Convolution4 -> Convolution4
I0928 13:46:48.575346  4581 net.cpp:122] Setting up Convolution4
I0928 13:46:48.575357  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.575362  4581 net.cpp:137] Memory required for data: 91258000
I0928 13:46:48.575369  4581 layer_factory.hpp:77] Creating layer BatchNorm4
I0928 13:46:48.575386  4581 net.cpp:84] Creating Layer BatchNorm4
I0928 13:46:48.575392  4581 net.cpp:406] BatchNorm4 <- Convolution4
I0928 13:46:48.575400  4581 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0928 13:46:48.575529  4581 net.cpp:122] Setting up BatchNorm4
I0928 13:46:48.575536  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.575541  4581 net.cpp:137] Memory required for data: 96275600
I0928 13:46:48.575551  4581 layer_factory.hpp:77] Creating layer Scale4
I0928 13:46:48.575556  4581 net.cpp:84] Creating Layer Scale4
I0928 13:46:48.575562  4581 net.cpp:406] Scale4 <- Convolution4
I0928 13:46:48.575570  4581 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0928 13:46:48.575599  4581 layer_factory.hpp:77] Creating layer Scale4
I0928 13:46:48.575678  4581 net.cpp:122] Setting up Scale4
I0928 13:46:48.575685  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.575690  4581 net.cpp:137] Memory required for data: 101293200
I0928 13:46:48.575701  4581 layer_factory.hpp:77] Creating layer M2PELU4
I0928 13:46:48.575711  4581 net.cpp:84] Creating Layer M2PELU4
I0928 13:46:48.575716  4581 net.cpp:406] M2PELU4 <- Convolution4
I0928 13:46:48.575721  4581 net.cpp:367] M2PELU4 -> Convolution4 (in-place)
I0928 13:46:48.575803  4581 net.cpp:122] Setting up M2PELU4
I0928 13:46:48.575811  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.575815  4581 net.cpp:137] Memory required for data: 106310800
I0928 13:46:48.575822  4581 layer_factory.hpp:77] Creating layer Convolution5
I0928 13:46:48.575834  4581 net.cpp:84] Creating Layer Convolution5
I0928 13:46:48.575839  4581 net.cpp:406] Convolution5 <- Convolution4
I0928 13:46:48.575845  4581 net.cpp:380] Convolution5 -> Convolution5
I0928 13:46:48.576714  4581 net.cpp:122] Setting up Convolution5
I0928 13:46:48.576726  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.576730  4581 net.cpp:137] Memory required for data: 111328400
I0928 13:46:48.576738  4581 layer_factory.hpp:77] Creating layer BatchNorm5
I0928 13:46:48.576746  4581 net.cpp:84] Creating Layer BatchNorm5
I0928 13:46:48.576751  4581 net.cpp:406] BatchNorm5 <- Convolution5
I0928 13:46:48.576761  4581 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0928 13:46:48.576889  4581 net.cpp:122] Setting up BatchNorm5
I0928 13:46:48.576895  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.576900  4581 net.cpp:137] Memory required for data: 116346000
I0928 13:46:48.576910  4581 layer_factory.hpp:77] Creating layer Scale5
I0928 13:46:48.576916  4581 net.cpp:84] Creating Layer Scale5
I0928 13:46:48.576921  4581 net.cpp:406] Scale5 <- Convolution5
I0928 13:46:48.576928  4581 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0928 13:46:48.576958  4581 layer_factory.hpp:77] Creating layer Scale5
I0928 13:46:48.577040  4581 net.cpp:122] Setting up Scale5
I0928 13:46:48.577049  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.577052  4581 net.cpp:137] Memory required for data: 121363600
I0928 13:46:48.577060  4581 layer_factory.hpp:77] Creating layer Eltwise2
I0928 13:46:48.577067  4581 net.cpp:84] Creating Layer Eltwise2
I0928 13:46:48.577072  4581 net.cpp:406] Eltwise2 <- Eltwise1_M2PELU3_0_split_1
I0928 13:46:48.577078  4581 net.cpp:406] Eltwise2 <- Convolution5
I0928 13:46:48.577086  4581 net.cpp:380] Eltwise2 -> Eltwise2
I0928 13:46:48.577105  4581 net.cpp:122] Setting up Eltwise2
I0928 13:46:48.577113  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.577118  4581 net.cpp:137] Memory required for data: 126381200
I0928 13:46:48.577122  4581 layer_factory.hpp:77] Creating layer M2PELU5
I0928 13:46:48.577131  4581 net.cpp:84] Creating Layer M2PELU5
I0928 13:46:48.577134  4581 net.cpp:406] M2PELU5 <- Eltwise2
I0928 13:46:48.577142  4581 net.cpp:367] M2PELU5 -> Eltwise2 (in-place)
I0928 13:46:48.577227  4581 net.cpp:122] Setting up M2PELU5
I0928 13:46:48.577234  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.577239  4581 net.cpp:137] Memory required for data: 131398800
I0928 13:46:48.577246  4581 layer_factory.hpp:77] Creating layer Eltwise2_M2PELU5_0_split
I0928 13:46:48.577260  4581 net.cpp:84] Creating Layer Eltwise2_M2PELU5_0_split
I0928 13:46:48.577265  4581 net.cpp:406] Eltwise2_M2PELU5_0_split <- Eltwise2
I0928 13:46:48.577272  4581 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_0
I0928 13:46:48.577280  4581 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_1
I0928 13:46:48.577307  4581 net.cpp:122] Setting up Eltwise2_M2PELU5_0_split
I0928 13:46:48.577314  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.577320  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.577325  4581 net.cpp:137] Memory required for data: 141434000
I0928 13:46:48.577330  4581 layer_factory.hpp:77] Creating layer Convolution6
I0928 13:46:48.577340  4581 net.cpp:84] Creating Layer Convolution6
I0928 13:46:48.577345  4581 net.cpp:406] Convolution6 <- Eltwise2_M2PELU5_0_split_0
I0928 13:46:48.577353  4581 net.cpp:380] Convolution6 -> Convolution6
I0928 13:46:48.578227  4581 net.cpp:122] Setting up Convolution6
I0928 13:46:48.578238  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.578243  4581 net.cpp:137] Memory required for data: 146451600
I0928 13:46:48.578250  4581 layer_factory.hpp:77] Creating layer BatchNorm6
I0928 13:46:48.578260  4581 net.cpp:84] Creating Layer BatchNorm6
I0928 13:46:48.578265  4581 net.cpp:406] BatchNorm6 <- Convolution6
I0928 13:46:48.578274  4581 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0928 13:46:48.578407  4581 net.cpp:122] Setting up BatchNorm6
I0928 13:46:48.578413  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.578418  4581 net.cpp:137] Memory required for data: 151469200
I0928 13:46:48.578428  4581 layer_factory.hpp:77] Creating layer Scale6
I0928 13:46:48.578436  4581 net.cpp:84] Creating Layer Scale6
I0928 13:46:48.578441  4581 net.cpp:406] Scale6 <- Convolution6
I0928 13:46:48.578447  4581 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0928 13:46:48.578478  4581 layer_factory.hpp:77] Creating layer Scale6
I0928 13:46:48.578588  4581 net.cpp:122] Setting up Scale6
I0928 13:46:48.578595  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.578599  4581 net.cpp:137] Memory required for data: 156486800
I0928 13:46:48.578606  4581 layer_factory.hpp:77] Creating layer M2PELU6
I0928 13:46:48.578616  4581 net.cpp:84] Creating Layer M2PELU6
I0928 13:46:48.578620  4581 net.cpp:406] M2PELU6 <- Convolution6
I0928 13:46:48.578627  4581 net.cpp:367] M2PELU6 -> Convolution6 (in-place)
I0928 13:46:48.578712  4581 net.cpp:122] Setting up M2PELU6
I0928 13:46:48.578722  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.578727  4581 net.cpp:137] Memory required for data: 161504400
I0928 13:46:48.578734  4581 layer_factory.hpp:77] Creating layer Convolution7
I0928 13:46:48.578743  4581 net.cpp:84] Creating Layer Convolution7
I0928 13:46:48.578747  4581 net.cpp:406] Convolution7 <- Convolution6
I0928 13:46:48.578755  4581 net.cpp:380] Convolution7 -> Convolution7
I0928 13:46:48.579310  4581 net.cpp:122] Setting up Convolution7
I0928 13:46:48.579321  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.579327  4581 net.cpp:137] Memory required for data: 166522000
I0928 13:46:48.579336  4581 layer_factory.hpp:77] Creating layer BatchNorm7
I0928 13:46:48.579344  4581 net.cpp:84] Creating Layer BatchNorm7
I0928 13:46:48.579349  4581 net.cpp:406] BatchNorm7 <- Convolution7
I0928 13:46:48.579355  4581 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0928 13:46:48.579490  4581 net.cpp:122] Setting up BatchNorm7
I0928 13:46:48.579497  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.579501  4581 net.cpp:137] Memory required for data: 171539600
I0928 13:46:48.579510  4581 layer_factory.hpp:77] Creating layer Scale7
I0928 13:46:48.579519  4581 net.cpp:84] Creating Layer Scale7
I0928 13:46:48.579524  4581 net.cpp:406] Scale7 <- Convolution7
I0928 13:46:48.579530  4581 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0928 13:46:48.579563  4581 layer_factory.hpp:77] Creating layer Scale7
I0928 13:46:48.579653  4581 net.cpp:122] Setting up Scale7
I0928 13:46:48.579661  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.579666  4581 net.cpp:137] Memory required for data: 176557200
I0928 13:46:48.579674  4581 layer_factory.hpp:77] Creating layer Eltwise3
I0928 13:46:48.579681  4581 net.cpp:84] Creating Layer Eltwise3
I0928 13:46:48.579686  4581 net.cpp:406] Eltwise3 <- Eltwise2_M2PELU5_0_split_1
I0928 13:46:48.579692  4581 net.cpp:406] Eltwise3 <- Convolution7
I0928 13:46:48.579699  4581 net.cpp:380] Eltwise3 -> Eltwise3
I0928 13:46:48.579721  4581 net.cpp:122] Setting up Eltwise3
I0928 13:46:48.579728  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.579733  4581 net.cpp:137] Memory required for data: 181574800
I0928 13:46:48.579738  4581 layer_factory.hpp:77] Creating layer M2PELU7
I0928 13:46:48.579746  4581 net.cpp:84] Creating Layer M2PELU7
I0928 13:46:48.579751  4581 net.cpp:406] M2PELU7 <- Eltwise3
I0928 13:46:48.579757  4581 net.cpp:367] M2PELU7 -> Eltwise3 (in-place)
I0928 13:46:48.579843  4581 net.cpp:122] Setting up M2PELU7
I0928 13:46:48.579850  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.579854  4581 net.cpp:137] Memory required for data: 186592400
I0928 13:46:48.579862  4581 layer_factory.hpp:77] Creating layer Eltwise3_M2PELU7_0_split
I0928 13:46:48.579869  4581 net.cpp:84] Creating Layer Eltwise3_M2PELU7_0_split
I0928 13:46:48.579874  4581 net.cpp:406] Eltwise3_M2PELU7_0_split <- Eltwise3
I0928 13:46:48.579880  4581 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_0
I0928 13:46:48.579890  4581 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_1
I0928 13:46:48.579916  4581 net.cpp:122] Setting up Eltwise3_M2PELU7_0_split
I0928 13:46:48.579923  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.579929  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.579934  4581 net.cpp:137] Memory required for data: 196627600
I0928 13:46:48.579938  4581 layer_factory.hpp:77] Creating layer Convolution8
I0928 13:46:48.579949  4581 net.cpp:84] Creating Layer Convolution8
I0928 13:46:48.579953  4581 net.cpp:406] Convolution8 <- Eltwise3_M2PELU7_0_split_0
I0928 13:46:48.579960  4581 net.cpp:380] Convolution8 -> Convolution8
I0928 13:46:48.580831  4581 net.cpp:122] Setting up Convolution8
I0928 13:46:48.580842  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.580847  4581 net.cpp:137] Memory required for data: 201645200
I0928 13:46:48.580862  4581 layer_factory.hpp:77] Creating layer BatchNorm8
I0928 13:46:48.580870  4581 net.cpp:84] Creating Layer BatchNorm8
I0928 13:46:48.580876  4581 net.cpp:406] BatchNorm8 <- Convolution8
I0928 13:46:48.580893  4581 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0928 13:46:48.581035  4581 net.cpp:122] Setting up BatchNorm8
I0928 13:46:48.581043  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.581048  4581 net.cpp:137] Memory required for data: 206662800
I0928 13:46:48.581068  4581 layer_factory.hpp:77] Creating layer Scale8
I0928 13:46:48.581075  4581 net.cpp:84] Creating Layer Scale8
I0928 13:46:48.581089  4581 net.cpp:406] Scale8 <- Convolution8
I0928 13:46:48.581105  4581 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0928 13:46:48.581146  4581 layer_factory.hpp:77] Creating layer Scale8
I0928 13:46:48.581248  4581 net.cpp:122] Setting up Scale8
I0928 13:46:48.581255  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.581259  4581 net.cpp:137] Memory required for data: 211680400
I0928 13:46:48.581277  4581 layer_factory.hpp:77] Creating layer M2PELU8
I0928 13:46:48.581287  4581 net.cpp:84] Creating Layer M2PELU8
I0928 13:46:48.581291  4581 net.cpp:406] M2PELU8 <- Convolution8
I0928 13:46:48.581300  4581 net.cpp:367] M2PELU8 -> Convolution8 (in-place)
I0928 13:46:48.581395  4581 net.cpp:122] Setting up M2PELU8
I0928 13:46:48.581403  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.581408  4581 net.cpp:137] Memory required for data: 216698000
I0928 13:46:48.581439  4581 layer_factory.hpp:77] Creating layer Convolution9
I0928 13:46:48.581461  4581 net.cpp:84] Creating Layer Convolution9
I0928 13:46:48.581466  4581 net.cpp:406] Convolution9 <- Convolution8
I0928 13:46:48.581475  4581 net.cpp:380] Convolution9 -> Convolution9
I0928 13:46:48.582543  4581 net.cpp:122] Setting up Convolution9
I0928 13:46:48.582554  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.582559  4581 net.cpp:137] Memory required for data: 221715600
I0928 13:46:48.582567  4581 layer_factory.hpp:77] Creating layer BatchNorm9
I0928 13:46:48.582577  4581 net.cpp:84] Creating Layer BatchNorm9
I0928 13:46:48.582592  4581 net.cpp:406] BatchNorm9 <- Convolution9
I0928 13:46:48.582599  4581 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0928 13:46:48.582744  4581 net.cpp:122] Setting up BatchNorm9
I0928 13:46:48.582751  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.582756  4581 net.cpp:137] Memory required for data: 226733200
I0928 13:46:48.582765  4581 layer_factory.hpp:77] Creating layer Scale9
I0928 13:46:48.582772  4581 net.cpp:84] Creating Layer Scale9
I0928 13:46:48.582777  4581 net.cpp:406] Scale9 <- Convolution9
I0928 13:46:48.582784  4581 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0928 13:46:48.582816  4581 layer_factory.hpp:77] Creating layer Scale9
I0928 13:46:48.582901  4581 net.cpp:122] Setting up Scale9
I0928 13:46:48.582908  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.582913  4581 net.cpp:137] Memory required for data: 231750800
I0928 13:46:48.582921  4581 layer_factory.hpp:77] Creating layer Eltwise4
I0928 13:46:48.582929  4581 net.cpp:84] Creating Layer Eltwise4
I0928 13:46:48.582934  4581 net.cpp:406] Eltwise4 <- Eltwise3_M2PELU7_0_split_1
I0928 13:46:48.582940  4581 net.cpp:406] Eltwise4 <- Convolution9
I0928 13:46:48.582947  4581 net.cpp:380] Eltwise4 -> Eltwise4
I0928 13:46:48.582967  4581 net.cpp:122] Setting up Eltwise4
I0928 13:46:48.582974  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.582979  4581 net.cpp:137] Memory required for data: 236768400
I0928 13:46:48.582984  4581 layer_factory.hpp:77] Creating layer M2PELU9
I0928 13:46:48.582994  4581 net.cpp:84] Creating Layer M2PELU9
I0928 13:46:48.582998  4581 net.cpp:406] M2PELU9 <- Eltwise4
I0928 13:46:48.583004  4581 net.cpp:367] M2PELU9 -> Eltwise4 (in-place)
I0928 13:46:48.583094  4581 net.cpp:122] Setting up M2PELU9
I0928 13:46:48.583101  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.583106  4581 net.cpp:137] Memory required for data: 241786000
I0928 13:46:48.583112  4581 layer_factory.hpp:77] Creating layer Eltwise4_M2PELU9_0_split
I0928 13:46:48.583119  4581 net.cpp:84] Creating Layer Eltwise4_M2PELU9_0_split
I0928 13:46:48.583124  4581 net.cpp:406] Eltwise4_M2PELU9_0_split <- Eltwise4
I0928 13:46:48.583130  4581 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_0
I0928 13:46:48.583138  4581 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_1
I0928 13:46:48.583166  4581 net.cpp:122] Setting up Eltwise4_M2PELU9_0_split
I0928 13:46:48.583173  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.583178  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.583184  4581 net.cpp:137] Memory required for data: 251821200
I0928 13:46:48.583187  4581 layer_factory.hpp:77] Creating layer Convolution10
I0928 13:46:48.583199  4581 net.cpp:84] Creating Layer Convolution10
I0928 13:46:48.583202  4581 net.cpp:406] Convolution10 <- Eltwise4_M2PELU9_0_split_0
I0928 13:46:48.583210  4581 net.cpp:380] Convolution10 -> Convolution10
I0928 13:46:48.584167  4581 net.cpp:122] Setting up Convolution10
I0928 13:46:48.584187  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.584190  4581 net.cpp:137] Memory required for data: 256838800
I0928 13:46:48.584198  4581 layer_factory.hpp:77] Creating layer BatchNorm10
I0928 13:46:48.584208  4581 net.cpp:84] Creating Layer BatchNorm10
I0928 13:46:48.584213  4581 net.cpp:406] BatchNorm10 <- Convolution10
I0928 13:46:48.584229  4581 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0928 13:46:48.584362  4581 net.cpp:122] Setting up BatchNorm10
I0928 13:46:48.584369  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.584373  4581 net.cpp:137] Memory required for data: 261856400
I0928 13:46:48.584383  4581 layer_factory.hpp:77] Creating layer Scale10
I0928 13:46:48.584390  4581 net.cpp:84] Creating Layer Scale10
I0928 13:46:48.584395  4581 net.cpp:406] Scale10 <- Convolution10
I0928 13:46:48.584401  4581 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0928 13:46:48.584434  4581 layer_factory.hpp:77] Creating layer Scale10
I0928 13:46:48.584514  4581 net.cpp:122] Setting up Scale10
I0928 13:46:48.584522  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.584525  4581 net.cpp:137] Memory required for data: 266874000
I0928 13:46:48.584533  4581 layer_factory.hpp:77] Creating layer M2PELU10
I0928 13:46:48.584542  4581 net.cpp:84] Creating Layer M2PELU10
I0928 13:46:48.584547  4581 net.cpp:406] M2PELU10 <- Convolution10
I0928 13:46:48.584554  4581 net.cpp:367] M2PELU10 -> Convolution10 (in-place)
I0928 13:46:48.584640  4581 net.cpp:122] Setting up M2PELU10
I0928 13:46:48.584646  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.584650  4581 net.cpp:137] Memory required for data: 271891600
I0928 13:46:48.584657  4581 layer_factory.hpp:77] Creating layer Convolution11
I0928 13:46:48.584668  4581 net.cpp:84] Creating Layer Convolution11
I0928 13:46:48.584672  4581 net.cpp:406] Convolution11 <- Convolution10
I0928 13:46:48.584681  4581 net.cpp:380] Convolution11 -> Convolution11
I0928 13:46:48.585551  4581 net.cpp:122] Setting up Convolution11
I0928 13:46:48.585562  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.585567  4581 net.cpp:137] Memory required for data: 276909200
I0928 13:46:48.585574  4581 layer_factory.hpp:77] Creating layer BatchNorm11
I0928 13:46:48.585583  4581 net.cpp:84] Creating Layer BatchNorm11
I0928 13:46:48.585588  4581 net.cpp:406] BatchNorm11 <- Convolution11
I0928 13:46:48.585594  4581 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0928 13:46:48.585726  4581 net.cpp:122] Setting up BatchNorm11
I0928 13:46:48.585733  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.585737  4581 net.cpp:137] Memory required for data: 281926800
I0928 13:46:48.585747  4581 layer_factory.hpp:77] Creating layer Scale11
I0928 13:46:48.585753  4581 net.cpp:84] Creating Layer Scale11
I0928 13:46:48.585758  4581 net.cpp:406] Scale11 <- Convolution11
I0928 13:46:48.585764  4581 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0928 13:46:48.585798  4581 layer_factory.hpp:77] Creating layer Scale11
I0928 13:46:48.585880  4581 net.cpp:122] Setting up Scale11
I0928 13:46:48.585887  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.585892  4581 net.cpp:137] Memory required for data: 286944400
I0928 13:46:48.585901  4581 layer_factory.hpp:77] Creating layer Eltwise5
I0928 13:46:48.585906  4581 net.cpp:84] Creating Layer Eltwise5
I0928 13:46:48.585911  4581 net.cpp:406] Eltwise5 <- Eltwise4_M2PELU9_0_split_1
I0928 13:46:48.585917  4581 net.cpp:406] Eltwise5 <- Convolution11
I0928 13:46:48.585923  4581 net.cpp:380] Eltwise5 -> Eltwise5
I0928 13:46:48.585944  4581 net.cpp:122] Setting up Eltwise5
I0928 13:46:48.585952  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.585957  4581 net.cpp:137] Memory required for data: 291962000
I0928 13:46:48.585961  4581 layer_factory.hpp:77] Creating layer M2PELU11
I0928 13:46:48.585970  4581 net.cpp:84] Creating Layer M2PELU11
I0928 13:46:48.585975  4581 net.cpp:406] M2PELU11 <- Eltwise5
I0928 13:46:48.585981  4581 net.cpp:367] M2PELU11 -> Eltwise5 (in-place)
I0928 13:46:48.586071  4581 net.cpp:122] Setting up M2PELU11
I0928 13:46:48.586076  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.586081  4581 net.cpp:137] Memory required for data: 296979600
I0928 13:46:48.586088  4581 layer_factory.hpp:77] Creating layer Eltwise5_M2PELU11_0_split
I0928 13:46:48.586096  4581 net.cpp:84] Creating Layer Eltwise5_M2PELU11_0_split
I0928 13:46:48.586107  4581 net.cpp:406] Eltwise5_M2PELU11_0_split <- Eltwise5
I0928 13:46:48.586114  4581 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_0
I0928 13:46:48.586122  4581 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_1
I0928 13:46:48.586151  4581 net.cpp:122] Setting up Eltwise5_M2PELU11_0_split
I0928 13:46:48.586158  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.586164  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.586169  4581 net.cpp:137] Memory required for data: 307014800
I0928 13:46:48.586174  4581 layer_factory.hpp:77] Creating layer Convolution12
I0928 13:46:48.586184  4581 net.cpp:84] Creating Layer Convolution12
I0928 13:46:48.586189  4581 net.cpp:406] Convolution12 <- Eltwise5_M2PELU11_0_split_0
I0928 13:46:48.586196  4581 net.cpp:380] Convolution12 -> Convolution12
I0928 13:46:48.587093  4581 net.cpp:122] Setting up Convolution12
I0928 13:46:48.587105  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.587110  4581 net.cpp:137] Memory required for data: 312032400
I0928 13:46:48.587116  4581 layer_factory.hpp:77] Creating layer BatchNorm12
I0928 13:46:48.587126  4581 net.cpp:84] Creating Layer BatchNorm12
I0928 13:46:48.587131  4581 net.cpp:406] BatchNorm12 <- Convolution12
I0928 13:46:48.587139  4581 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0928 13:46:48.587275  4581 net.cpp:122] Setting up BatchNorm12
I0928 13:46:48.587281  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.587285  4581 net.cpp:137] Memory required for data: 317050000
I0928 13:46:48.587294  4581 layer_factory.hpp:77] Creating layer Scale12
I0928 13:46:48.587302  4581 net.cpp:84] Creating Layer Scale12
I0928 13:46:48.587307  4581 net.cpp:406] Scale12 <- Convolution12
I0928 13:46:48.587312  4581 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0928 13:46:48.587353  4581 layer_factory.hpp:77] Creating layer Scale12
I0928 13:46:48.587440  4581 net.cpp:122] Setting up Scale12
I0928 13:46:48.587446  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.587450  4581 net.cpp:137] Memory required for data: 322067600
I0928 13:46:48.587458  4581 layer_factory.hpp:77] Creating layer M2PELU12
I0928 13:46:48.587467  4581 net.cpp:84] Creating Layer M2PELU12
I0928 13:46:48.587472  4581 net.cpp:406] M2PELU12 <- Convolution12
I0928 13:46:48.587479  4581 net.cpp:367] M2PELU12 -> Convolution12 (in-place)
I0928 13:46:48.587569  4581 net.cpp:122] Setting up M2PELU12
I0928 13:46:48.587576  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.587580  4581 net.cpp:137] Memory required for data: 327085200
I0928 13:46:48.587589  4581 layer_factory.hpp:77] Creating layer Convolution13
I0928 13:46:48.587599  4581 net.cpp:84] Creating Layer Convolution13
I0928 13:46:48.587604  4581 net.cpp:406] Convolution13 <- Convolution12
I0928 13:46:48.587611  4581 net.cpp:380] Convolution13 -> Convolution13
I0928 13:46:48.588506  4581 net.cpp:122] Setting up Convolution13
I0928 13:46:48.588517  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.588522  4581 net.cpp:137] Memory required for data: 332102800
I0928 13:46:48.588529  4581 layer_factory.hpp:77] Creating layer BatchNorm13
I0928 13:46:48.588538  4581 net.cpp:84] Creating Layer BatchNorm13
I0928 13:46:48.588543  4581 net.cpp:406] BatchNorm13 <- Convolution13
I0928 13:46:48.588549  4581 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0928 13:46:48.588683  4581 net.cpp:122] Setting up BatchNorm13
I0928 13:46:48.588690  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.588695  4581 net.cpp:137] Memory required for data: 337120400
I0928 13:46:48.588703  4581 layer_factory.hpp:77] Creating layer Scale13
I0928 13:46:48.588711  4581 net.cpp:84] Creating Layer Scale13
I0928 13:46:48.588716  4581 net.cpp:406] Scale13 <- Convolution13
I0928 13:46:48.588721  4581 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0928 13:46:48.588755  4581 layer_factory.hpp:77] Creating layer Scale13
I0928 13:46:48.588847  4581 net.cpp:122] Setting up Scale13
I0928 13:46:48.588856  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.588861  4581 net.cpp:137] Memory required for data: 342138000
I0928 13:46:48.588870  4581 layer_factory.hpp:77] Creating layer Eltwise6
I0928 13:46:48.588876  4581 net.cpp:84] Creating Layer Eltwise6
I0928 13:46:48.588881  4581 net.cpp:406] Eltwise6 <- Eltwise5_M2PELU11_0_split_1
I0928 13:46:48.588887  4581 net.cpp:406] Eltwise6 <- Convolution13
I0928 13:46:48.588893  4581 net.cpp:380] Eltwise6 -> Eltwise6
I0928 13:46:48.588917  4581 net.cpp:122] Setting up Eltwise6
I0928 13:46:48.588925  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.588930  4581 net.cpp:137] Memory required for data: 347155600
I0928 13:46:48.588934  4581 layer_factory.hpp:77] Creating layer M2PELU13
I0928 13:46:48.588946  4581 net.cpp:84] Creating Layer M2PELU13
I0928 13:46:48.588951  4581 net.cpp:406] M2PELU13 <- Eltwise6
I0928 13:46:48.588958  4581 net.cpp:367] M2PELU13 -> Eltwise6 (in-place)
I0928 13:46:48.589048  4581 net.cpp:122] Setting up M2PELU13
I0928 13:46:48.589056  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.589059  4581 net.cpp:137] Memory required for data: 352173200
I0928 13:46:48.589067  4581 layer_factory.hpp:77] Creating layer Eltwise6_M2PELU13_0_split
I0928 13:46:48.589073  4581 net.cpp:84] Creating Layer Eltwise6_M2PELU13_0_split
I0928 13:46:48.589078  4581 net.cpp:406] Eltwise6_M2PELU13_0_split <- Eltwise6
I0928 13:46:48.589087  4581 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_0
I0928 13:46:48.589093  4581 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_1
I0928 13:46:48.589121  4581 net.cpp:122] Setting up Eltwise6_M2PELU13_0_split
I0928 13:46:48.589128  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.589134  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.589138  4581 net.cpp:137] Memory required for data: 362208400
I0928 13:46:48.589140  4581 layer_factory.hpp:77] Creating layer Convolution14
I0928 13:46:48.589148  4581 net.cpp:84] Creating Layer Convolution14
I0928 13:46:48.589149  4581 net.cpp:406] Convolution14 <- Eltwise6_M2PELU13_0_split_0
I0928 13:46:48.589154  4581 net.cpp:380] Convolution14 -> Convolution14
I0928 13:46:48.590020  4581 net.cpp:122] Setting up Convolution14
I0928 13:46:48.590029  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.590031  4581 net.cpp:137] Memory required for data: 367226000
I0928 13:46:48.590035  4581 layer_factory.hpp:77] Creating layer BatchNorm14
I0928 13:46:48.590041  4581 net.cpp:84] Creating Layer BatchNorm14
I0928 13:46:48.590044  4581 net.cpp:406] BatchNorm14 <- Convolution14
I0928 13:46:48.590049  4581 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0928 13:46:48.590179  4581 net.cpp:122] Setting up BatchNorm14
I0928 13:46:48.590183  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.590185  4581 net.cpp:137] Memory required for data: 372243600
I0928 13:46:48.590190  4581 layer_factory.hpp:77] Creating layer Scale14
I0928 13:46:48.590194  4581 net.cpp:84] Creating Layer Scale14
I0928 13:46:48.590196  4581 net.cpp:406] Scale14 <- Convolution14
I0928 13:46:48.590199  4581 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0928 13:46:48.590225  4581 layer_factory.hpp:77] Creating layer Scale14
I0928 13:46:48.590301  4581 net.cpp:122] Setting up Scale14
I0928 13:46:48.590306  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.590307  4581 net.cpp:137] Memory required for data: 377261200
I0928 13:46:48.590311  4581 layer_factory.hpp:77] Creating layer M2PELU14
I0928 13:46:48.590315  4581 net.cpp:84] Creating Layer M2PELU14
I0928 13:46:48.590317  4581 net.cpp:406] M2PELU14 <- Convolution14
I0928 13:46:48.590322  4581 net.cpp:367] M2PELU14 -> Convolution14 (in-place)
I0928 13:46:48.590405  4581 net.cpp:122] Setting up M2PELU14
I0928 13:46:48.590410  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.590412  4581 net.cpp:137] Memory required for data: 382278800
I0928 13:46:48.590421  4581 layer_factory.hpp:77] Creating layer Convolution15
I0928 13:46:48.590428  4581 net.cpp:84] Creating Layer Convolution15
I0928 13:46:48.590431  4581 net.cpp:406] Convolution15 <- Convolution14
I0928 13:46:48.590435  4581 net.cpp:380] Convolution15 -> Convolution15
I0928 13:46:48.591346  4581 net.cpp:122] Setting up Convolution15
I0928 13:46:48.591354  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.591356  4581 net.cpp:137] Memory required for data: 387296400
I0928 13:46:48.591361  4581 layer_factory.hpp:77] Creating layer BatchNorm15
I0928 13:46:48.591367  4581 net.cpp:84] Creating Layer BatchNorm15
I0928 13:46:48.591370  4581 net.cpp:406] BatchNorm15 <- Convolution15
I0928 13:46:48.591374  4581 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0928 13:46:48.591503  4581 net.cpp:122] Setting up BatchNorm15
I0928 13:46:48.591508  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.591511  4581 net.cpp:137] Memory required for data: 392314000
I0928 13:46:48.591524  4581 layer_factory.hpp:77] Creating layer Scale15
I0928 13:46:48.591529  4581 net.cpp:84] Creating Layer Scale15
I0928 13:46:48.591531  4581 net.cpp:406] Scale15 <- Convolution15
I0928 13:46:48.591534  4581 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0928 13:46:48.591560  4581 layer_factory.hpp:77] Creating layer Scale15
I0928 13:46:48.591634  4581 net.cpp:122] Setting up Scale15
I0928 13:46:48.591639  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.591640  4581 net.cpp:137] Memory required for data: 397331600
I0928 13:46:48.591645  4581 layer_factory.hpp:77] Creating layer Eltwise7
I0928 13:46:48.591648  4581 net.cpp:84] Creating Layer Eltwise7
I0928 13:46:48.591650  4581 net.cpp:406] Eltwise7 <- Eltwise6_M2PELU13_0_split_1
I0928 13:46:48.591653  4581 net.cpp:406] Eltwise7 <- Convolution15
I0928 13:46:48.591657  4581 net.cpp:380] Eltwise7 -> Eltwise7
I0928 13:46:48.591673  4581 net.cpp:122] Setting up Eltwise7
I0928 13:46:48.591676  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.591678  4581 net.cpp:137] Memory required for data: 402349200
I0928 13:46:48.591681  4581 layer_factory.hpp:77] Creating layer M2PELU15
I0928 13:46:48.591686  4581 net.cpp:84] Creating Layer M2PELU15
I0928 13:46:48.591687  4581 net.cpp:406] M2PELU15 <- Eltwise7
I0928 13:46:48.591691  4581 net.cpp:367] M2PELU15 -> Eltwise7 (in-place)
I0928 13:46:48.591774  4581 net.cpp:122] Setting up M2PELU15
I0928 13:46:48.591778  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.591780  4581 net.cpp:137] Memory required for data: 407366800
I0928 13:46:48.591784  4581 layer_factory.hpp:77] Creating layer Eltwise7_M2PELU15_0_split
I0928 13:46:48.591789  4581 net.cpp:84] Creating Layer Eltwise7_M2PELU15_0_split
I0928 13:46:48.591790  4581 net.cpp:406] Eltwise7_M2PELU15_0_split <- Eltwise7
I0928 13:46:48.591794  4581 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_0
I0928 13:46:48.591797  4581 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_1
I0928 13:46:48.591820  4581 net.cpp:122] Setting up Eltwise7_M2PELU15_0_split
I0928 13:46:48.591822  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.591825  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.591827  4581 net.cpp:137] Memory required for data: 417402000
I0928 13:46:48.591830  4581 layer_factory.hpp:77] Creating layer Convolution16
I0928 13:46:48.591835  4581 net.cpp:84] Creating Layer Convolution16
I0928 13:46:48.591837  4581 net.cpp:406] Convolution16 <- Eltwise7_M2PELU15_0_split_0
I0928 13:46:48.591842  4581 net.cpp:380] Convolution16 -> Convolution16
I0928 13:46:48.592695  4581 net.cpp:122] Setting up Convolution16
I0928 13:46:48.592703  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.592705  4581 net.cpp:137] Memory required for data: 422419600
I0928 13:46:48.592710  4581 layer_factory.hpp:77] Creating layer BatchNorm16
I0928 13:46:48.592715  4581 net.cpp:84] Creating Layer BatchNorm16
I0928 13:46:48.592717  4581 net.cpp:406] BatchNorm16 <- Convolution16
I0928 13:46:48.592727  4581 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0928 13:46:48.592857  4581 net.cpp:122] Setting up BatchNorm16
I0928 13:46:48.592862  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.592864  4581 net.cpp:137] Memory required for data: 427437200
I0928 13:46:48.592869  4581 layer_factory.hpp:77] Creating layer Scale16
I0928 13:46:48.592874  4581 net.cpp:84] Creating Layer Scale16
I0928 13:46:48.592875  4581 net.cpp:406] Scale16 <- Convolution16
I0928 13:46:48.592878  4581 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0928 13:46:48.592905  4581 layer_factory.hpp:77] Creating layer Scale16
I0928 13:46:48.592979  4581 net.cpp:122] Setting up Scale16
I0928 13:46:48.592984  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.592986  4581 net.cpp:137] Memory required for data: 432454800
I0928 13:46:48.592990  4581 layer_factory.hpp:77] Creating layer M2PELU16
I0928 13:46:48.592994  4581 net.cpp:84] Creating Layer M2PELU16
I0928 13:46:48.592998  4581 net.cpp:406] M2PELU16 <- Convolution16
I0928 13:46:48.593000  4581 net.cpp:367] M2PELU16 -> Convolution16 (in-place)
I0928 13:46:48.593085  4581 net.cpp:122] Setting up M2PELU16
I0928 13:46:48.593088  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.593091  4581 net.cpp:137] Memory required for data: 437472400
I0928 13:46:48.593093  4581 layer_factory.hpp:77] Creating layer Convolution17
I0928 13:46:48.593101  4581 net.cpp:84] Creating Layer Convolution17
I0928 13:46:48.593102  4581 net.cpp:406] Convolution17 <- Convolution16
I0928 13:46:48.593107  4581 net.cpp:380] Convolution17 -> Convolution17
I0928 13:46:48.593650  4581 net.cpp:122] Setting up Convolution17
I0928 13:46:48.593657  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.593660  4581 net.cpp:137] Memory required for data: 442490000
I0928 13:46:48.593664  4581 layer_factory.hpp:77] Creating layer BatchNorm17
I0928 13:46:48.593669  4581 net.cpp:84] Creating Layer BatchNorm17
I0928 13:46:48.593672  4581 net.cpp:406] BatchNorm17 <- Convolution17
I0928 13:46:48.593675  4581 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0928 13:46:48.593804  4581 net.cpp:122] Setting up BatchNorm17
I0928 13:46:48.593808  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.593811  4581 net.cpp:137] Memory required for data: 447507600
I0928 13:46:48.593816  4581 layer_factory.hpp:77] Creating layer Scale17
I0928 13:46:48.593819  4581 net.cpp:84] Creating Layer Scale17
I0928 13:46:48.593822  4581 net.cpp:406] Scale17 <- Convolution17
I0928 13:46:48.593824  4581 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0928 13:46:48.593849  4581 layer_factory.hpp:77] Creating layer Scale17
I0928 13:46:48.593924  4581 net.cpp:122] Setting up Scale17
I0928 13:46:48.593927  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.593930  4581 net.cpp:137] Memory required for data: 452525200
I0928 13:46:48.593933  4581 layer_factory.hpp:77] Creating layer Eltwise8
I0928 13:46:48.593937  4581 net.cpp:84] Creating Layer Eltwise8
I0928 13:46:48.593940  4581 net.cpp:406] Eltwise8 <- Eltwise7_M2PELU15_0_split_1
I0928 13:46:48.593943  4581 net.cpp:406] Eltwise8 <- Convolution17
I0928 13:46:48.593946  4581 net.cpp:380] Eltwise8 -> Eltwise8
I0928 13:46:48.593961  4581 net.cpp:122] Setting up Eltwise8
I0928 13:46:48.593964  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.593966  4581 net.cpp:137] Memory required for data: 457542800
I0928 13:46:48.593968  4581 layer_factory.hpp:77] Creating layer M2PELU17
I0928 13:46:48.593973  4581 net.cpp:84] Creating Layer M2PELU17
I0928 13:46:48.593976  4581 net.cpp:406] M2PELU17 <- Eltwise8
I0928 13:46:48.593978  4581 net.cpp:367] M2PELU17 -> Eltwise8 (in-place)
I0928 13:46:48.594061  4581 net.cpp:122] Setting up M2PELU17
I0928 13:46:48.594066  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.594069  4581 net.cpp:137] Memory required for data: 462560400
I0928 13:46:48.594071  4581 layer_factory.hpp:77] Creating layer Eltwise8_M2PELU17_0_split
I0928 13:46:48.594081  4581 net.cpp:84] Creating Layer Eltwise8_M2PELU17_0_split
I0928 13:46:48.594084  4581 net.cpp:406] Eltwise8_M2PELU17_0_split <- Eltwise8
I0928 13:46:48.594087  4581 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_0
I0928 13:46:48.594090  4581 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_1
I0928 13:46:48.594115  4581 net.cpp:122] Setting up Eltwise8_M2PELU17_0_split
I0928 13:46:48.594117  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.594120  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.594122  4581 net.cpp:137] Memory required for data: 472595600
I0928 13:46:48.594125  4581 layer_factory.hpp:77] Creating layer Convolution18
I0928 13:46:48.594131  4581 net.cpp:84] Creating Layer Convolution18
I0928 13:46:48.594133  4581 net.cpp:406] Convolution18 <- Eltwise8_M2PELU17_0_split_0
I0928 13:46:48.594137  4581 net.cpp:380] Convolution18 -> Convolution18
I0928 13:46:48.595016  4581 net.cpp:122] Setting up Convolution18
I0928 13:46:48.595026  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.595027  4581 net.cpp:137] Memory required for data: 477613200
I0928 13:46:48.595031  4581 layer_factory.hpp:77] Creating layer BatchNorm18
I0928 13:46:48.595036  4581 net.cpp:84] Creating Layer BatchNorm18
I0928 13:46:48.595039  4581 net.cpp:406] BatchNorm18 <- Convolution18
I0928 13:46:48.595043  4581 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0928 13:46:48.595172  4581 net.cpp:122] Setting up BatchNorm18
I0928 13:46:48.595177  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.595180  4581 net.cpp:137] Memory required for data: 482630800
I0928 13:46:48.595185  4581 layer_factory.hpp:77] Creating layer Scale18
I0928 13:46:48.595188  4581 net.cpp:84] Creating Layer Scale18
I0928 13:46:48.595191  4581 net.cpp:406] Scale18 <- Convolution18
I0928 13:46:48.595194  4581 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0928 13:46:48.595219  4581 layer_factory.hpp:77] Creating layer Scale18
I0928 13:46:48.595296  4581 net.cpp:122] Setting up Scale18
I0928 13:46:48.595301  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.595304  4581 net.cpp:137] Memory required for data: 487648400
I0928 13:46:48.595306  4581 layer_factory.hpp:77] Creating layer M2PELU18
I0928 13:46:48.595311  4581 net.cpp:84] Creating Layer M2PELU18
I0928 13:46:48.595314  4581 net.cpp:406] M2PELU18 <- Convolution18
I0928 13:46:48.595317  4581 net.cpp:367] M2PELU18 -> Convolution18 (in-place)
I0928 13:46:48.595399  4581 net.cpp:122] Setting up M2PELU18
I0928 13:46:48.595404  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.595407  4581 net.cpp:137] Memory required for data: 492666000
I0928 13:46:48.595409  4581 layer_factory.hpp:77] Creating layer Convolution19
I0928 13:46:48.595417  4581 net.cpp:84] Creating Layer Convolution19
I0928 13:46:48.595418  4581 net.cpp:406] Convolution19 <- Convolution18
I0928 13:46:48.595422  4581 net.cpp:380] Convolution19 -> Convolution19
I0928 13:46:48.596297  4581 net.cpp:122] Setting up Convolution19
I0928 13:46:48.596307  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.596308  4581 net.cpp:137] Memory required for data: 497683600
I0928 13:46:48.596312  4581 layer_factory.hpp:77] Creating layer BatchNorm19
I0928 13:46:48.596318  4581 net.cpp:84] Creating Layer BatchNorm19
I0928 13:46:48.596320  4581 net.cpp:406] BatchNorm19 <- Convolution19
I0928 13:46:48.596323  4581 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0928 13:46:48.596503  4581 net.cpp:122] Setting up BatchNorm19
I0928 13:46:48.596509  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.596511  4581 net.cpp:137] Memory required for data: 502701200
I0928 13:46:48.596516  4581 layer_factory.hpp:77] Creating layer Scale19
I0928 13:46:48.596521  4581 net.cpp:84] Creating Layer Scale19
I0928 13:46:48.596524  4581 net.cpp:406] Scale19 <- Convolution19
I0928 13:46:48.596526  4581 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0928 13:46:48.596562  4581 layer_factory.hpp:77] Creating layer Scale19
I0928 13:46:48.596642  4581 net.cpp:122] Setting up Scale19
I0928 13:46:48.596647  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.596648  4581 net.cpp:137] Memory required for data: 507718800
I0928 13:46:48.596652  4581 layer_factory.hpp:77] Creating layer Eltwise9
I0928 13:46:48.596657  4581 net.cpp:84] Creating Layer Eltwise9
I0928 13:46:48.596659  4581 net.cpp:406] Eltwise9 <- Eltwise8_M2PELU17_0_split_1
I0928 13:46:48.596662  4581 net.cpp:406] Eltwise9 <- Convolution19
I0928 13:46:48.596665  4581 net.cpp:380] Eltwise9 -> Eltwise9
I0928 13:46:48.596681  4581 net.cpp:122] Setting up Eltwise9
I0928 13:46:48.596685  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.596688  4581 net.cpp:137] Memory required for data: 512736400
I0928 13:46:48.596689  4581 layer_factory.hpp:77] Creating layer M2PELU19
I0928 13:46:48.596694  4581 net.cpp:84] Creating Layer M2PELU19
I0928 13:46:48.596696  4581 net.cpp:406] M2PELU19 <- Eltwise9
I0928 13:46:48.596699  4581 net.cpp:367] M2PELU19 -> Eltwise9 (in-place)
I0928 13:46:48.596786  4581 net.cpp:122] Setting up M2PELU19
I0928 13:46:48.596789  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.596791  4581 net.cpp:137] Memory required for data: 517754000
I0928 13:46:48.596796  4581 layer_factory.hpp:77] Creating layer Eltwise9_M2PELU19_0_split
I0928 13:46:48.596799  4581 net.cpp:84] Creating Layer Eltwise9_M2PELU19_0_split
I0928 13:46:48.596801  4581 net.cpp:406] Eltwise9_M2PELU19_0_split <- Eltwise9
I0928 13:46:48.596804  4581 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_0
I0928 13:46:48.596808  4581 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_1
I0928 13:46:48.596832  4581 net.cpp:122] Setting up Eltwise9_M2PELU19_0_split
I0928 13:46:48.596835  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.596838  4581 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 13:46:48.596840  4581 net.cpp:137] Memory required for data: 527789200
I0928 13:46:48.596843  4581 layer_factory.hpp:77] Creating layer Convolution20
I0928 13:46:48.596850  4581 net.cpp:84] Creating Layer Convolution20
I0928 13:46:48.596853  4581 net.cpp:406] Convolution20 <- Eltwise9_M2PELU19_0_split_0
I0928 13:46:48.596856  4581 net.cpp:380] Convolution20 -> Convolution20
I0928 13:46:48.598115  4581 net.cpp:122] Setting up Convolution20
I0928 13:46:48.598124  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.598127  4581 net.cpp:137] Memory required for data: 530298000
I0928 13:46:48.598132  4581 layer_factory.hpp:77] Creating layer BatchNorm20
I0928 13:46:48.598137  4581 net.cpp:84] Creating Layer BatchNorm20
I0928 13:46:48.598140  4581 net.cpp:406] BatchNorm20 <- Convolution20
I0928 13:46:48.598145  4581 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0928 13:46:48.598291  4581 net.cpp:122] Setting up BatchNorm20
I0928 13:46:48.598295  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.598297  4581 net.cpp:137] Memory required for data: 532806800
I0928 13:46:48.598302  4581 layer_factory.hpp:77] Creating layer Scale20
I0928 13:46:48.598307  4581 net.cpp:84] Creating Layer Scale20
I0928 13:46:48.598309  4581 net.cpp:406] Scale20 <- Convolution20
I0928 13:46:48.598314  4581 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0928 13:46:48.598340  4581 layer_factory.hpp:77] Creating layer Scale20
I0928 13:46:48.598418  4581 net.cpp:122] Setting up Scale20
I0928 13:46:48.598423  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.598425  4581 net.cpp:137] Memory required for data: 535315600
I0928 13:46:48.598429  4581 layer_factory.hpp:77] Creating layer Convolution21
I0928 13:46:48.598436  4581 net.cpp:84] Creating Layer Convolution21
I0928 13:46:48.598439  4581 net.cpp:406] Convolution21 <- Eltwise9_M2PELU19_0_split_1
I0928 13:46:48.598443  4581 net.cpp:380] Convolution21 -> Convolution21
I0928 13:46:48.600162  4581 net.cpp:122] Setting up Convolution21
I0928 13:46:48.600170  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.600180  4581 net.cpp:137] Memory required for data: 537824400
I0928 13:46:48.600186  4581 layer_factory.hpp:77] Creating layer BatchNorm21
I0928 13:46:48.600193  4581 net.cpp:84] Creating Layer BatchNorm21
I0928 13:46:48.600195  4581 net.cpp:406] BatchNorm21 <- Convolution21
I0928 13:46:48.600198  4581 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0928 13:46:48.600342  4581 net.cpp:122] Setting up BatchNorm21
I0928 13:46:48.600345  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.600348  4581 net.cpp:137] Memory required for data: 540333200
I0928 13:46:48.600353  4581 layer_factory.hpp:77] Creating layer Scale21
I0928 13:46:48.600358  4581 net.cpp:84] Creating Layer Scale21
I0928 13:46:48.600360  4581 net.cpp:406] Scale21 <- Convolution21
I0928 13:46:48.600363  4581 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0928 13:46:48.600391  4581 layer_factory.hpp:77] Creating layer Scale21
I0928 13:46:48.600471  4581 net.cpp:122] Setting up Scale21
I0928 13:46:48.600474  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.600477  4581 net.cpp:137] Memory required for data: 542842000
I0928 13:46:48.600481  4581 layer_factory.hpp:77] Creating layer M2PELU20
I0928 13:46:48.600486  4581 net.cpp:84] Creating Layer M2PELU20
I0928 13:46:48.600489  4581 net.cpp:406] M2PELU20 <- Convolution21
I0928 13:46:48.600492  4581 net.cpp:367] M2PELU20 -> Convolution21 (in-place)
I0928 13:46:48.600586  4581 net.cpp:122] Setting up M2PELU20
I0928 13:46:48.600591  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.600594  4581 net.cpp:137] Memory required for data: 545350800
I0928 13:46:48.600596  4581 layer_factory.hpp:77] Creating layer Convolution22
I0928 13:46:48.600603  4581 net.cpp:84] Creating Layer Convolution22
I0928 13:46:48.600605  4581 net.cpp:406] Convolution22 <- Convolution21
I0928 13:46:48.600610  4581 net.cpp:380] Convolution22 -> Convolution22
I0928 13:46:48.601670  4581 net.cpp:122] Setting up Convolution22
I0928 13:46:48.601678  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.601681  4581 net.cpp:137] Memory required for data: 547859600
I0928 13:46:48.601686  4581 layer_factory.hpp:77] Creating layer BatchNorm22
I0928 13:46:48.601691  4581 net.cpp:84] Creating Layer BatchNorm22
I0928 13:46:48.601693  4581 net.cpp:406] BatchNorm22 <- Convolution22
I0928 13:46:48.601697  4581 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0928 13:46:48.601833  4581 net.cpp:122] Setting up BatchNorm22
I0928 13:46:48.601837  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.601840  4581 net.cpp:137] Memory required for data: 550368400
I0928 13:46:48.601845  4581 layer_factory.hpp:77] Creating layer Scale22
I0928 13:46:48.601848  4581 net.cpp:84] Creating Layer Scale22
I0928 13:46:48.601851  4581 net.cpp:406] Scale22 <- Convolution22
I0928 13:46:48.601855  4581 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0928 13:46:48.601881  4581 layer_factory.hpp:77] Creating layer Scale22
I0928 13:46:48.601956  4581 net.cpp:122] Setting up Scale22
I0928 13:46:48.601960  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.601963  4581 net.cpp:137] Memory required for data: 552877200
I0928 13:46:48.601966  4581 layer_factory.hpp:77] Creating layer Eltwise10
I0928 13:46:48.601971  4581 net.cpp:84] Creating Layer Eltwise10
I0928 13:46:48.601974  4581 net.cpp:406] Eltwise10 <- Convolution20
I0928 13:46:48.601976  4581 net.cpp:406] Eltwise10 <- Convolution22
I0928 13:46:48.601980  4581 net.cpp:380] Eltwise10 -> Eltwise10
I0928 13:46:48.601995  4581 net.cpp:122] Setting up Eltwise10
I0928 13:46:48.601999  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.602000  4581 net.cpp:137] Memory required for data: 555386000
I0928 13:46:48.602002  4581 layer_factory.hpp:77] Creating layer M2PELU21
I0928 13:46:48.602007  4581 net.cpp:84] Creating Layer M2PELU21
I0928 13:46:48.602010  4581 net.cpp:406] M2PELU21 <- Eltwise10
I0928 13:46:48.602013  4581 net.cpp:367] M2PELU21 -> Eltwise10 (in-place)
I0928 13:46:48.602097  4581 net.cpp:122] Setting up M2PELU21
I0928 13:46:48.602108  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.602109  4581 net.cpp:137] Memory required for data: 557894800
I0928 13:46:48.602113  4581 layer_factory.hpp:77] Creating layer Eltwise10_M2PELU21_0_split
I0928 13:46:48.602118  4581 net.cpp:84] Creating Layer Eltwise10_M2PELU21_0_split
I0928 13:46:48.602119  4581 net.cpp:406] Eltwise10_M2PELU21_0_split <- Eltwise10
I0928 13:46:48.602123  4581 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_0
I0928 13:46:48.602126  4581 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_1
I0928 13:46:48.602151  4581 net.cpp:122] Setting up Eltwise10_M2PELU21_0_split
I0928 13:46:48.602155  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.602157  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.602159  4581 net.cpp:137] Memory required for data: 562912400
I0928 13:46:48.602161  4581 layer_factory.hpp:77] Creating layer Convolution23
I0928 13:46:48.602169  4581 net.cpp:84] Creating Layer Convolution23
I0928 13:46:48.602170  4581 net.cpp:406] Convolution23 <- Eltwise10_M2PELU21_0_split_0
I0928 13:46:48.602174  4581 net.cpp:380] Convolution23 -> Convolution23
I0928 13:46:48.603544  4581 net.cpp:122] Setting up Convolution23
I0928 13:46:48.603554  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.603556  4581 net.cpp:137] Memory required for data: 565421200
I0928 13:46:48.603561  4581 layer_factory.hpp:77] Creating layer BatchNorm23
I0928 13:46:48.603566  4581 net.cpp:84] Creating Layer BatchNorm23
I0928 13:46:48.603569  4581 net.cpp:406] BatchNorm23 <- Convolution23
I0928 13:46:48.603574  4581 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0928 13:46:48.603713  4581 net.cpp:122] Setting up BatchNorm23
I0928 13:46:48.603716  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.603718  4581 net.cpp:137] Memory required for data: 567930000
I0928 13:46:48.603724  4581 layer_factory.hpp:77] Creating layer Scale23
I0928 13:46:48.603727  4581 net.cpp:84] Creating Layer Scale23
I0928 13:46:48.603730  4581 net.cpp:406] Scale23 <- Convolution23
I0928 13:46:48.603734  4581 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0928 13:46:48.603761  4581 layer_factory.hpp:77] Creating layer Scale23
I0928 13:46:48.603840  4581 net.cpp:122] Setting up Scale23
I0928 13:46:48.603845  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.603847  4581 net.cpp:137] Memory required for data: 570438800
I0928 13:46:48.603852  4581 layer_factory.hpp:77] Creating layer M2PELU22
I0928 13:46:48.603857  4581 net.cpp:84] Creating Layer M2PELU22
I0928 13:46:48.603858  4581 net.cpp:406] M2PELU22 <- Convolution23
I0928 13:46:48.603863  4581 net.cpp:367] M2PELU22 -> Convolution23 (in-place)
I0928 13:46:48.603946  4581 net.cpp:122] Setting up M2PELU22
I0928 13:46:48.603950  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.603952  4581 net.cpp:137] Memory required for data: 572947600
I0928 13:46:48.603956  4581 layer_factory.hpp:77] Creating layer Convolution24
I0928 13:46:48.603963  4581 net.cpp:84] Creating Layer Convolution24
I0928 13:46:48.603965  4581 net.cpp:406] Convolution24 <- Convolution23
I0928 13:46:48.603970  4581 net.cpp:380] Convolution24 -> Convolution24
I0928 13:46:48.605027  4581 net.cpp:122] Setting up Convolution24
I0928 13:46:48.605036  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.605038  4581 net.cpp:137] Memory required for data: 575456400
I0928 13:46:48.605043  4581 layer_factory.hpp:77] Creating layer BatchNorm24
I0928 13:46:48.605049  4581 net.cpp:84] Creating Layer BatchNorm24
I0928 13:46:48.605051  4581 net.cpp:406] BatchNorm24 <- Convolution24
I0928 13:46:48.605056  4581 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0928 13:46:48.605193  4581 net.cpp:122] Setting up BatchNorm24
I0928 13:46:48.605197  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.605199  4581 net.cpp:137] Memory required for data: 577965200
I0928 13:46:48.605204  4581 layer_factory.hpp:77] Creating layer Scale24
I0928 13:46:48.605216  4581 net.cpp:84] Creating Layer Scale24
I0928 13:46:48.605218  4581 net.cpp:406] Scale24 <- Convolution24
I0928 13:46:48.605221  4581 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0928 13:46:48.605249  4581 layer_factory.hpp:77] Creating layer Scale24
I0928 13:46:48.605327  4581 net.cpp:122] Setting up Scale24
I0928 13:46:48.605332  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.605334  4581 net.cpp:137] Memory required for data: 580474000
I0928 13:46:48.605339  4581 layer_factory.hpp:77] Creating layer Eltwise11
I0928 13:46:48.605342  4581 net.cpp:84] Creating Layer Eltwise11
I0928 13:46:48.605345  4581 net.cpp:406] Eltwise11 <- Eltwise10_M2PELU21_0_split_1
I0928 13:46:48.605347  4581 net.cpp:406] Eltwise11 <- Convolution24
I0928 13:46:48.605351  4581 net.cpp:380] Eltwise11 -> Eltwise11
I0928 13:46:48.605367  4581 net.cpp:122] Setting up Eltwise11
I0928 13:46:48.605370  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.605372  4581 net.cpp:137] Memory required for data: 582982800
I0928 13:46:48.605376  4581 layer_factory.hpp:77] Creating layer M2PELU23
I0928 13:46:48.605381  4581 net.cpp:84] Creating Layer M2PELU23
I0928 13:46:48.605382  4581 net.cpp:406] M2PELU23 <- Eltwise11
I0928 13:46:48.605386  4581 net.cpp:367] M2PELU23 -> Eltwise11 (in-place)
I0928 13:46:48.605471  4581 net.cpp:122] Setting up M2PELU23
I0928 13:46:48.605475  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.605478  4581 net.cpp:137] Memory required for data: 585491600
I0928 13:46:48.605481  4581 layer_factory.hpp:77] Creating layer Eltwise11_M2PELU23_0_split
I0928 13:46:48.605485  4581 net.cpp:84] Creating Layer Eltwise11_M2PELU23_0_split
I0928 13:46:48.605487  4581 net.cpp:406] Eltwise11_M2PELU23_0_split <- Eltwise11
I0928 13:46:48.605491  4581 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_0
I0928 13:46:48.605495  4581 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_1
I0928 13:46:48.605518  4581 net.cpp:122] Setting up Eltwise11_M2PELU23_0_split
I0928 13:46:48.605522  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.605525  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.605526  4581 net.cpp:137] Memory required for data: 590509200
I0928 13:46:48.605530  4581 layer_factory.hpp:77] Creating layer Convolution25
I0928 13:46:48.605535  4581 net.cpp:84] Creating Layer Convolution25
I0928 13:46:48.605537  4581 net.cpp:406] Convolution25 <- Eltwise11_M2PELU23_0_split_0
I0928 13:46:48.605541  4581 net.cpp:380] Convolution25 -> Convolution25
I0928 13:46:48.606606  4581 net.cpp:122] Setting up Convolution25
I0928 13:46:48.606614  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.606616  4581 net.cpp:137] Memory required for data: 593018000
I0928 13:46:48.606621  4581 layer_factory.hpp:77] Creating layer BatchNorm25
I0928 13:46:48.606626  4581 net.cpp:84] Creating Layer BatchNorm25
I0928 13:46:48.606628  4581 net.cpp:406] BatchNorm25 <- Convolution25
I0928 13:46:48.606632  4581 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0928 13:46:48.606767  4581 net.cpp:122] Setting up BatchNorm25
I0928 13:46:48.606772  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.606775  4581 net.cpp:137] Memory required for data: 595526800
I0928 13:46:48.606779  4581 layer_factory.hpp:77] Creating layer Scale25
I0928 13:46:48.606783  4581 net.cpp:84] Creating Layer Scale25
I0928 13:46:48.606786  4581 net.cpp:406] Scale25 <- Convolution25
I0928 13:46:48.606788  4581 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0928 13:46:48.606815  4581 layer_factory.hpp:77] Creating layer Scale25
I0928 13:46:48.606891  4581 net.cpp:122] Setting up Scale25
I0928 13:46:48.606896  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.606899  4581 net.cpp:137] Memory required for data: 598035600
I0928 13:46:48.606902  4581 layer_factory.hpp:77] Creating layer M2PELU24
I0928 13:46:48.606906  4581 net.cpp:84] Creating Layer M2PELU24
I0928 13:46:48.606909  4581 net.cpp:406] M2PELU24 <- Convolution25
I0928 13:46:48.606920  4581 net.cpp:367] M2PELU24 -> Convolution25 (in-place)
I0928 13:46:48.607004  4581 net.cpp:122] Setting up M2PELU24
I0928 13:46:48.607008  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.607010  4581 net.cpp:137] Memory required for data: 600544400
I0928 13:46:48.607014  4581 layer_factory.hpp:77] Creating layer Convolution26
I0928 13:46:48.607020  4581 net.cpp:84] Creating Layer Convolution26
I0928 13:46:48.607023  4581 net.cpp:406] Convolution26 <- Convolution25
I0928 13:46:48.607028  4581 net.cpp:380] Convolution26 -> Convolution26
I0928 13:46:48.608054  4581 net.cpp:122] Setting up Convolution26
I0928 13:46:48.608063  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.608065  4581 net.cpp:137] Memory required for data: 603053200
I0928 13:46:48.608070  4581 layer_factory.hpp:77] Creating layer BatchNorm26
I0928 13:46:48.608075  4581 net.cpp:84] Creating Layer BatchNorm26
I0928 13:46:48.608078  4581 net.cpp:406] BatchNorm26 <- Convolution26
I0928 13:46:48.608083  4581 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0928 13:46:48.608217  4581 net.cpp:122] Setting up BatchNorm26
I0928 13:46:48.608222  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.608223  4581 net.cpp:137] Memory required for data: 605562000
I0928 13:46:48.608228  4581 layer_factory.hpp:77] Creating layer Scale26
I0928 13:46:48.608232  4581 net.cpp:84] Creating Layer Scale26
I0928 13:46:48.608235  4581 net.cpp:406] Scale26 <- Convolution26
I0928 13:46:48.608238  4581 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0928 13:46:48.608264  4581 layer_factory.hpp:77] Creating layer Scale26
I0928 13:46:48.608340  4581 net.cpp:122] Setting up Scale26
I0928 13:46:48.608345  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.608347  4581 net.cpp:137] Memory required for data: 608070800
I0928 13:46:48.608350  4581 layer_factory.hpp:77] Creating layer Eltwise12
I0928 13:46:48.608355  4581 net.cpp:84] Creating Layer Eltwise12
I0928 13:46:48.608357  4581 net.cpp:406] Eltwise12 <- Eltwise11_M2PELU23_0_split_1
I0928 13:46:48.608361  4581 net.cpp:406] Eltwise12 <- Convolution26
I0928 13:46:48.608363  4581 net.cpp:380] Eltwise12 -> Eltwise12
I0928 13:46:48.608379  4581 net.cpp:122] Setting up Eltwise12
I0928 13:46:48.608383  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.608386  4581 net.cpp:137] Memory required for data: 610579600
I0928 13:46:48.608387  4581 layer_factory.hpp:77] Creating layer M2PELU25
I0928 13:46:48.608392  4581 net.cpp:84] Creating Layer M2PELU25
I0928 13:46:48.608394  4581 net.cpp:406] M2PELU25 <- Eltwise12
I0928 13:46:48.608397  4581 net.cpp:367] M2PELU25 -> Eltwise12 (in-place)
I0928 13:46:48.608480  4581 net.cpp:122] Setting up M2PELU25
I0928 13:46:48.608484  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.608486  4581 net.cpp:137] Memory required for data: 613088400
I0928 13:46:48.608490  4581 layer_factory.hpp:77] Creating layer Eltwise12_M2PELU25_0_split
I0928 13:46:48.608502  4581 net.cpp:84] Creating Layer Eltwise12_M2PELU25_0_split
I0928 13:46:48.608505  4581 net.cpp:406] Eltwise12_M2PELU25_0_split <- Eltwise12
I0928 13:46:48.608508  4581 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_0
I0928 13:46:48.608516  4581 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_1
I0928 13:46:48.608541  4581 net.cpp:122] Setting up Eltwise12_M2PELU25_0_split
I0928 13:46:48.608546  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.608548  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.608551  4581 net.cpp:137] Memory required for data: 618106000
I0928 13:46:48.608553  4581 layer_factory.hpp:77] Creating layer Convolution27
I0928 13:46:48.608559  4581 net.cpp:84] Creating Layer Convolution27
I0928 13:46:48.608562  4581 net.cpp:406] Convolution27 <- Eltwise12_M2PELU25_0_split_0
I0928 13:46:48.608566  4581 net.cpp:380] Convolution27 -> Convolution27
I0928 13:46:48.609267  4581 net.cpp:122] Setting up Convolution27
I0928 13:46:48.609280  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.609282  4581 net.cpp:137] Memory required for data: 620614800
I0928 13:46:48.609287  4581 layer_factory.hpp:77] Creating layer BatchNorm27
I0928 13:46:48.609292  4581 net.cpp:84] Creating Layer BatchNorm27
I0928 13:46:48.609294  4581 net.cpp:406] BatchNorm27 <- Convolution27
I0928 13:46:48.609298  4581 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0928 13:46:48.609433  4581 net.cpp:122] Setting up BatchNorm27
I0928 13:46:48.609437  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.609439  4581 net.cpp:137] Memory required for data: 623123600
I0928 13:46:48.609444  4581 layer_factory.hpp:77] Creating layer Scale27
I0928 13:46:48.609447  4581 net.cpp:84] Creating Layer Scale27
I0928 13:46:48.609449  4581 net.cpp:406] Scale27 <- Convolution27
I0928 13:46:48.609452  4581 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0928 13:46:48.609479  4581 layer_factory.hpp:77] Creating layer Scale27
I0928 13:46:48.609555  4581 net.cpp:122] Setting up Scale27
I0928 13:46:48.609558  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.609560  4581 net.cpp:137] Memory required for data: 625632400
I0928 13:46:48.609563  4581 layer_factory.hpp:77] Creating layer M2PELU26
I0928 13:46:48.609568  4581 net.cpp:84] Creating Layer M2PELU26
I0928 13:46:48.609571  4581 net.cpp:406] M2PELU26 <- Convolution27
I0928 13:46:48.609575  4581 net.cpp:367] M2PELU26 -> Convolution27 (in-place)
I0928 13:46:48.609657  4581 net.cpp:122] Setting up M2PELU26
I0928 13:46:48.609660  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.609663  4581 net.cpp:137] Memory required for data: 628141200
I0928 13:46:48.609666  4581 layer_factory.hpp:77] Creating layer Convolution28
I0928 13:46:48.609673  4581 net.cpp:84] Creating Layer Convolution28
I0928 13:46:48.609675  4581 net.cpp:406] Convolution28 <- Convolution27
I0928 13:46:48.609679  4581 net.cpp:380] Convolution28 -> Convolution28
I0928 13:46:48.610725  4581 net.cpp:122] Setting up Convolution28
I0928 13:46:48.610733  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.610736  4581 net.cpp:137] Memory required for data: 630650000
I0928 13:46:48.610740  4581 layer_factory.hpp:77] Creating layer BatchNorm28
I0928 13:46:48.610745  4581 net.cpp:84] Creating Layer BatchNorm28
I0928 13:46:48.610747  4581 net.cpp:406] BatchNorm28 <- Convolution28
I0928 13:46:48.610752  4581 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0928 13:46:48.610887  4581 net.cpp:122] Setting up BatchNorm28
I0928 13:46:48.610890  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.610893  4581 net.cpp:137] Memory required for data: 633158800
I0928 13:46:48.610898  4581 layer_factory.hpp:77] Creating layer Scale28
I0928 13:46:48.610901  4581 net.cpp:84] Creating Layer Scale28
I0928 13:46:48.610903  4581 net.cpp:406] Scale28 <- Convolution28
I0928 13:46:48.610908  4581 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0928 13:46:48.610934  4581 layer_factory.hpp:77] Creating layer Scale28
I0928 13:46:48.611012  4581 net.cpp:122] Setting up Scale28
I0928 13:46:48.611016  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.611018  4581 net.cpp:137] Memory required for data: 635667600
I0928 13:46:48.611022  4581 layer_factory.hpp:77] Creating layer Eltwise13
I0928 13:46:48.611027  4581 net.cpp:84] Creating Layer Eltwise13
I0928 13:46:48.611029  4581 net.cpp:406] Eltwise13 <- Eltwise12_M2PELU25_0_split_1
I0928 13:46:48.611032  4581 net.cpp:406] Eltwise13 <- Convolution28
I0928 13:46:48.611035  4581 net.cpp:380] Eltwise13 -> Eltwise13
I0928 13:46:48.611052  4581 net.cpp:122] Setting up Eltwise13
I0928 13:46:48.611055  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.611057  4581 net.cpp:137] Memory required for data: 638176400
I0928 13:46:48.611059  4581 layer_factory.hpp:77] Creating layer M2PELU27
I0928 13:46:48.611064  4581 net.cpp:84] Creating Layer M2PELU27
I0928 13:46:48.611066  4581 net.cpp:406] M2PELU27 <- Eltwise13
I0928 13:46:48.611069  4581 net.cpp:367] M2PELU27 -> Eltwise13 (in-place)
I0928 13:46:48.611161  4581 net.cpp:122] Setting up M2PELU27
I0928 13:46:48.611166  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.611168  4581 net.cpp:137] Memory required for data: 640685200
I0928 13:46:48.611171  4581 layer_factory.hpp:77] Creating layer Eltwise13_M2PELU27_0_split
I0928 13:46:48.611176  4581 net.cpp:84] Creating Layer Eltwise13_M2PELU27_0_split
I0928 13:46:48.611177  4581 net.cpp:406] Eltwise13_M2PELU27_0_split <- Eltwise13
I0928 13:46:48.611181  4581 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_0
I0928 13:46:48.611186  4581 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_1
I0928 13:46:48.611208  4581 net.cpp:122] Setting up Eltwise13_M2PELU27_0_split
I0928 13:46:48.611212  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.611214  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.611217  4581 net.cpp:137] Memory required for data: 645702800
I0928 13:46:48.611219  4581 layer_factory.hpp:77] Creating layer Convolution29
I0928 13:46:48.611225  4581 net.cpp:84] Creating Layer Convolution29
I0928 13:46:48.611227  4581 net.cpp:406] Convolution29 <- Eltwise13_M2PELU27_0_split_0
I0928 13:46:48.611232  4581 net.cpp:380] Convolution29 -> Convolution29
I0928 13:46:48.612251  4581 net.cpp:122] Setting up Convolution29
I0928 13:46:48.612260  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.612262  4581 net.cpp:137] Memory required for data: 648211600
I0928 13:46:48.612267  4581 layer_factory.hpp:77] Creating layer BatchNorm29
I0928 13:46:48.612272  4581 net.cpp:84] Creating Layer BatchNorm29
I0928 13:46:48.612275  4581 net.cpp:406] BatchNorm29 <- Convolution29
I0928 13:46:48.612278  4581 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0928 13:46:48.612412  4581 net.cpp:122] Setting up BatchNorm29
I0928 13:46:48.612416  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.612418  4581 net.cpp:137] Memory required for data: 650720400
I0928 13:46:48.612423  4581 layer_factory.hpp:77] Creating layer Scale29
I0928 13:46:48.612427  4581 net.cpp:84] Creating Layer Scale29
I0928 13:46:48.612431  4581 net.cpp:406] Scale29 <- Convolution29
I0928 13:46:48.612433  4581 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0928 13:46:48.612460  4581 layer_factory.hpp:77] Creating layer Scale29
I0928 13:46:48.612536  4581 net.cpp:122] Setting up Scale29
I0928 13:46:48.612540  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.612542  4581 net.cpp:137] Memory required for data: 653229200
I0928 13:46:48.612562  4581 layer_factory.hpp:77] Creating layer M2PELU28
I0928 13:46:48.612568  4581 net.cpp:84] Creating Layer M2PELU28
I0928 13:46:48.612571  4581 net.cpp:406] M2PELU28 <- Convolution29
I0928 13:46:48.612574  4581 net.cpp:367] M2PELU28 -> Convolution29 (in-place)
I0928 13:46:48.612661  4581 net.cpp:122] Setting up M2PELU28
I0928 13:46:48.612665  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.612668  4581 net.cpp:137] Memory required for data: 655738000
I0928 13:46:48.612671  4581 layer_factory.hpp:77] Creating layer Convolution30
I0928 13:46:48.612679  4581 net.cpp:84] Creating Layer Convolution30
I0928 13:46:48.612680  4581 net.cpp:406] Convolution30 <- Convolution29
I0928 13:46:48.612684  4581 net.cpp:380] Convolution30 -> Convolution30
I0928 13:46:48.613715  4581 net.cpp:122] Setting up Convolution30
I0928 13:46:48.613723  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.613726  4581 net.cpp:137] Memory required for data: 658246800
I0928 13:46:48.613730  4581 layer_factory.hpp:77] Creating layer BatchNorm30
I0928 13:46:48.613735  4581 net.cpp:84] Creating Layer BatchNorm30
I0928 13:46:48.613739  4581 net.cpp:406] BatchNorm30 <- Convolution30
I0928 13:46:48.613742  4581 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0928 13:46:48.613878  4581 net.cpp:122] Setting up BatchNorm30
I0928 13:46:48.613881  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.613883  4581 net.cpp:137] Memory required for data: 660755600
I0928 13:46:48.613894  4581 layer_factory.hpp:77] Creating layer Scale30
I0928 13:46:48.613899  4581 net.cpp:84] Creating Layer Scale30
I0928 13:46:48.613901  4581 net.cpp:406] Scale30 <- Convolution30
I0928 13:46:48.613904  4581 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0928 13:46:48.613932  4581 layer_factory.hpp:77] Creating layer Scale30
I0928 13:46:48.614011  4581 net.cpp:122] Setting up Scale30
I0928 13:46:48.614014  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.614017  4581 net.cpp:137] Memory required for data: 663264400
I0928 13:46:48.614020  4581 layer_factory.hpp:77] Creating layer Eltwise14
I0928 13:46:48.614023  4581 net.cpp:84] Creating Layer Eltwise14
I0928 13:46:48.614027  4581 net.cpp:406] Eltwise14 <- Eltwise13_M2PELU27_0_split_1
I0928 13:46:48.614029  4581 net.cpp:406] Eltwise14 <- Convolution30
I0928 13:46:48.614033  4581 net.cpp:380] Eltwise14 -> Eltwise14
I0928 13:46:48.614048  4581 net.cpp:122] Setting up Eltwise14
I0928 13:46:48.614051  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.614053  4581 net.cpp:137] Memory required for data: 665773200
I0928 13:46:48.614055  4581 layer_factory.hpp:77] Creating layer M2PELU29
I0928 13:46:48.614061  4581 net.cpp:84] Creating Layer M2PELU29
I0928 13:46:48.614063  4581 net.cpp:406] M2PELU29 <- Eltwise14
I0928 13:46:48.614066  4581 net.cpp:367] M2PELU29 -> Eltwise14 (in-place)
I0928 13:46:48.614150  4581 net.cpp:122] Setting up M2PELU29
I0928 13:46:48.614153  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.614156  4581 net.cpp:137] Memory required for data: 668282000
I0928 13:46:48.614159  4581 layer_factory.hpp:77] Creating layer Eltwise14_M2PELU29_0_split
I0928 13:46:48.614163  4581 net.cpp:84] Creating Layer Eltwise14_M2PELU29_0_split
I0928 13:46:48.614166  4581 net.cpp:406] Eltwise14_M2PELU29_0_split <- Eltwise14
I0928 13:46:48.614168  4581 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_0
I0928 13:46:48.614173  4581 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_1
I0928 13:46:48.614195  4581 net.cpp:122] Setting up Eltwise14_M2PELU29_0_split
I0928 13:46:48.614198  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.614202  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.614203  4581 net.cpp:137] Memory required for data: 673299600
I0928 13:46:48.614205  4581 layer_factory.hpp:77] Creating layer Convolution31
I0928 13:46:48.614212  4581 net.cpp:84] Creating Layer Convolution31
I0928 13:46:48.614215  4581 net.cpp:406] Convolution31 <- Eltwise14_M2PELU29_0_split_0
I0928 13:46:48.614219  4581 net.cpp:380] Convolution31 -> Convolution31
I0928 13:46:48.615252  4581 net.cpp:122] Setting up Convolution31
I0928 13:46:48.615260  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.615262  4581 net.cpp:137] Memory required for data: 675808400
I0928 13:46:48.615267  4581 layer_factory.hpp:77] Creating layer BatchNorm31
I0928 13:46:48.615272  4581 net.cpp:84] Creating Layer BatchNorm31
I0928 13:46:48.615274  4581 net.cpp:406] BatchNorm31 <- Convolution31
I0928 13:46:48.615278  4581 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0928 13:46:48.615413  4581 net.cpp:122] Setting up BatchNorm31
I0928 13:46:48.615418  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.615420  4581 net.cpp:137] Memory required for data: 678317200
I0928 13:46:48.615424  4581 layer_factory.hpp:77] Creating layer Scale31
I0928 13:46:48.615428  4581 net.cpp:84] Creating Layer Scale31
I0928 13:46:48.615432  4581 net.cpp:406] Scale31 <- Convolution31
I0928 13:46:48.615435  4581 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0928 13:46:48.615461  4581 layer_factory.hpp:77] Creating layer Scale31
I0928 13:46:48.615540  4581 net.cpp:122] Setting up Scale31
I0928 13:46:48.615543  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.615545  4581 net.cpp:137] Memory required for data: 680826000
I0928 13:46:48.615550  4581 layer_factory.hpp:77] Creating layer M2PELU30
I0928 13:46:48.615561  4581 net.cpp:84] Creating Layer M2PELU30
I0928 13:46:48.615564  4581 net.cpp:406] M2PELU30 <- Convolution31
I0928 13:46:48.615568  4581 net.cpp:367] M2PELU30 -> Convolution31 (in-place)
I0928 13:46:48.615654  4581 net.cpp:122] Setting up M2PELU30
I0928 13:46:48.615659  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.615661  4581 net.cpp:137] Memory required for data: 683334800
I0928 13:46:48.615664  4581 layer_factory.hpp:77] Creating layer Convolution32
I0928 13:46:48.615671  4581 net.cpp:84] Creating Layer Convolution32
I0928 13:46:48.615674  4581 net.cpp:406] Convolution32 <- Convolution31
I0928 13:46:48.615677  4581 net.cpp:380] Convolution32 -> Convolution32
I0928 13:46:48.616708  4581 net.cpp:122] Setting up Convolution32
I0928 13:46:48.616716  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.616719  4581 net.cpp:137] Memory required for data: 685843600
I0928 13:46:48.616724  4581 layer_factory.hpp:77] Creating layer BatchNorm32
I0928 13:46:48.616729  4581 net.cpp:84] Creating Layer BatchNorm32
I0928 13:46:48.616731  4581 net.cpp:406] BatchNorm32 <- Convolution32
I0928 13:46:48.616734  4581 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I0928 13:46:48.616869  4581 net.cpp:122] Setting up BatchNorm32
I0928 13:46:48.616873  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.616875  4581 net.cpp:137] Memory required for data: 688352400
I0928 13:46:48.616880  4581 layer_factory.hpp:77] Creating layer Scale32
I0928 13:46:48.616884  4581 net.cpp:84] Creating Layer Scale32
I0928 13:46:48.616888  4581 net.cpp:406] Scale32 <- Convolution32
I0928 13:46:48.616890  4581 net.cpp:367] Scale32 -> Convolution32 (in-place)
I0928 13:46:48.616919  4581 layer_factory.hpp:77] Creating layer Scale32
I0928 13:46:48.616996  4581 net.cpp:122] Setting up Scale32
I0928 13:46:48.616999  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.617002  4581 net.cpp:137] Memory required for data: 690861200
I0928 13:46:48.617005  4581 layer_factory.hpp:77] Creating layer Eltwise15
I0928 13:46:48.617009  4581 net.cpp:84] Creating Layer Eltwise15
I0928 13:46:48.617012  4581 net.cpp:406] Eltwise15 <- Eltwise14_M2PELU29_0_split_1
I0928 13:46:48.617014  4581 net.cpp:406] Eltwise15 <- Convolution32
I0928 13:46:48.617018  4581 net.cpp:380] Eltwise15 -> Eltwise15
I0928 13:46:48.617033  4581 net.cpp:122] Setting up Eltwise15
I0928 13:46:48.617038  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.617039  4581 net.cpp:137] Memory required for data: 693370000
I0928 13:46:48.617041  4581 layer_factory.hpp:77] Creating layer M2PELU31
I0928 13:46:48.617046  4581 net.cpp:84] Creating Layer M2PELU31
I0928 13:46:48.617049  4581 net.cpp:406] M2PELU31 <- Eltwise15
I0928 13:46:48.617053  4581 net.cpp:367] M2PELU31 -> Eltwise15 (in-place)
I0928 13:46:48.617136  4581 net.cpp:122] Setting up M2PELU31
I0928 13:46:48.617141  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.617142  4581 net.cpp:137] Memory required for data: 695878800
I0928 13:46:48.617146  4581 layer_factory.hpp:77] Creating layer Eltwise15_M2PELU31_0_split
I0928 13:46:48.617149  4581 net.cpp:84] Creating Layer Eltwise15_M2PELU31_0_split
I0928 13:46:48.617151  4581 net.cpp:406] Eltwise15_M2PELU31_0_split <- Eltwise15
I0928 13:46:48.617154  4581 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_0
I0928 13:46:48.617158  4581 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_1
I0928 13:46:48.617182  4581 net.cpp:122] Setting up Eltwise15_M2PELU31_0_split
I0928 13:46:48.617185  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.617188  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.617190  4581 net.cpp:137] Memory required for data: 700896400
I0928 13:46:48.617192  4581 layer_factory.hpp:77] Creating layer Convolution33
I0928 13:46:48.617198  4581 net.cpp:84] Creating Layer Convolution33
I0928 13:46:48.617202  4581 net.cpp:406] Convolution33 <- Eltwise15_M2PELU31_0_split_0
I0928 13:46:48.617204  4581 net.cpp:380] Convolution33 -> Convolution33
I0928 13:46:48.618578  4581 net.cpp:122] Setting up Convolution33
I0928 13:46:48.618587  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.618589  4581 net.cpp:137] Memory required for data: 703405200
I0928 13:46:48.618593  4581 layer_factory.hpp:77] Creating layer BatchNorm33
I0928 13:46:48.618599  4581 net.cpp:84] Creating Layer BatchNorm33
I0928 13:46:48.618602  4581 net.cpp:406] BatchNorm33 <- Convolution33
I0928 13:46:48.618605  4581 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I0928 13:46:48.618746  4581 net.cpp:122] Setting up BatchNorm33
I0928 13:46:48.618749  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.618752  4581 net.cpp:137] Memory required for data: 705914000
I0928 13:46:48.618757  4581 layer_factory.hpp:77] Creating layer Scale33
I0928 13:46:48.618760  4581 net.cpp:84] Creating Layer Scale33
I0928 13:46:48.618763  4581 net.cpp:406] Scale33 <- Convolution33
I0928 13:46:48.618767  4581 net.cpp:367] Scale33 -> Convolution33 (in-place)
I0928 13:46:48.618794  4581 layer_factory.hpp:77] Creating layer Scale33
I0928 13:46:48.618871  4581 net.cpp:122] Setting up Scale33
I0928 13:46:48.618876  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.618878  4581 net.cpp:137] Memory required for data: 708422800
I0928 13:46:48.618881  4581 layer_factory.hpp:77] Creating layer M2PELU32
I0928 13:46:48.618886  4581 net.cpp:84] Creating Layer M2PELU32
I0928 13:46:48.618890  4581 net.cpp:406] M2PELU32 <- Convolution33
I0928 13:46:48.618893  4581 net.cpp:367] M2PELU32 -> Convolution33 (in-place)
I0928 13:46:48.618978  4581 net.cpp:122] Setting up M2PELU32
I0928 13:46:48.618983  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.618984  4581 net.cpp:137] Memory required for data: 710931600
I0928 13:46:48.618988  4581 layer_factory.hpp:77] Creating layer Convolution34
I0928 13:46:48.618994  4581 net.cpp:84] Creating Layer Convolution34
I0928 13:46:48.618996  4581 net.cpp:406] Convolution34 <- Convolution33
I0928 13:46:48.619001  4581 net.cpp:380] Convolution34 -> Convolution34
I0928 13:46:48.620038  4581 net.cpp:122] Setting up Convolution34
I0928 13:46:48.620046  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.620049  4581 net.cpp:137] Memory required for data: 713440400
I0928 13:46:48.620054  4581 layer_factory.hpp:77] Creating layer BatchNorm34
I0928 13:46:48.620059  4581 net.cpp:84] Creating Layer BatchNorm34
I0928 13:46:48.620062  4581 net.cpp:406] BatchNorm34 <- Convolution34
I0928 13:46:48.620065  4581 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I0928 13:46:48.620203  4581 net.cpp:122] Setting up BatchNorm34
I0928 13:46:48.620206  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.620209  4581 net.cpp:137] Memory required for data: 715949200
I0928 13:46:48.620213  4581 layer_factory.hpp:77] Creating layer Scale34
I0928 13:46:48.620218  4581 net.cpp:84] Creating Layer Scale34
I0928 13:46:48.620220  4581 net.cpp:406] Scale34 <- Convolution34
I0928 13:46:48.620223  4581 net.cpp:367] Scale34 -> Convolution34 (in-place)
I0928 13:46:48.620249  4581 layer_factory.hpp:77] Creating layer Scale34
I0928 13:46:48.620326  4581 net.cpp:122] Setting up Scale34
I0928 13:46:48.620331  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.620332  4581 net.cpp:137] Memory required for data: 718458000
I0928 13:46:48.620337  4581 layer_factory.hpp:77] Creating layer Eltwise16
I0928 13:46:48.620342  4581 net.cpp:84] Creating Layer Eltwise16
I0928 13:46:48.620344  4581 net.cpp:406] Eltwise16 <- Eltwise15_M2PELU31_0_split_1
I0928 13:46:48.620347  4581 net.cpp:406] Eltwise16 <- Convolution34
I0928 13:46:48.620352  4581 net.cpp:380] Eltwise16 -> Eltwise16
I0928 13:46:48.620368  4581 net.cpp:122] Setting up Eltwise16
I0928 13:46:48.620371  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.620373  4581 net.cpp:137] Memory required for data: 720966800
I0928 13:46:48.620375  4581 layer_factory.hpp:77] Creating layer M2PELU33
I0928 13:46:48.620380  4581 net.cpp:84] Creating Layer M2PELU33
I0928 13:46:48.620390  4581 net.cpp:406] M2PELU33 <- Eltwise16
I0928 13:46:48.620393  4581 net.cpp:367] M2PELU33 -> Eltwise16 (in-place)
I0928 13:46:48.620478  4581 net.cpp:122] Setting up M2PELU33
I0928 13:46:48.620483  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.620486  4581 net.cpp:137] Memory required for data: 723475600
I0928 13:46:48.620488  4581 layer_factory.hpp:77] Creating layer Eltwise16_M2PELU33_0_split
I0928 13:46:48.620493  4581 net.cpp:84] Creating Layer Eltwise16_M2PELU33_0_split
I0928 13:46:48.620496  4581 net.cpp:406] Eltwise16_M2PELU33_0_split <- Eltwise16
I0928 13:46:48.620498  4581 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_0
I0928 13:46:48.620503  4581 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_1
I0928 13:46:48.620527  4581 net.cpp:122] Setting up Eltwise16_M2PELU33_0_split
I0928 13:46:48.620529  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.620532  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.620534  4581 net.cpp:137] Memory required for data: 728493200
I0928 13:46:48.620537  4581 layer_factory.hpp:77] Creating layer Convolution35
I0928 13:46:48.620543  4581 net.cpp:84] Creating Layer Convolution35
I0928 13:46:48.620544  4581 net.cpp:406] Convolution35 <- Eltwise16_M2PELU33_0_split_0
I0928 13:46:48.620548  4581 net.cpp:380] Convolution35 -> Convolution35
I0928 13:46:48.621583  4581 net.cpp:122] Setting up Convolution35
I0928 13:46:48.621592  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.621594  4581 net.cpp:137] Memory required for data: 731002000
I0928 13:46:48.621598  4581 layer_factory.hpp:77] Creating layer BatchNorm35
I0928 13:46:48.621603  4581 net.cpp:84] Creating Layer BatchNorm35
I0928 13:46:48.621606  4581 net.cpp:406] BatchNorm35 <- Convolution35
I0928 13:46:48.621610  4581 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I0928 13:46:48.621747  4581 net.cpp:122] Setting up BatchNorm35
I0928 13:46:48.621750  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.621752  4581 net.cpp:137] Memory required for data: 733510800
I0928 13:46:48.621757  4581 layer_factory.hpp:77] Creating layer Scale35
I0928 13:46:48.621762  4581 net.cpp:84] Creating Layer Scale35
I0928 13:46:48.621763  4581 net.cpp:406] Scale35 <- Convolution35
I0928 13:46:48.621767  4581 net.cpp:367] Scale35 -> Convolution35 (in-place)
I0928 13:46:48.621793  4581 layer_factory.hpp:77] Creating layer Scale35
I0928 13:46:48.621870  4581 net.cpp:122] Setting up Scale35
I0928 13:46:48.621873  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.621876  4581 net.cpp:137] Memory required for data: 736019600
I0928 13:46:48.621879  4581 layer_factory.hpp:77] Creating layer M2PELU34
I0928 13:46:48.621883  4581 net.cpp:84] Creating Layer M2PELU34
I0928 13:46:48.621886  4581 net.cpp:406] M2PELU34 <- Convolution35
I0928 13:46:48.621891  4581 net.cpp:367] M2PELU34 -> Convolution35 (in-place)
I0928 13:46:48.621974  4581 net.cpp:122] Setting up M2PELU34
I0928 13:46:48.621978  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.621980  4581 net.cpp:137] Memory required for data: 738528400
I0928 13:46:48.621984  4581 layer_factory.hpp:77] Creating layer Convolution36
I0928 13:46:48.621990  4581 net.cpp:84] Creating Layer Convolution36
I0928 13:46:48.621994  4581 net.cpp:406] Convolution36 <- Convolution35
I0928 13:46:48.621997  4581 net.cpp:380] Convolution36 -> Convolution36
I0928 13:46:48.623036  4581 net.cpp:122] Setting up Convolution36
I0928 13:46:48.623045  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.623047  4581 net.cpp:137] Memory required for data: 741037200
I0928 13:46:48.623051  4581 layer_factory.hpp:77] Creating layer BatchNorm36
I0928 13:46:48.623057  4581 net.cpp:84] Creating Layer BatchNorm36
I0928 13:46:48.623059  4581 net.cpp:406] BatchNorm36 <- Convolution36
I0928 13:46:48.623064  4581 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I0928 13:46:48.623200  4581 net.cpp:122] Setting up BatchNorm36
I0928 13:46:48.623205  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.623214  4581 net.cpp:137] Memory required for data: 743546000
I0928 13:46:48.623219  4581 layer_factory.hpp:77] Creating layer Scale36
I0928 13:46:48.623224  4581 net.cpp:84] Creating Layer Scale36
I0928 13:46:48.623225  4581 net.cpp:406] Scale36 <- Convolution36
I0928 13:46:48.623229  4581 net.cpp:367] Scale36 -> Convolution36 (in-place)
I0928 13:46:48.623257  4581 layer_factory.hpp:77] Creating layer Scale36
I0928 13:46:48.623334  4581 net.cpp:122] Setting up Scale36
I0928 13:46:48.623339  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.623342  4581 net.cpp:137] Memory required for data: 746054800
I0928 13:46:48.623345  4581 layer_factory.hpp:77] Creating layer Eltwise17
I0928 13:46:48.623349  4581 net.cpp:84] Creating Layer Eltwise17
I0928 13:46:48.623353  4581 net.cpp:406] Eltwise17 <- Eltwise16_M2PELU33_0_split_1
I0928 13:46:48.623355  4581 net.cpp:406] Eltwise17 <- Convolution36
I0928 13:46:48.623358  4581 net.cpp:380] Eltwise17 -> Eltwise17
I0928 13:46:48.623374  4581 net.cpp:122] Setting up Eltwise17
I0928 13:46:48.623378  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.623380  4581 net.cpp:137] Memory required for data: 748563600
I0928 13:46:48.623383  4581 layer_factory.hpp:77] Creating layer M2PELU35
I0928 13:46:48.623387  4581 net.cpp:84] Creating Layer M2PELU35
I0928 13:46:48.623390  4581 net.cpp:406] M2PELU35 <- Eltwise17
I0928 13:46:48.623394  4581 net.cpp:367] M2PELU35 -> Eltwise17 (in-place)
I0928 13:46:48.623477  4581 net.cpp:122] Setting up M2PELU35
I0928 13:46:48.623481  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.623483  4581 net.cpp:137] Memory required for data: 751072400
I0928 13:46:48.623487  4581 layer_factory.hpp:77] Creating layer Eltwise17_M2PELU35_0_split
I0928 13:46:48.623492  4581 net.cpp:84] Creating Layer Eltwise17_M2PELU35_0_split
I0928 13:46:48.623494  4581 net.cpp:406] Eltwise17_M2PELU35_0_split <- Eltwise17
I0928 13:46:48.623497  4581 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_0
I0928 13:46:48.623502  4581 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_1
I0928 13:46:48.623524  4581 net.cpp:122] Setting up Eltwise17_M2PELU35_0_split
I0928 13:46:48.623528  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.623530  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.623533  4581 net.cpp:137] Memory required for data: 756090000
I0928 13:46:48.623534  4581 layer_factory.hpp:77] Creating layer Convolution37
I0928 13:46:48.623540  4581 net.cpp:84] Creating Layer Convolution37
I0928 13:46:48.623543  4581 net.cpp:406] Convolution37 <- Eltwise17_M2PELU35_0_split_0
I0928 13:46:48.623548  4581 net.cpp:380] Convolution37 -> Convolution37
I0928 13:46:48.624258  4581 net.cpp:122] Setting up Convolution37
I0928 13:46:48.624265  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.624269  4581 net.cpp:137] Memory required for data: 758598800
I0928 13:46:48.624272  4581 layer_factory.hpp:77] Creating layer BatchNorm37
I0928 13:46:48.624277  4581 net.cpp:84] Creating Layer BatchNorm37
I0928 13:46:48.624279  4581 net.cpp:406] BatchNorm37 <- Convolution37
I0928 13:46:48.624284  4581 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I0928 13:46:48.624418  4581 net.cpp:122] Setting up BatchNorm37
I0928 13:46:48.624423  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.624425  4581 net.cpp:137] Memory required for data: 761107600
I0928 13:46:48.624429  4581 layer_factory.hpp:77] Creating layer Scale37
I0928 13:46:48.624434  4581 net.cpp:84] Creating Layer Scale37
I0928 13:46:48.624436  4581 net.cpp:406] Scale37 <- Convolution37
I0928 13:46:48.624439  4581 net.cpp:367] Scale37 -> Convolution37 (in-place)
I0928 13:46:48.624466  4581 layer_factory.hpp:77] Creating layer Scale37
I0928 13:46:48.624542  4581 net.cpp:122] Setting up Scale37
I0928 13:46:48.624547  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.624548  4581 net.cpp:137] Memory required for data: 763616400
I0928 13:46:48.624557  4581 layer_factory.hpp:77] Creating layer M2PELU36
I0928 13:46:48.624562  4581 net.cpp:84] Creating Layer M2PELU36
I0928 13:46:48.624565  4581 net.cpp:406] M2PELU36 <- Convolution37
I0928 13:46:48.624569  4581 net.cpp:367] M2PELU36 -> Convolution37 (in-place)
I0928 13:46:48.624652  4581 net.cpp:122] Setting up M2PELU36
I0928 13:46:48.624656  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.624658  4581 net.cpp:137] Memory required for data: 766125200
I0928 13:46:48.624662  4581 layer_factory.hpp:77] Creating layer Convolution38
I0928 13:46:48.624668  4581 net.cpp:84] Creating Layer Convolution38
I0928 13:46:48.624671  4581 net.cpp:406] Convolution38 <- Convolution37
I0928 13:46:48.624677  4581 net.cpp:380] Convolution38 -> Convolution38
I0928 13:46:48.625722  4581 net.cpp:122] Setting up Convolution38
I0928 13:46:48.625730  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.625733  4581 net.cpp:137] Memory required for data: 768634000
I0928 13:46:48.625737  4581 layer_factory.hpp:77] Creating layer BatchNorm38
I0928 13:46:48.625742  4581 net.cpp:84] Creating Layer BatchNorm38
I0928 13:46:48.625746  4581 net.cpp:406] BatchNorm38 <- Convolution38
I0928 13:46:48.625748  4581 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I0928 13:46:48.625886  4581 net.cpp:122] Setting up BatchNorm38
I0928 13:46:48.625890  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.625893  4581 net.cpp:137] Memory required for data: 771142800
I0928 13:46:48.625897  4581 layer_factory.hpp:77] Creating layer Scale38
I0928 13:46:48.625901  4581 net.cpp:84] Creating Layer Scale38
I0928 13:46:48.625903  4581 net.cpp:406] Scale38 <- Convolution38
I0928 13:46:48.625906  4581 net.cpp:367] Scale38 -> Convolution38 (in-place)
I0928 13:46:48.625934  4581 layer_factory.hpp:77] Creating layer Scale38
I0928 13:46:48.626010  4581 net.cpp:122] Setting up Scale38
I0928 13:46:48.626014  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.626016  4581 net.cpp:137] Memory required for data: 773651600
I0928 13:46:48.626020  4581 layer_factory.hpp:77] Creating layer Eltwise18
I0928 13:46:48.626025  4581 net.cpp:84] Creating Layer Eltwise18
I0928 13:46:48.626027  4581 net.cpp:406] Eltwise18 <- Eltwise17_M2PELU35_0_split_1
I0928 13:46:48.626030  4581 net.cpp:406] Eltwise18 <- Convolution38
I0928 13:46:48.626034  4581 net.cpp:380] Eltwise18 -> Eltwise18
I0928 13:46:48.626049  4581 net.cpp:122] Setting up Eltwise18
I0928 13:46:48.626054  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.626055  4581 net.cpp:137] Memory required for data: 776160400
I0928 13:46:48.626057  4581 layer_factory.hpp:77] Creating layer M2PELU37
I0928 13:46:48.626062  4581 net.cpp:84] Creating Layer M2PELU37
I0928 13:46:48.626065  4581 net.cpp:406] M2PELU37 <- Eltwise18
I0928 13:46:48.626067  4581 net.cpp:367] M2PELU37 -> Eltwise18 (in-place)
I0928 13:46:48.626152  4581 net.cpp:122] Setting up M2PELU37
I0928 13:46:48.626157  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.626158  4581 net.cpp:137] Memory required for data: 778669200
I0928 13:46:48.626161  4581 layer_factory.hpp:77] Creating layer Eltwise18_M2PELU37_0_split
I0928 13:46:48.626165  4581 net.cpp:84] Creating Layer Eltwise18_M2PELU37_0_split
I0928 13:46:48.626168  4581 net.cpp:406] Eltwise18_M2PELU37_0_split <- Eltwise18
I0928 13:46:48.626170  4581 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_0
I0928 13:46:48.626175  4581 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_1
I0928 13:46:48.626199  4581 net.cpp:122] Setting up Eltwise18_M2PELU37_0_split
I0928 13:46:48.626201  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.626204  4581 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 13:46:48.626206  4581 net.cpp:137] Memory required for data: 783686800
I0928 13:46:48.626209  4581 layer_factory.hpp:77] Creating layer Convolution39
I0928 13:46:48.626214  4581 net.cpp:84] Creating Layer Convolution39
I0928 13:46:48.626217  4581 net.cpp:406] Convolution39 <- Eltwise18_M2PELU37_0_split_0
I0928 13:46:48.626227  4581 net.cpp:380] Convolution39 -> Convolution39
I0928 13:46:48.627120  4581 net.cpp:122] Setting up Convolution39
I0928 13:46:48.627130  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.627132  4581 net.cpp:137] Memory required for data: 784941200
I0928 13:46:48.627136  4581 layer_factory.hpp:77] Creating layer BatchNorm39
I0928 13:46:48.627141  4581 net.cpp:84] Creating Layer BatchNorm39
I0928 13:46:48.627144  4581 net.cpp:406] BatchNorm39 <- Convolution39
I0928 13:46:48.627148  4581 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I0928 13:46:48.627281  4581 net.cpp:122] Setting up BatchNorm39
I0928 13:46:48.627285  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.627288  4581 net.cpp:137] Memory required for data: 786195600
I0928 13:46:48.627292  4581 layer_factory.hpp:77] Creating layer Scale39
I0928 13:46:48.627297  4581 net.cpp:84] Creating Layer Scale39
I0928 13:46:48.627300  4581 net.cpp:406] Scale39 <- Convolution39
I0928 13:46:48.627302  4581 net.cpp:367] Scale39 -> Convolution39 (in-place)
I0928 13:46:48.627331  4581 layer_factory.hpp:77] Creating layer Scale39
I0928 13:46:48.627408  4581 net.cpp:122] Setting up Scale39
I0928 13:46:48.627411  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.627413  4581 net.cpp:137] Memory required for data: 787450000
I0928 13:46:48.627418  4581 layer_factory.hpp:77] Creating layer Convolution40
I0928 13:46:48.627424  4581 net.cpp:84] Creating Layer Convolution40
I0928 13:46:48.627427  4581 net.cpp:406] Convolution40 <- Eltwise18_M2PELU37_0_split_1
I0928 13:46:48.627431  4581 net.cpp:380] Convolution40 -> Convolution40
I0928 13:46:48.629245  4581 net.cpp:122] Setting up Convolution40
I0928 13:46:48.629256  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.629257  4581 net.cpp:137] Memory required for data: 788704400
I0928 13:46:48.629262  4581 layer_factory.hpp:77] Creating layer BatchNorm40
I0928 13:46:48.629268  4581 net.cpp:84] Creating Layer BatchNorm40
I0928 13:46:48.629271  4581 net.cpp:406] BatchNorm40 <- Convolution40
I0928 13:46:48.629276  4581 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I0928 13:46:48.629412  4581 net.cpp:122] Setting up BatchNorm40
I0928 13:46:48.629416  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.629418  4581 net.cpp:137] Memory required for data: 789958800
I0928 13:46:48.629423  4581 layer_factory.hpp:77] Creating layer Scale40
I0928 13:46:48.629428  4581 net.cpp:84] Creating Layer Scale40
I0928 13:46:48.629431  4581 net.cpp:406] Scale40 <- Convolution40
I0928 13:46:48.629434  4581 net.cpp:367] Scale40 -> Convolution40 (in-place)
I0928 13:46:48.629462  4581 layer_factory.hpp:77] Creating layer Scale40
I0928 13:46:48.629541  4581 net.cpp:122] Setting up Scale40
I0928 13:46:48.629546  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.629549  4581 net.cpp:137] Memory required for data: 791213200
I0928 13:46:48.629552  4581 layer_factory.hpp:77] Creating layer M2PELU38
I0928 13:46:48.629557  4581 net.cpp:84] Creating Layer M2PELU38
I0928 13:46:48.629559  4581 net.cpp:406] M2PELU38 <- Convolution40
I0928 13:46:48.629564  4581 net.cpp:367] M2PELU38 -> Convolution40 (in-place)
I0928 13:46:48.629649  4581 net.cpp:122] Setting up M2PELU38
I0928 13:46:48.629655  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.629657  4581 net.cpp:137] Memory required for data: 792467600
I0928 13:46:48.629660  4581 layer_factory.hpp:77] Creating layer Convolution41
I0928 13:46:48.629667  4581 net.cpp:84] Creating Layer Convolution41
I0928 13:46:48.629669  4581 net.cpp:406] Convolution41 <- Convolution40
I0928 13:46:48.629673  4581 net.cpp:380] Convolution41 -> Convolution41
I0928 13:46:48.631973  4581 net.cpp:122] Setting up Convolution41
I0928 13:46:48.631983  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.631984  4581 net.cpp:137] Memory required for data: 793722000
I0928 13:46:48.631989  4581 layer_factory.hpp:77] Creating layer BatchNorm41
I0928 13:46:48.631995  4581 net.cpp:84] Creating Layer BatchNorm41
I0928 13:46:48.632004  4581 net.cpp:406] BatchNorm41 <- Convolution41
I0928 13:46:48.632009  4581 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I0928 13:46:48.632153  4581 net.cpp:122] Setting up BatchNorm41
I0928 13:46:48.632156  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.632159  4581 net.cpp:137] Memory required for data: 794976400
I0928 13:46:48.632164  4581 layer_factory.hpp:77] Creating layer Scale41
I0928 13:46:48.632169  4581 net.cpp:84] Creating Layer Scale41
I0928 13:46:48.632171  4581 net.cpp:406] Scale41 <- Convolution41
I0928 13:46:48.632174  4581 net.cpp:367] Scale41 -> Convolution41 (in-place)
I0928 13:46:48.632202  4581 layer_factory.hpp:77] Creating layer Scale41
I0928 13:46:48.632282  4581 net.cpp:122] Setting up Scale41
I0928 13:46:48.632287  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.632289  4581 net.cpp:137] Memory required for data: 796230800
I0928 13:46:48.632293  4581 layer_factory.hpp:77] Creating layer Eltwise19
I0928 13:46:48.632298  4581 net.cpp:84] Creating Layer Eltwise19
I0928 13:46:48.632300  4581 net.cpp:406] Eltwise19 <- Convolution39
I0928 13:46:48.632303  4581 net.cpp:406] Eltwise19 <- Convolution41
I0928 13:46:48.632308  4581 net.cpp:380] Eltwise19 -> Eltwise19
I0928 13:46:48.632324  4581 net.cpp:122] Setting up Eltwise19
I0928 13:46:48.632328  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.632329  4581 net.cpp:137] Memory required for data: 797485200
I0928 13:46:48.632333  4581 layer_factory.hpp:77] Creating layer M2PELU39
I0928 13:46:48.632338  4581 net.cpp:84] Creating Layer M2PELU39
I0928 13:46:48.632339  4581 net.cpp:406] M2PELU39 <- Eltwise19
I0928 13:46:48.632342  4581 net.cpp:367] M2PELU39 -> Eltwise19 (in-place)
I0928 13:46:48.632429  4581 net.cpp:122] Setting up M2PELU39
I0928 13:46:48.632433  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.632436  4581 net.cpp:137] Memory required for data: 798739600
I0928 13:46:48.632439  4581 layer_factory.hpp:77] Creating layer Eltwise19_M2PELU39_0_split
I0928 13:46:48.632444  4581 net.cpp:84] Creating Layer Eltwise19_M2PELU39_0_split
I0928 13:46:48.632447  4581 net.cpp:406] Eltwise19_M2PELU39_0_split <- Eltwise19
I0928 13:46:48.632449  4581 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_0
I0928 13:46:48.632463  4581 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_1
I0928 13:46:48.632488  4581 net.cpp:122] Setting up Eltwise19_M2PELU39_0_split
I0928 13:46:48.632491  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.632494  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.632496  4581 net.cpp:137] Memory required for data: 801248400
I0928 13:46:48.632498  4581 layer_factory.hpp:77] Creating layer Convolution42
I0928 13:46:48.632505  4581 net.cpp:84] Creating Layer Convolution42
I0928 13:46:48.632508  4581 net.cpp:406] Convolution42 <- Eltwise19_M2PELU39_0_split_0
I0928 13:46:48.632511  4581 net.cpp:380] Convolution42 -> Convolution42
I0928 13:46:48.634227  4581 net.cpp:122] Setting up Convolution42
I0928 13:46:48.634235  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.634238  4581 net.cpp:137] Memory required for data: 802502800
I0928 13:46:48.634243  4581 layer_factory.hpp:77] Creating layer BatchNorm42
I0928 13:46:48.634248  4581 net.cpp:84] Creating Layer BatchNorm42
I0928 13:46:48.634250  4581 net.cpp:406] BatchNorm42 <- Convolution42
I0928 13:46:48.634254  4581 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I0928 13:46:48.634395  4581 net.cpp:122] Setting up BatchNorm42
I0928 13:46:48.634400  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.634402  4581 net.cpp:137] Memory required for data: 803757200
I0928 13:46:48.634407  4581 layer_factory.hpp:77] Creating layer Scale42
I0928 13:46:48.634412  4581 net.cpp:84] Creating Layer Scale42
I0928 13:46:48.634413  4581 net.cpp:406] Scale42 <- Convolution42
I0928 13:46:48.634418  4581 net.cpp:367] Scale42 -> Convolution42 (in-place)
I0928 13:46:48.634445  4581 layer_factory.hpp:77] Creating layer Scale42
I0928 13:46:48.634539  4581 net.cpp:122] Setting up Scale42
I0928 13:46:48.634553  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.634555  4581 net.cpp:137] Memory required for data: 805011600
I0928 13:46:48.634559  4581 layer_factory.hpp:77] Creating layer M2PELU40
I0928 13:46:48.634564  4581 net.cpp:84] Creating Layer M2PELU40
I0928 13:46:48.634567  4581 net.cpp:406] M2PELU40 <- Convolution42
I0928 13:46:48.634570  4581 net.cpp:367] M2PELU40 -> Convolution42 (in-place)
I0928 13:46:48.634658  4581 net.cpp:122] Setting up M2PELU40
I0928 13:46:48.634663  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.634665  4581 net.cpp:137] Memory required for data: 806266000
I0928 13:46:48.634668  4581 layer_factory.hpp:77] Creating layer Convolution43
I0928 13:46:48.634675  4581 net.cpp:84] Creating Layer Convolution43
I0928 13:46:48.634677  4581 net.cpp:406] Convolution43 <- Convolution42
I0928 13:46:48.634681  4581 net.cpp:380] Convolution43 -> Convolution43
I0928 13:46:48.636930  4581 net.cpp:122] Setting up Convolution43
I0928 13:46:48.636940  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.636941  4581 net.cpp:137] Memory required for data: 807520400
I0928 13:46:48.636947  4581 layer_factory.hpp:77] Creating layer BatchNorm43
I0928 13:46:48.636951  4581 net.cpp:84] Creating Layer BatchNorm43
I0928 13:46:48.636955  4581 net.cpp:406] BatchNorm43 <- Convolution43
I0928 13:46:48.636957  4581 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I0928 13:46:48.637100  4581 net.cpp:122] Setting up BatchNorm43
I0928 13:46:48.637104  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.637106  4581 net.cpp:137] Memory required for data: 808774800
I0928 13:46:48.637111  4581 layer_factory.hpp:77] Creating layer Scale43
I0928 13:46:48.637115  4581 net.cpp:84] Creating Layer Scale43
I0928 13:46:48.637117  4581 net.cpp:406] Scale43 <- Convolution43
I0928 13:46:48.637120  4581 net.cpp:367] Scale43 -> Convolution43 (in-place)
I0928 13:46:48.637150  4581 layer_factory.hpp:77] Creating layer Scale43
I0928 13:46:48.637228  4581 net.cpp:122] Setting up Scale43
I0928 13:46:48.637233  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.637234  4581 net.cpp:137] Memory required for data: 810029200
I0928 13:46:48.637238  4581 layer_factory.hpp:77] Creating layer Eltwise20
I0928 13:46:48.637241  4581 net.cpp:84] Creating Layer Eltwise20
I0928 13:46:48.637244  4581 net.cpp:406] Eltwise20 <- Eltwise19_M2PELU39_0_split_1
I0928 13:46:48.637248  4581 net.cpp:406] Eltwise20 <- Convolution43
I0928 13:46:48.637250  4581 net.cpp:380] Eltwise20 -> Eltwise20
I0928 13:46:48.637267  4581 net.cpp:122] Setting up Eltwise20
I0928 13:46:48.637270  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.637272  4581 net.cpp:137] Memory required for data: 811283600
I0928 13:46:48.637274  4581 layer_factory.hpp:77] Creating layer M2PELU41
I0928 13:46:48.637279  4581 net.cpp:84] Creating Layer M2PELU41
I0928 13:46:48.637282  4581 net.cpp:406] M2PELU41 <- Eltwise20
I0928 13:46:48.637285  4581 net.cpp:367] M2PELU41 -> Eltwise20 (in-place)
I0928 13:46:48.637372  4581 net.cpp:122] Setting up M2PELU41
I0928 13:46:48.637375  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.637377  4581 net.cpp:137] Memory required for data: 812538000
I0928 13:46:48.637380  4581 layer_factory.hpp:77] Creating layer Eltwise20_M2PELU41_0_split
I0928 13:46:48.637384  4581 net.cpp:84] Creating Layer Eltwise20_M2PELU41_0_split
I0928 13:46:48.637387  4581 net.cpp:406] Eltwise20_M2PELU41_0_split <- Eltwise20
I0928 13:46:48.637390  4581 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_0
I0928 13:46:48.637394  4581 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_1
I0928 13:46:48.637418  4581 net.cpp:122] Setting up Eltwise20_M2PELU41_0_split
I0928 13:46:48.637423  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.637424  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.637426  4581 net.cpp:137] Memory required for data: 815046800
I0928 13:46:48.637434  4581 layer_factory.hpp:77] Creating layer Convolution44
I0928 13:46:48.637441  4581 net.cpp:84] Creating Layer Convolution44
I0928 13:46:48.637444  4581 net.cpp:406] Convolution44 <- Eltwise20_M2PELU41_0_split_0
I0928 13:46:48.637449  4581 net.cpp:380] Convolution44 -> Convolution44
I0928 13:46:48.639120  4581 net.cpp:122] Setting up Convolution44
I0928 13:46:48.639129  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.639132  4581 net.cpp:137] Memory required for data: 816301200
I0928 13:46:48.639137  4581 layer_factory.hpp:77] Creating layer BatchNorm44
I0928 13:46:48.639142  4581 net.cpp:84] Creating Layer BatchNorm44
I0928 13:46:48.639144  4581 net.cpp:406] BatchNorm44 <- Convolution44
I0928 13:46:48.639149  4581 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I0928 13:46:48.639288  4581 net.cpp:122] Setting up BatchNorm44
I0928 13:46:48.639292  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.639294  4581 net.cpp:137] Memory required for data: 817555600
I0928 13:46:48.639299  4581 layer_factory.hpp:77] Creating layer Scale44
I0928 13:46:48.639304  4581 net.cpp:84] Creating Layer Scale44
I0928 13:46:48.639307  4581 net.cpp:406] Scale44 <- Convolution44
I0928 13:46:48.639310  4581 net.cpp:367] Scale44 -> Convolution44 (in-place)
I0928 13:46:48.639338  4581 layer_factory.hpp:77] Creating layer Scale44
I0928 13:46:48.639417  4581 net.cpp:122] Setting up Scale44
I0928 13:46:48.639421  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.639423  4581 net.cpp:137] Memory required for data: 818810000
I0928 13:46:48.639427  4581 layer_factory.hpp:77] Creating layer M2PELU42
I0928 13:46:48.639432  4581 net.cpp:84] Creating Layer M2PELU42
I0928 13:46:48.639434  4581 net.cpp:406] M2PELU42 <- Convolution44
I0928 13:46:48.639437  4581 net.cpp:367] M2PELU42 -> Convolution44 (in-place)
I0928 13:46:48.639524  4581 net.cpp:122] Setting up M2PELU42
I0928 13:46:48.639528  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.639530  4581 net.cpp:137] Memory required for data: 820064400
I0928 13:46:48.639534  4581 layer_factory.hpp:77] Creating layer Convolution45
I0928 13:46:48.639540  4581 net.cpp:84] Creating Layer Convolution45
I0928 13:46:48.639542  4581 net.cpp:406] Convolution45 <- Convolution44
I0928 13:46:48.639547  4581 net.cpp:380] Convolution45 -> Convolution45
I0928 13:46:48.641489  4581 net.cpp:122] Setting up Convolution45
I0928 13:46:48.641496  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.641499  4581 net.cpp:137] Memory required for data: 821318800
I0928 13:46:48.641504  4581 layer_factory.hpp:77] Creating layer BatchNorm45
I0928 13:46:48.641510  4581 net.cpp:84] Creating Layer BatchNorm45
I0928 13:46:48.641511  4581 net.cpp:406] BatchNorm45 <- Convolution45
I0928 13:46:48.641515  4581 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I0928 13:46:48.641659  4581 net.cpp:122] Setting up BatchNorm45
I0928 13:46:48.641664  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.641665  4581 net.cpp:137] Memory required for data: 822573200
I0928 13:46:48.641670  4581 layer_factory.hpp:77] Creating layer Scale45
I0928 13:46:48.641674  4581 net.cpp:84] Creating Layer Scale45
I0928 13:46:48.641676  4581 net.cpp:406] Scale45 <- Convolution45
I0928 13:46:48.641680  4581 net.cpp:367] Scale45 -> Convolution45 (in-place)
I0928 13:46:48.641710  4581 layer_factory.hpp:77] Creating layer Scale45
I0928 13:46:48.641791  4581 net.cpp:122] Setting up Scale45
I0928 13:46:48.641796  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.641798  4581 net.cpp:137] Memory required for data: 823827600
I0928 13:46:48.641801  4581 layer_factory.hpp:77] Creating layer Eltwise21
I0928 13:46:48.641806  4581 net.cpp:84] Creating Layer Eltwise21
I0928 13:46:48.641809  4581 net.cpp:406] Eltwise21 <- Eltwise20_M2PELU41_0_split_1
I0928 13:46:48.641811  4581 net.cpp:406] Eltwise21 <- Convolution45
I0928 13:46:48.641815  4581 net.cpp:380] Eltwise21 -> Eltwise21
I0928 13:46:48.641834  4581 net.cpp:122] Setting up Eltwise21
I0928 13:46:48.641844  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.641845  4581 net.cpp:137] Memory required for data: 825082000
I0928 13:46:48.641847  4581 layer_factory.hpp:77] Creating layer M2PELU43
I0928 13:46:48.641852  4581 net.cpp:84] Creating Layer M2PELU43
I0928 13:46:48.641855  4581 net.cpp:406] M2PELU43 <- Eltwise21
I0928 13:46:48.641858  4581 net.cpp:367] M2PELU43 -> Eltwise21 (in-place)
I0928 13:46:48.641948  4581 net.cpp:122] Setting up M2PELU43
I0928 13:46:48.641952  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.641954  4581 net.cpp:137] Memory required for data: 826336400
I0928 13:46:48.641958  4581 layer_factory.hpp:77] Creating layer Eltwise21_M2PELU43_0_split
I0928 13:46:48.641961  4581 net.cpp:84] Creating Layer Eltwise21_M2PELU43_0_split
I0928 13:46:48.641964  4581 net.cpp:406] Eltwise21_M2PELU43_0_split <- Eltwise21
I0928 13:46:48.641968  4581 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_0
I0928 13:46:48.641973  4581 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_1
I0928 13:46:48.641996  4581 net.cpp:122] Setting up Eltwise21_M2PELU43_0_split
I0928 13:46:48.642000  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.642002  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.642004  4581 net.cpp:137] Memory required for data: 828845200
I0928 13:46:48.642007  4581 layer_factory.hpp:77] Creating layer Convolution46
I0928 13:46:48.642014  4581 net.cpp:84] Creating Layer Convolution46
I0928 13:46:48.642015  4581 net.cpp:406] Convolution46 <- Eltwise21_M2PELU43_0_split_0
I0928 13:46:48.642019  4581 net.cpp:380] Convolution46 -> Convolution46
I0928 13:46:48.643694  4581 net.cpp:122] Setting up Convolution46
I0928 13:46:48.643702  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.643705  4581 net.cpp:137] Memory required for data: 830099600
I0928 13:46:48.643709  4581 layer_factory.hpp:77] Creating layer BatchNorm46
I0928 13:46:48.643714  4581 net.cpp:84] Creating Layer BatchNorm46
I0928 13:46:48.643718  4581 net.cpp:406] BatchNorm46 <- Convolution46
I0928 13:46:48.643723  4581 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I0928 13:46:48.643863  4581 net.cpp:122] Setting up BatchNorm46
I0928 13:46:48.643868  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.643870  4581 net.cpp:137] Memory required for data: 831354000
I0928 13:46:48.643874  4581 layer_factory.hpp:77] Creating layer Scale46
I0928 13:46:48.643879  4581 net.cpp:84] Creating Layer Scale46
I0928 13:46:48.643882  4581 net.cpp:406] Scale46 <- Convolution46
I0928 13:46:48.643884  4581 net.cpp:367] Scale46 -> Convolution46 (in-place)
I0928 13:46:48.643913  4581 layer_factory.hpp:77] Creating layer Scale46
I0928 13:46:48.643993  4581 net.cpp:122] Setting up Scale46
I0928 13:46:48.643997  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.643999  4581 net.cpp:137] Memory required for data: 832608400
I0928 13:46:48.644003  4581 layer_factory.hpp:77] Creating layer M2PELU44
I0928 13:46:48.644008  4581 net.cpp:84] Creating Layer M2PELU44
I0928 13:46:48.644011  4581 net.cpp:406] M2PELU44 <- Convolution46
I0928 13:46:48.644014  4581 net.cpp:367] M2PELU44 -> Convolution46 (in-place)
I0928 13:46:48.644103  4581 net.cpp:122] Setting up M2PELU44
I0928 13:46:48.644107  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.644109  4581 net.cpp:137] Memory required for data: 833862800
I0928 13:46:48.644114  4581 layer_factory.hpp:77] Creating layer Convolution47
I0928 13:46:48.644119  4581 net.cpp:84] Creating Layer Convolution47
I0928 13:46:48.644121  4581 net.cpp:406] Convolution47 <- Convolution46
I0928 13:46:48.644125  4581 net.cpp:380] Convolution47 -> Convolution47
I0928 13:46:48.645751  4581 net.cpp:122] Setting up Convolution47
I0928 13:46:48.645759  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.645761  4581 net.cpp:137] Memory required for data: 835117200
I0928 13:46:48.645766  4581 layer_factory.hpp:77] Creating layer BatchNorm47
I0928 13:46:48.645771  4581 net.cpp:84] Creating Layer BatchNorm47
I0928 13:46:48.645779  4581 net.cpp:406] BatchNorm47 <- Convolution47
I0928 13:46:48.645787  4581 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I0928 13:46:48.645931  4581 net.cpp:122] Setting up BatchNorm47
I0928 13:46:48.645936  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.645938  4581 net.cpp:137] Memory required for data: 836371600
I0928 13:46:48.645942  4581 layer_factory.hpp:77] Creating layer Scale47
I0928 13:46:48.645946  4581 net.cpp:84] Creating Layer Scale47
I0928 13:46:48.645949  4581 net.cpp:406] Scale47 <- Convolution47
I0928 13:46:48.645952  4581 net.cpp:367] Scale47 -> Convolution47 (in-place)
I0928 13:46:48.645979  4581 layer_factory.hpp:77] Creating layer Scale47
I0928 13:46:48.646060  4581 net.cpp:122] Setting up Scale47
I0928 13:46:48.646064  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.646066  4581 net.cpp:137] Memory required for data: 837626000
I0928 13:46:48.646070  4581 layer_factory.hpp:77] Creating layer Eltwise22
I0928 13:46:48.646073  4581 net.cpp:84] Creating Layer Eltwise22
I0928 13:46:48.646076  4581 net.cpp:406] Eltwise22 <- Eltwise21_M2PELU43_0_split_1
I0928 13:46:48.646080  4581 net.cpp:406] Eltwise22 <- Convolution47
I0928 13:46:48.646083  4581 net.cpp:380] Eltwise22 -> Eltwise22
I0928 13:46:48.646100  4581 net.cpp:122] Setting up Eltwise22
I0928 13:46:48.646104  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.646106  4581 net.cpp:137] Memory required for data: 838880400
I0928 13:46:48.646108  4581 layer_factory.hpp:77] Creating layer M2PELU45
I0928 13:46:48.646112  4581 net.cpp:84] Creating Layer M2PELU45
I0928 13:46:48.646114  4581 net.cpp:406] M2PELU45 <- Eltwise22
I0928 13:46:48.646119  4581 net.cpp:367] M2PELU45 -> Eltwise22 (in-place)
I0928 13:46:48.646206  4581 net.cpp:122] Setting up M2PELU45
I0928 13:46:48.646210  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.646212  4581 net.cpp:137] Memory required for data: 840134800
I0928 13:46:48.646216  4581 layer_factory.hpp:77] Creating layer Eltwise22_M2PELU45_0_split
I0928 13:46:48.646220  4581 net.cpp:84] Creating Layer Eltwise22_M2PELU45_0_split
I0928 13:46:48.646222  4581 net.cpp:406] Eltwise22_M2PELU45_0_split <- Eltwise22
I0928 13:46:48.646226  4581 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_0
I0928 13:46:48.646230  4581 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_1
I0928 13:46:48.646255  4581 net.cpp:122] Setting up Eltwise22_M2PELU45_0_split
I0928 13:46:48.646257  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.646260  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.646262  4581 net.cpp:137] Memory required for data: 842643600
I0928 13:46:48.646265  4581 layer_factory.hpp:77] Creating layer Convolution48
I0928 13:46:48.646270  4581 net.cpp:84] Creating Layer Convolution48
I0928 13:46:48.646272  4581 net.cpp:406] Convolution48 <- Eltwise22_M2PELU45_0_split_0
I0928 13:46:48.646276  4581 net.cpp:380] Convolution48 -> Convolution48
I0928 13:46:48.647938  4581 net.cpp:122] Setting up Convolution48
I0928 13:46:48.647948  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.647950  4581 net.cpp:137] Memory required for data: 843898000
I0928 13:46:48.647954  4581 layer_factory.hpp:77] Creating layer BatchNorm48
I0928 13:46:48.647959  4581 net.cpp:84] Creating Layer BatchNorm48
I0928 13:46:48.647963  4581 net.cpp:406] BatchNorm48 <- Convolution48
I0928 13:46:48.647966  4581 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I0928 13:46:48.648109  4581 net.cpp:122] Setting up BatchNorm48
I0928 13:46:48.648113  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.648115  4581 net.cpp:137] Memory required for data: 845152400
I0928 13:46:48.648120  4581 layer_factory.hpp:77] Creating layer Scale48
I0928 13:46:48.648123  4581 net.cpp:84] Creating Layer Scale48
I0928 13:46:48.648126  4581 net.cpp:406] Scale48 <- Convolution48
I0928 13:46:48.648129  4581 net.cpp:367] Scale48 -> Convolution48 (in-place)
I0928 13:46:48.648159  4581 layer_factory.hpp:77] Creating layer Scale48
I0928 13:46:48.648250  4581 net.cpp:122] Setting up Scale48
I0928 13:46:48.648255  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.648257  4581 net.cpp:137] Memory required for data: 846406800
I0928 13:46:48.648262  4581 layer_factory.hpp:77] Creating layer M2PELU46
I0928 13:46:48.648267  4581 net.cpp:84] Creating Layer M2PELU46
I0928 13:46:48.648268  4581 net.cpp:406] M2PELU46 <- Convolution48
I0928 13:46:48.648272  4581 net.cpp:367] M2PELU46 -> Convolution48 (in-place)
I0928 13:46:48.648363  4581 net.cpp:122] Setting up M2PELU46
I0928 13:46:48.648367  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.648370  4581 net.cpp:137] Memory required for data: 847661200
I0928 13:46:48.648372  4581 layer_factory.hpp:77] Creating layer Convolution49
I0928 13:46:48.648380  4581 net.cpp:84] Creating Layer Convolution49
I0928 13:46:48.648382  4581 net.cpp:406] Convolution49 <- Convolution48
I0928 13:46:48.648386  4581 net.cpp:380] Convolution49 -> Convolution49
I0928 13:46:48.650336  4581 net.cpp:122] Setting up Convolution49
I0928 13:46:48.650346  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.650348  4581 net.cpp:137] Memory required for data: 848915600
I0928 13:46:48.650352  4581 layer_factory.hpp:77] Creating layer BatchNorm49
I0928 13:46:48.650357  4581 net.cpp:84] Creating Layer BatchNorm49
I0928 13:46:48.650359  4581 net.cpp:406] BatchNorm49 <- Convolution49
I0928 13:46:48.650363  4581 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I0928 13:46:48.650511  4581 net.cpp:122] Setting up BatchNorm49
I0928 13:46:48.650514  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.650516  4581 net.cpp:137] Memory required for data: 850170000
I0928 13:46:48.650537  4581 layer_factory.hpp:77] Creating layer Scale49
I0928 13:46:48.650542  4581 net.cpp:84] Creating Layer Scale49
I0928 13:46:48.650544  4581 net.cpp:406] Scale49 <- Convolution49
I0928 13:46:48.650547  4581 net.cpp:367] Scale49 -> Convolution49 (in-place)
I0928 13:46:48.650588  4581 layer_factory.hpp:77] Creating layer Scale49
I0928 13:46:48.650671  4581 net.cpp:122] Setting up Scale49
I0928 13:46:48.650676  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.650677  4581 net.cpp:137] Memory required for data: 851424400
I0928 13:46:48.650681  4581 layer_factory.hpp:77] Creating layer Eltwise23
I0928 13:46:48.650686  4581 net.cpp:84] Creating Layer Eltwise23
I0928 13:46:48.650687  4581 net.cpp:406] Eltwise23 <- Eltwise22_M2PELU45_0_split_1
I0928 13:46:48.650691  4581 net.cpp:406] Eltwise23 <- Convolution49
I0928 13:46:48.650694  4581 net.cpp:380] Eltwise23 -> Eltwise23
I0928 13:46:48.650712  4581 net.cpp:122] Setting up Eltwise23
I0928 13:46:48.650715  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.650717  4581 net.cpp:137] Memory required for data: 852678800
I0928 13:46:48.650719  4581 layer_factory.hpp:77] Creating layer M2PELU47
I0928 13:46:48.650724  4581 net.cpp:84] Creating Layer M2PELU47
I0928 13:46:48.650727  4581 net.cpp:406] M2PELU47 <- Eltwise23
I0928 13:46:48.650730  4581 net.cpp:367] M2PELU47 -> Eltwise23 (in-place)
I0928 13:46:48.650820  4581 net.cpp:122] Setting up M2PELU47
I0928 13:46:48.650823  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.650825  4581 net.cpp:137] Memory required for data: 853933200
I0928 13:46:48.650828  4581 layer_factory.hpp:77] Creating layer Eltwise23_M2PELU47_0_split
I0928 13:46:48.650833  4581 net.cpp:84] Creating Layer Eltwise23_M2PELU47_0_split
I0928 13:46:48.650835  4581 net.cpp:406] Eltwise23_M2PELU47_0_split <- Eltwise23
I0928 13:46:48.650838  4581 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_0
I0928 13:46:48.650842  4581 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_1
I0928 13:46:48.650867  4581 net.cpp:122] Setting up Eltwise23_M2PELU47_0_split
I0928 13:46:48.650871  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.650874  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.650876  4581 net.cpp:137] Memory required for data: 856442000
I0928 13:46:48.650884  4581 layer_factory.hpp:77] Creating layer Convolution50
I0928 13:46:48.650890  4581 net.cpp:84] Creating Layer Convolution50
I0928 13:46:48.650892  4581 net.cpp:406] Convolution50 <- Eltwise23_M2PELU47_0_split_0
I0928 13:46:48.650897  4581 net.cpp:380] Convolution50 -> Convolution50
I0928 13:46:48.652545  4581 net.cpp:122] Setting up Convolution50
I0928 13:46:48.652554  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.652557  4581 net.cpp:137] Memory required for data: 857696400
I0928 13:46:48.652561  4581 layer_factory.hpp:77] Creating layer BatchNorm50
I0928 13:46:48.652566  4581 net.cpp:84] Creating Layer BatchNorm50
I0928 13:46:48.652570  4581 net.cpp:406] BatchNorm50 <- Convolution50
I0928 13:46:48.652572  4581 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I0928 13:46:48.652739  4581 net.cpp:122] Setting up BatchNorm50
I0928 13:46:48.652742  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.659495  4581 net.cpp:137] Memory required for data: 858950800
I0928 13:46:48.659507  4581 layer_factory.hpp:77] Creating layer Scale50
I0928 13:46:48.659513  4581 net.cpp:84] Creating Layer Scale50
I0928 13:46:48.659518  4581 net.cpp:406] Scale50 <- Convolution50
I0928 13:46:48.659523  4581 net.cpp:367] Scale50 -> Convolution50 (in-place)
I0928 13:46:48.659572  4581 layer_factory.hpp:77] Creating layer Scale50
I0928 13:46:48.659668  4581 net.cpp:122] Setting up Scale50
I0928 13:46:48.659673  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.659675  4581 net.cpp:137] Memory required for data: 860205200
I0928 13:46:48.659680  4581 layer_factory.hpp:77] Creating layer M2PELU48
I0928 13:46:48.659687  4581 net.cpp:84] Creating Layer M2PELU48
I0928 13:46:48.659688  4581 net.cpp:406] M2PELU48 <- Convolution50
I0928 13:46:48.659693  4581 net.cpp:367] M2PELU48 -> Convolution50 (in-place)
I0928 13:46:48.659795  4581 net.cpp:122] Setting up M2PELU48
I0928 13:46:48.659798  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.659801  4581 net.cpp:137] Memory required for data: 861459600
I0928 13:46:48.659806  4581 layer_factory.hpp:77] Creating layer Convolution51
I0928 13:46:48.659812  4581 net.cpp:84] Creating Layer Convolution51
I0928 13:46:48.659814  4581 net.cpp:406] Convolution51 <- Convolution50
I0928 13:46:48.659819  4581 net.cpp:380] Convolution51 -> Convolution51
I0928 13:46:48.662431  4581 net.cpp:122] Setting up Convolution51
I0928 13:46:48.662441  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.662443  4581 net.cpp:137] Memory required for data: 862714000
I0928 13:46:48.662448  4581 layer_factory.hpp:77] Creating layer BatchNorm51
I0928 13:46:48.662453  4581 net.cpp:84] Creating Layer BatchNorm51
I0928 13:46:48.662456  4581 net.cpp:406] BatchNorm51 <- Convolution51
I0928 13:46:48.662461  4581 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I0928 13:46:48.662621  4581 net.cpp:122] Setting up BatchNorm51
I0928 13:46:48.662627  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.662629  4581 net.cpp:137] Memory required for data: 863968400
I0928 13:46:48.662634  4581 layer_factory.hpp:77] Creating layer Scale51
I0928 13:46:48.662638  4581 net.cpp:84] Creating Layer Scale51
I0928 13:46:48.662642  4581 net.cpp:406] Scale51 <- Convolution51
I0928 13:46:48.662644  4581 net.cpp:367] Scale51 -> Convolution51 (in-place)
I0928 13:46:48.662674  4581 layer_factory.hpp:77] Creating layer Scale51
I0928 13:46:48.662762  4581 net.cpp:122] Setting up Scale51
I0928 13:46:48.662766  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.662768  4581 net.cpp:137] Memory required for data: 865222800
I0928 13:46:48.662772  4581 layer_factory.hpp:77] Creating layer Eltwise24
I0928 13:46:48.662776  4581 net.cpp:84] Creating Layer Eltwise24
I0928 13:46:48.662780  4581 net.cpp:406] Eltwise24 <- Eltwise23_M2PELU47_0_split_1
I0928 13:46:48.662782  4581 net.cpp:406] Eltwise24 <- Convolution51
I0928 13:46:48.662786  4581 net.cpp:380] Eltwise24 -> Eltwise24
I0928 13:46:48.662804  4581 net.cpp:122] Setting up Eltwise24
I0928 13:46:48.662816  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.662817  4581 net.cpp:137] Memory required for data: 866477200
I0928 13:46:48.662819  4581 layer_factory.hpp:77] Creating layer M2PELU49
I0928 13:46:48.662824  4581 net.cpp:84] Creating Layer M2PELU49
I0928 13:46:48.662827  4581 net.cpp:406] M2PELU49 <- Eltwise24
I0928 13:46:48.662830  4581 net.cpp:367] M2PELU49 -> Eltwise24 (in-place)
I0928 13:46:48.662926  4581 net.cpp:122] Setting up M2PELU49
I0928 13:46:48.662930  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.662932  4581 net.cpp:137] Memory required for data: 867731600
I0928 13:46:48.662936  4581 layer_factory.hpp:77] Creating layer Eltwise24_M2PELU49_0_split
I0928 13:46:48.662940  4581 net.cpp:84] Creating Layer Eltwise24_M2PELU49_0_split
I0928 13:46:48.662943  4581 net.cpp:406] Eltwise24_M2PELU49_0_split <- Eltwise24
I0928 13:46:48.662946  4581 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_0
I0928 13:46:48.662950  4581 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_1
I0928 13:46:48.662976  4581 net.cpp:122] Setting up Eltwise24_M2PELU49_0_split
I0928 13:46:48.662981  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.662982  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.662984  4581 net.cpp:137] Memory required for data: 870240400
I0928 13:46:48.662986  4581 layer_factory.hpp:77] Creating layer Convolution52
I0928 13:46:48.662992  4581 net.cpp:84] Creating Layer Convolution52
I0928 13:46:48.662995  4581 net.cpp:406] Convolution52 <- Eltwise24_M2PELU49_0_split_0
I0928 13:46:48.663000  4581 net.cpp:380] Convolution52 -> Convolution52
I0928 13:46:48.664762  4581 net.cpp:122] Setting up Convolution52
I0928 13:46:48.664770  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.664773  4581 net.cpp:137] Memory required for data: 871494800
I0928 13:46:48.664777  4581 layer_factory.hpp:77] Creating layer BatchNorm52
I0928 13:46:48.664783  4581 net.cpp:84] Creating Layer BatchNorm52
I0928 13:46:48.664786  4581 net.cpp:406] BatchNorm52 <- Convolution52
I0928 13:46:48.664789  4581 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I0928 13:46:48.664937  4581 net.cpp:122] Setting up BatchNorm52
I0928 13:46:48.664942  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.664943  4581 net.cpp:137] Memory required for data: 872749200
I0928 13:46:48.664948  4581 layer_factory.hpp:77] Creating layer Scale52
I0928 13:46:48.664952  4581 net.cpp:84] Creating Layer Scale52
I0928 13:46:48.664954  4581 net.cpp:406] Scale52 <- Convolution52
I0928 13:46:48.664958  4581 net.cpp:367] Scale52 -> Convolution52 (in-place)
I0928 13:46:48.664986  4581 layer_factory.hpp:77] Creating layer Scale52
I0928 13:46:48.665071  4581 net.cpp:122] Setting up Scale52
I0928 13:46:48.665074  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.665076  4581 net.cpp:137] Memory required for data: 874003600
I0928 13:46:48.665081  4581 layer_factory.hpp:77] Creating layer M2PELU50
I0928 13:46:48.665086  4581 net.cpp:84] Creating Layer M2PELU50
I0928 13:46:48.665088  4581 net.cpp:406] M2PELU50 <- Convolution52
I0928 13:46:48.665091  4581 net.cpp:367] M2PELU50 -> Convolution52 (in-place)
I0928 13:46:48.665182  4581 net.cpp:122] Setting up M2PELU50
I0928 13:46:48.665186  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.665189  4581 net.cpp:137] Memory required for data: 875258000
I0928 13:46:48.665192  4581 layer_factory.hpp:77] Creating layer Convolution53
I0928 13:46:48.665215  4581 net.cpp:84] Creating Layer Convolution53
I0928 13:46:48.665217  4581 net.cpp:406] Convolution53 <- Convolution52
I0928 13:46:48.665221  4581 net.cpp:380] Convolution53 -> Convolution53
I0928 13:46:48.667215  4581 net.cpp:122] Setting up Convolution53
I0928 13:46:48.667224  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.667227  4581 net.cpp:137] Memory required for data: 876512400
I0928 13:46:48.667232  4581 layer_factory.hpp:77] Creating layer BatchNorm53
I0928 13:46:48.667237  4581 net.cpp:84] Creating Layer BatchNorm53
I0928 13:46:48.667246  4581 net.cpp:406] BatchNorm53 <- Convolution53
I0928 13:46:48.667250  4581 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I0928 13:46:48.667399  4581 net.cpp:122] Setting up BatchNorm53
I0928 13:46:48.667403  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.667407  4581 net.cpp:137] Memory required for data: 877766800
I0928 13:46:48.667410  4581 layer_factory.hpp:77] Creating layer Scale53
I0928 13:46:48.667415  4581 net.cpp:84] Creating Layer Scale53
I0928 13:46:48.667418  4581 net.cpp:406] Scale53 <- Convolution53
I0928 13:46:48.667421  4581 net.cpp:367] Scale53 -> Convolution53 (in-place)
I0928 13:46:48.667449  4581 layer_factory.hpp:77] Creating layer Scale53
I0928 13:46:48.667533  4581 net.cpp:122] Setting up Scale53
I0928 13:46:48.667537  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.667541  4581 net.cpp:137] Memory required for data: 879021200
I0928 13:46:48.667544  4581 layer_factory.hpp:77] Creating layer Eltwise25
I0928 13:46:48.667548  4581 net.cpp:84] Creating Layer Eltwise25
I0928 13:46:48.667551  4581 net.cpp:406] Eltwise25 <- Eltwise24_M2PELU49_0_split_1
I0928 13:46:48.667553  4581 net.cpp:406] Eltwise25 <- Convolution53
I0928 13:46:48.667557  4581 net.cpp:380] Eltwise25 -> Eltwise25
I0928 13:46:48.667574  4581 net.cpp:122] Setting up Eltwise25
I0928 13:46:48.667578  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.667580  4581 net.cpp:137] Memory required for data: 880275600
I0928 13:46:48.667582  4581 layer_factory.hpp:77] Creating layer M2PELU51
I0928 13:46:48.667587  4581 net.cpp:84] Creating Layer M2PELU51
I0928 13:46:48.667588  4581 net.cpp:406] M2PELU51 <- Eltwise25
I0928 13:46:48.667593  4581 net.cpp:367] M2PELU51 -> Eltwise25 (in-place)
I0928 13:46:48.667683  4581 net.cpp:122] Setting up M2PELU51
I0928 13:46:48.667687  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.667690  4581 net.cpp:137] Memory required for data: 881530000
I0928 13:46:48.667693  4581 layer_factory.hpp:77] Creating layer Eltwise25_M2PELU51_0_split
I0928 13:46:48.667696  4581 net.cpp:84] Creating Layer Eltwise25_M2PELU51_0_split
I0928 13:46:48.667699  4581 net.cpp:406] Eltwise25_M2PELU51_0_split <- Eltwise25
I0928 13:46:48.667703  4581 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_0
I0928 13:46:48.667707  4581 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_1
I0928 13:46:48.667732  4581 net.cpp:122] Setting up Eltwise25_M2PELU51_0_split
I0928 13:46:48.667735  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.667738  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.667739  4581 net.cpp:137] Memory required for data: 884038800
I0928 13:46:48.667742  4581 layer_factory.hpp:77] Creating layer Convolution54
I0928 13:46:48.667747  4581 net.cpp:84] Creating Layer Convolution54
I0928 13:46:48.667750  4581 net.cpp:406] Convolution54 <- Eltwise25_M2PELU51_0_split_0
I0928 13:46:48.667754  4581 net.cpp:380] Convolution54 -> Convolution54
I0928 13:46:48.669912  4581 net.cpp:122] Setting up Convolution54
I0928 13:46:48.669921  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.669924  4581 net.cpp:137] Memory required for data: 885293200
I0928 13:46:48.669929  4581 layer_factory.hpp:77] Creating layer BatchNorm54
I0928 13:46:48.669934  4581 net.cpp:84] Creating Layer BatchNorm54
I0928 13:46:48.669936  4581 net.cpp:406] BatchNorm54 <- Convolution54
I0928 13:46:48.669940  4581 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I0928 13:46:48.670085  4581 net.cpp:122] Setting up BatchNorm54
I0928 13:46:48.670089  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.670091  4581 net.cpp:137] Memory required for data: 886547600
I0928 13:46:48.670096  4581 layer_factory.hpp:77] Creating layer Scale54
I0928 13:46:48.670101  4581 net.cpp:84] Creating Layer Scale54
I0928 13:46:48.670104  4581 net.cpp:406] Scale54 <- Convolution54
I0928 13:46:48.670106  4581 net.cpp:367] Scale54 -> Convolution54 (in-place)
I0928 13:46:48.670136  4581 layer_factory.hpp:77] Creating layer Scale54
I0928 13:46:48.670230  4581 net.cpp:122] Setting up Scale54
I0928 13:46:48.670235  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.670238  4581 net.cpp:137] Memory required for data: 887802000
I0928 13:46:48.670241  4581 layer_factory.hpp:77] Creating layer M2PELU52
I0928 13:46:48.670245  4581 net.cpp:84] Creating Layer M2PELU52
I0928 13:46:48.670248  4581 net.cpp:406] M2PELU52 <- Convolution54
I0928 13:46:48.670251  4581 net.cpp:367] M2PELU52 -> Convolution54 (in-place)
I0928 13:46:48.670342  4581 net.cpp:122] Setting up M2PELU52
I0928 13:46:48.670347  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.670349  4581 net.cpp:137] Memory required for data: 889056400
I0928 13:46:48.670352  4581 layer_factory.hpp:77] Creating layer Convolution55
I0928 13:46:48.670359  4581 net.cpp:84] Creating Layer Convolution55
I0928 13:46:48.670362  4581 net.cpp:406] Convolution55 <- Convolution54
I0928 13:46:48.670366  4581 net.cpp:380] Convolution55 -> Convolution55
I0928 13:46:48.672343  4581 net.cpp:122] Setting up Convolution55
I0928 13:46:48.672353  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.672354  4581 net.cpp:137] Memory required for data: 890310800
I0928 13:46:48.672359  4581 layer_factory.hpp:77] Creating layer BatchNorm55
I0928 13:46:48.672364  4581 net.cpp:84] Creating Layer BatchNorm55
I0928 13:46:48.672368  4581 net.cpp:406] BatchNorm55 <- Convolution55
I0928 13:46:48.672370  4581 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I0928 13:46:48.672520  4581 net.cpp:122] Setting up BatchNorm55
I0928 13:46:48.672525  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.672528  4581 net.cpp:137] Memory required for data: 891565200
I0928 13:46:48.672533  4581 layer_factory.hpp:77] Creating layer Scale55
I0928 13:46:48.672535  4581 net.cpp:84] Creating Layer Scale55
I0928 13:46:48.672538  4581 net.cpp:406] Scale55 <- Convolution55
I0928 13:46:48.672541  4581 net.cpp:367] Scale55 -> Convolution55 (in-place)
I0928 13:46:48.672571  4581 layer_factory.hpp:77] Creating layer Scale55
I0928 13:46:48.672657  4581 net.cpp:122] Setting up Scale55
I0928 13:46:48.672662  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.672663  4581 net.cpp:137] Memory required for data: 892819600
I0928 13:46:48.672667  4581 layer_factory.hpp:77] Creating layer Eltwise26
I0928 13:46:48.672672  4581 net.cpp:84] Creating Layer Eltwise26
I0928 13:46:48.672674  4581 net.cpp:406] Eltwise26 <- Eltwise25_M2PELU51_0_split_1
I0928 13:46:48.672677  4581 net.cpp:406] Eltwise26 <- Convolution55
I0928 13:46:48.672680  4581 net.cpp:380] Eltwise26 -> Eltwise26
I0928 13:46:48.672698  4581 net.cpp:122] Setting up Eltwise26
I0928 13:46:48.672703  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.672704  4581 net.cpp:137] Memory required for data: 894074000
I0928 13:46:48.672706  4581 layer_factory.hpp:77] Creating layer M2PELU53
I0928 13:46:48.672711  4581 net.cpp:84] Creating Layer M2PELU53
I0928 13:46:48.672713  4581 net.cpp:406] M2PELU53 <- Eltwise26
I0928 13:46:48.672716  4581 net.cpp:367] M2PELU53 -> Eltwise26 (in-place)
I0928 13:46:48.672808  4581 net.cpp:122] Setting up M2PELU53
I0928 13:46:48.672812  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.672814  4581 net.cpp:137] Memory required for data: 895328400
I0928 13:46:48.672818  4581 layer_factory.hpp:77] Creating layer Eltwise26_M2PELU53_0_split
I0928 13:46:48.672821  4581 net.cpp:84] Creating Layer Eltwise26_M2PELU53_0_split
I0928 13:46:48.672824  4581 net.cpp:406] Eltwise26_M2PELU53_0_split <- Eltwise26
I0928 13:46:48.672827  4581 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_0
I0928 13:46:48.672832  4581 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_1
I0928 13:46:48.672857  4581 net.cpp:122] Setting up Eltwise26_M2PELU53_0_split
I0928 13:46:48.672860  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.672863  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.672865  4581 net.cpp:137] Memory required for data: 897837200
I0928 13:46:48.672873  4581 layer_factory.hpp:77] Creating layer Convolution56
I0928 13:46:48.672880  4581 net.cpp:84] Creating Layer Convolution56
I0928 13:46:48.672883  4581 net.cpp:406] Convolution56 <- Eltwise26_M2PELU53_0_split_0
I0928 13:46:48.672888  4581 net.cpp:380] Convolution56 -> Convolution56
I0928 13:46:48.674574  4581 net.cpp:122] Setting up Convolution56
I0928 13:46:48.674583  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.674585  4581 net.cpp:137] Memory required for data: 899091600
I0928 13:46:48.674590  4581 layer_factory.hpp:77] Creating layer BatchNorm56
I0928 13:46:48.674595  4581 net.cpp:84] Creating Layer BatchNorm56
I0928 13:46:48.674598  4581 net.cpp:406] BatchNorm56 <- Convolution56
I0928 13:46:48.674602  4581 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I0928 13:46:48.690289  4581 net.cpp:122] Setting up BatchNorm56
I0928 13:46:48.690297  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.690300  4581 net.cpp:137] Memory required for data: 900346000
I0928 13:46:48.690306  4581 layer_factory.hpp:77] Creating layer Scale56
I0928 13:46:48.690312  4581 net.cpp:84] Creating Layer Scale56
I0928 13:46:48.690316  4581 net.cpp:406] Scale56 <- Convolution56
I0928 13:46:48.690320  4581 net.cpp:367] Scale56 -> Convolution56 (in-place)
I0928 13:46:48.690354  4581 layer_factory.hpp:77] Creating layer Scale56
I0928 13:46:48.690450  4581 net.cpp:122] Setting up Scale56
I0928 13:46:48.690455  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.690457  4581 net.cpp:137] Memory required for data: 901600400
I0928 13:46:48.690462  4581 layer_factory.hpp:77] Creating layer M2PELU54
I0928 13:46:48.690467  4581 net.cpp:84] Creating Layer M2PELU54
I0928 13:46:48.690470  4581 net.cpp:406] M2PELU54 <- Convolution56
I0928 13:46:48.690474  4581 net.cpp:367] M2PELU54 -> Convolution56 (in-place)
I0928 13:46:48.690585  4581 net.cpp:122] Setting up M2PELU54
I0928 13:46:48.690590  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.690593  4581 net.cpp:137] Memory required for data: 902854800
I0928 13:46:48.690598  4581 layer_factory.hpp:77] Creating layer Convolution57
I0928 13:46:48.690605  4581 net.cpp:84] Creating Layer Convolution57
I0928 13:46:48.690608  4581 net.cpp:406] Convolution57 <- Convolution56
I0928 13:46:48.690613  4581 net.cpp:380] Convolution57 -> Convolution57
I0928 13:46:48.692418  4581 net.cpp:122] Setting up Convolution57
I0928 13:46:48.692427  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.692430  4581 net.cpp:137] Memory required for data: 904109200
I0928 13:46:48.692435  4581 layer_factory.hpp:77] Creating layer BatchNorm57
I0928 13:46:48.692440  4581 net.cpp:84] Creating Layer BatchNorm57
I0928 13:46:48.692442  4581 net.cpp:406] BatchNorm57 <- Convolution57
I0928 13:46:48.692447  4581 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I0928 13:46:48.692654  4581 net.cpp:122] Setting up BatchNorm57
I0928 13:46:48.692661  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.692662  4581 net.cpp:137] Memory required for data: 905363600
I0928 13:46:48.692668  4581 layer_factory.hpp:77] Creating layer Scale57
I0928 13:46:48.692672  4581 net.cpp:84] Creating Layer Scale57
I0928 13:46:48.692675  4581 net.cpp:406] Scale57 <- Convolution57
I0928 13:46:48.692679  4581 net.cpp:367] Scale57 -> Convolution57 (in-place)
I0928 13:46:48.692710  4581 layer_factory.hpp:77] Creating layer Scale57
I0928 13:46:48.692800  4581 net.cpp:122] Setting up Scale57
I0928 13:46:48.692806  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.692807  4581 net.cpp:137] Memory required for data: 906618000
I0928 13:46:48.692811  4581 layer_factory.hpp:77] Creating layer Eltwise27
I0928 13:46:48.692816  4581 net.cpp:84] Creating Layer Eltwise27
I0928 13:46:48.692817  4581 net.cpp:406] Eltwise27 <- Eltwise26_M2PELU53_0_split_1
I0928 13:46:48.692821  4581 net.cpp:406] Eltwise27 <- Convolution57
I0928 13:46:48.692824  4581 net.cpp:380] Eltwise27 -> Eltwise27
I0928 13:46:48.692843  4581 net.cpp:122] Setting up Eltwise27
I0928 13:46:48.692853  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.692857  4581 net.cpp:137] Memory required for data: 907872400
I0928 13:46:48.692858  4581 layer_factory.hpp:77] Creating layer M2PELU55
I0928 13:46:48.692862  4581 net.cpp:84] Creating Layer M2PELU55
I0928 13:46:48.692865  4581 net.cpp:406] M2PELU55 <- Eltwise27
I0928 13:46:48.692869  4581 net.cpp:367] M2PELU55 -> Eltwise27 (in-place)
I0928 13:46:48.692967  4581 net.cpp:122] Setting up M2PELU55
I0928 13:46:48.692972  4581 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 13:46:48.692975  4581 net.cpp:137] Memory required for data: 909126800
I0928 13:46:48.692978  4581 layer_factory.hpp:77] Creating layer Pooling1
I0928 13:46:48.692983  4581 net.cpp:84] Creating Layer Pooling1
I0928 13:46:48.692986  4581 net.cpp:406] Pooling1 <- Eltwise27
I0928 13:46:48.692989  4581 net.cpp:380] Pooling1 -> Pooling1
I0928 13:46:48.693464  4581 net.cpp:122] Setting up Pooling1
I0928 13:46:48.693473  4581 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0928 13:46:48.693476  4581 net.cpp:137] Memory required for data: 909152400
I0928 13:46:48.693478  4581 layer_factory.hpp:77] Creating layer InnerProduct1
I0928 13:46:48.693487  4581 net.cpp:84] Creating Layer InnerProduct1
I0928 13:46:48.693490  4581 net.cpp:406] InnerProduct1 <- Pooling1
I0928 13:46:48.693495  4581 net.cpp:380] InnerProduct1 -> InnerProduct1
I0928 13:46:48.693617  4581 net.cpp:122] Setting up InnerProduct1
I0928 13:46:48.693622  4581 net.cpp:129] Top shape: 100 10 (1000)
I0928 13:46:48.693624  4581 net.cpp:137] Memory required for data: 909156400
I0928 13:46:48.693629  4581 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0928 13:46:48.693634  4581 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0928 13:46:48.693636  4581 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I0928 13:46:48.693639  4581 net.cpp:406] SoftmaxWithLoss1 <- Data2
I0928 13:46:48.693644  4581 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0928 13:46:48.693648  4581 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0928 13:46:48.693866  4581 net.cpp:122] Setting up SoftmaxWithLoss1
I0928 13:46:48.693871  4581 net.cpp:129] Top shape: (1)
I0928 13:46:48.693874  4581 net.cpp:132]     with loss weight 1
I0928 13:46:48.693886  4581 net.cpp:137] Memory required for data: 909156404
I0928 13:46:48.693889  4581 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0928 13:46:48.693892  4581 net.cpp:198] InnerProduct1 needs backward computation.
I0928 13:46:48.693894  4581 net.cpp:198] Pooling1 needs backward computation.
I0928 13:46:48.693897  4581 net.cpp:198] M2PELU55 needs backward computation.
I0928 13:46:48.693898  4581 net.cpp:198] Eltwise27 needs backward computation.
I0928 13:46:48.693900  4581 net.cpp:198] Scale57 needs backward computation.
I0928 13:46:48.693903  4581 net.cpp:198] BatchNorm57 needs backward computation.
I0928 13:46:48.693905  4581 net.cpp:198] Convolution57 needs backward computation.
I0928 13:46:48.693907  4581 net.cpp:198] M2PELU54 needs backward computation.
I0928 13:46:48.693909  4581 net.cpp:198] Scale56 needs backward computation.
I0928 13:46:48.693912  4581 net.cpp:198] BatchNorm56 needs backward computation.
I0928 13:46:48.693913  4581 net.cpp:198] Convolution56 needs backward computation.
I0928 13:46:48.693915  4581 net.cpp:198] Eltwise26_M2PELU53_0_split needs backward computation.
I0928 13:46:48.693917  4581 net.cpp:198] M2PELU53 needs backward computation.
I0928 13:46:48.693919  4581 net.cpp:198] Eltwise26 needs backward computation.
I0928 13:46:48.693922  4581 net.cpp:198] Scale55 needs backward computation.
I0928 13:46:48.693924  4581 net.cpp:198] BatchNorm55 needs backward computation.
I0928 13:46:48.693928  4581 net.cpp:198] Convolution55 needs backward computation.
I0928 13:46:48.693930  4581 net.cpp:198] M2PELU52 needs backward computation.
I0928 13:46:48.693933  4581 net.cpp:198] Scale54 needs backward computation.
I0928 13:46:48.693934  4581 net.cpp:198] BatchNorm54 needs backward computation.
I0928 13:46:48.693936  4581 net.cpp:198] Convolution54 needs backward computation.
I0928 13:46:48.693946  4581 net.cpp:198] Eltwise25_M2PELU51_0_split needs backward computation.
I0928 13:46:48.693948  4581 net.cpp:198] M2PELU51 needs backward computation.
I0928 13:46:48.693951  4581 net.cpp:198] Eltwise25 needs backward computation.
I0928 13:46:48.693953  4581 net.cpp:198] Scale53 needs backward computation.
I0928 13:46:48.693955  4581 net.cpp:198] BatchNorm53 needs backward computation.
I0928 13:46:48.693958  4581 net.cpp:198] Convolution53 needs backward computation.
I0928 13:46:48.693959  4581 net.cpp:198] M2PELU50 needs backward computation.
I0928 13:46:48.693963  4581 net.cpp:198] Scale52 needs backward computation.
I0928 13:46:48.693964  4581 net.cpp:198] BatchNorm52 needs backward computation.
I0928 13:46:48.693966  4581 net.cpp:198] Convolution52 needs backward computation.
I0928 13:46:48.693969  4581 net.cpp:198] Eltwise24_M2PELU49_0_split needs backward computation.
I0928 13:46:48.693971  4581 net.cpp:198] M2PELU49 needs backward computation.
I0928 13:46:48.693974  4581 net.cpp:198] Eltwise24 needs backward computation.
I0928 13:46:48.693976  4581 net.cpp:198] Scale51 needs backward computation.
I0928 13:46:48.693979  4581 net.cpp:198] BatchNorm51 needs backward computation.
I0928 13:46:48.693980  4581 net.cpp:198] Convolution51 needs backward computation.
I0928 13:46:48.693984  4581 net.cpp:198] M2PELU48 needs backward computation.
I0928 13:46:48.693985  4581 net.cpp:198] Scale50 needs backward computation.
I0928 13:46:48.693987  4581 net.cpp:198] BatchNorm50 needs backward computation.
I0928 13:46:48.693989  4581 net.cpp:198] Convolution50 needs backward computation.
I0928 13:46:48.693991  4581 net.cpp:198] Eltwise23_M2PELU47_0_split needs backward computation.
I0928 13:46:48.693994  4581 net.cpp:198] M2PELU47 needs backward computation.
I0928 13:46:48.693996  4581 net.cpp:198] Eltwise23 needs backward computation.
I0928 13:46:48.694000  4581 net.cpp:198] Scale49 needs backward computation.
I0928 13:46:48.694001  4581 net.cpp:198] BatchNorm49 needs backward computation.
I0928 13:46:48.694005  4581 net.cpp:198] Convolution49 needs backward computation.
I0928 13:46:48.694006  4581 net.cpp:198] M2PELU46 needs backward computation.
I0928 13:46:48.694008  4581 net.cpp:198] Scale48 needs backward computation.
I0928 13:46:48.694010  4581 net.cpp:198] BatchNorm48 needs backward computation.
I0928 13:46:48.694013  4581 net.cpp:198] Convolution48 needs backward computation.
I0928 13:46:48.694015  4581 net.cpp:198] Eltwise22_M2PELU45_0_split needs backward computation.
I0928 13:46:48.694018  4581 net.cpp:198] M2PELU45 needs backward computation.
I0928 13:46:48.694020  4581 net.cpp:198] Eltwise22 needs backward computation.
I0928 13:46:48.694023  4581 net.cpp:198] Scale47 needs backward computation.
I0928 13:46:48.694025  4581 net.cpp:198] BatchNorm47 needs backward computation.
I0928 13:46:48.694027  4581 net.cpp:198] Convolution47 needs backward computation.
I0928 13:46:48.694031  4581 net.cpp:198] M2PELU44 needs backward computation.
I0928 13:46:48.694032  4581 net.cpp:198] Scale46 needs backward computation.
I0928 13:46:48.694034  4581 net.cpp:198] BatchNorm46 needs backward computation.
I0928 13:46:48.694037  4581 net.cpp:198] Convolution46 needs backward computation.
I0928 13:46:48.694039  4581 net.cpp:198] Eltwise21_M2PELU43_0_split needs backward computation.
I0928 13:46:48.694041  4581 net.cpp:198] M2PELU43 needs backward computation.
I0928 13:46:48.694044  4581 net.cpp:198] Eltwise21 needs backward computation.
I0928 13:46:48.694046  4581 net.cpp:198] Scale45 needs backward computation.
I0928 13:46:48.694049  4581 net.cpp:198] BatchNorm45 needs backward computation.
I0928 13:46:48.694051  4581 net.cpp:198] Convolution45 needs backward computation.
I0928 13:46:48.694054  4581 net.cpp:198] M2PELU42 needs backward computation.
I0928 13:46:48.694056  4581 net.cpp:198] Scale44 needs backward computation.
I0928 13:46:48.694058  4581 net.cpp:198] BatchNorm44 needs backward computation.
I0928 13:46:48.694061  4581 net.cpp:198] Convolution44 needs backward computation.
I0928 13:46:48.694067  4581 net.cpp:198] Eltwise20_M2PELU41_0_split needs backward computation.
I0928 13:46:48.694069  4581 net.cpp:198] M2PELU41 needs backward computation.
I0928 13:46:48.694072  4581 net.cpp:198] Eltwise20 needs backward computation.
I0928 13:46:48.694074  4581 net.cpp:198] Scale43 needs backward computation.
I0928 13:46:48.694077  4581 net.cpp:198] BatchNorm43 needs backward computation.
I0928 13:46:48.694078  4581 net.cpp:198] Convolution43 needs backward computation.
I0928 13:46:48.694082  4581 net.cpp:198] M2PELU40 needs backward computation.
I0928 13:46:48.694083  4581 net.cpp:198] Scale42 needs backward computation.
I0928 13:46:48.694085  4581 net.cpp:198] BatchNorm42 needs backward computation.
I0928 13:46:48.694088  4581 net.cpp:198] Convolution42 needs backward computation.
I0928 13:46:48.694092  4581 net.cpp:198] Eltwise19_M2PELU39_0_split needs backward computation.
I0928 13:46:48.694093  4581 net.cpp:198] M2PELU39 needs backward computation.
I0928 13:46:48.694095  4581 net.cpp:198] Eltwise19 needs backward computation.
I0928 13:46:48.694098  4581 net.cpp:198] Scale41 needs backward computation.
I0928 13:46:48.694102  4581 net.cpp:198] BatchNorm41 needs backward computation.
I0928 13:46:48.694103  4581 net.cpp:198] Convolution41 needs backward computation.
I0928 13:46:48.694105  4581 net.cpp:198] M2PELU38 needs backward computation.
I0928 13:46:48.694108  4581 net.cpp:198] Scale40 needs backward computation.
I0928 13:46:48.694110  4581 net.cpp:198] BatchNorm40 needs backward computation.
I0928 13:46:48.694113  4581 net.cpp:198] Convolution40 needs backward computation.
I0928 13:46:48.694115  4581 net.cpp:198] Scale39 needs backward computation.
I0928 13:46:48.694118  4581 net.cpp:198] BatchNorm39 needs backward computation.
I0928 13:46:48.694119  4581 net.cpp:198] Convolution39 needs backward computation.
I0928 13:46:48.694123  4581 net.cpp:198] Eltwise18_M2PELU37_0_split needs backward computation.
I0928 13:46:48.694124  4581 net.cpp:198] M2PELU37 needs backward computation.
I0928 13:46:48.694128  4581 net.cpp:198] Eltwise18 needs backward computation.
I0928 13:46:48.694129  4581 net.cpp:198] Scale38 needs backward computation.
I0928 13:46:48.694133  4581 net.cpp:198] BatchNorm38 needs backward computation.
I0928 13:46:48.694134  4581 net.cpp:198] Convolution38 needs backward computation.
I0928 13:46:48.694136  4581 net.cpp:198] M2PELU36 needs backward computation.
I0928 13:46:48.694139  4581 net.cpp:198] Scale37 needs backward computation.
I0928 13:46:48.694140  4581 net.cpp:198] BatchNorm37 needs backward computation.
I0928 13:46:48.694152  4581 net.cpp:198] Convolution37 needs backward computation.
I0928 13:46:48.694154  4581 net.cpp:198] Eltwise17_M2PELU35_0_split needs backward computation.
I0928 13:46:48.694157  4581 net.cpp:198] M2PELU35 needs backward computation.
I0928 13:46:48.694159  4581 net.cpp:198] Eltwise17 needs backward computation.
I0928 13:46:48.694162  4581 net.cpp:198] Scale36 needs backward computation.
I0928 13:46:48.694164  4581 net.cpp:198] BatchNorm36 needs backward computation.
I0928 13:46:48.694166  4581 net.cpp:198] Convolution36 needs backward computation.
I0928 13:46:48.694169  4581 net.cpp:198] M2PELU34 needs backward computation.
I0928 13:46:48.694171  4581 net.cpp:198] Scale35 needs backward computation.
I0928 13:46:48.694173  4581 net.cpp:198] BatchNorm35 needs backward computation.
I0928 13:46:48.694175  4581 net.cpp:198] Convolution35 needs backward computation.
I0928 13:46:48.694177  4581 net.cpp:198] Eltwise16_M2PELU33_0_split needs backward computation.
I0928 13:46:48.694180  4581 net.cpp:198] M2PELU33 needs backward computation.
I0928 13:46:48.694182  4581 net.cpp:198] Eltwise16 needs backward computation.
I0928 13:46:48.694185  4581 net.cpp:198] Scale34 needs backward computation.
I0928 13:46:48.694187  4581 net.cpp:198] BatchNorm34 needs backward computation.
I0928 13:46:48.694190  4581 net.cpp:198] Convolution34 needs backward computation.
I0928 13:46:48.694192  4581 net.cpp:198] M2PELU32 needs backward computation.
I0928 13:46:48.694195  4581 net.cpp:198] Scale33 needs backward computation.
I0928 13:46:48.694200  4581 net.cpp:198] BatchNorm33 needs backward computation.
I0928 13:46:48.694203  4581 net.cpp:198] Convolution33 needs backward computation.
I0928 13:46:48.694205  4581 net.cpp:198] Eltwise15_M2PELU31_0_split needs backward computation.
I0928 13:46:48.694218  4581 net.cpp:198] M2PELU31 needs backward computation.
I0928 13:46:48.694221  4581 net.cpp:198] Eltwise15 needs backward computation.
I0928 13:46:48.694223  4581 net.cpp:198] Scale32 needs backward computation.
I0928 13:46:48.694226  4581 net.cpp:198] BatchNorm32 needs backward computation.
I0928 13:46:48.694227  4581 net.cpp:198] Convolution32 needs backward computation.
I0928 13:46:48.720715  4581 net.cpp:198] M2PELU30 needs backward computation.
I0928 13:46:48.720726  4581 net.cpp:198] Scale31 needs backward computation.
I0928 13:46:48.720731  4581 net.cpp:198] BatchNorm31 needs backward computation.
I0928 13:46:48.720734  4581 net.cpp:198] Convolution31 needs backward computation.
I0928 13:46:48.720739  4581 net.cpp:198] Eltwise14_M2PELU29_0_split needs backward computation.
I0928 13:46:48.720743  4581 net.cpp:198] M2PELU29 needs backward computation.
I0928 13:46:48.720747  4581 net.cpp:198] Eltwise14 needs backward computation.
I0928 13:46:48.720752  4581 net.cpp:198] Scale30 needs backward computation.
I0928 13:46:48.720757  4581 net.cpp:198] BatchNorm30 needs backward computation.
I0928 13:46:48.720760  4581 net.cpp:198] Convolution30 needs backward computation.
I0928 13:46:48.720764  4581 net.cpp:198] M2PELU28 needs backward computation.
I0928 13:46:48.720768  4581 net.cpp:198] Scale29 needs backward computation.
I0928 13:46:48.720772  4581 net.cpp:198] BatchNorm29 needs backward computation.
I0928 13:46:48.720775  4581 net.cpp:198] Convolution29 needs backward computation.
I0928 13:46:48.720780  4581 net.cpp:198] Eltwise13_M2PELU27_0_split needs backward computation.
I0928 13:46:48.720784  4581 net.cpp:198] M2PELU27 needs backward computation.
I0928 13:46:48.720788  4581 net.cpp:198] Eltwise13 needs backward computation.
I0928 13:46:48.720793  4581 net.cpp:198] Scale28 needs backward computation.
I0928 13:46:48.720796  4581 net.cpp:198] BatchNorm28 needs backward computation.
I0928 13:46:48.720798  4581 net.cpp:198] Convolution28 needs backward computation.
I0928 13:46:48.720801  4581 net.cpp:198] M2PELU26 needs backward computation.
I0928 13:46:48.720803  4581 net.cpp:198] Scale27 needs backward computation.
I0928 13:46:48.720805  4581 net.cpp:198] BatchNorm27 needs backward computation.
I0928 13:46:48.720808  4581 net.cpp:198] Convolution27 needs backward computation.
I0928 13:46:48.720810  4581 net.cpp:198] Eltwise12_M2PELU25_0_split needs backward computation.
I0928 13:46:48.720813  4581 net.cpp:198] M2PELU25 needs backward computation.
I0928 13:46:48.720816  4581 net.cpp:198] Eltwise12 needs backward computation.
I0928 13:46:48.720818  4581 net.cpp:198] Scale26 needs backward computation.
I0928 13:46:48.720821  4581 net.cpp:198] BatchNorm26 needs backward computation.
I0928 13:46:48.720824  4581 net.cpp:198] Convolution26 needs backward computation.
I0928 13:46:48.720826  4581 net.cpp:198] M2PELU24 needs backward computation.
I0928 13:46:48.720829  4581 net.cpp:198] Scale25 needs backward computation.
I0928 13:46:48.720830  4581 net.cpp:198] BatchNorm25 needs backward computation.
I0928 13:46:48.720834  4581 net.cpp:198] Convolution25 needs backward computation.
I0928 13:46:48.720836  4581 net.cpp:198] Eltwise11_M2PELU23_0_split needs backward computation.
I0928 13:46:48.720839  4581 net.cpp:198] M2PELU23 needs backward computation.
I0928 13:46:48.720840  4581 net.cpp:198] Eltwise11 needs backward computation.
I0928 13:46:48.720844  4581 net.cpp:198] Scale24 needs backward computation.
I0928 13:46:48.720846  4581 net.cpp:198] BatchNorm24 needs backward computation.
I0928 13:46:48.720849  4581 net.cpp:198] Convolution24 needs backward computation.
I0928 13:46:48.720851  4581 net.cpp:198] M2PELU22 needs backward computation.
I0928 13:46:48.720854  4581 net.cpp:198] Scale23 needs backward computation.
I0928 13:46:48.720862  4581 net.cpp:198] BatchNorm23 needs backward computation.
I0928 13:46:48.720865  4581 net.cpp:198] Convolution23 needs backward computation.
I0928 13:46:48.720868  4581 net.cpp:198] Eltwise10_M2PELU21_0_split needs backward computation.
I0928 13:46:48.720870  4581 net.cpp:198] M2PELU21 needs backward computation.
I0928 13:46:48.720873  4581 net.cpp:198] Eltwise10 needs backward computation.
I0928 13:46:48.720876  4581 net.cpp:198] Scale22 needs backward computation.
I0928 13:46:48.720878  4581 net.cpp:198] BatchNorm22 needs backward computation.
I0928 13:46:48.720881  4581 net.cpp:198] Convolution22 needs backward computation.
I0928 13:46:48.720885  4581 net.cpp:198] M2PELU20 needs backward computation.
I0928 13:46:48.720886  4581 net.cpp:198] Scale21 needs backward computation.
I0928 13:46:48.720888  4581 net.cpp:198] BatchNorm21 needs backward computation.
I0928 13:46:48.720891  4581 net.cpp:198] Convolution21 needs backward computation.
I0928 13:46:48.720894  4581 net.cpp:198] Scale20 needs backward computation.
I0928 13:46:48.720896  4581 net.cpp:198] BatchNorm20 needs backward computation.
I0928 13:46:48.720898  4581 net.cpp:198] Convolution20 needs backward computation.
I0928 13:46:48.720901  4581 net.cpp:198] Eltwise9_M2PELU19_0_split needs backward computation.
I0928 13:46:48.720904  4581 net.cpp:198] M2PELU19 needs backward computation.
I0928 13:46:48.720906  4581 net.cpp:198] Eltwise9 needs backward computation.
I0928 13:46:48.720909  4581 net.cpp:198] Scale19 needs backward computation.
I0928 13:46:48.720913  4581 net.cpp:198] BatchNorm19 needs backward computation.
I0928 13:46:48.720916  4581 net.cpp:198] Convolution19 needs backward computation.
I0928 13:46:48.720918  4581 net.cpp:198] M2PELU18 needs backward computation.
I0928 13:46:48.720921  4581 net.cpp:198] Scale18 needs backward computation.
I0928 13:46:48.720923  4581 net.cpp:198] BatchNorm18 needs backward computation.
I0928 13:46:48.720926  4581 net.cpp:198] Convolution18 needs backward computation.
I0928 13:46:48.720928  4581 net.cpp:198] Eltwise8_M2PELU17_0_split needs backward computation.
I0928 13:46:48.720932  4581 net.cpp:198] M2PELU17 needs backward computation.
I0928 13:46:48.720933  4581 net.cpp:198] Eltwise8 needs backward computation.
I0928 13:46:48.720937  4581 net.cpp:198] Scale17 needs backward computation.
I0928 13:46:48.720939  4581 net.cpp:198] BatchNorm17 needs backward computation.
I0928 13:46:48.720942  4581 net.cpp:198] Convolution17 needs backward computation.
I0928 13:46:48.720943  4581 net.cpp:198] M2PELU16 needs backward computation.
I0928 13:46:48.720947  4581 net.cpp:198] Scale16 needs backward computation.
I0928 13:46:48.720948  4581 net.cpp:198] BatchNorm16 needs backward computation.
I0928 13:46:48.720950  4581 net.cpp:198] Convolution16 needs backward computation.
I0928 13:46:48.720953  4581 net.cpp:198] Eltwise7_M2PELU15_0_split needs backward computation.
I0928 13:46:48.720957  4581 net.cpp:198] M2PELU15 needs backward computation.
I0928 13:46:48.720958  4581 net.cpp:198] Eltwise7 needs backward computation.
I0928 13:46:48.720962  4581 net.cpp:198] Scale15 needs backward computation.
I0928 13:46:48.720964  4581 net.cpp:198] BatchNorm15 needs backward computation.
I0928 13:46:48.720966  4581 net.cpp:198] Convolution15 needs backward computation.
I0928 13:46:48.720968  4581 net.cpp:198] M2PELU14 needs backward computation.
I0928 13:46:48.720971  4581 net.cpp:198] Scale14 needs backward computation.
I0928 13:46:48.720973  4581 net.cpp:198] BatchNorm14 needs backward computation.
I0928 13:46:48.720976  4581 net.cpp:198] Convolution14 needs backward computation.
I0928 13:46:48.720979  4581 net.cpp:198] Eltwise6_M2PELU13_0_split needs backward computation.
I0928 13:46:48.720981  4581 net.cpp:198] M2PELU13 needs backward computation.
I0928 13:46:48.720984  4581 net.cpp:198] Eltwise6 needs backward computation.
I0928 13:46:48.720986  4581 net.cpp:198] Scale13 needs backward computation.
I0928 13:46:48.720989  4581 net.cpp:198] BatchNorm13 needs backward computation.
I0928 13:46:48.720991  4581 net.cpp:198] Convolution13 needs backward computation.
I0928 13:46:48.720998  4581 net.cpp:198] M2PELU12 needs backward computation.
I0928 13:46:48.721000  4581 net.cpp:198] Scale12 needs backward computation.
I0928 13:46:48.721002  4581 net.cpp:198] BatchNorm12 needs backward computation.
I0928 13:46:48.721004  4581 net.cpp:198] Convolution12 needs backward computation.
I0928 13:46:48.721007  4581 net.cpp:198] Eltwise5_M2PELU11_0_split needs backward computation.
I0928 13:46:48.721010  4581 net.cpp:198] M2PELU11 needs backward computation.
I0928 13:46:48.721012  4581 net.cpp:198] Eltwise5 needs backward computation.
I0928 13:46:48.723103  4581 net.cpp:198] Scale11 needs backward computation.
I0928 13:46:48.723111  4581 net.cpp:198] BatchNorm11 needs backward computation.
I0928 13:46:48.723115  4581 net.cpp:198] Convolution11 needs backward computation.
I0928 13:46:48.723119  4581 net.cpp:198] M2PELU10 needs backward computation.
I0928 13:46:48.723124  4581 net.cpp:198] Scale10 needs backward computation.
I0928 13:46:48.723135  4581 net.cpp:198] BatchNorm10 needs backward computation.
I0928 13:46:48.723140  4581 net.cpp:198] Convolution10 needs backward computation.
I0928 13:46:48.723153  4581 net.cpp:198] Eltwise4_M2PELU9_0_split needs backward computation.
I0928 13:46:48.723157  4581 net.cpp:198] M2PELU9 needs backward computation.
I0928 13:46:48.723161  4581 net.cpp:198] Eltwise4 needs backward computation.
I0928 13:46:48.723166  4581 net.cpp:198] Scale9 needs backward computation.
I0928 13:46:48.723170  4581 net.cpp:198] BatchNorm9 needs backward computation.
I0928 13:46:48.723173  4581 net.cpp:198] Convolution9 needs backward computation.
I0928 13:46:48.723178  4581 net.cpp:198] M2PELU8 needs backward computation.
I0928 13:46:48.723181  4581 net.cpp:198] Scale8 needs backward computation.
I0928 13:46:48.723182  4581 net.cpp:198] BatchNorm8 needs backward computation.
I0928 13:46:48.723194  4581 net.cpp:198] Convolution8 needs backward computation.
I0928 13:46:48.723196  4581 net.cpp:198] Eltwise3_M2PELU7_0_split needs backward computation.
I0928 13:46:48.723199  4581 net.cpp:198] M2PELU7 needs backward computation.
I0928 13:46:48.723201  4581 net.cpp:198] Eltwise3 needs backward computation.
I0928 13:46:48.723204  4581 net.cpp:198] Scale7 needs backward computation.
I0928 13:46:48.723206  4581 net.cpp:198] BatchNorm7 needs backward computation.
I0928 13:46:48.723209  4581 net.cpp:198] Convolution7 needs backward computation.
I0928 13:46:48.723212  4581 net.cpp:198] M2PELU6 needs backward computation.
I0928 13:46:48.723213  4581 net.cpp:198] Scale6 needs backward computation.
I0928 13:46:48.723215  4581 net.cpp:198] BatchNorm6 needs backward computation.
I0928 13:46:48.723217  4581 net.cpp:198] Convolution6 needs backward computation.
I0928 13:46:48.723220  4581 net.cpp:198] Eltwise2_M2PELU5_0_split needs backward computation.
I0928 13:46:48.723222  4581 net.cpp:198] M2PELU5 needs backward computation.
I0928 13:46:48.723224  4581 net.cpp:198] Eltwise2 needs backward computation.
I0928 13:46:48.723227  4581 net.cpp:198] Scale5 needs backward computation.
I0928 13:46:48.723229  4581 net.cpp:198] BatchNorm5 needs backward computation.
I0928 13:46:48.723232  4581 net.cpp:198] Convolution5 needs backward computation.
I0928 13:46:48.723234  4581 net.cpp:198] M2PELU4 needs backward computation.
I0928 13:46:48.723237  4581 net.cpp:198] Scale4 needs backward computation.
I0928 13:46:48.723238  4581 net.cpp:198] BatchNorm4 needs backward computation.
I0928 13:46:48.723242  4581 net.cpp:198] Convolution4 needs backward computation.
I0928 13:46:48.723243  4581 net.cpp:198] Eltwise1_M2PELU3_0_split needs backward computation.
I0928 13:46:48.723245  4581 net.cpp:198] M2PELU3 needs backward computation.
I0928 13:46:48.723248  4581 net.cpp:198] Eltwise1 needs backward computation.
I0928 13:46:48.723250  4581 net.cpp:198] Scale3 needs backward computation.
I0928 13:46:48.723253  4581 net.cpp:198] BatchNorm3 needs backward computation.
I0928 13:46:48.723255  4581 net.cpp:198] Convolution3 needs backward computation.
I0928 13:46:48.723258  4581 net.cpp:198] M2PELU2 needs backward computation.
I0928 13:46:48.723266  4581 net.cpp:198] Scale2 needs backward computation.
I0928 13:46:48.723269  4581 net.cpp:198] BatchNorm2 needs backward computation.
I0928 13:46:48.723271  4581 net.cpp:198] Convolution2 needs backward computation.
I0928 13:46:48.723273  4581 net.cpp:198] Convolution1_M2PELU1_0_split needs backward computation.
I0928 13:46:48.723276  4581 net.cpp:198] M2PELU1 needs backward computation.
I0928 13:46:48.723278  4581 net.cpp:198] Scale1 needs backward computation.
I0928 13:46:48.723280  4581 net.cpp:198] BatchNorm1 needs backward computation.
I0928 13:46:48.723284  4581 net.cpp:198] Convolution1 needs backward computation.
I0928 13:46:48.723285  4581 net.cpp:200] Data1 does not need backward computation.
I0928 13:46:48.723287  4581 net.cpp:242] This network produces output SoftmaxWithLoss1
I0928 13:46:48.723377  4581 net.cpp:255] Network initialization done.
I0928 13:46:48.727659  4581 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56_mpelu_train_test.prototxt
I0928 13:46:48.727671  4581 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0928 13:46:48.727676  4581 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56_mpelu_train_test.prototxt
I0928 13:46:48.727859  4581 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I0928 13:46:48.728977  4581 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU1"
  type: "M2PELU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU2"
  type: "M2PELU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU3"
  type: "M2PELU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU4"
  type: "M2PELU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU5"
  type: "M2PELU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU6"
  type: "M2PELU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU7"
  type: "M2PELU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU8"
  type: "M2PELU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU9"
  type: "M2PELU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU10"
  type: "M2PELU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU11"
  type: "M2PELU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU12"
  type: "M2PELU"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU13"
  type: "M2PELU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU14"
  type: "M2PELU"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU15"
  type: "M2PELU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU16"
  type: "M2PELU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU17"
  type: "M2PELU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU18"
  type: "M2PELU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU19"
  type: "M2PELU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU20"
  type: "M2PELU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU21"
  type: "M2PELU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU22"
  type: "M2PELU"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution24"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU23"
  type: "M2PELU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU24"
  type: "M2PELU"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
I0928 13:46:48.784598  4581 layer_factory.hpp:77] Creating layer Data1
I0928 13:46:48.784651  4581 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I0928 13:46:48.784662  4581 net.cpp:84] Creating Layer Data1
I0928 13:46:48.784667  4581 net.cpp:380] Data1 -> Data1
I0928 13:46:48.784675  4581 net.cpp:380] Data1 -> Data2
I0928 13:46:48.784682  4581 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0928 13:46:48.784854  4581 data_layer.cpp:45] output data size: 100,3,32,32
I0928 13:46:48.788908  4581 net.cpp:122] Setting up Data1
I0928 13:46:48.788929  4581 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0928 13:46:48.788933  4581 net.cpp:129] Top shape: 100 (100)
I0928 13:46:48.788935  4581 net.cpp:137] Memory required for data: 1229200
I0928 13:46:48.788940  4581 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0928 13:46:48.788950  4581 net.cpp:84] Creating Layer Data2_Data1_1_split
I0928 13:46:48.788954  4581 net.cpp:406] Data2_Data1_1_split <- Data2
I0928 13:46:48.788959  4581 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0928 13:46:48.788966  4581 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0928 13:46:48.789023  4581 net.cpp:122] Setting up Data2_Data1_1_split
I0928 13:46:48.789028  4581 net.cpp:129] Top shape: 100 (100)
I0928 13:46:48.789031  4581 net.cpp:129] Top shape: 100 (100)
I0928 13:46:48.789033  4581 net.cpp:137] Memory required for data: 1230000
I0928 13:46:48.789036  4581 layer_factory.hpp:77] Creating layer Convolution1
I0928 13:46:48.789047  4581 net.cpp:84] Creating Layer Convolution1
I0928 13:46:48.789048  4581 net.cpp:406] Convolution1 <- Data1
I0928 13:46:48.789053  4581 net.cpp:380] Convolution1 -> Convolution1
I0928 13:46:48.790283  4581 net.cpp:122] Setting up Convolution1
I0928 13:46:48.790294  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.790297  4581 net.cpp:137] Memory required for data: 7783600
I0928 13:46:48.790305  4581 layer_factory.hpp:77] Creating layer BatchNorm1
I0928 13:46:48.790311  4581 net.cpp:84] Creating Layer BatchNorm1
I0928 13:46:48.790315  4581 net.cpp:406] BatchNorm1 <- Convolution1
I0928 13:46:48.790323  4581 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0928 13:46:48.790484  4581 net.cpp:122] Setting up BatchNorm1
I0928 13:46:48.790489  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.790491  4581 net.cpp:137] Memory required for data: 14337200
I0928 13:46:48.790498  4581 layer_factory.hpp:77] Creating layer Scale1
I0928 13:46:48.790504  4581 net.cpp:84] Creating Layer Scale1
I0928 13:46:48.790506  4581 net.cpp:406] Scale1 <- Convolution1
I0928 13:46:48.790510  4581 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0928 13:46:48.790568  4581 layer_factory.hpp:77] Creating layer Scale1
I0928 13:46:48.790665  4581 net.cpp:122] Setting up Scale1
I0928 13:46:48.790673  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.790674  4581 net.cpp:137] Memory required for data: 20890800
I0928 13:46:48.790678  4581 layer_factory.hpp:77] Creating layer M2PELU1
I0928 13:46:48.790684  4581 net.cpp:84] Creating Layer M2PELU1
I0928 13:46:48.790686  4581 net.cpp:406] M2PELU1 <- Convolution1
I0928 13:46:48.790691  4581 net.cpp:367] M2PELU1 -> Convolution1 (in-place)
I0928 13:46:48.791329  4581 net.cpp:122] Setting up M2PELU1
I0928 13:46:48.791337  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.791340  4581 net.cpp:137] Memory required for data: 27444400
I0928 13:46:48.791347  4581 layer_factory.hpp:77] Creating layer Convolution1_M2PELU1_0_split
I0928 13:46:48.791353  4581 net.cpp:84] Creating Layer Convolution1_M2PELU1_0_split
I0928 13:46:48.791355  4581 net.cpp:406] Convolution1_M2PELU1_0_split <- Convolution1
I0928 13:46:48.791359  4581 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_0
I0928 13:46:48.791364  4581 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_1
I0928 13:46:48.791395  4581 net.cpp:122] Setting up Convolution1_M2PELU1_0_split
I0928 13:46:48.812069  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.812079  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.812083  4581 net.cpp:137] Memory required for data: 40551600
I0928 13:46:48.812088  4581 layer_factory.hpp:77] Creating layer Convolution2
I0928 13:46:48.812103  4581 net.cpp:84] Creating Layer Convolution2
I0928 13:46:48.812108  4581 net.cpp:406] Convolution2 <- Convolution1_M2PELU1_0_split_0
I0928 13:46:48.812114  4581 net.cpp:380] Convolution2 -> Convolution2
I0928 13:46:48.813282  4581 net.cpp:122] Setting up Convolution2
I0928 13:46:48.813292  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.813293  4581 net.cpp:137] Memory required for data: 47105200
I0928 13:46:48.813299  4581 layer_factory.hpp:77] Creating layer BatchNorm2
I0928 13:46:48.813307  4581 net.cpp:84] Creating Layer BatchNorm2
I0928 13:46:48.813309  4581 net.cpp:406] BatchNorm2 <- Convolution2
I0928 13:46:48.813313  4581 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0928 13:46:48.813482  4581 net.cpp:122] Setting up BatchNorm2
I0928 13:46:48.813488  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.813490  4581 net.cpp:137] Memory required for data: 53658800
I0928 13:46:48.813504  4581 layer_factory.hpp:77] Creating layer Scale2
I0928 13:46:48.813510  4581 net.cpp:84] Creating Layer Scale2
I0928 13:46:48.813513  4581 net.cpp:406] Scale2 <- Convolution2
I0928 13:46:48.813518  4581 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0928 13:46:48.813555  4581 layer_factory.hpp:77] Creating layer Scale2
I0928 13:46:48.813695  4581 net.cpp:122] Setting up Scale2
I0928 13:46:48.813706  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.813710  4581 net.cpp:137] Memory required for data: 60212400
I0928 13:46:48.813719  4581 layer_factory.hpp:77] Creating layer M2PELU2
I0928 13:46:48.813729  4581 net.cpp:84] Creating Layer M2PELU2
I0928 13:46:48.813733  4581 net.cpp:406] M2PELU2 <- Convolution2
I0928 13:46:48.813738  4581 net.cpp:367] M2PELU2 -> Convolution2 (in-place)
I0928 13:46:48.813899  4581 net.cpp:122] Setting up M2PELU2
I0928 13:46:48.813907  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.813910  4581 net.cpp:137] Memory required for data: 66766000
I0928 13:46:48.813916  4581 layer_factory.hpp:77] Creating layer Convolution3
I0928 13:46:48.813925  4581 net.cpp:84] Creating Layer Convolution3
I0928 13:46:48.813927  4581 net.cpp:406] Convolution3 <- Convolution2
I0928 13:46:48.813931  4581 net.cpp:380] Convolution3 -> Convolution3
I0928 13:46:48.815289  4581 net.cpp:122] Setting up Convolution3
I0928 13:46:48.815297  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.815300  4581 net.cpp:137] Memory required for data: 73319600
I0928 13:46:48.815304  4581 layer_factory.hpp:77] Creating layer BatchNorm3
I0928 13:46:48.815310  4581 net.cpp:84] Creating Layer BatchNorm3
I0928 13:46:48.815312  4581 net.cpp:406] BatchNorm3 <- Convolution3
I0928 13:46:48.815317  4581 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0928 13:46:48.815470  4581 net.cpp:122] Setting up BatchNorm3
I0928 13:46:48.815474  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.815476  4581 net.cpp:137] Memory required for data: 79873200
I0928 13:46:48.815481  4581 layer_factory.hpp:77] Creating layer Scale3
I0928 13:46:48.815486  4581 net.cpp:84] Creating Layer Scale3
I0928 13:46:48.815488  4581 net.cpp:406] Scale3 <- Convolution3
I0928 13:46:48.815492  4581 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0928 13:46:48.815521  4581 layer_factory.hpp:77] Creating layer Scale3
I0928 13:46:48.815606  4581 net.cpp:122] Setting up Scale3
I0928 13:46:48.815611  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.815613  4581 net.cpp:137] Memory required for data: 86426800
I0928 13:46:48.815616  4581 layer_factory.hpp:77] Creating layer Eltwise1
I0928 13:46:48.815621  4581 net.cpp:84] Creating Layer Eltwise1
I0928 13:46:48.815623  4581 net.cpp:406] Eltwise1 <- Convolution1_M2PELU1_0_split_1
I0928 13:46:48.815626  4581 net.cpp:406] Eltwise1 <- Convolution3
I0928 13:46:48.815629  4581 net.cpp:380] Eltwise1 -> Eltwise1
I0928 13:46:48.815659  4581 net.cpp:122] Setting up Eltwise1
I0928 13:46:48.815663  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.815665  4581 net.cpp:137] Memory required for data: 92980400
I0928 13:46:48.815668  4581 layer_factory.hpp:77] Creating layer M2PELU3
I0928 13:46:48.815673  4581 net.cpp:84] Creating Layer M2PELU3
I0928 13:46:48.815675  4581 net.cpp:406] M2PELU3 <- Eltwise1
I0928 13:46:48.815690  4581 net.cpp:367] M2PELU3 -> Eltwise1 (in-place)
I0928 13:46:48.815814  4581 net.cpp:122] Setting up M2PELU3
I0928 13:46:48.815819  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.815821  4581 net.cpp:137] Memory required for data: 99534000
I0928 13:46:48.815825  4581 layer_factory.hpp:77] Creating layer Eltwise1_M2PELU3_0_split
I0928 13:46:48.815830  4581 net.cpp:84] Creating Layer Eltwise1_M2PELU3_0_split
I0928 13:46:48.815834  4581 net.cpp:406] Eltwise1_M2PELU3_0_split <- Eltwise1
I0928 13:46:48.815846  4581 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_0
I0928 13:46:48.815850  4581 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_1
I0928 13:46:48.815886  4581 net.cpp:122] Setting up Eltwise1_M2PELU3_0_split
I0928 13:46:48.815889  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.815892  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.815894  4581 net.cpp:137] Memory required for data: 112641200
I0928 13:46:48.815896  4581 layer_factory.hpp:77] Creating layer Convolution4
I0928 13:46:48.815903  4581 net.cpp:84] Creating Layer Convolution4
I0928 13:46:48.815907  4581 net.cpp:406] Convolution4 <- Eltwise1_M2PELU3_0_split_0
I0928 13:46:48.815910  4581 net.cpp:380] Convolution4 -> Convolution4
I0928 13:46:48.816998  4581 net.cpp:122] Setting up Convolution4
I0928 13:46:48.817006  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.817009  4581 net.cpp:137] Memory required for data: 119194800
I0928 13:46:48.817013  4581 layer_factory.hpp:77] Creating layer BatchNorm4
I0928 13:46:48.817019  4581 net.cpp:84] Creating Layer BatchNorm4
I0928 13:46:48.817021  4581 net.cpp:406] BatchNorm4 <- Convolution4
I0928 13:46:48.817026  4581 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0928 13:46:48.817184  4581 net.cpp:122] Setting up BatchNorm4
I0928 13:46:48.817188  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.817190  4581 net.cpp:137] Memory required for data: 125748400
I0928 13:46:48.817195  4581 layer_factory.hpp:77] Creating layer Scale4
I0928 13:46:48.817200  4581 net.cpp:84] Creating Layer Scale4
I0928 13:46:48.817203  4581 net.cpp:406] Scale4 <- Convolution4
I0928 13:46:48.817205  4581 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0928 13:46:48.817236  4581 layer_factory.hpp:77] Creating layer Scale4
I0928 13:46:48.817323  4581 net.cpp:122] Setting up Scale4
I0928 13:46:48.817327  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.817329  4581 net.cpp:137] Memory required for data: 132302000
I0928 13:46:48.817337  4581 layer_factory.hpp:77] Creating layer M2PELU4
I0928 13:46:48.817342  4581 net.cpp:84] Creating Layer M2PELU4
I0928 13:46:48.817344  4581 net.cpp:406] M2PELU4 <- Convolution4
I0928 13:46:48.817348  4581 net.cpp:367] M2PELU4 -> Convolution4 (in-place)
I0928 13:46:48.817448  4581 net.cpp:122] Setting up M2PELU4
I0928 13:46:48.817452  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.817456  4581 net.cpp:137] Memory required for data: 138855600
I0928 13:46:48.817458  4581 layer_factory.hpp:77] Creating layer Convolution5
I0928 13:46:48.817466  4581 net.cpp:84] Creating Layer Convolution5
I0928 13:46:48.817467  4581 net.cpp:406] Convolution5 <- Convolution4
I0928 13:46:48.817471  4581 net.cpp:380] Convolution5 -> Convolution5
I0928 13:46:48.818433  4581 net.cpp:122] Setting up Convolution5
I0928 13:46:48.818441  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.818444  4581 net.cpp:137] Memory required for data: 145409200
I0928 13:46:48.818449  4581 layer_factory.hpp:77] Creating layer BatchNorm5
I0928 13:46:48.818454  4581 net.cpp:84] Creating Layer BatchNorm5
I0928 13:46:48.818456  4581 net.cpp:406] BatchNorm5 <- Convolution5
I0928 13:46:48.818460  4581 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0928 13:46:48.818655  4581 net.cpp:122] Setting up BatchNorm5
I0928 13:46:48.818660  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.818661  4581 net.cpp:137] Memory required for data: 151962800
I0928 13:46:48.818666  4581 layer_factory.hpp:77] Creating layer Scale5
I0928 13:46:48.818670  4581 net.cpp:84] Creating Layer Scale5
I0928 13:46:48.818673  4581 net.cpp:406] Scale5 <- Convolution5
I0928 13:46:48.818676  4581 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0928 13:46:48.818707  4581 layer_factory.hpp:77] Creating layer Scale5
I0928 13:46:48.818791  4581 net.cpp:122] Setting up Scale5
I0928 13:46:48.818795  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.818797  4581 net.cpp:137] Memory required for data: 158516400
I0928 13:46:48.818801  4581 layer_factory.hpp:77] Creating layer Eltwise2
I0928 13:46:48.818805  4581 net.cpp:84] Creating Layer Eltwise2
I0928 13:46:48.818815  4581 net.cpp:406] Eltwise2 <- Eltwise1_M2PELU3_0_split_1
I0928 13:46:48.818819  4581 net.cpp:406] Eltwise2 <- Convolution5
I0928 13:46:48.818821  4581 net.cpp:380] Eltwise2 -> Eltwise2
I0928 13:46:48.818840  4581 net.cpp:122] Setting up Eltwise2
I0928 13:46:48.818845  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.818846  4581 net.cpp:137] Memory required for data: 165070000
I0928 13:46:48.818848  4581 layer_factory.hpp:77] Creating layer M2PELU5
I0928 13:46:48.818853  4581 net.cpp:84] Creating Layer M2PELU5
I0928 13:46:48.818856  4581 net.cpp:406] M2PELU5 <- Eltwise2
I0928 13:46:48.818859  4581 net.cpp:367] M2PELU5 -> Eltwise2 (in-place)
I0928 13:46:48.818961  4581 net.cpp:122] Setting up M2PELU5
I0928 13:46:48.818965  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.818967  4581 net.cpp:137] Memory required for data: 171623600
I0928 13:46:48.818971  4581 layer_factory.hpp:77] Creating layer Eltwise2_M2PELU5_0_split
I0928 13:46:48.818975  4581 net.cpp:84] Creating Layer Eltwise2_M2PELU5_0_split
I0928 13:46:48.818977  4581 net.cpp:406] Eltwise2_M2PELU5_0_split <- Eltwise2
I0928 13:46:48.818981  4581 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_0
I0928 13:46:48.818985  4581 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_1
I0928 13:46:48.819012  4581 net.cpp:122] Setting up Eltwise2_M2PELU5_0_split
I0928 13:46:48.819015  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.819020  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.819021  4581 net.cpp:137] Memory required for data: 184730800
I0928 13:46:48.819023  4581 layer_factory.hpp:77] Creating layer Convolution6
I0928 13:46:48.819030  4581 net.cpp:84] Creating Layer Convolution6
I0928 13:46:48.819031  4581 net.cpp:406] Convolution6 <- Eltwise2_M2PELU5_0_split_0
I0928 13:46:48.819036  4581 net.cpp:380] Convolution6 -> Convolution6
I0928 13:46:48.819970  4581 net.cpp:122] Setting up Convolution6
I0928 13:46:48.819978  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.819981  4581 net.cpp:137] Memory required for data: 191284400
I0928 13:46:48.819985  4581 layer_factory.hpp:77] Creating layer BatchNorm6
I0928 13:46:48.819991  4581 net.cpp:84] Creating Layer BatchNorm6
I0928 13:46:48.819994  4581 net.cpp:406] BatchNorm6 <- Convolution6
I0928 13:46:48.819998  4581 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0928 13:46:48.820150  4581 net.cpp:122] Setting up BatchNorm6
I0928 13:46:48.820154  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.820156  4581 net.cpp:137] Memory required for data: 197838000
I0928 13:46:48.820161  4581 layer_factory.hpp:77] Creating layer Scale6
I0928 13:46:48.820165  4581 net.cpp:84] Creating Layer Scale6
I0928 13:46:48.820168  4581 net.cpp:406] Scale6 <- Convolution6
I0928 13:46:48.820171  4581 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0928 13:46:48.820201  4581 layer_factory.hpp:77] Creating layer Scale6
I0928 13:46:48.820287  4581 net.cpp:122] Setting up Scale6
I0928 13:46:48.820291  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.820293  4581 net.cpp:137] Memory required for data: 204391600
I0928 13:46:48.820297  4581 layer_factory.hpp:77] Creating layer M2PELU6
I0928 13:46:48.820302  4581 net.cpp:84] Creating Layer M2PELU6
I0928 13:46:48.820304  4581 net.cpp:406] M2PELU6 <- Convolution6
I0928 13:46:48.820307  4581 net.cpp:367] M2PELU6 -> Convolution6 (in-place)
I0928 13:46:48.820408  4581 net.cpp:122] Setting up M2PELU6
I0928 13:46:48.820413  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.820415  4581 net.cpp:137] Memory required for data: 210945200
I0928 13:46:48.820420  4581 layer_factory.hpp:77] Creating layer Convolution7
I0928 13:46:48.820425  4581 net.cpp:84] Creating Layer Convolution7
I0928 13:46:48.820427  4581 net.cpp:406] Convolution7 <- Convolution6
I0928 13:46:48.820432  4581 net.cpp:380] Convolution7 -> Convolution7
I0928 13:46:48.821362  4581 net.cpp:122] Setting up Convolution7
I0928 13:46:48.821370  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.821378  4581 net.cpp:137] Memory required for data: 217498800
I0928 13:46:48.821383  4581 layer_factory.hpp:77] Creating layer BatchNorm7
I0928 13:46:48.821390  4581 net.cpp:84] Creating Layer BatchNorm7
I0928 13:46:48.821393  4581 net.cpp:406] BatchNorm7 <- Convolution7
I0928 13:46:48.821398  4581 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0928 13:46:48.821550  4581 net.cpp:122] Setting up BatchNorm7
I0928 13:46:48.821554  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.821557  4581 net.cpp:137] Memory required for data: 224052400
I0928 13:46:48.821561  4581 layer_factory.hpp:77] Creating layer Scale7
I0928 13:46:48.821565  4581 net.cpp:84] Creating Layer Scale7
I0928 13:46:48.821568  4581 net.cpp:406] Scale7 <- Convolution7
I0928 13:46:48.821570  4581 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0928 13:46:48.821600  4581 layer_factory.hpp:77] Creating layer Scale7
I0928 13:46:48.821684  4581 net.cpp:122] Setting up Scale7
I0928 13:46:48.821688  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.821691  4581 net.cpp:137] Memory required for data: 230606000
I0928 13:46:48.821694  4581 layer_factory.hpp:77] Creating layer Eltwise3
I0928 13:46:48.821698  4581 net.cpp:84] Creating Layer Eltwise3
I0928 13:46:48.821702  4581 net.cpp:406] Eltwise3 <- Eltwise2_M2PELU5_0_split_1
I0928 13:46:48.821704  4581 net.cpp:406] Eltwise3 <- Convolution7
I0928 13:46:48.821707  4581 net.cpp:380] Eltwise3 -> Eltwise3
I0928 13:46:48.821724  4581 net.cpp:122] Setting up Eltwise3
I0928 13:46:48.821727  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.821729  4581 net.cpp:137] Memory required for data: 237159600
I0928 13:46:48.821732  4581 layer_factory.hpp:77] Creating layer M2PELU7
I0928 13:46:48.821738  4581 net.cpp:84] Creating Layer M2PELU7
I0928 13:46:48.821739  4581 net.cpp:406] M2PELU7 <- Eltwise3
I0928 13:46:48.821743  4581 net.cpp:367] M2PELU7 -> Eltwise3 (in-place)
I0928 13:46:48.821842  4581 net.cpp:122] Setting up M2PELU7
I0928 13:46:48.821847  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.821849  4581 net.cpp:137] Memory required for data: 243713200
I0928 13:46:48.821853  4581 layer_factory.hpp:77] Creating layer Eltwise3_M2PELU7_0_split
I0928 13:46:48.821857  4581 net.cpp:84] Creating Layer Eltwise3_M2PELU7_0_split
I0928 13:46:48.821859  4581 net.cpp:406] Eltwise3_M2PELU7_0_split <- Eltwise3
I0928 13:46:48.821862  4581 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_0
I0928 13:46:48.821866  4581 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_1
I0928 13:46:48.821894  4581 net.cpp:122] Setting up Eltwise3_M2PELU7_0_split
I0928 13:46:48.821897  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.842849  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.842857  4581 net.cpp:137] Memory required for data: 256820400
I0928 13:46:48.842862  4581 layer_factory.hpp:77] Creating layer Convolution8
I0928 13:46:48.842875  4581 net.cpp:84] Creating Layer Convolution8
I0928 13:46:48.842880  4581 net.cpp:406] Convolution8 <- Eltwise3_M2PELU7_0_split_0
I0928 13:46:48.842886  4581 net.cpp:380] Convolution8 -> Convolution8
I0928 13:46:48.843950  4581 net.cpp:122] Setting up Convolution8
I0928 13:46:48.843960  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.843962  4581 net.cpp:137] Memory required for data: 263374000
I0928 13:46:48.843974  4581 layer_factory.hpp:77] Creating layer BatchNorm8
I0928 13:46:48.843979  4581 net.cpp:84] Creating Layer BatchNorm8
I0928 13:46:48.843982  4581 net.cpp:406] BatchNorm8 <- Convolution8
I0928 13:46:48.843986  4581 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0928 13:46:48.844161  4581 net.cpp:122] Setting up BatchNorm8
I0928 13:46:48.844168  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.844172  4581 net.cpp:137] Memory required for data: 269927600
I0928 13:46:48.844182  4581 layer_factory.hpp:77] Creating layer Scale8
I0928 13:46:48.844188  4581 net.cpp:84] Creating Layer Scale8
I0928 13:46:48.844203  4581 net.cpp:406] Scale8 <- Convolution8
I0928 13:46:48.844211  4581 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0928 13:46:48.844276  4581 layer_factory.hpp:77] Creating layer Scale8
I0928 13:46:48.844439  4581 net.cpp:122] Setting up Scale8
I0928 13:46:48.844447  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.844450  4581 net.cpp:137] Memory required for data: 276481200
I0928 13:46:48.844455  4581 layer_factory.hpp:77] Creating layer M2PELU8
I0928 13:46:48.844461  4581 net.cpp:84] Creating Layer M2PELU8
I0928 13:46:48.844463  4581 net.cpp:406] M2PELU8 <- Convolution8
I0928 13:46:48.844468  4581 net.cpp:367] M2PELU8 -> Convolution8 (in-place)
I0928 13:46:48.844599  4581 net.cpp:122] Setting up M2PELU8
I0928 13:46:48.844604  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.844606  4581 net.cpp:137] Memory required for data: 283034800
I0928 13:46:48.844609  4581 layer_factory.hpp:77] Creating layer Convolution9
I0928 13:46:48.844617  4581 net.cpp:84] Creating Layer Convolution9
I0928 13:46:48.844619  4581 net.cpp:406] Convolution9 <- Convolution8
I0928 13:46:48.844624  4581 net.cpp:380] Convolution9 -> Convolution9
I0928 13:46:48.845670  4581 net.cpp:122] Setting up Convolution9
I0928 13:46:48.845679  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.845682  4581 net.cpp:137] Memory required for data: 289588400
I0928 13:46:48.845686  4581 layer_factory.hpp:77] Creating layer BatchNorm9
I0928 13:46:48.845692  4581 net.cpp:84] Creating Layer BatchNorm9
I0928 13:46:48.845695  4581 net.cpp:406] BatchNorm9 <- Convolution9
I0928 13:46:48.845698  4581 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0928 13:46:48.845857  4581 net.cpp:122] Setting up BatchNorm9
I0928 13:46:48.845862  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.845865  4581 net.cpp:137] Memory required for data: 296142000
I0928 13:46:48.845870  4581 layer_factory.hpp:77] Creating layer Scale9
I0928 13:46:48.845873  4581 net.cpp:84] Creating Layer Scale9
I0928 13:46:48.845875  4581 net.cpp:406] Scale9 <- Convolution9
I0928 13:46:48.845880  4581 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0928 13:46:48.845911  4581 layer_factory.hpp:77] Creating layer Scale9
I0928 13:46:48.845998  4581 net.cpp:122] Setting up Scale9
I0928 13:46:48.846002  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.846004  4581 net.cpp:137] Memory required for data: 302695600
I0928 13:46:48.846009  4581 layer_factory.hpp:77] Creating layer Eltwise4
I0928 13:46:48.846014  4581 net.cpp:84] Creating Layer Eltwise4
I0928 13:46:48.846016  4581 net.cpp:406] Eltwise4 <- Eltwise3_M2PELU7_0_split_1
I0928 13:46:48.846019  4581 net.cpp:406] Eltwise4 <- Convolution9
I0928 13:46:48.846022  4581 net.cpp:380] Eltwise4 -> Eltwise4
I0928 13:46:48.846041  4581 net.cpp:122] Setting up Eltwise4
I0928 13:46:48.846045  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.846046  4581 net.cpp:137] Memory required for data: 309249200
I0928 13:46:48.846050  4581 layer_factory.hpp:77] Creating layer M2PELU9
I0928 13:46:48.846055  4581 net.cpp:84] Creating Layer M2PELU9
I0928 13:46:48.846057  4581 net.cpp:406] M2PELU9 <- Eltwise4
I0928 13:46:48.846060  4581 net.cpp:367] M2PELU9 -> Eltwise4 (in-place)
I0928 13:46:48.846174  4581 net.cpp:122] Setting up M2PELU9
I0928 13:46:48.846177  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.846180  4581 net.cpp:137] Memory required for data: 315802800
I0928 13:46:48.846184  4581 layer_factory.hpp:77] Creating layer Eltwise4_M2PELU9_0_split
I0928 13:46:48.846187  4581 net.cpp:84] Creating Layer Eltwise4_M2PELU9_0_split
I0928 13:46:48.846189  4581 net.cpp:406] Eltwise4_M2PELU9_0_split <- Eltwise4
I0928 13:46:48.846194  4581 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_0
I0928 13:46:48.846199  4581 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_1
I0928 13:46:48.846225  4581 net.cpp:122] Setting up Eltwise4_M2PELU9_0_split
I0928 13:46:48.846230  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.846238  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.846240  4581 net.cpp:137] Memory required for data: 328910000
I0928 13:46:48.846242  4581 layer_factory.hpp:77] Creating layer Convolution10
I0928 13:46:48.846249  4581 net.cpp:84] Creating Layer Convolution10
I0928 13:46:48.846251  4581 net.cpp:406] Convolution10 <- Eltwise4_M2PELU9_0_split_0
I0928 13:46:48.846266  4581 net.cpp:380] Convolution10 -> Convolution10
I0928 13:46:48.847436  4581 net.cpp:122] Setting up Convolution10
I0928 13:46:48.847446  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.847450  4581 net.cpp:137] Memory required for data: 335463600
I0928 13:46:48.847453  4581 layer_factory.hpp:77] Creating layer BatchNorm10
I0928 13:46:48.847460  4581 net.cpp:84] Creating Layer BatchNorm10
I0928 13:46:48.847461  4581 net.cpp:406] BatchNorm10 <- Convolution10
I0928 13:46:48.847465  4581 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0928 13:46:48.847621  4581 net.cpp:122] Setting up BatchNorm10
I0928 13:46:48.847626  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.847628  4581 net.cpp:137] Memory required for data: 342017200
I0928 13:46:48.847633  4581 layer_factory.hpp:77] Creating layer Scale10
I0928 13:46:48.847638  4581 net.cpp:84] Creating Layer Scale10
I0928 13:46:48.847641  4581 net.cpp:406] Scale10 <- Convolution10
I0928 13:46:48.847645  4581 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0928 13:46:48.847676  4581 layer_factory.hpp:77] Creating layer Scale10
I0928 13:46:48.847761  4581 net.cpp:122] Setting up Scale10
I0928 13:46:48.847766  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.847769  4581 net.cpp:137] Memory required for data: 348570800
I0928 13:46:48.847772  4581 layer_factory.hpp:77] Creating layer M2PELU10
I0928 13:46:48.847777  4581 net.cpp:84] Creating Layer M2PELU10
I0928 13:46:48.847779  4581 net.cpp:406] M2PELU10 <- Convolution10
I0928 13:46:48.847784  4581 net.cpp:367] M2PELU10 -> Convolution10 (in-place)
I0928 13:46:48.847883  4581 net.cpp:122] Setting up M2PELU10
I0928 13:46:48.847887  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.847889  4581 net.cpp:137] Memory required for data: 355124400
I0928 13:46:48.847893  4581 layer_factory.hpp:77] Creating layer Convolution11
I0928 13:46:48.847899  4581 net.cpp:84] Creating Layer Convolution11
I0928 13:46:48.847903  4581 net.cpp:406] Convolution11 <- Convolution10
I0928 13:46:48.847906  4581 net.cpp:380] Convolution11 -> Convolution11
I0928 13:46:48.849184  4581 net.cpp:122] Setting up Convolution11
I0928 13:46:48.849194  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.849196  4581 net.cpp:137] Memory required for data: 361678000
I0928 13:46:48.849200  4581 layer_factory.hpp:77] Creating layer BatchNorm11
I0928 13:46:48.849206  4581 net.cpp:84] Creating Layer BatchNorm11
I0928 13:46:48.849210  4581 net.cpp:406] BatchNorm11 <- Convolution11
I0928 13:46:48.849212  4581 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0928 13:46:48.849375  4581 net.cpp:122] Setting up BatchNorm11
I0928 13:46:48.849380  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.849382  4581 net.cpp:137] Memory required for data: 368231600
I0928 13:46:48.849387  4581 layer_factory.hpp:77] Creating layer Scale11
I0928 13:46:48.849391  4581 net.cpp:84] Creating Layer Scale11
I0928 13:46:48.849395  4581 net.cpp:406] Scale11 <- Convolution11
I0928 13:46:48.849398  4581 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0928 13:46:48.849428  4581 layer_factory.hpp:77] Creating layer Scale11
I0928 13:46:48.849515  4581 net.cpp:122] Setting up Scale11
I0928 13:46:48.849520  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.849522  4581 net.cpp:137] Memory required for data: 374785200
I0928 13:46:48.849526  4581 layer_factory.hpp:77] Creating layer Eltwise5
I0928 13:46:48.849530  4581 net.cpp:84] Creating Layer Eltwise5
I0928 13:46:48.849534  4581 net.cpp:406] Eltwise5 <- Eltwise4_M2PELU9_0_split_1
I0928 13:46:48.849536  4581 net.cpp:406] Eltwise5 <- Convolution11
I0928 13:46:48.849546  4581 net.cpp:380] Eltwise5 -> Eltwise5
I0928 13:46:48.849566  4581 net.cpp:122] Setting up Eltwise5
I0928 13:46:48.849570  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.849572  4581 net.cpp:137] Memory required for data: 381338800
I0928 13:46:48.849575  4581 layer_factory.hpp:77] Creating layer M2PELU11
I0928 13:46:48.849581  4581 net.cpp:84] Creating Layer M2PELU11
I0928 13:46:48.849583  4581 net.cpp:406] M2PELU11 <- Eltwise5
I0928 13:46:48.849586  4581 net.cpp:367] M2PELU11 -> Eltwise5 (in-place)
I0928 13:46:48.849689  4581 net.cpp:122] Setting up M2PELU11
I0928 13:46:48.849694  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.849696  4581 net.cpp:137] Memory required for data: 387892400
I0928 13:46:48.849700  4581 layer_factory.hpp:77] Creating layer Eltwise5_M2PELU11_0_split
I0928 13:46:48.849704  4581 net.cpp:84] Creating Layer Eltwise5_M2PELU11_0_split
I0928 13:46:48.849706  4581 net.cpp:406] Eltwise5_M2PELU11_0_split <- Eltwise5
I0928 13:46:48.849709  4581 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_0
I0928 13:46:48.849714  4581 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_1
I0928 13:46:48.849740  4581 net.cpp:122] Setting up Eltwise5_M2PELU11_0_split
I0928 13:46:48.849745  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.849747  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.849750  4581 net.cpp:137] Memory required for data: 400999600
I0928 13:46:48.849751  4581 layer_factory.hpp:77] Creating layer Convolution12
I0928 13:46:48.849759  4581 net.cpp:84] Creating Layer Convolution12
I0928 13:46:48.849762  4581 net.cpp:406] Convolution12 <- Eltwise5_M2PELU11_0_split_0
I0928 13:46:48.849766  4581 net.cpp:380] Convolution12 -> Convolution12
I0928 13:46:48.850754  4581 net.cpp:122] Setting up Convolution12
I0928 13:46:48.850762  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.850764  4581 net.cpp:137] Memory required for data: 407553200
I0928 13:46:48.850769  4581 layer_factory.hpp:77] Creating layer BatchNorm12
I0928 13:46:48.850775  4581 net.cpp:84] Creating Layer BatchNorm12
I0928 13:46:48.850777  4581 net.cpp:406] BatchNorm12 <- Convolution12
I0928 13:46:48.850781  4581 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0928 13:46:48.850939  4581 net.cpp:122] Setting up BatchNorm12
I0928 13:46:48.850944  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.850945  4581 net.cpp:137] Memory required for data: 414106800
I0928 13:46:48.850950  4581 layer_factory.hpp:77] Creating layer Scale12
I0928 13:46:48.850963  4581 net.cpp:84] Creating Layer Scale12
I0928 13:46:48.850965  4581 net.cpp:406] Scale12 <- Convolution12
I0928 13:46:48.850970  4581 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0928 13:46:48.850999  4581 layer_factory.hpp:77] Creating layer Scale12
I0928 13:46:48.851083  4581 net.cpp:122] Setting up Scale12
I0928 13:46:48.851089  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.851090  4581 net.cpp:137] Memory required for data: 420660400
I0928 13:46:48.851094  4581 layer_factory.hpp:77] Creating layer M2PELU12
I0928 13:46:48.851099  4581 net.cpp:84] Creating Layer M2PELU12
I0928 13:46:48.851101  4581 net.cpp:406] M2PELU12 <- Convolution12
I0928 13:46:48.851104  4581 net.cpp:367] M2PELU12 -> Convolution12 (in-place)
I0928 13:46:48.851204  4581 net.cpp:122] Setting up M2PELU12
I0928 13:46:48.851208  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.851210  4581 net.cpp:137] Memory required for data: 427214000
I0928 13:46:48.851214  4581 layer_factory.hpp:77] Creating layer Convolution13
I0928 13:46:48.851222  4581 net.cpp:84] Creating Layer Convolution13
I0928 13:46:48.851223  4581 net.cpp:406] Convolution13 <- Convolution12
I0928 13:46:48.851227  4581 net.cpp:380] Convolution13 -> Convolution13
I0928 13:46:48.852174  4581 net.cpp:122] Setting up Convolution13
I0928 13:46:48.852183  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.852192  4581 net.cpp:137] Memory required for data: 433767600
I0928 13:46:48.852196  4581 layer_factory.hpp:77] Creating layer BatchNorm13
I0928 13:46:48.852202  4581 net.cpp:84] Creating Layer BatchNorm13
I0928 13:46:48.852205  4581 net.cpp:406] BatchNorm13 <- Convolution13
I0928 13:46:48.852210  4581 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0928 13:46:48.852363  4581 net.cpp:122] Setting up BatchNorm13
I0928 13:46:48.852367  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.852370  4581 net.cpp:137] Memory required for data: 440321200
I0928 13:46:48.852375  4581 layer_factory.hpp:77] Creating layer Scale13
I0928 13:46:48.852378  4581 net.cpp:84] Creating Layer Scale13
I0928 13:46:48.852380  4581 net.cpp:406] Scale13 <- Convolution13
I0928 13:46:48.852385  4581 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0928 13:46:48.852413  4581 layer_factory.hpp:77] Creating layer Scale13
I0928 13:46:48.852500  4581 net.cpp:122] Setting up Scale13
I0928 13:46:48.852504  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.852506  4581 net.cpp:137] Memory required for data: 446874800
I0928 13:46:48.852510  4581 layer_factory.hpp:77] Creating layer Eltwise6
I0928 13:46:48.852519  4581 net.cpp:84] Creating Layer Eltwise6
I0928 13:46:48.852522  4581 net.cpp:406] Eltwise6 <- Eltwise5_M2PELU11_0_split_1
I0928 13:46:48.852525  4581 net.cpp:406] Eltwise6 <- Convolution13
I0928 13:46:48.852529  4581 net.cpp:380] Eltwise6 -> Eltwise6
I0928 13:46:48.852547  4581 net.cpp:122] Setting up Eltwise6
I0928 13:46:48.852551  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.852553  4581 net.cpp:137] Memory required for data: 453428400
I0928 13:46:48.852555  4581 layer_factory.hpp:77] Creating layer M2PELU13
I0928 13:46:48.852560  4581 net.cpp:84] Creating Layer M2PELU13
I0928 13:46:48.852563  4581 net.cpp:406] M2PELU13 <- Eltwise6
I0928 13:46:48.852566  4581 net.cpp:367] M2PELU13 -> Eltwise6 (in-place)
I0928 13:46:48.852666  4581 net.cpp:122] Setting up M2PELU13
I0928 13:46:48.852671  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.852674  4581 net.cpp:137] Memory required for data: 459982000
I0928 13:46:48.852676  4581 layer_factory.hpp:77] Creating layer Eltwise6_M2PELU13_0_split
I0928 13:46:48.852681  4581 net.cpp:84] Creating Layer Eltwise6_M2PELU13_0_split
I0928 13:46:48.852684  4581 net.cpp:406] Eltwise6_M2PELU13_0_split <- Eltwise6
I0928 13:46:48.852686  4581 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_0
I0928 13:46:48.852691  4581 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_1
I0928 13:46:48.852717  4581 net.cpp:122] Setting up Eltwise6_M2PELU13_0_split
I0928 13:46:48.873401  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.873411  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.873415  4581 net.cpp:137] Memory required for data: 473089200
I0928 13:46:48.873420  4581 layer_factory.hpp:77] Creating layer Convolution14
I0928 13:46:48.873430  4581 net.cpp:84] Creating Layer Convolution14
I0928 13:46:48.873435  4581 net.cpp:406] Convolution14 <- Eltwise6_M2PELU13_0_split_0
I0928 13:46:48.873445  4581 net.cpp:380] Convolution14 -> Convolution14
I0928 13:46:48.874596  4581 net.cpp:122] Setting up Convolution14
I0928 13:46:48.874606  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.874609  4581 net.cpp:137] Memory required for data: 479642800
I0928 13:46:48.874614  4581 layer_factory.hpp:77] Creating layer BatchNorm14
I0928 13:46:48.874619  4581 net.cpp:84] Creating Layer BatchNorm14
I0928 13:46:48.874622  4581 net.cpp:406] BatchNorm14 <- Convolution14
I0928 13:46:48.874626  4581 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0928 13:46:48.874800  4581 net.cpp:122] Setting up BatchNorm14
I0928 13:46:48.874805  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.874809  4581 net.cpp:137] Memory required for data: 486196400
I0928 13:46:48.874824  4581 layer_factory.hpp:77] Creating layer Scale14
I0928 13:46:48.874830  4581 net.cpp:84] Creating Layer Scale14
I0928 13:46:48.874842  4581 net.cpp:406] Scale14 <- Convolution14
I0928 13:46:48.874850  4581 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0928 13:46:48.874903  4581 layer_factory.hpp:77] Creating layer Scale14
I0928 13:46:48.875068  4581 net.cpp:122] Setting up Scale14
I0928 13:46:48.875080  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.875084  4581 net.cpp:137] Memory required for data: 492750000
I0928 13:46:48.875090  4581 layer_factory.hpp:77] Creating layer M2PELU14
I0928 13:46:48.875097  4581 net.cpp:84] Creating Layer M2PELU14
I0928 13:46:48.875100  4581 net.cpp:406] M2PELU14 <- Convolution14
I0928 13:46:48.875104  4581 net.cpp:367] M2PELU14 -> Convolution14 (in-place)
I0928 13:46:48.875239  4581 net.cpp:122] Setting up M2PELU14
I0928 13:46:48.875246  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.875247  4581 net.cpp:137] Memory required for data: 499303600
I0928 13:46:48.875252  4581 layer_factory.hpp:77] Creating layer Convolution15
I0928 13:46:48.875258  4581 net.cpp:84] Creating Layer Convolution15
I0928 13:46:48.875262  4581 net.cpp:406] Convolution15 <- Convolution14
I0928 13:46:48.875265  4581 net.cpp:380] Convolution15 -> Convolution15
I0928 13:46:48.876652  4581 net.cpp:122] Setting up Convolution15
I0928 13:46:48.876660  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.876663  4581 net.cpp:137] Memory required for data: 505857200
I0928 13:46:48.876668  4581 layer_factory.hpp:77] Creating layer BatchNorm15
I0928 13:46:48.876673  4581 net.cpp:84] Creating Layer BatchNorm15
I0928 13:46:48.876677  4581 net.cpp:406] BatchNorm15 <- Convolution15
I0928 13:46:48.876680  4581 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0928 13:46:48.876840  4581 net.cpp:122] Setting up BatchNorm15
I0928 13:46:48.876845  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.876847  4581 net.cpp:137] Memory required for data: 512410800
I0928 13:46:48.876863  4581 layer_factory.hpp:77] Creating layer Scale15
I0928 13:46:48.876868  4581 net.cpp:84] Creating Layer Scale15
I0928 13:46:48.876870  4581 net.cpp:406] Scale15 <- Convolution15
I0928 13:46:48.876873  4581 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0928 13:46:48.876907  4581 layer_factory.hpp:77] Creating layer Scale15
I0928 13:46:48.876996  4581 net.cpp:122] Setting up Scale15
I0928 13:46:48.877001  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.877003  4581 net.cpp:137] Memory required for data: 518964400
I0928 13:46:48.877007  4581 layer_factory.hpp:77] Creating layer Eltwise7
I0928 13:46:48.877010  4581 net.cpp:84] Creating Layer Eltwise7
I0928 13:46:48.877013  4581 net.cpp:406] Eltwise7 <- Eltwise6_M2PELU13_0_split_1
I0928 13:46:48.877017  4581 net.cpp:406] Eltwise7 <- Convolution15
I0928 13:46:48.877020  4581 net.cpp:380] Eltwise7 -> Eltwise7
I0928 13:46:48.877038  4581 net.cpp:122] Setting up Eltwise7
I0928 13:46:48.877043  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.877044  4581 net.cpp:137] Memory required for data: 525518000
I0928 13:46:48.877046  4581 layer_factory.hpp:77] Creating layer M2PELU15
I0928 13:46:48.877051  4581 net.cpp:84] Creating Layer M2PELU15
I0928 13:46:48.877054  4581 net.cpp:406] M2PELU15 <- Eltwise7
I0928 13:46:48.877058  4581 net.cpp:367] M2PELU15 -> Eltwise7 (in-place)
I0928 13:46:48.877163  4581 net.cpp:122] Setting up M2PELU15
I0928 13:46:48.877167  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.877169  4581 net.cpp:137] Memory required for data: 532071600
I0928 13:46:48.877173  4581 layer_factory.hpp:77] Creating layer Eltwise7_M2PELU15_0_split
I0928 13:46:48.877177  4581 net.cpp:84] Creating Layer Eltwise7_M2PELU15_0_split
I0928 13:46:48.877179  4581 net.cpp:406] Eltwise7_M2PELU15_0_split <- Eltwise7
I0928 13:46:48.877183  4581 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_0
I0928 13:46:48.877187  4581 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_1
I0928 13:46:48.877214  4581 net.cpp:122] Setting up Eltwise7_M2PELU15_0_split
I0928 13:46:48.877224  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.877228  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.877229  4581 net.cpp:137] Memory required for data: 545178800
I0928 13:46:48.877231  4581 layer_factory.hpp:77] Creating layer Convolution16
I0928 13:46:48.877238  4581 net.cpp:84] Creating Layer Convolution16
I0928 13:46:48.877241  4581 net.cpp:406] Convolution16 <- Eltwise7_M2PELU15_0_split_0
I0928 13:46:48.877245  4581 net.cpp:380] Convolution16 -> Convolution16
I0928 13:46:48.877887  4581 net.cpp:122] Setting up Convolution16
I0928 13:46:48.877893  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.877897  4581 net.cpp:137] Memory required for data: 551732400
I0928 13:46:48.877900  4581 layer_factory.hpp:77] Creating layer BatchNorm16
I0928 13:46:48.877905  4581 net.cpp:84] Creating Layer BatchNorm16
I0928 13:46:48.877908  4581 net.cpp:406] BatchNorm16 <- Convolution16
I0928 13:46:48.877912  4581 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0928 13:46:48.878072  4581 net.cpp:122] Setting up BatchNorm16
I0928 13:46:48.878077  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.878078  4581 net.cpp:137] Memory required for data: 558286000
I0928 13:46:48.878083  4581 layer_factory.hpp:77] Creating layer Scale16
I0928 13:46:48.878087  4581 net.cpp:84] Creating Layer Scale16
I0928 13:46:48.878089  4581 net.cpp:406] Scale16 <- Convolution16
I0928 13:46:48.878093  4581 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0928 13:46:48.878124  4581 layer_factory.hpp:77] Creating layer Scale16
I0928 13:46:48.878212  4581 net.cpp:122] Setting up Scale16
I0928 13:46:48.878216  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.878218  4581 net.cpp:137] Memory required for data: 564839600
I0928 13:46:48.878222  4581 layer_factory.hpp:77] Creating layer M2PELU16
I0928 13:46:48.878227  4581 net.cpp:84] Creating Layer M2PELU16
I0928 13:46:48.878231  4581 net.cpp:406] M2PELU16 <- Convolution16
I0928 13:46:48.878234  4581 net.cpp:367] M2PELU16 -> Convolution16 (in-place)
I0928 13:46:48.878340  4581 net.cpp:122] Setting up M2PELU16
I0928 13:46:48.878346  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.878348  4581 net.cpp:137] Memory required for data: 571393200
I0928 13:46:48.878352  4581 layer_factory.hpp:77] Creating layer Convolution17
I0928 13:46:48.878358  4581 net.cpp:84] Creating Layer Convolution17
I0928 13:46:48.878360  4581 net.cpp:406] Convolution17 <- Convolution16
I0928 13:46:48.878365  4581 net.cpp:380] Convolution17 -> Convolution17
I0928 13:46:48.879344  4581 net.cpp:122] Setting up Convolution17
I0928 13:46:48.879353  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.879355  4581 net.cpp:137] Memory required for data: 577946800
I0928 13:46:48.879359  4581 layer_factory.hpp:77] Creating layer BatchNorm17
I0928 13:46:48.879364  4581 net.cpp:84] Creating Layer BatchNorm17
I0928 13:46:48.879367  4581 net.cpp:406] BatchNorm17 <- Convolution17
I0928 13:46:48.879371  4581 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0928 13:46:48.879526  4581 net.cpp:122] Setting up BatchNorm17
I0928 13:46:48.879531  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.879534  4581 net.cpp:137] Memory required for data: 584500400
I0928 13:46:48.879539  4581 layer_factory.hpp:77] Creating layer Scale17
I0928 13:46:48.879542  4581 net.cpp:84] Creating Layer Scale17
I0928 13:46:48.879544  4581 net.cpp:406] Scale17 <- Convolution17
I0928 13:46:48.879547  4581 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0928 13:46:48.879578  4581 layer_factory.hpp:77] Creating layer Scale17
I0928 13:46:48.879665  4581 net.cpp:122] Setting up Scale17
I0928 13:46:48.879669  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.879672  4581 net.cpp:137] Memory required for data: 591054000
I0928 13:46:48.879675  4581 layer_factory.hpp:77] Creating layer Eltwise8
I0928 13:46:48.879679  4581 net.cpp:84] Creating Layer Eltwise8
I0928 13:46:48.879683  4581 net.cpp:406] Eltwise8 <- Eltwise7_M2PELU15_0_split_1
I0928 13:46:48.879691  4581 net.cpp:406] Eltwise8 <- Convolution17
I0928 13:46:48.879696  4581 net.cpp:380] Eltwise8 -> Eltwise8
I0928 13:46:48.879715  4581 net.cpp:122] Setting up Eltwise8
I0928 13:46:48.879719  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.879721  4581 net.cpp:137] Memory required for data: 597607600
I0928 13:46:48.879724  4581 layer_factory.hpp:77] Creating layer M2PELU17
I0928 13:46:48.879729  4581 net.cpp:84] Creating Layer M2PELU17
I0928 13:46:48.879730  4581 net.cpp:406] M2PELU17 <- Eltwise8
I0928 13:46:48.879734  4581 net.cpp:367] M2PELU17 -> Eltwise8 (in-place)
I0928 13:46:48.879837  4581 net.cpp:122] Setting up M2PELU17
I0928 13:46:48.879842  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.879843  4581 net.cpp:137] Memory required for data: 604161200
I0928 13:46:48.879847  4581 layer_factory.hpp:77] Creating layer Eltwise8_M2PELU17_0_split
I0928 13:46:48.879850  4581 net.cpp:84] Creating Layer Eltwise8_M2PELU17_0_split
I0928 13:46:48.879853  4581 net.cpp:406] Eltwise8_M2PELU17_0_split <- Eltwise8
I0928 13:46:48.879856  4581 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_0
I0928 13:46:48.879860  4581 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_1
I0928 13:46:48.879887  4581 net.cpp:122] Setting up Eltwise8_M2PELU17_0_split
I0928 13:46:48.879890  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.879894  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.879895  4581 net.cpp:137] Memory required for data: 617268400
I0928 13:46:48.879897  4581 layer_factory.hpp:77] Creating layer Convolution18
I0928 13:46:48.879904  4581 net.cpp:84] Creating Layer Convolution18
I0928 13:46:48.879906  4581 net.cpp:406] Convolution18 <- Eltwise8_M2PELU17_0_split_0
I0928 13:46:48.879909  4581 net.cpp:380] Convolution18 -> Convolution18
I0928 13:46:48.880895  4581 net.cpp:122] Setting up Convolution18
I0928 13:46:48.880903  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.880906  4581 net.cpp:137] Memory required for data: 623822000
I0928 13:46:48.880910  4581 layer_factory.hpp:77] Creating layer BatchNorm18
I0928 13:46:48.880915  4581 net.cpp:84] Creating Layer BatchNorm18
I0928 13:46:48.880918  4581 net.cpp:406] BatchNorm18 <- Convolution18
I0928 13:46:48.880921  4581 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0928 13:46:48.881073  4581 net.cpp:122] Setting up BatchNorm18
I0928 13:46:48.881078  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.881080  4581 net.cpp:137] Memory required for data: 630375600
I0928 13:46:48.881085  4581 layer_factory.hpp:77] Creating layer Scale18
I0928 13:46:48.881089  4581 net.cpp:84] Creating Layer Scale18
I0928 13:46:48.881091  4581 net.cpp:406] Scale18 <- Convolution18
I0928 13:46:48.881094  4581 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0928 13:46:48.881125  4581 layer_factory.hpp:77] Creating layer Scale18
I0928 13:46:48.881212  4581 net.cpp:122] Setting up Scale18
I0928 13:46:48.881217  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.881218  4581 net.cpp:137] Memory required for data: 636929200
I0928 13:46:48.881222  4581 layer_factory.hpp:77] Creating layer M2PELU18
I0928 13:46:48.881227  4581 net.cpp:84] Creating Layer M2PELU18
I0928 13:46:48.881230  4581 net.cpp:406] M2PELU18 <- Convolution18
I0928 13:46:48.881234  4581 net.cpp:367] M2PELU18 -> Convolution18 (in-place)
I0928 13:46:48.881338  4581 net.cpp:122] Setting up M2PELU18
I0928 13:46:48.881342  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.881345  4581 net.cpp:137] Memory required for data: 643482800
I0928 13:46:48.881348  4581 layer_factory.hpp:77] Creating layer Convolution19
I0928 13:46:48.881356  4581 net.cpp:84] Creating Layer Convolution19
I0928 13:46:48.881357  4581 net.cpp:406] Convolution19 <- Convolution18
I0928 13:46:48.881361  4581 net.cpp:380] Convolution19 -> Convolution19
I0928 13:46:48.882309  4581 net.cpp:122] Setting up Convolution19
I0928 13:46:48.882318  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.882326  4581 net.cpp:137] Memory required for data: 650036400
I0928 13:46:48.882331  4581 layer_factory.hpp:77] Creating layer BatchNorm19
I0928 13:46:48.882336  4581 net.cpp:84] Creating Layer BatchNorm19
I0928 13:46:48.882339  4581 net.cpp:406] BatchNorm19 <- Convolution19
I0928 13:46:48.882344  4581 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0928 13:46:48.882500  4581 net.cpp:122] Setting up BatchNorm19
I0928 13:46:48.882505  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.882508  4581 net.cpp:137] Memory required for data: 656590000
I0928 13:46:48.882511  4581 layer_factory.hpp:77] Creating layer Scale19
I0928 13:46:48.882516  4581 net.cpp:84] Creating Layer Scale19
I0928 13:46:48.882519  4581 net.cpp:406] Scale19 <- Convolution19
I0928 13:46:48.882537  4581 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0928 13:46:48.882580  4581 layer_factory.hpp:77] Creating layer Scale19
I0928 13:46:48.882669  4581 net.cpp:122] Setting up Scale19
I0928 13:46:48.882674  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.882676  4581 net.cpp:137] Memory required for data: 663143600
I0928 13:46:48.882680  4581 layer_factory.hpp:77] Creating layer Eltwise9
I0928 13:46:48.882684  4581 net.cpp:84] Creating Layer Eltwise9
I0928 13:46:48.882688  4581 net.cpp:406] Eltwise9 <- Eltwise8_M2PELU17_0_split_1
I0928 13:46:48.882690  4581 net.cpp:406] Eltwise9 <- Convolution19
I0928 13:46:48.882694  4581 net.cpp:380] Eltwise9 -> Eltwise9
I0928 13:46:48.882712  4581 net.cpp:122] Setting up Eltwise9
I0928 13:46:48.882715  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.882717  4581 net.cpp:137] Memory required for data: 669697200
I0928 13:46:48.882719  4581 layer_factory.hpp:77] Creating layer M2PELU19
I0928 13:46:48.882725  4581 net.cpp:84] Creating Layer M2PELU19
I0928 13:46:48.882727  4581 net.cpp:406] M2PELU19 <- Eltwise9
I0928 13:46:48.882730  4581 net.cpp:367] M2PELU19 -> Eltwise9 (in-place)
I0928 13:46:48.882834  4581 net.cpp:122] Setting up M2PELU19
I0928 13:46:48.882839  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.882841  4581 net.cpp:137] Memory required for data: 676250800
I0928 13:46:48.882845  4581 layer_factory.hpp:77] Creating layer Eltwise9_M2PELU19_0_split
I0928 13:46:48.882849  4581 net.cpp:84] Creating Layer Eltwise9_M2PELU19_0_split
I0928 13:46:48.882851  4581 net.cpp:406] Eltwise9_M2PELU19_0_split <- Eltwise9
I0928 13:46:48.882854  4581 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_0
I0928 13:46:48.904173  4581 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_1
I0928 13:46:48.904232  4581 net.cpp:122] Setting up Eltwise9_M2PELU19_0_split
I0928 13:46:48.904239  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.904245  4581 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 13:46:48.904249  4581 net.cpp:137] Memory required for data: 689358000
I0928 13:46:48.904253  4581 layer_factory.hpp:77] Creating layer Convolution20
I0928 13:46:48.904263  4581 net.cpp:84] Creating Layer Convolution20
I0928 13:46:48.904266  4581 net.cpp:406] Convolution20 <- Eltwise9_M2PELU19_0_split_0
I0928 13:46:48.904275  4581 net.cpp:380] Convolution20 -> Convolution20
I0928 13:46:48.905357  4581 net.cpp:122] Setting up Convolution20
I0928 13:46:48.905367  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.905370  4581 net.cpp:137] Memory required for data: 692634800
I0928 13:46:48.905375  4581 layer_factory.hpp:77] Creating layer BatchNorm20
I0928 13:46:48.905380  4581 net.cpp:84] Creating Layer BatchNorm20
I0928 13:46:48.905382  4581 net.cpp:406] BatchNorm20 <- Convolution20
I0928 13:46:48.905386  4581 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0928 13:46:48.905568  4581 net.cpp:122] Setting up BatchNorm20
I0928 13:46:48.905587  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.905591  4581 net.cpp:137] Memory required for data: 695911600
I0928 13:46:48.905599  4581 layer_factory.hpp:77] Creating layer Scale20
I0928 13:46:48.905624  4581 net.cpp:84] Creating Layer Scale20
I0928 13:46:48.905630  4581 net.cpp:406] Scale20 <- Convolution20
I0928 13:46:48.905637  4581 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0928 13:46:48.905691  4581 layer_factory.hpp:77] Creating layer Scale20
I0928 13:46:48.905831  4581 net.cpp:122] Setting up Scale20
I0928 13:46:48.905839  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.905841  4581 net.cpp:137] Memory required for data: 699188400
I0928 13:46:48.905846  4581 layer_factory.hpp:77] Creating layer Convolution21
I0928 13:46:48.905855  4581 net.cpp:84] Creating Layer Convolution21
I0928 13:46:48.905860  4581 net.cpp:406] Convolution21 <- Eltwise9_M2PELU19_0_split_1
I0928 13:46:48.905869  4581 net.cpp:380] Convolution21 -> Convolution21
I0928 13:46:48.907049  4581 net.cpp:122] Setting up Convolution21
I0928 13:46:48.907058  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.907061  4581 net.cpp:137] Memory required for data: 702465200
I0928 13:46:48.907066  4581 layer_factory.hpp:77] Creating layer BatchNorm21
I0928 13:46:48.907073  4581 net.cpp:84] Creating Layer BatchNorm21
I0928 13:46:48.907075  4581 net.cpp:406] BatchNorm21 <- Convolution21
I0928 13:46:48.907079  4581 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0928 13:46:48.907236  4581 net.cpp:122] Setting up BatchNorm21
I0928 13:46:48.907240  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.907243  4581 net.cpp:137] Memory required for data: 705742000
I0928 13:46:48.907248  4581 layer_factory.hpp:77] Creating layer Scale21
I0928 13:46:48.907253  4581 net.cpp:84] Creating Layer Scale21
I0928 13:46:48.907255  4581 net.cpp:406] Scale21 <- Convolution21
I0928 13:46:48.907259  4581 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0928 13:46:48.907290  4581 layer_factory.hpp:77] Creating layer Scale21
I0928 13:46:48.907380  4581 net.cpp:122] Setting up Scale21
I0928 13:46:48.907385  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.907387  4581 net.cpp:137] Memory required for data: 709018800
I0928 13:46:48.907390  4581 layer_factory.hpp:77] Creating layer M2PELU20
I0928 13:46:48.907397  4581 net.cpp:84] Creating Layer M2PELU20
I0928 13:46:48.907398  4581 net.cpp:406] M2PELU20 <- Convolution21
I0928 13:46:48.907402  4581 net.cpp:367] M2PELU20 -> Convolution21 (in-place)
I0928 13:46:48.907498  4581 net.cpp:122] Setting up M2PELU20
I0928 13:46:48.907503  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.907505  4581 net.cpp:137] Memory required for data: 712295600
I0928 13:46:48.907510  4581 layer_factory.hpp:77] Creating layer Convolution22
I0928 13:46:48.907517  4581 net.cpp:84] Creating Layer Convolution22
I0928 13:46:48.907521  4581 net.cpp:406] Convolution22 <- Convolution21
I0928 13:46:48.907524  4581 net.cpp:380] Convolution22 -> Convolution22
I0928 13:46:48.908701  4581 net.cpp:122] Setting up Convolution22
I0928 13:46:48.908710  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.908713  4581 net.cpp:137] Memory required for data: 715572400
I0928 13:46:48.908717  4581 layer_factory.hpp:77] Creating layer BatchNorm22
I0928 13:46:48.908723  4581 net.cpp:84] Creating Layer BatchNorm22
I0928 13:46:48.908727  4581 net.cpp:406] BatchNorm22 <- Convolution22
I0928 13:46:48.908730  4581 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0928 13:46:48.908898  4581 net.cpp:122] Setting up BatchNorm22
I0928 13:46:48.908903  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.908905  4581 net.cpp:137] Memory required for data: 718849200
I0928 13:46:48.908910  4581 layer_factory.hpp:77] Creating layer Scale22
I0928 13:46:48.908915  4581 net.cpp:84] Creating Layer Scale22
I0928 13:46:48.908918  4581 net.cpp:406] Scale22 <- Convolution22
I0928 13:46:48.908921  4581 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0928 13:46:48.908954  4581 layer_factory.hpp:77] Creating layer Scale22
I0928 13:46:48.909054  4581 net.cpp:122] Setting up Scale22
I0928 13:46:48.909059  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.909067  4581 net.cpp:137] Memory required for data: 722126000
I0928 13:46:48.909080  4581 layer_factory.hpp:77] Creating layer Eltwise10
I0928 13:46:48.909085  4581 net.cpp:84] Creating Layer Eltwise10
I0928 13:46:48.909087  4581 net.cpp:406] Eltwise10 <- Convolution20
I0928 13:46:48.909090  4581 net.cpp:406] Eltwise10 <- Convolution22
I0928 13:46:48.909096  4581 net.cpp:380] Eltwise10 -> Eltwise10
I0928 13:46:48.909113  4581 net.cpp:122] Setting up Eltwise10
I0928 13:46:48.909118  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.909121  4581 net.cpp:137] Memory required for data: 725402800
I0928 13:46:48.909122  4581 layer_factory.hpp:77] Creating layer M2PELU21
I0928 13:46:48.909127  4581 net.cpp:84] Creating Layer M2PELU21
I0928 13:46:48.909131  4581 net.cpp:406] M2PELU21 <- Eltwise10
I0928 13:46:48.909134  4581 net.cpp:367] M2PELU21 -> Eltwise10 (in-place)
I0928 13:46:48.909245  4581 net.cpp:122] Setting up M2PELU21
I0928 13:46:48.909250  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.909251  4581 net.cpp:137] Memory required for data: 728679600
I0928 13:46:48.909255  4581 layer_factory.hpp:77] Creating layer Eltwise10_M2PELU21_0_split
I0928 13:46:48.909260  4581 net.cpp:84] Creating Layer Eltwise10_M2PELU21_0_split
I0928 13:46:48.909262  4581 net.cpp:406] Eltwise10_M2PELU21_0_split <- Eltwise10
I0928 13:46:48.909266  4581 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_0
I0928 13:46:48.909271  4581 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_1
I0928 13:46:48.909301  4581 net.cpp:122] Setting up Eltwise10_M2PELU21_0_split
I0928 13:46:48.909306  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.909308  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.909310  4581 net.cpp:137] Memory required for data: 735233200
I0928 13:46:48.909312  4581 layer_factory.hpp:77] Creating layer Convolution23
I0928 13:46:48.909319  4581 net.cpp:84] Creating Layer Convolution23
I0928 13:46:48.909322  4581 net.cpp:406] Convolution23 <- Eltwise10_M2PELU21_0_split_0
I0928 13:46:48.909327  4581 net.cpp:380] Convolution23 -> Convolution23
I0928 13:46:48.910539  4581 net.cpp:122] Setting up Convolution23
I0928 13:46:48.910549  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.910552  4581 net.cpp:137] Memory required for data: 738510000
I0928 13:46:48.910557  4581 layer_factory.hpp:77] Creating layer BatchNorm23
I0928 13:46:48.910562  4581 net.cpp:84] Creating Layer BatchNorm23
I0928 13:46:48.910565  4581 net.cpp:406] BatchNorm23 <- Convolution23
I0928 13:46:48.910568  4581 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0928 13:46:48.910732  4581 net.cpp:122] Setting up BatchNorm23
I0928 13:46:48.910737  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.910739  4581 net.cpp:137] Memory required for data: 741786800
I0928 13:46:48.910744  4581 layer_factory.hpp:77] Creating layer Scale23
I0928 13:46:48.910749  4581 net.cpp:84] Creating Layer Scale23
I0928 13:46:48.910753  4581 net.cpp:406] Scale23 <- Convolution23
I0928 13:46:48.910755  4581 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0928 13:46:48.910789  4581 layer_factory.hpp:77] Creating layer Scale23
I0928 13:46:48.910882  4581 net.cpp:122] Setting up Scale23
I0928 13:46:48.910887  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.910889  4581 net.cpp:137] Memory required for data: 745063600
I0928 13:46:48.910893  4581 layer_factory.hpp:77] Creating layer M2PELU22
I0928 13:46:48.910898  4581 net.cpp:84] Creating Layer M2PELU22
I0928 13:46:48.910902  4581 net.cpp:406] M2PELU22 <- Convolution23
I0928 13:46:48.910907  4581 net.cpp:367] M2PELU22 -> Convolution23 (in-place)
I0928 13:46:48.911015  4581 net.cpp:122] Setting up M2PELU22
I0928 13:46:48.911020  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.911022  4581 net.cpp:137] Memory required for data: 748340400
I0928 13:46:48.911026  4581 layer_factory.hpp:77] Creating layer Convolution24
I0928 13:46:48.911033  4581 net.cpp:84] Creating Layer Convolution24
I0928 13:46:48.911042  4581 net.cpp:406] Convolution24 <- Convolution23
I0928 13:46:48.911046  4581 net.cpp:380] Convolution24 -> Convolution24
I0928 13:46:48.912189  4581 net.cpp:122] Setting up Convolution24
I0928 13:46:48.912196  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.912199  4581 net.cpp:137] Memory required for data: 751617200
I0928 13:46:48.912204  4581 layer_factory.hpp:77] Creating layer BatchNorm24
I0928 13:46:48.912209  4581 net.cpp:84] Creating Layer BatchNorm24
I0928 13:46:48.912211  4581 net.cpp:406] BatchNorm24 <- Convolution24
I0928 13:46:48.912216  4581 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0928 13:46:48.912868  4581 net.cpp:122] Setting up BatchNorm24
I0928 13:46:48.912876  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.912879  4581 net.cpp:137] Memory required for data: 754894000
I0928 13:46:48.912885  4581 layer_factory.hpp:77] Creating layer Scale24
I0928 13:46:48.912889  4581 net.cpp:84] Creating Layer Scale24
I0928 13:46:48.912892  4581 net.cpp:406] Scale24 <- Convolution24
I0928 13:46:48.912895  4581 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0928 13:46:48.912923  4581 layer_factory.hpp:77] Creating layer Scale24
I0928 13:46:48.912997  4581 net.cpp:122] Setting up Scale24
I0928 13:46:48.913002  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.913003  4581 net.cpp:137] Memory required for data: 758170800
I0928 13:46:48.913007  4581 layer_factory.hpp:77] Creating layer Eltwise11
I0928 13:46:48.913012  4581 net.cpp:84] Creating Layer Eltwise11
I0928 13:46:48.913014  4581 net.cpp:406] Eltwise11 <- Eltwise10_M2PELU21_0_split_1
I0928 13:46:48.913017  4581 net.cpp:406] Eltwise11 <- Convolution24
I0928 13:46:48.913022  4581 net.cpp:380] Eltwise11 -> Eltwise11
I0928 13:46:48.913033  4581 net.cpp:122] Setting up Eltwise11
I0928 13:46:48.913036  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.913038  4581 net.cpp:137] Memory required for data: 761447600
I0928 13:46:48.913040  4581 layer_factory.hpp:77] Creating layer M2PELU23
I0928 13:46:48.913045  4581 net.cpp:84] Creating Layer M2PELU23
I0928 13:46:48.913048  4581 net.cpp:406] M2PELU23 <- Eltwise11
I0928 13:46:48.913051  4581 net.cpp:367] M2PELU23 -> Eltwise11 (in-place)
I0928 13:46:48.913136  4581 net.cpp:122] Setting up M2PELU23
I0928 13:46:48.913141  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.913142  4581 net.cpp:137] Memory required for data: 764724400
I0928 13:46:48.913146  4581 layer_factory.hpp:77] Creating layer Eltwise11_M2PELU23_0_split
I0928 13:46:48.913151  4581 net.cpp:84] Creating Layer Eltwise11_M2PELU23_0_split
I0928 13:46:48.913152  4581 net.cpp:406] Eltwise11_M2PELU23_0_split <- Eltwise11
I0928 13:46:48.913156  4581 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_0
I0928 13:46:48.913161  4581 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_1
I0928 13:46:48.913183  4581 net.cpp:122] Setting up Eltwise11_M2PELU23_0_split
I0928 13:46:48.913187  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.913189  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.913192  4581 net.cpp:137] Memory required for data: 771278000
I0928 13:46:48.913194  4581 layer_factory.hpp:77] Creating layer Convolution25
I0928 13:46:48.913199  4581 net.cpp:84] Creating Layer Convolution25
I0928 13:46:48.913203  4581 net.cpp:406] Convolution25 <- Eltwise11_M2PELU23_0_split_0
I0928 13:46:48.913208  4581 net.cpp:380] Convolution25 -> Convolution25
I0928 13:46:48.914328  4581 net.cpp:122] Setting up Convolution25
I0928 13:46:48.914337  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.914340  4581 net.cpp:137] Memory required for data: 774554800
I0928 13:46:48.914345  4581 layer_factory.hpp:77] Creating layer BatchNorm25
I0928 13:46:48.914350  4581 net.cpp:84] Creating Layer BatchNorm25
I0928 13:46:48.914352  4581 net.cpp:406] BatchNorm25 <- Convolution25
I0928 13:46:48.914357  4581 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0928 13:46:48.914486  4581 net.cpp:122] Setting up BatchNorm25
I0928 13:46:48.914497  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.914499  4581 net.cpp:137] Memory required for data: 777831600
I0928 13:46:48.914505  4581 layer_factory.hpp:77] Creating layer Scale25
I0928 13:46:48.914508  4581 net.cpp:84] Creating Layer Scale25
I0928 13:46:48.914510  4581 net.cpp:406] Scale25 <- Convolution25
I0928 13:46:48.914515  4581 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0928 13:46:48.914567  4581 layer_factory.hpp:77] Creating layer Scale25
I0928 13:46:48.914643  4581 net.cpp:122] Setting up Scale25
I0928 13:46:48.914646  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.914649  4581 net.cpp:137] Memory required for data: 781108400
I0928 13:46:48.914652  4581 layer_factory.hpp:77] Creating layer M2PELU24
I0928 13:46:48.914657  4581 net.cpp:84] Creating Layer M2PELU24
I0928 13:46:48.914660  4581 net.cpp:406] M2PELU24 <- Convolution25
I0928 13:46:48.914664  4581 net.cpp:367] M2PELU24 -> Convolution25 (in-place)
I0928 13:46:48.914746  4581 net.cpp:122] Setting up M2PELU24
I0928 13:46:48.914749  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.914752  4581 net.cpp:137] Memory required for data: 784385200
I0928 13:46:48.914755  4581 layer_factory.hpp:77] Creating layer Convolution26
I0928 13:46:48.914762  4581 net.cpp:84] Creating Layer Convolution26
I0928 13:46:48.914764  4581 net.cpp:406] Convolution26 <- Convolution25
I0928 13:46:48.914769  4581 net.cpp:380] Convolution26 -> Convolution26
I0928 13:46:48.915534  4581 net.cpp:122] Setting up Convolution26
I0928 13:46:48.915544  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.915545  4581 net.cpp:137] Memory required for data: 787662000
I0928 13:46:48.915550  4581 layer_factory.hpp:77] Creating layer BatchNorm26
I0928 13:46:48.915555  4581 net.cpp:84] Creating Layer BatchNorm26
I0928 13:46:48.915557  4581 net.cpp:406] BatchNorm26 <- Convolution26
I0928 13:46:48.915561  4581 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0928 13:46:48.915688  4581 net.cpp:122] Setting up BatchNorm26
I0928 13:46:48.915691  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.915693  4581 net.cpp:137] Memory required for data: 790938800
I0928 13:46:48.915697  4581 layer_factory.hpp:77] Creating layer Scale26
I0928 13:46:48.915702  4581 net.cpp:84] Creating Layer Scale26
I0928 13:46:48.935124  4581 net.cpp:406] Scale26 <- Convolution26
I0928 13:46:48.935137  4581 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0928 13:46:48.935187  4581 layer_factory.hpp:77] Creating layer Scale26
I0928 13:46:48.935274  4581 net.cpp:122] Setting up Scale26
I0928 13:46:48.935279  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.935282  4581 net.cpp:137] Memory required for data: 794215600
I0928 13:46:48.935287  4581 layer_factory.hpp:77] Creating layer Eltwise12
I0928 13:46:48.935292  4581 net.cpp:84] Creating Layer Eltwise12
I0928 13:46:48.935295  4581 net.cpp:406] Eltwise12 <- Eltwise11_M2PELU23_0_split_1
I0928 13:46:48.935298  4581 net.cpp:406] Eltwise12 <- Convolution26
I0928 13:46:48.935302  4581 net.cpp:380] Eltwise12 -> Eltwise12
I0928 13:46:48.935317  4581 net.cpp:122] Setting up Eltwise12
I0928 13:46:48.935320  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.935322  4581 net.cpp:137] Memory required for data: 797492400
I0928 13:46:48.935325  4581 layer_factory.hpp:77] Creating layer M2PELU25
I0928 13:46:48.935341  4581 net.cpp:84] Creating Layer M2PELU25
I0928 13:46:48.935344  4581 net.cpp:406] M2PELU25 <- Eltwise12
I0928 13:46:48.935348  4581 net.cpp:367] M2PELU25 -> Eltwise12 (in-place)
I0928 13:46:48.935443  4581 net.cpp:122] Setting up M2PELU25
I0928 13:46:48.935448  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.935451  4581 net.cpp:137] Memory required for data: 800769200
I0928 13:46:48.935456  4581 layer_factory.hpp:77] Creating layer Eltwise12_M2PELU25_0_split
I0928 13:46:48.935459  4581 net.cpp:84] Creating Layer Eltwise12_M2PELU25_0_split
I0928 13:46:48.935461  4581 net.cpp:406] Eltwise12_M2PELU25_0_split <- Eltwise12
I0928 13:46:48.935473  4581 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_0
I0928 13:46:48.935479  4581 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_1
I0928 13:46:48.935503  4581 net.cpp:122] Setting up Eltwise12_M2PELU25_0_split
I0928 13:46:48.935508  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.935510  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.935513  4581 net.cpp:137] Memory required for data: 807322800
I0928 13:46:48.935515  4581 layer_factory.hpp:77] Creating layer Convolution27
I0928 13:46:48.935523  4581 net.cpp:84] Creating Layer Convolution27
I0928 13:46:48.935525  4581 net.cpp:406] Convolution27 <- Eltwise12_M2PELU25_0_split_0
I0928 13:46:48.935529  4581 net.cpp:380] Convolution27 -> Convolution27
I0928 13:46:48.937230  4581 net.cpp:122] Setting up Convolution27
I0928 13:46:48.937240  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.937243  4581 net.cpp:137] Memory required for data: 810599600
I0928 13:46:48.937248  4581 layer_factory.hpp:77] Creating layer BatchNorm27
I0928 13:46:48.937252  4581 net.cpp:84] Creating Layer BatchNorm27
I0928 13:46:48.937255  4581 net.cpp:406] BatchNorm27 <- Convolution27
I0928 13:46:48.937260  4581 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0928 13:46:48.937388  4581 net.cpp:122] Setting up BatchNorm27
I0928 13:46:48.937392  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.937396  4581 net.cpp:137] Memory required for data: 813876400
I0928 13:46:48.937399  4581 layer_factory.hpp:77] Creating layer Scale27
I0928 13:46:48.937403  4581 net.cpp:84] Creating Layer Scale27
I0928 13:46:48.937407  4581 net.cpp:406] Scale27 <- Convolution27
I0928 13:46:48.937409  4581 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0928 13:46:48.937436  4581 layer_factory.hpp:77] Creating layer Scale27
I0928 13:46:48.937508  4581 net.cpp:122] Setting up Scale27
I0928 13:46:48.937512  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.937515  4581 net.cpp:137] Memory required for data: 817153200
I0928 13:46:48.937518  4581 layer_factory.hpp:77] Creating layer M2PELU26
I0928 13:46:48.937523  4581 net.cpp:84] Creating Layer M2PELU26
I0928 13:46:48.937525  4581 net.cpp:406] M2PELU26 <- Convolution27
I0928 13:46:48.937530  4581 net.cpp:367] M2PELU26 -> Convolution27 (in-place)
I0928 13:46:48.937609  4581 net.cpp:122] Setting up M2PELU26
I0928 13:46:48.937613  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.937615  4581 net.cpp:137] Memory required for data: 820430000
I0928 13:46:48.937619  4581 layer_factory.hpp:77] Creating layer Convolution28
I0928 13:46:48.937625  4581 net.cpp:84] Creating Layer Convolution28
I0928 13:46:48.937628  4581 net.cpp:406] Convolution28 <- Convolution27
I0928 13:46:48.937633  4581 net.cpp:380] Convolution28 -> Convolution28
I0928 13:46:48.939093  4581 net.cpp:122] Setting up Convolution28
I0928 13:46:48.939102  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.939105  4581 net.cpp:137] Memory required for data: 823706800
I0928 13:46:48.939110  4581 layer_factory.hpp:77] Creating layer BatchNorm28
I0928 13:46:48.939116  4581 net.cpp:84] Creating Layer BatchNorm28
I0928 13:46:48.939118  4581 net.cpp:406] BatchNorm28 <- Convolution28
I0928 13:46:48.939122  4581 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0928 13:46:48.939257  4581 net.cpp:122] Setting up BatchNorm28
I0928 13:46:48.939262  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.939265  4581 net.cpp:137] Memory required for data: 826983600
I0928 13:46:48.939270  4581 layer_factory.hpp:77] Creating layer Scale28
I0928 13:46:48.939273  4581 net.cpp:84] Creating Layer Scale28
I0928 13:46:48.939276  4581 net.cpp:406] Scale28 <- Convolution28
I0928 13:46:48.939280  4581 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0928 13:46:48.939306  4581 layer_factory.hpp:77] Creating layer Scale28
I0928 13:46:48.939378  4581 net.cpp:122] Setting up Scale28
I0928 13:46:48.939383  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.939390  4581 net.cpp:137] Memory required for data: 830260400
I0928 13:46:48.939395  4581 layer_factory.hpp:77] Creating layer Eltwise13
I0928 13:46:48.939399  4581 net.cpp:84] Creating Layer Eltwise13
I0928 13:46:48.939402  4581 net.cpp:406] Eltwise13 <- Eltwise12_M2PELU25_0_split_1
I0928 13:46:48.939405  4581 net.cpp:406] Eltwise13 <- Convolution28
I0928 13:46:48.939409  4581 net.cpp:380] Eltwise13 -> Eltwise13
I0928 13:46:48.939421  4581 net.cpp:122] Setting up Eltwise13
I0928 13:46:48.939425  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.939426  4581 net.cpp:137] Memory required for data: 833537200
I0928 13:46:48.939429  4581 layer_factory.hpp:77] Creating layer M2PELU27
I0928 13:46:48.939435  4581 net.cpp:84] Creating Layer M2PELU27
I0928 13:46:48.939436  4581 net.cpp:406] M2PELU27 <- Eltwise13
I0928 13:46:48.939440  4581 net.cpp:367] M2PELU27 -> Eltwise13 (in-place)
I0928 13:46:48.939524  4581 net.cpp:122] Setting up M2PELU27
I0928 13:46:48.939528  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.939530  4581 net.cpp:137] Memory required for data: 836814000
I0928 13:46:48.939533  4581 layer_factory.hpp:77] Creating layer Eltwise13_M2PELU27_0_split
I0928 13:46:48.939538  4581 net.cpp:84] Creating Layer Eltwise13_M2PELU27_0_split
I0928 13:46:48.939539  4581 net.cpp:406] Eltwise13_M2PELU27_0_split <- Eltwise13
I0928 13:46:48.939543  4581 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_0
I0928 13:46:48.939548  4581 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_1
I0928 13:46:48.939570  4581 net.cpp:122] Setting up Eltwise13_M2PELU27_0_split
I0928 13:46:48.939574  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.939576  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.939579  4581 net.cpp:137] Memory required for data: 843367600
I0928 13:46:48.939580  4581 layer_factory.hpp:77] Creating layer Convolution29
I0928 13:46:48.939586  4581 net.cpp:84] Creating Layer Convolution29
I0928 13:46:48.939589  4581 net.cpp:406] Convolution29 <- Eltwise13_M2PELU27_0_split_0
I0928 13:46:48.939594  4581 net.cpp:380] Convolution29 -> Convolution29
I0928 13:46:48.940663  4581 net.cpp:122] Setting up Convolution29
I0928 13:46:48.940672  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.940675  4581 net.cpp:137] Memory required for data: 846644400
I0928 13:46:48.940680  4581 layer_factory.hpp:77] Creating layer BatchNorm29
I0928 13:46:48.940685  4581 net.cpp:84] Creating Layer BatchNorm29
I0928 13:46:48.940688  4581 net.cpp:406] BatchNorm29 <- Convolution29
I0928 13:46:48.940692  4581 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0928 13:46:48.940816  4581 net.cpp:122] Setting up BatchNorm29
I0928 13:46:48.940820  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.940822  4581 net.cpp:137] Memory required for data: 849921200
I0928 13:46:48.940827  4581 layer_factory.hpp:77] Creating layer Scale29
I0928 13:46:48.940831  4581 net.cpp:84] Creating Layer Scale29
I0928 13:46:48.940834  4581 net.cpp:406] Scale29 <- Convolution29
I0928 13:46:48.940837  4581 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0928 13:46:48.940862  4581 layer_factory.hpp:77] Creating layer Scale29
I0928 13:46:48.940933  4581 net.cpp:122] Setting up Scale29
I0928 13:46:48.940937  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.940939  4581 net.cpp:137] Memory required for data: 853198000
I0928 13:46:48.940963  4581 layer_factory.hpp:77] Creating layer M2PELU28
I0928 13:46:48.940968  4581 net.cpp:84] Creating Layer M2PELU28
I0928 13:46:48.940970  4581 net.cpp:406] M2PELU28 <- Convolution29
I0928 13:46:48.940973  4581 net.cpp:367] M2PELU28 -> Convolution29 (in-place)
I0928 13:46:48.941057  4581 net.cpp:122] Setting up M2PELU28
I0928 13:46:48.941062  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.941064  4581 net.cpp:137] Memory required for data: 856474800
I0928 13:46:48.941067  4581 layer_factory.hpp:77] Creating layer Convolution30
I0928 13:46:48.941082  4581 net.cpp:84] Creating Layer Convolution30
I0928 13:46:48.941084  4581 net.cpp:406] Convolution30 <- Convolution29
I0928 13:46:48.941089  4581 net.cpp:380] Convolution30 -> Convolution30
I0928 13:46:48.942162  4581 net.cpp:122] Setting up Convolution30
I0928 13:46:48.942170  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.942173  4581 net.cpp:137] Memory required for data: 859751600
I0928 13:46:48.942178  4581 layer_factory.hpp:77] Creating layer BatchNorm30
I0928 13:46:48.942183  4581 net.cpp:84] Creating Layer BatchNorm30
I0928 13:46:48.942185  4581 net.cpp:406] BatchNorm30 <- Convolution30
I0928 13:46:48.942188  4581 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0928 13:46:48.942314  4581 net.cpp:122] Setting up BatchNorm30
I0928 13:46:48.942318  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.942320  4581 net.cpp:137] Memory required for data: 863028400
I0928 13:46:48.942325  4581 layer_factory.hpp:77] Creating layer Scale30
I0928 13:46:48.942328  4581 net.cpp:84] Creating Layer Scale30
I0928 13:46:48.942332  4581 net.cpp:406] Scale30 <- Convolution30
I0928 13:46:48.942334  4581 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0928 13:46:48.942359  4581 layer_factory.hpp:77] Creating layer Scale30
I0928 13:46:48.942430  4581 net.cpp:122] Setting up Scale30
I0928 13:46:48.942435  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.942436  4581 net.cpp:137] Memory required for data: 866305200
I0928 13:46:48.942440  4581 layer_factory.hpp:77] Creating layer Eltwise14
I0928 13:46:48.942445  4581 net.cpp:84] Creating Layer Eltwise14
I0928 13:46:48.942447  4581 net.cpp:406] Eltwise14 <- Eltwise13_M2PELU27_0_split_1
I0928 13:46:48.942451  4581 net.cpp:406] Eltwise14 <- Convolution30
I0928 13:46:48.942454  4581 net.cpp:380] Eltwise14 -> Eltwise14
I0928 13:46:48.942466  4581 net.cpp:122] Setting up Eltwise14
I0928 13:46:48.942468  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.942471  4581 net.cpp:137] Memory required for data: 869582000
I0928 13:46:48.942473  4581 layer_factory.hpp:77] Creating layer M2PELU29
I0928 13:46:48.942478  4581 net.cpp:84] Creating Layer M2PELU29
I0928 13:46:48.942481  4581 net.cpp:406] M2PELU29 <- Eltwise14
I0928 13:46:48.942484  4581 net.cpp:367] M2PELU29 -> Eltwise14 (in-place)
I0928 13:46:48.942605  4581 net.cpp:122] Setting up M2PELU29
I0928 13:46:48.942610  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.942611  4581 net.cpp:137] Memory required for data: 872858800
I0928 13:46:48.942615  4581 layer_factory.hpp:77] Creating layer Eltwise14_M2PELU29_0_split
I0928 13:46:48.942618  4581 net.cpp:84] Creating Layer Eltwise14_M2PELU29_0_split
I0928 13:46:48.942621  4581 net.cpp:406] Eltwise14_M2PELU29_0_split <- Eltwise14
I0928 13:46:48.942625  4581 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_0
I0928 13:46:48.942629  4581 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_1
I0928 13:46:48.942651  4581 net.cpp:122] Setting up Eltwise14_M2PELU29_0_split
I0928 13:46:48.942656  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.942657  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.942659  4581 net.cpp:137] Memory required for data: 879412400
I0928 13:46:48.942662  4581 layer_factory.hpp:77] Creating layer Convolution31
I0928 13:46:48.942667  4581 net.cpp:84] Creating Layer Convolution31
I0928 13:46:48.942670  4581 net.cpp:406] Convolution31 <- Eltwise14_M2PELU29_0_split_0
I0928 13:46:48.942674  4581 net.cpp:380] Convolution31 -> Convolution31
I0928 13:46:48.943750  4581 net.cpp:122] Setting up Convolution31
I0928 13:46:48.943759  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.943763  4581 net.cpp:137] Memory required for data: 882689200
I0928 13:46:48.943766  4581 layer_factory.hpp:77] Creating layer BatchNorm31
I0928 13:46:48.943771  4581 net.cpp:84] Creating Layer BatchNorm31
I0928 13:46:48.943773  4581 net.cpp:406] BatchNorm31 <- Convolution31
I0928 13:46:48.943778  4581 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0928 13:46:48.943909  4581 net.cpp:122] Setting up BatchNorm31
I0928 13:46:48.943914  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.943917  4581 net.cpp:137] Memory required for data: 885966000
I0928 13:46:48.943922  4581 layer_factory.hpp:77] Creating layer Scale31
I0928 13:46:48.943925  4581 net.cpp:84] Creating Layer Scale31
I0928 13:46:48.943928  4581 net.cpp:406] Scale31 <- Convolution31
I0928 13:46:48.943930  4581 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0928 13:46:48.943956  4581 layer_factory.hpp:77] Creating layer Scale31
I0928 13:46:48.944027  4581 net.cpp:122] Setting up Scale31
I0928 13:46:48.944032  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.944034  4581 net.cpp:137] Memory required for data: 889242800
I0928 13:46:48.944037  4581 layer_factory.hpp:77] Creating layer M2PELU30
I0928 13:46:48.944042  4581 net.cpp:84] Creating Layer M2PELU30
I0928 13:46:48.944046  4581 net.cpp:406] M2PELU30 <- Convolution31
I0928 13:46:48.944048  4581 net.cpp:367] M2PELU30 -> Convolution31 (in-place)
I0928 13:46:48.944126  4581 net.cpp:122] Setting up M2PELU30
I0928 13:46:48.944130  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.944133  4581 net.cpp:137] Memory required for data: 892519600
I0928 13:46:48.944135  4581 layer_factory.hpp:77] Creating layer Convolution32
I0928 13:46:48.944142  4581 net.cpp:84] Creating Layer Convolution32
I0928 13:46:48.944144  4581 net.cpp:406] Convolution32 <- Convolution31
I0928 13:46:48.944149  4581 net.cpp:380] Convolution32 -> Convolution32
I0928 13:46:48.945225  4581 net.cpp:122] Setting up Convolution32
I0928 13:46:48.945235  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.945236  4581 net.cpp:137] Memory required for data: 895796400
I0928 13:46:48.945241  4581 layer_factory.hpp:77] Creating layer BatchNorm32
I0928 13:46:48.945247  4581 net.cpp:84] Creating Layer BatchNorm32
I0928 13:46:48.945250  4581 net.cpp:406] BatchNorm32 <- Convolution32
I0928 13:46:48.945253  4581 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I0928 13:46:48.945379  4581 net.cpp:122] Setting up BatchNorm32
I0928 13:46:48.945382  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.966135  4581 net.cpp:137] Memory required for data: 899073200
I0928 13:46:48.966150  4581 layer_factory.hpp:77] Creating layer Scale32
I0928 13:46:48.966159  4581 net.cpp:84] Creating Layer Scale32
I0928 13:46:48.966164  4581 net.cpp:406] Scale32 <- Convolution32
I0928 13:46:48.966171  4581 net.cpp:367] Scale32 -> Convolution32 (in-place)
I0928 13:46:48.966214  4581 layer_factory.hpp:77] Creating layer Scale32
I0928 13:46:48.966302  4581 net.cpp:122] Setting up Scale32
I0928 13:46:48.966307  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.966310  4581 net.cpp:137] Memory required for data: 902350000
I0928 13:46:48.966313  4581 layer_factory.hpp:77] Creating layer Eltwise15
I0928 13:46:48.966318  4581 net.cpp:84] Creating Layer Eltwise15
I0928 13:46:48.966321  4581 net.cpp:406] Eltwise15 <- Eltwise14_M2PELU29_0_split_1
I0928 13:46:48.966325  4581 net.cpp:406] Eltwise15 <- Convolution32
I0928 13:46:48.966328  4581 net.cpp:380] Eltwise15 -> Eltwise15
I0928 13:46:48.966343  4581 net.cpp:122] Setting up Eltwise15
I0928 13:46:48.966347  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.966349  4581 net.cpp:137] Memory required for data: 905626800
I0928 13:46:48.966351  4581 layer_factory.hpp:77] Creating layer M2PELU31
I0928 13:46:48.966356  4581 net.cpp:84] Creating Layer M2PELU31
I0928 13:46:48.966359  4581 net.cpp:406] M2PELU31 <- Eltwise15
I0928 13:46:48.966363  4581 net.cpp:367] M2PELU31 -> Eltwise15 (in-place)
I0928 13:46:48.966457  4581 net.cpp:122] Setting up M2PELU31
I0928 13:46:48.966462  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.966464  4581 net.cpp:137] Memory required for data: 908903600
I0928 13:46:48.966469  4581 layer_factory.hpp:77] Creating layer Eltwise15_M2PELU31_0_split
I0928 13:46:48.966473  4581 net.cpp:84] Creating Layer Eltwise15_M2PELU31_0_split
I0928 13:46:48.966482  4581 net.cpp:406] Eltwise15_M2PELU31_0_split <- Eltwise15
I0928 13:46:48.966487  4581 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_0
I0928 13:46:48.966491  4581 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_1
I0928 13:46:48.966519  4581 net.cpp:122] Setting up Eltwise15_M2PELU31_0_split
I0928 13:46:48.966531  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.966533  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.966536  4581 net.cpp:137] Memory required for data: 915457200
I0928 13:46:48.966538  4581 layer_factory.hpp:77] Creating layer Convolution33
I0928 13:46:48.966544  4581 net.cpp:84] Creating Layer Convolution33
I0928 13:46:48.966547  4581 net.cpp:406] Convolution33 <- Eltwise15_M2PELU31_0_split_0
I0928 13:46:48.966553  4581 net.cpp:380] Convolution33 -> Convolution33
I0928 13:46:48.967916  4581 net.cpp:122] Setting up Convolution33
I0928 13:46:48.967924  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.967926  4581 net.cpp:137] Memory required for data: 918734000
I0928 13:46:48.967931  4581 layer_factory.hpp:77] Creating layer BatchNorm33
I0928 13:46:48.967936  4581 net.cpp:84] Creating Layer BatchNorm33
I0928 13:46:48.967939  4581 net.cpp:406] BatchNorm33 <- Convolution33
I0928 13:46:48.967943  4581 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I0928 13:46:48.968073  4581 net.cpp:122] Setting up BatchNorm33
I0928 13:46:48.968077  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.968080  4581 net.cpp:137] Memory required for data: 922010800
I0928 13:46:48.968086  4581 layer_factory.hpp:77] Creating layer Scale33
I0928 13:46:48.968089  4581 net.cpp:84] Creating Layer Scale33
I0928 13:46:48.968092  4581 net.cpp:406] Scale33 <- Convolution33
I0928 13:46:48.968096  4581 net.cpp:367] Scale33 -> Convolution33 (in-place)
I0928 13:46:48.968122  4581 layer_factory.hpp:77] Creating layer Scale33
I0928 13:46:48.968195  4581 net.cpp:122] Setting up Scale33
I0928 13:46:48.968199  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.968201  4581 net.cpp:137] Memory required for data: 925287600
I0928 13:46:48.968205  4581 layer_factory.hpp:77] Creating layer M2PELU32
I0928 13:46:48.968211  4581 net.cpp:84] Creating Layer M2PELU32
I0928 13:46:48.968214  4581 net.cpp:406] M2PELU32 <- Convolution33
I0928 13:46:48.968217  4581 net.cpp:367] M2PELU32 -> Convolution33 (in-place)
I0928 13:46:48.968298  4581 net.cpp:122] Setting up M2PELU32
I0928 13:46:48.968302  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.968304  4581 net.cpp:137] Memory required for data: 928564400
I0928 13:46:48.968308  4581 layer_factory.hpp:77] Creating layer Convolution34
I0928 13:46:48.968314  4581 net.cpp:84] Creating Layer Convolution34
I0928 13:46:48.968317  4581 net.cpp:406] Convolution34 <- Convolution33
I0928 13:46:48.968322  4581 net.cpp:380] Convolution34 -> Convolution34
I0928 13:46:48.970060  4581 net.cpp:122] Setting up Convolution34
I0928 13:46:48.970070  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.970073  4581 net.cpp:137] Memory required for data: 931841200
I0928 13:46:48.970077  4581 layer_factory.hpp:77] Creating layer BatchNorm34
I0928 13:46:48.970083  4581 net.cpp:84] Creating Layer BatchNorm34
I0928 13:46:48.970086  4581 net.cpp:406] BatchNorm34 <- Convolution34
I0928 13:46:48.970089  4581 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I0928 13:46:48.970218  4581 net.cpp:122] Setting up BatchNorm34
I0928 13:46:48.970230  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.970232  4581 net.cpp:137] Memory required for data: 935118000
I0928 13:46:48.970237  4581 layer_factory.hpp:77] Creating layer Scale34
I0928 13:46:48.970242  4581 net.cpp:84] Creating Layer Scale34
I0928 13:46:48.970244  4581 net.cpp:406] Scale34 <- Convolution34
I0928 13:46:48.970247  4581 net.cpp:367] Scale34 -> Convolution34 (in-place)
I0928 13:46:48.970275  4581 layer_factory.hpp:77] Creating layer Scale34
I0928 13:46:48.970360  4581 net.cpp:122] Setting up Scale34
I0928 13:46:48.970366  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.970367  4581 net.cpp:137] Memory required for data: 938394800
I0928 13:46:48.970371  4581 layer_factory.hpp:77] Creating layer Eltwise16
I0928 13:46:48.970376  4581 net.cpp:84] Creating Layer Eltwise16
I0928 13:46:48.970378  4581 net.cpp:406] Eltwise16 <- Eltwise15_M2PELU31_0_split_1
I0928 13:46:48.970381  4581 net.cpp:406] Eltwise16 <- Convolution34
I0928 13:46:48.970386  4581 net.cpp:380] Eltwise16 -> Eltwise16
I0928 13:46:48.970397  4581 net.cpp:122] Setting up Eltwise16
I0928 13:46:48.970402  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.970403  4581 net.cpp:137] Memory required for data: 941671600
I0928 13:46:48.970407  4581 layer_factory.hpp:77] Creating layer M2PELU33
I0928 13:46:48.970412  4581 net.cpp:84] Creating Layer M2PELU33
I0928 13:46:48.970413  4581 net.cpp:406] M2PELU33 <- Eltwise16
I0928 13:46:48.970417  4581 net.cpp:367] M2PELU33 -> Eltwise16 (in-place)
I0928 13:46:48.970504  4581 net.cpp:122] Setting up M2PELU33
I0928 13:46:48.970508  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.970510  4581 net.cpp:137] Memory required for data: 944948400
I0928 13:46:48.970515  4581 layer_factory.hpp:77] Creating layer Eltwise16_M2PELU33_0_split
I0928 13:46:48.970518  4581 net.cpp:84] Creating Layer Eltwise16_M2PELU33_0_split
I0928 13:46:48.970526  4581 net.cpp:406] Eltwise16_M2PELU33_0_split <- Eltwise16
I0928 13:46:48.970530  4581 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_0
I0928 13:46:48.970551  4581 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_1
I0928 13:46:48.970590  4581 net.cpp:122] Setting up Eltwise16_M2PELU33_0_split
I0928 13:46:48.970595  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.970597  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.970599  4581 net.cpp:137] Memory required for data: 951502000
I0928 13:46:48.970602  4581 layer_factory.hpp:77] Creating layer Convolution35
I0928 13:46:48.970608  4581 net.cpp:84] Creating Layer Convolution35
I0928 13:46:48.970612  4581 net.cpp:406] Convolution35 <- Eltwise16_M2PELU33_0_split_0
I0928 13:46:48.970615  4581 net.cpp:380] Convolution35 -> Convolution35
I0928 13:46:48.971724  4581 net.cpp:122] Setting up Convolution35
I0928 13:46:48.971734  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.971735  4581 net.cpp:137] Memory required for data: 954778800
I0928 13:46:48.971740  4581 layer_factory.hpp:77] Creating layer BatchNorm35
I0928 13:46:48.971745  4581 net.cpp:84] Creating Layer BatchNorm35
I0928 13:46:48.971748  4581 net.cpp:406] BatchNorm35 <- Convolution35
I0928 13:46:48.971751  4581 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I0928 13:46:48.971881  4581 net.cpp:122] Setting up BatchNorm35
I0928 13:46:48.971885  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.971889  4581 net.cpp:137] Memory required for data: 958055600
I0928 13:46:48.971892  4581 layer_factory.hpp:77] Creating layer Scale35
I0928 13:46:48.971896  4581 net.cpp:84] Creating Layer Scale35
I0928 13:46:48.971899  4581 net.cpp:406] Scale35 <- Convolution35
I0928 13:46:48.971902  4581 net.cpp:367] Scale35 -> Convolution35 (in-place)
I0928 13:46:48.971928  4581 layer_factory.hpp:77] Creating layer Scale35
I0928 13:46:48.972002  4581 net.cpp:122] Setting up Scale35
I0928 13:46:48.972007  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.972008  4581 net.cpp:137] Memory required for data: 961332400
I0928 13:46:48.972012  4581 layer_factory.hpp:77] Creating layer M2PELU34
I0928 13:46:48.972017  4581 net.cpp:84] Creating Layer M2PELU34
I0928 13:46:48.972019  4581 net.cpp:406] M2PELU34 <- Convolution35
I0928 13:46:48.972023  4581 net.cpp:367] M2PELU34 -> Convolution35 (in-place)
I0928 13:46:48.972102  4581 net.cpp:122] Setting up M2PELU34
I0928 13:46:48.972107  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.972110  4581 net.cpp:137] Memory required for data: 964609200
I0928 13:46:48.972120  4581 layer_factory.hpp:77] Creating layer Convolution36
I0928 13:46:48.972126  4581 net.cpp:84] Creating Layer Convolution36
I0928 13:46:48.972129  4581 net.cpp:406] Convolution36 <- Convolution35
I0928 13:46:48.972133  4581 net.cpp:380] Convolution36 -> Convolution36
I0928 13:46:48.972908  4581 net.cpp:122] Setting up Convolution36
I0928 13:46:48.972915  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.972918  4581 net.cpp:137] Memory required for data: 967886000
I0928 13:46:48.972923  4581 layer_factory.hpp:77] Creating layer BatchNorm36
I0928 13:46:48.972928  4581 net.cpp:84] Creating Layer BatchNorm36
I0928 13:46:48.972930  4581 net.cpp:406] BatchNorm36 <- Convolution36
I0928 13:46:48.972934  4581 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I0928 13:46:48.973064  4581 net.cpp:122] Setting up BatchNorm36
I0928 13:46:48.973068  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.973070  4581 net.cpp:137] Memory required for data: 971162800
I0928 13:46:48.973075  4581 layer_factory.hpp:77] Creating layer Scale36
I0928 13:46:48.973080  4581 net.cpp:84] Creating Layer Scale36
I0928 13:46:48.973083  4581 net.cpp:406] Scale36 <- Convolution36
I0928 13:46:48.973085  4581 net.cpp:367] Scale36 -> Convolution36 (in-place)
I0928 13:46:48.973112  4581 layer_factory.hpp:77] Creating layer Scale36
I0928 13:46:48.973188  4581 net.cpp:122] Setting up Scale36
I0928 13:46:48.973192  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.973194  4581 net.cpp:137] Memory required for data: 974439600
I0928 13:46:48.973198  4581 layer_factory.hpp:77] Creating layer Eltwise17
I0928 13:46:48.973202  4581 net.cpp:84] Creating Layer Eltwise17
I0928 13:46:48.973206  4581 net.cpp:406] Eltwise17 <- Eltwise16_M2PELU33_0_split_1
I0928 13:46:48.973208  4581 net.cpp:406] Eltwise17 <- Convolution36
I0928 13:46:48.973212  4581 net.cpp:380] Eltwise17 -> Eltwise17
I0928 13:46:48.973224  4581 net.cpp:122] Setting up Eltwise17
I0928 13:46:48.973237  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.973238  4581 net.cpp:137] Memory required for data: 977716400
I0928 13:46:48.973240  4581 layer_factory.hpp:77] Creating layer M2PELU35
I0928 13:46:48.973244  4581 net.cpp:84] Creating Layer M2PELU35
I0928 13:46:48.973248  4581 net.cpp:406] M2PELU35 <- Eltwise17
I0928 13:46:48.973253  4581 net.cpp:367] M2PELU35 -> Eltwise17 (in-place)
I0928 13:46:48.973336  4581 net.cpp:122] Setting up M2PELU35
I0928 13:46:48.973340  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.973342  4581 net.cpp:137] Memory required for data: 980993200
I0928 13:46:48.973346  4581 layer_factory.hpp:77] Creating layer Eltwise17_M2PELU35_0_split
I0928 13:46:48.973351  4581 net.cpp:84] Creating Layer Eltwise17_M2PELU35_0_split
I0928 13:46:48.973352  4581 net.cpp:406] Eltwise17_M2PELU35_0_split <- Eltwise17
I0928 13:46:48.973356  4581 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_0
I0928 13:46:48.973361  4581 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_1
I0928 13:46:48.973383  4581 net.cpp:122] Setting up Eltwise17_M2PELU35_0_split
I0928 13:46:48.973387  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.973390  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.973392  4581 net.cpp:137] Memory required for data: 987546800
I0928 13:46:48.973394  4581 layer_factory.hpp:77] Creating layer Convolution37
I0928 13:46:48.973399  4581 net.cpp:84] Creating Layer Convolution37
I0928 13:46:48.973402  4581 net.cpp:406] Convolution37 <- Eltwise17_M2PELU35_0_split_0
I0928 13:46:48.973407  4581 net.cpp:380] Convolution37 -> Convolution37
I0928 13:46:48.974531  4581 net.cpp:122] Setting up Convolution37
I0928 13:46:48.974541  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.974545  4581 net.cpp:137] Memory required for data: 990823600
I0928 13:46:48.974550  4581 layer_factory.hpp:77] Creating layer BatchNorm37
I0928 13:46:48.974555  4581 net.cpp:84] Creating Layer BatchNorm37
I0928 13:46:48.974565  4581 net.cpp:406] BatchNorm37 <- Convolution37
I0928 13:46:48.974570  4581 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I0928 13:46:48.974712  4581 net.cpp:122] Setting up BatchNorm37
I0928 13:46:48.974717  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.974720  4581 net.cpp:137] Memory required for data: 994100400
I0928 13:46:48.974725  4581 layer_factory.hpp:77] Creating layer Scale37
I0928 13:46:48.974730  4581 net.cpp:84] Creating Layer Scale37
I0928 13:46:48.974733  4581 net.cpp:406] Scale37 <- Convolution37
I0928 13:46:48.974736  4581 net.cpp:367] Scale37 -> Convolution37 (in-place)
I0928 13:46:48.974766  4581 layer_factory.hpp:77] Creating layer Scale37
I0928 13:46:48.974848  4581 net.cpp:122] Setting up Scale37
I0928 13:46:48.974853  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.974854  4581 net.cpp:137] Memory required for data: 997377200
I0928 13:46:48.974858  4581 layer_factory.hpp:77] Creating layer M2PELU36
I0928 13:46:48.974864  4581 net.cpp:84] Creating Layer M2PELU36
I0928 13:46:48.974866  4581 net.cpp:406] M2PELU36 <- Convolution37
I0928 13:46:48.974870  4581 net.cpp:367] M2PELU36 -> Convolution37 (in-place)
I0928 13:46:48.974959  4581 net.cpp:122] Setting up M2PELU36
I0928 13:46:48.974964  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.974967  4581 net.cpp:137] Memory required for data: 1000654000
I0928 13:46:48.974970  4581 layer_factory.hpp:77] Creating layer Convolution38
I0928 13:46:48.974977  4581 net.cpp:84] Creating Layer Convolution38
I0928 13:46:48.974980  4581 net.cpp:406] Convolution38 <- Convolution37
I0928 13:46:48.974984  4581 net.cpp:380] Convolution38 -> Convolution38
I0928 13:46:48.976446  4581 net.cpp:122] Setting up Convolution38
I0928 13:46:48.976454  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.976457  4581 net.cpp:137] Memory required for data: 1003930800
I0928 13:46:48.976461  4581 layer_factory.hpp:77] Creating layer BatchNorm38
I0928 13:46:48.976466  4581 net.cpp:84] Creating Layer BatchNorm38
I0928 13:46:48.976469  4581 net.cpp:406] BatchNorm38 <- Convolution38
I0928 13:46:48.996793  4581 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I0928 13:46:48.996965  4581 net.cpp:122] Setting up BatchNorm38
I0928 13:46:48.996973  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.996974  4581 net.cpp:137] Memory required for data: 1007207600
I0928 13:46:48.996980  4581 layer_factory.hpp:77] Creating layer Scale38
I0928 13:46:48.996985  4581 net.cpp:84] Creating Layer Scale38
I0928 13:46:48.996989  4581 net.cpp:406] Scale38 <- Convolution38
I0928 13:46:48.996992  4581 net.cpp:367] Scale38 -> Convolution38 (in-place)
I0928 13:46:48.997023  4581 layer_factory.hpp:77] Creating layer Scale38
I0928 13:46:48.997107  4581 net.cpp:122] Setting up Scale38
I0928 13:46:48.997112  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.997113  4581 net.cpp:137] Memory required for data: 1010484400
I0928 13:46:48.997118  4581 layer_factory.hpp:77] Creating layer Eltwise18
I0928 13:46:48.997123  4581 net.cpp:84] Creating Layer Eltwise18
I0928 13:46:48.997126  4581 net.cpp:406] Eltwise18 <- Eltwise17_M2PELU35_0_split_1
I0928 13:46:48.997129  4581 net.cpp:406] Eltwise18 <- Convolution38
I0928 13:46:48.997133  4581 net.cpp:380] Eltwise18 -> Eltwise18
I0928 13:46:48.997146  4581 net.cpp:122] Setting up Eltwise18
I0928 13:46:48.997150  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.997153  4581 net.cpp:137] Memory required for data: 1013761200
I0928 13:46:48.997154  4581 layer_factory.hpp:77] Creating layer M2PELU37
I0928 13:46:48.997160  4581 net.cpp:84] Creating Layer M2PELU37
I0928 13:46:48.997162  4581 net.cpp:406] M2PELU37 <- Eltwise18
I0928 13:46:48.997167  4581 net.cpp:367] M2PELU37 -> Eltwise18 (in-place)
I0928 13:46:48.997262  4581 net.cpp:122] Setting up M2PELU37
I0928 13:46:48.997267  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.997269  4581 net.cpp:137] Memory required for data: 1017038000
I0928 13:46:48.997274  4581 layer_factory.hpp:77] Creating layer Eltwise18_M2PELU37_0_split
I0928 13:46:48.997285  4581 net.cpp:84] Creating Layer Eltwise18_M2PELU37_0_split
I0928 13:46:48.997288  4581 net.cpp:406] Eltwise18_M2PELU37_0_split <- Eltwise18
I0928 13:46:48.997292  4581 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_0
I0928 13:46:48.997297  4581 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_1
I0928 13:46:48.997324  4581 net.cpp:122] Setting up Eltwise18_M2PELU37_0_split
I0928 13:46:48.997328  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.997331  4581 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 13:46:48.997334  4581 net.cpp:137] Memory required for data: 1023591600
I0928 13:46:48.997336  4581 layer_factory.hpp:77] Creating layer Convolution39
I0928 13:46:48.997344  4581 net.cpp:84] Creating Layer Convolution39
I0928 13:46:48.997346  4581 net.cpp:406] Convolution39 <- Eltwise18_M2PELU37_0_split_0
I0928 13:46:48.997350  4581 net.cpp:380] Convolution39 -> Convolution39
I0928 13:46:48.998591  4581 net.cpp:122] Setting up Convolution39
I0928 13:46:48.998601  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:48.998605  4581 net.cpp:137] Memory required for data: 1025230000
I0928 13:46:48.998610  4581 layer_factory.hpp:77] Creating layer BatchNorm39
I0928 13:46:48.998615  4581 net.cpp:84] Creating Layer BatchNorm39
I0928 13:46:48.998618  4581 net.cpp:406] BatchNorm39 <- Convolution39
I0928 13:46:48.998623  4581 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I0928 13:46:48.998759  4581 net.cpp:122] Setting up BatchNorm39
I0928 13:46:48.998762  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:48.998764  4581 net.cpp:137] Memory required for data: 1026868400
I0928 13:46:48.998769  4581 layer_factory.hpp:77] Creating layer Scale39
I0928 13:46:48.998775  4581 net.cpp:84] Creating Layer Scale39
I0928 13:46:48.998777  4581 net.cpp:406] Scale39 <- Convolution39
I0928 13:46:48.998780  4581 net.cpp:367] Scale39 -> Convolution39 (in-place)
I0928 13:46:48.998807  4581 layer_factory.hpp:77] Creating layer Scale39
I0928 13:46:48.998884  4581 net.cpp:122] Setting up Scale39
I0928 13:46:48.998888  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:48.998891  4581 net.cpp:137] Memory required for data: 1028506800
I0928 13:46:48.998894  4581 layer_factory.hpp:77] Creating layer Convolution40
I0928 13:46:48.998903  4581 net.cpp:84] Creating Layer Convolution40
I0928 13:46:48.998905  4581 net.cpp:406] Convolution40 <- Eltwise18_M2PELU37_0_split_1
I0928 13:46:48.998909  4581 net.cpp:380] Convolution40 -> Convolution40
I0928 13:46:49.000288  4581 net.cpp:122] Setting up Convolution40
I0928 13:46:49.000298  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.000299  4581 net.cpp:137] Memory required for data: 1030145200
I0928 13:46:49.000304  4581 layer_factory.hpp:77] Creating layer BatchNorm40
I0928 13:46:49.000311  4581 net.cpp:84] Creating Layer BatchNorm40
I0928 13:46:49.000315  4581 net.cpp:406] BatchNorm40 <- Convolution40
I0928 13:46:49.000319  4581 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I0928 13:46:49.000453  4581 net.cpp:122] Setting up BatchNorm40
I0928 13:46:49.000458  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.000460  4581 net.cpp:137] Memory required for data: 1031783600
I0928 13:46:49.000465  4581 layer_factory.hpp:77] Creating layer Scale40
I0928 13:46:49.000469  4581 net.cpp:84] Creating Layer Scale40
I0928 13:46:49.000473  4581 net.cpp:406] Scale40 <- Convolution40
I0928 13:46:49.000475  4581 net.cpp:367] Scale40 -> Convolution40 (in-place)
I0928 13:46:49.000502  4581 layer_factory.hpp:77] Creating layer Scale40
I0928 13:46:49.000581  4581 net.cpp:122] Setting up Scale40
I0928 13:46:49.000586  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.000587  4581 net.cpp:137] Memory required for data: 1033422000
I0928 13:46:49.000591  4581 layer_factory.hpp:77] Creating layer M2PELU38
I0928 13:46:49.000597  4581 net.cpp:84] Creating Layer M2PELU38
I0928 13:46:49.000598  4581 net.cpp:406] M2PELU38 <- Convolution40
I0928 13:46:49.000609  4581 net.cpp:367] M2PELU38 -> Convolution40 (in-place)
I0928 13:46:49.000704  4581 net.cpp:122] Setting up M2PELU38
I0928 13:46:49.000708  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.000710  4581 net.cpp:137] Memory required for data: 1035060400
I0928 13:46:49.000715  4581 layer_factory.hpp:77] Creating layer Convolution41
I0928 13:46:49.000721  4581 net.cpp:84] Creating Layer Convolution41
I0928 13:46:49.000725  4581 net.cpp:406] Convolution41 <- Convolution40
I0928 13:46:49.000728  4581 net.cpp:380] Convolution41 -> Convolution41
I0928 13:46:49.002466  4581 net.cpp:122] Setting up Convolution41
I0928 13:46:49.002475  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.002478  4581 net.cpp:137] Memory required for data: 1036698800
I0928 13:46:49.002482  4581 layer_factory.hpp:77] Creating layer BatchNorm41
I0928 13:46:49.002487  4581 net.cpp:84] Creating Layer BatchNorm41
I0928 13:46:49.002490  4581 net.cpp:406] BatchNorm41 <- Convolution41
I0928 13:46:49.002495  4581 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I0928 13:46:49.002635  4581 net.cpp:122] Setting up BatchNorm41
I0928 13:46:49.002640  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.002642  4581 net.cpp:137] Memory required for data: 1038337200
I0928 13:46:49.002646  4581 layer_factory.hpp:77] Creating layer Scale41
I0928 13:46:49.002650  4581 net.cpp:84] Creating Layer Scale41
I0928 13:46:49.002653  4581 net.cpp:406] Scale41 <- Convolution41
I0928 13:46:49.002657  4581 net.cpp:367] Scale41 -> Convolution41 (in-place)
I0928 13:46:49.002686  4581 layer_factory.hpp:77] Creating layer Scale41
I0928 13:46:49.002763  4581 net.cpp:122] Setting up Scale41
I0928 13:46:49.002766  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.002768  4581 net.cpp:137] Memory required for data: 1039975600
I0928 13:46:49.002773  4581 layer_factory.hpp:77] Creating layer Eltwise19
I0928 13:46:49.002776  4581 net.cpp:84] Creating Layer Eltwise19
I0928 13:46:49.002779  4581 net.cpp:406] Eltwise19 <- Convolution39
I0928 13:46:49.002782  4581 net.cpp:406] Eltwise19 <- Convolution41
I0928 13:46:49.002787  4581 net.cpp:380] Eltwise19 -> Eltwise19
I0928 13:46:49.002804  4581 net.cpp:122] Setting up Eltwise19
I0928 13:46:49.002809  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.002810  4581 net.cpp:137] Memory required for data: 1041614000
I0928 13:46:49.002812  4581 layer_factory.hpp:77] Creating layer M2PELU39
I0928 13:46:49.002816  4581 net.cpp:84] Creating Layer M2PELU39
I0928 13:46:49.002820  4581 net.cpp:406] M2PELU39 <- Eltwise19
I0928 13:46:49.002823  4581 net.cpp:367] M2PELU39 -> Eltwise19 (in-place)
I0928 13:46:49.002914  4581 net.cpp:122] Setting up M2PELU39
I0928 13:46:49.002918  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.002920  4581 net.cpp:137] Memory required for data: 1043252400
I0928 13:46:49.002924  4581 layer_factory.hpp:77] Creating layer Eltwise19_M2PELU39_0_split
I0928 13:46:49.002928  4581 net.cpp:84] Creating Layer Eltwise19_M2PELU39_0_split
I0928 13:46:49.002930  4581 net.cpp:406] Eltwise19_M2PELU39_0_split <- Eltwise19
I0928 13:46:49.002934  4581 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_0
I0928 13:46:49.002938  4581 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_1
I0928 13:46:49.002962  4581 net.cpp:122] Setting up Eltwise19_M2PELU39_0_split
I0928 13:46:49.002965  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.002969  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.002970  4581 net.cpp:137] Memory required for data: 1046529200
I0928 13:46:49.002972  4581 layer_factory.hpp:77] Creating layer Convolution42
I0928 13:46:49.002979  4581 net.cpp:84] Creating Layer Convolution42
I0928 13:46:49.002982  4581 net.cpp:406] Convolution42 <- Eltwise19_M2PELU39_0_split_0
I0928 13:46:49.002986  4581 net.cpp:380] Convolution42 -> Convolution42
I0928 13:46:49.004715  4581 net.cpp:122] Setting up Convolution42
I0928 13:46:49.004724  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.004734  4581 net.cpp:137] Memory required for data: 1048167600
I0928 13:46:49.004739  4581 layer_factory.hpp:77] Creating layer BatchNorm42
I0928 13:46:49.004743  4581 net.cpp:84] Creating Layer BatchNorm42
I0928 13:46:49.004746  4581 net.cpp:406] BatchNorm42 <- Convolution42
I0928 13:46:49.004751  4581 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I0928 13:46:49.004884  4581 net.cpp:122] Setting up BatchNorm42
I0928 13:46:49.004889  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.004891  4581 net.cpp:137] Memory required for data: 1049806000
I0928 13:46:49.004896  4581 layer_factory.hpp:77] Creating layer Scale42
I0928 13:46:49.004900  4581 net.cpp:84] Creating Layer Scale42
I0928 13:46:49.004904  4581 net.cpp:406] Scale42 <- Convolution42
I0928 13:46:49.004906  4581 net.cpp:367] Scale42 -> Convolution42 (in-place)
I0928 13:46:49.004933  4581 layer_factory.hpp:77] Creating layer Scale42
I0928 13:46:49.005012  4581 net.cpp:122] Setting up Scale42
I0928 13:46:49.005015  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.005017  4581 net.cpp:137] Memory required for data: 1051444400
I0928 13:46:49.005022  4581 layer_factory.hpp:77] Creating layer M2PELU40
I0928 13:46:49.005026  4581 net.cpp:84] Creating Layer M2PELU40
I0928 13:46:49.005029  4581 net.cpp:406] M2PELU40 <- Convolution42
I0928 13:46:49.005033  4581 net.cpp:367] M2PELU40 -> Convolution42 (in-place)
I0928 13:46:49.005120  4581 net.cpp:122] Setting up M2PELU40
I0928 13:46:49.005125  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.005127  4581 net.cpp:137] Memory required for data: 1053082800
I0928 13:46:49.005131  4581 layer_factory.hpp:77] Creating layer Convolution43
I0928 13:46:49.005137  4581 net.cpp:84] Creating Layer Convolution43
I0928 13:46:49.005141  4581 net.cpp:406] Convolution43 <- Convolution42
I0928 13:46:49.005144  4581 net.cpp:380] Convolution43 -> Convolution43
I0928 13:46:49.006860  4581 net.cpp:122] Setting up Convolution43
I0928 13:46:49.006870  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.006872  4581 net.cpp:137] Memory required for data: 1054721200
I0928 13:46:49.006877  4581 layer_factory.hpp:77] Creating layer BatchNorm43
I0928 13:46:49.006881  4581 net.cpp:84] Creating Layer BatchNorm43
I0928 13:46:49.006884  4581 net.cpp:406] BatchNorm43 <- Convolution43
I0928 13:46:49.006888  4581 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I0928 13:46:49.007027  4581 net.cpp:122] Setting up BatchNorm43
I0928 13:46:49.007032  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.007035  4581 net.cpp:137] Memory required for data: 1056359600
I0928 13:46:49.007040  4581 layer_factory.hpp:77] Creating layer Scale43
I0928 13:46:49.007043  4581 net.cpp:84] Creating Layer Scale43
I0928 13:46:49.007045  4581 net.cpp:406] Scale43 <- Convolution43
I0928 13:46:49.007050  4581 net.cpp:367] Scale43 -> Convolution43 (in-place)
I0928 13:46:49.007077  4581 layer_factory.hpp:77] Creating layer Scale43
I0928 13:46:49.007154  4581 net.cpp:122] Setting up Scale43
I0928 13:46:49.007159  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.007161  4581 net.cpp:137] Memory required for data: 1057998000
I0928 13:46:49.007165  4581 layer_factory.hpp:77] Creating layer Eltwise20
I0928 13:46:49.007169  4581 net.cpp:84] Creating Layer Eltwise20
I0928 13:46:49.007171  4581 net.cpp:406] Eltwise20 <- Eltwise19_M2PELU39_0_split_1
I0928 13:46:49.007174  4581 net.cpp:406] Eltwise20 <- Convolution43
I0928 13:46:49.007179  4581 net.cpp:380] Eltwise20 -> Eltwise20
I0928 13:46:49.007194  4581 net.cpp:122] Setting up Eltwise20
I0928 13:46:49.007200  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.007201  4581 net.cpp:137] Memory required for data: 1059636400
I0928 13:46:49.007203  4581 layer_factory.hpp:77] Creating layer M2PELU41
I0928 13:46:49.007208  4581 net.cpp:84] Creating Layer M2PELU41
I0928 13:46:49.007210  4581 net.cpp:406] M2PELU41 <- Eltwise20
I0928 13:46:49.007215  4581 net.cpp:367] M2PELU41 -> Eltwise20 (in-place)
I0928 13:46:49.007313  4581 net.cpp:122] Setting up M2PELU41
I0928 13:46:49.007318  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.007320  4581 net.cpp:137] Memory required for data: 1061274800
I0928 13:46:49.007324  4581 layer_factory.hpp:77] Creating layer Eltwise20_M2PELU41_0_split
I0928 13:46:49.007328  4581 net.cpp:84] Creating Layer Eltwise20_M2PELU41_0_split
I0928 13:46:49.007330  4581 net.cpp:406] Eltwise20_M2PELU41_0_split <- Eltwise20
I0928 13:46:49.007334  4581 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_0
I0928 13:46:49.007339  4581 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_1
I0928 13:46:49.007364  4581 net.cpp:122] Setting up Eltwise20_M2PELU41_0_split
I0928 13:46:49.007367  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.007370  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.007372  4581 net.cpp:137] Memory required for data: 1064551600
I0928 13:46:49.007375  4581 layer_factory.hpp:77] Creating layer Convolution44
I0928 13:46:49.007380  4581 net.cpp:84] Creating Layer Convolution44
I0928 13:46:49.007383  4581 net.cpp:406] Convolution44 <- Eltwise20_M2PELU41_0_split_0
I0928 13:46:49.007387  4581 net.cpp:380] Convolution44 -> Convolution44
I0928 13:46:49.009425  4581 net.cpp:122] Setting up Convolution44
I0928 13:46:49.009433  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.009436  4581 net.cpp:137] Memory required for data: 1066190000
I0928 13:46:49.009440  4581 layer_factory.hpp:77] Creating layer BatchNorm44
I0928 13:46:49.009446  4581 net.cpp:84] Creating Layer BatchNorm44
I0928 13:46:49.009449  4581 net.cpp:406] BatchNorm44 <- Convolution44
I0928 13:46:49.009452  4581 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I0928 13:46:49.009594  4581 net.cpp:122] Setting up BatchNorm44
I0928 13:46:49.009599  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.009601  4581 net.cpp:137] Memory required for data: 1067828400
I0928 13:46:49.029923  4581 layer_factory.hpp:77] Creating layer Scale44
I0928 13:46:49.029938  4581 net.cpp:84] Creating Layer Scale44
I0928 13:46:49.029944  4581 net.cpp:406] Scale44 <- Convolution44
I0928 13:46:49.029950  4581 net.cpp:367] Scale44 -> Convolution44 (in-place)
I0928 13:46:49.030004  4581 layer_factory.hpp:77] Creating layer Scale44
I0928 13:46:49.030112  4581 net.cpp:122] Setting up Scale44
I0928 13:46:49.030119  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.030122  4581 net.cpp:137] Memory required for data: 1069466800
I0928 13:46:49.030127  4581 layer_factory.hpp:77] Creating layer M2PELU42
I0928 13:46:49.030133  4581 net.cpp:84] Creating Layer M2PELU42
I0928 13:46:49.030135  4581 net.cpp:406] M2PELU42 <- Convolution44
I0928 13:46:49.030140  4581 net.cpp:367] M2PELU42 -> Convolution44 (in-place)
I0928 13:46:49.030242  4581 net.cpp:122] Setting up M2PELU42
I0928 13:46:49.030247  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.030251  4581 net.cpp:137] Memory required for data: 1071105200
I0928 13:46:49.030254  4581 layer_factory.hpp:77] Creating layer Convolution45
I0928 13:46:49.030261  4581 net.cpp:84] Creating Layer Convolution45
I0928 13:46:49.030264  4581 net.cpp:406] Convolution45 <- Convolution44
I0928 13:46:49.030269  4581 net.cpp:380] Convolution45 -> Convolution45
I0928 13:46:49.032151  4581 net.cpp:122] Setting up Convolution45
I0928 13:46:49.032160  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.032163  4581 net.cpp:137] Memory required for data: 1072743600
I0928 13:46:49.032168  4581 layer_factory.hpp:77] Creating layer BatchNorm45
I0928 13:46:49.032173  4581 net.cpp:84] Creating Layer BatchNorm45
I0928 13:46:49.032176  4581 net.cpp:406] BatchNorm45 <- Convolution45
I0928 13:46:49.032179  4581 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I0928 13:46:49.032313  4581 net.cpp:122] Setting up BatchNorm45
I0928 13:46:49.032318  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.032320  4581 net.cpp:137] Memory required for data: 1074382000
I0928 13:46:49.032325  4581 layer_factory.hpp:77] Creating layer Scale45
I0928 13:46:49.032335  4581 net.cpp:84] Creating Layer Scale45
I0928 13:46:49.032340  4581 net.cpp:406] Scale45 <- Convolution45
I0928 13:46:49.032342  4581 net.cpp:367] Scale45 -> Convolution45 (in-place)
I0928 13:46:49.032371  4581 layer_factory.hpp:77] Creating layer Scale45
I0928 13:46:49.032449  4581 net.cpp:122] Setting up Scale45
I0928 13:46:49.032452  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.032454  4581 net.cpp:137] Memory required for data: 1076020400
I0928 13:46:49.032459  4581 layer_factory.hpp:77] Creating layer Eltwise21
I0928 13:46:49.032462  4581 net.cpp:84] Creating Layer Eltwise21
I0928 13:46:49.032466  4581 net.cpp:406] Eltwise21 <- Eltwise20_M2PELU41_0_split_1
I0928 13:46:49.032469  4581 net.cpp:406] Eltwise21 <- Convolution45
I0928 13:46:49.032472  4581 net.cpp:380] Eltwise21 -> Eltwise21
I0928 13:46:49.032488  4581 net.cpp:122] Setting up Eltwise21
I0928 13:46:49.032491  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.032493  4581 net.cpp:137] Memory required for data: 1077658800
I0928 13:46:49.032495  4581 layer_factory.hpp:77] Creating layer M2PELU43
I0928 13:46:49.032500  4581 net.cpp:84] Creating Layer M2PELU43
I0928 13:46:49.032503  4581 net.cpp:406] M2PELU43 <- Eltwise21
I0928 13:46:49.032506  4581 net.cpp:367] M2PELU43 -> Eltwise21 (in-place)
I0928 13:46:49.032594  4581 net.cpp:122] Setting up M2PELU43
I0928 13:46:49.032598  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.032600  4581 net.cpp:137] Memory required for data: 1079297200
I0928 13:46:49.032604  4581 layer_factory.hpp:77] Creating layer Eltwise21_M2PELU43_0_split
I0928 13:46:49.032609  4581 net.cpp:84] Creating Layer Eltwise21_M2PELU43_0_split
I0928 13:46:49.032611  4581 net.cpp:406] Eltwise21_M2PELU43_0_split <- Eltwise21
I0928 13:46:49.032615  4581 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_0
I0928 13:46:49.032619  4581 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_1
I0928 13:46:49.032644  4581 net.cpp:122] Setting up Eltwise21_M2PELU43_0_split
I0928 13:46:49.032647  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.032649  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.032651  4581 net.cpp:137] Memory required for data: 1082574000
I0928 13:46:49.032654  4581 layer_factory.hpp:77] Creating layer Convolution46
I0928 13:46:49.032660  4581 net.cpp:84] Creating Layer Convolution46
I0928 13:46:49.032662  4581 net.cpp:406] Convolution46 <- Eltwise21_M2PELU43_0_split_0
I0928 13:46:49.032666  4581 net.cpp:380] Convolution46 -> Convolution46
I0928 13:46:49.034345  4581 net.cpp:122] Setting up Convolution46
I0928 13:46:49.034353  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.034356  4581 net.cpp:137] Memory required for data: 1084212400
I0928 13:46:49.034360  4581 layer_factory.hpp:77] Creating layer BatchNorm46
I0928 13:46:49.034366  4581 net.cpp:84] Creating Layer BatchNorm46
I0928 13:46:49.034368  4581 net.cpp:406] BatchNorm46 <- Convolution46
I0928 13:46:49.034373  4581 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I0928 13:46:49.034509  4581 net.cpp:122] Setting up BatchNorm46
I0928 13:46:49.034514  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.034517  4581 net.cpp:137] Memory required for data: 1085850800
I0928 13:46:49.034534  4581 layer_factory.hpp:77] Creating layer Scale46
I0928 13:46:49.034540  4581 net.cpp:84] Creating Layer Scale46
I0928 13:46:49.034543  4581 net.cpp:406] Scale46 <- Convolution46
I0928 13:46:49.034546  4581 net.cpp:367] Scale46 -> Convolution46 (in-place)
I0928 13:46:49.034584  4581 layer_factory.hpp:77] Creating layer Scale46
I0928 13:46:49.034662  4581 net.cpp:122] Setting up Scale46
I0928 13:46:49.034665  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.034668  4581 net.cpp:137] Memory required for data: 1087489200
I0928 13:46:49.034672  4581 layer_factory.hpp:77] Creating layer M2PELU44
I0928 13:46:49.034677  4581 net.cpp:84] Creating Layer M2PELU44
I0928 13:46:49.034679  4581 net.cpp:406] M2PELU44 <- Convolution46
I0928 13:46:49.034689  4581 net.cpp:367] M2PELU44 -> Convolution46 (in-place)
I0928 13:46:49.034777  4581 net.cpp:122] Setting up M2PELU44
I0928 13:46:49.034782  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.034785  4581 net.cpp:137] Memory required for data: 1089127600
I0928 13:46:49.034787  4581 layer_factory.hpp:77] Creating layer Convolution47
I0928 13:46:49.034795  4581 net.cpp:84] Creating Layer Convolution47
I0928 13:46:49.034797  4581 net.cpp:406] Convolution47 <- Convolution46
I0928 13:46:49.034802  4581 net.cpp:380] Convolution47 -> Convolution47
I0928 13:46:49.036525  4581 net.cpp:122] Setting up Convolution47
I0928 13:46:49.036533  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.036536  4581 net.cpp:137] Memory required for data: 1090766000
I0928 13:46:49.036540  4581 layer_factory.hpp:77] Creating layer BatchNorm47
I0928 13:46:49.036545  4581 net.cpp:84] Creating Layer BatchNorm47
I0928 13:46:49.036548  4581 net.cpp:406] BatchNorm47 <- Convolution47
I0928 13:46:49.036551  4581 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I0928 13:46:49.036684  4581 net.cpp:122] Setting up BatchNorm47
I0928 13:46:49.036689  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.036690  4581 net.cpp:137] Memory required for data: 1092404400
I0928 13:46:49.036695  4581 layer_factory.hpp:77] Creating layer Scale47
I0928 13:46:49.036700  4581 net.cpp:84] Creating Layer Scale47
I0928 13:46:49.036701  4581 net.cpp:406] Scale47 <- Convolution47
I0928 13:46:49.036705  4581 net.cpp:367] Scale47 -> Convolution47 (in-place)
I0928 13:46:49.036732  4581 layer_factory.hpp:77] Creating layer Scale47
I0928 13:46:49.036808  4581 net.cpp:122] Setting up Scale47
I0928 13:46:49.036813  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.036814  4581 net.cpp:137] Memory required for data: 1094042800
I0928 13:46:49.036818  4581 layer_factory.hpp:77] Creating layer Eltwise22
I0928 13:46:49.036823  4581 net.cpp:84] Creating Layer Eltwise22
I0928 13:46:49.036824  4581 net.cpp:406] Eltwise22 <- Eltwise21_M2PELU43_0_split_1
I0928 13:46:49.036828  4581 net.cpp:406] Eltwise22 <- Convolution47
I0928 13:46:49.036831  4581 net.cpp:380] Eltwise22 -> Eltwise22
I0928 13:46:49.036847  4581 net.cpp:122] Setting up Eltwise22
I0928 13:46:49.036851  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.036854  4581 net.cpp:137] Memory required for data: 1095681200
I0928 13:46:49.036855  4581 layer_factory.hpp:77] Creating layer M2PELU45
I0928 13:46:49.036860  4581 net.cpp:84] Creating Layer M2PELU45
I0928 13:46:49.036862  4581 net.cpp:406] M2PELU45 <- Eltwise22
I0928 13:46:49.036865  4581 net.cpp:367] M2PELU45 -> Eltwise22 (in-place)
I0928 13:46:49.036954  4581 net.cpp:122] Setting up M2PELU45
I0928 13:46:49.036958  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.036960  4581 net.cpp:137] Memory required for data: 1097319600
I0928 13:46:49.036964  4581 layer_factory.hpp:77] Creating layer Eltwise22_M2PELU45_0_split
I0928 13:46:49.036967  4581 net.cpp:84] Creating Layer Eltwise22_M2PELU45_0_split
I0928 13:46:49.036970  4581 net.cpp:406] Eltwise22_M2PELU45_0_split <- Eltwise22
I0928 13:46:49.036973  4581 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_0
I0928 13:46:49.036978  4581 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_1
I0928 13:46:49.037001  4581 net.cpp:122] Setting up Eltwise22_M2PELU45_0_split
I0928 13:46:49.037005  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.037009  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.037010  4581 net.cpp:137] Memory required for data: 1100596400
I0928 13:46:49.037012  4581 layer_factory.hpp:77] Creating layer Convolution48
I0928 13:46:49.037019  4581 net.cpp:84] Creating Layer Convolution48
I0928 13:46:49.037020  4581 net.cpp:406] Convolution48 <- Eltwise22_M2PELU45_0_split_0
I0928 13:46:49.037024  4581 net.cpp:380] Convolution48 -> Convolution48
I0928 13:46:49.039165  4581 net.cpp:122] Setting up Convolution48
I0928 13:46:49.039180  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.039182  4581 net.cpp:137] Memory required for data: 1102234800
I0928 13:46:49.039187  4581 layer_factory.hpp:77] Creating layer BatchNorm48
I0928 13:46:49.039193  4581 net.cpp:84] Creating Layer BatchNorm48
I0928 13:46:49.039196  4581 net.cpp:406] BatchNorm48 <- Convolution48
I0928 13:46:49.039201  4581 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I0928 13:46:49.039343  4581 net.cpp:122] Setting up BatchNorm48
I0928 13:46:49.039347  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.039350  4581 net.cpp:137] Memory required for data: 1103873200
I0928 13:46:49.039355  4581 layer_factory.hpp:77] Creating layer Scale48
I0928 13:46:49.039358  4581 net.cpp:84] Creating Layer Scale48
I0928 13:46:49.039361  4581 net.cpp:406] Scale48 <- Convolution48
I0928 13:46:49.039364  4581 net.cpp:367] Scale48 -> Convolution48 (in-place)
I0928 13:46:49.039402  4581 layer_factory.hpp:77] Creating layer Scale48
I0928 13:46:49.039479  4581 net.cpp:122] Setting up Scale48
I0928 13:46:49.039482  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.039484  4581 net.cpp:137] Memory required for data: 1105511600
I0928 13:46:49.039489  4581 layer_factory.hpp:77] Creating layer M2PELU46
I0928 13:46:49.039494  4581 net.cpp:84] Creating Layer M2PELU46
I0928 13:46:49.039495  4581 net.cpp:406] M2PELU46 <- Convolution48
I0928 13:46:49.039499  4581 net.cpp:367] M2PELU46 -> Convolution48 (in-place)
I0928 13:46:49.039589  4581 net.cpp:122] Setting up M2PELU46
I0928 13:46:49.039593  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.039595  4581 net.cpp:137] Memory required for data: 1107150000
I0928 13:46:49.039599  4581 layer_factory.hpp:77] Creating layer Convolution49
I0928 13:46:49.039605  4581 net.cpp:84] Creating Layer Convolution49
I0928 13:46:49.039608  4581 net.cpp:406] Convolution49 <- Convolution48
I0928 13:46:49.039613  4581 net.cpp:380] Convolution49 -> Convolution49
I0928 13:46:49.041666  4581 net.cpp:122] Setting up Convolution49
I0928 13:46:49.041674  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.041677  4581 net.cpp:137] Memory required for data: 1108788400
I0928 13:46:49.041682  4581 layer_factory.hpp:77] Creating layer BatchNorm49
I0928 13:46:49.041687  4581 net.cpp:84] Creating Layer BatchNorm49
I0928 13:46:49.041690  4581 net.cpp:406] BatchNorm49 <- Convolution49
I0928 13:46:49.041694  4581 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I0928 13:46:49.041831  4581 net.cpp:122] Setting up BatchNorm49
I0928 13:46:49.041834  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.041836  4581 net.cpp:137] Memory required for data: 1110426800
I0928 13:46:49.041841  4581 layer_factory.hpp:77] Creating layer Scale49
I0928 13:46:49.041846  4581 net.cpp:84] Creating Layer Scale49
I0928 13:46:49.041848  4581 net.cpp:406] Scale49 <- Convolution49
I0928 13:46:49.041851  4581 net.cpp:367] Scale49 -> Convolution49 (in-place)
I0928 13:46:49.041878  4581 layer_factory.hpp:77] Creating layer Scale49
I0928 13:46:49.041957  4581 net.cpp:122] Setting up Scale49
I0928 13:46:49.041961  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.041963  4581 net.cpp:137] Memory required for data: 1112065200
I0928 13:46:49.041967  4581 layer_factory.hpp:77] Creating layer Eltwise23
I0928 13:46:49.041971  4581 net.cpp:84] Creating Layer Eltwise23
I0928 13:46:49.041975  4581 net.cpp:406] Eltwise23 <- Eltwise22_M2PELU45_0_split_1
I0928 13:46:49.041977  4581 net.cpp:406] Eltwise23 <- Convolution49
I0928 13:46:49.041980  4581 net.cpp:380] Eltwise23 -> Eltwise23
I0928 13:46:49.041997  4581 net.cpp:122] Setting up Eltwise23
I0928 13:46:49.042001  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.042003  4581 net.cpp:137] Memory required for data: 1113703600
I0928 13:46:49.042006  4581 layer_factory.hpp:77] Creating layer M2PELU47
I0928 13:46:49.042011  4581 net.cpp:84] Creating Layer M2PELU47
I0928 13:46:49.042012  4581 net.cpp:406] M2PELU47 <- Eltwise23
I0928 13:46:49.042016  4581 net.cpp:367] M2PELU47 -> Eltwise23 (in-place)
I0928 13:46:49.042114  4581 net.cpp:122] Setting up M2PELU47
I0928 13:46:49.042119  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.042120  4581 net.cpp:137] Memory required for data: 1115342000
I0928 13:46:49.042124  4581 layer_factory.hpp:77] Creating layer Eltwise23_M2PELU47_0_split
I0928 13:46:49.042129  4581 net.cpp:84] Creating Layer Eltwise23_M2PELU47_0_split
I0928 13:46:49.042130  4581 net.cpp:406] Eltwise23_M2PELU47_0_split <- Eltwise23
I0928 13:46:49.042134  4581 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_0
I0928 13:46:49.042138  4581 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_1
I0928 13:46:49.042162  4581 net.cpp:122] Setting up Eltwise23_M2PELU47_0_split
I0928 13:46:49.042166  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.042170  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.042171  4581 net.cpp:137] Memory required for data: 1118618800
I0928 13:46:49.042173  4581 layer_factory.hpp:77] Creating layer Convolution50
I0928 13:46:49.042179  4581 net.cpp:84] Creating Layer Convolution50
I0928 13:46:49.042182  4581 net.cpp:406] Convolution50 <- Eltwise23_M2PELU47_0_split_0
I0928 13:46:49.042186  4581 net.cpp:380] Convolution50 -> Convolution50
I0928 13:46:49.044831  4581 net.cpp:122] Setting up Convolution50
I0928 13:46:49.044840  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.044842  4581 net.cpp:137] Memory required for data: 1120257200
I0928 13:46:49.044848  4581 layer_factory.hpp:77] Creating layer BatchNorm50
I0928 13:46:49.044853  4581 net.cpp:84] Creating Layer BatchNorm50
I0928 13:46:49.044857  4581 net.cpp:406] BatchNorm50 <- Convolution50
I0928 13:46:49.044860  4581 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I0928 13:46:49.058279  4581 net.cpp:122] Setting up BatchNorm50
I0928 13:46:49.058288  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.058291  4581 net.cpp:137] Memory required for data: 1121895600
I0928 13:46:49.058297  4581 layer_factory.hpp:77] Creating layer Scale50
I0928 13:46:49.058302  4581 net.cpp:84] Creating Layer Scale50
I0928 13:46:49.058305  4581 net.cpp:406] Scale50 <- Convolution50
I0928 13:46:49.058310  4581 net.cpp:367] Scale50 -> Convolution50 (in-place)
I0928 13:46:49.058341  4581 layer_factory.hpp:77] Creating layer Scale50
I0928 13:46:49.058429  4581 net.cpp:122] Setting up Scale50
I0928 13:46:49.058434  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.058437  4581 net.cpp:137] Memory required for data: 1123534000
I0928 13:46:49.058441  4581 layer_factory.hpp:77] Creating layer M2PELU48
I0928 13:46:49.058447  4581 net.cpp:84] Creating Layer M2PELU48
I0928 13:46:49.058449  4581 net.cpp:406] M2PELU48 <- Convolution50
I0928 13:46:49.058454  4581 net.cpp:367] M2PELU48 -> Convolution50 (in-place)
I0928 13:46:49.058560  4581 net.cpp:122] Setting up M2PELU48
I0928 13:46:49.058565  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.058568  4581 net.cpp:137] Memory required for data: 1125172400
I0928 13:46:49.058573  4581 layer_factory.hpp:77] Creating layer Convolution51
I0928 13:46:49.058579  4581 net.cpp:84] Creating Layer Convolution51
I0928 13:46:49.058583  4581 net.cpp:406] Convolution51 <- Convolution50
I0928 13:46:49.058588  4581 net.cpp:380] Convolution51 -> Convolution51
I0928 13:46:49.060760  4581 net.cpp:122] Setting up Convolution51
I0928 13:46:49.060772  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.060776  4581 net.cpp:137] Memory required for data: 1126810800
I0928 13:46:49.060783  4581 layer_factory.hpp:77] Creating layer BatchNorm51
I0928 13:46:49.060789  4581 net.cpp:84] Creating Layer BatchNorm51
I0928 13:46:49.060793  4581 net.cpp:406] BatchNorm51 <- Convolution51
I0928 13:46:49.060801  4581 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I0928 13:46:49.060952  4581 net.cpp:122] Setting up BatchNorm51
I0928 13:46:49.060957  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.060959  4581 net.cpp:137] Memory required for data: 1128449200
I0928 13:46:49.060971  4581 layer_factory.hpp:77] Creating layer Scale51
I0928 13:46:49.060976  4581 net.cpp:84] Creating Layer Scale51
I0928 13:46:49.060978  4581 net.cpp:406] Scale51 <- Convolution51
I0928 13:46:49.060982  4581 net.cpp:367] Scale51 -> Convolution51 (in-place)
I0928 13:46:49.061012  4581 layer_factory.hpp:77] Creating layer Scale51
I0928 13:46:49.061091  4581 net.cpp:122] Setting up Scale51
I0928 13:46:49.061095  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.061097  4581 net.cpp:137] Memory required for data: 1130087600
I0928 13:46:49.061101  4581 layer_factory.hpp:77] Creating layer Eltwise24
I0928 13:46:49.061105  4581 net.cpp:84] Creating Layer Eltwise24
I0928 13:46:49.061108  4581 net.cpp:406] Eltwise24 <- Eltwise23_M2PELU47_0_split_1
I0928 13:46:49.061111  4581 net.cpp:406] Eltwise24 <- Convolution51
I0928 13:46:49.061115  4581 net.cpp:380] Eltwise24 -> Eltwise24
I0928 13:46:49.061132  4581 net.cpp:122] Setting up Eltwise24
I0928 13:46:49.061136  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.061138  4581 net.cpp:137] Memory required for data: 1131726000
I0928 13:46:49.061141  4581 layer_factory.hpp:77] Creating layer M2PELU49
I0928 13:46:49.061144  4581 net.cpp:84] Creating Layer M2PELU49
I0928 13:46:49.061146  4581 net.cpp:406] M2PELU49 <- Eltwise24
I0928 13:46:49.061151  4581 net.cpp:367] M2PELU49 -> Eltwise24 (in-place)
I0928 13:46:49.061264  4581 net.cpp:122] Setting up M2PELU49
I0928 13:46:49.061267  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.061269  4581 net.cpp:137] Memory required for data: 1133364400
I0928 13:46:49.061273  4581 layer_factory.hpp:77] Creating layer Eltwise24_M2PELU49_0_split
I0928 13:46:49.061276  4581 net.cpp:84] Creating Layer Eltwise24_M2PELU49_0_split
I0928 13:46:49.061280  4581 net.cpp:406] Eltwise24_M2PELU49_0_split <- Eltwise24
I0928 13:46:49.061283  4581 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_0
I0928 13:46:49.061288  4581 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_1
I0928 13:46:49.061324  4581 net.cpp:122] Setting up Eltwise24_M2PELU49_0_split
I0928 13:46:49.061328  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.061331  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.061333  4581 net.cpp:137] Memory required for data: 1136641200
I0928 13:46:49.061336  4581 layer_factory.hpp:77] Creating layer Convolution52
I0928 13:46:49.061342  4581 net.cpp:84] Creating Layer Convolution52
I0928 13:46:49.061344  4581 net.cpp:406] Convolution52 <- Eltwise24_M2PELU49_0_split_0
I0928 13:46:49.061348  4581 net.cpp:380] Convolution52 -> Convolution52
I0928 13:46:49.063477  4581 net.cpp:122] Setting up Convolution52
I0928 13:46:49.063488  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.063489  4581 net.cpp:137] Memory required for data: 1138279600
I0928 13:46:49.063494  4581 layer_factory.hpp:77] Creating layer BatchNorm52
I0928 13:46:49.063499  4581 net.cpp:84] Creating Layer BatchNorm52
I0928 13:46:49.063503  4581 net.cpp:406] BatchNorm52 <- Convolution52
I0928 13:46:49.063506  4581 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I0928 13:46:49.063657  4581 net.cpp:122] Setting up BatchNorm52
I0928 13:46:49.063660  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.063663  4581 net.cpp:137] Memory required for data: 1139918000
I0928 13:46:49.063668  4581 layer_factory.hpp:77] Creating layer Scale52
I0928 13:46:49.063671  4581 net.cpp:84] Creating Layer Scale52
I0928 13:46:49.063674  4581 net.cpp:406] Scale52 <- Convolution52
I0928 13:46:49.063678  4581 net.cpp:367] Scale52 -> Convolution52 (in-place)
I0928 13:46:49.063709  4581 layer_factory.hpp:77] Creating layer Scale52
I0928 13:46:49.063792  4581 net.cpp:122] Setting up Scale52
I0928 13:46:49.063796  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.063798  4581 net.cpp:137] Memory required for data: 1141556400
I0928 13:46:49.063802  4581 layer_factory.hpp:77] Creating layer M2PELU50
I0928 13:46:49.063823  4581 net.cpp:84] Creating Layer M2PELU50
I0928 13:46:49.063833  4581 net.cpp:406] M2PELU50 <- Convolution52
I0928 13:46:49.063838  4581 net.cpp:367] M2PELU50 -> Convolution52 (in-place)
I0928 13:46:49.063937  4581 net.cpp:122] Setting up M2PELU50
I0928 13:46:49.063942  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.063944  4581 net.cpp:137] Memory required for data: 1143194800
I0928 13:46:49.063948  4581 layer_factory.hpp:77] Creating layer Convolution53
I0928 13:46:49.063954  4581 net.cpp:84] Creating Layer Convolution53
I0928 13:46:49.063957  4581 net.cpp:406] Convolution53 <- Convolution52
I0928 13:46:49.063961  4581 net.cpp:380] Convolution53 -> Convolution53
I0928 13:46:49.065681  4581 net.cpp:122] Setting up Convolution53
I0928 13:46:49.065690  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.065692  4581 net.cpp:137] Memory required for data: 1144833200
I0928 13:46:49.065696  4581 layer_factory.hpp:77] Creating layer BatchNorm53
I0928 13:46:49.065701  4581 net.cpp:84] Creating Layer BatchNorm53
I0928 13:46:49.065704  4581 net.cpp:406] BatchNorm53 <- Convolution53
I0928 13:46:49.065708  4581 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I0928 13:46:49.065848  4581 net.cpp:122] Setting up BatchNorm53
I0928 13:46:49.065852  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.065855  4581 net.cpp:137] Memory required for data: 1146471600
I0928 13:46:49.065860  4581 layer_factory.hpp:77] Creating layer Scale53
I0928 13:46:49.065863  4581 net.cpp:84] Creating Layer Scale53
I0928 13:46:49.065865  4581 net.cpp:406] Scale53 <- Convolution53
I0928 13:46:49.065870  4581 net.cpp:367] Scale53 -> Convolution53 (in-place)
I0928 13:46:49.065896  4581 layer_factory.hpp:77] Creating layer Scale53
I0928 13:46:49.065975  4581 net.cpp:122] Setting up Scale53
I0928 13:46:49.065979  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.065981  4581 net.cpp:137] Memory required for data: 1148110000
I0928 13:46:49.065985  4581 layer_factory.hpp:77] Creating layer Eltwise25
I0928 13:46:49.065989  4581 net.cpp:84] Creating Layer Eltwise25
I0928 13:46:49.065991  4581 net.cpp:406] Eltwise25 <- Eltwise24_M2PELU49_0_split_1
I0928 13:46:49.065994  4581 net.cpp:406] Eltwise25 <- Convolution53
I0928 13:46:49.065999  4581 net.cpp:380] Eltwise25 -> Eltwise25
I0928 13:46:49.066016  4581 net.cpp:122] Setting up Eltwise25
I0928 13:46:49.066020  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.066021  4581 net.cpp:137] Memory required for data: 1149748400
I0928 13:46:49.066023  4581 layer_factory.hpp:77] Creating layer M2PELU51
I0928 13:46:49.066028  4581 net.cpp:84] Creating Layer M2PELU51
I0928 13:46:49.066030  4581 net.cpp:406] M2PELU51 <- Eltwise25
I0928 13:46:49.066035  4581 net.cpp:367] M2PELU51 -> Eltwise25 (in-place)
I0928 13:46:49.066125  4581 net.cpp:122] Setting up M2PELU51
I0928 13:46:49.066129  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.066133  4581 net.cpp:137] Memory required for data: 1151386800
I0928 13:46:49.066135  4581 layer_factory.hpp:77] Creating layer Eltwise25_M2PELU51_0_split
I0928 13:46:49.066139  4581 net.cpp:84] Creating Layer Eltwise25_M2PELU51_0_split
I0928 13:46:49.066141  4581 net.cpp:406] Eltwise25_M2PELU51_0_split <- Eltwise25
I0928 13:46:49.066145  4581 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_0
I0928 13:46:49.066149  4581 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_1
I0928 13:46:49.066174  4581 net.cpp:122] Setting up Eltwise25_M2PELU51_0_split
I0928 13:46:49.066179  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.066182  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.066184  4581 net.cpp:137] Memory required for data: 1154663600
I0928 13:46:49.066186  4581 layer_factory.hpp:77] Creating layer Convolution54
I0928 13:46:49.066192  4581 net.cpp:84] Creating Layer Convolution54
I0928 13:46:49.066195  4581 net.cpp:406] Convolution54 <- Eltwise25_M2PELU51_0_split_0
I0928 13:46:49.066198  4581 net.cpp:380] Convolution54 -> Convolution54
I0928 13:46:49.068228  4581 net.cpp:122] Setting up Convolution54
I0928 13:46:49.068243  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.068246  4581 net.cpp:137] Memory required for data: 1156302000
I0928 13:46:49.068251  4581 layer_factory.hpp:77] Creating layer BatchNorm54
I0928 13:46:49.068256  4581 net.cpp:84] Creating Layer BatchNorm54
I0928 13:46:49.068259  4581 net.cpp:406] BatchNorm54 <- Convolution54
I0928 13:46:49.068264  4581 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I0928 13:46:49.068413  4581 net.cpp:122] Setting up BatchNorm54
I0928 13:46:49.068418  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.068419  4581 net.cpp:137] Memory required for data: 1157940400
I0928 13:46:49.068424  4581 layer_factory.hpp:77] Creating layer Scale54
I0928 13:46:49.068428  4581 net.cpp:84] Creating Layer Scale54
I0928 13:46:49.068431  4581 net.cpp:406] Scale54 <- Convolution54
I0928 13:46:49.068434  4581 net.cpp:367] Scale54 -> Convolution54 (in-place)
I0928 13:46:49.068471  4581 layer_factory.hpp:77] Creating layer Scale54
I0928 13:46:49.068552  4581 net.cpp:122] Setting up Scale54
I0928 13:46:49.068557  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.068558  4581 net.cpp:137] Memory required for data: 1159578800
I0928 13:46:49.068562  4581 layer_factory.hpp:77] Creating layer M2PELU52
I0928 13:46:49.068567  4581 net.cpp:84] Creating Layer M2PELU52
I0928 13:46:49.068569  4581 net.cpp:406] M2PELU52 <- Convolution54
I0928 13:46:49.068573  4581 net.cpp:367] M2PELU52 -> Convolution54 (in-place)
I0928 13:46:49.068665  4581 net.cpp:122] Setting up M2PELU52
I0928 13:46:49.068670  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.068672  4581 net.cpp:137] Memory required for data: 1161217200
I0928 13:46:49.068676  4581 layer_factory.hpp:77] Creating layer Convolution55
I0928 13:46:49.068682  4581 net.cpp:84] Creating Layer Convolution55
I0928 13:46:49.068686  4581 net.cpp:406] Convolution55 <- Convolution54
I0928 13:46:49.068689  4581 net.cpp:380] Convolution55 -> Convolution55
I0928 13:46:49.070394  4581 net.cpp:122] Setting up Convolution55
I0928 13:46:49.070402  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.070405  4581 net.cpp:137] Memory required for data: 1162855600
I0928 13:46:49.070410  4581 layer_factory.hpp:77] Creating layer BatchNorm55
I0928 13:46:49.070415  4581 net.cpp:84] Creating Layer BatchNorm55
I0928 13:46:49.070417  4581 net.cpp:406] BatchNorm55 <- Convolution55
I0928 13:46:49.070420  4581 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I0928 13:46:49.070567  4581 net.cpp:122] Setting up BatchNorm55
I0928 13:46:49.070572  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.070575  4581 net.cpp:137] Memory required for data: 1164494000
I0928 13:46:49.070580  4581 layer_factory.hpp:77] Creating layer Scale55
I0928 13:46:49.070583  4581 net.cpp:84] Creating Layer Scale55
I0928 13:46:49.070586  4581 net.cpp:406] Scale55 <- Convolution55
I0928 13:46:49.070590  4581 net.cpp:367] Scale55 -> Convolution55 (in-place)
I0928 13:46:49.070618  4581 layer_factory.hpp:77] Creating layer Scale55
I0928 13:46:49.070700  4581 net.cpp:122] Setting up Scale55
I0928 13:46:49.070706  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.070708  4581 net.cpp:137] Memory required for data: 1166132400
I0928 13:46:49.070711  4581 layer_factory.hpp:77] Creating layer Eltwise26
I0928 13:46:49.070715  4581 net.cpp:84] Creating Layer Eltwise26
I0928 13:46:49.070719  4581 net.cpp:406] Eltwise26 <- Eltwise25_M2PELU51_0_split_1
I0928 13:46:49.070721  4581 net.cpp:406] Eltwise26 <- Convolution55
I0928 13:46:49.070724  4581 net.cpp:380] Eltwise26 -> Eltwise26
I0928 13:46:49.070741  4581 net.cpp:122] Setting up Eltwise26
I0928 13:46:49.070745  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.070747  4581 net.cpp:137] Memory required for data: 1167770800
I0928 13:46:49.070749  4581 layer_factory.hpp:77] Creating layer M2PELU53
I0928 13:46:49.070755  4581 net.cpp:84] Creating Layer M2PELU53
I0928 13:46:49.070756  4581 net.cpp:406] M2PELU53 <- Eltwise26
I0928 13:46:49.070766  4581 net.cpp:367] M2PELU53 -> Eltwise26 (in-place)
I0928 13:46:49.070863  4581 net.cpp:122] Setting up M2PELU53
I0928 13:46:49.070866  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.070868  4581 net.cpp:137] Memory required for data: 1169409200
I0928 13:46:49.070873  4581 layer_factory.hpp:77] Creating layer Eltwise26_M2PELU53_0_split
I0928 13:46:49.070876  4581 net.cpp:84] Creating Layer Eltwise26_M2PELU53_0_split
I0928 13:46:49.070878  4581 net.cpp:406] Eltwise26_M2PELU53_0_split <- Eltwise26
I0928 13:46:49.070881  4581 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_0
I0928 13:46:49.070885  4581 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_1
I0928 13:46:49.070911  4581 net.cpp:122] Setting up Eltwise26_M2PELU53_0_split
I0928 13:46:49.070914  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.070917  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.070919  4581 net.cpp:137] Memory required for data: 1172686000
I0928 13:46:49.070921  4581 layer_factory.hpp:77] Creating layer Convolution56
I0928 13:46:49.070927  4581 net.cpp:84] Creating Layer Convolution56
I0928 13:46:49.070930  4581 net.cpp:406] Convolution56 <- Eltwise26_M2PELU53_0_split_0
I0928 13:46:49.070933  4581 net.cpp:380] Convolution56 -> Convolution56
I0928 13:46:49.072614  4581 net.cpp:122] Setting up Convolution56
I0928 13:46:49.072623  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.072625  4581 net.cpp:137] Memory required for data: 1174324400
I0928 13:46:49.072629  4581 layer_factory.hpp:77] Creating layer BatchNorm56
I0928 13:46:49.091548  4581 net.cpp:84] Creating Layer BatchNorm56
I0928 13:46:49.091558  4581 net.cpp:406] BatchNorm56 <- Convolution56
I0928 13:46:49.091567  4581 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I0928 13:46:49.091776  4581 net.cpp:122] Setting up BatchNorm56
I0928 13:46:49.091784  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.091786  4581 net.cpp:137] Memory required for data: 1175962800
I0928 13:46:49.091792  4581 layer_factory.hpp:77] Creating layer Scale56
I0928 13:46:49.091797  4581 net.cpp:84] Creating Layer Scale56
I0928 13:46:49.091800  4581 net.cpp:406] Scale56 <- Convolution56
I0928 13:46:49.091804  4581 net.cpp:367] Scale56 -> Convolution56 (in-place)
I0928 13:46:49.091837  4581 layer_factory.hpp:77] Creating layer Scale56
I0928 13:46:49.091928  4581 net.cpp:122] Setting up Scale56
I0928 13:46:49.091933  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.091936  4581 net.cpp:137] Memory required for data: 1177601200
I0928 13:46:49.091940  4581 layer_factory.hpp:77] Creating layer M2PELU54
I0928 13:46:49.091945  4581 net.cpp:84] Creating Layer M2PELU54
I0928 13:46:49.091948  4581 net.cpp:406] M2PELU54 <- Convolution56
I0928 13:46:49.091953  4581 net.cpp:367] M2PELU54 -> Convolution56 (in-place)
I0928 13:46:49.092056  4581 net.cpp:122] Setting up M2PELU54
I0928 13:46:49.092061  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.092063  4581 net.cpp:137] Memory required for data: 1179239600
I0928 13:46:49.092067  4581 layer_factory.hpp:77] Creating layer Convolution57
I0928 13:46:49.092074  4581 net.cpp:84] Creating Layer Convolution57
I0928 13:46:49.092077  4581 net.cpp:406] Convolution57 <- Convolution56
I0928 13:46:49.092082  4581 net.cpp:380] Convolution57 -> Convolution57
I0928 13:46:49.093945  4581 net.cpp:122] Setting up Convolution57
I0928 13:46:49.093953  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.093955  4581 net.cpp:137] Memory required for data: 1180878000
I0928 13:46:49.093961  4581 layer_factory.hpp:77] Creating layer BatchNorm57
I0928 13:46:49.093966  4581 net.cpp:84] Creating Layer BatchNorm57
I0928 13:46:49.093968  4581 net.cpp:406] BatchNorm57 <- Convolution57
I0928 13:46:49.093973  4581 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I0928 13:46:49.094116  4581 net.cpp:122] Setting up BatchNorm57
I0928 13:46:49.094121  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.094130  4581 net.cpp:137] Memory required for data: 1182516400
I0928 13:46:49.094135  4581 layer_factory.hpp:77] Creating layer Scale57
I0928 13:46:49.094139  4581 net.cpp:84] Creating Layer Scale57
I0928 13:46:49.094142  4581 net.cpp:406] Scale57 <- Convolution57
I0928 13:46:49.094146  4581 net.cpp:367] Scale57 -> Convolution57 (in-place)
I0928 13:46:49.094174  4581 layer_factory.hpp:77] Creating layer Scale57
I0928 13:46:49.094255  4581 net.cpp:122] Setting up Scale57
I0928 13:46:49.094259  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.094261  4581 net.cpp:137] Memory required for data: 1184154800
I0928 13:46:49.094265  4581 layer_factory.hpp:77] Creating layer Eltwise27
I0928 13:46:49.094269  4581 net.cpp:84] Creating Layer Eltwise27
I0928 13:46:49.094272  4581 net.cpp:406] Eltwise27 <- Eltwise26_M2PELU53_0_split_1
I0928 13:46:49.094275  4581 net.cpp:406] Eltwise27 <- Convolution57
I0928 13:46:49.094279  4581 net.cpp:380] Eltwise27 -> Eltwise27
I0928 13:46:49.094295  4581 net.cpp:122] Setting up Eltwise27
I0928 13:46:49.094300  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.094301  4581 net.cpp:137] Memory required for data: 1185793200
I0928 13:46:49.094303  4581 layer_factory.hpp:77] Creating layer M2PELU55
I0928 13:46:49.094308  4581 net.cpp:84] Creating Layer M2PELU55
I0928 13:46:49.094311  4581 net.cpp:406] M2PELU55 <- Eltwise27
I0928 13:46:49.094314  4581 net.cpp:367] M2PELU55 -> Eltwise27 (in-place)
I0928 13:46:49.094408  4581 net.cpp:122] Setting up M2PELU55
I0928 13:46:49.094413  4581 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 13:46:49.094415  4581 net.cpp:137] Memory required for data: 1187431600
I0928 13:46:49.094419  4581 layer_factory.hpp:77] Creating layer Pooling1
I0928 13:46:49.094424  4581 net.cpp:84] Creating Layer Pooling1
I0928 13:46:49.094425  4581 net.cpp:406] Pooling1 <- Eltwise27
I0928 13:46:49.094429  4581 net.cpp:380] Pooling1 -> Pooling1
I0928 13:46:49.094938  4581 net.cpp:122] Setting up Pooling1
I0928 13:46:49.094946  4581 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0928 13:46:49.094949  4581 net.cpp:137] Memory required for data: 1187457200
I0928 13:46:49.094951  4581 layer_factory.hpp:77] Creating layer InnerProduct1
I0928 13:46:49.094957  4581 net.cpp:84] Creating Layer InnerProduct1
I0928 13:46:49.094960  4581 net.cpp:406] InnerProduct1 <- Pooling1
I0928 13:46:49.094964  4581 net.cpp:380] InnerProduct1 -> InnerProduct1
I0928 13:46:49.095073  4581 net.cpp:122] Setting up InnerProduct1
I0928 13:46:49.095077  4581 net.cpp:129] Top shape: 100 10 (1000)
I0928 13:46:49.095079  4581 net.cpp:137] Memory required for data: 1187461200
I0928 13:46:49.095083  4581 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0928 13:46:49.095088  4581 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I0928 13:46:49.095090  4581 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0928 13:46:49.095094  4581 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0928 13:46:49.095098  4581 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0928 13:46:49.095124  4581 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I0928 13:46:49.095129  4581 net.cpp:129] Top shape: 100 10 (1000)
I0928 13:46:49.095131  4581 net.cpp:129] Top shape: 100 10 (1000)
I0928 13:46:49.095134  4581 net.cpp:137] Memory required for data: 1187469200
I0928 13:46:49.095135  4581 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0928 13:46:49.095139  4581 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0928 13:46:49.095141  4581 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I0928 13:46:49.095144  4581 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I0928 13:46:49.095147  4581 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0928 13:46:49.095152  4581 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0928 13:46:49.095352  4581 net.cpp:122] Setting up SoftmaxWithLoss1
I0928 13:46:49.095358  4581 net.cpp:129] Top shape: (1)
I0928 13:46:49.095366  4581 net.cpp:132]     with loss weight 1
I0928 13:46:49.095374  4581 net.cpp:137] Memory required for data: 1187469204
I0928 13:46:49.095376  4581 layer_factory.hpp:77] Creating layer Accuracy1
I0928 13:46:49.095386  4581 net.cpp:84] Creating Layer Accuracy1
I0928 13:46:49.095388  4581 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I0928 13:46:49.095391  4581 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I0928 13:46:49.095396  4581 net.cpp:380] Accuracy1 -> Accuracy1
I0928 13:46:49.095402  4581 net.cpp:122] Setting up Accuracy1
I0928 13:46:49.095404  4581 net.cpp:129] Top shape: (1)
I0928 13:46:49.095407  4581 net.cpp:137] Memory required for data: 1187469208
I0928 13:46:49.095408  4581 net.cpp:200] Accuracy1 does not need backward computation.
I0928 13:46:49.095412  4581 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0928 13:46:49.095413  4581 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0928 13:46:49.095417  4581 net.cpp:198] InnerProduct1 needs backward computation.
I0928 13:46:49.095418  4581 net.cpp:198] Pooling1 needs backward computation.
I0928 13:46:49.095420  4581 net.cpp:198] M2PELU55 needs backward computation.
I0928 13:46:49.095422  4581 net.cpp:198] Eltwise27 needs backward computation.
I0928 13:46:49.095425  4581 net.cpp:198] Scale57 needs backward computation.
I0928 13:46:49.095427  4581 net.cpp:198] BatchNorm57 needs backward computation.
I0928 13:46:49.095428  4581 net.cpp:198] Convolution57 needs backward computation.
I0928 13:46:49.095432  4581 net.cpp:198] M2PELU54 needs backward computation.
I0928 13:46:49.095433  4581 net.cpp:198] Scale56 needs backward computation.
I0928 13:46:49.095435  4581 net.cpp:198] BatchNorm56 needs backward computation.
I0928 13:46:49.095438  4581 net.cpp:198] Convolution56 needs backward computation.
I0928 13:46:49.095439  4581 net.cpp:198] Eltwise26_M2PELU53_0_split needs backward computation.
I0928 13:46:49.095441  4581 net.cpp:198] M2PELU53 needs backward computation.
I0928 13:46:49.095443  4581 net.cpp:198] Eltwise26 needs backward computation.
I0928 13:46:49.095446  4581 net.cpp:198] Scale55 needs backward computation.
I0928 13:46:49.095448  4581 net.cpp:198] BatchNorm55 needs backward computation.
I0928 13:46:49.095450  4581 net.cpp:198] Convolution55 needs backward computation.
I0928 13:46:49.095453  4581 net.cpp:198] M2PELU52 needs backward computation.
I0928 13:46:49.095454  4581 net.cpp:198] Scale54 needs backward computation.
I0928 13:46:49.095456  4581 net.cpp:198] BatchNorm54 needs backward computation.
I0928 13:46:49.095458  4581 net.cpp:198] Convolution54 needs backward computation.
I0928 13:46:49.095460  4581 net.cpp:198] Eltwise25_M2PELU51_0_split needs backward computation.
I0928 13:46:49.095463  4581 net.cpp:198] M2PELU51 needs backward computation.
I0928 13:46:49.095465  4581 net.cpp:198] Eltwise25 needs backward computation.
I0928 13:46:49.095468  4581 net.cpp:198] Scale53 needs backward computation.
I0928 13:46:49.095470  4581 net.cpp:198] BatchNorm53 needs backward computation.
I0928 13:46:49.095472  4581 net.cpp:198] Convolution53 needs backward computation.
I0928 13:46:49.095474  4581 net.cpp:198] M2PELU50 needs backward computation.
I0928 13:46:49.095476  4581 net.cpp:198] Scale52 needs backward computation.
I0928 13:46:49.095479  4581 net.cpp:198] BatchNorm52 needs backward computation.
I0928 13:46:49.095480  4581 net.cpp:198] Convolution52 needs backward computation.
I0928 13:46:49.095482  4581 net.cpp:198] Eltwise24_M2PELU49_0_split needs backward computation.
I0928 13:46:49.095484  4581 net.cpp:198] M2PELU49 needs backward computation.
I0928 13:46:49.095487  4581 net.cpp:198] Eltwise24 needs backward computation.
I0928 13:46:49.095489  4581 net.cpp:198] Scale51 needs backward computation.
I0928 13:46:49.095491  4581 net.cpp:198] BatchNorm51 needs backward computation.
I0928 13:46:49.095494  4581 net.cpp:198] Convolution51 needs backward computation.
I0928 13:46:49.095495  4581 net.cpp:198] M2PELU48 needs backward computation.
I0928 13:46:49.095497  4581 net.cpp:198] Scale50 needs backward computation.
I0928 13:46:49.095504  4581 net.cpp:198] BatchNorm50 needs backward computation.
I0928 13:46:49.095506  4581 net.cpp:198] Convolution50 needs backward computation.
I0928 13:46:49.095508  4581 net.cpp:198] Eltwise23_M2PELU47_0_split needs backward computation.
I0928 13:46:49.095511  4581 net.cpp:198] M2PELU47 needs backward computation.
I0928 13:46:49.095513  4581 net.cpp:198] Eltwise23 needs backward computation.
I0928 13:46:49.095516  4581 net.cpp:198] Scale49 needs backward computation.
I0928 13:46:49.095517  4581 net.cpp:198] BatchNorm49 needs backward computation.
I0928 13:46:49.095520  4581 net.cpp:198] Convolution49 needs backward computation.
I0928 13:46:49.095523  4581 net.cpp:198] M2PELU46 needs backward computation.
I0928 13:46:49.095525  4581 net.cpp:198] Scale48 needs backward computation.
I0928 13:46:49.095527  4581 net.cpp:198] BatchNorm48 needs backward computation.
I0928 13:46:49.095530  4581 net.cpp:198] Convolution48 needs backward computation.
I0928 13:46:49.095532  4581 net.cpp:198] Eltwise22_M2PELU45_0_split needs backward computation.
I0928 13:46:49.095535  4581 net.cpp:198] M2PELU45 needs backward computation.
I0928 13:46:49.095536  4581 net.cpp:198] Eltwise22 needs backward computation.
I0928 13:46:49.095538  4581 net.cpp:198] Scale47 needs backward computation.
I0928 13:46:49.095541  4581 net.cpp:198] BatchNorm47 needs backward computation.
I0928 13:46:49.095542  4581 net.cpp:198] Convolution47 needs backward computation.
I0928 13:46:49.095546  4581 net.cpp:198] M2PELU44 needs backward computation.
I0928 13:46:49.095547  4581 net.cpp:198] Scale46 needs backward computation.
I0928 13:46:49.095549  4581 net.cpp:198] BatchNorm46 needs backward computation.
I0928 13:46:49.095551  4581 net.cpp:198] Convolution46 needs backward computation.
I0928 13:46:49.095553  4581 net.cpp:198] Eltwise21_M2PELU43_0_split needs backward computation.
I0928 13:46:49.095556  4581 net.cpp:198] M2PELU43 needs backward computation.
I0928 13:46:49.095558  4581 net.cpp:198] Eltwise21 needs backward computation.
I0928 13:46:49.095561  4581 net.cpp:198] Scale45 needs backward computation.
I0928 13:46:49.095562  4581 net.cpp:198] BatchNorm45 needs backward computation.
I0928 13:46:49.095566  4581 net.cpp:198] Convolution45 needs backward computation.
I0928 13:46:49.095567  4581 net.cpp:198] M2PELU42 needs backward computation.
I0928 13:46:49.095569  4581 net.cpp:198] Scale44 needs backward computation.
I0928 13:46:49.095571  4581 net.cpp:198] BatchNorm44 needs backward computation.
I0928 13:46:49.095573  4581 net.cpp:198] Convolution44 needs backward computation.
I0928 13:46:49.095576  4581 net.cpp:198] Eltwise20_M2PELU41_0_split needs backward computation.
I0928 13:46:49.095578  4581 net.cpp:198] M2PELU41 needs backward computation.
I0928 13:46:49.095580  4581 net.cpp:198] Eltwise20 needs backward computation.
I0928 13:46:49.095583  4581 net.cpp:198] Scale43 needs backward computation.
I0928 13:46:49.095585  4581 net.cpp:198] BatchNorm43 needs backward computation.
I0928 13:46:49.095587  4581 net.cpp:198] Convolution43 needs backward computation.
I0928 13:46:49.095589  4581 net.cpp:198] M2PELU40 needs backward computation.
I0928 13:46:49.095592  4581 net.cpp:198] Scale42 needs backward computation.
I0928 13:46:49.095593  4581 net.cpp:198] BatchNorm42 needs backward computation.
I0928 13:46:49.095595  4581 net.cpp:198] Convolution42 needs backward computation.
I0928 13:46:49.095598  4581 net.cpp:198] Eltwise19_M2PELU39_0_split needs backward computation.
I0928 13:46:49.095602  4581 net.cpp:198] M2PELU39 needs backward computation.
I0928 13:46:49.095603  4581 net.cpp:198] Eltwise19 needs backward computation.
I0928 13:46:49.095605  4581 net.cpp:198] Scale41 needs backward computation.
I0928 13:46:49.095608  4581 net.cpp:198] BatchNorm41 needs backward computation.
I0928 13:46:49.095610  4581 net.cpp:198] Convolution41 needs backward computation.
I0928 13:46:49.095613  4581 net.cpp:198] M2PELU38 needs backward computation.
I0928 13:46:49.095615  4581 net.cpp:198] Scale40 needs backward computation.
I0928 13:46:49.095623  4581 net.cpp:198] BatchNorm40 needs backward computation.
I0928 13:46:49.095624  4581 net.cpp:198] Convolution40 needs backward computation.
I0928 13:46:49.095628  4581 net.cpp:198] Scale39 needs backward computation.
I0928 13:46:49.095629  4581 net.cpp:198] BatchNorm39 needs backward computation.
I0928 13:46:49.095631  4581 net.cpp:198] Convolution39 needs backward computation.
I0928 13:46:49.095633  4581 net.cpp:198] Eltwise18_M2PELU37_0_split needs backward computation.
I0928 13:46:49.095636  4581 net.cpp:198] M2PELU37 needs backward computation.
I0928 13:46:49.095638  4581 net.cpp:198] Eltwise18 needs backward computation.
I0928 13:46:49.095641  4581 net.cpp:198] Scale38 needs backward computation.
I0928 13:46:49.095643  4581 net.cpp:198] BatchNorm38 needs backward computation.
I0928 13:46:49.095645  4581 net.cpp:198] Convolution38 needs backward computation.
I0928 13:46:49.095649  4581 net.cpp:198] M2PELU36 needs backward computation.
I0928 13:46:49.095650  4581 net.cpp:198] Scale37 needs backward computation.
I0928 13:46:49.095652  4581 net.cpp:198] BatchNorm37 needs backward computation.
I0928 13:46:49.095654  4581 net.cpp:198] Convolution37 needs backward computation.
I0928 13:46:49.095656  4581 net.cpp:198] Eltwise17_M2PELU35_0_split needs backward computation.
I0928 13:46:49.095659  4581 net.cpp:198] M2PELU35 needs backward computation.
I0928 13:46:49.095661  4581 net.cpp:198] Eltwise17 needs backward computation.
I0928 13:46:49.122315  4581 net.cpp:198] Scale36 needs backward computation.
I0928 13:46:49.122325  4581 net.cpp:198] BatchNorm36 needs backward computation.
I0928 13:46:49.122329  4581 net.cpp:198] Convolution36 needs backward computation.
I0928 13:46:49.122334  4581 net.cpp:198] M2PELU34 needs backward computation.
I0928 13:46:49.122337  4581 net.cpp:198] Scale35 needs backward computation.
I0928 13:46:49.122341  4581 net.cpp:198] BatchNorm35 needs backward computation.
I0928 13:46:49.122345  4581 net.cpp:198] Convolution35 needs backward computation.
I0928 13:46:49.122349  4581 net.cpp:198] Eltwise16_M2PELU33_0_split needs backward computation.
I0928 13:46:49.122354  4581 net.cpp:198] M2PELU33 needs backward computation.
I0928 13:46:49.122359  4581 net.cpp:198] Eltwise16 needs backward computation.
I0928 13:46:49.122365  4581 net.cpp:198] Scale34 needs backward computation.
I0928 13:46:49.122370  4581 net.cpp:198] BatchNorm34 needs backward computation.
I0928 13:46:49.122373  4581 net.cpp:198] Convolution34 needs backward computation.
I0928 13:46:49.122377  4581 net.cpp:198] M2PELU32 needs backward computation.
I0928 13:46:49.122381  4581 net.cpp:198] Scale33 needs backward computation.
I0928 13:46:49.122385  4581 net.cpp:198] BatchNorm33 needs backward computation.
I0928 13:46:49.122388  4581 net.cpp:198] Convolution33 needs backward computation.
I0928 13:46:49.122393  4581 net.cpp:198] Eltwise15_M2PELU31_0_split needs backward computation.
I0928 13:46:49.122397  4581 net.cpp:198] M2PELU31 needs backward computation.
I0928 13:46:49.122401  4581 net.cpp:198] Eltwise15 needs backward computation.
I0928 13:46:49.122406  4581 net.cpp:198] Scale32 needs backward computation.
I0928 13:46:49.122409  4581 net.cpp:198] BatchNorm32 needs backward computation.
I0928 13:46:49.122413  4581 net.cpp:198] Convolution32 needs backward computation.
I0928 13:46:49.122417  4581 net.cpp:198] M2PELU30 needs backward computation.
I0928 13:46:49.122421  4581 net.cpp:198] Scale31 needs backward computation.
I0928 13:46:49.122426  4581 net.cpp:198] BatchNorm31 needs backward computation.
I0928 13:46:49.122429  4581 net.cpp:198] Convolution31 needs backward computation.
I0928 13:46:49.122433  4581 net.cpp:198] Eltwise14_M2PELU29_0_split needs backward computation.
I0928 13:46:49.122437  4581 net.cpp:198] M2PELU29 needs backward computation.
I0928 13:46:49.122442  4581 net.cpp:198] Eltwise14 needs backward computation.
I0928 13:46:49.122449  4581 net.cpp:198] Scale30 needs backward computation.
I0928 13:46:49.122453  4581 net.cpp:198] BatchNorm30 needs backward computation.
I0928 13:46:49.122457  4581 net.cpp:198] Convolution30 needs backward computation.
I0928 13:46:49.122468  4581 net.cpp:198] M2PELU28 needs backward computation.
I0928 13:46:49.122473  4581 net.cpp:198] Scale29 needs backward computation.
I0928 13:46:49.122478  4581 net.cpp:198] BatchNorm29 needs backward computation.
I0928 13:46:49.122480  4581 net.cpp:198] Convolution29 needs backward computation.
I0928 13:46:49.122485  4581 net.cpp:198] Eltwise13_M2PELU27_0_split needs backward computation.
I0928 13:46:49.122489  4581 net.cpp:198] M2PELU27 needs backward computation.
I0928 13:46:49.122491  4581 net.cpp:198] Eltwise13 needs backward computation.
I0928 13:46:49.122494  4581 net.cpp:198] Scale28 needs backward computation.
I0928 13:46:49.122496  4581 net.cpp:198] BatchNorm28 needs backward computation.
I0928 13:46:49.122499  4581 net.cpp:198] Convolution28 needs backward computation.
I0928 13:46:49.122501  4581 net.cpp:198] M2PELU26 needs backward computation.
I0928 13:46:49.122504  4581 net.cpp:198] Scale27 needs backward computation.
I0928 13:46:49.122506  4581 net.cpp:198] BatchNorm27 needs backward computation.
I0928 13:46:49.122509  4581 net.cpp:198] Convolution27 needs backward computation.
I0928 13:46:49.122511  4581 net.cpp:198] Eltwise12_M2PELU25_0_split needs backward computation.
I0928 13:46:49.122514  4581 net.cpp:198] M2PELU25 needs backward computation.
I0928 13:46:49.122516  4581 net.cpp:198] Eltwise12 needs backward computation.
I0928 13:46:49.122519  4581 net.cpp:198] Scale26 needs backward computation.
I0928 13:46:49.122529  4581 net.cpp:198] BatchNorm26 needs backward computation.
I0928 13:46:49.122531  4581 net.cpp:198] Convolution26 needs backward computation.
I0928 13:46:49.122534  4581 net.cpp:198] M2PELU24 needs backward computation.
I0928 13:46:49.122536  4581 net.cpp:198] Scale25 needs backward computation.
I0928 13:46:49.122539  4581 net.cpp:198] BatchNorm25 needs backward computation.
I0928 13:46:49.122541  4581 net.cpp:198] Convolution25 needs backward computation.
I0928 13:46:49.122544  4581 net.cpp:198] Eltwise11_M2PELU23_0_split needs backward computation.
I0928 13:46:49.122546  4581 net.cpp:198] M2PELU23 needs backward computation.
I0928 13:46:49.122548  4581 net.cpp:198] Eltwise11 needs backward computation.
I0928 13:46:49.122551  4581 net.cpp:198] Scale24 needs backward computation.
I0928 13:46:49.122553  4581 net.cpp:198] BatchNorm24 needs backward computation.
I0928 13:46:49.122556  4581 net.cpp:198] Convolution24 needs backward computation.
I0928 13:46:49.122558  4581 net.cpp:198] M2PELU22 needs backward computation.
I0928 13:46:49.122560  4581 net.cpp:198] Scale23 needs backward computation.
I0928 13:46:49.122563  4581 net.cpp:198] BatchNorm23 needs backward computation.
I0928 13:46:49.122565  4581 net.cpp:198] Convolution23 needs backward computation.
I0928 13:46:49.122568  4581 net.cpp:198] Eltwise10_M2PELU21_0_split needs backward computation.
I0928 13:46:49.122570  4581 net.cpp:198] M2PELU21 needs backward computation.
I0928 13:46:49.122573  4581 net.cpp:198] Eltwise10 needs backward computation.
I0928 13:46:49.122576  4581 net.cpp:198] Scale22 needs backward computation.
I0928 13:46:49.122578  4581 net.cpp:198] BatchNorm22 needs backward computation.
I0928 13:46:49.122581  4581 net.cpp:198] Convolution22 needs backward computation.
I0928 13:46:49.122583  4581 net.cpp:198] M2PELU20 needs backward computation.
I0928 13:46:49.122586  4581 net.cpp:198] Scale21 needs backward computation.
I0928 13:46:49.122588  4581 net.cpp:198] BatchNorm21 needs backward computation.
I0928 13:46:49.122591  4581 net.cpp:198] Convolution21 needs backward computation.
I0928 13:46:49.122593  4581 net.cpp:198] Scale20 needs backward computation.
I0928 13:46:49.122596  4581 net.cpp:198] BatchNorm20 needs backward computation.
I0928 13:46:49.122598  4581 net.cpp:198] Convolution20 needs backward computation.
I0928 13:46:49.122601  4581 net.cpp:198] Eltwise9_M2PELU19_0_split needs backward computation.
I0928 13:46:49.122603  4581 net.cpp:198] M2PELU19 needs backward computation.
I0928 13:46:49.122606  4581 net.cpp:198] Eltwise9 needs backward computation.
I0928 13:46:49.122614  4581 net.cpp:198] Scale19 needs backward computation.
I0928 13:46:49.122617  4581 net.cpp:198] BatchNorm19 needs backward computation.
I0928 13:46:49.122619  4581 net.cpp:198] Convolution19 needs backward computation.
I0928 13:46:49.122622  4581 net.cpp:198] M2PELU18 needs backward computation.
I0928 13:46:49.122624  4581 net.cpp:198] Scale18 needs backward computation.
I0928 13:46:49.122627  4581 net.cpp:198] BatchNorm18 needs backward computation.
I0928 13:46:49.122629  4581 net.cpp:198] Convolution18 needs backward computation.
I0928 13:46:49.122632  4581 net.cpp:198] Eltwise8_M2PELU17_0_split needs backward computation.
I0928 13:46:49.122635  4581 net.cpp:198] M2PELU17 needs backward computation.
I0928 13:46:49.122637  4581 net.cpp:198] Eltwise8 needs backward computation.
I0928 13:46:49.122640  4581 net.cpp:198] Scale17 needs backward computation.
I0928 13:46:49.122642  4581 net.cpp:198] BatchNorm17 needs backward computation.
I0928 13:46:49.122644  4581 net.cpp:198] Convolution17 needs backward computation.
I0928 13:46:49.122648  4581 net.cpp:198] M2PELU16 needs backward computation.
I0928 13:46:49.122649  4581 net.cpp:198] Scale16 needs backward computation.
I0928 13:46:49.122651  4581 net.cpp:198] BatchNorm16 needs backward computation.
I0928 13:46:49.122654  4581 net.cpp:198] Convolution16 needs backward computation.
I0928 13:46:49.122658  4581 net.cpp:198] Eltwise7_M2PELU15_0_split needs backward computation.
I0928 13:46:49.122659  4581 net.cpp:198] M2PELU15 needs backward computation.
I0928 13:46:49.122663  4581 net.cpp:198] Eltwise7 needs backward computation.
I0928 13:46:49.122664  4581 net.cpp:198] Scale15 needs backward computation.
I0928 13:46:49.122668  4581 net.cpp:198] BatchNorm15 needs backward computation.
I0928 13:46:49.122669  4581 net.cpp:198] Convolution15 needs backward computation.
I0928 13:46:49.122673  4581 net.cpp:198] M2PELU14 needs backward computation.
I0928 13:46:49.122674  4581 net.cpp:198] Scale14 needs backward computation.
I0928 13:46:49.122676  4581 net.cpp:198] BatchNorm14 needs backward computation.
I0928 13:46:49.122679  4581 net.cpp:198] Convolution14 needs backward computation.
I0928 13:46:49.122681  4581 net.cpp:198] Eltwise6_M2PELU13_0_split needs backward computation.
I0928 13:46:49.122684  4581 net.cpp:198] M2PELU13 needs backward computation.
I0928 13:46:49.122686  4581 net.cpp:198] Eltwise6 needs backward computation.
I0928 13:46:49.122690  4581 net.cpp:198] Scale13 needs backward computation.
I0928 13:46:49.122694  4581 net.cpp:198] BatchNorm13 needs backward computation.
I0928 13:46:49.122695  4581 net.cpp:198] Convolution13 needs backward computation.
I0928 13:46:49.122699  4581 net.cpp:198] M2PELU12 needs backward computation.
I0928 13:46:49.122700  4581 net.cpp:198] Scale12 needs backward computation.
I0928 13:46:49.122704  4581 net.cpp:198] BatchNorm12 needs backward computation.
I0928 13:46:49.122705  4581 net.cpp:198] Convolution12 needs backward computation.
I0928 13:46:49.122707  4581 net.cpp:198] Eltwise5_M2PELU11_0_split needs backward computation.
I0928 13:46:49.122710  4581 net.cpp:198] M2PELU11 needs backward computation.
I0928 13:46:49.122714  4581 net.cpp:198] Eltwise5 needs backward computation.
I0928 13:46:49.122716  4581 net.cpp:198] Scale11 needs backward computation.
I0928 13:46:49.122719  4581 net.cpp:198] BatchNorm11 needs backward computation.
I0928 13:46:49.122720  4581 net.cpp:198] Convolution11 needs backward computation.
I0928 13:46:49.122723  4581 net.cpp:198] M2PELU10 needs backward computation.
I0928 13:46:49.122725  4581 net.cpp:198] Scale10 needs backward computation.
I0928 13:46:49.122728  4581 net.cpp:198] BatchNorm10 needs backward computation.
I0928 13:46:49.122730  4581 net.cpp:198] Convolution10 needs backward computation.
I0928 13:46:49.122733  4581 net.cpp:198] Eltwise4_M2PELU9_0_split needs backward computation.
I0928 13:46:49.122736  4581 net.cpp:198] M2PELU9 needs backward computation.
I0928 13:46:49.122740  4581 net.cpp:198] Eltwise4 needs backward computation.
I0928 13:46:49.122745  4581 net.cpp:198] Scale9 needs backward computation.
I0928 13:46:49.122748  4581 net.cpp:198] BatchNorm9 needs backward computation.
I0928 13:46:49.122751  4581 net.cpp:198] Convolution9 needs backward computation.
I0928 13:46:49.122753  4581 net.cpp:198] M2PELU8 needs backward computation.
I0928 13:46:49.122756  4581 net.cpp:198] Scale8 needs backward computation.
I0928 13:46:49.122758  4581 net.cpp:198] BatchNorm8 needs backward computation.
I0928 13:46:49.122761  4581 net.cpp:198] Convolution8 needs backward computation.
I0928 13:46:49.122764  4581 net.cpp:198] Eltwise3_M2PELU7_0_split needs backward computation.
I0928 13:46:49.122766  4581 net.cpp:198] M2PELU7 needs backward computation.
I0928 13:46:49.122769  4581 net.cpp:198] Eltwise3 needs backward computation.
I0928 13:46:49.122772  4581 net.cpp:198] Scale7 needs backward computation.
I0928 13:46:49.122774  4581 net.cpp:198] BatchNorm7 needs backward computation.
I0928 13:46:49.122777  4581 net.cpp:198] Convolution7 needs backward computation.
I0928 13:46:49.122779  4581 net.cpp:198] M2PELU6 needs backward computation.
I0928 13:46:49.122781  4581 net.cpp:198] Scale6 needs backward computation.
I0928 13:46:49.122784  4581 net.cpp:198] BatchNorm6 needs backward computation.
I0928 13:46:49.122786  4581 net.cpp:198] Convolution6 needs backward computation.
I0928 13:46:49.122789  4581 net.cpp:198] Eltwise2_M2PELU5_0_split needs backward computation.
I0928 13:46:49.122792  4581 net.cpp:198] M2PELU5 needs backward computation.
I0928 13:46:49.122794  4581 net.cpp:198] Eltwise2 needs backward computation.
I0928 13:46:49.122797  4581 net.cpp:198] Scale5 needs backward computation.
I0928 13:46:49.122800  4581 net.cpp:198] BatchNorm5 needs backward computation.
I0928 13:46:49.122802  4581 net.cpp:198] Convolution5 needs backward computation.
I0928 13:46:49.122805  4581 net.cpp:198] M2PELU4 needs backward computation.
I0928 13:46:49.122807  4581 net.cpp:198] Scale4 needs backward computation.
I0928 13:46:49.122809  4581 net.cpp:198] BatchNorm4 needs backward computation.
I0928 13:46:49.122812  4581 net.cpp:198] Convolution4 needs backward computation.
I0928 13:46:49.122814  4581 net.cpp:198] Eltwise1_M2PELU3_0_split needs backward computation.
I0928 13:46:49.122817  4581 net.cpp:198] M2PELU3 needs backward computation.
I0928 13:46:49.122819  4581 net.cpp:198] Eltwise1 needs backward computation.
I0928 13:46:49.122822  4581 net.cpp:198] Scale3 needs backward computation.
I0928 13:46:49.122825  4581 net.cpp:198] BatchNorm3 needs backward computation.
I0928 13:46:49.122828  4581 net.cpp:198] Convolution3 needs backward computation.
I0928 13:46:49.122830  4581 net.cpp:198] M2PELU2 needs backward computation.
I0928 13:46:49.122833  4581 net.cpp:198] Scale2 needs backward computation.
I0928 13:46:49.122835  4581 net.cpp:198] BatchNorm2 needs backward computation.
I0928 13:46:49.122838  4581 net.cpp:198] Convolution2 needs backward computation.
I0928 13:46:49.122840  4581 net.cpp:198] Convolution1_M2PELU1_0_split needs backward computation.
I0928 13:46:49.122843  4581 net.cpp:198] M2PELU1 needs backward computation.
I0928 13:46:49.122845  4581 net.cpp:198] Scale1 needs backward computation.
I0928 13:46:49.122848  4581 net.cpp:198] BatchNorm1 needs backward computation.
I0928 13:46:49.122849  4581 net.cpp:198] Convolution1 needs backward computation.
I0928 13:46:49.122853  4581 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I0928 13:46:49.122856  4581 net.cpp:200] Data1 does not need backward computation.
I0928 13:46:49.122859  4581 net.cpp:242] This network produces output Accuracy1
I0928 13:46:49.122861  4581 net.cpp:242] This network produces output SoftmaxWithLoss1
I0928 13:46:49.122958  4581 net.cpp:255] Network initialization done.
I0928 13:46:49.123751  4581 solver.cpp:56] Solver scaffolding done.
I0928 13:46:49.136405  4581 caffe.cpp:248] Starting Optimization
I0928 13:46:49.136412  4581 solver.cpp:272] Solving resnet_cifar10
I0928 13:46:49.136415  4581 solver.cpp:273] Learning Rate Policy: multistep
I0928 13:46:49.142324  4581 solver.cpp:330] Iteration 0, Testing net (#0)
I0928 13:46:52.597704  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:46:52.737864  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I0928 13:46:52.737892  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I0928 13:46:52.935454  4581 solver.cpp:218] Iteration 0 (0 iter/s, 3.79895s/100 iters), loss = 2.30564
I0928 13:46:52.935487  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.30564 (* 1 = 2.30564 loss)
I0928 13:46:52.935523  4581 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I0928 13:47:07.129714  4581 solver.cpp:218] Iteration 100 (7.04517 iter/s, 14.1941s/100 iters), loss = 1.94546
I0928 13:47:07.129745  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.94546 (* 1 = 1.94546 loss)
I0928 13:47:07.129765  4581 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I0928 13:47:21.315719  4581 solver.cpp:218] Iteration 200 (7.04927 iter/s, 14.1859s/100 iters), loss = 2.15135
I0928 13:47:21.315881  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.15135 (* 1 = 2.15135 loss)
I0928 13:47:21.315893  4581 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I0928 13:47:35.507580  4581 solver.cpp:218] Iteration 300 (7.04642 iter/s, 14.1916s/100 iters), loss = 1.7077
I0928 13:47:35.507612  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.7077 (* 1 = 1.7077 loss)
I0928 13:47:35.507621  4581 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I0928 13:47:49.697175  4581 solver.cpp:218] Iteration 400 (7.04748 iter/s, 14.1895s/100 iters), loss = 1.50945
I0928 13:47:49.697207  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.50945 (* 1 = 1.50945 loss)
I0928 13:47:49.697216  4581 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I0928 13:48:03.186620  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:48:03.756327  4581 solver.cpp:330] Iteration 500, Testing net (#0)
I0928 13:48:07.109589  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:48:07.249886  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1005
I0928 13:48:07.249915  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 7.68554 (* 1 = 7.68554 loss)
I0928 13:48:07.390660  4581 solver.cpp:218] Iteration 500 (5.65184 iter/s, 17.6933s/100 iters), loss = 1.68715
I0928 13:48:07.390688  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.68715 (* 1 = 1.68715 loss)
I0928 13:48:07.390698  4581 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I0928 13:48:21.597198  4581 solver.cpp:218] Iteration 600 (7.03907 iter/s, 14.2064s/100 iters), loss = 1.47456
I0928 13:48:21.597230  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.47456 (* 1 = 1.47456 loss)
I0928 13:48:21.597249  4581 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I0928 13:48:35.813083  4581 solver.cpp:218] Iteration 700 (7.03444 iter/s, 14.2158s/100 iters), loss = 1.41934
I0928 13:48:35.813194  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.41934 (* 1 = 1.41934 loss)
I0928 13:48:35.813204  4581 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I0928 13:48:50.025094  4581 solver.cpp:218] Iteration 800 (7.03639 iter/s, 14.2118s/100 iters), loss = 1.31636
I0928 13:48:50.025126  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.31636 (* 1 = 1.31636 loss)
I0928 13:48:50.025144  4581 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I0928 13:49:04.233450  4581 solver.cpp:218] Iteration 900 (7.03816 iter/s, 14.2083s/100 iters), loss = 1.20431
I0928 13:49:04.233484  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.20431 (* 1 = 1.20431 loss)
I0928 13:49:04.233502  4581 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I0928 13:49:17.738458  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:49:18.307672  4581 solver.cpp:330] Iteration 1000, Testing net (#0)
I0928 13:49:21.669710  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:49:21.810317  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.193
I0928 13:49:21.810343  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 5.27604 (* 1 = 5.27604 loss)
I0928 13:49:21.951418  4581 solver.cpp:218] Iteration 1000 (5.64402 iter/s, 17.7179s/100 iters), loss = 1.15225
I0928 13:49:21.951448  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.15225 (* 1 = 1.15225 loss)
I0928 13:49:21.951457  4581 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I0928 13:49:36.154904  4581 solver.cpp:218] Iteration 1100 (7.04057 iter/s, 14.2034s/100 iters), loss = 1.14278
I0928 13:49:36.154937  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.14278 (* 1 = 1.14278 loss)
I0928 13:49:36.154955  4581 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I0928 13:49:50.356207  4581 solver.cpp:218] Iteration 1200 (7.04165 iter/s, 14.2012s/100 iters), loss = 1.11446
I0928 13:49:50.356302  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.11446 (* 1 = 1.11446 loss)
I0928 13:49:50.356328  4581 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I0928 13:50:04.560263  4581 solver.cpp:218] Iteration 1300 (7.04031 iter/s, 14.2039s/100 iters), loss = 1.02241
I0928 13:50:04.560297  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.02241 (* 1 = 1.02241 loss)
I0928 13:50:04.560315  4581 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I0928 13:50:18.771450  4581 solver.cpp:218] Iteration 1400 (7.03675 iter/s, 14.2111s/100 iters), loss = 0.914812
I0928 13:50:18.771482  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.914812 (* 1 = 0.914812 loss)
I0928 13:50:18.771502  4581 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I0928 13:50:32.270234  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:50:32.838081  4581 solver.cpp:330] Iteration 1500, Testing net (#0)
I0928 13:50:36.200606  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:50:36.340888  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.2614
I0928 13:50:36.340915  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.96508 (* 1 = 3.96508 loss)
I0928 13:50:36.482185  4581 solver.cpp:218] Iteration 1500 (5.64632 iter/s, 17.7106s/100 iters), loss = 0.798246
I0928 13:50:36.482215  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.798246 (* 1 = 0.798246 loss)
I0928 13:50:36.482225  4581 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I0928 13:50:50.708161  4581 solver.cpp:218] Iteration 1600 (7.02943 iter/s, 14.2259s/100 iters), loss = 0.746512
I0928 13:50:50.708195  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.746512 (* 1 = 0.746512 loss)
I0928 13:50:50.708214  4581 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I0928 13:51:04.936713  4581 solver.cpp:218] Iteration 1700 (7.02816 iter/s, 14.2285s/100 iters), loss = 0.767369
I0928 13:51:04.936799  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.767369 (* 1 = 0.767369 loss)
I0928 13:51:04.936807  4581 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I0928 13:51:19.167529  4581 solver.cpp:218] Iteration 1800 (7.02707 iter/s, 14.2307s/100 iters), loss = 0.719473
I0928 13:51:19.167563  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.719473 (* 1 = 0.719473 loss)
I0928 13:51:19.167572  4581 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I0928 13:51:33.394428  4581 solver.cpp:218] Iteration 1900 (7.02898 iter/s, 14.2268s/100 iters), loss = 0.70644
I0928 13:51:33.394460  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.70644 (* 1 = 0.70644 loss)
I0928 13:51:33.394479  4581 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I0928 13:51:46.922760  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:51:47.493201  4581 solver.cpp:330] Iteration 2000, Testing net (#0)
I0928 13:51:50.856609  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:51:50.997486  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3518
I0928 13:51:50.997516  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.53517 (* 1 = 2.53517 loss)
I0928 13:51:51.138401  4581 solver.cpp:218] Iteration 2000 (5.63575 iter/s, 17.7439s/100 iters), loss = 0.818798
I0928 13:51:51.138434  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.818798 (* 1 = 0.818798 loss)
I0928 13:51:51.138444  4581 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I0928 13:52:05.351037  4581 solver.cpp:218] Iteration 2100 (7.03603 iter/s, 14.2126s/100 iters), loss = 0.582346
I0928 13:52:05.351073  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.582346 (* 1 = 0.582346 loss)
I0928 13:52:05.351090  4581 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I0928 13:52:19.571601  4581 solver.cpp:218] Iteration 2200 (7.03211 iter/s, 14.2205s/100 iters), loss = 0.698535
I0928 13:52:19.571741  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.698535 (* 1 = 0.698535 loss)
I0928 13:52:19.571763  4581 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I0928 13:52:33.795845  4581 solver.cpp:218] Iteration 2300 (7.03034 iter/s, 14.2241s/100 iters), loss = 0.670517
I0928 13:52:33.795876  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.670517 (* 1 = 0.670517 loss)
I0928 13:52:33.795886  4581 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I0928 13:52:48.013520  4581 solver.cpp:218] Iteration 2400 (7.03354 iter/s, 14.2176s/100 iters), loss = 0.57731
I0928 13:52:48.013552  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.57731 (* 1 = 0.57731 loss)
I0928 13:52:48.013571  4581 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I0928 13:53:01.524448  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:53:02.095151  4581 solver.cpp:330] Iteration 2500, Testing net (#0)
I0928 13:53:05.460330  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:53:05.601490  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4247
I0928 13:53:05.601518  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.86921 (* 1 = 1.86921 loss)
I0928 13:53:05.742249  4581 solver.cpp:218] Iteration 2500 (5.64059 iter/s, 17.7286s/100 iters), loss = 0.621658
I0928 13:53:05.742280  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.621658 (* 1 = 0.621658 loss)
I0928 13:53:05.742300  4581 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I0928 13:53:19.953668  4581 solver.cpp:218] Iteration 2600 (7.03667 iter/s, 14.2113s/100 iters), loss = 0.567522
I0928 13:53:19.953701  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.567522 (* 1 = 0.567522 loss)
I0928 13:53:19.953711  4581 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I0928 13:53:34.167621  4581 solver.cpp:218] Iteration 2700 (7.03538 iter/s, 14.2139s/100 iters), loss = 0.613742
I0928 13:53:34.167696  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.613742 (* 1 = 0.613742 loss)
I0928 13:53:34.167708  4581 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I0928 13:53:48.380515  4581 solver.cpp:218] Iteration 2800 (7.03593 iter/s, 14.2128s/100 iters), loss = 0.536691
I0928 13:53:48.380548  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.536691 (* 1 = 0.536691 loss)
I0928 13:53:48.380566  4581 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I0928 13:54:02.599160  4581 solver.cpp:218] Iteration 2900 (7.03306 iter/s, 14.2186s/100 iters), loss = 0.489669
I0928 13:54:02.599194  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.489669 (* 1 = 0.489669 loss)
I0928 13:54:02.599212  4581 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I0928 13:54:16.107709  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:54:16.677155  4581 solver.cpp:330] Iteration 3000, Testing net (#0)
I0928 13:54:20.041489  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:54:20.182184  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4665
I0928 13:54:20.182212  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.55572 (* 1 = 1.55572 loss)
I0928 13:54:20.323158  4581 solver.cpp:218] Iteration 3000 (5.6421 iter/s, 17.7239s/100 iters), loss = 0.565796
I0928 13:54:20.323189  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.565796 (* 1 = 0.565796 loss)
I0928 13:54:20.323197  4581 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I0928 13:54:34.544131  4581 solver.cpp:218] Iteration 3100 (7.03191 iter/s, 14.2209s/100 iters), loss = 0.473704
I0928 13:54:34.544163  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.473704 (* 1 = 0.473704 loss)
I0928 13:54:34.544179  4581 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I0928 13:54:48.763589  4581 solver.cpp:218] Iteration 3200 (7.03266 iter/s, 14.2194s/100 iters), loss = 0.512317
I0928 13:54:48.763679  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.512317 (* 1 = 0.512317 loss)
I0928 13:54:48.763698  4581 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I0928 13:55:02.989938  4581 solver.cpp:218] Iteration 3300 (7.02928 iter/s, 14.2262s/100 iters), loss = 0.583781
I0928 13:55:02.989969  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.583781 (* 1 = 0.583781 loss)
I0928 13:55:02.989986  4581 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I0928 13:55:17.210244  4581 solver.cpp:218] Iteration 3400 (7.03224 iter/s, 14.2202s/100 iters), loss = 0.467273
I0928 13:55:17.210275  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.467273 (* 1 = 0.467273 loss)
I0928 13:55:17.210292  4581 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I0928 13:55:30.725944  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:55:31.295873  4581 solver.cpp:330] Iteration 3500, Testing net (#0)
I0928 13:55:34.662034  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:55:34.802763  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5741
I0928 13:55:34.802799  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.23794 (* 1 = 1.23794 loss)
I0928 13:55:34.944521  4581 solver.cpp:218] Iteration 3500 (5.63883 iter/s, 17.7342s/100 iters), loss = 0.534377
I0928 13:55:34.944550  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.534377 (* 1 = 0.534377 loss)
I0928 13:55:34.944557  4581 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I0928 13:55:49.147786  4581 solver.cpp:218] Iteration 3600 (7.04067 iter/s, 14.2032s/100 iters), loss = 0.545812
I0928 13:55:49.147815  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.545812 (* 1 = 0.545812 loss)
I0928 13:55:49.147821  4581 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I0928 13:56:03.354835  4581 solver.cpp:218] Iteration 3700 (7.0388 iter/s, 14.207s/100 iters), loss = 0.471854
I0928 13:56:03.354915  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.471854 (* 1 = 0.471854 loss)
I0928 13:56:03.354933  4581 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I0928 13:56:17.560153  4581 solver.cpp:218] Iteration 3800 (7.03968 iter/s, 14.2052s/100 iters), loss = 0.577409
I0928 13:56:17.560184  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.577409 (* 1 = 0.577409 loss)
I0928 13:56:17.560191  4581 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I0928 13:56:31.771649  4581 solver.cpp:218] Iteration 3900 (7.0366 iter/s, 14.2114s/100 iters), loss = 0.404076
I0928 13:56:31.771682  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.404076 (* 1 = 0.404076 loss)
I0928 13:56:31.771697  4581 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I0928 13:56:45.279814  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:56:45.848973  4581 solver.cpp:330] Iteration 4000, Testing net (#0)
I0928 13:56:49.213135  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:56:49.353600  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5931
I0928 13:56:49.353636  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.08934 (* 1 = 1.08934 loss)
I0928 13:56:49.494726  4581 solver.cpp:218] Iteration 4000 (5.64239 iter/s, 17.723s/100 iters), loss = 0.461656
I0928 13:56:49.494755  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.461656 (* 1 = 0.461656 loss)
I0928 13:56:49.494761  4581 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I0928 13:57:03.720901  4581 solver.cpp:218] Iteration 4100 (7.02933 iter/s, 14.2261s/100 iters), loss = 0.414374
I0928 13:57:03.720943  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.414373 (* 1 = 0.414373 loss)
I0928 13:57:03.720949  4581 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I0928 13:57:17.946650  4581 solver.cpp:218] Iteration 4200 (7.02955 iter/s, 14.2257s/100 iters), loss = 0.361872
I0928 13:57:17.946779  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.361872 (* 1 = 0.361872 loss)
I0928 13:57:17.946797  4581 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I0928 13:57:32.174609  4581 solver.cpp:218] Iteration 4300 (7.02849 iter/s, 14.2278s/100 iters), loss = 0.407743
I0928 13:57:32.174650  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.407743 (* 1 = 0.407743 loss)
I0928 13:57:32.174657  4581 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I0928 13:57:46.405347  4581 solver.cpp:218] Iteration 4400 (7.02709 iter/s, 14.2306s/100 iters), loss = 0.454244
I0928 13:57:46.405388  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.454244 (* 1 = 0.454244 loss)
I0928 13:57:46.405395  4581 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I0928 13:57:59.926821  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:58:00.497664  4581 solver.cpp:330] Iteration 4500, Testing net (#0)
I0928 13:58:03.860496  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:58:04.001293  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6606
I0928 13:58:04.001329  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.947161 (* 1 = 0.947161 loss)
I0928 13:58:04.142530  4581 solver.cpp:218] Iteration 4500 (5.63791 iter/s, 17.7371s/100 iters), loss = 0.38772
I0928 13:58:04.142568  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.38772 (* 1 = 0.38772 loss)
I0928 13:58:04.142575  4581 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I0928 13:58:18.345291  4581 solver.cpp:218] Iteration 4600 (7.04093 iter/s, 14.2027s/100 iters), loss = 0.377784
I0928 13:58:18.345322  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.377784 (* 1 = 0.377784 loss)
I0928 13:58:18.345330  4581 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I0928 13:58:32.552974  4581 solver.cpp:218] Iteration 4700 (7.03848 iter/s, 14.2076s/100 iters), loss = 0.476832
I0928 13:58:32.553098  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.476832 (* 1 = 0.476832 loss)
I0928 13:58:32.553105  4581 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I0928 13:58:46.761420  4581 solver.cpp:218] Iteration 4800 (7.03815 iter/s, 14.2083s/100 iters), loss = 0.415732
I0928 13:58:46.761449  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.415732 (* 1 = 0.415732 loss)
I0928 13:58:46.761456  4581 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I0928 13:59:00.973408  4581 solver.cpp:218] Iteration 4900 (7.03635 iter/s, 14.2119s/100 iters), loss = 0.369548
I0928 13:59:00.973439  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.369548 (* 1 = 0.369548 loss)
I0928 13:59:00.973448  4581 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I0928 13:59:14.476339  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:59:15.045243  4581 solver.cpp:330] Iteration 5000, Testing net (#0)
I0928 13:59:18.410204  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:59:18.550730  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6456
I0928 13:59:18.550765  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.00597 (* 1 = 1.00597 loss)
I0928 13:59:18.691892  4581 solver.cpp:218] Iteration 5000 (5.64385 iter/s, 17.7184s/100 iters), loss = 0.444648
I0928 13:59:18.691921  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.444648 (* 1 = 0.444648 loss)
I0928 13:59:18.691927  4581 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I0928 13:59:32.902205  4581 solver.cpp:218] Iteration 5100 (7.03718 iter/s, 14.2102s/100 iters), loss = 0.372918
I0928 13:59:32.902237  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.372918 (* 1 = 0.372918 loss)
I0928 13:59:32.902254  4581 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I0928 13:59:47.113129  4581 solver.cpp:218] Iteration 5200 (7.03688 iter/s, 14.2108s/100 iters), loss = 0.338378
I0928 13:59:47.113281  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338378 (* 1 = 0.338378 loss)
I0928 13:59:47.113298  4581 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I0928 14:00:01.326098  4581 solver.cpp:218] Iteration 5300 (7.03592 iter/s, 14.2128s/100 iters), loss = 0.388071
I0928 14:00:01.326128  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.388071 (* 1 = 0.388071 loss)
I0928 14:00:01.326133  4581 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I0928 14:00:15.532881  4581 solver.cpp:218] Iteration 5400 (7.03893 iter/s, 14.2067s/100 iters), loss = 0.466244
I0928 14:00:15.532912  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.466244 (* 1 = 0.466244 loss)
I0928 14:00:15.532918  4581 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I0928 14:00:29.030751  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:00:29.597839  4581 solver.cpp:330] Iteration 5500, Testing net (#0)
I0928 14:00:32.962363  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:00:33.103080  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6528
I0928 14:00:33.103116  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.940572 (* 1 = 0.940572 loss)
I0928 14:00:33.244107  4581 solver.cpp:218] Iteration 5500 (5.64616 iter/s, 17.7111s/100 iters), loss = 0.36486
I0928 14:00:33.244134  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.36486 (* 1 = 0.36486 loss)
I0928 14:00:33.244141  4581 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I0928 14:00:47.444198  4581 solver.cpp:218] Iteration 5600 (7.04224 iter/s, 14.2s/100 iters), loss = 0.419101
I0928 14:00:47.444238  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.419101 (* 1 = 0.419101 loss)
I0928 14:00:47.444244  4581 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I0928 14:01:01.664374  4581 solver.cpp:218] Iteration 5700 (7.0323 iter/s, 14.2201s/100 iters), loss = 0.348259
I0928 14:01:01.664474  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.348259 (* 1 = 0.348259 loss)
I0928 14:01:01.664480  4581 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I0928 14:01:15.874056  4581 solver.cpp:218] Iteration 5800 (7.03753 iter/s, 14.2095s/100 iters), loss = 0.510902
I0928 14:01:15.874086  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.510902 (* 1 = 0.510902 loss)
I0928 14:01:15.874092  4581 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I0928 14:01:30.085680  4581 solver.cpp:218] Iteration 5900 (7.03653 iter/s, 14.2116s/100 iters), loss = 0.472891
I0928 14:01:30.085721  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.472891 (* 1 = 0.472891 loss)
I0928 14:01:30.085726  4581 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I0928 14:01:43.590322  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:01:44.158947  4581 solver.cpp:330] Iteration 6000, Testing net (#0)
I0928 14:01:47.523664  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:01:47.664062  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6979
I0928 14:01:47.664098  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.870572 (* 1 = 0.870572 loss)
I0928 14:01:47.805167  4581 solver.cpp:218] Iteration 6000 (5.64353 iter/s, 17.7194s/100 iters), loss = 0.380325
I0928 14:01:47.805196  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.380324 (* 1 = 0.380324 loss)
I0928 14:01:47.805202  4581 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I0928 14:02:02.006189  4581 solver.cpp:218] Iteration 6100 (7.04178 iter/s, 14.201s/100 iters), loss = 0.36705
I0928 14:02:02.006229  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.36705 (* 1 = 0.36705 loss)
I0928 14:02:02.006235  4581 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I0928 14:02:16.212409  4581 solver.cpp:218] Iteration 6200 (7.03921 iter/s, 14.2061s/100 iters), loss = 0.282888
I0928 14:02:16.212492  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282888 (* 1 = 0.282888 loss)
I0928 14:02:16.212501  4581 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I0928 14:02:30.419332  4581 solver.cpp:218] Iteration 6300 (7.03888 iter/s, 14.2068s/100 iters), loss = 0.405186
I0928 14:02:30.419373  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405186 (* 1 = 0.405186 loss)
I0928 14:02:30.419378  4581 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I0928 14:02:44.624305  4581 solver.cpp:218] Iteration 6400 (7.03983 iter/s, 14.2049s/100 iters), loss = 0.327848
I0928 14:02:44.624344  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327848 (* 1 = 0.327848 loss)
I0928 14:02:44.624351  4581 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I0928 14:02:58.123459  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:02:58.691478  4581 solver.cpp:330] Iteration 6500, Testing net (#0)
I0928 14:03:02.055069  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:03:02.195597  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7001
I0928 14:03:02.195634  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.861848 (* 1 = 0.861848 loss)
I0928 14:03:02.336547  4581 solver.cpp:218] Iteration 6500 (5.64584 iter/s, 17.7122s/100 iters), loss = 0.350101
I0928 14:03:02.336576  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350101 (* 1 = 0.350101 loss)
I0928 14:03:02.336583  4581 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I0928 14:03:16.545930  4581 solver.cpp:218] Iteration 6600 (7.03764 iter/s, 14.2093s/100 iters), loss = 0.311046
I0928 14:03:16.545970  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311046 (* 1 = 0.311046 loss)
I0928 14:03:16.545976  4581 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I0928 14:03:30.761415  4581 solver.cpp:218] Iteration 6700 (7.03462 iter/s, 14.2154s/100 iters), loss = 0.339011
I0928 14:03:30.761526  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.339011 (* 1 = 0.339011 loss)
I0928 14:03:30.761533  4581 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I0928 14:03:44.976980  4581 solver.cpp:218] Iteration 6800 (7.03462 iter/s, 14.2154s/100 iters), loss = 0.317956
I0928 14:03:44.977011  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317956 (* 1 = 0.317956 loss)
I0928 14:03:44.977017  4581 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I0928 14:03:59.190515  4581 solver.cpp:218] Iteration 6900 (7.03558 iter/s, 14.2135s/100 iters), loss = 0.24046
I0928 14:03:59.190557  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24046 (* 1 = 0.24046 loss)
I0928 14:03:59.190562  4581 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I0928 14:04:12.691082  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:04:13.260366  4581 solver.cpp:330] Iteration 7000, Testing net (#0)
I0928 14:04:16.622666  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:04:16.763253  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.754
I0928 14:04:16.763289  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.691398 (* 1 = 0.691398 loss)
I0928 14:04:16.904147  4581 solver.cpp:218] Iteration 7000 (5.6454 iter/s, 17.7135s/100 iters), loss = 0.358554
I0928 14:04:16.904175  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.358554 (* 1 = 0.358554 loss)
I0928 14:04:16.904181  4581 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I0928 14:04:31.098646  4581 solver.cpp:218] Iteration 7100 (7.04502 iter/s, 14.1944s/100 iters), loss = 0.319252
I0928 14:04:31.098676  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319252 (* 1 = 0.319252 loss)
I0928 14:04:31.098682  4581 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I0928 14:04:45.297821  4581 solver.cpp:218] Iteration 7200 (7.0427 iter/s, 14.1991s/100 iters), loss = 0.436926
I0928 14:04:45.297968  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.436925 (* 1 = 0.436925 loss)
I0928 14:04:45.297987  4581 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I0928 14:04:59.498317  4581 solver.cpp:218] Iteration 7300 (7.0421 iter/s, 14.2003s/100 iters), loss = 0.433993
I0928 14:04:59.498347  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.433993 (* 1 = 0.433993 loss)
I0928 14:04:59.498353  4581 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I0928 14:05:13.702678  4581 solver.cpp:218] Iteration 7400 (7.04013 iter/s, 14.2043s/100 iters), loss = 0.225899
I0928 14:05:13.702708  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225899 (* 1 = 0.225899 loss)
I0928 14:05:13.702714  4581 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I0928 14:05:27.196748  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:05:27.764858  4581 solver.cpp:330] Iteration 7500, Testing net (#0)
I0928 14:05:31.130810  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:05:31.271569  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7277
I0928 14:05:31.271605  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.78751 (* 1 = 0.78751 loss)
I0928 14:05:31.412299  4581 solver.cpp:218] Iteration 7500 (5.64667 iter/s, 17.7095s/100 iters), loss = 0.320968
I0928 14:05:31.412328  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320968 (* 1 = 0.320968 loss)
I0928 14:05:31.412334  4581 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I0928 14:05:45.619923  4581 solver.cpp:218] Iteration 7600 (7.03851 iter/s, 14.2076s/100 iters), loss = 0.405019
I0928 14:05:45.619963  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405019 (* 1 = 0.405019 loss)
I0928 14:05:45.619969  4581 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I0928 14:05:59.837704  4581 solver.cpp:218] Iteration 7700 (7.03349 iter/s, 14.2177s/100 iters), loss = 0.267516
I0928 14:05:59.837785  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267516 (* 1 = 0.267516 loss)
I0928 14:05:59.837800  4581 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I0928 14:06:14.050809  4581 solver.cpp:218] Iteration 7800 (7.03582 iter/s, 14.213s/100 iters), loss = 0.378711
I0928 14:06:14.050838  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378711 (* 1 = 0.378711 loss)
I0928 14:06:14.050845  4581 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I0928 14:06:28.259692  4581 solver.cpp:218] Iteration 7900 (7.03789 iter/s, 14.2088s/100 iters), loss = 0.274221
I0928 14:06:28.259722  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274221 (* 1 = 0.274221 loss)
I0928 14:06:28.259728  4581 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I0928 14:06:41.763437  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:06:42.331504  4581 solver.cpp:330] Iteration 8000, Testing net (#0)
I0928 14:06:45.697022  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:06:45.838099  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7128
I0928 14:06:45.838136  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.844633 (* 1 = 0.844633 loss)
I0928 14:06:45.978842  4581 solver.cpp:218] Iteration 8000 (5.64364 iter/s, 17.7191s/100 iters), loss = 0.344322
I0928 14:06:45.978870  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344321 (* 1 = 0.344321 loss)
I0928 14:06:45.978876  4581 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I0928 14:07:00.182207  4581 solver.cpp:218] Iteration 8100 (7.04062 iter/s, 14.2033s/100 iters), loss = 0.270268
I0928 14:07:00.182247  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270268 (* 1 = 0.270268 loss)
I0928 14:07:00.182253  4581 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I0928 14:07:14.388362  4581 solver.cpp:218] Iteration 8200 (7.03925 iter/s, 14.2061s/100 iters), loss = 0.337236
I0928 14:07:14.388471  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337236 (* 1 = 0.337236 loss)
I0928 14:07:14.388479  4581 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I0928 14:07:28.596951  4581 solver.cpp:218] Iteration 8300 (7.03807 iter/s, 14.2084s/100 iters), loss = 0.299228
I0928 14:07:28.596992  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299228 (* 1 = 0.299228 loss)
I0928 14:07:28.596999  4581 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I0928 14:07:42.805994  4581 solver.cpp:218] Iteration 8400 (7.03781 iter/s, 14.209s/100 iters), loss = 0.321845
I0928 14:07:42.806035  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.321845 (* 1 = 0.321845 loss)
I0928 14:07:42.806041  4581 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I0928 14:07:56.307071  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:07:56.876516  4581 solver.cpp:330] Iteration 8500, Testing net (#0)
I0928 14:08:00.241732  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:08:00.382542  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7462
I0928 14:08:00.382580  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.799065 (* 1 = 0.799065 loss)
I0928 14:08:00.522927  4581 solver.cpp:218] Iteration 8500 (5.64435 iter/s, 17.7168s/100 iters), loss = 0.286867
I0928 14:08:00.522956  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286867 (* 1 = 0.286867 loss)
I0928 14:08:00.522964  4581 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I0928 14:08:14.723194  4581 solver.cpp:218] Iteration 8600 (7.04216 iter/s, 14.2002s/100 iters), loss = 0.280451
I0928 14:08:14.723235  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280451 (* 1 = 0.280451 loss)
I0928 14:08:14.723242  4581 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I0928 14:08:28.929970  4581 solver.cpp:218] Iteration 8700 (7.03894 iter/s, 14.2067s/100 iters), loss = 0.27589
I0928 14:08:28.930053  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27589 (* 1 = 0.27589 loss)
I0928 14:08:28.930069  4581 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I0928 14:08:43.128721  4581 solver.cpp:218] Iteration 8800 (7.04293 iter/s, 14.1986s/100 iters), loss = 0.262859
I0928 14:08:43.128762  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262859 (* 1 = 0.262859 loss)
I0928 14:08:43.128769  4581 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I0928 14:08:57.336096  4581 solver.cpp:218] Iteration 8900 (7.03864 iter/s, 14.2073s/100 iters), loss = 0.285985
I0928 14:08:57.336136  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285985 (* 1 = 0.285985 loss)
I0928 14:08:57.336143  4581 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I0928 14:09:10.836372  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:09:11.406006  4581 solver.cpp:330] Iteration 9000, Testing net (#0)
I0928 14:09:14.771795  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:09:14.912786  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7641
I0928 14:09:14.912812  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.707066 (* 1 = 0.707066 loss)
I0928 14:09:15.054181  4581 solver.cpp:218] Iteration 9000 (5.64398 iter/s, 17.718s/100 iters), loss = 0.280828
I0928 14:09:15.054220  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280828 (* 1 = 0.280828 loss)
I0928 14:09:15.054239  4581 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I0928 14:09:29.276624  4581 solver.cpp:218] Iteration 9100 (7.03123 iter/s, 14.2223s/100 iters), loss = 0.247817
I0928 14:09:29.276655  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247816 (* 1 = 0.247816 loss)
I0928 14:09:29.276662  4581 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I0928 14:09:43.497449  4581 solver.cpp:218] Iteration 9200 (7.03198 iter/s, 14.2208s/100 iters), loss = 0.392004
I0928 14:09:43.497534  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.392004 (* 1 = 0.392004 loss)
I0928 14:09:43.497550  4581 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I0928 14:09:57.720549  4581 solver.cpp:218] Iteration 9300 (7.03088 iter/s, 14.223s/100 iters), loss = 0.279719
I0928 14:09:57.720588  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279719 (* 1 = 0.279719 loss)
I0928 14:09:57.720595  4581 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I0928 14:10:11.945137  4581 solver.cpp:218] Iteration 9400 (7.03012 iter/s, 14.2245s/100 iters), loss = 0.329675
I0928 14:10:11.945178  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329675 (* 1 = 0.329675 loss)
I0928 14:10:11.945184  4581 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I0928 14:10:25.462704  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:10:26.031553  4581 solver.cpp:330] Iteration 9500, Testing net (#0)
I0928 14:10:29.396798  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:10:29.537518  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.704
I0928 14:10:29.537544  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.921042 (* 1 = 0.921042 loss)
I0928 14:10:29.679641  4581 solver.cpp:218] Iteration 9500 (5.63875 iter/s, 17.7344s/100 iters), loss = 0.330835
I0928 14:10:29.679669  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330835 (* 1 = 0.330835 loss)
I0928 14:10:29.679677  4581 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I0928 14:10:43.881522  4581 solver.cpp:218] Iteration 9600 (7.04137 iter/s, 14.2018s/100 iters), loss = 0.220908
I0928 14:10:43.881562  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220907 (* 1 = 0.220907 loss)
I0928 14:10:43.881568  4581 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I0928 14:10:58.086107  4581 solver.cpp:218] Iteration 9700 (7.04002 iter/s, 14.2045s/100 iters), loss = 0.393063
I0928 14:10:58.086174  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.393063 (* 1 = 0.393063 loss)
I0928 14:10:58.086180  4581 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I0928 14:11:12.291200  4581 solver.cpp:218] Iteration 9800 (7.03978 iter/s, 14.205s/100 iters), loss = 0.26585
I0928 14:11:12.291230  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26585 (* 1 = 0.26585 loss)
I0928 14:11:12.291236  4581 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I0928 14:11:26.497056  4581 solver.cpp:218] Iteration 9900 (7.03938 iter/s, 14.2058s/100 iters), loss = 0.276601
I0928 14:11:26.497097  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276601 (* 1 = 0.276601 loss)
I0928 14:11:26.497102  4581 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I0928 14:11:39.999653  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:11:40.566993  4581 solver.cpp:330] Iteration 10000, Testing net (#0)
I0928 14:11:43.936780  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:11:44.078057  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6938
I0928 14:11:44.078091  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.07789 (* 1 = 1.07789 loss)
I0928 14:11:44.219856  4581 solver.cpp:218] Iteration 10000 (5.64248 iter/s, 17.7227s/100 iters), loss = 0.236184
I0928 14:11:44.219884  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236184 (* 1 = 0.236184 loss)
I0928 14:11:44.219890  4581 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I0928 14:11:58.460352  4581 solver.cpp:218] Iteration 10100 (7.02226 iter/s, 14.2404s/100 iters), loss = 0.247285
I0928 14:11:58.460394  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247285 (* 1 = 0.247285 loss)
I0928 14:11:58.460399  4581 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I0928 14:12:12.704588  4581 solver.cpp:218] Iteration 10200 (7.02042 iter/s, 14.2442s/100 iters), loss = 0.254609
I0928 14:12:12.704653  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254609 (* 1 = 0.254609 loss)
I0928 14:12:12.704659  4581 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I0928 14:12:26.945561  4581 solver.cpp:218] Iteration 10300 (7.02204 iter/s, 14.2409s/100 iters), loss = 0.345931
I0928 14:12:26.945602  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.345931 (* 1 = 0.345931 loss)
I0928 14:12:26.945608  4581 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I0928 14:12:41.188845  4581 solver.cpp:218] Iteration 10400 (7.02089 iter/s, 14.2432s/100 iters), loss = 0.304559
I0928 14:12:41.188886  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304558 (* 1 = 0.304558 loss)
I0928 14:12:41.188892  4581 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I0928 14:12:54.720561  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:12:55.290359  4581 solver.cpp:330] Iteration 10500, Testing net (#0)
I0928 14:12:58.660765  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:12:58.801750  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5872
I0928 14:12:58.801787  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.57903 (* 1 = 1.57903 loss)
I0928 14:12:58.944352  4581 solver.cpp:218] Iteration 10500 (5.63208 iter/s, 17.7554s/100 iters), loss = 0.20753
I0928 14:12:58.944383  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20753 (* 1 = 0.20753 loss)
I0928 14:12:58.944391  4581 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I0928 14:13:13.175817  4581 solver.cpp:218] Iteration 10600 (7.02672 iter/s, 14.2314s/100 iters), loss = 0.268624
I0928 14:13:13.175856  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268624 (* 1 = 0.268624 loss)
I0928 14:13:13.175863  4581 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I0928 14:13:27.411053  4581 solver.cpp:218] Iteration 10700 (7.02486 iter/s, 14.2352s/100 iters), loss = 0.372549
I0928 14:13:27.411162  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.372549 (* 1 = 0.372549 loss)
I0928 14:13:27.411170  4581 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I0928 14:13:41.643177  4581 solver.cpp:218] Iteration 10800 (7.02643 iter/s, 14.232s/100 iters), loss = 0.341507
I0928 14:13:41.643218  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.341506 (* 1 = 0.341506 loss)
I0928 14:13:41.643224  4581 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I0928 14:13:55.878142  4581 solver.cpp:218] Iteration 10900 (7.025 iter/s, 14.2349s/100 iters), loss = 0.235802
I0928 14:13:55.878183  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235801 (* 1 = 0.235801 loss)
I0928 14:13:55.878190  4581 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I0928 14:14:09.408473  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:14:09.977026  4581 solver.cpp:330] Iteration 11000, Testing net (#0)
I0928 14:14:13.345304  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:14:13.486153  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7548
I0928 14:14:13.486191  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.833655 (* 1 = 0.833655 loss)
I0928 14:14:13.627782  4581 solver.cpp:218] Iteration 11000 (5.63395 iter/s, 17.7495s/100 iters), loss = 0.204501
I0928 14:14:13.627811  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204501 (* 1 = 0.204501 loss)
I0928 14:14:13.627818  4581 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I0928 14:14:27.854796  4581 solver.cpp:218] Iteration 11100 (7.02892 iter/s, 14.2269s/100 iters), loss = 0.350089
I0928 14:14:27.854837  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350089 (* 1 = 0.350089 loss)
I0928 14:14:27.854843  4581 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I0928 14:14:42.080925  4581 solver.cpp:218] Iteration 11200 (7.02936 iter/s, 14.226s/100 iters), loss = 0.299745
I0928 14:14:42.081053  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299744 (* 1 = 0.299744 loss)
I0928 14:14:42.081059  4581 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I0928 14:14:56.307922  4581 solver.cpp:218] Iteration 11300 (7.02897 iter/s, 14.2268s/100 iters), loss = 0.23192
I0928 14:14:56.307962  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23192 (* 1 = 0.23192 loss)
I0928 14:14:56.307968  4581 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I0928 14:15:10.538894  4581 solver.cpp:218] Iteration 11400 (7.02697 iter/s, 14.2309s/100 iters), loss = 0.215863
I0928 14:15:10.538935  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215863 (* 1 = 0.215863 loss)
I0928 14:15:10.538941  4581 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I0928 14:15:24.061060  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:15:24.630550  4581 solver.cpp:330] Iteration 11500, Testing net (#0)
I0928 14:15:28.000301  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:15:28.140694  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7338
I0928 14:15:28.140730  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.83401 (* 1 = 0.83401 loss)
I0928 14:15:28.281689  4581 solver.cpp:218] Iteration 11500 (5.63612 iter/s, 17.7427s/100 iters), loss = 0.284676
I0928 14:15:28.281718  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284676 (* 1 = 0.284676 loss)
I0928 14:15:28.281725  4581 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I0928 14:15:42.524927  4581 solver.cpp:218] Iteration 11600 (7.02091 iter/s, 14.2432s/100 iters), loss = 0.351037
I0928 14:15:42.524967  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351037 (* 1 = 0.351037 loss)
I0928 14:15:42.524973  4581 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I0928 14:15:56.770989  4581 solver.cpp:218] Iteration 11700 (7.01952 iter/s, 14.246s/100 iters), loss = 0.334505
I0928 14:15:56.771116  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.334505 (* 1 = 0.334505 loss)
I0928 14:15:56.771133  4581 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I0928 14:16:11.014052  4581 solver.cpp:218] Iteration 11800 (7.02104 iter/s, 14.2429s/100 iters), loss = 0.285226
I0928 14:16:11.014092  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285225 (* 1 = 0.285225 loss)
I0928 14:16:11.014099  4581 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I0928 14:16:25.258628  4581 solver.cpp:218] Iteration 11900 (7.02026 iter/s, 14.2445s/100 iters), loss = 0.23046
I0928 14:16:25.258669  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230459 (* 1 = 0.230459 loss)
I0928 14:16:25.258675  4581 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I0928 14:16:38.792044  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:16:39.363554  4581 solver.cpp:330] Iteration 12000, Testing net (#0)
I0928 14:16:42.732352  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:16:42.873193  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6752
I0928 14:16:42.873229  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.17965 (* 1 = 1.17965 loss)
I0928 14:16:43.015522  4581 solver.cpp:218] Iteration 12000 (5.63164 iter/s, 17.7568s/100 iters), loss = 0.231474
I0928 14:16:43.015553  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231474 (* 1 = 0.231474 loss)
I0928 14:16:43.015559  4581 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I0928 14:16:57.244447  4581 solver.cpp:218] Iteration 12100 (7.02797 iter/s, 14.2289s/100 iters), loss = 0.271701
I0928 14:16:57.244488  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271701 (* 1 = 0.271701 loss)
I0928 14:16:57.244494  4581 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I0928 14:17:11.479842  4581 solver.cpp:218] Iteration 12200 (7.02478 iter/s, 14.2353s/100 iters), loss = 0.305691
I0928 14:17:11.479914  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305691 (* 1 = 0.305691 loss)
I0928 14:17:11.479921  4581 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I0928 14:17:25.708614  4581 solver.cpp:218] Iteration 12300 (7.02807 iter/s, 14.2287s/100 iters), loss = 0.228902
I0928 14:17:25.708654  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228902 (* 1 = 0.228902 loss)
I0928 14:17:25.708660  4581 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I0928 14:17:39.942672  4581 solver.cpp:218] Iteration 12400 (7.02544 iter/s, 14.234s/100 iters), loss = 0.212882
I0928 14:17:39.942713  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212882 (* 1 = 0.212882 loss)
I0928 14:17:39.942718  4581 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I0928 14:17:53.467361  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:17:54.036581  4581 solver.cpp:330] Iteration 12500, Testing net (#0)
I0928 14:17:57.407882  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:17:57.548684  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6796
I0928 14:17:57.548720  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.05535 (* 1 = 1.05535 loss)
I0928 14:17:57.689903  4581 solver.cpp:218] Iteration 12500 (5.63471 iter/s, 17.7471s/100 iters), loss = 0.231794
I0928 14:17:57.689932  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231794 (* 1 = 0.231794 loss)
I0928 14:17:57.689939  4581 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I0928 14:18:11.926107  4581 solver.cpp:218] Iteration 12600 (7.02438 iter/s, 14.2361s/100 iters), loss = 0.230888
I0928 14:18:11.926148  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230888 (* 1 = 0.230888 loss)
I0928 14:18:11.926154  4581 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I0928 14:18:26.163589  4581 solver.cpp:218] Iteration 12700 (7.02375 iter/s, 14.2374s/100 iters), loss = 0.342169
I0928 14:18:26.163707  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342169 (* 1 = 0.342169 loss)
I0928 14:18:26.163724  4581 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I0928 14:18:40.405409  4581 solver.cpp:218] Iteration 12800 (7.02165 iter/s, 14.2417s/100 iters), loss = 0.24354
I0928 14:18:40.405449  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24354 (* 1 = 0.24354 loss)
I0928 14:18:40.405455  4581 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I0928 14:18:54.649150  4581 solver.cpp:218] Iteration 12900 (7.02067 iter/s, 14.2437s/100 iters), loss = 0.25555
I0928 14:18:54.649191  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25555 (* 1 = 0.25555 loss)
I0928 14:18:54.649197  4581 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I0928 14:19:08.180831  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:19:08.750010  4581 solver.cpp:330] Iteration 13000, Testing net (#0)
I0928 14:19:12.120844  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:19:12.261934  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7536
I0928 14:19:12.261970  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.799763 (* 1 = 0.799763 loss)
I0928 14:19:12.403368  4581 solver.cpp:218] Iteration 13000 (5.63249 iter/s, 17.7541s/100 iters), loss = 0.220595
I0928 14:19:12.403396  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220595 (* 1 = 0.220595 loss)
I0928 14:19:12.403403  4581 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I0928 14:19:26.639817  4581 solver.cpp:218] Iteration 13100 (7.02426 iter/s, 14.2364s/100 iters), loss = 0.235336
I0928 14:19:26.639858  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235336 (* 1 = 0.235336 loss)
I0928 14:19:26.639863  4581 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I0928 14:19:40.874529  4581 solver.cpp:218] Iteration 13200 (7.02512 iter/s, 14.2346s/100 iters), loss = 0.273232
I0928 14:19:40.874665  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273232 (* 1 = 0.273232 loss)
I0928 14:19:40.874673  4581 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I0928 14:19:55.109885  4581 solver.cpp:218] Iteration 13300 (7.02484 iter/s, 14.2352s/100 iters), loss = 0.288985
I0928 14:19:55.109925  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288985 (* 1 = 0.288985 loss)
I0928 14:19:55.109931  4581 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I0928 14:20:09.344458  4581 solver.cpp:218] Iteration 13400 (7.02519 iter/s, 14.2345s/100 iters), loss = 0.306925
I0928 14:20:09.344498  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306925 (* 1 = 0.306925 loss)
I0928 14:20:09.344504  4581 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I0928 14:20:22.873174  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:20:23.443322  4581 solver.cpp:330] Iteration 13500, Testing net (#0)
I0928 14:20:26.814505  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:20:26.955343  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.649
I0928 14:20:26.955368  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.05098 (* 1 = 1.05098 loss)
I0928 14:20:27.097460  4581 solver.cpp:218] Iteration 13500 (5.63288 iter/s, 17.7529s/100 iters), loss = 0.157763
I0928 14:20:27.097489  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157763 (* 1 = 0.157763 loss)
I0928 14:20:27.097496  4581 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I0928 14:20:41.320772  4581 solver.cpp:218] Iteration 13600 (7.03075 iter/s, 14.2232s/100 iters), loss = 0.263159
I0928 14:20:41.320813  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263159 (* 1 = 0.263159 loss)
I0928 14:20:41.320819  4581 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I0928 14:20:55.545946  4581 solver.cpp:218] Iteration 13700 (7.02983 iter/s, 14.2251s/100 iters), loss = 0.272387
I0928 14:20:55.546012  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272387 (* 1 = 0.272387 loss)
I0928 14:20:55.546020  4581 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I0928 14:21:09.777251  4581 solver.cpp:218] Iteration 13800 (7.02682 iter/s, 14.2312s/100 iters), loss = 0.231937
I0928 14:21:09.777290  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231937 (* 1 = 0.231937 loss)
I0928 14:21:09.777297  4581 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I0928 14:21:24.003662  4581 solver.cpp:218] Iteration 13900 (7.02922 iter/s, 14.2263s/100 iters), loss = 0.188421
I0928 14:21:24.003702  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188421 (* 1 = 0.188421 loss)
I0928 14:21:24.003708  4581 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I0928 14:21:37.525696  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:21:38.094385  4581 solver.cpp:330] Iteration 14000, Testing net (#0)
I0928 14:21:41.465708  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:21:41.606566  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4952
I0928 14:21:41.606603  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.40066 (* 1 = 2.40066 loss)
I0928 14:21:41.748126  4581 solver.cpp:218] Iteration 14000 (5.63559 iter/s, 17.7444s/100 iters), loss = 0.246418
I0928 14:21:41.748155  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246418 (* 1 = 0.246418 loss)
I0928 14:21:41.748163  4581 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I0928 14:21:55.979827  4581 solver.cpp:218] Iteration 14100 (7.0266 iter/s, 14.2316s/100 iters), loss = 0.27178
I0928 14:21:55.979856  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27178 (* 1 = 0.27178 loss)
I0928 14:21:55.979862  4581 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I0928 14:22:10.214711  4581 solver.cpp:218] Iteration 14200 (7.02503 iter/s, 14.2348s/100 iters), loss = 0.312342
I0928 14:22:10.214810  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312342 (* 1 = 0.312342 loss)
I0928 14:22:10.214818  4581 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I0928 14:22:24.444968  4581 solver.cpp:218] Iteration 14300 (7.02734 iter/s, 14.2301s/100 iters), loss = 0.220255
I0928 14:22:24.445008  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220255 (* 1 = 0.220255 loss)
I0928 14:22:24.445014  4581 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I0928 14:22:38.676604  4581 solver.cpp:218] Iteration 14400 (7.02664 iter/s, 14.2316s/100 iters), loss = 0.178302
I0928 14:22:38.676645  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178302 (* 1 = 0.178302 loss)
I0928 14:22:38.676651  4581 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I0928 14:22:52.204406  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:22:52.773788  4581 solver.cpp:330] Iteration 14500, Testing net (#0)
I0928 14:22:56.145864  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:22:56.286602  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7602
I0928 14:22:56.286628  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.751806 (* 1 = 0.751806 loss)
I0928 14:22:56.429004  4581 solver.cpp:218] Iteration 14500 (5.63307 iter/s, 17.7523s/100 iters), loss = 0.177563
I0928 14:22:56.429034  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177563 (* 1 = 0.177563 loss)
I0928 14:22:56.429041  4581 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I0928 14:23:10.659611  4581 solver.cpp:218] Iteration 14600 (7.02714 iter/s, 14.2305s/100 iters), loss = 0.28124
I0928 14:23:10.659652  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28124 (* 1 = 0.28124 loss)
I0928 14:23:10.659658  4581 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I0928 14:23:24.890848  4581 solver.cpp:218] Iteration 14700 (7.02684 iter/s, 14.2312s/100 iters), loss = 0.184437
I0928 14:23:24.890913  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184437 (* 1 = 0.184437 loss)
I0928 14:23:24.890920  4581 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I0928 14:23:39.122934  4581 solver.cpp:218] Iteration 14800 (7.02643 iter/s, 14.232s/100 iters), loss = 0.270555
I0928 14:23:39.122975  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270555 (* 1 = 0.270555 loss)
I0928 14:23:39.122982  4581 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I0928 14:23:53.353914  4581 solver.cpp:218] Iteration 14900 (7.02697 iter/s, 14.2309s/100 iters), loss = 0.204146
I0928 14:23:53.353953  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204146 (* 1 = 0.204146 loss)
I0928 14:23:53.353960  4581 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I0928 14:24:06.879161  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:24:07.449546  4581 solver.cpp:330] Iteration 15000, Testing net (#0)
I0928 14:24:10.819370  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:24:10.960324  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7969
I0928 14:24:10.960360  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.595136 (* 1 = 0.595136 loss)
I0928 14:24:11.102625  4581 solver.cpp:218] Iteration 15000 (5.63424 iter/s, 17.7486s/100 iters), loss = 0.193902
I0928 14:24:11.102654  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193902 (* 1 = 0.193902 loss)
I0928 14:24:11.102661  4581 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I0928 14:24:25.326162  4581 solver.cpp:218] Iteration 15100 (7.03063 iter/s, 14.2235s/100 iters), loss = 0.228178
I0928 14:24:25.326203  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228178 (* 1 = 0.228178 loss)
I0928 14:24:25.326210  4581 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I0928 14:24:39.552294  4581 solver.cpp:218] Iteration 15200 (7.02936 iter/s, 14.226s/100 iters), loss = 0.222801
I0928 14:24:39.552392  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222801 (* 1 = 0.222801 loss)
I0928 14:24:39.552399  4581 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I0928 14:24:53.778059  4581 solver.cpp:218] Iteration 15300 (7.02956 iter/s, 14.2256s/100 iters), loss = 0.215231
I0928 14:24:53.778100  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215231 (* 1 = 0.215231 loss)
I0928 14:24:53.778106  4581 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I0928 14:25:08.007791  4581 solver.cpp:218] Iteration 15400 (7.02758 iter/s, 14.2296s/100 iters), loss = 0.226361
I0928 14:25:08.007833  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226361 (* 1 = 0.226361 loss)
I0928 14:25:08.007838  4581 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I0928 14:25:21.529345  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:25:22.098465  4581 solver.cpp:330] Iteration 15500, Testing net (#0)
I0928 14:25:25.469334  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:25:25.610390  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7559
I0928 14:25:25.610426  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.820955 (* 1 = 0.820955 loss)
I0928 14:25:25.752276  4581 solver.cpp:218] Iteration 15500 (5.63558 iter/s, 17.7444s/100 iters), loss = 0.19043
I0928 14:25:25.752305  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19043 (* 1 = 0.19043 loss)
I0928 14:25:25.752312  4581 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I0928 14:25:39.983129  4581 solver.cpp:218] Iteration 15600 (7.02702 iter/s, 14.2308s/100 iters), loss = 0.269674
I0928 14:25:39.983170  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269674 (* 1 = 0.269674 loss)
I0928 14:25:39.983176  4581 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I0928 14:25:54.216478  4581 solver.cpp:218] Iteration 15700 (7.0258 iter/s, 14.2333s/100 iters), loss = 0.275564
I0928 14:25:54.216572  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275564 (* 1 = 0.275564 loss)
I0928 14:25:54.216579  4581 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I0928 14:26:08.452553  4581 solver.cpp:218] Iteration 15800 (7.02447 iter/s, 14.2359s/100 iters), loss = 0.220548
I0928 14:26:08.452594  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220548 (* 1 = 0.220548 loss)
I0928 14:26:08.452600  4581 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I0928 14:26:22.690899  4581 solver.cpp:218] Iteration 15900 (7.02333 iter/s, 14.2383s/100 iters), loss = 0.255391
I0928 14:26:22.690939  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255392 (* 1 = 0.255392 loss)
I0928 14:26:22.690945  4581 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I0928 14:26:36.217137  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:26:36.785816  4581 solver.cpp:330] Iteration 16000, Testing net (#0)
I0928 14:26:40.157940  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:26:40.299093  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6749
I0928 14:26:40.299129  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.15415 (* 1 = 1.15415 loss)
I0928 14:26:40.441177  4581 solver.cpp:218] Iteration 16000 (5.63374 iter/s, 17.7502s/100 iters), loss = 0.153826
I0928 14:26:40.441206  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153826 (* 1 = 0.153826 loss)
I0928 14:26:40.441213  4581 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I0928 14:26:54.673403  4581 solver.cpp:218] Iteration 16100 (7.02634 iter/s, 14.2322s/100 iters), loss = 0.229218
I0928 14:26:54.673431  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229218 (* 1 = 0.229218 loss)
I0928 14:26:54.673447  4581 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I0928 14:27:08.905876  4581 solver.cpp:218] Iteration 16200 (7.02622 iter/s, 14.2324s/100 iters), loss = 0.165562
I0928 14:27:08.905983  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165563 (* 1 = 0.165563 loss)
I0928 14:27:08.906002  4581 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I0928 14:27:23.131592  4581 solver.cpp:218] Iteration 16300 (7.02959 iter/s, 14.2256s/100 iters), loss = 0.16251
I0928 14:27:23.131621  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16251 (* 1 = 0.16251 loss)
I0928 14:27:23.131638  4581 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I0928 14:27:37.364497  4581 solver.cpp:218] Iteration 16400 (7.02601 iter/s, 14.2328s/100 iters), loss = 0.277342
I0928 14:27:37.364527  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277343 (* 1 = 0.277343 loss)
I0928 14:27:37.364543  4581 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I0928 14:27:50.890826  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:27:51.460230  4581 solver.cpp:330] Iteration 16500, Testing net (#0)
I0928 14:27:54.830415  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:27:54.971259  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5523
I0928 14:27:54.971295  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.16087 (* 1 = 2.16087 loss)
I0928 14:27:55.113497  4581 solver.cpp:218] Iteration 16500 (5.63415 iter/s, 17.7489s/100 iters), loss = 0.216825
I0928 14:27:55.113528  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216825 (* 1 = 0.216825 loss)
I0928 14:27:55.113536  4581 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I0928 14:28:09.340414  4581 solver.cpp:218] Iteration 16600 (7.02897 iter/s, 14.2268s/100 iters), loss = 0.179424
I0928 14:28:09.340445  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179424 (* 1 = 0.179424 loss)
I0928 14:28:09.340461  4581 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I0928 14:28:23.575582  4581 solver.cpp:218] Iteration 16700 (7.02489 iter/s, 14.2351s/100 iters), loss = 0.288204
I0928 14:28:23.575688  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288204 (* 1 = 0.288204 loss)
I0928 14:28:23.575707  4581 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I0928 14:28:37.803488  4581 solver.cpp:218] Iteration 16800 (7.02852 iter/s, 14.2278s/100 iters), loss = 0.238307
I0928 14:28:37.803517  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238307 (* 1 = 0.238307 loss)
I0928 14:28:37.803534  4581 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I0928 14:28:52.034905  4581 solver.cpp:218] Iteration 16900 (7.02674 iter/s, 14.2313s/100 iters), loss = 0.211369
I0928 14:28:52.034934  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211369 (* 1 = 0.211369 loss)
I0928 14:28:52.034940  4581 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I0928 14:29:05.553292  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:29:06.121706  4581 solver.cpp:330] Iteration 17000, Testing net (#0)
I0928 14:29:09.489814  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:29:09.630643  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5622
I0928 14:29:09.630678  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.21023 (* 1 = 2.21023 loss)
I0928 14:29:09.770725  4581 solver.cpp:218] Iteration 17000 (5.63833 iter/s, 17.7357s/100 iters), loss = 0.191424
I0928 14:29:09.770754  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191424 (* 1 = 0.191424 loss)
I0928 14:29:09.770761  4581 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I0928 14:29:23.989109  4581 solver.cpp:218] Iteration 17100 (7.0332 iter/s, 14.2183s/100 iters), loss = 0.189659
I0928 14:29:23.989140  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189659 (* 1 = 0.189659 loss)
I0928 14:29:23.989145  4581 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I0928 14:29:38.209044  4581 solver.cpp:218] Iteration 17200 (7.03242 iter/s, 14.2199s/100 iters), loss = 0.176015
I0928 14:29:38.209133  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176016 (* 1 = 0.176016 loss)
I0928 14:29:38.209151  4581 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I0928 14:29:52.431450  4581 solver.cpp:218] Iteration 17300 (7.03122 iter/s, 14.2223s/100 iters), loss = 0.225276
I0928 14:29:52.431480  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225276 (* 1 = 0.225276 loss)
I0928 14:29:52.431498  4581 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I0928 14:30:06.653517  4581 solver.cpp:218] Iteration 17400 (7.03136 iter/s, 14.222s/100 iters), loss = 0.222702
I0928 14:30:06.653547  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222702 (* 1 = 0.222702 loss)
I0928 14:30:06.653563  4581 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I0928 14:30:20.169708  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:30:20.740134  4581 solver.cpp:330] Iteration 17500, Testing net (#0)
I0928 14:30:24.106887  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:30:24.248239  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.629
I0928 14:30:24.248265  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.55071 (* 1 = 1.55071 loss)
I0928 14:30:24.390511  4581 solver.cpp:218] Iteration 17500 (5.63796 iter/s, 17.7369s/100 iters), loss = 0.224828
I0928 14:30:24.390542  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224828 (* 1 = 0.224828 loss)
I0928 14:30:24.390548  4581 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I0928 14:30:38.624869  4581 solver.cpp:218] Iteration 17600 (7.02529 iter/s, 14.2343s/100 iters), loss = 0.286375
I0928 14:30:38.624900  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286375 (* 1 = 0.286375 loss)
I0928 14:30:38.624917  4581 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I0928 14:30:52.863962  4581 solver.cpp:218] Iteration 17700 (7.02295 iter/s, 14.239s/100 iters), loss = 0.296126
I0928 14:30:52.864073  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296126 (* 1 = 0.296126 loss)
I0928 14:30:52.864092  4581 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I0928 14:31:07.102568  4581 solver.cpp:218] Iteration 17800 (7.02324 iter/s, 14.2385s/100 iters), loss = 0.172228
I0928 14:31:07.102598  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172228 (* 1 = 0.172228 loss)
I0928 14:31:07.102604  4581 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I0928 14:31:21.337839  4581 solver.cpp:218] Iteration 17900 (7.02484 iter/s, 14.2352s/100 iters), loss = 0.134076
I0928 14:31:21.337869  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134076 (* 1 = 0.134076 loss)
I0928 14:31:21.337885  4581 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I0928 14:31:34.867403  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:31:35.439174  4581 solver.cpp:330] Iteration 18000, Testing net (#0)
I0928 14:31:38.807231  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:31:38.947762  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5271
I0928 14:31:38.947798  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.55389 (* 1 = 2.55389 loss)
I0928 14:31:39.090215  4581 solver.cpp:218] Iteration 18000 (5.63307 iter/s, 17.7523s/100 iters), loss = 0.256835
I0928 14:31:39.090245  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256835 (* 1 = 0.256835 loss)
I0928 14:31:39.090251  4581 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I0928 14:31:53.316740  4581 solver.cpp:218] Iteration 18100 (7.02916 iter/s, 14.2265s/100 iters), loss = 0.203798
I0928 14:31:53.316771  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203798 (* 1 = 0.203798 loss)
I0928 14:31:53.316786  4581 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I0928 14:32:07.550045  4581 solver.cpp:218] Iteration 18200 (7.02581 iter/s, 14.2332s/100 iters), loss = 0.198454
I0928 14:32:07.550137  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198454 (* 1 = 0.198454 loss)
I0928 14:32:07.550155  4581 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I0928 14:32:21.782374  4581 solver.cpp:218] Iteration 18300 (7.02633 iter/s, 14.2322s/100 iters), loss = 0.191411
I0928 14:32:21.782405  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191411 (* 1 = 0.191411 loss)
I0928 14:32:21.782421  4581 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I0928 14:32:36.014813  4581 solver.cpp:218] Iteration 18400 (7.02624 iter/s, 14.2324s/100 iters), loss = 0.213096
I0928 14:32:36.014844  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213096 (* 1 = 0.213096 loss)
I0928 14:32:36.014860  4581 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I0928 14:32:49.526583  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:32:50.096838  4581 solver.cpp:330] Iteration 18500, Testing net (#0)
I0928 14:32:53.466158  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:32:53.607867  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7115
I0928 14:32:53.607892  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.996299 (* 1 = 0.996299 loss)
I0928 14:32:53.749797  4581 solver.cpp:218] Iteration 18500 (5.6386 iter/s, 17.7349s/100 iters), loss = 0.292683
I0928 14:32:53.749826  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292683 (* 1 = 0.292683 loss)
I0928 14:32:53.749833  4581 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I0928 14:33:07.981101  4581 solver.cpp:218] Iteration 18600 (7.0268 iter/s, 14.2312s/100 iters), loss = 0.281325
I0928 14:33:07.981130  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281325 (* 1 = 0.281325 loss)
I0928 14:33:07.981148  4581 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I0928 14:33:22.218164  4581 solver.cpp:218] Iteration 18700 (7.02396 iter/s, 14.237s/100 iters), loss = 0.315948
I0928 14:33:22.218282  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315948 (* 1 = 0.315948 loss)
I0928 14:33:22.218291  4581 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I0928 14:33:36.451182  4581 solver.cpp:218] Iteration 18800 (7.02599 iter/s, 14.2329s/100 iters), loss = 0.164964
I0928 14:33:36.451212  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164964 (* 1 = 0.164964 loss)
I0928 14:33:36.451230  4581 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I0928 14:33:50.683064  4581 solver.cpp:218] Iteration 18900 (7.02651 iter/s, 14.2318s/100 iters), loss = 0.15766
I0928 14:33:50.683095  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15766 (* 1 = 0.15766 loss)
I0928 14:33:50.683112  4581 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I0928 14:34:04.206315  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:34:04.776304  4581 solver.cpp:330] Iteration 19000, Testing net (#0)
I0928 14:34:08.146343  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:34:08.287436  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5802
I0928 14:34:08.287472  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.09749 (* 1 = 2.09749 loss)
I0928 14:34:08.429190  4581 solver.cpp:218] Iteration 19000 (5.63506 iter/s, 17.746s/100 iters), loss = 0.200233
I0928 14:34:08.429219  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200233 (* 1 = 0.200233 loss)
I0928 14:34:08.429226  4581 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I0928 14:34:22.647059  4581 solver.cpp:218] Iteration 19100 (7.03344 iter/s, 14.2178s/100 iters), loss = 0.232752
I0928 14:34:22.647091  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232752 (* 1 = 0.232752 loss)
I0928 14:34:22.647097  4581 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I0928 14:34:36.877027  4581 solver.cpp:218] Iteration 19200 (7.02746 iter/s, 14.2299s/100 iters), loss = 0.188307
I0928 14:34:36.877135  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188307 (* 1 = 0.188307 loss)
I0928 14:34:36.877142  4581 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I0928 14:34:51.101181  4581 solver.cpp:218] Iteration 19300 (7.03036 iter/s, 14.224s/100 iters), loss = 0.121112
I0928 14:34:51.101210  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.121112 (* 1 = 0.121112 loss)
I0928 14:34:51.101227  4581 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I0928 14:35:05.325125  4581 solver.cpp:218] Iteration 19400 (7.03044 iter/s, 14.2239s/100 iters), loss = 0.219423
I0928 14:35:05.325155  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219423 (* 1 = 0.219423 loss)
I0928 14:35:05.325170  4581 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I0928 14:35:18.844573  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:35:19.414214  4581 solver.cpp:330] Iteration 19500, Testing net (#0)
I0928 14:35:22.785866  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:35:22.926934  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6108
I0928 14:35:22.926970  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.56133 (* 1 = 1.56133 loss)
I0928 14:35:23.068563  4581 solver.cpp:218] Iteration 19500 (5.63591 iter/s, 17.7434s/100 iters), loss = 0.149814
I0928 14:35:23.068593  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149814 (* 1 = 0.149814 loss)
I0928 14:35:23.068599  4581 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I0928 14:35:37.288694  4581 solver.cpp:218] Iteration 19600 (7.03232 iter/s, 14.2201s/100 iters), loss = 0.237527
I0928 14:35:37.288724  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237527 (* 1 = 0.237527 loss)
I0928 14:35:37.288730  4581 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I0928 14:35:51.514864  4581 solver.cpp:218] Iteration 19700 (7.02933 iter/s, 14.2261s/100 iters), loss = 0.205132
I0928 14:35:51.515005  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205132 (* 1 = 0.205132 loss)
I0928 14:35:51.515025  4581 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I0928 14:36:05.735510  4581 solver.cpp:218] Iteration 19800 (7.03212 iter/s, 14.2205s/100 iters), loss = 0.130558
I0928 14:36:05.735539  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.130558 (* 1 = 0.130558 loss)
I0928 14:36:05.735555  4581 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I0928 14:36:19.957849  4581 solver.cpp:218] Iteration 19900 (7.03123 iter/s, 14.2223s/100 iters), loss = 0.203471
I0928 14:36:19.957880  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203471 (* 1 = 0.203471 loss)
I0928 14:36:19.957885  4581 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I0928 14:36:33.475111  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:36:34.044555  4581 solver.cpp:330] Iteration 20000, Testing net (#0)
I0928 14:36:37.415623  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:36:37.556933  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7088
I0928 14:36:37.556959  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.06994 (* 1 = 1.06994 loss)
I0928 14:36:37.698411  4581 solver.cpp:218] Iteration 20000 (5.63683 iter/s, 17.7405s/100 iters), loss = 0.171336
I0928 14:36:37.698441  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171336 (* 1 = 0.171336 loss)
I0928 14:36:37.698447  4581 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I0928 14:36:51.926893  4581 solver.cpp:218] Iteration 20100 (7.02819 iter/s, 14.2284s/100 iters), loss = 0.200222
I0928 14:36:51.926923  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200222 (* 1 = 0.200222 loss)
I0928 14:36:51.926939  4581 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I0928 14:37:06.163767  4581 solver.cpp:218] Iteration 20200 (7.02405 iter/s, 14.2368s/100 iters), loss = 0.191429
I0928 14:37:06.163887  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191429 (* 1 = 0.191429 loss)
I0928 14:37:06.163903  4581 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I0928 14:37:20.395150  4581 solver.cpp:218] Iteration 20300 (7.0268 iter/s, 14.2312s/100 iters), loss = 0.182288
I0928 14:37:20.395179  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182288 (* 1 = 0.182288 loss)
I0928 14:37:20.395185  4581 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I0928 14:37:34.626083  4581 solver.cpp:218] Iteration 20400 (7.02698 iter/s, 14.2309s/100 iters), loss = 0.232456
I0928 14:37:34.626116  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232456 (* 1 = 0.232456 loss)
I0928 14:37:34.626132  4581 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I0928 14:37:48.150333  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:37:48.721210  4581 solver.cpp:330] Iteration 20500, Testing net (#0)
I0928 14:37:52.092303  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:37:52.233332  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6597
I0928 14:37:52.233368  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.30398 (* 1 = 1.30398 loss)
I0928 14:37:52.375478  4581 solver.cpp:218] Iteration 20500 (5.63402 iter/s, 17.7493s/100 iters), loss = 0.167133
I0928 14:37:52.375505  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167133 (* 1 = 0.167133 loss)
I0928 14:37:52.375512  4581 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I0928 14:38:06.609212  4581 solver.cpp:218] Iteration 20600 (7.0256 iter/s, 14.2337s/100 iters), loss = 0.221093
I0928 14:38:06.609252  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221093 (* 1 = 0.221093 loss)
I0928 14:38:06.609258  4581 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I0928 14:38:20.844424  4581 solver.cpp:218] Iteration 20700 (7.02487 iter/s, 14.2351s/100 iters), loss = 0.232427
I0928 14:38:20.844561  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232427 (* 1 = 0.232427 loss)
I0928 14:38:20.844578  4581 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I0928 14:38:35.080514  4581 solver.cpp:218] Iteration 20800 (7.02448 iter/s, 14.2359s/100 iters), loss = 0.200975
I0928 14:38:35.080545  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200975 (* 1 = 0.200975 loss)
I0928 14:38:35.080551  4581 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I0928 14:38:49.312969  4581 solver.cpp:218] Iteration 20900 (7.02623 iter/s, 14.2324s/100 iters), loss = 0.227668
I0928 14:38:49.313010  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227668 (* 1 = 0.227668 loss)
I0928 14:38:49.313016  4581 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I0928 14:39:02.849243  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:39:03.419903  4581 solver.cpp:330] Iteration 21000, Testing net (#0)
I0928 14:39:06.790220  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:39:06.931246  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5772
I0928 14:39:06.931282  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.51984 (* 1 = 1.51984 loss)
I0928 14:39:07.073530  4581 solver.cpp:218] Iteration 21000 (5.63048 iter/s, 17.7605s/100 iters), loss = 0.179774
I0928 14:39:07.073557  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179774 (* 1 = 0.179774 loss)
I0928 14:39:07.073565  4581 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I0928 14:39:21.295321  4581 solver.cpp:218] Iteration 21100 (7.0315 iter/s, 14.2217s/100 iters), loss = 0.215334
I0928 14:39:21.295351  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215335 (* 1 = 0.215335 loss)
I0928 14:39:21.295358  4581 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I0928 14:39:35.523773  4581 solver.cpp:218] Iteration 21200 (7.02821 iter/s, 14.2284s/100 iters), loss = 0.158219
I0928 14:39:35.523905  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158219 (* 1 = 0.158219 loss)
I0928 14:39:35.523912  4581 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I0928 14:39:49.758172  4581 solver.cpp:218] Iteration 21300 (7.02531 iter/s, 14.2342s/100 iters), loss = 0.1749
I0928 14:39:49.758214  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174901 (* 1 = 0.174901 loss)
I0928 14:39:49.758220  4581 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I0928 14:40:03.990352  4581 solver.cpp:218] Iteration 21400 (7.02637 iter/s, 14.2321s/100 iters), loss = 0.158468
I0928 14:40:03.990383  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158468 (* 1 = 0.158468 loss)
I0928 14:40:03.990389  4581 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I0928 14:40:17.515318  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:40:18.085027  4581 solver.cpp:330] Iteration 21500, Testing net (#0)
I0928 14:40:21.457512  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:40:21.598379  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4653
I0928 14:40:21.598404  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.35514 (* 1 = 2.35514 loss)
I0928 14:40:21.740777  4581 solver.cpp:218] Iteration 21500 (5.63369 iter/s, 17.7503s/100 iters), loss = 0.256021
I0928 14:40:21.740805  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256021 (* 1 = 0.256021 loss)
I0928 14:40:21.740813  4581 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I0928 14:40:35.962522  4581 solver.cpp:218] Iteration 21600 (7.03152 iter/s, 14.2217s/100 iters), loss = 0.217548
I0928 14:40:35.962561  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217548 (* 1 = 0.217548 loss)
I0928 14:40:35.962568  4581 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I0928 14:40:50.192802  4581 solver.cpp:218] Iteration 21700 (7.02731 iter/s, 14.2302s/100 iters), loss = 0.227069
I0928 14:40:50.192926  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22707 (* 1 = 0.22707 loss)
I0928 14:40:50.192934  4581 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I0928 14:41:04.425434  4581 solver.cpp:218] Iteration 21800 (7.02619 iter/s, 14.2325s/100 iters), loss = 0.179736
I0928 14:41:04.425475  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179736 (* 1 = 0.179736 loss)
I0928 14:41:04.425482  4581 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I0928 14:41:18.657093  4581 solver.cpp:218] Iteration 21900 (7.02663 iter/s, 14.2316s/100 iters), loss = 0.180065
I0928 14:41:18.657133  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180065 (* 1 = 0.180065 loss)
I0928 14:41:18.657140  4581 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I0928 14:41:32.178165  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:41:32.748549  4581 solver.cpp:330] Iteration 22000, Testing net (#0)
I0928 14:41:36.118441  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:41:36.260501  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6547
I0928 14:41:36.260526  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.20733 (* 1 = 1.20733 loss)
I0928 14:41:36.402014  4581 solver.cpp:218] Iteration 22000 (5.63544 iter/s, 17.7448s/100 iters), loss = 0.183406
I0928 14:41:36.402043  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183407 (* 1 = 0.183407 loss)
I0928 14:41:36.402050  4581 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I0928 14:41:50.618651  4581 solver.cpp:218] Iteration 22100 (7.03405 iter/s, 14.2166s/100 iters), loss = 0.195218
I0928 14:41:50.618693  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195218 (* 1 = 0.195218 loss)
I0928 14:41:50.618700  4581 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I0928 14:42:04.842041  4581 solver.cpp:218] Iteration 22200 (7.03071 iter/s, 14.2233s/100 iters), loss = 0.204631
I0928 14:42:04.842114  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204631 (* 1 = 0.204631 loss)
I0928 14:42:04.842121  4581 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I0928 14:42:19.067754  4581 solver.cpp:218] Iteration 22300 (7.02958 iter/s, 14.2256s/100 iters), loss = 0.161875
I0928 14:42:19.067795  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161875 (* 1 = 0.161875 loss)
I0928 14:42:19.067800  4581 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I0928 14:42:33.297272  4581 solver.cpp:218] Iteration 22400 (7.02769 iter/s, 14.2294s/100 iters), loss = 0.171166
I0928 14:42:33.297314  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171166 (* 1 = 0.171166 loss)
I0928 14:42:33.297320  4581 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I0928 14:42:46.814363  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:42:47.384009  4581 solver.cpp:330] Iteration 22500, Testing net (#0)
I0928 14:42:50.751893  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:42:50.892683  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6726
I0928 14:42:50.892717  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.33674 (* 1 = 1.33674 loss)
I0928 14:42:51.035022  4581 solver.cpp:218] Iteration 22500 (5.63772 iter/s, 17.7377s/100 iters), loss = 0.137906
I0928 14:42:51.035051  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.137906 (* 1 = 0.137906 loss)
I0928 14:42:51.035058  4581 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I0928 14:43:05.268187  4581 solver.cpp:218] Iteration 22600 (7.02588 iter/s, 14.2331s/100 iters), loss = 0.16719
I0928 14:43:05.268227  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16719 (* 1 = 0.16719 loss)
I0928 14:43:05.268234  4581 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I0928 14:43:19.504181  4581 solver.cpp:218] Iteration 22700 (7.02449 iter/s, 14.2359s/100 iters), loss = 0.157565
I0928 14:43:19.504343  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157565 (* 1 = 0.157565 loss)
I0928 14:43:19.504361  4581 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I0928 14:43:33.742195  4581 solver.cpp:218] Iteration 22800 (7.02355 iter/s, 14.2378s/100 iters), loss = 0.235586
I0928 14:43:33.742236  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235586 (* 1 = 0.235586 loss)
I0928 14:43:33.742242  4581 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I0928 14:43:47.985179  4581 solver.cpp:218] Iteration 22900 (7.02104 iter/s, 14.2429s/100 iters), loss = 0.138782
I0928 14:43:47.985219  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.138782 (* 1 = 0.138782 loss)
I0928 14:43:47.985224  4581 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I0928 14:44:01.518302  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:44:02.087937  4581 solver.cpp:330] Iteration 23000, Testing net (#0)
I0928 14:44:05.455642  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:44:05.596439  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7119
I0928 14:44:05.596475  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.04434 (* 1 = 1.04434 loss)
I0928 14:44:05.738378  4581 solver.cpp:218] Iteration 23000 (5.63282 iter/s, 17.7531s/100 iters), loss = 0.265112
I0928 14:44:05.738406  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265112 (* 1 = 0.265112 loss)
I0928 14:44:05.738414  4581 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I0928 14:44:19.960616  4581 solver.cpp:218] Iteration 23100 (7.03128 iter/s, 14.2222s/100 iters), loss = 0.2307
I0928 14:44:19.960656  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230701 (* 1 = 0.230701 loss)
I0928 14:44:19.960662  4581 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I0928 14:44:34.188941  4581 solver.cpp:218] Iteration 23200 (7.02827 iter/s, 14.2282s/100 iters), loss = 0.256651
I0928 14:44:34.188998  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256651 (* 1 = 0.256651 loss)
I0928 14:44:34.189005  4581 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I0928 14:44:48.418536  4581 solver.cpp:218] Iteration 23300 (7.02765 iter/s, 14.2295s/100 iters), loss = 0.208583
I0928 14:44:48.418577  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208583 (* 1 = 0.208583 loss)
I0928 14:44:48.418583  4581 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I0928 14:45:02.644809  4581 solver.cpp:218] Iteration 23400 (7.02929 iter/s, 14.2262s/100 iters), loss = 0.0985574
I0928 14:45:02.644850  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0985575 (* 1 = 0.0985575 loss)
I0928 14:45:02.644856  4581 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I0928 14:45:16.159929  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:45:16.730615  4581 solver.cpp:330] Iteration 23500, Testing net (#0)
I0928 14:45:20.100052  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:45:20.241102  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7187
I0928 14:45:20.241138  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.947173 (* 1 = 0.947173 loss)
I0928 14:45:20.382571  4581 solver.cpp:218] Iteration 23500 (5.63772 iter/s, 17.7377s/100 iters), loss = 0.217946
I0928 14:45:20.382599  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217946 (* 1 = 0.217946 loss)
I0928 14:45:20.382606  4581 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I0928 14:45:34.606292  4581 solver.cpp:218] Iteration 23600 (7.03054 iter/s, 14.2236s/100 iters), loss = 0.193893
I0928 14:45:34.606333  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193893 (* 1 = 0.193893 loss)
I0928 14:45:34.606339  4581 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I0928 14:45:48.841121  4581 solver.cpp:218] Iteration 23700 (7.02506 iter/s, 14.2347s/100 iters), loss = 0.162812
I0928 14:45:48.841269  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162812 (* 1 = 0.162812 loss)
I0928 14:45:48.841276  4581 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I0928 14:46:03.071576  4581 solver.cpp:218] Iteration 23800 (7.02727 iter/s, 14.2303s/100 iters), loss = 0.151517
I0928 14:46:03.071616  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151517 (* 1 = 0.151517 loss)
I0928 14:46:03.071622  4581 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I0928 14:46:17.297951  4581 solver.cpp:218] Iteration 23900 (7.02924 iter/s, 14.2263s/100 iters), loss = 0.171952
I0928 14:46:17.297992  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171952 (* 1 = 0.171952 loss)
I0928 14:46:17.297998  4581 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I0928 14:46:30.822374  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:46:31.391940  4581 solver.cpp:330] Iteration 24000, Testing net (#0)
I0928 14:46:34.760325  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:46:34.901609  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6377
I0928 14:46:34.901645  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.31241 (* 1 = 1.31241 loss)
I0928 14:46:35.043174  4581 solver.cpp:218] Iteration 24000 (5.63535 iter/s, 17.7451s/100 iters), loss = 0.201455
I0928 14:46:35.043203  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201455 (* 1 = 0.201455 loss)
I0928 14:46:35.043210  4581 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I0928 14:46:49.268003  4581 solver.cpp:218] Iteration 24100 (7.03 iter/s, 14.2248s/100 iters), loss = 0.196937
I0928 14:46:49.268043  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196937 (* 1 = 0.196937 loss)
I0928 14:46:49.268050  4581 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I0928 14:47:03.495846  4581 solver.cpp:218] Iteration 24200 (7.02851 iter/s, 14.2278s/100 iters), loss = 0.246955
I0928 14:47:03.495965  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246956 (* 1 = 0.246956 loss)
I0928 14:47:03.495983  4581 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I0928 14:47:17.722898  4581 solver.cpp:218] Iteration 24300 (7.02894 iter/s, 14.2269s/100 iters), loss = 0.248846
I0928 14:47:17.722937  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248846 (* 1 = 0.248846 loss)
I0928 14:47:17.722944  4581 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I0928 14:47:31.953461  4581 solver.cpp:218] Iteration 24400 (7.02717 iter/s, 14.2305s/100 iters), loss = 0.096458
I0928 14:47:31.953500  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0964581 (* 1 = 0.0964581 loss)
I0928 14:47:31.953506  4581 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I0928 14:47:45.477460  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:47:46.047096  4581 solver.cpp:330] Iteration 24500, Testing net (#0)
I0928 14:47:49.416824  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:47:49.557958  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5747
I0928 14:47:49.557994  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.83769 (* 1 = 1.83769 loss)
I0928 14:47:49.699662  4581 solver.cpp:218] Iteration 24500 (5.63504 iter/s, 17.7461s/100 iters), loss = 0.138944
I0928 14:47:49.699690  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.138944 (* 1 = 0.138944 loss)
I0928 14:47:49.699697  4581 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I0928 14:48:03.922107  4581 solver.cpp:218] Iteration 24600 (7.03118 iter/s, 14.2224s/100 iters), loss = 0.145616
I0928 14:48:03.922147  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145616 (* 1 = 0.145616 loss)
I0928 14:48:03.922153  4581 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I0928 14:48:18.147317  4581 solver.cpp:218] Iteration 24700 (7.02981 iter/s, 14.2251s/100 iters), loss = 0.185925
I0928 14:48:18.147423  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185925 (* 1 = 0.185925 loss)
I0928 14:48:18.147431  4581 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I0928 14:48:32.372030  4581 solver.cpp:218] Iteration 24800 (7.03009 iter/s, 14.2246s/100 iters), loss = 0.182015
I0928 14:48:32.372069  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182015 (* 1 = 0.182015 loss)
I0928 14:48:32.372076  4581 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I0928 14:48:46.597718  4581 solver.cpp:218] Iteration 24900 (7.02958 iter/s, 14.2256s/100 iters), loss = 0.115572
I0928 14:48:46.597759  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115572 (* 1 = 0.115572 loss)
I0928 14:48:46.597764  4581 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I0928 14:49:00.115660  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:49:00.685228  4581 solver.cpp:330] Iteration 25000, Testing net (#0)
I0928 14:49:04.053354  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:49:04.194375  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6969
I0928 14:49:04.194411  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.99808 (* 1 = 0.99808 loss)
I0928 14:49:04.336251  4581 solver.cpp:218] Iteration 25000 (5.63747 iter/s, 17.7384s/100 iters), loss = 0.267008
I0928 14:49:04.336278  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267008 (* 1 = 0.267008 loss)
I0928 14:49:04.336285  4581 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I0928 14:49:18.563060  4581 solver.cpp:218] Iteration 25100 (7.02902 iter/s, 14.2267s/100 iters), loss = 0.174067
I0928 14:49:18.563102  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174067 (* 1 = 0.174067 loss)
I0928 14:49:18.563107  4581 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I0928 14:49:32.790284  4581 solver.cpp:218] Iteration 25200 (7.02882 iter/s, 14.2271s/100 iters), loss = 0.12859
I0928 14:49:32.790395  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12859 (* 1 = 0.12859 loss)
I0928 14:49:32.790410  4581 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I0928 14:49:47.024178  4581 solver.cpp:218] Iteration 25300 (7.02555 iter/s, 14.2338s/100 iters), loss = 0.139324
I0928 14:49:47.024209  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139324 (* 1 = 0.139324 loss)
I0928 14:49:47.024216  4581 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I0928 14:50:01.260460  4581 solver.cpp:218] Iteration 25400 (7.02434 iter/s, 14.2362s/100 iters), loss = 0.123687
I0928 14:50:01.260501  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123687 (* 1 = 0.123687 loss)
I0928 14:50:01.260507  4581 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I0928 14:50:14.786558  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:50:15.358487  4581 solver.cpp:330] Iteration 25500, Testing net (#0)
I0928 14:50:18.729537  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:50:18.870329  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4839
I0928 14:50:18.870354  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.60527 (* 1 = 2.60527 loss)
I0928 14:50:19.012614  4581 solver.cpp:218] Iteration 25500 (5.63315 iter/s, 17.7521s/100 iters), loss = 0.181059
I0928 14:50:19.012643  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181059 (* 1 = 0.181059 loss)
I0928 14:50:19.012650  4581 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I0928 14:50:33.249214  4581 solver.cpp:218] Iteration 25600 (7.02418 iter/s, 14.2365s/100 iters), loss = 0.201263
I0928 14:50:33.249244  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201263 (* 1 = 0.201263 loss)
I0928 14:50:33.249250  4581 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I0928 14:50:47.484866  4581 solver.cpp:218] Iteration 25700 (7.02465 iter/s, 14.2356s/100 iters), loss = 0.162842
I0928 14:50:47.484913  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162842 (* 1 = 0.162842 loss)
I0928 14:50:47.484930  4581 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I0928 14:51:01.719214  4581 solver.cpp:218] Iteration 25800 (7.0253 iter/s, 14.2343s/100 iters), loss = 0.151239
I0928 14:51:01.719246  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151239 (* 1 = 0.151239 loss)
I0928 14:51:01.719262  4581 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I0928 14:51:15.953909  4581 solver.cpp:218] Iteration 25900 (7.02513 iter/s, 14.2346s/100 iters), loss = 0.195294
I0928 14:51:15.953945  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195294 (* 1 = 0.195294 loss)
I0928 14:51:15.953963  4581 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I0928 14:51:29.482967  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:51:30.052654  4581 solver.cpp:330] Iteration 26000, Testing net (#0)
I0928 14:51:33.423004  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:51:33.563848  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5315
I0928 14:51:33.563884  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.43732 (* 1 = 2.43732 loss)
I0928 14:51:33.705762  4581 solver.cpp:218] Iteration 26000 (5.63324 iter/s, 17.7518s/100 iters), loss = 0.162084
I0928 14:51:33.705791  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162084 (* 1 = 0.162084 loss)
I0928 14:51:33.705798  4581 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I0928 14:51:47.932621  4581 solver.cpp:218] Iteration 26100 (7.02899 iter/s, 14.2268s/100 iters), loss = 0.212043
I0928 14:51:47.932660  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212043 (* 1 = 0.212043 loss)
I0928 14:51:47.932667  4581 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I0928 14:52:02.164131  4581 solver.cpp:218] Iteration 26200 (7.0267 iter/s, 14.2314s/100 iters), loss = 0.283894
I0928 14:52:02.164233  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283894 (* 1 = 0.283894 loss)
I0928 14:52:02.164240  4581 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I0928 14:52:16.395874  4581 solver.cpp:218] Iteration 26300 (7.02662 iter/s, 14.2316s/100 iters), loss = 0.163115
I0928 14:52:16.395915  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163115 (* 1 = 0.163115 loss)
I0928 14:52:16.395920  4581 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I0928 14:52:30.628787  4581 solver.cpp:218] Iteration 26400 (7.02601 iter/s, 14.2328s/100 iters), loss = 0.165651
I0928 14:52:30.628829  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165651 (* 1 = 0.165651 loss)
I0928 14:52:30.628834  4581 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I0928 14:52:44.153187  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:52:44.723520  4581 solver.cpp:330] Iteration 26500, Testing net (#0)
I0928 14:52:48.094205  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:52:48.235538  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6635
I0928 14:52:48.235574  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.21752 (* 1 = 1.21752 loss)
I0928 14:52:48.377177  4581 solver.cpp:218] Iteration 26500 (5.63434 iter/s, 17.7483s/100 iters), loss = 0.104685
I0928 14:52:48.377207  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.104685 (* 1 = 0.104685 loss)
I0928 14:52:48.377213  4581 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I0928 14:53:02.600841  4581 solver.cpp:218] Iteration 26600 (7.03057 iter/s, 14.2236s/100 iters), loss = 0.0936635
I0928 14:53:02.600883  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0936634 (* 1 = 0.0936634 loss)
I0928 14:53:02.600888  4581 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I0928 14:53:16.827765  4581 solver.cpp:218] Iteration 26700 (7.02897 iter/s, 14.2268s/100 iters), loss = 0.265034
I0928 14:53:16.827894  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265034 (* 1 = 0.265034 loss)
I0928 14:53:16.827901  4581 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I0928 14:53:31.057498  4581 solver.cpp:218] Iteration 26800 (7.02762 iter/s, 14.2296s/100 iters), loss = 0.113631
I0928 14:53:31.057530  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.113631 (* 1 = 0.113631 loss)
I0928 14:53:31.057538  4581 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I0928 14:53:45.285217  4581 solver.cpp:218] Iteration 26900 (7.02857 iter/s, 14.2276s/100 iters), loss = 0.0961503
I0928 14:53:45.285257  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0961503 (* 1 = 0.0961503 loss)
I0928 14:53:45.285264  4581 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I0928 14:53:58.809335  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:53:59.379722  4581 solver.cpp:330] Iteration 27000, Testing net (#0)
I0928 14:54:02.752949  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:54:02.893656  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6904
I0928 14:54:02.893692  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.00117 (* 1 = 1.00117 loss)
I0928 14:54:03.035967  4581 solver.cpp:218] Iteration 27000 (5.63359 iter/s, 17.7507s/100 iters), loss = 0.203837
I0928 14:54:03.035997  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203837 (* 1 = 0.203837 loss)
I0928 14:54:03.036003  4581 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I0928 14:54:17.257107  4581 solver.cpp:218] Iteration 27100 (7.03182 iter/s, 14.2211s/100 iters), loss = 0.225484
I0928 14:54:17.257148  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225484 (* 1 = 0.225484 loss)
I0928 14:54:17.257153  4581 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I0928 14:54:31.483297  4581 solver.cpp:218] Iteration 27200 (7.02933 iter/s, 14.2261s/100 iters), loss = 0.18563
I0928 14:54:31.483407  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18563 (* 1 = 0.18563 loss)
I0928 14:54:31.483414  4581 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I0928 14:54:45.702891  4581 solver.cpp:218] Iteration 27300 (7.03262 iter/s, 14.2194s/100 iters), loss = 0.120603
I0928 14:54:45.702932  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120603 (* 1 = 0.120603 loss)
I0928 14:54:45.702939  4581 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I0928 14:54:59.930006  4581 solver.cpp:218] Iteration 27400 (7.02887 iter/s, 14.227s/100 iters), loss = 0.151087
I0928 14:54:59.930047  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151087 (* 1 = 0.151087 loss)
I0928 14:54:59.930053  4581 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I0928 14:55:13.448292  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:55:14.017714  4581 solver.cpp:330] Iteration 27500, Testing net (#0)
I0928 14:55:17.384714  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:55:17.527426  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6214
I0928 14:55:17.527452  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.31299 (* 1 = 1.31299 loss)
I0928 14:55:17.669894  4581 solver.cpp:218] Iteration 27500 (5.63704 iter/s, 17.7398s/100 iters), loss = 0.0992693
I0928 14:55:17.669924  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0992692 (* 1 = 0.0992692 loss)
I0928 14:55:17.669930  4581 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I0928 14:55:31.900209  4581 solver.cpp:218] Iteration 27600 (7.02729 iter/s, 14.2302s/100 iters), loss = 0.18687
I0928 14:55:31.900250  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18687 (* 1 = 0.18687 loss)
I0928 14:55:31.900256  4581 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I0928 14:55:46.136943  4581 solver.cpp:218] Iteration 27700 (7.02412 iter/s, 14.2367s/100 iters), loss = 0.189983
I0928 14:55:46.137064  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189983 (* 1 = 0.189983 loss)
I0928 14:55:46.137073  4581 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I0928 14:56:00.372683  4581 solver.cpp:218] Iteration 27800 (7.02465 iter/s, 14.2356s/100 iters), loss = 0.110526
I0928 14:56:00.372710  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.110526 (* 1 = 0.110526 loss)
I0928 14:56:00.372717  4581 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I0928 14:56:14.606125  4581 solver.cpp:218] Iteration 27900 (7.02574 iter/s, 14.2334s/100 iters), loss = 0.194374
I0928 14:56:14.606166  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194374 (* 1 = 0.194374 loss)
I0928 14:56:14.606173  4581 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I0928 14:56:28.133496  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:56:28.704211  4581 solver.cpp:330] Iteration 28000, Testing net (#0)
I0928 14:56:32.072809  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:56:32.213639  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5322
I0928 14:56:32.213675  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.95942 (* 1 = 1.95942 loss)
I0928 14:56:32.355221  4581 solver.cpp:218] Iteration 28000 (5.63412 iter/s, 17.749s/100 iters), loss = 0.167023
I0928 14:56:32.355249  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167023 (* 1 = 0.167023 loss)
I0928 14:56:32.355257  4581 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I0928 14:56:46.583793  4581 solver.cpp:218] Iteration 28100 (7.02815 iter/s, 14.2285s/100 iters), loss = 0.227633
I0928 14:56:46.583835  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227633 (* 1 = 0.227633 loss)
I0928 14:56:46.583842  4581 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I0928 14:57:00.813707  4581 solver.cpp:218] Iteration 28200 (7.02749 iter/s, 14.2298s/100 iters), loss = 0.199196
I0928 14:57:00.813796  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199196 (* 1 = 0.199196 loss)
I0928 14:57:00.813813  4581 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I0928 14:57:15.038017  4581 solver.cpp:218] Iteration 28300 (7.03028 iter/s, 14.2242s/100 iters), loss = 0.203096
I0928 14:57:15.038058  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203096 (* 1 = 0.203096 loss)
I0928 14:57:15.038065  4581 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I0928 14:57:29.269400  4581 solver.cpp:218] Iteration 28400 (7.02676 iter/s, 14.2313s/100 iters), loss = 0.0967815
I0928 14:57:29.269441  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0967814 (* 1 = 0.0967814 loss)
I0928 14:57:29.269448  4581 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I0928 14:57:42.789695  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:57:43.359272  4581 solver.cpp:330] Iteration 28500, Testing net (#0)
I0928 14:57:46.728405  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:57:46.869671  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6091
I0928 14:57:46.869706  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.58083 (* 1 = 1.58083 loss)
I0928 14:57:47.011623  4581 solver.cpp:218] Iteration 28500 (5.6363 iter/s, 17.7421s/100 iters), loss = 0.131513
I0928 14:57:47.011652  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.131513 (* 1 = 0.131513 loss)
I0928 14:57:47.011659  4581 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I0928 14:58:01.244473  4581 solver.cpp:218] Iteration 28600 (7.02603 iter/s, 14.2328s/100 iters), loss = 0.147392
I0928 14:58:01.244514  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147392 (* 1 = 0.147392 loss)
I0928 14:58:01.244521  4581 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I0928 14:58:15.480255  4581 solver.cpp:218] Iteration 28700 (7.02459 iter/s, 14.2357s/100 iters), loss = 0.158028
I0928 14:58:15.480376  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158028 (* 1 = 0.158028 loss)
I0928 14:58:15.480393  4581 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I0928 14:58:29.710531  4581 solver.cpp:218] Iteration 28800 (7.02735 iter/s, 14.2301s/100 iters), loss = 0.154321
I0928 14:58:29.710572  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154321 (* 1 = 0.154321 loss)
I0928 14:58:29.710578  4581 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I0928 14:58:43.941962  4581 solver.cpp:218] Iteration 28900 (7.02674 iter/s, 14.2313s/100 iters), loss = 0.123203
I0928 14:58:43.942004  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123203 (* 1 = 0.123203 loss)
I0928 14:58:43.942010  4581 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I0928 14:58:57.461771  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:58:58.033874  4581 solver.cpp:330] Iteration 29000, Testing net (#0)
I0928 14:59:01.403728  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 14:59:01.544824  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5108
I0928 14:59:01.544860  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.48575 (* 1 = 2.48575 loss)
I0928 14:59:01.687170  4581 solver.cpp:218] Iteration 29000 (5.63535 iter/s, 17.7451s/100 iters), loss = 0.0911575
I0928 14:59:01.687199  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0911574 (* 1 = 0.0911574 loss)
I0928 14:59:01.687206  4581 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I0928 14:59:15.909098  4581 solver.cpp:218] Iteration 29100 (7.03143 iter/s, 14.2219s/100 iters), loss = 0.0835668
I0928 14:59:15.909139  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0835667 (* 1 = 0.0835667 loss)
I0928 14:59:15.909147  4581 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I0928 14:59:30.137737  4581 solver.cpp:218] Iteration 29200 (7.02812 iter/s, 14.2286s/100 iters), loss = 0.167198
I0928 14:59:30.137815  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167198 (* 1 = 0.167198 loss)
I0928 14:59:30.137833  4581 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I0928 14:59:44.366816  4581 solver.cpp:218] Iteration 29300 (7.02792 iter/s, 14.229s/100 iters), loss = 0.25963
I0928 14:59:44.366847  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25963 (* 1 = 0.25963 loss)
I0928 14:59:44.366852  4581 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I0928 14:59:58.594105  4581 solver.cpp:218] Iteration 29400 (7.02878 iter/s, 14.2272s/100 iters), loss = 0.134507
I0928 14:59:58.594146  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134507 (* 1 = 0.134507 loss)
I0928 14:59:58.594151  4581 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I0928 15:00:12.117504  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:00:12.687139  4581 solver.cpp:330] Iteration 29500, Testing net (#0)
I0928 15:00:16.056591  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:00:16.196923  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5377
I0928 15:00:16.196947  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.00253 (* 1 = 2.00253 loss)
I0928 15:00:16.338377  4581 solver.cpp:218] Iteration 29500 (5.63565 iter/s, 17.7442s/100 iters), loss = 0.165634
I0928 15:00:16.338407  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165634 (* 1 = 0.165634 loss)
I0928 15:00:16.338414  4581 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I0928 15:00:30.559695  4581 solver.cpp:218] Iteration 29600 (7.03173 iter/s, 14.2212s/100 iters), loss = 0.215936
I0928 15:00:30.559744  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215936 (* 1 = 0.215936 loss)
I0928 15:00:30.559751  4581 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I0928 15:00:44.788475  4581 solver.cpp:218] Iteration 29700 (7.02805 iter/s, 14.2287s/100 iters), loss = 0.0682243
I0928 15:00:44.788599  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0682242 (* 1 = 0.0682242 loss)
I0928 15:00:44.788606  4581 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I0928 15:00:59.014694  4581 solver.cpp:218] Iteration 29800 (7.02935 iter/s, 14.2261s/100 iters), loss = 0.156635
I0928 15:00:59.014725  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156634 (* 1 = 0.156634 loss)
I0928 15:00:59.014731  4581 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I0928 15:01:13.236212  4581 solver.cpp:218] Iteration 29900 (7.03163 iter/s, 14.2214s/100 iters), loss = 0.173695
I0928 15:01:13.236253  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173694 (* 1 = 0.173694 loss)
I0928 15:01:13.236259  4581 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I0928 15:01:26.750839  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:01:27.321188  4581 solver.cpp:330] Iteration 30000, Testing net (#0)
I0928 15:01:30.689883  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:01:30.830737  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7276
I0928 15:01:30.830773  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.985792 (* 1 = 0.985792 loss)
I0928 15:01:30.972942  4581 solver.cpp:218] Iteration 30000 (5.63805 iter/s, 17.7366s/100 iters), loss = 0.206895
I0928 15:01:30.972972  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206895 (* 1 = 0.206895 loss)
I0928 15:01:30.972980  4581 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I0928 15:01:45.204015  4581 solver.cpp:218] Iteration 30100 (7.02691 iter/s, 14.231s/100 iters), loss = 0.218466
I0928 15:01:45.204054  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218466 (* 1 = 0.218466 loss)
I0928 15:01:45.204061  4581 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I0928 15:01:59.434938  4581 solver.cpp:218] Iteration 30200 (7.02699 iter/s, 14.2308s/100 iters), loss = 0.177699
I0928 15:01:59.435055  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177699 (* 1 = 0.177699 loss)
I0928 15:01:59.435065  4581 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I0928 15:02:13.667403  4581 solver.cpp:218] Iteration 30300 (7.02627 iter/s, 14.2323s/100 iters), loss = 0.217239
I0928 15:02:13.667443  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217239 (* 1 = 0.217239 loss)
I0928 15:02:13.667449  4581 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I0928 15:02:27.897054  4581 solver.cpp:218] Iteration 30400 (7.02762 iter/s, 14.2296s/100 iters), loss = 0.238766
I0928 15:02:27.897095  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238766 (* 1 = 0.238766 loss)
I0928 15:02:27.897101  4581 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I0928 15:02:41.426856  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:02:41.997244  4581 solver.cpp:330] Iteration 30500, Testing net (#0)
I0928 15:02:45.366138  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:02:45.507277  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6657
I0928 15:02:45.507313  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.21648 (* 1 = 1.21648 loss)
I0928 15:02:45.649503  4581 solver.cpp:218] Iteration 30500 (5.63305 iter/s, 17.7524s/100 iters), loss = 0.107508
I0928 15:02:45.649533  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.107507 (* 1 = 0.107507 loss)
I0928 15:02:45.649540  4581 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I0928 15:02:59.874483  4581 solver.cpp:218] Iteration 30600 (7.02992 iter/s, 14.2249s/100 iters), loss = 0.318819
I0928 15:02:59.874526  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.318819 (* 1 = 0.318819 loss)
I0928 15:02:59.874532  4581 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I0928 15:03:14.112149  4581 solver.cpp:218] Iteration 30700 (7.02366 iter/s, 14.2376s/100 iters), loss = 0.116297
I0928 15:03:14.112301  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116297 (* 1 = 0.116297 loss)
I0928 15:03:14.112309  4581 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I0928 15:03:28.346698  4581 solver.cpp:218] Iteration 30800 (7.02526 iter/s, 14.2344s/100 iters), loss = 0.131856
I0928 15:03:28.346726  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.131855 (* 1 = 0.131855 loss)
I0928 15:03:28.346734  4581 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I0928 15:03:42.577113  4581 solver.cpp:218] Iteration 30900 (7.02724 iter/s, 14.2303s/100 iters), loss = 0.130922
I0928 15:03:42.577154  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.130922 (* 1 = 0.130922 loss)
I0928 15:03:42.577160  4581 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I0928 15:03:56.101408  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:03:56.670245  4581 solver.cpp:330] Iteration 31000, Testing net (#0)
I0928 15:04:00.039945  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:04:00.181787  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6146
I0928 15:04:00.181813  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.41874 (* 1 = 1.41874 loss)
I0928 15:04:00.323108  4581 solver.cpp:218] Iteration 31000 (5.6351 iter/s, 17.7459s/100 iters), loss = 0.169953
I0928 15:04:00.323137  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169952 (* 1 = 0.169952 loss)
I0928 15:04:00.323143  4581 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I0928 15:04:14.553627  4581 solver.cpp:218] Iteration 31100 (7.02719 iter/s, 14.2304s/100 iters), loss = 0.244749
I0928 15:04:14.553668  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244748 (* 1 = 0.244748 loss)
I0928 15:04:14.553673  4581 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I0928 15:04:28.782466  4581 solver.cpp:218] Iteration 31200 (7.02802 iter/s, 14.2288s/100 iters), loss = 0.161077
I0928 15:04:28.782588  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161077 (* 1 = 0.161077 loss)
I0928 15:04:28.782603  4581 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I0928 15:04:43.012305  4581 solver.cpp:218] Iteration 31300 (7.02757 iter/s, 14.2297s/100 iters), loss = 0.158612
I0928 15:04:43.012346  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158611 (* 1 = 0.158611 loss)
I0928 15:04:43.012352  4581 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I0928 15:04:57.245247  4581 solver.cpp:218] Iteration 31400 (7.02599 iter/s, 14.2329s/100 iters), loss = 0.132074
I0928 15:04:57.245278  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132073 (* 1 = 0.132073 loss)
I0928 15:04:57.245285  4581 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I0928 15:05:10.771939  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:05:11.342489  4581 solver.cpp:330] Iteration 31500, Testing net (#0)
I0928 15:05:14.713793  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:05:14.854881  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7564
I0928 15:05:14.854907  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.757576 (* 1 = 0.757576 loss)
I0928 15:05:14.996965  4581 solver.cpp:218] Iteration 31500 (5.63328 iter/s, 17.7516s/100 iters), loss = 0.171411
I0928 15:05:14.996994  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171411 (* 1 = 0.171411 loss)
I0928 15:05:14.997001  4581 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I0928 15:05:29.216351  4581 solver.cpp:218] Iteration 31600 (7.03269 iter/s, 14.2193s/100 iters), loss = 0.170002
I0928 15:05:29.216392  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170002 (* 1 = 0.170002 loss)
I0928 15:05:29.216398  4581 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I0928 15:05:43.441591  4581 solver.cpp:218] Iteration 31700 (7.0298 iter/s, 14.2252s/100 iters), loss = 0.231698
I0928 15:05:43.441726  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231698 (* 1 = 0.231698 loss)
I0928 15:05:43.441735  4581 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I0928 15:05:57.671597  4581 solver.cpp:218] Iteration 31800 (7.02749 iter/s, 14.2298s/100 iters), loss = 0.121995
I0928 15:05:57.671638  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.121995 (* 1 = 0.121995 loss)
I0928 15:05:57.671643  4581 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I0928 15:06:11.909837  4581 solver.cpp:218] Iteration 31900 (7.02338 iter/s, 14.2382s/100 iters), loss = 0.180287
I0928 15:06:11.909878  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180287 (* 1 = 0.180287 loss)
I0928 15:06:11.909883  4581 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I0928 15:06:25.436282  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:06:26.004969  4581 solver.cpp:330] Iteration 32000, Testing net (#0)
I0928 15:06:29.374271  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:06:29.515128  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6315
I0928 15:06:29.515164  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.4244 (* 1 = 1.4244 loss)
I0928 15:06:29.655915  4581 solver.cpp:218] Iteration 32000 (5.63508 iter/s, 17.746s/100 iters), loss = 0.163507
I0928 15:06:29.655943  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163506 (* 1 = 0.163506 loss)
I0928 15:06:29.655952  4581 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I0928 15:06:43.876091  4581 solver.cpp:218] Iteration 32100 (7.03243 iter/s, 14.2198s/100 iters), loss = 0.179655
I0928 15:06:43.876132  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179655 (* 1 = 0.179655 loss)
I0928 15:06:43.876137  4581 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I0928 15:06:58.104429  4581 solver.cpp:218] Iteration 32200 (7.02827 iter/s, 14.2283s/100 iters), loss = 0.203811
I0928 15:06:58.104548  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203811 (* 1 = 0.203811 loss)
I0928 15:06:58.104555  4581 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I0928 15:07:12.334278  4581 solver.cpp:218] Iteration 32300 (7.02756 iter/s, 14.2297s/100 iters), loss = 0.203027
I0928 15:07:12.334308  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203027 (* 1 = 0.203027 loss)
I0928 15:07:12.334314  4581 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I0928 15:07:26.560547  4581 solver.cpp:218] Iteration 32400 (7.02929 iter/s, 14.2262s/100 iters), loss = 0.173592
I0928 15:07:26.560588  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173592 (* 1 = 0.173592 loss)
I0928 15:07:26.560595  4581 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I0928 15:07:40.079965  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:07:40.650149  4581 solver.cpp:330] Iteration 32500, Testing net (#0)
I0928 15:07:44.019084  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:07:44.159379  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5608
I0928 15:07:44.159415  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.13505 (* 1 = 2.13505 loss)
I0928 15:07:44.301409  4581 solver.cpp:218] Iteration 32500 (5.63673 iter/s, 17.7408s/100 iters), loss = 0.163589
I0928 15:07:44.301439  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163589 (* 1 = 0.163589 loss)
I0928 15:07:44.301445  4581 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I0928 15:07:58.528841  4581 solver.cpp:218] Iteration 32600 (7.02871 iter/s, 14.2274s/100 iters), loss = 0.105896
I0928 15:07:58.528883  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.105896 (* 1 = 0.105896 loss)
I0928 15:07:58.528889  4581 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I0928 15:08:12.757939  4581 solver.cpp:218] Iteration 32700 (7.02789 iter/s, 14.229s/100 iters), loss = 0.22999
I0928 15:08:12.758055  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22999 (* 1 = 0.22999 loss)
I0928 15:08:12.758074  4581 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I0928 15:08:26.991645  4581 solver.cpp:218] Iteration 32800 (7.02565 iter/s, 14.2336s/100 iters), loss = 0.191599
I0928 15:08:26.991686  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191599 (* 1 = 0.191599 loss)
I0928 15:08:26.991693  4581 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I0928 15:08:41.228806  4581 solver.cpp:218] Iteration 32900 (7.02391 iter/s, 14.2371s/100 iters), loss = 0.107784
I0928 15:08:41.228845  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.107783 (* 1 = 0.107783 loss)
I0928 15:08:41.228852  4581 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I0928 15:08:54.756907  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:08:55.326443  4581 solver.cpp:330] Iteration 33000, Testing net (#0)
I0928 15:08:58.692637  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:08:58.833789  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7293
I0928 15:08:58.833825  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.907426 (* 1 = 0.907426 loss)
I0928 15:08:58.975754  4581 solver.cpp:218] Iteration 33000 (5.6348 iter/s, 17.7469s/100 iters), loss = 0.205972
I0928 15:08:58.975783  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205972 (* 1 = 0.205972 loss)
I0928 15:08:58.975790  4581 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I0928 15:09:13.200613  4581 solver.cpp:218] Iteration 33100 (7.02998 iter/s, 14.2248s/100 iters), loss = 0.213037
I0928 15:09:13.200650  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213036 (* 1 = 0.213036 loss)
I0928 15:09:13.200656  4581 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I0928 15:09:27.431401  4581 solver.cpp:218] Iteration 33200 (7.02706 iter/s, 14.2307s/100 iters), loss = 0.1687
I0928 15:09:27.431522  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1687 (* 1 = 0.1687 loss)
I0928 15:09:27.431540  4581 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I0928 15:09:41.655345  4581 solver.cpp:218] Iteration 33300 (7.03048 iter/s, 14.2238s/100 iters), loss = 0.136516
I0928 15:09:41.655375  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136515 (* 1 = 0.136515 loss)
I0928 15:09:41.655382  4581 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I0928 15:09:55.887413  4581 solver.cpp:218] Iteration 33400 (7.02642 iter/s, 14.232s/100 iters), loss = 0.19749
I0928 15:09:55.887454  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197489 (* 1 = 0.197489 loss)
I0928 15:09:55.887459  4581 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I0928 15:10:09.411833  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:10:09.980680  4581 solver.cpp:330] Iteration 33500, Testing net (#0)
I0928 15:10:13.348611  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:10:13.489506  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6574
I0928 15:10:13.489542  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.18062 (* 1 = 1.18062 loss)
I0928 15:10:13.631266  4581 solver.cpp:218] Iteration 33500 (5.63578 iter/s, 17.7438s/100 iters), loss = 0.137488
I0928 15:10:13.631294  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.137487 (* 1 = 0.137487 loss)
I0928 15:10:13.631301  4581 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I0928 15:10:27.856227  4581 solver.cpp:218] Iteration 33600 (7.02993 iter/s, 14.2249s/100 iters), loss = 0.104414
I0928 15:10:27.856268  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.104413 (* 1 = 0.104413 loss)
I0928 15:10:27.856276  4581 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I0928 15:10:42.086341  4581 solver.cpp:218] Iteration 33700 (7.02739 iter/s, 14.23s/100 iters), loss = 0.217461
I0928 15:10:42.086478  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217461 (* 1 = 0.217461 loss)
I0928 15:10:42.086488  4581 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I0928 15:10:56.318827  4581 solver.cpp:218] Iteration 33800 (7.02627 iter/s, 14.2323s/100 iters), loss = 0.225848
I0928 15:10:56.318868  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225848 (* 1 = 0.225848 loss)
I0928 15:10:56.318874  4581 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I0928 15:11:10.554409  4581 solver.cpp:218] Iteration 33900 (7.02469 iter/s, 14.2355s/100 iters), loss = 0.127477
I0928 15:11:10.554450  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127476 (* 1 = 0.127476 loss)
I0928 15:11:10.554456  4581 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I0928 15:11:24.078981  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:11:24.648571  4581 solver.cpp:330] Iteration 34000, Testing net (#0)
I0928 15:11:28.016440  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:11:28.157299  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3935
I0928 15:11:28.157335  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.44543 (* 1 = 3.44543 loss)
I0928 15:11:28.298419  4581 solver.cpp:218] Iteration 34000 (5.63573 iter/s, 17.7439s/100 iters), loss = 0.150886
I0928 15:11:28.298457  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.150886 (* 1 = 0.150886 loss)
I0928 15:11:28.298465  4581 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I0928 15:11:42.524343  4581 solver.cpp:218] Iteration 34100 (7.02955 iter/s, 14.2257s/100 iters), loss = 0.193534
I0928 15:11:42.524384  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193534 (* 1 = 0.193534 loss)
I0928 15:11:42.524389  4581 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I0928 15:11:56.756827  4581 solver.cpp:218] Iteration 34200 (7.02622 iter/s, 14.2324s/100 iters), loss = 0.144863
I0928 15:11:56.756985  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144863 (* 1 = 0.144863 loss)
I0928 15:11:56.757002  4581 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I0928 15:12:10.983361  4581 solver.cpp:218] Iteration 34300 (7.02921 iter/s, 14.2263s/100 iters), loss = 0.149762
I0928 15:12:10.983402  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149762 (* 1 = 0.149762 loss)
I0928 15:12:10.983407  4581 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I0928 15:12:25.210538  4581 solver.cpp:218] Iteration 34400 (7.02885 iter/s, 14.2271s/100 iters), loss = 0.18778
I0928 15:12:25.210588  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18778 (* 1 = 0.18778 loss)
I0928 15:12:25.210594  4581 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I0928 15:12:38.732347  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:12:39.303841  4581 solver.cpp:330] Iteration 34500, Testing net (#0)
I0928 15:12:42.672798  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:12:42.813618  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7086
I0928 15:12:42.813654  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.970657 (* 1 = 0.970657 loss)
I0928 15:12:42.954936  4581 solver.cpp:218] Iteration 34500 (5.63561 iter/s, 17.7443s/100 iters), loss = 0.181357
I0928 15:12:42.954965  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181357 (* 1 = 0.181357 loss)
I0928 15:12:42.954972  4581 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I0928 15:12:57.171308  4581 solver.cpp:218] Iteration 34600 (7.0342 iter/s, 14.2163s/100 iters), loss = 0.178523
I0928 15:12:57.171350  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178523 (* 1 = 0.178523 loss)
I0928 15:12:57.171355  4581 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I0928 15:13:11.399189  4581 solver.cpp:218] Iteration 34700 (7.0285 iter/s, 14.2278s/100 iters), loss = 0.193312
I0928 15:13:11.399255  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193312 (* 1 = 0.193312 loss)
I0928 15:13:11.399262  4581 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I0928 15:13:25.621176  4581 solver.cpp:218] Iteration 34800 (7.03142 iter/s, 14.2219s/100 iters), loss = 0.176181
I0928 15:13:25.621213  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17618 (* 1 = 0.17618 loss)
I0928 15:13:25.621219  4581 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I0928 15:13:39.844398  4581 solver.cpp:218] Iteration 34900 (7.0308 iter/s, 14.2231s/100 iters), loss = 0.18697
I0928 15:13:39.844439  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18697 (* 1 = 0.18697 loss)
I0928 15:13:39.844446  4581 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I0928 15:13:53.359802  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:13:53.929147  4581 solver.cpp:330] Iteration 35000, Testing net (#0)
I0928 15:13:57.299031  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:13:57.440119  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6173
I0928 15:13:57.440155  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.61474 (* 1 = 1.61474 loss)
I0928 15:13:57.581269  4581 solver.cpp:218] Iteration 35000 (5.638 iter/s, 17.7368s/100 iters), loss = 0.10327
I0928 15:13:57.581298  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10327 (* 1 = 0.10327 loss)
I0928 15:13:57.581305  4581 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I0928 15:14:11.812996  4581 solver.cpp:218] Iteration 35100 (7.02659 iter/s, 14.2317s/100 iters), loss = 0.159804
I0928 15:14:11.813037  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159803 (* 1 = 0.159803 loss)
I0928 15:14:11.813042  4581 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I0928 15:14:26.045645  4581 solver.cpp:218] Iteration 35200 (7.02614 iter/s, 14.2326s/100 iters), loss = 0.197154
I0928 15:14:26.045791  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197154 (* 1 = 0.197154 loss)
I0928 15:14:26.045810  4581 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I0928 15:14:40.277557  4581 solver.cpp:218] Iteration 35300 (7.02655 iter/s, 14.2317s/100 iters), loss = 0.122578
I0928 15:14:40.277587  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.122578 (* 1 = 0.122578 loss)
I0928 15:14:40.277593  4581 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I0928 15:14:54.514454  4581 solver.cpp:218] Iteration 35400 (7.02404 iter/s, 14.2368s/100 iters), loss = 0.115481
I0928 15:14:54.514484  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115481 (* 1 = 0.115481 loss)
I0928 15:14:54.514490  4581 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I0928 15:15:08.039018  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:15:08.607792  4581 solver.cpp:330] Iteration 35500, Testing net (#0)
I0928 15:15:11.978140  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:15:12.118625  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.516
I0928 15:15:12.118661  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.08414 (* 1 = 2.08414 loss)
I0928 15:15:12.261173  4581 solver.cpp:218] Iteration 35500 (5.63487 iter/s, 17.7466s/100 iters), loss = 0.149633
I0928 15:15:12.261204  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149633 (* 1 = 0.149633 loss)
I0928 15:15:12.261210  4581 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I0928 15:15:26.486402  4581 solver.cpp:218] Iteration 35600 (7.0298 iter/s, 14.2252s/100 iters), loss = 0.135472
I0928 15:15:26.486444  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135471 (* 1 = 0.135471 loss)
I0928 15:15:26.486459  4581 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I0928 15:15:40.722375  4581 solver.cpp:218] Iteration 35700 (7.0245 iter/s, 14.2359s/100 iters), loss = 0.187845
I0928 15:15:40.722501  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187844 (* 1 = 0.187844 loss)
I0928 15:15:40.722507  4581 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I0928 15:15:54.951838  4581 solver.cpp:218] Iteration 35800 (7.02775 iter/s, 14.2293s/100 iters), loss = 0.154961
I0928 15:15:54.951879  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154961 (* 1 = 0.154961 loss)
I0928 15:15:54.951884  4581 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I0928 15:16:09.182293  4581 solver.cpp:218] Iteration 35900 (7.02722 iter/s, 14.2304s/100 iters), loss = 0.193712
I0928 15:16:09.182323  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193712 (* 1 = 0.193712 loss)
I0928 15:16:09.182329  4581 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I0928 15:16:22.712322  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:16:23.281316  4581 solver.cpp:330] Iteration 36000, Testing net (#0)
I0928 15:16:26.651165  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:16:26.791934  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.562
I0928 15:16:26.791960  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.06153 (* 1 = 2.06153 loss)
I0928 15:16:26.933569  4581 solver.cpp:218] Iteration 36000 (5.63342 iter/s, 17.7512s/100 iters), loss = 0.142721
I0928 15:16:26.933598  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14272 (* 1 = 0.14272 loss)
I0928 15:16:26.933604  4581 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I0928 15:16:41.159960  4581 solver.cpp:218] Iteration 36100 (7.02922 iter/s, 14.2263s/100 iters), loss = 0.212798
I0928 15:16:41.160002  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212798 (* 1 = 0.212798 loss)
I0928 15:16:41.160008  4581 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I0928 15:16:55.389838  4581 solver.cpp:218] Iteration 36200 (7.02751 iter/s, 14.2298s/100 iters), loss = 0.232051
I0928 15:16:55.389981  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232051 (* 1 = 0.232051 loss)
I0928 15:16:55.389999  4581 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I0928 15:17:09.625900  4581 solver.cpp:218] Iteration 36300 (7.02451 iter/s, 14.2359s/100 iters), loss = 0.109324
I0928 15:17:09.625941  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.109324 (* 1 = 0.109324 loss)
I0928 15:17:09.625947  4581 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I0928 15:17:23.862653  4581 solver.cpp:218] Iteration 36400 (7.02411 iter/s, 14.2367s/100 iters), loss = 0.114938
I0928 15:17:23.862694  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114938 (* 1 = 0.114938 loss)
I0928 15:17:23.862700  4581 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I0928 15:17:37.386327  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:17:37.955713  4581 solver.cpp:330] Iteration 36500, Testing net (#0)
I0928 15:17:41.323235  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:17:41.463990  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7251
I0928 15:17:41.464026  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.922078 (* 1 = 0.922078 loss)
I0928 15:17:41.605033  4581 solver.cpp:218] Iteration 36500 (5.63625 iter/s, 17.7423s/100 iters), loss = 0.225574
I0928 15:17:41.605062  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225574 (* 1 = 0.225574 loss)
I0928 15:17:41.605069  4581 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I0928 15:17:55.828444  4581 solver.cpp:218] Iteration 36600 (7.03079 iter/s, 14.2232s/100 iters), loss = 0.245661
I0928 15:17:55.828483  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245661 (* 1 = 0.245661 loss)
I0928 15:17:55.828490  4581 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I0928 15:18:10.059706  4581 solver.cpp:218] Iteration 36700 (7.02682 iter/s, 14.2312s/100 iters), loss = 0.188588
I0928 15:18:10.059844  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188588 (* 1 = 0.188588 loss)
I0928 15:18:10.059864  4581 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I0928 15:18:24.286782  4581 solver.cpp:218] Iteration 36800 (7.02894 iter/s, 14.2269s/100 iters), loss = 0.155817
I0928 15:18:24.286823  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155817 (* 1 = 0.155817 loss)
I0928 15:18:24.286828  4581 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I0928 15:18:38.516333  4581 solver.cpp:218] Iteration 36900 (7.02767 iter/s, 14.2295s/100 iters), loss = 0.105809
I0928 15:18:38.516376  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.105809 (* 1 = 0.105809 loss)
I0928 15:18:38.516382  4581 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I0928 15:18:52.035831  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:18:52.605247  4581 solver.cpp:330] Iteration 37000, Testing net (#0)
I0928 15:18:55.975891  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:18:56.116420  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6735
I0928 15:18:56.116454  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.25532 (* 1 = 1.25532 loss)
I0928 15:18:56.258568  4581 solver.cpp:218] Iteration 37000 (5.6363 iter/s, 17.7421s/100 iters), loss = 0.104401
I0928 15:18:56.258596  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.104401 (* 1 = 0.104401 loss)
I0928 15:18:56.258602  4581 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I0928 15:19:10.479600  4581 solver.cpp:218] Iteration 37100 (7.03187 iter/s, 14.221s/100 iters), loss = 0.168959
I0928 15:19:10.479642  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168959 (* 1 = 0.168959 loss)
I0928 15:19:10.479648  4581 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I0928 15:19:24.702849  4581 solver.cpp:218] Iteration 37200 (7.03078 iter/s, 14.2232s/100 iters), loss = 0.137151
I0928 15:19:24.702975  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.137151 (* 1 = 0.137151 loss)
I0928 15:19:24.702982  4581 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I0928 15:19:38.928647  4581 solver.cpp:218] Iteration 37300 (7.02956 iter/s, 14.2256s/100 iters), loss = 0.169506
I0928 15:19:38.928689  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169506 (* 1 = 0.169506 loss)
I0928 15:19:38.928694  4581 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I0928 15:19:53.154770  4581 solver.cpp:218] Iteration 37400 (7.02936 iter/s, 14.226s/100 iters), loss = 0.106216
I0928 15:19:53.154810  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106216 (* 1 = 0.106216 loss)
I0928 15:19:53.154816  4581 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I0928 15:20:06.671828  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:20:07.241961  4581 solver.cpp:330] Iteration 37500, Testing net (#0)
I0928 15:20:10.608832  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:20:10.749858  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6448
I0928 15:20:10.749894  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.34216 (* 1 = 1.34216 loss)
I0928 15:20:10.892072  4581 solver.cpp:218] Iteration 37500 (5.63787 iter/s, 17.7372s/100 iters), loss = 0.0725198
I0928 15:20:10.892102  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0725195 (* 1 = 0.0725195 loss)
I0928 15:20:10.892109  4581 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I0928 15:20:25.125432  4581 solver.cpp:218] Iteration 37600 (7.02579 iter/s, 14.2333s/100 iters), loss = 0.211467
I0928 15:20:25.125471  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211467 (* 1 = 0.211467 loss)
I0928 15:20:25.125478  4581 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I0928 15:20:39.360872  4581 solver.cpp:218] Iteration 37700 (7.02476 iter/s, 14.2354s/100 iters), loss = 0.221887
I0928 15:20:39.360991  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221887 (* 1 = 0.221887 loss)
I0928 15:20:39.361011  4581 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I0928 15:20:53.601377  4581 solver.cpp:218] Iteration 37800 (7.0223 iter/s, 14.2403s/100 iters), loss = 0.11765
I0928 15:20:53.601418  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.11765 (* 1 = 0.11765 loss)
I0928 15:20:53.601423  4581 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I0928 15:21:07.835585  4581 solver.cpp:218] Iteration 37900 (7.02537 iter/s, 14.2341s/100 iters), loss = 0.190917
I0928 15:21:07.835626  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190916 (* 1 = 0.190916 loss)
I0928 15:21:07.835633  4581 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I0928 15:21:21.367903  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:21:21.937113  4581 solver.cpp:330] Iteration 38000, Testing net (#0)
I0928 15:21:25.307385  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:21:25.448209  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5494
I0928 15:21:25.448243  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.98972 (* 1 = 1.98972 loss)
I0928 15:21:25.590817  4581 solver.cpp:218] Iteration 38000 (5.63217 iter/s, 17.7551s/100 iters), loss = 0.174963
I0928 15:21:25.590847  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174962 (* 1 = 0.174962 loss)
I0928 15:21:25.590853  4581 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I0928 15:21:39.819952  4581 solver.cpp:218] Iteration 38100 (7.02787 iter/s, 14.2291s/100 iters), loss = 0.210842
I0928 15:21:39.819991  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210841 (* 1 = 0.210841 loss)
I0928 15:21:39.819998  4581 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I0928 15:21:54.052801  4581 solver.cpp:218] Iteration 38200 (7.02604 iter/s, 14.2328s/100 iters), loss = 0.16081
I0928 15:21:54.052882  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160809 (* 1 = 0.160809 loss)
I0928 15:21:54.052898  4581 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I0928 15:22:08.283226  4581 solver.cpp:218] Iteration 38300 (7.02726 iter/s, 14.2303s/100 iters), loss = 0.154441
I0928 15:22:08.283254  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154441 (* 1 = 0.154441 loss)
I0928 15:22:08.283260  4581 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I0928 15:22:22.509295  4581 solver.cpp:218] Iteration 38400 (7.02938 iter/s, 14.226s/100 iters), loss = 0.149867
I0928 15:22:22.509336  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149867 (* 1 = 0.149867 loss)
I0928 15:22:22.509342  4581 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I0928 15:22:36.029753  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:22:36.599004  4581 solver.cpp:330] Iteration 38500, Testing net (#0)
I0928 15:22:39.968356  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:22:40.108758  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4784
I0928 15:22:40.108793  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.18355 (* 1 = 2.18355 loss)
I0928 15:22:40.250540  4581 solver.cpp:218] Iteration 38500 (5.63661 iter/s, 17.7412s/100 iters), loss = 0.234971
I0928 15:22:40.250568  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234971 (* 1 = 0.234971 loss)
I0928 15:22:40.250576  4581 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I0928 15:22:54.478236  4581 solver.cpp:218] Iteration 38600 (7.02858 iter/s, 14.2276s/100 iters), loss = 0.117388
I0928 15:22:54.478276  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.117388 (* 1 = 0.117388 loss)
I0928 15:22:54.478283  4581 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I0928 15:23:08.708101  4581 solver.cpp:218] Iteration 38700 (7.02752 iter/s, 14.2298s/100 iters), loss = 0.214702
I0928 15:23:08.708226  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214701 (* 1 = 0.214701 loss)
I0928 15:23:08.708233  4581 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I0928 15:23:22.939859  4581 solver.cpp:218] Iteration 38800 (7.02662 iter/s, 14.2316s/100 iters), loss = 0.120582
I0928 15:23:22.939901  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120582 (* 1 = 0.120582 loss)
I0928 15:23:22.939908  4581 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I0928 15:23:37.168730  4581 solver.cpp:218] Iteration 38900 (7.02801 iter/s, 14.2288s/100 iters), loss = 0.0984936
I0928 15:23:37.168769  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0984933 (* 1 = 0.0984933 loss)
I0928 15:23:37.168776  4581 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I0928 15:23:50.692183  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:23:51.260954  4581 solver.cpp:330] Iteration 39000, Testing net (#0)
I0928 15:23:54.627307  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:23:54.768179  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5735
I0928 15:23:54.768215  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.97606 (* 1 = 1.97606 loss)
I0928 15:23:54.909721  4581 solver.cpp:218] Iteration 39000 (5.63669 iter/s, 17.7409s/100 iters), loss = 0.133232
I0928 15:23:54.909762  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133232 (* 1 = 0.133232 loss)
I0928 15:23:54.909778  4581 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I0928 15:24:09.133541  4581 solver.cpp:218] Iteration 39100 (7.03055 iter/s, 14.2236s/100 iters), loss = 0.102086
I0928 15:24:09.133584  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102086 (* 1 = 0.102086 loss)
I0928 15:24:09.133589  4581 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I0928 15:24:23.363823  4581 solver.cpp:218] Iteration 39200 (7.02731 iter/s, 14.2302s/100 iters), loss = 0.246928
I0928 15:24:23.363973  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246928 (* 1 = 0.246928 loss)
I0928 15:24:23.363992  4581 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I0928 15:24:37.595386  4581 solver.cpp:218] Iteration 39300 (7.02672 iter/s, 14.2314s/100 iters), loss = 0.193208
I0928 15:24:37.595427  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193207 (* 1 = 0.193207 loss)
I0928 15:24:37.595432  4581 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I0928 15:24:51.821270  4581 solver.cpp:218] Iteration 39400 (7.02948 iter/s, 14.2258s/100 iters), loss = 0.150747
I0928 15:24:51.821311  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.150747 (* 1 = 0.150747 loss)
I0928 15:24:51.821317  4581 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I0928 15:25:05.344180  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:25:05.914173  4581 solver.cpp:330] Iteration 39500, Testing net (#0)
I0928 15:25:09.282315  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:25:09.423406  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.672
I0928 15:25:09.423444  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.22248 (* 1 = 1.22248 loss)
I0928 15:25:09.565448  4581 solver.cpp:218] Iteration 39500 (5.63568 iter/s, 17.7441s/100 iters), loss = 0.0585872
I0928 15:25:09.565477  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.058587 (* 1 = 0.058587 loss)
I0928 15:25:09.565485  4581 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I0928 15:25:23.786391  4581 solver.cpp:218] Iteration 39600 (7.03192 iter/s, 14.2209s/100 iters), loss = 0.118472
I0928 15:25:23.786432  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.118471 (* 1 = 0.118471 loss)
I0928 15:25:23.786438  4581 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I0928 15:25:38.006330  4581 solver.cpp:218] Iteration 39700 (7.03242 iter/s, 14.2199s/100 iters), loss = 0.17562
I0928 15:25:38.006454  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17562 (* 1 = 0.17562 loss)
I0928 15:25:38.006464  4581 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I0928 15:25:52.230497  4581 solver.cpp:218] Iteration 39800 (7.03037 iter/s, 14.224s/100 iters), loss = 0.139115
I0928 15:25:52.230540  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139115 (* 1 = 0.139115 loss)
I0928 15:25:52.230547  4581 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I0928 15:26:06.450805  4581 solver.cpp:218] Iteration 39900 (7.03224 iter/s, 14.2202s/100 iters), loss = 0.24406
I0928 15:26:06.450845  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24406 (* 1 = 0.24406 loss)
I0928 15:26:06.450850  4581 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I0928 15:26:19.964128  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:26:20.534632  4581 solver.cpp:330] Iteration 40000, Testing net (#0)
I0928 15:26:23.903564  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:26:24.044735  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4395
I0928 15:26:24.044772  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.14131 (* 1 = 3.14131 loss)
I0928 15:26:24.186003  4581 solver.cpp:218] Iteration 40000 (5.63853 iter/s, 17.7351s/100 iters), loss = 0.149424
I0928 15:26:24.186033  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149424 (* 1 = 0.149424 loss)
I0928 15:26:24.186038  4581 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I0928 15:26:24.186041  4581 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I0928 15:26:38.414983  4581 solver.cpp:218] Iteration 40100 (7.02795 iter/s, 14.2289s/100 iters), loss = 0.11269
I0928 15:26:38.415022  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.11269 (* 1 = 0.11269 loss)
I0928 15:26:38.415029  4581 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I0928 15:26:52.649638  4581 solver.cpp:218] Iteration 40200 (7.02515 iter/s, 14.2346s/100 iters), loss = 0.0760321
I0928 15:26:52.649722  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0760319 (* 1 = 0.0760319 loss)
I0928 15:26:52.649729  4581 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I0928 15:27:06.880642  4581 solver.cpp:218] Iteration 40300 (7.02697 iter/s, 14.2309s/100 iters), loss = 0.086518
I0928 15:27:06.880683  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0865177 (* 1 = 0.0865177 loss)
I0928 15:27:06.880689  4581 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I0928 15:27:21.116230  4581 solver.cpp:218] Iteration 40400 (7.02469 iter/s, 14.2355s/100 iters), loss = 0.0588509
I0928 15:27:21.116271  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0588506 (* 1 = 0.0588506 loss)
I0928 15:27:21.116277  4581 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I0928 15:27:34.640275  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:27:35.210157  4581 solver.cpp:330] Iteration 40500, Testing net (#0)
I0928 15:27:38.579150  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:27:38.720232  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8925
I0928 15:27:38.720266  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.321772 (* 1 = 0.321772 loss)
I0928 15:27:38.862576  4581 solver.cpp:218] Iteration 40500 (5.63499 iter/s, 17.7463s/100 iters), loss = 0.0765632
I0928 15:27:38.862606  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.076563 (* 1 = 0.076563 loss)
I0928 15:27:38.862612  4581 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I0928 15:27:53.088464  4581 solver.cpp:218] Iteration 40600 (7.02947 iter/s, 14.2258s/100 iters), loss = 0.0740475
I0928 15:27:53.088505  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0740472 (* 1 = 0.0740472 loss)
I0928 15:27:53.088511  4581 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I0928 15:28:07.322098  4581 solver.cpp:218] Iteration 40700 (7.02565 iter/s, 14.2336s/100 iters), loss = 0.051398
I0928 15:28:07.322160  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0513977 (* 1 = 0.0513977 loss)
I0928 15:28:07.322166  4581 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I0928 15:28:21.553328  4581 solver.cpp:218] Iteration 40800 (7.02685 iter/s, 14.2311s/100 iters), loss = 0.0473469
I0928 15:28:21.553367  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0473467 (* 1 = 0.0473467 loss)
I0928 15:28:21.553373  4581 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I0928 15:28:35.787000  4581 solver.cpp:218] Iteration 40900 (7.02563 iter/s, 14.2336s/100 iters), loss = 0.0277811
I0928 15:28:35.787041  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0277808 (* 1 = 0.0277808 loss)
I0928 15:28:35.787047  4581 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I0928 15:28:49.312919  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:28:49.882899  4581 solver.cpp:330] Iteration 41000, Testing net (#0)
I0928 15:28:53.254283  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:28:53.395311  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9127
I0928 15:28:53.395346  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.269481 (* 1 = 0.269481 loss)
I0928 15:28:53.537168  4581 solver.cpp:218] Iteration 41000 (5.63378 iter/s, 17.7501s/100 iters), loss = 0.04718
I0928 15:28:53.537197  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0471797 (* 1 = 0.0471797 loss)
I0928 15:28:53.537204  4581 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I0928 15:29:07.768144  4581 solver.cpp:218] Iteration 41100 (7.02696 iter/s, 14.2309s/100 iters), loss = 0.0432522
I0928 15:29:07.768187  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0432519 (* 1 = 0.0432519 loss)
I0928 15:29:07.768193  4581 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I0928 15:29:21.996762  4581 solver.cpp:218] Iteration 41200 (7.02813 iter/s, 14.2285s/100 iters), loss = 0.0407477
I0928 15:29:21.996871  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0407474 (* 1 = 0.0407474 loss)
I0928 15:29:21.996878  4581 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I0928 15:29:36.223434  4581 solver.cpp:218] Iteration 41300 (7.02913 iter/s, 14.2265s/100 iters), loss = 0.0187257
I0928 15:29:36.223464  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0187254 (* 1 = 0.0187254 loss)
I0928 15:29:36.223470  4581 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I0928 15:29:50.451988  4581 solver.cpp:218] Iteration 41400 (7.02816 iter/s, 14.2285s/100 iters), loss = 0.0326819
I0928 15:29:50.452029  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0326816 (* 1 = 0.0326816 loss)
I0928 15:29:50.452035  4581 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I0928 15:30:03.977485  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:30:04.547097  4581 solver.cpp:330] Iteration 41500, Testing net (#0)
I0928 15:30:07.917421  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:30:08.058774  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9162
I0928 15:30:08.058809  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.255961 (* 1 = 0.255961 loss)
I0928 15:30:08.200845  4581 solver.cpp:218] Iteration 41500 (5.63419 iter/s, 17.7488s/100 iters), loss = 0.0561162
I0928 15:30:08.200873  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0561159 (* 1 = 0.0561159 loss)
I0928 15:30:08.200881  4581 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I0928 15:30:22.427573  4581 solver.cpp:218] Iteration 41600 (7.02906 iter/s, 14.2267s/100 iters), loss = 0.0660746
I0928 15:30:22.427614  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0660743 (* 1 = 0.0660743 loss)
I0928 15:30:22.427620  4581 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I0928 15:30:36.657796  4581 solver.cpp:218] Iteration 41700 (7.02734 iter/s, 14.2301s/100 iters), loss = 0.0183095
I0928 15:30:36.657868  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0183092 (* 1 = 0.0183092 loss)
I0928 15:30:36.657876  4581 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I0928 15:30:50.885804  4581 solver.cpp:218] Iteration 41800 (7.02845 iter/s, 14.2279s/100 iters), loss = 0.0452675
I0928 15:30:50.885843  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0452672 (* 1 = 0.0452672 loss)
I0928 15:30:50.885850  4581 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I0928 15:31:05.115121  4581 solver.cpp:218] Iteration 41900 (7.02778 iter/s, 14.2292s/100 iters), loss = 0.013666
I0928 15:31:05.115162  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136658 (* 1 = 0.0136658 loss)
I0928 15:31:05.115170  4581 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I0928 15:31:18.637363  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:31:19.207535  4581 solver.cpp:330] Iteration 42000, Testing net (#0)
I0928 15:31:22.576807  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:31:22.717535  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9202
I0928 15:31:22.717571  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.250371 (* 1 = 0.250371 loss)
I0928 15:31:22.859422  4581 solver.cpp:218] Iteration 42000 (5.63564 iter/s, 17.7442s/100 iters), loss = 0.028683
I0928 15:31:22.859452  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0286827 (* 1 = 0.0286827 loss)
I0928 15:31:22.859458  4581 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I0928 15:31:37.080303  4581 solver.cpp:218] Iteration 42100 (7.03195 iter/s, 14.2208s/100 iters), loss = 0.0533991
I0928 15:31:37.080344  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0533988 (* 1 = 0.0533988 loss)
I0928 15:31:37.080350  4581 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I0928 15:31:51.309021  4581 solver.cpp:218] Iteration 42200 (7.02808 iter/s, 14.2286s/100 iters), loss = 0.0765283
I0928 15:31:51.309137  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.076528 (* 1 = 0.076528 loss)
I0928 15:31:51.309144  4581 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I0928 15:32:05.531280  4581 solver.cpp:218] Iteration 42300 (7.03131 iter/s, 14.2221s/100 iters), loss = 0.0407004
I0928 15:32:05.531321  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0407001 (* 1 = 0.0407001 loss)
I0928 15:32:05.531327  4581 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I0928 15:32:19.753772  4581 solver.cpp:218] Iteration 42400 (7.03116 iter/s, 14.2224s/100 iters), loss = 0.014116
I0928 15:32:19.753813  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141157 (* 1 = 0.0141157 loss)
I0928 15:32:19.753818  4581 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I0928 15:32:33.278532  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:32:33.847620  4581 solver.cpp:330] Iteration 42500, Testing net (#0)
I0928 15:32:37.217010  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:32:37.358058  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9157
I0928 15:32:37.358093  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.263574 (* 1 = 0.263574 loss)
I0928 15:32:37.499294  4581 solver.cpp:218] Iteration 42500 (5.63525 iter/s, 17.7454s/100 iters), loss = 0.0280478
I0928 15:32:37.499322  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0280475 (* 1 = 0.0280475 loss)
I0928 15:32:37.499330  4581 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I0928 15:32:51.729670  4581 solver.cpp:218] Iteration 42600 (7.02726 iter/s, 14.2303s/100 iters), loss = 0.0291933
I0928 15:32:51.729712  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0291931 (* 1 = 0.0291931 loss)
I0928 15:32:51.729717  4581 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I0928 15:33:05.952327  4581 solver.cpp:218] Iteration 42700 (7.03108 iter/s, 14.2226s/100 iters), loss = 0.0303714
I0928 15:33:05.952389  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0303712 (* 1 = 0.0303712 loss)
I0928 15:33:05.952395  4581 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I0928 15:33:20.172458  4581 solver.cpp:218] Iteration 42800 (7.03233 iter/s, 14.22s/100 iters), loss = 0.0231773
I0928 15:33:20.172500  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.023177 (* 1 = 0.023177 loss)
I0928 15:33:20.172505  4581 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I0928 15:33:34.388443  4581 solver.cpp:218] Iteration 42900 (7.03438 iter/s, 14.2159s/100 iters), loss = 0.0300823
I0928 15:33:34.388484  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.030082 (* 1 = 0.030082 loss)
I0928 15:33:34.388491  4581 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I0928 15:33:47.907554  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:33:48.477571  4581 solver.cpp:330] Iteration 43000, Testing net (#0)
I0928 15:33:51.847278  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:33:51.988310  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9125
I0928 15:33:51.988346  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.277193 (* 1 = 0.277193 loss)
I0928 15:33:52.130650  4581 solver.cpp:218] Iteration 43000 (5.63631 iter/s, 17.7421s/100 iters), loss = 0.0219225
I0928 15:33:52.130678  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0219223 (* 1 = 0.0219223 loss)
I0928 15:33:52.130686  4581 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I0928 15:34:06.358883  4581 solver.cpp:218] Iteration 43100 (7.02831 iter/s, 14.2282s/100 iters), loss = 0.0682173
I0928 15:34:06.358913  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0682171 (* 1 = 0.0682171 loss)
I0928 15:34:06.358930  4581 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I0928 15:34:20.590893  4581 solver.cpp:218] Iteration 43200 (7.02645 iter/s, 14.2319s/100 iters), loss = 0.0101641
I0928 15:34:20.591015  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101638 (* 1 = 0.0101638 loss)
I0928 15:34:20.591032  4581 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I0928 15:34:34.828845  4581 solver.cpp:218] Iteration 43300 (7.02356 iter/s, 14.2378s/100 iters), loss = 0.0601019
I0928 15:34:34.828874  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0601016 (* 1 = 0.0601016 loss)
I0928 15:34:34.828891  4581 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I0928 15:34:49.063074  4581 solver.cpp:218] Iteration 43400 (7.02535 iter/s, 14.2342s/100 iters), loss = 0.0471728
I0928 15:34:49.063105  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0471726 (* 1 = 0.0471726 loss)
I0928 15:34:49.063112  4581 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I0928 15:35:02.589635  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:35:03.160503  4581 solver.cpp:330] Iteration 43500, Testing net (#0)
I0928 15:35:06.532564  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:35:06.673560  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9132
I0928 15:35:06.673596  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.281428 (* 1 = 0.281428 loss)
I0928 15:35:06.815490  4581 solver.cpp:218] Iteration 43500 (5.63306 iter/s, 17.7523s/100 iters), loss = 0.017639
I0928 15:35:06.815518  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176387 (* 1 = 0.0176387 loss)
I0928 15:35:06.815526  4581 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I0928 15:35:21.034514  4581 solver.cpp:218] Iteration 43600 (7.03287 iter/s, 14.2189s/100 iters), loss = 0.0491471
I0928 15:35:21.034548  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0491469 (* 1 = 0.0491469 loss)
I0928 15:35:21.034554  4581 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I0928 15:35:35.265015  4581 solver.cpp:218] Iteration 43700 (7.0272 iter/s, 14.2304s/100 iters), loss = 0.0347933
I0928 15:35:35.265133  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.034793 (* 1 = 0.034793 loss)
I0928 15:35:35.265151  4581 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I0928 15:35:49.497238  4581 solver.cpp:218] Iteration 43800 (7.02639 iter/s, 14.2321s/100 iters), loss = 0.0251282
I0928 15:35:49.497268  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.025128 (* 1 = 0.025128 loss)
I0928 15:35:49.497284  4581 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I0928 15:36:03.727219  4581 solver.cpp:218] Iteration 43900 (7.02745 iter/s, 14.2299s/100 iters), loss = 0.00613042
I0928 15:36:03.727252  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00613016 (* 1 = 0.00613016 loss)
I0928 15:36:03.727257  4581 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I0928 15:36:17.252109  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:36:17.822618  4581 solver.cpp:330] Iteration 44000, Testing net (#0)
I0928 15:36:21.192255  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:36:21.334115  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9108
I0928 15:36:21.334151  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.297553 (* 1 = 0.297553 loss)
I0928 15:36:21.476795  4581 solver.cpp:218] Iteration 44000 (5.63396 iter/s, 17.7495s/100 iters), loss = 0.0173137
I0928 15:36:21.476824  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0173134 (* 1 = 0.0173134 loss)
I0928 15:36:21.476830  4581 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I0928 15:36:35.699038  4581 solver.cpp:218] Iteration 44100 (7.03127 iter/s, 14.2222s/100 iters), loss = 0.0385205
I0928 15:36:35.699067  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0385202 (* 1 = 0.0385202 loss)
I0928 15:36:35.699084  4581 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I0928 15:36:49.922914  4581 solver.cpp:218] Iteration 44200 (7.03047 iter/s, 14.2238s/100 iters), loss = 0.025427
I0928 15:36:49.923004  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0254267 (* 1 = 0.0254267 loss)
I0928 15:36:49.923012  4581 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I0928 15:37:04.147893  4581 solver.cpp:218] Iteration 44300 (7.02995 iter/s, 14.2249s/100 iters), loss = 0.00535301
I0928 15:37:04.147924  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00535275 (* 1 = 0.00535275 loss)
I0928 15:37:04.147940  4581 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I0928 15:37:18.380089  4581 solver.cpp:218] Iteration 44400 (7.02636 iter/s, 14.2321s/100 iters), loss = 0.00902633
I0928 15:37:18.380120  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00902608 (* 1 = 0.00902608 loss)
I0928 15:37:18.380136  4581 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I0928 15:37:31.901340  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:37:32.470003  4581 solver.cpp:330] Iteration 44500, Testing net (#0)
I0928 15:37:35.839135  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:37:35.980414  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9162
I0928 15:37:35.980440  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.279048 (* 1 = 0.279048 loss)
I0928 15:37:36.122429  4581 solver.cpp:218] Iteration 44500 (5.63626 iter/s, 17.7423s/100 iters), loss = 0.0412119
I0928 15:37:36.122458  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0412116 (* 1 = 0.0412116 loss)
I0928 15:37:36.122465  4581 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I0928 15:37:50.343935  4581 solver.cpp:218] Iteration 44600 (7.03164 iter/s, 14.2214s/100 iters), loss = 0.0129081
I0928 15:37:50.343966  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0129078 (* 1 = 0.0129078 loss)
I0928 15:37:50.343981  4581 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I0928 15:38:04.567126  4581 solver.cpp:218] Iteration 44700 (7.03081 iter/s, 14.2231s/100 iters), loss = 0.0182921
I0928 15:38:04.567252  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0182918 (* 1 = 0.0182918 loss)
I0928 15:38:04.567270  4581 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I0928 15:38:18.789037  4581 solver.cpp:218] Iteration 44800 (7.03149 iter/s, 14.2217s/100 iters), loss = 0.0179898
I0928 15:38:18.789067  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0179895 (* 1 = 0.0179895 loss)
I0928 15:38:18.789083  4581 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I0928 15:38:33.011081  4581 solver.cpp:218] Iteration 44900 (7.03137 iter/s, 14.222s/100 iters), loss = 0.00622443
I0928 15:38:33.011112  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00622419 (* 1 = 0.00622419 loss)
I0928 15:38:33.011128  4581 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I0928 15:38:46.532277  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:38:47.102108  4581 solver.cpp:330] Iteration 45000, Testing net (#0)
I0928 15:38:50.471042  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:38:50.612042  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9177
I0928 15:38:50.612078  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.274154 (* 1 = 0.274154 loss)
I0928 15:38:50.754107  4581 solver.cpp:218] Iteration 45000 (5.63604 iter/s, 17.7429s/100 iters), loss = 0.00975788
I0928 15:38:50.754138  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00975763 (* 1 = 0.00975763 loss)
I0928 15:38:50.754145  4581 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I0928 15:39:04.981077  4581 solver.cpp:218] Iteration 45100 (7.02894 iter/s, 14.2269s/100 iters), loss = 0.00965925
I0928 15:39:04.981108  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00965901 (* 1 = 0.00965901 loss)
I0928 15:39:04.981124  4581 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I0928 15:39:19.215725  4581 solver.cpp:218] Iteration 45200 (7.02515 iter/s, 14.2346s/100 iters), loss = 0.0141973
I0928 15:39:19.215867  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014197 (* 1 = 0.014197 loss)
I0928 15:39:19.215890  4581 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I0928 15:39:33.443020  4581 solver.cpp:218] Iteration 45300 (7.02883 iter/s, 14.2271s/100 iters), loss = 0.00529142
I0928 15:39:33.443051  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0052912 (* 1 = 0.0052912 loss)
I0928 15:39:33.443068  4581 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I0928 15:39:47.669682  4581 solver.cpp:218] Iteration 45400 (7.02909 iter/s, 14.2266s/100 iters), loss = 0.0216597
I0928 15:39:47.669713  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0216595 (* 1 = 0.0216595 loss)
I0928 15:39:47.669728  4581 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I0928 15:40:01.188163  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:40:01.759038  4581 solver.cpp:330] Iteration 45500, Testing net (#0)
I0928 15:40:05.127598  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:40:05.268366  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9199
I0928 15:40:05.268402  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.273058 (* 1 = 0.273058 loss)
I0928 15:40:05.410595  4581 solver.cpp:218] Iteration 45500 (5.63671 iter/s, 17.7408s/100 iters), loss = 0.0346784
I0928 15:40:05.410624  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0346782 (* 1 = 0.0346782 loss)
I0928 15:40:05.410630  4581 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I0928 15:40:19.639727  4581 solver.cpp:218] Iteration 45600 (7.02787 iter/s, 14.2291s/100 iters), loss = 0.0148036
I0928 15:40:19.639758  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148033 (* 1 = 0.0148033 loss)
I0928 15:40:19.639775  4581 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I0928 15:40:33.877763  4581 solver.cpp:218] Iteration 45700 (7.02348 iter/s, 14.238s/100 iters), loss = 0.0124134
I0928 15:40:33.877846  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124132 (* 1 = 0.0124132 loss)
I0928 15:40:33.877863  4581 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I0928 15:40:48.110322  4581 solver.cpp:218] Iteration 45800 (7.0262 iter/s, 14.2324s/100 iters), loss = 0.0292243
I0928 15:40:48.110353  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.029224 (* 1 = 0.029224 loss)
I0928 15:40:48.110369  4581 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I0928 15:41:02.342022  4581 solver.cpp:218] Iteration 45900 (7.0266 iter/s, 14.2316s/100 iters), loss = 0.00764976
I0928 15:41:02.342051  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00764948 (* 1 = 0.00764948 loss)
I0928 15:41:02.342068  4581 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I0928 15:41:15.865767  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:41:16.435925  4581 solver.cpp:330] Iteration 46000, Testing net (#0)
I0928 15:41:19.807284  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:41:19.948284  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9195
I0928 15:41:19.948319  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.281711 (* 1 = 0.281711 loss)
I0928 15:41:20.089645  4581 solver.cpp:218] Iteration 46000 (5.63458 iter/s, 17.7475s/100 iters), loss = 0.0142894
I0928 15:41:20.089674  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142891 (* 1 = 0.0142891 loss)
I0928 15:41:20.089681  4581 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I0928 15:41:34.306203  4581 solver.cpp:218] Iteration 46100 (7.03409 iter/s, 14.2165s/100 iters), loss = 0.044168
I0928 15:41:34.306233  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0441677 (* 1 = 0.0441677 loss)
I0928 15:41:34.306239  4581 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I0928 15:41:48.531170  4581 solver.cpp:218] Iteration 46200 (7.02993 iter/s, 14.2249s/100 iters), loss = 0.0237381
I0928 15:41:48.531293  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0237378 (* 1 = 0.0237378 loss)
I0928 15:41:48.531311  4581 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I0928 15:42:02.756455  4581 solver.cpp:218] Iteration 46300 (7.02982 iter/s, 14.2251s/100 iters), loss = 0.00560576
I0928 15:42:02.756486  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00560548 (* 1 = 0.00560548 loss)
I0928 15:42:02.756502  4581 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I0928 15:42:16.980356  4581 solver.cpp:218] Iteration 46400 (7.03046 iter/s, 14.2238s/100 iters), loss = 0.00546871
I0928 15:42:16.980387  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00546844 (* 1 = 0.00546844 loss)
I0928 15:42:16.980403  4581 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I0928 15:42:30.494829  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:42:31.063760  4581 solver.cpp:330] Iteration 46500, Testing net (#0)
I0928 15:42:34.433449  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:42:34.574494  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9203
I0928 15:42:34.574532  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.280279 (* 1 = 0.280279 loss)
I0928 15:42:34.715979  4581 solver.cpp:218] Iteration 46500 (5.6384 iter/s, 17.7355s/100 iters), loss = 0.00889132
I0928 15:42:34.716008  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00889106 (* 1 = 0.00889106 loss)
I0928 15:42:34.716014  4581 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I0928 15:42:48.936864  4581 solver.cpp:218] Iteration 46600 (7.03195 iter/s, 14.2208s/100 iters), loss = 0.0462342
I0928 15:42:48.936906  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.046234 (* 1 = 0.046234 loss)
I0928 15:42:48.936913  4581 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I0928 15:43:03.164795  4581 solver.cpp:218] Iteration 46700 (7.02847 iter/s, 14.2278s/100 iters), loss = 0.00422245
I0928 15:43:03.164912  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00422219 (* 1 = 0.00422219 loss)
I0928 15:43:03.164929  4581 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I0928 15:43:17.393940  4581 solver.cpp:218] Iteration 46800 (7.0279 iter/s, 14.229s/100 iters), loss = 0.0246041
I0928 15:43:17.393980  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0246038 (* 1 = 0.0246038 loss)
I0928 15:43:17.393986  4581 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I0928 15:43:31.621296  4581 solver.cpp:218] Iteration 46900 (7.02875 iter/s, 14.2273s/100 iters), loss = 0.00716325
I0928 15:43:31.621336  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00716299 (* 1 = 0.00716299 loss)
I0928 15:43:31.621342  4581 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I0928 15:43:45.140377  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:43:45.710395  4581 solver.cpp:330] Iteration 47000, Testing net (#0)
I0928 15:43:49.081023  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:43:49.222338  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9182
I0928 15:43:49.222373  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.292053 (* 1 = 0.292053 loss)
I0928 15:43:49.364751  4581 solver.cpp:218] Iteration 47000 (5.63591 iter/s, 17.7434s/100 iters), loss = 0.00750649
I0928 15:43:49.364779  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00750623 (* 1 = 0.00750623 loss)
I0928 15:43:49.364786  4581 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I0928 15:44:03.588454  4581 solver.cpp:218] Iteration 47100 (7.03056 iter/s, 14.2236s/100 iters), loss = 0.011635
I0928 15:44:03.588493  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116348 (* 1 = 0.0116348 loss)
I0928 15:44:03.588500  4581 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I0928 15:44:17.812650  4581 solver.cpp:218] Iteration 47200 (7.03031 iter/s, 14.2241s/100 iters), loss = 0.0391116
I0928 15:44:17.812777  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0391113 (* 1 = 0.0391113 loss)
I0928 15:44:17.812783  4581 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I0928 15:44:32.039151  4581 solver.cpp:218] Iteration 47300 (7.02921 iter/s, 14.2263s/100 iters), loss = 0.00978993
I0928 15:44:32.039181  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00978967 (* 1 = 0.00978967 loss)
I0928 15:44:32.039188  4581 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I0928 15:44:46.263121  4581 solver.cpp:218] Iteration 47400 (7.03042 iter/s, 14.2239s/100 iters), loss = 0.00683581
I0928 15:44:46.263162  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00683555 (* 1 = 0.00683555 loss)
I0928 15:44:46.263169  4581 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I0928 15:44:59.784692  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:45:00.354594  4581 solver.cpp:330] Iteration 47500, Testing net (#0)
I0928 15:45:03.725913  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:45:03.867292  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9177
I0928 15:45:03.867328  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307148 (* 1 = 0.307148 loss)
I0928 15:45:04.009114  4581 solver.cpp:218] Iteration 47500 (5.6351 iter/s, 17.7459s/100 iters), loss = 0.0191471
I0928 15:45:04.009142  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0191468 (* 1 = 0.0191468 loss)
I0928 15:45:04.009150  4581 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I0928 15:45:18.232139  4581 solver.cpp:218] Iteration 47600 (7.03089 iter/s, 14.2229s/100 iters), loss = 0.0884334
I0928 15:45:18.232179  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0884332 (* 1 = 0.0884332 loss)
I0928 15:45:18.232185  4581 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I0928 15:45:32.460469  4581 solver.cpp:218] Iteration 47700 (7.02827 iter/s, 14.2282s/100 iters), loss = 0.0113022
I0928 15:45:32.460546  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011302 (* 1 = 0.011302 loss)
I0928 15:45:32.460552  4581 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I0928 15:45:46.686807  4581 solver.cpp:218] Iteration 47800 (7.02927 iter/s, 14.2262s/100 iters), loss = 0.010676
I0928 15:45:46.686848  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106757 (* 1 = 0.0106757 loss)
I0928 15:45:46.686854  4581 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I0928 15:46:00.905148  4581 solver.cpp:218] Iteration 47900 (7.03321 iter/s, 14.2183s/100 iters), loss = 0.0141639
I0928 15:46:00.905189  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141636 (* 1 = 0.0141636 loss)
I0928 15:46:00.905195  4581 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I0928 15:46:14.425379  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:46:14.995204  4581 solver.cpp:330] Iteration 48000, Testing net (#0)
I0928 15:46:18.367313  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:46:18.508087  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9176
I0928 15:46:18.508123  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.297421 (* 1 = 0.297421 loss)
I0928 15:46:18.649488  4581 solver.cpp:218] Iteration 48000 (5.63563 iter/s, 17.7442s/100 iters), loss = 0.013192
I0928 15:46:18.649518  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131918 (* 1 = 0.0131918 loss)
I0928 15:46:18.649524  4581 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I0928 15:46:32.884291  4581 solver.cpp:218] Iteration 48100 (7.02507 iter/s, 14.2347s/100 iters), loss = 0.0308435
I0928 15:46:32.884332  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0308433 (* 1 = 0.0308433 loss)
I0928 15:46:32.884338  4581 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I0928 15:46:47.117619  4581 solver.cpp:218] Iteration 48200 (7.02581 iter/s, 14.2332s/100 iters), loss = 0.0104266
I0928 15:46:47.117696  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104264 (* 1 = 0.0104264 loss)
I0928 15:46:47.117712  4581 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I0928 15:47:01.353567  4581 solver.cpp:218] Iteration 48300 (7.02453 iter/s, 14.2358s/100 iters), loss = 0.0264874
I0928 15:47:01.353608  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0264871 (* 1 = 0.0264871 loss)
I0928 15:47:01.353615  4581 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I0928 15:47:15.590188  4581 solver.cpp:218] Iteration 48400 (7.02418 iter/s, 14.2365s/100 iters), loss = 0.00871023
I0928 15:47:15.590227  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00871 (* 1 = 0.00871 loss)
I0928 15:47:15.590234  4581 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I0928 15:47:29.117357  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:47:29.687813  4581 solver.cpp:330] Iteration 48500, Testing net (#0)
I0928 15:47:33.059149  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:47:33.200749  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9214
I0928 15:47:33.200785  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.281034 (* 1 = 0.281034 loss)
I0928 15:47:33.342408  4581 solver.cpp:218] Iteration 48500 (5.63313 iter/s, 17.7521s/100 iters), loss = 0.010199
I0928 15:47:33.342438  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101988 (* 1 = 0.0101988 loss)
I0928 15:47:33.342444  4581 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I0928 15:47:47.578424  4581 solver.cpp:218] Iteration 48600 (7.02449 iter/s, 14.2359s/100 iters), loss = 0.00470654
I0928 15:47:47.578464  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00470632 (* 1 = 0.00470632 loss)
I0928 15:47:47.578469  4581 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I0928 15:48:01.816742  4581 solver.cpp:218] Iteration 48700 (7.02334 iter/s, 14.2382s/100 iters), loss = 0.0166058
I0928 15:48:01.816817  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0166056 (* 1 = 0.0166056 loss)
I0928 15:48:01.816823  4581 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I0928 15:48:16.054155  4581 solver.cpp:218] Iteration 48800 (7.0238 iter/s, 14.2373s/100 iters), loss = 0.00476047
I0928 15:48:16.054196  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00476025 (* 1 = 0.00476025 loss)
I0928 15:48:16.054203  4581 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I0928 15:48:30.285980  4581 solver.cpp:218] Iteration 48900 (7.02655 iter/s, 14.2317s/100 iters), loss = 0.00314907
I0928 15:48:30.286022  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00314885 (* 1 = 0.00314885 loss)
I0928 15:48:30.286028  4581 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I0928 15:48:43.814728  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:48:44.383963  4581 solver.cpp:330] Iteration 49000, Testing net (#0)
I0928 15:48:47.755286  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:48:47.896354  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9232
I0928 15:48:47.896390  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.279448 (* 1 = 0.279448 loss)
I0928 15:48:48.037890  4581 solver.cpp:218] Iteration 49000 (5.63323 iter/s, 17.7518s/100 iters), loss = 0.00901654
I0928 15:48:48.037919  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00901632 (* 1 = 0.00901632 loss)
I0928 15:48:48.037926  4581 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I0928 15:49:02.267472  4581 solver.cpp:218] Iteration 49100 (7.02765 iter/s, 14.2295s/100 iters), loss = 0.0236345
I0928 15:49:02.267511  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0236343 (* 1 = 0.0236343 loss)
I0928 15:49:02.267518  4581 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I0928 15:49:16.499524  4581 solver.cpp:218] Iteration 49200 (7.02643 iter/s, 14.232s/100 iters), loss = 0.00191969
I0928 15:49:16.499656  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00191947 (* 1 = 0.00191947 loss)
I0928 15:49:16.499665  4581 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I0928 15:49:30.726747  4581 solver.cpp:218] Iteration 49300 (7.02886 iter/s, 14.2271s/100 iters), loss = 0.0096987
I0928 15:49:30.726788  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00969849 (* 1 = 0.00969849 loss)
I0928 15:49:30.726794  4581 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I0928 15:49:44.956974  4581 solver.cpp:218] Iteration 49400 (7.02734 iter/s, 14.2301s/100 iters), loss = 0.00362493
I0928 15:49:44.957015  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00362471 (* 1 = 0.00362471 loss)
I0928 15:49:44.957021  4581 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I0928 15:49:58.481111  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:49:59.050346  4581 solver.cpp:330] Iteration 49500, Testing net (#0)
I0928 15:50:02.420347  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:50:02.562458  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9208
I0928 15:50:02.562494  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295557 (* 1 = 0.295557 loss)
I0928 15:50:02.704679  4581 solver.cpp:218] Iteration 49500 (5.63456 iter/s, 17.7476s/100 iters), loss = 0.0413367
I0928 15:50:02.704706  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0413365 (* 1 = 0.0413365 loss)
I0928 15:50:02.704715  4581 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I0928 15:50:16.920754  4581 solver.cpp:218] Iteration 49600 (7.03433 iter/s, 14.216s/100 iters), loss = 0.0198293
I0928 15:50:16.920795  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0198291 (* 1 = 0.0198291 loss)
I0928 15:50:16.920801  4581 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I0928 15:50:31.143299  4581 solver.cpp:218] Iteration 49700 (7.03113 iter/s, 14.2225s/100 iters), loss = 0.0156384
I0928 15:50:31.143442  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156382 (* 1 = 0.0156382 loss)
I0928 15:50:31.143450  4581 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I0928 15:50:45.363517  4581 solver.cpp:218] Iteration 49800 (7.03233 iter/s, 14.22s/100 iters), loss = 0.0286654
I0928 15:50:45.363557  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0286651 (* 1 = 0.0286651 loss)
I0928 15:50:45.363564  4581 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I0928 15:50:59.581681  4581 solver.cpp:218] Iteration 49900 (7.0333 iter/s, 14.2181s/100 iters), loss = 0.00473597
I0928 15:50:59.581722  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00473575 (* 1 = 0.00473575 loss)
I0928 15:50:59.581728  4581 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I0928 15:51:13.097465  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:51:13.667151  4581 solver.cpp:330] Iteration 50000, Testing net (#0)
I0928 15:51:17.035274  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:51:17.176311  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.919
I0928 15:51:17.176348  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296308 (* 1 = 0.296308 loss)
I0928 15:51:17.318202  4581 solver.cpp:218] Iteration 50000 (5.63811 iter/s, 17.7364s/100 iters), loss = 0.00599593
I0928 15:51:17.318230  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00599572 (* 1 = 0.00599572 loss)
I0928 15:51:17.318238  4581 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I0928 15:51:31.534672  4581 solver.cpp:218] Iteration 50100 (7.03413 iter/s, 14.2164s/100 iters), loss = 0.0316546
I0928 15:51:31.534713  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0316544 (* 1 = 0.0316544 loss)
I0928 15:51:31.534719  4581 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I0928 15:51:45.765079  4581 solver.cpp:218] Iteration 50200 (7.02725 iter/s, 14.2303s/100 iters), loss = 0.0060301
I0928 15:51:45.765184  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00602989 (* 1 = 0.00602989 loss)
I0928 15:51:45.765192  4581 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I0928 15:51:59.994767  4581 solver.cpp:218] Iteration 50300 (7.02763 iter/s, 14.2295s/100 iters), loss = 0.0044163
I0928 15:51:59.994807  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00441609 (* 1 = 0.00441609 loss)
I0928 15:51:59.994812  4581 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I0928 15:52:14.220345  4581 solver.cpp:218] Iteration 50400 (7.02963 iter/s, 14.2255s/100 iters), loss = 0.0126277
I0928 15:52:14.220386  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126275 (* 1 = 0.0126275 loss)
I0928 15:52:14.220391  4581 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I0928 15:52:27.747015  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:52:28.315850  4581 solver.cpp:330] Iteration 50500, Testing net (#0)
I0928 15:52:31.683243  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:52:31.824342  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9239
I0928 15:52:31.824376  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.283117 (* 1 = 0.283117 loss)
I0928 15:52:31.965703  4581 solver.cpp:218] Iteration 50500 (5.63531 iter/s, 17.7453s/100 iters), loss = 0.00520739
I0928 15:52:31.965734  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00520719 (* 1 = 0.00520719 loss)
I0928 15:52:31.965742  4581 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I0928 15:52:46.195701  4581 solver.cpp:218] Iteration 50600 (7.02758 iter/s, 14.2297s/100 iters), loss = 0.00750045
I0928 15:52:46.195742  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00750024 (* 1 = 0.00750024 loss)
I0928 15:52:46.195749  4581 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I0928 15:53:00.424640  4581 solver.cpp:218] Iteration 50700 (7.02797 iter/s, 14.2289s/100 iters), loss = 0.0231207
I0928 15:53:00.424715  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0231206 (* 1 = 0.0231206 loss)
I0928 15:53:00.424722  4581 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I0928 15:53:14.654918  4581 solver.cpp:218] Iteration 50800 (7.02733 iter/s, 14.2302s/100 iters), loss = 0.00624164
I0928 15:53:14.654959  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00624145 (* 1 = 0.00624145 loss)
I0928 15:53:14.654965  4581 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I0928 15:53:28.880578  4581 solver.cpp:218] Iteration 50900 (7.02959 iter/s, 14.2256s/100 iters), loss = 0.00267812
I0928 15:53:28.880617  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00267793 (* 1 = 0.00267793 loss)
I0928 15:53:28.880623  4581 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I0928 15:53:42.401161  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:53:42.973026  4581 solver.cpp:330] Iteration 51000, Testing net (#0)
I0928 15:53:46.342772  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:53:46.483992  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9203
I0928 15:53:46.484030  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307056 (* 1 = 0.307056 loss)
I0928 15:53:46.625583  4581 solver.cpp:218] Iteration 51000 (5.63542 iter/s, 17.7449s/100 iters), loss = 0.00294743
I0928 15:53:46.625613  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00294724 (* 1 = 0.00294724 loss)
I0928 15:53:46.625619  4581 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I0928 15:54:00.853252  4581 solver.cpp:218] Iteration 51100 (7.02859 iter/s, 14.2276s/100 iters), loss = 0.00234613
I0928 15:54:00.853293  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00234594 (* 1 = 0.00234594 loss)
I0928 15:54:00.853299  4581 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I0928 15:54:15.082011  4581 solver.cpp:218] Iteration 51200 (7.02806 iter/s, 14.2287s/100 iters), loss = 0.00160603
I0928 15:54:15.082077  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00160585 (* 1 = 0.00160585 loss)
I0928 15:54:15.082083  4581 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I0928 15:54:29.307118  4581 solver.cpp:218] Iteration 51300 (7.02988 iter/s, 14.225s/100 iters), loss = 0.00414544
I0928 15:54:29.307159  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00414525 (* 1 = 0.00414525 loss)
I0928 15:54:29.307166  4581 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I0928 15:54:43.537684  4581 solver.cpp:218] Iteration 51400 (7.02717 iter/s, 14.2305s/100 iters), loss = 0.00430573
I0928 15:54:43.537725  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00430553 (* 1 = 0.00430553 loss)
I0928 15:54:43.537731  4581 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I0928 15:54:57.055196  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:54:57.625356  4581 solver.cpp:330] Iteration 51500, Testing net (#0)
I0928 15:55:00.995568  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:55:01.136507  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9142
I0928 15:55:01.136533  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329256 (* 1 = 0.329256 loss)
I0928 15:55:01.278247  4581 solver.cpp:218] Iteration 51500 (5.63683 iter/s, 17.7405s/100 iters), loss = 0.00876248
I0928 15:55:01.278276  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00876228 (* 1 = 0.00876228 loss)
I0928 15:55:01.278283  4581 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I0928 15:55:15.508478  4581 solver.cpp:218] Iteration 51600 (7.02733 iter/s, 14.2302s/100 iters), loss = 0.00138958
I0928 15:55:15.508508  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00138938 (* 1 = 0.00138938 loss)
I0928 15:55:15.508525  4581 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I0928 15:55:29.731683  4581 solver.cpp:218] Iteration 51700 (7.0308 iter/s, 14.2231s/100 iters), loss = 0.00658285
I0928 15:55:29.731748  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00658266 (* 1 = 0.00658266 loss)
I0928 15:55:29.731755  4581 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I0928 15:55:43.959017  4581 solver.cpp:218] Iteration 51800 (7.02878 iter/s, 14.2272s/100 iters), loss = 0.00245323
I0928 15:55:43.959046  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00245304 (* 1 = 0.00245304 loss)
I0928 15:55:43.959062  4581 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I0928 15:55:58.180560  4581 solver.cpp:218] Iteration 51900 (7.03162 iter/s, 14.2215s/100 iters), loss = 0.00348008
I0928 15:55:58.180591  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00347989 (* 1 = 0.00347989 loss)
I0928 15:55:58.180608  4581 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I0928 15:56:11.698112  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:56:12.268216  4581 solver.cpp:330] Iteration 52000, Testing net (#0)
I0928 15:56:15.636548  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:56:15.777904  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9233
I0928 15:56:15.777938  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300837 (* 1 = 0.300837 loss)
I0928 15:56:15.919594  4581 solver.cpp:218] Iteration 52000 (5.63731 iter/s, 17.739s/100 iters), loss = 0.012497
I0928 15:56:15.919623  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124969 (* 1 = 0.0124969 loss)
I0928 15:56:15.919631  4581 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I0928 15:56:30.139647  4581 solver.cpp:218] Iteration 52100 (7.03236 iter/s, 14.22s/100 iters), loss = 0.0134249
I0928 15:56:30.139688  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134247 (* 1 = 0.0134247 loss)
I0928 15:56:30.139693  4581 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I0928 15:56:44.370864  4581 solver.cpp:218] Iteration 52200 (7.02684 iter/s, 14.2311s/100 iters), loss = 0.00877355
I0928 15:56:44.370928  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00877336 (* 1 = 0.00877336 loss)
I0928 15:56:44.370944  4581 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I0928 15:56:58.602614  4581 solver.cpp:218] Iteration 52300 (7.02659 iter/s, 14.2316s/100 iters), loss = 0.00406893
I0928 15:56:58.602655  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00406874 (* 1 = 0.00406874 loss)
I0928 15:56:58.602661  4581 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I0928 15:57:12.834503  4581 solver.cpp:218] Iteration 52400 (7.02651 iter/s, 14.2318s/100 iters), loss = 0.00141995
I0928 15:57:12.834547  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00141975 (* 1 = 0.00141975 loss)
I0928 15:57:12.834553  4581 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I0928 15:57:26.356904  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:57:26.925576  4581 solver.cpp:330] Iteration 52500, Testing net (#0)
I0928 15:57:30.294850  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:57:30.435837  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9204
I0928 15:57:30.435873  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326536 (* 1 = 0.326536 loss)
I0928 15:57:30.577791  4581 solver.cpp:218] Iteration 52500 (5.63596 iter/s, 17.7432s/100 iters), loss = 0.00207108
I0928 15:57:30.577821  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00207089 (* 1 = 0.00207089 loss)
I0928 15:57:30.577827  4581 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I0928 15:57:44.801957  4581 solver.cpp:218] Iteration 52600 (7.03032 iter/s, 14.2241s/100 iters), loss = 0.00438899
I0928 15:57:44.801997  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0043888 (* 1 = 0.0043888 loss)
I0928 15:57:44.802003  4581 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I0928 15:57:59.029754  4581 solver.cpp:218] Iteration 52700 (7.02854 iter/s, 14.2277s/100 iters), loss = 0.005325
I0928 15:57:59.029836  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00532481 (* 1 = 0.00532481 loss)
I0928 15:57:59.029846  4581 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I0928 15:58:13.259826  4581 solver.cpp:218] Iteration 52800 (7.02743 iter/s, 14.2299s/100 iters), loss = 0.00773797
I0928 15:58:13.259857  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00773779 (* 1 = 0.00773779 loss)
I0928 15:58:13.259865  4581 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I0928 15:58:27.483574  4581 solver.cpp:218] Iteration 52900 (7.03053 iter/s, 14.2237s/100 iters), loss = 0.00183664
I0928 15:58:27.483615  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00183646 (* 1 = 0.00183646 loss)
I0928 15:58:27.483621  4581 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I0928 15:58:41.004446  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:58:41.574090  4581 solver.cpp:330] Iteration 53000, Testing net (#0)
I0928 15:58:44.945112  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:58:45.086160  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9239
I0928 15:58:45.086195  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.292506 (* 1 = 0.292506 loss)
I0928 15:58:45.228261  4581 solver.cpp:218] Iteration 53000 (5.63552 iter/s, 17.7446s/100 iters), loss = 0.0041746
I0928 15:58:45.228291  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00417443 (* 1 = 0.00417443 loss)
I0928 15:58:45.228297  4581 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I0928 15:58:59.456807  4581 solver.cpp:218] Iteration 53100 (7.02816 iter/s, 14.2285s/100 iters), loss = 0.00770465
I0928 15:58:59.456847  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00770448 (* 1 = 0.00770448 loss)
I0928 15:58:59.456854  4581 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I0928 15:59:13.695561  4581 solver.cpp:218] Iteration 53200 (7.02313 iter/s, 14.2387s/100 iters), loss = 0.00128246
I0928 15:59:13.695695  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128228 (* 1 = 0.00128228 loss)
I0928 15:59:13.695703  4581 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I0928 15:59:27.923990  4581 solver.cpp:218] Iteration 53300 (7.02826 iter/s, 14.2283s/100 iters), loss = 0.00468952
I0928 15:59:27.924031  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00468934 (* 1 = 0.00468934 loss)
I0928 15:59:27.924036  4581 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I0928 15:59:42.157544  4581 solver.cpp:218] Iteration 53400 (7.02569 iter/s, 14.2335s/100 iters), loss = 0.0197827
I0928 15:59:42.157584  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0197825 (* 1 = 0.0197825 loss)
I0928 15:59:42.157589  4581 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I0928 15:59:55.687464  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:59:56.257079  4581 solver.cpp:330] Iteration 53500, Testing net (#0)
I0928 15:59:59.627868  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 15:59:59.768930  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9218
I0928 15:59:59.768965  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.297783 (* 1 = 0.297783 loss)
I0928 15:59:59.910621  4581 solver.cpp:218] Iteration 53500 (5.63285 iter/s, 17.753s/100 iters), loss = 0.00416152
I0928 15:59:59.910651  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00416134 (* 1 = 0.00416134 loss)
I0928 15:59:59.910658  4581 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I0928 16:00:14.142711  4581 solver.cpp:218] Iteration 53600 (7.02643 iter/s, 14.232s/100 iters), loss = 0.00219729
I0928 16:00:14.142751  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00219712 (* 1 = 0.00219712 loss)
I0928 16:00:14.142757  4581 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I0928 16:00:28.375322  4581 solver.cpp:218] Iteration 53700 (7.02616 iter/s, 14.2325s/100 iters), loss = 0.00279759
I0928 16:00:28.375463  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00279741 (* 1 = 0.00279741 loss)
I0928 16:00:28.375471  4581 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I0928 16:00:42.604638  4581 solver.cpp:218] Iteration 53800 (7.02783 iter/s, 14.2291s/100 iters), loss = 0.0313001
I0928 16:00:42.604688  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0313 (* 1 = 0.0313 loss)
I0928 16:00:42.604693  4581 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I0928 16:00:56.837290  4581 solver.cpp:218] Iteration 53900 (7.02614 iter/s, 14.2326s/100 iters), loss = 0.00285297
I0928 16:00:56.837330  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00285278 (* 1 = 0.00285278 loss)
I0928 16:00:56.837337  4581 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I0928 16:01:10.367569  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:01:10.937072  4581 solver.cpp:330] Iteration 54000, Testing net (#0)
I0928 16:01:14.307155  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:01:14.447999  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9165
I0928 16:01:14.448034  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333901 (* 1 = 0.333901 loss)
I0928 16:01:14.590095  4581 solver.cpp:218] Iteration 54000 (5.63294 iter/s, 17.7527s/100 iters), loss = 0.00943022
I0928 16:01:14.590126  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00943004 (* 1 = 0.00943004 loss)
I0928 16:01:14.590131  4581 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I0928 16:01:28.812713  4581 solver.cpp:218] Iteration 54100 (7.03109 iter/s, 14.2225s/100 iters), loss = 0.00608754
I0928 16:01:28.812753  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00608736 (* 1 = 0.00608736 loss)
I0928 16:01:28.812759  4581 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I0928 16:01:43.040045  4581 solver.cpp:218] Iteration 54200 (7.02877 iter/s, 14.2273s/100 iters), loss = 0.00490326
I0928 16:01:43.040145  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00490307 (* 1 = 0.00490307 loss)
I0928 16:01:43.040153  4581 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I0928 16:01:57.269821  4581 solver.cpp:218] Iteration 54300 (7.02759 iter/s, 14.2296s/100 iters), loss = 0.00104404
I0928 16:01:57.269852  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00104385 (* 1 = 0.00104385 loss)
I0928 16:01:57.269858  4581 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I0928 16:02:11.500756  4581 solver.cpp:218] Iteration 54400 (7.02698 iter/s, 14.2309s/100 iters), loss = 0.00419389
I0928 16:02:11.500797  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0041937 (* 1 = 0.0041937 loss)
I0928 16:02:11.500802  4581 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I0928 16:02:25.025035  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:02:25.594322  4581 solver.cpp:330] Iteration 54500, Testing net (#0)
I0928 16:02:28.967474  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:02:29.107641  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9153
I0928 16:02:29.107678  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.340005 (* 1 = 0.340005 loss)
I0928 16:02:29.249168  4581 solver.cpp:218] Iteration 54500 (5.63434 iter/s, 17.7483s/100 iters), loss = 0.000863501
I0928 16:02:29.249197  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000863312 (* 1 = 0.000863312 loss)
I0928 16:02:29.249203  4581 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I0928 16:02:43.472028  4581 solver.cpp:218] Iteration 54600 (7.03097 iter/s, 14.2228s/100 iters), loss = 0.0165415
I0928 16:02:43.472069  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0165413 (* 1 = 0.0165413 loss)
I0928 16:02:43.472075  4581 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I0928 16:02:57.694358  4581 solver.cpp:218] Iteration 54700 (7.03124 iter/s, 14.2222s/100 iters), loss = 0.00275991
I0928 16:02:57.694445  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00275973 (* 1 = 0.00275973 loss)
I0928 16:02:57.694453  4581 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I0928 16:03:11.921593  4581 solver.cpp:218] Iteration 54800 (7.02884 iter/s, 14.2271s/100 iters), loss = 0.00136892
I0928 16:03:11.921633  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00136873 (* 1 = 0.00136873 loss)
I0928 16:03:11.921640  4581 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I0928 16:03:26.145925  4581 solver.cpp:218] Iteration 54900 (7.03025 iter/s, 14.2243s/100 iters), loss = 0.00107652
I0928 16:03:26.145967  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00107632 (* 1 = 0.00107632 loss)
I0928 16:03:26.145972  4581 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I0928 16:03:39.667788  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:03:40.237557  4581 solver.cpp:330] Iteration 55000, Testing net (#0)
I0928 16:03:43.606317  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:03:43.749011  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9226
I0928 16:03:43.749037  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313488 (* 1 = 0.313488 loss)
I0928 16:03:43.890689  4581 solver.cpp:218] Iteration 55000 (5.63549 iter/s, 17.7447s/100 iters), loss = 0.00672026
I0928 16:03:43.890718  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00672007 (* 1 = 0.00672007 loss)
I0928 16:03:43.890724  4581 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I0928 16:03:58.114181  4581 solver.cpp:218] Iteration 55100 (7.03066 iter/s, 14.2234s/100 iters), loss = 0.00324287
I0928 16:03:58.114223  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00324267 (* 1 = 0.00324267 loss)
I0928 16:03:58.114229  4581 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I0928 16:04:12.344884  4581 solver.cpp:218] Iteration 55200 (7.0271 iter/s, 14.2306s/100 iters), loss = 0.000660175
I0928 16:04:12.345015  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000659985 (* 1 = 0.000659985 loss)
I0928 16:04:12.345023  4581 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I0928 16:04:26.568495  4581 solver.cpp:218] Iteration 55300 (7.03065 iter/s, 14.2234s/100 iters), loss = 0.00388454
I0928 16:04:26.568536  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00388435 (* 1 = 0.00388435 loss)
I0928 16:04:26.568542  4581 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I0928 16:04:40.795850  4581 solver.cpp:218] Iteration 55400 (7.02875 iter/s, 14.2273s/100 iters), loss = 0.000309128
I0928 16:04:40.795892  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000308935 (* 1 = 0.000308935 loss)
I0928 16:04:40.795897  4581 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I0928 16:04:54.317939  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:04:54.886626  4581 solver.cpp:330] Iteration 55500, Testing net (#0)
I0928 16:04:58.254781  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:04:58.395556  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9231
I0928 16:04:58.395593  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310469 (* 1 = 0.310469 loss)
I0928 16:04:58.537870  4581 solver.cpp:218] Iteration 55500 (5.63636 iter/s, 17.7419s/100 iters), loss = 0.00507751
I0928 16:04:58.537901  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00507732 (* 1 = 0.00507732 loss)
I0928 16:04:58.537909  4581 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I0928 16:05:12.758991  4581 solver.cpp:218] Iteration 55600 (7.03183 iter/s, 14.221s/100 iters), loss = 0.00534922
I0928 16:05:12.759030  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00534903 (* 1 = 0.00534903 loss)
I0928 16:05:12.759037  4581 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I0928 16:05:26.991322  4581 solver.cpp:218] Iteration 55700 (7.0263 iter/s, 14.2323s/100 iters), loss = 0.0022059
I0928 16:05:26.991456  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0022057 (* 1 = 0.0022057 loss)
I0928 16:05:26.991463  4581 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I0928 16:05:41.220850  4581 solver.cpp:218] Iteration 55800 (7.02772 iter/s, 14.2294s/100 iters), loss = 0.00335517
I0928 16:05:41.220891  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00335497 (* 1 = 0.00335497 loss)
I0928 16:05:41.220897  4581 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I0928 16:05:55.451287  4581 solver.cpp:218] Iteration 55900 (7.02723 iter/s, 14.2304s/100 iters), loss = 0.00389849
I0928 16:05:55.451328  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00389829 (* 1 = 0.00389829 loss)
I0928 16:05:55.451333  4581 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I0928 16:06:08.974905  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:06:09.543792  4581 solver.cpp:330] Iteration 56000, Testing net (#0)
I0928 16:06:12.911329  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:06:13.052487  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9256
I0928 16:06:13.052522  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295683 (* 1 = 0.295683 loss)
I0928 16:06:13.194211  4581 solver.cpp:218] Iteration 56000 (5.63608 iter/s, 17.7428s/100 iters), loss = 0.00455221
I0928 16:06:13.194238  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00455202 (* 1 = 0.00455202 loss)
I0928 16:06:13.194245  4581 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I0928 16:06:27.414714  4581 solver.cpp:218] Iteration 56100 (7.03214 iter/s, 14.2204s/100 iters), loss = 0.00352204
I0928 16:06:27.414746  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00352184 (* 1 = 0.00352184 loss)
I0928 16:06:27.414752  4581 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I0928 16:06:41.642881  4581 solver.cpp:218] Iteration 56200 (7.02835 iter/s, 14.2281s/100 iters), loss = 0.00991565
I0928 16:06:41.642974  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00991545 (* 1 = 0.00991545 loss)
I0928 16:06:41.642982  4581 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I0928 16:06:55.871632  4581 solver.cpp:218] Iteration 56300 (7.02809 iter/s, 14.2286s/100 iters), loss = 0.00199151
I0928 16:06:55.871673  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0019913 (* 1 = 0.0019913 loss)
I0928 16:06:55.871680  4581 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I0928 16:07:10.097162  4581 solver.cpp:218] Iteration 56400 (7.02966 iter/s, 14.2254s/100 iters), loss = 0.0010417
I0928 16:07:10.097193  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00104149 (* 1 = 0.00104149 loss)
I0928 16:07:10.097198  4581 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I0928 16:07:23.613840  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:07:24.184955  4581 solver.cpp:330] Iteration 56500, Testing net (#0)
I0928 16:07:27.551108  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:07:27.691586  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I0928 16:07:27.691622  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.301896 (* 1 = 0.301896 loss)
I0928 16:07:27.833695  4581 solver.cpp:218] Iteration 56500 (5.63811 iter/s, 17.7365s/100 iters), loss = 0.014329
I0928 16:07:27.833724  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143287 (* 1 = 0.0143287 loss)
I0928 16:07:27.833731  4581 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I0928 16:07:42.056344  4581 solver.cpp:218] Iteration 56600 (7.03108 iter/s, 14.2226s/100 iters), loss = 0.00426868
I0928 16:07:42.056385  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00426847 (* 1 = 0.00426847 loss)
I0928 16:07:42.056391  4581 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I0928 16:07:56.287921  4581 solver.cpp:218] Iteration 56700 (7.02667 iter/s, 14.2315s/100 iters), loss = 0.00506708
I0928 16:07:56.288043  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00506688 (* 1 = 0.00506688 loss)
I0928 16:07:56.288060  4581 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I0928 16:08:10.519644  4581 solver.cpp:218] Iteration 56800 (7.02663 iter/s, 14.2316s/100 iters), loss = 0.00289898
I0928 16:08:10.519685  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00289878 (* 1 = 0.00289878 loss)
I0928 16:08:10.519691  4581 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I0928 16:08:24.746264  4581 solver.cpp:218] Iteration 56900 (7.02912 iter/s, 14.2265s/100 iters), loss = 0.00130482
I0928 16:08:24.746306  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00130461 (* 1 = 0.00130461 loss)
I0928 16:08:24.746312  4581 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I0928 16:08:38.266110  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:08:38.837031  4581 solver.cpp:330] Iteration 57000, Testing net (#0)
I0928 16:08:42.206969  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:08:42.347776  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9248
I0928 16:08:42.347813  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303179 (* 1 = 0.303179 loss)
I0928 16:08:42.489512  4581 solver.cpp:218] Iteration 57000 (5.63597 iter/s, 17.7432s/100 iters), loss = 0.0039046
I0928 16:08:42.489542  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0039044 (* 1 = 0.0039044 loss)
I0928 16:08:42.489548  4581 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I0928 16:08:56.711786  4581 solver.cpp:218] Iteration 57100 (7.03126 iter/s, 14.2222s/100 iters), loss = 0.000883926
I0928 16:08:56.711827  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000883718 (* 1 = 0.000883718 loss)
I0928 16:08:56.711834  4581 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I0928 16:09:10.936905  4581 solver.cpp:218] Iteration 57200 (7.02986 iter/s, 14.225s/100 iters), loss = 0.00199438
I0928 16:09:10.936975  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00199417 (* 1 = 0.00199417 loss)
I0928 16:09:10.936982  4581 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I0928 16:09:25.157132  4581 solver.cpp:218] Iteration 57300 (7.03229 iter/s, 14.2201s/100 iters), loss = 0.00464416
I0928 16:09:25.157172  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00464395 (* 1 = 0.00464395 loss)
I0928 16:09:25.157178  4581 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I0928 16:09:39.379153  4581 solver.cpp:218] Iteration 57400 (7.03139 iter/s, 14.2219s/100 iters), loss = 0.00196427
I0928 16:09:39.379186  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00196406 (* 1 = 0.00196406 loss)
I0928 16:09:39.379194  4581 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I0928 16:09:52.895320  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:09:53.464284  4581 solver.cpp:330] Iteration 57500, Testing net (#0)
I0928 16:09:56.834743  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:09:56.975630  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9221
I0928 16:09:56.975666  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314749 (* 1 = 0.314749 loss)
I0928 16:09:57.117158  4581 solver.cpp:218] Iteration 57500 (5.63764 iter/s, 17.7379s/100 iters), loss = 0.00326951
I0928 16:09:57.117187  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0032693 (* 1 = 0.0032693 loss)
I0928 16:09:57.117194  4581 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I0928 16:10:11.339646  4581 solver.cpp:218] Iteration 57600 (7.03115 iter/s, 14.2224s/100 iters), loss = 0.0021737
I0928 16:10:11.339675  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0021735 (* 1 = 0.0021735 loss)
I0928 16:10:11.339681  4581 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I0928 16:10:25.563371  4581 solver.cpp:218] Iteration 57700 (7.03054 iter/s, 14.2237s/100 iters), loss = 0.000915814
I0928 16:10:25.563441  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000915607 (* 1 = 0.000915607 loss)
I0928 16:10:25.563447  4581 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I0928 16:10:39.787374  4581 solver.cpp:218] Iteration 57800 (7.03042 iter/s, 14.2239s/100 iters), loss = 0.00226517
I0928 16:10:39.787416  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00226496 (* 1 = 0.00226496 loss)
I0928 16:10:39.787422  4581 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I0928 16:10:54.008970  4581 solver.cpp:218] Iteration 57900 (7.0316 iter/s, 14.2215s/100 iters), loss = 0.00681862
I0928 16:10:54.009011  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0068184 (* 1 = 0.0068184 loss)
I0928 16:10:54.009017  4581 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I0928 16:11:07.526823  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:11:08.095712  4581 solver.cpp:330] Iteration 58000, Testing net (#0)
I0928 16:11:11.466178  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:11:11.607151  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9225
I0928 16:11:11.607187  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322709 (* 1 = 0.322709 loss)
I0928 16:11:11.748935  4581 solver.cpp:218] Iteration 58000 (5.63702 iter/s, 17.7399s/100 iters), loss = 0.00412883
I0928 16:11:11.748965  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00412861 (* 1 = 0.00412861 loss)
I0928 16:11:11.748970  4581 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I0928 16:11:25.980370  4581 solver.cpp:218] Iteration 58100 (7.02673 iter/s, 14.2314s/100 iters), loss = 0.00379512
I0928 16:11:25.980412  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00379491 (* 1 = 0.00379491 loss)
I0928 16:11:25.980418  4581 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I0928 16:11:40.219482  4581 solver.cpp:218] Iteration 58200 (7.02295 iter/s, 14.239s/100 iters), loss = 0.00105262
I0928 16:11:40.219580  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010524 (* 1 = 0.0010524 loss)
I0928 16:11:40.219588  4581 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I0928 16:11:54.453660  4581 solver.cpp:218] Iteration 58300 (7.02541 iter/s, 14.234s/100 iters), loss = 0.00214748
I0928 16:11:54.453701  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00214727 (* 1 = 0.00214727 loss)
I0928 16:11:54.453707  4581 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I0928 16:12:08.697679  4581 solver.cpp:218] Iteration 58400 (7.02053 iter/s, 14.2439s/100 iters), loss = 0.00128492
I0928 16:12:08.697721  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128471 (* 1 = 0.00128471 loss)
I0928 16:12:08.697726  4581 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I0928 16:12:22.232823  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:12:22.802762  4581 solver.cpp:330] Iteration 58500, Testing net (#0)
I0928 16:12:26.173857  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:12:26.315030  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9202
I0928 16:12:26.315066  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.345049 (* 1 = 0.345049 loss)
I0928 16:12:26.456885  4581 solver.cpp:218] Iteration 58500 (5.63091 iter/s, 17.7591s/100 iters), loss = 0.000916606
I0928 16:12:26.456913  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000916392 (* 1 = 0.000916392 loss)
I0928 16:12:26.456920  4581 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I0928 16:12:40.685897  4581 solver.cpp:218] Iteration 58600 (7.02793 iter/s, 14.2289s/100 iters), loss = 0.00571732
I0928 16:12:40.685940  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0057171 (* 1 = 0.0057171 loss)
I0928 16:12:40.685945  4581 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I0928 16:12:54.918099  4581 solver.cpp:218] Iteration 58700 (7.02636 iter/s, 14.2321s/100 iters), loss = 0.00439226
I0928 16:12:54.918186  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00439204 (* 1 = 0.00439204 loss)
I0928 16:12:54.918202  4581 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I0928 16:13:09.149885  4581 solver.cpp:218] Iteration 58800 (7.02659 iter/s, 14.2317s/100 iters), loss = 0.00355392
I0928 16:13:09.149926  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00355371 (* 1 = 0.00355371 loss)
I0928 16:13:09.149932  4581 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I0928 16:13:23.382939  4581 solver.cpp:218] Iteration 58900 (7.02594 iter/s, 14.233s/100 iters), loss = 0.00170212
I0928 16:13:23.382971  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0017019 (* 1 = 0.0017019 loss)
I0928 16:13:23.382977  4581 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I0928 16:13:36.913892  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:13:37.484267  4581 solver.cpp:330] Iteration 59000, Testing net (#0)
I0928 16:13:40.854627  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:13:40.995553  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9207
I0928 16:13:40.995589  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.340708 (* 1 = 0.340708 loss)
I0928 16:13:41.137922  4581 solver.cpp:218] Iteration 59000 (5.63225 iter/s, 17.7549s/100 iters), loss = 0.00391435
I0928 16:13:41.137948  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00391413 (* 1 = 0.00391413 loss)
I0928 16:13:41.137954  4581 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I0928 16:13:55.366093  4581 solver.cpp:218] Iteration 59100 (7.02834 iter/s, 14.2281s/100 iters), loss = 0.00175096
I0928 16:13:55.366134  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00175074 (* 1 = 0.00175074 loss)
I0928 16:13:55.366139  4581 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I0928 16:14:09.594506  4581 solver.cpp:218] Iteration 59200 (7.02823 iter/s, 14.2283s/100 iters), loss = 0.00172443
I0928 16:14:09.594635  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00172421 (* 1 = 0.00172421 loss)
I0928 16:14:09.594643  4581 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I0928 16:14:23.823868  4581 solver.cpp:218] Iteration 59300 (7.0278 iter/s, 14.2292s/100 iters), loss = 0.00108903
I0928 16:14:23.823909  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108881 (* 1 = 0.00108881 loss)
I0928 16:14:23.823915  4581 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I0928 16:14:38.057448  4581 solver.cpp:218] Iteration 59400 (7.02568 iter/s, 14.2335s/100 iters), loss = 0.00554904
I0928 16:14:38.057489  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00554882 (* 1 = 0.00554882 loss)
I0928 16:14:38.057495  4581 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I0928 16:14:51.582152  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:14:52.151108  4581 solver.cpp:330] Iteration 59500, Testing net (#0)
I0928 16:14:55.522550  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:14:55.663846  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9195
I0928 16:14:55.663872  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32852 (* 1 = 0.32852 loss)
I0928 16:14:55.806195  4581 solver.cpp:218] Iteration 59500 (5.63423 iter/s, 17.7487s/100 iters), loss = 0.0201514
I0928 16:14:55.806223  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0201512 (* 1 = 0.0201512 loss)
I0928 16:14:55.806231  4581 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I0928 16:15:10.033080  4581 solver.cpp:218] Iteration 59600 (7.02898 iter/s, 14.2268s/100 iters), loss = 0.0162366
I0928 16:15:10.033121  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0162364 (* 1 = 0.0162364 loss)
I0928 16:15:10.033128  4581 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I0928 16:15:24.253403  4581 solver.cpp:218] Iteration 59700 (7.03223 iter/s, 14.2202s/100 iters), loss = 0.00439803
I0928 16:15:24.253535  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00439781 (* 1 = 0.00439781 loss)
I0928 16:15:24.253542  4581 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I0928 16:15:38.473676  4581 solver.cpp:218] Iteration 59800 (7.03229 iter/s, 14.2201s/100 iters), loss = 0.00252089
I0928 16:15:38.473716  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00252067 (* 1 = 0.00252067 loss)
I0928 16:15:38.473722  4581 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I0928 16:15:52.696732  4581 solver.cpp:218] Iteration 59900 (7.03088 iter/s, 14.223s/100 iters), loss = 0.00138588
I0928 16:15:52.696774  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00138567 (* 1 = 0.00138567 loss)
I0928 16:15:52.696779  4581 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I0928 16:16:06.215248  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:16:06.783991  4581 solver.cpp:330] Iteration 60000, Testing net (#0)
I0928 16:16:10.153362  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:16:10.294706  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9237
I0928 16:16:10.294744  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312205 (* 1 = 0.312205 loss)
I0928 16:16:10.436272  4581 solver.cpp:218] Iteration 60000 (5.63715 iter/s, 17.7395s/100 iters), loss = 0.00118752
I0928 16:16:10.436303  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0011873 (* 1 = 0.0011873 loss)
I0928 16:16:10.436311  4581 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I0928 16:16:24.665176  4581 solver.cpp:218] Iteration 60100 (7.02798 iter/s, 14.2288s/100 iters), loss = 0.000767202
I0928 16:16:24.665218  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000766987 (* 1 = 0.000766987 loss)
I0928 16:16:24.665225  4581 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I0928 16:16:38.889031  4581 solver.cpp:218] Iteration 60200 (7.03049 iter/s, 14.2238s/100 iters), loss = 0.000838982
I0928 16:16:38.889145  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00083877 (* 1 = 0.00083877 loss)
I0928 16:16:38.889153  4581 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I0928 16:16:53.115501  4581 solver.cpp:218] Iteration 60300 (7.02923 iter/s, 14.2263s/100 iters), loss = 0.000279357
I0928 16:16:53.115542  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000279143 (* 1 = 0.000279143 loss)
I0928 16:16:53.115548  4581 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I0928 16:17:07.344233  4581 solver.cpp:218] Iteration 60400 (7.02808 iter/s, 14.2286s/100 iters), loss = 0.00185078
I0928 16:17:07.344274  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00185057 (* 1 = 0.00185057 loss)
I0928 16:17:07.344280  4581 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I0928 16:17:20.862010  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:17:21.431746  4581 solver.cpp:330] Iteration 60500, Testing net (#0)
I0928 16:17:24.800812  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:17:24.941635  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9268
I0928 16:17:24.941673  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304436 (* 1 = 0.304436 loss)
I0928 16:17:25.084848  4581 solver.cpp:218] Iteration 60500 (5.63681 iter/s, 17.7405s/100 iters), loss = 0.00280592
I0928 16:17:25.084878  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0028057 (* 1 = 0.0028057 loss)
I0928 16:17:25.084885  4581 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I0928 16:17:39.304379  4581 solver.cpp:218] Iteration 60600 (7.03262 iter/s, 14.2195s/100 iters), loss = 0.00199337
I0928 16:17:39.304421  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00199316 (* 1 = 0.00199316 loss)
I0928 16:17:39.304427  4581 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I0928 16:17:53.533820  4581 solver.cpp:218] Iteration 60700 (7.02773 iter/s, 14.2294s/100 iters), loss = 0.000942183
I0928 16:17:53.533948  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000941971 (* 1 = 0.000941971 loss)
I0928 16:17:53.533957  4581 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I0928 16:18:07.763339  4581 solver.cpp:218] Iteration 60800 (7.02772 iter/s, 14.2294s/100 iters), loss = 0.00173082
I0928 16:18:07.763378  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00173061 (* 1 = 0.00173061 loss)
I0928 16:18:07.763384  4581 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I0928 16:18:21.994671  4581 solver.cpp:218] Iteration 60900 (7.02679 iter/s, 14.2313s/100 iters), loss = 0.00470531
I0928 16:18:21.994711  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0047051 (* 1 = 0.0047051 loss)
I0928 16:18:21.994719  4581 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I0928 16:18:35.519302  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:18:36.088505  4581 solver.cpp:330] Iteration 61000, Testing net (#0)
I0928 16:18:39.456399  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:18:39.597384  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9223
I0928 16:18:39.597420  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.317593 (* 1 = 0.317593 loss)
I0928 16:18:39.739465  4581 solver.cpp:218] Iteration 61000 (5.63548 iter/s, 17.7447s/100 iters), loss = 0.0030705
I0928 16:18:39.739495  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0030703 (* 1 = 0.0030703 loss)
I0928 16:18:39.739501  4581 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I0928 16:18:53.967547  4581 solver.cpp:218] Iteration 61100 (7.02839 iter/s, 14.228s/100 iters), loss = 0.000814001
I0928 16:18:53.967587  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000813796 (* 1 = 0.000813796 loss)
I0928 16:18:53.967594  4581 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I0928 16:19:08.198987  4581 solver.cpp:218] Iteration 61200 (7.02674 iter/s, 14.2314s/100 iters), loss = 0.00360658
I0928 16:19:08.199105  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00360637 (* 1 = 0.00360637 loss)
I0928 16:19:08.199111  4581 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I0928 16:19:22.430423  4581 solver.cpp:218] Iteration 61300 (7.02677 iter/s, 14.2313s/100 iters), loss = 0.00135781
I0928 16:19:22.430464  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0013576 (* 1 = 0.0013576 loss)
I0928 16:19:22.430469  4581 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I0928 16:19:36.661801  4581 solver.cpp:218] Iteration 61400 (7.02677 iter/s, 14.2313s/100 iters), loss = 0.000839597
I0928 16:19:36.661841  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000839384 (* 1 = 0.000839384 loss)
I0928 16:19:36.661849  4581 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I0928 16:19:50.185925  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:19:50.756662  4581 solver.cpp:330] Iteration 61500, Testing net (#0)
I0928 16:19:54.125167  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:19:54.266263  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9258
I0928 16:19:54.266288  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.30918 (* 1 = 0.30918 loss)
I0928 16:19:54.407969  4581 solver.cpp:218] Iteration 61500 (5.63505 iter/s, 17.7461s/100 iters), loss = 0.0207028
I0928 16:19:54.407999  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0207026 (* 1 = 0.0207026 loss)
I0928 16:19:54.408004  4581 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I0928 16:20:08.635803  4581 solver.cpp:218] Iteration 61600 (7.02851 iter/s, 14.2278s/100 iters), loss = 0.00101808
I0928 16:20:08.635844  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00101787 (* 1 = 0.00101787 loss)
I0928 16:20:08.635850  4581 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I0928 16:20:22.862066  4581 solver.cpp:218] Iteration 61700 (7.0293 iter/s, 14.2262s/100 iters), loss = 0.00278504
I0928 16:20:22.862157  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00278483 (* 1 = 0.00278483 loss)
I0928 16:20:22.862174  4581 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I0928 16:20:37.098821  4581 solver.cpp:218] Iteration 61800 (7.02414 iter/s, 14.2366s/100 iters), loss = 0.000330877
I0928 16:20:37.098862  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000330668 (* 1 = 0.000330668 loss)
I0928 16:20:37.098868  4581 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I0928 16:20:51.328157  4581 solver.cpp:218] Iteration 61900 (7.02778 iter/s, 14.2293s/100 iters), loss = 0.00269871
I0928 16:20:51.328197  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0026985 (* 1 = 0.0026985 loss)
I0928 16:20:51.328203  4581 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I0928 16:21:04.850563  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:21:05.421999  4581 solver.cpp:330] Iteration 62000, Testing net (#0)
I0928 16:21:08.790148  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:21:08.930665  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9209
I0928 16:21:08.930701  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.332906 (* 1 = 0.332906 loss)
I0928 16:21:09.072984  4581 solver.cpp:218] Iteration 62000 (5.63547 iter/s, 17.7447s/100 iters), loss = 0.00220819
I0928 16:21:09.073012  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00220798 (* 1 = 0.00220798 loss)
I0928 16:21:09.073019  4581 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I0928 16:21:23.296615  4581 solver.cpp:218] Iteration 62100 (7.03059 iter/s, 14.2236s/100 iters), loss = 0.00563649
I0928 16:21:23.296656  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00563628 (* 1 = 0.00563628 loss)
I0928 16:21:23.296663  4581 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I0928 16:21:37.523983  4581 solver.cpp:218] Iteration 62200 (7.02875 iter/s, 14.2273s/100 iters), loss = 0.00213243
I0928 16:21:37.524109  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00213222 (* 1 = 0.00213222 loss)
I0928 16:21:37.524117  4581 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I0928 16:21:51.747334  4581 solver.cpp:218] Iteration 62300 (7.03077 iter/s, 14.2232s/100 iters), loss = 0.00520879
I0928 16:21:51.747376  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00520858 (* 1 = 0.00520858 loss)
I0928 16:21:51.747382  4581 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I0928 16:22:05.975453  4581 solver.cpp:218] Iteration 62400 (7.02838 iter/s, 14.228s/100 iters), loss = 0.00361183
I0928 16:22:05.975493  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00361162 (* 1 = 0.00361162 loss)
I0928 16:22:05.975499  4581 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I0928 16:22:19.490375  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:22:20.059662  4581 solver.cpp:330] Iteration 62500, Testing net (#0)
I0928 16:22:23.428442  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:22:23.569524  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9205
I0928 16:22:23.569558  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322255 (* 1 = 0.322255 loss)
I0928 16:22:23.711390  4581 solver.cpp:218] Iteration 62500 (5.6383 iter/s, 17.7358s/100 iters), loss = 0.00474774
I0928 16:22:23.711419  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00474753 (* 1 = 0.00474753 loss)
I0928 16:22:23.711426  4581 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I0928 16:22:37.933640  4581 solver.cpp:218] Iteration 62600 (7.03127 iter/s, 14.2222s/100 iters), loss = 0.00364977
I0928 16:22:37.933679  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00364956 (* 1 = 0.00364956 loss)
I0928 16:22:37.933686  4581 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I0928 16:22:52.156673  4581 solver.cpp:218] Iteration 62700 (7.03089 iter/s, 14.223s/100 iters), loss = 0.00169738
I0928 16:22:52.156805  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00169717 (* 1 = 0.00169717 loss)
I0928 16:22:52.156811  4581 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I0928 16:23:06.383378  4581 solver.cpp:218] Iteration 62800 (7.02912 iter/s, 14.2265s/100 iters), loss = 0.00201625
I0928 16:23:06.383419  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00201604 (* 1 = 0.00201604 loss)
I0928 16:23:06.383425  4581 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I0928 16:23:20.609654  4581 solver.cpp:218] Iteration 62900 (7.02929 iter/s, 14.2262s/100 iters), loss = 0.00965138
I0928 16:23:20.609684  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00965117 (* 1 = 0.00965117 loss)
I0928 16:23:20.609691  4581 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I0928 16:23:34.126574  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:23:34.696936  4581 solver.cpp:330] Iteration 63000, Testing net (#0)
I0928 16:23:38.066738  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:23:38.207643  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9246
I0928 16:23:38.207679  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.321881 (* 1 = 0.321881 loss)
I0928 16:23:38.349694  4581 solver.cpp:218] Iteration 63000 (5.63699 iter/s, 17.74s/100 iters), loss = 0.0030767
I0928 16:23:38.349722  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00307649 (* 1 = 0.00307649 loss)
I0928 16:23:38.349730  4581 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I0928 16:23:52.588037  4581 solver.cpp:218] Iteration 63100 (7.02332 iter/s, 14.2383s/100 iters), loss = 0.000667708
I0928 16:23:52.588078  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000667498 (* 1 = 0.000667498 loss)
I0928 16:23:52.588084  4581 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I0928 16:24:06.826282  4581 solver.cpp:218] Iteration 63200 (7.02338 iter/s, 14.2382s/100 iters), loss = 0.00140732
I0928 16:24:06.826370  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00140711 (* 1 = 0.00140711 loss)
I0928 16:24:06.826386  4581 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I0928 16:24:21.060015  4581 solver.cpp:218] Iteration 63300 (7.02563 iter/s, 14.2336s/100 iters), loss = 0.00147347
I0928 16:24:21.060056  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00147325 (* 1 = 0.00147325 loss)
I0928 16:24:21.060062  4581 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I0928 16:24:35.298008  4581 solver.cpp:218] Iteration 63400 (7.0235 iter/s, 14.2379s/100 iters), loss = 0.00165654
I0928 16:24:35.298050  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00165633 (* 1 = 0.00165633 loss)
I0928 16:24:35.298056  4581 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I0928 16:24:48.832026  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:24:49.401902  4581 solver.cpp:330] Iteration 63500, Testing net (#0)
I0928 16:24:52.772979  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:24:52.914146  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9242
I0928 16:24:52.914182  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318544 (* 1 = 0.318544 loss)
I0928 16:24:53.055649  4581 solver.cpp:218] Iteration 63500 (5.63141 iter/s, 17.7576s/100 iters), loss = 0.00206922
I0928 16:24:53.055680  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00206902 (* 1 = 0.00206902 loss)
I0928 16:24:53.055686  4581 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I0928 16:25:07.289588  4581 solver.cpp:218] Iteration 63600 (7.0255 iter/s, 14.2339s/100 iters), loss = 0.00108685
I0928 16:25:07.289628  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108665 (* 1 = 0.00108665 loss)
I0928 16:25:07.289635  4581 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I0928 16:25:21.518213  4581 solver.cpp:218] Iteration 63700 (7.02813 iter/s, 14.2285s/100 iters), loss = 0.00128047
I0928 16:25:21.518369  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128027 (* 1 = 0.00128027 loss)
I0928 16:25:21.518386  4581 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I0928 16:25:35.748941  4581 solver.cpp:218] Iteration 63800 (7.02714 iter/s, 14.2305s/100 iters), loss = 0.0240221
I0928 16:25:35.748971  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0240219 (* 1 = 0.0240219 loss)
I0928 16:25:35.748978  4581 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I0928 16:25:49.980020  4581 solver.cpp:218] Iteration 63900 (7.02691 iter/s, 14.231s/100 iters), loss = 0.00211397
I0928 16:25:49.980049  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00211377 (* 1 = 0.00211377 loss)
I0928 16:25:49.980056  4581 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I0928 16:26:03.507230  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:26:04.077894  4581 solver.cpp:330] Iteration 64000, Testing net (#0)
I0928 16:26:07.449229  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:26:07.589958  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9214
I0928 16:26:07.589995  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.331168 (* 1 = 0.331168 loss)
I0928 16:26:07.732427  4581 solver.cpp:218] Iteration 64000 (5.63306 iter/s, 17.7523s/100 iters), loss = 0.00132826
I0928 16:26:07.732455  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00132806 (* 1 = 0.00132806 loss)
I0928 16:26:07.732462  4581 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I0928 16:26:21.947412  4581 solver.cpp:218] Iteration 64100 (7.03487 iter/s, 14.2149s/100 iters), loss = 0.00784741
I0928 16:26:21.947450  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00784722 (* 1 = 0.00784722 loss)
I0928 16:26:21.947456  4581 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I0928 16:26:36.173465  4581 solver.cpp:218] Iteration 64200 (7.02939 iter/s, 14.226s/100 iters), loss = 0.00970867
I0928 16:26:36.173576  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00970848 (* 1 = 0.00970848 loss)
I0928 16:26:36.173583  4581 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I0928 16:26:50.401281  4581 solver.cpp:218] Iteration 64300 (7.02856 iter/s, 14.2277s/100 iters), loss = 0.00229365
I0928 16:26:50.401321  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00229346 (* 1 = 0.00229346 loss)
I0928 16:26:50.401327  4581 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I0928 16:27:04.626979  4581 solver.cpp:218] Iteration 64400 (7.02957 iter/s, 14.2256s/100 iters), loss = 0.00185842
I0928 16:27:04.627020  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00185823 (* 1 = 0.00185823 loss)
I0928 16:27:04.627027  4581 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I0928 16:27:18.150888  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:27:18.720748  4581 solver.cpp:330] Iteration 64500, Testing net (#0)
I0928 16:27:22.090466  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:27:22.231786  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9223
I0928 16:27:22.231822  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320823 (* 1 = 0.320823 loss)
I0928 16:27:22.373713  4581 solver.cpp:218] Iteration 64500 (5.63487 iter/s, 17.7466s/100 iters), loss = 0.0178263
I0928 16:27:22.373740  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0178261 (* 1 = 0.0178261 loss)
I0928 16:27:22.373747  4581 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I0928 16:27:36.596004  4581 solver.cpp:218] Iteration 64600 (7.03125 iter/s, 14.2222s/100 iters), loss = 0.000787675
I0928 16:27:36.596045  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000787492 (* 1 = 0.000787492 loss)
I0928 16:27:36.596050  4581 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I0928 16:27:50.816393  4581 solver.cpp:218] Iteration 64700 (7.0322 iter/s, 14.2203s/100 iters), loss = 0.00231892
I0928 16:27:50.816498  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00231874 (* 1 = 0.00231874 loss)
I0928 16:27:50.816514  4581 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I0928 16:28:05.039274  4581 solver.cpp:218] Iteration 64800 (7.031 iter/s, 14.2227s/100 iters), loss = 0.000781645
I0928 16:28:05.039315  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000781465 (* 1 = 0.000781465 loss)
I0928 16:28:05.039321  4581 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I0928 16:28:19.259681  4581 solver.cpp:218] Iteration 64900 (7.03219 iter/s, 14.2203s/100 iters), loss = 0.00050161
I0928 16:28:19.259722  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000501431 (* 1 = 0.000501431 loss)
I0928 16:28:19.259728  4581 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I0928 16:28:32.775507  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:28:33.345335  4581 solver.cpp:330] Iteration 65000, Testing net (#0)
I0928 16:28:36.716496  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:28:36.857868  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9211
I0928 16:28:36.857903  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33995 (* 1 = 0.33995 loss)
I0928 16:28:36.999590  4581 solver.cpp:218] Iteration 65000 (5.63703 iter/s, 17.7398s/100 iters), loss = 0.00259653
I0928 16:28:36.999619  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00259635 (* 1 = 0.00259635 loss)
I0928 16:28:36.999625  4581 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I0928 16:28:51.220600  4581 solver.cpp:218] Iteration 65100 (7.03188 iter/s, 14.2209s/100 iters), loss = 0.00124373
I0928 16:28:51.220631  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00124356 (* 1 = 0.00124356 loss)
I0928 16:28:51.220638  4581 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I0928 16:29:05.445492  4581 solver.cpp:218] Iteration 65200 (7.02997 iter/s, 14.2248s/100 iters), loss = 0.000720345
I0928 16:29:05.445581  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000720168 (* 1 = 0.000720168 loss)
I0928 16:29:05.445597  4581 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I0928 16:29:19.671350  4581 solver.cpp:218] Iteration 65300 (7.02952 iter/s, 14.2257s/100 iters), loss = 0.00155269
I0928 16:29:19.671391  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00155251 (* 1 = 0.00155251 loss)
I0928 16:29:19.671397  4581 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I0928 16:29:33.891865  4581 solver.cpp:218] Iteration 65400 (7.03213 iter/s, 14.2204s/100 iters), loss = 0.00228809
I0928 16:29:33.891906  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00228791 (* 1 = 0.00228791 loss)
I0928 16:29:33.891912  4581 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I0928 16:29:47.410311  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:29:47.981052  4581 solver.cpp:330] Iteration 65500, Testing net (#0)
I0928 16:29:51.350852  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:29:51.491653  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9228
I0928 16:29:51.491689  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322435 (* 1 = 0.322435 loss)
I0928 16:29:51.634552  4581 solver.cpp:218] Iteration 65500 (5.63615 iter/s, 17.7426s/100 iters), loss = 0.0046465
I0928 16:29:51.634582  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00464632 (* 1 = 0.00464632 loss)
I0928 16:29:51.634588  4581 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I0928 16:30:05.865075  4581 solver.cpp:218] Iteration 65600 (7.02718 iter/s, 14.2305s/100 iters), loss = 0.00108728
I0928 16:30:05.865116  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108711 (* 1 = 0.00108711 loss)
I0928 16:30:05.865123  4581 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I0928 16:30:20.101871  4581 solver.cpp:218] Iteration 65700 (7.02409 iter/s, 14.2367s/100 iters), loss = 0.00938068
I0928 16:30:20.102007  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0093805 (* 1 = 0.0093805 loss)
I0928 16:30:20.102016  4581 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I0928 16:30:34.343708  4581 solver.cpp:218] Iteration 65800 (7.02165 iter/s, 14.2417s/100 iters), loss = 0.00320171
I0928 16:30:34.343749  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00320153 (* 1 = 0.00320153 loss)
I0928 16:30:34.343755  4581 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I0928 16:30:48.583350  4581 solver.cpp:218] Iteration 65900 (7.02269 iter/s, 14.2396s/100 iters), loss = 0.00258234
I0928 16:30:48.583391  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00258217 (* 1 = 0.00258217 loss)
I0928 16:30:48.583397  4581 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I0928 16:31:02.116312  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:31:02.685274  4581 solver.cpp:330] Iteration 66000, Testing net (#0)
I0928 16:31:06.051568  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:31:06.192395  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9222
I0928 16:31:06.192425  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335443 (* 1 = 0.335443 loss)
I0928 16:31:06.337067  4581 solver.cpp:218] Iteration 66000 (5.63265 iter/s, 17.7536s/100 iters), loss = 0.00111425
I0928 16:31:06.337098  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00111408 (* 1 = 0.00111408 loss)
I0928 16:31:06.337105  4581 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I0928 16:31:20.565695  4581 solver.cpp:218] Iteration 66100 (7.02812 iter/s, 14.2286s/100 iters), loss = 0.00295581
I0928 16:31:20.565735  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00295564 (* 1 = 0.00295564 loss)
I0928 16:31:20.565742  4581 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I0928 16:31:34.801331  4581 solver.cpp:218] Iteration 66200 (7.02466 iter/s, 14.2356s/100 iters), loss = 0.00208974
I0928 16:31:34.801437  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00208957 (* 1 = 0.00208957 loss)
I0928 16:31:34.801445  4581 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I0928 16:31:49.032788  4581 solver.cpp:218] Iteration 66300 (7.02676 iter/s, 14.2313s/100 iters), loss = 0.00375674
I0928 16:31:49.032817  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00375657 (* 1 = 0.00375657 loss)
I0928 16:31:49.032824  4581 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I0928 16:32:03.261497  4581 solver.cpp:218] Iteration 66400 (7.02808 iter/s, 14.2286s/100 iters), loss = 0.00192487
I0928 16:32:03.261528  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00192471 (* 1 = 0.00192471 loss)
I0928 16:32:03.261533  4581 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I0928 16:32:16.787593  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:32:17.357518  4581 solver.cpp:330] Iteration 66500, Testing net (#0)
I0928 16:32:20.727617  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:32:20.868513  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I0928 16:32:20.868551  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.332575 (* 1 = 0.332575 loss)
I0928 16:32:21.010366  4581 solver.cpp:218] Iteration 66500 (5.63419 iter/s, 17.7488s/100 iters), loss = 0.00109935
I0928 16:32:21.010396  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00109919 (* 1 = 0.00109919 loss)
I0928 16:32:21.010402  4581 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I0928 16:32:35.234022  4581 solver.cpp:218] Iteration 66600 (7.03058 iter/s, 14.2236s/100 iters), loss = 0.000975615
I0928 16:32:35.234062  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000975452 (* 1 = 0.000975452 loss)
I0928 16:32:35.234069  4581 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I0928 16:32:49.464205  4581 solver.cpp:218] Iteration 66700 (7.02736 iter/s, 14.2301s/100 iters), loss = 0.0026372
I0928 16:32:49.464345  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00263703 (* 1 = 0.00263703 loss)
I0928 16:32:49.464363  4581 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I0928 16:33:03.691434  4581 solver.cpp:218] Iteration 66800 (7.02886 iter/s, 14.2271s/100 iters), loss = 0.00208335
I0928 16:33:03.691476  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00208319 (* 1 = 0.00208319 loss)
I0928 16:33:03.691483  4581 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I0928 16:33:17.918323  4581 solver.cpp:218] Iteration 66900 (7.02899 iter/s, 14.2268s/100 iters), loss = 0.000294778
I0928 16:33:17.918365  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000294614 (* 1 = 0.000294614 loss)
I0928 16:33:17.918370  4581 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I0928 16:33:31.443331  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:33:32.012994  4581 solver.cpp:330] Iteration 67000, Testing net (#0)
I0928 16:33:35.381521  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:33:35.522563  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9202
I0928 16:33:35.522600  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.344692 (* 1 = 0.344692 loss)
I0928 16:33:35.664572  4581 solver.cpp:218] Iteration 67000 (5.63502 iter/s, 17.7462s/100 iters), loss = 0.00107508
I0928 16:33:35.664602  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00107492 (* 1 = 0.00107492 loss)
I0928 16:33:35.664609  4581 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I0928 16:33:49.883173  4581 solver.cpp:218] Iteration 67100 (7.03307 iter/s, 14.2185s/100 iters), loss = 0.011644
I0928 16:33:49.883213  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116438 (* 1 = 0.0116438 loss)
I0928 16:33:49.883219  4581 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I0928 16:34:04.102041  4581 solver.cpp:218] Iteration 67200 (7.03295 iter/s, 14.2188s/100 iters), loss = 0.0028562
I0928 16:34:04.102180  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00285604 (* 1 = 0.00285604 loss)
I0928 16:34:04.102187  4581 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I0928 16:34:18.322247  4581 solver.cpp:218] Iteration 67300 (7.03233 iter/s, 14.22s/100 iters), loss = 0.00101012
I0928 16:34:18.322288  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100996 (* 1 = 0.00100996 loss)
I0928 16:34:18.322293  4581 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I0928 16:34:32.542356  4581 solver.cpp:218] Iteration 67400 (7.03233 iter/s, 14.22s/100 iters), loss = 0.000242985
I0928 16:34:32.542387  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000242822 (* 1 = 0.000242822 loss)
I0928 16:34:32.542393  4581 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I0928 16:34:46.059211  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:34:46.630211  4581 solver.cpp:330] Iteration 67500, Testing net (#0)
I0928 16:34:49.997277  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:34:50.138506  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I0928 16:34:50.138543  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326926 (* 1 = 0.326926 loss)
I0928 16:34:50.279780  4581 solver.cpp:218] Iteration 67500 (5.63782 iter/s, 17.7373s/100 iters), loss = 0.00139784
I0928 16:34:50.279809  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00139767 (* 1 = 0.00139767 loss)
I0928 16:34:50.279815  4581 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I0928 16:35:04.505115  4581 solver.cpp:218] Iteration 67600 (7.02975 iter/s, 14.2253s/100 iters), loss = 0.00163716
I0928 16:35:04.505156  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.001637 (* 1 = 0.001637 loss)
I0928 16:35:04.505162  4581 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I0928 16:35:18.734072  4581 solver.cpp:218] Iteration 67700 (7.02796 iter/s, 14.2289s/100 iters), loss = 0.00301194
I0928 16:35:18.734153  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00301178 (* 1 = 0.00301178 loss)
I0928 16:35:18.734163  4581 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I0928 16:35:32.964015  4581 solver.cpp:218] Iteration 67800 (7.02749 iter/s, 14.2298s/100 iters), loss = 0.00704691
I0928 16:35:32.964057  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00704675 (* 1 = 0.00704675 loss)
I0928 16:35:32.964063  4581 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I0928 16:35:47.190925  4581 solver.cpp:218] Iteration 67900 (7.02897 iter/s, 14.2268s/100 iters), loss = 0.00123579
I0928 16:35:47.190955  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00123563 (* 1 = 0.00123563 loss)
I0928 16:35:47.190963  4581 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I0928 16:36:00.713348  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:36:01.282397  4581 solver.cpp:330] Iteration 68000, Testing net (#0)
I0928 16:36:04.652449  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:36:04.793205  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9187
I0928 16:36:04.793231  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.362491 (* 1 = 0.362491 loss)
I0928 16:36:04.934934  4581 solver.cpp:218] Iteration 68000 (5.63573 iter/s, 17.7439s/100 iters), loss = 0.0028168
I0928 16:36:04.934962  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00281665 (* 1 = 0.00281665 loss)
I0928 16:36:04.934969  4581 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I0928 16:36:19.167942  4581 solver.cpp:218] Iteration 68100 (7.02596 iter/s, 14.2329s/100 iters), loss = 0.000819329
I0928 16:36:19.167982  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000819174 (* 1 = 0.000819174 loss)
I0928 16:36:19.167989  4581 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I0928 16:36:33.402699  4581 solver.cpp:218] Iteration 68200 (7.0251 iter/s, 14.2347s/100 iters), loss = 0.000657306
I0928 16:36:33.402758  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000657149 (* 1 = 0.000657149 loss)
I0928 16:36:33.402765  4581 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I0928 16:36:47.632930  4581 solver.cpp:218] Iteration 68300 (7.02734 iter/s, 14.2301s/100 iters), loss = 0.000542332
I0928 16:36:47.632961  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000542173 (* 1 = 0.000542173 loss)
I0928 16:36:47.632967  4581 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I0928 16:37:01.860700  4581 solver.cpp:218] Iteration 68400 (7.02854 iter/s, 14.2277s/100 iters), loss = 0.00126813
I0928 16:37:01.860730  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00126797 (* 1 = 0.00126797 loss)
I0928 16:37:01.860738  4581 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I0928 16:37:15.387168  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:37:15.956871  4581 solver.cpp:330] Iteration 68500, Testing net (#0)
I0928 16:37:19.326042  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:37:19.467145  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9202
I0928 16:37:19.467182  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.340948 (* 1 = 0.340948 loss)
I0928 16:37:19.608618  4581 solver.cpp:218] Iteration 68500 (5.63449 iter/s, 17.7478s/100 iters), loss = 0.000785592
I0928 16:37:19.608647  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000785432 (* 1 = 0.000785432 loss)
I0928 16:37:19.608654  4581 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I0928 16:37:33.837034  4581 solver.cpp:218] Iteration 68600 (7.02822 iter/s, 14.2283s/100 iters), loss = 0.000578389
I0928 16:37:33.837076  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000578229 (* 1 = 0.000578229 loss)
I0928 16:37:33.837082  4581 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I0928 16:37:48.066606  4581 solver.cpp:218] Iteration 68700 (7.02766 iter/s, 14.2295s/100 iters), loss = 0.00066179
I0928 16:37:48.066720  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00066163 (* 1 = 0.00066163 loss)
I0928 16:37:48.066727  4581 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I0928 16:38:02.299626  4581 solver.cpp:218] Iteration 68800 (7.02599 iter/s, 14.2329s/100 iters), loss = 0.00907215
I0928 16:38:02.299666  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00907199 (* 1 = 0.00907199 loss)
I0928 16:38:02.299672  4581 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I0928 16:38:16.528201  4581 solver.cpp:218] Iteration 68900 (7.02815 iter/s, 14.2285s/100 iters), loss = 0.00141566
I0928 16:38:16.528242  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00141549 (* 1 = 0.00141549 loss)
I0928 16:38:16.528249  4581 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I0928 16:38:30.044198  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:38:30.613086  4581 solver.cpp:330] Iteration 69000, Testing net (#0)
I0928 16:38:33.982847  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:38:34.123477  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9221
I0928 16:38:34.123503  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334246 (* 1 = 0.334246 loss)
I0928 16:38:34.264145  4581 solver.cpp:218] Iteration 69000 (5.6383 iter/s, 17.7359s/100 iters), loss = 0.00776175
I0928 16:38:34.264174  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00776158 (* 1 = 0.00776158 loss)
I0928 16:38:34.264181  4581 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I0928 16:38:48.490634  4581 solver.cpp:218] Iteration 69100 (7.02926 iter/s, 14.2262s/100 iters), loss = 0.00267437
I0928 16:38:48.490675  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0026742 (* 1 = 0.0026742 loss)
I0928 16:38:48.490681  4581 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I0928 16:39:02.721101  4581 solver.cpp:218] Iteration 69200 (7.02722 iter/s, 14.2304s/100 iters), loss = 0.00159175
I0928 16:39:02.721163  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00159158 (* 1 = 0.00159158 loss)
I0928 16:39:02.721171  4581 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I0928 16:39:16.949569  4581 solver.cpp:218] Iteration 69300 (7.02821 iter/s, 14.2284s/100 iters), loss = 0.000366386
I0928 16:39:16.949610  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00036622 (* 1 = 0.00036622 loss)
I0928 16:39:16.949616  4581 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I0928 16:39:31.189059  4581 solver.cpp:218] Iteration 69400 (7.02276 iter/s, 14.2394s/100 iters), loss = 0.0176402
I0928 16:39:31.189100  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176401 (* 1 = 0.0176401 loss)
I0928 16:39:31.189106  4581 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I0928 16:39:44.715337  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:39:45.284925  4581 solver.cpp:330] Iteration 69500, Testing net (#0)
I0928 16:39:48.655474  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:39:48.796365  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I0928 16:39:48.796401  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325345 (* 1 = 0.325345 loss)
I0928 16:39:48.938110  4581 solver.cpp:218] Iteration 69500 (5.63413 iter/s, 17.749s/100 iters), loss = 0.0017593
I0928 16:39:48.938140  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00175913 (* 1 = 0.00175913 loss)
I0928 16:39:48.938148  4581 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I0928 16:40:03.168241  4581 solver.cpp:218] Iteration 69600 (7.02738 iter/s, 14.2301s/100 iters), loss = 0.000430166
I0928 16:40:03.168280  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000429999 (* 1 = 0.000429999 loss)
I0928 16:40:03.168287  4581 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I0928 16:40:17.399919  4581 solver.cpp:218] Iteration 69700 (7.02661 iter/s, 14.2316s/100 iters), loss = 0.000624312
I0928 16:40:17.400043  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000624146 (* 1 = 0.000624146 loss)
I0928 16:40:17.400049  4581 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I0928 16:40:31.625182  4581 solver.cpp:218] Iteration 69800 (7.02982 iter/s, 14.2251s/100 iters), loss = 0.00160433
I0928 16:40:31.625223  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00160416 (* 1 = 0.00160416 loss)
I0928 16:40:31.625229  4581 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I0928 16:40:45.854882  4581 solver.cpp:218] Iteration 69900 (7.0276 iter/s, 14.2296s/100 iters), loss = 0.00127656
I0928 16:40:45.854924  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0012764 (* 1 = 0.0012764 loss)
I0928 16:40:45.854930  4581 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I0928 16:40:59.382944  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:40:59.952400  4581 solver.cpp:330] Iteration 70000, Testing net (#0)
I0928 16:41:03.325966  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:41:03.466891  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9243
I0928 16:41:03.466928  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324359 (* 1 = 0.324359 loss)
I0928 16:41:03.607964  4581 solver.cpp:218] Iteration 70000 (5.63285 iter/s, 17.753s/100 iters), loss = 0.00127384
I0928 16:41:03.607993  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00127367 (* 1 = 0.00127367 loss)
I0928 16:41:03.608000  4581 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I0928 16:41:17.835906  4581 solver.cpp:218] Iteration 70100 (7.02846 iter/s, 14.2279s/100 iters), loss = 0.0154405
I0928 16:41:17.835947  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0154403 (* 1 = 0.0154403 loss)
I0928 16:41:17.835953  4581 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I0928 16:41:32.066392  4581 solver.cpp:218] Iteration 70200 (7.02721 iter/s, 14.2304s/100 iters), loss = 0.000962363
I0928 16:41:32.066493  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000962197 (* 1 = 0.000962197 loss)
I0928 16:41:32.066499  4581 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I0928 16:41:46.290881  4581 solver.cpp:218] Iteration 70300 (7.03019 iter/s, 14.2244s/100 iters), loss = 0.00998529
I0928 16:41:46.290922  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00998513 (* 1 = 0.00998513 loss)
I0928 16:41:46.290928  4581 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I0928 16:42:00.523187  4581 solver.cpp:218] Iteration 70400 (7.02631 iter/s, 14.2322s/100 iters), loss = 0.00144214
I0928 16:42:00.523227  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00144197 (* 1 = 0.00144197 loss)
I0928 16:42:00.523233  4581 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I0928 16:42:14.041384  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:42:14.611400  4581 solver.cpp:330] Iteration 70500, Testing net (#0)
I0928 16:42:17.982517  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:42:18.123131  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9247
I0928 16:42:18.123167  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327938 (* 1 = 0.327938 loss)
I0928 16:42:18.265312  4581 solver.cpp:218] Iteration 70500 (5.63633 iter/s, 17.742s/100 iters), loss = 0.00731353
I0928 16:42:18.265341  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00731336 (* 1 = 0.00731336 loss)
I0928 16:42:18.265347  4581 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I0928 16:42:32.500775  4581 solver.cpp:218] Iteration 70600 (7.02475 iter/s, 14.2354s/100 iters), loss = 0.000951745
I0928 16:42:32.500816  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000951575 (* 1 = 0.000951575 loss)
I0928 16:42:32.500823  4581 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I0928 16:42:46.733572  4581 solver.cpp:218] Iteration 70700 (7.02607 iter/s, 14.2327s/100 iters), loss = 0.00310205
I0928 16:42:46.733675  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00310188 (* 1 = 0.00310188 loss)
I0928 16:42:46.733692  4581 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I0928 16:43:00.969038  4581 solver.cpp:218] Iteration 70800 (7.02478 iter/s, 14.2353s/100 iters), loss = 0.00102066
I0928 16:43:00.969069  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102048 (* 1 = 0.00102048 loss)
I0928 16:43:00.969075  4581 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I0928 16:43:15.203781  4581 solver.cpp:218] Iteration 70900 (7.0251 iter/s, 14.2347s/100 iters), loss = 0.000925556
I0928 16:43:15.203812  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00092538 (* 1 = 0.00092538 loss)
I0928 16:43:15.203829  4581 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I0928 16:43:28.736152  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:43:29.306702  4581 solver.cpp:330] Iteration 71000, Testing net (#0)
I0928 16:43:32.676604  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:43:32.817709  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9221
I0928 16:43:32.817745  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327433 (* 1 = 0.327433 loss)
I0928 16:43:32.958897  4581 solver.cpp:218] Iteration 71000 (5.6322 iter/s, 17.755s/100 iters), loss = 0.00399983
I0928 16:43:32.958926  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00399966 (* 1 = 0.00399966 loss)
I0928 16:43:32.958933  4581 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I0928 16:43:47.190373  4581 solver.cpp:218] Iteration 71100 (7.02671 iter/s, 14.2314s/100 iters), loss = 0.00439922
I0928 16:43:47.190403  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00439904 (* 1 = 0.00439904 loss)
I0928 16:43:47.190409  4581 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I0928 16:44:01.423076  4581 solver.cpp:218] Iteration 71200 (7.02611 iter/s, 14.2326s/100 iters), loss = 0.000572023
I0928 16:44:01.423141  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000571843 (* 1 = 0.000571843 loss)
I0928 16:44:01.423148  4581 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I0928 16:44:15.661944  4581 solver.cpp:218] Iteration 71300 (7.02308 iter/s, 14.2388s/100 iters), loss = 0.011847
I0928 16:44:15.661974  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118469 (* 1 = 0.0118469 loss)
I0928 16:44:15.661980  4581 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I0928 16:44:29.891885  4581 solver.cpp:218] Iteration 71400 (7.02747 iter/s, 14.2299s/100 iters), loss = 0.000399549
I0928 16:44:29.891924  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00039937 (* 1 = 0.00039937 loss)
I0928 16:44:29.891930  4581 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I0928 16:44:43.415949  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:44:43.986397  4581 solver.cpp:330] Iteration 71500, Testing net (#0)
I0928 16:44:47.354794  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:44:47.497210  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9219
I0928 16:44:47.497236  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32427 (* 1 = 0.32427 loss)
I0928 16:44:47.638793  4581 solver.cpp:218] Iteration 71500 (5.63481 iter/s, 17.7468s/100 iters), loss = 0.00242032
I0928 16:44:47.638823  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00242014 (* 1 = 0.00242014 loss)
I0928 16:44:47.638829  4581 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I0928 16:45:01.864192  4581 solver.cpp:218] Iteration 71600 (7.02971 iter/s, 14.2253s/100 iters), loss = 0.00953941
I0928 16:45:01.864222  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00953923 (* 1 = 0.00953923 loss)
I0928 16:45:01.864228  4581 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I0928 16:45:16.092646  4581 solver.cpp:218] Iteration 71700 (7.02821 iter/s, 14.2284s/100 iters), loss = 0.000497321
I0928 16:45:16.092725  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000497145 (* 1 = 0.000497145 loss)
I0928 16:45:16.092732  4581 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I0928 16:45:30.322006  4581 solver.cpp:218] Iteration 71800 (7.02778 iter/s, 14.2292s/100 iters), loss = 0.00123829
I0928 16:45:30.322036  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00123812 (* 1 = 0.00123812 loss)
I0928 16:45:30.322042  4581 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I0928 16:45:44.549772  4581 solver.cpp:218] Iteration 71900 (7.02854 iter/s, 14.2277s/100 iters), loss = 0.000911206
I0928 16:45:44.549803  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000911033 (* 1 = 0.000911033 loss)
I0928 16:45:44.549808  4581 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I0928 16:45:58.071744  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:45:58.641562  4581 solver.cpp:330] Iteration 72000, Testing net (#0)
I0928 16:46:02.008719  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:46:02.149796  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9209
I0928 16:46:02.149833  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33895 (* 1 = 0.33895 loss)
I0928 16:46:02.292217  4581 solver.cpp:218] Iteration 72000 (5.63623 iter/s, 17.7424s/100 iters), loss = 0.000581916
I0928 16:46:02.292248  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000581741 (* 1 = 0.000581741 loss)
I0928 16:46:02.292254  4581 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I0928 16:46:16.521845  4581 solver.cpp:218] Iteration 72100 (7.02763 iter/s, 14.2296s/100 iters), loss = 0.00199075
I0928 16:46:16.521875  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00199057 (* 1 = 0.00199057 loss)
I0928 16:46:16.521881  4581 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I0928 16:46:30.758008  4581 solver.cpp:218] Iteration 72200 (7.0244 iter/s, 14.2361s/100 iters), loss = 0.00309518
I0928 16:46:30.758076  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00309501 (* 1 = 0.00309501 loss)
I0928 16:46:30.758083  4581 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I0928 16:46:44.992449  4581 solver.cpp:218] Iteration 72300 (7.02527 iter/s, 14.2343s/100 iters), loss = 0.00359377
I0928 16:46:44.992491  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00359359 (* 1 = 0.00359359 loss)
I0928 16:46:44.992496  4581 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I0928 16:46:59.226462  4581 solver.cpp:218] Iteration 72400 (7.02547 iter/s, 14.2339s/100 iters), loss = 0.000842192
I0928 16:46:59.226492  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000842016 (* 1 = 0.000842016 loss)
I0928 16:46:59.226498  4581 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I0928 16:47:12.748122  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:47:13.318115  4581 solver.cpp:330] Iteration 72500, Testing net (#0)
I0928 16:47:16.686098  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:47:16.827374  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.925
I0928 16:47:16.827409  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318796 (* 1 = 0.318796 loss)
I0928 16:47:16.970166  4581 solver.cpp:218] Iteration 72500 (5.63583 iter/s, 17.7436s/100 iters), loss = 0.00359732
I0928 16:47:16.970194  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00359715 (* 1 = 0.00359715 loss)
I0928 16:47:16.970201  4581 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I0928 16:47:31.201131  4581 solver.cpp:218] Iteration 72600 (7.02696 iter/s, 14.2309s/100 iters), loss = 0.00115359
I0928 16:47:31.201160  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00115342 (* 1 = 0.00115342 loss)
I0928 16:47:31.201166  4581 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I0928 16:47:45.434779  4581 solver.cpp:218] Iteration 72700 (7.02564 iter/s, 14.2336s/100 iters), loss = 0.000414148
I0928 16:47:45.434916  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000413973 (* 1 = 0.000413973 loss)
I0928 16:47:45.434926  4581 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I0928 16:47:59.670259  4581 solver.cpp:218] Iteration 72800 (7.02479 iter/s, 14.2353s/100 iters), loss = 0.000198299
I0928 16:47:59.670300  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000198125 (* 1 = 0.000198125 loss)
I0928 16:47:59.670305  4581 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I0928 16:48:13.902642  4581 solver.cpp:218] Iteration 72900 (7.02627 iter/s, 14.2323s/100 iters), loss = 0.000646246
I0928 16:48:13.902673  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000646072 (* 1 = 0.000646072 loss)
I0928 16:48:13.902678  4581 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I0928 16:48:27.432443  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:48:28.003561  4581 solver.cpp:330] Iteration 73000, Testing net (#0)
I0928 16:48:31.372201  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:48:31.512485  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I0928 16:48:31.512521  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329885 (* 1 = 0.329885 loss)
I0928 16:48:31.654373  4581 solver.cpp:218] Iteration 73000 (5.63328 iter/s, 17.7517s/100 iters), loss = 0.00119003
I0928 16:48:31.654403  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00118986 (* 1 = 0.00118986 loss)
I0928 16:48:31.654410  4581 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I0928 16:48:45.886698  4581 solver.cpp:218] Iteration 73100 (7.0263 iter/s, 14.2322s/100 iters), loss = 0.000697593
I0928 16:48:45.886729  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000697422 (* 1 = 0.000697422 loss)
I0928 16:48:45.886734  4581 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I0928 16:49:00.125119  4581 solver.cpp:218] Iteration 73200 (7.02329 iter/s, 14.2383s/100 iters), loss = 0.00190178
I0928 16:49:00.125190  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00190161 (* 1 = 0.00190161 loss)
I0928 16:49:00.125198  4581 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I0928 16:49:14.360852  4581 solver.cpp:218] Iteration 73300 (7.02463 iter/s, 14.2356s/100 iters), loss = 0.00040413
I0928 16:49:14.360893  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000403959 (* 1 = 0.000403959 loss)
I0928 16:49:14.360898  4581 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I0928 16:49:28.601893  4581 solver.cpp:218] Iteration 73400 (7.022 iter/s, 14.241s/100 iters), loss = 0.000443691
I0928 16:49:28.601923  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000443521 (* 1 = 0.000443521 loss)
I0928 16:49:28.601929  4581 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I0928 16:49:42.124270  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:49:42.693377  4581 solver.cpp:330] Iteration 73500, Testing net (#0)
I0928 16:49:46.063881  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:49:46.204864  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9253
I0928 16:49:46.204900  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319707 (* 1 = 0.319707 loss)
I0928 16:49:46.346230  4581 solver.cpp:218] Iteration 73500 (5.63563 iter/s, 17.7443s/100 iters), loss = 0.00818476
I0928 16:49:46.346261  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00818459 (* 1 = 0.00818459 loss)
I0928 16:49:46.346267  4581 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I0928 16:50:00.571419  4581 solver.cpp:218] Iteration 73600 (7.02982 iter/s, 14.2251s/100 iters), loss = 0.00536521
I0928 16:50:00.571460  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00536504 (* 1 = 0.00536504 loss)
I0928 16:50:00.571466  4581 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I0928 16:50:14.798142  4581 solver.cpp:218] Iteration 73700 (7.02906 iter/s, 14.2266s/100 iters), loss = 0.000340183
I0928 16:50:14.798249  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000340012 (* 1 = 0.000340012 loss)
I0928 16:50:14.798256  4581 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I0928 16:50:29.026576  4581 solver.cpp:218] Iteration 73800 (7.02825 iter/s, 14.2283s/100 iters), loss = 0.0012064
I0928 16:50:29.026617  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00120623 (* 1 = 0.00120623 loss)
I0928 16:50:29.026623  4581 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I0928 16:50:43.255856  4581 solver.cpp:218] Iteration 73900 (7.0278 iter/s, 14.2292s/100 iters), loss = 0.00198516
I0928 16:50:43.255885  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00198499 (* 1 = 0.00198499 loss)
I0928 16:50:43.255892  4581 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I0928 16:50:56.775041  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:50:57.343960  4581 solver.cpp:330] Iteration 74000, Testing net (#0)
I0928 16:51:00.713418  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:51:00.854430  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9221
I0928 16:51:00.854466  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339626 (* 1 = 0.339626 loss)
I0928 16:51:00.996397  4581 solver.cpp:218] Iteration 74000 (5.63683 iter/s, 17.7405s/100 iters), loss = 0.000716508
I0928 16:51:00.996424  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00071634 (* 1 = 0.00071634 loss)
I0928 16:51:00.996431  4581 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I0928 16:51:15.220371  4581 solver.cpp:218] Iteration 74100 (7.03042 iter/s, 14.2239s/100 iters), loss = 0.00101073
I0928 16:51:15.220402  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00101056 (* 1 = 0.00101056 loss)
I0928 16:51:15.220407  4581 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I0928 16:51:29.446862  4581 solver.cpp:218] Iteration 74200 (7.02918 iter/s, 14.2264s/100 iters), loss = 0.00323687
I0928 16:51:29.446960  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0032367 (* 1 = 0.0032367 loss)
I0928 16:51:29.446969  4581 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I0928 16:51:43.669008  4581 solver.cpp:218] Iteration 74300 (7.03135 iter/s, 14.222s/100 iters), loss = 0.00104971
I0928 16:51:43.669047  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00104954 (* 1 = 0.00104954 loss)
I0928 16:51:43.669054  4581 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I0928 16:51:57.891604  4581 solver.cpp:218] Iteration 74400 (7.0311 iter/s, 14.2225s/100 iters), loss = 0.000352249
I0928 16:51:57.891635  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000352083 (* 1 = 0.000352083 loss)
I0928 16:51:57.891641  4581 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I0928 16:52:11.408176  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:52:11.977893  4581 solver.cpp:330] Iteration 74500, Testing net (#0)
I0928 16:52:15.348572  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:52:15.489413  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9193
I0928 16:52:15.489449  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.354342 (* 1 = 0.354342 loss)
I0928 16:52:15.630775  4581 solver.cpp:218] Iteration 74500 (5.63727 iter/s, 17.7391s/100 iters), loss = 0.00849046
I0928 16:52:15.630805  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00849029 (* 1 = 0.00849029 loss)
I0928 16:52:15.630810  4581 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I0928 16:52:29.857547  4581 solver.cpp:218] Iteration 74600 (7.02904 iter/s, 14.2267s/100 iters), loss = 0.010515
I0928 16:52:29.857587  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105149 (* 1 = 0.0105149 loss)
I0928 16:52:29.857594  4581 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I0928 16:52:44.086920  4581 solver.cpp:218] Iteration 74700 (7.02776 iter/s, 14.2293s/100 iters), loss = 0.00130106
I0928 16:52:44.087018  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0013009 (* 1 = 0.0013009 loss)
I0928 16:52:44.087034  4581 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I0928 16:52:58.317203  4581 solver.cpp:218] Iteration 74800 (7.02733 iter/s, 14.2301s/100 iters), loss = 0.000248025
I0928 16:52:58.317235  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000247856 (* 1 = 0.000247856 loss)
I0928 16:52:58.317242  4581 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I0928 16:53:12.555028  4581 solver.cpp:218] Iteration 74900 (7.02358 iter/s, 14.2378s/100 iters), loss = 0.000593102
I0928 16:53:12.555068  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000592932 (* 1 = 0.000592932 loss)
I0928 16:53:12.555075  4581 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I0928 16:53:26.079072  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:53:26.649220  4581 solver.cpp:330] Iteration 75000, Testing net (#0)
I0928 16:53:30.019443  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:53:30.159394  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9192
I0928 16:53:30.159430  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.350834 (* 1 = 0.350834 loss)
I0928 16:53:30.301671  4581 solver.cpp:218] Iteration 75000 (5.6349 iter/s, 17.7466s/100 iters), loss = 0.00193175
I0928 16:53:30.301699  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00193158 (* 1 = 0.00193158 loss)
I0928 16:53:30.301707  4581 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I0928 16:53:44.525084  4581 solver.cpp:218] Iteration 75100 (7.03071 iter/s, 14.2233s/100 iters), loss = 0.000554431
I0928 16:53:44.525113  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000554258 (* 1 = 0.000554258 loss)
I0928 16:53:44.525120  4581 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I0928 16:53:58.754971  4581 solver.cpp:218] Iteration 75200 (7.0275 iter/s, 14.2298s/100 iters), loss = 0.000946919
I0928 16:53:58.755089  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000946742 (* 1 = 0.000946742 loss)
I0928 16:53:58.755105  4581 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I0928 16:54:12.985003  4581 solver.cpp:218] Iteration 75300 (7.02746 iter/s, 14.2299s/100 iters), loss = 0.000318545
I0928 16:54:12.985045  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000318368 (* 1 = 0.000318368 loss)
I0928 16:54:12.985051  4581 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I0928 16:54:27.210295  4581 solver.cpp:218] Iteration 75400 (7.02977 iter/s, 14.2252s/100 iters), loss = 0.00100233
I0928 16:54:27.210325  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100215 (* 1 = 0.00100215 loss)
I0928 16:54:27.210330  4581 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I0928 16:54:40.733685  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:54:41.302007  4581 solver.cpp:330] Iteration 75500, Testing net (#0)
I0928 16:54:44.672255  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:54:44.812856  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9164
I0928 16:54:44.812892  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364771 (* 1 = 0.364771 loss)
I0928 16:54:44.954958  4581 solver.cpp:218] Iteration 75500 (5.63552 iter/s, 17.7446s/100 iters), loss = 0.000669876
I0928 16:54:44.954987  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000669699 (* 1 = 0.000669699 loss)
I0928 16:54:44.954993  4581 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I0928 16:54:59.174484  4581 solver.cpp:218] Iteration 75600 (7.03262 iter/s, 14.2195s/100 iters), loss = 0.000901412
I0928 16:54:59.174515  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000901234 (* 1 = 0.000901234 loss)
I0928 16:54:59.174522  4581 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I0928 16:55:13.392576  4581 solver.cpp:218] Iteration 75700 (7.03333 iter/s, 14.218s/100 iters), loss = 0.000714308
I0928 16:55:13.392673  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000714129 (* 1 = 0.000714129 loss)
I0928 16:55:13.392680  4581 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I0928 16:55:27.612233  4581 solver.cpp:218] Iteration 75800 (7.03259 iter/s, 14.2195s/100 iters), loss = 0.00205051
I0928 16:55:27.612277  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00205033 (* 1 = 0.00205033 loss)
I0928 16:55:27.612282  4581 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I0928 16:55:41.830708  4581 solver.cpp:218] Iteration 75900 (7.03314 iter/s, 14.2184s/100 iters), loss = 0.00154933
I0928 16:55:41.830737  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154915 (* 1 = 0.00154915 loss)
I0928 16:55:41.830744  4581 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I0928 16:55:55.350801  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:55:55.919411  4581 solver.cpp:330] Iteration 76000, Testing net (#0)
I0928 16:55:59.288604  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:55:59.429078  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9222
I0928 16:55:59.429114  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.336036 (* 1 = 0.336036 loss)
I0928 16:55:59.570952  4581 solver.cpp:218] Iteration 76000 (5.63693 iter/s, 17.7402s/100 iters), loss = 0.000397729
I0928 16:55:59.570981  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00039755 (* 1 = 0.00039755 loss)
I0928 16:55:59.570988  4581 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I0928 16:56:13.798180  4581 solver.cpp:218] Iteration 76100 (7.02881 iter/s, 14.2272s/100 iters), loss = 0.000596889
I0928 16:56:13.798220  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000596712 (* 1 = 0.000596712 loss)
I0928 16:56:13.798226  4581 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I0928 16:56:28.023941  4581 solver.cpp:218] Iteration 76200 (7.02954 iter/s, 14.2257s/100 iters), loss = 0.00261554
I0928 16:56:28.024055  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00261537 (* 1 = 0.00261537 loss)
I0928 16:56:28.024073  4581 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I0928 16:56:42.249969  4581 solver.cpp:218] Iteration 76300 (7.02945 iter/s, 14.2259s/100 iters), loss = 0.000476246
I0928 16:56:42.250015  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000476069 (* 1 = 0.000476069 loss)
I0928 16:56:42.250021  4581 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I0928 16:56:56.481231  4581 solver.cpp:218] Iteration 76400 (7.02683 iter/s, 14.2312s/100 iters), loss = 0.000290088
I0928 16:56:56.481261  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000289912 (* 1 = 0.000289912 loss)
I0928 16:56:56.481267  4581 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I0928 16:57:10.003897  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:57:10.573472  4581 solver.cpp:330] Iteration 76500, Testing net (#0)
I0928 16:57:13.943413  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:57:14.083837  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9234
I0928 16:57:14.083873  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329789 (* 1 = 0.329789 loss)
I0928 16:57:14.226213  4581 solver.cpp:218] Iteration 76500 (5.63542 iter/s, 17.7449s/100 iters), loss = 0.000921604
I0928 16:57:14.226243  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000921428 (* 1 = 0.000921428 loss)
I0928 16:57:14.226250  4581 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I0928 16:57:28.448462  4581 solver.cpp:218] Iteration 76600 (7.03127 iter/s, 14.2222s/100 iters), loss = 0.00180338
I0928 16:57:28.448492  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0018032 (* 1 = 0.0018032 loss)
I0928 16:57:28.448498  4581 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I0928 16:57:42.678766  4581 solver.cpp:218] Iteration 76700 (7.02729 iter/s, 14.2302s/100 iters), loss = 0.00125989
I0928 16:57:42.678922  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00125971 (* 1 = 0.00125971 loss)
I0928 16:57:42.678930  4581 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I0928 16:57:56.913451  4581 solver.cpp:218] Iteration 76800 (7.02518 iter/s, 14.2345s/100 iters), loss = 0.000783999
I0928 16:57:56.913491  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00078382 (* 1 = 0.00078382 loss)
I0928 16:57:56.913497  4581 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I0928 16:58:11.146832  4581 solver.cpp:218] Iteration 76900 (7.02578 iter/s, 14.2333s/100 iters), loss = 0.000920999
I0928 16:58:11.146874  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00092082 (* 1 = 0.00092082 loss)
I0928 16:58:11.146880  4581 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I0928 16:58:24.671736  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:58:25.241116  4581 solver.cpp:330] Iteration 77000, Testing net (#0)
I0928 16:58:28.609572  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:58:28.750749  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.922
I0928 16:58:28.750774  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329731 (* 1 = 0.329731 loss)
I0928 16:58:28.892264  4581 solver.cpp:218] Iteration 77000 (5.63528 iter/s, 17.7453s/100 iters), loss = 0.002373
I0928 16:58:28.892294  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00237282 (* 1 = 0.00237282 loss)
I0928 16:58:28.892302  4581 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I0928 16:58:43.114078  4581 solver.cpp:218] Iteration 77100 (7.03149 iter/s, 14.2217s/100 iters), loss = 0.00214572
I0928 16:58:43.114109  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00214554 (* 1 = 0.00214554 loss)
I0928 16:58:43.114115  4581 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I0928 16:58:57.340477  4581 solver.cpp:218] Iteration 77200 (7.02922 iter/s, 14.2263s/100 iters), loss = 0.000888478
I0928 16:58:57.340618  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0008883 (* 1 = 0.0008883 loss)
I0928 16:58:57.340626  4581 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I0928 16:59:11.572175  4581 solver.cpp:218] Iteration 77300 (7.02665 iter/s, 14.2315s/100 iters), loss = 0.00176486
I0928 16:59:11.572216  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00176468 (* 1 = 0.00176468 loss)
I0928 16:59:11.572222  4581 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I0928 16:59:25.800691  4581 solver.cpp:218] Iteration 77400 (7.02818 iter/s, 14.2284s/100 iters), loss = 0.000535366
I0928 16:59:25.800731  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000535186 (* 1 = 0.000535186 loss)
I0928 16:59:25.800737  4581 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I0928 16:59:39.326468  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:59:39.894836  4581 solver.cpp:330] Iteration 77500, Testing net (#0)
I0928 16:59:43.263075  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 16:59:43.404346  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9224
I0928 16:59:43.404382  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334079 (* 1 = 0.334079 loss)
I0928 16:59:43.545748  4581 solver.cpp:218] Iteration 77500 (5.6354 iter/s, 17.745s/100 iters), loss = 0.00160607
I0928 16:59:43.545778  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00160589 (* 1 = 0.00160589 loss)
I0928 16:59:43.545784  4581 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I0928 16:59:57.773391  4581 solver.cpp:218] Iteration 77600 (7.02861 iter/s, 14.2276s/100 iters), loss = 0.00169328
I0928 16:59:57.773432  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0016931 (* 1 = 0.0016931 loss)
I0928 16:59:57.773437  4581 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I0928 17:00:12.005079  4581 solver.cpp:218] Iteration 77700 (7.02661 iter/s, 14.2316s/100 iters), loss = 0.00596673
I0928 17:00:12.005167  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00596655 (* 1 = 0.00596655 loss)
I0928 17:00:12.005174  4581 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I0928 17:00:26.235769  4581 solver.cpp:218] Iteration 77800 (7.02713 iter/s, 14.2306s/100 iters), loss = 0.000904927
I0928 17:00:26.235808  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000904749 (* 1 = 0.000904749 loss)
I0928 17:00:26.235815  4581 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I0928 17:00:40.468395  4581 solver.cpp:218] Iteration 77900 (7.02615 iter/s, 14.2325s/100 iters), loss = 0.000575414
I0928 17:00:40.468436  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000575236 (* 1 = 0.000575236 loss)
I0928 17:00:40.468441  4581 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I0928 17:00:53.997548  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:00:54.566460  4581 solver.cpp:330] Iteration 78000, Testing net (#0)
I0928 17:00:57.934736  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:00:58.075747  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9213
I0928 17:00:58.075781  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.346519 (* 1 = 0.346519 loss)
I0928 17:00:58.217433  4581 solver.cpp:218] Iteration 78000 (5.63414 iter/s, 17.7489s/100 iters), loss = 0.000536953
I0928 17:00:58.217460  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000536774 (* 1 = 0.000536774 loss)
I0928 17:00:58.217468  4581 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I0928 17:01:12.445044  4581 solver.cpp:218] Iteration 78100 (7.02862 iter/s, 14.2275s/100 iters), loss = 0.0043875
I0928 17:01:12.445071  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00438732 (* 1 = 0.00438732 loss)
I0928 17:01:12.445078  4581 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I0928 17:01:26.679819  4581 solver.cpp:218] Iteration 78200 (7.02508 iter/s, 14.2347s/100 iters), loss = 0.000366345
I0928 17:01:26.679883  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000366164 (* 1 = 0.000366164 loss)
I0928 17:01:26.679889  4581 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I0928 17:01:40.911492  4581 solver.cpp:218] Iteration 78300 (7.02663 iter/s, 14.2316s/100 iters), loss = 0.00275773
I0928 17:01:40.911535  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00275755 (* 1 = 0.00275755 loss)
I0928 17:01:40.911540  4581 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I0928 17:01:55.143937  4581 solver.cpp:218] Iteration 78400 (7.02624 iter/s, 14.2324s/100 iters), loss = 0.000502091
I0928 17:01:55.143980  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000501909 (* 1 = 0.000501909 loss)
I0928 17:01:55.143985  4581 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I0928 17:02:08.668391  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:02:09.238992  4581 solver.cpp:330] Iteration 78500, Testing net (#0)
I0928 17:02:12.606503  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:02:12.747228  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9126
I0928 17:02:12.747264  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.408712 (* 1 = 0.408712 loss)
I0928 17:02:12.888459  4581 solver.cpp:218] Iteration 78500 (5.63557 iter/s, 17.7444s/100 iters), loss = 0.000756697
I0928 17:02:12.888489  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000756513 (* 1 = 0.000756513 loss)
I0928 17:02:12.888496  4581 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I0928 17:02:27.115698  4581 solver.cpp:218] Iteration 78600 (7.0288 iter/s, 14.2272s/100 iters), loss = 0.00146131
I0928 17:02:27.115730  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00146113 (* 1 = 0.00146113 loss)
I0928 17:02:27.115736  4581 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I0928 17:02:41.348263  4581 solver.cpp:218] Iteration 78700 (7.02618 iter/s, 14.2325s/100 iters), loss = 0.000503991
I0928 17:02:41.348382  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000503808 (* 1 = 0.000503808 loss)
I0928 17:02:41.348392  4581 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I0928 17:02:55.583168  4581 solver.cpp:218] Iteration 78800 (7.02506 iter/s, 14.2347s/100 iters), loss = 0.000211341
I0928 17:02:55.583209  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000211158 (* 1 = 0.000211158 loss)
I0928 17:02:55.583214  4581 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I0928 17:03:09.811060  4581 solver.cpp:218] Iteration 78900 (7.02849 iter/s, 14.2278s/100 iters), loss = 0.0018454
I0928 17:03:09.811090  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00184522 (* 1 = 0.00184522 loss)
I0928 17:03:09.811097  4581 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I0928 17:03:23.334394  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:03:23.904350  4581 solver.cpp:330] Iteration 79000, Testing net (#0)
I0928 17:03:27.274617  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:03:27.415408  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9244
I0928 17:03:27.415444  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333872 (* 1 = 0.333872 loss)
I0928 17:03:27.556902  4581 solver.cpp:218] Iteration 79000 (5.63515 iter/s, 17.7458s/100 iters), loss = 0.00065649
I0928 17:03:27.556931  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000656304 (* 1 = 0.000656304 loss)
I0928 17:03:27.556938  4581 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I0928 17:03:41.783447  4581 solver.cpp:218] Iteration 79100 (7.02915 iter/s, 14.2265s/100 iters), loss = 0.00108088
I0928 17:03:41.783488  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108069 (* 1 = 0.00108069 loss)
I0928 17:03:41.783494  4581 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I0928 17:03:56.011513  4581 solver.cpp:218] Iteration 79200 (7.0284 iter/s, 14.228s/100 iters), loss = 0.00599454
I0928 17:03:56.011587  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00599436 (* 1 = 0.00599436 loss)
I0928 17:03:56.011605  4581 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I0928 17:04:10.236941  4581 solver.cpp:218] Iteration 79300 (7.02972 iter/s, 14.2253s/100 iters), loss = 0.0022944
I0928 17:04:10.236982  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00229421 (* 1 = 0.00229421 loss)
I0928 17:04:10.236989  4581 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I0928 17:04:24.461144  4581 solver.cpp:218] Iteration 79400 (7.03031 iter/s, 14.2241s/100 iters), loss = 0.00198286
I0928 17:04:24.461184  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00198267 (* 1 = 0.00198267 loss)
I0928 17:04:24.461191  4581 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I0928 17:04:37.980017  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:04:38.549058  4581 solver.cpp:330] Iteration 79500, Testing net (#0)
I0928 17:04:41.919884  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:04:42.060657  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9214
I0928 17:04:42.060693  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329237 (* 1 = 0.329237 loss)
I0928 17:04:42.202253  4581 solver.cpp:218] Iteration 79500 (5.63665 iter/s, 17.741s/100 iters), loss = 0.00057402
I0928 17:04:42.202283  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000573836 (* 1 = 0.000573836 loss)
I0928 17:04:42.202291  4581 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I0928 17:04:56.432276  4581 solver.cpp:218] Iteration 79600 (7.02743 iter/s, 14.23s/100 iters), loss = 0.00163714
I0928 17:04:56.432317  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00163696 (* 1 = 0.00163696 loss)
I0928 17:04:56.432322  4581 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I0928 17:05:10.662451  4581 solver.cpp:218] Iteration 79700 (7.02736 iter/s, 14.2301s/100 iters), loss = 0.0109591
I0928 17:05:10.662576  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109589 (* 1 = 0.0109589 loss)
I0928 17:05:10.662585  4581 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I0928 17:05:24.901430  4581 solver.cpp:218] Iteration 79800 (7.02305 iter/s, 14.2388s/100 iters), loss = 0.00051465
I0928 17:05:24.901471  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000514465 (* 1 = 0.000514465 loss)
I0928 17:05:24.901477  4581 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I0928 17:05:39.142331  4581 solver.cpp:218] Iteration 79900 (7.02207 iter/s, 14.2408s/100 iters), loss = 0.00225711
I0928 17:05:39.142371  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00225693 (* 1 = 0.00225693 loss)
I0928 17:05:39.142377  4581 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I0928 17:05:52.671607  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:05:53.241592  4581 solver.cpp:330] Iteration 80000, Testing net (#0)
I0928 17:05:56.611212  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:05:56.752018  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9222
I0928 17:05:56.752055  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33131 (* 1 = 0.33131 loss)
I0928 17:05:56.893743  4581 solver.cpp:218] Iteration 80000 (5.63338 iter/s, 17.7513s/100 iters), loss = 0.00481157
I0928 17:05:56.893772  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00481139 (* 1 = 0.00481139 loss)
I0928 17:05:56.893779  4581 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I0928 17:05:56.893781  4581 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I0928 17:06:11.136696  4581 solver.cpp:218] Iteration 80100 (7.02105 iter/s, 14.2429s/100 iters), loss = 0.0036385
I0928 17:06:11.136744  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00363832 (* 1 = 0.00363832 loss)
I0928 17:06:11.136750  4581 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I0928 17:06:25.368049  4581 solver.cpp:218] Iteration 80200 (7.02678 iter/s, 14.2313s/100 iters), loss = 0.000988218
I0928 17:06:25.368190  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000988031 (* 1 = 0.000988031 loss)
I0928 17:06:25.368198  4581 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I0928 17:06:39.601629  4581 solver.cpp:218] Iteration 80300 (7.02573 iter/s, 14.2334s/100 iters), loss = 0.000698617
I0928 17:06:39.601661  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000698431 (* 1 = 0.000698431 loss)
I0928 17:06:39.601668  4581 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I0928 17:06:53.826112  4581 solver.cpp:218] Iteration 80400 (7.03017 iter/s, 14.2244s/100 iters), loss = 0.00230054
I0928 17:06:53.826153  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00230035 (* 1 = 0.00230035 loss)
I0928 17:06:53.826159  4581 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I0928 17:07:07.350883  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:07:07.921135  4581 solver.cpp:330] Iteration 80500, Testing net (#0)
I0928 17:07:11.288717  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:07:11.430003  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.926
I0928 17:07:11.430039  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322459 (* 1 = 0.322459 loss)
I0928 17:07:11.571918  4581 solver.cpp:218] Iteration 80500 (5.63516 iter/s, 17.7457s/100 iters), loss = 0.00156653
I0928 17:07:11.571949  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00156635 (* 1 = 0.00156635 loss)
I0928 17:07:11.571956  4581 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I0928 17:07:25.790472  4581 solver.cpp:218] Iteration 80600 (7.0331 iter/s, 14.2185s/100 iters), loss = 0.000289819
I0928 17:07:25.790513  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00028963 (* 1 = 0.00028963 loss)
I0928 17:07:25.790521  4581 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I0928 17:07:40.016901  4581 solver.cpp:218] Iteration 80700 (7.02921 iter/s, 14.2263s/100 iters), loss = 0.000409907
I0928 17:07:40.016989  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00040972 (* 1 = 0.00040972 loss)
I0928 17:07:40.016997  4581 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I0928 17:07:54.246682  4581 solver.cpp:218] Iteration 80800 (7.02758 iter/s, 14.2297s/100 iters), loss = 0.00130399
I0928 17:07:54.246723  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0013038 (* 1 = 0.0013038 loss)
I0928 17:07:54.246729  4581 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I0928 17:08:08.476341  4581 solver.cpp:218] Iteration 80900 (7.02761 iter/s, 14.2296s/100 iters), loss = 0.000674556
I0928 17:08:08.476371  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000674369 (* 1 = 0.000674369 loss)
I0928 17:08:08.476377  4581 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I0928 17:08:22.008563  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:08:22.578512  4581 solver.cpp:330] Iteration 81000, Testing net (#0)
I0928 17:08:25.947933  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:08:26.088887  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9259
I0928 17:08:26.088924  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.317979 (* 1 = 0.317979 loss)
I0928 17:08:26.231300  4581 solver.cpp:218] Iteration 81000 (5.63225 iter/s, 17.7549s/100 iters), loss = 0.00305274
I0928 17:08:26.231331  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00305255 (* 1 = 0.00305255 loss)
I0928 17:08:26.231339  4581 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I0928 17:08:40.460254  4581 solver.cpp:218] Iteration 81100 (7.02796 iter/s, 14.2289s/100 iters), loss = 0.00146399
I0928 17:08:40.460283  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0014638 (* 1 = 0.0014638 loss)
I0928 17:08:40.460290  4581 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I0928 17:08:54.694680  4581 solver.cpp:218] Iteration 81200 (7.02526 iter/s, 14.2344s/100 iters), loss = 0.00232084
I0928 17:08:54.694800  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00232066 (* 1 = 0.00232066 loss)
I0928 17:08:54.694818  4581 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I0928 17:09:08.922552  4581 solver.cpp:218] Iteration 81300 (7.02854 iter/s, 14.2277s/100 iters), loss = 0.000714311
I0928 17:09:08.922585  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000714123 (* 1 = 0.000714123 loss)
I0928 17:09:08.922590  4581 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I0928 17:09:23.147729  4581 solver.cpp:218] Iteration 81400 (7.02983 iter/s, 14.2251s/100 iters), loss = 0.000844634
I0928 17:09:23.147769  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000844448 (* 1 = 0.000844448 loss)
I0928 17:09:23.147775  4581 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I0928 17:09:36.667115  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:09:37.237181  4581 solver.cpp:330] Iteration 81500, Testing net (#0)
I0928 17:09:40.607728  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:09:40.748746  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9265
I0928 17:09:40.748781  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.317805 (* 1 = 0.317805 loss)
I0928 17:09:40.890512  4581 solver.cpp:218] Iteration 81500 (5.63612 iter/s, 17.7427s/100 iters), loss = 0.000679097
I0928 17:09:40.890544  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000678911 (* 1 = 0.000678911 loss)
I0928 17:09:40.890552  4581 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I0928 17:09:55.125933  4581 solver.cpp:218] Iteration 81600 (7.02477 iter/s, 14.2353s/100 iters), loss = 0.000412586
I0928 17:09:55.125973  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000412401 (* 1 = 0.000412401 loss)
I0928 17:09:55.125980  4581 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I0928 17:10:09.357882  4581 solver.cpp:218] Iteration 81700 (7.02648 iter/s, 14.2319s/100 iters), loss = 0.000299024
I0928 17:10:09.358032  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000298839 (* 1 = 0.000298839 loss)
I0928 17:10:09.358041  4581 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I0928 17:10:23.591567  4581 solver.cpp:218] Iteration 81800 (7.02568 iter/s, 14.2335s/100 iters), loss = 0.00279552
I0928 17:10:23.591609  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00279534 (* 1 = 0.00279534 loss)
I0928 17:10:23.591614  4581 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I0928 17:10:37.826966  4581 solver.cpp:218] Iteration 81900 (7.02478 iter/s, 14.2353s/100 iters), loss = 0.00121721
I0928 17:10:37.827006  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00121703 (* 1 = 0.00121703 loss)
I0928 17:10:37.827013  4581 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I0928 17:10:51.351263  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:10:51.921262  4581 solver.cpp:330] Iteration 82000, Testing net (#0)
I0928 17:10:55.290412  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:10:55.431334  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9273
I0928 17:10:55.431370  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316807 (* 1 = 0.316807 loss)
I0928 17:10:55.572963  4581 solver.cpp:218] Iteration 82000 (5.6351 iter/s, 17.7459s/100 iters), loss = 0.000917651
I0928 17:10:55.572994  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000917466 (* 1 = 0.000917466 loss)
I0928 17:10:55.573001  4581 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I0928 17:11:09.802937  4581 solver.cpp:218] Iteration 82100 (7.02746 iter/s, 14.2299s/100 iters), loss = 0.000875398
I0928 17:11:09.802978  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000875214 (* 1 = 0.000875214 loss)
I0928 17:11:09.802984  4581 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I0928 17:11:24.035584  4581 solver.cpp:218] Iteration 82200 (7.02614 iter/s, 14.2326s/100 iters), loss = 0.00112801
I0928 17:11:24.035701  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00112783 (* 1 = 0.00112783 loss)
I0928 17:11:24.035717  4581 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I0928 17:11:38.273986  4581 solver.cpp:218] Iteration 82300 (7.02333 iter/s, 14.2383s/100 iters), loss = 0.000745628
I0928 17:11:38.274019  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000745443 (* 1 = 0.000745443 loss)
I0928 17:11:38.274024  4581 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I0928 17:11:52.505295  4581 solver.cpp:218] Iteration 82400 (7.0268 iter/s, 14.2312s/100 iters), loss = 0.00087338
I0928 17:11:52.505338  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000873195 (* 1 = 0.000873195 loss)
I0928 17:11:52.505344  4581 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I0928 17:12:06.028605  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:12:06.598173  4581 solver.cpp:330] Iteration 82500, Testing net (#0)
I0928 17:12:09.966382  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:12:10.110298  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9273
I0928 17:12:10.110334  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.315633 (* 1 = 0.315633 loss)
I0928 17:12:10.251641  4581 solver.cpp:218] Iteration 82500 (5.63499 iter/s, 17.7463s/100 iters), loss = 0.000392888
I0928 17:12:10.251669  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000392702 (* 1 = 0.000392702 loss)
I0928 17:12:10.251677  4581 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I0928 17:12:24.476940  4581 solver.cpp:218] Iteration 82600 (7.02977 iter/s, 14.2252s/100 iters), loss = 0.00227765
I0928 17:12:24.476980  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00227746 (* 1 = 0.00227746 loss)
I0928 17:12:24.476986  4581 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I0928 17:12:38.706254  4581 solver.cpp:218] Iteration 82700 (7.02778 iter/s, 14.2292s/100 iters), loss = 0.000514338
I0928 17:12:38.706339  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000514151 (* 1 = 0.000514151 loss)
I0928 17:12:38.706346  4581 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I0928 17:12:52.938007  4581 solver.cpp:218] Iteration 82800 (7.0266 iter/s, 14.2316s/100 iters), loss = 0.0056363
I0928 17:12:52.938047  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00563612 (* 1 = 0.00563612 loss)
I0928 17:12:52.938053  4581 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I0928 17:13:07.165673  4581 solver.cpp:218] Iteration 82900 (7.0286 iter/s, 14.2276s/100 iters), loss = 0.000332728
I0928 17:13:07.165702  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000332542 (* 1 = 0.000332542 loss)
I0928 17:13:07.165709  4581 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I0928 17:13:20.689978  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:13:21.257984  4581 solver.cpp:330] Iteration 83000, Testing net (#0)
I0928 17:13:24.625300  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:13:24.766258  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9278
I0928 17:13:24.766281  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.315243 (* 1 = 0.315243 loss)
I0928 17:13:24.907737  4581 solver.cpp:218] Iteration 83000 (5.63635 iter/s, 17.742s/100 iters), loss = 0.00071619
I0928 17:13:24.907778  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000716004 (* 1 = 0.000716004 loss)
I0928 17:13:24.907788  4581 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I0928 17:13:39.131755  4581 solver.cpp:218] Iteration 83100 (7.03044 iter/s, 14.2239s/100 iters), loss = 0.00143537
I0928 17:13:39.131785  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00143519 (* 1 = 0.00143519 loss)
I0928 17:13:39.131791  4581 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I0928 17:13:53.353302  4581 solver.cpp:218] Iteration 83200 (7.03162 iter/s, 14.2215s/100 iters), loss = 0.000892141
I0928 17:13:53.353432  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000891957 (* 1 = 0.000891957 loss)
I0928 17:13:53.353440  4581 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I0928 17:14:07.584159  4581 solver.cpp:218] Iteration 83300 (7.02707 iter/s, 14.2307s/100 iters), loss = 0.000572036
I0928 17:14:07.584198  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000571853 (* 1 = 0.000571853 loss)
I0928 17:14:07.584205  4581 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I0928 17:14:21.812559  4581 solver.cpp:218] Iteration 83400 (7.02824 iter/s, 14.2283s/100 iters), loss = 0.000696045
I0928 17:14:21.812600  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000695862 (* 1 = 0.000695862 loss)
I0928 17:14:21.812607  4581 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I0928 17:14:35.337151  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:14:35.906405  4581 solver.cpp:330] Iteration 83500, Testing net (#0)
I0928 17:14:39.275454  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:14:39.416133  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9284
I0928 17:14:39.416169  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.315536 (* 1 = 0.315536 loss)
I0928 17:14:39.557812  4581 solver.cpp:218] Iteration 83500 (5.63534 iter/s, 17.7452s/100 iters), loss = 0.000480608
I0928 17:14:39.557842  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000480426 (* 1 = 0.000480426 loss)
I0928 17:14:39.557848  4581 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I0928 17:14:53.783835  4581 solver.cpp:218] Iteration 83600 (7.02941 iter/s, 14.226s/100 iters), loss = 0.00179103
I0928 17:14:53.783865  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00179085 (* 1 = 0.00179085 loss)
I0928 17:14:53.783871  4581 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I0928 17:15:08.015399  4581 solver.cpp:218] Iteration 83700 (7.02667 iter/s, 14.2315s/100 iters), loss = 0.000417284
I0928 17:15:08.015506  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000417101 (* 1 = 0.000417101 loss)
I0928 17:15:08.015513  4581 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I0928 17:15:22.247274  4581 solver.cpp:218] Iteration 83800 (7.02655 iter/s, 14.2317s/100 iters), loss = 0.00159415
I0928 17:15:22.247315  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00159397 (* 1 = 0.00159397 loss)
I0928 17:15:22.247321  4581 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I0928 17:15:36.480990  4581 solver.cpp:218] Iteration 83900 (7.02561 iter/s, 14.2336s/100 iters), loss = 0.00324403
I0928 17:15:36.481020  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00324385 (* 1 = 0.00324385 loss)
I0928 17:15:36.481026  4581 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I0928 17:15:50.002718  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:15:50.575289  4581 solver.cpp:330] Iteration 84000, Testing net (#0)
I0928 17:15:53.943910  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:15:54.084877  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9286
I0928 17:15:54.084913  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.315039 (* 1 = 0.315039 loss)
I0928 17:15:54.227205  4581 solver.cpp:218] Iteration 84000 (5.63503 iter/s, 17.7461s/100 iters), loss = 0.000448628
I0928 17:15:54.227234  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000448445 (* 1 = 0.000448445 loss)
I0928 17:15:54.227241  4581 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I0928 17:16:08.444667  4581 solver.cpp:218] Iteration 84100 (7.03364 iter/s, 14.2174s/100 iters), loss = 0.000511136
I0928 17:16:08.444708  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000510953 (* 1 = 0.000510953 loss)
I0928 17:16:08.444715  4581 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I0928 17:16:22.670897  4581 solver.cpp:218] Iteration 84200 (7.02931 iter/s, 14.2261s/100 iters), loss = 0.000569404
I0928 17:16:22.671027  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000569221 (* 1 = 0.000569221 loss)
I0928 17:16:22.671036  4581 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I0928 17:16:36.895666  4581 solver.cpp:218] Iteration 84300 (7.03007 iter/s, 14.2246s/100 iters), loss = 0.000812862
I0928 17:16:36.895706  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000812679 (* 1 = 0.000812679 loss)
I0928 17:16:36.895712  4581 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I0928 17:16:51.126025  4581 solver.cpp:218] Iteration 84400 (7.02727 iter/s, 14.2303s/100 iters), loss = 0.00039631
I0928 17:16:51.126055  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000396128 (* 1 = 0.000396128 loss)
I0928 17:16:51.126061  4581 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I0928 17:17:04.642891  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:17:05.212069  4581 solver.cpp:330] Iteration 84500, Testing net (#0)
I0928 17:17:08.582113  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:17:08.722795  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9282
I0928 17:17:08.722829  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314726 (* 1 = 0.314726 loss)
I0928 17:17:08.864320  4581 solver.cpp:218] Iteration 84500 (5.63754 iter/s, 17.7382s/100 iters), loss = 0.00123999
I0928 17:17:08.864348  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0012398 (* 1 = 0.0012398 loss)
I0928 17:17:08.864356  4581 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I0928 17:17:23.090006  4581 solver.cpp:218] Iteration 84600 (7.02957 iter/s, 14.2256s/100 iters), loss = 0.00067556
I0928 17:17:23.090047  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000675377 (* 1 = 0.000675377 loss)
I0928 17:17:23.090054  4581 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I0928 17:17:37.323261  4581 solver.cpp:218] Iteration 84700 (7.02584 iter/s, 14.2332s/100 iters), loss = 0.000469731
I0928 17:17:37.323345  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000469548 (* 1 = 0.000469548 loss)
I0928 17:17:37.323352  4581 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I0928 17:17:51.553025  4581 solver.cpp:218] Iteration 84800 (7.02758 iter/s, 14.2296s/100 iters), loss = 0.000988509
I0928 17:17:51.553066  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000988324 (* 1 = 0.000988324 loss)
I0928 17:17:51.553072  4581 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I0928 17:18:05.784817  4581 solver.cpp:218] Iteration 84900 (7.02656 iter/s, 14.2317s/100 iters), loss = 0.000635004
I0928 17:18:05.784847  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000634819 (* 1 = 0.000634819 loss)
I0928 17:18:05.784855  4581 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I0928 17:18:19.308300  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:18:19.878937  4581 solver.cpp:330] Iteration 85000, Testing net (#0)
I0928 17:18:23.249126  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:18:23.390018  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9286
I0928 17:18:23.390055  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.315109 (* 1 = 0.315109 loss)
I0928 17:18:23.532101  4581 solver.cpp:218] Iteration 85000 (5.63469 iter/s, 17.7472s/100 iters), loss = 0.000615462
I0928 17:18:23.532130  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000615276 (* 1 = 0.000615276 loss)
I0928 17:18:23.532137  4581 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I0928 17:18:37.760190  4581 solver.cpp:218] Iteration 85100 (7.02839 iter/s, 14.228s/100 iters), loss = 0.00144877
I0928 17:18:37.760231  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00144859 (* 1 = 0.00144859 loss)
I0928 17:18:37.760236  4581 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I0928 17:18:51.994052  4581 solver.cpp:218] Iteration 85200 (7.02554 iter/s, 14.2338s/100 iters), loss = 0.000382906
I0928 17:18:51.994187  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000382719 (* 1 = 0.000382719 loss)
I0928 17:18:51.994195  4581 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I0928 17:19:06.229954  4581 solver.cpp:218] Iteration 85300 (7.02458 iter/s, 14.2357s/100 iters), loss = 0.000848303
I0928 17:19:06.229984  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000848116 (* 1 = 0.000848116 loss)
I0928 17:19:06.230000  4581 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I0928 17:19:20.456290  4581 solver.cpp:218] Iteration 85400 (7.02925 iter/s, 14.2263s/100 iters), loss = 0.00127012
I0928 17:19:20.456320  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00126993 (* 1 = 0.00126993 loss)
I0928 17:19:20.456326  4581 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I0928 17:19:33.983469  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:19:34.551476  4581 solver.cpp:330] Iteration 85500, Testing net (#0)
I0928 17:19:37.921661  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:19:38.062170  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9281
I0928 17:19:38.062206  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313593 (* 1 = 0.313593 loss)
I0928 17:19:38.204342  4581 solver.cpp:218] Iteration 85500 (5.63445 iter/s, 17.748s/100 iters), loss = 0.00110619
I0928 17:19:38.204371  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.001106 (* 1 = 0.001106 loss)
I0928 17:19:38.204380  4581 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I0928 17:19:52.425129  4581 solver.cpp:218] Iteration 85600 (7.03199 iter/s, 14.2207s/100 iters), loss = 0.00103745
I0928 17:19:52.425159  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103726 (* 1 = 0.00103726 loss)
I0928 17:19:52.425165  4581 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I0928 17:20:06.651963  4581 solver.cpp:218] Iteration 85700 (7.029 iter/s, 14.2268s/100 iters), loss = 0.00112366
I0928 17:20:06.652109  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00112348 (* 1 = 0.00112348 loss)
I0928 17:20:06.652117  4581 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I0928 17:20:20.874276  4581 solver.cpp:218] Iteration 85800 (7.0313 iter/s, 14.2221s/100 iters), loss = 0.00119655
I0928 17:20:20.874307  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00119636 (* 1 = 0.00119636 loss)
I0928 17:20:20.874315  4581 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I0928 17:20:35.101032  4581 solver.cpp:218] Iteration 85900 (7.02904 iter/s, 14.2267s/100 iters), loss = 0.00101075
I0928 17:20:35.101073  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00101056 (* 1 = 0.00101056 loss)
I0928 17:20:35.101079  4581 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I0928 17:20:48.616725  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:20:49.186017  4581 solver.cpp:330] Iteration 86000, Testing net (#0)
I0928 17:20:52.553797  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:20:52.694532  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9283
I0928 17:20:52.694569  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312848 (* 1 = 0.312848 loss)
I0928 17:20:52.836086  4581 solver.cpp:218] Iteration 86000 (5.63858 iter/s, 17.735s/100 iters), loss = 0.000722646
I0928 17:20:52.836117  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000722459 (* 1 = 0.000722459 loss)
I0928 17:20:52.836123  4581 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I0928 17:21:07.058225  4581 solver.cpp:218] Iteration 86100 (7.03133 iter/s, 14.2221s/100 iters), loss = 0.00120097
I0928 17:21:07.058256  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00120078 (* 1 = 0.00120078 loss)
I0928 17:21:07.058264  4581 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I0928 17:21:21.288180  4581 solver.cpp:218] Iteration 86200 (7.02746 iter/s, 14.2299s/100 iters), loss = 0.0014029
I0928 17:21:21.288298  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00140271 (* 1 = 0.00140271 loss)
I0928 17:21:21.288316  4581 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I0928 17:21:35.518442  4581 solver.cpp:218] Iteration 86300 (7.02736 iter/s, 14.2301s/100 iters), loss = 0.000248054
I0928 17:21:35.518484  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000247868 (* 1 = 0.000247868 loss)
I0928 17:21:35.518491  4581 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I0928 17:21:49.747808  4581 solver.cpp:218] Iteration 86400 (7.02776 iter/s, 14.2293s/100 iters), loss = 0.00088149
I0928 17:21:49.747849  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000881305 (* 1 = 0.000881305 loss)
I0928 17:21:49.747855  4581 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I0928 17:22:03.269464  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:22:03.839520  4581 solver.cpp:330] Iteration 86500, Testing net (#0)
I0928 17:22:07.209895  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:22:07.350674  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9279
I0928 17:22:07.350710  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312287 (* 1 = 0.312287 loss)
I0928 17:22:07.492594  4581 solver.cpp:218] Iteration 86500 (5.63549 iter/s, 17.7447s/100 iters), loss = 0.000527474
I0928 17:22:07.492624  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000527287 (* 1 = 0.000527287 loss)
I0928 17:22:07.492631  4581 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I0928 17:22:21.721483  4581 solver.cpp:218] Iteration 86600 (7.02799 iter/s, 14.2288s/100 iters), loss = 0.000875793
I0928 17:22:21.721524  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000875607 (* 1 = 0.000875607 loss)
I0928 17:22:21.721529  4581 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I0928 17:22:35.951215  4581 solver.cpp:218] Iteration 86700 (7.02758 iter/s, 14.2297s/100 iters), loss = 0.000805345
I0928 17:22:35.951375  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00080516 (* 1 = 0.00080516 loss)
I0928 17:22:35.951393  4581 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I0928 17:22:50.174893  4581 solver.cpp:218] Iteration 86800 (7.03063 iter/s, 14.2235s/100 iters), loss = 0.000870588
I0928 17:22:50.174924  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000870403 (* 1 = 0.000870403 loss)
I0928 17:22:50.174940  4581 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I0928 17:23:04.406368  4581 solver.cpp:218] Iteration 86900 (7.02671 iter/s, 14.2314s/100 iters), loss = 0.000888664
I0928 17:23:04.406399  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000888479 (* 1 = 0.000888479 loss)
I0928 17:23:04.406415  4581 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I0928 17:23:17.928295  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:23:18.497503  4581 solver.cpp:330] Iteration 87000, Testing net (#0)
I0928 17:23:21.867880  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:23:22.009153  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9281
I0928 17:23:22.009189  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311311 (* 1 = 0.311311 loss)
I0928 17:23:22.150657  4581 solver.cpp:218] Iteration 87000 (5.63564 iter/s, 17.7442s/100 iters), loss = 0.000447669
I0928 17:23:22.150686  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000447484 (* 1 = 0.000447484 loss)
I0928 17:23:22.150692  4581 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I0928 17:23:36.378119  4581 solver.cpp:218] Iteration 87100 (7.0287 iter/s, 14.2274s/100 iters), loss = 0.000366639
I0928 17:23:36.378150  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000366453 (* 1 = 0.000366453 loss)
I0928 17:23:36.378156  4581 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I0928 17:23:50.608880  4581 solver.cpp:218] Iteration 87200 (7.02707 iter/s, 14.2307s/100 iters), loss = 0.000483528
I0928 17:23:50.609014  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000483342 (* 1 = 0.000483342 loss)
I0928 17:23:50.609021  4581 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I0928 17:24:04.841596  4581 solver.cpp:218] Iteration 87300 (7.02615 iter/s, 14.2326s/100 iters), loss = 0.000261574
I0928 17:24:04.841627  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000261388 (* 1 = 0.000261388 loss)
I0928 17:24:04.841642  4581 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I0928 17:24:19.075155  4581 solver.cpp:218] Iteration 87400 (7.02568 iter/s, 14.2335s/100 iters), loss = 0.00128935
I0928 17:24:19.075196  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128916 (* 1 = 0.00128916 loss)
I0928 17:24:19.075202  4581 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I0928 17:24:32.602111  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:24:33.171907  4581 solver.cpp:330] Iteration 87500, Testing net (#0)
I0928 17:24:36.541654  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:24:36.682400  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9286
I0928 17:24:36.682426  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31215 (* 1 = 0.31215 loss)
I0928 17:24:36.824424  4581 solver.cpp:218] Iteration 87500 (5.63406 iter/s, 17.7492s/100 iters), loss = 0.0003872
I0928 17:24:36.824453  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000387012 (* 1 = 0.000387012 loss)
I0928 17:24:36.824460  4581 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I0928 17:24:51.052054  4581 solver.cpp:218] Iteration 87600 (7.02861 iter/s, 14.2276s/100 iters), loss = 0.00109565
I0928 17:24:51.052084  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00109546 (* 1 = 0.00109546 loss)
I0928 17:24:51.052091  4581 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I0928 17:25:05.285868  4581 solver.cpp:218] Iteration 87700 (7.02556 iter/s, 14.2337s/100 iters), loss = 0.000847077
I0928 17:25:05.285970  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000846888 (* 1 = 0.000846888 loss)
I0928 17:25:05.285986  4581 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I0928 17:25:19.521047  4581 solver.cpp:218] Iteration 87800 (7.02492 iter/s, 14.235s/100 iters), loss = 0.000341923
I0928 17:25:19.521078  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000341735 (* 1 = 0.000341735 loss)
I0928 17:25:19.521085  4581 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I0928 17:25:33.758203  4581 solver.cpp:218] Iteration 87900 (7.02391 iter/s, 14.2371s/100 iters), loss = 0.000208277
I0928 17:25:33.758244  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00020809 (* 1 = 0.00020809 loss)
I0928 17:25:33.758249  4581 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I0928 17:25:47.287269  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:25:47.856876  4581 solver.cpp:330] Iteration 88000, Testing net (#0)
I0928 17:25:51.225162  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:25:51.367645  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9285
I0928 17:25:51.367669  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312122 (* 1 = 0.312122 loss)
I0928 17:25:51.509208  4581 solver.cpp:218] Iteration 88000 (5.63351 iter/s, 17.7509s/100 iters), loss = 0.000215816
I0928 17:25:51.509238  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00021563 (* 1 = 0.00021563 loss)
I0928 17:25:51.509243  4581 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I0928 17:26:05.731565  4581 solver.cpp:218] Iteration 88100 (7.03122 iter/s, 14.2223s/100 iters), loss = 0.000487719
I0928 17:26:05.731595  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000487532 (* 1 = 0.000487532 loss)
I0928 17:26:05.731600  4581 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I0928 17:26:19.955641  4581 solver.cpp:218] Iteration 88200 (7.03037 iter/s, 14.224s/100 iters), loss = 0.000665175
I0928 17:26:19.955775  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000664989 (* 1 = 0.000664989 loss)
I0928 17:26:19.955782  4581 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I0928 17:26:34.178550  4581 solver.cpp:218] Iteration 88300 (7.031 iter/s, 14.2227s/100 iters), loss = 0.00153613
I0928 17:26:34.178580  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153594 (* 1 = 0.00153594 loss)
I0928 17:26:34.178587  4581 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I0928 17:26:48.409636  4581 solver.cpp:218] Iteration 88400 (7.0269 iter/s, 14.231s/100 iters), loss = 0.00133796
I0928 17:26:48.409667  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00133777 (* 1 = 0.00133777 loss)
I0928 17:26:48.409672  4581 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I0928 17:27:01.934234  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:27:02.503042  4581 solver.cpp:330] Iteration 88500, Testing net (#0)
I0928 17:27:05.869021  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:27:06.010388  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9285
I0928 17:27:06.010424  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311697 (* 1 = 0.311697 loss)
I0928 17:27:06.151463  4581 solver.cpp:218] Iteration 88500 (5.63642 iter/s, 17.7418s/100 iters), loss = 0.00113719
I0928 17:27:06.151492  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00113701 (* 1 = 0.00113701 loss)
I0928 17:27:06.151499  4581 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I0928 17:27:20.390272  4581 solver.cpp:218] Iteration 88600 (7.02311 iter/s, 14.2387s/100 iters), loss = 0.00128698
I0928 17:27:20.390312  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0012868 (* 1 = 0.0012868 loss)
I0928 17:27:20.390319  4581 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I0928 17:27:34.624064  4581 solver.cpp:218] Iteration 88700 (7.02557 iter/s, 14.2337s/100 iters), loss = 0.000566864
I0928 17:27:34.624174  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000566679 (* 1 = 0.000566679 loss)
I0928 17:27:34.624181  4581 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I0928 17:27:48.857535  4581 solver.cpp:218] Iteration 88800 (7.02577 iter/s, 14.2333s/100 iters), loss = 0.00018028
I0928 17:27:48.857565  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000180096 (* 1 = 0.000180096 loss)
I0928 17:27:48.857571  4581 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I0928 17:28:03.096621  4581 solver.cpp:218] Iteration 88900 (7.02296 iter/s, 14.239s/100 iters), loss = 0.00233421
I0928 17:28:03.096652  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00233403 (* 1 = 0.00233403 loss)
I0928 17:28:03.096658  4581 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I0928 17:28:16.625308  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:28:17.195155  4581 solver.cpp:330] Iteration 89000, Testing net (#0)
I0928 17:28:20.562719  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:28:20.704061  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9285
I0928 17:28:20.704097  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311704 (* 1 = 0.311704 loss)
I0928 17:28:20.846007  4581 solver.cpp:218] Iteration 89000 (5.63402 iter/s, 17.7493s/100 iters), loss = 0.000609132
I0928 17:28:20.846035  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000608948 (* 1 = 0.000608948 loss)
I0928 17:28:20.846042  4581 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I0928 17:28:35.068117  4581 solver.cpp:218] Iteration 89100 (7.03134 iter/s, 14.222s/100 iters), loss = 0.00135055
I0928 17:28:35.068148  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00135036 (* 1 = 0.00135036 loss)
I0928 17:28:35.068155  4581 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I0928 17:28:49.296521  4581 solver.cpp:218] Iteration 89200 (7.02823 iter/s, 14.2283s/100 iters), loss = 0.000762906
I0928 17:28:49.296597  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000762721 (* 1 = 0.000762721 loss)
I0928 17:28:49.296605  4581 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I0928 17:29:03.522238  4581 solver.cpp:218] Iteration 89300 (7.02958 iter/s, 14.2256s/100 iters), loss = 0.000366047
I0928 17:29:03.522277  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000365863 (* 1 = 0.000365863 loss)
I0928 17:29:03.522284  4581 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I0928 17:29:17.747649  4581 solver.cpp:218] Iteration 89400 (7.02971 iter/s, 14.2253s/100 iters), loss = 0.000414065
I0928 17:29:17.747689  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000413882 (* 1 = 0.000413882 loss)
I0928 17:29:17.747694  4581 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I0928 17:29:31.263016  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:29:31.832892  4581 solver.cpp:330] Iteration 89500, Testing net (#0)
I0928 17:29:35.201817  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:29:35.342628  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9285
I0928 17:29:35.342653  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312429 (* 1 = 0.312429 loss)
I0928 17:29:35.484135  4581 solver.cpp:218] Iteration 89500 (5.63812 iter/s, 17.7364s/100 iters), loss = 0.000777439
I0928 17:29:35.484165  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000777255 (* 1 = 0.000777255 loss)
I0928 17:29:35.484172  4581 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I0928 17:29:49.708132  4581 solver.cpp:218] Iteration 89600 (7.03041 iter/s, 14.2239s/100 iters), loss = 0.00100338
I0928 17:29:49.708174  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100319 (* 1 = 0.00100319 loss)
I0928 17:29:49.708180  4581 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I0928 17:30:03.937561  4581 solver.cpp:218] Iteration 89700 (7.02773 iter/s, 14.2293s/100 iters), loss = 0.000733499
I0928 17:30:03.937692  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00073331 (* 1 = 0.00073331 loss)
I0928 17:30:03.937700  4581 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I0928 17:30:18.171459  4581 solver.cpp:218] Iteration 89800 (7.02556 iter/s, 14.2337s/100 iters), loss = 0.00159978
I0928 17:30:18.171489  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00159959 (* 1 = 0.00159959 loss)
I0928 17:30:18.171494  4581 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I0928 17:30:32.402606  4581 solver.cpp:218] Iteration 89900 (7.02688 iter/s, 14.2311s/100 iters), loss = 0.00296317
I0928 17:30:32.402645  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00296298 (* 1 = 0.00296298 loss)
I0928 17:30:32.402652  4581 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I0928 17:30:45.926436  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:30:46.495648  4581 solver.cpp:330] Iteration 90000, Testing net (#0)
I0928 17:30:49.866729  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:30:50.007827  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9282
I0928 17:30:50.007851  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312038 (* 1 = 0.312038 loss)
I0928 17:30:50.149029  4581 solver.cpp:218] Iteration 90000 (5.63497 iter/s, 17.7463s/100 iters), loss = 0.00193324
I0928 17:30:50.149057  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00193305 (* 1 = 0.00193305 loss)
I0928 17:30:50.149065  4581 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I0928 17:31:04.383982  4581 solver.cpp:218] Iteration 90100 (7.02499 iter/s, 14.2349s/100 iters), loss = 0.00246743
I0928 17:31:04.384013  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00246724 (* 1 = 0.00246724 loss)
I0928 17:31:04.384019  4581 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I0928 17:31:18.619027  4581 solver.cpp:218] Iteration 90200 (7.02495 iter/s, 14.235s/100 iters), loss = 0.000821311
I0928 17:31:18.619134  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000821123 (* 1 = 0.000821123 loss)
I0928 17:31:18.619151  4581 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I0928 17:31:32.854331  4581 solver.cpp:218] Iteration 90300 (7.02486 iter/s, 14.2352s/100 iters), loss = 0.000434147
I0928 17:31:32.854372  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000433959 (* 1 = 0.000433959 loss)
I0928 17:31:32.854377  4581 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I0928 17:31:47.094812  4581 solver.cpp:218] Iteration 90400 (7.02227 iter/s, 14.2404s/100 iters), loss = 0.000221744
I0928 17:31:47.094854  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000221555 (* 1 = 0.000221555 loss)
I0928 17:31:47.094861  4581 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I0928 17:32:00.626353  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:32:01.196234  4581 solver.cpp:330] Iteration 90500, Testing net (#0)
I0928 17:32:04.565330  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:32:04.706313  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9289
I0928 17:32:04.706349  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31295 (* 1 = 0.31295 loss)
I0928 17:32:04.848474  4581 solver.cpp:218] Iteration 90500 (5.63267 iter/s, 17.7536s/100 iters), loss = 0.000427431
I0928 17:32:04.848503  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000427243 (* 1 = 0.000427243 loss)
I0928 17:32:04.848510  4581 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I0928 17:32:19.078954  4581 solver.cpp:218] Iteration 90600 (7.02721 iter/s, 14.2304s/100 iters), loss = 0.0156222
I0928 17:32:19.078994  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015622 (* 1 = 0.015622 loss)
I0928 17:32:19.079000  4581 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I0928 17:32:33.316443  4581 solver.cpp:218] Iteration 90700 (7.02375 iter/s, 14.2374s/100 iters), loss = 0.00191331
I0928 17:32:33.316561  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00191313 (* 1 = 0.00191313 loss)
I0928 17:32:33.316570  4581 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I0928 17:32:47.550014  4581 solver.cpp:218] Iteration 90800 (7.02572 iter/s, 14.2334s/100 iters), loss = 0.00194597
I0928 17:32:47.550055  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00194578 (* 1 = 0.00194578 loss)
I0928 17:32:47.550060  4581 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I0928 17:33:01.783957  4581 solver.cpp:218] Iteration 90900 (7.0255 iter/s, 14.2339s/100 iters), loss = 0.00180726
I0928 17:33:01.783987  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00180707 (* 1 = 0.00180707 loss)
I0928 17:33:01.783993  4581 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I0928 17:33:15.313521  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:33:15.882086  4581 solver.cpp:330] Iteration 91000, Testing net (#0)
I0928 17:33:19.252468  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:33:19.393254  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9288
I0928 17:33:19.393290  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31174 (* 1 = 0.31174 loss)
I0928 17:33:19.535204  4581 solver.cpp:218] Iteration 91000 (5.63343 iter/s, 17.7512s/100 iters), loss = 0.000349009
I0928 17:33:19.535234  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000348818 (* 1 = 0.000348818 loss)
I0928 17:33:19.535241  4581 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I0928 17:33:33.767974  4581 solver.cpp:218] Iteration 91100 (7.02607 iter/s, 14.2327s/100 iters), loss = 0.0010038
I0928 17:33:33.768004  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100361 (* 1 = 0.00100361 loss)
I0928 17:33:33.768010  4581 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I0928 17:33:48.001569  4581 solver.cpp:218] Iteration 91200 (7.02567 iter/s, 14.2335s/100 iters), loss = 0.000879092
I0928 17:33:48.001665  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000878901 (* 1 = 0.000878901 loss)
I0928 17:33:48.001682  4581 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I0928 17:34:02.237534  4581 solver.cpp:218] Iteration 91300 (7.02453 iter/s, 14.2358s/100 iters), loss = 0.0019136
I0928 17:34:02.237562  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0019134 (* 1 = 0.0019134 loss)
I0928 17:34:02.237568  4581 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I0928 17:34:16.468603  4581 solver.cpp:218] Iteration 91400 (7.02691 iter/s, 14.231s/100 iters), loss = 0.000909678
I0928 17:34:16.468632  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000909487 (* 1 = 0.000909487 loss)
I0928 17:34:16.468638  4581 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I0928 17:34:29.989060  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:34:30.557476  4581 solver.cpp:330] Iteration 91500, Testing net (#0)
I0928 17:34:33.928329  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:34:34.069113  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9291
I0928 17:34:34.069149  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311188 (* 1 = 0.311188 loss)
I0928 17:34:34.211118  4581 solver.cpp:218] Iteration 91500 (5.6362 iter/s, 17.7424s/100 iters), loss = 0.0021899
I0928 17:34:34.211148  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00218971 (* 1 = 0.00218971 loss)
I0928 17:34:34.211155  4581 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I0928 17:34:48.432435  4581 solver.cpp:218] Iteration 91600 (7.03173 iter/s, 14.2212s/100 iters), loss = 0.00104231
I0928 17:34:48.432466  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00104212 (* 1 = 0.00104212 loss)
I0928 17:34:48.432472  4581 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I0928 17:35:02.664726  4581 solver.cpp:218] Iteration 91700 (7.02631 iter/s, 14.2322s/100 iters), loss = 0.00341317
I0928 17:35:02.664824  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00341298 (* 1 = 0.00341298 loss)
I0928 17:35:02.664841  4581 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I0928 17:35:16.892638  4581 solver.cpp:218] Iteration 91800 (7.02851 iter/s, 14.2278s/100 iters), loss = 0.00140168
I0928 17:35:16.892668  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00140149 (* 1 = 0.00140149 loss)
I0928 17:35:16.892684  4581 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I0928 17:35:31.118165  4581 solver.cpp:218] Iteration 91900 (7.02965 iter/s, 14.2255s/100 iters), loss = 0.000714987
I0928 17:35:31.118194  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000714797 (* 1 = 0.000714797 loss)
I0928 17:35:31.118201  4581 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I0928 17:35:44.640326  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:35:45.209514  4581 solver.cpp:330] Iteration 92000, Testing net (#0)
I0928 17:35:48.579741  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:35:48.720693  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9288
I0928 17:35:48.720729  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310555 (* 1 = 0.310555 loss)
I0928 17:35:48.862756  4581 solver.cpp:218] Iteration 92000 (5.63555 iter/s, 17.7445s/100 iters), loss = 0.000311587
I0928 17:35:48.862787  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000311397 (* 1 = 0.000311397 loss)
I0928 17:35:48.862793  4581 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I0928 17:36:03.092990  4581 solver.cpp:218] Iteration 92100 (7.02733 iter/s, 14.2302s/100 iters), loss = 0.00104805
I0928 17:36:03.093031  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00104786 (* 1 = 0.00104786 loss)
I0928 17:36:03.093039  4581 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I0928 17:36:17.322736  4581 solver.cpp:218] Iteration 92200 (7.02757 iter/s, 14.2297s/100 iters), loss = 0.00051036
I0928 17:36:17.322794  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000510171 (* 1 = 0.000510171 loss)
I0928 17:36:17.322813  4581 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I0928 17:36:31.551692  4581 solver.cpp:218] Iteration 92300 (7.02797 iter/s, 14.2289s/100 iters), loss = 0.00043308
I0928 17:36:31.551733  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000432891 (* 1 = 0.000432891 loss)
I0928 17:36:31.551739  4581 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I0928 17:36:45.775885  4581 solver.cpp:218] Iteration 92400 (7.03032 iter/s, 14.2241s/100 iters), loss = 0.000418194
I0928 17:36:45.775916  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000418003 (* 1 = 0.000418003 loss)
I0928 17:36:45.775923  4581 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I0928 17:36:59.296777  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:36:59.867207  4581 solver.cpp:330] Iteration 92500, Testing net (#0)
I0928 17:37:03.238070  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:37:03.379025  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9288
I0928 17:37:03.379061  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31233 (* 1 = 0.31233 loss)
I0928 17:37:03.520794  4581 solver.cpp:218] Iteration 92500 (5.63544 iter/s, 17.7448s/100 iters), loss = 0.000731501
I0928 17:37:03.520823  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000731311 (* 1 = 0.000731311 loss)
I0928 17:37:03.520830  4581 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I0928 17:37:17.750113  4581 solver.cpp:218] Iteration 92600 (7.02778 iter/s, 14.2292s/100 iters), loss = 0.000682582
I0928 17:37:17.750154  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000682393 (* 1 = 0.000682393 loss)
I0928 17:37:17.750159  4581 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I0928 17:37:31.982400  4581 solver.cpp:218] Iteration 92700 (7.02632 iter/s, 14.2322s/100 iters), loss = 0.000349941
I0928 17:37:31.982503  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000349752 (* 1 = 0.000349752 loss)
I0928 17:37:31.982524  4581 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I0928 17:37:46.210638  4581 solver.cpp:218] Iteration 92800 (7.02835 iter/s, 14.2281s/100 iters), loss = 0.000866257
I0928 17:37:46.210667  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000866068 (* 1 = 0.000866068 loss)
I0928 17:37:46.210674  4581 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I0928 17:38:00.440327  4581 solver.cpp:218] Iteration 92900 (7.02759 iter/s, 14.2296s/100 iters), loss = 0.000873044
I0928 17:38:00.440367  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000872853 (* 1 = 0.000872853 loss)
I0928 17:38:00.440373  4581 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I0928 17:38:13.961329  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:38:14.531563  4581 solver.cpp:330] Iteration 93000, Testing net (#0)
I0928 17:38:17.902182  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:38:18.043745  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9284
I0928 17:38:18.043771  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312607 (* 1 = 0.312607 loss)
I0928 17:38:18.185127  4581 solver.cpp:218] Iteration 93000 (5.63548 iter/s, 17.7447s/100 iters), loss = 0.000820419
I0928 17:38:18.185156  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000820228 (* 1 = 0.000820228 loss)
I0928 17:38:18.185164  4581 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I0928 17:38:32.408638  4581 solver.cpp:218] Iteration 93100 (7.03065 iter/s, 14.2234s/100 iters), loss = 0.00336077
I0928 17:38:32.408677  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00336058 (* 1 = 0.00336058 loss)
I0928 17:38:32.408684  4581 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I0928 17:38:46.638979  4581 solver.cpp:218] Iteration 93200 (7.02728 iter/s, 14.2303s/100 iters), loss = 0.000613601
I0928 17:38:46.639047  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00061341 (* 1 = 0.00061341 loss)
I0928 17:38:46.639055  4581 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I0928 17:39:00.869473  4581 solver.cpp:218] Iteration 93300 (7.02722 iter/s, 14.2304s/100 iters), loss = 0.000479341
I0928 17:39:00.869514  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00047915 (* 1 = 0.00047915 loss)
I0928 17:39:00.869521  4581 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I0928 17:39:15.094956  4581 solver.cpp:218] Iteration 93400 (7.02968 iter/s, 14.2254s/100 iters), loss = 0.00158726
I0928 17:39:15.094987  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00158707 (* 1 = 0.00158707 loss)
I0928 17:39:15.094993  4581 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I0928 17:39:28.617655  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:39:29.186467  4581 solver.cpp:330] Iteration 93500, Testing net (#0)
I0928 17:39:32.554466  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:39:32.696272  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9285
I0928 17:39:32.696310  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312033 (* 1 = 0.312033 loss)
I0928 17:39:32.837777  4581 solver.cpp:218] Iteration 93500 (5.63611 iter/s, 17.7427s/100 iters), loss = 0.00207292
I0928 17:39:32.837805  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00207273 (* 1 = 0.00207273 loss)
I0928 17:39:32.837813  4581 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I0928 17:39:47.071126  4581 solver.cpp:218] Iteration 93600 (7.02579 iter/s, 14.2333s/100 iters), loss = 0.000281043
I0928 17:39:47.071156  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000280852 (* 1 = 0.000280852 loss)
I0928 17:39:47.071162  4581 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I0928 17:40:01.312790  4581 solver.cpp:218] Iteration 93700 (7.02169 iter/s, 14.2416s/100 iters), loss = 0.000875455
I0928 17:40:01.312922  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000875265 (* 1 = 0.000875265 loss)
I0928 17:40:01.312930  4581 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I0928 17:40:15.550994  4581 solver.cpp:218] Iteration 93800 (7.02344 iter/s, 14.238s/100 iters), loss = 0.000723675
I0928 17:40:15.551034  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000723485 (* 1 = 0.000723485 loss)
I0928 17:40:15.551040  4581 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I0928 17:40:29.788821  4581 solver.cpp:218] Iteration 93900 (7.02358 iter/s, 14.2377s/100 iters), loss = 0.000845603
I0928 17:40:29.788862  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000845414 (* 1 = 0.000845414 loss)
I0928 17:40:29.788869  4581 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I0928 17:40:43.318691  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:40:43.887910  4581 solver.cpp:330] Iteration 94000, Testing net (#0)
I0928 17:40:47.255777  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:40:47.396796  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9284
I0928 17:40:47.396832  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312891 (* 1 = 0.312891 loss)
I0928 17:40:47.537731  4581 solver.cpp:218] Iteration 94000 (5.63418 iter/s, 17.7488s/100 iters), loss = 0.00170847
I0928 17:40:47.537761  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00170828 (* 1 = 0.00170828 loss)
I0928 17:40:47.537781  4581 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I0928 17:41:01.759376  4581 solver.cpp:218] Iteration 94100 (7.03171 iter/s, 14.2213s/100 iters), loss = 0.000122499
I0928 17:41:01.759416  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000122309 (* 1 = 0.000122309 loss)
I0928 17:41:01.759423  4581 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I0928 17:41:15.987253  4581 solver.cpp:218] Iteration 94200 (7.0285 iter/s, 14.2278s/100 iters), loss = 0.00027513
I0928 17:41:15.987332  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00027494 (* 1 = 0.00027494 loss)
I0928 17:41:15.987347  4581 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I0928 17:41:30.208111  4581 solver.cpp:218] Iteration 94300 (7.03198 iter/s, 14.2207s/100 iters), loss = 0.000395984
I0928 17:41:30.208140  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000395795 (* 1 = 0.000395795 loss)
I0928 17:41:30.208147  4581 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I0928 17:41:44.433746  4581 solver.cpp:218] Iteration 94400 (7.0296 iter/s, 14.2256s/100 iters), loss = 0.000874243
I0928 17:41:44.433776  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000874053 (* 1 = 0.000874053 loss)
I0928 17:41:44.433782  4581 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I0928 17:41:57.952401  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:41:58.522012  4581 solver.cpp:330] Iteration 94500, Testing net (#0)
I0928 17:42:01.893126  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:42:02.034037  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9288
I0928 17:42:02.034072  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312713 (* 1 = 0.312713 loss)
I0928 17:42:02.175808  4581 solver.cpp:218] Iteration 94500 (5.63635 iter/s, 17.742s/100 iters), loss = 0.00173548
I0928 17:42:02.175838  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00173529 (* 1 = 0.00173529 loss)
I0928 17:42:02.175845  4581 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I0928 17:42:16.405447  4581 solver.cpp:218] Iteration 94600 (7.02762 iter/s, 14.2296s/100 iters), loss = 0.000401029
I0928 17:42:16.405488  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00040084 (* 1 = 0.00040084 loss)
I0928 17:42:16.405493  4581 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I0928 17:42:30.641549  4581 solver.cpp:218] Iteration 94700 (7.02443 iter/s, 14.236s/100 iters), loss = 0.000588155
I0928 17:42:30.641674  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000587966 (* 1 = 0.000587966 loss)
I0928 17:42:30.641681  4581 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I0928 17:42:44.869737  4581 solver.cpp:218] Iteration 94800 (7.02838 iter/s, 14.228s/100 iters), loss = 0.000560516
I0928 17:42:44.869777  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000560326 (* 1 = 0.000560326 loss)
I0928 17:42:44.869783  4581 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I0928 17:42:59.103561  4581 solver.cpp:218] Iteration 94900 (7.02556 iter/s, 14.2337s/100 iters), loss = 0.000584923
I0928 17:42:59.103602  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000584734 (* 1 = 0.000584734 loss)
I0928 17:42:59.103608  4581 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I0928 17:43:12.627037  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:43:13.196960  4581 solver.cpp:330] Iteration 95000, Testing net (#0)
I0928 17:43:16.566004  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:43:16.706953  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9287
I0928 17:43:16.706987  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311901 (* 1 = 0.311901 loss)
I0928 17:43:16.848815  4581 solver.cpp:218] Iteration 95000 (5.63534 iter/s, 17.7452s/100 iters), loss = 0.000893934
I0928 17:43:16.848845  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000893745 (* 1 = 0.000893745 loss)
I0928 17:43:16.848851  4581 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I0928 17:43:31.074332  4581 solver.cpp:218] Iteration 95100 (7.02966 iter/s, 14.2254s/100 iters), loss = 0.000583021
I0928 17:43:31.074373  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000582832 (* 1 = 0.000582832 loss)
I0928 17:43:31.074378  4581 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I0928 17:43:45.310592  4581 solver.cpp:218] Iteration 95200 (7.02436 iter/s, 14.2362s/100 iters), loss = 0.000277477
I0928 17:43:45.310643  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000277288 (* 1 = 0.000277288 loss)
I0928 17:43:45.310650  4581 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I0928 17:43:59.536487  4581 solver.cpp:218] Iteration 95300 (7.02948 iter/s, 14.2258s/100 iters), loss = 0.000250486
I0928 17:43:59.536530  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000250297 (* 1 = 0.000250297 loss)
I0928 17:43:59.536535  4581 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I0928 17:44:13.768348  4581 solver.cpp:218] Iteration 95400 (7.02653 iter/s, 14.2318s/100 iters), loss = 0.000256491
I0928 17:44:13.768389  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000256302 (* 1 = 0.000256302 loss)
I0928 17:44:13.768395  4581 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I0928 17:44:27.290010  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:44:27.860146  4581 solver.cpp:330] Iteration 95500, Testing net (#0)
I0928 17:44:31.230121  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:44:31.370677  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9293
I0928 17:44:31.370713  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312241 (* 1 = 0.312241 loss)
I0928 17:44:31.512998  4581 solver.cpp:218] Iteration 95500 (5.63553 iter/s, 17.7446s/100 iters), loss = 0.000755306
I0928 17:44:31.513027  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000755117 (* 1 = 0.000755117 loss)
I0928 17:44:31.513034  4581 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I0928 17:44:45.739435  4581 solver.cpp:218] Iteration 95600 (7.0292 iter/s, 14.2264s/100 iters), loss = 0.000774207
I0928 17:44:45.739475  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000774017 (* 1 = 0.000774017 loss)
I0928 17:44:45.739481  4581 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I0928 17:44:59.967115  4581 solver.cpp:218] Iteration 95700 (7.02859 iter/s, 14.2276s/100 iters), loss = 0.000168748
I0928 17:44:59.967218  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000168558 (* 1 = 0.000168558 loss)
I0928 17:44:59.967226  4581 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I0928 17:45:14.201876  4581 solver.cpp:218] Iteration 95800 (7.02513 iter/s, 14.2346s/100 iters), loss = 0.00488354
I0928 17:45:14.201905  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00488334 (* 1 = 0.00488334 loss)
I0928 17:45:14.201912  4581 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I0928 17:45:28.432288  4581 solver.cpp:218] Iteration 95900 (7.02724 iter/s, 14.2303s/100 iters), loss = 0.000579307
I0928 17:45:28.432329  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000579115 (* 1 = 0.000579115 loss)
I0928 17:45:28.432335  4581 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I0928 17:45:41.954965  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:45:42.523198  4581 solver.cpp:330] Iteration 96000, Testing net (#0)
I0928 17:45:45.894592  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:45:46.035606  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9289
I0928 17:45:46.035642  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312561 (* 1 = 0.312561 loss)
I0928 17:45:46.177758  4581 solver.cpp:218] Iteration 96000 (5.63527 iter/s, 17.7454s/100 iters), loss = 0.000847585
I0928 17:45:46.177788  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000847392 (* 1 = 0.000847392 loss)
I0928 17:45:46.177793  4581 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I0928 17:46:00.410794  4581 solver.cpp:218] Iteration 96100 (7.02594 iter/s, 14.233s/100 iters), loss = 0.000529217
I0928 17:46:00.410835  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000529025 (* 1 = 0.000529025 loss)
I0928 17:46:00.410841  4581 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I0928 17:46:14.640465  4581 solver.cpp:218] Iteration 96200 (7.02761 iter/s, 14.2296s/100 iters), loss = 0.000510419
I0928 17:46:14.640592  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000510228 (* 1 = 0.000510228 loss)
I0928 17:46:14.640600  4581 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I0928 17:46:28.876747  4581 solver.cpp:218] Iteration 96300 (7.02439 iter/s, 14.2361s/100 iters), loss = 0.000212483
I0928 17:46:28.876790  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000212292 (* 1 = 0.000212292 loss)
I0928 17:46:28.876796  4581 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I0928 17:46:43.106981  4581 solver.cpp:218] Iteration 96400 (7.02733 iter/s, 14.2302s/100 iters), loss = 0.000296442
I0928 17:46:43.107022  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000296251 (* 1 = 0.000296251 loss)
I0928 17:46:43.107028  4581 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I0928 17:46:56.631964  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:46:57.201485  4581 solver.cpp:330] Iteration 96500, Testing net (#0)
I0928 17:47:00.572129  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:47:00.712817  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.929
I0928 17:47:00.712852  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312831 (* 1 = 0.312831 loss)
I0928 17:47:00.855000  4581 solver.cpp:218] Iteration 96500 (5.63446 iter/s, 17.7479s/100 iters), loss = 0.000556122
I0928 17:47:00.855029  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000555931 (* 1 = 0.000555931 loss)
I0928 17:47:00.855036  4581 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I0928 17:47:15.075052  4581 solver.cpp:218] Iteration 96600 (7.03236 iter/s, 14.22s/100 iters), loss = 0.000592186
I0928 17:47:15.075079  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000591994 (* 1 = 0.000591994 loss)
I0928 17:47:15.075085  4581 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I0928 17:47:29.306493  4581 solver.cpp:218] Iteration 96700 (7.02673 iter/s, 14.2314s/100 iters), loss = 0.000548795
I0928 17:47:29.306644  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000548604 (* 1 = 0.000548604 loss)
I0928 17:47:29.306663  4581 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I0928 17:47:43.538215  4581 solver.cpp:218] Iteration 96800 (7.02665 iter/s, 14.2315s/100 iters), loss = 0.000541747
I0928 17:47:43.538256  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000541556 (* 1 = 0.000541556 loss)
I0928 17:47:43.538264  4581 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I0928 17:47:57.767652  4581 solver.cpp:218] Iteration 96900 (7.02773 iter/s, 14.2294s/100 iters), loss = 0.000242753
I0928 17:47:57.767691  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000242562 (* 1 = 0.000242562 loss)
I0928 17:47:57.767698  4581 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I0928 17:48:11.284509  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:48:11.853853  4581 solver.cpp:330] Iteration 97000, Testing net (#0)
I0928 17:48:15.223812  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:48:15.364615  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9286
I0928 17:48:15.364652  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312347 (* 1 = 0.312347 loss)
I0928 17:48:15.505779  4581 solver.cpp:218] Iteration 97000 (5.6376 iter/s, 17.738s/100 iters), loss = 0.000983209
I0928 17:48:15.505808  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000983018 (* 1 = 0.000983018 loss)
I0928 17:48:15.505815  4581 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I0928 17:48:29.737303  4581 solver.cpp:218] Iteration 97100 (7.02669 iter/s, 14.2315s/100 iters), loss = 0.000550934
I0928 17:48:29.737344  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000550743 (* 1 = 0.000550743 loss)
I0928 17:48:29.737350  4581 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I0928 17:48:43.967505  4581 solver.cpp:218] Iteration 97200 (7.02735 iter/s, 14.2301s/100 iters), loss = 0.00166908
I0928 17:48:43.967633  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00166889 (* 1 = 0.00166889 loss)
I0928 17:48:43.967640  4581 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I0928 17:48:58.200772  4581 solver.cpp:218] Iteration 97300 (7.02587 iter/s, 14.2331s/100 iters), loss = 0.000502839
I0928 17:48:58.200812  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000502647 (* 1 = 0.000502647 loss)
I0928 17:48:58.200819  4581 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I0928 17:49:12.432999  4581 solver.cpp:218] Iteration 97400 (7.02635 iter/s, 14.2321s/100 iters), loss = 0.000785394
I0928 17:49:12.433040  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000785203 (* 1 = 0.000785203 loss)
I0928 17:49:12.433046  4581 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I0928 17:49:25.959133  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:49:26.527835  4581 solver.cpp:330] Iteration 97500, Testing net (#0)
I0928 17:49:29.899263  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:49:30.040143  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.929
I0928 17:49:30.040179  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311453 (* 1 = 0.311453 loss)
I0928 17:49:30.181839  4581 solver.cpp:218] Iteration 97500 (5.6342 iter/s, 17.7488s/100 iters), loss = 0.000896046
I0928 17:49:30.181867  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000895854 (* 1 = 0.000895854 loss)
I0928 17:49:30.181874  4581 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I0928 17:49:44.410729  4581 solver.cpp:218] Iteration 97600 (7.02799 iter/s, 14.2288s/100 iters), loss = 0.000874687
I0928 17:49:44.410759  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000874495 (* 1 = 0.000874495 loss)
I0928 17:49:44.410765  4581 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I0928 17:49:58.645767  4581 solver.cpp:218] Iteration 97700 (7.02495 iter/s, 14.235s/100 iters), loss = 0.000419943
I0928 17:49:58.645874  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000419751 (* 1 = 0.000419751 loss)
I0928 17:49:58.645890  4581 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I0928 17:50:12.875885  4581 solver.cpp:218] Iteration 97800 (7.02742 iter/s, 14.23s/100 iters), loss = 0.000393627
I0928 17:50:12.875927  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000393434 (* 1 = 0.000393434 loss)
I0928 17:50:12.875934  4581 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I0928 17:50:27.106969  4581 solver.cpp:218] Iteration 97900 (7.02691 iter/s, 14.231s/100 iters), loss = 0.000768065
I0928 17:50:27.107009  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000767872 (* 1 = 0.000767872 loss)
I0928 17:50:27.107015  4581 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I0928 17:50:40.627661  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:50:41.196633  4581 solver.cpp:330] Iteration 98000, Testing net (#0)
I0928 17:50:44.568168  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:50:44.708953  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9286
I0928 17:50:44.708989  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312365 (* 1 = 0.312365 loss)
I0928 17:50:44.850747  4581 solver.cpp:218] Iteration 98000 (5.63581 iter/s, 17.7437s/100 iters), loss = 0.000947639
I0928 17:50:44.850775  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000947446 (* 1 = 0.000947446 loss)
I0928 17:50:44.850782  4581 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I0928 17:50:59.079219  4581 solver.cpp:218] Iteration 98100 (7.0282 iter/s, 14.2284s/100 iters), loss = 0.00122507
I0928 17:50:59.079258  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00122487 (* 1 = 0.00122487 loss)
I0928 17:50:59.079264  4581 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I0928 17:51:13.300499  4581 solver.cpp:218] Iteration 98200 (7.03175 iter/s, 14.2212s/100 iters), loss = 0.000538327
I0928 17:51:13.300577  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000538134 (* 1 = 0.000538134 loss)
I0928 17:51:13.300595  4581 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I0928 17:51:27.530328  4581 solver.cpp:218] Iteration 98300 (7.02755 iter/s, 14.2297s/100 iters), loss = 0.000729673
I0928 17:51:27.530359  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00072948 (* 1 = 0.00072948 loss)
I0928 17:51:27.530365  4581 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I0928 17:51:41.758999  4581 solver.cpp:218] Iteration 98400 (7.0281 iter/s, 14.2286s/100 iters), loss = 0.00159132
I0928 17:51:41.759040  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00159113 (* 1 = 0.00159113 loss)
I0928 17:51:41.759047  4581 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I0928 17:51:55.282711  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:51:55.852563  4581 solver.cpp:330] Iteration 98500, Testing net (#0)
I0928 17:51:59.223850  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:51:59.364867  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9286
I0928 17:51:59.364904  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31195 (* 1 = 0.31195 loss)
I0928 17:51:59.506147  4581 solver.cpp:218] Iteration 98500 (5.63474 iter/s, 17.7471s/100 iters), loss = 0.00143879
I0928 17:51:59.506176  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0014386 (* 1 = 0.0014386 loss)
I0928 17:51:59.506183  4581 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I0928 17:52:13.733464  4581 solver.cpp:218] Iteration 98600 (7.02877 iter/s, 14.2272s/100 iters), loss = 0.000477626
I0928 17:52:13.733495  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000477433 (* 1 = 0.000477433 loss)
I0928 17:52:13.733502  4581 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I0928 17:52:27.958905  4581 solver.cpp:218] Iteration 98700 (7.02969 iter/s, 14.2254s/100 iters), loss = 0.000340646
I0928 17:52:27.959005  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000340454 (* 1 = 0.000340454 loss)
I0928 17:52:27.959022  4581 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I0928 17:52:42.184746  4581 solver.cpp:218] Iteration 98800 (7.02953 iter/s, 14.2257s/100 iters), loss = 0.000436062
I0928 17:52:42.184774  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00043587 (* 1 = 0.00043587 loss)
I0928 17:52:42.184780  4581 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I0928 17:52:56.417913  4581 solver.cpp:218] Iteration 98900 (7.02588 iter/s, 14.2331s/100 iters), loss = 0.000903744
I0928 17:52:56.417943  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000903551 (* 1 = 0.000903551 loss)
I0928 17:52:56.417948  4581 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I0928 17:53:09.939290  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:53:10.508713  4581 solver.cpp:330] Iteration 99000, Testing net (#0)
I0928 17:53:13.878342  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:53:14.019117  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9287
I0928 17:53:14.019153  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.3122 (* 1 = 0.3122 loss)
I0928 17:53:14.161183  4581 solver.cpp:218] Iteration 99000 (5.63596 iter/s, 17.7432s/100 iters), loss = 0.00147129
I0928 17:53:14.161212  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0014711 (* 1 = 0.0014711 loss)
I0928 17:53:14.161219  4581 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I0928 17:53:28.378803  4581 solver.cpp:218] Iteration 99100 (7.03356 iter/s, 14.2176s/100 iters), loss = 0.000977035
I0928 17:53:28.378845  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000976844 (* 1 = 0.000976844 loss)
I0928 17:53:28.378851  4581 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I0928 17:53:42.604233  4581 solver.cpp:218] Iteration 99200 (7.02971 iter/s, 14.2253s/100 iters), loss = 0.000231499
I0928 17:53:42.604292  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000231308 (* 1 = 0.000231308 loss)
I0928 17:53:42.604300  4581 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I0928 17:53:56.829991  4581 solver.cpp:218] Iteration 99300 (7.02955 iter/s, 14.2257s/100 iters), loss = 0.000324115
I0928 17:53:56.830034  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000323924 (* 1 = 0.000323924 loss)
I0928 17:53:56.830039  4581 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I0928 17:54:11.053388  4581 solver.cpp:218] Iteration 99400 (7.03071 iter/s, 14.2233s/100 iters), loss = 0.000472892
I0928 17:54:11.053429  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0004727 (* 1 = 0.0004727 loss)
I0928 17:54:11.053436  4581 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I0928 17:54:24.567275  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:54:25.136984  4581 solver.cpp:330] Iteration 99500, Testing net (#0)
I0928 17:54:28.508285  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:54:28.649282  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9283
I0928 17:54:28.649319  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313334 (* 1 = 0.313334 loss)
I0928 17:54:28.790694  4581 solver.cpp:218] Iteration 99500 (5.63786 iter/s, 17.7372s/100 iters), loss = 0.00104541
I0928 17:54:28.790722  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00104522 (* 1 = 0.00104522 loss)
I0928 17:54:28.790729  4581 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I0928 17:54:43.018251  4581 solver.cpp:218] Iteration 99600 (7.02865 iter/s, 14.2275s/100 iters), loss = 0.000416983
I0928 17:54:43.018282  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00041679 (* 1 = 0.00041679 loss)
I0928 17:54:43.018288  4581 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I0928 17:54:57.251145  4581 solver.cpp:218] Iteration 99700 (7.02601 iter/s, 14.2328s/100 iters), loss = 0.000655168
I0928 17:54:57.251224  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000654976 (* 1 = 0.000654976 loss)
I0928 17:54:57.251241  4581 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I0928 17:55:11.480517  4581 solver.cpp:218] Iteration 99800 (7.02777 iter/s, 14.2293s/100 iters), loss = 0.000554093
I0928 17:55:11.480547  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000553901 (* 1 = 0.000553901 loss)
I0928 17:55:11.480563  4581 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I0928 17:55:25.717294  4581 solver.cpp:218] Iteration 99900 (7.0241 iter/s, 14.2367s/100 iters), loss = 0.00144756
I0928 17:55:25.717324  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00144737 (* 1 = 0.00144737 loss)
I0928 17:55:25.717329  4581 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I0928 17:55:39.246492  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:55:39.816185  4581 solver.cpp:330] Iteration 100000, Testing net (#0)
I0928 17:55:43.185663  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:55:43.326731  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9289
I0928 17:55:43.326772  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311879 (* 1 = 0.311879 loss)
I0928 17:55:43.468766  4581 solver.cpp:218] Iteration 100000 (5.63336 iter/s, 17.7514s/100 iters), loss = 0.000659296
I0928 17:55:43.468796  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000659105 (* 1 = 0.000659105 loss)
I0928 17:55:43.468801  4581 sgd_solver.cpp:46] MultiStep Status: Iteration 100000, step = 3
I0928 17:55:43.468804  4581 sgd_solver.cpp:105] Iteration 100000, lr = 0.0001
I0928 17:55:57.696017  4581 solver.cpp:218] Iteration 100100 (7.0288 iter/s, 14.2272s/100 iters), loss = 0.000294519
I0928 17:55:57.696056  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000294327 (* 1 = 0.000294327 loss)
I0928 17:55:57.696063  4581 sgd_solver.cpp:105] Iteration 100100, lr = 0.0001
I0928 17:56:11.926342  4581 solver.cpp:218] Iteration 100200 (7.02729 iter/s, 14.2302s/100 iters), loss = 0.000218293
I0928 17:56:11.926424  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000218101 (* 1 = 0.000218101 loss)
I0928 17:56:11.926441  4581 sgd_solver.cpp:105] Iteration 100200, lr = 0.0001
I0928 17:56:26.155812  4581 solver.cpp:218] Iteration 100300 (7.02773 iter/s, 14.2294s/100 iters), loss = 0.000588969
I0928 17:56:26.155843  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000588778 (* 1 = 0.000588778 loss)
I0928 17:56:26.155848  4581 sgd_solver.cpp:105] Iteration 100300, lr = 0.0001
I0928 17:56:40.382768  4581 solver.cpp:218] Iteration 100400 (7.02895 iter/s, 14.2269s/100 iters), loss = 0.000781861
I0928 17:56:40.382798  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000781669 (* 1 = 0.000781669 loss)
I0928 17:56:40.382804  4581 sgd_solver.cpp:105] Iteration 100400, lr = 0.0001
I0928 17:56:53.901055  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:56:54.472126  4581 solver.cpp:330] Iteration 100500, Testing net (#0)
I0928 17:56:57.841253  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:56:57.982444  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9287
I0928 17:56:57.982480  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311761 (* 1 = 0.311761 loss)
I0928 17:56:58.124655  4581 solver.cpp:218] Iteration 100500 (5.6364 iter/s, 17.7418s/100 iters), loss = 0.000919336
I0928 17:56:58.124682  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000919143 (* 1 = 0.000919143 loss)
I0928 17:56:58.124691  4581 sgd_solver.cpp:105] Iteration 100500, lr = 0.0001
I0928 17:57:12.352167  4581 solver.cpp:218] Iteration 100600 (7.02867 iter/s, 14.2274s/100 iters), loss = 0.00142638
I0928 17:57:12.352197  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00142618 (* 1 = 0.00142618 loss)
I0928 17:57:12.352203  4581 sgd_solver.cpp:105] Iteration 100600, lr = 0.0001
I0928 17:57:26.583086  4581 solver.cpp:218] Iteration 100700 (7.02699 iter/s, 14.2309s/100 iters), loss = 0.000483456
I0928 17:57:26.583257  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000483263 (* 1 = 0.000483263 loss)
I0928 17:57:26.583276  4581 sgd_solver.cpp:105] Iteration 100700, lr = 0.0001
I0928 17:57:40.816411  4581 solver.cpp:218] Iteration 100800 (7.02587 iter/s, 14.2331s/100 iters), loss = 0.000186659
I0928 17:57:40.816452  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000186466 (* 1 = 0.000186466 loss)
I0928 17:57:40.816458  4581 sgd_solver.cpp:105] Iteration 100800, lr = 0.0001
I0928 17:57:55.043618  4581 solver.cpp:218] Iteration 100900 (7.02882 iter/s, 14.2271s/100 iters), loss = 0.000479194
I0928 17:57:55.043649  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000479001 (* 1 = 0.000479001 loss)
I0928 17:57:55.043656  4581 sgd_solver.cpp:105] Iteration 100900, lr = 0.0001
I0928 17:58:08.557086  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:58:09.125798  4581 solver.cpp:330] Iteration 101000, Testing net (#0)
I0928 17:58:12.497858  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:58:12.638818  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9286
I0928 17:58:12.638854  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311881 (* 1 = 0.311881 loss)
I0928 17:58:12.781025  4581 solver.cpp:218] Iteration 101000 (5.63783 iter/s, 17.7373s/100 iters), loss = 0.00117344
I0928 17:58:12.781054  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00117324 (* 1 = 0.00117324 loss)
I0928 17:58:12.781060  4581 sgd_solver.cpp:105] Iteration 101000, lr = 0.0001
I0928 17:58:27.006239  4581 solver.cpp:218] Iteration 101100 (7.02981 iter/s, 14.2251s/100 iters), loss = 0.000709813
I0928 17:58:27.006280  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00070962 (* 1 = 0.00070962 loss)
I0928 17:58:27.006286  4581 sgd_solver.cpp:105] Iteration 101100, lr = 0.0001
I0928 17:58:41.236382  4581 solver.cpp:218] Iteration 101200 (7.02738 iter/s, 14.2301s/100 iters), loss = 0.00100154
I0928 17:58:41.236513  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100135 (* 1 = 0.00100135 loss)
I0928 17:58:41.236522  4581 sgd_solver.cpp:105] Iteration 101200, lr = 0.0001
I0928 17:58:55.465153  4581 solver.cpp:218] Iteration 101300 (7.02809 iter/s, 14.2286s/100 iters), loss = 0.000330676
I0928 17:58:55.465184  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000330483 (* 1 = 0.000330483 loss)
I0928 17:58:55.465190  4581 sgd_solver.cpp:105] Iteration 101300, lr = 0.0001
I0928 17:59:09.698354  4581 solver.cpp:218] Iteration 101400 (7.02586 iter/s, 14.2331s/100 iters), loss = 0.000451187
I0928 17:59:09.698385  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000450995 (* 1 = 0.000450995 loss)
I0928 17:59:09.698391  4581 sgd_solver.cpp:105] Iteration 101400, lr = 0.0001
I0928 17:59:23.218489  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:59:23.787804  4581 solver.cpp:330] Iteration 101500, Testing net (#0)
I0928 17:59:27.159121  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 17:59:27.300091  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9286
I0928 17:59:27.300127  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312007 (* 1 = 0.312007 loss)
I0928 17:59:27.442160  4581 solver.cpp:218] Iteration 101500 (5.6358 iter/s, 17.7437s/100 iters), loss = 0.00132301
I0928 17:59:27.442189  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00132282 (* 1 = 0.00132282 loss)
I0928 17:59:27.442198  4581 sgd_solver.cpp:105] Iteration 101500, lr = 0.0001
I0928 17:59:41.660650  4581 solver.cpp:218] Iteration 101600 (7.03313 iter/s, 14.2184s/100 iters), loss = 0.00125521
I0928 17:59:41.660691  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00125502 (* 1 = 0.00125502 loss)
I0928 17:59:41.660697  4581 sgd_solver.cpp:105] Iteration 101600, lr = 0.0001
I0928 17:59:55.885145  4581 solver.cpp:218] Iteration 101700 (7.03016 iter/s, 14.2244s/100 iters), loss = 0.000828497
I0928 17:59:55.885298  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000828305 (* 1 = 0.000828305 loss)
I0928 17:59:55.885305  4581 sgd_solver.cpp:105] Iteration 101700, lr = 0.0001
I0928 18:00:10.107722  4581 solver.cpp:218] Iteration 101800 (7.03116 iter/s, 14.2224s/100 iters), loss = 0.00105866
I0928 18:00:10.107751  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00105847 (* 1 = 0.00105847 loss)
I0928 18:00:10.107767  4581 sgd_solver.cpp:105] Iteration 101800, lr = 0.0001
I0928 18:00:24.331826  4581 solver.cpp:218] Iteration 101900 (7.03035 iter/s, 14.224s/100 iters), loss = 0.000649267
I0928 18:00:24.331856  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000649077 (* 1 = 0.000649077 loss)
I0928 18:00:24.331864  4581 sgd_solver.cpp:105] Iteration 101900, lr = 0.0001
I0928 18:00:37.853847  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:00:38.422915  4581 solver.cpp:330] Iteration 102000, Testing net (#0)
I0928 18:00:41.793704  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:00:41.934660  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9285
I0928 18:00:41.934696  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31192 (* 1 = 0.31192 loss)
I0928 18:00:42.076503  4581 solver.cpp:218] Iteration 102000 (5.63552 iter/s, 17.7446s/100 iters), loss = 0.000938187
I0928 18:00:42.076532  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000937995 (* 1 = 0.000937995 loss)
I0928 18:00:42.076540  4581 sgd_solver.cpp:105] Iteration 102000, lr = 0.0001
I0928 18:00:56.303973  4581 solver.cpp:218] Iteration 102100 (7.0287 iter/s, 14.2274s/100 iters), loss = 0.00163463
I0928 18:00:56.304003  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00163444 (* 1 = 0.00163444 loss)
I0928 18:00:56.304010  4581 sgd_solver.cpp:105] Iteration 102100, lr = 0.0001
I0928 18:01:10.533251  4581 solver.cpp:218] Iteration 102200 (7.0278 iter/s, 14.2292s/100 iters), loss = 0.000731874
I0928 18:01:10.533382  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000731682 (* 1 = 0.000731682 loss)
I0928 18:01:10.533390  4581 sgd_solver.cpp:105] Iteration 102200, lr = 0.0001
I0928 18:01:24.765413  4581 solver.cpp:218] Iteration 102300 (7.02642 iter/s, 14.232s/100 iters), loss = 0.000747056
I0928 18:01:24.765442  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000746864 (* 1 = 0.000746864 loss)
I0928 18:01:24.765460  4581 sgd_solver.cpp:105] Iteration 102300, lr = 0.0001
I0928 18:01:38.995277  4581 solver.cpp:218] Iteration 102400 (7.02751 iter/s, 14.2298s/100 iters), loss = 0.000473763
I0928 18:01:38.995308  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000473571 (* 1 = 0.000473571 loss)
I0928 18:01:38.995316  4581 sgd_solver.cpp:105] Iteration 102400, lr = 0.0001
I0928 18:01:52.520880  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:01:53.090770  4581 solver.cpp:330] Iteration 102500, Testing net (#0)
I0928 18:01:56.462446  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:01:56.603852  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9281
I0928 18:01:56.603888  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31203 (* 1 = 0.31203 loss)
I0928 18:01:56.745973  4581 solver.cpp:218] Iteration 102500 (5.63361 iter/s, 17.7506s/100 iters), loss = 0.00225228
I0928 18:01:56.746006  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00225209 (* 1 = 0.00225209 loss)
I0928 18:01:56.746016  4581 sgd_solver.cpp:105] Iteration 102500, lr = 0.0001
I0928 18:02:10.972834  4581 solver.cpp:218] Iteration 102600 (7.02899 iter/s, 14.2268s/100 iters), loss = 0.00124404
I0928 18:02:10.972864  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00124385 (* 1 = 0.00124385 loss)
I0928 18:02:10.972870  4581 sgd_solver.cpp:105] Iteration 102600, lr = 0.0001
I0928 18:02:25.203339  4581 solver.cpp:218] Iteration 102700 (7.02719 iter/s, 14.2304s/100 iters), loss = 0.000772367
I0928 18:02:25.203425  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000772175 (* 1 = 0.000772175 loss)
I0928 18:02:25.203433  4581 sgd_solver.cpp:105] Iteration 102700, lr = 0.0001
I0928 18:02:39.433008  4581 solver.cpp:218] Iteration 102800 (7.02763 iter/s, 14.2295s/100 iters), loss = 0.00172033
I0928 18:02:39.433049  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00172014 (* 1 = 0.00172014 loss)
I0928 18:02:39.433056  4581 sgd_solver.cpp:105] Iteration 102800, lr = 0.0001
I0928 18:02:53.663229  4581 solver.cpp:218] Iteration 102900 (7.02734 iter/s, 14.2301s/100 iters), loss = 0.002033
I0928 18:02:53.663259  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00203281 (* 1 = 0.00203281 loss)
I0928 18:02:53.663265  4581 sgd_solver.cpp:105] Iteration 102900, lr = 0.0001
I0928 18:03:07.184811  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:03:07.754734  4581 solver.cpp:330] Iteration 103000, Testing net (#0)
I0928 18:03:11.122920  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:03:11.263538  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9282
I0928 18:03:11.263563  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312033 (* 1 = 0.312033 loss)
I0928 18:03:11.405279  4581 solver.cpp:218] Iteration 103000 (5.63635 iter/s, 17.742s/100 iters), loss = 0.000874048
I0928 18:03:11.405309  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000873855 (* 1 = 0.000873855 loss)
I0928 18:03:11.405316  4581 sgd_solver.cpp:105] Iteration 103000, lr = 0.0001
I0928 18:03:25.631981  4581 solver.cpp:218] Iteration 103100 (7.02907 iter/s, 14.2266s/100 iters), loss = 0.000886559
I0928 18:03:25.632022  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000886367 (* 1 = 0.000886367 loss)
I0928 18:03:25.632028  4581 sgd_solver.cpp:105] Iteration 103100, lr = 0.0001
I0928 18:03:39.856367  4581 solver.cpp:218] Iteration 103200 (7.03022 iter/s, 14.2243s/100 iters), loss = 0.0031257
I0928 18:03:39.856487  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00312551 (* 1 = 0.00312551 loss)
I0928 18:03:39.856494  4581 sgd_solver.cpp:105] Iteration 103200, lr = 0.0001
I0928 18:03:54.083325  4581 solver.cpp:218] Iteration 103300 (7.02899 iter/s, 14.2268s/100 iters), loss = 0.00187381
I0928 18:03:54.083366  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00187362 (* 1 = 0.00187362 loss)
I0928 18:03:54.083372  4581 sgd_solver.cpp:105] Iteration 103300, lr = 0.0001
I0928 18:04:08.310125  4581 solver.cpp:218] Iteration 103400 (7.02903 iter/s, 14.2267s/100 iters), loss = 0.00320775
I0928 18:04:08.310165  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00320755 (* 1 = 0.00320755 loss)
I0928 18:04:08.310171  4581 sgd_solver.cpp:105] Iteration 103400, lr = 0.0001
I0928 18:04:21.830998  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:04:22.399967  4581 solver.cpp:330] Iteration 103500, Testing net (#0)
I0928 18:04:25.770309  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:04:25.911698  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9282
I0928 18:04:25.911734  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312013 (* 1 = 0.312013 loss)
I0928 18:04:26.053386  4581 solver.cpp:218] Iteration 103500 (5.63597 iter/s, 17.7432s/100 iters), loss = 0.000339347
I0928 18:04:26.053414  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000339154 (* 1 = 0.000339154 loss)
I0928 18:04:26.053421  4581 sgd_solver.cpp:105] Iteration 103500, lr = 0.0001
I0928 18:04:40.276876  4581 solver.cpp:218] Iteration 103600 (7.03066 iter/s, 14.2234s/100 iters), loss = 0.000696529
I0928 18:04:40.276906  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000696337 (* 1 = 0.000696337 loss)
I0928 18:04:40.276912  4581 sgd_solver.cpp:105] Iteration 103600, lr = 0.0001
I0928 18:04:54.503653  4581 solver.cpp:218] Iteration 103700 (7.02903 iter/s, 14.2267s/100 iters), loss = 0.000295345
I0928 18:04:54.503798  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000295152 (* 1 = 0.000295152 loss)
I0928 18:04:54.503814  4581 sgd_solver.cpp:105] Iteration 103700, lr = 0.0001
I0928 18:05:08.737020  4581 solver.cpp:218] Iteration 103800 (7.02583 iter/s, 14.2332s/100 iters), loss = 0.00100252
I0928 18:05:08.737051  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100232 (* 1 = 0.00100232 loss)
I0928 18:05:08.737056  4581 sgd_solver.cpp:105] Iteration 103800, lr = 0.0001
I0928 18:05:22.971174  4581 solver.cpp:218] Iteration 103900 (7.02539 iter/s, 14.2341s/100 iters), loss = 0.000261267
I0928 18:05:22.971202  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000261074 (* 1 = 0.000261074 loss)
I0928 18:05:22.971209  4581 sgd_solver.cpp:105] Iteration 103900, lr = 0.0001
I0928 18:05:36.494416  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:05:37.063063  4581 solver.cpp:330] Iteration 104000, Testing net (#0)
I0928 18:05:40.433379  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:05:40.574283  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9282
I0928 18:05:40.574321  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311966 (* 1 = 0.311966 loss)
I0928 18:05:40.716114  4581 solver.cpp:218] Iteration 104000 (5.63543 iter/s, 17.7449s/100 iters), loss = 0.000613142
I0928 18:05:40.716143  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000612948 (* 1 = 0.000612948 loss)
I0928 18:05:40.716150  4581 sgd_solver.cpp:105] Iteration 104000, lr = 0.0001
I0928 18:05:54.934437  4581 solver.cpp:218] Iteration 104100 (7.03321 iter/s, 14.2183s/100 iters), loss = 0.00125466
I0928 18:05:54.934478  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00125446 (* 1 = 0.00125446 loss)
I0928 18:05:54.934484  4581 sgd_solver.cpp:105] Iteration 104100, lr = 0.0001
I0928 18:06:09.216111  4581 solver.cpp:218] Iteration 104200 (7.00202 iter/s, 14.2816s/100 iters), loss = 0.0113682
I0928 18:06:09.216243  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011368 (* 1 = 0.011368 loss)
I0928 18:06:09.216253  4581 sgd_solver.cpp:105] Iteration 104200, lr = 0.0001
I0928 18:06:23.566114  4581 solver.cpp:218] Iteration 104300 (6.96872 iter/s, 14.3498s/100 iters), loss = 0.00176279
I0928 18:06:23.566148  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00176259 (* 1 = 0.00176259 loss)
I0928 18:06:23.566155  4581 sgd_solver.cpp:105] Iteration 104300, lr = 0.0001
I0928 18:06:37.817769  4581 solver.cpp:218] Iteration 104400 (7.01677 iter/s, 14.2516s/100 iters), loss = 0.000395275
I0928 18:06:37.817809  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000395081 (* 1 = 0.000395081 loss)
I0928 18:06:37.817816  4581 sgd_solver.cpp:105] Iteration 104400, lr = 0.0001
I0928 18:06:51.334137  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:06:51.903482  4581 solver.cpp:330] Iteration 104500, Testing net (#0)
I0928 18:06:55.274157  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:06:55.415019  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9281
I0928 18:06:55.415053  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311999 (* 1 = 0.311999 loss)
I0928 18:06:55.557209  4581 solver.cpp:218] Iteration 104500 (5.63719 iter/s, 17.7393s/100 iters), loss = 0.000297577
I0928 18:06:55.557238  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000297382 (* 1 = 0.000297382 loss)
I0928 18:06:55.557246  4581 sgd_solver.cpp:105] Iteration 104500, lr = 0.0001
I0928 18:07:09.784941  4581 solver.cpp:218] Iteration 104600 (7.02856 iter/s, 14.2277s/100 iters), loss = 0.000976526
I0928 18:07:09.784983  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000976332 (* 1 = 0.000976332 loss)
I0928 18:07:09.784989  4581 sgd_solver.cpp:105] Iteration 104600, lr = 0.0001
I0928 18:07:24.013555  4581 solver.cpp:218] Iteration 104700 (7.02813 iter/s, 14.2285s/100 iters), loss = 0.000702768
I0928 18:07:24.013684  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000702574 (* 1 = 0.000702574 loss)
I0928 18:07:24.013702  4581 sgd_solver.cpp:105] Iteration 104700, lr = 0.0001
I0928 18:07:38.248265  4581 solver.cpp:218] Iteration 104800 (7.02516 iter/s, 14.2345s/100 iters), loss = 0.00300436
I0928 18:07:38.248313  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00300417 (* 1 = 0.00300417 loss)
I0928 18:07:38.248322  4581 sgd_solver.cpp:105] Iteration 104800, lr = 0.0001
I0928 18:07:52.482703  4581 solver.cpp:218] Iteration 104900 (7.02526 iter/s, 14.2344s/100 iters), loss = 0.000868525
I0928 18:07:52.482733  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000868331 (* 1 = 0.000868331 loss)
I0928 18:07:52.482739  4581 sgd_solver.cpp:105] Iteration 104900, lr = 0.0001
I0928 18:08:06.011194  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:08:06.579663  4581 solver.cpp:330] Iteration 105000, Testing net (#0)
I0928 18:08:09.948439  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:08:10.089413  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9282
I0928 18:08:10.089449  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312127 (* 1 = 0.312127 loss)
I0928 18:08:10.232342  4581 solver.cpp:218] Iteration 105000 (5.63394 iter/s, 17.7496s/100 iters), loss = 0.00145818
I0928 18:08:10.232372  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00145798 (* 1 = 0.00145798 loss)
I0928 18:08:10.232379  4581 sgd_solver.cpp:105] Iteration 105000, lr = 0.0001
I0928 18:08:24.458604  4581 solver.cpp:218] Iteration 105100 (7.02929 iter/s, 14.2262s/100 iters), loss = 0.000707269
I0928 18:08:24.458645  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000707075 (* 1 = 0.000707075 loss)
I0928 18:08:24.458652  4581 sgd_solver.cpp:105] Iteration 105100, lr = 0.0001
I0928 18:08:38.685775  4581 solver.cpp:218] Iteration 105200 (7.02885 iter/s, 14.2271s/100 iters), loss = 0.000653173
I0928 18:08:38.685852  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000652979 (* 1 = 0.000652979 loss)
I0928 18:08:38.685868  4581 sgd_solver.cpp:105] Iteration 105200, lr = 0.0001
I0928 18:08:52.916143  4581 solver.cpp:218] Iteration 105300 (7.02728 iter/s, 14.2303s/100 iters), loss = 0.0021977
I0928 18:08:52.916184  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00219751 (* 1 = 0.00219751 loss)
I0928 18:08:52.916190  4581 sgd_solver.cpp:105] Iteration 105300, lr = 0.0001
I0928 18:09:07.146867  4581 solver.cpp:218] Iteration 105400 (7.02709 iter/s, 14.2306s/100 iters), loss = 0.00113524
I0928 18:09:07.146908  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00113504 (* 1 = 0.00113504 loss)
I0928 18:09:07.146914  4581 sgd_solver.cpp:105] Iteration 105400, lr = 0.0001
I0928 18:09:20.669050  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:09:21.240100  4581 solver.cpp:330] Iteration 105500, Testing net (#0)
I0928 18:09:24.610195  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:09:24.751054  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9282
I0928 18:09:24.751090  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312094 (* 1 = 0.312094 loss)
I0928 18:09:24.892657  4581 solver.cpp:218] Iteration 105500 (5.63517 iter/s, 17.7457s/100 iters), loss = 0.000578649
I0928 18:09:24.892686  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000578454 (* 1 = 0.000578454 loss)
I0928 18:09:24.892693  4581 sgd_solver.cpp:105] Iteration 105500, lr = 0.0001
I0928 18:09:39.117501  4581 solver.cpp:218] Iteration 105600 (7.02999 iter/s, 14.2248s/100 iters), loss = 0.00119132
I0928 18:09:39.117542  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00119112 (* 1 = 0.00119112 loss)
I0928 18:09:39.117547  4581 sgd_solver.cpp:105] Iteration 105600, lr = 0.0001
I0928 18:09:53.346014  4581 solver.cpp:218] Iteration 105700 (7.02818 iter/s, 14.2284s/100 iters), loss = 0.000404157
I0928 18:09:53.346096  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000403963 (* 1 = 0.000403963 loss)
I0928 18:09:53.346103  4581 sgd_solver.cpp:105] Iteration 105700, lr = 0.0001
I0928 18:10:07.575448  4581 solver.cpp:218] Iteration 105800 (7.02775 iter/s, 14.2293s/100 iters), loss = 0.000567073
I0928 18:10:07.575489  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000566879 (* 1 = 0.000566879 loss)
I0928 18:10:07.575496  4581 sgd_solver.cpp:105] Iteration 105800, lr = 0.0001
I0928 18:10:21.803189  4581 solver.cpp:218] Iteration 105900 (7.02856 iter/s, 14.2277s/100 iters), loss = 0.00149087
I0928 18:10:21.803231  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00149068 (* 1 = 0.00149068 loss)
I0928 18:10:21.803238  4581 sgd_solver.cpp:105] Iteration 105900, lr = 0.0001
I0928 18:10:35.324724  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:10:35.895922  4581 solver.cpp:330] Iteration 106000, Testing net (#0)
I0928 18:10:39.264113  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:10:39.404562  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9282
I0928 18:10:39.404598  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312014 (* 1 = 0.312014 loss)
I0928 18:10:39.547116  4581 solver.cpp:218] Iteration 106000 (5.63576 iter/s, 17.7438s/100 iters), loss = 0.000476286
I0928 18:10:39.547144  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000476092 (* 1 = 0.000476092 loss)
I0928 18:10:39.547152  4581 sgd_solver.cpp:105] Iteration 106000, lr = 0.0001
I0928 18:10:53.774543  4581 solver.cpp:218] Iteration 106100 (7.02871 iter/s, 14.2274s/100 iters), loss = 0.000719596
I0928 18:10:53.774583  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000719402 (* 1 = 0.000719402 loss)
I0928 18:10:53.774590  4581 sgd_solver.cpp:105] Iteration 106100, lr = 0.0001
I0928 18:11:08.007443  4581 solver.cpp:218] Iteration 106200 (7.02601 iter/s, 14.2328s/100 iters), loss = 0.000963199
I0928 18:11:08.007557  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000963005 (* 1 = 0.000963005 loss)
I0928 18:11:08.007565  4581 sgd_solver.cpp:105] Iteration 106200, lr = 0.0001
I0928 18:11:22.238739  4581 solver.cpp:218] Iteration 106300 (7.02684 iter/s, 14.2312s/100 iters), loss = 0.000313445
I0928 18:11:22.238770  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000313251 (* 1 = 0.000313251 loss)
I0928 18:11:22.238775  4581 sgd_solver.cpp:105] Iteration 106300, lr = 0.0001
I0928 18:11:36.468590  4581 solver.cpp:218] Iteration 106400 (7.02751 iter/s, 14.2298s/100 iters), loss = 0.000745958
I0928 18:11:36.468628  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000745765 (* 1 = 0.000745765 loss)
I0928 18:11:36.468634  4581 sgd_solver.cpp:105] Iteration 106400, lr = 0.0001
I0928 18:11:49.989749  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:11:50.561619  4581 solver.cpp:330] Iteration 106500, Testing net (#0)
I0928 18:11:53.929860  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:11:54.070962  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9284
I0928 18:11:54.070986  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312097 (* 1 = 0.312097 loss)
I0928 18:11:54.213470  4581 solver.cpp:218] Iteration 106500 (5.63546 iter/s, 17.7448s/100 iters), loss = 0.00137186
I0928 18:11:54.213500  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00137166 (* 1 = 0.00137166 loss)
I0928 18:11:54.213508  4581 sgd_solver.cpp:105] Iteration 106500, lr = 0.0001
I0928 18:12:08.438032  4581 solver.cpp:218] Iteration 106600 (7.03013 iter/s, 14.2245s/100 iters), loss = 0.00356023
I0928 18:12:08.438062  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00356004 (* 1 = 0.00356004 loss)
I0928 18:12:08.438068  4581 sgd_solver.cpp:105] Iteration 106600, lr = 0.0001
I0928 18:12:22.666985  4581 solver.cpp:218] Iteration 106700 (7.02796 iter/s, 14.2289s/100 iters), loss = 0.00034485
I0928 18:12:22.667157  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000344657 (* 1 = 0.000344657 loss)
I0928 18:12:22.667165  4581 sgd_solver.cpp:105] Iteration 106700, lr = 0.0001
I0928 18:12:36.890020  4581 solver.cpp:218] Iteration 106800 (7.03095 iter/s, 14.2228s/100 iters), loss = 0.00107297
I0928 18:12:36.890060  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00107277 (* 1 = 0.00107277 loss)
I0928 18:12:36.890067  4581 sgd_solver.cpp:105] Iteration 106800, lr = 0.0001
I0928 18:12:51.113782  4581 solver.cpp:218] Iteration 106900 (7.03053 iter/s, 14.2237s/100 iters), loss = 0.001175
I0928 18:12:51.113823  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0011748 (* 1 = 0.0011748 loss)
I0928 18:12:51.113831  4581 sgd_solver.cpp:105] Iteration 106900, lr = 0.0001
I0928 18:13:04.630789  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:13:05.199760  4581 solver.cpp:330] Iteration 107000, Testing net (#0)
I0928 18:13:08.570384  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:13:08.711140  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9285
I0928 18:13:08.711177  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312078 (* 1 = 0.312078 loss)
I0928 18:13:08.852766  4581 solver.cpp:218] Iteration 107000 (5.63733 iter/s, 17.7389s/100 iters), loss = 0.00212939
I0928 18:13:08.852797  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00212919 (* 1 = 0.00212919 loss)
I0928 18:13:08.852804  4581 sgd_solver.cpp:105] Iteration 107000, lr = 0.0001
I0928 18:13:23.080916  4581 solver.cpp:218] Iteration 107100 (7.02836 iter/s, 14.2281s/100 iters), loss = 0.000626683
I0928 18:13:23.080957  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000626491 (* 1 = 0.000626491 loss)
I0928 18:13:23.080963  4581 sgd_solver.cpp:105] Iteration 107100, lr = 0.0001
I0928 18:13:37.310295  4581 solver.cpp:218] Iteration 107200 (7.02775 iter/s, 14.2293s/100 iters), loss = 0.000485156
I0928 18:13:37.310433  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000484964 (* 1 = 0.000484964 loss)
I0928 18:13:37.310442  4581 sgd_solver.cpp:105] Iteration 107200, lr = 0.0001
I0928 18:13:51.537143  4581 solver.cpp:218] Iteration 107300 (7.02905 iter/s, 14.2267s/100 iters), loss = 0.000390696
I0928 18:13:51.537174  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000390503 (* 1 = 0.000390503 loss)
I0928 18:13:51.537180  4581 sgd_solver.cpp:105] Iteration 107300, lr = 0.0001
I0928 18:14:05.767446  4581 solver.cpp:218] Iteration 107400 (7.02729 iter/s, 14.2302s/100 iters), loss = 0.000717389
I0928 18:14:05.767477  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000717197 (* 1 = 0.000717197 loss)
I0928 18:14:05.767485  4581 sgd_solver.cpp:105] Iteration 107400, lr = 0.0001
I0928 18:14:19.288475  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:14:19.858582  4581 solver.cpp:330] Iteration 107500, Testing net (#0)
I0928 18:14:23.231990  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:14:23.372788  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9283
I0928 18:14:23.372824  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312018 (* 1 = 0.312018 loss)
I0928 18:14:23.514987  4581 solver.cpp:218] Iteration 107500 (5.63461 iter/s, 17.7475s/100 iters), loss = 0.000353511
I0928 18:14:23.515015  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000353319 (* 1 = 0.000353319 loss)
I0928 18:14:23.515023  4581 sgd_solver.cpp:105] Iteration 107500, lr = 0.0001
I0928 18:14:37.747459  4581 solver.cpp:218] Iteration 107600 (7.02622 iter/s, 14.2324s/100 iters), loss = 0.000398979
I0928 18:14:37.747500  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000398787 (* 1 = 0.000398787 loss)
I0928 18:14:37.747506  4581 sgd_solver.cpp:105] Iteration 107600, lr = 0.0001
I0928 18:14:51.980275  4581 solver.cpp:218] Iteration 107700 (7.02606 iter/s, 14.2327s/100 iters), loss = 0.000888733
I0928 18:14:51.980368  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00088854 (* 1 = 0.00088854 loss)
I0928 18:14:51.980376  4581 sgd_solver.cpp:105] Iteration 107700, lr = 0.0001
I0928 18:15:06.210733  4581 solver.cpp:218] Iteration 107800 (7.02725 iter/s, 14.2303s/100 iters), loss = 0.000612438
I0928 18:15:06.210774  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000612245 (* 1 = 0.000612245 loss)
I0928 18:15:06.210781  4581 sgd_solver.cpp:105] Iteration 107800, lr = 0.0001
I0928 18:15:20.437333  4581 solver.cpp:218] Iteration 107900 (7.02913 iter/s, 14.2265s/100 iters), loss = 0.000458
I0928 18:15:20.437373  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000457808 (* 1 = 0.000457808 loss)
I0928 18:15:20.437379  4581 sgd_solver.cpp:105] Iteration 107900, lr = 0.0001
I0928 18:15:33.959097  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:15:34.529340  4581 solver.cpp:330] Iteration 108000, Testing net (#0)
I0928 18:15:37.900029  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:15:38.040483  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9284
I0928 18:15:38.040510  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312058 (* 1 = 0.312058 loss)
I0928 18:15:38.181895  4581 solver.cpp:218] Iteration 108000 (5.63556 iter/s, 17.7445s/100 iters), loss = 0.000470664
I0928 18:15:38.181924  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000470471 (* 1 = 0.000470471 loss)
I0928 18:15:38.181931  4581 sgd_solver.cpp:105] Iteration 108000, lr = 0.0001
I0928 18:15:52.409729  4581 solver.cpp:218] Iteration 108100 (7.02851 iter/s, 14.2278s/100 iters), loss = 0.000985653
I0928 18:15:52.409757  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00098546 (* 1 = 0.00098546 loss)
I0928 18:15:52.409765  4581 sgd_solver.cpp:105] Iteration 108100, lr = 0.0001
I0928 18:16:06.641742  4581 solver.cpp:218] Iteration 108200 (7.02645 iter/s, 14.2319s/100 iters), loss = 0.000738422
I0928 18:16:06.641870  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000738229 (* 1 = 0.000738229 loss)
I0928 18:16:06.641876  4581 sgd_solver.cpp:105] Iteration 108200, lr = 0.0001
I0928 18:16:20.872005  4581 solver.cpp:218] Iteration 108300 (7.02735 iter/s, 14.2301s/100 iters), loss = 0.00053921
I0928 18:16:20.872035  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000539017 (* 1 = 0.000539017 loss)
I0928 18:16:20.872041  4581 sgd_solver.cpp:105] Iteration 108300, lr = 0.0001
I0928 18:16:35.104919  4581 solver.cpp:218] Iteration 108400 (7.026 iter/s, 14.2328s/100 iters), loss = 0.000428709
I0928 18:16:35.104949  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000428516 (* 1 = 0.000428516 loss)
I0928 18:16:35.104955  4581 sgd_solver.cpp:105] Iteration 108400, lr = 0.0001
I0928 18:16:48.626322  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:16:49.195356  4581 solver.cpp:330] Iteration 108500, Testing net (#0)
I0928 18:16:52.564671  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:16:52.705652  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9284
I0928 18:16:52.705689  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311995 (* 1 = 0.311995 loss)
I0928 18:16:52.847748  4581 solver.cpp:218] Iteration 108500 (5.63611 iter/s, 17.7427s/100 iters), loss = 0.000779294
I0928 18:16:52.847775  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0007791 (* 1 = 0.0007791 loss)
I0928 18:16:52.847784  4581 sgd_solver.cpp:105] Iteration 108500, lr = 0.0001
I0928 18:17:07.081409  4581 solver.cpp:218] Iteration 108600 (7.02563 iter/s, 14.2336s/100 iters), loss = 0.000640169
I0928 18:17:07.081450  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000639976 (* 1 = 0.000639976 loss)
I0928 18:17:07.081456  4581 sgd_solver.cpp:105] Iteration 108600, lr = 0.0001
I0928 18:17:21.310796  4581 solver.cpp:218] Iteration 108700 (7.02775 iter/s, 14.2293s/100 iters), loss = 0.00135909
I0928 18:17:21.310957  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00135889 (* 1 = 0.00135889 loss)
I0928 18:17:21.310978  4581 sgd_solver.cpp:105] Iteration 108700, lr = 0.0001
I0928 18:17:35.540968  4581 solver.cpp:218] Iteration 108800 (7.02742 iter/s, 14.23s/100 iters), loss = 0.000370127
I0928 18:17:35.541009  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000369934 (* 1 = 0.000369934 loss)
I0928 18:17:35.541015  4581 sgd_solver.cpp:105] Iteration 108800, lr = 0.0001
I0928 18:17:49.770191  4581 solver.cpp:218] Iteration 108900 (7.02783 iter/s, 14.2291s/100 iters), loss = 0.00137544
I0928 18:17:49.770232  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00137525 (* 1 = 0.00137525 loss)
I0928 18:17:49.770238  4581 sgd_solver.cpp:105] Iteration 108900, lr = 0.0001
I0928 18:18:03.297639  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:18:03.867522  4581 solver.cpp:330] Iteration 109000, Testing net (#0)
I0928 18:18:07.237723  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:18:07.378193  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9284
I0928 18:18:07.378228  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312013 (* 1 = 0.312013 loss)
I0928 18:18:07.518852  4581 solver.cpp:218] Iteration 109000 (5.63426 iter/s, 17.7486s/100 iters), loss = 0.00168287
I0928 18:18:07.518882  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168268 (* 1 = 0.00168268 loss)
I0928 18:18:07.518889  4581 sgd_solver.cpp:105] Iteration 109000, lr = 0.0001
I0928 18:18:21.739140  4581 solver.cpp:218] Iteration 109100 (7.03224 iter/s, 14.2202s/100 iters), loss = 0.000734018
I0928 18:18:21.739179  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000733825 (* 1 = 0.000733825 loss)
I0928 18:18:21.739187  4581 sgd_solver.cpp:105] Iteration 109100, lr = 0.0001
I0928 18:18:35.956866  4581 solver.cpp:218] Iteration 109200 (7.03352 iter/s, 14.2176s/100 iters), loss = 0.000398119
I0928 18:18:35.956995  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000397927 (* 1 = 0.000397927 loss)
I0928 18:18:35.957002  4581 sgd_solver.cpp:105] Iteration 109200, lr = 0.0001
I0928 18:18:50.173928  4581 solver.cpp:218] Iteration 109300 (7.03388 iter/s, 14.2169s/100 iters), loss = 0.00200544
I0928 18:18:50.173959  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00200524 (* 1 = 0.00200524 loss)
I0928 18:18:50.173965  4581 sgd_solver.cpp:105] Iteration 109300, lr = 0.0001
I0928 18:19:04.398768  4581 solver.cpp:218] Iteration 109400 (7.02999 iter/s, 14.2248s/100 iters), loss = 0.00110939
I0928 18:19:04.398810  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0011092 (* 1 = 0.0011092 loss)
I0928 18:19:04.398816  4581 sgd_solver.cpp:105] Iteration 109400, lr = 0.0001
I0928 18:19:17.919178  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:19:18.488028  4581 solver.cpp:330] Iteration 109500, Testing net (#0)
I0928 18:19:21.857067  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:19:21.998446  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9283
I0928 18:19:21.998482  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312004 (* 1 = 0.312004 loss)
I0928 18:19:22.140213  4581 solver.cpp:218] Iteration 109500 (5.63655 iter/s, 17.7414s/100 iters), loss = 0.000392921
I0928 18:19:22.140241  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00039273 (* 1 = 0.00039273 loss)
I0928 18:19:22.140249  4581 sgd_solver.cpp:105] Iteration 109500, lr = 0.0001
I0928 18:19:36.368116  4581 solver.cpp:218] Iteration 109600 (7.02848 iter/s, 14.2278s/100 iters), loss = 0.00108843
I0928 18:19:36.368147  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108824 (* 1 = 0.00108824 loss)
I0928 18:19:36.368155  4581 sgd_solver.cpp:105] Iteration 109600, lr = 0.0001
I0928 18:19:50.595921  4581 solver.cpp:218] Iteration 109700 (7.02853 iter/s, 14.2277s/100 iters), loss = 0.000359181
I0928 18:19:50.596086  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000358989 (* 1 = 0.000358989 loss)
I0928 18:19:50.596097  4581 sgd_solver.cpp:105] Iteration 109700, lr = 0.0001
I0928 18:20:04.823173  4581 solver.cpp:218] Iteration 109800 (7.02886 iter/s, 14.2271s/100 iters), loss = 0.000912577
I0928 18:20:04.823202  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000912385 (* 1 = 0.000912385 loss)
I0928 18:20:04.823209  4581 sgd_solver.cpp:105] Iteration 109800, lr = 0.0001
I0928 18:20:19.056008  4581 solver.cpp:218] Iteration 109900 (7.02604 iter/s, 14.2328s/100 iters), loss = 0.000527731
I0928 18:20:19.056040  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000527539 (* 1 = 0.000527539 loss)
I0928 18:20:19.056047  4581 sgd_solver.cpp:105] Iteration 109900, lr = 0.0001
I0928 18:20:32.590950  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:20:33.160902  4581 solver.cpp:330] Iteration 110000, Testing net (#0)
I0928 18:20:36.530899  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:20:36.671319  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9284
I0928 18:20:36.671355  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312021 (* 1 = 0.312021 loss)
I0928 18:20:36.813228  4581 solver.cpp:218] Iteration 110000 (5.63154 iter/s, 17.7571s/100 iters), loss = 0.00108301
I0928 18:20:36.813257  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108282 (* 1 = 0.00108282 loss)
I0928 18:20:36.813264  4581 sgd_solver.cpp:105] Iteration 110000, lr = 0.0001
I0928 18:20:51.041867  4581 solver.cpp:218] Iteration 110100 (7.02814 iter/s, 14.2285s/100 iters), loss = 0.000786788
I0928 18:20:51.041914  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000786597 (* 1 = 0.000786597 loss)
I0928 18:20:51.041923  4581 sgd_solver.cpp:105] Iteration 110100, lr = 0.0001
I0928 18:21:05.282709  4581 solver.cpp:218] Iteration 110200 (7.0221 iter/s, 14.2408s/100 iters), loss = 0.000179075
I0928 18:21:05.282825  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000178884 (* 1 = 0.000178884 loss)
I0928 18:21:05.282842  4581 sgd_solver.cpp:105] Iteration 110200, lr = 0.0001
I0928 18:21:19.519672  4581 solver.cpp:218] Iteration 110300 (7.02405 iter/s, 14.2368s/100 iters), loss = 0.000334324
I0928 18:21:19.519709  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000334133 (* 1 = 0.000334133 loss)
I0928 18:21:19.519716  4581 sgd_solver.cpp:105] Iteration 110300, lr = 0.0001
I0928 18:21:33.762320  4581 solver.cpp:218] Iteration 110400 (7.0212 iter/s, 14.2426s/100 iters), loss = 0.000391985
I0928 18:21:33.762348  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000391793 (* 1 = 0.000391793 loss)
I0928 18:21:33.762356  4581 sgd_solver.cpp:105] Iteration 110400, lr = 0.0001
I0928 18:21:47.291239  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:21:47.861089  4581 solver.cpp:330] Iteration 110500, Testing net (#0)
I0928 18:21:51.230123  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:21:51.371234  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9284
I0928 18:21:51.371268  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312004 (* 1 = 0.312004 loss)
I0928 18:21:51.516016  4581 solver.cpp:218] Iteration 110500 (5.63266 iter/s, 17.7536s/100 iters), loss = 0.000484958
I0928 18:21:51.516053  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000484766 (* 1 = 0.000484766 loss)
I0928 18:21:51.516062  4581 sgd_solver.cpp:105] Iteration 110500, lr = 0.0001
I0928 18:22:05.749263  4581 solver.cpp:218] Iteration 110600 (7.02584 iter/s, 14.2332s/100 iters), loss = 0.00188108
I0928 18:22:05.749292  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188088 (* 1 = 0.00188088 loss)
I0928 18:22:05.749299  4581 sgd_solver.cpp:105] Iteration 110600, lr = 0.0001
I0928 18:22:19.994004  4581 solver.cpp:218] Iteration 110700 (7.02017 iter/s, 14.2447s/100 iters), loss = 0.00141345
I0928 18:22:19.994161  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00141325 (* 1 = 0.00141325 loss)
I0928 18:22:19.994169  4581 sgd_solver.cpp:105] Iteration 110700, lr = 0.0001
I0928 18:22:34.231979  4581 solver.cpp:218] Iteration 110800 (7.02357 iter/s, 14.2378s/100 iters), loss = 0.000235176
I0928 18:22:34.232028  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000234983 (* 1 = 0.000234983 loss)
I0928 18:22:34.232035  4581 sgd_solver.cpp:105] Iteration 110800, lr = 0.0001
I0928 18:22:48.473295  4581 solver.cpp:218] Iteration 110900 (7.02187 iter/s, 14.2412s/100 iters), loss = 0.000522368
I0928 18:22:48.473325  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000522176 (* 1 = 0.000522176 loss)
I0928 18:22:48.473331  4581 sgd_solver.cpp:105] Iteration 110900, lr = 0.0001
I0928 18:23:01.995239  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:23:02.564960  4581 solver.cpp:330] Iteration 111000, Testing net (#0)
I0928 18:23:05.934137  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:23:06.074623  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9284
I0928 18:23:06.074650  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311925 (* 1 = 0.311925 loss)
I0928 18:23:06.216898  4581 solver.cpp:218] Iteration 111000 (5.63586 iter/s, 17.7435s/100 iters), loss = 0.00175187
I0928 18:23:06.216928  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00175168 (* 1 = 0.00175168 loss)
I0928 18:23:06.216938  4581 sgd_solver.cpp:105] Iteration 111000, lr = 0.0001
I0928 18:23:20.441864  4581 solver.cpp:218] Iteration 111100 (7.02993 iter/s, 14.2249s/100 iters), loss = 0.00249645
I0928 18:23:20.441893  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00249626 (* 1 = 0.00249626 loss)
I0928 18:23:20.441900  4581 sgd_solver.cpp:105] Iteration 111100, lr = 0.0001
I0928 18:23:34.666766  4581 solver.cpp:218] Iteration 111200 (7.02996 iter/s, 14.2248s/100 iters), loss = 0.000412619
I0928 18:23:34.666901  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000412427 (* 1 = 0.000412427 loss)
I0928 18:23:34.666908  4581 sgd_solver.cpp:105] Iteration 111200, lr = 0.0001
I0928 18:23:48.896903  4581 solver.cpp:218] Iteration 111300 (7.02742 iter/s, 14.23s/100 iters), loss = 0.00101476
I0928 18:23:48.896934  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00101457 (* 1 = 0.00101457 loss)
I0928 18:23:48.896939  4581 sgd_solver.cpp:105] Iteration 111300, lr = 0.0001
I0928 18:24:03.127938  4581 solver.cpp:218] Iteration 111400 (7.02693 iter/s, 14.231s/100 iters), loss = 0.0010687
I0928 18:24:03.127967  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00106851 (* 1 = 0.00106851 loss)
I0928 18:24:03.127974  4581 sgd_solver.cpp:105] Iteration 111400, lr = 0.0001
I0928 18:24:16.655537  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:24:17.224865  4581 solver.cpp:330] Iteration 111500, Testing net (#0)
I0928 18:24:20.595531  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:24:20.736682  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9285
I0928 18:24:20.736718  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311983 (* 1 = 0.311983 loss)
I0928 18:24:20.878602  4581 solver.cpp:218] Iteration 111500 (5.63362 iter/s, 17.7506s/100 iters), loss = 0.000615884
I0928 18:24:20.878629  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000615694 (* 1 = 0.000615694 loss)
I0928 18:24:20.878636  4581 sgd_solver.cpp:105] Iteration 111500, lr = 0.0001
I0928 18:24:35.102926  4581 solver.cpp:218] Iteration 111600 (7.03024 iter/s, 14.2243s/100 iters), loss = 0.000812741
I0928 18:24:35.102969  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000812552 (* 1 = 0.000812552 loss)
I0928 18:24:35.102975  4581 sgd_solver.cpp:105] Iteration 111600, lr = 0.0001
I0928 18:24:49.324893  4581 solver.cpp:218] Iteration 111700 (7.03142 iter/s, 14.2219s/100 iters), loss = 0.00154808
I0928 18:24:49.325029  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0015479 (* 1 = 0.0015479 loss)
I0928 18:24:49.325038  4581 sgd_solver.cpp:105] Iteration 111700, lr = 0.0001
I0928 18:25:03.550609  4581 solver.cpp:218] Iteration 111800 (7.0296 iter/s, 14.2256s/100 iters), loss = 0.000469385
I0928 18:25:03.550638  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000469196 (* 1 = 0.000469196 loss)
I0928 18:25:03.550644  4581 sgd_solver.cpp:105] Iteration 111800, lr = 0.0001
I0928 18:25:17.774049  4581 solver.cpp:218] Iteration 111900 (7.03069 iter/s, 14.2234s/100 iters), loss = 0.000536541
I0928 18:25:17.774088  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000536352 (* 1 = 0.000536352 loss)
I0928 18:25:17.774096  4581 sgd_solver.cpp:105] Iteration 111900, lr = 0.0001
I0928 18:25:31.290638  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:25:31.860710  4581 solver.cpp:330] Iteration 112000, Testing net (#0)
I0928 18:25:35.230589  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:25:35.371480  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9284
I0928 18:25:35.371516  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311939 (* 1 = 0.311939 loss)
I0928 18:25:35.512810  4581 solver.cpp:218] Iteration 112000 (5.6374 iter/s, 17.7387s/100 iters), loss = 0.000835832
I0928 18:25:35.512840  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000835644 (* 1 = 0.000835644 loss)
I0928 18:25:35.512848  4581 sgd_solver.cpp:105] Iteration 112000, lr = 0.0001
I0928 18:25:49.742811  4581 solver.cpp:218] Iteration 112100 (7.02744 iter/s, 14.2299s/100 iters), loss = 0.00430086
I0928 18:25:49.742841  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00430067 (* 1 = 0.00430067 loss)
I0928 18:25:49.742847  4581 sgd_solver.cpp:105] Iteration 112100, lr = 0.0001
I0928 18:26:03.972172  4581 solver.cpp:218] Iteration 112200 (7.02776 iter/s, 14.2293s/100 iters), loss = 0.00105902
I0928 18:26:03.972244  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00105883 (* 1 = 0.00105883 loss)
I0928 18:26:03.972250  4581 sgd_solver.cpp:105] Iteration 112200, lr = 0.0001
I0928 18:26:18.199604  4581 solver.cpp:218] Iteration 112300 (7.02873 iter/s, 14.2273s/100 iters), loss = 0.000277557
I0928 18:26:18.199645  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000277369 (* 1 = 0.000277369 loss)
I0928 18:26:18.199651  4581 sgd_solver.cpp:105] Iteration 112300, lr = 0.0001
I0928 18:26:32.426856  4581 solver.cpp:218] Iteration 112400 (7.0288 iter/s, 14.2272s/100 iters), loss = 0.000431474
I0928 18:26:32.426895  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000431287 (* 1 = 0.000431287 loss)
I0928 18:26:32.426903  4581 sgd_solver.cpp:105] Iteration 112400, lr = 0.0001
I0928 18:26:45.952581  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:26:46.522747  4581 solver.cpp:330] Iteration 112500, Testing net (#0)
I0928 18:26:49.893038  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:26:50.033943  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9285
I0928 18:26:50.033978  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311808 (* 1 = 0.311808 loss)
I0928 18:26:50.176267  4581 solver.cpp:218] Iteration 112500 (5.63402 iter/s, 17.7493s/100 iters), loss = 0.00275714
I0928 18:26:50.176295  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00275695 (* 1 = 0.00275695 loss)
I0928 18:26:50.176302  4581 sgd_solver.cpp:105] Iteration 112500, lr = 0.0001
I0928 18:27:04.410241  4581 solver.cpp:218] Iteration 112600 (7.02548 iter/s, 14.2339s/100 iters), loss = 0.00171888
I0928 18:27:04.410282  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00171869 (* 1 = 0.00171869 loss)
I0928 18:27:04.410290  4581 sgd_solver.cpp:105] Iteration 112600, lr = 0.0001
I0928 18:27:18.640918  4581 solver.cpp:218] Iteration 112700 (7.02711 iter/s, 14.2306s/100 iters), loss = 0.000822893
I0928 18:27:18.641063  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000822707 (* 1 = 0.000822707 loss)
I0928 18:27:18.641072  4581 sgd_solver.cpp:105] Iteration 112700, lr = 0.0001
I0928 18:27:32.873265  4581 solver.cpp:218] Iteration 112800 (7.02633 iter/s, 14.2322s/100 iters), loss = 0.000291802
I0928 18:27:32.873296  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000291617 (* 1 = 0.000291617 loss)
I0928 18:27:32.873311  4581 sgd_solver.cpp:105] Iteration 112800, lr = 0.0001
I0928 18:27:47.110836  4581 solver.cpp:218] Iteration 112900 (7.02371 iter/s, 14.2375s/100 iters), loss = 0.000427215
I0928 18:27:47.110867  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000427029 (* 1 = 0.000427029 loss)
I0928 18:27:47.110874  4581 sgd_solver.cpp:105] Iteration 112900, lr = 0.0001
I0928 18:28:00.640076  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:28:01.209136  4581 solver.cpp:330] Iteration 113000, Testing net (#0)
I0928 18:28:04.579233  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:28:04.719746  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9285
I0928 18:28:04.719784  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311677 (* 1 = 0.311677 loss)
I0928 18:28:04.861500  4581 solver.cpp:218] Iteration 113000 (5.63362 iter/s, 17.7506s/100 iters), loss = 0.000325138
I0928 18:28:04.861529  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000324952 (* 1 = 0.000324952 loss)
I0928 18:28:04.861536  4581 sgd_solver.cpp:105] Iteration 113000, lr = 0.0001
I0928 18:28:19.093451  4581 solver.cpp:218] Iteration 113100 (7.02648 iter/s, 14.2319s/100 iters), loss = 0.00439512
I0928 18:28:19.093479  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00439493 (* 1 = 0.00439493 loss)
I0928 18:28:19.093485  4581 sgd_solver.cpp:105] Iteration 113100, lr = 0.0001
I0928 18:28:33.320648  4581 solver.cpp:218] Iteration 113200 (7.02882 iter/s, 14.2271s/100 iters), loss = 0.000406609
I0928 18:28:33.320776  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000406423 (* 1 = 0.000406423 loss)
I0928 18:28:33.320785  4581 sgd_solver.cpp:105] Iteration 113200, lr = 0.0001
I0928 18:28:47.545382  4581 solver.cpp:218] Iteration 113300 (7.03009 iter/s, 14.2246s/100 iters), loss = 0.000577368
I0928 18:28:47.545411  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000577183 (* 1 = 0.000577183 loss)
I0928 18:28:47.545418  4581 sgd_solver.cpp:105] Iteration 113300, lr = 0.0001
I0928 18:29:01.777060  4581 solver.cpp:218] Iteration 113400 (7.02661 iter/s, 14.2316s/100 iters), loss = 0.000708151
I0928 18:29:01.777101  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000707966 (* 1 = 0.000707966 loss)
I0928 18:29:01.777107  4581 sgd_solver.cpp:105] Iteration 113400, lr = 0.0001
I0928 18:29:15.307159  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:29:15.877285  4581 solver.cpp:330] Iteration 113500, Testing net (#0)
I0928 18:29:19.248064  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:29:19.388754  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9284
I0928 18:29:19.388790  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311627 (* 1 = 0.311627 loss)
I0928 18:29:19.530942  4581 solver.cpp:218] Iteration 113500 (5.6326 iter/s, 17.7538s/100 iters), loss = 0.000344477
I0928 18:29:19.530972  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000344292 (* 1 = 0.000344292 loss)
I0928 18:29:19.530979  4581 sgd_solver.cpp:105] Iteration 113500, lr = 0.0001
I0928 18:29:33.747146  4581 solver.cpp:218] Iteration 113600 (7.03428 iter/s, 14.2161s/100 iters), loss = 0.000359005
I0928 18:29:33.747185  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000358821 (* 1 = 0.000358821 loss)
I0928 18:29:33.747191  4581 sgd_solver.cpp:105] Iteration 113600, lr = 0.0001
I0928 18:29:47.970582  4581 solver.cpp:218] Iteration 113700 (7.03069 iter/s, 14.2234s/100 iters), loss = 0.00052645
I0928 18:29:47.970868  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000526265 (* 1 = 0.000526265 loss)
I0928 18:29:47.970886  4581 sgd_solver.cpp:105] Iteration 113700, lr = 0.0001
I0928 18:30:02.192003  4581 solver.cpp:218] Iteration 113800 (7.03181 iter/s, 14.2211s/100 iters), loss = 0.000524501
I0928 18:30:02.192034  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000524315 (* 1 = 0.000524315 loss)
I0928 18:30:02.192041  4581 sgd_solver.cpp:105] Iteration 113800, lr = 0.0001
I0928 18:30:16.416821  4581 solver.cpp:218] Iteration 113900 (7.03 iter/s, 14.2247s/100 iters), loss = 0.000951673
I0928 18:30:16.416851  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000951487 (* 1 = 0.000951487 loss)
I0928 18:30:16.416858  4581 sgd_solver.cpp:105] Iteration 113900, lr = 0.0001
I0928 18:30:29.936285  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:30:30.505738  4581 solver.cpp:330] Iteration 114000, Testing net (#0)
I0928 18:30:33.877281  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:30:34.018754  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9285
I0928 18:30:34.018791  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31158 (* 1 = 0.31158 loss)
I0928 18:30:34.160305  4581 solver.cpp:218] Iteration 114000 (5.6359 iter/s, 17.7434s/100 iters), loss = 0.000511318
I0928 18:30:34.160334  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000511132 (* 1 = 0.000511132 loss)
I0928 18:30:34.160341  4581 sgd_solver.cpp:105] Iteration 114000, lr = 0.0001
I0928 18:30:48.384696  4581 solver.cpp:218] Iteration 114100 (7.03021 iter/s, 14.2243s/100 iters), loss = 0.000357339
I0928 18:30:48.384737  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000357153 (* 1 = 0.000357153 loss)
I0928 18:30:48.384742  4581 sgd_solver.cpp:105] Iteration 114100, lr = 0.0001
I0928 18:31:02.619640  4581 solver.cpp:218] Iteration 114200 (7.02501 iter/s, 14.2349s/100 iters), loss = 0.000442254
I0928 18:31:02.619740  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000442068 (* 1 = 0.000442068 loss)
I0928 18:31:02.619747  4581 sgd_solver.cpp:105] Iteration 114200, lr = 0.0001
I0928 18:31:16.846895  4581 solver.cpp:218] Iteration 114300 (7.02882 iter/s, 14.2271s/100 iters), loss = 0.000350805
I0928 18:31:16.846926  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00035062 (* 1 = 0.00035062 loss)
I0928 18:31:16.846942  4581 sgd_solver.cpp:105] Iteration 114300, lr = 0.0001
I0928 18:31:31.075601  4581 solver.cpp:218] Iteration 114400 (7.02808 iter/s, 14.2286s/100 iters), loss = 0.000596268
I0928 18:31:31.075631  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000596083 (* 1 = 0.000596083 loss)
I0928 18:31:31.075637  4581 sgd_solver.cpp:105] Iteration 114400, lr = 0.0001
I0928 18:31:44.596861  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:31:45.165920  4581 solver.cpp:330] Iteration 114500, Testing net (#0)
I0928 18:31:48.538908  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:31:48.679865  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9286
I0928 18:31:48.679901  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311678 (* 1 = 0.311678 loss)
I0928 18:31:48.822460  4581 solver.cpp:218] Iteration 114500 (5.63483 iter/s, 17.7468s/100 iters), loss = 0.000654187
I0928 18:31:48.822489  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000654002 (* 1 = 0.000654002 loss)
I0928 18:31:48.822496  4581 sgd_solver.cpp:105] Iteration 114500, lr = 0.0001
I0928 18:32:03.060310  4581 solver.cpp:218] Iteration 114600 (7.02357 iter/s, 14.2378s/100 iters), loss = 0.000779645
I0928 18:32:03.060341  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00077946 (* 1 = 0.00077946 loss)
I0928 18:32:03.060348  4581 sgd_solver.cpp:105] Iteration 114600, lr = 0.0001
I0928 18:32:17.298750  4581 solver.cpp:218] Iteration 114700 (7.02328 iter/s, 14.2384s/100 iters), loss = 0.000243145
I0928 18:32:17.298842  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00024296 (* 1 = 0.00024296 loss)
I0928 18:32:17.298851  4581 sgd_solver.cpp:105] Iteration 114700, lr = 0.0001
I0928 18:32:31.537487  4581 solver.cpp:218] Iteration 114800 (7.02316 iter/s, 14.2386s/100 iters), loss = 0.000358198
I0928 18:32:31.537529  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000358012 (* 1 = 0.000358012 loss)
I0928 18:32:31.537535  4581 sgd_solver.cpp:105] Iteration 114800, lr = 0.0001
I0928 18:32:45.777051  4581 solver.cpp:218] Iteration 114900 (7.02273 iter/s, 14.2395s/100 iters), loss = 0.000478367
I0928 18:32:45.777081  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000478181 (* 1 = 0.000478181 loss)
I0928 18:32:45.777087  4581 sgd_solver.cpp:105] Iteration 114900, lr = 0.0001
I0928 18:32:59.304697  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:32:59.874147  4581 solver.cpp:330] Iteration 115000, Testing net (#0)
I0928 18:33:03.246062  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:33:03.386871  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9287
I0928 18:33:03.386907  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311761 (* 1 = 0.311761 loss)
I0928 18:33:03.529428  4581 solver.cpp:218] Iteration 115000 (5.63307 iter/s, 17.7523s/100 iters), loss = 0.00129839
I0928 18:33:03.529459  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00129821 (* 1 = 0.00129821 loss)
I0928 18:33:03.529467  4581 sgd_solver.cpp:105] Iteration 115000, lr = 0.0001
I0928 18:33:17.759013  4581 solver.cpp:218] Iteration 115100 (7.02765 iter/s, 14.2295s/100 iters), loss = 0.00215087
I0928 18:33:17.759043  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00215069 (* 1 = 0.00215069 loss)
I0928 18:33:17.759049  4581 sgd_solver.cpp:105] Iteration 115100, lr = 0.0001
I0928 18:33:31.993427  4581 solver.cpp:218] Iteration 115200 (7.02526 iter/s, 14.2343s/100 iters), loss = 0.000653228
I0928 18:33:31.993484  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000653045 (* 1 = 0.000653045 loss)
I0928 18:33:31.993490  4581 sgd_solver.cpp:105] Iteration 115200, lr = 0.0001
I0928 18:33:46.221451  4581 solver.cpp:218] Iteration 115300 (7.02843 iter/s, 14.2279s/100 iters), loss = 0.00195718
I0928 18:33:46.221482  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.001957 (* 1 = 0.001957 loss)
I0928 18:33:46.221488  4581 sgd_solver.cpp:105] Iteration 115300, lr = 0.0001
I0928 18:34:00.450137  4581 solver.cpp:218] Iteration 115400 (7.02809 iter/s, 14.2286s/100 iters), loss = 0.000390168
I0928 18:34:00.450167  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000389986 (* 1 = 0.000389986 loss)
I0928 18:34:00.450173  4581 sgd_solver.cpp:105] Iteration 115400, lr = 0.0001
I0928 18:34:13.975402  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:34:14.544924  4581 solver.cpp:330] Iteration 115500, Testing net (#0)
I0928 18:34:17.914593  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:34:18.055877  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9288
I0928 18:34:18.055903  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311608 (* 1 = 0.311608 loss)
I0928 18:34:18.197365  4581 solver.cpp:218] Iteration 115500 (5.63471 iter/s, 17.7471s/100 iters), loss = 0.000871661
I0928 18:34:18.197394  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000871479 (* 1 = 0.000871479 loss)
I0928 18:34:18.197402  4581 sgd_solver.cpp:105] Iteration 115500, lr = 0.0001
I0928 18:34:32.427186  4581 solver.cpp:218] Iteration 115600 (7.02753 iter/s, 14.2297s/100 iters), loss = 0.000349489
I0928 18:34:32.427217  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000349307 (* 1 = 0.000349307 loss)
I0928 18:34:32.427223  4581 sgd_solver.cpp:105] Iteration 115600, lr = 0.0001
I0928 18:34:46.658160  4581 solver.cpp:218] Iteration 115700 (7.02696 iter/s, 14.2309s/100 iters), loss = 0.000287658
I0928 18:34:46.658311  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000287476 (* 1 = 0.000287476 loss)
I0928 18:34:46.658319  4581 sgd_solver.cpp:105] Iteration 115700, lr = 0.0001
I0928 18:35:00.895915  4581 solver.cpp:218] Iteration 115800 (7.02367 iter/s, 14.2376s/100 iters), loss = 0.000685093
I0928 18:35:00.895947  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000684911 (* 1 = 0.000684911 loss)
I0928 18:35:00.895956  4581 sgd_solver.cpp:105] Iteration 115800, lr = 0.0001
I0928 18:35:15.137934  4581 solver.cpp:218] Iteration 115900 (7.02151 iter/s, 14.2419s/100 iters), loss = 0.000665309
I0928 18:35:15.137975  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000665127 (* 1 = 0.000665127 loss)
I0928 18:35:15.137981  4581 sgd_solver.cpp:105] Iteration 115900, lr = 0.0001
I0928 18:35:28.665011  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:35:29.235522  4581 solver.cpp:330] Iteration 116000, Testing net (#0)
I0928 18:35:32.606999  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:35:32.750082  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9286
I0928 18:35:32.750118  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311671 (* 1 = 0.311671 loss)
I0928 18:35:32.891296  4581 solver.cpp:218] Iteration 116000 (5.63276 iter/s, 17.7533s/100 iters), loss = 0.000660818
I0928 18:35:32.891325  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000660636 (* 1 = 0.000660636 loss)
I0928 18:35:32.891332  4581 sgd_solver.cpp:105] Iteration 116000, lr = 0.0001
I0928 18:35:47.108057  4581 solver.cpp:218] Iteration 116100 (7.03398 iter/s, 14.2167s/100 iters), loss = 0.000373471
I0928 18:35:47.108088  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000373289 (* 1 = 0.000373289 loss)
I0928 18:35:47.108095  4581 sgd_solver.cpp:105] Iteration 116100, lr = 0.0001
I0928 18:36:01.327016  4581 solver.cpp:218] Iteration 116200 (7.0329 iter/s, 14.2189s/100 iters), loss = 0.000465687
I0928 18:36:01.327154  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000465504 (* 1 = 0.000465504 loss)
I0928 18:36:01.327162  4581 sgd_solver.cpp:105] Iteration 116200, lr = 0.0001
I0928 18:36:15.549520  4581 solver.cpp:218] Iteration 116300 (7.0312 iter/s, 14.2223s/100 iters), loss = 0.000891907
I0928 18:36:15.549549  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000891725 (* 1 = 0.000891725 loss)
I0928 18:36:15.549556  4581 sgd_solver.cpp:105] Iteration 116300, lr = 0.0001
I0928 18:36:29.773414  4581 solver.cpp:218] Iteration 116400 (7.03046 iter/s, 14.2238s/100 iters), loss = 0.000683658
I0928 18:36:29.773442  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000683475 (* 1 = 0.000683475 loss)
I0928 18:36:29.773448  4581 sgd_solver.cpp:105] Iteration 116400, lr = 0.0001
I0928 18:36:43.288944  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:36:43.858109  4581 solver.cpp:330] Iteration 116500, Testing net (#0)
I0928 18:36:47.226617  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:36:47.366765  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9286
I0928 18:36:47.366802  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311635 (* 1 = 0.311635 loss)
I0928 18:36:47.508210  4581 solver.cpp:218] Iteration 116500 (5.63866 iter/s, 17.7347s/100 iters), loss = 0.000826434
I0928 18:36:47.508239  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000826252 (* 1 = 0.000826252 loss)
I0928 18:36:47.508260  4581 sgd_solver.cpp:105] Iteration 116500, lr = 0.0001
I0928 18:37:01.741025  4581 solver.cpp:218] Iteration 116600 (7.02605 iter/s, 14.2327s/100 iters), loss = 0.000578435
I0928 18:37:01.741055  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000578253 (* 1 = 0.000578253 loss)
I0928 18:37:01.741061  4581 sgd_solver.cpp:105] Iteration 116600, lr = 0.0001
I0928 18:37:15.973863  4581 solver.cpp:218] Iteration 116700 (7.02604 iter/s, 14.2328s/100 iters), loss = 0.00212551
I0928 18:37:15.973958  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00212533 (* 1 = 0.00212533 loss)
I0928 18:37:15.973975  4581 sgd_solver.cpp:105] Iteration 116700, lr = 0.0001
I0928 18:37:30.204135  4581 solver.cpp:218] Iteration 116800 (7.02734 iter/s, 14.2301s/100 iters), loss = 0.000475504
I0928 18:37:30.204175  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000475321 (* 1 = 0.000475321 loss)
I0928 18:37:30.204181  4581 sgd_solver.cpp:105] Iteration 116800, lr = 0.0001
I0928 18:37:44.438061  4581 solver.cpp:218] Iteration 116900 (7.02551 iter/s, 14.2338s/100 iters), loss = 0.00119919
I0928 18:37:44.438093  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00119901 (* 1 = 0.00119901 loss)
I0928 18:37:44.438100  4581 sgd_solver.cpp:105] Iteration 116900, lr = 0.0001
I0928 18:37:57.966861  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:37:58.536046  4581 solver.cpp:330] Iteration 117000, Testing net (#0)
I0928 18:38:01.907027  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:38:02.048007  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9286
I0928 18:38:02.048032  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311595 (* 1 = 0.311595 loss)
I0928 18:38:02.190053  4581 solver.cpp:218] Iteration 117000 (5.63319 iter/s, 17.7519s/100 iters), loss = 0.000684276
I0928 18:38:02.190083  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000684094 (* 1 = 0.000684094 loss)
I0928 18:38:02.190089  4581 sgd_solver.cpp:105] Iteration 117000, lr = 0.0001
I0928 18:38:16.419111  4581 solver.cpp:218] Iteration 117100 (7.02791 iter/s, 14.229s/100 iters), loss = 0.000790592
I0928 18:38:16.419152  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00079041 (* 1 = 0.00079041 loss)
I0928 18:38:16.419158  4581 sgd_solver.cpp:105] Iteration 117100, lr = 0.0001
I0928 18:38:30.648777  4581 solver.cpp:218] Iteration 117200 (7.02761 iter/s, 14.2296s/100 iters), loss = 0.000196934
I0928 18:38:30.648896  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000196751 (* 1 = 0.000196751 loss)
I0928 18:38:30.648905  4581 sgd_solver.cpp:105] Iteration 117200, lr = 0.0001
I0928 18:38:44.882920  4581 solver.cpp:218] Iteration 117300 (7.02544 iter/s, 14.234s/100 iters), loss = 0.000719505
I0928 18:38:44.882961  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000719322 (* 1 = 0.000719322 loss)
I0928 18:38:44.882967  4581 sgd_solver.cpp:105] Iteration 117300, lr = 0.0001
I0928 18:38:59.115213  4581 solver.cpp:218] Iteration 117400 (7.02631 iter/s, 14.2322s/100 iters), loss = 0.0011499
I0928 18:38:59.115254  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00114971 (* 1 = 0.00114971 loss)
I0928 18:38:59.115260  4581 sgd_solver.cpp:105] Iteration 117400, lr = 0.0001
I0928 18:39:12.636999  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:39:13.206450  4581 solver.cpp:330] Iteration 117500, Testing net (#0)
I0928 18:39:16.580797  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:39:16.723160  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9286
I0928 18:39:16.723186  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311617 (* 1 = 0.311617 loss)
I0928 18:39:16.863842  4581 solver.cpp:218] Iteration 117500 (5.63427 iter/s, 17.7485s/100 iters), loss = 0.000397768
I0928 18:39:16.863870  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000397585 (* 1 = 0.000397585 loss)
I0928 18:39:16.863878  4581 sgd_solver.cpp:105] Iteration 117500, lr = 0.0001
I0928 18:39:31.247859  4581 solver.cpp:218] Iteration 117600 (6.95219 iter/s, 14.3839s/100 iters), loss = 0.000351654
I0928 18:39:31.247900  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00035147 (* 1 = 0.00035147 loss)
I0928 18:39:31.247905  4581 sgd_solver.cpp:105] Iteration 117600, lr = 0.0001
I0928 18:39:45.482538  4581 solver.cpp:218] Iteration 117700 (7.02514 iter/s, 14.2346s/100 iters), loss = 0.000720533
I0928 18:39:45.482681  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000720349 (* 1 = 0.000720349 loss)
I0928 18:39:45.482709  4581 sgd_solver.cpp:105] Iteration 117700, lr = 0.0001
I0928 18:39:59.720403  4581 solver.cpp:218] Iteration 117800 (7.02361 iter/s, 14.2377s/100 iters), loss = 0.00228349
I0928 18:39:59.720445  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00228331 (* 1 = 0.00228331 loss)
I0928 18:39:59.720451  4581 sgd_solver.cpp:105] Iteration 117800, lr = 0.0001
I0928 18:40:13.955678  4581 solver.cpp:218] Iteration 117900 (7.02484 iter/s, 14.2352s/100 iters), loss = 0.000431179
I0928 18:40:13.955714  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000430995 (* 1 = 0.000430995 loss)
I0928 18:40:13.955723  4581 sgd_solver.cpp:105] Iteration 117900, lr = 0.0001
I0928 18:40:27.480638  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:40:28.050886  4581 solver.cpp:330] Iteration 118000, Testing net (#0)
I0928 18:40:31.423658  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:40:31.564210  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9285
I0928 18:40:31.564235  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311504 (* 1 = 0.311504 loss)
I0928 18:40:31.706666  4581 solver.cpp:218] Iteration 118000 (5.63351 iter/s, 17.7509s/100 iters), loss = 0.000835349
I0928 18:40:31.706696  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000835165 (* 1 = 0.000835165 loss)
I0928 18:40:31.706703  4581 sgd_solver.cpp:105] Iteration 118000, lr = 0.0001
I0928 18:40:45.934541  4581 solver.cpp:218] Iteration 118100 (7.02849 iter/s, 14.2278s/100 iters), loss = 0.00211398
I0928 18:40:45.934581  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0021138 (* 1 = 0.0021138 loss)
I0928 18:40:45.934588  4581 sgd_solver.cpp:105] Iteration 118100, lr = 0.0001
I0928 18:41:00.168572  4581 solver.cpp:218] Iteration 118200 (7.02546 iter/s, 14.234s/100 iters), loss = 0.00156397
I0928 18:41:00.168682  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00156379 (* 1 = 0.00156379 loss)
I0928 18:41:00.168690  4581 sgd_solver.cpp:105] Iteration 118200, lr = 0.0001
I0928 18:41:14.399777  4581 solver.cpp:218] Iteration 118300 (7.02688 iter/s, 14.2311s/100 iters), loss = 0.000620929
I0928 18:41:14.399806  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000620745 (* 1 = 0.000620745 loss)
I0928 18:41:14.399812  4581 sgd_solver.cpp:105] Iteration 118300, lr = 0.0001
I0928 18:41:28.630528  4581 solver.cpp:218] Iteration 118400 (7.02707 iter/s, 14.2307s/100 iters), loss = 0.000647263
I0928 18:41:28.630558  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000647078 (* 1 = 0.000647078 loss)
I0928 18:41:28.630564  4581 sgd_solver.cpp:105] Iteration 118400, lr = 0.0001
I0928 18:41:42.149107  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:41:42.719033  4581 solver.cpp:330] Iteration 118500, Testing net (#0)
I0928 18:41:46.092218  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:41:46.232645  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9283
I0928 18:41:46.232681  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311541 (* 1 = 0.311541 loss)
I0928 18:41:46.374649  4581 solver.cpp:218] Iteration 118500 (5.63569 iter/s, 17.744s/100 iters), loss = 0.00174398
I0928 18:41:46.374680  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0017438 (* 1 = 0.0017438 loss)
I0928 18:41:46.374687  4581 sgd_solver.cpp:105] Iteration 118500, lr = 0.0001
I0928 18:42:00.598671  4581 solver.cpp:218] Iteration 118600 (7.0304 iter/s, 14.2239s/100 iters), loss = 0.000758817
I0928 18:42:00.598701  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000758632 (* 1 = 0.000758632 loss)
I0928 18:42:00.598707  4581 sgd_solver.cpp:105] Iteration 118600, lr = 0.0001
I0928 18:42:14.817719  4581 solver.cpp:218] Iteration 118700 (7.03285 iter/s, 14.219s/100 iters), loss = 0.00194424
I0928 18:42:14.817857  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00194405 (* 1 = 0.00194405 loss)
I0928 18:42:14.817874  4581 sgd_solver.cpp:105] Iteration 118700, lr = 0.0001
I0928 18:42:29.038723  4581 solver.cpp:218] Iteration 118800 (7.03193 iter/s, 14.2208s/100 iters), loss = 0.00148046
I0928 18:42:29.038754  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00148027 (* 1 = 0.00148027 loss)
I0928 18:42:29.038760  4581 sgd_solver.cpp:105] Iteration 118800, lr = 0.0001
I0928 18:42:43.260326  4581 solver.cpp:218] Iteration 118900 (7.03159 iter/s, 14.2215s/100 iters), loss = 0.000273445
I0928 18:42:43.260366  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000273259 (* 1 = 0.000273259 loss)
I0928 18:42:43.260372  4581 sgd_solver.cpp:105] Iteration 118900, lr = 0.0001
I0928 18:42:56.778977  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:42:57.348268  4581 solver.cpp:330] Iteration 119000, Testing net (#0)
I0928 18:43:00.719897  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:43:00.860641  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9284
I0928 18:43:00.860667  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311567 (* 1 = 0.311567 loss)
I0928 18:43:01.002570  4581 solver.cpp:218] Iteration 119000 (5.63629 iter/s, 17.7422s/100 iters), loss = 0.00159135
I0928 18:43:01.002600  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00159117 (* 1 = 0.00159117 loss)
I0928 18:43:01.002609  4581 sgd_solver.cpp:105] Iteration 119000, lr = 0.0001
I0928 18:43:15.226208  4581 solver.cpp:218] Iteration 119100 (7.03058 iter/s, 14.2236s/100 iters), loss = 0.00061315
I0928 18:43:15.226248  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000612965 (* 1 = 0.000612965 loss)
I0928 18:43:15.226254  4581 sgd_solver.cpp:105] Iteration 119100, lr = 0.0001
I0928 18:43:29.456238  4581 solver.cpp:218] Iteration 119200 (7.02743 iter/s, 14.2299s/100 iters), loss = 0.000172744
I0928 18:43:29.456342  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000172557 (* 1 = 0.000172557 loss)
I0928 18:43:29.456351  4581 sgd_solver.cpp:105] Iteration 119200, lr = 0.0001
I0928 18:43:43.685503  4581 solver.cpp:218] Iteration 119300 (7.02784 iter/s, 14.2291s/100 iters), loss = 0.000105766
I0928 18:43:43.685544  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000105579 (* 1 = 0.000105579 loss)
I0928 18:43:43.685550  4581 sgd_solver.cpp:105] Iteration 119300, lr = 0.0001
I0928 18:43:57.913105  4581 solver.cpp:218] Iteration 119400 (7.02863 iter/s, 14.2275s/100 iters), loss = 0.00220002
I0928 18:43:57.913146  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00219983 (* 1 = 0.00219983 loss)
I0928 18:43:57.913151  4581 sgd_solver.cpp:105] Iteration 119400, lr = 0.0001
I0928 18:44:11.433543  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:44:12.002331  4581 solver.cpp:330] Iteration 119500, Testing net (#0)
I0928 18:44:15.375531  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:44:15.516638  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9283
I0928 18:44:15.516674  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311639 (* 1 = 0.311639 loss)
I0928 18:44:15.658869  4581 solver.cpp:218] Iteration 119500 (5.63517 iter/s, 17.7457s/100 iters), loss = 0.000478329
I0928 18:44:15.658900  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000478142 (* 1 = 0.000478142 loss)
I0928 18:44:15.658906  4581 sgd_solver.cpp:105] Iteration 119500, lr = 0.0001
I0928 18:44:29.895341  4581 solver.cpp:218] Iteration 119600 (7.02425 iter/s, 14.2364s/100 iters), loss = 0.000818784
I0928 18:44:29.895382  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000818597 (* 1 = 0.000818597 loss)
I0928 18:44:29.895388  4581 sgd_solver.cpp:105] Iteration 119600, lr = 0.0001
I0928 18:44:44.138998  4581 solver.cpp:218] Iteration 119700 (7.02071 iter/s, 14.2436s/100 iters), loss = 0.000197205
I0928 18:44:44.139153  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000197018 (* 1 = 0.000197018 loss)
I0928 18:44:44.139160  4581 sgd_solver.cpp:105] Iteration 119700, lr = 0.0001
I0928 18:44:58.376324  4581 solver.cpp:218] Iteration 119800 (7.02388 iter/s, 14.2371s/100 iters), loss = 0.000949391
I0928 18:44:58.376363  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000949203 (* 1 = 0.000949203 loss)
I0928 18:44:58.376370  4581 sgd_solver.cpp:105] Iteration 119800, lr = 0.0001
I0928 18:45:12.616780  4581 solver.cpp:218] Iteration 119900 (7.02229 iter/s, 14.2404s/100 iters), loss = 0.00119765
I0928 18:45:12.616821  4581 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00119747 (* 1 = 0.00119747 loss)
I0928 18:45:12.616827  4581 sgd_solver.cpp:105] Iteration 119900, lr = 0.0001
I0928 18:45:26.149639  4591 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:45:26.719532  4581 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res56_mpelu_alpha0.25_beta1_nodecay12_gauss_iter_120000.caffemodel
I0928 18:45:26.745026  4581 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res56_mpelu_alpha0.25_beta1_nodecay12_gauss_iter_120000.solverstate
I0928 18:45:26.785717  4581 solver.cpp:310] Iteration 120000, loss = 0.000392213
I0928 18:45:26.785737  4581 solver.cpp:330] Iteration 120000, Testing net (#0)
I0928 18:45:30.154022  4592 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:45:30.295176  4581 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9284
I0928 18:45:30.295212  4581 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311672 (* 1 = 0.311672 loss)
I0928 18:45:30.295217  4581 solver.cpp:315] Optimization Done.
I0928 18:45:30.295218  4581 caffe.cpp:259] Optimization Done.
