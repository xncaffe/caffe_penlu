I0928 09:32:12.138495  4247 caffe.cpp:218] Using GPUs 0
I0928 09:32:12.166764  4247 caffe.cpp:223] GPU 0: GeForce GTX 1080
I0928 09:32:12.393858  4247 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res56_mpelu_alpha1_beta1_nodecay_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res56_mpelu_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I0928 09:32:12.393996  4247 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56_mpelu_train_test.prototxt
I0928 09:32:12.397634  4247 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56_mpelu_train_test.prototxt
I0928 09:32:12.397650  4247 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0928 09:32:12.397871  4247 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I0928 09:32:12.397989  4247 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I0928 09:32:12.399047  4247 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU1"
  type: "M2PELU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU2"
  type: "M2PELU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU3"
  type: "M2PELU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU4"
  type: "M2PELU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU5"
  type: "M2PELU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU6"
  type: "M2PELU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU7"
  type: "M2PELU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU8"
  type: "M2PELU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU9"
  type: "M2PELU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU10"
  type: "M2PELU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU11"
  type: "M2PELU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU12"
  type: "M2PELU"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU13"
  type: "M2PELU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU14"
  type: "M2PELU"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU15"
  type: "M2PELU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU16"
  type: "M2PELU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU17"
  type: "M2PELU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU18"
  type: "M2PELU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU19"
  type: "M2PELU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU20"
  type: "M2PELU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU21"
  type: "M2PELU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU22"
  type: "M2PELU"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution24"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU23"
  type: "M2PELU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU24"
  type: "M2PELU"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
I0928 09:32:12.399811  4247 layer_factory.hpp:77] Creating layer Data1
I0928 09:32:12.399888  4247 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I0928 09:32:12.399906  4247 net.cpp:84] Creating Layer Data1
I0928 09:32:12.399912  4247 net.cpp:380] Data1 -> Data1
I0928 09:32:12.399927  4247 net.cpp:380] Data1 -> Data2
I0928 09:32:12.399935  4247 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0928 09:32:12.401321  4247 data_layer.cpp:45] output data size: 100,3,28,28
I0928 09:32:12.403609  4247 net.cpp:122] Setting up Data1
I0928 09:32:12.403631  4247 net.cpp:129] Top shape: 100 3 28 28 (235200)
I0928 09:32:12.403635  4247 net.cpp:129] Top shape: 100 (100)
I0928 09:32:12.403638  4247 net.cpp:137] Memory required for data: 941200
I0928 09:32:12.403645  4247 layer_factory.hpp:77] Creating layer Convolution1
I0928 09:32:12.403662  4247 net.cpp:84] Creating Layer Convolution1
I0928 09:32:12.403666  4247 net.cpp:406] Convolution1 <- Data1
I0928 09:32:12.403676  4247 net.cpp:380] Convolution1 -> Convolution1
I0928 09:32:12.549075  4247 net.cpp:122] Setting up Convolution1
I0928 09:32:12.549098  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.549103  4247 net.cpp:137] Memory required for data: 5958800
I0928 09:32:12.549116  4247 layer_factory.hpp:77] Creating layer BatchNorm1
I0928 09:32:12.549127  4247 net.cpp:84] Creating Layer BatchNorm1
I0928 09:32:12.549141  4247 net.cpp:406] BatchNorm1 <- Convolution1
I0928 09:32:12.549157  4247 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0928 09:32:12.549290  4247 net.cpp:122] Setting up BatchNorm1
I0928 09:32:12.549295  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.549298  4247 net.cpp:137] Memory required for data: 10976400
I0928 09:32:12.549304  4247 layer_factory.hpp:77] Creating layer Scale1
I0928 09:32:12.549314  4247 net.cpp:84] Creating Layer Scale1
I0928 09:32:12.549316  4247 net.cpp:406] Scale1 <- Convolution1
I0928 09:32:12.549329  4247 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0928 09:32:12.549368  4247 layer_factory.hpp:77] Creating layer Scale1
I0928 09:32:12.549464  4247 net.cpp:122] Setting up Scale1
I0928 09:32:12.549469  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.549471  4247 net.cpp:137] Memory required for data: 15994000
I0928 09:32:12.549475  4247 layer_factory.hpp:77] Creating layer M2PELU1
I0928 09:32:12.549484  4247 net.cpp:84] Creating Layer M2PELU1
I0928 09:32:12.549486  4247 net.cpp:406] M2PELU1 <- Convolution1
I0928 09:32:12.549490  4247 net.cpp:367] M2PELU1 -> Convolution1 (in-place)
I0928 09:32:12.550078  4247 net.cpp:122] Setting up M2PELU1
I0928 09:32:12.550087  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.550091  4247 net.cpp:137] Memory required for data: 21011600
I0928 09:32:12.550107  4247 layer_factory.hpp:77] Creating layer Convolution1_M2PELU1_0_split
I0928 09:32:12.550112  4247 net.cpp:84] Creating Layer Convolution1_M2PELU1_0_split
I0928 09:32:12.550115  4247 net.cpp:406] Convolution1_M2PELU1_0_split <- Convolution1
I0928 09:32:12.550118  4247 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_0
I0928 09:32:12.550125  4247 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_1
I0928 09:32:12.550148  4247 net.cpp:122] Setting up Convolution1_M2PELU1_0_split
I0928 09:32:12.550153  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.550165  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.550168  4247 net.cpp:137] Memory required for data: 31046800
I0928 09:32:12.550169  4247 layer_factory.hpp:77] Creating layer Convolution2
I0928 09:32:12.550186  4247 net.cpp:84] Creating Layer Convolution2
I0928 09:32:12.550189  4247 net.cpp:406] Convolution2 <- Convolution1_M2PELU1_0_split_0
I0928 09:32:12.550194  4247 net.cpp:380] Convolution2 -> Convolution2
I0928 09:32:12.551065  4247 net.cpp:122] Setting up Convolution2
I0928 09:32:12.551075  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.551079  4247 net.cpp:137] Memory required for data: 36064400
I0928 09:32:12.551095  4247 layer_factory.hpp:77] Creating layer BatchNorm2
I0928 09:32:12.551110  4247 net.cpp:84] Creating Layer BatchNorm2
I0928 09:32:12.551115  4247 net.cpp:406] BatchNorm2 <- Convolution2
I0928 09:32:12.551117  4247 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0928 09:32:12.551250  4247 net.cpp:122] Setting up BatchNorm2
I0928 09:32:12.551255  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.551259  4247 net.cpp:137] Memory required for data: 41082000
I0928 09:32:12.551273  4247 layer_factory.hpp:77] Creating layer Scale2
I0928 09:32:12.551280  4247 net.cpp:84] Creating Layer Scale2
I0928 09:32:12.551282  4247 net.cpp:406] Scale2 <- Convolution2
I0928 09:32:12.551285  4247 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0928 09:32:12.551311  4247 layer_factory.hpp:77] Creating layer Scale2
I0928 09:32:12.551407  4247 net.cpp:122] Setting up Scale2
I0928 09:32:12.551412  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.551415  4247 net.cpp:137] Memory required for data: 46099600
I0928 09:32:12.551429  4247 layer_factory.hpp:77] Creating layer M2PELU2
I0928 09:32:12.551434  4247 net.cpp:84] Creating Layer M2PELU2
I0928 09:32:12.551437  4247 net.cpp:406] M2PELU2 <- Convolution2
I0928 09:32:12.551441  4247 net.cpp:367] M2PELU2 -> Convolution2 (in-place)
I0928 09:32:12.551522  4247 net.cpp:122] Setting up M2PELU2
I0928 09:32:12.551527  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.551537  4247 net.cpp:137] Memory required for data: 51117200
I0928 09:32:12.551543  4247 layer_factory.hpp:77] Creating layer Convolution3
I0928 09:32:12.551550  4247 net.cpp:84] Creating Layer Convolution3
I0928 09:32:12.551553  4247 net.cpp:406] Convolution3 <- Convolution2
I0928 09:32:12.551558  4247 net.cpp:380] Convolution3 -> Convolution3
I0928 09:32:12.552371  4247 net.cpp:122] Setting up Convolution3
I0928 09:32:12.552381  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.552384  4247 net.cpp:137] Memory required for data: 56134800
I0928 09:32:12.552389  4247 layer_factory.hpp:77] Creating layer BatchNorm3
I0928 09:32:12.552394  4247 net.cpp:84] Creating Layer BatchNorm3
I0928 09:32:12.552397  4247 net.cpp:406] BatchNorm3 <- Convolution3
I0928 09:32:12.552402  4247 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0928 09:32:12.552515  4247 net.cpp:122] Setting up BatchNorm3
I0928 09:32:12.552520  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.552523  4247 net.cpp:137] Memory required for data: 61152400
I0928 09:32:12.552528  4247 layer_factory.hpp:77] Creating layer Scale3
I0928 09:32:12.552533  4247 net.cpp:84] Creating Layer Scale3
I0928 09:32:12.552536  4247 net.cpp:406] Scale3 <- Convolution3
I0928 09:32:12.552539  4247 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0928 09:32:12.552562  4247 layer_factory.hpp:77] Creating layer Scale3
I0928 09:32:12.552629  4247 net.cpp:122] Setting up Scale3
I0928 09:32:12.552634  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.552637  4247 net.cpp:137] Memory required for data: 66170000
I0928 09:32:12.552641  4247 layer_factory.hpp:77] Creating layer Eltwise1
I0928 09:32:12.552646  4247 net.cpp:84] Creating Layer Eltwise1
I0928 09:32:12.552649  4247 net.cpp:406] Eltwise1 <- Convolution1_M2PELU1_0_split_1
I0928 09:32:12.552652  4247 net.cpp:406] Eltwise1 <- Convolution3
I0928 09:32:12.552656  4247 net.cpp:380] Eltwise1 -> Eltwise1
I0928 09:32:12.552671  4247 net.cpp:122] Setting up Eltwise1
I0928 09:32:12.552676  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.552678  4247 net.cpp:137] Memory required for data: 71187600
I0928 09:32:12.552680  4247 layer_factory.hpp:77] Creating layer M2PELU3
I0928 09:32:12.552685  4247 net.cpp:84] Creating Layer M2PELU3
I0928 09:32:12.552688  4247 net.cpp:406] M2PELU3 <- Eltwise1
I0928 09:32:12.552691  4247 net.cpp:367] M2PELU3 -> Eltwise1 (in-place)
I0928 09:32:12.552764  4247 net.cpp:122] Setting up M2PELU3
I0928 09:32:12.552769  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.552772  4247 net.cpp:137] Memory required for data: 76205200
I0928 09:32:12.552776  4247 layer_factory.hpp:77] Creating layer Eltwise1_M2PELU3_0_split
I0928 09:32:12.552781  4247 net.cpp:84] Creating Layer Eltwise1_M2PELU3_0_split
I0928 09:32:12.552783  4247 net.cpp:406] Eltwise1_M2PELU3_0_split <- Eltwise1
I0928 09:32:12.552786  4247 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_0
I0928 09:32:12.552791  4247 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_1
I0928 09:32:12.552812  4247 net.cpp:122] Setting up Eltwise1_M2PELU3_0_split
I0928 09:32:12.552816  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.552820  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.552822  4247 net.cpp:137] Memory required for data: 86240400
I0928 09:32:12.552824  4247 layer_factory.hpp:77] Creating layer Convolution4
I0928 09:32:12.552831  4247 net.cpp:84] Creating Layer Convolution4
I0928 09:32:12.552834  4247 net.cpp:406] Convolution4 <- Eltwise1_M2PELU3_0_split_0
I0928 09:32:12.552837  4247 net.cpp:380] Convolution4 -> Convolution4
I0928 09:32:12.553668  4247 net.cpp:122] Setting up Convolution4
I0928 09:32:12.553678  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.553683  4247 net.cpp:137] Memory required for data: 91258000
I0928 09:32:12.553686  4247 layer_factory.hpp:77] Creating layer BatchNorm4
I0928 09:32:12.553691  4247 net.cpp:84] Creating Layer BatchNorm4
I0928 09:32:12.553701  4247 net.cpp:406] BatchNorm4 <- Convolution4
I0928 09:32:12.553706  4247 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0928 09:32:12.553818  4247 net.cpp:122] Setting up BatchNorm4
I0928 09:32:12.553824  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.553828  4247 net.cpp:137] Memory required for data: 96275600
I0928 09:32:12.553831  4247 layer_factory.hpp:77] Creating layer Scale4
I0928 09:32:12.553836  4247 net.cpp:84] Creating Layer Scale4
I0928 09:32:12.553839  4247 net.cpp:406] Scale4 <- Convolution4
I0928 09:32:12.553843  4247 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0928 09:32:12.553865  4247 layer_factory.hpp:77] Creating layer Scale4
I0928 09:32:12.553930  4247 net.cpp:122] Setting up Scale4
I0928 09:32:12.553936  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.553938  4247 net.cpp:137] Memory required for data: 101293200
I0928 09:32:12.553944  4247 layer_factory.hpp:77] Creating layer M2PELU4
I0928 09:32:12.553951  4247 net.cpp:84] Creating Layer M2PELU4
I0928 09:32:12.553953  4247 net.cpp:406] M2PELU4 <- Convolution4
I0928 09:32:12.553956  4247 net.cpp:367] M2PELU4 -> Convolution4 (in-place)
I0928 09:32:12.554030  4247 net.cpp:122] Setting up M2PELU4
I0928 09:32:12.554036  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.554039  4247 net.cpp:137] Memory required for data: 106310800
I0928 09:32:12.554042  4247 layer_factory.hpp:77] Creating layer Convolution5
I0928 09:32:12.554049  4247 net.cpp:84] Creating Layer Convolution5
I0928 09:32:12.554052  4247 net.cpp:406] Convolution5 <- Convolution4
I0928 09:32:12.554056  4247 net.cpp:380] Convolution5 -> Convolution5
I0928 09:32:12.554916  4247 net.cpp:122] Setting up Convolution5
I0928 09:32:12.554926  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.554930  4247 net.cpp:137] Memory required for data: 111328400
I0928 09:32:12.554935  4247 layer_factory.hpp:77] Creating layer BatchNorm5
I0928 09:32:12.554940  4247 net.cpp:84] Creating Layer BatchNorm5
I0928 09:32:12.554944  4247 net.cpp:406] BatchNorm5 <- Convolution5
I0928 09:32:12.554947  4247 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0928 09:32:12.555066  4247 net.cpp:122] Setting up BatchNorm5
I0928 09:32:12.555071  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.555074  4247 net.cpp:137] Memory required for data: 116346000
I0928 09:32:12.555078  4247 layer_factory.hpp:77] Creating layer Scale5
I0928 09:32:12.555083  4247 net.cpp:84] Creating Layer Scale5
I0928 09:32:12.555086  4247 net.cpp:406] Scale5 <- Convolution5
I0928 09:32:12.555089  4247 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0928 09:32:12.555114  4247 layer_factory.hpp:77] Creating layer Scale5
I0928 09:32:12.555184  4247 net.cpp:122] Setting up Scale5
I0928 09:32:12.555189  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.555191  4247 net.cpp:137] Memory required for data: 121363600
I0928 09:32:12.555196  4247 layer_factory.hpp:77] Creating layer Eltwise2
I0928 09:32:12.555199  4247 net.cpp:84] Creating Layer Eltwise2
I0928 09:32:12.555202  4247 net.cpp:406] Eltwise2 <- Eltwise1_M2PELU3_0_split_1
I0928 09:32:12.555205  4247 net.cpp:406] Eltwise2 <- Convolution5
I0928 09:32:12.555208  4247 net.cpp:380] Eltwise2 -> Eltwise2
I0928 09:32:12.555224  4247 net.cpp:122] Setting up Eltwise2
I0928 09:32:12.555228  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.555230  4247 net.cpp:137] Memory required for data: 126381200
I0928 09:32:12.555233  4247 layer_factory.hpp:77] Creating layer M2PELU5
I0928 09:32:12.555238  4247 net.cpp:84] Creating Layer M2PELU5
I0928 09:32:12.555240  4247 net.cpp:406] M2PELU5 <- Eltwise2
I0928 09:32:12.555244  4247 net.cpp:367] M2PELU5 -> Eltwise2 (in-place)
I0928 09:32:12.555320  4247 net.cpp:122] Setting up M2PELU5
I0928 09:32:12.555325  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.555328  4247 net.cpp:137] Memory required for data: 131398800
I0928 09:32:12.555332  4247 layer_factory.hpp:77] Creating layer Eltwise2_M2PELU5_0_split
I0928 09:32:12.555342  4247 net.cpp:84] Creating Layer Eltwise2_M2PELU5_0_split
I0928 09:32:12.555346  4247 net.cpp:406] Eltwise2_M2PELU5_0_split <- Eltwise2
I0928 09:32:12.555349  4247 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_0
I0928 09:32:12.555354  4247 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_1
I0928 09:32:12.555377  4247 net.cpp:122] Setting up Eltwise2_M2PELU5_0_split
I0928 09:32:12.555380  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.555383  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.555387  4247 net.cpp:137] Memory required for data: 141434000
I0928 09:32:12.555388  4247 layer_factory.hpp:77] Creating layer Convolution6
I0928 09:32:12.555397  4247 net.cpp:84] Creating Layer Convolution6
I0928 09:32:12.555399  4247 net.cpp:406] Convolution6 <- Eltwise2_M2PELU5_0_split_0
I0928 09:32:12.555403  4247 net.cpp:380] Convolution6 -> Convolution6
I0928 09:32:12.556244  4247 net.cpp:122] Setting up Convolution6
I0928 09:32:12.556253  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.556257  4247 net.cpp:137] Memory required for data: 146451600
I0928 09:32:12.556262  4247 layer_factory.hpp:77] Creating layer BatchNorm6
I0928 09:32:12.556267  4247 net.cpp:84] Creating Layer BatchNorm6
I0928 09:32:12.556270  4247 net.cpp:406] BatchNorm6 <- Convolution6
I0928 09:32:12.556274  4247 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0928 09:32:12.556397  4247 net.cpp:122] Setting up BatchNorm6
I0928 09:32:12.556403  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.556406  4247 net.cpp:137] Memory required for data: 151469200
I0928 09:32:12.556411  4247 layer_factory.hpp:77] Creating layer Scale6
I0928 09:32:12.556416  4247 net.cpp:84] Creating Layer Scale6
I0928 09:32:12.556418  4247 net.cpp:406] Scale6 <- Convolution6
I0928 09:32:12.556422  4247 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0928 09:32:12.556445  4247 layer_factory.hpp:77] Creating layer Scale6
I0928 09:32:12.556519  4247 net.cpp:122] Setting up Scale6
I0928 09:32:12.556524  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.556525  4247 net.cpp:137] Memory required for data: 156486800
I0928 09:32:12.556529  4247 layer_factory.hpp:77] Creating layer M2PELU6
I0928 09:32:12.556535  4247 net.cpp:84] Creating Layer M2PELU6
I0928 09:32:12.556538  4247 net.cpp:406] M2PELU6 <- Convolution6
I0928 09:32:12.556541  4247 net.cpp:367] M2PELU6 -> Convolution6 (in-place)
I0928 09:32:12.556619  4247 net.cpp:122] Setting up M2PELU6
I0928 09:32:12.556624  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.556627  4247 net.cpp:137] Memory required for data: 161504400
I0928 09:32:12.556630  4247 layer_factory.hpp:77] Creating layer Convolution7
I0928 09:32:12.556638  4247 net.cpp:84] Creating Layer Convolution7
I0928 09:32:12.556640  4247 net.cpp:406] Convolution7 <- Convolution6
I0928 09:32:12.556646  4247 net.cpp:380] Convolution7 -> Convolution7
I0928 09:32:12.557175  4247 net.cpp:122] Setting up Convolution7
I0928 09:32:12.557183  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.557186  4247 net.cpp:137] Memory required for data: 166522000
I0928 09:32:12.557190  4247 layer_factory.hpp:77] Creating layer BatchNorm7
I0928 09:32:12.557196  4247 net.cpp:84] Creating Layer BatchNorm7
I0928 09:32:12.557199  4247 net.cpp:406] BatchNorm7 <- Convolution7
I0928 09:32:12.557204  4247 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0928 09:32:12.557327  4247 net.cpp:122] Setting up BatchNorm7
I0928 09:32:12.557332  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.557334  4247 net.cpp:137] Memory required for data: 171539600
I0928 09:32:12.557339  4247 layer_factory.hpp:77] Creating layer Scale7
I0928 09:32:12.557346  4247 net.cpp:84] Creating Layer Scale7
I0928 09:32:12.557349  4247 net.cpp:406] Scale7 <- Convolution7
I0928 09:32:12.557353  4247 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0928 09:32:12.557377  4247 layer_factory.hpp:77] Creating layer Scale7
I0928 09:32:12.557458  4247 net.cpp:122] Setting up Scale7
I0928 09:32:12.557463  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.557466  4247 net.cpp:137] Memory required for data: 176557200
I0928 09:32:12.557471  4247 layer_factory.hpp:77] Creating layer Eltwise3
I0928 09:32:12.557476  4247 net.cpp:84] Creating Layer Eltwise3
I0928 09:32:12.557478  4247 net.cpp:406] Eltwise3 <- Eltwise2_M2PELU5_0_split_1
I0928 09:32:12.557482  4247 net.cpp:406] Eltwise3 <- Convolution7
I0928 09:32:12.557485  4247 net.cpp:380] Eltwise3 -> Eltwise3
I0928 09:32:12.557500  4247 net.cpp:122] Setting up Eltwise3
I0928 09:32:12.557504  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.557507  4247 net.cpp:137] Memory required for data: 181574800
I0928 09:32:12.557508  4247 layer_factory.hpp:77] Creating layer M2PELU7
I0928 09:32:12.557513  4247 net.cpp:84] Creating Layer M2PELU7
I0928 09:32:12.557516  4247 net.cpp:406] M2PELU7 <- Eltwise3
I0928 09:32:12.557519  4247 net.cpp:367] M2PELU7 -> Eltwise3 (in-place)
I0928 09:32:12.557596  4247 net.cpp:122] Setting up M2PELU7
I0928 09:32:12.557601  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.557605  4247 net.cpp:137] Memory required for data: 186592400
I0928 09:32:12.557608  4247 layer_factory.hpp:77] Creating layer Eltwise3_M2PELU7_0_split
I0928 09:32:12.557612  4247 net.cpp:84] Creating Layer Eltwise3_M2PELU7_0_split
I0928 09:32:12.557615  4247 net.cpp:406] Eltwise3_M2PELU7_0_split <- Eltwise3
I0928 09:32:12.557618  4247 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_0
I0928 09:32:12.557622  4247 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_1
I0928 09:32:12.557646  4247 net.cpp:122] Setting up Eltwise3_M2PELU7_0_split
I0928 09:32:12.557649  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.557652  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.557654  4247 net.cpp:137] Memory required for data: 196627600
I0928 09:32:12.557657  4247 layer_factory.hpp:77] Creating layer Convolution8
I0928 09:32:12.557662  4247 net.cpp:84] Creating Layer Convolution8
I0928 09:32:12.557665  4247 net.cpp:406] Convolution8 <- Eltwise3_M2PELU7_0_split_0
I0928 09:32:12.557669  4247 net.cpp:380] Convolution8 -> Convolution8
I0928 09:32:12.558508  4247 net.cpp:122] Setting up Convolution8
I0928 09:32:12.558518  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.558537  4247 net.cpp:137] Memory required for data: 201645200
I0928 09:32:12.558547  4247 layer_factory.hpp:77] Creating layer BatchNorm8
I0928 09:32:12.558554  4247 net.cpp:84] Creating Layer BatchNorm8
I0928 09:32:12.558567  4247 net.cpp:406] BatchNorm8 <- Convolution8
I0928 09:32:12.558570  4247 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0928 09:32:12.558713  4247 net.cpp:122] Setting up BatchNorm8
I0928 09:32:12.558718  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.558722  4247 net.cpp:137] Memory required for data: 206662800
I0928 09:32:12.558727  4247 layer_factory.hpp:77] Creating layer Scale8
I0928 09:32:12.558732  4247 net.cpp:84] Creating Layer Scale8
I0928 09:32:12.558735  4247 net.cpp:406] Scale8 <- Convolution8
I0928 09:32:12.558738  4247 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0928 09:32:12.558763  4247 layer_factory.hpp:77] Creating layer Scale8
I0928 09:32:12.558836  4247 net.cpp:122] Setting up Scale8
I0928 09:32:12.558841  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.558845  4247 net.cpp:137] Memory required for data: 211680400
I0928 09:32:12.558848  4247 layer_factory.hpp:77] Creating layer M2PELU8
I0928 09:32:12.558854  4247 net.cpp:84] Creating Layer M2PELU8
I0928 09:32:12.558857  4247 net.cpp:406] M2PELU8 <- Convolution8
I0928 09:32:12.558861  4247 net.cpp:367] M2PELU8 -> Convolution8 (in-place)
I0928 09:32:12.558956  4247 net.cpp:122] Setting up M2PELU8
I0928 09:32:12.558961  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.558964  4247 net.cpp:137] Memory required for data: 216698000
I0928 09:32:12.558969  4247 layer_factory.hpp:77] Creating layer Convolution9
I0928 09:32:12.558982  4247 net.cpp:84] Creating Layer Convolution9
I0928 09:32:12.558985  4247 net.cpp:406] Convolution9 <- Convolution8
I0928 09:32:12.558990  4247 net.cpp:380] Convolution9 -> Convolution9
I0928 09:32:12.559856  4247 net.cpp:122] Setting up Convolution9
I0928 09:32:12.559866  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.559870  4247 net.cpp:137] Memory required for data: 221715600
I0928 09:32:12.559875  4247 layer_factory.hpp:77] Creating layer BatchNorm9
I0928 09:32:12.559883  4247 net.cpp:84] Creating Layer BatchNorm9
I0928 09:32:12.559886  4247 net.cpp:406] BatchNorm9 <- Convolution9
I0928 09:32:12.559890  4247 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0928 09:32:12.560020  4247 net.cpp:122] Setting up BatchNorm9
I0928 09:32:12.560025  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.560027  4247 net.cpp:137] Memory required for data: 226733200
I0928 09:32:12.560032  4247 layer_factory.hpp:77] Creating layer Scale9
I0928 09:32:12.560037  4247 net.cpp:84] Creating Layer Scale9
I0928 09:32:12.560050  4247 net.cpp:406] Scale9 <- Convolution9
I0928 09:32:12.560053  4247 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0928 09:32:12.560088  4247 layer_factory.hpp:77] Creating layer Scale9
I0928 09:32:12.560165  4247 net.cpp:122] Setting up Scale9
I0928 09:32:12.560170  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.560173  4247 net.cpp:137] Memory required for data: 231750800
I0928 09:32:12.560178  4247 layer_factory.hpp:77] Creating layer Eltwise4
I0928 09:32:12.560183  4247 net.cpp:84] Creating Layer Eltwise4
I0928 09:32:12.560185  4247 net.cpp:406] Eltwise4 <- Eltwise3_M2PELU7_0_split_1
I0928 09:32:12.560189  4247 net.cpp:406] Eltwise4 <- Convolution9
I0928 09:32:12.560194  4247 net.cpp:380] Eltwise4 -> Eltwise4
I0928 09:32:12.560209  4247 net.cpp:122] Setting up Eltwise4
I0928 09:32:12.560212  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.560214  4247 net.cpp:137] Memory required for data: 236768400
I0928 09:32:12.560216  4247 layer_factory.hpp:77] Creating layer M2PELU9
I0928 09:32:12.560221  4247 net.cpp:84] Creating Layer M2PELU9
I0928 09:32:12.560225  4247 net.cpp:406] M2PELU9 <- Eltwise4
I0928 09:32:12.560228  4247 net.cpp:367] M2PELU9 -> Eltwise4 (in-place)
I0928 09:32:12.560312  4247 net.cpp:122] Setting up M2PELU9
I0928 09:32:12.560317  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.560319  4247 net.cpp:137] Memory required for data: 241786000
I0928 09:32:12.560323  4247 layer_factory.hpp:77] Creating layer Eltwise4_M2PELU9_0_split
I0928 09:32:12.560328  4247 net.cpp:84] Creating Layer Eltwise4_M2PELU9_0_split
I0928 09:32:12.560331  4247 net.cpp:406] Eltwise4_M2PELU9_0_split <- Eltwise4
I0928 09:32:12.560334  4247 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_0
I0928 09:32:12.560338  4247 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_1
I0928 09:32:12.560361  4247 net.cpp:122] Setting up Eltwise4_M2PELU9_0_split
I0928 09:32:12.560375  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.560379  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.560382  4247 net.cpp:137] Memory required for data: 251821200
I0928 09:32:12.560384  4247 layer_factory.hpp:77] Creating layer Convolution10
I0928 09:32:12.560391  4247 net.cpp:84] Creating Layer Convolution10
I0928 09:32:12.560395  4247 net.cpp:406] Convolution10 <- Eltwise4_M2PELU9_0_split_0
I0928 09:32:12.560400  4247 net.cpp:380] Convolution10 -> Convolution10
I0928 09:32:12.561460  4247 net.cpp:122] Setting up Convolution10
I0928 09:32:12.561470  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.561473  4247 net.cpp:137] Memory required for data: 256838800
I0928 09:32:12.561478  4247 layer_factory.hpp:77] Creating layer BatchNorm10
I0928 09:32:12.561483  4247 net.cpp:84] Creating Layer BatchNorm10
I0928 09:32:12.561487  4247 net.cpp:406] BatchNorm10 <- Convolution10
I0928 09:32:12.561491  4247 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0928 09:32:12.561624  4247 net.cpp:122] Setting up BatchNorm10
I0928 09:32:12.561628  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.561631  4247 net.cpp:137] Memory required for data: 261856400
I0928 09:32:12.561635  4247 layer_factory.hpp:77] Creating layer Scale10
I0928 09:32:12.561641  4247 net.cpp:84] Creating Layer Scale10
I0928 09:32:12.561645  4247 net.cpp:406] Scale10 <- Convolution10
I0928 09:32:12.561647  4247 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0928 09:32:12.561674  4247 layer_factory.hpp:77] Creating layer Scale10
I0928 09:32:12.561749  4247 net.cpp:122] Setting up Scale10
I0928 09:32:12.561754  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.561758  4247 net.cpp:137] Memory required for data: 266874000
I0928 09:32:12.561761  4247 layer_factory.hpp:77] Creating layer M2PELU10
I0928 09:32:12.561767  4247 net.cpp:84] Creating Layer M2PELU10
I0928 09:32:12.561770  4247 net.cpp:406] M2PELU10 <- Convolution10
I0928 09:32:12.561774  4247 net.cpp:367] M2PELU10 -> Convolution10 (in-place)
I0928 09:32:12.561852  4247 net.cpp:122] Setting up M2PELU10
I0928 09:32:12.561857  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.561861  4247 net.cpp:137] Memory required for data: 271891600
I0928 09:32:12.561864  4247 layer_factory.hpp:77] Creating layer Convolution11
I0928 09:32:12.561882  4247 net.cpp:84] Creating Layer Convolution11
I0928 09:32:12.561884  4247 net.cpp:406] Convolution11 <- Convolution10
I0928 09:32:12.561889  4247 net.cpp:380] Convolution11 -> Convolution11
I0928 09:32:12.562906  4247 net.cpp:122] Setting up Convolution11
I0928 09:32:12.562916  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.562918  4247 net.cpp:137] Memory required for data: 276909200
I0928 09:32:12.562922  4247 layer_factory.hpp:77] Creating layer BatchNorm11
I0928 09:32:12.562928  4247 net.cpp:84] Creating Layer BatchNorm11
I0928 09:32:12.562932  4247 net.cpp:406] BatchNorm11 <- Convolution11
I0928 09:32:12.562935  4247 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0928 09:32:12.563061  4247 net.cpp:122] Setting up BatchNorm11
I0928 09:32:12.563066  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.563068  4247 net.cpp:137] Memory required for data: 281926800
I0928 09:32:12.563072  4247 layer_factory.hpp:77] Creating layer Scale11
I0928 09:32:12.563076  4247 net.cpp:84] Creating Layer Scale11
I0928 09:32:12.563079  4247 net.cpp:406] Scale11 <- Convolution11
I0928 09:32:12.563082  4247 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0928 09:32:12.563107  4247 layer_factory.hpp:77] Creating layer Scale11
I0928 09:32:12.563184  4247 net.cpp:122] Setting up Scale11
I0928 09:32:12.563189  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.563191  4247 net.cpp:137] Memory required for data: 286944400
I0928 09:32:12.563194  4247 layer_factory.hpp:77] Creating layer Eltwise5
I0928 09:32:12.563200  4247 net.cpp:84] Creating Layer Eltwise5
I0928 09:32:12.563204  4247 net.cpp:406] Eltwise5 <- Eltwise4_M2PELU9_0_split_1
I0928 09:32:12.563206  4247 net.cpp:406] Eltwise5 <- Convolution11
I0928 09:32:12.563210  4247 net.cpp:380] Eltwise5 -> Eltwise5
I0928 09:32:12.563225  4247 net.cpp:122] Setting up Eltwise5
I0928 09:32:12.563230  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.563231  4247 net.cpp:137] Memory required for data: 291962000
I0928 09:32:12.563233  4247 layer_factory.hpp:77] Creating layer M2PELU11
I0928 09:32:12.563238  4247 net.cpp:84] Creating Layer M2PELU11
I0928 09:32:12.563241  4247 net.cpp:406] M2PELU11 <- Eltwise5
I0928 09:32:12.563244  4247 net.cpp:367] M2PELU11 -> Eltwise5 (in-place)
I0928 09:32:12.563326  4247 net.cpp:122] Setting up M2PELU11
I0928 09:32:12.563331  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.563334  4247 net.cpp:137] Memory required for data: 296979600
I0928 09:32:12.563338  4247 layer_factory.hpp:77] Creating layer Eltwise5_M2PELU11_0_split
I0928 09:32:12.563344  4247 net.cpp:84] Creating Layer Eltwise5_M2PELU11_0_split
I0928 09:32:12.563352  4247 net.cpp:406] Eltwise5_M2PELU11_0_split <- Eltwise5
I0928 09:32:12.563356  4247 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_0
I0928 09:32:12.563361  4247 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_1
I0928 09:32:12.563385  4247 net.cpp:122] Setting up Eltwise5_M2PELU11_0_split
I0928 09:32:12.563390  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.563393  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.563396  4247 net.cpp:137] Memory required for data: 307014800
I0928 09:32:12.563398  4247 layer_factory.hpp:77] Creating layer Convolution12
I0928 09:32:12.563405  4247 net.cpp:84] Creating Layer Convolution12
I0928 09:32:12.563407  4247 net.cpp:406] Convolution12 <- Eltwise5_M2PELU11_0_split_0
I0928 09:32:12.563411  4247 net.cpp:380] Convolution12 -> Convolution12
I0928 09:32:12.564272  4247 net.cpp:122] Setting up Convolution12
I0928 09:32:12.564282  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.564286  4247 net.cpp:137] Memory required for data: 312032400
I0928 09:32:12.564291  4247 layer_factory.hpp:77] Creating layer BatchNorm12
I0928 09:32:12.564296  4247 net.cpp:84] Creating Layer BatchNorm12
I0928 09:32:12.564301  4247 net.cpp:406] BatchNorm12 <- Convolution12
I0928 09:32:12.564303  4247 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0928 09:32:12.564432  4247 net.cpp:122] Setting up BatchNorm12
I0928 09:32:12.564437  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.564440  4247 net.cpp:137] Memory required for data: 317050000
I0928 09:32:12.564445  4247 layer_factory.hpp:77] Creating layer Scale12
I0928 09:32:12.564450  4247 net.cpp:84] Creating Layer Scale12
I0928 09:32:12.564452  4247 net.cpp:406] Scale12 <- Convolution12
I0928 09:32:12.564456  4247 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0928 09:32:12.564482  4247 layer_factory.hpp:77] Creating layer Scale12
I0928 09:32:12.564558  4247 net.cpp:122] Setting up Scale12
I0928 09:32:12.564563  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.564565  4247 net.cpp:137] Memory required for data: 322067600
I0928 09:32:12.564569  4247 layer_factory.hpp:77] Creating layer M2PELU12
I0928 09:32:12.564574  4247 net.cpp:84] Creating Layer M2PELU12
I0928 09:32:12.564577  4247 net.cpp:406] M2PELU12 <- Convolution12
I0928 09:32:12.564581  4247 net.cpp:367] M2PELU12 -> Convolution12 (in-place)
I0928 09:32:12.564664  4247 net.cpp:122] Setting up M2PELU12
I0928 09:32:12.564669  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.564672  4247 net.cpp:137] Memory required for data: 327085200
I0928 09:32:12.564676  4247 layer_factory.hpp:77] Creating layer Convolution13
I0928 09:32:12.564682  4247 net.cpp:84] Creating Layer Convolution13
I0928 09:32:12.564685  4247 net.cpp:406] Convolution13 <- Convolution12
I0928 09:32:12.564689  4247 net.cpp:380] Convolution13 -> Convolution13
I0928 09:32:12.565548  4247 net.cpp:122] Setting up Convolution13
I0928 09:32:12.565558  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.565562  4247 net.cpp:137] Memory required for data: 332102800
I0928 09:32:12.565567  4247 layer_factory.hpp:77] Creating layer BatchNorm13
I0928 09:32:12.565572  4247 net.cpp:84] Creating Layer BatchNorm13
I0928 09:32:12.565575  4247 net.cpp:406] BatchNorm13 <- Convolution13
I0928 09:32:12.565579  4247 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0928 09:32:12.565706  4247 net.cpp:122] Setting up BatchNorm13
I0928 09:32:12.565711  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.565713  4247 net.cpp:137] Memory required for data: 337120400
I0928 09:32:12.565718  4247 layer_factory.hpp:77] Creating layer Scale13
I0928 09:32:12.565722  4247 net.cpp:84] Creating Layer Scale13
I0928 09:32:12.565726  4247 net.cpp:406] Scale13 <- Convolution13
I0928 09:32:12.565728  4247 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0928 09:32:12.565754  4247 layer_factory.hpp:77] Creating layer Scale13
I0928 09:32:12.565830  4247 net.cpp:122] Setting up Scale13
I0928 09:32:12.565841  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.565845  4247 net.cpp:137] Memory required for data: 342138000
I0928 09:32:12.565848  4247 layer_factory.hpp:77] Creating layer Eltwise6
I0928 09:32:12.565855  4247 net.cpp:84] Creating Layer Eltwise6
I0928 09:32:12.565857  4247 net.cpp:406] Eltwise6 <- Eltwise5_M2PELU11_0_split_1
I0928 09:32:12.565860  4247 net.cpp:406] Eltwise6 <- Convolution13
I0928 09:32:12.565863  4247 net.cpp:380] Eltwise6 -> Eltwise6
I0928 09:32:12.565882  4247 net.cpp:122] Setting up Eltwise6
I0928 09:32:12.565887  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.565891  4247 net.cpp:137] Memory required for data: 347155600
I0928 09:32:12.565892  4247 layer_factory.hpp:77] Creating layer M2PELU13
I0928 09:32:12.565901  4247 net.cpp:84] Creating Layer M2PELU13
I0928 09:32:12.565903  4247 net.cpp:406] M2PELU13 <- Eltwise6
I0928 09:32:12.565907  4247 net.cpp:367] M2PELU13 -> Eltwise6 (in-place)
I0928 09:32:12.565992  4247 net.cpp:122] Setting up M2PELU13
I0928 09:32:12.565997  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.566000  4247 net.cpp:137] Memory required for data: 352173200
I0928 09:32:12.566004  4247 layer_factory.hpp:77] Creating layer Eltwise6_M2PELU13_0_split
I0928 09:32:12.566009  4247 net.cpp:84] Creating Layer Eltwise6_M2PELU13_0_split
I0928 09:32:12.566011  4247 net.cpp:406] Eltwise6_M2PELU13_0_split <- Eltwise6
I0928 09:32:12.566015  4247 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_0
I0928 09:32:12.566020  4247 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_1
I0928 09:32:12.566043  4247 net.cpp:122] Setting up Eltwise6_M2PELU13_0_split
I0928 09:32:12.566048  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.566051  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.566053  4247 net.cpp:137] Memory required for data: 362208400
I0928 09:32:12.566056  4247 layer_factory.hpp:77] Creating layer Convolution14
I0928 09:32:12.566061  4247 net.cpp:84] Creating Layer Convolution14
I0928 09:32:12.566063  4247 net.cpp:406] Convolution14 <- Eltwise6_M2PELU13_0_split_0
I0928 09:32:12.566067  4247 net.cpp:380] Convolution14 -> Convolution14
I0928 09:32:12.566949  4247 net.cpp:122] Setting up Convolution14
I0928 09:32:12.566958  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.566961  4247 net.cpp:137] Memory required for data: 367226000
I0928 09:32:12.566964  4247 layer_factory.hpp:77] Creating layer BatchNorm14
I0928 09:32:12.566970  4247 net.cpp:84] Creating Layer BatchNorm14
I0928 09:32:12.566972  4247 net.cpp:406] BatchNorm14 <- Convolution14
I0928 09:32:12.566977  4247 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0928 09:32:12.567106  4247 net.cpp:122] Setting up BatchNorm14
I0928 09:32:12.567111  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.567112  4247 net.cpp:137] Memory required for data: 372243600
I0928 09:32:12.567117  4247 layer_factory.hpp:77] Creating layer Scale14
I0928 09:32:12.567121  4247 net.cpp:84] Creating Layer Scale14
I0928 09:32:12.567123  4247 net.cpp:406] Scale14 <- Convolution14
I0928 09:32:12.567126  4247 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0928 09:32:12.567152  4247 layer_factory.hpp:77] Creating layer Scale14
I0928 09:32:12.567227  4247 net.cpp:122] Setting up Scale14
I0928 09:32:12.567231  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.567234  4247 net.cpp:137] Memory required for data: 377261200
I0928 09:32:12.567237  4247 layer_factory.hpp:77] Creating layer M2PELU14
I0928 09:32:12.567242  4247 net.cpp:84] Creating Layer M2PELU14
I0928 09:32:12.567245  4247 net.cpp:406] M2PELU14 <- Convolution14
I0928 09:32:12.567248  4247 net.cpp:367] M2PELU14 -> Convolution14 (in-place)
I0928 09:32:12.567332  4247 net.cpp:122] Setting up M2PELU14
I0928 09:32:12.567337  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.567338  4247 net.cpp:137] Memory required for data: 382278800
I0928 09:32:12.567348  4247 layer_factory.hpp:77] Creating layer Convolution15
I0928 09:32:12.567356  4247 net.cpp:84] Creating Layer Convolution15
I0928 09:32:12.567358  4247 net.cpp:406] Convolution15 <- Convolution14
I0928 09:32:12.567363  4247 net.cpp:380] Convolution15 -> Convolution15
I0928 09:32:12.568224  4247 net.cpp:122] Setting up Convolution15
I0928 09:32:12.568233  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.568235  4247 net.cpp:137] Memory required for data: 387296400
I0928 09:32:12.568239  4247 layer_factory.hpp:77] Creating layer BatchNorm15
I0928 09:32:12.568245  4247 net.cpp:84] Creating Layer BatchNorm15
I0928 09:32:12.568248  4247 net.cpp:406] BatchNorm15 <- Convolution15
I0928 09:32:12.568253  4247 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0928 09:32:12.568382  4247 net.cpp:122] Setting up BatchNorm15
I0928 09:32:12.568387  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.568388  4247 net.cpp:137] Memory required for data: 392314000
I0928 09:32:12.568403  4247 layer_factory.hpp:77] Creating layer Scale15
I0928 09:32:12.568408  4247 net.cpp:84] Creating Layer Scale15
I0928 09:32:12.568409  4247 net.cpp:406] Scale15 <- Convolution15
I0928 09:32:12.568413  4247 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0928 09:32:12.568439  4247 layer_factory.hpp:77] Creating layer Scale15
I0928 09:32:12.568513  4247 net.cpp:122] Setting up Scale15
I0928 09:32:12.568518  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.568521  4247 net.cpp:137] Memory required for data: 397331600
I0928 09:32:12.568523  4247 layer_factory.hpp:77] Creating layer Eltwise7
I0928 09:32:12.568527  4247 net.cpp:84] Creating Layer Eltwise7
I0928 09:32:12.568529  4247 net.cpp:406] Eltwise7 <- Eltwise6_M2PELU13_0_split_1
I0928 09:32:12.568532  4247 net.cpp:406] Eltwise7 <- Convolution15
I0928 09:32:12.568537  4247 net.cpp:380] Eltwise7 -> Eltwise7
I0928 09:32:12.568552  4247 net.cpp:122] Setting up Eltwise7
I0928 09:32:12.568557  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.568558  4247 net.cpp:137] Memory required for data: 402349200
I0928 09:32:12.568560  4247 layer_factory.hpp:77] Creating layer M2PELU15
I0928 09:32:12.568564  4247 net.cpp:84] Creating Layer M2PELU15
I0928 09:32:12.568567  4247 net.cpp:406] M2PELU15 <- Eltwise7
I0928 09:32:12.568570  4247 net.cpp:367] M2PELU15 -> Eltwise7 (in-place)
I0928 09:32:12.568653  4247 net.cpp:122] Setting up M2PELU15
I0928 09:32:12.568657  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.568660  4247 net.cpp:137] Memory required for data: 407366800
I0928 09:32:12.568663  4247 layer_factory.hpp:77] Creating layer Eltwise7_M2PELU15_0_split
I0928 09:32:12.568666  4247 net.cpp:84] Creating Layer Eltwise7_M2PELU15_0_split
I0928 09:32:12.568668  4247 net.cpp:406] Eltwise7_M2PELU15_0_split <- Eltwise7
I0928 09:32:12.568672  4247 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_0
I0928 09:32:12.568676  4247 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_1
I0928 09:32:12.568697  4247 net.cpp:122] Setting up Eltwise7_M2PELU15_0_split
I0928 09:32:12.568701  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.568704  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.568706  4247 net.cpp:137] Memory required for data: 417402000
I0928 09:32:12.568708  4247 layer_factory.hpp:77] Creating layer Convolution16
I0928 09:32:12.568714  4247 net.cpp:84] Creating Layer Convolution16
I0928 09:32:12.568717  4247 net.cpp:406] Convolution16 <- Eltwise7_M2PELU15_0_split_0
I0928 09:32:12.568720  4247 net.cpp:380] Convolution16 -> Convolution16
I0928 09:32:12.569572  4247 net.cpp:122] Setting up Convolution16
I0928 09:32:12.569581  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.569583  4247 net.cpp:137] Memory required for data: 422419600
I0928 09:32:12.569587  4247 layer_factory.hpp:77] Creating layer BatchNorm16
I0928 09:32:12.569592  4247 net.cpp:84] Creating Layer BatchNorm16
I0928 09:32:12.569595  4247 net.cpp:406] BatchNorm16 <- Convolution16
I0928 09:32:12.569604  4247 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0928 09:32:12.569735  4247 net.cpp:122] Setting up BatchNorm16
I0928 09:32:12.569738  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.569741  4247 net.cpp:137] Memory required for data: 427437200
I0928 09:32:12.569746  4247 layer_factory.hpp:77] Creating layer Scale16
I0928 09:32:12.569749  4247 net.cpp:84] Creating Layer Scale16
I0928 09:32:12.569751  4247 net.cpp:406] Scale16 <- Convolution16
I0928 09:32:12.569754  4247 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0928 09:32:12.569782  4247 layer_factory.hpp:77] Creating layer Scale16
I0928 09:32:12.569857  4247 net.cpp:122] Setting up Scale16
I0928 09:32:12.569861  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.569864  4247 net.cpp:137] Memory required for data: 432454800
I0928 09:32:12.569867  4247 layer_factory.hpp:77] Creating layer M2PELU16
I0928 09:32:12.569872  4247 net.cpp:84] Creating Layer M2PELU16
I0928 09:32:12.569875  4247 net.cpp:406] M2PELU16 <- Convolution16
I0928 09:32:12.569877  4247 net.cpp:367] M2PELU16 -> Convolution16 (in-place)
I0928 09:32:12.569958  4247 net.cpp:122] Setting up M2PELU16
I0928 09:32:12.569963  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.569965  4247 net.cpp:137] Memory required for data: 437472400
I0928 09:32:12.569968  4247 layer_factory.hpp:77] Creating layer Convolution17
I0928 09:32:12.569975  4247 net.cpp:84] Creating Layer Convolution17
I0928 09:32:12.569977  4247 net.cpp:406] Convolution17 <- Convolution16
I0928 09:32:12.569983  4247 net.cpp:380] Convolution17 -> Convolution17
I0928 09:32:12.570543  4247 net.cpp:122] Setting up Convolution17
I0928 09:32:12.570550  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.570554  4247 net.cpp:137] Memory required for data: 442490000
I0928 09:32:12.570566  4247 layer_factory.hpp:77] Creating layer BatchNorm17
I0928 09:32:12.570571  4247 net.cpp:84] Creating Layer BatchNorm17
I0928 09:32:12.570574  4247 net.cpp:406] BatchNorm17 <- Convolution17
I0928 09:32:12.570577  4247 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0928 09:32:12.570704  4247 net.cpp:122] Setting up BatchNorm17
I0928 09:32:12.570708  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.570710  4247 net.cpp:137] Memory required for data: 447507600
I0928 09:32:12.570714  4247 layer_factory.hpp:77] Creating layer Scale17
I0928 09:32:12.570719  4247 net.cpp:84] Creating Layer Scale17
I0928 09:32:12.570721  4247 net.cpp:406] Scale17 <- Convolution17
I0928 09:32:12.570724  4247 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0928 09:32:12.570749  4247 layer_factory.hpp:77] Creating layer Scale17
I0928 09:32:12.570823  4247 net.cpp:122] Setting up Scale17
I0928 09:32:12.570827  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.570829  4247 net.cpp:137] Memory required for data: 452525200
I0928 09:32:12.570832  4247 layer_factory.hpp:77] Creating layer Eltwise8
I0928 09:32:12.570837  4247 net.cpp:84] Creating Layer Eltwise8
I0928 09:32:12.570838  4247 net.cpp:406] Eltwise8 <- Eltwise7_M2PELU15_0_split_1
I0928 09:32:12.570842  4247 net.cpp:406] Eltwise8 <- Convolution17
I0928 09:32:12.570845  4247 net.cpp:380] Eltwise8 -> Eltwise8
I0928 09:32:12.570859  4247 net.cpp:122] Setting up Eltwise8
I0928 09:32:12.570863  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.570864  4247 net.cpp:137] Memory required for data: 457542800
I0928 09:32:12.570866  4247 layer_factory.hpp:77] Creating layer M2PELU17
I0928 09:32:12.570871  4247 net.cpp:84] Creating Layer M2PELU17
I0928 09:32:12.570873  4247 net.cpp:406] M2PELU17 <- Eltwise8
I0928 09:32:12.570876  4247 net.cpp:367] M2PELU17 -> Eltwise8 (in-place)
I0928 09:32:12.570960  4247 net.cpp:122] Setting up M2PELU17
I0928 09:32:12.570964  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.570966  4247 net.cpp:137] Memory required for data: 462560400
I0928 09:32:12.570969  4247 layer_factory.hpp:77] Creating layer Eltwise8_M2PELU17_0_split
I0928 09:32:12.570981  4247 net.cpp:84] Creating Layer Eltwise8_M2PELU17_0_split
I0928 09:32:12.570983  4247 net.cpp:406] Eltwise8_M2PELU17_0_split <- Eltwise8
I0928 09:32:12.570986  4247 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_0
I0928 09:32:12.570991  4247 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_1
I0928 09:32:12.571012  4247 net.cpp:122] Setting up Eltwise8_M2PELU17_0_split
I0928 09:32:12.571017  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.571019  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.571022  4247 net.cpp:137] Memory required for data: 472595600
I0928 09:32:12.571023  4247 layer_factory.hpp:77] Creating layer Convolution18
I0928 09:32:12.571029  4247 net.cpp:84] Creating Layer Convolution18
I0928 09:32:12.571032  4247 net.cpp:406] Convolution18 <- Eltwise8_M2PELU17_0_split_0
I0928 09:32:12.571035  4247 net.cpp:380] Convolution18 -> Convolution18
I0928 09:32:12.571889  4247 net.cpp:122] Setting up Convolution18
I0928 09:32:12.571897  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.571899  4247 net.cpp:137] Memory required for data: 477613200
I0928 09:32:12.571904  4247 layer_factory.hpp:77] Creating layer BatchNorm18
I0928 09:32:12.571909  4247 net.cpp:84] Creating Layer BatchNorm18
I0928 09:32:12.571912  4247 net.cpp:406] BatchNorm18 <- Convolution18
I0928 09:32:12.571915  4247 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0928 09:32:12.572046  4247 net.cpp:122] Setting up BatchNorm18
I0928 09:32:12.572051  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.572052  4247 net.cpp:137] Memory required for data: 482630800
I0928 09:32:12.572057  4247 layer_factory.hpp:77] Creating layer Scale18
I0928 09:32:12.572062  4247 net.cpp:84] Creating Layer Scale18
I0928 09:32:12.572064  4247 net.cpp:406] Scale18 <- Convolution18
I0928 09:32:12.572067  4247 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0928 09:32:12.572093  4247 layer_factory.hpp:77] Creating layer Scale18
I0928 09:32:12.572167  4247 net.cpp:122] Setting up Scale18
I0928 09:32:12.572172  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.572175  4247 net.cpp:137] Memory required for data: 487648400
I0928 09:32:12.572177  4247 layer_factory.hpp:77] Creating layer M2PELU18
I0928 09:32:12.572182  4247 net.cpp:84] Creating Layer M2PELU18
I0928 09:32:12.572185  4247 net.cpp:406] M2PELU18 <- Convolution18
I0928 09:32:12.572188  4247 net.cpp:367] M2PELU18 -> Convolution18 (in-place)
I0928 09:32:12.572271  4247 net.cpp:122] Setting up M2PELU18
I0928 09:32:12.572275  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.572278  4247 net.cpp:137] Memory required for data: 492666000
I0928 09:32:12.572281  4247 layer_factory.hpp:77] Creating layer Convolution19
I0928 09:32:12.572288  4247 net.cpp:84] Creating Layer Convolution19
I0928 09:32:12.572289  4247 net.cpp:406] Convolution19 <- Convolution18
I0928 09:32:12.572293  4247 net.cpp:380] Convolution19 -> Convolution19
I0928 09:32:12.573165  4247 net.cpp:122] Setting up Convolution19
I0928 09:32:12.573174  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.573176  4247 net.cpp:137] Memory required for data: 497683600
I0928 09:32:12.573181  4247 layer_factory.hpp:77] Creating layer BatchNorm19
I0928 09:32:12.573186  4247 net.cpp:84] Creating Layer BatchNorm19
I0928 09:32:12.573189  4247 net.cpp:406] BatchNorm19 <- Convolution19
I0928 09:32:12.573192  4247 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0928 09:32:12.573321  4247 net.cpp:122] Setting up BatchNorm19
I0928 09:32:12.573325  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.573328  4247 net.cpp:137] Memory required for data: 502701200
I0928 09:32:12.573333  4247 layer_factory.hpp:77] Creating layer Scale19
I0928 09:32:12.573335  4247 net.cpp:84] Creating Layer Scale19
I0928 09:32:12.573338  4247 net.cpp:406] Scale19 <- Convolution19
I0928 09:32:12.573341  4247 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0928 09:32:12.573367  4247 layer_factory.hpp:77] Creating layer Scale19
I0928 09:32:12.573451  4247 net.cpp:122] Setting up Scale19
I0928 09:32:12.573454  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.573457  4247 net.cpp:137] Memory required for data: 507718800
I0928 09:32:12.573460  4247 layer_factory.hpp:77] Creating layer Eltwise9
I0928 09:32:12.573465  4247 net.cpp:84] Creating Layer Eltwise9
I0928 09:32:12.573467  4247 net.cpp:406] Eltwise9 <- Eltwise8_M2PELU17_0_split_1
I0928 09:32:12.573470  4247 net.cpp:406] Eltwise9 <- Convolution19
I0928 09:32:12.573473  4247 net.cpp:380] Eltwise9 -> Eltwise9
I0928 09:32:12.573488  4247 net.cpp:122] Setting up Eltwise9
I0928 09:32:12.573493  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.573494  4247 net.cpp:137] Memory required for data: 512736400
I0928 09:32:12.573496  4247 layer_factory.hpp:77] Creating layer M2PELU19
I0928 09:32:12.573500  4247 net.cpp:84] Creating Layer M2PELU19
I0928 09:32:12.573503  4247 net.cpp:406] M2PELU19 <- Eltwise9
I0928 09:32:12.573505  4247 net.cpp:367] M2PELU19 -> Eltwise9 (in-place)
I0928 09:32:12.573587  4247 net.cpp:122] Setting up M2PELU19
I0928 09:32:12.573592  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.573595  4247 net.cpp:137] Memory required for data: 517754000
I0928 09:32:12.573597  4247 layer_factory.hpp:77] Creating layer Eltwise9_M2PELU19_0_split
I0928 09:32:12.573601  4247 net.cpp:84] Creating Layer Eltwise9_M2PELU19_0_split
I0928 09:32:12.573603  4247 net.cpp:406] Eltwise9_M2PELU19_0_split <- Eltwise9
I0928 09:32:12.573606  4247 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_0
I0928 09:32:12.573611  4247 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_1
I0928 09:32:12.573633  4247 net.cpp:122] Setting up Eltwise9_M2PELU19_0_split
I0928 09:32:12.573637  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.573639  4247 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 09:32:12.573642  4247 net.cpp:137] Memory required for data: 527789200
I0928 09:32:12.573643  4247 layer_factory.hpp:77] Creating layer Convolution20
I0928 09:32:12.573650  4247 net.cpp:84] Creating Layer Convolution20
I0928 09:32:12.573653  4247 net.cpp:406] Convolution20 <- Eltwise9_M2PELU19_0_split_0
I0928 09:32:12.573657  4247 net.cpp:380] Convolution20 -> Convolution20
I0928 09:32:12.574836  4247 net.cpp:122] Setting up Convolution20
I0928 09:32:12.574853  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.574856  4247 net.cpp:137] Memory required for data: 530298000
I0928 09:32:12.574861  4247 layer_factory.hpp:77] Creating layer BatchNorm20
I0928 09:32:12.574875  4247 net.cpp:84] Creating Layer BatchNorm20
I0928 09:32:12.574878  4247 net.cpp:406] BatchNorm20 <- Convolution20
I0928 09:32:12.574882  4247 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0928 09:32:12.575033  4247 net.cpp:122] Setting up BatchNorm20
I0928 09:32:12.575038  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.575040  4247 net.cpp:137] Memory required for data: 532806800
I0928 09:32:12.575045  4247 layer_factory.hpp:77] Creating layer Scale20
I0928 09:32:12.575049  4247 net.cpp:84] Creating Layer Scale20
I0928 09:32:12.575052  4247 net.cpp:406] Scale20 <- Convolution20
I0928 09:32:12.575054  4247 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0928 09:32:12.575081  4247 layer_factory.hpp:77] Creating layer Scale20
I0928 09:32:12.575156  4247 net.cpp:122] Setting up Scale20
I0928 09:32:12.575161  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.575163  4247 net.cpp:137] Memory required for data: 535315600
I0928 09:32:12.575167  4247 layer_factory.hpp:77] Creating layer Convolution21
I0928 09:32:12.575173  4247 net.cpp:84] Creating Layer Convolution21
I0928 09:32:12.575176  4247 net.cpp:406] Convolution21 <- Eltwise9_M2PELU19_0_split_1
I0928 09:32:12.575181  4247 net.cpp:380] Convolution21 -> Convolution21
I0928 09:32:12.576954  4247 net.cpp:122] Setting up Convolution21
I0928 09:32:12.576963  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.576972  4247 net.cpp:137] Memory required for data: 537824400
I0928 09:32:12.576977  4247 layer_factory.hpp:77] Creating layer BatchNorm21
I0928 09:32:12.576982  4247 net.cpp:84] Creating Layer BatchNorm21
I0928 09:32:12.576985  4247 net.cpp:406] BatchNorm21 <- Convolution21
I0928 09:32:12.576989  4247 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0928 09:32:12.577124  4247 net.cpp:122] Setting up BatchNorm21
I0928 09:32:12.577139  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.577142  4247 net.cpp:137] Memory required for data: 540333200
I0928 09:32:12.577147  4247 layer_factory.hpp:77] Creating layer Scale21
I0928 09:32:12.577150  4247 net.cpp:84] Creating Layer Scale21
I0928 09:32:12.577153  4247 net.cpp:406] Scale21 <- Convolution21
I0928 09:32:12.577157  4247 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0928 09:32:12.577183  4247 layer_factory.hpp:77] Creating layer Scale21
I0928 09:32:12.577312  4247 net.cpp:122] Setting up Scale21
I0928 09:32:12.577316  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.577318  4247 net.cpp:137] Memory required for data: 542842000
I0928 09:32:12.577323  4247 layer_factory.hpp:77] Creating layer M2PELU20
I0928 09:32:12.577337  4247 net.cpp:84] Creating Layer M2PELU20
I0928 09:32:12.577339  4247 net.cpp:406] M2PELU20 <- Convolution21
I0928 09:32:12.577342  4247 net.cpp:367] M2PELU20 -> Convolution21 (in-place)
I0928 09:32:12.577428  4247 net.cpp:122] Setting up M2PELU20
I0928 09:32:12.577433  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.577435  4247 net.cpp:137] Memory required for data: 545350800
I0928 09:32:12.577438  4247 layer_factory.hpp:77] Creating layer Convolution22
I0928 09:32:12.577445  4247 net.cpp:84] Creating Layer Convolution22
I0928 09:32:12.577448  4247 net.cpp:406] Convolution22 <- Convolution21
I0928 09:32:12.577451  4247 net.cpp:380] Convolution22 -> Convolution22
I0928 09:32:12.578514  4247 net.cpp:122] Setting up Convolution22
I0928 09:32:12.578527  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.578531  4247 net.cpp:137] Memory required for data: 547859600
I0928 09:32:12.578536  4247 layer_factory.hpp:77] Creating layer BatchNorm22
I0928 09:32:12.578541  4247 net.cpp:84] Creating Layer BatchNorm22
I0928 09:32:12.578543  4247 net.cpp:406] BatchNorm22 <- Convolution22
I0928 09:32:12.578557  4247 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0928 09:32:12.578709  4247 net.cpp:122] Setting up BatchNorm22
I0928 09:32:12.578714  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.578716  4247 net.cpp:137] Memory required for data: 550368400
I0928 09:32:12.578722  4247 layer_factory.hpp:77] Creating layer Scale22
I0928 09:32:12.578727  4247 net.cpp:84] Creating Layer Scale22
I0928 09:32:12.578728  4247 net.cpp:406] Scale22 <- Convolution22
I0928 09:32:12.578732  4247 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0928 09:32:12.578758  4247 layer_factory.hpp:77] Creating layer Scale22
I0928 09:32:12.578832  4247 net.cpp:122] Setting up Scale22
I0928 09:32:12.578836  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.578848  4247 net.cpp:137] Memory required for data: 552877200
I0928 09:32:12.578852  4247 layer_factory.hpp:77] Creating layer Eltwise10
I0928 09:32:12.578856  4247 net.cpp:84] Creating Layer Eltwise10
I0928 09:32:12.578860  4247 net.cpp:406] Eltwise10 <- Convolution20
I0928 09:32:12.578861  4247 net.cpp:406] Eltwise10 <- Convolution22
I0928 09:32:12.578866  4247 net.cpp:380] Eltwise10 -> Eltwise10
I0928 09:32:12.578881  4247 net.cpp:122] Setting up Eltwise10
I0928 09:32:12.578886  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.578887  4247 net.cpp:137] Memory required for data: 555386000
I0928 09:32:12.578889  4247 layer_factory.hpp:77] Creating layer M2PELU21
I0928 09:32:12.578894  4247 net.cpp:84] Creating Layer M2PELU21
I0928 09:32:12.578896  4247 net.cpp:406] M2PELU21 <- Eltwise10
I0928 09:32:12.578899  4247 net.cpp:367] M2PELU21 -> Eltwise10 (in-place)
I0928 09:32:12.578984  4247 net.cpp:122] Setting up M2PELU21
I0928 09:32:12.578995  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.578997  4247 net.cpp:137] Memory required for data: 557894800
I0928 09:32:12.579001  4247 layer_factory.hpp:77] Creating layer Eltwise10_M2PELU21_0_split
I0928 09:32:12.579005  4247 net.cpp:84] Creating Layer Eltwise10_M2PELU21_0_split
I0928 09:32:12.579007  4247 net.cpp:406] Eltwise10_M2PELU21_0_split <- Eltwise10
I0928 09:32:12.579012  4247 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_0
I0928 09:32:12.579016  4247 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_1
I0928 09:32:12.579041  4247 net.cpp:122] Setting up Eltwise10_M2PELU21_0_split
I0928 09:32:12.579044  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.579046  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.579048  4247 net.cpp:137] Memory required for data: 562912400
I0928 09:32:12.579051  4247 layer_factory.hpp:77] Creating layer Convolution23
I0928 09:32:12.579057  4247 net.cpp:84] Creating Layer Convolution23
I0928 09:32:12.579059  4247 net.cpp:406] Convolution23 <- Eltwise10_M2PELU21_0_split_0
I0928 09:32:12.579063  4247 net.cpp:380] Convolution23 -> Convolution23
I0928 09:32:12.580418  4247 net.cpp:122] Setting up Convolution23
I0928 09:32:12.580427  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.580430  4247 net.cpp:137] Memory required for data: 565421200
I0928 09:32:12.580435  4247 layer_factory.hpp:77] Creating layer BatchNorm23
I0928 09:32:12.580440  4247 net.cpp:84] Creating Layer BatchNorm23
I0928 09:32:12.580442  4247 net.cpp:406] BatchNorm23 <- Convolution23
I0928 09:32:12.580446  4247 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0928 09:32:12.580584  4247 net.cpp:122] Setting up BatchNorm23
I0928 09:32:12.580587  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.580590  4247 net.cpp:137] Memory required for data: 567930000
I0928 09:32:12.580595  4247 layer_factory.hpp:77] Creating layer Scale23
I0928 09:32:12.580598  4247 net.cpp:84] Creating Layer Scale23
I0928 09:32:12.580600  4247 net.cpp:406] Scale23 <- Convolution23
I0928 09:32:12.580605  4247 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0928 09:32:12.580631  4247 layer_factory.hpp:77] Creating layer Scale23
I0928 09:32:12.580708  4247 net.cpp:122] Setting up Scale23
I0928 09:32:12.580713  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.580715  4247 net.cpp:137] Memory required for data: 570438800
I0928 09:32:12.580719  4247 layer_factory.hpp:77] Creating layer M2PELU22
I0928 09:32:12.580724  4247 net.cpp:84] Creating Layer M2PELU22
I0928 09:32:12.580727  4247 net.cpp:406] M2PELU22 <- Convolution23
I0928 09:32:12.580730  4247 net.cpp:367] M2PELU22 -> Convolution23 (in-place)
I0928 09:32:12.580813  4247 net.cpp:122] Setting up M2PELU22
I0928 09:32:12.580818  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.580821  4247 net.cpp:137] Memory required for data: 572947600
I0928 09:32:12.580824  4247 layer_factory.hpp:77] Creating layer Convolution24
I0928 09:32:12.580831  4247 net.cpp:84] Creating Layer Convolution24
I0928 09:32:12.580832  4247 net.cpp:406] Convolution24 <- Convolution23
I0928 09:32:12.580837  4247 net.cpp:380] Convolution24 -> Convolution24
I0928 09:32:12.581887  4247 net.cpp:122] Setting up Convolution24
I0928 09:32:12.581894  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.581897  4247 net.cpp:137] Memory required for data: 575456400
I0928 09:32:12.581902  4247 layer_factory.hpp:77] Creating layer BatchNorm24
I0928 09:32:12.581907  4247 net.cpp:84] Creating Layer BatchNorm24
I0928 09:32:12.581910  4247 net.cpp:406] BatchNorm24 <- Convolution24
I0928 09:32:12.581913  4247 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0928 09:32:12.582051  4247 net.cpp:122] Setting up BatchNorm24
I0928 09:32:12.582056  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.582057  4247 net.cpp:137] Memory required for data: 577965200
I0928 09:32:12.582062  4247 layer_factory.hpp:77] Creating layer Scale24
I0928 09:32:12.582073  4247 net.cpp:84] Creating Layer Scale24
I0928 09:32:12.582077  4247 net.cpp:406] Scale24 <- Convolution24
I0928 09:32:12.582079  4247 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0928 09:32:12.582106  4247 layer_factory.hpp:77] Creating layer Scale24
I0928 09:32:12.582185  4247 net.cpp:122] Setting up Scale24
I0928 09:32:12.582190  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.582191  4247 net.cpp:137] Memory required for data: 580474000
I0928 09:32:12.582195  4247 layer_factory.hpp:77] Creating layer Eltwise11
I0928 09:32:12.582200  4247 net.cpp:84] Creating Layer Eltwise11
I0928 09:32:12.582202  4247 net.cpp:406] Eltwise11 <- Eltwise10_M2PELU21_0_split_1
I0928 09:32:12.582206  4247 net.cpp:406] Eltwise11 <- Convolution24
I0928 09:32:12.582208  4247 net.cpp:380] Eltwise11 -> Eltwise11
I0928 09:32:12.582224  4247 net.cpp:122] Setting up Eltwise11
I0928 09:32:12.582228  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.582231  4247 net.cpp:137] Memory required for data: 582982800
I0928 09:32:12.582232  4247 layer_factory.hpp:77] Creating layer M2PELU23
I0928 09:32:12.582237  4247 net.cpp:84] Creating Layer M2PELU23
I0928 09:32:12.582239  4247 net.cpp:406] M2PELU23 <- Eltwise11
I0928 09:32:12.582243  4247 net.cpp:367] M2PELU23 -> Eltwise11 (in-place)
I0928 09:32:12.582327  4247 net.cpp:122] Setting up M2PELU23
I0928 09:32:12.582332  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.582334  4247 net.cpp:137] Memory required for data: 585491600
I0928 09:32:12.582337  4247 layer_factory.hpp:77] Creating layer Eltwise11_M2PELU23_0_split
I0928 09:32:12.582342  4247 net.cpp:84] Creating Layer Eltwise11_M2PELU23_0_split
I0928 09:32:12.582345  4247 net.cpp:406] Eltwise11_M2PELU23_0_split <- Eltwise11
I0928 09:32:12.582348  4247 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_0
I0928 09:32:12.582352  4247 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_1
I0928 09:32:12.582376  4247 net.cpp:122] Setting up Eltwise11_M2PELU23_0_split
I0928 09:32:12.582381  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.582382  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.582384  4247 net.cpp:137] Memory required for data: 590509200
I0928 09:32:12.582386  4247 layer_factory.hpp:77] Creating layer Convolution25
I0928 09:32:12.582392  4247 net.cpp:84] Creating Layer Convolution25
I0928 09:32:12.582394  4247 net.cpp:406] Convolution25 <- Eltwise11_M2PELU23_0_split_0
I0928 09:32:12.582399  4247 net.cpp:380] Convolution25 -> Convolution25
I0928 09:32:12.583441  4247 net.cpp:122] Setting up Convolution25
I0928 09:32:12.583451  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.583453  4247 net.cpp:137] Memory required for data: 593018000
I0928 09:32:12.583457  4247 layer_factory.hpp:77] Creating layer BatchNorm25
I0928 09:32:12.583463  4247 net.cpp:84] Creating Layer BatchNorm25
I0928 09:32:12.583465  4247 net.cpp:406] BatchNorm25 <- Convolution25
I0928 09:32:12.583469  4247 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0928 09:32:12.583602  4247 net.cpp:122] Setting up BatchNorm25
I0928 09:32:12.583607  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.583609  4247 net.cpp:137] Memory required for data: 595526800
I0928 09:32:12.583614  4247 layer_factory.hpp:77] Creating layer Scale25
I0928 09:32:12.583618  4247 net.cpp:84] Creating Layer Scale25
I0928 09:32:12.583621  4247 net.cpp:406] Scale25 <- Convolution25
I0928 09:32:12.583623  4247 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0928 09:32:12.583650  4247 layer_factory.hpp:77] Creating layer Scale25
I0928 09:32:12.583725  4247 net.cpp:122] Setting up Scale25
I0928 09:32:12.583729  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.583731  4247 net.cpp:137] Memory required for data: 598035600
I0928 09:32:12.583735  4247 layer_factory.hpp:77] Creating layer M2PELU24
I0928 09:32:12.583740  4247 net.cpp:84] Creating Layer M2PELU24
I0928 09:32:12.583742  4247 net.cpp:406] M2PELU24 <- Convolution25
I0928 09:32:12.583753  4247 net.cpp:367] M2PELU24 -> Convolution25 (in-place)
I0928 09:32:12.583839  4247 net.cpp:122] Setting up M2PELU24
I0928 09:32:12.583843  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.583845  4247 net.cpp:137] Memory required for data: 600544400
I0928 09:32:12.583849  4247 layer_factory.hpp:77] Creating layer Convolution26
I0928 09:32:12.583856  4247 net.cpp:84] Creating Layer Convolution26
I0928 09:32:12.583858  4247 net.cpp:406] Convolution26 <- Convolution25
I0928 09:32:12.583863  4247 net.cpp:380] Convolution26 -> Convolution26
I0928 09:32:12.584883  4247 net.cpp:122] Setting up Convolution26
I0928 09:32:12.584892  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.584893  4247 net.cpp:137] Memory required for data: 603053200
I0928 09:32:12.584898  4247 layer_factory.hpp:77] Creating layer BatchNorm26
I0928 09:32:12.584903  4247 net.cpp:84] Creating Layer BatchNorm26
I0928 09:32:12.584905  4247 net.cpp:406] BatchNorm26 <- Convolution26
I0928 09:32:12.584909  4247 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0928 09:32:12.585042  4247 net.cpp:122] Setting up BatchNorm26
I0928 09:32:12.585047  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.585048  4247 net.cpp:137] Memory required for data: 605562000
I0928 09:32:12.585053  4247 layer_factory.hpp:77] Creating layer Scale26
I0928 09:32:12.585057  4247 net.cpp:84] Creating Layer Scale26
I0928 09:32:12.585060  4247 net.cpp:406] Scale26 <- Convolution26
I0928 09:32:12.585063  4247 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0928 09:32:12.585089  4247 layer_factory.hpp:77] Creating layer Scale26
I0928 09:32:12.585165  4247 net.cpp:122] Setting up Scale26
I0928 09:32:12.585170  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.585172  4247 net.cpp:137] Memory required for data: 608070800
I0928 09:32:12.585175  4247 layer_factory.hpp:77] Creating layer Eltwise12
I0928 09:32:12.585180  4247 net.cpp:84] Creating Layer Eltwise12
I0928 09:32:12.585183  4247 net.cpp:406] Eltwise12 <- Eltwise11_M2PELU23_0_split_1
I0928 09:32:12.585186  4247 net.cpp:406] Eltwise12 <- Convolution26
I0928 09:32:12.585188  4247 net.cpp:380] Eltwise12 -> Eltwise12
I0928 09:32:12.585204  4247 net.cpp:122] Setting up Eltwise12
I0928 09:32:12.585208  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.585211  4247 net.cpp:137] Memory required for data: 610579600
I0928 09:32:12.585212  4247 layer_factory.hpp:77] Creating layer M2PELU25
I0928 09:32:12.585216  4247 net.cpp:84] Creating Layer M2PELU25
I0928 09:32:12.585218  4247 net.cpp:406] M2PELU25 <- Eltwise12
I0928 09:32:12.585222  4247 net.cpp:367] M2PELU25 -> Eltwise12 (in-place)
I0928 09:32:12.585304  4247 net.cpp:122] Setting up M2PELU25
I0928 09:32:12.585309  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.585311  4247 net.cpp:137] Memory required for data: 613088400
I0928 09:32:12.585314  4247 layer_factory.hpp:77] Creating layer Eltwise12_M2PELU25_0_split
I0928 09:32:12.585326  4247 net.cpp:84] Creating Layer Eltwise12_M2PELU25_0_split
I0928 09:32:12.585330  4247 net.cpp:406] Eltwise12_M2PELU25_0_split <- Eltwise12
I0928 09:32:12.585333  4247 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_0
I0928 09:32:12.585341  4247 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_1
I0928 09:32:12.585366  4247 net.cpp:122] Setting up Eltwise12_M2PELU25_0_split
I0928 09:32:12.585371  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.585373  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.585376  4247 net.cpp:137] Memory required for data: 618106000
I0928 09:32:12.585378  4247 layer_factory.hpp:77] Creating layer Convolution27
I0928 09:32:12.585384  4247 net.cpp:84] Creating Layer Convolution27
I0928 09:32:12.585386  4247 net.cpp:406] Convolution27 <- Eltwise12_M2PELU25_0_split_0
I0928 09:32:12.585391  4247 net.cpp:380] Convolution27 -> Convolution27
I0928 09:32:12.586087  4247 net.cpp:122] Setting up Convolution27
I0928 09:32:12.586094  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.586103  4247 net.cpp:137] Memory required for data: 620614800
I0928 09:32:12.586107  4247 layer_factory.hpp:77] Creating layer BatchNorm27
I0928 09:32:12.586113  4247 net.cpp:84] Creating Layer BatchNorm27
I0928 09:32:12.586117  4247 net.cpp:406] BatchNorm27 <- Convolution27
I0928 09:32:12.586119  4247 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0928 09:32:12.586253  4247 net.cpp:122] Setting up BatchNorm27
I0928 09:32:12.586258  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.586261  4247 net.cpp:137] Memory required for data: 623123600
I0928 09:32:12.586264  4247 layer_factory.hpp:77] Creating layer Scale27
I0928 09:32:12.586269  4247 net.cpp:84] Creating Layer Scale27
I0928 09:32:12.586272  4247 net.cpp:406] Scale27 <- Convolution27
I0928 09:32:12.586274  4247 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0928 09:32:12.586300  4247 layer_factory.hpp:77] Creating layer Scale27
I0928 09:32:12.586375  4247 net.cpp:122] Setting up Scale27
I0928 09:32:12.586380  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.586381  4247 net.cpp:137] Memory required for data: 625632400
I0928 09:32:12.586385  4247 layer_factory.hpp:77] Creating layer M2PELU26
I0928 09:32:12.586390  4247 net.cpp:84] Creating Layer M2PELU26
I0928 09:32:12.586392  4247 net.cpp:406] M2PELU26 <- Convolution27
I0928 09:32:12.586396  4247 net.cpp:367] M2PELU26 -> Convolution27 (in-place)
I0928 09:32:12.586478  4247 net.cpp:122] Setting up M2PELU26
I0928 09:32:12.586483  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.586484  4247 net.cpp:137] Memory required for data: 628141200
I0928 09:32:12.586488  4247 layer_factory.hpp:77] Creating layer Convolution28
I0928 09:32:12.586494  4247 net.cpp:84] Creating Layer Convolution28
I0928 09:32:12.586496  4247 net.cpp:406] Convolution28 <- Convolution27
I0928 09:32:12.586500  4247 net.cpp:380] Convolution28 -> Convolution28
I0928 09:32:12.587569  4247 net.cpp:122] Setting up Convolution28
I0928 09:32:12.587579  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.587581  4247 net.cpp:137] Memory required for data: 630650000
I0928 09:32:12.587586  4247 layer_factory.hpp:77] Creating layer BatchNorm28
I0928 09:32:12.587590  4247 net.cpp:84] Creating Layer BatchNorm28
I0928 09:32:12.587594  4247 net.cpp:406] BatchNorm28 <- Convolution28
I0928 09:32:12.587597  4247 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0928 09:32:12.587735  4247 net.cpp:122] Setting up BatchNorm28
I0928 09:32:12.587739  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.587741  4247 net.cpp:137] Memory required for data: 633158800
I0928 09:32:12.587746  4247 layer_factory.hpp:77] Creating layer Scale28
I0928 09:32:12.587750  4247 net.cpp:84] Creating Layer Scale28
I0928 09:32:12.587752  4247 net.cpp:406] Scale28 <- Convolution28
I0928 09:32:12.587755  4247 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0928 09:32:12.587783  4247 layer_factory.hpp:77] Creating layer Scale28
I0928 09:32:12.587862  4247 net.cpp:122] Setting up Scale28
I0928 09:32:12.587867  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.587868  4247 net.cpp:137] Memory required for data: 635667600
I0928 09:32:12.587872  4247 layer_factory.hpp:77] Creating layer Eltwise13
I0928 09:32:12.587877  4247 net.cpp:84] Creating Layer Eltwise13
I0928 09:32:12.587879  4247 net.cpp:406] Eltwise13 <- Eltwise12_M2PELU25_0_split_1
I0928 09:32:12.587882  4247 net.cpp:406] Eltwise13 <- Convolution28
I0928 09:32:12.587885  4247 net.cpp:380] Eltwise13 -> Eltwise13
I0928 09:32:12.587903  4247 net.cpp:122] Setting up Eltwise13
I0928 09:32:12.587905  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.587908  4247 net.cpp:137] Memory required for data: 638176400
I0928 09:32:12.587909  4247 layer_factory.hpp:77] Creating layer M2PELU27
I0928 09:32:12.587914  4247 net.cpp:84] Creating Layer M2PELU27
I0928 09:32:12.587918  4247 net.cpp:406] M2PELU27 <- Eltwise13
I0928 09:32:12.587920  4247 net.cpp:367] M2PELU27 -> Eltwise13 (in-place)
I0928 09:32:12.588014  4247 net.cpp:122] Setting up M2PELU27
I0928 09:32:12.588019  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.588021  4247 net.cpp:137] Memory required for data: 640685200
I0928 09:32:12.588026  4247 layer_factory.hpp:77] Creating layer Eltwise13_M2PELU27_0_split
I0928 09:32:12.588028  4247 net.cpp:84] Creating Layer Eltwise13_M2PELU27_0_split
I0928 09:32:12.588032  4247 net.cpp:406] Eltwise13_M2PELU27_0_split <- Eltwise13
I0928 09:32:12.588035  4247 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_0
I0928 09:32:12.588039  4247 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_1
I0928 09:32:12.588063  4247 net.cpp:122] Setting up Eltwise13_M2PELU27_0_split
I0928 09:32:12.588066  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.588069  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.588071  4247 net.cpp:137] Memory required for data: 645702800
I0928 09:32:12.588073  4247 layer_factory.hpp:77] Creating layer Convolution29
I0928 09:32:12.588079  4247 net.cpp:84] Creating Layer Convolution29
I0928 09:32:12.588083  4247 net.cpp:406] Convolution29 <- Eltwise13_M2PELU27_0_split_0
I0928 09:32:12.588086  4247 net.cpp:380] Convolution29 -> Convolution29
I0928 09:32:12.589133  4247 net.cpp:122] Setting up Convolution29
I0928 09:32:12.589141  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.589143  4247 net.cpp:137] Memory required for data: 648211600
I0928 09:32:12.589148  4247 layer_factory.hpp:77] Creating layer BatchNorm29
I0928 09:32:12.589154  4247 net.cpp:84] Creating Layer BatchNorm29
I0928 09:32:12.589156  4247 net.cpp:406] BatchNorm29 <- Convolution29
I0928 09:32:12.589160  4247 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0928 09:32:12.589294  4247 net.cpp:122] Setting up BatchNorm29
I0928 09:32:12.589298  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.589300  4247 net.cpp:137] Memory required for data: 650720400
I0928 09:32:12.589305  4247 layer_factory.hpp:77] Creating layer Scale29
I0928 09:32:12.589309  4247 net.cpp:84] Creating Layer Scale29
I0928 09:32:12.589313  4247 net.cpp:406] Scale29 <- Convolution29
I0928 09:32:12.589315  4247 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0928 09:32:12.589341  4247 layer_factory.hpp:77] Creating layer Scale29
I0928 09:32:12.589421  4247 net.cpp:122] Setting up Scale29
I0928 09:32:12.589426  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.589427  4247 net.cpp:137] Memory required for data: 653229200
I0928 09:32:12.589447  4247 layer_factory.hpp:77] Creating layer M2PELU28
I0928 09:32:12.589453  4247 net.cpp:84] Creating Layer M2PELU28
I0928 09:32:12.589455  4247 net.cpp:406] M2PELU28 <- Convolution29
I0928 09:32:12.589459  4247 net.cpp:367] M2PELU28 -> Convolution29 (in-place)
I0928 09:32:12.589545  4247 net.cpp:122] Setting up M2PELU28
I0928 09:32:12.589550  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.589551  4247 net.cpp:137] Memory required for data: 655738000
I0928 09:32:12.589555  4247 layer_factory.hpp:77] Creating layer Convolution30
I0928 09:32:12.589562  4247 net.cpp:84] Creating Layer Convolution30
I0928 09:32:12.589565  4247 net.cpp:406] Convolution30 <- Convolution29
I0928 09:32:12.589568  4247 net.cpp:380] Convolution30 -> Convolution30
I0928 09:32:12.590620  4247 net.cpp:122] Setting up Convolution30
I0928 09:32:12.590629  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.590631  4247 net.cpp:137] Memory required for data: 658246800
I0928 09:32:12.590636  4247 layer_factory.hpp:77] Creating layer BatchNorm30
I0928 09:32:12.590641  4247 net.cpp:84] Creating Layer BatchNorm30
I0928 09:32:12.590644  4247 net.cpp:406] BatchNorm30 <- Convolution30
I0928 09:32:12.590648  4247 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0928 09:32:12.590783  4247 net.cpp:122] Setting up BatchNorm30
I0928 09:32:12.590787  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.590790  4247 net.cpp:137] Memory required for data: 660755600
I0928 09:32:12.590801  4247 layer_factory.hpp:77] Creating layer Scale30
I0928 09:32:12.590806  4247 net.cpp:84] Creating Layer Scale30
I0928 09:32:12.590809  4247 net.cpp:406] Scale30 <- Convolution30
I0928 09:32:12.590812  4247 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0928 09:32:12.590839  4247 layer_factory.hpp:77] Creating layer Scale30
I0928 09:32:12.590917  4247 net.cpp:122] Setting up Scale30
I0928 09:32:12.590921  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.590924  4247 net.cpp:137] Memory required for data: 663264400
I0928 09:32:12.590927  4247 layer_factory.hpp:77] Creating layer Eltwise14
I0928 09:32:12.590931  4247 net.cpp:84] Creating Layer Eltwise14
I0928 09:32:12.590934  4247 net.cpp:406] Eltwise14 <- Eltwise13_M2PELU27_0_split_1
I0928 09:32:12.590936  4247 net.cpp:406] Eltwise14 <- Convolution30
I0928 09:32:12.590941  4247 net.cpp:380] Eltwise14 -> Eltwise14
I0928 09:32:12.590956  4247 net.cpp:122] Setting up Eltwise14
I0928 09:32:12.590960  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.590962  4247 net.cpp:137] Memory required for data: 665773200
I0928 09:32:12.590965  4247 layer_factory.hpp:77] Creating layer M2PELU29
I0928 09:32:12.590970  4247 net.cpp:84] Creating Layer M2PELU29
I0928 09:32:12.590971  4247 net.cpp:406] M2PELU29 <- Eltwise14
I0928 09:32:12.590975  4247 net.cpp:367] M2PELU29 -> Eltwise14 (in-place)
I0928 09:32:12.591058  4247 net.cpp:122] Setting up M2PELU29
I0928 09:32:12.591063  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.591064  4247 net.cpp:137] Memory required for data: 668282000
I0928 09:32:12.591068  4247 layer_factory.hpp:77] Creating layer Eltwise14_M2PELU29_0_split
I0928 09:32:12.591071  4247 net.cpp:84] Creating Layer Eltwise14_M2PELU29_0_split
I0928 09:32:12.591073  4247 net.cpp:406] Eltwise14_M2PELU29_0_split <- Eltwise14
I0928 09:32:12.591078  4247 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_0
I0928 09:32:12.591081  4247 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_1
I0928 09:32:12.591104  4247 net.cpp:122] Setting up Eltwise14_M2PELU29_0_split
I0928 09:32:12.591107  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.591110  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.591112  4247 net.cpp:137] Memory required for data: 673299600
I0928 09:32:12.591114  4247 layer_factory.hpp:77] Creating layer Convolution31
I0928 09:32:12.591120  4247 net.cpp:84] Creating Layer Convolution31
I0928 09:32:12.591122  4247 net.cpp:406] Convolution31 <- Eltwise14_M2PELU29_0_split_0
I0928 09:32:12.591125  4247 net.cpp:380] Convolution31 -> Convolution31
I0928 09:32:12.592150  4247 net.cpp:122] Setting up Convolution31
I0928 09:32:12.592159  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.592161  4247 net.cpp:137] Memory required for data: 675808400
I0928 09:32:12.592165  4247 layer_factory.hpp:77] Creating layer BatchNorm31
I0928 09:32:12.592170  4247 net.cpp:84] Creating Layer BatchNorm31
I0928 09:32:12.592172  4247 net.cpp:406] BatchNorm31 <- Convolution31
I0928 09:32:12.592176  4247 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0928 09:32:12.592312  4247 net.cpp:122] Setting up BatchNorm31
I0928 09:32:12.592317  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.592319  4247 net.cpp:137] Memory required for data: 678317200
I0928 09:32:12.592324  4247 layer_factory.hpp:77] Creating layer Scale31
I0928 09:32:12.592327  4247 net.cpp:84] Creating Layer Scale31
I0928 09:32:12.592329  4247 net.cpp:406] Scale31 <- Convolution31
I0928 09:32:12.592334  4247 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0928 09:32:12.592360  4247 layer_factory.hpp:77] Creating layer Scale31
I0928 09:32:12.592437  4247 net.cpp:122] Setting up Scale31
I0928 09:32:12.592442  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.592444  4247 net.cpp:137] Memory required for data: 680826000
I0928 09:32:12.592448  4247 layer_factory.hpp:77] Creating layer M2PELU30
I0928 09:32:12.592453  4247 net.cpp:84] Creating Layer M2PELU30
I0928 09:32:12.592460  4247 net.cpp:406] M2PELU30 <- Convolution31
I0928 09:32:12.592465  4247 net.cpp:367] M2PELU30 -> Convolution31 (in-place)
I0928 09:32:12.592551  4247 net.cpp:122] Setting up M2PELU30
I0928 09:32:12.592555  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.592557  4247 net.cpp:137] Memory required for data: 683334800
I0928 09:32:12.592561  4247 layer_factory.hpp:77] Creating layer Convolution32
I0928 09:32:12.592568  4247 net.cpp:84] Creating Layer Convolution32
I0928 09:32:12.592571  4247 net.cpp:406] Convolution32 <- Convolution31
I0928 09:32:12.592574  4247 net.cpp:380] Convolution32 -> Convolution32
I0928 09:32:12.593601  4247 net.cpp:122] Setting up Convolution32
I0928 09:32:12.593611  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.593613  4247 net.cpp:137] Memory required for data: 685843600
I0928 09:32:12.593617  4247 layer_factory.hpp:77] Creating layer BatchNorm32
I0928 09:32:12.593622  4247 net.cpp:84] Creating Layer BatchNorm32
I0928 09:32:12.593626  4247 net.cpp:406] BatchNorm32 <- Convolution32
I0928 09:32:12.593628  4247 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I0928 09:32:12.593762  4247 net.cpp:122] Setting up BatchNorm32
I0928 09:32:12.593767  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.593770  4247 net.cpp:137] Memory required for data: 688352400
I0928 09:32:12.593773  4247 layer_factory.hpp:77] Creating layer Scale32
I0928 09:32:12.593778  4247 net.cpp:84] Creating Layer Scale32
I0928 09:32:12.593781  4247 net.cpp:406] Scale32 <- Convolution32
I0928 09:32:12.593785  4247 net.cpp:367] Scale32 -> Convolution32 (in-place)
I0928 09:32:12.593811  4247 layer_factory.hpp:77] Creating layer Scale32
I0928 09:32:12.593886  4247 net.cpp:122] Setting up Scale32
I0928 09:32:12.593891  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.593894  4247 net.cpp:137] Memory required for data: 690861200
I0928 09:32:12.593896  4247 layer_factory.hpp:77] Creating layer Eltwise15
I0928 09:32:12.593900  4247 net.cpp:84] Creating Layer Eltwise15
I0928 09:32:12.593904  4247 net.cpp:406] Eltwise15 <- Eltwise14_M2PELU29_0_split_1
I0928 09:32:12.593905  4247 net.cpp:406] Eltwise15 <- Convolution32
I0928 09:32:12.593909  4247 net.cpp:380] Eltwise15 -> Eltwise15
I0928 09:32:12.593924  4247 net.cpp:122] Setting up Eltwise15
I0928 09:32:12.593928  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.593930  4247 net.cpp:137] Memory required for data: 693370000
I0928 09:32:12.593932  4247 layer_factory.hpp:77] Creating layer M2PELU31
I0928 09:32:12.593937  4247 net.cpp:84] Creating Layer M2PELU31
I0928 09:32:12.593940  4247 net.cpp:406] M2PELU31 <- Eltwise15
I0928 09:32:12.593942  4247 net.cpp:367] M2PELU31 -> Eltwise15 (in-place)
I0928 09:32:12.594025  4247 net.cpp:122] Setting up M2PELU31
I0928 09:32:12.594029  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.594032  4247 net.cpp:137] Memory required for data: 695878800
I0928 09:32:12.594034  4247 layer_factory.hpp:77] Creating layer Eltwise15_M2PELU31_0_split
I0928 09:32:12.594039  4247 net.cpp:84] Creating Layer Eltwise15_M2PELU31_0_split
I0928 09:32:12.594041  4247 net.cpp:406] Eltwise15_M2PELU31_0_split <- Eltwise15
I0928 09:32:12.594044  4247 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_0
I0928 09:32:12.594048  4247 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_1
I0928 09:32:12.594071  4247 net.cpp:122] Setting up Eltwise15_M2PELU31_0_split
I0928 09:32:12.594075  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.594077  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.594079  4247 net.cpp:137] Memory required for data: 700896400
I0928 09:32:12.594081  4247 layer_factory.hpp:77] Creating layer Convolution33
I0928 09:32:12.594089  4247 net.cpp:84] Creating Layer Convolution33
I0928 09:32:12.594090  4247 net.cpp:406] Convolution33 <- Eltwise15_M2PELU31_0_split_0
I0928 09:32:12.594094  4247 net.cpp:380] Convolution33 -> Convolution33
I0928 09:32:12.595466  4247 net.cpp:122] Setting up Convolution33
I0928 09:32:12.595476  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.595479  4247 net.cpp:137] Memory required for data: 703405200
I0928 09:32:12.595484  4247 layer_factory.hpp:77] Creating layer BatchNorm33
I0928 09:32:12.595489  4247 net.cpp:84] Creating Layer BatchNorm33
I0928 09:32:12.595491  4247 net.cpp:406] BatchNorm33 <- Convolution33
I0928 09:32:12.595495  4247 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I0928 09:32:12.595636  4247 net.cpp:122] Setting up BatchNorm33
I0928 09:32:12.595641  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.595643  4247 net.cpp:137] Memory required for data: 705914000
I0928 09:32:12.595649  4247 layer_factory.hpp:77] Creating layer Scale33
I0928 09:32:12.595652  4247 net.cpp:84] Creating Layer Scale33
I0928 09:32:12.595654  4247 net.cpp:406] Scale33 <- Convolution33
I0928 09:32:12.595657  4247 net.cpp:367] Scale33 -> Convolution33 (in-place)
I0928 09:32:12.595685  4247 layer_factory.hpp:77] Creating layer Scale33
I0928 09:32:12.595762  4247 net.cpp:122] Setting up Scale33
I0928 09:32:12.595767  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.595768  4247 net.cpp:137] Memory required for data: 708422800
I0928 09:32:12.595772  4247 layer_factory.hpp:77] Creating layer M2PELU32
I0928 09:32:12.595777  4247 net.cpp:84] Creating Layer M2PELU32
I0928 09:32:12.595779  4247 net.cpp:406] M2PELU32 <- Convolution33
I0928 09:32:12.595782  4247 net.cpp:367] M2PELU32 -> Convolution33 (in-place)
I0928 09:32:12.595866  4247 net.cpp:122] Setting up M2PELU32
I0928 09:32:12.595870  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.595872  4247 net.cpp:137] Memory required for data: 710931600
I0928 09:32:12.595876  4247 layer_factory.hpp:77] Creating layer Convolution34
I0928 09:32:12.595882  4247 net.cpp:84] Creating Layer Convolution34
I0928 09:32:12.595885  4247 net.cpp:406] Convolution34 <- Convolution33
I0928 09:32:12.595890  4247 net.cpp:380] Convolution34 -> Convolution34
I0928 09:32:12.596927  4247 net.cpp:122] Setting up Convolution34
I0928 09:32:12.596936  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.596940  4247 net.cpp:137] Memory required for data: 713440400
I0928 09:32:12.596943  4247 layer_factory.hpp:77] Creating layer BatchNorm34
I0928 09:32:12.596949  4247 net.cpp:84] Creating Layer BatchNorm34
I0928 09:32:12.596951  4247 net.cpp:406] BatchNorm34 <- Convolution34
I0928 09:32:12.596956  4247 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I0928 09:32:12.597092  4247 net.cpp:122] Setting up BatchNorm34
I0928 09:32:12.597096  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.597098  4247 net.cpp:137] Memory required for data: 715949200
I0928 09:32:12.597103  4247 layer_factory.hpp:77] Creating layer Scale34
I0928 09:32:12.597107  4247 net.cpp:84] Creating Layer Scale34
I0928 09:32:12.597110  4247 net.cpp:406] Scale34 <- Convolution34
I0928 09:32:12.597113  4247 net.cpp:367] Scale34 -> Convolution34 (in-place)
I0928 09:32:12.597139  4247 layer_factory.hpp:77] Creating layer Scale34
I0928 09:32:12.597215  4247 net.cpp:122] Setting up Scale34
I0928 09:32:12.597219  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.597221  4247 net.cpp:137] Memory required for data: 718458000
I0928 09:32:12.597225  4247 layer_factory.hpp:77] Creating layer Eltwise16
I0928 09:32:12.597229  4247 net.cpp:84] Creating Layer Eltwise16
I0928 09:32:12.597231  4247 net.cpp:406] Eltwise16 <- Eltwise15_M2PELU31_0_split_1
I0928 09:32:12.597234  4247 net.cpp:406] Eltwise16 <- Convolution34
I0928 09:32:12.597240  4247 net.cpp:380] Eltwise16 -> Eltwise16
I0928 09:32:12.597257  4247 net.cpp:122] Setting up Eltwise16
I0928 09:32:12.597260  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.597262  4247 net.cpp:137] Memory required for data: 720966800
I0928 09:32:12.597265  4247 layer_factory.hpp:77] Creating layer M2PELU33
I0928 09:32:12.597268  4247 net.cpp:84] Creating Layer M2PELU33
I0928 09:32:12.597271  4247 net.cpp:406] M2PELU33 <- Eltwise16
I0928 09:32:12.597282  4247 net.cpp:367] M2PELU33 -> Eltwise16 (in-place)
I0928 09:32:12.597368  4247 net.cpp:122] Setting up M2PELU33
I0928 09:32:12.597373  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.597374  4247 net.cpp:137] Memory required for data: 723475600
I0928 09:32:12.597378  4247 layer_factory.hpp:77] Creating layer Eltwise16_M2PELU33_0_split
I0928 09:32:12.597383  4247 net.cpp:84] Creating Layer Eltwise16_M2PELU33_0_split
I0928 09:32:12.597385  4247 net.cpp:406] Eltwise16_M2PELU33_0_split <- Eltwise16
I0928 09:32:12.597388  4247 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_0
I0928 09:32:12.597393  4247 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_1
I0928 09:32:12.597415  4247 net.cpp:122] Setting up Eltwise16_M2PELU33_0_split
I0928 09:32:12.597419  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.597421  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.597424  4247 net.cpp:137] Memory required for data: 728493200
I0928 09:32:12.597425  4247 layer_factory.hpp:77] Creating layer Convolution35
I0928 09:32:12.597431  4247 net.cpp:84] Creating Layer Convolution35
I0928 09:32:12.597434  4247 net.cpp:406] Convolution35 <- Eltwise16_M2PELU33_0_split_0
I0928 09:32:12.597439  4247 net.cpp:380] Convolution35 -> Convolution35
I0928 09:32:12.598466  4247 net.cpp:122] Setting up Convolution35
I0928 09:32:12.598474  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.598477  4247 net.cpp:137] Memory required for data: 731002000
I0928 09:32:12.598481  4247 layer_factory.hpp:77] Creating layer BatchNorm35
I0928 09:32:12.598486  4247 net.cpp:84] Creating Layer BatchNorm35
I0928 09:32:12.598489  4247 net.cpp:406] BatchNorm35 <- Convolution35
I0928 09:32:12.598492  4247 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I0928 09:32:12.598654  4247 net.cpp:122] Setting up BatchNorm35
I0928 09:32:12.598659  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.598660  4247 net.cpp:137] Memory required for data: 733510800
I0928 09:32:12.598665  4247 layer_factory.hpp:77] Creating layer Scale35
I0928 09:32:12.598670  4247 net.cpp:84] Creating Layer Scale35
I0928 09:32:12.598671  4247 net.cpp:406] Scale35 <- Convolution35
I0928 09:32:12.598675  4247 net.cpp:367] Scale35 -> Convolution35 (in-place)
I0928 09:32:12.598702  4247 layer_factory.hpp:77] Creating layer Scale35
I0928 09:32:12.598778  4247 net.cpp:122] Setting up Scale35
I0928 09:32:12.598783  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.598784  4247 net.cpp:137] Memory required for data: 736019600
I0928 09:32:12.598788  4247 layer_factory.hpp:77] Creating layer M2PELU34
I0928 09:32:12.598793  4247 net.cpp:84] Creating Layer M2PELU34
I0928 09:32:12.598795  4247 net.cpp:406] M2PELU34 <- Convolution35
I0928 09:32:12.598799  4247 net.cpp:367] M2PELU34 -> Convolution35 (in-place)
I0928 09:32:12.598896  4247 net.cpp:122] Setting up M2PELU34
I0928 09:32:12.598899  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.598901  4247 net.cpp:137] Memory required for data: 738528400
I0928 09:32:12.598906  4247 layer_factory.hpp:77] Creating layer Convolution36
I0928 09:32:12.598912  4247 net.cpp:84] Creating Layer Convolution36
I0928 09:32:12.598914  4247 net.cpp:406] Convolution36 <- Convolution35
I0928 09:32:12.598918  4247 net.cpp:380] Convolution36 -> Convolution36
I0928 09:32:12.599982  4247 net.cpp:122] Setting up Convolution36
I0928 09:32:12.599990  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.599992  4247 net.cpp:137] Memory required for data: 741037200
I0928 09:32:12.599997  4247 layer_factory.hpp:77] Creating layer BatchNorm36
I0928 09:32:12.600002  4247 net.cpp:84] Creating Layer BatchNorm36
I0928 09:32:12.600004  4247 net.cpp:406] BatchNorm36 <- Convolution36
I0928 09:32:12.600008  4247 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I0928 09:32:12.600144  4247 net.cpp:122] Setting up BatchNorm36
I0928 09:32:12.600148  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.600157  4247 net.cpp:137] Memory required for data: 743546000
I0928 09:32:12.600162  4247 layer_factory.hpp:77] Creating layer Scale36
I0928 09:32:12.600165  4247 net.cpp:84] Creating Layer Scale36
I0928 09:32:12.600168  4247 net.cpp:406] Scale36 <- Convolution36
I0928 09:32:12.600172  4247 net.cpp:367] Scale36 -> Convolution36 (in-place)
I0928 09:32:12.600199  4247 layer_factory.hpp:77] Creating layer Scale36
I0928 09:32:12.600277  4247 net.cpp:122] Setting up Scale36
I0928 09:32:12.600281  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.600283  4247 net.cpp:137] Memory required for data: 746054800
I0928 09:32:12.600287  4247 layer_factory.hpp:77] Creating layer Eltwise17
I0928 09:32:12.600291  4247 net.cpp:84] Creating Layer Eltwise17
I0928 09:32:12.600293  4247 net.cpp:406] Eltwise17 <- Eltwise16_M2PELU33_0_split_1
I0928 09:32:12.600296  4247 net.cpp:406] Eltwise17 <- Convolution36
I0928 09:32:12.600301  4247 net.cpp:380] Eltwise17 -> Eltwise17
I0928 09:32:12.600317  4247 net.cpp:122] Setting up Eltwise17
I0928 09:32:12.600322  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.600323  4247 net.cpp:137] Memory required for data: 748563600
I0928 09:32:12.600325  4247 layer_factory.hpp:77] Creating layer M2PELU35
I0928 09:32:12.600329  4247 net.cpp:84] Creating Layer M2PELU35
I0928 09:32:12.600332  4247 net.cpp:406] M2PELU35 <- Eltwise17
I0928 09:32:12.600335  4247 net.cpp:367] M2PELU35 -> Eltwise17 (in-place)
I0928 09:32:12.600420  4247 net.cpp:122] Setting up M2PELU35
I0928 09:32:12.600425  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.600426  4247 net.cpp:137] Memory required for data: 751072400
I0928 09:32:12.600430  4247 layer_factory.hpp:77] Creating layer Eltwise17_M2PELU35_0_split
I0928 09:32:12.600435  4247 net.cpp:84] Creating Layer Eltwise17_M2PELU35_0_split
I0928 09:32:12.600437  4247 net.cpp:406] Eltwise17_M2PELU35_0_split <- Eltwise17
I0928 09:32:12.600440  4247 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_0
I0928 09:32:12.600445  4247 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_1
I0928 09:32:12.600468  4247 net.cpp:122] Setting up Eltwise17_M2PELU35_0_split
I0928 09:32:12.600471  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.600474  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.600476  4247 net.cpp:137] Memory required for data: 756090000
I0928 09:32:12.600478  4247 layer_factory.hpp:77] Creating layer Convolution37
I0928 09:32:12.600483  4247 net.cpp:84] Creating Layer Convolution37
I0928 09:32:12.600486  4247 net.cpp:406] Convolution37 <- Eltwise17_M2PELU35_0_split_0
I0928 09:32:12.600491  4247 net.cpp:380] Convolution37 -> Convolution37
I0928 09:32:12.601217  4247 net.cpp:122] Setting up Convolution37
I0928 09:32:12.601223  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.601225  4247 net.cpp:137] Memory required for data: 758598800
I0928 09:32:12.601229  4247 layer_factory.hpp:77] Creating layer BatchNorm37
I0928 09:32:12.601234  4247 net.cpp:84] Creating Layer BatchNorm37
I0928 09:32:12.601238  4247 net.cpp:406] BatchNorm37 <- Convolution37
I0928 09:32:12.601241  4247 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I0928 09:32:12.601380  4247 net.cpp:122] Setting up BatchNorm37
I0928 09:32:12.601384  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.601387  4247 net.cpp:137] Memory required for data: 761107600
I0928 09:32:12.601392  4247 layer_factory.hpp:77] Creating layer Scale37
I0928 09:32:12.601397  4247 net.cpp:84] Creating Layer Scale37
I0928 09:32:12.601398  4247 net.cpp:406] Scale37 <- Convolution37
I0928 09:32:12.601402  4247 net.cpp:367] Scale37 -> Convolution37 (in-place)
I0928 09:32:12.601428  4247 layer_factory.hpp:77] Creating layer Scale37
I0928 09:32:12.601507  4247 net.cpp:122] Setting up Scale37
I0928 09:32:12.601512  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.601514  4247 net.cpp:137] Memory required for data: 763616400
I0928 09:32:12.601518  4247 layer_factory.hpp:77] Creating layer M2PELU36
I0928 09:32:12.601528  4247 net.cpp:84] Creating Layer M2PELU36
I0928 09:32:12.601531  4247 net.cpp:406] M2PELU36 <- Convolution37
I0928 09:32:12.601536  4247 net.cpp:367] M2PELU36 -> Convolution37 (in-place)
I0928 09:32:12.601621  4247 net.cpp:122] Setting up M2PELU36
I0928 09:32:12.601626  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.601629  4247 net.cpp:137] Memory required for data: 766125200
I0928 09:32:12.601632  4247 layer_factory.hpp:77] Creating layer Convolution38
I0928 09:32:12.601639  4247 net.cpp:84] Creating Layer Convolution38
I0928 09:32:12.601641  4247 net.cpp:406] Convolution38 <- Convolution37
I0928 09:32:12.601647  4247 net.cpp:380] Convolution38 -> Convolution38
I0928 09:32:12.602735  4247 net.cpp:122] Setting up Convolution38
I0928 09:32:12.602744  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.602746  4247 net.cpp:137] Memory required for data: 768634000
I0928 09:32:12.602751  4247 layer_factory.hpp:77] Creating layer BatchNorm38
I0928 09:32:12.602756  4247 net.cpp:84] Creating Layer BatchNorm38
I0928 09:32:12.602759  4247 net.cpp:406] BatchNorm38 <- Convolution38
I0928 09:32:12.602762  4247 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I0928 09:32:12.602910  4247 net.cpp:122] Setting up BatchNorm38
I0928 09:32:12.602913  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.602916  4247 net.cpp:137] Memory required for data: 771142800
I0928 09:32:12.602921  4247 layer_factory.hpp:77] Creating layer Scale38
I0928 09:32:12.602924  4247 net.cpp:84] Creating Layer Scale38
I0928 09:32:12.602927  4247 net.cpp:406] Scale38 <- Convolution38
I0928 09:32:12.602931  4247 net.cpp:367] Scale38 -> Convolution38 (in-place)
I0928 09:32:12.602957  4247 layer_factory.hpp:77] Creating layer Scale38
I0928 09:32:12.603035  4247 net.cpp:122] Setting up Scale38
I0928 09:32:12.603040  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.603042  4247 net.cpp:137] Memory required for data: 773651600
I0928 09:32:12.603045  4247 layer_factory.hpp:77] Creating layer Eltwise18
I0928 09:32:12.603050  4247 net.cpp:84] Creating Layer Eltwise18
I0928 09:32:12.603054  4247 net.cpp:406] Eltwise18 <- Eltwise17_M2PELU35_0_split_1
I0928 09:32:12.603055  4247 net.cpp:406] Eltwise18 <- Convolution38
I0928 09:32:12.603060  4247 net.cpp:380] Eltwise18 -> Eltwise18
I0928 09:32:12.603075  4247 net.cpp:122] Setting up Eltwise18
I0928 09:32:12.603078  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.603080  4247 net.cpp:137] Memory required for data: 776160400
I0928 09:32:12.603082  4247 layer_factory.hpp:77] Creating layer M2PELU37
I0928 09:32:12.603087  4247 net.cpp:84] Creating Layer M2PELU37
I0928 09:32:12.603090  4247 net.cpp:406] M2PELU37 <- Eltwise18
I0928 09:32:12.603092  4247 net.cpp:367] M2PELU37 -> Eltwise18 (in-place)
I0928 09:32:12.603178  4247 net.cpp:122] Setting up M2PELU37
I0928 09:32:12.603183  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.603185  4247 net.cpp:137] Memory required for data: 778669200
I0928 09:32:12.603189  4247 layer_factory.hpp:77] Creating layer Eltwise18_M2PELU37_0_split
I0928 09:32:12.603193  4247 net.cpp:84] Creating Layer Eltwise18_M2PELU37_0_split
I0928 09:32:12.603194  4247 net.cpp:406] Eltwise18_M2PELU37_0_split <- Eltwise18
I0928 09:32:12.603199  4247 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_0
I0928 09:32:12.603202  4247 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_1
I0928 09:32:12.603226  4247 net.cpp:122] Setting up Eltwise18_M2PELU37_0_split
I0928 09:32:12.603230  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.603233  4247 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 09:32:12.603235  4247 net.cpp:137] Memory required for data: 783686800
I0928 09:32:12.603237  4247 layer_factory.hpp:77] Creating layer Convolution39
I0928 09:32:12.603243  4247 net.cpp:84] Creating Layer Convolution39
I0928 09:32:12.603245  4247 net.cpp:406] Convolution39 <- Eltwise18_M2PELU37_0_split_0
I0928 09:32:12.603256  4247 net.cpp:380] Convolution39 -> Convolution39
I0928 09:32:12.604164  4247 net.cpp:122] Setting up Convolution39
I0928 09:32:12.604172  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.604176  4247 net.cpp:137] Memory required for data: 784941200
I0928 09:32:12.604179  4247 layer_factory.hpp:77] Creating layer BatchNorm39
I0928 09:32:12.604184  4247 net.cpp:84] Creating Layer BatchNorm39
I0928 09:32:12.604187  4247 net.cpp:406] BatchNorm39 <- Convolution39
I0928 09:32:12.604190  4247 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I0928 09:32:12.604326  4247 net.cpp:122] Setting up BatchNorm39
I0928 09:32:12.604329  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.604331  4247 net.cpp:137] Memory required for data: 786195600
I0928 09:32:12.604336  4247 layer_factory.hpp:77] Creating layer Scale39
I0928 09:32:12.604341  4247 net.cpp:84] Creating Layer Scale39
I0928 09:32:12.604343  4247 net.cpp:406] Scale39 <- Convolution39
I0928 09:32:12.604346  4247 net.cpp:367] Scale39 -> Convolution39 (in-place)
I0928 09:32:12.604372  4247 layer_factory.hpp:77] Creating layer Scale39
I0928 09:32:12.604449  4247 net.cpp:122] Setting up Scale39
I0928 09:32:12.604454  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.604455  4247 net.cpp:137] Memory required for data: 787450000
I0928 09:32:12.604460  4247 layer_factory.hpp:77] Creating layer Convolution40
I0928 09:32:12.604466  4247 net.cpp:84] Creating Layer Convolution40
I0928 09:32:12.604470  4247 net.cpp:406] Convolution40 <- Eltwise18_M2PELU37_0_split_1
I0928 09:32:12.604473  4247 net.cpp:380] Convolution40 -> Convolution40
I0928 09:32:12.606199  4247 net.cpp:122] Setting up Convolution40
I0928 09:32:12.606209  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.606211  4247 net.cpp:137] Memory required for data: 788704400
I0928 09:32:12.606215  4247 layer_factory.hpp:77] Creating layer BatchNorm40
I0928 09:32:12.606221  4247 net.cpp:84] Creating Layer BatchNorm40
I0928 09:32:12.606225  4247 net.cpp:406] BatchNorm40 <- Convolution40
I0928 09:32:12.606227  4247 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I0928 09:32:12.606362  4247 net.cpp:122] Setting up BatchNorm40
I0928 09:32:12.606366  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.606369  4247 net.cpp:137] Memory required for data: 789958800
I0928 09:32:12.606374  4247 layer_factory.hpp:77] Creating layer Scale40
I0928 09:32:12.606377  4247 net.cpp:84] Creating Layer Scale40
I0928 09:32:12.606380  4247 net.cpp:406] Scale40 <- Convolution40
I0928 09:32:12.606384  4247 net.cpp:367] Scale40 -> Convolution40 (in-place)
I0928 09:32:12.606410  4247 layer_factory.hpp:77] Creating layer Scale40
I0928 09:32:12.606488  4247 net.cpp:122] Setting up Scale40
I0928 09:32:12.606492  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.606494  4247 net.cpp:137] Memory required for data: 791213200
I0928 09:32:12.606498  4247 layer_factory.hpp:77] Creating layer M2PELU38
I0928 09:32:12.606503  4247 net.cpp:84] Creating Layer M2PELU38
I0928 09:32:12.606505  4247 net.cpp:406] M2PELU38 <- Convolution40
I0928 09:32:12.606509  4247 net.cpp:367] M2PELU38 -> Convolution40 (in-place)
I0928 09:32:12.606621  4247 net.cpp:122] Setting up M2PELU38
I0928 09:32:12.606626  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.606627  4247 net.cpp:137] Memory required for data: 792467600
I0928 09:32:12.606631  4247 layer_factory.hpp:77] Creating layer Convolution41
I0928 09:32:12.606638  4247 net.cpp:84] Creating Layer Convolution41
I0928 09:32:12.606640  4247 net.cpp:406] Convolution41 <- Convolution40
I0928 09:32:12.606644  4247 net.cpp:380] Convolution41 -> Convolution41
I0928 09:32:12.608662  4247 net.cpp:122] Setting up Convolution41
I0928 09:32:12.608674  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.608677  4247 net.cpp:137] Memory required for data: 793722000
I0928 09:32:12.608685  4247 layer_factory.hpp:77] Creating layer BatchNorm41
I0928 09:32:12.608693  4247 net.cpp:84] Creating Layer BatchNorm41
I0928 09:32:12.608706  4247 net.cpp:406] BatchNorm41 <- Convolution41
I0928 09:32:12.608713  4247 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I0928 09:32:12.608930  4247 net.cpp:122] Setting up BatchNorm41
I0928 09:32:12.608942  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.608945  4247 net.cpp:137] Memory required for data: 794976400
I0928 09:32:12.608954  4247 layer_factory.hpp:77] Creating layer Scale41
I0928 09:32:12.608963  4247 net.cpp:84] Creating Layer Scale41
I0928 09:32:12.608968  4247 net.cpp:406] Scale41 <- Convolution41
I0928 09:32:12.608971  4247 net.cpp:367] Scale41 -> Convolution41 (in-place)
I0928 09:32:12.609004  4247 layer_factory.hpp:77] Creating layer Scale41
I0928 09:32:12.609122  4247 net.cpp:122] Setting up Scale41
I0928 09:32:12.609131  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.609135  4247 net.cpp:137] Memory required for data: 796230800
I0928 09:32:12.609143  4247 layer_factory.hpp:77] Creating layer Eltwise19
I0928 09:32:12.609151  4247 net.cpp:84] Creating Layer Eltwise19
I0928 09:32:12.609156  4247 net.cpp:406] Eltwise19 <- Convolution39
I0928 09:32:12.609161  4247 net.cpp:406] Eltwise19 <- Convolution41
I0928 09:32:12.609167  4247 net.cpp:380] Eltwise19 -> Eltwise19
I0928 09:32:12.609190  4247 net.cpp:122] Setting up Eltwise19
I0928 09:32:12.609195  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.609197  4247 net.cpp:137] Memory required for data: 797485200
I0928 09:32:12.609200  4247 layer_factory.hpp:77] Creating layer M2PELU39
I0928 09:32:12.609205  4247 net.cpp:84] Creating Layer M2PELU39
I0928 09:32:12.609207  4247 net.cpp:406] M2PELU39 <- Eltwise19
I0928 09:32:12.609211  4247 net.cpp:367] M2PELU39 -> Eltwise19 (in-place)
I0928 09:32:12.609300  4247 net.cpp:122] Setting up M2PELU39
I0928 09:32:12.609304  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.609307  4247 net.cpp:137] Memory required for data: 798739600
I0928 09:32:12.609310  4247 layer_factory.hpp:77] Creating layer Eltwise19_M2PELU39_0_split
I0928 09:32:12.609314  4247 net.cpp:84] Creating Layer Eltwise19_M2PELU39_0_split
I0928 09:32:12.609316  4247 net.cpp:406] Eltwise19_M2PELU39_0_split <- Eltwise19
I0928 09:32:12.609320  4247 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_0
I0928 09:32:12.609324  4247 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_1
I0928 09:32:12.609349  4247 net.cpp:122] Setting up Eltwise19_M2PELU39_0_split
I0928 09:32:12.609352  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.609354  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.609357  4247 net.cpp:137] Memory required for data: 801248400
I0928 09:32:12.609359  4247 layer_factory.hpp:77] Creating layer Convolution42
I0928 09:32:12.609365  4247 net.cpp:84] Creating Layer Convolution42
I0928 09:32:12.609367  4247 net.cpp:406] Convolution42 <- Eltwise19_M2PELU39_0_split_0
I0928 09:32:12.609371  4247 net.cpp:380] Convolution42 -> Convolution42
I0928 09:32:12.611191  4247 net.cpp:122] Setting up Convolution42
I0928 09:32:12.611199  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.611202  4247 net.cpp:137] Memory required for data: 802502800
I0928 09:32:12.611207  4247 layer_factory.hpp:77] Creating layer BatchNorm42
I0928 09:32:12.611212  4247 net.cpp:84] Creating Layer BatchNorm42
I0928 09:32:12.611214  4247 net.cpp:406] BatchNorm42 <- Convolution42
I0928 09:32:12.611218  4247 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I0928 09:32:12.611377  4247 net.cpp:122] Setting up BatchNorm42
I0928 09:32:12.611382  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.611384  4247 net.cpp:137] Memory required for data: 803757200
I0928 09:32:12.611389  4247 layer_factory.hpp:77] Creating layer Scale42
I0928 09:32:12.611393  4247 net.cpp:84] Creating Layer Scale42
I0928 09:32:12.611395  4247 net.cpp:406] Scale42 <- Convolution42
I0928 09:32:12.611398  4247 net.cpp:367] Scale42 -> Convolution42 (in-place)
I0928 09:32:12.611428  4247 layer_factory.hpp:77] Creating layer Scale42
I0928 09:32:12.611527  4247 net.cpp:122] Setting up Scale42
I0928 09:32:12.611532  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.611534  4247 net.cpp:137] Memory required for data: 805011600
I0928 09:32:12.611538  4247 layer_factory.hpp:77] Creating layer M2PELU40
I0928 09:32:12.611543  4247 net.cpp:84] Creating Layer M2PELU40
I0928 09:32:12.611546  4247 net.cpp:406] M2PELU40 <- Convolution42
I0928 09:32:12.611549  4247 net.cpp:367] M2PELU40 -> Convolution42 (in-place)
I0928 09:32:12.611646  4247 net.cpp:122] Setting up M2PELU40
I0928 09:32:12.611650  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.611652  4247 net.cpp:137] Memory required for data: 806266000
I0928 09:32:12.611656  4247 layer_factory.hpp:77] Creating layer Convolution43
I0928 09:32:12.611663  4247 net.cpp:84] Creating Layer Convolution43
I0928 09:32:12.611665  4247 net.cpp:406] Convolution43 <- Convolution42
I0928 09:32:12.611670  4247 net.cpp:380] Convolution43 -> Convolution43
I0928 09:32:12.613916  4247 net.cpp:122] Setting up Convolution43
I0928 09:32:12.613925  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.613927  4247 net.cpp:137] Memory required for data: 807520400
I0928 09:32:12.613932  4247 layer_factory.hpp:77] Creating layer BatchNorm43
I0928 09:32:12.613939  4247 net.cpp:84] Creating Layer BatchNorm43
I0928 09:32:12.613940  4247 net.cpp:406] BatchNorm43 <- Convolution43
I0928 09:32:12.613945  4247 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I0928 09:32:12.614085  4247 net.cpp:122] Setting up BatchNorm43
I0928 09:32:12.614089  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.614091  4247 net.cpp:137] Memory required for data: 808774800
I0928 09:32:12.614096  4247 layer_factory.hpp:77] Creating layer Scale43
I0928 09:32:12.614100  4247 net.cpp:84] Creating Layer Scale43
I0928 09:32:12.614104  4247 net.cpp:406] Scale43 <- Convolution43
I0928 09:32:12.614106  4247 net.cpp:367] Scale43 -> Convolution43 (in-place)
I0928 09:32:12.614135  4247 layer_factory.hpp:77] Creating layer Scale43
I0928 09:32:12.614213  4247 net.cpp:122] Setting up Scale43
I0928 09:32:12.614217  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.614219  4247 net.cpp:137] Memory required for data: 810029200
I0928 09:32:12.614223  4247 layer_factory.hpp:77] Creating layer Eltwise20
I0928 09:32:12.614228  4247 net.cpp:84] Creating Layer Eltwise20
I0928 09:32:12.614231  4247 net.cpp:406] Eltwise20 <- Eltwise19_M2PELU39_0_split_1
I0928 09:32:12.614233  4247 net.cpp:406] Eltwise20 <- Convolution43
I0928 09:32:12.614238  4247 net.cpp:380] Eltwise20 -> Eltwise20
I0928 09:32:12.614254  4247 net.cpp:122] Setting up Eltwise20
I0928 09:32:12.614258  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.614259  4247 net.cpp:137] Memory required for data: 811283600
I0928 09:32:12.614261  4247 layer_factory.hpp:77] Creating layer M2PELU41
I0928 09:32:12.614266  4247 net.cpp:84] Creating Layer M2PELU41
I0928 09:32:12.614269  4247 net.cpp:406] M2PELU41 <- Eltwise20
I0928 09:32:12.614272  4247 net.cpp:367] M2PELU41 -> Eltwise20 (in-place)
I0928 09:32:12.614361  4247 net.cpp:122] Setting up M2PELU41
I0928 09:32:12.614364  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.614367  4247 net.cpp:137] Memory required for data: 812538000
I0928 09:32:12.614370  4247 layer_factory.hpp:77] Creating layer Eltwise20_M2PELU41_0_split
I0928 09:32:12.614373  4247 net.cpp:84] Creating Layer Eltwise20_M2PELU41_0_split
I0928 09:32:12.614377  4247 net.cpp:406] Eltwise20_M2PELU41_0_split <- Eltwise20
I0928 09:32:12.614379  4247 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_0
I0928 09:32:12.614383  4247 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_1
I0928 09:32:12.614408  4247 net.cpp:122] Setting up Eltwise20_M2PELU41_0_split
I0928 09:32:12.614411  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.614414  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.614416  4247 net.cpp:137] Memory required for data: 815046800
I0928 09:32:12.614423  4247 layer_factory.hpp:77] Creating layer Convolution44
I0928 09:32:12.614430  4247 net.cpp:84] Creating Layer Convolution44
I0928 09:32:12.614434  4247 net.cpp:406] Convolution44 <- Eltwise20_M2PELU41_0_split_0
I0928 09:32:12.614437  4247 net.cpp:380] Convolution44 -> Convolution44
I0928 09:32:12.616106  4247 net.cpp:122] Setting up Convolution44
I0928 09:32:12.616116  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.616118  4247 net.cpp:137] Memory required for data: 816301200
I0928 09:32:12.616122  4247 layer_factory.hpp:77] Creating layer BatchNorm44
I0928 09:32:12.616128  4247 net.cpp:84] Creating Layer BatchNorm44
I0928 09:32:12.616132  4247 net.cpp:406] BatchNorm44 <- Convolution44
I0928 09:32:12.616135  4247 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I0928 09:32:12.616276  4247 net.cpp:122] Setting up BatchNorm44
I0928 09:32:12.616279  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.616281  4247 net.cpp:137] Memory required for data: 817555600
I0928 09:32:12.616286  4247 layer_factory.hpp:77] Creating layer Scale44
I0928 09:32:12.616291  4247 net.cpp:84] Creating Layer Scale44
I0928 09:32:12.616293  4247 net.cpp:406] Scale44 <- Convolution44
I0928 09:32:12.616297  4247 net.cpp:367] Scale44 -> Convolution44 (in-place)
I0928 09:32:12.616324  4247 layer_factory.hpp:77] Creating layer Scale44
I0928 09:32:12.616403  4247 net.cpp:122] Setting up Scale44
I0928 09:32:12.616407  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.616410  4247 net.cpp:137] Memory required for data: 818810000
I0928 09:32:12.616413  4247 layer_factory.hpp:77] Creating layer M2PELU42
I0928 09:32:12.616418  4247 net.cpp:84] Creating Layer M2PELU42
I0928 09:32:12.616420  4247 net.cpp:406] M2PELU42 <- Convolution44
I0928 09:32:12.616425  4247 net.cpp:367] M2PELU42 -> Convolution44 (in-place)
I0928 09:32:12.616510  4247 net.cpp:122] Setting up M2PELU42
I0928 09:32:12.616515  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.616518  4247 net.cpp:137] Memory required for data: 820064400
I0928 09:32:12.616520  4247 layer_factory.hpp:77] Creating layer Convolution45
I0928 09:32:12.616526  4247 net.cpp:84] Creating Layer Convolution45
I0928 09:32:12.616528  4247 net.cpp:406] Convolution45 <- Convolution44
I0928 09:32:12.616533  4247 net.cpp:380] Convolution45 -> Convolution45
I0928 09:32:12.618466  4247 net.cpp:122] Setting up Convolution45
I0928 09:32:12.618475  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.618477  4247 net.cpp:137] Memory required for data: 821318800
I0928 09:32:12.618482  4247 layer_factory.hpp:77] Creating layer BatchNorm45
I0928 09:32:12.618489  4247 net.cpp:84] Creating Layer BatchNorm45
I0928 09:32:12.618490  4247 net.cpp:406] BatchNorm45 <- Convolution45
I0928 09:32:12.618494  4247 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I0928 09:32:12.618664  4247 net.cpp:122] Setting up BatchNorm45
I0928 09:32:12.618670  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.618672  4247 net.cpp:137] Memory required for data: 822573200
I0928 09:32:12.618677  4247 layer_factory.hpp:77] Creating layer Scale45
I0928 09:32:12.618680  4247 net.cpp:84] Creating Layer Scale45
I0928 09:32:12.618683  4247 net.cpp:406] Scale45 <- Convolution45
I0928 09:32:12.618686  4247 net.cpp:367] Scale45 -> Convolution45 (in-place)
I0928 09:32:12.618715  4247 layer_factory.hpp:77] Creating layer Scale45
I0928 09:32:12.618798  4247 net.cpp:122] Setting up Scale45
I0928 09:32:12.618803  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.618804  4247 net.cpp:137] Memory required for data: 823827600
I0928 09:32:12.618808  4247 layer_factory.hpp:77] Creating layer Eltwise21
I0928 09:32:12.618811  4247 net.cpp:84] Creating Layer Eltwise21
I0928 09:32:12.618814  4247 net.cpp:406] Eltwise21 <- Eltwise20_M2PELU41_0_split_1
I0928 09:32:12.618818  4247 net.cpp:406] Eltwise21 <- Convolution45
I0928 09:32:12.618821  4247 net.cpp:380] Eltwise21 -> Eltwise21
I0928 09:32:12.618839  4247 net.cpp:122] Setting up Eltwise21
I0928 09:32:12.618841  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.618850  4247 net.cpp:137] Memory required for data: 825082000
I0928 09:32:12.618852  4247 layer_factory.hpp:77] Creating layer M2PELU43
I0928 09:32:12.618857  4247 net.cpp:84] Creating Layer M2PELU43
I0928 09:32:12.618868  4247 net.cpp:406] M2PELU43 <- Eltwise21
I0928 09:32:12.618871  4247 net.cpp:367] M2PELU43 -> Eltwise21 (in-place)
I0928 09:32:12.618965  4247 net.cpp:122] Setting up M2PELU43
I0928 09:32:12.618969  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.618971  4247 net.cpp:137] Memory required for data: 826336400
I0928 09:32:12.618975  4247 layer_factory.hpp:77] Creating layer Eltwise21_M2PELU43_0_split
I0928 09:32:12.618979  4247 net.cpp:84] Creating Layer Eltwise21_M2PELU43_0_split
I0928 09:32:12.618981  4247 net.cpp:406] Eltwise21_M2PELU43_0_split <- Eltwise21
I0928 09:32:12.618984  4247 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_0
I0928 09:32:12.618988  4247 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_1
I0928 09:32:12.619014  4247 net.cpp:122] Setting up Eltwise21_M2PELU43_0_split
I0928 09:32:12.619019  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.619020  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.619022  4247 net.cpp:137] Memory required for data: 828845200
I0928 09:32:12.619025  4247 layer_factory.hpp:77] Creating layer Convolution46
I0928 09:32:12.619031  4247 net.cpp:84] Creating Layer Convolution46
I0928 09:32:12.619033  4247 net.cpp:406] Convolution46 <- Eltwise21_M2PELU43_0_split_0
I0928 09:32:12.619037  4247 net.cpp:380] Convolution46 -> Convolution46
I0928 09:32:12.620728  4247 net.cpp:122] Setting up Convolution46
I0928 09:32:12.620736  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.620739  4247 net.cpp:137] Memory required for data: 830099600
I0928 09:32:12.620743  4247 layer_factory.hpp:77] Creating layer BatchNorm46
I0928 09:32:12.620748  4247 net.cpp:84] Creating Layer BatchNorm46
I0928 09:32:12.620751  4247 net.cpp:406] BatchNorm46 <- Convolution46
I0928 09:32:12.620755  4247 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I0928 09:32:12.620908  4247 net.cpp:122] Setting up BatchNorm46
I0928 09:32:12.620913  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.620914  4247 net.cpp:137] Memory required for data: 831354000
I0928 09:32:12.620919  4247 layer_factory.hpp:77] Creating layer Scale46
I0928 09:32:12.620923  4247 net.cpp:84] Creating Layer Scale46
I0928 09:32:12.620925  4247 net.cpp:406] Scale46 <- Convolution46
I0928 09:32:12.620929  4247 net.cpp:367] Scale46 -> Convolution46 (in-place)
I0928 09:32:12.620957  4247 layer_factory.hpp:77] Creating layer Scale46
I0928 09:32:12.621037  4247 net.cpp:122] Setting up Scale46
I0928 09:32:12.621042  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.621044  4247 net.cpp:137] Memory required for data: 832608400
I0928 09:32:12.621047  4247 layer_factory.hpp:77] Creating layer M2PELU44
I0928 09:32:12.621052  4247 net.cpp:84] Creating Layer M2PELU44
I0928 09:32:12.621055  4247 net.cpp:406] M2PELU44 <- Convolution46
I0928 09:32:12.621059  4247 net.cpp:367] M2PELU44 -> Convolution46 (in-place)
I0928 09:32:12.621146  4247 net.cpp:122] Setting up M2PELU44
I0928 09:32:12.621150  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.621152  4247 net.cpp:137] Memory required for data: 833862800
I0928 09:32:12.621156  4247 layer_factory.hpp:77] Creating layer Convolution47
I0928 09:32:12.621162  4247 net.cpp:84] Creating Layer Convolution47
I0928 09:32:12.621165  4247 net.cpp:406] Convolution47 <- Convolution46
I0928 09:32:12.621170  4247 net.cpp:380] Convolution47 -> Convolution47
I0928 09:32:12.622817  4247 net.cpp:122] Setting up Convolution47
I0928 09:32:12.622826  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.622828  4247 net.cpp:137] Memory required for data: 835117200
I0928 09:32:12.622833  4247 layer_factory.hpp:77] Creating layer BatchNorm47
I0928 09:32:12.622838  4247 net.cpp:84] Creating Layer BatchNorm47
I0928 09:32:12.622846  4247 net.cpp:406] BatchNorm47 <- Convolution47
I0928 09:32:12.622853  4247 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I0928 09:32:12.622995  4247 net.cpp:122] Setting up BatchNorm47
I0928 09:32:12.623000  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.623003  4247 net.cpp:137] Memory required for data: 836371600
I0928 09:32:12.623008  4247 layer_factory.hpp:77] Creating layer Scale47
I0928 09:32:12.623010  4247 net.cpp:84] Creating Layer Scale47
I0928 09:32:12.623013  4247 net.cpp:406] Scale47 <- Convolution47
I0928 09:32:12.623016  4247 net.cpp:367] Scale47 -> Convolution47 (in-place)
I0928 09:32:12.623044  4247 layer_factory.hpp:77] Creating layer Scale47
I0928 09:32:12.623124  4247 net.cpp:122] Setting up Scale47
I0928 09:32:12.623128  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.623131  4247 net.cpp:137] Memory required for data: 837626000
I0928 09:32:12.623134  4247 layer_factory.hpp:77] Creating layer Eltwise22
I0928 09:32:12.623138  4247 net.cpp:84] Creating Layer Eltwise22
I0928 09:32:12.623142  4247 net.cpp:406] Eltwise22 <- Eltwise21_M2PELU43_0_split_1
I0928 09:32:12.623143  4247 net.cpp:406] Eltwise22 <- Convolution47
I0928 09:32:12.623147  4247 net.cpp:380] Eltwise22 -> Eltwise22
I0928 09:32:12.623163  4247 net.cpp:122] Setting up Eltwise22
I0928 09:32:12.623167  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.623169  4247 net.cpp:137] Memory required for data: 838880400
I0928 09:32:12.623172  4247 layer_factory.hpp:77] Creating layer M2PELU45
I0928 09:32:12.623178  4247 net.cpp:84] Creating Layer M2PELU45
I0928 09:32:12.623179  4247 net.cpp:406] M2PELU45 <- Eltwise22
I0928 09:32:12.623183  4247 net.cpp:367] M2PELU45 -> Eltwise22 (in-place)
I0928 09:32:12.623270  4247 net.cpp:122] Setting up M2PELU45
I0928 09:32:12.623275  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.623276  4247 net.cpp:137] Memory required for data: 840134800
I0928 09:32:12.623280  4247 layer_factory.hpp:77] Creating layer Eltwise22_M2PELU45_0_split
I0928 09:32:12.623283  4247 net.cpp:84] Creating Layer Eltwise22_M2PELU45_0_split
I0928 09:32:12.623286  4247 net.cpp:406] Eltwise22_M2PELU45_0_split <- Eltwise22
I0928 09:32:12.623289  4247 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_0
I0928 09:32:12.623293  4247 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_1
I0928 09:32:12.623317  4247 net.cpp:122] Setting up Eltwise22_M2PELU45_0_split
I0928 09:32:12.623322  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.623323  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.623325  4247 net.cpp:137] Memory required for data: 842643600
I0928 09:32:12.623327  4247 layer_factory.hpp:77] Creating layer Convolution48
I0928 09:32:12.623332  4247 net.cpp:84] Creating Layer Convolution48
I0928 09:32:12.623335  4247 net.cpp:406] Convolution48 <- Eltwise22_M2PELU45_0_split_0
I0928 09:32:12.623339  4247 net.cpp:380] Convolution48 -> Convolution48
I0928 09:32:12.624958  4247 net.cpp:122] Setting up Convolution48
I0928 09:32:12.624967  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.624969  4247 net.cpp:137] Memory required for data: 843898000
I0928 09:32:12.624974  4247 layer_factory.hpp:77] Creating layer BatchNorm48
I0928 09:32:12.624979  4247 net.cpp:84] Creating Layer BatchNorm48
I0928 09:32:12.624981  4247 net.cpp:406] BatchNorm48 <- Convolution48
I0928 09:32:12.624985  4247 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I0928 09:32:12.625128  4247 net.cpp:122] Setting up BatchNorm48
I0928 09:32:12.625131  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.625134  4247 net.cpp:137] Memory required for data: 845152400
I0928 09:32:12.625138  4247 layer_factory.hpp:77] Creating layer Scale48
I0928 09:32:12.625142  4247 net.cpp:84] Creating Layer Scale48
I0928 09:32:12.625144  4247 net.cpp:406] Scale48 <- Convolution48
I0928 09:32:12.625147  4247 net.cpp:367] Scale48 -> Convolution48 (in-place)
I0928 09:32:12.625176  4247 layer_factory.hpp:77] Creating layer Scale48
I0928 09:32:12.625267  4247 net.cpp:122] Setting up Scale48
I0928 09:32:12.625272  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.625273  4247 net.cpp:137] Memory required for data: 846406800
I0928 09:32:12.625277  4247 layer_factory.hpp:77] Creating layer M2PELU46
I0928 09:32:12.625283  4247 net.cpp:84] Creating Layer M2PELU46
I0928 09:32:12.625285  4247 net.cpp:406] M2PELU46 <- Convolution48
I0928 09:32:12.625289  4247 net.cpp:367] M2PELU46 -> Convolution48 (in-place)
I0928 09:32:12.625380  4247 net.cpp:122] Setting up M2PELU46
I0928 09:32:12.625385  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.625386  4247 net.cpp:137] Memory required for data: 847661200
I0928 09:32:12.625389  4247 layer_factory.hpp:77] Creating layer Convolution49
I0928 09:32:12.625396  4247 net.cpp:84] Creating Layer Convolution49
I0928 09:32:12.625398  4247 net.cpp:406] Convolution49 <- Convolution48
I0928 09:32:12.625402  4247 net.cpp:380] Convolution49 -> Convolution49
I0928 09:32:12.627367  4247 net.cpp:122] Setting up Convolution49
I0928 09:32:12.627377  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.627378  4247 net.cpp:137] Memory required for data: 848915600
I0928 09:32:12.627384  4247 layer_factory.hpp:77] Creating layer BatchNorm49
I0928 09:32:12.627388  4247 net.cpp:84] Creating Layer BatchNorm49
I0928 09:32:12.627391  4247 net.cpp:406] BatchNorm49 <- Convolution49
I0928 09:32:12.627394  4247 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I0928 09:32:12.627540  4247 net.cpp:122] Setting up BatchNorm49
I0928 09:32:12.627544  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.627547  4247 net.cpp:137] Memory required for data: 850170000
I0928 09:32:12.627552  4247 layer_factory.hpp:77] Creating layer Scale49
I0928 09:32:12.627555  4247 net.cpp:84] Creating Layer Scale49
I0928 09:32:12.627558  4247 net.cpp:406] Scale49 <- Convolution49
I0928 09:32:12.627562  4247 net.cpp:367] Scale49 -> Convolution49 (in-place)
I0928 09:32:12.627589  4247 layer_factory.hpp:77] Creating layer Scale49
I0928 09:32:12.627671  4247 net.cpp:122] Setting up Scale49
I0928 09:32:12.627676  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.627678  4247 net.cpp:137] Memory required for data: 851424400
I0928 09:32:12.627682  4247 layer_factory.hpp:77] Creating layer Eltwise23
I0928 09:32:12.627686  4247 net.cpp:84] Creating Layer Eltwise23
I0928 09:32:12.627688  4247 net.cpp:406] Eltwise23 <- Eltwise22_M2PELU45_0_split_1
I0928 09:32:12.627691  4247 net.cpp:406] Eltwise23 <- Convolution49
I0928 09:32:12.627694  4247 net.cpp:380] Eltwise23 -> Eltwise23
I0928 09:32:12.627712  4247 net.cpp:122] Setting up Eltwise23
I0928 09:32:12.627715  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.627717  4247 net.cpp:137] Memory required for data: 852678800
I0928 09:32:12.627719  4247 layer_factory.hpp:77] Creating layer M2PELU47
I0928 09:32:12.627724  4247 net.cpp:84] Creating Layer M2PELU47
I0928 09:32:12.627727  4247 net.cpp:406] M2PELU47 <- Eltwise23
I0928 09:32:12.627729  4247 net.cpp:367] M2PELU47 -> Eltwise23 (in-place)
I0928 09:32:12.627817  4247 net.cpp:122] Setting up M2PELU47
I0928 09:32:12.627821  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.627823  4247 net.cpp:137] Memory required for data: 853933200
I0928 09:32:12.627827  4247 layer_factory.hpp:77] Creating layer Eltwise23_M2PELU47_0_split
I0928 09:32:12.627830  4247 net.cpp:84] Creating Layer Eltwise23_M2PELU47_0_split
I0928 09:32:12.627832  4247 net.cpp:406] Eltwise23_M2PELU47_0_split <- Eltwise23
I0928 09:32:12.627836  4247 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_0
I0928 09:32:12.627841  4247 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_1
I0928 09:32:12.627866  4247 net.cpp:122] Setting up Eltwise23_M2PELU47_0_split
I0928 09:32:12.627868  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.627871  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.627873  4247 net.cpp:137] Memory required for data: 856442000
I0928 09:32:12.627882  4247 layer_factory.hpp:77] Creating layer Convolution50
I0928 09:32:12.627889  4247 net.cpp:84] Creating Layer Convolution50
I0928 09:32:12.627892  4247 net.cpp:406] Convolution50 <- Eltwise23_M2PELU47_0_split_0
I0928 09:32:12.627895  4247 net.cpp:380] Convolution50 -> Convolution50
I0928 09:32:12.629536  4247 net.cpp:122] Setting up Convolution50
I0928 09:32:12.629546  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.629549  4247 net.cpp:137] Memory required for data: 857696400
I0928 09:32:12.629554  4247 layer_factory.hpp:77] Creating layer BatchNorm50
I0928 09:32:12.629560  4247 net.cpp:84] Creating Layer BatchNorm50
I0928 09:32:12.629562  4247 net.cpp:406] BatchNorm50 <- Convolution50
I0928 09:32:12.629566  4247 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I0928 09:32:12.629709  4247 net.cpp:122] Setting up BatchNorm50
I0928 09:32:12.629714  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.638007  4247 net.cpp:137] Memory required for data: 858950800
I0928 09:32:12.638013  4247 layer_factory.hpp:77] Creating layer Scale50
I0928 09:32:12.638018  4247 net.cpp:84] Creating Layer Scale50
I0928 09:32:12.638021  4247 net.cpp:406] Scale50 <- Convolution50
I0928 09:32:12.638025  4247 net.cpp:367] Scale50 -> Convolution50 (in-place)
I0928 09:32:12.638059  4247 layer_factory.hpp:77] Creating layer Scale50
I0928 09:32:12.638150  4247 net.cpp:122] Setting up Scale50
I0928 09:32:12.638155  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.638159  4247 net.cpp:137] Memory required for data: 860205200
I0928 09:32:12.638162  4247 layer_factory.hpp:77] Creating layer M2PELU48
I0928 09:32:12.638169  4247 net.cpp:84] Creating Layer M2PELU48
I0928 09:32:12.638171  4247 net.cpp:406] M2PELU48 <- Convolution50
I0928 09:32:12.638175  4247 net.cpp:367] M2PELU48 -> Convolution50 (in-place)
I0928 09:32:12.638273  4247 net.cpp:122] Setting up M2PELU48
I0928 09:32:12.638278  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.638280  4247 net.cpp:137] Memory required for data: 861459600
I0928 09:32:12.638284  4247 layer_factory.hpp:77] Creating layer Convolution51
I0928 09:32:12.638291  4247 net.cpp:84] Creating Layer Convolution51
I0928 09:32:12.638293  4247 net.cpp:406] Convolution51 <- Convolution50
I0928 09:32:12.638298  4247 net.cpp:380] Convolution51 -> Convolution51
I0928 09:32:12.641049  4247 net.cpp:122] Setting up Convolution51
I0928 09:32:12.641058  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.641062  4247 net.cpp:137] Memory required for data: 862714000
I0928 09:32:12.641067  4247 layer_factory.hpp:77] Creating layer BatchNorm51
I0928 09:32:12.641072  4247 net.cpp:84] Creating Layer BatchNorm51
I0928 09:32:12.641074  4247 net.cpp:406] BatchNorm51 <- Convolution51
I0928 09:32:12.641077  4247 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I0928 09:32:12.641227  4247 net.cpp:122] Setting up BatchNorm51
I0928 09:32:12.641232  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.641234  4247 net.cpp:137] Memory required for data: 863968400
I0928 09:32:12.641239  4247 layer_factory.hpp:77] Creating layer Scale51
I0928 09:32:12.641243  4247 net.cpp:84] Creating Layer Scale51
I0928 09:32:12.641245  4247 net.cpp:406] Scale51 <- Convolution51
I0928 09:32:12.641249  4247 net.cpp:367] Scale51 -> Convolution51 (in-place)
I0928 09:32:12.641278  4247 layer_factory.hpp:77] Creating layer Scale51
I0928 09:32:12.641362  4247 net.cpp:122] Setting up Scale51
I0928 09:32:12.641367  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.641369  4247 net.cpp:137] Memory required for data: 865222800
I0928 09:32:12.641373  4247 layer_factory.hpp:77] Creating layer Eltwise24
I0928 09:32:12.641377  4247 net.cpp:84] Creating Layer Eltwise24
I0928 09:32:12.641381  4247 net.cpp:406] Eltwise24 <- Eltwise23_M2PELU47_0_split_1
I0928 09:32:12.641383  4247 net.cpp:406] Eltwise24 <- Convolution51
I0928 09:32:12.641386  4247 net.cpp:380] Eltwise24 -> Eltwise24
I0928 09:32:12.641404  4247 net.cpp:122] Setting up Eltwise24
I0928 09:32:12.641414  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.641417  4247 net.cpp:137] Memory required for data: 866477200
I0928 09:32:12.641419  4247 layer_factory.hpp:77] Creating layer M2PELU49
I0928 09:32:12.641424  4247 net.cpp:84] Creating Layer M2PELU49
I0928 09:32:12.641427  4247 net.cpp:406] M2PELU49 <- Eltwise24
I0928 09:32:12.641430  4247 net.cpp:367] M2PELU49 -> Eltwise24 (in-place)
I0928 09:32:12.641523  4247 net.cpp:122] Setting up M2PELU49
I0928 09:32:12.641527  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.641530  4247 net.cpp:137] Memory required for data: 867731600
I0928 09:32:12.641533  4247 layer_factory.hpp:77] Creating layer Eltwise24_M2PELU49_0_split
I0928 09:32:12.641537  4247 net.cpp:84] Creating Layer Eltwise24_M2PELU49_0_split
I0928 09:32:12.641540  4247 net.cpp:406] Eltwise24_M2PELU49_0_split <- Eltwise24
I0928 09:32:12.641543  4247 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_0
I0928 09:32:12.641547  4247 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_1
I0928 09:32:12.641583  4247 net.cpp:122] Setting up Eltwise24_M2PELU49_0_split
I0928 09:32:12.641587  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.641589  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.641592  4247 net.cpp:137] Memory required for data: 870240400
I0928 09:32:12.641593  4247 layer_factory.hpp:77] Creating layer Convolution52
I0928 09:32:12.641609  4247 net.cpp:84] Creating Layer Convolution52
I0928 09:32:12.641611  4247 net.cpp:406] Convolution52 <- Eltwise24_M2PELU49_0_split_0
I0928 09:32:12.641615  4247 net.cpp:380] Convolution52 -> Convolution52
I0928 09:32:12.643425  4247 net.cpp:122] Setting up Convolution52
I0928 09:32:12.643435  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.643437  4247 net.cpp:137] Memory required for data: 871494800
I0928 09:32:12.643441  4247 layer_factory.hpp:77] Creating layer BatchNorm52
I0928 09:32:12.643447  4247 net.cpp:84] Creating Layer BatchNorm52
I0928 09:32:12.643450  4247 net.cpp:406] BatchNorm52 <- Convolution52
I0928 09:32:12.643455  4247 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I0928 09:32:12.643604  4247 net.cpp:122] Setting up BatchNorm52
I0928 09:32:12.643610  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.643611  4247 net.cpp:137] Memory required for data: 872749200
I0928 09:32:12.643616  4247 layer_factory.hpp:77] Creating layer Scale52
I0928 09:32:12.643621  4247 net.cpp:84] Creating Layer Scale52
I0928 09:32:12.643623  4247 net.cpp:406] Scale52 <- Convolution52
I0928 09:32:12.643626  4247 net.cpp:367] Scale52 -> Convolution52 (in-place)
I0928 09:32:12.643657  4247 layer_factory.hpp:77] Creating layer Scale52
I0928 09:32:12.643743  4247 net.cpp:122] Setting up Scale52
I0928 09:32:12.643748  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.643749  4247 net.cpp:137] Memory required for data: 874003600
I0928 09:32:12.643752  4247 layer_factory.hpp:77] Creating layer M2PELU50
I0928 09:32:12.643759  4247 net.cpp:84] Creating Layer M2PELU50
I0928 09:32:12.643760  4247 net.cpp:406] M2PELU50 <- Convolution52
I0928 09:32:12.643764  4247 net.cpp:367] M2PELU50 -> Convolution52 (in-place)
I0928 09:32:12.643858  4247 net.cpp:122] Setting up M2PELU50
I0928 09:32:12.643862  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.643864  4247 net.cpp:137] Memory required for data: 875258000
I0928 09:32:12.643868  4247 layer_factory.hpp:77] Creating layer Convolution53
I0928 09:32:12.643890  4247 net.cpp:84] Creating Layer Convolution53
I0928 09:32:12.643893  4247 net.cpp:406] Convolution53 <- Convolution52
I0928 09:32:12.643898  4247 net.cpp:380] Convolution53 -> Convolution53
I0928 09:32:12.645911  4247 net.cpp:122] Setting up Convolution53
I0928 09:32:12.645921  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.645925  4247 net.cpp:137] Memory required for data: 876512400
I0928 09:32:12.645929  4247 layer_factory.hpp:77] Creating layer BatchNorm53
I0928 09:32:12.645934  4247 net.cpp:84] Creating Layer BatchNorm53
I0928 09:32:12.645944  4247 net.cpp:406] BatchNorm53 <- Convolution53
I0928 09:32:12.645949  4247 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I0928 09:32:12.646101  4247 net.cpp:122] Setting up BatchNorm53
I0928 09:32:12.646106  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.646108  4247 net.cpp:137] Memory required for data: 877766800
I0928 09:32:12.646113  4247 layer_factory.hpp:77] Creating layer Scale53
I0928 09:32:12.646117  4247 net.cpp:84] Creating Layer Scale53
I0928 09:32:12.646119  4247 net.cpp:406] Scale53 <- Convolution53
I0928 09:32:12.646123  4247 net.cpp:367] Scale53 -> Convolution53 (in-place)
I0928 09:32:12.646152  4247 layer_factory.hpp:77] Creating layer Scale53
I0928 09:32:12.646239  4247 net.cpp:122] Setting up Scale53
I0928 09:32:12.646244  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.646245  4247 net.cpp:137] Memory required for data: 879021200
I0928 09:32:12.646250  4247 layer_factory.hpp:77] Creating layer Eltwise25
I0928 09:32:12.646253  4247 net.cpp:84] Creating Layer Eltwise25
I0928 09:32:12.646255  4247 net.cpp:406] Eltwise25 <- Eltwise24_M2PELU49_0_split_1
I0928 09:32:12.646258  4247 net.cpp:406] Eltwise25 <- Convolution53
I0928 09:32:12.646262  4247 net.cpp:380] Eltwise25 -> Eltwise25
I0928 09:32:12.646281  4247 net.cpp:122] Setting up Eltwise25
I0928 09:32:12.646284  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.646286  4247 net.cpp:137] Memory required for data: 880275600
I0928 09:32:12.646288  4247 layer_factory.hpp:77] Creating layer M2PELU51
I0928 09:32:12.646292  4247 net.cpp:84] Creating Layer M2PELU51
I0928 09:32:12.646294  4247 net.cpp:406] M2PELU51 <- Eltwise25
I0928 09:32:12.646298  4247 net.cpp:367] M2PELU51 -> Eltwise25 (in-place)
I0928 09:32:12.646391  4247 net.cpp:122] Setting up M2PELU51
I0928 09:32:12.646396  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.646399  4247 net.cpp:137] Memory required for data: 881530000
I0928 09:32:12.646401  4247 layer_factory.hpp:77] Creating layer Eltwise25_M2PELU51_0_split
I0928 09:32:12.646406  4247 net.cpp:84] Creating Layer Eltwise25_M2PELU51_0_split
I0928 09:32:12.646409  4247 net.cpp:406] Eltwise25_M2PELU51_0_split <- Eltwise25
I0928 09:32:12.646411  4247 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_0
I0928 09:32:12.646415  4247 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_1
I0928 09:32:12.646441  4247 net.cpp:122] Setting up Eltwise25_M2PELU51_0_split
I0928 09:32:12.646445  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.646447  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.646450  4247 net.cpp:137] Memory required for data: 884038800
I0928 09:32:12.646452  4247 layer_factory.hpp:77] Creating layer Convolution54
I0928 09:32:12.646457  4247 net.cpp:84] Creating Layer Convolution54
I0928 09:32:12.646461  4247 net.cpp:406] Convolution54 <- Eltwise25_M2PELU51_0_split_0
I0928 09:32:12.646464  4247 net.cpp:380] Convolution54 -> Convolution54
I0928 09:32:12.648687  4247 net.cpp:122] Setting up Convolution54
I0928 09:32:12.648697  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.648699  4247 net.cpp:137] Memory required for data: 885293200
I0928 09:32:12.648705  4247 layer_factory.hpp:77] Creating layer BatchNorm54
I0928 09:32:12.648710  4247 net.cpp:84] Creating Layer BatchNorm54
I0928 09:32:12.648712  4247 net.cpp:406] BatchNorm54 <- Convolution54
I0928 09:32:12.648716  4247 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I0928 09:32:12.648867  4247 net.cpp:122] Setting up BatchNorm54
I0928 09:32:12.648872  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.648874  4247 net.cpp:137] Memory required for data: 886547600
I0928 09:32:12.648880  4247 layer_factory.hpp:77] Creating layer Scale54
I0928 09:32:12.648883  4247 net.cpp:84] Creating Layer Scale54
I0928 09:32:12.648886  4247 net.cpp:406] Scale54 <- Convolution54
I0928 09:32:12.648890  4247 net.cpp:367] Scale54 -> Convolution54 (in-place)
I0928 09:32:12.648921  4247 layer_factory.hpp:77] Creating layer Scale54
I0928 09:32:12.649016  4247 net.cpp:122] Setting up Scale54
I0928 09:32:12.649021  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.649024  4247 net.cpp:137] Memory required for data: 887802000
I0928 09:32:12.649027  4247 layer_factory.hpp:77] Creating layer M2PELU52
I0928 09:32:12.649032  4247 net.cpp:84] Creating Layer M2PELU52
I0928 09:32:12.649035  4247 net.cpp:406] M2PELU52 <- Convolution54
I0928 09:32:12.649039  4247 net.cpp:367] M2PELU52 -> Convolution54 (in-place)
I0928 09:32:12.649132  4247 net.cpp:122] Setting up M2PELU52
I0928 09:32:12.649137  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.649139  4247 net.cpp:137] Memory required for data: 889056400
I0928 09:32:12.649142  4247 layer_factory.hpp:77] Creating layer Convolution55
I0928 09:32:12.649148  4247 net.cpp:84] Creating Layer Convolution55
I0928 09:32:12.649152  4247 net.cpp:406] Convolution55 <- Convolution54
I0928 09:32:12.649155  4247 net.cpp:380] Convolution55 -> Convolution55
I0928 09:32:12.651193  4247 net.cpp:122] Setting up Convolution55
I0928 09:32:12.651202  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.651204  4247 net.cpp:137] Memory required for data: 890310800
I0928 09:32:12.651211  4247 layer_factory.hpp:77] Creating layer BatchNorm55
I0928 09:32:12.651214  4247 net.cpp:84] Creating Layer BatchNorm55
I0928 09:32:12.651217  4247 net.cpp:406] BatchNorm55 <- Convolution55
I0928 09:32:12.651221  4247 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I0928 09:32:12.651374  4247 net.cpp:122] Setting up BatchNorm55
I0928 09:32:12.651379  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.651381  4247 net.cpp:137] Memory required for data: 891565200
I0928 09:32:12.651386  4247 layer_factory.hpp:77] Creating layer Scale55
I0928 09:32:12.651391  4247 net.cpp:84] Creating Layer Scale55
I0928 09:32:12.651392  4247 net.cpp:406] Scale55 <- Convolution55
I0928 09:32:12.651396  4247 net.cpp:367] Scale55 -> Convolution55 (in-place)
I0928 09:32:12.651427  4247 layer_factory.hpp:77] Creating layer Scale55
I0928 09:32:12.651515  4247 net.cpp:122] Setting up Scale55
I0928 09:32:12.651518  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.651520  4247 net.cpp:137] Memory required for data: 892819600
I0928 09:32:12.651525  4247 layer_factory.hpp:77] Creating layer Eltwise26
I0928 09:32:12.651528  4247 net.cpp:84] Creating Layer Eltwise26
I0928 09:32:12.651531  4247 net.cpp:406] Eltwise26 <- Eltwise25_M2PELU51_0_split_1
I0928 09:32:12.651535  4247 net.cpp:406] Eltwise26 <- Convolution55
I0928 09:32:12.651538  4247 net.cpp:380] Eltwise26 -> Eltwise26
I0928 09:32:12.651556  4247 net.cpp:122] Setting up Eltwise26
I0928 09:32:12.651558  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.651561  4247 net.cpp:137] Memory required for data: 894074000
I0928 09:32:12.651562  4247 layer_factory.hpp:77] Creating layer M2PELU53
I0928 09:32:12.651568  4247 net.cpp:84] Creating Layer M2PELU53
I0928 09:32:12.651571  4247 net.cpp:406] M2PELU53 <- Eltwise26
I0928 09:32:12.651573  4247 net.cpp:367] M2PELU53 -> Eltwise26 (in-place)
I0928 09:32:12.651667  4247 net.cpp:122] Setting up M2PELU53
I0928 09:32:12.651671  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.651674  4247 net.cpp:137] Memory required for data: 895328400
I0928 09:32:12.651677  4247 layer_factory.hpp:77] Creating layer Eltwise26_M2PELU53_0_split
I0928 09:32:12.651680  4247 net.cpp:84] Creating Layer Eltwise26_M2PELU53_0_split
I0928 09:32:12.651682  4247 net.cpp:406] Eltwise26_M2PELU53_0_split <- Eltwise26
I0928 09:32:12.651686  4247 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_0
I0928 09:32:12.651690  4247 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_1
I0928 09:32:12.651716  4247 net.cpp:122] Setting up Eltwise26_M2PELU53_0_split
I0928 09:32:12.651721  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.651722  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.651724  4247 net.cpp:137] Memory required for data: 897837200
I0928 09:32:12.651733  4247 layer_factory.hpp:77] Creating layer Convolution56
I0928 09:32:12.651739  4247 net.cpp:84] Creating Layer Convolution56
I0928 09:32:12.651742  4247 net.cpp:406] Convolution56 <- Eltwise26_M2PELU53_0_split_0
I0928 09:32:12.651746  4247 net.cpp:380] Convolution56 -> Convolution56
I0928 09:32:12.653450  4247 net.cpp:122] Setting up Convolution56
I0928 09:32:12.653460  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.653461  4247 net.cpp:137] Memory required for data: 899091600
I0928 09:32:12.653466  4247 layer_factory.hpp:77] Creating layer BatchNorm56
I0928 09:32:12.653471  4247 net.cpp:84] Creating Layer BatchNorm56
I0928 09:32:12.653475  4247 net.cpp:406] BatchNorm56 <- Convolution56
I0928 09:32:12.653478  4247 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I0928 09:32:12.668983  4247 net.cpp:122] Setting up BatchNorm56
I0928 09:32:12.668993  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.668997  4247 net.cpp:137] Memory required for data: 900346000
I0928 09:32:12.669001  4247 layer_factory.hpp:77] Creating layer Scale56
I0928 09:32:12.669008  4247 net.cpp:84] Creating Layer Scale56
I0928 09:32:12.669011  4247 net.cpp:406] Scale56 <- Convolution56
I0928 09:32:12.669015  4247 net.cpp:367] Scale56 -> Convolution56 (in-place)
I0928 09:32:12.669049  4247 layer_factory.hpp:77] Creating layer Scale56
I0928 09:32:12.669143  4247 net.cpp:122] Setting up Scale56
I0928 09:32:12.669148  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.669152  4247 net.cpp:137] Memory required for data: 901600400
I0928 09:32:12.669155  4247 layer_factory.hpp:77] Creating layer M2PELU54
I0928 09:32:12.669162  4247 net.cpp:84] Creating Layer M2PELU54
I0928 09:32:12.669163  4247 net.cpp:406] M2PELU54 <- Convolution56
I0928 09:32:12.669168  4247 net.cpp:367] M2PELU54 -> Convolution56 (in-place)
I0928 09:32:12.669270  4247 net.cpp:122] Setting up M2PELU54
I0928 09:32:12.669275  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.669277  4247 net.cpp:137] Memory required for data: 902854800
I0928 09:32:12.669281  4247 layer_factory.hpp:77] Creating layer Convolution57
I0928 09:32:12.669287  4247 net.cpp:84] Creating Layer Convolution57
I0928 09:32:12.669289  4247 net.cpp:406] Convolution57 <- Convolution56
I0928 09:32:12.669296  4247 net.cpp:380] Convolution57 -> Convolution57
I0928 09:32:12.671910  4247 net.cpp:122] Setting up Convolution57
I0928 09:32:12.671918  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.671921  4247 net.cpp:137] Memory required for data: 904109200
I0928 09:32:12.671926  4247 layer_factory.hpp:77] Creating layer BatchNorm57
I0928 09:32:12.671931  4247 net.cpp:84] Creating Layer BatchNorm57
I0928 09:32:12.671934  4247 net.cpp:406] BatchNorm57 <- Convolution57
I0928 09:32:12.671938  4247 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I0928 09:32:12.672091  4247 net.cpp:122] Setting up BatchNorm57
I0928 09:32:12.672096  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.672097  4247 net.cpp:137] Memory required for data: 905363600
I0928 09:32:12.672102  4247 layer_factory.hpp:77] Creating layer Scale57
I0928 09:32:12.672106  4247 net.cpp:84] Creating Layer Scale57
I0928 09:32:12.672108  4247 net.cpp:406] Scale57 <- Convolution57
I0928 09:32:12.672111  4247 net.cpp:367] Scale57 -> Convolution57 (in-place)
I0928 09:32:12.672140  4247 layer_factory.hpp:77] Creating layer Scale57
I0928 09:32:12.672228  4247 net.cpp:122] Setting up Scale57
I0928 09:32:12.672232  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.672235  4247 net.cpp:137] Memory required for data: 906618000
I0928 09:32:12.672238  4247 layer_factory.hpp:77] Creating layer Eltwise27
I0928 09:32:12.672242  4247 net.cpp:84] Creating Layer Eltwise27
I0928 09:32:12.672245  4247 net.cpp:406] Eltwise27 <- Eltwise26_M2PELU53_0_split_1
I0928 09:32:12.672248  4247 net.cpp:406] Eltwise27 <- Convolution57
I0928 09:32:12.672251  4247 net.cpp:380] Eltwise27 -> Eltwise27
I0928 09:32:12.672269  4247 net.cpp:122] Setting up Eltwise27
I0928 09:32:12.672281  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.672282  4247 net.cpp:137] Memory required for data: 907872400
I0928 09:32:12.672284  4247 layer_factory.hpp:77] Creating layer M2PELU55
I0928 09:32:12.672291  4247 net.cpp:84] Creating Layer M2PELU55
I0928 09:32:12.672292  4247 net.cpp:406] M2PELU55 <- Eltwise27
I0928 09:32:12.672297  4247 net.cpp:367] M2PELU55 -> Eltwise27 (in-place)
I0928 09:32:12.672391  4247 net.cpp:122] Setting up M2PELU55
I0928 09:32:12.672396  4247 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 09:32:12.672399  4247 net.cpp:137] Memory required for data: 909126800
I0928 09:32:12.672401  4247 layer_factory.hpp:77] Creating layer Pooling1
I0928 09:32:12.672407  4247 net.cpp:84] Creating Layer Pooling1
I0928 09:32:12.672410  4247 net.cpp:406] Pooling1 <- Eltwise27
I0928 09:32:12.672413  4247 net.cpp:380] Pooling1 -> Pooling1
I0928 09:32:12.672955  4247 net.cpp:122] Setting up Pooling1
I0928 09:32:12.672965  4247 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0928 09:32:12.672967  4247 net.cpp:137] Memory required for data: 909152400
I0928 09:32:12.672969  4247 layer_factory.hpp:77] Creating layer InnerProduct1
I0928 09:32:12.672981  4247 net.cpp:84] Creating Layer InnerProduct1
I0928 09:32:12.672983  4247 net.cpp:406] InnerProduct1 <- Pooling1
I0928 09:32:12.672987  4247 net.cpp:380] InnerProduct1 -> InnerProduct1
I0928 09:32:12.673115  4247 net.cpp:122] Setting up InnerProduct1
I0928 09:32:12.673120  4247 net.cpp:129] Top shape: 100 10 (1000)
I0928 09:32:12.673122  4247 net.cpp:137] Memory required for data: 909156400
I0928 09:32:12.673126  4247 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0928 09:32:12.673130  4247 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0928 09:32:12.673132  4247 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I0928 09:32:12.673135  4247 net.cpp:406] SoftmaxWithLoss1 <- Data2
I0928 09:32:12.673140  4247 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0928 09:32:12.673146  4247 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0928 09:32:12.673331  4247 net.cpp:122] Setting up SoftmaxWithLoss1
I0928 09:32:12.673336  4247 net.cpp:129] Top shape: (1)
I0928 09:32:12.673338  4247 net.cpp:132]     with loss weight 1
I0928 09:32:12.673352  4247 net.cpp:137] Memory required for data: 909156404
I0928 09:32:12.673354  4247 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0928 09:32:12.673357  4247 net.cpp:198] InnerProduct1 needs backward computation.
I0928 09:32:12.673358  4247 net.cpp:198] Pooling1 needs backward computation.
I0928 09:32:12.673360  4247 net.cpp:198] M2PELU55 needs backward computation.
I0928 09:32:12.673362  4247 net.cpp:198] Eltwise27 needs backward computation.
I0928 09:32:12.673365  4247 net.cpp:198] Scale57 needs backward computation.
I0928 09:32:12.673367  4247 net.cpp:198] BatchNorm57 needs backward computation.
I0928 09:32:12.673368  4247 net.cpp:198] Convolution57 needs backward computation.
I0928 09:32:12.673370  4247 net.cpp:198] M2PELU54 needs backward computation.
I0928 09:32:12.673372  4247 net.cpp:198] Scale56 needs backward computation.
I0928 09:32:12.673374  4247 net.cpp:198] BatchNorm56 needs backward computation.
I0928 09:32:12.673377  4247 net.cpp:198] Convolution56 needs backward computation.
I0928 09:32:12.673378  4247 net.cpp:198] Eltwise26_M2PELU53_0_split needs backward computation.
I0928 09:32:12.673380  4247 net.cpp:198] M2PELU53 needs backward computation.
I0928 09:32:12.673382  4247 net.cpp:198] Eltwise26 needs backward computation.
I0928 09:32:12.673385  4247 net.cpp:198] Scale55 needs backward computation.
I0928 09:32:12.673388  4247 net.cpp:198] BatchNorm55 needs backward computation.
I0928 09:32:12.673389  4247 net.cpp:198] Convolution55 needs backward computation.
I0928 09:32:12.673391  4247 net.cpp:198] M2PELU52 needs backward computation.
I0928 09:32:12.673393  4247 net.cpp:198] Scale54 needs backward computation.
I0928 09:32:12.673395  4247 net.cpp:198] BatchNorm54 needs backward computation.
I0928 09:32:12.673398  4247 net.cpp:198] Convolution54 needs backward computation.
I0928 09:32:12.673405  4247 net.cpp:198] Eltwise25_M2PELU51_0_split needs backward computation.
I0928 09:32:12.673408  4247 net.cpp:198] M2PELU51 needs backward computation.
I0928 09:32:12.673410  4247 net.cpp:198] Eltwise25 needs backward computation.
I0928 09:32:12.673413  4247 net.cpp:198] Scale53 needs backward computation.
I0928 09:32:12.673414  4247 net.cpp:198] BatchNorm53 needs backward computation.
I0928 09:32:12.673416  4247 net.cpp:198] Convolution53 needs backward computation.
I0928 09:32:12.673418  4247 net.cpp:198] M2PELU50 needs backward computation.
I0928 09:32:12.673420  4247 net.cpp:198] Scale52 needs backward computation.
I0928 09:32:12.673422  4247 net.cpp:198] BatchNorm52 needs backward computation.
I0928 09:32:12.673424  4247 net.cpp:198] Convolution52 needs backward computation.
I0928 09:32:12.673427  4247 net.cpp:198] Eltwise24_M2PELU49_0_split needs backward computation.
I0928 09:32:12.673429  4247 net.cpp:198] M2PELU49 needs backward computation.
I0928 09:32:12.673431  4247 net.cpp:198] Eltwise24 needs backward computation.
I0928 09:32:12.673434  4247 net.cpp:198] Scale51 needs backward computation.
I0928 09:32:12.673436  4247 net.cpp:198] BatchNorm51 needs backward computation.
I0928 09:32:12.673439  4247 net.cpp:198] Convolution51 needs backward computation.
I0928 09:32:12.673440  4247 net.cpp:198] M2PELU48 needs backward computation.
I0928 09:32:12.673442  4247 net.cpp:198] Scale50 needs backward computation.
I0928 09:32:12.673444  4247 net.cpp:198] BatchNorm50 needs backward computation.
I0928 09:32:12.673446  4247 net.cpp:198] Convolution50 needs backward computation.
I0928 09:32:12.673449  4247 net.cpp:198] Eltwise23_M2PELU47_0_split needs backward computation.
I0928 09:32:12.673451  4247 net.cpp:198] M2PELU47 needs backward computation.
I0928 09:32:12.673454  4247 net.cpp:198] Eltwise23 needs backward computation.
I0928 09:32:12.673456  4247 net.cpp:198] Scale49 needs backward computation.
I0928 09:32:12.673458  4247 net.cpp:198] BatchNorm49 needs backward computation.
I0928 09:32:12.673460  4247 net.cpp:198] Convolution49 needs backward computation.
I0928 09:32:12.673463  4247 net.cpp:198] M2PELU46 needs backward computation.
I0928 09:32:12.673465  4247 net.cpp:198] Scale48 needs backward computation.
I0928 09:32:12.673467  4247 net.cpp:198] BatchNorm48 needs backward computation.
I0928 09:32:12.673470  4247 net.cpp:198] Convolution48 needs backward computation.
I0928 09:32:12.673471  4247 net.cpp:198] Eltwise22_M2PELU45_0_split needs backward computation.
I0928 09:32:12.673475  4247 net.cpp:198] M2PELU45 needs backward computation.
I0928 09:32:12.673476  4247 net.cpp:198] Eltwise22 needs backward computation.
I0928 09:32:12.673480  4247 net.cpp:198] Scale47 needs backward computation.
I0928 09:32:12.673481  4247 net.cpp:198] BatchNorm47 needs backward computation.
I0928 09:32:12.673483  4247 net.cpp:198] Convolution47 needs backward computation.
I0928 09:32:12.673485  4247 net.cpp:198] M2PELU44 needs backward computation.
I0928 09:32:12.673487  4247 net.cpp:198] Scale46 needs backward computation.
I0928 09:32:12.673490  4247 net.cpp:198] BatchNorm46 needs backward computation.
I0928 09:32:12.673491  4247 net.cpp:198] Convolution46 needs backward computation.
I0928 09:32:12.673494  4247 net.cpp:198] Eltwise21_M2PELU43_0_split needs backward computation.
I0928 09:32:12.673496  4247 net.cpp:198] M2PELU43 needs backward computation.
I0928 09:32:12.673498  4247 net.cpp:198] Eltwise21 needs backward computation.
I0928 09:32:12.673501  4247 net.cpp:198] Scale45 needs backward computation.
I0928 09:32:12.673503  4247 net.cpp:198] BatchNorm45 needs backward computation.
I0928 09:32:12.673506  4247 net.cpp:198] Convolution45 needs backward computation.
I0928 09:32:12.673507  4247 net.cpp:198] M2PELU42 needs backward computation.
I0928 09:32:12.673509  4247 net.cpp:198] Scale44 needs backward computation.
I0928 09:32:12.673511  4247 net.cpp:198] BatchNorm44 needs backward computation.
I0928 09:32:12.673513  4247 net.cpp:198] Convolution44 needs backward computation.
I0928 09:32:12.673516  4247 net.cpp:198] Eltwise20_M2PELU41_0_split needs backward computation.
I0928 09:32:12.673521  4247 net.cpp:198] M2PELU41 needs backward computation.
I0928 09:32:12.673524  4247 net.cpp:198] Eltwise20 needs backward computation.
I0928 09:32:12.673527  4247 net.cpp:198] Scale43 needs backward computation.
I0928 09:32:12.673529  4247 net.cpp:198] BatchNorm43 needs backward computation.
I0928 09:32:12.673532  4247 net.cpp:198] Convolution43 needs backward computation.
I0928 09:32:12.673533  4247 net.cpp:198] M2PELU40 needs backward computation.
I0928 09:32:12.673535  4247 net.cpp:198] Scale42 needs backward computation.
I0928 09:32:12.673537  4247 net.cpp:198] BatchNorm42 needs backward computation.
I0928 09:32:12.673540  4247 net.cpp:198] Convolution42 needs backward computation.
I0928 09:32:12.673542  4247 net.cpp:198] Eltwise19_M2PELU39_0_split needs backward computation.
I0928 09:32:12.673545  4247 net.cpp:198] M2PELU39 needs backward computation.
I0928 09:32:12.673547  4247 net.cpp:198] Eltwise19 needs backward computation.
I0928 09:32:12.673550  4247 net.cpp:198] Scale41 needs backward computation.
I0928 09:32:12.673552  4247 net.cpp:198] BatchNorm41 needs backward computation.
I0928 09:32:12.673554  4247 net.cpp:198] Convolution41 needs backward computation.
I0928 09:32:12.673557  4247 net.cpp:198] M2PELU38 needs backward computation.
I0928 09:32:12.673558  4247 net.cpp:198] Scale40 needs backward computation.
I0928 09:32:12.673562  4247 net.cpp:198] BatchNorm40 needs backward computation.
I0928 09:32:12.673563  4247 net.cpp:198] Convolution40 needs backward computation.
I0928 09:32:12.673565  4247 net.cpp:198] Scale39 needs backward computation.
I0928 09:32:12.673568  4247 net.cpp:198] BatchNorm39 needs backward computation.
I0928 09:32:12.673570  4247 net.cpp:198] Convolution39 needs backward computation.
I0928 09:32:12.673573  4247 net.cpp:198] Eltwise18_M2PELU37_0_split needs backward computation.
I0928 09:32:12.673575  4247 net.cpp:198] M2PELU37 needs backward computation.
I0928 09:32:12.673578  4247 net.cpp:198] Eltwise18 needs backward computation.
I0928 09:32:12.673579  4247 net.cpp:198] Scale38 needs backward computation.
I0928 09:32:12.673583  4247 net.cpp:198] BatchNorm38 needs backward computation.
I0928 09:32:12.673584  4247 net.cpp:198] Convolution38 needs backward computation.
I0928 09:32:12.673586  4247 net.cpp:198] M2PELU36 needs backward computation.
I0928 09:32:12.673588  4247 net.cpp:198] Scale37 needs backward computation.
I0928 09:32:12.673590  4247 net.cpp:198] BatchNorm37 needs backward computation.
I0928 09:32:12.673593  4247 net.cpp:198] Convolution37 needs backward computation.
I0928 09:32:12.673595  4247 net.cpp:198] Eltwise17_M2PELU35_0_split needs backward computation.
I0928 09:32:12.673597  4247 net.cpp:198] M2PELU35 needs backward computation.
I0928 09:32:12.673599  4247 net.cpp:198] Eltwise17 needs backward computation.
I0928 09:32:12.673602  4247 net.cpp:198] Scale36 needs backward computation.
I0928 09:32:12.673604  4247 net.cpp:198] BatchNorm36 needs backward computation.
I0928 09:32:12.673606  4247 net.cpp:198] Convolution36 needs backward computation.
I0928 09:32:12.673609  4247 net.cpp:198] M2PELU34 needs backward computation.
I0928 09:32:12.673611  4247 net.cpp:198] Scale35 needs backward computation.
I0928 09:32:12.673614  4247 net.cpp:198] BatchNorm35 needs backward computation.
I0928 09:32:12.673615  4247 net.cpp:198] Convolution35 needs backward computation.
I0928 09:32:12.673617  4247 net.cpp:198] Eltwise16_M2PELU33_0_split needs backward computation.
I0928 09:32:12.673620  4247 net.cpp:198] M2PELU33 needs backward computation.
I0928 09:32:12.673622  4247 net.cpp:198] Eltwise16 needs backward computation.
I0928 09:32:12.673624  4247 net.cpp:198] Scale34 needs backward computation.
I0928 09:32:12.673626  4247 net.cpp:198] BatchNorm34 needs backward computation.
I0928 09:32:12.673629  4247 net.cpp:198] Convolution34 needs backward computation.
I0928 09:32:12.673631  4247 net.cpp:198] M2PELU32 needs backward computation.
I0928 09:32:12.673633  4247 net.cpp:198] Scale33 needs backward computation.
I0928 09:32:12.673638  4247 net.cpp:198] BatchNorm33 needs backward computation.
I0928 09:32:12.673640  4247 net.cpp:198] Convolution33 needs backward computation.
I0928 09:32:12.673642  4247 net.cpp:198] Eltwise15_M2PELU31_0_split needs backward computation.
I0928 09:32:12.673645  4247 net.cpp:198] M2PELU31 needs backward computation.
I0928 09:32:12.673647  4247 net.cpp:198] Eltwise15 needs backward computation.
I0928 09:32:12.673650  4247 net.cpp:198] Scale32 needs backward computation.
I0928 09:32:12.673651  4247 net.cpp:198] BatchNorm32 needs backward computation.
I0928 09:32:12.673653  4247 net.cpp:198] Convolution32 needs backward computation.
I0928 09:32:12.699690  4247 net.cpp:198] M2PELU30 needs backward computation.
I0928 09:32:12.699697  4247 net.cpp:198] Scale31 needs backward computation.
I0928 09:32:12.699700  4247 net.cpp:198] BatchNorm31 needs backward computation.
I0928 09:32:12.699703  4247 net.cpp:198] Convolution31 needs backward computation.
I0928 09:32:12.699707  4247 net.cpp:198] Eltwise14_M2PELU29_0_split needs backward computation.
I0928 09:32:12.699708  4247 net.cpp:198] M2PELU29 needs backward computation.
I0928 09:32:12.699712  4247 net.cpp:198] Eltwise14 needs backward computation.
I0928 09:32:12.699714  4247 net.cpp:198] Scale30 needs backward computation.
I0928 09:32:12.699717  4247 net.cpp:198] BatchNorm30 needs backward computation.
I0928 09:32:12.699719  4247 net.cpp:198] Convolution30 needs backward computation.
I0928 09:32:12.699721  4247 net.cpp:198] M2PELU28 needs backward computation.
I0928 09:32:12.699724  4247 net.cpp:198] Scale29 needs backward computation.
I0928 09:32:12.699726  4247 net.cpp:198] BatchNorm29 needs backward computation.
I0928 09:32:12.699728  4247 net.cpp:198] Convolution29 needs backward computation.
I0928 09:32:12.699731  4247 net.cpp:198] Eltwise13_M2PELU27_0_split needs backward computation.
I0928 09:32:12.699736  4247 net.cpp:198] M2PELU27 needs backward computation.
I0928 09:32:12.699738  4247 net.cpp:198] Eltwise13 needs backward computation.
I0928 09:32:12.699741  4247 net.cpp:198] Scale28 needs backward computation.
I0928 09:32:12.699744  4247 net.cpp:198] BatchNorm28 needs backward computation.
I0928 09:32:12.699746  4247 net.cpp:198] Convolution28 needs backward computation.
I0928 09:32:12.699749  4247 net.cpp:198] M2PELU26 needs backward computation.
I0928 09:32:12.699751  4247 net.cpp:198] Scale27 needs backward computation.
I0928 09:32:12.699754  4247 net.cpp:198] BatchNorm27 needs backward computation.
I0928 09:32:12.699756  4247 net.cpp:198] Convolution27 needs backward computation.
I0928 09:32:12.699759  4247 net.cpp:198] Eltwise12_M2PELU25_0_split needs backward computation.
I0928 09:32:12.699761  4247 net.cpp:198] M2PELU25 needs backward computation.
I0928 09:32:12.699764  4247 net.cpp:198] Eltwise12 needs backward computation.
I0928 09:32:12.699767  4247 net.cpp:198] Scale26 needs backward computation.
I0928 09:32:12.699769  4247 net.cpp:198] BatchNorm26 needs backward computation.
I0928 09:32:12.699771  4247 net.cpp:198] Convolution26 needs backward computation.
I0928 09:32:12.699774  4247 net.cpp:198] M2PELU24 needs backward computation.
I0928 09:32:12.699776  4247 net.cpp:198] Scale25 needs backward computation.
I0928 09:32:12.699779  4247 net.cpp:198] BatchNorm25 needs backward computation.
I0928 09:32:12.699781  4247 net.cpp:198] Convolution25 needs backward computation.
I0928 09:32:12.699784  4247 net.cpp:198] Eltwise11_M2PELU23_0_split needs backward computation.
I0928 09:32:12.699786  4247 net.cpp:198] M2PELU23 needs backward computation.
I0928 09:32:12.699789  4247 net.cpp:198] Eltwise11 needs backward computation.
I0928 09:32:12.699791  4247 net.cpp:198] Scale24 needs backward computation.
I0928 09:32:12.699793  4247 net.cpp:198] BatchNorm24 needs backward computation.
I0928 09:32:12.699795  4247 net.cpp:198] Convolution24 needs backward computation.
I0928 09:32:12.699798  4247 net.cpp:198] M2PELU22 needs backward computation.
I0928 09:32:12.699800  4247 net.cpp:198] Scale23 needs backward computation.
I0928 09:32:12.699810  4247 net.cpp:198] BatchNorm23 needs backward computation.
I0928 09:32:12.699813  4247 net.cpp:198] Convolution23 needs backward computation.
I0928 09:32:12.699816  4247 net.cpp:198] Eltwise10_M2PELU21_0_split needs backward computation.
I0928 09:32:12.699818  4247 net.cpp:198] M2PELU21 needs backward computation.
I0928 09:32:12.699821  4247 net.cpp:198] Eltwise10 needs backward computation.
I0928 09:32:12.699825  4247 net.cpp:198] Scale22 needs backward computation.
I0928 09:32:12.699826  4247 net.cpp:198] BatchNorm22 needs backward computation.
I0928 09:32:12.699828  4247 net.cpp:198] Convolution22 needs backward computation.
I0928 09:32:12.699831  4247 net.cpp:198] M2PELU20 needs backward computation.
I0928 09:32:12.699834  4247 net.cpp:198] Scale21 needs backward computation.
I0928 09:32:12.699836  4247 net.cpp:198] BatchNorm21 needs backward computation.
I0928 09:32:12.699839  4247 net.cpp:198] Convolution21 needs backward computation.
I0928 09:32:12.699841  4247 net.cpp:198] Scale20 needs backward computation.
I0928 09:32:12.699844  4247 net.cpp:198] BatchNorm20 needs backward computation.
I0928 09:32:12.699846  4247 net.cpp:198] Convolution20 needs backward computation.
I0928 09:32:12.699849  4247 net.cpp:198] Eltwise9_M2PELU19_0_split needs backward computation.
I0928 09:32:12.699851  4247 net.cpp:198] M2PELU19 needs backward computation.
I0928 09:32:12.699854  4247 net.cpp:198] Eltwise9 needs backward computation.
I0928 09:32:12.699857  4247 net.cpp:198] Scale19 needs backward computation.
I0928 09:32:12.699859  4247 net.cpp:198] BatchNorm19 needs backward computation.
I0928 09:32:12.699862  4247 net.cpp:198] Convolution19 needs backward computation.
I0928 09:32:12.699864  4247 net.cpp:198] M2PELU18 needs backward computation.
I0928 09:32:12.699867  4247 net.cpp:198] Scale18 needs backward computation.
I0928 09:32:12.699869  4247 net.cpp:198] BatchNorm18 needs backward computation.
I0928 09:32:12.699872  4247 net.cpp:198] Convolution18 needs backward computation.
I0928 09:32:12.699874  4247 net.cpp:198] Eltwise8_M2PELU17_0_split needs backward computation.
I0928 09:32:12.699877  4247 net.cpp:198] M2PELU17 needs backward computation.
I0928 09:32:12.699879  4247 net.cpp:198] Eltwise8 needs backward computation.
I0928 09:32:12.699882  4247 net.cpp:198] Scale17 needs backward computation.
I0928 09:32:12.699884  4247 net.cpp:198] BatchNorm17 needs backward computation.
I0928 09:32:12.699887  4247 net.cpp:198] Convolution17 needs backward computation.
I0928 09:32:12.699889  4247 net.cpp:198] M2PELU16 needs backward computation.
I0928 09:32:12.699892  4247 net.cpp:198] Scale16 needs backward computation.
I0928 09:32:12.699894  4247 net.cpp:198] BatchNorm16 needs backward computation.
I0928 09:32:12.699897  4247 net.cpp:198] Convolution16 needs backward computation.
I0928 09:32:12.699899  4247 net.cpp:198] Eltwise7_M2PELU15_0_split needs backward computation.
I0928 09:32:12.699903  4247 net.cpp:198] M2PELU15 needs backward computation.
I0928 09:32:12.699904  4247 net.cpp:198] Eltwise7 needs backward computation.
I0928 09:32:12.699908  4247 net.cpp:198] Scale15 needs backward computation.
I0928 09:32:12.699909  4247 net.cpp:198] BatchNorm15 needs backward computation.
I0928 09:32:12.699914  4247 net.cpp:198] Convolution15 needs backward computation.
I0928 09:32:12.699918  4247 net.cpp:198] M2PELU14 needs backward computation.
I0928 09:32:12.699919  4247 net.cpp:198] Scale14 needs backward computation.
I0928 09:32:12.699923  4247 net.cpp:198] BatchNorm14 needs backward computation.
I0928 09:32:12.699924  4247 net.cpp:198] Convolution14 needs backward computation.
I0928 09:32:12.699928  4247 net.cpp:198] Eltwise6_M2PELU13_0_split needs backward computation.
I0928 09:32:12.699930  4247 net.cpp:198] M2PELU13 needs backward computation.
I0928 09:32:12.699932  4247 net.cpp:198] Eltwise6 needs backward computation.
I0928 09:32:12.699935  4247 net.cpp:198] Scale13 needs backward computation.
I0928 09:32:12.699937  4247 net.cpp:198] BatchNorm13 needs backward computation.
I0928 09:32:12.699939  4247 net.cpp:198] Convolution13 needs backward computation.
I0928 09:32:12.699946  4247 net.cpp:198] M2PELU12 needs backward computation.
I0928 09:32:12.699949  4247 net.cpp:198] Scale12 needs backward computation.
I0928 09:32:12.699951  4247 net.cpp:198] BatchNorm12 needs backward computation.
I0928 09:32:12.699954  4247 net.cpp:198] Convolution12 needs backward computation.
I0928 09:32:12.699955  4247 net.cpp:198] Eltwise5_M2PELU11_0_split needs backward computation.
I0928 09:32:12.699959  4247 net.cpp:198] M2PELU11 needs backward computation.
I0928 09:32:12.699961  4247 net.cpp:198] Eltwise5 needs backward computation.
I0928 09:32:12.702100  4247 net.cpp:198] Scale11 needs backward computation.
I0928 09:32:12.702107  4247 net.cpp:198] BatchNorm11 needs backward computation.
I0928 09:32:12.702111  4247 net.cpp:198] Convolution11 needs backward computation.
I0928 09:32:12.702113  4247 net.cpp:198] M2PELU10 needs backward computation.
I0928 09:32:12.702116  4247 net.cpp:198] Scale10 needs backward computation.
I0928 09:32:12.702117  4247 net.cpp:198] BatchNorm10 needs backward computation.
I0928 09:32:12.702121  4247 net.cpp:198] Convolution10 needs backward computation.
I0928 09:32:12.702123  4247 net.cpp:198] Eltwise4_M2PELU9_0_split needs backward computation.
I0928 09:32:12.702126  4247 net.cpp:198] M2PELU9 needs backward computation.
I0928 09:32:12.702128  4247 net.cpp:198] Eltwise4 needs backward computation.
I0928 09:32:12.702131  4247 net.cpp:198] Scale9 needs backward computation.
I0928 09:32:12.702134  4247 net.cpp:198] BatchNorm9 needs backward computation.
I0928 09:32:12.702136  4247 net.cpp:198] Convolution9 needs backward computation.
I0928 09:32:12.702139  4247 net.cpp:198] M2PELU8 needs backward computation.
I0928 09:32:12.702142  4247 net.cpp:198] Scale8 needs backward computation.
I0928 09:32:12.702144  4247 net.cpp:198] BatchNorm8 needs backward computation.
I0928 09:32:12.702147  4247 net.cpp:198] Convolution8 needs backward computation.
I0928 09:32:12.702149  4247 net.cpp:198] Eltwise3_M2PELU7_0_split needs backward computation.
I0928 09:32:12.702152  4247 net.cpp:198] M2PELU7 needs backward computation.
I0928 09:32:12.702154  4247 net.cpp:198] Eltwise3 needs backward computation.
I0928 09:32:12.702157  4247 net.cpp:198] Scale7 needs backward computation.
I0928 09:32:12.702159  4247 net.cpp:198] BatchNorm7 needs backward computation.
I0928 09:32:12.702162  4247 net.cpp:198] Convolution7 needs backward computation.
I0928 09:32:12.702164  4247 net.cpp:198] M2PELU6 needs backward computation.
I0928 09:32:12.702167  4247 net.cpp:198] Scale6 needs backward computation.
I0928 09:32:12.702168  4247 net.cpp:198] BatchNorm6 needs backward computation.
I0928 09:32:12.702170  4247 net.cpp:198] Convolution6 needs backward computation.
I0928 09:32:12.702173  4247 net.cpp:198] Eltwise2_M2PELU5_0_split needs backward computation.
I0928 09:32:12.702177  4247 net.cpp:198] M2PELU5 needs backward computation.
I0928 09:32:12.702178  4247 net.cpp:198] Eltwise2 needs backward computation.
I0928 09:32:12.702181  4247 net.cpp:198] Scale5 needs backward computation.
I0928 09:32:12.702183  4247 net.cpp:198] BatchNorm5 needs backward computation.
I0928 09:32:12.702186  4247 net.cpp:198] Convolution5 needs backward computation.
I0928 09:32:12.702188  4247 net.cpp:198] M2PELU4 needs backward computation.
I0928 09:32:12.702190  4247 net.cpp:198] Scale4 needs backward computation.
I0928 09:32:12.702193  4247 net.cpp:198] BatchNorm4 needs backward computation.
I0928 09:32:12.702195  4247 net.cpp:198] Convolution4 needs backward computation.
I0928 09:32:12.702198  4247 net.cpp:198] Eltwise1_M2PELU3_0_split needs backward computation.
I0928 09:32:12.702200  4247 net.cpp:198] M2PELU3 needs backward computation.
I0928 09:32:12.702203  4247 net.cpp:198] Eltwise1 needs backward computation.
I0928 09:32:12.702205  4247 net.cpp:198] Scale3 needs backward computation.
I0928 09:32:12.702208  4247 net.cpp:198] BatchNorm3 needs backward computation.
I0928 09:32:12.702210  4247 net.cpp:198] Convolution3 needs backward computation.
I0928 09:32:12.702214  4247 net.cpp:198] M2PELU2 needs backward computation.
I0928 09:32:12.702222  4247 net.cpp:198] Scale2 needs backward computation.
I0928 09:32:12.702225  4247 net.cpp:198] BatchNorm2 needs backward computation.
I0928 09:32:12.702227  4247 net.cpp:198] Convolution2 needs backward computation.
I0928 09:32:12.702230  4247 net.cpp:198] Convolution1_M2PELU1_0_split needs backward computation.
I0928 09:32:12.702234  4247 net.cpp:198] M2PELU1 needs backward computation.
I0928 09:32:12.702235  4247 net.cpp:198] Scale1 needs backward computation.
I0928 09:32:12.702237  4247 net.cpp:198] BatchNorm1 needs backward computation.
I0928 09:32:12.702240  4247 net.cpp:198] Convolution1 needs backward computation.
I0928 09:32:12.702242  4247 net.cpp:200] Data1 does not need backward computation.
I0928 09:32:12.702244  4247 net.cpp:242] This network produces output SoftmaxWithLoss1
I0928 09:32:12.702339  4247 net.cpp:255] Network initialization done.
I0928 09:32:12.706684  4247 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56_mpelu_train_test.prototxt
I0928 09:32:12.706696  4247 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0928 09:32:12.706701  4247 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56_mpelu_train_test.prototxt
I0928 09:32:12.706892  4247 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I0928 09:32:12.708014  4247 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU1"
  type: "M2PELU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU2"
  type: "M2PELU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU3"
  type: "M2PELU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU4"
  type: "M2PELU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU5"
  type: "M2PELU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU6"
  type: "M2PELU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU7"
  type: "M2PELU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU8"
  type: "M2PELU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU9"
  type: "M2PELU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU10"
  type: "M2PELU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU11"
  type: "M2PELU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU12"
  type: "M2PELU"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU13"
  type: "M2PELU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU14"
  type: "M2PELU"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU15"
  type: "M2PELU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU16"
  type: "M2PELU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU17"
  type: "M2PELU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU18"
  type: "M2PELU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU19"
  type: "M2PELU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU20"
  type: "M2PELU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU21"
  type: "M2PELU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU22"
  type: "M2PELU"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution24"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU23"
  type: "M2PELU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU24"
  type: "M2PELU"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      t
I0928 09:32:12.764065  4247 layer_factory.hpp:77] Creating layer Data1
I0928 09:32:12.764116  4247 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I0928 09:32:12.764127  4247 net.cpp:84] Creating Layer Data1
I0928 09:32:12.764132  4247 net.cpp:380] Data1 -> Data1
I0928 09:32:12.764142  4247 net.cpp:380] Data1 -> Data2
I0928 09:32:12.764147  4247 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0928 09:32:12.764323  4247 data_layer.cpp:45] output data size: 100,3,32,32
I0928 09:32:12.768316  4247 net.cpp:122] Setting up Data1
I0928 09:32:12.768335  4247 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0928 09:32:12.768339  4247 net.cpp:129] Top shape: 100 (100)
I0928 09:32:12.768342  4247 net.cpp:137] Memory required for data: 1229200
I0928 09:32:12.768347  4247 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0928 09:32:12.768355  4247 net.cpp:84] Creating Layer Data2_Data1_1_split
I0928 09:32:12.768358  4247 net.cpp:406] Data2_Data1_1_split <- Data2
I0928 09:32:12.768363  4247 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0928 09:32:12.768370  4247 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0928 09:32:12.768447  4247 net.cpp:122] Setting up Data2_Data1_1_split
I0928 09:32:12.768452  4247 net.cpp:129] Top shape: 100 (100)
I0928 09:32:12.768455  4247 net.cpp:129] Top shape: 100 (100)
I0928 09:32:12.768457  4247 net.cpp:137] Memory required for data: 1230000
I0928 09:32:12.768460  4247 layer_factory.hpp:77] Creating layer Convolution1
I0928 09:32:12.768470  4247 net.cpp:84] Creating Layer Convolution1
I0928 09:32:12.768471  4247 net.cpp:406] Convolution1 <- Data1
I0928 09:32:12.768476  4247 net.cpp:380] Convolution1 -> Convolution1
I0928 09:32:12.769786  4247 net.cpp:122] Setting up Convolution1
I0928 09:32:12.769798  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.769803  4247 net.cpp:137] Memory required for data: 7783600
I0928 09:32:12.769810  4247 layer_factory.hpp:77] Creating layer BatchNorm1
I0928 09:32:12.769815  4247 net.cpp:84] Creating Layer BatchNorm1
I0928 09:32:12.769819  4247 net.cpp:406] BatchNorm1 <- Convolution1
I0928 09:32:12.769822  4247 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0928 09:32:12.769979  4247 net.cpp:122] Setting up BatchNorm1
I0928 09:32:12.769989  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.769991  4247 net.cpp:137] Memory required for data: 14337200
I0928 09:32:12.770000  4247 layer_factory.hpp:77] Creating layer Scale1
I0928 09:32:12.770006  4247 net.cpp:84] Creating Layer Scale1
I0928 09:32:12.770009  4247 net.cpp:406] Scale1 <- Convolution1
I0928 09:32:12.770011  4247 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0928 09:32:12.770045  4247 layer_factory.hpp:77] Creating layer Scale1
I0928 09:32:12.770133  4247 net.cpp:122] Setting up Scale1
I0928 09:32:12.770138  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.770139  4247 net.cpp:137] Memory required for data: 20890800
I0928 09:32:12.770143  4247 layer_factory.hpp:77] Creating layer M2PELU1
I0928 09:32:12.770149  4247 net.cpp:84] Creating Layer M2PELU1
I0928 09:32:12.770151  4247 net.cpp:406] M2PELU1 <- Convolution1
I0928 09:32:12.770155  4247 net.cpp:367] M2PELU1 -> Convolution1 (in-place)
I0928 09:32:12.770779  4247 net.cpp:122] Setting up M2PELU1
I0928 09:32:12.770787  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.770790  4247 net.cpp:137] Memory required for data: 27444400
I0928 09:32:12.770797  4247 layer_factory.hpp:77] Creating layer Convolution1_M2PELU1_0_split
I0928 09:32:12.770802  4247 net.cpp:84] Creating Layer Convolution1_M2PELU1_0_split
I0928 09:32:12.770804  4247 net.cpp:406] Convolution1_M2PELU1_0_split <- Convolution1
I0928 09:32:12.770808  4247 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_0
I0928 09:32:12.770812  4247 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_1
I0928 09:32:12.770843  4247 net.cpp:122] Setting up Convolution1_M2PELU1_0_split
I0928 09:32:12.791586  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.791594  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.791596  4247 net.cpp:137] Memory required for data: 40551600
I0928 09:32:12.791599  4247 layer_factory.hpp:77] Creating layer Convolution2
I0928 09:32:12.791610  4247 net.cpp:84] Creating Layer Convolution2
I0928 09:32:12.791612  4247 net.cpp:406] Convolution2 <- Convolution1_M2PELU1_0_split_0
I0928 09:32:12.791617  4247 net.cpp:380] Convolution2 -> Convolution2
I0928 09:32:12.792749  4247 net.cpp:122] Setting up Convolution2
I0928 09:32:12.792759  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.792763  4247 net.cpp:137] Memory required for data: 47105200
I0928 09:32:12.792768  4247 layer_factory.hpp:77] Creating layer BatchNorm2
I0928 09:32:12.792775  4247 net.cpp:84] Creating Layer BatchNorm2
I0928 09:32:12.792778  4247 net.cpp:406] BatchNorm2 <- Convolution2
I0928 09:32:12.792783  4247 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0928 09:32:12.792959  4247 net.cpp:122] Setting up BatchNorm2
I0928 09:32:12.792965  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.792969  4247 net.cpp:137] Memory required for data: 53658800
I0928 09:32:12.792996  4247 layer_factory.hpp:77] Creating layer Scale2
I0928 09:32:12.793004  4247 net.cpp:84] Creating Layer Scale2
I0928 09:32:12.793007  4247 net.cpp:406] Scale2 <- Convolution2
I0928 09:32:12.793014  4247 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0928 09:32:12.793062  4247 layer_factory.hpp:77] Creating layer Scale2
I0928 09:32:12.793205  4247 net.cpp:122] Setting up Scale2
I0928 09:32:12.793215  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.793220  4247 net.cpp:137] Memory required for data: 60212400
I0928 09:32:12.793236  4247 layer_factory.hpp:77] Creating layer M2PELU2
I0928 09:32:12.793246  4247 net.cpp:84] Creating Layer M2PELU2
I0928 09:32:12.793251  4247 net.cpp:406] M2PELU2 <- Convolution2
I0928 09:32:12.793267  4247 net.cpp:367] M2PELU2 -> Convolution2 (in-place)
I0928 09:32:12.793418  4247 net.cpp:122] Setting up M2PELU2
I0928 09:32:12.793427  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.793431  4247 net.cpp:137] Memory required for data: 66766000
I0928 09:32:12.793450  4247 layer_factory.hpp:77] Creating layer Convolution3
I0928 09:32:12.793462  4247 net.cpp:84] Creating Layer Convolution3
I0928 09:32:12.793467  4247 net.cpp:406] Convolution3 <- Convolution2
I0928 09:32:12.793485  4247 net.cpp:380] Convolution3 -> Convolution3
I0928 09:32:12.794910  4247 net.cpp:122] Setting up Convolution3
I0928 09:32:12.794919  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.794922  4247 net.cpp:137] Memory required for data: 73319600
I0928 09:32:12.794926  4247 layer_factory.hpp:77] Creating layer BatchNorm3
I0928 09:32:12.794932  4247 net.cpp:84] Creating Layer BatchNorm3
I0928 09:32:12.794934  4247 net.cpp:406] BatchNorm3 <- Convolution3
I0928 09:32:12.794939  4247 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0928 09:32:12.795092  4247 net.cpp:122] Setting up BatchNorm3
I0928 09:32:12.795096  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.795099  4247 net.cpp:137] Memory required for data: 79873200
I0928 09:32:12.795104  4247 layer_factory.hpp:77] Creating layer Scale3
I0928 09:32:12.795107  4247 net.cpp:84] Creating Layer Scale3
I0928 09:32:12.795109  4247 net.cpp:406] Scale3 <- Convolution3
I0928 09:32:12.795114  4247 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0928 09:32:12.795142  4247 layer_factory.hpp:77] Creating layer Scale3
I0928 09:32:12.795224  4247 net.cpp:122] Setting up Scale3
I0928 09:32:12.795229  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.795231  4247 net.cpp:137] Memory required for data: 86426800
I0928 09:32:12.795234  4247 layer_factory.hpp:77] Creating layer Eltwise1
I0928 09:32:12.795239  4247 net.cpp:84] Creating Layer Eltwise1
I0928 09:32:12.795243  4247 net.cpp:406] Eltwise1 <- Convolution1_M2PELU1_0_split_1
I0928 09:32:12.795245  4247 net.cpp:406] Eltwise1 <- Convolution3
I0928 09:32:12.795248  4247 net.cpp:380] Eltwise1 -> Eltwise1
I0928 09:32:12.795267  4247 net.cpp:122] Setting up Eltwise1
I0928 09:32:12.795271  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.795274  4247 net.cpp:137] Memory required for data: 92980400
I0928 09:32:12.795276  4247 layer_factory.hpp:77] Creating layer M2PELU3
I0928 09:32:12.795281  4247 net.cpp:84] Creating Layer M2PELU3
I0928 09:32:12.795284  4247 net.cpp:406] M2PELU3 <- Eltwise1
I0928 09:32:12.795287  4247 net.cpp:367] M2PELU3 -> Eltwise1 (in-place)
I0928 09:32:12.795418  4247 net.cpp:122] Setting up M2PELU3
I0928 09:32:12.795423  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.795424  4247 net.cpp:137] Memory required for data: 99534000
I0928 09:32:12.795428  4247 layer_factory.hpp:77] Creating layer Eltwise1_M2PELU3_0_split
I0928 09:32:12.795433  4247 net.cpp:84] Creating Layer Eltwise1_M2PELU3_0_split
I0928 09:32:12.795435  4247 net.cpp:406] Eltwise1_M2PELU3_0_split <- Eltwise1
I0928 09:32:12.795439  4247 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_0
I0928 09:32:12.795444  4247 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_1
I0928 09:32:12.795487  4247 net.cpp:122] Setting up Eltwise1_M2PELU3_0_split
I0928 09:32:12.795491  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.795495  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.795496  4247 net.cpp:137] Memory required for data: 112641200
I0928 09:32:12.795498  4247 layer_factory.hpp:77] Creating layer Convolution4
I0928 09:32:12.795505  4247 net.cpp:84] Creating Layer Convolution4
I0928 09:32:12.795507  4247 net.cpp:406] Convolution4 <- Eltwise1_M2PELU3_0_split_0
I0928 09:32:12.795511  4247 net.cpp:380] Convolution4 -> Convolution4
I0928 09:32:12.796494  4247 net.cpp:122] Setting up Convolution4
I0928 09:32:12.796502  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.796505  4247 net.cpp:137] Memory required for data: 119194800
I0928 09:32:12.796509  4247 layer_factory.hpp:77] Creating layer BatchNorm4
I0928 09:32:12.796515  4247 net.cpp:84] Creating Layer BatchNorm4
I0928 09:32:12.796517  4247 net.cpp:406] BatchNorm4 <- Convolution4
I0928 09:32:12.796521  4247 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0928 09:32:12.796674  4247 net.cpp:122] Setting up BatchNorm4
I0928 09:32:12.796679  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.796680  4247 net.cpp:137] Memory required for data: 125748400
I0928 09:32:12.796685  4247 layer_factory.hpp:77] Creating layer Scale4
I0928 09:32:12.796690  4247 net.cpp:84] Creating Layer Scale4
I0928 09:32:12.796692  4247 net.cpp:406] Scale4 <- Convolution4
I0928 09:32:12.796695  4247 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0928 09:32:12.796725  4247 layer_factory.hpp:77] Creating layer Scale4
I0928 09:32:12.796808  4247 net.cpp:122] Setting up Scale4
I0928 09:32:12.796813  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.796815  4247 net.cpp:137] Memory required for data: 132302000
I0928 09:32:12.796823  4247 layer_factory.hpp:77] Creating layer M2PELU4
I0928 09:32:12.796828  4247 net.cpp:84] Creating Layer M2PELU4
I0928 09:32:12.796829  4247 net.cpp:406] M2PELU4 <- Convolution4
I0928 09:32:12.796833  4247 net.cpp:367] M2PELU4 -> Convolution4 (in-place)
I0928 09:32:12.796931  4247 net.cpp:122] Setting up M2PELU4
I0928 09:32:12.796936  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.796937  4247 net.cpp:137] Memory required for data: 138855600
I0928 09:32:12.796941  4247 layer_factory.hpp:77] Creating layer Convolution5
I0928 09:32:12.796947  4247 net.cpp:84] Creating Layer Convolution5
I0928 09:32:12.796949  4247 net.cpp:406] Convolution5 <- Convolution4
I0928 09:32:12.796954  4247 net.cpp:380] Convolution5 -> Convolution5
I0928 09:32:12.797890  4247 net.cpp:122] Setting up Convolution5
I0928 09:32:12.797899  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.797902  4247 net.cpp:137] Memory required for data: 145409200
I0928 09:32:12.797906  4247 layer_factory.hpp:77] Creating layer BatchNorm5
I0928 09:32:12.797912  4247 net.cpp:84] Creating Layer BatchNorm5
I0928 09:32:12.797914  4247 net.cpp:406] BatchNorm5 <- Convolution5
I0928 09:32:12.797919  4247 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0928 09:32:12.798071  4247 net.cpp:122] Setting up BatchNorm5
I0928 09:32:12.798076  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.798079  4247 net.cpp:137] Memory required for data: 151962800
I0928 09:32:12.798084  4247 layer_factory.hpp:77] Creating layer Scale5
I0928 09:32:12.798087  4247 net.cpp:84] Creating Layer Scale5
I0928 09:32:12.798090  4247 net.cpp:406] Scale5 <- Convolution5
I0928 09:32:12.798094  4247 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0928 09:32:12.798123  4247 layer_factory.hpp:77] Creating layer Scale5
I0928 09:32:12.798207  4247 net.cpp:122] Setting up Scale5
I0928 09:32:12.798210  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.798213  4247 net.cpp:137] Memory required for data: 158516400
I0928 09:32:12.798215  4247 layer_factory.hpp:77] Creating layer Eltwise2
I0928 09:32:12.798219  4247 net.cpp:84] Creating Layer Eltwise2
I0928 09:32:12.798223  4247 net.cpp:406] Eltwise2 <- Eltwise1_M2PELU3_0_split_1
I0928 09:32:12.798231  4247 net.cpp:406] Eltwise2 <- Convolution5
I0928 09:32:12.798235  4247 net.cpp:380] Eltwise2 -> Eltwise2
I0928 09:32:12.798254  4247 net.cpp:122] Setting up Eltwise2
I0928 09:32:12.798259  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.798260  4247 net.cpp:137] Memory required for data: 165070000
I0928 09:32:12.798262  4247 layer_factory.hpp:77] Creating layer M2PELU5
I0928 09:32:12.798267  4247 net.cpp:84] Creating Layer M2PELU5
I0928 09:32:12.798269  4247 net.cpp:406] M2PELU5 <- Eltwise2
I0928 09:32:12.798274  4247 net.cpp:367] M2PELU5 -> Eltwise2 (in-place)
I0928 09:32:12.798373  4247 net.cpp:122] Setting up M2PELU5
I0928 09:32:12.798378  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.798379  4247 net.cpp:137] Memory required for data: 171623600
I0928 09:32:12.798383  4247 layer_factory.hpp:77] Creating layer Eltwise2_M2PELU5_0_split
I0928 09:32:12.798388  4247 net.cpp:84] Creating Layer Eltwise2_M2PELU5_0_split
I0928 09:32:12.798390  4247 net.cpp:406] Eltwise2_M2PELU5_0_split <- Eltwise2
I0928 09:32:12.798393  4247 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_0
I0928 09:32:12.798398  4247 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_1
I0928 09:32:12.798424  4247 net.cpp:122] Setting up Eltwise2_M2PELU5_0_split
I0928 09:32:12.798429  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.798431  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.798434  4247 net.cpp:137] Memory required for data: 184730800
I0928 09:32:12.798435  4247 layer_factory.hpp:77] Creating layer Convolution6
I0928 09:32:12.798441  4247 net.cpp:84] Creating Layer Convolution6
I0928 09:32:12.798444  4247 net.cpp:406] Convolution6 <- Eltwise2_M2PELU5_0_split_0
I0928 09:32:12.798447  4247 net.cpp:380] Convolution6 -> Convolution6
I0928 09:32:12.799401  4247 net.cpp:122] Setting up Convolution6
I0928 09:32:12.799409  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.799412  4247 net.cpp:137] Memory required for data: 191284400
I0928 09:32:12.799417  4247 layer_factory.hpp:77] Creating layer BatchNorm6
I0928 09:32:12.799422  4247 net.cpp:84] Creating Layer BatchNorm6
I0928 09:32:12.799425  4247 net.cpp:406] BatchNorm6 <- Convolution6
I0928 09:32:12.799428  4247 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0928 09:32:12.799579  4247 net.cpp:122] Setting up BatchNorm6
I0928 09:32:12.799583  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.799585  4247 net.cpp:137] Memory required for data: 197838000
I0928 09:32:12.799590  4247 layer_factory.hpp:77] Creating layer Scale6
I0928 09:32:12.799594  4247 net.cpp:84] Creating Layer Scale6
I0928 09:32:12.799597  4247 net.cpp:406] Scale6 <- Convolution6
I0928 09:32:12.799600  4247 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0928 09:32:12.799629  4247 layer_factory.hpp:77] Creating layer Scale6
I0928 09:32:12.799712  4247 net.cpp:122] Setting up Scale6
I0928 09:32:12.799717  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.799720  4247 net.cpp:137] Memory required for data: 204391600
I0928 09:32:12.799722  4247 layer_factory.hpp:77] Creating layer M2PELU6
I0928 09:32:12.799728  4247 net.cpp:84] Creating Layer M2PELU6
I0928 09:32:12.799731  4247 net.cpp:406] M2PELU6 <- Convolution6
I0928 09:32:12.799734  4247 net.cpp:367] M2PELU6 -> Convolution6 (in-place)
I0928 09:32:12.799830  4247 net.cpp:122] Setting up M2PELU6
I0928 09:32:12.799835  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.799837  4247 net.cpp:137] Memory required for data: 210945200
I0928 09:32:12.799840  4247 layer_factory.hpp:77] Creating layer Convolution7
I0928 09:32:12.799847  4247 net.cpp:84] Creating Layer Convolution7
I0928 09:32:12.799849  4247 net.cpp:406] Convolution7 <- Convolution6
I0928 09:32:12.799855  4247 net.cpp:380] Convolution7 -> Convolution7
I0928 09:32:12.800783  4247 net.cpp:122] Setting up Convolution7
I0928 09:32:12.800791  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.800801  4247 net.cpp:137] Memory required for data: 217498800
I0928 09:32:12.800806  4247 layer_factory.hpp:77] Creating layer BatchNorm7
I0928 09:32:12.800813  4247 net.cpp:84] Creating Layer BatchNorm7
I0928 09:32:12.800815  4247 net.cpp:406] BatchNorm7 <- Convolution7
I0928 09:32:12.800819  4247 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0928 09:32:12.800971  4247 net.cpp:122] Setting up BatchNorm7
I0928 09:32:12.800976  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.800977  4247 net.cpp:137] Memory required for data: 224052400
I0928 09:32:12.800982  4247 layer_factory.hpp:77] Creating layer Scale7
I0928 09:32:12.800987  4247 net.cpp:84] Creating Layer Scale7
I0928 09:32:12.800988  4247 net.cpp:406] Scale7 <- Convolution7
I0928 09:32:12.800992  4247 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0928 09:32:12.801021  4247 layer_factory.hpp:77] Creating layer Scale7
I0928 09:32:12.801106  4247 net.cpp:122] Setting up Scale7
I0928 09:32:12.801110  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.801112  4247 net.cpp:137] Memory required for data: 230606000
I0928 09:32:12.801116  4247 layer_factory.hpp:77] Creating layer Eltwise3
I0928 09:32:12.801120  4247 net.cpp:84] Creating Layer Eltwise3
I0928 09:32:12.801122  4247 net.cpp:406] Eltwise3 <- Eltwise2_M2PELU5_0_split_1
I0928 09:32:12.801126  4247 net.cpp:406] Eltwise3 <- Convolution7
I0928 09:32:12.801129  4247 net.cpp:380] Eltwise3 -> Eltwise3
I0928 09:32:12.801146  4247 net.cpp:122] Setting up Eltwise3
I0928 09:32:12.801149  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.801151  4247 net.cpp:137] Memory required for data: 237159600
I0928 09:32:12.801153  4247 layer_factory.hpp:77] Creating layer M2PELU7
I0928 09:32:12.801158  4247 net.cpp:84] Creating Layer M2PELU7
I0928 09:32:12.801162  4247 net.cpp:406] M2PELU7 <- Eltwise3
I0928 09:32:12.801164  4247 net.cpp:367] M2PELU7 -> Eltwise3 (in-place)
I0928 09:32:12.801264  4247 net.cpp:122] Setting up M2PELU7
I0928 09:32:12.801267  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.801270  4247 net.cpp:137] Memory required for data: 243713200
I0928 09:32:12.801273  4247 layer_factory.hpp:77] Creating layer Eltwise3_M2PELU7_0_split
I0928 09:32:12.801277  4247 net.cpp:84] Creating Layer Eltwise3_M2PELU7_0_split
I0928 09:32:12.801280  4247 net.cpp:406] Eltwise3_M2PELU7_0_split <- Eltwise3
I0928 09:32:12.801283  4247 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_0
I0928 09:32:12.801287  4247 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_1
I0928 09:32:12.801312  4247 net.cpp:122] Setting up Eltwise3_M2PELU7_0_split
I0928 09:32:12.801316  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.822541  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.822547  4247 net.cpp:137] Memory required for data: 256820400
I0928 09:32:12.822551  4247 layer_factory.hpp:77] Creating layer Convolution8
I0928 09:32:12.822559  4247 net.cpp:84] Creating Layer Convolution8
I0928 09:32:12.822563  4247 net.cpp:406] Convolution8 <- Eltwise3_M2PELU7_0_split_0
I0928 09:32:12.822568  4247 net.cpp:380] Convolution8 -> Convolution8
I0928 09:32:12.823593  4247 net.cpp:122] Setting up Convolution8
I0928 09:32:12.823602  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.823606  4247 net.cpp:137] Memory required for data: 263374000
I0928 09:32:12.823616  4247 layer_factory.hpp:77] Creating layer BatchNorm8
I0928 09:32:12.823621  4247 net.cpp:84] Creating Layer BatchNorm8
I0928 09:32:12.823623  4247 net.cpp:406] BatchNorm8 <- Convolution8
I0928 09:32:12.823627  4247 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0928 09:32:12.823825  4247 net.cpp:122] Setting up BatchNorm8
I0928 09:32:12.823832  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.823837  4247 net.cpp:137] Memory required for data: 269927600
I0928 09:32:12.823844  4247 layer_factory.hpp:77] Creating layer Scale8
I0928 09:32:12.823853  4247 net.cpp:84] Creating Layer Scale8
I0928 09:32:12.823865  4247 net.cpp:406] Scale8 <- Convolution8
I0928 09:32:12.823873  4247 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0928 09:32:12.823925  4247 layer_factory.hpp:77] Creating layer Scale8
I0928 09:32:12.824075  4247 net.cpp:122] Setting up Scale8
I0928 09:32:12.824086  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.824090  4247 net.cpp:137] Memory required for data: 276481200
I0928 09:32:12.824097  4247 layer_factory.hpp:77] Creating layer M2PELU8
I0928 09:32:12.824106  4247 net.cpp:84] Creating Layer M2PELU8
I0928 09:32:12.824110  4247 net.cpp:406] M2PELU8 <- Convolution8
I0928 09:32:12.824113  4247 net.cpp:367] M2PELU8 -> Convolution8 (in-place)
I0928 09:32:12.824280  4247 net.cpp:122] Setting up M2PELU8
I0928 09:32:12.824290  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.824304  4247 net.cpp:137] Memory required for data: 283034800
I0928 09:32:12.824311  4247 layer_factory.hpp:77] Creating layer Convolution9
I0928 09:32:12.824331  4247 net.cpp:84] Creating Layer Convolution9
I0928 09:32:12.824345  4247 net.cpp:406] Convolution9 <- Convolution8
I0928 09:32:12.824354  4247 net.cpp:380] Convolution9 -> Convolution9
I0928 09:32:12.825393  4247 net.cpp:122] Setting up Convolution9
I0928 09:32:12.825402  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.825405  4247 net.cpp:137] Memory required for data: 289588400
I0928 09:32:12.825410  4247 layer_factory.hpp:77] Creating layer BatchNorm9
I0928 09:32:12.825417  4247 net.cpp:84] Creating Layer BatchNorm9
I0928 09:32:12.825419  4247 net.cpp:406] BatchNorm9 <- Convolution9
I0928 09:32:12.825423  4247 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0928 09:32:12.825580  4247 net.cpp:122] Setting up BatchNorm9
I0928 09:32:12.825585  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.825587  4247 net.cpp:137] Memory required for data: 296142000
I0928 09:32:12.825592  4247 layer_factory.hpp:77] Creating layer Scale9
I0928 09:32:12.825598  4247 net.cpp:84] Creating Layer Scale9
I0928 09:32:12.825600  4247 net.cpp:406] Scale9 <- Convolution9
I0928 09:32:12.825603  4247 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0928 09:32:12.825634  4247 layer_factory.hpp:77] Creating layer Scale9
I0928 09:32:12.825724  4247 net.cpp:122] Setting up Scale9
I0928 09:32:12.825728  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.825731  4247 net.cpp:137] Memory required for data: 302695600
I0928 09:32:12.825736  4247 layer_factory.hpp:77] Creating layer Eltwise4
I0928 09:32:12.825739  4247 net.cpp:84] Creating Layer Eltwise4
I0928 09:32:12.825742  4247 net.cpp:406] Eltwise4 <- Eltwise3_M2PELU7_0_split_1
I0928 09:32:12.825747  4247 net.cpp:406] Eltwise4 <- Convolution9
I0928 09:32:12.825749  4247 net.cpp:380] Eltwise4 -> Eltwise4
I0928 09:32:12.825769  4247 net.cpp:122] Setting up Eltwise4
I0928 09:32:12.825773  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.825775  4247 net.cpp:137] Memory required for data: 309249200
I0928 09:32:12.825778  4247 layer_factory.hpp:77] Creating layer M2PELU9
I0928 09:32:12.825781  4247 net.cpp:84] Creating Layer M2PELU9
I0928 09:32:12.825784  4247 net.cpp:406] M2PELU9 <- Eltwise4
I0928 09:32:12.825788  4247 net.cpp:367] M2PELU9 -> Eltwise4 (in-place)
I0928 09:32:12.825892  4247 net.cpp:122] Setting up M2PELU9
I0928 09:32:12.825896  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.825898  4247 net.cpp:137] Memory required for data: 315802800
I0928 09:32:12.825902  4247 layer_factory.hpp:77] Creating layer Eltwise4_M2PELU9_0_split
I0928 09:32:12.825907  4247 net.cpp:84] Creating Layer Eltwise4_M2PELU9_0_split
I0928 09:32:12.825909  4247 net.cpp:406] Eltwise4_M2PELU9_0_split <- Eltwise4
I0928 09:32:12.825912  4247 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_0
I0928 09:32:12.825917  4247 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_1
I0928 09:32:12.825944  4247 net.cpp:122] Setting up Eltwise4_M2PELU9_0_split
I0928 09:32:12.825948  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.825958  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.825960  4247 net.cpp:137] Memory required for data: 328910000
I0928 09:32:12.825963  4247 layer_factory.hpp:77] Creating layer Convolution10
I0928 09:32:12.825968  4247 net.cpp:84] Creating Layer Convolution10
I0928 09:32:12.825970  4247 net.cpp:406] Convolution10 <- Eltwise4_M2PELU9_0_split_0
I0928 09:32:12.825975  4247 net.cpp:380] Convolution10 -> Convolution10
I0928 09:32:12.827018  4247 net.cpp:122] Setting up Convolution10
I0928 09:32:12.827028  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.827029  4247 net.cpp:137] Memory required for data: 335463600
I0928 09:32:12.827034  4247 layer_factory.hpp:77] Creating layer BatchNorm10
I0928 09:32:12.827039  4247 net.cpp:84] Creating Layer BatchNorm10
I0928 09:32:12.827042  4247 net.cpp:406] BatchNorm10 <- Convolution10
I0928 09:32:12.827046  4247 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0928 09:32:12.827201  4247 net.cpp:122] Setting up BatchNorm10
I0928 09:32:12.827206  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.827208  4247 net.cpp:137] Memory required for data: 342017200
I0928 09:32:12.827214  4247 layer_factory.hpp:77] Creating layer Scale10
I0928 09:32:12.827219  4247 net.cpp:84] Creating Layer Scale10
I0928 09:32:12.827220  4247 net.cpp:406] Scale10 <- Convolution10
I0928 09:32:12.827224  4247 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0928 09:32:12.827253  4247 layer_factory.hpp:77] Creating layer Scale10
I0928 09:32:12.827340  4247 net.cpp:122] Setting up Scale10
I0928 09:32:12.827344  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.827347  4247 net.cpp:137] Memory required for data: 348570800
I0928 09:32:12.827350  4247 layer_factory.hpp:77] Creating layer M2PELU10
I0928 09:32:12.827355  4247 net.cpp:84] Creating Layer M2PELU10
I0928 09:32:12.827358  4247 net.cpp:406] M2PELU10 <- Convolution10
I0928 09:32:12.827361  4247 net.cpp:367] M2PELU10 -> Convolution10 (in-place)
I0928 09:32:12.827463  4247 net.cpp:122] Setting up M2PELU10
I0928 09:32:12.827467  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.827469  4247 net.cpp:137] Memory required for data: 355124400
I0928 09:32:12.827473  4247 layer_factory.hpp:77] Creating layer Convolution11
I0928 09:32:12.827482  4247 net.cpp:84] Creating Layer Convolution11
I0928 09:32:12.827484  4247 net.cpp:406] Convolution11 <- Convolution10
I0928 09:32:12.827488  4247 net.cpp:380] Convolution11 -> Convolution11
I0928 09:32:12.828768  4247 net.cpp:122] Setting up Convolution11
I0928 09:32:12.828776  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.828778  4247 net.cpp:137] Memory required for data: 361678000
I0928 09:32:12.828784  4247 layer_factory.hpp:77] Creating layer BatchNorm11
I0928 09:32:12.828788  4247 net.cpp:84] Creating Layer BatchNorm11
I0928 09:32:12.828791  4247 net.cpp:406] BatchNorm11 <- Convolution11
I0928 09:32:12.828795  4247 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0928 09:32:12.828956  4247 net.cpp:122] Setting up BatchNorm11
I0928 09:32:12.828961  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.828963  4247 net.cpp:137] Memory required for data: 368231600
I0928 09:32:12.828969  4247 layer_factory.hpp:77] Creating layer Scale11
I0928 09:32:12.828972  4247 net.cpp:84] Creating Layer Scale11
I0928 09:32:12.828974  4247 net.cpp:406] Scale11 <- Convolution11
I0928 09:32:12.828977  4247 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0928 09:32:12.829008  4247 layer_factory.hpp:77] Creating layer Scale11
I0928 09:32:12.829097  4247 net.cpp:122] Setting up Scale11
I0928 09:32:12.829102  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.829103  4247 net.cpp:137] Memory required for data: 374785200
I0928 09:32:12.829107  4247 layer_factory.hpp:77] Creating layer Eltwise5
I0928 09:32:12.829113  4247 net.cpp:84] Creating Layer Eltwise5
I0928 09:32:12.829114  4247 net.cpp:406] Eltwise5 <- Eltwise4_M2PELU9_0_split_1
I0928 09:32:12.829118  4247 net.cpp:406] Eltwise5 <- Convolution11
I0928 09:32:12.829128  4247 net.cpp:380] Eltwise5 -> Eltwise5
I0928 09:32:12.829149  4247 net.cpp:122] Setting up Eltwise5
I0928 09:32:12.829152  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.829154  4247 net.cpp:137] Memory required for data: 381338800
I0928 09:32:12.829156  4247 layer_factory.hpp:77] Creating layer M2PELU11
I0928 09:32:12.829160  4247 net.cpp:84] Creating Layer M2PELU11
I0928 09:32:12.829164  4247 net.cpp:406] M2PELU11 <- Eltwise5
I0928 09:32:12.829167  4247 net.cpp:367] M2PELU11 -> Eltwise5 (in-place)
I0928 09:32:12.829269  4247 net.cpp:122] Setting up M2PELU11
I0928 09:32:12.829275  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.829277  4247 net.cpp:137] Memory required for data: 387892400
I0928 09:32:12.829282  4247 layer_factory.hpp:77] Creating layer Eltwise5_M2PELU11_0_split
I0928 09:32:12.829285  4247 net.cpp:84] Creating Layer Eltwise5_M2PELU11_0_split
I0928 09:32:12.829288  4247 net.cpp:406] Eltwise5_M2PELU11_0_split <- Eltwise5
I0928 09:32:12.829290  4247 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_0
I0928 09:32:12.829294  4247 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_1
I0928 09:32:12.829321  4247 net.cpp:122] Setting up Eltwise5_M2PELU11_0_split
I0928 09:32:12.829325  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.829329  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.829330  4247 net.cpp:137] Memory required for data: 400999600
I0928 09:32:12.829332  4247 layer_factory.hpp:77] Creating layer Convolution12
I0928 09:32:12.829339  4247 net.cpp:84] Creating Layer Convolution12
I0928 09:32:12.829340  4247 net.cpp:406] Convolution12 <- Eltwise5_M2PELU11_0_split_0
I0928 09:32:12.829344  4247 net.cpp:380] Convolution12 -> Convolution12
I0928 09:32:12.830312  4247 net.cpp:122] Setting up Convolution12
I0928 09:32:12.830322  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.830324  4247 net.cpp:137] Memory required for data: 407553200
I0928 09:32:12.830328  4247 layer_factory.hpp:77] Creating layer BatchNorm12
I0928 09:32:12.830333  4247 net.cpp:84] Creating Layer BatchNorm12
I0928 09:32:12.830337  4247 net.cpp:406] BatchNorm12 <- Convolution12
I0928 09:32:12.830340  4247 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0928 09:32:12.830497  4247 net.cpp:122] Setting up BatchNorm12
I0928 09:32:12.830502  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.830504  4247 net.cpp:137] Memory required for data: 414106800
I0928 09:32:12.830508  4247 layer_factory.hpp:77] Creating layer Scale12
I0928 09:32:12.830513  4247 net.cpp:84] Creating Layer Scale12
I0928 09:32:12.830516  4247 net.cpp:406] Scale12 <- Convolution12
I0928 09:32:12.830523  4247 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0928 09:32:12.830575  4247 layer_factory.hpp:77] Creating layer Scale12
I0928 09:32:12.830663  4247 net.cpp:122] Setting up Scale12
I0928 09:32:12.830667  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.830669  4247 net.cpp:137] Memory required for data: 420660400
I0928 09:32:12.830673  4247 layer_factory.hpp:77] Creating layer M2PELU12
I0928 09:32:12.830678  4247 net.cpp:84] Creating Layer M2PELU12
I0928 09:32:12.830680  4247 net.cpp:406] M2PELU12 <- Convolution12
I0928 09:32:12.830684  4247 net.cpp:367] M2PELU12 -> Convolution12 (in-place)
I0928 09:32:12.830785  4247 net.cpp:122] Setting up M2PELU12
I0928 09:32:12.830790  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.830792  4247 net.cpp:137] Memory required for data: 427214000
I0928 09:32:12.830796  4247 layer_factory.hpp:77] Creating layer Convolution13
I0928 09:32:12.830803  4247 net.cpp:84] Creating Layer Convolution13
I0928 09:32:12.830806  4247 net.cpp:406] Convolution13 <- Convolution12
I0928 09:32:12.830809  4247 net.cpp:380] Convolution13 -> Convolution13
I0928 09:32:12.831773  4247 net.cpp:122] Setting up Convolution13
I0928 09:32:12.831781  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.831784  4247 net.cpp:137] Memory required for data: 433767600
I0928 09:32:12.831794  4247 layer_factory.hpp:77] Creating layer BatchNorm13
I0928 09:32:12.831801  4247 net.cpp:84] Creating Layer BatchNorm13
I0928 09:32:12.831804  4247 net.cpp:406] BatchNorm13 <- Convolution13
I0928 09:32:12.831807  4247 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0928 09:32:12.831967  4247 net.cpp:122] Setting up BatchNorm13
I0928 09:32:12.831972  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.831974  4247 net.cpp:137] Memory required for data: 440321200
I0928 09:32:12.831979  4247 layer_factory.hpp:77] Creating layer Scale13
I0928 09:32:12.831984  4247 net.cpp:84] Creating Layer Scale13
I0928 09:32:12.831985  4247 net.cpp:406] Scale13 <- Convolution13
I0928 09:32:12.831990  4247 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0928 09:32:12.832020  4247 layer_factory.hpp:77] Creating layer Scale13
I0928 09:32:12.832108  4247 net.cpp:122] Setting up Scale13
I0928 09:32:12.832111  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.832113  4247 net.cpp:137] Memory required for data: 446874800
I0928 09:32:12.832118  4247 layer_factory.hpp:77] Creating layer Eltwise6
I0928 09:32:12.832125  4247 net.cpp:84] Creating Layer Eltwise6
I0928 09:32:12.832128  4247 net.cpp:406] Eltwise6 <- Eltwise5_M2PELU11_0_split_1
I0928 09:32:12.832130  4247 net.cpp:406] Eltwise6 <- Convolution13
I0928 09:32:12.832135  4247 net.cpp:380] Eltwise6 -> Eltwise6
I0928 09:32:12.832154  4247 net.cpp:122] Setting up Eltwise6
I0928 09:32:12.832159  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.832160  4247 net.cpp:137] Memory required for data: 453428400
I0928 09:32:12.832162  4247 layer_factory.hpp:77] Creating layer M2PELU13
I0928 09:32:12.832167  4247 net.cpp:84] Creating Layer M2PELU13
I0928 09:32:12.832170  4247 net.cpp:406] M2PELU13 <- Eltwise6
I0928 09:32:12.832173  4247 net.cpp:367] M2PELU13 -> Eltwise6 (in-place)
I0928 09:32:12.832278  4247 net.cpp:122] Setting up M2PELU13
I0928 09:32:12.832281  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.832283  4247 net.cpp:137] Memory required for data: 459982000
I0928 09:32:12.832288  4247 layer_factory.hpp:77] Creating layer Eltwise6_M2PELU13_0_split
I0928 09:32:12.832291  4247 net.cpp:84] Creating Layer Eltwise6_M2PELU13_0_split
I0928 09:32:12.832293  4247 net.cpp:406] Eltwise6_M2PELU13_0_split <- Eltwise6
I0928 09:32:12.832298  4247 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_0
I0928 09:32:12.832301  4247 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_1
I0928 09:32:12.832329  4247 net.cpp:122] Setting up Eltwise6_M2PELU13_0_split
I0928 09:32:12.853260  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.853267  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.853271  4247 net.cpp:137] Memory required for data: 473089200
I0928 09:32:12.853273  4247 layer_factory.hpp:77] Creating layer Convolution14
I0928 09:32:12.853281  4247 net.cpp:84] Creating Layer Convolution14
I0928 09:32:12.853283  4247 net.cpp:406] Convolution14 <- Eltwise6_M2PELU13_0_split_0
I0928 09:32:12.853291  4247 net.cpp:380] Convolution14 -> Convolution14
I0928 09:32:12.854351  4247 net.cpp:122] Setting up Convolution14
I0928 09:32:12.854362  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.854364  4247 net.cpp:137] Memory required for data: 479642800
I0928 09:32:12.854368  4247 layer_factory.hpp:77] Creating layer BatchNorm14
I0928 09:32:12.854374  4247 net.cpp:84] Creating Layer BatchNorm14
I0928 09:32:12.854377  4247 net.cpp:406] BatchNorm14 <- Convolution14
I0928 09:32:12.854382  4247 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0928 09:32:12.854635  4247 net.cpp:122] Setting up BatchNorm14
I0928 09:32:12.854647  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.854651  4247 net.cpp:137] Memory required for data: 486196400
I0928 09:32:12.854661  4247 layer_factory.hpp:77] Creating layer Scale14
I0928 09:32:12.854671  4247 net.cpp:84] Creating Layer Scale14
I0928 09:32:12.854684  4247 net.cpp:406] Scale14 <- Convolution14
I0928 09:32:12.854692  4247 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0928 09:32:12.854737  4247 layer_factory.hpp:77] Creating layer Scale14
I0928 09:32:12.854876  4247 net.cpp:122] Setting up Scale14
I0928 09:32:12.854887  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.854889  4247 net.cpp:137] Memory required for data: 492750000
I0928 09:32:12.854894  4247 layer_factory.hpp:77] Creating layer M2PELU14
I0928 09:32:12.854902  4247 net.cpp:84] Creating Layer M2PELU14
I0928 09:32:12.854903  4247 net.cpp:406] M2PELU14 <- Convolution14
I0928 09:32:12.854908  4247 net.cpp:367] M2PELU14 -> Convolution14 (in-place)
I0928 09:32:12.855028  4247 net.cpp:122] Setting up M2PELU14
I0928 09:32:12.855033  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.855036  4247 net.cpp:137] Memory required for data: 499303600
I0928 09:32:12.855039  4247 layer_factory.hpp:77] Creating layer Convolution15
I0928 09:32:12.855046  4247 net.cpp:84] Creating Layer Convolution15
I0928 09:32:12.855048  4247 net.cpp:406] Convolution15 <- Convolution14
I0928 09:32:12.855052  4247 net.cpp:380] Convolution15 -> Convolution15
I0928 09:32:12.856271  4247 net.cpp:122] Setting up Convolution15
I0928 09:32:12.856279  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.856282  4247 net.cpp:137] Memory required for data: 505857200
I0928 09:32:12.856287  4247 layer_factory.hpp:77] Creating layer BatchNorm15
I0928 09:32:12.856292  4247 net.cpp:84] Creating Layer BatchNorm15
I0928 09:32:12.856297  4247 net.cpp:406] BatchNorm15 <- Convolution15
I0928 09:32:12.856300  4247 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0928 09:32:12.856461  4247 net.cpp:122] Setting up BatchNorm15
I0928 09:32:12.856464  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.856467  4247 net.cpp:137] Memory required for data: 512410800
I0928 09:32:12.856482  4247 layer_factory.hpp:77] Creating layer Scale15
I0928 09:32:12.856488  4247 net.cpp:84] Creating Layer Scale15
I0928 09:32:12.856490  4247 net.cpp:406] Scale15 <- Convolution15
I0928 09:32:12.856493  4247 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0928 09:32:12.856526  4247 layer_factory.hpp:77] Creating layer Scale15
I0928 09:32:12.856616  4247 net.cpp:122] Setting up Scale15
I0928 09:32:12.856621  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.856622  4247 net.cpp:137] Memory required for data: 518964400
I0928 09:32:12.856626  4247 layer_factory.hpp:77] Creating layer Eltwise7
I0928 09:32:12.856631  4247 net.cpp:84] Creating Layer Eltwise7
I0928 09:32:12.856632  4247 net.cpp:406] Eltwise7 <- Eltwise6_M2PELU13_0_split_1
I0928 09:32:12.856636  4247 net.cpp:406] Eltwise7 <- Convolution15
I0928 09:32:12.856639  4247 net.cpp:380] Eltwise7 -> Eltwise7
I0928 09:32:12.856658  4247 net.cpp:122] Setting up Eltwise7
I0928 09:32:12.856662  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.856664  4247 net.cpp:137] Memory required for data: 525518000
I0928 09:32:12.856667  4247 layer_factory.hpp:77] Creating layer M2PELU15
I0928 09:32:12.856673  4247 net.cpp:84] Creating Layer M2PELU15
I0928 09:32:12.856674  4247 net.cpp:406] M2PELU15 <- Eltwise7
I0928 09:32:12.856678  4247 net.cpp:367] M2PELU15 -> Eltwise7 (in-place)
I0928 09:32:12.856786  4247 net.cpp:122] Setting up M2PELU15
I0928 09:32:12.856791  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.856793  4247 net.cpp:137] Memory required for data: 532071600
I0928 09:32:12.856797  4247 layer_factory.hpp:77] Creating layer Eltwise7_M2PELU15_0_split
I0928 09:32:12.856801  4247 net.cpp:84] Creating Layer Eltwise7_M2PELU15_0_split
I0928 09:32:12.856803  4247 net.cpp:406] Eltwise7_M2PELU15_0_split <- Eltwise7
I0928 09:32:12.856806  4247 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_0
I0928 09:32:12.856812  4247 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_1
I0928 09:32:12.856839  4247 net.cpp:122] Setting up Eltwise7_M2PELU15_0_split
I0928 09:32:12.856843  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.856853  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.856855  4247 net.cpp:137] Memory required for data: 545178800
I0928 09:32:12.856858  4247 layer_factory.hpp:77] Creating layer Convolution16
I0928 09:32:12.856865  4247 net.cpp:84] Creating Layer Convolution16
I0928 09:32:12.856868  4247 net.cpp:406] Convolution16 <- Eltwise7_M2PELU15_0_split_0
I0928 09:32:12.856873  4247 net.cpp:380] Convolution16 -> Convolution16
I0928 09:32:12.857540  4247 net.cpp:122] Setting up Convolution16
I0928 09:32:12.857548  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.857551  4247 net.cpp:137] Memory required for data: 551732400
I0928 09:32:12.857555  4247 layer_factory.hpp:77] Creating layer BatchNorm16
I0928 09:32:12.857560  4247 net.cpp:84] Creating Layer BatchNorm16
I0928 09:32:12.857563  4247 net.cpp:406] BatchNorm16 <- Convolution16
I0928 09:32:12.857566  4247 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0928 09:32:12.857728  4247 net.cpp:122] Setting up BatchNorm16
I0928 09:32:12.857733  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.857735  4247 net.cpp:137] Memory required for data: 558286000
I0928 09:32:12.857741  4247 layer_factory.hpp:77] Creating layer Scale16
I0928 09:32:12.857745  4247 net.cpp:84] Creating Layer Scale16
I0928 09:32:12.857748  4247 net.cpp:406] Scale16 <- Convolution16
I0928 09:32:12.857751  4247 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0928 09:32:12.857784  4247 layer_factory.hpp:77] Creating layer Scale16
I0928 09:32:12.857875  4247 net.cpp:122] Setting up Scale16
I0928 09:32:12.857879  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.857882  4247 net.cpp:137] Memory required for data: 564839600
I0928 09:32:12.857885  4247 layer_factory.hpp:77] Creating layer M2PELU16
I0928 09:32:12.857890  4247 net.cpp:84] Creating Layer M2PELU16
I0928 09:32:12.857893  4247 net.cpp:406] M2PELU16 <- Convolution16
I0928 09:32:12.857897  4247 net.cpp:367] M2PELU16 -> Convolution16 (in-place)
I0928 09:32:12.858001  4247 net.cpp:122] Setting up M2PELU16
I0928 09:32:12.858006  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.858008  4247 net.cpp:137] Memory required for data: 571393200
I0928 09:32:12.858012  4247 layer_factory.hpp:77] Creating layer Convolution17
I0928 09:32:12.858019  4247 net.cpp:84] Creating Layer Convolution17
I0928 09:32:12.858021  4247 net.cpp:406] Convolution17 <- Convolution16
I0928 09:32:12.858026  4247 net.cpp:380] Convolution17 -> Convolution17
I0928 09:32:12.859017  4247 net.cpp:122] Setting up Convolution17
I0928 09:32:12.859026  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.859030  4247 net.cpp:137] Memory required for data: 577946800
I0928 09:32:12.859033  4247 layer_factory.hpp:77] Creating layer BatchNorm17
I0928 09:32:12.859038  4247 net.cpp:84] Creating Layer BatchNorm17
I0928 09:32:12.859041  4247 net.cpp:406] BatchNorm17 <- Convolution17
I0928 09:32:12.859045  4247 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0928 09:32:12.859202  4247 net.cpp:122] Setting up BatchNorm17
I0928 09:32:12.859206  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.859208  4247 net.cpp:137] Memory required for data: 584500400
I0928 09:32:12.859213  4247 layer_factory.hpp:77] Creating layer Scale17
I0928 09:32:12.859218  4247 net.cpp:84] Creating Layer Scale17
I0928 09:32:12.859221  4247 net.cpp:406] Scale17 <- Convolution17
I0928 09:32:12.859225  4247 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0928 09:32:12.859256  4247 layer_factory.hpp:77] Creating layer Scale17
I0928 09:32:12.859344  4247 net.cpp:122] Setting up Scale17
I0928 09:32:12.859349  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.859350  4247 net.cpp:137] Memory required for data: 591054000
I0928 09:32:12.859354  4247 layer_factory.hpp:77] Creating layer Eltwise8
I0928 09:32:12.859359  4247 net.cpp:84] Creating Layer Eltwise8
I0928 09:32:12.859361  4247 net.cpp:406] Eltwise8 <- Eltwise7_M2PELU15_0_split_1
I0928 09:32:12.859370  4247 net.cpp:406] Eltwise8 <- Convolution17
I0928 09:32:12.859375  4247 net.cpp:380] Eltwise8 -> Eltwise8
I0928 09:32:12.859395  4247 net.cpp:122] Setting up Eltwise8
I0928 09:32:12.859400  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.859401  4247 net.cpp:137] Memory required for data: 597607600
I0928 09:32:12.859403  4247 layer_factory.hpp:77] Creating layer M2PELU17
I0928 09:32:12.859408  4247 net.cpp:84] Creating Layer M2PELU17
I0928 09:32:12.859411  4247 net.cpp:406] M2PELU17 <- Eltwise8
I0928 09:32:12.859414  4247 net.cpp:367] M2PELU17 -> Eltwise8 (in-place)
I0928 09:32:12.859529  4247 net.cpp:122] Setting up M2PELU17
I0928 09:32:12.859534  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.859536  4247 net.cpp:137] Memory required for data: 604161200
I0928 09:32:12.859540  4247 layer_factory.hpp:77] Creating layer Eltwise8_M2PELU17_0_split
I0928 09:32:12.859545  4247 net.cpp:84] Creating Layer Eltwise8_M2PELU17_0_split
I0928 09:32:12.859547  4247 net.cpp:406] Eltwise8_M2PELU17_0_split <- Eltwise8
I0928 09:32:12.859550  4247 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_0
I0928 09:32:12.859555  4247 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_1
I0928 09:32:12.859583  4247 net.cpp:122] Setting up Eltwise8_M2PELU17_0_split
I0928 09:32:12.859587  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.859591  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.859592  4247 net.cpp:137] Memory required for data: 617268400
I0928 09:32:12.859594  4247 layer_factory.hpp:77] Creating layer Convolution18
I0928 09:32:12.859601  4247 net.cpp:84] Creating Layer Convolution18
I0928 09:32:12.859602  4247 net.cpp:406] Convolution18 <- Eltwise8_M2PELU17_0_split_0
I0928 09:32:12.859607  4247 net.cpp:380] Convolution18 -> Convolution18
I0928 09:32:12.860635  4247 net.cpp:122] Setting up Convolution18
I0928 09:32:12.860644  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.860647  4247 net.cpp:137] Memory required for data: 623822000
I0928 09:32:12.860652  4247 layer_factory.hpp:77] Creating layer BatchNorm18
I0928 09:32:12.860656  4247 net.cpp:84] Creating Layer BatchNorm18
I0928 09:32:12.860659  4247 net.cpp:406] BatchNorm18 <- Convolution18
I0928 09:32:12.860663  4247 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0928 09:32:12.860816  4247 net.cpp:122] Setting up BatchNorm18
I0928 09:32:12.860821  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.860823  4247 net.cpp:137] Memory required for data: 630375600
I0928 09:32:12.860828  4247 layer_factory.hpp:77] Creating layer Scale18
I0928 09:32:12.860832  4247 net.cpp:84] Creating Layer Scale18
I0928 09:32:12.860836  4247 net.cpp:406] Scale18 <- Convolution18
I0928 09:32:12.860838  4247 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0928 09:32:12.860868  4247 layer_factory.hpp:77] Creating layer Scale18
I0928 09:32:12.860956  4247 net.cpp:122] Setting up Scale18
I0928 09:32:12.860961  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.860963  4247 net.cpp:137] Memory required for data: 636929200
I0928 09:32:12.860967  4247 layer_factory.hpp:77] Creating layer M2PELU18
I0928 09:32:12.860972  4247 net.cpp:84] Creating Layer M2PELU18
I0928 09:32:12.860975  4247 net.cpp:406] M2PELU18 <- Convolution18
I0928 09:32:12.860978  4247 net.cpp:367] M2PELU18 -> Convolution18 (in-place)
I0928 09:32:12.861084  4247 net.cpp:122] Setting up M2PELU18
I0928 09:32:12.861089  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.861091  4247 net.cpp:137] Memory required for data: 643482800
I0928 09:32:12.861095  4247 layer_factory.hpp:77] Creating layer Convolution19
I0928 09:32:12.861101  4247 net.cpp:84] Creating Layer Convolution19
I0928 09:32:12.861104  4247 net.cpp:406] Convolution19 <- Convolution18
I0928 09:32:12.861109  4247 net.cpp:380] Convolution19 -> Convolution19
I0928 09:32:12.862072  4247 net.cpp:122] Setting up Convolution19
I0928 09:32:12.862081  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.862089  4247 net.cpp:137] Memory required for data: 650036400
I0928 09:32:12.862094  4247 layer_factory.hpp:77] Creating layer BatchNorm19
I0928 09:32:12.862100  4247 net.cpp:84] Creating Layer BatchNorm19
I0928 09:32:12.862103  4247 net.cpp:406] BatchNorm19 <- Convolution19
I0928 09:32:12.862107  4247 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0928 09:32:12.862267  4247 net.cpp:122] Setting up BatchNorm19
I0928 09:32:12.862270  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.862272  4247 net.cpp:137] Memory required for data: 656590000
I0928 09:32:12.862277  4247 layer_factory.hpp:77] Creating layer Scale19
I0928 09:32:12.862282  4247 net.cpp:84] Creating Layer Scale19
I0928 09:32:12.862284  4247 net.cpp:406] Scale19 <- Convolution19
I0928 09:32:12.862288  4247 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0928 09:32:12.862318  4247 layer_factory.hpp:77] Creating layer Scale19
I0928 09:32:12.862406  4247 net.cpp:122] Setting up Scale19
I0928 09:32:12.862411  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.862413  4247 net.cpp:137] Memory required for data: 663143600
I0928 09:32:12.862417  4247 layer_factory.hpp:77] Creating layer Eltwise9
I0928 09:32:12.862421  4247 net.cpp:84] Creating Layer Eltwise9
I0928 09:32:12.862423  4247 net.cpp:406] Eltwise9 <- Eltwise8_M2PELU17_0_split_1
I0928 09:32:12.862426  4247 net.cpp:406] Eltwise9 <- Convolution19
I0928 09:32:12.862431  4247 net.cpp:380] Eltwise9 -> Eltwise9
I0928 09:32:12.862449  4247 net.cpp:122] Setting up Eltwise9
I0928 09:32:12.862453  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.862455  4247 net.cpp:137] Memory required for data: 669697200
I0928 09:32:12.862457  4247 layer_factory.hpp:77] Creating layer M2PELU19
I0928 09:32:12.862462  4247 net.cpp:84] Creating Layer M2PELU19
I0928 09:32:12.862464  4247 net.cpp:406] M2PELU19 <- Eltwise9
I0928 09:32:12.862468  4247 net.cpp:367] M2PELU19 -> Eltwise9 (in-place)
I0928 09:32:12.862601  4247 net.cpp:122] Setting up M2PELU19
I0928 09:32:12.862606  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.862607  4247 net.cpp:137] Memory required for data: 676250800
I0928 09:32:12.862612  4247 layer_factory.hpp:77] Creating layer Eltwise9_M2PELU19_0_split
I0928 09:32:12.862615  4247 net.cpp:84] Creating Layer Eltwise9_M2PELU19_0_split
I0928 09:32:12.862618  4247 net.cpp:406] Eltwise9_M2PELU19_0_split <- Eltwise9
I0928 09:32:12.862622  4247 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_0
I0928 09:32:12.883956  4247 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_1
I0928 09:32:12.884004  4247 net.cpp:122] Setting up Eltwise9_M2PELU19_0_split
I0928 09:32:12.884011  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.884014  4247 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 09:32:12.884016  4247 net.cpp:137] Memory required for data: 689358000
I0928 09:32:12.884018  4247 layer_factory.hpp:77] Creating layer Convolution20
I0928 09:32:12.884026  4247 net.cpp:84] Creating Layer Convolution20
I0928 09:32:12.884028  4247 net.cpp:406] Convolution20 <- Eltwise9_M2PELU19_0_split_0
I0928 09:32:12.884034  4247 net.cpp:380] Convolution20 -> Convolution20
I0928 09:32:12.885068  4247 net.cpp:122] Setting up Convolution20
I0928 09:32:12.885078  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.885082  4247 net.cpp:137] Memory required for data: 692634800
I0928 09:32:12.885087  4247 layer_factory.hpp:77] Creating layer BatchNorm20
I0928 09:32:12.885092  4247 net.cpp:84] Creating Layer BatchNorm20
I0928 09:32:12.885095  4247 net.cpp:406] BatchNorm20 <- Convolution20
I0928 09:32:12.885099  4247 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0928 09:32:12.885319  4247 net.cpp:122] Setting up BatchNorm20
I0928 09:32:12.885331  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.885336  4247 net.cpp:137] Memory required for data: 695911600
I0928 09:32:12.885345  4247 layer_factory.hpp:77] Creating layer Scale20
I0928 09:32:12.885354  4247 net.cpp:84] Creating Layer Scale20
I0928 09:32:12.885370  4247 net.cpp:406] Scale20 <- Convolution20
I0928 09:32:12.885378  4247 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0928 09:32:12.885437  4247 layer_factory.hpp:77] Creating layer Scale20
I0928 09:32:12.885576  4247 net.cpp:122] Setting up Scale20
I0928 09:32:12.885587  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.885591  4247 net.cpp:137] Memory required for data: 699188400
I0928 09:32:12.885599  4247 layer_factory.hpp:77] Creating layer Convolution21
I0928 09:32:12.885620  4247 net.cpp:84] Creating Layer Convolution21
I0928 09:32:12.885625  4247 net.cpp:406] Convolution21 <- Eltwise9_M2PELU19_0_split_1
I0928 09:32:12.885632  4247 net.cpp:380] Convolution21 -> Convolution21
I0928 09:32:12.886710  4247 net.cpp:122] Setting up Convolution21
I0928 09:32:12.886719  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.886723  4247 net.cpp:137] Memory required for data: 702465200
I0928 09:32:12.886728  4247 layer_factory.hpp:77] Creating layer BatchNorm21
I0928 09:32:12.886732  4247 net.cpp:84] Creating Layer BatchNorm21
I0928 09:32:12.886745  4247 net.cpp:406] BatchNorm21 <- Convolution21
I0928 09:32:12.886749  4247 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0928 09:32:12.886916  4247 net.cpp:122] Setting up BatchNorm21
I0928 09:32:12.886921  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.886924  4247 net.cpp:137] Memory required for data: 705742000
I0928 09:32:12.886929  4247 layer_factory.hpp:77] Creating layer Scale21
I0928 09:32:12.886932  4247 net.cpp:84] Creating Layer Scale21
I0928 09:32:12.886934  4247 net.cpp:406] Scale21 <- Convolution21
I0928 09:32:12.886940  4247 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0928 09:32:12.886970  4247 layer_factory.hpp:77] Creating layer Scale21
I0928 09:32:12.887058  4247 net.cpp:122] Setting up Scale21
I0928 09:32:12.887063  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.887065  4247 net.cpp:137] Memory required for data: 709018800
I0928 09:32:12.887069  4247 layer_factory.hpp:77] Creating layer M2PELU20
I0928 09:32:12.887073  4247 net.cpp:84] Creating Layer M2PELU20
I0928 09:32:12.887075  4247 net.cpp:406] M2PELU20 <- Convolution21
I0928 09:32:12.887079  4247 net.cpp:367] M2PELU20 -> Convolution21 (in-place)
I0928 09:32:12.887176  4247 net.cpp:122] Setting up M2PELU20
I0928 09:32:12.887181  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.887183  4247 net.cpp:137] Memory required for data: 712295600
I0928 09:32:12.887187  4247 layer_factory.hpp:77] Creating layer Convolution22
I0928 09:32:12.887195  4247 net.cpp:84] Creating Layer Convolution22
I0928 09:32:12.887197  4247 net.cpp:406] Convolution22 <- Convolution21
I0928 09:32:12.887202  4247 net.cpp:380] Convolution22 -> Convolution22
I0928 09:32:12.888350  4247 net.cpp:122] Setting up Convolution22
I0928 09:32:12.888358  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.888361  4247 net.cpp:137] Memory required for data: 715572400
I0928 09:32:12.888365  4247 layer_factory.hpp:77] Creating layer BatchNorm22
I0928 09:32:12.888370  4247 net.cpp:84] Creating Layer BatchNorm22
I0928 09:32:12.888373  4247 net.cpp:406] BatchNorm22 <- Convolution22
I0928 09:32:12.888377  4247 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0928 09:32:12.888533  4247 net.cpp:122] Setting up BatchNorm22
I0928 09:32:12.888537  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.888540  4247 net.cpp:137] Memory required for data: 718849200
I0928 09:32:12.888545  4247 layer_factory.hpp:77] Creating layer Scale22
I0928 09:32:12.888548  4247 net.cpp:84] Creating Layer Scale22
I0928 09:32:12.888551  4247 net.cpp:406] Scale22 <- Convolution22
I0928 09:32:12.888556  4247 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0928 09:32:12.888586  4247 layer_factory.hpp:77] Creating layer Scale22
I0928 09:32:12.888676  4247 net.cpp:122] Setting up Scale22
I0928 09:32:12.888680  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.888682  4247 net.cpp:137] Memory required for data: 722126000
I0928 09:32:12.888694  4247 layer_factory.hpp:77] Creating layer Eltwise10
I0928 09:32:12.888697  4247 net.cpp:84] Creating Layer Eltwise10
I0928 09:32:12.888700  4247 net.cpp:406] Eltwise10 <- Convolution20
I0928 09:32:12.888703  4247 net.cpp:406] Eltwise10 <- Convolution22
I0928 09:32:12.888707  4247 net.cpp:380] Eltwise10 -> Eltwise10
I0928 09:32:12.888723  4247 net.cpp:122] Setting up Eltwise10
I0928 09:32:12.888727  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.888730  4247 net.cpp:137] Memory required for data: 725402800
I0928 09:32:12.888731  4247 layer_factory.hpp:77] Creating layer M2PELU21
I0928 09:32:12.888736  4247 net.cpp:84] Creating Layer M2PELU21
I0928 09:32:12.888739  4247 net.cpp:406] M2PELU21 <- Eltwise10
I0928 09:32:12.888742  4247 net.cpp:367] M2PELU21 -> Eltwise10 (in-place)
I0928 09:32:12.888844  4247 net.cpp:122] Setting up M2PELU21
I0928 09:32:12.888849  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.888851  4247 net.cpp:137] Memory required for data: 728679600
I0928 09:32:12.888854  4247 layer_factory.hpp:77] Creating layer Eltwise10_M2PELU21_0_split
I0928 09:32:12.888859  4247 net.cpp:84] Creating Layer Eltwise10_M2PELU21_0_split
I0928 09:32:12.888860  4247 net.cpp:406] Eltwise10_M2PELU21_0_split <- Eltwise10
I0928 09:32:12.888864  4247 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_0
I0928 09:32:12.888870  4247 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_1
I0928 09:32:12.888896  4247 net.cpp:122] Setting up Eltwise10_M2PELU21_0_split
I0928 09:32:12.888900  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.888903  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.888906  4247 net.cpp:137] Memory required for data: 735233200
I0928 09:32:12.888907  4247 layer_factory.hpp:77] Creating layer Convolution23
I0928 09:32:12.888913  4247 net.cpp:84] Creating Layer Convolution23
I0928 09:32:12.888916  4247 net.cpp:406] Convolution23 <- Eltwise10_M2PELU21_0_split_0
I0928 09:32:12.888921  4247 net.cpp:380] Convolution23 -> Convolution23
I0928 09:32:12.890041  4247 net.cpp:122] Setting up Convolution23
I0928 09:32:12.890050  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.890053  4247 net.cpp:137] Memory required for data: 738510000
I0928 09:32:12.890058  4247 layer_factory.hpp:77] Creating layer BatchNorm23
I0928 09:32:12.890064  4247 net.cpp:84] Creating Layer BatchNorm23
I0928 09:32:12.890065  4247 net.cpp:406] BatchNorm23 <- Convolution23
I0928 09:32:12.890070  4247 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0928 09:32:12.890229  4247 net.cpp:122] Setting up BatchNorm23
I0928 09:32:12.890233  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.890235  4247 net.cpp:137] Memory required for data: 741786800
I0928 09:32:12.890240  4247 layer_factory.hpp:77] Creating layer Scale23
I0928 09:32:12.890244  4247 net.cpp:84] Creating Layer Scale23
I0928 09:32:12.890247  4247 net.cpp:406] Scale23 <- Convolution23
I0928 09:32:12.890250  4247 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0928 09:32:12.890281  4247 layer_factory.hpp:77] Creating layer Scale23
I0928 09:32:12.890372  4247 net.cpp:122] Setting up Scale23
I0928 09:32:12.890377  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.890379  4247 net.cpp:137] Memory required for data: 745063600
I0928 09:32:12.890383  4247 layer_factory.hpp:77] Creating layer M2PELU22
I0928 09:32:12.890388  4247 net.cpp:84] Creating Layer M2PELU22
I0928 09:32:12.890390  4247 net.cpp:406] M2PELU22 <- Convolution23
I0928 09:32:12.890394  4247 net.cpp:367] M2PELU22 -> Convolution23 (in-place)
I0928 09:32:12.890494  4247 net.cpp:122] Setting up M2PELU22
I0928 09:32:12.890498  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.890501  4247 net.cpp:137] Memory required for data: 748340400
I0928 09:32:12.890504  4247 layer_factory.hpp:77] Creating layer Convolution24
I0928 09:32:12.890511  4247 net.cpp:84] Creating Layer Convolution24
I0928 09:32:12.890523  4247 net.cpp:406] Convolution24 <- Convolution23
I0928 09:32:12.890529  4247 net.cpp:380] Convolution24 -> Convolution24
I0928 09:32:12.891660  4247 net.cpp:122] Setting up Convolution24
I0928 09:32:12.891669  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.891672  4247 net.cpp:137] Memory required for data: 751617200
I0928 09:32:12.891676  4247 layer_factory.hpp:77] Creating layer BatchNorm24
I0928 09:32:12.891681  4247 net.cpp:84] Creating Layer BatchNorm24
I0928 09:32:12.891685  4247 net.cpp:406] BatchNorm24 <- Convolution24
I0928 09:32:12.891687  4247 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0928 09:32:12.892338  4247 net.cpp:122] Setting up BatchNorm24
I0928 09:32:12.892345  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.892349  4247 net.cpp:137] Memory required for data: 754894000
I0928 09:32:12.892354  4247 layer_factory.hpp:77] Creating layer Scale24
I0928 09:32:12.892359  4247 net.cpp:84] Creating Layer Scale24
I0928 09:32:12.892361  4247 net.cpp:406] Scale24 <- Convolution24
I0928 09:32:12.892365  4247 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0928 09:32:12.892393  4247 layer_factory.hpp:77] Creating layer Scale24
I0928 09:32:12.892464  4247 net.cpp:122] Setting up Scale24
I0928 09:32:12.892468  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.892470  4247 net.cpp:137] Memory required for data: 758170800
I0928 09:32:12.892474  4247 layer_factory.hpp:77] Creating layer Eltwise11
I0928 09:32:12.892479  4247 net.cpp:84] Creating Layer Eltwise11
I0928 09:32:12.892482  4247 net.cpp:406] Eltwise11 <- Eltwise10_M2PELU21_0_split_1
I0928 09:32:12.892484  4247 net.cpp:406] Eltwise11 <- Convolution24
I0928 09:32:12.892488  4247 net.cpp:380] Eltwise11 -> Eltwise11
I0928 09:32:12.892500  4247 net.cpp:122] Setting up Eltwise11
I0928 09:32:12.892503  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.892505  4247 net.cpp:137] Memory required for data: 761447600
I0928 09:32:12.892508  4247 layer_factory.hpp:77] Creating layer M2PELU23
I0928 09:32:12.892513  4247 net.cpp:84] Creating Layer M2PELU23
I0928 09:32:12.892514  4247 net.cpp:406] M2PELU23 <- Eltwise11
I0928 09:32:12.892518  4247 net.cpp:367] M2PELU23 -> Eltwise11 (in-place)
I0928 09:32:12.892601  4247 net.cpp:122] Setting up M2PELU23
I0928 09:32:12.892606  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.892608  4247 net.cpp:137] Memory required for data: 764724400
I0928 09:32:12.892612  4247 layer_factory.hpp:77] Creating layer Eltwise11_M2PELU23_0_split
I0928 09:32:12.892616  4247 net.cpp:84] Creating Layer Eltwise11_M2PELU23_0_split
I0928 09:32:12.892618  4247 net.cpp:406] Eltwise11_M2PELU23_0_split <- Eltwise11
I0928 09:32:12.892622  4247 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_0
I0928 09:32:12.892627  4247 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_1
I0928 09:32:12.892649  4247 net.cpp:122] Setting up Eltwise11_M2PELU23_0_split
I0928 09:32:12.892653  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.892655  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.892657  4247 net.cpp:137] Memory required for data: 771278000
I0928 09:32:12.892659  4247 layer_factory.hpp:77] Creating layer Convolution25
I0928 09:32:12.892665  4247 net.cpp:84] Creating Layer Convolution25
I0928 09:32:12.892668  4247 net.cpp:406] Convolution25 <- Eltwise11_M2PELU23_0_split_0
I0928 09:32:12.892673  4247 net.cpp:380] Convolution25 -> Convolution25
I0928 09:32:12.893781  4247 net.cpp:122] Setting up Convolution25
I0928 09:32:12.893790  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.893793  4247 net.cpp:137] Memory required for data: 774554800
I0928 09:32:12.893797  4247 layer_factory.hpp:77] Creating layer BatchNorm25
I0928 09:32:12.893802  4247 net.cpp:84] Creating Layer BatchNorm25
I0928 09:32:12.893805  4247 net.cpp:406] BatchNorm25 <- Convolution25
I0928 09:32:12.893810  4247 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0928 09:32:12.893937  4247 net.cpp:122] Setting up BatchNorm25
I0928 09:32:12.893949  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.893951  4247 net.cpp:137] Memory required for data: 777831600
I0928 09:32:12.893956  4247 layer_factory.hpp:77] Creating layer Scale25
I0928 09:32:12.893961  4247 net.cpp:84] Creating Layer Scale25
I0928 09:32:12.893965  4247 net.cpp:406] Scale25 <- Convolution25
I0928 09:32:12.893967  4247 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0928 09:32:12.893996  4247 layer_factory.hpp:77] Creating layer Scale25
I0928 09:32:12.894069  4247 net.cpp:122] Setting up Scale25
I0928 09:32:12.894073  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.894075  4247 net.cpp:137] Memory required for data: 781108400
I0928 09:32:12.894079  4247 layer_factory.hpp:77] Creating layer M2PELU24
I0928 09:32:12.894084  4247 net.cpp:84] Creating Layer M2PELU24
I0928 09:32:12.894086  4247 net.cpp:406] M2PELU24 <- Convolution25
I0928 09:32:12.894090  4247 net.cpp:367] M2PELU24 -> Convolution25 (in-place)
I0928 09:32:12.894171  4247 net.cpp:122] Setting up M2PELU24
I0928 09:32:12.894176  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.894177  4247 net.cpp:137] Memory required for data: 784385200
I0928 09:32:12.894181  4247 layer_factory.hpp:77] Creating layer Convolution26
I0928 09:32:12.894188  4247 net.cpp:84] Creating Layer Convolution26
I0928 09:32:12.894191  4247 net.cpp:406] Convolution26 <- Convolution25
I0928 09:32:12.894196  4247 net.cpp:380] Convolution26 -> Convolution26
I0928 09:32:12.894960  4247 net.cpp:122] Setting up Convolution26
I0928 09:32:12.894968  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.894970  4247 net.cpp:137] Memory required for data: 787662000
I0928 09:32:12.894975  4247 layer_factory.hpp:77] Creating layer BatchNorm26
I0928 09:32:12.894980  4247 net.cpp:84] Creating Layer BatchNorm26
I0928 09:32:12.894982  4247 net.cpp:406] BatchNorm26 <- Convolution26
I0928 09:32:12.894986  4247 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0928 09:32:12.895113  4247 net.cpp:122] Setting up BatchNorm26
I0928 09:32:12.895118  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.895120  4247 net.cpp:137] Memory required for data: 790938800
I0928 09:32:12.895125  4247 layer_factory.hpp:77] Creating layer Scale26
I0928 09:32:12.895129  4247 net.cpp:84] Creating Layer Scale26
I0928 09:32:12.914856  4247 net.cpp:406] Scale26 <- Convolution26
I0928 09:32:12.914867  4247 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0928 09:32:12.914907  4247 layer_factory.hpp:77] Creating layer Scale26
I0928 09:32:12.914994  4247 net.cpp:122] Setting up Scale26
I0928 09:32:12.914999  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.915000  4247 net.cpp:137] Memory required for data: 794215600
I0928 09:32:12.915005  4247 layer_factory.hpp:77] Creating layer Eltwise12
I0928 09:32:12.915009  4247 net.cpp:84] Creating Layer Eltwise12
I0928 09:32:12.915012  4247 net.cpp:406] Eltwise12 <- Eltwise11_M2PELU23_0_split_1
I0928 09:32:12.915015  4247 net.cpp:406] Eltwise12 <- Convolution26
I0928 09:32:12.915020  4247 net.cpp:380] Eltwise12 -> Eltwise12
I0928 09:32:12.915033  4247 net.cpp:122] Setting up Eltwise12
I0928 09:32:12.915037  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.915040  4247 net.cpp:137] Memory required for data: 797492400
I0928 09:32:12.915041  4247 layer_factory.hpp:77] Creating layer M2PELU25
I0928 09:32:12.915055  4247 net.cpp:84] Creating Layer M2PELU25
I0928 09:32:12.915058  4247 net.cpp:406] M2PELU25 <- Eltwise12
I0928 09:32:12.915062  4247 net.cpp:367] M2PELU25 -> Eltwise12 (in-place)
I0928 09:32:12.915155  4247 net.cpp:122] Setting up M2PELU25
I0928 09:32:12.915160  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.915163  4247 net.cpp:137] Memory required for data: 800769200
I0928 09:32:12.915168  4247 layer_factory.hpp:77] Creating layer Eltwise12_M2PELU25_0_split
I0928 09:32:12.915170  4247 net.cpp:84] Creating Layer Eltwise12_M2PELU25_0_split
I0928 09:32:12.915174  4247 net.cpp:406] Eltwise12_M2PELU25_0_split <- Eltwise12
I0928 09:32:12.915184  4247 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_0
I0928 09:32:12.915190  4247 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_1
I0928 09:32:12.915217  4247 net.cpp:122] Setting up Eltwise12_M2PELU25_0_split
I0928 09:32:12.915221  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.915225  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.915227  4247 net.cpp:137] Memory required for data: 807322800
I0928 09:32:12.915230  4247 layer_factory.hpp:77] Creating layer Convolution27
I0928 09:32:12.915236  4247 net.cpp:84] Creating Layer Convolution27
I0928 09:32:12.915240  4247 net.cpp:406] Convolution27 <- Eltwise12_M2PELU25_0_split_0
I0928 09:32:12.915244  4247 net.cpp:380] Convolution27 -> Convolution27
I0928 09:32:12.916900  4247 net.cpp:122] Setting up Convolution27
I0928 09:32:12.916909  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.916913  4247 net.cpp:137] Memory required for data: 810599600
I0928 09:32:12.916916  4247 layer_factory.hpp:77] Creating layer BatchNorm27
I0928 09:32:12.916923  4247 net.cpp:84] Creating Layer BatchNorm27
I0928 09:32:12.916925  4247 net.cpp:406] BatchNorm27 <- Convolution27
I0928 09:32:12.916929  4247 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0928 09:32:12.917057  4247 net.cpp:122] Setting up BatchNorm27
I0928 09:32:12.917062  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.917063  4247 net.cpp:137] Memory required for data: 813876400
I0928 09:32:12.917068  4247 layer_factory.hpp:77] Creating layer Scale27
I0928 09:32:12.917073  4247 net.cpp:84] Creating Layer Scale27
I0928 09:32:12.917075  4247 net.cpp:406] Scale27 <- Convolution27
I0928 09:32:12.917078  4247 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0928 09:32:12.917105  4247 layer_factory.hpp:77] Creating layer Scale27
I0928 09:32:12.917177  4247 net.cpp:122] Setting up Scale27
I0928 09:32:12.917181  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.917183  4247 net.cpp:137] Memory required for data: 817153200
I0928 09:32:12.917187  4247 layer_factory.hpp:77] Creating layer M2PELU26
I0928 09:32:12.917192  4247 net.cpp:84] Creating Layer M2PELU26
I0928 09:32:12.917196  4247 net.cpp:406] M2PELU26 <- Convolution27
I0928 09:32:12.917199  4247 net.cpp:367] M2PELU26 -> Convolution27 (in-place)
I0928 09:32:12.917279  4247 net.cpp:122] Setting up M2PELU26
I0928 09:32:12.917284  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.917285  4247 net.cpp:137] Memory required for data: 820430000
I0928 09:32:12.917289  4247 layer_factory.hpp:77] Creating layer Convolution28
I0928 09:32:12.917295  4247 net.cpp:84] Creating Layer Convolution28
I0928 09:32:12.917297  4247 net.cpp:406] Convolution28 <- Convolution27
I0928 09:32:12.917302  4247 net.cpp:380] Convolution28 -> Convolution28
I0928 09:32:12.918862  4247 net.cpp:122] Setting up Convolution28
I0928 09:32:12.918872  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.918874  4247 net.cpp:137] Memory required for data: 823706800
I0928 09:32:12.918879  4247 layer_factory.hpp:77] Creating layer BatchNorm28
I0928 09:32:12.918885  4247 net.cpp:84] Creating Layer BatchNorm28
I0928 09:32:12.918889  4247 net.cpp:406] BatchNorm28 <- Convolution28
I0928 09:32:12.918892  4247 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0928 09:32:12.919021  4247 net.cpp:122] Setting up BatchNorm28
I0928 09:32:12.919025  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.919028  4247 net.cpp:137] Memory required for data: 826983600
I0928 09:32:12.919033  4247 layer_factory.hpp:77] Creating layer Scale28
I0928 09:32:12.919036  4247 net.cpp:84] Creating Layer Scale28
I0928 09:32:12.919039  4247 net.cpp:406] Scale28 <- Convolution28
I0928 09:32:12.919044  4247 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0928 09:32:12.919068  4247 layer_factory.hpp:77] Creating layer Scale28
I0928 09:32:12.919142  4247 net.cpp:122] Setting up Scale28
I0928 09:32:12.919145  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.919155  4247 net.cpp:137] Memory required for data: 830260400
I0928 09:32:12.919160  4247 layer_factory.hpp:77] Creating layer Eltwise13
I0928 09:32:12.919164  4247 net.cpp:84] Creating Layer Eltwise13
I0928 09:32:12.919167  4247 net.cpp:406] Eltwise13 <- Eltwise12_M2PELU25_0_split_1
I0928 09:32:12.919170  4247 net.cpp:406] Eltwise13 <- Convolution28
I0928 09:32:12.919173  4247 net.cpp:380] Eltwise13 -> Eltwise13
I0928 09:32:12.919188  4247 net.cpp:122] Setting up Eltwise13
I0928 09:32:12.919193  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.919194  4247 net.cpp:137] Memory required for data: 833537200
I0928 09:32:12.919198  4247 layer_factory.hpp:77] Creating layer M2PELU27
I0928 09:32:12.919203  4247 net.cpp:84] Creating Layer M2PELU27
I0928 09:32:12.919204  4247 net.cpp:406] M2PELU27 <- Eltwise13
I0928 09:32:12.919208  4247 net.cpp:367] M2PELU27 -> Eltwise13 (in-place)
I0928 09:32:12.919293  4247 net.cpp:122] Setting up M2PELU27
I0928 09:32:12.919297  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.919299  4247 net.cpp:137] Memory required for data: 836814000
I0928 09:32:12.919303  4247 layer_factory.hpp:77] Creating layer Eltwise13_M2PELU27_0_split
I0928 09:32:12.919306  4247 net.cpp:84] Creating Layer Eltwise13_M2PELU27_0_split
I0928 09:32:12.919309  4247 net.cpp:406] Eltwise13_M2PELU27_0_split <- Eltwise13
I0928 09:32:12.919312  4247 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_0
I0928 09:32:12.919317  4247 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_1
I0928 09:32:12.919340  4247 net.cpp:122] Setting up Eltwise13_M2PELU27_0_split
I0928 09:32:12.919344  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.919348  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.919349  4247 net.cpp:137] Memory required for data: 843367600
I0928 09:32:12.919351  4247 layer_factory.hpp:77] Creating layer Convolution29
I0928 09:32:12.919358  4247 net.cpp:84] Creating Layer Convolution29
I0928 09:32:12.919360  4247 net.cpp:406] Convolution29 <- Eltwise13_M2PELU27_0_split_0
I0928 09:32:12.919364  4247 net.cpp:380] Convolution29 -> Convolution29
I0928 09:32:12.920457  4247 net.cpp:122] Setting up Convolution29
I0928 09:32:12.920466  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.920469  4247 net.cpp:137] Memory required for data: 846644400
I0928 09:32:12.920473  4247 layer_factory.hpp:77] Creating layer BatchNorm29
I0928 09:32:12.920480  4247 net.cpp:84] Creating Layer BatchNorm29
I0928 09:32:12.920482  4247 net.cpp:406] BatchNorm29 <- Convolution29
I0928 09:32:12.920485  4247 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0928 09:32:12.920613  4247 net.cpp:122] Setting up BatchNorm29
I0928 09:32:12.920617  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.920619  4247 net.cpp:137] Memory required for data: 849921200
I0928 09:32:12.920624  4247 layer_factory.hpp:77] Creating layer Scale29
I0928 09:32:12.920629  4247 net.cpp:84] Creating Layer Scale29
I0928 09:32:12.920630  4247 net.cpp:406] Scale29 <- Convolution29
I0928 09:32:12.920634  4247 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0928 09:32:12.920660  4247 layer_factory.hpp:77] Creating layer Scale29
I0928 09:32:12.920732  4247 net.cpp:122] Setting up Scale29
I0928 09:32:12.920737  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.920738  4247 net.cpp:137] Memory required for data: 853198000
I0928 09:32:12.920763  4247 layer_factory.hpp:77] Creating layer M2PELU28
I0928 09:32:12.920768  4247 net.cpp:84] Creating Layer M2PELU28
I0928 09:32:12.920771  4247 net.cpp:406] M2PELU28 <- Convolution29
I0928 09:32:12.920774  4247 net.cpp:367] M2PELU28 -> Convolution29 (in-place)
I0928 09:32:12.920858  4247 net.cpp:122] Setting up M2PELU28
I0928 09:32:12.920862  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.920864  4247 net.cpp:137] Memory required for data: 856474800
I0928 09:32:12.920868  4247 layer_factory.hpp:77] Creating layer Convolution30
I0928 09:32:12.920882  4247 net.cpp:84] Creating Layer Convolution30
I0928 09:32:12.920886  4247 net.cpp:406] Convolution30 <- Convolution29
I0928 09:32:12.920889  4247 net.cpp:380] Convolution30 -> Convolution30
I0928 09:32:12.921985  4247 net.cpp:122] Setting up Convolution30
I0928 09:32:12.921994  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.921996  4247 net.cpp:137] Memory required for data: 859751600
I0928 09:32:12.922001  4247 layer_factory.hpp:77] Creating layer BatchNorm30
I0928 09:32:12.922006  4247 net.cpp:84] Creating Layer BatchNorm30
I0928 09:32:12.922009  4247 net.cpp:406] BatchNorm30 <- Convolution30
I0928 09:32:12.922013  4247 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0928 09:32:12.922139  4247 net.cpp:122] Setting up BatchNorm30
I0928 09:32:12.922144  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.922147  4247 net.cpp:137] Memory required for data: 863028400
I0928 09:32:12.922152  4247 layer_factory.hpp:77] Creating layer Scale30
I0928 09:32:12.922157  4247 net.cpp:84] Creating Layer Scale30
I0928 09:32:12.922158  4247 net.cpp:406] Scale30 <- Convolution30
I0928 09:32:12.922161  4247 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0928 09:32:12.922188  4247 layer_factory.hpp:77] Creating layer Scale30
I0928 09:32:12.922260  4247 net.cpp:122] Setting up Scale30
I0928 09:32:12.922264  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.922266  4247 net.cpp:137] Memory required for data: 866305200
I0928 09:32:12.922271  4247 layer_factory.hpp:77] Creating layer Eltwise14
I0928 09:32:12.922274  4247 net.cpp:84] Creating Layer Eltwise14
I0928 09:32:12.922277  4247 net.cpp:406] Eltwise14 <- Eltwise13_M2PELU27_0_split_1
I0928 09:32:12.922281  4247 net.cpp:406] Eltwise14 <- Convolution30
I0928 09:32:12.922283  4247 net.cpp:380] Eltwise14 -> Eltwise14
I0928 09:32:12.922297  4247 net.cpp:122] Setting up Eltwise14
I0928 09:32:12.922299  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.922302  4247 net.cpp:137] Memory required for data: 869582000
I0928 09:32:12.922303  4247 layer_factory.hpp:77] Creating layer M2PELU29
I0928 09:32:12.922308  4247 net.cpp:84] Creating Layer M2PELU29
I0928 09:32:12.922310  4247 net.cpp:406] M2PELU29 <- Eltwise14
I0928 09:32:12.922314  4247 net.cpp:367] M2PELU29 -> Eltwise14 (in-place)
I0928 09:32:12.922399  4247 net.cpp:122] Setting up M2PELU29
I0928 09:32:12.922405  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.922406  4247 net.cpp:137] Memory required for data: 872858800
I0928 09:32:12.922410  4247 layer_factory.hpp:77] Creating layer Eltwise14_M2PELU29_0_split
I0928 09:32:12.922415  4247 net.cpp:84] Creating Layer Eltwise14_M2PELU29_0_split
I0928 09:32:12.922416  4247 net.cpp:406] Eltwise14_M2PELU29_0_split <- Eltwise14
I0928 09:32:12.922420  4247 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_0
I0928 09:32:12.922425  4247 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_1
I0928 09:32:12.922447  4247 net.cpp:122] Setting up Eltwise14_M2PELU29_0_split
I0928 09:32:12.922451  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.922453  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.922456  4247 net.cpp:137] Memory required for data: 879412400
I0928 09:32:12.922457  4247 layer_factory.hpp:77] Creating layer Convolution31
I0928 09:32:12.922463  4247 net.cpp:84] Creating Layer Convolution31
I0928 09:32:12.922466  4247 net.cpp:406] Convolution31 <- Eltwise14_M2PELU29_0_split_0
I0928 09:32:12.922471  4247 net.cpp:380] Convolution31 -> Convolution31
I0928 09:32:12.923564  4247 net.cpp:122] Setting up Convolution31
I0928 09:32:12.923573  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.923575  4247 net.cpp:137] Memory required for data: 882689200
I0928 09:32:12.923580  4247 layer_factory.hpp:77] Creating layer BatchNorm31
I0928 09:32:12.923585  4247 net.cpp:84] Creating Layer BatchNorm31
I0928 09:32:12.923588  4247 net.cpp:406] BatchNorm31 <- Convolution31
I0928 09:32:12.923591  4247 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0928 09:32:12.923727  4247 net.cpp:122] Setting up BatchNorm31
I0928 09:32:12.923732  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.923733  4247 net.cpp:137] Memory required for data: 885966000
I0928 09:32:12.923738  4247 layer_factory.hpp:77] Creating layer Scale31
I0928 09:32:12.923743  4247 net.cpp:84] Creating Layer Scale31
I0928 09:32:12.923745  4247 net.cpp:406] Scale31 <- Convolution31
I0928 09:32:12.923749  4247 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0928 09:32:12.923774  4247 layer_factory.hpp:77] Creating layer Scale31
I0928 09:32:12.923848  4247 net.cpp:122] Setting up Scale31
I0928 09:32:12.923852  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.923854  4247 net.cpp:137] Memory required for data: 889242800
I0928 09:32:12.923858  4247 layer_factory.hpp:77] Creating layer M2PELU30
I0928 09:32:12.923863  4247 net.cpp:84] Creating Layer M2PELU30
I0928 09:32:12.923866  4247 net.cpp:406] M2PELU30 <- Convolution31
I0928 09:32:12.923871  4247 net.cpp:367] M2PELU30 -> Convolution31 (in-place)
I0928 09:32:12.923949  4247 net.cpp:122] Setting up M2PELU30
I0928 09:32:12.923954  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.923955  4247 net.cpp:137] Memory required for data: 892519600
I0928 09:32:12.923959  4247 layer_factory.hpp:77] Creating layer Convolution32
I0928 09:32:12.923966  4247 net.cpp:84] Creating Layer Convolution32
I0928 09:32:12.923969  4247 net.cpp:406] Convolution32 <- Convolution31
I0928 09:32:12.923974  4247 net.cpp:380] Convolution32 -> Convolution32
I0928 09:32:12.925065  4247 net.cpp:122] Setting up Convolution32
I0928 09:32:12.925074  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.925077  4247 net.cpp:137] Memory required for data: 895796400
I0928 09:32:12.925081  4247 layer_factory.hpp:77] Creating layer BatchNorm32
I0928 09:32:12.925087  4247 net.cpp:84] Creating Layer BatchNorm32
I0928 09:32:12.925091  4247 net.cpp:406] BatchNorm32 <- Convolution32
I0928 09:32:12.925094  4247 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I0928 09:32:12.925220  4247 net.cpp:122] Setting up BatchNorm32
I0928 09:32:12.925225  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.945848  4247 net.cpp:137] Memory required for data: 899073200
I0928 09:32:12.945860  4247 layer_factory.hpp:77] Creating layer Scale32
I0928 09:32:12.945868  4247 net.cpp:84] Creating Layer Scale32
I0928 09:32:12.945871  4247 net.cpp:406] Scale32 <- Convolution32
I0928 09:32:12.945875  4247 net.cpp:367] Scale32 -> Convolution32 (in-place)
I0928 09:32:12.945915  4247 layer_factory.hpp:77] Creating layer Scale32
I0928 09:32:12.946002  4247 net.cpp:122] Setting up Scale32
I0928 09:32:12.946005  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.946008  4247 net.cpp:137] Memory required for data: 902350000
I0928 09:32:12.946012  4247 layer_factory.hpp:77] Creating layer Eltwise15
I0928 09:32:12.946017  4247 net.cpp:84] Creating Layer Eltwise15
I0928 09:32:12.946019  4247 net.cpp:406] Eltwise15 <- Eltwise14_M2PELU29_0_split_1
I0928 09:32:12.946023  4247 net.cpp:406] Eltwise15 <- Convolution32
I0928 09:32:12.946027  4247 net.cpp:380] Eltwise15 -> Eltwise15
I0928 09:32:12.946040  4247 net.cpp:122] Setting up Eltwise15
I0928 09:32:12.946045  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.946048  4247 net.cpp:137] Memory required for data: 905626800
I0928 09:32:12.946049  4247 layer_factory.hpp:77] Creating layer M2PELU31
I0928 09:32:12.946054  4247 net.cpp:84] Creating Layer M2PELU31
I0928 09:32:12.946056  4247 net.cpp:406] M2PELU31 <- Eltwise15
I0928 09:32:12.946061  4247 net.cpp:367] M2PELU31 -> Eltwise15 (in-place)
I0928 09:32:12.946154  4247 net.cpp:122] Setting up M2PELU31
I0928 09:32:12.946159  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.946161  4247 net.cpp:137] Memory required for data: 908903600
I0928 09:32:12.946166  4247 layer_factory.hpp:77] Creating layer Eltwise15_M2PELU31_0_split
I0928 09:32:12.946169  4247 net.cpp:84] Creating Layer Eltwise15_M2PELU31_0_split
I0928 09:32:12.946179  4247 net.cpp:406] Eltwise15_M2PELU31_0_split <- Eltwise15
I0928 09:32:12.946184  4247 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_0
I0928 09:32:12.946189  4247 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_1
I0928 09:32:12.946216  4247 net.cpp:122] Setting up Eltwise15_M2PELU31_0_split
I0928 09:32:12.946220  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.946223  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.946225  4247 net.cpp:137] Memory required for data: 915457200
I0928 09:32:12.946228  4247 layer_factory.hpp:77] Creating layer Convolution33
I0928 09:32:12.946234  4247 net.cpp:84] Creating Layer Convolution33
I0928 09:32:12.946238  4247 net.cpp:406] Convolution33 <- Eltwise15_M2PELU31_0_split_0
I0928 09:32:12.946241  4247 net.cpp:380] Convolution33 -> Convolution33
I0928 09:32:12.947610  4247 net.cpp:122] Setting up Convolution33
I0928 09:32:12.947623  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.947628  4247 net.cpp:137] Memory required for data: 918734000
I0928 09:32:12.947635  4247 layer_factory.hpp:77] Creating layer BatchNorm33
I0928 09:32:12.947643  4247 net.cpp:84] Creating Layer BatchNorm33
I0928 09:32:12.947645  4247 net.cpp:406] BatchNorm33 <- Convolution33
I0928 09:32:12.947649  4247 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I0928 09:32:12.947782  4247 net.cpp:122] Setting up BatchNorm33
I0928 09:32:12.947787  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.947788  4247 net.cpp:137] Memory required for data: 922010800
I0928 09:32:12.947793  4247 layer_factory.hpp:77] Creating layer Scale33
I0928 09:32:12.947798  4247 net.cpp:84] Creating Layer Scale33
I0928 09:32:12.947801  4247 net.cpp:406] Scale33 <- Convolution33
I0928 09:32:12.947804  4247 net.cpp:367] Scale33 -> Convolution33 (in-place)
I0928 09:32:12.947831  4247 layer_factory.hpp:77] Creating layer Scale33
I0928 09:32:12.947906  4247 net.cpp:122] Setting up Scale33
I0928 09:32:12.947911  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.947912  4247 net.cpp:137] Memory required for data: 925287600
I0928 09:32:12.947916  4247 layer_factory.hpp:77] Creating layer M2PELU32
I0928 09:32:12.947922  4247 net.cpp:84] Creating Layer M2PELU32
I0928 09:32:12.947926  4247 net.cpp:406] M2PELU32 <- Convolution33
I0928 09:32:12.947929  4247 net.cpp:367] M2PELU32 -> Convolution33 (in-place)
I0928 09:32:12.948011  4247 net.cpp:122] Setting up M2PELU32
I0928 09:32:12.948016  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.948019  4247 net.cpp:137] Memory required for data: 928564400
I0928 09:32:12.948022  4247 layer_factory.hpp:77] Creating layer Convolution34
I0928 09:32:12.948029  4247 net.cpp:84] Creating Layer Convolution34
I0928 09:32:12.948032  4247 net.cpp:406] Convolution34 <- Convolution33
I0928 09:32:12.948035  4247 net.cpp:380] Convolution34 -> Convolution34
I0928 09:32:12.949753  4247 net.cpp:122] Setting up Convolution34
I0928 09:32:12.949764  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.949765  4247 net.cpp:137] Memory required for data: 931841200
I0928 09:32:12.949770  4247 layer_factory.hpp:77] Creating layer BatchNorm34
I0928 09:32:12.949775  4247 net.cpp:84] Creating Layer BatchNorm34
I0928 09:32:12.949779  4247 net.cpp:406] BatchNorm34 <- Convolution34
I0928 09:32:12.949784  4247 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I0928 09:32:12.949913  4247 net.cpp:122] Setting up BatchNorm34
I0928 09:32:12.949918  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.949919  4247 net.cpp:137] Memory required for data: 935118000
I0928 09:32:12.949924  4247 layer_factory.hpp:77] Creating layer Scale34
I0928 09:32:12.949939  4247 net.cpp:84] Creating Layer Scale34
I0928 09:32:12.949941  4247 net.cpp:406] Scale34 <- Convolution34
I0928 09:32:12.949944  4247 net.cpp:367] Scale34 -> Convolution34 (in-place)
I0928 09:32:12.949972  4247 layer_factory.hpp:77] Creating layer Scale34
I0928 09:32:12.950057  4247 net.cpp:122] Setting up Scale34
I0928 09:32:12.950068  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.950070  4247 net.cpp:137] Memory required for data: 938394800
I0928 09:32:12.950074  4247 layer_factory.hpp:77] Creating layer Eltwise16
I0928 09:32:12.950080  4247 net.cpp:84] Creating Layer Eltwise16
I0928 09:32:12.950083  4247 net.cpp:406] Eltwise16 <- Eltwise15_M2PELU31_0_split_1
I0928 09:32:12.950086  4247 net.cpp:406] Eltwise16 <- Convolution34
I0928 09:32:12.950090  4247 net.cpp:380] Eltwise16 -> Eltwise16
I0928 09:32:12.950103  4247 net.cpp:122] Setting up Eltwise16
I0928 09:32:12.950106  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.950109  4247 net.cpp:137] Memory required for data: 941671600
I0928 09:32:12.950110  4247 layer_factory.hpp:77] Creating layer M2PELU33
I0928 09:32:12.950116  4247 net.cpp:84] Creating Layer M2PELU33
I0928 09:32:12.950119  4247 net.cpp:406] M2PELU33 <- Eltwise16
I0928 09:32:12.950122  4247 net.cpp:367] M2PELU33 -> Eltwise16 (in-place)
I0928 09:32:12.950207  4247 net.cpp:122] Setting up M2PELU33
I0928 09:32:12.950212  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.950213  4247 net.cpp:137] Memory required for data: 944948400
I0928 09:32:12.950217  4247 layer_factory.hpp:77] Creating layer Eltwise16_M2PELU33_0_split
I0928 09:32:12.950222  4247 net.cpp:84] Creating Layer Eltwise16_M2PELU33_0_split
I0928 09:32:12.950224  4247 net.cpp:406] Eltwise16_M2PELU33_0_split <- Eltwise16
I0928 09:32:12.950227  4247 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_0
I0928 09:32:12.950232  4247 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_1
I0928 09:32:12.950255  4247 net.cpp:122] Setting up Eltwise16_M2PELU33_0_split
I0928 09:32:12.950260  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.950263  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.950265  4247 net.cpp:137] Memory required for data: 951502000
I0928 09:32:12.950268  4247 layer_factory.hpp:77] Creating layer Convolution35
I0928 09:32:12.950273  4247 net.cpp:84] Creating Layer Convolution35
I0928 09:32:12.950276  4247 net.cpp:406] Convolution35 <- Eltwise16_M2PELU33_0_split_0
I0928 09:32:12.950280  4247 net.cpp:380] Convolution35 -> Convolution35
I0928 09:32:12.951385  4247 net.cpp:122] Setting up Convolution35
I0928 09:32:12.951395  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.951396  4247 net.cpp:137] Memory required for data: 954778800
I0928 09:32:12.951401  4247 layer_factory.hpp:77] Creating layer BatchNorm35
I0928 09:32:12.951406  4247 net.cpp:84] Creating Layer BatchNorm35
I0928 09:32:12.951408  4247 net.cpp:406] BatchNorm35 <- Convolution35
I0928 09:32:12.951412  4247 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I0928 09:32:12.951545  4247 net.cpp:122] Setting up BatchNorm35
I0928 09:32:12.951550  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.951551  4247 net.cpp:137] Memory required for data: 958055600
I0928 09:32:12.951556  4247 layer_factory.hpp:77] Creating layer Scale35
I0928 09:32:12.951560  4247 net.cpp:84] Creating Layer Scale35
I0928 09:32:12.951563  4247 net.cpp:406] Scale35 <- Convolution35
I0928 09:32:12.951566  4247 net.cpp:367] Scale35 -> Convolution35 (in-place)
I0928 09:32:12.951593  4247 layer_factory.hpp:77] Creating layer Scale35
I0928 09:32:12.951668  4247 net.cpp:122] Setting up Scale35
I0928 09:32:12.951671  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.951674  4247 net.cpp:137] Memory required for data: 961332400
I0928 09:32:12.951678  4247 layer_factory.hpp:77] Creating layer M2PELU34
I0928 09:32:12.951683  4247 net.cpp:84] Creating Layer M2PELU34
I0928 09:32:12.951685  4247 net.cpp:406] M2PELU34 <- Convolution35
I0928 09:32:12.951689  4247 net.cpp:367] M2PELU34 -> Convolution35 (in-place)
I0928 09:32:12.951769  4247 net.cpp:122] Setting up M2PELU34
I0928 09:32:12.951774  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.951776  4247 net.cpp:137] Memory required for data: 964609200
I0928 09:32:12.951786  4247 layer_factory.hpp:77] Creating layer Convolution36
I0928 09:32:12.951794  4247 net.cpp:84] Creating Layer Convolution36
I0928 09:32:12.951797  4247 net.cpp:406] Convolution36 <- Convolution35
I0928 09:32:12.951802  4247 net.cpp:380] Convolution36 -> Convolution36
I0928 09:32:12.952564  4247 net.cpp:122] Setting up Convolution36
I0928 09:32:12.952570  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.952574  4247 net.cpp:137] Memory required for data: 967886000
I0928 09:32:12.952577  4247 layer_factory.hpp:77] Creating layer BatchNorm36
I0928 09:32:12.952584  4247 net.cpp:84] Creating Layer BatchNorm36
I0928 09:32:12.952585  4247 net.cpp:406] BatchNorm36 <- Convolution36
I0928 09:32:12.952589  4247 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I0928 09:32:12.952719  4247 net.cpp:122] Setting up BatchNorm36
I0928 09:32:12.952723  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.952725  4247 net.cpp:137] Memory required for data: 971162800
I0928 09:32:12.952730  4247 layer_factory.hpp:77] Creating layer Scale36
I0928 09:32:12.952735  4247 net.cpp:84] Creating Layer Scale36
I0928 09:32:12.952738  4247 net.cpp:406] Scale36 <- Convolution36
I0928 09:32:12.952741  4247 net.cpp:367] Scale36 -> Convolution36 (in-place)
I0928 09:32:12.952767  4247 layer_factory.hpp:77] Creating layer Scale36
I0928 09:32:12.952842  4247 net.cpp:122] Setting up Scale36
I0928 09:32:12.952847  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.952849  4247 net.cpp:137] Memory required for data: 974439600
I0928 09:32:12.952853  4247 layer_factory.hpp:77] Creating layer Eltwise17
I0928 09:32:12.952857  4247 net.cpp:84] Creating Layer Eltwise17
I0928 09:32:12.952859  4247 net.cpp:406] Eltwise17 <- Eltwise16_M2PELU33_0_split_1
I0928 09:32:12.952862  4247 net.cpp:406] Eltwise17 <- Convolution36
I0928 09:32:12.952867  4247 net.cpp:380] Eltwise17 -> Eltwise17
I0928 09:32:12.952877  4247 net.cpp:122] Setting up Eltwise17
I0928 09:32:12.952883  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.952884  4247 net.cpp:137] Memory required for data: 977716400
I0928 09:32:12.952886  4247 layer_factory.hpp:77] Creating layer M2PELU35
I0928 09:32:12.952890  4247 net.cpp:84] Creating Layer M2PELU35
I0928 09:32:12.952893  4247 net.cpp:406] M2PELU35 <- Eltwise17
I0928 09:32:12.952898  4247 net.cpp:367] M2PELU35 -> Eltwise17 (in-place)
I0928 09:32:12.952985  4247 net.cpp:122] Setting up M2PELU35
I0928 09:32:12.952988  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.952991  4247 net.cpp:137] Memory required for data: 980993200
I0928 09:32:12.952994  4247 layer_factory.hpp:77] Creating layer Eltwise17_M2PELU35_0_split
I0928 09:32:12.952997  4247 net.cpp:84] Creating Layer Eltwise17_M2PELU35_0_split
I0928 09:32:12.952999  4247 net.cpp:406] Eltwise17_M2PELU35_0_split <- Eltwise17
I0928 09:32:12.953003  4247 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_0
I0928 09:32:12.953008  4247 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_1
I0928 09:32:12.953032  4247 net.cpp:122] Setting up Eltwise17_M2PELU35_0_split
I0928 09:32:12.953035  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.953038  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.953040  4247 net.cpp:137] Memory required for data: 987546800
I0928 09:32:12.953042  4247 layer_factory.hpp:77] Creating layer Convolution37
I0928 09:32:12.953048  4247 net.cpp:84] Creating Layer Convolution37
I0928 09:32:12.953052  4247 net.cpp:406] Convolution37 <- Eltwise17_M2PELU35_0_split_0
I0928 09:32:12.953055  4247 net.cpp:380] Convolution37 -> Convolution37
I0928 09:32:12.954150  4247 net.cpp:122] Setting up Convolution37
I0928 09:32:12.954159  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.954161  4247 net.cpp:137] Memory required for data: 990823600
I0928 09:32:12.954166  4247 layer_factory.hpp:77] Creating layer BatchNorm37
I0928 09:32:12.954171  4247 net.cpp:84] Creating Layer BatchNorm37
I0928 09:32:12.954174  4247 net.cpp:406] BatchNorm37 <- Convolution37
I0928 09:32:12.954185  4247 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I0928 09:32:12.954318  4247 net.cpp:122] Setting up BatchNorm37
I0928 09:32:12.954321  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.954324  4247 net.cpp:137] Memory required for data: 994100400
I0928 09:32:12.954329  4247 layer_factory.hpp:77] Creating layer Scale37
I0928 09:32:12.954334  4247 net.cpp:84] Creating Layer Scale37
I0928 09:32:12.954335  4247 net.cpp:406] Scale37 <- Convolution37
I0928 09:32:12.954339  4247 net.cpp:367] Scale37 -> Convolution37 (in-place)
I0928 09:32:12.954365  4247 layer_factory.hpp:77] Creating layer Scale37
I0928 09:32:12.954442  4247 net.cpp:122] Setting up Scale37
I0928 09:32:12.954447  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.954448  4247 net.cpp:137] Memory required for data: 997377200
I0928 09:32:12.954452  4247 layer_factory.hpp:77] Creating layer M2PELU36
I0928 09:32:12.954457  4247 net.cpp:84] Creating Layer M2PELU36
I0928 09:32:12.954460  4247 net.cpp:406] M2PELU36 <- Convolution37
I0928 09:32:12.954463  4247 net.cpp:367] M2PELU36 -> Convolution37 (in-place)
I0928 09:32:12.954550  4247 net.cpp:122] Setting up M2PELU36
I0928 09:32:12.954555  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.954556  4247 net.cpp:137] Memory required for data: 1000654000
I0928 09:32:12.954560  4247 layer_factory.hpp:77] Creating layer Convolution38
I0928 09:32:12.954567  4247 net.cpp:84] Creating Layer Convolution38
I0928 09:32:12.954569  4247 net.cpp:406] Convolution38 <- Convolution37
I0928 09:32:12.954573  4247 net.cpp:380] Convolution38 -> Convolution38
I0928 09:32:12.956013  4247 net.cpp:122] Setting up Convolution38
I0928 09:32:12.956022  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.956024  4247 net.cpp:137] Memory required for data: 1003930800
I0928 09:32:12.956029  4247 layer_factory.hpp:77] Creating layer BatchNorm38
I0928 09:32:12.956033  4247 net.cpp:84] Creating Layer BatchNorm38
I0928 09:32:12.956037  4247 net.cpp:406] BatchNorm38 <- Convolution38
I0928 09:32:12.976379  4247 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I0928 09:32:12.976543  4247 net.cpp:122] Setting up BatchNorm38
I0928 09:32:12.976549  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.976552  4247 net.cpp:137] Memory required for data: 1007207600
I0928 09:32:12.976557  4247 layer_factory.hpp:77] Creating layer Scale38
I0928 09:32:12.976562  4247 net.cpp:84] Creating Layer Scale38
I0928 09:32:12.976565  4247 net.cpp:406] Scale38 <- Convolution38
I0928 09:32:12.976568  4247 net.cpp:367] Scale38 -> Convolution38 (in-place)
I0928 09:32:12.976599  4247 layer_factory.hpp:77] Creating layer Scale38
I0928 09:32:12.976685  4247 net.cpp:122] Setting up Scale38
I0928 09:32:12.976688  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.976691  4247 net.cpp:137] Memory required for data: 1010484400
I0928 09:32:12.976696  4247 layer_factory.hpp:77] Creating layer Eltwise18
I0928 09:32:12.976701  4247 net.cpp:84] Creating Layer Eltwise18
I0928 09:32:12.976703  4247 net.cpp:406] Eltwise18 <- Eltwise17_M2PELU35_0_split_1
I0928 09:32:12.976706  4247 net.cpp:406] Eltwise18 <- Convolution38
I0928 09:32:12.976709  4247 net.cpp:380] Eltwise18 -> Eltwise18
I0928 09:32:12.976722  4247 net.cpp:122] Setting up Eltwise18
I0928 09:32:12.976727  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.976729  4247 net.cpp:137] Memory required for data: 1013761200
I0928 09:32:12.976732  4247 layer_factory.hpp:77] Creating layer M2PELU37
I0928 09:32:12.976737  4247 net.cpp:84] Creating Layer M2PELU37
I0928 09:32:12.976739  4247 net.cpp:406] M2PELU37 <- Eltwise18
I0928 09:32:12.976743  4247 net.cpp:367] M2PELU37 -> Eltwise18 (in-place)
I0928 09:32:12.976838  4247 net.cpp:122] Setting up M2PELU37
I0928 09:32:12.976843  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.976845  4247 net.cpp:137] Memory required for data: 1017038000
I0928 09:32:12.976850  4247 layer_factory.hpp:77] Creating layer Eltwise18_M2PELU37_0_split
I0928 09:32:12.976861  4247 net.cpp:84] Creating Layer Eltwise18_M2PELU37_0_split
I0928 09:32:12.976864  4247 net.cpp:406] Eltwise18_M2PELU37_0_split <- Eltwise18
I0928 09:32:12.976868  4247 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_0
I0928 09:32:12.976873  4247 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_1
I0928 09:32:12.976900  4247 net.cpp:122] Setting up Eltwise18_M2PELU37_0_split
I0928 09:32:12.976905  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.976908  4247 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 09:32:12.976910  4247 net.cpp:137] Memory required for data: 1023591600
I0928 09:32:12.976912  4247 layer_factory.hpp:77] Creating layer Convolution39
I0928 09:32:12.976920  4247 net.cpp:84] Creating Layer Convolution39
I0928 09:32:12.976922  4247 net.cpp:406] Convolution39 <- Eltwise18_M2PELU37_0_split_0
I0928 09:32:12.976927  4247 net.cpp:380] Convolution39 -> Convolution39
I0928 09:32:12.978173  4247 net.cpp:122] Setting up Convolution39
I0928 09:32:12.978194  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:12.978199  4247 net.cpp:137] Memory required for data: 1025230000
I0928 09:32:12.978204  4247 layer_factory.hpp:77] Creating layer BatchNorm39
I0928 09:32:12.978219  4247 net.cpp:84] Creating Layer BatchNorm39
I0928 09:32:12.978222  4247 net.cpp:406] BatchNorm39 <- Convolution39
I0928 09:32:12.978226  4247 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I0928 09:32:12.978363  4247 net.cpp:122] Setting up BatchNorm39
I0928 09:32:12.978368  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:12.978370  4247 net.cpp:137] Memory required for data: 1026868400
I0928 09:32:12.978374  4247 layer_factory.hpp:77] Creating layer Scale39
I0928 09:32:12.978379  4247 net.cpp:84] Creating Layer Scale39
I0928 09:32:12.978382  4247 net.cpp:406] Scale39 <- Convolution39
I0928 09:32:12.978385  4247 net.cpp:367] Scale39 -> Convolution39 (in-place)
I0928 09:32:12.978412  4247 layer_factory.hpp:77] Creating layer Scale39
I0928 09:32:12.978489  4247 net.cpp:122] Setting up Scale39
I0928 09:32:12.978493  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:12.978495  4247 net.cpp:137] Memory required for data: 1028506800
I0928 09:32:12.978499  4247 layer_factory.hpp:77] Creating layer Convolution40
I0928 09:32:12.978508  4247 net.cpp:84] Creating Layer Convolution40
I0928 09:32:12.978510  4247 net.cpp:406] Convolution40 <- Eltwise18_M2PELU37_0_split_1
I0928 09:32:12.978515  4247 net.cpp:380] Convolution40 -> Convolution40
I0928 09:32:12.979982  4247 net.cpp:122] Setting up Convolution40
I0928 09:32:12.979991  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:12.979995  4247 net.cpp:137] Memory required for data: 1030145200
I0928 09:32:12.979998  4247 layer_factory.hpp:77] Creating layer BatchNorm40
I0928 09:32:12.980005  4247 net.cpp:84] Creating Layer BatchNorm40
I0928 09:32:12.980008  4247 net.cpp:406] BatchNorm40 <- Convolution40
I0928 09:32:12.980012  4247 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I0928 09:32:12.980159  4247 net.cpp:122] Setting up BatchNorm40
I0928 09:32:12.980162  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:12.980165  4247 net.cpp:137] Memory required for data: 1031783600
I0928 09:32:12.980170  4247 layer_factory.hpp:77] Creating layer Scale40
I0928 09:32:12.980175  4247 net.cpp:84] Creating Layer Scale40
I0928 09:32:12.980176  4247 net.cpp:406] Scale40 <- Convolution40
I0928 09:32:12.980180  4247 net.cpp:367] Scale40 -> Convolution40 (in-place)
I0928 09:32:12.980217  4247 layer_factory.hpp:77] Creating layer Scale40
I0928 09:32:12.980305  4247 net.cpp:122] Setting up Scale40
I0928 09:32:12.980309  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:12.980311  4247 net.cpp:137] Memory required for data: 1033422000
I0928 09:32:12.980315  4247 layer_factory.hpp:77] Creating layer M2PELU38
I0928 09:32:12.980320  4247 net.cpp:84] Creating Layer M2PELU38
I0928 09:32:12.980324  4247 net.cpp:406] M2PELU38 <- Convolution40
I0928 09:32:12.980335  4247 net.cpp:367] M2PELU38 -> Convolution40 (in-place)
I0928 09:32:12.980428  4247 net.cpp:122] Setting up M2PELU38
I0928 09:32:12.980433  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:12.980435  4247 net.cpp:137] Memory required for data: 1035060400
I0928 09:32:12.980439  4247 layer_factory.hpp:77] Creating layer Convolution41
I0928 09:32:12.980445  4247 net.cpp:84] Creating Layer Convolution41
I0928 09:32:12.980448  4247 net.cpp:406] Convolution41 <- Convolution40
I0928 09:32:12.980453  4247 net.cpp:380] Convolution41 -> Convolution41
I0928 09:32:12.982208  4247 net.cpp:122] Setting up Convolution41
I0928 09:32:12.982216  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:12.982219  4247 net.cpp:137] Memory required for data: 1036698800
I0928 09:32:12.982223  4247 layer_factory.hpp:77] Creating layer BatchNorm41
I0928 09:32:12.982229  4247 net.cpp:84] Creating Layer BatchNorm41
I0928 09:32:12.982233  4247 net.cpp:406] BatchNorm41 <- Convolution41
I0928 09:32:12.982236  4247 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I0928 09:32:12.982373  4247 net.cpp:122] Setting up BatchNorm41
I0928 09:32:12.982378  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:12.982380  4247 net.cpp:137] Memory required for data: 1038337200
I0928 09:32:12.982384  4247 layer_factory.hpp:77] Creating layer Scale41
I0928 09:32:12.982388  4247 net.cpp:84] Creating Layer Scale41
I0928 09:32:12.982390  4247 net.cpp:406] Scale41 <- Convolution41
I0928 09:32:12.982394  4247 net.cpp:367] Scale41 -> Convolution41 (in-place)
I0928 09:32:12.982421  4247 layer_factory.hpp:77] Creating layer Scale41
I0928 09:32:12.982501  4247 net.cpp:122] Setting up Scale41
I0928 09:32:12.982504  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:12.982506  4247 net.cpp:137] Memory required for data: 1039975600
I0928 09:32:12.982511  4247 layer_factory.hpp:77] Creating layer Eltwise19
I0928 09:32:12.982514  4247 net.cpp:84] Creating Layer Eltwise19
I0928 09:32:12.982517  4247 net.cpp:406] Eltwise19 <- Convolution39
I0928 09:32:12.982519  4247 net.cpp:406] Eltwise19 <- Convolution41
I0928 09:32:12.982527  4247 net.cpp:380] Eltwise19 -> Eltwise19
I0928 09:32:12.982555  4247 net.cpp:122] Setting up Eltwise19
I0928 09:32:12.982559  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:12.982561  4247 net.cpp:137] Memory required for data: 1041614000
I0928 09:32:12.982563  4247 layer_factory.hpp:77] Creating layer M2PELU39
I0928 09:32:12.982568  4247 net.cpp:84] Creating Layer M2PELU39
I0928 09:32:12.982570  4247 net.cpp:406] M2PELU39 <- Eltwise19
I0928 09:32:12.982573  4247 net.cpp:367] M2PELU39 -> Eltwise19 (in-place)
I0928 09:32:12.982661  4247 net.cpp:122] Setting up M2PELU39
I0928 09:32:12.982666  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:12.982668  4247 net.cpp:137] Memory required for data: 1043252400
I0928 09:32:12.982671  4247 layer_factory.hpp:77] Creating layer Eltwise19_M2PELU39_0_split
I0928 09:32:12.982676  4247 net.cpp:84] Creating Layer Eltwise19_M2PELU39_0_split
I0928 09:32:12.982677  4247 net.cpp:406] Eltwise19_M2PELU39_0_split <- Eltwise19
I0928 09:32:12.982681  4247 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_0
I0928 09:32:12.982686  4247 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_1
I0928 09:32:12.982709  4247 net.cpp:122] Setting up Eltwise19_M2PELU39_0_split
I0928 09:32:12.982712  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:12.982715  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:12.982717  4247 net.cpp:137] Memory required for data: 1046529200
I0928 09:32:12.982719  4247 layer_factory.hpp:77] Creating layer Convolution42
I0928 09:32:12.982725  4247 net.cpp:84] Creating Layer Convolution42
I0928 09:32:12.982728  4247 net.cpp:406] Convolution42 <- Eltwise19_M2PELU39_0_split_0
I0928 09:32:12.982731  4247 net.cpp:380] Convolution42 -> Convolution42
I0928 09:32:12.984416  4247 net.cpp:122] Setting up Convolution42
I0928 09:32:12.984426  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:12.984433  4247 net.cpp:137] Memory required for data: 1048167600
I0928 09:32:12.984438  4247 layer_factory.hpp:77] Creating layer BatchNorm42
I0928 09:32:12.984443  4247 net.cpp:84] Creating Layer BatchNorm42
I0928 09:32:12.984447  4247 net.cpp:406] BatchNorm42 <- Convolution42
I0928 09:32:12.984452  4247 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I0928 09:32:12.984583  4247 net.cpp:122] Setting up BatchNorm42
I0928 09:32:12.984588  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:12.984591  4247 net.cpp:137] Memory required for data: 1049806000
I0928 09:32:12.984594  4247 layer_factory.hpp:77] Creating layer Scale42
I0928 09:32:12.984601  4247 net.cpp:84] Creating Layer Scale42
I0928 09:32:12.984603  4247 net.cpp:406] Scale42 <- Convolution42
I0928 09:32:12.984606  4247 net.cpp:367] Scale42 -> Convolution42 (in-place)
I0928 09:32:12.984632  4247 layer_factory.hpp:77] Creating layer Scale42
I0928 09:32:12.984709  4247 net.cpp:122] Setting up Scale42
I0928 09:32:12.984712  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:12.984714  4247 net.cpp:137] Memory required for data: 1051444400
I0928 09:32:12.984719  4247 layer_factory.hpp:77] Creating layer M2PELU40
I0928 09:32:12.984724  4247 net.cpp:84] Creating Layer M2PELU40
I0928 09:32:12.984725  4247 net.cpp:406] M2PELU40 <- Convolution42
I0928 09:32:12.984730  4247 net.cpp:367] M2PELU40 -> Convolution42 (in-place)
I0928 09:32:12.984815  4247 net.cpp:122] Setting up M2PELU40
I0928 09:32:12.984819  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:12.984822  4247 net.cpp:137] Memory required for data: 1053082800
I0928 09:32:12.984825  4247 layer_factory.hpp:77] Creating layer Convolution43
I0928 09:32:12.984832  4247 net.cpp:84] Creating Layer Convolution43
I0928 09:32:12.984833  4247 net.cpp:406] Convolution43 <- Convolution42
I0928 09:32:12.984838  4247 net.cpp:380] Convolution43 -> Convolution43
I0928 09:32:12.986515  4247 net.cpp:122] Setting up Convolution43
I0928 09:32:12.986538  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:12.986541  4247 net.cpp:137] Memory required for data: 1054721200
I0928 09:32:12.986546  4247 layer_factory.hpp:77] Creating layer BatchNorm43
I0928 09:32:12.986563  4247 net.cpp:84] Creating Layer BatchNorm43
I0928 09:32:12.986567  4247 net.cpp:406] BatchNorm43 <- Convolution43
I0928 09:32:12.986569  4247 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I0928 09:32:12.986707  4247 net.cpp:122] Setting up BatchNorm43
I0928 09:32:12.986711  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:12.986713  4247 net.cpp:137] Memory required for data: 1056359600
I0928 09:32:12.986718  4247 layer_factory.hpp:77] Creating layer Scale43
I0928 09:32:12.986722  4247 net.cpp:84] Creating Layer Scale43
I0928 09:32:12.986724  4247 net.cpp:406] Scale43 <- Convolution43
I0928 09:32:12.986727  4247 net.cpp:367] Scale43 -> Convolution43 (in-place)
I0928 09:32:12.986755  4247 layer_factory.hpp:77] Creating layer Scale43
I0928 09:32:12.986831  4247 net.cpp:122] Setting up Scale43
I0928 09:32:12.986835  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:12.986837  4247 net.cpp:137] Memory required for data: 1057998000
I0928 09:32:12.986841  4247 layer_factory.hpp:77] Creating layer Eltwise20
I0928 09:32:12.986845  4247 net.cpp:84] Creating Layer Eltwise20
I0928 09:32:12.986848  4247 net.cpp:406] Eltwise20 <- Eltwise19_M2PELU39_0_split_1
I0928 09:32:12.986850  4247 net.cpp:406] Eltwise20 <- Convolution43
I0928 09:32:12.986855  4247 net.cpp:380] Eltwise20 -> Eltwise20
I0928 09:32:12.986871  4247 net.cpp:122] Setting up Eltwise20
I0928 09:32:12.986873  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:12.986876  4247 net.cpp:137] Memory required for data: 1059636400
I0928 09:32:12.986877  4247 layer_factory.hpp:77] Creating layer M2PELU41
I0928 09:32:12.986883  4247 net.cpp:84] Creating Layer M2PELU41
I0928 09:32:12.986886  4247 net.cpp:406] M2PELU41 <- Eltwise20
I0928 09:32:12.986888  4247 net.cpp:367] M2PELU41 -> Eltwise20 (in-place)
I0928 09:32:12.986977  4247 net.cpp:122] Setting up M2PELU41
I0928 09:32:12.986989  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:12.986990  4247 net.cpp:137] Memory required for data: 1061274800
I0928 09:32:12.986994  4247 layer_factory.hpp:77] Creating layer Eltwise20_M2PELU41_0_split
I0928 09:32:12.986999  4247 net.cpp:84] Creating Layer Eltwise20_M2PELU41_0_split
I0928 09:32:12.987000  4247 net.cpp:406] Eltwise20_M2PELU41_0_split <- Eltwise20
I0928 09:32:12.987004  4247 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_0
I0928 09:32:12.987010  4247 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_1
I0928 09:32:12.987035  4247 net.cpp:122] Setting up Eltwise20_M2PELU41_0_split
I0928 09:32:12.987037  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:12.987040  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:12.987042  4247 net.cpp:137] Memory required for data: 1064551600
I0928 09:32:12.987045  4247 layer_factory.hpp:77] Creating layer Convolution44
I0928 09:32:12.987051  4247 net.cpp:84] Creating Layer Convolution44
I0928 09:32:12.987052  4247 net.cpp:406] Convolution44 <- Eltwise20_M2PELU41_0_split_0
I0928 09:32:12.987056  4247 net.cpp:380] Convolution44 -> Convolution44
I0928 09:32:12.989042  4247 net.cpp:122] Setting up Convolution44
I0928 09:32:12.989049  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:12.989053  4247 net.cpp:137] Memory required for data: 1066190000
I0928 09:32:12.989056  4247 layer_factory.hpp:77] Creating layer BatchNorm44
I0928 09:32:12.989061  4247 net.cpp:84] Creating Layer BatchNorm44
I0928 09:32:12.989064  4247 net.cpp:406] BatchNorm44 <- Convolution44
I0928 09:32:12.989068  4247 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I0928 09:32:12.989207  4247 net.cpp:122] Setting up BatchNorm44
I0928 09:32:12.989212  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:12.989213  4247 net.cpp:137] Memory required for data: 1067828400
I0928 09:32:13.009703  4247 layer_factory.hpp:77] Creating layer Scale44
I0928 09:32:13.009713  4247 net.cpp:84] Creating Layer Scale44
I0928 09:32:13.009716  4247 net.cpp:406] Scale44 <- Convolution44
I0928 09:32:13.009723  4247 net.cpp:367] Scale44 -> Convolution44 (in-place)
I0928 09:32:13.009765  4247 layer_factory.hpp:77] Creating layer Scale44
I0928 09:32:13.009857  4247 net.cpp:122] Setting up Scale44
I0928 09:32:13.009862  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.009865  4247 net.cpp:137] Memory required for data: 1069466800
I0928 09:32:13.009869  4247 layer_factory.hpp:77] Creating layer M2PELU42
I0928 09:32:13.009876  4247 net.cpp:84] Creating Layer M2PELU42
I0928 09:32:13.009878  4247 net.cpp:406] M2PELU42 <- Convolution44
I0928 09:32:13.009881  4247 net.cpp:367] M2PELU42 -> Convolution44 (in-place)
I0928 09:32:13.009984  4247 net.cpp:122] Setting up M2PELU42
I0928 09:32:13.009989  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.009991  4247 net.cpp:137] Memory required for data: 1071105200
I0928 09:32:13.009995  4247 layer_factory.hpp:77] Creating layer Convolution45
I0928 09:32:13.010004  4247 net.cpp:84] Creating Layer Convolution45
I0928 09:32:13.010006  4247 net.cpp:406] Convolution45 <- Convolution44
I0928 09:32:13.010010  4247 net.cpp:380] Convolution45 -> Convolution45
I0928 09:32:13.011886  4247 net.cpp:122] Setting up Convolution45
I0928 09:32:13.011895  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.011898  4247 net.cpp:137] Memory required for data: 1072743600
I0928 09:32:13.011903  4247 layer_factory.hpp:77] Creating layer BatchNorm45
I0928 09:32:13.011907  4247 net.cpp:84] Creating Layer BatchNorm45
I0928 09:32:13.011910  4247 net.cpp:406] BatchNorm45 <- Convolution45
I0928 09:32:13.011914  4247 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I0928 09:32:13.012049  4247 net.cpp:122] Setting up BatchNorm45
I0928 09:32:13.012053  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.012055  4247 net.cpp:137] Memory required for data: 1074382000
I0928 09:32:13.012060  4247 layer_factory.hpp:77] Creating layer Scale45
I0928 09:32:13.012073  4247 net.cpp:84] Creating Layer Scale45
I0928 09:32:13.012076  4247 net.cpp:406] Scale45 <- Convolution45
I0928 09:32:13.012079  4247 net.cpp:367] Scale45 -> Convolution45 (in-place)
I0928 09:32:13.012107  4247 layer_factory.hpp:77] Creating layer Scale45
I0928 09:32:13.012187  4247 net.cpp:122] Setting up Scale45
I0928 09:32:13.012190  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.012192  4247 net.cpp:137] Memory required for data: 1076020400
I0928 09:32:13.012197  4247 layer_factory.hpp:77] Creating layer Eltwise21
I0928 09:32:13.012200  4247 net.cpp:84] Creating Layer Eltwise21
I0928 09:32:13.012203  4247 net.cpp:406] Eltwise21 <- Eltwise20_M2PELU41_0_split_1
I0928 09:32:13.012207  4247 net.cpp:406] Eltwise21 <- Convolution45
I0928 09:32:13.012210  4247 net.cpp:380] Eltwise21 -> Eltwise21
I0928 09:32:13.012226  4247 net.cpp:122] Setting up Eltwise21
I0928 09:32:13.012230  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.012233  4247 net.cpp:137] Memory required for data: 1077658800
I0928 09:32:13.012234  4247 layer_factory.hpp:77] Creating layer M2PELU43
I0928 09:32:13.012239  4247 net.cpp:84] Creating Layer M2PELU43
I0928 09:32:13.012241  4247 net.cpp:406] M2PELU43 <- Eltwise21
I0928 09:32:13.012244  4247 net.cpp:367] M2PELU43 -> Eltwise21 (in-place)
I0928 09:32:13.012333  4247 net.cpp:122] Setting up M2PELU43
I0928 09:32:13.012338  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.012341  4247 net.cpp:137] Memory required for data: 1079297200
I0928 09:32:13.012343  4247 layer_factory.hpp:77] Creating layer Eltwise21_M2PELU43_0_split
I0928 09:32:13.012347  4247 net.cpp:84] Creating Layer Eltwise21_M2PELU43_0_split
I0928 09:32:13.012349  4247 net.cpp:406] Eltwise21_M2PELU43_0_split <- Eltwise21
I0928 09:32:13.012353  4247 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_0
I0928 09:32:13.012357  4247 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_1
I0928 09:32:13.012382  4247 net.cpp:122] Setting up Eltwise21_M2PELU43_0_split
I0928 09:32:13.012384  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.012387  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.012389  4247 net.cpp:137] Memory required for data: 1082574000
I0928 09:32:13.012392  4247 layer_factory.hpp:77] Creating layer Convolution46
I0928 09:32:13.012398  4247 net.cpp:84] Creating Layer Convolution46
I0928 09:32:13.012399  4247 net.cpp:406] Convolution46 <- Eltwise21_M2PELU43_0_split_0
I0928 09:32:13.012403  4247 net.cpp:380] Convolution46 -> Convolution46
I0928 09:32:13.014072  4247 net.cpp:122] Setting up Convolution46
I0928 09:32:13.014081  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.014083  4247 net.cpp:137] Memory required for data: 1084212400
I0928 09:32:13.014087  4247 layer_factory.hpp:77] Creating layer BatchNorm46
I0928 09:32:13.014092  4247 net.cpp:84] Creating Layer BatchNorm46
I0928 09:32:13.014096  4247 net.cpp:406] BatchNorm46 <- Convolution46
I0928 09:32:13.014099  4247 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I0928 09:32:13.014238  4247 net.cpp:122] Setting up BatchNorm46
I0928 09:32:13.014243  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.014245  4247 net.cpp:137] Memory required for data: 1085850800
I0928 09:32:13.014250  4247 layer_factory.hpp:77] Creating layer Scale46
I0928 09:32:13.014253  4247 net.cpp:84] Creating Layer Scale46
I0928 09:32:13.014256  4247 net.cpp:406] Scale46 <- Convolution46
I0928 09:32:13.014259  4247 net.cpp:367] Scale46 -> Convolution46 (in-place)
I0928 09:32:13.014287  4247 layer_factory.hpp:77] Creating layer Scale46
I0928 09:32:13.014364  4247 net.cpp:122] Setting up Scale46
I0928 09:32:13.014369  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.014371  4247 net.cpp:137] Memory required for data: 1087489200
I0928 09:32:13.014375  4247 layer_factory.hpp:77] Creating layer M2PELU44
I0928 09:32:13.014380  4247 net.cpp:84] Creating Layer M2PELU44
I0928 09:32:13.014382  4247 net.cpp:406] M2PELU44 <- Convolution46
I0928 09:32:13.014392  4247 net.cpp:367] M2PELU44 -> Convolution46 (in-place)
I0928 09:32:13.014482  4247 net.cpp:122] Setting up M2PELU44
I0928 09:32:13.014485  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.014487  4247 net.cpp:137] Memory required for data: 1089127600
I0928 09:32:13.014492  4247 layer_factory.hpp:77] Creating layer Convolution47
I0928 09:32:13.014497  4247 net.cpp:84] Creating Layer Convolution47
I0928 09:32:13.014500  4247 net.cpp:406] Convolution47 <- Convolution46
I0928 09:32:13.014504  4247 net.cpp:380] Convolution47 -> Convolution47
I0928 09:32:13.016191  4247 net.cpp:122] Setting up Convolution47
I0928 09:32:13.016199  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.016202  4247 net.cpp:137] Memory required for data: 1090766000
I0928 09:32:13.016206  4247 layer_factory.hpp:77] Creating layer BatchNorm47
I0928 09:32:13.016211  4247 net.cpp:84] Creating Layer BatchNorm47
I0928 09:32:13.016214  4247 net.cpp:406] BatchNorm47 <- Convolution47
I0928 09:32:13.016218  4247 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I0928 09:32:13.016351  4247 net.cpp:122] Setting up BatchNorm47
I0928 09:32:13.016356  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.016358  4247 net.cpp:137] Memory required for data: 1092404400
I0928 09:32:13.016362  4247 layer_factory.hpp:77] Creating layer Scale47
I0928 09:32:13.016366  4247 net.cpp:84] Creating Layer Scale47
I0928 09:32:13.016368  4247 net.cpp:406] Scale47 <- Convolution47
I0928 09:32:13.016371  4247 net.cpp:367] Scale47 -> Convolution47 (in-place)
I0928 09:32:13.016399  4247 layer_factory.hpp:77] Creating layer Scale47
I0928 09:32:13.016476  4247 net.cpp:122] Setting up Scale47
I0928 09:32:13.016480  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.016482  4247 net.cpp:137] Memory required for data: 1094042800
I0928 09:32:13.016486  4247 layer_factory.hpp:77] Creating layer Eltwise22
I0928 09:32:13.016490  4247 net.cpp:84] Creating Layer Eltwise22
I0928 09:32:13.016494  4247 net.cpp:406] Eltwise22 <- Eltwise21_M2PELU43_0_split_1
I0928 09:32:13.016496  4247 net.cpp:406] Eltwise22 <- Convolution47
I0928 09:32:13.016499  4247 net.cpp:380] Eltwise22 -> Eltwise22
I0928 09:32:13.016515  4247 net.cpp:122] Setting up Eltwise22
I0928 09:32:13.016520  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.016521  4247 net.cpp:137] Memory required for data: 1095681200
I0928 09:32:13.016523  4247 layer_factory.hpp:77] Creating layer M2PELU45
I0928 09:32:13.016528  4247 net.cpp:84] Creating Layer M2PELU45
I0928 09:32:13.016530  4247 net.cpp:406] M2PELU45 <- Eltwise22
I0928 09:32:13.016533  4247 net.cpp:367] M2PELU45 -> Eltwise22 (in-place)
I0928 09:32:13.016623  4247 net.cpp:122] Setting up M2PELU45
I0928 09:32:13.016628  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.016629  4247 net.cpp:137] Memory required for data: 1097319600
I0928 09:32:13.016633  4247 layer_factory.hpp:77] Creating layer Eltwise22_M2PELU45_0_split
I0928 09:32:13.016636  4247 net.cpp:84] Creating Layer Eltwise22_M2PELU45_0_split
I0928 09:32:13.016639  4247 net.cpp:406] Eltwise22_M2PELU45_0_split <- Eltwise22
I0928 09:32:13.016643  4247 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_0
I0928 09:32:13.016646  4247 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_1
I0928 09:32:13.016670  4247 net.cpp:122] Setting up Eltwise22_M2PELU45_0_split
I0928 09:32:13.016674  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.016676  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.016679  4247 net.cpp:137] Memory required for data: 1100596400
I0928 09:32:13.016680  4247 layer_factory.hpp:77] Creating layer Convolution48
I0928 09:32:13.016686  4247 net.cpp:84] Creating Layer Convolution48
I0928 09:32:13.016690  4247 net.cpp:406] Convolution48 <- Eltwise22_M2PELU45_0_split_0
I0928 09:32:13.016693  4247 net.cpp:380] Convolution48 -> Convolution48
I0928 09:32:13.018690  4247 net.cpp:122] Setting up Convolution48
I0928 09:32:13.018699  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.018708  4247 net.cpp:137] Memory required for data: 1102234800
I0928 09:32:13.018713  4247 layer_factory.hpp:77] Creating layer BatchNorm48
I0928 09:32:13.018719  4247 net.cpp:84] Creating Layer BatchNorm48
I0928 09:32:13.018723  4247 net.cpp:406] BatchNorm48 <- Convolution48
I0928 09:32:13.018725  4247 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I0928 09:32:13.018865  4247 net.cpp:122] Setting up BatchNorm48
I0928 09:32:13.018869  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.018872  4247 net.cpp:137] Memory required for data: 1103873200
I0928 09:32:13.018877  4247 layer_factory.hpp:77] Creating layer Scale48
I0928 09:32:13.018880  4247 net.cpp:84] Creating Layer Scale48
I0928 09:32:13.018883  4247 net.cpp:406] Scale48 <- Convolution48
I0928 09:32:13.018887  4247 net.cpp:367] Scale48 -> Convolution48 (in-place)
I0928 09:32:13.018914  4247 layer_factory.hpp:77] Creating layer Scale48
I0928 09:32:13.018991  4247 net.cpp:122] Setting up Scale48
I0928 09:32:13.018996  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.018998  4247 net.cpp:137] Memory required for data: 1105511600
I0928 09:32:13.019002  4247 layer_factory.hpp:77] Creating layer M2PELU46
I0928 09:32:13.019007  4247 net.cpp:84] Creating Layer M2PELU46
I0928 09:32:13.019011  4247 net.cpp:406] M2PELU46 <- Convolution48
I0928 09:32:13.019013  4247 net.cpp:367] M2PELU46 -> Convolution48 (in-place)
I0928 09:32:13.019103  4247 net.cpp:122] Setting up M2PELU46
I0928 09:32:13.019106  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.019109  4247 net.cpp:137] Memory required for data: 1107150000
I0928 09:32:13.019112  4247 layer_factory.hpp:77] Creating layer Convolution49
I0928 09:32:13.019119  4247 net.cpp:84] Creating Layer Convolution49
I0928 09:32:13.019121  4247 net.cpp:406] Convolution49 <- Convolution48
I0928 09:32:13.019126  4247 net.cpp:380] Convolution49 -> Convolution49
I0928 09:32:13.021133  4247 net.cpp:122] Setting up Convolution49
I0928 09:32:13.021142  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.021144  4247 net.cpp:137] Memory required for data: 1108788400
I0928 09:32:13.021148  4247 layer_factory.hpp:77] Creating layer BatchNorm49
I0928 09:32:13.021153  4247 net.cpp:84] Creating Layer BatchNorm49
I0928 09:32:13.021157  4247 net.cpp:406] BatchNorm49 <- Convolution49
I0928 09:32:13.021160  4247 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I0928 09:32:13.021297  4247 net.cpp:122] Setting up BatchNorm49
I0928 09:32:13.021301  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.021303  4247 net.cpp:137] Memory required for data: 1110426800
I0928 09:32:13.021308  4247 layer_factory.hpp:77] Creating layer Scale49
I0928 09:32:13.021312  4247 net.cpp:84] Creating Layer Scale49
I0928 09:32:13.021314  4247 net.cpp:406] Scale49 <- Convolution49
I0928 09:32:13.021318  4247 net.cpp:367] Scale49 -> Convolution49 (in-place)
I0928 09:32:13.021347  4247 layer_factory.hpp:77] Creating layer Scale49
I0928 09:32:13.021426  4247 net.cpp:122] Setting up Scale49
I0928 09:32:13.021430  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.021432  4247 net.cpp:137] Memory required for data: 1112065200
I0928 09:32:13.021436  4247 layer_factory.hpp:77] Creating layer Eltwise23
I0928 09:32:13.021440  4247 net.cpp:84] Creating Layer Eltwise23
I0928 09:32:13.021443  4247 net.cpp:406] Eltwise23 <- Eltwise22_M2PELU45_0_split_1
I0928 09:32:13.021446  4247 net.cpp:406] Eltwise23 <- Convolution49
I0928 09:32:13.021450  4247 net.cpp:380] Eltwise23 -> Eltwise23
I0928 09:32:13.021467  4247 net.cpp:122] Setting up Eltwise23
I0928 09:32:13.021471  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.021472  4247 net.cpp:137] Memory required for data: 1113703600
I0928 09:32:13.021474  4247 layer_factory.hpp:77] Creating layer M2PELU47
I0928 09:32:13.021479  4247 net.cpp:84] Creating Layer M2PELU47
I0928 09:32:13.021482  4247 net.cpp:406] M2PELU47 <- Eltwise23
I0928 09:32:13.021486  4247 net.cpp:367] M2PELU47 -> Eltwise23 (in-place)
I0928 09:32:13.021584  4247 net.cpp:122] Setting up M2PELU47
I0928 09:32:13.021589  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.021591  4247 net.cpp:137] Memory required for data: 1115342000
I0928 09:32:13.021595  4247 layer_factory.hpp:77] Creating layer Eltwise23_M2PELU47_0_split
I0928 09:32:13.021598  4247 net.cpp:84] Creating Layer Eltwise23_M2PELU47_0_split
I0928 09:32:13.021600  4247 net.cpp:406] Eltwise23_M2PELU47_0_split <- Eltwise23
I0928 09:32:13.021605  4247 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_0
I0928 09:32:13.021608  4247 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_1
I0928 09:32:13.021633  4247 net.cpp:122] Setting up Eltwise23_M2PELU47_0_split
I0928 09:32:13.021637  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.021639  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.021641  4247 net.cpp:137] Memory required for data: 1118618800
I0928 09:32:13.021643  4247 layer_factory.hpp:77] Creating layer Convolution50
I0928 09:32:13.021651  4247 net.cpp:84] Creating Layer Convolution50
I0928 09:32:13.021652  4247 net.cpp:406] Convolution50 <- Eltwise23_M2PELU47_0_split_0
I0928 09:32:13.021656  4247 net.cpp:380] Convolution50 -> Convolution50
I0928 09:32:13.024191  4247 net.cpp:122] Setting up Convolution50
I0928 09:32:13.024200  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.024204  4247 net.cpp:137] Memory required for data: 1120257200
I0928 09:32:13.024207  4247 layer_factory.hpp:77] Creating layer BatchNorm50
I0928 09:32:13.024212  4247 net.cpp:84] Creating Layer BatchNorm50
I0928 09:32:13.024215  4247 net.cpp:406] BatchNorm50 <- Convolution50
I0928 09:32:13.024220  4247 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I0928 09:32:13.038033  4247 net.cpp:122] Setting up BatchNorm50
I0928 09:32:13.038043  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.038045  4247 net.cpp:137] Memory required for data: 1121895600
I0928 09:32:13.038051  4247 layer_factory.hpp:77] Creating layer Scale50
I0928 09:32:13.038058  4247 net.cpp:84] Creating Layer Scale50
I0928 09:32:13.038060  4247 net.cpp:406] Scale50 <- Convolution50
I0928 09:32:13.038064  4247 net.cpp:367] Scale50 -> Convolution50 (in-place)
I0928 09:32:13.038096  4247 layer_factory.hpp:77] Creating layer Scale50
I0928 09:32:13.038183  4247 net.cpp:122] Setting up Scale50
I0928 09:32:13.038188  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.038192  4247 net.cpp:137] Memory required for data: 1123534000
I0928 09:32:13.038195  4247 layer_factory.hpp:77] Creating layer M2PELU48
I0928 09:32:13.038202  4247 net.cpp:84] Creating Layer M2PELU48
I0928 09:32:13.038203  4247 net.cpp:406] M2PELU48 <- Convolution50
I0928 09:32:13.038208  4247 net.cpp:367] M2PELU48 -> Convolution50 (in-place)
I0928 09:32:13.038306  4247 net.cpp:122] Setting up M2PELU48
I0928 09:32:13.038312  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.038314  4247 net.cpp:137] Memory required for data: 1125172400
I0928 09:32:13.038318  4247 layer_factory.hpp:77] Creating layer Convolution51
I0928 09:32:13.038326  4247 net.cpp:84] Creating Layer Convolution51
I0928 09:32:13.038327  4247 net.cpp:406] Convolution51 <- Convolution50
I0928 09:32:13.038332  4247 net.cpp:380] Convolution51 -> Convolution51
I0928 09:32:13.040599  4247 net.cpp:122] Setting up Convolution51
I0928 09:32:13.040609  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.040612  4247 net.cpp:137] Memory required for data: 1126810800
I0928 09:32:13.040616  4247 layer_factory.hpp:77] Creating layer BatchNorm51
I0928 09:32:13.040621  4247 net.cpp:84] Creating Layer BatchNorm51
I0928 09:32:13.040623  4247 net.cpp:406] BatchNorm51 <- Convolution51
I0928 09:32:13.040628  4247 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I0928 09:32:13.040766  4247 net.cpp:122] Setting up BatchNorm51
I0928 09:32:13.040771  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.040773  4247 net.cpp:137] Memory required for data: 1128449200
I0928 09:32:13.040786  4247 layer_factory.hpp:77] Creating layer Scale51
I0928 09:32:13.040791  4247 net.cpp:84] Creating Layer Scale51
I0928 09:32:13.040793  4247 net.cpp:406] Scale51 <- Convolution51
I0928 09:32:13.040796  4247 net.cpp:367] Scale51 -> Convolution51 (in-place)
I0928 09:32:13.040825  4247 layer_factory.hpp:77] Creating layer Scale51
I0928 09:32:13.040904  4247 net.cpp:122] Setting up Scale51
I0928 09:32:13.040908  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.040910  4247 net.cpp:137] Memory required for data: 1130087600
I0928 09:32:13.040915  4247 layer_factory.hpp:77] Creating layer Eltwise24
I0928 09:32:13.040918  4247 net.cpp:84] Creating Layer Eltwise24
I0928 09:32:13.040921  4247 net.cpp:406] Eltwise24 <- Eltwise23_M2PELU47_0_split_1
I0928 09:32:13.040925  4247 net.cpp:406] Eltwise24 <- Convolution51
I0928 09:32:13.040927  4247 net.cpp:380] Eltwise24 -> Eltwise24
I0928 09:32:13.040944  4247 net.cpp:122] Setting up Eltwise24
I0928 09:32:13.040948  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.040951  4247 net.cpp:137] Memory required for data: 1131726000
I0928 09:32:13.040952  4247 layer_factory.hpp:77] Creating layer M2PELU49
I0928 09:32:13.040957  4247 net.cpp:84] Creating Layer M2PELU49
I0928 09:32:13.040961  4247 net.cpp:406] M2PELU49 <- Eltwise24
I0928 09:32:13.040964  4247 net.cpp:367] M2PELU49 -> Eltwise24 (in-place)
I0928 09:32:13.041057  4247 net.cpp:122] Setting up M2PELU49
I0928 09:32:13.041062  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.041064  4247 net.cpp:137] Memory required for data: 1133364400
I0928 09:32:13.041067  4247 layer_factory.hpp:77] Creating layer Eltwise24_M2PELU49_0_split
I0928 09:32:13.041071  4247 net.cpp:84] Creating Layer Eltwise24_M2PELU49_0_split
I0928 09:32:13.041074  4247 net.cpp:406] Eltwise24_M2PELU49_0_split <- Eltwise24
I0928 09:32:13.041077  4247 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_0
I0928 09:32:13.041082  4247 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_1
I0928 09:32:13.041116  4247 net.cpp:122] Setting up Eltwise24_M2PELU49_0_split
I0928 09:32:13.041121  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.041124  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.041126  4247 net.cpp:137] Memory required for data: 1136641200
I0928 09:32:13.041128  4247 layer_factory.hpp:77] Creating layer Convolution52
I0928 09:32:13.041134  4247 net.cpp:84] Creating Layer Convolution52
I0928 09:32:13.041137  4247 net.cpp:406] Convolution52 <- Eltwise24_M2PELU49_0_split_0
I0928 09:32:13.041141  4247 net.cpp:380] Convolution52 -> Convolution52
I0928 09:32:13.043287  4247 net.cpp:122] Setting up Convolution52
I0928 09:32:13.043296  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.043299  4247 net.cpp:137] Memory required for data: 1138279600
I0928 09:32:13.043303  4247 layer_factory.hpp:77] Creating layer BatchNorm52
I0928 09:32:13.043308  4247 net.cpp:84] Creating Layer BatchNorm52
I0928 09:32:13.043310  4247 net.cpp:406] BatchNorm52 <- Convolution52
I0928 09:32:13.043315  4247 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I0928 09:32:13.043462  4247 net.cpp:122] Setting up BatchNorm52
I0928 09:32:13.043465  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.043467  4247 net.cpp:137] Memory required for data: 1139918000
I0928 09:32:13.043473  4247 layer_factory.hpp:77] Creating layer Scale52
I0928 09:32:13.043476  4247 net.cpp:84] Creating Layer Scale52
I0928 09:32:13.043479  4247 net.cpp:406] Scale52 <- Convolution52
I0928 09:32:13.043483  4247 net.cpp:367] Scale52 -> Convolution52 (in-place)
I0928 09:32:13.043510  4247 layer_factory.hpp:77] Creating layer Scale52
I0928 09:32:13.043592  4247 net.cpp:122] Setting up Scale52
I0928 09:32:13.043596  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.043598  4247 net.cpp:137] Memory required for data: 1141556400
I0928 09:32:13.043602  4247 layer_factory.hpp:77] Creating layer M2PELU50
I0928 09:32:13.043623  4247 net.cpp:84] Creating Layer M2PELU50
I0928 09:32:13.043633  4247 net.cpp:406] M2PELU50 <- Convolution52
I0928 09:32:13.043637  4247 net.cpp:367] M2PELU50 -> Convolution52 (in-place)
I0928 09:32:13.043735  4247 net.cpp:122] Setting up M2PELU50
I0928 09:32:13.043740  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.043741  4247 net.cpp:137] Memory required for data: 1143194800
I0928 09:32:13.043745  4247 layer_factory.hpp:77] Creating layer Convolution53
I0928 09:32:13.043751  4247 net.cpp:84] Creating Layer Convolution53
I0928 09:32:13.043754  4247 net.cpp:406] Convolution53 <- Convolution52
I0928 09:32:13.043758  4247 net.cpp:380] Convolution53 -> Convolution53
I0928 09:32:13.045456  4247 net.cpp:122] Setting up Convolution53
I0928 09:32:13.045465  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.045469  4247 net.cpp:137] Memory required for data: 1144833200
I0928 09:32:13.045473  4247 layer_factory.hpp:77] Creating layer BatchNorm53
I0928 09:32:13.045477  4247 net.cpp:84] Creating Layer BatchNorm53
I0928 09:32:13.045480  4247 net.cpp:406] BatchNorm53 <- Convolution53
I0928 09:32:13.045485  4247 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I0928 09:32:13.045625  4247 net.cpp:122] Setting up BatchNorm53
I0928 09:32:13.045629  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.045631  4247 net.cpp:137] Memory required for data: 1146471600
I0928 09:32:13.045636  4247 layer_factory.hpp:77] Creating layer Scale53
I0928 09:32:13.045640  4247 net.cpp:84] Creating Layer Scale53
I0928 09:32:13.045644  4247 net.cpp:406] Scale53 <- Convolution53
I0928 09:32:13.045646  4247 net.cpp:367] Scale53 -> Convolution53 (in-place)
I0928 09:32:13.045673  4247 layer_factory.hpp:77] Creating layer Scale53
I0928 09:32:13.045753  4247 net.cpp:122] Setting up Scale53
I0928 09:32:13.045756  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.045758  4247 net.cpp:137] Memory required for data: 1148110000
I0928 09:32:13.045763  4247 layer_factory.hpp:77] Creating layer Eltwise25
I0928 09:32:13.045766  4247 net.cpp:84] Creating Layer Eltwise25
I0928 09:32:13.045768  4247 net.cpp:406] Eltwise25 <- Eltwise24_M2PELU49_0_split_1
I0928 09:32:13.045771  4247 net.cpp:406] Eltwise25 <- Convolution53
I0928 09:32:13.045774  4247 net.cpp:380] Eltwise25 -> Eltwise25
I0928 09:32:13.045791  4247 net.cpp:122] Setting up Eltwise25
I0928 09:32:13.045795  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.045797  4247 net.cpp:137] Memory required for data: 1149748400
I0928 09:32:13.045799  4247 layer_factory.hpp:77] Creating layer M2PELU51
I0928 09:32:13.045805  4247 net.cpp:84] Creating Layer M2PELU51
I0928 09:32:13.045807  4247 net.cpp:406] M2PELU51 <- Eltwise25
I0928 09:32:13.045810  4247 net.cpp:367] M2PELU51 -> Eltwise25 (in-place)
I0928 09:32:13.045902  4247 net.cpp:122] Setting up M2PELU51
I0928 09:32:13.045907  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.045908  4247 net.cpp:137] Memory required for data: 1151386800
I0928 09:32:13.045912  4247 layer_factory.hpp:77] Creating layer Eltwise25_M2PELU51_0_split
I0928 09:32:13.045915  4247 net.cpp:84] Creating Layer Eltwise25_M2PELU51_0_split
I0928 09:32:13.045918  4247 net.cpp:406] Eltwise25_M2PELU51_0_split <- Eltwise25
I0928 09:32:13.045922  4247 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_0
I0928 09:32:13.045927  4247 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_1
I0928 09:32:13.045949  4247 net.cpp:122] Setting up Eltwise25_M2PELU51_0_split
I0928 09:32:13.045953  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.045956  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.045958  4247 net.cpp:137] Memory required for data: 1154663600
I0928 09:32:13.045960  4247 layer_factory.hpp:77] Creating layer Convolution54
I0928 09:32:13.045966  4247 net.cpp:84] Creating Layer Convolution54
I0928 09:32:13.045969  4247 net.cpp:406] Convolution54 <- Eltwise25_M2PELU51_0_split_0
I0928 09:32:13.045972  4247 net.cpp:380] Convolution54 -> Convolution54
I0928 09:32:13.047971  4247 net.cpp:122] Setting up Convolution54
I0928 09:32:13.047986  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.047988  4247 net.cpp:137] Memory required for data: 1156302000
I0928 09:32:13.047993  4247 layer_factory.hpp:77] Creating layer BatchNorm54
I0928 09:32:13.047997  4247 net.cpp:84] Creating Layer BatchNorm54
I0928 09:32:13.048001  4247 net.cpp:406] BatchNorm54 <- Convolution54
I0928 09:32:13.048004  4247 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I0928 09:32:13.048151  4247 net.cpp:122] Setting up BatchNorm54
I0928 09:32:13.048156  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.048157  4247 net.cpp:137] Memory required for data: 1157940400
I0928 09:32:13.048162  4247 layer_factory.hpp:77] Creating layer Scale54
I0928 09:32:13.048166  4247 net.cpp:84] Creating Layer Scale54
I0928 09:32:13.048169  4247 net.cpp:406] Scale54 <- Convolution54
I0928 09:32:13.048172  4247 net.cpp:367] Scale54 -> Convolution54 (in-place)
I0928 09:32:13.048200  4247 layer_factory.hpp:77] Creating layer Scale54
I0928 09:32:13.048280  4247 net.cpp:122] Setting up Scale54
I0928 09:32:13.048285  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.048286  4247 net.cpp:137] Memory required for data: 1159578800
I0928 09:32:13.048290  4247 layer_factory.hpp:77] Creating layer M2PELU52
I0928 09:32:13.048295  4247 net.cpp:84] Creating Layer M2PELU52
I0928 09:32:13.048298  4247 net.cpp:406] M2PELU52 <- Convolution54
I0928 09:32:13.048301  4247 net.cpp:367] M2PELU52 -> Convolution54 (in-place)
I0928 09:32:13.048393  4247 net.cpp:122] Setting up M2PELU52
I0928 09:32:13.048398  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.048400  4247 net.cpp:137] Memory required for data: 1161217200
I0928 09:32:13.048404  4247 layer_factory.hpp:77] Creating layer Convolution55
I0928 09:32:13.048410  4247 net.cpp:84] Creating Layer Convolution55
I0928 09:32:13.048413  4247 net.cpp:406] Convolution55 <- Convolution54
I0928 09:32:13.048416  4247 net.cpp:380] Convolution55 -> Convolution55
I0928 09:32:13.050113  4247 net.cpp:122] Setting up Convolution55
I0928 09:32:13.050122  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.050125  4247 net.cpp:137] Memory required for data: 1162855600
I0928 09:32:13.050129  4247 layer_factory.hpp:77] Creating layer BatchNorm55
I0928 09:32:13.050134  4247 net.cpp:84] Creating Layer BatchNorm55
I0928 09:32:13.050137  4247 net.cpp:406] BatchNorm55 <- Convolution55
I0928 09:32:13.050142  4247 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I0928 09:32:13.050281  4247 net.cpp:122] Setting up BatchNorm55
I0928 09:32:13.050284  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.050287  4247 net.cpp:137] Memory required for data: 1164494000
I0928 09:32:13.050292  4247 layer_factory.hpp:77] Creating layer Scale55
I0928 09:32:13.050294  4247 net.cpp:84] Creating Layer Scale55
I0928 09:32:13.050297  4247 net.cpp:406] Scale55 <- Convolution55
I0928 09:32:13.050300  4247 net.cpp:367] Scale55 -> Convolution55 (in-place)
I0928 09:32:13.050329  4247 layer_factory.hpp:77] Creating layer Scale55
I0928 09:32:13.050410  4247 net.cpp:122] Setting up Scale55
I0928 09:32:13.050415  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.050416  4247 net.cpp:137] Memory required for data: 1166132400
I0928 09:32:13.050420  4247 layer_factory.hpp:77] Creating layer Eltwise26
I0928 09:32:13.050424  4247 net.cpp:84] Creating Layer Eltwise26
I0928 09:32:13.050427  4247 net.cpp:406] Eltwise26 <- Eltwise25_M2PELU51_0_split_1
I0928 09:32:13.050431  4247 net.cpp:406] Eltwise26 <- Convolution55
I0928 09:32:13.050433  4247 net.cpp:380] Eltwise26 -> Eltwise26
I0928 09:32:13.050451  4247 net.cpp:122] Setting up Eltwise26
I0928 09:32:13.050454  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.050457  4247 net.cpp:137] Memory required for data: 1167770800
I0928 09:32:13.050458  4247 layer_factory.hpp:77] Creating layer M2PELU53
I0928 09:32:13.050462  4247 net.cpp:84] Creating Layer M2PELU53
I0928 09:32:13.050464  4247 net.cpp:406] M2PELU53 <- Eltwise26
I0928 09:32:13.050473  4247 net.cpp:367] M2PELU53 -> Eltwise26 (in-place)
I0928 09:32:13.050572  4247 net.cpp:122] Setting up M2PELU53
I0928 09:32:13.050580  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.050581  4247 net.cpp:137] Memory required for data: 1169409200
I0928 09:32:13.050585  4247 layer_factory.hpp:77] Creating layer Eltwise26_M2PELU53_0_split
I0928 09:32:13.050588  4247 net.cpp:84] Creating Layer Eltwise26_M2PELU53_0_split
I0928 09:32:13.050590  4247 net.cpp:406] Eltwise26_M2PELU53_0_split <- Eltwise26
I0928 09:32:13.050595  4247 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_0
I0928 09:32:13.050598  4247 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_1
I0928 09:32:13.050623  4247 net.cpp:122] Setting up Eltwise26_M2PELU53_0_split
I0928 09:32:13.050627  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.050631  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.050632  4247 net.cpp:137] Memory required for data: 1172686000
I0928 09:32:13.050633  4247 layer_factory.hpp:77] Creating layer Convolution56
I0928 09:32:13.050640  4247 net.cpp:84] Creating Layer Convolution56
I0928 09:32:13.050642  4247 net.cpp:406] Convolution56 <- Eltwise26_M2PELU53_0_split_0
I0928 09:32:13.050647  4247 net.cpp:380] Convolution56 -> Convolution56
I0928 09:32:13.052319  4247 net.cpp:122] Setting up Convolution56
I0928 09:32:13.052327  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.052330  4247 net.cpp:137] Memory required for data: 1174324400
I0928 09:32:13.052335  4247 layer_factory.hpp:77] Creating layer BatchNorm56
I0928 09:32:13.068684  4247 net.cpp:84] Creating Layer BatchNorm56
I0928 09:32:13.068692  4247 net.cpp:406] BatchNorm56 <- Convolution56
I0928 09:32:13.068697  4247 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I0928 09:32:13.068866  4247 net.cpp:122] Setting up BatchNorm56
I0928 09:32:13.068871  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.068874  4247 net.cpp:137] Memory required for data: 1175962800
I0928 09:32:13.068881  4247 layer_factory.hpp:77] Creating layer Scale56
I0928 09:32:13.068886  4247 net.cpp:84] Creating Layer Scale56
I0928 09:32:13.068888  4247 net.cpp:406] Scale56 <- Convolution56
I0928 09:32:13.068892  4247 net.cpp:367] Scale56 -> Convolution56 (in-place)
I0928 09:32:13.068923  4247 layer_factory.hpp:77] Creating layer Scale56
I0928 09:32:13.069013  4247 net.cpp:122] Setting up Scale56
I0928 09:32:13.069018  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.069020  4247 net.cpp:137] Memory required for data: 1177601200
I0928 09:32:13.069025  4247 layer_factory.hpp:77] Creating layer M2PELU54
I0928 09:32:13.069031  4247 net.cpp:84] Creating Layer M2PELU54
I0928 09:32:13.069033  4247 net.cpp:406] M2PELU54 <- Convolution56
I0928 09:32:13.069037  4247 net.cpp:367] M2PELU54 -> Convolution56 (in-place)
I0928 09:32:13.069138  4247 net.cpp:122] Setting up M2PELU54
I0928 09:32:13.069142  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.069145  4247 net.cpp:137] Memory required for data: 1179239600
I0928 09:32:13.069149  4247 layer_factory.hpp:77] Creating layer Convolution57
I0928 09:32:13.069156  4247 net.cpp:84] Creating Layer Convolution57
I0928 09:32:13.069159  4247 net.cpp:406] Convolution57 <- Convolution56
I0928 09:32:13.069164  4247 net.cpp:380] Convolution57 -> Convolution57
I0928 09:32:13.071415  4247 net.cpp:122] Setting up Convolution57
I0928 09:32:13.071425  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.071427  4247 net.cpp:137] Memory required for data: 1180878000
I0928 09:32:13.071432  4247 layer_factory.hpp:77] Creating layer BatchNorm57
I0928 09:32:13.071437  4247 net.cpp:84] Creating Layer BatchNorm57
I0928 09:32:13.071440  4247 net.cpp:406] BatchNorm57 <- Convolution57
I0928 09:32:13.071444  4247 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I0928 09:32:13.071586  4247 net.cpp:122] Setting up BatchNorm57
I0928 09:32:13.071591  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.071593  4247 net.cpp:137] Memory required for data: 1182516400
I0928 09:32:13.071606  4247 layer_factory.hpp:77] Creating layer Scale57
I0928 09:32:13.071610  4247 net.cpp:84] Creating Layer Scale57
I0928 09:32:13.071614  4247 net.cpp:406] Scale57 <- Convolution57
I0928 09:32:13.071616  4247 net.cpp:367] Scale57 -> Convolution57 (in-place)
I0928 09:32:13.071647  4247 layer_factory.hpp:77] Creating layer Scale57
I0928 09:32:13.071727  4247 net.cpp:122] Setting up Scale57
I0928 09:32:13.071732  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.071733  4247 net.cpp:137] Memory required for data: 1184154800
I0928 09:32:13.071738  4247 layer_factory.hpp:77] Creating layer Eltwise27
I0928 09:32:13.071743  4247 net.cpp:84] Creating Layer Eltwise27
I0928 09:32:13.071745  4247 net.cpp:406] Eltwise27 <- Eltwise26_M2PELU53_0_split_1
I0928 09:32:13.071748  4247 net.cpp:406] Eltwise27 <- Convolution57
I0928 09:32:13.071751  4247 net.cpp:380] Eltwise27 -> Eltwise27
I0928 09:32:13.071768  4247 net.cpp:122] Setting up Eltwise27
I0928 09:32:13.071772  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.071774  4247 net.cpp:137] Memory required for data: 1185793200
I0928 09:32:13.071776  4247 layer_factory.hpp:77] Creating layer M2PELU55
I0928 09:32:13.071781  4247 net.cpp:84] Creating Layer M2PELU55
I0928 09:32:13.071784  4247 net.cpp:406] M2PELU55 <- Eltwise27
I0928 09:32:13.071786  4247 net.cpp:367] M2PELU55 -> Eltwise27 (in-place)
I0928 09:32:13.071880  4247 net.cpp:122] Setting up M2PELU55
I0928 09:32:13.071884  4247 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 09:32:13.071887  4247 net.cpp:137] Memory required for data: 1187431600
I0928 09:32:13.071890  4247 layer_factory.hpp:77] Creating layer Pooling1
I0928 09:32:13.071894  4247 net.cpp:84] Creating Layer Pooling1
I0928 09:32:13.071897  4247 net.cpp:406] Pooling1 <- Eltwise27
I0928 09:32:13.071900  4247 net.cpp:380] Pooling1 -> Pooling1
I0928 09:32:13.072715  4247 net.cpp:122] Setting up Pooling1
I0928 09:32:13.072723  4247 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0928 09:32:13.072726  4247 net.cpp:137] Memory required for data: 1187457200
I0928 09:32:13.072738  4247 layer_factory.hpp:77] Creating layer InnerProduct1
I0928 09:32:13.072744  4247 net.cpp:84] Creating Layer InnerProduct1
I0928 09:32:13.072746  4247 net.cpp:406] InnerProduct1 <- Pooling1
I0928 09:32:13.072751  4247 net.cpp:380] InnerProduct1 -> InnerProduct1
I0928 09:32:13.072863  4247 net.cpp:122] Setting up InnerProduct1
I0928 09:32:13.072868  4247 net.cpp:129] Top shape: 100 10 (1000)
I0928 09:32:13.072870  4247 net.cpp:137] Memory required for data: 1187461200
I0928 09:32:13.072875  4247 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0928 09:32:13.072880  4247 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I0928 09:32:13.072881  4247 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0928 09:32:13.072885  4247 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0928 09:32:13.072890  4247 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0928 09:32:13.072916  4247 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I0928 09:32:13.072919  4247 net.cpp:129] Top shape: 100 10 (1000)
I0928 09:32:13.072922  4247 net.cpp:129] Top shape: 100 10 (1000)
I0928 09:32:13.072924  4247 net.cpp:137] Memory required for data: 1187469200
I0928 09:32:13.072926  4247 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0928 09:32:13.072930  4247 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0928 09:32:13.072933  4247 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I0928 09:32:13.072937  4247 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I0928 09:32:13.072939  4247 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0928 09:32:13.072944  4247 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0928 09:32:13.073185  4247 net.cpp:122] Setting up SoftmaxWithLoss1
I0928 09:32:13.073192  4247 net.cpp:129] Top shape: (1)
I0928 09:32:13.073194  4247 net.cpp:132]     with loss weight 1
I0928 09:32:13.073209  4247 net.cpp:137] Memory required for data: 1187469204
I0928 09:32:13.073211  4247 layer_factory.hpp:77] Creating layer Accuracy1
I0928 09:32:13.073216  4247 net.cpp:84] Creating Layer Accuracy1
I0928 09:32:13.073218  4247 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I0928 09:32:13.073221  4247 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I0928 09:32:13.073226  4247 net.cpp:380] Accuracy1 -> Accuracy1
I0928 09:32:13.073232  4247 net.cpp:122] Setting up Accuracy1
I0928 09:32:13.073235  4247 net.cpp:129] Top shape: (1)
I0928 09:32:13.073237  4247 net.cpp:137] Memory required for data: 1187469208
I0928 09:32:13.073240  4247 net.cpp:200] Accuracy1 does not need backward computation.
I0928 09:32:13.073242  4247 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0928 09:32:13.073245  4247 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0928 09:32:13.073247  4247 net.cpp:198] InnerProduct1 needs backward computation.
I0928 09:32:13.073249  4247 net.cpp:198] Pooling1 needs backward computation.
I0928 09:32:13.073251  4247 net.cpp:198] M2PELU55 needs backward computation.
I0928 09:32:13.073253  4247 net.cpp:198] Eltwise27 needs backward computation.
I0928 09:32:13.073256  4247 net.cpp:198] Scale57 needs backward computation.
I0928 09:32:13.073257  4247 net.cpp:198] BatchNorm57 needs backward computation.
I0928 09:32:13.073259  4247 net.cpp:198] Convolution57 needs backward computation.
I0928 09:32:13.073262  4247 net.cpp:198] M2PELU54 needs backward computation.
I0928 09:32:13.073264  4247 net.cpp:198] Scale56 needs backward computation.
I0928 09:32:13.073266  4247 net.cpp:198] BatchNorm56 needs backward computation.
I0928 09:32:13.073268  4247 net.cpp:198] Convolution56 needs backward computation.
I0928 09:32:13.073271  4247 net.cpp:198] Eltwise26_M2PELU53_0_split needs backward computation.
I0928 09:32:13.073272  4247 net.cpp:198] M2PELU53 needs backward computation.
I0928 09:32:13.073274  4247 net.cpp:198] Eltwise26 needs backward computation.
I0928 09:32:13.073277  4247 net.cpp:198] Scale55 needs backward computation.
I0928 09:32:13.073279  4247 net.cpp:198] BatchNorm55 needs backward computation.
I0928 09:32:13.073282  4247 net.cpp:198] Convolution55 needs backward computation.
I0928 09:32:13.073283  4247 net.cpp:198] M2PELU52 needs backward computation.
I0928 09:32:13.073285  4247 net.cpp:198] Scale54 needs backward computation.
I0928 09:32:13.073287  4247 net.cpp:198] BatchNorm54 needs backward computation.
I0928 09:32:13.073288  4247 net.cpp:198] Convolution54 needs backward computation.
I0928 09:32:13.073292  4247 net.cpp:198] Eltwise25_M2PELU51_0_split needs backward computation.
I0928 09:32:13.073293  4247 net.cpp:198] M2PELU51 needs backward computation.
I0928 09:32:13.073295  4247 net.cpp:198] Eltwise25 needs backward computation.
I0928 09:32:13.073298  4247 net.cpp:198] Scale53 needs backward computation.
I0928 09:32:13.073300  4247 net.cpp:198] BatchNorm53 needs backward computation.
I0928 09:32:13.073302  4247 net.cpp:198] Convolution53 needs backward computation.
I0928 09:32:13.073304  4247 net.cpp:198] M2PELU50 needs backward computation.
I0928 09:32:13.073307  4247 net.cpp:198] Scale52 needs backward computation.
I0928 09:32:13.073308  4247 net.cpp:198] BatchNorm52 needs backward computation.
I0928 09:32:13.073310  4247 net.cpp:198] Convolution52 needs backward computation.
I0928 09:32:13.073312  4247 net.cpp:198] Eltwise24_M2PELU49_0_split needs backward computation.
I0928 09:32:13.073314  4247 net.cpp:198] M2PELU49 needs backward computation.
I0928 09:32:13.073317  4247 net.cpp:198] Eltwise24 needs backward computation.
I0928 09:32:13.073319  4247 net.cpp:198] Scale51 needs backward computation.
I0928 09:32:13.073321  4247 net.cpp:198] BatchNorm51 needs backward computation.
I0928 09:32:13.073323  4247 net.cpp:198] Convolution51 needs backward computation.
I0928 09:32:13.073325  4247 net.cpp:198] M2PELU48 needs backward computation.
I0928 09:32:13.073328  4247 net.cpp:198] Scale50 needs backward computation.
I0928 09:32:13.073333  4247 net.cpp:198] BatchNorm50 needs backward computation.
I0928 09:32:13.073335  4247 net.cpp:198] Convolution50 needs backward computation.
I0928 09:32:13.073338  4247 net.cpp:198] Eltwise23_M2PELU47_0_split needs backward computation.
I0928 09:32:13.073340  4247 net.cpp:198] M2PELU47 needs backward computation.
I0928 09:32:13.073343  4247 net.cpp:198] Eltwise23 needs backward computation.
I0928 09:32:13.073345  4247 net.cpp:198] Scale49 needs backward computation.
I0928 09:32:13.073348  4247 net.cpp:198] BatchNorm49 needs backward computation.
I0928 09:32:13.073349  4247 net.cpp:198] Convolution49 needs backward computation.
I0928 09:32:13.073351  4247 net.cpp:198] M2PELU46 needs backward computation.
I0928 09:32:13.073354  4247 net.cpp:198] Scale48 needs backward computation.
I0928 09:32:13.073355  4247 net.cpp:198] BatchNorm48 needs backward computation.
I0928 09:32:13.073357  4247 net.cpp:198] Convolution48 needs backward computation.
I0928 09:32:13.073360  4247 net.cpp:198] Eltwise22_M2PELU45_0_split needs backward computation.
I0928 09:32:13.073362  4247 net.cpp:198] M2PELU45 needs backward computation.
I0928 09:32:13.073364  4247 net.cpp:198] Eltwise22 needs backward computation.
I0928 09:32:13.073366  4247 net.cpp:198] Scale47 needs backward computation.
I0928 09:32:13.073369  4247 net.cpp:198] BatchNorm47 needs backward computation.
I0928 09:32:13.073371  4247 net.cpp:198] Convolution47 needs backward computation.
I0928 09:32:13.073374  4247 net.cpp:198] M2PELU44 needs backward computation.
I0928 09:32:13.073375  4247 net.cpp:198] Scale46 needs backward computation.
I0928 09:32:13.073379  4247 net.cpp:198] BatchNorm46 needs backward computation.
I0928 09:32:13.073380  4247 net.cpp:198] Convolution46 needs backward computation.
I0928 09:32:13.073382  4247 net.cpp:198] Eltwise21_M2PELU43_0_split needs backward computation.
I0928 09:32:13.073385  4247 net.cpp:198] M2PELU43 needs backward computation.
I0928 09:32:13.073386  4247 net.cpp:198] Eltwise21 needs backward computation.
I0928 09:32:13.073390  4247 net.cpp:198] Scale45 needs backward computation.
I0928 09:32:13.073391  4247 net.cpp:198] BatchNorm45 needs backward computation.
I0928 09:32:13.073393  4247 net.cpp:198] Convolution45 needs backward computation.
I0928 09:32:13.073396  4247 net.cpp:198] M2PELU42 needs backward computation.
I0928 09:32:13.073398  4247 net.cpp:198] Scale44 needs backward computation.
I0928 09:32:13.073400  4247 net.cpp:198] BatchNorm44 needs backward computation.
I0928 09:32:13.073402  4247 net.cpp:198] Convolution44 needs backward computation.
I0928 09:32:13.073405  4247 net.cpp:198] Eltwise20_M2PELU41_0_split needs backward computation.
I0928 09:32:13.073407  4247 net.cpp:198] M2PELU41 needs backward computation.
I0928 09:32:13.073410  4247 net.cpp:198] Eltwise20 needs backward computation.
I0928 09:32:13.073412  4247 net.cpp:198] Scale43 needs backward computation.
I0928 09:32:13.073415  4247 net.cpp:198] BatchNorm43 needs backward computation.
I0928 09:32:13.073416  4247 net.cpp:198] Convolution43 needs backward computation.
I0928 09:32:13.073418  4247 net.cpp:198] M2PELU40 needs backward computation.
I0928 09:32:13.073421  4247 net.cpp:198] Scale42 needs backward computation.
I0928 09:32:13.073423  4247 net.cpp:198] BatchNorm42 needs backward computation.
I0928 09:32:13.073426  4247 net.cpp:198] Convolution42 needs backward computation.
I0928 09:32:13.073427  4247 net.cpp:198] Eltwise19_M2PELU39_0_split needs backward computation.
I0928 09:32:13.073431  4247 net.cpp:198] M2PELU39 needs backward computation.
I0928 09:32:13.073432  4247 net.cpp:198] Eltwise19 needs backward computation.
I0928 09:32:13.073436  4247 net.cpp:198] Scale41 needs backward computation.
I0928 09:32:13.073437  4247 net.cpp:198] BatchNorm41 needs backward computation.
I0928 09:32:13.073439  4247 net.cpp:198] Convolution41 needs backward computation.
I0928 09:32:13.073442  4247 net.cpp:198] M2PELU38 needs backward computation.
I0928 09:32:13.073444  4247 net.cpp:198] Scale40 needs backward computation.
I0928 09:32:13.073446  4247 net.cpp:198] BatchNorm40 needs backward computation.
I0928 09:32:13.073451  4247 net.cpp:198] Convolution40 needs backward computation.
I0928 09:32:13.073454  4247 net.cpp:198] Scale39 needs backward computation.
I0928 09:32:13.073457  4247 net.cpp:198] BatchNorm39 needs backward computation.
I0928 09:32:13.073458  4247 net.cpp:198] Convolution39 needs backward computation.
I0928 09:32:13.073462  4247 net.cpp:198] Eltwise18_M2PELU37_0_split needs backward computation.
I0928 09:32:13.073463  4247 net.cpp:198] M2PELU37 needs backward computation.
I0928 09:32:13.073465  4247 net.cpp:198] Eltwise18 needs backward computation.
I0928 09:32:13.073468  4247 net.cpp:198] Scale38 needs backward computation.
I0928 09:32:13.073470  4247 net.cpp:198] BatchNorm38 needs backward computation.
I0928 09:32:13.073472  4247 net.cpp:198] Convolution38 needs backward computation.
I0928 09:32:13.073475  4247 net.cpp:198] M2PELU36 needs backward computation.
I0928 09:32:13.073477  4247 net.cpp:198] Scale37 needs backward computation.
I0928 09:32:13.073479  4247 net.cpp:198] BatchNorm37 needs backward computation.
I0928 09:32:13.073482  4247 net.cpp:198] Convolution37 needs backward computation.
I0928 09:32:13.073483  4247 net.cpp:198] Eltwise17_M2PELU35_0_split needs backward computation.
I0928 09:32:13.073487  4247 net.cpp:198] M2PELU35 needs backward computation.
I0928 09:32:13.073488  4247 net.cpp:198] Eltwise17 needs backward computation.
I0928 09:32:13.101886  4247 net.cpp:198] Scale36 needs backward computation.
I0928 09:32:13.101903  4247 net.cpp:198] BatchNorm36 needs backward computation.
I0928 09:32:13.101907  4247 net.cpp:198] Convolution36 needs backward computation.
I0928 09:32:13.101908  4247 net.cpp:198] M2PELU34 needs backward computation.
I0928 09:32:13.101910  4247 net.cpp:198] Scale35 needs backward computation.
I0928 09:32:13.101913  4247 net.cpp:198] BatchNorm35 needs backward computation.
I0928 09:32:13.101915  4247 net.cpp:198] Convolution35 needs backward computation.
I0928 09:32:13.101918  4247 net.cpp:198] Eltwise16_M2PELU33_0_split needs backward computation.
I0928 09:32:13.101922  4247 net.cpp:198] M2PELU33 needs backward computation.
I0928 09:32:13.101923  4247 net.cpp:198] Eltwise16 needs backward computation.
I0928 09:32:13.101927  4247 net.cpp:198] Scale34 needs backward computation.
I0928 09:32:13.101928  4247 net.cpp:198] BatchNorm34 needs backward computation.
I0928 09:32:13.101930  4247 net.cpp:198] Convolution34 needs backward computation.
I0928 09:32:13.101933  4247 net.cpp:198] M2PELU32 needs backward computation.
I0928 09:32:13.101935  4247 net.cpp:198] Scale33 needs backward computation.
I0928 09:32:13.101938  4247 net.cpp:198] BatchNorm33 needs backward computation.
I0928 09:32:13.101939  4247 net.cpp:198] Convolution33 needs backward computation.
I0928 09:32:13.101953  4247 net.cpp:198] Eltwise15_M2PELU31_0_split needs backward computation.
I0928 09:32:13.101954  4247 net.cpp:198] M2PELU31 needs backward computation.
I0928 09:32:13.101956  4247 net.cpp:198] Eltwise15 needs backward computation.
I0928 09:32:13.101969  4247 net.cpp:198] Scale32 needs backward computation.
I0928 09:32:13.101971  4247 net.cpp:198] BatchNorm32 needs backward computation.
I0928 09:32:13.101974  4247 net.cpp:198] Convolution32 needs backward computation.
I0928 09:32:13.101976  4247 net.cpp:198] M2PELU30 needs backward computation.
I0928 09:32:13.101979  4247 net.cpp:198] Scale31 needs backward computation.
I0928 09:32:13.101989  4247 net.cpp:198] BatchNorm31 needs backward computation.
I0928 09:32:13.101991  4247 net.cpp:198] Convolution31 needs backward computation.
I0928 09:32:13.101994  4247 net.cpp:198] Eltwise14_M2PELU29_0_split needs backward computation.
I0928 09:32:13.101996  4247 net.cpp:198] M2PELU29 needs backward computation.
I0928 09:32:13.102008  4247 net.cpp:198] Eltwise14 needs backward computation.
I0928 09:32:13.102010  4247 net.cpp:198] Scale30 needs backward computation.
I0928 09:32:13.102013  4247 net.cpp:198] BatchNorm30 needs backward computation.
I0928 09:32:13.102015  4247 net.cpp:198] Convolution30 needs backward computation.
I0928 09:32:13.102033  4247 net.cpp:198] M2PELU28 needs backward computation.
I0928 09:32:13.102037  4247 net.cpp:198] Scale29 needs backward computation.
I0928 09:32:13.102041  4247 net.cpp:198] BatchNorm29 needs backward computation.
I0928 09:32:13.102042  4247 net.cpp:198] Convolution29 needs backward computation.
I0928 09:32:13.102046  4247 net.cpp:198] Eltwise13_M2PELU27_0_split needs backward computation.
I0928 09:32:13.102047  4247 net.cpp:198] M2PELU27 needs backward computation.
I0928 09:32:13.102051  4247 net.cpp:198] Eltwise13 needs backward computation.
I0928 09:32:13.102053  4247 net.cpp:198] Scale28 needs backward computation.
I0928 09:32:13.102056  4247 net.cpp:198] BatchNorm28 needs backward computation.
I0928 09:32:13.102057  4247 net.cpp:198] Convolution28 needs backward computation.
I0928 09:32:13.102061  4247 net.cpp:198] M2PELU26 needs backward computation.
I0928 09:32:13.102062  4247 net.cpp:198] Scale27 needs backward computation.
I0928 09:32:13.102066  4247 net.cpp:198] BatchNorm27 needs backward computation.
I0928 09:32:13.102067  4247 net.cpp:198] Convolution27 needs backward computation.
I0928 09:32:13.102071  4247 net.cpp:198] Eltwise12_M2PELU25_0_split needs backward computation.
I0928 09:32:13.102072  4247 net.cpp:198] M2PELU25 needs backward computation.
I0928 09:32:13.102075  4247 net.cpp:198] Eltwise12 needs backward computation.
I0928 09:32:13.102078  4247 net.cpp:198] Scale26 needs backward computation.
I0928 09:32:13.102080  4247 net.cpp:198] BatchNorm26 needs backward computation.
I0928 09:32:13.102082  4247 net.cpp:198] Convolution26 needs backward computation.
I0928 09:32:13.102085  4247 net.cpp:198] M2PELU24 needs backward computation.
I0928 09:32:13.102087  4247 net.cpp:198] Scale25 needs backward computation.
I0928 09:32:13.102089  4247 net.cpp:198] BatchNorm25 needs backward computation.
I0928 09:32:13.102092  4247 net.cpp:198] Convolution25 needs backward computation.
I0928 09:32:13.102094  4247 net.cpp:198] Eltwise11_M2PELU23_0_split needs backward computation.
I0928 09:32:13.102097  4247 net.cpp:198] M2PELU23 needs backward computation.
I0928 09:32:13.102100  4247 net.cpp:198] Eltwise11 needs backward computation.
I0928 09:32:13.102102  4247 net.cpp:198] Scale24 needs backward computation.
I0928 09:32:13.102105  4247 net.cpp:198] BatchNorm24 needs backward computation.
I0928 09:32:13.102108  4247 net.cpp:198] Convolution24 needs backward computation.
I0928 09:32:13.102109  4247 net.cpp:198] M2PELU22 needs backward computation.
I0928 09:32:13.102113  4247 net.cpp:198] Scale23 needs backward computation.
I0928 09:32:13.102114  4247 net.cpp:198] BatchNorm23 needs backward computation.
I0928 09:32:13.102116  4247 net.cpp:198] Convolution23 needs backward computation.
I0928 09:32:13.102119  4247 net.cpp:198] Eltwise10_M2PELU21_0_split needs backward computation.
I0928 09:32:13.102123  4247 net.cpp:198] M2PELU21 needs backward computation.
I0928 09:32:13.102124  4247 net.cpp:198] Eltwise10 needs backward computation.
I0928 09:32:13.102128  4247 net.cpp:198] Scale22 needs backward computation.
I0928 09:32:13.102129  4247 net.cpp:198] BatchNorm22 needs backward computation.
I0928 09:32:13.102133  4247 net.cpp:198] Convolution22 needs backward computation.
I0928 09:32:13.102134  4247 net.cpp:198] M2PELU20 needs backward computation.
I0928 09:32:13.102138  4247 net.cpp:198] Scale21 needs backward computation.
I0928 09:32:13.102139  4247 net.cpp:198] BatchNorm21 needs backward computation.
I0928 09:32:13.102141  4247 net.cpp:198] Convolution21 needs backward computation.
I0928 09:32:13.102144  4247 net.cpp:198] Scale20 needs backward computation.
I0928 09:32:13.102147  4247 net.cpp:198] BatchNorm20 needs backward computation.
I0928 09:32:13.102149  4247 net.cpp:198] Convolution20 needs backward computation.
I0928 09:32:13.102152  4247 net.cpp:198] Eltwise9_M2PELU19_0_split needs backward computation.
I0928 09:32:13.102154  4247 net.cpp:198] M2PELU19 needs backward computation.
I0928 09:32:13.102157  4247 net.cpp:198] Eltwise9 needs backward computation.
I0928 09:32:13.102164  4247 net.cpp:198] Scale19 needs backward computation.
I0928 09:32:13.102166  4247 net.cpp:198] BatchNorm19 needs backward computation.
I0928 09:32:13.102169  4247 net.cpp:198] Convolution19 needs backward computation.
I0928 09:32:13.102171  4247 net.cpp:198] M2PELU18 needs backward computation.
I0928 09:32:13.102174  4247 net.cpp:198] Scale18 needs backward computation.
I0928 09:32:13.102176  4247 net.cpp:198] BatchNorm18 needs backward computation.
I0928 09:32:13.102179  4247 net.cpp:198] Convolution18 needs backward computation.
I0928 09:32:13.102181  4247 net.cpp:198] Eltwise8_M2PELU17_0_split needs backward computation.
I0928 09:32:13.102183  4247 net.cpp:198] M2PELU17 needs backward computation.
I0928 09:32:13.102186  4247 net.cpp:198] Eltwise8 needs backward computation.
I0928 09:32:13.102188  4247 net.cpp:198] Scale17 needs backward computation.
I0928 09:32:13.102191  4247 net.cpp:198] BatchNorm17 needs backward computation.
I0928 09:32:13.102193  4247 net.cpp:198] Convolution17 needs backward computation.
I0928 09:32:13.102196  4247 net.cpp:198] M2PELU16 needs backward computation.
I0928 09:32:13.102198  4247 net.cpp:198] Scale16 needs backward computation.
I0928 09:32:13.102200  4247 net.cpp:198] BatchNorm16 needs backward computation.
I0928 09:32:13.102203  4247 net.cpp:198] Convolution16 needs backward computation.
I0928 09:32:13.102205  4247 net.cpp:198] Eltwise7_M2PELU15_0_split needs backward computation.
I0928 09:32:13.102208  4247 net.cpp:198] M2PELU15 needs backward computation.
I0928 09:32:13.102211  4247 net.cpp:198] Eltwise7 needs backward computation.
I0928 09:32:13.102213  4247 net.cpp:198] Scale15 needs backward computation.
I0928 09:32:13.102216  4247 net.cpp:198] BatchNorm15 needs backward computation.
I0928 09:32:13.102218  4247 net.cpp:198] Convolution15 needs backward computation.
I0928 09:32:13.102221  4247 net.cpp:198] M2PELU14 needs backward computation.
I0928 09:32:13.102223  4247 net.cpp:198] Scale14 needs backward computation.
I0928 09:32:13.102226  4247 net.cpp:198] BatchNorm14 needs backward computation.
I0928 09:32:13.102228  4247 net.cpp:198] Convolution14 needs backward computation.
I0928 09:32:13.102231  4247 net.cpp:198] Eltwise6_M2PELU13_0_split needs backward computation.
I0928 09:32:13.102233  4247 net.cpp:198] M2PELU13 needs backward computation.
I0928 09:32:13.102236  4247 net.cpp:198] Eltwise6 needs backward computation.
I0928 09:32:13.102238  4247 net.cpp:198] Scale13 needs backward computation.
I0928 09:32:13.102241  4247 net.cpp:198] BatchNorm13 needs backward computation.
I0928 09:32:13.102243  4247 net.cpp:198] Convolution13 needs backward computation.
I0928 09:32:13.102246  4247 net.cpp:198] M2PELU12 needs backward computation.
I0928 09:32:13.102248  4247 net.cpp:198] Scale12 needs backward computation.
I0928 09:32:13.102250  4247 net.cpp:198] BatchNorm12 needs backward computation.
I0928 09:32:13.102252  4247 net.cpp:198] Convolution12 needs backward computation.
I0928 09:32:13.102255  4247 net.cpp:198] Eltwise5_M2PELU11_0_split needs backward computation.
I0928 09:32:13.102257  4247 net.cpp:198] M2PELU11 needs backward computation.
I0928 09:32:13.102260  4247 net.cpp:198] Eltwise5 needs backward computation.
I0928 09:32:13.102263  4247 net.cpp:198] Scale11 needs backward computation.
I0928 09:32:13.102265  4247 net.cpp:198] BatchNorm11 needs backward computation.
I0928 09:32:13.102267  4247 net.cpp:198] Convolution11 needs backward computation.
I0928 09:32:13.102270  4247 net.cpp:198] M2PELU10 needs backward computation.
I0928 09:32:13.102272  4247 net.cpp:198] Scale10 needs backward computation.
I0928 09:32:13.102275  4247 net.cpp:198] BatchNorm10 needs backward computation.
I0928 09:32:13.102277  4247 net.cpp:198] Convolution10 needs backward computation.
I0928 09:32:13.102280  4247 net.cpp:198] Eltwise4_M2PELU9_0_split needs backward computation.
I0928 09:32:13.102283  4247 net.cpp:198] M2PELU9 needs backward computation.
I0928 09:32:13.102285  4247 net.cpp:198] Eltwise4 needs backward computation.
I0928 09:32:13.102288  4247 net.cpp:198] Scale9 needs backward computation.
I0928 09:32:13.102295  4247 net.cpp:198] BatchNorm9 needs backward computation.
I0928 09:32:13.102298  4247 net.cpp:198] Convolution9 needs backward computation.
I0928 09:32:13.102300  4247 net.cpp:198] M2PELU8 needs backward computation.
I0928 09:32:13.102303  4247 net.cpp:198] Scale8 needs backward computation.
I0928 09:32:13.102305  4247 net.cpp:198] BatchNorm8 needs backward computation.
I0928 09:32:13.102308  4247 net.cpp:198] Convolution8 needs backward computation.
I0928 09:32:13.102313  4247 net.cpp:198] Eltwise3_M2PELU7_0_split needs backward computation.
I0928 09:32:13.102314  4247 net.cpp:198] M2PELU7 needs backward computation.
I0928 09:32:13.102318  4247 net.cpp:198] Eltwise3 needs backward computation.
I0928 09:32:13.102320  4247 net.cpp:198] Scale7 needs backward computation.
I0928 09:32:13.102322  4247 net.cpp:198] BatchNorm7 needs backward computation.
I0928 09:32:13.102325  4247 net.cpp:198] Convolution7 needs backward computation.
I0928 09:32:13.102327  4247 net.cpp:198] M2PELU6 needs backward computation.
I0928 09:32:13.102329  4247 net.cpp:198] Scale6 needs backward computation.
I0928 09:32:13.102332  4247 net.cpp:198] BatchNorm6 needs backward computation.
I0928 09:32:13.102334  4247 net.cpp:198] Convolution6 needs backward computation.
I0928 09:32:13.102337  4247 net.cpp:198] Eltwise2_M2PELU5_0_split needs backward computation.
I0928 09:32:13.102340  4247 net.cpp:198] M2PELU5 needs backward computation.
I0928 09:32:13.102342  4247 net.cpp:198] Eltwise2 needs backward computation.
I0928 09:32:13.102345  4247 net.cpp:198] Scale5 needs backward computation.
I0928 09:32:13.102349  4247 net.cpp:198] BatchNorm5 needs backward computation.
I0928 09:32:13.102350  4247 net.cpp:198] Convolution5 needs backward computation.
I0928 09:32:13.102354  4247 net.cpp:198] M2PELU4 needs backward computation.
I0928 09:32:13.102355  4247 net.cpp:198] Scale4 needs backward computation.
I0928 09:32:13.102358  4247 net.cpp:198] BatchNorm4 needs backward computation.
I0928 09:32:13.102360  4247 net.cpp:198] Convolution4 needs backward computation.
I0928 09:32:13.102363  4247 net.cpp:198] Eltwise1_M2PELU3_0_split needs backward computation.
I0928 09:32:13.102366  4247 net.cpp:198] M2PELU3 needs backward computation.
I0928 09:32:13.102368  4247 net.cpp:198] Eltwise1 needs backward computation.
I0928 09:32:13.102371  4247 net.cpp:198] Scale3 needs backward computation.
I0928 09:32:13.102373  4247 net.cpp:198] BatchNorm3 needs backward computation.
I0928 09:32:13.102376  4247 net.cpp:198] Convolution3 needs backward computation.
I0928 09:32:13.102378  4247 net.cpp:198] M2PELU2 needs backward computation.
I0928 09:32:13.102380  4247 net.cpp:198] Scale2 needs backward computation.
I0928 09:32:13.102383  4247 net.cpp:198] BatchNorm2 needs backward computation.
I0928 09:32:13.102385  4247 net.cpp:198] Convolution2 needs backward computation.
I0928 09:32:13.102388  4247 net.cpp:198] Convolution1_M2PELU1_0_split needs backward computation.
I0928 09:32:13.102391  4247 net.cpp:198] M2PELU1 needs backward computation.
I0928 09:32:13.102393  4247 net.cpp:198] Scale1 needs backward computation.
I0928 09:32:13.102396  4247 net.cpp:198] BatchNorm1 needs backward computation.
I0928 09:32:13.102398  4247 net.cpp:198] Convolution1 needs backward computation.
I0928 09:32:13.102401  4247 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I0928 09:32:13.102404  4247 net.cpp:200] Data1 does not need backward computation.
I0928 09:32:13.102406  4247 net.cpp:242] This network produces output Accuracy1
I0928 09:32:13.102409  4247 net.cpp:242] This network produces output SoftmaxWithLoss1
I0928 09:32:13.102505  4247 net.cpp:255] Network initialization done.
I0928 09:32:13.103404  4247 solver.cpp:56] Solver scaffolding done.
I0928 09:32:13.116075  4247 caffe.cpp:248] Starting Optimization
I0928 09:32:13.116082  4247 solver.cpp:272] Solving resnet_cifar10
I0928 09:32:13.116084  4247 solver.cpp:273] Learning Rate Policy: multistep
I0928 09:32:13.122025  4247 solver.cpp:330] Iteration 0, Testing net (#0)
I0928 09:32:16.544610  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:32:16.684026  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I0928 09:32:16.684063  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I0928 09:32:16.880764  4247 solver.cpp:218] Iteration 0 (-2.10195e-44 iter/s, 3.76458s/100 iters), loss = 2.31288
I0928 09:32:16.880795  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.31288 (* 1 = 2.31288 loss)
I0928 09:32:16.880806  4247 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I0928 09:32:31.040915  4247 solver.cpp:218] Iteration 100 (7.06215 iter/s, 14.16s/100 iters), loss = 1.51685
I0928 09:32:31.040956  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.51685 (* 1 = 1.51685 loss)
I0928 09:32:31.040961  4247 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I0928 09:32:45.193624  4247 solver.cpp:218] Iteration 200 (7.06587 iter/s, 14.1525s/100 iters), loss = 1.51512
I0928 09:32:45.193713  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.51512 (* 1 = 1.51512 loss)
I0928 09:32:45.193720  4247 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I0928 09:32:59.352690  4247 solver.cpp:218] Iteration 300 (7.06273 iter/s, 14.1588s/100 iters), loss = 1.32749
I0928 09:32:59.352738  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.32749 (* 1 = 1.32749 loss)
I0928 09:32:59.352746  4247 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I0928 09:33:13.509426  4247 solver.cpp:218] Iteration 400 (7.06387 iter/s, 14.1566s/100 iters), loss = 1.00286
I0928 09:33:13.509469  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.00286 (* 1 = 1.00286 loss)
I0928 09:33:13.509474  4247 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I0928 09:33:26.970000  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:33:27.537093  4247 solver.cpp:330] Iteration 500, Testing net (#0)
I0928 09:33:30.885169  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:33:31.024931  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3237
I0928 09:33:31.024967  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.14582 (* 1 = 3.14582 loss)
I0928 09:33:31.165408  4247 solver.cpp:218] Iteration 500 (5.66387 iter/s, 17.6558s/100 iters), loss = 1.16021
I0928 09:33:31.165436  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.16021 (* 1 = 1.16021 loss)
I0928 09:33:31.165441  4247 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I0928 09:33:45.397157  4247 solver.cpp:218] Iteration 600 (7.02662 iter/s, 14.2316s/100 iters), loss = 1.05297
I0928 09:33:45.397189  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.05297 (* 1 = 1.05297 loss)
I0928 09:33:45.397197  4247 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I0928 09:33:59.627421  4247 solver.cpp:218] Iteration 700 (7.02736 iter/s, 14.2301s/100 iters), loss = 0.996373
I0928 09:33:59.627537  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.996373 (* 1 = 0.996373 loss)
I0928 09:33:59.627544  4247 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I0928 09:34:13.796746  4247 solver.cpp:218] Iteration 800 (7.05762 iter/s, 14.1691s/100 iters), loss = 1.07446
I0928 09:34:13.796777  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.07446 (* 1 = 1.07446 loss)
I0928 09:34:13.796793  4247 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I0928 09:34:28.109053  4247 solver.cpp:218] Iteration 900 (6.98707 iter/s, 14.3121s/100 iters), loss = 0.900758
I0928 09:34:28.109087  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.900758 (* 1 = 0.900758 loss)
I0928 09:34:28.109093  4247 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I0928 09:34:41.632359  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:34:42.204210  4247 solver.cpp:330] Iteration 1000, Testing net (#0)
I0928 09:34:45.618559  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:34:45.760069  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3877
I0928 09:34:45.760105  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.60066 (* 1 = 2.60066 loss)
I0928 09:34:45.906165  4247 solver.cpp:218] Iteration 1000 (5.61895 iter/s, 17.7969s/100 iters), loss = 0.934788
I0928 09:34:45.906204  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.934788 (* 1 = 0.934788 loss)
I0928 09:34:45.906213  4247 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I0928 09:35:00.118531  4247 solver.cpp:218] Iteration 1100 (7.0362 iter/s, 14.2122s/100 iters), loss = 0.698441
I0928 09:35:00.118562  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.698441 (* 1 = 0.698441 loss)
I0928 09:35:00.118568  4247 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I0928 09:35:14.313707  4247 solver.cpp:218] Iteration 1200 (7.04472 iter/s, 14.195s/100 iters), loss = 0.834789
I0928 09:35:14.313838  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.834789 (* 1 = 0.834789 loss)
I0928 09:35:14.313855  4247 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I0928 09:35:28.569736  4247 solver.cpp:218] Iteration 1300 (7.01469 iter/s, 14.2558s/100 iters), loss = 0.835964
I0928 09:35:28.569768  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.835964 (* 1 = 0.835964 loss)
I0928 09:35:28.569775  4247 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I0928 09:35:42.760334  4247 solver.cpp:218] Iteration 1400 (7.04699 iter/s, 14.1905s/100 iters), loss = 0.79296
I0928 09:35:42.760366  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.79296 (* 1 = 0.79296 loss)
I0928 09:35:42.760372  4247 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I0928 09:35:56.250533  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:35:56.820029  4247 solver.cpp:330] Iteration 1500, Testing net (#0)
I0928 09:36:00.168216  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:36:00.309011  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4454
I0928 09:36:00.309047  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.37705 (* 1 = 2.37705 loss)
I0928 09:36:00.449362  4247 solver.cpp:218] Iteration 1500 (5.65327 iter/s, 17.6889s/100 iters), loss = 0.894752
I0928 09:36:00.449388  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.894752 (* 1 = 0.894752 loss)
I0928 09:36:00.449394  4247 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I0928 09:36:14.728355  4247 solver.cpp:218] Iteration 1600 (7.00335 iter/s, 14.2789s/100 iters), loss = 0.54462
I0928 09:36:14.728387  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.54462 (* 1 = 0.54462 loss)
I0928 09:36:14.728394  4247 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I0928 09:36:29.003819  4247 solver.cpp:218] Iteration 1700 (7.00508 iter/s, 14.2754s/100 iters), loss = 0.601022
I0928 09:36:29.003967  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.601022 (* 1 = 0.601022 loss)
I0928 09:36:29.003974  4247 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I0928 09:36:43.231060  4247 solver.cpp:218] Iteration 1800 (7.02888 iter/s, 14.227s/100 iters), loss = 0.781089
I0928 09:36:43.231091  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.781089 (* 1 = 0.781089 loss)
I0928 09:36:43.231097  4247 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I0928 09:36:57.485679  4247 solver.cpp:218] Iteration 1900 (7.01532 iter/s, 14.2545s/100 iters), loss = 0.57114
I0928 09:36:57.485721  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.57114 (* 1 = 0.57114 loss)
I0928 09:36:57.485728  4247 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I0928 09:37:11.013620  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:37:11.583933  4247 solver.cpp:330] Iteration 2000, Testing net (#0)
I0928 09:37:14.942042  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:37:15.088520  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6101
I0928 09:37:15.088546  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.33152 (* 1 = 1.33152 loss)
I0928 09:37:15.229344  4247 solver.cpp:218] Iteration 2000 (5.63585 iter/s, 17.7435s/100 iters), loss = 0.809326
I0928 09:37:15.229372  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.809326 (* 1 = 0.809326 loss)
I0928 09:37:15.229379  4247 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I0928 09:37:29.565950  4247 solver.cpp:218] Iteration 2100 (6.9752 iter/s, 14.3365s/100 iters), loss = 0.573152
I0928 09:37:29.565994  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.573152 (* 1 = 0.573152 loss)
I0928 09:37:29.566000  4247 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I0928 09:37:43.818678  4247 solver.cpp:218] Iteration 2200 (7.01625 iter/s, 14.2526s/100 iters), loss = 0.633313
I0928 09:37:43.818786  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.633313 (* 1 = 0.633313 loss)
I0928 09:37:43.818794  4247 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I0928 09:37:58.074648  4247 solver.cpp:218] Iteration 2300 (7.01469 iter/s, 14.2558s/100 iters), loss = 0.655246
I0928 09:37:58.074692  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.655246 (* 1 = 0.655246 loss)
I0928 09:37:58.074698  4247 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I0928 09:38:12.342377  4247 solver.cpp:218] Iteration 2400 (7.00888 iter/s, 14.2676s/100 iters), loss = 0.585481
I0928 09:38:12.342419  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.585481 (* 1 = 0.585481 loss)
I0928 09:38:12.342425  4247 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I0928 09:38:25.903254  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:38:26.473467  4247 solver.cpp:330] Iteration 2500, Testing net (#0)
I0928 09:38:29.840415  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:38:29.981299  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6768
I0928 09:38:29.981328  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.933191 (* 1 = 0.933191 loss)
I0928 09:38:30.122258  4247 solver.cpp:218] Iteration 2500 (5.62437 iter/s, 17.7798s/100 iters), loss = 0.650477
I0928 09:38:30.122287  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.650477 (* 1 = 0.650477 loss)
I0928 09:38:30.122293  4247 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I0928 09:38:44.395309  4247 solver.cpp:218] Iteration 2600 (7.00626 iter/s, 14.273s/100 iters), loss = 0.51146
I0928 09:38:44.395342  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.51146 (* 1 = 0.51146 loss)
I0928 09:38:44.395349  4247 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I0928 09:38:58.678917  4247 solver.cpp:218] Iteration 2700 (7.00108 iter/s, 14.2835s/100 iters), loss = 0.510433
I0928 09:38:58.678988  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.510433 (* 1 = 0.510433 loss)
I0928 09:38:58.679005  4247 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I0928 09:39:12.943897  4247 solver.cpp:218] Iteration 2800 (7.01024 iter/s, 14.2648s/100 iters), loss = 0.589434
I0928 09:39:12.943930  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.589434 (* 1 = 0.589434 loss)
I0928 09:39:12.943948  4247 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I0928 09:39:27.215929  4247 solver.cpp:218] Iteration 2900 (7.00676 iter/s, 14.2719s/100 iters), loss = 0.564868
I0928 09:39:27.215961  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.564868 (* 1 = 0.564868 loss)
I0928 09:39:27.215968  4247 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I0928 09:39:40.791059  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:39:41.363497  4247 solver.cpp:330] Iteration 3000, Testing net (#0)
I0928 09:39:44.727066  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:39:44.867204  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6768
I0928 09:39:44.867241  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.955526 (* 1 = 0.955526 loss)
I0928 09:39:45.009176  4247 solver.cpp:218] Iteration 3000 (5.62014 iter/s, 17.7931s/100 iters), loss = 0.550584
I0928 09:39:45.009207  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.550584 (* 1 = 0.550584 loss)
I0928 09:39:45.009214  4247 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I0928 09:39:59.278697  4247 solver.cpp:218] Iteration 3100 (7.00799 iter/s, 14.2694s/100 iters), loss = 0.471973
I0928 09:39:59.278733  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.471973 (* 1 = 0.471973 loss)
I0928 09:39:59.278743  4247 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I0928 09:40:13.560014  4247 solver.cpp:218] Iteration 3200 (7.0022 iter/s, 14.2812s/100 iters), loss = 0.563239
I0928 09:40:13.560181  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.563239 (* 1 = 0.563239 loss)
I0928 09:40:13.560194  4247 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I0928 09:40:27.830927  4247 solver.cpp:218] Iteration 3300 (7.00737 iter/s, 14.2707s/100 iters), loss = 0.513792
I0928 09:40:27.830965  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.513792 (* 1 = 0.513792 loss)
I0928 09:40:27.830974  4247 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I0928 09:40:42.102386  4247 solver.cpp:218] Iteration 3400 (7.00704 iter/s, 14.2714s/100 iters), loss = 0.548791
I0928 09:40:42.102422  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.548791 (* 1 = 0.548791 loss)
I0928 09:40:42.102432  4247 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I0928 09:40:55.673818  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:40:56.243261  4247 solver.cpp:330] Iteration 3500, Testing net (#0)
I0928 09:40:59.642999  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:40:59.788404  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5819
I0928 09:40:59.788434  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.25845 (* 1 = 1.25845 loss)
I0928 09:40:59.928961  4247 solver.cpp:218] Iteration 3500 (5.60964 iter/s, 17.8265s/100 iters), loss = 0.497173
I0928 09:40:59.928993  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.497173 (* 1 = 0.497173 loss)
I0928 09:40:59.929000  4247 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I0928 09:41:14.238322  4247 solver.cpp:218] Iteration 3600 (6.98867 iter/s, 14.3089s/100 iters), loss = 0.418514
I0928 09:41:14.238364  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.418514 (* 1 = 0.418514 loss)
I0928 09:41:14.238371  4247 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I0928 09:41:28.475379  4247 solver.cpp:218] Iteration 3700 (7.02397 iter/s, 14.237s/100 iters), loss = 0.467293
I0928 09:41:28.475478  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.467293 (* 1 = 0.467293 loss)
I0928 09:41:28.475487  4247 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I0928 09:41:42.726727  4247 solver.cpp:218] Iteration 3800 (7.01695 iter/s, 14.2512s/100 iters), loss = 0.578335
I0928 09:41:42.726758  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.578335 (* 1 = 0.578335 loss)
I0928 09:41:42.726764  4247 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I0928 09:41:57.014135  4247 solver.cpp:218] Iteration 3900 (6.99921 iter/s, 14.2873s/100 iters), loss = 0.470794
I0928 09:41:57.014168  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.470794 (* 1 = 0.470794 loss)
I0928 09:41:57.014174  4247 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I0928 09:42:10.616581  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:42:11.185467  4247 solver.cpp:330] Iteration 4000, Testing net (#0)
I0928 09:42:14.572648  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:42:14.712937  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.563
I0928 09:42:14.712973  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.26907 (* 1 = 1.26907 loss)
I0928 09:42:14.854674  4247 solver.cpp:218] Iteration 4000 (5.60524 iter/s, 17.8404s/100 iters), loss = 0.461656
I0928 09:42:14.854707  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.461656 (* 1 = 0.461656 loss)
I0928 09:42:14.854712  4247 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I0928 09:42:29.154018  4247 solver.cpp:218] Iteration 4100 (6.99337 iter/s, 14.2993s/100 iters), loss = 0.328551
I0928 09:42:29.154058  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328551 (* 1 = 0.328551 loss)
I0928 09:42:29.154065  4247 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I0928 09:42:43.429257  4247 solver.cpp:218] Iteration 4200 (7.00518 iter/s, 14.2751s/100 iters), loss = 0.432346
I0928 09:42:43.429430  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.432346 (* 1 = 0.432346 loss)
I0928 09:42:43.429440  4247 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I0928 09:42:57.658828  4247 solver.cpp:218] Iteration 4300 (7.02773 iter/s, 14.2293s/100 iters), loss = 0.615496
I0928 09:42:57.658869  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.615496 (* 1 = 0.615496 loss)
I0928 09:42:57.658876  4247 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I0928 09:43:11.976549  4247 solver.cpp:218] Iteration 4400 (6.9844 iter/s, 14.3176s/100 iters), loss = 0.515386
I0928 09:43:11.976585  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.515386 (* 1 = 0.515386 loss)
I0928 09:43:11.976593  4247 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I0928 09:43:25.589607  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:43:26.157899  4247 solver.cpp:330] Iteration 4500, Testing net (#0)
I0928 09:43:29.508599  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:43:29.648480  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5006
I0928 09:43:29.648517  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.47823 (* 1 = 1.47823 loss)
I0928 09:43:29.789522  4247 solver.cpp:218] Iteration 4500 (5.61392 iter/s, 17.8129s/100 iters), loss = 0.483361
I0928 09:43:29.789561  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.483361 (* 1 = 0.483361 loss)
I0928 09:43:29.789567  4247 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I0928 09:43:43.997347  4247 solver.cpp:218] Iteration 4600 (7.03842 iter/s, 14.2077s/100 iters), loss = 0.38283
I0928 09:43:43.997390  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.38283 (* 1 = 0.38283 loss)
I0928 09:43:43.997396  4247 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I0928 09:43:58.348423  4247 solver.cpp:218] Iteration 4700 (6.96817 iter/s, 14.351s/100 iters), loss = 0.357102
I0928 09:43:58.348572  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.357102 (* 1 = 0.357102 loss)
I0928 09:43:58.348592  4247 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I0928 09:44:12.581166  4247 solver.cpp:218] Iteration 4800 (7.02615 iter/s, 14.2325s/100 iters), loss = 0.469366
I0928 09:44:12.581198  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.469366 (* 1 = 0.469366 loss)
I0928 09:44:12.581205  4247 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I0928 09:44:26.877185  4247 solver.cpp:218] Iteration 4900 (6.995 iter/s, 14.2959s/100 iters), loss = 0.476976
I0928 09:44:26.877218  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.476976 (* 1 = 0.476976 loss)
I0928 09:44:26.877234  4247 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I0928 09:44:40.402400  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:44:40.969871  4247 solver.cpp:330] Iteration 5000, Testing net (#0)
I0928 09:44:44.328017  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:44:44.468086  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5236
I0928 09:44:44.468123  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.36948 (* 1 = 1.36948 loss)
I0928 09:44:44.609385  4247 solver.cpp:218] Iteration 5000 (5.63949 iter/s, 17.7321s/100 iters), loss = 0.442203
I0928 09:44:44.609413  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.442203 (* 1 = 0.442203 loss)
I0928 09:44:44.609421  4247 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I0928 09:44:58.880333  4247 solver.cpp:218] Iteration 5100 (7.00728 iter/s, 14.2709s/100 iters), loss = 0.329994
I0928 09:44:58.880364  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329994 (* 1 = 0.329994 loss)
I0928 09:44:58.880372  4247 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I0928 09:45:13.156394  4247 solver.cpp:218] Iteration 5200 (7.00477 iter/s, 14.276s/100 iters), loss = 0.416644
I0928 09:45:13.156574  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.416644 (* 1 = 0.416644 loss)
I0928 09:45:13.156584  4247 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I0928 09:45:27.403419  4247 solver.cpp:218] Iteration 5300 (7.01912 iter/s, 14.2468s/100 iters), loss = 0.489362
I0928 09:45:27.403450  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.489362 (* 1 = 0.489362 loss)
I0928 09:45:27.403457  4247 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I0928 09:45:41.712982  4247 solver.cpp:218] Iteration 5400 (6.98837 iter/s, 14.3095s/100 iters), loss = 0.39193
I0928 09:45:41.713024  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.39193 (* 1 = 0.39193 loss)
I0928 09:45:41.713030  4247 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I0928 09:45:55.247853  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:45:55.815925  4247 solver.cpp:330] Iteration 5500, Testing net (#0)
I0928 09:45:59.174090  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:45:59.314505  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6143
I0928 09:45:59.314535  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.0775 (* 1 = 1.0775 loss)
I0928 09:45:59.456838  4247 solver.cpp:218] Iteration 5500 (5.63579 iter/s, 17.7438s/100 iters), loss = 0.461577
I0928 09:45:59.456871  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.461577 (* 1 = 0.461577 loss)
I0928 09:45:59.456877  4247 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I0928 09:46:13.773708  4247 solver.cpp:218] Iteration 5600 (6.98481 iter/s, 14.3168s/100 iters), loss = 0.293764
I0928 09:46:13.773741  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293764 (* 1 = 0.293764 loss)
I0928 09:46:13.773746  4247 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I0928 09:46:27.997663  4247 solver.cpp:218] Iteration 5700 (7.03044 iter/s, 14.2239s/100 iters), loss = 0.416389
I0928 09:46:27.997776  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.416389 (* 1 = 0.416389 loss)
I0928 09:46:27.997782  4247 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I0928 09:46:42.303565  4247 solver.cpp:218] Iteration 5800 (6.9902 iter/s, 14.3057s/100 iters), loss = 0.484653
I0928 09:46:42.303606  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.484653 (* 1 = 0.484653 loss)
I0928 09:46:42.303612  4247 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I0928 09:46:56.548836  4247 solver.cpp:218] Iteration 5900 (7.01992 iter/s, 14.2452s/100 iters), loss = 0.407285
I0928 09:46:56.548868  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.407285 (* 1 = 0.407285 loss)
I0928 09:46:56.548874  4247 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I0928 09:47:10.176427  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:47:10.745389  4247 solver.cpp:330] Iteration 6000, Testing net (#0)
I0928 09:47:14.145838  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:47:14.286276  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.674
I0928 09:47:14.286303  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.925892 (* 1 = 0.925892 loss)
I0928 09:47:14.432394  4247 solver.cpp:218] Iteration 6000 (5.59176 iter/s, 17.8835s/100 iters), loss = 0.452318
I0928 09:47:14.432430  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.452318 (* 1 = 0.452318 loss)
I0928 09:47:14.432437  4247 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I0928 09:47:28.673780  4247 solver.cpp:218] Iteration 6100 (7.02183 iter/s, 14.2413s/100 iters), loss = 0.287506
I0928 09:47:28.673822  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287506 (* 1 = 0.287506 loss)
I0928 09:47:28.673830  4247 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I0928 09:47:42.989049  4247 solver.cpp:218] Iteration 6200 (6.98559 iter/s, 14.3152s/100 iters), loss = 0.428773
I0928 09:47:42.989220  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.428773 (* 1 = 0.428773 loss)
I0928 09:47:42.989241  4247 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I0928 09:47:57.266368  4247 solver.cpp:218] Iteration 6300 (7.00423 iter/s, 14.2771s/100 iters), loss = 0.413225
I0928 09:47:57.266423  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.413225 (* 1 = 0.413225 loss)
I0928 09:47:57.266441  4247 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I0928 09:48:11.542982  4247 solver.cpp:218] Iteration 6400 (7.00463 iter/s, 14.2763s/100 iters), loss = 0.384294
I0928 09:48:11.543014  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.384294 (* 1 = 0.384294 loss)
I0928 09:48:11.543020  4247 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I0928 09:48:25.129015  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:48:25.697409  4247 solver.cpp:330] Iteration 6500, Testing net (#0)
I0928 09:48:29.054494  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:48:29.194923  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6547
I0928 09:48:29.194950  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.996373 (* 1 = 0.996373 loss)
I0928 09:48:29.335708  4247 solver.cpp:218] Iteration 6500 (5.6203 iter/s, 17.7926s/100 iters), loss = 0.374088
I0928 09:48:29.335736  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.374088 (* 1 = 0.374088 loss)
I0928 09:48:29.335742  4247 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I0928 09:48:43.640318  4247 solver.cpp:218] Iteration 6600 (6.99079 iter/s, 14.3045s/100 iters), loss = 0.313217
I0928 09:48:43.640352  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313217 (* 1 = 0.313217 loss)
I0928 09:48:43.640358  4247 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I0928 09:48:57.943562  4247 solver.cpp:218] Iteration 6700 (6.99146 iter/s, 14.3032s/100 iters), loss = 0.392652
I0928 09:48:57.943670  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.392652 (* 1 = 0.392652 loss)
I0928 09:48:57.943678  4247 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I0928 09:49:12.187171  4247 solver.cpp:218] Iteration 6800 (7.02077 iter/s, 14.2435s/100 iters), loss = 0.445001
I0928 09:49:12.187214  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.445001 (* 1 = 0.445001 loss)
I0928 09:49:12.187232  4247 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I0928 09:49:26.488101  4247 solver.cpp:218] Iteration 6900 (6.9926 iter/s, 14.3008s/100 iters), loss = 0.348173
I0928 09:49:26.488132  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.348173 (* 1 = 0.348173 loss)
I0928 09:49:26.488138  4247 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I0928 09:49:40.088624  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:49:40.660725  4247 solver.cpp:330] Iteration 7000, Testing net (#0)
I0928 09:49:44.024710  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:49:44.164789  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7232
I0928 09:49:44.164816  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.806787 (* 1 = 0.806787 loss)
I0928 09:49:44.305541  4247 solver.cpp:218] Iteration 7000 (5.61251 iter/s, 17.8173s/100 iters), loss = 0.311121
I0928 09:49:44.305570  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311121 (* 1 = 0.311121 loss)
I0928 09:49:44.305577  4247 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I0928 09:49:58.535922  4247 solver.cpp:218] Iteration 7100 (7.02726 iter/s, 14.2303s/100 iters), loss = 0.264245
I0928 09:49:58.535954  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264245 (* 1 = 0.264245 loss)
I0928 09:49:58.535961  4247 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I0928 09:50:12.870936  4247 solver.cpp:218] Iteration 7200 (6.97597 iter/s, 14.3349s/100 iters), loss = 0.350039
I0928 09:50:12.871039  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350039 (* 1 = 0.350039 loss)
I0928 09:50:12.871047  4247 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I0928 09:50:27.184023  4247 solver.cpp:218] Iteration 7300 (6.98668 iter/s, 14.3129s/100 iters), loss = 0.453107
I0928 09:50:27.184056  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.453107 (* 1 = 0.453107 loss)
I0928 09:50:27.184062  4247 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I0928 09:50:41.414646  4247 solver.cpp:218] Iteration 7400 (7.02714 iter/s, 14.2305s/100 iters), loss = 0.338996
I0928 09:50:41.414679  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338996 (* 1 = 0.338996 loss)
I0928 09:50:41.414695  4247 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I0928 09:50:55.003466  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:50:55.574810  4247 solver.cpp:330] Iteration 7500, Testing net (#0)
I0928 09:50:58.935714  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:50:59.075762  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7446
I0928 09:50:59.075795  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.746688 (* 1 = 0.746688 loss)
I0928 09:50:59.215381  4247 solver.cpp:218] Iteration 7500 (5.61777 iter/s, 17.8006s/100 iters), loss = 0.344515
I0928 09:50:59.215415  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344515 (* 1 = 0.344515 loss)
I0928 09:50:59.215432  4247 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I0928 09:51:13.511490  4247 solver.cpp:218] Iteration 7600 (6.99495 iter/s, 14.296s/100 iters), loss = 0.317378
I0928 09:51:13.511520  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317378 (* 1 = 0.317378 loss)
I0928 09:51:13.511526  4247 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I0928 09:51:27.742630  4247 solver.cpp:218] Iteration 7700 (7.02688 iter/s, 14.2311s/100 iters), loss = 0.383668
I0928 09:51:27.742727  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.383668 (* 1 = 0.383668 loss)
I0928 09:51:27.742735  4247 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I0928 09:51:42.007735  4247 solver.cpp:218] Iteration 7800 (7.01018 iter/s, 14.265s/100 iters), loss = 0.436424
I0928 09:51:42.007766  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.436424 (* 1 = 0.436424 loss)
I0928 09:51:42.007771  4247 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I0928 09:51:56.296208  4247 solver.cpp:218] Iteration 7900 (6.99869 iter/s, 14.2884s/100 iters), loss = 0.29373
I0928 09:51:56.296242  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29373 (* 1 = 0.29373 loss)
I0928 09:51:56.296252  4247 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I0928 09:52:09.879384  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:52:10.450083  4247 solver.cpp:330] Iteration 8000, Testing net (#0)
I0928 09:52:13.809569  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:52:13.949659  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6265
I0928 09:52:13.949697  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.03801 (* 1 = 1.03801 loss)
I0928 09:52:14.090520  4247 solver.cpp:218] Iteration 8000 (5.6198 iter/s, 17.7942s/100 iters), loss = 0.40421
I0928 09:52:14.090549  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.40421 (* 1 = 0.40421 loss)
I0928 09:52:14.090556  4247 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I0928 09:52:28.380285  4247 solver.cpp:218] Iteration 8100 (6.99805 iter/s, 14.2897s/100 iters), loss = 0.291162
I0928 09:52:28.380319  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291162 (* 1 = 0.291162 loss)
I0928 09:52:28.380326  4247 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I0928 09:52:42.657510  4247 solver.cpp:218] Iteration 8200 (7.0042 iter/s, 14.2771s/100 iters), loss = 0.475138
I0928 09:52:42.657692  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.475138 (* 1 = 0.475138 loss)
I0928 09:52:42.657701  4247 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I0928 09:52:56.913657  4247 solver.cpp:218] Iteration 8300 (7.01464 iter/s, 14.2559s/100 iters), loss = 0.41294
I0928 09:52:56.913689  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.412939 (* 1 = 0.412939 loss)
I0928 09:52:56.913697  4247 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I0928 09:53:11.189244  4247 solver.cpp:218] Iteration 8400 (7.00501 iter/s, 14.2755s/100 iters), loss = 0.355927
I0928 09:53:11.189277  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355927 (* 1 = 0.355927 loss)
I0928 09:53:11.189285  4247 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I0928 09:53:24.725960  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:53:25.297564  4247 solver.cpp:330] Iteration 8500, Testing net (#0)
I0928 09:53:28.655194  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:53:28.795327  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7091
I0928 09:53:28.795363  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.812738 (* 1 = 0.812738 loss)
I0928 09:53:28.936174  4247 solver.cpp:218] Iteration 8500 (5.6348 iter/s, 17.7468s/100 iters), loss = 0.525206
I0928 09:53:28.936203  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.525206 (* 1 = 0.525206 loss)
I0928 09:53:28.936209  4247 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I0928 09:53:43.181257  4247 solver.cpp:218] Iteration 8600 (7.02 iter/s, 14.245s/100 iters), loss = 0.307073
I0928 09:53:43.181303  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307073 (* 1 = 0.307073 loss)
I0928 09:53:43.181309  4247 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I0928 09:53:57.465849  4247 solver.cpp:218] Iteration 8700 (7.00059 iter/s, 14.2845s/100 iters), loss = 0.315377
I0928 09:53:57.465984  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315377 (* 1 = 0.315377 loss)
I0928 09:53:57.465991  4247 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I0928 09:54:11.706066  4247 solver.cpp:218] Iteration 8800 (7.02245 iter/s, 14.24s/100 iters), loss = 0.367697
I0928 09:54:11.706097  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.367697 (* 1 = 0.367697 loss)
I0928 09:54:11.706104  4247 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I0928 09:54:26.007828  4247 solver.cpp:218] Iteration 8900 (6.99218 iter/s, 14.3017s/100 iters), loss = 0.262323
I0928 09:54:26.007860  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262323 (* 1 = 0.262323 loss)
I0928 09:54:26.007876  4247 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I0928 09:54:39.585070  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:54:40.157256  4247 solver.cpp:330] Iteration 9000, Testing net (#0)
I0928 09:54:43.512428  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:54:43.652771  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7588
I0928 09:54:43.652809  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.671389 (* 1 = 0.671389 loss)
I0928 09:54:43.794126  4247 solver.cpp:218] Iteration 9000 (5.62233 iter/s, 17.7862s/100 iters), loss = 0.294892
I0928 09:54:43.794159  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294892 (* 1 = 0.294892 loss)
I0928 09:54:43.794167  4247 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I0928 09:54:58.029700  4247 solver.cpp:218] Iteration 9100 (7.0247 iter/s, 14.2355s/100 iters), loss = 0.210849
I0928 09:54:58.029732  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210849 (* 1 = 0.210849 loss)
I0928 09:54:58.029739  4247 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I0928 09:55:12.249452  4247 solver.cpp:218] Iteration 9200 (7.03251 iter/s, 14.2197s/100 iters), loss = 0.395861
I0928 09:55:12.249528  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.39586 (* 1 = 0.39586 loss)
I0928 09:55:12.249547  4247 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I0928 09:55:26.552925  4247 solver.cpp:218] Iteration 9300 (6.99137 iter/s, 14.3034s/100 iters), loss = 0.369275
I0928 09:55:26.552968  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.369275 (* 1 = 0.369275 loss)
I0928 09:55:26.552973  4247 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I0928 09:55:40.870682  4247 solver.cpp:218] Iteration 9400 (6.98438 iter/s, 14.3177s/100 iters), loss = 0.346881
I0928 09:55:40.870715  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.346881 (* 1 = 0.346881 loss)
I0928 09:55:40.870723  4247 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I0928 09:55:54.414458  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:55:54.985270  4247 solver.cpp:330] Iteration 9500, Testing net (#0)
I0928 09:55:58.378495  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:55:58.524425  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.751
I0928 09:55:58.524462  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.695322 (* 1 = 0.695322 loss)
I0928 09:55:58.671036  4247 solver.cpp:218] Iteration 9500 (5.61789 iter/s, 17.8003s/100 iters), loss = 0.329268
I0928 09:55:58.671072  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329268 (* 1 = 0.329268 loss)
I0928 09:55:58.671079  4247 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I0928 09:56:12.937852  4247 solver.cpp:218] Iteration 9600 (7.00931 iter/s, 14.2667s/100 iters), loss = 0.36699
I0928 09:56:12.937885  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.36699 (* 1 = 0.36699 loss)
I0928 09:56:12.937891  4247 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I0928 09:56:27.203932  4247 solver.cpp:218] Iteration 9700 (7.00967 iter/s, 14.266s/100 iters), loss = 0.255958
I0928 09:56:27.204044  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255958 (* 1 = 0.255958 loss)
I0928 09:56:27.204051  4247 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I0928 09:56:41.445825  4247 solver.cpp:218] Iteration 9800 (7.02161 iter/s, 14.2417s/100 iters), loss = 0.379194
I0928 09:56:41.445866  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.379193 (* 1 = 0.379193 loss)
I0928 09:56:41.445873  4247 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I0928 09:56:55.736388  4247 solver.cpp:218] Iteration 9900 (6.99767 iter/s, 14.2905s/100 iters), loss = 0.29872
I0928 09:56:55.736431  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29872 (* 1 = 0.29872 loss)
I0928 09:56:55.736438  4247 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I0928 09:57:09.313192  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:57:09.883587  4247 solver.cpp:330] Iteration 10000, Testing net (#0)
I0928 09:57:13.249373  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:57:13.390413  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7913
I0928 09:57:13.390439  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.593858 (* 1 = 0.593858 loss)
I0928 09:57:13.530582  4247 solver.cpp:218] Iteration 10000 (5.61984 iter/s, 17.7941s/100 iters), loss = 0.321159
I0928 09:57:13.530612  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.321159 (* 1 = 0.321159 loss)
I0928 09:57:13.530618  4247 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I0928 09:57:27.761057  4247 solver.cpp:218] Iteration 10100 (7.02721 iter/s, 14.2304s/100 iters), loss = 0.335747
I0928 09:57:27.761090  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335747 (* 1 = 0.335747 loss)
I0928 09:57:27.761098  4247 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I0928 09:57:42.039947  4247 solver.cpp:218] Iteration 10200 (7.00338 iter/s, 14.2788s/100 iters), loss = 0.386481
I0928 09:57:42.040088  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.386481 (* 1 = 0.386481 loss)
I0928 09:57:42.040098  4247 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I0928 09:57:56.286229  4247 solver.cpp:218] Iteration 10300 (7.01947 iter/s, 14.2461s/100 iters), loss = 0.417174
I0928 09:57:56.286260  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.417174 (* 1 = 0.417174 loss)
I0928 09:57:56.286267  4247 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I0928 09:58:10.577153  4247 solver.cpp:218] Iteration 10400 (6.99748 iter/s, 14.2908s/100 iters), loss = 0.279462
I0928 09:58:10.577184  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279462 (* 1 = 0.279462 loss)
I0928 09:58:10.577191  4247 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I0928 09:58:24.160114  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:58:24.736881  4247 solver.cpp:330] Iteration 10500, Testing net (#0)
I0928 09:58:28.094877  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:58:28.235844  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8069
I0928 09:58:28.235882  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.563629 (* 1 = 0.563629 loss)
I0928 09:58:28.377872  4247 solver.cpp:218] Iteration 10500 (5.61778 iter/s, 17.8006s/100 iters), loss = 0.249026
I0928 09:58:28.377907  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249026 (* 1 = 0.249026 loss)
I0928 09:58:28.377913  4247 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I0928 09:58:42.686899  4247 solver.cpp:218] Iteration 10600 (6.98864 iter/s, 14.3089s/100 iters), loss = 0.28767
I0928 09:58:42.686930  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28767 (* 1 = 0.28767 loss)
I0928 09:58:42.686936  4247 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I0928 09:58:56.920683  4247 solver.cpp:218] Iteration 10700 (7.02558 iter/s, 14.2337s/100 iters), loss = 0.354751
I0928 09:58:56.920796  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35475 (* 1 = 0.35475 loss)
I0928 09:58:56.920814  4247 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I0928 09:59:11.168759  4247 solver.cpp:218] Iteration 10800 (7.01856 iter/s, 14.2479s/100 iters), loss = 0.318333
I0928 09:59:11.168800  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.318332 (* 1 = 0.318332 loss)
I0928 09:59:11.168807  4247 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I0928 09:59:25.406764  4247 solver.cpp:218] Iteration 10900 (7.0235 iter/s, 14.2379s/100 iters), loss = 0.211322
I0928 09:59:25.406805  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211321 (* 1 = 0.211321 loss)
I0928 09:59:25.406811  4247 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I0928 09:59:38.987987  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:59:39.559167  4247 solver.cpp:330] Iteration 11000, Testing net (#0)
I0928 09:59:42.914774  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 09:59:43.054576  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7915
I0928 09:59:43.054613  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.612481 (* 1 = 0.612481 loss)
I0928 09:59:43.195722  4247 solver.cpp:218] Iteration 11000 (5.62149 iter/s, 17.7889s/100 iters), loss = 0.340721
I0928 09:59:43.195755  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340721 (* 1 = 0.340721 loss)
I0928 09:59:43.195762  4247 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I0928 09:59:57.496923  4247 solver.cpp:218] Iteration 11100 (6.99246 iter/s, 14.3011s/100 iters), loss = 0.197872
I0928 09:59:57.496954  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197872 (* 1 = 0.197872 loss)
I0928 09:59:57.496960  4247 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I0928 10:00:11.745893  4247 solver.cpp:218] Iteration 11200 (7.01809 iter/s, 14.2489s/100 iters), loss = 0.293032
I0928 10:00:11.746035  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293032 (* 1 = 0.293032 loss)
I0928 10:00:11.746042  4247 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I0928 10:00:26.052420  4247 solver.cpp:218] Iteration 11300 (6.98991 iter/s, 14.3063s/100 iters), loss = 0.418343
I0928 10:00:26.052453  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.418343 (* 1 = 0.418343 loss)
I0928 10:00:26.052459  4247 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I0928 10:00:40.360563  4247 solver.cpp:218] Iteration 11400 (6.98907 iter/s, 14.3081s/100 iters), loss = 0.223488
I0928 10:00:40.360597  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223488 (* 1 = 0.223488 loss)
I0928 10:00:40.360605  4247 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I0928 10:00:53.895555  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:00:54.464025  4247 solver.cpp:330] Iteration 11500, Testing net (#0)
I0928 10:00:57.839419  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:00:57.979764  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7757
I0928 10:00:57.979800  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.662071 (* 1 = 0.662071 loss)
I0928 10:00:58.120573  4247 solver.cpp:218] Iteration 11500 (5.63066 iter/s, 17.7599s/100 iters), loss = 0.300393
I0928 10:00:58.120609  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300393 (* 1 = 0.300393 loss)
I0928 10:00:58.120616  4247 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I0928 10:01:12.396234  4247 solver.cpp:218] Iteration 11600 (7.00497 iter/s, 14.2756s/100 iters), loss = 0.269855
I0928 10:01:12.396266  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269855 (* 1 = 0.269855 loss)
I0928 10:01:12.396273  4247 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I0928 10:01:26.701079  4247 solver.cpp:218] Iteration 11700 (6.99068 iter/s, 14.3048s/100 iters), loss = 0.287198
I0928 10:01:26.701202  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287197 (* 1 = 0.287197 loss)
I0928 10:01:26.701210  4247 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I0928 10:01:40.944939  4247 solver.cpp:218] Iteration 11800 (7.02065 iter/s, 14.2437s/100 iters), loss = 0.278639
I0928 10:01:40.944972  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278639 (* 1 = 0.278639 loss)
I0928 10:01:40.944977  4247 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I0928 10:01:55.239867  4247 solver.cpp:218] Iteration 11900 (6.99553 iter/s, 14.2949s/100 iters), loss = 0.285624
I0928 10:01:55.239898  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285623 (* 1 = 0.285623 loss)
I0928 10:01:55.239905  4247 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I0928 10:02:08.764511  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:02:09.333170  4247 solver.cpp:330] Iteration 12000, Testing net (#0)
I0928 10:02:12.711977  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:02:12.853968  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8098
I0928 10:02:12.853994  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.551538 (* 1 = 0.551538 loss)
I0928 10:02:12.997117  4247 solver.cpp:218] Iteration 12000 (5.63153 iter/s, 17.7572s/100 iters), loss = 0.325233
I0928 10:02:12.997150  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325233 (* 1 = 0.325233 loss)
I0928 10:02:12.997156  4247 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I0928 10:02:27.290169  4247 solver.cpp:218] Iteration 12100 (6.99644 iter/s, 14.293s/100 iters), loss = 0.281045
I0928 10:02:27.290201  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281045 (* 1 = 0.281045 loss)
I0928 10:02:27.290208  4247 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I0928 10:02:41.525801  4247 solver.cpp:218] Iteration 12200 (7.02466 iter/s, 14.2356s/100 iters), loss = 0.308863
I0928 10:02:41.525921  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308863 (* 1 = 0.308863 loss)
I0928 10:02:41.525938  4247 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I0928 10:02:55.817503  4247 solver.cpp:218] Iteration 12300 (6.99714 iter/s, 14.2915s/100 iters), loss = 0.30337
I0928 10:02:55.817535  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30337 (* 1 = 0.30337 loss)
I0928 10:02:55.817541  4247 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I0928 10:03:10.103893  4247 solver.cpp:218] Iteration 12400 (6.99971 iter/s, 14.2863s/100 iters), loss = 0.19225
I0928 10:03:10.103927  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19225 (* 1 = 0.19225 loss)
I0928 10:03:10.103935  4247 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I0928 10:03:23.660895  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:03:24.231014  4247 solver.cpp:330] Iteration 12500, Testing net (#0)
I0928 10:03:27.584177  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:03:27.725661  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8326
I0928 10:03:27.725697  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.488282 (* 1 = 0.488282 loss)
I0928 10:03:27.867242  4247 solver.cpp:218] Iteration 12500 (5.6296 iter/s, 17.7633s/100 iters), loss = 0.24561
I0928 10:03:27.867269  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24561 (* 1 = 0.24561 loss)
I0928 10:03:27.867276  4247 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I0928 10:03:42.172592  4247 solver.cpp:218] Iteration 12600 (6.99043 iter/s, 14.3053s/100 iters), loss = 0.23635
I0928 10:03:42.172621  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23635 (* 1 = 0.23635 loss)
I0928 10:03:42.172626  4247 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I0928 10:03:56.484344  4247 solver.cpp:218] Iteration 12700 (6.9873 iter/s, 14.3117s/100 iters), loss = 0.317684
I0928 10:03:56.484463  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317684 (* 1 = 0.317684 loss)
I0928 10:03:56.484472  4247 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I0928 10:04:10.743216  4247 solver.cpp:218] Iteration 12800 (7.01325 iter/s, 14.2587s/100 iters), loss = 0.297147
I0928 10:04:10.743258  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297147 (* 1 = 0.297147 loss)
I0928 10:04:10.743264  4247 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I0928 10:04:25.065248  4247 solver.cpp:218] Iteration 12900 (6.98229 iter/s, 14.3219s/100 iters), loss = 0.221991
I0928 10:04:25.065289  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221991 (* 1 = 0.221991 loss)
I0928 10:04:25.065295  4247 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I0928 10:04:38.663599  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:04:39.233552  4247 solver.cpp:330] Iteration 13000, Testing net (#0)
I0928 10:04:42.602200  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:04:42.743796  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7847
I0928 10:04:42.743834  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.647574 (* 1 = 0.647574 loss)
I0928 10:04:42.886487  4247 solver.cpp:218] Iteration 13000 (5.61131 iter/s, 17.8211s/100 iters), loss = 0.216065
I0928 10:04:42.886518  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216065 (* 1 = 0.216065 loss)
I0928 10:04:42.886528  4247 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I0928 10:04:57.149106  4247 solver.cpp:218] Iteration 13100 (7.01137 iter/s, 14.2625s/100 iters), loss = 0.23516
I0928 10:04:57.149137  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23516 (* 1 = 0.23516 loss)
I0928 10:04:57.149143  4247 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I0928 10:05:11.473115  4247 solver.cpp:218] Iteration 13200 (6.98132 iter/s, 14.3239s/100 iters), loss = 0.345815
I0928 10:05:11.473242  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.345815 (* 1 = 0.345815 loss)
I0928 10:05:11.473259  4247 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I0928 10:05:25.742583  4247 solver.cpp:218] Iteration 13300 (7.00805 iter/s, 14.2693s/100 iters), loss = 0.213439
I0928 10:05:25.742627  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213439 (* 1 = 0.213439 loss)
I0928 10:05:25.742636  4247 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I0928 10:05:40.085578  4247 solver.cpp:218] Iteration 13400 (6.9722 iter/s, 14.3427s/100 iters), loss = 0.259222
I0928 10:05:40.085609  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259222 (* 1 = 0.259222 loss)
I0928 10:05:40.085616  4247 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I0928 10:05:53.690541  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:05:54.268682  4247 solver.cpp:330] Iteration 13500, Testing net (#0)
I0928 10:05:57.644001  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:05:57.785327  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.778
I0928 10:05:57.785367  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.659565 (* 1 = 0.659565 loss)
I0928 10:05:57.927434  4247 solver.cpp:218] Iteration 13500 (5.60483 iter/s, 17.8418s/100 iters), loss = 0.333379
I0928 10:05:57.927465  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333379 (* 1 = 0.333379 loss)
I0928 10:05:57.927472  4247 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I0928 10:06:12.227124  4247 solver.cpp:218] Iteration 13600 (6.9932 iter/s, 14.2996s/100 iters), loss = 0.315092
I0928 10:06:12.227159  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315092 (* 1 = 0.315092 loss)
I0928 10:06:12.227165  4247 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I0928 10:06:26.498633  4247 solver.cpp:218] Iteration 13700 (7.007 iter/s, 14.2714s/100 iters), loss = 0.29197
I0928 10:06:26.498718  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29197 (* 1 = 0.29197 loss)
I0928 10:06:26.498726  4247 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I0928 10:06:40.783713  4247 solver.cpp:218] Iteration 13800 (7.00038 iter/s, 14.2849s/100 iters), loss = 0.33046
I0928 10:06:40.783747  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.33046 (* 1 = 0.33046 loss)
I0928 10:06:40.783756  4247 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I0928 10:06:55.102272  4247 solver.cpp:218] Iteration 13900 (6.98398 iter/s, 14.3185s/100 iters), loss = 0.249219
I0928 10:06:55.102304  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249219 (* 1 = 0.249219 loss)
I0928 10:06:55.102310  4247 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I0928 10:07:08.629654  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:07:09.198385  4247 solver.cpp:330] Iteration 14000, Testing net (#0)
I0928 10:07:12.551592  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:07:12.692569  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7308
I0928 10:07:12.692595  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.86241 (* 1 = 0.86241 loss)
I0928 10:07:12.833487  4247 solver.cpp:218] Iteration 14000 (5.6398 iter/s, 17.7311s/100 iters), loss = 0.293725
I0928 10:07:12.833518  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293725 (* 1 = 0.293725 loss)
I0928 10:07:12.833523  4247 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I0928 10:07:27.191910  4247 solver.cpp:218] Iteration 14100 (6.96459 iter/s, 14.3583s/100 iters), loss = 0.209139
I0928 10:07:27.191942  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209139 (* 1 = 0.209139 loss)
I0928 10:07:27.191948  4247 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I0928 10:07:41.437969  4247 solver.cpp:218] Iteration 14200 (7.01952 iter/s, 14.246s/100 iters), loss = 0.29317
I0928 10:07:41.438112  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29317 (* 1 = 0.29317 loss)
I0928 10:07:41.438120  4247 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I0928 10:07:55.705926  4247 solver.cpp:218] Iteration 14300 (7.0088 iter/s, 14.2678s/100 iters), loss = 0.338807
I0928 10:07:55.705960  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338807 (* 1 = 0.338807 loss)
I0928 10:07:55.705966  4247 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I0928 10:08:10.024956  4247 solver.cpp:218] Iteration 14400 (6.98375 iter/s, 14.319s/100 iters), loss = 0.241327
I0928 10:08:10.025001  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241327 (* 1 = 0.241327 loss)
I0928 10:08:10.025007  4247 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I0928 10:08:23.567517  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:08:24.137588  4247 solver.cpp:330] Iteration 14500, Testing net (#0)
I0928 10:08:27.495931  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:08:27.636112  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8081
I0928 10:08:27.636150  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.583951 (* 1 = 0.583951 loss)
I0928 10:08:27.777312  4247 solver.cpp:218] Iteration 14500 (5.63309 iter/s, 17.7523s/100 iters), loss = 0.234373
I0928 10:08:27.777340  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234373 (* 1 = 0.234373 loss)
I0928 10:08:27.777346  4247 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I0928 10:08:42.000939  4247 solver.cpp:218] Iteration 14600 (7.03059 iter/s, 14.2236s/100 iters), loss = 0.385961
I0928 10:08:42.000982  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.385961 (* 1 = 0.385961 loss)
I0928 10:08:42.000988  4247 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I0928 10:08:56.228057  4247 solver.cpp:218] Iteration 14700 (7.02887 iter/s, 14.227s/100 iters), loss = 0.321976
I0928 10:08:56.228168  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.321977 (* 1 = 0.321977 loss)
I0928 10:08:56.228174  4247 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I0928 10:09:10.451684  4247 solver.cpp:218] Iteration 14800 (7.03063 iter/s, 14.2235s/100 iters), loss = 0.240247
I0928 10:09:10.451714  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240247 (* 1 = 0.240247 loss)
I0928 10:09:10.451719  4247 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I0928 10:09:24.674907  4247 solver.cpp:218] Iteration 14900 (7.03079 iter/s, 14.2231s/100 iters), loss = 0.161945
I0928 10:09:24.674949  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161945 (* 1 = 0.161945 loss)
I0928 10:09:24.674955  4247 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I0928 10:09:38.189052  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:09:38.758728  4247 solver.cpp:330] Iteration 15000, Testing net (#0)
I0928 10:09:42.115460  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:09:42.255698  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7354
I0928 10:09:42.255724  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.943476 (* 1 = 0.943476 loss)
I0928 10:09:42.397102  4247 solver.cpp:218] Iteration 15000 (5.64267 iter/s, 17.7221s/100 iters), loss = 0.206754
I0928 10:09:42.397130  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206754 (* 1 = 0.206754 loss)
I0928 10:09:42.397137  4247 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I0928 10:09:56.607300  4247 solver.cpp:218] Iteration 15100 (7.03724 iter/s, 14.2101s/100 iters), loss = 0.204716
I0928 10:09:56.607340  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204716 (* 1 = 0.204716 loss)
I0928 10:09:56.607347  4247 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I0928 10:10:10.818143  4247 solver.cpp:218] Iteration 15200 (7.03692 iter/s, 14.2108s/100 iters), loss = 0.340486
I0928 10:10:10.818270  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340486 (* 1 = 0.340486 loss)
I0928 10:10:10.818277  4247 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I0928 10:10:25.032919  4247 solver.cpp:218] Iteration 15300 (7.03501 iter/s, 14.2146s/100 iters), loss = 0.307238
I0928 10:10:25.032961  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307238 (* 1 = 0.307238 loss)
I0928 10:10:25.032968  4247 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I0928 10:10:39.245157  4247 solver.cpp:218] Iteration 15400 (7.03623 iter/s, 14.2122s/100 iters), loss = 0.296853
I0928 10:10:39.245199  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296853 (* 1 = 0.296853 loss)
I0928 10:10:39.245205  4247 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I0928 10:10:52.752598  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:10:53.320992  4247 solver.cpp:330] Iteration 15500, Testing net (#0)
I0928 10:10:56.679567  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:10:56.819949  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7116
I0928 10:10:56.819986  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.952587 (* 1 = 0.952587 loss)
I0928 10:10:56.961180  4247 solver.cpp:218] Iteration 15500 (5.64464 iter/s, 17.7159s/100 iters), loss = 0.285846
I0928 10:10:56.961210  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285846 (* 1 = 0.285846 loss)
I0928 10:10:56.961216  4247 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I0928 10:11:11.183459  4247 solver.cpp:218] Iteration 15600 (7.03126 iter/s, 14.2222s/100 iters), loss = 0.314978
I0928 10:11:11.183502  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314978 (* 1 = 0.314978 loss)
I0928 10:11:11.183508  4247 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I0928 10:11:25.413975  4247 solver.cpp:218] Iteration 15700 (7.02719 iter/s, 14.2304s/100 iters), loss = 0.285642
I0928 10:11:25.414103  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285642 (* 1 = 0.285642 loss)
I0928 10:11:25.414110  4247 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I0928 10:11:39.641882  4247 solver.cpp:218] Iteration 15800 (7.02852 iter/s, 14.2277s/100 iters), loss = 0.20244
I0928 10:11:39.641926  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20244 (* 1 = 0.20244 loss)
I0928 10:11:39.641930  4247 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I0928 10:11:53.871228  4247 solver.cpp:218] Iteration 15900 (7.02777 iter/s, 14.2293s/100 iters), loss = 0.16157
I0928 10:11:53.871270  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16157 (* 1 = 0.16157 loss)
I0928 10:11:53.871276  4247 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I0928 10:12:07.392772  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:12:07.960989  4247 solver.cpp:330] Iteration 16000, Testing net (#0)
I0928 10:12:11.318161  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:12:11.458359  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7719
I0928 10:12:11.458397  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.703572 (* 1 = 0.703572 loss)
I0928 10:12:11.599849  4247 solver.cpp:218] Iteration 16000 (5.64063 iter/s, 17.7285s/100 iters), loss = 0.267913
I0928 10:12:11.599879  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267913 (* 1 = 0.267913 loss)
I0928 10:12:11.599885  4247 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I0928 10:12:25.810536  4247 solver.cpp:218] Iteration 16100 (7.03699 iter/s, 14.2106s/100 iters), loss = 0.266641
I0928 10:12:25.810580  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266641 (* 1 = 0.266641 loss)
I0928 10:12:25.810586  4247 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I0928 10:12:40.025544  4247 solver.cpp:218] Iteration 16200 (7.03486 iter/s, 14.2149s/100 iters), loss = 0.30643
I0928 10:12:40.025609  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30643 (* 1 = 0.30643 loss)
I0928 10:12:40.025615  4247 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I0928 10:12:54.244035  4247 solver.cpp:218] Iteration 16300 (7.03315 iter/s, 14.2184s/100 iters), loss = 0.274429
I0928 10:12:54.244077  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274429 (* 1 = 0.274429 loss)
I0928 10:12:54.244083  4247 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I0928 10:13:08.465337  4247 solver.cpp:218] Iteration 16400 (7.03175 iter/s, 14.2212s/100 iters), loss = 0.113502
I0928 10:13:08.465368  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.113502 (* 1 = 0.113502 loss)
I0928 10:13:08.465374  4247 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I0928 10:13:21.977272  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:13:22.546213  4247 solver.cpp:330] Iteration 16500, Testing net (#0)
I0928 10:13:25.904903  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:13:26.045346  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8082
I0928 10:13:26.045383  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.577196 (* 1 = 0.577196 loss)
I0928 10:13:26.186707  4247 solver.cpp:218] Iteration 16500 (5.64293 iter/s, 17.7213s/100 iters), loss = 0.238389
I0928 10:13:26.186733  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238389 (* 1 = 0.238389 loss)
I0928 10:13:26.186740  4247 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I0928 10:13:40.405174  4247 solver.cpp:218] Iteration 16600 (7.03314 iter/s, 14.2184s/100 iters), loss = 0.212451
I0928 10:13:40.405205  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212451 (* 1 = 0.212451 loss)
I0928 10:13:40.405211  4247 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I0928 10:13:54.630849  4247 solver.cpp:218] Iteration 16700 (7.02958 iter/s, 14.2256s/100 iters), loss = 0.418816
I0928 10:13:54.631000  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.418816 (* 1 = 0.418816 loss)
I0928 10:13:54.631016  4247 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I0928 10:14:08.858413  4247 solver.cpp:218] Iteration 16800 (7.0287 iter/s, 14.2274s/100 iters), loss = 0.256332
I0928 10:14:08.858455  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256332 (* 1 = 0.256332 loss)
I0928 10:14:08.858461  4247 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I0928 10:14:23.081887  4247 solver.cpp:218] Iteration 16900 (7.03067 iter/s, 14.2234s/100 iters), loss = 0.171163
I0928 10:14:23.081929  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171164 (* 1 = 0.171164 loss)
I0928 10:14:23.081934  4247 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I0928 10:14:36.594063  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:14:37.162518  4247 solver.cpp:330] Iteration 17000, Testing net (#0)
I0928 10:14:40.522363  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:14:40.662760  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6499
I0928 10:14:40.662797  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.42079 (* 1 = 1.42079 loss)
I0928 10:14:40.803838  4247 solver.cpp:218] Iteration 17000 (5.64275 iter/s, 17.7219s/100 iters), loss = 0.286241
I0928 10:14:40.803869  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286241 (* 1 = 0.286241 loss)
I0928 10:14:40.803874  4247 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I0928 10:14:55.018944  4247 solver.cpp:218] Iteration 17100 (7.03481 iter/s, 14.215s/100 iters), loss = 0.193269
I0928 10:14:55.018986  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193269 (* 1 = 0.193269 loss)
I0928 10:14:55.018991  4247 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I0928 10:15:09.235349  4247 solver.cpp:218] Iteration 17200 (7.03417 iter/s, 14.2163s/100 iters), loss = 0.27365
I0928 10:15:09.235466  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27365 (* 1 = 0.27365 loss)
I0928 10:15:09.235482  4247 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I0928 10:15:23.453224  4247 solver.cpp:218] Iteration 17300 (7.03347 iter/s, 14.2177s/100 iters), loss = 0.289078
I0928 10:15:23.453267  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289078 (* 1 = 0.289078 loss)
I0928 10:15:23.453272  4247 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I0928 10:15:37.671371  4247 solver.cpp:218] Iteration 17400 (7.03331 iter/s, 14.2181s/100 iters), loss = 0.219141
I0928 10:15:37.671413  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219141 (* 1 = 0.219141 loss)
I0928 10:15:37.671419  4247 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I0928 10:15:51.181789  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:15:51.750638  4247 solver.cpp:330] Iteration 17500, Testing net (#0)
I0928 10:15:55.107807  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:15:55.248309  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6906
I0928 10:15:55.248347  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.14622 (* 1 = 1.14622 loss)
I0928 10:15:55.389319  4247 solver.cpp:218] Iteration 17500 (5.64403 iter/s, 17.7179s/100 iters), loss = 0.231755
I0928 10:15:55.389348  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231755 (* 1 = 0.231755 loss)
I0928 10:15:55.389354  4247 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I0928 10:16:09.609725  4247 solver.cpp:218] Iteration 17600 (7.03219 iter/s, 14.2203s/100 iters), loss = 0.253624
I0928 10:16:09.609769  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253625 (* 1 = 0.253625 loss)
I0928 10:16:09.609776  4247 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I0928 10:16:23.828974  4247 solver.cpp:218] Iteration 17700 (7.03276 iter/s, 14.2192s/100 iters), loss = 0.18276
I0928 10:16:23.829115  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18276 (* 1 = 0.18276 loss)
I0928 10:16:23.829133  4247 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I0928 10:16:38.049278  4247 solver.cpp:218] Iteration 17800 (7.03229 iter/s, 14.2201s/100 iters), loss = 0.202203
I0928 10:16:38.049321  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202204 (* 1 = 0.202204 loss)
I0928 10:16:38.049327  4247 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I0928 10:16:52.267593  4247 solver.cpp:218] Iteration 17900 (7.03323 iter/s, 14.2182s/100 iters), loss = 0.153458
I0928 10:16:52.267634  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153459 (* 1 = 0.153459 loss)
I0928 10:16:52.267640  4247 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I0928 10:17:05.782281  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:17:06.351397  4247 solver.cpp:330] Iteration 18000, Testing net (#0)
I0928 10:17:09.707393  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:17:09.847889  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6982
I0928 10:17:09.847928  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.0926 (* 1 = 1.0926 loss)
I0928 10:17:09.988978  4247 solver.cpp:218] Iteration 18000 (5.64293 iter/s, 17.7213s/100 iters), loss = 0.274188
I0928 10:17:09.989008  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274188 (* 1 = 0.274188 loss)
I0928 10:17:09.989015  4247 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I0928 10:17:24.215610  4247 solver.cpp:218] Iteration 18100 (7.02911 iter/s, 14.2266s/100 iters), loss = 0.269468
I0928 10:17:24.215652  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269468 (* 1 = 0.269468 loss)
I0928 10:17:24.215658  4247 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I0928 10:17:38.503590  4247 solver.cpp:218] Iteration 18200 (6.99893 iter/s, 14.2879s/100 iters), loss = 0.251981
I0928 10:17:38.503736  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251981 (* 1 = 0.251981 loss)
I0928 10:17:38.503744  4247 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I0928 10:17:52.784186  4247 solver.cpp:218] Iteration 18300 (7.0026 iter/s, 14.2804s/100 iters), loss = 0.251348
I0928 10:17:52.784229  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251348 (* 1 = 0.251348 loss)
I0928 10:17:52.784235  4247 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I0928 10:18:07.011586  4247 solver.cpp:218] Iteration 18400 (7.02873 iter/s, 14.2273s/100 iters), loss = 0.147385
I0928 10:18:07.011627  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147385 (* 1 = 0.147385 loss)
I0928 10:18:07.011633  4247 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I0928 10:18:20.555876  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:18:21.129003  4247 solver.cpp:330] Iteration 18500, Testing net (#0)
I0928 10:18:24.487872  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:18:24.628015  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7661
I0928 10:18:24.628041  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.776043 (* 1 = 0.776043 loss)
I0928 10:18:24.769112  4247 solver.cpp:218] Iteration 18500 (5.63145 iter/s, 17.7574s/100 iters), loss = 0.216209
I0928 10:18:24.769141  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216209 (* 1 = 0.216209 loss)
I0928 10:18:24.769148  4247 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I0928 10:18:39.029490  4247 solver.cpp:218] Iteration 18600 (7.01247 iter/s, 14.2603s/100 iters), loss = 0.238318
I0928 10:18:39.029520  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238318 (* 1 = 0.238318 loss)
I0928 10:18:39.029526  4247 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I0928 10:18:53.353087  4247 solver.cpp:218] Iteration 18700 (6.98152 iter/s, 14.3235s/100 iters), loss = 0.313669
I0928 10:18:53.353216  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313669 (* 1 = 0.313669 loss)
I0928 10:18:53.353232  4247 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I0928 10:19:07.714620  4247 solver.cpp:218] Iteration 18800 (6.96312 iter/s, 14.3614s/100 iters), loss = 0.225216
I0928 10:19:07.714658  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225217 (* 1 = 0.225217 loss)
I0928 10:19:07.714679  4247 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I0928 10:19:22.106402  4247 solver.cpp:218] Iteration 18900 (6.94845 iter/s, 14.3917s/100 iters), loss = 0.218347
I0928 10:19:22.106436  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218347 (* 1 = 0.218347 loss)
I0928 10:19:22.106446  4247 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I0928 10:19:35.765558  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:19:36.351621  4247 solver.cpp:330] Iteration 19000, Testing net (#0)
I0928 10:19:39.742442  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:19:39.882743  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7675
I0928 10:19:39.882781  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.76148 (* 1 = 0.76148 loss)
I0928 10:19:40.023891  4247 solver.cpp:218] Iteration 19000 (5.58117 iter/s, 17.9174s/100 iters), loss = 0.158818
I0928 10:19:40.023921  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158818 (* 1 = 0.158818 loss)
I0928 10:19:40.023927  4247 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I0928 10:19:54.428323  4247 solver.cpp:218] Iteration 19100 (6.94234 iter/s, 14.4044s/100 iters), loss = 0.198171
I0928 10:19:54.428357  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198171 (* 1 = 0.198171 loss)
I0928 10:19:54.428373  4247 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I0928 10:20:08.821532  4247 solver.cpp:218] Iteration 19200 (6.94776 iter/s, 14.3931s/100 iters), loss = 0.297999
I0928 10:20:08.821669  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297999 (* 1 = 0.297999 loss)
I0928 10:20:08.821677  4247 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I0928 10:20:23.233423  4247 solver.cpp:218] Iteration 19300 (6.9388 iter/s, 14.4117s/100 iters), loss = 0.294807
I0928 10:20:23.233456  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294807 (* 1 = 0.294807 loss)
I0928 10:20:23.233463  4247 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I0928 10:20:37.649750  4247 solver.cpp:218] Iteration 19400 (6.93662 iter/s, 14.4163s/100 iters), loss = 0.260954
I0928 10:20:37.649796  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260954 (* 1 = 0.260954 loss)
I0928 10:20:37.649812  4247 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I0928 10:20:51.370882  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:20:51.941296  4247 solver.cpp:330] Iteration 19500, Testing net (#0)
I0928 10:20:55.302634  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:20:55.442636  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7863
I0928 10:20:55.442673  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.724744 (* 1 = 0.724744 loss)
I0928 10:20:55.583662  4247 solver.cpp:218] Iteration 19500 (5.57609 iter/s, 17.9337s/100 iters), loss = 0.132838
I0928 10:20:55.583689  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132839 (* 1 = 0.132839 loss)
I0928 10:20:55.583695  4247 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I0928 10:21:09.902062  4247 solver.cpp:218] Iteration 19600 (6.98406 iter/s, 14.3183s/100 iters), loss = 0.206501
I0928 10:21:09.902108  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206501 (* 1 = 0.206501 loss)
I0928 10:21:09.902115  4247 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I0928 10:21:24.214833  4247 solver.cpp:218] Iteration 19700 (6.98689 iter/s, 14.3125s/100 iters), loss = 0.23942
I0928 10:21:24.214936  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23942 (* 1 = 0.23942 loss)
I0928 10:21:24.214954  4247 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I0928 10:21:38.565842  4247 solver.cpp:218] Iteration 19800 (6.96822 iter/s, 14.3509s/100 iters), loss = 0.153185
I0928 10:21:38.565876  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153185 (* 1 = 0.153185 loss)
I0928 10:21:38.565881  4247 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I0928 10:21:52.946280  4247 solver.cpp:218] Iteration 19900 (6.95393 iter/s, 14.3804s/100 iters), loss = 0.141866
I0928 10:21:52.946315  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.141866 (* 1 = 0.141866 loss)
I0928 10:21:52.946321  4247 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I0928 10:22:06.655107  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:22:07.229080  4247 solver.cpp:330] Iteration 20000, Testing net (#0)
I0928 10:22:10.648247  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:22:10.794047  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7163
I0928 10:22:10.794075  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.972528 (* 1 = 0.972528 loss)
I0928 10:22:10.938866  4247 solver.cpp:218] Iteration 20000 (5.55787 iter/s, 17.9925s/100 iters), loss = 0.258823
I0928 10:22:10.938899  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258823 (* 1 = 0.258823 loss)
I0928 10:22:10.938906  4247 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I0928 10:22:25.349887  4247 solver.cpp:218] Iteration 20100 (6.93917 iter/s, 14.4109s/100 iters), loss = 0.253365
I0928 10:22:25.349920  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253365 (* 1 = 0.253365 loss)
I0928 10:22:25.349925  4247 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I0928 10:22:39.765724  4247 solver.cpp:218] Iteration 20200 (6.93685 iter/s, 14.4158s/100 iters), loss = 0.211974
I0928 10:22:39.765836  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211975 (* 1 = 0.211975 loss)
I0928 10:22:39.765853  4247 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I0928 10:22:54.168145  4247 solver.cpp:218] Iteration 20300 (6.94335 iter/s, 14.4023s/100 iters), loss = 0.154002
I0928 10:22:54.168177  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154002 (* 1 = 0.154002 loss)
I0928 10:22:54.168184  4247 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I0928 10:23:08.487586  4247 solver.cpp:218] Iteration 20400 (6.98355 iter/s, 14.3194s/100 iters), loss = 0.171567
I0928 10:23:08.487618  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171568 (* 1 = 0.171568 loss)
I0928 10:23:08.487627  4247 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I0928 10:23:22.117866  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:23:22.699575  4247 solver.cpp:330] Iteration 20500, Testing net (#0)
I0928 10:23:26.098987  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:23:26.239068  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6722
I0928 10:23:26.239104  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.16524 (* 1 = 1.16524 loss)
I0928 10:23:26.383690  4247 solver.cpp:218] Iteration 20500 (5.58784 iter/s, 17.896s/100 iters), loss = 0.230937
I0928 10:23:26.383725  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230938 (* 1 = 0.230938 loss)
I0928 10:23:26.383731  4247 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I0928 10:23:40.743571  4247 solver.cpp:218] Iteration 20600 (6.96389 iter/s, 14.3598s/100 iters), loss = 0.152303
I0928 10:23:40.743602  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152303 (* 1 = 0.152303 loss)
I0928 10:23:40.743607  4247 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I0928 10:23:55.173102  4247 solver.cpp:218] Iteration 20700 (6.93027 iter/s, 14.4295s/100 iters), loss = 0.195364
I0928 10:23:55.173254  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195364 (* 1 = 0.195364 loss)
I0928 10:23:55.173264  4247 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I0928 10:24:09.621773  4247 solver.cpp:218] Iteration 20800 (6.92115 iter/s, 14.4485s/100 iters), loss = 0.208746
I0928 10:24:09.621803  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208746 (* 1 = 0.208746 loss)
I0928 10:24:09.621810  4247 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I0928 10:24:24.069059  4247 solver.cpp:218] Iteration 20900 (6.92175 iter/s, 14.4472s/100 iters), loss = 0.17196
I0928 10:24:24.069092  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17196 (* 1 = 0.17196 loss)
I0928 10:24:24.069099  4247 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I0928 10:24:37.792845  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:24:38.369894  4247 solver.cpp:330] Iteration 21000, Testing net (#0)
I0928 10:24:41.758807  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:24:41.899305  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6868
I0928 10:24:41.899343  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.07747 (* 1 = 1.07747 loss)
I0928 10:24:42.040961  4247 solver.cpp:218] Iteration 21000 (5.56427 iter/s, 17.9718s/100 iters), loss = 0.303469
I0928 10:24:42.040992  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303469 (* 1 = 0.303469 loss)
I0928 10:24:42.040999  4247 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I0928 10:24:56.479471  4247 solver.cpp:218] Iteration 21100 (6.92596 iter/s, 14.4384s/100 iters), loss = 0.213188
I0928 10:24:56.479502  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213188 (* 1 = 0.213188 loss)
I0928 10:24:56.479509  4247 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I0928 10:25:10.902225  4247 solver.cpp:218] Iteration 21200 (6.93352 iter/s, 14.4227s/100 iters), loss = 0.212824
I0928 10:25:10.902328  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212824 (* 1 = 0.212824 loss)
I0928 10:25:10.902335  4247 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I0928 10:25:25.283865  4247 solver.cpp:218] Iteration 21300 (6.95338 iter/s, 14.3815s/100 iters), loss = 0.271517
I0928 10:25:25.283901  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271517 (* 1 = 0.271517 loss)
I0928 10:25:25.283907  4247 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I0928 10:25:39.710614  4247 solver.cpp:218] Iteration 21400 (6.93161 iter/s, 14.4267s/100 iters), loss = 0.157187
I0928 10:25:39.710649  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157187 (* 1 = 0.157187 loss)
I0928 10:25:39.710656  4247 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I0928 10:25:53.422683  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:25:54.004096  4247 solver.cpp:330] Iteration 21500, Testing net (#0)
I0928 10:25:57.376143  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:25:57.516948  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7375
I0928 10:25:57.516975  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.954154 (* 1 = 0.954154 loss)
I0928 10:25:57.658795  4247 solver.cpp:218] Iteration 21500 (5.57162 iter/s, 17.9481s/100 iters), loss = 0.198965
I0928 10:25:57.658826  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198965 (* 1 = 0.198965 loss)
I0928 10:25:57.658833  4247 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I0928 10:26:11.990380  4247 solver.cpp:218] Iteration 21600 (6.97763 iter/s, 14.3315s/100 iters), loss = 0.159228
I0928 10:26:11.990413  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159228 (* 1 = 0.159228 loss)
I0928 10:26:11.990420  4247 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I0928 10:26:26.303187  4247 solver.cpp:218] Iteration 21700 (6.98679 iter/s, 14.3127s/100 iters), loss = 0.216485
I0928 10:26:26.303318  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216485 (* 1 = 0.216485 loss)
I0928 10:26:26.303336  4247 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I0928 10:26:40.559026  4247 solver.cpp:218] Iteration 21800 (7.01476 iter/s, 14.2557s/100 iters), loss = 0.177285
I0928 10:26:40.559067  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177285 (* 1 = 0.177285 loss)
I0928 10:26:40.559074  4247 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I0928 10:26:54.766580  4247 solver.cpp:218] Iteration 21900 (7.03855 iter/s, 14.2075s/100 iters), loss = 0.233392
I0928 10:26:54.766623  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233392 (* 1 = 0.233392 loss)
I0928 10:26:54.766628  4247 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I0928 10:27:08.293287  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:27:08.864576  4247 solver.cpp:330] Iteration 22000, Testing net (#0)
I0928 10:27:12.222883  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:27:12.363541  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7753
I0928 10:27:12.363579  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.739342 (* 1 = 0.739342 loss)
I0928 10:27:12.504938  4247 solver.cpp:218] Iteration 22000 (5.63753 iter/s, 17.7383s/100 iters), loss = 0.138656
I0928 10:27:12.504968  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.138656 (* 1 = 0.138656 loss)
I0928 10:27:12.504974  4247 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I0928 10:27:26.717998  4247 solver.cpp:218] Iteration 22100 (7.03582 iter/s, 14.213s/100 iters), loss = 0.188451
I0928 10:27:26.718031  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188451 (* 1 = 0.188451 loss)
I0928 10:27:26.718037  4247 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I0928 10:27:40.941527  4247 solver.cpp:218] Iteration 22200 (7.03064 iter/s, 14.2235s/100 iters), loss = 0.273541
I0928 10:27:40.941627  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273542 (* 1 = 0.273542 loss)
I0928 10:27:40.941635  4247 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I0928 10:27:55.166062  4247 solver.cpp:218] Iteration 22300 (7.03018 iter/s, 14.2244s/100 iters), loss = 0.243465
I0928 10:27:55.166105  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243466 (* 1 = 0.243466 loss)
I0928 10:27:55.166111  4247 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I0928 10:28:09.386332  4247 solver.cpp:218] Iteration 22400 (7.03226 iter/s, 14.2202s/100 iters), loss = 0.161166
I0928 10:28:09.386363  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161167 (* 1 = 0.161167 loss)
I0928 10:28:09.386368  4247 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I0928 10:28:22.899497  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:28:23.468794  4247 solver.cpp:330] Iteration 22500, Testing net (#0)
I0928 10:28:26.825327  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:28:26.966197  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.768
I0928 10:28:26.966223  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.7253 (* 1 = 0.7253 loss)
I0928 10:28:27.107574  4247 solver.cpp:218] Iteration 22500 (5.64297 iter/s, 17.7212s/100 iters), loss = 0.176004
I0928 10:28:27.107604  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176005 (* 1 = 0.176005 loss)
I0928 10:28:27.107610  4247 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I0928 10:28:41.325963  4247 solver.cpp:218] Iteration 22600 (7.03318 iter/s, 14.2183s/100 iters), loss = 0.231073
I0928 10:28:41.326004  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231073 (* 1 = 0.231073 loss)
I0928 10:28:41.326010  4247 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I0928 10:28:55.544106  4247 solver.cpp:218] Iteration 22700 (7.03331 iter/s, 14.2181s/100 iters), loss = 0.349891
I0928 10:28:55.544209  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349892 (* 1 = 0.349892 loss)
I0928 10:28:55.544224  4247 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I0928 10:29:09.758127  4247 solver.cpp:218] Iteration 22800 (7.03538 iter/s, 14.2139s/100 iters), loss = 0.250693
I0928 10:29:09.758159  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250693 (* 1 = 0.250693 loss)
I0928 10:29:09.758165  4247 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I0928 10:29:23.975353  4247 solver.cpp:218] Iteration 22900 (7.03376 iter/s, 14.2172s/100 iters), loss = 0.299462
I0928 10:29:23.975394  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299462 (* 1 = 0.299462 loss)
I0928 10:29:23.975399  4247 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I0928 10:29:37.486748  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:29:38.055624  4247 solver.cpp:330] Iteration 23000, Testing net (#0)
I0928 10:29:41.412638  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:29:41.553505  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7086
I0928 10:29:41.553542  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.06763 (* 1 = 1.06763 loss)
I0928 10:29:41.694375  4247 solver.cpp:218] Iteration 23000 (5.64368 iter/s, 17.7189s/100 iters), loss = 0.170191
I0928 10:29:41.694403  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170191 (* 1 = 0.170191 loss)
I0928 10:29:41.694411  4247 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I0928 10:29:55.909823  4247 solver.cpp:218] Iteration 23100 (7.03464 iter/s, 14.2154s/100 iters), loss = 0.166877
I0928 10:29:55.909865  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166877 (* 1 = 0.166877 loss)
I0928 10:29:55.909870  4247 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I0928 10:30:10.135044  4247 solver.cpp:218] Iteration 23200 (7.02981 iter/s, 14.2251s/100 iters), loss = 0.220203
I0928 10:30:10.135110  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220203 (* 1 = 0.220203 loss)
I0928 10:30:10.135118  4247 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I0928 10:30:24.359323  4247 solver.cpp:218] Iteration 23300 (7.03029 iter/s, 14.2242s/100 iters), loss = 0.265288
I0928 10:30:24.359364  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265289 (* 1 = 0.265289 loss)
I0928 10:30:24.359370  4247 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I0928 10:30:38.581744  4247 solver.cpp:218] Iteration 23400 (7.03119 iter/s, 14.2223s/100 iters), loss = 0.148929
I0928 10:30:38.581785  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148929 (* 1 = 0.148929 loss)
I0928 10:30:38.581791  4247 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I0928 10:30:52.096732  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:30:52.667274  4247 solver.cpp:330] Iteration 23500, Testing net (#0)
I0928 10:30:56.024583  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:30:56.165406  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6986
I0928 10:30:56.165434  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.08671 (* 1 = 1.08671 loss)
I0928 10:30:56.307065  4247 solver.cpp:218] Iteration 23500 (5.64168 iter/s, 17.7252s/100 iters), loss = 0.24322
I0928 10:30:56.307092  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24322 (* 1 = 0.24322 loss)
I0928 10:30:56.307099  4247 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I0928 10:31:10.530230  4247 solver.cpp:218] Iteration 23600 (7.03082 iter/s, 14.2231s/100 iters), loss = 0.155801
I0928 10:31:10.530263  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155802 (* 1 = 0.155802 loss)
I0928 10:31:10.530269  4247 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I0928 10:31:24.757015  4247 solver.cpp:218] Iteration 23700 (7.02903 iter/s, 14.2267s/100 iters), loss = 0.312714
I0928 10:31:24.757153  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312714 (* 1 = 0.312714 loss)
I0928 10:31:24.757160  4247 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I0928 10:31:38.982305  4247 solver.cpp:218] Iteration 23800 (7.02982 iter/s, 14.2251s/100 iters), loss = 0.246842
I0928 10:31:38.982347  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246842 (* 1 = 0.246842 loss)
I0928 10:31:38.982353  4247 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I0928 10:31:53.207064  4247 solver.cpp:218] Iteration 23900 (7.03004 iter/s, 14.2247s/100 iters), loss = 0.193336
I0928 10:31:53.207098  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193337 (* 1 = 0.193337 loss)
I0928 10:31:53.207103  4247 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I0928 10:32:06.725873  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:32:07.294272  4247 solver.cpp:330] Iteration 24000, Testing net (#0)
I0928 10:32:10.651130  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:32:10.791246  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6821
I0928 10:32:10.791282  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.26519 (* 1 = 1.26519 loss)
I0928 10:32:10.932284  4247 solver.cpp:218] Iteration 24000 (5.64171 iter/s, 17.7251s/100 iters), loss = 0.171549
I0928 10:32:10.932312  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171549 (* 1 = 0.171549 loss)
I0928 10:32:10.932319  4247 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I0928 10:32:25.145448  4247 solver.cpp:218] Iteration 24100 (7.03577 iter/s, 14.2131s/100 iters), loss = 0.243812
I0928 10:32:25.145490  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243812 (* 1 = 0.243812 loss)
I0928 10:32:25.145496  4247 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I0928 10:32:39.360924  4247 solver.cpp:218] Iteration 24200 (7.03463 iter/s, 14.2154s/100 iters), loss = 0.17663
I0928 10:32:39.361042  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17663 (* 1 = 0.17663 loss)
I0928 10:32:39.361060  4247 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I0928 10:32:53.579016  4247 solver.cpp:218] Iteration 24300 (7.03337 iter/s, 14.2179s/100 iters), loss = 0.209038
I0928 10:32:53.579058  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209038 (* 1 = 0.209038 loss)
I0928 10:32:53.579064  4247 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I0928 10:33:07.799429  4247 solver.cpp:218] Iteration 24400 (7.03219 iter/s, 14.2203s/100 iters), loss = 0.210986
I0928 10:33:07.799471  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210986 (* 1 = 0.210986 loss)
I0928 10:33:07.799476  4247 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I0928 10:33:21.308288  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:33:21.877063  4247 solver.cpp:330] Iteration 24500, Testing net (#0)
I0928 10:33:25.234239  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:33:25.374450  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7479
I0928 10:33:25.374475  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.851881 (* 1 = 0.851881 loss)
I0928 10:33:25.515548  4247 solver.cpp:218] Iteration 24500 (5.64461 iter/s, 17.716s/100 iters), loss = 0.180963
I0928 10:33:25.515576  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180963 (* 1 = 0.180963 loss)
I0928 10:33:25.515583  4247 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I0928 10:33:39.728701  4247 solver.cpp:218] Iteration 24600 (7.03577 iter/s, 14.2131s/100 iters), loss = 0.188394
I0928 10:33:39.728734  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188395 (* 1 = 0.188395 loss)
I0928 10:33:39.728739  4247 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I0928 10:33:53.942889  4247 solver.cpp:218] Iteration 24700 (7.03526 iter/s, 14.2141s/100 iters), loss = 0.390343
I0928 10:33:53.943022  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.390343 (* 1 = 0.390343 loss)
I0928 10:33:53.943039  4247 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I0928 10:34:08.160728  4247 solver.cpp:218] Iteration 24800 (7.0335 iter/s, 14.2177s/100 iters), loss = 0.265987
I0928 10:34:08.160759  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265988 (* 1 = 0.265988 loss)
I0928 10:34:08.160774  4247 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I0928 10:34:22.376873  4247 solver.cpp:218] Iteration 24900 (7.03429 iter/s, 14.2161s/100 iters), loss = 0.192651
I0928 10:34:22.376904  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192651 (* 1 = 0.192651 loss)
I0928 10:34:22.376909  4247 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I0928 10:34:35.882637  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:34:36.450513  4247 solver.cpp:330] Iteration 25000, Testing net (#0)
I0928 10:34:39.806879  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:34:39.947206  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7779
I0928 10:34:39.947230  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.699909 (* 1 = 0.699909 loss)
I0928 10:34:40.088784  4247 solver.cpp:218] Iteration 25000 (5.64594 iter/s, 17.7118s/100 iters), loss = 0.165235
I0928 10:34:40.088814  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165236 (* 1 = 0.165236 loss)
I0928 10:34:40.088820  4247 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I0928 10:34:54.306336  4247 solver.cpp:218] Iteration 25100 (7.0336 iter/s, 14.2175s/100 iters), loss = 0.197194
I0928 10:34:54.306378  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197194 (* 1 = 0.197194 loss)
I0928 10:34:54.306385  4247 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I0928 10:35:08.523125  4247 solver.cpp:218] Iteration 25200 (7.03398 iter/s, 14.2167s/100 iters), loss = 0.205967
I0928 10:35:08.523267  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205967 (* 1 = 0.205967 loss)
I0928 10:35:08.523274  4247 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I0928 10:35:22.739573  4247 solver.cpp:218] Iteration 25300 (7.0342 iter/s, 14.2163s/100 iters), loss = 0.194587
I0928 10:35:22.739606  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194587 (* 1 = 0.194587 loss)
I0928 10:35:22.739622  4247 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I0928 10:35:36.960064  4247 solver.cpp:218] Iteration 25400 (7.03215 iter/s, 14.2204s/100 iters), loss = 0.0944419
I0928 10:35:36.960101  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0944422 (* 1 = 0.0944422 loss)
I0928 10:35:36.960119  4247 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I0928 10:35:50.471109  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:35:51.040565  4247 solver.cpp:330] Iteration 25500, Testing net (#0)
I0928 10:35:54.394727  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:35:54.534934  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7089
I0928 10:35:54.534960  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.903966 (* 1 = 0.903966 loss)
I0928 10:35:54.675711  4247 solver.cpp:218] Iteration 25500 (5.64476 iter/s, 17.7156s/100 iters), loss = 0.157693
I0928 10:35:54.675740  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157693 (* 1 = 0.157693 loss)
I0928 10:35:54.675747  4247 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I0928 10:36:08.890525  4247 solver.cpp:218] Iteration 25600 (7.03495 iter/s, 14.2147s/100 iters), loss = 0.202355
I0928 10:36:08.890557  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202355 (* 1 = 0.202355 loss)
I0928 10:36:08.890563  4247 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I0928 10:36:23.104435  4247 solver.cpp:218] Iteration 25700 (7.0354 iter/s, 14.2138s/100 iters), loss = 0.189261
I0928 10:36:23.104543  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189262 (* 1 = 0.189262 loss)
I0928 10:36:23.104549  4247 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I0928 10:36:37.320696  4247 solver.cpp:218] Iteration 25800 (7.03427 iter/s, 14.2161s/100 iters), loss = 0.19948
I0928 10:36:37.320729  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19948 (* 1 = 0.19948 loss)
I0928 10:36:37.320734  4247 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I0928 10:36:51.539424  4247 solver.cpp:218] Iteration 25900 (7.03302 iter/s, 14.2187s/100 iters), loss = 0.194697
I0928 10:36:51.539455  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194697 (* 1 = 0.194697 loss)
I0928 10:36:51.539461  4247 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I0928 10:37:05.049842  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:37:05.618677  4247 solver.cpp:330] Iteration 26000, Testing net (#0)
I0928 10:37:08.975075  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:37:09.115854  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6919
I0928 10:37:09.115890  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.2383 (* 1 = 1.2383 loss)
I0928 10:37:09.256615  4247 solver.cpp:218] Iteration 26000 (5.64426 iter/s, 17.7171s/100 iters), loss = 0.216565
I0928 10:37:09.256642  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216565 (* 1 = 0.216565 loss)
I0928 10:37:09.256649  4247 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I0928 10:37:23.458295  4247 solver.cpp:218] Iteration 26100 (7.04146 iter/s, 14.2016s/100 iters), loss = 0.164096
I0928 10:37:23.458338  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164096 (* 1 = 0.164096 loss)
I0928 10:37:23.458343  4247 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I0928 10:37:37.670047  4247 solver.cpp:218] Iteration 26200 (7.03647 iter/s, 14.2117s/100 iters), loss = 0.203274
I0928 10:37:37.670172  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203274 (* 1 = 0.203274 loss)
I0928 10:37:37.670179  4247 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I0928 10:37:51.874496  4247 solver.cpp:218] Iteration 26300 (7.04013 iter/s, 14.2043s/100 iters), loss = 0.264314
I0928 10:37:51.874541  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264315 (* 1 = 0.264315 loss)
I0928 10:37:51.874547  4247 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I0928 10:38:06.079457  4247 solver.cpp:218] Iteration 26400 (7.03984 iter/s, 14.2049s/100 iters), loss = 0.197941
I0928 10:38:06.079488  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197941 (* 1 = 0.197941 loss)
I0928 10:38:06.079494  4247 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I0928 10:38:19.583524  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:38:20.151865  4247 solver.cpp:330] Iteration 26500, Testing net (#0)
I0928 10:38:23.505962  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:38:23.646083  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7192
I0928 10:38:23.646121  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.965759 (* 1 = 0.965759 loss)
I0928 10:38:23.787278  4247 solver.cpp:218] Iteration 26500 (5.64725 iter/s, 17.7077s/100 iters), loss = 0.184974
I0928 10:38:23.787307  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184974 (* 1 = 0.184974 loss)
I0928 10:38:23.787314  4247 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I0928 10:38:37.994577  4247 solver.cpp:218] Iteration 26600 (7.03867 iter/s, 14.2072s/100 iters), loss = 0.199173
I0928 10:38:37.994609  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199173 (* 1 = 0.199173 loss)
I0928 10:38:37.994616  4247 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I0928 10:38:52.208498  4247 solver.cpp:218] Iteration 26700 (7.03539 iter/s, 14.2138s/100 iters), loss = 0.198929
I0928 10:38:52.208573  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198929 (* 1 = 0.198929 loss)
I0928 10:38:52.208588  4247 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I0928 10:39:06.418531  4247 solver.cpp:218] Iteration 26800 (7.03734 iter/s, 14.2099s/100 iters), loss = 0.178326
I0928 10:39:06.418572  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178327 (* 1 = 0.178327 loss)
I0928 10:39:06.418578  4247 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I0928 10:39:20.625095  4247 solver.cpp:218] Iteration 26900 (7.03904 iter/s, 14.2065s/100 iters), loss = 0.114453
I0928 10:39:20.625136  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114454 (* 1 = 0.114454 loss)
I0928 10:39:20.625142  4247 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I0928 10:39:34.130548  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:39:34.700707  4247 solver.cpp:330] Iteration 27000, Testing net (#0)
I0928 10:39:38.057821  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:39:38.197860  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6424
I0928 10:39:38.197896  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.32903 (* 1 = 1.32903 loss)
I0928 10:39:38.339390  4247 solver.cpp:218] Iteration 27000 (5.64519 iter/s, 17.7142s/100 iters), loss = 0.185594
I0928 10:39:38.339417  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185594 (* 1 = 0.185594 loss)
I0928 10:39:38.339426  4247 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I0928 10:39:52.543570  4247 solver.cpp:218] Iteration 27100 (7.04022 iter/s, 14.2041s/100 iters), loss = 0.190273
I0928 10:39:52.543609  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190273 (* 1 = 0.190273 loss)
I0928 10:39:52.543615  4247 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I0928 10:40:06.754071  4247 solver.cpp:218] Iteration 27200 (7.03709 iter/s, 14.2104s/100 iters), loss = 0.15791
I0928 10:40:06.754178  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157911 (* 1 = 0.157911 loss)
I0928 10:40:06.754184  4247 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I0928 10:40:20.959444  4247 solver.cpp:218] Iteration 27300 (7.03966 iter/s, 14.2052s/100 iters), loss = 0.156826
I0928 10:40:20.959475  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156826 (* 1 = 0.156826 loss)
I0928 10:40:20.959481  4247 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I0928 10:40:35.171386  4247 solver.cpp:218] Iteration 27400 (7.03637 iter/s, 14.2119s/100 iters), loss = 0.222407
I0928 10:40:35.171427  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222408 (* 1 = 0.222408 loss)
I0928 10:40:35.171433  4247 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I0928 10:40:48.683200  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:40:49.252576  4247 solver.cpp:330] Iteration 27500, Testing net (#0)
I0928 10:40:52.609297  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:40:52.749799  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7013
I0928 10:40:52.749835  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.01528 (* 1 = 1.01528 loss)
I0928 10:40:52.891307  4247 solver.cpp:218] Iteration 27500 (5.6434 iter/s, 17.7198s/100 iters), loss = 0.209547
I0928 10:40:52.891336  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209547 (* 1 = 0.209547 loss)
I0928 10:40:52.891343  4247 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I0928 10:41:07.105307  4247 solver.cpp:218] Iteration 27600 (7.03535 iter/s, 14.2139s/100 iters), loss = 0.113968
I0928 10:41:07.105340  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.113969 (* 1 = 0.113969 loss)
I0928 10:41:07.105345  4247 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I0928 10:41:21.320713  4247 solver.cpp:218] Iteration 27700 (7.03466 iter/s, 14.2153s/100 iters), loss = 0.211998
I0928 10:41:21.320827  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211998 (* 1 = 0.211998 loss)
I0928 10:41:21.320843  4247 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I0928 10:41:35.535683  4247 solver.cpp:218] Iteration 27800 (7.03491 iter/s, 14.2148s/100 iters), loss = 0.189755
I0928 10:41:35.535714  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189755 (* 1 = 0.189755 loss)
I0928 10:41:35.535719  4247 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I0928 10:41:49.747182  4247 solver.cpp:218] Iteration 27900 (7.03659 iter/s, 14.2114s/100 iters), loss = 0.164964
I0928 10:41:49.747215  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164964 (* 1 = 0.164964 loss)
I0928 10:41:49.747220  4247 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I0928 10:42:03.256976  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:42:03.826246  4247 solver.cpp:330] Iteration 28000, Testing net (#0)
I0928 10:42:07.182317  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:42:07.322593  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7133
I0928 10:42:07.322630  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.974938 (* 1 = 0.974938 loss)
I0928 10:42:07.463863  4247 solver.cpp:218] Iteration 28000 (5.64442 iter/s, 17.7166s/100 iters), loss = 0.148066
I0928 10:42:07.463892  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148066 (* 1 = 0.148066 loss)
I0928 10:42:07.463899  4247 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I0928 10:42:21.678649  4247 solver.cpp:218] Iteration 28100 (7.03497 iter/s, 14.2147s/100 iters), loss = 0.168325
I0928 10:42:21.678691  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168325 (* 1 = 0.168325 loss)
I0928 10:42:21.678697  4247 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I0928 10:42:35.900097  4247 solver.cpp:218] Iteration 28200 (7.03168 iter/s, 14.2214s/100 iters), loss = 0.28244
I0928 10:42:35.900187  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282441 (* 1 = 0.282441 loss)
I0928 10:42:35.900202  4247 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I0928 10:42:50.120859  4247 solver.cpp:218] Iteration 28300 (7.03204 iter/s, 14.2206s/100 iters), loss = 0.175585
I0928 10:42:50.120892  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175585 (* 1 = 0.175585 loss)
I0928 10:42:50.120908  4247 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I0928 10:43:04.337632  4247 solver.cpp:218] Iteration 28400 (7.03398 iter/s, 14.2167s/100 iters), loss = 0.199256
I0928 10:43:04.337666  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199257 (* 1 = 0.199257 loss)
I0928 10:43:04.337682  4247 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I0928 10:43:17.850416  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:43:18.419088  4247 solver.cpp:330] Iteration 28500, Testing net (#0)
I0928 10:43:21.775941  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:43:21.916571  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6185
I0928 10:43:21.916609  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.43055 (* 1 = 1.43055 loss)
I0928 10:43:22.057988  4247 solver.cpp:218] Iteration 28500 (5.64325 iter/s, 17.7203s/100 iters), loss = 0.168269
I0928 10:43:22.058017  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168269 (* 1 = 0.168269 loss)
I0928 10:43:22.058023  4247 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I0928 10:43:36.268626  4247 solver.cpp:218] Iteration 28600 (7.03702 iter/s, 14.2106s/100 iters), loss = 0.169509
I0928 10:43:36.268668  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169509 (* 1 = 0.169509 loss)
I0928 10:43:36.268674  4247 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I0928 10:43:50.486218  4247 solver.cpp:218] Iteration 28700 (7.03358 iter/s, 14.2175s/100 iters), loss = 0.228494
I0928 10:43:50.486335  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228494 (* 1 = 0.228494 loss)
I0928 10:43:50.486351  4247 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I0928 10:44:04.702599  4247 solver.cpp:218] Iteration 28800 (7.03422 iter/s, 14.2162s/100 iters), loss = 0.305998
I0928 10:44:04.702638  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305999 (* 1 = 0.305999 loss)
I0928 10:44:04.702644  4247 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I0928 10:44:18.923482  4247 solver.cpp:218] Iteration 28900 (7.03195 iter/s, 14.2208s/100 iters), loss = 0.16419
I0928 10:44:18.923526  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16419 (* 1 = 0.16419 loss)
I0928 10:44:18.923532  4247 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I0928 10:44:32.433187  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:44:33.001390  4247 solver.cpp:330] Iteration 29000, Testing net (#0)
I0928 10:44:36.357688  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:44:36.498132  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6765
I0928 10:44:36.498157  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.22218 (* 1 = 1.22218 loss)
I0928 10:44:36.638829  4247 solver.cpp:218] Iteration 29000 (5.64485 iter/s, 17.7153s/100 iters), loss = 0.284925
I0928 10:44:36.638857  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284926 (* 1 = 0.284926 loss)
I0928 10:44:36.638864  4247 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I0928 10:44:50.848178  4247 solver.cpp:218] Iteration 29100 (7.03766 iter/s, 14.2093s/100 iters), loss = 0.154816
I0928 10:44:50.848211  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154817 (* 1 = 0.154817 loss)
I0928 10:44:50.848217  4247 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I0928 10:45:05.060200  4247 solver.cpp:218] Iteration 29200 (7.03633 iter/s, 14.2119s/100 iters), loss = 0.143416
I0928 10:45:05.060277  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143417 (* 1 = 0.143417 loss)
I0928 10:45:05.060284  4247 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I0928 10:45:19.271595  4247 solver.cpp:218] Iteration 29300 (7.03667 iter/s, 14.2113s/100 iters), loss = 0.292755
I0928 10:45:19.271627  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292756 (* 1 = 0.292756 loss)
I0928 10:45:19.271633  4247 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I0928 10:45:33.478071  4247 solver.cpp:218] Iteration 29400 (7.03908 iter/s, 14.2064s/100 iters), loss = 0.14715
I0928 10:45:33.478101  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14715 (* 1 = 0.14715 loss)
I0928 10:45:33.478107  4247 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I0928 10:45:46.984208  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:45:47.552414  4247 solver.cpp:330] Iteration 29500, Testing net (#0)
I0928 10:45:50.907876  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:45:51.048344  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6204
I0928 10:45:51.048372  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.51053 (* 1 = 1.51053 loss)
I0928 10:45:51.189388  4247 solver.cpp:218] Iteration 29500 (5.64613 iter/s, 17.7112s/100 iters), loss = 0.214015
I0928 10:45:51.189417  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214015 (* 1 = 0.214015 loss)
I0928 10:45:51.189424  4247 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I0928 10:46:05.407555  4247 solver.cpp:218] Iteration 29600 (7.03329 iter/s, 14.2181s/100 iters), loss = 0.178377
I0928 10:46:05.407598  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178377 (* 1 = 0.178377 loss)
I0928 10:46:05.407603  4247 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I0928 10:46:19.622797  4247 solver.cpp:218] Iteration 29700 (7.03475 iter/s, 14.2152s/100 iters), loss = 0.141291
I0928 10:46:19.622895  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.141291 (* 1 = 0.141291 loss)
I0928 10:46:19.622902  4247 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I0928 10:46:33.843442  4247 solver.cpp:218] Iteration 29800 (7.0321 iter/s, 14.2205s/100 iters), loss = 0.171224
I0928 10:46:33.843485  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171224 (* 1 = 0.171224 loss)
I0928 10:46:33.843492  4247 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I0928 10:46:48.056890  4247 solver.cpp:218] Iteration 29900 (7.03563 iter/s, 14.2134s/100 iters), loss = 0.171102
I0928 10:46:48.056921  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171103 (* 1 = 0.171103 loss)
I0928 10:46:48.056927  4247 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I0928 10:47:01.563310  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:47:02.133412  4247 solver.cpp:330] Iteration 30000, Testing net (#0)
I0928 10:47:05.488991  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:47:05.629503  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7942
I0928 10:47:05.629539  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.689326 (* 1 = 0.689326 loss)
I0928 10:47:05.770623  4247 solver.cpp:218] Iteration 30000 (5.64536 iter/s, 17.7136s/100 iters), loss = 0.123661
I0928 10:47:05.770653  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123661 (* 1 = 0.123661 loss)
I0928 10:47:05.770659  4247 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I0928 10:47:19.986193  4247 solver.cpp:218] Iteration 30100 (7.03458 iter/s, 14.2155s/100 iters), loss = 0.176442
I0928 10:47:19.986237  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176442 (* 1 = 0.176442 loss)
I0928 10:47:19.986241  4247 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I0928 10:47:34.208353  4247 solver.cpp:218] Iteration 30200 (7.03132 iter/s, 14.2221s/100 iters), loss = 0.18943
I0928 10:47:34.208482  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18943 (* 1 = 0.18943 loss)
I0928 10:47:34.208489  4247 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I0928 10:47:48.427639  4247 solver.cpp:218] Iteration 30300 (7.03278 iter/s, 14.2191s/100 iters), loss = 0.2069
I0928 10:47:48.427681  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2069 (* 1 = 0.2069 loss)
I0928 10:47:48.427687  4247 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I0928 10:48:02.647078  4247 solver.cpp:218] Iteration 30400 (7.03267 iter/s, 14.2194s/100 iters), loss = 0.116614
I0928 10:48:02.647119  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116614 (* 1 = 0.116614 loss)
I0928 10:48:02.647125  4247 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I0928 10:48:16.162564  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:48:16.732151  4247 solver.cpp:330] Iteration 30500, Testing net (#0)
I0928 10:48:20.087625  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:48:20.227707  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7451
I0928 10:48:20.227746  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.896576 (* 1 = 0.896576 loss)
I0928 10:48:20.368957  4247 solver.cpp:218] Iteration 30500 (5.64277 iter/s, 17.7218s/100 iters), loss = 0.136968
I0928 10:48:20.368986  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136968 (* 1 = 0.136968 loss)
I0928 10:48:20.368993  4247 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I0928 10:48:34.580406  4247 solver.cpp:218] Iteration 30600 (7.03662 iter/s, 14.2114s/100 iters), loss = 0.20759
I0928 10:48:34.580448  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20759 (* 1 = 0.20759 loss)
I0928 10:48:34.580454  4247 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I0928 10:48:48.799782  4247 solver.cpp:218] Iteration 30700 (7.0327 iter/s, 14.2193s/100 iters), loss = 0.260038
I0928 10:48:48.799906  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260038 (* 1 = 0.260038 loss)
I0928 10:48:48.799912  4247 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I0928 10:49:03.019372  4247 solver.cpp:218] Iteration 30800 (7.03263 iter/s, 14.2194s/100 iters), loss = 0.256637
I0928 10:49:03.019414  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256637 (* 1 = 0.256637 loss)
I0928 10:49:03.019420  4247 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I0928 10:49:17.237042  4247 solver.cpp:218] Iteration 30900 (7.03354 iter/s, 14.2176s/100 iters), loss = 0.112889
I0928 10:49:17.237083  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.112889 (* 1 = 0.112889 loss)
I0928 10:49:17.237089  4247 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I0928 10:49:30.752594  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:49:31.321281  4247 solver.cpp:330] Iteration 31000, Testing net (#0)
I0928 10:49:34.676561  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:49:34.817035  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6064
I0928 10:49:34.817062  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.6982 (* 1 = 1.6982 loss)
I0928 10:49:34.958804  4247 solver.cpp:218] Iteration 31000 (5.64281 iter/s, 17.7217s/100 iters), loss = 0.174274
I0928 10:49:34.958833  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174274 (* 1 = 0.174274 loss)
I0928 10:49:34.958840  4247 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I0928 10:49:49.161425  4247 solver.cpp:218] Iteration 31100 (7.04099 iter/s, 14.2026s/100 iters), loss = 0.18698
I0928 10:49:49.161456  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18698 (* 1 = 0.18698 loss)
I0928 10:49:49.161461  4247 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I0928 10:50:03.369343  4247 solver.cpp:218] Iteration 31200 (7.03837 iter/s, 14.2078s/100 iters), loss = 0.16636
I0928 10:50:03.369418  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16636 (* 1 = 0.16636 loss)
I0928 10:50:03.369436  4247 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I0928 10:50:17.576303  4247 solver.cpp:218] Iteration 31300 (7.03886 iter/s, 14.2068s/100 iters), loss = 0.217206
I0928 10:50:17.576333  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217206 (* 1 = 0.217206 loss)
I0928 10:50:17.576339  4247 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I0928 10:50:31.790602  4247 solver.cpp:218] Iteration 31400 (7.03521 iter/s, 14.2142s/100 iters), loss = 0.201775
I0928 10:50:31.790634  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201776 (* 1 = 0.201776 loss)
I0928 10:50:31.790642  4247 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I0928 10:50:45.294553  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:50:45.863494  4247 solver.cpp:330] Iteration 31500, Testing net (#0)
I0928 10:50:49.219009  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:50:49.359359  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6156
I0928 10:50:49.359386  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.65819 (* 1 = 1.65819 loss)
I0928 10:50:49.500686  4247 solver.cpp:218] Iteration 31500 (5.64653 iter/s, 17.71s/100 iters), loss = 0.140261
I0928 10:50:49.500715  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140262 (* 1 = 0.140262 loss)
I0928 10:50:49.500722  4247 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I0928 10:51:03.727164  4247 solver.cpp:218] Iteration 31600 (7.02918 iter/s, 14.2264s/100 iters), loss = 0.172524
I0928 10:51:03.727197  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172525 (* 1 = 0.172525 loss)
I0928 10:51:03.727205  4247 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I0928 10:51:17.952278  4247 solver.cpp:218] Iteration 31700 (7.02986 iter/s, 14.225s/100 iters), loss = 0.278731
I0928 10:51:17.952395  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278731 (* 1 = 0.278731 loss)
I0928 10:51:17.952404  4247 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I0928 10:51:32.177652  4247 solver.cpp:218] Iteration 31800 (7.02977 iter/s, 14.2252s/100 iters), loss = 0.216146
I0928 10:51:32.177695  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216147 (* 1 = 0.216147 loss)
I0928 10:51:32.177700  4247 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I0928 10:51:46.399807  4247 solver.cpp:218] Iteration 31900 (7.03132 iter/s, 14.2221s/100 iters), loss = 0.0886043
I0928 10:51:46.399840  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0886046 (* 1 = 0.0886046 loss)
I0928 10:51:46.399848  4247 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I0928 10:51:59.917676  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:52:00.487761  4247 solver.cpp:330] Iteration 32000, Testing net (#0)
I0928 10:52:03.841326  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:52:03.981598  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6675
I0928 10:52:03.981636  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.21756 (* 1 = 1.21756 loss)
I0928 10:52:04.122017  4247 solver.cpp:218] Iteration 32000 (5.64266 iter/s, 17.7221s/100 iters), loss = 0.160111
I0928 10:52:04.122046  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160111 (* 1 = 0.160111 loss)
I0928 10:52:04.122053  4247 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I0928 10:52:18.343030  4247 solver.cpp:218] Iteration 32100 (7.03188 iter/s, 14.2209s/100 iters), loss = 0.183277
I0928 10:52:18.343071  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183278 (* 1 = 0.183278 loss)
I0928 10:52:18.343077  4247 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I0928 10:52:32.568110  4247 solver.cpp:218] Iteration 32200 (7.02988 iter/s, 14.225s/100 iters), loss = 0.214042
I0928 10:52:32.568210  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214043 (* 1 = 0.214043 loss)
I0928 10:52:32.568218  4247 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I0928 10:52:46.793149  4247 solver.cpp:218] Iteration 32300 (7.02992 iter/s, 14.2249s/100 iters), loss = 0.128311
I0928 10:52:46.793191  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128311 (* 1 = 0.128311 loss)
I0928 10:52:46.793197  4247 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I0928 10:53:01.019094  4247 solver.cpp:218] Iteration 32400 (7.02945 iter/s, 14.2259s/100 iters), loss = 0.134707
I0928 10:53:01.019136  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134707 (* 1 = 0.134707 loss)
I0928 10:53:01.019142  4247 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I0928 10:53:14.532013  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:53:15.101482  4247 solver.cpp:330] Iteration 32500, Testing net (#0)
I0928 10:53:18.456935  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:53:18.597548  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.758
I0928 10:53:18.597585  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.75498 (* 1 = 0.75498 loss)
I0928 10:53:18.739204  4247 solver.cpp:218] Iteration 32500 (5.64333 iter/s, 17.72s/100 iters), loss = 0.180385
I0928 10:53:18.739234  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180386 (* 1 = 0.180386 loss)
I0928 10:53:18.739241  4247 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I0928 10:53:32.960836  4247 solver.cpp:218] Iteration 32600 (7.03158 iter/s, 14.2216s/100 iters), loss = 0.25208
I0928 10:53:32.960880  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252081 (* 1 = 0.252081 loss)
I0928 10:53:32.960886  4247 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I0928 10:53:47.182171  4247 solver.cpp:218] Iteration 32700 (7.03173 iter/s, 14.2212s/100 iters), loss = 0.190198
I0928 10:53:47.182297  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190198 (* 1 = 0.190198 loss)
I0928 10:53:47.182307  4247 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I0928 10:54:01.405716  4247 solver.cpp:218] Iteration 32800 (7.03068 iter/s, 14.2234s/100 iters), loss = 0.153295
I0928 10:54:01.405746  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153295 (* 1 = 0.153295 loss)
I0928 10:54:01.405752  4247 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I0928 10:54:15.629102  4247 solver.cpp:218] Iteration 32900 (7.03071 iter/s, 14.2233s/100 iters), loss = 0.184896
I0928 10:54:15.629144  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184897 (* 1 = 0.184897 loss)
I0928 10:54:15.629150  4247 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I0928 10:54:29.142398  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:54:29.711735  4247 solver.cpp:330] Iteration 33000, Testing net (#0)
I0928 10:54:33.066185  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:54:33.206326  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5425
I0928 10:54:33.206360  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.05929 (* 1 = 2.05929 loss)
I0928 10:54:33.347371  4247 solver.cpp:218] Iteration 33000 (5.64392 iter/s, 17.7182s/100 iters), loss = 0.142066
I0928 10:54:33.347400  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142066 (* 1 = 0.142066 loss)
I0928 10:54:33.347407  4247 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I0928 10:54:47.563828  4247 solver.cpp:218] Iteration 33100 (7.03414 iter/s, 14.2164s/100 iters), loss = 0.384363
I0928 10:54:47.563859  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.384364 (* 1 = 0.384364 loss)
I0928 10:54:47.563866  4247 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I0928 10:55:01.783812  4247 solver.cpp:218] Iteration 33200 (7.03239 iter/s, 14.2199s/100 iters), loss = 0.219523
I0928 10:55:01.783943  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219523 (* 1 = 0.219523 loss)
I0928 10:55:01.783952  4247 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I0928 10:55:16.007544  4247 solver.cpp:218] Iteration 33300 (7.03059 iter/s, 14.2236s/100 iters), loss = 0.212657
I0928 10:55:16.007575  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212657 (* 1 = 0.212657 loss)
I0928 10:55:16.007581  4247 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I0928 10:55:30.226646  4247 solver.cpp:218] Iteration 33400 (7.03283 iter/s, 14.219s/100 iters), loss = 0.139487
I0928 10:55:30.226688  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139487 (* 1 = 0.139487 loss)
I0928 10:55:30.226694  4247 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I0928 10:55:43.745167  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:55:44.315263  4247 solver.cpp:330] Iteration 33500, Testing net (#0)
I0928 10:55:47.672029  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:55:47.812453  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7653
I0928 10:55:47.812480  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.84232 (* 1 = 0.84232 loss)
I0928 10:55:47.953795  4247 solver.cpp:218] Iteration 33500 (5.64109 iter/s, 17.7271s/100 iters), loss = 0.181758
I0928 10:55:47.953824  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181758 (* 1 = 0.181758 loss)
I0928 10:55:47.953831  4247 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I0928 10:56:02.169796  4247 solver.cpp:218] Iteration 33600 (7.03436 iter/s, 14.2159s/100 iters), loss = 0.221557
I0928 10:56:02.169827  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221557 (* 1 = 0.221557 loss)
I0928 10:56:02.169833  4247 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I0928 10:56:16.383949  4247 solver.cpp:218] Iteration 33700 (7.03528 iter/s, 14.2141s/100 iters), loss = 0.269865
I0928 10:56:16.384019  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269866 (* 1 = 0.269866 loss)
I0928 10:56:16.384027  4247 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I0928 10:56:30.596877  4247 solver.cpp:218] Iteration 33800 (7.0359 iter/s, 14.2128s/100 iters), loss = 0.24623
I0928 10:56:30.596920  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246231 (* 1 = 0.246231 loss)
I0928 10:56:30.596926  4247 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I0928 10:56:44.805685  4247 solver.cpp:218] Iteration 33900 (7.03793 iter/s, 14.2087s/100 iters), loss = 0.117235
I0928 10:56:44.805727  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.117235 (* 1 = 0.117235 loss)
I0928 10:56:44.805733  4247 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I0928 10:56:58.311334  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:56:58.880576  4247 solver.cpp:330] Iteration 34000, Testing net (#0)
I0928 10:57:02.237871  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:57:02.377503  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6855
I0928 10:57:02.377540  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.40773 (* 1 = 1.40773 loss)
I0928 10:57:02.519044  4247 solver.cpp:218] Iteration 34000 (5.64549 iter/s, 17.7133s/100 iters), loss = 0.116104
I0928 10:57:02.519073  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116104 (* 1 = 0.116104 loss)
I0928 10:57:02.519080  4247 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I0928 10:57:16.739879  4247 solver.cpp:218] Iteration 34100 (7.03197 iter/s, 14.2208s/100 iters), loss = 0.133231
I0928 10:57:16.739922  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133232 (* 1 = 0.133232 loss)
I0928 10:57:16.739928  4247 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I0928 10:57:30.965121  4247 solver.cpp:218] Iteration 34200 (7.0298 iter/s, 14.2252s/100 iters), loss = 0.221343
I0928 10:57:30.965206  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221343 (* 1 = 0.221343 loss)
I0928 10:57:30.965214  4247 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I0928 10:57:45.189404  4247 solver.cpp:218] Iteration 34300 (7.03029 iter/s, 14.2242s/100 iters), loss = 0.182085
I0928 10:57:45.189445  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182086 (* 1 = 0.182086 loss)
I0928 10:57:45.189451  4247 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I0928 10:57:59.462172  4247 solver.cpp:218] Iteration 34400 (7.00639 iter/s, 14.2727s/100 iters), loss = 0.156475
I0928 10:57:59.462205  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156475 (* 1 = 0.156475 loss)
I0928 10:57:59.462213  4247 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I0928 10:58:13.076495  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:58:13.651506  4247 solver.cpp:330] Iteration 34500, Testing net (#0)
I0928 10:58:17.041309  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:58:17.180558  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7938
I0928 10:58:17.180595  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.653536 (* 1 = 0.653536 loss)
I0928 10:58:17.324476  4247 solver.cpp:218] Iteration 34500 (5.59841 iter/s, 17.8622s/100 iters), loss = 0.227268
I0928 10:58:17.324520  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227268 (* 1 = 0.227268 loss)
I0928 10:58:17.324527  4247 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I0928 10:58:31.580011  4247 solver.cpp:218] Iteration 34600 (7.01486 iter/s, 14.2554s/100 iters), loss = 0.211222
I0928 10:58:31.580054  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211222 (* 1 = 0.211222 loss)
I0928 10:58:31.580060  4247 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I0928 10:58:45.801345  4247 solver.cpp:218] Iteration 34700 (7.03173 iter/s, 14.2213s/100 iters), loss = 0.168299
I0928 10:58:45.801452  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168299 (* 1 = 0.168299 loss)
I0928 10:58:45.801460  4247 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I0928 10:59:00.026327  4247 solver.cpp:218] Iteration 34800 (7.02996 iter/s, 14.2248s/100 iters), loss = 0.165201
I0928 10:59:00.026368  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165201 (* 1 = 0.165201 loss)
I0928 10:59:00.026374  4247 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I0928 10:59:14.243937  4247 solver.cpp:218] Iteration 34900 (7.03357 iter/s, 14.2175s/100 iters), loss = 0.172729
I0928 10:59:14.243979  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172729 (* 1 = 0.172729 loss)
I0928 10:59:14.243985  4247 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I0928 10:59:27.839835  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:59:28.409111  4247 solver.cpp:330] Iteration 35000, Testing net (#0)
I0928 10:59:31.764133  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 10:59:31.905166  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7506
I0928 10:59:31.905203  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.863616 (* 1 = 0.863616 loss)
I0928 10:59:32.045972  4247 solver.cpp:218] Iteration 35000 (5.61736 iter/s, 17.8019s/100 iters), loss = 0.169923
I0928 10:59:32.046000  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169923 (* 1 = 0.169923 loss)
I0928 10:59:32.046006  4247 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I0928 10:59:46.286592  4247 solver.cpp:218] Iteration 35100 (7.0222 iter/s, 14.2406s/100 iters), loss = 0.261032
I0928 10:59:46.286623  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261032 (* 1 = 0.261032 loss)
I0928 10:59:46.286629  4247 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I0928 11:00:00.818572  4247 solver.cpp:218] Iteration 35200 (6.88141 iter/s, 14.5319s/100 iters), loss = 0.124209
I0928 11:00:00.818686  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.124209 (* 1 = 0.124209 loss)
I0928 11:00:00.818704  4247 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I0928 11:00:15.168298  4247 solver.cpp:218] Iteration 35300 (6.96887 iter/s, 14.3495s/100 iters), loss = 0.152754
I0928 11:00:15.168329  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152754 (* 1 = 0.152754 loss)
I0928 11:00:15.168335  4247 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I0928 11:00:29.532294  4247 solver.cpp:218] Iteration 35400 (6.96189 iter/s, 14.3639s/100 iters), loss = 0.175047
I0928 11:00:29.532327  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175048 (* 1 = 0.175048 loss)
I0928 11:00:29.532335  4247 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I0928 11:00:43.094322  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:00:43.664758  4247 solver.cpp:330] Iteration 35500, Testing net (#0)
I0928 11:00:47.024770  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:00:47.164625  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4959
I0928 11:00:47.164660  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.2569 (* 1 = 3.2569 loss)
I0928 11:00:47.305835  4247 solver.cpp:218] Iteration 35500 (5.62637 iter/s, 17.7735s/100 iters), loss = 0.15796
I0928 11:00:47.305863  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157961 (* 1 = 0.157961 loss)
I0928 11:00:47.305869  4247 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I0928 11:01:01.625047  4247 solver.cpp:218] Iteration 35600 (6.98366 iter/s, 14.3191s/100 iters), loss = 0.22294
I0928 11:01:01.625077  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222941 (* 1 = 0.222941 loss)
I0928 11:01:01.625083  4247 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I0928 11:01:15.922775  4247 solver.cpp:218] Iteration 35700 (6.99416 iter/s, 14.2977s/100 iters), loss = 0.127331
I0928 11:01:15.922857  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127331 (* 1 = 0.127331 loss)
I0928 11:01:15.922874  4247 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I0928 11:01:30.145298  4247 solver.cpp:218] Iteration 35800 (7.03116 iter/s, 14.2224s/100 iters), loss = 0.130261
I0928 11:01:30.145329  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.130261 (* 1 = 0.130261 loss)
I0928 11:01:30.145334  4247 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I0928 11:01:44.373518  4247 solver.cpp:218] Iteration 35900 (7.02832 iter/s, 14.2281s/100 iters), loss = 0.191836
I0928 11:01:44.373549  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191836 (* 1 = 0.191836 loss)
I0928 11:01:44.373555  4247 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I0928 11:01:57.897387  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:01:58.467016  4247 solver.cpp:330] Iteration 36000, Testing net (#0)
I0928 11:02:01.823140  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:02:01.963358  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.622
I0928 11:02:01.963394  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.76987 (* 1 = 1.76987 loss)
I0928 11:02:02.104943  4247 solver.cpp:218] Iteration 36000 (5.63973 iter/s, 17.7313s/100 iters), loss = 0.129022
I0928 11:02:02.104974  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.129022 (* 1 = 0.129022 loss)
I0928 11:02:02.104979  4247 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I0928 11:02:16.319190  4247 solver.cpp:218] Iteration 36100 (7.03523 iter/s, 14.2142s/100 iters), loss = 0.272493
I0928 11:02:16.319221  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272493 (* 1 = 0.272493 loss)
I0928 11:02:16.319227  4247 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I0928 11:02:30.536404  4247 solver.cpp:218] Iteration 36200 (7.03377 iter/s, 14.2171s/100 iters), loss = 0.220671
I0928 11:02:30.536504  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220671 (* 1 = 0.220671 loss)
I0928 11:02:30.536520  4247 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I0928 11:02:44.756083  4247 solver.cpp:218] Iteration 36300 (7.03258 iter/s, 14.2195s/100 iters), loss = 0.131515
I0928 11:02:44.756125  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.131515 (* 1 = 0.131515 loss)
I0928 11:02:44.756131  4247 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I0928 11:02:58.978637  4247 solver.cpp:218] Iteration 36400 (7.03113 iter/s, 14.2225s/100 iters), loss = 0.12631
I0928 11:02:58.978679  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12631 (* 1 = 0.12631 loss)
I0928 11:02:58.978685  4247 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I0928 11:03:12.494433  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:03:13.065723  4247 solver.cpp:330] Iteration 36500, Testing net (#0)
I0928 11:03:16.422037  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:03:16.561892  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.572
I0928 11:03:16.561928  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.79743 (* 1 = 1.79743 loss)
I0928 11:03:16.703222  4247 solver.cpp:218] Iteration 36500 (5.64191 iter/s, 17.7245s/100 iters), loss = 0.118644
I0928 11:03:16.703253  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.118644 (* 1 = 0.118644 loss)
I0928 11:03:16.703260  4247 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I0928 11:03:30.923924  4247 solver.cpp:218] Iteration 36600 (7.03204 iter/s, 14.2206s/100 iters), loss = 0.176247
I0928 11:03:30.923955  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176247 (* 1 = 0.176247 loss)
I0928 11:03:30.923961  4247 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I0928 11:03:45.156240  4247 solver.cpp:218] Iteration 36700 (7.0263 iter/s, 14.2322s/100 iters), loss = 0.15233
I0928 11:03:45.156358  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15233 (* 1 = 0.15233 loss)
I0928 11:03:45.156375  4247 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I0928 11:03:59.388511  4247 solver.cpp:218] Iteration 36800 (7.02636 iter/s, 14.2321s/100 iters), loss = 0.116422
I0928 11:03:59.388542  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116422 (* 1 = 0.116422 loss)
I0928 11:03:59.388548  4247 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I0928 11:04:13.617029  4247 solver.cpp:218] Iteration 36900 (7.02818 iter/s, 14.2284s/100 iters), loss = 0.217583
I0928 11:04:13.617071  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217583 (* 1 = 0.217583 loss)
I0928 11:04:13.617077  4247 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I0928 11:04:27.135229  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:04:27.704313  4247 solver.cpp:330] Iteration 37000, Testing net (#0)
I0928 11:04:31.062861  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:04:31.202963  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6326
I0928 11:04:31.203001  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.5237 (* 1 = 1.5237 loss)
I0928 11:04:31.344290  4247 solver.cpp:218] Iteration 37000 (5.64106 iter/s, 17.7272s/100 iters), loss = 0.145224
I0928 11:04:31.344321  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145225 (* 1 = 0.145225 loss)
I0928 11:04:31.344326  4247 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I0928 11:04:45.565289  4247 solver.cpp:218] Iteration 37100 (7.03189 iter/s, 14.2209s/100 iters), loss = 0.190259
I0928 11:04:45.565331  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190259 (* 1 = 0.190259 loss)
I0928 11:04:45.565337  4247 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I0928 11:04:59.787979  4247 solver.cpp:218] Iteration 37200 (7.03106 iter/s, 14.2226s/100 iters), loss = 0.172683
I0928 11:04:59.788086  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172684 (* 1 = 0.172684 loss)
I0928 11:04:59.788103  4247 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I0928 11:05:14.008867  4247 solver.cpp:218] Iteration 37300 (7.03198 iter/s, 14.2207s/100 iters), loss = 0.160728
I0928 11:05:14.008908  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160728 (* 1 = 0.160728 loss)
I0928 11:05:14.008913  4247 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I0928 11:05:28.232264  4247 solver.cpp:218] Iteration 37400 (7.03071 iter/s, 14.2233s/100 iters), loss = 0.201029
I0928 11:05:28.232295  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201029 (* 1 = 0.201029 loss)
I0928 11:05:28.232300  4247 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I0928 11:05:41.746161  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:05:42.314942  4247 solver.cpp:330] Iteration 37500, Testing net (#0)
I0928 11:05:45.670871  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:05:45.811321  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7047
I0928 11:05:45.811357  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.22599 (* 1 = 1.22599 loss)
I0928 11:05:45.952664  4247 solver.cpp:218] Iteration 37500 (5.64324 iter/s, 17.7203s/100 iters), loss = 0.0973797
I0928 11:05:45.952694  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0973798 (* 1 = 0.0973798 loss)
I0928 11:05:45.952702  4247 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I0928 11:06:00.161038  4247 solver.cpp:218] Iteration 37600 (7.03814 iter/s, 14.2083s/100 iters), loss = 0.233561
I0928 11:06:00.161079  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233561 (* 1 = 0.233561 loss)
I0928 11:06:00.161085  4247 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I0928 11:06:14.376720  4247 solver.cpp:218] Iteration 37700 (7.03453 iter/s, 14.2156s/100 iters), loss = 0.205362
I0928 11:06:14.376801  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205362 (* 1 = 0.205362 loss)
I0928 11:06:14.376816  4247 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I0928 11:06:28.591068  4247 solver.cpp:218] Iteration 37800 (7.03521 iter/s, 14.2142s/100 iters), loss = 0.181579
I0928 11:06:28.591110  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181579 (* 1 = 0.181579 loss)
I0928 11:06:28.591115  4247 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I0928 11:06:42.795517  4247 solver.cpp:218] Iteration 37900 (7.04009 iter/s, 14.2044s/100 iters), loss = 0.200765
I0928 11:06:42.795548  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200765 (* 1 = 0.200765 loss)
I0928 11:06:42.795554  4247 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I0928 11:06:56.300413  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:06:56.869767  4247 solver.cpp:330] Iteration 38000, Testing net (#0)
I0928 11:07:00.228884  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:07:00.368851  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7823
I0928 11:07:00.368890  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.790783 (* 1 = 0.790783 loss)
I0928 11:07:00.509979  4247 solver.cpp:218] Iteration 38000 (5.64513 iter/s, 17.7144s/100 iters), loss = 0.165504
I0928 11:07:00.510009  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165504 (* 1 = 0.165504 loss)
I0928 11:07:00.510015  4247 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I0928 11:07:14.738661  4247 solver.cpp:218] Iteration 38100 (7.02809 iter/s, 14.2286s/100 iters), loss = 0.161857
I0928 11:07:14.738703  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161857 (* 1 = 0.161857 loss)
I0928 11:07:14.738708  4247 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I0928 11:07:28.964866  4247 solver.cpp:218] Iteration 38200 (7.02932 iter/s, 14.2261s/100 iters), loss = 0.196584
I0928 11:07:28.964947  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196585 (* 1 = 0.196585 loss)
I0928 11:07:28.964954  4247 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I0928 11:07:43.191556  4247 solver.cpp:218] Iteration 38300 (7.0291 iter/s, 14.2266s/100 iters), loss = 0.131711
I0928 11:07:43.191588  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.131711 (* 1 = 0.131711 loss)
I0928 11:07:43.191594  4247 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I0928 11:07:57.419695  4247 solver.cpp:218] Iteration 38400 (7.02836 iter/s, 14.2281s/100 iters), loss = 0.145374
I0928 11:07:57.419736  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145374 (* 1 = 0.145374 loss)
I0928 11:07:57.419742  4247 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I0928 11:08:10.942747  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:08:11.512348  4247 solver.cpp:330] Iteration 38500, Testing net (#0)
I0928 11:08:14.868598  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:08:15.009117  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.443
I0928 11:08:15.009155  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.82853 (* 1 = 3.82853 loss)
I0928 11:08:15.150604  4247 solver.cpp:218] Iteration 38500 (5.6399 iter/s, 17.7308s/100 iters), loss = 0.197524
I0928 11:08:15.150635  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197524 (* 1 = 0.197524 loss)
I0928 11:08:15.150641  4247 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I0928 11:08:29.366160  4247 solver.cpp:218] Iteration 38600 (7.03458 iter/s, 14.2155s/100 iters), loss = 0.152736
I0928 11:08:29.366202  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152736 (* 1 = 0.152736 loss)
I0928 11:08:29.366209  4247 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I0928 11:08:43.593168  4247 solver.cpp:218] Iteration 38700 (7.02893 iter/s, 14.2269s/100 iters), loss = 0.16731
I0928 11:08:43.593230  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16731 (* 1 = 0.16731 loss)
I0928 11:08:43.593237  4247 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I0928 11:08:57.807399  4247 solver.cpp:218] Iteration 38800 (7.03525 iter/s, 14.2141s/100 iters), loss = 0.10737
I0928 11:08:57.807441  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10737 (* 1 = 0.10737 loss)
I0928 11:08:57.807447  4247 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I0928 11:09:12.027148  4247 solver.cpp:218] Iteration 38900 (7.03252 iter/s, 14.2197s/100 iters), loss = 0.119838
I0928 11:09:12.027178  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119838 (* 1 = 0.119838 loss)
I0928 11:09:12.027184  4247 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I0928 11:09:25.538301  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:09:26.106993  4247 solver.cpp:330] Iteration 39000, Testing net (#0)
I0928 11:09:29.464092  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:09:29.604099  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7903
I0928 11:09:29.604136  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.71843 (* 1 = 0.71843 loss)
I0928 11:09:29.746170  4247 solver.cpp:218] Iteration 39000 (5.64368 iter/s, 17.7189s/100 iters), loss = 0.127161
I0928 11:09:29.746201  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127162 (* 1 = 0.127162 loss)
I0928 11:09:29.746206  4247 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I0928 11:09:43.964166  4247 solver.cpp:218] Iteration 39100 (7.03337 iter/s, 14.2179s/100 iters), loss = 0.137475
I0928 11:09:43.964197  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.137475 (* 1 = 0.137475 loss)
I0928 11:09:43.964202  4247 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I0928 11:09:58.175936  4247 solver.cpp:218] Iteration 39200 (7.03646 iter/s, 14.2117s/100 iters), loss = 0.208359
I0928 11:09:58.176031  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208359 (* 1 = 0.208359 loss)
I0928 11:09:58.176048  4247 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I0928 11:10:12.391120  4247 solver.cpp:218] Iteration 39300 (7.0348 iter/s, 14.215s/100 iters), loss = 0.17789
I0928 11:10:12.391151  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17789 (* 1 = 0.17789 loss)
I0928 11:10:12.391157  4247 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I0928 11:10:26.610638  4247 solver.cpp:218] Iteration 39400 (7.03262 iter/s, 14.2194s/100 iters), loss = 0.0812362
I0928 11:10:26.610677  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0812364 (* 1 = 0.0812364 loss)
I0928 11:10:26.610683  4247 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I0928 11:10:40.119963  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:10:40.689455  4247 solver.cpp:330] Iteration 39500, Testing net (#0)
I0928 11:10:44.044114  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:10:44.184829  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5369
I0928 11:10:44.184865  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.8943 (* 1 = 1.8943 loss)
I0928 11:10:44.326004  4247 solver.cpp:218] Iteration 39500 (5.64485 iter/s, 17.7153s/100 iters), loss = 0.153997
I0928 11:10:44.326038  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153997 (* 1 = 0.153997 loss)
I0928 11:10:44.326046  4247 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I0928 11:10:58.538203  4247 solver.cpp:218] Iteration 39600 (7.03624 iter/s, 14.2121s/100 iters), loss = 0.219771
I0928 11:10:58.538245  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219771 (* 1 = 0.219771 loss)
I0928 11:10:58.538252  4247 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I0928 11:11:12.758152  4247 solver.cpp:218] Iteration 39700 (7.03242 iter/s, 14.2199s/100 iters), loss = 0.31269
I0928 11:11:12.758209  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31269 (* 1 = 0.31269 loss)
I0928 11:11:12.758226  4247 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I0928 11:11:26.985113  4247 solver.cpp:218] Iteration 39800 (7.02896 iter/s, 14.2269s/100 iters), loss = 0.140553
I0928 11:11:26.985157  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140553 (* 1 = 0.140553 loss)
I0928 11:11:26.985162  4247 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I0928 11:11:41.208310  4247 solver.cpp:218] Iteration 39900 (7.03081 iter/s, 14.2231s/100 iters), loss = 0.0943694
I0928 11:11:41.208353  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0943696 (* 1 = 0.0943696 loss)
I0928 11:11:41.208359  4247 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I0928 11:11:54.721812  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:11:55.290766  4247 solver.cpp:330] Iteration 40000, Testing net (#0)
I0928 11:11:58.647819  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:11:58.788084  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7964
I0928 11:11:58.788120  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.665073 (* 1 = 0.665073 loss)
I0928 11:11:58.928932  4247 solver.cpp:218] Iteration 40000 (5.64317 iter/s, 17.7205s/100 iters), loss = 0.109876
I0928 11:11:58.928961  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.109876 (* 1 = 0.109876 loss)
I0928 11:11:58.928966  4247 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I0928 11:11:58.928970  4247 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I0928 11:12:13.148679  4247 solver.cpp:218] Iteration 40100 (7.03251 iter/s, 14.2197s/100 iters), loss = 0.152008
I0928 11:12:13.148722  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152009 (* 1 = 0.152009 loss)
I0928 11:12:13.148727  4247 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I0928 11:12:27.367599  4247 solver.cpp:218] Iteration 40200 (7.03293 iter/s, 14.2188s/100 iters), loss = 0.189756
I0928 11:12:27.367740  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189756 (* 1 = 0.189756 loss)
I0928 11:12:27.367759  4247 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I0928 11:12:41.591820  4247 solver.cpp:218] Iteration 40300 (7.03035 iter/s, 14.224s/100 iters), loss = 0.05162
I0928 11:12:41.591853  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0516203 (* 1 = 0.0516203 loss)
I0928 11:12:41.591861  4247 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I0928 11:12:55.813900  4247 solver.cpp:218] Iteration 40400 (7.03136 iter/s, 14.222s/100 iters), loss = 0.144094
I0928 11:12:55.813941  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144094 (* 1 = 0.144094 loss)
I0928 11:12:55.813947  4247 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I0928 11:13:09.327564  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:13:09.897032  4247 solver.cpp:330] Iteration 40500, Testing net (#0)
I0928 11:13:13.252905  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:13:13.393534  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8963
I0928 11:13:13.393571  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307645 (* 1 = 0.307645 loss)
I0928 11:13:13.535075  4247 solver.cpp:218] Iteration 40500 (5.64299 iter/s, 17.7211s/100 iters), loss = 0.0708611
I0928 11:13:13.535106  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0708614 (* 1 = 0.0708614 loss)
I0928 11:13:13.535112  4247 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I0928 11:13:27.753319  4247 solver.cpp:218] Iteration 40600 (7.03325 iter/s, 14.2182s/100 iters), loss = 0.104829
I0928 11:13:27.753350  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.104829 (* 1 = 0.104829 loss)
I0928 11:13:27.753357  4247 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I0928 11:13:41.975311  4247 solver.cpp:218] Iteration 40700 (7.0314 iter/s, 14.2219s/100 iters), loss = 0.174004
I0928 11:13:41.975401  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174004 (* 1 = 0.174004 loss)
I0928 11:13:41.975410  4247 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I0928 11:13:56.198676  4247 solver.cpp:218] Iteration 40800 (7.03075 iter/s, 14.2232s/100 iters), loss = 0.0451276
I0928 11:13:56.198719  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0451279 (* 1 = 0.0451279 loss)
I0928 11:13:56.198724  4247 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I0928 11:14:10.431346  4247 solver.cpp:218] Iteration 40900 (7.02613 iter/s, 14.2326s/100 iters), loss = 0.0532631
I0928 11:14:10.431377  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0532634 (* 1 = 0.0532634 loss)
I0928 11:14:10.431382  4247 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I0928 11:14:23.952275  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:14:24.521667  4247 solver.cpp:330] Iteration 41000, Testing net (#0)
I0928 11:14:27.876806  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:14:28.016947  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9111
I0928 11:14:28.016983  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.27185 (* 1 = 0.27185 loss)
I0928 11:14:28.158347  4247 solver.cpp:218] Iteration 41000 (5.64114 iter/s, 17.7269s/100 iters), loss = 0.0814144
I0928 11:14:28.158376  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0814147 (* 1 = 0.0814147 loss)
I0928 11:14:28.158383  4247 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I0928 11:14:42.385390  4247 solver.cpp:218] Iteration 41100 (7.0289 iter/s, 14.227s/100 iters), loss = 0.055168
I0928 11:14:42.385421  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0551683 (* 1 = 0.0551683 loss)
I0928 11:14:42.385426  4247 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I0928 11:14:56.613312  4247 solver.cpp:218] Iteration 41200 (7.02847 iter/s, 14.2278s/100 iters), loss = 0.0535254
I0928 11:14:56.613409  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0535257 (* 1 = 0.0535257 loss)
I0928 11:14:56.613425  4247 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I0928 11:15:10.837221  4247 solver.cpp:218] Iteration 41300 (7.03048 iter/s, 14.2238s/100 iters), loss = 0.0488661
I0928 11:15:10.837251  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0488664 (* 1 = 0.0488664 loss)
I0928 11:15:10.837256  4247 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I0928 11:15:25.058140  4247 solver.cpp:218] Iteration 41400 (7.03193 iter/s, 14.2208s/100 iters), loss = 0.04747
I0928 11:15:25.058171  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0474703 (* 1 = 0.0474703 loss)
I0928 11:15:25.058188  4247 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I0928 11:15:38.571890  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:15:39.142597  4247 solver.cpp:330] Iteration 41500, Testing net (#0)
I0928 11:15:42.497880  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:15:42.638557  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9149
I0928 11:15:42.638594  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.254447 (* 1 = 0.254447 loss)
I0928 11:15:42.779940  4247 solver.cpp:218] Iteration 41500 (5.64279 iter/s, 17.7217s/100 iters), loss = 0.0505273
I0928 11:15:42.779971  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0505275 (* 1 = 0.0505275 loss)
I0928 11:15:42.779978  4247 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I0928 11:15:57.005853  4247 solver.cpp:218] Iteration 41600 (7.02946 iter/s, 14.2258s/100 iters), loss = 0.0895253
I0928 11:15:57.005895  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0895256 (* 1 = 0.0895256 loss)
I0928 11:15:57.005901  4247 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I0928 11:16:11.233536  4247 solver.cpp:218] Iteration 41700 (7.02859 iter/s, 14.2276s/100 iters), loss = 0.0532875
I0928 11:16:11.233645  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0532877 (* 1 = 0.0532877 loss)
I0928 11:16:11.233652  4247 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I0928 11:16:25.453835  4247 solver.cpp:218] Iteration 41800 (7.03227 iter/s, 14.2201s/100 iters), loss = 0.058877
I0928 11:16:25.453866  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0588773 (* 1 = 0.0588773 loss)
I0928 11:16:25.453872  4247 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I0928 11:16:39.676300  4247 solver.cpp:218] Iteration 41900 (7.03117 iter/s, 14.2224s/100 iters), loss = 0.0474306
I0928 11:16:39.676329  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0474308 (* 1 = 0.0474308 loss)
I0928 11:16:39.676336  4247 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I0928 11:16:53.193189  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:16:53.762007  4247 solver.cpp:330] Iteration 42000, Testing net (#0)
I0928 11:16:57.118738  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:16:57.258987  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9144
I0928 11:16:57.259023  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.264243 (* 1 = 0.264243 loss)
I0928 11:16:57.400717  4247 solver.cpp:218] Iteration 42000 (5.64196 iter/s, 17.7243s/100 iters), loss = 0.0637605
I0928 11:16:57.400746  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0637608 (* 1 = 0.0637608 loss)
I0928 11:16:57.400753  4247 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I0928 11:17:11.617786  4247 solver.cpp:218] Iteration 42100 (7.03383 iter/s, 14.217s/100 iters), loss = 0.0861501
I0928 11:17:11.617816  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0861504 (* 1 = 0.0861504 loss)
I0928 11:17:11.617822  4247 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I0928 11:17:25.836233  4247 solver.cpp:218] Iteration 42200 (7.03315 iter/s, 14.2184s/100 iters), loss = 0.0639857
I0928 11:17:25.836369  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0639859 (* 1 = 0.0639859 loss)
I0928 11:17:25.836386  4247 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I0928 11:17:40.057837  4247 solver.cpp:218] Iteration 42300 (7.03164 iter/s, 14.2214s/100 iters), loss = 0.0379977
I0928 11:17:40.057868  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0379979 (* 1 = 0.0379979 loss)
I0928 11:17:40.057884  4247 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I0928 11:17:54.280187  4247 solver.cpp:218] Iteration 42400 (7.03122 iter/s, 14.2223s/100 iters), loss = 0.0499927
I0928 11:17:54.280220  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0499929 (* 1 = 0.0499929 loss)
I0928 11:17:54.280225  4247 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I0928 11:18:07.797009  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:18:08.366056  4247 solver.cpp:330] Iteration 42500, Testing net (#0)
I0928 11:18:11.722579  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:18:11.863021  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9178
I0928 11:18:11.863049  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.256296 (* 1 = 0.256296 loss)
I0928 11:18:12.003566  4247 solver.cpp:218] Iteration 42500 (5.64229 iter/s, 17.7233s/100 iters), loss = 0.0246184
I0928 11:18:12.003594  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0246186 (* 1 = 0.0246186 loss)
I0928 11:18:12.003602  4247 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I0928 11:18:26.210546  4247 solver.cpp:218] Iteration 42600 (7.03883 iter/s, 14.2069s/100 iters), loss = 0.0752677
I0928 11:18:26.210577  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0752679 (* 1 = 0.0752679 loss)
I0928 11:18:26.210593  4247 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I0928 11:18:40.422840  4247 solver.cpp:218] Iteration 42700 (7.0362 iter/s, 14.2122s/100 iters), loss = 0.0697275
I0928 11:18:40.422960  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0697277 (* 1 = 0.0697277 loss)
I0928 11:18:40.422969  4247 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I0928 11:18:54.636970  4247 solver.cpp:218] Iteration 42800 (7.03533 iter/s, 14.214s/100 iters), loss = 0.0179413
I0928 11:18:54.636997  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0179415 (* 1 = 0.0179415 loss)
I0928 11:18:54.637003  4247 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I0928 11:19:08.857687  4247 solver.cpp:218] Iteration 42900 (7.03203 iter/s, 14.2206s/100 iters), loss = 0.0283003
I0928 11:19:08.857720  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0283005 (* 1 = 0.0283005 loss)
I0928 11:19:08.857736  4247 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I0928 11:19:22.368448  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:19:22.937789  4247 solver.cpp:330] Iteration 43000, Testing net (#0)
I0928 11:19:26.294771  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:19:26.435127  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9193
I0928 11:19:26.435153  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.249622 (* 1 = 0.249622 loss)
I0928 11:19:26.576766  4247 solver.cpp:218] Iteration 43000 (5.64366 iter/s, 17.719s/100 iters), loss = 0.0411373
I0928 11:19:26.576797  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0411375 (* 1 = 0.0411375 loss)
I0928 11:19:26.576803  4247 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I0928 11:19:40.795337  4247 solver.cpp:218] Iteration 43100 (7.03309 iter/s, 14.2185s/100 iters), loss = 0.0763646
I0928 11:19:40.795370  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0763648 (* 1 = 0.0763648 loss)
I0928 11:19:40.795377  4247 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I0928 11:19:55.019333  4247 solver.cpp:218] Iteration 43200 (7.03041 iter/s, 14.2239s/100 iters), loss = 0.0302857
I0928 11:19:55.019464  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0302859 (* 1 = 0.0302859 loss)
I0928 11:19:55.019480  4247 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I0928 11:20:09.247728  4247 solver.cpp:218] Iteration 43300 (7.02828 iter/s, 14.2282s/100 iters), loss = 0.0835898
I0928 11:20:09.247761  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.08359 (* 1 = 0.08359 loss)
I0928 11:20:09.247768  4247 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I0928 11:20:23.466892  4247 solver.cpp:218] Iteration 43400 (7.0328 iter/s, 14.2191s/100 iters), loss = 0.0314232
I0928 11:20:23.466929  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0314234 (* 1 = 0.0314234 loss)
I0928 11:20:23.466936  4247 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I0928 11:20:36.977502  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:20:37.546222  4247 solver.cpp:330] Iteration 43500, Testing net (#0)
I0928 11:20:40.902693  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:20:41.043601  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9145
I0928 11:20:41.043638  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.281992 (* 1 = 0.281992 loss)
I0928 11:20:41.185151  4247 solver.cpp:218] Iteration 43500 (5.64392 iter/s, 17.7182s/100 iters), loss = 0.0252441
I0928 11:20:41.185179  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0252443 (* 1 = 0.0252443 loss)
I0928 11:20:41.185186  4247 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I0928 11:20:55.402235  4247 solver.cpp:218] Iteration 43600 (7.03383 iter/s, 14.217s/100 iters), loss = 0.0733181
I0928 11:20:55.402276  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0733182 (* 1 = 0.0733182 loss)
I0928 11:20:55.402281  4247 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I0928 11:21:09.631036  4247 solver.cpp:218] Iteration 43700 (7.02804 iter/s, 14.2287s/100 iters), loss = 0.0294867
I0928 11:21:09.631139  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0294869 (* 1 = 0.0294869 loss)
I0928 11:21:09.631156  4247 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I0928 11:21:23.860946  4247 solver.cpp:218] Iteration 43800 (7.02752 iter/s, 14.2298s/100 iters), loss = 0.0152174
I0928 11:21:23.860990  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152175 (* 1 = 0.0152175 loss)
I0928 11:21:23.860996  4247 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I0928 11:21:38.092008  4247 solver.cpp:218] Iteration 43900 (7.02692 iter/s, 14.231s/100 iters), loss = 0.0301426
I0928 11:21:38.092051  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0301427 (* 1 = 0.0301427 loss)
I0928 11:21:38.092058  4247 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I0928 11:21:51.612148  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:21:52.181608  4247 solver.cpp:330] Iteration 44000, Testing net (#0)
I0928 11:21:55.536502  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:21:55.676811  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9156
I0928 11:21:55.676838  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.278287 (* 1 = 0.278287 loss)
I0928 11:21:55.818235  4247 solver.cpp:218] Iteration 44000 (5.64139 iter/s, 17.7261s/100 iters), loss = 0.0351941
I0928 11:21:55.818265  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0351943 (* 1 = 0.0351943 loss)
I0928 11:21:55.818272  4247 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I0928 11:22:10.040738  4247 solver.cpp:218] Iteration 44100 (7.03115 iter/s, 14.2224s/100 iters), loss = 0.0852856
I0928 11:22:10.040779  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0852858 (* 1 = 0.0852858 loss)
I0928 11:22:10.040786  4247 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I0928 11:22:24.260946  4247 solver.cpp:218] Iteration 44200 (7.03229 iter/s, 14.2201s/100 iters), loss = 0.0168673
I0928 11:22:24.261051  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0168675 (* 1 = 0.0168675 loss)
I0928 11:22:24.261059  4247 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I0928 11:22:38.484236  4247 solver.cpp:218] Iteration 44300 (7.0308 iter/s, 14.2231s/100 iters), loss = 0.0222905
I0928 11:22:38.484277  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0222907 (* 1 = 0.0222907 loss)
I0928 11:22:38.484283  4247 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I0928 11:22:52.703794  4247 solver.cpp:218] Iteration 44400 (7.03261 iter/s, 14.2195s/100 iters), loss = 0.0465206
I0928 11:22:52.703824  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0465208 (* 1 = 0.0465208 loss)
I0928 11:22:52.703830  4247 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I0928 11:23:06.220569  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:23:06.789338  4247 solver.cpp:330] Iteration 44500, Testing net (#0)
I0928 11:23:10.145967  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:23:10.286542  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9175
I0928 11:23:10.286578  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.270804 (* 1 = 0.270804 loss)
I0928 11:23:10.428084  4247 solver.cpp:218] Iteration 44500 (5.642 iter/s, 17.7242s/100 iters), loss = 0.023289
I0928 11:23:10.428114  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0232892 (* 1 = 0.0232892 loss)
I0928 11:23:10.428122  4247 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I0928 11:23:24.647372  4247 solver.cpp:218] Iteration 44600 (7.03274 iter/s, 14.2192s/100 iters), loss = 0.0336726
I0928 11:23:24.647404  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0336728 (* 1 = 0.0336728 loss)
I0928 11:23:24.647410  4247 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I0928 11:23:38.868577  4247 solver.cpp:218] Iteration 44700 (7.03179 iter/s, 14.2211s/100 iters), loss = 0.0193688
I0928 11:23:38.868654  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0193691 (* 1 = 0.0193691 loss)
I0928 11:23:38.868660  4247 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I0928 11:23:53.092443  4247 solver.cpp:218] Iteration 44800 (7.0305 iter/s, 14.2237s/100 iters), loss = 0.0292675
I0928 11:23:53.092476  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0292677 (* 1 = 0.0292677 loss)
I0928 11:23:53.092483  4247 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I0928 11:24:07.315093  4247 solver.cpp:218] Iteration 44900 (7.03108 iter/s, 14.2226s/100 iters), loss = 0.060122
I0928 11:24:07.315135  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0601222 (* 1 = 0.0601222 loss)
I0928 11:24:07.315140  4247 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I0928 11:24:20.824586  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:24:21.393636  4247 solver.cpp:330] Iteration 45000, Testing net (#0)
I0928 11:24:24.750610  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:24:24.891085  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.918
I0928 11:24:24.891113  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.280616 (* 1 = 0.280616 loss)
I0928 11:24:25.032177  4247 solver.cpp:218] Iteration 45000 (5.6443 iter/s, 17.717s/100 iters), loss = 0.0249391
I0928 11:24:25.032207  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0249393 (* 1 = 0.0249393 loss)
I0928 11:24:25.032213  4247 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I0928 11:24:39.245959  4247 solver.cpp:218] Iteration 45100 (7.03546 iter/s, 14.2137s/100 iters), loss = 0.027613
I0928 11:24:39.246001  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0276132 (* 1 = 0.0276132 loss)
I0928 11:24:39.246006  4247 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I0928 11:24:53.457125  4247 solver.cpp:218] Iteration 45200 (7.03676 iter/s, 14.2111s/100 iters), loss = 0.0408347
I0928 11:24:53.457267  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0408349 (* 1 = 0.0408349 loss)
I0928 11:24:53.457274  4247 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I0928 11:25:07.672505  4247 solver.cpp:218] Iteration 45300 (7.03472 iter/s, 14.2152s/100 iters), loss = 0.00910507
I0928 11:25:07.672536  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00910526 (* 1 = 0.00910526 loss)
I0928 11:25:07.672543  4247 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I0928 11:25:21.881079  4247 solver.cpp:218] Iteration 45400 (7.03804 iter/s, 14.2085s/100 iters), loss = 0.0155949
I0928 11:25:21.881111  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155951 (* 1 = 0.0155951 loss)
I0928 11:25:21.881127  4247 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I0928 11:25:35.394064  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:25:35.963614  4247 solver.cpp:330] Iteration 45500, Testing net (#0)
I0928 11:25:39.319948  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:25:39.460144  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9166
I0928 11:25:39.460180  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.293928 (* 1 = 0.293928 loss)
I0928 11:25:39.602061  4247 solver.cpp:218] Iteration 45500 (5.64305 iter/s, 17.7209s/100 iters), loss = 0.0115572
I0928 11:25:39.602090  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115574 (* 1 = 0.0115574 loss)
I0928 11:25:39.602097  4247 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I0928 11:25:53.818778  4247 solver.cpp:218] Iteration 45600 (7.03401 iter/s, 14.2166s/100 iters), loss = 0.0553288
I0928 11:25:53.818822  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.055329 (* 1 = 0.055329 loss)
I0928 11:25:53.818828  4247 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I0928 11:26:08.041535  4247 solver.cpp:218] Iteration 45700 (7.03103 iter/s, 14.2227s/100 iters), loss = 0.00923554
I0928 11:26:08.041645  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00923577 (* 1 = 0.00923577 loss)
I0928 11:26:08.041651  4247 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I0928 11:26:22.261232  4247 solver.cpp:218] Iteration 45800 (7.03257 iter/s, 14.2195s/100 iters), loss = 0.0273163
I0928 11:26:22.261274  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0273165 (* 1 = 0.0273165 loss)
I0928 11:26:22.261281  4247 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I0928 11:26:36.485064  4247 solver.cpp:218] Iteration 45900 (7.0305 iter/s, 14.2237s/100 iters), loss = 0.0174576
I0928 11:26:36.485106  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0174578 (* 1 = 0.0174578 loss)
I0928 11:26:36.485112  4247 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I0928 11:26:50.006453  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:26:50.576058  4247 solver.cpp:330] Iteration 46000, Testing net (#0)
I0928 11:26:53.932729  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:26:54.073058  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9127
I0928 11:26:54.073096  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300265 (* 1 = 0.300265 loss)
I0928 11:26:54.214392  4247 solver.cpp:218] Iteration 46000 (5.6404 iter/s, 17.7292s/100 iters), loss = 0.0191027
I0928 11:26:54.214423  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0191029 (* 1 = 0.0191029 loss)
I0928 11:26:54.214429  4247 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I0928 11:27:08.440546  4247 solver.cpp:218] Iteration 46100 (7.02935 iter/s, 14.2261s/100 iters), loss = 0.0530432
I0928 11:27:08.440588  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0530434 (* 1 = 0.0530434 loss)
I0928 11:27:08.440594  4247 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I0928 11:27:22.669808  4247 solver.cpp:218] Iteration 46200 (7.02781 iter/s, 14.2292s/100 iters), loss = 0.0149162
I0928 11:27:22.669908  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149164 (* 1 = 0.0149164 loss)
I0928 11:27:22.669914  4247 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I0928 11:27:36.899835  4247 solver.cpp:218] Iteration 46300 (7.02746 iter/s, 14.2299s/100 iters), loss = 0.0269053
I0928 11:27:36.899878  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0269055 (* 1 = 0.0269055 loss)
I0928 11:27:36.899883  4247 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I0928 11:27:51.130446  4247 solver.cpp:218] Iteration 46400 (7.02715 iter/s, 14.2305s/100 iters), loss = 0.0170236
I0928 11:27:51.130489  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0170237 (* 1 = 0.0170237 loss)
I0928 11:27:51.130496  4247 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I0928 11:28:04.649816  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:28:05.220705  4247 solver.cpp:330] Iteration 46500, Testing net (#0)
I0928 11:28:08.575717  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:28:08.716051  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.913
I0928 11:28:08.716089  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325502 (* 1 = 0.325502 loss)
I0928 11:28:08.857053  4247 solver.cpp:218] Iteration 46500 (5.64127 iter/s, 17.7265s/100 iters), loss = 0.00765368
I0928 11:28:08.857081  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00765387 (* 1 = 0.00765387 loss)
I0928 11:28:08.857089  4247 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I0928 11:28:23.073228  4247 solver.cpp:218] Iteration 46600 (7.03428 iter/s, 14.2161s/100 iters), loss = 0.0359881
I0928 11:28:23.073271  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0359882 (* 1 = 0.0359882 loss)
I0928 11:28:23.073276  4247 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I0928 11:28:37.295325  4247 solver.cpp:218] Iteration 46700 (7.03135 iter/s, 14.222s/100 iters), loss = 0.0318474
I0928 11:28:37.295415  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0318475 (* 1 = 0.0318475 loss)
I0928 11:28:37.295433  4247 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I0928 11:28:51.519130  4247 solver.cpp:218] Iteration 46800 (7.03053 iter/s, 14.2237s/100 iters), loss = 0.0118263
I0928 11:28:51.519161  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118265 (* 1 = 0.0118265 loss)
I0928 11:28:51.519166  4247 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I0928 11:29:05.738167  4247 solver.cpp:218] Iteration 46900 (7.03286 iter/s, 14.219s/100 iters), loss = 0.0158018
I0928 11:29:05.738209  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0158019 (* 1 = 0.0158019 loss)
I0928 11:29:05.738214  4247 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I0928 11:29:19.257522  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:29:19.826550  4247 solver.cpp:330] Iteration 47000, Testing net (#0)
I0928 11:29:23.183696  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:29:23.324064  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9161
I0928 11:29:23.324090  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.302203 (* 1 = 0.302203 loss)
I0928 11:29:23.465342  4247 solver.cpp:218] Iteration 47000 (5.64109 iter/s, 17.7271s/100 iters), loss = 0.00934162
I0928 11:29:23.465373  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00934181 (* 1 = 0.00934181 loss)
I0928 11:29:23.465378  4247 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I0928 11:29:37.685988  4247 solver.cpp:218] Iteration 47100 (7.03206 iter/s, 14.2206s/100 iters), loss = 0.0229894
I0928 11:29:37.686019  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0229896 (* 1 = 0.0229896 loss)
I0928 11:29:37.686025  4247 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I0928 11:29:51.908751  4247 solver.cpp:218] Iteration 47200 (7.03102 iter/s, 14.2227s/100 iters), loss = 0.0531457
I0928 11:29:51.908838  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0531459 (* 1 = 0.0531459 loss)
I0928 11:29:51.908854  4247 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I0928 11:30:06.130117  4247 solver.cpp:218] Iteration 47300 (7.03173 iter/s, 14.2212s/100 iters), loss = 0.0151996
I0928 11:30:06.130149  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0151998 (* 1 = 0.0151998 loss)
I0928 11:30:06.130154  4247 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I0928 11:30:20.351471  4247 solver.cpp:218] Iteration 47400 (7.03172 iter/s, 14.2213s/100 iters), loss = 0.0113681
I0928 11:30:20.351502  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113683 (* 1 = 0.0113683 loss)
I0928 11:30:20.351510  4247 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I0928 11:30:33.869621  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:30:34.439894  4247 solver.cpp:330] Iteration 47500, Testing net (#0)
I0928 11:30:37.797538  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:30:37.938498  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9166
I0928 11:30:37.938537  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308677 (* 1 = 0.308677 loss)
I0928 11:30:38.079067  4247 solver.cpp:218] Iteration 47500 (5.64095 iter/s, 17.7275s/100 iters), loss = 0.0122028
I0928 11:30:38.079097  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012203 (* 1 = 0.012203 loss)
I0928 11:30:38.079104  4247 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I0928 11:30:52.295140  4247 solver.cpp:218] Iteration 47600 (7.03433 iter/s, 14.216s/100 iters), loss = 0.0230357
I0928 11:30:52.295171  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0230359 (* 1 = 0.0230359 loss)
I0928 11:30:52.295177  4247 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I0928 11:31:06.517350  4247 solver.cpp:218] Iteration 47700 (7.03129 iter/s, 14.2221s/100 iters), loss = 0.0288296
I0928 11:31:06.517479  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0288298 (* 1 = 0.0288298 loss)
I0928 11:31:06.517487  4247 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I0928 11:31:20.736119  4247 solver.cpp:218] Iteration 47800 (7.03304 iter/s, 14.2186s/100 iters), loss = 0.00479262
I0928 11:31:20.736151  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0047928 (* 1 = 0.0047928 loss)
I0928 11:31:20.736158  4247 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I0928 11:31:34.951491  4247 solver.cpp:218] Iteration 47900 (7.03468 iter/s, 14.2153s/100 iters), loss = 0.00489975
I0928 11:31:34.951522  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00489992 (* 1 = 0.00489992 loss)
I0928 11:31:34.951539  4247 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I0928 11:31:48.465008  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:31:49.034174  4247 solver.cpp:330] Iteration 48000, Testing net (#0)
I0928 11:31:52.389935  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:31:52.530097  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9178
I0928 11:31:52.530134  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.293974 (* 1 = 0.293974 loss)
I0928 11:31:52.670418  4247 solver.cpp:218] Iteration 48000 (5.64371 iter/s, 17.7188s/100 iters), loss = 0.00999469
I0928 11:31:52.670446  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00999487 (* 1 = 0.00999487 loss)
I0928 11:31:52.670454  4247 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I0928 11:32:06.886679  4247 solver.cpp:218] Iteration 48100 (7.03424 iter/s, 14.2162s/100 iters), loss = 0.0130682
I0928 11:32:06.886721  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130683 (* 1 = 0.0130683 loss)
I0928 11:32:06.886728  4247 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I0928 11:32:21.108486  4247 solver.cpp:218] Iteration 48200 (7.0315 iter/s, 14.2217s/100 iters), loss = 0.00968073
I0928 11:32:21.108592  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00968089 (* 1 = 0.00968089 loss)
I0928 11:32:21.108609  4247 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I0928 11:32:35.327204  4247 solver.cpp:218] Iteration 48300 (7.03306 iter/s, 14.2186s/100 iters), loss = 0.0315881
I0928 11:32:35.327247  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0315883 (* 1 = 0.0315883 loss)
I0928 11:32:35.327253  4247 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I0928 11:32:49.548888  4247 solver.cpp:218] Iteration 48400 (7.03156 iter/s, 14.2216s/100 iters), loss = 0.0182014
I0928 11:32:49.548919  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0182015 (* 1 = 0.0182015 loss)
I0928 11:32:49.548925  4247 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I0928 11:33:03.067381  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:33:03.636519  4247 solver.cpp:330] Iteration 48500, Testing net (#0)
I0928 11:33:06.992498  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:33:07.132686  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9195
I0928 11:33:07.132722  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.290208 (* 1 = 0.290208 loss)
I0928 11:33:07.273831  4247 solver.cpp:218] Iteration 48500 (5.64179 iter/s, 17.7249s/100 iters), loss = 0.0113696
I0928 11:33:07.273861  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113698 (* 1 = 0.0113698 loss)
I0928 11:33:07.273869  4247 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I0928 11:33:21.495028  4247 solver.cpp:218] Iteration 48600 (7.03179 iter/s, 14.2211s/100 iters), loss = 0.00425118
I0928 11:33:21.495060  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00425135 (* 1 = 0.00425135 loss)
I0928 11:33:21.495066  4247 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I0928 11:33:35.722192  4247 solver.cpp:218] Iteration 48700 (7.02884 iter/s, 14.2271s/100 iters), loss = 0.0391822
I0928 11:33:35.722327  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0391824 (* 1 = 0.0391824 loss)
I0928 11:33:35.722335  4247 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I0928 11:33:49.940815  4247 solver.cpp:218] Iteration 48800 (7.03311 iter/s, 14.2185s/100 iters), loss = 0.0289126
I0928 11:33:49.940858  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0289128 (* 1 = 0.0289128 loss)
I0928 11:33:49.940865  4247 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I0928 11:34:04.165233  4247 solver.cpp:218] Iteration 48900 (7.03021 iter/s, 14.2243s/100 iters), loss = 0.0365459
I0928 11:34:04.165266  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0365461 (* 1 = 0.0365461 loss)
I0928 11:34:04.165271  4247 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I0928 11:34:17.680860  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:34:18.249864  4247 solver.cpp:330] Iteration 49000, Testing net (#0)
I0928 11:34:21.606468  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:34:21.746747  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9176
I0928 11:34:21.746783  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308533 (* 1 = 0.308533 loss)
I0928 11:34:21.888190  4247 solver.cpp:218] Iteration 49000 (5.64243 iter/s, 17.7229s/100 iters), loss = 0.0293984
I0928 11:34:21.888219  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0293985 (* 1 = 0.0293985 loss)
I0928 11:34:21.888226  4247 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I0928 11:34:36.103709  4247 solver.cpp:218] Iteration 49100 (7.0346 iter/s, 14.2155s/100 iters), loss = 0.0285621
I0928 11:34:36.103741  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0285623 (* 1 = 0.0285623 loss)
I0928 11:34:36.103746  4247 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I0928 11:34:50.324749  4247 solver.cpp:218] Iteration 49200 (7.03187 iter/s, 14.221s/100 iters), loss = 0.00829302
I0928 11:34:50.324870  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0082932 (* 1 = 0.0082932 loss)
I0928 11:34:50.324888  4247 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I0928 11:35:04.549095  4247 solver.cpp:218] Iteration 49300 (7.03028 iter/s, 14.2242s/100 iters), loss = 0.00514341
I0928 11:35:04.549139  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00514358 (* 1 = 0.00514358 loss)
I0928 11:35:04.549144  4247 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I0928 11:35:18.771800  4247 solver.cpp:218] Iteration 49400 (7.03105 iter/s, 14.2226s/100 iters), loss = 0.0112286
I0928 11:35:18.771842  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112288 (* 1 = 0.0112288 loss)
I0928 11:35:18.771848  4247 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I0928 11:35:32.288421  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:35:32.858783  4247 solver.cpp:330] Iteration 49500, Testing net (#0)
I0928 11:35:36.214680  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:35:36.355129  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9195
I0928 11:35:36.355167  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295223 (* 1 = 0.295223 loss)
I0928 11:35:36.496261  4247 solver.cpp:218] Iteration 49500 (5.64195 iter/s, 17.7244s/100 iters), loss = 0.00339544
I0928 11:35:36.496291  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0033956 (* 1 = 0.0033956 loss)
I0928 11:35:36.496297  4247 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I0928 11:35:50.708763  4247 solver.cpp:218] Iteration 49600 (7.0361 iter/s, 14.2124s/100 iters), loss = 0.00625608
I0928 11:35:50.708796  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00625626 (* 1 = 0.00625626 loss)
I0928 11:35:50.708803  4247 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I0928 11:36:04.928155  4247 solver.cpp:218] Iteration 49700 (7.03269 iter/s, 14.2193s/100 iters), loss = 0.0258213
I0928 11:36:04.928231  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0258214 (* 1 = 0.0258214 loss)
I0928 11:36:04.928238  4247 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I0928 11:36:19.146028  4247 solver.cpp:218] Iteration 49800 (7.03346 iter/s, 14.2178s/100 iters), loss = 0.00322041
I0928 11:36:19.146070  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00322059 (* 1 = 0.00322059 loss)
I0928 11:36:19.146076  4247 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I0928 11:36:33.361167  4247 solver.cpp:218] Iteration 49900 (7.03479 iter/s, 14.2151s/100 iters), loss = 0.00874141
I0928 11:36:33.361198  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00874159 (* 1 = 0.00874159 loss)
I0928 11:36:33.361204  4247 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I0928 11:36:46.874347  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:36:47.443899  4247 solver.cpp:330] Iteration 50000, Testing net (#0)
I0928 11:36:50.800796  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:36:50.940449  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9181
I0928 11:36:50.940485  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303272 (* 1 = 0.303272 loss)
I0928 11:36:51.081735  4247 solver.cpp:218] Iteration 50000 (5.64319 iter/s, 17.7205s/100 iters), loss = 0.0035088
I0928 11:36:51.081765  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00350899 (* 1 = 0.00350899 loss)
I0928 11:36:51.081773  4247 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I0928 11:37:05.288228  4247 solver.cpp:218] Iteration 50100 (7.03907 iter/s, 14.2064s/100 iters), loss = 0.0099968
I0928 11:37:05.288269  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00999699 (* 1 = 0.00999699 loss)
I0928 11:37:05.288276  4247 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I0928 11:37:19.500190  4247 solver.cpp:218] Iteration 50200 (7.03637 iter/s, 14.2119s/100 iters), loss = 0.00424051
I0928 11:37:19.500304  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0042407 (* 1 = 0.0042407 loss)
I0928 11:37:19.500321  4247 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I0928 11:37:33.714529  4247 solver.cpp:218] Iteration 50300 (7.03523 iter/s, 14.2142s/100 iters), loss = 0.00409506
I0928 11:37:33.714562  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00409526 (* 1 = 0.00409526 loss)
I0928 11:37:33.714568  4247 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I0928 11:37:47.932083  4247 solver.cpp:218] Iteration 50400 (7.0336 iter/s, 14.2175s/100 iters), loss = 0.00714888
I0928 11:37:47.932124  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00714908 (* 1 = 0.00714908 loss)
I0928 11:37:47.932130  4247 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I0928 11:38:01.444881  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:38:02.014905  4247 solver.cpp:330] Iteration 50500, Testing net (#0)
I0928 11:38:05.370687  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:38:05.511027  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9199
I0928 11:38:05.511065  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.298202 (* 1 = 0.298202 loss)
I0928 11:38:05.652498  4247 solver.cpp:218] Iteration 50500 (5.64324 iter/s, 17.7203s/100 iters), loss = 0.00398268
I0928 11:38:05.652528  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00398288 (* 1 = 0.00398288 loss)
I0928 11:38:05.652534  4247 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I0928 11:38:19.870185  4247 solver.cpp:218] Iteration 50600 (7.03353 iter/s, 14.2176s/100 iters), loss = 0.0070635
I0928 11:38:19.870226  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00706371 (* 1 = 0.00706371 loss)
I0928 11:38:19.870232  4247 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I0928 11:38:34.092279  4247 solver.cpp:218] Iteration 50700 (7.03135 iter/s, 14.222s/100 iters), loss = 0.027296
I0928 11:38:34.092365  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0272962 (* 1 = 0.0272962 loss)
I0928 11:38:34.092382  4247 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I0928 11:38:48.311211  4247 solver.cpp:218] Iteration 50800 (7.03294 iter/s, 14.2188s/100 iters), loss = 0.00460145
I0928 11:38:48.311254  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00460166 (* 1 = 0.00460166 loss)
I0928 11:38:48.311259  4247 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I0928 11:39:02.528901  4247 solver.cpp:218] Iteration 50900 (7.03353 iter/s, 14.2176s/100 iters), loss = 0.0575915
I0928 11:39:02.528942  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0575918 (* 1 = 0.0575918 loss)
I0928 11:39:02.528949  4247 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I0928 11:39:16.040593  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:39:16.610357  4247 solver.cpp:330] Iteration 51000, Testing net (#0)
I0928 11:39:19.965625  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:39:20.105784  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9231
I0928 11:39:20.105821  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296578 (* 1 = 0.296578 loss)
I0928 11:39:20.247179  4247 solver.cpp:218] Iteration 51000 (5.64392 iter/s, 17.7182s/100 iters), loss = 0.00496602
I0928 11:39:20.247208  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00496622 (* 1 = 0.00496622 loss)
I0928 11:39:20.247215  4247 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I0928 11:39:34.466667  4247 solver.cpp:218] Iteration 51100 (7.03264 iter/s, 14.2194s/100 iters), loss = 0.00688302
I0928 11:39:34.466711  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00688322 (* 1 = 0.00688322 loss)
I0928 11:39:34.466717  4247 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I0928 11:39:48.690944  4247 solver.cpp:218] Iteration 51200 (7.03027 iter/s, 14.2242s/100 iters), loss = 0.00411543
I0928 11:39:48.691026  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00411562 (* 1 = 0.00411562 loss)
I0928 11:39:48.691042  4247 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I0928 11:40:02.915263  4247 solver.cpp:218] Iteration 51300 (7.03028 iter/s, 14.2242s/100 iters), loss = 0.0105408
I0928 11:40:02.915307  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010541 (* 1 = 0.010541 loss)
I0928 11:40:02.915313  4247 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I0928 11:40:17.136131  4247 solver.cpp:218] Iteration 51400 (7.03196 iter/s, 14.2208s/100 iters), loss = 0.0177259
I0928 11:40:17.136173  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177261 (* 1 = 0.0177261 loss)
I0928 11:40:17.136179  4247 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I0928 11:40:30.650074  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:40:31.221473  4247 solver.cpp:330] Iteration 51500, Testing net (#0)
I0928 11:40:34.576661  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:40:34.717320  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.919
I0928 11:40:34.717357  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312792 (* 1 = 0.312792 loss)
I0928 11:40:34.858518  4247 solver.cpp:218] Iteration 51500 (5.64261 iter/s, 17.7223s/100 iters), loss = 0.000924936
I0928 11:40:34.858551  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000925143 (* 1 = 0.000925143 loss)
I0928 11:40:34.858557  4247 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I0928 11:40:49.072868  4247 solver.cpp:218] Iteration 51600 (7.03518 iter/s, 14.2143s/100 iters), loss = 0.00428976
I0928 11:40:49.072911  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00428996 (* 1 = 0.00428996 loss)
I0928 11:40:49.072916  4247 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I0928 11:41:03.293712  4247 solver.cpp:218] Iteration 51700 (7.03197 iter/s, 14.2208s/100 iters), loss = 0.0216016
I0928 11:41:03.293815  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0216018 (* 1 = 0.0216018 loss)
I0928 11:41:03.293823  4247 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I0928 11:41:17.519065  4247 solver.cpp:218] Iteration 51800 (7.02977 iter/s, 14.2252s/100 iters), loss = 0.00327329
I0928 11:41:17.519109  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00327349 (* 1 = 0.00327349 loss)
I0928 11:41:17.519114  4247 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I0928 11:41:31.743652  4247 solver.cpp:218] Iteration 51900 (7.03012 iter/s, 14.2245s/100 iters), loss = 0.00479082
I0928 11:41:31.743695  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00479102 (* 1 = 0.00479102 loss)
I0928 11:41:31.743701  4247 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I0928 11:41:45.258827  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:41:45.827513  4247 solver.cpp:330] Iteration 52000, Testing net (#0)
I0928 11:41:49.183459  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:41:49.323655  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.92
I0928 11:41:49.323693  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311368 (* 1 = 0.311368 loss)
I0928 11:41:49.465153  4247 solver.cpp:218] Iteration 52000 (5.64289 iter/s, 17.7214s/100 iters), loss = 0.036465
I0928 11:41:49.465183  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0364652 (* 1 = 0.0364652 loss)
I0928 11:41:49.465190  4247 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I0928 11:42:03.678759  4247 solver.cpp:218] Iteration 52100 (7.03555 iter/s, 14.2135s/100 iters), loss = 0.00296468
I0928 11:42:03.678802  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00296488 (* 1 = 0.00296488 loss)
I0928 11:42:03.678808  4247 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I0928 11:42:17.903034  4247 solver.cpp:218] Iteration 52200 (7.03028 iter/s, 14.2242s/100 iters), loss = 0.0143146
I0928 11:42:17.903120  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143148 (* 1 = 0.0143148 loss)
I0928 11:42:17.903136  4247 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I0928 11:42:32.122110  4247 solver.cpp:218] Iteration 52300 (7.03287 iter/s, 14.219s/100 iters), loss = 0.0445576
I0928 11:42:32.122151  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0445578 (* 1 = 0.0445578 loss)
I0928 11:42:32.122158  4247 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I0928 11:42:46.338621  4247 solver.cpp:218] Iteration 52400 (7.03412 iter/s, 14.2164s/100 iters), loss = 0.011283
I0928 11:42:46.338672  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112832 (* 1 = 0.0112832 loss)
I0928 11:42:46.338680  4247 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I0928 11:42:59.850421  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:43:00.421597  4247 solver.cpp:330] Iteration 52500, Testing net (#0)
I0928 11:43:03.777536  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:43:03.917865  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9203
I0928 11:43:03.917901  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310394 (* 1 = 0.310394 loss)
I0928 11:43:04.058707  4247 solver.cpp:218] Iteration 52500 (5.64335 iter/s, 17.72s/100 iters), loss = 0.00191345
I0928 11:43:04.058737  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00191363 (* 1 = 0.00191363 loss)
I0928 11:43:04.058744  4247 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I0928 11:43:18.272586  4247 solver.cpp:218] Iteration 52600 (7.03541 iter/s, 14.2138s/100 iters), loss = 0.00861173
I0928 11:43:18.272627  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00861191 (* 1 = 0.00861191 loss)
I0928 11:43:18.272634  4247 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I0928 11:43:32.488564  4247 solver.cpp:218] Iteration 52700 (7.03438 iter/s, 14.2159s/100 iters), loss = 0.00238336
I0928 11:43:32.488705  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00238355 (* 1 = 0.00238355 loss)
I0928 11:43:32.488713  4247 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I0928 11:43:46.709911  4247 solver.cpp:218] Iteration 52800 (7.03177 iter/s, 14.2212s/100 iters), loss = 0.00745189
I0928 11:43:46.709944  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00745208 (* 1 = 0.00745208 loss)
I0928 11:43:46.709959  4247 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I0928 11:44:00.926172  4247 solver.cpp:218] Iteration 52900 (7.03424 iter/s, 14.2162s/100 iters), loss = 0.00540798
I0928 11:44:00.926205  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00540817 (* 1 = 0.00540817 loss)
I0928 11:44:00.926213  4247 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I0928 11:44:14.438196  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:44:15.008324  4247 solver.cpp:330] Iteration 53000, Testing net (#0)
I0928 11:44:18.364351  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:44:18.504606  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9188
I0928 11:44:18.504634  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326265 (* 1 = 0.326265 loss)
I0928 11:44:18.645941  4247 solver.cpp:218] Iteration 53000 (5.64344 iter/s, 17.7197s/100 iters), loss = 0.00442346
I0928 11:44:18.645968  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00442366 (* 1 = 0.00442366 loss)
I0928 11:44:18.645975  4247 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I0928 11:44:32.869408  4247 solver.cpp:218] Iteration 53100 (7.03067 iter/s, 14.2234s/100 iters), loss = 0.0149838
I0928 11:44:32.869451  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014984 (* 1 = 0.014984 loss)
I0928 11:44:32.869457  4247 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I0928 11:44:47.093803  4247 solver.cpp:218] Iteration 53200 (7.03022 iter/s, 14.2243s/100 iters), loss = 0.00307208
I0928 11:44:47.093891  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00307227 (* 1 = 0.00307227 loss)
I0928 11:44:47.093907  4247 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I0928 11:45:01.318614  4247 solver.cpp:218] Iteration 53300 (7.03003 iter/s, 14.2247s/100 iters), loss = 0.00583577
I0928 11:45:01.318655  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00583595 (* 1 = 0.00583595 loss)
I0928 11:45:01.318662  4247 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I0928 11:45:15.538316  4247 solver.cpp:218] Iteration 53400 (7.03254 iter/s, 14.2196s/100 iters), loss = 0.00994646
I0928 11:45:15.538347  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00994664 (* 1 = 0.00994664 loss)
I0928 11:45:15.538353  4247 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I0928 11:45:29.052325  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:45:29.622815  4247 solver.cpp:330] Iteration 53500, Testing net (#0)
I0928 11:45:32.980065  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:45:33.120347  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9159
I0928 11:45:33.120371  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335458 (* 1 = 0.335458 loss)
I0928 11:45:33.261335  4247 solver.cpp:218] Iteration 53500 (5.64241 iter/s, 17.7229s/100 iters), loss = 0.0117397
I0928 11:45:33.261365  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117399 (* 1 = 0.0117399 loss)
I0928 11:45:33.261371  4247 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I0928 11:45:47.483644  4247 solver.cpp:218] Iteration 53600 (7.03124 iter/s, 14.2222s/100 iters), loss = 0.0136168
I0928 11:45:47.483686  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013617 (* 1 = 0.013617 loss)
I0928 11:45:47.483693  4247 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I0928 11:46:01.711768  4247 solver.cpp:218] Iteration 53700 (7.02837 iter/s, 14.228s/100 iters), loss = 0.00992644
I0928 11:46:01.711871  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00992662 (* 1 = 0.00992662 loss)
I0928 11:46:01.711887  4247 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I0928 11:46:15.938530  4247 solver.cpp:218] Iteration 53800 (7.02908 iter/s, 14.2266s/100 iters), loss = 0.00328478
I0928 11:46:15.938572  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00328497 (* 1 = 0.00328497 loss)
I0928 11:46:15.938578  4247 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I0928 11:46:30.169533  4247 solver.cpp:218] Iteration 53900 (7.02695 iter/s, 14.2309s/100 iters), loss = 0.0406009
I0928 11:46:30.169564  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0406011 (* 1 = 0.0406011 loss)
I0928 11:46:30.169569  4247 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I0928 11:46:43.696105  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:46:44.265923  4247 solver.cpp:330] Iteration 54000, Testing net (#0)
I0928 11:46:47.620805  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:46:47.761145  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9207
I0928 11:46:47.761171  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319459 (* 1 = 0.319459 loss)
I0928 11:46:47.901643  4247 solver.cpp:218] Iteration 54000 (5.63951 iter/s, 17.732s/100 iters), loss = 0.00187639
I0928 11:46:47.901674  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00187657 (* 1 = 0.00187657 loss)
I0928 11:46:47.901679  4247 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I0928 11:47:02.121592  4247 solver.cpp:218] Iteration 54100 (7.03241 iter/s, 14.2199s/100 iters), loss = 0.00983426
I0928 11:47:02.121634  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00983444 (* 1 = 0.00983444 loss)
I0928 11:47:02.121640  4247 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I0928 11:47:16.339391  4247 solver.cpp:218] Iteration 54200 (7.03348 iter/s, 14.2177s/100 iters), loss = 0.00153785
I0928 11:47:16.339507  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153803 (* 1 = 0.00153803 loss)
I0928 11:47:16.339515  4247 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I0928 11:47:30.561712  4247 solver.cpp:218] Iteration 54300 (7.03128 iter/s, 14.2222s/100 iters), loss = 0.00715726
I0928 11:47:30.561744  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00715744 (* 1 = 0.00715744 loss)
I0928 11:47:30.561750  4247 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I0928 11:47:44.781452  4247 solver.cpp:218] Iteration 54400 (7.03251 iter/s, 14.2197s/100 iters), loss = 0.00423538
I0928 11:47:44.781484  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00423556 (* 1 = 0.00423556 loss)
I0928 11:47:44.781491  4247 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I0928 11:47:58.299281  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:47:58.867101  4247 solver.cpp:330] Iteration 54500, Testing net (#0)
I0928 11:48:02.225137  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:48:02.365506  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9198
I0928 11:48:02.365533  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31462 (* 1 = 0.31462 loss)
I0928 11:48:02.506580  4247 solver.cpp:218] Iteration 54500 (5.64173 iter/s, 17.725s/100 iters), loss = 0.00155336
I0928 11:48:02.506610  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00155355 (* 1 = 0.00155355 loss)
I0928 11:48:02.506618  4247 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I0928 11:48:16.723166  4247 solver.cpp:218] Iteration 54600 (7.03407 iter/s, 14.2165s/100 iters), loss = 0.0130304
I0928 11:48:16.723197  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130306 (* 1 = 0.0130306 loss)
I0928 11:48:16.723203  4247 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I0928 11:48:30.944702  4247 solver.cpp:218] Iteration 54700 (7.03163 iter/s, 14.2215s/100 iters), loss = 0.00250573
I0928 11:48:30.944792  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00250592 (* 1 = 0.00250592 loss)
I0928 11:48:30.944808  4247 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I0928 11:48:45.159395  4247 solver.cpp:218] Iteration 54800 (7.03504 iter/s, 14.2146s/100 iters), loss = 0.0144054
I0928 11:48:45.159438  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0144056 (* 1 = 0.0144056 loss)
I0928 11:48:45.159445  4247 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I0928 11:48:59.377773  4247 solver.cpp:218] Iteration 54900 (7.03319 iter/s, 14.2183s/100 iters), loss = 0.00538203
I0928 11:48:59.377804  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00538222 (* 1 = 0.00538222 loss)
I0928 11:48:59.377810  4247 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I0928 11:49:12.894839  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:49:13.464180  4247 solver.cpp:330] Iteration 55000, Testing net (#0)
I0928 11:49:16.818936  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:49:16.960891  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9182
I0928 11:49:16.960917  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320775 (* 1 = 0.320775 loss)
I0928 11:49:17.101708  4247 solver.cpp:218] Iteration 55000 (5.64211 iter/s, 17.7239s/100 iters), loss = 0.00455132
I0928 11:49:17.101740  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00455151 (* 1 = 0.00455151 loss)
I0928 11:49:17.101757  4247 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I0928 11:49:31.310910  4247 solver.cpp:218] Iteration 55100 (7.03773 iter/s, 14.2091s/100 iters), loss = 0.0215677
I0928 11:49:31.310952  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0215679 (* 1 = 0.0215679 loss)
I0928 11:49:31.310958  4247 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I0928 11:49:45.527887  4247 solver.cpp:218] Iteration 55200 (7.03389 iter/s, 14.2169s/100 iters), loss = 0.00890218
I0928 11:49:45.527969  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00890237 (* 1 = 0.00890237 loss)
I0928 11:49:45.527986  4247 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I0928 11:49:59.746495  4247 solver.cpp:218] Iteration 55300 (7.0331 iter/s, 14.2185s/100 iters), loss = 0.0136674
I0928 11:49:59.746548  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136676 (* 1 = 0.0136676 loss)
I0928 11:49:59.746556  4247 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I0928 11:50:13.962327  4247 solver.cpp:218] Iteration 55400 (7.03445 iter/s, 14.2157s/100 iters), loss = 0.0015272
I0928 11:50:13.962369  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00152739 (* 1 = 0.00152739 loss)
I0928 11:50:13.962375  4247 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I0928 11:50:27.476801  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:50:28.046531  4247 solver.cpp:330] Iteration 55500, Testing net (#0)
I0928 11:50:31.401257  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:50:31.542407  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9131
I0928 11:50:31.542434  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.361209 (* 1 = 0.361209 loss)
I0928 11:50:31.683388  4247 solver.cpp:218] Iteration 55500 (5.64303 iter/s, 17.721s/100 iters), loss = 0.0077273
I0928 11:50:31.683418  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00772749 (* 1 = 0.00772749 loss)
I0928 11:50:31.683424  4247 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I0928 11:50:45.900943  4247 solver.cpp:218] Iteration 55600 (7.0336 iter/s, 14.2175s/100 iters), loss = 0.0060361
I0928 11:50:45.900986  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00603628 (* 1 = 0.00603628 loss)
I0928 11:50:45.900992  4247 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I0928 11:51:00.125025  4247 solver.cpp:218] Iteration 55700 (7.03037 iter/s, 14.224s/100 iters), loss = 0.00555102
I0928 11:51:00.125097  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00555119 (* 1 = 0.00555119 loss)
I0928 11:51:00.125104  4247 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I0928 11:51:14.355187  4247 solver.cpp:218] Iteration 55800 (7.02738 iter/s, 14.23s/100 iters), loss = 0.00882158
I0928 11:51:14.355229  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00882176 (* 1 = 0.00882176 loss)
I0928 11:51:14.355235  4247 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I0928 11:51:28.576401  4247 solver.cpp:218] Iteration 55900 (7.03179 iter/s, 14.2211s/100 iters), loss = 0.00319567
I0928 11:51:28.576431  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00319585 (* 1 = 0.00319585 loss)
I0928 11:51:28.576436  4247 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I0928 11:51:42.089764  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:51:42.662122  4247 solver.cpp:330] Iteration 56000, Testing net (#0)
I0928 11:51:46.016811  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:51:46.157402  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9193
I0928 11:51:46.157429  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.332482 (* 1 = 0.332482 loss)
I0928 11:51:46.299474  4247 solver.cpp:218] Iteration 56000 (5.64239 iter/s, 17.723s/100 iters), loss = 0.00688113
I0928 11:51:46.299502  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00688131 (* 1 = 0.00688131 loss)
I0928 11:51:46.299510  4247 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I0928 11:52:00.521543  4247 solver.cpp:218] Iteration 56100 (7.03136 iter/s, 14.222s/100 iters), loss = 0.0103722
I0928 11:52:00.521594  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103723 (* 1 = 0.0103723 loss)
I0928 11:52:00.521600  4247 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I0928 11:52:14.747817  4247 solver.cpp:218] Iteration 56200 (7.02929 iter/s, 14.2262s/100 iters), loss = 0.00557746
I0928 11:52:14.747884  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00557764 (* 1 = 0.00557764 loss)
I0928 11:52:14.747891  4247 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I0928 11:52:28.977876  4247 solver.cpp:218] Iteration 56300 (7.02743 iter/s, 14.23s/100 iters), loss = 0.006475
I0928 11:52:28.977917  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00647519 (* 1 = 0.00647519 loss)
I0928 11:52:28.977923  4247 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I0928 11:52:43.209152  4247 solver.cpp:218] Iteration 56400 (7.02682 iter/s, 14.2312s/100 iters), loss = 0.0106908
I0928 11:52:43.209194  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010691 (* 1 = 0.010691 loss)
I0928 11:52:43.209200  4247 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I0928 11:52:56.727713  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:52:57.297782  4247 solver.cpp:330] Iteration 56500, Testing net (#0)
I0928 11:53:00.653477  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:53:00.793346  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9154
I0928 11:53:00.793375  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.344254 (* 1 = 0.344254 loss)
I0928 11:53:00.934962  4247 solver.cpp:218] Iteration 56500 (5.64152 iter/s, 17.7257s/100 iters), loss = 0.00476091
I0928 11:53:00.934993  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00476109 (* 1 = 0.00476109 loss)
I0928 11:53:00.935000  4247 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I0928 11:53:15.157188  4247 solver.cpp:218] Iteration 56600 (7.03129 iter/s, 14.2221s/100 iters), loss = 0.0111957
I0928 11:53:15.157230  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111959 (* 1 = 0.0111959 loss)
I0928 11:53:15.157236  4247 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I0928 11:53:29.379403  4247 solver.cpp:218] Iteration 56700 (7.03129 iter/s, 14.2221s/100 iters), loss = 0.00499019
I0928 11:53:29.379516  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00499038 (* 1 = 0.00499038 loss)
I0928 11:53:29.379534  4247 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I0928 11:53:43.602306  4247 solver.cpp:218] Iteration 56800 (7.03099 iter/s, 14.2228s/100 iters), loss = 0.00371761
I0928 11:53:43.602349  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00371779 (* 1 = 0.00371779 loss)
I0928 11:53:43.602355  4247 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I0928 11:53:57.829484  4247 solver.cpp:218] Iteration 56900 (7.02884 iter/s, 14.2271s/100 iters), loss = 0.0101216
I0928 11:53:57.829527  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101218 (* 1 = 0.0101218 loss)
I0928 11:53:57.829535  4247 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I0928 11:54:11.347214  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:54:11.917548  4247 solver.cpp:330] Iteration 57000, Testing net (#0)
I0928 11:54:15.273407  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:54:15.413638  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9203
I0928 11:54:15.413676  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.331159 (* 1 = 0.331159 loss)
I0928 11:54:15.554755  4247 solver.cpp:218] Iteration 57000 (5.64169 iter/s, 17.7252s/100 iters), loss = 0.00216859
I0928 11:54:15.554785  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00216877 (* 1 = 0.00216877 loss)
I0928 11:54:15.554792  4247 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I0928 11:54:29.767925  4247 solver.cpp:218] Iteration 57100 (7.03576 iter/s, 14.2131s/100 iters), loss = 0.00209958
I0928 11:54:29.767968  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00209977 (* 1 = 0.00209977 loss)
I0928 11:54:29.767974  4247 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I0928 11:54:43.995682  4247 solver.cpp:218] Iteration 57200 (7.02856 iter/s, 14.2277s/100 iters), loss = 0.00210593
I0928 11:54:43.995759  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00210612 (* 1 = 0.00210612 loss)
I0928 11:54:43.995765  4247 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I0928 11:54:58.215674  4247 solver.cpp:218] Iteration 57300 (7.03241 iter/s, 14.2199s/100 iters), loss = 0.00140084
I0928 11:54:58.215708  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00140103 (* 1 = 0.00140103 loss)
I0928 11:54:58.215714  4247 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I0928 11:55:12.438403  4247 solver.cpp:218] Iteration 57400 (7.03104 iter/s, 14.2227s/100 iters), loss = 0.00247121
I0928 11:55:12.438447  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00247141 (* 1 = 0.00247141 loss)
I0928 11:55:12.438453  4247 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I0928 11:55:25.947207  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:55:26.516800  4247 solver.cpp:330] Iteration 57500, Testing net (#0)
I0928 11:55:29.873363  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:55:30.013828  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9192
I0928 11:55:30.013865  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.321894 (* 1 = 0.321894 loss)
I0928 11:55:30.154830  4247 solver.cpp:218] Iteration 57500 (5.64451 iter/s, 17.7163s/100 iters), loss = 0.00351523
I0928 11:55:30.154861  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00351542 (* 1 = 0.00351542 loss)
I0928 11:55:30.154867  4247 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I0928 11:55:44.367406  4247 solver.cpp:218] Iteration 57600 (7.03606 iter/s, 14.2125s/100 iters), loss = 0.0083484
I0928 11:55:44.367437  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00834859 (* 1 = 0.00834859 loss)
I0928 11:55:44.367444  4247 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I0928 11:55:58.584856  4247 solver.cpp:218] Iteration 57700 (7.03365 iter/s, 14.2174s/100 iters), loss = 0.00847575
I0928 11:55:58.584959  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00847595 (* 1 = 0.00847595 loss)
I0928 11:55:58.584966  4247 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I0928 11:56:12.806660  4247 solver.cpp:218] Iteration 57800 (7.03152 iter/s, 14.2217s/100 iters), loss = 0.00550478
I0928 11:56:12.806702  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00550498 (* 1 = 0.00550498 loss)
I0928 11:56:12.806708  4247 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I0928 11:56:27.026970  4247 solver.cpp:218] Iteration 57900 (7.03224 iter/s, 14.2202s/100 iters), loss = 0.0180712
I0928 11:56:27.027014  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0180714 (* 1 = 0.0180714 loss)
I0928 11:56:27.027020  4247 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I0928 11:56:40.544441  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:56:41.114050  4247 solver.cpp:330] Iteration 58000, Testing net (#0)
I0928 11:56:44.471068  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:56:44.611003  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9222
I0928 11:56:44.611042  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310491 (* 1 = 0.310491 loss)
I0928 11:56:44.752490  4247 solver.cpp:218] Iteration 58000 (5.64161 iter/s, 17.7254s/100 iters), loss = 0.00386709
I0928 11:56:44.752521  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00386729 (* 1 = 0.00386729 loss)
I0928 11:56:44.752528  4247 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I0928 11:56:58.963989  4247 solver.cpp:218] Iteration 58100 (7.03659 iter/s, 14.2114s/100 iters), loss = 0.0188029
I0928 11:56:58.964033  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0188031 (* 1 = 0.0188031 loss)
I0928 11:56:58.964040  4247 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I0928 11:57:13.182050  4247 solver.cpp:218] Iteration 58200 (7.03335 iter/s, 14.218s/100 iters), loss = 0.00431893
I0928 11:57:13.182158  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00431914 (* 1 = 0.00431914 loss)
I0928 11:57:13.182175  4247 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I0928 11:57:27.396354  4247 solver.cpp:218] Iteration 58300 (7.03524 iter/s, 14.2142s/100 iters), loss = 0.00269089
I0928 11:57:27.396397  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0026911 (* 1 = 0.0026911 loss)
I0928 11:57:27.396404  4247 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I0928 11:57:41.614742  4247 solver.cpp:218] Iteration 58400 (7.03319 iter/s, 14.2183s/100 iters), loss = 0.00224883
I0928 11:57:41.614784  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00224903 (* 1 = 0.00224903 loss)
I0928 11:57:41.614790  4247 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I0928 11:57:55.126896  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:57:55.696934  4247 solver.cpp:330] Iteration 58500, Testing net (#0)
I0928 11:57:59.053134  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:57:59.193576  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9177
I0928 11:57:59.193612  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33808 (* 1 = 0.33808 loss)
I0928 11:57:59.335445  4247 solver.cpp:218] Iteration 58500 (5.64315 iter/s, 17.7206s/100 iters), loss = 0.0012473
I0928 11:57:59.335476  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00124751 (* 1 = 0.00124751 loss)
I0928 11:57:59.335484  4247 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I0928 11:58:13.556078  4247 solver.cpp:218] Iteration 58600 (7.03208 iter/s, 14.2206s/100 iters), loss = 0.00438069
I0928 11:58:13.556120  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0043809 (* 1 = 0.0043809 loss)
I0928 11:58:13.556126  4247 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I0928 11:58:27.781289  4247 solver.cpp:218] Iteration 58700 (7.02981 iter/s, 14.2251s/100 iters), loss = 0.00367606
I0928 11:58:27.781383  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00367628 (* 1 = 0.00367628 loss)
I0928 11:58:27.781401  4247 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I0928 11:58:42.001870  4247 solver.cpp:218] Iteration 58800 (7.03222 iter/s, 14.2203s/100 iters), loss = 0.00465276
I0928 11:58:42.001914  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00465297 (* 1 = 0.00465297 loss)
I0928 11:58:42.001919  4247 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I0928 11:58:56.224856  4247 solver.cpp:218] Iteration 58900 (7.03091 iter/s, 14.2229s/100 iters), loss = 0.00301278
I0928 11:58:56.224898  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00301299 (* 1 = 0.00301299 loss)
I0928 11:58:56.224905  4247 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I0928 11:59:09.750968  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:59:10.319959  4247 solver.cpp:330] Iteration 59000, Testing net (#0)
I0928 11:59:13.675987  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 11:59:13.816638  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9196
I0928 11:59:13.816676  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.330038 (* 1 = 0.330038 loss)
I0928 11:59:13.957597  4247 solver.cpp:218] Iteration 59000 (5.63932 iter/s, 17.7326s/100 iters), loss = 0.0114036
I0928 11:59:13.957628  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114039 (* 1 = 0.0114039 loss)
I0928 11:59:13.957634  4247 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I0928 11:59:28.167429  4247 solver.cpp:218] Iteration 59100 (7.03742 iter/s, 14.2098s/100 iters), loss = 0.00593748
I0928 11:59:28.167470  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0059377 (* 1 = 0.0059377 loss)
I0928 11:59:28.167476  4247 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I0928 11:59:42.383837  4247 solver.cpp:218] Iteration 59200 (7.03417 iter/s, 14.2163s/100 iters), loss = 0.00366105
I0928 11:59:42.383945  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00366127 (* 1 = 0.00366127 loss)
I0928 11:59:42.383952  4247 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I0928 11:59:56.596499  4247 solver.cpp:218] Iteration 59300 (7.03605 iter/s, 14.2125s/100 iters), loss = 0.0035748
I0928 11:59:56.596541  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00357502 (* 1 = 0.00357502 loss)
I0928 11:59:56.596549  4247 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I0928 12:00:10.813385  4247 solver.cpp:218] Iteration 59400 (7.03393 iter/s, 14.2168s/100 iters), loss = 0.00922957
I0928 12:00:10.813427  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0092298 (* 1 = 0.0092298 loss)
I0928 12:00:10.813433  4247 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I0928 12:00:24.326066  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:00:24.895596  4247 solver.cpp:330] Iteration 59500, Testing net (#0)
I0928 12:00:28.252466  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:00:28.392768  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9208
I0928 12:00:28.392805  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.323008 (* 1 = 0.323008 loss)
I0928 12:00:28.533751  4247 solver.cpp:218] Iteration 59500 (5.64325 iter/s, 17.7203s/100 iters), loss = 0.00659915
I0928 12:00:28.533780  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00659937 (* 1 = 0.00659937 loss)
I0928 12:00:28.533787  4247 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I0928 12:00:42.758682  4247 solver.cpp:218] Iteration 59600 (7.02995 iter/s, 14.2249s/100 iters), loss = 0.00601789
I0928 12:00:42.758726  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00601812 (* 1 = 0.00601812 loss)
I0928 12:00:42.758733  4247 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I0928 12:00:56.988467  4247 solver.cpp:218] Iteration 59700 (7.02755 iter/s, 14.2297s/100 iters), loss = 0.0106543
I0928 12:00:56.988606  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106545 (* 1 = 0.0106545 loss)
I0928 12:00:56.988615  4247 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I0928 12:01:11.223894  4247 solver.cpp:218] Iteration 59800 (7.02481 iter/s, 14.2353s/100 iters), loss = 0.0220374
I0928 12:01:11.223935  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0220377 (* 1 = 0.0220377 loss)
I0928 12:01:11.223942  4247 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I0928 12:01:25.454237  4247 solver.cpp:218] Iteration 59900 (7.02728 iter/s, 14.2303s/100 iters), loss = 0.00487073
I0928 12:01:25.454279  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00487095 (* 1 = 0.00487095 loss)
I0928 12:01:25.454285  4247 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I0928 12:01:38.982311  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:01:39.551852  4247 solver.cpp:330] Iteration 60000, Testing net (#0)
I0928 12:01:42.907474  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:01:43.048166  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9175
I0928 12:01:43.048192  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348283 (* 1 = 0.348283 loss)
I0928 12:01:43.189242  4247 solver.cpp:218] Iteration 60000 (5.6386 iter/s, 17.7349s/100 iters), loss = 0.00223622
I0928 12:01:43.189271  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00223644 (* 1 = 0.00223644 loss)
I0928 12:01:43.189277  4247 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I0928 12:01:57.394882  4247 solver.cpp:218] Iteration 60100 (7.03949 iter/s, 14.2056s/100 iters), loss = 0.00172875
I0928 12:01:57.394923  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00172896 (* 1 = 0.00172896 loss)
I0928 12:01:57.394929  4247 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I0928 12:02:11.608024  4247 solver.cpp:218] Iteration 60200 (7.03578 iter/s, 14.2131s/100 iters), loss = 0.00169007
I0928 12:02:11.608160  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00169029 (* 1 = 0.00169029 loss)
I0928 12:02:11.608167  4247 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I0928 12:02:25.820943  4247 solver.cpp:218] Iteration 60300 (7.03593 iter/s, 14.2128s/100 iters), loss = 0.0015042
I0928 12:02:25.820986  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00150442 (* 1 = 0.00150442 loss)
I0928 12:02:25.820992  4247 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I0928 12:02:40.032196  4247 solver.cpp:218] Iteration 60400 (7.03672 iter/s, 14.2112s/100 iters), loss = 0.00160788
I0928 12:02:40.032227  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0016081 (* 1 = 0.0016081 loss)
I0928 12:02:40.032234  4247 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I0928 12:02:53.539340  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:02:54.107666  4247 solver.cpp:330] Iteration 60500, Testing net (#0)
I0928 12:02:57.463470  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:02:57.604080  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9192
I0928 12:02:57.604117  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338669 (* 1 = 0.338669 loss)
I0928 12:02:57.745252  4247 solver.cpp:218] Iteration 60500 (5.64558 iter/s, 17.713s/100 iters), loss = 0.000891387
I0928 12:02:57.745281  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000891599 (* 1 = 0.000891599 loss)
I0928 12:02:57.745288  4247 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I0928 12:03:11.963260  4247 solver.cpp:218] Iteration 60600 (7.03337 iter/s, 14.2179s/100 iters), loss = 0.00328609
I0928 12:03:11.963304  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00328631 (* 1 = 0.00328631 loss)
I0928 12:03:11.963310  4247 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I0928 12:03:26.183264  4247 solver.cpp:218] Iteration 60700 (7.03239 iter/s, 14.2199s/100 iters), loss = 0.00456063
I0928 12:03:26.183421  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00456084 (* 1 = 0.00456084 loss)
I0928 12:03:26.183430  4247 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I0928 12:03:40.402735  4247 solver.cpp:218] Iteration 60800 (7.03271 iter/s, 14.2193s/100 iters), loss = 0.00760442
I0928 12:03:40.402768  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00760463 (* 1 = 0.00760463 loss)
I0928 12:03:40.402776  4247 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I0928 12:03:54.626684  4247 solver.cpp:218] Iteration 60900 (7.03043 iter/s, 14.2239s/100 iters), loss = 0.00299448
I0928 12:03:54.626726  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00299469 (* 1 = 0.00299469 loss)
I0928 12:03:54.626732  4247 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I0928 12:04:08.141387  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:04:08.712090  4247 solver.cpp:330] Iteration 61000, Testing net (#0)
I0928 12:04:12.066684  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:04:12.207224  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9208
I0928 12:04:12.207262  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327108 (* 1 = 0.327108 loss)
I0928 12:04:12.348577  4247 solver.cpp:218] Iteration 61000 (5.64277 iter/s, 17.7218s/100 iters), loss = 0.00407054
I0928 12:04:12.348606  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00407075 (* 1 = 0.00407075 loss)
I0928 12:04:12.348613  4247 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I0928 12:04:26.566882  4247 solver.cpp:218] Iteration 61100 (7.03322 iter/s, 14.2182s/100 iters), loss = 0.00414392
I0928 12:04:26.566926  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00414413 (* 1 = 0.00414413 loss)
I0928 12:04:26.566931  4247 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I0928 12:04:40.792796  4247 solver.cpp:218] Iteration 61200 (7.02947 iter/s, 14.2258s/100 iters), loss = 0.00328281
I0928 12:04:40.792870  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00328302 (* 1 = 0.00328302 loss)
I0928 12:04:40.792876  4247 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I0928 12:04:55.018815  4247 solver.cpp:218] Iteration 61300 (7.02943 iter/s, 14.2259s/100 iters), loss = 0.00867848
I0928 12:04:55.018857  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00867868 (* 1 = 0.00867868 loss)
I0928 12:04:55.018863  4247 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I0928 12:05:09.239943  4247 solver.cpp:218] Iteration 61400 (7.03183 iter/s, 14.221s/100 iters), loss = 0.0082152
I0928 12:05:09.239974  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00821542 (* 1 = 0.00821542 loss)
I0928 12:05:09.239979  4247 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I0928 12:05:22.750948  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:05:23.320541  4247 solver.cpp:330] Iteration 61500, Testing net (#0)
I0928 12:05:26.678220  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:05:26.818883  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9219
I0928 12:05:26.818909  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31932 (* 1 = 0.31932 loss)
I0928 12:05:26.960453  4247 solver.cpp:218] Iteration 61500 (5.6432 iter/s, 17.7204s/100 iters), loss = 0.00550412
I0928 12:05:26.960481  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00550434 (* 1 = 0.00550434 loss)
I0928 12:05:26.960487  4247 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I0928 12:05:41.175710  4247 solver.cpp:218] Iteration 61600 (7.03473 iter/s, 14.2152s/100 iters), loss = 0.00700911
I0928 12:05:41.175752  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00700932 (* 1 = 0.00700932 loss)
I0928 12:05:41.175760  4247 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I0928 12:05:55.393896  4247 solver.cpp:218] Iteration 61700 (7.03329 iter/s, 14.2181s/100 iters), loss = 0.00815346
I0928 12:05:55.394016  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00815367 (* 1 = 0.00815367 loss)
I0928 12:05:55.394034  4247 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I0928 12:06:09.615420  4247 solver.cpp:218] Iteration 61800 (7.03167 iter/s, 14.2214s/100 iters), loss = 0.000352092
I0928 12:06:09.615461  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000352301 (* 1 = 0.000352301 loss)
I0928 12:06:09.615468  4247 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I0928 12:06:23.826716  4247 solver.cpp:218] Iteration 61900 (7.0367 iter/s, 14.2112s/100 iters), loss = 0.00296227
I0928 12:06:23.826757  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00296248 (* 1 = 0.00296248 loss)
I0928 12:06:23.826763  4247 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I0928 12:06:37.331429  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:06:37.900985  4247 solver.cpp:330] Iteration 62000, Testing net (#0)
I0928 12:06:41.257531  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:06:41.397589  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9179
I0928 12:06:41.397614  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338615 (* 1 = 0.338615 loss)
I0928 12:06:41.538100  4247 solver.cpp:218] Iteration 62000 (5.64612 iter/s, 17.7113s/100 iters), loss = 0.00321342
I0928 12:06:41.538127  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00321363 (* 1 = 0.00321363 loss)
I0928 12:06:41.538133  4247 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I0928 12:06:55.756930  4247 solver.cpp:218] Iteration 62100 (7.03296 iter/s, 14.2188s/100 iters), loss = 0.00365701
I0928 12:06:55.756973  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00365723 (* 1 = 0.00365723 loss)
I0928 12:06:55.756979  4247 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I0928 12:07:09.979728  4247 solver.cpp:218] Iteration 62200 (7.03101 iter/s, 14.2227s/100 iters), loss = 0.00733329
I0928 12:07:09.979799  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0073335 (* 1 = 0.0073335 loss)
I0928 12:07:09.979805  4247 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I0928 12:07:24.202646  4247 solver.cpp:218] Iteration 62300 (7.03096 iter/s, 14.2228s/100 iters), loss = 0.00107884
I0928 12:07:24.202677  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00107905 (* 1 = 0.00107905 loss)
I0928 12:07:24.202683  4247 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I0928 12:07:38.422212  4247 solver.cpp:218] Iteration 62400 (7.0326 iter/s, 14.2195s/100 iters), loss = 0.000748684
I0928 12:07:38.422255  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000748894 (* 1 = 0.000748894 loss)
I0928 12:07:38.422260  4247 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I0928 12:07:51.938699  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:07:52.508755  4247 solver.cpp:330] Iteration 62500, Testing net (#0)
I0928 12:07:55.865250  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:07:56.005887  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9208
I0928 12:07:56.005924  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334844 (* 1 = 0.334844 loss)
I0928 12:07:56.147872  4247 solver.cpp:218] Iteration 62500 (5.64157 iter/s, 17.7256s/100 iters), loss = 0.000982944
I0928 12:07:56.147902  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000983155 (* 1 = 0.000983155 loss)
I0928 12:07:56.147908  4247 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I0928 12:08:10.363283  4247 solver.cpp:218] Iteration 62600 (7.03465 iter/s, 14.2153s/100 iters), loss = 0.00577243
I0928 12:08:10.363325  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00577264 (* 1 = 0.00577264 loss)
I0928 12:08:10.363332  4247 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I0928 12:08:24.581212  4247 solver.cpp:218] Iteration 62700 (7.03341 iter/s, 14.2178s/100 iters), loss = 0.00312838
I0928 12:08:24.581332  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00312858 (* 1 = 0.00312858 loss)
I0928 12:08:24.581341  4247 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I0928 12:08:38.795938  4247 solver.cpp:218] Iteration 62800 (7.03503 iter/s, 14.2146s/100 iters), loss = 0.00284455
I0928 12:08:38.795980  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00284476 (* 1 = 0.00284476 loss)
I0928 12:08:38.795987  4247 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I0928 12:08:53.012318  4247 solver.cpp:218] Iteration 62900 (7.03418 iter/s, 14.2163s/100 iters), loss = 0.00288376
I0928 12:08:53.012361  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00288397 (* 1 = 0.00288397 loss)
I0928 12:08:53.012367  4247 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I0928 12:09:06.522626  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:09:07.091678  4247 solver.cpp:330] Iteration 63000, Testing net (#0)
I0928 12:09:10.448700  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:09:10.588922  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9216
I0928 12:09:10.588958  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338557 (* 1 = 0.338557 loss)
I0928 12:09:10.730779  4247 solver.cpp:218] Iteration 63000 (5.64386 iter/s, 17.7184s/100 iters), loss = 0.0278734
I0928 12:09:10.730810  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0278736 (* 1 = 0.0278736 loss)
I0928 12:09:10.730816  4247 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I0928 12:09:24.946522  4247 solver.cpp:218] Iteration 63100 (7.03449 iter/s, 14.2157s/100 iters), loss = 0.00430914
I0928 12:09:24.946564  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00430935 (* 1 = 0.00430935 loss)
I0928 12:09:24.946571  4247 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I0928 12:09:39.168962  4247 solver.cpp:218] Iteration 63200 (7.03118 iter/s, 14.2224s/100 iters), loss = 0.00259358
I0928 12:09:39.169104  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00259379 (* 1 = 0.00259379 loss)
I0928 12:09:39.169113  4247 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I0928 12:09:53.391314  4247 solver.cpp:218] Iteration 63300 (7.03127 iter/s, 14.2222s/100 iters), loss = 0.00381199
I0928 12:09:53.391347  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0038122 (* 1 = 0.0038122 loss)
I0928 12:09:53.391355  4247 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I0928 12:10:07.617533  4247 solver.cpp:218] Iteration 63400 (7.02931 iter/s, 14.2261s/100 iters), loss = 0.00709206
I0928 12:10:07.617576  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00709227 (* 1 = 0.00709227 loss)
I0928 12:10:07.617583  4247 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I0928 12:10:21.128875  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:10:21.699265  4247 solver.cpp:330] Iteration 63500, Testing net (#0)
I0928 12:10:25.055119  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:10:25.195322  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.919
I0928 12:10:25.195359  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.343801 (* 1 = 0.343801 loss)
I0928 12:10:25.336818  4247 solver.cpp:218] Iteration 63500 (5.6436 iter/s, 17.7192s/100 iters), loss = 0.0232028
I0928 12:10:25.336848  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0232031 (* 1 = 0.0232031 loss)
I0928 12:10:25.336855  4247 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I0928 12:10:39.552640  4247 solver.cpp:218] Iteration 63600 (7.03445 iter/s, 14.2157s/100 iters), loss = 0.00283278
I0928 12:10:39.552683  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00283299 (* 1 = 0.00283299 loss)
I0928 12:10:39.552690  4247 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I0928 12:10:53.773432  4247 solver.cpp:218] Iteration 63700 (7.032 iter/s, 14.2207s/100 iters), loss = 0.00219551
I0928 12:10:53.773520  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00219571 (* 1 = 0.00219571 loss)
I0928 12:10:53.773530  4247 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I0928 12:11:07.992928  4247 solver.cpp:218] Iteration 63800 (7.03266 iter/s, 14.2194s/100 iters), loss = 0.00204328
I0928 12:11:07.992969  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00204349 (* 1 = 0.00204349 loss)
I0928 12:11:07.992974  4247 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I0928 12:11:22.214699  4247 solver.cpp:218] Iteration 63900 (7.03151 iter/s, 14.2217s/100 iters), loss = 0.00301462
I0928 12:11:22.214740  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00301482 (* 1 = 0.00301482 loss)
I0928 12:11:22.214745  4247 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I0928 12:11:35.727913  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:11:36.297430  4247 solver.cpp:330] Iteration 64000, Testing net (#0)
I0928 12:11:39.654803  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:11:39.795531  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9228
I0928 12:11:39.795570  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326361 (* 1 = 0.326361 loss)
I0928 12:11:39.936985  4247 solver.cpp:218] Iteration 64000 (5.64264 iter/s, 17.7222s/100 iters), loss = 0.00100558
I0928 12:11:39.937014  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100578 (* 1 = 0.00100578 loss)
I0928 12:11:39.937021  4247 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I0928 12:11:54.151548  4247 solver.cpp:218] Iteration 64100 (7.03508 iter/s, 14.2145s/100 iters), loss = 0.00802771
I0928 12:11:54.151579  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00802791 (* 1 = 0.00802791 loss)
I0928 12:11:54.151587  4247 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I0928 12:12:08.369544  4247 solver.cpp:218] Iteration 64200 (7.03338 iter/s, 14.2179s/100 iters), loss = 0.00201664
I0928 12:12:08.369616  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00201684 (* 1 = 0.00201684 loss)
I0928 12:12:08.369622  4247 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I0928 12:12:22.594758  4247 solver.cpp:218] Iteration 64300 (7.02983 iter/s, 14.2251s/100 iters), loss = 0.00158213
I0928 12:12:22.594799  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00158233 (* 1 = 0.00158233 loss)
I0928 12:12:22.594805  4247 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I0928 12:12:36.814904  4247 solver.cpp:218] Iteration 64400 (7.03232 iter/s, 14.2201s/100 iters), loss = 0.0043348
I0928 12:12:36.814935  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.004335 (* 1 = 0.004335 loss)
I0928 12:12:36.814941  4247 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I0928 12:12:50.328261  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:12:50.898064  4247 solver.cpp:330] Iteration 64500, Testing net (#0)
I0928 12:12:54.254573  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:12:54.394634  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9212
I0928 12:12:54.394670  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.331909 (* 1 = 0.331909 loss)
I0928 12:12:54.536154  4247 solver.cpp:218] Iteration 64500 (5.64297 iter/s, 17.7212s/100 iters), loss = 0.00139266
I0928 12:12:54.536195  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00139286 (* 1 = 0.00139286 loss)
I0928 12:12:54.536201  4247 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I0928 12:13:08.762395  4247 solver.cpp:218] Iteration 64600 (7.02931 iter/s, 14.2262s/100 iters), loss = 0.00583654
I0928 12:13:08.762436  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00583674 (* 1 = 0.00583674 loss)
I0928 12:13:08.762444  4247 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I0928 12:13:22.989707  4247 solver.cpp:218] Iteration 64700 (7.02878 iter/s, 14.2272s/100 iters), loss = 0.0264163
I0928 12:13:22.989799  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0264165 (* 1 = 0.0264165 loss)
I0928 12:13:22.989807  4247 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I0928 12:13:37.222352  4247 solver.cpp:218] Iteration 64800 (7.02617 iter/s, 14.2325s/100 iters), loss = 0.000594003
I0928 12:13:37.222383  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000594208 (* 1 = 0.000594208 loss)
I0928 12:13:37.222388  4247 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I0928 12:13:51.453042  4247 solver.cpp:218] Iteration 64900 (7.0271 iter/s, 14.2306s/100 iters), loss = 0.00133427
I0928 12:13:51.453084  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00133447 (* 1 = 0.00133447 loss)
I0928 12:13:51.453090  4247 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I0928 12:14:04.977947  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:14:05.547294  4247 solver.cpp:330] Iteration 65000, Testing net (#0)
I0928 12:14:08.901762  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:14:09.041787  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9176
I0928 12:14:09.041815  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.341604 (* 1 = 0.341604 loss)
I0928 12:14:09.184288  4247 solver.cpp:218] Iteration 65000 (5.63979 iter/s, 17.7312s/100 iters), loss = 0.00155354
I0928 12:14:09.184320  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00155375 (* 1 = 0.00155375 loss)
I0928 12:14:09.184327  4247 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I0928 12:14:23.395332  4247 solver.cpp:218] Iteration 65100 (7.03682 iter/s, 14.211s/100 iters), loss = 0.000513136
I0928 12:14:23.395375  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000513342 (* 1 = 0.000513342 loss)
I0928 12:14:23.395381  4247 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I0928 12:14:37.614485  4247 solver.cpp:218] Iteration 65200 (7.03281 iter/s, 14.2191s/100 iters), loss = 0.00442663
I0928 12:14:37.614548  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00442684 (* 1 = 0.00442684 loss)
I0928 12:14:37.614555  4247 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I0928 12:14:51.833577  4247 solver.cpp:218] Iteration 65300 (7.03285 iter/s, 14.219s/100 iters), loss = 0.0170854
I0928 12:14:51.833619  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0170856 (* 1 = 0.0170856 loss)
I0928 12:14:51.833626  4247 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I0928 12:15:06.051609  4247 solver.cpp:218] Iteration 65400 (7.03336 iter/s, 14.218s/100 iters), loss = 0.00848781
I0928 12:15:06.051650  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00848801 (* 1 = 0.00848801 loss)
I0928 12:15:06.051656  4247 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I0928 12:15:19.565623  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:15:20.134649  4247 solver.cpp:330] Iteration 65500, Testing net (#0)
I0928 12:15:23.488734  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:15:23.629040  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9234
I0928 12:15:23.629077  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324278 (* 1 = 0.324278 loss)
I0928 12:15:23.770588  4247 solver.cpp:218] Iteration 65500 (5.64369 iter/s, 17.7189s/100 iters), loss = 0.00160537
I0928 12:15:23.770619  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00160557 (* 1 = 0.00160557 loss)
I0928 12:15:23.770627  4247 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I0928 12:15:37.983774  4247 solver.cpp:218] Iteration 65600 (7.03575 iter/s, 14.2131s/100 iters), loss = 0.00195505
I0928 12:15:37.983806  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00195525 (* 1 = 0.00195525 loss)
I0928 12:15:37.983813  4247 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I0928 12:15:52.200126  4247 solver.cpp:218] Iteration 65700 (7.03419 iter/s, 14.2163s/100 iters), loss = 0.00181114
I0928 12:15:52.200245  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00181134 (* 1 = 0.00181134 loss)
I0928 12:15:52.200253  4247 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I0928 12:16:06.422040  4247 solver.cpp:218] Iteration 65800 (7.03148 iter/s, 14.2218s/100 iters), loss = 0.00275264
I0928 12:16:06.422070  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00275283 (* 1 = 0.00275283 loss)
I0928 12:16:06.422076  4247 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I0928 12:16:20.642479  4247 solver.cpp:218] Iteration 65900 (7.03217 iter/s, 14.2204s/100 iters), loss = 0.00175012
I0928 12:16:20.642511  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00175032 (* 1 = 0.00175032 loss)
I0928 12:16:20.642518  4247 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I0928 12:16:34.155905  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:16:34.727036  4247 solver.cpp:330] Iteration 66000, Testing net (#0)
I0928 12:16:38.082983  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:16:38.222544  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9217
I0928 12:16:38.222570  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329677 (* 1 = 0.329677 loss)
I0928 12:16:38.363492  4247 solver.cpp:218] Iteration 66000 (5.64304 iter/s, 17.7209s/100 iters), loss = 0.0050242
I0928 12:16:38.363523  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00502441 (* 1 = 0.00502441 loss)
I0928 12:16:38.363529  4247 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I0928 12:16:52.587203  4247 solver.cpp:218] Iteration 66100 (7.03055 iter/s, 14.2236s/100 iters), loss = 0.00218534
I0928 12:16:52.587246  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00218554 (* 1 = 0.00218554 loss)
I0928 12:16:52.587252  4247 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I0928 12:17:06.813836  4247 solver.cpp:218] Iteration 66200 (7.02911 iter/s, 14.2266s/100 iters), loss = 0.00965302
I0928 12:17:06.813916  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00965322 (* 1 = 0.00965322 loss)
I0928 12:17:06.813923  4247 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I0928 12:17:21.038197  4247 solver.cpp:218] Iteration 66300 (7.03025 iter/s, 14.2242s/100 iters), loss = 0.00355645
I0928 12:17:21.038228  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00355665 (* 1 = 0.00355665 loss)
I0928 12:17:21.038234  4247 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I0928 12:17:35.258311  4247 solver.cpp:218] Iteration 66400 (7.03233 iter/s, 14.22s/100 iters), loss = 0.00191107
I0928 12:17:35.258342  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00191127 (* 1 = 0.00191127 loss)
I0928 12:17:35.258348  4247 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I0928 12:17:48.773100  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:17:49.342219  4247 solver.cpp:330] Iteration 66500, Testing net (#0)
I0928 12:17:52.697137  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:17:52.837391  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9242
I0928 12:17:52.837429  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324616 (* 1 = 0.324616 loss)
I0928 12:17:52.979363  4247 solver.cpp:218] Iteration 66500 (5.64303 iter/s, 17.721s/100 iters), loss = 0.00652714
I0928 12:17:52.979393  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00652734 (* 1 = 0.00652734 loss)
I0928 12:17:52.979398  4247 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I0928 12:18:07.195617  4247 solver.cpp:218] Iteration 66600 (7.03424 iter/s, 14.2162s/100 iters), loss = 0.00195204
I0928 12:18:07.195658  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00195223 (* 1 = 0.00195223 loss)
I0928 12:18:07.195664  4247 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I0928 12:18:21.414322  4247 solver.cpp:218] Iteration 66700 (7.03303 iter/s, 14.2186s/100 iters), loss = 0.00243991
I0928 12:18:21.414456  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00244011 (* 1 = 0.00244011 loss)
I0928 12:18:21.414474  4247 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I0928 12:18:35.633268  4247 solver.cpp:218] Iteration 66800 (7.03295 iter/s, 14.2188s/100 iters), loss = 0.000386627
I0928 12:18:35.633311  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000386826 (* 1 = 0.000386826 loss)
I0928 12:18:35.633317  4247 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I0928 12:18:49.855171  4247 solver.cpp:218] Iteration 66900 (7.03145 iter/s, 14.2218s/100 iters), loss = 0.00543502
I0928 12:18:49.855213  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00543522 (* 1 = 0.00543522 loss)
I0928 12:18:49.855221  4247 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I0928 12:19:03.366798  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:19:03.935207  4247 solver.cpp:330] Iteration 67000, Testing net (#0)
I0928 12:19:07.289898  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:19:07.430217  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9224
I0928 12:19:07.430253  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.331475 (* 1 = 0.331475 loss)
I0928 12:19:07.571195  4247 solver.cpp:218] Iteration 67000 (5.64464 iter/s, 17.7159s/100 iters), loss = 0.00322797
I0928 12:19:07.571225  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00322816 (* 1 = 0.00322816 loss)
I0928 12:19:07.571233  4247 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I0928 12:19:21.789209  4247 solver.cpp:218] Iteration 67100 (7.03337 iter/s, 14.2179s/100 iters), loss = 0.00471388
I0928 12:19:21.789252  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00471408 (* 1 = 0.00471408 loss)
I0928 12:19:21.789258  4247 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I0928 12:19:36.005372  4247 solver.cpp:218] Iteration 67200 (7.03429 iter/s, 14.2161s/100 iters), loss = 0.00851333
I0928 12:19:36.005504  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00851353 (* 1 = 0.00851353 loss)
I0928 12:19:36.005511  4247 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I0928 12:19:50.229720  4247 solver.cpp:218] Iteration 67300 (7.03028 iter/s, 14.2242s/100 iters), loss = 0.00783546
I0928 12:19:50.229763  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00783565 (* 1 = 0.00783565 loss)
I0928 12:19:50.229769  4247 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I0928 12:20:04.454668  4247 solver.cpp:218] Iteration 67400 (7.02994 iter/s, 14.2249s/100 iters), loss = 0.000430774
I0928 12:20:04.454711  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000430974 (* 1 = 0.000430974 loss)
I0928 12:20:04.454718  4247 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I0928 12:20:17.967301  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:20:18.537957  4247 solver.cpp:330] Iteration 67500, Testing net (#0)
I0928 12:20:21.894289  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:20:22.034855  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I0928 12:20:22.034890  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.317869 (* 1 = 0.317869 loss)
I0928 12:20:22.176187  4247 solver.cpp:218] Iteration 67500 (5.64289 iter/s, 17.7214s/100 iters), loss = 0.000981871
I0928 12:20:22.176218  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00098207 (* 1 = 0.00098207 loss)
I0928 12:20:22.176223  4247 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I0928 12:20:36.407729  4247 solver.cpp:218] Iteration 67600 (7.02668 iter/s, 14.2315s/100 iters), loss = 0.00291279
I0928 12:20:36.407771  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00291299 (* 1 = 0.00291299 loss)
I0928 12:20:36.407778  4247 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I0928 12:20:50.642834  4247 solver.cpp:218] Iteration 67700 (7.02493 iter/s, 14.235s/100 iters), loss = 0.00796381
I0928 12:20:50.642982  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00796402 (* 1 = 0.00796402 loss)
I0928 12:20:50.642989  4247 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I0928 12:21:04.876622  4247 solver.cpp:218] Iteration 67800 (7.02563 iter/s, 14.2336s/100 iters), loss = 0.00145973
I0928 12:21:04.876664  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00145994 (* 1 = 0.00145994 loss)
I0928 12:21:04.876670  4247 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I0928 12:21:19.108564  4247 solver.cpp:218] Iteration 67900 (7.02649 iter/s, 14.2319s/100 iters), loss = 0.00322596
I0928 12:21:19.108606  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00322616 (* 1 = 0.00322616 loss)
I0928 12:21:19.108613  4247 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I0928 12:21:32.636678  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:21:33.206581  4247 solver.cpp:330] Iteration 68000, Testing net (#0)
I0928 12:21:36.562566  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:21:36.703282  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9114
I0928 12:21:36.703320  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.403941 (* 1 = 0.403941 loss)
I0928 12:21:36.844878  4247 solver.cpp:218] Iteration 68000 (5.63818 iter/s, 17.7362s/100 iters), loss = 0.00355274
I0928 12:21:36.844908  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00355294 (* 1 = 0.00355294 loss)
I0928 12:21:36.844914  4247 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I0928 12:21:51.064180  4247 solver.cpp:218] Iteration 68100 (7.03273 iter/s, 14.2192s/100 iters), loss = 0.00139377
I0928 12:21:51.064222  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00139397 (* 1 = 0.00139397 loss)
I0928 12:21:51.064229  4247 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I0928 12:22:05.286128  4247 solver.cpp:218] Iteration 68200 (7.03143 iter/s, 14.2219s/100 iters), loss = 0.00588815
I0928 12:22:05.286190  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00588835 (* 1 = 0.00588835 loss)
I0928 12:22:05.286195  4247 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I0928 12:22:19.505208  4247 solver.cpp:218] Iteration 68300 (7.03285 iter/s, 14.219s/100 iters), loss = 0.00366389
I0928 12:22:19.505250  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00366409 (* 1 = 0.00366409 loss)
I0928 12:22:19.505256  4247 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I0928 12:22:33.724480  4247 solver.cpp:218] Iteration 68400 (7.03275 iter/s, 14.2192s/100 iters), loss = 0.00669097
I0928 12:22:33.724524  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00669117 (* 1 = 0.00669117 loss)
I0928 12:22:33.724529  4247 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I0928 12:22:47.239128  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:22:47.808117  4247 solver.cpp:330] Iteration 68500, Testing net (#0)
I0928 12:22:51.166245  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:22:51.306779  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9218
I0928 12:22:51.306816  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.346143 (* 1 = 0.346143 loss)
I0928 12:22:51.448256  4247 solver.cpp:218] Iteration 68500 (5.64217 iter/s, 17.7237s/100 iters), loss = 0.00157693
I0928 12:22:51.448285  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00157712 (* 1 = 0.00157712 loss)
I0928 12:22:51.448292  4247 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I0928 12:23:05.672188  4247 solver.cpp:218] Iteration 68600 (7.03044 iter/s, 14.2239s/100 iters), loss = 0.00100536
I0928 12:23:05.672230  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100556 (* 1 = 0.00100556 loss)
I0928 12:23:05.672236  4247 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I0928 12:23:19.895259  4247 solver.cpp:218] Iteration 68700 (7.03087 iter/s, 14.223s/100 iters), loss = 0.00247301
I0928 12:23:19.895382  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00247321 (* 1 = 0.00247321 loss)
I0928 12:23:19.895390  4247 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I0928 12:23:34.118635  4247 solver.cpp:218] Iteration 68800 (7.03076 iter/s, 14.2232s/100 iters), loss = 0.00180107
I0928 12:23:34.118679  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00180128 (* 1 = 0.00180128 loss)
I0928 12:23:34.118685  4247 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I0928 12:23:48.339846  4247 solver.cpp:218] Iteration 68900 (7.03179 iter/s, 14.2211s/100 iters), loss = 0.00529273
I0928 12:23:48.339890  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00529294 (* 1 = 0.00529294 loss)
I0928 12:23:48.339895  4247 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I0928 12:24:01.856495  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:24:02.426816  4247 solver.cpp:330] Iteration 69000, Testing net (#0)
I0928 12:24:05.783483  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:24:05.923686  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9212
I0928 12:24:05.923722  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.351002 (* 1 = 0.351002 loss)
I0928 12:24:06.065086  4247 solver.cpp:218] Iteration 69000 (5.6417 iter/s, 17.7252s/100 iters), loss = 0.00222137
I0928 12:24:06.065117  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00222158 (* 1 = 0.00222158 loss)
I0928 12:24:06.065124  4247 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I0928 12:24:20.279042  4247 solver.cpp:218] Iteration 69100 (7.03538 iter/s, 14.2139s/100 iters), loss = 0.0270578
I0928 12:24:20.279084  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.027058 (* 1 = 0.027058 loss)
I0928 12:24:20.279091  4247 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I0928 12:24:34.500949  4247 solver.cpp:218] Iteration 69200 (7.03145 iter/s, 14.2218s/100 iters), loss = 0.0019792
I0928 12:24:34.501085  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0019794 (* 1 = 0.0019794 loss)
I0928 12:24:34.501091  4247 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I0928 12:24:48.715718  4247 solver.cpp:218] Iteration 69300 (7.03502 iter/s, 14.2146s/100 iters), loss = 0.00218226
I0928 12:24:48.715750  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00218246 (* 1 = 0.00218246 loss)
I0928 12:24:48.715756  4247 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I0928 12:25:02.933178  4247 solver.cpp:218] Iteration 69400 (7.03364 iter/s, 14.2174s/100 iters), loss = 0.00118843
I0928 12:25:02.933220  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00118863 (* 1 = 0.00118863 loss)
I0928 12:25:02.933226  4247 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I0928 12:25:16.447181  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:25:17.017287  4247 solver.cpp:330] Iteration 69500, Testing net (#0)
I0928 12:25:20.373940  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:25:20.514124  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9182
I0928 12:25:20.514161  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367711 (* 1 = 0.367711 loss)
I0928 12:25:20.654938  4247 solver.cpp:218] Iteration 69500 (5.64281 iter/s, 17.7217s/100 iters), loss = 0.00305083
I0928 12:25:20.654968  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00305103 (* 1 = 0.00305103 loss)
I0928 12:25:20.654973  4247 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I0928 12:25:34.874905  4247 solver.cpp:218] Iteration 69600 (7.0324 iter/s, 14.2199s/100 iters), loss = 0.00126289
I0928 12:25:34.874938  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0012631 (* 1 = 0.0012631 loss)
I0928 12:25:34.874953  4247 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I0928 12:25:49.099721  4247 solver.cpp:218] Iteration 69700 (7.03 iter/s, 14.2247s/100 iters), loss = 0.00310317
I0928 12:25:49.099858  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00310337 (* 1 = 0.00310337 loss)
I0928 12:25:49.099877  4247 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I0928 12:26:03.319095  4247 solver.cpp:218] Iteration 69800 (7.03274 iter/s, 14.2192s/100 iters), loss = 0.00318315
I0928 12:26:03.319128  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00318335 (* 1 = 0.00318335 loss)
I0928 12:26:03.319144  4247 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I0928 12:26:17.545847  4247 solver.cpp:218] Iteration 69900 (7.02905 iter/s, 14.2267s/100 iters), loss = 0.0108401
I0928 12:26:17.545879  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108403 (* 1 = 0.0108403 loss)
I0928 12:26:17.545895  4247 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I0928 12:26:31.065121  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:26:31.635216  4247 solver.cpp:330] Iteration 70000, Testing net (#0)
I0928 12:26:34.989689  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:26:35.129669  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9205
I0928 12:26:35.129696  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347555 (* 1 = 0.347555 loss)
I0928 12:26:35.271819  4247 solver.cpp:218] Iteration 70000 (5.64147 iter/s, 17.7259s/100 iters), loss = 0.00101321
I0928 12:26:35.271852  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010134 (* 1 = 0.0010134 loss)
I0928 12:26:35.271858  4247 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I0928 12:26:49.494652  4247 solver.cpp:218] Iteration 70100 (7.03099 iter/s, 14.2228s/100 iters), loss = 0.00195312
I0928 12:26:49.494684  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00195332 (* 1 = 0.00195332 loss)
I0928 12:26:49.494700  4247 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I0928 12:27:03.730312  4247 solver.cpp:218] Iteration 70200 (7.02465 iter/s, 14.2356s/100 iters), loss = 0.0202636
I0928 12:27:03.730368  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0202638 (* 1 = 0.0202638 loss)
I0928 12:27:03.730374  4247 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I0928 12:27:17.961181  4247 solver.cpp:218] Iteration 70300 (7.02703 iter/s, 14.2308s/100 iters), loss = 0.00454913
I0928 12:27:17.961213  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00454933 (* 1 = 0.00454933 loss)
I0928 12:27:17.961230  4247 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I0928 12:27:32.187659  4247 solver.cpp:218] Iteration 70400 (7.02918 iter/s, 14.2264s/100 iters), loss = 0.000908709
I0928 12:27:32.187690  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000908902 (* 1 = 0.000908902 loss)
I0928 12:27:32.187706  4247 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I0928 12:27:45.713840  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:27:46.283387  4247 solver.cpp:330] Iteration 70500, Testing net (#0)
I0928 12:27:49.639606  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:27:49.780010  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9203
I0928 12:27:49.780047  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.336737 (* 1 = 0.336737 loss)
I0928 12:27:49.921779  4247 solver.cpp:218] Iteration 70500 (5.63887 iter/s, 17.734s/100 iters), loss = 0.00115164
I0928 12:27:49.921808  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00115183 (* 1 = 0.00115183 loss)
I0928 12:27:49.921815  4247 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I0928 12:28:04.138736  4247 solver.cpp:218] Iteration 70600 (7.03389 iter/s, 14.2169s/100 iters), loss = 0.0223416
I0928 12:28:04.138767  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0223418 (* 1 = 0.0223418 loss)
I0928 12:28:04.138783  4247 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I0928 12:28:18.353649  4247 solver.cpp:218] Iteration 70700 (7.0349 iter/s, 14.2148s/100 iters), loss = 0.00315959
I0928 12:28:18.353777  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00315978 (* 1 = 0.00315978 loss)
I0928 12:28:18.353802  4247 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I0928 12:28:32.574162  4247 solver.cpp:218] Iteration 70800 (7.03217 iter/s, 14.2204s/100 iters), loss = 0.00153675
I0928 12:28:32.574194  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153693 (* 1 = 0.00153693 loss)
I0928 12:28:32.574210  4247 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I0928 12:28:46.788439  4247 solver.cpp:218] Iteration 70900 (7.03522 iter/s, 14.2142s/100 iters), loss = 0.00296219
I0928 12:28:46.788471  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00296238 (* 1 = 0.00296238 loss)
I0928 12:28:46.788487  4247 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I0928 12:29:00.300127  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:29:00.869707  4247 solver.cpp:330] Iteration 71000, Testing net (#0)
I0928 12:29:04.224340  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:29:04.364666  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9131
I0928 12:29:04.364704  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.38613 (* 1 = 0.38613 loss)
I0928 12:29:04.505558  4247 solver.cpp:218] Iteration 71000 (5.64428 iter/s, 17.717s/100 iters), loss = 0.000513029
I0928 12:29:04.505587  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000513221 (* 1 = 0.000513221 loss)
I0928 12:29:04.505604  4247 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I0928 12:29:18.731168  4247 solver.cpp:218] Iteration 71100 (7.02961 iter/s, 14.2255s/100 iters), loss = 0.00149287
I0928 12:29:18.731202  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00149307 (* 1 = 0.00149307 loss)
I0928 12:29:18.731209  4247 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I0928 12:29:32.958103  4247 solver.cpp:218] Iteration 71200 (7.02896 iter/s, 14.2269s/100 iters), loss = 0.00202423
I0928 12:29:32.958220  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00202442 (* 1 = 0.00202442 loss)
I0928 12:29:32.958236  4247 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I0928 12:29:47.186206  4247 solver.cpp:218] Iteration 71300 (7.02842 iter/s, 14.228s/100 iters), loss = 0.00597874
I0928 12:29:47.186238  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00597893 (* 1 = 0.00597893 loss)
I0928 12:29:47.186254  4247 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I0928 12:30:01.415025  4247 solver.cpp:218] Iteration 71400 (7.02803 iter/s, 14.2287s/100 iters), loss = 0.000698662
I0928 12:30:01.415057  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000698853 (* 1 = 0.000698853 loss)
I0928 12:30:01.415074  4247 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I0928 12:30:14.932940  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:30:15.502626  4247 solver.cpp:330] Iteration 71500, Testing net (#0)
I0928 12:30:18.857441  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:30:18.998235  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9137
I0928 12:30:18.998261  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.374757 (* 1 = 0.374757 loss)
I0928 12:30:19.139802  4247 solver.cpp:218] Iteration 71500 (5.64185 iter/s, 17.7247s/100 iters), loss = 0.00168528
I0928 12:30:19.139830  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168547 (* 1 = 0.00168547 loss)
I0928 12:30:19.139837  4247 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I0928 12:30:33.354274  4247 solver.cpp:218] Iteration 71600 (7.03512 iter/s, 14.2144s/100 iters), loss = 0.00186319
I0928 12:30:33.354307  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00186338 (* 1 = 0.00186338 loss)
I0928 12:30:33.354323  4247 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I0928 12:30:47.572441  4247 solver.cpp:218] Iteration 71700 (7.03329 iter/s, 14.2181s/100 iters), loss = 0.00337905
I0928 12:30:47.572577  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00337924 (* 1 = 0.00337924 loss)
I0928 12:30:47.572597  4247 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I0928 12:31:01.788970  4247 solver.cpp:218] Iteration 71800 (7.03415 iter/s, 14.2164s/100 iters), loss = 0.00204897
I0928 12:31:01.789002  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00204916 (* 1 = 0.00204916 loss)
I0928 12:31:01.789018  4247 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I0928 12:31:16.008302  4247 solver.cpp:218] Iteration 71900 (7.03272 iter/s, 14.2193s/100 iters), loss = 0.00499547
I0928 12:31:16.008335  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00499566 (* 1 = 0.00499566 loss)
I0928 12:31:16.008352  4247 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I0928 12:31:29.519420  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:31:30.087981  4247 solver.cpp:330] Iteration 72000, Testing net (#0)
I0928 12:31:33.444103  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:31:33.584659  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9221
I0928 12:31:33.584697  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33468 (* 1 = 0.33468 loss)
I0928 12:31:33.725975  4247 solver.cpp:218] Iteration 72000 (5.64411 iter/s, 17.7176s/100 iters), loss = 0.000590977
I0928 12:31:33.726006  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000591166 (* 1 = 0.000591166 loss)
I0928 12:31:33.726012  4247 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I0928 12:31:47.945556  4247 solver.cpp:218] Iteration 72100 (7.03259 iter/s, 14.2195s/100 iters), loss = 0.00222255
I0928 12:31:47.945588  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00222273 (* 1 = 0.00222273 loss)
I0928 12:31:47.945605  4247 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I0928 12:32:02.168479  4247 solver.cpp:218] Iteration 72200 (7.03094 iter/s, 14.2228s/100 iters), loss = 0.00381181
I0928 12:32:02.168596  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.003812 (* 1 = 0.003812 loss)
I0928 12:32:02.168614  4247 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I0928 12:32:16.397611  4247 solver.cpp:218] Iteration 72300 (7.02791 iter/s, 14.229s/100 iters), loss = 0.00254369
I0928 12:32:16.397644  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00254388 (* 1 = 0.00254388 loss)
I0928 12:32:16.397660  4247 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I0928 12:32:30.621407  4247 solver.cpp:218] Iteration 72400 (7.03051 iter/s, 14.2237s/100 iters), loss = 0.00100204
I0928 12:32:30.621449  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100223 (* 1 = 0.00100223 loss)
I0928 12:32:30.621464  4247 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I0928 12:32:44.138896  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:32:44.708360  4247 solver.cpp:330] Iteration 72500, Testing net (#0)
I0928 12:32:48.065091  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:32:48.205301  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9213
I0928 12:32:48.205338  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.345428 (* 1 = 0.345428 loss)
I0928 12:32:48.346407  4247 solver.cpp:218] Iteration 72500 (5.64178 iter/s, 17.7249s/100 iters), loss = 0.00069795
I0928 12:32:48.346437  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000698141 (* 1 = 0.000698141 loss)
I0928 12:32:48.346443  4247 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I0928 12:33:02.569675  4247 solver.cpp:218] Iteration 72600 (7.03077 iter/s, 14.2232s/100 iters), loss = 0.00760154
I0928 12:33:02.569708  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00760173 (* 1 = 0.00760173 loss)
I0928 12:33:02.569725  4247 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I0928 12:33:16.796087  4247 solver.cpp:218] Iteration 72700 (7.02922 iter/s, 14.2263s/100 iters), loss = 0.00373908
I0928 12:33:16.796197  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00373927 (* 1 = 0.00373927 loss)
I0928 12:33:16.796205  4247 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I0928 12:33:31.026481  4247 solver.cpp:218] Iteration 72800 (7.02729 iter/s, 14.2302s/100 iters), loss = 0.00251557
I0928 12:33:31.026515  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00251576 (* 1 = 0.00251576 loss)
I0928 12:33:31.026533  4247 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I0928 12:33:45.252115  4247 solver.cpp:218] Iteration 72900 (7.0296 iter/s, 14.2256s/100 iters), loss = 0.00667575
I0928 12:33:45.252147  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00667594 (* 1 = 0.00667594 loss)
I0928 12:33:45.252163  4247 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I0928 12:33:58.781555  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:33:59.352284  4247 solver.cpp:330] Iteration 73000, Testing net (#0)
I0928 12:34:02.712195  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:34:02.852741  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I0928 12:34:02.852778  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.337237 (* 1 = 0.337237 loss)
I0928 12:34:02.993804  4247 solver.cpp:218] Iteration 73000 (5.63647 iter/s, 17.7416s/100 iters), loss = 0.00880549
I0928 12:34:02.993834  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00880568 (* 1 = 0.00880568 loss)
I0928 12:34:02.993840  4247 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I0928 12:34:17.219668  4247 solver.cpp:218] Iteration 73100 (7.02949 iter/s, 14.2258s/100 iters), loss = 0.00059331
I0928 12:34:17.219702  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000593499 (* 1 = 0.000593499 loss)
I0928 12:34:17.219717  4247 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I0928 12:34:31.445016  4247 solver.cpp:218] Iteration 73200 (7.02974 iter/s, 14.2253s/100 iters), loss = 0.00246983
I0928 12:34:31.445128  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00247002 (* 1 = 0.00247002 loss)
I0928 12:34:31.445135  4247 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I0928 12:34:45.668910  4247 solver.cpp:218] Iteration 73300 (7.0305 iter/s, 14.2237s/100 iters), loss = 0.00783627
I0928 12:34:45.668942  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00783646 (* 1 = 0.00783646 loss)
I0928 12:34:45.668958  4247 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I0928 12:34:59.893596  4247 solver.cpp:218] Iteration 73400 (7.03007 iter/s, 14.2246s/100 iters), loss = 0.00206308
I0928 12:34:59.893630  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00206328 (* 1 = 0.00206328 loss)
I0928 12:34:59.893645  4247 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I0928 12:35:13.414970  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:35:13.985944  4247 solver.cpp:330] Iteration 73500, Testing net (#0)
I0928 12:35:17.343053  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:35:17.483445  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9218
I0928 12:35:17.483482  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334753 (* 1 = 0.334753 loss)
I0928 12:35:17.624727  4247 solver.cpp:218] Iteration 73500 (5.63982 iter/s, 17.731s/100 iters), loss = 0.000607243
I0928 12:35:17.624756  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000607433 (* 1 = 0.000607433 loss)
I0928 12:35:17.624763  4247 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I0928 12:35:31.858319  4247 solver.cpp:218] Iteration 73600 (7.02567 iter/s, 14.2335s/100 iters), loss = 0.00122493
I0928 12:35:31.858350  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00122513 (* 1 = 0.00122513 loss)
I0928 12:35:31.858366  4247 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I0928 12:35:46.099196  4247 solver.cpp:218] Iteration 73700 (7.02208 iter/s, 14.2408s/100 iters), loss = 0.00203614
I0928 12:35:46.099346  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00203633 (* 1 = 0.00203633 loss)
I0928 12:35:46.099365  4247 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I0928 12:36:00.337553  4247 solver.cpp:218] Iteration 73800 (7.02338 iter/s, 14.2382s/100 iters), loss = 0.00319259
I0928 12:36:00.337584  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00319278 (* 1 = 0.00319278 loss)
I0928 12:36:00.337590  4247 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I0928 12:36:14.578092  4247 solver.cpp:218] Iteration 73900 (7.02224 iter/s, 14.2405s/100 iters), loss = 0.00249016
I0928 12:36:14.578125  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00249035 (* 1 = 0.00249035 loss)
I0928 12:36:14.578140  4247 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I0928 12:36:28.106909  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:36:28.677968  4247 solver.cpp:330] Iteration 74000, Testing net (#0)
I0928 12:36:32.034250  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:36:32.174571  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9236
I0928 12:36:32.174607  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329941 (* 1 = 0.329941 loss)
I0928 12:36:32.315547  4247 solver.cpp:218] Iteration 74000 (5.63781 iter/s, 17.7374s/100 iters), loss = 0.00387339
I0928 12:36:32.315577  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00387359 (* 1 = 0.00387359 loss)
I0928 12:36:32.315584  4247 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I0928 12:36:46.529875  4247 solver.cpp:218] Iteration 74100 (7.03519 iter/s, 14.2142s/100 iters), loss = 0.0013795
I0928 12:36:46.529907  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0013797 (* 1 = 0.0013797 loss)
I0928 12:36:46.529922  4247 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I0928 12:37:00.747704  4247 solver.cpp:218] Iteration 74200 (7.03346 iter/s, 14.2178s/100 iters), loss = 0.00160293
I0928 12:37:00.747762  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00160312 (* 1 = 0.00160312 loss)
I0928 12:37:00.747779  4247 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I0928 12:37:14.967265  4247 solver.cpp:218] Iteration 74300 (7.03262 iter/s, 14.2195s/100 iters), loss = 0.00126824
I0928 12:37:14.967298  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00126844 (* 1 = 0.00126844 loss)
I0928 12:37:14.967314  4247 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I0928 12:37:29.185762  4247 solver.cpp:218] Iteration 74400 (7.03313 iter/s, 14.2184s/100 iters), loss = 0.00183525
I0928 12:37:29.185796  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00183545 (* 1 = 0.00183545 loss)
I0928 12:37:29.185811  4247 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I0928 12:37:42.693933  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:37:43.263309  4247 solver.cpp:330] Iteration 74500, Testing net (#0)
I0928 12:37:46.620124  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:37:46.760820  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.921
I0928 12:37:46.760857  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.345097 (* 1 = 0.345097 loss)
I0928 12:37:46.901861  4247 solver.cpp:218] Iteration 74500 (5.64461 iter/s, 17.716s/100 iters), loss = 0.00469433
I0928 12:37:46.901890  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00469453 (* 1 = 0.00469453 loss)
I0928 12:37:46.901896  4247 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I0928 12:38:01.120754  4247 solver.cpp:218] Iteration 74600 (7.03293 iter/s, 14.2188s/100 iters), loss = 0.00134088
I0928 12:38:01.120786  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00134108 (* 1 = 0.00134108 loss)
I0928 12:38:01.120802  4247 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I0928 12:38:15.344538  4247 solver.cpp:218] Iteration 74700 (7.03051 iter/s, 14.2237s/100 iters), loss = 0.000730751
I0928 12:38:15.344643  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000730948 (* 1 = 0.000730948 loss)
I0928 12:38:15.344662  4247 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I0928 12:38:29.572175  4247 solver.cpp:218] Iteration 74800 (7.02864 iter/s, 14.2275s/100 iters), loss = 0.000994107
I0928 12:38:29.572208  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000994302 (* 1 = 0.000994302 loss)
I0928 12:38:29.572224  4247 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I0928 12:38:43.795568  4247 solver.cpp:218] Iteration 74900 (7.03071 iter/s, 14.2233s/100 iters), loss = 0.000688678
I0928 12:38:43.795599  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000688872 (* 1 = 0.000688872 loss)
I0928 12:38:43.795615  4247 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I0928 12:38:57.308717  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:38:57.877754  4247 solver.cpp:330] Iteration 75000, Testing net (#0)
I0928 12:39:01.233247  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:39:01.375411  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9197
I0928 12:39:01.375447  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.357987 (* 1 = 0.357987 loss)
I0928 12:39:01.516966  4247 solver.cpp:218] Iteration 75000 (5.64292 iter/s, 17.7213s/100 iters), loss = 0.00110247
I0928 12:39:01.516995  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00110267 (* 1 = 0.00110267 loss)
I0928 12:39:01.517002  4247 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I0928 12:39:15.740028  4247 solver.cpp:218] Iteration 75100 (7.03087 iter/s, 14.223s/100 iters), loss = 0.00445844
I0928 12:39:15.740059  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00445863 (* 1 = 0.00445863 loss)
I0928 12:39:15.740075  4247 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I0928 12:39:29.966423  4247 solver.cpp:218] Iteration 75200 (7.02922 iter/s, 14.2263s/100 iters), loss = 0.00663634
I0928 12:39:29.966550  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00663653 (* 1 = 0.00663653 loss)
I0928 12:39:29.966568  4247 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I0928 12:39:44.194447  4247 solver.cpp:218] Iteration 75300 (7.02847 iter/s, 14.2279s/100 iters), loss = 0.000829886
I0928 12:39:44.194479  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00083008 (* 1 = 0.00083008 loss)
I0928 12:39:44.194495  4247 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I0928 12:39:58.420605  4247 solver.cpp:218] Iteration 75400 (7.02934 iter/s, 14.2261s/100 iters), loss = 0.00486143
I0928 12:39:58.420639  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00486163 (* 1 = 0.00486163 loss)
I0928 12:39:58.420655  4247 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I0928 12:40:11.945960  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:40:12.516597  4247 solver.cpp:330] Iteration 75500, Testing net (#0)
I0928 12:40:15.872877  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:40:16.013506  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9237
I0928 12:40:16.013543  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.330254 (* 1 = 0.330254 loss)
I0928 12:40:16.154886  4247 solver.cpp:218] Iteration 75500 (5.63882 iter/s, 17.7342s/100 iters), loss = 0.00131076
I0928 12:40:16.154917  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00131095 (* 1 = 0.00131095 loss)
I0928 12:40:16.154922  4247 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I0928 12:40:30.367240  4247 solver.cpp:218] Iteration 75600 (7.03617 iter/s, 14.2123s/100 iters), loss = 0.000844853
I0928 12:40:30.367272  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00084504 (* 1 = 0.00084504 loss)
I0928 12:40:30.367288  4247 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I0928 12:40:44.588073  4247 solver.cpp:218] Iteration 75700 (7.03197 iter/s, 14.2208s/100 iters), loss = 0.00184052
I0928 12:40:44.588214  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00184071 (* 1 = 0.00184071 loss)
I0928 12:40:44.588222  4247 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I0928 12:40:58.812471  4247 solver.cpp:218] Iteration 75800 (7.03026 iter/s, 14.2242s/100 iters), loss = 0.000556126
I0928 12:40:58.812505  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000556313 (* 1 = 0.000556313 loss)
I0928 12:40:58.812520  4247 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I0928 12:41:13.031469  4247 solver.cpp:218] Iteration 75900 (7.03288 iter/s, 14.2189s/100 iters), loss = 0.000440659
I0928 12:41:13.031502  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000440844 (* 1 = 0.000440844 loss)
I0928 12:41:13.031517  4247 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I0928 12:41:26.541383  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:41:27.110427  4247 solver.cpp:330] Iteration 76000, Testing net (#0)
I0928 12:41:30.465916  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:41:30.606758  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9209
I0928 12:41:30.606794  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.362916 (* 1 = 0.362916 loss)
I0928 12:41:30.747509  4247 solver.cpp:218] Iteration 76000 (5.64463 iter/s, 17.716s/100 iters), loss = 0.000922648
I0928 12:41:30.747537  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000922832 (* 1 = 0.000922832 loss)
I0928 12:41:30.747545  4247 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I0928 12:41:44.967506  4247 solver.cpp:218] Iteration 76100 (7.03239 iter/s, 14.2199s/100 iters), loss = 0.00494447
I0928 12:41:44.967538  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00494466 (* 1 = 0.00494466 loss)
I0928 12:41:44.967555  4247 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I0928 12:41:59.192195  4247 solver.cpp:218] Iteration 76200 (7.03007 iter/s, 14.2246s/100 iters), loss = 0.00150948
I0928 12:41:59.192319  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00150967 (* 1 = 0.00150967 loss)
I0928 12:41:59.192337  4247 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I0928 12:42:13.419289  4247 solver.cpp:218] Iteration 76300 (7.02892 iter/s, 14.2269s/100 iters), loss = 0.000799178
I0928 12:42:13.419322  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000799361 (* 1 = 0.000799361 loss)
I0928 12:42:13.419338  4247 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I0928 12:42:27.645714  4247 solver.cpp:218] Iteration 76400 (7.02921 iter/s, 14.2264s/100 iters), loss = 0.00148636
I0928 12:42:27.645745  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00148654 (* 1 = 0.00148654 loss)
I0928 12:42:27.645761  4247 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I0928 12:42:41.162444  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:42:41.733960  4247 solver.cpp:330] Iteration 76500, Testing net (#0)
I0928 12:42:45.089843  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:42:45.230247  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9248
I0928 12:42:45.230285  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.337541 (* 1 = 0.337541 loss)
I0928 12:42:45.371146  4247 solver.cpp:218] Iteration 76500 (5.64164 iter/s, 17.7253s/100 iters), loss = 0.00175655
I0928 12:42:45.371176  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00175674 (* 1 = 0.00175674 loss)
I0928 12:42:45.371182  4247 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I0928 12:42:59.581037  4247 solver.cpp:218] Iteration 76600 (7.03739 iter/s, 14.2098s/100 iters), loss = 0.00325663
I0928 12:42:59.581070  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00325681 (* 1 = 0.00325681 loss)
I0928 12:42:59.581086  4247 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I0928 12:43:13.795862  4247 solver.cpp:218] Iteration 76700 (7.03495 iter/s, 14.2148s/100 iters), loss = 0.00134972
I0928 12:43:13.795940  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0013499 (* 1 = 0.0013499 loss)
I0928 12:43:13.795958  4247 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I0928 12:43:28.012749  4247 solver.cpp:218] Iteration 76800 (7.03395 iter/s, 14.2168s/100 iters), loss = 0.0053213
I0928 12:43:28.012781  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00532148 (* 1 = 0.00532148 loss)
I0928 12:43:28.012797  4247 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I0928 12:43:42.222566  4247 solver.cpp:218] Iteration 76900 (7.03742 iter/s, 14.2097s/100 iters), loss = 0.00359784
I0928 12:43:42.222597  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00359802 (* 1 = 0.00359802 loss)
I0928 12:43:42.222614  4247 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I0928 12:43:55.725272  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:43:56.294283  4247 solver.cpp:330] Iteration 77000, Testing net (#0)
I0928 12:43:59.652236  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:43:59.792755  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9204
I0928 12:43:59.792781  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.356968 (* 1 = 0.356968 loss)
I0928 12:43:59.934072  4247 solver.cpp:218] Iteration 77000 (5.64607 iter/s, 17.7114s/100 iters), loss = 0.000398379
I0928 12:43:59.934101  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000398559 (* 1 = 0.000398559 loss)
I0928 12:43:59.934108  4247 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I0928 12:44:14.160079  4247 solver.cpp:218] Iteration 77100 (7.02941 iter/s, 14.2259s/100 iters), loss = 0.0025685
I0928 12:44:14.160122  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00256869 (* 1 = 0.00256869 loss)
I0928 12:44:14.160128  4247 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I0928 12:44:28.394162  4247 solver.cpp:218] Iteration 77200 (7.02543 iter/s, 14.234s/100 iters), loss = 0.00181699
I0928 12:44:28.394273  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00181718 (* 1 = 0.00181718 loss)
I0928 12:44:28.394290  4247 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I0928 12:44:42.623559  4247 solver.cpp:218] Iteration 77300 (7.02777 iter/s, 14.2293s/100 iters), loss = 0.00308376
I0928 12:44:42.623590  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00308394 (* 1 = 0.00308394 loss)
I0928 12:44:42.623596  4247 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I0928 12:44:56.848951  4247 solver.cpp:218] Iteration 77400 (7.02972 iter/s, 14.2253s/100 iters), loss = 0.000756209
I0928 12:44:56.848984  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000756392 (* 1 = 0.000756392 loss)
I0928 12:44:56.848990  4247 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I0928 12:45:10.370802  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:45:10.939863  4247 solver.cpp:330] Iteration 77500, Testing net (#0)
I0928 12:45:14.295722  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:45:14.436728  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9174
I0928 12:45:14.436764  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.357785 (* 1 = 0.357785 loss)
I0928 12:45:14.577772  4247 solver.cpp:218] Iteration 77500 (5.64056 iter/s, 17.7287s/100 iters), loss = 0.00516606
I0928 12:45:14.577803  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00516623 (* 1 = 0.00516623 loss)
I0928 12:45:14.577811  4247 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I0928 12:45:28.868641  4247 solver.cpp:218] Iteration 77600 (6.99751 iter/s, 14.2908s/100 iters), loss = 0.00129234
I0928 12:45:28.868677  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00129252 (* 1 = 0.00129252 loss)
I0928 12:45:28.868695  4247 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I0928 12:45:43.201877  4247 solver.cpp:218] Iteration 77700 (6.97683 iter/s, 14.3332s/100 iters), loss = 0.00255848
I0928 12:45:43.202044  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00255866 (* 1 = 0.00255866 loss)
I0928 12:45:43.202052  4247 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I0928 12:45:57.486076  4247 solver.cpp:218] Iteration 77800 (7.00084 iter/s, 14.284s/100 iters), loss = 0.00265449
I0928 12:45:57.486119  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00265467 (* 1 = 0.00265467 loss)
I0928 12:45:57.486125  4247 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I0928 12:46:11.719964  4247 solver.cpp:218] Iteration 77900 (7.02553 iter/s, 14.2338s/100 iters), loss = 0.00148841
I0928 12:46:11.720006  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00148858 (* 1 = 0.00148858 loss)
I0928 12:46:11.720012  4247 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I0928 12:46:25.250097  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:46:25.821041  4247 solver.cpp:330] Iteration 78000, Testing net (#0)
I0928 12:46:29.175565  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:46:29.316207  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9211
I0928 12:46:29.316244  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.346641 (* 1 = 0.346641 loss)
I0928 12:46:29.457389  4247 solver.cpp:218] Iteration 78000 (5.63783 iter/s, 17.7373s/100 iters), loss = 0.00155886
I0928 12:46:29.457420  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00155904 (* 1 = 0.00155904 loss)
I0928 12:46:29.457427  4247 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I0928 12:46:43.675037  4247 solver.cpp:218] Iteration 78100 (7.03355 iter/s, 14.2176s/100 iters), loss = 0.00499695
I0928 12:46:43.675079  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00499713 (* 1 = 0.00499713 loss)
I0928 12:46:43.675086  4247 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I0928 12:46:57.898699  4247 solver.cpp:218] Iteration 78200 (7.03058 iter/s, 14.2236s/100 iters), loss = 0.00210366
I0928 12:46:57.898808  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00210383 (* 1 = 0.00210383 loss)
I0928 12:46:57.898816  4247 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I0928 12:47:12.125329  4247 solver.cpp:218] Iteration 78300 (7.02915 iter/s, 14.2265s/100 iters), loss = 0.00333711
I0928 12:47:12.125357  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00333729 (* 1 = 0.00333729 loss)
I0928 12:47:12.125363  4247 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I0928 12:47:26.348688  4247 solver.cpp:218] Iteration 78400 (7.03072 iter/s, 14.2233s/100 iters), loss = 0.00496395
I0928 12:47:26.348731  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00496413 (* 1 = 0.00496413 loss)
I0928 12:47:26.348737  4247 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I0928 12:47:39.869390  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:47:40.438549  4247 solver.cpp:330] Iteration 78500, Testing net (#0)
I0928 12:47:43.793375  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:47:43.933419  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9253
I0928 12:47:43.933456  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.330802 (* 1 = 0.330802 loss)
I0928 12:47:44.075598  4247 solver.cpp:218] Iteration 78500 (5.64117 iter/s, 17.7268s/100 iters), loss = 0.00995223
I0928 12:47:44.075625  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00995241 (* 1 = 0.00995241 loss)
I0928 12:47:44.075631  4247 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I0928 12:47:58.308876  4247 solver.cpp:218] Iteration 78600 (7.02582 iter/s, 14.2332s/100 iters), loss = 0.00540538
I0928 12:47:58.308917  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00540555 (* 1 = 0.00540555 loss)
I0928 12:47:58.308923  4247 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I0928 12:48:12.544492  4247 solver.cpp:218] Iteration 78700 (7.02468 iter/s, 14.2355s/100 iters), loss = 0.000803889
I0928 12:48:12.544647  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000804064 (* 1 = 0.000804064 loss)
I0928 12:48:12.544656  4247 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I0928 12:48:26.787842  4247 solver.cpp:218] Iteration 78800 (7.02091 iter/s, 14.2432s/100 iters), loss = 0.000739506
I0928 12:48:26.787874  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00073968 (* 1 = 0.00073968 loss)
I0928 12:48:26.787881  4247 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I0928 12:48:41.024648  4247 solver.cpp:218] Iteration 78900 (7.02408 iter/s, 14.2367s/100 iters), loss = 0.000980651
I0928 12:48:41.024690  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000980825 (* 1 = 0.000980825 loss)
I0928 12:48:41.024696  4247 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I0928 12:48:54.550801  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:48:55.121282  4247 solver.cpp:330] Iteration 79000, Testing net (#0)
I0928 12:48:58.477437  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:48:58.617714  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9233
I0928 12:48:58.617753  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.342086 (* 1 = 0.342086 loss)
I0928 12:48:58.758997  4247 solver.cpp:218] Iteration 79000 (5.6388 iter/s, 17.7343s/100 iters), loss = 0.00492303
I0928 12:48:58.759027  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0049232 (* 1 = 0.0049232 loss)
I0928 12:48:58.759033  4247 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I0928 12:49:12.973994  4247 solver.cpp:218] Iteration 79100 (7.03486 iter/s, 14.2149s/100 iters), loss = 0.013824
I0928 12:49:12.974026  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138241 (* 1 = 0.0138241 loss)
I0928 12:49:12.974032  4247 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I0928 12:49:27.190829  4247 solver.cpp:218] Iteration 79200 (7.03395 iter/s, 14.2168s/100 iters), loss = 0.00114222
I0928 12:49:27.190968  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00114239 (* 1 = 0.00114239 loss)
I0928 12:49:27.190975  4247 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I0928 12:49:41.413635  4247 solver.cpp:218] Iteration 79300 (7.03104 iter/s, 14.2226s/100 iters), loss = 0.00113729
I0928 12:49:41.413678  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00113747 (* 1 = 0.00113747 loss)
I0928 12:49:41.413684  4247 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I0928 12:49:55.633137  4247 solver.cpp:218] Iteration 79400 (7.03264 iter/s, 14.2194s/100 iters), loss = 0.00152981
I0928 12:49:55.633180  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00152998 (* 1 = 0.00152998 loss)
I0928 12:49:55.633186  4247 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I0928 12:50:09.148630  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:50:09.717381  4247 solver.cpp:330] Iteration 79500, Testing net (#0)
I0928 12:50:13.075052  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:50:13.215586  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9253
I0928 12:50:13.215623  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.331688 (* 1 = 0.331688 loss)
I0928 12:50:13.357108  4247 solver.cpp:218] Iteration 79500 (5.6421 iter/s, 17.7239s/100 iters), loss = 0.0007245
I0928 12:50:13.357138  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000724676 (* 1 = 0.000724676 loss)
I0928 12:50:13.357157  4247 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I0928 12:50:27.578152  4247 solver.cpp:218] Iteration 79600 (7.03187 iter/s, 14.221s/100 iters), loss = 0.00639042
I0928 12:50:27.578194  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0063906 (* 1 = 0.0063906 loss)
I0928 12:50:27.578200  4247 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I0928 12:50:41.798280  4247 solver.cpp:218] Iteration 79700 (7.03233 iter/s, 14.22s/100 iters), loss = 0.00156619
I0928 12:50:41.798405  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00156636 (* 1 = 0.00156636 loss)
I0928 12:50:41.798413  4247 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I0928 12:50:56.023995  4247 solver.cpp:218] Iteration 79800 (7.02961 iter/s, 14.2255s/100 iters), loss = 0.00243176
I0928 12:50:56.024037  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00243193 (* 1 = 0.00243193 loss)
I0928 12:50:56.024044  4247 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I0928 12:51:10.253867  4247 solver.cpp:218] Iteration 79900 (7.02751 iter/s, 14.2298s/100 iters), loss = 0.00223248
I0928 12:51:10.253899  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00223265 (* 1 = 0.00223265 loss)
I0928 12:51:10.253906  4247 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I0928 12:51:23.766363  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:51:24.334849  4247 solver.cpp:330] Iteration 80000, Testing net (#0)
I0928 12:51:27.691136  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:51:27.831588  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9224
I0928 12:51:27.831624  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34297 (* 1 = 0.34297 loss)
I0928 12:51:27.973001  4247 solver.cpp:218] Iteration 80000 (5.64364 iter/s, 17.7191s/100 iters), loss = 0.00181931
I0928 12:51:27.973031  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00181948 (* 1 = 0.00181948 loss)
I0928 12:51:27.973037  4247 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I0928 12:51:27.973040  4247 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I0928 12:51:42.187734  4247 solver.cpp:218] Iteration 80100 (7.03499 iter/s, 14.2147s/100 iters), loss = 0.000682092
I0928 12:51:42.187775  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000682264 (* 1 = 0.000682264 loss)
I0928 12:51:42.187782  4247 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I0928 12:51:56.402496  4247 solver.cpp:218] Iteration 80200 (7.03498 iter/s, 14.2147s/100 iters), loss = 0.00342376
I0928 12:51:56.402597  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00342393 (* 1 = 0.00342393 loss)
I0928 12:51:56.402604  4247 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I0928 12:52:10.618454  4247 solver.cpp:218] Iteration 80300 (7.03442 iter/s, 14.2158s/100 iters), loss = 0.00145201
I0928 12:52:10.618496  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00145218 (* 1 = 0.00145218 loss)
I0928 12:52:10.618502  4247 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I0928 12:52:24.835711  4247 solver.cpp:218] Iteration 80400 (7.03375 iter/s, 14.2172s/100 iters), loss = 0.0012127
I0928 12:52:24.835742  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00121287 (* 1 = 0.00121287 loss)
I0928 12:52:24.835748  4247 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I0928 12:52:38.341024  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:52:38.909917  4247 solver.cpp:330] Iteration 80500, Testing net (#0)
I0928 12:52:42.264472  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:52:42.404525  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9261
I0928 12:52:42.404562  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318411 (* 1 = 0.318411 loss)
I0928 12:52:42.549904  4247 solver.cpp:218] Iteration 80500 (5.64522 iter/s, 17.7141s/100 iters), loss = 0.000655102
I0928 12:52:42.549937  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000655273 (* 1 = 0.000655273 loss)
I0928 12:52:42.549944  4247 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I0928 12:52:56.769729  4247 solver.cpp:218] Iteration 80600 (7.03247 iter/s, 14.2197s/100 iters), loss = 0.00641417
I0928 12:52:56.769760  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00641434 (* 1 = 0.00641434 loss)
I0928 12:52:56.769767  4247 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I0928 12:53:10.995533  4247 solver.cpp:218] Iteration 80700 (7.02951 iter/s, 14.2257s/100 iters), loss = 0.000998551
I0928 12:53:10.995645  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000998721 (* 1 = 0.000998721 loss)
I0928 12:53:10.995651  4247 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I0928 12:53:25.221956  4247 solver.cpp:218] Iteration 80800 (7.02924 iter/s, 14.2263s/100 iters), loss = 0.000826949
I0928 12:53:25.221998  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000827119 (* 1 = 0.000827119 loss)
I0928 12:53:25.222004  4247 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I0928 12:53:39.447487  4247 solver.cpp:218] Iteration 80900 (7.02966 iter/s, 14.2254s/100 iters), loss = 0.0010275
I0928 12:53:39.447530  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102767 (* 1 = 0.00102767 loss)
I0928 12:53:39.447536  4247 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I0928 12:53:52.968188  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:53:53.536736  4247 solver.cpp:330] Iteration 81000, Testing net (#0)
I0928 12:53:56.891228  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:53:57.031728  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9278
I0928 12:53:57.031764  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31343 (* 1 = 0.31343 loss)
I0928 12:53:57.173506  4247 solver.cpp:218] Iteration 81000 (5.64145 iter/s, 17.7259s/100 iters), loss = 0.00371226
I0928 12:53:57.173534  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00371243 (* 1 = 0.00371243 loss)
I0928 12:53:57.173540  4247 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I0928 12:54:11.388984  4247 solver.cpp:218] Iteration 81100 (7.03462 iter/s, 14.2154s/100 iters), loss = 0.00553191
I0928 12:54:11.389026  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00553208 (* 1 = 0.00553208 loss)
I0928 12:54:11.389032  4247 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I0928 12:54:25.613849  4247 solver.cpp:218] Iteration 81200 (7.02999 iter/s, 14.2248s/100 iters), loss = 0.00106791
I0928 12:54:25.613975  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00106808 (* 1 = 0.00106808 loss)
I0928 12:54:25.613981  4247 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I0928 12:54:39.838382  4247 solver.cpp:218] Iteration 81300 (7.03019 iter/s, 14.2244s/100 iters), loss = 0.000285757
I0928 12:54:39.838424  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000285924 (* 1 = 0.000285924 loss)
I0928 12:54:39.838430  4247 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I0928 12:54:54.061724  4247 solver.cpp:218] Iteration 81400 (7.03074 iter/s, 14.2233s/100 iters), loss = 0.00100427
I0928 12:54:54.061766  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100444 (* 1 = 0.00100444 loss)
I0928 12:54:54.061772  4247 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I0928 12:55:07.573326  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:55:08.143335  4247 solver.cpp:330] Iteration 81500, Testing net (#0)
I0928 12:55:11.499624  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:55:11.639652  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9273
I0928 12:55:11.639688  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314053 (* 1 = 0.314053 loss)
I0928 12:55:11.780784  4247 solver.cpp:218] Iteration 81500 (5.64367 iter/s, 17.719s/100 iters), loss = 0.000762593
I0928 12:55:11.780813  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000762759 (* 1 = 0.000762759 loss)
I0928 12:55:11.780820  4247 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I0928 12:55:25.996778  4247 solver.cpp:218] Iteration 81600 (7.03437 iter/s, 14.2159s/100 iters), loss = 0.00223534
I0928 12:55:25.996821  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0022355 (* 1 = 0.0022355 loss)
I0928 12:55:25.996827  4247 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I0928 12:55:40.214301  4247 solver.cpp:218] Iteration 81700 (7.03362 iter/s, 14.2174s/100 iters), loss = 0.000533668
I0928 12:55:40.214391  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000533833 (* 1 = 0.000533833 loss)
I0928 12:55:40.214398  4247 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I0928 12:55:54.431033  4247 solver.cpp:218] Iteration 81800 (7.03403 iter/s, 14.2166s/100 iters), loss = 0.000156681
I0928 12:55:54.431077  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000156847 (* 1 = 0.000156847 loss)
I0928 12:55:54.431082  4247 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I0928 12:56:08.649281  4247 solver.cpp:218] Iteration 81900 (7.03326 iter/s, 14.2182s/100 iters), loss = 0.00356277
I0928 12:56:08.649322  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00356294 (* 1 = 0.00356294 loss)
I0928 12:56:08.649327  4247 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I0928 12:56:22.160372  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:56:22.729238  4247 solver.cpp:330] Iteration 82000, Testing net (#0)
I0928 12:56:26.085927  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:56:26.226459  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.928
I0928 12:56:26.226497  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312625 (* 1 = 0.312625 loss)
I0928 12:56:26.367491  4247 solver.cpp:218] Iteration 82000 (5.64394 iter/s, 17.7181s/100 iters), loss = 0.00146822
I0928 12:56:26.367521  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00146838 (* 1 = 0.00146838 loss)
I0928 12:56:26.367527  4247 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I0928 12:56:40.581109  4247 solver.cpp:218] Iteration 82100 (7.03554 iter/s, 14.2135s/100 iters), loss = 0.00367483
I0928 12:56:40.581149  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00367499 (* 1 = 0.00367499 loss)
I0928 12:56:40.581156  4247 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I0928 12:56:54.800103  4247 solver.cpp:218] Iteration 82200 (7.03289 iter/s, 14.2189s/100 iters), loss = 0.000792802
I0928 12:56:54.800231  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000792966 (* 1 = 0.000792966 loss)
I0928 12:56:54.800240  4247 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I0928 12:57:09.021826  4247 solver.cpp:218] Iteration 82300 (7.03157 iter/s, 14.2216s/100 iters), loss = 0.00276975
I0928 12:57:09.021867  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00276991 (* 1 = 0.00276991 loss)
I0928 12:57:09.021872  4247 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I0928 12:57:23.242609  4247 solver.cpp:218] Iteration 82400 (7.032 iter/s, 14.2207s/100 iters), loss = 0.00301266
I0928 12:57:23.242651  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00301282 (* 1 = 0.00301282 loss)
I0928 12:57:23.242657  4247 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I0928 12:57:36.753628  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:57:37.322729  4247 solver.cpp:330] Iteration 82500, Testing net (#0)
I0928 12:57:40.678947  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:57:40.819546  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.928
I0928 12:57:40.819583  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313654 (* 1 = 0.313654 loss)
I0928 12:57:40.960744  4247 solver.cpp:218] Iteration 82500 (5.64396 iter/s, 17.718s/100 iters), loss = 0.00104873
I0928 12:57:40.960777  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010489 (* 1 = 0.0010489 loss)
I0928 12:57:40.960783  4247 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I0928 12:57:55.177578  4247 solver.cpp:218] Iteration 82600 (7.03395 iter/s, 14.2168s/100 iters), loss = 0.00101508
I0928 12:57:55.177621  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00101524 (* 1 = 0.00101524 loss)
I0928 12:57:55.177628  4247 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I0928 12:58:09.399766  4247 solver.cpp:218] Iteration 82700 (7.03131 iter/s, 14.2221s/100 iters), loss = 0.00100724
I0928 12:58:09.399895  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100741 (* 1 = 0.00100741 loss)
I0928 12:58:09.399902  4247 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I0928 12:58:23.620064  4247 solver.cpp:218] Iteration 82800 (7.03229 iter/s, 14.2201s/100 iters), loss = 0.000775721
I0928 12:58:23.620106  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000775888 (* 1 = 0.000775888 loss)
I0928 12:58:23.620112  4247 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I0928 12:58:37.838533  4247 solver.cpp:218] Iteration 82900 (7.03315 iter/s, 14.2184s/100 iters), loss = 0.00166499
I0928 12:58:37.838577  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00166516 (* 1 = 0.00166516 loss)
I0928 12:58:37.838582  4247 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I0928 12:58:51.348961  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:58:51.918124  4247 solver.cpp:330] Iteration 83000, Testing net (#0)
I0928 12:58:55.274065  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 12:58:55.414494  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9275
I0928 12:58:55.414532  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.315538 (* 1 = 0.315538 loss)
I0928 12:58:55.555866  4247 solver.cpp:218] Iteration 83000 (5.64422 iter/s, 17.7172s/100 iters), loss = 0.00301883
I0928 12:58:55.555896  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.003019 (* 1 = 0.003019 loss)
I0928 12:58:55.555902  4247 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I0928 12:59:09.777088  4247 solver.cpp:218] Iteration 83100 (7.03178 iter/s, 14.2212s/100 iters), loss = 0.000871033
I0928 12:59:09.777130  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0008712 (* 1 = 0.0008712 loss)
I0928 12:59:09.777137  4247 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I0928 12:59:23.997360  4247 solver.cpp:218] Iteration 83200 (7.03226 iter/s, 14.2202s/100 iters), loss = 0.000576342
I0928 12:59:23.997439  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00057651 (* 1 = 0.00057651 loss)
I0928 12:59:23.997455  4247 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I0928 12:59:38.219200  4247 solver.cpp:218] Iteration 83300 (7.0315 iter/s, 14.2217s/100 iters), loss = 0.000879505
I0928 12:59:38.219243  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000879673 (* 1 = 0.000879673 loss)
I0928 12:59:38.219249  4247 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I0928 12:59:52.439219  4247 solver.cpp:218] Iteration 83400 (7.03238 iter/s, 14.2199s/100 iters), loss = 0.000825311
I0928 12:59:52.439260  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000825479 (* 1 = 0.000825479 loss)
I0928 12:59:52.439266  4247 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I0928 13:00:05.957816  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:00:06.526262  4247 solver.cpp:330] Iteration 83500, Testing net (#0)
I0928 13:00:09.882861  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:00:10.023234  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9281
I0928 13:00:10.023272  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313381 (* 1 = 0.313381 loss)
I0928 13:00:10.164558  4247 solver.cpp:218] Iteration 83500 (5.64167 iter/s, 17.7252s/100 iters), loss = 0.00098983
I0928 13:00:10.164587  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000989996 (* 1 = 0.000989996 loss)
I0928 13:00:10.164593  4247 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I0928 13:00:24.389479  4247 solver.cpp:218] Iteration 83600 (7.02995 iter/s, 14.2248s/100 iters), loss = 0.00430128
I0928 13:00:24.389511  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00430144 (* 1 = 0.00430144 loss)
I0928 13:00:24.389518  4247 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I0928 13:00:38.619403  4247 solver.cpp:218] Iteration 83700 (7.02748 iter/s, 14.2298s/100 iters), loss = 0.000980007
I0928 13:00:38.619526  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000980174 (* 1 = 0.000980174 loss)
I0928 13:00:38.619534  4247 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I0928 13:00:52.847623  4247 solver.cpp:218] Iteration 83800 (7.02836 iter/s, 14.2281s/100 iters), loss = 0.00155019
I0928 13:00:52.847663  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00155036 (* 1 = 0.00155036 loss)
I0928 13:00:52.847669  4247 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I0928 13:01:07.072551  4247 solver.cpp:218] Iteration 83900 (7.02995 iter/s, 14.2248s/100 iters), loss = 0.000564543
I0928 13:01:07.072592  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000564708 (* 1 = 0.000564708 loss)
I0928 13:01:07.072597  4247 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I0928 13:01:20.592751  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:01:21.162153  4247 solver.cpp:330] Iteration 84000, Testing net (#0)
I0928 13:01:24.517962  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:01:24.658192  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9284
I0928 13:01:24.658219  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.3122 (* 1 = 0.3122 loss)
I0928 13:01:24.799249  4247 solver.cpp:218] Iteration 84000 (5.64124 iter/s, 17.7266s/100 iters), loss = 0.000498576
I0928 13:01:24.799278  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000498741 (* 1 = 0.000498741 loss)
I0928 13:01:24.799285  4247 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I0928 13:01:39.007699  4247 solver.cpp:218] Iteration 84100 (7.0381 iter/s, 14.2084s/100 iters), loss = 0.0056408
I0928 13:01:39.007743  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00564097 (* 1 = 0.00564097 loss)
I0928 13:01:39.007750  4247 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I0928 13:01:53.221372  4247 solver.cpp:218] Iteration 84200 (7.03552 iter/s, 14.2136s/100 iters), loss = 0.000783894
I0928 13:01:53.221454  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00078406 (* 1 = 0.00078406 loss)
I0928 13:01:53.221469  4247 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I0928 13:02:07.437180  4247 solver.cpp:218] Iteration 84300 (7.03448 iter/s, 14.2157s/100 iters), loss = 0.000674182
I0928 13:02:07.437223  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000674348 (* 1 = 0.000674348 loss)
I0928 13:02:07.437229  4247 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I0928 13:02:21.659802  4247 solver.cpp:218] Iteration 84400 (7.03109 iter/s, 14.2225s/100 iters), loss = 0.000884332
I0928 13:02:21.659844  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000884499 (* 1 = 0.000884499 loss)
I0928 13:02:21.659850  4247 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I0928 13:02:35.173620  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:02:35.742604  4247 solver.cpp:330] Iteration 84500, Testing net (#0)
I0928 13:02:39.099052  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:02:39.238955  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.928
I0928 13:02:39.238992  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308848 (* 1 = 0.308848 loss)
I0928 13:02:39.380272  4247 solver.cpp:218] Iteration 84500 (5.64322 iter/s, 17.7204s/100 iters), loss = 0.000528149
I0928 13:02:39.380301  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000528317 (* 1 = 0.000528317 loss)
I0928 13:02:39.380308  4247 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I0928 13:02:53.601982  4247 solver.cpp:218] Iteration 84600 (7.03154 iter/s, 14.2216s/100 iters), loss = 0.00129341
I0928 13:02:53.602025  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00129357 (* 1 = 0.00129357 loss)
I0928 13:02:53.602032  4247 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I0928 13:03:07.830065  4247 solver.cpp:218] Iteration 84700 (7.0284 iter/s, 14.228s/100 iters), loss = 0.000513486
I0928 13:03:07.830170  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000513651 (* 1 = 0.000513651 loss)
I0928 13:03:07.830186  4247 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I0928 13:03:22.053413  4247 solver.cpp:218] Iteration 84800 (7.03077 iter/s, 14.2232s/100 iters), loss = 0.000591427
I0928 13:03:22.053455  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000591593 (* 1 = 0.000591593 loss)
I0928 13:03:22.053462  4247 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I0928 13:03:36.279206  4247 solver.cpp:218] Iteration 84900 (7.02953 iter/s, 14.2257s/100 iters), loss = 0.00115766
I0928 13:03:36.279249  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00115783 (* 1 = 0.00115783 loss)
I0928 13:03:36.279255  4247 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I0928 13:03:49.797385  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:03:50.367311  4247 solver.cpp:330] Iteration 85000, Testing net (#0)
I0928 13:03:53.723887  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:03:53.863899  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9293
I0928 13:03:53.863936  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308978 (* 1 = 0.308978 loss)
I0928 13:03:54.004917  4247 solver.cpp:218] Iteration 85000 (5.64155 iter/s, 17.7256s/100 iters), loss = 0.000614424
I0928 13:03:54.004945  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000614589 (* 1 = 0.000614589 loss)
I0928 13:03:54.004952  4247 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I0928 13:04:08.213600  4247 solver.cpp:218] Iteration 85100 (7.03798 iter/s, 14.2086s/100 iters), loss = 0.00196201
I0928 13:04:08.213644  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00196218 (* 1 = 0.00196218 loss)
I0928 13:04:08.213650  4247 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I0928 13:04:22.432763  4247 solver.cpp:218] Iteration 85200 (7.03281 iter/s, 14.2191s/100 iters), loss = 0.00102846
I0928 13:04:22.432881  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102863 (* 1 = 0.00102863 loss)
I0928 13:04:22.432899  4247 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I0928 13:04:36.651093  4247 solver.cpp:218] Iteration 85300 (7.03325 iter/s, 14.2182s/100 iters), loss = 0.00140624
I0928 13:04:36.651124  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0014064 (* 1 = 0.0014064 loss)
I0928 13:04:36.651129  4247 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I0928 13:04:50.873136  4247 solver.cpp:218] Iteration 85400 (7.03137 iter/s, 14.222s/100 iters), loss = 0.00188482
I0928 13:04:50.873179  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188498 (* 1 = 0.00188498 loss)
I0928 13:04:50.873185  4247 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I0928 13:05:04.385442  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:05:04.955183  4247 solver.cpp:330] Iteration 85500, Testing net (#0)
I0928 13:05:08.309928  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:05:08.449987  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9287
I0928 13:05:08.450013  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308113 (* 1 = 0.308113 loss)
I0928 13:05:08.594094  4247 solver.cpp:218] Iteration 85500 (5.64306 iter/s, 17.7209s/100 iters), loss = 0.00216722
I0928 13:05:08.594125  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00216739 (* 1 = 0.00216739 loss)
I0928 13:05:08.594132  4247 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I0928 13:05:22.814987  4247 solver.cpp:218] Iteration 85600 (7.03194 iter/s, 14.2208s/100 iters), loss = 0.000905803
I0928 13:05:22.815028  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000905968 (* 1 = 0.000905968 loss)
I0928 13:05:22.815035  4247 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I0928 13:05:37.037524  4247 solver.cpp:218] Iteration 85700 (7.03113 iter/s, 14.2225s/100 iters), loss = 0.000793141
I0928 13:05:37.037643  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000793307 (* 1 = 0.000793307 loss)
I0928 13:05:37.037652  4247 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I0928 13:05:51.264578  4247 solver.cpp:218] Iteration 85800 (7.02893 iter/s, 14.2269s/100 iters), loss = 0.0019005
I0928 13:05:51.264621  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00190066 (* 1 = 0.00190066 loss)
I0928 13:05:51.264627  4247 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I0928 13:06:05.495926  4247 solver.cpp:218] Iteration 85900 (7.02678 iter/s, 14.2313s/100 iters), loss = 0.000845744
I0928 13:06:05.495967  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00084591 (* 1 = 0.00084591 loss)
I0928 13:06:05.495973  4247 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I0928 13:06:19.020831  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:06:19.590731  4247 solver.cpp:330] Iteration 86000, Testing net (#0)
I0928 13:06:22.945642  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:06:23.086313  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9286
I0928 13:06:23.086349  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308753 (* 1 = 0.308753 loss)
I0928 13:06:23.227488  4247 solver.cpp:218] Iteration 86000 (5.63969 iter/s, 17.7315s/100 iters), loss = 0.000553219
I0928 13:06:23.227516  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000553385 (* 1 = 0.000553385 loss)
I0928 13:06:23.227522  4247 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I0928 13:06:37.446226  4247 solver.cpp:218] Iteration 86100 (7.03301 iter/s, 14.2187s/100 iters), loss = 0.000814307
I0928 13:06:37.446267  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000814471 (* 1 = 0.000814471 loss)
I0928 13:06:37.446272  4247 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I0928 13:06:51.671502  4247 solver.cpp:218] Iteration 86200 (7.02978 iter/s, 14.2252s/100 iters), loss = 0.000691757
I0928 13:06:51.671591  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000691923 (* 1 = 0.000691923 loss)
I0928 13:06:51.671608  4247 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I0928 13:07:05.893481  4247 solver.cpp:218] Iteration 86300 (7.03143 iter/s, 14.2219s/100 iters), loss = 0.00110158
I0928 13:07:05.893524  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00110175 (* 1 = 0.00110175 loss)
I0928 13:07:05.893530  4247 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I0928 13:07:20.114919  4247 solver.cpp:218] Iteration 86400 (7.03168 iter/s, 14.2213s/100 iters), loss = 0.00334978
I0928 13:07:20.114961  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00334995 (* 1 = 0.00334995 loss)
I0928 13:07:20.114967  4247 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I0928 13:07:33.633508  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:07:34.202920  4247 solver.cpp:330] Iteration 86500, Testing net (#0)
I0928 13:07:37.558576  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:07:37.699092  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9282
I0928 13:07:37.699131  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309927 (* 1 = 0.309927 loss)
I0928 13:07:37.840240  4247 solver.cpp:218] Iteration 86500 (5.64167 iter/s, 17.7252s/100 iters), loss = 0.00123878
I0928 13:07:37.840268  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00123895 (* 1 = 0.00123895 loss)
I0928 13:07:37.840276  4247 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I0928 13:07:52.056484  4247 solver.cpp:218] Iteration 86600 (7.03424 iter/s, 14.2162s/100 iters), loss = 0.000146747
I0928 13:07:52.056526  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000146911 (* 1 = 0.000146911 loss)
I0928 13:07:52.056532  4247 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I0928 13:08:06.276940  4247 solver.cpp:218] Iteration 86700 (7.03216 iter/s, 14.2204s/100 iters), loss = 0.00103544
I0928 13:08:06.277062  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010356 (* 1 = 0.0010356 loss)
I0928 13:08:06.277070  4247 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I0928 13:08:20.499902  4247 solver.cpp:218] Iteration 86800 (7.03096 iter/s, 14.2228s/100 iters), loss = 0.00106158
I0928 13:08:20.499943  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00106174 (* 1 = 0.00106174 loss)
I0928 13:08:20.499949  4247 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I0928 13:08:34.717787  4247 solver.cpp:218] Iteration 86900 (7.03344 iter/s, 14.2178s/100 iters), loss = 0.00244289
I0928 13:08:34.717829  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00244305 (* 1 = 0.00244305 loss)
I0928 13:08:34.717835  4247 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I0928 13:08:48.232587  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:08:48.802301  4247 solver.cpp:330] Iteration 87000, Testing net (#0)
I0928 13:08:52.157373  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:08:52.297673  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9285
I0928 13:08:52.297710  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312664 (* 1 = 0.312664 loss)
I0928 13:08:52.439105  4247 solver.cpp:218] Iteration 87000 (5.64295 iter/s, 17.7212s/100 iters), loss = 0.000203791
I0928 13:08:52.439136  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000203952 (* 1 = 0.000203952 loss)
I0928 13:08:52.439153  4247 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I0928 13:09:06.664417  4247 solver.cpp:218] Iteration 87100 (7.02976 iter/s, 14.2252s/100 iters), loss = 0.000694607
I0928 13:09:06.664449  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000694768 (* 1 = 0.000694768 loss)
I0928 13:09:06.664466  4247 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I0928 13:09:20.889811  4247 solver.cpp:218] Iteration 87200 (7.02972 iter/s, 14.2253s/100 iters), loss = 0.000653492
I0928 13:09:20.889931  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000653653 (* 1 = 0.000653653 loss)
I0928 13:09:20.889950  4247 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I0928 13:09:35.112985  4247 solver.cpp:218] Iteration 87300 (7.03086 iter/s, 14.223s/100 iters), loss = 0.00170704
I0928 13:09:35.113018  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0017072 (* 1 = 0.0017072 loss)
I0928 13:09:35.113034  4247 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I0928 13:09:49.335650  4247 solver.cpp:218] Iteration 87400 (7.03107 iter/s, 14.2226s/100 iters), loss = 0.00541229
I0928 13:09:49.335681  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00541245 (* 1 = 0.00541245 loss)
I0928 13:09:49.335698  4247 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I0928 13:10:02.850827  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:10:03.420244  4247 solver.cpp:330] Iteration 87500, Testing net (#0)
I0928 13:10:06.776551  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:10:06.917006  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9288
I0928 13:10:06.917042  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311412 (* 1 = 0.311412 loss)
I0928 13:10:07.059047  4247 solver.cpp:218] Iteration 87500 (5.64228 iter/s, 17.7233s/100 iters), loss = 0.00144858
I0928 13:10:07.059077  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00144874 (* 1 = 0.00144874 loss)
I0928 13:10:07.059084  4247 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I0928 13:10:21.271919  4247 solver.cpp:218] Iteration 87600 (7.03591 iter/s, 14.2128s/100 iters), loss = 0.00251241
I0928 13:10:21.271951  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00251256 (* 1 = 0.00251256 loss)
I0928 13:10:21.271967  4247 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I0928 13:10:35.489241  4247 solver.cpp:218] Iteration 87700 (7.03371 iter/s, 14.2172s/100 iters), loss = 0.00104074
I0928 13:10:35.489322  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010409 (* 1 = 0.0010409 loss)
I0928 13:10:35.489341  4247 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I0928 13:10:49.706266  4247 solver.cpp:218] Iteration 87800 (7.03388 iter/s, 14.2169s/100 iters), loss = 0.000432356
I0928 13:10:49.706297  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000432516 (* 1 = 0.000432516 loss)
I0928 13:10:49.706313  4247 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I0928 13:11:03.920469  4247 solver.cpp:218] Iteration 87900 (7.03525 iter/s, 14.2141s/100 iters), loss = 0.00163627
I0928 13:11:03.920501  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00163643 (* 1 = 0.00163643 loss)
I0928 13:11:03.920507  4247 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I0928 13:11:17.429630  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:11:17.998352  4247 solver.cpp:330] Iteration 88000, Testing net (#0)
I0928 13:11:21.355751  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:11:21.495949  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9292
I0928 13:11:21.495985  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309352 (* 1 = 0.309352 loss)
I0928 13:11:21.637410  4247 solver.cpp:218] Iteration 88000 (5.64434 iter/s, 17.7169s/100 iters), loss = 0.000457694
I0928 13:11:21.637439  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000457852 (* 1 = 0.000457852 loss)
I0928 13:11:21.637446  4247 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I0928 13:11:35.858546  4247 solver.cpp:218] Iteration 88100 (7.03182 iter/s, 14.2211s/100 iters), loss = 0.000631153
I0928 13:11:35.858577  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000631311 (* 1 = 0.000631311 loss)
I0928 13:11:35.858583  4247 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I0928 13:11:50.080471  4247 solver.cpp:218] Iteration 88200 (7.03143 iter/s, 14.2219s/100 iters), loss = 0.000656513
I0928 13:11:50.080611  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00065667 (* 1 = 0.00065667 loss)
I0928 13:11:50.080620  4247 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I0928 13:12:04.306203  4247 solver.cpp:218] Iteration 88300 (7.0296 iter/s, 14.2256s/100 iters), loss = 0.000571776
I0928 13:12:04.306246  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000571931 (* 1 = 0.000571931 loss)
I0928 13:12:04.306253  4247 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I0928 13:12:18.525326  4247 solver.cpp:218] Iteration 88400 (7.03282 iter/s, 14.219s/100 iters), loss = 0.00420164
I0928 13:12:18.525367  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00420179 (* 1 = 0.00420179 loss)
I0928 13:12:18.525373  4247 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I0928 13:12:32.040586  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:12:32.609869  4247 solver.cpp:330] Iteration 88500, Testing net (#0)
I0928 13:12:35.967681  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:12:36.108391  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9287
I0928 13:12:36.108417  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308704 (* 1 = 0.308704 loss)
I0928 13:12:36.249222  4247 solver.cpp:218] Iteration 88500 (5.64213 iter/s, 17.7238s/100 iters), loss = 0.000392018
I0928 13:12:36.249250  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000392174 (* 1 = 0.000392174 loss)
I0928 13:12:36.249258  4247 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I0928 13:12:50.475226  4247 solver.cpp:218] Iteration 88600 (7.02942 iter/s, 14.2259s/100 iters), loss = 0.000948242
I0928 13:12:50.475270  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000948398 (* 1 = 0.000948398 loss)
I0928 13:12:50.475275  4247 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I0928 13:13:04.707589  4247 solver.cpp:218] Iteration 88700 (7.02628 iter/s, 14.2323s/100 iters), loss = 0.000855495
I0928 13:13:04.707692  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000855652 (* 1 = 0.000855652 loss)
I0928 13:13:04.707710  4247 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I0928 13:13:18.941447  4247 solver.cpp:218] Iteration 88800 (7.02557 iter/s, 14.2337s/100 iters), loss = 0.000789862
I0928 13:13:18.941489  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000790019 (* 1 = 0.000790019 loss)
I0928 13:13:18.941495  4247 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I0928 13:13:33.174798  4247 solver.cpp:218] Iteration 88900 (7.02579 iter/s, 14.2333s/100 iters), loss = 0.000507044
I0928 13:13:33.174839  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000507201 (* 1 = 0.000507201 loss)
I0928 13:13:33.174845  4247 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I0928 13:13:46.700230  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:13:47.269831  4247 solver.cpp:330] Iteration 89000, Testing net (#0)
I0928 13:13:50.626329  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:13:50.766649  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.929
I0928 13:13:50.766686  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312474 (* 1 = 0.312474 loss)
I0928 13:13:50.908287  4247 solver.cpp:218] Iteration 89000 (5.63908 iter/s, 17.7334s/100 iters), loss = 0.00181588
I0928 13:13:50.908316  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00181604 (* 1 = 0.00181604 loss)
I0928 13:13:50.908324  4247 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I0928 13:14:05.124754  4247 solver.cpp:218] Iteration 89100 (7.03413 iter/s, 14.2164s/100 iters), loss = 0.00114058
I0928 13:14:05.124796  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00114074 (* 1 = 0.00114074 loss)
I0928 13:14:05.124802  4247 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I0928 13:14:19.348498  4247 solver.cpp:218] Iteration 89200 (7.03054 iter/s, 14.2237s/100 iters), loss = 0.00125405
I0928 13:14:19.348624  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0012542 (* 1 = 0.0012542 loss)
I0928 13:14:19.348631  4247 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I0928 13:14:33.567262  4247 solver.cpp:218] Iteration 89300 (7.03304 iter/s, 14.2186s/100 iters), loss = 0.000663899
I0928 13:14:33.567293  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000664053 (* 1 = 0.000664053 loss)
I0928 13:14:33.567301  4247 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I0928 13:14:47.784956  4247 solver.cpp:218] Iteration 89400 (7.03353 iter/s, 14.2176s/100 iters), loss = 0.00130902
I0928 13:14:47.784988  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00130917 (* 1 = 0.00130917 loss)
I0928 13:14:47.785006  4247 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I0928 13:15:01.297214  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:15:01.865896  4247 solver.cpp:330] Iteration 89500, Testing net (#0)
I0928 13:15:05.221777  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:15:05.362438  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9289
I0928 13:15:05.362464  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310808 (* 1 = 0.310808 loss)
I0928 13:15:05.503754  4247 solver.cpp:218] Iteration 89500 (5.64375 iter/s, 17.7187s/100 iters), loss = 0.000890857
I0928 13:15:05.503783  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000891011 (* 1 = 0.000891011 loss)
I0928 13:15:05.503800  4247 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I0928 13:15:19.727792  4247 solver.cpp:218] Iteration 89600 (7.03039 iter/s, 14.224s/100 iters), loss = 0.0013421
I0928 13:15:19.727823  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00134225 (* 1 = 0.00134225 loss)
I0928 13:15:19.727829  4247 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I0928 13:15:33.950855  4247 solver.cpp:218] Iteration 89700 (7.03087 iter/s, 14.223s/100 iters), loss = 0.000544456
I0928 13:15:33.950994  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000544612 (* 1 = 0.000544612 loss)
I0928 13:15:33.951012  4247 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I0928 13:15:48.177454  4247 solver.cpp:218] Iteration 89800 (7.02917 iter/s, 14.2264s/100 iters), loss = 0.000775392
I0928 13:15:48.177496  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000775547 (* 1 = 0.000775547 loss)
I0928 13:15:48.177502  4247 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I0928 13:16:02.411680  4247 solver.cpp:218] Iteration 89900 (7.02536 iter/s, 14.2341s/100 iters), loss = 0.000396932
I0928 13:16:02.411722  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000397087 (* 1 = 0.000397087 loss)
I0928 13:16:02.411728  4247 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I0928 13:16:15.932931  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:16:16.502979  4247 solver.cpp:330] Iteration 90000, Testing net (#0)
I0928 13:16:19.858566  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:16:19.998890  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.929
I0928 13:16:19.998927  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310375 (* 1 = 0.310375 loss)
I0928 13:16:20.139951  4247 solver.cpp:218] Iteration 90000 (5.64074 iter/s, 17.7282s/100 iters), loss = 0.00063091
I0928 13:16:20.139981  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000631065 (* 1 = 0.000631065 loss)
I0928 13:16:20.139986  4247 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I0928 13:16:34.352463  4247 solver.cpp:218] Iteration 90100 (7.03609 iter/s, 14.2124s/100 iters), loss = 0.000720599
I0928 13:16:34.352505  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000720754 (* 1 = 0.000720754 loss)
I0928 13:16:34.352511  4247 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I0928 13:16:48.569113  4247 solver.cpp:218] Iteration 90200 (7.03405 iter/s, 14.2166s/100 iters), loss = 0.000493444
I0928 13:16:48.569196  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0004936 (* 1 = 0.0004936 loss)
I0928 13:16:48.569212  4247 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I0928 13:17:02.785948  4247 solver.cpp:218] Iteration 90300 (7.03397 iter/s, 14.2167s/100 iters), loss = 0.000285194
I0928 13:17:02.785990  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000285349 (* 1 = 0.000285349 loss)
I0928 13:17:02.785996  4247 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I0928 13:17:16.998945  4247 solver.cpp:218] Iteration 90400 (7.03585 iter/s, 14.2129s/100 iters), loss = 0.0109813
I0928 13:17:16.998988  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109815 (* 1 = 0.0109815 loss)
I0928 13:17:16.998993  4247 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I0928 13:17:30.508944  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:17:31.077234  4247 solver.cpp:330] Iteration 90500, Testing net (#0)
I0928 13:17:34.433730  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:17:34.574581  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9297
I0928 13:17:34.574618  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309313 (* 1 = 0.309313 loss)
I0928 13:17:34.714917  4247 solver.cpp:218] Iteration 90500 (5.64465 iter/s, 17.7159s/100 iters), loss = 0.000826359
I0928 13:17:34.714946  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000826514 (* 1 = 0.000826514 loss)
I0928 13:17:34.714952  4247 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I0928 13:17:48.939343  4247 solver.cpp:218] Iteration 90600 (7.03019 iter/s, 14.2244s/100 iters), loss = 0.00678422
I0928 13:17:48.939385  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00678438 (* 1 = 0.00678438 loss)
I0928 13:17:48.939393  4247 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I0928 13:18:03.172235  4247 solver.cpp:218] Iteration 90700 (7.02602 iter/s, 14.2328s/100 iters), loss = 0.00107831
I0928 13:18:03.172356  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00107846 (* 1 = 0.00107846 loss)
I0928 13:18:03.172364  4247 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I0928 13:18:17.399013  4247 solver.cpp:218] Iteration 90800 (7.02907 iter/s, 14.2266s/100 iters), loss = 0.00080681
I0928 13:18:17.399044  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000806965 (* 1 = 0.000806965 loss)
I0928 13:18:17.399050  4247 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I0928 13:18:31.625735  4247 solver.cpp:218] Iteration 90900 (7.02906 iter/s, 14.2266s/100 iters), loss = 0.000791045
I0928 13:18:31.625766  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000791199 (* 1 = 0.000791199 loss)
I0928 13:18:31.625782  4247 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I0928 13:18:45.147471  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:18:45.717288  4247 solver.cpp:330] Iteration 91000, Testing net (#0)
I0928 13:18:49.072983  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:18:49.213208  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9288
I0928 13:18:49.213245  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309778 (* 1 = 0.309778 loss)
I0928 13:18:49.354106  4247 solver.cpp:218] Iteration 91000 (5.6407 iter/s, 17.7283s/100 iters), loss = 0.000758583
I0928 13:18:49.354136  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000758738 (* 1 = 0.000758738 loss)
I0928 13:18:49.354142  4247 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I0928 13:19:03.572275  4247 solver.cpp:218] Iteration 91100 (7.03329 iter/s, 14.2181s/100 iters), loss = 0.000410992
I0928 13:19:03.572306  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000411147 (* 1 = 0.000411147 loss)
I0928 13:19:03.572312  4247 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I0928 13:19:17.796548  4247 solver.cpp:218] Iteration 91200 (7.03027 iter/s, 14.2242s/100 iters), loss = 0.00170311
I0928 13:19:17.796677  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00170326 (* 1 = 0.00170326 loss)
I0928 13:19:17.796684  4247 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I0928 13:19:32.018393  4247 solver.cpp:218] Iteration 91300 (7.03152 iter/s, 14.2217s/100 iters), loss = 0.000957492
I0928 13:19:32.018435  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000957648 (* 1 = 0.000957648 loss)
I0928 13:19:32.018440  4247 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I0928 13:19:46.243046  4247 solver.cpp:218] Iteration 91400 (7.03009 iter/s, 14.2246s/100 iters), loss = 0.00065962
I0928 13:19:46.243077  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000659777 (* 1 = 0.000659777 loss)
I0928 13:19:46.243083  4247 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I0928 13:19:59.757632  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:20:00.329049  4247 solver.cpp:330] Iteration 91500, Testing net (#0)
I0928 13:20:03.683830  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:20:03.824594  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9286
I0928 13:20:03.824632  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311976 (* 1 = 0.311976 loss)
I0928 13:20:03.965538  4247 solver.cpp:218] Iteration 91500 (5.64257 iter/s, 17.7224s/100 iters), loss = 0.00119574
I0928 13:20:03.965566  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00119589 (* 1 = 0.00119589 loss)
I0928 13:20:03.965574  4247 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I0928 13:20:18.177860  4247 solver.cpp:218] Iteration 91600 (7.03619 iter/s, 14.2122s/100 iters), loss = 0.00388347
I0928 13:20:18.177901  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00388362 (* 1 = 0.00388362 loss)
I0928 13:20:18.177906  4247 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I0928 13:20:32.398337  4247 solver.cpp:218] Iteration 91700 (7.03215 iter/s, 14.2204s/100 iters), loss = 0.00246575
I0928 13:20:32.398434  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00246591 (* 1 = 0.00246591 loss)
I0928 13:20:32.398442  4247 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I0928 13:20:46.612149  4247 solver.cpp:218] Iteration 91800 (7.03548 iter/s, 14.2137s/100 iters), loss = 0.000688776
I0928 13:20:46.612179  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000688933 (* 1 = 0.000688933 loss)
I0928 13:20:46.612185  4247 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I0928 13:21:00.831787  4247 solver.cpp:218] Iteration 91900 (7.03256 iter/s, 14.2196s/100 iters), loss = 0.00125604
I0928 13:21:00.831830  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0012562 (* 1 = 0.0012562 loss)
I0928 13:21:00.831835  4247 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I0928 13:21:14.338802  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:21:14.909508  4247 solver.cpp:330] Iteration 92000, Testing net (#0)
I0928 13:21:18.265298  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:21:18.405494  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9279
I0928 13:21:18.405531  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311874 (* 1 = 0.311874 loss)
I0928 13:21:18.546464  4247 solver.cpp:218] Iteration 92000 (5.64507 iter/s, 17.7146s/100 iters), loss = 0.000373968
I0928 13:21:18.546494  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000374125 (* 1 = 0.000374125 loss)
I0928 13:21:18.546501  4247 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I0928 13:21:32.767957  4247 solver.cpp:218] Iteration 92100 (7.03165 iter/s, 14.2214s/100 iters), loss = 0.00012933
I0928 13:21:32.767999  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000129488 (* 1 = 0.000129488 loss)
I0928 13:21:32.768007  4247 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I0928 13:21:46.988005  4247 solver.cpp:218] Iteration 92200 (7.03237 iter/s, 14.22s/100 iters), loss = 0.00112859
I0928 13:21:46.988080  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00112875 (* 1 = 0.00112875 loss)
I0928 13:21:46.988097  4247 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I0928 13:22:01.210086  4247 solver.cpp:218] Iteration 92300 (7.03138 iter/s, 14.222s/100 iters), loss = 0.000642768
I0928 13:22:01.210117  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000642927 (* 1 = 0.000642927 loss)
I0928 13:22:01.210124  4247 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I0928 13:22:15.433365  4247 solver.cpp:218] Iteration 92400 (7.03076 iter/s, 14.2232s/100 iters), loss = 0.000883254
I0928 13:22:15.433408  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000883412 (* 1 = 0.000883412 loss)
I0928 13:22:15.433413  4247 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I0928 13:22:28.945111  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:22:29.513823  4247 solver.cpp:330] Iteration 92500, Testing net (#0)
I0928 13:22:32.872390  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:22:33.012917  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9285
I0928 13:22:33.012954  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311741 (* 1 = 0.311741 loss)
I0928 13:22:33.154073  4247 solver.cpp:218] Iteration 92500 (5.64314 iter/s, 17.7206s/100 iters), loss = 0.000949721
I0928 13:22:33.154103  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000949878 (* 1 = 0.000949878 loss)
I0928 13:22:33.154110  4247 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I0928 13:22:47.365238  4247 solver.cpp:218] Iteration 92600 (7.03675 iter/s, 14.2111s/100 iters), loss = 0.000501275
I0928 13:22:47.365268  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000501432 (* 1 = 0.000501432 loss)
I0928 13:22:47.365274  4247 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I0928 13:23:01.583797  4247 solver.cpp:218] Iteration 92700 (7.0331 iter/s, 14.2185s/100 iters), loss = 0.00107691
I0928 13:23:01.583894  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00107707 (* 1 = 0.00107707 loss)
I0928 13:23:01.583900  4247 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I0928 13:23:15.804778  4247 solver.cpp:218] Iteration 92800 (7.03193 iter/s, 14.2208s/100 iters), loss = 0.0010404
I0928 13:23:15.804821  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00104055 (* 1 = 0.00104055 loss)
I0928 13:23:15.804827  4247 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I0928 13:23:30.018602  4247 solver.cpp:218] Iteration 92900 (7.03545 iter/s, 14.2137s/100 iters), loss = 0.00256551
I0928 13:23:30.018636  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00256566 (* 1 = 0.00256566 loss)
I0928 13:23:30.018643  4247 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I0928 13:23:43.527350  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:23:44.096976  4247 solver.cpp:330] Iteration 93000, Testing net (#0)
I0928 13:23:47.453595  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:23:47.594048  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9286
I0928 13:23:47.594085  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311109 (* 1 = 0.311109 loss)
I0928 13:23:47.735177  4247 solver.cpp:218] Iteration 93000 (5.64446 iter/s, 17.7165s/100 iters), loss = 0.000333093
I0928 13:23:47.735205  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000333247 (* 1 = 0.000333247 loss)
I0928 13:23:47.735222  4247 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I0928 13:24:01.958119  4247 solver.cpp:218] Iteration 93100 (7.03093 iter/s, 14.2229s/100 iters), loss = 0.00131155
I0928 13:24:01.958161  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0013117 (* 1 = 0.0013117 loss)
I0928 13:24:01.958168  4247 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I0928 13:24:16.183359  4247 solver.cpp:218] Iteration 93200 (7.0298 iter/s, 14.2252s/100 iters), loss = 0.000919934
I0928 13:24:16.183436  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000920088 (* 1 = 0.000920088 loss)
I0928 13:24:16.183442  4247 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I0928 13:24:30.412164  4247 solver.cpp:218] Iteration 93300 (7.02805 iter/s, 14.2287s/100 iters), loss = 0.000303332
I0928 13:24:30.412205  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000303484 (* 1 = 0.000303484 loss)
I0928 13:24:30.412211  4247 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I0928 13:24:44.634073  4247 solver.cpp:218] Iteration 93400 (7.03145 iter/s, 14.2218s/100 iters), loss = 0.00164294
I0928 13:24:44.634115  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00164309 (* 1 = 0.00164309 loss)
I0928 13:24:44.634121  4247 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I0928 13:24:58.154314  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:24:58.722723  4247 solver.cpp:330] Iteration 93500, Testing net (#0)
I0928 13:25:02.080432  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:25:02.221256  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9283
I0928 13:25:02.221292  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310814 (* 1 = 0.310814 loss)
I0928 13:25:02.361784  4247 solver.cpp:218] Iteration 93500 (5.64091 iter/s, 17.7276s/100 iters), loss = 0.000641522
I0928 13:25:02.361811  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000641674 (* 1 = 0.000641674 loss)
I0928 13:25:02.361819  4247 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I0928 13:25:16.590761  4247 solver.cpp:218] Iteration 93600 (7.02795 iter/s, 14.2289s/100 iters), loss = 0.000259725
I0928 13:25:16.590803  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000259877 (* 1 = 0.000259877 loss)
I0928 13:25:16.590809  4247 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I0928 13:25:30.825253  4247 solver.cpp:218] Iteration 93700 (7.02523 iter/s, 14.2344s/100 iters), loss = 0.000624654
I0928 13:25:30.825412  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000624808 (* 1 = 0.000624808 loss)
I0928 13:25:30.825418  4247 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I0928 13:25:45.060292  4247 solver.cpp:218] Iteration 93800 (7.02502 iter/s, 14.2348s/100 iters), loss = 0.000489519
I0928 13:25:45.060334  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000489672 (* 1 = 0.000489672 loss)
I0928 13:25:45.060340  4247 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I0928 13:25:59.296746  4247 solver.cpp:218] Iteration 93900 (7.02426 iter/s, 14.2364s/100 iters), loss = 0.000367781
I0928 13:25:59.296788  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000367934 (* 1 = 0.000367934 loss)
I0928 13:25:59.296794  4247 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I0928 13:26:12.825459  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:26:13.395782  4247 solver.cpp:330] Iteration 94000, Testing net (#0)
I0928 13:26:16.752821  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:26:16.893259  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9287
I0928 13:26:16.893285  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310148 (* 1 = 0.310148 loss)
I0928 13:26:17.034235  4247 solver.cpp:218] Iteration 94000 (5.63781 iter/s, 17.7374s/100 iters), loss = 0.000271121
I0928 13:26:17.034265  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000271275 (* 1 = 0.000271275 loss)
I0928 13:26:17.034271  4247 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I0928 13:26:31.251118  4247 solver.cpp:218] Iteration 94100 (7.03393 iter/s, 14.2168s/100 iters), loss = 0.000403838
I0928 13:26:31.251160  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000403992 (* 1 = 0.000403992 loss)
I0928 13:26:31.251166  4247 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I0928 13:26:45.472393  4247 solver.cpp:218] Iteration 94200 (7.03176 iter/s, 14.2212s/100 iters), loss = 0.00154074
I0928 13:26:45.472465  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0015409 (* 1 = 0.0015409 loss)
I0928 13:26:45.472482  4247 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I0928 13:26:59.688990  4247 solver.cpp:218] Iteration 94300 (7.03409 iter/s, 14.2165s/100 iters), loss = 0.000417035
I0928 13:26:59.689033  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000417191 (* 1 = 0.000417191 loss)
I0928 13:26:59.689039  4247 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I0928 13:27:13.906497  4247 solver.cpp:218] Iteration 94400 (7.03362 iter/s, 14.2174s/100 iters), loss = 0.000552325
I0928 13:27:13.906541  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000552481 (* 1 = 0.000552481 loss)
I0928 13:27:13.906548  4247 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I0928 13:27:27.421895  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:27:27.991683  4247 solver.cpp:330] Iteration 94500, Testing net (#0)
I0928 13:27:31.348249  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:27:31.488734  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9289
I0928 13:27:31.488761  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310225 (* 1 = 0.310225 loss)
I0928 13:27:31.630132  4247 solver.cpp:218] Iteration 94500 (5.64221 iter/s, 17.7235s/100 iters), loss = 0.000615286
I0928 13:27:31.630162  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000615441 (* 1 = 0.000615441 loss)
I0928 13:27:31.630169  4247 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I0928 13:27:45.855448  4247 solver.cpp:218] Iteration 94600 (7.02975 iter/s, 14.2252s/100 iters), loss = 0.00188367
I0928 13:27:45.855479  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188383 (* 1 = 0.00188383 loss)
I0928 13:27:45.855484  4247 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I0928 13:28:00.079195  4247 solver.cpp:218] Iteration 94700 (7.03053 iter/s, 14.2237s/100 iters), loss = 0.000501599
I0928 13:28:00.079310  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000501755 (* 1 = 0.000501755 loss)
I0928 13:28:00.079326  4247 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I0928 13:28:14.302510  4247 solver.cpp:218] Iteration 94800 (7.03079 iter/s, 14.2232s/100 iters), loss = 0.00104994
I0928 13:28:14.302553  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010501 (* 1 = 0.0010501 loss)
I0928 13:28:14.302559  4247 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I0928 13:28:28.527485  4247 solver.cpp:218] Iteration 94900 (7.02993 iter/s, 14.2249s/100 iters), loss = 0.000318322
I0928 13:28:28.527518  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000318477 (* 1 = 0.000318477 loss)
I0928 13:28:28.527523  4247 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I0928 13:28:42.051635  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:28:42.621687  4247 solver.cpp:330] Iteration 95000, Testing net (#0)
I0928 13:28:45.979564  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:28:46.119745  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9291
I0928 13:28:46.119781  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311177 (* 1 = 0.311177 loss)
I0928 13:28:46.261168  4247 solver.cpp:218] Iteration 95000 (5.63901 iter/s, 17.7336s/100 iters), loss = 0.000488515
I0928 13:28:46.261198  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000488669 (* 1 = 0.000488669 loss)
I0928 13:28:46.261204  4247 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I0928 13:29:00.482141  4247 solver.cpp:218] Iteration 95100 (7.0319 iter/s, 14.2209s/100 iters), loss = 0.00059608
I0928 13:29:00.482173  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000596234 (* 1 = 0.000596234 loss)
I0928 13:29:00.482179  4247 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I0928 13:29:14.703433  4247 solver.cpp:218] Iteration 95200 (7.03175 iter/s, 14.2212s/100 iters), loss = 0.000567228
I0928 13:29:14.703554  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000567382 (* 1 = 0.000567382 loss)
I0928 13:29:14.703562  4247 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I0928 13:29:28.923913  4247 solver.cpp:218] Iteration 95300 (7.03219 iter/s, 14.2203s/100 iters), loss = 0.000344078
I0928 13:29:28.923954  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000344233 (* 1 = 0.000344233 loss)
I0928 13:29:28.923960  4247 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I0928 13:29:43.144143  4247 solver.cpp:218] Iteration 95400 (7.03228 iter/s, 14.2201s/100 iters), loss = 0.000694051
I0928 13:29:43.144174  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000694205 (* 1 = 0.000694205 loss)
I0928 13:29:43.144181  4247 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I0928 13:29:56.652289  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:29:57.221624  4247 solver.cpp:330] Iteration 95500, Testing net (#0)
I0928 13:30:00.580868  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:30:00.721230  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9288
I0928 13:30:00.721266  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311257 (* 1 = 0.311257 loss)
I0928 13:30:00.862392  4247 solver.cpp:218] Iteration 95500 (5.64392 iter/s, 17.7182s/100 iters), loss = 0.00102441
I0928 13:30:00.862422  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102457 (* 1 = 0.00102457 loss)
I0928 13:30:00.862429  4247 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I0928 13:30:15.083530  4247 solver.cpp:218] Iteration 95600 (7.03182 iter/s, 14.2211s/100 iters), loss = 0.00155745
I0928 13:30:15.083572  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00155761 (* 1 = 0.00155761 loss)
I0928 13:30:15.083578  4247 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I0928 13:30:29.304580  4247 solver.cpp:218] Iteration 95700 (7.03187 iter/s, 14.221s/100 iters), loss = 0.000870135
I0928 13:30:29.304673  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000870288 (* 1 = 0.000870288 loss)
I0928 13:30:29.304680  4247 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I0928 13:30:43.529212  4247 solver.cpp:218] Iteration 95800 (7.03012 iter/s, 14.2245s/100 iters), loss = 0.00057711
I0928 13:30:43.529253  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000577264 (* 1 = 0.000577264 loss)
I0928 13:30:43.529259  4247 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I0928 13:30:57.751164  4247 solver.cpp:218] Iteration 95900 (7.03143 iter/s, 14.2219s/100 iters), loss = 0.00113282
I0928 13:30:57.751196  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00113297 (* 1 = 0.00113297 loss)
I0928 13:30:57.751202  4247 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I0928 13:31:11.269176  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:31:11.838358  4247 solver.cpp:330] Iteration 96000, Testing net (#0)
I0928 13:31:15.194881  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:31:15.335383  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9292
I0928 13:31:15.335410  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312045 (* 1 = 0.312045 loss)
I0928 13:31:15.476160  4247 solver.cpp:218] Iteration 96000 (5.64178 iter/s, 17.7249s/100 iters), loss = 0.000448758
I0928 13:31:15.476188  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000448913 (* 1 = 0.000448913 loss)
I0928 13:31:15.476196  4247 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I0928 13:31:29.688846  4247 solver.cpp:218] Iteration 96100 (7.036 iter/s, 14.2126s/100 iters), loss = 0.0014382
I0928 13:31:29.688889  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00143835 (* 1 = 0.00143835 loss)
I0928 13:31:29.688895  4247 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I0928 13:31:43.905407  4247 solver.cpp:218] Iteration 96200 (7.03409 iter/s, 14.2165s/100 iters), loss = 0.000490136
I0928 13:31:43.905532  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000490288 (* 1 = 0.000490288 loss)
I0928 13:31:43.905539  4247 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I0928 13:31:58.125594  4247 solver.cpp:218] Iteration 96300 (7.03234 iter/s, 14.22s/100 iters), loss = 0.00103621
I0928 13:31:58.125638  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103636 (* 1 = 0.00103636 loss)
I0928 13:31:58.125643  4247 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I0928 13:32:12.342242  4247 solver.cpp:218] Iteration 96400 (7.03405 iter/s, 14.2166s/100 iters), loss = 0.00252769
I0928 13:32:12.342283  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00252785 (* 1 = 0.00252785 loss)
I0928 13:32:12.342288  4247 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I0928 13:32:25.857614  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:32:26.426141  4247 solver.cpp:330] Iteration 96500, Testing net (#0)
I0928 13:32:29.782184  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:32:29.922312  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9293
I0928 13:32:29.922349  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310149 (* 1 = 0.310149 loss)
I0928 13:32:30.063599  4247 solver.cpp:218] Iteration 96500 (5.64294 iter/s, 17.7213s/100 iters), loss = 0.00114487
I0928 13:32:30.063628  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00114502 (* 1 = 0.00114502 loss)
I0928 13:32:30.063635  4247 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I0928 13:32:44.271131  4247 solver.cpp:218] Iteration 96600 (7.03856 iter/s, 14.2075s/100 iters), loss = 0.000261977
I0928 13:32:44.271169  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000262129 (* 1 = 0.000262129 loss)
I0928 13:32:44.271176  4247 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I0928 13:32:58.486166  4247 solver.cpp:218] Iteration 96700 (7.03484 iter/s, 14.215s/100 iters), loss = 0.00083436
I0928 13:32:58.486227  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000834513 (* 1 = 0.000834513 loss)
I0928 13:32:58.486234  4247 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I0928 13:33:12.704619  4247 solver.cpp:218] Iteration 96800 (7.03316 iter/s, 14.2184s/100 iters), loss = 0.0015245
I0928 13:33:12.704651  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00152466 (* 1 = 0.00152466 loss)
I0928 13:33:12.704668  4247 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I0928 13:33:26.921943  4247 solver.cpp:218] Iteration 96900 (7.03371 iter/s, 14.2172s/100 iters), loss = 0.000360334
I0928 13:33:26.921974  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000360486 (* 1 = 0.000360486 loss)
I0928 13:33:26.921980  4247 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I0928 13:33:40.434268  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:33:41.005652  4247 solver.cpp:330] Iteration 97000, Testing net (#0)
I0928 13:33:44.361870  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:33:44.502288  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9286
I0928 13:33:44.502324  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31105 (* 1 = 0.31105 loss)
I0928 13:33:44.643116  4247 solver.cpp:218] Iteration 97000 (5.64299 iter/s, 17.7211s/100 iters), loss = 0.00179763
I0928 13:33:44.643146  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00179779 (* 1 = 0.00179779 loss)
I0928 13:33:44.643152  4247 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I0928 13:33:58.859241  4247 solver.cpp:218] Iteration 97100 (7.0343 iter/s, 14.2161s/100 iters), loss = 0.00172384
I0928 13:33:58.859272  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00172399 (* 1 = 0.00172399 loss)
I0928 13:33:58.859277  4247 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I0928 13:34:13.080783  4247 solver.cpp:218] Iteration 97200 (7.03162 iter/s, 14.2215s/100 iters), loss = 0.00213678
I0928 13:34:13.080896  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00213694 (* 1 = 0.00213694 loss)
I0928 13:34:13.080905  4247 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I0928 13:34:27.306030  4247 solver.cpp:218] Iteration 97300 (7.02983 iter/s, 14.2251s/100 iters), loss = 0.000982628
I0928 13:34:27.306062  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000982782 (* 1 = 0.000982782 loss)
I0928 13:34:27.306068  4247 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I0928 13:34:41.529667  4247 solver.cpp:218] Iteration 97400 (7.03059 iter/s, 14.2236s/100 iters), loss = 0.000736367
I0928 13:34:41.529700  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000736521 (* 1 = 0.000736521 loss)
I0928 13:34:41.529706  4247 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I0928 13:34:55.045125  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:34:55.614745  4247 solver.cpp:330] Iteration 97500, Testing net (#0)
I0928 13:34:58.971442  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:34:59.111624  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9292
I0928 13:34:59.111661  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309829 (* 1 = 0.309829 loss)
I0928 13:34:59.253139  4247 solver.cpp:218] Iteration 97500 (5.64226 iter/s, 17.7234s/100 iters), loss = 0.000872656
I0928 13:34:59.253168  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00087281 (* 1 = 0.00087281 loss)
I0928 13:34:59.253175  4247 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I0928 13:35:13.474613  4247 solver.cpp:218] Iteration 97600 (7.03165 iter/s, 14.2214s/100 iters), loss = 0.00149923
I0928 13:35:13.474655  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00149939 (* 1 = 0.00149939 loss)
I0928 13:35:13.474661  4247 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I0928 13:35:27.693701  4247 solver.cpp:218] Iteration 97700 (7.03284 iter/s, 14.219s/100 iters), loss = 0.000803543
I0928 13:35:27.693785  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000803697 (* 1 = 0.000803697 loss)
I0928 13:35:27.693802  4247 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I0928 13:35:41.912858  4247 solver.cpp:218] Iteration 97800 (7.03283 iter/s, 14.219s/100 iters), loss = 0.00101748
I0928 13:35:41.912900  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00101763 (* 1 = 0.00101763 loss)
I0928 13:35:41.912906  4247 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I0928 13:35:56.128608  4247 solver.cpp:218] Iteration 97900 (7.03449 iter/s, 14.2157s/100 iters), loss = 0.00045602
I0928 13:35:56.128639  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000456174 (* 1 = 0.000456174 loss)
I0928 13:35:56.128645  4247 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I0928 13:36:09.646914  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:36:10.215610  4247 solver.cpp:330] Iteration 98000, Testing net (#0)
I0928 13:36:13.573565  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:36:13.713876  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9292
I0928 13:36:13.713904  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310392 (* 1 = 0.310392 loss)
I0928 13:36:13.854763  4247 solver.cpp:218] Iteration 98000 (5.64141 iter/s, 17.7261s/100 iters), loss = 0.000491569
I0928 13:36:13.854801  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000491723 (* 1 = 0.000491723 loss)
I0928 13:36:13.854809  4247 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I0928 13:36:28.078333  4247 solver.cpp:218] Iteration 98100 (7.03063 iter/s, 14.2235s/100 iters), loss = 0.000748836
I0928 13:36:28.078366  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00074899 (* 1 = 0.00074899 loss)
I0928 13:36:28.078372  4247 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I0928 13:36:42.369760  4247 solver.cpp:218] Iteration 98200 (6.99724 iter/s, 14.2913s/100 iters), loss = 0.0010938
I0928 13:36:42.369904  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00109395 (* 1 = 0.00109395 loss)
I0928 13:36:42.369911  4247 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I0928 13:36:56.687736  4247 solver.cpp:218] Iteration 98300 (6.98432 iter/s, 14.3178s/100 iters), loss = 0.000236949
I0928 13:36:56.687772  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000237102 (* 1 = 0.000237102 loss)
I0928 13:36:56.687778  4247 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I0928 13:37:11.000586  4247 solver.cpp:218] Iteration 98400 (6.98677 iter/s, 14.3128s/100 iters), loss = 0.000664749
I0928 13:37:11.000617  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000664902 (* 1 = 0.000664902 loss)
I0928 13:37:11.000623  4247 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I0928 13:37:24.513696  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:37:25.083343  4247 solver.cpp:330] Iteration 98500, Testing net (#0)
I0928 13:37:28.440829  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:37:28.581032  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.929
I0928 13:37:28.581059  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310792 (* 1 = 0.310792 loss)
I0928 13:37:28.722028  4247 solver.cpp:218] Iteration 98500 (5.64291 iter/s, 17.7214s/100 iters), loss = 0.000831505
I0928 13:37:28.722059  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000831658 (* 1 = 0.000831658 loss)
I0928 13:37:28.722065  4247 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I0928 13:37:42.946161  4247 solver.cpp:218] Iteration 98600 (7.03034 iter/s, 14.2241s/100 iters), loss = 0.00119125
I0928 13:37:42.946195  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00119141 (* 1 = 0.00119141 loss)
I0928 13:37:42.946202  4247 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I0928 13:37:57.171914  4247 solver.cpp:218] Iteration 98700 (7.02954 iter/s, 14.2257s/100 iters), loss = 0.000822571
I0928 13:37:57.172003  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000822723 (* 1 = 0.000822723 loss)
I0928 13:37:57.172009  4247 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I0928 13:38:11.400101  4247 solver.cpp:218] Iteration 98800 (7.02836 iter/s, 14.2281s/100 iters), loss = 0.000755156
I0928 13:38:11.400143  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000755309 (* 1 = 0.000755309 loss)
I0928 13:38:11.400149  4247 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I0928 13:38:25.630437  4247 solver.cpp:218] Iteration 98900 (7.02728 iter/s, 14.2303s/100 iters), loss = 0.000917868
I0928 13:38:25.630479  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000918021 (* 1 = 0.000918021 loss)
I0928 13:38:25.630486  4247 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I0928 13:38:39.146402  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:38:39.715761  4247 solver.cpp:330] Iteration 99000, Testing net (#0)
I0928 13:38:43.073417  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:38:43.213879  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9291
I0928 13:38:43.213917  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309947 (* 1 = 0.309947 loss)
I0928 13:38:43.355079  4247 solver.cpp:218] Iteration 99000 (5.64189 iter/s, 17.7245s/100 iters), loss = 0.000809047
I0928 13:38:43.355108  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000809199 (* 1 = 0.000809199 loss)
I0928 13:38:43.355115  4247 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I0928 13:38:57.651521  4247 solver.cpp:218] Iteration 99100 (6.99478 iter/s, 14.2964s/100 iters), loss = 0.00154877
I0928 13:38:57.651564  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154892 (* 1 = 0.00154892 loss)
I0928 13:38:57.651579  4247 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I0928 13:39:11.925551  4247 solver.cpp:218] Iteration 99200 (7.00577 iter/s, 14.2739s/100 iters), loss = 0.00117995
I0928 13:39:11.925628  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0011801 (* 1 = 0.0011801 loss)
I0928 13:39:11.925635  4247 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I0928 13:39:26.158004  4247 solver.cpp:218] Iteration 99300 (7.02625 iter/s, 14.2323s/100 iters), loss = 0.00187747
I0928 13:39:26.158036  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00187762 (* 1 = 0.00187762 loss)
I0928 13:39:26.158044  4247 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I0928 13:39:40.414940  4247 solver.cpp:218] Iteration 99400 (7.01417 iter/s, 14.2569s/100 iters), loss = 0.00287921
I0928 13:39:40.414973  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00287937 (* 1 = 0.00287937 loss)
I0928 13:39:40.414981  4247 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I0928 13:39:53.985884  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:39:54.555598  4247 solver.cpp:330] Iteration 99500, Testing net (#0)
I0928 13:39:57.913167  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:39:58.053486  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9286
I0928 13:39:58.053514  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312617 (* 1 = 0.312617 loss)
I0928 13:39:58.194733  4247 solver.cpp:218] Iteration 99500 (5.62439 iter/s, 17.7797s/100 iters), loss = 0.000695583
I0928 13:39:58.194761  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000695736 (* 1 = 0.000695736 loss)
I0928 13:39:58.194767  4247 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I0928 13:40:12.432250  4247 solver.cpp:218] Iteration 99600 (7.02373 iter/s, 14.2374s/100 iters), loss = 0.000589309
I0928 13:40:12.432281  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000589461 (* 1 = 0.000589461 loss)
I0928 13:40:12.432286  4247 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I0928 13:40:26.677064  4247 solver.cpp:218] Iteration 99700 (7.02013 iter/s, 14.2447s/100 iters), loss = 0.00103492
I0928 13:40:26.677165  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103508 (* 1 = 0.00103508 loss)
I0928 13:40:26.677183  4247 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I0928 13:40:40.979151  4247 solver.cpp:218] Iteration 99800 (6.99205 iter/s, 14.302s/100 iters), loss = 0.000373223
I0928 13:40:40.979182  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000373375 (* 1 = 0.000373375 loss)
I0928 13:40:40.979188  4247 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I0928 13:40:55.274986  4247 solver.cpp:218] Iteration 99900 (6.99508 iter/s, 14.2958s/100 iters), loss = 0.000881706
I0928 13:40:55.275017  4247 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000881858 (* 1 = 0.000881858 loss)
I0928 13:40:55.275023  4247 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I0928 13:41:08.890991  4256 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:41:09.461135  4247 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res56_mpelu_alpha1_beta1_nodecay_gauss_iter_100000.caffemodel
I0928 13:41:09.486917  4247 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res56_mpelu_alpha1_beta1_nodecay_gauss_iter_100000.solverstate
I0928 13:41:09.527654  4247 solver.cpp:310] Iteration 100000, loss = 0.000744776
I0928 13:41:09.527676  4247 solver.cpp:330] Iteration 100000, Testing net (#0)
I0928 13:41:12.889997  4257 data_layer.cpp:73] Restarting data prefetching from start.
I0928 13:41:13.029695  4247 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9278
I0928 13:41:13.029719  4247 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311402 (* 1 = 0.311402 loss)
I0928 13:41:13.029724  4247 solver.cpp:315] Optimization Done.
I0928 13:41:13.029726  4247 caffe.cpp:259] Optimization Done.
