I0927 14:49:10.410390  3463 caffe.cpp:218] Using GPUs 0
I0927 14:49:10.449502  3463 caffe.cpp:223] GPU 0: GeForce GTX 1080
I0927 14:49:10.674955  3463 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res56_mpelu_alpha0.25_eta1_2decay_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res56_mpelu_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I0927 14:49:10.675096  3463 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56_mpelu_train_test.prototxt
I0927 14:49:10.678719  3463 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56_mpelu_train_test.prototxt
I0927 14:49:10.678733  3463 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0927 14:49:10.679010  3463 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I0927 14:49:10.679141  3463 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I0927 14:49:10.680235  3463 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU1"
  type: "M2PELU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU2"
  type: "M2PELU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU3"
  type: "M2PELU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU4"
  type: "M2PELU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU5"
  type: "M2PELU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU6"
  type: "M2PELU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU7"
  type: "M2PELU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU8"
  type: "M2PELU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU9"
  type: "M2PELU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU10"
  type: "M2PELU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU11"
  type: "M2PELU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU12"
  type: "M2PELU"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU13"
  type: "M2PELU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU14"
  type: "M2PELU"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU15"
  type: "M2PELU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU16"
  type: "M2PELU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU17"
  type: "M2PELU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU18"
  type: "M2PELU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU19"
  type: "M2PELU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU20"
  type: "M2PELU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU21"
  type: "M2PELU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU22"
  type: "M2PELU"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution24"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU23"
  type: "M2PELU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU24"
  type: "M2PELU"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
 
I0927 14:49:10.681121  3463 layer_factory.hpp:77] Creating layer Data1
I0927 14:49:10.681198  3463 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I0927 14:49:10.681217  3463 net.cpp:84] Creating Layer Data1
I0927 14:49:10.681224  3463 net.cpp:380] Data1 -> Data1
I0927 14:49:10.681241  3463 net.cpp:380] Data1 -> Data2
I0927 14:49:10.681249  3463 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0927 14:49:10.682669  3463 data_layer.cpp:45] output data size: 100,3,28,28
I0927 14:49:10.684928  3463 net.cpp:122] Setting up Data1
I0927 14:49:10.684950  3463 net.cpp:129] Top shape: 100 3 28 28 (235200)
I0927 14:49:10.684955  3463 net.cpp:129] Top shape: 100 (100)
I0927 14:49:10.684957  3463 net.cpp:137] Memory required for data: 941200
I0927 14:49:10.684963  3463 layer_factory.hpp:77] Creating layer Convolution1
I0927 14:49:10.684981  3463 net.cpp:84] Creating Layer Convolution1
I0927 14:49:10.684986  3463 net.cpp:406] Convolution1 <- Data1
I0927 14:49:10.684995  3463 net.cpp:380] Convolution1 -> Convolution1
I0927 14:49:10.832129  3463 net.cpp:122] Setting up Convolution1
I0927 14:49:10.832152  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.832156  3463 net.cpp:137] Memory required for data: 5958800
I0927 14:49:10.832171  3463 layer_factory.hpp:77] Creating layer BatchNorm1
I0927 14:49:10.832196  3463 net.cpp:84] Creating Layer BatchNorm1
I0927 14:49:10.832217  3463 net.cpp:406] BatchNorm1 <- Convolution1
I0927 14:49:10.832247  3463 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0927 14:49:10.832411  3463 net.cpp:122] Setting up BatchNorm1
I0927 14:49:10.832418  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.832420  3463 net.cpp:137] Memory required for data: 10976400
I0927 14:49:10.832428  3463 layer_factory.hpp:77] Creating layer Scale1
I0927 14:49:10.832446  3463 net.cpp:84] Creating Layer Scale1
I0927 14:49:10.832451  3463 net.cpp:406] Scale1 <- Convolution1
I0927 14:49:10.832455  3463 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0927 14:49:10.832527  3463 layer_factory.hpp:77] Creating layer Scale1
I0927 14:49:10.832638  3463 net.cpp:122] Setting up Scale1
I0927 14:49:10.832644  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.832648  3463 net.cpp:137] Memory required for data: 15994000
I0927 14:49:10.832651  3463 layer_factory.hpp:77] Creating layer M2PELU1
I0927 14:49:10.832660  3463 net.cpp:84] Creating Layer M2PELU1
I0927 14:49:10.832664  3463 net.cpp:406] M2PELU1 <- Convolution1
I0927 14:49:10.832676  3463 net.cpp:367] M2PELU1 -> Convolution1 (in-place)
I0927 14:49:10.833258  3463 net.cpp:122] Setting up M2PELU1
I0927 14:49:10.833268  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.833287  3463 net.cpp:137] Memory required for data: 21011600
I0927 14:49:10.833294  3463 layer_factory.hpp:77] Creating layer Convolution1_M2PELU1_0_split
I0927 14:49:10.833317  3463 net.cpp:84] Creating Layer Convolution1_M2PELU1_0_split
I0927 14:49:10.833333  3463 net.cpp:406] Convolution1_M2PELU1_0_split <- Convolution1
I0927 14:49:10.833339  3463 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_0
I0927 14:49:10.833359  3463 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_1
I0927 14:49:10.833407  3463 net.cpp:122] Setting up Convolution1_M2PELU1_0_split
I0927 14:49:10.833415  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.833418  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.833420  3463 net.cpp:137] Memory required for data: 31046800
I0927 14:49:10.833422  3463 layer_factory.hpp:77] Creating layer Convolution2
I0927 14:49:10.833431  3463 net.cpp:84] Creating Layer Convolution2
I0927 14:49:10.833432  3463 net.cpp:406] Convolution2 <- Convolution1_M2PELU1_0_split_0
I0927 14:49:10.833446  3463 net.cpp:380] Convolution2 -> Convolution2
I0927 14:49:10.834291  3463 net.cpp:122] Setting up Convolution2
I0927 14:49:10.834301  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.834305  3463 net.cpp:137] Memory required for data: 36064400
I0927 14:49:10.834308  3463 layer_factory.hpp:77] Creating layer BatchNorm2
I0927 14:49:10.834313  3463 net.cpp:84] Creating Layer BatchNorm2
I0927 14:49:10.834316  3463 net.cpp:406] BatchNorm2 <- Convolution2
I0927 14:49:10.834329  3463 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0927 14:49:10.834481  3463 net.cpp:122] Setting up BatchNorm2
I0927 14:49:10.834489  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.834491  3463 net.cpp:137] Memory required for data: 41082000
I0927 14:49:10.834496  3463 layer_factory.hpp:77] Creating layer Scale2
I0927 14:49:10.834501  3463 net.cpp:84] Creating Layer Scale2
I0927 14:49:10.834503  3463 net.cpp:406] Scale2 <- Convolution2
I0927 14:49:10.834507  3463 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0927 14:49:10.834586  3463 layer_factory.hpp:77] Creating layer Scale2
I0927 14:49:10.834688  3463 net.cpp:122] Setting up Scale2
I0927 14:49:10.834695  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.834697  3463 net.cpp:137] Memory required for data: 46099600
I0927 14:49:10.834702  3463 layer_factory.hpp:77] Creating layer M2PELU2
I0927 14:49:10.834707  3463 net.cpp:84] Creating Layer M2PELU2
I0927 14:49:10.834709  3463 net.cpp:406] M2PELU2 <- Convolution2
I0927 14:49:10.834712  3463 net.cpp:367] M2PELU2 -> Convolution2 (in-place)
I0927 14:49:10.834815  3463 net.cpp:122] Setting up M2PELU2
I0927 14:49:10.834821  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.834830  3463 net.cpp:137] Memory required for data: 51117200
I0927 14:49:10.834837  3463 layer_factory.hpp:77] Creating layer Convolution3
I0927 14:49:10.834854  3463 net.cpp:84] Creating Layer Convolution3
I0927 14:49:10.834858  3463 net.cpp:406] Convolution3 <- Convolution2
I0927 14:49:10.834862  3463 net.cpp:380] Convolution3 -> Convolution3
I0927 14:49:10.835692  3463 net.cpp:122] Setting up Convolution3
I0927 14:49:10.835703  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.835706  3463 net.cpp:137] Memory required for data: 56134800
I0927 14:49:10.835711  3463 layer_factory.hpp:77] Creating layer BatchNorm3
I0927 14:49:10.835716  3463 net.cpp:84] Creating Layer BatchNorm3
I0927 14:49:10.835717  3463 net.cpp:406] BatchNorm3 <- Convolution3
I0927 14:49:10.835731  3463 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0927 14:49:10.835857  3463 net.cpp:122] Setting up BatchNorm3
I0927 14:49:10.835862  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.835865  3463 net.cpp:137] Memory required for data: 61152400
I0927 14:49:10.835870  3463 layer_factory.hpp:77] Creating layer Scale3
I0927 14:49:10.835873  3463 net.cpp:84] Creating Layer Scale3
I0927 14:49:10.835876  3463 net.cpp:406] Scale3 <- Convolution3
I0927 14:49:10.835880  3463 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0927 14:49:10.835922  3463 layer_factory.hpp:77] Creating layer Scale3
I0927 14:49:10.836009  3463 net.cpp:122] Setting up Scale3
I0927 14:49:10.836014  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.836017  3463 net.cpp:137] Memory required for data: 66170000
I0927 14:49:10.836020  3463 layer_factory.hpp:77] Creating layer Eltwise1
I0927 14:49:10.836025  3463 net.cpp:84] Creating Layer Eltwise1
I0927 14:49:10.836028  3463 net.cpp:406] Eltwise1 <- Convolution1_M2PELU1_0_split_1
I0927 14:49:10.836031  3463 net.cpp:406] Eltwise1 <- Convolution3
I0927 14:49:10.836045  3463 net.cpp:380] Eltwise1 -> Eltwise1
I0927 14:49:10.836071  3463 net.cpp:122] Setting up Eltwise1
I0927 14:49:10.836076  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.836078  3463 net.cpp:137] Memory required for data: 71187600
I0927 14:49:10.836081  3463 layer_factory.hpp:77] Creating layer M2PELU3
I0927 14:49:10.836086  3463 net.cpp:84] Creating Layer M2PELU3
I0927 14:49:10.836087  3463 net.cpp:406] M2PELU3 <- Eltwise1
I0927 14:49:10.836091  3463 net.cpp:367] M2PELU3 -> Eltwise1 (in-place)
I0927 14:49:10.836182  3463 net.cpp:122] Setting up M2PELU3
I0927 14:49:10.836189  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.836190  3463 net.cpp:137] Memory required for data: 76205200
I0927 14:49:10.836194  3463 layer_factory.hpp:77] Creating layer Eltwise1_M2PELU3_0_split
I0927 14:49:10.836197  3463 net.cpp:84] Creating Layer Eltwise1_M2PELU3_0_split
I0927 14:49:10.836200  3463 net.cpp:406] Eltwise1_M2PELU3_0_split <- Eltwise1
I0927 14:49:10.836203  3463 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_0
I0927 14:49:10.836218  3463 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_1
I0927 14:49:10.836248  3463 net.cpp:122] Setting up Eltwise1_M2PELU3_0_split
I0927 14:49:10.836253  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.836256  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.836258  3463 net.cpp:137] Memory required for data: 86240400
I0927 14:49:10.836261  3463 layer_factory.hpp:77] Creating layer Convolution4
I0927 14:49:10.836266  3463 net.cpp:84] Creating Layer Convolution4
I0927 14:49:10.836268  3463 net.cpp:406] Convolution4 <- Eltwise1_M2PELU3_0_split_0
I0927 14:49:10.836282  3463 net.cpp:380] Convolution4 -> Convolution4
I0927 14:49:10.837116  3463 net.cpp:122] Setting up Convolution4
I0927 14:49:10.837126  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.837128  3463 net.cpp:137] Memory required for data: 91258000
I0927 14:49:10.837133  3463 layer_factory.hpp:77] Creating layer BatchNorm4
I0927 14:49:10.837139  3463 net.cpp:84] Creating Layer BatchNorm4
I0927 14:49:10.837158  3463 net.cpp:406] BatchNorm4 <- Convolution4
I0927 14:49:10.837172  3463 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0927 14:49:10.837311  3463 net.cpp:122] Setting up BatchNorm4
I0927 14:49:10.837316  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.837318  3463 net.cpp:137] Memory required for data: 96275600
I0927 14:49:10.837323  3463 layer_factory.hpp:77] Creating layer Scale4
I0927 14:49:10.837327  3463 net.cpp:84] Creating Layer Scale4
I0927 14:49:10.837330  3463 net.cpp:406] Scale4 <- Convolution4
I0927 14:49:10.837344  3463 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0927 14:49:10.837388  3463 layer_factory.hpp:77] Creating layer Scale4
I0927 14:49:10.837491  3463 net.cpp:122] Setting up Scale4
I0927 14:49:10.837496  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.837507  3463 net.cpp:137] Memory required for data: 101293200
I0927 14:49:10.837515  3463 layer_factory.hpp:77] Creating layer M2PELU4
I0927 14:49:10.837522  3463 net.cpp:84] Creating Layer M2PELU4
I0927 14:49:10.837524  3463 net.cpp:406] M2PELU4 <- Convolution4
I0927 14:49:10.837527  3463 net.cpp:367] M2PELU4 -> Convolution4 (in-place)
I0927 14:49:10.837604  3463 net.cpp:122] Setting up M2PELU4
I0927 14:49:10.837610  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.837612  3463 net.cpp:137] Memory required for data: 106310800
I0927 14:49:10.837617  3463 layer_factory.hpp:77] Creating layer Convolution5
I0927 14:49:10.837625  3463 net.cpp:84] Creating Layer Convolution5
I0927 14:49:10.837628  3463 net.cpp:406] Convolution5 <- Convolution4
I0927 14:49:10.837632  3463 net.cpp:380] Convolution5 -> Convolution5
I0927 14:49:10.838495  3463 net.cpp:122] Setting up Convolution5
I0927 14:49:10.838505  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.838508  3463 net.cpp:137] Memory required for data: 111328400
I0927 14:49:10.838513  3463 layer_factory.hpp:77] Creating layer BatchNorm5
I0927 14:49:10.838522  3463 net.cpp:84] Creating Layer BatchNorm5
I0927 14:49:10.838537  3463 net.cpp:406] BatchNorm5 <- Convolution5
I0927 14:49:10.838541  3463 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0927 14:49:10.838673  3463 net.cpp:122] Setting up BatchNorm5
I0927 14:49:10.838680  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.838682  3463 net.cpp:137] Memory required for data: 116346000
I0927 14:49:10.838687  3463 layer_factory.hpp:77] Creating layer Scale5
I0927 14:49:10.838692  3463 net.cpp:84] Creating Layer Scale5
I0927 14:49:10.838696  3463 net.cpp:406] Scale5 <- Convolution5
I0927 14:49:10.838698  3463 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0927 14:49:10.838724  3463 layer_factory.hpp:77] Creating layer Scale5
I0927 14:49:10.838799  3463 net.cpp:122] Setting up Scale5
I0927 14:49:10.838805  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.838809  3463 net.cpp:137] Memory required for data: 121363600
I0927 14:49:10.838812  3463 layer_factory.hpp:77] Creating layer Eltwise2
I0927 14:49:10.838819  3463 net.cpp:84] Creating Layer Eltwise2
I0927 14:49:10.838821  3463 net.cpp:406] Eltwise2 <- Eltwise1_M2PELU3_0_split_1
I0927 14:49:10.838824  3463 net.cpp:406] Eltwise2 <- Convolution5
I0927 14:49:10.838829  3463 net.cpp:380] Eltwise2 -> Eltwise2
I0927 14:49:10.838843  3463 net.cpp:122] Setting up Eltwise2
I0927 14:49:10.838848  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.838850  3463 net.cpp:137] Memory required for data: 126381200
I0927 14:49:10.838853  3463 layer_factory.hpp:77] Creating layer M2PELU5
I0927 14:49:10.838858  3463 net.cpp:84] Creating Layer M2PELU5
I0927 14:49:10.838861  3463 net.cpp:406] M2PELU5 <- Eltwise2
I0927 14:49:10.838865  3463 net.cpp:367] M2PELU5 -> Eltwise2 (in-place)
I0927 14:49:10.838943  3463 net.cpp:122] Setting up M2PELU5
I0927 14:49:10.838949  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.838953  3463 net.cpp:137] Memory required for data: 131398800
I0927 14:49:10.838955  3463 layer_factory.hpp:77] Creating layer Eltwise2_M2PELU5_0_split
I0927 14:49:10.838966  3463 net.cpp:84] Creating Layer Eltwise2_M2PELU5_0_split
I0927 14:49:10.838970  3463 net.cpp:406] Eltwise2_M2PELU5_0_split <- Eltwise2
I0927 14:49:10.838973  3463 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_0
I0927 14:49:10.838979  3463 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_1
I0927 14:49:10.839002  3463 net.cpp:122] Setting up Eltwise2_M2PELU5_0_split
I0927 14:49:10.839007  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.839011  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.839015  3463 net.cpp:137] Memory required for data: 141434000
I0927 14:49:10.839016  3463 layer_factory.hpp:77] Creating layer Convolution6
I0927 14:49:10.839023  3463 net.cpp:84] Creating Layer Convolution6
I0927 14:49:10.839027  3463 net.cpp:406] Convolution6 <- Eltwise2_M2PELU5_0_split_0
I0927 14:49:10.839031  3463 net.cpp:380] Convolution6 -> Convolution6
I0927 14:49:10.839893  3463 net.cpp:122] Setting up Convolution6
I0927 14:49:10.839903  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.839907  3463 net.cpp:137] Memory required for data: 146451600
I0927 14:49:10.839912  3463 layer_factory.hpp:77] Creating layer BatchNorm6
I0927 14:49:10.839917  3463 net.cpp:84] Creating Layer BatchNorm6
I0927 14:49:10.839920  3463 net.cpp:406] BatchNorm6 <- Convolution6
I0927 14:49:10.839926  3463 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0927 14:49:10.840052  3463 net.cpp:122] Setting up BatchNorm6
I0927 14:49:10.840059  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.840061  3463 net.cpp:137] Memory required for data: 151469200
I0927 14:49:10.840066  3463 layer_factory.hpp:77] Creating layer Scale6
I0927 14:49:10.840071  3463 net.cpp:84] Creating Layer Scale6
I0927 14:49:10.840075  3463 net.cpp:406] Scale6 <- Convolution6
I0927 14:49:10.840080  3463 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0927 14:49:10.840104  3463 layer_factory.hpp:77] Creating layer Scale6
I0927 14:49:10.840179  3463 net.cpp:122] Setting up Scale6
I0927 14:49:10.840184  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.840188  3463 net.cpp:137] Memory required for data: 156486800
I0927 14:49:10.840191  3463 layer_factory.hpp:77] Creating layer M2PELU6
I0927 14:49:10.840198  3463 net.cpp:84] Creating Layer M2PELU6
I0927 14:49:10.840200  3463 net.cpp:406] M2PELU6 <- Convolution6
I0927 14:49:10.840204  3463 net.cpp:367] M2PELU6 -> Convolution6 (in-place)
I0927 14:49:10.840286  3463 net.cpp:122] Setting up M2PELU6
I0927 14:49:10.840291  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.840293  3463 net.cpp:137] Memory required for data: 161504400
I0927 14:49:10.840297  3463 layer_factory.hpp:77] Creating layer Convolution7
I0927 14:49:10.840306  3463 net.cpp:84] Creating Layer Convolution7
I0927 14:49:10.840309  3463 net.cpp:406] Convolution7 <- Convolution6
I0927 14:49:10.840313  3463 net.cpp:380] Convolution7 -> Convolution7
I0927 14:49:10.840857  3463 net.cpp:122] Setting up Convolution7
I0927 14:49:10.840865  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.840869  3463 net.cpp:137] Memory required for data: 166522000
I0927 14:49:10.840873  3463 layer_factory.hpp:77] Creating layer BatchNorm7
I0927 14:49:10.840879  3463 net.cpp:84] Creating Layer BatchNorm7
I0927 14:49:10.840883  3463 net.cpp:406] BatchNorm7 <- Convolution7
I0927 14:49:10.840886  3463 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0927 14:49:10.841013  3463 net.cpp:122] Setting up BatchNorm7
I0927 14:49:10.841019  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.841022  3463 net.cpp:137] Memory required for data: 171539600
I0927 14:49:10.841027  3463 layer_factory.hpp:77] Creating layer Scale7
I0927 14:49:10.841034  3463 net.cpp:84] Creating Layer Scale7
I0927 14:49:10.841038  3463 net.cpp:406] Scale7 <- Convolution7
I0927 14:49:10.841042  3463 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0927 14:49:10.841068  3463 layer_factory.hpp:77] Creating layer Scale7
I0927 14:49:10.841150  3463 net.cpp:122] Setting up Scale7
I0927 14:49:10.841156  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.841159  3463 net.cpp:137] Memory required for data: 176557200
I0927 14:49:10.841163  3463 layer_factory.hpp:77] Creating layer Eltwise3
I0927 14:49:10.841169  3463 net.cpp:84] Creating Layer Eltwise3
I0927 14:49:10.841172  3463 net.cpp:406] Eltwise3 <- Eltwise2_M2PELU5_0_split_1
I0927 14:49:10.841176  3463 net.cpp:406] Eltwise3 <- Convolution7
I0927 14:49:10.841181  3463 net.cpp:380] Eltwise3 -> Eltwise3
I0927 14:49:10.841197  3463 net.cpp:122] Setting up Eltwise3
I0927 14:49:10.841202  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.841204  3463 net.cpp:137] Memory required for data: 181574800
I0927 14:49:10.841207  3463 layer_factory.hpp:77] Creating layer M2PELU7
I0927 14:49:10.841212  3463 net.cpp:84] Creating Layer M2PELU7
I0927 14:49:10.841215  3463 net.cpp:406] M2PELU7 <- Eltwise3
I0927 14:49:10.841218  3463 net.cpp:367] M2PELU7 -> Eltwise3 (in-place)
I0927 14:49:10.841298  3463 net.cpp:122] Setting up M2PELU7
I0927 14:49:10.841305  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.841307  3463 net.cpp:137] Memory required for data: 186592400
I0927 14:49:10.841311  3463 layer_factory.hpp:77] Creating layer Eltwise3_M2PELU7_0_split
I0927 14:49:10.841315  3463 net.cpp:84] Creating Layer Eltwise3_M2PELU7_0_split
I0927 14:49:10.841318  3463 net.cpp:406] Eltwise3_M2PELU7_0_split <- Eltwise3
I0927 14:49:10.841323  3463 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_0
I0927 14:49:10.841328  3463 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_1
I0927 14:49:10.841351  3463 net.cpp:122] Setting up Eltwise3_M2PELU7_0_split
I0927 14:49:10.841356  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.841358  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.841361  3463 net.cpp:137] Memory required for data: 196627600
I0927 14:49:10.841364  3463 layer_factory.hpp:77] Creating layer Convolution8
I0927 14:49:10.841372  3463 net.cpp:84] Creating Layer Convolution8
I0927 14:49:10.841374  3463 net.cpp:406] Convolution8 <- Eltwise3_M2PELU7_0_split_0
I0927 14:49:10.841378  3463 net.cpp:380] Convolution8 -> Convolution8
I0927 14:49:10.842238  3463 net.cpp:122] Setting up Convolution8
I0927 14:49:10.842248  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.842252  3463 net.cpp:137] Memory required for data: 201645200
I0927 14:49:10.842262  3463 layer_factory.hpp:77] Creating layer BatchNorm8
I0927 14:49:10.842268  3463 net.cpp:84] Creating Layer BatchNorm8
I0927 14:49:10.842272  3463 net.cpp:406] BatchNorm8 <- Convolution8
I0927 14:49:10.842277  3463 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0927 14:49:10.842402  3463 net.cpp:122] Setting up BatchNorm8
I0927 14:49:10.842407  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.842411  3463 net.cpp:137] Memory required for data: 206662800
I0927 14:49:10.842416  3463 layer_factory.hpp:77] Creating layer Scale8
I0927 14:49:10.842420  3463 net.cpp:84] Creating Layer Scale8
I0927 14:49:10.842423  3463 net.cpp:406] Scale8 <- Convolution8
I0927 14:49:10.842427  3463 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0927 14:49:10.842453  3463 layer_factory.hpp:77] Creating layer Scale8
I0927 14:49:10.842545  3463 net.cpp:122] Setting up Scale8
I0927 14:49:10.842551  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.842555  3463 net.cpp:137] Memory required for data: 211680400
I0927 14:49:10.842568  3463 layer_factory.hpp:77] Creating layer M2PELU8
I0927 14:49:10.842574  3463 net.cpp:84] Creating Layer M2PELU8
I0927 14:49:10.842577  3463 net.cpp:406] M2PELU8 <- Convolution8
I0927 14:49:10.842581  3463 net.cpp:367] M2PELU8 -> Convolution8 (in-place)
I0927 14:49:10.842664  3463 net.cpp:122] Setting up M2PELU8
I0927 14:49:10.842670  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.842674  3463 net.cpp:137] Memory required for data: 216698000
I0927 14:49:10.842677  3463 layer_factory.hpp:77] Creating layer Convolution9
I0927 14:49:10.842692  3463 net.cpp:84] Creating Layer Convolution9
I0927 14:49:10.842695  3463 net.cpp:406] Convolution9 <- Convolution8
I0927 14:49:10.842700  3463 net.cpp:380] Convolution9 -> Convolution9
I0927 14:49:10.843881  3463 net.cpp:122] Setting up Convolution9
I0927 14:49:10.843894  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.843900  3463 net.cpp:137] Memory required for data: 221715600
I0927 14:49:10.843909  3463 layer_factory.hpp:77] Creating layer BatchNorm9
I0927 14:49:10.843919  3463 net.cpp:84] Creating Layer BatchNorm9
I0927 14:49:10.843924  3463 net.cpp:406] BatchNorm9 <- Convolution9
I0927 14:49:10.843933  3463 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0927 14:49:10.844130  3463 net.cpp:122] Setting up BatchNorm9
I0927 14:49:10.844137  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.844141  3463 net.cpp:137] Memory required for data: 226733200
I0927 14:49:10.844146  3463 layer_factory.hpp:77] Creating layer Scale9
I0927 14:49:10.844153  3463 net.cpp:84] Creating Layer Scale9
I0927 14:49:10.844156  3463 net.cpp:406] Scale9 <- Convolution9
I0927 14:49:10.844161  3463 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0927 14:49:10.844194  3463 layer_factory.hpp:77] Creating layer Scale9
I0927 14:49:10.844337  3463 net.cpp:122] Setting up Scale9
I0927 14:49:10.844349  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.844354  3463 net.cpp:137] Memory required for data: 231750800
I0927 14:49:10.844362  3463 layer_factory.hpp:77] Creating layer Eltwise4
I0927 14:49:10.844370  3463 net.cpp:84] Creating Layer Eltwise4
I0927 14:49:10.844377  3463 net.cpp:406] Eltwise4 <- Eltwise3_M2PELU7_0_split_1
I0927 14:49:10.844383  3463 net.cpp:406] Eltwise4 <- Convolution9
I0927 14:49:10.844389  3463 net.cpp:380] Eltwise4 -> Eltwise4
I0927 14:49:10.844425  3463 net.cpp:122] Setting up Eltwise4
I0927 14:49:10.844435  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.844440  3463 net.cpp:137] Memory required for data: 236768400
I0927 14:49:10.844445  3463 layer_factory.hpp:77] Creating layer M2PELU9
I0927 14:49:10.844455  3463 net.cpp:84] Creating Layer M2PELU9
I0927 14:49:10.844462  3463 net.cpp:406] M2PELU9 <- Eltwise4
I0927 14:49:10.844470  3463 net.cpp:367] M2PELU9 -> Eltwise4 (in-place)
I0927 14:49:10.844604  3463 net.cpp:122] Setting up M2PELU9
I0927 14:49:10.844632  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.844647  3463 net.cpp:137] Memory required for data: 241786000
I0927 14:49:10.844665  3463 layer_factory.hpp:77] Creating layer Eltwise4_M2PELU9_0_split
I0927 14:49:10.844672  3463 net.cpp:84] Creating Layer Eltwise4_M2PELU9_0_split
I0927 14:49:10.844677  3463 net.cpp:406] Eltwise4_M2PELU9_0_split <- Eltwise4
I0927 14:49:10.844684  3463 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_0
I0927 14:49:10.844696  3463 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_1
I0927 14:49:10.844732  3463 net.cpp:122] Setting up Eltwise4_M2PELU9_0_split
I0927 14:49:10.844739  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.844745  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.844750  3463 net.cpp:137] Memory required for data: 251821200
I0927 14:49:10.844755  3463 layer_factory.hpp:77] Creating layer Convolution10
I0927 14:49:10.844775  3463 net.cpp:84] Creating Layer Convolution10
I0927 14:49:10.844789  3463 net.cpp:406] Convolution10 <- Eltwise4_M2PELU9_0_split_0
I0927 14:49:10.844799  3463 net.cpp:380] Convolution10 -> Convolution10
I0927 14:49:10.845693  3463 net.cpp:122] Setting up Convolution10
I0927 14:49:10.845705  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.845721  3463 net.cpp:137] Memory required for data: 256838800
I0927 14:49:10.845729  3463 layer_factory.hpp:77] Creating layer BatchNorm10
I0927 14:49:10.845737  3463 net.cpp:84] Creating Layer BatchNorm10
I0927 14:49:10.845752  3463 net.cpp:406] BatchNorm10 <- Convolution10
I0927 14:49:10.845770  3463 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0927 14:49:10.845913  3463 net.cpp:122] Setting up BatchNorm10
I0927 14:49:10.845922  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.845927  3463 net.cpp:137] Memory required for data: 261856400
I0927 14:49:10.845937  3463 layer_factory.hpp:77] Creating layer Scale10
I0927 14:49:10.845943  3463 net.cpp:84] Creating Layer Scale10
I0927 14:49:10.845949  3463 net.cpp:406] Scale10 <- Convolution10
I0927 14:49:10.845957  3463 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0927 14:49:10.845993  3463 layer_factory.hpp:77] Creating layer Scale10
I0927 14:49:10.846087  3463 net.cpp:122] Setting up Scale10
I0927 14:49:10.846096  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.846110  3463 net.cpp:137] Memory required for data: 266874000
I0927 14:49:10.846119  3463 layer_factory.hpp:77] Creating layer M2PELU10
I0927 14:49:10.846127  3463 net.cpp:84] Creating Layer M2PELU10
I0927 14:49:10.846132  3463 net.cpp:406] M2PELU10 <- Convolution10
I0927 14:49:10.846141  3463 net.cpp:367] M2PELU10 -> Convolution10 (in-place)
I0927 14:49:10.846261  3463 net.cpp:122] Setting up M2PELU10
I0927 14:49:10.846267  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.846272  3463 net.cpp:137] Memory required for data: 271891600
I0927 14:49:10.846289  3463 layer_factory.hpp:77] Creating layer Convolution11
I0927 14:49:10.846302  3463 net.cpp:84] Creating Layer Convolution11
I0927 14:49:10.846307  3463 net.cpp:406] Convolution11 <- Convolution10
I0927 14:49:10.846314  3463 net.cpp:380] Convolution11 -> Convolution11
I0927 14:49:10.847224  3463 net.cpp:122] Setting up Convolution11
I0927 14:49:10.847236  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.847241  3463 net.cpp:137] Memory required for data: 276909200
I0927 14:49:10.847249  3463 layer_factory.hpp:77] Creating layer BatchNorm11
I0927 14:49:10.847259  3463 net.cpp:84] Creating Layer BatchNorm11
I0927 14:49:10.847265  3463 net.cpp:406] BatchNorm11 <- Convolution11
I0927 14:49:10.847272  3463 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0927 14:49:10.847403  3463 net.cpp:122] Setting up BatchNorm11
I0927 14:49:10.847410  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.847416  3463 net.cpp:137] Memory required for data: 281926800
I0927 14:49:10.847426  3463 layer_factory.hpp:77] Creating layer Scale11
I0927 14:49:10.847434  3463 net.cpp:84] Creating Layer Scale11
I0927 14:49:10.847440  3463 net.cpp:406] Scale11 <- Convolution11
I0927 14:49:10.847445  3463 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0927 14:49:10.847478  3463 layer_factory.hpp:77] Creating layer Scale11
I0927 14:49:10.847563  3463 net.cpp:122] Setting up Scale11
I0927 14:49:10.847571  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.847576  3463 net.cpp:137] Memory required for data: 286944400
I0927 14:49:10.847585  3463 layer_factory.hpp:77] Creating layer Eltwise5
I0927 14:49:10.847594  3463 net.cpp:84] Creating Layer Eltwise5
I0927 14:49:10.847599  3463 net.cpp:406] Eltwise5 <- Eltwise4_M2PELU9_0_split_1
I0927 14:49:10.847604  3463 net.cpp:406] Eltwise5 <- Convolution11
I0927 14:49:10.847612  3463 net.cpp:380] Eltwise5 -> Eltwise5
I0927 14:49:10.847632  3463 net.cpp:122] Setting up Eltwise5
I0927 14:49:10.847640  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.847645  3463 net.cpp:137] Memory required for data: 291962000
I0927 14:49:10.847648  3463 layer_factory.hpp:77] Creating layer M2PELU11
I0927 14:49:10.847658  3463 net.cpp:84] Creating Layer M2PELU11
I0927 14:49:10.847662  3463 net.cpp:406] M2PELU11 <- Eltwise5
I0927 14:49:10.847669  3463 net.cpp:367] M2PELU11 -> Eltwise5 (in-place)
I0927 14:49:10.847759  3463 net.cpp:122] Setting up M2PELU11
I0927 14:49:10.847767  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.847771  3463 net.cpp:137] Memory required for data: 296979600
I0927 14:49:10.847779  3463 layer_factory.hpp:77] Creating layer Eltwise5_M2PELU11_0_split
I0927 14:49:10.847785  3463 net.cpp:84] Creating Layer Eltwise5_M2PELU11_0_split
I0927 14:49:10.847797  3463 net.cpp:406] Eltwise5_M2PELU11_0_split <- Eltwise5
I0927 14:49:10.847807  3463 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_0
I0927 14:49:10.847815  3463 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_1
I0927 14:49:10.847844  3463 net.cpp:122] Setting up Eltwise5_M2PELU11_0_split
I0927 14:49:10.847851  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.847858  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.847863  3463 net.cpp:137] Memory required for data: 307014800
I0927 14:49:10.847867  3463 layer_factory.hpp:77] Creating layer Convolution12
I0927 14:49:10.847878  3463 net.cpp:84] Creating Layer Convolution12
I0927 14:49:10.847883  3463 net.cpp:406] Convolution12 <- Eltwise5_M2PELU11_0_split_0
I0927 14:49:10.847890  3463 net.cpp:380] Convolution12 -> Convolution12
I0927 14:49:10.848778  3463 net.cpp:122] Setting up Convolution12
I0927 14:49:10.848790  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.848796  3463 net.cpp:137] Memory required for data: 312032400
I0927 14:49:10.848803  3463 layer_factory.hpp:77] Creating layer BatchNorm12
I0927 14:49:10.848812  3463 net.cpp:84] Creating Layer BatchNorm12
I0927 14:49:10.848817  3463 net.cpp:406] BatchNorm12 <- Convolution12
I0927 14:49:10.848827  3463 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0927 14:49:10.848963  3463 net.cpp:122] Setting up BatchNorm12
I0927 14:49:10.848971  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.848976  3463 net.cpp:137] Memory required for data: 317050000
I0927 14:49:10.848986  3463 layer_factory.hpp:77] Creating layer Scale12
I0927 14:49:10.848994  3463 net.cpp:84] Creating Layer Scale12
I0927 14:49:10.848999  3463 net.cpp:406] Scale12 <- Convolution12
I0927 14:49:10.849005  3463 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0927 14:49:10.849038  3463 layer_factory.hpp:77] Creating layer Scale12
I0927 14:49:10.849123  3463 net.cpp:122] Setting up Scale12
I0927 14:49:10.849131  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.849135  3463 net.cpp:137] Memory required for data: 322067600
I0927 14:49:10.849143  3463 layer_factory.hpp:77] Creating layer M2PELU12
I0927 14:49:10.849151  3463 net.cpp:84] Creating Layer M2PELU12
I0927 14:49:10.849156  3463 net.cpp:406] M2PELU12 <- Convolution12
I0927 14:49:10.849164  3463 net.cpp:367] M2PELU12 -> Convolution12 (in-place)
I0927 14:49:10.849256  3463 net.cpp:122] Setting up M2PELU12
I0927 14:49:10.849262  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.849267  3463 net.cpp:137] Memory required for data: 327085200
I0927 14:49:10.849274  3463 layer_factory.hpp:77] Creating layer Convolution13
I0927 14:49:10.849287  3463 net.cpp:84] Creating Layer Convolution13
I0927 14:49:10.849292  3463 net.cpp:406] Convolution13 <- Convolution12
I0927 14:49:10.849298  3463 net.cpp:380] Convolution13 -> Convolution13
I0927 14:49:10.850184  3463 net.cpp:122] Setting up Convolution13
I0927 14:49:10.850195  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.850200  3463 net.cpp:137] Memory required for data: 332102800
I0927 14:49:10.850208  3463 layer_factory.hpp:77] Creating layer BatchNorm13
I0927 14:49:10.850217  3463 net.cpp:84] Creating Layer BatchNorm13
I0927 14:49:10.850222  3463 net.cpp:406] BatchNorm13 <- Convolution13
I0927 14:49:10.850230  3463 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0927 14:49:10.850366  3463 net.cpp:122] Setting up BatchNorm13
I0927 14:49:10.850374  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.850380  3463 net.cpp:137] Memory required for data: 337120400
I0927 14:49:10.850389  3463 layer_factory.hpp:77] Creating layer Scale13
I0927 14:49:10.850397  3463 net.cpp:84] Creating Layer Scale13
I0927 14:49:10.850402  3463 net.cpp:406] Scale13 <- Convolution13
I0927 14:49:10.850410  3463 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0927 14:49:10.850443  3463 layer_factory.hpp:77] Creating layer Scale13
I0927 14:49:10.850544  3463 net.cpp:122] Setting up Scale13
I0927 14:49:10.850559  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.850574  3463 net.cpp:137] Memory required for data: 342138000
I0927 14:49:10.850582  3463 layer_factory.hpp:77] Creating layer Eltwise6
I0927 14:49:10.850594  3463 net.cpp:84] Creating Layer Eltwise6
I0927 14:49:10.850599  3463 net.cpp:406] Eltwise6 <- Eltwise5_M2PELU11_0_split_1
I0927 14:49:10.850605  3463 net.cpp:406] Eltwise6 <- Convolution13
I0927 14:49:10.850613  3463 net.cpp:380] Eltwise6 -> Eltwise6
I0927 14:49:10.850638  3463 net.cpp:122] Setting up Eltwise6
I0927 14:49:10.850646  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.850651  3463 net.cpp:137] Memory required for data: 347155600
I0927 14:49:10.850656  3463 layer_factory.hpp:77] Creating layer M2PELU13
I0927 14:49:10.850667  3463 net.cpp:84] Creating Layer M2PELU13
I0927 14:49:10.850672  3463 net.cpp:406] M2PELU13 <- Eltwise6
I0927 14:49:10.850680  3463 net.cpp:367] M2PELU13 -> Eltwise6 (in-place)
I0927 14:49:10.850772  3463 net.cpp:122] Setting up M2PELU13
I0927 14:49:10.850780  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.850785  3463 net.cpp:137] Memory required for data: 352173200
I0927 14:49:10.850792  3463 layer_factory.hpp:77] Creating layer Eltwise6_M2PELU13_0_split
I0927 14:49:10.850800  3463 net.cpp:84] Creating Layer Eltwise6_M2PELU13_0_split
I0927 14:49:10.850805  3463 net.cpp:406] Eltwise6_M2PELU13_0_split <- Eltwise6
I0927 14:49:10.850811  3463 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_0
I0927 14:49:10.850819  3463 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_1
I0927 14:49:10.850847  3463 net.cpp:122] Setting up Eltwise6_M2PELU13_0_split
I0927 14:49:10.850854  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.850862  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.850864  3463 net.cpp:137] Memory required for data: 362208400
I0927 14:49:10.850867  3463 layer_factory.hpp:77] Creating layer Convolution14
I0927 14:49:10.850874  3463 net.cpp:84] Creating Layer Convolution14
I0927 14:49:10.850878  3463 net.cpp:406] Convolution14 <- Eltwise6_M2PELU13_0_split_0
I0927 14:49:10.850881  3463 net.cpp:380] Convolution14 -> Convolution14
I0927 14:49:10.851761  3463 net.cpp:122] Setting up Convolution14
I0927 14:49:10.851769  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.851773  3463 net.cpp:137] Memory required for data: 367226000
I0927 14:49:10.851776  3463 layer_factory.hpp:77] Creating layer BatchNorm14
I0927 14:49:10.851783  3463 net.cpp:84] Creating Layer BatchNorm14
I0927 14:49:10.851784  3463 net.cpp:406] BatchNorm14 <- Convolution14
I0927 14:49:10.851789  3463 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0927 14:49:10.851920  3463 net.cpp:122] Setting up BatchNorm14
I0927 14:49:10.851924  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.851927  3463 net.cpp:137] Memory required for data: 372243600
I0927 14:49:10.851932  3463 layer_factory.hpp:77] Creating layer Scale14
I0927 14:49:10.851936  3463 net.cpp:84] Creating Layer Scale14
I0927 14:49:10.851938  3463 net.cpp:406] Scale14 <- Convolution14
I0927 14:49:10.851943  3463 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0927 14:49:10.851968  3463 layer_factory.hpp:77] Creating layer Scale14
I0927 14:49:10.852046  3463 net.cpp:122] Setting up Scale14
I0927 14:49:10.852049  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.852051  3463 net.cpp:137] Memory required for data: 377261200
I0927 14:49:10.852056  3463 layer_factory.hpp:77] Creating layer M2PELU14
I0927 14:49:10.852061  3463 net.cpp:84] Creating Layer M2PELU14
I0927 14:49:10.852062  3463 net.cpp:406] M2PELU14 <- Convolution14
I0927 14:49:10.852066  3463 net.cpp:367] M2PELU14 -> Convolution14 (in-place)
I0927 14:49:10.852149  3463 net.cpp:122] Setting up M2PELU14
I0927 14:49:10.852154  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.852155  3463 net.cpp:137] Memory required for data: 382278800
I0927 14:49:10.852165  3463 layer_factory.hpp:77] Creating layer Convolution15
I0927 14:49:10.852172  3463 net.cpp:84] Creating Layer Convolution15
I0927 14:49:10.852174  3463 net.cpp:406] Convolution15 <- Convolution14
I0927 14:49:10.852179  3463 net.cpp:380] Convolution15 -> Convolution15
I0927 14:49:10.853058  3463 net.cpp:122] Setting up Convolution15
I0927 14:49:10.853067  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.853070  3463 net.cpp:137] Memory required for data: 387296400
I0927 14:49:10.853075  3463 layer_factory.hpp:77] Creating layer BatchNorm15
I0927 14:49:10.853080  3463 net.cpp:84] Creating Layer BatchNorm15
I0927 14:49:10.853082  3463 net.cpp:406] BatchNorm15 <- Convolution15
I0927 14:49:10.853087  3463 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0927 14:49:10.853230  3463 net.cpp:122] Setting up BatchNorm15
I0927 14:49:10.853235  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.853236  3463 net.cpp:137] Memory required for data: 392314000
I0927 14:49:10.853250  3463 layer_factory.hpp:77] Creating layer Scale15
I0927 14:49:10.853255  3463 net.cpp:84] Creating Layer Scale15
I0927 14:49:10.853257  3463 net.cpp:406] Scale15 <- Convolution15
I0927 14:49:10.853261  3463 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0927 14:49:10.853287  3463 layer_factory.hpp:77] Creating layer Scale15
I0927 14:49:10.853363  3463 net.cpp:122] Setting up Scale15
I0927 14:49:10.853366  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.853368  3463 net.cpp:137] Memory required for data: 397331600
I0927 14:49:10.853373  3463 layer_factory.hpp:77] Creating layer Eltwise7
I0927 14:49:10.853375  3463 net.cpp:84] Creating Layer Eltwise7
I0927 14:49:10.853379  3463 net.cpp:406] Eltwise7 <- Eltwise6_M2PELU13_0_split_1
I0927 14:49:10.853380  3463 net.cpp:406] Eltwise7 <- Convolution15
I0927 14:49:10.853384  3463 net.cpp:380] Eltwise7 -> Eltwise7
I0927 14:49:10.853400  3463 net.cpp:122] Setting up Eltwise7
I0927 14:49:10.853404  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.853405  3463 net.cpp:137] Memory required for data: 402349200
I0927 14:49:10.853407  3463 layer_factory.hpp:77] Creating layer M2PELU15
I0927 14:49:10.853412  3463 net.cpp:84] Creating Layer M2PELU15
I0927 14:49:10.853415  3463 net.cpp:406] M2PELU15 <- Eltwise7
I0927 14:49:10.853418  3463 net.cpp:367] M2PELU15 -> Eltwise7 (in-place)
I0927 14:49:10.853500  3463 net.cpp:122] Setting up M2PELU15
I0927 14:49:10.853504  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.853507  3463 net.cpp:137] Memory required for data: 407366800
I0927 14:49:10.853510  3463 layer_factory.hpp:77] Creating layer Eltwise7_M2PELU15_0_split
I0927 14:49:10.853513  3463 net.cpp:84] Creating Layer Eltwise7_M2PELU15_0_split
I0927 14:49:10.853515  3463 net.cpp:406] Eltwise7_M2PELU15_0_split <- Eltwise7
I0927 14:49:10.853518  3463 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_0
I0927 14:49:10.853523  3463 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_1
I0927 14:49:10.853544  3463 net.cpp:122] Setting up Eltwise7_M2PELU15_0_split
I0927 14:49:10.853549  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.853551  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.853552  3463 net.cpp:137] Memory required for data: 417402000
I0927 14:49:10.853554  3463 layer_factory.hpp:77] Creating layer Convolution16
I0927 14:49:10.853560  3463 net.cpp:84] Creating Layer Convolution16
I0927 14:49:10.853564  3463 net.cpp:406] Convolution16 <- Eltwise7_M2PELU15_0_split_0
I0927 14:49:10.853567  3463 net.cpp:380] Convolution16 -> Convolution16
I0927 14:49:10.854416  3463 net.cpp:122] Setting up Convolution16
I0927 14:49:10.854425  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.854427  3463 net.cpp:137] Memory required for data: 422419600
I0927 14:49:10.854431  3463 layer_factory.hpp:77] Creating layer BatchNorm16
I0927 14:49:10.854436  3463 net.cpp:84] Creating Layer BatchNorm16
I0927 14:49:10.854439  3463 net.cpp:406] BatchNorm16 <- Convolution16
I0927 14:49:10.854449  3463 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0927 14:49:10.854604  3463 net.cpp:122] Setting up BatchNorm16
I0927 14:49:10.854609  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.854610  3463 net.cpp:137] Memory required for data: 427437200
I0927 14:49:10.854615  3463 layer_factory.hpp:77] Creating layer Scale16
I0927 14:49:10.854619  3463 net.cpp:84] Creating Layer Scale16
I0927 14:49:10.854622  3463 net.cpp:406] Scale16 <- Convolution16
I0927 14:49:10.854625  3463 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0927 14:49:10.854650  3463 layer_factory.hpp:77] Creating layer Scale16
I0927 14:49:10.854725  3463 net.cpp:122] Setting up Scale16
I0927 14:49:10.854730  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.854732  3463 net.cpp:137] Memory required for data: 432454800
I0927 14:49:10.854737  3463 layer_factory.hpp:77] Creating layer M2PELU16
I0927 14:49:10.854742  3463 net.cpp:84] Creating Layer M2PELU16
I0927 14:49:10.854743  3463 net.cpp:406] M2PELU16 <- Convolution16
I0927 14:49:10.854748  3463 net.cpp:367] M2PELU16 -> Convolution16 (in-place)
I0927 14:49:10.854836  3463 net.cpp:122] Setting up M2PELU16
I0927 14:49:10.854841  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.854843  3463 net.cpp:137] Memory required for data: 437472400
I0927 14:49:10.854846  3463 layer_factory.hpp:77] Creating layer Convolution17
I0927 14:49:10.854853  3463 net.cpp:84] Creating Layer Convolution17
I0927 14:49:10.854856  3463 net.cpp:406] Convolution17 <- Convolution16
I0927 14:49:10.854861  3463 net.cpp:380] Convolution17 -> Convolution17
I0927 14:49:10.855413  3463 net.cpp:122] Setting up Convolution17
I0927 14:49:10.855422  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.855423  3463 net.cpp:137] Memory required for data: 442490000
I0927 14:49:10.855427  3463 layer_factory.hpp:77] Creating layer BatchNorm17
I0927 14:49:10.855432  3463 net.cpp:84] Creating Layer BatchNorm17
I0927 14:49:10.855435  3463 net.cpp:406] BatchNorm17 <- Convolution17
I0927 14:49:10.855438  3463 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0927 14:49:10.855567  3463 net.cpp:122] Setting up BatchNorm17
I0927 14:49:10.855571  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.855573  3463 net.cpp:137] Memory required for data: 447507600
I0927 14:49:10.855578  3463 layer_factory.hpp:77] Creating layer Scale17
I0927 14:49:10.855582  3463 net.cpp:84] Creating Layer Scale17
I0927 14:49:10.855585  3463 net.cpp:406] Scale17 <- Convolution17
I0927 14:49:10.855588  3463 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0927 14:49:10.855612  3463 layer_factory.hpp:77] Creating layer Scale17
I0927 14:49:10.855689  3463 net.cpp:122] Setting up Scale17
I0927 14:49:10.855693  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.855695  3463 net.cpp:137] Memory required for data: 452525200
I0927 14:49:10.855698  3463 layer_factory.hpp:77] Creating layer Eltwise8
I0927 14:49:10.855703  3463 net.cpp:84] Creating Layer Eltwise8
I0927 14:49:10.855705  3463 net.cpp:406] Eltwise8 <- Eltwise7_M2PELU15_0_split_1
I0927 14:49:10.855708  3463 net.cpp:406] Eltwise8 <- Convolution17
I0927 14:49:10.855711  3463 net.cpp:380] Eltwise8 -> Eltwise8
I0927 14:49:10.855727  3463 net.cpp:122] Setting up Eltwise8
I0927 14:49:10.855731  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.855732  3463 net.cpp:137] Memory required for data: 457542800
I0927 14:49:10.855736  3463 layer_factory.hpp:77] Creating layer M2PELU17
I0927 14:49:10.855741  3463 net.cpp:84] Creating Layer M2PELU17
I0927 14:49:10.855742  3463 net.cpp:406] M2PELU17 <- Eltwise8
I0927 14:49:10.855746  3463 net.cpp:367] M2PELU17 -> Eltwise8 (in-place)
I0927 14:49:10.855839  3463 net.cpp:122] Setting up M2PELU17
I0927 14:49:10.855844  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.855846  3463 net.cpp:137] Memory required for data: 462560400
I0927 14:49:10.855850  3463 layer_factory.hpp:77] Creating layer Eltwise8_M2PELU17_0_split
I0927 14:49:10.855861  3463 net.cpp:84] Creating Layer Eltwise8_M2PELU17_0_split
I0927 14:49:10.855865  3463 net.cpp:406] Eltwise8_M2PELU17_0_split <- Eltwise8
I0927 14:49:10.855868  3463 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_0
I0927 14:49:10.855873  3463 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_1
I0927 14:49:10.855898  3463 net.cpp:122] Setting up Eltwise8_M2PELU17_0_split
I0927 14:49:10.855902  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.855906  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.855907  3463 net.cpp:137] Memory required for data: 472595600
I0927 14:49:10.855911  3463 layer_factory.hpp:77] Creating layer Convolution18
I0927 14:49:10.855916  3463 net.cpp:84] Creating Layer Convolution18
I0927 14:49:10.855918  3463 net.cpp:406] Convolution18 <- Eltwise8_M2PELU17_0_split_0
I0927 14:49:10.855923  3463 net.cpp:380] Convolution18 -> Convolution18
I0927 14:49:10.856865  3463 net.cpp:122] Setting up Convolution18
I0927 14:49:10.856873  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.856875  3463 net.cpp:137] Memory required for data: 477613200
I0927 14:49:10.856879  3463 layer_factory.hpp:77] Creating layer BatchNorm18
I0927 14:49:10.856884  3463 net.cpp:84] Creating Layer BatchNorm18
I0927 14:49:10.856887  3463 net.cpp:406] BatchNorm18 <- Convolution18
I0927 14:49:10.856890  3463 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0927 14:49:10.857019  3463 net.cpp:122] Setting up BatchNorm18
I0927 14:49:10.857023  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.857025  3463 net.cpp:137] Memory required for data: 482630800
I0927 14:49:10.857030  3463 layer_factory.hpp:77] Creating layer Scale18
I0927 14:49:10.857034  3463 net.cpp:84] Creating Layer Scale18
I0927 14:49:10.857036  3463 net.cpp:406] Scale18 <- Convolution18
I0927 14:49:10.857039  3463 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0927 14:49:10.857065  3463 layer_factory.hpp:77] Creating layer Scale18
I0927 14:49:10.857141  3463 net.cpp:122] Setting up Scale18
I0927 14:49:10.857144  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.857146  3463 net.cpp:137] Memory required for data: 487648400
I0927 14:49:10.857151  3463 layer_factory.hpp:77] Creating layer M2PELU18
I0927 14:49:10.857154  3463 net.cpp:84] Creating Layer M2PELU18
I0927 14:49:10.857156  3463 net.cpp:406] M2PELU18 <- Convolution18
I0927 14:49:10.857161  3463 net.cpp:367] M2PELU18 -> Convolution18 (in-place)
I0927 14:49:10.857242  3463 net.cpp:122] Setting up M2PELU18
I0927 14:49:10.857246  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.857249  3463 net.cpp:137] Memory required for data: 492666000
I0927 14:49:10.857252  3463 layer_factory.hpp:77] Creating layer Convolution19
I0927 14:49:10.857259  3463 net.cpp:84] Creating Layer Convolution19
I0927 14:49:10.857260  3463 net.cpp:406] Convolution19 <- Convolution18
I0927 14:49:10.857265  3463 net.cpp:380] Convolution19 -> Convolution19
I0927 14:49:10.858151  3463 net.cpp:122] Setting up Convolution19
I0927 14:49:10.858160  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.858162  3463 net.cpp:137] Memory required for data: 497683600
I0927 14:49:10.858166  3463 layer_factory.hpp:77] Creating layer BatchNorm19
I0927 14:49:10.858171  3463 net.cpp:84] Creating Layer BatchNorm19
I0927 14:49:10.858175  3463 net.cpp:406] BatchNorm19 <- Convolution19
I0927 14:49:10.858178  3463 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0927 14:49:10.858309  3463 net.cpp:122] Setting up BatchNorm19
I0927 14:49:10.858314  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.858315  3463 net.cpp:137] Memory required for data: 502701200
I0927 14:49:10.858319  3463 layer_factory.hpp:77] Creating layer Scale19
I0927 14:49:10.858325  3463 net.cpp:84] Creating Layer Scale19
I0927 14:49:10.858326  3463 net.cpp:406] Scale19 <- Convolution19
I0927 14:49:10.858330  3463 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0927 14:49:10.858355  3463 layer_factory.hpp:77] Creating layer Scale19
I0927 14:49:10.858441  3463 net.cpp:122] Setting up Scale19
I0927 14:49:10.858446  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.858448  3463 net.cpp:137] Memory required for data: 507718800
I0927 14:49:10.858453  3463 layer_factory.hpp:77] Creating layer Eltwise9
I0927 14:49:10.858458  3463 net.cpp:84] Creating Layer Eltwise9
I0927 14:49:10.858460  3463 net.cpp:406] Eltwise9 <- Eltwise8_M2PELU17_0_split_1
I0927 14:49:10.858463  3463 net.cpp:406] Eltwise9 <- Convolution19
I0927 14:49:10.858466  3463 net.cpp:380] Eltwise9 -> Eltwise9
I0927 14:49:10.858481  3463 net.cpp:122] Setting up Eltwise9
I0927 14:49:10.858485  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.858487  3463 net.cpp:137] Memory required for data: 512736400
I0927 14:49:10.858489  3463 layer_factory.hpp:77] Creating layer M2PELU19
I0927 14:49:10.858494  3463 net.cpp:84] Creating Layer M2PELU19
I0927 14:49:10.858496  3463 net.cpp:406] M2PELU19 <- Eltwise9
I0927 14:49:10.858500  3463 net.cpp:367] M2PELU19 -> Eltwise9 (in-place)
I0927 14:49:10.858610  3463 net.cpp:122] Setting up M2PELU19
I0927 14:49:10.858615  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.858618  3463 net.cpp:137] Memory required for data: 517754000
I0927 14:49:10.858621  3463 layer_factory.hpp:77] Creating layer Eltwise9_M2PELU19_0_split
I0927 14:49:10.858624  3463 net.cpp:84] Creating Layer Eltwise9_M2PELU19_0_split
I0927 14:49:10.858628  3463 net.cpp:406] Eltwise9_M2PELU19_0_split <- Eltwise9
I0927 14:49:10.858631  3463 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_0
I0927 14:49:10.858635  3463 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_1
I0927 14:49:10.858657  3463 net.cpp:122] Setting up Eltwise9_M2PELU19_0_split
I0927 14:49:10.858661  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.858664  3463 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 14:49:10.858666  3463 net.cpp:137] Memory required for data: 527789200
I0927 14:49:10.858669  3463 layer_factory.hpp:77] Creating layer Convolution20
I0927 14:49:10.858676  3463 net.cpp:84] Creating Layer Convolution20
I0927 14:49:10.858680  3463 net.cpp:406] Convolution20 <- Eltwise9_M2PELU19_0_split_0
I0927 14:49:10.858683  3463 net.cpp:380] Convolution20 -> Convolution20
I0927 14:49:10.859879  3463 net.cpp:122] Setting up Convolution20
I0927 14:49:10.859887  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.859889  3463 net.cpp:137] Memory required for data: 530298000
I0927 14:49:10.859895  3463 layer_factory.hpp:77] Creating layer BatchNorm20
I0927 14:49:10.859900  3463 net.cpp:84] Creating Layer BatchNorm20
I0927 14:49:10.859902  3463 net.cpp:406] BatchNorm20 <- Convolution20
I0927 14:49:10.859906  3463 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0927 14:49:10.860056  3463 net.cpp:122] Setting up BatchNorm20
I0927 14:49:10.860060  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.860064  3463 net.cpp:137] Memory required for data: 532806800
I0927 14:49:10.860069  3463 layer_factory.hpp:77] Creating layer Scale20
I0927 14:49:10.860072  3463 net.cpp:84] Creating Layer Scale20
I0927 14:49:10.860074  3463 net.cpp:406] Scale20 <- Convolution20
I0927 14:49:10.860079  3463 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0927 14:49:10.860105  3463 layer_factory.hpp:77] Creating layer Scale20
I0927 14:49:10.860203  3463 net.cpp:122] Setting up Scale20
I0927 14:49:10.860206  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.860208  3463 net.cpp:137] Memory required for data: 535315600
I0927 14:49:10.860213  3463 layer_factory.hpp:77] Creating layer Convolution21
I0927 14:49:10.860219  3463 net.cpp:84] Creating Layer Convolution21
I0927 14:49:10.860221  3463 net.cpp:406] Convolution21 <- Eltwise9_M2PELU19_0_split_1
I0927 14:49:10.860226  3463 net.cpp:380] Convolution21 -> Convolution21
I0927 14:49:10.862041  3463 net.cpp:122] Setting up Convolution21
I0927 14:49:10.862051  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.862059  3463 net.cpp:137] Memory required for data: 537824400
I0927 14:49:10.862066  3463 layer_factory.hpp:77] Creating layer BatchNorm21
I0927 14:49:10.862069  3463 net.cpp:84] Creating Layer BatchNorm21
I0927 14:49:10.862072  3463 net.cpp:406] BatchNorm21 <- Convolution21
I0927 14:49:10.862076  3463 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0927 14:49:10.862222  3463 net.cpp:122] Setting up BatchNorm21
I0927 14:49:10.862226  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.862228  3463 net.cpp:137] Memory required for data: 540333200
I0927 14:49:10.862233  3463 layer_factory.hpp:77] Creating layer Scale21
I0927 14:49:10.862238  3463 net.cpp:84] Creating Layer Scale21
I0927 14:49:10.862241  3463 net.cpp:406] Scale21 <- Convolution21
I0927 14:49:10.862243  3463 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0927 14:49:10.862291  3463 layer_factory.hpp:77] Creating layer Scale21
I0927 14:49:10.862368  3463 net.cpp:122] Setting up Scale21
I0927 14:49:10.862373  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.862375  3463 net.cpp:137] Memory required for data: 542842000
I0927 14:49:10.862380  3463 layer_factory.hpp:77] Creating layer M2PELU20
I0927 14:49:10.862385  3463 net.cpp:84] Creating Layer M2PELU20
I0927 14:49:10.862387  3463 net.cpp:406] M2PELU20 <- Convolution21
I0927 14:49:10.862391  3463 net.cpp:367] M2PELU20 -> Convolution21 (in-place)
I0927 14:49:10.862478  3463 net.cpp:122] Setting up M2PELU20
I0927 14:49:10.862483  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.862484  3463 net.cpp:137] Memory required for data: 545350800
I0927 14:49:10.862488  3463 layer_factory.hpp:77] Creating layer Convolution22
I0927 14:49:10.862495  3463 net.cpp:84] Creating Layer Convolution22
I0927 14:49:10.862498  3463 net.cpp:406] Convolution22 <- Convolution21
I0927 14:49:10.862502  3463 net.cpp:380] Convolution22 -> Convolution22
I0927 14:49:10.863587  3463 net.cpp:122] Setting up Convolution22
I0927 14:49:10.863596  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.863600  3463 net.cpp:137] Memory required for data: 547859600
I0927 14:49:10.863603  3463 layer_factory.hpp:77] Creating layer BatchNorm22
I0927 14:49:10.863608  3463 net.cpp:84] Creating Layer BatchNorm22
I0927 14:49:10.863611  3463 net.cpp:406] BatchNorm22 <- Convolution22
I0927 14:49:10.863615  3463 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0927 14:49:10.863749  3463 net.cpp:122] Setting up BatchNorm22
I0927 14:49:10.863754  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.863755  3463 net.cpp:137] Memory required for data: 550368400
I0927 14:49:10.863759  3463 layer_factory.hpp:77] Creating layer Scale22
I0927 14:49:10.863765  3463 net.cpp:84] Creating Layer Scale22
I0927 14:49:10.863767  3463 net.cpp:406] Scale22 <- Convolution22
I0927 14:49:10.863770  3463 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0927 14:49:10.863796  3463 layer_factory.hpp:77] Creating layer Scale22
I0927 14:49:10.863883  3463 net.cpp:122] Setting up Scale22
I0927 14:49:10.863888  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.863889  3463 net.cpp:137] Memory required for data: 552877200
I0927 14:49:10.863893  3463 layer_factory.hpp:77] Creating layer Eltwise10
I0927 14:49:10.863898  3463 net.cpp:84] Creating Layer Eltwise10
I0927 14:49:10.863901  3463 net.cpp:406] Eltwise10 <- Convolution20
I0927 14:49:10.863904  3463 net.cpp:406] Eltwise10 <- Convolution22
I0927 14:49:10.863907  3463 net.cpp:380] Eltwise10 -> Eltwise10
I0927 14:49:10.863924  3463 net.cpp:122] Setting up Eltwise10
I0927 14:49:10.863929  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.863930  3463 net.cpp:137] Memory required for data: 555386000
I0927 14:49:10.863932  3463 layer_factory.hpp:77] Creating layer M2PELU21
I0927 14:49:10.863937  3463 net.cpp:84] Creating Layer M2PELU21
I0927 14:49:10.863940  3463 net.cpp:406] M2PELU21 <- Eltwise10
I0927 14:49:10.863943  3463 net.cpp:367] M2PELU21 -> Eltwise10 (in-place)
I0927 14:49:10.864027  3463 net.cpp:122] Setting up M2PELU21
I0927 14:49:10.864038  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.864042  3463 net.cpp:137] Memory required for data: 557894800
I0927 14:49:10.864045  3463 layer_factory.hpp:77] Creating layer Eltwise10_M2PELU21_0_split
I0927 14:49:10.864050  3463 net.cpp:84] Creating Layer Eltwise10_M2PELU21_0_split
I0927 14:49:10.864053  3463 net.cpp:406] Eltwise10_M2PELU21_0_split <- Eltwise10
I0927 14:49:10.864056  3463 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_0
I0927 14:49:10.864060  3463 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_1
I0927 14:49:10.864085  3463 net.cpp:122] Setting up Eltwise10_M2PELU21_0_split
I0927 14:49:10.864089  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.864092  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.864094  3463 net.cpp:137] Memory required for data: 562912400
I0927 14:49:10.864096  3463 layer_factory.hpp:77] Creating layer Convolution23
I0927 14:49:10.864102  3463 net.cpp:84] Creating Layer Convolution23
I0927 14:49:10.864105  3463 net.cpp:406] Convolution23 <- Eltwise10_M2PELU21_0_split_0
I0927 14:49:10.864110  3463 net.cpp:380] Convolution23 -> Convolution23
I0927 14:49:10.865483  3463 net.cpp:122] Setting up Convolution23
I0927 14:49:10.865492  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.865494  3463 net.cpp:137] Memory required for data: 565421200
I0927 14:49:10.865499  3463 layer_factory.hpp:77] Creating layer BatchNorm23
I0927 14:49:10.865504  3463 net.cpp:84] Creating Layer BatchNorm23
I0927 14:49:10.865507  3463 net.cpp:406] BatchNorm23 <- Convolution23
I0927 14:49:10.865511  3463 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0927 14:49:10.865648  3463 net.cpp:122] Setting up BatchNorm23
I0927 14:49:10.865653  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.865654  3463 net.cpp:137] Memory required for data: 567930000
I0927 14:49:10.865659  3463 layer_factory.hpp:77] Creating layer Scale23
I0927 14:49:10.865664  3463 net.cpp:84] Creating Layer Scale23
I0927 14:49:10.865666  3463 net.cpp:406] Scale23 <- Convolution23
I0927 14:49:10.865669  3463 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0927 14:49:10.865695  3463 layer_factory.hpp:77] Creating layer Scale23
I0927 14:49:10.865773  3463 net.cpp:122] Setting up Scale23
I0927 14:49:10.865778  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.865780  3463 net.cpp:137] Memory required for data: 570438800
I0927 14:49:10.865784  3463 layer_factory.hpp:77] Creating layer M2PELU22
I0927 14:49:10.865789  3463 net.cpp:84] Creating Layer M2PELU22
I0927 14:49:10.865792  3463 net.cpp:406] M2PELU22 <- Convolution23
I0927 14:49:10.865795  3463 net.cpp:367] M2PELU22 -> Convolution23 (in-place)
I0927 14:49:10.865877  3463 net.cpp:122] Setting up M2PELU22
I0927 14:49:10.865882  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.865885  3463 net.cpp:137] Memory required for data: 572947600
I0927 14:49:10.865888  3463 layer_factory.hpp:77] Creating layer Convolution24
I0927 14:49:10.865893  3463 net.cpp:84] Creating Layer Convolution24
I0927 14:49:10.865896  3463 net.cpp:406] Convolution24 <- Convolution23
I0927 14:49:10.865900  3463 net.cpp:380] Convolution24 -> Convolution24
I0927 14:49:10.866977  3463 net.cpp:122] Setting up Convolution24
I0927 14:49:10.866987  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.866989  3463 net.cpp:137] Memory required for data: 575456400
I0927 14:49:10.866994  3463 layer_factory.hpp:77] Creating layer BatchNorm24
I0927 14:49:10.866998  3463 net.cpp:84] Creating Layer BatchNorm24
I0927 14:49:10.867002  3463 net.cpp:406] BatchNorm24 <- Convolution24
I0927 14:49:10.867005  3463 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0927 14:49:10.867137  3463 net.cpp:122] Setting up BatchNorm24
I0927 14:49:10.867141  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.867144  3463 net.cpp:137] Memory required for data: 577965200
I0927 14:49:10.867148  3463 layer_factory.hpp:77] Creating layer Scale24
I0927 14:49:10.867158  3463 net.cpp:84] Creating Layer Scale24
I0927 14:49:10.867161  3463 net.cpp:406] Scale24 <- Convolution24
I0927 14:49:10.867164  3463 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0927 14:49:10.867192  3463 layer_factory.hpp:77] Creating layer Scale24
I0927 14:49:10.867267  3463 net.cpp:122] Setting up Scale24
I0927 14:49:10.867271  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.867274  3463 net.cpp:137] Memory required for data: 580474000
I0927 14:49:10.867277  3463 layer_factory.hpp:77] Creating layer Eltwise11
I0927 14:49:10.867281  3463 net.cpp:84] Creating Layer Eltwise11
I0927 14:49:10.867285  3463 net.cpp:406] Eltwise11 <- Eltwise10_M2PELU21_0_split_1
I0927 14:49:10.867286  3463 net.cpp:406] Eltwise11 <- Convolution24
I0927 14:49:10.867290  3463 net.cpp:380] Eltwise11 -> Eltwise11
I0927 14:49:10.867305  3463 net.cpp:122] Setting up Eltwise11
I0927 14:49:10.867310  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.867311  3463 net.cpp:137] Memory required for data: 582982800
I0927 14:49:10.867313  3463 layer_factory.hpp:77] Creating layer M2PELU23
I0927 14:49:10.867318  3463 net.cpp:84] Creating Layer M2PELU23
I0927 14:49:10.867321  3463 net.cpp:406] M2PELU23 <- Eltwise11
I0927 14:49:10.867324  3463 net.cpp:367] M2PELU23 -> Eltwise11 (in-place)
I0927 14:49:10.867406  3463 net.cpp:122] Setting up M2PELU23
I0927 14:49:10.867410  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.867413  3463 net.cpp:137] Memory required for data: 585491600
I0927 14:49:10.867416  3463 layer_factory.hpp:77] Creating layer Eltwise11_M2PELU23_0_split
I0927 14:49:10.867420  3463 net.cpp:84] Creating Layer Eltwise11_M2PELU23_0_split
I0927 14:49:10.867422  3463 net.cpp:406] Eltwise11_M2PELU23_0_split <- Eltwise11
I0927 14:49:10.867425  3463 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_0
I0927 14:49:10.867430  3463 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_1
I0927 14:49:10.867452  3463 net.cpp:122] Setting up Eltwise11_M2PELU23_0_split
I0927 14:49:10.867456  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.867460  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.867461  3463 net.cpp:137] Memory required for data: 590509200
I0927 14:49:10.867463  3463 layer_factory.hpp:77] Creating layer Convolution25
I0927 14:49:10.867470  3463 net.cpp:84] Creating Layer Convolution25
I0927 14:49:10.867472  3463 net.cpp:406] Convolution25 <- Eltwise11_M2PELU23_0_split_0
I0927 14:49:10.867475  3463 net.cpp:380] Convolution25 -> Convolution25
I0927 14:49:10.868520  3463 net.cpp:122] Setting up Convolution25
I0927 14:49:10.868528  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.868530  3463 net.cpp:137] Memory required for data: 593018000
I0927 14:49:10.868535  3463 layer_factory.hpp:77] Creating layer BatchNorm25
I0927 14:49:10.868541  3463 net.cpp:84] Creating Layer BatchNorm25
I0927 14:49:10.868544  3463 net.cpp:406] BatchNorm25 <- Convolution25
I0927 14:49:10.868549  3463 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0927 14:49:10.868685  3463 net.cpp:122] Setting up BatchNorm25
I0927 14:49:10.868688  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.868690  3463 net.cpp:137] Memory required for data: 595526800
I0927 14:49:10.868695  3463 layer_factory.hpp:77] Creating layer Scale25
I0927 14:49:10.868700  3463 net.cpp:84] Creating Layer Scale25
I0927 14:49:10.868703  3463 net.cpp:406] Scale25 <- Convolution25
I0927 14:49:10.868706  3463 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0927 14:49:10.868732  3463 layer_factory.hpp:77] Creating layer Scale25
I0927 14:49:10.868809  3463 net.cpp:122] Setting up Scale25
I0927 14:49:10.868813  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.868815  3463 net.cpp:137] Memory required for data: 598035600
I0927 14:49:10.868818  3463 layer_factory.hpp:77] Creating layer M2PELU24
I0927 14:49:10.868832  3463 net.cpp:84] Creating Layer M2PELU24
I0927 14:49:10.868834  3463 net.cpp:406] M2PELU24 <- Convolution25
I0927 14:49:10.868844  3463 net.cpp:367] M2PELU24 -> Convolution25 (in-place)
I0927 14:49:10.868927  3463 net.cpp:122] Setting up M2PELU24
I0927 14:49:10.868932  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.868933  3463 net.cpp:137] Memory required for data: 600544400
I0927 14:49:10.868937  3463 layer_factory.hpp:77] Creating layer Convolution26
I0927 14:49:10.868943  3463 net.cpp:84] Creating Layer Convolution26
I0927 14:49:10.868945  3463 net.cpp:406] Convolution26 <- Convolution25
I0927 14:49:10.868950  3463 net.cpp:380] Convolution26 -> Convolution26
I0927 14:49:10.870002  3463 net.cpp:122] Setting up Convolution26
I0927 14:49:10.870012  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.870014  3463 net.cpp:137] Memory required for data: 603053200
I0927 14:49:10.870018  3463 layer_factory.hpp:77] Creating layer BatchNorm26
I0927 14:49:10.870023  3463 net.cpp:84] Creating Layer BatchNorm26
I0927 14:49:10.870025  3463 net.cpp:406] BatchNorm26 <- Convolution26
I0927 14:49:10.870030  3463 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0927 14:49:10.870165  3463 net.cpp:122] Setting up BatchNorm26
I0927 14:49:10.870170  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.870172  3463 net.cpp:137] Memory required for data: 605562000
I0927 14:49:10.870177  3463 layer_factory.hpp:77] Creating layer Scale26
I0927 14:49:10.870180  3463 net.cpp:84] Creating Layer Scale26
I0927 14:49:10.870183  3463 net.cpp:406] Scale26 <- Convolution26
I0927 14:49:10.870187  3463 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0927 14:49:10.870213  3463 layer_factory.hpp:77] Creating layer Scale26
I0927 14:49:10.870292  3463 net.cpp:122] Setting up Scale26
I0927 14:49:10.870296  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.870298  3463 net.cpp:137] Memory required for data: 608070800
I0927 14:49:10.870302  3463 layer_factory.hpp:77] Creating layer Eltwise12
I0927 14:49:10.870306  3463 net.cpp:84] Creating Layer Eltwise12
I0927 14:49:10.870308  3463 net.cpp:406] Eltwise12 <- Eltwise11_M2PELU23_0_split_1
I0927 14:49:10.870311  3463 net.cpp:406] Eltwise12 <- Convolution26
I0927 14:49:10.870314  3463 net.cpp:380] Eltwise12 -> Eltwise12
I0927 14:49:10.870332  3463 net.cpp:122] Setting up Eltwise12
I0927 14:49:10.870337  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.870338  3463 net.cpp:137] Memory required for data: 610579600
I0927 14:49:10.870340  3463 layer_factory.hpp:77] Creating layer M2PELU25
I0927 14:49:10.870345  3463 net.cpp:84] Creating Layer M2PELU25
I0927 14:49:10.870347  3463 net.cpp:406] M2PELU25 <- Eltwise12
I0927 14:49:10.870352  3463 net.cpp:367] M2PELU25 -> Eltwise12 (in-place)
I0927 14:49:10.870435  3463 net.cpp:122] Setting up M2PELU25
I0927 14:49:10.870440  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.870441  3463 net.cpp:137] Memory required for data: 613088400
I0927 14:49:10.870445  3463 layer_factory.hpp:77] Creating layer Eltwise12_M2PELU25_0_split
I0927 14:49:10.870457  3463 net.cpp:84] Creating Layer Eltwise12_M2PELU25_0_split
I0927 14:49:10.870460  3463 net.cpp:406] Eltwise12_M2PELU25_0_split <- Eltwise12
I0927 14:49:10.870463  3463 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_0
I0927 14:49:10.870472  3463 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_1
I0927 14:49:10.870496  3463 net.cpp:122] Setting up Eltwise12_M2PELU25_0_split
I0927 14:49:10.870501  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.870503  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.870506  3463 net.cpp:137] Memory required for data: 618106000
I0927 14:49:10.870508  3463 layer_factory.hpp:77] Creating layer Convolution27
I0927 14:49:10.870514  3463 net.cpp:84] Creating Layer Convolution27
I0927 14:49:10.870517  3463 net.cpp:406] Convolution27 <- Eltwise12_M2PELU25_0_split_0
I0927 14:49:10.870537  3463 net.cpp:380] Convolution27 -> Convolution27
I0927 14:49:10.871265  3463 net.cpp:122] Setting up Convolution27
I0927 14:49:10.871273  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.871281  3463 net.cpp:137] Memory required for data: 620614800
I0927 14:49:10.871285  3463 layer_factory.hpp:77] Creating layer BatchNorm27
I0927 14:49:10.871290  3463 net.cpp:84] Creating Layer BatchNorm27
I0927 14:49:10.871294  3463 net.cpp:406] BatchNorm27 <- Convolution27
I0927 14:49:10.871296  3463 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0927 14:49:10.871429  3463 net.cpp:122] Setting up BatchNorm27
I0927 14:49:10.871433  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.871435  3463 net.cpp:137] Memory required for data: 623123600
I0927 14:49:10.871440  3463 layer_factory.hpp:77] Creating layer Scale27
I0927 14:49:10.871444  3463 net.cpp:84] Creating Layer Scale27
I0927 14:49:10.871446  3463 net.cpp:406] Scale27 <- Convolution27
I0927 14:49:10.871450  3463 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0927 14:49:10.871475  3463 layer_factory.hpp:77] Creating layer Scale27
I0927 14:49:10.871551  3463 net.cpp:122] Setting up Scale27
I0927 14:49:10.871554  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.871556  3463 net.cpp:137] Memory required for data: 625632400
I0927 14:49:10.871559  3463 layer_factory.hpp:77] Creating layer M2PELU26
I0927 14:49:10.871564  3463 net.cpp:84] Creating Layer M2PELU26
I0927 14:49:10.871567  3463 net.cpp:406] M2PELU26 <- Convolution27
I0927 14:49:10.871572  3463 net.cpp:367] M2PELU26 -> Convolution27 (in-place)
I0927 14:49:10.871651  3463 net.cpp:122] Setting up M2PELU26
I0927 14:49:10.871655  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.871657  3463 net.cpp:137] Memory required for data: 628141200
I0927 14:49:10.871661  3463 layer_factory.hpp:77] Creating layer Convolution28
I0927 14:49:10.871667  3463 net.cpp:84] Creating Layer Convolution28
I0927 14:49:10.871670  3463 net.cpp:406] Convolution28 <- Convolution27
I0927 14:49:10.871673  3463 net.cpp:380] Convolution28 -> Convolution28
I0927 14:49:10.872691  3463 net.cpp:122] Setting up Convolution28
I0927 14:49:10.872699  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.872702  3463 net.cpp:137] Memory required for data: 630650000
I0927 14:49:10.872706  3463 layer_factory.hpp:77] Creating layer BatchNorm28
I0927 14:49:10.872711  3463 net.cpp:84] Creating Layer BatchNorm28
I0927 14:49:10.872714  3463 net.cpp:406] BatchNorm28 <- Convolution28
I0927 14:49:10.872717  3463 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0927 14:49:10.872851  3463 net.cpp:122] Setting up BatchNorm28
I0927 14:49:10.872855  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.872858  3463 net.cpp:137] Memory required for data: 633158800
I0927 14:49:10.872862  3463 layer_factory.hpp:77] Creating layer Scale28
I0927 14:49:10.872866  3463 net.cpp:84] Creating Layer Scale28
I0927 14:49:10.872869  3463 net.cpp:406] Scale28 <- Convolution28
I0927 14:49:10.872871  3463 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0927 14:49:10.872898  3463 layer_factory.hpp:77] Creating layer Scale28
I0927 14:49:10.872972  3463 net.cpp:122] Setting up Scale28
I0927 14:49:10.872977  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.872978  3463 net.cpp:137] Memory required for data: 635667600
I0927 14:49:10.872982  3463 layer_factory.hpp:77] Creating layer Eltwise13
I0927 14:49:10.872987  3463 net.cpp:84] Creating Layer Eltwise13
I0927 14:49:10.872989  3463 net.cpp:406] Eltwise13 <- Eltwise12_M2PELU25_0_split_1
I0927 14:49:10.872992  3463 net.cpp:406] Eltwise13 <- Convolution28
I0927 14:49:10.872995  3463 net.cpp:380] Eltwise13 -> Eltwise13
I0927 14:49:10.873010  3463 net.cpp:122] Setting up Eltwise13
I0927 14:49:10.873014  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.873016  3463 net.cpp:137] Memory required for data: 638176400
I0927 14:49:10.873018  3463 layer_factory.hpp:77] Creating layer M2PELU27
I0927 14:49:10.873023  3463 net.cpp:84] Creating Layer M2PELU27
I0927 14:49:10.873025  3463 net.cpp:406] M2PELU27 <- Eltwise13
I0927 14:49:10.873028  3463 net.cpp:367] M2PELU27 -> Eltwise13 (in-place)
I0927 14:49:10.873117  3463 net.cpp:122] Setting up M2PELU27
I0927 14:49:10.873122  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.873124  3463 net.cpp:137] Memory required for data: 640685200
I0927 14:49:10.873128  3463 layer_factory.hpp:77] Creating layer Eltwise13_M2PELU27_0_split
I0927 14:49:10.873132  3463 net.cpp:84] Creating Layer Eltwise13_M2PELU27_0_split
I0927 14:49:10.873134  3463 net.cpp:406] Eltwise13_M2PELU27_0_split <- Eltwise13
I0927 14:49:10.873137  3463 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_0
I0927 14:49:10.873142  3463 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_1
I0927 14:49:10.873167  3463 net.cpp:122] Setting up Eltwise13_M2PELU27_0_split
I0927 14:49:10.873169  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.873172  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.873174  3463 net.cpp:137] Memory required for data: 645702800
I0927 14:49:10.873176  3463 layer_factory.hpp:77] Creating layer Convolution29
I0927 14:49:10.873183  3463 net.cpp:84] Creating Layer Convolution29
I0927 14:49:10.873185  3463 net.cpp:406] Convolution29 <- Eltwise13_M2PELU27_0_split_0
I0927 14:49:10.873189  3463 net.cpp:380] Convolution29 -> Convolution29
I0927 14:49:10.874249  3463 net.cpp:122] Setting up Convolution29
I0927 14:49:10.874258  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.874260  3463 net.cpp:137] Memory required for data: 648211600
I0927 14:49:10.874264  3463 layer_factory.hpp:77] Creating layer BatchNorm29
I0927 14:49:10.874270  3463 net.cpp:84] Creating Layer BatchNorm29
I0927 14:49:10.874274  3463 net.cpp:406] BatchNorm29 <- Convolution29
I0927 14:49:10.874276  3463 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0927 14:49:10.874413  3463 net.cpp:122] Setting up BatchNorm29
I0927 14:49:10.874418  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.874420  3463 net.cpp:137] Memory required for data: 650720400
I0927 14:49:10.874424  3463 layer_factory.hpp:77] Creating layer Scale29
I0927 14:49:10.874429  3463 net.cpp:84] Creating Layer Scale29
I0927 14:49:10.874433  3463 net.cpp:406] Scale29 <- Convolution29
I0927 14:49:10.874435  3463 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0927 14:49:10.874462  3463 layer_factory.hpp:77] Creating layer Scale29
I0927 14:49:10.874567  3463 net.cpp:122] Setting up Scale29
I0927 14:49:10.874572  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.874574  3463 net.cpp:137] Memory required for data: 653229200
I0927 14:49:10.874594  3463 layer_factory.hpp:77] Creating layer M2PELU28
I0927 14:49:10.874601  3463 net.cpp:84] Creating Layer M2PELU28
I0927 14:49:10.874604  3463 net.cpp:406] M2PELU28 <- Convolution29
I0927 14:49:10.874608  3463 net.cpp:367] M2PELU28 -> Convolution29 (in-place)
I0927 14:49:10.874696  3463 net.cpp:122] Setting up M2PELU28
I0927 14:49:10.874701  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.874703  3463 net.cpp:137] Memory required for data: 655738000
I0927 14:49:10.874707  3463 layer_factory.hpp:77] Creating layer Convolution30
I0927 14:49:10.874713  3463 net.cpp:84] Creating Layer Convolution30
I0927 14:49:10.874716  3463 net.cpp:406] Convolution30 <- Convolution29
I0927 14:49:10.874721  3463 net.cpp:380] Convolution30 -> Convolution30
I0927 14:49:10.875771  3463 net.cpp:122] Setting up Convolution30
I0927 14:49:10.875779  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.875782  3463 net.cpp:137] Memory required for data: 658246800
I0927 14:49:10.875787  3463 layer_factory.hpp:77] Creating layer BatchNorm30
I0927 14:49:10.875792  3463 net.cpp:84] Creating Layer BatchNorm30
I0927 14:49:10.875794  3463 net.cpp:406] BatchNorm30 <- Convolution30
I0927 14:49:10.875798  3463 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0927 14:49:10.875931  3463 net.cpp:122] Setting up BatchNorm30
I0927 14:49:10.875934  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.875936  3463 net.cpp:137] Memory required for data: 660755600
I0927 14:49:10.875947  3463 layer_factory.hpp:77] Creating layer Scale30
I0927 14:49:10.875952  3463 net.cpp:84] Creating Layer Scale30
I0927 14:49:10.875954  3463 net.cpp:406] Scale30 <- Convolution30
I0927 14:49:10.875958  3463 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0927 14:49:10.875984  3463 layer_factory.hpp:77] Creating layer Scale30
I0927 14:49:10.876061  3463 net.cpp:122] Setting up Scale30
I0927 14:49:10.876065  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.876067  3463 net.cpp:137] Memory required for data: 663264400
I0927 14:49:10.876071  3463 layer_factory.hpp:77] Creating layer Eltwise14
I0927 14:49:10.876075  3463 net.cpp:84] Creating Layer Eltwise14
I0927 14:49:10.876077  3463 net.cpp:406] Eltwise14 <- Eltwise13_M2PELU27_0_split_1
I0927 14:49:10.876080  3463 net.cpp:406] Eltwise14 <- Convolution30
I0927 14:49:10.876085  3463 net.cpp:380] Eltwise14 -> Eltwise14
I0927 14:49:10.876101  3463 net.cpp:122] Setting up Eltwise14
I0927 14:49:10.876104  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.876106  3463 net.cpp:137] Memory required for data: 665773200
I0927 14:49:10.876108  3463 layer_factory.hpp:77] Creating layer M2PELU29
I0927 14:49:10.876112  3463 net.cpp:84] Creating Layer M2PELU29
I0927 14:49:10.876114  3463 net.cpp:406] M2PELU29 <- Eltwise14
I0927 14:49:10.876118  3463 net.cpp:367] M2PELU29 -> Eltwise14 (in-place)
I0927 14:49:10.876201  3463 net.cpp:122] Setting up M2PELU29
I0927 14:49:10.876205  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.876207  3463 net.cpp:137] Memory required for data: 668282000
I0927 14:49:10.876211  3463 layer_factory.hpp:77] Creating layer Eltwise14_M2PELU29_0_split
I0927 14:49:10.876215  3463 net.cpp:84] Creating Layer Eltwise14_M2PELU29_0_split
I0927 14:49:10.876217  3463 net.cpp:406] Eltwise14_M2PELU29_0_split <- Eltwise14
I0927 14:49:10.876220  3463 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_0
I0927 14:49:10.876224  3463 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_1
I0927 14:49:10.876247  3463 net.cpp:122] Setting up Eltwise14_M2PELU29_0_split
I0927 14:49:10.876251  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.876255  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.876256  3463 net.cpp:137] Memory required for data: 673299600
I0927 14:49:10.876258  3463 layer_factory.hpp:77] Creating layer Convolution31
I0927 14:49:10.876263  3463 net.cpp:84] Creating Layer Convolution31
I0927 14:49:10.876266  3463 net.cpp:406] Convolution31 <- Eltwise14_M2PELU29_0_split_0
I0927 14:49:10.876271  3463 net.cpp:380] Convolution31 -> Convolution31
I0927 14:49:10.877292  3463 net.cpp:122] Setting up Convolution31
I0927 14:49:10.877301  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.877303  3463 net.cpp:137] Memory required for data: 675808400
I0927 14:49:10.877307  3463 layer_factory.hpp:77] Creating layer BatchNorm31
I0927 14:49:10.877313  3463 net.cpp:84] Creating Layer BatchNorm31
I0927 14:49:10.877315  3463 net.cpp:406] BatchNorm31 <- Convolution31
I0927 14:49:10.877319  3463 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0927 14:49:10.877456  3463 net.cpp:122] Setting up BatchNorm31
I0927 14:49:10.877460  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.877462  3463 net.cpp:137] Memory required for data: 678317200
I0927 14:49:10.877467  3463 layer_factory.hpp:77] Creating layer Scale31
I0927 14:49:10.877471  3463 net.cpp:84] Creating Layer Scale31
I0927 14:49:10.877473  3463 net.cpp:406] Scale31 <- Convolution31
I0927 14:49:10.877476  3463 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0927 14:49:10.877503  3463 layer_factory.hpp:77] Creating layer Scale31
I0927 14:49:10.877579  3463 net.cpp:122] Setting up Scale31
I0927 14:49:10.877583  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.877585  3463 net.cpp:137] Memory required for data: 680826000
I0927 14:49:10.877589  3463 layer_factory.hpp:77] Creating layer M2PELU30
I0927 14:49:10.877594  3463 net.cpp:84] Creating Layer M2PELU30
I0927 14:49:10.877601  3463 net.cpp:406] M2PELU30 <- Convolution31
I0927 14:49:10.877606  3463 net.cpp:367] M2PELU30 -> Convolution31 (in-place)
I0927 14:49:10.877692  3463 net.cpp:122] Setting up M2PELU30
I0927 14:49:10.877697  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.877699  3463 net.cpp:137] Memory required for data: 683334800
I0927 14:49:10.877702  3463 layer_factory.hpp:77] Creating layer Convolution32
I0927 14:49:10.877709  3463 net.cpp:84] Creating Layer Convolution32
I0927 14:49:10.877712  3463 net.cpp:406] Convolution32 <- Convolution31
I0927 14:49:10.877715  3463 net.cpp:380] Convolution32 -> Convolution32
I0927 14:49:10.878785  3463 net.cpp:122] Setting up Convolution32
I0927 14:49:10.878793  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.878796  3463 net.cpp:137] Memory required for data: 685843600
I0927 14:49:10.878800  3463 layer_factory.hpp:77] Creating layer BatchNorm32
I0927 14:49:10.878805  3463 net.cpp:84] Creating Layer BatchNorm32
I0927 14:49:10.878808  3463 net.cpp:406] BatchNorm32 <- Convolution32
I0927 14:49:10.878811  3463 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I0927 14:49:10.878943  3463 net.cpp:122] Setting up BatchNorm32
I0927 14:49:10.878947  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.878949  3463 net.cpp:137] Memory required for data: 688352400
I0927 14:49:10.878954  3463 layer_factory.hpp:77] Creating layer Scale32
I0927 14:49:10.878959  3463 net.cpp:84] Creating Layer Scale32
I0927 14:49:10.878962  3463 net.cpp:406] Scale32 <- Convolution32
I0927 14:49:10.878964  3463 net.cpp:367] Scale32 -> Convolution32 (in-place)
I0927 14:49:10.878990  3463 layer_factory.hpp:77] Creating layer Scale32
I0927 14:49:10.879067  3463 net.cpp:122] Setting up Scale32
I0927 14:49:10.879071  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.879073  3463 net.cpp:137] Memory required for data: 690861200
I0927 14:49:10.879076  3463 layer_factory.hpp:77] Creating layer Eltwise15
I0927 14:49:10.879081  3463 net.cpp:84] Creating Layer Eltwise15
I0927 14:49:10.879083  3463 net.cpp:406] Eltwise15 <- Eltwise14_M2PELU29_0_split_1
I0927 14:49:10.879086  3463 net.cpp:406] Eltwise15 <- Convolution32
I0927 14:49:10.879089  3463 net.cpp:380] Eltwise15 -> Eltwise15
I0927 14:49:10.879106  3463 net.cpp:122] Setting up Eltwise15
I0927 14:49:10.879109  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.879112  3463 net.cpp:137] Memory required for data: 693370000
I0927 14:49:10.879113  3463 layer_factory.hpp:77] Creating layer M2PELU31
I0927 14:49:10.879118  3463 net.cpp:84] Creating Layer M2PELU31
I0927 14:49:10.879120  3463 net.cpp:406] M2PELU31 <- Eltwise15
I0927 14:49:10.879123  3463 net.cpp:367] M2PELU31 -> Eltwise15 (in-place)
I0927 14:49:10.879206  3463 net.cpp:122] Setting up M2PELU31
I0927 14:49:10.879210  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.879212  3463 net.cpp:137] Memory required for data: 695878800
I0927 14:49:10.879215  3463 layer_factory.hpp:77] Creating layer Eltwise15_M2PELU31_0_split
I0927 14:49:10.879220  3463 net.cpp:84] Creating Layer Eltwise15_M2PELU31_0_split
I0927 14:49:10.879222  3463 net.cpp:406] Eltwise15_M2PELU31_0_split <- Eltwise15
I0927 14:49:10.879225  3463 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_0
I0927 14:49:10.879230  3463 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_1
I0927 14:49:10.879253  3463 net.cpp:122] Setting up Eltwise15_M2PELU31_0_split
I0927 14:49:10.879256  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.879259  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.879261  3463 net.cpp:137] Memory required for data: 700896400
I0927 14:49:10.879263  3463 layer_factory.hpp:77] Creating layer Convolution33
I0927 14:49:10.879268  3463 net.cpp:84] Creating Layer Convolution33
I0927 14:49:10.879271  3463 net.cpp:406] Convolution33 <- Eltwise15_M2PELU31_0_split_0
I0927 14:49:10.879277  3463 net.cpp:380] Convolution33 -> Convolution33
I0927 14:49:10.880619  3463 net.cpp:122] Setting up Convolution33
I0927 14:49:10.880626  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.880628  3463 net.cpp:137] Memory required for data: 703405200
I0927 14:49:10.880633  3463 layer_factory.hpp:77] Creating layer BatchNorm33
I0927 14:49:10.880638  3463 net.cpp:84] Creating Layer BatchNorm33
I0927 14:49:10.880640  3463 net.cpp:406] BatchNorm33 <- Convolution33
I0927 14:49:10.880645  3463 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I0927 14:49:10.880782  3463 net.cpp:122] Setting up BatchNorm33
I0927 14:49:10.880786  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.880789  3463 net.cpp:137] Memory required for data: 705914000
I0927 14:49:10.880794  3463 layer_factory.hpp:77] Creating layer Scale33
I0927 14:49:10.880798  3463 net.cpp:84] Creating Layer Scale33
I0927 14:49:10.880800  3463 net.cpp:406] Scale33 <- Convolution33
I0927 14:49:10.880803  3463 net.cpp:367] Scale33 -> Convolution33 (in-place)
I0927 14:49:10.880831  3463 layer_factory.hpp:77] Creating layer Scale33
I0927 14:49:10.880908  3463 net.cpp:122] Setting up Scale33
I0927 14:49:10.880911  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.880913  3463 net.cpp:137] Memory required for data: 708422800
I0927 14:49:10.880918  3463 layer_factory.hpp:77] Creating layer M2PELU32
I0927 14:49:10.880923  3463 net.cpp:84] Creating Layer M2PELU32
I0927 14:49:10.880924  3463 net.cpp:406] M2PELU32 <- Convolution33
I0927 14:49:10.880928  3463 net.cpp:367] M2PELU32 -> Convolution33 (in-place)
I0927 14:49:10.881011  3463 net.cpp:122] Setting up M2PELU32
I0927 14:49:10.881016  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.881017  3463 net.cpp:137] Memory required for data: 710931600
I0927 14:49:10.881021  3463 layer_factory.hpp:77] Creating layer Convolution34
I0927 14:49:10.881027  3463 net.cpp:84] Creating Layer Convolution34
I0927 14:49:10.881029  3463 net.cpp:406] Convolution34 <- Convolution33
I0927 14:49:10.881034  3463 net.cpp:380] Convolution34 -> Convolution34
I0927 14:49:10.882064  3463 net.cpp:122] Setting up Convolution34
I0927 14:49:10.882072  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.882074  3463 net.cpp:137] Memory required for data: 713440400
I0927 14:49:10.882078  3463 layer_factory.hpp:77] Creating layer BatchNorm34
I0927 14:49:10.882083  3463 net.cpp:84] Creating Layer BatchNorm34
I0927 14:49:10.882086  3463 net.cpp:406] BatchNorm34 <- Convolution34
I0927 14:49:10.882089  3463 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I0927 14:49:10.882225  3463 net.cpp:122] Setting up BatchNorm34
I0927 14:49:10.882230  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.882231  3463 net.cpp:137] Memory required for data: 715949200
I0927 14:49:10.882236  3463 layer_factory.hpp:77] Creating layer Scale34
I0927 14:49:10.882241  3463 net.cpp:84] Creating Layer Scale34
I0927 14:49:10.882242  3463 net.cpp:406] Scale34 <- Convolution34
I0927 14:49:10.882246  3463 net.cpp:367] Scale34 -> Convolution34 (in-place)
I0927 14:49:10.882272  3463 layer_factory.hpp:77] Creating layer Scale34
I0927 14:49:10.882349  3463 net.cpp:122] Setting up Scale34
I0927 14:49:10.882354  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.882355  3463 net.cpp:137] Memory required for data: 718458000
I0927 14:49:10.882359  3463 layer_factory.hpp:77] Creating layer Eltwise16
I0927 14:49:10.882364  3463 net.cpp:84] Creating Layer Eltwise16
I0927 14:49:10.882365  3463 net.cpp:406] Eltwise16 <- Eltwise15_M2PELU31_0_split_1
I0927 14:49:10.882369  3463 net.cpp:406] Eltwise16 <- Convolution34
I0927 14:49:10.882371  3463 net.cpp:380] Eltwise16 -> Eltwise16
I0927 14:49:10.882388  3463 net.cpp:122] Setting up Eltwise16
I0927 14:49:10.882392  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.882395  3463 net.cpp:137] Memory required for data: 720966800
I0927 14:49:10.882396  3463 layer_factory.hpp:77] Creating layer M2PELU33
I0927 14:49:10.882401  3463 net.cpp:84] Creating Layer M2PELU33
I0927 14:49:10.882403  3463 net.cpp:406] M2PELU33 <- Eltwise16
I0927 14:49:10.882413  3463 net.cpp:367] M2PELU33 -> Eltwise16 (in-place)
I0927 14:49:10.882498  3463 net.cpp:122] Setting up M2PELU33
I0927 14:49:10.882503  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.882504  3463 net.cpp:137] Memory required for data: 723475600
I0927 14:49:10.882508  3463 layer_factory.hpp:77] Creating layer Eltwise16_M2PELU33_0_split
I0927 14:49:10.882513  3463 net.cpp:84] Creating Layer Eltwise16_M2PELU33_0_split
I0927 14:49:10.882514  3463 net.cpp:406] Eltwise16_M2PELU33_0_split <- Eltwise16
I0927 14:49:10.882517  3463 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_0
I0927 14:49:10.882537  3463 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_1
I0927 14:49:10.882572  3463 net.cpp:122] Setting up Eltwise16_M2PELU33_0_split
I0927 14:49:10.882576  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.882580  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.882581  3463 net.cpp:137] Memory required for data: 728493200
I0927 14:49:10.882583  3463 layer_factory.hpp:77] Creating layer Convolution35
I0927 14:49:10.882589  3463 net.cpp:84] Creating Layer Convolution35
I0927 14:49:10.882592  3463 net.cpp:406] Convolution35 <- Eltwise16_M2PELU33_0_split_0
I0927 14:49:10.882596  3463 net.cpp:380] Convolution35 -> Convolution35
I0927 14:49:10.883651  3463 net.cpp:122] Setting up Convolution35
I0927 14:49:10.883659  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.883661  3463 net.cpp:137] Memory required for data: 731002000
I0927 14:49:10.883666  3463 layer_factory.hpp:77] Creating layer BatchNorm35
I0927 14:49:10.883671  3463 net.cpp:84] Creating Layer BatchNorm35
I0927 14:49:10.883674  3463 net.cpp:406] BatchNorm35 <- Convolution35
I0927 14:49:10.883679  3463 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I0927 14:49:10.883816  3463 net.cpp:122] Setting up BatchNorm35
I0927 14:49:10.883821  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.883822  3463 net.cpp:137] Memory required for data: 733510800
I0927 14:49:10.883826  3463 layer_factory.hpp:77] Creating layer Scale35
I0927 14:49:10.883831  3463 net.cpp:84] Creating Layer Scale35
I0927 14:49:10.883833  3463 net.cpp:406] Scale35 <- Convolution35
I0927 14:49:10.883837  3463 net.cpp:367] Scale35 -> Convolution35 (in-place)
I0927 14:49:10.883864  3463 layer_factory.hpp:77] Creating layer Scale35
I0927 14:49:10.883949  3463 net.cpp:122] Setting up Scale35
I0927 14:49:10.883954  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.883955  3463 net.cpp:137] Memory required for data: 736019600
I0927 14:49:10.883960  3463 layer_factory.hpp:77] Creating layer M2PELU34
I0927 14:49:10.883965  3463 net.cpp:84] Creating Layer M2PELU34
I0927 14:49:10.883966  3463 net.cpp:406] M2PELU34 <- Convolution35
I0927 14:49:10.883970  3463 net.cpp:367] M2PELU34 -> Convolution35 (in-place)
I0927 14:49:10.884052  3463 net.cpp:122] Setting up M2PELU34
I0927 14:49:10.884057  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.884058  3463 net.cpp:137] Memory required for data: 738528400
I0927 14:49:10.884063  3463 layer_factory.hpp:77] Creating layer Convolution36
I0927 14:49:10.884068  3463 net.cpp:84] Creating Layer Convolution36
I0927 14:49:10.884070  3463 net.cpp:406] Convolution36 <- Convolution35
I0927 14:49:10.884074  3463 net.cpp:380] Convolution36 -> Convolution36
I0927 14:49:10.885118  3463 net.cpp:122] Setting up Convolution36
I0927 14:49:10.885126  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.885129  3463 net.cpp:137] Memory required for data: 741037200
I0927 14:49:10.885133  3463 layer_factory.hpp:77] Creating layer BatchNorm36
I0927 14:49:10.885138  3463 net.cpp:84] Creating Layer BatchNorm36
I0927 14:49:10.885141  3463 net.cpp:406] BatchNorm36 <- Convolution36
I0927 14:49:10.885144  3463 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I0927 14:49:10.885284  3463 net.cpp:122] Setting up BatchNorm36
I0927 14:49:10.885288  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.885298  3463 net.cpp:137] Memory required for data: 743546000
I0927 14:49:10.885303  3463 layer_factory.hpp:77] Creating layer Scale36
I0927 14:49:10.885308  3463 net.cpp:84] Creating Layer Scale36
I0927 14:49:10.885309  3463 net.cpp:406] Scale36 <- Convolution36
I0927 14:49:10.885313  3463 net.cpp:367] Scale36 -> Convolution36 (in-place)
I0927 14:49:10.885342  3463 layer_factory.hpp:77] Creating layer Scale36
I0927 14:49:10.885419  3463 net.cpp:122] Setting up Scale36
I0927 14:49:10.885424  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.885427  3463 net.cpp:137] Memory required for data: 746054800
I0927 14:49:10.885430  3463 layer_factory.hpp:77] Creating layer Eltwise17
I0927 14:49:10.885434  3463 net.cpp:84] Creating Layer Eltwise17
I0927 14:49:10.885437  3463 net.cpp:406] Eltwise17 <- Eltwise16_M2PELU33_0_split_1
I0927 14:49:10.885440  3463 net.cpp:406] Eltwise17 <- Convolution36
I0927 14:49:10.885443  3463 net.cpp:380] Eltwise17 -> Eltwise17
I0927 14:49:10.885460  3463 net.cpp:122] Setting up Eltwise17
I0927 14:49:10.885463  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.885465  3463 net.cpp:137] Memory required for data: 748563600
I0927 14:49:10.885468  3463 layer_factory.hpp:77] Creating layer M2PELU35
I0927 14:49:10.885473  3463 net.cpp:84] Creating Layer M2PELU35
I0927 14:49:10.885476  3463 net.cpp:406] M2PELU35 <- Eltwise17
I0927 14:49:10.885479  3463 net.cpp:367] M2PELU35 -> Eltwise17 (in-place)
I0927 14:49:10.885566  3463 net.cpp:122] Setting up M2PELU35
I0927 14:49:10.885571  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.885572  3463 net.cpp:137] Memory required for data: 751072400
I0927 14:49:10.885576  3463 layer_factory.hpp:77] Creating layer Eltwise17_M2PELU35_0_split
I0927 14:49:10.885579  3463 net.cpp:84] Creating Layer Eltwise17_M2PELU35_0_split
I0927 14:49:10.885581  3463 net.cpp:406] Eltwise17_M2PELU35_0_split <- Eltwise17
I0927 14:49:10.885586  3463 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_0
I0927 14:49:10.885591  3463 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_1
I0927 14:49:10.885614  3463 net.cpp:122] Setting up Eltwise17_M2PELU35_0_split
I0927 14:49:10.885617  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.885620  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.885622  3463 net.cpp:137] Memory required for data: 756090000
I0927 14:49:10.885624  3463 layer_factory.hpp:77] Creating layer Convolution37
I0927 14:49:10.885630  3463 net.cpp:84] Creating Layer Convolution37
I0927 14:49:10.885633  3463 net.cpp:406] Convolution37 <- Eltwise17_M2PELU35_0_split_0
I0927 14:49:10.885637  3463 net.cpp:380] Convolution37 -> Convolution37
I0927 14:49:10.886359  3463 net.cpp:122] Setting up Convolution37
I0927 14:49:10.886368  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.886370  3463 net.cpp:137] Memory required for data: 758598800
I0927 14:49:10.886374  3463 layer_factory.hpp:77] Creating layer BatchNorm37
I0927 14:49:10.886379  3463 net.cpp:84] Creating Layer BatchNorm37
I0927 14:49:10.886380  3463 net.cpp:406] BatchNorm37 <- Convolution37
I0927 14:49:10.886384  3463 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I0927 14:49:10.886518  3463 net.cpp:122] Setting up BatchNorm37
I0927 14:49:10.886538  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.886539  3463 net.cpp:137] Memory required for data: 761107600
I0927 14:49:10.886544  3463 layer_factory.hpp:77] Creating layer Scale37
I0927 14:49:10.886548  3463 net.cpp:84] Creating Layer Scale37
I0927 14:49:10.886551  3463 net.cpp:406] Scale37 <- Convolution37
I0927 14:49:10.886554  3463 net.cpp:367] Scale37 -> Convolution37 (in-place)
I0927 14:49:10.886590  3463 layer_factory.hpp:77] Creating layer Scale37
I0927 14:49:10.886667  3463 net.cpp:122] Setting up Scale37
I0927 14:49:10.886672  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.886673  3463 net.cpp:137] Memory required for data: 763616400
I0927 14:49:10.886677  3463 layer_factory.hpp:77] Creating layer M2PELU36
I0927 14:49:10.886688  3463 net.cpp:84] Creating Layer M2PELU36
I0927 14:49:10.886690  3463 net.cpp:406] M2PELU36 <- Convolution37
I0927 14:49:10.886694  3463 net.cpp:367] M2PELU36 -> Convolution37 (in-place)
I0927 14:49:10.886780  3463 net.cpp:122] Setting up M2PELU36
I0927 14:49:10.886785  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.886786  3463 net.cpp:137] Memory required for data: 766125200
I0927 14:49:10.886790  3463 layer_factory.hpp:77] Creating layer Convolution38
I0927 14:49:10.886796  3463 net.cpp:84] Creating Layer Convolution38
I0927 14:49:10.886798  3463 net.cpp:406] Convolution38 <- Convolution37
I0927 14:49:10.886802  3463 net.cpp:380] Convolution38 -> Convolution38
I0927 14:49:10.887847  3463 net.cpp:122] Setting up Convolution38
I0927 14:49:10.887856  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.887857  3463 net.cpp:137] Memory required for data: 768634000
I0927 14:49:10.887862  3463 layer_factory.hpp:77] Creating layer BatchNorm38
I0927 14:49:10.887867  3463 net.cpp:84] Creating Layer BatchNorm38
I0927 14:49:10.887869  3463 net.cpp:406] BatchNorm38 <- Convolution38
I0927 14:49:10.887873  3463 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I0927 14:49:10.888008  3463 net.cpp:122] Setting up BatchNorm38
I0927 14:49:10.888013  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.888015  3463 net.cpp:137] Memory required for data: 771142800
I0927 14:49:10.888020  3463 layer_factory.hpp:77] Creating layer Scale38
I0927 14:49:10.888025  3463 net.cpp:84] Creating Layer Scale38
I0927 14:49:10.888026  3463 net.cpp:406] Scale38 <- Convolution38
I0927 14:49:10.888031  3463 net.cpp:367] Scale38 -> Convolution38 (in-place)
I0927 14:49:10.888056  3463 layer_factory.hpp:77] Creating layer Scale38
I0927 14:49:10.888134  3463 net.cpp:122] Setting up Scale38
I0927 14:49:10.888137  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.888139  3463 net.cpp:137] Memory required for data: 773651600
I0927 14:49:10.888144  3463 layer_factory.hpp:77] Creating layer Eltwise18
I0927 14:49:10.888147  3463 net.cpp:84] Creating Layer Eltwise18
I0927 14:49:10.888150  3463 net.cpp:406] Eltwise18 <- Eltwise17_M2PELU35_0_split_1
I0927 14:49:10.888154  3463 net.cpp:406] Eltwise18 <- Convolution38
I0927 14:49:10.888156  3463 net.cpp:380] Eltwise18 -> Eltwise18
I0927 14:49:10.888172  3463 net.cpp:122] Setting up Eltwise18
I0927 14:49:10.888176  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.888178  3463 net.cpp:137] Memory required for data: 776160400
I0927 14:49:10.888180  3463 layer_factory.hpp:77] Creating layer M2PELU37
I0927 14:49:10.888185  3463 net.cpp:84] Creating Layer M2PELU37
I0927 14:49:10.888187  3463 net.cpp:406] M2PELU37 <- Eltwise18
I0927 14:49:10.888191  3463 net.cpp:367] M2PELU37 -> Eltwise18 (in-place)
I0927 14:49:10.888275  3463 net.cpp:122] Setting up M2PELU37
I0927 14:49:10.888279  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.888281  3463 net.cpp:137] Memory required for data: 778669200
I0927 14:49:10.888284  3463 layer_factory.hpp:77] Creating layer Eltwise18_M2PELU37_0_split
I0927 14:49:10.888288  3463 net.cpp:84] Creating Layer Eltwise18_M2PELU37_0_split
I0927 14:49:10.888290  3463 net.cpp:406] Eltwise18_M2PELU37_0_split <- Eltwise18
I0927 14:49:10.888294  3463 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_0
I0927 14:49:10.888298  3463 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_1
I0927 14:49:10.888321  3463 net.cpp:122] Setting up Eltwise18_M2PELU37_0_split
I0927 14:49:10.888325  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.888327  3463 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 14:49:10.888329  3463 net.cpp:137] Memory required for data: 783686800
I0927 14:49:10.888331  3463 layer_factory.hpp:77] Creating layer Convolution39
I0927 14:49:10.888336  3463 net.cpp:84] Creating Layer Convolution39
I0927 14:49:10.888339  3463 net.cpp:406] Convolution39 <- Eltwise18_M2PELU37_0_split_0
I0927 14:49:10.888350  3463 net.cpp:380] Convolution39 -> Convolution39
I0927 14:49:10.889236  3463 net.cpp:122] Setting up Convolution39
I0927 14:49:10.889245  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.889248  3463 net.cpp:137] Memory required for data: 784941200
I0927 14:49:10.889252  3463 layer_factory.hpp:77] Creating layer BatchNorm39
I0927 14:49:10.889256  3463 net.cpp:84] Creating Layer BatchNorm39
I0927 14:49:10.889259  3463 net.cpp:406] BatchNorm39 <- Convolution39
I0927 14:49:10.889263  3463 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I0927 14:49:10.889397  3463 net.cpp:122] Setting up BatchNorm39
I0927 14:49:10.889401  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.889403  3463 net.cpp:137] Memory required for data: 786195600
I0927 14:49:10.889408  3463 layer_factory.hpp:77] Creating layer Scale39
I0927 14:49:10.889412  3463 net.cpp:84] Creating Layer Scale39
I0927 14:49:10.889415  3463 net.cpp:406] Scale39 <- Convolution39
I0927 14:49:10.889417  3463 net.cpp:367] Scale39 -> Convolution39 (in-place)
I0927 14:49:10.889443  3463 layer_factory.hpp:77] Creating layer Scale39
I0927 14:49:10.889520  3463 net.cpp:122] Setting up Scale39
I0927 14:49:10.889524  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.889526  3463 net.cpp:137] Memory required for data: 787450000
I0927 14:49:10.889530  3463 layer_factory.hpp:77] Creating layer Convolution40
I0927 14:49:10.889536  3463 net.cpp:84] Creating Layer Convolution40
I0927 14:49:10.889539  3463 net.cpp:406] Convolution40 <- Eltwise18_M2PELU37_0_split_1
I0927 14:49:10.889544  3463 net.cpp:380] Convolution40 -> Convolution40
I0927 14:49:10.891363  3463 net.cpp:122] Setting up Convolution40
I0927 14:49:10.891376  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.891381  3463 net.cpp:137] Memory required for data: 788704400
I0927 14:49:10.891386  3463 layer_factory.hpp:77] Creating layer BatchNorm40
I0927 14:49:10.891393  3463 net.cpp:84] Creating Layer BatchNorm40
I0927 14:49:10.891396  3463 net.cpp:406] BatchNorm40 <- Convolution40
I0927 14:49:10.891402  3463 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I0927 14:49:10.891538  3463 net.cpp:122] Setting up BatchNorm40
I0927 14:49:10.891542  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.891546  3463 net.cpp:137] Memory required for data: 789958800
I0927 14:49:10.891549  3463 layer_factory.hpp:77] Creating layer Scale40
I0927 14:49:10.891553  3463 net.cpp:84] Creating Layer Scale40
I0927 14:49:10.891556  3463 net.cpp:406] Scale40 <- Convolution40
I0927 14:49:10.891561  3463 net.cpp:367] Scale40 -> Convolution40 (in-place)
I0927 14:49:10.891587  3463 layer_factory.hpp:77] Creating layer Scale40
I0927 14:49:10.891667  3463 net.cpp:122] Setting up Scale40
I0927 14:49:10.891671  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.891674  3463 net.cpp:137] Memory required for data: 791213200
I0927 14:49:10.891677  3463 layer_factory.hpp:77] Creating layer M2PELU38
I0927 14:49:10.891681  3463 net.cpp:84] Creating Layer M2PELU38
I0927 14:49:10.891685  3463 net.cpp:406] M2PELU38 <- Convolution40
I0927 14:49:10.891688  3463 net.cpp:367] M2PELU38 -> Convolution40 (in-place)
I0927 14:49:10.891777  3463 net.cpp:122] Setting up M2PELU38
I0927 14:49:10.891782  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.891783  3463 net.cpp:137] Memory required for data: 792467600
I0927 14:49:10.891788  3463 layer_factory.hpp:77] Creating layer Convolution41
I0927 14:49:10.891794  3463 net.cpp:84] Creating Layer Convolution41
I0927 14:49:10.891796  3463 net.cpp:406] Convolution41 <- Convolution40
I0927 14:49:10.891800  3463 net.cpp:380] Convolution41 -> Convolution41
I0927 14:49:10.894166  3463 net.cpp:122] Setting up Convolution41
I0927 14:49:10.894176  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.894179  3463 net.cpp:137] Memory required for data: 793722000
I0927 14:49:10.894183  3463 layer_factory.hpp:77] Creating layer BatchNorm41
I0927 14:49:10.894188  3463 net.cpp:84] Creating Layer BatchNorm41
I0927 14:49:10.894198  3463 net.cpp:406] BatchNorm41 <- Convolution41
I0927 14:49:10.894203  3463 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I0927 14:49:10.894351  3463 net.cpp:122] Setting up BatchNorm41
I0927 14:49:10.894356  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.894357  3463 net.cpp:137] Memory required for data: 794976400
I0927 14:49:10.894362  3463 layer_factory.hpp:77] Creating layer Scale41
I0927 14:49:10.894367  3463 net.cpp:84] Creating Layer Scale41
I0927 14:49:10.894369  3463 net.cpp:406] Scale41 <- Convolution41
I0927 14:49:10.894373  3463 net.cpp:367] Scale41 -> Convolution41 (in-place)
I0927 14:49:10.894402  3463 layer_factory.hpp:77] Creating layer Scale41
I0927 14:49:10.894484  3463 net.cpp:122] Setting up Scale41
I0927 14:49:10.894489  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.894490  3463 net.cpp:137] Memory required for data: 796230800
I0927 14:49:10.894495  3463 layer_factory.hpp:77] Creating layer Eltwise19
I0927 14:49:10.894498  3463 net.cpp:84] Creating Layer Eltwise19
I0927 14:49:10.894501  3463 net.cpp:406] Eltwise19 <- Convolution39
I0927 14:49:10.894505  3463 net.cpp:406] Eltwise19 <- Convolution41
I0927 14:49:10.894508  3463 net.cpp:380] Eltwise19 -> Eltwise19
I0927 14:49:10.894531  3463 net.cpp:122] Setting up Eltwise19
I0927 14:49:10.894536  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.894538  3463 net.cpp:137] Memory required for data: 797485200
I0927 14:49:10.894541  3463 layer_factory.hpp:77] Creating layer M2PELU39
I0927 14:49:10.894546  3463 net.cpp:84] Creating Layer M2PELU39
I0927 14:49:10.894547  3463 net.cpp:406] M2PELU39 <- Eltwise19
I0927 14:49:10.894551  3463 net.cpp:367] M2PELU39 -> Eltwise19 (in-place)
I0927 14:49:10.894644  3463 net.cpp:122] Setting up M2PELU39
I0927 14:49:10.894649  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.894650  3463 net.cpp:137] Memory required for data: 798739600
I0927 14:49:10.894654  3463 layer_factory.hpp:77] Creating layer Eltwise19_M2PELU39_0_split
I0927 14:49:10.894659  3463 net.cpp:84] Creating Layer Eltwise19_M2PELU39_0_split
I0927 14:49:10.894661  3463 net.cpp:406] Eltwise19_M2PELU39_0_split <- Eltwise19
I0927 14:49:10.894665  3463 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_0
I0927 14:49:10.894668  3463 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_1
I0927 14:49:10.894695  3463 net.cpp:122] Setting up Eltwise19_M2PELU39_0_split
I0927 14:49:10.894698  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.894701  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.894702  3463 net.cpp:137] Memory required for data: 801248400
I0927 14:49:10.894704  3463 layer_factory.hpp:77] Creating layer Convolution42
I0927 14:49:10.894711  3463 net.cpp:84] Creating Layer Convolution42
I0927 14:49:10.894713  3463 net.cpp:406] Convolution42 <- Eltwise19_M2PELU39_0_split_0
I0927 14:49:10.894717  3463 net.cpp:380] Convolution42 -> Convolution42
I0927 14:49:10.896452  3463 net.cpp:122] Setting up Convolution42
I0927 14:49:10.896461  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.896464  3463 net.cpp:137] Memory required for data: 802502800
I0927 14:49:10.896468  3463 layer_factory.hpp:77] Creating layer BatchNorm42
I0927 14:49:10.896473  3463 net.cpp:84] Creating Layer BatchNorm42
I0927 14:49:10.896476  3463 net.cpp:406] BatchNorm42 <- Convolution42
I0927 14:49:10.896479  3463 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I0927 14:49:10.896620  3463 net.cpp:122] Setting up BatchNorm42
I0927 14:49:10.896625  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.896626  3463 net.cpp:137] Memory required for data: 803757200
I0927 14:49:10.896631  3463 layer_factory.hpp:77] Creating layer Scale42
I0927 14:49:10.896634  3463 net.cpp:84] Creating Layer Scale42
I0927 14:49:10.896637  3463 net.cpp:406] Scale42 <- Convolution42
I0927 14:49:10.896641  3463 net.cpp:367] Scale42 -> Convolution42 (in-place)
I0927 14:49:10.896669  3463 layer_factory.hpp:77] Creating layer Scale42
I0927 14:49:10.896759  3463 net.cpp:122] Setting up Scale42
I0927 14:49:10.896764  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.896766  3463 net.cpp:137] Memory required for data: 805011600
I0927 14:49:10.896770  3463 layer_factory.hpp:77] Creating layer M2PELU40
I0927 14:49:10.896775  3463 net.cpp:84] Creating Layer M2PELU40
I0927 14:49:10.896778  3463 net.cpp:406] M2PELU40 <- Convolution42
I0927 14:49:10.896781  3463 net.cpp:367] M2PELU40 -> Convolution42 (in-place)
I0927 14:49:10.896868  3463 net.cpp:122] Setting up M2PELU40
I0927 14:49:10.896873  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.896875  3463 net.cpp:137] Memory required for data: 806266000
I0927 14:49:10.896878  3463 layer_factory.hpp:77] Creating layer Convolution43
I0927 14:49:10.896885  3463 net.cpp:84] Creating Layer Convolution43
I0927 14:49:10.896888  3463 net.cpp:406] Convolution43 <- Convolution42
I0927 14:49:10.896893  3463 net.cpp:380] Convolution43 -> Convolution43
I0927 14:49:10.899224  3463 net.cpp:122] Setting up Convolution43
I0927 14:49:10.899233  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.899236  3463 net.cpp:137] Memory required for data: 807520400
I0927 14:49:10.899240  3463 layer_factory.hpp:77] Creating layer BatchNorm43
I0927 14:49:10.899246  3463 net.cpp:84] Creating Layer BatchNorm43
I0927 14:49:10.899250  3463 net.cpp:406] BatchNorm43 <- Convolution43
I0927 14:49:10.899255  3463 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I0927 14:49:10.899397  3463 net.cpp:122] Setting up BatchNorm43
I0927 14:49:10.899401  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.899405  3463 net.cpp:137] Memory required for data: 808774800
I0927 14:49:10.899408  3463 layer_factory.hpp:77] Creating layer Scale43
I0927 14:49:10.899413  3463 net.cpp:84] Creating Layer Scale43
I0927 14:49:10.899416  3463 net.cpp:406] Scale43 <- Convolution43
I0927 14:49:10.899420  3463 net.cpp:367] Scale43 -> Convolution43 (in-place)
I0927 14:49:10.899447  3463 layer_factory.hpp:77] Creating layer Scale43
I0927 14:49:10.899528  3463 net.cpp:122] Setting up Scale43
I0927 14:49:10.899531  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.899533  3463 net.cpp:137] Memory required for data: 810029200
I0927 14:49:10.899538  3463 layer_factory.hpp:77] Creating layer Eltwise20
I0927 14:49:10.899543  3463 net.cpp:84] Creating Layer Eltwise20
I0927 14:49:10.899544  3463 net.cpp:406] Eltwise20 <- Eltwise19_M2PELU39_0_split_1
I0927 14:49:10.899547  3463 net.cpp:406] Eltwise20 <- Convolution43
I0927 14:49:10.899551  3463 net.cpp:380] Eltwise20 -> Eltwise20
I0927 14:49:10.899569  3463 net.cpp:122] Setting up Eltwise20
I0927 14:49:10.899571  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.899574  3463 net.cpp:137] Memory required for data: 811283600
I0927 14:49:10.899575  3463 layer_factory.hpp:77] Creating layer M2PELU41
I0927 14:49:10.899581  3463 net.cpp:84] Creating Layer M2PELU41
I0927 14:49:10.899583  3463 net.cpp:406] M2PELU41 <- Eltwise20
I0927 14:49:10.899586  3463 net.cpp:367] M2PELU41 -> Eltwise20 (in-place)
I0927 14:49:10.899673  3463 net.cpp:122] Setting up M2PELU41
I0927 14:49:10.899678  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.899680  3463 net.cpp:137] Memory required for data: 812538000
I0927 14:49:10.899683  3463 layer_factory.hpp:77] Creating layer Eltwise20_M2PELU41_0_split
I0927 14:49:10.899688  3463 net.cpp:84] Creating Layer Eltwise20_M2PELU41_0_split
I0927 14:49:10.899690  3463 net.cpp:406] Eltwise20_M2PELU41_0_split <- Eltwise20
I0927 14:49:10.899693  3463 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_0
I0927 14:49:10.899698  3463 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_1
I0927 14:49:10.899721  3463 net.cpp:122] Setting up Eltwise20_M2PELU41_0_split
I0927 14:49:10.899725  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.899729  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.899730  3463 net.cpp:137] Memory required for data: 815046800
I0927 14:49:10.899739  3463 layer_factory.hpp:77] Creating layer Convolution44
I0927 14:49:10.899745  3463 net.cpp:84] Creating Layer Convolution44
I0927 14:49:10.899749  3463 net.cpp:406] Convolution44 <- Eltwise20_M2PELU41_0_split_0
I0927 14:49:10.899752  3463 net.cpp:380] Convolution44 -> Convolution44
I0927 14:49:10.901437  3463 net.cpp:122] Setting up Convolution44
I0927 14:49:10.901445  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.901448  3463 net.cpp:137] Memory required for data: 816301200
I0927 14:49:10.901453  3463 layer_factory.hpp:77] Creating layer BatchNorm44
I0927 14:49:10.901456  3463 net.cpp:84] Creating Layer BatchNorm44
I0927 14:49:10.901459  3463 net.cpp:406] BatchNorm44 <- Convolution44
I0927 14:49:10.901464  3463 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I0927 14:49:10.901607  3463 net.cpp:122] Setting up BatchNorm44
I0927 14:49:10.901612  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.901613  3463 net.cpp:137] Memory required for data: 817555600
I0927 14:49:10.901618  3463 layer_factory.hpp:77] Creating layer Scale44
I0927 14:49:10.901623  3463 net.cpp:84] Creating Layer Scale44
I0927 14:49:10.901624  3463 net.cpp:406] Scale44 <- Convolution44
I0927 14:49:10.901628  3463 net.cpp:367] Scale44 -> Convolution44 (in-place)
I0927 14:49:10.901655  3463 layer_factory.hpp:77] Creating layer Scale44
I0927 14:49:10.901736  3463 net.cpp:122] Setting up Scale44
I0927 14:49:10.901741  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.901742  3463 net.cpp:137] Memory required for data: 818810000
I0927 14:49:10.901746  3463 layer_factory.hpp:77] Creating layer M2PELU42
I0927 14:49:10.901751  3463 net.cpp:84] Creating Layer M2PELU42
I0927 14:49:10.901754  3463 net.cpp:406] M2PELU42 <- Convolution44
I0927 14:49:10.901757  3463 net.cpp:367] M2PELU42 -> Convolution44 (in-place)
I0927 14:49:10.901845  3463 net.cpp:122] Setting up M2PELU42
I0927 14:49:10.901850  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.901852  3463 net.cpp:137] Memory required for data: 820064400
I0927 14:49:10.901855  3463 layer_factory.hpp:77] Creating layer Convolution45
I0927 14:49:10.901862  3463 net.cpp:84] Creating Layer Convolution45
I0927 14:49:10.901865  3463 net.cpp:406] Convolution45 <- Convolution44
I0927 14:49:10.901870  3463 net.cpp:380] Convolution45 -> Convolution45
I0927 14:49:10.903884  3463 net.cpp:122] Setting up Convolution45
I0927 14:49:10.903892  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.903895  3463 net.cpp:137] Memory required for data: 821318800
I0927 14:49:10.903899  3463 layer_factory.hpp:77] Creating layer BatchNorm45
I0927 14:49:10.903905  3463 net.cpp:84] Creating Layer BatchNorm45
I0927 14:49:10.903908  3463 net.cpp:406] BatchNorm45 <- Convolution45
I0927 14:49:10.903913  3463 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I0927 14:49:10.904057  3463 net.cpp:122] Setting up BatchNorm45
I0927 14:49:10.904062  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.904064  3463 net.cpp:137] Memory required for data: 822573200
I0927 14:49:10.904068  3463 layer_factory.hpp:77] Creating layer Scale45
I0927 14:49:10.904073  3463 net.cpp:84] Creating Layer Scale45
I0927 14:49:10.904075  3463 net.cpp:406] Scale45 <- Convolution45
I0927 14:49:10.904079  3463 net.cpp:367] Scale45 -> Convolution45 (in-place)
I0927 14:49:10.904108  3463 layer_factory.hpp:77] Creating layer Scale45
I0927 14:49:10.904191  3463 net.cpp:122] Setting up Scale45
I0927 14:49:10.904196  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.904198  3463 net.cpp:137] Memory required for data: 823827600
I0927 14:49:10.904202  3463 layer_factory.hpp:77] Creating layer Eltwise21
I0927 14:49:10.904206  3463 net.cpp:84] Creating Layer Eltwise21
I0927 14:49:10.904209  3463 net.cpp:406] Eltwise21 <- Eltwise20_M2PELU41_0_split_1
I0927 14:49:10.904212  3463 net.cpp:406] Eltwise21 <- Convolution45
I0927 14:49:10.904215  3463 net.cpp:380] Eltwise21 -> Eltwise21
I0927 14:49:10.904233  3463 net.cpp:122] Setting up Eltwise21
I0927 14:49:10.904237  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.904245  3463 net.cpp:137] Memory required for data: 825082000
I0927 14:49:10.904248  3463 layer_factory.hpp:77] Creating layer M2PELU43
I0927 14:49:10.904253  3463 net.cpp:84] Creating Layer M2PELU43
I0927 14:49:10.904256  3463 net.cpp:406] M2PELU43 <- Eltwise21
I0927 14:49:10.904259  3463 net.cpp:367] M2PELU43 -> Eltwise21 (in-place)
I0927 14:49:10.904350  3463 net.cpp:122] Setting up M2PELU43
I0927 14:49:10.904356  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.904357  3463 net.cpp:137] Memory required for data: 826336400
I0927 14:49:10.904361  3463 layer_factory.hpp:77] Creating layer Eltwise21_M2PELU43_0_split
I0927 14:49:10.904364  3463 net.cpp:84] Creating Layer Eltwise21_M2PELU43_0_split
I0927 14:49:10.904367  3463 net.cpp:406] Eltwise21_M2PELU43_0_split <- Eltwise21
I0927 14:49:10.904371  3463 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_0
I0927 14:49:10.904376  3463 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_1
I0927 14:49:10.904400  3463 net.cpp:122] Setting up Eltwise21_M2PELU43_0_split
I0927 14:49:10.904404  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.904407  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.904409  3463 net.cpp:137] Memory required for data: 828845200
I0927 14:49:10.904412  3463 layer_factory.hpp:77] Creating layer Convolution46
I0927 14:49:10.904417  3463 net.cpp:84] Creating Layer Convolution46
I0927 14:49:10.904419  3463 net.cpp:406] Convolution46 <- Eltwise21_M2PELU43_0_split_0
I0927 14:49:10.904423  3463 net.cpp:380] Convolution46 -> Convolution46
I0927 14:49:10.906113  3463 net.cpp:122] Setting up Convolution46
I0927 14:49:10.906122  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.906126  3463 net.cpp:137] Memory required for data: 830099600
I0927 14:49:10.906131  3463 layer_factory.hpp:77] Creating layer BatchNorm46
I0927 14:49:10.906134  3463 net.cpp:84] Creating Layer BatchNorm46
I0927 14:49:10.906137  3463 net.cpp:406] BatchNorm46 <- Convolution46
I0927 14:49:10.906142  3463 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I0927 14:49:10.906286  3463 net.cpp:122] Setting up BatchNorm46
I0927 14:49:10.906291  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.906293  3463 net.cpp:137] Memory required for data: 831354000
I0927 14:49:10.906297  3463 layer_factory.hpp:77] Creating layer Scale46
I0927 14:49:10.906302  3463 net.cpp:84] Creating Layer Scale46
I0927 14:49:10.906304  3463 net.cpp:406] Scale46 <- Convolution46
I0927 14:49:10.906307  3463 net.cpp:367] Scale46 -> Convolution46 (in-place)
I0927 14:49:10.906335  3463 layer_factory.hpp:77] Creating layer Scale46
I0927 14:49:10.906417  3463 net.cpp:122] Setting up Scale46
I0927 14:49:10.906421  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.906424  3463 net.cpp:137] Memory required for data: 832608400
I0927 14:49:10.906427  3463 layer_factory.hpp:77] Creating layer M2PELU44
I0927 14:49:10.906432  3463 net.cpp:84] Creating Layer M2PELU44
I0927 14:49:10.906435  3463 net.cpp:406] M2PELU44 <- Convolution46
I0927 14:49:10.906438  3463 net.cpp:367] M2PELU44 -> Convolution46 (in-place)
I0927 14:49:10.906545  3463 net.cpp:122] Setting up M2PELU44
I0927 14:49:10.906550  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.906553  3463 net.cpp:137] Memory required for data: 833862800
I0927 14:49:10.906556  3463 layer_factory.hpp:77] Creating layer Convolution47
I0927 14:49:10.906574  3463 net.cpp:84] Creating Layer Convolution47
I0927 14:49:10.906576  3463 net.cpp:406] Convolution47 <- Convolution46
I0927 14:49:10.906580  3463 net.cpp:380] Convolution47 -> Convolution47
I0927 14:49:10.908252  3463 net.cpp:122] Setting up Convolution47
I0927 14:49:10.908259  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.908262  3463 net.cpp:137] Memory required for data: 835117200
I0927 14:49:10.908267  3463 layer_factory.hpp:77] Creating layer BatchNorm47
I0927 14:49:10.908272  3463 net.cpp:84] Creating Layer BatchNorm47
I0927 14:49:10.908280  3463 net.cpp:406] BatchNorm47 <- Convolution47
I0927 14:49:10.908285  3463 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I0927 14:49:10.908430  3463 net.cpp:122] Setting up BatchNorm47
I0927 14:49:10.908435  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.908437  3463 net.cpp:137] Memory required for data: 836371600
I0927 14:49:10.908442  3463 layer_factory.hpp:77] Creating layer Scale47
I0927 14:49:10.908445  3463 net.cpp:84] Creating Layer Scale47
I0927 14:49:10.908448  3463 net.cpp:406] Scale47 <- Convolution47
I0927 14:49:10.908452  3463 net.cpp:367] Scale47 -> Convolution47 (in-place)
I0927 14:49:10.908480  3463 layer_factory.hpp:77] Creating layer Scale47
I0927 14:49:10.908562  3463 net.cpp:122] Setting up Scale47
I0927 14:49:10.908566  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.908568  3463 net.cpp:137] Memory required for data: 837626000
I0927 14:49:10.908572  3463 layer_factory.hpp:77] Creating layer Eltwise22
I0927 14:49:10.908576  3463 net.cpp:84] Creating Layer Eltwise22
I0927 14:49:10.908579  3463 net.cpp:406] Eltwise22 <- Eltwise21_M2PELU43_0_split_1
I0927 14:49:10.908582  3463 net.cpp:406] Eltwise22 <- Convolution47
I0927 14:49:10.908586  3463 net.cpp:380] Eltwise22 -> Eltwise22
I0927 14:49:10.908603  3463 net.cpp:122] Setting up Eltwise22
I0927 14:49:10.908607  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.908609  3463 net.cpp:137] Memory required for data: 838880400
I0927 14:49:10.908612  3463 layer_factory.hpp:77] Creating layer M2PELU45
I0927 14:49:10.908617  3463 net.cpp:84] Creating Layer M2PELU45
I0927 14:49:10.908618  3463 net.cpp:406] M2PELU45 <- Eltwise22
I0927 14:49:10.908622  3463 net.cpp:367] M2PELU45 -> Eltwise22 (in-place)
I0927 14:49:10.908711  3463 net.cpp:122] Setting up M2PELU45
I0927 14:49:10.908715  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.908717  3463 net.cpp:137] Memory required for data: 840134800
I0927 14:49:10.908720  3463 layer_factory.hpp:77] Creating layer Eltwise22_M2PELU45_0_split
I0927 14:49:10.908725  3463 net.cpp:84] Creating Layer Eltwise22_M2PELU45_0_split
I0927 14:49:10.908726  3463 net.cpp:406] Eltwise22_M2PELU45_0_split <- Eltwise22
I0927 14:49:10.908730  3463 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_0
I0927 14:49:10.908735  3463 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_1
I0927 14:49:10.908759  3463 net.cpp:122] Setting up Eltwise22_M2PELU45_0_split
I0927 14:49:10.908762  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.908766  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.908767  3463 net.cpp:137] Memory required for data: 842643600
I0927 14:49:10.908769  3463 layer_factory.hpp:77] Creating layer Convolution48
I0927 14:49:10.908776  3463 net.cpp:84] Creating Layer Convolution48
I0927 14:49:10.908778  3463 net.cpp:406] Convolution48 <- Eltwise22_M2PELU45_0_split_0
I0927 14:49:10.908782  3463 net.cpp:380] Convolution48 -> Convolution48
I0927 14:49:10.910456  3463 net.cpp:122] Setting up Convolution48
I0927 14:49:10.910465  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.910467  3463 net.cpp:137] Memory required for data: 843898000
I0927 14:49:10.910471  3463 layer_factory.hpp:77] Creating layer BatchNorm48
I0927 14:49:10.910477  3463 net.cpp:84] Creating Layer BatchNorm48
I0927 14:49:10.910480  3463 net.cpp:406] BatchNorm48 <- Convolution48
I0927 14:49:10.910485  3463 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I0927 14:49:10.910655  3463 net.cpp:122] Setting up BatchNorm48
I0927 14:49:10.910660  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.910662  3463 net.cpp:137] Memory required for data: 845152400
I0927 14:49:10.910667  3463 layer_factory.hpp:77] Creating layer Scale48
I0927 14:49:10.910672  3463 net.cpp:84] Creating Layer Scale48
I0927 14:49:10.910676  3463 net.cpp:406] Scale48 <- Convolution48
I0927 14:49:10.910678  3463 net.cpp:367] Scale48 -> Convolution48 (in-place)
I0927 14:49:10.910707  3463 layer_factory.hpp:77] Creating layer Scale48
I0927 14:49:10.910801  3463 net.cpp:122] Setting up Scale48
I0927 14:49:10.910807  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.910809  3463 net.cpp:137] Memory required for data: 846406800
I0927 14:49:10.910814  3463 layer_factory.hpp:77] Creating layer M2PELU46
I0927 14:49:10.910818  3463 net.cpp:84] Creating Layer M2PELU46
I0927 14:49:10.910820  3463 net.cpp:406] M2PELU46 <- Convolution48
I0927 14:49:10.910825  3463 net.cpp:367] M2PELU46 -> Convolution48 (in-place)
I0927 14:49:10.910915  3463 net.cpp:122] Setting up M2PELU46
I0927 14:49:10.910919  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.910922  3463 net.cpp:137] Memory required for data: 847661200
I0927 14:49:10.910925  3463 layer_factory.hpp:77] Creating layer Convolution49
I0927 14:49:10.910931  3463 net.cpp:84] Creating Layer Convolution49
I0927 14:49:10.910934  3463 net.cpp:406] Convolution49 <- Convolution48
I0927 14:49:10.910938  3463 net.cpp:380] Convolution49 -> Convolution49
I0927 14:49:10.912932  3463 net.cpp:122] Setting up Convolution49
I0927 14:49:10.912941  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.912943  3463 net.cpp:137] Memory required for data: 848915600
I0927 14:49:10.912950  3463 layer_factory.hpp:77] Creating layer BatchNorm49
I0927 14:49:10.912953  3463 net.cpp:84] Creating Layer BatchNorm49
I0927 14:49:10.912956  3463 net.cpp:406] BatchNorm49 <- Convolution49
I0927 14:49:10.912961  3463 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I0927 14:49:10.913108  3463 net.cpp:122] Setting up BatchNorm49
I0927 14:49:10.913113  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.913115  3463 net.cpp:137] Memory required for data: 850170000
I0927 14:49:10.913120  3463 layer_factory.hpp:77] Creating layer Scale49
I0927 14:49:10.913125  3463 net.cpp:84] Creating Layer Scale49
I0927 14:49:10.913127  3463 net.cpp:406] Scale49 <- Convolution49
I0927 14:49:10.913130  3463 net.cpp:367] Scale49 -> Convolution49 (in-place)
I0927 14:49:10.913159  3463 layer_factory.hpp:77] Creating layer Scale49
I0927 14:49:10.913244  3463 net.cpp:122] Setting up Scale49
I0927 14:49:10.913247  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.913249  3463 net.cpp:137] Memory required for data: 851424400
I0927 14:49:10.913254  3463 layer_factory.hpp:77] Creating layer Eltwise23
I0927 14:49:10.913257  3463 net.cpp:84] Creating Layer Eltwise23
I0927 14:49:10.913259  3463 net.cpp:406] Eltwise23 <- Eltwise22_M2PELU45_0_split_1
I0927 14:49:10.913262  3463 net.cpp:406] Eltwise23 <- Convolution49
I0927 14:49:10.913266  3463 net.cpp:380] Eltwise23 -> Eltwise23
I0927 14:49:10.913283  3463 net.cpp:122] Setting up Eltwise23
I0927 14:49:10.913287  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.913290  3463 net.cpp:137] Memory required for data: 852678800
I0927 14:49:10.913291  3463 layer_factory.hpp:77] Creating layer M2PELU47
I0927 14:49:10.913296  3463 net.cpp:84] Creating Layer M2PELU47
I0927 14:49:10.913300  3463 net.cpp:406] M2PELU47 <- Eltwise23
I0927 14:49:10.913302  3463 net.cpp:367] M2PELU47 -> Eltwise23 (in-place)
I0927 14:49:10.913391  3463 net.cpp:122] Setting up M2PELU47
I0927 14:49:10.913396  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.913398  3463 net.cpp:137] Memory required for data: 853933200
I0927 14:49:10.913401  3463 layer_factory.hpp:77] Creating layer Eltwise23_M2PELU47_0_split
I0927 14:49:10.913405  3463 net.cpp:84] Creating Layer Eltwise23_M2PELU47_0_split
I0927 14:49:10.913408  3463 net.cpp:406] Eltwise23_M2PELU47_0_split <- Eltwise23
I0927 14:49:10.913410  3463 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_0
I0927 14:49:10.913415  3463 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_1
I0927 14:49:10.913439  3463 net.cpp:122] Setting up Eltwise23_M2PELU47_0_split
I0927 14:49:10.913444  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.913446  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.913449  3463 net.cpp:137] Memory required for data: 856442000
I0927 14:49:10.913455  3463 layer_factory.hpp:77] Creating layer Convolution50
I0927 14:49:10.913462  3463 net.cpp:84] Creating Layer Convolution50
I0927 14:49:10.913465  3463 net.cpp:406] Convolution50 <- Eltwise23_M2PELU47_0_split_0
I0927 14:49:10.913470  3463 net.cpp:380] Convolution50 -> Convolution50
I0927 14:49:10.915187  3463 net.cpp:122] Setting up Convolution50
I0927 14:49:10.915195  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.915199  3463 net.cpp:137] Memory required for data: 857696400
I0927 14:49:10.915202  3463 layer_factory.hpp:77] Creating layer BatchNorm50
I0927 14:49:10.915210  3463 net.cpp:84] Creating Layer BatchNorm50
I0927 14:49:10.915211  3463 net.cpp:406] BatchNorm50 <- Convolution50
I0927 14:49:10.915216  3463 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I0927 14:49:10.915361  3463 net.cpp:122] Setting up BatchNorm50
I0927 14:49:10.915366  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.921785  3463 net.cpp:137] Memory required for data: 858950800
I0927 14:49:10.921797  3463 layer_factory.hpp:77] Creating layer Scale50
I0927 14:49:10.921805  3463 net.cpp:84] Creating Layer Scale50
I0927 14:49:10.921810  3463 net.cpp:406] Scale50 <- Convolution50
I0927 14:49:10.921815  3463 net.cpp:367] Scale50 -> Convolution50 (in-place)
I0927 14:49:10.921862  3463 layer_factory.hpp:77] Creating layer Scale50
I0927 14:49:10.921958  3463 net.cpp:122] Setting up Scale50
I0927 14:49:10.921963  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.921965  3463 net.cpp:137] Memory required for data: 860205200
I0927 14:49:10.921969  3463 layer_factory.hpp:77] Creating layer M2PELU48
I0927 14:49:10.921975  3463 net.cpp:84] Creating Layer M2PELU48
I0927 14:49:10.921977  3463 net.cpp:406] M2PELU48 <- Convolution50
I0927 14:49:10.921983  3463 net.cpp:367] M2PELU48 -> Convolution50 (in-place)
I0927 14:49:10.922080  3463 net.cpp:122] Setting up M2PELU48
I0927 14:49:10.922086  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.922088  3463 net.cpp:137] Memory required for data: 861459600
I0927 14:49:10.922092  3463 layer_factory.hpp:77] Creating layer Convolution51
I0927 14:49:10.922099  3463 net.cpp:84] Creating Layer Convolution51
I0927 14:49:10.922101  3463 net.cpp:406] Convolution51 <- Convolution50
I0927 14:49:10.922106  3463 net.cpp:380] Convolution51 -> Convolution51
I0927 14:49:10.924715  3463 net.cpp:122] Setting up Convolution51
I0927 14:49:10.924724  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.924727  3463 net.cpp:137] Memory required for data: 862714000
I0927 14:49:10.924732  3463 layer_factory.hpp:77] Creating layer BatchNorm51
I0927 14:49:10.924738  3463 net.cpp:84] Creating Layer BatchNorm51
I0927 14:49:10.924741  3463 net.cpp:406] BatchNorm51 <- Convolution51
I0927 14:49:10.924746  3463 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I0927 14:49:10.924899  3463 net.cpp:122] Setting up BatchNorm51
I0927 14:49:10.924904  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.924906  3463 net.cpp:137] Memory required for data: 863968400
I0927 14:49:10.924912  3463 layer_factory.hpp:77] Creating layer Scale51
I0927 14:49:10.924916  3463 net.cpp:84] Creating Layer Scale51
I0927 14:49:10.924919  3463 net.cpp:406] Scale51 <- Convolution51
I0927 14:49:10.924922  3463 net.cpp:367] Scale51 -> Convolution51 (in-place)
I0927 14:49:10.924952  3463 layer_factory.hpp:77] Creating layer Scale51
I0927 14:49:10.925040  3463 net.cpp:122] Setting up Scale51
I0927 14:49:10.925045  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.925047  3463 net.cpp:137] Memory required for data: 865222800
I0927 14:49:10.925051  3463 layer_factory.hpp:77] Creating layer Eltwise24
I0927 14:49:10.925055  3463 net.cpp:84] Creating Layer Eltwise24
I0927 14:49:10.925058  3463 net.cpp:406] Eltwise24 <- Eltwise23_M2PELU47_0_split_1
I0927 14:49:10.925061  3463 net.cpp:406] Eltwise24 <- Convolution51
I0927 14:49:10.925065  3463 net.cpp:380] Eltwise24 -> Eltwise24
I0927 14:49:10.925083  3463 net.cpp:122] Setting up Eltwise24
I0927 14:49:10.925093  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.925096  3463 net.cpp:137] Memory required for data: 866477200
I0927 14:49:10.925098  3463 layer_factory.hpp:77] Creating layer M2PELU49
I0927 14:49:10.925104  3463 net.cpp:84] Creating Layer M2PELU49
I0927 14:49:10.925107  3463 net.cpp:406] M2PELU49 <- Eltwise24
I0927 14:49:10.925110  3463 net.cpp:367] M2PELU49 -> Eltwise24 (in-place)
I0927 14:49:10.925207  3463 net.cpp:122] Setting up M2PELU49
I0927 14:49:10.925212  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.925215  3463 net.cpp:137] Memory required for data: 867731600
I0927 14:49:10.925218  3463 layer_factory.hpp:77] Creating layer Eltwise24_M2PELU49_0_split
I0927 14:49:10.925221  3463 net.cpp:84] Creating Layer Eltwise24_M2PELU49_0_split
I0927 14:49:10.925225  3463 net.cpp:406] Eltwise24_M2PELU49_0_split <- Eltwise24
I0927 14:49:10.925227  3463 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_0
I0927 14:49:10.925231  3463 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_1
I0927 14:49:10.925259  3463 net.cpp:122] Setting up Eltwise24_M2PELU49_0_split
I0927 14:49:10.925263  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.925266  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.925268  3463 net.cpp:137] Memory required for data: 870240400
I0927 14:49:10.925271  3463 layer_factory.hpp:77] Creating layer Convolution52
I0927 14:49:10.925276  3463 net.cpp:84] Creating Layer Convolution52
I0927 14:49:10.925279  3463 net.cpp:406] Convolution52 <- Eltwise24_M2PELU49_0_split_0
I0927 14:49:10.925283  3463 net.cpp:380] Convolution52 -> Convolution52
I0927 14:49:10.927040  3463 net.cpp:122] Setting up Convolution52
I0927 14:49:10.927049  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.927052  3463 net.cpp:137] Memory required for data: 871494800
I0927 14:49:10.927057  3463 layer_factory.hpp:77] Creating layer BatchNorm52
I0927 14:49:10.927062  3463 net.cpp:84] Creating Layer BatchNorm52
I0927 14:49:10.927064  3463 net.cpp:406] BatchNorm52 <- Convolution52
I0927 14:49:10.927068  3463 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I0927 14:49:10.927222  3463 net.cpp:122] Setting up BatchNorm52
I0927 14:49:10.927227  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.927229  3463 net.cpp:137] Memory required for data: 872749200
I0927 14:49:10.927234  3463 layer_factory.hpp:77] Creating layer Scale52
I0927 14:49:10.927239  3463 net.cpp:84] Creating Layer Scale52
I0927 14:49:10.927242  3463 net.cpp:406] Scale52 <- Convolution52
I0927 14:49:10.927245  3463 net.cpp:367] Scale52 -> Convolution52 (in-place)
I0927 14:49:10.927274  3463 layer_factory.hpp:77] Creating layer Scale52
I0927 14:49:10.927362  3463 net.cpp:122] Setting up Scale52
I0927 14:49:10.927366  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.927368  3463 net.cpp:137] Memory required for data: 874003600
I0927 14:49:10.927372  3463 layer_factory.hpp:77] Creating layer M2PELU50
I0927 14:49:10.927377  3463 net.cpp:84] Creating Layer M2PELU50
I0927 14:49:10.927381  3463 net.cpp:406] M2PELU50 <- Convolution52
I0927 14:49:10.927384  3463 net.cpp:367] M2PELU50 -> Convolution52 (in-place)
I0927 14:49:10.927479  3463 net.cpp:122] Setting up M2PELU50
I0927 14:49:10.927484  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.927485  3463 net.cpp:137] Memory required for data: 875258000
I0927 14:49:10.927489  3463 layer_factory.hpp:77] Creating layer Convolution53
I0927 14:49:10.927513  3463 net.cpp:84] Creating Layer Convolution53
I0927 14:49:10.927516  3463 net.cpp:406] Convolution53 <- Convolution52
I0927 14:49:10.927520  3463 net.cpp:380] Convolution53 -> Convolution53
I0927 14:49:10.929589  3463 net.cpp:122] Setting up Convolution53
I0927 14:49:10.929599  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.929600  3463 net.cpp:137] Memory required for data: 876512400
I0927 14:49:10.929605  3463 layer_factory.hpp:77] Creating layer BatchNorm53
I0927 14:49:10.929611  3463 net.cpp:84] Creating Layer BatchNorm53
I0927 14:49:10.929621  3463 net.cpp:406] BatchNorm53 <- Convolution53
I0927 14:49:10.929625  3463 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I0927 14:49:10.929780  3463 net.cpp:122] Setting up BatchNorm53
I0927 14:49:10.929785  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.929787  3463 net.cpp:137] Memory required for data: 877766800
I0927 14:49:10.929792  3463 layer_factory.hpp:77] Creating layer Scale53
I0927 14:49:10.929796  3463 net.cpp:84] Creating Layer Scale53
I0927 14:49:10.929800  3463 net.cpp:406] Scale53 <- Convolution53
I0927 14:49:10.929802  3463 net.cpp:367] Scale53 -> Convolution53 (in-place)
I0927 14:49:10.929833  3463 layer_factory.hpp:77] Creating layer Scale53
I0927 14:49:10.929920  3463 net.cpp:122] Setting up Scale53
I0927 14:49:10.929926  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.929929  3463 net.cpp:137] Memory required for data: 879021200
I0927 14:49:10.929932  3463 layer_factory.hpp:77] Creating layer Eltwise25
I0927 14:49:10.929936  3463 net.cpp:84] Creating Layer Eltwise25
I0927 14:49:10.929939  3463 net.cpp:406] Eltwise25 <- Eltwise24_M2PELU49_0_split_1
I0927 14:49:10.929941  3463 net.cpp:406] Eltwise25 <- Convolution53
I0927 14:49:10.929945  3463 net.cpp:380] Eltwise25 -> Eltwise25
I0927 14:49:10.929963  3463 net.cpp:122] Setting up Eltwise25
I0927 14:49:10.929967  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.929970  3463 net.cpp:137] Memory required for data: 880275600
I0927 14:49:10.929971  3463 layer_factory.hpp:77] Creating layer M2PELU51
I0927 14:49:10.929976  3463 net.cpp:84] Creating Layer M2PELU51
I0927 14:49:10.929978  3463 net.cpp:406] M2PELU51 <- Eltwise25
I0927 14:49:10.929982  3463 net.cpp:367] M2PELU51 -> Eltwise25 (in-place)
I0927 14:49:10.930078  3463 net.cpp:122] Setting up M2PELU51
I0927 14:49:10.930081  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.930083  3463 net.cpp:137] Memory required for data: 881530000
I0927 14:49:10.930088  3463 layer_factory.hpp:77] Creating layer Eltwise25_M2PELU51_0_split
I0927 14:49:10.930090  3463 net.cpp:84] Creating Layer Eltwise25_M2PELU51_0_split
I0927 14:49:10.930094  3463 net.cpp:406] Eltwise25_M2PELU51_0_split <- Eltwise25
I0927 14:49:10.930097  3463 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_0
I0927 14:49:10.930101  3463 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_1
I0927 14:49:10.930127  3463 net.cpp:122] Setting up Eltwise25_M2PELU51_0_split
I0927 14:49:10.930131  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.930135  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.930136  3463 net.cpp:137] Memory required for data: 884038800
I0927 14:49:10.930138  3463 layer_factory.hpp:77] Creating layer Convolution54
I0927 14:49:10.930145  3463 net.cpp:84] Creating Layer Convolution54
I0927 14:49:10.930147  3463 net.cpp:406] Convolution54 <- Eltwise25_M2PELU51_0_split_0
I0927 14:49:10.930151  3463 net.cpp:380] Convolution54 -> Convolution54
I0927 14:49:10.932413  3463 net.cpp:122] Setting up Convolution54
I0927 14:49:10.932423  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.932426  3463 net.cpp:137] Memory required for data: 885293200
I0927 14:49:10.932430  3463 layer_factory.hpp:77] Creating layer BatchNorm54
I0927 14:49:10.932435  3463 net.cpp:84] Creating Layer BatchNorm54
I0927 14:49:10.932437  3463 net.cpp:406] BatchNorm54 <- Convolution54
I0927 14:49:10.932442  3463 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I0927 14:49:10.932595  3463 net.cpp:122] Setting up BatchNorm54
I0927 14:49:10.932600  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.932602  3463 net.cpp:137] Memory required for data: 886547600
I0927 14:49:10.932606  3463 layer_factory.hpp:77] Creating layer Scale54
I0927 14:49:10.932610  3463 net.cpp:84] Creating Layer Scale54
I0927 14:49:10.932613  3463 net.cpp:406] Scale54 <- Convolution54
I0927 14:49:10.932620  3463 net.cpp:367] Scale54 -> Convolution54 (in-place)
I0927 14:49:10.932649  3463 layer_factory.hpp:77] Creating layer Scale54
I0927 14:49:10.932746  3463 net.cpp:122] Setting up Scale54
I0927 14:49:10.932751  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.932754  3463 net.cpp:137] Memory required for data: 887802000
I0927 14:49:10.932757  3463 layer_factory.hpp:77] Creating layer M2PELU52
I0927 14:49:10.932762  3463 net.cpp:84] Creating Layer M2PELU52
I0927 14:49:10.932765  3463 net.cpp:406] M2PELU52 <- Convolution54
I0927 14:49:10.932770  3463 net.cpp:367] M2PELU52 -> Convolution54 (in-place)
I0927 14:49:10.932867  3463 net.cpp:122] Setting up M2PELU52
I0927 14:49:10.932871  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.932873  3463 net.cpp:137] Memory required for data: 889056400
I0927 14:49:10.932876  3463 layer_factory.hpp:77] Creating layer Convolution55
I0927 14:49:10.932883  3463 net.cpp:84] Creating Layer Convolution55
I0927 14:49:10.932886  3463 net.cpp:406] Convolution55 <- Convolution54
I0927 14:49:10.932889  3463 net.cpp:380] Convolution55 -> Convolution55
I0927 14:49:10.934957  3463 net.cpp:122] Setting up Convolution55
I0927 14:49:10.934967  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.934969  3463 net.cpp:137] Memory required for data: 890310800
I0927 14:49:10.934974  3463 layer_factory.hpp:77] Creating layer BatchNorm55
I0927 14:49:10.934979  3463 net.cpp:84] Creating Layer BatchNorm55
I0927 14:49:10.934983  3463 net.cpp:406] BatchNorm55 <- Convolution55
I0927 14:49:10.934986  3463 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I0927 14:49:10.935143  3463 net.cpp:122] Setting up BatchNorm55
I0927 14:49:10.935148  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.935150  3463 net.cpp:137] Memory required for data: 891565200
I0927 14:49:10.935155  3463 layer_factory.hpp:77] Creating layer Scale55
I0927 14:49:10.935160  3463 net.cpp:84] Creating Layer Scale55
I0927 14:49:10.935163  3463 net.cpp:406] Scale55 <- Convolution55
I0927 14:49:10.935166  3463 net.cpp:367] Scale55 -> Convolution55 (in-place)
I0927 14:49:10.935197  3463 layer_factory.hpp:77] Creating layer Scale55
I0927 14:49:10.935286  3463 net.cpp:122] Setting up Scale55
I0927 14:49:10.935292  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.935293  3463 net.cpp:137] Memory required for data: 892819600
I0927 14:49:10.935297  3463 layer_factory.hpp:77] Creating layer Eltwise26
I0927 14:49:10.935302  3463 net.cpp:84] Creating Layer Eltwise26
I0927 14:49:10.935304  3463 net.cpp:406] Eltwise26 <- Eltwise25_M2PELU51_0_split_1
I0927 14:49:10.935307  3463 net.cpp:406] Eltwise26 <- Convolution55
I0927 14:49:10.935312  3463 net.cpp:380] Eltwise26 -> Eltwise26
I0927 14:49:10.935329  3463 net.cpp:122] Setting up Eltwise26
I0927 14:49:10.935333  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.935335  3463 net.cpp:137] Memory required for data: 894074000
I0927 14:49:10.935338  3463 layer_factory.hpp:77] Creating layer M2PELU53
I0927 14:49:10.935343  3463 net.cpp:84] Creating Layer M2PELU53
I0927 14:49:10.935345  3463 net.cpp:406] M2PELU53 <- Eltwise26
I0927 14:49:10.935348  3463 net.cpp:367] M2PELU53 -> Eltwise26 (in-place)
I0927 14:49:10.935446  3463 net.cpp:122] Setting up M2PELU53
I0927 14:49:10.935449  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.935451  3463 net.cpp:137] Memory required for data: 895328400
I0927 14:49:10.935456  3463 layer_factory.hpp:77] Creating layer Eltwise26_M2PELU53_0_split
I0927 14:49:10.935459  3463 net.cpp:84] Creating Layer Eltwise26_M2PELU53_0_split
I0927 14:49:10.935461  3463 net.cpp:406] Eltwise26_M2PELU53_0_split <- Eltwise26
I0927 14:49:10.935465  3463 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_0
I0927 14:49:10.935469  3463 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_1
I0927 14:49:10.935497  3463 net.cpp:122] Setting up Eltwise26_M2PELU53_0_split
I0927 14:49:10.935499  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.935503  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.935504  3463 net.cpp:137] Memory required for data: 897837200
I0927 14:49:10.935513  3463 layer_factory.hpp:77] Creating layer Convolution56
I0927 14:49:10.935521  3463 net.cpp:84] Creating Layer Convolution56
I0927 14:49:10.935524  3463 net.cpp:406] Convolution56 <- Eltwise26_M2PELU53_0_split_0
I0927 14:49:10.935529  3463 net.cpp:380] Convolution56 -> Convolution56
I0927 14:49:10.937283  3463 net.cpp:122] Setting up Convolution56
I0927 14:49:10.937291  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.937294  3463 net.cpp:137] Memory required for data: 899091600
I0927 14:49:10.937299  3463 layer_factory.hpp:77] Creating layer BatchNorm56
I0927 14:49:10.937304  3463 net.cpp:84] Creating Layer BatchNorm56
I0927 14:49:10.937305  3463 net.cpp:406] BatchNorm56 <- Convolution56
I0927 14:49:10.937310  3463 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I0927 14:49:10.952527  3463 net.cpp:122] Setting up BatchNorm56
I0927 14:49:10.952535  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.952538  3463 net.cpp:137] Memory required for data: 900346000
I0927 14:49:10.952544  3463 layer_factory.hpp:77] Creating layer Scale56
I0927 14:49:10.952549  3463 net.cpp:84] Creating Layer Scale56
I0927 14:49:10.952553  3463 net.cpp:406] Scale56 <- Convolution56
I0927 14:49:10.952558  3463 net.cpp:367] Scale56 -> Convolution56 (in-place)
I0927 14:49:10.952591  3463 layer_factory.hpp:77] Creating layer Scale56
I0927 14:49:10.952687  3463 net.cpp:122] Setting up Scale56
I0927 14:49:10.952692  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.952693  3463 net.cpp:137] Memory required for data: 901600400
I0927 14:49:10.952697  3463 layer_factory.hpp:77] Creating layer M2PELU54
I0927 14:49:10.952703  3463 net.cpp:84] Creating Layer M2PELU54
I0927 14:49:10.952705  3463 net.cpp:406] M2PELU54 <- Convolution56
I0927 14:49:10.952710  3463 net.cpp:367] M2PELU54 -> Convolution56 (in-place)
I0927 14:49:10.952813  3463 net.cpp:122] Setting up M2PELU54
I0927 14:49:10.952818  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.952821  3463 net.cpp:137] Memory required for data: 902854800
I0927 14:49:10.952824  3463 layer_factory.hpp:77] Creating layer Convolution57
I0927 14:49:10.952832  3463 net.cpp:84] Creating Layer Convolution57
I0927 14:49:10.952834  3463 net.cpp:406] Convolution57 <- Convolution56
I0927 14:49:10.952839  3463 net.cpp:380] Convolution57 -> Convolution57
I0927 14:49:10.955263  3463 net.cpp:122] Setting up Convolution57
I0927 14:49:10.955272  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.955276  3463 net.cpp:137] Memory required for data: 904109200
I0927 14:49:10.955281  3463 layer_factory.hpp:77] Creating layer BatchNorm57
I0927 14:49:10.955286  3463 net.cpp:84] Creating Layer BatchNorm57
I0927 14:49:10.955288  3463 net.cpp:406] BatchNorm57 <- Convolution57
I0927 14:49:10.955292  3463 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I0927 14:49:10.955456  3463 net.cpp:122] Setting up BatchNorm57
I0927 14:49:10.955459  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.955462  3463 net.cpp:137] Memory required for data: 905363600
I0927 14:49:10.955466  3463 layer_factory.hpp:77] Creating layer Scale57
I0927 14:49:10.955471  3463 net.cpp:84] Creating Layer Scale57
I0927 14:49:10.955473  3463 net.cpp:406] Scale57 <- Convolution57
I0927 14:49:10.955476  3463 net.cpp:367] Scale57 -> Convolution57 (in-place)
I0927 14:49:10.955508  3463 layer_factory.hpp:77] Creating layer Scale57
I0927 14:49:10.955600  3463 net.cpp:122] Setting up Scale57
I0927 14:49:10.955605  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.955607  3463 net.cpp:137] Memory required for data: 906618000
I0927 14:49:10.955611  3463 layer_factory.hpp:77] Creating layer Eltwise27
I0927 14:49:10.955616  3463 net.cpp:84] Creating Layer Eltwise27
I0927 14:49:10.955620  3463 net.cpp:406] Eltwise27 <- Eltwise26_M2PELU53_0_split_1
I0927 14:49:10.955622  3463 net.cpp:406] Eltwise27 <- Convolution57
I0927 14:49:10.955626  3463 net.cpp:380] Eltwise27 -> Eltwise27
I0927 14:49:10.955646  3463 net.cpp:122] Setting up Eltwise27
I0927 14:49:10.955655  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.955658  3463 net.cpp:137] Memory required for data: 907872400
I0927 14:49:10.955660  3463 layer_factory.hpp:77] Creating layer M2PELU55
I0927 14:49:10.955665  3463 net.cpp:84] Creating Layer M2PELU55
I0927 14:49:10.955667  3463 net.cpp:406] M2PELU55 <- Eltwise27
I0927 14:49:10.955670  3463 net.cpp:367] M2PELU55 -> Eltwise27 (in-place)
I0927 14:49:10.955771  3463 net.cpp:122] Setting up M2PELU55
I0927 14:49:10.955776  3463 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 14:49:10.955778  3463 net.cpp:137] Memory required for data: 909126800
I0927 14:49:10.955782  3463 layer_factory.hpp:77] Creating layer Pooling1
I0927 14:49:10.955786  3463 net.cpp:84] Creating Layer Pooling1
I0927 14:49:10.955790  3463 net.cpp:406] Pooling1 <- Eltwise27
I0927 14:49:10.955793  3463 net.cpp:380] Pooling1 -> Pooling1
I0927 14:49:10.956296  3463 net.cpp:122] Setting up Pooling1
I0927 14:49:10.956305  3463 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0927 14:49:10.956307  3463 net.cpp:137] Memory required for data: 909152400
I0927 14:49:10.956310  3463 layer_factory.hpp:77] Creating layer InnerProduct1
I0927 14:49:10.956320  3463 net.cpp:84] Creating Layer InnerProduct1
I0927 14:49:10.956321  3463 net.cpp:406] InnerProduct1 <- Pooling1
I0927 14:49:10.956326  3463 net.cpp:380] InnerProduct1 -> InnerProduct1
I0927 14:49:10.956439  3463 net.cpp:122] Setting up InnerProduct1
I0927 14:49:10.956444  3463 net.cpp:129] Top shape: 100 10 (1000)
I0927 14:49:10.956445  3463 net.cpp:137] Memory required for data: 909156400
I0927 14:49:10.956449  3463 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0927 14:49:10.956454  3463 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0927 14:49:10.956455  3463 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I0927 14:49:10.956459  3463 net.cpp:406] SoftmaxWithLoss1 <- Data2
I0927 14:49:10.956465  3463 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0927 14:49:10.956470  3463 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0927 14:49:10.956662  3463 net.cpp:122] Setting up SoftmaxWithLoss1
I0927 14:49:10.956668  3463 net.cpp:129] Top shape: (1)
I0927 14:49:10.956670  3463 net.cpp:132]     with loss weight 1
I0927 14:49:10.956682  3463 net.cpp:137] Memory required for data: 909156404
I0927 14:49:10.956686  3463 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0927 14:49:10.956688  3463 net.cpp:198] InnerProduct1 needs backward computation.
I0927 14:49:10.956691  3463 net.cpp:198] Pooling1 needs backward computation.
I0927 14:49:10.956692  3463 net.cpp:198] M2PELU55 needs backward computation.
I0927 14:49:10.956694  3463 net.cpp:198] Eltwise27 needs backward computation.
I0927 14:49:10.956696  3463 net.cpp:198] Scale57 needs backward computation.
I0927 14:49:10.956698  3463 net.cpp:198] BatchNorm57 needs backward computation.
I0927 14:49:10.956701  3463 net.cpp:198] Convolution57 needs backward computation.
I0927 14:49:10.956702  3463 net.cpp:198] M2PELU54 needs backward computation.
I0927 14:49:10.956704  3463 net.cpp:198] Scale56 needs backward computation.
I0927 14:49:10.956707  3463 net.cpp:198] BatchNorm56 needs backward computation.
I0927 14:49:10.956708  3463 net.cpp:198] Convolution56 needs backward computation.
I0927 14:49:10.956710  3463 net.cpp:198] Eltwise26_M2PELU53_0_split needs backward computation.
I0927 14:49:10.956713  3463 net.cpp:198] M2PELU53 needs backward computation.
I0927 14:49:10.956715  3463 net.cpp:198] Eltwise26 needs backward computation.
I0927 14:49:10.956717  3463 net.cpp:198] Scale55 needs backward computation.
I0927 14:49:10.956719  3463 net.cpp:198] BatchNorm55 needs backward computation.
I0927 14:49:10.956722  3463 net.cpp:198] Convolution55 needs backward computation.
I0927 14:49:10.956723  3463 net.cpp:198] M2PELU52 needs backward computation.
I0927 14:49:10.956725  3463 net.cpp:198] Scale54 needs backward computation.
I0927 14:49:10.956727  3463 net.cpp:198] BatchNorm54 needs backward computation.
I0927 14:49:10.956729  3463 net.cpp:198] Convolution54 needs backward computation.
I0927 14:49:10.956737  3463 net.cpp:198] Eltwise25_M2PELU51_0_split needs backward computation.
I0927 14:49:10.956740  3463 net.cpp:198] M2PELU51 needs backward computation.
I0927 14:49:10.956743  3463 net.cpp:198] Eltwise25 needs backward computation.
I0927 14:49:10.956745  3463 net.cpp:198] Scale53 needs backward computation.
I0927 14:49:10.956748  3463 net.cpp:198] BatchNorm53 needs backward computation.
I0927 14:49:10.956749  3463 net.cpp:198] Convolution53 needs backward computation.
I0927 14:49:10.956751  3463 net.cpp:198] M2PELU50 needs backward computation.
I0927 14:49:10.956754  3463 net.cpp:198] Scale52 needs backward computation.
I0927 14:49:10.956756  3463 net.cpp:198] BatchNorm52 needs backward computation.
I0927 14:49:10.956758  3463 net.cpp:198] Convolution52 needs backward computation.
I0927 14:49:10.956760  3463 net.cpp:198] Eltwise24_M2PELU49_0_split needs backward computation.
I0927 14:49:10.956763  3463 net.cpp:198] M2PELU49 needs backward computation.
I0927 14:49:10.956765  3463 net.cpp:198] Eltwise24 needs backward computation.
I0927 14:49:10.956768  3463 net.cpp:198] Scale51 needs backward computation.
I0927 14:49:10.956770  3463 net.cpp:198] BatchNorm51 needs backward computation.
I0927 14:49:10.956773  3463 net.cpp:198] Convolution51 needs backward computation.
I0927 14:49:10.956774  3463 net.cpp:198] M2PELU48 needs backward computation.
I0927 14:49:10.956776  3463 net.cpp:198] Scale50 needs backward computation.
I0927 14:49:10.956779  3463 net.cpp:198] BatchNorm50 needs backward computation.
I0927 14:49:10.956780  3463 net.cpp:198] Convolution50 needs backward computation.
I0927 14:49:10.956784  3463 net.cpp:198] Eltwise23_M2PELU47_0_split needs backward computation.
I0927 14:49:10.956785  3463 net.cpp:198] M2PELU47 needs backward computation.
I0927 14:49:10.956787  3463 net.cpp:198] Eltwise23 needs backward computation.
I0927 14:49:10.956790  3463 net.cpp:198] Scale49 needs backward computation.
I0927 14:49:10.956792  3463 net.cpp:198] BatchNorm49 needs backward computation.
I0927 14:49:10.956794  3463 net.cpp:198] Convolution49 needs backward computation.
I0927 14:49:10.956796  3463 net.cpp:198] M2PELU46 needs backward computation.
I0927 14:49:10.956799  3463 net.cpp:198] Scale48 needs backward computation.
I0927 14:49:10.956800  3463 net.cpp:198] BatchNorm48 needs backward computation.
I0927 14:49:10.956804  3463 net.cpp:198] Convolution48 needs backward computation.
I0927 14:49:10.956805  3463 net.cpp:198] Eltwise22_M2PELU45_0_split needs backward computation.
I0927 14:49:10.956809  3463 net.cpp:198] M2PELU45 needs backward computation.
I0927 14:49:10.956810  3463 net.cpp:198] Eltwise22 needs backward computation.
I0927 14:49:10.956812  3463 net.cpp:198] Scale47 needs backward computation.
I0927 14:49:10.956815  3463 net.cpp:198] BatchNorm47 needs backward computation.
I0927 14:49:10.956816  3463 net.cpp:198] Convolution47 needs backward computation.
I0927 14:49:10.956820  3463 net.cpp:198] M2PELU44 needs backward computation.
I0927 14:49:10.956821  3463 net.cpp:198] Scale46 needs backward computation.
I0927 14:49:10.956823  3463 net.cpp:198] BatchNorm46 needs backward computation.
I0927 14:49:10.956825  3463 net.cpp:198] Convolution46 needs backward computation.
I0927 14:49:10.956827  3463 net.cpp:198] Eltwise21_M2PELU43_0_split needs backward computation.
I0927 14:49:10.956830  3463 net.cpp:198] M2PELU43 needs backward computation.
I0927 14:49:10.956832  3463 net.cpp:198] Eltwise21 needs backward computation.
I0927 14:49:10.956835  3463 net.cpp:198] Scale45 needs backward computation.
I0927 14:49:10.956837  3463 net.cpp:198] BatchNorm45 needs backward computation.
I0927 14:49:10.956840  3463 net.cpp:198] Convolution45 needs backward computation.
I0927 14:49:10.956841  3463 net.cpp:198] M2PELU42 needs backward computation.
I0927 14:49:10.956843  3463 net.cpp:198] Scale44 needs backward computation.
I0927 14:49:10.956845  3463 net.cpp:198] BatchNorm44 needs backward computation.
I0927 14:49:10.956847  3463 net.cpp:198] Convolution44 needs backward computation.
I0927 14:49:10.956849  3463 net.cpp:198] Eltwise20_M2PELU41_0_split needs backward computation.
I0927 14:49:10.956856  3463 net.cpp:198] M2PELU41 needs backward computation.
I0927 14:49:10.956857  3463 net.cpp:198] Eltwise20 needs backward computation.
I0927 14:49:10.956861  3463 net.cpp:198] Scale43 needs backward computation.
I0927 14:49:10.956862  3463 net.cpp:198] BatchNorm43 needs backward computation.
I0927 14:49:10.956864  3463 net.cpp:198] Convolution43 needs backward computation.
I0927 14:49:10.956867  3463 net.cpp:198] M2PELU40 needs backward computation.
I0927 14:49:10.956869  3463 net.cpp:198] Scale42 needs backward computation.
I0927 14:49:10.956871  3463 net.cpp:198] BatchNorm42 needs backward computation.
I0927 14:49:10.956873  3463 net.cpp:198] Convolution42 needs backward computation.
I0927 14:49:10.956876  3463 net.cpp:198] Eltwise19_M2PELU39_0_split needs backward computation.
I0927 14:49:10.956878  3463 net.cpp:198] M2PELU39 needs backward computation.
I0927 14:49:10.956881  3463 net.cpp:198] Eltwise19 needs backward computation.
I0927 14:49:10.956883  3463 net.cpp:198] Scale41 needs backward computation.
I0927 14:49:10.956885  3463 net.cpp:198] BatchNorm41 needs backward computation.
I0927 14:49:10.956888  3463 net.cpp:198] Convolution41 needs backward computation.
I0927 14:49:10.956890  3463 net.cpp:198] M2PELU38 needs backward computation.
I0927 14:49:10.956892  3463 net.cpp:198] Scale40 needs backward computation.
I0927 14:49:10.956894  3463 net.cpp:198] BatchNorm40 needs backward computation.
I0927 14:49:10.956899  3463 net.cpp:198] Convolution40 needs backward computation.
I0927 14:49:10.956902  3463 net.cpp:198] Scale39 needs backward computation.
I0927 14:49:10.956903  3463 net.cpp:198] BatchNorm39 needs backward computation.
I0927 14:49:10.956905  3463 net.cpp:198] Convolution39 needs backward computation.
I0927 14:49:10.956908  3463 net.cpp:198] Eltwise18_M2PELU37_0_split needs backward computation.
I0927 14:49:10.956912  3463 net.cpp:198] M2PELU37 needs backward computation.
I0927 14:49:10.956913  3463 net.cpp:198] Eltwise18 needs backward computation.
I0927 14:49:10.956915  3463 net.cpp:198] Scale38 needs backward computation.
I0927 14:49:10.956918  3463 net.cpp:198] BatchNorm38 needs backward computation.
I0927 14:49:10.956920  3463 net.cpp:198] Convolution38 needs backward computation.
I0927 14:49:10.956923  3463 net.cpp:198] M2PELU36 needs backward computation.
I0927 14:49:10.956924  3463 net.cpp:198] Scale37 needs backward computation.
I0927 14:49:10.956926  3463 net.cpp:198] BatchNorm37 needs backward computation.
I0927 14:49:10.956928  3463 net.cpp:198] Convolution37 needs backward computation.
I0927 14:49:10.956931  3463 net.cpp:198] Eltwise17_M2PELU35_0_split needs backward computation.
I0927 14:49:10.956933  3463 net.cpp:198] M2PELU35 needs backward computation.
I0927 14:49:10.956935  3463 net.cpp:198] Eltwise17 needs backward computation.
I0927 14:49:10.956938  3463 net.cpp:198] Scale36 needs backward computation.
I0927 14:49:10.956940  3463 net.cpp:198] BatchNorm36 needs backward computation.
I0927 14:49:10.956943  3463 net.cpp:198] Convolution36 needs backward computation.
I0927 14:49:10.956945  3463 net.cpp:198] M2PELU34 needs backward computation.
I0927 14:49:10.956948  3463 net.cpp:198] Scale35 needs backward computation.
I0927 14:49:10.956949  3463 net.cpp:198] BatchNorm35 needs backward computation.
I0927 14:49:10.956951  3463 net.cpp:198] Convolution35 needs backward computation.
I0927 14:49:10.956954  3463 net.cpp:198] Eltwise16_M2PELU33_0_split needs backward computation.
I0927 14:49:10.956956  3463 net.cpp:198] M2PELU33 needs backward computation.
I0927 14:49:10.956959  3463 net.cpp:198] Eltwise16 needs backward computation.
I0927 14:49:10.956961  3463 net.cpp:198] Scale34 needs backward computation.
I0927 14:49:10.956964  3463 net.cpp:198] BatchNorm34 needs backward computation.
I0927 14:49:10.956965  3463 net.cpp:198] Convolution34 needs backward computation.
I0927 14:49:10.956967  3463 net.cpp:198] M2PELU32 needs backward computation.
I0927 14:49:10.956970  3463 net.cpp:198] Scale33 needs backward computation.
I0927 14:49:10.956975  3463 net.cpp:198] BatchNorm33 needs backward computation.
I0927 14:49:10.956977  3463 net.cpp:198] Convolution33 needs backward computation.
I0927 14:49:10.956980  3463 net.cpp:198] Eltwise15_M2PELU31_0_split needs backward computation.
I0927 14:49:10.956982  3463 net.cpp:198] M2PELU31 needs backward computation.
I0927 14:49:10.956984  3463 net.cpp:198] Eltwise15 needs backward computation.
I0927 14:49:10.956987  3463 net.cpp:198] Scale32 needs backward computation.
I0927 14:49:10.956990  3463 net.cpp:198] BatchNorm32 needs backward computation.
I0927 14:49:10.956991  3463 net.cpp:198] Convolution32 needs backward computation.
I0927 14:49:10.982957  3463 net.cpp:198] M2PELU30 needs backward computation.
I0927 14:49:10.982967  3463 net.cpp:198] Scale31 needs backward computation.
I0927 14:49:10.982971  3463 net.cpp:198] BatchNorm31 needs backward computation.
I0927 14:49:10.982975  3463 net.cpp:198] Convolution31 needs backward computation.
I0927 14:49:10.982980  3463 net.cpp:198] Eltwise14_M2PELU29_0_split needs backward computation.
I0927 14:49:10.982985  3463 net.cpp:198] M2PELU29 needs backward computation.
I0927 14:49:10.982988  3463 net.cpp:198] Eltwise14 needs backward computation.
I0927 14:49:10.982993  3463 net.cpp:198] Scale30 needs backward computation.
I0927 14:49:10.982997  3463 net.cpp:198] BatchNorm30 needs backward computation.
I0927 14:49:10.983000  3463 net.cpp:198] Convolution30 needs backward computation.
I0927 14:49:10.983005  3463 net.cpp:198] M2PELU28 needs backward computation.
I0927 14:49:10.983008  3463 net.cpp:198] Scale29 needs backward computation.
I0927 14:49:10.983012  3463 net.cpp:198] BatchNorm29 needs backward computation.
I0927 14:49:10.983016  3463 net.cpp:198] Convolution29 needs backward computation.
I0927 14:49:10.983021  3463 net.cpp:198] Eltwise13_M2PELU27_0_split needs backward computation.
I0927 14:49:10.983026  3463 net.cpp:198] M2PELU27 needs backward computation.
I0927 14:49:10.983027  3463 net.cpp:198] Eltwise13 needs backward computation.
I0927 14:49:10.983031  3463 net.cpp:198] Scale28 needs backward computation.
I0927 14:49:10.983033  3463 net.cpp:198] BatchNorm28 needs backward computation.
I0927 14:49:10.983036  3463 net.cpp:198] Convolution28 needs backward computation.
I0927 14:49:10.983038  3463 net.cpp:198] M2PELU26 needs backward computation.
I0927 14:49:10.983041  3463 net.cpp:198] Scale27 needs backward computation.
I0927 14:49:10.983042  3463 net.cpp:198] BatchNorm27 needs backward computation.
I0927 14:49:10.983045  3463 net.cpp:198] Convolution27 needs backward computation.
I0927 14:49:10.983047  3463 net.cpp:198] Eltwise12_M2PELU25_0_split needs backward computation.
I0927 14:49:10.983050  3463 net.cpp:198] M2PELU25 needs backward computation.
I0927 14:49:10.983052  3463 net.cpp:198] Eltwise12 needs backward computation.
I0927 14:49:10.983055  3463 net.cpp:198] Scale26 needs backward computation.
I0927 14:49:10.983058  3463 net.cpp:198] BatchNorm26 needs backward computation.
I0927 14:49:10.983060  3463 net.cpp:198] Convolution26 needs backward computation.
I0927 14:49:10.983062  3463 net.cpp:198] M2PELU24 needs backward computation.
I0927 14:49:10.983065  3463 net.cpp:198] Scale25 needs backward computation.
I0927 14:49:10.983067  3463 net.cpp:198] BatchNorm25 needs backward computation.
I0927 14:49:10.983069  3463 net.cpp:198] Convolution25 needs backward computation.
I0927 14:49:10.983072  3463 net.cpp:198] Eltwise11_M2PELU23_0_split needs backward computation.
I0927 14:49:10.983074  3463 net.cpp:198] M2PELU23 needs backward computation.
I0927 14:49:10.983078  3463 net.cpp:198] Eltwise11 needs backward computation.
I0927 14:49:10.983080  3463 net.cpp:198] Scale24 needs backward computation.
I0927 14:49:10.983083  3463 net.cpp:198] BatchNorm24 needs backward computation.
I0927 14:49:10.983084  3463 net.cpp:198] Convolution24 needs backward computation.
I0927 14:49:10.983088  3463 net.cpp:198] M2PELU22 needs backward computation.
I0927 14:49:10.983089  3463 net.cpp:198] Scale23 needs backward computation.
I0927 14:49:10.983099  3463 net.cpp:198] BatchNorm23 needs backward computation.
I0927 14:49:10.983101  3463 net.cpp:198] Convolution23 needs backward computation.
I0927 14:49:10.983104  3463 net.cpp:198] Eltwise10_M2PELU21_0_split needs backward computation.
I0927 14:49:10.983108  3463 net.cpp:198] M2PELU21 needs backward computation.
I0927 14:49:10.983109  3463 net.cpp:198] Eltwise10 needs backward computation.
I0927 14:49:10.983113  3463 net.cpp:198] Scale22 needs backward computation.
I0927 14:49:10.983115  3463 net.cpp:198] BatchNorm22 needs backward computation.
I0927 14:49:10.983117  3463 net.cpp:198] Convolution22 needs backward computation.
I0927 14:49:10.983120  3463 net.cpp:198] M2PELU20 needs backward computation.
I0927 14:49:10.983124  3463 net.cpp:198] Scale21 needs backward computation.
I0927 14:49:10.983125  3463 net.cpp:198] BatchNorm21 needs backward computation.
I0927 14:49:10.983127  3463 net.cpp:198] Convolution21 needs backward computation.
I0927 14:49:10.983130  3463 net.cpp:198] Scale20 needs backward computation.
I0927 14:49:10.983132  3463 net.cpp:198] BatchNorm20 needs backward computation.
I0927 14:49:10.983135  3463 net.cpp:198] Convolution20 needs backward computation.
I0927 14:49:10.983137  3463 net.cpp:198] Eltwise9_M2PELU19_0_split needs backward computation.
I0927 14:49:10.983140  3463 net.cpp:198] M2PELU19 needs backward computation.
I0927 14:49:10.983142  3463 net.cpp:198] Eltwise9 needs backward computation.
I0927 14:49:10.983145  3463 net.cpp:198] Scale19 needs backward computation.
I0927 14:49:10.983148  3463 net.cpp:198] BatchNorm19 needs backward computation.
I0927 14:49:10.983150  3463 net.cpp:198] Convolution19 needs backward computation.
I0927 14:49:10.983155  3463 net.cpp:198] M2PELU18 needs backward computation.
I0927 14:49:10.983157  3463 net.cpp:198] Scale18 needs backward computation.
I0927 14:49:10.983160  3463 net.cpp:198] BatchNorm18 needs backward computation.
I0927 14:49:10.983162  3463 net.cpp:198] Convolution18 needs backward computation.
I0927 14:49:10.983165  3463 net.cpp:198] Eltwise8_M2PELU17_0_split needs backward computation.
I0927 14:49:10.983167  3463 net.cpp:198] M2PELU17 needs backward computation.
I0927 14:49:10.983170  3463 net.cpp:198] Eltwise8 needs backward computation.
I0927 14:49:10.983172  3463 net.cpp:198] Scale17 needs backward computation.
I0927 14:49:10.983175  3463 net.cpp:198] BatchNorm17 needs backward computation.
I0927 14:49:10.983177  3463 net.cpp:198] Convolution17 needs backward computation.
I0927 14:49:10.983180  3463 net.cpp:198] M2PELU16 needs backward computation.
I0927 14:49:10.983182  3463 net.cpp:198] Scale16 needs backward computation.
I0927 14:49:10.983184  3463 net.cpp:198] BatchNorm16 needs backward computation.
I0927 14:49:10.983186  3463 net.cpp:198] Convolution16 needs backward computation.
I0927 14:49:10.983189  3463 net.cpp:198] Eltwise7_M2PELU15_0_split needs backward computation.
I0927 14:49:10.983192  3463 net.cpp:198] M2PELU15 needs backward computation.
I0927 14:49:10.983194  3463 net.cpp:198] Eltwise7 needs backward computation.
I0927 14:49:10.983197  3463 net.cpp:198] Scale15 needs backward computation.
I0927 14:49:10.983199  3463 net.cpp:198] BatchNorm15 needs backward computation.
I0927 14:49:10.983201  3463 net.cpp:198] Convolution15 needs backward computation.
I0927 14:49:10.983204  3463 net.cpp:198] M2PELU14 needs backward computation.
I0927 14:49:10.983206  3463 net.cpp:198] Scale14 needs backward computation.
I0927 14:49:10.983209  3463 net.cpp:198] BatchNorm14 needs backward computation.
I0927 14:49:10.983211  3463 net.cpp:198] Convolution14 needs backward computation.
I0927 14:49:10.983214  3463 net.cpp:198] Eltwise6_M2PELU13_0_split needs backward computation.
I0927 14:49:10.983217  3463 net.cpp:198] M2PELU13 needs backward computation.
I0927 14:49:10.983219  3463 net.cpp:198] Eltwise6 needs backward computation.
I0927 14:49:10.983222  3463 net.cpp:198] Scale13 needs backward computation.
I0927 14:49:10.983224  3463 net.cpp:198] BatchNorm13 needs backward computation.
I0927 14:49:10.983227  3463 net.cpp:198] Convolution13 needs backward computation.
I0927 14:49:10.983232  3463 net.cpp:198] M2PELU12 needs backward computation.
I0927 14:49:10.983235  3463 net.cpp:198] Scale12 needs backward computation.
I0927 14:49:10.983237  3463 net.cpp:198] BatchNorm12 needs backward computation.
I0927 14:49:10.983239  3463 net.cpp:198] Convolution12 needs backward computation.
I0927 14:49:10.983242  3463 net.cpp:198] Eltwise5_M2PELU11_0_split needs backward computation.
I0927 14:49:10.983245  3463 net.cpp:198] M2PELU11 needs backward computation.
I0927 14:49:10.983247  3463 net.cpp:198] Eltwise5 needs backward computation.
I0927 14:49:10.985313  3463 net.cpp:198] Scale11 needs backward computation.
I0927 14:49:10.985322  3463 net.cpp:198] BatchNorm11 needs backward computation.
I0927 14:49:10.985335  3463 net.cpp:198] Convolution11 needs backward computation.
I0927 14:49:10.985339  3463 net.cpp:198] M2PELU10 needs backward computation.
I0927 14:49:10.985353  3463 net.cpp:198] Scale10 needs backward computation.
I0927 14:49:10.985357  3463 net.cpp:198] BatchNorm10 needs backward computation.
I0927 14:49:10.985360  3463 net.cpp:198] Convolution10 needs backward computation.
I0927 14:49:10.985364  3463 net.cpp:198] Eltwise4_M2PELU9_0_split needs backward computation.
I0927 14:49:10.985369  3463 net.cpp:198] M2PELU9 needs backward computation.
I0927 14:49:10.985373  3463 net.cpp:198] Eltwise4 needs backward computation.
I0927 14:49:10.985378  3463 net.cpp:198] Scale9 needs backward computation.
I0927 14:49:10.985381  3463 net.cpp:198] BatchNorm9 needs backward computation.
I0927 14:49:10.985383  3463 net.cpp:198] Convolution9 needs backward computation.
I0927 14:49:10.985386  3463 net.cpp:198] M2PELU8 needs backward computation.
I0927 14:49:10.985399  3463 net.cpp:198] Scale8 needs backward computation.
I0927 14:49:10.985400  3463 net.cpp:198] BatchNorm8 needs backward computation.
I0927 14:49:10.985402  3463 net.cpp:198] Convolution8 needs backward computation.
I0927 14:49:10.985405  3463 net.cpp:198] Eltwise3_M2PELU7_0_split needs backward computation.
I0927 14:49:10.985407  3463 net.cpp:198] M2PELU7 needs backward computation.
I0927 14:49:10.985409  3463 net.cpp:198] Eltwise3 needs backward computation.
I0927 14:49:10.985412  3463 net.cpp:198] Scale7 needs backward computation.
I0927 14:49:10.985415  3463 net.cpp:198] BatchNorm7 needs backward computation.
I0927 14:49:10.985417  3463 net.cpp:198] Convolution7 needs backward computation.
I0927 14:49:10.985419  3463 net.cpp:198] M2PELU6 needs backward computation.
I0927 14:49:10.985421  3463 net.cpp:198] Scale6 needs backward computation.
I0927 14:49:10.985424  3463 net.cpp:198] BatchNorm6 needs backward computation.
I0927 14:49:10.985426  3463 net.cpp:198] Convolution6 needs backward computation.
I0927 14:49:10.985430  3463 net.cpp:198] Eltwise2_M2PELU5_0_split needs backward computation.
I0927 14:49:10.985431  3463 net.cpp:198] M2PELU5 needs backward computation.
I0927 14:49:10.985433  3463 net.cpp:198] Eltwise2 needs backward computation.
I0927 14:49:10.985436  3463 net.cpp:198] Scale5 needs backward computation.
I0927 14:49:10.985440  3463 net.cpp:198] BatchNorm5 needs backward computation.
I0927 14:49:10.985442  3463 net.cpp:198] Convolution5 needs backward computation.
I0927 14:49:10.985445  3463 net.cpp:198] M2PELU4 needs backward computation.
I0927 14:49:10.985447  3463 net.cpp:198] Scale4 needs backward computation.
I0927 14:49:10.985450  3463 net.cpp:198] BatchNorm4 needs backward computation.
I0927 14:49:10.985451  3463 net.cpp:198] Convolution4 needs backward computation.
I0927 14:49:10.985455  3463 net.cpp:198] Eltwise1_M2PELU3_0_split needs backward computation.
I0927 14:49:10.985456  3463 net.cpp:198] M2PELU3 needs backward computation.
I0927 14:49:10.985458  3463 net.cpp:198] Eltwise1 needs backward computation.
I0927 14:49:10.985461  3463 net.cpp:198] Scale3 needs backward computation.
I0927 14:49:10.985463  3463 net.cpp:198] BatchNorm3 needs backward computation.
I0927 14:49:10.985466  3463 net.cpp:198] Convolution3 needs backward computation.
I0927 14:49:10.985468  3463 net.cpp:198] M2PELU2 needs backward computation.
I0927 14:49:10.985476  3463 net.cpp:198] Scale2 needs backward computation.
I0927 14:49:10.985478  3463 net.cpp:198] BatchNorm2 needs backward computation.
I0927 14:49:10.985481  3463 net.cpp:198] Convolution2 needs backward computation.
I0927 14:49:10.985483  3463 net.cpp:198] Convolution1_M2PELU1_0_split needs backward computation.
I0927 14:49:10.985486  3463 net.cpp:198] M2PELU1 needs backward computation.
I0927 14:49:10.985488  3463 net.cpp:198] Scale1 needs backward computation.
I0927 14:49:10.985491  3463 net.cpp:198] BatchNorm1 needs backward computation.
I0927 14:49:10.985492  3463 net.cpp:198] Convolution1 needs backward computation.
I0927 14:49:10.985496  3463 net.cpp:200] Data1 does not need backward computation.
I0927 14:49:10.985497  3463 net.cpp:242] This network produces output SoftmaxWithLoss1
I0927 14:49:10.985586  3463 net.cpp:255] Network initialization done.
I0927 14:49:10.989804  3463 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56_mpelu_train_test.prototxt
I0927 14:49:10.989816  3463 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0927 14:49:10.989820  3463 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56_mpelu_train_test.prototxt
I0927 14:49:10.990002  3463 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I0927 14:49:10.991133  3463 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU1"
  type: "M2PELU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU2"
  type: "M2PELU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU3"
  type: "M2PELU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU4"
  type: "M2PELU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU5"
  type: "M2PELU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU6"
  type: "M2PELU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU7"
  type: "M2PELU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU8"
  type: "M2PELU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU9"
  type: "M2PELU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU10"
  type: "M2PELU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU11"
  type: "M2PELU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU12"
  type: "M2PELU"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU13"
  type: "M2PELU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU14"
  type: "M2PELU"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU15"
  type: "M2PELU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU16"
  type: "M2PELU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU17"
  type: "M2PELU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU18"
  type: "M2PELU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU19"
  type: "M2PELU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU20"
  type: "M2PELU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU21"
  type: "M2PELU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU22"
  type: "M2PELU"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution24"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU23"
  type: "M2PELU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU24"
  type: "M2PELU"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
I0927 14:49:11.047057  3463 layer_factory.hpp:77] Creating layer Data1
I0927 14:49:11.047103  3463 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I0927 14:49:11.047123  3463 net.cpp:84] Creating Layer Data1
I0927 14:49:11.047128  3463 net.cpp:380] Data1 -> Data1
I0927 14:49:11.047137  3463 net.cpp:380] Data1 -> Data2
I0927 14:49:11.047142  3463 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0927 14:49:11.047314  3463 data_layer.cpp:45] output data size: 100,3,32,32
I0927 14:49:11.051307  3463 net.cpp:122] Setting up Data1
I0927 14:49:11.051329  3463 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0927 14:49:11.051333  3463 net.cpp:129] Top shape: 100 (100)
I0927 14:49:11.051336  3463 net.cpp:137] Memory required for data: 1229200
I0927 14:49:11.051340  3463 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0927 14:49:11.051348  3463 net.cpp:84] Creating Layer Data2_Data1_1_split
I0927 14:49:11.051352  3463 net.cpp:406] Data2_Data1_1_split <- Data2
I0927 14:49:11.051357  3463 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0927 14:49:11.051365  3463 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0927 14:49:11.051420  3463 net.cpp:122] Setting up Data2_Data1_1_split
I0927 14:49:11.051426  3463 net.cpp:129] Top shape: 100 (100)
I0927 14:49:11.051429  3463 net.cpp:129] Top shape: 100 (100)
I0927 14:49:11.051430  3463 net.cpp:137] Memory required for data: 1230000
I0927 14:49:11.051434  3463 layer_factory.hpp:77] Creating layer Convolution1
I0927 14:49:11.051443  3463 net.cpp:84] Creating Layer Convolution1
I0927 14:49:11.051446  3463 net.cpp:406] Convolution1 <- Data1
I0927 14:49:11.051450  3463 net.cpp:380] Convolution1 -> Convolution1
I0927 14:49:11.052736  3463 net.cpp:122] Setting up Convolution1
I0927 14:49:11.052747  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.052749  3463 net.cpp:137] Memory required for data: 7783600
I0927 14:49:11.052757  3463 layer_factory.hpp:77] Creating layer BatchNorm1
I0927 14:49:11.052767  3463 net.cpp:84] Creating Layer BatchNorm1
I0927 14:49:11.052768  3463 net.cpp:406] BatchNorm1 <- Convolution1
I0927 14:49:11.052772  3463 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0927 14:49:11.052942  3463 net.cpp:122] Setting up BatchNorm1
I0927 14:49:11.052947  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.052949  3463 net.cpp:137] Memory required for data: 14337200
I0927 14:49:11.052958  3463 layer_factory.hpp:77] Creating layer Scale1
I0927 14:49:11.052963  3463 net.cpp:84] Creating Layer Scale1
I0927 14:49:11.052966  3463 net.cpp:406] Scale1 <- Convolution1
I0927 14:49:11.052969  3463 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0927 14:49:11.053004  3463 layer_factory.hpp:77] Creating layer Scale1
I0927 14:49:11.053100  3463 net.cpp:122] Setting up Scale1
I0927 14:49:11.053105  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.053108  3463 net.cpp:137] Memory required for data: 20890800
I0927 14:49:11.053112  3463 layer_factory.hpp:77] Creating layer M2PELU1
I0927 14:49:11.053118  3463 net.cpp:84] Creating Layer M2PELU1
I0927 14:49:11.053122  3463 net.cpp:406] M2PELU1 <- Convolution1
I0927 14:49:11.053125  3463 net.cpp:367] M2PELU1 -> Convolution1 (in-place)
I0927 14:49:11.053755  3463 net.cpp:122] Setting up M2PELU1
I0927 14:49:11.053763  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.053766  3463 net.cpp:137] Memory required for data: 27444400
I0927 14:49:11.053773  3463 layer_factory.hpp:77] Creating layer Convolution1_M2PELU1_0_split
I0927 14:49:11.053779  3463 net.cpp:84] Creating Layer Convolution1_M2PELU1_0_split
I0927 14:49:11.053781  3463 net.cpp:406] Convolution1_M2PELU1_0_split <- Convolution1
I0927 14:49:11.053786  3463 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_0
I0927 14:49:11.053791  3463 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_1
I0927 14:49:11.053820  3463 net.cpp:122] Setting up Convolution1_M2PELU1_0_split
I0927 14:49:11.074580  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.074590  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.074594  3463 net.cpp:137] Memory required for data: 40551600
I0927 14:49:11.074599  3463 layer_factory.hpp:77] Creating layer Convolution2
I0927 14:49:11.074609  3463 net.cpp:84] Creating Layer Convolution2
I0927 14:49:11.074615  3463 net.cpp:406] Convolution2 <- Convolution1_M2PELU1_0_split_0
I0927 14:49:11.074625  3463 net.cpp:380] Convolution2 -> Convolution2
I0927 14:49:11.075783  3463 net.cpp:122] Setting up Convolution2
I0927 14:49:11.075793  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.075795  3463 net.cpp:137] Memory required for data: 47105200
I0927 14:49:11.075799  3463 layer_factory.hpp:77] Creating layer BatchNorm2
I0927 14:49:11.075808  3463 net.cpp:84] Creating Layer BatchNorm2
I0927 14:49:11.075809  3463 net.cpp:406] BatchNorm2 <- Convolution2
I0927 14:49:11.075814  3463 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0927 14:49:11.075991  3463 net.cpp:122] Setting up BatchNorm2
I0927 14:49:11.075995  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.075999  3463 net.cpp:137] Memory required for data: 53658800
I0927 14:49:11.076010  3463 layer_factory.hpp:77] Creating layer Scale2
I0927 14:49:11.076015  3463 net.cpp:84] Creating Layer Scale2
I0927 14:49:11.076019  3463 net.cpp:406] Scale2 <- Convolution2
I0927 14:49:11.076021  3463 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0927 14:49:11.076069  3463 layer_factory.hpp:77] Creating layer Scale2
I0927 14:49:11.076159  3463 net.cpp:122] Setting up Scale2
I0927 14:49:11.076164  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.076166  3463 net.cpp:137] Memory required for data: 60212400
I0927 14:49:11.076170  3463 layer_factory.hpp:77] Creating layer M2PELU2
I0927 14:49:11.076176  3463 net.cpp:84] Creating Layer M2PELU2
I0927 14:49:11.076179  3463 net.cpp:406] M2PELU2 <- Convolution2
I0927 14:49:11.076182  3463 net.cpp:367] M2PELU2 -> Convolution2 (in-place)
I0927 14:49:11.076304  3463 net.cpp:122] Setting up M2PELU2
I0927 14:49:11.076309  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.076311  3463 net.cpp:137] Memory required for data: 66766000
I0927 14:49:11.076318  3463 layer_factory.hpp:77] Creating layer Convolution3
I0927 14:49:11.076335  3463 net.cpp:84] Creating Layer Convolution3
I0927 14:49:11.076337  3463 net.cpp:406] Convolution3 <- Convolution2
I0927 14:49:11.076341  3463 net.cpp:380] Convolution3 -> Convolution3
I0927 14:49:11.077734  3463 net.cpp:122] Setting up Convolution3
I0927 14:49:11.077744  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.077747  3463 net.cpp:137] Memory required for data: 73319600
I0927 14:49:11.077752  3463 layer_factory.hpp:77] Creating layer BatchNorm3
I0927 14:49:11.077756  3463 net.cpp:84] Creating Layer BatchNorm3
I0927 14:49:11.077759  3463 net.cpp:406] BatchNorm3 <- Convolution3
I0927 14:49:11.077764  3463 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0927 14:49:11.077921  3463 net.cpp:122] Setting up BatchNorm3
I0927 14:49:11.077925  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.077927  3463 net.cpp:137] Memory required for data: 79873200
I0927 14:49:11.077932  3463 layer_factory.hpp:77] Creating layer Scale3
I0927 14:49:11.077936  3463 net.cpp:84] Creating Layer Scale3
I0927 14:49:11.077939  3463 net.cpp:406] Scale3 <- Convolution3
I0927 14:49:11.077941  3463 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0927 14:49:11.077972  3463 layer_factory.hpp:77] Creating layer Scale3
I0927 14:49:11.078058  3463 net.cpp:122] Setting up Scale3
I0927 14:49:11.078063  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.078064  3463 net.cpp:137] Memory required for data: 86426800
I0927 14:49:11.078068  3463 layer_factory.hpp:77] Creating layer Eltwise1
I0927 14:49:11.078073  3463 net.cpp:84] Creating Layer Eltwise1
I0927 14:49:11.078075  3463 net.cpp:406] Eltwise1 <- Convolution1_M2PELU1_0_split_1
I0927 14:49:11.078078  3463 net.cpp:406] Eltwise1 <- Convolution3
I0927 14:49:11.078083  3463 net.cpp:380] Eltwise1 -> Eltwise1
I0927 14:49:11.078100  3463 net.cpp:122] Setting up Eltwise1
I0927 14:49:11.078104  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.078106  3463 net.cpp:137] Memory required for data: 92980400
I0927 14:49:11.078109  3463 layer_factory.hpp:77] Creating layer M2PELU3
I0927 14:49:11.078115  3463 net.cpp:84] Creating Layer M2PELU3
I0927 14:49:11.078128  3463 net.cpp:406] M2PELU3 <- Eltwise1
I0927 14:49:11.078133  3463 net.cpp:367] M2PELU3 -> Eltwise1 (in-place)
I0927 14:49:11.078258  3463 net.cpp:122] Setting up M2PELU3
I0927 14:49:11.078263  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.078265  3463 net.cpp:137] Memory required for data: 99534000
I0927 14:49:11.078269  3463 layer_factory.hpp:77] Creating layer Eltwise1_M2PELU3_0_split
I0927 14:49:11.078275  3463 net.cpp:84] Creating Layer Eltwise1_M2PELU3_0_split
I0927 14:49:11.078277  3463 net.cpp:406] Eltwise1_M2PELU3_0_split <- Eltwise1
I0927 14:49:11.078280  3463 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_0
I0927 14:49:11.078284  3463 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_1
I0927 14:49:11.078320  3463 net.cpp:122] Setting up Eltwise1_M2PELU3_0_split
I0927 14:49:11.078325  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.078328  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.078330  3463 net.cpp:137] Memory required for data: 112641200
I0927 14:49:11.078332  3463 layer_factory.hpp:77] Creating layer Convolution4
I0927 14:49:11.078339  3463 net.cpp:84] Creating Layer Convolution4
I0927 14:49:11.078342  3463 net.cpp:406] Convolution4 <- Eltwise1_M2PELU3_0_split_0
I0927 14:49:11.078346  3463 net.cpp:380] Convolution4 -> Convolution4
I0927 14:49:11.079412  3463 net.cpp:122] Setting up Convolution4
I0927 14:49:11.079421  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.079423  3463 net.cpp:137] Memory required for data: 119194800
I0927 14:49:11.079427  3463 layer_factory.hpp:77] Creating layer BatchNorm4
I0927 14:49:11.079433  3463 net.cpp:84] Creating Layer BatchNorm4
I0927 14:49:11.079435  3463 net.cpp:406] BatchNorm4 <- Convolution4
I0927 14:49:11.079439  3463 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0927 14:49:11.079592  3463 net.cpp:122] Setting up BatchNorm4
I0927 14:49:11.079597  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.079599  3463 net.cpp:137] Memory required for data: 125748400
I0927 14:49:11.079604  3463 layer_factory.hpp:77] Creating layer Scale4
I0927 14:49:11.079608  3463 net.cpp:84] Creating Layer Scale4
I0927 14:49:11.079610  3463 net.cpp:406] Scale4 <- Convolution4
I0927 14:49:11.079614  3463 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0927 14:49:11.079643  3463 layer_factory.hpp:77] Creating layer Scale4
I0927 14:49:11.079727  3463 net.cpp:122] Setting up Scale4
I0927 14:49:11.079731  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.079733  3463 net.cpp:137] Memory required for data: 132302000
I0927 14:49:11.079741  3463 layer_factory.hpp:77] Creating layer M2PELU4
I0927 14:49:11.079746  3463 net.cpp:84] Creating Layer M2PELU4
I0927 14:49:11.079748  3463 net.cpp:406] M2PELU4 <- Convolution4
I0927 14:49:11.079752  3463 net.cpp:367] M2PELU4 -> Convolution4 (in-place)
I0927 14:49:11.079851  3463 net.cpp:122] Setting up M2PELU4
I0927 14:49:11.079856  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.079859  3463 net.cpp:137] Memory required for data: 138855600
I0927 14:49:11.079861  3463 layer_factory.hpp:77] Creating layer Convolution5
I0927 14:49:11.079869  3463 net.cpp:84] Creating Layer Convolution5
I0927 14:49:11.079870  3463 net.cpp:406] Convolution5 <- Convolution4
I0927 14:49:11.079874  3463 net.cpp:380] Convolution5 -> Convolution5
I0927 14:49:11.080813  3463 net.cpp:122] Setting up Convolution5
I0927 14:49:11.080821  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.080826  3463 net.cpp:137] Memory required for data: 145409200
I0927 14:49:11.080829  3463 layer_factory.hpp:77] Creating layer BatchNorm5
I0927 14:49:11.080834  3463 net.cpp:84] Creating Layer BatchNorm5
I0927 14:49:11.080837  3463 net.cpp:406] BatchNorm5 <- Convolution5
I0927 14:49:11.080842  3463 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0927 14:49:11.080994  3463 net.cpp:122] Setting up BatchNorm5
I0927 14:49:11.080999  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.081001  3463 net.cpp:137] Memory required for data: 151962800
I0927 14:49:11.081007  3463 layer_factory.hpp:77] Creating layer Scale5
I0927 14:49:11.081010  3463 net.cpp:84] Creating Layer Scale5
I0927 14:49:11.081013  3463 net.cpp:406] Scale5 <- Convolution5
I0927 14:49:11.081017  3463 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0927 14:49:11.081046  3463 layer_factory.hpp:77] Creating layer Scale5
I0927 14:49:11.081131  3463 net.cpp:122] Setting up Scale5
I0927 14:49:11.081136  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.081138  3463 net.cpp:137] Memory required for data: 158516400
I0927 14:49:11.081141  3463 layer_factory.hpp:77] Creating layer Eltwise2
I0927 14:49:11.081146  3463 net.cpp:84] Creating Layer Eltwise2
I0927 14:49:11.081148  3463 net.cpp:406] Eltwise2 <- Eltwise1_M2PELU3_0_split_1
I0927 14:49:11.081157  3463 net.cpp:406] Eltwise2 <- Convolution5
I0927 14:49:11.081161  3463 net.cpp:380] Eltwise2 -> Eltwise2
I0927 14:49:11.081181  3463 net.cpp:122] Setting up Eltwise2
I0927 14:49:11.081184  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.081187  3463 net.cpp:137] Memory required for data: 165070000
I0927 14:49:11.081188  3463 layer_factory.hpp:77] Creating layer M2PELU5
I0927 14:49:11.081193  3463 net.cpp:84] Creating Layer M2PELU5
I0927 14:49:11.081195  3463 net.cpp:406] M2PELU5 <- Eltwise2
I0927 14:49:11.081199  3463 net.cpp:367] M2PELU5 -> Eltwise2 (in-place)
I0927 14:49:11.081300  3463 net.cpp:122] Setting up M2PELU5
I0927 14:49:11.081305  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.081306  3463 net.cpp:137] Memory required for data: 171623600
I0927 14:49:11.081310  3463 layer_factory.hpp:77] Creating layer Eltwise2_M2PELU5_0_split
I0927 14:49:11.081313  3463 net.cpp:84] Creating Layer Eltwise2_M2PELU5_0_split
I0927 14:49:11.081315  3463 net.cpp:406] Eltwise2_M2PELU5_0_split <- Eltwise2
I0927 14:49:11.081320  3463 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_0
I0927 14:49:11.081323  3463 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_1
I0927 14:49:11.081351  3463 net.cpp:122] Setting up Eltwise2_M2PELU5_0_split
I0927 14:49:11.081356  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.081359  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.081362  3463 net.cpp:137] Memory required for data: 184730800
I0927 14:49:11.081363  3463 layer_factory.hpp:77] Creating layer Convolution6
I0927 14:49:11.081369  3463 net.cpp:84] Creating Layer Convolution6
I0927 14:49:11.081372  3463 net.cpp:406] Convolution6 <- Eltwise2_M2PELU5_0_split_0
I0927 14:49:11.081375  3463 net.cpp:380] Convolution6 -> Convolution6
I0927 14:49:11.082310  3463 net.cpp:122] Setting up Convolution6
I0927 14:49:11.082319  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.082321  3463 net.cpp:137] Memory required for data: 191284400
I0927 14:49:11.082325  3463 layer_factory.hpp:77] Creating layer BatchNorm6
I0927 14:49:11.082331  3463 net.cpp:84] Creating Layer BatchNorm6
I0927 14:49:11.082334  3463 net.cpp:406] BatchNorm6 <- Convolution6
I0927 14:49:11.082339  3463 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0927 14:49:11.082489  3463 net.cpp:122] Setting up BatchNorm6
I0927 14:49:11.082492  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.082495  3463 net.cpp:137] Memory required for data: 197838000
I0927 14:49:11.082499  3463 layer_factory.hpp:77] Creating layer Scale6
I0927 14:49:11.082504  3463 net.cpp:84] Creating Layer Scale6
I0927 14:49:11.082506  3463 net.cpp:406] Scale6 <- Convolution6
I0927 14:49:11.082510  3463 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0927 14:49:11.082571  3463 layer_factory.hpp:77] Creating layer Scale6
I0927 14:49:11.082656  3463 net.cpp:122] Setting up Scale6
I0927 14:49:11.082660  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.082662  3463 net.cpp:137] Memory required for data: 204391600
I0927 14:49:11.082666  3463 layer_factory.hpp:77] Creating layer M2PELU6
I0927 14:49:11.082672  3463 net.cpp:84] Creating Layer M2PELU6
I0927 14:49:11.082674  3463 net.cpp:406] M2PELU6 <- Convolution6
I0927 14:49:11.082679  3463 net.cpp:367] M2PELU6 -> Convolution6 (in-place)
I0927 14:49:11.082777  3463 net.cpp:122] Setting up M2PELU6
I0927 14:49:11.082780  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.082782  3463 net.cpp:137] Memory required for data: 210945200
I0927 14:49:11.082787  3463 layer_factory.hpp:77] Creating layer Convolution7
I0927 14:49:11.082793  3463 net.cpp:84] Creating Layer Convolution7
I0927 14:49:11.082795  3463 net.cpp:406] Convolution7 <- Convolution6
I0927 14:49:11.082799  3463 net.cpp:380] Convolution7 -> Convolution7
I0927 14:49:11.083729  3463 net.cpp:122] Setting up Convolution7
I0927 14:49:11.083737  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.083745  3463 net.cpp:137] Memory required for data: 217498800
I0927 14:49:11.083750  3463 layer_factory.hpp:77] Creating layer BatchNorm7
I0927 14:49:11.083758  3463 net.cpp:84] Creating Layer BatchNorm7
I0927 14:49:11.083761  3463 net.cpp:406] BatchNorm7 <- Convolution7
I0927 14:49:11.083765  3463 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0927 14:49:11.083915  3463 net.cpp:122] Setting up BatchNorm7
I0927 14:49:11.083920  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.083921  3463 net.cpp:137] Memory required for data: 224052400
I0927 14:49:11.083926  3463 layer_factory.hpp:77] Creating layer Scale7
I0927 14:49:11.083931  3463 net.cpp:84] Creating Layer Scale7
I0927 14:49:11.083933  3463 net.cpp:406] Scale7 <- Convolution7
I0927 14:49:11.083936  3463 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0927 14:49:11.083966  3463 layer_factory.hpp:77] Creating layer Scale7
I0927 14:49:11.084050  3463 net.cpp:122] Setting up Scale7
I0927 14:49:11.084055  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.084058  3463 net.cpp:137] Memory required for data: 230606000
I0927 14:49:11.084060  3463 layer_factory.hpp:77] Creating layer Eltwise3
I0927 14:49:11.084065  3463 net.cpp:84] Creating Layer Eltwise3
I0927 14:49:11.084067  3463 net.cpp:406] Eltwise3 <- Eltwise2_M2PELU5_0_split_1
I0927 14:49:11.084070  3463 net.cpp:406] Eltwise3 <- Convolution7
I0927 14:49:11.084074  3463 net.cpp:380] Eltwise3 -> Eltwise3
I0927 14:49:11.084091  3463 net.cpp:122] Setting up Eltwise3
I0927 14:49:11.084095  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.084097  3463 net.cpp:137] Memory required for data: 237159600
I0927 14:49:11.084100  3463 layer_factory.hpp:77] Creating layer M2PELU7
I0927 14:49:11.084105  3463 net.cpp:84] Creating Layer M2PELU7
I0927 14:49:11.084106  3463 net.cpp:406] M2PELU7 <- Eltwise3
I0927 14:49:11.084110  3463 net.cpp:367] M2PELU7 -> Eltwise3 (in-place)
I0927 14:49:11.084209  3463 net.cpp:122] Setting up M2PELU7
I0927 14:49:11.084213  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.084215  3463 net.cpp:137] Memory required for data: 243713200
I0927 14:49:11.084218  3463 layer_factory.hpp:77] Creating layer Eltwise3_M2PELU7_0_split
I0927 14:49:11.084223  3463 net.cpp:84] Creating Layer Eltwise3_M2PELU7_0_split
I0927 14:49:11.084225  3463 net.cpp:406] Eltwise3_M2PELU7_0_split <- Eltwise3
I0927 14:49:11.084228  3463 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_0
I0927 14:49:11.084233  3463 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_1
I0927 14:49:11.084259  3463 net.cpp:122] Setting up Eltwise3_M2PELU7_0_split
I0927 14:49:11.084262  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.105273  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.105280  3463 net.cpp:137] Memory required for data: 256820400
I0927 14:49:11.105285  3463 layer_factory.hpp:77] Creating layer Convolution8
I0927 14:49:11.105295  3463 net.cpp:84] Creating Layer Convolution8
I0927 14:49:11.105299  3463 net.cpp:406] Convolution8 <- Eltwise3_M2PELU7_0_split_0
I0927 14:49:11.105309  3463 net.cpp:380] Convolution8 -> Convolution8
I0927 14:49:11.106366  3463 net.cpp:122] Setting up Convolution8
I0927 14:49:11.106375  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.106379  3463 net.cpp:137] Memory required for data: 263374000
I0927 14:49:11.106389  3463 layer_factory.hpp:77] Creating layer BatchNorm8
I0927 14:49:11.106395  3463 net.cpp:84] Creating Layer BatchNorm8
I0927 14:49:11.106397  3463 net.cpp:406] BatchNorm8 <- Convolution8
I0927 14:49:11.106401  3463 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0927 14:49:11.106580  3463 net.cpp:122] Setting up BatchNorm8
I0927 14:49:11.106585  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.106587  3463 net.cpp:137] Memory required for data: 269927600
I0927 14:49:11.106592  3463 layer_factory.hpp:77] Creating layer Scale8
I0927 14:49:11.106597  3463 net.cpp:84] Creating Layer Scale8
I0927 14:49:11.106606  3463 net.cpp:406] Scale8 <- Convolution8
I0927 14:49:11.106611  3463 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0927 14:49:11.106665  3463 layer_factory.hpp:77] Creating layer Scale8
I0927 14:49:11.106757  3463 net.cpp:122] Setting up Scale8
I0927 14:49:11.106762  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.106765  3463 net.cpp:137] Memory required for data: 276481200
I0927 14:49:11.106768  3463 layer_factory.hpp:77] Creating layer M2PELU8
I0927 14:49:11.106773  3463 net.cpp:84] Creating Layer M2PELU8
I0927 14:49:11.106775  3463 net.cpp:406] M2PELU8 <- Convolution8
I0927 14:49:11.106779  3463 net.cpp:367] M2PELU8 -> Convolution8 (in-place)
I0927 14:49:11.106902  3463 net.cpp:122] Setting up M2PELU8
I0927 14:49:11.106907  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.106909  3463 net.cpp:137] Memory required for data: 283034800
I0927 14:49:11.106914  3463 layer_factory.hpp:77] Creating layer Convolution9
I0927 14:49:11.106921  3463 net.cpp:84] Creating Layer Convolution9
I0927 14:49:11.106923  3463 net.cpp:406] Convolution9 <- Convolution8
I0927 14:49:11.106927  3463 net.cpp:380] Convolution9 -> Convolution9
I0927 14:49:11.107980  3463 net.cpp:122] Setting up Convolution9
I0927 14:49:11.107988  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.107991  3463 net.cpp:137] Memory required for data: 289588400
I0927 14:49:11.107995  3463 layer_factory.hpp:77] Creating layer BatchNorm9
I0927 14:49:11.108001  3463 net.cpp:84] Creating Layer BatchNorm9
I0927 14:49:11.108003  3463 net.cpp:406] BatchNorm9 <- Convolution9
I0927 14:49:11.108008  3463 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0927 14:49:11.108162  3463 net.cpp:122] Setting up BatchNorm9
I0927 14:49:11.108166  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.108168  3463 net.cpp:137] Memory required for data: 296142000
I0927 14:49:11.108173  3463 layer_factory.hpp:77] Creating layer Scale9
I0927 14:49:11.108178  3463 net.cpp:84] Creating Layer Scale9
I0927 14:49:11.108180  3463 net.cpp:406] Scale9 <- Convolution9
I0927 14:49:11.108184  3463 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0927 14:49:11.108214  3463 layer_factory.hpp:77] Creating layer Scale9
I0927 14:49:11.108301  3463 net.cpp:122] Setting up Scale9
I0927 14:49:11.108306  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.108309  3463 net.cpp:137] Memory required for data: 302695600
I0927 14:49:11.108311  3463 layer_factory.hpp:77] Creating layer Eltwise4
I0927 14:49:11.108315  3463 net.cpp:84] Creating Layer Eltwise4
I0927 14:49:11.108319  3463 net.cpp:406] Eltwise4 <- Eltwise3_M2PELU7_0_split_1
I0927 14:49:11.108321  3463 net.cpp:406] Eltwise4 <- Convolution9
I0927 14:49:11.108325  3463 net.cpp:380] Eltwise4 -> Eltwise4
I0927 14:49:11.108343  3463 net.cpp:122] Setting up Eltwise4
I0927 14:49:11.108348  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.108350  3463 net.cpp:137] Memory required for data: 309249200
I0927 14:49:11.108352  3463 layer_factory.hpp:77] Creating layer M2PELU9
I0927 14:49:11.108356  3463 net.cpp:84] Creating Layer M2PELU9
I0927 14:49:11.108358  3463 net.cpp:406] M2PELU9 <- Eltwise4
I0927 14:49:11.108362  3463 net.cpp:367] M2PELU9 -> Eltwise4 (in-place)
I0927 14:49:11.108463  3463 net.cpp:122] Setting up M2PELU9
I0927 14:49:11.108467  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.108469  3463 net.cpp:137] Memory required for data: 315802800
I0927 14:49:11.108474  3463 layer_factory.hpp:77] Creating layer Eltwise4_M2PELU9_0_split
I0927 14:49:11.108476  3463 net.cpp:84] Creating Layer Eltwise4_M2PELU9_0_split
I0927 14:49:11.108479  3463 net.cpp:406] Eltwise4_M2PELU9_0_split <- Eltwise4
I0927 14:49:11.108482  3463 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_0
I0927 14:49:11.108486  3463 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_1
I0927 14:49:11.108513  3463 net.cpp:122] Setting up Eltwise4_M2PELU9_0_split
I0927 14:49:11.108517  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.108528  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.108530  3463 net.cpp:137] Memory required for data: 328910000
I0927 14:49:11.108532  3463 layer_factory.hpp:77] Creating layer Convolution10
I0927 14:49:11.108539  3463 net.cpp:84] Creating Layer Convolution10
I0927 14:49:11.108542  3463 net.cpp:406] Convolution10 <- Eltwise4_M2PELU9_0_split_0
I0927 14:49:11.108546  3463 net.cpp:380] Convolution10 -> Convolution10
I0927 14:49:11.109632  3463 net.cpp:122] Setting up Convolution10
I0927 14:49:11.109640  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.109643  3463 net.cpp:137] Memory required for data: 335463600
I0927 14:49:11.109647  3463 layer_factory.hpp:77] Creating layer BatchNorm10
I0927 14:49:11.109652  3463 net.cpp:84] Creating Layer BatchNorm10
I0927 14:49:11.109655  3463 net.cpp:406] BatchNorm10 <- Convolution10
I0927 14:49:11.109658  3463 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0927 14:49:11.109813  3463 net.cpp:122] Setting up BatchNorm10
I0927 14:49:11.109818  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.109820  3463 net.cpp:137] Memory required for data: 342017200
I0927 14:49:11.109825  3463 layer_factory.hpp:77] Creating layer Scale10
I0927 14:49:11.109829  3463 net.cpp:84] Creating Layer Scale10
I0927 14:49:11.109832  3463 net.cpp:406] Scale10 <- Convolution10
I0927 14:49:11.109835  3463 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0927 14:49:11.109865  3463 layer_factory.hpp:77] Creating layer Scale10
I0927 14:49:11.109952  3463 net.cpp:122] Setting up Scale10
I0927 14:49:11.109956  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.109958  3463 net.cpp:137] Memory required for data: 348570800
I0927 14:49:11.109962  3463 layer_factory.hpp:77] Creating layer M2PELU10
I0927 14:49:11.109967  3463 net.cpp:84] Creating Layer M2PELU10
I0927 14:49:11.109969  3463 net.cpp:406] M2PELU10 <- Convolution10
I0927 14:49:11.109973  3463 net.cpp:367] M2PELU10 -> Convolution10 (in-place)
I0927 14:49:11.110075  3463 net.cpp:122] Setting up M2PELU10
I0927 14:49:11.110080  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.110081  3463 net.cpp:137] Memory required for data: 355124400
I0927 14:49:11.110085  3463 layer_factory.hpp:77] Creating layer Convolution11
I0927 14:49:11.110092  3463 net.cpp:84] Creating Layer Convolution11
I0927 14:49:11.110095  3463 net.cpp:406] Convolution11 <- Convolution10
I0927 14:49:11.110100  3463 net.cpp:380] Convolution11 -> Convolution11
I0927 14:49:11.111454  3463 net.cpp:122] Setting up Convolution11
I0927 14:49:11.111462  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.111465  3463 net.cpp:137] Memory required for data: 361678000
I0927 14:49:11.111471  3463 layer_factory.hpp:77] Creating layer BatchNorm11
I0927 14:49:11.111475  3463 net.cpp:84] Creating Layer BatchNorm11
I0927 14:49:11.111479  3463 net.cpp:406] BatchNorm11 <- Convolution11
I0927 14:49:11.111481  3463 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0927 14:49:11.111641  3463 net.cpp:122] Setting up BatchNorm11
I0927 14:49:11.111645  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.111649  3463 net.cpp:137] Memory required for data: 368231600
I0927 14:49:11.111652  3463 layer_factory.hpp:77] Creating layer Scale11
I0927 14:49:11.111656  3463 net.cpp:84] Creating Layer Scale11
I0927 14:49:11.111660  3463 net.cpp:406] Scale11 <- Convolution11
I0927 14:49:11.111662  3463 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0927 14:49:11.111693  3463 layer_factory.hpp:77] Creating layer Scale11
I0927 14:49:11.111781  3463 net.cpp:122] Setting up Scale11
I0927 14:49:11.111785  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.111788  3463 net.cpp:137] Memory required for data: 374785200
I0927 14:49:11.111791  3463 layer_factory.hpp:77] Creating layer Eltwise5
I0927 14:49:11.111798  3463 net.cpp:84] Creating Layer Eltwise5
I0927 14:49:11.111800  3463 net.cpp:406] Eltwise5 <- Eltwise4_M2PELU9_0_split_1
I0927 14:49:11.111804  3463 net.cpp:406] Eltwise5 <- Convolution11
I0927 14:49:11.111814  3463 net.cpp:380] Eltwise5 -> Eltwise5
I0927 14:49:11.111834  3463 net.cpp:122] Setting up Eltwise5
I0927 14:49:11.111838  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.111840  3463 net.cpp:137] Memory required for data: 381338800
I0927 14:49:11.111842  3463 layer_factory.hpp:77] Creating layer M2PELU11
I0927 14:49:11.111847  3463 net.cpp:84] Creating Layer M2PELU11
I0927 14:49:11.111850  3463 net.cpp:406] M2PELU11 <- Eltwise5
I0927 14:49:11.111853  3463 net.cpp:367] M2PELU11 -> Eltwise5 (in-place)
I0927 14:49:11.111956  3463 net.cpp:122] Setting up M2PELU11
I0927 14:49:11.111960  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.111963  3463 net.cpp:137] Memory required for data: 387892400
I0927 14:49:11.111966  3463 layer_factory.hpp:77] Creating layer Eltwise5_M2PELU11_0_split
I0927 14:49:11.111970  3463 net.cpp:84] Creating Layer Eltwise5_M2PELU11_0_split
I0927 14:49:11.111973  3463 net.cpp:406] Eltwise5_M2PELU11_0_split <- Eltwise5
I0927 14:49:11.111976  3463 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_0
I0927 14:49:11.111980  3463 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_1
I0927 14:49:11.112007  3463 net.cpp:122] Setting up Eltwise5_M2PELU11_0_split
I0927 14:49:11.112010  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.112013  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.112015  3463 net.cpp:137] Memory required for data: 400999600
I0927 14:49:11.112017  3463 layer_factory.hpp:77] Creating layer Convolution12
I0927 14:49:11.112023  3463 net.cpp:84] Creating Layer Convolution12
I0927 14:49:11.112026  3463 net.cpp:406] Convolution12 <- Eltwise5_M2PELU11_0_split_0
I0927 14:49:11.112030  3463 net.cpp:380] Convolution12 -> Convolution12
I0927 14:49:11.112998  3463 net.cpp:122] Setting up Convolution12
I0927 14:49:11.113008  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.113009  3463 net.cpp:137] Memory required for data: 407553200
I0927 14:49:11.113014  3463 layer_factory.hpp:77] Creating layer BatchNorm12
I0927 14:49:11.113018  3463 net.cpp:84] Creating Layer BatchNorm12
I0927 14:49:11.113021  3463 net.cpp:406] BatchNorm12 <- Convolution12
I0927 14:49:11.113025  3463 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0927 14:49:11.113181  3463 net.cpp:122] Setting up BatchNorm12
I0927 14:49:11.113186  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.113188  3463 net.cpp:137] Memory required for data: 414106800
I0927 14:49:11.113193  3463 layer_factory.hpp:77] Creating layer Scale12
I0927 14:49:11.113198  3463 net.cpp:84] Creating Layer Scale12
I0927 14:49:11.113199  3463 net.cpp:406] Scale12 <- Convolution12
I0927 14:49:11.113204  3463 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0927 14:49:11.113234  3463 layer_factory.hpp:77] Creating layer Scale12
I0927 14:49:11.113320  3463 net.cpp:122] Setting up Scale12
I0927 14:49:11.113324  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.113327  3463 net.cpp:137] Memory required for data: 420660400
I0927 14:49:11.113330  3463 layer_factory.hpp:77] Creating layer M2PELU12
I0927 14:49:11.113335  3463 net.cpp:84] Creating Layer M2PELU12
I0927 14:49:11.113337  3463 net.cpp:406] M2PELU12 <- Convolution12
I0927 14:49:11.113342  3463 net.cpp:367] M2PELU12 -> Convolution12 (in-place)
I0927 14:49:11.113443  3463 net.cpp:122] Setting up M2PELU12
I0927 14:49:11.113447  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.113450  3463 net.cpp:137] Memory required for data: 427214000
I0927 14:49:11.113453  3463 layer_factory.hpp:77] Creating layer Convolution13
I0927 14:49:11.113461  3463 net.cpp:84] Creating Layer Convolution13
I0927 14:49:11.113462  3463 net.cpp:406] Convolution13 <- Convolution12
I0927 14:49:11.113466  3463 net.cpp:380] Convolution13 -> Convolution13
I0927 14:49:11.114430  3463 net.cpp:122] Setting up Convolution13
I0927 14:49:11.114439  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.114442  3463 net.cpp:137] Memory required for data: 433767600
I0927 14:49:11.114452  3463 layer_factory.hpp:77] Creating layer BatchNorm13
I0927 14:49:11.114457  3463 net.cpp:84] Creating Layer BatchNorm13
I0927 14:49:11.114460  3463 net.cpp:406] BatchNorm13 <- Convolution13
I0927 14:49:11.114465  3463 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0927 14:49:11.114629  3463 net.cpp:122] Setting up BatchNorm13
I0927 14:49:11.114635  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.114637  3463 net.cpp:137] Memory required for data: 440321200
I0927 14:49:11.114642  3463 layer_factory.hpp:77] Creating layer Scale13
I0927 14:49:11.114646  3463 net.cpp:84] Creating Layer Scale13
I0927 14:49:11.114648  3463 net.cpp:406] Scale13 <- Convolution13
I0927 14:49:11.114652  3463 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0927 14:49:11.114684  3463 layer_factory.hpp:77] Creating layer Scale13
I0927 14:49:11.114773  3463 net.cpp:122] Setting up Scale13
I0927 14:49:11.114776  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.114778  3463 net.cpp:137] Memory required for data: 446874800
I0927 14:49:11.114783  3463 layer_factory.hpp:77] Creating layer Eltwise6
I0927 14:49:11.114791  3463 net.cpp:84] Creating Layer Eltwise6
I0927 14:49:11.114794  3463 net.cpp:406] Eltwise6 <- Eltwise5_M2PELU11_0_split_1
I0927 14:49:11.114797  3463 net.cpp:406] Eltwise6 <- Convolution13
I0927 14:49:11.114800  3463 net.cpp:380] Eltwise6 -> Eltwise6
I0927 14:49:11.114820  3463 net.cpp:122] Setting up Eltwise6
I0927 14:49:11.114823  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.114825  3463 net.cpp:137] Memory required for data: 453428400
I0927 14:49:11.114828  3463 layer_factory.hpp:77] Creating layer M2PELU13
I0927 14:49:11.114833  3463 net.cpp:84] Creating Layer M2PELU13
I0927 14:49:11.114835  3463 net.cpp:406] M2PELU13 <- Eltwise6
I0927 14:49:11.114838  3463 net.cpp:367] M2PELU13 -> Eltwise6 (in-place)
I0927 14:49:11.114941  3463 net.cpp:122] Setting up M2PELU13
I0927 14:49:11.114945  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.114948  3463 net.cpp:137] Memory required for data: 459982000
I0927 14:49:11.114951  3463 layer_factory.hpp:77] Creating layer Eltwise6_M2PELU13_0_split
I0927 14:49:11.114955  3463 net.cpp:84] Creating Layer Eltwise6_M2PELU13_0_split
I0927 14:49:11.114958  3463 net.cpp:406] Eltwise6_M2PELU13_0_split <- Eltwise6
I0927 14:49:11.114960  3463 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_0
I0927 14:49:11.114965  3463 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_1
I0927 14:49:11.114991  3463 net.cpp:122] Setting up Eltwise6_M2PELU13_0_split
I0927 14:49:11.135779  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.135789  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.135793  3463 net.cpp:137] Memory required for data: 473089200
I0927 14:49:11.135797  3463 layer_factory.hpp:77] Creating layer Convolution14
I0927 14:49:11.135809  3463 net.cpp:84] Creating Layer Convolution14
I0927 14:49:11.135814  3463 net.cpp:406] Convolution14 <- Eltwise6_M2PELU13_0_split_0
I0927 14:49:11.135821  3463 net.cpp:380] Convolution14 -> Convolution14
I0927 14:49:11.136929  3463 net.cpp:122] Setting up Convolution14
I0927 14:49:11.136939  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.136941  3463 net.cpp:137] Memory required for data: 479642800
I0927 14:49:11.136945  3463 layer_factory.hpp:77] Creating layer BatchNorm14
I0927 14:49:11.136950  3463 net.cpp:84] Creating Layer BatchNorm14
I0927 14:49:11.136953  3463 net.cpp:406] BatchNorm14 <- Convolution14
I0927 14:49:11.136958  3463 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0927 14:49:11.137135  3463 net.cpp:122] Setting up BatchNorm14
I0927 14:49:11.137140  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.137142  3463 net.cpp:137] Memory required for data: 486196400
I0927 14:49:11.137147  3463 layer_factory.hpp:77] Creating layer Scale14
I0927 14:49:11.137152  3463 net.cpp:84] Creating Layer Scale14
I0927 14:49:11.137161  3463 net.cpp:406] Scale14 <- Convolution14
I0927 14:49:11.137164  3463 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0927 14:49:11.137208  3463 layer_factory.hpp:77] Creating layer Scale14
I0927 14:49:11.137300  3463 net.cpp:122] Setting up Scale14
I0927 14:49:11.137305  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.137307  3463 net.cpp:137] Memory required for data: 492750000
I0927 14:49:11.137311  3463 layer_factory.hpp:77] Creating layer M2PELU14
I0927 14:49:11.137316  3463 net.cpp:84] Creating Layer M2PELU14
I0927 14:49:11.137318  3463 net.cpp:406] M2PELU14 <- Convolution14
I0927 14:49:11.137322  3463 net.cpp:367] M2PELU14 -> Convolution14 (in-place)
I0927 14:49:11.137428  3463 net.cpp:122] Setting up M2PELU14
I0927 14:49:11.137434  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.137435  3463 net.cpp:137] Memory required for data: 499303600
I0927 14:49:11.137439  3463 layer_factory.hpp:77] Creating layer Convolution15
I0927 14:49:11.137446  3463 net.cpp:84] Creating Layer Convolution15
I0927 14:49:11.137449  3463 net.cpp:406] Convolution15 <- Convolution14
I0927 14:49:11.137454  3463 net.cpp:380] Convolution15 -> Convolution15
I0927 14:49:11.138938  3463 net.cpp:122] Setting up Convolution15
I0927 14:49:11.138947  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.138949  3463 net.cpp:137] Memory required for data: 505857200
I0927 14:49:11.138954  3463 layer_factory.hpp:77] Creating layer BatchNorm15
I0927 14:49:11.138959  3463 net.cpp:84] Creating Layer BatchNorm15
I0927 14:49:11.138962  3463 net.cpp:406] BatchNorm15 <- Convolution15
I0927 14:49:11.138967  3463 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0927 14:49:11.139122  3463 net.cpp:122] Setting up BatchNorm15
I0927 14:49:11.139127  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.139129  3463 net.cpp:137] Memory required for data: 512410800
I0927 14:49:11.139145  3463 layer_factory.hpp:77] Creating layer Scale15
I0927 14:49:11.139150  3463 net.cpp:84] Creating Layer Scale15
I0927 14:49:11.139153  3463 net.cpp:406] Scale15 <- Convolution15
I0927 14:49:11.139156  3463 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0927 14:49:11.139189  3463 layer_factory.hpp:77] Creating layer Scale15
I0927 14:49:11.139288  3463 net.cpp:122] Setting up Scale15
I0927 14:49:11.139293  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.139295  3463 net.cpp:137] Memory required for data: 518964400
I0927 14:49:11.139299  3463 layer_factory.hpp:77] Creating layer Eltwise7
I0927 14:49:11.139303  3463 net.cpp:84] Creating Layer Eltwise7
I0927 14:49:11.139307  3463 net.cpp:406] Eltwise7 <- Eltwise6_M2PELU13_0_split_1
I0927 14:49:11.139309  3463 net.cpp:406] Eltwise7 <- Convolution15
I0927 14:49:11.139322  3463 net.cpp:380] Eltwise7 -> Eltwise7
I0927 14:49:11.139351  3463 net.cpp:122] Setting up Eltwise7
I0927 14:49:11.139355  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.139358  3463 net.cpp:137] Memory required for data: 525518000
I0927 14:49:11.139359  3463 layer_factory.hpp:77] Creating layer M2PELU15
I0927 14:49:11.139364  3463 net.cpp:84] Creating Layer M2PELU15
I0927 14:49:11.139366  3463 net.cpp:406] M2PELU15 <- Eltwise7
I0927 14:49:11.139370  3463 net.cpp:367] M2PELU15 -> Eltwise7 (in-place)
I0927 14:49:11.139475  3463 net.cpp:122] Setting up M2PELU15
I0927 14:49:11.139482  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.139483  3463 net.cpp:137] Memory required for data: 532071600
I0927 14:49:11.139487  3463 layer_factory.hpp:77] Creating layer Eltwise7_M2PELU15_0_split
I0927 14:49:11.139492  3463 net.cpp:84] Creating Layer Eltwise7_M2PELU15_0_split
I0927 14:49:11.139493  3463 net.cpp:406] Eltwise7_M2PELU15_0_split <- Eltwise7
I0927 14:49:11.139497  3463 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_0
I0927 14:49:11.139502  3463 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_1
I0927 14:49:11.139549  3463 net.cpp:122] Setting up Eltwise7_M2PELU15_0_split
I0927 14:49:11.139552  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.139562  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.139565  3463 net.cpp:137] Memory required for data: 545178800
I0927 14:49:11.139567  3463 layer_factory.hpp:77] Creating layer Convolution16
I0927 14:49:11.139575  3463 net.cpp:84] Creating Layer Convolution16
I0927 14:49:11.139577  3463 net.cpp:406] Convolution16 <- Eltwise7_M2PELU15_0_split_0
I0927 14:49:11.139581  3463 net.cpp:380] Convolution16 -> Convolution16
I0927 14:49:11.140230  3463 net.cpp:122] Setting up Convolution16
I0927 14:49:11.140239  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.140240  3463 net.cpp:137] Memory required for data: 551732400
I0927 14:49:11.140244  3463 layer_factory.hpp:77] Creating layer BatchNorm16
I0927 14:49:11.140250  3463 net.cpp:84] Creating Layer BatchNorm16
I0927 14:49:11.140252  3463 net.cpp:406] BatchNorm16 <- Convolution16
I0927 14:49:11.140257  3463 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0927 14:49:11.140413  3463 net.cpp:122] Setting up BatchNorm16
I0927 14:49:11.140417  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.140419  3463 net.cpp:137] Memory required for data: 558286000
I0927 14:49:11.140424  3463 layer_factory.hpp:77] Creating layer Scale16
I0927 14:49:11.140429  3463 net.cpp:84] Creating Layer Scale16
I0927 14:49:11.140431  3463 net.cpp:406] Scale16 <- Convolution16
I0927 14:49:11.140434  3463 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0927 14:49:11.140466  3463 layer_factory.hpp:77] Creating layer Scale16
I0927 14:49:11.140555  3463 net.cpp:122] Setting up Scale16
I0927 14:49:11.140559  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.140563  3463 net.cpp:137] Memory required for data: 564839600
I0927 14:49:11.140565  3463 layer_factory.hpp:77] Creating layer M2PELU16
I0927 14:49:11.140570  3463 net.cpp:84] Creating Layer M2PELU16
I0927 14:49:11.140573  3463 net.cpp:406] M2PELU16 <- Convolution16
I0927 14:49:11.140576  3463 net.cpp:367] M2PELU16 -> Convolution16 (in-place)
I0927 14:49:11.140678  3463 net.cpp:122] Setting up M2PELU16
I0927 14:49:11.140683  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.140686  3463 net.cpp:137] Memory required for data: 571393200
I0927 14:49:11.140688  3463 layer_factory.hpp:77] Creating layer Convolution17
I0927 14:49:11.140697  3463 net.cpp:84] Creating Layer Convolution17
I0927 14:49:11.140698  3463 net.cpp:406] Convolution17 <- Convolution16
I0927 14:49:11.140702  3463 net.cpp:380] Convolution17 -> Convolution17
I0927 14:49:11.141670  3463 net.cpp:122] Setting up Convolution17
I0927 14:49:11.141679  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.141681  3463 net.cpp:137] Memory required for data: 577946800
I0927 14:49:11.141685  3463 layer_factory.hpp:77] Creating layer BatchNorm17
I0927 14:49:11.141691  3463 net.cpp:84] Creating Layer BatchNorm17
I0927 14:49:11.141695  3463 net.cpp:406] BatchNorm17 <- Convolution17
I0927 14:49:11.141698  3463 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0927 14:49:11.141855  3463 net.cpp:122] Setting up BatchNorm17
I0927 14:49:11.141860  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.141862  3463 net.cpp:137] Memory required for data: 584500400
I0927 14:49:11.141866  3463 layer_factory.hpp:77] Creating layer Scale17
I0927 14:49:11.141871  3463 net.cpp:84] Creating Layer Scale17
I0927 14:49:11.141875  3463 net.cpp:406] Scale17 <- Convolution17
I0927 14:49:11.141877  3463 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0927 14:49:11.141908  3463 layer_factory.hpp:77] Creating layer Scale17
I0927 14:49:11.141997  3463 net.cpp:122] Setting up Scale17
I0927 14:49:11.142002  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.142004  3463 net.cpp:137] Memory required for data: 591054000
I0927 14:49:11.142007  3463 layer_factory.hpp:77] Creating layer Eltwise8
I0927 14:49:11.142011  3463 net.cpp:84] Creating Layer Eltwise8
I0927 14:49:11.142014  3463 net.cpp:406] Eltwise8 <- Eltwise7_M2PELU15_0_split_1
I0927 14:49:11.142024  3463 net.cpp:406] Eltwise8 <- Convolution17
I0927 14:49:11.142027  3463 net.cpp:380] Eltwise8 -> Eltwise8
I0927 14:49:11.142047  3463 net.cpp:122] Setting up Eltwise8
I0927 14:49:11.142052  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.142055  3463 net.cpp:137] Memory required for data: 597607600
I0927 14:49:11.142056  3463 layer_factory.hpp:77] Creating layer M2PELU17
I0927 14:49:11.142060  3463 net.cpp:84] Creating Layer M2PELU17
I0927 14:49:11.142063  3463 net.cpp:406] M2PELU17 <- Eltwise8
I0927 14:49:11.142066  3463 net.cpp:367] M2PELU17 -> Eltwise8 (in-place)
I0927 14:49:11.142170  3463 net.cpp:122] Setting up M2PELU17
I0927 14:49:11.142175  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.142177  3463 net.cpp:137] Memory required for data: 604161200
I0927 14:49:11.142180  3463 layer_factory.hpp:77] Creating layer Eltwise8_M2PELU17_0_split
I0927 14:49:11.142184  3463 net.cpp:84] Creating Layer Eltwise8_M2PELU17_0_split
I0927 14:49:11.142186  3463 net.cpp:406] Eltwise8_M2PELU17_0_split <- Eltwise8
I0927 14:49:11.142190  3463 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_0
I0927 14:49:11.142194  3463 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_1
I0927 14:49:11.142222  3463 net.cpp:122] Setting up Eltwise8_M2PELU17_0_split
I0927 14:49:11.142226  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.142228  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.142230  3463 net.cpp:137] Memory required for data: 617268400
I0927 14:49:11.142232  3463 layer_factory.hpp:77] Creating layer Convolution18
I0927 14:49:11.142240  3463 net.cpp:84] Creating Layer Convolution18
I0927 14:49:11.142241  3463 net.cpp:406] Convolution18 <- Eltwise8_M2PELU17_0_split_0
I0927 14:49:11.142246  3463 net.cpp:380] Convolution18 -> Convolution18
I0927 14:49:11.143252  3463 net.cpp:122] Setting up Convolution18
I0927 14:49:11.143261  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.143265  3463 net.cpp:137] Memory required for data: 623822000
I0927 14:49:11.143270  3463 layer_factory.hpp:77] Creating layer BatchNorm18
I0927 14:49:11.143273  3463 net.cpp:84] Creating Layer BatchNorm18
I0927 14:49:11.143276  3463 net.cpp:406] BatchNorm18 <- Convolution18
I0927 14:49:11.143280  3463 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0927 14:49:11.143432  3463 net.cpp:122] Setting up BatchNorm18
I0927 14:49:11.143437  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.143440  3463 net.cpp:137] Memory required for data: 630375600
I0927 14:49:11.143445  3463 layer_factory.hpp:77] Creating layer Scale18
I0927 14:49:11.143450  3463 net.cpp:84] Creating Layer Scale18
I0927 14:49:11.143451  3463 net.cpp:406] Scale18 <- Convolution18
I0927 14:49:11.143455  3463 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0927 14:49:11.143494  3463 layer_factory.hpp:77] Creating layer Scale18
I0927 14:49:11.143584  3463 net.cpp:122] Setting up Scale18
I0927 14:49:11.143589  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.143591  3463 net.cpp:137] Memory required for data: 636929200
I0927 14:49:11.143595  3463 layer_factory.hpp:77] Creating layer M2PELU18
I0927 14:49:11.143600  3463 net.cpp:84] Creating Layer M2PELU18
I0927 14:49:11.143602  3463 net.cpp:406] M2PELU18 <- Convolution18
I0927 14:49:11.143606  3463 net.cpp:367] M2PELU18 -> Convolution18 (in-place)
I0927 14:49:11.143715  3463 net.cpp:122] Setting up M2PELU18
I0927 14:49:11.143720  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.143723  3463 net.cpp:137] Memory required for data: 643482800
I0927 14:49:11.143726  3463 layer_factory.hpp:77] Creating layer Convolution19
I0927 14:49:11.143733  3463 net.cpp:84] Creating Layer Convolution19
I0927 14:49:11.143735  3463 net.cpp:406] Convolution19 <- Convolution18
I0927 14:49:11.143739  3463 net.cpp:380] Convolution19 -> Convolution19
I0927 14:49:11.144729  3463 net.cpp:122] Setting up Convolution19
I0927 14:49:11.144737  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.144747  3463 net.cpp:137] Memory required for data: 650036400
I0927 14:49:11.144752  3463 layer_factory.hpp:77] Creating layer BatchNorm19
I0927 14:49:11.144757  3463 net.cpp:84] Creating Layer BatchNorm19
I0927 14:49:11.144759  3463 net.cpp:406] BatchNorm19 <- Convolution19
I0927 14:49:11.144763  3463 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0927 14:49:11.144922  3463 net.cpp:122] Setting up BatchNorm19
I0927 14:49:11.144927  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.144929  3463 net.cpp:137] Memory required for data: 656590000
I0927 14:49:11.144934  3463 layer_factory.hpp:77] Creating layer Scale19
I0927 14:49:11.144938  3463 net.cpp:84] Creating Layer Scale19
I0927 14:49:11.144940  3463 net.cpp:406] Scale19 <- Convolution19
I0927 14:49:11.144944  3463 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0927 14:49:11.144974  3463 layer_factory.hpp:77] Creating layer Scale19
I0927 14:49:11.145063  3463 net.cpp:122] Setting up Scale19
I0927 14:49:11.145068  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.145071  3463 net.cpp:137] Memory required for data: 663143600
I0927 14:49:11.145074  3463 layer_factory.hpp:77] Creating layer Eltwise9
I0927 14:49:11.145078  3463 net.cpp:84] Creating Layer Eltwise9
I0927 14:49:11.145081  3463 net.cpp:406] Eltwise9 <- Eltwise8_M2PELU17_0_split_1
I0927 14:49:11.145083  3463 net.cpp:406] Eltwise9 <- Convolution19
I0927 14:49:11.145087  3463 net.cpp:380] Eltwise9 -> Eltwise9
I0927 14:49:11.145105  3463 net.cpp:122] Setting up Eltwise9
I0927 14:49:11.145109  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.145112  3463 net.cpp:137] Memory required for data: 669697200
I0927 14:49:11.145113  3463 layer_factory.hpp:77] Creating layer M2PELU19
I0927 14:49:11.145118  3463 net.cpp:84] Creating Layer M2PELU19
I0927 14:49:11.145121  3463 net.cpp:406] M2PELU19 <- Eltwise9
I0927 14:49:11.145124  3463 net.cpp:367] M2PELU19 -> Eltwise9 (in-place)
I0927 14:49:11.145231  3463 net.cpp:122] Setting up M2PELU19
I0927 14:49:11.145236  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.145237  3463 net.cpp:137] Memory required for data: 676250800
I0927 14:49:11.145241  3463 layer_factory.hpp:77] Creating layer Eltwise9_M2PELU19_0_split
I0927 14:49:11.145246  3463 net.cpp:84] Creating Layer Eltwise9_M2PELU19_0_split
I0927 14:49:11.145247  3463 net.cpp:406] Eltwise9_M2PELU19_0_split <- Eltwise9
I0927 14:49:11.145251  3463 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_0
I0927 14:49:11.166460  3463 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_1
I0927 14:49:11.166518  3463 net.cpp:122] Setting up Eltwise9_M2PELU19_0_split
I0927 14:49:11.166537  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.166541  3463 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 14:49:11.166545  3463 net.cpp:137] Memory required for data: 689358000
I0927 14:49:11.166549  3463 layer_factory.hpp:77] Creating layer Convolution20
I0927 14:49:11.166560  3463 net.cpp:84] Creating Layer Convolution20
I0927 14:49:11.166565  3463 net.cpp:406] Convolution20 <- Eltwise9_M2PELU19_0_split_0
I0927 14:49:11.166573  3463 net.cpp:380] Convolution20 -> Convolution20
I0927 14:49:11.167611  3463 net.cpp:122] Setting up Convolution20
I0927 14:49:11.167620  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.167623  3463 net.cpp:137] Memory required for data: 692634800
I0927 14:49:11.167629  3463 layer_factory.hpp:77] Creating layer BatchNorm20
I0927 14:49:11.167634  3463 net.cpp:84] Creating Layer BatchNorm20
I0927 14:49:11.167636  3463 net.cpp:406] BatchNorm20 <- Convolution20
I0927 14:49:11.167640  3463 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0927 14:49:11.167809  3463 net.cpp:122] Setting up BatchNorm20
I0927 14:49:11.167814  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.167815  3463 net.cpp:137] Memory required for data: 695911600
I0927 14:49:11.167820  3463 layer_factory.hpp:77] Creating layer Scale20
I0927 14:49:11.167825  3463 net.cpp:84] Creating Layer Scale20
I0927 14:49:11.167834  3463 net.cpp:406] Scale20 <- Convolution20
I0927 14:49:11.167839  3463 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0927 14:49:11.167872  3463 layer_factory.hpp:77] Creating layer Scale20
I0927 14:49:11.167964  3463 net.cpp:122] Setting up Scale20
I0927 14:49:11.167969  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.167971  3463 net.cpp:137] Memory required for data: 699188400
I0927 14:49:11.167975  3463 layer_factory.hpp:77] Creating layer Convolution21
I0927 14:49:11.167982  3463 net.cpp:84] Creating Layer Convolution21
I0927 14:49:11.167985  3463 net.cpp:406] Convolution21 <- Eltwise9_M2PELU19_0_split_1
I0927 14:49:11.167990  3463 net.cpp:380] Convolution21 -> Convolution21
I0927 14:49:11.169123  3463 net.cpp:122] Setting up Convolution21
I0927 14:49:11.169132  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.169134  3463 net.cpp:137] Memory required for data: 702465200
I0927 14:49:11.169139  3463 layer_factory.hpp:77] Creating layer BatchNorm21
I0927 14:49:11.169144  3463 net.cpp:84] Creating Layer BatchNorm21
I0927 14:49:11.169147  3463 net.cpp:406] BatchNorm21 <- Convolution21
I0927 14:49:11.169152  3463 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0927 14:49:11.169311  3463 net.cpp:122] Setting up BatchNorm21
I0927 14:49:11.169315  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.169317  3463 net.cpp:137] Memory required for data: 705742000
I0927 14:49:11.169322  3463 layer_factory.hpp:77] Creating layer Scale21
I0927 14:49:11.169327  3463 net.cpp:84] Creating Layer Scale21
I0927 14:49:11.169329  3463 net.cpp:406] Scale21 <- Convolution21
I0927 14:49:11.169332  3463 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0927 14:49:11.169364  3463 layer_factory.hpp:77] Creating layer Scale21
I0927 14:49:11.169453  3463 net.cpp:122] Setting up Scale21
I0927 14:49:11.169458  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.169461  3463 net.cpp:137] Memory required for data: 709018800
I0927 14:49:11.169464  3463 layer_factory.hpp:77] Creating layer M2PELU20
I0927 14:49:11.169469  3463 net.cpp:84] Creating Layer M2PELU20
I0927 14:49:11.169472  3463 net.cpp:406] M2PELU20 <- Convolution21
I0927 14:49:11.169476  3463 net.cpp:367] M2PELU20 -> Convolution21 (in-place)
I0927 14:49:11.169576  3463 net.cpp:122] Setting up M2PELU20
I0927 14:49:11.169581  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.169584  3463 net.cpp:137] Memory required for data: 712295600
I0927 14:49:11.169587  3463 layer_factory.hpp:77] Creating layer Convolution22
I0927 14:49:11.169595  3463 net.cpp:84] Creating Layer Convolution22
I0927 14:49:11.169597  3463 net.cpp:406] Convolution22 <- Convolution21
I0927 14:49:11.169601  3463 net.cpp:380] Convolution22 -> Convolution22
I0927 14:49:11.170765  3463 net.cpp:122] Setting up Convolution22
I0927 14:49:11.170774  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.170776  3463 net.cpp:137] Memory required for data: 715572400
I0927 14:49:11.170781  3463 layer_factory.hpp:77] Creating layer BatchNorm22
I0927 14:49:11.170786  3463 net.cpp:84] Creating Layer BatchNorm22
I0927 14:49:11.170789  3463 net.cpp:406] BatchNorm22 <- Convolution22
I0927 14:49:11.170792  3463 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0927 14:49:11.170948  3463 net.cpp:122] Setting up BatchNorm22
I0927 14:49:11.170953  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.170955  3463 net.cpp:137] Memory required for data: 718849200
I0927 14:49:11.170960  3463 layer_factory.hpp:77] Creating layer Scale22
I0927 14:49:11.170964  3463 net.cpp:84] Creating Layer Scale22
I0927 14:49:11.170966  3463 net.cpp:406] Scale22 <- Convolution22
I0927 14:49:11.170969  3463 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0927 14:49:11.171001  3463 layer_factory.hpp:77] Creating layer Scale22
I0927 14:49:11.171094  3463 net.cpp:122] Setting up Scale22
I0927 14:49:11.171098  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.171100  3463 net.cpp:137] Memory required for data: 722126000
I0927 14:49:11.171110  3463 layer_factory.hpp:77] Creating layer Eltwise10
I0927 14:49:11.171116  3463 net.cpp:84] Creating Layer Eltwise10
I0927 14:49:11.171119  3463 net.cpp:406] Eltwise10 <- Convolution20
I0927 14:49:11.171123  3463 net.cpp:406] Eltwise10 <- Convolution22
I0927 14:49:11.171125  3463 net.cpp:380] Eltwise10 -> Eltwise10
I0927 14:49:11.171142  3463 net.cpp:122] Setting up Eltwise10
I0927 14:49:11.171145  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.171147  3463 net.cpp:137] Memory required for data: 725402800
I0927 14:49:11.171149  3463 layer_factory.hpp:77] Creating layer M2PELU21
I0927 14:49:11.171155  3463 net.cpp:84] Creating Layer M2PELU21
I0927 14:49:11.171157  3463 net.cpp:406] M2PELU21 <- Eltwise10
I0927 14:49:11.171161  3463 net.cpp:367] M2PELU21 -> Eltwise10 (in-place)
I0927 14:49:11.171263  3463 net.cpp:122] Setting up M2PELU21
I0927 14:49:11.171267  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.171269  3463 net.cpp:137] Memory required for data: 728679600
I0927 14:49:11.171273  3463 layer_factory.hpp:77] Creating layer Eltwise10_M2PELU21_0_split
I0927 14:49:11.171277  3463 net.cpp:84] Creating Layer Eltwise10_M2PELU21_0_split
I0927 14:49:11.171280  3463 net.cpp:406] Eltwise10_M2PELU21_0_split <- Eltwise10
I0927 14:49:11.171283  3463 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_0
I0927 14:49:11.171288  3463 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_1
I0927 14:49:11.171315  3463 net.cpp:122] Setting up Eltwise10_M2PELU21_0_split
I0927 14:49:11.171319  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.171322  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.171324  3463 net.cpp:137] Memory required for data: 735233200
I0927 14:49:11.171326  3463 layer_factory.hpp:77] Creating layer Convolution23
I0927 14:49:11.171334  3463 net.cpp:84] Creating Layer Convolution23
I0927 14:49:11.171335  3463 net.cpp:406] Convolution23 <- Eltwise10_M2PELU21_0_split_0
I0927 14:49:11.171339  3463 net.cpp:380] Convolution23 -> Convolution23
I0927 14:49:11.172458  3463 net.cpp:122] Setting up Convolution23
I0927 14:49:11.172467  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.172469  3463 net.cpp:137] Memory required for data: 738510000
I0927 14:49:11.172473  3463 layer_factory.hpp:77] Creating layer BatchNorm23
I0927 14:49:11.172479  3463 net.cpp:84] Creating Layer BatchNorm23
I0927 14:49:11.172482  3463 net.cpp:406] BatchNorm23 <- Convolution23
I0927 14:49:11.172485  3463 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0927 14:49:11.172644  3463 net.cpp:122] Setting up BatchNorm23
I0927 14:49:11.172649  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.172652  3463 net.cpp:137] Memory required for data: 741786800
I0927 14:49:11.172657  3463 layer_factory.hpp:77] Creating layer Scale23
I0927 14:49:11.172660  3463 net.cpp:84] Creating Layer Scale23
I0927 14:49:11.172662  3463 net.cpp:406] Scale23 <- Convolution23
I0927 14:49:11.172665  3463 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0927 14:49:11.172698  3463 layer_factory.hpp:77] Creating layer Scale23
I0927 14:49:11.172790  3463 net.cpp:122] Setting up Scale23
I0927 14:49:11.172794  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.172796  3463 net.cpp:137] Memory required for data: 745063600
I0927 14:49:11.172801  3463 layer_factory.hpp:77] Creating layer M2PELU22
I0927 14:49:11.172806  3463 net.cpp:84] Creating Layer M2PELU22
I0927 14:49:11.172807  3463 net.cpp:406] M2PELU22 <- Convolution23
I0927 14:49:11.172811  3463 net.cpp:367] M2PELU22 -> Convolution23 (in-place)
I0927 14:49:11.172911  3463 net.cpp:122] Setting up M2PELU22
I0927 14:49:11.172915  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.172917  3463 net.cpp:137] Memory required for data: 748340400
I0927 14:49:11.172921  3463 layer_factory.hpp:77] Creating layer Convolution24
I0927 14:49:11.172930  3463 net.cpp:84] Creating Layer Convolution24
I0927 14:49:11.172937  3463 net.cpp:406] Convolution24 <- Convolution23
I0927 14:49:11.172943  3463 net.cpp:380] Convolution24 -> Convolution24
I0927 14:49:11.174077  3463 net.cpp:122] Setting up Convolution24
I0927 14:49:11.174085  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.174088  3463 net.cpp:137] Memory required for data: 751617200
I0927 14:49:11.174093  3463 layer_factory.hpp:77] Creating layer BatchNorm24
I0927 14:49:11.174096  3463 net.cpp:84] Creating Layer BatchNorm24
I0927 14:49:11.174099  3463 net.cpp:406] BatchNorm24 <- Convolution24
I0927 14:49:11.174103  3463 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0927 14:49:11.174773  3463 net.cpp:122] Setting up BatchNorm24
I0927 14:49:11.174782  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.174784  3463 net.cpp:137] Memory required for data: 754894000
I0927 14:49:11.174789  3463 layer_factory.hpp:77] Creating layer Scale24
I0927 14:49:11.174794  3463 net.cpp:84] Creating Layer Scale24
I0927 14:49:11.174796  3463 net.cpp:406] Scale24 <- Convolution24
I0927 14:49:11.174801  3463 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0927 14:49:11.174829  3463 layer_factory.hpp:77] Creating layer Scale24
I0927 14:49:11.174901  3463 net.cpp:122] Setting up Scale24
I0927 14:49:11.174906  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.174907  3463 net.cpp:137] Memory required for data: 758170800
I0927 14:49:11.174911  3463 layer_factory.hpp:77] Creating layer Eltwise11
I0927 14:49:11.174916  3463 net.cpp:84] Creating Layer Eltwise11
I0927 14:49:11.174918  3463 net.cpp:406] Eltwise11 <- Eltwise10_M2PELU21_0_split_1
I0927 14:49:11.174921  3463 net.cpp:406] Eltwise11 <- Convolution24
I0927 14:49:11.174924  3463 net.cpp:380] Eltwise11 -> Eltwise11
I0927 14:49:11.174937  3463 net.cpp:122] Setting up Eltwise11
I0927 14:49:11.174939  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.174942  3463 net.cpp:137] Memory required for data: 761447600
I0927 14:49:11.174943  3463 layer_factory.hpp:77] Creating layer M2PELU23
I0927 14:49:11.174948  3463 net.cpp:84] Creating Layer M2PELU23
I0927 14:49:11.174952  3463 net.cpp:406] M2PELU23 <- Eltwise11
I0927 14:49:11.174954  3463 net.cpp:367] M2PELU23 -> Eltwise11 (in-place)
I0927 14:49:11.175036  3463 net.cpp:122] Setting up M2PELU23
I0927 14:49:11.175041  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.175043  3463 net.cpp:137] Memory required for data: 764724400
I0927 14:49:11.175047  3463 layer_factory.hpp:77] Creating layer Eltwise11_M2PELU23_0_split
I0927 14:49:11.175050  3463 net.cpp:84] Creating Layer Eltwise11_M2PELU23_0_split
I0927 14:49:11.175053  3463 net.cpp:406] Eltwise11_M2PELU23_0_split <- Eltwise11
I0927 14:49:11.175057  3463 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_0
I0927 14:49:11.175061  3463 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_1
I0927 14:49:11.175084  3463 net.cpp:122] Setting up Eltwise11_M2PELU23_0_split
I0927 14:49:11.175087  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.175091  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.175092  3463 net.cpp:137] Memory required for data: 771278000
I0927 14:49:11.175094  3463 layer_factory.hpp:77] Creating layer Convolution25
I0927 14:49:11.175101  3463 net.cpp:84] Creating Layer Convolution25
I0927 14:49:11.175103  3463 net.cpp:406] Convolution25 <- Eltwise11_M2PELU23_0_split_0
I0927 14:49:11.175107  3463 net.cpp:380] Convolution25 -> Convolution25
I0927 14:49:11.176213  3463 net.cpp:122] Setting up Convolution25
I0927 14:49:11.176221  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.176224  3463 net.cpp:137] Memory required for data: 774554800
I0927 14:49:11.176229  3463 layer_factory.hpp:77] Creating layer BatchNorm25
I0927 14:49:11.176234  3463 net.cpp:84] Creating Layer BatchNorm25
I0927 14:49:11.176237  3463 net.cpp:406] BatchNorm25 <- Convolution25
I0927 14:49:11.176241  3463 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0927 14:49:11.176368  3463 net.cpp:122] Setting up BatchNorm25
I0927 14:49:11.176379  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.176381  3463 net.cpp:137] Memory required for data: 777831600
I0927 14:49:11.176386  3463 layer_factory.hpp:77] Creating layer Scale25
I0927 14:49:11.176391  3463 net.cpp:84] Creating Layer Scale25
I0927 14:49:11.176393  3463 net.cpp:406] Scale25 <- Convolution25
I0927 14:49:11.176398  3463 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0927 14:49:11.176424  3463 layer_factory.hpp:77] Creating layer Scale25
I0927 14:49:11.176497  3463 net.cpp:122] Setting up Scale25
I0927 14:49:11.176501  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.176503  3463 net.cpp:137] Memory required for data: 781108400
I0927 14:49:11.176507  3463 layer_factory.hpp:77] Creating layer M2PELU24
I0927 14:49:11.176513  3463 net.cpp:84] Creating Layer M2PELU24
I0927 14:49:11.176515  3463 net.cpp:406] M2PELU24 <- Convolution25
I0927 14:49:11.176519  3463 net.cpp:367] M2PELU24 -> Convolution25 (in-place)
I0927 14:49:11.176600  3463 net.cpp:122] Setting up M2PELU24
I0927 14:49:11.176604  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.176606  3463 net.cpp:137] Memory required for data: 784385200
I0927 14:49:11.176610  3463 layer_factory.hpp:77] Creating layer Convolution26
I0927 14:49:11.176618  3463 net.cpp:84] Creating Layer Convolution26
I0927 14:49:11.176620  3463 net.cpp:406] Convolution26 <- Convolution25
I0927 14:49:11.176625  3463 net.cpp:380] Convolution26 -> Convolution26
I0927 14:49:11.177382  3463 net.cpp:122] Setting up Convolution26
I0927 14:49:11.177390  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.177393  3463 net.cpp:137] Memory required for data: 787662000
I0927 14:49:11.177397  3463 layer_factory.hpp:77] Creating layer BatchNorm26
I0927 14:49:11.177402  3463 net.cpp:84] Creating Layer BatchNorm26
I0927 14:49:11.177405  3463 net.cpp:406] BatchNorm26 <- Convolution26
I0927 14:49:11.177408  3463 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0927 14:49:11.177536  3463 net.cpp:122] Setting up BatchNorm26
I0927 14:49:11.177541  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.177542  3463 net.cpp:137] Memory required for data: 790938800
I0927 14:49:11.177547  3463 layer_factory.hpp:77] Creating layer Scale26
I0927 14:49:11.177551  3463 net.cpp:84] Creating Layer Scale26
I0927 14:49:11.199151  3463 net.cpp:406] Scale26 <- Convolution26
I0927 14:49:11.199167  3463 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0927 14:49:11.199213  3463 layer_factory.hpp:77] Creating layer Scale26
I0927 14:49:11.199298  3463 net.cpp:122] Setting up Scale26
I0927 14:49:11.199304  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.199306  3463 net.cpp:137] Memory required for data: 794215600
I0927 14:49:11.199311  3463 layer_factory.hpp:77] Creating layer Eltwise12
I0927 14:49:11.199316  3463 net.cpp:84] Creating Layer Eltwise12
I0927 14:49:11.199318  3463 net.cpp:406] Eltwise12 <- Eltwise11_M2PELU23_0_split_1
I0927 14:49:11.199322  3463 net.cpp:406] Eltwise12 <- Convolution26
I0927 14:49:11.199326  3463 net.cpp:380] Eltwise12 -> Eltwise12
I0927 14:49:11.199339  3463 net.cpp:122] Setting up Eltwise12
I0927 14:49:11.199344  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.199347  3463 net.cpp:137] Memory required for data: 797492400
I0927 14:49:11.199348  3463 layer_factory.hpp:77] Creating layer M2PELU25
I0927 14:49:11.199362  3463 net.cpp:84] Creating Layer M2PELU25
I0927 14:49:11.199365  3463 net.cpp:406] M2PELU25 <- Eltwise12
I0927 14:49:11.199369  3463 net.cpp:367] M2PELU25 -> Eltwise12 (in-place)
I0927 14:49:11.199465  3463 net.cpp:122] Setting up M2PELU25
I0927 14:49:11.199468  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.199471  3463 net.cpp:137] Memory required for data: 800769200
I0927 14:49:11.199476  3463 layer_factory.hpp:77] Creating layer Eltwise12_M2PELU25_0_split
I0927 14:49:11.199479  3463 net.cpp:84] Creating Layer Eltwise12_M2PELU25_0_split
I0927 14:49:11.199481  3463 net.cpp:406] Eltwise12_M2PELU25_0_split <- Eltwise12
I0927 14:49:11.199496  3463 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_0
I0927 14:49:11.199501  3463 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_1
I0927 14:49:11.199529  3463 net.cpp:122] Setting up Eltwise12_M2PELU25_0_split
I0927 14:49:11.199533  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.199537  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.199539  3463 net.cpp:137] Memory required for data: 807322800
I0927 14:49:11.199542  3463 layer_factory.hpp:77] Creating layer Convolution27
I0927 14:49:11.199548  3463 net.cpp:84] Creating Layer Convolution27
I0927 14:49:11.199551  3463 net.cpp:406] Convolution27 <- Eltwise12_M2PELU25_0_split_0
I0927 14:49:11.199555  3463 net.cpp:380] Convolution27 -> Convolution27
I0927 14:49:11.201284  3463 net.cpp:122] Setting up Convolution27
I0927 14:49:11.201294  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.201297  3463 net.cpp:137] Memory required for data: 810599600
I0927 14:49:11.201301  3463 layer_factory.hpp:77] Creating layer BatchNorm27
I0927 14:49:11.201308  3463 net.cpp:84] Creating Layer BatchNorm27
I0927 14:49:11.201310  3463 net.cpp:406] BatchNorm27 <- Convolution27
I0927 14:49:11.201314  3463 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0927 14:49:11.201442  3463 net.cpp:122] Setting up BatchNorm27
I0927 14:49:11.201447  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.201448  3463 net.cpp:137] Memory required for data: 813876400
I0927 14:49:11.201453  3463 layer_factory.hpp:77] Creating layer Scale27
I0927 14:49:11.201458  3463 net.cpp:84] Creating Layer Scale27
I0927 14:49:11.201462  3463 net.cpp:406] Scale27 <- Convolution27
I0927 14:49:11.201464  3463 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0927 14:49:11.201491  3463 layer_factory.hpp:77] Creating layer Scale27
I0927 14:49:11.201563  3463 net.cpp:122] Setting up Scale27
I0927 14:49:11.201568  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.201570  3463 net.cpp:137] Memory required for data: 817153200
I0927 14:49:11.201575  3463 layer_factory.hpp:77] Creating layer M2PELU26
I0927 14:49:11.201580  3463 net.cpp:84] Creating Layer M2PELU26
I0927 14:49:11.201581  3463 net.cpp:406] M2PELU26 <- Convolution27
I0927 14:49:11.201586  3463 net.cpp:367] M2PELU26 -> Convolution27 (in-place)
I0927 14:49:11.201666  3463 net.cpp:122] Setting up M2PELU26
I0927 14:49:11.201670  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.201673  3463 net.cpp:137] Memory required for data: 820430000
I0927 14:49:11.201676  3463 layer_factory.hpp:77] Creating layer Convolution28
I0927 14:49:11.201683  3463 net.cpp:84] Creating Layer Convolution28
I0927 14:49:11.201685  3463 net.cpp:406] Convolution28 <- Convolution27
I0927 14:49:11.201689  3463 net.cpp:380] Convolution28 -> Convolution28
I0927 14:49:11.203128  3463 net.cpp:122] Setting up Convolution28
I0927 14:49:11.203137  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.203140  3463 net.cpp:137] Memory required for data: 823706800
I0927 14:49:11.203145  3463 layer_factory.hpp:77] Creating layer BatchNorm28
I0927 14:49:11.203150  3463 net.cpp:84] Creating Layer BatchNorm28
I0927 14:49:11.203152  3463 net.cpp:406] BatchNorm28 <- Convolution28
I0927 14:49:11.203156  3463 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0927 14:49:11.203286  3463 net.cpp:122] Setting up BatchNorm28
I0927 14:49:11.203291  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.203294  3463 net.cpp:137] Memory required for data: 826983600
I0927 14:49:11.203299  3463 layer_factory.hpp:77] Creating layer Scale28
I0927 14:49:11.203302  3463 net.cpp:84] Creating Layer Scale28
I0927 14:49:11.203305  3463 net.cpp:406] Scale28 <- Convolution28
I0927 14:49:11.203308  3463 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0927 14:49:11.203336  3463 layer_factory.hpp:77] Creating layer Scale28
I0927 14:49:11.203410  3463 net.cpp:122] Setting up Scale28
I0927 14:49:11.203414  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.203424  3463 net.cpp:137] Memory required for data: 830260400
I0927 14:49:11.203428  3463 layer_factory.hpp:77] Creating layer Eltwise13
I0927 14:49:11.203433  3463 net.cpp:84] Creating Layer Eltwise13
I0927 14:49:11.203436  3463 net.cpp:406] Eltwise13 <- Eltwise12_M2PELU25_0_split_1
I0927 14:49:11.203439  3463 net.cpp:406] Eltwise13 <- Convolution28
I0927 14:49:11.203443  3463 net.cpp:380] Eltwise13 -> Eltwise13
I0927 14:49:11.203455  3463 net.cpp:122] Setting up Eltwise13
I0927 14:49:11.203459  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.203461  3463 net.cpp:137] Memory required for data: 833537200
I0927 14:49:11.203464  3463 layer_factory.hpp:77] Creating layer M2PELU27
I0927 14:49:11.203469  3463 net.cpp:84] Creating Layer M2PELU27
I0927 14:49:11.203470  3463 net.cpp:406] M2PELU27 <- Eltwise13
I0927 14:49:11.203475  3463 net.cpp:367] M2PELU27 -> Eltwise13 (in-place)
I0927 14:49:11.203562  3463 net.cpp:122] Setting up M2PELU27
I0927 14:49:11.203567  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.203568  3463 net.cpp:137] Memory required for data: 836814000
I0927 14:49:11.203572  3463 layer_factory.hpp:77] Creating layer Eltwise13_M2PELU27_0_split
I0927 14:49:11.203577  3463 net.cpp:84] Creating Layer Eltwise13_M2PELU27_0_split
I0927 14:49:11.203578  3463 net.cpp:406] Eltwise13_M2PELU27_0_split <- Eltwise13
I0927 14:49:11.203583  3463 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_0
I0927 14:49:11.203586  3463 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_1
I0927 14:49:11.203610  3463 net.cpp:122] Setting up Eltwise13_M2PELU27_0_split
I0927 14:49:11.203614  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.203618  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.203619  3463 net.cpp:137] Memory required for data: 843367600
I0927 14:49:11.203621  3463 layer_factory.hpp:77] Creating layer Convolution29
I0927 14:49:11.203627  3463 net.cpp:84] Creating Layer Convolution29
I0927 14:49:11.203630  3463 net.cpp:406] Convolution29 <- Eltwise13_M2PELU27_0_split_0
I0927 14:49:11.203634  3463 net.cpp:380] Convolution29 -> Convolution29
I0927 14:49:11.204733  3463 net.cpp:122] Setting up Convolution29
I0927 14:49:11.204743  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.204746  3463 net.cpp:137] Memory required for data: 846644400
I0927 14:49:11.204751  3463 layer_factory.hpp:77] Creating layer BatchNorm29
I0927 14:49:11.204754  3463 net.cpp:84] Creating Layer BatchNorm29
I0927 14:49:11.204757  3463 net.cpp:406] BatchNorm29 <- Convolution29
I0927 14:49:11.204762  3463 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0927 14:49:11.204890  3463 net.cpp:122] Setting up BatchNorm29
I0927 14:49:11.204895  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.204896  3463 net.cpp:137] Memory required for data: 849921200
I0927 14:49:11.204901  3463 layer_factory.hpp:77] Creating layer Scale29
I0927 14:49:11.204905  3463 net.cpp:84] Creating Layer Scale29
I0927 14:49:11.204908  3463 net.cpp:406] Scale29 <- Convolution29
I0927 14:49:11.204911  3463 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0927 14:49:11.204937  3463 layer_factory.hpp:77] Creating layer Scale29
I0927 14:49:11.205009  3463 net.cpp:122] Setting up Scale29
I0927 14:49:11.205013  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.205015  3463 net.cpp:137] Memory required for data: 853198000
I0927 14:49:11.205039  3463 layer_factory.hpp:77] Creating layer M2PELU28
I0927 14:49:11.205046  3463 net.cpp:84] Creating Layer M2PELU28
I0927 14:49:11.205049  3463 net.cpp:406] M2PELU28 <- Convolution29
I0927 14:49:11.205052  3463 net.cpp:367] M2PELU28 -> Convolution29 (in-place)
I0927 14:49:11.205137  3463 net.cpp:122] Setting up M2PELU28
I0927 14:49:11.205140  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.205142  3463 net.cpp:137] Memory required for data: 856474800
I0927 14:49:11.205147  3463 layer_factory.hpp:77] Creating layer Convolution30
I0927 14:49:11.205159  3463 net.cpp:84] Creating Layer Convolution30
I0927 14:49:11.205163  3463 net.cpp:406] Convolution30 <- Convolution29
I0927 14:49:11.205166  3463 net.cpp:380] Convolution30 -> Convolution30
I0927 14:49:11.206267  3463 net.cpp:122] Setting up Convolution30
I0927 14:49:11.206275  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.206279  3463 net.cpp:137] Memory required for data: 859751600
I0927 14:49:11.206282  3463 layer_factory.hpp:77] Creating layer BatchNorm30
I0927 14:49:11.206288  3463 net.cpp:84] Creating Layer BatchNorm30
I0927 14:49:11.206290  3463 net.cpp:406] BatchNorm30 <- Convolution30
I0927 14:49:11.206295  3463 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0927 14:49:11.206421  3463 net.cpp:122] Setting up BatchNorm30
I0927 14:49:11.206425  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.206428  3463 net.cpp:137] Memory required for data: 863028400
I0927 14:49:11.206432  3463 layer_factory.hpp:77] Creating layer Scale30
I0927 14:49:11.206436  3463 net.cpp:84] Creating Layer Scale30
I0927 14:49:11.206439  3463 net.cpp:406] Scale30 <- Convolution30
I0927 14:49:11.206442  3463 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0927 14:49:11.206468  3463 layer_factory.hpp:77] Creating layer Scale30
I0927 14:49:11.206545  3463 net.cpp:122] Setting up Scale30
I0927 14:49:11.206552  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.206553  3463 net.cpp:137] Memory required for data: 866305200
I0927 14:49:11.206557  3463 layer_factory.hpp:77] Creating layer Eltwise14
I0927 14:49:11.206560  3463 net.cpp:84] Creating Layer Eltwise14
I0927 14:49:11.206563  3463 net.cpp:406] Eltwise14 <- Eltwise13_M2PELU27_0_split_1
I0927 14:49:11.206567  3463 net.cpp:406] Eltwise14 <- Convolution30
I0927 14:49:11.206570  3463 net.cpp:380] Eltwise14 -> Eltwise14
I0927 14:49:11.206583  3463 net.cpp:122] Setting up Eltwise14
I0927 14:49:11.206586  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.206588  3463 net.cpp:137] Memory required for data: 869582000
I0927 14:49:11.206590  3463 layer_factory.hpp:77] Creating layer M2PELU29
I0927 14:49:11.206595  3463 net.cpp:84] Creating Layer M2PELU29
I0927 14:49:11.206598  3463 net.cpp:406] M2PELU29 <- Eltwise14
I0927 14:49:11.206601  3463 net.cpp:367] M2PELU29 -> Eltwise14 (in-place)
I0927 14:49:11.206686  3463 net.cpp:122] Setting up M2PELU29
I0927 14:49:11.206691  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.206692  3463 net.cpp:137] Memory required for data: 872858800
I0927 14:49:11.206696  3463 layer_factory.hpp:77] Creating layer Eltwise14_M2PELU29_0_split
I0927 14:49:11.206701  3463 net.cpp:84] Creating Layer Eltwise14_M2PELU29_0_split
I0927 14:49:11.206702  3463 net.cpp:406] Eltwise14_M2PELU29_0_split <- Eltwise14
I0927 14:49:11.206707  3463 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_0
I0927 14:49:11.206712  3463 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_1
I0927 14:49:11.206734  3463 net.cpp:122] Setting up Eltwise14_M2PELU29_0_split
I0927 14:49:11.206738  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.206742  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.206743  3463 net.cpp:137] Memory required for data: 879412400
I0927 14:49:11.206745  3463 layer_factory.hpp:77] Creating layer Convolution31
I0927 14:49:11.206751  3463 net.cpp:84] Creating Layer Convolution31
I0927 14:49:11.206754  3463 net.cpp:406] Convolution31 <- Eltwise14_M2PELU29_0_split_0
I0927 14:49:11.206758  3463 net.cpp:380] Convolution31 -> Convolution31
I0927 14:49:11.207849  3463 net.cpp:122] Setting up Convolution31
I0927 14:49:11.207857  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.207859  3463 net.cpp:137] Memory required for data: 882689200
I0927 14:49:11.207864  3463 layer_factory.hpp:77] Creating layer BatchNorm31
I0927 14:49:11.207870  3463 net.cpp:84] Creating Layer BatchNorm31
I0927 14:49:11.207873  3463 net.cpp:406] BatchNorm31 <- Convolution31
I0927 14:49:11.207876  3463 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0927 14:49:11.208009  3463 net.cpp:122] Setting up BatchNorm31
I0927 14:49:11.208012  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.208014  3463 net.cpp:137] Memory required for data: 885966000
I0927 14:49:11.208019  3463 layer_factory.hpp:77] Creating layer Scale31
I0927 14:49:11.208025  3463 net.cpp:84] Creating Layer Scale31
I0927 14:49:11.208027  3463 net.cpp:406] Scale31 <- Convolution31
I0927 14:49:11.208031  3463 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0927 14:49:11.208057  3463 layer_factory.hpp:77] Creating layer Scale31
I0927 14:49:11.208130  3463 net.cpp:122] Setting up Scale31
I0927 14:49:11.208134  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.208137  3463 net.cpp:137] Memory required for data: 889242800
I0927 14:49:11.208140  3463 layer_factory.hpp:77] Creating layer M2PELU30
I0927 14:49:11.208147  3463 net.cpp:84] Creating Layer M2PELU30
I0927 14:49:11.208148  3463 net.cpp:406] M2PELU30 <- Convolution31
I0927 14:49:11.208151  3463 net.cpp:367] M2PELU30 -> Convolution31 (in-place)
I0927 14:49:11.208230  3463 net.cpp:122] Setting up M2PELU30
I0927 14:49:11.208235  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.208237  3463 net.cpp:137] Memory required for data: 892519600
I0927 14:49:11.208240  3463 layer_factory.hpp:77] Creating layer Convolution32
I0927 14:49:11.208248  3463 net.cpp:84] Creating Layer Convolution32
I0927 14:49:11.208250  3463 net.cpp:406] Convolution32 <- Convolution31
I0927 14:49:11.208254  3463 net.cpp:380] Convolution32 -> Convolution32
I0927 14:49:11.209349  3463 net.cpp:122] Setting up Convolution32
I0927 14:49:11.209357  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.209360  3463 net.cpp:137] Memory required for data: 895796400
I0927 14:49:11.209365  3463 layer_factory.hpp:77] Creating layer BatchNorm32
I0927 14:49:11.209370  3463 net.cpp:84] Creating Layer BatchNorm32
I0927 14:49:11.209373  3463 net.cpp:406] BatchNorm32 <- Convolution32
I0927 14:49:11.209378  3463 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I0927 14:49:11.209504  3463 net.cpp:122] Setting up BatchNorm32
I0927 14:49:11.209508  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.228312  3463 net.cpp:137] Memory required for data: 899073200
I0927 14:49:11.228324  3463 layer_factory.hpp:77] Creating layer Scale32
I0927 14:49:11.228329  3463 net.cpp:84] Creating Layer Scale32
I0927 14:49:11.228333  3463 net.cpp:406] Scale32 <- Convolution32
I0927 14:49:11.228339  3463 net.cpp:367] Scale32 -> Convolution32 (in-place)
I0927 14:49:11.228377  3463 layer_factory.hpp:77] Creating layer Scale32
I0927 14:49:11.228462  3463 net.cpp:122] Setting up Scale32
I0927 14:49:11.228467  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.228469  3463 net.cpp:137] Memory required for data: 902350000
I0927 14:49:11.228473  3463 layer_factory.hpp:77] Creating layer Eltwise15
I0927 14:49:11.228477  3463 net.cpp:84] Creating Layer Eltwise15
I0927 14:49:11.228480  3463 net.cpp:406] Eltwise15 <- Eltwise14_M2PELU29_0_split_1
I0927 14:49:11.228484  3463 net.cpp:406] Eltwise15 <- Convolution32
I0927 14:49:11.228487  3463 net.cpp:380] Eltwise15 -> Eltwise15
I0927 14:49:11.228502  3463 net.cpp:122] Setting up Eltwise15
I0927 14:49:11.228505  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.228507  3463 net.cpp:137] Memory required for data: 905626800
I0927 14:49:11.228509  3463 layer_factory.hpp:77] Creating layer M2PELU31
I0927 14:49:11.228515  3463 net.cpp:84] Creating Layer M2PELU31
I0927 14:49:11.228518  3463 net.cpp:406] M2PELU31 <- Eltwise15
I0927 14:49:11.228521  3463 net.cpp:367] M2PELU31 -> Eltwise15 (in-place)
I0927 14:49:11.228615  3463 net.cpp:122] Setting up M2PELU31
I0927 14:49:11.228621  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.228622  3463 net.cpp:137] Memory required for data: 908903600
I0927 14:49:11.228626  3463 layer_factory.hpp:77] Creating layer Eltwise15_M2PELU31_0_split
I0927 14:49:11.228631  3463 net.cpp:84] Creating Layer Eltwise15_M2PELU31_0_split
I0927 14:49:11.228641  3463 net.cpp:406] Eltwise15_M2PELU31_0_split <- Eltwise15
I0927 14:49:11.228644  3463 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_0
I0927 14:49:11.228649  3463 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_1
I0927 14:49:11.228677  3463 net.cpp:122] Setting up Eltwise15_M2PELU31_0_split
I0927 14:49:11.228682  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.228684  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.228687  3463 net.cpp:137] Memory required for data: 915457200
I0927 14:49:11.228688  3463 layer_factory.hpp:77] Creating layer Convolution33
I0927 14:49:11.228695  3463 net.cpp:84] Creating Layer Convolution33
I0927 14:49:11.228698  3463 net.cpp:406] Convolution33 <- Eltwise15_M2PELU31_0_split_0
I0927 14:49:11.228703  3463 net.cpp:380] Convolution33 -> Convolution33
I0927 14:49:11.230010  3463 net.cpp:122] Setting up Convolution33
I0927 14:49:11.230021  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.230026  3463 net.cpp:137] Memory required for data: 918734000
I0927 14:49:11.230034  3463 layer_factory.hpp:77] Creating layer BatchNorm33
I0927 14:49:11.230043  3463 net.cpp:84] Creating Layer BatchNorm33
I0927 14:49:11.230049  3463 net.cpp:406] BatchNorm33 <- Convolution33
I0927 14:49:11.230057  3463 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I0927 14:49:11.230195  3463 net.cpp:122] Setting up BatchNorm33
I0927 14:49:11.230199  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.230201  3463 net.cpp:137] Memory required for data: 922010800
I0927 14:49:11.230206  3463 layer_factory.hpp:77] Creating layer Scale33
I0927 14:49:11.230211  3463 net.cpp:84] Creating Layer Scale33
I0927 14:49:11.230213  3463 net.cpp:406] Scale33 <- Convolution33
I0927 14:49:11.230217  3463 net.cpp:367] Scale33 -> Convolution33 (in-place)
I0927 14:49:11.230244  3463 layer_factory.hpp:77] Creating layer Scale33
I0927 14:49:11.230322  3463 net.cpp:122] Setting up Scale33
I0927 14:49:11.230326  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.230329  3463 net.cpp:137] Memory required for data: 925287600
I0927 14:49:11.230334  3463 layer_factory.hpp:77] Creating layer M2PELU32
I0927 14:49:11.230337  3463 net.cpp:84] Creating Layer M2PELU32
I0927 14:49:11.230340  3463 net.cpp:406] M2PELU32 <- Convolution33
I0927 14:49:11.230345  3463 net.cpp:367] M2PELU32 -> Convolution33 (in-place)
I0927 14:49:11.230432  3463 net.cpp:122] Setting up M2PELU32
I0927 14:49:11.230437  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.230438  3463 net.cpp:137] Memory required for data: 928564400
I0927 14:49:11.230443  3463 layer_factory.hpp:77] Creating layer Convolution34
I0927 14:49:11.230449  3463 net.cpp:84] Creating Layer Convolution34
I0927 14:49:11.230451  3463 net.cpp:406] Convolution34 <- Convolution33
I0927 14:49:11.230456  3463 net.cpp:380] Convolution34 -> Convolution34
I0927 14:49:11.232167  3463 net.cpp:122] Setting up Convolution34
I0927 14:49:11.232175  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.232178  3463 net.cpp:137] Memory required for data: 931841200
I0927 14:49:11.232183  3463 layer_factory.hpp:77] Creating layer BatchNorm34
I0927 14:49:11.232189  3463 net.cpp:84] Creating Layer BatchNorm34
I0927 14:49:11.232192  3463 net.cpp:406] BatchNorm34 <- Convolution34
I0927 14:49:11.232197  3463 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I0927 14:49:11.232331  3463 net.cpp:122] Setting up BatchNorm34
I0927 14:49:11.232336  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.232337  3463 net.cpp:137] Memory required for data: 935118000
I0927 14:49:11.232342  3463 layer_factory.hpp:77] Creating layer Scale34
I0927 14:49:11.232347  3463 net.cpp:84] Creating Layer Scale34
I0927 14:49:11.232350  3463 net.cpp:406] Scale34 <- Convolution34
I0927 14:49:11.232353  3463 net.cpp:367] Scale34 -> Convolution34 (in-place)
I0927 14:49:11.232381  3463 layer_factory.hpp:77] Creating layer Scale34
I0927 14:49:11.232457  3463 net.cpp:122] Setting up Scale34
I0927 14:49:11.232470  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.232471  3463 net.cpp:137] Memory required for data: 938394800
I0927 14:49:11.232476  3463 layer_factory.hpp:77] Creating layer Eltwise16
I0927 14:49:11.232481  3463 net.cpp:84] Creating Layer Eltwise16
I0927 14:49:11.232484  3463 net.cpp:406] Eltwise16 <- Eltwise15_M2PELU31_0_split_1
I0927 14:49:11.232487  3463 net.cpp:406] Eltwise16 <- Convolution34
I0927 14:49:11.232491  3463 net.cpp:380] Eltwise16 -> Eltwise16
I0927 14:49:11.232506  3463 net.cpp:122] Setting up Eltwise16
I0927 14:49:11.232509  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.232511  3463 net.cpp:137] Memory required for data: 941671600
I0927 14:49:11.232513  3463 layer_factory.hpp:77] Creating layer M2PELU33
I0927 14:49:11.232518  3463 net.cpp:84] Creating Layer M2PELU33
I0927 14:49:11.232522  3463 net.cpp:406] M2PELU33 <- Eltwise16
I0927 14:49:11.232524  3463 net.cpp:367] M2PELU33 -> Eltwise16 (in-place)
I0927 14:49:11.232614  3463 net.cpp:122] Setting up M2PELU33
I0927 14:49:11.232619  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.232620  3463 net.cpp:137] Memory required for data: 944948400
I0927 14:49:11.232625  3463 layer_factory.hpp:77] Creating layer Eltwise16_M2PELU33_0_split
I0927 14:49:11.232628  3463 net.cpp:84] Creating Layer Eltwise16_M2PELU33_0_split
I0927 14:49:11.232631  3463 net.cpp:406] Eltwise16_M2PELU33_0_split <- Eltwise16
I0927 14:49:11.232635  3463 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_0
I0927 14:49:11.232640  3463 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_1
I0927 14:49:11.232666  3463 net.cpp:122] Setting up Eltwise16_M2PELU33_0_split
I0927 14:49:11.232669  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.232672  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.232674  3463 net.cpp:137] Memory required for data: 951502000
I0927 14:49:11.232676  3463 layer_factory.hpp:77] Creating layer Convolution35
I0927 14:49:11.232682  3463 net.cpp:84] Creating Layer Convolution35
I0927 14:49:11.232684  3463 net.cpp:406] Convolution35 <- Eltwise16_M2PELU33_0_split_0
I0927 14:49:11.232689  3463 net.cpp:380] Convolution35 -> Convolution35
I0927 14:49:11.233825  3463 net.cpp:122] Setting up Convolution35
I0927 14:49:11.233834  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.233836  3463 net.cpp:137] Memory required for data: 954778800
I0927 14:49:11.233841  3463 layer_factory.hpp:77] Creating layer BatchNorm35
I0927 14:49:11.233846  3463 net.cpp:84] Creating Layer BatchNorm35
I0927 14:49:11.233850  3463 net.cpp:406] BatchNorm35 <- Convolution35
I0927 14:49:11.233855  3463 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I0927 14:49:11.233990  3463 net.cpp:122] Setting up BatchNorm35
I0927 14:49:11.233995  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.233997  3463 net.cpp:137] Memory required for data: 958055600
I0927 14:49:11.234002  3463 layer_factory.hpp:77] Creating layer Scale35
I0927 14:49:11.234006  3463 net.cpp:84] Creating Layer Scale35
I0927 14:49:11.234009  3463 net.cpp:406] Scale35 <- Convolution35
I0927 14:49:11.234012  3463 net.cpp:367] Scale35 -> Convolution35 (in-place)
I0927 14:49:11.234040  3463 layer_factory.hpp:77] Creating layer Scale35
I0927 14:49:11.234117  3463 net.cpp:122] Setting up Scale35
I0927 14:49:11.234122  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.234123  3463 net.cpp:137] Memory required for data: 961332400
I0927 14:49:11.234127  3463 layer_factory.hpp:77] Creating layer M2PELU34
I0927 14:49:11.234131  3463 net.cpp:84] Creating Layer M2PELU34
I0927 14:49:11.234135  3463 net.cpp:406] M2PELU34 <- Convolution35
I0927 14:49:11.234138  3463 net.cpp:367] M2PELU34 -> Convolution35 (in-place)
I0927 14:49:11.234221  3463 net.cpp:122] Setting up M2PELU34
I0927 14:49:11.234226  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.234228  3463 net.cpp:137] Memory required for data: 964609200
I0927 14:49:11.234238  3463 layer_factory.hpp:77] Creating layer Convolution36
I0927 14:49:11.234246  3463 net.cpp:84] Creating Layer Convolution36
I0927 14:49:11.234249  3463 net.cpp:406] Convolution36 <- Convolution35
I0927 14:49:11.234254  3463 net.cpp:380] Convolution36 -> Convolution36
I0927 14:49:11.235059  3463 net.cpp:122] Setting up Convolution36
I0927 14:49:11.235067  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.235069  3463 net.cpp:137] Memory required for data: 967886000
I0927 14:49:11.235074  3463 layer_factory.hpp:77] Creating layer BatchNorm36
I0927 14:49:11.235080  3463 net.cpp:84] Creating Layer BatchNorm36
I0927 14:49:11.235082  3463 net.cpp:406] BatchNorm36 <- Convolution36
I0927 14:49:11.235086  3463 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I0927 14:49:11.235220  3463 net.cpp:122] Setting up BatchNorm36
I0927 14:49:11.235225  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.235227  3463 net.cpp:137] Memory required for data: 971162800
I0927 14:49:11.235231  3463 layer_factory.hpp:77] Creating layer Scale36
I0927 14:49:11.235235  3463 net.cpp:84] Creating Layer Scale36
I0927 14:49:11.235239  3463 net.cpp:406] Scale36 <- Convolution36
I0927 14:49:11.235242  3463 net.cpp:367] Scale36 -> Convolution36 (in-place)
I0927 14:49:11.235270  3463 layer_factory.hpp:77] Creating layer Scale36
I0927 14:49:11.235347  3463 net.cpp:122] Setting up Scale36
I0927 14:49:11.235350  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.235352  3463 net.cpp:137] Memory required for data: 974439600
I0927 14:49:11.235357  3463 layer_factory.hpp:77] Creating layer Eltwise17
I0927 14:49:11.235360  3463 net.cpp:84] Creating Layer Eltwise17
I0927 14:49:11.235363  3463 net.cpp:406] Eltwise17 <- Eltwise16_M2PELU33_0_split_1
I0927 14:49:11.235366  3463 net.cpp:406] Eltwise17 <- Convolution36
I0927 14:49:11.235369  3463 net.cpp:380] Eltwise17 -> Eltwise17
I0927 14:49:11.235383  3463 net.cpp:122] Setting up Eltwise17
I0927 14:49:11.235386  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.235388  3463 net.cpp:137] Memory required for data: 977716400
I0927 14:49:11.235390  3463 layer_factory.hpp:77] Creating layer M2PELU35
I0927 14:49:11.235396  3463 net.cpp:84] Creating Layer M2PELU35
I0927 14:49:11.235399  3463 net.cpp:406] M2PELU35 <- Eltwise17
I0927 14:49:11.235401  3463 net.cpp:367] M2PELU35 -> Eltwise17 (in-place)
I0927 14:49:11.235493  3463 net.cpp:122] Setting up M2PELU35
I0927 14:49:11.235498  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.235501  3463 net.cpp:137] Memory required for data: 980993200
I0927 14:49:11.235504  3463 layer_factory.hpp:77] Creating layer Eltwise17_M2PELU35_0_split
I0927 14:49:11.235507  3463 net.cpp:84] Creating Layer Eltwise17_M2PELU35_0_split
I0927 14:49:11.235510  3463 net.cpp:406] Eltwise17_M2PELU35_0_split <- Eltwise17
I0927 14:49:11.235513  3463 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_0
I0927 14:49:11.235517  3463 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_1
I0927 14:49:11.235543  3463 net.cpp:122] Setting up Eltwise17_M2PELU35_0_split
I0927 14:49:11.235546  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.235549  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.235551  3463 net.cpp:137] Memory required for data: 987546800
I0927 14:49:11.235554  3463 layer_factory.hpp:77] Creating layer Convolution37
I0927 14:49:11.235560  3463 net.cpp:84] Creating Layer Convolution37
I0927 14:49:11.235563  3463 net.cpp:406] Convolution37 <- Eltwise17_M2PELU35_0_split_0
I0927 14:49:11.235568  3463 net.cpp:380] Convolution37 -> Convolution37
I0927 14:49:11.236687  3463 net.cpp:122] Setting up Convolution37
I0927 14:49:11.236696  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.236698  3463 net.cpp:137] Memory required for data: 990823600
I0927 14:49:11.236703  3463 layer_factory.hpp:77] Creating layer BatchNorm37
I0927 14:49:11.236708  3463 net.cpp:84] Creating Layer BatchNorm37
I0927 14:49:11.236711  3463 net.cpp:406] BatchNorm37 <- Convolution37
I0927 14:49:11.236721  3463 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I0927 14:49:11.236857  3463 net.cpp:122] Setting up BatchNorm37
I0927 14:49:11.236861  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.236865  3463 net.cpp:137] Memory required for data: 994100400
I0927 14:49:11.236868  3463 layer_factory.hpp:77] Creating layer Scale37
I0927 14:49:11.236873  3463 net.cpp:84] Creating Layer Scale37
I0927 14:49:11.236876  3463 net.cpp:406] Scale37 <- Convolution37
I0927 14:49:11.236879  3463 net.cpp:367] Scale37 -> Convolution37 (in-place)
I0927 14:49:11.236907  3463 layer_factory.hpp:77] Creating layer Scale37
I0927 14:49:11.236984  3463 net.cpp:122] Setting up Scale37
I0927 14:49:11.236989  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.236990  3463 net.cpp:137] Memory required for data: 997377200
I0927 14:49:11.236994  3463 layer_factory.hpp:77] Creating layer M2PELU36
I0927 14:49:11.236999  3463 net.cpp:84] Creating Layer M2PELU36
I0927 14:49:11.237001  3463 net.cpp:406] M2PELU36 <- Convolution37
I0927 14:49:11.237005  3463 net.cpp:367] M2PELU36 -> Convolution37 (in-place)
I0927 14:49:11.237090  3463 net.cpp:122] Setting up M2PELU36
I0927 14:49:11.237095  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.237097  3463 net.cpp:137] Memory required for data: 1000654000
I0927 14:49:11.237100  3463 layer_factory.hpp:77] Creating layer Convolution38
I0927 14:49:11.237107  3463 net.cpp:84] Creating Layer Convolution38
I0927 14:49:11.237110  3463 net.cpp:406] Convolution38 <- Convolution37
I0927 14:49:11.237115  3463 net.cpp:380] Convolution38 -> Convolution38
I0927 14:49:11.238592  3463 net.cpp:122] Setting up Convolution38
I0927 14:49:11.238601  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.238603  3463 net.cpp:137] Memory required for data: 1003930800
I0927 14:49:11.238608  3463 layer_factory.hpp:77] Creating layer BatchNorm38
I0927 14:49:11.238613  3463 net.cpp:84] Creating Layer BatchNorm38
I0927 14:49:11.238616  3463 net.cpp:406] BatchNorm38 <- Convolution38
I0927 14:49:11.258796  3463 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I0927 14:49:11.258956  3463 net.cpp:122] Setting up BatchNorm38
I0927 14:49:11.258962  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.258965  3463 net.cpp:137] Memory required for data: 1007207600
I0927 14:49:11.258970  3463 layer_factory.hpp:77] Creating layer Scale38
I0927 14:49:11.258976  3463 net.cpp:84] Creating Layer Scale38
I0927 14:49:11.258980  3463 net.cpp:406] Scale38 <- Convolution38
I0927 14:49:11.258983  3463 net.cpp:367] Scale38 -> Convolution38 (in-place)
I0927 14:49:11.259012  3463 layer_factory.hpp:77] Creating layer Scale38
I0927 14:49:11.259095  3463 net.cpp:122] Setting up Scale38
I0927 14:49:11.259100  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.259102  3463 net.cpp:137] Memory required for data: 1010484400
I0927 14:49:11.259107  3463 layer_factory.hpp:77] Creating layer Eltwise18
I0927 14:49:11.259114  3463 net.cpp:84] Creating Layer Eltwise18
I0927 14:49:11.259117  3463 net.cpp:406] Eltwise18 <- Eltwise17_M2PELU35_0_split_1
I0927 14:49:11.259121  3463 net.cpp:406] Eltwise18 <- Convolution38
I0927 14:49:11.259125  3463 net.cpp:380] Eltwise18 -> Eltwise18
I0927 14:49:11.259140  3463 net.cpp:122] Setting up Eltwise18
I0927 14:49:11.259143  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.259145  3463 net.cpp:137] Memory required for data: 1013761200
I0927 14:49:11.259147  3463 layer_factory.hpp:77] Creating layer M2PELU37
I0927 14:49:11.259153  3463 net.cpp:84] Creating Layer M2PELU37
I0927 14:49:11.259156  3463 net.cpp:406] M2PELU37 <- Eltwise18
I0927 14:49:11.259160  3463 net.cpp:367] M2PELU37 -> Eltwise18 (in-place)
I0927 14:49:11.259255  3463 net.cpp:122] Setting up M2PELU37
I0927 14:49:11.259260  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.259263  3463 net.cpp:137] Memory required for data: 1017038000
I0927 14:49:11.259266  3463 layer_factory.hpp:77] Creating layer Eltwise18_M2PELU37_0_split
I0927 14:49:11.259279  3463 net.cpp:84] Creating Layer Eltwise18_M2PELU37_0_split
I0927 14:49:11.259282  3463 net.cpp:406] Eltwise18_M2PELU37_0_split <- Eltwise18
I0927 14:49:11.259285  3463 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_0
I0927 14:49:11.259290  3463 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_1
I0927 14:49:11.259317  3463 net.cpp:122] Setting up Eltwise18_M2PELU37_0_split
I0927 14:49:11.259322  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.259325  3463 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 14:49:11.259327  3463 net.cpp:137] Memory required for data: 1023591600
I0927 14:49:11.259330  3463 layer_factory.hpp:77] Creating layer Convolution39
I0927 14:49:11.259335  3463 net.cpp:84] Creating Layer Convolution39
I0927 14:49:11.259338  3463 net.cpp:406] Convolution39 <- Eltwise18_M2PELU37_0_split_0
I0927 14:49:11.259343  3463 net.cpp:380] Convolution39 -> Convolution39
I0927 14:49:11.260535  3463 net.cpp:122] Setting up Convolution39
I0927 14:49:11.260545  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.260548  3463 net.cpp:137] Memory required for data: 1025230000
I0927 14:49:11.260552  3463 layer_factory.hpp:77] Creating layer BatchNorm39
I0927 14:49:11.260557  3463 net.cpp:84] Creating Layer BatchNorm39
I0927 14:49:11.260560  3463 net.cpp:406] BatchNorm39 <- Convolution39
I0927 14:49:11.260565  3463 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I0927 14:49:11.260704  3463 net.cpp:122] Setting up BatchNorm39
I0927 14:49:11.260709  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.260711  3463 net.cpp:137] Memory required for data: 1026868400
I0927 14:49:11.260716  3463 layer_factory.hpp:77] Creating layer Scale39
I0927 14:49:11.260720  3463 net.cpp:84] Creating Layer Scale39
I0927 14:49:11.260722  3463 net.cpp:406] Scale39 <- Convolution39
I0927 14:49:11.260726  3463 net.cpp:367] Scale39 -> Convolution39 (in-place)
I0927 14:49:11.260753  3463 layer_factory.hpp:77] Creating layer Scale39
I0927 14:49:11.260833  3463 net.cpp:122] Setting up Scale39
I0927 14:49:11.260838  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.260839  3463 net.cpp:137] Memory required for data: 1028506800
I0927 14:49:11.260843  3463 layer_factory.hpp:77] Creating layer Convolution40
I0927 14:49:11.260851  3463 net.cpp:84] Creating Layer Convolution40
I0927 14:49:11.260854  3463 net.cpp:406] Convolution40 <- Eltwise18_M2PELU37_0_split_1
I0927 14:49:11.260859  3463 net.cpp:380] Convolution40 -> Convolution40
I0927 14:49:11.262255  3463 net.cpp:122] Setting up Convolution40
I0927 14:49:11.262274  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.262277  3463 net.cpp:137] Memory required for data: 1030145200
I0927 14:49:11.262282  3463 layer_factory.hpp:77] Creating layer BatchNorm40
I0927 14:49:11.262287  3463 net.cpp:84] Creating Layer BatchNorm40
I0927 14:49:11.262290  3463 net.cpp:406] BatchNorm40 <- Convolution40
I0927 14:49:11.262295  3463 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I0927 14:49:11.262441  3463 net.cpp:122] Setting up BatchNorm40
I0927 14:49:11.262446  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.262449  3463 net.cpp:137] Memory required for data: 1031783600
I0927 14:49:11.262452  3463 layer_factory.hpp:77] Creating layer Scale40
I0927 14:49:11.262456  3463 net.cpp:84] Creating Layer Scale40
I0927 14:49:11.262459  3463 net.cpp:406] Scale40 <- Convolution40
I0927 14:49:11.262464  3463 net.cpp:367] Scale40 -> Convolution40 (in-place)
I0927 14:49:11.262490  3463 layer_factory.hpp:77] Creating layer Scale40
I0927 14:49:11.262599  3463 net.cpp:122] Setting up Scale40
I0927 14:49:11.262605  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.262607  3463 net.cpp:137] Memory required for data: 1033422000
I0927 14:49:11.262611  3463 layer_factory.hpp:77] Creating layer M2PELU38
I0927 14:49:11.262616  3463 net.cpp:84] Creating Layer M2PELU38
I0927 14:49:11.262619  3463 net.cpp:406] M2PELU38 <- Convolution40
I0927 14:49:11.262629  3463 net.cpp:367] M2PELU38 -> Convolution40 (in-place)
I0927 14:49:11.262729  3463 net.cpp:122] Setting up M2PELU38
I0927 14:49:11.262734  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.262737  3463 net.cpp:137] Memory required for data: 1035060400
I0927 14:49:11.262739  3463 layer_factory.hpp:77] Creating layer Convolution41
I0927 14:49:11.262747  3463 net.cpp:84] Creating Layer Convolution41
I0927 14:49:11.262749  3463 net.cpp:406] Convolution41 <- Convolution40
I0927 14:49:11.262753  3463 net.cpp:380] Convolution41 -> Convolution41
I0927 14:49:11.264484  3463 net.cpp:122] Setting up Convolution41
I0927 14:49:11.264493  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.264495  3463 net.cpp:137] Memory required for data: 1036698800
I0927 14:49:11.264500  3463 layer_factory.hpp:77] Creating layer BatchNorm41
I0927 14:49:11.264505  3463 net.cpp:84] Creating Layer BatchNorm41
I0927 14:49:11.264508  3463 net.cpp:406] BatchNorm41 <- Convolution41
I0927 14:49:11.264513  3463 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I0927 14:49:11.264645  3463 net.cpp:122] Setting up BatchNorm41
I0927 14:49:11.264650  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.264652  3463 net.cpp:137] Memory required for data: 1038337200
I0927 14:49:11.264657  3463 layer_factory.hpp:77] Creating layer Scale41
I0927 14:49:11.264660  3463 net.cpp:84] Creating Layer Scale41
I0927 14:49:11.264663  3463 net.cpp:406] Scale41 <- Convolution41
I0927 14:49:11.264667  3463 net.cpp:367] Scale41 -> Convolution41 (in-place)
I0927 14:49:11.264694  3463 layer_factory.hpp:77] Creating layer Scale41
I0927 14:49:11.264771  3463 net.cpp:122] Setting up Scale41
I0927 14:49:11.264775  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.264777  3463 net.cpp:137] Memory required for data: 1039975600
I0927 14:49:11.264781  3463 layer_factory.hpp:77] Creating layer Eltwise19
I0927 14:49:11.264786  3463 net.cpp:84] Creating Layer Eltwise19
I0927 14:49:11.264788  3463 net.cpp:406] Eltwise19 <- Convolution39
I0927 14:49:11.264791  3463 net.cpp:406] Eltwise19 <- Convolution41
I0927 14:49:11.264794  3463 net.cpp:380] Eltwise19 -> Eltwise19
I0927 14:49:11.264811  3463 net.cpp:122] Setting up Eltwise19
I0927 14:49:11.264816  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.264817  3463 net.cpp:137] Memory required for data: 1041614000
I0927 14:49:11.264819  3463 layer_factory.hpp:77] Creating layer M2PELU39
I0927 14:49:11.264823  3463 net.cpp:84] Creating Layer M2PELU39
I0927 14:49:11.264825  3463 net.cpp:406] M2PELU39 <- Eltwise19
I0927 14:49:11.264829  3463 net.cpp:367] M2PELU39 -> Eltwise19 (in-place)
I0927 14:49:11.264920  3463 net.cpp:122] Setting up M2PELU39
I0927 14:49:11.264925  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.264927  3463 net.cpp:137] Memory required for data: 1043252400
I0927 14:49:11.264930  3463 layer_factory.hpp:77] Creating layer Eltwise19_M2PELU39_0_split
I0927 14:49:11.264935  3463 net.cpp:84] Creating Layer Eltwise19_M2PELU39_0_split
I0927 14:49:11.264937  3463 net.cpp:406] Eltwise19_M2PELU39_0_split <- Eltwise19
I0927 14:49:11.264940  3463 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_0
I0927 14:49:11.264945  3463 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_1
I0927 14:49:11.264968  3463 net.cpp:122] Setting up Eltwise19_M2PELU39_0_split
I0927 14:49:11.264972  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.264974  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.264976  3463 net.cpp:137] Memory required for data: 1046529200
I0927 14:49:11.264979  3463 layer_factory.hpp:77] Creating layer Convolution42
I0927 14:49:11.264987  3463 net.cpp:84] Creating Layer Convolution42
I0927 14:49:11.264989  3463 net.cpp:406] Convolution42 <- Eltwise19_M2PELU39_0_split_0
I0927 14:49:11.264994  3463 net.cpp:380] Convolution42 -> Convolution42
I0927 14:49:11.266731  3463 net.cpp:122] Setting up Convolution42
I0927 14:49:11.266739  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.266749  3463 net.cpp:137] Memory required for data: 1048167600
I0927 14:49:11.266754  3463 layer_factory.hpp:77] Creating layer BatchNorm42
I0927 14:49:11.266758  3463 net.cpp:84] Creating Layer BatchNorm42
I0927 14:49:11.266762  3463 net.cpp:406] BatchNorm42 <- Convolution42
I0927 14:49:11.266767  3463 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I0927 14:49:11.266901  3463 net.cpp:122] Setting up BatchNorm42
I0927 14:49:11.266906  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.266908  3463 net.cpp:137] Memory required for data: 1049806000
I0927 14:49:11.266913  3463 layer_factory.hpp:77] Creating layer Scale42
I0927 14:49:11.266916  3463 net.cpp:84] Creating Layer Scale42
I0927 14:49:11.266919  3463 net.cpp:406] Scale42 <- Convolution42
I0927 14:49:11.266923  3463 net.cpp:367] Scale42 -> Convolution42 (in-place)
I0927 14:49:11.266949  3463 layer_factory.hpp:77] Creating layer Scale42
I0927 14:49:11.267025  3463 net.cpp:122] Setting up Scale42
I0927 14:49:11.267030  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.267031  3463 net.cpp:137] Memory required for data: 1051444400
I0927 14:49:11.267035  3463 layer_factory.hpp:77] Creating layer M2PELU40
I0927 14:49:11.267040  3463 net.cpp:84] Creating Layer M2PELU40
I0927 14:49:11.267043  3463 net.cpp:406] M2PELU40 <- Convolution42
I0927 14:49:11.267046  3463 net.cpp:367] M2PELU40 -> Convolution42 (in-place)
I0927 14:49:11.267138  3463 net.cpp:122] Setting up M2PELU40
I0927 14:49:11.267143  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.267145  3463 net.cpp:137] Memory required for data: 1053082800
I0927 14:49:11.267148  3463 layer_factory.hpp:77] Creating layer Convolution43
I0927 14:49:11.267155  3463 net.cpp:84] Creating Layer Convolution43
I0927 14:49:11.267158  3463 net.cpp:406] Convolution43 <- Convolution42
I0927 14:49:11.267163  3463 net.cpp:380] Convolution43 -> Convolution43
I0927 14:49:11.268885  3463 net.cpp:122] Setting up Convolution43
I0927 14:49:11.268894  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.268896  3463 net.cpp:137] Memory required for data: 1054721200
I0927 14:49:11.268901  3463 layer_factory.hpp:77] Creating layer BatchNorm43
I0927 14:49:11.268908  3463 net.cpp:84] Creating Layer BatchNorm43
I0927 14:49:11.268910  3463 net.cpp:406] BatchNorm43 <- Convolution43
I0927 14:49:11.268913  3463 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I0927 14:49:11.269049  3463 net.cpp:122] Setting up BatchNorm43
I0927 14:49:11.269054  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.269057  3463 net.cpp:137] Memory required for data: 1056359600
I0927 14:49:11.269062  3463 layer_factory.hpp:77] Creating layer Scale43
I0927 14:49:11.269065  3463 net.cpp:84] Creating Layer Scale43
I0927 14:49:11.269068  3463 net.cpp:406] Scale43 <- Convolution43
I0927 14:49:11.269070  3463 net.cpp:367] Scale43 -> Convolution43 (in-place)
I0927 14:49:11.269098  3463 layer_factory.hpp:77] Creating layer Scale43
I0927 14:49:11.269176  3463 net.cpp:122] Setting up Scale43
I0927 14:49:11.269181  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.269182  3463 net.cpp:137] Memory required for data: 1057998000
I0927 14:49:11.269186  3463 layer_factory.hpp:77] Creating layer Eltwise20
I0927 14:49:11.269191  3463 net.cpp:84] Creating Layer Eltwise20
I0927 14:49:11.269194  3463 net.cpp:406] Eltwise20 <- Eltwise19_M2PELU39_0_split_1
I0927 14:49:11.269197  3463 net.cpp:406] Eltwise20 <- Convolution43
I0927 14:49:11.269201  3463 net.cpp:380] Eltwise20 -> Eltwise20
I0927 14:49:11.269217  3463 net.cpp:122] Setting up Eltwise20
I0927 14:49:11.269222  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.269223  3463 net.cpp:137] Memory required for data: 1059636400
I0927 14:49:11.269225  3463 layer_factory.hpp:77] Creating layer M2PELU41
I0927 14:49:11.269230  3463 net.cpp:84] Creating Layer M2PELU41
I0927 14:49:11.269232  3463 net.cpp:406] M2PELU41 <- Eltwise20
I0927 14:49:11.269235  3463 net.cpp:367] M2PELU41 -> Eltwise20 (in-place)
I0927 14:49:11.269327  3463 net.cpp:122] Setting up M2PELU41
I0927 14:49:11.269338  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.269341  3463 net.cpp:137] Memory required for data: 1061274800
I0927 14:49:11.269345  3463 layer_factory.hpp:77] Creating layer Eltwise20_M2PELU41_0_split
I0927 14:49:11.269349  3463 net.cpp:84] Creating Layer Eltwise20_M2PELU41_0_split
I0927 14:49:11.269351  3463 net.cpp:406] Eltwise20_M2PELU41_0_split <- Eltwise20
I0927 14:49:11.269356  3463 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_0
I0927 14:49:11.269359  3463 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_1
I0927 14:49:11.269385  3463 net.cpp:122] Setting up Eltwise20_M2PELU41_0_split
I0927 14:49:11.269389  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.269392  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.269394  3463 net.cpp:137] Memory required for data: 1064551600
I0927 14:49:11.269397  3463 layer_factory.hpp:77] Creating layer Convolution44
I0927 14:49:11.269402  3463 net.cpp:84] Creating Layer Convolution44
I0927 14:49:11.269405  3463 net.cpp:406] Convolution44 <- Eltwise20_M2PELU41_0_split_0
I0927 14:49:11.269409  3463 net.cpp:380] Convolution44 -> Convolution44
I0927 14:49:11.271487  3463 net.cpp:122] Setting up Convolution44
I0927 14:49:11.271497  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.271498  3463 net.cpp:137] Memory required for data: 1066190000
I0927 14:49:11.271504  3463 layer_factory.hpp:77] Creating layer BatchNorm44
I0927 14:49:11.271509  3463 net.cpp:84] Creating Layer BatchNorm44
I0927 14:49:11.271512  3463 net.cpp:406] BatchNorm44 <- Convolution44
I0927 14:49:11.271515  3463 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I0927 14:49:11.271661  3463 net.cpp:122] Setting up BatchNorm44
I0927 14:49:11.271664  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.271667  3463 net.cpp:137] Memory required for data: 1067828400
I0927 14:49:11.289232  3463 layer_factory.hpp:77] Creating layer Scale44
I0927 14:49:11.289242  3463 net.cpp:84] Creating Layer Scale44
I0927 14:49:11.289244  3463 net.cpp:406] Scale44 <- Convolution44
I0927 14:49:11.289248  3463 net.cpp:367] Scale44 -> Convolution44 (in-place)
I0927 14:49:11.289294  3463 layer_factory.hpp:77] Creating layer Scale44
I0927 14:49:11.289384  3463 net.cpp:122] Setting up Scale44
I0927 14:49:11.289391  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.289393  3463 net.cpp:137] Memory required for data: 1069466800
I0927 14:49:11.289397  3463 layer_factory.hpp:77] Creating layer M2PELU42
I0927 14:49:11.289402  3463 net.cpp:84] Creating Layer M2PELU42
I0927 14:49:11.289405  3463 net.cpp:406] M2PELU42 <- Convolution44
I0927 14:49:11.289409  3463 net.cpp:367] M2PELU42 -> Convolution44 (in-place)
I0927 14:49:11.289511  3463 net.cpp:122] Setting up M2PELU42
I0927 14:49:11.289516  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.289518  3463 net.cpp:137] Memory required for data: 1071105200
I0927 14:49:11.289522  3463 layer_factory.hpp:77] Creating layer Convolution45
I0927 14:49:11.289530  3463 net.cpp:84] Creating Layer Convolution45
I0927 14:49:11.289532  3463 net.cpp:406] Convolution45 <- Convolution44
I0927 14:49:11.289537  3463 net.cpp:380] Convolution45 -> Convolution45
I0927 14:49:11.291630  3463 net.cpp:122] Setting up Convolution45
I0927 14:49:11.291640  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.291641  3463 net.cpp:137] Memory required for data: 1072743600
I0927 14:49:11.291646  3463 layer_factory.hpp:77] Creating layer BatchNorm45
I0927 14:49:11.291653  3463 net.cpp:84] Creating Layer BatchNorm45
I0927 14:49:11.291657  3463 net.cpp:406] BatchNorm45 <- Convolution45
I0927 14:49:11.291661  3463 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I0927 14:49:11.291805  3463 net.cpp:122] Setting up BatchNorm45
I0927 14:49:11.291808  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.291810  3463 net.cpp:137] Memory required for data: 1074382000
I0927 14:49:11.291815  3463 layer_factory.hpp:77] Creating layer Scale45
I0927 14:49:11.291828  3463 net.cpp:84] Creating Layer Scale45
I0927 14:49:11.291831  3463 net.cpp:406] Scale45 <- Convolution45
I0927 14:49:11.291836  3463 net.cpp:367] Scale45 -> Convolution45 (in-place)
I0927 14:49:11.291865  3463 layer_factory.hpp:77] Creating layer Scale45
I0927 14:49:11.291946  3463 net.cpp:122] Setting up Scale45
I0927 14:49:11.291951  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.291954  3463 net.cpp:137] Memory required for data: 1076020400
I0927 14:49:11.291957  3463 layer_factory.hpp:77] Creating layer Eltwise21
I0927 14:49:11.291962  3463 net.cpp:84] Creating Layer Eltwise21
I0927 14:49:11.291965  3463 net.cpp:406] Eltwise21 <- Eltwise20_M2PELU41_0_split_1
I0927 14:49:11.291968  3463 net.cpp:406] Eltwise21 <- Convolution45
I0927 14:49:11.291972  3463 net.cpp:380] Eltwise21 -> Eltwise21
I0927 14:49:11.291990  3463 net.cpp:122] Setting up Eltwise21
I0927 14:49:11.291993  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.291996  3463 net.cpp:137] Memory required for data: 1077658800
I0927 14:49:11.291997  3463 layer_factory.hpp:77] Creating layer M2PELU43
I0927 14:49:11.292001  3463 net.cpp:84] Creating Layer M2PELU43
I0927 14:49:11.292004  3463 net.cpp:406] M2PELU43 <- Eltwise21
I0927 14:49:11.292009  3463 net.cpp:367] M2PELU43 -> Eltwise21 (in-place)
I0927 14:49:11.292102  3463 net.cpp:122] Setting up M2PELU43
I0927 14:49:11.292107  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.292109  3463 net.cpp:137] Memory required for data: 1079297200
I0927 14:49:11.292114  3463 layer_factory.hpp:77] Creating layer Eltwise21_M2PELU43_0_split
I0927 14:49:11.292119  3463 net.cpp:84] Creating Layer Eltwise21_M2PELU43_0_split
I0927 14:49:11.292120  3463 net.cpp:406] Eltwise21_M2PELU43_0_split <- Eltwise21
I0927 14:49:11.292124  3463 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_0
I0927 14:49:11.292129  3463 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_1
I0927 14:49:11.292155  3463 net.cpp:122] Setting up Eltwise21_M2PELU43_0_split
I0927 14:49:11.292158  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.292160  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.292162  3463 net.cpp:137] Memory required for data: 1082574000
I0927 14:49:11.292165  3463 layer_factory.hpp:77] Creating layer Convolution46
I0927 14:49:11.292171  3463 net.cpp:84] Creating Layer Convolution46
I0927 14:49:11.292173  3463 net.cpp:406] Convolution46 <- Eltwise21_M2PELU43_0_split_0
I0927 14:49:11.292178  3463 net.cpp:380] Convolution46 -> Convolution46
I0927 14:49:11.293937  3463 net.cpp:122] Setting up Convolution46
I0927 14:49:11.293946  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.293949  3463 net.cpp:137] Memory required for data: 1084212400
I0927 14:49:11.293954  3463 layer_factory.hpp:77] Creating layer BatchNorm46
I0927 14:49:11.293958  3463 net.cpp:84] Creating Layer BatchNorm46
I0927 14:49:11.293962  3463 net.cpp:406] BatchNorm46 <- Convolution46
I0927 14:49:11.293967  3463 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I0927 14:49:11.294111  3463 net.cpp:122] Setting up BatchNorm46
I0927 14:49:11.294116  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.294118  3463 net.cpp:137] Memory required for data: 1085850800
I0927 14:49:11.294123  3463 layer_factory.hpp:77] Creating layer Scale46
I0927 14:49:11.294127  3463 net.cpp:84] Creating Layer Scale46
I0927 14:49:11.294129  3463 net.cpp:406] Scale46 <- Convolution46
I0927 14:49:11.294133  3463 net.cpp:367] Scale46 -> Convolution46 (in-place)
I0927 14:49:11.294162  3463 layer_factory.hpp:77] Creating layer Scale46
I0927 14:49:11.294244  3463 net.cpp:122] Setting up Scale46
I0927 14:49:11.294248  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.294250  3463 net.cpp:137] Memory required for data: 1087489200
I0927 14:49:11.294255  3463 layer_factory.hpp:77] Creating layer M2PELU44
I0927 14:49:11.294260  3463 net.cpp:84] Creating Layer M2PELU44
I0927 14:49:11.294261  3463 net.cpp:406] M2PELU44 <- Convolution46
I0927 14:49:11.294272  3463 net.cpp:367] M2PELU44 -> Convolution46 (in-place)
I0927 14:49:11.294369  3463 net.cpp:122] Setting up M2PELU44
I0927 14:49:11.294374  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.294376  3463 net.cpp:137] Memory required for data: 1089127600
I0927 14:49:11.294380  3463 layer_factory.hpp:77] Creating layer Convolution47
I0927 14:49:11.294389  3463 net.cpp:84] Creating Layer Convolution47
I0927 14:49:11.294390  3463 net.cpp:406] Convolution47 <- Convolution46
I0927 14:49:11.294394  3463 net.cpp:380] Convolution47 -> Convolution47
I0927 14:49:11.296144  3463 net.cpp:122] Setting up Convolution47
I0927 14:49:11.296152  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.296155  3463 net.cpp:137] Memory required for data: 1090766000
I0927 14:49:11.296160  3463 layer_factory.hpp:77] Creating layer BatchNorm47
I0927 14:49:11.296166  3463 net.cpp:84] Creating Layer BatchNorm47
I0927 14:49:11.296169  3463 net.cpp:406] BatchNorm47 <- Convolution47
I0927 14:49:11.296174  3463 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I0927 14:49:11.296308  3463 net.cpp:122] Setting up BatchNorm47
I0927 14:49:11.296313  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.296315  3463 net.cpp:137] Memory required for data: 1092404400
I0927 14:49:11.296319  3463 layer_factory.hpp:77] Creating layer Scale47
I0927 14:49:11.296324  3463 net.cpp:84] Creating Layer Scale47
I0927 14:49:11.296327  3463 net.cpp:406] Scale47 <- Convolution47
I0927 14:49:11.296330  3463 net.cpp:367] Scale47 -> Convolution47 (in-place)
I0927 14:49:11.296357  3463 layer_factory.hpp:77] Creating layer Scale47
I0927 14:49:11.296435  3463 net.cpp:122] Setting up Scale47
I0927 14:49:11.296439  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.296442  3463 net.cpp:137] Memory required for data: 1094042800
I0927 14:49:11.296447  3463 layer_factory.hpp:77] Creating layer Eltwise22
I0927 14:49:11.296450  3463 net.cpp:84] Creating Layer Eltwise22
I0927 14:49:11.296453  3463 net.cpp:406] Eltwise22 <- Eltwise21_M2PELU43_0_split_1
I0927 14:49:11.296456  3463 net.cpp:406] Eltwise22 <- Convolution47
I0927 14:49:11.296460  3463 net.cpp:380] Eltwise22 -> Eltwise22
I0927 14:49:11.296478  3463 net.cpp:122] Setting up Eltwise22
I0927 14:49:11.296480  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.296483  3463 net.cpp:137] Memory required for data: 1095681200
I0927 14:49:11.296484  3463 layer_factory.hpp:77] Creating layer M2PELU45
I0927 14:49:11.296489  3463 net.cpp:84] Creating Layer M2PELU45
I0927 14:49:11.296492  3463 net.cpp:406] M2PELU45 <- Eltwise22
I0927 14:49:11.296495  3463 net.cpp:367] M2PELU45 -> Eltwise22 (in-place)
I0927 14:49:11.296586  3463 net.cpp:122] Setting up M2PELU45
I0927 14:49:11.296591  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.296593  3463 net.cpp:137] Memory required for data: 1097319600
I0927 14:49:11.296597  3463 layer_factory.hpp:77] Creating layer Eltwise22_M2PELU45_0_split
I0927 14:49:11.296600  3463 net.cpp:84] Creating Layer Eltwise22_M2PELU45_0_split
I0927 14:49:11.296603  3463 net.cpp:406] Eltwise22_M2PELU45_0_split <- Eltwise22
I0927 14:49:11.296607  3463 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_0
I0927 14:49:11.296612  3463 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_1
I0927 14:49:11.296635  3463 net.cpp:122] Setting up Eltwise22_M2PELU45_0_split
I0927 14:49:11.296639  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.296641  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.296643  3463 net.cpp:137] Memory required for data: 1100596400
I0927 14:49:11.296645  3463 layer_factory.hpp:77] Creating layer Convolution48
I0927 14:49:11.296653  3463 net.cpp:84] Creating Layer Convolution48
I0927 14:49:11.296654  3463 net.cpp:406] Convolution48 <- Eltwise22_M2PELU45_0_split_0
I0927 14:49:11.296658  3463 net.cpp:380] Convolution48 -> Convolution48
I0927 14:49:11.298722  3463 net.cpp:122] Setting up Convolution48
I0927 14:49:11.298732  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.298740  3463 net.cpp:137] Memory required for data: 1102234800
I0927 14:49:11.298745  3463 layer_factory.hpp:77] Creating layer BatchNorm48
I0927 14:49:11.298753  3463 net.cpp:84] Creating Layer BatchNorm48
I0927 14:49:11.298755  3463 net.cpp:406] BatchNorm48 <- Convolution48
I0927 14:49:11.298759  3463 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I0927 14:49:11.298913  3463 net.cpp:122] Setting up BatchNorm48
I0927 14:49:11.298918  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.298920  3463 net.cpp:137] Memory required for data: 1103873200
I0927 14:49:11.298925  3463 layer_factory.hpp:77] Creating layer Scale48
I0927 14:49:11.298930  3463 net.cpp:84] Creating Layer Scale48
I0927 14:49:11.298933  3463 net.cpp:406] Scale48 <- Convolution48
I0927 14:49:11.298936  3463 net.cpp:367] Scale48 -> Convolution48 (in-place)
I0927 14:49:11.298965  3463 layer_factory.hpp:77] Creating layer Scale48
I0927 14:49:11.299047  3463 net.cpp:122] Setting up Scale48
I0927 14:49:11.299052  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.299054  3463 net.cpp:137] Memory required for data: 1105511600
I0927 14:49:11.299058  3463 layer_factory.hpp:77] Creating layer M2PELU46
I0927 14:49:11.299063  3463 net.cpp:84] Creating Layer M2PELU46
I0927 14:49:11.299067  3463 net.cpp:406] M2PELU46 <- Convolution48
I0927 14:49:11.299070  3463 net.cpp:367] M2PELU46 -> Convolution48 (in-place)
I0927 14:49:11.299162  3463 net.cpp:122] Setting up M2PELU46
I0927 14:49:11.299167  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.299170  3463 net.cpp:137] Memory required for data: 1107150000
I0927 14:49:11.299173  3463 layer_factory.hpp:77] Creating layer Convolution49
I0927 14:49:11.299180  3463 net.cpp:84] Creating Layer Convolution49
I0927 14:49:11.299182  3463 net.cpp:406] Convolution49 <- Convolution48
I0927 14:49:11.299187  3463 net.cpp:380] Convolution49 -> Convolution49
I0927 14:49:11.301298  3463 net.cpp:122] Setting up Convolution49
I0927 14:49:11.301307  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.301311  3463 net.cpp:137] Memory required for data: 1108788400
I0927 14:49:11.301314  3463 layer_factory.hpp:77] Creating layer BatchNorm49
I0927 14:49:11.301319  3463 net.cpp:84] Creating Layer BatchNorm49
I0927 14:49:11.301322  3463 net.cpp:406] BatchNorm49 <- Convolution49
I0927 14:49:11.301327  3463 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I0927 14:49:11.301465  3463 net.cpp:122] Setting up BatchNorm49
I0927 14:49:11.301470  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.301471  3463 net.cpp:137] Memory required for data: 1110426800
I0927 14:49:11.301476  3463 layer_factory.hpp:77] Creating layer Scale49
I0927 14:49:11.301481  3463 net.cpp:84] Creating Layer Scale49
I0927 14:49:11.301483  3463 net.cpp:406] Scale49 <- Convolution49
I0927 14:49:11.301486  3463 net.cpp:367] Scale49 -> Convolution49 (in-place)
I0927 14:49:11.301514  3463 layer_factory.hpp:77] Creating layer Scale49
I0927 14:49:11.301597  3463 net.cpp:122] Setting up Scale49
I0927 14:49:11.301602  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.301604  3463 net.cpp:137] Memory required for data: 1112065200
I0927 14:49:11.301609  3463 layer_factory.hpp:77] Creating layer Eltwise23
I0927 14:49:11.301611  3463 net.cpp:84] Creating Layer Eltwise23
I0927 14:49:11.301614  3463 net.cpp:406] Eltwise23 <- Eltwise22_M2PELU45_0_split_1
I0927 14:49:11.301617  3463 net.cpp:406] Eltwise23 <- Convolution49
I0927 14:49:11.301621  3463 net.cpp:380] Eltwise23 -> Eltwise23
I0927 14:49:11.301638  3463 net.cpp:122] Setting up Eltwise23
I0927 14:49:11.301642  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.301645  3463 net.cpp:137] Memory required for data: 1113703600
I0927 14:49:11.301646  3463 layer_factory.hpp:77] Creating layer M2PELU47
I0927 14:49:11.301651  3463 net.cpp:84] Creating Layer M2PELU47
I0927 14:49:11.301654  3463 net.cpp:406] M2PELU47 <- Eltwise23
I0927 14:49:11.301657  3463 net.cpp:367] M2PELU47 -> Eltwise23 (in-place)
I0927 14:49:11.301759  3463 net.cpp:122] Setting up M2PELU47
I0927 14:49:11.301764  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.301765  3463 net.cpp:137] Memory required for data: 1115342000
I0927 14:49:11.301769  3463 layer_factory.hpp:77] Creating layer Eltwise23_M2PELU47_0_split
I0927 14:49:11.301774  3463 net.cpp:84] Creating Layer Eltwise23_M2PELU47_0_split
I0927 14:49:11.301776  3463 net.cpp:406] Eltwise23_M2PELU47_0_split <- Eltwise23
I0927 14:49:11.301779  3463 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_0
I0927 14:49:11.301784  3463 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_1
I0927 14:49:11.301808  3463 net.cpp:122] Setting up Eltwise23_M2PELU47_0_split
I0927 14:49:11.301812  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.301815  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.301816  3463 net.cpp:137] Memory required for data: 1118618800
I0927 14:49:11.301820  3463 layer_factory.hpp:77] Creating layer Convolution50
I0927 14:49:11.301826  3463 net.cpp:84] Creating Layer Convolution50
I0927 14:49:11.301828  3463 net.cpp:406] Convolution50 <- Eltwise23_M2PELU47_0_split_0
I0927 14:49:11.301831  3463 net.cpp:380] Convolution50 -> Convolution50
I0927 14:49:11.304450  3463 net.cpp:122] Setting up Convolution50
I0927 14:49:11.304458  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.304461  3463 net.cpp:137] Memory required for data: 1120257200
I0927 14:49:11.304466  3463 layer_factory.hpp:77] Creating layer BatchNorm50
I0927 14:49:11.304471  3463 net.cpp:84] Creating Layer BatchNorm50
I0927 14:49:11.304474  3463 net.cpp:406] BatchNorm50 <- Convolution50
I0927 14:49:11.304478  3463 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I0927 14:49:11.319854  3463 net.cpp:122] Setting up BatchNorm50
I0927 14:49:11.319862  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.319865  3463 net.cpp:137] Memory required for data: 1121895600
I0927 14:49:11.319870  3463 layer_factory.hpp:77] Creating layer Scale50
I0927 14:49:11.319875  3463 net.cpp:84] Creating Layer Scale50
I0927 14:49:11.319878  3463 net.cpp:406] Scale50 <- Convolution50
I0927 14:49:11.319883  3463 net.cpp:367] Scale50 -> Convolution50 (in-place)
I0927 14:49:11.319913  3463 layer_factory.hpp:77] Creating layer Scale50
I0927 14:49:11.319996  3463 net.cpp:122] Setting up Scale50
I0927 14:49:11.320001  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.320003  3463 net.cpp:137] Memory required for data: 1123534000
I0927 14:49:11.320008  3463 layer_factory.hpp:77] Creating layer M2PELU48
I0927 14:49:11.320013  3463 net.cpp:84] Creating Layer M2PELU48
I0927 14:49:11.320015  3463 net.cpp:406] M2PELU48 <- Convolution50
I0927 14:49:11.320019  3463 net.cpp:367] M2PELU48 -> Convolution50 (in-place)
I0927 14:49:11.320113  3463 net.cpp:122] Setting up M2PELU48
I0927 14:49:11.320118  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.320121  3463 net.cpp:137] Memory required for data: 1125172400
I0927 14:49:11.320124  3463 layer_factory.hpp:77] Creating layer Convolution51
I0927 14:49:11.320132  3463 net.cpp:84] Creating Layer Convolution51
I0927 14:49:11.320133  3463 net.cpp:406] Convolution51 <- Convolution50
I0927 14:49:11.320138  3463 net.cpp:380] Convolution51 -> Convolution51
I0927 14:49:11.322156  3463 net.cpp:122] Setting up Convolution51
I0927 14:49:11.322165  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.322167  3463 net.cpp:137] Memory required for data: 1126810800
I0927 14:49:11.322172  3463 layer_factory.hpp:77] Creating layer BatchNorm51
I0927 14:49:11.322178  3463 net.cpp:84] Creating Layer BatchNorm51
I0927 14:49:11.322181  3463 net.cpp:406] BatchNorm51 <- Convolution51
I0927 14:49:11.322185  3463 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I0927 14:49:11.322327  3463 net.cpp:122] Setting up BatchNorm51
I0927 14:49:11.322331  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.322335  3463 net.cpp:137] Memory required for data: 1128449200
I0927 14:49:11.322346  3463 layer_factory.hpp:77] Creating layer Scale51
I0927 14:49:11.322351  3463 net.cpp:84] Creating Layer Scale51
I0927 14:49:11.322355  3463 net.cpp:406] Scale51 <- Convolution51
I0927 14:49:11.322357  3463 net.cpp:367] Scale51 -> Convolution51 (in-place)
I0927 14:49:11.322388  3463 layer_factory.hpp:77] Creating layer Scale51
I0927 14:49:11.322469  3463 net.cpp:122] Setting up Scale51
I0927 14:49:11.322474  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.322475  3463 net.cpp:137] Memory required for data: 1130087600
I0927 14:49:11.322479  3463 layer_factory.hpp:77] Creating layer Eltwise24
I0927 14:49:11.322484  3463 net.cpp:84] Creating Layer Eltwise24
I0927 14:49:11.322487  3463 net.cpp:406] Eltwise24 <- Eltwise23_M2PELU47_0_split_1
I0927 14:49:11.322490  3463 net.cpp:406] Eltwise24 <- Convolution51
I0927 14:49:11.322494  3463 net.cpp:380] Eltwise24 -> Eltwise24
I0927 14:49:11.322510  3463 net.cpp:122] Setting up Eltwise24
I0927 14:49:11.322515  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.322516  3463 net.cpp:137] Memory required for data: 1131726000
I0927 14:49:11.322518  3463 layer_factory.hpp:77] Creating layer M2PELU49
I0927 14:49:11.322533  3463 net.cpp:84] Creating Layer M2PELU49
I0927 14:49:11.322536  3463 net.cpp:406] M2PELU49 <- Eltwise24
I0927 14:49:11.322540  3463 net.cpp:367] M2PELU49 -> Eltwise24 (in-place)
I0927 14:49:11.322638  3463 net.cpp:122] Setting up M2PELU49
I0927 14:49:11.322643  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.322644  3463 net.cpp:137] Memory required for data: 1133364400
I0927 14:49:11.322649  3463 layer_factory.hpp:77] Creating layer Eltwise24_M2PELU49_0_split
I0927 14:49:11.322652  3463 net.cpp:84] Creating Layer Eltwise24_M2PELU49_0_split
I0927 14:49:11.322654  3463 net.cpp:406] Eltwise24_M2PELU49_0_split <- Eltwise24
I0927 14:49:11.322659  3463 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_0
I0927 14:49:11.322662  3463 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_1
I0927 14:49:11.322701  3463 net.cpp:122] Setting up Eltwise24_M2PELU49_0_split
I0927 14:49:11.322705  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.322710  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.322711  3463 net.cpp:137] Memory required for data: 1136641200
I0927 14:49:11.322713  3463 layer_factory.hpp:77] Creating layer Convolution52
I0927 14:49:11.322720  3463 net.cpp:84] Creating Layer Convolution52
I0927 14:49:11.322722  3463 net.cpp:406] Convolution52 <- Eltwise24_M2PELU49_0_split_0
I0927 14:49:11.322726  3463 net.cpp:380] Convolution52 -> Convolution52
I0927 14:49:11.324877  3463 net.cpp:122] Setting up Convolution52
I0927 14:49:11.324887  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.324888  3463 net.cpp:137] Memory required for data: 1138279600
I0927 14:49:11.324893  3463 layer_factory.hpp:77] Creating layer BatchNorm52
I0927 14:49:11.324899  3463 net.cpp:84] Creating Layer BatchNorm52
I0927 14:49:11.324903  3463 net.cpp:406] BatchNorm52 <- Convolution52
I0927 14:49:11.324905  3463 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I0927 14:49:11.325053  3463 net.cpp:122] Setting up BatchNorm52
I0927 14:49:11.325058  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.325060  3463 net.cpp:137] Memory required for data: 1139918000
I0927 14:49:11.325065  3463 layer_factory.hpp:77] Creating layer Scale52
I0927 14:49:11.325068  3463 net.cpp:84] Creating Layer Scale52
I0927 14:49:11.325072  3463 net.cpp:406] Scale52 <- Convolution52
I0927 14:49:11.325074  3463 net.cpp:367] Scale52 -> Convolution52 (in-place)
I0927 14:49:11.325104  3463 layer_factory.hpp:77] Creating layer Scale52
I0927 14:49:11.325187  3463 net.cpp:122] Setting up Scale52
I0927 14:49:11.325193  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.325196  3463 net.cpp:137] Memory required for data: 1141556400
I0927 14:49:11.325199  3463 layer_factory.hpp:77] Creating layer M2PELU50
I0927 14:49:11.325219  3463 net.cpp:84] Creating Layer M2PELU50
I0927 14:49:11.325229  3463 net.cpp:406] M2PELU50 <- Convolution52
I0927 14:49:11.325234  3463 net.cpp:367] M2PELU50 -> Convolution52 (in-place)
I0927 14:49:11.325333  3463 net.cpp:122] Setting up M2PELU50
I0927 14:49:11.325338  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.325340  3463 net.cpp:137] Memory required for data: 1143194800
I0927 14:49:11.325345  3463 layer_factory.hpp:77] Creating layer Convolution53
I0927 14:49:11.325351  3463 net.cpp:84] Creating Layer Convolution53
I0927 14:49:11.325354  3463 net.cpp:406] Convolution53 <- Convolution52
I0927 14:49:11.325358  3463 net.cpp:380] Convolution53 -> Convolution53
I0927 14:49:11.327111  3463 net.cpp:122] Setting up Convolution53
I0927 14:49:11.327121  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.327122  3463 net.cpp:137] Memory required for data: 1144833200
I0927 14:49:11.327127  3463 layer_factory.hpp:77] Creating layer BatchNorm53
I0927 14:49:11.327133  3463 net.cpp:84] Creating Layer BatchNorm53
I0927 14:49:11.327136  3463 net.cpp:406] BatchNorm53 <- Convolution53
I0927 14:49:11.327139  3463 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I0927 14:49:11.327281  3463 net.cpp:122] Setting up BatchNorm53
I0927 14:49:11.327286  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.327287  3463 net.cpp:137] Memory required for data: 1146471600
I0927 14:49:11.327292  3463 layer_factory.hpp:77] Creating layer Scale53
I0927 14:49:11.327296  3463 net.cpp:84] Creating Layer Scale53
I0927 14:49:11.327299  3463 net.cpp:406] Scale53 <- Convolution53
I0927 14:49:11.327302  3463 net.cpp:367] Scale53 -> Convolution53 (in-place)
I0927 14:49:11.327330  3463 layer_factory.hpp:77] Creating layer Scale53
I0927 14:49:11.327411  3463 net.cpp:122] Setting up Scale53
I0927 14:49:11.327415  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.327417  3463 net.cpp:137] Memory required for data: 1148110000
I0927 14:49:11.327421  3463 layer_factory.hpp:77] Creating layer Eltwise25
I0927 14:49:11.327425  3463 net.cpp:84] Creating Layer Eltwise25
I0927 14:49:11.327428  3463 net.cpp:406] Eltwise25 <- Eltwise24_M2PELU49_0_split_1
I0927 14:49:11.327431  3463 net.cpp:406] Eltwise25 <- Convolution53
I0927 14:49:11.327435  3463 net.cpp:380] Eltwise25 -> Eltwise25
I0927 14:49:11.327453  3463 net.cpp:122] Setting up Eltwise25
I0927 14:49:11.327457  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.327460  3463 net.cpp:137] Memory required for data: 1149748400
I0927 14:49:11.327461  3463 layer_factory.hpp:77] Creating layer M2PELU51
I0927 14:49:11.327466  3463 net.cpp:84] Creating Layer M2PELU51
I0927 14:49:11.327469  3463 net.cpp:406] M2PELU51 <- Eltwise25
I0927 14:49:11.327472  3463 net.cpp:367] M2PELU51 -> Eltwise25 (in-place)
I0927 14:49:11.327566  3463 net.cpp:122] Setting up M2PELU51
I0927 14:49:11.327572  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.327574  3463 net.cpp:137] Memory required for data: 1151386800
I0927 14:49:11.327579  3463 layer_factory.hpp:77] Creating layer Eltwise25_M2PELU51_0_split
I0927 14:49:11.327582  3463 net.cpp:84] Creating Layer Eltwise25_M2PELU51_0_split
I0927 14:49:11.327584  3463 net.cpp:406] Eltwise25_M2PELU51_0_split <- Eltwise25
I0927 14:49:11.327587  3463 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_0
I0927 14:49:11.327591  3463 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_1
I0927 14:49:11.327617  3463 net.cpp:122] Setting up Eltwise25_M2PELU51_0_split
I0927 14:49:11.327621  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.327625  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.327626  3463 net.cpp:137] Memory required for data: 1154663600
I0927 14:49:11.327628  3463 layer_factory.hpp:77] Creating layer Convolution54
I0927 14:49:11.327635  3463 net.cpp:84] Creating Layer Convolution54
I0927 14:49:11.327636  3463 net.cpp:406] Convolution54 <- Eltwise25_M2PELU51_0_split_0
I0927 14:49:11.327641  3463 net.cpp:380] Convolution54 -> Convolution54
I0927 14:49:11.329697  3463 net.cpp:122] Setting up Convolution54
I0927 14:49:11.329712  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.329715  3463 net.cpp:137] Memory required for data: 1156302000
I0927 14:49:11.329721  3463 layer_factory.hpp:77] Creating layer BatchNorm54
I0927 14:49:11.329726  3463 net.cpp:84] Creating Layer BatchNorm54
I0927 14:49:11.329730  3463 net.cpp:406] BatchNorm54 <- Convolution54
I0927 14:49:11.329733  3463 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I0927 14:49:11.329882  3463 net.cpp:122] Setting up BatchNorm54
I0927 14:49:11.329887  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.329890  3463 net.cpp:137] Memory required for data: 1157940400
I0927 14:49:11.329895  3463 layer_factory.hpp:77] Creating layer Scale54
I0927 14:49:11.329898  3463 net.cpp:84] Creating Layer Scale54
I0927 14:49:11.329900  3463 net.cpp:406] Scale54 <- Convolution54
I0927 14:49:11.329903  3463 net.cpp:367] Scale54 -> Convolution54 (in-place)
I0927 14:49:11.329933  3463 layer_factory.hpp:77] Creating layer Scale54
I0927 14:49:11.330015  3463 net.cpp:122] Setting up Scale54
I0927 14:49:11.330020  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.330023  3463 net.cpp:137] Memory required for data: 1159578800
I0927 14:49:11.330026  3463 layer_factory.hpp:77] Creating layer M2PELU52
I0927 14:49:11.330030  3463 net.cpp:84] Creating Layer M2PELU52
I0927 14:49:11.330034  3463 net.cpp:406] M2PELU52 <- Convolution54
I0927 14:49:11.330037  3463 net.cpp:367] M2PELU52 -> Convolution54 (in-place)
I0927 14:49:11.330132  3463 net.cpp:122] Setting up M2PELU52
I0927 14:49:11.330137  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.330139  3463 net.cpp:137] Memory required for data: 1161217200
I0927 14:49:11.330143  3463 layer_factory.hpp:77] Creating layer Convolution55
I0927 14:49:11.330150  3463 net.cpp:84] Creating Layer Convolution55
I0927 14:49:11.330154  3463 net.cpp:406] Convolution55 <- Convolution54
I0927 14:49:11.330158  3463 net.cpp:380] Convolution55 -> Convolution55
I0927 14:49:11.331912  3463 net.cpp:122] Setting up Convolution55
I0927 14:49:11.331921  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.331923  3463 net.cpp:137] Memory required for data: 1162855600
I0927 14:49:11.331928  3463 layer_factory.hpp:77] Creating layer BatchNorm55
I0927 14:49:11.331933  3463 net.cpp:84] Creating Layer BatchNorm55
I0927 14:49:11.331936  3463 net.cpp:406] BatchNorm55 <- Convolution55
I0927 14:49:11.331940  3463 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I0927 14:49:11.332084  3463 net.cpp:122] Setting up BatchNorm55
I0927 14:49:11.332088  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.332090  3463 net.cpp:137] Memory required for data: 1164494000
I0927 14:49:11.332095  3463 layer_factory.hpp:77] Creating layer Scale55
I0927 14:49:11.332100  3463 net.cpp:84] Creating Layer Scale55
I0927 14:49:11.332103  3463 net.cpp:406] Scale55 <- Convolution55
I0927 14:49:11.332106  3463 net.cpp:367] Scale55 -> Convolution55 (in-place)
I0927 14:49:11.332135  3463 layer_factory.hpp:77] Creating layer Scale55
I0927 14:49:11.332218  3463 net.cpp:122] Setting up Scale55
I0927 14:49:11.332222  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.332224  3463 net.cpp:137] Memory required for data: 1166132400
I0927 14:49:11.332228  3463 layer_factory.hpp:77] Creating layer Eltwise26
I0927 14:49:11.332235  3463 net.cpp:84] Creating Layer Eltwise26
I0927 14:49:11.332238  3463 net.cpp:406] Eltwise26 <- Eltwise25_M2PELU51_0_split_1
I0927 14:49:11.332242  3463 net.cpp:406] Eltwise26 <- Convolution55
I0927 14:49:11.332245  3463 net.cpp:380] Eltwise26 -> Eltwise26
I0927 14:49:11.332262  3463 net.cpp:122] Setting up Eltwise26
I0927 14:49:11.332267  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.332268  3463 net.cpp:137] Memory required for data: 1167770800
I0927 14:49:11.332270  3463 layer_factory.hpp:77] Creating layer M2PELU53
I0927 14:49:11.332275  3463 net.cpp:84] Creating Layer M2PELU53
I0927 14:49:11.332278  3463 net.cpp:406] M2PELU53 <- Eltwise26
I0927 14:49:11.332288  3463 net.cpp:367] M2PELU53 -> Eltwise26 (in-place)
I0927 14:49:11.332386  3463 net.cpp:122] Setting up M2PELU53
I0927 14:49:11.332391  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.332392  3463 net.cpp:137] Memory required for data: 1169409200
I0927 14:49:11.332396  3463 layer_factory.hpp:77] Creating layer Eltwise26_M2PELU53_0_split
I0927 14:49:11.332399  3463 net.cpp:84] Creating Layer Eltwise26_M2PELU53_0_split
I0927 14:49:11.332402  3463 net.cpp:406] Eltwise26_M2PELU53_0_split <- Eltwise26
I0927 14:49:11.332406  3463 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_0
I0927 14:49:11.332411  3463 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_1
I0927 14:49:11.332437  3463 net.cpp:122] Setting up Eltwise26_M2PELU53_0_split
I0927 14:49:11.332439  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.332442  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.332444  3463 net.cpp:137] Memory required for data: 1172686000
I0927 14:49:11.332446  3463 layer_factory.hpp:77] Creating layer Convolution56
I0927 14:49:11.332453  3463 net.cpp:84] Creating Layer Convolution56
I0927 14:49:11.332455  3463 net.cpp:406] Convolution56 <- Eltwise26_M2PELU53_0_split_0
I0927 14:49:11.332459  3463 net.cpp:380] Convolution56 -> Convolution56
I0927 14:49:11.334184  3463 net.cpp:122] Setting up Convolution56
I0927 14:49:11.334194  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.334197  3463 net.cpp:137] Memory required for data: 1174324400
I0927 14:49:11.334201  3463 layer_factory.hpp:77] Creating layer BatchNorm56
I0927 14:49:11.350106  3463 net.cpp:84] Creating Layer BatchNorm56
I0927 14:49:11.350114  3463 net.cpp:406] BatchNorm56 <- Convolution56
I0927 14:49:11.350121  3463 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I0927 14:49:11.350292  3463 net.cpp:122] Setting up BatchNorm56
I0927 14:49:11.350298  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.350301  3463 net.cpp:137] Memory required for data: 1175962800
I0927 14:49:11.350306  3463 layer_factory.hpp:77] Creating layer Scale56
I0927 14:49:11.350311  3463 net.cpp:84] Creating Layer Scale56
I0927 14:49:11.350313  3463 net.cpp:406] Scale56 <- Convolution56
I0927 14:49:11.350318  3463 net.cpp:367] Scale56 -> Convolution56 (in-place)
I0927 14:49:11.350349  3463 layer_factory.hpp:77] Creating layer Scale56
I0927 14:49:11.350440  3463 net.cpp:122] Setting up Scale56
I0927 14:49:11.350443  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.350446  3463 net.cpp:137] Memory required for data: 1177601200
I0927 14:49:11.350450  3463 layer_factory.hpp:77] Creating layer M2PELU54
I0927 14:49:11.350455  3463 net.cpp:84] Creating Layer M2PELU54
I0927 14:49:11.350457  3463 net.cpp:406] M2PELU54 <- Convolution56
I0927 14:49:11.350462  3463 net.cpp:367] M2PELU54 -> Convolution56 (in-place)
I0927 14:49:11.350576  3463 net.cpp:122] Setting up M2PELU54
I0927 14:49:11.350582  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.350584  3463 net.cpp:137] Memory required for data: 1179239600
I0927 14:49:11.350589  3463 layer_factory.hpp:77] Creating layer Convolution57
I0927 14:49:11.350596  3463 net.cpp:84] Creating Layer Convolution57
I0927 14:49:11.350600  3463 net.cpp:406] Convolution57 <- Convolution56
I0927 14:49:11.350603  3463 net.cpp:380] Convolution57 -> Convolution57
I0927 14:49:11.352687  3463 net.cpp:122] Setting up Convolution57
I0927 14:49:11.352697  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.352700  3463 net.cpp:137] Memory required for data: 1180878000
I0927 14:49:11.352705  3463 layer_factory.hpp:77] Creating layer BatchNorm57
I0927 14:49:11.352710  3463 net.cpp:84] Creating Layer BatchNorm57
I0927 14:49:11.352713  3463 net.cpp:406] BatchNorm57 <- Convolution57
I0927 14:49:11.352717  3463 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I0927 14:49:11.352869  3463 net.cpp:122] Setting up BatchNorm57
I0927 14:49:11.352874  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.352875  3463 net.cpp:137] Memory required for data: 1182516400
I0927 14:49:11.352888  3463 layer_factory.hpp:77] Creating layer Scale57
I0927 14:49:11.352893  3463 net.cpp:84] Creating Layer Scale57
I0927 14:49:11.352896  3463 net.cpp:406] Scale57 <- Convolution57
I0927 14:49:11.352900  3463 net.cpp:367] Scale57 -> Convolution57 (in-place)
I0927 14:49:11.352933  3463 layer_factory.hpp:77] Creating layer Scale57
I0927 14:49:11.353020  3463 net.cpp:122] Setting up Scale57
I0927 14:49:11.353024  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.353026  3463 net.cpp:137] Memory required for data: 1184154800
I0927 14:49:11.353030  3463 layer_factory.hpp:77] Creating layer Eltwise27
I0927 14:49:11.353035  3463 net.cpp:84] Creating Layer Eltwise27
I0927 14:49:11.353039  3463 net.cpp:406] Eltwise27 <- Eltwise26_M2PELU53_0_split_1
I0927 14:49:11.353041  3463 net.cpp:406] Eltwise27 <- Convolution57
I0927 14:49:11.353045  3463 net.cpp:380] Eltwise27 -> Eltwise27
I0927 14:49:11.353062  3463 net.cpp:122] Setting up Eltwise27
I0927 14:49:11.353066  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.353068  3463 net.cpp:137] Memory required for data: 1185793200
I0927 14:49:11.353070  3463 layer_factory.hpp:77] Creating layer M2PELU55
I0927 14:49:11.353076  3463 net.cpp:84] Creating Layer M2PELU55
I0927 14:49:11.353078  3463 net.cpp:406] M2PELU55 <- Eltwise27
I0927 14:49:11.353082  3463 net.cpp:367] M2PELU55 -> Eltwise27 (in-place)
I0927 14:49:11.353181  3463 net.cpp:122] Setting up M2PELU55
I0927 14:49:11.353186  3463 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 14:49:11.353188  3463 net.cpp:137] Memory required for data: 1187431600
I0927 14:49:11.353193  3463 layer_factory.hpp:77] Creating layer Pooling1
I0927 14:49:11.353197  3463 net.cpp:84] Creating Layer Pooling1
I0927 14:49:11.353200  3463 net.cpp:406] Pooling1 <- Eltwise27
I0927 14:49:11.353204  3463 net.cpp:380] Pooling1 -> Pooling1
I0927 14:49:11.353775  3463 net.cpp:122] Setting up Pooling1
I0927 14:49:11.353796  3463 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0927 14:49:11.353799  3463 net.cpp:137] Memory required for data: 1187457200
I0927 14:49:11.353802  3463 layer_factory.hpp:77] Creating layer InnerProduct1
I0927 14:49:11.353808  3463 net.cpp:84] Creating Layer InnerProduct1
I0927 14:49:11.353811  3463 net.cpp:406] InnerProduct1 <- Pooling1
I0927 14:49:11.353816  3463 net.cpp:380] InnerProduct1 -> InnerProduct1
I0927 14:49:11.353935  3463 net.cpp:122] Setting up InnerProduct1
I0927 14:49:11.353940  3463 net.cpp:129] Top shape: 100 10 (1000)
I0927 14:49:11.353941  3463 net.cpp:137] Memory required for data: 1187461200
I0927 14:49:11.353945  3463 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0927 14:49:11.353950  3463 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I0927 14:49:11.353952  3463 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0927 14:49:11.353956  3463 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0927 14:49:11.353961  3463 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0927 14:49:11.353989  3463 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I0927 14:49:11.353992  3463 net.cpp:129] Top shape: 100 10 (1000)
I0927 14:49:11.353996  3463 net.cpp:129] Top shape: 100 10 (1000)
I0927 14:49:11.353997  3463 net.cpp:137] Memory required for data: 1187469200
I0927 14:49:11.353999  3463 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0927 14:49:11.354004  3463 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0927 14:49:11.354007  3463 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I0927 14:49:11.354010  3463 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I0927 14:49:11.354015  3463 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0927 14:49:11.354019  3463 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0927 14:49:11.354233  3463 net.cpp:122] Setting up SoftmaxWithLoss1
I0927 14:49:11.354239  3463 net.cpp:129] Top shape: (1)
I0927 14:49:11.354241  3463 net.cpp:132]     with loss weight 1
I0927 14:49:11.354255  3463 net.cpp:137] Memory required for data: 1187469204
I0927 14:49:11.354259  3463 layer_factory.hpp:77] Creating layer Accuracy1
I0927 14:49:11.354264  3463 net.cpp:84] Creating Layer Accuracy1
I0927 14:49:11.354267  3463 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I0927 14:49:11.354271  3463 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I0927 14:49:11.354274  3463 net.cpp:380] Accuracy1 -> Accuracy1
I0927 14:49:11.354280  3463 net.cpp:122] Setting up Accuracy1
I0927 14:49:11.354285  3463 net.cpp:129] Top shape: (1)
I0927 14:49:11.354287  3463 net.cpp:137] Memory required for data: 1187469208
I0927 14:49:11.354290  3463 net.cpp:200] Accuracy1 does not need backward computation.
I0927 14:49:11.354292  3463 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0927 14:49:11.354295  3463 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0927 14:49:11.354297  3463 net.cpp:198] InnerProduct1 needs backward computation.
I0927 14:49:11.354300  3463 net.cpp:198] Pooling1 needs backward computation.
I0927 14:49:11.354301  3463 net.cpp:198] M2PELU55 needs backward computation.
I0927 14:49:11.354303  3463 net.cpp:198] Eltwise27 needs backward computation.
I0927 14:49:11.354306  3463 net.cpp:198] Scale57 needs backward computation.
I0927 14:49:11.354308  3463 net.cpp:198] BatchNorm57 needs backward computation.
I0927 14:49:11.354310  3463 net.cpp:198] Convolution57 needs backward computation.
I0927 14:49:11.354313  3463 net.cpp:198] M2PELU54 needs backward computation.
I0927 14:49:11.354315  3463 net.cpp:198] Scale56 needs backward computation.
I0927 14:49:11.354317  3463 net.cpp:198] BatchNorm56 needs backward computation.
I0927 14:49:11.354320  3463 net.cpp:198] Convolution56 needs backward computation.
I0927 14:49:11.354321  3463 net.cpp:198] Eltwise26_M2PELU53_0_split needs backward computation.
I0927 14:49:11.354324  3463 net.cpp:198] M2PELU53 needs backward computation.
I0927 14:49:11.354326  3463 net.cpp:198] Eltwise26 needs backward computation.
I0927 14:49:11.354328  3463 net.cpp:198] Scale55 needs backward computation.
I0927 14:49:11.354331  3463 net.cpp:198] BatchNorm55 needs backward computation.
I0927 14:49:11.354332  3463 net.cpp:198] Convolution55 needs backward computation.
I0927 14:49:11.354336  3463 net.cpp:198] M2PELU52 needs backward computation.
I0927 14:49:11.354337  3463 net.cpp:198] Scale54 needs backward computation.
I0927 14:49:11.354339  3463 net.cpp:198] BatchNorm54 needs backward computation.
I0927 14:49:11.354341  3463 net.cpp:198] Convolution54 needs backward computation.
I0927 14:49:11.354343  3463 net.cpp:198] Eltwise25_M2PELU51_0_split needs backward computation.
I0927 14:49:11.354346  3463 net.cpp:198] M2PELU51 needs backward computation.
I0927 14:49:11.354348  3463 net.cpp:198] Eltwise25 needs backward computation.
I0927 14:49:11.354351  3463 net.cpp:198] Scale53 needs backward computation.
I0927 14:49:11.354353  3463 net.cpp:198] BatchNorm53 needs backward computation.
I0927 14:49:11.354356  3463 net.cpp:198] Convolution53 needs backward computation.
I0927 14:49:11.354357  3463 net.cpp:198] M2PELU50 needs backward computation.
I0927 14:49:11.354359  3463 net.cpp:198] Scale52 needs backward computation.
I0927 14:49:11.354362  3463 net.cpp:198] BatchNorm52 needs backward computation.
I0927 14:49:11.354363  3463 net.cpp:198] Convolution52 needs backward computation.
I0927 14:49:11.354365  3463 net.cpp:198] Eltwise24_M2PELU49_0_split needs backward computation.
I0927 14:49:11.354368  3463 net.cpp:198] M2PELU49 needs backward computation.
I0927 14:49:11.354370  3463 net.cpp:198] Eltwise24 needs backward computation.
I0927 14:49:11.354373  3463 net.cpp:198] Scale51 needs backward computation.
I0927 14:49:11.354375  3463 net.cpp:198] BatchNorm51 needs backward computation.
I0927 14:49:11.354377  3463 net.cpp:198] Convolution51 needs backward computation.
I0927 14:49:11.354379  3463 net.cpp:198] M2PELU48 needs backward computation.
I0927 14:49:11.354382  3463 net.cpp:198] Scale50 needs backward computation.
I0927 14:49:11.354388  3463 net.cpp:198] BatchNorm50 needs backward computation.
I0927 14:49:11.354390  3463 net.cpp:198] Convolution50 needs backward computation.
I0927 14:49:11.354393  3463 net.cpp:198] Eltwise23_M2PELU47_0_split needs backward computation.
I0927 14:49:11.354395  3463 net.cpp:198] M2PELU47 needs backward computation.
I0927 14:49:11.354398  3463 net.cpp:198] Eltwise23 needs backward computation.
I0927 14:49:11.354400  3463 net.cpp:198] Scale49 needs backward computation.
I0927 14:49:11.354403  3463 net.cpp:198] BatchNorm49 needs backward computation.
I0927 14:49:11.354404  3463 net.cpp:198] Convolution49 needs backward computation.
I0927 14:49:11.354408  3463 net.cpp:198] M2PELU46 needs backward computation.
I0927 14:49:11.354409  3463 net.cpp:198] Scale48 needs backward computation.
I0927 14:49:11.354411  3463 net.cpp:198] BatchNorm48 needs backward computation.
I0927 14:49:11.354413  3463 net.cpp:198] Convolution48 needs backward computation.
I0927 14:49:11.354415  3463 net.cpp:198] Eltwise22_M2PELU45_0_split needs backward computation.
I0927 14:49:11.354418  3463 net.cpp:198] M2PELU45 needs backward computation.
I0927 14:49:11.354420  3463 net.cpp:198] Eltwise22 needs backward computation.
I0927 14:49:11.354423  3463 net.cpp:198] Scale47 needs backward computation.
I0927 14:49:11.354425  3463 net.cpp:198] BatchNorm47 needs backward computation.
I0927 14:49:11.354427  3463 net.cpp:198] Convolution47 needs backward computation.
I0927 14:49:11.354430  3463 net.cpp:198] M2PELU44 needs backward computation.
I0927 14:49:11.354432  3463 net.cpp:198] Scale46 needs backward computation.
I0927 14:49:11.354434  3463 net.cpp:198] BatchNorm46 needs backward computation.
I0927 14:49:11.354436  3463 net.cpp:198] Convolution46 needs backward computation.
I0927 14:49:11.354439  3463 net.cpp:198] Eltwise21_M2PELU43_0_split needs backward computation.
I0927 14:49:11.354441  3463 net.cpp:198] M2PELU43 needs backward computation.
I0927 14:49:11.354444  3463 net.cpp:198] Eltwise21 needs backward computation.
I0927 14:49:11.354446  3463 net.cpp:198] Scale45 needs backward computation.
I0927 14:49:11.354449  3463 net.cpp:198] BatchNorm45 needs backward computation.
I0927 14:49:11.354450  3463 net.cpp:198] Convolution45 needs backward computation.
I0927 14:49:11.354454  3463 net.cpp:198] M2PELU42 needs backward computation.
I0927 14:49:11.354455  3463 net.cpp:198] Scale44 needs backward computation.
I0927 14:49:11.354457  3463 net.cpp:198] BatchNorm44 needs backward computation.
I0927 14:49:11.354460  3463 net.cpp:198] Convolution44 needs backward computation.
I0927 14:49:11.354462  3463 net.cpp:198] Eltwise20_M2PELU41_0_split needs backward computation.
I0927 14:49:11.354465  3463 net.cpp:198] M2PELU41 needs backward computation.
I0927 14:49:11.354466  3463 net.cpp:198] Eltwise20 needs backward computation.
I0927 14:49:11.354470  3463 net.cpp:198] Scale43 needs backward computation.
I0927 14:49:11.354471  3463 net.cpp:198] BatchNorm43 needs backward computation.
I0927 14:49:11.354473  3463 net.cpp:198] Convolution43 needs backward computation.
I0927 14:49:11.354476  3463 net.cpp:198] M2PELU40 needs backward computation.
I0927 14:49:11.354478  3463 net.cpp:198] Scale42 needs backward computation.
I0927 14:49:11.354480  3463 net.cpp:198] BatchNorm42 needs backward computation.
I0927 14:49:11.354482  3463 net.cpp:198] Convolution42 needs backward computation.
I0927 14:49:11.354485  3463 net.cpp:198] Eltwise19_M2PELU39_0_split needs backward computation.
I0927 14:49:11.354488  3463 net.cpp:198] M2PELU39 needs backward computation.
I0927 14:49:11.354490  3463 net.cpp:198] Eltwise19 needs backward computation.
I0927 14:49:11.354493  3463 net.cpp:198] Scale41 needs backward computation.
I0927 14:49:11.354496  3463 net.cpp:198] BatchNorm41 needs backward computation.
I0927 14:49:11.354497  3463 net.cpp:198] Convolution41 needs backward computation.
I0927 14:49:11.354501  3463 net.cpp:198] M2PELU38 needs backward computation.
I0927 14:49:11.354502  3463 net.cpp:198] Scale40 needs backward computation.
I0927 14:49:11.354508  3463 net.cpp:198] BatchNorm40 needs backward computation.
I0927 14:49:11.354511  3463 net.cpp:198] Convolution40 needs backward computation.
I0927 14:49:11.354512  3463 net.cpp:198] Scale39 needs backward computation.
I0927 14:49:11.354516  3463 net.cpp:198] BatchNorm39 needs backward computation.
I0927 14:49:11.354517  3463 net.cpp:198] Convolution39 needs backward computation.
I0927 14:49:11.354528  3463 net.cpp:198] Eltwise18_M2PELU37_0_split needs backward computation.
I0927 14:49:11.354532  3463 net.cpp:198] M2PELU37 needs backward computation.
I0927 14:49:11.354534  3463 net.cpp:198] Eltwise18 needs backward computation.
I0927 14:49:11.354537  3463 net.cpp:198] Scale38 needs backward computation.
I0927 14:49:11.354539  3463 net.cpp:198] BatchNorm38 needs backward computation.
I0927 14:49:11.354552  3463 net.cpp:198] Convolution38 needs backward computation.
I0927 14:49:11.354553  3463 net.cpp:198] M2PELU36 needs backward computation.
I0927 14:49:11.354557  3463 net.cpp:198] Scale37 needs backward computation.
I0927 14:49:11.354558  3463 net.cpp:198] BatchNorm37 needs backward computation.
I0927 14:49:11.354560  3463 net.cpp:198] Convolution37 needs backward computation.
I0927 14:49:11.354562  3463 net.cpp:198] Eltwise17_M2PELU35_0_split needs backward computation.
I0927 14:49:11.354565  3463 net.cpp:198] M2PELU35 needs backward computation.
I0927 14:49:11.354568  3463 net.cpp:198] Eltwise17 needs backward computation.
I0927 14:49:11.380642  3463 net.cpp:198] Scale36 needs backward computation.
I0927 14:49:11.380650  3463 net.cpp:198] BatchNorm36 needs backward computation.
I0927 14:49:11.380653  3463 net.cpp:198] Convolution36 needs backward computation.
I0927 14:49:11.380656  3463 net.cpp:198] M2PELU34 needs backward computation.
I0927 14:49:11.380658  3463 net.cpp:198] Scale35 needs backward computation.
I0927 14:49:11.380661  3463 net.cpp:198] BatchNorm35 needs backward computation.
I0927 14:49:11.380663  3463 net.cpp:198] Convolution35 needs backward computation.
I0927 14:49:11.380666  3463 net.cpp:198] Eltwise16_M2PELU33_0_split needs backward computation.
I0927 14:49:11.380671  3463 net.cpp:198] M2PELU33 needs backward computation.
I0927 14:49:11.380674  3463 net.cpp:198] Eltwise16 needs backward computation.
I0927 14:49:11.380677  3463 net.cpp:198] Scale34 needs backward computation.
I0927 14:49:11.380681  3463 net.cpp:198] BatchNorm34 needs backward computation.
I0927 14:49:11.380682  3463 net.cpp:198] Convolution34 needs backward computation.
I0927 14:49:11.380684  3463 net.cpp:198] M2PELU32 needs backward computation.
I0927 14:49:11.380687  3463 net.cpp:198] Scale33 needs backward computation.
I0927 14:49:11.380689  3463 net.cpp:198] BatchNorm33 needs backward computation.
I0927 14:49:11.380692  3463 net.cpp:198] Convolution33 needs backward computation.
I0927 14:49:11.380694  3463 net.cpp:198] Eltwise15_M2PELU31_0_split needs backward computation.
I0927 14:49:11.380697  3463 net.cpp:198] M2PELU31 needs backward computation.
I0927 14:49:11.380700  3463 net.cpp:198] Eltwise15 needs backward computation.
I0927 14:49:11.380702  3463 net.cpp:198] Scale32 needs backward computation.
I0927 14:49:11.380705  3463 net.cpp:198] BatchNorm32 needs backward computation.
I0927 14:49:11.380707  3463 net.cpp:198] Convolution32 needs backward computation.
I0927 14:49:11.380710  3463 net.cpp:198] M2PELU30 needs backward computation.
I0927 14:49:11.380712  3463 net.cpp:198] Scale31 needs backward computation.
I0927 14:49:11.380714  3463 net.cpp:198] BatchNorm31 needs backward computation.
I0927 14:49:11.380717  3463 net.cpp:198] Convolution31 needs backward computation.
I0927 14:49:11.380719  3463 net.cpp:198] Eltwise14_M2PELU29_0_split needs backward computation.
I0927 14:49:11.380722  3463 net.cpp:198] M2PELU29 needs backward computation.
I0927 14:49:11.380724  3463 net.cpp:198] Eltwise14 needs backward computation.
I0927 14:49:11.380728  3463 net.cpp:198] Scale30 needs backward computation.
I0927 14:49:11.380729  3463 net.cpp:198] BatchNorm30 needs backward computation.
I0927 14:49:11.380733  3463 net.cpp:198] Convolution30 needs backward computation.
I0927 14:49:11.380743  3463 net.cpp:198] M2PELU28 needs backward computation.
I0927 14:49:11.380745  3463 net.cpp:198] Scale29 needs backward computation.
I0927 14:49:11.380748  3463 net.cpp:198] BatchNorm29 needs backward computation.
I0927 14:49:11.380750  3463 net.cpp:198] Convolution29 needs backward computation.
I0927 14:49:11.380753  3463 net.cpp:198] Eltwise13_M2PELU27_0_split needs backward computation.
I0927 14:49:11.380755  3463 net.cpp:198] M2PELU27 needs backward computation.
I0927 14:49:11.380758  3463 net.cpp:198] Eltwise13 needs backward computation.
I0927 14:49:11.380760  3463 net.cpp:198] Scale28 needs backward computation.
I0927 14:49:11.380764  3463 net.cpp:198] BatchNorm28 needs backward computation.
I0927 14:49:11.380765  3463 net.cpp:198] Convolution28 needs backward computation.
I0927 14:49:11.380769  3463 net.cpp:198] M2PELU26 needs backward computation.
I0927 14:49:11.380770  3463 net.cpp:198] Scale27 needs backward computation.
I0927 14:49:11.380772  3463 net.cpp:198] BatchNorm27 needs backward computation.
I0927 14:49:11.380775  3463 net.cpp:198] Convolution27 needs backward computation.
I0927 14:49:11.380777  3463 net.cpp:198] Eltwise12_M2PELU25_0_split needs backward computation.
I0927 14:49:11.380780  3463 net.cpp:198] M2PELU25 needs backward computation.
I0927 14:49:11.380782  3463 net.cpp:198] Eltwise12 needs backward computation.
I0927 14:49:11.380786  3463 net.cpp:198] Scale26 needs backward computation.
I0927 14:49:11.380789  3463 net.cpp:198] BatchNorm26 needs backward computation.
I0927 14:49:11.380790  3463 net.cpp:198] Convolution26 needs backward computation.
I0927 14:49:11.380794  3463 net.cpp:198] M2PELU24 needs backward computation.
I0927 14:49:11.380795  3463 net.cpp:198] Scale25 needs backward computation.
I0927 14:49:11.380798  3463 net.cpp:198] BatchNorm25 needs backward computation.
I0927 14:49:11.380800  3463 net.cpp:198] Convolution25 needs backward computation.
I0927 14:49:11.380803  3463 net.cpp:198] Eltwise11_M2PELU23_0_split needs backward computation.
I0927 14:49:11.380805  3463 net.cpp:198] M2PELU23 needs backward computation.
I0927 14:49:11.380808  3463 net.cpp:198] Eltwise11 needs backward computation.
I0927 14:49:11.380811  3463 net.cpp:198] Scale24 needs backward computation.
I0927 14:49:11.380813  3463 net.cpp:198] BatchNorm24 needs backward computation.
I0927 14:49:11.380815  3463 net.cpp:198] Convolution24 needs backward computation.
I0927 14:49:11.380818  3463 net.cpp:198] M2PELU22 needs backward computation.
I0927 14:49:11.380820  3463 net.cpp:198] Scale23 needs backward computation.
I0927 14:49:11.380823  3463 net.cpp:198] BatchNorm23 needs backward computation.
I0927 14:49:11.380825  3463 net.cpp:198] Convolution23 needs backward computation.
I0927 14:49:11.380828  3463 net.cpp:198] Eltwise10_M2PELU21_0_split needs backward computation.
I0927 14:49:11.380831  3463 net.cpp:198] M2PELU21 needs backward computation.
I0927 14:49:11.380833  3463 net.cpp:198] Eltwise10 needs backward computation.
I0927 14:49:11.380836  3463 net.cpp:198] Scale22 needs backward computation.
I0927 14:49:11.380838  3463 net.cpp:198] BatchNorm22 needs backward computation.
I0927 14:49:11.380841  3463 net.cpp:198] Convolution22 needs backward computation.
I0927 14:49:11.380844  3463 net.cpp:198] M2PELU20 needs backward computation.
I0927 14:49:11.380846  3463 net.cpp:198] Scale21 needs backward computation.
I0927 14:49:11.380848  3463 net.cpp:198] BatchNorm21 needs backward computation.
I0927 14:49:11.380851  3463 net.cpp:198] Convolution21 needs backward computation.
I0927 14:49:11.380853  3463 net.cpp:198] Scale20 needs backward computation.
I0927 14:49:11.380857  3463 net.cpp:198] BatchNorm20 needs backward computation.
I0927 14:49:11.380859  3463 net.cpp:198] Convolution20 needs backward computation.
I0927 14:49:11.380862  3463 net.cpp:198] Eltwise9_M2PELU19_0_split needs backward computation.
I0927 14:49:11.380866  3463 net.cpp:198] M2PELU19 needs backward computation.
I0927 14:49:11.380867  3463 net.cpp:198] Eltwise9 needs backward computation.
I0927 14:49:11.380874  3463 net.cpp:198] Scale19 needs backward computation.
I0927 14:49:11.380877  3463 net.cpp:198] BatchNorm19 needs backward computation.
I0927 14:49:11.380879  3463 net.cpp:198] Convolution19 needs backward computation.
I0927 14:49:11.380882  3463 net.cpp:198] M2PELU18 needs backward computation.
I0927 14:49:11.380884  3463 net.cpp:198] Scale18 needs backward computation.
I0927 14:49:11.380887  3463 net.cpp:198] BatchNorm18 needs backward computation.
I0927 14:49:11.380889  3463 net.cpp:198] Convolution18 needs backward computation.
I0927 14:49:11.380892  3463 net.cpp:198] Eltwise8_M2PELU17_0_split needs backward computation.
I0927 14:49:11.380894  3463 net.cpp:198] M2PELU17 needs backward computation.
I0927 14:49:11.380897  3463 net.cpp:198] Eltwise8 needs backward computation.
I0927 14:49:11.380900  3463 net.cpp:198] Scale17 needs backward computation.
I0927 14:49:11.380903  3463 net.cpp:198] BatchNorm17 needs backward computation.
I0927 14:49:11.380904  3463 net.cpp:198] Convolution17 needs backward computation.
I0927 14:49:11.380908  3463 net.cpp:198] M2PELU16 needs backward computation.
I0927 14:49:11.380909  3463 net.cpp:198] Scale16 needs backward computation.
I0927 14:49:11.380913  3463 net.cpp:198] BatchNorm16 needs backward computation.
I0927 14:49:11.380914  3463 net.cpp:198] Convolution16 needs backward computation.
I0927 14:49:11.382997  3463 net.cpp:198] Eltwise7_M2PELU15_0_split needs backward computation.
I0927 14:49:11.383004  3463 net.cpp:198] M2PELU15 needs backward computation.
I0927 14:49:11.383008  3463 net.cpp:198] Eltwise7 needs backward computation.
I0927 14:49:11.383011  3463 net.cpp:198] Scale15 needs backward computation.
I0927 14:49:11.383023  3463 net.cpp:198] BatchNorm15 needs backward computation.
I0927 14:49:11.383025  3463 net.cpp:198] Convolution15 needs backward computation.
I0927 14:49:11.383028  3463 net.cpp:198] M2PELU14 needs backward computation.
I0927 14:49:11.383029  3463 net.cpp:198] Scale14 needs backward computation.
I0927 14:49:11.383033  3463 net.cpp:198] BatchNorm14 needs backward computation.
I0927 14:49:11.383034  3463 net.cpp:198] Convolution14 needs backward computation.
I0927 14:49:11.383036  3463 net.cpp:198] Eltwise6_M2PELU13_0_split needs backward computation.
I0927 14:49:11.383039  3463 net.cpp:198] M2PELU13 needs backward computation.
I0927 14:49:11.383041  3463 net.cpp:198] Eltwise6 needs backward computation.
I0927 14:49:11.383044  3463 net.cpp:198] Scale13 needs backward computation.
I0927 14:49:11.383046  3463 net.cpp:198] BatchNorm13 needs backward computation.
I0927 14:49:11.383049  3463 net.cpp:198] Convolution13 needs backward computation.
I0927 14:49:11.383051  3463 net.cpp:198] M2PELU12 needs backward computation.
I0927 14:49:11.383054  3463 net.cpp:198] Scale12 needs backward computation.
I0927 14:49:11.383056  3463 net.cpp:198] BatchNorm12 needs backward computation.
I0927 14:49:11.383059  3463 net.cpp:198] Convolution12 needs backward computation.
I0927 14:49:11.383060  3463 net.cpp:198] Eltwise5_M2PELU11_0_split needs backward computation.
I0927 14:49:11.383064  3463 net.cpp:198] M2PELU11 needs backward computation.
I0927 14:49:11.383065  3463 net.cpp:198] Eltwise5 needs backward computation.
I0927 14:49:11.383069  3463 net.cpp:198] Scale11 needs backward computation.
I0927 14:49:11.383071  3463 net.cpp:198] BatchNorm11 needs backward computation.
I0927 14:49:11.383074  3463 net.cpp:198] Convolution11 needs backward computation.
I0927 14:49:11.383075  3463 net.cpp:198] M2PELU10 needs backward computation.
I0927 14:49:11.383077  3463 net.cpp:198] Scale10 needs backward computation.
I0927 14:49:11.383080  3463 net.cpp:198] BatchNorm10 needs backward computation.
I0927 14:49:11.383082  3463 net.cpp:198] Convolution10 needs backward computation.
I0927 14:49:11.383085  3463 net.cpp:198] Eltwise4_M2PELU9_0_split needs backward computation.
I0927 14:49:11.383087  3463 net.cpp:198] M2PELU9 needs backward computation.
I0927 14:49:11.383090  3463 net.cpp:198] Eltwise4 needs backward computation.
I0927 14:49:11.383092  3463 net.cpp:198] Scale9 needs backward computation.
I0927 14:49:11.383105  3463 net.cpp:198] BatchNorm9 needs backward computation.
I0927 14:49:11.383107  3463 net.cpp:198] Convolution9 needs backward computation.
I0927 14:49:11.383111  3463 net.cpp:198] M2PELU8 needs backward computation.
I0927 14:49:11.383112  3463 net.cpp:198] Scale8 needs backward computation.
I0927 14:49:11.383114  3463 net.cpp:198] BatchNorm8 needs backward computation.
I0927 14:49:11.383116  3463 net.cpp:198] Convolution8 needs backward computation.
I0927 14:49:11.383119  3463 net.cpp:198] Eltwise3_M2PELU7_0_split needs backward computation.
I0927 14:49:11.383122  3463 net.cpp:198] M2PELU7 needs backward computation.
I0927 14:49:11.383124  3463 net.cpp:198] Eltwise3 needs backward computation.
I0927 14:49:11.383127  3463 net.cpp:198] Scale7 needs backward computation.
I0927 14:49:11.383129  3463 net.cpp:198] BatchNorm7 needs backward computation.
I0927 14:49:11.383132  3463 net.cpp:198] Convolution7 needs backward computation.
I0927 14:49:11.383134  3463 net.cpp:198] M2PELU6 needs backward computation.
I0927 14:49:11.383136  3463 net.cpp:198] Scale6 needs backward computation.
I0927 14:49:11.383138  3463 net.cpp:198] BatchNorm6 needs backward computation.
I0927 14:49:11.383141  3463 net.cpp:198] Convolution6 needs backward computation.
I0927 14:49:11.383144  3463 net.cpp:198] Eltwise2_M2PELU5_0_split needs backward computation.
I0927 14:49:11.383147  3463 net.cpp:198] M2PELU5 needs backward computation.
I0927 14:49:11.383148  3463 net.cpp:198] Eltwise2 needs backward computation.
I0927 14:49:11.383152  3463 net.cpp:198] Scale5 needs backward computation.
I0927 14:49:11.383154  3463 net.cpp:198] BatchNorm5 needs backward computation.
I0927 14:49:11.383157  3463 net.cpp:198] Convolution5 needs backward computation.
I0927 14:49:11.383159  3463 net.cpp:198] M2PELU4 needs backward computation.
I0927 14:49:11.383162  3463 net.cpp:198] Scale4 needs backward computation.
I0927 14:49:11.383163  3463 net.cpp:198] BatchNorm4 needs backward computation.
I0927 14:49:11.383165  3463 net.cpp:198] Convolution4 needs backward computation.
I0927 14:49:11.383168  3463 net.cpp:198] Eltwise1_M2PELU3_0_split needs backward computation.
I0927 14:49:11.383170  3463 net.cpp:198] M2PELU3 needs backward computation.
I0927 14:49:11.383172  3463 net.cpp:198] Eltwise1 needs backward computation.
I0927 14:49:11.383175  3463 net.cpp:198] Scale3 needs backward computation.
I0927 14:49:11.383178  3463 net.cpp:198] BatchNorm3 needs backward computation.
I0927 14:49:11.383180  3463 net.cpp:198] Convolution3 needs backward computation.
I0927 14:49:11.383183  3463 net.cpp:198] M2PELU2 needs backward computation.
I0927 14:49:11.383185  3463 net.cpp:198] Scale2 needs backward computation.
I0927 14:49:11.383188  3463 net.cpp:198] BatchNorm2 needs backward computation.
I0927 14:49:11.383189  3463 net.cpp:198] Convolution2 needs backward computation.
I0927 14:49:11.383193  3463 net.cpp:198] Convolution1_M2PELU1_0_split needs backward computation.
I0927 14:49:11.383194  3463 net.cpp:198] M2PELU1 needs backward computation.
I0927 14:49:11.383198  3463 net.cpp:198] Scale1 needs backward computation.
I0927 14:49:11.383199  3463 net.cpp:198] BatchNorm1 needs backward computation.
I0927 14:49:11.383201  3463 net.cpp:198] Convolution1 needs backward computation.
I0927 14:49:11.383204  3463 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I0927 14:49:11.383209  3463 net.cpp:200] Data1 does not need backward computation.
I0927 14:49:11.383211  3463 net.cpp:242] This network produces output Accuracy1
I0927 14:49:11.383213  3463 net.cpp:242] This network produces output SoftmaxWithLoss1
I0927 14:49:11.383313  3463 net.cpp:255] Network initialization done.
I0927 14:49:11.384346  3463 solver.cpp:56] Solver scaffolding done.
I0927 14:49:11.397181  3463 caffe.cpp:248] Starting Optimization
I0927 14:49:11.397187  3463 solver.cpp:272] Solving resnet_cifar10
I0927 14:49:11.397189  3463 solver.cpp:273] Learning Rate Policy: multistep
I0927 14:49:11.403260  3463 solver.cpp:330] Iteration 0, Testing net (#0)
I0927 14:49:14.840098  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:49:14.979379  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I0927 14:49:14.979416  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I0927 14:49:15.177466  3463 solver.cpp:218] Iteration 0 (0 iter/s, 3.78018s/100 iters), loss = 2.30785
I0927 14:49:15.177497  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.30785 (* 1 = 2.30785 loss)
I0927 14:49:15.177511  3463 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I0927 14:49:29.330484  3463 solver.cpp:218] Iteration 100 (7.06571 iter/s, 14.1529s/100 iters), loss = 2.27623
I0927 14:49:29.330515  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.27623 (* 1 = 2.27623 loss)
I0927 14:49:29.330523  3463 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I0927 14:49:43.465939  3463 solver.cpp:218] Iteration 200 (7.07449 iter/s, 14.1353s/100 iters), loss = 2.24919
I0927 14:49:43.466028  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.24919 (* 1 = 2.24919 loss)
I0927 14:49:43.466037  3463 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I0927 14:49:57.604847  3463 solver.cpp:218] Iteration 300 (7.07279 iter/s, 14.1387s/100 iters), loss = 2.05987
I0927 14:49:57.604888  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.05987 (* 1 = 2.05987 loss)
I0927 14:49:57.604894  3463 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I0927 14:50:11.741963  3463 solver.cpp:218] Iteration 400 (7.07366 iter/s, 14.137s/100 iters), loss = 1.62974
I0927 14:50:11.742004  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.62974 (* 1 = 1.62974 loss)
I0927 14:50:11.742009  3463 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I0927 14:50:25.196480  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:50:25.763375  3463 solver.cpp:330] Iteration 500, Testing net (#0)
I0927 14:50:29.102327  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:50:29.241792  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1795
I0927 14:50:29.241829  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.39844 (* 1 = 2.39844 loss)
I0927 14:50:29.382851  3463 solver.cpp:218] Iteration 500 (5.66871 iter/s, 17.6407s/100 iters), loss = 1.82057
I0927 14:50:29.382879  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.82057 (* 1 = 1.82057 loss)
I0927 14:50:29.382885  3463 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I0927 14:50:43.547811  3463 solver.cpp:218] Iteration 600 (7.05975 iter/s, 14.1648s/100 iters), loss = 1.63236
I0927 14:50:43.547852  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.63236 (* 1 = 1.63236 loss)
I0927 14:50:43.547857  3463 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I0927 14:50:57.715276  3463 solver.cpp:218] Iteration 700 (7.0585 iter/s, 14.1673s/100 iters), loss = 1.73005
I0927 14:50:57.715394  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.73005 (* 1 = 1.73005 loss)
I0927 14:50:57.715411  3463 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I0927 14:51:11.884330  3463 solver.cpp:218] Iteration 800 (7.05775 iter/s, 14.1688s/100 iters), loss = 1.39564
I0927 14:51:11.884371  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.39564 (* 1 = 1.39564 loss)
I0927 14:51:11.884377  3463 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I0927 14:51:26.048101  3463 solver.cpp:218] Iteration 900 (7.06034 iter/s, 14.1636s/100 iters), loss = 1.13578
I0927 14:51:26.048143  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.13578 (* 1 = 1.13578 loss)
I0927 14:51:26.048149  3463 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I0927 14:51:39.505758  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:51:40.073007  3463 solver.cpp:330] Iteration 1000, Testing net (#0)
I0927 14:51:43.422219  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:51:43.561923  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1718
I0927 14:51:43.561949  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 4.87673 (* 1 = 4.87673 loss)
I0927 14:51:43.702409  3463 solver.cpp:218] Iteration 1000 (5.6644 iter/s, 17.6541s/100 iters), loss = 1.3909
I0927 14:51:43.702438  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.3909 (* 1 = 1.3909 loss)
I0927 14:51:43.702445  3463 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I0927 14:51:57.885576  3463 solver.cpp:218] Iteration 1100 (7.05068 iter/s, 14.183s/100 iters), loss = 1.15876
I0927 14:51:57.885617  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.15876 (* 1 = 1.15876 loss)
I0927 14:51:57.885623  3463 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I0927 14:52:12.070698  3463 solver.cpp:218] Iteration 1200 (7.04971 iter/s, 14.185s/100 iters), loss = 1.18365
I0927 14:52:12.070785  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.18365 (* 1 = 1.18365 loss)
I0927 14:52:12.070802  3463 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I0927 14:52:26.252588  3463 solver.cpp:218] Iteration 1300 (7.05134 iter/s, 14.1817s/100 iters), loss = 0.998485
I0927 14:52:26.252629  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.998485 (* 1 = 0.998485 loss)
I0927 14:52:26.252635  3463 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I0927 14:52:40.438266  3463 solver.cpp:218] Iteration 1400 (7.04943 iter/s, 14.1855s/100 iters), loss = 0.81113
I0927 14:52:40.438298  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.81113 (* 1 = 0.81113 loss)
I0927 14:52:40.438304  3463 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I0927 14:52:53.911415  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:52:54.479244  3463 solver.cpp:330] Iteration 1500, Testing net (#0)
I0927 14:52:57.826795  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:52:57.966549  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.2777
I0927 14:52:57.966586  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.32501 (* 1 = 3.32501 loss)
I0927 14:52:58.107213  3463 solver.cpp:218] Iteration 1500 (5.65969 iter/s, 17.6688s/100 iters), loss = 0.98142
I0927 14:52:58.107240  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.98142 (* 1 = 0.98142 loss)
I0927 14:52:58.107247  3463 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I0927 14:53:12.276317  3463 solver.cpp:218] Iteration 1600 (7.05766 iter/s, 14.169s/100 iters), loss = 0.818209
I0927 14:53:12.276358  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.818209 (* 1 = 0.818209 loss)
I0927 14:53:12.276365  3463 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I0927 14:53:26.446602  3463 solver.cpp:218] Iteration 1700 (7.05708 iter/s, 14.1702s/100 iters), loss = 0.879969
I0927 14:53:26.446744  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.879969 (* 1 = 0.879969 loss)
I0927 14:53:26.446753  3463 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I0927 14:53:40.615422  3463 solver.cpp:218] Iteration 1800 (7.05785 iter/s, 14.1686s/100 iters), loss = 0.800816
I0927 14:53:40.615453  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.800816 (* 1 = 0.800816 loss)
I0927 14:53:40.615469  3463 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I0927 14:53:54.776361  3463 solver.cpp:218] Iteration 1900 (7.06172 iter/s, 14.1608s/100 iters), loss = 0.677836
I0927 14:53:54.776391  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.677836 (* 1 = 0.677836 loss)
I0927 14:53:54.776396  3463 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I0927 14:54:08.238519  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:54:08.805841  3463 solver.cpp:330] Iteration 2000, Testing net (#0)
I0927 14:54:12.153865  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:54:12.294049  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.2571
I0927 14:54:12.294087  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.81838 (* 1 = 3.81838 loss)
I0927 14:54:12.434577  3463 solver.cpp:218] Iteration 2000 (5.66312 iter/s, 17.6581s/100 iters), loss = 0.781181
I0927 14:54:12.434604  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.781181 (* 1 = 0.781181 loss)
I0927 14:54:12.434612  3463 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I0927 14:54:26.603340  3463 solver.cpp:218] Iteration 2100 (7.05782 iter/s, 14.1687s/100 iters), loss = 0.654727
I0927 14:54:26.603373  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.654727 (* 1 = 0.654727 loss)
I0927 14:54:26.603379  3463 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I0927 14:54:40.778889  3463 solver.cpp:218] Iteration 2200 (7.05444 iter/s, 14.1755s/100 iters), loss = 0.641411
I0927 14:54:40.778966  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.641411 (* 1 = 0.641411 loss)
I0927 14:54:40.778983  3463 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I0927 14:54:54.959355  3463 solver.cpp:218] Iteration 2300 (7.05202 iter/s, 14.1803s/100 iters), loss = 0.642045
I0927 14:54:54.959386  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.642045 (* 1 = 0.642045 loss)
I0927 14:54:54.959401  3463 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I0927 14:55:09.135010  3463 solver.cpp:218] Iteration 2400 (7.05439 iter/s, 14.1756s/100 iters), loss = 0.583661
I0927 14:55:09.135041  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.583661 (* 1 = 0.583661 loss)
I0927 14:55:09.135047  3463 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I0927 14:55:22.608711  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:55:23.176543  3463 solver.cpp:330] Iteration 2500, Testing net (#0)
I0927 14:55:26.523738  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:55:26.663512  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5262
I0927 14:55:26.663548  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.37994 (* 1 = 1.37994 loss)
I0927 14:55:26.804260  3463 solver.cpp:218] Iteration 2500 (5.65958 iter/s, 17.6692s/100 iters), loss = 0.643044
I0927 14:55:26.804289  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.643044 (* 1 = 0.643044 loss)
I0927 14:55:26.804296  3463 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I0927 14:55:40.975750  3463 solver.cpp:218] Iteration 2600 (7.05646 iter/s, 14.1714s/100 iters), loss = 0.489936
I0927 14:55:40.975782  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.489936 (* 1 = 0.489936 loss)
I0927 14:55:40.975800  3463 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I0927 14:55:55.158243  3463 solver.cpp:218] Iteration 2700 (7.05099 iter/s, 14.1824s/100 iters), loss = 0.632464
I0927 14:55:55.158378  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.632464 (* 1 = 0.632464 loss)
I0927 14:55:55.158386  3463 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I0927 14:56:09.344085  3463 solver.cpp:218] Iteration 2800 (7.04937 iter/s, 14.1857s/100 iters), loss = 0.665626
I0927 14:56:09.344116  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.665626 (* 1 = 0.665626 loss)
I0927 14:56:09.344122  3463 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I0927 14:56:23.522864  3463 solver.cpp:218] Iteration 2900 (7.05283 iter/s, 14.1787s/100 iters), loss = 0.550857
I0927 14:56:23.522895  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.550857 (* 1 = 0.550857 loss)
I0927 14:56:23.522900  3463 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I0927 14:56:36.998487  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:56:37.566568  3463 solver.cpp:330] Iteration 3000, Testing net (#0)
I0927 14:56:40.913774  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:56:41.053427  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5841
I0927 14:56:41.053453  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.28514 (* 1 = 1.28514 loss)
I0927 14:56:41.194289  3463 solver.cpp:218] Iteration 3000 (5.65888 iter/s, 17.6713s/100 iters), loss = 0.606207
I0927 14:56:41.194317  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.606207 (* 1 = 0.606207 loss)
I0927 14:56:41.194324  3463 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I0927 14:56:55.370576  3463 solver.cpp:218] Iteration 3100 (7.05407 iter/s, 14.1762s/100 iters), loss = 0.466364
I0927 14:56:55.370606  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.466364 (* 1 = 0.466364 loss)
I0927 14:56:55.370612  3463 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I0927 14:57:09.542814  3463 solver.cpp:218] Iteration 3200 (7.05609 iter/s, 14.1722s/100 iters), loss = 0.545623
I0927 14:57:09.542918  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.545623 (* 1 = 0.545623 loss)
I0927 14:57:09.542925  3463 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I0927 14:57:23.724366  3463 solver.cpp:218] Iteration 3300 (7.05149 iter/s, 14.1814s/100 iters), loss = 0.552112
I0927 14:57:23.724398  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.552112 (* 1 = 0.552112 loss)
I0927 14:57:23.724403  3463 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I0927 14:57:37.904986  3463 solver.cpp:218] Iteration 3400 (7.05192 iter/s, 14.1805s/100 iters), loss = 0.519667
I0927 14:57:37.905019  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.519667 (* 1 = 0.519667 loss)
I0927 14:57:37.905035  3463 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I0927 14:57:51.383474  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:57:51.951010  3463 solver.cpp:330] Iteration 3500, Testing net (#0)
I0927 14:57:55.298255  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:57:55.438045  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5609
I0927 14:57:55.438081  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.31011 (* 1 = 1.31011 loss)
I0927 14:57:55.578740  3463 solver.cpp:218] Iteration 3500 (5.65814 iter/s, 17.6737s/100 iters), loss = 0.614161
I0927 14:57:55.578768  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.614161 (* 1 = 0.614161 loss)
I0927 14:57:55.578775  3463 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I0927 14:58:09.753820  3463 solver.cpp:218] Iteration 3600 (7.05467 iter/s, 14.175s/100 iters), loss = 0.631981
I0927 14:58:09.753851  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.631981 (* 1 = 0.631981 loss)
I0927 14:58:09.753867  3463 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I0927 14:58:23.942159  3463 solver.cpp:218] Iteration 3700 (7.04808 iter/s, 14.1883s/100 iters), loss = 0.434864
I0927 14:58:23.942252  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.434864 (* 1 = 0.434864 loss)
I0927 14:58:23.942271  3463 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I0927 14:58:38.133397  3463 solver.cpp:218] Iteration 3800 (7.04667 iter/s, 14.1911s/100 iters), loss = 0.52268
I0927 14:58:38.133430  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.52268 (* 1 = 0.52268 loss)
I0927 14:58:38.133435  3463 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I0927 14:58:52.320663  3463 solver.cpp:218] Iteration 3900 (7.04862 iter/s, 14.1872s/100 iters), loss = 0.553448
I0927 14:58:52.320694  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.553448 (* 1 = 0.553448 loss)
I0927 14:58:52.320699  3463 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I0927 14:59:05.800681  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:59:06.367347  3463 solver.cpp:330] Iteration 4000, Testing net (#0)
I0927 14:59:09.712488  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:59:09.852385  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6348
I0927 14:59:09.852421  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.967126 (* 1 = 0.967126 loss)
I0927 14:59:09.993250  3463 solver.cpp:218] Iteration 4000 (5.65851 iter/s, 17.6725s/100 iters), loss = 0.505962
I0927 14:59:09.993278  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.505962 (* 1 = 0.505962 loss)
I0927 14:59:09.993283  3463 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I0927 14:59:24.158514  3463 solver.cpp:218] Iteration 4100 (7.05956 iter/s, 14.1652s/100 iters), loss = 0.454815
I0927 14:59:24.158546  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.454815 (* 1 = 0.454815 loss)
I0927 14:59:24.158552  3463 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I0927 14:59:38.333081  3463 solver.cpp:218] Iteration 4200 (7.05493 iter/s, 14.1745s/100 iters), loss = 0.386161
I0927 14:59:38.333222  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.386161 (* 1 = 0.386161 loss)
I0927 14:59:38.333242  3463 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I0927 14:59:52.509392  3463 solver.cpp:218] Iteration 4300 (7.05411 iter/s, 14.1761s/100 iters), loss = 0.534062
I0927 14:59:52.509420  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.534062 (* 1 = 0.534062 loss)
I0927 14:59:52.509436  3463 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I0927 15:00:06.689481  3463 solver.cpp:218] Iteration 4400 (7.05218 iter/s, 14.18s/100 iters), loss = 0.407327
I0927 15:00:06.689512  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.407327 (* 1 = 0.407327 loss)
I0927 15:00:06.689517  3463 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I0927 15:00:20.160528  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:00:20.728704  3463 solver.cpp:330] Iteration 4500, Testing net (#0)
I0927 15:00:24.072494  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:00:24.212545  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6442
I0927 15:00:24.212584  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.984113 (* 1 = 0.984113 loss)
I0927 15:00:24.353026  3463 solver.cpp:218] Iteration 4500 (5.66141 iter/s, 17.6635s/100 iters), loss = 0.476151
I0927 15:00:24.353054  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.476151 (* 1 = 0.476151 loss)
I0927 15:00:24.353060  3463 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I0927 15:00:38.530849  3463 solver.cpp:218] Iteration 4600 (7.05331 iter/s, 14.1777s/100 iters), loss = 0.481243
I0927 15:00:38.530881  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.481243 (* 1 = 0.481243 loss)
I0927 15:00:38.530897  3463 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I0927 15:00:52.711709  3463 solver.cpp:218] Iteration 4700 (7.0518 iter/s, 14.1808s/100 iters), loss = 0.381961
I0927 15:00:52.711773  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.381961 (* 1 = 0.381961 loss)
I0927 15:00:52.711791  3463 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I0927 15:01:06.890681  3463 solver.cpp:218] Iteration 4800 (7.05275 iter/s, 14.1789s/100 iters), loss = 0.519167
I0927 15:01:06.890712  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.519167 (* 1 = 0.519167 loss)
I0927 15:01:06.890728  3463 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I0927 15:01:21.067906  3463 solver.cpp:218] Iteration 4900 (7.05361 iter/s, 14.1771s/100 iters), loss = 0.502065
I0927 15:01:21.067936  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.502065 (* 1 = 0.502065 loss)
I0927 15:01:21.067942  3463 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I0927 15:01:34.545886  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:01:35.114176  3463 solver.cpp:330] Iteration 5000, Testing net (#0)
I0927 15:01:38.459656  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:01:38.599190  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7056
I0927 15:01:38.599226  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.839625 (* 1 = 0.839625 loss)
I0927 15:01:38.740182  3463 solver.cpp:218] Iteration 5000 (5.65861 iter/s, 17.6722s/100 iters), loss = 0.465771
I0927 15:01:38.740211  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.465771 (* 1 = 0.465771 loss)
I0927 15:01:38.740217  3463 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I0927 15:01:52.927203  3463 solver.cpp:218] Iteration 5100 (7.04873 iter/s, 14.1869s/100 iters), loss = 0.393534
I0927 15:01:52.927244  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.393534 (* 1 = 0.393534 loss)
I0927 15:01:52.927250  3463 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I0927 15:02:07.125241  3463 solver.cpp:218] Iteration 5200 (7.04327 iter/s, 14.198s/100 iters), loss = 0.39738
I0927 15:02:07.125344  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.39738 (* 1 = 0.39738 loss)
I0927 15:02:07.125361  3463 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I0927 15:02:21.322474  3463 solver.cpp:218] Iteration 5300 (7.0437 iter/s, 14.1971s/100 iters), loss = 0.490333
I0927 15:02:21.322505  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.490333 (* 1 = 0.490333 loss)
I0927 15:02:21.322523  3463 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I0927 15:02:35.515991  3463 solver.cpp:218] Iteration 5400 (7.04551 iter/s, 14.1934s/100 iters), loss = 0.362521
I0927 15:02:35.516021  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362521 (* 1 = 0.362521 loss)
I0927 15:02:35.516026  3463 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I0927 15:02:49.007294  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:02:49.576665  3463 solver.cpp:330] Iteration 5500, Testing net (#0)
I0927 15:02:52.921502  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:02:53.061333  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7074
I0927 15:02:53.061360  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.823323 (* 1 = 0.823323 loss)
I0927 15:02:53.201596  3463 solver.cpp:218] Iteration 5500 (5.65434 iter/s, 17.6855s/100 iters), loss = 0.393553
I0927 15:02:53.201624  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.393553 (* 1 = 0.393553 loss)
I0927 15:02:53.201632  3463 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I0927 15:03:07.379226  3463 solver.cpp:218] Iteration 5600 (7.0534 iter/s, 14.1776s/100 iters), loss = 0.276974
I0927 15:03:07.379256  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276974 (* 1 = 0.276974 loss)
I0927 15:03:07.379262  3463 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I0927 15:03:21.557276  3463 solver.cpp:218] Iteration 5700 (7.05319 iter/s, 14.178s/100 iters), loss = 0.436186
I0927 15:03:21.557394  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.436186 (* 1 = 0.436186 loss)
I0927 15:03:21.557410  3463 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I0927 15:03:35.738142  3463 solver.cpp:218] Iteration 5800 (7.05184 iter/s, 14.1807s/100 iters), loss = 0.444202
I0927 15:03:35.738180  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.444202 (* 1 = 0.444202 loss)
I0927 15:03:35.738188  3463 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I0927 15:03:49.916553  3463 solver.cpp:218] Iteration 5900 (7.05302 iter/s, 14.1783s/100 iters), loss = 0.366472
I0927 15:03:49.916584  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366472 (* 1 = 0.366472 loss)
I0927 15:03:49.916590  3463 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I0927 15:04:03.389001  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:04:03.955938  3463 solver.cpp:330] Iteration 6000, Testing net (#0)
I0927 15:04:07.299940  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:04:07.438899  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7356
I0927 15:04:07.438923  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.727262 (* 1 = 0.727262 loss)
I0927 15:04:07.579653  3463 solver.cpp:218] Iteration 6000 (5.66155 iter/s, 17.663s/100 iters), loss = 0.363627
I0927 15:04:07.579680  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.363627 (* 1 = 0.363627 loss)
I0927 15:04:07.579687  3463 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I0927 15:04:21.765194  3463 solver.cpp:218] Iteration 6100 (7.04947 iter/s, 14.1855s/100 iters), loss = 0.321011
I0927 15:04:21.765225  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.321011 (* 1 = 0.321011 loss)
I0927 15:04:21.765231  3463 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I0927 15:04:35.951170  3463 solver.cpp:218] Iteration 6200 (7.04926 iter/s, 14.1859s/100 iters), loss = 0.345647
I0927 15:04:35.951273  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.345647 (* 1 = 0.345647 loss)
I0927 15:04:35.951282  3463 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I0927 15:04:50.133663  3463 solver.cpp:218] Iteration 6300 (7.05102 iter/s, 14.1824s/100 iters), loss = 0.428279
I0927 15:04:50.133694  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.428279 (* 1 = 0.428279 loss)
I0927 15:04:50.133710  3463 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I0927 15:05:04.317626  3463 solver.cpp:218] Iteration 6400 (7.05025 iter/s, 14.1839s/100 iters), loss = 0.363205
I0927 15:05:04.317657  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.363205 (* 1 = 0.363205 loss)
I0927 15:05:04.317663  3463 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I0927 15:05:17.790957  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:05:18.357578  3463 solver.cpp:330] Iteration 6500, Testing net (#0)
I0927 15:05:21.702381  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:05:21.841954  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7376
I0927 15:05:21.841980  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.762187 (* 1 = 0.762187 loss)
I0927 15:05:21.982534  3463 solver.cpp:218] Iteration 6500 (5.66097 iter/s, 17.6648s/100 iters), loss = 0.299772
I0927 15:05:21.982563  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299772 (* 1 = 0.299772 loss)
I0927 15:05:21.982569  3463 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I0927 15:05:36.146436  3463 solver.cpp:218] Iteration 6600 (7.06024 iter/s, 14.1638s/100 iters), loss = 0.452469
I0927 15:05:36.146467  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.452469 (* 1 = 0.452469 loss)
I0927 15:05:36.146483  3463 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I0927 15:05:50.319228  3463 solver.cpp:218] Iteration 6700 (7.05581 iter/s, 14.1727s/100 iters), loss = 0.336398
I0927 15:05:50.319315  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336398 (* 1 = 0.336398 loss)
I0927 15:05:50.319326  3463 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I0927 15:06:04.494377  3463 solver.cpp:218] Iteration 6800 (7.05467 iter/s, 14.175s/100 iters), loss = 0.51659
I0927 15:06:04.494407  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.51659 (* 1 = 0.51659 loss)
I0927 15:06:04.494413  3463 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I0927 15:06:18.668946  3463 solver.cpp:218] Iteration 6900 (7.05493 iter/s, 14.1745s/100 iters), loss = 0.442961
I0927 15:06:18.668977  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.442961 (* 1 = 0.442961 loss)
I0927 15:06:18.668983  3463 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I0927 15:06:32.146173  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:06:32.714241  3463 solver.cpp:330] Iteration 7000, Testing net (#0)
I0927 15:06:36.058344  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:06:36.198248  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7257
I0927 15:06:36.198276  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.813977 (* 1 = 0.813977 loss)
I0927 15:06:36.339287  3463 solver.cpp:218] Iteration 7000 (5.65923 iter/s, 17.6703s/100 iters), loss = 0.37514
I0927 15:06:36.339314  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.37514 (* 1 = 0.37514 loss)
I0927 15:06:36.339321  3463 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I0927 15:06:50.525153  3463 solver.cpp:218] Iteration 7100 (7.0493 iter/s, 14.1858s/100 iters), loss = 0.341188
I0927 15:06:50.525183  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.341188 (* 1 = 0.341188 loss)
I0927 15:06:50.525189  3463 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I0927 15:07:04.711304  3463 solver.cpp:218] Iteration 7200 (7.04917 iter/s, 14.1861s/100 iters), loss = 0.323867
I0927 15:07:04.711469  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323867 (* 1 = 0.323867 loss)
I0927 15:07:04.711480  3463 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I0927 15:07:18.900149  3463 solver.cpp:218] Iteration 7300 (7.04789 iter/s, 14.1886s/100 iters), loss = 0.41351
I0927 15:07:18.900182  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.41351 (* 1 = 0.41351 loss)
I0927 15:07:18.900187  3463 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I0927 15:07:33.087568  3463 solver.cpp:218] Iteration 7400 (7.04853 iter/s, 14.1873s/100 iters), loss = 0.331462
I0927 15:07:33.087599  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331462 (* 1 = 0.331462 loss)
I0927 15:07:33.087604  3463 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I0927 15:07:46.576508  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:07:47.144454  3463 solver.cpp:330] Iteration 7500, Testing net (#0)
I0927 15:07:50.491282  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:07:50.630465  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7516
I0927 15:07:50.630491  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.726264 (* 1 = 0.726264 loss)
I0927 15:07:50.770563  3463 solver.cpp:218] Iteration 7500 (5.65518 iter/s, 17.6829s/100 iters), loss = 0.376938
I0927 15:07:50.770591  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.376938 (* 1 = 0.376938 loss)
I0927 15:07:50.770598  3463 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I0927 15:08:04.958132  3463 solver.cpp:218] Iteration 7600 (7.04846 iter/s, 14.1875s/100 iters), loss = 0.340577
I0927 15:08:04.958161  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340577 (* 1 = 0.340577 loss)
I0927 15:08:04.958168  3463 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I0927 15:08:19.148458  3463 solver.cpp:218] Iteration 7700 (7.04709 iter/s, 14.1903s/100 iters), loss = 0.380825
I0927 15:08:19.148571  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.380825 (* 1 = 0.380825 loss)
I0927 15:08:19.148592  3463 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I0927 15:08:33.340482  3463 solver.cpp:218] Iteration 7800 (7.04628 iter/s, 14.1919s/100 iters), loss = 0.319345
I0927 15:08:33.340513  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319345 (* 1 = 0.319345 loss)
I0927 15:08:33.340519  3463 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I0927 15:08:47.532672  3463 solver.cpp:218] Iteration 7900 (7.04616 iter/s, 14.1921s/100 iters), loss = 0.382169
I0927 15:08:47.532703  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.382169 (* 1 = 0.382169 loss)
I0927 15:08:47.532709  3463 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I0927 15:09:01.024098  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:09:01.592121  3463 solver.cpp:330] Iteration 8000, Testing net (#0)
I0927 15:09:04.937554  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:09:05.077601  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7537
I0927 15:09:05.077627  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.717271 (* 1 = 0.717271 loss)
I0927 15:09:05.219036  3463 solver.cpp:218] Iteration 8000 (5.6541 iter/s, 17.6863s/100 iters), loss = 0.347975
I0927 15:09:05.219064  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.347975 (* 1 = 0.347975 loss)
I0927 15:09:05.219071  3463 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I0927 15:09:19.421053  3463 solver.cpp:218] Iteration 8100 (7.04129 iter/s, 14.2019s/100 iters), loss = 0.338519
I0927 15:09:19.421084  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338519 (* 1 = 0.338519 loss)
I0927 15:09:19.421092  3463 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I0927 15:09:33.626307  3463 solver.cpp:218] Iteration 8200 (7.03968 iter/s, 14.2052s/100 iters), loss = 0.326124
I0927 15:09:33.626438  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326124 (* 1 = 0.326124 loss)
I0927 15:09:33.626456  3463 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I0927 15:09:47.827811  3463 solver.cpp:218] Iteration 8300 (7.04159 iter/s, 14.2013s/100 iters), loss = 0.47873
I0927 15:09:47.827841  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.47873 (* 1 = 0.47873 loss)
I0927 15:09:47.827847  3463 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I0927 15:10:02.027799  3463 solver.cpp:218] Iteration 8400 (7.04229 iter/s, 14.1999s/100 iters), loss = 0.27727
I0927 15:10:02.027830  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27727 (* 1 = 0.27727 loss)
I0927 15:10:02.027835  3463 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I0927 15:10:15.523665  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:10:16.091976  3463 solver.cpp:330] Iteration 8500, Testing net (#0)
I0927 15:10:19.441928  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:10:19.582319  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7716
I0927 15:10:19.582347  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.638781 (* 1 = 0.638781 loss)
I0927 15:10:19.722843  3463 solver.cpp:218] Iteration 8500 (5.65133 iter/s, 17.695s/100 iters), loss = 0.281837
I0927 15:10:19.722872  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281837 (* 1 = 0.281837 loss)
I0927 15:10:19.722877  3463 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I0927 15:10:33.932703  3463 solver.cpp:218] Iteration 8600 (7.0374 iter/s, 14.2098s/100 iters), loss = 0.330318
I0927 15:10:33.932734  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330318 (* 1 = 0.330318 loss)
I0927 15:10:33.932740  3463 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I0927 15:10:48.143702  3463 solver.cpp:218] Iteration 8700 (7.03684 iter/s, 14.2109s/100 iters), loss = 0.349974
I0927 15:10:48.143820  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349974 (* 1 = 0.349974 loss)
I0927 15:10:48.143836  3463 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I0927 15:11:02.356665  3463 solver.cpp:218] Iteration 8800 (7.03591 iter/s, 14.2128s/100 iters), loss = 0.323007
I0927 15:11:02.356695  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323007 (* 1 = 0.323007 loss)
I0927 15:11:02.356701  3463 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I0927 15:11:16.566306  3463 solver.cpp:218] Iteration 8900 (7.03751 iter/s, 14.2096s/100 iters), loss = 0.277093
I0927 15:11:16.566337  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277093 (* 1 = 0.277093 loss)
I0927 15:11:16.566344  3463 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I0927 15:11:30.078624  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:11:30.648406  3463 solver.cpp:330] Iteration 9000, Testing net (#0)
I0927 15:11:33.998126  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:11:34.138170  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8119
I0927 15:11:34.138207  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.557718 (* 1 = 0.557718 loss)
I0927 15:11:34.278398  3463 solver.cpp:218] Iteration 9000 (5.64589 iter/s, 17.712s/100 iters), loss = 0.285023
I0927 15:11:34.278426  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285023 (* 1 = 0.285023 loss)
I0927 15:11:34.278434  3463 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I0927 15:11:48.476519  3463 solver.cpp:218] Iteration 9100 (7.04322 iter/s, 14.1981s/100 iters), loss = 0.211166
I0927 15:11:48.476560  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211166 (* 1 = 0.211166 loss)
I0927 15:11:48.476567  3463 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I0927 15:12:02.683898  3463 solver.cpp:218] Iteration 9200 (7.03863 iter/s, 14.2073s/100 iters), loss = 0.336941
I0927 15:12:02.683971  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336941 (* 1 = 0.336941 loss)
I0927 15:12:02.683979  3463 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I0927 15:12:16.887001  3463 solver.cpp:218] Iteration 9300 (7.04077 iter/s, 14.203s/100 iters), loss = 0.401258
I0927 15:12:16.887043  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.401258 (* 1 = 0.401258 loss)
I0927 15:12:16.887049  3463 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I0927 15:12:31.086015  3463 solver.cpp:218] Iteration 9400 (7.04278 iter/s, 14.1989s/100 iters), loss = 0.263
I0927 15:12:31.086056  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263 (* 1 = 0.263 loss)
I0927 15:12:31.086062  3463 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I0927 15:12:44.586022  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:12:45.155403  3463 solver.cpp:330] Iteration 9500, Testing net (#0)
I0927 15:12:48.506219  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:12:48.646050  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8035
I0927 15:12:48.646087  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.590048 (* 1 = 0.590048 loss)
I0927 15:12:48.786170  3463 solver.cpp:218] Iteration 9500 (5.6497 iter/s, 17.7001s/100 iters), loss = 0.251688
I0927 15:12:48.786197  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251688 (* 1 = 0.251688 loss)
I0927 15:12:48.786203  3463 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I0927 15:13:02.984673  3463 solver.cpp:218] Iteration 9600 (7.04303 iter/s, 14.1984s/100 iters), loss = 0.370045
I0927 15:13:02.984715  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.370045 (* 1 = 0.370045 loss)
I0927 15:13:02.984721  3463 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I0927 15:13:17.187821  3463 solver.cpp:218] Iteration 9700 (7.04073 iter/s, 14.2031s/100 iters), loss = 0.38224
I0927 15:13:17.187965  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.38224 (* 1 = 0.38224 loss)
I0927 15:13:17.187973  3463 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I0927 15:13:31.392449  3463 solver.cpp:218] Iteration 9800 (7.04005 iter/s, 14.2045s/100 iters), loss = 0.268856
I0927 15:13:31.392479  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268856 (* 1 = 0.268856 loss)
I0927 15:13:31.392485  3463 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I0927 15:13:45.594789  3463 solver.cpp:218] Iteration 9900 (7.04113 iter/s, 14.2023s/100 iters), loss = 0.335143
I0927 15:13:45.594820  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335143 (* 1 = 0.335143 loss)
I0927 15:13:45.594826  3463 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I0927 15:13:59.093806  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:13:59.662343  3463 solver.cpp:330] Iteration 10000, Testing net (#0)
I0927 15:14:03.014050  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:14:03.154175  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7492
I0927 15:14:03.154201  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.749973 (* 1 = 0.749973 loss)
I0927 15:14:03.294605  3463 solver.cpp:218] Iteration 10000 (5.6498 iter/s, 17.6997s/100 iters), loss = 0.252969
I0927 15:14:03.294633  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252969 (* 1 = 0.252969 loss)
I0927 15:14:03.294641  3463 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I0927 15:14:17.509141  3463 solver.cpp:218] Iteration 10100 (7.03508 iter/s, 14.2145s/100 iters), loss = 0.410414
I0927 15:14:17.509181  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.410415 (* 1 = 0.410415 loss)
I0927 15:14:17.509187  3463 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I0927 15:14:31.727440  3463 solver.cpp:218] Iteration 10200 (7.03323 iter/s, 14.2182s/100 iters), loss = 0.21779
I0927 15:14:31.727558  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21779 (* 1 = 0.21779 loss)
I0927 15:14:31.727576  3463 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I0927 15:14:45.946557  3463 solver.cpp:218] Iteration 10300 (7.03286 iter/s, 14.219s/100 iters), loss = 0.356555
I0927 15:14:45.946599  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.356555 (* 1 = 0.356555 loss)
I0927 15:14:45.946604  3463 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I0927 15:15:00.163529  3463 solver.cpp:218] Iteration 10400 (7.03389 iter/s, 14.2169s/100 iters), loss = 0.234287
I0927 15:15:00.163564  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234287 (* 1 = 0.234287 loss)
I0927 15:15:00.163571  3463 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I0927 15:15:13.675240  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:15:14.244841  3463 solver.cpp:330] Iteration 10500, Testing net (#0)
I0927 15:15:17.597111  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:15:17.737263  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.809
I0927 15:15:17.737299  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.541489 (* 1 = 0.541489 loss)
I0927 15:15:17.877948  3463 solver.cpp:218] Iteration 10500 (5.64514 iter/s, 17.7143s/100 iters), loss = 0.243233
I0927 15:15:17.877976  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243233 (* 1 = 0.243233 loss)
I0927 15:15:17.877984  3463 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I0927 15:15:32.083101  3463 solver.cpp:218] Iteration 10600 (7.03973 iter/s, 14.2051s/100 iters), loss = 0.304788
I0927 15:15:32.083142  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304788 (* 1 = 0.304788 loss)
I0927 15:15:32.083147  3463 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I0927 15:15:46.288475  3463 solver.cpp:218] Iteration 10700 (7.03963 iter/s, 14.2053s/100 iters), loss = 0.350404
I0927 15:15:46.288616  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350404 (* 1 = 0.350404 loss)
I0927 15:15:46.288625  3463 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I0927 15:16:00.498610  3463 solver.cpp:218] Iteration 10800 (7.03732 iter/s, 14.21s/100 iters), loss = 0.337829
I0927 15:16:00.498641  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337829 (* 1 = 0.337829 loss)
I0927 15:16:00.498647  3463 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I0927 15:16:14.706413  3463 solver.cpp:218] Iteration 10900 (7.03842 iter/s, 14.2077s/100 iters), loss = 0.433636
I0927 15:16:14.706459  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.433636 (* 1 = 0.433636 loss)
I0927 15:16:14.706466  3463 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I0927 15:16:28.208473  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:16:28.776937  3463 solver.cpp:330] Iteration 11000, Testing net (#0)
I0927 15:16:32.128834  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:16:32.268882  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8176
I0927 15:16:32.268918  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.545635 (* 1 = 0.545635 loss)
I0927 15:16:32.409886  3463 solver.cpp:218] Iteration 11000 (5.64864 iter/s, 17.7034s/100 iters), loss = 0.311198
I0927 15:16:32.409914  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311198 (* 1 = 0.311198 loss)
I0927 15:16:32.409921  3463 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I0927 15:16:46.616464  3463 solver.cpp:218] Iteration 11100 (7.03903 iter/s, 14.2065s/100 iters), loss = 0.27752
I0927 15:16:46.616506  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27752 (* 1 = 0.27752 loss)
I0927 15:16:46.616513  3463 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I0927 15:17:00.820952  3463 solver.cpp:218] Iteration 11200 (7.04007 iter/s, 14.2044s/100 iters), loss = 0.313761
I0927 15:17:00.821027  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313761 (* 1 = 0.313761 loss)
I0927 15:17:00.821033  3463 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I0927 15:17:15.032644  3463 solver.cpp:218] Iteration 11300 (7.03652 iter/s, 14.2116s/100 iters), loss = 0.195199
I0927 15:17:15.032686  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195199 (* 1 = 0.195199 loss)
I0927 15:17:15.032692  3463 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I0927 15:17:29.238864  3463 solver.cpp:218] Iteration 11400 (7.03921 iter/s, 14.2061s/100 iters), loss = 0.309975
I0927 15:17:29.238906  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309975 (* 1 = 0.309975 loss)
I0927 15:17:29.238912  3463 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I0927 15:17:42.743347  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:17:43.312680  3463 solver.cpp:330] Iteration 11500, Testing net (#0)
I0927 15:17:46.665376  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:17:46.805053  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7598
I0927 15:17:46.805090  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.72505 (* 1 = 0.72505 loss)
I0927 15:17:46.946125  3463 solver.cpp:218] Iteration 11500 (5.64743 iter/s, 17.7072s/100 iters), loss = 0.253937
I0927 15:17:46.946151  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253937 (* 1 = 0.253937 loss)
I0927 15:17:46.946159  3463 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I0927 15:18:01.141062  3463 solver.cpp:218] Iteration 11600 (7.0448 iter/s, 14.1949s/100 iters), loss = 0.450119
I0927 15:18:01.141103  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.450119 (* 1 = 0.450119 loss)
I0927 15:18:01.141109  3463 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I0927 15:18:15.337035  3463 solver.cpp:218] Iteration 11700 (7.04429 iter/s, 14.1959s/100 iters), loss = 0.294804
I0927 15:18:15.337123  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294804 (* 1 = 0.294804 loss)
I0927 15:18:15.337131  3463 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I0927 15:18:29.535125  3463 solver.cpp:218] Iteration 11800 (7.04326 iter/s, 14.198s/100 iters), loss = 0.305874
I0927 15:18:29.535156  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305874 (* 1 = 0.305874 loss)
I0927 15:18:29.535163  3463 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I0927 15:18:43.735458  3463 solver.cpp:218] Iteration 11900 (7.04212 iter/s, 14.2003s/100 iters), loss = 0.29173
I0927 15:18:43.735505  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29173 (* 1 = 0.29173 loss)
I0927 15:18:43.735513  3463 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I0927 15:18:57.230001  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:18:57.799252  3463 solver.cpp:330] Iteration 12000, Testing net (#0)
I0927 15:19:01.153558  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:19:01.294173  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7931
I0927 15:19:01.294209  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.633993 (* 1 = 0.633993 loss)
I0927 15:19:01.435438  3463 solver.cpp:218] Iteration 12000 (5.64975 iter/s, 17.6999s/100 iters), loss = 0.252139
I0927 15:19:01.435468  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252139 (* 1 = 0.252139 loss)
I0927 15:19:01.435475  3463 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I0927 15:19:15.643163  3463 solver.cpp:218] Iteration 12100 (7.03846 iter/s, 14.2077s/100 iters), loss = 0.280405
I0927 15:19:15.643204  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280405 (* 1 = 0.280405 loss)
I0927 15:19:15.643210  3463 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I0927 15:19:29.849746  3463 solver.cpp:218] Iteration 12200 (7.03903 iter/s, 14.2065s/100 iters), loss = 0.373712
I0927 15:19:29.849831  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.373712 (* 1 = 0.373712 loss)
I0927 15:19:29.849848  3463 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I0927 15:19:44.060875  3463 solver.cpp:218] Iteration 12300 (7.0368 iter/s, 14.211s/100 iters), loss = 0.361139
I0927 15:19:44.060925  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.361139 (* 1 = 0.361139 loss)
I0927 15:19:44.060931  3463 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I0927 15:19:58.277293  3463 solver.cpp:218] Iteration 12400 (7.03416 iter/s, 14.2163s/100 iters), loss = 0.203903
I0927 15:19:58.277324  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203903 (* 1 = 0.203903 loss)
I0927 15:19:58.277331  3463 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I0927 15:20:11.786223  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:20:12.355247  3463 solver.cpp:330] Iteration 12500, Testing net (#0)
I0927 15:20:15.707464  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:20:15.847379  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8061
I0927 15:20:15.847416  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.593619 (* 1 = 0.593619 loss)
I0927 15:20:15.988471  3463 solver.cpp:218] Iteration 12500 (5.64618 iter/s, 17.7111s/100 iters), loss = 0.230422
I0927 15:20:15.988499  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230422 (* 1 = 0.230422 loss)
I0927 15:20:15.988507  3463 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I0927 15:20:30.195926  3463 solver.cpp:218] Iteration 12600 (7.03859 iter/s, 14.2074s/100 iters), loss = 0.219333
I0927 15:20:30.195958  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219333 (* 1 = 0.219333 loss)
I0927 15:20:30.195964  3463 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I0927 15:20:44.411758  3463 solver.cpp:218] Iteration 12700 (7.03444 iter/s, 14.2158s/100 iters), loss = 0.27502
I0927 15:20:44.411891  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27502 (* 1 = 0.27502 loss)
I0927 15:20:44.411900  3463 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I0927 15:20:58.626876  3463 solver.cpp:218] Iteration 12800 (7.03485 iter/s, 14.215s/100 iters), loss = 0.301677
I0927 15:20:58.626907  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301677 (* 1 = 0.301677 loss)
I0927 15:20:58.626914  3463 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I0927 15:21:12.845819  3463 solver.cpp:218] Iteration 12900 (7.03291 iter/s, 14.2189s/100 iters), loss = 0.240097
I0927 15:21:12.845860  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240097 (* 1 = 0.240097 loss)
I0927 15:21:12.845865  3463 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I0927 15:21:26.351275  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:21:26.919637  3463 solver.cpp:330] Iteration 13000, Testing net (#0)
I0927 15:21:30.270927  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:21:30.410987  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7667
I0927 15:21:30.411026  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.725612 (* 1 = 0.725612 loss)
I0927 15:21:30.552096  3463 solver.cpp:218] Iteration 13000 (5.64774 iter/s, 17.7062s/100 iters), loss = 0.226304
I0927 15:21:30.552124  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226304 (* 1 = 0.226304 loss)
I0927 15:21:30.552131  3463 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I0927 15:21:44.757030  3463 solver.cpp:218] Iteration 13100 (7.03984 iter/s, 14.2049s/100 iters), loss = 0.241881
I0927 15:21:44.757071  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241881 (* 1 = 0.241881 loss)
I0927 15:21:44.757077  3463 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I0927 15:21:58.965499  3463 solver.cpp:218] Iteration 13200 (7.03809 iter/s, 14.2084s/100 iters), loss = 0.29458
I0927 15:21:58.965574  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29458 (* 1 = 0.29458 loss)
I0927 15:21:58.965591  3463 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I0927 15:22:13.176719  3463 solver.cpp:218] Iteration 13300 (7.03675 iter/s, 14.2111s/100 iters), loss = 0.325201
I0927 15:22:13.176760  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325201 (* 1 = 0.325201 loss)
I0927 15:22:13.176766  3463 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I0927 15:22:27.383847  3463 solver.cpp:218] Iteration 13400 (7.03876 iter/s, 14.207s/100 iters), loss = 0.316059
I0927 15:22:27.383889  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316059 (* 1 = 0.316059 loss)
I0927 15:22:27.383895  3463 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I0927 15:22:40.885334  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:22:41.454335  3463 solver.cpp:330] Iteration 13500, Testing net (#0)
I0927 15:22:44.806325  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:22:44.946213  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7891
I0927 15:22:44.946247  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.649979 (* 1 = 0.649979 loss)
I0927 15:22:45.086683  3463 solver.cpp:218] Iteration 13500 (5.64884 iter/s, 17.7027s/100 iters), loss = 0.204963
I0927 15:22:45.086709  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204963 (* 1 = 0.204963 loss)
I0927 15:22:45.086716  3463 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I0927 15:22:59.308696  3463 solver.cpp:218] Iteration 13600 (7.03138 iter/s, 14.222s/100 iters), loss = 0.330615
I0927 15:22:59.308727  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330615 (* 1 = 0.330615 loss)
I0927 15:22:59.308732  3463 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I0927 15:23:13.520972  3463 solver.cpp:218] Iteration 13700 (7.0362 iter/s, 14.2122s/100 iters), loss = 0.275817
I0927 15:23:13.521095  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275817 (* 1 = 0.275817 loss)
I0927 15:23:13.521113  3463 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I0927 15:23:27.745167  3463 solver.cpp:218] Iteration 13800 (7.03035 iter/s, 14.224s/100 iters), loss = 0.437452
I0927 15:23:27.745198  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.437452 (* 1 = 0.437452 loss)
I0927 15:23:27.745204  3463 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I0927 15:23:41.963021  3463 solver.cpp:218] Iteration 13900 (7.03344 iter/s, 14.2178s/100 iters), loss = 0.398229
I0927 15:23:41.963053  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.398229 (* 1 = 0.398229 loss)
I0927 15:23:41.963062  3463 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I0927 15:23:55.467587  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:23:56.036403  3463 solver.cpp:330] Iteration 14000, Testing net (#0)
I0927 15:23:59.387312  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:23:59.527467  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.666
I0927 15:23:59.527493  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.26736 (* 1 = 1.26736 loss)
I0927 15:23:59.668560  3463 solver.cpp:218] Iteration 14000 (5.64797 iter/s, 17.7055s/100 iters), loss = 0.325749
I0927 15:23:59.668587  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325749 (* 1 = 0.325749 loss)
I0927 15:23:59.668594  3463 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I0927 15:24:13.866158  3463 solver.cpp:218] Iteration 14100 (7.04348 iter/s, 14.1975s/100 iters), loss = 0.219533
I0927 15:24:13.866199  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219533 (* 1 = 0.219533 loss)
I0927 15:24:13.866205  3463 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I0927 15:24:28.076103  3463 solver.cpp:218] Iteration 14200 (7.03737 iter/s, 14.2099s/100 iters), loss = 0.291904
I0927 15:24:28.076180  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291904 (* 1 = 0.291904 loss)
I0927 15:24:28.076189  3463 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I0927 15:24:42.284307  3463 solver.cpp:218] Iteration 14300 (7.03824 iter/s, 14.2081s/100 iters), loss = 0.235204
I0927 15:24:42.284349  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235204 (* 1 = 0.235204 loss)
I0927 15:24:42.284355  3463 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I0927 15:24:56.481608  3463 solver.cpp:218] Iteration 14400 (7.04363 iter/s, 14.1972s/100 iters), loss = 0.169636
I0927 15:24:56.481650  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169637 (* 1 = 0.169637 loss)
I0927 15:24:56.481657  3463 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I0927 15:25:09.975847  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:25:10.545331  3463 solver.cpp:330] Iteration 14500, Testing net (#0)
I0927 15:25:13.896404  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:25:14.036595  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7668
I0927 15:25:14.036631  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.775229 (* 1 = 0.775229 loss)
I0927 15:25:14.178067  3463 solver.cpp:218] Iteration 14500 (5.65088 iter/s, 17.6964s/100 iters), loss = 0.191296
I0927 15:25:14.178095  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191296 (* 1 = 0.191296 loss)
I0927 15:25:14.178102  3463 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I0927 15:25:28.382756  3463 solver.cpp:218] Iteration 14600 (7.03996 iter/s, 14.2046s/100 iters), loss = 0.210507
I0927 15:25:28.382797  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210507 (* 1 = 0.210507 loss)
I0927 15:25:28.382803  3463 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I0927 15:25:42.592730  3463 solver.cpp:218] Iteration 14700 (7.03735 iter/s, 14.2099s/100 iters), loss = 0.359902
I0927 15:25:42.592813  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.359902 (* 1 = 0.359902 loss)
I0927 15:25:42.592828  3463 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I0927 15:25:56.797880  3463 solver.cpp:218] Iteration 14800 (7.03976 iter/s, 14.205s/100 iters), loss = 0.204186
I0927 15:25:56.797909  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204186 (* 1 = 0.204186 loss)
I0927 15:25:56.797914  3463 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I0927 15:26:11.004581  3463 solver.cpp:218] Iteration 14900 (7.03896 iter/s, 14.2066s/100 iters), loss = 0.169171
I0927 15:26:11.004623  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169172 (* 1 = 0.169172 loss)
I0927 15:26:11.004631  3463 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I0927 15:26:24.504487  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:26:25.073283  3463 solver.cpp:330] Iteration 15000, Testing net (#0)
I0927 15:26:28.424448  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:26:28.564641  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7268
I0927 15:26:28.564679  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.915697 (* 1 = 0.915697 loss)
I0927 15:26:28.705577  3463 solver.cpp:218] Iteration 15000 (5.64943 iter/s, 17.7009s/100 iters), loss = 0.278262
I0927 15:26:28.705605  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278262 (* 1 = 0.278262 loss)
I0927 15:26:28.705611  3463 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I0927 15:26:42.921425  3463 solver.cpp:218] Iteration 15100 (7.03444 iter/s, 14.2158s/100 iters), loss = 0.247381
I0927 15:26:42.921468  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247381 (* 1 = 0.247381 loss)
I0927 15:26:42.921473  3463 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I0927 15:26:57.142045  3463 solver.cpp:218] Iteration 15200 (7.03208 iter/s, 14.2205s/100 iters), loss = 0.347813
I0927 15:26:57.142130  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.347813 (* 1 = 0.347813 loss)
I0927 15:26:57.142146  3463 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I0927 15:27:11.355648  3463 solver.cpp:218] Iteration 15300 (7.03557 iter/s, 14.2135s/100 iters), loss = 0.189825
I0927 15:27:11.355677  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189825 (* 1 = 0.189825 loss)
I0927 15:27:11.355684  3463 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I0927 15:27:25.567673  3463 solver.cpp:218] Iteration 15400 (7.03633 iter/s, 14.212s/100 iters), loss = 0.241059
I0927 15:27:25.567714  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24106 (* 1 = 0.24106 loss)
I0927 15:27:25.567720  3463 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I0927 15:27:39.079716  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:27:39.649379  3463 solver.cpp:330] Iteration 15500, Testing net (#0)
I0927 15:27:43.000669  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:27:43.140880  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.75
I0927 15:27:43.140918  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.799474 (* 1 = 0.799474 loss)
I0927 15:27:43.281844  3463 solver.cpp:218] Iteration 15500 (5.64523 iter/s, 17.7141s/100 iters), loss = 0.21788
I0927 15:27:43.281874  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21788 (* 1 = 0.21788 loss)
I0927 15:27:43.281882  3463 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I0927 15:27:57.486552  3463 solver.cpp:218] Iteration 15600 (7.03996 iter/s, 14.2046s/100 iters), loss = 0.145845
I0927 15:27:57.486594  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145845 (* 1 = 0.145845 loss)
I0927 15:27:57.486600  3463 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I0927 15:28:11.693104  3463 solver.cpp:218] Iteration 15700 (7.03905 iter/s, 14.2065s/100 iters), loss = 0.247641
I0927 15:28:11.693212  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247641 (* 1 = 0.247641 loss)
I0927 15:28:11.693229  3463 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I0927 15:28:25.894666  3463 solver.cpp:218] Iteration 15800 (7.04155 iter/s, 14.2014s/100 iters), loss = 0.254926
I0927 15:28:25.894697  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254926 (* 1 = 0.254926 loss)
I0927 15:28:25.894702  3463 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I0927 15:28:40.100244  3463 solver.cpp:218] Iteration 15900 (7.03952 iter/s, 14.2055s/100 iters), loss = 0.189977
I0927 15:28:40.100275  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189977 (* 1 = 0.189977 loss)
I0927 15:28:40.100281  3463 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I0927 15:28:53.601572  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:28:54.169777  3463 solver.cpp:330] Iteration 16000, Testing net (#0)
I0927 15:28:57.521313  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:28:57.661772  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8245
I0927 15:28:57.661803  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.594658 (* 1 = 0.594658 loss)
I0927 15:28:57.802858  3463 solver.cpp:218] Iteration 16000 (5.64891 iter/s, 17.7025s/100 iters), loss = 0.241065
I0927 15:28:57.802888  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241065 (* 1 = 0.241065 loss)
I0927 15:28:57.802896  3463 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I0927 15:29:12.007922  3463 solver.cpp:218] Iteration 16100 (7.03978 iter/s, 14.205s/100 iters), loss = 0.258185
I0927 15:29:12.007963  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258185 (* 1 = 0.258185 loss)
I0927 15:29:12.007969  3463 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I0927 15:29:26.217067  3463 solver.cpp:218] Iteration 16200 (7.03776 iter/s, 14.2091s/100 iters), loss = 0.356172
I0927 15:29:26.217197  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.356172 (* 1 = 0.356172 loss)
I0927 15:29:26.217206  3463 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I0927 15:29:40.425321  3463 solver.cpp:218] Iteration 16300 (7.03825 iter/s, 14.2081s/100 iters), loss = 0.332693
I0927 15:29:40.425362  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.332693 (* 1 = 0.332693 loss)
I0927 15:29:40.425369  3463 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I0927 15:29:54.632627  3463 solver.cpp:218] Iteration 16400 (7.03867 iter/s, 14.2072s/100 iters), loss = 0.193231
I0927 15:29:54.632668  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193231 (* 1 = 0.193231 loss)
I0927 15:29:54.632673  3463 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I0927 15:30:08.140894  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:30:08.709924  3463 solver.cpp:330] Iteration 16500, Testing net (#0)
I0927 15:30:12.061136  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:30:12.201244  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7856
I0927 15:30:12.201280  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.680126 (* 1 = 0.680126 loss)
I0927 15:30:12.341707  3463 solver.cpp:218] Iteration 16500 (5.64685 iter/s, 17.709s/100 iters), loss = 0.252031
I0927 15:30:12.341737  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252031 (* 1 = 0.252031 loss)
I0927 15:30:12.341744  3463 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I0927 15:30:26.538051  3463 solver.cpp:218] Iteration 16600 (7.0441 iter/s, 14.1963s/100 iters), loss = 0.22012
I0927 15:30:26.538094  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22012 (* 1 = 0.22012 loss)
I0927 15:30:26.538100  3463 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I0927 15:30:40.737776  3463 solver.cpp:218] Iteration 16700 (7.04243 iter/s, 14.1996s/100 iters), loss = 0.2313
I0927 15:30:40.737886  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2313 (* 1 = 0.2313 loss)
I0927 15:30:40.737903  3463 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I0927 15:30:54.933471  3463 solver.cpp:218] Iteration 16800 (7.04446 iter/s, 14.1955s/100 iters), loss = 0.260281
I0927 15:30:54.933502  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260281 (* 1 = 0.260281 loss)
I0927 15:30:54.933508  3463 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I0927 15:31:09.128541  3463 solver.cpp:218] Iteration 16900 (7.04473 iter/s, 14.195s/100 iters), loss = 0.20347
I0927 15:31:09.128581  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20347 (* 1 = 0.20347 loss)
I0927 15:31:09.128587  3463 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I0927 15:31:22.617138  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:31:23.185600  3463 solver.cpp:330] Iteration 17000, Testing net (#0)
I0927 15:31:26.536887  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:31:26.677076  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8267
I0927 15:31:26.677112  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.532429 (* 1 = 0.532429 loss)
I0927 15:31:26.817764  3463 solver.cpp:218] Iteration 17000 (5.65319 iter/s, 17.6891s/100 iters), loss = 0.27585
I0927 15:31:26.817793  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27585 (* 1 = 0.27585 loss)
I0927 15:31:26.817800  3463 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I0927 15:31:41.020000  3463 solver.cpp:218] Iteration 17100 (7.04118 iter/s, 14.2022s/100 iters), loss = 0.204476
I0927 15:31:41.020041  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204476 (* 1 = 0.204476 loss)
I0927 15:31:41.020047  3463 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I0927 15:31:55.228862  3463 solver.cpp:218] Iteration 17200 (7.0379 iter/s, 14.2088s/100 iters), loss = 0.279303
I0927 15:31:55.228935  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279303 (* 1 = 0.279303 loss)
I0927 15:31:55.228950  3463 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I0927 15:32:09.439596  3463 solver.cpp:218] Iteration 17300 (7.03699 iter/s, 14.2106s/100 iters), loss = 0.229374
I0927 15:32:09.439637  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229374 (* 1 = 0.229374 loss)
I0927 15:32:09.439642  3463 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I0927 15:32:23.652106  3463 solver.cpp:218] Iteration 17400 (7.03609 iter/s, 14.2124s/100 iters), loss = 0.165733
I0927 15:32:23.652146  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165733 (* 1 = 0.165733 loss)
I0927 15:32:23.652151  3463 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I0927 15:32:37.159749  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:32:37.728835  3463 solver.cpp:330] Iteration 17500, Testing net (#0)
I0927 15:32:41.079181  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:32:41.219004  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7845
I0927 15:32:41.219040  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.67972 (* 1 = 0.67972 loss)
I0927 15:32:41.359611  3463 solver.cpp:218] Iteration 17500 (5.64735 iter/s, 17.7074s/100 iters), loss = 0.185642
I0927 15:32:41.359637  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185642 (* 1 = 0.185642 loss)
I0927 15:32:41.359643  3463 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I0927 15:32:55.575809  3463 solver.cpp:218] Iteration 17600 (7.03426 iter/s, 14.2161s/100 iters), loss = 0.294812
I0927 15:32:55.575850  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294812 (* 1 = 0.294812 loss)
I0927 15:32:55.575856  3463 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I0927 15:33:09.793350  3463 solver.cpp:218] Iteration 17700 (7.0336 iter/s, 14.2175s/100 iters), loss = 0.260892
I0927 15:33:09.793445  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260892 (* 1 = 0.260892 loss)
I0927 15:33:09.793452  3463 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I0927 15:33:24.006770  3463 solver.cpp:218] Iteration 17800 (7.03567 iter/s, 14.2133s/100 iters), loss = 0.197952
I0927 15:33:24.006811  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197952 (* 1 = 0.197952 loss)
I0927 15:33:24.006817  3463 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I0927 15:33:38.223175  3463 solver.cpp:218] Iteration 17900 (7.03417 iter/s, 14.2163s/100 iters), loss = 0.152949
I0927 15:33:38.223204  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152949 (* 1 = 0.152949 loss)
I0927 15:33:38.223211  3463 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I0927 15:33:51.730250  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:33:52.298162  3463 solver.cpp:330] Iteration 18000, Testing net (#0)
I0927 15:33:55.647011  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:33:55.787112  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7881
I0927 15:33:55.787148  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.639594 (* 1 = 0.639594 loss)
I0927 15:33:55.928548  3463 solver.cpp:218] Iteration 18000 (5.64803 iter/s, 17.7053s/100 iters), loss = 0.223569
I0927 15:33:55.928578  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223569 (* 1 = 0.223569 loss)
I0927 15:33:55.928596  3463 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I0927 15:34:10.128653  3463 solver.cpp:218] Iteration 18100 (7.04223 iter/s, 14.2s/100 iters), loss = 0.34452
I0927 15:34:10.128693  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344519 (* 1 = 0.344519 loss)
I0927 15:34:10.128698  3463 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I0927 15:34:24.326114  3463 solver.cpp:218] Iteration 18200 (7.04355 iter/s, 14.1974s/100 iters), loss = 0.319379
I0927 15:34:24.326266  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319379 (* 1 = 0.319379 loss)
I0927 15:34:24.326273  3463 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I0927 15:34:38.528839  3463 solver.cpp:218] Iteration 18300 (7.04099 iter/s, 14.2025s/100 iters), loss = 0.251843
I0927 15:34:38.528882  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251843 (* 1 = 0.251843 loss)
I0927 15:34:38.528887  3463 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I0927 15:34:52.724835  3463 solver.cpp:218] Iteration 18400 (7.04428 iter/s, 14.1959s/100 iters), loss = 0.20266
I0927 15:34:52.724875  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20266 (* 1 = 0.20266 loss)
I0927 15:34:52.724881  3463 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I0927 15:35:06.221235  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:35:06.789609  3463 solver.cpp:330] Iteration 18500, Testing net (#0)
I0927 15:35:10.140398  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:35:10.280251  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5241
I0927 15:35:10.280293  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.94848 (* 1 = 1.94848 loss)
I0927 15:35:10.420714  3463 solver.cpp:218] Iteration 18500 (5.65106 iter/s, 17.6958s/100 iters), loss = 0.234748
I0927 15:35:10.420743  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234748 (* 1 = 0.234748 loss)
I0927 15:35:10.420750  3463 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I0927 15:35:24.626833  3463 solver.cpp:218] Iteration 18600 (7.03925 iter/s, 14.2061s/100 iters), loss = 0.24618
I0927 15:35:24.626875  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24618 (* 1 = 0.24618 loss)
I0927 15:35:24.626881  3463 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I0927 15:35:38.842124  3463 solver.cpp:218] Iteration 18700 (7.03472 iter/s, 14.2152s/100 iters), loss = 0.293027
I0927 15:35:38.842257  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293027 (* 1 = 0.293027 loss)
I0927 15:35:38.842263  3463 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I0927 15:35:53.047956  3463 solver.cpp:218] Iteration 18800 (7.03944 iter/s, 14.2057s/100 iters), loss = 0.26052
I0927 15:35:53.047996  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26052 (* 1 = 0.26052 loss)
I0927 15:35:53.048002  3463 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I0927 15:36:07.262039  3463 solver.cpp:218] Iteration 18900 (7.03531 iter/s, 14.214s/100 iters), loss = 0.153307
I0927 15:36:07.262079  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153307 (* 1 = 0.153307 loss)
I0927 15:36:07.262085  3463 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I0927 15:36:20.769456  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:36:21.338644  3463 solver.cpp:330] Iteration 19000, Testing net (#0)
I0927 15:36:24.690804  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:36:24.830581  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7885
I0927 15:36:24.830617  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.635814 (* 1 = 0.635814 loss)
I0927 15:36:24.970943  3463 solver.cpp:218] Iteration 19000 (5.6469 iter/s, 17.7088s/100 iters), loss = 0.218248
I0927 15:36:24.970971  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218248 (* 1 = 0.218248 loss)
I0927 15:36:24.970978  3463 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I0927 15:36:39.162158  3463 solver.cpp:218] Iteration 19100 (7.04664 iter/s, 14.1912s/100 iters), loss = 0.224781
I0927 15:36:39.162189  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224781 (* 1 = 0.224781 loss)
I0927 15:36:39.162195  3463 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I0927 15:36:53.357193  3463 solver.cpp:218] Iteration 19200 (7.04475 iter/s, 14.195s/100 iters), loss = 0.342513
I0927 15:36:53.357332  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342513 (* 1 = 0.342513 loss)
I0927 15:36:53.357340  3463 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I0927 15:37:07.557582  3463 solver.cpp:218] Iteration 19300 (7.04215 iter/s, 14.2002s/100 iters), loss = 0.208318
I0927 15:37:07.557622  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208318 (* 1 = 0.208318 loss)
I0927 15:37:07.557628  3463 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I0927 15:37:21.764142  3463 solver.cpp:218] Iteration 19400 (7.03904 iter/s, 14.2065s/100 iters), loss = 0.174159
I0927 15:37:21.764181  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174159 (* 1 = 0.174159 loss)
I0927 15:37:21.764187  3463 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I0927 15:37:35.262856  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:37:35.832767  3463 solver.cpp:330] Iteration 19500, Testing net (#0)
I0927 15:37:39.181632  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:37:39.321539  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7711
I0927 15:37:39.321580  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.703708 (* 1 = 0.703708 loss)
I0927 15:37:39.461277  3463 solver.cpp:218] Iteration 19500 (5.65066 iter/s, 17.697s/100 iters), loss = 0.265246
I0927 15:37:39.461309  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265246 (* 1 = 0.265246 loss)
I0927 15:37:39.461318  3463 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I0927 15:37:53.667898  3463 solver.cpp:218] Iteration 19600 (7.039 iter/s, 14.2066s/100 iters), loss = 0.2238
I0927 15:37:53.667927  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2238 (* 1 = 0.2238 loss)
I0927 15:37:53.667933  3463 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I0927 15:38:07.882062  3463 solver.cpp:218] Iteration 19700 (7.03527 iter/s, 14.2141s/100 iters), loss = 0.316646
I0927 15:38:07.882158  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316646 (* 1 = 0.316646 loss)
I0927 15:38:07.882164  3463 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I0927 15:38:22.124650  3463 solver.cpp:218] Iteration 19800 (7.02126 iter/s, 14.2425s/100 iters), loss = 0.178331
I0927 15:38:22.124680  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178331 (* 1 = 0.178331 loss)
I0927 15:38:22.124686  3463 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I0927 15:38:36.392930  3463 solver.cpp:218] Iteration 19900 (7.00859 iter/s, 14.2682s/100 iters), loss = 0.234007
I0927 15:38:36.392971  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234007 (* 1 = 0.234007 loss)
I0927 15:38:36.392976  3463 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I0927 15:38:49.927526  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:38:50.502159  3463 solver.cpp:330] Iteration 20000, Testing net (#0)
I0927 15:38:53.865105  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:38:54.003242  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7745
I0927 15:38:54.003278  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.740974 (* 1 = 0.740974 loss)
I0927 15:38:54.142350  3463 solver.cpp:218] Iteration 20000 (5.63401 iter/s, 17.7493s/100 iters), loss = 0.182028
I0927 15:38:54.142377  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182028 (* 1 = 0.182028 loss)
I0927 15:38:54.142385  3463 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I0927 15:39:08.729763  3463 solver.cpp:218] Iteration 20100 (6.85526 iter/s, 14.5873s/100 iters), loss = 0.195711
I0927 15:39:08.729809  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195711 (* 1 = 0.195711 loss)
I0927 15:39:08.729815  3463 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I0927 15:39:23.280995  3463 solver.cpp:218] Iteration 20200 (6.87231 iter/s, 14.5512s/100 iters), loss = 0.275135
I0927 15:39:23.281095  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275135 (* 1 = 0.275135 loss)
I0927 15:39:23.281111  3463 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I0927 15:39:37.602270  3463 solver.cpp:218] Iteration 20300 (6.98268 iter/s, 14.3211s/100 iters), loss = 0.2734
I0927 15:39:37.602300  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2734 (* 1 = 0.2734 loss)
I0927 15:39:37.602308  3463 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I0927 15:39:51.892503  3463 solver.cpp:218] Iteration 20400 (6.99782 iter/s, 14.2902s/100 iters), loss = 0.1746
I0927 15:39:51.892532  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1746 (* 1 = 0.1746 loss)
I0927 15:39:51.892539  3463 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I0927 15:40:05.489742  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:40:06.064855  3463 solver.cpp:330] Iteration 20500, Testing net (#0)
I0927 15:40:09.449247  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:40:09.588084  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7289
I0927 15:40:09.588120  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.908278 (* 1 = 0.908278 loss)
I0927 15:40:09.727152  3463 solver.cpp:218] Iteration 20500 (5.60709 iter/s, 17.8346s/100 iters), loss = 0.181827
I0927 15:40:09.727180  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181827 (* 1 = 0.181827 loss)
I0927 15:40:09.727187  3463 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I0927 15:40:24.020601  3463 solver.cpp:218] Iteration 20600 (6.99624 iter/s, 14.2934s/100 iters), loss = 0.259684
I0927 15:40:24.020643  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259684 (* 1 = 0.259684 loss)
I0927 15:40:24.020650  3463 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I0927 15:40:38.276837  3463 solver.cpp:218] Iteration 20700 (7.01451 iter/s, 14.2562s/100 iters), loss = 0.226063
I0927 15:40:38.277019  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226063 (* 1 = 0.226063 loss)
I0927 15:40:38.277029  3463 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I0927 15:40:52.605278  3463 solver.cpp:218] Iteration 20800 (6.97923 iter/s, 14.3282s/100 iters), loss = 0.115262
I0927 15:40:52.605320  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115262 (* 1 = 0.115262 loss)
I0927 15:40:52.605327  3463 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I0927 15:41:06.934478  3463 solver.cpp:218] Iteration 20900 (6.9788 iter/s, 14.3291s/100 iters), loss = 0.188758
I0927 15:41:06.934518  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188758 (* 1 = 0.188758 loss)
I0927 15:41:06.934527  3463 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I0927 15:41:20.432510  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:41:21.001917  3463 solver.cpp:330] Iteration 21000, Testing net (#0)
I0927 15:41:24.349752  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:41:24.489717  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7532
I0927 15:41:24.489745  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.860812 (* 1 = 0.860812 loss)
I0927 15:41:24.630609  3463 solver.cpp:218] Iteration 21000 (5.65098 iter/s, 17.696s/100 iters), loss = 0.1745
I0927 15:41:24.630637  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1745 (* 1 = 0.1745 loss)
I0927 15:41:24.630645  3463 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I0927 15:41:38.824483  3463 solver.cpp:218] Iteration 21100 (7.04533 iter/s, 14.1938s/100 iters), loss = 0.240969
I0927 15:41:38.824513  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240969 (* 1 = 0.240969 loss)
I0927 15:41:38.824519  3463 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I0927 15:41:53.021077  3463 solver.cpp:218] Iteration 21200 (7.04398 iter/s, 14.1965s/100 iters), loss = 0.232806
I0927 15:41:53.021180  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232806 (* 1 = 0.232806 loss)
I0927 15:41:53.021196  3463 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I0927 15:42:07.222028  3463 solver.cpp:218] Iteration 21300 (7.04185 iter/s, 14.2008s/100 iters), loss = 0.228787
I0927 15:42:07.222059  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228787 (* 1 = 0.228787 loss)
I0927 15:42:07.222065  3463 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I0927 15:42:21.423774  3463 solver.cpp:218] Iteration 21400 (7.04142 iter/s, 14.2017s/100 iters), loss = 0.155179
I0927 15:42:21.423804  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155179 (* 1 = 0.155179 loss)
I0927 15:42:21.423810  3463 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I0927 15:42:34.917448  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:42:35.486982  3463 solver.cpp:330] Iteration 21500, Testing net (#0)
I0927 15:42:38.834791  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:42:38.974717  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8271
I0927 15:42:38.974755  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.551742 (* 1 = 0.551742 loss)
I0927 15:42:39.115692  3463 solver.cpp:218] Iteration 21500 (5.65232 iter/s, 17.6918s/100 iters), loss = 0.267123
I0927 15:42:39.115720  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267123 (* 1 = 0.267123 loss)
I0927 15:42:39.115726  3463 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I0927 15:42:53.304132  3463 solver.cpp:218] Iteration 21600 (7.04802 iter/s, 14.1884s/100 iters), loss = 0.141616
I0927 15:42:53.304164  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.141616 (* 1 = 0.141616 loss)
I0927 15:42:53.304170  3463 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I0927 15:43:07.492024  3463 solver.cpp:218] Iteration 21700 (7.0483 iter/s, 14.1878s/100 iters), loss = 0.177999
I0927 15:43:07.492120  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177999 (* 1 = 0.177999 loss)
I0927 15:43:07.492136  3463 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I0927 15:43:21.682477  3463 solver.cpp:218] Iteration 21800 (7.04705 iter/s, 14.1903s/100 iters), loss = 0.185074
I0927 15:43:21.682508  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185074 (* 1 = 0.185074 loss)
I0927 15:43:21.682526  3463 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I0927 15:43:35.870942  3463 solver.cpp:218] Iteration 21900 (7.04801 iter/s, 14.1884s/100 iters), loss = 0.243543
I0927 15:43:35.870973  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243543 (* 1 = 0.243543 loss)
I0927 15:43:35.870990  3463 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I0927 15:43:49.349624  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:43:49.917804  3463 solver.cpp:330] Iteration 22000, Testing net (#0)
I0927 15:43:53.267666  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:43:53.407611  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8134
I0927 15:43:53.407647  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.570219 (* 1 = 0.570219 loss)
I0927 15:43:53.548285  3463 solver.cpp:218] Iteration 22000 (5.65698 iter/s, 17.6773s/100 iters), loss = 0.175415
I0927 15:43:53.548315  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175415 (* 1 = 0.175415 loss)
I0927 15:43:53.548321  3463 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I0927 15:44:07.739276  3463 solver.cpp:218] Iteration 22100 (7.04676 iter/s, 14.1909s/100 iters), loss = 0.133907
I0927 15:44:07.739307  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133907 (* 1 = 0.133907 loss)
I0927 15:44:07.739323  3463 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I0927 15:44:21.926570  3463 solver.cpp:218] Iteration 22200 (7.0486 iter/s, 14.1872s/100 iters), loss = 0.234578
I0927 15:44:21.926681  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234578 (* 1 = 0.234578 loss)
I0927 15:44:21.926687  3463 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I0927 15:44:36.116575  3463 solver.cpp:218] Iteration 22300 (7.04728 iter/s, 14.1899s/100 iters), loss = 0.191606
I0927 15:44:36.116605  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191606 (* 1 = 0.191606 loss)
I0927 15:44:36.116611  3463 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I0927 15:44:50.309978  3463 solver.cpp:218] Iteration 22400 (7.04556 iter/s, 14.1933s/100 iters), loss = 0.1218
I0927 15:44:50.310009  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1218 (* 1 = 0.1218 loss)
I0927 15:44:50.310014  3463 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I0927 15:45:03.795847  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:45:04.365407  3463 solver.cpp:330] Iteration 22500, Testing net (#0)
I0927 15:45:07.714397  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:45:07.854604  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7693
I0927 15:45:07.854641  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.757111 (* 1 = 0.757111 loss)
I0927 15:45:07.995334  3463 solver.cpp:218] Iteration 22500 (5.65442 iter/s, 17.6853s/100 iters), loss = 0.196335
I0927 15:45:07.995363  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196335 (* 1 = 0.196335 loss)
I0927 15:45:07.995370  3463 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I0927 15:45:22.208501  3463 solver.cpp:218] Iteration 22600 (7.03576 iter/s, 14.2131s/100 iters), loss = 0.205846
I0927 15:45:22.208541  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205846 (* 1 = 0.205846 loss)
I0927 15:45:22.208547  3463 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I0927 15:45:36.413895  3463 solver.cpp:218] Iteration 22700 (7.03962 iter/s, 14.2053s/100 iters), loss = 0.226798
I0927 15:45:36.414047  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226798 (* 1 = 0.226798 loss)
I0927 15:45:36.414055  3463 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I0927 15:45:50.622753  3463 solver.cpp:218] Iteration 22800 (7.03795 iter/s, 14.2087s/100 iters), loss = 0.283416
I0927 15:45:50.622795  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283416 (* 1 = 0.283416 loss)
I0927 15:45:50.622802  3463 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I0927 15:46:04.838984  3463 solver.cpp:218] Iteration 22900 (7.03425 iter/s, 14.2161s/100 iters), loss = 0.206915
I0927 15:46:04.839025  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206915 (* 1 = 0.206915 loss)
I0927 15:46:04.839031  3463 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I0927 15:46:18.344915  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:46:18.914680  3463 solver.cpp:330] Iteration 23000, Testing net (#0)
I0927 15:46:22.262487  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:46:22.402592  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7585
I0927 15:46:22.402629  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.823788 (* 1 = 0.823788 loss)
I0927 15:46:22.543139  3463 solver.cpp:218] Iteration 23000 (5.64842 iter/s, 17.7041s/100 iters), loss = 0.146484
I0927 15:46:22.543167  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146484 (* 1 = 0.146484 loss)
I0927 15:46:22.543174  3463 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I0927 15:46:36.737656  3463 solver.cpp:218] Iteration 23100 (7.04501 iter/s, 14.1944s/100 iters), loss = 0.189639
I0927 15:46:36.737696  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189639 (* 1 = 0.189639 loss)
I0927 15:46:36.737702  3463 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I0927 15:46:50.937382  3463 solver.cpp:218] Iteration 23200 (7.04243 iter/s, 14.1997s/100 iters), loss = 0.270528
I0927 15:46:50.937458  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270528 (* 1 = 0.270528 loss)
I0927 15:46:50.937464  3463 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I0927 15:47:05.134249  3463 solver.cpp:218] Iteration 23300 (7.04386 iter/s, 14.1968s/100 iters), loss = 0.170716
I0927 15:47:05.134291  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170716 (* 1 = 0.170716 loss)
I0927 15:47:05.134297  3463 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I0927 15:47:19.331118  3463 solver.cpp:218] Iteration 23400 (7.04385 iter/s, 14.1968s/100 iters), loss = 0.162512
I0927 15:47:19.331159  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162512 (* 1 = 0.162512 loss)
I0927 15:47:19.331166  3463 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I0927 15:47:32.823657  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:47:33.391674  3463 solver.cpp:330] Iteration 23500, Testing net (#0)
I0927 15:47:36.740380  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:47:36.879964  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8199
I0927 15:47:36.880002  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.538565 (* 1 = 0.538565 loss)
I0927 15:47:37.020856  3463 solver.cpp:218] Iteration 23500 (5.65302 iter/s, 17.6897s/100 iters), loss = 0.151841
I0927 15:47:37.020885  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151841 (* 1 = 0.151841 loss)
I0927 15:47:37.020891  3463 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I0927 15:47:51.219499  3463 solver.cpp:218] Iteration 23600 (7.04296 iter/s, 14.1986s/100 iters), loss = 0.192796
I0927 15:47:51.219540  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192796 (* 1 = 0.192796 loss)
I0927 15:47:51.219547  3463 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I0927 15:48:05.422798  3463 solver.cpp:218] Iteration 23700 (7.04066 iter/s, 14.2032s/100 iters), loss = 0.268443
I0927 15:48:05.422897  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268443 (* 1 = 0.268443 loss)
I0927 15:48:05.422914  3463 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I0927 15:48:19.627316  3463 solver.cpp:218] Iteration 23800 (7.04008 iter/s, 14.2044s/100 iters), loss = 0.201509
I0927 15:48:19.627357  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201509 (* 1 = 0.201509 loss)
I0927 15:48:19.627362  3463 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I0927 15:48:33.829968  3463 solver.cpp:218] Iteration 23900 (7.04098 iter/s, 14.2026s/100 iters), loss = 0.131293
I0927 15:48:33.829999  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.131293 (* 1 = 0.131293 loss)
I0927 15:48:33.830005  3463 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I0927 15:48:47.328372  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:48:47.897320  3463 solver.cpp:330] Iteration 24000, Testing net (#0)
I0927 15:48:51.245702  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:48:51.385210  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8086
I0927 15:48:51.385236  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.6087 (* 1 = 0.6087 loss)
I0927 15:48:51.526147  3463 solver.cpp:218] Iteration 24000 (5.65096 iter/s, 17.6961s/100 iters), loss = 0.188112
I0927 15:48:51.526175  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188112 (* 1 = 0.188112 loss)
I0927 15:48:51.526181  3463 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I0927 15:49:05.728590  3463 solver.cpp:218] Iteration 24100 (7.04107 iter/s, 14.2024s/100 iters), loss = 0.253152
I0927 15:49:05.728631  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253152 (* 1 = 0.253152 loss)
I0927 15:49:05.728636  3463 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I0927 15:49:19.923689  3463 solver.cpp:218] Iteration 24200 (7.04472 iter/s, 14.195s/100 iters), loss = 0.173785
I0927 15:49:19.923795  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173785 (* 1 = 0.173785 loss)
I0927 15:49:19.923802  3463 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I0927 15:49:34.124868  3463 solver.cpp:218] Iteration 24300 (7.04174 iter/s, 14.201s/100 iters), loss = 0.246003
I0927 15:49:34.124908  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246003 (* 1 = 0.246003 loss)
I0927 15:49:34.124914  3463 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I0927 15:49:48.324174  3463 solver.cpp:218] Iteration 24400 (7.04264 iter/s, 14.1992s/100 iters), loss = 0.160481
I0927 15:49:48.324216  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160481 (* 1 = 0.160481 loss)
I0927 15:49:48.324223  3463 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I0927 15:50:01.819064  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:50:02.387228  3463 solver.cpp:330] Iteration 24500, Testing net (#0)
I0927 15:50:05.733855  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:50:05.873792  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6441
I0927 15:50:05.873828  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.45453 (* 1 = 1.45453 loss)
I0927 15:50:06.014107  3463 solver.cpp:218] Iteration 24500 (5.65296 iter/s, 17.6898s/100 iters), loss = 0.203323
I0927 15:50:06.014134  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203323 (* 1 = 0.203323 loss)
I0927 15:50:06.014142  3463 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I0927 15:50:20.224700  3463 solver.cpp:218] Iteration 24600 (7.03704 iter/s, 14.2105s/100 iters), loss = 0.212722
I0927 15:50:20.224731  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212722 (* 1 = 0.212722 loss)
I0927 15:50:20.224738  3463 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I0927 15:50:34.437595  3463 solver.cpp:218] Iteration 24700 (7.0359 iter/s, 14.2128s/100 iters), loss = 0.292002
I0927 15:50:34.437722  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292002 (* 1 = 0.292002 loss)
I0927 15:50:34.437731  3463 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I0927 15:50:48.647442  3463 solver.cpp:218] Iteration 24800 (7.03746 iter/s, 14.2097s/100 iters), loss = 0.184136
I0927 15:50:48.647483  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184136 (* 1 = 0.184136 loss)
I0927 15:50:48.647490  3463 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I0927 15:51:02.863268  3463 solver.cpp:218] Iteration 24900 (7.03445 iter/s, 14.2157s/100 iters), loss = 0.210002
I0927 15:51:02.863299  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210002 (* 1 = 0.210002 loss)
I0927 15:51:02.863306  3463 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I0927 15:51:16.364270  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:51:16.933338  3463 solver.cpp:330] Iteration 25000, Testing net (#0)
I0927 15:51:20.279747  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:51:20.419656  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7932
I0927 15:51:20.419692  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.66023 (* 1 = 0.66023 loss)
I0927 15:51:20.560259  3463 solver.cpp:218] Iteration 25000 (5.6507 iter/s, 17.6969s/100 iters), loss = 0.238536
I0927 15:51:20.560287  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238536 (* 1 = 0.238536 loss)
I0927 15:51:20.560293  3463 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I0927 15:51:34.767501  3463 solver.cpp:218] Iteration 25100 (7.03869 iter/s, 14.2072s/100 iters), loss = 0.244764
I0927 15:51:34.767542  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244764 (* 1 = 0.244764 loss)
I0927 15:51:34.767549  3463 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I0927 15:51:48.978302  3463 solver.cpp:218] Iteration 25200 (7.03694 iter/s, 14.2107s/100 iters), loss = 0.151245
I0927 15:51:48.978377  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151245 (* 1 = 0.151245 loss)
I0927 15:51:48.978384  3463 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I0927 15:52:03.188997  3463 solver.cpp:218] Iteration 25300 (7.03701 iter/s, 14.2106s/100 iters), loss = 0.194635
I0927 15:52:03.189038  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194635 (* 1 = 0.194635 loss)
I0927 15:52:03.189044  3463 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I0927 15:52:17.398218  3463 solver.cpp:218] Iteration 25400 (7.03772 iter/s, 14.2091s/100 iters), loss = 0.187654
I0927 15:52:17.398260  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187654 (* 1 = 0.187654 loss)
I0927 15:52:17.398267  3463 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I0927 15:52:30.900162  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:52:31.469372  3463 solver.cpp:330] Iteration 25500, Testing net (#0)
I0927 15:52:34.817312  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:52:34.957386  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7824
I0927 15:52:34.957424  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.733541 (* 1 = 0.733541 loss)
I0927 15:52:35.097960  3463 solver.cpp:218] Iteration 25500 (5.64983 iter/s, 17.6997s/100 iters), loss = 0.235021
I0927 15:52:35.097987  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235021 (* 1 = 0.235021 loss)
I0927 15:52:35.097995  3463 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I0927 15:52:49.295359  3463 solver.cpp:218] Iteration 25600 (7.04358 iter/s, 14.1973s/100 iters), loss = 0.189648
I0927 15:52:49.295399  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189648 (* 1 = 0.189648 loss)
I0927 15:52:49.295405  3463 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I0927 15:53:03.495971  3463 solver.cpp:218] Iteration 25700 (7.04199 iter/s, 14.2005s/100 iters), loss = 0.182875
I0927 15:53:03.496103  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182875 (* 1 = 0.182875 loss)
I0927 15:53:03.496111  3463 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I0927 15:53:17.701050  3463 solver.cpp:218] Iteration 25800 (7.03982 iter/s, 14.2049s/100 iters), loss = 0.151996
I0927 15:53:17.701090  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151996 (* 1 = 0.151996 loss)
I0927 15:53:17.701095  3463 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I0927 15:53:31.902762  3463 solver.cpp:218] Iteration 25900 (7.04145 iter/s, 14.2016s/100 iters), loss = 0.188053
I0927 15:53:31.902804  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188053 (* 1 = 0.188053 loss)
I0927 15:53:31.902811  3463 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I0927 15:53:45.400540  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:53:45.969785  3463 solver.cpp:330] Iteration 26000, Testing net (#0)
I0927 15:53:49.319097  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:53:49.458915  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8272
I0927 15:53:49.458951  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.553765 (* 1 = 0.553765 loss)
I0927 15:53:49.599920  3463 solver.cpp:218] Iteration 26000 (5.65065 iter/s, 17.6971s/100 iters), loss = 0.201449
I0927 15:53:49.599947  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201449 (* 1 = 0.201449 loss)
I0927 15:53:49.599954  3463 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I0927 15:54:03.799403  3463 solver.cpp:218] Iteration 26100 (7.04254 iter/s, 14.1994s/100 iters), loss = 0.201305
I0927 15:54:03.799443  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201305 (* 1 = 0.201305 loss)
I0927 15:54:03.799449  3463 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I0927 15:54:17.996734  3463 solver.cpp:218] Iteration 26200 (7.04361 iter/s, 14.1973s/100 iters), loss = 0.260842
I0927 15:54:17.996829  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260842 (* 1 = 0.260842 loss)
I0927 15:54:17.996836  3463 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I0927 15:54:32.189764  3463 solver.cpp:218] Iteration 26300 (7.04578 iter/s, 14.1929s/100 iters), loss = 0.182299
I0927 15:54:32.189793  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182299 (* 1 = 0.182299 loss)
I0927 15:54:32.189800  3463 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I0927 15:54:46.385987  3463 solver.cpp:218] Iteration 26400 (7.04416 iter/s, 14.1962s/100 iters), loss = 0.119312
I0927 15:54:46.386018  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119312 (* 1 = 0.119312 loss)
I0927 15:54:46.386024  3463 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I0927 15:54:59.876868  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:55:00.446199  3463 solver.cpp:330] Iteration 26500, Testing net (#0)
I0927 15:55:03.792924  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:55:03.932868  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6967
I0927 15:55:03.932904  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.21537 (* 1 = 1.21537 loss)
I0927 15:55:04.073629  3463 solver.cpp:218] Iteration 26500 (5.65369 iter/s, 17.6876s/100 iters), loss = 0.226637
I0927 15:55:04.073657  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226636 (* 1 = 0.226636 loss)
I0927 15:55:04.073664  3463 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I0927 15:55:18.270566  3463 solver.cpp:218] Iteration 26600 (7.04381 iter/s, 14.1969s/100 iters), loss = 0.235207
I0927 15:55:18.270599  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235207 (* 1 = 0.235207 loss)
I0927 15:55:18.270604  3463 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I0927 15:55:32.464510  3463 solver.cpp:218] Iteration 26700 (7.04529 iter/s, 14.1939s/100 iters), loss = 0.186984
I0927 15:55:32.464594  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186984 (* 1 = 0.186984 loss)
I0927 15:55:32.464610  3463 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I0927 15:55:46.661221  3463 solver.cpp:218] Iteration 26800 (7.04395 iter/s, 14.1966s/100 iters), loss = 0.226716
I0927 15:55:46.661252  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226716 (* 1 = 0.226716 loss)
I0927 15:55:46.661257  3463 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I0927 15:56:00.853696  3463 solver.cpp:218] Iteration 26900 (7.04602 iter/s, 14.1924s/100 iters), loss = 0.154439
I0927 15:56:00.853739  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154439 (* 1 = 0.154439 loss)
I0927 15:56:00.853744  3463 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I0927 15:56:14.340281  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:56:14.910048  3463 solver.cpp:330] Iteration 27000, Testing net (#0)
I0927 15:56:18.257287  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:56:18.397276  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.822
I0927 15:56:18.397313  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.544108 (* 1 = 0.544108 loss)
I0927 15:56:18.537598  3463 solver.cpp:218] Iteration 27000 (5.65489 iter/s, 17.6838s/100 iters), loss = 0.191551
I0927 15:56:18.537626  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191551 (* 1 = 0.191551 loss)
I0927 15:56:18.537633  3463 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I0927 15:56:32.732452  3463 solver.cpp:218] Iteration 27100 (7.04484 iter/s, 14.1948s/100 iters), loss = 0.180416
I0927 15:56:32.732494  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180416 (* 1 = 0.180416 loss)
I0927 15:56:32.732501  3463 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I0927 15:56:46.925223  3463 solver.cpp:218] Iteration 27200 (7.04588 iter/s, 14.1927s/100 iters), loss = 0.284105
I0927 15:56:46.925338  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284104 (* 1 = 0.284104 loss)
I0927 15:56:46.925344  3463 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I0927 15:57:01.115643  3463 solver.cpp:218] Iteration 27300 (7.04708 iter/s, 14.1903s/100 iters), loss = 0.245154
I0927 15:57:01.115684  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245154 (* 1 = 0.245154 loss)
I0927 15:57:01.115690  3463 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I0927 15:57:15.301229  3463 solver.cpp:218] Iteration 27400 (7.04945 iter/s, 14.1855s/100 iters), loss = 0.112828
I0927 15:57:15.301260  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.112828 (* 1 = 0.112828 loss)
I0927 15:57:15.301266  3463 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I0927 15:57:28.792274  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:57:29.361608  3463 solver.cpp:330] Iteration 27500, Testing net (#0)
I0927 15:57:32.709692  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:57:32.849990  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.82
I0927 15:57:32.850028  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.576755 (* 1 = 0.576755 loss)
I0927 15:57:32.990757  3463 solver.cpp:218] Iteration 27500 (5.65309 iter/s, 17.6895s/100 iters), loss = 0.170654
I0927 15:57:32.990787  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170654 (* 1 = 0.170654 loss)
I0927 15:57:32.990795  3463 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I0927 15:57:47.205533  3463 solver.cpp:218] Iteration 27600 (7.03497 iter/s, 14.2147s/100 iters), loss = 0.158485
I0927 15:57:47.205574  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158485 (* 1 = 0.158485 loss)
I0927 15:57:47.205579  3463 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I0927 15:58:01.412473  3463 solver.cpp:218] Iteration 27700 (7.03885 iter/s, 14.2069s/100 iters), loss = 0.257673
I0927 15:58:01.412591  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257673 (* 1 = 0.257673 loss)
I0927 15:58:01.412598  3463 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I0927 15:58:15.618749  3463 solver.cpp:218] Iteration 27800 (7.03922 iter/s, 14.2061s/100 iters), loss = 0.17083
I0927 15:58:15.618790  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170831 (* 1 = 0.170831 loss)
I0927 15:58:15.618796  3463 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I0927 15:58:29.826349  3463 solver.cpp:218] Iteration 27900 (7.03853 iter/s, 14.2075s/100 iters), loss = 0.15353
I0927 15:58:29.826390  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15353 (* 1 = 0.15353 loss)
I0927 15:58:29.826395  3463 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I0927 15:58:43.325655  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:58:43.896425  3463 solver.cpp:330] Iteration 28000, Testing net (#0)
I0927 15:58:47.243078  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:58:47.383227  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.766
I0927 15:58:47.383263  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.773562 (* 1 = 0.773562 loss)
I0927 15:58:47.524224  3463 solver.cpp:218] Iteration 28000 (5.65042 iter/s, 17.6978s/100 iters), loss = 0.146321
I0927 15:58:47.524252  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146321 (* 1 = 0.146321 loss)
I0927 15:58:47.524260  3463 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I0927 15:59:01.726287  3463 solver.cpp:218] Iteration 28100 (7.04126 iter/s, 14.202s/100 iters), loss = 0.270062
I0927 15:59:01.726318  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270062 (* 1 = 0.270062 loss)
I0927 15:59:01.726325  3463 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I0927 15:59:15.927659  3463 solver.cpp:218] Iteration 28200 (7.04161 iter/s, 14.2013s/100 iters), loss = 0.200608
I0927 15:59:15.927747  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200608 (* 1 = 0.200608 loss)
I0927 15:59:15.927763  3463 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I0927 15:59:30.131124  3463 solver.cpp:218] Iteration 28300 (7.0406 iter/s, 14.2033s/100 iters), loss = 0.161596
I0927 15:59:30.131166  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161596 (* 1 = 0.161596 loss)
I0927 15:59:30.131172  3463 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I0927 15:59:44.335286  3463 solver.cpp:218] Iteration 28400 (7.04023 iter/s, 14.2041s/100 iters), loss = 0.157004
I0927 15:59:44.335317  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157004 (* 1 = 0.157004 loss)
I0927 15:59:44.335324  3463 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I0927 15:59:57.833400  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 15:59:58.402671  3463 solver.cpp:330] Iteration 28500, Testing net (#0)
I0927 16:00:01.751462  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:00:01.890950  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8263
I0927 16:00:01.890987  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.546886 (* 1 = 0.546886 loss)
I0927 16:00:02.032268  3463 solver.cpp:218] Iteration 28500 (5.65071 iter/s, 17.6969s/100 iters), loss = 0.198445
I0927 16:00:02.032294  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198445 (* 1 = 0.198445 loss)
I0927 16:00:02.032301  3463 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I0927 16:00:16.235169  3463 solver.cpp:218] Iteration 28600 (7.04085 iter/s, 14.2028s/100 iters), loss = 0.15081
I0927 16:00:16.235211  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15081 (* 1 = 0.15081 loss)
I0927 16:00:16.235218  3463 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I0927 16:00:30.440788  3463 solver.cpp:218] Iteration 28700 (7.03951 iter/s, 14.2055s/100 iters), loss = 0.383467
I0927 16:00:30.440907  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.383467 (* 1 = 0.383467 loss)
I0927 16:00:30.440914  3463 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I0927 16:00:44.643564  3463 solver.cpp:218] Iteration 28800 (7.04095 iter/s, 14.2026s/100 iters), loss = 0.227457
I0927 16:00:44.643605  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227457 (* 1 = 0.227457 loss)
I0927 16:00:44.643611  3463 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I0927 16:00:58.843920  3463 solver.cpp:218] Iteration 28900 (7.04212 iter/s, 14.2003s/100 iters), loss = 0.222075
I0927 16:00:58.843961  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222075 (* 1 = 0.222075 loss)
I0927 16:00:58.843966  3463 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I0927 16:01:12.341387  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:01:12.910648  3463 solver.cpp:330] Iteration 29000, Testing net (#0)
I0927 16:01:16.260545  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:01:16.400652  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.824
I0927 16:01:16.400688  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.560181 (* 1 = 0.560181 loss)
I0927 16:01:16.541329  3463 solver.cpp:218] Iteration 29000 (5.65057 iter/s, 17.6973s/100 iters), loss = 0.148869
I0927 16:01:16.541357  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14887 (* 1 = 0.14887 loss)
I0927 16:01:16.541364  3463 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I0927 16:01:30.739537  3463 solver.cpp:218] Iteration 29100 (7.04318 iter/s, 14.1981s/100 iters), loss = 0.214548
I0927 16:01:30.739578  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214548 (* 1 = 0.214548 loss)
I0927 16:01:30.739584  3463 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I0927 16:01:44.928535  3463 solver.cpp:218] Iteration 29200 (7.04775 iter/s, 14.1889s/100 iters), loss = 0.136806
I0927 16:01:44.928594  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136806 (* 1 = 0.136806 loss)
I0927 16:01:44.928603  3463 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I0927 16:01:59.118960  3463 solver.cpp:218] Iteration 29300 (7.04705 iter/s, 14.1903s/100 iters), loss = 0.189266
I0927 16:01:59.118990  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189266 (* 1 = 0.189266 loss)
I0927 16:01:59.118996  3463 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I0927 16:02:13.310302  3463 solver.cpp:218] Iteration 29400 (7.04658 iter/s, 14.1913s/100 iters), loss = 0.171371
I0927 16:02:13.310331  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171371 (* 1 = 0.171371 loss)
I0927 16:02:13.310338  3463 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I0927 16:02:26.800256  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:02:27.369577  3463 solver.cpp:330] Iteration 29500, Testing net (#0)
I0927 16:02:30.715387  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:02:30.855229  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7658
I0927 16:02:30.855264  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.783339 (* 1 = 0.783339 loss)
I0927 16:02:30.996168  3463 solver.cpp:218] Iteration 29500 (5.65426 iter/s, 17.6858s/100 iters), loss = 0.106512
I0927 16:02:30.996196  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106512 (* 1 = 0.106512 loss)
I0927 16:02:30.996203  3463 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I0927 16:02:45.205451  3463 solver.cpp:218] Iteration 29600 (7.03769 iter/s, 14.2092s/100 iters), loss = 0.243221
I0927 16:02:45.205482  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243221 (* 1 = 0.243221 loss)
I0927 16:02:45.205487  3463 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I0927 16:02:59.414110  3463 solver.cpp:218] Iteration 29700 (7.038 iter/s, 14.2086s/100 iters), loss = 0.22084
I0927 16:02:59.414216  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22084 (* 1 = 0.22084 loss)
I0927 16:02:59.414224  3463 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I0927 16:03:13.624195  3463 solver.cpp:218] Iteration 29800 (7.03732 iter/s, 14.2099s/100 iters), loss = 0.239572
I0927 16:03:13.624236  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239572 (* 1 = 0.239572 loss)
I0927 16:03:13.624243  3463 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I0927 16:03:27.831516  3463 solver.cpp:218] Iteration 29900 (7.03866 iter/s, 14.2072s/100 iters), loss = 0.186842
I0927 16:03:27.831555  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186843 (* 1 = 0.186843 loss)
I0927 16:03:27.831562  3463 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I0927 16:03:41.336055  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:03:41.903553  3463 solver.cpp:330] Iteration 30000, Testing net (#0)
I0927 16:03:45.251116  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:03:45.391275  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7705
I0927 16:03:45.391312  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.794654 (* 1 = 0.794654 loss)
I0927 16:03:45.532050  3463 solver.cpp:218] Iteration 30000 (5.64957 iter/s, 17.7005s/100 iters), loss = 0.179754
I0927 16:03:45.532079  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179754 (* 1 = 0.179754 loss)
I0927 16:03:45.532086  3463 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I0927 16:03:59.735708  3463 solver.cpp:218] Iteration 30100 (7.04047 iter/s, 14.2036s/100 iters), loss = 0.167959
I0927 16:03:59.735749  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167959 (* 1 = 0.167959 loss)
I0927 16:03:59.735755  3463 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I0927 16:04:13.936805  3463 solver.cpp:218] Iteration 30200 (7.04175 iter/s, 14.201s/100 iters), loss = 0.262945
I0927 16:04:13.936882  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262946 (* 1 = 0.262946 loss)
I0927 16:04:13.936888  3463 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I0927 16:04:28.142377  3463 solver.cpp:218] Iteration 30300 (7.03955 iter/s, 14.2055s/100 iters), loss = 0.221079
I0927 16:04:28.142417  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221079 (* 1 = 0.221079 loss)
I0927 16:04:28.142424  3463 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I0927 16:04:42.351279  3463 solver.cpp:218] Iteration 30400 (7.03788 iter/s, 14.2088s/100 iters), loss = 0.127079
I0927 16:04:42.351318  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12708 (* 1 = 0.12708 loss)
I0927 16:04:42.351325  3463 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I0927 16:04:55.852041  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:04:56.421234  3463 solver.cpp:330] Iteration 30500, Testing net (#0)
I0927 16:04:59.768260  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:04:59.908310  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7812
I0927 16:04:59.908345  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.732678 (* 1 = 0.732678 loss)
I0927 16:05:00.049407  3463 solver.cpp:218] Iteration 30500 (5.65034 iter/s, 17.698s/100 iters), loss = 0.225028
I0927 16:05:00.049435  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225029 (* 1 = 0.225029 loss)
I0927 16:05:00.049443  3463 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I0927 16:05:14.253231  3463 solver.cpp:218] Iteration 30600 (7.04039 iter/s, 14.2038s/100 iters), loss = 0.146146
I0927 16:05:14.253271  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146146 (* 1 = 0.146146 loss)
I0927 16:05:14.253278  3463 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I0927 16:05:28.456333  3463 solver.cpp:218] Iteration 30700 (7.04075 iter/s, 14.203s/100 iters), loss = 0.143742
I0927 16:05:28.456432  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143742 (* 1 = 0.143742 loss)
I0927 16:05:28.456439  3463 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I0927 16:05:42.654660  3463 solver.cpp:218] Iteration 30800 (7.04314 iter/s, 14.1982s/100 iters), loss = 0.153006
I0927 16:05:42.654692  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153007 (* 1 = 0.153007 loss)
I0927 16:05:42.654697  3463 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I0927 16:05:56.858016  3463 solver.cpp:218] Iteration 30900 (7.04062 iter/s, 14.2033s/100 iters), loss = 0.111048
I0927 16:05:56.858047  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.111048 (* 1 = 0.111048 loss)
I0927 16:05:56.858055  3463 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I0927 16:06:10.353803  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:06:10.923189  3463 solver.cpp:330] Iteration 31000, Testing net (#0)
I0927 16:06:14.270694  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:06:14.410645  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8201
I0927 16:06:14.410670  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.576552 (* 1 = 0.576552 loss)
I0927 16:06:14.552055  3463 solver.cpp:218] Iteration 31000 (5.65164 iter/s, 17.694s/100 iters), loss = 0.17836
I0927 16:06:14.552083  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17836 (* 1 = 0.17836 loss)
I0927 16:06:14.552090  3463 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I0927 16:06:28.751145  3463 solver.cpp:218] Iteration 31100 (7.04274 iter/s, 14.199s/100 iters), loss = 0.184746
I0927 16:06:28.751188  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184746 (* 1 = 0.184746 loss)
I0927 16:06:28.751194  3463 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I0927 16:06:42.951699  3463 solver.cpp:218] Iteration 31200 (7.04202 iter/s, 14.2005s/100 iters), loss = 0.184311
I0927 16:06:42.951786  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184311 (* 1 = 0.184311 loss)
I0927 16:06:42.951802  3463 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I0927 16:06:57.148238  3463 solver.cpp:218] Iteration 31300 (7.04403 iter/s, 14.1964s/100 iters), loss = 0.195894
I0927 16:06:57.148280  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195895 (* 1 = 0.195895 loss)
I0927 16:06:57.148286  3463 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I0927 16:07:11.344494  3463 solver.cpp:218] Iteration 31400 (7.04415 iter/s, 14.1962s/100 iters), loss = 0.149144
I0927 16:07:11.344524  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149144 (* 1 = 0.149144 loss)
I0927 16:07:11.344530  3463 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I0927 16:07:24.841419  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:07:25.410768  3463 solver.cpp:330] Iteration 31500, Testing net (#0)
I0927 16:07:28.757315  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:07:28.897236  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8158
I0927 16:07:28.897272  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.565191 (* 1 = 0.565191 loss)
I0927 16:07:29.037734  3463 solver.cpp:218] Iteration 31500 (5.6519 iter/s, 17.6932s/100 iters), loss = 0.129858
I0927 16:07:29.037761  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.129858 (* 1 = 0.129858 loss)
I0927 16:07:29.037768  3463 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I0927 16:07:43.232451  3463 solver.cpp:218] Iteration 31600 (7.04491 iter/s, 14.1947s/100 iters), loss = 0.136023
I0927 16:07:43.232482  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136023 (* 1 = 0.136023 loss)
I0927 16:07:43.232488  3463 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I0927 16:07:57.425016  3463 solver.cpp:218] Iteration 31700 (7.04598 iter/s, 14.1925s/100 iters), loss = 0.283912
I0927 16:07:57.425144  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283912 (* 1 = 0.283912 loss)
I0927 16:07:57.425153  3463 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I0927 16:08:11.618497  3463 solver.cpp:218] Iteration 31800 (7.04556 iter/s, 14.1933s/100 iters), loss = 0.107393
I0927 16:08:11.618541  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.107393 (* 1 = 0.107393 loss)
I0927 16:08:11.618547  3463 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I0927 16:08:25.809279  3463 solver.cpp:218] Iteration 31900 (7.04687 iter/s, 14.1907s/100 iters), loss = 0.103027
I0927 16:08:25.809320  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103027 (* 1 = 0.103027 loss)
I0927 16:08:25.809326  3463 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I0927 16:08:39.296325  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:08:39.863907  3463 solver.cpp:330] Iteration 32000, Testing net (#0)
I0927 16:08:43.210532  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:08:43.350950  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7898
I0927 16:08:43.350975  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.739337 (* 1 = 0.739337 loss)
I0927 16:08:43.491940  3463 solver.cpp:218] Iteration 32000 (5.65529 iter/s, 17.6826s/100 iters), loss = 0.203169
I0927 16:08:43.491967  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203169 (* 1 = 0.203169 loss)
I0927 16:08:43.491973  3463 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I0927 16:08:57.686228  3463 solver.cpp:218] Iteration 32100 (7.04512 iter/s, 14.1942s/100 iters), loss = 0.25026
I0927 16:08:57.686269  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25026 (* 1 = 0.25026 loss)
I0927 16:08:57.686275  3463 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I0927 16:09:11.882074  3463 solver.cpp:218] Iteration 32200 (7.04435 iter/s, 14.1958s/100 iters), loss = 0.182365
I0927 16:09:11.882213  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182365 (* 1 = 0.182365 loss)
I0927 16:09:11.882220  3463 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I0927 16:09:26.073571  3463 solver.cpp:218] Iteration 32300 (7.04655 iter/s, 14.1913s/100 iters), loss = 0.160929
I0927 16:09:26.073614  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160929 (* 1 = 0.160929 loss)
I0927 16:09:26.073621  3463 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I0927 16:09:40.265625  3463 solver.cpp:218] Iteration 32400 (7.04624 iter/s, 14.192s/100 iters), loss = 0.219807
I0927 16:09:40.265666  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219807 (* 1 = 0.219807 loss)
I0927 16:09:40.265672  3463 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I0927 16:09:53.748652  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:09:54.317936  3463 solver.cpp:330] Iteration 32500, Testing net (#0)
I0927 16:09:57.665236  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:09:57.805356  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7815
I0927 16:09:57.805393  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.717553 (* 1 = 0.717553 loss)
I0927 16:09:57.945739  3463 solver.cpp:218] Iteration 32500 (5.6561 iter/s, 17.68s/100 iters), loss = 0.158944
I0927 16:09:57.945768  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158944 (* 1 = 0.158944 loss)
I0927 16:09:57.945775  3463 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I0927 16:10:12.150391  3463 solver.cpp:218] Iteration 32600 (7.03998 iter/s, 14.2046s/100 iters), loss = 0.278118
I0927 16:10:12.150432  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278118 (* 1 = 0.278118 loss)
I0927 16:10:12.150437  3463 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I0927 16:10:26.356835  3463 solver.cpp:218] Iteration 32700 (7.0391 iter/s, 14.2064s/100 iters), loss = 0.229006
I0927 16:10:26.356951  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229006 (* 1 = 0.229006 loss)
I0927 16:10:26.356962  3463 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I0927 16:10:40.559757  3463 solver.cpp:218] Iteration 32800 (7.04088 iter/s, 14.2028s/100 iters), loss = 0.190072
I0927 16:10:40.559799  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190072 (* 1 = 0.190072 loss)
I0927 16:10:40.559805  3463 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I0927 16:10:54.769721  3463 solver.cpp:218] Iteration 32900 (7.03735 iter/s, 14.2099s/100 iters), loss = 0.155505
I0927 16:10:54.769762  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155505 (* 1 = 0.155505 loss)
I0927 16:10:54.769768  3463 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I0927 16:11:08.264694  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:11:08.833194  3463 solver.cpp:330] Iteration 33000, Testing net (#0)
I0927 16:11:12.181478  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:11:12.321710  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.812
I0927 16:11:12.321738  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.584261 (* 1 = 0.584261 loss)
I0927 16:11:12.462396  3463 solver.cpp:218] Iteration 33000 (5.65208 iter/s, 17.6926s/100 iters), loss = 0.13588
I0927 16:11:12.462424  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13588 (* 1 = 0.13588 loss)
I0927 16:11:12.462431  3463 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I0927 16:11:26.656756  3463 solver.cpp:218] Iteration 33100 (7.04508 iter/s, 14.1943s/100 iters), loss = 0.266459
I0927 16:11:26.656798  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26646 (* 1 = 0.26646 loss)
I0927 16:11:26.656805  3463 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I0927 16:11:40.854228  3463 solver.cpp:218] Iteration 33200 (7.04355 iter/s, 14.1974s/100 iters), loss = 0.163038
I0927 16:11:40.854337  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163038 (* 1 = 0.163038 loss)
I0927 16:11:40.854344  3463 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I0927 16:11:55.053635  3463 solver.cpp:218] Iteration 33300 (7.04262 iter/s, 14.1993s/100 iters), loss = 0.215958
I0927 16:11:55.053678  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215958 (* 1 = 0.215958 loss)
I0927 16:11:55.053683  3463 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I0927 16:12:09.246982  3463 solver.cpp:218] Iteration 33400 (7.04559 iter/s, 14.1933s/100 iters), loss = 0.186755
I0927 16:12:09.247023  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186755 (* 1 = 0.186755 loss)
I0927 16:12:09.247030  3463 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I0927 16:12:22.739162  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:12:23.307646  3463 solver.cpp:330] Iteration 33500, Testing net (#0)
I0927 16:12:26.657366  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:12:26.797154  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8408
I0927 16:12:26.797190  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.511382 (* 1 = 0.511382 loss)
I0927 16:12:26.938064  3463 solver.cpp:218] Iteration 33500 (5.65259 iter/s, 17.691s/100 iters), loss = 0.119261
I0927 16:12:26.938093  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119261 (* 1 = 0.119261 loss)
I0927 16:12:26.938102  3463 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I0927 16:12:41.143100  3463 solver.cpp:218] Iteration 33600 (7.03979 iter/s, 14.205s/100 iters), loss = 0.150511
I0927 16:12:41.143141  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.150511 (* 1 = 0.150511 loss)
I0927 16:12:41.143146  3463 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I0927 16:12:55.342135  3463 solver.cpp:218] Iteration 33700 (7.04277 iter/s, 14.199s/100 iters), loss = 0.309699
I0927 16:12:55.342259  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309699 (* 1 = 0.309699 loss)
I0927 16:12:55.342277  3463 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I0927 16:13:09.541821  3463 solver.cpp:218] Iteration 33800 (7.04249 iter/s, 14.1995s/100 iters), loss = 0.227105
I0927 16:13:09.541862  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227105 (* 1 = 0.227105 loss)
I0927 16:13:09.541868  3463 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I0927 16:13:23.742976  3463 solver.cpp:218] Iteration 33900 (7.04172 iter/s, 14.2011s/100 iters), loss = 0.185983
I0927 16:13:23.743017  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185983 (* 1 = 0.185983 loss)
I0927 16:13:23.743023  3463 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I0927 16:13:37.236706  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:13:37.804711  3463 solver.cpp:330] Iteration 34000, Testing net (#0)
I0927 16:13:41.152554  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:13:41.292354  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7972
I0927 16:13:41.292390  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.716306 (* 1 = 0.716306 loss)
I0927 16:13:41.433009  3463 solver.cpp:218] Iteration 34000 (5.65293 iter/s, 17.6899s/100 iters), loss = 0.198612
I0927 16:13:41.433037  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198612 (* 1 = 0.198612 loss)
I0927 16:13:41.433044  3463 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I0927 16:13:55.626616  3463 solver.cpp:218] Iteration 34100 (7.04546 iter/s, 14.1935s/100 iters), loss = 0.149388
I0927 16:13:55.626669  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149388 (* 1 = 0.149388 loss)
I0927 16:13:55.626675  3463 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I0927 16:14:09.821877  3463 solver.cpp:218] Iteration 34200 (7.04465 iter/s, 14.1952s/100 iters), loss = 0.333661
I0927 16:14:09.822016  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333661 (* 1 = 0.333661 loss)
I0927 16:14:09.822033  3463 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I0927 16:14:24.014015  3463 solver.cpp:218] Iteration 34300 (7.04624 iter/s, 14.192s/100 iters), loss = 0.155795
I0927 16:14:24.014046  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155795 (* 1 = 0.155795 loss)
I0927 16:14:24.014062  3463 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I0927 16:14:38.201092  3463 solver.cpp:218] Iteration 34400 (7.0487 iter/s, 14.187s/100 iters), loss = 0.0743136
I0927 16:14:38.201122  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0743138 (* 1 = 0.0743138 loss)
I0927 16:14:38.201138  3463 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I0927 16:14:51.685024  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:14:52.253798  3463 solver.cpp:330] Iteration 34500, Testing net (#0)
I0927 16:14:55.600096  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:14:55.739930  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7768
I0927 16:14:55.739966  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.755138 (* 1 = 0.755138 loss)
I0927 16:14:55.880477  3463 solver.cpp:218] Iteration 34500 (5.65633 iter/s, 17.6793s/100 iters), loss = 0.148093
I0927 16:14:55.880506  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148093 (* 1 = 0.148093 loss)
I0927 16:14:55.880511  3463 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I0927 16:15:10.079538  3463 solver.cpp:218] Iteration 34600 (7.04275 iter/s, 14.199s/100 iters), loss = 0.102484
I0927 16:15:10.079579  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102484 (* 1 = 0.102484 loss)
I0927 16:15:10.079586  3463 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I0927 16:15:24.284721  3463 solver.cpp:218] Iteration 34700 (7.03972 iter/s, 14.2051s/100 iters), loss = 0.190969
I0927 16:15:24.284790  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190969 (* 1 = 0.190969 loss)
I0927 16:15:24.284796  3463 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I0927 16:15:38.490819  3463 solver.cpp:218] Iteration 34800 (7.03928 iter/s, 14.206s/100 iters), loss = 0.209939
I0927 16:15:38.490860  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209939 (* 1 = 0.209939 loss)
I0927 16:15:38.490866  3463 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I0927 16:15:52.693680  3463 solver.cpp:218] Iteration 34900 (7.04087 iter/s, 14.2028s/100 iters), loss = 0.20678
I0927 16:15:52.693722  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20678 (* 1 = 0.20678 loss)
I0927 16:15:52.693727  3463 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I0927 16:16:06.195653  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:16:06.765338  3463 solver.cpp:330] Iteration 35000, Testing net (#0)
I0927 16:16:10.112920  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:16:10.253129  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7807
I0927 16:16:10.253165  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.710181 (* 1 = 0.710181 loss)
I0927 16:16:10.394328  3463 solver.cpp:218] Iteration 35000 (5.64954 iter/s, 17.7006s/100 iters), loss = 0.132676
I0927 16:16:10.394356  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132677 (* 1 = 0.132677 loss)
I0927 16:16:10.394363  3463 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I0927 16:16:24.603605  3463 solver.cpp:218] Iteration 35100 (7.03769 iter/s, 14.2092s/100 iters), loss = 0.181248
I0927 16:16:24.603647  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181248 (* 1 = 0.181248 loss)
I0927 16:16:24.603653  3463 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I0927 16:16:38.811115  3463 solver.cpp:218] Iteration 35200 (7.03857 iter/s, 14.2074s/100 iters), loss = 0.260624
I0927 16:16:38.811233  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260624 (* 1 = 0.260624 loss)
I0927 16:16:38.811241  3463 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I0927 16:16:53.016005  3463 solver.cpp:218] Iteration 35300 (7.0399 iter/s, 14.2047s/100 iters), loss = 0.0904856
I0927 16:16:53.016046  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0904859 (* 1 = 0.0904859 loss)
I0927 16:16:53.016052  3463 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I0927 16:17:07.223384  3463 solver.cpp:218] Iteration 35400 (7.03863 iter/s, 14.2073s/100 iters), loss = 0.175483
I0927 16:17:07.223415  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175483 (* 1 = 0.175483 loss)
I0927 16:17:07.223422  3463 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I0927 16:17:20.725631  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:17:21.294828  3463 solver.cpp:330] Iteration 35500, Testing net (#0)
I0927 16:17:24.643950  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:17:24.784071  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6832
I0927 16:17:24.784107  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.28188 (* 1 = 1.28188 loss)
I0927 16:17:24.924574  3463 solver.cpp:218] Iteration 35500 (5.64936 iter/s, 17.7011s/100 iters), loss = 0.14917
I0927 16:17:24.924602  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14917 (* 1 = 0.14917 loss)
I0927 16:17:24.924609  3463 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I0927 16:17:39.119424  3463 solver.cpp:218] Iteration 35600 (7.04484 iter/s, 14.1948s/100 iters), loss = 0.210344
I0927 16:17:39.119467  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210344 (* 1 = 0.210344 loss)
I0927 16:17:39.119472  3463 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I0927 16:17:53.316107  3463 solver.cpp:218] Iteration 35700 (7.04394 iter/s, 14.1966s/100 iters), loss = 0.166949
I0927 16:17:53.316238  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166949 (* 1 = 0.166949 loss)
I0927 16:17:53.316246  3463 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I0927 16:18:07.506577  3463 solver.cpp:218] Iteration 35800 (7.04706 iter/s, 14.1903s/100 iters), loss = 0.195781
I0927 16:18:07.506616  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195781 (* 1 = 0.195781 loss)
I0927 16:18:07.506623  3463 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I0927 16:18:21.700212  3463 solver.cpp:218] Iteration 35900 (7.04545 iter/s, 14.1936s/100 iters), loss = 0.198602
I0927 16:18:21.700242  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198602 (* 1 = 0.198602 loss)
I0927 16:18:21.700248  3463 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I0927 16:18:35.193076  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:18:35.762303  3463 solver.cpp:330] Iteration 36000, Testing net (#0)
I0927 16:18:39.110363  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:18:39.249697  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7795
I0927 16:18:39.249735  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.757242 (* 1 = 0.757242 loss)
I0927 16:18:39.390741  3463 solver.cpp:218] Iteration 36000 (5.65277 iter/s, 17.6905s/100 iters), loss = 0.231183
I0927 16:18:39.390769  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231183 (* 1 = 0.231183 loss)
I0927 16:18:39.390776  3463 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I0927 16:18:53.587924  3463 solver.cpp:218] Iteration 36100 (7.04368 iter/s, 14.1971s/100 iters), loss = 0.266231
I0927 16:18:53.587954  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266231 (* 1 = 0.266231 loss)
I0927 16:18:53.587960  3463 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I0927 16:19:07.781077  3463 solver.cpp:218] Iteration 36200 (7.04568 iter/s, 14.1931s/100 iters), loss = 0.290606
I0927 16:19:07.781186  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290606 (* 1 = 0.290606 loss)
I0927 16:19:07.781193  3463 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I0927 16:19:21.980149  3463 solver.cpp:218] Iteration 36300 (7.04279 iter/s, 14.1989s/100 iters), loss = 0.233747
I0927 16:19:21.980190  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233747 (* 1 = 0.233747 loss)
I0927 16:19:21.980195  3463 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I0927 16:19:36.177791  3463 solver.cpp:218] Iteration 36400 (7.04346 iter/s, 14.1976s/100 iters), loss = 0.105482
I0927 16:19:36.177831  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.105482 (* 1 = 0.105482 loss)
I0927 16:19:36.177837  3463 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I0927 16:19:49.668591  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:19:50.236956  3463 solver.cpp:330] Iteration 36500, Testing net (#0)
I0927 16:19:53.585250  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:19:53.725596  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7969
I0927 16:19:53.725632  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.606282 (* 1 = 0.606282 loss)
I0927 16:19:53.866564  3463 solver.cpp:218] Iteration 36500 (5.65333 iter/s, 17.6887s/100 iters), loss = 0.169709
I0927 16:19:53.866590  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169709 (* 1 = 0.169709 loss)
I0927 16:19:53.866597  3463 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I0927 16:20:08.056784  3463 solver.cpp:218] Iteration 36600 (7.04714 iter/s, 14.1902s/100 iters), loss = 0.120816
I0927 16:20:08.056813  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120816 (* 1 = 0.120816 loss)
I0927 16:20:08.056819  3463 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I0927 16:20:22.247550  3463 solver.cpp:218] Iteration 36700 (7.04687 iter/s, 14.1907s/100 iters), loss = 0.179258
I0927 16:20:22.247625  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179259 (* 1 = 0.179259 loss)
I0927 16:20:22.247642  3463 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I0927 16:20:36.443639  3463 solver.cpp:218] Iteration 36800 (7.04425 iter/s, 14.196s/100 iters), loss = 0.188796
I0927 16:20:36.443680  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188796 (* 1 = 0.188796 loss)
I0927 16:20:36.443686  3463 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I0927 16:20:50.637768  3463 solver.cpp:218] Iteration 36900 (7.0452 iter/s, 14.1941s/100 iters), loss = 0.206403
I0927 16:20:50.637809  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206404 (* 1 = 0.206404 loss)
I0927 16:20:50.637815  3463 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I0927 16:21:04.123807  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:21:04.692576  3463 solver.cpp:330] Iteration 37000, Testing net (#0)
I0927 16:21:08.039522  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:21:08.179430  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7785
I0927 16:21:08.179466  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.794115 (* 1 = 0.794115 loss)
I0927 16:21:08.320607  3463 solver.cpp:218] Iteration 37000 (5.65523 iter/s, 17.6828s/100 iters), loss = 0.192883
I0927 16:21:08.320634  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192884 (* 1 = 0.192884 loss)
I0927 16:21:08.320641  3463 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I0927 16:21:22.510046  3463 solver.cpp:218] Iteration 37100 (7.04753 iter/s, 14.1894s/100 iters), loss = 0.145527
I0927 16:21:22.510087  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145528 (* 1 = 0.145528 loss)
I0927 16:21:22.510092  3463 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I0927 16:21:36.699015  3463 solver.cpp:218] Iteration 37200 (7.04777 iter/s, 14.1889s/100 iters), loss = 0.174494
I0927 16:21:36.699163  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174494 (* 1 = 0.174494 loss)
I0927 16:21:36.699172  3463 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I0927 16:21:50.894752  3463 solver.cpp:218] Iteration 37300 (7.04445 iter/s, 14.1956s/100 iters), loss = 0.207776
I0927 16:21:50.894793  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207777 (* 1 = 0.207777 loss)
I0927 16:21:50.894799  3463 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I0927 16:22:05.088358  3463 solver.cpp:218] Iteration 37400 (7.04547 iter/s, 14.1935s/100 iters), loss = 0.104568
I0927 16:22:05.088400  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.104568 (* 1 = 0.104568 loss)
I0927 16:22:05.088407  3463 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I0927 16:22:18.581387  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:22:19.149379  3463 solver.cpp:330] Iteration 37500, Testing net (#0)
I0927 16:22:22.497014  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:22:22.637063  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7073
I0927 16:22:22.637097  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.00436 (* 1 = 1.00436 loss)
I0927 16:22:22.777814  3463 solver.cpp:218] Iteration 37500 (5.65311 iter/s, 17.6894s/100 iters), loss = 0.160567
I0927 16:22:22.777842  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160568 (* 1 = 0.160568 loss)
I0927 16:22:22.777848  3463 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I0927 16:22:36.980109  3463 solver.cpp:218] Iteration 37600 (7.04115 iter/s, 14.2022s/100 iters), loss = 0.155957
I0927 16:22:36.980149  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155957 (* 1 = 0.155957 loss)
I0927 16:22:36.980155  3463 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I0927 16:22:51.184701  3463 solver.cpp:218] Iteration 37700 (7.04002 iter/s, 14.2045s/100 iters), loss = 0.182376
I0927 16:22:51.184819  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182376 (* 1 = 0.182376 loss)
I0927 16:22:51.184836  3463 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I0927 16:23:05.390740  3463 solver.cpp:218] Iteration 37800 (7.03933 iter/s, 14.2059s/100 iters), loss = 0.114549
I0927 16:23:05.390781  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114549 (* 1 = 0.114549 loss)
I0927 16:23:05.390787  3463 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I0927 16:23:19.596541  3463 solver.cpp:218] Iteration 37900 (7.03942 iter/s, 14.2057s/100 iters), loss = 0.0851578
I0927 16:23:19.596582  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0851581 (* 1 = 0.0851581 loss)
I0927 16:23:19.596588  3463 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I0927 16:23:33.095437  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:23:33.665299  3463 solver.cpp:330] Iteration 38000, Testing net (#0)
I0927 16:23:37.013366  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:23:37.153422  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7829
I0927 16:23:37.153458  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.715773 (* 1 = 0.715773 loss)
I0927 16:23:37.294792  3463 solver.cpp:218] Iteration 38000 (5.6503 iter/s, 17.6982s/100 iters), loss = 0.178412
I0927 16:23:37.294819  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178412 (* 1 = 0.178412 loss)
I0927 16:23:37.294826  3463 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I0927 16:23:51.491164  3463 solver.cpp:218] Iteration 38100 (7.04409 iter/s, 14.1963s/100 iters), loss = 0.13287
I0927 16:23:51.491195  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13287 (* 1 = 0.13287 loss)
I0927 16:23:51.491201  3463 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I0927 16:24:05.684667  3463 solver.cpp:218] Iteration 38200 (7.04551 iter/s, 14.1934s/100 iters), loss = 0.191572
I0927 16:24:05.684772  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191572 (* 1 = 0.191572 loss)
I0927 16:24:05.684788  3463 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I0927 16:24:19.878931  3463 solver.cpp:218] Iteration 38300 (7.04517 iter/s, 14.1941s/100 iters), loss = 0.150616
I0927 16:24:19.878973  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.150616 (* 1 = 0.150616 loss)
I0927 16:24:19.878978  3463 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I0927 16:24:34.074913  3463 solver.cpp:218] Iteration 38400 (7.04428 iter/s, 14.1959s/100 iters), loss = 0.129064
I0927 16:24:34.074954  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.129064 (* 1 = 0.129064 loss)
I0927 16:24:34.074960  3463 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I0927 16:24:47.567380  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:24:48.136138  3463 solver.cpp:330] Iteration 38500, Testing net (#0)
I0927 16:24:51.483678  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:24:51.623590  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8543
I0927 16:24:51.623627  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.444556 (* 1 = 0.444556 loss)
I0927 16:24:51.764194  3463 solver.cpp:218] Iteration 38500 (5.65317 iter/s, 17.6892s/100 iters), loss = 0.145619
I0927 16:24:51.764221  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145619 (* 1 = 0.145619 loss)
I0927 16:24:51.764228  3463 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I0927 16:25:05.962719  3463 solver.cpp:218] Iteration 38600 (7.04302 iter/s, 14.1985s/100 iters), loss = 0.165289
I0927 16:25:05.962760  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165289 (* 1 = 0.165289 loss)
I0927 16:25:05.962766  3463 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I0927 16:25:20.162039  3463 solver.cpp:218] Iteration 38700 (7.04263 iter/s, 14.1992s/100 iters), loss = 0.210167
I0927 16:25:20.162119  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210167 (* 1 = 0.210167 loss)
I0927 16:25:20.162135  3463 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I0927 16:25:34.359915  3463 solver.cpp:218] Iteration 38800 (7.04336 iter/s, 14.1978s/100 iters), loss = 0.132715
I0927 16:25:34.359956  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132716 (* 1 = 0.132716 loss)
I0927 16:25:34.359961  3463 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I0927 16:25:48.555568  3463 solver.cpp:218] Iteration 38900 (7.04445 iter/s, 14.1956s/100 iters), loss = 0.10083
I0927 16:25:48.555608  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10083 (* 1 = 0.10083 loss)
I0927 16:25:48.555615  3463 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I0927 16:26:02.055649  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:26:02.623880  3463 solver.cpp:330] Iteration 39000, Testing net (#0)
I0927 16:26:05.971626  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:26:06.111560  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8125
I0927 16:26:06.111588  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.604669 (* 1 = 0.604669 loss)
I0927 16:26:06.252248  3463 solver.cpp:218] Iteration 39000 (5.6508 iter/s, 17.6966s/100 iters), loss = 0.110465
I0927 16:26:06.252274  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.110465 (* 1 = 0.110465 loss)
I0927 16:26:06.252280  3463 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I0927 16:26:20.441900  3463 solver.cpp:218] Iteration 39100 (7.04742 iter/s, 14.1896s/100 iters), loss = 0.148565
I0927 16:26:20.441926  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148565 (* 1 = 0.148565 loss)
I0927 16:26:20.441932  3463 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I0927 16:26:34.633285  3463 solver.cpp:218] Iteration 39200 (7.04656 iter/s, 14.1913s/100 iters), loss = 0.303881
I0927 16:26:34.633426  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303881 (* 1 = 0.303881 loss)
I0927 16:26:34.633435  3463 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I0927 16:26:48.832698  3463 solver.cpp:218] Iteration 39300 (7.04263 iter/s, 14.1992s/100 iters), loss = 0.173265
I0927 16:26:48.832731  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173265 (* 1 = 0.173265 loss)
I0927 16:26:48.832746  3463 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I0927 16:27:03.025985  3463 solver.cpp:218] Iteration 39400 (7.04562 iter/s, 14.1932s/100 iters), loss = 0.189977
I0927 16:27:03.026016  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189977 (* 1 = 0.189977 loss)
I0927 16:27:03.026021  3463 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I0927 16:27:16.514398  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:27:17.083068  3463 solver.cpp:330] Iteration 39500, Testing net (#0)
I0927 16:27:20.428699  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:27:20.569075  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7996
I0927 16:27:20.569113  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.660926 (* 1 = 0.660926 loss)
I0927 16:27:20.709542  3463 solver.cpp:218] Iteration 39500 (5.65499 iter/s, 17.6835s/100 iters), loss = 0.201762
I0927 16:27:20.709570  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201762 (* 1 = 0.201762 loss)
I0927 16:27:20.709578  3463 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I0927 16:27:34.914204  3463 solver.cpp:218] Iteration 39600 (7.03998 iter/s, 14.2046s/100 iters), loss = 0.191879
I0927 16:27:34.914235  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191879 (* 1 = 0.191879 loss)
I0927 16:27:34.914252  3463 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I0927 16:27:49.116775  3463 solver.cpp:218] Iteration 39700 (7.04101 iter/s, 14.2025s/100 iters), loss = 0.221809
I0927 16:27:49.116835  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221809 (* 1 = 0.221809 loss)
I0927 16:27:49.116852  3463 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I0927 16:28:03.319196  3463 solver.cpp:218] Iteration 39800 (7.0411 iter/s, 14.2023s/100 iters), loss = 0.201083
I0927 16:28:03.319227  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201083 (* 1 = 0.201083 loss)
I0927 16:28:03.319236  3463 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I0927 16:28:17.524018  3463 solver.cpp:218] Iteration 39900 (7.0399 iter/s, 14.2048s/100 iters), loss = 0.137656
I0927 16:28:17.524047  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.137656 (* 1 = 0.137656 loss)
I0927 16:28:17.524063  3463 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I0927 16:28:31.019798  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:28:31.588778  3463 solver.cpp:330] Iteration 40000, Testing net (#0)
I0927 16:28:34.935593  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:28:35.075467  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7693
I0927 16:28:35.075503  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.785546 (* 1 = 0.785546 loss)
I0927 16:28:35.216403  3463 solver.cpp:218] Iteration 40000 (5.65217 iter/s, 17.6923s/100 iters), loss = 0.133586
I0927 16:28:35.216431  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133586 (* 1 = 0.133586 loss)
I0927 16:28:35.216437  3463 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I0927 16:28:35.216440  3463 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I0927 16:28:49.422621  3463 solver.cpp:218] Iteration 40100 (7.03921 iter/s, 14.2061s/100 iters), loss = 0.189236
I0927 16:28:49.422652  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189237 (* 1 = 0.189237 loss)
I0927 16:28:49.422667  3463 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I0927 16:29:03.627029  3463 solver.cpp:218] Iteration 40200 (7.0401 iter/s, 14.2043s/100 iters), loss = 0.182568
I0927 16:29:03.627177  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182568 (* 1 = 0.182568 loss)
I0927 16:29:03.627184  3463 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I0927 16:29:17.826784  3463 solver.cpp:218] Iteration 40300 (7.04247 iter/s, 14.1996s/100 iters), loss = 0.0554266
I0927 16:29:17.826815  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0554267 (* 1 = 0.0554267 loss)
I0927 16:29:17.826831  3463 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I0927 16:29:32.032058  3463 solver.cpp:218] Iteration 40400 (7.03967 iter/s, 14.2052s/100 iters), loss = 0.0301527
I0927 16:29:32.032088  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0301527 (* 1 = 0.0301527 loss)
I0927 16:29:32.032104  3463 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I0927 16:29:45.532063  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:29:46.101814  3463 solver.cpp:330] Iteration 40500, Testing net (#0)
I0927 16:29:49.447552  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:29:49.587487  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9052
I0927 16:29:49.587524  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.283248 (* 1 = 0.283248 loss)
I0927 16:29:49.728581  3463 solver.cpp:218] Iteration 40500 (5.65085 iter/s, 17.6965s/100 iters), loss = 0.0689611
I0927 16:29:49.728607  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0689612 (* 1 = 0.0689612 loss)
I0927 16:29:49.728615  3463 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I0927 16:30:03.927386  3463 solver.cpp:218] Iteration 40600 (7.04288 iter/s, 14.1987s/100 iters), loss = 0.180985
I0927 16:30:03.927428  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180985 (* 1 = 0.180985 loss)
I0927 16:30:03.927433  3463 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I0927 16:30:18.121647  3463 solver.cpp:218] Iteration 40700 (7.04514 iter/s, 14.1942s/100 iters), loss = 0.105646
I0927 16:30:18.121724  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.105646 (* 1 = 0.105646 loss)
I0927 16:30:18.121731  3463 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I0927 16:30:32.312250  3463 solver.cpp:218] Iteration 40800 (7.04697 iter/s, 14.1905s/100 iters), loss = 0.0341307
I0927 16:30:32.312279  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0341308 (* 1 = 0.0341308 loss)
I0927 16:30:32.312285  3463 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I0927 16:30:46.508154  3463 solver.cpp:218] Iteration 40900 (7.04432 iter/s, 14.1958s/100 iters), loss = 0.0383071
I0927 16:30:46.508195  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0383073 (* 1 = 0.0383073 loss)
I0927 16:30:46.508201  3463 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I0927 16:31:00.003585  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:31:00.574643  3463 solver.cpp:330] Iteration 41000, Testing net (#0)
I0927 16:31:03.920630  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:31:04.060809  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9146
I0927 16:31:04.060847  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.259394 (* 1 = 0.259394 loss)
I0927 16:31:04.201604  3463 solver.cpp:218] Iteration 41000 (5.65184 iter/s, 17.6934s/100 iters), loss = 0.0726138
I0927 16:31:04.201630  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0726139 (* 1 = 0.0726139 loss)
I0927 16:31:04.201637  3463 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I0927 16:31:18.400857  3463 solver.cpp:218] Iteration 41100 (7.04266 iter/s, 14.1992s/100 iters), loss = 0.101848
I0927 16:31:18.400898  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.101848 (* 1 = 0.101848 loss)
I0927 16:31:18.400904  3463 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I0927 16:31:32.599587  3463 solver.cpp:218] Iteration 41200 (7.04292 iter/s, 14.1987s/100 iters), loss = 0.0824431
I0927 16:31:32.599725  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0824432 (* 1 = 0.0824432 loss)
I0927 16:31:32.599732  3463 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I0927 16:31:46.797248  3463 solver.cpp:218] Iteration 41300 (7.0435 iter/s, 14.1975s/100 iters), loss = 0.0668225
I0927 16:31:46.797291  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0668227 (* 1 = 0.0668227 loss)
I0927 16:31:46.797297  3463 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I0927 16:32:00.996136  3463 solver.cpp:218] Iteration 41400 (7.04285 iter/s, 14.1988s/100 iters), loss = 0.0707936
I0927 16:32:00.996178  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0707937 (* 1 = 0.0707937 loss)
I0927 16:32:00.996183  3463 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I0927 16:32:14.486452  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:32:15.055608  3463 solver.cpp:330] Iteration 41500, Testing net (#0)
I0927 16:32:18.401451  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:32:18.541426  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9159
I0927 16:32:18.541463  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.259841 (* 1 = 0.259841 loss)
I0927 16:32:18.682261  3463 solver.cpp:218] Iteration 41500 (5.65418 iter/s, 17.686s/100 iters), loss = 0.0220204
I0927 16:32:18.682287  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0220205 (* 1 = 0.0220205 loss)
I0927 16:32:18.682294  3463 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I0927 16:32:32.878290  3463 solver.cpp:218] Iteration 41600 (7.04426 iter/s, 14.196s/100 iters), loss = 0.0806444
I0927 16:32:32.878331  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0806445 (* 1 = 0.0806445 loss)
I0927 16:32:32.878337  3463 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I0927 16:32:47.072420  3463 solver.cpp:218] Iteration 41700 (7.04521 iter/s, 14.194s/100 iters), loss = 0.0585802
I0927 16:32:47.072531  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0585803 (* 1 = 0.0585803 loss)
I0927 16:32:47.072547  3463 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I0927 16:33:01.271980  3463 solver.cpp:218] Iteration 41800 (7.04254 iter/s, 14.1994s/100 iters), loss = 0.0444835
I0927 16:33:01.272020  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0444836 (* 1 = 0.0444836 loss)
I0927 16:33:01.272027  3463 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I0927 16:33:15.467280  3463 solver.cpp:218] Iteration 41900 (7.04462 iter/s, 14.1952s/100 iters), loss = 0.0212414
I0927 16:33:15.467320  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0212415 (* 1 = 0.0212415 loss)
I0927 16:33:15.467326  3463 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I0927 16:33:28.952492  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:33:29.522089  3463 solver.cpp:330] Iteration 42000, Testing net (#0)
I0927 16:33:32.869140  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:33:33.009719  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9169
I0927 16:33:33.009755  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.267015 (* 1 = 0.267015 loss)
I0927 16:33:33.150131  3463 solver.cpp:218] Iteration 42000 (5.65522 iter/s, 17.6828s/100 iters), loss = 0.0401766
I0927 16:33:33.150158  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0401767 (* 1 = 0.0401767 loss)
I0927 16:33:33.150166  3463 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I0927 16:33:47.343313  3463 solver.cpp:218] Iteration 42100 (7.04567 iter/s, 14.1931s/100 iters), loss = 0.0559798
I0927 16:33:47.343354  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.05598 (* 1 = 0.05598 loss)
I0927 16:33:47.343360  3463 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I0927 16:34:01.534241  3463 solver.cpp:218] Iteration 42200 (7.04679 iter/s, 14.1908s/100 iters), loss = 0.0790054
I0927 16:34:01.534415  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0790056 (* 1 = 0.0790056 loss)
I0927 16:34:01.534432  3463 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I0927 16:34:15.720052  3463 solver.cpp:218] Iteration 42300 (7.04939 iter/s, 14.1856s/100 iters), loss = 0.0649721
I0927 16:34:15.720093  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0649722 (* 1 = 0.0649722 loss)
I0927 16:34:15.720098  3463 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I0927 16:34:29.911471  3463 solver.cpp:218] Iteration 42400 (7.04655 iter/s, 14.1913s/100 iters), loss = 0.0264333
I0927 16:34:29.911512  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0264334 (* 1 = 0.0264334 loss)
I0927 16:34:29.911519  3463 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I0927 16:34:43.402390  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:34:43.969700  3463 solver.cpp:330] Iteration 42500, Testing net (#0)
I0927 16:34:47.318351  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:34:47.458019  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9193
I0927 16:34:47.458055  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.262178 (* 1 = 0.262178 loss)
I0927 16:34:47.599396  3463 solver.cpp:218] Iteration 42500 (5.6536 iter/s, 17.6878s/100 iters), loss = 0.0413176
I0927 16:34:47.599424  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0413177 (* 1 = 0.0413177 loss)
I0927 16:34:47.599431  3463 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I0927 16:35:01.804114  3463 solver.cpp:218] Iteration 42600 (7.03995 iter/s, 14.2047s/100 iters), loss = 0.0480548
I0927 16:35:01.804155  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0480548 (* 1 = 0.0480548 loss)
I0927 16:35:01.804162  3463 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I0927 16:35:16.011055  3463 solver.cpp:218] Iteration 42700 (7.03885 iter/s, 14.2069s/100 iters), loss = 0.0686325
I0927 16:35:16.011127  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0686326 (* 1 = 0.0686326 loss)
I0927 16:35:16.011134  3463 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I0927 16:35:30.213899  3463 solver.cpp:218] Iteration 42800 (7.0409 iter/s, 14.2027s/100 iters), loss = 0.0220138
I0927 16:35:30.213939  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0220139 (* 1 = 0.0220139 loss)
I0927 16:35:30.213945  3463 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I0927 16:35:44.413867  3463 solver.cpp:218] Iteration 42900 (7.04231 iter/s, 14.1999s/100 iters), loss = 0.01283
I0927 16:35:44.413908  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128301 (* 1 = 0.0128301 loss)
I0927 16:35:44.413914  3463 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I0927 16:35:57.915719  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:35:58.485013  3463 solver.cpp:330] Iteration 43000, Testing net (#0)
I0927 16:36:01.832679  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:36:01.972625  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9182
I0927 16:36:01.972662  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.265646 (* 1 = 0.265646 loss)
I0927 16:36:02.113512  3463 solver.cpp:218] Iteration 43000 (5.64986 iter/s, 17.6996s/100 iters), loss = 0.0230699
I0927 16:36:02.113538  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.02307 (* 1 = 0.02307 loss)
I0927 16:36:02.113545  3463 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I0927 16:36:16.310258  3463 solver.cpp:218] Iteration 43100 (7.0439 iter/s, 14.1967s/100 iters), loss = 0.0266324
I0927 16:36:16.310288  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0266325 (* 1 = 0.0266325 loss)
I0927 16:36:16.310294  3463 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I0927 16:36:30.506420  3463 solver.cpp:218] Iteration 43200 (7.04419 iter/s, 14.1961s/100 iters), loss = 0.0600561
I0927 16:36:30.506541  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0600562 (* 1 = 0.0600562 loss)
I0927 16:36:30.506547  3463 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I0927 16:36:44.702600  3463 solver.cpp:218] Iteration 43300 (7.04422 iter/s, 14.196s/100 iters), loss = 0.0120529
I0927 16:36:44.702641  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012053 (* 1 = 0.012053 loss)
I0927 16:36:44.702647  3463 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I0927 16:36:58.899621  3463 solver.cpp:218] Iteration 43400 (7.04377 iter/s, 14.1969s/100 iters), loss = 0.016632
I0927 16:36:58.899663  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0166321 (* 1 = 0.0166321 loss)
I0927 16:36:58.899669  3463 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I0927 16:37:12.391999  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:37:12.960945  3463 solver.cpp:330] Iteration 43500, Testing net (#0)
I0927 16:37:16.306572  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:37:16.446854  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9191
I0927 16:37:16.446892  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.268801 (* 1 = 0.268801 loss)
I0927 16:37:16.587745  3463 solver.cpp:218] Iteration 43500 (5.65354 iter/s, 17.688s/100 iters), loss = 0.0181157
I0927 16:37:16.587774  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181158 (* 1 = 0.0181158 loss)
I0927 16:37:16.587780  3463 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I0927 16:37:30.790436  3463 solver.cpp:218] Iteration 43600 (7.04095 iter/s, 14.2026s/100 iters), loss = 0.0387066
I0927 16:37:30.790478  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0387066 (* 1 = 0.0387066 loss)
I0927 16:37:30.790484  3463 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I0927 16:37:44.990221  3463 solver.cpp:218] Iteration 43700 (7.0424 iter/s, 14.1997s/100 iters), loss = 0.0673442
I0927 16:37:44.990294  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0673442 (* 1 = 0.0673442 loss)
I0927 16:37:44.990301  3463 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I0927 16:37:59.193545  3463 solver.cpp:218] Iteration 43800 (7.04066 iter/s, 14.2032s/100 iters), loss = 0.0210962
I0927 16:37:59.193588  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0210962 (* 1 = 0.0210962 loss)
I0927 16:37:59.193593  3463 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I0927 16:38:13.396334  3463 solver.cpp:218] Iteration 43900 (7.04091 iter/s, 14.2027s/100 iters), loss = 0.013384
I0927 16:38:13.396375  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0133841 (* 1 = 0.0133841 loss)
I0927 16:38:13.396381  3463 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I0927 16:38:26.889847  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:38:27.458287  3463 solver.cpp:330] Iteration 44000, Testing net (#0)
I0927 16:38:30.805037  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:38:30.945103  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9206
I0927 16:38:30.945140  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.259869 (* 1 = 0.259869 loss)
I0927 16:38:31.085881  3463 solver.cpp:218] Iteration 44000 (5.65308 iter/s, 17.6895s/100 iters), loss = 0.0227605
I0927 16:38:31.085909  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227605 (* 1 = 0.0227605 loss)
I0927 16:38:31.085916  3463 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I0927 16:38:45.277479  3463 solver.cpp:218] Iteration 44100 (7.04646 iter/s, 14.1915s/100 iters), loss = 0.0150392
I0927 16:38:45.277509  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0150392 (* 1 = 0.0150392 loss)
I0927 16:38:45.277515  3463 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I0927 16:38:59.470715  3463 solver.cpp:218] Iteration 44200 (7.04564 iter/s, 14.1932s/100 iters), loss = 0.0454631
I0927 16:38:59.470849  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0454631 (* 1 = 0.0454631 loss)
I0927 16:38:59.470865  3463 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I0927 16:39:13.665812  3463 solver.cpp:218] Iteration 44300 (7.04476 iter/s, 14.1949s/100 iters), loss = 0.0219333
I0927 16:39:13.665841  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0219334 (* 1 = 0.0219334 loss)
I0927 16:39:13.665848  3463 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I0927 16:39:27.861179  3463 solver.cpp:218] Iteration 44400 (7.04459 iter/s, 14.1953s/100 iters), loss = 0.0498585
I0927 16:39:27.861219  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0498585 (* 1 = 0.0498585 loss)
I0927 16:39:27.861225  3463 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I0927 16:39:41.352491  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:39:41.920938  3463 solver.cpp:330] Iteration 44500, Testing net (#0)
I0927 16:39:45.268267  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:39:45.407711  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9227
I0927 16:39:45.407747  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.261084 (* 1 = 0.261084 loss)
I0927 16:39:45.548599  3463 solver.cpp:218] Iteration 44500 (5.65376 iter/s, 17.6873s/100 iters), loss = 0.0151943
I0927 16:39:45.548626  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0151944 (* 1 = 0.0151944 loss)
I0927 16:39:45.548633  3463 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I0927 16:39:59.752853  3463 solver.cpp:218] Iteration 44600 (7.04018 iter/s, 14.2042s/100 iters), loss = 0.0408083
I0927 16:39:59.752894  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0408084 (* 1 = 0.0408084 loss)
I0927 16:39:59.752900  3463 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I0927 16:40:13.954895  3463 solver.cpp:218] Iteration 44700 (7.04128 iter/s, 14.202s/100 iters), loss = 0.0428796
I0927 16:40:13.954969  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0428796 (* 1 = 0.0428796 loss)
I0927 16:40:13.954977  3463 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I0927 16:40:28.154274  3463 solver.cpp:218] Iteration 44800 (7.04262 iter/s, 14.1993s/100 iters), loss = 0.0289306
I0927 16:40:28.154304  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0289306 (* 1 = 0.0289306 loss)
I0927 16:40:28.154310  3463 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I0927 16:40:42.355834  3463 solver.cpp:218] Iteration 44900 (7.04151 iter/s, 14.2015s/100 iters), loss = 0.0332845
I0927 16:40:42.355875  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0332846 (* 1 = 0.0332846 loss)
I0927 16:40:42.355880  3463 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I0927 16:40:55.857990  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:40:56.427168  3463 solver.cpp:330] Iteration 45000, Testing net (#0)
I0927 16:40:59.772969  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:40:59.912513  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9181
I0927 16:40:59.912547  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.278754 (* 1 = 0.278754 loss)
I0927 16:41:00.053155  3463 solver.cpp:218] Iteration 45000 (5.6506 iter/s, 17.6972s/100 iters), loss = 0.0151901
I0927 16:41:00.053181  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0151901 (* 1 = 0.0151901 loss)
I0927 16:41:00.053189  3463 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I0927 16:41:14.259234  3463 solver.cpp:218] Iteration 45100 (7.03927 iter/s, 14.206s/100 iters), loss = 0.0267403
I0927 16:41:14.259264  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0267403 (* 1 = 0.0267403 loss)
I0927 16:41:14.259270  3463 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I0927 16:41:28.462265  3463 solver.cpp:218] Iteration 45200 (7.04078 iter/s, 14.203s/100 iters), loss = 0.0499676
I0927 16:41:28.462335  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0499677 (* 1 = 0.0499677 loss)
I0927 16:41:28.462342  3463 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I0927 16:41:42.668990  3463 solver.cpp:218] Iteration 45300 (7.03897 iter/s, 14.2066s/100 iters), loss = 0.0181136
I0927 16:41:42.669031  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181137 (* 1 = 0.0181137 loss)
I0927 16:41:42.669037  3463 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I0927 16:41:56.871814  3463 solver.cpp:218] Iteration 45400 (7.04089 iter/s, 14.2027s/100 iters), loss = 0.0192982
I0927 16:41:56.871855  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0192982 (* 1 = 0.0192982 loss)
I0927 16:41:56.871860  3463 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I0927 16:42:10.371294  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:42:10.940996  3463 solver.cpp:330] Iteration 45500, Testing net (#0)
I0927 16:42:14.287974  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:42:14.427994  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9172
I0927 16:42:14.428030  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.280691 (* 1 = 0.280691 loss)
I0927 16:42:14.569197  3463 solver.cpp:218] Iteration 45500 (5.65058 iter/s, 17.6973s/100 iters), loss = 0.0125921
I0927 16:42:14.569224  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125921 (* 1 = 0.0125921 loss)
I0927 16:42:14.569231  3463 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I0927 16:42:28.764250  3463 solver.cpp:218] Iteration 45600 (7.04474 iter/s, 14.195s/100 iters), loss = 0.0439325
I0927 16:42:28.764292  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0439325 (* 1 = 0.0439325 loss)
I0927 16:42:28.764297  3463 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I0927 16:42:42.955756  3463 solver.cpp:218] Iteration 45700 (7.04651 iter/s, 14.1914s/100 iters), loss = 0.0261421
I0927 16:42:42.955850  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0261421 (* 1 = 0.0261421 loss)
I0927 16:42:42.955857  3463 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I0927 16:42:57.149520  3463 solver.cpp:218] Iteration 45800 (7.04541 iter/s, 14.1936s/100 iters), loss = 0.0085054
I0927 16:42:57.149551  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00850543 (* 1 = 0.00850543 loss)
I0927 16:42:57.149557  3463 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I0927 16:43:11.343713  3463 solver.cpp:218] Iteration 45900 (7.04517 iter/s, 14.1941s/100 iters), loss = 0.024342
I0927 16:43:11.343744  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.024342 (* 1 = 0.024342 loss)
I0927 16:43:11.343750  3463 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I0927 16:43:24.832794  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:43:25.401852  3463 solver.cpp:330] Iteration 46000, Testing net (#0)
I0927 16:43:28.747257  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:43:28.887312  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.922
I0927 16:43:28.887349  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.267205 (* 1 = 0.267205 loss)
I0927 16:43:29.028354  3463 solver.cpp:218] Iteration 46000 (5.65465 iter/s, 17.6846s/100 iters), loss = 0.0248073
I0927 16:43:29.028381  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0248073 (* 1 = 0.0248073 loss)
I0927 16:43:29.028388  3463 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I0927 16:43:43.220631  3463 solver.cpp:218] Iteration 46100 (7.04612 iter/s, 14.1922s/100 iters), loss = 0.00825543
I0927 16:43:43.220672  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00825543 (* 1 = 0.00825543 loss)
I0927 16:43:43.220679  3463 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I0927 16:43:57.416587  3463 solver.cpp:218] Iteration 46200 (7.0443 iter/s, 14.1959s/100 iters), loss = 0.072129
I0927 16:43:57.416728  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.072129 (* 1 = 0.072129 loss)
I0927 16:43:57.416736  3463 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I0927 16:44:11.612321  3463 solver.cpp:218] Iteration 46300 (7.04446 iter/s, 14.1956s/100 iters), loss = 0.009353
I0927 16:44:11.612362  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.009353 (* 1 = 0.009353 loss)
I0927 16:44:11.612368  3463 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I0927 16:44:25.804267  3463 solver.cpp:218] Iteration 46400 (7.04629 iter/s, 14.1919s/100 iters), loss = 0.0111741
I0927 16:44:25.804307  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011174 (* 1 = 0.011174 loss)
I0927 16:44:25.804313  3463 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I0927 16:44:39.294860  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:44:39.863703  3463 solver.cpp:330] Iteration 46500, Testing net (#0)
I0927 16:44:43.211608  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:44:43.351750  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9232
I0927 16:44:43.351788  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.277128 (* 1 = 0.277128 loss)
I0927 16:44:43.492734  3463 solver.cpp:218] Iteration 46500 (5.65343 iter/s, 17.6884s/100 iters), loss = 0.00693879
I0927 16:44:43.492763  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00693875 (* 1 = 0.00693875 loss)
I0927 16:44:43.492770  3463 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I0927 16:44:57.680244  3463 solver.cpp:218] Iteration 46600 (7.04849 iter/s, 14.1874s/100 iters), loss = 0.00840753
I0927 16:44:57.680284  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00840748 (* 1 = 0.00840748 loss)
I0927 16:44:57.680289  3463 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I0927 16:45:11.867940  3463 solver.cpp:218] Iteration 46700 (7.0484 iter/s, 14.1876s/100 iters), loss = 0.027847
I0927 16:45:11.868059  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0278469 (* 1 = 0.0278469 loss)
I0927 16:45:11.868077  3463 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I0927 16:45:26.054500  3463 solver.cpp:218] Iteration 46800 (7.049 iter/s, 14.1864s/100 iters), loss = 0.0127864
I0927 16:45:26.054543  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127863 (* 1 = 0.0127863 loss)
I0927 16:45:26.054549  3463 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I0927 16:45:40.238716  3463 solver.cpp:218] Iteration 46900 (7.05013 iter/s, 14.1841s/100 iters), loss = 0.00474028
I0927 16:45:40.238759  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00474022 (* 1 = 0.00474022 loss)
I0927 16:45:40.238765  3463 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I0927 16:45:53.723340  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:45:54.291564  3463 solver.cpp:330] Iteration 47000, Testing net (#0)
I0927 16:45:57.638309  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:45:57.778358  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9236
I0927 16:45:57.778394  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.274932 (* 1 = 0.274932 loss)
I0927 16:45:57.919600  3463 solver.cpp:218] Iteration 47000 (5.65585 iter/s, 17.6808s/100 iters), loss = 0.00559509
I0927 16:45:57.919630  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00559504 (* 1 = 0.00559504 loss)
I0927 16:45:57.919636  3463 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I0927 16:46:12.113203  3463 solver.cpp:218] Iteration 47100 (7.04546 iter/s, 14.1935s/100 iters), loss = 0.0199397
I0927 16:46:12.113234  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0199397 (* 1 = 0.0199397 loss)
I0927 16:46:12.113240  3463 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I0927 16:46:26.305764  3463 solver.cpp:218] Iteration 47200 (7.04598 iter/s, 14.1925s/100 iters), loss = 0.0318187
I0927 16:46:26.305871  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0318186 (* 1 = 0.0318186 loss)
I0927 16:46:26.305878  3463 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I0927 16:46:40.494616  3463 solver.cpp:218] Iteration 47300 (7.04786 iter/s, 14.1887s/100 iters), loss = 0.0278855
I0927 16:46:40.494648  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0278854 (* 1 = 0.0278854 loss)
I0927 16:46:40.494654  3463 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I0927 16:46:54.681582  3463 solver.cpp:218] Iteration 47400 (7.04876 iter/s, 14.1869s/100 iters), loss = 0.00967981
I0927 16:46:54.681612  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00967974 (* 1 = 0.00967974 loss)
I0927 16:46:54.681618  3463 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I0927 16:47:08.168264  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:47:08.736569  3463 solver.cpp:330] Iteration 47500, Testing net (#0)
I0927 16:47:12.083638  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:47:12.223971  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9248
I0927 16:47:12.224006  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.274425 (* 1 = 0.274425 loss)
I0927 16:47:12.365120  3463 solver.cpp:218] Iteration 47500 (5.655 iter/s, 17.6835s/100 iters), loss = 0.00267984
I0927 16:47:12.365149  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00267977 (* 1 = 0.00267977 loss)
I0927 16:47:12.365154  3463 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I0927 16:47:26.572206  3463 solver.cpp:218] Iteration 47600 (7.03877 iter/s, 14.207s/100 iters), loss = 0.0320985
I0927 16:47:26.572247  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0320984 (* 1 = 0.0320984 loss)
I0927 16:47:26.572252  3463 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I0927 16:47:40.774718  3463 solver.cpp:218] Iteration 47700 (7.04105 iter/s, 14.2024s/100 iters), loss = 0.0400191
I0927 16:47:40.774791  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.040019 (* 1 = 0.040019 loss)
I0927 16:47:40.774799  3463 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I0927 16:47:54.982167  3463 solver.cpp:218] Iteration 47800 (7.03862 iter/s, 14.2073s/100 iters), loss = 0.00591497
I0927 16:47:54.982208  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0059149 (* 1 = 0.0059149 loss)
I0927 16:47:54.982213  3463 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I0927 16:48:09.183957  3463 solver.cpp:218] Iteration 47900 (7.0414 iter/s, 14.2017s/100 iters), loss = 0.0184701
I0927 16:48:09.183989  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0184701 (* 1 = 0.0184701 loss)
I0927 16:48:09.183995  3463 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I0927 16:48:22.683954  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:48:23.253726  3463 solver.cpp:330] Iteration 48000, Testing net (#0)
I0927 16:48:26.600215  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:48:26.740149  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9242
I0927 16:48:26.740185  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.282631 (* 1 = 0.282631 loss)
I0927 16:48:26.880718  3463 solver.cpp:218] Iteration 48000 (5.65077 iter/s, 17.6967s/100 iters), loss = 0.0123285
I0927 16:48:26.880745  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0123284 (* 1 = 0.0123284 loss)
I0927 16:48:26.880753  3463 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I0927 16:48:41.077807  3463 solver.cpp:218] Iteration 48100 (7.04373 iter/s, 14.197s/100 iters), loss = 0.0235185
I0927 16:48:41.077838  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0235184 (* 1 = 0.0235184 loss)
I0927 16:48:41.077844  3463 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I0927 16:48:55.273731  3463 solver.cpp:218] Iteration 48200 (7.04431 iter/s, 14.1958s/100 iters), loss = 0.0101554
I0927 16:48:55.273871  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101553 (* 1 = 0.0101553 loss)
I0927 16:48:55.273880  3463 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I0927 16:49:09.476173  3463 solver.cpp:218] Iteration 48300 (7.04113 iter/s, 14.2023s/100 iters), loss = 0.0181037
I0927 16:49:09.476215  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181036 (* 1 = 0.0181036 loss)
I0927 16:49:09.476222  3463 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I0927 16:49:23.674830  3463 solver.cpp:218] Iteration 48400 (7.04296 iter/s, 14.1986s/100 iters), loss = 0.00940973
I0927 16:49:23.674872  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00940964 (* 1 = 0.00940964 loss)
I0927 16:49:23.674878  3463 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I0927 16:49:37.167719  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:49:37.735687  3463 solver.cpp:330] Iteration 48500, Testing net (#0)
I0927 16:49:41.082789  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:49:41.222944  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9219
I0927 16:49:41.222980  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.29375 (* 1 = 0.29375 loss)
I0927 16:49:41.364058  3463 solver.cpp:218] Iteration 48500 (5.65319 iter/s, 17.6891s/100 iters), loss = 0.0062141
I0927 16:49:41.364084  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00621402 (* 1 = 0.00621402 loss)
I0927 16:49:41.364090  3463 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I0927 16:49:55.567850  3463 solver.cpp:218] Iteration 48600 (7.0404 iter/s, 14.2037s/100 iters), loss = 0.0140744
I0927 16:49:55.567880  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0140743 (* 1 = 0.0140743 loss)
I0927 16:49:55.567886  3463 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I0927 16:50:09.771365  3463 solver.cpp:218] Iteration 48700 (7.04054 iter/s, 14.2034s/100 iters), loss = 0.0392978
I0927 16:50:09.771445  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0392977 (* 1 = 0.0392977 loss)
I0927 16:50:09.771451  3463 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I0927 16:50:23.967839  3463 solver.cpp:218] Iteration 48800 (7.04406 iter/s, 14.1964s/100 iters), loss = 0.00490065
I0927 16:50:23.967880  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00490058 (* 1 = 0.00490058 loss)
I0927 16:50:23.967885  3463 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I0927 16:50:38.164675  3463 solver.cpp:218] Iteration 48900 (7.04386 iter/s, 14.1968s/100 iters), loss = 0.00740564
I0927 16:50:38.164714  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00740558 (* 1 = 0.00740558 loss)
I0927 16:50:38.164721  3463 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I0927 16:50:51.659368  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:50:52.228395  3463 solver.cpp:330] Iteration 49000, Testing net (#0)
I0927 16:50:55.574383  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:50:55.714498  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9201
I0927 16:50:55.714538  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.287755 (* 1 = 0.287755 loss)
I0927 16:50:55.855469  3463 solver.cpp:218] Iteration 49000 (5.65269 iter/s, 17.6907s/100 iters), loss = 0.00399183
I0927 16:50:55.855495  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00399176 (* 1 = 0.00399176 loss)
I0927 16:50:55.855502  3463 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I0927 16:51:10.052856  3463 solver.cpp:218] Iteration 49100 (7.04358 iter/s, 14.1973s/100 iters), loss = 0.00956405
I0927 16:51:10.052897  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00956398 (* 1 = 0.00956398 loss)
I0927 16:51:10.052903  3463 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I0927 16:51:24.240067  3463 solver.cpp:218] Iteration 49200 (7.04864 iter/s, 14.1871s/100 iters), loss = 0.0300035
I0927 16:51:24.240150  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0300034 (* 1 = 0.0300034 loss)
I0927 16:51:24.240167  3463 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I0927 16:51:38.434327  3463 solver.cpp:218] Iteration 49300 (7.04516 iter/s, 14.1941s/100 iters), loss = 0.0177178
I0927 16:51:38.434370  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177177 (* 1 = 0.0177177 loss)
I0927 16:51:38.434376  3463 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I0927 16:51:52.630343  3463 solver.cpp:218] Iteration 49400 (7.04427 iter/s, 14.1959s/100 iters), loss = 0.00350234
I0927 16:51:52.630384  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00350227 (* 1 = 0.00350227 loss)
I0927 16:51:52.630390  3463 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I0927 16:52:06.121644  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:52:06.690456  3463 solver.cpp:330] Iteration 49500, Testing net (#0)
I0927 16:52:10.036231  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:52:10.176906  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9218
I0927 16:52:10.176934  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.287823 (* 1 = 0.287823 loss)
I0927 16:52:10.317834  3463 solver.cpp:218] Iteration 49500 (5.65374 iter/s, 17.6874s/100 iters), loss = 0.00634607
I0927 16:52:10.317862  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00634599 (* 1 = 0.00634599 loss)
I0927 16:52:10.317869  3463 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I0927 16:52:24.519522  3463 solver.cpp:218] Iteration 49600 (7.04145 iter/s, 14.2016s/100 iters), loss = 0.0244756
I0927 16:52:24.519563  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0244756 (* 1 = 0.0244756 loss)
I0927 16:52:24.519569  3463 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I0927 16:52:38.721848  3463 solver.cpp:218] Iteration 49700 (7.04114 iter/s, 14.2022s/100 iters), loss = 0.00747323
I0927 16:52:38.721956  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00747315 (* 1 = 0.00747315 loss)
I0927 16:52:38.721963  3463 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I0927 16:52:52.923686  3463 solver.cpp:218] Iteration 49800 (7.04141 iter/s, 14.2017s/100 iters), loss = 0.00390978
I0927 16:52:52.923718  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00390969 (* 1 = 0.00390969 loss)
I0927 16:52:52.923724  3463 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I0927 16:53:07.129647  3463 solver.cpp:218] Iteration 49900 (7.03933 iter/s, 14.2059s/100 iters), loss = 0.0410218
I0927 16:53:07.129688  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0410217 (* 1 = 0.0410217 loss)
I0927 16:53:07.129694  3463 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I0927 16:53:20.629137  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:53:21.199431  3463 solver.cpp:330] Iteration 50000, Testing net (#0)
I0927 16:53:24.546874  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:53:24.686839  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9209
I0927 16:53:24.686875  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296228 (* 1 = 0.296228 loss)
I0927 16:53:24.827585  3463 solver.cpp:218] Iteration 50000 (5.6504 iter/s, 17.6979s/100 iters), loss = 0.00567239
I0927 16:53:24.827613  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00567231 (* 1 = 0.00567231 loss)
I0927 16:53:24.827620  3463 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I0927 16:53:39.028240  3463 solver.cpp:218] Iteration 50100 (7.04196 iter/s, 14.2006s/100 iters), loss = 0.0329106
I0927 16:53:39.028280  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0329105 (* 1 = 0.0329105 loss)
I0927 16:53:39.028286  3463 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I0927 16:53:53.228431  3463 solver.cpp:218] Iteration 50200 (7.0422 iter/s, 14.2001s/100 iters), loss = 0.0369104
I0927 16:53:53.228505  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0369103 (* 1 = 0.0369103 loss)
I0927 16:53:53.228513  3463 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I0927 16:54:07.435485  3463 solver.cpp:218] Iteration 50300 (7.03881 iter/s, 14.2069s/100 iters), loss = 0.00356802
I0927 16:54:07.435526  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00356792 (* 1 = 0.00356792 loss)
I0927 16:54:07.435534  3463 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I0927 16:54:21.643656  3463 solver.cpp:218] Iteration 50400 (7.03824 iter/s, 14.2081s/100 iters), loss = 0.00184374
I0927 16:54:21.643697  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00184364 (* 1 = 0.00184364 loss)
I0927 16:54:21.643703  3463 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I0927 16:54:35.142447  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:54:35.711555  3463 solver.cpp:330] Iteration 50500, Testing net (#0)
I0927 16:54:39.058473  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:54:39.197947  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9243
I0927 16:54:39.197984  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.277584 (* 1 = 0.277584 loss)
I0927 16:54:39.338304  3463 solver.cpp:218] Iteration 50500 (5.65145 iter/s, 17.6946s/100 iters), loss = 0.00783983
I0927 16:54:39.338330  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00783974 (* 1 = 0.00783974 loss)
I0927 16:54:39.338337  3463 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I0927 16:54:53.535279  3463 solver.cpp:218] Iteration 50600 (7.04379 iter/s, 14.1969s/100 iters), loss = 0.0110555
I0927 16:54:53.535320  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110554 (* 1 = 0.0110554 loss)
I0927 16:54:53.535326  3463 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I0927 16:55:07.736097  3463 solver.cpp:218] Iteration 50700 (7.04189 iter/s, 14.2007s/100 iters), loss = 0.0230518
I0927 16:55:07.736225  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0230517 (* 1 = 0.0230517 loss)
I0927 16:55:07.736232  3463 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I0927 16:55:21.932881  3463 solver.cpp:218] Iteration 50800 (7.04393 iter/s, 14.1966s/100 iters), loss = 0.00538633
I0927 16:55:21.932922  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00538625 (* 1 = 0.00538625 loss)
I0927 16:55:21.932929  3463 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I0927 16:55:36.126992  3463 solver.cpp:218] Iteration 50900 (7.04521 iter/s, 14.194s/100 iters), loss = 0.0147967
I0927 16:55:36.127032  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0147966 (* 1 = 0.0147966 loss)
I0927 16:55:36.127038  3463 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I0927 16:55:49.613328  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:55:50.181838  3463 solver.cpp:330] Iteration 51000, Testing net (#0)
I0927 16:55:53.528103  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:55:53.667923  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9197
I0927 16:55:53.667959  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.299958 (* 1 = 0.299958 loss)
I0927 16:55:53.808521  3463 solver.cpp:218] Iteration 51000 (5.65565 iter/s, 17.6814s/100 iters), loss = 0.00644038
I0927 16:55:53.808549  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00644031 (* 1 = 0.00644031 loss)
I0927 16:55:53.808557  3463 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I0927 16:56:08.001710  3463 solver.cpp:218] Iteration 51100 (7.04567 iter/s, 14.1931s/100 iters), loss = 0.0109431
I0927 16:56:08.001751  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010943 (* 1 = 0.010943 loss)
I0927 16:56:08.001757  3463 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I0927 16:56:22.194784  3463 solver.cpp:218] Iteration 51200 (7.04573 iter/s, 14.193s/100 iters), loss = 0.043625
I0927 16:56:22.194856  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0436249 (* 1 = 0.0436249 loss)
I0927 16:56:22.194864  3463 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I0927 16:56:36.387696  3463 solver.cpp:218] Iteration 51300 (7.04583 iter/s, 14.1928s/100 iters), loss = 0.00691715
I0927 16:56:36.387737  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00691708 (* 1 = 0.00691708 loss)
I0927 16:56:36.387743  3463 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I0927 16:56:50.580796  3463 solver.cpp:218] Iteration 51400 (7.04571 iter/s, 14.193s/100 iters), loss = 0.0122993
I0927 16:56:50.580824  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122992 (* 1 = 0.0122992 loss)
I0927 16:56:50.580831  3463 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I0927 16:57:04.071405  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:57:04.640385  3463 solver.cpp:330] Iteration 51500, Testing net (#0)
I0927 16:57:07.987036  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:57:08.126997  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9223
I0927 16:57:08.127033  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.29276 (* 1 = 0.29276 loss)
I0927 16:57:08.267762  3463 solver.cpp:218] Iteration 51500 (5.6539 iter/s, 17.6869s/100 iters), loss = 0.00868322
I0927 16:57:08.267791  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00868314 (* 1 = 0.00868314 loss)
I0927 16:57:08.267796  3463 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I0927 16:57:22.459309  3463 solver.cpp:218] Iteration 51600 (7.04648 iter/s, 14.1915s/100 iters), loss = 0.00574441
I0927 16:57:22.459349  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00574433 (* 1 = 0.00574433 loss)
I0927 16:57:22.459355  3463 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I0927 16:57:36.651643  3463 solver.cpp:218] Iteration 51700 (7.0461 iter/s, 14.1923s/100 iters), loss = 0.0209822
I0927 16:57:36.651758  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0209821 (* 1 = 0.0209821 loss)
I0927 16:57:36.651774  3463 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I0927 16:57:50.840133  3463 solver.cpp:218] Iteration 51800 (7.04804 iter/s, 14.1883s/100 iters), loss = 0.00538378
I0927 16:57:50.840175  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00538369 (* 1 = 0.00538369 loss)
I0927 16:57:50.840181  3463 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I0927 16:58:05.029558  3463 solver.cpp:218] Iteration 51900 (7.04754 iter/s, 14.1893s/100 iters), loss = 0.00660633
I0927 16:58:05.029590  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00660623 (* 1 = 0.00660623 loss)
I0927 16:58:05.029597  3463 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I0927 16:58:18.519227  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:58:19.086949  3463 solver.cpp:330] Iteration 52000, Testing net (#0)
I0927 16:58:22.431190  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:58:22.571163  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9252
I0927 16:58:22.571200  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.281838 (* 1 = 0.281838 loss)
I0927 16:58:22.711896  3463 solver.cpp:218] Iteration 52000 (5.65539 iter/s, 17.6823s/100 iters), loss = 0.0594221
I0927 16:58:22.711925  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.059422 (* 1 = 0.059422 loss)
I0927 16:58:22.711930  3463 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I0927 16:58:36.908365  3463 solver.cpp:218] Iteration 52100 (7.04404 iter/s, 14.1964s/100 iters), loss = 0.0243028
I0927 16:58:36.908406  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0243027 (* 1 = 0.0243027 loss)
I0927 16:58:36.908411  3463 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I0927 16:58:51.099957  3463 solver.cpp:218] Iteration 52200 (7.04646 iter/s, 14.1915s/100 iters), loss = 0.0363746
I0927 16:58:51.100054  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0363745 (* 1 = 0.0363745 loss)
I0927 16:58:51.100059  3463 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I0927 16:59:05.293680  3463 solver.cpp:218] Iteration 52300 (7.04543 iter/s, 14.1936s/100 iters), loss = 0.0174879
I0927 16:59:05.293720  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0174878 (* 1 = 0.0174878 loss)
I0927 16:59:05.293726  3463 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I0927 16:59:19.485193  3463 solver.cpp:218] Iteration 52400 (7.0465 iter/s, 14.1914s/100 iters), loss = 0.00453903
I0927 16:59:19.485224  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00453894 (* 1 = 0.00453894 loss)
I0927 16:59:19.485229  3463 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I0927 16:59:32.974629  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:59:33.543439  3463 solver.cpp:330] Iteration 52500, Testing net (#0)
I0927 16:59:36.889261  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 16:59:37.029512  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9266
I0927 16:59:37.029548  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.282628 (* 1 = 0.282628 loss)
I0927 16:59:37.170306  3463 solver.cpp:218] Iteration 52500 (5.6545 iter/s, 17.685s/100 iters), loss = 0.00556166
I0927 16:59:37.170336  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00556158 (* 1 = 0.00556158 loss)
I0927 16:59:37.170343  3463 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I0927 16:59:51.374841  3463 solver.cpp:218] Iteration 52600 (7.04004 iter/s, 14.2045s/100 iters), loss = 0.00337696
I0927 16:59:51.374882  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00337689 (* 1 = 0.00337689 loss)
I0927 16:59:51.374888  3463 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I0927 17:00:05.591698  3463 solver.cpp:218] Iteration 52700 (7.03394 iter/s, 14.2168s/100 iters), loss = 0.0184698
I0927 17:00:05.591820  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0184698 (* 1 = 0.0184698 loss)
I0927 17:00:05.591827  3463 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I0927 17:00:19.799368  3463 solver.cpp:218] Iteration 52800 (7.03853 iter/s, 14.2075s/100 iters), loss = 0.0437366
I0927 17:00:19.799409  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0437365 (* 1 = 0.0437365 loss)
I0927 17:00:19.799415  3463 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I0927 17:00:34.013873  3463 solver.cpp:218] Iteration 52900 (7.03511 iter/s, 14.2144s/100 iters), loss = 0.00210759
I0927 17:00:34.013916  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00210751 (* 1 = 0.00210751 loss)
I0927 17:00:34.013921  3463 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I0927 17:00:47.516276  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:00:48.087034  3463 solver.cpp:330] Iteration 53000, Testing net (#0)
I0927 17:00:51.432545  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:00:51.572713  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9235
I0927 17:00:51.572749  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.293555 (* 1 = 0.293555 loss)
I0927 17:00:51.713380  3463 solver.cpp:218] Iteration 53000 (5.6499 iter/s, 17.6994s/100 iters), loss = 0.00655513
I0927 17:00:51.713409  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00655506 (* 1 = 0.00655506 loss)
I0927 17:00:51.713416  3463 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I0927 17:01:05.916801  3463 solver.cpp:218] Iteration 53100 (7.04059 iter/s, 14.2034s/100 iters), loss = 0.0128033
I0927 17:01:05.916831  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128032 (* 1 = 0.0128032 loss)
I0927 17:01:05.916837  3463 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I0927 17:01:20.116237  3463 solver.cpp:218] Iteration 53200 (7.04257 iter/s, 14.1994s/100 iters), loss = 0.00713287
I0927 17:01:20.116354  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0071328 (* 1 = 0.0071328 loss)
I0927 17:01:20.116363  3463 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I0927 17:01:34.314998  3463 solver.cpp:218] Iteration 53300 (7.04294 iter/s, 14.1986s/100 iters), loss = 0.00817794
I0927 17:01:34.315040  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00817787 (* 1 = 0.00817787 loss)
I0927 17:01:34.315047  3463 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I0927 17:01:48.518425  3463 solver.cpp:218] Iteration 53400 (7.0406 iter/s, 14.2033s/100 iters), loss = 0.00418113
I0927 17:01:48.518467  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00418106 (* 1 = 0.00418106 loss)
I0927 17:01:48.518473  3463 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I0927 17:02:02.012675  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:02:02.581857  3463 solver.cpp:330] Iteration 53500, Testing net (#0)
I0927 17:02:05.929190  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:02:06.069149  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9214
I0927 17:02:06.069185  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31724 (* 1 = 0.31724 loss)
I0927 17:02:06.209316  3463 solver.cpp:218] Iteration 53500 (5.65265 iter/s, 17.6908s/100 iters), loss = 0.00291699
I0927 17:02:06.209344  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00291691 (* 1 = 0.00291691 loss)
I0927 17:02:06.209352  3463 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I0927 17:02:20.409735  3463 solver.cpp:218] Iteration 53600 (7.04208 iter/s, 14.2004s/100 iters), loss = 0.0123114
I0927 17:02:20.409776  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0123113 (* 1 = 0.0123113 loss)
I0927 17:02:20.409782  3463 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I0927 17:02:34.611569  3463 solver.cpp:218] Iteration 53700 (7.04138 iter/s, 14.2018s/100 iters), loss = 0.0115906
I0927 17:02:34.611683  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115905 (* 1 = 0.0115905 loss)
I0927 17:02:34.611690  3463 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I0927 17:02:48.816151  3463 solver.cpp:218] Iteration 53800 (7.04006 iter/s, 14.2044s/100 iters), loss = 0.00360177
I0927 17:02:48.816192  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00360168 (* 1 = 0.00360168 loss)
I0927 17:02:48.816200  3463 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I0927 17:03:03.017238  3463 solver.cpp:218] Iteration 53900 (7.04176 iter/s, 14.201s/100 iters), loss = 0.00847065
I0927 17:03:03.017278  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00847057 (* 1 = 0.00847057 loss)
I0927 17:03:03.017284  3463 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I0927 17:03:16.514106  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:03:17.082701  3463 solver.cpp:330] Iteration 54000, Testing net (#0)
I0927 17:03:20.427686  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:03:20.567662  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9237
I0927 17:03:20.567699  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.289145 (* 1 = 0.289145 loss)
I0927 17:03:20.708483  3463 solver.cpp:218] Iteration 54000 (5.65254 iter/s, 17.6912s/100 iters), loss = 0.00723318
I0927 17:03:20.708510  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00723309 (* 1 = 0.00723309 loss)
I0927 17:03:20.708518  3463 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I0927 17:03:34.910907  3463 solver.cpp:218] Iteration 54100 (7.04108 iter/s, 14.2024s/100 iters), loss = 0.0059412
I0927 17:03:34.910948  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00594111 (* 1 = 0.00594111 loss)
I0927 17:03:34.910953  3463 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I0927 17:03:49.116024  3463 solver.cpp:218] Iteration 54200 (7.03976 iter/s, 14.205s/100 iters), loss = 0.00607058
I0927 17:03:49.116156  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00607049 (* 1 = 0.00607049 loss)
I0927 17:03:49.116165  3463 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I0927 17:04:03.319394  3463 solver.cpp:218] Iteration 54300 (7.04066 iter/s, 14.2032s/100 iters), loss = 0.00275421
I0927 17:04:03.319435  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00275412 (* 1 = 0.00275412 loss)
I0927 17:04:03.319442  3463 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I0927 17:04:17.521746  3463 solver.cpp:218] Iteration 54400 (7.04113 iter/s, 14.2023s/100 iters), loss = 0.00529511
I0927 17:04:17.521787  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00529502 (* 1 = 0.00529502 loss)
I0927 17:04:17.521793  3463 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I0927 17:04:31.017010  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:04:31.585781  3463 solver.cpp:330] Iteration 54500, Testing net (#0)
I0927 17:04:34.932569  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:04:35.072948  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.925
I0927 17:04:35.072976  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.289047 (* 1 = 0.289047 loss)
I0927 17:04:35.213948  3463 solver.cpp:218] Iteration 54500 (5.65224 iter/s, 17.6921s/100 iters), loss = 0.00545245
I0927 17:04:35.213976  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00545236 (* 1 = 0.00545236 loss)
I0927 17:04:35.213984  3463 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I0927 17:04:49.404276  3463 solver.cpp:218] Iteration 54600 (7.04709 iter/s, 14.1903s/100 iters), loss = 0.00253754
I0927 17:04:49.404317  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00253745 (* 1 = 0.00253745 loss)
I0927 17:04:49.404323  3463 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I0927 17:05:03.596876  3463 solver.cpp:218] Iteration 54700 (7.04597 iter/s, 14.1925s/100 iters), loss = 0.0044473
I0927 17:05:03.596985  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0044472 (* 1 = 0.0044472 loss)
I0927 17:05:03.596995  3463 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I0927 17:05:17.790577  3463 solver.cpp:218] Iteration 54800 (7.04545 iter/s, 14.1936s/100 iters), loss = 0.00153202
I0927 17:05:17.790618  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153192 (* 1 = 0.00153192 loss)
I0927 17:05:17.790624  3463 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I0927 17:05:31.983520  3463 solver.cpp:218] Iteration 54900 (7.04579 iter/s, 14.1929s/100 iters), loss = 0.00596021
I0927 17:05:31.983561  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00596011 (* 1 = 0.00596011 loss)
I0927 17:05:31.983567  3463 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I0927 17:05:45.472728  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:05:46.041321  3463 solver.cpp:330] Iteration 55000, Testing net (#0)
I0927 17:05:49.387652  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:05:49.527484  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9252
I0927 17:05:49.527521  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.302787 (* 1 = 0.302787 loss)
I0927 17:05:49.668160  3463 solver.cpp:218] Iteration 55000 (5.65465 iter/s, 17.6846s/100 iters), loss = 0.00459724
I0927 17:05:49.668190  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00459714 (* 1 = 0.00459714 loss)
I0927 17:05:49.668196  3463 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I0927 17:06:03.867434  3463 solver.cpp:218] Iteration 55100 (7.04265 iter/s, 14.1992s/100 iters), loss = 0.00721365
I0927 17:06:03.867475  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00721354 (* 1 = 0.00721354 loss)
I0927 17:06:03.867481  3463 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I0927 17:06:18.067891  3463 solver.cpp:218] Iteration 55200 (7.04207 iter/s, 14.2004s/100 iters), loss = 0.00846066
I0927 17:06:18.067996  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00846055 (* 1 = 0.00846055 loss)
I0927 17:06:18.068004  3463 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I0927 17:06:32.271558  3463 solver.cpp:218] Iteration 55300 (7.04051 iter/s, 14.2035s/100 iters), loss = 0.0112945
I0927 17:06:32.271597  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112943 (* 1 = 0.0112943 loss)
I0927 17:06:32.271603  3463 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I0927 17:06:46.472141  3463 solver.cpp:218] Iteration 55400 (7.042 iter/s, 14.2005s/100 iters), loss = 0.00684344
I0927 17:06:46.472172  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00684332 (* 1 = 0.00684332 loss)
I0927 17:06:46.472178  3463 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I0927 17:06:59.965015  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:07:00.535135  3463 solver.cpp:330] Iteration 55500, Testing net (#0)
I0927 17:07:03.883782  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:07:04.023715  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9221
I0927 17:07:04.023741  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305086 (* 1 = 0.305086 loss)
I0927 17:07:04.164367  3463 solver.cpp:218] Iteration 55500 (5.65222 iter/s, 17.6922s/100 iters), loss = 0.00947339
I0927 17:07:04.164396  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00947328 (* 1 = 0.00947328 loss)
I0927 17:07:04.164402  3463 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I0927 17:07:18.352730  3463 solver.cpp:218] Iteration 55600 (7.04807 iter/s, 14.1883s/100 iters), loss = 0.0265023
I0927 17:07:18.352773  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0265022 (* 1 = 0.0265022 loss)
I0927 17:07:18.352779  3463 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I0927 17:07:32.537371  3463 solver.cpp:218] Iteration 55700 (7.04992 iter/s, 14.1846s/100 iters), loss = 0.00710132
I0927 17:07:32.537508  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00710121 (* 1 = 0.00710121 loss)
I0927 17:07:32.537515  3463 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I0927 17:07:46.730880  3463 solver.cpp:218] Iteration 55800 (7.04556 iter/s, 14.1933s/100 iters), loss = 0.00248293
I0927 17:07:46.730921  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00248281 (* 1 = 0.00248281 loss)
I0927 17:07:46.730927  3463 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I0927 17:08:00.926970  3463 solver.cpp:218] Iteration 55900 (7.04423 iter/s, 14.196s/100 iters), loss = 0.00227479
I0927 17:08:00.927011  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00227466 (* 1 = 0.00227466 loss)
I0927 17:08:00.927017  3463 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I0927 17:08:14.409865  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:08:14.977792  3463 solver.cpp:330] Iteration 56000, Testing net (#0)
I0927 17:08:18.326231  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:08:18.466722  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9203
I0927 17:08:18.466749  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307153 (* 1 = 0.307153 loss)
I0927 17:08:18.607395  3463 solver.cpp:218] Iteration 56000 (5.656 iter/s, 17.6803s/100 iters), loss = 0.00184258
I0927 17:08:18.607425  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00184246 (* 1 = 0.00184246 loss)
I0927 17:08:18.607432  3463 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I0927 17:08:32.803562  3463 solver.cpp:218] Iteration 56100 (7.04419 iter/s, 14.1961s/100 iters), loss = 0.00603216
I0927 17:08:32.803603  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00603203 (* 1 = 0.00603203 loss)
I0927 17:08:32.803609  3463 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I0927 17:08:47.003129  3463 solver.cpp:218] Iteration 56200 (7.04251 iter/s, 14.1995s/100 iters), loss = 0.00323989
I0927 17:08:47.003202  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00323977 (* 1 = 0.00323977 loss)
I0927 17:08:47.003211  3463 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I0927 17:09:01.200955  3463 solver.cpp:218] Iteration 56300 (7.04339 iter/s, 14.1977s/100 iters), loss = 0.0562018
I0927 17:09:01.200996  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0562017 (* 1 = 0.0562017 loss)
I0927 17:09:01.201002  3463 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I0927 17:09:15.406421  3463 solver.cpp:218] Iteration 56400 (7.03958 iter/s, 14.2054s/100 iters), loss = 0.00339847
I0927 17:09:15.406461  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00339834 (* 1 = 0.00339834 loss)
I0927 17:09:15.406467  3463 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I0927 17:09:28.897209  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:09:29.465878  3463 solver.cpp:330] Iteration 56500, Testing net (#0)
I0927 17:09:32.813379  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:09:32.953857  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.924
I0927 17:09:32.953884  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.289094 (* 1 = 0.289094 loss)
I0927 17:09:33.094754  3463 solver.cpp:218] Iteration 56500 (5.65347 iter/s, 17.6882s/100 iters), loss = 0.00585154
I0927 17:09:33.094781  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00585141 (* 1 = 0.00585141 loss)
I0927 17:09:33.094789  3463 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I0927 17:09:47.288434  3463 solver.cpp:218] Iteration 56600 (7.04543 iter/s, 14.1936s/100 iters), loss = 0.00718912
I0927 17:09:47.288475  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.007189 (* 1 = 0.007189 loss)
I0927 17:09:47.288480  3463 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I0927 17:10:01.484426  3463 solver.cpp:218] Iteration 56700 (7.04428 iter/s, 14.1959s/100 iters), loss = 0.00432538
I0927 17:10:01.484562  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00432525 (* 1 = 0.00432525 loss)
I0927 17:10:01.484571  3463 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I0927 17:10:15.679033  3463 solver.cpp:218] Iteration 56800 (7.04501 iter/s, 14.1944s/100 iters), loss = 0.00260972
I0927 17:10:15.679075  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00260959 (* 1 = 0.00260959 loss)
I0927 17:10:15.679081  3463 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I0927 17:10:29.868142  3463 solver.cpp:218] Iteration 56900 (7.0477 iter/s, 14.189s/100 iters), loss = 0.00673722
I0927 17:10:29.868185  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0067371 (* 1 = 0.0067371 loss)
I0927 17:10:29.868191  3463 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I0927 17:10:43.353369  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:10:43.922237  3463 solver.cpp:330] Iteration 57000, Testing net (#0)
I0927 17:10:47.270229  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:10:47.410233  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9221
I0927 17:10:47.410271  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31509 (* 1 = 0.31509 loss)
I0927 17:10:47.551440  3463 solver.cpp:218] Iteration 57000 (5.65508 iter/s, 17.6832s/100 iters), loss = 0.00181205
I0927 17:10:47.551466  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00181192 (* 1 = 0.00181192 loss)
I0927 17:10:47.551473  3463 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I0927 17:11:01.737088  3463 solver.cpp:218] Iteration 57100 (7.04941 iter/s, 14.1856s/100 iters), loss = 0.0318076
I0927 17:11:01.737129  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0318075 (* 1 = 0.0318075 loss)
I0927 17:11:01.737135  3463 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I0927 17:11:15.916035  3463 solver.cpp:218] Iteration 57200 (7.05275 iter/s, 14.1789s/100 iters), loss = 0.00430406
I0927 17:11:15.916142  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00430393 (* 1 = 0.00430393 loss)
I0927 17:11:15.916149  3463 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I0927 17:11:30.099467  3463 solver.cpp:218] Iteration 57300 (7.05055 iter/s, 14.1833s/100 iters), loss = 0.00212332
I0927 17:11:30.099509  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00212319 (* 1 = 0.00212319 loss)
I0927 17:11:30.099514  3463 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I0927 17:11:44.284546  3463 solver.cpp:218] Iteration 57400 (7.0497 iter/s, 14.185s/100 iters), loss = 0.00469623
I0927 17:11:44.284588  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00469611 (* 1 = 0.00469611 loss)
I0927 17:11:44.284595  3463 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I0927 17:11:57.767395  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:11:58.336552  3463 solver.cpp:330] Iteration 57500, Testing net (#0)
I0927 17:12:01.686288  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:12:01.826500  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9233
I0927 17:12:01.826539  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308352 (* 1 = 0.308352 loss)
I0927 17:12:01.967224  3463 solver.cpp:218] Iteration 57500 (5.65528 iter/s, 17.6826s/100 iters), loss = 0.00200002
I0927 17:12:01.967252  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00199989 (* 1 = 0.00199989 loss)
I0927 17:12:01.967258  3463 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I0927 17:12:16.182744  3463 solver.cpp:218] Iteration 57600 (7.0346 iter/s, 14.2154s/100 iters), loss = 0.00140141
I0927 17:12:16.182785  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00140129 (* 1 = 0.00140129 loss)
I0927 17:12:16.182791  3463 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I0927 17:12:30.392139  3463 solver.cpp:218] Iteration 57700 (7.03764 iter/s, 14.2093s/100 iters), loss = 0.00651459
I0927 17:12:30.392256  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00651446 (* 1 = 0.00651446 loss)
I0927 17:12:30.392272  3463 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I0927 17:12:44.606848  3463 solver.cpp:218] Iteration 57800 (7.03504 iter/s, 14.2146s/100 iters), loss = 0.00112345
I0927 17:12:44.606890  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00112333 (* 1 = 0.00112333 loss)
I0927 17:12:44.606896  3463 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I0927 17:12:58.816821  3463 solver.cpp:218] Iteration 57900 (7.03735 iter/s, 14.2099s/100 iters), loss = 0.00403758
I0927 17:12:58.816864  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00403745 (* 1 = 0.00403745 loss)
I0927 17:12:58.816869  3463 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I0927 17:13:12.323865  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:13:12.892874  3463 solver.cpp:330] Iteration 58000, Testing net (#0)
I0927 17:13:16.238669  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:13:16.378903  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9241
I0927 17:13:16.378939  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308643 (* 1 = 0.308643 loss)
I0927 17:13:16.519881  3463 solver.cpp:218] Iteration 58000 (5.64877 iter/s, 17.703s/100 iters), loss = 0.000775182
I0927 17:13:16.519908  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000775052 (* 1 = 0.000775052 loss)
I0927 17:13:16.519915  3463 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I0927 17:13:30.712031  3463 solver.cpp:218] Iteration 58100 (7.04618 iter/s, 14.1921s/100 iters), loss = 0.0153255
I0927 17:13:30.712072  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0153254 (* 1 = 0.0153254 loss)
I0927 17:13:30.712079  3463 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I0927 17:13:44.906018  3463 solver.cpp:218] Iteration 58200 (7.04528 iter/s, 14.1939s/100 iters), loss = 0.00742259
I0927 17:13:44.906095  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00742246 (* 1 = 0.00742246 loss)
I0927 17:13:44.906103  3463 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I0927 17:13:59.101368  3463 solver.cpp:218] Iteration 58300 (7.04462 iter/s, 14.1952s/100 iters), loss = 0.00252844
I0927 17:13:59.101409  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0025283 (* 1 = 0.0025283 loss)
I0927 17:13:59.101416  3463 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I0927 17:14:13.293537  3463 solver.cpp:218] Iteration 58400 (7.04618 iter/s, 14.1921s/100 iters), loss = 0.00367534
I0927 17:14:13.293578  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00367521 (* 1 = 0.00367521 loss)
I0927 17:14:13.293584  3463 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I0927 17:14:26.788576  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:14:27.356806  3463 solver.cpp:330] Iteration 58500, Testing net (#0)
I0927 17:14:30.703579  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:14:30.843602  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.924
I0927 17:14:30.843638  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.301801 (* 1 = 0.301801 loss)
I0927 17:14:30.984045  3463 solver.cpp:218] Iteration 58500 (5.65278 iter/s, 17.6904s/100 iters), loss = 0.00241392
I0927 17:14:30.984074  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00241378 (* 1 = 0.00241378 loss)
I0927 17:14:30.984081  3463 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I0927 17:14:45.183791  3463 solver.cpp:218] Iteration 58600 (7.04241 iter/s, 14.1997s/100 iters), loss = 0.00173459
I0927 17:14:45.183832  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00173445 (* 1 = 0.00173445 loss)
I0927 17:14:45.183838  3463 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I0927 17:14:59.382035  3463 solver.cpp:218] Iteration 58700 (7.04316 iter/s, 14.1982s/100 iters), loss = 0.00647413
I0927 17:14:59.382113  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.006474 (* 1 = 0.006474 loss)
I0927 17:14:59.382130  3463 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I0927 17:15:13.582190  3463 solver.cpp:218] Iteration 58800 (7.04223 iter/s, 14.2s/100 iters), loss = 0.00595919
I0927 17:15:13.582231  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00595906 (* 1 = 0.00595906 loss)
I0927 17:15:13.582237  3463 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I0927 17:15:27.784507  3463 solver.cpp:218] Iteration 58900 (7.04114 iter/s, 14.2022s/100 iters), loss = 0.00642533
I0927 17:15:27.784548  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0064252 (* 1 = 0.0064252 loss)
I0927 17:15:27.784554  3463 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I0927 17:15:41.285948  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:15:41.854079  3463 solver.cpp:330] Iteration 59000, Testing net (#0)
I0927 17:15:45.199743  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:15:45.339579  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9176
I0927 17:15:45.339617  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339283 (* 1 = 0.339283 loss)
I0927 17:15:45.480394  3463 solver.cpp:218] Iteration 59000 (5.65106 iter/s, 17.6958s/100 iters), loss = 0.00889314
I0927 17:15:45.480424  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00889301 (* 1 = 0.00889301 loss)
I0927 17:15:45.480432  3463 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I0927 17:15:59.686998  3463 solver.cpp:218] Iteration 59100 (7.03901 iter/s, 14.2065s/100 iters), loss = 0.00783335
I0927 17:15:59.687029  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00783322 (* 1 = 0.00783322 loss)
I0927 17:15:59.687036  3463 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I0927 17:16:13.890455  3463 solver.cpp:218] Iteration 59200 (7.04058 iter/s, 14.2034s/100 iters), loss = 0.00596587
I0927 17:16:13.890533  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00596574 (* 1 = 0.00596574 loss)
I0927 17:16:13.890540  3463 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I0927 17:16:28.090678  3463 solver.cpp:218] Iteration 59300 (7.0422 iter/s, 14.2001s/100 iters), loss = 0.00304252
I0927 17:16:28.090720  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00304239 (* 1 = 0.00304239 loss)
I0927 17:16:28.090725  3463 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I0927 17:16:42.292341  3463 solver.cpp:218] Iteration 59400 (7.04147 iter/s, 14.2016s/100 iters), loss = 0.00372805
I0927 17:16:42.292382  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00372792 (* 1 = 0.00372792 loss)
I0927 17:16:42.292387  3463 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I0927 17:16:55.788441  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:16:56.357632  3463 solver.cpp:330] Iteration 59500, Testing net (#0)
I0927 17:16:59.703933  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:16:59.843917  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9219
I0927 17:16:59.843955  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.317614 (* 1 = 0.317614 loss)
I0927 17:16:59.984899  3463 solver.cpp:218] Iteration 59500 (5.65212 iter/s, 17.6925s/100 iters), loss = 0.0100371
I0927 17:16:59.984927  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010037 (* 1 = 0.010037 loss)
I0927 17:16:59.984935  3463 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I0927 17:17:14.184304  3463 solver.cpp:218] Iteration 59600 (7.04258 iter/s, 14.1993s/100 iters), loss = 0.0107365
I0927 17:17:14.184346  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107363 (* 1 = 0.0107363 loss)
I0927 17:17:14.184352  3463 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I0927 17:17:28.378367  3463 solver.cpp:218] Iteration 59700 (7.04524 iter/s, 14.194s/100 iters), loss = 0.0189059
I0927 17:17:28.378512  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0189057 (* 1 = 0.0189057 loss)
I0927 17:17:28.378535  3463 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I0927 17:17:42.576100  3463 solver.cpp:218] Iteration 59800 (7.04347 iter/s, 14.1976s/100 iters), loss = 0.000859467
I0927 17:17:42.576143  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000859342 (* 1 = 0.000859342 loss)
I0927 17:17:42.576148  3463 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I0927 17:17:56.776412  3463 solver.cpp:218] Iteration 59900 (7.04214 iter/s, 14.2002s/100 iters), loss = 0.00275732
I0927 17:17:56.776453  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00275718 (* 1 = 0.00275718 loss)
I0927 17:17:56.776458  3463 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I0927 17:18:10.263777  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:18:10.834002  3463 solver.cpp:330] Iteration 60000, Testing net (#0)
I0927 17:18:14.179028  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:18:14.318933  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9212
I0927 17:18:14.318975  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318267 (* 1 = 0.318267 loss)
I0927 17:18:14.459091  3463 solver.cpp:218] Iteration 60000 (5.65528 iter/s, 17.6826s/100 iters), loss = 0.00384171
I0927 17:18:14.459120  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00384157 (* 1 = 0.00384157 loss)
I0927 17:18:14.459126  3463 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I0927 17:18:28.660158  3463 solver.cpp:218] Iteration 60100 (7.04176 iter/s, 14.201s/100 iters), loss = 0.00194483
I0927 17:18:28.660189  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0019447 (* 1 = 0.0019447 loss)
I0927 17:18:28.660195  3463 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I0927 17:18:42.862627  3463 solver.cpp:218] Iteration 60200 (7.04106 iter/s, 14.2024s/100 iters), loss = 0.0117738
I0927 17:18:42.862704  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117737 (* 1 = 0.0117737 loss)
I0927 17:18:42.862710  3463 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I0927 17:18:57.066814  3463 solver.cpp:218] Iteration 60300 (7.04024 iter/s, 14.2041s/100 iters), loss = 0.00686783
I0927 17:18:57.066856  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00686769 (* 1 = 0.00686769 loss)
I0927 17:18:57.066862  3463 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I0927 17:19:11.277194  3463 solver.cpp:218] Iteration 60400 (7.03715 iter/s, 14.2103s/100 iters), loss = 0.00247826
I0927 17:19:11.277235  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00247812 (* 1 = 0.00247812 loss)
I0927 17:19:11.277241  3463 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I0927 17:19:24.778076  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:19:25.347218  3463 solver.cpp:330] Iteration 60500, Testing net (#0)
I0927 17:19:28.694880  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:19:28.835145  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9223
I0927 17:19:28.835181  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320808 (* 1 = 0.320808 loss)
I0927 17:19:28.976342  3463 solver.cpp:218] Iteration 60500 (5.65002 iter/s, 17.6991s/100 iters), loss = 0.0023314
I0927 17:19:28.976371  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00233126 (* 1 = 0.00233126 loss)
I0927 17:19:28.976377  3463 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I0927 17:19:43.171478  3463 solver.cpp:218] Iteration 60600 (7.0447 iter/s, 14.1951s/100 iters), loss = 0.00215612
I0927 17:19:43.171519  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00215598 (* 1 = 0.00215598 loss)
I0927 17:19:43.171525  3463 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I0927 17:19:57.364097  3463 solver.cpp:218] Iteration 60700 (7.04596 iter/s, 14.1925s/100 iters), loss = 0.00413175
I0927 17:19:57.364233  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00413161 (* 1 = 0.00413161 loss)
I0927 17:19:57.364251  3463 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I0927 17:20:11.555732  3463 solver.cpp:218] Iteration 60800 (7.04649 iter/s, 14.1915s/100 iters), loss = 0.00741423
I0927 17:20:11.555773  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00741409 (* 1 = 0.00741409 loss)
I0927 17:20:11.555779  3463 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I0927 17:20:25.743894  3463 solver.cpp:218] Iteration 60900 (7.04817 iter/s, 14.1881s/100 iters), loss = 0.00290711
I0927 17:20:25.743935  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00290697 (* 1 = 0.00290697 loss)
I0927 17:20:25.743942  3463 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I0927 17:20:39.230832  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:20:39.799868  3463 solver.cpp:330] Iteration 61000, Testing net (#0)
I0927 17:20:43.145741  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:20:43.285938  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I0927 17:20:43.285974  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316525 (* 1 = 0.316525 loss)
I0927 17:20:43.426735  3463 solver.cpp:218] Iteration 61000 (5.65523 iter/s, 17.6828s/100 iters), loss = 0.00471839
I0927 17:20:43.426764  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00471824 (* 1 = 0.00471824 loss)
I0927 17:20:43.426770  3463 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I0927 17:20:57.632428  3463 solver.cpp:218] Iteration 61100 (7.03947 iter/s, 14.2056s/100 iters), loss = 0.00402019
I0927 17:20:57.632469  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00402005 (* 1 = 0.00402005 loss)
I0927 17:20:57.632475  3463 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I0927 17:21:11.836983  3463 solver.cpp:218] Iteration 61200 (7.04004 iter/s, 14.2045s/100 iters), loss = 0.00517412
I0927 17:21:11.837087  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00517398 (* 1 = 0.00517398 loss)
I0927 17:21:11.837095  3463 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I0927 17:21:26.038372  3463 solver.cpp:218] Iteration 61300 (7.04164 iter/s, 14.2012s/100 iters), loss = 0.00483958
I0927 17:21:26.038403  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00483943 (* 1 = 0.00483943 loss)
I0927 17:21:26.038408  3463 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I0927 17:21:40.237121  3463 solver.cpp:218] Iteration 61400 (7.04291 iter/s, 14.1987s/100 iters), loss = 0.0017872
I0927 17:21:40.237162  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00178706 (* 1 = 0.00178706 loss)
I0927 17:21:40.237169  3463 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I0927 17:21:53.733269  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:21:54.302505  3463 solver.cpp:330] Iteration 61500, Testing net (#0)
I0927 17:21:57.647754  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:21:57.787608  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9216
I0927 17:21:57.787643  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.323673 (* 1 = 0.323673 loss)
I0927 17:21:57.928244  3463 solver.cpp:218] Iteration 61500 (5.65258 iter/s, 17.691s/100 iters), loss = 0.00286299
I0927 17:21:57.928272  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00286284 (* 1 = 0.00286284 loss)
I0927 17:21:57.928277  3463 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I0927 17:22:12.124578  3463 solver.cpp:218] Iteration 61600 (7.0441 iter/s, 14.1963s/100 iters), loss = 0.0262613
I0927 17:22:12.124619  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0262611 (* 1 = 0.0262611 loss)
I0927 17:22:12.124625  3463 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I0927 17:22:26.318845  3463 solver.cpp:218] Iteration 61700 (7.04514 iter/s, 14.1942s/100 iters), loss = 0.00805319
I0927 17:22:26.319006  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00805305 (* 1 = 0.00805305 loss)
I0927 17:22:26.319015  3463 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I0927 17:22:40.515261  3463 solver.cpp:218] Iteration 61800 (7.04413 iter/s, 14.1962s/100 iters), loss = 0.0120445
I0927 17:22:40.515302  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0120444 (* 1 = 0.0120444 loss)
I0927 17:22:40.515308  3463 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I0927 17:22:54.707375  3463 solver.cpp:218] Iteration 61900 (7.04621 iter/s, 14.192s/100 iters), loss = 0.00405664
I0927 17:22:54.707417  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00405651 (* 1 = 0.00405651 loss)
I0927 17:22:54.707422  3463 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I0927 17:23:08.197659  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:23:08.766475  3463 solver.cpp:330] Iteration 62000, Testing net (#0)
I0927 17:23:12.113229  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:23:12.253057  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9218
I0927 17:23:12.253093  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.323058 (* 1 = 0.323058 loss)
I0927 17:23:12.393988  3463 solver.cpp:218] Iteration 62000 (5.65402 iter/s, 17.6865s/100 iters), loss = 0.00611297
I0927 17:23:12.394016  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00611284 (* 1 = 0.00611284 loss)
I0927 17:23:12.394022  3463 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I0927 17:23:26.583732  3463 solver.cpp:218] Iteration 62100 (7.04738 iter/s, 14.1897s/100 iters), loss = 0.00588381
I0927 17:23:26.583775  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00588367 (* 1 = 0.00588367 loss)
I0927 17:23:26.583781  3463 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I0927 17:23:40.778605  3463 solver.cpp:218] Iteration 62200 (7.04484 iter/s, 14.1948s/100 iters), loss = 0.00518977
I0927 17:23:40.778748  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00518963 (* 1 = 0.00518963 loss)
I0927 17:23:40.778754  3463 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I0927 17:23:54.966166  3463 solver.cpp:218] Iteration 62300 (7.04852 iter/s, 14.1874s/100 iters), loss = 0.00197346
I0927 17:23:54.966207  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00197332 (* 1 = 0.00197332 loss)
I0927 17:23:54.966212  3463 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I0927 17:24:09.156383  3463 solver.cpp:218] Iteration 62400 (7.04715 iter/s, 14.1901s/100 iters), loss = 0.002857
I0927 17:24:09.156425  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00285686 (* 1 = 0.00285686 loss)
I0927 17:24:09.156431  3463 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I0927 17:24:22.642942  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:24:23.211421  3463 solver.cpp:330] Iteration 62500, Testing net (#0)
I0927 17:24:26.556324  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:24:26.696512  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9216
I0927 17:24:26.696549  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311486 (* 1 = 0.311486 loss)
I0927 17:24:26.837039  3463 solver.cpp:218] Iteration 62500 (5.65593 iter/s, 17.6806s/100 iters), loss = 0.00221239
I0927 17:24:26.837066  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00221225 (* 1 = 0.00221225 loss)
I0927 17:24:26.837074  3463 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I0927 17:24:41.047216  3463 solver.cpp:218] Iteration 62600 (7.03724 iter/s, 14.2101s/100 iters), loss = 0.0051113
I0927 17:24:41.047257  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00511116 (* 1 = 0.00511116 loss)
I0927 17:24:41.047263  3463 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I0927 17:24:55.259552  3463 solver.cpp:218] Iteration 62700 (7.03618 iter/s, 14.2123s/100 iters), loss = 0.00741926
I0927 17:24:55.259655  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00741911 (* 1 = 0.00741911 loss)
I0927 17:24:55.259663  3463 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I0927 17:25:09.472407  3463 solver.cpp:218] Iteration 62800 (7.03595 iter/s, 14.2127s/100 iters), loss = 0.00383746
I0927 17:25:09.472448  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00383731 (* 1 = 0.00383731 loss)
I0927 17:25:09.472455  3463 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I0927 17:25:23.678148  3463 solver.cpp:218] Iteration 62900 (7.03945 iter/s, 14.2057s/100 iters), loss = 0.00825527
I0927 17:25:23.678189  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00825511 (* 1 = 0.00825511 loss)
I0927 17:25:23.678195  3463 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I0927 17:25:37.174346  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:25:37.743522  3463 solver.cpp:330] Iteration 63000, Testing net (#0)
I0927 17:25:41.089936  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:25:41.229848  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9231
I0927 17:25:41.229883  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31623 (* 1 = 0.31623 loss)
I0927 17:25:41.370193  3463 solver.cpp:218] Iteration 63000 (5.65229 iter/s, 17.692s/100 iters), loss = 0.0123134
I0927 17:25:41.370223  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0123133 (* 1 = 0.0123133 loss)
I0927 17:25:41.370229  3463 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I0927 17:25:55.563880  3463 solver.cpp:218] Iteration 63100 (7.04542 iter/s, 14.1936s/100 iters), loss = 0.00579089
I0927 17:25:55.563922  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00579074 (* 1 = 0.00579074 loss)
I0927 17:25:55.563928  3463 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I0927 17:26:09.857132  3463 solver.cpp:218] Iteration 63200 (6.99635 iter/s, 14.2932s/100 iters), loss = 0.00644427
I0927 17:26:09.857213  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00644412 (* 1 = 0.00644412 loss)
I0927 17:26:09.857228  3463 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I0927 17:26:24.078202  3463 solver.cpp:218] Iteration 63300 (7.03188 iter/s, 14.221s/100 iters), loss = 0.00126521
I0927 17:26:24.078243  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00126506 (* 1 = 0.00126506 loss)
I0927 17:26:24.078249  3463 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I0927 17:26:38.283237  3463 solver.cpp:218] Iteration 63400 (7.0398 iter/s, 14.205s/100 iters), loss = 0.00756418
I0927 17:26:38.283278  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00756403 (* 1 = 0.00756403 loss)
I0927 17:26:38.283285  3463 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I0927 17:26:51.782691  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:26:52.351233  3463 solver.cpp:330] Iteration 63500, Testing net (#0)
I0927 17:26:55.699455  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:26:55.839521  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9254
I0927 17:26:55.839557  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311545 (* 1 = 0.311545 loss)
I0927 17:26:55.980458  3463 solver.cpp:218] Iteration 63500 (5.65063 iter/s, 17.6971s/100 iters), loss = 0.00300635
I0927 17:26:55.980487  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00300619 (* 1 = 0.00300619 loss)
I0927 17:26:55.980494  3463 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I0927 17:27:10.186581  3463 solver.cpp:218] Iteration 63600 (7.03926 iter/s, 14.206s/100 iters), loss = 0.00240599
I0927 17:27:10.186620  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00240584 (* 1 = 0.00240584 loss)
I0927 17:27:10.186637  3463 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I0927 17:27:24.391060  3463 solver.cpp:218] Iteration 63700 (7.04007 iter/s, 14.2044s/100 iters), loss = 0.00928385
I0927 17:27:24.391162  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0092837 (* 1 = 0.0092837 loss)
I0927 17:27:24.391180  3463 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I0927 17:27:38.598574  3463 solver.cpp:218] Iteration 63800 (7.03859 iter/s, 14.2074s/100 iters), loss = 0.0019888
I0927 17:27:38.598605  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00198865 (* 1 = 0.00198865 loss)
I0927 17:27:38.598621  3463 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I0927 17:27:52.803962  3463 solver.cpp:218] Iteration 63900 (7.03962 iter/s, 14.2053s/100 iters), loss = 0.010028
I0927 17:27:52.803993  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100278 (* 1 = 0.0100278 loss)
I0927 17:27:52.804009  3463 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I0927 17:28:06.303933  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:28:06.871958  3463 solver.cpp:330] Iteration 64000, Testing net (#0)
I0927 17:28:10.221668  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:28:10.361719  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9205
I0927 17:28:10.361762  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316584 (* 1 = 0.316584 loss)
I0927 17:28:10.502463  3463 solver.cpp:218] Iteration 64000 (5.65022 iter/s, 17.6984s/100 iters), loss = 0.00353488
I0927 17:28:10.502493  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00353473 (* 1 = 0.00353473 loss)
I0927 17:28:10.502501  3463 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I0927 17:28:24.712733  3463 solver.cpp:218] Iteration 64100 (7.0372 iter/s, 14.2102s/100 iters), loss = 0.00856953
I0927 17:28:24.712765  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00856937 (* 1 = 0.00856937 loss)
I0927 17:28:24.712771  3463 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I0927 17:28:38.922533  3463 solver.cpp:218] Iteration 64200 (7.03743 iter/s, 14.2097s/100 iters), loss = 0.00692824
I0927 17:28:38.922622  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00692809 (* 1 = 0.00692809 loss)
I0927 17:28:38.922639  3463 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I0927 17:28:53.137071  3463 solver.cpp:218] Iteration 64300 (7.03511 iter/s, 14.2144s/100 iters), loss = 0.00129618
I0927 17:28:53.137102  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00129602 (* 1 = 0.00129602 loss)
I0927 17:28:53.137118  3463 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I0927 17:29:07.347025  3463 solver.cpp:218] Iteration 64400 (7.03736 iter/s, 14.2099s/100 iters), loss = 0.00416137
I0927 17:29:07.347057  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0041612 (* 1 = 0.0041612 loss)
I0927 17:29:07.347074  3463 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I0927 17:29:20.856031  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:29:21.424522  3463 solver.cpp:330] Iteration 64500, Testing net (#0)
I0927 17:29:24.772148  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:29:24.912248  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.925
I0927 17:29:24.912284  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310246 (* 1 = 0.310246 loss)
I0927 17:29:25.053457  3463 solver.cpp:218] Iteration 64500 (5.64769 iter/s, 17.7064s/100 iters), loss = 0.00409425
I0927 17:29:25.053488  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00409409 (* 1 = 0.00409409 loss)
I0927 17:29:25.053495  3463 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I0927 17:29:39.245519  3463 solver.cpp:218] Iteration 64600 (7.04623 iter/s, 14.192s/100 iters), loss = 0.000913308
I0927 17:29:39.245549  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000913146 (* 1 = 0.000913146 loss)
I0927 17:29:39.245555  3463 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I0927 17:29:53.458523  3463 solver.cpp:218] Iteration 64700 (7.03585 iter/s, 14.2129s/100 iters), loss = 0.00344862
I0927 17:29:53.458634  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00344846 (* 1 = 0.00344846 loss)
I0927 17:29:53.458652  3463 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I0927 17:30:07.667453  3463 solver.cpp:218] Iteration 64800 (7.0379 iter/s, 14.2088s/100 iters), loss = 0.00358583
I0927 17:30:07.667484  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00358567 (* 1 = 0.00358567 loss)
I0927 17:30:07.667500  3463 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I0927 17:30:21.869755  3463 solver.cpp:218] Iteration 64900 (7.04115 iter/s, 14.2022s/100 iters), loss = 0.00522064
I0927 17:30:21.869786  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00522048 (* 1 = 0.00522048 loss)
I0927 17:30:21.869802  3463 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I0927 17:30:35.366838  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:30:35.935946  3463 solver.cpp:330] Iteration 65000, Testing net (#0)
I0927 17:30:39.285619  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:30:39.426110  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I0927 17:30:39.426146  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319516 (* 1 = 0.319516 loss)
I0927 17:30:39.566682  3463 solver.cpp:218] Iteration 65000 (5.65072 iter/s, 17.6968s/100 iters), loss = 0.00417876
I0927 17:30:39.566714  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0041786 (* 1 = 0.0041786 loss)
I0927 17:30:39.566720  3463 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I0927 17:30:53.777144  3463 solver.cpp:218] Iteration 65100 (7.0371 iter/s, 14.2104s/100 iters), loss = 0.0054593
I0927 17:30:53.777175  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00545915 (* 1 = 0.00545915 loss)
I0927 17:30:53.777191  3463 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I0927 17:31:07.994410  3463 solver.cpp:218] Iteration 65200 (7.03374 iter/s, 14.2172s/100 iters), loss = 0.00205277
I0927 17:31:07.994530  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00205262 (* 1 = 0.00205262 loss)
I0927 17:31:07.994549  3463 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I0927 17:31:22.207067  3463 solver.cpp:218] Iteration 65300 (7.03605 iter/s, 14.2125s/100 iters), loss = 0.00294498
I0927 17:31:22.207098  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00294482 (* 1 = 0.00294482 loss)
I0927 17:31:22.207114  3463 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I0927 17:31:36.423566  3463 solver.cpp:218] Iteration 65400 (7.03411 iter/s, 14.2164s/100 iters), loss = 0.00283037
I0927 17:31:36.423597  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00283021 (* 1 = 0.00283021 loss)
I0927 17:31:36.423614  3463 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I0927 17:31:49.939285  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:31:50.509413  3463 solver.cpp:330] Iteration 65500, Testing net (#0)
I0927 17:31:53.858773  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:31:53.999320  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9251
I0927 17:31:53.999356  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320784 (* 1 = 0.320784 loss)
I0927 17:31:54.139896  3463 solver.cpp:218] Iteration 65500 (5.64453 iter/s, 17.7163s/100 iters), loss = 0.00274498
I0927 17:31:54.139926  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00274483 (* 1 = 0.00274483 loss)
I0927 17:31:54.139933  3463 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I0927 17:32:08.340631  3463 solver.cpp:218] Iteration 65600 (7.04192 iter/s, 14.2007s/100 iters), loss = 0.00425209
I0927 17:32:08.340662  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00425194 (* 1 = 0.00425194 loss)
I0927 17:32:08.340668  3463 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I0927 17:32:22.549614  3463 solver.cpp:218] Iteration 65700 (7.03784 iter/s, 14.2089s/100 iters), loss = 0.0134903
I0927 17:32:22.549726  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134902 (* 1 = 0.0134902 loss)
I0927 17:32:22.549734  3463 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I0927 17:32:36.754416  3463 solver.cpp:218] Iteration 65800 (7.03995 iter/s, 14.2047s/100 iters), loss = 0.00371081
I0927 17:32:36.754446  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00371066 (* 1 = 0.00371066 loss)
I0927 17:32:36.754463  3463 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I0927 17:32:50.959583  3463 solver.cpp:218] Iteration 65900 (7.03973 iter/s, 14.2051s/100 iters), loss = 0.00340549
I0927 17:32:50.959615  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00340534 (* 1 = 0.00340534 loss)
I0927 17:32:50.959631  3463 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I0927 17:33:04.458773  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:33:05.026804  3463 solver.cpp:330] Iteration 66000, Testing net (#0)
I0927 17:33:08.377732  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:33:08.517452  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9213
I0927 17:33:08.517477  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324453 (* 1 = 0.324453 loss)
I0927 17:33:08.658680  3463 solver.cpp:218] Iteration 66000 (5.65003 iter/s, 17.699s/100 iters), loss = 0.00159762
I0927 17:33:08.658710  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00159747 (* 1 = 0.00159747 loss)
I0927 17:33:08.658717  3463 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I0927 17:33:22.869801  3463 solver.cpp:218] Iteration 66100 (7.03678 iter/s, 14.211s/100 iters), loss = 0.00104557
I0927 17:33:22.869832  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010454 (* 1 = 0.0010454 loss)
I0927 17:33:22.869848  3463 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I0927 17:33:37.078066  3463 solver.cpp:218] Iteration 66200 (7.03819 iter/s, 14.2082s/100 iters), loss = 0.00746552
I0927 17:33:37.078152  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00746534 (* 1 = 0.00746534 loss)
I0927 17:33:37.078169  3463 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I0927 17:33:51.294350  3463 solver.cpp:218] Iteration 66300 (7.03424 iter/s, 14.2162s/100 iters), loss = 0.00235393
I0927 17:33:51.294380  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00235376 (* 1 = 0.00235376 loss)
I0927 17:33:51.294386  3463 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I0927 17:34:05.510335  3463 solver.cpp:218] Iteration 66400 (7.03437 iter/s, 14.2159s/100 iters), loss = 0.00147238
I0927 17:34:05.510366  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0014722 (* 1 = 0.0014722 loss)
I0927 17:34:05.510371  3463 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I0927 17:34:19.020354  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:34:19.589773  3463 solver.cpp:330] Iteration 66500, Testing net (#0)
I0927 17:34:22.939895  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:34:23.080509  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9262
I0927 17:34:23.080546  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304867 (* 1 = 0.304867 loss)
I0927 17:34:23.221657  3463 solver.cpp:218] Iteration 66500 (5.64613 iter/s, 17.7112s/100 iters), loss = 0.00524768
I0927 17:34:23.221686  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00524751 (* 1 = 0.00524751 loss)
I0927 17:34:23.221693  3463 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I0927 17:34:37.430277  3463 solver.cpp:218] Iteration 66600 (7.03802 iter/s, 14.2085s/100 iters), loss = 0.00907428
I0927 17:34:37.430318  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0090741 (* 1 = 0.0090741 loss)
I0927 17:34:37.430325  3463 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I0927 17:34:51.637126  3463 solver.cpp:218] Iteration 66700 (7.0389 iter/s, 14.2068s/100 iters), loss = 0.00436923
I0927 17:34:51.637248  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00436905 (* 1 = 0.00436905 loss)
I0927 17:34:51.637254  3463 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I0927 17:35:05.848510  3463 solver.cpp:218] Iteration 66800 (7.03669 iter/s, 14.2112s/100 iters), loss = 0.00150511
I0927 17:35:05.848551  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00150494 (* 1 = 0.00150494 loss)
I0927 17:35:05.848557  3463 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I0927 17:35:20.059701  3463 solver.cpp:218] Iteration 66900 (7.03675 iter/s, 14.2111s/100 iters), loss = 0.00156945
I0927 17:35:20.059742  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00156927 (* 1 = 0.00156927 loss)
I0927 17:35:20.059747  3463 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I0927 17:35:33.561209  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:35:34.130748  3463 solver.cpp:330] Iteration 67000, Testing net (#0)
I0927 17:35:37.482116  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:35:37.622161  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9273
I0927 17:35:37.622198  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295726 (* 1 = 0.295726 loss)
I0927 17:35:37.763257  3463 solver.cpp:218] Iteration 67000 (5.64861 iter/s, 17.7035s/100 iters), loss = 0.011193
I0927 17:35:37.763286  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111928 (* 1 = 0.0111928 loss)
I0927 17:35:37.763293  3463 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I0927 17:35:51.958003  3463 solver.cpp:218] Iteration 67100 (7.04489 iter/s, 14.1947s/100 iters), loss = 0.00212762
I0927 17:35:51.958043  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00212744 (* 1 = 0.00212744 loss)
I0927 17:35:51.958050  3463 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I0927 17:36:06.156868  3463 solver.cpp:218] Iteration 67200 (7.04286 iter/s, 14.1988s/100 iters), loss = 0.00153885
I0927 17:36:06.156983  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153868 (* 1 = 0.00153868 loss)
I0927 17:36:06.157001  3463 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I0927 17:36:20.355792  3463 solver.cpp:218] Iteration 67300 (7.04286 iter/s, 14.1988s/100 iters), loss = 0.000833954
I0927 17:36:20.355823  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00083378 (* 1 = 0.00083378 loss)
I0927 17:36:20.355829  3463 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I0927 17:36:34.555866  3463 solver.cpp:218] Iteration 67400 (7.04225 iter/s, 14.2s/100 iters), loss = 0.0115743
I0927 17:36:34.555917  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115741 (* 1 = 0.0115741 loss)
I0927 17:36:34.555923  3463 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I0927 17:36:48.046818  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:36:48.614642  3463 solver.cpp:330] Iteration 67500, Testing net (#0)
I0927 17:36:51.966532  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:36:52.106600  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9227
I0927 17:36:52.106636  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324966 (* 1 = 0.324966 loss)
I0927 17:36:52.247632  3463 solver.cpp:218] Iteration 67500 (5.65238 iter/s, 17.6917s/100 iters), loss = 0.0028119
I0927 17:36:52.247663  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00281172 (* 1 = 0.00281172 loss)
I0927 17:36:52.247669  3463 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I0927 17:37:06.460826  3463 solver.cpp:218] Iteration 67600 (7.03575 iter/s, 14.2131s/100 iters), loss = 0.00599321
I0927 17:37:06.460857  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00599304 (* 1 = 0.00599304 loss)
I0927 17:37:06.460862  3463 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I0927 17:37:20.675055  3463 solver.cpp:218] Iteration 67700 (7.03524 iter/s, 14.2142s/100 iters), loss = 0.00662501
I0927 17:37:20.675176  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00662484 (* 1 = 0.00662484 loss)
I0927 17:37:20.675184  3463 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I0927 17:37:34.892155  3463 solver.cpp:218] Iteration 67800 (7.03386 iter/s, 14.217s/100 iters), loss = 0.00505615
I0927 17:37:34.892197  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00505597 (* 1 = 0.00505597 loss)
I0927 17:37:34.892204  3463 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I0927 17:37:49.114688  3463 solver.cpp:218] Iteration 67900 (7.03114 iter/s, 14.2225s/100 iters), loss = 0.00314634
I0927 17:37:49.114719  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00314616 (* 1 = 0.00314616 loss)
I0927 17:37:49.114725  3463 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I0927 17:38:02.622309  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:38:03.191726  3463 solver.cpp:330] Iteration 68000, Testing net (#0)
I0927 17:38:06.542536  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:38:06.682606  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9233
I0927 17:38:06.682642  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.30358 (* 1 = 0.30358 loss)
I0927 17:38:06.823984  3463 solver.cpp:218] Iteration 68000 (5.64678 iter/s, 17.7092s/100 iters), loss = 0.00206559
I0927 17:38:06.824013  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00206541 (* 1 = 0.00206541 loss)
I0927 17:38:06.824020  3463 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I0927 17:38:21.025578  3463 solver.cpp:218] Iteration 68100 (7.0415 iter/s, 14.2015s/100 iters), loss = 0.0444126
I0927 17:38:21.025609  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0444125 (* 1 = 0.0444125 loss)
I0927 17:38:21.025625  3463 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I0927 17:38:35.230542  3463 solver.cpp:218] Iteration 68200 (7.03983 iter/s, 14.2049s/100 iters), loss = 0.00588065
I0927 17:38:35.230661  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00588048 (* 1 = 0.00588048 loss)
I0927 17:38:35.230679  3463 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I0927 17:38:49.429131  3463 solver.cpp:218] Iteration 68300 (7.04303 iter/s, 14.1984s/100 iters), loss = 0.000705431
I0927 17:38:49.429160  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000705258 (* 1 = 0.000705258 loss)
I0927 17:38:49.429167  3463 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I0927 17:39:03.631161  3463 solver.cpp:218] Iteration 68400 (7.04128 iter/s, 14.202s/100 iters), loss = 0.0035045
I0927 17:39:03.631191  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00350432 (* 1 = 0.00350432 loss)
I0927 17:39:03.631197  3463 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I0927 17:39:17.126298  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:39:17.693946  3463 solver.cpp:330] Iteration 68500, Testing net (#0)
I0927 17:39:21.044256  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:39:21.184432  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9242
I0927 17:39:21.184468  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316727 (* 1 = 0.316727 loss)
I0927 17:39:21.325305  3463 solver.cpp:218] Iteration 68500 (5.65161 iter/s, 17.6941s/100 iters), loss = 0.0174092
I0927 17:39:21.325335  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.017409 (* 1 = 0.017409 loss)
I0927 17:39:21.325341  3463 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I0927 17:39:35.535331  3463 solver.cpp:218] Iteration 68600 (7.03732 iter/s, 14.21s/100 iters), loss = 0.00260305
I0927 17:39:35.535372  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00260287 (* 1 = 0.00260287 loss)
I0927 17:39:35.535378  3463 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I0927 17:39:49.746898  3463 solver.cpp:218] Iteration 68700 (7.03656 iter/s, 14.2115s/100 iters), loss = 0.00119463
I0927 17:39:49.747021  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00119446 (* 1 = 0.00119446 loss)
I0927 17:39:49.747028  3463 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I0927 17:40:03.964021  3463 solver.cpp:218] Iteration 68800 (7.03385 iter/s, 14.217s/100 iters), loss = 0.0197833
I0927 17:40:03.964063  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0197831 (* 1 = 0.0197831 loss)
I0927 17:40:03.964069  3463 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I0927 17:40:18.182818  3463 solver.cpp:218] Iteration 68900 (7.03298 iter/s, 14.2187s/100 iters), loss = 0.00162411
I0927 17:40:18.182860  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00162393 (* 1 = 0.00162393 loss)
I0927 17:40:18.182868  3463 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I0927 17:40:31.687522  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:40:32.257907  3463 solver.cpp:330] Iteration 69000, Testing net (#0)
I0927 17:40:35.608795  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:40:35.748663  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.924
I0927 17:40:35.748689  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32805 (* 1 = 0.32805 loss)
I0927 17:40:35.889314  3463 solver.cpp:218] Iteration 69000 (5.64767 iter/s, 17.7064s/100 iters), loss = 0.0152835
I0927 17:40:35.889343  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152833 (* 1 = 0.0152833 loss)
I0927 17:40:35.889349  3463 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I0927 17:40:50.089452  3463 solver.cpp:218] Iteration 69100 (7.04222 iter/s, 14.2001s/100 iters), loss = 0.00364029
I0927 17:40:50.089493  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00364012 (* 1 = 0.00364012 loss)
I0927 17:40:50.089499  3463 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I0927 17:41:04.293704  3463 solver.cpp:218] Iteration 69200 (7.04019 iter/s, 14.2042s/100 iters), loss = 0.0135347
I0927 17:41:04.293790  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0135345 (* 1 = 0.0135345 loss)
I0927 17:41:04.293807  3463 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I0927 17:41:18.496383  3463 solver.cpp:218] Iteration 69300 (7.04099 iter/s, 14.2026s/100 iters), loss = 0.00134396
I0927 17:41:18.496426  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00134378 (* 1 = 0.00134378 loss)
I0927 17:41:18.496433  3463 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I0927 17:41:32.703780  3463 solver.cpp:218] Iteration 69400 (7.03863 iter/s, 14.2073s/100 iters), loss = 0.00100577
I0927 17:41:32.703819  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010056 (* 1 = 0.0010056 loss)
I0927 17:41:32.703826  3463 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I0927 17:41:46.207446  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:41:46.776217  3463 solver.cpp:330] Iteration 69500, Testing net (#0)
I0927 17:41:50.126205  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:41:50.266278  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.924
I0927 17:41:50.266315  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.321277 (* 1 = 0.321277 loss)
I0927 17:41:50.407404  3463 solver.cpp:218] Iteration 69500 (5.64859 iter/s, 17.7035s/100 iters), loss = 0.000728017
I0927 17:41:50.407433  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000727842 (* 1 = 0.000727842 loss)
I0927 17:41:50.407440  3463 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I0927 17:42:04.615519  3463 solver.cpp:218] Iteration 69600 (7.03827 iter/s, 14.208s/100 iters), loss = 0.00364125
I0927 17:42:04.615550  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00364107 (* 1 = 0.00364107 loss)
I0927 17:42:04.615556  3463 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I0927 17:42:18.828703  3463 solver.cpp:218] Iteration 69700 (7.03576 iter/s, 14.2131s/100 iters), loss = 0.00061957
I0927 17:42:18.828830  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000619392 (* 1 = 0.000619392 loss)
I0927 17:42:18.828837  3463 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I0927 17:42:33.037400  3463 solver.cpp:218] Iteration 69800 (7.03802 iter/s, 14.2085s/100 iters), loss = 0.00527626
I0927 17:42:33.037427  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00527608 (* 1 = 0.00527608 loss)
I0927 17:42:33.037433  3463 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I0927 17:42:47.249954  3463 solver.cpp:218] Iteration 69900 (7.03607 iter/s, 14.2125s/100 iters), loss = 0.000816745
I0927 17:42:47.249984  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000816566 (* 1 = 0.000816566 loss)
I0927 17:42:47.249990  3463 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I0927 17:43:00.758601  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:43:01.328838  3463 solver.cpp:330] Iteration 70000, Testing net (#0)
I0927 17:43:04.680667  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:43:04.820533  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9172
I0927 17:43:04.820569  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.346079 (* 1 = 0.346079 loss)
I0927 17:43:04.961459  3463 solver.cpp:218] Iteration 70000 (5.64607 iter/s, 17.7114s/100 iters), loss = 0.00481913
I0927 17:43:04.961488  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00481895 (* 1 = 0.00481895 loss)
I0927 17:43:04.961494  3463 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I0927 17:43:19.173403  3463 solver.cpp:218] Iteration 70100 (7.03637 iter/s, 14.2119s/100 iters), loss = 0.0116779
I0927 17:43:19.173432  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116777 (* 1 = 0.0116777 loss)
I0927 17:43:19.173437  3463 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I0927 17:43:33.389560  3463 solver.cpp:218] Iteration 70200 (7.03428 iter/s, 14.2161s/100 iters), loss = 0.0416906
I0927 17:43:33.389683  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0416904 (* 1 = 0.0416904 loss)
I0927 17:43:33.389700  3463 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I0927 17:43:47.606647  3463 solver.cpp:218] Iteration 70300 (7.03387 iter/s, 14.2169s/100 iters), loss = 0.00621855
I0927 17:43:47.606678  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00621838 (* 1 = 0.00621838 loss)
I0927 17:43:47.606684  3463 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I0927 17:44:01.817859  3463 solver.cpp:218] Iteration 70400 (7.03673 iter/s, 14.2111s/100 iters), loss = 0.00448415
I0927 17:44:01.817900  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00448397 (* 1 = 0.00448397 loss)
I0927 17:44:01.817906  3463 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I0927 17:44:15.326428  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:44:15.896800  3463 solver.cpp:330] Iteration 70500, Testing net (#0)
I0927 17:44:19.248689  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:44:19.387500  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9158
I0927 17:44:19.387537  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.359296 (* 1 = 0.359296 loss)
I0927 17:44:19.528424  3463 solver.cpp:218] Iteration 70500 (5.64638 iter/s, 17.7105s/100 iters), loss = 0.00146467
I0927 17:44:19.528453  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00146449 (* 1 = 0.00146449 loss)
I0927 17:44:19.528460  3463 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I0927 17:44:33.733201  3463 solver.cpp:218] Iteration 70600 (7.03992 iter/s, 14.2047s/100 iters), loss = 0.00261814
I0927 17:44:33.733232  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00261796 (* 1 = 0.00261796 loss)
I0927 17:44:33.733237  3463 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I0927 17:44:47.947366  3463 solver.cpp:218] Iteration 70700 (7.03527 iter/s, 14.2141s/100 iters), loss = 0.0106143
I0927 17:44:47.947494  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106141 (* 1 = 0.0106141 loss)
I0927 17:44:47.947501  3463 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I0927 17:45:02.159610  3463 solver.cpp:218] Iteration 70800 (7.03627 iter/s, 14.2121s/100 iters), loss = 0.00169737
I0927 17:45:02.159641  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00169719 (* 1 = 0.00169719 loss)
I0927 17:45:02.159646  3463 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I0927 17:45:16.372567  3463 solver.cpp:218] Iteration 70900 (7.03587 iter/s, 14.2129s/100 iters), loss = 0.00156311
I0927 17:45:16.372597  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00156292 (* 1 = 0.00156292 loss)
I0927 17:45:16.372603  3463 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I0927 17:45:29.880726  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:45:30.450400  3463 solver.cpp:330] Iteration 71000, Testing net (#0)
I0927 17:45:33.802048  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:45:33.942469  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9247
I0927 17:45:33.942505  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325682 (* 1 = 0.325682 loss)
I0927 17:45:34.083678  3463 solver.cpp:218] Iteration 71000 (5.6462 iter/s, 17.711s/100 iters), loss = 0.00325803
I0927 17:45:34.083709  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00325784 (* 1 = 0.00325784 loss)
I0927 17:45:34.083716  3463 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I0927 17:45:48.293819  3463 solver.cpp:218] Iteration 71100 (7.03726 iter/s, 14.2101s/100 iters), loss = 0.0106054
I0927 17:45:48.293861  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106052 (* 1 = 0.0106052 loss)
I0927 17:45:48.293867  3463 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I0927 17:46:02.514597  3463 solver.cpp:218] Iteration 71200 (7.032 iter/s, 14.2207s/100 iters), loss = 0.00231744
I0927 17:46:02.514699  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00231726 (* 1 = 0.00231726 loss)
I0927 17:46:02.514715  3463 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I0927 17:46:16.733832  3463 solver.cpp:218] Iteration 71300 (7.0328 iter/s, 14.2191s/100 iters), loss = 0.00235459
I0927 17:46:16.733875  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00235441 (* 1 = 0.00235441 loss)
I0927 17:46:16.733880  3463 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I0927 17:46:30.946921  3463 solver.cpp:218] Iteration 71400 (7.03581 iter/s, 14.213s/100 iters), loss = 0.00229418
I0927 17:46:30.946952  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.002294 (* 1 = 0.002294 loss)
I0927 17:46:30.946959  3463 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I0927 17:46:44.453838  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:46:45.023198  3463 solver.cpp:330] Iteration 71500, Testing net (#0)
I0927 17:46:48.374709  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:46:48.514911  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9242
I0927 17:46:48.514948  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311592 (* 1 = 0.311592 loss)
I0927 17:46:48.655824  3463 solver.cpp:218] Iteration 71500 (5.6469 iter/s, 17.7088s/100 iters), loss = 0.0041083
I0927 17:46:48.655853  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00410812 (* 1 = 0.00410812 loss)
I0927 17:46:48.655860  3463 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I0927 17:47:02.861724  3463 solver.cpp:218] Iteration 71600 (7.03936 iter/s, 14.2058s/100 iters), loss = 0.00465028
I0927 17:47:02.861765  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0046501 (* 1 = 0.0046501 loss)
I0927 17:47:02.861771  3463 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I0927 17:47:17.080725  3463 solver.cpp:218] Iteration 71700 (7.03288 iter/s, 14.2189s/100 iters), loss = 0.0244952
I0927 17:47:17.080832  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.024495 (* 1 = 0.024495 loss)
I0927 17:47:17.080849  3463 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I0927 17:47:31.285084  3463 solver.cpp:218] Iteration 71800 (7.04016 iter/s, 14.2042s/100 iters), loss = 0.00201369
I0927 17:47:31.285115  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00201351 (* 1 = 0.00201351 loss)
I0927 17:47:31.285120  3463 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I0927 17:47:45.481912  3463 solver.cpp:218] Iteration 71900 (7.04386 iter/s, 14.1968s/100 iters), loss = 0.00130538
I0927 17:47:45.481941  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00130519 (* 1 = 0.00130519 loss)
I0927 17:47:45.481957  3463 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I0927 17:47:58.985846  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:47:59.554392  3463 solver.cpp:330] Iteration 72000, Testing net (#0)
I0927 17:48:02.905216  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:48:03.045150  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9217
I0927 17:48:03.045173  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327446 (* 1 = 0.327446 loss)
I0927 17:48:03.186125  3463 solver.cpp:218] Iteration 72000 (5.6484 iter/s, 17.7041s/100 iters), loss = 0.0033964
I0927 17:48:03.186156  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00339621 (* 1 = 0.00339621 loss)
I0927 17:48:03.186162  3463 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I0927 17:48:17.391887  3463 solver.cpp:218] Iteration 72100 (7.03943 iter/s, 14.2057s/100 iters), loss = 0.00153342
I0927 17:48:17.391916  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153323 (* 1 = 0.00153323 loss)
I0927 17:48:17.391922  3463 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I0927 17:48:31.602648  3463 solver.cpp:218] Iteration 72200 (7.03695 iter/s, 14.2107s/100 iters), loss = 0.0116355
I0927 17:48:31.602747  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116353 (* 1 = 0.0116353 loss)
I0927 17:48:31.602754  3463 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I0927 17:48:45.813285  3463 solver.cpp:218] Iteration 72300 (7.03705 iter/s, 14.2105s/100 iters), loss = 0.00214696
I0927 17:48:45.813315  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00214677 (* 1 = 0.00214677 loss)
I0927 17:48:45.813321  3463 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I0927 17:49:00.022037  3463 solver.cpp:218] Iteration 72400 (7.03795 iter/s, 14.2087s/100 iters), loss = 0.00326477
I0927 17:49:00.022078  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00326458 (* 1 = 0.00326458 loss)
I0927 17:49:00.022083  3463 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I0927 17:49:13.530714  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:49:14.100255  3463 solver.cpp:330] Iteration 72500, Testing net (#0)
I0927 17:49:17.448829  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:49:17.589275  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.924
I0927 17:49:17.589301  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325652 (* 1 = 0.325652 loss)
I0927 17:49:17.730104  3463 solver.cpp:218] Iteration 72500 (5.64717 iter/s, 17.708s/100 iters), loss = 0.0116641
I0927 17:49:17.730132  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116639 (* 1 = 0.0116639 loss)
I0927 17:49:17.730139  3463 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I0927 17:49:31.944759  3463 solver.cpp:218] Iteration 72600 (7.03503 iter/s, 14.2146s/100 iters), loss = 0.0048764
I0927 17:49:31.944800  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00487621 (* 1 = 0.00487621 loss)
I0927 17:49:31.944806  3463 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I0927 17:49:46.159435  3463 solver.cpp:218] Iteration 72700 (7.03502 iter/s, 14.2146s/100 iters), loss = 0.002895
I0927 17:49:46.159565  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00289481 (* 1 = 0.00289481 loss)
I0927 17:49:46.159574  3463 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I0927 17:50:00.376607  3463 solver.cpp:218] Iteration 72800 (7.03383 iter/s, 14.217s/100 iters), loss = 0.00176207
I0927 17:50:00.376648  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00176188 (* 1 = 0.00176188 loss)
I0927 17:50:00.376655  3463 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I0927 17:50:14.593827  3463 solver.cpp:218] Iteration 72900 (7.03376 iter/s, 14.2171s/100 iters), loss = 0.0108286
I0927 17:50:14.593858  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108284 (* 1 = 0.0108284 loss)
I0927 17:50:14.593864  3463 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I0927 17:50:28.103932  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:50:28.673681  3463 solver.cpp:330] Iteration 73000, Testing net (#0)
I0927 17:50:32.023917  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:50:32.163960  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9244
I0927 17:50:32.163997  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314444 (* 1 = 0.314444 loss)
I0927 17:50:32.304175  3463 solver.cpp:218] Iteration 73000 (5.64644 iter/s, 17.7103s/100 iters), loss = 0.00760995
I0927 17:50:32.304204  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00760976 (* 1 = 0.00760976 loss)
I0927 17:50:32.304211  3463 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I0927 17:50:46.504209  3463 solver.cpp:218] Iteration 73100 (7.04227 iter/s, 14.2s/100 iters), loss = 0.00282395
I0927 17:50:46.504251  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00282376 (* 1 = 0.00282376 loss)
I0927 17:50:46.504257  3463 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I0927 17:51:00.712138  3463 solver.cpp:218] Iteration 73200 (7.03836 iter/s, 14.2078s/100 iters), loss = 0.00148658
I0927 17:51:00.712247  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0014864 (* 1 = 0.0014864 loss)
I0927 17:51:00.712265  3463 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I0927 17:51:14.917470  3463 solver.cpp:218] Iteration 73300 (7.03968 iter/s, 14.2052s/100 iters), loss = 0.00688556
I0927 17:51:14.917510  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00688538 (* 1 = 0.00688538 loss)
I0927 17:51:14.917516  3463 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I0927 17:51:29.124248  3463 solver.cpp:218] Iteration 73400 (7.03894 iter/s, 14.2067s/100 iters), loss = 0.00171385
I0927 17:51:29.124279  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00171367 (* 1 = 0.00171367 loss)
I0927 17:51:29.124285  3463 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I0927 17:51:42.624649  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:51:43.193635  3463 solver.cpp:330] Iteration 73500, Testing net (#0)
I0927 17:51:46.544819  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:51:46.684763  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9213
I0927 17:51:46.684799  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.331929 (* 1 = 0.331929 loss)
I0927 17:51:46.825687  3463 solver.cpp:218] Iteration 73500 (5.64928 iter/s, 17.7014s/100 iters), loss = 0.00272437
I0927 17:51:46.825716  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00272419 (* 1 = 0.00272419 loss)
I0927 17:51:46.825722  3463 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I0927 17:52:01.037925  3463 solver.cpp:218] Iteration 73600 (7.03622 iter/s, 14.2122s/100 iters), loss = 0.00644065
I0927 17:52:01.037967  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00644047 (* 1 = 0.00644047 loss)
I0927 17:52:01.037973  3463 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I0927 17:52:15.247319  3463 solver.cpp:218] Iteration 73700 (7.03764 iter/s, 14.2093s/100 iters), loss = 0.00102472
I0927 17:52:15.247447  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102454 (* 1 = 0.00102454 loss)
I0927 17:52:15.247467  3463 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I0927 17:52:29.461190  3463 solver.cpp:218] Iteration 73800 (7.03546 iter/s, 14.2137s/100 iters), loss = 0.00569101
I0927 17:52:29.461232  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00569082 (* 1 = 0.00569082 loss)
I0927 17:52:29.461238  3463 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I0927 17:52:43.677364  3463 solver.cpp:218] Iteration 73900 (7.03428 iter/s, 14.2161s/100 iters), loss = 0.00279984
I0927 17:52:43.677395  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00279965 (* 1 = 0.00279965 loss)
I0927 17:52:43.677402  3463 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I0927 17:52:57.186805  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:52:57.755625  3463 solver.cpp:330] Iteration 74000, Testing net (#0)
I0927 17:53:01.105784  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:53:01.245467  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9185
I0927 17:53:01.245503  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.344665 (* 1 = 0.344665 loss)
I0927 17:53:01.386672  3463 solver.cpp:218] Iteration 74000 (5.64677 iter/s, 17.7092s/100 iters), loss = 0.00103495
I0927 17:53:01.386703  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103476 (* 1 = 0.00103476 loss)
I0927 17:53:01.386709  3463 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I0927 17:53:15.586212  3463 solver.cpp:218] Iteration 74100 (7.04252 iter/s, 14.1995s/100 iters), loss = 0.00241181
I0927 17:53:15.586243  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00241162 (* 1 = 0.00241162 loss)
I0927 17:53:15.586249  3463 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I0927 17:53:29.788045  3463 solver.cpp:218] Iteration 74200 (7.04138 iter/s, 14.2018s/100 iters), loss = 0.00100645
I0927 17:53:29.788163  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100626 (* 1 = 0.00100626 loss)
I0927 17:53:29.788172  3463 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I0927 17:53:43.987594  3463 solver.cpp:218] Iteration 74300 (7.04255 iter/s, 14.1994s/100 iters), loss = 0.00293029
I0927 17:53:43.987625  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0029301 (* 1 = 0.0029301 loss)
I0927 17:53:43.987630  3463 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I0927 17:53:58.190874  3463 solver.cpp:218] Iteration 74400 (7.04066 iter/s, 14.2032s/100 iters), loss = 0.00237833
I0927 17:53:58.190915  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00237814 (* 1 = 0.00237814 loss)
I0927 17:53:58.190922  3463 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I0927 17:54:11.693843  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:54:12.262257  3463 solver.cpp:330] Iteration 74500, Testing net (#0)
I0927 17:54:15.612483  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:54:15.752724  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9237
I0927 17:54:15.752761  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.315845 (* 1 = 0.315845 loss)
I0927 17:54:15.893155  3463 solver.cpp:218] Iteration 74500 (5.64902 iter/s, 17.7022s/100 iters), loss = 0.000713145
I0927 17:54:15.893185  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000712952 (* 1 = 0.000712952 loss)
I0927 17:54:15.893193  3463 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I0927 17:54:30.096643  3463 solver.cpp:218] Iteration 74600 (7.04056 iter/s, 14.2034s/100 iters), loss = 0.00634358
I0927 17:54:30.096683  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00634339 (* 1 = 0.00634339 loss)
I0927 17:54:30.096689  3463 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I0927 17:54:44.307462  3463 solver.cpp:218] Iteration 74700 (7.03693 iter/s, 14.2107s/100 iters), loss = 0.00308957
I0927 17:54:44.307595  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00308937 (* 1 = 0.00308937 loss)
I0927 17:54:44.307611  3463 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I0927 17:54:58.514605  3463 solver.cpp:218] Iteration 74800 (7.03879 iter/s, 14.207s/100 iters), loss = 0.00143778
I0927 17:54:58.514647  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00143758 (* 1 = 0.00143758 loss)
I0927 17:54:58.514652  3463 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I0927 17:55:12.721339  3463 solver.cpp:218] Iteration 74900 (7.03896 iter/s, 14.2067s/100 iters), loss = 0.00158805
I0927 17:55:12.721382  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00158786 (* 1 = 0.00158786 loss)
I0927 17:55:12.721388  3463 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I0927 17:55:26.220968  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:55:26.789912  3463 solver.cpp:330] Iteration 75000, Testing net (#0)
I0927 17:55:30.139245  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:55:30.279196  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9227
I0927 17:55:30.279222  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.323898 (* 1 = 0.323898 loss)
I0927 17:55:30.420482  3463 solver.cpp:218] Iteration 75000 (5.65002 iter/s, 17.6991s/100 iters), loss = 0.000688435
I0927 17:55:30.420512  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000688244 (* 1 = 0.000688244 loss)
I0927 17:55:30.420518  3463 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I0927 17:55:44.631253  3463 solver.cpp:218] Iteration 75100 (7.03695 iter/s, 14.2107s/100 iters), loss = 0.00499219
I0927 17:55:44.631283  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.004992 (* 1 = 0.004992 loss)
I0927 17:55:44.631290  3463 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I0927 17:55:58.842270  3463 solver.cpp:218] Iteration 75200 (7.03683 iter/s, 14.2109s/100 iters), loss = 0.000809153
I0927 17:55:58.842438  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000808963 (* 1 = 0.000808963 loss)
I0927 17:55:58.842447  3463 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I0927 17:56:13.059633  3463 solver.cpp:218] Iteration 75300 (7.03375 iter/s, 14.2172s/100 iters), loss = 0.00163043
I0927 17:56:13.059664  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00163024 (* 1 = 0.00163024 loss)
I0927 17:56:13.059670  3463 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I0927 17:56:27.274406  3463 solver.cpp:218] Iteration 75400 (7.03497 iter/s, 14.2147s/100 iters), loss = 0.0170361
I0927 17:56:27.274436  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0170359 (* 1 = 0.0170359 loss)
I0927 17:56:27.274442  3463 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I0927 17:56:40.780366  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:56:41.348816  3463 solver.cpp:330] Iteration 75500, Testing net (#0)
I0927 17:56:44.698004  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:56:44.837945  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.926
I0927 17:56:44.837982  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.315257 (* 1 = 0.315257 loss)
I0927 17:56:44.978576  3463 solver.cpp:218] Iteration 75500 (5.64841 iter/s, 17.7041s/100 iters), loss = 0.00170975
I0927 17:56:44.978607  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00170956 (* 1 = 0.00170956 loss)
I0927 17:56:44.978615  3463 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I0927 17:56:59.185273  3463 solver.cpp:218] Iteration 75600 (7.03897 iter/s, 14.2066s/100 iters), loss = 0.00236955
I0927 17:56:59.185304  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00236936 (* 1 = 0.00236936 loss)
I0927 17:56:59.185310  3463 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I0927 17:57:13.388883  3463 solver.cpp:218] Iteration 75700 (7.0405 iter/s, 14.2035s/100 iters), loss = 0.00879191
I0927 17:57:13.388977  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00879171 (* 1 = 0.00879171 loss)
I0927 17:57:13.388983  3463 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I0927 17:57:27.597220  3463 solver.cpp:218] Iteration 75800 (7.03819 iter/s, 14.2082s/100 iters), loss = 0.00191555
I0927 17:57:27.597251  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00191535 (* 1 = 0.00191535 loss)
I0927 17:57:27.597257  3463 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I0927 17:57:41.806969  3463 solver.cpp:218] Iteration 75900 (7.03746 iter/s, 14.2097s/100 iters), loss = 0.00224905
I0927 17:57:41.807010  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00224886 (* 1 = 0.00224886 loss)
I0927 17:57:41.807016  3463 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I0927 17:57:55.313478  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:57:55.882205  3463 solver.cpp:330] Iteration 76000, Testing net (#0)
I0927 17:57:59.231029  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:57:59.371009  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9205
I0927 17:57:59.371047  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.350211 (* 1 = 0.350211 loss)
I0927 17:57:59.511770  3463 solver.cpp:218] Iteration 76000 (5.64821 iter/s, 17.7047s/100 iters), loss = 0.00231161
I0927 17:57:59.511800  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00231141 (* 1 = 0.00231141 loss)
I0927 17:57:59.511806  3463 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I0927 17:58:13.720717  3463 solver.cpp:218] Iteration 76100 (7.03785 iter/s, 14.2089s/100 iters), loss = 0.000960417
I0927 17:58:13.720748  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00096022 (* 1 = 0.00096022 loss)
I0927 17:58:13.720754  3463 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I0927 17:58:27.931110  3463 solver.cpp:218] Iteration 76200 (7.03714 iter/s, 14.2103s/100 iters), loss = 0.0023676
I0927 17:58:27.931221  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0023674 (* 1 = 0.0023674 loss)
I0927 17:58:27.931237  3463 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I0927 17:58:42.143538  3463 solver.cpp:218] Iteration 76300 (7.03617 iter/s, 14.2123s/100 iters), loss = 0.0123382
I0927 17:58:42.143579  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012338 (* 1 = 0.012338 loss)
I0927 17:58:42.143584  3463 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I0927 17:58:56.354564  3463 solver.cpp:218] Iteration 76400 (7.03683 iter/s, 14.2109s/100 iters), loss = 0.00221347
I0927 17:58:56.354606  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00221327 (* 1 = 0.00221327 loss)
I0927 17:58:56.354611  3463 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I0927 17:59:09.856212  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:59:10.425504  3463 solver.cpp:330] Iteration 76500, Testing net (#0)
I0927 17:59:13.775439  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 17:59:13.915459  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9237
I0927 17:59:13.915496  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.317697 (* 1 = 0.317697 loss)
I0927 17:59:14.056531  3463 solver.cpp:218] Iteration 76500 (5.64912 iter/s, 17.7019s/100 iters), loss = 0.00103231
I0927 17:59:14.056560  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103211 (* 1 = 0.00103211 loss)
I0927 17:59:14.056567  3463 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I0927 17:59:28.260044  3463 solver.cpp:218] Iteration 76600 (7.04055 iter/s, 14.2034s/100 iters), loss = 0.00987517
I0927 17:59:28.260076  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00987497 (* 1 = 0.00987497 loss)
I0927 17:59:28.260082  3463 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I0927 17:59:42.469244  3463 solver.cpp:218] Iteration 76700 (7.03773 iter/s, 14.2091s/100 iters), loss = 0.00943705
I0927 17:59:42.469323  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00943685 (* 1 = 0.00943685 loss)
I0927 17:59:42.469341  3463 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I0927 17:59:56.675020  3463 solver.cpp:218] Iteration 76800 (7.03945 iter/s, 14.2057s/100 iters), loss = 0.000629107
I0927 17:59:56.675050  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000628907 (* 1 = 0.000628907 loss)
I0927 17:59:56.675056  3463 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I0927 18:00:10.882767  3463 solver.cpp:218] Iteration 76900 (7.03845 iter/s, 14.2077s/100 iters), loss = 0.00330262
I0927 18:00:10.882808  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00330242 (* 1 = 0.00330242 loss)
I0927 18:00:10.882814  3463 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I0927 18:00:24.386807  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:00:24.955252  3463 solver.cpp:330] Iteration 77000, Testing net (#0)
I0927 18:00:28.303817  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:00:28.443822  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9195
I0927 18:00:28.443859  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338391 (* 1 = 0.338391 loss)
I0927 18:00:28.584543  3463 solver.cpp:218] Iteration 77000 (5.64918 iter/s, 17.7017s/100 iters), loss = 0.00131755
I0927 18:00:28.584574  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00131735 (* 1 = 0.00131735 loss)
I0927 18:00:28.584583  3463 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I0927 18:00:42.792472  3463 solver.cpp:218] Iteration 77100 (7.03836 iter/s, 14.2079s/100 iters), loss = 0.007475
I0927 18:00:42.792512  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0074748 (* 1 = 0.0074748 loss)
I0927 18:00:42.792518  3463 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I0927 18:00:57.003351  3463 solver.cpp:218] Iteration 77200 (7.0369 iter/s, 14.2108s/100 iters), loss = 0.0109235
I0927 18:00:57.003435  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109233 (* 1 = 0.0109233 loss)
I0927 18:00:57.003451  3463 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I0927 18:01:11.220278  3463 solver.cpp:218] Iteration 77300 (7.03393 iter/s, 14.2168s/100 iters), loss = 0.00254699
I0927 18:01:11.220320  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00254679 (* 1 = 0.00254679 loss)
I0927 18:01:11.220326  3463 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I0927 18:01:25.434093  3463 solver.cpp:218] Iteration 77400 (7.03545 iter/s, 14.2137s/100 iters), loss = 0.00405951
I0927 18:01:25.434134  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00405931 (* 1 = 0.00405931 loss)
I0927 18:01:25.434140  3463 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I0927 18:01:38.941712  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:01:39.510856  3463 solver.cpp:330] Iteration 77500, Testing net (#0)
I0927 18:01:42.860644  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:01:43.000882  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9192
I0927 18:01:43.000918  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.353398 (* 1 = 0.353398 loss)
I0927 18:01:43.141043  3463 solver.cpp:218] Iteration 77500 (5.64753 iter/s, 17.7069s/100 iters), loss = 0.00489308
I0927 18:01:43.141073  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00489288 (* 1 = 0.00489288 loss)
I0927 18:01:43.141079  3463 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I0927 18:01:57.336768  3463 solver.cpp:218] Iteration 77600 (7.04441 iter/s, 14.1957s/100 iters), loss = 0.0017575
I0927 18:01:57.336810  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00175731 (* 1 = 0.00175731 loss)
I0927 18:01:57.336817  3463 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I0927 18:02:11.540638  3463 solver.cpp:218] Iteration 77700 (7.04038 iter/s, 14.2038s/100 iters), loss = 0.00274873
I0927 18:02:11.540758  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00274853 (* 1 = 0.00274853 loss)
I0927 18:02:11.540766  3463 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I0927 18:02:25.744770  3463 solver.cpp:218] Iteration 77800 (7.04028 iter/s, 14.204s/100 iters), loss = 0.00148812
I0927 18:02:25.744809  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00148792 (* 1 = 0.00148792 loss)
I0927 18:02:25.744815  3463 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I0927 18:02:39.939132  3463 solver.cpp:218] Iteration 77900 (7.04509 iter/s, 14.1943s/100 iters), loss = 0.0029267
I0927 18:02:39.939173  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0029265 (* 1 = 0.0029265 loss)
I0927 18:02:39.939179  3463 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I0927 18:02:53.438177  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:02:54.006722  3463 solver.cpp:330] Iteration 78000, Testing net (#0)
I0927 18:02:57.356760  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:02:57.497068  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9215
I0927 18:02:57.497105  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.323753 (* 1 = 0.323753 loss)
I0927 18:02:57.637604  3463 solver.cpp:218] Iteration 78000 (5.65023 iter/s, 17.6984s/100 iters), loss = 0.00252479
I0927 18:02:57.637635  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00252459 (* 1 = 0.00252459 loss)
I0927 18:02:57.637641  3463 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I0927 18:03:11.837445  3463 solver.cpp:218] Iteration 78100 (7.04237 iter/s, 14.1998s/100 iters), loss = 0.00215704
I0927 18:03:11.837487  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00215684 (* 1 = 0.00215684 loss)
I0927 18:03:11.837493  3463 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I0927 18:03:26.036346  3463 solver.cpp:218] Iteration 78200 (7.04284 iter/s, 14.1988s/100 iters), loss = 0.00271676
I0927 18:03:26.036430  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00271656 (* 1 = 0.00271656 loss)
I0927 18:03:26.036447  3463 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I0927 18:03:40.238178  3463 solver.cpp:218] Iteration 78300 (7.04141 iter/s, 14.2017s/100 iters), loss = 0.00288833
I0927 18:03:40.238219  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00288813 (* 1 = 0.00288813 loss)
I0927 18:03:40.238224  3463 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I0927 18:03:54.437721  3463 solver.cpp:218] Iteration 78400 (7.04252 iter/s, 14.1995s/100 iters), loss = 0.00244516
I0927 18:03:54.437762  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00244496 (* 1 = 0.00244496 loss)
I0927 18:03:54.437767  3463 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I0927 18:04:07.935223  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:04:08.504231  3463 solver.cpp:330] Iteration 78500, Testing net (#0)
I0927 18:04:11.853868  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:04:11.994163  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9161
I0927 18:04:11.994200  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.360249 (* 1 = 0.360249 loss)
I0927 18:04:12.134933  3463 solver.cpp:218] Iteration 78500 (5.65064 iter/s, 17.6971s/100 iters), loss = 0.00249828
I0927 18:04:12.134963  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00249808 (* 1 = 0.00249808 loss)
I0927 18:04:12.134969  3463 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I0927 18:04:26.353914  3463 solver.cpp:218] Iteration 78600 (7.03289 iter/s, 14.2189s/100 iters), loss = 0.00413951
I0927 18:04:26.353955  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0041393 (* 1 = 0.0041393 loss)
I0927 18:04:26.353961  3463 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I0927 18:04:40.859895  3463 solver.cpp:218] Iteration 78700 (6.89375 iter/s, 14.5059s/100 iters), loss = 0.0033517
I0927 18:04:40.860057  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00335149 (* 1 = 0.00335149 loss)
I0927 18:04:40.860076  3463 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I0927 18:04:55.173030  3463 solver.cpp:218] Iteration 78800 (6.98669 iter/s, 14.3129s/100 iters), loss = 0.00169957
I0927 18:04:55.173063  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00169936 (* 1 = 0.00169936 loss)
I0927 18:04:55.173069  3463 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I0927 18:05:09.521862  3463 solver.cpp:218] Iteration 78900 (6.96924 iter/s, 14.3488s/100 iters), loss = 0.0177788
I0927 18:05:09.521896  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177786 (* 1 = 0.0177786 loss)
I0927 18:05:09.521903  3463 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I0927 18:05:23.112392  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:05:23.687623  3463 solver.cpp:330] Iteration 79000, Testing net (#0)
I0927 18:05:27.092877  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:05:27.235015  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9214
I0927 18:05:27.235051  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.341867 (* 1 = 0.341867 loss)
I0927 18:05:27.375530  3463 solver.cpp:218] Iteration 79000 (5.60112 iter/s, 17.8536s/100 iters), loss = 0.0194805
I0927 18:05:27.375560  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0194803 (* 1 = 0.0194803 loss)
I0927 18:05:27.375566  3463 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I0927 18:05:41.661932  3463 solver.cpp:218] Iteration 79100 (6.9997 iter/s, 14.2863s/100 iters), loss = 0.00403106
I0927 18:05:41.661964  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00403084 (* 1 = 0.00403084 loss)
I0927 18:05:41.661972  3463 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I0927 18:05:55.995219  3463 solver.cpp:218] Iteration 79200 (6.9768 iter/s, 14.3332s/100 iters), loss = 0.00116874
I0927 18:05:55.995331  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00116852 (* 1 = 0.00116852 loss)
I0927 18:05:55.995347  3463 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I0927 18:06:10.197913  3463 solver.cpp:218] Iteration 79300 (7.04099 iter/s, 14.2026s/100 iters), loss = 0.00818321
I0927 18:06:10.197944  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00818298 (* 1 = 0.00818298 loss)
I0927 18:06:10.197950  3463 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I0927 18:06:24.396471  3463 solver.cpp:218] Iteration 79400 (7.043 iter/s, 14.1985s/100 iters), loss = 0.000595927
I0927 18:06:24.396500  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000595701 (* 1 = 0.000595701 loss)
I0927 18:06:24.396507  3463 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I0927 18:06:37.895442  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:06:38.464453  3463 solver.cpp:330] Iteration 79500, Testing net (#0)
I0927 18:06:41.814618  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:06:41.954675  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9224
I0927 18:06:41.954712  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.332188 (* 1 = 0.332188 loss)
I0927 18:06:42.095134  3463 solver.cpp:218] Iteration 79500 (5.65017 iter/s, 17.6986s/100 iters), loss = 0.00126044
I0927 18:06:42.095163  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00126022 (* 1 = 0.00126022 loss)
I0927 18:06:42.095171  3463 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I0927 18:06:56.309065  3463 solver.cpp:218] Iteration 79600 (7.03539 iter/s, 14.2139s/100 iters), loss = 0.00304481
I0927 18:06:56.309106  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00304458 (* 1 = 0.00304458 loss)
I0927 18:06:56.309113  3463 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I0927 18:07:10.522420  3463 solver.cpp:218] Iteration 79700 (7.03567 iter/s, 14.2133s/100 iters), loss = 0.00729085
I0927 18:07:10.522569  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00729063 (* 1 = 0.00729063 loss)
I0927 18:07:10.522590  3463 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I0927 18:07:24.733799  3463 solver.cpp:218] Iteration 79800 (7.03671 iter/s, 14.2112s/100 iters), loss = 0.00314964
I0927 18:07:24.733840  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00314941 (* 1 = 0.00314941 loss)
I0927 18:07:24.733847  3463 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I0927 18:07:38.949512  3463 solver.cpp:218] Iteration 79900 (7.03451 iter/s, 14.2156s/100 iters), loss = 0.00646536
I0927 18:07:38.949542  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00646514 (* 1 = 0.00646514 loss)
I0927 18:07:38.949548  3463 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I0927 18:07:52.453002  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:07:53.022977  3463 solver.cpp:330] Iteration 80000, Testing net (#0)
I0927 18:07:56.372972  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:07:56.513018  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9215
I0927 18:07:56.513056  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333366 (* 1 = 0.333366 loss)
I0927 18:07:56.654422  3463 solver.cpp:218] Iteration 80000 (5.64818 iter/s, 17.7048s/100 iters), loss = 0.00528736
I0927 18:07:56.654453  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00528715 (* 1 = 0.00528715 loss)
I0927 18:07:56.654458  3463 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I0927 18:07:56.654461  3463 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I0927 18:08:10.853340  3463 solver.cpp:218] Iteration 80100 (7.04282 iter/s, 14.1988s/100 iters), loss = 0.00487458
I0927 18:08:10.853370  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00487436 (* 1 = 0.00487436 loss)
I0927 18:08:10.853376  3463 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I0927 18:08:25.057739  3463 solver.cpp:218] Iteration 80200 (7.04011 iter/s, 14.2043s/100 iters), loss = 0.000944015
I0927 18:08:25.057874  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000943795 (* 1 = 0.000943795 loss)
I0927 18:08:25.057881  3463 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I0927 18:08:39.257230  3463 solver.cpp:218] Iteration 80300 (7.04259 iter/s, 14.1993s/100 iters), loss = 0.000957086
I0927 18:08:39.257272  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000956864 (* 1 = 0.000956864 loss)
I0927 18:08:39.257277  3463 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I0927 18:08:53.457857  3463 solver.cpp:218] Iteration 80400 (7.04198 iter/s, 14.2005s/100 iters), loss = 0.00315391
I0927 18:08:53.457900  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00315369 (* 1 = 0.00315369 loss)
I0927 18:08:53.457904  3463 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I0927 18:09:06.951421  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:09:07.520462  3463 solver.cpp:330] Iteration 80500, Testing net (#0)
I0927 18:09:10.871073  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:09:11.011696  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9264
I0927 18:09:11.011724  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310236 (* 1 = 0.310236 loss)
I0927 18:09:11.152971  3463 solver.cpp:218] Iteration 80500 (5.65131 iter/s, 17.695s/100 iters), loss = 0.00299071
I0927 18:09:11.153003  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00299049 (* 1 = 0.00299049 loss)
I0927 18:09:11.153013  3463 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I0927 18:09:25.359113  3463 solver.cpp:218] Iteration 80600 (7.03925 iter/s, 14.2061s/100 iters), loss = 0.00138974
I0927 18:09:25.359148  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00138952 (* 1 = 0.00138952 loss)
I0927 18:09:25.359165  3463 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I0927 18:09:39.567067  3463 solver.cpp:218] Iteration 80700 (7.03835 iter/s, 14.2079s/100 iters), loss = 0.000657603
I0927 18:09:39.567225  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000657379 (* 1 = 0.000657379 loss)
I0927 18:09:39.567236  3463 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I0927 18:09:53.776001  3463 solver.cpp:218] Iteration 80800 (7.03792 iter/s, 14.2087s/100 iters), loss = 0.000728157
I0927 18:09:53.776036  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000727934 (* 1 = 0.000727934 loss)
I0927 18:09:53.776054  3463 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I0927 18:10:07.986512  3463 solver.cpp:218] Iteration 80900 (7.03708 iter/s, 14.2104s/100 iters), loss = 0.00129529
I0927 18:10:07.986546  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00129507 (* 1 = 0.00129507 loss)
I0927 18:10:07.986552  3463 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I0927 18:10:21.495760  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:10:22.065258  3463 solver.cpp:330] Iteration 81000, Testing net (#0)
I0927 18:10:25.415608  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:10:25.555840  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9282
I0927 18:10:25.555876  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304639 (* 1 = 0.304639 loss)
I0927 18:10:25.696709  3463 solver.cpp:218] Iteration 81000 (5.64649 iter/s, 17.7101s/100 iters), loss = 0.00189879
I0927 18:10:25.696740  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00189856 (* 1 = 0.00189856 loss)
I0927 18:10:25.696746  3463 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I0927 18:10:39.896695  3463 solver.cpp:218] Iteration 81100 (7.0423 iter/s, 14.1999s/100 iters), loss = 0.00300294
I0927 18:10:39.896736  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00300271 (* 1 = 0.00300271 loss)
I0927 18:10:39.896741  3463 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I0927 18:10:54.102411  3463 solver.cpp:218] Iteration 81200 (7.03946 iter/s, 14.2056s/100 iters), loss = 0.00289926
I0927 18:10:54.102560  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00289904 (* 1 = 0.00289904 loss)
I0927 18:10:54.102578  3463 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I0927 18:11:08.302892  3463 solver.cpp:218] Iteration 81300 (7.04211 iter/s, 14.2003s/100 iters), loss = 0.00139176
I0927 18:11:08.302935  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00139153 (* 1 = 0.00139153 loss)
I0927 18:11:08.302942  3463 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I0927 18:11:22.508960  3463 solver.cpp:218] Iteration 81400 (7.03929 iter/s, 14.206s/100 iters), loss = 0.000991224
I0927 18:11:22.508991  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000990999 (* 1 = 0.000990999 loss)
I0927 18:11:22.508996  3463 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I0927 18:11:36.010735  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:11:36.579830  3463 solver.cpp:330] Iteration 81500, Testing net (#0)
I0927 18:11:39.930452  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:11:40.070236  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9288
I0927 18:11:40.070273  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300065 (* 1 = 0.300065 loss)
I0927 18:11:40.211302  3463 solver.cpp:218] Iteration 81500 (5.649 iter/s, 17.7023s/100 iters), loss = 0.00246081
I0927 18:11:40.211330  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00246059 (* 1 = 0.00246059 loss)
I0927 18:11:40.211338  3463 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I0927 18:11:54.415482  3463 solver.cpp:218] Iteration 81600 (7.04021 iter/s, 14.2041s/100 iters), loss = 0.00200248
I0927 18:11:54.415524  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00200225 (* 1 = 0.00200225 loss)
I0927 18:11:54.415529  3463 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I0927 18:12:08.619503  3463 solver.cpp:218] Iteration 81700 (7.0403 iter/s, 14.2039s/100 iters), loss = 0.00132837
I0927 18:12:08.619658  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00132814 (* 1 = 0.00132814 loss)
I0927 18:12:08.619665  3463 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I0927 18:12:22.820719  3463 solver.cpp:218] Iteration 81800 (7.04175 iter/s, 14.201s/100 iters), loss = 0.00412085
I0927 18:12:22.820749  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00412062 (* 1 = 0.00412062 loss)
I0927 18:12:22.820755  3463 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I0927 18:12:37.033459  3463 solver.cpp:218] Iteration 81900 (7.03597 iter/s, 14.2127s/100 iters), loss = 0.00111406
I0927 18:12:37.033491  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00111384 (* 1 = 0.00111384 loss)
I0927 18:12:37.033506  3463 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I0927 18:12:50.537480  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:12:51.107741  3463 solver.cpp:330] Iteration 82000, Testing net (#0)
I0927 18:12:54.460275  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:12:54.600630  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9284
I0927 18:12:54.600667  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.297762 (* 1 = 0.297762 loss)
I0927 18:12:54.741600  3463 solver.cpp:218] Iteration 82000 (5.64715 iter/s, 17.7081s/100 iters), loss = 0.00384945
I0927 18:12:54.741631  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00384922 (* 1 = 0.00384922 loss)
I0927 18:12:54.741637  3463 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I0927 18:13:08.961369  3463 solver.cpp:218] Iteration 82100 (7.0325 iter/s, 14.2197s/100 iters), loss = 0.00139289
I0927 18:13:08.961411  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00139266 (* 1 = 0.00139266 loss)
I0927 18:13:08.961417  3463 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I0927 18:13:23.175338  3463 solver.cpp:218] Iteration 82200 (7.03537 iter/s, 14.2139s/100 iters), loss = 0.00101124
I0927 18:13:23.175457  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00101101 (* 1 = 0.00101101 loss)
I0927 18:13:23.175474  3463 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I0927 18:13:37.395656  3463 solver.cpp:218] Iteration 82300 (7.03227 iter/s, 14.2202s/100 iters), loss = 0.000898724
I0927 18:13:37.395699  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000898496 (* 1 = 0.000898496 loss)
I0927 18:13:37.395704  3463 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I0927 18:13:51.615592  3463 solver.cpp:218] Iteration 82400 (7.03242 iter/s, 14.2199s/100 iters), loss = 0.00304017
I0927 18:13:51.615634  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00303995 (* 1 = 0.00303995 loss)
I0927 18:13:51.615640  3463 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I0927 18:14:05.131039  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:14:05.700075  3463 solver.cpp:330] Iteration 82500, Testing net (#0)
I0927 18:14:09.050783  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:14:09.190888  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9282
I0927 18:14:09.190927  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.29499 (* 1 = 0.29499 loss)
I0927 18:14:09.331719  3463 solver.cpp:218] Iteration 82500 (5.6446 iter/s, 17.716s/100 iters), loss = 0.000752002
I0927 18:14:09.331749  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000751774 (* 1 = 0.000751774 loss)
I0927 18:14:09.331756  3463 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I0927 18:14:23.526577  3463 solver.cpp:218] Iteration 82600 (7.04484 iter/s, 14.1948s/100 iters), loss = 0.00497377
I0927 18:14:23.526608  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00497354 (* 1 = 0.00497354 loss)
I0927 18:14:23.526614  3463 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I0927 18:14:37.727897  3463 solver.cpp:218] Iteration 82700 (7.04163 iter/s, 14.2012s/100 iters), loss = 0.000441857
I0927 18:14:37.728004  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000441629 (* 1 = 0.000441629 loss)
I0927 18:14:37.728011  3463 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I0927 18:14:51.928501  3463 solver.cpp:218] Iteration 82800 (7.04203 iter/s, 14.2005s/100 iters), loss = 0.000482419
I0927 18:14:51.928532  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00048219 (* 1 = 0.00048219 loss)
I0927 18:14:51.928539  3463 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I0927 18:15:06.130566  3463 solver.cpp:218] Iteration 82900 (7.04127 iter/s, 14.202s/100 iters), loss = 0.000868377
I0927 18:15:06.130599  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000868147 (* 1 = 0.000868147 loss)
I0927 18:15:06.130614  3463 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I0927 18:15:19.630322  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:15:20.198740  3463 solver.cpp:330] Iteration 83000, Testing net (#0)
I0927 18:15:23.549906  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:15:23.690030  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9292
I0927 18:15:23.690068  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296286 (* 1 = 0.296286 loss)
I0927 18:15:23.830775  3463 solver.cpp:218] Iteration 83000 (5.64968 iter/s, 17.7001s/100 iters), loss = 0.00224334
I0927 18:15:23.830804  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00224311 (* 1 = 0.00224311 loss)
I0927 18:15:23.830811  3463 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I0927 18:15:38.031455  3463 solver.cpp:218] Iteration 83100 (7.04195 iter/s, 14.2006s/100 iters), loss = 0.00618083
I0927 18:15:38.031486  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0061806 (* 1 = 0.0061806 loss)
I0927 18:15:38.031502  3463 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I0927 18:15:52.237205  3463 solver.cpp:218] Iteration 83200 (7.03944 iter/s, 14.2057s/100 iters), loss = 0.00152908
I0927 18:15:52.237316  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00152885 (* 1 = 0.00152885 loss)
I0927 18:15:52.237323  3463 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I0927 18:16:06.449045  3463 solver.cpp:218] Iteration 83300 (7.03646 iter/s, 14.2117s/100 iters), loss = 0.000597835
I0927 18:16:06.449076  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000597604 (* 1 = 0.000597604 loss)
I0927 18:16:06.449092  3463 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I0927 18:16:20.658715  3463 solver.cpp:218] Iteration 83400 (7.0375 iter/s, 14.2096s/100 iters), loss = 0.00145952
I0927 18:16:20.658746  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00145929 (* 1 = 0.00145929 loss)
I0927 18:16:20.658752  3463 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I0927 18:16:34.159857  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:16:34.728332  3463 solver.cpp:330] Iteration 83500, Testing net (#0)
I0927 18:16:38.078919  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:16:38.218369  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9283
I0927 18:16:38.218394  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296874 (* 1 = 0.296874 loss)
I0927 18:16:38.359048  3463 solver.cpp:218] Iteration 83500 (5.64964 iter/s, 17.7003s/100 iters), loss = 0.000900816
I0927 18:16:38.359081  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000900586 (* 1 = 0.000900586 loss)
I0927 18:16:38.359089  3463 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I0927 18:16:52.569332  3463 solver.cpp:218] Iteration 83600 (7.03719 iter/s, 14.2102s/100 iters), loss = 0.000955681
I0927 18:16:52.569372  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000955452 (* 1 = 0.000955452 loss)
I0927 18:16:52.569378  3463 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I0927 18:17:06.775717  3463 solver.cpp:218] Iteration 83700 (7.03913 iter/s, 14.2063s/100 iters), loss = 0.0015347
I0927 18:17:06.775873  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153447 (* 1 = 0.00153447 loss)
I0927 18:17:06.775883  3463 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I0927 18:17:20.983085  3463 solver.cpp:218] Iteration 83800 (7.0387 iter/s, 14.2072s/100 iters), loss = 0.000795051
I0927 18:17:20.983116  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00079482 (* 1 = 0.00079482 loss)
I0927 18:17:20.983122  3463 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I0927 18:17:35.190697  3463 solver.cpp:218] Iteration 83900 (7.03852 iter/s, 14.2075s/100 iters), loss = 0.000669307
I0927 18:17:35.190727  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000669077 (* 1 = 0.000669077 loss)
I0927 18:17:35.190733  3463 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I0927 18:17:48.690241  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:17:49.257918  3463 solver.cpp:330] Iteration 84000, Testing net (#0)
I0927 18:17:52.608506  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:17:52.748726  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9288
I0927 18:17:52.748764  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296084 (* 1 = 0.296084 loss)
I0927 18:17:52.889469  3463 solver.cpp:218] Iteration 84000 (5.65013 iter/s, 17.6987s/100 iters), loss = 0.00044657
I0927 18:17:52.889500  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000446339 (* 1 = 0.000446339 loss)
I0927 18:17:52.889508  3463 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I0927 18:18:07.089139  3463 solver.cpp:218] Iteration 84100 (7.04245 iter/s, 14.1996s/100 iters), loss = 0.00075888
I0927 18:18:07.089180  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000758648 (* 1 = 0.000758648 loss)
I0927 18:18:07.089186  3463 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I0927 18:18:21.290827  3463 solver.cpp:218] Iteration 84200 (7.04146 iter/s, 14.2016s/100 iters), loss = 0.000990549
I0927 18:18:21.290904  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000990318 (* 1 = 0.000990318 loss)
I0927 18:18:21.290910  3463 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I0927 18:18:35.497189  3463 solver.cpp:218] Iteration 84300 (7.03916 iter/s, 14.2063s/100 iters), loss = 0.000590083
I0927 18:18:35.497229  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000589851 (* 1 = 0.000589851 loss)
I0927 18:18:35.497236  3463 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I0927 18:18:49.704882  3463 solver.cpp:218] Iteration 84400 (7.03848 iter/s, 14.2076s/100 iters), loss = 0.00104964
I0927 18:18:49.704924  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00104941 (* 1 = 0.00104941 loss)
I0927 18:18:49.704931  3463 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I0927 18:19:03.206341  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:19:03.775610  3463 solver.cpp:330] Iteration 84500, Testing net (#0)
I0927 18:19:07.129359  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:19:07.269312  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9287
I0927 18:19:07.269340  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.29655 (* 1 = 0.29655 loss)
I0927 18:19:07.409337  3463 solver.cpp:218] Iteration 84500 (5.64832 iter/s, 17.7044s/100 iters), loss = 0.000852194
I0927 18:19:07.409366  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000851963 (* 1 = 0.000851963 loss)
I0927 18:19:07.409373  3463 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I0927 18:19:21.619201  3463 solver.cpp:218] Iteration 84600 (7.0374 iter/s, 14.2098s/100 iters), loss = 0.00552671
I0927 18:19:21.619232  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00552648 (* 1 = 0.00552648 loss)
I0927 18:19:21.619238  3463 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I0927 18:19:35.834735  3463 solver.cpp:218] Iteration 84700 (7.03459 iter/s, 14.2155s/100 iters), loss = 0.00282162
I0927 18:19:35.834898  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00282138 (* 1 = 0.00282138 loss)
I0927 18:19:35.834909  3463 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I0927 18:19:50.055114  3463 solver.cpp:218] Iteration 84800 (7.03226 iter/s, 14.2202s/100 iters), loss = 0.00071439
I0927 18:19:50.055156  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000714157 (* 1 = 0.000714157 loss)
I0927 18:19:50.055162  3463 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I0927 18:20:04.268894  3463 solver.cpp:218] Iteration 84900 (7.03547 iter/s, 14.2137s/100 iters), loss = 0.000473389
I0927 18:20:04.268936  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000473156 (* 1 = 0.000473156 loss)
I0927 18:20:04.268942  3463 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I0927 18:20:17.771767  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:20:18.340533  3463 solver.cpp:330] Iteration 85000, Testing net (#0)
I0927 18:20:21.690601  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:20:21.831045  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9282
I0927 18:20:21.831084  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296317 (* 1 = 0.296317 loss)
I0927 18:20:21.972034  3463 solver.cpp:218] Iteration 85000 (5.64874 iter/s, 17.703s/100 iters), loss = 0.00217026
I0927 18:20:21.972064  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00217002 (* 1 = 0.00217002 loss)
I0927 18:20:21.972071  3463 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I0927 18:20:36.170054  3463 solver.cpp:218] Iteration 85100 (7.04327 iter/s, 14.198s/100 iters), loss = 0.00164924
I0927 18:20:36.170086  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00164901 (* 1 = 0.00164901 loss)
I0927 18:20:36.170094  3463 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I0927 18:20:50.373149  3463 solver.cpp:218] Iteration 85200 (7.04076 iter/s, 14.203s/100 iters), loss = 0.00185979
I0927 18:20:50.373224  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00185956 (* 1 = 0.00185956 loss)
I0927 18:20:50.373231  3463 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I0927 18:21:04.578094  3463 solver.cpp:218] Iteration 85300 (7.03986 iter/s, 14.2048s/100 iters), loss = 0.0288175
I0927 18:21:04.578135  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0288172 (* 1 = 0.0288172 loss)
I0927 18:21:04.578141  3463 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I0927 18:21:18.782604  3463 solver.cpp:218] Iteration 85400 (7.04006 iter/s, 14.2044s/100 iters), loss = 0.000993437
I0927 18:21:18.782645  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000993203 (* 1 = 0.000993203 loss)
I0927 18:21:18.782651  3463 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I0927 18:21:32.281136  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:21:32.849251  3463 solver.cpp:330] Iteration 85500, Testing net (#0)
I0927 18:21:36.199801  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:21:36.339870  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9295
I0927 18:21:36.339896  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.29584 (* 1 = 0.29584 loss)
I0927 18:21:36.480762  3463 solver.cpp:218] Iteration 85500 (5.65033 iter/s, 17.6981s/100 iters), loss = 0.00628189
I0927 18:21:36.480792  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00628166 (* 1 = 0.00628166 loss)
I0927 18:21:36.480798  3463 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I0927 18:21:50.688230  3463 solver.cpp:218] Iteration 85600 (7.03859 iter/s, 14.2074s/100 iters), loss = 0.000866552
I0927 18:21:50.688271  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000866323 (* 1 = 0.000866323 loss)
I0927 18:21:50.688277  3463 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I0927 18:22:04.897202  3463 solver.cpp:218] Iteration 85700 (7.03785 iter/s, 14.2089s/100 iters), loss = 0.00684747
I0927 18:22:04.897313  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00684724 (* 1 = 0.00684724 loss)
I0927 18:22:04.897320  3463 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I0927 18:22:19.105234  3463 solver.cpp:218] Iteration 85800 (7.03834 iter/s, 14.2079s/100 iters), loss = 0.000743107
I0927 18:22:19.105265  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000742874 (* 1 = 0.000742874 loss)
I0927 18:22:19.105281  3463 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I0927 18:22:33.311308  3463 solver.cpp:218] Iteration 85900 (7.03928 iter/s, 14.206s/100 iters), loss = 0.000422952
I0927 18:22:33.311339  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000422718 (* 1 = 0.000422718 loss)
I0927 18:22:33.311345  3463 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I0927 18:22:46.810473  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:22:47.380153  3463 solver.cpp:330] Iteration 86000, Testing net (#0)
I0927 18:22:50.731822  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:22:50.871947  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9298
I0927 18:22:50.871989  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296837 (* 1 = 0.296837 loss)
I0927 18:22:51.011977  3463 solver.cpp:218] Iteration 86000 (5.64953 iter/s, 17.7006s/100 iters), loss = 0.000524062
I0927 18:22:51.012010  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00052383 (* 1 = 0.00052383 loss)
I0927 18:22:51.012019  3463 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I0927 18:23:05.218601  3463 solver.cpp:218] Iteration 86100 (7.039 iter/s, 14.2066s/100 iters), loss = 0.000533489
I0927 18:23:05.218633  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000533257 (* 1 = 0.000533257 loss)
I0927 18:23:05.218639  3463 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I0927 18:23:19.421890  3463 solver.cpp:218] Iteration 86200 (7.04066 iter/s, 14.2032s/100 iters), loss = 0.000353245
I0927 18:23:19.421964  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000353013 (* 1 = 0.000353013 loss)
I0927 18:23:19.421980  3463 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I0927 18:23:33.628965  3463 solver.cpp:218] Iteration 86300 (7.0388 iter/s, 14.207s/100 iters), loss = 0.00206284
I0927 18:23:33.628998  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00206261 (* 1 = 0.00206261 loss)
I0927 18:23:33.629014  3463 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I0927 18:23:47.835597  3463 solver.cpp:218] Iteration 86400 (7.039 iter/s, 14.2066s/100 iters), loss = 0.000299008
I0927 18:23:47.835628  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000298776 (* 1 = 0.000298776 loss)
I0927 18:23:47.835633  3463 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I0927 18:24:01.337815  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:24:01.905989  3463 solver.cpp:330] Iteration 86500, Testing net (#0)
I0927 18:24:05.258738  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:24:05.398507  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9297
I0927 18:24:05.398536  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296168 (* 1 = 0.296168 loss)
I0927 18:24:05.539094  3463 solver.cpp:218] Iteration 86500 (5.64863 iter/s, 17.7034s/100 iters), loss = 0.0129738
I0927 18:24:05.539124  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0129736 (* 1 = 0.0129736 loss)
I0927 18:24:05.539129  3463 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I0927 18:24:19.741726  3463 solver.cpp:218] Iteration 86600 (7.04098 iter/s, 14.2026s/100 iters), loss = 0.00199666
I0927 18:24:19.741755  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00199643 (* 1 = 0.00199643 loss)
I0927 18:24:19.741761  3463 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I0927 18:24:33.950691  3463 solver.cpp:218] Iteration 86700 (7.03785 iter/s, 14.2089s/100 iters), loss = 0.0114499
I0927 18:24:33.950834  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114497 (* 1 = 0.0114497 loss)
I0927 18:24:33.950855  3463 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I0927 18:24:48.146922  3463 solver.cpp:218] Iteration 86800 (7.04421 iter/s, 14.1961s/100 iters), loss = 0.000470464
I0927 18:24:48.146953  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000470232 (* 1 = 0.000470232 loss)
I0927 18:24:48.146960  3463 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I0927 18:25:02.347121  3463 solver.cpp:218] Iteration 86900 (7.04219 iter/s, 14.2001s/100 iters), loss = 0.00164079
I0927 18:25:02.347151  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00164056 (* 1 = 0.00164056 loss)
I0927 18:25:02.347157  3463 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I0927 18:25:15.848294  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:25:16.417425  3463 solver.cpp:330] Iteration 87000, Testing net (#0)
I0927 18:25:19.769891  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:25:19.909675  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9288
I0927 18:25:19.909701  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.294397 (* 1 = 0.294397 loss)
I0927 18:25:20.050309  3463 solver.cpp:218] Iteration 87000 (5.64872 iter/s, 17.7031s/100 iters), loss = 0.000725084
I0927 18:25:20.050338  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000724851 (* 1 = 0.000724851 loss)
I0927 18:25:20.050344  3463 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I0927 18:25:34.263622  3463 solver.cpp:218] Iteration 87100 (7.03569 iter/s, 14.2132s/100 iters), loss = 0.00270728
I0927 18:25:34.263653  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00270704 (* 1 = 0.00270704 loss)
I0927 18:25:34.263659  3463 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I0927 18:25:48.479444  3463 solver.cpp:218] Iteration 87200 (7.03445 iter/s, 14.2158s/100 iters), loss = 0.00197981
I0927 18:25:48.479548  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00197958 (* 1 = 0.00197958 loss)
I0927 18:25:48.479557  3463 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I0927 18:26:02.695271  3463 solver.cpp:218] Iteration 87300 (7.03448 iter/s, 14.2157s/100 iters), loss = 0.00147464
I0927 18:26:02.695303  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00147441 (* 1 = 0.00147441 loss)
I0927 18:26:02.695309  3463 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I0927 18:26:16.911926  3463 solver.cpp:218] Iteration 87400 (7.03404 iter/s, 14.2166s/100 iters), loss = 0.000863894
I0927 18:26:16.911967  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000863663 (* 1 = 0.000863663 loss)
I0927 18:26:16.911973  3463 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I0927 18:26:30.416913  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:26:30.985374  3463 solver.cpp:330] Iteration 87500, Testing net (#0)
I0927 18:26:34.335155  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:26:34.475484  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9293
I0927 18:26:34.475522  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296175 (* 1 = 0.296175 loss)
I0927 18:26:34.616091  3463 solver.cpp:218] Iteration 87500 (5.64842 iter/s, 17.7041s/100 iters), loss = 0.000617419
I0927 18:26:34.616122  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000617187 (* 1 = 0.000617187 loss)
I0927 18:26:34.616129  3463 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I0927 18:26:48.814101  3463 solver.cpp:218] Iteration 87600 (7.04327 iter/s, 14.1979s/100 iters), loss = 0.000582653
I0927 18:26:48.814132  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00058242 (* 1 = 0.00058242 loss)
I0927 18:26:48.814139  3463 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I0927 18:27:03.019819  3463 solver.cpp:218] Iteration 87700 (7.03945 iter/s, 14.2056s/100 iters), loss = 0.00230685
I0927 18:27:03.019917  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00230662 (* 1 = 0.00230662 loss)
I0927 18:27:03.019927  3463 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I0927 18:27:17.228514  3463 solver.cpp:218] Iteration 87800 (7.03801 iter/s, 14.2086s/100 iters), loss = 0.000328741
I0927 18:27:17.228545  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000328508 (* 1 = 0.000328508 loss)
I0927 18:27:17.228551  3463 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I0927 18:27:31.445163  3463 solver.cpp:218] Iteration 87900 (7.03404 iter/s, 14.2166s/100 iters), loss = 0.00103974
I0927 18:27:31.445204  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103951 (* 1 = 0.00103951 loss)
I0927 18:27:31.445210  3463 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I0927 18:27:44.953343  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:27:45.522780  3463 solver.cpp:330] Iteration 88000, Testing net (#0)
I0927 18:27:48.872790  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:27:49.012964  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9291
I0927 18:27:49.013001  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296297 (* 1 = 0.296297 loss)
I0927 18:27:49.153600  3463 solver.cpp:218] Iteration 88000 (5.64705 iter/s, 17.7083s/100 iters), loss = 0.00100938
I0927 18:27:49.153630  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100915 (* 1 = 0.00100915 loss)
I0927 18:27:49.153638  3463 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I0927 18:28:03.355522  3463 solver.cpp:218] Iteration 88100 (7.04134 iter/s, 14.2018s/100 iters), loss = 0.00143277
I0927 18:28:03.355553  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00143254 (* 1 = 0.00143254 loss)
I0927 18:28:03.355559  3463 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I0927 18:28:17.567962  3463 solver.cpp:218] Iteration 88200 (7.03612 iter/s, 14.2124s/100 iters), loss = 0.00127473
I0927 18:28:17.568037  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0012745 (* 1 = 0.0012745 loss)
I0927 18:28:17.568044  3463 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I0927 18:28:31.775285  3463 solver.cpp:218] Iteration 88300 (7.03868 iter/s, 14.2072s/100 iters), loss = 0.00138894
I0927 18:28:31.775312  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00138871 (* 1 = 0.00138871 loss)
I0927 18:28:31.775318  3463 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I0927 18:28:45.985394  3463 solver.cpp:218] Iteration 88400 (7.03728 iter/s, 14.21s/100 iters), loss = 0.000843788
I0927 18:28:45.985435  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000843554 (* 1 = 0.000843554 loss)
I0927 18:28:45.985441  3463 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I0927 18:28:59.488087  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:29:00.056596  3463 solver.cpp:330] Iteration 88500, Testing net (#0)
I0927 18:29:03.408459  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:29:03.548688  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9288
I0927 18:29:03.548725  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296232 (* 1 = 0.296232 loss)
I0927 18:29:03.689509  3463 solver.cpp:218] Iteration 88500 (5.64843 iter/s, 17.704s/100 iters), loss = 0.00138975
I0927 18:29:03.689540  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00138952 (* 1 = 0.00138952 loss)
I0927 18:29:03.689548  3463 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I0927 18:29:17.884717  3463 solver.cpp:218] Iteration 88600 (7.04467 iter/s, 14.1951s/100 iters), loss = 0.00430231
I0927 18:29:17.884747  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00430208 (* 1 = 0.00430208 loss)
I0927 18:29:17.884753  3463 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I0927 18:29:32.087954  3463 solver.cpp:218] Iteration 88700 (7.04068 iter/s, 14.2032s/100 iters), loss = 0.00268009
I0927 18:29:32.088003  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00267986 (* 1 = 0.00267986 loss)
I0927 18:29:32.088011  3463 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I0927 18:29:46.289064  3463 solver.cpp:218] Iteration 88800 (7.04175 iter/s, 14.201s/100 iters), loss = 0.000402353
I0927 18:29:46.289105  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00040212 (* 1 = 0.00040212 loss)
I0927 18:29:46.289111  3463 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I0927 18:30:00.495945  3463 solver.cpp:218] Iteration 88900 (7.03888 iter/s, 14.2068s/100 iters), loss = 0.00132976
I0927 18:30:00.495985  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00132953 (* 1 = 0.00132953 loss)
I0927 18:30:00.495991  3463 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I0927 18:30:13.991641  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:30:14.560802  3463 solver.cpp:330] Iteration 89000, Testing net (#0)
I0927 18:30:17.912565  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:30:18.052664  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9289
I0927 18:30:18.052701  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296931 (* 1 = 0.296931 loss)
I0927 18:30:18.193627  3463 solver.cpp:218] Iteration 89000 (5.65049 iter/s, 17.6976s/100 iters), loss = 0.00145077
I0927 18:30:18.193657  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00145053 (* 1 = 0.00145053 loss)
I0927 18:30:18.193665  3463 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I0927 18:30:32.393072  3463 solver.cpp:218] Iteration 89100 (7.04256 iter/s, 14.1994s/100 iters), loss = 0.00169089
I0927 18:30:32.393102  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00169066 (* 1 = 0.00169066 loss)
I0927 18:30:32.393110  3463 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I0927 18:30:46.592372  3463 solver.cpp:218] Iteration 89200 (7.04263 iter/s, 14.1992s/100 iters), loss = 0.000948795
I0927 18:30:46.592448  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00094856 (* 1 = 0.00094856 loss)
I0927 18:30:46.592455  3463 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I0927 18:31:00.796216  3463 solver.cpp:218] Iteration 89300 (7.04041 iter/s, 14.2037s/100 iters), loss = 0.00123614
I0927 18:31:00.796257  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0012359 (* 1 = 0.0012359 loss)
I0927 18:31:00.796263  3463 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I0927 18:31:14.996618  3463 solver.cpp:218] Iteration 89400 (7.04209 iter/s, 14.2003s/100 iters), loss = 0.000482632
I0927 18:31:14.996659  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000482397 (* 1 = 0.000482397 loss)
I0927 18:31:14.996665  3463 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I0927 18:31:28.490146  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:31:29.058419  3463 solver.cpp:330] Iteration 89500, Testing net (#0)
I0927 18:31:32.408349  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:31:32.548744  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9291
I0927 18:31:32.548782  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296103 (* 1 = 0.296103 loss)
I0927 18:31:32.689200  3463 solver.cpp:218] Iteration 89500 (5.65211 iter/s, 17.6925s/100 iters), loss = 0.00100138
I0927 18:31:32.689230  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100115 (* 1 = 0.00100115 loss)
I0927 18:31:32.689237  3463 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I0927 18:31:46.895401  3463 solver.cpp:218] Iteration 89600 (7.03921 iter/s, 14.2061s/100 iters), loss = 0.00212828
I0927 18:31:46.895442  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00212804 (* 1 = 0.00212804 loss)
I0927 18:31:46.895448  3463 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I0927 18:32:01.097335  3463 solver.cpp:218] Iteration 89700 (7.04134 iter/s, 14.2019s/100 iters), loss = 0.00119224
I0927 18:32:01.097435  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.001192 (* 1 = 0.001192 loss)
I0927 18:32:01.097442  3463 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I0927 18:32:15.295086  3463 solver.cpp:218] Iteration 89800 (7.04344 iter/s, 14.1976s/100 iters), loss = 0.00327386
I0927 18:32:15.295116  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00327362 (* 1 = 0.00327362 loss)
I0927 18:32:15.295122  3463 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I0927 18:32:29.494949  3463 solver.cpp:218] Iteration 89900 (7.04236 iter/s, 14.1998s/100 iters), loss = 0.000752973
I0927 18:32:29.494990  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000752731 (* 1 = 0.000752731 loss)
I0927 18:32:29.494997  3463 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I0927 18:32:42.991344  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:32:43.559522  3463 solver.cpp:330] Iteration 90000, Testing net (#0)
I0927 18:32:46.909768  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:32:47.049583  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9296
I0927 18:32:47.049620  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295694 (* 1 = 0.295694 loss)
I0927 18:32:47.190932  3463 solver.cpp:218] Iteration 90000 (5.65103 iter/s, 17.6959s/100 iters), loss = 0.00325513
I0927 18:32:47.190961  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00325488 (* 1 = 0.00325488 loss)
I0927 18:32:47.190968  3463 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I0927 18:33:01.394999  3463 solver.cpp:218] Iteration 90100 (7.04027 iter/s, 14.204s/100 iters), loss = 0.0020236
I0927 18:33:01.395040  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00202336 (* 1 = 0.00202336 loss)
I0927 18:33:01.395045  3463 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I0927 18:33:15.603893  3463 solver.cpp:218] Iteration 90200 (7.03788 iter/s, 14.2088s/100 iters), loss = 0.000438342
I0927 18:33:15.604022  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000438102 (* 1 = 0.000438102 loss)
I0927 18:33:15.604029  3463 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I0927 18:33:29.809227  3463 solver.cpp:218] Iteration 90300 (7.03969 iter/s, 14.2052s/100 iters), loss = 0.00133292
I0927 18:33:29.809269  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00133268 (* 1 = 0.00133268 loss)
I0927 18:33:29.809275  3463 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I0927 18:33:44.017066  3463 solver.cpp:218] Iteration 90400 (7.03841 iter/s, 14.2078s/100 iters), loss = 0.00273309
I0927 18:33:44.017107  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00273285 (* 1 = 0.00273285 loss)
I0927 18:33:44.017113  3463 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I0927 18:33:57.519984  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:33:58.088798  3463 solver.cpp:330] Iteration 90500, Testing net (#0)
I0927 18:34:01.441282  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:34:01.581245  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9297
I0927 18:34:01.581281  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.29446 (* 1 = 0.29446 loss)
I0927 18:34:01.721913  3463 solver.cpp:218] Iteration 90500 (5.6482 iter/s, 17.7048s/100 iters), loss = 0.00131143
I0927 18:34:01.721942  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00131119 (* 1 = 0.00131119 loss)
I0927 18:34:01.721949  3463 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I0927 18:34:15.924443  3463 solver.cpp:218] Iteration 90600 (7.04103 iter/s, 14.2025s/100 iters), loss = 0.000648122
I0927 18:34:15.924484  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000647882 (* 1 = 0.000647882 loss)
I0927 18:34:15.924489  3463 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I0927 18:34:30.128880  3463 solver.cpp:218] Iteration 90700 (7.04009 iter/s, 14.2044s/100 iters), loss = 0.000843661
I0927 18:34:30.128940  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000843421 (* 1 = 0.000843421 loss)
I0927 18:34:30.128947  3463 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I0927 18:34:44.331959  3463 solver.cpp:218] Iteration 90800 (7.04077 iter/s, 14.203s/100 iters), loss = 0.00164354
I0927 18:34:44.331989  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00164329 (* 1 = 0.00164329 loss)
I0927 18:34:44.331993  3463 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I0927 18:34:58.533521  3463 solver.cpp:218] Iteration 90900 (7.04152 iter/s, 14.2015s/100 iters), loss = 0.00151255
I0927 18:34:58.533552  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00151231 (* 1 = 0.00151231 loss)
I0927 18:34:58.533558  3463 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I0927 18:35:12.046597  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:35:12.617007  3463 solver.cpp:330] Iteration 91000, Testing net (#0)
I0927 18:35:16.004282  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:35:16.142979  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9299
I0927 18:35:16.143004  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296113 (* 1 = 0.296113 loss)
I0927 18:35:16.281942  3463 solver.cpp:218] Iteration 91000 (5.63433 iter/s, 17.7483s/100 iters), loss = 0.00075678
I0927 18:35:16.281968  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000756536 (* 1 = 0.000756536 loss)
I0927 18:35:16.281975  3463 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I0927 18:35:30.635913  3463 solver.cpp:218] Iteration 91100 (6.96674 iter/s, 14.3539s/100 iters), loss = 0.00354682
I0927 18:35:30.635946  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00354658 (* 1 = 0.00354658 loss)
I0927 18:35:30.635962  3463 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I0927 18:35:44.956861  3463 solver.cpp:218] Iteration 91200 (6.98281 iter/s, 14.3209s/100 iters), loss = 0.000736329
I0927 18:35:44.956969  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000736085 (* 1 = 0.000736085 loss)
I0927 18:35:44.956979  3463 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I0927 18:35:59.276355  3463 solver.cpp:218] Iteration 91300 (6.98356 iter/s, 14.3194s/100 iters), loss = 0.00195266
I0927 18:35:59.276386  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00195241 (* 1 = 0.00195241 loss)
I0927 18:35:59.276391  3463 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I0927 18:36:13.470525  3463 solver.cpp:218] Iteration 91400 (7.04518 iter/s, 14.1941s/100 iters), loss = 0.00081783
I0927 18:36:13.470557  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000817584 (* 1 = 0.000817584 loss)
I0927 18:36:13.470563  3463 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I0927 18:36:26.969952  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:36:27.538173  3463 solver.cpp:330] Iteration 91500, Testing net (#0)
I0927 18:36:30.888846  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:36:31.029039  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9301
I0927 18:36:31.029076  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295379 (* 1 = 0.295379 loss)
I0927 18:36:31.169659  3463 solver.cpp:218] Iteration 91500 (5.65002 iter/s, 17.6991s/100 iters), loss = 0.000982947
I0927 18:36:31.169689  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000982702 (* 1 = 0.000982702 loss)
I0927 18:36:31.169697  3463 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I0927 18:36:45.359151  3463 solver.cpp:218] Iteration 91600 (7.0475 iter/s, 14.1894s/100 iters), loss = 0.00170702
I0927 18:36:45.359194  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00170677 (* 1 = 0.00170677 loss)
I0927 18:36:45.359200  3463 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I0927 18:36:59.558385  3463 solver.cpp:218] Iteration 91700 (7.04267 iter/s, 14.1992s/100 iters), loss = 0.0012059
I0927 18:36:59.558526  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00120566 (* 1 = 0.00120566 loss)
I0927 18:36:59.558534  3463 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I0927 18:37:13.760795  3463 solver.cpp:218] Iteration 91800 (7.04114 iter/s, 14.2022s/100 iters), loss = 0.00060673
I0927 18:37:13.760838  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000606485 (* 1 = 0.000606485 loss)
I0927 18:37:13.760843  3463 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I0927 18:37:27.962715  3463 solver.cpp:218] Iteration 91900 (7.04134 iter/s, 14.2018s/100 iters), loss = 0.00173836
I0927 18:37:27.962759  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00173811 (* 1 = 0.00173811 loss)
I0927 18:37:27.962764  3463 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I0927 18:37:41.450870  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:37:42.019130  3463 solver.cpp:330] Iteration 92000, Testing net (#0)
I0927 18:37:45.369699  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:37:45.509532  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9301
I0927 18:37:45.509569  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296055 (* 1 = 0.296055 loss)
I0927 18:37:45.650876  3463 solver.cpp:218] Iteration 92000 (5.65353 iter/s, 17.6881s/100 iters), loss = 0.00380771
I0927 18:37:45.650904  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00380746 (* 1 = 0.00380746 loss)
I0927 18:37:45.650912  3463 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I0927 18:37:59.843042  3463 solver.cpp:218] Iteration 92100 (7.04617 iter/s, 14.1921s/100 iters), loss = 0.000370606
I0927 18:37:59.843072  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000370363 (* 1 = 0.000370363 loss)
I0927 18:37:59.843078  3463 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I0927 18:38:14.049000  3463 solver.cpp:218] Iteration 92200 (7.03933 iter/s, 14.2059s/100 iters), loss = 0.00252367
I0927 18:38:14.049103  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00252343 (* 1 = 0.00252343 loss)
I0927 18:38:14.049120  3463 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I0927 18:38:28.253551  3463 solver.cpp:218] Iteration 92300 (7.04007 iter/s, 14.2044s/100 iters), loss = 0.000779455
I0927 18:38:28.253592  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000779213 (* 1 = 0.000779213 loss)
I0927 18:38:28.253598  3463 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I0927 18:38:42.456954  3463 solver.cpp:218] Iteration 92400 (7.04061 iter/s, 14.2033s/100 iters), loss = 0.00176337
I0927 18:38:42.456995  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00176313 (* 1 = 0.00176313 loss)
I0927 18:38:42.457000  3463 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I0927 18:38:55.952597  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:38:56.520747  3463 solver.cpp:330] Iteration 92500, Testing net (#0)
I0927 18:38:59.871640  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:39:00.012034  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9297
I0927 18:39:00.012071  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.29562 (* 1 = 0.29562 loss)
I0927 18:39:00.152775  3463 solver.cpp:218] Iteration 92500 (5.65108 iter/s, 17.6957s/100 iters), loss = 0.00127183
I0927 18:39:00.152827  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00127159 (* 1 = 0.00127159 loss)
I0927 18:39:00.152834  3463 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I0927 18:39:14.356456  3463 solver.cpp:218] Iteration 92600 (7.04056 iter/s, 14.2034s/100 iters), loss = 0.00117614
I0927 18:39:14.356497  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0011759 (* 1 = 0.0011759 loss)
I0927 18:39:14.356503  3463 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I0927 18:39:28.571452  3463 solver.cpp:218] Iteration 92700 (7.03486 iter/s, 14.2149s/100 iters), loss = 0.0004334
I0927 18:39:28.571552  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000433161 (* 1 = 0.000433161 loss)
I0927 18:39:28.571558  3463 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I0927 18:39:42.781908  3463 solver.cpp:218] Iteration 92800 (7.03714 iter/s, 14.2103s/100 iters), loss = 0.0042442
I0927 18:39:42.781939  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00424396 (* 1 = 0.00424396 loss)
I0927 18:39:42.781944  3463 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I0927 18:39:56.988916  3463 solver.cpp:218] Iteration 92900 (7.03881 iter/s, 14.2069s/100 iters), loss = 0.000862142
I0927 18:39:56.988957  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000861903 (* 1 = 0.000861903 loss)
I0927 18:39:56.988963  3463 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I0927 18:40:10.493244  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:40:11.062628  3463 solver.cpp:330] Iteration 93000, Testing net (#0)
I0927 18:40:14.414337  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:40:14.554853  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9294
I0927 18:40:14.554891  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295749 (* 1 = 0.295749 loss)
I0927 18:40:14.695487  3463 solver.cpp:218] Iteration 93000 (5.64765 iter/s, 17.7065s/100 iters), loss = 0.00161361
I0927 18:40:14.695516  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00161337 (* 1 = 0.00161337 loss)
I0927 18:40:14.695523  3463 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I0927 18:40:28.895187  3463 solver.cpp:218] Iteration 93100 (7.04243 iter/s, 14.1996s/100 iters), loss = 0.00349343
I0927 18:40:28.895217  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00349319 (* 1 = 0.00349319 loss)
I0927 18:40:28.895223  3463 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I0927 18:40:43.095070  3463 solver.cpp:218] Iteration 93200 (7.04235 iter/s, 14.1998s/100 iters), loss = 0.000728596
I0927 18:40:43.095139  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000728357 (* 1 = 0.000728357 loss)
I0927 18:40:43.095156  3463 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I0927 18:40:57.298678  3463 solver.cpp:218] Iteration 93300 (7.04052 iter/s, 14.2035s/100 iters), loss = 0.000628301
I0927 18:40:57.298720  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000628062 (* 1 = 0.000628062 loss)
I0927 18:40:57.298727  3463 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I0927 18:41:11.500762  3463 solver.cpp:218] Iteration 93400 (7.04126 iter/s, 14.202s/100 iters), loss = 0.00101956
I0927 18:41:11.500804  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00101932 (* 1 = 0.00101932 loss)
I0927 18:41:11.500810  3463 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I0927 18:41:24.991585  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:41:25.560530  3463 solver.cpp:330] Iteration 93500, Testing net (#0)
I0927 18:41:28.911947  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:41:29.052053  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9296
I0927 18:41:29.052079  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.294849 (* 1 = 0.294849 loss)
I0927 18:41:29.192616  3463 solver.cpp:218] Iteration 93500 (5.65235 iter/s, 17.6918s/100 iters), loss = 0.00057059
I0927 18:41:29.192647  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000570351 (* 1 = 0.000570351 loss)
I0927 18:41:29.192654  3463 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I0927 18:41:43.395975  3463 solver.cpp:218] Iteration 93600 (7.04062 iter/s, 14.2033s/100 iters), loss = 0.00539506
I0927 18:41:43.396018  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00539482 (* 1 = 0.00539482 loss)
I0927 18:41:43.396023  3463 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I0927 18:41:57.602885  3463 solver.cpp:218] Iteration 93700 (7.03887 iter/s, 14.2068s/100 iters), loss = 0.00112202
I0927 18:41:57.602936  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00112178 (* 1 = 0.00112178 loss)
I0927 18:41:57.602946  3463 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I0927 18:42:11.809677  3463 solver.cpp:218] Iteration 93800 (7.03893 iter/s, 14.2067s/100 iters), loss = 0.000227084
I0927 18:42:11.809710  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000226845 (* 1 = 0.000226845 loss)
I0927 18:42:11.809725  3463 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I0927 18:42:26.016625  3463 solver.cpp:218] Iteration 93900 (7.03884 iter/s, 14.2069s/100 iters), loss = 0.000443383
I0927 18:42:26.016657  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000443144 (* 1 = 0.000443144 loss)
I0927 18:42:26.016674  3463 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I0927 18:42:39.508522  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:42:40.076571  3463 solver.cpp:330] Iteration 94000, Testing net (#0)
I0927 18:42:43.426370  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:42:43.566320  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9297
I0927 18:42:43.566357  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.29526 (* 1 = 0.29526 loss)
I0927 18:42:43.707461  3463 solver.cpp:218] Iteration 94000 (5.65267 iter/s, 17.6908s/100 iters), loss = 0.000580173
I0927 18:42:43.707499  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000579934 (* 1 = 0.000579934 loss)
I0927 18:42:43.707507  3463 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I0927 18:42:57.906215  3463 solver.cpp:218] Iteration 94100 (7.04291 iter/s, 14.1987s/100 iters), loss = 0.000699843
I0927 18:42:57.906256  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000699605 (* 1 = 0.000699605 loss)
I0927 18:42:57.906262  3463 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I0927 18:43:12.111264  3463 solver.cpp:218] Iteration 94200 (7.03979 iter/s, 14.205s/100 iters), loss = 0.00201241
I0927 18:43:12.111377  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00201218 (* 1 = 0.00201218 loss)
I0927 18:43:12.111384  3463 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I0927 18:43:26.318481  3463 solver.cpp:218] Iteration 94300 (7.03875 iter/s, 14.2071s/100 iters), loss = 0.000579526
I0927 18:43:26.318524  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000579288 (* 1 = 0.000579288 loss)
I0927 18:43:26.318531  3463 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I0927 18:43:40.520025  3463 solver.cpp:218] Iteration 94400 (7.04153 iter/s, 14.2015s/100 iters), loss = 0.000538094
I0927 18:43:40.520066  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000537855 (* 1 = 0.000537855 loss)
I0927 18:43:40.520072  3463 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I0927 18:43:54.015542  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:43:54.585011  3463 solver.cpp:330] Iteration 94500, Testing net (#0)
I0927 18:43:57.936102  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:43:58.076058  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9292
I0927 18:43:58.076095  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295684 (* 1 = 0.295684 loss)
I0927 18:43:58.216531  3463 solver.cpp:218] Iteration 94500 (5.65086 iter/s, 17.6964s/100 iters), loss = 0.000596181
I0927 18:43:58.216560  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000595942 (* 1 = 0.000595942 loss)
I0927 18:43:58.216567  3463 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I0927 18:44:12.416704  3463 solver.cpp:218] Iteration 94600 (7.0422 iter/s, 14.2001s/100 iters), loss = 0.00338771
I0927 18:44:12.416745  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00338747 (* 1 = 0.00338747 loss)
I0927 18:44:12.416751  3463 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I0927 18:44:26.617363  3463 solver.cpp:218] Iteration 94700 (7.04197 iter/s, 14.2006s/100 iters), loss = 0.0012091
I0927 18:44:26.617470  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00120886 (* 1 = 0.00120886 loss)
I0927 18:44:26.617478  3463 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I0927 18:44:40.817414  3463 solver.cpp:218] Iteration 94800 (7.0423 iter/s, 14.1999s/100 iters), loss = 0.00582978
I0927 18:44:40.817445  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00582954 (* 1 = 0.00582954 loss)
I0927 18:44:40.817451  3463 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I0927 18:44:55.015769  3463 solver.cpp:218] Iteration 94900 (7.0431 iter/s, 14.1983s/100 iters), loss = 0.000253142
I0927 18:44:55.015810  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000252903 (* 1 = 0.000252903 loss)
I0927 18:44:55.015816  3463 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I0927 18:45:08.507505  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:45:09.075616  3463 solver.cpp:330] Iteration 95000, Testing net (#0)
I0927 18:45:12.424865  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:45:12.564904  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9286
I0927 18:45:12.564940  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295411 (* 1 = 0.295411 loss)
I0927 18:45:12.705461  3463 solver.cpp:218] Iteration 95000 (5.65304 iter/s, 17.6896s/100 iters), loss = 0.000618168
I0927 18:45:12.705490  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000617928 (* 1 = 0.000617928 loss)
I0927 18:45:12.705497  3463 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I0927 18:45:26.910961  3463 solver.cpp:218] Iteration 95100 (7.03956 iter/s, 14.2054s/100 iters), loss = 0.00401558
I0927 18:45:26.911003  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00401535 (* 1 = 0.00401535 loss)
I0927 18:45:26.911010  3463 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I0927 18:45:41.115468  3463 solver.cpp:218] Iteration 95200 (7.04006 iter/s, 14.2044s/100 iters), loss = 0.00111168
I0927 18:45:41.115542  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00111144 (* 1 = 0.00111144 loss)
I0927 18:45:41.115550  3463 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I0927 18:45:55.324385  3463 solver.cpp:218] Iteration 95300 (7.03789 iter/s, 14.2088s/100 iters), loss = 0.00285397
I0927 18:45:55.324427  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00285373 (* 1 = 0.00285373 loss)
I0927 18:45:55.324434  3463 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I0927 18:46:09.531241  3463 solver.cpp:218] Iteration 95400 (7.03889 iter/s, 14.2068s/100 iters), loss = 0.000866967
I0927 18:46:09.531285  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000866729 (* 1 = 0.000866729 loss)
I0927 18:46:09.531291  3463 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I0927 18:46:23.032814  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:46:23.601091  3463 solver.cpp:330] Iteration 95500, Testing net (#0)
I0927 18:46:26.951578  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:46:27.091258  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9289
I0927 18:46:27.091295  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.29567 (* 1 = 0.29567 loss)
I0927 18:46:27.232295  3463 solver.cpp:218] Iteration 95500 (5.64941 iter/s, 17.701s/100 iters), loss = 0.00121751
I0927 18:46:27.232323  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00121728 (* 1 = 0.00121728 loss)
I0927 18:46:27.232329  3463 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I0927 18:46:41.434914  3463 solver.cpp:218] Iteration 95600 (7.04099 iter/s, 14.2026s/100 iters), loss = 0.000537733
I0927 18:46:41.434965  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000537497 (* 1 = 0.000537497 loss)
I0927 18:46:41.434984  3463 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I0927 18:46:55.642966  3463 solver.cpp:218] Iteration 95700 (7.03831 iter/s, 14.208s/100 iters), loss = 0.000526474
I0927 18:46:55.643040  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000526238 (* 1 = 0.000526238 loss)
I0927 18:46:55.643048  3463 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I0927 18:47:09.848834  3463 solver.cpp:218] Iteration 95800 (7.0394 iter/s, 14.2058s/100 iters), loss = 0.00450346
I0927 18:47:09.848876  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00450322 (* 1 = 0.00450322 loss)
I0927 18:47:09.848882  3463 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I0927 18:47:24.055153  3463 solver.cpp:218] Iteration 95900 (7.03916 iter/s, 14.2062s/100 iters), loss = 0.000559694
I0927 18:47:24.055184  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000559461 (* 1 = 0.000559461 loss)
I0927 18:47:24.055191  3463 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I0927 18:47:37.555368  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:47:38.124644  3463 solver.cpp:330] Iteration 96000, Testing net (#0)
I0927 18:47:41.475893  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:47:41.615978  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9287
I0927 18:47:41.616015  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295945 (* 1 = 0.295945 loss)
I0927 18:47:41.756491  3463 solver.cpp:218] Iteration 96000 (5.64932 iter/s, 17.7013s/100 iters), loss = 0.000344208
I0927 18:47:41.756523  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000343975 (* 1 = 0.000343975 loss)
I0927 18:47:41.756531  3463 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I0927 18:47:55.959491  3463 solver.cpp:218] Iteration 96100 (7.0408 iter/s, 14.2029s/100 iters), loss = 0.00484001
I0927 18:47:55.959532  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00483978 (* 1 = 0.00483978 loss)
I0927 18:47:55.959537  3463 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I0927 18:48:10.166970  3463 solver.cpp:218] Iteration 96200 (7.03859 iter/s, 14.2074s/100 iters), loss = 0.00198995
I0927 18:48:10.167045  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00198972 (* 1 = 0.00198972 loss)
I0927 18:48:10.167053  3463 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I0927 18:48:24.373347  3463 solver.cpp:218] Iteration 96300 (7.03915 iter/s, 14.2063s/100 iters), loss = 0.000557472
I0927 18:48:24.373378  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000557239 (* 1 = 0.000557239 loss)
I0927 18:48:24.373384  3463 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I0927 18:48:38.580886  3463 solver.cpp:218] Iteration 96400 (7.03855 iter/s, 14.2075s/100 iters), loss = 0.00063488
I0927 18:48:38.580917  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000634648 (* 1 = 0.000634648 loss)
I0927 18:48:38.580924  3463 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I0927 18:48:52.081712  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:48:52.650769  3463 solver.cpp:330] Iteration 96500, Testing net (#0)
I0927 18:48:56.003259  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:48:56.142660  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.929
I0927 18:48:56.142699  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295581 (* 1 = 0.295581 loss)
I0927 18:48:56.283510  3463 solver.cpp:218] Iteration 96500 (5.64891 iter/s, 17.7025s/100 iters), loss = 0.00145753
I0927 18:48:56.283540  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00145729 (* 1 = 0.00145729 loss)
I0927 18:48:56.283547  3463 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I0927 18:49:10.479545  3463 solver.cpp:218] Iteration 96600 (7.04425 iter/s, 14.196s/100 iters), loss = 0.000463223
I0927 18:49:10.479588  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00046299 (* 1 = 0.00046299 loss)
I0927 18:49:10.479593  3463 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I0927 18:49:24.681160  3463 solver.cpp:218] Iteration 96700 (7.04149 iter/s, 14.2015s/100 iters), loss = 0.00107407
I0927 18:49:24.681289  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00107383 (* 1 = 0.00107383 loss)
I0927 18:49:24.681296  3463 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I0927 18:49:38.878546  3463 solver.cpp:218] Iteration 96800 (7.04363 iter/s, 14.1972s/100 iters), loss = 0.000563095
I0927 18:49:38.878588  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000562862 (* 1 = 0.000562862 loss)
I0927 18:49:38.878594  3463 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I0927 18:49:53.077571  3463 solver.cpp:218] Iteration 96900 (7.04278 iter/s, 14.1989s/100 iters), loss = 0.00141754
I0927 18:49:53.077602  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00141731 (* 1 = 0.00141731 loss)
I0927 18:49:53.077607  3463 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I0927 18:50:06.575151  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:50:07.143999  3463 solver.cpp:330] Iteration 97000, Testing net (#0)
I0927 18:50:10.495872  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:50:10.635965  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9293
I0927 18:50:10.636003  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295984 (* 1 = 0.295984 loss)
I0927 18:50:10.776628  3463 solver.cpp:218] Iteration 97000 (5.65004 iter/s, 17.699s/100 iters), loss = 0.00129437
I0927 18:50:10.776657  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00129414 (* 1 = 0.00129414 loss)
I0927 18:50:10.776664  3463 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I0927 18:50:24.975728  3463 solver.cpp:218] Iteration 97100 (7.04273 iter/s, 14.199s/100 iters), loss = 0.000363318
I0927 18:50:24.975759  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000363083 (* 1 = 0.000363083 loss)
I0927 18:50:24.975769  3463 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I0927 18:50:39.172508  3463 solver.cpp:218] Iteration 97200 (7.04389 iter/s, 14.1967s/100 iters), loss = 0.00053665
I0927 18:50:39.172569  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000536416 (* 1 = 0.000536416 loss)
I0927 18:50:39.172588  3463 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I0927 18:50:53.374681  3463 solver.cpp:218] Iteration 97300 (7.04122 iter/s, 14.2021s/100 iters), loss = 0.000781621
I0927 18:50:53.374713  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000781386 (* 1 = 0.000781386 loss)
I0927 18:50:53.374722  3463 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I0927 18:51:07.574157  3463 solver.cpp:218] Iteration 97400 (7.04255 iter/s, 14.1994s/100 iters), loss = 0.00149202
I0927 18:51:07.574188  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00149178 (* 1 = 0.00149178 loss)
I0927 18:51:07.574205  3463 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I0927 18:51:21.075614  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:51:21.644191  3463 solver.cpp:330] Iteration 97500, Testing net (#0)
I0927 18:51:24.994369  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:51:25.134306  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9291
I0927 18:51:25.134331  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.29679 (* 1 = 0.29679 loss)
I0927 18:51:25.274878  3463 solver.cpp:218] Iteration 97500 (5.64951 iter/s, 17.7006s/100 iters), loss = 0.00500662
I0927 18:51:25.274907  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00500639 (* 1 = 0.00500639 loss)
I0927 18:51:25.274914  3463 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I0927 18:51:39.478688  3463 solver.cpp:218] Iteration 97600 (7.0404 iter/s, 14.2037s/100 iters), loss = 0.00191879
I0927 18:51:39.478729  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00191856 (* 1 = 0.00191856 loss)
I0927 18:51:39.478735  3463 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I0927 18:51:53.689589  3463 solver.cpp:218] Iteration 97700 (7.03689 iter/s, 14.2108s/100 iters), loss = 0.00081122
I0927 18:51:53.689693  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000810985 (* 1 = 0.000810985 loss)
I0927 18:51:53.689700  3463 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I0927 18:52:07.897449  3463 solver.cpp:218] Iteration 97800 (7.03843 iter/s, 14.2077s/100 iters), loss = 0.000836182
I0927 18:52:07.897480  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000835947 (* 1 = 0.000835947 loss)
I0927 18:52:07.897485  3463 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I0927 18:52:22.106609  3463 solver.cpp:218] Iteration 97900 (7.03775 iter/s, 14.2091s/100 iters), loss = 0.00109635
I0927 18:52:22.106640  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00109612 (* 1 = 0.00109612 loss)
I0927 18:52:22.106647  3463 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I0927 18:52:35.607475  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:52:36.174918  3463 solver.cpp:330] Iteration 98000, Testing net (#0)
I0927 18:52:39.526705  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:52:39.666831  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9292
I0927 18:52:39.666858  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296547 (* 1 = 0.296547 loss)
I0927 18:52:39.807493  3463 solver.cpp:218] Iteration 98000 (5.64946 iter/s, 17.7008s/100 iters), loss = 0.000867166
I0927 18:52:39.807523  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000866932 (* 1 = 0.000866932 loss)
I0927 18:52:39.807529  3463 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I0927 18:52:54.007131  3463 solver.cpp:218] Iteration 98100 (7.04247 iter/s, 14.1996s/100 iters), loss = 0.00430991
I0927 18:52:54.007172  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00430968 (* 1 = 0.00430968 loss)
I0927 18:52:54.007179  3463 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I0927 18:53:08.205879  3463 solver.cpp:218] Iteration 98200 (7.04291 iter/s, 14.1987s/100 iters), loss = 0.00138598
I0927 18:53:08.205955  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00138575 (* 1 = 0.00138575 loss)
I0927 18:53:08.205962  3463 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I0927 18:53:22.406147  3463 solver.cpp:218] Iteration 98300 (7.04218 iter/s, 14.2002s/100 iters), loss = 0.000402756
I0927 18:53:22.406188  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000402521 (* 1 = 0.000402521 loss)
I0927 18:53:22.406194  3463 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I0927 18:53:36.612249  3463 solver.cpp:218] Iteration 98400 (7.03927 iter/s, 14.206s/100 iters), loss = 0.0024583
I0927 18:53:36.612279  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00245807 (* 1 = 0.00245807 loss)
I0927 18:53:36.612285  3463 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I0927 18:53:50.110198  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:53:50.679021  3463 solver.cpp:330] Iteration 98500, Testing net (#0)
I0927 18:53:54.029989  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:53:54.170379  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9291
I0927 18:53:54.170405  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295672 (* 1 = 0.295672 loss)
I0927 18:53:54.311702  3463 solver.cpp:218] Iteration 98500 (5.64992 iter/s, 17.6994s/100 iters), loss = 0.00204313
I0927 18:53:54.311733  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00204289 (* 1 = 0.00204289 loss)
I0927 18:53:54.311740  3463 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I0927 18:54:08.512738  3463 solver.cpp:218] Iteration 98600 (7.04177 iter/s, 14.201s/100 iters), loss = 0.00158705
I0927 18:54:08.512769  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00158681 (* 1 = 0.00158681 loss)
I0927 18:54:08.512775  3463 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I0927 18:54:22.714869  3463 solver.cpp:218] Iteration 98700 (7.04123 iter/s, 14.2021s/100 iters), loss = 0.000967716
I0927 18:54:22.714969  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000967478 (* 1 = 0.000967478 loss)
I0927 18:54:22.714977  3463 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I0927 18:54:36.910774  3463 solver.cpp:218] Iteration 98800 (7.04435 iter/s, 14.1958s/100 iters), loss = 0.000440505
I0927 18:54:36.910815  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000440268 (* 1 = 0.000440268 loss)
I0927 18:54:36.910820  3463 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I0927 18:54:51.106307  3463 solver.cpp:218] Iteration 98900 (7.04451 iter/s, 14.1955s/100 iters), loss = 0.000262439
I0927 18:54:51.106349  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000262202 (* 1 = 0.000262202 loss)
I0927 18:54:51.106354  3463 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I0927 18:55:04.670694  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:55:05.240936  3463 solver.cpp:330] Iteration 99000, Testing net (#0)
I0927 18:55:08.616572  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:55:08.755182  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9294
I0927 18:55:08.755208  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295962 (* 1 = 0.295962 loss)
I0927 18:55:08.894822  3463 solver.cpp:218] Iteration 99000 (5.62163 iter/s, 17.7884s/100 iters), loss = 0.00073848
I0927 18:55:08.894861  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000738243 (* 1 = 0.000738243 loss)
I0927 18:55:08.894868  3463 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I0927 18:55:23.142150  3463 solver.cpp:218] Iteration 99100 (7.0189 iter/s, 14.2473s/100 iters), loss = 0.00091261
I0927 18:55:23.142180  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000912373 (* 1 = 0.000912373 loss)
I0927 18:55:23.142186  3463 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I0927 18:55:37.342227  3463 solver.cpp:218] Iteration 99200 (7.04225 iter/s, 14.2s/100 iters), loss = 0.000573604
I0927 18:55:37.342329  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000573366 (* 1 = 0.000573366 loss)
I0927 18:55:37.342337  3463 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I0927 18:55:51.548773  3463 solver.cpp:218] Iteration 99300 (7.03907 iter/s, 14.2064s/100 iters), loss = 0.00219297
I0927 18:55:51.548813  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00219273 (* 1 = 0.00219273 loss)
I0927 18:55:51.548820  3463 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I0927 18:56:05.757576  3463 solver.cpp:218] Iteration 99400 (7.03793 iter/s, 14.2087s/100 iters), loss = 0.000713642
I0927 18:56:05.757617  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000713404 (* 1 = 0.000713404 loss)
I0927 18:56:05.757623  3463 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I0927 18:56:19.258903  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:56:19.829360  3463 solver.cpp:330] Iteration 99500, Testing net (#0)
I0927 18:56:23.181043  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:56:23.320802  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9292
I0927 18:56:23.320839  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296731 (* 1 = 0.296731 loss)
I0927 18:56:23.461951  3463 solver.cpp:218] Iteration 99500 (5.64835 iter/s, 17.7043s/100 iters), loss = 0.000754287
I0927 18:56:23.461979  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00075405 (* 1 = 0.00075405 loss)
I0927 18:56:23.461987  3463 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I0927 18:56:37.679770  3463 solver.cpp:218] Iteration 99600 (7.03346 iter/s, 14.2178s/100 iters), loss = 0.00182965
I0927 18:56:37.679811  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00182941 (* 1 = 0.00182941 loss)
I0927 18:56:37.679816  3463 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I0927 18:56:51.901082  3463 solver.cpp:218] Iteration 99700 (7.03174 iter/s, 14.2212s/100 iters), loss = 0.000705883
I0927 18:56:51.901178  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000705647 (* 1 = 0.000705647 loss)
I0927 18:56:51.901185  3463 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I0927 18:57:06.124624  3463 solver.cpp:218] Iteration 99800 (7.03067 iter/s, 14.2234s/100 iters), loss = 0.000289586
I0927 18:57:06.124655  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00028935 (* 1 = 0.00028935 loss)
I0927 18:57:06.124660  3463 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I0927 18:57:20.344027  3463 solver.cpp:218] Iteration 99900 (7.03268 iter/s, 14.2193s/100 iters), loss = 0.000824569
I0927 18:57:20.344069  3463 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000824332 (* 1 = 0.000824332 loss)
I0927 18:57:20.344074  3463 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I0927 18:57:33.857094  3472 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:57:34.426242  3463 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res56_mpelu_alpha0.25_eta1_2decay_gauss_iter_100000.caffemodel
I0927 18:57:34.451705  3463 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res56_mpelu_alpha0.25_eta1_2decay_gauss_iter_100000.solverstate
I0927 18:57:34.492256  3463 solver.cpp:310] Iteration 100000, loss = 0.000641225
I0927 18:57:34.492278  3463 solver.cpp:330] Iteration 100000, Testing net (#0)
I0927 18:57:37.841009  3473 data_layer.cpp:73] Restarting data prefetching from start.
I0927 18:57:37.981182  3463 solver.cpp:397]     Test net output #0: Accuracy1 = 0.929
I0927 18:57:37.981218  3463 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296975 (* 1 = 0.296975 loss)
I0927 18:57:37.981223  3463 solver.cpp:315] Optimization Done.
I0927 18:57:37.981226  3463 caffe.cpp:259] Optimization Done.
