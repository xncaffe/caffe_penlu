I0926 14:52:16.333274  4911 caffe.cpp:218] Using GPUs 0
I0926 14:52:16.361747  4911 caffe.cpp:223] GPU 0: GeForce GTX 1080
I0926 14:52:16.590456  4911 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.001
display: 100
max_iter: 30000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 30000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res56_penlu_alpha2w_eta1w_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res56_penlu_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 10000
stepvalue: 20000
I0926 14:52:16.590610  4911 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56_penlu_train_test.prototxt
I0926 14:52:16.594516  4911 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56_penlu_train_test.prototxt
I0926 14:52:16.594529  4911 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0926 14:52:16.594820  4911 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I0926 14:52:16.594955  4911 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I0926 14:52:16.596146  4911 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu20"
  type: "PENLU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu21"
  type: "PENLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu22"
  type: "PENLU"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std
I0926 14:52:16.597175  4911 layer_factory.hpp:77] Creating layer Data1
I0926 14:52:16.597250  4911 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I0926 14:52:16.597268  4911 net.cpp:84] Creating Layer Data1
I0926 14:52:16.597275  4911 net.cpp:380] Data1 -> Data1
I0926 14:52:16.597290  4911 net.cpp:380] Data1 -> Data2
I0926 14:52:16.597298  4911 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0926 14:52:16.598670  4911 data_layer.cpp:45] output data size: 100,3,28,28
I0926 14:52:16.600953  4911 net.cpp:122] Setting up Data1
I0926 14:52:16.600968  4911 net.cpp:129] Top shape: 100 3 28 28 (235200)
I0926 14:52:16.600972  4911 net.cpp:129] Top shape: 100 (100)
I0926 14:52:16.600975  4911 net.cpp:137] Memory required for data: 941200
I0926 14:52:16.600980  4911 layer_factory.hpp:77] Creating layer Convolution1
I0926 14:52:16.600998  4911 net.cpp:84] Creating Layer Convolution1
I0926 14:52:16.601003  4911 net.cpp:406] Convolution1 <- Data1
I0926 14:52:16.601012  4911 net.cpp:380] Convolution1 -> Convolution1
I0926 14:52:16.747198  4911 net.cpp:122] Setting up Convolution1
I0926 14:52:16.747222  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.747225  4911 net.cpp:137] Memory required for data: 5958800
I0926 14:52:16.747241  4911 layer_factory.hpp:77] Creating layer BatchNorm1
I0926 14:52:16.747262  4911 net.cpp:84] Creating Layer BatchNorm1
I0926 14:52:16.747265  4911 net.cpp:406] BatchNorm1 <- Convolution1
I0926 14:52:16.747303  4911 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0926 14:52:16.747457  4911 net.cpp:122] Setting up BatchNorm1
I0926 14:52:16.747462  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.747465  4911 net.cpp:137] Memory required for data: 10976400
I0926 14:52:16.747473  4911 layer_factory.hpp:77] Creating layer Scale1
I0926 14:52:16.747483  4911 net.cpp:84] Creating Layer Scale1
I0926 14:52:16.747484  4911 net.cpp:406] Scale1 <- Convolution1
I0926 14:52:16.747489  4911 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0926 14:52:16.747539  4911 layer_factory.hpp:77] Creating layer Scale1
I0926 14:52:16.747617  4911 net.cpp:122] Setting up Scale1
I0926 14:52:16.747622  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.747625  4911 net.cpp:137] Memory required for data: 15994000
I0926 14:52:16.747629  4911 layer_factory.hpp:77] Creating layer penlu1
I0926 14:52:16.747635  4911 net.cpp:84] Creating Layer penlu1
I0926 14:52:16.747638  4911 net.cpp:406] penlu1 <- Convolution1
I0926 14:52:16.747642  4911 net.cpp:367] penlu1 -> Convolution1 (in-place)
I0926 14:52:16.748268  4911 net.cpp:122] Setting up penlu1
I0926 14:52:16.748281  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.748286  4911 net.cpp:137] Memory required for data: 21011600
I0926 14:52:16.748309  4911 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I0926 14:52:16.748335  4911 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I0926 14:52:16.748338  4911 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I0926 14:52:16.748342  4911 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I0926 14:52:16.748348  4911 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I0926 14:52:16.748383  4911 net.cpp:122] Setting up Convolution1_penlu1_0_split
I0926 14:52:16.748397  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.748400  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.748402  4911 net.cpp:137] Memory required for data: 31046800
I0926 14:52:16.748405  4911 layer_factory.hpp:77] Creating layer Convolution2
I0926 14:52:16.748422  4911 net.cpp:84] Creating Layer Convolution2
I0926 14:52:16.748425  4911 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I0926 14:52:16.748440  4911 net.cpp:380] Convolution2 -> Convolution2
I0926 14:52:16.749296  4911 net.cpp:122] Setting up Convolution2
I0926 14:52:16.749306  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.749310  4911 net.cpp:137] Memory required for data: 36064400
I0926 14:52:16.749315  4911 layer_factory.hpp:77] Creating layer BatchNorm2
I0926 14:52:16.749320  4911 net.cpp:84] Creating Layer BatchNorm2
I0926 14:52:16.749321  4911 net.cpp:406] BatchNorm2 <- Convolution2
I0926 14:52:16.749325  4911 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0926 14:52:16.749457  4911 net.cpp:122] Setting up BatchNorm2
I0926 14:52:16.749464  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.749465  4911 net.cpp:137] Memory required for data: 41082000
I0926 14:52:16.749470  4911 layer_factory.hpp:77] Creating layer Scale2
I0926 14:52:16.749475  4911 net.cpp:84] Creating Layer Scale2
I0926 14:52:16.749477  4911 net.cpp:406] Scale2 <- Convolution2
I0926 14:52:16.749480  4911 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0926 14:52:16.749524  4911 layer_factory.hpp:77] Creating layer Scale2
I0926 14:52:16.749639  4911 net.cpp:122] Setting up Scale2
I0926 14:52:16.749644  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.749646  4911 net.cpp:137] Memory required for data: 46099600
I0926 14:52:16.749652  4911 layer_factory.hpp:77] Creating layer penlu2
I0926 14:52:16.749657  4911 net.cpp:84] Creating Layer penlu2
I0926 14:52:16.749660  4911 net.cpp:406] penlu2 <- Convolution2
I0926 14:52:16.749672  4911 net.cpp:367] penlu2 -> Convolution2 (in-place)
I0926 14:52:16.749774  4911 net.cpp:122] Setting up penlu2
I0926 14:52:16.749779  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.749789  4911 net.cpp:137] Memory required for data: 51117200
I0926 14:52:16.749794  4911 layer_factory.hpp:77] Creating layer Convolution3
I0926 14:52:16.749810  4911 net.cpp:84] Creating Layer Convolution3
I0926 14:52:16.749814  4911 net.cpp:406] Convolution3 <- Convolution2
I0926 14:52:16.749817  4911 net.cpp:380] Convolution3 -> Convolution3
I0926 14:52:16.750635  4911 net.cpp:122] Setting up Convolution3
I0926 14:52:16.750645  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.750648  4911 net.cpp:137] Memory required for data: 56134800
I0926 14:52:16.750653  4911 layer_factory.hpp:77] Creating layer BatchNorm3
I0926 14:52:16.750658  4911 net.cpp:84] Creating Layer BatchNorm3
I0926 14:52:16.750660  4911 net.cpp:406] BatchNorm3 <- Convolution3
I0926 14:52:16.750674  4911 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0926 14:52:16.750798  4911 net.cpp:122] Setting up BatchNorm3
I0926 14:52:16.750804  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.750807  4911 net.cpp:137] Memory required for data: 61152400
I0926 14:52:16.750811  4911 layer_factory.hpp:77] Creating layer Scale3
I0926 14:52:16.750815  4911 net.cpp:84] Creating Layer Scale3
I0926 14:52:16.750818  4911 net.cpp:406] Scale3 <- Convolution3
I0926 14:52:16.750821  4911 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0926 14:52:16.750864  4911 layer_factory.hpp:77] Creating layer Scale3
I0926 14:52:16.750955  4911 net.cpp:122] Setting up Scale3
I0926 14:52:16.750960  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.750962  4911 net.cpp:137] Memory required for data: 66170000
I0926 14:52:16.750967  4911 layer_factory.hpp:77] Creating layer Eltwise1
I0926 14:52:16.750970  4911 net.cpp:84] Creating Layer Eltwise1
I0926 14:52:16.750973  4911 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I0926 14:52:16.750975  4911 net.cpp:406] Eltwise1 <- Convolution3
I0926 14:52:16.750991  4911 net.cpp:380] Eltwise1 -> Eltwise1
I0926 14:52:16.751019  4911 net.cpp:122] Setting up Eltwise1
I0926 14:52:16.751024  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.751026  4911 net.cpp:137] Memory required for data: 71187600
I0926 14:52:16.751029  4911 layer_factory.hpp:77] Creating layer penlu3
I0926 14:52:16.751034  4911 net.cpp:84] Creating Layer penlu3
I0926 14:52:16.751035  4911 net.cpp:406] penlu3 <- Eltwise1
I0926 14:52:16.751039  4911 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I0926 14:52:16.751155  4911 net.cpp:122] Setting up penlu3
I0926 14:52:16.751160  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.751163  4911 net.cpp:137] Memory required for data: 76205200
I0926 14:52:16.751168  4911 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I0926 14:52:16.751170  4911 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I0926 14:52:16.751173  4911 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I0926 14:52:16.751176  4911 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I0926 14:52:16.751190  4911 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I0926 14:52:16.751220  4911 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I0926 14:52:16.751225  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.751229  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.751230  4911 net.cpp:137] Memory required for data: 86240400
I0926 14:52:16.751232  4911 layer_factory.hpp:77] Creating layer Convolution4
I0926 14:52:16.751240  4911 net.cpp:84] Creating Layer Convolution4
I0926 14:52:16.751242  4911 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I0926 14:52:16.751245  4911 net.cpp:380] Convolution4 -> Convolution4
I0926 14:52:16.752079  4911 net.cpp:122] Setting up Convolution4
I0926 14:52:16.752089  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.752092  4911 net.cpp:137] Memory required for data: 91258000
I0926 14:52:16.752096  4911 layer_factory.hpp:77] Creating layer BatchNorm4
I0926 14:52:16.752101  4911 net.cpp:84] Creating Layer BatchNorm4
I0926 14:52:16.752111  4911 net.cpp:406] BatchNorm4 <- Convolution4
I0926 14:52:16.752116  4911 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0926 14:52:16.752231  4911 net.cpp:122] Setting up BatchNorm4
I0926 14:52:16.752238  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.752239  4911 net.cpp:137] Memory required for data: 96275600
I0926 14:52:16.752248  4911 layer_factory.hpp:77] Creating layer Scale4
I0926 14:52:16.752252  4911 net.cpp:84] Creating Layer Scale4
I0926 14:52:16.752254  4911 net.cpp:406] Scale4 <- Convolution4
I0926 14:52:16.752257  4911 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0926 14:52:16.752281  4911 layer_factory.hpp:77] Creating layer Scale4
I0926 14:52:16.752352  4911 net.cpp:122] Setting up Scale4
I0926 14:52:16.752357  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.752359  4911 net.cpp:137] Memory required for data: 101293200
I0926 14:52:16.752363  4911 layer_factory.hpp:77] Creating layer penlu4
I0926 14:52:16.752369  4911 net.cpp:84] Creating Layer penlu4
I0926 14:52:16.752372  4911 net.cpp:406] penlu4 <- Convolution4
I0926 14:52:16.752375  4911 net.cpp:367] penlu4 -> Convolution4 (in-place)
I0926 14:52:16.752466  4911 net.cpp:122] Setting up penlu4
I0926 14:52:16.752472  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.752475  4911 net.cpp:137] Memory required for data: 106310800
I0926 14:52:16.752478  4911 layer_factory.hpp:77] Creating layer Convolution5
I0926 14:52:16.752485  4911 net.cpp:84] Creating Layer Convolution5
I0926 14:52:16.752488  4911 net.cpp:406] Convolution5 <- Convolution4
I0926 14:52:16.752492  4911 net.cpp:380] Convolution5 -> Convolution5
I0926 14:52:16.753355  4911 net.cpp:122] Setting up Convolution5
I0926 14:52:16.753365  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.753368  4911 net.cpp:137] Memory required for data: 111328400
I0926 14:52:16.753372  4911 layer_factory.hpp:77] Creating layer BatchNorm5
I0926 14:52:16.753378  4911 net.cpp:84] Creating Layer BatchNorm5
I0926 14:52:16.753382  4911 net.cpp:406] BatchNorm5 <- Convolution5
I0926 14:52:16.753386  4911 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0926 14:52:16.753505  4911 net.cpp:122] Setting up BatchNorm5
I0926 14:52:16.753511  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.753513  4911 net.cpp:137] Memory required for data: 116346000
I0926 14:52:16.753518  4911 layer_factory.hpp:77] Creating layer Scale5
I0926 14:52:16.753523  4911 net.cpp:84] Creating Layer Scale5
I0926 14:52:16.753526  4911 net.cpp:406] Scale5 <- Convolution5
I0926 14:52:16.753530  4911 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0926 14:52:16.753554  4911 layer_factory.hpp:77] Creating layer Scale5
I0926 14:52:16.753626  4911 net.cpp:122] Setting up Scale5
I0926 14:52:16.753631  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.753633  4911 net.cpp:137] Memory required for data: 121363600
I0926 14:52:16.753638  4911 layer_factory.hpp:77] Creating layer Eltwise2
I0926 14:52:16.753643  4911 net.cpp:84] Creating Layer Eltwise2
I0926 14:52:16.753645  4911 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I0926 14:52:16.753648  4911 net.cpp:406] Eltwise2 <- Convolution5
I0926 14:52:16.753651  4911 net.cpp:380] Eltwise2 -> Eltwise2
I0926 14:52:16.753666  4911 net.cpp:122] Setting up Eltwise2
I0926 14:52:16.753670  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.753674  4911 net.cpp:137] Memory required for data: 126381200
I0926 14:52:16.753675  4911 layer_factory.hpp:77] Creating layer penlu5
I0926 14:52:16.753681  4911 net.cpp:84] Creating Layer penlu5
I0926 14:52:16.753684  4911 net.cpp:406] penlu5 <- Eltwise2
I0926 14:52:16.753687  4911 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I0926 14:52:16.753783  4911 net.cpp:122] Setting up penlu5
I0926 14:52:16.753788  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.753790  4911 net.cpp:137] Memory required for data: 131398800
I0926 14:52:16.753795  4911 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I0926 14:52:16.753799  4911 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I0926 14:52:16.753808  4911 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I0926 14:52:16.753813  4911 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I0926 14:52:16.753816  4911 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I0926 14:52:16.753839  4911 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I0926 14:52:16.753844  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.753846  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.753849  4911 net.cpp:137] Memory required for data: 141434000
I0926 14:52:16.753850  4911 layer_factory.hpp:77] Creating layer Convolution6
I0926 14:52:16.753856  4911 net.cpp:84] Creating Layer Convolution6
I0926 14:52:16.753860  4911 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I0926 14:52:16.753864  4911 net.cpp:380] Convolution6 -> Convolution6
I0926 14:52:16.754705  4911 net.cpp:122] Setting up Convolution6
I0926 14:52:16.754715  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.754719  4911 net.cpp:137] Memory required for data: 146451600
I0926 14:52:16.754724  4911 layer_factory.hpp:77] Creating layer BatchNorm6
I0926 14:52:16.754729  4911 net.cpp:84] Creating Layer BatchNorm6
I0926 14:52:16.754732  4911 net.cpp:406] BatchNorm6 <- Convolution6
I0926 14:52:16.754736  4911 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0926 14:52:16.754858  4911 net.cpp:122] Setting up BatchNorm6
I0926 14:52:16.754863  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.754866  4911 net.cpp:137] Memory required for data: 151469200
I0926 14:52:16.754871  4911 layer_factory.hpp:77] Creating layer Scale6
I0926 14:52:16.754878  4911 net.cpp:84] Creating Layer Scale6
I0926 14:52:16.754881  4911 net.cpp:406] Scale6 <- Convolution6
I0926 14:52:16.754884  4911 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0926 14:52:16.754909  4911 layer_factory.hpp:77] Creating layer Scale6
I0926 14:52:16.754981  4911 net.cpp:122] Setting up Scale6
I0926 14:52:16.754987  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.754989  4911 net.cpp:137] Memory required for data: 156486800
I0926 14:52:16.754992  4911 layer_factory.hpp:77] Creating layer penlu6
I0926 14:52:16.754999  4911 net.cpp:84] Creating Layer penlu6
I0926 14:52:16.755002  4911 net.cpp:406] penlu6 <- Convolution6
I0926 14:52:16.755007  4911 net.cpp:367] penlu6 -> Convolution6 (in-place)
I0926 14:52:16.755105  4911 net.cpp:122] Setting up penlu6
I0926 14:52:16.755110  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.755112  4911 net.cpp:137] Memory required for data: 161504400
I0926 14:52:16.755117  4911 layer_factory.hpp:77] Creating layer Convolution7
I0926 14:52:16.755125  4911 net.cpp:84] Creating Layer Convolution7
I0926 14:52:16.755127  4911 net.cpp:406] Convolution7 <- Convolution6
I0926 14:52:16.755131  4911 net.cpp:380] Convolution7 -> Convolution7
I0926 14:52:16.755653  4911 net.cpp:122] Setting up Convolution7
I0926 14:52:16.755662  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.755666  4911 net.cpp:137] Memory required for data: 166522000
I0926 14:52:16.755669  4911 layer_factory.hpp:77] Creating layer BatchNorm7
I0926 14:52:16.755676  4911 net.cpp:84] Creating Layer BatchNorm7
I0926 14:52:16.755678  4911 net.cpp:406] BatchNorm7 <- Convolution7
I0926 14:52:16.755681  4911 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0926 14:52:16.755803  4911 net.cpp:122] Setting up BatchNorm7
I0926 14:52:16.755808  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.755810  4911 net.cpp:137] Memory required for data: 171539600
I0926 14:52:16.755820  4911 layer_factory.hpp:77] Creating layer Scale7
I0926 14:52:16.755827  4911 net.cpp:84] Creating Layer Scale7
I0926 14:52:16.755831  4911 net.cpp:406] Scale7 <- Convolution7
I0926 14:52:16.755833  4911 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0926 14:52:16.755858  4911 layer_factory.hpp:77] Creating layer Scale7
I0926 14:52:16.755929  4911 net.cpp:122] Setting up Scale7
I0926 14:52:16.755941  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.755945  4911 net.cpp:137] Memory required for data: 176557200
I0926 14:52:16.755949  4911 layer_factory.hpp:77] Creating layer Eltwise3
I0926 14:52:16.755954  4911 net.cpp:84] Creating Layer Eltwise3
I0926 14:52:16.755956  4911 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I0926 14:52:16.755959  4911 net.cpp:406] Eltwise3 <- Convolution7
I0926 14:52:16.755964  4911 net.cpp:380] Eltwise3 -> Eltwise3
I0926 14:52:16.755978  4911 net.cpp:122] Setting up Eltwise3
I0926 14:52:16.755983  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.755985  4911 net.cpp:137] Memory required for data: 181574800
I0926 14:52:16.755987  4911 layer_factory.hpp:77] Creating layer penlu7
I0926 14:52:16.755992  4911 net.cpp:84] Creating Layer penlu7
I0926 14:52:16.755995  4911 net.cpp:406] penlu7 <- Eltwise3
I0926 14:52:16.756000  4911 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I0926 14:52:16.756103  4911 net.cpp:122] Setting up penlu7
I0926 14:52:16.756108  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.756110  4911 net.cpp:137] Memory required for data: 186592400
I0926 14:52:16.756115  4911 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I0926 14:52:16.756120  4911 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I0926 14:52:16.756122  4911 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I0926 14:52:16.756125  4911 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I0926 14:52:16.756129  4911 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I0926 14:52:16.756151  4911 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I0926 14:52:16.756155  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.756158  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.756160  4911 net.cpp:137] Memory required for data: 196627600
I0926 14:52:16.756162  4911 layer_factory.hpp:77] Creating layer Convolution8
I0926 14:52:16.756168  4911 net.cpp:84] Creating Layer Convolution8
I0926 14:52:16.756171  4911 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I0926 14:52:16.756176  4911 net.cpp:380] Convolution8 -> Convolution8
I0926 14:52:16.757035  4911 net.cpp:122] Setting up Convolution8
I0926 14:52:16.757045  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.757047  4911 net.cpp:137] Memory required for data: 201645200
I0926 14:52:16.757052  4911 layer_factory.hpp:77] Creating layer BatchNorm8
I0926 14:52:16.757058  4911 net.cpp:84] Creating Layer BatchNorm8
I0926 14:52:16.757062  4911 net.cpp:406] BatchNorm8 <- Convolution8
I0926 14:52:16.757066  4911 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0926 14:52:16.757186  4911 net.cpp:122] Setting up BatchNorm8
I0926 14:52:16.757191  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.757194  4911 net.cpp:137] Memory required for data: 206662800
I0926 14:52:16.757199  4911 layer_factory.hpp:77] Creating layer Scale8
I0926 14:52:16.757203  4911 net.cpp:84] Creating Layer Scale8
I0926 14:52:16.757206  4911 net.cpp:406] Scale8 <- Convolution8
I0926 14:52:16.757210  4911 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0926 14:52:16.757236  4911 layer_factory.hpp:77] Creating layer Scale8
I0926 14:52:16.757308  4911 net.cpp:122] Setting up Scale8
I0926 14:52:16.757313  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.757318  4911 net.cpp:137] Memory required for data: 211680400
I0926 14:52:16.757321  4911 layer_factory.hpp:77] Creating layer penlu8
I0926 14:52:16.757325  4911 net.cpp:84] Creating Layer penlu8
I0926 14:52:16.757328  4911 net.cpp:406] penlu8 <- Convolution8
I0926 14:52:16.757333  4911 net.cpp:367] penlu8 -> Convolution8 (in-place)
I0926 14:52:16.757448  4911 net.cpp:122] Setting up penlu8
I0926 14:52:16.757455  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.757458  4911 net.cpp:137] Memory required for data: 216698000
I0926 14:52:16.757467  4911 layer_factory.hpp:77] Creating layer Convolution9
I0926 14:52:16.757477  4911 net.cpp:84] Creating Layer Convolution9
I0926 14:52:16.757488  4911 net.cpp:406] Convolution9 <- Convolution8
I0926 14:52:16.757493  4911 net.cpp:380] Convolution9 -> Convolution9
I0926 14:52:16.758360  4911 net.cpp:122] Setting up Convolution9
I0926 14:52:16.758370  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.758373  4911 net.cpp:137] Memory required for data: 221715600
I0926 14:52:16.758378  4911 layer_factory.hpp:77] Creating layer BatchNorm9
I0926 14:52:16.758385  4911 net.cpp:84] Creating Layer BatchNorm9
I0926 14:52:16.758388  4911 net.cpp:406] BatchNorm9 <- Convolution9
I0926 14:52:16.758393  4911 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0926 14:52:16.758518  4911 net.cpp:122] Setting up BatchNorm9
I0926 14:52:16.758524  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.758527  4911 net.cpp:137] Memory required for data: 226733200
I0926 14:52:16.758543  4911 layer_factory.hpp:77] Creating layer Scale9
I0926 14:52:16.758555  4911 net.cpp:84] Creating Layer Scale9
I0926 14:52:16.758558  4911 net.cpp:406] Scale9 <- Convolution9
I0926 14:52:16.758561  4911 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0926 14:52:16.758606  4911 layer_factory.hpp:77] Creating layer Scale9
I0926 14:52:16.758723  4911 net.cpp:122] Setting up Scale9
I0926 14:52:16.758729  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.758741  4911 net.cpp:137] Memory required for data: 231750800
I0926 14:52:16.758746  4911 layer_factory.hpp:77] Creating layer Eltwise4
I0926 14:52:16.758750  4911 net.cpp:84] Creating Layer Eltwise4
I0926 14:52:16.758752  4911 net.cpp:406] Eltwise4 <- Eltwise3_penlu7_0_split_1
I0926 14:52:16.758756  4911 net.cpp:406] Eltwise4 <- Convolution9
I0926 14:52:16.758761  4911 net.cpp:380] Eltwise4 -> Eltwise4
I0926 14:52:16.758777  4911 net.cpp:122] Setting up Eltwise4
I0926 14:52:16.758791  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.758793  4911 net.cpp:137] Memory required for data: 236768400
I0926 14:52:16.758795  4911 layer_factory.hpp:77] Creating layer penlu9
I0926 14:52:16.758811  4911 net.cpp:84] Creating Layer penlu9
I0926 14:52:16.758813  4911 net.cpp:406] penlu9 <- Eltwise4
I0926 14:52:16.758817  4911 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I0926 14:52:16.758944  4911 net.cpp:122] Setting up penlu9
I0926 14:52:16.758951  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.758955  4911 net.cpp:137] Memory required for data: 241786000
I0926 14:52:16.758963  4911 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I0926 14:52:16.758970  4911 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I0926 14:52:16.758975  4911 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I0926 14:52:16.758983  4911 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I0926 14:52:16.758991  4911 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I0926 14:52:16.759021  4911 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I0926 14:52:16.759027  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.759033  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.759037  4911 net.cpp:137] Memory required for data: 251821200
I0926 14:52:16.759052  4911 layer_factory.hpp:77] Creating layer Convolution10
I0926 14:52:16.759075  4911 net.cpp:84] Creating Layer Convolution10
I0926 14:52:16.759081  4911 net.cpp:406] Convolution10 <- Eltwise4_penlu9_0_split_0
I0926 14:52:16.759086  4911 net.cpp:380] Convolution10 -> Convolution10
I0926 14:52:16.759989  4911 net.cpp:122] Setting up Convolution10
I0926 14:52:16.759999  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.760002  4911 net.cpp:137] Memory required for data: 256838800
I0926 14:52:16.760006  4911 layer_factory.hpp:77] Creating layer BatchNorm10
I0926 14:52:16.760012  4911 net.cpp:84] Creating Layer BatchNorm10
I0926 14:52:16.760016  4911 net.cpp:406] BatchNorm10 <- Convolution10
I0926 14:52:16.760020  4911 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0926 14:52:16.760150  4911 net.cpp:122] Setting up BatchNorm10
I0926 14:52:16.760164  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.760166  4911 net.cpp:137] Memory required for data: 261856400
I0926 14:52:16.760172  4911 layer_factory.hpp:77] Creating layer Scale10
I0926 14:52:16.760177  4911 net.cpp:84] Creating Layer Scale10
I0926 14:52:16.760180  4911 net.cpp:406] Scale10 <- Convolution10
I0926 14:52:16.760185  4911 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0926 14:52:16.760212  4911 layer_factory.hpp:77] Creating layer Scale10
I0926 14:52:16.760290  4911 net.cpp:122] Setting up Scale10
I0926 14:52:16.760296  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.760298  4911 net.cpp:137] Memory required for data: 266874000
I0926 14:52:16.760303  4911 layer_factory.hpp:77] Creating layer penlu10
I0926 14:52:16.760308  4911 net.cpp:84] Creating Layer penlu10
I0926 14:52:16.760311  4911 net.cpp:406] penlu10 <- Convolution10
I0926 14:52:16.760315  4911 net.cpp:367] penlu10 -> Convolution10 (in-place)
I0926 14:52:16.760433  4911 net.cpp:122] Setting up penlu10
I0926 14:52:16.760439  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.760450  4911 net.cpp:137] Memory required for data: 271891600
I0926 14:52:16.760455  4911 layer_factory.hpp:77] Creating layer Convolution11
I0926 14:52:16.760463  4911 net.cpp:84] Creating Layer Convolution11
I0926 14:52:16.760466  4911 net.cpp:406] Convolution11 <- Convolution10
I0926 14:52:16.760470  4911 net.cpp:380] Convolution11 -> Convolution11
I0926 14:52:16.761471  4911 net.cpp:122] Setting up Convolution11
I0926 14:52:16.761492  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.761495  4911 net.cpp:137] Memory required for data: 276909200
I0926 14:52:16.761499  4911 layer_factory.hpp:77] Creating layer BatchNorm11
I0926 14:52:16.761505  4911 net.cpp:84] Creating Layer BatchNorm11
I0926 14:52:16.761508  4911 net.cpp:406] BatchNorm11 <- Convolution11
I0926 14:52:16.761513  4911 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0926 14:52:16.761647  4911 net.cpp:122] Setting up BatchNorm11
I0926 14:52:16.761653  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.761664  4911 net.cpp:137] Memory required for data: 281926800
I0926 14:52:16.761669  4911 layer_factory.hpp:77] Creating layer Scale11
I0926 14:52:16.761674  4911 net.cpp:84] Creating Layer Scale11
I0926 14:52:16.761677  4911 net.cpp:406] Scale11 <- Convolution11
I0926 14:52:16.761682  4911 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0926 14:52:16.761716  4911 layer_factory.hpp:77] Creating layer Scale11
I0926 14:52:16.761811  4911 net.cpp:122] Setting up Scale11
I0926 14:52:16.761816  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.761828  4911 net.cpp:137] Memory required for data: 286944400
I0926 14:52:16.761832  4911 layer_factory.hpp:77] Creating layer Eltwise5
I0926 14:52:16.761837  4911 net.cpp:84] Creating Layer Eltwise5
I0926 14:52:16.761839  4911 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I0926 14:52:16.761842  4911 net.cpp:406] Eltwise5 <- Convolution11
I0926 14:52:16.761847  4911 net.cpp:380] Eltwise5 -> Eltwise5
I0926 14:52:16.761863  4911 net.cpp:122] Setting up Eltwise5
I0926 14:52:16.761878  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.761879  4911 net.cpp:137] Memory required for data: 291962000
I0926 14:52:16.761881  4911 layer_factory.hpp:77] Creating layer penlu11
I0926 14:52:16.761896  4911 net.cpp:84] Creating Layer penlu11
I0926 14:52:16.761899  4911 net.cpp:406] penlu11 <- Eltwise5
I0926 14:52:16.761903  4911 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I0926 14:52:16.762010  4911 net.cpp:122] Setting up penlu11
I0926 14:52:16.762017  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.762019  4911 net.cpp:137] Memory required for data: 296979600
I0926 14:52:16.762024  4911 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I0926 14:52:16.762028  4911 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I0926 14:52:16.762032  4911 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I0926 14:52:16.762042  4911 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I0926 14:52:16.762048  4911 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I0926 14:52:16.762071  4911 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I0926 14:52:16.762076  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.762080  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.762082  4911 net.cpp:137] Memory required for data: 307014800
I0926 14:52:16.762084  4911 layer_factory.hpp:77] Creating layer Convolution12
I0926 14:52:16.762092  4911 net.cpp:84] Creating Layer Convolution12
I0926 14:52:16.762095  4911 net.cpp:406] Convolution12 <- Eltwise5_penlu11_0_split_0
I0926 14:52:16.762099  4911 net.cpp:380] Convolution12 -> Convolution12
I0926 14:52:16.762979  4911 net.cpp:122] Setting up Convolution12
I0926 14:52:16.762989  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.762994  4911 net.cpp:137] Memory required for data: 312032400
I0926 14:52:16.762998  4911 layer_factory.hpp:77] Creating layer BatchNorm12
I0926 14:52:16.763005  4911 net.cpp:84] Creating Layer BatchNorm12
I0926 14:52:16.763007  4911 net.cpp:406] BatchNorm12 <- Convolution12
I0926 14:52:16.763012  4911 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0926 14:52:16.763144  4911 net.cpp:122] Setting up BatchNorm12
I0926 14:52:16.763149  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.763151  4911 net.cpp:137] Memory required for data: 317050000
I0926 14:52:16.763156  4911 layer_factory.hpp:77] Creating layer Scale12
I0926 14:52:16.763164  4911 net.cpp:84] Creating Layer Scale12
I0926 14:52:16.763167  4911 net.cpp:406] Scale12 <- Convolution12
I0926 14:52:16.763170  4911 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0926 14:52:16.763197  4911 layer_factory.hpp:77] Creating layer Scale12
I0926 14:52:16.763275  4911 net.cpp:122] Setting up Scale12
I0926 14:52:16.763281  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.763284  4911 net.cpp:137] Memory required for data: 322067600
I0926 14:52:16.763288  4911 layer_factory.hpp:77] Creating layer penlu12
I0926 14:52:16.763294  4911 net.cpp:84] Creating Layer penlu12
I0926 14:52:16.763298  4911 net.cpp:406] penlu12 <- Convolution12
I0926 14:52:16.763303  4911 net.cpp:367] penlu12 -> Convolution12 (in-place)
I0926 14:52:16.763409  4911 net.cpp:122] Setting up penlu12
I0926 14:52:16.763415  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.763418  4911 net.cpp:137] Memory required for data: 327085200
I0926 14:52:16.763422  4911 layer_factory.hpp:77] Creating layer Convolution13
I0926 14:52:16.763430  4911 net.cpp:84] Creating Layer Convolution13
I0926 14:52:16.763433  4911 net.cpp:406] Convolution13 <- Convolution12
I0926 14:52:16.763437  4911 net.cpp:380] Convolution13 -> Convolution13
I0926 14:52:16.764317  4911 net.cpp:122] Setting up Convolution13
I0926 14:52:16.764327  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.764330  4911 net.cpp:137] Memory required for data: 332102800
I0926 14:52:16.764334  4911 layer_factory.hpp:77] Creating layer BatchNorm13
I0926 14:52:16.764340  4911 net.cpp:84] Creating Layer BatchNorm13
I0926 14:52:16.764344  4911 net.cpp:406] BatchNorm13 <- Convolution13
I0926 14:52:16.764348  4911 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0926 14:52:16.764480  4911 net.cpp:122] Setting up BatchNorm13
I0926 14:52:16.764487  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.764489  4911 net.cpp:137] Memory required for data: 337120400
I0926 14:52:16.764513  4911 layer_factory.hpp:77] Creating layer Scale13
I0926 14:52:16.764520  4911 net.cpp:84] Creating Layer Scale13
I0926 14:52:16.764523  4911 net.cpp:406] Scale13 <- Convolution13
I0926 14:52:16.764528  4911 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0926 14:52:16.764564  4911 layer_factory.hpp:77] Creating layer Scale13
I0926 14:52:16.764643  4911 net.cpp:122] Setting up Scale13
I0926 14:52:16.764648  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.764658  4911 net.cpp:137] Memory required for data: 342138000
I0926 14:52:16.764663  4911 layer_factory.hpp:77] Creating layer Eltwise6
I0926 14:52:16.764668  4911 net.cpp:84] Creating Layer Eltwise6
I0926 14:52:16.764672  4911 net.cpp:406] Eltwise6 <- Eltwise5_penlu11_0_split_1
I0926 14:52:16.764675  4911 net.cpp:406] Eltwise6 <- Convolution13
I0926 14:52:16.764679  4911 net.cpp:380] Eltwise6 -> Eltwise6
I0926 14:52:16.764698  4911 net.cpp:122] Setting up Eltwise6
I0926 14:52:16.764703  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.764706  4911 net.cpp:137] Memory required for data: 347155600
I0926 14:52:16.764709  4911 layer_factory.hpp:77] Creating layer penlu13
I0926 14:52:16.764717  4911 net.cpp:84] Creating Layer penlu13
I0926 14:52:16.764721  4911 net.cpp:406] penlu13 <- Eltwise6
I0926 14:52:16.764725  4911 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I0926 14:52:16.764835  4911 net.cpp:122] Setting up penlu13
I0926 14:52:16.764842  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.764844  4911 net.cpp:137] Memory required for data: 352173200
I0926 14:52:16.764858  4911 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I0926 14:52:16.764863  4911 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I0926 14:52:16.764866  4911 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I0926 14:52:16.764869  4911 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I0926 14:52:16.764874  4911 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I0926 14:52:16.764899  4911 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I0926 14:52:16.764904  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.764907  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.764909  4911 net.cpp:137] Memory required for data: 362208400
I0926 14:52:16.764911  4911 layer_factory.hpp:77] Creating layer Convolution14
I0926 14:52:16.764919  4911 net.cpp:84] Creating Layer Convolution14
I0926 14:52:16.764922  4911 net.cpp:406] Convolution14 <- Eltwise6_penlu13_0_split_0
I0926 14:52:16.764926  4911 net.cpp:380] Convolution14 -> Convolution14
I0926 14:52:16.765808  4911 net.cpp:122] Setting up Convolution14
I0926 14:52:16.765817  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.765820  4911 net.cpp:137] Memory required for data: 367226000
I0926 14:52:16.765825  4911 layer_factory.hpp:77] Creating layer BatchNorm14
I0926 14:52:16.765830  4911 net.cpp:84] Creating Layer BatchNorm14
I0926 14:52:16.765832  4911 net.cpp:406] BatchNorm14 <- Convolution14
I0926 14:52:16.765837  4911 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0926 14:52:16.765970  4911 net.cpp:122] Setting up BatchNorm14
I0926 14:52:16.765975  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.765977  4911 net.cpp:137] Memory required for data: 372243600
I0926 14:52:16.765982  4911 layer_factory.hpp:77] Creating layer Scale14
I0926 14:52:16.765987  4911 net.cpp:84] Creating Layer Scale14
I0926 14:52:16.765990  4911 net.cpp:406] Scale14 <- Convolution14
I0926 14:52:16.765992  4911 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0926 14:52:16.766018  4911 layer_factory.hpp:77] Creating layer Scale14
I0926 14:52:16.766095  4911 net.cpp:122] Setting up Scale14
I0926 14:52:16.766099  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.766101  4911 net.cpp:137] Memory required for data: 377261200
I0926 14:52:16.766105  4911 layer_factory.hpp:77] Creating layer penlu14
I0926 14:52:16.766111  4911 net.cpp:84] Creating Layer penlu14
I0926 14:52:16.766113  4911 net.cpp:406] penlu14 <- Convolution14
I0926 14:52:16.766116  4911 net.cpp:367] penlu14 -> Convolution14 (in-place)
I0926 14:52:16.766224  4911 net.cpp:122] Setting up penlu14
I0926 14:52:16.766228  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.766230  4911 net.cpp:137] Memory required for data: 382278800
I0926 14:52:16.766234  4911 layer_factory.hpp:77] Creating layer Convolution15
I0926 14:52:16.766242  4911 net.cpp:84] Creating Layer Convolution15
I0926 14:52:16.766250  4911 net.cpp:406] Convolution15 <- Convolution14
I0926 14:52:16.766254  4911 net.cpp:380] Convolution15 -> Convolution15
I0926 14:52:16.767133  4911 net.cpp:122] Setting up Convolution15
I0926 14:52:16.767141  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.767144  4911 net.cpp:137] Memory required for data: 387296400
I0926 14:52:16.767148  4911 layer_factory.hpp:77] Creating layer BatchNorm15
I0926 14:52:16.767153  4911 net.cpp:84] Creating Layer BatchNorm15
I0926 14:52:16.767156  4911 net.cpp:406] BatchNorm15 <- Convolution15
I0926 14:52:16.767160  4911 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0926 14:52:16.767293  4911 net.cpp:122] Setting up BatchNorm15
I0926 14:52:16.767297  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.767300  4911 net.cpp:137] Memory required for data: 392314000
I0926 14:52:16.767304  4911 layer_factory.hpp:77] Creating layer Scale15
I0926 14:52:16.767309  4911 net.cpp:84] Creating Layer Scale15
I0926 14:52:16.767313  4911 net.cpp:406] Scale15 <- Convolution15
I0926 14:52:16.767315  4911 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0926 14:52:16.767340  4911 layer_factory.hpp:77] Creating layer Scale15
I0926 14:52:16.767418  4911 net.cpp:122] Setting up Scale15
I0926 14:52:16.767423  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.767426  4911 net.cpp:137] Memory required for data: 397331600
I0926 14:52:16.767429  4911 layer_factory.hpp:77] Creating layer Eltwise7
I0926 14:52:16.767433  4911 net.cpp:84] Creating Layer Eltwise7
I0926 14:52:16.767436  4911 net.cpp:406] Eltwise7 <- Eltwise6_penlu13_0_split_1
I0926 14:52:16.767438  4911 net.cpp:406] Eltwise7 <- Convolution15
I0926 14:52:16.767442  4911 net.cpp:380] Eltwise7 -> Eltwise7
I0926 14:52:16.767457  4911 net.cpp:122] Setting up Eltwise7
I0926 14:52:16.767462  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.767463  4911 net.cpp:137] Memory required for data: 402349200
I0926 14:52:16.767465  4911 layer_factory.hpp:77] Creating layer penlu15
I0926 14:52:16.767472  4911 net.cpp:84] Creating Layer penlu15
I0926 14:52:16.767473  4911 net.cpp:406] penlu15 <- Eltwise7
I0926 14:52:16.767477  4911 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I0926 14:52:16.767598  4911 net.cpp:122] Setting up penlu15
I0926 14:52:16.767604  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.767606  4911 net.cpp:137] Memory required for data: 407366800
I0926 14:52:16.767611  4911 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I0926 14:52:16.767614  4911 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I0926 14:52:16.767617  4911 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I0926 14:52:16.767621  4911 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I0926 14:52:16.767624  4911 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I0926 14:52:16.767647  4911 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I0926 14:52:16.767650  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.767653  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.767655  4911 net.cpp:137] Memory required for data: 417402000
I0926 14:52:16.767657  4911 layer_factory.hpp:77] Creating layer Convolution16
I0926 14:52:16.767663  4911 net.cpp:84] Creating Layer Convolution16
I0926 14:52:16.767666  4911 net.cpp:406] Convolution16 <- Eltwise7_penlu15_0_split_0
I0926 14:52:16.767669  4911 net.cpp:380] Convolution16 -> Convolution16
I0926 14:52:16.768573  4911 net.cpp:122] Setting up Convolution16
I0926 14:52:16.768582  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.768585  4911 net.cpp:137] Memory required for data: 422419600
I0926 14:52:16.768589  4911 layer_factory.hpp:77] Creating layer BatchNorm16
I0926 14:52:16.768594  4911 net.cpp:84] Creating Layer BatchNorm16
I0926 14:52:16.768597  4911 net.cpp:406] BatchNorm16 <- Convolution16
I0926 14:52:16.768601  4911 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0926 14:52:16.768733  4911 net.cpp:122] Setting up BatchNorm16
I0926 14:52:16.768744  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.768746  4911 net.cpp:137] Memory required for data: 427437200
I0926 14:52:16.768751  4911 layer_factory.hpp:77] Creating layer Scale16
I0926 14:52:16.768756  4911 net.cpp:84] Creating Layer Scale16
I0926 14:52:16.768759  4911 net.cpp:406] Scale16 <- Convolution16
I0926 14:52:16.768762  4911 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0926 14:52:16.768788  4911 layer_factory.hpp:77] Creating layer Scale16
I0926 14:52:16.768867  4911 net.cpp:122] Setting up Scale16
I0926 14:52:16.768872  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.768873  4911 net.cpp:137] Memory required for data: 432454800
I0926 14:52:16.768877  4911 layer_factory.hpp:77] Creating layer penlu16
I0926 14:52:16.768882  4911 net.cpp:84] Creating Layer penlu16
I0926 14:52:16.768884  4911 net.cpp:406] penlu16 <- Convolution16
I0926 14:52:16.768888  4911 net.cpp:367] penlu16 -> Convolution16 (in-place)
I0926 14:52:16.769001  4911 net.cpp:122] Setting up penlu16
I0926 14:52:16.769006  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.769008  4911 net.cpp:137] Memory required for data: 437472400
I0926 14:52:16.769012  4911 layer_factory.hpp:77] Creating layer Convolution17
I0926 14:52:16.769018  4911 net.cpp:84] Creating Layer Convolution17
I0926 14:52:16.769021  4911 net.cpp:406] Convolution17 <- Convolution16
I0926 14:52:16.769026  4911 net.cpp:380] Convolution17 -> Convolution17
I0926 14:52:16.769588  4911 net.cpp:122] Setting up Convolution17
I0926 14:52:16.769596  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.769598  4911 net.cpp:137] Memory required for data: 442490000
I0926 14:52:16.769603  4911 layer_factory.hpp:77] Creating layer BatchNorm17
I0926 14:52:16.769608  4911 net.cpp:84] Creating Layer BatchNorm17
I0926 14:52:16.769610  4911 net.cpp:406] BatchNorm17 <- Convolution17
I0926 14:52:16.769613  4911 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0926 14:52:16.769744  4911 net.cpp:122] Setting up BatchNorm17
I0926 14:52:16.769748  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.769750  4911 net.cpp:137] Memory required for data: 447507600
I0926 14:52:16.769755  4911 layer_factory.hpp:77] Creating layer Scale17
I0926 14:52:16.769759  4911 net.cpp:84] Creating Layer Scale17
I0926 14:52:16.769762  4911 net.cpp:406] Scale17 <- Convolution17
I0926 14:52:16.769764  4911 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0926 14:52:16.769790  4911 layer_factory.hpp:77] Creating layer Scale17
I0926 14:52:16.769865  4911 net.cpp:122] Setting up Scale17
I0926 14:52:16.769870  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.769872  4911 net.cpp:137] Memory required for data: 452525200
I0926 14:52:16.769876  4911 layer_factory.hpp:77] Creating layer Eltwise8
I0926 14:52:16.769881  4911 net.cpp:84] Creating Layer Eltwise8
I0926 14:52:16.769882  4911 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I0926 14:52:16.769886  4911 net.cpp:406] Eltwise8 <- Convolution17
I0926 14:52:16.769888  4911 net.cpp:380] Eltwise8 -> Eltwise8
I0926 14:52:16.769903  4911 net.cpp:122] Setting up Eltwise8
I0926 14:52:16.769906  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.769908  4911 net.cpp:137] Memory required for data: 457542800
I0926 14:52:16.769911  4911 layer_factory.hpp:77] Creating layer penlu17
I0926 14:52:16.769917  4911 net.cpp:84] Creating Layer penlu17
I0926 14:52:16.769918  4911 net.cpp:406] penlu17 <- Eltwise8
I0926 14:52:16.769922  4911 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I0926 14:52:16.770030  4911 net.cpp:122] Setting up penlu17
I0926 14:52:16.770035  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.770037  4911 net.cpp:137] Memory required for data: 462560400
I0926 14:52:16.770041  4911 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I0926 14:52:16.770045  4911 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I0926 14:52:16.770047  4911 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I0926 14:52:16.770058  4911 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I0926 14:52:16.770062  4911 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I0926 14:52:16.770086  4911 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I0926 14:52:16.770088  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.770092  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.770093  4911 net.cpp:137] Memory required for data: 472595600
I0926 14:52:16.770095  4911 layer_factory.hpp:77] Creating layer Convolution18
I0926 14:52:16.770102  4911 net.cpp:84] Creating Layer Convolution18
I0926 14:52:16.770104  4911 net.cpp:406] Convolution18 <- Eltwise8_penlu17_0_split_0
I0926 14:52:16.770108  4911 net.cpp:380] Convolution18 -> Convolution18
I0926 14:52:16.770994  4911 net.cpp:122] Setting up Convolution18
I0926 14:52:16.771003  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.771005  4911 net.cpp:137] Memory required for data: 477613200
I0926 14:52:16.771010  4911 layer_factory.hpp:77] Creating layer BatchNorm18
I0926 14:52:16.771015  4911 net.cpp:84] Creating Layer BatchNorm18
I0926 14:52:16.771018  4911 net.cpp:406] BatchNorm18 <- Convolution18
I0926 14:52:16.771021  4911 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0926 14:52:16.771152  4911 net.cpp:122] Setting up BatchNorm18
I0926 14:52:16.771157  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.771158  4911 net.cpp:137] Memory required for data: 482630800
I0926 14:52:16.771163  4911 layer_factory.hpp:77] Creating layer Scale18
I0926 14:52:16.771167  4911 net.cpp:84] Creating Layer Scale18
I0926 14:52:16.771170  4911 net.cpp:406] Scale18 <- Convolution18
I0926 14:52:16.771173  4911 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0926 14:52:16.771200  4911 layer_factory.hpp:77] Creating layer Scale18
I0926 14:52:16.771280  4911 net.cpp:122] Setting up Scale18
I0926 14:52:16.771283  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.771286  4911 net.cpp:137] Memory required for data: 487648400
I0926 14:52:16.771289  4911 layer_factory.hpp:77] Creating layer penlu18
I0926 14:52:16.771296  4911 net.cpp:84] Creating Layer penlu18
I0926 14:52:16.771297  4911 net.cpp:406] penlu18 <- Convolution18
I0926 14:52:16.771301  4911 net.cpp:367] penlu18 -> Convolution18 (in-place)
I0926 14:52:16.771409  4911 net.cpp:122] Setting up penlu18
I0926 14:52:16.771414  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.771415  4911 net.cpp:137] Memory required for data: 492666000
I0926 14:52:16.771420  4911 layer_factory.hpp:77] Creating layer Convolution19
I0926 14:52:16.771426  4911 net.cpp:84] Creating Layer Convolution19
I0926 14:52:16.771428  4911 net.cpp:406] Convolution19 <- Convolution18
I0926 14:52:16.771432  4911 net.cpp:380] Convolution19 -> Convolution19
I0926 14:52:16.772325  4911 net.cpp:122] Setting up Convolution19
I0926 14:52:16.772333  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.772336  4911 net.cpp:137] Memory required for data: 497683600
I0926 14:52:16.772341  4911 layer_factory.hpp:77] Creating layer BatchNorm19
I0926 14:52:16.772346  4911 net.cpp:84] Creating Layer BatchNorm19
I0926 14:52:16.772348  4911 net.cpp:406] BatchNorm19 <- Convolution19
I0926 14:52:16.772352  4911 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0926 14:52:16.772483  4911 net.cpp:122] Setting up BatchNorm19
I0926 14:52:16.772488  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.772490  4911 net.cpp:137] Memory required for data: 502701200
I0926 14:52:16.772511  4911 layer_factory.hpp:77] Creating layer Scale19
I0926 14:52:16.772516  4911 net.cpp:84] Creating Layer Scale19
I0926 14:52:16.772519  4911 net.cpp:406] Scale19 <- Convolution19
I0926 14:52:16.772522  4911 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0926 14:52:16.772560  4911 layer_factory.hpp:77] Creating layer Scale19
I0926 14:52:16.772639  4911 net.cpp:122] Setting up Scale19
I0926 14:52:16.772642  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.772644  4911 net.cpp:137] Memory required for data: 507718800
I0926 14:52:16.772655  4911 layer_factory.hpp:77] Creating layer Eltwise9
I0926 14:52:16.772660  4911 net.cpp:84] Creating Layer Eltwise9
I0926 14:52:16.772662  4911 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I0926 14:52:16.772665  4911 net.cpp:406] Eltwise9 <- Convolution19
I0926 14:52:16.772670  4911 net.cpp:380] Eltwise9 -> Eltwise9
I0926 14:52:16.772686  4911 net.cpp:122] Setting up Eltwise9
I0926 14:52:16.772689  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.772691  4911 net.cpp:137] Memory required for data: 512736400
I0926 14:52:16.772693  4911 layer_factory.hpp:77] Creating layer penlu19
I0926 14:52:16.772698  4911 net.cpp:84] Creating Layer penlu19
I0926 14:52:16.772701  4911 net.cpp:406] penlu19 <- Eltwise9
I0926 14:52:16.772704  4911 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I0926 14:52:16.772812  4911 net.cpp:122] Setting up penlu19
I0926 14:52:16.772817  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.772819  4911 net.cpp:137] Memory required for data: 517754000
I0926 14:52:16.772824  4911 layer_factory.hpp:77] Creating layer Eltwise9_penlu19_0_split
I0926 14:52:16.772827  4911 net.cpp:84] Creating Layer Eltwise9_penlu19_0_split
I0926 14:52:16.772830  4911 net.cpp:406] Eltwise9_penlu19_0_split <- Eltwise9
I0926 14:52:16.772835  4911 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_0
I0926 14:52:16.772838  4911 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_1
I0926 14:52:16.772861  4911 net.cpp:122] Setting up Eltwise9_penlu19_0_split
I0926 14:52:16.772864  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.772867  4911 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 14:52:16.772869  4911 net.cpp:137] Memory required for data: 527789200
I0926 14:52:16.772871  4911 layer_factory.hpp:77] Creating layer Convolution20
I0926 14:52:16.772878  4911 net.cpp:84] Creating Layer Convolution20
I0926 14:52:16.772881  4911 net.cpp:406] Convolution20 <- Eltwise9_penlu19_0_split_0
I0926 14:52:16.772884  4911 net.cpp:380] Convolution20 -> Convolution20
I0926 14:52:16.774080  4911 net.cpp:122] Setting up Convolution20
I0926 14:52:16.774089  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.774092  4911 net.cpp:137] Memory required for data: 530298000
I0926 14:52:16.774096  4911 layer_factory.hpp:77] Creating layer BatchNorm20
I0926 14:52:16.774101  4911 net.cpp:84] Creating Layer BatchNorm20
I0926 14:52:16.774103  4911 net.cpp:406] BatchNorm20 <- Convolution20
I0926 14:52:16.774108  4911 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0926 14:52:16.774250  4911 net.cpp:122] Setting up BatchNorm20
I0926 14:52:16.774255  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.774256  4911 net.cpp:137] Memory required for data: 532806800
I0926 14:52:16.774261  4911 layer_factory.hpp:77] Creating layer Scale20
I0926 14:52:16.774266  4911 net.cpp:84] Creating Layer Scale20
I0926 14:52:16.774268  4911 net.cpp:406] Scale20 <- Convolution20
I0926 14:52:16.774272  4911 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0926 14:52:16.774297  4911 layer_factory.hpp:77] Creating layer Scale20
I0926 14:52:16.774372  4911 net.cpp:122] Setting up Scale20
I0926 14:52:16.774377  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.774379  4911 net.cpp:137] Memory required for data: 535315600
I0926 14:52:16.774384  4911 layer_factory.hpp:77] Creating layer Convolution21
I0926 14:52:16.774389  4911 net.cpp:84] Creating Layer Convolution21
I0926 14:52:16.774391  4911 net.cpp:406] Convolution21 <- Eltwise9_penlu19_0_split_1
I0926 14:52:16.774396  4911 net.cpp:380] Convolution21 -> Convolution21
I0926 14:52:16.776114  4911 net.cpp:122] Setting up Convolution21
I0926 14:52:16.776124  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.776126  4911 net.cpp:137] Memory required for data: 537824400
I0926 14:52:16.776130  4911 layer_factory.hpp:77] Creating layer BatchNorm21
I0926 14:52:16.776136  4911 net.cpp:84] Creating Layer BatchNorm21
I0926 14:52:16.776144  4911 net.cpp:406] BatchNorm21 <- Convolution21
I0926 14:52:16.776149  4911 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0926 14:52:16.776286  4911 net.cpp:122] Setting up BatchNorm21
I0926 14:52:16.776291  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.776293  4911 net.cpp:137] Memory required for data: 540333200
I0926 14:52:16.776298  4911 layer_factory.hpp:77] Creating layer Scale21
I0926 14:52:16.776304  4911 net.cpp:84] Creating Layer Scale21
I0926 14:52:16.776305  4911 net.cpp:406] Scale21 <- Convolution21
I0926 14:52:16.776309  4911 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0926 14:52:16.776336  4911 layer_factory.hpp:77] Creating layer Scale21
I0926 14:52:16.776437  4911 net.cpp:122] Setting up Scale21
I0926 14:52:16.776443  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.776445  4911 net.cpp:137] Memory required for data: 542842000
I0926 14:52:16.776449  4911 layer_factory.hpp:77] Creating layer penlu20
I0926 14:52:16.776455  4911 net.cpp:84] Creating Layer penlu20
I0926 14:52:16.776458  4911 net.cpp:406] penlu20 <- Convolution21
I0926 14:52:16.776471  4911 net.cpp:367] penlu20 -> Convolution21 (in-place)
I0926 14:52:16.776623  4911 net.cpp:122] Setting up penlu20
I0926 14:52:16.776629  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.776631  4911 net.cpp:137] Memory required for data: 545350800
I0926 14:52:16.776635  4911 layer_factory.hpp:77] Creating layer Convolution22
I0926 14:52:16.776643  4911 net.cpp:84] Creating Layer Convolution22
I0926 14:52:16.776644  4911 net.cpp:406] Convolution22 <- Convolution21
I0926 14:52:16.776648  4911 net.cpp:380] Convolution22 -> Convolution22
I0926 14:52:16.777722  4911 net.cpp:122] Setting up Convolution22
I0926 14:52:16.777731  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.777734  4911 net.cpp:137] Memory required for data: 547859600
I0926 14:52:16.777739  4911 layer_factory.hpp:77] Creating layer BatchNorm22
I0926 14:52:16.777743  4911 net.cpp:84] Creating Layer BatchNorm22
I0926 14:52:16.777745  4911 net.cpp:406] BatchNorm22 <- Convolution22
I0926 14:52:16.777750  4911 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0926 14:52:16.777880  4911 net.cpp:122] Setting up BatchNorm22
I0926 14:52:16.777885  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.777887  4911 net.cpp:137] Memory required for data: 550368400
I0926 14:52:16.777892  4911 layer_factory.hpp:77] Creating layer Scale22
I0926 14:52:16.777895  4911 net.cpp:84] Creating Layer Scale22
I0926 14:52:16.777899  4911 net.cpp:406] Scale22 <- Convolution22
I0926 14:52:16.777902  4911 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0926 14:52:16.777927  4911 layer_factory.hpp:77] Creating layer Scale22
I0926 14:52:16.778002  4911 net.cpp:122] Setting up Scale22
I0926 14:52:16.778005  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.778007  4911 net.cpp:137] Memory required for data: 552877200
I0926 14:52:16.778012  4911 layer_factory.hpp:77] Creating layer Eltwise10
I0926 14:52:16.778015  4911 net.cpp:84] Creating Layer Eltwise10
I0926 14:52:16.778017  4911 net.cpp:406] Eltwise10 <- Convolution20
I0926 14:52:16.778020  4911 net.cpp:406] Eltwise10 <- Convolution22
I0926 14:52:16.778024  4911 net.cpp:380] Eltwise10 -> Eltwise10
I0926 14:52:16.778039  4911 net.cpp:122] Setting up Eltwise10
I0926 14:52:16.778043  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.778045  4911 net.cpp:137] Memory required for data: 555386000
I0926 14:52:16.778048  4911 layer_factory.hpp:77] Creating layer penlu21
I0926 14:52:16.778051  4911 net.cpp:84] Creating Layer penlu21
I0926 14:52:16.778054  4911 net.cpp:406] penlu21 <- Eltwise10
I0926 14:52:16.778059  4911 net.cpp:367] penlu21 -> Eltwise10 (in-place)
I0926 14:52:16.778164  4911 net.cpp:122] Setting up penlu21
I0926 14:52:16.778168  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.778170  4911 net.cpp:137] Memory required for data: 557894800
I0926 14:52:16.778175  4911 layer_factory.hpp:77] Creating layer Eltwise10_penlu21_0_split
I0926 14:52:16.778187  4911 net.cpp:84] Creating Layer Eltwise10_penlu21_0_split
I0926 14:52:16.778188  4911 net.cpp:406] Eltwise10_penlu21_0_split <- Eltwise10
I0926 14:52:16.778192  4911 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_0
I0926 14:52:16.778197  4911 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_1
I0926 14:52:16.778219  4911 net.cpp:122] Setting up Eltwise10_penlu21_0_split
I0926 14:52:16.778223  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.778226  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.778228  4911 net.cpp:137] Memory required for data: 562912400
I0926 14:52:16.778230  4911 layer_factory.hpp:77] Creating layer Convolution23
I0926 14:52:16.778236  4911 net.cpp:84] Creating Layer Convolution23
I0926 14:52:16.778239  4911 net.cpp:406] Convolution23 <- Eltwise10_penlu21_0_split_0
I0926 14:52:16.778242  4911 net.cpp:380] Convolution23 -> Convolution23
I0926 14:52:16.779559  4911 net.cpp:122] Setting up Convolution23
I0926 14:52:16.779568  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.779570  4911 net.cpp:137] Memory required for data: 565421200
I0926 14:52:16.779575  4911 layer_factory.hpp:77] Creating layer BatchNorm23
I0926 14:52:16.779580  4911 net.cpp:84] Creating Layer BatchNorm23
I0926 14:52:16.779582  4911 net.cpp:406] BatchNorm23 <- Convolution23
I0926 14:52:16.779587  4911 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0926 14:52:16.779721  4911 net.cpp:122] Setting up BatchNorm23
I0926 14:52:16.779726  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.779727  4911 net.cpp:137] Memory required for data: 567930000
I0926 14:52:16.779732  4911 layer_factory.hpp:77] Creating layer Scale23
I0926 14:52:16.779736  4911 net.cpp:84] Creating Layer Scale23
I0926 14:52:16.779738  4911 net.cpp:406] Scale23 <- Convolution23
I0926 14:52:16.779742  4911 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0926 14:52:16.779769  4911 layer_factory.hpp:77] Creating layer Scale23
I0926 14:52:16.779844  4911 net.cpp:122] Setting up Scale23
I0926 14:52:16.779848  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.779850  4911 net.cpp:137] Memory required for data: 570438800
I0926 14:52:16.779855  4911 layer_factory.hpp:77] Creating layer penlu22
I0926 14:52:16.779860  4911 net.cpp:84] Creating Layer penlu22
I0926 14:52:16.779861  4911 net.cpp:406] penlu22 <- Convolution23
I0926 14:52:16.779865  4911 net.cpp:367] penlu22 -> Convolution23 (in-place)
I0926 14:52:16.779973  4911 net.cpp:122] Setting up penlu22
I0926 14:52:16.779978  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.779979  4911 net.cpp:137] Memory required for data: 572947600
I0926 14:52:16.779983  4911 layer_factory.hpp:77] Creating layer Convolution24
I0926 14:52:16.779989  4911 net.cpp:84] Creating Layer Convolution24
I0926 14:52:16.779992  4911 net.cpp:406] Convolution24 <- Convolution23
I0926 14:52:16.779996  4911 net.cpp:380] Convolution24 -> Convolution24
I0926 14:52:16.781057  4911 net.cpp:122] Setting up Convolution24
I0926 14:52:16.781065  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.781069  4911 net.cpp:137] Memory required for data: 575456400
I0926 14:52:16.781072  4911 layer_factory.hpp:77] Creating layer BatchNorm24
I0926 14:52:16.781078  4911 net.cpp:84] Creating Layer BatchNorm24
I0926 14:52:16.781080  4911 net.cpp:406] BatchNorm24 <- Convolution24
I0926 14:52:16.781085  4911 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0926 14:52:16.781216  4911 net.cpp:122] Setting up BatchNorm24
I0926 14:52:16.781221  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.781224  4911 net.cpp:137] Memory required for data: 577965200
I0926 14:52:16.781227  4911 layer_factory.hpp:77] Creating layer Scale24
I0926 14:52:16.781231  4911 net.cpp:84] Creating Layer Scale24
I0926 14:52:16.781234  4911 net.cpp:406] Scale24 <- Convolution24
I0926 14:52:16.781237  4911 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0926 14:52:16.781270  4911 layer_factory.hpp:77] Creating layer Scale24
I0926 14:52:16.781345  4911 net.cpp:122] Setting up Scale24
I0926 14:52:16.781350  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.781352  4911 net.cpp:137] Memory required for data: 580474000
I0926 14:52:16.781357  4911 layer_factory.hpp:77] Creating layer Eltwise11
I0926 14:52:16.781360  4911 net.cpp:84] Creating Layer Eltwise11
I0926 14:52:16.781363  4911 net.cpp:406] Eltwise11 <- Eltwise10_penlu21_0_split_1
I0926 14:52:16.781365  4911 net.cpp:406] Eltwise11 <- Convolution24
I0926 14:52:16.781369  4911 net.cpp:380] Eltwise11 -> Eltwise11
I0926 14:52:16.781384  4911 net.cpp:122] Setting up Eltwise11
I0926 14:52:16.781388  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.781390  4911 net.cpp:137] Memory required for data: 582982800
I0926 14:52:16.781392  4911 layer_factory.hpp:77] Creating layer penlu23
I0926 14:52:16.781396  4911 net.cpp:84] Creating Layer penlu23
I0926 14:52:16.781399  4911 net.cpp:406] penlu23 <- Eltwise11
I0926 14:52:16.781402  4911 net.cpp:367] penlu23 -> Eltwise11 (in-place)
I0926 14:52:16.781507  4911 net.cpp:122] Setting up penlu23
I0926 14:52:16.781510  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.781512  4911 net.cpp:137] Memory required for data: 585491600
I0926 14:52:16.781517  4911 layer_factory.hpp:77] Creating layer Eltwise11_penlu23_0_split
I0926 14:52:16.781520  4911 net.cpp:84] Creating Layer Eltwise11_penlu23_0_split
I0926 14:52:16.781522  4911 net.cpp:406] Eltwise11_penlu23_0_split <- Eltwise11
I0926 14:52:16.781527  4911 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_0
I0926 14:52:16.781533  4911 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_1
I0926 14:52:16.781554  4911 net.cpp:122] Setting up Eltwise11_penlu23_0_split
I0926 14:52:16.781558  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.781560  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.781563  4911 net.cpp:137] Memory required for data: 590509200
I0926 14:52:16.781564  4911 layer_factory.hpp:77] Creating layer Convolution25
I0926 14:52:16.781570  4911 net.cpp:84] Creating Layer Convolution25
I0926 14:52:16.781574  4911 net.cpp:406] Convolution25 <- Eltwise11_penlu23_0_split_0
I0926 14:52:16.781577  4911 net.cpp:380] Convolution25 -> Convolution25
I0926 14:52:16.782598  4911 net.cpp:122] Setting up Convolution25
I0926 14:52:16.782605  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.782608  4911 net.cpp:137] Memory required for data: 593018000
I0926 14:52:16.782611  4911 layer_factory.hpp:77] Creating layer BatchNorm25
I0926 14:52:16.782616  4911 net.cpp:84] Creating Layer BatchNorm25
I0926 14:52:16.782619  4911 net.cpp:406] BatchNorm25 <- Convolution25
I0926 14:52:16.782624  4911 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0926 14:52:16.782755  4911 net.cpp:122] Setting up BatchNorm25
I0926 14:52:16.782759  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.782762  4911 net.cpp:137] Memory required for data: 595526800
I0926 14:52:16.782766  4911 layer_factory.hpp:77] Creating layer Scale25
I0926 14:52:16.782771  4911 net.cpp:84] Creating Layer Scale25
I0926 14:52:16.782773  4911 net.cpp:406] Scale25 <- Convolution25
I0926 14:52:16.782776  4911 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0926 14:52:16.782802  4911 layer_factory.hpp:77] Creating layer Scale25
I0926 14:52:16.782877  4911 net.cpp:122] Setting up Scale25
I0926 14:52:16.782881  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.782883  4911 net.cpp:137] Memory required for data: 598035600
I0926 14:52:16.782887  4911 layer_factory.hpp:77] Creating layer penlu24
I0926 14:52:16.782892  4911 net.cpp:84] Creating Layer penlu24
I0926 14:52:16.782896  4911 net.cpp:406] penlu24 <- Convolution25
I0926 14:52:16.782898  4911 net.cpp:367] penlu24 -> Convolution25 (in-place)
I0926 14:52:16.783001  4911 net.cpp:122] Setting up penlu24
I0926 14:52:16.783005  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.783013  4911 net.cpp:137] Memory required for data: 600544400
I0926 14:52:16.783018  4911 layer_factory.hpp:77] Creating layer Convolution26
I0926 14:52:16.783025  4911 net.cpp:84] Creating Layer Convolution26
I0926 14:52:16.783027  4911 net.cpp:406] Convolution26 <- Convolution25
I0926 14:52:16.783031  4911 net.cpp:380] Convolution26 -> Convolution26
I0926 14:52:16.784065  4911 net.cpp:122] Setting up Convolution26
I0926 14:52:16.784075  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.784076  4911 net.cpp:137] Memory required for data: 603053200
I0926 14:52:16.784080  4911 layer_factory.hpp:77] Creating layer BatchNorm26
I0926 14:52:16.784086  4911 net.cpp:84] Creating Layer BatchNorm26
I0926 14:52:16.784088  4911 net.cpp:406] BatchNorm26 <- Convolution26
I0926 14:52:16.784092  4911 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0926 14:52:16.784226  4911 net.cpp:122] Setting up BatchNorm26
I0926 14:52:16.784230  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.784234  4911 net.cpp:137] Memory required for data: 605562000
I0926 14:52:16.784237  4911 layer_factory.hpp:77] Creating layer Scale26
I0926 14:52:16.784242  4911 net.cpp:84] Creating Layer Scale26
I0926 14:52:16.784245  4911 net.cpp:406] Scale26 <- Convolution26
I0926 14:52:16.784247  4911 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0926 14:52:16.784273  4911 layer_factory.hpp:77] Creating layer Scale26
I0926 14:52:16.784350  4911 net.cpp:122] Setting up Scale26
I0926 14:52:16.784355  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.784358  4911 net.cpp:137] Memory required for data: 608070800
I0926 14:52:16.784361  4911 layer_factory.hpp:77] Creating layer Eltwise12
I0926 14:52:16.784365  4911 net.cpp:84] Creating Layer Eltwise12
I0926 14:52:16.784368  4911 net.cpp:406] Eltwise12 <- Eltwise11_penlu23_0_split_1
I0926 14:52:16.784371  4911 net.cpp:406] Eltwise12 <- Convolution26
I0926 14:52:16.784374  4911 net.cpp:380] Eltwise12 -> Eltwise12
I0926 14:52:16.784390  4911 net.cpp:122] Setting up Eltwise12
I0926 14:52:16.784394  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.784395  4911 net.cpp:137] Memory required for data: 610579600
I0926 14:52:16.784397  4911 layer_factory.hpp:77] Creating layer penlu25
I0926 14:52:16.784402  4911 net.cpp:84] Creating Layer penlu25
I0926 14:52:16.784405  4911 net.cpp:406] penlu25 <- Eltwise12
I0926 14:52:16.784409  4911 net.cpp:367] penlu25 -> Eltwise12 (in-place)
I0926 14:52:16.784543  4911 net.cpp:122] Setting up penlu25
I0926 14:52:16.784548  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.784549  4911 net.cpp:137] Memory required for data: 613088400
I0926 14:52:16.784581  4911 layer_factory.hpp:77] Creating layer Eltwise12_penlu25_0_split
I0926 14:52:16.784592  4911 net.cpp:84] Creating Layer Eltwise12_penlu25_0_split
I0926 14:52:16.784595  4911 net.cpp:406] Eltwise12_penlu25_0_split <- Eltwise12
I0926 14:52:16.784598  4911 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_0
I0926 14:52:16.784606  4911 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_1
I0926 14:52:16.784631  4911 net.cpp:122] Setting up Eltwise12_penlu25_0_split
I0926 14:52:16.784636  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.784638  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.784641  4911 net.cpp:137] Memory required for data: 618106000
I0926 14:52:16.784643  4911 layer_factory.hpp:77] Creating layer Convolution27
I0926 14:52:16.784649  4911 net.cpp:84] Creating Layer Convolution27
I0926 14:52:16.784651  4911 net.cpp:406] Convolution27 <- Eltwise12_penlu25_0_split_0
I0926 14:52:16.784656  4911 net.cpp:380] Convolution27 -> Convolution27
I0926 14:52:16.785360  4911 net.cpp:122] Setting up Convolution27
I0926 14:52:16.785368  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.785370  4911 net.cpp:137] Memory required for data: 620614800
I0926 14:52:16.785374  4911 layer_factory.hpp:77] Creating layer BatchNorm27
I0926 14:52:16.785379  4911 net.cpp:84] Creating Layer BatchNorm27
I0926 14:52:16.785388  4911 net.cpp:406] BatchNorm27 <- Convolution27
I0926 14:52:16.785392  4911 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0926 14:52:16.785527  4911 net.cpp:122] Setting up BatchNorm27
I0926 14:52:16.785531  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.785533  4911 net.cpp:137] Memory required for data: 623123600
I0926 14:52:16.785538  4911 layer_factory.hpp:77] Creating layer Scale27
I0926 14:52:16.785542  4911 net.cpp:84] Creating Layer Scale27
I0926 14:52:16.785544  4911 net.cpp:406] Scale27 <- Convolution27
I0926 14:52:16.785547  4911 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0926 14:52:16.785574  4911 layer_factory.hpp:77] Creating layer Scale27
I0926 14:52:16.785650  4911 net.cpp:122] Setting up Scale27
I0926 14:52:16.785653  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.785655  4911 net.cpp:137] Memory required for data: 625632400
I0926 14:52:16.785660  4911 layer_factory.hpp:77] Creating layer penlu26
I0926 14:52:16.785665  4911 net.cpp:84] Creating Layer penlu26
I0926 14:52:16.785666  4911 net.cpp:406] penlu26 <- Convolution27
I0926 14:52:16.785670  4911 net.cpp:367] penlu26 -> Convolution27 (in-place)
I0926 14:52:16.785778  4911 net.cpp:122] Setting up penlu26
I0926 14:52:16.785781  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.785784  4911 net.cpp:137] Memory required for data: 628141200
I0926 14:52:16.785789  4911 layer_factory.hpp:77] Creating layer Convolution28
I0926 14:52:16.785795  4911 net.cpp:84] Creating Layer Convolution28
I0926 14:52:16.785797  4911 net.cpp:406] Convolution28 <- Convolution27
I0926 14:52:16.785801  4911 net.cpp:380] Convolution28 -> Convolution28
I0926 14:52:16.786813  4911 net.cpp:122] Setting up Convolution28
I0926 14:52:16.786820  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.786823  4911 net.cpp:137] Memory required for data: 630650000
I0926 14:52:16.786828  4911 layer_factory.hpp:77] Creating layer BatchNorm28
I0926 14:52:16.786833  4911 net.cpp:84] Creating Layer BatchNorm28
I0926 14:52:16.786835  4911 net.cpp:406] BatchNorm28 <- Convolution28
I0926 14:52:16.786839  4911 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0926 14:52:16.786972  4911 net.cpp:122] Setting up BatchNorm28
I0926 14:52:16.786976  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.786978  4911 net.cpp:137] Memory required for data: 633158800
I0926 14:52:16.786983  4911 layer_factory.hpp:77] Creating layer Scale28
I0926 14:52:16.786988  4911 net.cpp:84] Creating Layer Scale28
I0926 14:52:16.786990  4911 net.cpp:406] Scale28 <- Convolution28
I0926 14:52:16.786993  4911 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0926 14:52:16.787019  4911 layer_factory.hpp:77] Creating layer Scale28
I0926 14:52:16.787096  4911 net.cpp:122] Setting up Scale28
I0926 14:52:16.787101  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.787102  4911 net.cpp:137] Memory required for data: 635667600
I0926 14:52:16.787106  4911 layer_factory.hpp:77] Creating layer Eltwise13
I0926 14:52:16.787111  4911 net.cpp:84] Creating Layer Eltwise13
I0926 14:52:16.787113  4911 net.cpp:406] Eltwise13 <- Eltwise12_penlu25_0_split_1
I0926 14:52:16.787117  4911 net.cpp:406] Eltwise13 <- Convolution28
I0926 14:52:16.787119  4911 net.cpp:380] Eltwise13 -> Eltwise13
I0926 14:52:16.787135  4911 net.cpp:122] Setting up Eltwise13
I0926 14:52:16.787138  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.787140  4911 net.cpp:137] Memory required for data: 638176400
I0926 14:52:16.787142  4911 layer_factory.hpp:77] Creating layer penlu27
I0926 14:52:16.787147  4911 net.cpp:84] Creating Layer penlu27
I0926 14:52:16.787150  4911 net.cpp:406] penlu27 <- Eltwise13
I0926 14:52:16.787153  4911 net.cpp:367] penlu27 -> Eltwise13 (in-place)
I0926 14:52:16.787258  4911 net.cpp:122] Setting up penlu27
I0926 14:52:16.787263  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.787266  4911 net.cpp:137] Memory required for data: 640685200
I0926 14:52:16.787269  4911 layer_factory.hpp:77] Creating layer Eltwise13_penlu27_0_split
I0926 14:52:16.787278  4911 net.cpp:84] Creating Layer Eltwise13_penlu27_0_split
I0926 14:52:16.787281  4911 net.cpp:406] Eltwise13_penlu27_0_split <- Eltwise13
I0926 14:52:16.787284  4911 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_0
I0926 14:52:16.787288  4911 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_1
I0926 14:52:16.787312  4911 net.cpp:122] Setting up Eltwise13_penlu27_0_split
I0926 14:52:16.787315  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.787318  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.787320  4911 net.cpp:137] Memory required for data: 645702800
I0926 14:52:16.787322  4911 layer_factory.hpp:77] Creating layer Convolution29
I0926 14:52:16.787329  4911 net.cpp:84] Creating Layer Convolution29
I0926 14:52:16.787331  4911 net.cpp:406] Convolution29 <- Eltwise13_penlu27_0_split_0
I0926 14:52:16.787335  4911 net.cpp:380] Convolution29 -> Convolution29
I0926 14:52:16.788353  4911 net.cpp:122] Setting up Convolution29
I0926 14:52:16.788362  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.788364  4911 net.cpp:137] Memory required for data: 648211600
I0926 14:52:16.788368  4911 layer_factory.hpp:77] Creating layer BatchNorm29
I0926 14:52:16.788373  4911 net.cpp:84] Creating Layer BatchNorm29
I0926 14:52:16.788377  4911 net.cpp:406] BatchNorm29 <- Convolution29
I0926 14:52:16.788380  4911 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0926 14:52:16.788527  4911 net.cpp:122] Setting up BatchNorm29
I0926 14:52:16.788542  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.788544  4911 net.cpp:137] Memory required for data: 650720400
I0926 14:52:16.788548  4911 layer_factory.hpp:77] Creating layer Scale29
I0926 14:52:16.788553  4911 net.cpp:84] Creating Layer Scale29
I0926 14:52:16.788555  4911 net.cpp:406] Scale29 <- Convolution29
I0926 14:52:16.788559  4911 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0926 14:52:16.788586  4911 layer_factory.hpp:77] Creating layer Scale29
I0926 14:52:16.788663  4911 net.cpp:122] Setting up Scale29
I0926 14:52:16.788667  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.788669  4911 net.cpp:137] Memory required for data: 653229200
I0926 14:52:16.788673  4911 layer_factory.hpp:77] Creating layer penlu28
I0926 14:52:16.788681  4911 net.cpp:84] Creating Layer penlu28
I0926 14:52:16.788682  4911 net.cpp:406] penlu28 <- Convolution29
I0926 14:52:16.788686  4911 net.cpp:367] penlu28 -> Convolution29 (in-place)
I0926 14:52:16.788790  4911 net.cpp:122] Setting up penlu28
I0926 14:52:16.788795  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.788797  4911 net.cpp:137] Memory required for data: 655738000
I0926 14:52:16.788801  4911 layer_factory.hpp:77] Creating layer Convolution30
I0926 14:52:16.788807  4911 net.cpp:84] Creating Layer Convolution30
I0926 14:52:16.788810  4911 net.cpp:406] Convolution30 <- Convolution29
I0926 14:52:16.788813  4911 net.cpp:380] Convolution30 -> Convolution30
I0926 14:52:16.789835  4911 net.cpp:122] Setting up Convolution30
I0926 14:52:16.789844  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.789846  4911 net.cpp:137] Memory required for data: 658246800
I0926 14:52:16.789851  4911 layer_factory.hpp:77] Creating layer BatchNorm30
I0926 14:52:16.789856  4911 net.cpp:84] Creating Layer BatchNorm30
I0926 14:52:16.789858  4911 net.cpp:406] BatchNorm30 <- Convolution30
I0926 14:52:16.789862  4911 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0926 14:52:16.789994  4911 net.cpp:122] Setting up BatchNorm30
I0926 14:52:16.789999  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.790001  4911 net.cpp:137] Memory required for data: 660755600
I0926 14:52:16.790005  4911 layer_factory.hpp:77] Creating layer Scale30
I0926 14:52:16.790009  4911 net.cpp:84] Creating Layer Scale30
I0926 14:52:16.790011  4911 net.cpp:406] Scale30 <- Convolution30
I0926 14:52:16.790015  4911 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0926 14:52:16.790048  4911 layer_factory.hpp:77] Creating layer Scale30
I0926 14:52:16.790125  4911 net.cpp:122] Setting up Scale30
I0926 14:52:16.790130  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.790132  4911 net.cpp:137] Memory required for data: 663264400
I0926 14:52:16.790135  4911 layer_factory.hpp:77] Creating layer Eltwise14
I0926 14:52:16.790139  4911 net.cpp:84] Creating Layer Eltwise14
I0926 14:52:16.790143  4911 net.cpp:406] Eltwise14 <- Eltwise13_penlu27_0_split_1
I0926 14:52:16.790145  4911 net.cpp:406] Eltwise14 <- Convolution30
I0926 14:52:16.790148  4911 net.cpp:380] Eltwise14 -> Eltwise14
I0926 14:52:16.790164  4911 net.cpp:122] Setting up Eltwise14
I0926 14:52:16.790169  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.790170  4911 net.cpp:137] Memory required for data: 665773200
I0926 14:52:16.790172  4911 layer_factory.hpp:77] Creating layer penlu29
I0926 14:52:16.790177  4911 net.cpp:84] Creating Layer penlu29
I0926 14:52:16.790179  4911 net.cpp:406] penlu29 <- Eltwise14
I0926 14:52:16.790182  4911 net.cpp:367] penlu29 -> Eltwise14 (in-place)
I0926 14:52:16.790292  4911 net.cpp:122] Setting up penlu29
I0926 14:52:16.790295  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.790297  4911 net.cpp:137] Memory required for data: 668282000
I0926 14:52:16.790302  4911 layer_factory.hpp:77] Creating layer Eltwise14_penlu29_0_split
I0926 14:52:16.790305  4911 net.cpp:84] Creating Layer Eltwise14_penlu29_0_split
I0926 14:52:16.790307  4911 net.cpp:406] Eltwise14_penlu29_0_split <- Eltwise14
I0926 14:52:16.790310  4911 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_0
I0926 14:52:16.790315  4911 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_1
I0926 14:52:16.790338  4911 net.cpp:122] Setting up Eltwise14_penlu29_0_split
I0926 14:52:16.790341  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.790344  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.790346  4911 net.cpp:137] Memory required for data: 673299600
I0926 14:52:16.790349  4911 layer_factory.hpp:77] Creating layer Convolution31
I0926 14:52:16.790354  4911 net.cpp:84] Creating Layer Convolution31
I0926 14:52:16.790356  4911 net.cpp:406] Convolution31 <- Eltwise14_penlu29_0_split_0
I0926 14:52:16.790360  4911 net.cpp:380] Convolution31 -> Convolution31
I0926 14:52:16.791394  4911 net.cpp:122] Setting up Convolution31
I0926 14:52:16.791402  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.791405  4911 net.cpp:137] Memory required for data: 675808400
I0926 14:52:16.791409  4911 layer_factory.hpp:77] Creating layer BatchNorm31
I0926 14:52:16.791414  4911 net.cpp:84] Creating Layer BatchNorm31
I0926 14:52:16.791417  4911 net.cpp:406] BatchNorm31 <- Convolution31
I0926 14:52:16.791420  4911 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0926 14:52:16.791556  4911 net.cpp:122] Setting up BatchNorm31
I0926 14:52:16.791561  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.791563  4911 net.cpp:137] Memory required for data: 678317200
I0926 14:52:16.791568  4911 layer_factory.hpp:77] Creating layer Scale31
I0926 14:52:16.791571  4911 net.cpp:84] Creating Layer Scale31
I0926 14:52:16.791574  4911 net.cpp:406] Scale31 <- Convolution31
I0926 14:52:16.791579  4911 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0926 14:52:16.791604  4911 layer_factory.hpp:77] Creating layer Scale31
I0926 14:52:16.791679  4911 net.cpp:122] Setting up Scale31
I0926 14:52:16.791683  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.791685  4911 net.cpp:137] Memory required for data: 680826000
I0926 14:52:16.791689  4911 layer_factory.hpp:77] Creating layer penlu30
I0926 14:52:16.791694  4911 net.cpp:84] Creating Layer penlu30
I0926 14:52:16.791697  4911 net.cpp:406] penlu30 <- Convolution31
I0926 14:52:16.791702  4911 net.cpp:367] penlu30 -> Convolution31 (in-place)
I0926 14:52:16.791808  4911 net.cpp:122] Setting up penlu30
I0926 14:52:16.791813  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.791821  4911 net.cpp:137] Memory required for data: 683334800
I0926 14:52:16.791826  4911 layer_factory.hpp:77] Creating layer Convolution32
I0926 14:52:16.791832  4911 net.cpp:84] Creating Layer Convolution32
I0926 14:52:16.791834  4911 net.cpp:406] Convolution32 <- Convolution31
I0926 14:52:16.791838  4911 net.cpp:380] Convolution32 -> Convolution32
I0926 14:52:16.792888  4911 net.cpp:122] Setting up Convolution32
I0926 14:52:16.792896  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.792899  4911 net.cpp:137] Memory required for data: 685843600
I0926 14:52:16.792903  4911 layer_factory.hpp:77] Creating layer BatchNorm32
I0926 14:52:16.792907  4911 net.cpp:84] Creating Layer BatchNorm32
I0926 14:52:16.792910  4911 net.cpp:406] BatchNorm32 <- Convolution32
I0926 14:52:16.792915  4911 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I0926 14:52:16.793051  4911 net.cpp:122] Setting up BatchNorm32
I0926 14:52:16.793054  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.793056  4911 net.cpp:137] Memory required for data: 688352400
I0926 14:52:16.793061  4911 layer_factory.hpp:77] Creating layer Scale32
I0926 14:52:16.793064  4911 net.cpp:84] Creating Layer Scale32
I0926 14:52:16.793067  4911 net.cpp:406] Scale32 <- Convolution32
I0926 14:52:16.793071  4911 net.cpp:367] Scale32 -> Convolution32 (in-place)
I0926 14:52:16.793097  4911 layer_factory.hpp:77] Creating layer Scale32
I0926 14:52:16.793175  4911 net.cpp:122] Setting up Scale32
I0926 14:52:16.793180  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.793182  4911 net.cpp:137] Memory required for data: 690861200
I0926 14:52:16.793186  4911 layer_factory.hpp:77] Creating layer Eltwise15
I0926 14:52:16.793190  4911 net.cpp:84] Creating Layer Eltwise15
I0926 14:52:16.793192  4911 net.cpp:406] Eltwise15 <- Eltwise14_penlu29_0_split_1
I0926 14:52:16.793195  4911 net.cpp:406] Eltwise15 <- Convolution32
I0926 14:52:16.793198  4911 net.cpp:380] Eltwise15 -> Eltwise15
I0926 14:52:16.793215  4911 net.cpp:122] Setting up Eltwise15
I0926 14:52:16.793220  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.793221  4911 net.cpp:137] Memory required for data: 693370000
I0926 14:52:16.793223  4911 layer_factory.hpp:77] Creating layer penlu31
I0926 14:52:16.793227  4911 net.cpp:84] Creating Layer penlu31
I0926 14:52:16.793231  4911 net.cpp:406] penlu31 <- Eltwise15
I0926 14:52:16.793233  4911 net.cpp:367] penlu31 -> Eltwise15 (in-place)
I0926 14:52:16.793342  4911 net.cpp:122] Setting up penlu31
I0926 14:52:16.793346  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.793349  4911 net.cpp:137] Memory required for data: 695878800
I0926 14:52:16.793352  4911 layer_factory.hpp:77] Creating layer Eltwise15_penlu31_0_split
I0926 14:52:16.793356  4911 net.cpp:84] Creating Layer Eltwise15_penlu31_0_split
I0926 14:52:16.793359  4911 net.cpp:406] Eltwise15_penlu31_0_split <- Eltwise15
I0926 14:52:16.793361  4911 net.cpp:380] Eltwise15_penlu31_0_split -> Eltwise15_penlu31_0_split_0
I0926 14:52:16.793365  4911 net.cpp:380] Eltwise15_penlu31_0_split -> Eltwise15_penlu31_0_split_1
I0926 14:52:16.793388  4911 net.cpp:122] Setting up Eltwise15_penlu31_0_split
I0926 14:52:16.793391  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.793395  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.793396  4911 net.cpp:137] Memory required for data: 700896400
I0926 14:52:16.793398  4911 layer_factory.hpp:77] Creating layer Convolution33
I0926 14:52:16.793404  4911 net.cpp:84] Creating Layer Convolution33
I0926 14:52:16.793407  4911 net.cpp:406] Convolution33 <- Eltwise15_penlu31_0_split_0
I0926 14:52:16.793411  4911 net.cpp:380] Convolution33 -> Convolution33
I0926 14:52:16.794742  4911 net.cpp:122] Setting up Convolution33
I0926 14:52:16.794750  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.794754  4911 net.cpp:137] Memory required for data: 703405200
I0926 14:52:16.794757  4911 layer_factory.hpp:77] Creating layer BatchNorm33
I0926 14:52:16.794764  4911 net.cpp:84] Creating Layer BatchNorm33
I0926 14:52:16.794772  4911 net.cpp:406] BatchNorm33 <- Convolution33
I0926 14:52:16.794776  4911 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I0926 14:52:16.794916  4911 net.cpp:122] Setting up BatchNorm33
I0926 14:52:16.794921  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.794924  4911 net.cpp:137] Memory required for data: 705914000
I0926 14:52:16.794929  4911 layer_factory.hpp:77] Creating layer Scale33
I0926 14:52:16.794934  4911 net.cpp:84] Creating Layer Scale33
I0926 14:52:16.794935  4911 net.cpp:406] Scale33 <- Convolution33
I0926 14:52:16.794939  4911 net.cpp:367] Scale33 -> Convolution33 (in-place)
I0926 14:52:16.794965  4911 layer_factory.hpp:77] Creating layer Scale33
I0926 14:52:16.795044  4911 net.cpp:122] Setting up Scale33
I0926 14:52:16.795048  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.795050  4911 net.cpp:137] Memory required for data: 708422800
I0926 14:52:16.795053  4911 layer_factory.hpp:77] Creating layer penlu32
I0926 14:52:16.795058  4911 net.cpp:84] Creating Layer penlu32
I0926 14:52:16.795061  4911 net.cpp:406] penlu32 <- Convolution33
I0926 14:52:16.795064  4911 net.cpp:367] penlu32 -> Convolution33 (in-place)
I0926 14:52:16.795172  4911 net.cpp:122] Setting up penlu32
I0926 14:52:16.795177  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.795179  4911 net.cpp:137] Memory required for data: 710931600
I0926 14:52:16.795183  4911 layer_factory.hpp:77] Creating layer Convolution34
I0926 14:52:16.795189  4911 net.cpp:84] Creating Layer Convolution34
I0926 14:52:16.795192  4911 net.cpp:406] Convolution34 <- Convolution33
I0926 14:52:16.795197  4911 net.cpp:380] Convolution34 -> Convolution34
I0926 14:52:16.796233  4911 net.cpp:122] Setting up Convolution34
I0926 14:52:16.796241  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.796244  4911 net.cpp:137] Memory required for data: 713440400
I0926 14:52:16.796248  4911 layer_factory.hpp:77] Creating layer BatchNorm34
I0926 14:52:16.796253  4911 net.cpp:84] Creating Layer BatchNorm34
I0926 14:52:16.796257  4911 net.cpp:406] BatchNorm34 <- Convolution34
I0926 14:52:16.796260  4911 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I0926 14:52:16.796396  4911 net.cpp:122] Setting up BatchNorm34
I0926 14:52:16.796401  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.796402  4911 net.cpp:137] Memory required for data: 715949200
I0926 14:52:16.796406  4911 layer_factory.hpp:77] Creating layer Scale34
I0926 14:52:16.796411  4911 net.cpp:84] Creating Layer Scale34
I0926 14:52:16.796413  4911 net.cpp:406] Scale34 <- Convolution34
I0926 14:52:16.796417  4911 net.cpp:367] Scale34 -> Convolution34 (in-place)
I0926 14:52:16.796443  4911 layer_factory.hpp:77] Creating layer Scale34
I0926 14:52:16.796546  4911 net.cpp:122] Setting up Scale34
I0926 14:52:16.796551  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.796553  4911 net.cpp:137] Memory required for data: 718458000
I0926 14:52:16.796557  4911 layer_factory.hpp:77] Creating layer Eltwise16
I0926 14:52:16.796562  4911 net.cpp:84] Creating Layer Eltwise16
I0926 14:52:16.796566  4911 net.cpp:406] Eltwise16 <- Eltwise15_penlu31_0_split_1
I0926 14:52:16.796567  4911 net.cpp:406] Eltwise16 <- Convolution34
I0926 14:52:16.796571  4911 net.cpp:380] Eltwise16 -> Eltwise16
I0926 14:52:16.796587  4911 net.cpp:122] Setting up Eltwise16
I0926 14:52:16.796591  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.796593  4911 net.cpp:137] Memory required for data: 720966800
I0926 14:52:16.796596  4911 layer_factory.hpp:77] Creating layer penlu33
I0926 14:52:16.796600  4911 net.cpp:84] Creating Layer penlu33
I0926 14:52:16.796602  4911 net.cpp:406] penlu33 <- Eltwise16
I0926 14:52:16.796605  4911 net.cpp:367] penlu33 -> Eltwise16 (in-place)
I0926 14:52:16.796711  4911 net.cpp:122] Setting up penlu33
I0926 14:52:16.796715  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.796717  4911 net.cpp:137] Memory required for data: 723475600
I0926 14:52:16.796730  4911 layer_factory.hpp:77] Creating layer Eltwise16_penlu33_0_split
I0926 14:52:16.796733  4911 net.cpp:84] Creating Layer Eltwise16_penlu33_0_split
I0926 14:52:16.796736  4911 net.cpp:406] Eltwise16_penlu33_0_split <- Eltwise16
I0926 14:52:16.796738  4911 net.cpp:380] Eltwise16_penlu33_0_split -> Eltwise16_penlu33_0_split_0
I0926 14:52:16.796742  4911 net.cpp:380] Eltwise16_penlu33_0_split -> Eltwise16_penlu33_0_split_1
I0926 14:52:16.796766  4911 net.cpp:122] Setting up Eltwise16_penlu33_0_split
I0926 14:52:16.796771  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.796772  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.796774  4911 net.cpp:137] Memory required for data: 728493200
I0926 14:52:16.796777  4911 layer_factory.hpp:77] Creating layer Convolution35
I0926 14:52:16.796782  4911 net.cpp:84] Creating Layer Convolution35
I0926 14:52:16.796785  4911 net.cpp:406] Convolution35 <- Eltwise16_penlu33_0_split_0
I0926 14:52:16.796789  4911 net.cpp:380] Convolution35 -> Convolution35
I0926 14:52:16.797818  4911 net.cpp:122] Setting up Convolution35
I0926 14:52:16.797827  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.797829  4911 net.cpp:137] Memory required for data: 731002000
I0926 14:52:16.797834  4911 layer_factory.hpp:77] Creating layer BatchNorm35
I0926 14:52:16.797839  4911 net.cpp:84] Creating Layer BatchNorm35
I0926 14:52:16.797842  4911 net.cpp:406] BatchNorm35 <- Convolution35
I0926 14:52:16.797847  4911 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I0926 14:52:16.797979  4911 net.cpp:122] Setting up BatchNorm35
I0926 14:52:16.797984  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.797986  4911 net.cpp:137] Memory required for data: 733510800
I0926 14:52:16.797991  4911 layer_factory.hpp:77] Creating layer Scale35
I0926 14:52:16.797996  4911 net.cpp:84] Creating Layer Scale35
I0926 14:52:16.797997  4911 net.cpp:406] Scale35 <- Convolution35
I0926 14:52:16.798001  4911 net.cpp:367] Scale35 -> Convolution35 (in-place)
I0926 14:52:16.798028  4911 layer_factory.hpp:77] Creating layer Scale35
I0926 14:52:16.798106  4911 net.cpp:122] Setting up Scale35
I0926 14:52:16.798110  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.798112  4911 net.cpp:137] Memory required for data: 736019600
I0926 14:52:16.798116  4911 layer_factory.hpp:77] Creating layer penlu34
I0926 14:52:16.798122  4911 net.cpp:84] Creating Layer penlu34
I0926 14:52:16.798125  4911 net.cpp:406] penlu34 <- Convolution35
I0926 14:52:16.798127  4911 net.cpp:367] penlu34 -> Convolution35 (in-place)
I0926 14:52:16.798233  4911 net.cpp:122] Setting up penlu34
I0926 14:52:16.798238  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.798240  4911 net.cpp:137] Memory required for data: 738528400
I0926 14:52:16.798244  4911 layer_factory.hpp:77] Creating layer Convolution36
I0926 14:52:16.798251  4911 net.cpp:84] Creating Layer Convolution36
I0926 14:52:16.798254  4911 net.cpp:406] Convolution36 <- Convolution35
I0926 14:52:16.798257  4911 net.cpp:380] Convolution36 -> Convolution36
I0926 14:52:16.799304  4911 net.cpp:122] Setting up Convolution36
I0926 14:52:16.799314  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.799315  4911 net.cpp:137] Memory required for data: 741037200
I0926 14:52:16.799320  4911 layer_factory.hpp:77] Creating layer BatchNorm36
I0926 14:52:16.799325  4911 net.cpp:84] Creating Layer BatchNorm36
I0926 14:52:16.799327  4911 net.cpp:406] BatchNorm36 <- Convolution36
I0926 14:52:16.799331  4911 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I0926 14:52:16.799464  4911 net.cpp:122] Setting up BatchNorm36
I0926 14:52:16.799468  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.799471  4911 net.cpp:137] Memory required for data: 743546000
I0926 14:52:16.799475  4911 layer_factory.hpp:77] Creating layer Scale36
I0926 14:52:16.799479  4911 net.cpp:84] Creating Layer Scale36
I0926 14:52:16.799481  4911 net.cpp:406] Scale36 <- Convolution36
I0926 14:52:16.799485  4911 net.cpp:367] Scale36 -> Convolution36 (in-place)
I0926 14:52:16.799518  4911 layer_factory.hpp:77] Creating layer Scale36
I0926 14:52:16.799595  4911 net.cpp:122] Setting up Scale36
I0926 14:52:16.799600  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.799602  4911 net.cpp:137] Memory required for data: 746054800
I0926 14:52:16.799605  4911 layer_factory.hpp:77] Creating layer Eltwise17
I0926 14:52:16.799609  4911 net.cpp:84] Creating Layer Eltwise17
I0926 14:52:16.799612  4911 net.cpp:406] Eltwise17 <- Eltwise16_penlu33_0_split_1
I0926 14:52:16.799615  4911 net.cpp:406] Eltwise17 <- Convolution36
I0926 14:52:16.799619  4911 net.cpp:380] Eltwise17 -> Eltwise17
I0926 14:52:16.799635  4911 net.cpp:122] Setting up Eltwise17
I0926 14:52:16.799638  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.799640  4911 net.cpp:137] Memory required for data: 748563600
I0926 14:52:16.799643  4911 layer_factory.hpp:77] Creating layer penlu35
I0926 14:52:16.799649  4911 net.cpp:84] Creating Layer penlu35
I0926 14:52:16.799650  4911 net.cpp:406] penlu35 <- Eltwise17
I0926 14:52:16.799654  4911 net.cpp:367] penlu35 -> Eltwise17 (in-place)
I0926 14:52:16.799763  4911 net.cpp:122] Setting up penlu35
I0926 14:52:16.799767  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.799769  4911 net.cpp:137] Memory required for data: 751072400
I0926 14:52:16.799774  4911 layer_factory.hpp:77] Creating layer Eltwise17_penlu35_0_split
I0926 14:52:16.799778  4911 net.cpp:84] Creating Layer Eltwise17_penlu35_0_split
I0926 14:52:16.799780  4911 net.cpp:406] Eltwise17_penlu35_0_split <- Eltwise17
I0926 14:52:16.799783  4911 net.cpp:380] Eltwise17_penlu35_0_split -> Eltwise17_penlu35_0_split_0
I0926 14:52:16.799787  4911 net.cpp:380] Eltwise17_penlu35_0_split -> Eltwise17_penlu35_0_split_1
I0926 14:52:16.799810  4911 net.cpp:122] Setting up Eltwise17_penlu35_0_split
I0926 14:52:16.799814  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.799816  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.799818  4911 net.cpp:137] Memory required for data: 756090000
I0926 14:52:16.799821  4911 layer_factory.hpp:77] Creating layer Convolution37
I0926 14:52:16.799827  4911 net.cpp:84] Creating Layer Convolution37
I0926 14:52:16.799829  4911 net.cpp:406] Convolution37 <- Eltwise17_penlu35_0_split_0
I0926 14:52:16.799834  4911 net.cpp:380] Convolution37 -> Convolution37
I0926 14:52:16.800580  4911 net.cpp:122] Setting up Convolution37
I0926 14:52:16.800587  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.800590  4911 net.cpp:137] Memory required for data: 758598800
I0926 14:52:16.800595  4911 layer_factory.hpp:77] Creating layer BatchNorm37
I0926 14:52:16.800598  4911 net.cpp:84] Creating Layer BatchNorm37
I0926 14:52:16.800601  4911 net.cpp:406] BatchNorm37 <- Convolution37
I0926 14:52:16.800604  4911 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I0926 14:52:16.800740  4911 net.cpp:122] Setting up BatchNorm37
I0926 14:52:16.800743  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.800745  4911 net.cpp:137] Memory required for data: 761107600
I0926 14:52:16.800750  4911 layer_factory.hpp:77] Creating layer Scale37
I0926 14:52:16.800753  4911 net.cpp:84] Creating Layer Scale37
I0926 14:52:16.800756  4911 net.cpp:406] Scale37 <- Convolution37
I0926 14:52:16.800760  4911 net.cpp:367] Scale37 -> Convolution37 (in-place)
I0926 14:52:16.800786  4911 layer_factory.hpp:77] Creating layer Scale37
I0926 14:52:16.800861  4911 net.cpp:122] Setting up Scale37
I0926 14:52:16.800865  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.800868  4911 net.cpp:137] Memory required for data: 763616400
I0926 14:52:16.800870  4911 layer_factory.hpp:77] Creating layer penlu36
I0926 14:52:16.800876  4911 net.cpp:84] Creating Layer penlu36
I0926 14:52:16.800879  4911 net.cpp:406] penlu36 <- Convolution37
I0926 14:52:16.800882  4911 net.cpp:367] penlu36 -> Convolution37 (in-place)
I0926 14:52:16.800988  4911 net.cpp:122] Setting up penlu36
I0926 14:52:16.800993  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.801002  4911 net.cpp:137] Memory required for data: 766125200
I0926 14:52:16.801005  4911 layer_factory.hpp:77] Creating layer Convolution38
I0926 14:52:16.801012  4911 net.cpp:84] Creating Layer Convolution38
I0926 14:52:16.801015  4911 net.cpp:406] Convolution38 <- Convolution37
I0926 14:52:16.801019  4911 net.cpp:380] Convolution38 -> Convolution38
I0926 14:52:16.802057  4911 net.cpp:122] Setting up Convolution38
I0926 14:52:16.802064  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.802067  4911 net.cpp:137] Memory required for data: 768634000
I0926 14:52:16.802072  4911 layer_factory.hpp:77] Creating layer BatchNorm38
I0926 14:52:16.802076  4911 net.cpp:84] Creating Layer BatchNorm38
I0926 14:52:16.802079  4911 net.cpp:406] BatchNorm38 <- Convolution38
I0926 14:52:16.802083  4911 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I0926 14:52:16.802219  4911 net.cpp:122] Setting up BatchNorm38
I0926 14:52:16.802224  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.802227  4911 net.cpp:137] Memory required for data: 771142800
I0926 14:52:16.802232  4911 layer_factory.hpp:77] Creating layer Scale38
I0926 14:52:16.802235  4911 net.cpp:84] Creating Layer Scale38
I0926 14:52:16.802238  4911 net.cpp:406] Scale38 <- Convolution38
I0926 14:52:16.802242  4911 net.cpp:367] Scale38 -> Convolution38 (in-place)
I0926 14:52:16.802269  4911 layer_factory.hpp:77] Creating layer Scale38
I0926 14:52:16.802346  4911 net.cpp:122] Setting up Scale38
I0926 14:52:16.802350  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.802352  4911 net.cpp:137] Memory required for data: 773651600
I0926 14:52:16.802356  4911 layer_factory.hpp:77] Creating layer Eltwise18
I0926 14:52:16.802359  4911 net.cpp:84] Creating Layer Eltwise18
I0926 14:52:16.802362  4911 net.cpp:406] Eltwise18 <- Eltwise17_penlu35_0_split_1
I0926 14:52:16.802366  4911 net.cpp:406] Eltwise18 <- Convolution38
I0926 14:52:16.802369  4911 net.cpp:380] Eltwise18 -> Eltwise18
I0926 14:52:16.802384  4911 net.cpp:122] Setting up Eltwise18
I0926 14:52:16.802388  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.802390  4911 net.cpp:137] Memory required for data: 776160400
I0926 14:52:16.802392  4911 layer_factory.hpp:77] Creating layer penlu37
I0926 14:52:16.802397  4911 net.cpp:84] Creating Layer penlu37
I0926 14:52:16.802399  4911 net.cpp:406] penlu37 <- Eltwise18
I0926 14:52:16.802403  4911 net.cpp:367] penlu37 -> Eltwise18 (in-place)
I0926 14:52:16.802510  4911 net.cpp:122] Setting up penlu37
I0926 14:52:16.802515  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.802516  4911 net.cpp:137] Memory required for data: 778669200
I0926 14:52:16.802521  4911 layer_factory.hpp:77] Creating layer Eltwise18_penlu37_0_split
I0926 14:52:16.802525  4911 net.cpp:84] Creating Layer Eltwise18_penlu37_0_split
I0926 14:52:16.802526  4911 net.cpp:406] Eltwise18_penlu37_0_split <- Eltwise18
I0926 14:52:16.802530  4911 net.cpp:380] Eltwise18_penlu37_0_split -> Eltwise18_penlu37_0_split_0
I0926 14:52:16.802534  4911 net.cpp:380] Eltwise18_penlu37_0_split -> Eltwise18_penlu37_0_split_1
I0926 14:52:16.802556  4911 net.cpp:122] Setting up Eltwise18_penlu37_0_split
I0926 14:52:16.802561  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.802562  4911 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 14:52:16.802564  4911 net.cpp:137] Memory required for data: 783686800
I0926 14:52:16.802567  4911 layer_factory.hpp:77] Creating layer Convolution39
I0926 14:52:16.802574  4911 net.cpp:84] Creating Layer Convolution39
I0926 14:52:16.802577  4911 net.cpp:406] Convolution39 <- Eltwise18_penlu37_0_split_0
I0926 14:52:16.802580  4911 net.cpp:380] Convolution39 -> Convolution39
I0926 14:52:16.803459  4911 net.cpp:122] Setting up Convolution39
I0926 14:52:16.803468  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.803470  4911 net.cpp:137] Memory required for data: 784941200
I0926 14:52:16.803475  4911 layer_factory.hpp:77] Creating layer BatchNorm39
I0926 14:52:16.803486  4911 net.cpp:84] Creating Layer BatchNorm39
I0926 14:52:16.803489  4911 net.cpp:406] BatchNorm39 <- Convolution39
I0926 14:52:16.803493  4911 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I0926 14:52:16.803627  4911 net.cpp:122] Setting up BatchNorm39
I0926 14:52:16.803632  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.803633  4911 net.cpp:137] Memory required for data: 786195600
I0926 14:52:16.803638  4911 layer_factory.hpp:77] Creating layer Scale39
I0926 14:52:16.803642  4911 net.cpp:84] Creating Layer Scale39
I0926 14:52:16.803645  4911 net.cpp:406] Scale39 <- Convolution39
I0926 14:52:16.803648  4911 net.cpp:367] Scale39 -> Convolution39 (in-place)
I0926 14:52:16.803674  4911 layer_factory.hpp:77] Creating layer Scale39
I0926 14:52:16.803751  4911 net.cpp:122] Setting up Scale39
I0926 14:52:16.803756  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.803758  4911 net.cpp:137] Memory required for data: 787450000
I0926 14:52:16.803762  4911 layer_factory.hpp:77] Creating layer Convolution40
I0926 14:52:16.803768  4911 net.cpp:84] Creating Layer Convolution40
I0926 14:52:16.803771  4911 net.cpp:406] Convolution40 <- Eltwise18_penlu37_0_split_1
I0926 14:52:16.803776  4911 net.cpp:380] Convolution40 -> Convolution40
I0926 14:52:16.805608  4911 net.cpp:122] Setting up Convolution40
I0926 14:52:16.805619  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.805621  4911 net.cpp:137] Memory required for data: 788704400
I0926 14:52:16.805626  4911 layer_factory.hpp:77] Creating layer BatchNorm40
I0926 14:52:16.805632  4911 net.cpp:84] Creating Layer BatchNorm40
I0926 14:52:16.805636  4911 net.cpp:406] BatchNorm40 <- Convolution40
I0926 14:52:16.805639  4911 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I0926 14:52:16.805783  4911 net.cpp:122] Setting up BatchNorm40
I0926 14:52:16.805788  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.805789  4911 net.cpp:137] Memory required for data: 789958800
I0926 14:52:16.805794  4911 layer_factory.hpp:77] Creating layer Scale40
I0926 14:52:16.805799  4911 net.cpp:84] Creating Layer Scale40
I0926 14:52:16.805801  4911 net.cpp:406] Scale40 <- Convolution40
I0926 14:52:16.805804  4911 net.cpp:367] Scale40 -> Convolution40 (in-place)
I0926 14:52:16.805833  4911 layer_factory.hpp:77] Creating layer Scale40
I0926 14:52:16.805915  4911 net.cpp:122] Setting up Scale40
I0926 14:52:16.805920  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.805922  4911 net.cpp:137] Memory required for data: 791213200
I0926 14:52:16.805927  4911 layer_factory.hpp:77] Creating layer penlu38
I0926 14:52:16.805932  4911 net.cpp:84] Creating Layer penlu38
I0926 14:52:16.805934  4911 net.cpp:406] penlu38 <- Convolution40
I0926 14:52:16.805938  4911 net.cpp:367] penlu38 -> Convolution40 (in-place)
I0926 14:52:16.806049  4911 net.cpp:122] Setting up penlu38
I0926 14:52:16.806054  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.806056  4911 net.cpp:137] Memory required for data: 792467600
I0926 14:52:16.806061  4911 layer_factory.hpp:77] Creating layer Convolution41
I0926 14:52:16.806067  4911 net.cpp:84] Creating Layer Convolution41
I0926 14:52:16.806071  4911 net.cpp:406] Convolution41 <- Convolution40
I0926 14:52:16.806074  4911 net.cpp:380] Convolution41 -> Convolution41
I0926 14:52:16.808221  4911 net.cpp:122] Setting up Convolution41
I0926 14:52:16.808230  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.808233  4911 net.cpp:137] Memory required for data: 793722000
I0926 14:52:16.808238  4911 layer_factory.hpp:77] Creating layer BatchNorm41
I0926 14:52:16.808243  4911 net.cpp:84] Creating Layer BatchNorm41
I0926 14:52:16.808245  4911 net.cpp:406] BatchNorm41 <- Convolution41
I0926 14:52:16.808249  4911 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I0926 14:52:16.808393  4911 net.cpp:122] Setting up BatchNorm41
I0926 14:52:16.808396  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.808398  4911 net.cpp:137] Memory required for data: 794976400
I0926 14:52:16.808403  4911 layer_factory.hpp:77] Creating layer Scale41
I0926 14:52:16.808414  4911 net.cpp:84] Creating Layer Scale41
I0926 14:52:16.808418  4911 net.cpp:406] Scale41 <- Convolution41
I0926 14:52:16.808420  4911 net.cpp:367] Scale41 -> Convolution41 (in-place)
I0926 14:52:16.808450  4911 layer_factory.hpp:77] Creating layer Scale41
I0926 14:52:16.808558  4911 net.cpp:122] Setting up Scale41
I0926 14:52:16.808564  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.808567  4911 net.cpp:137] Memory required for data: 796230800
I0926 14:52:16.808570  4911 layer_factory.hpp:77] Creating layer Eltwise19
I0926 14:52:16.808574  4911 net.cpp:84] Creating Layer Eltwise19
I0926 14:52:16.808578  4911 net.cpp:406] Eltwise19 <- Convolution39
I0926 14:52:16.808580  4911 net.cpp:406] Eltwise19 <- Convolution41
I0926 14:52:16.808584  4911 net.cpp:380] Eltwise19 -> Eltwise19
I0926 14:52:16.808601  4911 net.cpp:122] Setting up Eltwise19
I0926 14:52:16.808605  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.808607  4911 net.cpp:137] Memory required for data: 797485200
I0926 14:52:16.808609  4911 layer_factory.hpp:77] Creating layer penlu39
I0926 14:52:16.808615  4911 net.cpp:84] Creating Layer penlu39
I0926 14:52:16.808617  4911 net.cpp:406] penlu39 <- Eltwise19
I0926 14:52:16.808621  4911 net.cpp:367] penlu39 -> Eltwise19 (in-place)
I0926 14:52:16.808734  4911 net.cpp:122] Setting up penlu39
I0926 14:52:16.808739  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.808742  4911 net.cpp:137] Memory required for data: 798739600
I0926 14:52:16.808745  4911 layer_factory.hpp:77] Creating layer Eltwise19_penlu39_0_split
I0926 14:52:16.808749  4911 net.cpp:84] Creating Layer Eltwise19_penlu39_0_split
I0926 14:52:16.808751  4911 net.cpp:406] Eltwise19_penlu39_0_split <- Eltwise19
I0926 14:52:16.808754  4911 net.cpp:380] Eltwise19_penlu39_0_split -> Eltwise19_penlu39_0_split_0
I0926 14:52:16.808758  4911 net.cpp:380] Eltwise19_penlu39_0_split -> Eltwise19_penlu39_0_split_1
I0926 14:52:16.808792  4911 net.cpp:122] Setting up Eltwise19_penlu39_0_split
I0926 14:52:16.808796  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.808799  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.808801  4911 net.cpp:137] Memory required for data: 801248400
I0926 14:52:16.808804  4911 layer_factory.hpp:77] Creating layer Convolution42
I0926 14:52:16.808809  4911 net.cpp:84] Creating Layer Convolution42
I0926 14:52:16.808812  4911 net.cpp:406] Convolution42 <- Eltwise19_penlu39_0_split_0
I0926 14:52:16.808816  4911 net.cpp:380] Convolution42 -> Convolution42
I0926 14:52:16.810571  4911 net.cpp:122] Setting up Convolution42
I0926 14:52:16.810580  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.810582  4911 net.cpp:137] Memory required for data: 802502800
I0926 14:52:16.810587  4911 layer_factory.hpp:77] Creating layer BatchNorm42
I0926 14:52:16.810592  4911 net.cpp:84] Creating Layer BatchNorm42
I0926 14:52:16.810595  4911 net.cpp:406] BatchNorm42 <- Convolution42
I0926 14:52:16.810598  4911 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I0926 14:52:16.810739  4911 net.cpp:122] Setting up BatchNorm42
I0926 14:52:16.810744  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.810745  4911 net.cpp:137] Memory required for data: 803757200
I0926 14:52:16.810750  4911 layer_factory.hpp:77] Creating layer Scale42
I0926 14:52:16.810755  4911 net.cpp:84] Creating Layer Scale42
I0926 14:52:16.810757  4911 net.cpp:406] Scale42 <- Convolution42
I0926 14:52:16.810760  4911 net.cpp:367] Scale42 -> Convolution42 (in-place)
I0926 14:52:16.810789  4911 layer_factory.hpp:77] Creating layer Scale42
I0926 14:52:16.810870  4911 net.cpp:122] Setting up Scale42
I0926 14:52:16.810874  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.810876  4911 net.cpp:137] Memory required for data: 805011600
I0926 14:52:16.810880  4911 layer_factory.hpp:77] Creating layer penlu40
I0926 14:52:16.810885  4911 net.cpp:84] Creating Layer penlu40
I0926 14:52:16.810887  4911 net.cpp:406] penlu40 <- Convolution42
I0926 14:52:16.810899  4911 net.cpp:367] penlu40 -> Convolution42 (in-place)
I0926 14:52:16.811013  4911 net.cpp:122] Setting up penlu40
I0926 14:52:16.811018  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.811020  4911 net.cpp:137] Memory required for data: 806266000
I0926 14:52:16.811024  4911 layer_factory.hpp:77] Creating layer Convolution43
I0926 14:52:16.811031  4911 net.cpp:84] Creating Layer Convolution43
I0926 14:52:16.811034  4911 net.cpp:406] Convolution43 <- Convolution42
I0926 14:52:16.811039  4911 net.cpp:380] Convolution43 -> Convolution43
I0926 14:52:16.813365  4911 net.cpp:122] Setting up Convolution43
I0926 14:52:16.813374  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.813377  4911 net.cpp:137] Memory required for data: 807520400
I0926 14:52:16.813381  4911 layer_factory.hpp:77] Creating layer BatchNorm43
I0926 14:52:16.813386  4911 net.cpp:84] Creating Layer BatchNorm43
I0926 14:52:16.813390  4911 net.cpp:406] BatchNorm43 <- Convolution43
I0926 14:52:16.813393  4911 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I0926 14:52:16.813540  4911 net.cpp:122] Setting up BatchNorm43
I0926 14:52:16.813545  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.813547  4911 net.cpp:137] Memory required for data: 808774800
I0926 14:52:16.813552  4911 layer_factory.hpp:77] Creating layer Scale43
I0926 14:52:16.813556  4911 net.cpp:84] Creating Layer Scale43
I0926 14:52:16.813560  4911 net.cpp:406] Scale43 <- Convolution43
I0926 14:52:16.813563  4911 net.cpp:367] Scale43 -> Convolution43 (in-place)
I0926 14:52:16.813591  4911 layer_factory.hpp:77] Creating layer Scale43
I0926 14:52:16.813671  4911 net.cpp:122] Setting up Scale43
I0926 14:52:16.813676  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.813678  4911 net.cpp:137] Memory required for data: 810029200
I0926 14:52:16.813683  4911 layer_factory.hpp:77] Creating layer Eltwise20
I0926 14:52:16.813685  4911 net.cpp:84] Creating Layer Eltwise20
I0926 14:52:16.813688  4911 net.cpp:406] Eltwise20 <- Eltwise19_penlu39_0_split_1
I0926 14:52:16.813691  4911 net.cpp:406] Eltwise20 <- Convolution43
I0926 14:52:16.813695  4911 net.cpp:380] Eltwise20 -> Eltwise20
I0926 14:52:16.813712  4911 net.cpp:122] Setting up Eltwise20
I0926 14:52:16.813716  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.813719  4911 net.cpp:137] Memory required for data: 811283600
I0926 14:52:16.813720  4911 layer_factory.hpp:77] Creating layer penlu41
I0926 14:52:16.813724  4911 net.cpp:84] Creating Layer penlu41
I0926 14:52:16.813727  4911 net.cpp:406] penlu41 <- Eltwise20
I0926 14:52:16.813731  4911 net.cpp:367] penlu41 -> Eltwise20 (in-place)
I0926 14:52:16.813845  4911 net.cpp:122] Setting up penlu41
I0926 14:52:16.813850  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.813853  4911 net.cpp:137] Memory required for data: 812538000
I0926 14:52:16.813856  4911 layer_factory.hpp:77] Creating layer Eltwise20_penlu41_0_split
I0926 14:52:16.813860  4911 net.cpp:84] Creating Layer Eltwise20_penlu41_0_split
I0926 14:52:16.813863  4911 net.cpp:406] Eltwise20_penlu41_0_split <- Eltwise20
I0926 14:52:16.813865  4911 net.cpp:380] Eltwise20_penlu41_0_split -> Eltwise20_penlu41_0_split_0
I0926 14:52:16.813869  4911 net.cpp:380] Eltwise20_penlu41_0_split -> Eltwise20_penlu41_0_split_1
I0926 14:52:16.813894  4911 net.cpp:122] Setting up Eltwise20_penlu41_0_split
I0926 14:52:16.813897  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.813900  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.813902  4911 net.cpp:137] Memory required for data: 815046800
I0926 14:52:16.813905  4911 layer_factory.hpp:77] Creating layer Convolution44
I0926 14:52:16.813911  4911 net.cpp:84] Creating Layer Convolution44
I0926 14:52:16.813913  4911 net.cpp:406] Convolution44 <- Eltwise20_penlu41_0_split_0
I0926 14:52:16.813917  4911 net.cpp:380] Convolution44 -> Convolution44
I0926 14:52:16.815601  4911 net.cpp:122] Setting up Convolution44
I0926 14:52:16.815610  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.815620  4911 net.cpp:137] Memory required for data: 816301200
I0926 14:52:16.815625  4911 layer_factory.hpp:77] Creating layer BatchNorm44
I0926 14:52:16.815629  4911 net.cpp:84] Creating Layer BatchNorm44
I0926 14:52:16.815632  4911 net.cpp:406] BatchNorm44 <- Convolution44
I0926 14:52:16.815636  4911 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I0926 14:52:16.815795  4911 net.cpp:122] Setting up BatchNorm44
I0926 14:52:16.815801  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.815804  4911 net.cpp:137] Memory required for data: 817555600
I0926 14:52:16.815809  4911 layer_factory.hpp:77] Creating layer Scale44
I0926 14:52:16.815814  4911 net.cpp:84] Creating Layer Scale44
I0926 14:52:16.815815  4911 net.cpp:406] Scale44 <- Convolution44
I0926 14:52:16.815821  4911 net.cpp:367] Scale44 -> Convolution44 (in-place)
I0926 14:52:16.815850  4911 layer_factory.hpp:77] Creating layer Scale44
I0926 14:52:16.815932  4911 net.cpp:122] Setting up Scale44
I0926 14:52:16.815937  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.815938  4911 net.cpp:137] Memory required for data: 818810000
I0926 14:52:16.815943  4911 layer_factory.hpp:77] Creating layer penlu42
I0926 14:52:16.815948  4911 net.cpp:84] Creating Layer penlu42
I0926 14:52:16.815950  4911 net.cpp:406] penlu42 <- Convolution44
I0926 14:52:16.815954  4911 net.cpp:367] penlu42 -> Convolution44 (in-place)
I0926 14:52:16.816068  4911 net.cpp:122] Setting up penlu42
I0926 14:52:16.816072  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.816074  4911 net.cpp:137] Memory required for data: 820064400
I0926 14:52:16.816078  4911 layer_factory.hpp:77] Creating layer Convolution45
I0926 14:52:16.816085  4911 net.cpp:84] Creating Layer Convolution45
I0926 14:52:16.816088  4911 net.cpp:406] Convolution45 <- Convolution44
I0926 14:52:16.816092  4911 net.cpp:380] Convolution45 -> Convolution45
I0926 14:52:16.818104  4911 net.cpp:122] Setting up Convolution45
I0926 14:52:16.818114  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.818116  4911 net.cpp:137] Memory required for data: 821318800
I0926 14:52:16.818120  4911 layer_factory.hpp:77] Creating layer BatchNorm45
I0926 14:52:16.818125  4911 net.cpp:84] Creating Layer BatchNorm45
I0926 14:52:16.818128  4911 net.cpp:406] BatchNorm45 <- Convolution45
I0926 14:52:16.818132  4911 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I0926 14:52:16.818279  4911 net.cpp:122] Setting up BatchNorm45
I0926 14:52:16.818282  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.818285  4911 net.cpp:137] Memory required for data: 822573200
I0926 14:52:16.818290  4911 layer_factory.hpp:77] Creating layer Scale45
I0926 14:52:16.818294  4911 net.cpp:84] Creating Layer Scale45
I0926 14:52:16.818296  4911 net.cpp:406] Scale45 <- Convolution45
I0926 14:52:16.818300  4911 net.cpp:367] Scale45 -> Convolution45 (in-place)
I0926 14:52:16.818328  4911 layer_factory.hpp:77] Creating layer Scale45
I0926 14:52:16.818410  4911 net.cpp:122] Setting up Scale45
I0926 14:52:16.818414  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.818416  4911 net.cpp:137] Memory required for data: 823827600
I0926 14:52:16.818420  4911 layer_factory.hpp:77] Creating layer Eltwise21
I0926 14:52:16.818425  4911 net.cpp:84] Creating Layer Eltwise21
I0926 14:52:16.818428  4911 net.cpp:406] Eltwise21 <- Eltwise20_penlu41_0_split_1
I0926 14:52:16.818430  4911 net.cpp:406] Eltwise21 <- Convolution45
I0926 14:52:16.818434  4911 net.cpp:380] Eltwise21 -> Eltwise21
I0926 14:52:16.818451  4911 net.cpp:122] Setting up Eltwise21
I0926 14:52:16.818454  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.818456  4911 net.cpp:137] Memory required for data: 825082000
I0926 14:52:16.818459  4911 layer_factory.hpp:77] Creating layer penlu43
I0926 14:52:16.818464  4911 net.cpp:84] Creating Layer penlu43
I0926 14:52:16.818466  4911 net.cpp:406] penlu43 <- Eltwise21
I0926 14:52:16.818470  4911 net.cpp:367] penlu43 -> Eltwise21 (in-place)
I0926 14:52:16.818586  4911 net.cpp:122] Setting up penlu43
I0926 14:52:16.818598  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.818599  4911 net.cpp:137] Memory required for data: 826336400
I0926 14:52:16.818604  4911 layer_factory.hpp:77] Creating layer Eltwise21_penlu43_0_split
I0926 14:52:16.818609  4911 net.cpp:84] Creating Layer Eltwise21_penlu43_0_split
I0926 14:52:16.818611  4911 net.cpp:406] Eltwise21_penlu43_0_split <- Eltwise21
I0926 14:52:16.818615  4911 net.cpp:380] Eltwise21_penlu43_0_split -> Eltwise21_penlu43_0_split_0
I0926 14:52:16.818619  4911 net.cpp:380] Eltwise21_penlu43_0_split -> Eltwise21_penlu43_0_split_1
I0926 14:52:16.818645  4911 net.cpp:122] Setting up Eltwise21_penlu43_0_split
I0926 14:52:16.818648  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.818651  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.818653  4911 net.cpp:137] Memory required for data: 828845200
I0926 14:52:16.818656  4911 layer_factory.hpp:77] Creating layer Convolution46
I0926 14:52:16.818661  4911 net.cpp:84] Creating Layer Convolution46
I0926 14:52:16.818665  4911 net.cpp:406] Convolution46 <- Eltwise21_penlu43_0_split_0
I0926 14:52:16.818670  4911 net.cpp:380] Convolution46 -> Convolution46
I0926 14:52:16.820356  4911 net.cpp:122] Setting up Convolution46
I0926 14:52:16.820365  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.820367  4911 net.cpp:137] Memory required for data: 830099600
I0926 14:52:16.820371  4911 layer_factory.hpp:77] Creating layer BatchNorm46
I0926 14:52:16.820376  4911 net.cpp:84] Creating Layer BatchNorm46
I0926 14:52:16.820379  4911 net.cpp:406] BatchNorm46 <- Convolution46
I0926 14:52:16.820384  4911 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I0926 14:52:16.820555  4911 net.cpp:122] Setting up BatchNorm46
I0926 14:52:16.820561  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.820564  4911 net.cpp:137] Memory required for data: 831354000
I0926 14:52:16.820569  4911 layer_factory.hpp:77] Creating layer Scale46
I0926 14:52:16.820572  4911 net.cpp:84] Creating Layer Scale46
I0926 14:52:16.820575  4911 net.cpp:406] Scale46 <- Convolution46
I0926 14:52:16.820578  4911 net.cpp:367] Scale46 -> Convolution46 (in-place)
I0926 14:52:16.820608  4911 layer_factory.hpp:77] Creating layer Scale46
I0926 14:52:16.820690  4911 net.cpp:122] Setting up Scale46
I0926 14:52:16.820694  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.820698  4911 net.cpp:137] Memory required for data: 832608400
I0926 14:52:16.820700  4911 layer_factory.hpp:77] Creating layer penlu44
I0926 14:52:16.820708  4911 net.cpp:84] Creating Layer penlu44
I0926 14:52:16.820709  4911 net.cpp:406] penlu44 <- Convolution46
I0926 14:52:16.820713  4911 net.cpp:367] penlu44 -> Convolution46 (in-place)
I0926 14:52:16.820829  4911 net.cpp:122] Setting up penlu44
I0926 14:52:16.820834  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.820837  4911 net.cpp:137] Memory required for data: 833862800
I0926 14:52:16.820840  4911 layer_factory.hpp:77] Creating layer Convolution47
I0926 14:52:16.820847  4911 net.cpp:84] Creating Layer Convolution47
I0926 14:52:16.820849  4911 net.cpp:406] Convolution47 <- Convolution46
I0926 14:52:16.820854  4911 net.cpp:380] Convolution47 -> Convolution47
I0926 14:52:16.822520  4911 net.cpp:122] Setting up Convolution47
I0926 14:52:16.822528  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.822530  4911 net.cpp:137] Memory required for data: 835117200
I0926 14:52:16.822536  4911 layer_factory.hpp:77] Creating layer BatchNorm47
I0926 14:52:16.822540  4911 net.cpp:84] Creating Layer BatchNorm47
I0926 14:52:16.822543  4911 net.cpp:406] BatchNorm47 <- Convolution47
I0926 14:52:16.822547  4911 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I0926 14:52:16.822695  4911 net.cpp:122] Setting up BatchNorm47
I0926 14:52:16.822700  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.822701  4911 net.cpp:137] Memory required for data: 836371600
I0926 14:52:16.822706  4911 layer_factory.hpp:77] Creating layer Scale47
I0926 14:52:16.822716  4911 net.cpp:84] Creating Layer Scale47
I0926 14:52:16.822720  4911 net.cpp:406] Scale47 <- Convolution47
I0926 14:52:16.822723  4911 net.cpp:367] Scale47 -> Convolution47 (in-place)
I0926 14:52:16.822753  4911 layer_factory.hpp:77] Creating layer Scale47
I0926 14:52:16.822837  4911 net.cpp:122] Setting up Scale47
I0926 14:52:16.822842  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.822844  4911 net.cpp:137] Memory required for data: 837626000
I0926 14:52:16.822849  4911 layer_factory.hpp:77] Creating layer Eltwise22
I0926 14:52:16.822852  4911 net.cpp:84] Creating Layer Eltwise22
I0926 14:52:16.822854  4911 net.cpp:406] Eltwise22 <- Eltwise21_penlu43_0_split_1
I0926 14:52:16.822857  4911 net.cpp:406] Eltwise22 <- Convolution47
I0926 14:52:16.822861  4911 net.cpp:380] Eltwise22 -> Eltwise22
I0926 14:52:16.822878  4911 net.cpp:122] Setting up Eltwise22
I0926 14:52:16.822882  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.822885  4911 net.cpp:137] Memory required for data: 838880400
I0926 14:52:16.822886  4911 layer_factory.hpp:77] Creating layer penlu45
I0926 14:52:16.822892  4911 net.cpp:84] Creating Layer penlu45
I0926 14:52:16.822895  4911 net.cpp:406] penlu45 <- Eltwise22
I0926 14:52:16.822898  4911 net.cpp:367] penlu45 -> Eltwise22 (in-place)
I0926 14:52:16.823015  4911 net.cpp:122] Setting up penlu45
I0926 14:52:16.823019  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.823021  4911 net.cpp:137] Memory required for data: 840134800
I0926 14:52:16.823026  4911 layer_factory.hpp:77] Creating layer Eltwise22_penlu45_0_split
I0926 14:52:16.823029  4911 net.cpp:84] Creating Layer Eltwise22_penlu45_0_split
I0926 14:52:16.823031  4911 net.cpp:406] Eltwise22_penlu45_0_split <- Eltwise22
I0926 14:52:16.823035  4911 net.cpp:380] Eltwise22_penlu45_0_split -> Eltwise22_penlu45_0_split_0
I0926 14:52:16.823040  4911 net.cpp:380] Eltwise22_penlu45_0_split -> Eltwise22_penlu45_0_split_1
I0926 14:52:16.823065  4911 net.cpp:122] Setting up Eltwise22_penlu45_0_split
I0926 14:52:16.823068  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.823071  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.823072  4911 net.cpp:137] Memory required for data: 842643600
I0926 14:52:16.823076  4911 layer_factory.hpp:77] Creating layer Convolution48
I0926 14:52:16.823081  4911 net.cpp:84] Creating Layer Convolution48
I0926 14:52:16.823083  4911 net.cpp:406] Convolution48 <- Eltwise22_penlu45_0_split_0
I0926 14:52:16.823087  4911 net.cpp:380] Convolution48 -> Convolution48
I0926 14:52:16.824782  4911 net.cpp:122] Setting up Convolution48
I0926 14:52:16.824791  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.824795  4911 net.cpp:137] Memory required for data: 843898000
I0926 14:52:16.824798  4911 layer_factory.hpp:77] Creating layer BatchNorm48
I0926 14:52:16.824803  4911 net.cpp:84] Creating Layer BatchNorm48
I0926 14:52:16.824805  4911 net.cpp:406] BatchNorm48 <- Convolution48
I0926 14:52:16.824810  4911 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I0926 14:52:16.824955  4911 net.cpp:122] Setting up BatchNorm48
I0926 14:52:16.824960  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.824962  4911 net.cpp:137] Memory required for data: 845152400
I0926 14:52:16.824966  4911 layer_factory.hpp:77] Creating layer Scale48
I0926 14:52:16.824970  4911 net.cpp:84] Creating Layer Scale48
I0926 14:52:16.824973  4911 net.cpp:406] Scale48 <- Convolution48
I0926 14:52:16.824977  4911 net.cpp:367] Scale48 -> Convolution48 (in-place)
I0926 14:52:16.825004  4911 layer_factory.hpp:77] Creating layer Scale48
I0926 14:52:16.825086  4911 net.cpp:122] Setting up Scale48
I0926 14:52:16.825091  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.825093  4911 net.cpp:137] Memory required for data: 846406800
I0926 14:52:16.825098  4911 layer_factory.hpp:77] Creating layer penlu46
I0926 14:52:16.825103  4911 net.cpp:84] Creating Layer penlu46
I0926 14:52:16.825105  4911 net.cpp:406] penlu46 <- Convolution48
I0926 14:52:16.825109  4911 net.cpp:367] penlu46 -> Convolution48 (in-place)
I0926 14:52:16.825232  4911 net.cpp:122] Setting up penlu46
I0926 14:52:16.825237  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.825239  4911 net.cpp:137] Memory required for data: 847661200
I0926 14:52:16.825244  4911 layer_factory.hpp:77] Creating layer Convolution49
I0926 14:52:16.825250  4911 net.cpp:84] Creating Layer Convolution49
I0926 14:52:16.825253  4911 net.cpp:406] Convolution49 <- Convolution48
I0926 14:52:16.825258  4911 net.cpp:380] Convolution49 -> Convolution49
I0926 14:52:16.827250  4911 net.cpp:122] Setting up Convolution49
I0926 14:52:16.827258  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.827260  4911 net.cpp:137] Memory required for data: 848915600
I0926 14:52:16.827265  4911 layer_factory.hpp:77] Creating layer BatchNorm49
I0926 14:52:16.827270  4911 net.cpp:84] Creating Layer BatchNorm49
I0926 14:52:16.827273  4911 net.cpp:406] BatchNorm49 <- Convolution49
I0926 14:52:16.827278  4911 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I0926 14:52:16.827425  4911 net.cpp:122] Setting up BatchNorm49
I0926 14:52:16.827428  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.827430  4911 net.cpp:137] Memory required for data: 850170000
I0926 14:52:16.827435  4911 layer_factory.hpp:77] Creating layer Scale49
I0926 14:52:16.827440  4911 net.cpp:84] Creating Layer Scale49
I0926 14:52:16.827443  4911 net.cpp:406] Scale49 <- Convolution49
I0926 14:52:16.827446  4911 net.cpp:367] Scale49 -> Convolution49 (in-place)
I0926 14:52:16.827474  4911 layer_factory.hpp:77] Creating layer Scale49
I0926 14:52:16.827558  4911 net.cpp:122] Setting up Scale49
I0926 14:52:16.827564  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.827565  4911 net.cpp:137] Memory required for data: 851424400
I0926 14:52:16.827569  4911 layer_factory.hpp:77] Creating layer Eltwise23
I0926 14:52:16.827572  4911 net.cpp:84] Creating Layer Eltwise23
I0926 14:52:16.827575  4911 net.cpp:406] Eltwise23 <- Eltwise22_penlu45_0_split_1
I0926 14:52:16.827579  4911 net.cpp:406] Eltwise23 <- Convolution49
I0926 14:52:16.827582  4911 net.cpp:380] Eltwise23 -> Eltwise23
I0926 14:52:16.827599  4911 net.cpp:122] Setting up Eltwise23
I0926 14:52:16.827602  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.827605  4911 net.cpp:137] Memory required for data: 852678800
I0926 14:52:16.827606  4911 layer_factory.hpp:77] Creating layer penlu47
I0926 14:52:16.827612  4911 net.cpp:84] Creating Layer penlu47
I0926 14:52:16.827615  4911 net.cpp:406] penlu47 <- Eltwise23
I0926 14:52:16.827617  4911 net.cpp:367] penlu47 -> Eltwise23 (in-place)
I0926 14:52:16.827734  4911 net.cpp:122] Setting up penlu47
I0926 14:52:16.827739  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.827740  4911 net.cpp:137] Memory required for data: 853933200
I0926 14:52:16.827745  4911 layer_factory.hpp:77] Creating layer Eltwise23_penlu47_0_split
I0926 14:52:16.827749  4911 net.cpp:84] Creating Layer Eltwise23_penlu47_0_split
I0926 14:52:16.827751  4911 net.cpp:406] Eltwise23_penlu47_0_split <- Eltwise23
I0926 14:52:16.827755  4911 net.cpp:380] Eltwise23_penlu47_0_split -> Eltwise23_penlu47_0_split_0
I0926 14:52:16.827759  4911 net.cpp:380] Eltwise23_penlu47_0_split -> Eltwise23_penlu47_0_split_1
I0926 14:52:16.827783  4911 net.cpp:122] Setting up Eltwise23_penlu47_0_split
I0926 14:52:16.827787  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.827790  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.827791  4911 net.cpp:137] Memory required for data: 856442000
I0926 14:52:16.827795  4911 layer_factory.hpp:77] Creating layer Convolution50
I0926 14:52:16.827800  4911 net.cpp:84] Creating Layer Convolution50
I0926 14:52:16.827802  4911 net.cpp:406] Convolution50 <- Eltwise23_penlu47_0_split_0
I0926 14:52:16.827806  4911 net.cpp:380] Convolution50 -> Convolution50
I0926 14:52:16.829519  4911 net.cpp:122] Setting up Convolution50
I0926 14:52:16.829529  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.829531  4911 net.cpp:137] Memory required for data: 857696400
I0926 14:52:16.829542  4911 layer_factory.hpp:77] Creating layer BatchNorm50
I0926 14:52:16.829548  4911 net.cpp:84] Creating Layer BatchNorm50
I0926 14:52:16.829551  4911 net.cpp:406] BatchNorm50 <- Convolution50
I0926 14:52:16.829555  4911 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I0926 14:52:16.829701  4911 net.cpp:122] Setting up BatchNorm50
I0926 14:52:16.829705  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.829708  4911 net.cpp:137] Memory required for data: 858950800
I0926 14:52:16.829712  4911 layer_factory.hpp:77] Creating layer Scale50
I0926 14:52:16.829716  4911 net.cpp:84] Creating Layer Scale50
I0926 14:52:16.829720  4911 net.cpp:406] Scale50 <- Convolution50
I0926 14:52:16.829722  4911 net.cpp:367] Scale50 -> Convolution50 (in-place)
I0926 14:52:16.829754  4911 layer_factory.hpp:77] Creating layer Scale50
I0926 14:52:16.829838  4911 net.cpp:122] Setting up Scale50
I0926 14:52:16.829843  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.835923  4911 net.cpp:137] Memory required for data: 860205200
I0926 14:52:16.835934  4911 layer_factory.hpp:77] Creating layer penlu48
I0926 14:52:16.835942  4911 net.cpp:84] Creating Layer penlu48
I0926 14:52:16.835945  4911 net.cpp:406] penlu48 <- Convolution50
I0926 14:52:16.835950  4911 net.cpp:367] penlu48 -> Convolution50 (in-place)
I0926 14:52:16.836082  4911 net.cpp:122] Setting up penlu48
I0926 14:52:16.836087  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.836091  4911 net.cpp:137] Memory required for data: 861459600
I0926 14:52:16.836096  4911 layer_factory.hpp:77] Creating layer Convolution51
I0926 14:52:16.836102  4911 net.cpp:84] Creating Layer Convolution51
I0926 14:52:16.836104  4911 net.cpp:406] Convolution51 <- Convolution50
I0926 14:52:16.836109  4911 net.cpp:380] Convolution51 -> Convolution51
I0926 14:52:16.838600  4911 net.cpp:122] Setting up Convolution51
I0926 14:52:16.838610  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.838613  4911 net.cpp:137] Memory required for data: 862714000
I0926 14:52:16.838618  4911 layer_factory.hpp:77] Creating layer BatchNorm51
I0926 14:52:16.838624  4911 net.cpp:84] Creating Layer BatchNorm51
I0926 14:52:16.838626  4911 net.cpp:406] BatchNorm51 <- Convolution51
I0926 14:52:16.838630  4911 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I0926 14:52:16.838783  4911 net.cpp:122] Setting up BatchNorm51
I0926 14:52:16.838786  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.838788  4911 net.cpp:137] Memory required for data: 863968400
I0926 14:52:16.838793  4911 layer_factory.hpp:77] Creating layer Scale51
I0926 14:52:16.838799  4911 net.cpp:84] Creating Layer Scale51
I0926 14:52:16.838801  4911 net.cpp:406] Scale51 <- Convolution51
I0926 14:52:16.838805  4911 net.cpp:367] Scale51 -> Convolution51 (in-place)
I0926 14:52:16.838835  4911 layer_factory.hpp:77] Creating layer Scale51
I0926 14:52:16.838920  4911 net.cpp:122] Setting up Scale51
I0926 14:52:16.838924  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.838927  4911 net.cpp:137] Memory required for data: 865222800
I0926 14:52:16.838930  4911 layer_factory.hpp:77] Creating layer Eltwise24
I0926 14:52:16.838935  4911 net.cpp:84] Creating Layer Eltwise24
I0926 14:52:16.838938  4911 net.cpp:406] Eltwise24 <- Eltwise23_penlu47_0_split_1
I0926 14:52:16.838940  4911 net.cpp:406] Eltwise24 <- Convolution51
I0926 14:52:16.838944  4911 net.cpp:380] Eltwise24 -> Eltwise24
I0926 14:52:16.838963  4911 net.cpp:122] Setting up Eltwise24
I0926 14:52:16.838965  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.838968  4911 net.cpp:137] Memory required for data: 866477200
I0926 14:52:16.838969  4911 layer_factory.hpp:77] Creating layer penlu49
I0926 14:52:16.838975  4911 net.cpp:84] Creating Layer penlu49
I0926 14:52:16.838977  4911 net.cpp:406] penlu49 <- Eltwise24
I0926 14:52:16.838980  4911 net.cpp:367] penlu49 -> Eltwise24 (in-place)
I0926 14:52:16.839102  4911 net.cpp:122] Setting up penlu49
I0926 14:52:16.839107  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.839114  4911 net.cpp:137] Memory required for data: 867731600
I0926 14:52:16.839119  4911 layer_factory.hpp:77] Creating layer Eltwise24_penlu49_0_split
I0926 14:52:16.839133  4911 net.cpp:84] Creating Layer Eltwise24_penlu49_0_split
I0926 14:52:16.839136  4911 net.cpp:406] Eltwise24_penlu49_0_split <- Eltwise24
I0926 14:52:16.839139  4911 net.cpp:380] Eltwise24_penlu49_0_split -> Eltwise24_penlu49_0_split_0
I0926 14:52:16.839144  4911 net.cpp:380] Eltwise24_penlu49_0_split -> Eltwise24_penlu49_0_split_1
I0926 14:52:16.839180  4911 net.cpp:122] Setting up Eltwise24_penlu49_0_split
I0926 14:52:16.839184  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.839186  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.839188  4911 net.cpp:137] Memory required for data: 870240400
I0926 14:52:16.839191  4911 layer_factory.hpp:77] Creating layer Convolution52
I0926 14:52:16.839208  4911 net.cpp:84] Creating Layer Convolution52
I0926 14:52:16.839211  4911 net.cpp:406] Convolution52 <- Eltwise24_penlu49_0_split_0
I0926 14:52:16.839215  4911 net.cpp:380] Convolution52 -> Convolution52
I0926 14:52:16.840961  4911 net.cpp:122] Setting up Convolution52
I0926 14:52:16.840970  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.840972  4911 net.cpp:137] Memory required for data: 871494800
I0926 14:52:16.840977  4911 layer_factory.hpp:77] Creating layer BatchNorm52
I0926 14:52:16.840982  4911 net.cpp:84] Creating Layer BatchNorm52
I0926 14:52:16.840986  4911 net.cpp:406] BatchNorm52 <- Convolution52
I0926 14:52:16.840989  4911 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I0926 14:52:16.841133  4911 net.cpp:122] Setting up BatchNorm52
I0926 14:52:16.841138  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.841140  4911 net.cpp:137] Memory required for data: 872749200
I0926 14:52:16.841145  4911 layer_factory.hpp:77] Creating layer Scale52
I0926 14:52:16.841150  4911 net.cpp:84] Creating Layer Scale52
I0926 14:52:16.841152  4911 net.cpp:406] Scale52 <- Convolution52
I0926 14:52:16.841156  4911 net.cpp:367] Scale52 -> Convolution52 (in-place)
I0926 14:52:16.841183  4911 layer_factory.hpp:77] Creating layer Scale52
I0926 14:52:16.841269  4911 net.cpp:122] Setting up Scale52
I0926 14:52:16.841272  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.841274  4911 net.cpp:137] Memory required for data: 874003600
I0926 14:52:16.841279  4911 layer_factory.hpp:77] Creating layer penlu50
I0926 14:52:16.841284  4911 net.cpp:84] Creating Layer penlu50
I0926 14:52:16.841286  4911 net.cpp:406] penlu50 <- Convolution52
I0926 14:52:16.841289  4911 net.cpp:367] penlu50 -> Convolution52 (in-place)
I0926 14:52:16.841405  4911 net.cpp:122] Setting up penlu50
I0926 14:52:16.841410  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.841413  4911 net.cpp:137] Memory required for data: 875258000
I0926 14:52:16.841454  4911 layer_factory.hpp:77] Creating layer Convolution53
I0926 14:52:16.841476  4911 net.cpp:84] Creating Layer Convolution53
I0926 14:52:16.841478  4911 net.cpp:406] Convolution53 <- Convolution52
I0926 14:52:16.841482  4911 net.cpp:380] Convolution53 -> Convolution53
I0926 14:52:16.843453  4911 net.cpp:122] Setting up Convolution53
I0926 14:52:16.843462  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.843466  4911 net.cpp:137] Memory required for data: 876512400
I0926 14:52:16.843469  4911 layer_factory.hpp:77] Creating layer BatchNorm53
I0926 14:52:16.843477  4911 net.cpp:84] Creating Layer BatchNorm53
I0926 14:52:16.843479  4911 net.cpp:406] BatchNorm53 <- Convolution53
I0926 14:52:16.843483  4911 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I0926 14:52:16.843629  4911 net.cpp:122] Setting up BatchNorm53
I0926 14:52:16.843634  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.843636  4911 net.cpp:137] Memory required for data: 877766800
I0926 14:52:16.843641  4911 layer_factory.hpp:77] Creating layer Scale53
I0926 14:52:16.843646  4911 net.cpp:84] Creating Layer Scale53
I0926 14:52:16.843655  4911 net.cpp:406] Scale53 <- Convolution53
I0926 14:52:16.843659  4911 net.cpp:367] Scale53 -> Convolution53 (in-place)
I0926 14:52:16.843689  4911 layer_factory.hpp:77] Creating layer Scale53
I0926 14:52:16.843772  4911 net.cpp:122] Setting up Scale53
I0926 14:52:16.843777  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.843780  4911 net.cpp:137] Memory required for data: 879021200
I0926 14:52:16.843783  4911 layer_factory.hpp:77] Creating layer Eltwise25
I0926 14:52:16.843787  4911 net.cpp:84] Creating Layer Eltwise25
I0926 14:52:16.843791  4911 net.cpp:406] Eltwise25 <- Eltwise24_penlu49_0_split_1
I0926 14:52:16.843793  4911 net.cpp:406] Eltwise25 <- Convolution53
I0926 14:52:16.843796  4911 net.cpp:380] Eltwise25 -> Eltwise25
I0926 14:52:16.843813  4911 net.cpp:122] Setting up Eltwise25
I0926 14:52:16.843816  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.843818  4911 net.cpp:137] Memory required for data: 880275600
I0926 14:52:16.843822  4911 layer_factory.hpp:77] Creating layer penlu51
I0926 14:52:16.843827  4911 net.cpp:84] Creating Layer penlu51
I0926 14:52:16.843828  4911 net.cpp:406] penlu51 <- Eltwise25
I0926 14:52:16.843832  4911 net.cpp:367] penlu51 -> Eltwise25 (in-place)
I0926 14:52:16.843946  4911 net.cpp:122] Setting up penlu51
I0926 14:52:16.843951  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.843953  4911 net.cpp:137] Memory required for data: 881530000
I0926 14:52:16.843957  4911 layer_factory.hpp:77] Creating layer Eltwise25_penlu51_0_split
I0926 14:52:16.843961  4911 net.cpp:84] Creating Layer Eltwise25_penlu51_0_split
I0926 14:52:16.843962  4911 net.cpp:406] Eltwise25_penlu51_0_split <- Eltwise25
I0926 14:52:16.843966  4911 net.cpp:380] Eltwise25_penlu51_0_split -> Eltwise25_penlu51_0_split_0
I0926 14:52:16.843971  4911 net.cpp:380] Eltwise25_penlu51_0_split -> Eltwise25_penlu51_0_split_1
I0926 14:52:16.843994  4911 net.cpp:122] Setting up Eltwise25_penlu51_0_split
I0926 14:52:16.843998  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.844002  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.844003  4911 net.cpp:137] Memory required for data: 884038800
I0926 14:52:16.844005  4911 layer_factory.hpp:77] Creating layer Convolution54
I0926 14:52:16.844012  4911 net.cpp:84] Creating Layer Convolution54
I0926 14:52:16.844014  4911 net.cpp:406] Convolution54 <- Eltwise25_penlu51_0_split_0
I0926 14:52:16.844017  4911 net.cpp:380] Convolution54 -> Convolution54
I0926 14:52:16.846201  4911 net.cpp:122] Setting up Convolution54
I0926 14:52:16.846211  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.846215  4911 net.cpp:137] Memory required for data: 885293200
I0926 14:52:16.846218  4911 layer_factory.hpp:77] Creating layer BatchNorm54
I0926 14:52:16.846223  4911 net.cpp:84] Creating Layer BatchNorm54
I0926 14:52:16.846226  4911 net.cpp:406] BatchNorm54 <- Convolution54
I0926 14:52:16.846231  4911 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I0926 14:52:16.846376  4911 net.cpp:122] Setting up BatchNorm54
I0926 14:52:16.846380  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.846384  4911 net.cpp:137] Memory required for data: 886547600
I0926 14:52:16.846387  4911 layer_factory.hpp:77] Creating layer Scale54
I0926 14:52:16.846391  4911 net.cpp:84] Creating Layer Scale54
I0926 14:52:16.846395  4911 net.cpp:406] Scale54 <- Convolution54
I0926 14:52:16.846397  4911 net.cpp:367] Scale54 -> Convolution54 (in-place)
I0926 14:52:16.846427  4911 layer_factory.hpp:77] Creating layer Scale54
I0926 14:52:16.846510  4911 net.cpp:122] Setting up Scale54
I0926 14:52:16.846514  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.846518  4911 net.cpp:137] Memory required for data: 887802000
I0926 14:52:16.846520  4911 layer_factory.hpp:77] Creating layer penlu52
I0926 14:52:16.846525  4911 net.cpp:84] Creating Layer penlu52
I0926 14:52:16.846527  4911 net.cpp:406] penlu52 <- Convolution54
I0926 14:52:16.846531  4911 net.cpp:367] penlu52 -> Convolution54 (in-place)
I0926 14:52:16.846657  4911 net.cpp:122] Setting up penlu52
I0926 14:52:16.846662  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.846664  4911 net.cpp:137] Memory required for data: 889056400
I0926 14:52:16.846668  4911 layer_factory.hpp:77] Creating layer Convolution55
I0926 14:52:16.846675  4911 net.cpp:84] Creating Layer Convolution55
I0926 14:52:16.846678  4911 net.cpp:406] Convolution55 <- Convolution54
I0926 14:52:16.846681  4911 net.cpp:380] Convolution55 -> Convolution55
I0926 14:52:16.848668  4911 net.cpp:122] Setting up Convolution55
I0926 14:52:16.848677  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.848680  4911 net.cpp:137] Memory required for data: 890310800
I0926 14:52:16.848685  4911 layer_factory.hpp:77] Creating layer BatchNorm55
I0926 14:52:16.848690  4911 net.cpp:84] Creating Layer BatchNorm55
I0926 14:52:16.848693  4911 net.cpp:406] BatchNorm55 <- Convolution55
I0926 14:52:16.848696  4911 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I0926 14:52:16.848847  4911 net.cpp:122] Setting up BatchNorm55
I0926 14:52:16.848851  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.848853  4911 net.cpp:137] Memory required for data: 891565200
I0926 14:52:16.848858  4911 layer_factory.hpp:77] Creating layer Scale55
I0926 14:52:16.848862  4911 net.cpp:84] Creating Layer Scale55
I0926 14:52:16.848865  4911 net.cpp:406] Scale55 <- Convolution55
I0926 14:52:16.848868  4911 net.cpp:367] Scale55 -> Convolution55 (in-place)
I0926 14:52:16.848897  4911 layer_factory.hpp:77] Creating layer Scale55
I0926 14:52:16.848980  4911 net.cpp:122] Setting up Scale55
I0926 14:52:16.848984  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.848986  4911 net.cpp:137] Memory required for data: 892819600
I0926 14:52:16.848990  4911 layer_factory.hpp:77] Creating layer Eltwise26
I0926 14:52:16.848994  4911 net.cpp:84] Creating Layer Eltwise26
I0926 14:52:16.848997  4911 net.cpp:406] Eltwise26 <- Eltwise25_penlu51_0_split_1
I0926 14:52:16.849000  4911 net.cpp:406] Eltwise26 <- Convolution55
I0926 14:52:16.849004  4911 net.cpp:380] Eltwise26 -> Eltwise26
I0926 14:52:16.849020  4911 net.cpp:122] Setting up Eltwise26
I0926 14:52:16.849023  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.849025  4911 net.cpp:137] Memory required for data: 894074000
I0926 14:52:16.849027  4911 layer_factory.hpp:77] Creating layer penlu53
I0926 14:52:16.849032  4911 net.cpp:84] Creating Layer penlu53
I0926 14:52:16.849035  4911 net.cpp:406] penlu53 <- Eltwise26
I0926 14:52:16.849038  4911 net.cpp:367] penlu53 -> Eltwise26 (in-place)
I0926 14:52:16.849156  4911 net.cpp:122] Setting up penlu53
I0926 14:52:16.849161  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.849164  4911 net.cpp:137] Memory required for data: 895328400
I0926 14:52:16.849167  4911 layer_factory.hpp:77] Creating layer Eltwise26_penlu53_0_split
I0926 14:52:16.849172  4911 net.cpp:84] Creating Layer Eltwise26_penlu53_0_split
I0926 14:52:16.849174  4911 net.cpp:406] Eltwise26_penlu53_0_split <- Eltwise26
I0926 14:52:16.849179  4911 net.cpp:380] Eltwise26_penlu53_0_split -> Eltwise26_penlu53_0_split_0
I0926 14:52:16.849182  4911 net.cpp:380] Eltwise26_penlu53_0_split -> Eltwise26_penlu53_0_split_1
I0926 14:52:16.849206  4911 net.cpp:122] Setting up Eltwise26_penlu53_0_split
I0926 14:52:16.849210  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.849213  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.849215  4911 net.cpp:137] Memory required for data: 897837200
I0926 14:52:16.849217  4911 layer_factory.hpp:77] Creating layer Convolution56
I0926 14:52:16.849222  4911 net.cpp:84] Creating Layer Convolution56
I0926 14:52:16.849225  4911 net.cpp:406] Convolution56 <- Eltwise26_penlu53_0_split_0
I0926 14:52:16.849230  4911 net.cpp:380] Convolution56 -> Convolution56
I0926 14:52:16.850890  4911 net.cpp:122] Setting up Convolution56
I0926 14:52:16.850898  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.850901  4911 net.cpp:137] Memory required for data: 899091600
I0926 14:52:16.850911  4911 layer_factory.hpp:77] Creating layer BatchNorm56
I0926 14:52:16.850917  4911 net.cpp:84] Creating Layer BatchNorm56
I0926 14:52:16.850920  4911 net.cpp:406] BatchNorm56 <- Convolution56
I0926 14:52:16.850924  4911 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I0926 14:52:16.851073  4911 net.cpp:122] Setting up BatchNorm56
I0926 14:52:16.851078  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.851080  4911 net.cpp:137] Memory required for data: 900346000
I0926 14:52:16.851084  4911 layer_factory.hpp:77] Creating layer Scale56
I0926 14:52:16.851089  4911 net.cpp:84] Creating Layer Scale56
I0926 14:52:16.851091  4911 net.cpp:406] Scale56 <- Convolution56
I0926 14:52:16.851094  4911 net.cpp:367] Scale56 -> Convolution56 (in-place)
I0926 14:52:16.851125  4911 layer_factory.hpp:77] Creating layer Scale56
I0926 14:52:16.866463  4911 net.cpp:122] Setting up Scale56
I0926 14:52:16.866473  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.866477  4911 net.cpp:137] Memory required for data: 901600400
I0926 14:52:16.866482  4911 layer_factory.hpp:77] Creating layer penlu54
I0926 14:52:16.866487  4911 net.cpp:84] Creating Layer penlu54
I0926 14:52:16.866490  4911 net.cpp:406] penlu54 <- Convolution56
I0926 14:52:16.866495  4911 net.cpp:367] penlu54 -> Convolution56 (in-place)
I0926 14:52:16.866631  4911 net.cpp:122] Setting up penlu54
I0926 14:52:16.866636  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.866638  4911 net.cpp:137] Memory required for data: 902854800
I0926 14:52:16.866643  4911 layer_factory.hpp:77] Creating layer Convolution57
I0926 14:52:16.866650  4911 net.cpp:84] Creating Layer Convolution57
I0926 14:52:16.866653  4911 net.cpp:406] Convolution57 <- Convolution56
I0926 14:52:16.866658  4911 net.cpp:380] Convolution57 -> Convolution57
I0926 14:52:16.868469  4911 net.cpp:122] Setting up Convolution57
I0926 14:52:16.868489  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.868490  4911 net.cpp:137] Memory required for data: 904109200
I0926 14:52:16.868505  4911 layer_factory.hpp:77] Creating layer BatchNorm57
I0926 14:52:16.868510  4911 net.cpp:84] Creating Layer BatchNorm57
I0926 14:52:16.868513  4911 net.cpp:406] BatchNorm57 <- Convolution57
I0926 14:52:16.868517  4911 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I0926 14:52:16.868707  4911 net.cpp:122] Setting up BatchNorm57
I0926 14:52:16.868713  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.868716  4911 net.cpp:137] Memory required for data: 905363600
I0926 14:52:16.868721  4911 layer_factory.hpp:77] Creating layer Scale57
I0926 14:52:16.868724  4911 net.cpp:84] Creating Layer Scale57
I0926 14:52:16.868727  4911 net.cpp:406] Scale57 <- Convolution57
I0926 14:52:16.868731  4911 net.cpp:367] Scale57 -> Convolution57 (in-place)
I0926 14:52:16.868762  4911 layer_factory.hpp:77] Creating layer Scale57
I0926 14:52:16.868854  4911 net.cpp:122] Setting up Scale57
I0926 14:52:16.868860  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.868861  4911 net.cpp:137] Memory required for data: 906618000
I0926 14:52:16.868865  4911 layer_factory.hpp:77] Creating layer Eltwise27
I0926 14:52:16.868870  4911 net.cpp:84] Creating Layer Eltwise27
I0926 14:52:16.868873  4911 net.cpp:406] Eltwise27 <- Eltwise26_penlu53_0_split_1
I0926 14:52:16.868876  4911 net.cpp:406] Eltwise27 <- Convolution57
I0926 14:52:16.868880  4911 net.cpp:380] Eltwise27 -> Eltwise27
I0926 14:52:16.868898  4911 net.cpp:122] Setting up Eltwise27
I0926 14:52:16.868902  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.868904  4911 net.cpp:137] Memory required for data: 907872400
I0926 14:52:16.868906  4911 layer_factory.hpp:77] Creating layer penlu55
I0926 14:52:16.868912  4911 net.cpp:84] Creating Layer penlu55
I0926 14:52:16.868914  4911 net.cpp:406] penlu55 <- Eltwise27
I0926 14:52:16.868918  4911 net.cpp:367] penlu55 -> Eltwise27 (in-place)
I0926 14:52:16.869043  4911 net.cpp:122] Setting up penlu55
I0926 14:52:16.869048  4911 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 14:52:16.869057  4911 net.cpp:137] Memory required for data: 909126800
I0926 14:52:16.869062  4911 layer_factory.hpp:77] Creating layer Pooling1
I0926 14:52:16.869067  4911 net.cpp:84] Creating Layer Pooling1
I0926 14:52:16.869071  4911 net.cpp:406] Pooling1 <- Eltwise27
I0926 14:52:16.869074  4911 net.cpp:380] Pooling1 -> Pooling1
I0926 14:52:16.869567  4911 net.cpp:122] Setting up Pooling1
I0926 14:52:16.869576  4911 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0926 14:52:16.869580  4911 net.cpp:137] Memory required for data: 909152400
I0926 14:52:16.869581  4911 layer_factory.hpp:77] Creating layer InnerProduct1
I0926 14:52:16.869591  4911 net.cpp:84] Creating Layer InnerProduct1
I0926 14:52:16.869595  4911 net.cpp:406] InnerProduct1 <- Pooling1
I0926 14:52:16.869598  4911 net.cpp:380] InnerProduct1 -> InnerProduct1
I0926 14:52:16.869710  4911 net.cpp:122] Setting up InnerProduct1
I0926 14:52:16.869715  4911 net.cpp:129] Top shape: 100 10 (1000)
I0926 14:52:16.869717  4911 net.cpp:137] Memory required for data: 909156400
I0926 14:52:16.869721  4911 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0926 14:52:16.869726  4911 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0926 14:52:16.869729  4911 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I0926 14:52:16.869731  4911 net.cpp:406] SoftmaxWithLoss1 <- Data2
I0926 14:52:16.869735  4911 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0926 14:52:16.869741  4911 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0926 14:52:16.869940  4911 net.cpp:122] Setting up SoftmaxWithLoss1
I0926 14:52:16.869947  4911 net.cpp:129] Top shape: (1)
I0926 14:52:16.869951  4911 net.cpp:132]     with loss weight 1
I0926 14:52:16.869963  4911 net.cpp:137] Memory required for data: 909156404
I0926 14:52:16.869966  4911 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0926 14:52:16.869968  4911 net.cpp:198] InnerProduct1 needs backward computation.
I0926 14:52:16.869971  4911 net.cpp:198] Pooling1 needs backward computation.
I0926 14:52:16.869972  4911 net.cpp:198] penlu55 needs backward computation.
I0926 14:52:16.869974  4911 net.cpp:198] Eltwise27 needs backward computation.
I0926 14:52:16.869977  4911 net.cpp:198] Scale57 needs backward computation.
I0926 14:52:16.869979  4911 net.cpp:198] BatchNorm57 needs backward computation.
I0926 14:52:16.869982  4911 net.cpp:198] Convolution57 needs backward computation.
I0926 14:52:16.869983  4911 net.cpp:198] penlu54 needs backward computation.
I0926 14:52:16.869985  4911 net.cpp:198] Scale56 needs backward computation.
I0926 14:52:16.869987  4911 net.cpp:198] BatchNorm56 needs backward computation.
I0926 14:52:16.869989  4911 net.cpp:198] Convolution56 needs backward computation.
I0926 14:52:16.869992  4911 net.cpp:198] Eltwise26_penlu53_0_split needs backward computation.
I0926 14:52:16.869993  4911 net.cpp:198] penlu53 needs backward computation.
I0926 14:52:16.869997  4911 net.cpp:198] Eltwise26 needs backward computation.
I0926 14:52:16.869998  4911 net.cpp:198] Scale55 needs backward computation.
I0926 14:52:16.870000  4911 net.cpp:198] BatchNorm55 needs backward computation.
I0926 14:52:16.870002  4911 net.cpp:198] Convolution55 needs backward computation.
I0926 14:52:16.870005  4911 net.cpp:198] penlu52 needs backward computation.
I0926 14:52:16.870007  4911 net.cpp:198] Scale54 needs backward computation.
I0926 14:52:16.870008  4911 net.cpp:198] BatchNorm54 needs backward computation.
I0926 14:52:16.870010  4911 net.cpp:198] Convolution54 needs backward computation.
I0926 14:52:16.870013  4911 net.cpp:198] Eltwise25_penlu51_0_split needs backward computation.
I0926 14:52:16.870015  4911 net.cpp:198] penlu51 needs backward computation.
I0926 14:52:16.870018  4911 net.cpp:198] Eltwise25 needs backward computation.
I0926 14:52:16.870020  4911 net.cpp:198] Scale53 needs backward computation.
I0926 14:52:16.870023  4911 net.cpp:198] BatchNorm53 needs backward computation.
I0926 14:52:16.870024  4911 net.cpp:198] Convolution53 needs backward computation.
I0926 14:52:16.870026  4911 net.cpp:198] penlu50 needs backward computation.
I0926 14:52:16.870035  4911 net.cpp:198] Scale52 needs backward computation.
I0926 14:52:16.870038  4911 net.cpp:198] BatchNorm52 needs backward computation.
I0926 14:52:16.870039  4911 net.cpp:198] Convolution52 needs backward computation.
I0926 14:52:16.870043  4911 net.cpp:198] Eltwise24_penlu49_0_split needs backward computation.
I0926 14:52:16.870044  4911 net.cpp:198] penlu49 needs backward computation.
I0926 14:52:16.870046  4911 net.cpp:198] Eltwise24 needs backward computation.
I0926 14:52:16.870049  4911 net.cpp:198] Scale51 needs backward computation.
I0926 14:52:16.870051  4911 net.cpp:198] BatchNorm51 needs backward computation.
I0926 14:52:16.870054  4911 net.cpp:198] Convolution51 needs backward computation.
I0926 14:52:16.870055  4911 net.cpp:198] penlu48 needs backward computation.
I0926 14:52:16.870059  4911 net.cpp:198] Scale50 needs backward computation.
I0926 14:52:16.870060  4911 net.cpp:198] BatchNorm50 needs backward computation.
I0926 14:52:16.870062  4911 net.cpp:198] Convolution50 needs backward computation.
I0926 14:52:16.870065  4911 net.cpp:198] Eltwise23_penlu47_0_split needs backward computation.
I0926 14:52:16.870067  4911 net.cpp:198] penlu47 needs backward computation.
I0926 14:52:16.870069  4911 net.cpp:198] Eltwise23 needs backward computation.
I0926 14:52:16.870072  4911 net.cpp:198] Scale49 needs backward computation.
I0926 14:52:16.870074  4911 net.cpp:198] BatchNorm49 needs backward computation.
I0926 14:52:16.870076  4911 net.cpp:198] Convolution49 needs backward computation.
I0926 14:52:16.870079  4911 net.cpp:198] penlu46 needs backward computation.
I0926 14:52:16.870081  4911 net.cpp:198] Scale48 needs backward computation.
I0926 14:52:16.870084  4911 net.cpp:198] BatchNorm48 needs backward computation.
I0926 14:52:16.870085  4911 net.cpp:198] Convolution48 needs backward computation.
I0926 14:52:16.870087  4911 net.cpp:198] Eltwise22_penlu45_0_split needs backward computation.
I0926 14:52:16.870090  4911 net.cpp:198] penlu45 needs backward computation.
I0926 14:52:16.870092  4911 net.cpp:198] Eltwise22 needs backward computation.
I0926 14:52:16.870095  4911 net.cpp:198] Scale47 needs backward computation.
I0926 14:52:16.870096  4911 net.cpp:198] BatchNorm47 needs backward computation.
I0926 14:52:16.870098  4911 net.cpp:198] Convolution47 needs backward computation.
I0926 14:52:16.870101  4911 net.cpp:198] penlu44 needs backward computation.
I0926 14:52:16.870103  4911 net.cpp:198] Scale46 needs backward computation.
I0926 14:52:16.870105  4911 net.cpp:198] BatchNorm46 needs backward computation.
I0926 14:52:16.870107  4911 net.cpp:198] Convolution46 needs backward computation.
I0926 14:52:16.870110  4911 net.cpp:198] Eltwise21_penlu43_0_split needs backward computation.
I0926 14:52:16.870112  4911 net.cpp:198] penlu43 needs backward computation.
I0926 14:52:16.870115  4911 net.cpp:198] Eltwise21 needs backward computation.
I0926 14:52:16.870116  4911 net.cpp:198] Scale45 needs backward computation.
I0926 14:52:16.870120  4911 net.cpp:198] BatchNorm45 needs backward computation.
I0926 14:52:16.870121  4911 net.cpp:198] Convolution45 needs backward computation.
I0926 14:52:16.870123  4911 net.cpp:198] penlu42 needs backward computation.
I0926 14:52:16.870126  4911 net.cpp:198] Scale44 needs backward computation.
I0926 14:52:16.870127  4911 net.cpp:198] BatchNorm44 needs backward computation.
I0926 14:52:16.870131  4911 net.cpp:198] Convolution44 needs backward computation.
I0926 14:52:16.870132  4911 net.cpp:198] Eltwise20_penlu41_0_split needs backward computation.
I0926 14:52:16.870134  4911 net.cpp:198] penlu41 needs backward computation.
I0926 14:52:16.870136  4911 net.cpp:198] Eltwise20 needs backward computation.
I0926 14:52:16.870139  4911 net.cpp:198] Scale43 needs backward computation.
I0926 14:52:16.870141  4911 net.cpp:198] BatchNorm43 needs backward computation.
I0926 14:52:16.870143  4911 net.cpp:198] Convolution43 needs backward computation.
I0926 14:52:16.870146  4911 net.cpp:198] penlu40 needs backward computation.
I0926 14:52:16.870148  4911 net.cpp:198] Scale42 needs backward computation.
I0926 14:52:16.870162  4911 net.cpp:198] BatchNorm42 needs backward computation.
I0926 14:52:16.870165  4911 net.cpp:198] Convolution42 needs backward computation.
I0926 14:52:16.870167  4911 net.cpp:198] Eltwise19_penlu39_0_split needs backward computation.
I0926 14:52:16.870170  4911 net.cpp:198] penlu39 needs backward computation.
I0926 14:52:16.870172  4911 net.cpp:198] Eltwise19 needs backward computation.
I0926 14:52:16.870175  4911 net.cpp:198] Scale41 needs backward computation.
I0926 14:52:16.870177  4911 net.cpp:198] BatchNorm41 needs backward computation.
I0926 14:52:16.870179  4911 net.cpp:198] Convolution41 needs backward computation.
I0926 14:52:16.870182  4911 net.cpp:198] penlu38 needs backward computation.
I0926 14:52:16.870184  4911 net.cpp:198] Scale40 needs backward computation.
I0926 14:52:16.870187  4911 net.cpp:198] BatchNorm40 needs backward computation.
I0926 14:52:16.870188  4911 net.cpp:198] Convolution40 needs backward computation.
I0926 14:52:16.870192  4911 net.cpp:198] Scale39 needs backward computation.
I0926 14:52:16.870193  4911 net.cpp:198] BatchNorm39 needs backward computation.
I0926 14:52:16.870195  4911 net.cpp:198] Convolution39 needs backward computation.
I0926 14:52:16.870198  4911 net.cpp:198] Eltwise18_penlu37_0_split needs backward computation.
I0926 14:52:16.870200  4911 net.cpp:198] penlu37 needs backward computation.
I0926 14:52:16.870203  4911 net.cpp:198] Eltwise18 needs backward computation.
I0926 14:52:16.870205  4911 net.cpp:198] Scale38 needs backward computation.
I0926 14:52:16.870208  4911 net.cpp:198] BatchNorm38 needs backward computation.
I0926 14:52:16.870210  4911 net.cpp:198] Convolution38 needs backward computation.
I0926 14:52:16.870213  4911 net.cpp:198] penlu36 needs backward computation.
I0926 14:52:16.870214  4911 net.cpp:198] Scale37 needs backward computation.
I0926 14:52:16.870216  4911 net.cpp:198] BatchNorm37 needs backward computation.
I0926 14:52:16.870219  4911 net.cpp:198] Convolution37 needs backward computation.
I0926 14:52:16.870221  4911 net.cpp:198] Eltwise17_penlu35_0_split needs backward computation.
I0926 14:52:16.870223  4911 net.cpp:198] penlu35 needs backward computation.
I0926 14:52:16.870225  4911 net.cpp:198] Eltwise17 needs backward computation.
I0926 14:52:16.870230  4911 net.cpp:198] Scale36 needs backward computation.
I0926 14:52:16.870234  4911 net.cpp:198] BatchNorm36 needs backward computation.
I0926 14:52:16.870235  4911 net.cpp:198] Convolution36 needs backward computation.
I0926 14:52:16.870237  4911 net.cpp:198] penlu34 needs backward computation.
I0926 14:52:16.870239  4911 net.cpp:198] Scale35 needs backward computation.
I0926 14:52:16.870242  4911 net.cpp:198] BatchNorm35 needs backward computation.
I0926 14:52:16.870244  4911 net.cpp:198] Convolution35 needs backward computation.
I0926 14:52:16.870246  4911 net.cpp:198] Eltwise16_penlu33_0_split needs backward computation.
I0926 14:52:16.870249  4911 net.cpp:198] penlu33 needs backward computation.
I0926 14:52:16.870251  4911 net.cpp:198] Eltwise16 needs backward computation.
I0926 14:52:16.870254  4911 net.cpp:198] Scale34 needs backward computation.
I0926 14:52:16.870256  4911 net.cpp:198] BatchNorm34 needs backward computation.
I0926 14:52:16.870259  4911 net.cpp:198] Convolution34 needs backward computation.
I0926 14:52:16.870260  4911 net.cpp:198] penlu32 needs backward computation.
I0926 14:52:16.870262  4911 net.cpp:198] Scale33 needs backward computation.
I0926 14:52:16.870265  4911 net.cpp:198] BatchNorm33 needs backward computation.
I0926 14:52:16.870266  4911 net.cpp:198] Convolution33 needs backward computation.
I0926 14:52:16.870270  4911 net.cpp:198] Eltwise15_penlu31_0_split needs backward computation.
I0926 14:52:16.870271  4911 net.cpp:198] penlu31 needs backward computation.
I0926 14:52:16.870273  4911 net.cpp:198] Eltwise15 needs backward computation.
I0926 14:52:16.870276  4911 net.cpp:198] Scale32 needs backward computation.
I0926 14:52:16.870278  4911 net.cpp:198] BatchNorm32 needs backward computation.
I0926 14:52:16.870283  4911 net.cpp:198] Convolution32 needs backward computation.
I0926 14:52:16.870286  4911 net.cpp:198] penlu30 needs backward computation.
I0926 14:52:16.870288  4911 net.cpp:198] Scale31 needs backward computation.
I0926 14:52:16.870290  4911 net.cpp:198] BatchNorm31 needs backward computation.
I0926 14:52:16.870292  4911 net.cpp:198] Convolution31 needs backward computation.
I0926 14:52:16.870296  4911 net.cpp:198] Eltwise14_penlu29_0_split needs backward computation.
I0926 14:52:16.870297  4911 net.cpp:198] penlu29 needs backward computation.
I0926 14:52:16.870299  4911 net.cpp:198] Eltwise14 needs backward computation.
I0926 14:52:16.870302  4911 net.cpp:198] Scale30 needs backward computation.
I0926 14:52:16.896677  4911 net.cpp:198] BatchNorm30 needs backward computation.
I0926 14:52:16.896685  4911 net.cpp:198] Convolution30 needs backward computation.
I0926 14:52:16.896688  4911 net.cpp:198] penlu28 needs backward computation.
I0926 14:52:16.896692  4911 net.cpp:198] Scale29 needs backward computation.
I0926 14:52:16.896693  4911 net.cpp:198] BatchNorm29 needs backward computation.
I0926 14:52:16.896695  4911 net.cpp:198] Convolution29 needs backward computation.
I0926 14:52:16.896699  4911 net.cpp:198] Eltwise13_penlu27_0_split needs backward computation.
I0926 14:52:16.896701  4911 net.cpp:198] penlu27 needs backward computation.
I0926 14:52:16.896704  4911 net.cpp:198] Eltwise13 needs backward computation.
I0926 14:52:16.896708  4911 net.cpp:198] Scale28 needs backward computation.
I0926 14:52:16.896710  4911 net.cpp:198] BatchNorm28 needs backward computation.
I0926 14:52:16.896713  4911 net.cpp:198] Convolution28 needs backward computation.
I0926 14:52:16.896715  4911 net.cpp:198] penlu26 needs backward computation.
I0926 14:52:16.896718  4911 net.cpp:198] Scale27 needs backward computation.
I0926 14:52:16.896720  4911 net.cpp:198] BatchNorm27 needs backward computation.
I0926 14:52:16.896724  4911 net.cpp:198] Convolution27 needs backward computation.
I0926 14:52:16.896728  4911 net.cpp:198] Eltwise12_penlu25_0_split needs backward computation.
I0926 14:52:16.896733  4911 net.cpp:198] penlu25 needs backward computation.
I0926 14:52:16.896737  4911 net.cpp:198] Eltwise12 needs backward computation.
I0926 14:52:16.896742  4911 net.cpp:198] Scale26 needs backward computation.
I0926 14:52:16.896746  4911 net.cpp:198] BatchNorm26 needs backward computation.
I0926 14:52:16.896750  4911 net.cpp:198] Convolution26 needs backward computation.
I0926 14:52:16.896754  4911 net.cpp:198] penlu24 needs backward computation.
I0926 14:52:16.896755  4911 net.cpp:198] Scale25 needs backward computation.
I0926 14:52:16.896759  4911 net.cpp:198] BatchNorm25 needs backward computation.
I0926 14:52:16.896760  4911 net.cpp:198] Convolution25 needs backward computation.
I0926 14:52:16.896764  4911 net.cpp:198] Eltwise11_penlu23_0_split needs backward computation.
I0926 14:52:16.896765  4911 net.cpp:198] penlu23 needs backward computation.
I0926 14:52:16.896769  4911 net.cpp:198] Eltwise11 needs backward computation.
I0926 14:52:16.896770  4911 net.cpp:198] Scale24 needs backward computation.
I0926 14:52:16.896773  4911 net.cpp:198] BatchNorm24 needs backward computation.
I0926 14:52:16.896775  4911 net.cpp:198] Convolution24 needs backward computation.
I0926 14:52:16.896778  4911 net.cpp:198] penlu22 needs backward computation.
I0926 14:52:16.896780  4911 net.cpp:198] Scale23 needs backward computation.
I0926 14:52:16.896783  4911 net.cpp:198] BatchNorm23 needs backward computation.
I0926 14:52:16.896785  4911 net.cpp:198] Convolution23 needs backward computation.
I0926 14:52:16.896788  4911 net.cpp:198] Eltwise10_penlu21_0_split needs backward computation.
I0926 14:52:16.896790  4911 net.cpp:198] penlu21 needs backward computation.
I0926 14:52:16.896795  4911 net.cpp:198] Eltwise10 needs backward computation.
I0926 14:52:16.896798  4911 net.cpp:198] Scale22 needs backward computation.
I0926 14:52:16.896800  4911 net.cpp:198] BatchNorm22 needs backward computation.
I0926 14:52:16.896803  4911 net.cpp:198] Convolution22 needs backward computation.
I0926 14:52:16.896813  4911 net.cpp:198] penlu20 needs backward computation.
I0926 14:52:16.896816  4911 net.cpp:198] Scale21 needs backward computation.
I0926 14:52:16.896819  4911 net.cpp:198] BatchNorm21 needs backward computation.
I0926 14:52:16.896821  4911 net.cpp:198] Convolution21 needs backward computation.
I0926 14:52:16.896824  4911 net.cpp:198] Scale20 needs backward computation.
I0926 14:52:16.896826  4911 net.cpp:198] BatchNorm20 needs backward computation.
I0926 14:52:16.896828  4911 net.cpp:198] Convolution20 needs backward computation.
I0926 14:52:16.896831  4911 net.cpp:198] Eltwise9_penlu19_0_split needs backward computation.
I0926 14:52:16.896834  4911 net.cpp:198] penlu19 needs backward computation.
I0926 14:52:16.896836  4911 net.cpp:198] Eltwise9 needs backward computation.
I0926 14:52:16.896839  4911 net.cpp:198] Scale19 needs backward computation.
I0926 14:52:16.896842  4911 net.cpp:198] BatchNorm19 needs backward computation.
I0926 14:52:16.896844  4911 net.cpp:198] Convolution19 needs backward computation.
I0926 14:52:16.896847  4911 net.cpp:198] penlu18 needs backward computation.
I0926 14:52:16.896849  4911 net.cpp:198] Scale18 needs backward computation.
I0926 14:52:16.896852  4911 net.cpp:198] BatchNorm18 needs backward computation.
I0926 14:52:16.896853  4911 net.cpp:198] Convolution18 needs backward computation.
I0926 14:52:16.896857  4911 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I0926 14:52:16.896859  4911 net.cpp:198] penlu17 needs backward computation.
I0926 14:52:16.896862  4911 net.cpp:198] Eltwise8 needs backward computation.
I0926 14:52:16.896864  4911 net.cpp:198] Scale17 needs backward computation.
I0926 14:52:16.896867  4911 net.cpp:198] BatchNorm17 needs backward computation.
I0926 14:52:16.896869  4911 net.cpp:198] Convolution17 needs backward computation.
I0926 14:52:16.896872  4911 net.cpp:198] penlu16 needs backward computation.
I0926 14:52:16.896873  4911 net.cpp:198] Scale16 needs backward computation.
I0926 14:52:16.896877  4911 net.cpp:198] BatchNorm16 needs backward computation.
I0926 14:52:16.896878  4911 net.cpp:198] Convolution16 needs backward computation.
I0926 14:52:16.896880  4911 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I0926 14:52:16.896883  4911 net.cpp:198] penlu15 needs backward computation.
I0926 14:52:16.896885  4911 net.cpp:198] Eltwise7 needs backward computation.
I0926 14:52:16.896888  4911 net.cpp:198] Scale15 needs backward computation.
I0926 14:52:16.896891  4911 net.cpp:198] BatchNorm15 needs backward computation.
I0926 14:52:16.896893  4911 net.cpp:198] Convolution15 needs backward computation.
I0926 14:52:16.896896  4911 net.cpp:198] penlu14 needs backward computation.
I0926 14:52:16.896898  4911 net.cpp:198] Scale14 needs backward computation.
I0926 14:52:16.896900  4911 net.cpp:198] BatchNorm14 needs backward computation.
I0926 14:52:16.896903  4911 net.cpp:198] Convolution14 needs backward computation.
I0926 14:52:16.896905  4911 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I0926 14:52:16.896908  4911 net.cpp:198] penlu13 needs backward computation.
I0926 14:52:16.896910  4911 net.cpp:198] Eltwise6 needs backward computation.
I0926 14:52:16.896914  4911 net.cpp:198] Scale13 needs backward computation.
I0926 14:52:16.896915  4911 net.cpp:198] BatchNorm13 needs backward computation.
I0926 14:52:16.896917  4911 net.cpp:198] Convolution13 needs backward computation.
I0926 14:52:16.896920  4911 net.cpp:198] penlu12 needs backward computation.
I0926 14:52:16.896922  4911 net.cpp:198] Scale12 needs backward computation.
I0926 14:52:16.896924  4911 net.cpp:198] BatchNorm12 needs backward computation.
I0926 14:52:16.896927  4911 net.cpp:198] Convolution12 needs backward computation.
I0926 14:52:16.896929  4911 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I0926 14:52:16.896932  4911 net.cpp:198] penlu11 needs backward computation.
I0926 14:52:16.896934  4911 net.cpp:198] Eltwise5 needs backward computation.
I0926 14:52:16.896940  4911 net.cpp:198] Scale11 needs backward computation.
I0926 14:52:16.896944  4911 net.cpp:198] BatchNorm11 needs backward computation.
I0926 14:52:16.896945  4911 net.cpp:198] Convolution11 needs backward computation.
I0926 14:52:16.896948  4911 net.cpp:198] penlu10 needs backward computation.
I0926 14:52:16.896950  4911 net.cpp:198] Scale10 needs backward computation.
I0926 14:52:16.896953  4911 net.cpp:198] BatchNorm10 needs backward computation.
I0926 14:52:16.896955  4911 net.cpp:198] Convolution10 needs backward computation.
I0926 14:52:16.896958  4911 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I0926 14:52:16.898859  4911 net.cpp:198] penlu9 needs backward computation.
I0926 14:52:16.898867  4911 net.cpp:198] Eltwise4 needs backward computation.
I0926 14:52:16.898882  4911 net.cpp:198] Scale9 needs backward computation.
I0926 14:52:16.898886  4911 net.cpp:198] BatchNorm9 needs backward computation.
I0926 14:52:16.898890  4911 net.cpp:198] Convolution9 needs backward computation.
I0926 14:52:16.898893  4911 net.cpp:198] penlu8 needs backward computation.
I0926 14:52:16.898897  4911 net.cpp:198] Scale8 needs backward computation.
I0926 14:52:16.898901  4911 net.cpp:198] BatchNorm8 needs backward computation.
I0926 14:52:16.898905  4911 net.cpp:198] Convolution8 needs backward computation.
I0926 14:52:16.898910  4911 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I0926 14:52:16.898913  4911 net.cpp:198] penlu7 needs backward computation.
I0926 14:52:16.898916  4911 net.cpp:198] Eltwise3 needs backward computation.
I0926 14:52:16.898921  4911 net.cpp:198] Scale7 needs backward computation.
I0926 14:52:16.898926  4911 net.cpp:198] BatchNorm7 needs backward computation.
I0926 14:52:16.898928  4911 net.cpp:198] Convolution7 needs backward computation.
I0926 14:52:16.898932  4911 net.cpp:198] penlu6 needs backward computation.
I0926 14:52:16.898936  4911 net.cpp:198] Scale6 needs backward computation.
I0926 14:52:16.898939  4911 net.cpp:198] BatchNorm6 needs backward computation.
I0926 14:52:16.898943  4911 net.cpp:198] Convolution6 needs backward computation.
I0926 14:52:16.898947  4911 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I0926 14:52:16.898949  4911 net.cpp:198] penlu5 needs backward computation.
I0926 14:52:16.898952  4911 net.cpp:198] Eltwise2 needs backward computation.
I0926 14:52:16.898955  4911 net.cpp:198] Scale5 needs backward computation.
I0926 14:52:16.898957  4911 net.cpp:198] BatchNorm5 needs backward computation.
I0926 14:52:16.898959  4911 net.cpp:198] Convolution5 needs backward computation.
I0926 14:52:16.898962  4911 net.cpp:198] penlu4 needs backward computation.
I0926 14:52:16.898964  4911 net.cpp:198] Scale4 needs backward computation.
I0926 14:52:16.898967  4911 net.cpp:198] BatchNorm4 needs backward computation.
I0926 14:52:16.898968  4911 net.cpp:198] Convolution4 needs backward computation.
I0926 14:52:16.898972  4911 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I0926 14:52:16.898973  4911 net.cpp:198] penlu3 needs backward computation.
I0926 14:52:16.898975  4911 net.cpp:198] Eltwise1 needs backward computation.
I0926 14:52:16.898979  4911 net.cpp:198] Scale3 needs backward computation.
I0926 14:52:16.898982  4911 net.cpp:198] BatchNorm3 needs backward computation.
I0926 14:52:16.898983  4911 net.cpp:198] Convolution3 needs backward computation.
I0926 14:52:16.898986  4911 net.cpp:198] penlu2 needs backward computation.
I0926 14:52:16.898988  4911 net.cpp:198] Scale2 needs backward computation.
I0926 14:52:16.898990  4911 net.cpp:198] BatchNorm2 needs backward computation.
I0926 14:52:16.898993  4911 net.cpp:198] Convolution2 needs backward computation.
I0926 14:52:16.898995  4911 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I0926 14:52:16.898998  4911 net.cpp:198] penlu1 needs backward computation.
I0926 14:52:16.898999  4911 net.cpp:198] Scale1 needs backward computation.
I0926 14:52:16.899003  4911 net.cpp:198] BatchNorm1 needs backward computation.
I0926 14:52:16.899004  4911 net.cpp:198] Convolution1 needs backward computation.
I0926 14:52:16.899013  4911 net.cpp:200] Data1 does not need backward computation.
I0926 14:52:16.899016  4911 net.cpp:242] This network produces output SoftmaxWithLoss1
I0926 14:52:16.899103  4911 net.cpp:255] Network initialization done.
I0926 14:52:16.903650  4911 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56_penlu_train_test.prototxt
I0926 14:52:16.903661  4911 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0926 14:52:16.903666  4911 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56_penlu_train_test.prototxt
I0926 14:52:16.903854  4911 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I0926 14:52:16.905076  4911 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu20"
  type: "PENLU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu21"
  type: "PENLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu22"
  type: "PENLU"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      
I0926 14:52:16.960314  4911 layer_factory.hpp:77] Creating layer Data1
I0926 14:52:16.960361  4911 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I0926 14:52:16.960372  4911 net.cpp:84] Creating Layer Data1
I0926 14:52:16.960376  4911 net.cpp:380] Data1 -> Data1
I0926 14:52:16.960384  4911 net.cpp:380] Data1 -> Data2
I0926 14:52:16.960389  4911 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0926 14:52:16.960587  4911 data_layer.cpp:45] output data size: 100,3,32,32
I0926 14:52:16.964679  4911 net.cpp:122] Setting up Data1
I0926 14:52:16.964700  4911 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0926 14:52:16.964704  4911 net.cpp:129] Top shape: 100 (100)
I0926 14:52:16.964707  4911 net.cpp:137] Memory required for data: 1229200
I0926 14:52:16.964712  4911 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0926 14:52:16.964720  4911 net.cpp:84] Creating Layer Data2_Data1_1_split
I0926 14:52:16.964723  4911 net.cpp:406] Data2_Data1_1_split <- Data2
I0926 14:52:16.964728  4911 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0926 14:52:16.964736  4911 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0926 14:52:16.964815  4911 net.cpp:122] Setting up Data2_Data1_1_split
I0926 14:52:16.964825  4911 net.cpp:129] Top shape: 100 (100)
I0926 14:52:16.964828  4911 net.cpp:129] Top shape: 100 (100)
I0926 14:52:16.964830  4911 net.cpp:137] Memory required for data: 1230000
I0926 14:52:16.964833  4911 layer_factory.hpp:77] Creating layer Convolution1
I0926 14:52:16.964844  4911 net.cpp:84] Creating Layer Convolution1
I0926 14:52:16.964848  4911 net.cpp:406] Convolution1 <- Data1
I0926 14:52:16.964851  4911 net.cpp:380] Convolution1 -> Convolution1
I0926 14:52:16.966061  4911 net.cpp:122] Setting up Convolution1
I0926 14:52:16.966071  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.966089  4911 net.cpp:137] Memory required for data: 7783600
I0926 14:52:16.966096  4911 layer_factory.hpp:77] Creating layer BatchNorm1
I0926 14:52:16.966102  4911 net.cpp:84] Creating Layer BatchNorm1
I0926 14:52:16.966105  4911 net.cpp:406] BatchNorm1 <- Convolution1
I0926 14:52:16.966109  4911 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0926 14:52:16.966259  4911 net.cpp:122] Setting up BatchNorm1
I0926 14:52:16.966265  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.966267  4911 net.cpp:137] Memory required for data: 14337200
I0926 14:52:16.966274  4911 layer_factory.hpp:77] Creating layer Scale1
I0926 14:52:16.966281  4911 net.cpp:84] Creating Layer Scale1
I0926 14:52:16.966284  4911 net.cpp:406] Scale1 <- Convolution1
I0926 14:52:16.966286  4911 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0926 14:52:16.966320  4911 layer_factory.hpp:77] Creating layer Scale1
I0926 14:52:16.966404  4911 net.cpp:122] Setting up Scale1
I0926 14:52:16.966408  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.966411  4911 net.cpp:137] Memory required for data: 20890800
I0926 14:52:16.966415  4911 layer_factory.hpp:77] Creating layer penlu1
I0926 14:52:16.966421  4911 net.cpp:84] Creating Layer penlu1
I0926 14:52:16.966423  4911 net.cpp:406] penlu1 <- Convolution1
I0926 14:52:16.966428  4911 net.cpp:367] penlu1 -> Convolution1 (in-place)
I0926 14:52:16.967046  4911 net.cpp:122] Setting up penlu1
I0926 14:52:16.967054  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.967057  4911 net.cpp:137] Memory required for data: 27444400
I0926 14:52:16.967064  4911 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I0926 14:52:16.967068  4911 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I0926 14:52:16.967072  4911 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I0926 14:52:16.967074  4911 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I0926 14:52:16.967079  4911 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I0926 14:52:16.967108  4911 net.cpp:122] Setting up Convolution1_penlu1_0_split
I0926 14:52:16.967111  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.987818  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.987828  4911 net.cpp:137] Memory required for data: 40551600
I0926 14:52:16.987833  4911 layer_factory.hpp:77] Creating layer Convolution2
I0926 14:52:16.987848  4911 net.cpp:84] Creating Layer Convolution2
I0926 14:52:16.987853  4911 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I0926 14:52:16.987860  4911 net.cpp:380] Convolution2 -> Convolution2
I0926 14:52:16.989040  4911 net.cpp:122] Setting up Convolution2
I0926 14:52:16.989049  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.989053  4911 net.cpp:137] Memory required for data: 47105200
I0926 14:52:16.989058  4911 layer_factory.hpp:77] Creating layer BatchNorm2
I0926 14:52:16.989064  4911 net.cpp:84] Creating Layer BatchNorm2
I0926 14:52:16.989068  4911 net.cpp:406] BatchNorm2 <- Convolution2
I0926 14:52:16.989071  4911 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0926 14:52:16.989245  4911 net.cpp:122] Setting up BatchNorm2
I0926 14:52:16.989253  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.989255  4911 net.cpp:137] Memory required for data: 53658800
I0926 14:52:16.989260  4911 layer_factory.hpp:77] Creating layer Scale2
I0926 14:52:16.989265  4911 net.cpp:84] Creating Layer Scale2
I0926 14:52:16.989269  4911 net.cpp:406] Scale2 <- Convolution2
I0926 14:52:16.989272  4911 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0926 14:52:16.989306  4911 layer_factory.hpp:77] Creating layer Scale2
I0926 14:52:16.989519  4911 net.cpp:122] Setting up Scale2
I0926 14:52:16.989531  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.989536  4911 net.cpp:137] Memory required for data: 60212400
I0926 14:52:16.989547  4911 layer_factory.hpp:77] Creating layer penlu2
I0926 14:52:16.989557  4911 net.cpp:84] Creating Layer penlu2
I0926 14:52:16.989569  4911 net.cpp:406] penlu2 <- Convolution2
I0926 14:52:16.989575  4911 net.cpp:367] penlu2 -> Convolution2 (in-place)
I0926 14:52:16.989739  4911 net.cpp:122] Setting up penlu2
I0926 14:52:16.989744  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.989747  4911 net.cpp:137] Memory required for data: 66766000
I0926 14:52:16.989751  4911 layer_factory.hpp:77] Creating layer Convolution3
I0926 14:52:16.989758  4911 net.cpp:84] Creating Layer Convolution3
I0926 14:52:16.989761  4911 net.cpp:406] Convolution3 <- Convolution2
I0926 14:52:16.989765  4911 net.cpp:380] Convolution3 -> Convolution3
I0926 14:52:16.990838  4911 net.cpp:122] Setting up Convolution3
I0926 14:52:16.990847  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.990849  4911 net.cpp:137] Memory required for data: 73319600
I0926 14:52:16.990854  4911 layer_factory.hpp:77] Creating layer BatchNorm3
I0926 14:52:16.990859  4911 net.cpp:84] Creating Layer BatchNorm3
I0926 14:52:16.990862  4911 net.cpp:406] BatchNorm3 <- Convolution3
I0926 14:52:16.990865  4911 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0926 14:52:16.991019  4911 net.cpp:122] Setting up BatchNorm3
I0926 14:52:16.991024  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.991025  4911 net.cpp:137] Memory required for data: 79873200
I0926 14:52:16.991030  4911 layer_factory.hpp:77] Creating layer Scale3
I0926 14:52:16.991034  4911 net.cpp:84] Creating Layer Scale3
I0926 14:52:16.991036  4911 net.cpp:406] Scale3 <- Convolution3
I0926 14:52:16.991039  4911 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0926 14:52:16.991070  4911 layer_factory.hpp:77] Creating layer Scale3
I0926 14:52:16.991166  4911 net.cpp:122] Setting up Scale3
I0926 14:52:16.991180  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.991183  4911 net.cpp:137] Memory required for data: 86426800
I0926 14:52:16.991186  4911 layer_factory.hpp:77] Creating layer Eltwise1
I0926 14:52:16.991192  4911 net.cpp:84] Creating Layer Eltwise1
I0926 14:52:16.991194  4911 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I0926 14:52:16.991197  4911 net.cpp:406] Eltwise1 <- Convolution3
I0926 14:52:16.991200  4911 net.cpp:380] Eltwise1 -> Eltwise1
I0926 14:52:16.991231  4911 net.cpp:122] Setting up Eltwise1
I0926 14:52:16.991235  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.991237  4911 net.cpp:137] Memory required for data: 92980400
I0926 14:52:16.991240  4911 layer_factory.hpp:77] Creating layer penlu3
I0926 14:52:16.991245  4911 net.cpp:84] Creating Layer penlu3
I0926 14:52:16.991248  4911 net.cpp:406] penlu3 <- Eltwise1
I0926 14:52:16.991251  4911 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I0926 14:52:16.991389  4911 net.cpp:122] Setting up penlu3
I0926 14:52:16.991394  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.991396  4911 net.cpp:137] Memory required for data: 99534000
I0926 14:52:16.991400  4911 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I0926 14:52:16.991405  4911 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I0926 14:52:16.991407  4911 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I0926 14:52:16.991410  4911 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I0926 14:52:16.991415  4911 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I0926 14:52:16.991441  4911 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I0926 14:52:16.991446  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.991447  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.991449  4911 net.cpp:137] Memory required for data: 112641200
I0926 14:52:16.991452  4911 layer_factory.hpp:77] Creating layer Convolution4
I0926 14:52:16.991459  4911 net.cpp:84] Creating Layer Convolution4
I0926 14:52:16.991462  4911 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I0926 14:52:16.991466  4911 net.cpp:380] Convolution4 -> Convolution4
I0926 14:52:16.992480  4911 net.cpp:122] Setting up Convolution4
I0926 14:52:16.992498  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.992502  4911 net.cpp:137] Memory required for data: 119194800
I0926 14:52:16.992507  4911 layer_factory.hpp:77] Creating layer BatchNorm4
I0926 14:52:16.992512  4911 net.cpp:84] Creating Layer BatchNorm4
I0926 14:52:16.992516  4911 net.cpp:406] BatchNorm4 <- Convolution4
I0926 14:52:16.992521  4911 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0926 14:52:16.992676  4911 net.cpp:122] Setting up BatchNorm4
I0926 14:52:16.992679  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.992681  4911 net.cpp:137] Memory required for data: 125748400
I0926 14:52:16.992691  4911 layer_factory.hpp:77] Creating layer Scale4
I0926 14:52:16.992694  4911 net.cpp:84] Creating Layer Scale4
I0926 14:52:16.992697  4911 net.cpp:406] Scale4 <- Convolution4
I0926 14:52:16.992700  4911 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0926 14:52:16.992732  4911 layer_factory.hpp:77] Creating layer Scale4
I0926 14:52:16.992817  4911 net.cpp:122] Setting up Scale4
I0926 14:52:16.992821  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.992823  4911 net.cpp:137] Memory required for data: 132302000
I0926 14:52:16.992827  4911 layer_factory.hpp:77] Creating layer penlu4
I0926 14:52:16.992833  4911 net.cpp:84] Creating Layer penlu4
I0926 14:52:16.992835  4911 net.cpp:406] penlu4 <- Convolution4
I0926 14:52:16.992839  4911 net.cpp:367] penlu4 -> Convolution4 (in-place)
I0926 14:52:16.992969  4911 net.cpp:122] Setting up penlu4
I0926 14:52:16.992974  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.992975  4911 net.cpp:137] Memory required for data: 138855600
I0926 14:52:16.992980  4911 layer_factory.hpp:77] Creating layer Convolution5
I0926 14:52:16.992987  4911 net.cpp:84] Creating Layer Convolution5
I0926 14:52:16.992990  4911 net.cpp:406] Convolution5 <- Convolution4
I0926 14:52:16.992993  4911 net.cpp:380] Convolution5 -> Convolution5
I0926 14:52:16.993957  4911 net.cpp:122] Setting up Convolution5
I0926 14:52:16.993966  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.993968  4911 net.cpp:137] Memory required for data: 145409200
I0926 14:52:16.993973  4911 layer_factory.hpp:77] Creating layer BatchNorm5
I0926 14:52:16.993978  4911 net.cpp:84] Creating Layer BatchNorm5
I0926 14:52:16.993980  4911 net.cpp:406] BatchNorm5 <- Convolution5
I0926 14:52:16.993985  4911 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0926 14:52:16.994139  4911 net.cpp:122] Setting up BatchNorm5
I0926 14:52:16.994143  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.994145  4911 net.cpp:137] Memory required for data: 151962800
I0926 14:52:16.994150  4911 layer_factory.hpp:77] Creating layer Scale5
I0926 14:52:16.994154  4911 net.cpp:84] Creating Layer Scale5
I0926 14:52:16.994156  4911 net.cpp:406] Scale5 <- Convolution5
I0926 14:52:16.994160  4911 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0926 14:52:16.994189  4911 layer_factory.hpp:77] Creating layer Scale5
I0926 14:52:16.994274  4911 net.cpp:122] Setting up Scale5
I0926 14:52:16.994279  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.994282  4911 net.cpp:137] Memory required for data: 158516400
I0926 14:52:16.994285  4911 layer_factory.hpp:77] Creating layer Eltwise2
I0926 14:52:16.994289  4911 net.cpp:84] Creating Layer Eltwise2
I0926 14:52:16.994292  4911 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I0926 14:52:16.994294  4911 net.cpp:406] Eltwise2 <- Convolution5
I0926 14:52:16.994298  4911 net.cpp:380] Eltwise2 -> Eltwise2
I0926 14:52:16.994315  4911 net.cpp:122] Setting up Eltwise2
I0926 14:52:16.994319  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.994321  4911 net.cpp:137] Memory required for data: 165070000
I0926 14:52:16.994323  4911 layer_factory.hpp:77] Creating layer penlu5
I0926 14:52:16.994329  4911 net.cpp:84] Creating Layer penlu5
I0926 14:52:16.994331  4911 net.cpp:406] penlu5 <- Eltwise2
I0926 14:52:16.994335  4911 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I0926 14:52:16.994464  4911 net.cpp:122] Setting up penlu5
I0926 14:52:16.994475  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.994477  4911 net.cpp:137] Memory required for data: 171623600
I0926 14:52:16.994482  4911 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I0926 14:52:16.994487  4911 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I0926 14:52:16.994488  4911 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I0926 14:52:16.994493  4911 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I0926 14:52:16.994496  4911 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I0926 14:52:16.994524  4911 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I0926 14:52:16.994527  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.994531  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.994534  4911 net.cpp:137] Memory required for data: 184730800
I0926 14:52:16.994536  4911 layer_factory.hpp:77] Creating layer Convolution6
I0926 14:52:16.994541  4911 net.cpp:84] Creating Layer Convolution6
I0926 14:52:16.994544  4911 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I0926 14:52:16.994549  4911 net.cpp:380] Convolution6 -> Convolution6
I0926 14:52:16.995507  4911 net.cpp:122] Setting up Convolution6
I0926 14:52:16.995515  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.995517  4911 net.cpp:137] Memory required for data: 191284400
I0926 14:52:16.995522  4911 layer_factory.hpp:77] Creating layer BatchNorm6
I0926 14:52:16.995527  4911 net.cpp:84] Creating Layer BatchNorm6
I0926 14:52:16.995530  4911 net.cpp:406] BatchNorm6 <- Convolution6
I0926 14:52:16.995535  4911 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0926 14:52:16.995683  4911 net.cpp:122] Setting up BatchNorm6
I0926 14:52:16.995688  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.995690  4911 net.cpp:137] Memory required for data: 197838000
I0926 14:52:16.995694  4911 layer_factory.hpp:77] Creating layer Scale6
I0926 14:52:16.995699  4911 net.cpp:84] Creating Layer Scale6
I0926 14:52:16.995702  4911 net.cpp:406] Scale6 <- Convolution6
I0926 14:52:16.995705  4911 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0926 14:52:16.995734  4911 layer_factory.hpp:77] Creating layer Scale6
I0926 14:52:16.995820  4911 net.cpp:122] Setting up Scale6
I0926 14:52:16.995823  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.995826  4911 net.cpp:137] Memory required for data: 204391600
I0926 14:52:16.995829  4911 layer_factory.hpp:77] Creating layer penlu6
I0926 14:52:16.995836  4911 net.cpp:84] Creating Layer penlu6
I0926 14:52:16.995837  4911 net.cpp:406] penlu6 <- Convolution6
I0926 14:52:16.995841  4911 net.cpp:367] penlu6 -> Convolution6 (in-place)
I0926 14:52:16.995965  4911 net.cpp:122] Setting up penlu6
I0926 14:52:16.995971  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.995973  4911 net.cpp:137] Memory required for data: 210945200
I0926 14:52:16.995977  4911 layer_factory.hpp:77] Creating layer Convolution7
I0926 14:52:16.995983  4911 net.cpp:84] Creating Layer Convolution7
I0926 14:52:16.995985  4911 net.cpp:406] Convolution7 <- Convolution6
I0926 14:52:16.995990  4911 net.cpp:380] Convolution7 -> Convolution7
I0926 14:52:16.996944  4911 net.cpp:122] Setting up Convolution7
I0926 14:52:16.996953  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.996955  4911 net.cpp:137] Memory required for data: 217498800
I0926 14:52:16.996959  4911 layer_factory.hpp:77] Creating layer BatchNorm7
I0926 14:52:16.996966  4911 net.cpp:84] Creating Layer BatchNorm7
I0926 14:52:16.996969  4911 net.cpp:406] BatchNorm7 <- Convolution7
I0926 14:52:16.996973  4911 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0926 14:52:16.997123  4911 net.cpp:122] Setting up BatchNorm7
I0926 14:52:16.997128  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.997129  4911 net.cpp:137] Memory required for data: 224052400
I0926 14:52:16.997138  4911 layer_factory.hpp:77] Creating layer Scale7
I0926 14:52:16.997143  4911 net.cpp:84] Creating Layer Scale7
I0926 14:52:16.997151  4911 net.cpp:406] Scale7 <- Convolution7
I0926 14:52:16.997155  4911 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0926 14:52:16.997187  4911 layer_factory.hpp:77] Creating layer Scale7
I0926 14:52:16.997272  4911 net.cpp:122] Setting up Scale7
I0926 14:52:16.997277  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.997278  4911 net.cpp:137] Memory required for data: 230606000
I0926 14:52:16.997282  4911 layer_factory.hpp:77] Creating layer Eltwise3
I0926 14:52:16.997287  4911 net.cpp:84] Creating Layer Eltwise3
I0926 14:52:16.997289  4911 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I0926 14:52:16.997292  4911 net.cpp:406] Eltwise3 <- Convolution7
I0926 14:52:16.997297  4911 net.cpp:380] Eltwise3 -> Eltwise3
I0926 14:52:16.997313  4911 net.cpp:122] Setting up Eltwise3
I0926 14:52:16.997316  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.997318  4911 net.cpp:137] Memory required for data: 237159600
I0926 14:52:16.997320  4911 layer_factory.hpp:77] Creating layer penlu7
I0926 14:52:16.997326  4911 net.cpp:84] Creating Layer penlu7
I0926 14:52:16.997328  4911 net.cpp:406] penlu7 <- Eltwise3
I0926 14:52:16.997331  4911 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I0926 14:52:16.997457  4911 net.cpp:122] Setting up penlu7
I0926 14:52:16.997460  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.997462  4911 net.cpp:137] Memory required for data: 243713200
I0926 14:52:16.997467  4911 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I0926 14:52:16.997470  4911 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I0926 14:52:16.997473  4911 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I0926 14:52:16.997475  4911 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I0926 14:52:16.997480  4911 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I0926 14:52:16.997504  4911 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I0926 14:52:16.997509  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:16.997511  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.018286  4911 net.cpp:137] Memory required for data: 256820400
I0926 14:52:17.018296  4911 layer_factory.hpp:77] Creating layer Convolution8
I0926 14:52:17.018308  4911 net.cpp:84] Creating Layer Convolution8
I0926 14:52:17.018313  4911 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I0926 14:52:17.018321  4911 net.cpp:380] Convolution8 -> Convolution8
I0926 14:52:17.019385  4911 net.cpp:122] Setting up Convolution8
I0926 14:52:17.019395  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.019398  4911 net.cpp:137] Memory required for data: 263374000
I0926 14:52:17.019403  4911 layer_factory.hpp:77] Creating layer BatchNorm8
I0926 14:52:17.019409  4911 net.cpp:84] Creating Layer BatchNorm8
I0926 14:52:17.019412  4911 net.cpp:406] BatchNorm8 <- Convolution8
I0926 14:52:17.019417  4911 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0926 14:52:17.019603  4911 net.cpp:122] Setting up BatchNorm8
I0926 14:52:17.019609  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.019611  4911 net.cpp:137] Memory required for data: 269927600
I0926 14:52:17.019616  4911 layer_factory.hpp:77] Creating layer Scale8
I0926 14:52:17.019620  4911 net.cpp:84] Creating Layer Scale8
I0926 14:52:17.019623  4911 net.cpp:406] Scale8 <- Convolution8
I0926 14:52:17.019628  4911 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0926 14:52:17.019668  4911 layer_factory.hpp:77] Creating layer Scale8
I0926 14:52:17.019784  4911 net.cpp:122] Setting up Scale8
I0926 14:52:17.019794  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.019798  4911 net.cpp:137] Memory required for data: 276481200
I0926 14:52:17.019801  4911 layer_factory.hpp:77] Creating layer penlu8
I0926 14:52:17.019807  4911 net.cpp:84] Creating Layer penlu8
I0926 14:52:17.019810  4911 net.cpp:406] penlu8 <- Convolution8
I0926 14:52:17.019815  4911 net.cpp:367] penlu8 -> Convolution8 (in-place)
I0926 14:52:17.020017  4911 net.cpp:122] Setting up penlu8
I0926 14:52:17.020032  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.020035  4911 net.cpp:137] Memory required for data: 283034800
I0926 14:52:17.020040  4911 layer_factory.hpp:77] Creating layer Convolution9
I0926 14:52:17.020057  4911 net.cpp:84] Creating Layer Convolution9
I0926 14:52:17.020061  4911 net.cpp:406] Convolution9 <- Convolution8
I0926 14:52:17.020064  4911 net.cpp:380] Convolution9 -> Convolution9
I0926 14:52:17.021163  4911 net.cpp:122] Setting up Convolution9
I0926 14:52:17.021173  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.021174  4911 net.cpp:137] Memory required for data: 289588400
I0926 14:52:17.021179  4911 layer_factory.hpp:77] Creating layer BatchNorm9
I0926 14:52:17.021184  4911 net.cpp:84] Creating Layer BatchNorm9
I0926 14:52:17.021188  4911 net.cpp:406] BatchNorm9 <- Convolution9
I0926 14:52:17.021193  4911 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0926 14:52:17.021345  4911 net.cpp:122] Setting up BatchNorm9
I0926 14:52:17.021349  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.021353  4911 net.cpp:137] Memory required for data: 296142000
I0926 14:52:17.021356  4911 layer_factory.hpp:77] Creating layer Scale9
I0926 14:52:17.021361  4911 net.cpp:84] Creating Layer Scale9
I0926 14:52:17.021364  4911 net.cpp:406] Scale9 <- Convolution9
I0926 14:52:17.021368  4911 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0926 14:52:17.021409  4911 layer_factory.hpp:77] Creating layer Scale9
I0926 14:52:17.021517  4911 net.cpp:122] Setting up Scale9
I0926 14:52:17.021522  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.021523  4911 net.cpp:137] Memory required for data: 302695600
I0926 14:52:17.021528  4911 layer_factory.hpp:77] Creating layer Eltwise4
I0926 14:52:17.021533  4911 net.cpp:84] Creating Layer Eltwise4
I0926 14:52:17.021534  4911 net.cpp:406] Eltwise4 <- Eltwise3_penlu7_0_split_1
I0926 14:52:17.021538  4911 net.cpp:406] Eltwise4 <- Convolution9
I0926 14:52:17.021543  4911 net.cpp:380] Eltwise4 -> Eltwise4
I0926 14:52:17.021561  4911 net.cpp:122] Setting up Eltwise4
I0926 14:52:17.021565  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.021567  4911 net.cpp:137] Memory required for data: 309249200
I0926 14:52:17.021570  4911 layer_factory.hpp:77] Creating layer penlu9
I0926 14:52:17.021575  4911 net.cpp:84] Creating Layer penlu9
I0926 14:52:17.021577  4911 net.cpp:406] penlu9 <- Eltwise4
I0926 14:52:17.021582  4911 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I0926 14:52:17.021734  4911 net.cpp:122] Setting up penlu9
I0926 14:52:17.021739  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.021741  4911 net.cpp:137] Memory required for data: 315802800
I0926 14:52:17.021745  4911 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I0926 14:52:17.021749  4911 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I0926 14:52:17.021751  4911 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I0926 14:52:17.021755  4911 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I0926 14:52:17.021759  4911 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I0926 14:52:17.021786  4911 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I0926 14:52:17.021790  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.021792  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.021795  4911 net.cpp:137] Memory required for data: 328910000
I0926 14:52:17.021797  4911 layer_factory.hpp:77] Creating layer Convolution10
I0926 14:52:17.021803  4911 net.cpp:84] Creating Layer Convolution10
I0926 14:52:17.021806  4911 net.cpp:406] Convolution10 <- Eltwise4_penlu9_0_split_0
I0926 14:52:17.021811  4911 net.cpp:380] Convolution10 -> Convolution10
I0926 14:52:17.022814  4911 net.cpp:122] Setting up Convolution10
I0926 14:52:17.022824  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.022825  4911 net.cpp:137] Memory required for data: 335463600
I0926 14:52:17.022830  4911 layer_factory.hpp:77] Creating layer BatchNorm10
I0926 14:52:17.022843  4911 net.cpp:84] Creating Layer BatchNorm10
I0926 14:52:17.022846  4911 net.cpp:406] BatchNorm10 <- Convolution10
I0926 14:52:17.022850  4911 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0926 14:52:17.023007  4911 net.cpp:122] Setting up BatchNorm10
I0926 14:52:17.023012  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.023015  4911 net.cpp:137] Memory required for data: 342017200
I0926 14:52:17.023020  4911 layer_factory.hpp:77] Creating layer Scale10
I0926 14:52:17.023023  4911 net.cpp:84] Creating Layer Scale10
I0926 14:52:17.023025  4911 net.cpp:406] Scale10 <- Convolution10
I0926 14:52:17.023028  4911 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0926 14:52:17.023061  4911 layer_factory.hpp:77] Creating layer Scale10
I0926 14:52:17.023146  4911 net.cpp:122] Setting up Scale10
I0926 14:52:17.023150  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.023154  4911 net.cpp:137] Memory required for data: 348570800
I0926 14:52:17.023156  4911 layer_factory.hpp:77] Creating layer penlu10
I0926 14:52:17.023162  4911 net.cpp:84] Creating Layer penlu10
I0926 14:52:17.023165  4911 net.cpp:406] penlu10 <- Convolution10
I0926 14:52:17.023169  4911 net.cpp:367] penlu10 -> Convolution10 (in-place)
I0926 14:52:17.023298  4911 net.cpp:122] Setting up penlu10
I0926 14:52:17.023303  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.023304  4911 net.cpp:137] Memory required for data: 355124400
I0926 14:52:17.023308  4911 layer_factory.hpp:77] Creating layer Convolution11
I0926 14:52:17.023315  4911 net.cpp:84] Creating Layer Convolution11
I0926 14:52:17.023317  4911 net.cpp:406] Convolution11 <- Convolution10
I0926 14:52:17.023321  4911 net.cpp:380] Convolution11 -> Convolution11
I0926 14:52:17.024637  4911 net.cpp:122] Setting up Convolution11
I0926 14:52:17.024646  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.024648  4911 net.cpp:137] Memory required for data: 361678000
I0926 14:52:17.024653  4911 layer_factory.hpp:77] Creating layer BatchNorm11
I0926 14:52:17.024658  4911 net.cpp:84] Creating Layer BatchNorm11
I0926 14:52:17.024662  4911 net.cpp:406] BatchNorm11 <- Convolution11
I0926 14:52:17.024664  4911 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0926 14:52:17.024821  4911 net.cpp:122] Setting up BatchNorm11
I0926 14:52:17.024824  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.024827  4911 net.cpp:137] Memory required for data: 368231600
I0926 14:52:17.024832  4911 layer_factory.hpp:77] Creating layer Scale11
I0926 14:52:17.024835  4911 net.cpp:84] Creating Layer Scale11
I0926 14:52:17.024837  4911 net.cpp:406] Scale11 <- Convolution11
I0926 14:52:17.024842  4911 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0926 14:52:17.024870  4911 layer_factory.hpp:77] Creating layer Scale11
I0926 14:52:17.024956  4911 net.cpp:122] Setting up Scale11
I0926 14:52:17.024960  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.024963  4911 net.cpp:137] Memory required for data: 374785200
I0926 14:52:17.024966  4911 layer_factory.hpp:77] Creating layer Eltwise5
I0926 14:52:17.024971  4911 net.cpp:84] Creating Layer Eltwise5
I0926 14:52:17.024973  4911 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I0926 14:52:17.024976  4911 net.cpp:406] Eltwise5 <- Convolution11
I0926 14:52:17.024979  4911 net.cpp:380] Eltwise5 -> Eltwise5
I0926 14:52:17.024997  4911 net.cpp:122] Setting up Eltwise5
I0926 14:52:17.025002  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.025003  4911 net.cpp:137] Memory required for data: 381338800
I0926 14:52:17.025005  4911 layer_factory.hpp:77] Creating layer penlu11
I0926 14:52:17.025010  4911 net.cpp:84] Creating Layer penlu11
I0926 14:52:17.025012  4911 net.cpp:406] penlu11 <- Eltwise5
I0926 14:52:17.025017  4911 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I0926 14:52:17.025144  4911 net.cpp:122] Setting up penlu11
I0926 14:52:17.025148  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.025151  4911 net.cpp:137] Memory required for data: 387892400
I0926 14:52:17.025161  4911 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I0926 14:52:17.025166  4911 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I0926 14:52:17.025167  4911 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I0926 14:52:17.025171  4911 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I0926 14:52:17.025176  4911 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I0926 14:52:17.025202  4911 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I0926 14:52:17.025207  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.025208  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.025210  4911 net.cpp:137] Memory required for data: 400999600
I0926 14:52:17.025213  4911 layer_factory.hpp:77] Creating layer Convolution12
I0926 14:52:17.025219  4911 net.cpp:84] Creating Layer Convolution12
I0926 14:52:17.025221  4911 net.cpp:406] Convolution12 <- Eltwise5_penlu11_0_split_0
I0926 14:52:17.025225  4911 net.cpp:380] Convolution12 -> Convolution12
I0926 14:52:17.026176  4911 net.cpp:122] Setting up Convolution12
I0926 14:52:17.026185  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.026187  4911 net.cpp:137] Memory required for data: 407553200
I0926 14:52:17.026191  4911 layer_factory.hpp:77] Creating layer BatchNorm12
I0926 14:52:17.026196  4911 net.cpp:84] Creating Layer BatchNorm12
I0926 14:52:17.026199  4911 net.cpp:406] BatchNorm12 <- Convolution12
I0926 14:52:17.026204  4911 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0926 14:52:17.026355  4911 net.cpp:122] Setting up BatchNorm12
I0926 14:52:17.026360  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.026361  4911 net.cpp:137] Memory required for data: 414106800
I0926 14:52:17.026365  4911 layer_factory.hpp:77] Creating layer Scale12
I0926 14:52:17.026371  4911 net.cpp:84] Creating Layer Scale12
I0926 14:52:17.026373  4911 net.cpp:406] Scale12 <- Convolution12
I0926 14:52:17.026376  4911 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0926 14:52:17.026407  4911 layer_factory.hpp:77] Creating layer Scale12
I0926 14:52:17.026494  4911 net.cpp:122] Setting up Scale12
I0926 14:52:17.026497  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.026499  4911 net.cpp:137] Memory required for data: 420660400
I0926 14:52:17.026504  4911 layer_factory.hpp:77] Creating layer penlu12
I0926 14:52:17.026509  4911 net.cpp:84] Creating Layer penlu12
I0926 14:52:17.026510  4911 net.cpp:406] penlu12 <- Convolution12
I0926 14:52:17.026515  4911 net.cpp:367] penlu12 -> Convolution12 (in-place)
I0926 14:52:17.026640  4911 net.cpp:122] Setting up penlu12
I0926 14:52:17.026645  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.026648  4911 net.cpp:137] Memory required for data: 427214000
I0926 14:52:17.026651  4911 layer_factory.hpp:77] Creating layer Convolution13
I0926 14:52:17.026657  4911 net.cpp:84] Creating Layer Convolution13
I0926 14:52:17.026660  4911 net.cpp:406] Convolution13 <- Convolution12
I0926 14:52:17.026664  4911 net.cpp:380] Convolution13 -> Convolution13
I0926 14:52:17.027607  4911 net.cpp:122] Setting up Convolution13
I0926 14:52:17.027616  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.027618  4911 net.cpp:137] Memory required for data: 433767600
I0926 14:52:17.027622  4911 layer_factory.hpp:77] Creating layer BatchNorm13
I0926 14:52:17.027628  4911 net.cpp:84] Creating Layer BatchNorm13
I0926 14:52:17.027631  4911 net.cpp:406] BatchNorm13 <- Convolution13
I0926 14:52:17.027635  4911 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0926 14:52:17.027786  4911 net.cpp:122] Setting up BatchNorm13
I0926 14:52:17.027791  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.027792  4911 net.cpp:137] Memory required for data: 440321200
I0926 14:52:17.027797  4911 layer_factory.hpp:77] Creating layer Scale13
I0926 14:52:17.027802  4911 net.cpp:84] Creating Layer Scale13
I0926 14:52:17.027804  4911 net.cpp:406] Scale13 <- Convolution13
I0926 14:52:17.027814  4911 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0926 14:52:17.027846  4911 layer_factory.hpp:77] Creating layer Scale13
I0926 14:52:17.027931  4911 net.cpp:122] Setting up Scale13
I0926 14:52:17.027936  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.027938  4911 net.cpp:137] Memory required for data: 446874800
I0926 14:52:17.027942  4911 layer_factory.hpp:77] Creating layer Eltwise6
I0926 14:52:17.027950  4911 net.cpp:84] Creating Layer Eltwise6
I0926 14:52:17.027953  4911 net.cpp:406] Eltwise6 <- Eltwise5_penlu11_0_split_1
I0926 14:52:17.027956  4911 net.cpp:406] Eltwise6 <- Convolution13
I0926 14:52:17.027959  4911 net.cpp:380] Eltwise6 -> Eltwise6
I0926 14:52:17.027977  4911 net.cpp:122] Setting up Eltwise6
I0926 14:52:17.027981  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.027983  4911 net.cpp:137] Memory required for data: 453428400
I0926 14:52:17.027986  4911 layer_factory.hpp:77] Creating layer penlu13
I0926 14:52:17.027992  4911 net.cpp:84] Creating Layer penlu13
I0926 14:52:17.027993  4911 net.cpp:406] penlu13 <- Eltwise6
I0926 14:52:17.027997  4911 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I0926 14:52:17.028125  4911 net.cpp:122] Setting up penlu13
I0926 14:52:17.028129  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.028131  4911 net.cpp:137] Memory required for data: 459982000
I0926 14:52:17.028143  4911 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I0926 14:52:17.028148  4911 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I0926 14:52:17.028151  4911 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I0926 14:52:17.028154  4911 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I0926 14:52:17.028158  4911 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I0926 14:52:17.028187  4911 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I0926 14:52:17.028190  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.028192  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.048635  4911 net.cpp:137] Memory required for data: 473089200
I0926 14:52:17.048643  4911 layer_factory.hpp:77] Creating layer Convolution14
I0926 14:52:17.048658  4911 net.cpp:84] Creating Layer Convolution14
I0926 14:52:17.048663  4911 net.cpp:406] Convolution14 <- Eltwise6_penlu13_0_split_0
I0926 14:52:17.048672  4911 net.cpp:380] Convolution14 -> Convolution14
I0926 14:52:17.049803  4911 net.cpp:122] Setting up Convolution14
I0926 14:52:17.049813  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.049815  4911 net.cpp:137] Memory required for data: 479642800
I0926 14:52:17.049820  4911 layer_factory.hpp:77] Creating layer BatchNorm14
I0926 14:52:17.049825  4911 net.cpp:84] Creating Layer BatchNorm14
I0926 14:52:17.049829  4911 net.cpp:406] BatchNorm14 <- Convolution14
I0926 14:52:17.049834  4911 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0926 14:52:17.050027  4911 net.cpp:122] Setting up BatchNorm14
I0926 14:52:17.050034  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.050036  4911 net.cpp:137] Memory required for data: 486196400
I0926 14:52:17.050041  4911 layer_factory.hpp:77] Creating layer Scale14
I0926 14:52:17.050046  4911 net.cpp:84] Creating Layer Scale14
I0926 14:52:17.050050  4911 net.cpp:406] Scale14 <- Convolution14
I0926 14:52:17.050053  4911 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0926 14:52:17.050106  4911 layer_factory.hpp:77] Creating layer Scale14
I0926 14:52:17.050225  4911 net.cpp:122] Setting up Scale14
I0926 14:52:17.050233  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.050235  4911 net.cpp:137] Memory required for data: 492750000
I0926 14:52:17.050240  4911 layer_factory.hpp:77] Creating layer penlu14
I0926 14:52:17.050246  4911 net.cpp:84] Creating Layer penlu14
I0926 14:52:17.050248  4911 net.cpp:406] penlu14 <- Convolution14
I0926 14:52:17.050252  4911 net.cpp:367] penlu14 -> Convolution14 (in-place)
I0926 14:52:17.050448  4911 net.cpp:122] Setting up penlu14
I0926 14:52:17.050462  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.050464  4911 net.cpp:137] Memory required for data: 499303600
I0926 14:52:17.050469  4911 layer_factory.hpp:77] Creating layer Convolution15
I0926 14:52:17.050477  4911 net.cpp:84] Creating Layer Convolution15
I0926 14:52:17.050479  4911 net.cpp:406] Convolution15 <- Convolution14
I0926 14:52:17.050483  4911 net.cpp:380] Convolution15 -> Convolution15
I0926 14:52:17.051599  4911 net.cpp:122] Setting up Convolution15
I0926 14:52:17.051609  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.051611  4911 net.cpp:137] Memory required for data: 505857200
I0926 14:52:17.051615  4911 layer_factory.hpp:77] Creating layer BatchNorm15
I0926 14:52:17.051621  4911 net.cpp:84] Creating Layer BatchNorm15
I0926 14:52:17.051625  4911 net.cpp:406] BatchNorm15 <- Convolution15
I0926 14:52:17.051628  4911 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0926 14:52:17.051784  4911 net.cpp:122] Setting up BatchNorm15
I0926 14:52:17.051789  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.051791  4911 net.cpp:137] Memory required for data: 512410800
I0926 14:52:17.051796  4911 layer_factory.hpp:77] Creating layer Scale15
I0926 14:52:17.051801  4911 net.cpp:84] Creating Layer Scale15
I0926 14:52:17.051803  4911 net.cpp:406] Scale15 <- Convolution15
I0926 14:52:17.051807  4911 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0926 14:52:17.051837  4911 layer_factory.hpp:77] Creating layer Scale15
I0926 14:52:17.051939  4911 net.cpp:122] Setting up Scale15
I0926 14:52:17.051944  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.051945  4911 net.cpp:137] Memory required for data: 518964400
I0926 14:52:17.051949  4911 layer_factory.hpp:77] Creating layer Eltwise7
I0926 14:52:17.051954  4911 net.cpp:84] Creating Layer Eltwise7
I0926 14:52:17.051956  4911 net.cpp:406] Eltwise7 <- Eltwise6_penlu13_0_split_1
I0926 14:52:17.051960  4911 net.cpp:406] Eltwise7 <- Convolution15
I0926 14:52:17.051964  4911 net.cpp:380] Eltwise7 -> Eltwise7
I0926 14:52:17.051983  4911 net.cpp:122] Setting up Eltwise7
I0926 14:52:17.051987  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.051990  4911 net.cpp:137] Memory required for data: 525518000
I0926 14:52:17.051992  4911 layer_factory.hpp:77] Creating layer penlu15
I0926 14:52:17.051996  4911 net.cpp:84] Creating Layer penlu15
I0926 14:52:17.052000  4911 net.cpp:406] penlu15 <- Eltwise7
I0926 14:52:17.052003  4911 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I0926 14:52:17.052139  4911 net.cpp:122] Setting up penlu15
I0926 14:52:17.052145  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.052147  4911 net.cpp:137] Memory required for data: 532071600
I0926 14:52:17.052151  4911 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I0926 14:52:17.052165  4911 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I0926 14:52:17.052167  4911 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I0926 14:52:17.052170  4911 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I0926 14:52:17.052184  4911 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I0926 14:52:17.052212  4911 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I0926 14:52:17.052217  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.052219  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.052222  4911 net.cpp:137] Memory required for data: 545178800
I0926 14:52:17.052224  4911 layer_factory.hpp:77] Creating layer Convolution16
I0926 14:52:17.052230  4911 net.cpp:84] Creating Layer Convolution16
I0926 14:52:17.052233  4911 net.cpp:406] Convolution16 <- Eltwise7_penlu15_0_split_0
I0926 14:52:17.052237  4911 net.cpp:380] Convolution16 -> Convolution16
I0926 14:52:17.052902  4911 net.cpp:122] Setting up Convolution16
I0926 14:52:17.052911  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.052913  4911 net.cpp:137] Memory required for data: 551732400
I0926 14:52:17.052917  4911 layer_factory.hpp:77] Creating layer BatchNorm16
I0926 14:52:17.052929  4911 net.cpp:84] Creating Layer BatchNorm16
I0926 14:52:17.052932  4911 net.cpp:406] BatchNorm16 <- Convolution16
I0926 14:52:17.052937  4911 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0926 14:52:17.053095  4911 net.cpp:122] Setting up BatchNorm16
I0926 14:52:17.053099  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.053102  4911 net.cpp:137] Memory required for data: 558286000
I0926 14:52:17.053107  4911 layer_factory.hpp:77] Creating layer Scale16
I0926 14:52:17.053110  4911 net.cpp:84] Creating Layer Scale16
I0926 14:52:17.053113  4911 net.cpp:406] Scale16 <- Convolution16
I0926 14:52:17.053117  4911 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0926 14:52:17.053148  4911 layer_factory.hpp:77] Creating layer Scale16
I0926 14:52:17.053236  4911 net.cpp:122] Setting up Scale16
I0926 14:52:17.053239  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.053241  4911 net.cpp:137] Memory required for data: 564839600
I0926 14:52:17.053246  4911 layer_factory.hpp:77] Creating layer penlu16
I0926 14:52:17.053251  4911 net.cpp:84] Creating Layer penlu16
I0926 14:52:17.053252  4911 net.cpp:406] penlu16 <- Convolution16
I0926 14:52:17.053257  4911 net.cpp:367] penlu16 -> Convolution16 (in-place)
I0926 14:52:17.053391  4911 net.cpp:122] Setting up penlu16
I0926 14:52:17.053396  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.053398  4911 net.cpp:137] Memory required for data: 571393200
I0926 14:52:17.053402  4911 layer_factory.hpp:77] Creating layer Convolution17
I0926 14:52:17.053408  4911 net.cpp:84] Creating Layer Convolution17
I0926 14:52:17.053411  4911 net.cpp:406] Convolution17 <- Convolution16
I0926 14:52:17.053416  4911 net.cpp:380] Convolution17 -> Convolution17
I0926 14:52:17.054391  4911 net.cpp:122] Setting up Convolution17
I0926 14:52:17.054400  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.054402  4911 net.cpp:137] Memory required for data: 577946800
I0926 14:52:17.054407  4911 layer_factory.hpp:77] Creating layer BatchNorm17
I0926 14:52:17.054412  4911 net.cpp:84] Creating Layer BatchNorm17
I0926 14:52:17.054415  4911 net.cpp:406] BatchNorm17 <- Convolution17
I0926 14:52:17.054419  4911 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0926 14:52:17.054576  4911 net.cpp:122] Setting up BatchNorm17
I0926 14:52:17.054581  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.054584  4911 net.cpp:137] Memory required for data: 584500400
I0926 14:52:17.054589  4911 layer_factory.hpp:77] Creating layer Scale17
I0926 14:52:17.054592  4911 net.cpp:84] Creating Layer Scale17
I0926 14:52:17.054595  4911 net.cpp:406] Scale17 <- Convolution17
I0926 14:52:17.054599  4911 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0926 14:52:17.054630  4911 layer_factory.hpp:77] Creating layer Scale17
I0926 14:52:17.054718  4911 net.cpp:122] Setting up Scale17
I0926 14:52:17.054723  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.054724  4911 net.cpp:137] Memory required for data: 591054000
I0926 14:52:17.054728  4911 layer_factory.hpp:77] Creating layer Eltwise8
I0926 14:52:17.054733  4911 net.cpp:84] Creating Layer Eltwise8
I0926 14:52:17.054735  4911 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I0926 14:52:17.054738  4911 net.cpp:406] Eltwise8 <- Convolution17
I0926 14:52:17.054741  4911 net.cpp:380] Eltwise8 -> Eltwise8
I0926 14:52:17.054760  4911 net.cpp:122] Setting up Eltwise8
I0926 14:52:17.054764  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.054766  4911 net.cpp:137] Memory required for data: 597607600
I0926 14:52:17.054769  4911 layer_factory.hpp:77] Creating layer penlu17
I0926 14:52:17.054774  4911 net.cpp:84] Creating Layer penlu17
I0926 14:52:17.054776  4911 net.cpp:406] penlu17 <- Eltwise8
I0926 14:52:17.054780  4911 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I0926 14:52:17.054915  4911 net.cpp:122] Setting up penlu17
I0926 14:52:17.054920  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.054922  4911 net.cpp:137] Memory required for data: 604161200
I0926 14:52:17.054932  4911 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I0926 14:52:17.054937  4911 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I0926 14:52:17.054939  4911 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I0926 14:52:17.054942  4911 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I0926 14:52:17.054946  4911 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I0926 14:52:17.054975  4911 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I0926 14:52:17.054980  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.054981  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.054985  4911 net.cpp:137] Memory required for data: 617268400
I0926 14:52:17.054986  4911 layer_factory.hpp:77] Creating layer Convolution18
I0926 14:52:17.054992  4911 net.cpp:84] Creating Layer Convolution18
I0926 14:52:17.054994  4911 net.cpp:406] Convolution18 <- Eltwise8_penlu17_0_split_0
I0926 14:52:17.054998  4911 net.cpp:380] Convolution18 -> Convolution18
I0926 14:52:17.056005  4911 net.cpp:122] Setting up Convolution18
I0926 14:52:17.056015  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.056017  4911 net.cpp:137] Memory required for data: 623822000
I0926 14:52:17.056021  4911 layer_factory.hpp:77] Creating layer BatchNorm18
I0926 14:52:17.056026  4911 net.cpp:84] Creating Layer BatchNorm18
I0926 14:52:17.056030  4911 net.cpp:406] BatchNorm18 <- Convolution18
I0926 14:52:17.056032  4911 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0926 14:52:17.056190  4911 net.cpp:122] Setting up BatchNorm18
I0926 14:52:17.056195  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.056197  4911 net.cpp:137] Memory required for data: 630375600
I0926 14:52:17.056201  4911 layer_factory.hpp:77] Creating layer Scale18
I0926 14:52:17.056205  4911 net.cpp:84] Creating Layer Scale18
I0926 14:52:17.056208  4911 net.cpp:406] Scale18 <- Convolution18
I0926 14:52:17.056211  4911 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0926 14:52:17.056242  4911 layer_factory.hpp:77] Creating layer Scale18
I0926 14:52:17.056330  4911 net.cpp:122] Setting up Scale18
I0926 14:52:17.056335  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.056337  4911 net.cpp:137] Memory required for data: 636929200
I0926 14:52:17.056341  4911 layer_factory.hpp:77] Creating layer penlu18
I0926 14:52:17.056346  4911 net.cpp:84] Creating Layer penlu18
I0926 14:52:17.056349  4911 net.cpp:406] penlu18 <- Convolution18
I0926 14:52:17.056352  4911 net.cpp:367] penlu18 -> Convolution18 (in-place)
I0926 14:52:17.056489  4911 net.cpp:122] Setting up penlu18
I0926 14:52:17.056493  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.056499  4911 net.cpp:137] Memory required for data: 643482800
I0926 14:52:17.056504  4911 layer_factory.hpp:77] Creating layer Convolution19
I0926 14:52:17.056511  4911 net.cpp:84] Creating Layer Convolution19
I0926 14:52:17.056514  4911 net.cpp:406] Convolution19 <- Convolution18
I0926 14:52:17.056526  4911 net.cpp:380] Convolution19 -> Convolution19
I0926 14:52:17.057473  4911 net.cpp:122] Setting up Convolution19
I0926 14:52:17.057482  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.057484  4911 net.cpp:137] Memory required for data: 650036400
I0926 14:52:17.057489  4911 layer_factory.hpp:77] Creating layer BatchNorm19
I0926 14:52:17.057495  4911 net.cpp:84] Creating Layer BatchNorm19
I0926 14:52:17.057497  4911 net.cpp:406] BatchNorm19 <- Convolution19
I0926 14:52:17.057502  4911 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0926 14:52:17.057657  4911 net.cpp:122] Setting up BatchNorm19
I0926 14:52:17.057662  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.057664  4911 net.cpp:137] Memory required for data: 656590000
I0926 14:52:17.057668  4911 layer_factory.hpp:77] Creating layer Scale19
I0926 14:52:17.057672  4911 net.cpp:84] Creating Layer Scale19
I0926 14:52:17.057675  4911 net.cpp:406] Scale19 <- Convolution19
I0926 14:52:17.057685  4911 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0926 14:52:17.057716  4911 layer_factory.hpp:77] Creating layer Scale19
I0926 14:52:17.057803  4911 net.cpp:122] Setting up Scale19
I0926 14:52:17.057808  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.057811  4911 net.cpp:137] Memory required for data: 663143600
I0926 14:52:17.057814  4911 layer_factory.hpp:77] Creating layer Eltwise9
I0926 14:52:17.057818  4911 net.cpp:84] Creating Layer Eltwise9
I0926 14:52:17.057821  4911 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I0926 14:52:17.057823  4911 net.cpp:406] Eltwise9 <- Convolution19
I0926 14:52:17.057826  4911 net.cpp:380] Eltwise9 -> Eltwise9
I0926 14:52:17.057844  4911 net.cpp:122] Setting up Eltwise9
I0926 14:52:17.057848  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.057850  4911 net.cpp:137] Memory required for data: 669697200
I0926 14:52:17.057852  4911 layer_factory.hpp:77] Creating layer penlu19
I0926 14:52:17.057857  4911 net.cpp:84] Creating Layer penlu19
I0926 14:52:17.057860  4911 net.cpp:406] penlu19 <- Eltwise9
I0926 14:52:17.057864  4911 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I0926 14:52:17.057996  4911 net.cpp:122] Setting up penlu19
I0926 14:52:17.058001  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.058003  4911 net.cpp:137] Memory required for data: 676250800
I0926 14:52:17.058007  4911 layer_factory.hpp:77] Creating layer Eltwise9_penlu19_0_split
I0926 14:52:17.058012  4911 net.cpp:84] Creating Layer Eltwise9_penlu19_0_split
I0926 14:52:17.058014  4911 net.cpp:406] Eltwise9_penlu19_0_split <- Eltwise9
I0926 14:52:17.058017  4911 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_0
I0926 14:52:17.058022  4911 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_1
I0926 14:52:17.058048  4911 net.cpp:122] Setting up Eltwise9_penlu19_0_split
I0926 14:52:17.079113  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.079123  4911 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 14:52:17.079128  4911 net.cpp:137] Memory required for data: 689358000
I0926 14:52:17.079133  4911 layer_factory.hpp:77] Creating layer Convolution20
I0926 14:52:17.079143  4911 net.cpp:84] Creating Layer Convolution20
I0926 14:52:17.079147  4911 net.cpp:406] Convolution20 <- Eltwise9_penlu19_0_split_0
I0926 14:52:17.079157  4911 net.cpp:380] Convolution20 -> Convolution20
I0926 14:52:17.080888  4911 net.cpp:122] Setting up Convolution20
I0926 14:52:17.080909  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.080911  4911 net.cpp:137] Memory required for data: 692634800
I0926 14:52:17.080916  4911 layer_factory.hpp:77] Creating layer BatchNorm20
I0926 14:52:17.080921  4911 net.cpp:84] Creating Layer BatchNorm20
I0926 14:52:17.080924  4911 net.cpp:406] BatchNorm20 <- Convolution20
I0926 14:52:17.080929  4911 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0926 14:52:17.081111  4911 net.cpp:122] Setting up BatchNorm20
I0926 14:52:17.081120  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.081123  4911 net.cpp:137] Memory required for data: 695911600
I0926 14:52:17.081131  4911 layer_factory.hpp:77] Creating layer Scale20
I0926 14:52:17.081140  4911 net.cpp:84] Creating Layer Scale20
I0926 14:52:17.081143  4911 net.cpp:406] Scale20 <- Convolution20
I0926 14:52:17.081149  4911 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0926 14:52:17.081185  4911 layer_factory.hpp:77] Creating layer Scale20
I0926 14:52:17.081271  4911 net.cpp:122] Setting up Scale20
I0926 14:52:17.081276  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.081279  4911 net.cpp:137] Memory required for data: 699188400
I0926 14:52:17.081282  4911 layer_factory.hpp:77] Creating layer Convolution21
I0926 14:52:17.081290  4911 net.cpp:84] Creating Layer Convolution21
I0926 14:52:17.081292  4911 net.cpp:406] Convolution21 <- Eltwise9_penlu19_0_split_1
I0926 14:52:17.081297  4911 net.cpp:380] Convolution21 -> Convolution21
I0926 14:52:17.082425  4911 net.cpp:122] Setting up Convolution21
I0926 14:52:17.082444  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.082448  4911 net.cpp:137] Memory required for data: 702465200
I0926 14:52:17.082453  4911 layer_factory.hpp:77] Creating layer BatchNorm21
I0926 14:52:17.082458  4911 net.cpp:84] Creating Layer BatchNorm21
I0926 14:52:17.082460  4911 net.cpp:406] BatchNorm21 <- Convolution21
I0926 14:52:17.082465  4911 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0926 14:52:17.082602  4911 net.cpp:122] Setting up BatchNorm21
I0926 14:52:17.082605  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.082607  4911 net.cpp:137] Memory required for data: 705742000
I0926 14:52:17.082612  4911 layer_factory.hpp:77] Creating layer Scale21
I0926 14:52:17.082617  4911 net.cpp:84] Creating Layer Scale21
I0926 14:52:17.082619  4911 net.cpp:406] Scale21 <- Convolution21
I0926 14:52:17.082623  4911 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0926 14:52:17.082648  4911 layer_factory.hpp:77] Creating layer Scale21
I0926 14:52:17.082720  4911 net.cpp:122] Setting up Scale21
I0926 14:52:17.082723  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.082726  4911 net.cpp:137] Memory required for data: 709018800
I0926 14:52:17.082729  4911 layer_factory.hpp:77] Creating layer penlu20
I0926 14:52:17.082736  4911 net.cpp:84] Creating Layer penlu20
I0926 14:52:17.082737  4911 net.cpp:406] penlu20 <- Convolution21
I0926 14:52:17.082741  4911 net.cpp:367] penlu20 -> Convolution21 (in-place)
I0926 14:52:17.082849  4911 net.cpp:122] Setting up penlu20
I0926 14:52:17.082854  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.082855  4911 net.cpp:137] Memory required for data: 712295600
I0926 14:52:17.082860  4911 layer_factory.hpp:77] Creating layer Convolution22
I0926 14:52:17.082866  4911 net.cpp:84] Creating Layer Convolution22
I0926 14:52:17.082870  4911 net.cpp:406] Convolution22 <- Convolution21
I0926 14:52:17.082873  4911 net.cpp:380] Convolution22 -> Convolution22
I0926 14:52:17.084008  4911 net.cpp:122] Setting up Convolution22
I0926 14:52:17.084017  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.084020  4911 net.cpp:137] Memory required for data: 715572400
I0926 14:52:17.084025  4911 layer_factory.hpp:77] Creating layer BatchNorm22
I0926 14:52:17.084030  4911 net.cpp:84] Creating Layer BatchNorm22
I0926 14:52:17.084033  4911 net.cpp:406] BatchNorm22 <- Convolution22
I0926 14:52:17.084038  4911 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0926 14:52:17.084167  4911 net.cpp:122] Setting up BatchNorm22
I0926 14:52:17.084172  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.084173  4911 net.cpp:137] Memory required for data: 718849200
I0926 14:52:17.084178  4911 layer_factory.hpp:77] Creating layer Scale22
I0926 14:52:17.084182  4911 net.cpp:84] Creating Layer Scale22
I0926 14:52:17.084184  4911 net.cpp:406] Scale22 <- Convolution22
I0926 14:52:17.084189  4911 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0926 14:52:17.084215  4911 layer_factory.hpp:77] Creating layer Scale22
I0926 14:52:17.084291  4911 net.cpp:122] Setting up Scale22
I0926 14:52:17.084295  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.084297  4911 net.cpp:137] Memory required for data: 722126000
I0926 14:52:17.084301  4911 layer_factory.hpp:77] Creating layer Eltwise10
I0926 14:52:17.084306  4911 net.cpp:84] Creating Layer Eltwise10
I0926 14:52:17.084308  4911 net.cpp:406] Eltwise10 <- Convolution20
I0926 14:52:17.084311  4911 net.cpp:406] Eltwise10 <- Convolution22
I0926 14:52:17.084314  4911 net.cpp:380] Eltwise10 -> Eltwise10
I0926 14:52:17.084327  4911 net.cpp:122] Setting up Eltwise10
I0926 14:52:17.084331  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.084333  4911 net.cpp:137] Memory required for data: 725402800
I0926 14:52:17.084336  4911 layer_factory.hpp:77] Creating layer penlu21
I0926 14:52:17.084342  4911 net.cpp:84] Creating Layer penlu21
I0926 14:52:17.084343  4911 net.cpp:406] penlu21 <- Eltwise10
I0926 14:52:17.084347  4911 net.cpp:367] penlu21 -> Eltwise10 (in-place)
I0926 14:52:17.084465  4911 net.cpp:122] Setting up penlu21
I0926 14:52:17.084470  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.084472  4911 net.cpp:137] Memory required for data: 728679600
I0926 14:52:17.084477  4911 layer_factory.hpp:77] Creating layer Eltwise10_penlu21_0_split
I0926 14:52:17.084482  4911 net.cpp:84] Creating Layer Eltwise10_penlu21_0_split
I0926 14:52:17.084484  4911 net.cpp:406] Eltwise10_penlu21_0_split <- Eltwise10
I0926 14:52:17.084503  4911 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_0
I0926 14:52:17.084517  4911 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_1
I0926 14:52:17.084552  4911 net.cpp:122] Setting up Eltwise10_penlu21_0_split
I0926 14:52:17.084555  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.084558  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.084559  4911 net.cpp:137] Memory required for data: 735233200
I0926 14:52:17.084563  4911 layer_factory.hpp:77] Creating layer Convolution23
I0926 14:52:17.084568  4911 net.cpp:84] Creating Layer Convolution23
I0926 14:52:17.084570  4911 net.cpp:406] Convolution23 <- Eltwise10_penlu21_0_split_0
I0926 14:52:17.084576  4911 net.cpp:380] Convolution23 -> Convolution23
I0926 14:52:17.085683  4911 net.cpp:122] Setting up Convolution23
I0926 14:52:17.085692  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.085695  4911 net.cpp:137] Memory required for data: 738510000
I0926 14:52:17.085700  4911 layer_factory.hpp:77] Creating layer BatchNorm23
I0926 14:52:17.085705  4911 net.cpp:84] Creating Layer BatchNorm23
I0926 14:52:17.085708  4911 net.cpp:406] BatchNorm23 <- Convolution23
I0926 14:52:17.085711  4911 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0926 14:52:17.085834  4911 net.cpp:122] Setting up BatchNorm23
I0926 14:52:17.085839  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.085841  4911 net.cpp:137] Memory required for data: 741786800
I0926 14:52:17.085845  4911 layer_factory.hpp:77] Creating layer Scale23
I0926 14:52:17.085850  4911 net.cpp:84] Creating Layer Scale23
I0926 14:52:17.085853  4911 net.cpp:406] Scale23 <- Convolution23
I0926 14:52:17.085856  4911 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0926 14:52:17.085881  4911 layer_factory.hpp:77] Creating layer Scale23
I0926 14:52:17.085957  4911 net.cpp:122] Setting up Scale23
I0926 14:52:17.085961  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.085963  4911 net.cpp:137] Memory required for data: 745063600
I0926 14:52:17.085968  4911 layer_factory.hpp:77] Creating layer penlu22
I0926 14:52:17.085973  4911 net.cpp:84] Creating Layer penlu22
I0926 14:52:17.085976  4911 net.cpp:406] penlu22 <- Convolution23
I0926 14:52:17.085979  4911 net.cpp:367] penlu22 -> Convolution23 (in-place)
I0926 14:52:17.086086  4911 net.cpp:122] Setting up penlu22
I0926 14:52:17.086089  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.086091  4911 net.cpp:137] Memory required for data: 748340400
I0926 14:52:17.086097  4911 layer_factory.hpp:77] Creating layer Convolution24
I0926 14:52:17.086102  4911 net.cpp:84] Creating Layer Convolution24
I0926 14:52:17.086105  4911 net.cpp:406] Convolution24 <- Convolution23
I0926 14:52:17.086109  4911 net.cpp:380] Convolution24 -> Convolution24
I0926 14:52:17.087211  4911 net.cpp:122] Setting up Convolution24
I0926 14:52:17.087221  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.087224  4911 net.cpp:137] Memory required for data: 751617200
I0926 14:52:17.087229  4911 layer_factory.hpp:77] Creating layer BatchNorm24
I0926 14:52:17.087232  4911 net.cpp:84] Creating Layer BatchNorm24
I0926 14:52:17.087235  4911 net.cpp:406] BatchNorm24 <- Convolution24
I0926 14:52:17.087239  4911 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0926 14:52:17.087366  4911 net.cpp:122] Setting up BatchNorm24
I0926 14:52:17.087370  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.087373  4911 net.cpp:137] Memory required for data: 754894000
I0926 14:52:17.087384  4911 layer_factory.hpp:77] Creating layer Scale24
I0926 14:52:17.087389  4911 net.cpp:84] Creating Layer Scale24
I0926 14:52:17.087391  4911 net.cpp:406] Scale24 <- Convolution24
I0926 14:52:17.087395  4911 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0926 14:52:17.087424  4911 layer_factory.hpp:77] Creating layer Scale24
I0926 14:52:17.087496  4911 net.cpp:122] Setting up Scale24
I0926 14:52:17.087499  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.087502  4911 net.cpp:137] Memory required for data: 758170800
I0926 14:52:17.087505  4911 layer_factory.hpp:77] Creating layer Eltwise11
I0926 14:52:17.087509  4911 net.cpp:84] Creating Layer Eltwise11
I0926 14:52:17.087512  4911 net.cpp:406] Eltwise11 <- Eltwise10_penlu21_0_split_1
I0926 14:52:17.087515  4911 net.cpp:406] Eltwise11 <- Convolution24
I0926 14:52:17.087519  4911 net.cpp:380] Eltwise11 -> Eltwise11
I0926 14:52:17.087530  4911 net.cpp:122] Setting up Eltwise11
I0926 14:52:17.087534  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.087537  4911 net.cpp:137] Memory required for data: 761447600
I0926 14:52:17.087538  4911 layer_factory.hpp:77] Creating layer penlu23
I0926 14:52:17.087543  4911 net.cpp:84] Creating Layer penlu23
I0926 14:52:17.087545  4911 net.cpp:406] penlu23 <- Eltwise11
I0926 14:52:17.087549  4911 net.cpp:367] penlu23 -> Eltwise11 (in-place)
I0926 14:52:17.087659  4911 net.cpp:122] Setting up penlu23
I0926 14:52:17.087664  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.087666  4911 net.cpp:137] Memory required for data: 764724400
I0926 14:52:17.087671  4911 layer_factory.hpp:77] Creating layer Eltwise11_penlu23_0_split
I0926 14:52:17.087674  4911 net.cpp:84] Creating Layer Eltwise11_penlu23_0_split
I0926 14:52:17.087677  4911 net.cpp:406] Eltwise11_penlu23_0_split <- Eltwise11
I0926 14:52:17.087680  4911 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_0
I0926 14:52:17.087685  4911 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_1
I0926 14:52:17.087707  4911 net.cpp:122] Setting up Eltwise11_penlu23_0_split
I0926 14:52:17.087710  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.087713  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.087715  4911 net.cpp:137] Memory required for data: 771278000
I0926 14:52:17.087718  4911 layer_factory.hpp:77] Creating layer Convolution25
I0926 14:52:17.087723  4911 net.cpp:84] Creating Layer Convolution25
I0926 14:52:17.087726  4911 net.cpp:406] Convolution25 <- Eltwise11_penlu23_0_split_0
I0926 14:52:17.087730  4911 net.cpp:380] Convolution25 -> Convolution25
I0926 14:52:17.088857  4911 net.cpp:122] Setting up Convolution25
I0926 14:52:17.088866  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.088870  4911 net.cpp:137] Memory required for data: 774554800
I0926 14:52:17.088873  4911 layer_factory.hpp:77] Creating layer BatchNorm25
I0926 14:52:17.088879  4911 net.cpp:84] Creating Layer BatchNorm25
I0926 14:52:17.088881  4911 net.cpp:406] BatchNorm25 <- Convolution25
I0926 14:52:17.088886  4911 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0926 14:52:17.089015  4911 net.cpp:122] Setting up BatchNorm25
I0926 14:52:17.089020  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.089021  4911 net.cpp:137] Memory required for data: 777831600
I0926 14:52:17.089026  4911 layer_factory.hpp:77] Creating layer Scale25
I0926 14:52:17.089030  4911 net.cpp:84] Creating Layer Scale25
I0926 14:52:17.089032  4911 net.cpp:406] Scale25 <- Convolution25
I0926 14:52:17.089036  4911 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0926 14:52:17.089062  4911 layer_factory.hpp:77] Creating layer Scale25
I0926 14:52:17.089135  4911 net.cpp:122] Setting up Scale25
I0926 14:52:17.089139  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.089141  4911 net.cpp:137] Memory required for data: 781108400
I0926 14:52:17.089145  4911 layer_factory.hpp:77] Creating layer penlu24
I0926 14:52:17.089150  4911 net.cpp:84] Creating Layer penlu24
I0926 14:52:17.089160  4911 net.cpp:406] penlu24 <- Convolution25
I0926 14:52:17.089164  4911 net.cpp:367] penlu24 -> Convolution25 (in-place)
I0926 14:52:17.089272  4911 net.cpp:122] Setting up penlu24
I0926 14:52:17.089277  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.089278  4911 net.cpp:137] Memory required for data: 784385200
I0926 14:52:17.089283  4911 layer_factory.hpp:77] Creating layer Convolution26
I0926 14:52:17.089290  4911 net.cpp:84] Creating Layer Convolution26
I0926 14:52:17.089293  4911 net.cpp:406] Convolution26 <- Convolution25
I0926 14:52:17.089298  4911 net.cpp:380] Convolution26 -> Convolution26
I0926 14:52:17.090064  4911 net.cpp:122] Setting up Convolution26
I0926 14:52:17.090072  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.090075  4911 net.cpp:137] Memory required for data: 787662000
I0926 14:52:17.090080  4911 layer_factory.hpp:77] Creating layer BatchNorm26
I0926 14:52:17.090085  4911 net.cpp:84] Creating Layer BatchNorm26
I0926 14:52:17.090086  4911 net.cpp:406] BatchNorm26 <- Convolution26
I0926 14:52:17.090090  4911 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0926 14:52:17.090214  4911 net.cpp:122] Setting up BatchNorm26
I0926 14:52:17.090219  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.090220  4911 net.cpp:137] Memory required for data: 790938800
I0926 14:52:17.090225  4911 layer_factory.hpp:77] Creating layer Scale26
I0926 14:52:17.090230  4911 net.cpp:84] Creating Layer Scale26
I0926 14:52:17.090232  4911 net.cpp:406] Scale26 <- Convolution26
I0926 14:52:17.090235  4911 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0926 14:52:17.090260  4911 layer_factory.hpp:77] Creating layer Scale26
I0926 14:52:17.110208  4911 net.cpp:122] Setting up Scale26
I0926 14:52:17.110218  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.110220  4911 net.cpp:137] Memory required for data: 794215600
I0926 14:52:17.110225  4911 layer_factory.hpp:77] Creating layer Eltwise12
I0926 14:52:17.110230  4911 net.cpp:84] Creating Layer Eltwise12
I0926 14:52:17.110232  4911 net.cpp:406] Eltwise12 <- Eltwise11_penlu23_0_split_1
I0926 14:52:17.110237  4911 net.cpp:406] Eltwise12 <- Convolution26
I0926 14:52:17.110241  4911 net.cpp:380] Eltwise12 -> Eltwise12
I0926 14:52:17.110255  4911 net.cpp:122] Setting up Eltwise12
I0926 14:52:17.110260  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.110262  4911 net.cpp:137] Memory required for data: 797492400
I0926 14:52:17.110265  4911 layer_factory.hpp:77] Creating layer penlu25
I0926 14:52:17.110278  4911 net.cpp:84] Creating Layer penlu25
I0926 14:52:17.110281  4911 net.cpp:406] penlu25 <- Eltwise12
I0926 14:52:17.110285  4911 net.cpp:367] penlu25 -> Eltwise12 (in-place)
I0926 14:52:17.110406  4911 net.cpp:122] Setting up penlu25
I0926 14:52:17.110412  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.110414  4911 net.cpp:137] Memory required for data: 800769200
I0926 14:52:17.110440  4911 layer_factory.hpp:77] Creating layer Eltwise12_penlu25_0_split
I0926 14:52:17.110443  4911 net.cpp:84] Creating Layer Eltwise12_penlu25_0_split
I0926 14:52:17.110446  4911 net.cpp:406] Eltwise12_penlu25_0_split <- Eltwise12
I0926 14:52:17.110450  4911 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_0
I0926 14:52:17.110455  4911 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_1
I0926 14:52:17.110482  4911 net.cpp:122] Setting up Eltwise12_penlu25_0_split
I0926 14:52:17.110486  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.110489  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.110491  4911 net.cpp:137] Memory required for data: 807322800
I0926 14:52:17.110493  4911 layer_factory.hpp:77] Creating layer Convolution27
I0926 14:52:17.110501  4911 net.cpp:84] Creating Layer Convolution27
I0926 14:52:17.110503  4911 net.cpp:406] Convolution27 <- Eltwise12_penlu25_0_split_0
I0926 14:52:17.110508  4911 net.cpp:380] Convolution27 -> Convolution27
I0926 14:52:17.112269  4911 net.cpp:122] Setting up Convolution27
I0926 14:52:17.112285  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.112288  4911 net.cpp:137] Memory required for data: 810599600
I0926 14:52:17.112293  4911 layer_factory.hpp:77] Creating layer BatchNorm27
I0926 14:52:17.112298  4911 net.cpp:84] Creating Layer BatchNorm27
I0926 14:52:17.112301  4911 net.cpp:406] BatchNorm27 <- Convolution27
I0926 14:52:17.112305  4911 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0926 14:52:17.112431  4911 net.cpp:122] Setting up BatchNorm27
I0926 14:52:17.112435  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.112437  4911 net.cpp:137] Memory required for data: 813876400
I0926 14:52:17.112442  4911 layer_factory.hpp:77] Creating layer Scale27
I0926 14:52:17.112447  4911 net.cpp:84] Creating Layer Scale27
I0926 14:52:17.112450  4911 net.cpp:406] Scale27 <- Convolution27
I0926 14:52:17.112453  4911 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0926 14:52:17.112479  4911 layer_factory.hpp:77] Creating layer Scale27
I0926 14:52:17.112578  4911 net.cpp:122] Setting up Scale27
I0926 14:52:17.112583  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.112586  4911 net.cpp:137] Memory required for data: 817153200
I0926 14:52:17.112589  4911 layer_factory.hpp:77] Creating layer penlu26
I0926 14:52:17.112596  4911 net.cpp:84] Creating Layer penlu26
I0926 14:52:17.112597  4911 net.cpp:406] penlu26 <- Convolution27
I0926 14:52:17.112602  4911 net.cpp:367] penlu26 -> Convolution27 (in-place)
I0926 14:52:17.112709  4911 net.cpp:122] Setting up penlu26
I0926 14:52:17.112713  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.112715  4911 net.cpp:137] Memory required for data: 820430000
I0926 14:52:17.112720  4911 layer_factory.hpp:77] Creating layer Convolution28
I0926 14:52:17.112727  4911 net.cpp:84] Creating Layer Convolution28
I0926 14:52:17.112730  4911 net.cpp:406] Convolution28 <- Convolution27
I0926 14:52:17.112733  4911 net.cpp:380] Convolution28 -> Convolution28
I0926 14:52:17.114231  4911 net.cpp:122] Setting up Convolution28
I0926 14:52:17.114240  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.114243  4911 net.cpp:137] Memory required for data: 823706800
I0926 14:52:17.114248  4911 layer_factory.hpp:77] Creating layer BatchNorm28
I0926 14:52:17.114253  4911 net.cpp:84] Creating Layer BatchNorm28
I0926 14:52:17.114256  4911 net.cpp:406] BatchNorm28 <- Convolution28
I0926 14:52:17.114259  4911 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0926 14:52:17.114392  4911 net.cpp:122] Setting up BatchNorm28
I0926 14:52:17.114397  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.114398  4911 net.cpp:137] Memory required for data: 826983600
I0926 14:52:17.114403  4911 layer_factory.hpp:77] Creating layer Scale28
I0926 14:52:17.114408  4911 net.cpp:84] Creating Layer Scale28
I0926 14:52:17.114410  4911 net.cpp:406] Scale28 <- Convolution28
I0926 14:52:17.114414  4911 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0926 14:52:17.114441  4911 layer_factory.hpp:77] Creating layer Scale28
I0926 14:52:17.114516  4911 net.cpp:122] Setting up Scale28
I0926 14:52:17.114521  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.114522  4911 net.cpp:137] Memory required for data: 830260400
I0926 14:52:17.114526  4911 layer_factory.hpp:77] Creating layer Eltwise13
I0926 14:52:17.114531  4911 net.cpp:84] Creating Layer Eltwise13
I0926 14:52:17.114534  4911 net.cpp:406] Eltwise13 <- Eltwise12_penlu25_0_split_1
I0926 14:52:17.114537  4911 net.cpp:406] Eltwise13 <- Convolution28
I0926 14:52:17.114540  4911 net.cpp:380] Eltwise13 -> Eltwise13
I0926 14:52:17.114553  4911 net.cpp:122] Setting up Eltwise13
I0926 14:52:17.114557  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.114559  4911 net.cpp:137] Memory required for data: 833537200
I0926 14:52:17.114562  4911 layer_factory.hpp:77] Creating layer penlu27
I0926 14:52:17.114565  4911 net.cpp:84] Creating Layer penlu27
I0926 14:52:17.114568  4911 net.cpp:406] penlu27 <- Eltwise13
I0926 14:52:17.114573  4911 net.cpp:367] penlu27 -> Eltwise13 (in-place)
I0926 14:52:17.114691  4911 net.cpp:122] Setting up penlu27
I0926 14:52:17.114696  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.114698  4911 net.cpp:137] Memory required for data: 836814000
I0926 14:52:17.114703  4911 layer_factory.hpp:77] Creating layer Eltwise13_penlu27_0_split
I0926 14:52:17.114707  4911 net.cpp:84] Creating Layer Eltwise13_penlu27_0_split
I0926 14:52:17.114709  4911 net.cpp:406] Eltwise13_penlu27_0_split <- Eltwise13
I0926 14:52:17.114712  4911 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_0
I0926 14:52:17.114717  4911 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_1
I0926 14:52:17.114739  4911 net.cpp:122] Setting up Eltwise13_penlu27_0_split
I0926 14:52:17.114743  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.114747  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.114748  4911 net.cpp:137] Memory required for data: 843367600
I0926 14:52:17.114750  4911 layer_factory.hpp:77] Creating layer Convolution29
I0926 14:52:17.114756  4911 net.cpp:84] Creating Layer Convolution29
I0926 14:52:17.114759  4911 net.cpp:406] Convolution29 <- Eltwise13_penlu27_0_split_0
I0926 14:52:17.114763  4911 net.cpp:380] Convolution29 -> Convolution29
I0926 14:52:17.115872  4911 net.cpp:122] Setting up Convolution29
I0926 14:52:17.115881  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.115885  4911 net.cpp:137] Memory required for data: 846644400
I0926 14:52:17.115888  4911 layer_factory.hpp:77] Creating layer BatchNorm29
I0926 14:52:17.115893  4911 net.cpp:84] Creating Layer BatchNorm29
I0926 14:52:17.141160  4911 net.cpp:406] BatchNorm29 <- Convolution29
I0926 14:52:17.141176  4911 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0926 14:52:17.141327  4911 net.cpp:122] Setting up BatchNorm29
I0926 14:52:17.141332  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.141335  4911 net.cpp:137] Memory required for data: 849921200
I0926 14:52:17.141341  4911 layer_factory.hpp:77] Creating layer Scale29
I0926 14:52:17.141346  4911 net.cpp:84] Creating Layer Scale29
I0926 14:52:17.141348  4911 net.cpp:406] Scale29 <- Convolution29
I0926 14:52:17.141352  4911 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0926 14:52:17.141384  4911 layer_factory.hpp:77] Creating layer Scale29
I0926 14:52:17.141465  4911 net.cpp:122] Setting up Scale29
I0926 14:52:17.141469  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.141472  4911 net.cpp:137] Memory required for data: 853198000
I0926 14:52:17.141476  4911 layer_factory.hpp:77] Creating layer penlu28
I0926 14:52:17.141482  4911 net.cpp:84] Creating Layer penlu28
I0926 14:52:17.141485  4911 net.cpp:406] penlu28 <- Convolution29
I0926 14:52:17.141489  4911 net.cpp:367] penlu28 -> Convolution29 (in-place)
I0926 14:52:17.141605  4911 net.cpp:122] Setting up penlu28
I0926 14:52:17.141610  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.141613  4911 net.cpp:137] Memory required for data: 856474800
I0926 14:52:17.141618  4911 layer_factory.hpp:77] Creating layer Convolution30
I0926 14:52:17.141624  4911 net.cpp:84] Creating Layer Convolution30
I0926 14:52:17.141628  4911 net.cpp:406] Convolution30 <- Convolution29
I0926 14:52:17.141633  4911 net.cpp:380] Convolution30 -> Convolution30
I0926 14:52:17.142921  4911 net.cpp:122] Setting up Convolution30
I0926 14:52:17.142931  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.142933  4911 net.cpp:137] Memory required for data: 859751600
I0926 14:52:17.142938  4911 layer_factory.hpp:77] Creating layer BatchNorm30
I0926 14:52:17.142943  4911 net.cpp:84] Creating Layer BatchNorm30
I0926 14:52:17.142946  4911 net.cpp:406] BatchNorm30 <- Convolution30
I0926 14:52:17.142951  4911 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0926 14:52:17.143076  4911 net.cpp:122] Setting up BatchNorm30
I0926 14:52:17.143080  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.143084  4911 net.cpp:137] Memory required for data: 863028400
I0926 14:52:17.143095  4911 layer_factory.hpp:77] Creating layer Scale30
I0926 14:52:17.143100  4911 net.cpp:84] Creating Layer Scale30
I0926 14:52:17.143103  4911 net.cpp:406] Scale30 <- Convolution30
I0926 14:52:17.143107  4911 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0926 14:52:17.143133  4911 layer_factory.hpp:77] Creating layer Scale30
I0926 14:52:17.143229  4911 net.cpp:122] Setting up Scale30
I0926 14:52:17.143234  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.143235  4911 net.cpp:137] Memory required for data: 866305200
I0926 14:52:17.143239  4911 layer_factory.hpp:77] Creating layer Eltwise14
I0926 14:52:17.143244  4911 net.cpp:84] Creating Layer Eltwise14
I0926 14:52:17.143245  4911 net.cpp:406] Eltwise14 <- Eltwise13_penlu27_0_split_1
I0926 14:52:17.143249  4911 net.cpp:406] Eltwise14 <- Convolution30
I0926 14:52:17.143251  4911 net.cpp:380] Eltwise14 -> Eltwise14
I0926 14:52:17.143275  4911 net.cpp:122] Setting up Eltwise14
I0926 14:52:17.143277  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.143280  4911 net.cpp:137] Memory required for data: 869582000
I0926 14:52:17.143282  4911 layer_factory.hpp:77] Creating layer penlu29
I0926 14:52:17.143288  4911 net.cpp:84] Creating Layer penlu29
I0926 14:52:17.143291  4911 net.cpp:406] penlu29 <- Eltwise14
I0926 14:52:17.143295  4911 net.cpp:367] penlu29 -> Eltwise14 (in-place)
I0926 14:52:17.143414  4911 net.cpp:122] Setting up penlu29
I0926 14:52:17.143419  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.143421  4911 net.cpp:137] Memory required for data: 872858800
I0926 14:52:17.143425  4911 layer_factory.hpp:77] Creating layer Eltwise14_penlu29_0_split
I0926 14:52:17.143430  4911 net.cpp:84] Creating Layer Eltwise14_penlu29_0_split
I0926 14:52:17.143432  4911 net.cpp:406] Eltwise14_penlu29_0_split <- Eltwise14
I0926 14:52:17.143435  4911 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_0
I0926 14:52:17.143440  4911 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_1
I0926 14:52:17.143465  4911 net.cpp:122] Setting up Eltwise14_penlu29_0_split
I0926 14:52:17.143468  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.143471  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.143473  4911 net.cpp:137] Memory required for data: 879412400
I0926 14:52:17.143476  4911 layer_factory.hpp:77] Creating layer Convolution31
I0926 14:52:17.143481  4911 net.cpp:84] Creating Layer Convolution31
I0926 14:52:17.143483  4911 net.cpp:406] Convolution31 <- Eltwise14_penlu29_0_split_0
I0926 14:52:17.143488  4911 net.cpp:380] Convolution31 -> Convolution31
I0926 14:52:17.144659  4911 net.cpp:122] Setting up Convolution31
I0926 14:52:17.144667  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.144670  4911 net.cpp:137] Memory required for data: 882689200
I0926 14:52:17.144675  4911 layer_factory.hpp:77] Creating layer BatchNorm31
I0926 14:52:17.144680  4911 net.cpp:84] Creating Layer BatchNorm31
I0926 14:52:17.144683  4911 net.cpp:406] BatchNorm31 <- Convolution31
I0926 14:52:17.144687  4911 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0926 14:52:17.144812  4911 net.cpp:122] Setting up BatchNorm31
I0926 14:52:17.144816  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.144819  4911 net.cpp:137] Memory required for data: 885966000
I0926 14:52:17.144824  4911 layer_factory.hpp:77] Creating layer Scale31
I0926 14:52:17.144829  4911 net.cpp:84] Creating Layer Scale31
I0926 14:52:17.144831  4911 net.cpp:406] Scale31 <- Convolution31
I0926 14:52:17.144834  4911 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0926 14:52:17.144861  4911 layer_factory.hpp:77] Creating layer Scale31
I0926 14:52:17.144933  4911 net.cpp:122] Setting up Scale31
I0926 14:52:17.144937  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.144939  4911 net.cpp:137] Memory required for data: 889242800
I0926 14:52:17.144943  4911 layer_factory.hpp:77] Creating layer penlu30
I0926 14:52:17.144949  4911 net.cpp:84] Creating Layer penlu30
I0926 14:52:17.144958  4911 net.cpp:406] penlu30 <- Convolution31
I0926 14:52:17.144963  4911 net.cpp:367] penlu30 -> Convolution31 (in-place)
I0926 14:52:17.145067  4911 net.cpp:122] Setting up penlu30
I0926 14:52:17.145071  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.145073  4911 net.cpp:137] Memory required for data: 892519600
I0926 14:52:17.145078  4911 layer_factory.hpp:77] Creating layer Convolution32
I0926 14:52:17.145086  4911 net.cpp:84] Creating Layer Convolution32
I0926 14:52:17.145088  4911 net.cpp:406] Convolution32 <- Convolution31
I0926 14:52:17.145092  4911 net.cpp:380] Convolution32 -> Convolution32
I0926 14:52:17.146209  4911 net.cpp:122] Setting up Convolution32
I0926 14:52:17.146219  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.146220  4911 net.cpp:137] Memory required for data: 895796400
I0926 14:52:17.146225  4911 layer_factory.hpp:77] Creating layer BatchNorm32
I0926 14:52:17.146229  4911 net.cpp:84] Creating Layer BatchNorm32
I0926 14:52:17.146232  4911 net.cpp:406] BatchNorm32 <- Convolution32
I0926 14:52:17.146236  4911 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I0926 14:52:17.146363  4911 net.cpp:122] Setting up BatchNorm32
I0926 14:52:17.146368  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.146369  4911 net.cpp:137] Memory required for data: 899073200
I0926 14:52:17.146374  4911 layer_factory.hpp:77] Creating layer Scale32
I0926 14:52:17.146378  4911 net.cpp:84] Creating Layer Scale32
I0926 14:52:17.146381  4911 net.cpp:406] Scale32 <- Convolution32
I0926 14:52:17.146384  4911 net.cpp:367] Scale32 -> Convolution32 (in-place)
I0926 14:52:17.146410  4911 layer_factory.hpp:77] Creating layer Scale32
I0926 14:52:17.146486  4911 net.cpp:122] Setting up Scale32
I0926 14:52:17.146489  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.146492  4911 net.cpp:137] Memory required for data: 902350000
I0926 14:52:17.146495  4911 layer_factory.hpp:77] Creating layer Eltwise15
I0926 14:52:17.146499  4911 net.cpp:84] Creating Layer Eltwise15
I0926 14:52:17.146502  4911 net.cpp:406] Eltwise15 <- Eltwise14_penlu29_0_split_1
I0926 14:52:17.146505  4911 net.cpp:406] Eltwise15 <- Convolution32
I0926 14:52:17.146509  4911 net.cpp:380] Eltwise15 -> Eltwise15
I0926 14:52:17.146522  4911 net.cpp:122] Setting up Eltwise15
I0926 14:52:17.146524  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.146526  4911 net.cpp:137] Memory required for data: 905626800
I0926 14:52:17.146529  4911 layer_factory.hpp:77] Creating layer penlu31
I0926 14:52:17.146534  4911 net.cpp:84] Creating Layer penlu31
I0926 14:52:17.146536  4911 net.cpp:406] penlu31 <- Eltwise15
I0926 14:52:17.146540  4911 net.cpp:367] penlu31 -> Eltwise15 (in-place)
I0926 14:52:17.146651  4911 net.cpp:122] Setting up penlu31
I0926 14:52:17.146656  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.146658  4911 net.cpp:137] Memory required for data: 908903600
I0926 14:52:17.146662  4911 layer_factory.hpp:77] Creating layer Eltwise15_penlu31_0_split
I0926 14:52:17.146667  4911 net.cpp:84] Creating Layer Eltwise15_penlu31_0_split
I0926 14:52:17.146668  4911 net.cpp:406] Eltwise15_penlu31_0_split <- Eltwise15
I0926 14:52:17.146672  4911 net.cpp:380] Eltwise15_penlu31_0_split -> Eltwise15_penlu31_0_split_0
I0926 14:52:17.146677  4911 net.cpp:380] Eltwise15_penlu31_0_split -> Eltwise15_penlu31_0_split_1
I0926 14:52:17.146699  4911 net.cpp:122] Setting up Eltwise15_penlu31_0_split
I0926 14:52:17.146703  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.146705  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.146708  4911 net.cpp:137] Memory required for data: 915457200
I0926 14:52:17.146709  4911 layer_factory.hpp:77] Creating layer Convolution33
I0926 14:52:17.146715  4911 net.cpp:84] Creating Layer Convolution33
I0926 14:52:17.146718  4911 net.cpp:406] Convolution33 <- Eltwise15_penlu31_0_split_0
I0926 14:52:17.146723  4911 net.cpp:380] Convolution33 -> Convolution33
I0926 14:52:17.147846  4911 net.cpp:122] Setting up Convolution33
I0926 14:52:17.147861  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.147864  4911 net.cpp:137] Memory required for data: 918734000
I0926 14:52:17.147869  4911 layer_factory.hpp:77] Creating layer BatchNorm33
I0926 14:52:17.147876  4911 net.cpp:84] Creating Layer BatchNorm33
I0926 14:52:17.147878  4911 net.cpp:406] BatchNorm33 <- Convolution33
I0926 14:52:17.147882  4911 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I0926 14:52:17.148012  4911 net.cpp:122] Setting up BatchNorm33
I0926 14:52:17.148016  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.148018  4911 net.cpp:137] Memory required for data: 922010800
I0926 14:52:17.148023  4911 layer_factory.hpp:77] Creating layer Scale33
I0926 14:52:17.148027  4911 net.cpp:84] Creating Layer Scale33
I0926 14:52:17.148030  4911 net.cpp:406] Scale33 <- Convolution33
I0926 14:52:17.148035  4911 net.cpp:367] Scale33 -> Convolution33 (in-place)
I0926 14:52:17.148059  4911 layer_factory.hpp:77] Creating layer Scale33
I0926 14:52:17.148134  4911 net.cpp:122] Setting up Scale33
I0926 14:52:17.148138  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.148140  4911 net.cpp:137] Memory required for data: 925287600
I0926 14:52:17.148144  4911 layer_factory.hpp:77] Creating layer penlu32
I0926 14:52:17.148149  4911 net.cpp:84] Creating Layer penlu32
I0926 14:52:17.148151  4911 net.cpp:406] penlu32 <- Convolution33
I0926 14:52:17.148155  4911 net.cpp:367] penlu32 -> Convolution33 (in-place)
I0926 14:52:17.148263  4911 net.cpp:122] Setting up penlu32
I0926 14:52:17.148267  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.148269  4911 net.cpp:137] Memory required for data: 928564400
I0926 14:52:17.148274  4911 layer_factory.hpp:77] Creating layer Convolution34
I0926 14:52:17.148281  4911 net.cpp:84] Creating Layer Convolution34
I0926 14:52:17.148283  4911 net.cpp:406] Convolution34 <- Convolution33
I0926 14:52:17.148288  4911 net.cpp:380] Convolution34 -> Convolution34
I0926 14:52:17.149952  4911 net.cpp:122] Setting up Convolution34
I0926 14:52:17.149961  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.149965  4911 net.cpp:137] Memory required for data: 931841200
I0926 14:52:17.149968  4911 layer_factory.hpp:77] Creating layer BatchNorm34
I0926 14:52:17.149974  4911 net.cpp:84] Creating Layer BatchNorm34
I0926 14:52:17.149977  4911 net.cpp:406] BatchNorm34 <- Convolution34
I0926 14:52:17.149981  4911 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I0926 14:52:17.150111  4911 net.cpp:122] Setting up BatchNorm34
I0926 14:52:17.150116  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.150118  4911 net.cpp:137] Memory required for data: 935118000
I0926 14:52:17.150123  4911 layer_factory.hpp:77] Creating layer Scale34
I0926 14:52:17.150127  4911 net.cpp:84] Creating Layer Scale34
I0926 14:52:17.150130  4911 net.cpp:406] Scale34 <- Convolution34
I0926 14:52:17.150133  4911 net.cpp:367] Scale34 -> Convolution34 (in-place)
I0926 14:52:17.150161  4911 layer_factory.hpp:77] Creating layer Scale34
I0926 14:52:17.150235  4911 net.cpp:122] Setting up Scale34
I0926 14:52:17.150240  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.150243  4911 net.cpp:137] Memory required for data: 938394800
I0926 14:52:17.150246  4911 layer_factory.hpp:77] Creating layer Eltwise16
I0926 14:52:17.150250  4911 net.cpp:84] Creating Layer Eltwise16
I0926 14:52:17.150254  4911 net.cpp:406] Eltwise16 <- Eltwise15_penlu31_0_split_1
I0926 14:52:17.150255  4911 net.cpp:406] Eltwise16 <- Convolution34
I0926 14:52:17.150259  4911 net.cpp:380] Eltwise16 -> Eltwise16
I0926 14:52:17.150271  4911 net.cpp:122] Setting up Eltwise16
I0926 14:52:17.150275  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.150277  4911 net.cpp:137] Memory required for data: 941671600
I0926 14:52:17.150279  4911 layer_factory.hpp:77] Creating layer penlu33
I0926 14:52:17.150285  4911 net.cpp:84] Creating Layer penlu33
I0926 14:52:17.150287  4911 net.cpp:406] penlu33 <- Eltwise16
I0926 14:52:17.150298  4911 net.cpp:367] penlu33 -> Eltwise16 (in-place)
I0926 14:52:17.150413  4911 net.cpp:122] Setting up penlu33
I0926 14:52:17.150418  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.150419  4911 net.cpp:137] Memory required for data: 944948400
I0926 14:52:17.150424  4911 layer_factory.hpp:77] Creating layer Eltwise16_penlu33_0_split
I0926 14:52:17.150427  4911 net.cpp:84] Creating Layer Eltwise16_penlu33_0_split
I0926 14:52:17.150429  4911 net.cpp:406] Eltwise16_penlu33_0_split <- Eltwise16
I0926 14:52:17.150434  4911 net.cpp:380] Eltwise16_penlu33_0_split -> Eltwise16_penlu33_0_split_0
I0926 14:52:17.150439  4911 net.cpp:380] Eltwise16_penlu33_0_split -> Eltwise16_penlu33_0_split_1
I0926 14:52:17.150461  4911 net.cpp:122] Setting up Eltwise16_penlu33_0_split
I0926 14:52:17.150465  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.150468  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.150470  4911 net.cpp:137] Memory required for data: 951502000
I0926 14:52:17.150472  4911 layer_factory.hpp:77] Creating layer Convolution35
I0926 14:52:17.150478  4911 net.cpp:84] Creating Layer Convolution35
I0926 14:52:17.150481  4911 net.cpp:406] Convolution35 <- Eltwise16_penlu33_0_split_0
I0926 14:52:17.150485  4911 net.cpp:380] Convolution35 -> Convolution35
I0926 14:52:17.151617  4911 net.cpp:122] Setting up Convolution35
I0926 14:52:17.151625  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.151628  4911 net.cpp:137] Memory required for data: 954778800
I0926 14:52:17.151633  4911 layer_factory.hpp:77] Creating layer BatchNorm35
I0926 14:52:17.151638  4911 net.cpp:84] Creating Layer BatchNorm35
I0926 14:52:17.151640  4911 net.cpp:406] BatchNorm35 <- Convolution35
I0926 14:52:17.151644  4911 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I0926 14:52:17.151774  4911 net.cpp:122] Setting up BatchNorm35
I0926 14:52:17.151778  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.151780  4911 net.cpp:137] Memory required for data: 958055600
I0926 14:52:17.151785  4911 layer_factory.hpp:77] Creating layer Scale35
I0926 14:52:17.151790  4911 net.cpp:84] Creating Layer Scale35
I0926 14:52:17.151793  4911 net.cpp:406] Scale35 <- Convolution35
I0926 14:52:17.151796  4911 net.cpp:367] Scale35 -> Convolution35 (in-place)
I0926 14:52:17.151823  4911 layer_factory.hpp:77] Creating layer Scale35
I0926 14:52:17.151901  4911 net.cpp:122] Setting up Scale35
I0926 14:52:17.151906  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.151907  4911 net.cpp:137] Memory required for data: 961332400
I0926 14:52:17.151911  4911 layer_factory.hpp:77] Creating layer penlu34
I0926 14:52:17.151916  4911 net.cpp:84] Creating Layer penlu34
I0926 14:52:17.151919  4911 net.cpp:406] penlu34 <- Convolution35
I0926 14:52:17.151923  4911 net.cpp:367] penlu34 -> Convolution35 (in-place)
I0926 14:52:17.152029  4911 net.cpp:122] Setting up penlu34
I0926 14:52:17.152034  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.152035  4911 net.cpp:137] Memory required for data: 964609200
I0926 14:52:17.152040  4911 layer_factory.hpp:77] Creating layer Convolution36
I0926 14:52:17.152045  4911 net.cpp:84] Creating Layer Convolution36
I0926 14:52:17.152048  4911 net.cpp:406] Convolution36 <- Convolution35
I0926 14:52:17.152052  4911 net.cpp:380] Convolution36 -> Convolution36
I0926 14:52:17.152854  4911 net.cpp:122] Setting up Convolution36
I0926 14:52:17.152863  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.152865  4911 net.cpp:137] Memory required for data: 967886000
I0926 14:52:17.152869  4911 layer_factory.hpp:77] Creating layer BatchNorm36
I0926 14:52:17.152874  4911 net.cpp:84] Creating Layer BatchNorm36
I0926 14:52:17.152878  4911 net.cpp:406] BatchNorm36 <- Convolution36
I0926 14:52:17.152881  4911 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I0926 14:52:17.153013  4911 net.cpp:122] Setting up BatchNorm36
I0926 14:52:17.153017  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.153019  4911 net.cpp:137] Memory required for data: 971162800
I0926 14:52:17.153031  4911 layer_factory.hpp:77] Creating layer Scale36
I0926 14:52:17.153036  4911 net.cpp:84] Creating Layer Scale36
I0926 14:52:17.153039  4911 net.cpp:406] Scale36 <- Convolution36
I0926 14:52:17.153043  4911 net.cpp:367] Scale36 -> Convolution36 (in-place)
I0926 14:52:17.153070  4911 layer_factory.hpp:77] Creating layer Scale36
I0926 14:52:17.153146  4911 net.cpp:122] Setting up Scale36
I0926 14:52:17.153151  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.153153  4911 net.cpp:137] Memory required for data: 974439600
I0926 14:52:17.153156  4911 layer_factory.hpp:77] Creating layer Eltwise17
I0926 14:52:17.153161  4911 net.cpp:84] Creating Layer Eltwise17
I0926 14:52:17.153163  4911 net.cpp:406] Eltwise17 <- Eltwise16_penlu33_0_split_1
I0926 14:52:17.153167  4911 net.cpp:406] Eltwise17 <- Convolution36
I0926 14:52:17.153170  4911 net.cpp:380] Eltwise17 -> Eltwise17
I0926 14:52:17.153182  4911 net.cpp:122] Setting up Eltwise17
I0926 14:52:17.153185  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.153187  4911 net.cpp:137] Memory required for data: 977716400
I0926 14:52:17.153189  4911 layer_factory.hpp:77] Creating layer penlu35
I0926 14:52:17.153195  4911 net.cpp:84] Creating Layer penlu35
I0926 14:52:17.153198  4911 net.cpp:406] penlu35 <- Eltwise17
I0926 14:52:17.153201  4911 net.cpp:367] penlu35 -> Eltwise17 (in-place)
I0926 14:52:17.153312  4911 net.cpp:122] Setting up penlu35
I0926 14:52:17.153316  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.153318  4911 net.cpp:137] Memory required for data: 980993200
I0926 14:52:17.153323  4911 layer_factory.hpp:77] Creating layer Eltwise17_penlu35_0_split
I0926 14:52:17.153326  4911 net.cpp:84] Creating Layer Eltwise17_penlu35_0_split
I0926 14:52:17.153328  4911 net.cpp:406] Eltwise17_penlu35_0_split <- Eltwise17
I0926 14:52:17.153332  4911 net.cpp:380] Eltwise17_penlu35_0_split -> Eltwise17_penlu35_0_split_0
I0926 14:52:17.153337  4911 net.cpp:380] Eltwise17_penlu35_0_split -> Eltwise17_penlu35_0_split_1
I0926 14:52:17.153359  4911 net.cpp:122] Setting up Eltwise17_penlu35_0_split
I0926 14:52:17.153363  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.153365  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.153368  4911 net.cpp:137] Memory required for data: 987546800
I0926 14:52:17.153370  4911 layer_factory.hpp:77] Creating layer Convolution37
I0926 14:52:17.153375  4911 net.cpp:84] Creating Layer Convolution37
I0926 14:52:17.153378  4911 net.cpp:406] Convolution37 <- Eltwise17_penlu35_0_split_0
I0926 14:52:17.153383  4911 net.cpp:380] Convolution37 -> Convolution37
I0926 14:52:17.154489  4911 net.cpp:122] Setting up Convolution37
I0926 14:52:17.154497  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.154500  4911 net.cpp:137] Memory required for data: 990823600
I0926 14:52:17.154505  4911 layer_factory.hpp:77] Creating layer BatchNorm37
I0926 14:52:17.154510  4911 net.cpp:84] Creating Layer BatchNorm37
I0926 14:52:17.154512  4911 net.cpp:406] BatchNorm37 <- Convolution37
I0926 14:52:17.154516  4911 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I0926 14:52:17.154650  4911 net.cpp:122] Setting up BatchNorm37
I0926 14:52:17.154654  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.154657  4911 net.cpp:137] Memory required for data: 994100400
I0926 14:52:17.154661  4911 layer_factory.hpp:77] Creating layer Scale37
I0926 14:52:17.154666  4911 net.cpp:84] Creating Layer Scale37
I0926 14:52:17.154670  4911 net.cpp:406] Scale37 <- Convolution37
I0926 14:52:17.154672  4911 net.cpp:367] Scale37 -> Convolution37 (in-place)
I0926 14:52:17.154700  4911 layer_factory.hpp:77] Creating layer Scale37
I0926 14:52:17.154777  4911 net.cpp:122] Setting up Scale37
I0926 14:52:17.154780  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.154783  4911 net.cpp:137] Memory required for data: 997377200
I0926 14:52:17.154786  4911 layer_factory.hpp:77] Creating layer penlu36
I0926 14:52:17.154791  4911 net.cpp:84] Creating Layer penlu36
I0926 14:52:17.154800  4911 net.cpp:406] penlu36 <- Convolution37
I0926 14:52:17.154805  4911 net.cpp:367] penlu36 -> Convolution37 (in-place)
I0926 14:52:17.154912  4911 net.cpp:122] Setting up penlu36
I0926 14:52:17.154917  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.154919  4911 net.cpp:137] Memory required for data: 1000654000
I0926 14:52:17.154923  4911 layer_factory.hpp:77] Creating layer Convolution38
I0926 14:52:17.154930  4911 net.cpp:84] Creating Layer Convolution38
I0926 14:52:17.154932  4911 net.cpp:406] Convolution38 <- Convolution37
I0926 14:52:17.154937  4911 net.cpp:380] Convolution38 -> Convolution38
I0926 14:52:17.156368  4911 net.cpp:122] Setting up Convolution38
I0926 14:52:17.156376  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.156379  4911 net.cpp:137] Memory required for data: 1003930800
I0926 14:52:17.156383  4911 layer_factory.hpp:77] Creating layer BatchNorm38
I0926 14:52:17.156389  4911 net.cpp:84] Creating Layer BatchNorm38
I0926 14:52:17.156391  4911 net.cpp:406] BatchNorm38 <- Convolution38
I0926 14:52:17.156395  4911 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I0926 14:52:17.156566  4911 net.cpp:122] Setting up BatchNorm38
I0926 14:52:17.156571  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.156574  4911 net.cpp:137] Memory required for data: 1007207600
I0926 14:52:17.171583  4911 layer_factory.hpp:77] Creating layer Scale38
I0926 14:52:17.171597  4911 net.cpp:84] Creating Layer Scale38
I0926 14:52:17.171602  4911 net.cpp:406] Scale38 <- Convolution38
I0926 14:52:17.171605  4911 net.cpp:367] Scale38 -> Convolution38 (in-place)
I0926 14:52:17.171646  4911 layer_factory.hpp:77] Creating layer Scale38
I0926 14:52:17.171738  4911 net.cpp:122] Setting up Scale38
I0926 14:52:17.171744  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.171746  4911 net.cpp:137] Memory required for data: 1010484400
I0926 14:52:17.171751  4911 layer_factory.hpp:77] Creating layer Eltwise18
I0926 14:52:17.171756  4911 net.cpp:84] Creating Layer Eltwise18
I0926 14:52:17.171759  4911 net.cpp:406] Eltwise18 <- Eltwise17_penlu35_0_split_1
I0926 14:52:17.171762  4911 net.cpp:406] Eltwise18 <- Convolution38
I0926 14:52:17.171766  4911 net.cpp:380] Eltwise18 -> Eltwise18
I0926 14:52:17.171780  4911 net.cpp:122] Setting up Eltwise18
I0926 14:52:17.171784  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.171787  4911 net.cpp:137] Memory required for data: 1013761200
I0926 14:52:17.171789  4911 layer_factory.hpp:77] Creating layer penlu37
I0926 14:52:17.171795  4911 net.cpp:84] Creating Layer penlu37
I0926 14:52:17.171797  4911 net.cpp:406] penlu37 <- Eltwise18
I0926 14:52:17.171802  4911 net.cpp:367] penlu37 -> Eltwise18 (in-place)
I0926 14:52:17.171922  4911 net.cpp:122] Setting up penlu37
I0926 14:52:17.171927  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.171931  4911 net.cpp:137] Memory required for data: 1017038000
I0926 14:52:17.171934  4911 layer_factory.hpp:77] Creating layer Eltwise18_penlu37_0_split
I0926 14:52:17.171938  4911 net.cpp:84] Creating Layer Eltwise18_penlu37_0_split
I0926 14:52:17.171941  4911 net.cpp:406] Eltwise18_penlu37_0_split <- Eltwise18
I0926 14:52:17.171944  4911 net.cpp:380] Eltwise18_penlu37_0_split -> Eltwise18_penlu37_0_split_0
I0926 14:52:17.171949  4911 net.cpp:380] Eltwise18_penlu37_0_split -> Eltwise18_penlu37_0_split_1
I0926 14:52:17.171974  4911 net.cpp:122] Setting up Eltwise18_penlu37_0_split
I0926 14:52:17.171979  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.171983  4911 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 14:52:17.171984  4911 net.cpp:137] Memory required for data: 1023591600
I0926 14:52:17.171986  4911 layer_factory.hpp:77] Creating layer Convolution39
I0926 14:52:17.171993  4911 net.cpp:84] Creating Layer Convolution39
I0926 14:52:17.171996  4911 net.cpp:406] Convolution39 <- Eltwise18_penlu37_0_split_0
I0926 14:52:17.172000  4911 net.cpp:380] Convolution39 -> Convolution39
I0926 14:52:17.173115  4911 net.cpp:122] Setting up Convolution39
I0926 14:52:17.173125  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.173128  4911 net.cpp:137] Memory required for data: 1025230000
I0926 14:52:17.173132  4911 layer_factory.hpp:77] Creating layer BatchNorm39
I0926 14:52:17.173138  4911 net.cpp:84] Creating Layer BatchNorm39
I0926 14:52:17.173141  4911 net.cpp:406] BatchNorm39 <- Convolution39
I0926 14:52:17.173146  4911 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I0926 14:52:17.173326  4911 net.cpp:122] Setting up BatchNorm39
I0926 14:52:17.173333  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.173336  4911 net.cpp:137] Memory required for data: 1026868400
I0926 14:52:17.173341  4911 layer_factory.hpp:77] Creating layer Scale39
I0926 14:52:17.173346  4911 net.cpp:84] Creating Layer Scale39
I0926 14:52:17.173349  4911 net.cpp:406] Scale39 <- Convolution39
I0926 14:52:17.173352  4911 net.cpp:367] Scale39 -> Convolution39 (in-place)
I0926 14:52:17.173382  4911 layer_factory.hpp:77] Creating layer Scale39
I0926 14:52:17.173460  4911 net.cpp:122] Setting up Scale39
I0926 14:52:17.173465  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.173467  4911 net.cpp:137] Memory required for data: 1028506800
I0926 14:52:17.173471  4911 layer_factory.hpp:77] Creating layer Convolution40
I0926 14:52:17.173480  4911 net.cpp:84] Creating Layer Convolution40
I0926 14:52:17.173482  4911 net.cpp:406] Convolution40 <- Eltwise18_penlu37_0_split_1
I0926 14:52:17.173486  4911 net.cpp:380] Convolution40 -> Convolution40
I0926 14:52:17.174942  4911 net.cpp:122] Setting up Convolution40
I0926 14:52:17.174950  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.174953  4911 net.cpp:137] Memory required for data: 1030145200
I0926 14:52:17.174958  4911 layer_factory.hpp:77] Creating layer BatchNorm40
I0926 14:52:17.174963  4911 net.cpp:84] Creating Layer BatchNorm40
I0926 14:52:17.174967  4911 net.cpp:406] BatchNorm40 <- Convolution40
I0926 14:52:17.174971  4911 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I0926 14:52:17.175114  4911 net.cpp:122] Setting up BatchNorm40
I0926 14:52:17.175119  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.175122  4911 net.cpp:137] Memory required for data: 1031783600
I0926 14:52:17.175127  4911 layer_factory.hpp:77] Creating layer Scale40
I0926 14:52:17.175132  4911 net.cpp:84] Creating Layer Scale40
I0926 14:52:17.175134  4911 net.cpp:406] Scale40 <- Convolution40
I0926 14:52:17.175137  4911 net.cpp:367] Scale40 -> Convolution40 (in-place)
I0926 14:52:17.175165  4911 layer_factory.hpp:77] Creating layer Scale40
I0926 14:52:17.175246  4911 net.cpp:122] Setting up Scale40
I0926 14:52:17.175251  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.175253  4911 net.cpp:137] Memory required for data: 1033422000
I0926 14:52:17.175257  4911 layer_factory.hpp:77] Creating layer penlu38
I0926 14:52:17.175263  4911 net.cpp:84] Creating Layer penlu38
I0926 14:52:17.175266  4911 net.cpp:406] penlu38 <- Convolution40
I0926 14:52:17.175269  4911 net.cpp:367] penlu38 -> Convolution40 (in-place)
I0926 14:52:17.175390  4911 net.cpp:122] Setting up penlu38
I0926 14:52:17.175395  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.175397  4911 net.cpp:137] Memory required for data: 1035060400
I0926 14:52:17.175402  4911 layer_factory.hpp:77] Creating layer Convolution41
I0926 14:52:17.175410  4911 net.cpp:84] Creating Layer Convolution41
I0926 14:52:17.175412  4911 net.cpp:406] Convolution41 <- Convolution40
I0926 14:52:17.175416  4911 net.cpp:380] Convolution41 -> Convolution41
I0926 14:52:17.177224  4911 net.cpp:122] Setting up Convolution41
I0926 14:52:17.177233  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.177237  4911 net.cpp:137] Memory required for data: 1036698800
I0926 14:52:17.177240  4911 layer_factory.hpp:77] Creating layer BatchNorm41
I0926 14:52:17.177247  4911 net.cpp:84] Creating Layer BatchNorm41
I0926 14:52:17.177249  4911 net.cpp:406] BatchNorm41 <- Convolution41
I0926 14:52:17.177261  4911 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I0926 14:52:17.177400  4911 net.cpp:122] Setting up BatchNorm41
I0926 14:52:17.177405  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.177407  4911 net.cpp:137] Memory required for data: 1038337200
I0926 14:52:17.177412  4911 layer_factory.hpp:77] Creating layer Scale41
I0926 14:52:17.177417  4911 net.cpp:84] Creating Layer Scale41
I0926 14:52:17.177419  4911 net.cpp:406] Scale41 <- Convolution41
I0926 14:52:17.177423  4911 net.cpp:367] Scale41 -> Convolution41 (in-place)
I0926 14:52:17.177450  4911 layer_factory.hpp:77] Creating layer Scale41
I0926 14:52:17.177531  4911 net.cpp:122] Setting up Scale41
I0926 14:52:17.177534  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.177537  4911 net.cpp:137] Memory required for data: 1039975600
I0926 14:52:17.177541  4911 layer_factory.hpp:77] Creating layer Eltwise19
I0926 14:52:17.177546  4911 net.cpp:84] Creating Layer Eltwise19
I0926 14:52:17.177548  4911 net.cpp:406] Eltwise19 <- Convolution39
I0926 14:52:17.177551  4911 net.cpp:406] Eltwise19 <- Convolution41
I0926 14:52:17.177554  4911 net.cpp:380] Eltwise19 -> Eltwise19
I0926 14:52:17.177570  4911 net.cpp:122] Setting up Eltwise19
I0926 14:52:17.177574  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.177577  4911 net.cpp:137] Memory required for data: 1041614000
I0926 14:52:17.177578  4911 layer_factory.hpp:77] Creating layer penlu39
I0926 14:52:17.177584  4911 net.cpp:84] Creating Layer penlu39
I0926 14:52:17.177587  4911 net.cpp:406] penlu39 <- Eltwise19
I0926 14:52:17.177590  4911 net.cpp:367] penlu39 -> Eltwise19 (in-place)
I0926 14:52:17.177705  4911 net.cpp:122] Setting up penlu39
I0926 14:52:17.177709  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.177711  4911 net.cpp:137] Memory required for data: 1043252400
I0926 14:52:17.177716  4911 layer_factory.hpp:77] Creating layer Eltwise19_penlu39_0_split
I0926 14:52:17.177721  4911 net.cpp:84] Creating Layer Eltwise19_penlu39_0_split
I0926 14:52:17.177722  4911 net.cpp:406] Eltwise19_penlu39_0_split <- Eltwise19
I0926 14:52:17.177726  4911 net.cpp:380] Eltwise19_penlu39_0_split -> Eltwise19_penlu39_0_split_0
I0926 14:52:17.177731  4911 net.cpp:380] Eltwise19_penlu39_0_split -> Eltwise19_penlu39_0_split_1
I0926 14:52:17.177754  4911 net.cpp:122] Setting up Eltwise19_penlu39_0_split
I0926 14:52:17.177758  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.177760  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.177762  4911 net.cpp:137] Memory required for data: 1046529200
I0926 14:52:17.177765  4911 layer_factory.hpp:77] Creating layer Convolution42
I0926 14:52:17.177772  4911 net.cpp:84] Creating Layer Convolution42
I0926 14:52:17.177773  4911 net.cpp:406] Convolution42 <- Eltwise19_penlu39_0_split_0
I0926 14:52:17.177778  4911 net.cpp:380] Convolution42 -> Convolution42
I0926 14:52:17.179549  4911 net.cpp:122] Setting up Convolution42
I0926 14:52:17.179558  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.179560  4911 net.cpp:137] Memory required for data: 1048167600
I0926 14:52:17.179565  4911 layer_factory.hpp:77] Creating layer BatchNorm42
I0926 14:52:17.179570  4911 net.cpp:84] Creating Layer BatchNorm42
I0926 14:52:17.179574  4911 net.cpp:406] BatchNorm42 <- Convolution42
I0926 14:52:17.179577  4911 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I0926 14:52:17.179714  4911 net.cpp:122] Setting up BatchNorm42
I0926 14:52:17.179718  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.179720  4911 net.cpp:137] Memory required for data: 1049806000
I0926 14:52:17.179725  4911 layer_factory.hpp:77] Creating layer Scale42
I0926 14:52:17.179731  4911 net.cpp:84] Creating Layer Scale42
I0926 14:52:17.179733  4911 net.cpp:406] Scale42 <- Convolution42
I0926 14:52:17.179738  4911 net.cpp:367] Scale42 -> Convolution42 (in-place)
I0926 14:52:17.179765  4911 layer_factory.hpp:77] Creating layer Scale42
I0926 14:52:17.179843  4911 net.cpp:122] Setting up Scale42
I0926 14:52:17.179848  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.179857  4911 net.cpp:137] Memory required for data: 1051444400
I0926 14:52:17.179860  4911 layer_factory.hpp:77] Creating layer penlu40
I0926 14:52:17.179867  4911 net.cpp:84] Creating Layer penlu40
I0926 14:52:17.179869  4911 net.cpp:406] penlu40 <- Convolution42
I0926 14:52:17.179873  4911 net.cpp:367] penlu40 -> Convolution42 (in-place)
I0926 14:52:17.179989  4911 net.cpp:122] Setting up penlu40
I0926 14:52:17.179994  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.179996  4911 net.cpp:137] Memory required for data: 1053082800
I0926 14:52:17.180001  4911 layer_factory.hpp:77] Creating layer Convolution43
I0926 14:52:17.180007  4911 net.cpp:84] Creating Layer Convolution43
I0926 14:52:17.180011  4911 net.cpp:406] Convolution43 <- Convolution42
I0926 14:52:17.180014  4911 net.cpp:380] Convolution43 -> Convolution43
I0926 14:52:17.181813  4911 net.cpp:122] Setting up Convolution43
I0926 14:52:17.181821  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.181824  4911 net.cpp:137] Memory required for data: 1054721200
I0926 14:52:17.181828  4911 layer_factory.hpp:77] Creating layer BatchNorm43
I0926 14:52:17.181833  4911 net.cpp:84] Creating Layer BatchNorm43
I0926 14:52:17.181836  4911 net.cpp:406] BatchNorm43 <- Convolution43
I0926 14:52:17.181841  4911 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I0926 14:52:17.181978  4911 net.cpp:122] Setting up BatchNorm43
I0926 14:52:17.181983  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.181985  4911 net.cpp:137] Memory required for data: 1056359600
I0926 14:52:17.181990  4911 layer_factory.hpp:77] Creating layer Scale43
I0926 14:52:17.181994  4911 net.cpp:84] Creating Layer Scale43
I0926 14:52:17.181998  4911 net.cpp:406] Scale43 <- Convolution43
I0926 14:52:17.182001  4911 net.cpp:367] Scale43 -> Convolution43 (in-place)
I0926 14:52:17.182029  4911 layer_factory.hpp:77] Creating layer Scale43
I0926 14:52:17.182108  4911 net.cpp:122] Setting up Scale43
I0926 14:52:17.182113  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.182116  4911 net.cpp:137] Memory required for data: 1057998000
I0926 14:52:17.182119  4911 layer_factory.hpp:77] Creating layer Eltwise20
I0926 14:52:17.182123  4911 net.cpp:84] Creating Layer Eltwise20
I0926 14:52:17.182126  4911 net.cpp:406] Eltwise20 <- Eltwise19_penlu39_0_split_1
I0926 14:52:17.182128  4911 net.cpp:406] Eltwise20 <- Convolution43
I0926 14:52:17.182133  4911 net.cpp:380] Eltwise20 -> Eltwise20
I0926 14:52:17.182152  4911 net.cpp:122] Setting up Eltwise20
I0926 14:52:17.182155  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.182157  4911 net.cpp:137] Memory required for data: 1059636400
I0926 14:52:17.182159  4911 layer_factory.hpp:77] Creating layer penlu41
I0926 14:52:17.182164  4911 net.cpp:84] Creating Layer penlu41
I0926 14:52:17.182166  4911 net.cpp:406] penlu41 <- Eltwise20
I0926 14:52:17.182170  4911 net.cpp:367] penlu41 -> Eltwise20 (in-place)
I0926 14:52:17.182286  4911 net.cpp:122] Setting up penlu41
I0926 14:52:17.182291  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.182292  4911 net.cpp:137] Memory required for data: 1061274800
I0926 14:52:17.182296  4911 layer_factory.hpp:77] Creating layer Eltwise20_penlu41_0_split
I0926 14:52:17.182301  4911 net.cpp:84] Creating Layer Eltwise20_penlu41_0_split
I0926 14:52:17.182302  4911 net.cpp:406] Eltwise20_penlu41_0_split <- Eltwise20
I0926 14:52:17.182305  4911 net.cpp:380] Eltwise20_penlu41_0_split -> Eltwise20_penlu41_0_split_0
I0926 14:52:17.182309  4911 net.cpp:380] Eltwise20_penlu41_0_split -> Eltwise20_penlu41_0_split_1
I0926 14:52:17.182333  4911 net.cpp:122] Setting up Eltwise20_penlu41_0_split
I0926 14:52:17.182337  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.182339  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.182341  4911 net.cpp:137] Memory required for data: 1064551600
I0926 14:52:17.182344  4911 layer_factory.hpp:77] Creating layer Convolution44
I0926 14:52:17.182350  4911 net.cpp:84] Creating Layer Convolution44
I0926 14:52:17.182359  4911 net.cpp:406] Convolution44 <- Eltwise20_penlu41_0_split_0
I0926 14:52:17.182364  4911 net.cpp:380] Convolution44 -> Convolution44
I0926 14:52:17.184453  4911 net.cpp:122] Setting up Convolution44
I0926 14:52:17.184460  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.184463  4911 net.cpp:137] Memory required for data: 1066190000
I0926 14:52:17.184468  4911 layer_factory.hpp:77] Creating layer BatchNorm44
I0926 14:52:17.184473  4911 net.cpp:84] Creating Layer BatchNorm44
I0926 14:52:17.184476  4911 net.cpp:406] BatchNorm44 <- Convolution44
I0926 14:52:17.184480  4911 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I0926 14:52:17.184646  4911 net.cpp:122] Setting up BatchNorm44
I0926 14:52:17.184651  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.184653  4911 net.cpp:137] Memory required for data: 1067828400
I0926 14:52:17.184659  4911 layer_factory.hpp:77] Creating layer Scale44
I0926 14:52:17.184662  4911 net.cpp:84] Creating Layer Scale44
I0926 14:52:17.184664  4911 net.cpp:406] Scale44 <- Convolution44
I0926 14:52:17.184667  4911 net.cpp:367] Scale44 -> Convolution44 (in-place)
I0926 14:52:17.184697  4911 layer_factory.hpp:77] Creating layer Scale44
I0926 14:52:17.184775  4911 net.cpp:122] Setting up Scale44
I0926 14:52:17.184780  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.184782  4911 net.cpp:137] Memory required for data: 1069466800
I0926 14:52:17.184787  4911 layer_factory.hpp:77] Creating layer penlu42
I0926 14:52:17.184792  4911 net.cpp:84] Creating Layer penlu42
I0926 14:52:17.184794  4911 net.cpp:406] penlu42 <- Convolution44
I0926 14:52:17.184798  4911 net.cpp:367] penlu42 -> Convolution44 (in-place)
I0926 14:52:17.184916  4911 net.cpp:122] Setting up penlu42
I0926 14:52:17.184921  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.184922  4911 net.cpp:137] Memory required for data: 1071105200
I0926 14:52:17.184926  4911 layer_factory.hpp:77] Creating layer Convolution45
I0926 14:52:17.184933  4911 net.cpp:84] Creating Layer Convolution45
I0926 14:52:17.184936  4911 net.cpp:406] Convolution45 <- Convolution44
I0926 14:52:17.184939  4911 net.cpp:380] Convolution45 -> Convolution45
I0926 14:52:17.186722  4911 net.cpp:122] Setting up Convolution45
I0926 14:52:17.186731  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.186733  4911 net.cpp:137] Memory required for data: 1072743600
I0926 14:52:17.186738  4911 layer_factory.hpp:77] Creating layer BatchNorm45
I0926 14:52:17.186743  4911 net.cpp:84] Creating Layer BatchNorm45
I0926 14:52:17.186745  4911 net.cpp:406] BatchNorm45 <- Convolution45
I0926 14:52:17.186750  4911 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I0926 14:52:17.186887  4911 net.cpp:122] Setting up BatchNorm45
I0926 14:52:17.186892  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.186894  4911 net.cpp:137] Memory required for data: 1074382000
I0926 14:52:17.186899  4911 layer_factory.hpp:77] Creating layer Scale45
I0926 14:52:17.186903  4911 net.cpp:84] Creating Layer Scale45
I0926 14:52:17.186906  4911 net.cpp:406] Scale45 <- Convolution45
I0926 14:52:17.186909  4911 net.cpp:367] Scale45 -> Convolution45 (in-place)
I0926 14:52:17.186938  4911 layer_factory.hpp:77] Creating layer Scale45
I0926 14:52:17.187016  4911 net.cpp:122] Setting up Scale45
I0926 14:52:17.187021  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.187022  4911 net.cpp:137] Memory required for data: 1076020400
I0926 14:52:17.187026  4911 layer_factory.hpp:77] Creating layer Eltwise21
I0926 14:52:17.187031  4911 net.cpp:84] Creating Layer Eltwise21
I0926 14:52:17.187033  4911 net.cpp:406] Eltwise21 <- Eltwise20_penlu41_0_split_1
I0926 14:52:17.187036  4911 net.cpp:406] Eltwise21 <- Convolution45
I0926 14:52:17.187041  4911 net.cpp:380] Eltwise21 -> Eltwise21
I0926 14:52:17.187057  4911 net.cpp:122] Setting up Eltwise21
I0926 14:52:17.187059  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.187062  4911 net.cpp:137] Memory required for data: 1077658800
I0926 14:52:17.187070  4911 layer_factory.hpp:77] Creating layer penlu43
I0926 14:52:17.187077  4911 net.cpp:84] Creating Layer penlu43
I0926 14:52:17.187078  4911 net.cpp:406] penlu43 <- Eltwise21
I0926 14:52:17.187083  4911 net.cpp:367] penlu43 -> Eltwise21 (in-place)
I0926 14:52:17.187198  4911 net.cpp:122] Setting up penlu43
I0926 14:52:17.187203  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.187206  4911 net.cpp:137] Memory required for data: 1079297200
I0926 14:52:17.187209  4911 layer_factory.hpp:77] Creating layer Eltwise21_penlu43_0_split
I0926 14:52:17.187213  4911 net.cpp:84] Creating Layer Eltwise21_penlu43_0_split
I0926 14:52:17.187216  4911 net.cpp:406] Eltwise21_penlu43_0_split <- Eltwise21
I0926 14:52:17.187218  4911 net.cpp:380] Eltwise21_penlu43_0_split -> Eltwise21_penlu43_0_split_0
I0926 14:52:17.187224  4911 net.cpp:380] Eltwise21_penlu43_0_split -> Eltwise21_penlu43_0_split_1
I0926 14:52:17.187247  4911 net.cpp:122] Setting up Eltwise21_penlu43_0_split
I0926 14:52:17.187250  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.187253  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.202019  4911 net.cpp:137] Memory required for data: 1082574000
I0926 14:52:17.202029  4911 layer_factory.hpp:77] Creating layer Convolution46
I0926 14:52:17.202039  4911 net.cpp:84] Creating Layer Convolution46
I0926 14:52:17.202044  4911 net.cpp:406] Convolution46 <- Eltwise21_penlu43_0_split_0
I0926 14:52:17.202049  4911 net.cpp:380] Convolution46 -> Convolution46
I0926 14:52:17.204044  4911 net.cpp:122] Setting up Convolution46
I0926 14:52:17.204054  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.204056  4911 net.cpp:137] Memory required for data: 1084212400
I0926 14:52:17.204062  4911 layer_factory.hpp:77] Creating layer BatchNorm46
I0926 14:52:17.204067  4911 net.cpp:84] Creating Layer BatchNorm46
I0926 14:52:17.204071  4911 net.cpp:406] BatchNorm46 <- Convolution46
I0926 14:52:17.204075  4911 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I0926 14:52:17.204282  4911 net.cpp:122] Setting up BatchNorm46
I0926 14:52:17.204288  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.204289  4911 net.cpp:137] Memory required for data: 1085850800
I0926 14:52:17.204295  4911 layer_factory.hpp:77] Creating layer Scale46
I0926 14:52:17.204299  4911 net.cpp:84] Creating Layer Scale46
I0926 14:52:17.204301  4911 net.cpp:406] Scale46 <- Convolution46
I0926 14:52:17.204305  4911 net.cpp:367] Scale46 -> Convolution46 (in-place)
I0926 14:52:17.204334  4911 layer_factory.hpp:77] Creating layer Scale46
I0926 14:52:17.204416  4911 net.cpp:122] Setting up Scale46
I0926 14:52:17.204421  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.204422  4911 net.cpp:137] Memory required for data: 1087489200
I0926 14:52:17.204427  4911 layer_factory.hpp:77] Creating layer penlu44
I0926 14:52:17.204432  4911 net.cpp:84] Creating Layer penlu44
I0926 14:52:17.204434  4911 net.cpp:406] penlu44 <- Convolution46
I0926 14:52:17.204438  4911 net.cpp:367] penlu44 -> Convolution46 (in-place)
I0926 14:52:17.204566  4911 net.cpp:122] Setting up penlu44
I0926 14:52:17.204571  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.204572  4911 net.cpp:137] Memory required for data: 1089127600
I0926 14:52:17.204577  4911 layer_factory.hpp:77] Creating layer Convolution47
I0926 14:52:17.204586  4911 net.cpp:84] Creating Layer Convolution47
I0926 14:52:17.204587  4911 net.cpp:406] Convolution47 <- Convolution46
I0926 14:52:17.204591  4911 net.cpp:380] Convolution47 -> Convolution47
I0926 14:52:17.206495  4911 net.cpp:122] Setting up Convolution47
I0926 14:52:17.206504  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.206507  4911 net.cpp:137] Memory required for data: 1090766000
I0926 14:52:17.206511  4911 layer_factory.hpp:77] Creating layer BatchNorm47
I0926 14:52:17.206517  4911 net.cpp:84] Creating Layer BatchNorm47
I0926 14:52:17.206521  4911 net.cpp:406] BatchNorm47 <- Convolution47
I0926 14:52:17.206524  4911 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I0926 14:52:17.206673  4911 net.cpp:122] Setting up BatchNorm47
I0926 14:52:17.206678  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.206681  4911 net.cpp:137] Memory required for data: 1092404400
I0926 14:52:17.206686  4911 layer_factory.hpp:77] Creating layer Scale47
I0926 14:52:17.206691  4911 net.cpp:84] Creating Layer Scale47
I0926 14:52:17.206693  4911 net.cpp:406] Scale47 <- Convolution47
I0926 14:52:17.206696  4911 net.cpp:367] Scale47 -> Convolution47 (in-place)
I0926 14:52:17.206724  4911 layer_factory.hpp:77] Creating layer Scale47
I0926 14:52:17.206804  4911 net.cpp:122] Setting up Scale47
I0926 14:52:17.206809  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.206811  4911 net.cpp:137] Memory required for data: 1094042800
I0926 14:52:17.206815  4911 layer_factory.hpp:77] Creating layer Eltwise22
I0926 14:52:17.206818  4911 net.cpp:84] Creating Layer Eltwise22
I0926 14:52:17.206821  4911 net.cpp:406] Eltwise22 <- Eltwise21_penlu43_0_split_1
I0926 14:52:17.206825  4911 net.cpp:406] Eltwise22 <- Convolution47
I0926 14:52:17.206830  4911 net.cpp:380] Eltwise22 -> Eltwise22
I0926 14:52:17.206845  4911 net.cpp:122] Setting up Eltwise22
I0926 14:52:17.206849  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.206851  4911 net.cpp:137] Memory required for data: 1095681200
I0926 14:52:17.206853  4911 layer_factory.hpp:77] Creating layer penlu45
I0926 14:52:17.206858  4911 net.cpp:84] Creating Layer penlu45
I0926 14:52:17.206861  4911 net.cpp:406] penlu45 <- Eltwise22
I0926 14:52:17.206864  4911 net.cpp:367] penlu45 -> Eltwise22 (in-place)
I0926 14:52:17.206980  4911 net.cpp:122] Setting up penlu45
I0926 14:52:17.206985  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.206987  4911 net.cpp:137] Memory required for data: 1097319600
I0926 14:52:17.206991  4911 layer_factory.hpp:77] Creating layer Eltwise22_penlu45_0_split
I0926 14:52:17.206995  4911 net.cpp:84] Creating Layer Eltwise22_penlu45_0_split
I0926 14:52:17.206997  4911 net.cpp:406] Eltwise22_penlu45_0_split <- Eltwise22
I0926 14:52:17.207001  4911 net.cpp:380] Eltwise22_penlu45_0_split -> Eltwise22_penlu45_0_split_0
I0926 14:52:17.207007  4911 net.cpp:380] Eltwise22_penlu45_0_split -> Eltwise22_penlu45_0_split_1
I0926 14:52:17.207031  4911 net.cpp:122] Setting up Eltwise22_penlu45_0_split
I0926 14:52:17.207036  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.207038  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.207041  4911 net.cpp:137] Memory required for data: 1100596400
I0926 14:52:17.207042  4911 layer_factory.hpp:77] Creating layer Convolution48
I0926 14:52:17.207049  4911 net.cpp:84] Creating Layer Convolution48
I0926 14:52:17.207051  4911 net.cpp:406] Convolution48 <- Eltwise22_penlu45_0_split_0
I0926 14:52:17.207056  4911 net.cpp:380] Convolution48 -> Convolution48
I0926 14:52:17.209154  4911 net.cpp:122] Setting up Convolution48
I0926 14:52:17.209163  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.209166  4911 net.cpp:137] Memory required for data: 1102234800
I0926 14:52:17.209170  4911 layer_factory.hpp:77] Creating layer BatchNorm48
I0926 14:52:17.209177  4911 net.cpp:84] Creating Layer BatchNorm48
I0926 14:52:17.209178  4911 net.cpp:406] BatchNorm48 <- Convolution48
I0926 14:52:17.209182  4911 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I0926 14:52:17.209327  4911 net.cpp:122] Setting up BatchNorm48
I0926 14:52:17.209332  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.209334  4911 net.cpp:137] Memory required for data: 1103873200
I0926 14:52:17.209339  4911 layer_factory.hpp:77] Creating layer Scale48
I0926 14:52:17.209343  4911 net.cpp:84] Creating Layer Scale48
I0926 14:52:17.209347  4911 net.cpp:406] Scale48 <- Convolution48
I0926 14:52:17.209349  4911 net.cpp:367] Scale48 -> Convolution48 (in-place)
I0926 14:52:17.209378  4911 layer_factory.hpp:77] Creating layer Scale48
I0926 14:52:17.209460  4911 net.cpp:122] Setting up Scale48
I0926 14:52:17.209465  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.209475  4911 net.cpp:137] Memory required for data: 1105511600
I0926 14:52:17.209478  4911 layer_factory.hpp:77] Creating layer penlu46
I0926 14:52:17.209483  4911 net.cpp:84] Creating Layer penlu46
I0926 14:52:17.209486  4911 net.cpp:406] penlu46 <- Convolution48
I0926 14:52:17.209491  4911 net.cpp:367] penlu46 -> Convolution48 (in-place)
I0926 14:52:17.209611  4911 net.cpp:122] Setting up penlu46
I0926 14:52:17.209616  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.209619  4911 net.cpp:137] Memory required for data: 1107150000
I0926 14:52:17.209622  4911 layer_factory.hpp:77] Creating layer Convolution49
I0926 14:52:17.209630  4911 net.cpp:84] Creating Layer Convolution49
I0926 14:52:17.209631  4911 net.cpp:406] Convolution49 <- Convolution48
I0926 14:52:17.209635  4911 net.cpp:380] Convolution49 -> Convolution49
I0926 14:52:17.211745  4911 net.cpp:122] Setting up Convolution49
I0926 14:52:17.211753  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.211755  4911 net.cpp:137] Memory required for data: 1108788400
I0926 14:52:17.211760  4911 layer_factory.hpp:77] Creating layer BatchNorm49
I0926 14:52:17.211766  4911 net.cpp:84] Creating Layer BatchNorm49
I0926 14:52:17.211769  4911 net.cpp:406] BatchNorm49 <- Convolution49
I0926 14:52:17.211773  4911 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I0926 14:52:17.211916  4911 net.cpp:122] Setting up BatchNorm49
I0926 14:52:17.211921  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.211923  4911 net.cpp:137] Memory required for data: 1110426800
I0926 14:52:17.211927  4911 layer_factory.hpp:77] Creating layer Scale49
I0926 14:52:17.211932  4911 net.cpp:84] Creating Layer Scale49
I0926 14:52:17.211935  4911 net.cpp:406] Scale49 <- Convolution49
I0926 14:52:17.211938  4911 net.cpp:367] Scale49 -> Convolution49 (in-place)
I0926 14:52:17.211966  4911 layer_factory.hpp:77] Creating layer Scale49
I0926 14:52:17.212047  4911 net.cpp:122] Setting up Scale49
I0926 14:52:17.212052  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.212054  4911 net.cpp:137] Memory required for data: 1112065200
I0926 14:52:17.212059  4911 layer_factory.hpp:77] Creating layer Eltwise23
I0926 14:52:17.212062  4911 net.cpp:84] Creating Layer Eltwise23
I0926 14:52:17.212065  4911 net.cpp:406] Eltwise23 <- Eltwise22_penlu45_0_split_1
I0926 14:52:17.212069  4911 net.cpp:406] Eltwise23 <- Convolution49
I0926 14:52:17.212072  4911 net.cpp:380] Eltwise23 -> Eltwise23
I0926 14:52:17.212096  4911 net.cpp:122] Setting up Eltwise23
I0926 14:52:17.212105  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.212108  4911 net.cpp:137] Memory required for data: 1113703600
I0926 14:52:17.212112  4911 layer_factory.hpp:77] Creating layer penlu47
I0926 14:52:17.212119  4911 net.cpp:84] Creating Layer penlu47
I0926 14:52:17.212122  4911 net.cpp:406] penlu47 <- Eltwise23
I0926 14:52:17.212126  4911 net.cpp:367] penlu47 -> Eltwise23 (in-place)
I0926 14:52:17.212247  4911 net.cpp:122] Setting up penlu47
I0926 14:52:17.212252  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.212255  4911 net.cpp:137] Memory required for data: 1115342000
I0926 14:52:17.212258  4911 layer_factory.hpp:77] Creating layer Eltwise23_penlu47_0_split
I0926 14:52:17.212262  4911 net.cpp:84] Creating Layer Eltwise23_penlu47_0_split
I0926 14:52:17.212265  4911 net.cpp:406] Eltwise23_penlu47_0_split <- Eltwise23
I0926 14:52:17.212268  4911 net.cpp:380] Eltwise23_penlu47_0_split -> Eltwise23_penlu47_0_split_0
I0926 14:52:17.212272  4911 net.cpp:380] Eltwise23_penlu47_0_split -> Eltwise23_penlu47_0_split_1
I0926 14:52:17.212297  4911 net.cpp:122] Setting up Eltwise23_penlu47_0_split
I0926 14:52:17.212301  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.212304  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.212306  4911 net.cpp:137] Memory required for data: 1118618800
I0926 14:52:17.212308  4911 layer_factory.hpp:77] Creating layer Convolution50
I0926 14:52:17.212316  4911 net.cpp:84] Creating Layer Convolution50
I0926 14:52:17.212323  4911 net.cpp:406] Convolution50 <- Eltwise23_penlu47_0_split_0
I0926 14:52:17.212328  4911 net.cpp:380] Convolution50 -> Convolution50
I0926 14:52:17.214947  4911 net.cpp:122] Setting up Convolution50
I0926 14:52:17.214956  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.214959  4911 net.cpp:137] Memory required for data: 1120257200
I0926 14:52:17.214964  4911 layer_factory.hpp:77] Creating layer BatchNorm50
I0926 14:52:17.214969  4911 net.cpp:84] Creating Layer BatchNorm50
I0926 14:52:17.214972  4911 net.cpp:406] BatchNorm50 <- Convolution50
I0926 14:52:17.214977  4911 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I0926 14:52:17.215124  4911 net.cpp:122] Setting up BatchNorm50
I0926 14:52:17.215128  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.215131  4911 net.cpp:137] Memory required for data: 1121895600
I0926 14:52:17.215137  4911 layer_factory.hpp:77] Creating layer Scale50
I0926 14:52:17.215140  4911 net.cpp:84] Creating Layer Scale50
I0926 14:52:17.215143  4911 net.cpp:406] Scale50 <- Convolution50
I0926 14:52:17.215147  4911 net.cpp:367] Scale50 -> Convolution50 (in-place)
I0926 14:52:17.215176  4911 layer_factory.hpp:77] Creating layer Scale50
I0926 14:52:17.215258  4911 net.cpp:122] Setting up Scale50
I0926 14:52:17.215262  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.215265  4911 net.cpp:137] Memory required for data: 1123534000
I0926 14:52:17.215268  4911 layer_factory.hpp:77] Creating layer penlu48
I0926 14:52:17.215275  4911 net.cpp:84] Creating Layer penlu48
I0926 14:52:17.215276  4911 net.cpp:406] penlu48 <- Convolution50
I0926 14:52:17.215281  4911 net.cpp:367] penlu48 -> Convolution50 (in-place)
I0926 14:52:17.215399  4911 net.cpp:122] Setting up penlu48
I0926 14:52:17.215404  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.215405  4911 net.cpp:137] Memory required for data: 1125172400
I0926 14:52:17.215410  4911 layer_factory.hpp:77] Creating layer Convolution51
I0926 14:52:17.215418  4911 net.cpp:84] Creating Layer Convolution51
I0926 14:52:17.215421  4911 net.cpp:406] Convolution51 <- Convolution50
I0926 14:52:17.215425  4911 net.cpp:380] Convolution51 -> Convolution51
I0926 14:52:17.217203  4911 net.cpp:122] Setting up Convolution51
I0926 14:52:17.217212  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.217216  4911 net.cpp:137] Memory required for data: 1126810800
I0926 14:52:17.217219  4911 layer_factory.hpp:77] Creating layer BatchNorm51
I0926 14:52:17.217226  4911 net.cpp:84] Creating Layer BatchNorm51
I0926 14:52:17.217228  4911 net.cpp:406] BatchNorm51 <- Convolution51
I0926 14:52:17.217231  4911 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I0926 14:52:17.217372  4911 net.cpp:122] Setting up BatchNorm51
I0926 14:52:17.217377  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.217380  4911 net.cpp:137] Memory required for data: 1128449200
I0926 14:52:17.217384  4911 layer_factory.hpp:77] Creating layer Scale51
I0926 14:52:17.217389  4911 net.cpp:84] Creating Layer Scale51
I0926 14:52:17.217391  4911 net.cpp:406] Scale51 <- Convolution51
I0926 14:52:17.217394  4911 net.cpp:367] Scale51 -> Convolution51 (in-place)
I0926 14:52:17.217423  4911 layer_factory.hpp:77] Creating layer Scale51
I0926 14:52:17.217504  4911 net.cpp:122] Setting up Scale51
I0926 14:52:17.217509  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.217511  4911 net.cpp:137] Memory required for data: 1130087600
I0926 14:52:17.217515  4911 layer_factory.hpp:77] Creating layer Eltwise24
I0926 14:52:17.217519  4911 net.cpp:84] Creating Layer Eltwise24
I0926 14:52:17.217522  4911 net.cpp:406] Eltwise24 <- Eltwise23_penlu47_0_split_1
I0926 14:52:17.217525  4911 net.cpp:406] Eltwise24 <- Convolution51
I0926 14:52:17.217530  4911 net.cpp:380] Eltwise24 -> Eltwise24
I0926 14:52:17.217546  4911 net.cpp:122] Setting up Eltwise24
I0926 14:52:17.217550  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.217552  4911 net.cpp:137] Memory required for data: 1131726000
I0926 14:52:17.217561  4911 layer_factory.hpp:77] Creating layer penlu49
I0926 14:52:17.217567  4911 net.cpp:84] Creating Layer penlu49
I0926 14:52:17.217569  4911 net.cpp:406] penlu49 <- Eltwise24
I0926 14:52:17.217573  4911 net.cpp:367] penlu49 -> Eltwise24 (in-place)
I0926 14:52:17.217691  4911 net.cpp:122] Setting up penlu49
I0926 14:52:17.217696  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.217699  4911 net.cpp:137] Memory required for data: 1133364400
I0926 14:52:17.217702  4911 layer_factory.hpp:77] Creating layer Eltwise24_penlu49_0_split
I0926 14:52:17.217706  4911 net.cpp:84] Creating Layer Eltwise24_penlu49_0_split
I0926 14:52:17.217708  4911 net.cpp:406] Eltwise24_penlu49_0_split <- Eltwise24
I0926 14:52:17.217711  4911 net.cpp:380] Eltwise24_penlu49_0_split -> Eltwise24_penlu49_0_split_0
I0926 14:52:17.217716  4911 net.cpp:380] Eltwise24_penlu49_0_split -> Eltwise24_penlu49_0_split_1
I0926 14:52:17.217749  4911 net.cpp:122] Setting up Eltwise24_penlu49_0_split
I0926 14:52:17.232404  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.232415  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.232419  4911 net.cpp:137] Memory required for data: 1136641200
I0926 14:52:17.232421  4911 layer_factory.hpp:77] Creating layer Convolution52
I0926 14:52:17.232431  4911 net.cpp:84] Creating Layer Convolution52
I0926 14:52:17.232435  4911 net.cpp:406] Convolution52 <- Eltwise24_penlu49_0_split_0
I0926 14:52:17.232441  4911 net.cpp:380] Convolution52 -> Convolution52
I0926 14:52:17.235049  4911 net.cpp:122] Setting up Convolution52
I0926 14:52:17.235059  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.235061  4911 net.cpp:137] Memory required for data: 1138279600
I0926 14:52:17.235067  4911 layer_factory.hpp:77] Creating layer BatchNorm52
I0926 14:52:17.235072  4911 net.cpp:84] Creating Layer BatchNorm52
I0926 14:52:17.235076  4911 net.cpp:406] BatchNorm52 <- Convolution52
I0926 14:52:17.235080  4911 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I0926 14:52:17.235231  4911 net.cpp:122] Setting up BatchNorm52
I0926 14:52:17.235236  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.235239  4911 net.cpp:137] Memory required for data: 1139918000
I0926 14:52:17.235244  4911 layer_factory.hpp:77] Creating layer Scale52
I0926 14:52:17.235249  4911 net.cpp:84] Creating Layer Scale52
I0926 14:52:17.235250  4911 net.cpp:406] Scale52 <- Convolution52
I0926 14:52:17.235255  4911 net.cpp:367] Scale52 -> Convolution52 (in-place)
I0926 14:52:17.235285  4911 layer_factory.hpp:77] Creating layer Scale52
I0926 14:52:17.235370  4911 net.cpp:122] Setting up Scale52
I0926 14:52:17.235375  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.235378  4911 net.cpp:137] Memory required for data: 1141556400
I0926 14:52:17.235381  4911 layer_factory.hpp:77] Creating layer penlu50
I0926 14:52:17.235404  4911 net.cpp:84] Creating Layer penlu50
I0926 14:52:17.235406  4911 net.cpp:406] penlu50 <- Convolution52
I0926 14:52:17.235410  4911 net.cpp:367] penlu50 -> Convolution52 (in-place)
I0926 14:52:17.235535  4911 net.cpp:122] Setting up penlu50
I0926 14:52:17.235540  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.235543  4911 net.cpp:137] Memory required for data: 1143194800
I0926 14:52:17.235589  4911 layer_factory.hpp:77] Creating layer Convolution53
I0926 14:52:17.235596  4911 net.cpp:84] Creating Layer Convolution53
I0926 14:52:17.235599  4911 net.cpp:406] Convolution53 <- Convolution52
I0926 14:52:17.235604  4911 net.cpp:380] Convolution53 -> Convolution53
I0926 14:52:17.237481  4911 net.cpp:122] Setting up Convolution53
I0926 14:52:17.237490  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.237493  4911 net.cpp:137] Memory required for data: 1144833200
I0926 14:52:17.237498  4911 layer_factory.hpp:77] Creating layer BatchNorm53
I0926 14:52:17.237502  4911 net.cpp:84] Creating Layer BatchNorm53
I0926 14:52:17.237505  4911 net.cpp:406] BatchNorm53 <- Convolution53
I0926 14:52:17.237509  4911 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I0926 14:52:17.237661  4911 net.cpp:122] Setting up BatchNorm53
I0926 14:52:17.237666  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.237668  4911 net.cpp:137] Memory required for data: 1146471600
I0926 14:52:17.237673  4911 layer_factory.hpp:77] Creating layer Scale53
I0926 14:52:17.237679  4911 net.cpp:84] Creating Layer Scale53
I0926 14:52:17.237680  4911 net.cpp:406] Scale53 <- Convolution53
I0926 14:52:17.237684  4911 net.cpp:367] Scale53 -> Convolution53 (in-place)
I0926 14:52:17.237712  4911 layer_factory.hpp:77] Creating layer Scale53
I0926 14:52:17.237797  4911 net.cpp:122] Setting up Scale53
I0926 14:52:17.237802  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.237803  4911 net.cpp:137] Memory required for data: 1148110000
I0926 14:52:17.237807  4911 layer_factory.hpp:77] Creating layer Eltwise25
I0926 14:52:17.237812  4911 net.cpp:84] Creating Layer Eltwise25
I0926 14:52:17.237815  4911 net.cpp:406] Eltwise25 <- Eltwise24_penlu49_0_split_1
I0926 14:52:17.237818  4911 net.cpp:406] Eltwise25 <- Convolution53
I0926 14:52:17.237823  4911 net.cpp:380] Eltwise25 -> Eltwise25
I0926 14:52:17.237840  4911 net.cpp:122] Setting up Eltwise25
I0926 14:52:17.237844  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.237848  4911 net.cpp:137] Memory required for data: 1149748400
I0926 14:52:17.237849  4911 layer_factory.hpp:77] Creating layer penlu51
I0926 14:52:17.237854  4911 net.cpp:84] Creating Layer penlu51
I0926 14:52:17.237856  4911 net.cpp:406] penlu51 <- Eltwise25
I0926 14:52:17.237860  4911 net.cpp:367] penlu51 -> Eltwise25 (in-place)
I0926 14:52:17.237982  4911 net.cpp:122] Setting up penlu51
I0926 14:52:17.237985  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.237987  4911 net.cpp:137] Memory required for data: 1151386800
I0926 14:52:17.237993  4911 layer_factory.hpp:77] Creating layer Eltwise25_penlu51_0_split
I0926 14:52:17.237995  4911 net.cpp:84] Creating Layer Eltwise25_penlu51_0_split
I0926 14:52:17.237998  4911 net.cpp:406] Eltwise25_penlu51_0_split <- Eltwise25
I0926 14:52:17.238001  4911 net.cpp:380] Eltwise25_penlu51_0_split -> Eltwise25_penlu51_0_split_0
I0926 14:52:17.238005  4911 net.cpp:380] Eltwise25_penlu51_0_split -> Eltwise25_penlu51_0_split_1
I0926 14:52:17.238030  4911 net.cpp:122] Setting up Eltwise25_penlu51_0_split
I0926 14:52:17.238034  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.238037  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.238039  4911 net.cpp:137] Memory required for data: 1154663600
I0926 14:52:17.238041  4911 layer_factory.hpp:77] Creating layer Convolution54
I0926 14:52:17.238047  4911 net.cpp:84] Creating Layer Convolution54
I0926 14:52:17.238050  4911 net.cpp:406] Convolution54 <- Eltwise25_penlu51_0_split_0
I0926 14:52:17.238054  4911 net.cpp:380] Convolution54 -> Convolution54
I0926 14:52:17.240155  4911 net.cpp:122] Setting up Convolution54
I0926 14:52:17.240164  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.240166  4911 net.cpp:137] Memory required for data: 1156302000
I0926 14:52:17.240171  4911 layer_factory.hpp:77] Creating layer BatchNorm54
I0926 14:52:17.240177  4911 net.cpp:84] Creating Layer BatchNorm54
I0926 14:52:17.240180  4911 net.cpp:406] BatchNorm54 <- Convolution54
I0926 14:52:17.240183  4911 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I0926 14:52:17.240334  4911 net.cpp:122] Setting up BatchNorm54
I0926 14:52:17.240337  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.240340  4911 net.cpp:137] Memory required for data: 1157940400
I0926 14:52:17.240345  4911 layer_factory.hpp:77] Creating layer Scale54
I0926 14:52:17.240348  4911 net.cpp:84] Creating Layer Scale54
I0926 14:52:17.240351  4911 net.cpp:406] Scale54 <- Convolution54
I0926 14:52:17.240355  4911 net.cpp:367] Scale54 -> Convolution54 (in-place)
I0926 14:52:17.240386  4911 layer_factory.hpp:77] Creating layer Scale54
I0926 14:52:17.240468  4911 net.cpp:122] Setting up Scale54
I0926 14:52:17.240473  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.240481  4911 net.cpp:137] Memory required for data: 1159578800
I0926 14:52:17.240486  4911 layer_factory.hpp:77] Creating layer penlu52
I0926 14:52:17.240492  4911 net.cpp:84] Creating Layer penlu52
I0926 14:52:17.240499  4911 net.cpp:406] penlu52 <- Convolution54
I0926 14:52:17.240514  4911 net.cpp:367] penlu52 -> Convolution54 (in-place)
I0926 14:52:17.240646  4911 net.cpp:122] Setting up penlu52
I0926 14:52:17.240651  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.240653  4911 net.cpp:137] Memory required for data: 1161217200
I0926 14:52:17.240658  4911 layer_factory.hpp:77] Creating layer Convolution55
I0926 14:52:17.240664  4911 net.cpp:84] Creating Layer Convolution55
I0926 14:52:17.240667  4911 net.cpp:406] Convolution55 <- Convolution54
I0926 14:52:17.240671  4911 net.cpp:380] Convolution55 -> Convolution55
I0926 14:52:17.242457  4911 net.cpp:122] Setting up Convolution55
I0926 14:52:17.242470  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.242473  4911 net.cpp:137] Memory required for data: 1162855600
I0926 14:52:17.242483  4911 layer_factory.hpp:77] Creating layer BatchNorm55
I0926 14:52:17.242491  4911 net.cpp:84] Creating Layer BatchNorm55
I0926 14:52:17.242497  4911 net.cpp:406] BatchNorm55 <- Convolution55
I0926 14:52:17.242501  4911 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I0926 14:52:17.242646  4911 net.cpp:122] Setting up BatchNorm55
I0926 14:52:17.242651  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.242653  4911 net.cpp:137] Memory required for data: 1164494000
I0926 14:52:17.242658  4911 layer_factory.hpp:77] Creating layer Scale55
I0926 14:52:17.242663  4911 net.cpp:84] Creating Layer Scale55
I0926 14:52:17.242666  4911 net.cpp:406] Scale55 <- Convolution55
I0926 14:52:17.242669  4911 net.cpp:367] Scale55 -> Convolution55 (in-place)
I0926 14:52:17.242698  4911 layer_factory.hpp:77] Creating layer Scale55
I0926 14:52:17.242782  4911 net.cpp:122] Setting up Scale55
I0926 14:52:17.242786  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.242789  4911 net.cpp:137] Memory required for data: 1166132400
I0926 14:52:17.242792  4911 layer_factory.hpp:77] Creating layer Eltwise26
I0926 14:52:17.242795  4911 net.cpp:84] Creating Layer Eltwise26
I0926 14:52:17.242799  4911 net.cpp:406] Eltwise26 <- Eltwise25_penlu51_0_split_1
I0926 14:52:17.242801  4911 net.cpp:406] Eltwise26 <- Convolution55
I0926 14:52:17.242805  4911 net.cpp:380] Eltwise26 -> Eltwise26
I0926 14:52:17.242821  4911 net.cpp:122] Setting up Eltwise26
I0926 14:52:17.242825  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.242827  4911 net.cpp:137] Memory required for data: 1167770800
I0926 14:52:17.242830  4911 layer_factory.hpp:77] Creating layer penlu53
I0926 14:52:17.242835  4911 net.cpp:84] Creating Layer penlu53
I0926 14:52:17.242837  4911 net.cpp:406] penlu53 <- Eltwise26
I0926 14:52:17.242841  4911 net.cpp:367] penlu53 -> Eltwise26 (in-place)
I0926 14:52:17.242961  4911 net.cpp:122] Setting up penlu53
I0926 14:52:17.242965  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.242967  4911 net.cpp:137] Memory required for data: 1169409200
I0926 14:52:17.242972  4911 layer_factory.hpp:77] Creating layer Eltwise26_penlu53_0_split
I0926 14:52:17.242975  4911 net.cpp:84] Creating Layer Eltwise26_penlu53_0_split
I0926 14:52:17.242979  4911 net.cpp:406] Eltwise26_penlu53_0_split <- Eltwise26
I0926 14:52:17.242983  4911 net.cpp:380] Eltwise26_penlu53_0_split -> Eltwise26_penlu53_0_split_0
I0926 14:52:17.242987  4911 net.cpp:380] Eltwise26_penlu53_0_split -> Eltwise26_penlu53_0_split_1
I0926 14:52:17.243011  4911 net.cpp:122] Setting up Eltwise26_penlu53_0_split
I0926 14:52:17.243015  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.243017  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.243019  4911 net.cpp:137] Memory required for data: 1172686000
I0926 14:52:17.243021  4911 layer_factory.hpp:77] Creating layer Convolution56
I0926 14:52:17.243028  4911 net.cpp:84] Creating Layer Convolution56
I0926 14:52:17.243037  4911 net.cpp:406] Convolution56 <- Eltwise26_penlu53_0_split_0
I0926 14:52:17.243042  4911 net.cpp:380] Convolution56 -> Convolution56
I0926 14:52:17.244828  4911 net.cpp:122] Setting up Convolution56
I0926 14:52:17.244837  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.244840  4911 net.cpp:137] Memory required for data: 1174324400
I0926 14:52:17.244845  4911 layer_factory.hpp:77] Creating layer BatchNorm56
I0926 14:52:17.244850  4911 net.cpp:84] Creating Layer BatchNorm56
I0926 14:52:17.244853  4911 net.cpp:406] BatchNorm56 <- Convolution56
I0926 14:52:17.244858  4911 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I0926 14:52:17.245015  4911 net.cpp:122] Setting up BatchNorm56
I0926 14:52:17.245020  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.245023  4911 net.cpp:137] Memory required for data: 1175962800
I0926 14:52:17.245028  4911 layer_factory.hpp:77] Creating layer Scale56
I0926 14:52:17.245033  4911 net.cpp:84] Creating Layer Scale56
I0926 14:52:17.245036  4911 net.cpp:406] Scale56 <- Convolution56
I0926 14:52:17.245040  4911 net.cpp:367] Scale56 -> Convolution56 (in-place)
I0926 14:52:17.245069  4911 layer_factory.hpp:77] Creating layer Scale56
I0926 14:52:17.245156  4911 net.cpp:122] Setting up Scale56
I0926 14:52:17.245159  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.245162  4911 net.cpp:137] Memory required for data: 1177601200
I0926 14:52:17.245165  4911 layer_factory.hpp:77] Creating layer penlu54
I0926 14:52:17.245172  4911 net.cpp:84] Creating Layer penlu54
I0926 14:52:17.245174  4911 net.cpp:406] penlu54 <- Convolution56
I0926 14:52:17.245177  4911 net.cpp:367] penlu54 -> Convolution56 (in-place)
I0926 14:52:17.245303  4911 net.cpp:122] Setting up penlu54
I0926 14:52:17.245308  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.245311  4911 net.cpp:137] Memory required for data: 1179239600
I0926 14:52:17.245314  4911 layer_factory.hpp:77] Creating layer Convolution57
I0926 14:52:17.245321  4911 net.cpp:84] Creating Layer Convolution57
I0926 14:52:17.245323  4911 net.cpp:406] Convolution57 <- Convolution56
I0926 14:52:17.245327  4911 net.cpp:380] Convolution57 -> Convolution57
I0926 14:52:17.247112  4911 net.cpp:122] Setting up Convolution57
I0926 14:52:17.247122  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.247124  4911 net.cpp:137] Memory required for data: 1180878000
I0926 14:52:17.247128  4911 layer_factory.hpp:77] Creating layer BatchNorm57
I0926 14:52:17.247134  4911 net.cpp:84] Creating Layer BatchNorm57
I0926 14:52:17.247138  4911 net.cpp:406] BatchNorm57 <- Convolution57
I0926 14:52:17.247141  4911 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I0926 14:52:17.247285  4911 net.cpp:122] Setting up BatchNorm57
I0926 14:52:17.247290  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.247292  4911 net.cpp:137] Memory required for data: 1182516400
I0926 14:52:17.247298  4911 layer_factory.hpp:77] Creating layer Scale57
I0926 14:52:17.247301  4911 net.cpp:84] Creating Layer Scale57
I0926 14:52:17.247304  4911 net.cpp:406] Scale57 <- Convolution57
I0926 14:52:17.247308  4911 net.cpp:367] Scale57 -> Convolution57 (in-place)
I0926 14:52:17.247336  4911 layer_factory.hpp:77] Creating layer Scale57
I0926 14:52:17.247421  4911 net.cpp:122] Setting up Scale57
I0926 14:52:17.247424  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.247426  4911 net.cpp:137] Memory required for data: 1184154800
I0926 14:52:17.247431  4911 layer_factory.hpp:77] Creating layer Eltwise27
I0926 14:52:17.247434  4911 net.cpp:84] Creating Layer Eltwise27
I0926 14:52:17.247437  4911 net.cpp:406] Eltwise27 <- Eltwise26_penlu53_0_split_1
I0926 14:52:17.247440  4911 net.cpp:406] Eltwise27 <- Convolution57
I0926 14:52:17.247444  4911 net.cpp:380] Eltwise27 -> Eltwise27
I0926 14:52:17.247460  4911 net.cpp:122] Setting up Eltwise27
I0926 14:52:17.247464  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.247467  4911 net.cpp:137] Memory required for data: 1185793200
I0926 14:52:17.247475  4911 layer_factory.hpp:77] Creating layer penlu55
I0926 14:52:17.247481  4911 net.cpp:84] Creating Layer penlu55
I0926 14:52:17.247483  4911 net.cpp:406] penlu55 <- Eltwise27
I0926 14:52:17.247488  4911 net.cpp:367] penlu55 -> Eltwise27 (in-place)
I0926 14:52:17.247609  4911 net.cpp:122] Setting up penlu55
I0926 14:52:17.247615  4911 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 14:52:17.247617  4911 net.cpp:137] Memory required for data: 1187431600
I0926 14:52:17.247622  4911 layer_factory.hpp:77] Creating layer Pooling1
I0926 14:52:17.247627  4911 net.cpp:84] Creating Layer Pooling1
I0926 14:52:17.247628  4911 net.cpp:406] Pooling1 <- Eltwise27
I0926 14:52:17.247632  4911 net.cpp:380] Pooling1 -> Pooling1
I0926 14:52:17.248116  4911 net.cpp:122] Setting up Pooling1
I0926 14:52:17.248124  4911 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0926 14:52:17.262811  4911 net.cpp:137] Memory required for data: 1187457200
I0926 14:52:17.262821  4911 layer_factory.hpp:77] Creating layer InnerProduct1
I0926 14:52:17.262828  4911 net.cpp:84] Creating Layer InnerProduct1
I0926 14:52:17.262831  4911 net.cpp:406] InnerProduct1 <- Pooling1
I0926 14:52:17.262837  4911 net.cpp:380] InnerProduct1 -> InnerProduct1
I0926 14:52:17.262966  4911 net.cpp:122] Setting up InnerProduct1
I0926 14:52:17.262972  4911 net.cpp:129] Top shape: 100 10 (1000)
I0926 14:52:17.262975  4911 net.cpp:137] Memory required for data: 1187461200
I0926 14:52:17.262979  4911 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0926 14:52:17.262984  4911 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I0926 14:52:17.262986  4911 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0926 14:52:17.262990  4911 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0926 14:52:17.262996  4911 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0926 14:52:17.263025  4911 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I0926 14:52:17.263029  4911 net.cpp:129] Top shape: 100 10 (1000)
I0926 14:52:17.263032  4911 net.cpp:129] Top shape: 100 10 (1000)
I0926 14:52:17.263034  4911 net.cpp:137] Memory required for data: 1187469200
I0926 14:52:17.263036  4911 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0926 14:52:17.263042  4911 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0926 14:52:17.263046  4911 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I0926 14:52:17.263048  4911 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I0926 14:52:17.263052  4911 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0926 14:52:17.263057  4911 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0926 14:52:17.263276  4911 net.cpp:122] Setting up SoftmaxWithLoss1
I0926 14:52:17.263283  4911 net.cpp:129] Top shape: (1)
I0926 14:52:17.263286  4911 net.cpp:132]     with loss weight 1
I0926 14:52:17.263293  4911 net.cpp:137] Memory required for data: 1187469204
I0926 14:52:17.263296  4911 layer_factory.hpp:77] Creating layer Accuracy1
I0926 14:52:17.263303  4911 net.cpp:84] Creating Layer Accuracy1
I0926 14:52:17.263305  4911 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I0926 14:52:17.263309  4911 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I0926 14:52:17.263312  4911 net.cpp:380] Accuracy1 -> Accuracy1
I0926 14:52:17.263319  4911 net.cpp:122] Setting up Accuracy1
I0926 14:52:17.263321  4911 net.cpp:129] Top shape: (1)
I0926 14:52:17.263324  4911 net.cpp:137] Memory required for data: 1187469208
I0926 14:52:17.263326  4911 net.cpp:200] Accuracy1 does not need backward computation.
I0926 14:52:17.263329  4911 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0926 14:52:17.263331  4911 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0926 14:52:17.263334  4911 net.cpp:198] InnerProduct1 needs backward computation.
I0926 14:52:17.263336  4911 net.cpp:198] Pooling1 needs backward computation.
I0926 14:52:17.263339  4911 net.cpp:198] penlu55 needs backward computation.
I0926 14:52:17.263350  4911 net.cpp:198] Eltwise27 needs backward computation.
I0926 14:52:17.263352  4911 net.cpp:198] Scale57 needs backward computation.
I0926 14:52:17.263355  4911 net.cpp:198] BatchNorm57 needs backward computation.
I0926 14:52:17.263356  4911 net.cpp:198] Convolution57 needs backward computation.
I0926 14:52:17.263360  4911 net.cpp:198] penlu54 needs backward computation.
I0926 14:52:17.263361  4911 net.cpp:198] Scale56 needs backward computation.
I0926 14:52:17.263363  4911 net.cpp:198] BatchNorm56 needs backward computation.
I0926 14:52:17.263365  4911 net.cpp:198] Convolution56 needs backward computation.
I0926 14:52:17.263367  4911 net.cpp:198] Eltwise26_penlu53_0_split needs backward computation.
I0926 14:52:17.263370  4911 net.cpp:198] penlu53 needs backward computation.
I0926 14:52:17.263372  4911 net.cpp:198] Eltwise26 needs backward computation.
I0926 14:52:17.263375  4911 net.cpp:198] Scale55 needs backward computation.
I0926 14:52:17.263377  4911 net.cpp:198] BatchNorm55 needs backward computation.
I0926 14:52:17.263380  4911 net.cpp:198] Convolution55 needs backward computation.
I0926 14:52:17.263382  4911 net.cpp:198] penlu52 needs backward computation.
I0926 14:52:17.263384  4911 net.cpp:198] Scale54 needs backward computation.
I0926 14:52:17.263386  4911 net.cpp:198] BatchNorm54 needs backward computation.
I0926 14:52:17.263388  4911 net.cpp:198] Convolution54 needs backward computation.
I0926 14:52:17.263391  4911 net.cpp:198] Eltwise25_penlu51_0_split needs backward computation.
I0926 14:52:17.263393  4911 net.cpp:198] penlu51 needs backward computation.
I0926 14:52:17.263396  4911 net.cpp:198] Eltwise25 needs backward computation.
I0926 14:52:17.263397  4911 net.cpp:198] Scale53 needs backward computation.
I0926 14:52:17.263401  4911 net.cpp:198] BatchNorm53 needs backward computation.
I0926 14:52:17.263402  4911 net.cpp:198] Convolution53 needs backward computation.
I0926 14:52:17.263404  4911 net.cpp:198] penlu50 needs backward computation.
I0926 14:52:17.263406  4911 net.cpp:198] Scale52 needs backward computation.
I0926 14:52:17.263408  4911 net.cpp:198] BatchNorm52 needs backward computation.
I0926 14:52:17.263411  4911 net.cpp:198] Convolution52 needs backward computation.
I0926 14:52:17.263413  4911 net.cpp:198] Eltwise24_penlu49_0_split needs backward computation.
I0926 14:52:17.263415  4911 net.cpp:198] penlu49 needs backward computation.
I0926 14:52:17.263418  4911 net.cpp:198] Eltwise24 needs backward computation.
I0926 14:52:17.263420  4911 net.cpp:198] Scale51 needs backward computation.
I0926 14:52:17.263423  4911 net.cpp:198] BatchNorm51 needs backward computation.
I0926 14:52:17.263425  4911 net.cpp:198] Convolution51 needs backward computation.
I0926 14:52:17.263427  4911 net.cpp:198] penlu48 needs backward computation.
I0926 14:52:17.263429  4911 net.cpp:198] Scale50 needs backward computation.
I0926 14:52:17.263432  4911 net.cpp:198] BatchNorm50 needs backward computation.
I0926 14:52:17.263434  4911 net.cpp:198] Convolution50 needs backward computation.
I0926 14:52:17.263437  4911 net.cpp:198] Eltwise23_penlu47_0_split needs backward computation.
I0926 14:52:17.263439  4911 net.cpp:198] penlu47 needs backward computation.
I0926 14:52:17.263442  4911 net.cpp:198] Eltwise23 needs backward computation.
I0926 14:52:17.263444  4911 net.cpp:198] Scale49 needs backward computation.
I0926 14:52:17.263447  4911 net.cpp:198] BatchNorm49 needs backward computation.
I0926 14:52:17.263448  4911 net.cpp:198] Convolution49 needs backward computation.
I0926 14:52:17.263451  4911 net.cpp:198] penlu46 needs backward computation.
I0926 14:52:17.263453  4911 net.cpp:198] Scale48 needs backward computation.
I0926 14:52:17.263456  4911 net.cpp:198] BatchNorm48 needs backward computation.
I0926 14:52:17.263458  4911 net.cpp:198] Convolution48 needs backward computation.
I0926 14:52:17.263461  4911 net.cpp:198] Eltwise22_penlu45_0_split needs backward computation.
I0926 14:52:17.263463  4911 net.cpp:198] penlu45 needs backward computation.
I0926 14:52:17.263466  4911 net.cpp:198] Eltwise22 needs backward computation.
I0926 14:52:17.263473  4911 net.cpp:198] Scale47 needs backward computation.
I0926 14:52:17.263474  4911 net.cpp:198] BatchNorm47 needs backward computation.
I0926 14:52:17.263478  4911 net.cpp:198] Convolution47 needs backward computation.
I0926 14:52:17.263479  4911 net.cpp:198] penlu44 needs backward computation.
I0926 14:52:17.263481  4911 net.cpp:198] Scale46 needs backward computation.
I0926 14:52:17.263484  4911 net.cpp:198] BatchNorm46 needs backward computation.
I0926 14:52:17.263486  4911 net.cpp:198] Convolution46 needs backward computation.
I0926 14:52:17.263489  4911 net.cpp:198] Eltwise21_penlu43_0_split needs backward computation.
I0926 14:52:17.263491  4911 net.cpp:198] penlu43 needs backward computation.
I0926 14:52:17.265164  4911 net.cpp:198] Eltwise21 needs backward computation.
I0926 14:52:17.265175  4911 net.cpp:198] Scale45 needs backward computation.
I0926 14:52:17.265179  4911 net.cpp:198] BatchNorm45 needs backward computation.
I0926 14:52:17.265182  4911 net.cpp:198] Convolution45 needs backward computation.
I0926 14:52:17.265184  4911 net.cpp:198] penlu42 needs backward computation.
I0926 14:52:17.265187  4911 net.cpp:198] Scale44 needs backward computation.
I0926 14:52:17.265189  4911 net.cpp:198] BatchNorm44 needs backward computation.
I0926 14:52:17.265192  4911 net.cpp:198] Convolution44 needs backward computation.
I0926 14:52:17.265194  4911 net.cpp:198] Eltwise20_penlu41_0_split needs backward computation.
I0926 14:52:17.265197  4911 net.cpp:198] penlu41 needs backward computation.
I0926 14:52:17.265199  4911 net.cpp:198] Eltwise20 needs backward computation.
I0926 14:52:17.265202  4911 net.cpp:198] Scale43 needs backward computation.
I0926 14:52:17.265205  4911 net.cpp:198] BatchNorm43 needs backward computation.
I0926 14:52:17.265208  4911 net.cpp:198] Convolution43 needs backward computation.
I0926 14:52:17.265209  4911 net.cpp:198] penlu40 needs backward computation.
I0926 14:52:17.265213  4911 net.cpp:198] Scale42 needs backward computation.
I0926 14:52:17.265214  4911 net.cpp:198] BatchNorm42 needs backward computation.
I0926 14:52:17.265218  4911 net.cpp:198] Convolution42 needs backward computation.
I0926 14:52:17.265219  4911 net.cpp:198] Eltwise19_penlu39_0_split needs backward computation.
I0926 14:52:17.265223  4911 net.cpp:198] penlu39 needs backward computation.
I0926 14:52:17.265225  4911 net.cpp:198] Eltwise19 needs backward computation.
I0926 14:52:17.265228  4911 net.cpp:198] Scale41 needs backward computation.
I0926 14:52:17.265230  4911 net.cpp:198] BatchNorm41 needs backward computation.
I0926 14:52:17.265233  4911 net.cpp:198] Convolution41 needs backward computation.
I0926 14:52:17.265235  4911 net.cpp:198] penlu38 needs backward computation.
I0926 14:52:17.265239  4911 net.cpp:198] Scale40 needs backward computation.
I0926 14:52:17.265240  4911 net.cpp:198] BatchNorm40 needs backward computation.
I0926 14:52:17.265242  4911 net.cpp:198] Convolution40 needs backward computation.
I0926 14:52:17.265245  4911 net.cpp:198] Scale39 needs backward computation.
I0926 14:52:17.265249  4911 net.cpp:198] BatchNorm39 needs backward computation.
I0926 14:52:17.265250  4911 net.cpp:198] Convolution39 needs backward computation.
I0926 14:52:17.265254  4911 net.cpp:198] Eltwise18_penlu37_0_split needs backward computation.
I0926 14:52:17.265256  4911 net.cpp:198] penlu37 needs backward computation.
I0926 14:52:17.265259  4911 net.cpp:198] Eltwise18 needs backward computation.
I0926 14:52:17.265261  4911 net.cpp:198] Scale38 needs backward computation.
I0926 14:52:17.265264  4911 net.cpp:198] BatchNorm38 needs backward computation.
I0926 14:52:17.265266  4911 net.cpp:198] Convolution38 needs backward computation.
I0926 14:52:17.265269  4911 net.cpp:198] penlu36 needs backward computation.
I0926 14:52:17.265271  4911 net.cpp:198] Scale37 needs backward computation.
I0926 14:52:17.265274  4911 net.cpp:198] BatchNorm37 needs backward computation.
I0926 14:52:17.265275  4911 net.cpp:198] Convolution37 needs backward computation.
I0926 14:52:17.265285  4911 net.cpp:198] Eltwise17_penlu35_0_split needs backward computation.
I0926 14:52:17.265288  4911 net.cpp:198] penlu35 needs backward computation.
I0926 14:52:17.265291  4911 net.cpp:198] Eltwise17 needs backward computation.
I0926 14:52:17.265295  4911 net.cpp:198] Scale36 needs backward computation.
I0926 14:52:17.265296  4911 net.cpp:198] BatchNorm36 needs backward computation.
I0926 14:52:17.265298  4911 net.cpp:198] Convolution36 needs backward computation.
I0926 14:52:17.265301  4911 net.cpp:198] penlu34 needs backward computation.
I0926 14:52:17.265305  4911 net.cpp:198] Scale35 needs backward computation.
I0926 14:52:17.265306  4911 net.cpp:198] BatchNorm35 needs backward computation.
I0926 14:52:17.265310  4911 net.cpp:198] Convolution35 needs backward computation.
I0926 14:52:17.265311  4911 net.cpp:198] Eltwise16_penlu33_0_split needs backward computation.
I0926 14:52:17.265314  4911 net.cpp:198] penlu33 needs backward computation.
I0926 14:52:17.265317  4911 net.cpp:198] Eltwise16 needs backward computation.
I0926 14:52:17.265319  4911 net.cpp:198] Scale34 needs backward computation.
I0926 14:52:17.265322  4911 net.cpp:198] BatchNorm34 needs backward computation.
I0926 14:52:17.265324  4911 net.cpp:198] Convolution34 needs backward computation.
I0926 14:52:17.265326  4911 net.cpp:198] penlu32 needs backward computation.
I0926 14:52:17.265329  4911 net.cpp:198] Scale33 needs backward computation.
I0926 14:52:17.265331  4911 net.cpp:198] BatchNorm33 needs backward computation.
I0926 14:52:17.265333  4911 net.cpp:198] Convolution33 needs backward computation.
I0926 14:52:17.265336  4911 net.cpp:198] Eltwise15_penlu31_0_split needs backward computation.
I0926 14:52:17.265338  4911 net.cpp:198] penlu31 needs backward computation.
I0926 14:52:17.265341  4911 net.cpp:198] Eltwise15 needs backward computation.
I0926 14:52:17.265344  4911 net.cpp:198] Scale32 needs backward computation.
I0926 14:52:17.265347  4911 net.cpp:198] BatchNorm32 needs backward computation.
I0926 14:52:17.265348  4911 net.cpp:198] Convolution32 needs backward computation.
I0926 14:52:17.265352  4911 net.cpp:198] penlu30 needs backward computation.
I0926 14:52:17.265353  4911 net.cpp:198] Scale31 needs backward computation.
I0926 14:52:17.265355  4911 net.cpp:198] BatchNorm31 needs backward computation.
I0926 14:52:17.265358  4911 net.cpp:198] Convolution31 needs backward computation.
I0926 14:52:17.265360  4911 net.cpp:198] Eltwise14_penlu29_0_split needs backward computation.
I0926 14:52:17.265364  4911 net.cpp:198] penlu29 needs backward computation.
I0926 14:52:17.265367  4911 net.cpp:198] Eltwise14 needs backward computation.
I0926 14:52:17.265369  4911 net.cpp:198] Scale30 needs backward computation.
I0926 14:52:17.265372  4911 net.cpp:198] BatchNorm30 needs backward computation.
I0926 14:52:17.265374  4911 net.cpp:198] Convolution30 needs backward computation.
I0926 14:52:17.265377  4911 net.cpp:198] penlu28 needs backward computation.
I0926 14:52:17.265379  4911 net.cpp:198] Scale29 needs backward computation.
I0926 14:52:17.265381  4911 net.cpp:198] BatchNorm29 needs backward computation.
I0926 14:52:17.265384  4911 net.cpp:198] Convolution29 needs backward computation.
I0926 14:52:17.265386  4911 net.cpp:198] Eltwise13_penlu27_0_split needs backward computation.
I0926 14:52:17.265389  4911 net.cpp:198] penlu27 needs backward computation.
I0926 14:52:17.265391  4911 net.cpp:198] Eltwise13 needs backward computation.
I0926 14:52:17.265394  4911 net.cpp:198] Scale28 needs backward computation.
I0926 14:52:17.265396  4911 net.cpp:198] BatchNorm28 needs backward computation.
I0926 14:52:17.265399  4911 net.cpp:198] Convolution28 needs backward computation.
I0926 14:52:17.265401  4911 net.cpp:198] penlu26 needs backward computation.
I0926 14:52:17.265403  4911 net.cpp:198] Scale27 needs backward computation.
I0926 14:52:17.265406  4911 net.cpp:198] BatchNorm27 needs backward computation.
I0926 14:52:17.265408  4911 net.cpp:198] Convolution27 needs backward computation.
I0926 14:52:17.265411  4911 net.cpp:198] Eltwise12_penlu25_0_split needs backward computation.
I0926 14:52:17.265417  4911 net.cpp:198] penlu25 needs backward computation.
I0926 14:52:17.265420  4911 net.cpp:198] Eltwise12 needs backward computation.
I0926 14:52:17.265424  4911 net.cpp:198] Scale26 needs backward computation.
I0926 14:52:17.265425  4911 net.cpp:198] BatchNorm26 needs backward computation.
I0926 14:52:17.265429  4911 net.cpp:198] Convolution26 needs backward computation.
I0926 14:52:17.265430  4911 net.cpp:198] penlu24 needs backward computation.
I0926 14:52:17.265432  4911 net.cpp:198] Scale25 needs backward computation.
I0926 14:52:17.265435  4911 net.cpp:198] BatchNorm25 needs backward computation.
I0926 14:52:17.295578  4911 net.cpp:198] Convolution25 needs backward computation.
I0926 14:52:17.295589  4911 net.cpp:198] Eltwise11_penlu23_0_split needs backward computation.
I0926 14:52:17.295593  4911 net.cpp:198] penlu23 needs backward computation.
I0926 14:52:17.295595  4911 net.cpp:198] Eltwise11 needs backward computation.
I0926 14:52:17.295599  4911 net.cpp:198] Scale24 needs backward computation.
I0926 14:52:17.295601  4911 net.cpp:198] BatchNorm24 needs backward computation.
I0926 14:52:17.295603  4911 net.cpp:198] Convolution24 needs backward computation.
I0926 14:52:17.295606  4911 net.cpp:198] penlu22 needs backward computation.
I0926 14:52:17.295608  4911 net.cpp:198] Scale23 needs backward computation.
I0926 14:52:17.295611  4911 net.cpp:198] BatchNorm23 needs backward computation.
I0926 14:52:17.295614  4911 net.cpp:198] Convolution23 needs backward computation.
I0926 14:52:17.295616  4911 net.cpp:198] Eltwise10_penlu21_0_split needs backward computation.
I0926 14:52:17.295619  4911 net.cpp:198] penlu21 needs backward computation.
I0926 14:52:17.295621  4911 net.cpp:198] Eltwise10 needs backward computation.
I0926 14:52:17.295624  4911 net.cpp:198] Scale22 needs backward computation.
I0926 14:52:17.295627  4911 net.cpp:198] BatchNorm22 needs backward computation.
I0926 14:52:17.295629  4911 net.cpp:198] Convolution22 needs backward computation.
I0926 14:52:17.295632  4911 net.cpp:198] penlu20 needs backward computation.
I0926 14:52:17.295634  4911 net.cpp:198] Scale21 needs backward computation.
I0926 14:52:17.295637  4911 net.cpp:198] BatchNorm21 needs backward computation.
I0926 14:52:17.295639  4911 net.cpp:198] Convolution21 needs backward computation.
I0926 14:52:17.295642  4911 net.cpp:198] Scale20 needs backward computation.
I0926 14:52:17.295644  4911 net.cpp:198] BatchNorm20 needs backward computation.
I0926 14:52:17.295646  4911 net.cpp:198] Convolution20 needs backward computation.
I0926 14:52:17.295650  4911 net.cpp:198] Eltwise9_penlu19_0_split needs backward computation.
I0926 14:52:17.295652  4911 net.cpp:198] penlu19 needs backward computation.
I0926 14:52:17.295655  4911 net.cpp:198] Eltwise9 needs backward computation.
I0926 14:52:17.295657  4911 net.cpp:198] Scale19 needs backward computation.
I0926 14:52:17.295660  4911 net.cpp:198] BatchNorm19 needs backward computation.
I0926 14:52:17.295662  4911 net.cpp:198] Convolution19 needs backward computation.
I0926 14:52:17.295665  4911 net.cpp:198] penlu18 needs backward computation.
I0926 14:52:17.295667  4911 net.cpp:198] Scale18 needs backward computation.
I0926 14:52:17.295670  4911 net.cpp:198] BatchNorm18 needs backward computation.
I0926 14:52:17.295672  4911 net.cpp:198] Convolution18 needs backward computation.
I0926 14:52:17.295675  4911 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I0926 14:52:17.295677  4911 net.cpp:198] penlu17 needs backward computation.
I0926 14:52:17.295680  4911 net.cpp:198] Eltwise8 needs backward computation.
I0926 14:52:17.295683  4911 net.cpp:198] Scale17 needs backward computation.
I0926 14:52:17.295686  4911 net.cpp:198] BatchNorm17 needs backward computation.
I0926 14:52:17.295688  4911 net.cpp:198] Convolution17 needs backward computation.
I0926 14:52:17.295691  4911 net.cpp:198] penlu16 needs backward computation.
I0926 14:52:17.295692  4911 net.cpp:198] Scale16 needs backward computation.
I0926 14:52:17.295696  4911 net.cpp:198] BatchNorm16 needs backward computation.
I0926 14:52:17.295706  4911 net.cpp:198] Convolution16 needs backward computation.
I0926 14:52:17.295708  4911 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I0926 14:52:17.295711  4911 net.cpp:198] penlu15 needs backward computation.
I0926 14:52:17.295713  4911 net.cpp:198] Eltwise7 needs backward computation.
I0926 14:52:17.295717  4911 net.cpp:198] Scale15 needs backward computation.
I0926 14:52:17.295719  4911 net.cpp:198] BatchNorm15 needs backward computation.
I0926 14:52:17.295722  4911 net.cpp:198] Convolution15 needs backward computation.
I0926 14:52:17.295724  4911 net.cpp:198] penlu14 needs backward computation.
I0926 14:52:17.295727  4911 net.cpp:198] Scale14 needs backward computation.
I0926 14:52:17.295729  4911 net.cpp:198] BatchNorm14 needs backward computation.
I0926 14:52:17.295732  4911 net.cpp:198] Convolution14 needs backward computation.
I0926 14:52:17.295734  4911 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I0926 14:52:17.295737  4911 net.cpp:198] penlu13 needs backward computation.
I0926 14:52:17.295739  4911 net.cpp:198] Eltwise6 needs backward computation.
I0926 14:52:17.295742  4911 net.cpp:198] Scale13 needs backward computation.
I0926 14:52:17.295744  4911 net.cpp:198] BatchNorm13 needs backward computation.
I0926 14:52:17.295747  4911 net.cpp:198] Convolution13 needs backward computation.
I0926 14:52:17.295749  4911 net.cpp:198] penlu12 needs backward computation.
I0926 14:52:17.295752  4911 net.cpp:198] Scale12 needs backward computation.
I0926 14:52:17.295753  4911 net.cpp:198] BatchNorm12 needs backward computation.
I0926 14:52:17.295756  4911 net.cpp:198] Convolution12 needs backward computation.
I0926 14:52:17.295758  4911 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I0926 14:52:17.295761  4911 net.cpp:198] penlu11 needs backward computation.
I0926 14:52:17.295763  4911 net.cpp:198] Eltwise5 needs backward computation.
I0926 14:52:17.295766  4911 net.cpp:198] Scale11 needs backward computation.
I0926 14:52:17.295768  4911 net.cpp:198] BatchNorm11 needs backward computation.
I0926 14:52:17.295771  4911 net.cpp:198] Convolution11 needs backward computation.
I0926 14:52:17.295773  4911 net.cpp:198] penlu10 needs backward computation.
I0926 14:52:17.295776  4911 net.cpp:198] Scale10 needs backward computation.
I0926 14:52:17.295778  4911 net.cpp:198] BatchNorm10 needs backward computation.
I0926 14:52:17.295780  4911 net.cpp:198] Convolution10 needs backward computation.
I0926 14:52:17.295785  4911 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I0926 14:52:17.295788  4911 net.cpp:198] penlu9 needs backward computation.
I0926 14:52:17.295790  4911 net.cpp:198] Eltwise4 needs backward computation.
I0926 14:52:17.295794  4911 net.cpp:198] Scale9 needs backward computation.
I0926 14:52:17.295796  4911 net.cpp:198] BatchNorm9 needs backward computation.
I0926 14:52:17.295799  4911 net.cpp:198] Convolution9 needs backward computation.
I0926 14:52:17.295802  4911 net.cpp:198] penlu8 needs backward computation.
I0926 14:52:17.295804  4911 net.cpp:198] Scale8 needs backward computation.
I0926 14:52:17.295807  4911 net.cpp:198] BatchNorm8 needs backward computation.
I0926 14:52:17.295809  4911 net.cpp:198] Convolution8 needs backward computation.
I0926 14:52:17.295812  4911 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I0926 14:52:17.295814  4911 net.cpp:198] penlu7 needs backward computation.
I0926 14:52:17.295817  4911 net.cpp:198] Eltwise3 needs backward computation.
I0926 14:52:17.295820  4911 net.cpp:198] Scale7 needs backward computation.
I0926 14:52:17.295822  4911 net.cpp:198] BatchNorm7 needs backward computation.
I0926 14:52:17.295825  4911 net.cpp:198] Convolution7 needs backward computation.
I0926 14:52:17.295827  4911 net.cpp:198] penlu6 needs backward computation.
I0926 14:52:17.295830  4911 net.cpp:198] Scale6 needs backward computation.
I0926 14:52:17.295832  4911 net.cpp:198] BatchNorm6 needs backward computation.
I0926 14:52:17.295835  4911 net.cpp:198] Convolution6 needs backward computation.
I0926 14:52:17.295840  4911 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I0926 14:52:17.295843  4911 net.cpp:198] penlu5 needs backward computation.
I0926 14:52:17.295846  4911 net.cpp:198] Eltwise2 needs backward computation.
I0926 14:52:17.295850  4911 net.cpp:198] Scale5 needs backward computation.
I0926 14:52:17.295851  4911 net.cpp:198] BatchNorm5 needs backward computation.
I0926 14:52:17.295855  4911 net.cpp:198] Convolution5 needs backward computation.
I0926 14:52:17.295857  4911 net.cpp:198] penlu4 needs backward computation.
I0926 14:52:17.295859  4911 net.cpp:198] Scale4 needs backward computation.
I0926 14:52:17.295861  4911 net.cpp:198] BatchNorm4 needs backward computation.
I0926 14:52:17.295864  4911 net.cpp:198] Convolution4 needs backward computation.
I0926 14:52:17.295866  4911 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I0926 14:52:17.295869  4911 net.cpp:198] penlu3 needs backward computation.
I0926 14:52:17.295872  4911 net.cpp:198] Eltwise1 needs backward computation.
I0926 14:52:17.295876  4911 net.cpp:198] Scale3 needs backward computation.
I0926 14:52:17.295877  4911 net.cpp:198] BatchNorm3 needs backward computation.
I0926 14:52:17.295879  4911 net.cpp:198] Convolution3 needs backward computation.
I0926 14:52:17.295882  4911 net.cpp:198] penlu2 needs backward computation.
I0926 14:52:17.295886  4911 net.cpp:198] Scale2 needs backward computation.
I0926 14:52:17.295887  4911 net.cpp:198] BatchNorm2 needs backward computation.
I0926 14:52:17.295889  4911 net.cpp:198] Convolution2 needs backward computation.
I0926 14:52:17.295892  4911 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I0926 14:52:17.295895  4911 net.cpp:198] penlu1 needs backward computation.
I0926 14:52:17.295897  4911 net.cpp:198] Scale1 needs backward computation.
I0926 14:52:17.295899  4911 net.cpp:198] BatchNorm1 needs backward computation.
I0926 14:52:17.295902  4911 net.cpp:198] Convolution1 needs backward computation.
I0926 14:52:17.295905  4911 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I0926 14:52:17.295908  4911 net.cpp:200] Data1 does not need backward computation.
I0926 14:52:17.295910  4911 net.cpp:242] This network produces output Accuracy1
I0926 14:52:17.295913  4911 net.cpp:242] This network produces output SoftmaxWithLoss1
I0926 14:52:17.296013  4911 net.cpp:255] Network initialization done.
I0926 14:52:17.296849  4911 solver.cpp:56] Solver scaffolding done.
I0926 14:52:17.311195  4911 caffe.cpp:155] Finetuning from xn/PENLU/snapshot/resnet/res56_relu_iter_100000.caffemodel
I0926 14:52:17.315647  4911 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: xn/PENLU/snapshot/resnet/res56_relu_iter_100000.caffemodel
I0926 14:52:17.315672  4911 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0926 14:52:17.315685  4911 net.cpp:744] Ignoring source layer ReLU1
I0926 14:52:17.315686  4911 net.cpp:744] Ignoring source layer Convolution1_ReLU1_0_split
I0926 14:52:17.315693  4911 net.cpp:744] Ignoring source layer ReLU2
I0926 14:52:17.315701  4911 net.cpp:744] Ignoring source layer ReLU3
I0926 14:52:17.315703  4911 net.cpp:744] Ignoring source layer Eltwise1_ReLU3_0_split
I0926 14:52:17.315711  4911 net.cpp:744] Ignoring source layer ReLU4
I0926 14:52:17.315718  4911 net.cpp:744] Ignoring source layer ReLU5
I0926 14:52:17.315721  4911 net.cpp:744] Ignoring source layer Eltwise2_ReLU5_0_split
I0926 14:52:17.315727  4911 net.cpp:744] Ignoring source layer ReLU6
I0926 14:52:17.315734  4911 net.cpp:744] Ignoring source layer ReLU7
I0926 14:52:17.315737  4911 net.cpp:744] Ignoring source layer Eltwise3_ReLU7_0_split
I0926 14:52:17.315743  4911 net.cpp:744] Ignoring source layer ReLU8
I0926 14:52:17.315750  4911 net.cpp:744] Ignoring source layer ReLU9
I0926 14:52:17.315753  4911 net.cpp:744] Ignoring source layer Eltwise4_ReLU9_0_split
I0926 14:52:17.315760  4911 net.cpp:744] Ignoring source layer ReLU10
I0926 14:52:17.315781  4911 net.cpp:744] Ignoring source layer ReLU11
I0926 14:52:17.315784  4911 net.cpp:744] Ignoring source layer Eltwise5_ReLU11_0_split
I0926 14:52:17.315793  4911 net.cpp:744] Ignoring source layer ReLU12
I0926 14:52:17.315799  4911 net.cpp:744] Ignoring source layer ReLU13
I0926 14:52:17.315801  4911 net.cpp:744] Ignoring source layer Eltwise6_ReLU13_0_split
I0926 14:52:17.315809  4911 net.cpp:744] Ignoring source layer ReLU14
I0926 14:52:17.315816  4911 net.cpp:744] Ignoring source layer ReLU15
I0926 14:52:17.315819  4911 net.cpp:744] Ignoring source layer Eltwise7_ReLU15_0_split
I0926 14:52:17.315826  4911 net.cpp:744] Ignoring source layer ReLU16
I0926 14:52:17.315834  4911 net.cpp:744] Ignoring source layer ReLU17
I0926 14:52:17.315836  4911 net.cpp:744] Ignoring source layer Eltwise8_ReLU17_0_split
I0926 14:52:17.315843  4911 net.cpp:744] Ignoring source layer ReLU18
I0926 14:52:17.315850  4911 net.cpp:744] Ignoring source layer ReLU19
I0926 14:52:17.315852  4911 net.cpp:744] Ignoring source layer Eltwise9_ReLU19_0_split
I0926 14:52:17.315866  4911 net.cpp:744] Ignoring source layer ReLU20
I0926 14:52:17.315878  4911 net.cpp:744] Ignoring source layer ReLU21
I0926 14:52:17.315881  4911 net.cpp:744] Ignoring source layer Eltwise10_ReLU21_0_split
I0926 14:52:17.315893  4911 net.cpp:744] Ignoring source layer ReLU22
I0926 14:52:17.315907  4911 net.cpp:744] Ignoring source layer ReLU23
I0926 14:52:17.315909  4911 net.cpp:744] Ignoring source layer Eltwise11_ReLU23_0_split
I0926 14:52:17.315922  4911 net.cpp:744] Ignoring source layer ReLU24
I0926 14:52:17.315934  4911 net.cpp:744] Ignoring source layer ReLU25
I0926 14:52:17.315937  4911 net.cpp:744] Ignoring source layer Eltwise12_ReLU25_0_split
I0926 14:52:17.315949  4911 net.cpp:744] Ignoring source layer ReLU26
I0926 14:52:17.315963  4911 net.cpp:744] Ignoring source layer ReLU27
I0926 14:52:17.315964  4911 net.cpp:744] Ignoring source layer Eltwise13_ReLU27_0_split
I0926 14:52:17.315978  4911 net.cpp:744] Ignoring source layer ReLU28
I0926 14:52:17.315989  4911 net.cpp:744] Ignoring source layer ReLU29
I0926 14:52:17.315992  4911 net.cpp:744] Ignoring source layer Eltwise14_ReLU29_0_split
I0926 14:52:17.316004  4911 net.cpp:744] Ignoring source layer ReLU30
I0926 14:52:17.316017  4911 net.cpp:744] Ignoring source layer ReLU31
I0926 14:52:17.316020  4911 net.cpp:744] Ignoring source layer Eltwise15_ReLU31_0_split
I0926 14:52:17.316031  4911 net.cpp:744] Ignoring source layer ReLU32
I0926 14:52:17.316045  4911 net.cpp:744] Ignoring source layer ReLU33
I0926 14:52:17.316046  4911 net.cpp:744] Ignoring source layer Eltwise16_ReLU33_0_split
I0926 14:52:17.316058  4911 net.cpp:744] Ignoring source layer ReLU34
I0926 14:52:17.316071  4911 net.cpp:744] Ignoring source layer ReLU35
I0926 14:52:17.316073  4911 net.cpp:744] Ignoring source layer Eltwise17_ReLU35_0_split
I0926 14:52:17.316085  4911 net.cpp:744] Ignoring source layer ReLU36
I0926 14:52:17.316097  4911 net.cpp:744] Ignoring source layer ReLU37
I0926 14:52:17.316100  4911 net.cpp:744] Ignoring source layer Eltwise18_ReLU37_0_split
I0926 14:52:17.316123  4911 net.cpp:744] Ignoring source layer ReLU38
I0926 14:52:17.316151  4911 net.cpp:744] Ignoring source layer ReLU39
I0926 14:52:17.316154  4911 net.cpp:744] Ignoring source layer Eltwise19_ReLU39_0_split
I0926 14:52:17.316182  4911 net.cpp:744] Ignoring source layer ReLU40
I0926 14:52:17.316210  4911 net.cpp:744] Ignoring source layer ReLU41
I0926 14:52:17.316212  4911 net.cpp:744] Ignoring source layer Eltwise20_ReLU41_0_split
I0926 14:52:17.316238  4911 net.cpp:744] Ignoring source layer ReLU42
I0926 14:52:17.316267  4911 net.cpp:744] Ignoring source layer ReLU43
I0926 14:52:17.316270  4911 net.cpp:744] Ignoring source layer Eltwise21_ReLU43_0_split
I0926 14:52:17.316295  4911 net.cpp:744] Ignoring source layer ReLU44
I0926 14:52:17.316323  4911 net.cpp:744] Ignoring source layer ReLU45
I0926 14:52:17.316325  4911 net.cpp:744] Ignoring source layer Eltwise22_ReLU45_0_split
I0926 14:52:17.316351  4911 net.cpp:744] Ignoring source layer ReLU46
I0926 14:52:17.316381  4911 net.cpp:744] Ignoring source layer ReLU47
I0926 14:52:17.316385  4911 net.cpp:744] Ignoring source layer Eltwise23_ReLU47_0_split
I0926 14:52:17.316411  4911 net.cpp:744] Ignoring source layer ReLU48
I0926 14:52:17.316439  4911 net.cpp:744] Ignoring source layer ReLU49
I0926 14:52:17.316442  4911 net.cpp:744] Ignoring source layer Eltwise24_ReLU49_0_split
I0926 14:52:17.316468  4911 net.cpp:744] Ignoring source layer ReLU50
I0926 14:52:17.323812  4911 net.cpp:744] Ignoring source layer ReLU51
I0926 14:52:17.323822  4911 net.cpp:744] Ignoring source layer Eltwise25_ReLU51_0_split
I0926 14:52:17.323851  4911 net.cpp:744] Ignoring source layer ReLU52
I0926 14:52:17.323882  4911 net.cpp:744] Ignoring source layer ReLU53
I0926 14:52:17.323885  4911 net.cpp:744] Ignoring source layer Eltwise26_ReLU53_0_split
I0926 14:52:17.323916  4911 net.cpp:744] Ignoring source layer ReLU54
I0926 14:52:17.323947  4911 net.cpp:744] Ignoring source layer ReLU55
I0926 14:52:17.328063  4911 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: xn/PENLU/snapshot/resnet/res56_relu_iter_100000.caffemodel
I0926 14:52:17.328094  4911 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0926 14:52:17.328105  4911 net.cpp:744] Ignoring source layer ReLU1
I0926 14:52:17.328107  4911 net.cpp:744] Ignoring source layer Convolution1_ReLU1_0_split
I0926 14:52:17.328115  4911 net.cpp:744] Ignoring source layer ReLU2
I0926 14:52:17.328122  4911 net.cpp:744] Ignoring source layer ReLU3
I0926 14:52:17.328125  4911 net.cpp:744] Ignoring source layer Eltwise1_ReLU3_0_split
I0926 14:52:17.328131  4911 net.cpp:744] Ignoring source layer ReLU4
I0926 14:52:17.328140  4911 net.cpp:744] Ignoring source layer ReLU5
I0926 14:52:17.328141  4911 net.cpp:744] Ignoring source layer Eltwise2_ReLU5_0_split
I0926 14:52:17.328148  4911 net.cpp:744] Ignoring source layer ReLU6
I0926 14:52:17.328155  4911 net.cpp:744] Ignoring source layer ReLU7
I0926 14:52:17.328158  4911 net.cpp:744] Ignoring source layer Eltwise3_ReLU7_0_split
I0926 14:52:17.328166  4911 net.cpp:744] Ignoring source layer ReLU8
I0926 14:52:17.328172  4911 net.cpp:744] Ignoring source layer ReLU9
I0926 14:52:17.328174  4911 net.cpp:744] Ignoring source layer Eltwise4_ReLU9_0_split
I0926 14:52:17.328181  4911 net.cpp:744] Ignoring source layer ReLU10
I0926 14:52:17.328188  4911 net.cpp:744] Ignoring source layer ReLU11
I0926 14:52:17.328191  4911 net.cpp:744] Ignoring source layer Eltwise5_ReLU11_0_split
I0926 14:52:17.328198  4911 net.cpp:744] Ignoring source layer ReLU12
I0926 14:52:17.328207  4911 net.cpp:744] Ignoring source layer ReLU13
I0926 14:52:17.328208  4911 net.cpp:744] Ignoring source layer Eltwise6_ReLU13_0_split
I0926 14:52:17.328215  4911 net.cpp:744] Ignoring source layer ReLU14
I0926 14:52:17.328223  4911 net.cpp:744] Ignoring source layer ReLU15
I0926 14:52:17.328227  4911 net.cpp:744] Ignoring source layer Eltwise7_ReLU15_0_split
I0926 14:52:17.328233  4911 net.cpp:744] Ignoring source layer ReLU16
I0926 14:52:17.328240  4911 net.cpp:744] Ignoring source layer ReLU17
I0926 14:52:17.328243  4911 net.cpp:744] Ignoring source layer Eltwise8_ReLU17_0_split
I0926 14:52:17.328249  4911 net.cpp:744] Ignoring source layer ReLU18
I0926 14:52:17.328258  4911 net.cpp:744] Ignoring source layer ReLU19
I0926 14:52:17.328259  4911 net.cpp:744] Ignoring source layer Eltwise9_ReLU19_0_split
I0926 14:52:17.328274  4911 net.cpp:744] Ignoring source layer ReLU20
I0926 14:52:17.328287  4911 net.cpp:744] Ignoring source layer ReLU21
I0926 14:52:17.328289  4911 net.cpp:744] Ignoring source layer Eltwise10_ReLU21_0_split
I0926 14:52:17.328302  4911 net.cpp:744] Ignoring source layer ReLU22
I0926 14:52:17.328316  4911 net.cpp:744] Ignoring source layer ReLU23
I0926 14:52:17.328320  4911 net.cpp:744] Ignoring source layer Eltwise11_ReLU23_0_split
I0926 14:52:17.328332  4911 net.cpp:744] Ignoring source layer ReLU24
I0926 14:52:17.328346  4911 net.cpp:744] Ignoring source layer ReLU25
I0926 14:52:17.328347  4911 net.cpp:744] Ignoring source layer Eltwise12_ReLU25_0_split
I0926 14:52:17.328374  4911 net.cpp:744] Ignoring source layer ReLU26
I0926 14:52:17.328387  4911 net.cpp:744] Ignoring source layer ReLU27
I0926 14:52:17.328390  4911 net.cpp:744] Ignoring source layer Eltwise13_ReLU27_0_split
I0926 14:52:17.328402  4911 net.cpp:744] Ignoring source layer ReLU28
I0926 14:52:17.328416  4911 net.cpp:744] Ignoring source layer ReLU29
I0926 14:52:17.328419  4911 net.cpp:744] Ignoring source layer Eltwise14_ReLU29_0_split
I0926 14:52:17.328433  4911 net.cpp:744] Ignoring source layer ReLU30
I0926 14:52:17.328445  4911 net.cpp:744] Ignoring source layer ReLU31
I0926 14:52:17.328447  4911 net.cpp:744] Ignoring source layer Eltwise15_ReLU31_0_split
I0926 14:52:17.328459  4911 net.cpp:744] Ignoring source layer ReLU32
I0926 14:52:17.328472  4911 net.cpp:744] Ignoring source layer ReLU33
I0926 14:52:17.328475  4911 net.cpp:744] Ignoring source layer Eltwise16_ReLU33_0_split
I0926 14:52:17.328487  4911 net.cpp:744] Ignoring source layer ReLU34
I0926 14:52:17.328507  4911 net.cpp:744] Ignoring source layer ReLU35
I0926 14:52:17.328510  4911 net.cpp:744] Ignoring source layer Eltwise17_ReLU35_0_split
I0926 14:52:17.328532  4911 net.cpp:744] Ignoring source layer ReLU36
I0926 14:52:17.328546  4911 net.cpp:744] Ignoring source layer ReLU37
I0926 14:52:17.328547  4911 net.cpp:744] Ignoring source layer Eltwise18_ReLU37_0_split
I0926 14:52:17.328570  4911 net.cpp:744] Ignoring source layer ReLU38
I0926 14:52:17.328603  4911 net.cpp:744] Ignoring source layer ReLU39
I0926 14:52:17.328605  4911 net.cpp:744] Ignoring source layer Eltwise19_ReLU39_0_split
I0926 14:52:17.328635  4911 net.cpp:744] Ignoring source layer ReLU40
I0926 14:52:17.328666  4911 net.cpp:744] Ignoring source layer ReLU41
I0926 14:52:17.328668  4911 net.cpp:744] Ignoring source layer Eltwise20_ReLU41_0_split
I0926 14:52:17.328699  4911 net.cpp:744] Ignoring source layer ReLU42
I0926 14:52:17.328730  4911 net.cpp:744] Ignoring source layer ReLU43
I0926 14:52:17.328732  4911 net.cpp:744] Ignoring source layer Eltwise21_ReLU43_0_split
I0926 14:52:17.328761  4911 net.cpp:744] Ignoring source layer ReLU44
I0926 14:52:17.328793  4911 net.cpp:744] Ignoring source layer ReLU45
I0926 14:52:17.328794  4911 net.cpp:744] Ignoring source layer Eltwise22_ReLU45_0_split
I0926 14:52:17.328824  4911 net.cpp:744] Ignoring source layer ReLU46
I0926 14:52:17.328855  4911 net.cpp:744] Ignoring source layer ReLU47
I0926 14:52:17.328858  4911 net.cpp:744] Ignoring source layer Eltwise23_ReLU47_0_split
I0926 14:52:17.328889  4911 net.cpp:744] Ignoring source layer ReLU48
I0926 14:52:17.328922  4911 net.cpp:744] Ignoring source layer ReLU49
I0926 14:52:17.328924  4911 net.cpp:744] Ignoring source layer Eltwise24_ReLU49_0_split
I0926 14:52:17.328953  4911 net.cpp:744] Ignoring source layer ReLU50
I0926 14:52:17.328980  4911 net.cpp:744] Ignoring source layer ReLU51
I0926 14:52:17.328984  4911 net.cpp:744] Ignoring source layer Eltwise25_ReLU51_0_split
I0926 14:52:17.329013  4911 net.cpp:744] Ignoring source layer ReLU52
I0926 14:52:17.329043  4911 net.cpp:744] Ignoring source layer ReLU53
I0926 14:52:17.329046  4911 net.cpp:744] Ignoring source layer Eltwise26_ReLU53_0_split
I0926 14:52:17.329075  4911 net.cpp:744] Ignoring source layer ReLU54
I0926 14:52:17.329104  4911 net.cpp:744] Ignoring source layer ReLU55
I0926 14:52:17.329316  4911 caffe.cpp:248] Starting Optimization
I0926 14:52:17.329321  4911 solver.cpp:272] Solving resnet_cifar10
I0926 14:52:17.329324  4911 solver.cpp:273] Learning Rate Policy: multistep
I0926 14:52:17.335937  4911 solver.cpp:330] Iteration 0, Testing net (#0)
I0926 14:52:20.830447  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 14:52:20.972213  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1198
I0926 14:52:20.972249  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 70.8184 (* 1 = 70.8184 loss)
I0926 14:52:21.171222  4911 solver.cpp:218] Iteration 0 (-2.10195e-44 iter/s, 3.84181s/100 iters), loss = 6.46071
I0926 14:52:21.171252  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 6.46071 (* 1 = 6.46071 loss)
I0926 14:52:21.171288  4911 sgd_solver.cpp:105] Iteration 0, lr = 0.001
I0926 14:52:35.858359  4911 solver.cpp:218] Iteration 100 (6.80871 iter/s, 14.6871s/100 iters), loss = 1.15122
I0926 14:52:35.858389  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.15122 (* 1 = 1.15122 loss)
I0926 14:52:35.858395  4911 sgd_solver.cpp:105] Iteration 100, lr = 0.001
I0926 14:52:50.415520  4911 solver.cpp:218] Iteration 200 (6.86951 iter/s, 14.5571s/100 iters), loss = 1.55402
I0926 14:52:50.415709  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.55402 (* 1 = 1.55402 loss)
I0926 14:52:50.415716  4911 sgd_solver.cpp:105] Iteration 200, lr = 0.001
I0926 14:53:04.971159  4911 solver.cpp:218] Iteration 300 (6.87029 iter/s, 14.5554s/100 iters), loss = 0.974249
I0926 14:53:04.971200  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.974249 (* 1 = 0.974249 loss)
I0926 14:53:04.971206  4911 sgd_solver.cpp:105] Iteration 300, lr = 0.001
I0926 14:53:19.522397  4911 solver.cpp:218] Iteration 400 (6.87231 iter/s, 14.5512s/100 iters), loss = 0.783287
I0926 14:53:19.522439  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.783287 (* 1 = 0.783287 loss)
I0926 14:53:19.522444  4911 sgd_solver.cpp:105] Iteration 400, lr = 0.001
I0926 14:53:33.353839  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 14:53:33.935989  4911 solver.cpp:330] Iteration 500, Testing net (#0)
I0926 14:53:37.340435  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 14:53:37.482717  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3006
I0926 14:53:37.482753  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 24.6529 (* 1 = 24.6529 loss)
I0926 14:53:37.627279  4911 solver.cpp:218] Iteration 500 (5.5234 iter/s, 18.1048s/100 iters), loss = 0.956334
I0926 14:53:37.627310  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.956334 (* 1 = 0.956334 loss)
I0926 14:53:37.627316  4911 sgd_solver.cpp:105] Iteration 500, lr = 0.001
I0926 14:53:52.184991  4911 solver.cpp:218] Iteration 600 (6.86925 iter/s, 14.5576s/100 iters), loss = 0.735922
I0926 14:53:52.185032  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.735922 (* 1 = 0.735922 loss)
I0926 14:53:52.185039  4911 sgd_solver.cpp:105] Iteration 600, lr = 0.001
I0926 14:54:06.747138  4911 solver.cpp:218] Iteration 700 (6.86716 iter/s, 14.5621s/100 iters), loss = 0.999632
I0926 14:54:06.747257  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.999632 (* 1 = 0.999632 loss)
I0926 14:54:06.747274  4911 sgd_solver.cpp:105] Iteration 700, lr = 0.001
I0926 14:54:21.307193  4911 solver.cpp:218] Iteration 800 (6.86818 iter/s, 14.5599s/100 iters), loss = 0.780199
I0926 14:54:21.307234  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.780199 (* 1 = 0.780199 loss)
I0926 14:54:21.307238  4911 sgd_solver.cpp:105] Iteration 800, lr = 0.001
I0926 14:54:35.874915  4911 solver.cpp:218] Iteration 900 (6.86453 iter/s, 14.5676s/100 iters), loss = 0.703025
I0926 14:54:35.874945  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.703025 (* 1 = 0.703025 loss)
I0926 14:54:35.874951  4911 sgd_solver.cpp:105] Iteration 900, lr = 0.001
I0926 14:54:49.778529  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 14:54:50.366619  4911 solver.cpp:330] Iteration 1000, Testing net (#0)
I0926 14:54:53.782629  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 14:54:53.925190  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.2877
I0926 14:54:53.925217  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 12.3233 (* 1 = 12.3233 loss)
I0926 14:54:54.069151  4911 solver.cpp:218] Iteration 1000 (5.49627 iter/s, 18.1941s/100 iters), loss = 0.614798
I0926 14:54:54.069181  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.614798 (* 1 = 0.614798 loss)
I0926 14:54:54.069188  4911 sgd_solver.cpp:105] Iteration 1000, lr = 0.001
I0926 14:55:08.692638  4911 solver.cpp:218] Iteration 1100 (6.83835 iter/s, 14.6234s/100 iters), loss = 0.567929
I0926 14:55:08.692670  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.567929 (* 1 = 0.567929 loss)
I0926 14:55:08.692677  4911 sgd_solver.cpp:105] Iteration 1100, lr = 0.001
I0926 14:55:23.259294  4911 solver.cpp:218] Iteration 1200 (6.86503 iter/s, 14.5666s/100 iters), loss = 0.84259
I0926 14:55:23.259444  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.84259 (* 1 = 0.84259 loss)
I0926 14:55:23.259454  4911 sgd_solver.cpp:105] Iteration 1200, lr = 0.001
I0926 14:55:37.838155  4911 solver.cpp:218] Iteration 1300 (6.85934 iter/s, 14.5787s/100 iters), loss = 0.716489
I0926 14:55:37.838186  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.716489 (* 1 = 0.716489 loss)
I0926 14:55:37.838192  4911 sgd_solver.cpp:105] Iteration 1300, lr = 0.001
I0926 14:55:52.483800  4911 solver.cpp:218] Iteration 1400 (6.82801 iter/s, 14.6456s/100 iters), loss = 0.595217
I0926 14:55:52.483830  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.595217 (* 1 = 0.595217 loss)
I0926 14:55:52.483837  4911 sgd_solver.cpp:105] Iteration 1400, lr = 0.001
I0926 14:56:06.384650  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 14:56:06.969632  4911 solver.cpp:330] Iteration 1500, Testing net (#0)
I0926 14:56:10.425118  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 14:56:10.567128  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4057
I0926 14:56:10.567163  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 4.72507 (* 1 = 4.72507 loss)
I0926 14:56:10.710866  4911 solver.cpp:218] Iteration 1500 (5.48637 iter/s, 18.227s/100 iters), loss = 0.67338
I0926 14:56:10.710894  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.67338 (* 1 = 0.67338 loss)
I0926 14:56:10.710902  4911 sgd_solver.cpp:105] Iteration 1500, lr = 0.001
I0926 14:56:25.406966  4911 solver.cpp:218] Iteration 1600 (6.80456 iter/s, 14.696s/100 iters), loss = 0.651559
I0926 14:56:25.407011  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.651559 (* 1 = 0.651559 loss)
I0926 14:56:25.407019  4911 sgd_solver.cpp:105] Iteration 1600, lr = 0.001
I0926 14:56:40.292265  4911 solver.cpp:218] Iteration 1700 (6.71808 iter/s, 14.8852s/100 iters), loss = 0.700408
I0926 14:56:40.292376  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.700408 (* 1 = 0.700408 loss)
I0926 14:56:40.292385  4911 sgd_solver.cpp:105] Iteration 1700, lr = 0.001
I0926 14:56:54.940985  4911 solver.cpp:218] Iteration 1800 (6.8266 iter/s, 14.6486s/100 iters), loss = 0.649604
I0926 14:56:54.941027  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.649604 (* 1 = 0.649604 loss)
I0926 14:56:54.941045  4911 sgd_solver.cpp:105] Iteration 1800, lr = 0.001
I0926 14:57:10.127632  4911 solver.cpp:218] Iteration 1900 (6.58478 iter/s, 15.1865s/100 iters), loss = 0.652353
I0926 14:57:10.127662  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.652353 (* 1 = 0.652353 loss)
I0926 14:57:10.127668  4911 sgd_solver.cpp:105] Iteration 1900, lr = 0.001
I0926 14:57:24.349969  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 14:57:24.979820  4911 solver.cpp:330] Iteration 2000, Testing net (#0)
I0926 14:57:28.420337  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 14:57:28.562270  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.559
I0926 14:57:28.562295  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.05511 (* 1 = 2.05511 loss)
I0926 14:57:28.707222  4911 solver.cpp:218] Iteration 2000 (5.38227 iter/s, 18.5795s/100 iters), loss = 0.529979
I0926 14:57:28.707252  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.529979 (* 1 = 0.529979 loss)
I0926 14:57:28.707259  4911 sgd_solver.cpp:105] Iteration 2000, lr = 0.001
I0926 14:57:43.457778  4911 solver.cpp:218] Iteration 2100 (6.77944 iter/s, 14.7505s/100 iters), loss = 0.466378
I0926 14:57:43.457813  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.466378 (* 1 = 0.466378 loss)
I0926 14:57:43.457818  4911 sgd_solver.cpp:105] Iteration 2100, lr = 0.001
I0926 14:57:58.403816  4911 solver.cpp:218] Iteration 2200 (6.69077 iter/s, 14.946s/100 iters), loss = 0.648456
I0926 14:57:58.403956  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.648456 (* 1 = 0.648456 loss)
I0926 14:57:58.403965  4911 sgd_solver.cpp:105] Iteration 2200, lr = 0.001
I0926 14:58:13.192764  4911 solver.cpp:218] Iteration 2300 (6.76189 iter/s, 14.7888s/100 iters), loss = 0.684424
I0926 14:58:13.192798  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.684424 (* 1 = 0.684424 loss)
I0926 14:58:13.192806  4911 sgd_solver.cpp:105] Iteration 2300, lr = 0.001
I0926 14:58:27.968163  4911 solver.cpp:218] Iteration 2400 (6.76804 iter/s, 14.7753s/100 iters), loss = 0.486173
I0926 14:58:27.968196  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.486173 (* 1 = 0.486173 loss)
I0926 14:58:27.968204  4911 sgd_solver.cpp:105] Iteration 2400, lr = 0.001
I0926 14:58:41.944766  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 14:58:42.548197  4911 solver.cpp:330] Iteration 2500, Testing net (#0)
I0926 14:58:45.982928  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 14:58:46.126045  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7028
I0926 14:58:46.126080  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.0171 (* 1 = 1.0171 loss)
I0926 14:58:46.270870  4911 solver.cpp:218] Iteration 2500 (5.4637 iter/s, 18.3026s/100 iters), loss = 0.491827
I0926 14:58:46.270903  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.491827 (* 1 = 0.491827 loss)
I0926 14:58:46.270910  4911 sgd_solver.cpp:105] Iteration 2500, lr = 0.001
I0926 14:59:00.891592  4911 solver.cpp:218] Iteration 2600 (6.83964 iter/s, 14.6206s/100 iters), loss = 0.501629
I0926 14:59:00.891633  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.501629 (* 1 = 0.501629 loss)
I0926 14:59:00.891638  4911 sgd_solver.cpp:105] Iteration 2600, lr = 0.001
I0926 14:59:15.490792  4911 solver.cpp:218] Iteration 2700 (6.84973 iter/s, 14.5991s/100 iters), loss = 0.6228
I0926 14:59:15.490917  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.6228 (* 1 = 0.6228 loss)
I0926 14:59:15.490926  4911 sgd_solver.cpp:105] Iteration 2700, lr = 0.001
I0926 14:59:30.122056  4911 solver.cpp:218] Iteration 2800 (6.83476 iter/s, 14.6311s/100 iters), loss = 0.706324
I0926 14:59:30.122090  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.706324 (* 1 = 0.706324 loss)
I0926 14:59:30.122098  4911 sgd_solver.cpp:105] Iteration 2800, lr = 0.001
I0926 14:59:44.878965  4911 solver.cpp:218] Iteration 2900 (6.77652 iter/s, 14.7568s/100 iters), loss = 0.504677
I0926 14:59:44.878995  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.504677 (* 1 = 0.504677 loss)
I0926 14:59:44.879003  4911 sgd_solver.cpp:105] Iteration 2900, lr = 0.001
I0926 14:59:58.783771  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 14:59:59.367522  4911 solver.cpp:330] Iteration 3000, Testing net (#0)
I0926 15:00:02.786922  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:00:02.930162  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7473
I0926 15:00:02.930198  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.780791 (* 1 = 0.780791 loss)
I0926 15:00:03.075009  4911 solver.cpp:218] Iteration 3000 (5.49572 iter/s, 18.196s/100 iters), loss = 0.453774
I0926 15:00:03.075043  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.453774 (* 1 = 0.453774 loss)
I0926 15:00:03.075050  4911 sgd_solver.cpp:105] Iteration 3000, lr = 0.001
I0926 15:00:17.712913  4911 solver.cpp:218] Iteration 3100 (6.83161 iter/s, 14.6378s/100 iters), loss = 0.47655
I0926 15:00:17.712945  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.47655 (* 1 = 0.47655 loss)
I0926 15:00:17.712951  4911 sgd_solver.cpp:105] Iteration 3100, lr = 0.001
I0926 15:00:32.345062  4911 solver.cpp:218] Iteration 3200 (6.8343 iter/s, 14.6321s/100 iters), loss = 0.51227
I0926 15:00:32.345166  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.51227 (* 1 = 0.51227 loss)
I0926 15:00:32.345183  4911 sgd_solver.cpp:105] Iteration 3200, lr = 0.001
I0926 15:00:46.992923  4911 solver.cpp:218] Iteration 3300 (6.827 iter/s, 14.6477s/100 iters), loss = 0.621146
I0926 15:00:46.992954  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.621146 (* 1 = 0.621146 loss)
I0926 15:00:46.992959  4911 sgd_solver.cpp:105] Iteration 3300, lr = 0.001
I0926 15:01:01.634131  4911 solver.cpp:218] Iteration 3400 (6.83007 iter/s, 14.6411s/100 iters), loss = 0.49705
I0926 15:01:01.634172  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.49705 (* 1 = 0.49705 loss)
I0926 15:01:01.634178  4911 sgd_solver.cpp:105] Iteration 3400, lr = 0.001
I0926 15:01:15.626134  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:01:16.219585  4911 solver.cpp:330] Iteration 3500, Testing net (#0)
I0926 15:01:19.756039  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:01:19.900281  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7701
I0926 15:01:19.900307  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.672271 (* 1 = 0.672271 loss)
I0926 15:01:20.046371  4911 solver.cpp:218] Iteration 3500 (5.4312 iter/s, 18.4121s/100 iters), loss = 0.440975
I0926 15:01:20.046406  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.440975 (* 1 = 0.440975 loss)
I0926 15:01:20.046429  4911 sgd_solver.cpp:105] Iteration 3500, lr = 0.001
I0926 15:01:34.728495  4911 solver.cpp:218] Iteration 3600 (6.81104 iter/s, 14.682s/100 iters), loss = 0.371168
I0926 15:01:34.728528  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371168 (* 1 = 0.371168 loss)
I0926 15:01:34.728534  4911 sgd_solver.cpp:105] Iteration 3600, lr = 0.001
I0926 15:01:49.377396  4911 solver.cpp:218] Iteration 3700 (6.82648 iter/s, 14.6488s/100 iters), loss = 0.491294
I0926 15:01:49.377485  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.491294 (* 1 = 0.491294 loss)
I0926 15:01:49.377502  4911 sgd_solver.cpp:105] Iteration 3700, lr = 0.001
I0926 15:02:04.046694  4911 solver.cpp:218] Iteration 3800 (6.81701 iter/s, 14.6692s/100 iters), loss = 0.625938
I0926 15:02:04.046727  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.625938 (* 1 = 0.625938 loss)
I0926 15:02:04.046733  4911 sgd_solver.cpp:105] Iteration 3800, lr = 0.001
I0926 15:02:18.710115  4911 solver.cpp:218] Iteration 3900 (6.81973 iter/s, 14.6633s/100 iters), loss = 0.395558
I0926 15:02:18.710146  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.395558 (* 1 = 0.395558 loss)
I0926 15:02:18.710153  4911 sgd_solver.cpp:105] Iteration 3900, lr = 0.001
I0926 15:02:32.583787  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:02:33.168097  4911 solver.cpp:330] Iteration 4000, Testing net (#0)
I0926 15:02:36.584548  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:02:36.726555  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7941
I0926 15:02:36.726591  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.595362 (* 1 = 0.595362 loss)
I0926 15:02:36.871151  4911 solver.cpp:218] Iteration 4000 (5.50632 iter/s, 18.161s/100 iters), loss = 0.40306
I0926 15:02:36.871181  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.40306 (* 1 = 0.40306 loss)
I0926 15:02:36.871188  4911 sgd_solver.cpp:105] Iteration 4000, lr = 0.001
I0926 15:02:51.491535  4911 solver.cpp:218] Iteration 4100 (6.8398 iter/s, 14.6203s/100 iters), loss = 0.447324
I0926 15:02:51.491577  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.447324 (* 1 = 0.447324 loss)
I0926 15:02:51.491583  4911 sgd_solver.cpp:105] Iteration 4100, lr = 0.001
I0926 15:03:06.103055  4911 solver.cpp:218] Iteration 4200 (6.84395 iter/s, 14.6114s/100 iters), loss = 0.507965
I0926 15:03:06.103173  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.507965 (* 1 = 0.507965 loss)
I0926 15:03:06.103183  4911 sgd_solver.cpp:105] Iteration 4200, lr = 0.001
I0926 15:03:20.813571  4911 solver.cpp:218] Iteration 4300 (6.79793 iter/s, 14.7104s/100 iters), loss = 0.59357
I0926 15:03:20.813603  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.59357 (* 1 = 0.59357 loss)
I0926 15:03:20.813611  4911 sgd_solver.cpp:105] Iteration 4300, lr = 0.001
I0926 15:03:35.491304  4911 solver.cpp:218] Iteration 4400 (6.81308 iter/s, 14.6777s/100 iters), loss = 0.440389
I0926 15:03:35.491336  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.440389 (* 1 = 0.440389 loss)
I0926 15:03:35.491343  4911 sgd_solver.cpp:105] Iteration 4400, lr = 0.001
I0926 15:03:49.416622  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:03:50.002534  4911 solver.cpp:330] Iteration 4500, Testing net (#0)
I0926 15:03:53.421201  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:03:53.563896  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.789
I0926 15:03:53.563920  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.609935 (* 1 = 0.609935 loss)
I0926 15:03:53.709208  4911 solver.cpp:218] Iteration 4500 (5.48913 iter/s, 18.2178s/100 iters), loss = 0.545396
I0926 15:03:53.709237  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.545396 (* 1 = 0.545396 loss)
I0926 15:03:53.709244  4911 sgd_solver.cpp:105] Iteration 4500, lr = 0.001
I0926 15:04:08.463634  4911 solver.cpp:218] Iteration 4600 (6.77766 iter/s, 14.7544s/100 iters), loss = 0.446512
I0926 15:04:08.463666  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.446512 (* 1 = 0.446512 loss)
I0926 15:04:08.463672  4911 sgd_solver.cpp:105] Iteration 4600, lr = 0.001
I0926 15:04:23.130139  4911 solver.cpp:218] Iteration 4700 (6.81829 iter/s, 14.6664s/100 iters), loss = 0.518505
I0926 15:04:23.130250  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.518505 (* 1 = 0.518505 loss)
I0926 15:04:23.130269  4911 sgd_solver.cpp:105] Iteration 4700, lr = 0.001
I0926 15:04:37.781095  4911 solver.cpp:218] Iteration 4800 (6.82556 iter/s, 14.6508s/100 iters), loss = 0.564345
I0926 15:04:37.781131  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.564345 (* 1 = 0.564345 loss)
I0926 15:04:37.781138  4911 sgd_solver.cpp:105] Iteration 4800, lr = 0.001
I0926 15:04:52.435312  4911 solver.cpp:218] Iteration 4900 (6.82401 iter/s, 14.6541s/100 iters), loss = 0.425119
I0926 15:04:52.435353  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.425119 (* 1 = 0.425119 loss)
I0926 15:04:52.435360  4911 sgd_solver.cpp:105] Iteration 4900, lr = 0.001
I0926 15:05:06.371114  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:05:06.956929  4911 solver.cpp:330] Iteration 5000, Testing net (#0)
I0926 15:05:10.376231  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:05:10.519207  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8092
I0926 15:05:10.519232  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.556945 (* 1 = 0.556945 loss)
I0926 15:05:10.664314  4911 solver.cpp:218] Iteration 5000 (5.48579 iter/s, 18.2289s/100 iters), loss = 0.353442
I0926 15:05:10.664345  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.353442 (* 1 = 0.353442 loss)
I0926 15:05:10.664351  4911 sgd_solver.cpp:105] Iteration 5000, lr = 0.001
I0926 15:05:25.307338  4911 solver.cpp:218] Iteration 5100 (6.82922 iter/s, 14.643s/100 iters), loss = 0.394572
I0926 15:05:25.307377  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.394572 (* 1 = 0.394572 loss)
I0926 15:05:25.307384  4911 sgd_solver.cpp:105] Iteration 5100, lr = 0.001
I0926 15:05:39.937831  4911 solver.cpp:218] Iteration 5200 (6.83508 iter/s, 14.6304s/100 iters), loss = 0.502541
I0926 15:05:39.937968  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.502541 (* 1 = 0.502541 loss)
I0926 15:05:39.937976  4911 sgd_solver.cpp:105] Iteration 5200, lr = 0.001
I0926 15:05:54.561213  4911 solver.cpp:218] Iteration 5300 (6.83844 iter/s, 14.6232s/100 iters), loss = 0.54161
I0926 15:05:54.561244  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.54161 (* 1 = 0.54161 loss)
I0926 15:05:54.561249  4911 sgd_solver.cpp:105] Iteration 5300, lr = 0.001
I0926 15:06:09.180840  4911 solver.cpp:218] Iteration 5400 (6.84015 iter/s, 14.6196s/100 iters), loss = 0.42299
I0926 15:06:09.180874  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.42299 (* 1 = 0.42299 loss)
I0926 15:06:09.180881  4911 sgd_solver.cpp:105] Iteration 5400, lr = 0.001
I0926 15:06:23.084755  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:06:23.671237  4911 solver.cpp:330] Iteration 5500, Testing net (#0)
I0926 15:06:27.088925  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:06:27.231158  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8132
I0926 15:06:27.231192  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.545414 (* 1 = 0.545414 loss)
I0926 15:06:27.376299  4911 solver.cpp:218] Iteration 5500 (5.4959 iter/s, 18.1954s/100 iters), loss = 0.337839
I0926 15:06:27.376329  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337839 (* 1 = 0.337839 loss)
I0926 15:06:27.376336  4911 sgd_solver.cpp:105] Iteration 5500, lr = 0.001
I0926 15:06:42.034778  4911 solver.cpp:218] Iteration 5600 (6.82202 iter/s, 14.6584s/100 iters), loss = 0.378942
I0926 15:06:42.034814  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378942 (* 1 = 0.378942 loss)
I0926 15:06:42.034822  4911 sgd_solver.cpp:105] Iteration 5600, lr = 0.001
I0926 15:06:56.655035  4911 solver.cpp:218] Iteration 5700 (6.83986 iter/s, 14.6202s/100 iters), loss = 0.506555
I0926 15:06:56.655150  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.506555 (* 1 = 0.506555 loss)
I0926 15:06:56.655158  4911 sgd_solver.cpp:105] Iteration 5700, lr = 0.001
I0926 15:07:11.307107  4911 solver.cpp:218] Iteration 5800 (6.82504 iter/s, 14.6519s/100 iters), loss = 0.478463
I0926 15:07:11.307137  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.478463 (* 1 = 0.478463 loss)
I0926 15:07:11.307143  4911 sgd_solver.cpp:105] Iteration 5800, lr = 0.001
I0926 15:07:25.948834  4911 solver.cpp:218] Iteration 5900 (6.82983 iter/s, 14.6417s/100 iters), loss = 0.377509
I0926 15:07:25.948864  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.377509 (* 1 = 0.377509 loss)
I0926 15:07:25.948870  4911 sgd_solver.cpp:105] Iteration 5900, lr = 0.001
I0926 15:07:39.856822  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:07:40.441406  4911 solver.cpp:330] Iteration 6000, Testing net (#0)
I0926 15:07:43.863011  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:07:44.005544  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8232
I0926 15:07:44.005581  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.518773 (* 1 = 0.518773 loss)
I0926 15:07:44.150446  4911 solver.cpp:218] Iteration 6000 (5.49404 iter/s, 18.2015s/100 iters), loss = 0.356509
I0926 15:07:44.150478  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.356509 (* 1 = 0.356509 loss)
I0926 15:07:44.150485  4911 sgd_solver.cpp:105] Iteration 6000, lr = 0.001
I0926 15:07:58.781800  4911 solver.cpp:218] Iteration 6100 (6.83467 iter/s, 14.6313s/100 iters), loss = 0.360304
I0926 15:07:58.781841  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.360304 (* 1 = 0.360304 loss)
I0926 15:07:58.781847  4911 sgd_solver.cpp:105] Iteration 6100, lr = 0.001
I0926 15:08:13.426579  4911 solver.cpp:218] Iteration 6200 (6.82841 iter/s, 14.6447s/100 iters), loss = 0.464142
I0926 15:08:13.426708  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.464142 (* 1 = 0.464142 loss)
I0926 15:08:13.426717  4911 sgd_solver.cpp:105] Iteration 6200, lr = 0.001
I0926 15:08:28.068352  4911 solver.cpp:218] Iteration 6300 (6.82985 iter/s, 14.6416s/100 iters), loss = 0.458294
I0926 15:08:28.068387  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.458294 (* 1 = 0.458294 loss)
I0926 15:08:28.068394  4911 sgd_solver.cpp:105] Iteration 6300, lr = 0.001
I0926 15:08:42.701539  4911 solver.cpp:218] Iteration 6400 (6.83382 iter/s, 14.6331s/100 iters), loss = 0.408287
I0926 15:08:42.701580  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.408287 (* 1 = 0.408287 loss)
I0926 15:08:42.701586  4911 sgd_solver.cpp:105] Iteration 6400, lr = 0.001
I0926 15:08:56.605448  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:08:57.189496  4911 solver.cpp:330] Iteration 6500, Testing net (#0)
I0926 15:09:00.609167  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:09:00.752513  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8234
I0926 15:09:00.752549  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.52336 (* 1 = 0.52336 loss)
I0926 15:09:00.897435  4911 solver.cpp:218] Iteration 6500 (5.49577 iter/s, 18.1958s/100 iters), loss = 0.348498
I0926 15:09:00.897467  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.348498 (* 1 = 0.348498 loss)
I0926 15:09:00.897475  4911 sgd_solver.cpp:105] Iteration 6500, lr = 0.001
I0926 15:09:15.546926  4911 solver.cpp:218] Iteration 6600 (6.82621 iter/s, 14.6494s/100 iters), loss = 0.355315
I0926 15:09:15.546959  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355315 (* 1 = 0.355315 loss)
I0926 15:09:15.546967  4911 sgd_solver.cpp:105] Iteration 6600, lr = 0.001
I0926 15:09:30.177744  4911 solver.cpp:218] Iteration 6700 (6.83492 iter/s, 14.6307s/100 iters), loss = 0.402843
I0926 15:09:30.177858  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.402843 (* 1 = 0.402843 loss)
I0926 15:09:30.177867  4911 sgd_solver.cpp:105] Iteration 6700, lr = 0.001
I0926 15:09:44.816509  4911 solver.cpp:218] Iteration 6800 (6.83124 iter/s, 14.6386s/100 iters), loss = 0.51491
I0926 15:09:44.816540  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.51491 (* 1 = 0.51491 loss)
I0926 15:09:44.816546  4911 sgd_solver.cpp:105] Iteration 6800, lr = 0.001
I0926 15:09:59.468282  4911 solver.cpp:218] Iteration 6900 (6.82515 iter/s, 14.6517s/100 iters), loss = 0.413986
I0926 15:09:59.468315  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.413986 (* 1 = 0.413986 loss)
I0926 15:09:59.468322  4911 sgd_solver.cpp:105] Iteration 6900, lr = 0.001
I0926 15:10:13.387154  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:10:13.973278  4911 solver.cpp:330] Iteration 7000, Testing net (#0)
I0926 15:10:17.393178  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:10:17.536231  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8226
I0926 15:10:17.536265  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.515224 (* 1 = 0.515224 loss)
I0926 15:10:17.681298  4911 solver.cpp:218] Iteration 7000 (5.4906 iter/s, 18.2129s/100 iters), loss = 0.358916
I0926 15:10:17.681327  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.358916 (* 1 = 0.358916 loss)
I0926 15:10:17.681334  4911 sgd_solver.cpp:105] Iteration 7000, lr = 0.001
I0926 15:10:32.317417  4911 solver.cpp:218] Iteration 7100 (6.83244 iter/s, 14.6361s/100 iters), loss = 0.30162
I0926 15:10:32.317446  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30162 (* 1 = 0.30162 loss)
I0926 15:10:32.317453  4911 sgd_solver.cpp:105] Iteration 7100, lr = 0.001
I0926 15:10:46.967293  4911 solver.cpp:218] Iteration 7200 (6.82603 iter/s, 14.6498s/100 iters), loss = 0.403739
I0926 15:10:46.967402  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.403739 (* 1 = 0.403739 loss)
I0926 15:10:46.967411  4911 sgd_solver.cpp:105] Iteration 7200, lr = 0.001
I0926 15:11:01.608157  4911 solver.cpp:218] Iteration 7300 (6.83027 iter/s, 14.6407s/100 iters), loss = 0.436916
I0926 15:11:01.608192  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.436916 (* 1 = 0.436916 loss)
I0926 15:11:01.608211  4911 sgd_solver.cpp:105] Iteration 7300, lr = 0.001
I0926 15:11:16.265013  4911 solver.cpp:218] Iteration 7400 (6.82287 iter/s, 14.6566s/100 iters), loss = 0.381661
I0926 15:11:16.265044  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.381661 (* 1 = 0.381661 loss)
I0926 15:11:16.265050  4911 sgd_solver.cpp:105] Iteration 7400, lr = 0.001
I0926 15:11:30.190070  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:11:30.773281  4911 solver.cpp:330] Iteration 7500, Testing net (#0)
I0926 15:11:34.199080  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:11:34.340864  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8363
I0926 15:11:34.340899  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.479958 (* 1 = 0.479958 loss)
I0926 15:11:34.483702  4911 solver.cpp:218] Iteration 7500 (5.48889 iter/s, 18.2186s/100 iters), loss = 0.362516
I0926 15:11:34.483733  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362516 (* 1 = 0.362516 loss)
I0926 15:11:34.483741  4911 sgd_solver.cpp:105] Iteration 7500, lr = 0.001
I0926 15:11:49.128027  4911 solver.cpp:218] Iteration 7600 (6.82862 iter/s, 14.6443s/100 iters), loss = 0.350831
I0926 15:11:49.128068  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350831 (* 1 = 0.350831 loss)
I0926 15:11:49.128075  4911 sgd_solver.cpp:105] Iteration 7600, lr = 0.001
I0926 15:12:03.740466  4911 solver.cpp:218] Iteration 7700 (6.84352 iter/s, 14.6124s/100 iters), loss = 0.33612
I0926 15:12:03.740586  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.33612 (* 1 = 0.33612 loss)
I0926 15:12:03.740593  4911 sgd_solver.cpp:105] Iteration 7700, lr = 0.001
I0926 15:12:18.349135  4911 solver.cpp:218] Iteration 7800 (6.84532 iter/s, 14.6085s/100 iters), loss = 0.430424
I0926 15:12:18.349175  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.430424 (* 1 = 0.430424 loss)
I0926 15:12:18.349181  4911 sgd_solver.cpp:105] Iteration 7800, lr = 0.001
I0926 15:12:32.977663  4911 solver.cpp:218] Iteration 7900 (6.83599 iter/s, 14.6284s/100 iters), loss = 0.468751
I0926 15:12:32.977699  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.468751 (* 1 = 0.468751 loss)
I0926 15:12:32.977705  4911 sgd_solver.cpp:105] Iteration 7900, lr = 0.001
I0926 15:12:46.893724  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:12:47.480916  4911 solver.cpp:330] Iteration 8000, Testing net (#0)
I0926 15:12:50.891019  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:12:51.032871  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8421
I0926 15:12:51.032907  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.461803 (* 1 = 0.461803 loss)
I0926 15:12:51.177742  4911 solver.cpp:218] Iteration 8000 (5.4945 iter/s, 18.2s/100 iters), loss = 0.30612
I0926 15:12:51.177772  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30612 (* 1 = 0.30612 loss)
I0926 15:12:51.177779  4911 sgd_solver.cpp:105] Iteration 8000, lr = 0.001
I0926 15:13:05.832259  4911 solver.cpp:218] Iteration 8100 (6.82387 iter/s, 14.6544s/100 iters), loss = 0.316601
I0926 15:13:05.832291  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316601 (* 1 = 0.316601 loss)
I0926 15:13:05.832298  4911 sgd_solver.cpp:105] Iteration 8100, lr = 0.001
I0926 15:13:20.479205  4911 solver.cpp:218] Iteration 8200 (6.82739 iter/s, 14.6469s/100 iters), loss = 0.366766
I0926 15:13:20.479310  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366766 (* 1 = 0.366766 loss)
I0926 15:13:20.479316  4911 sgd_solver.cpp:105] Iteration 8200, lr = 0.001
I0926 15:13:35.124496  4911 solver.cpp:218] Iteration 8300 (6.8282 iter/s, 14.6451s/100 iters), loss = 0.405041
I0926 15:13:35.124531  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405041 (* 1 = 0.405041 loss)
I0926 15:13:35.124537  4911 sgd_solver.cpp:105] Iteration 8300, lr = 0.001
I0926 15:13:49.768110  4911 solver.cpp:218] Iteration 8400 (6.82895 iter/s, 14.6435s/100 iters), loss = 0.248563
I0926 15:13:49.768142  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248563 (* 1 = 0.248563 loss)
I0926 15:13:49.768149  4911 sgd_solver.cpp:105] Iteration 8400, lr = 0.001
I0926 15:14:03.694371  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:14:04.279597  4911 solver.cpp:330] Iteration 8500, Testing net (#0)
I0926 15:14:07.702824  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:14:07.844321  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8426
I0926 15:14:07.844346  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.459274 (* 1 = 0.459274 loss)
I0926 15:14:07.989521  4911 solver.cpp:218] Iteration 8500 (5.48811 iter/s, 18.2212s/100 iters), loss = 0.30805
I0926 15:14:07.989558  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30805 (* 1 = 0.30805 loss)
I0926 15:14:07.989567  4911 sgd_solver.cpp:105] Iteration 8500, lr = 0.001
I0926 15:14:22.618000  4911 solver.cpp:218] Iteration 8600 (6.83602 iter/s, 14.6284s/100 iters), loss = 0.2994
I0926 15:14:22.618039  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2994 (* 1 = 0.2994 loss)
I0926 15:14:22.618046  4911 sgd_solver.cpp:105] Iteration 8600, lr = 0.001
I0926 15:14:37.259578  4911 solver.cpp:218] Iteration 8700 (6.8299 iter/s, 14.6415s/100 iters), loss = 0.444005
I0926 15:14:37.259757  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.444005 (* 1 = 0.444005 loss)
I0926 15:14:37.259774  4911 sgd_solver.cpp:105] Iteration 8700, lr = 0.001
I0926 15:14:51.894589  4911 solver.cpp:218] Iteration 8800 (6.83303 iter/s, 14.6348s/100 iters), loss = 0.40436
I0926 15:14:51.894619  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.40436 (* 1 = 0.40436 loss)
I0926 15:14:51.894626  4911 sgd_solver.cpp:105] Iteration 8800, lr = 0.001
I0926 15:15:06.541478  4911 solver.cpp:218] Iteration 8900 (6.82742 iter/s, 14.6468s/100 iters), loss = 0.331067
I0926 15:15:06.541510  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331067 (* 1 = 0.331067 loss)
I0926 15:15:06.541517  4911 sgd_solver.cpp:105] Iteration 8900, lr = 0.001
I0926 15:15:20.442551  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:15:21.027616  4911 solver.cpp:330] Iteration 9000, Testing net (#0)
I0926 15:15:24.444806  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:15:24.588573  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8469
I0926 15:15:24.588609  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.453209 (* 1 = 0.453209 loss)
I0926 15:15:24.734180  4911 solver.cpp:218] Iteration 9000 (5.49673 iter/s, 18.1926s/100 iters), loss = 0.327386
I0926 15:15:24.734213  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327386 (* 1 = 0.327386 loss)
I0926 15:15:24.734220  4911 sgd_solver.cpp:105] Iteration 9000, lr = 0.001
I0926 15:15:39.390990  4911 solver.cpp:218] Iteration 9100 (6.8228 iter/s, 14.6567s/100 iters), loss = 0.283166
I0926 15:15:39.391042  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283166 (* 1 = 0.283166 loss)
I0926 15:15:39.391052  4911 sgd_solver.cpp:105] Iteration 9100, lr = 0.001
I0926 15:15:54.026011  4911 solver.cpp:218] Iteration 9200 (6.83297 iter/s, 14.6349s/100 iters), loss = 0.376292
I0926 15:15:54.026121  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.376292 (* 1 = 0.376292 loss)
I0926 15:15:54.026130  4911 sgd_solver.cpp:105] Iteration 9200, lr = 0.001
I0926 15:16:08.688918  4911 solver.cpp:218] Iteration 9300 (6.81999 iter/s, 14.6628s/100 iters), loss = 0.443972
I0926 15:16:08.688951  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.443972 (* 1 = 0.443972 loss)
I0926 15:16:08.688956  4911 sgd_solver.cpp:105] Iteration 9300, lr = 0.001
I0926 15:16:23.334977  4911 solver.cpp:218] Iteration 9400 (6.82781 iter/s, 14.646s/100 iters), loss = 0.316147
I0926 15:16:23.335017  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316147 (* 1 = 0.316147 loss)
I0926 15:16:23.335023  4911 sgd_solver.cpp:105] Iteration 9400, lr = 0.001
I0926 15:16:37.268342  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:16:37.853217  4911 solver.cpp:330] Iteration 9500, Testing net (#0)
I0926 15:16:41.272298  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:16:41.414361  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.841
I0926 15:16:41.414397  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.454906 (* 1 = 0.454906 loss)
I0926 15:16:41.558861  4911 solver.cpp:218] Iteration 9500 (5.48733 iter/s, 18.2238s/100 iters), loss = 0.289129
I0926 15:16:41.558890  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289129 (* 1 = 0.289129 loss)
I0926 15:16:41.558897  4911 sgd_solver.cpp:105] Iteration 9500, lr = 0.001
I0926 15:16:56.219640  4911 solver.cpp:218] Iteration 9600 (6.82095 iter/s, 14.6607s/100 iters), loss = 0.325322
I0926 15:16:56.219673  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325322 (* 1 = 0.325322 loss)
I0926 15:16:56.219681  4911 sgd_solver.cpp:105] Iteration 9600, lr = 0.001
I0926 15:17:10.891084  4911 solver.cpp:218] Iteration 9700 (6.81599 iter/s, 14.6714s/100 iters), loss = 0.332986
I0926 15:17:10.891192  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.332986 (* 1 = 0.332986 loss)
I0926 15:17:10.891199  4911 sgd_solver.cpp:105] Iteration 9700, lr = 0.001
I0926 15:17:25.543298  4911 solver.cpp:218] Iteration 9800 (6.82497 iter/s, 14.6521s/100 iters), loss = 0.377993
I0926 15:17:25.543328  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.377993 (* 1 = 0.377993 loss)
I0926 15:17:25.543334  4911 sgd_solver.cpp:105] Iteration 9800, lr = 0.001
I0926 15:17:40.196683  4911 solver.cpp:218] Iteration 9900 (6.82439 iter/s, 14.6533s/100 iters), loss = 0.307481
I0926 15:17:40.196724  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307481 (* 1 = 0.307481 loss)
I0926 15:17:40.196732  4911 sgd_solver.cpp:105] Iteration 9900, lr = 0.001
I0926 15:17:54.129405  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:17:54.715509  4911 solver.cpp:330] Iteration 10000, Testing net (#0)
I0926 15:17:58.148324  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:17:58.291625  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8438
I0926 15:17:58.291661  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.454827 (* 1 = 0.454827 loss)
I0926 15:17:58.436309  4911 solver.cpp:218] Iteration 10000 (5.48259 iter/s, 18.2395s/100 iters), loss = 0.250884
I0926 15:17:58.436336  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250884 (* 1 = 0.250884 loss)
I0926 15:17:58.436342  4911 sgd_solver.cpp:46] MultiStep Status: Iteration 10000, step = 1
I0926 15:17:58.436344  4911 sgd_solver.cpp:105] Iteration 10000, lr = 0.0001
I0926 15:18:13.092311  4911 solver.cpp:218] Iteration 10100 (6.82317 iter/s, 14.6559s/100 iters), loss = 0.317823
I0926 15:18:13.092345  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317823 (* 1 = 0.317823 loss)
I0926 15:18:13.092352  4911 sgd_solver.cpp:105] Iteration 10100, lr = 0.0001
I0926 15:18:27.753469  4911 solver.cpp:218] Iteration 10200 (6.82078 iter/s, 14.6611s/100 iters), loss = 0.300534
I0926 15:18:27.753585  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300534 (* 1 = 0.300534 loss)
I0926 15:18:27.753593  4911 sgd_solver.cpp:105] Iteration 10200, lr = 0.0001
I0926 15:18:42.407686  4911 solver.cpp:218] Iteration 10300 (6.82405 iter/s, 14.6541s/100 iters), loss = 0.368535
I0926 15:18:42.407719  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.368535 (* 1 = 0.368535 loss)
I0926 15:18:42.407727  4911 sgd_solver.cpp:105] Iteration 10300, lr = 0.0001
I0926 15:18:57.045212  4911 solver.cpp:218] Iteration 10400 (6.83179 iter/s, 14.6375s/100 iters), loss = 0.286303
I0926 15:18:57.045244  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286302 (* 1 = 0.286302 loss)
I0926 15:18:57.045250  4911 sgd_solver.cpp:105] Iteration 10400, lr = 0.0001
I0926 15:19:10.976557  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:19:11.564244  4911 solver.cpp:330] Iteration 10500, Testing net (#0)
I0926 15:19:14.983795  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:19:15.128087  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8549
I0926 15:19:15.128113  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.427332 (* 1 = 0.427332 loss)
I0926 15:19:15.271651  4911 solver.cpp:218] Iteration 10500 (5.48656 iter/s, 18.2264s/100 iters), loss = 0.274973
I0926 15:19:15.271678  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274973 (* 1 = 0.274973 loss)
I0926 15:19:15.271685  4911 sgd_solver.cpp:105] Iteration 10500, lr = 0.0001
I0926 15:19:29.936738  4911 solver.cpp:218] Iteration 10600 (6.81895 iter/s, 14.665s/100 iters), loss = 0.277589
I0926 15:19:29.936769  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277589 (* 1 = 0.277589 loss)
I0926 15:19:29.936774  4911 sgd_solver.cpp:105] Iteration 10600, lr = 0.0001
I0926 15:19:44.609788  4911 solver.cpp:218] Iteration 10700 (6.81525 iter/s, 14.673s/100 iters), loss = 0.302923
I0926 15:19:44.609905  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302923 (* 1 = 0.302923 loss)
I0926 15:19:44.609922  4911 sgd_solver.cpp:105] Iteration 10700, lr = 0.0001
I0926 15:19:59.267011  4911 solver.cpp:218] Iteration 10800 (6.82264 iter/s, 14.6571s/100 iters), loss = 0.407832
I0926 15:19:59.267051  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.407831 (* 1 = 0.407831 loss)
I0926 15:19:59.267057  4911 sgd_solver.cpp:105] Iteration 10800, lr = 0.0001
I0926 15:20:13.906525  4911 solver.cpp:218] Iteration 10900 (6.83086 iter/s, 14.6394s/100 iters), loss = 0.280223
I0926 15:20:13.906559  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280223 (* 1 = 0.280223 loss)
I0926 15:20:13.906566  4911 sgd_solver.cpp:105] Iteration 10900, lr = 0.0001
I0926 15:20:27.878383  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:20:28.462713  4911 solver.cpp:330] Iteration 11000, Testing net (#0)
I0926 15:20:31.884101  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:20:32.026679  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.857
I0926 15:20:32.026705  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.420486 (* 1 = 0.420486 loss)
I0926 15:20:32.171979  4911 solver.cpp:218] Iteration 11000 (5.47484 iter/s, 18.2654s/100 iters), loss = 0.230514
I0926 15:20:32.172013  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230514 (* 1 = 0.230514 loss)
I0926 15:20:32.172019  4911 sgd_solver.cpp:105] Iteration 11000, lr = 0.0001
I0926 15:20:46.817611  4911 solver.cpp:218] Iteration 11100 (6.82801 iter/s, 14.6456s/100 iters), loss = 0.317274
I0926 15:20:46.817646  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317274 (* 1 = 0.317274 loss)
I0926 15:20:46.817652  4911 sgd_solver.cpp:105] Iteration 11100, lr = 0.0001
I0926 15:21:01.459424  4911 solver.cpp:218] Iteration 11200 (6.82979 iter/s, 14.6417s/100 iters), loss = 0.371197
I0926 15:21:01.459540  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371197 (* 1 = 0.371197 loss)
I0926 15:21:01.459549  4911 sgd_solver.cpp:105] Iteration 11200, lr = 0.0001
I0926 15:21:16.115370  4911 solver.cpp:218] Iteration 11300 (6.82324 iter/s, 14.6558s/100 iters), loss = 0.314514
I0926 15:21:16.115399  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314514 (* 1 = 0.314514 loss)
I0926 15:21:16.115406  4911 sgd_solver.cpp:105] Iteration 11300, lr = 0.0001
I0926 15:21:30.754091  4911 solver.cpp:218] Iteration 11400 (6.83123 iter/s, 14.6387s/100 iters), loss = 0.322102
I0926 15:21:30.754123  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322102 (* 1 = 0.322102 loss)
I0926 15:21:30.754130  4911 sgd_solver.cpp:105] Iteration 11400, lr = 0.0001
I0926 15:21:44.657687  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:21:45.242117  4911 solver.cpp:330] Iteration 11500, Testing net (#0)
I0926 15:21:48.694195  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:21:48.837227  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8575
I0926 15:21:48.837263  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.415428 (* 1 = 0.415428 loss)
I0926 15:21:48.980998  4911 solver.cpp:218] Iteration 11500 (5.48642 iter/s, 18.2268s/100 iters), loss = 0.234579
I0926 15:21:48.981040  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234579 (* 1 = 0.234579 loss)
I0926 15:21:48.981046  4911 sgd_solver.cpp:105] Iteration 11500, lr = 0.0001
I0926 15:22:03.612056  4911 solver.cpp:218] Iteration 11600 (6.83481 iter/s, 14.631s/100 iters), loss = 0.277567
I0926 15:22:03.612089  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277567 (* 1 = 0.277567 loss)
I0926 15:22:03.612097  4911 sgd_solver.cpp:105] Iteration 11600, lr = 0.0001
I0926 15:22:18.239224  4911 solver.cpp:218] Iteration 11700 (6.83663 iter/s, 14.6271s/100 iters), loss = 0.294329
I0926 15:22:18.239379  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294329 (* 1 = 0.294329 loss)
I0926 15:22:18.239387  4911 sgd_solver.cpp:105] Iteration 11700, lr = 0.0001
I0926 15:22:32.886435  4911 solver.cpp:218] Iteration 11800 (6.82733 iter/s, 14.647s/100 iters), loss = 0.343597
I0926 15:22:32.886466  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343597 (* 1 = 0.343597 loss)
I0926 15:22:32.886473  4911 sgd_solver.cpp:105] Iteration 11800, lr = 0.0001
I0926 15:22:47.530107  4911 solver.cpp:218] Iteration 11900 (6.82892 iter/s, 14.6436s/100 iters), loss = 0.332235
I0926 15:22:47.530138  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.332235 (* 1 = 0.332235 loss)
I0926 15:22:47.530144  4911 sgd_solver.cpp:105] Iteration 11900, lr = 0.0001
I0926 15:23:01.450585  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:23:02.038087  4911 solver.cpp:330] Iteration 12000, Testing net (#0)
I0926 15:23:05.455410  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:23:05.597436  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8587
I0926 15:23:05.597472  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.41314 (* 1 = 0.41314 loss)
I0926 15:23:05.742398  4911 solver.cpp:218] Iteration 12000 (5.49082 iter/s, 18.2122s/100 iters), loss = 0.269882
I0926 15:23:05.742426  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269882 (* 1 = 0.269882 loss)
I0926 15:23:05.742434  4911 sgd_solver.cpp:105] Iteration 12000, lr = 0.0001
I0926 15:23:20.394181  4911 solver.cpp:218] Iteration 12100 (6.82514 iter/s, 14.6517s/100 iters), loss = 0.303945
I0926 15:23:20.394222  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303944 (* 1 = 0.303944 loss)
I0926 15:23:20.394227  4911 sgd_solver.cpp:105] Iteration 12100, lr = 0.0001
I0926 15:23:35.056877  4911 solver.cpp:218] Iteration 12200 (6.82006 iter/s, 14.6626s/100 iters), loss = 0.299231
I0926 15:23:35.056996  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299231 (* 1 = 0.299231 loss)
I0926 15:23:35.057014  4911 sgd_solver.cpp:105] Iteration 12200, lr = 0.0001
I0926 15:23:49.695129  4911 solver.cpp:218] Iteration 12300 (6.83149 iter/s, 14.6381s/100 iters), loss = 0.395249
I0926 15:23:49.695170  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.395249 (* 1 = 0.395249 loss)
I0926 15:23:49.695176  4911 sgd_solver.cpp:105] Iteration 12300, lr = 0.0001
I0926 15:24:04.338316  4911 solver.cpp:218] Iteration 12400 (6.82915 iter/s, 14.6431s/100 iters), loss = 0.268011
I0926 15:24:04.338346  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268011 (* 1 = 0.268011 loss)
I0926 15:24:04.338352  4911 sgd_solver.cpp:105] Iteration 12400, lr = 0.0001
I0926 15:24:18.257968  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:24:18.842016  4911 solver.cpp:330] Iteration 12500, Testing net (#0)
I0926 15:24:22.258523  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:24:22.400900  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8585
I0926 15:24:22.400936  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.411566 (* 1 = 0.411566 loss)
I0926 15:24:22.544600  4911 solver.cpp:218] Iteration 12500 (5.49263 iter/s, 18.2062s/100 iters), loss = 0.27492
I0926 15:24:22.544631  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27492 (* 1 = 0.27492 loss)
I0926 15:24:22.544637  4911 sgd_solver.cpp:105] Iteration 12500, lr = 0.0001
I0926 15:24:37.194947  4911 solver.cpp:218] Iteration 12600 (6.82581 iter/s, 14.6503s/100 iters), loss = 0.25217
I0926 15:24:37.194979  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25217 (* 1 = 0.25217 loss)
I0926 15:24:37.194988  4911 sgd_solver.cpp:105] Iteration 12600, lr = 0.0001
I0926 15:24:51.860586  4911 solver.cpp:218] Iteration 12700 (6.81869 iter/s, 14.6656s/100 iters), loss = 0.292786
I0926 15:24:51.860703  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292786 (* 1 = 0.292786 loss)
I0926 15:24:51.860711  4911 sgd_solver.cpp:105] Iteration 12700, lr = 0.0001
I0926 15:25:06.514750  4911 solver.cpp:218] Iteration 12800 (6.82412 iter/s, 14.6539s/100 iters), loss = 0.365611
I0926 15:25:06.514781  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365611 (* 1 = 0.365611 loss)
I0926 15:25:06.514787  4911 sgd_solver.cpp:105] Iteration 12800, lr = 0.0001
I0926 15:25:21.172032  4911 solver.cpp:218] Iteration 12900 (6.82258 iter/s, 14.6572s/100 iters), loss = 0.317085
I0926 15:25:21.172065  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317085 (* 1 = 0.317085 loss)
I0926 15:25:21.172072  4911 sgd_solver.cpp:105] Iteration 12900, lr = 0.0001
I0926 15:25:35.094079  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:25:35.681044  4911 solver.cpp:330] Iteration 13000, Testing net (#0)
I0926 15:25:39.104454  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:25:39.246603  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8594
I0926 15:25:39.246629  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.410378 (* 1 = 0.410378 loss)
I0926 15:25:39.390835  4911 solver.cpp:218] Iteration 13000 (5.48886 iter/s, 18.2187s/100 iters), loss = 0.278205
I0926 15:25:39.390864  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278205 (* 1 = 0.278205 loss)
I0926 15:25:39.390872  4911 sgd_solver.cpp:105] Iteration 13000, lr = 0.0001
I0926 15:25:54.038724  4911 solver.cpp:218] Iteration 13100 (6.82695 iter/s, 14.6478s/100 iters), loss = 0.304501
I0926 15:25:54.038754  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304501 (* 1 = 0.304501 loss)
I0926 15:25:54.038761  4911 sgd_solver.cpp:105] Iteration 13100, lr = 0.0001
I0926 15:26:08.693449  4911 solver.cpp:218] Iteration 13200 (6.82377 iter/s, 14.6547s/100 iters), loss = 0.327774
I0926 15:26:08.693516  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327774 (* 1 = 0.327774 loss)
I0926 15:26:08.693524  4911 sgd_solver.cpp:105] Iteration 13200, lr = 0.0001
I0926 15:26:23.338546  4911 solver.cpp:218] Iteration 13300 (6.82827 iter/s, 14.645s/100 iters), loss = 0.35887
I0926 15:26:23.338577  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35887 (* 1 = 0.35887 loss)
I0926 15:26:23.338584  4911 sgd_solver.cpp:105] Iteration 13300, lr = 0.0001
I0926 15:26:37.977177  4911 solver.cpp:218] Iteration 13400 (6.83127 iter/s, 14.6386s/100 iters), loss = 0.328166
I0926 15:26:37.977210  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328166 (* 1 = 0.328166 loss)
I0926 15:26:37.977218  4911 sgd_solver.cpp:105] Iteration 13400, lr = 0.0001
I0926 15:26:51.893800  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:26:52.480623  4911 solver.cpp:330] Iteration 13500, Testing net (#0)
I0926 15:26:55.904673  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:26:56.046661  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8574
I0926 15:26:56.046697  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.411802 (* 1 = 0.411802 loss)
I0926 15:26:56.190142  4911 solver.cpp:218] Iteration 13500 (5.49062 iter/s, 18.2129s/100 iters), loss = 0.228985
I0926 15:26:56.190171  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228985 (* 1 = 0.228985 loss)
I0926 15:26:56.190178  4911 sgd_solver.cpp:105] Iteration 13500, lr = 0.0001
I0926 15:27:10.832453  4911 solver.cpp:218] Iteration 13600 (6.82955 iter/s, 14.6422s/100 iters), loss = 0.251249
I0926 15:27:10.832484  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251249 (* 1 = 0.251249 loss)
I0926 15:27:10.832501  4911 sgd_solver.cpp:105] Iteration 13600, lr = 0.0001
I0926 15:27:25.468184  4911 solver.cpp:218] Iteration 13700 (6.83262 iter/s, 14.6357s/100 iters), loss = 0.345277
I0926 15:27:25.468262  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.345277 (* 1 = 0.345277 loss)
I0926 15:27:25.468271  4911 sgd_solver.cpp:105] Iteration 13700, lr = 0.0001
I0926 15:27:40.113171  4911 solver.cpp:218] Iteration 13800 (6.82833 iter/s, 14.6449s/100 iters), loss = 0.331848
I0926 15:27:40.113205  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331848 (* 1 = 0.331848 loss)
I0926 15:27:40.113212  4911 sgd_solver.cpp:105] Iteration 13800, lr = 0.0001
I0926 15:27:54.753633  4911 solver.cpp:218] Iteration 13900 (6.83042 iter/s, 14.6404s/100 iters), loss = 0.374176
I0926 15:27:54.753664  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.374176 (* 1 = 0.374176 loss)
I0926 15:27:54.753670  4911 sgd_solver.cpp:105] Iteration 13900, lr = 0.0001
I0926 15:28:08.668269  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:28:09.253264  4911 solver.cpp:330] Iteration 14000, Testing net (#0)
I0926 15:28:12.682060  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:28:12.824177  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.861
I0926 15:28:12.824213  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.410037 (* 1 = 0.410037 loss)
I0926 15:28:12.968757  4911 solver.cpp:218] Iteration 14000 (5.48997 iter/s, 18.215s/100 iters), loss = 0.226754
I0926 15:28:12.968791  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226754 (* 1 = 0.226754 loss)
I0926 15:28:12.968799  4911 sgd_solver.cpp:105] Iteration 14000, lr = 0.0001
I0926 15:28:27.615434  4911 solver.cpp:218] Iteration 14100 (6.82752 iter/s, 14.6466s/100 iters), loss = 0.312648
I0926 15:28:27.615465  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312648 (* 1 = 0.312648 loss)
I0926 15:28:27.615471  4911 sgd_solver.cpp:105] Iteration 14100, lr = 0.0001
I0926 15:28:42.255290  4911 solver.cpp:218] Iteration 14200 (6.8307 iter/s, 14.6398s/100 iters), loss = 0.302836
I0926 15:28:42.255404  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302836 (* 1 = 0.302836 loss)
I0926 15:28:42.255427  4911 sgd_solver.cpp:105] Iteration 14200, lr = 0.0001
I0926 15:28:56.913491  4911 solver.cpp:218] Iteration 14300 (6.82219 iter/s, 14.6581s/100 iters), loss = 0.378231
I0926 15:28:56.913525  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378231 (* 1 = 0.378231 loss)
I0926 15:28:56.913533  4911 sgd_solver.cpp:105] Iteration 14300, lr = 0.0001
I0926 15:29:11.557759  4911 solver.cpp:218] Iteration 14400 (6.82864 iter/s, 14.6442s/100 iters), loss = 0.325018
I0926 15:29:11.557795  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325018 (* 1 = 0.325018 loss)
I0926 15:29:11.557802  4911 sgd_solver.cpp:105] Iteration 14400, lr = 0.0001
I0926 15:29:25.479918  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:29:26.064357  4911 solver.cpp:330] Iteration 14500, Testing net (#0)
I0926 15:29:29.495163  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:29:29.637748  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8611
I0926 15:29:29.637784  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.410191 (* 1 = 0.410191 loss)
I0926 15:29:29.783617  4911 solver.cpp:218] Iteration 14500 (5.48673 iter/s, 18.2258s/100 iters), loss = 0.24986
I0926 15:29:29.783650  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24986 (* 1 = 0.24986 loss)
I0926 15:29:29.783658  4911 sgd_solver.cpp:105] Iteration 14500, lr = 0.0001
I0926 15:29:44.445116  4911 solver.cpp:218] Iteration 14600 (6.82062 iter/s, 14.6614s/100 iters), loss = 0.25915
I0926 15:29:44.445147  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25915 (* 1 = 0.25915 loss)
I0926 15:29:44.445153  4911 sgd_solver.cpp:105] Iteration 14600, lr = 0.0001
I0926 15:29:59.078794  4911 solver.cpp:218] Iteration 14700 (6.83358 iter/s, 14.6336s/100 iters), loss = 0.355163
I0926 15:29:59.078925  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355163 (* 1 = 0.355163 loss)
I0926 15:29:59.078933  4911 sgd_solver.cpp:105] Iteration 14700, lr = 0.0001
I0926 15:30:13.727095  4911 solver.cpp:218] Iteration 14800 (6.8268 iter/s, 14.6481s/100 iters), loss = 0.323368
I0926 15:30:13.727138  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323368 (* 1 = 0.323368 loss)
I0926 15:30:13.727144  4911 sgd_solver.cpp:105] Iteration 14800, lr = 0.0001
I0926 15:30:28.379688  4911 solver.cpp:218] Iteration 14900 (6.82477 iter/s, 14.6525s/100 iters), loss = 0.328658
I0926 15:30:28.379719  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328658 (* 1 = 0.328658 loss)
I0926 15:30:28.379724  4911 sgd_solver.cpp:105] Iteration 14900, lr = 0.0001
I0926 15:30:42.269834  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:30:42.854642  4911 solver.cpp:330] Iteration 15000, Testing net (#0)
I0926 15:30:46.284757  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:30:46.427021  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8602
I0926 15:30:46.427057  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.409283 (* 1 = 0.409283 loss)
I0926 15:30:46.571425  4911 solver.cpp:218] Iteration 15000 (5.49702 iter/s, 18.1917s/100 iters), loss = 0.227044
I0926 15:30:46.571455  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227044 (* 1 = 0.227044 loss)
I0926 15:30:46.571460  4911 sgd_solver.cpp:105] Iteration 15000, lr = 0.0001
I0926 15:31:01.225541  4911 solver.cpp:218] Iteration 15100 (6.82405 iter/s, 14.6541s/100 iters), loss = 0.302831
I0926 15:31:01.225572  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302831 (* 1 = 0.302831 loss)
I0926 15:31:01.225579  4911 sgd_solver.cpp:105] Iteration 15100, lr = 0.0001
I0926 15:31:15.899334  4911 solver.cpp:218] Iteration 15200 (6.8149 iter/s, 14.6737s/100 iters), loss = 0.322536
I0926 15:31:15.899441  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322536 (* 1 = 0.322536 loss)
I0926 15:31:15.899448  4911 sgd_solver.cpp:105] Iteration 15200, lr = 0.0001
I0926 15:31:30.578757  4911 solver.cpp:218] Iteration 15300 (6.81232 iter/s, 14.6793s/100 iters), loss = 0.381322
I0926 15:31:30.578786  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.381322 (* 1 = 0.381322 loss)
I0926 15:31:30.578794  4911 sgd_solver.cpp:105] Iteration 15300, lr = 0.0001
I0926 15:31:45.252331  4911 solver.cpp:218] Iteration 15400 (6.815 iter/s, 14.6735s/100 iters), loss = 0.269388
I0926 15:31:45.252362  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269388 (* 1 = 0.269388 loss)
I0926 15:31:45.252367  4911 sgd_solver.cpp:105] Iteration 15400, lr = 0.0001
I0926 15:31:59.181356  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:31:59.765070  4911 solver.cpp:330] Iteration 15500, Testing net (#0)
I0926 15:32:03.199281  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:32:03.341684  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8583
I0926 15:32:03.341722  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.409127 (* 1 = 0.409127 loss)
I0926 15:32:03.485481  4911 solver.cpp:218] Iteration 15500 (5.48454 iter/s, 18.2331s/100 iters), loss = 0.235432
I0926 15:32:03.485517  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235432 (* 1 = 0.235432 loss)
I0926 15:32:03.485524  4911 sgd_solver.cpp:105] Iteration 15500, lr = 0.0001
I0926 15:32:18.170063  4911 solver.cpp:218] Iteration 15600 (6.8099 iter/s, 14.6845s/100 iters), loss = 0.2905
I0926 15:32:18.170094  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2905 (* 1 = 0.2905 loss)
I0926 15:32:18.170099  4911 sgd_solver.cpp:105] Iteration 15600, lr = 0.0001
I0926 15:32:32.809655  4911 solver.cpp:218] Iteration 15700 (6.83082 iter/s, 14.6395s/100 iters), loss = 0.393895
I0926 15:32:32.809768  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.393895 (* 1 = 0.393895 loss)
I0926 15:32:32.809787  4911 sgd_solver.cpp:105] Iteration 15700, lr = 0.0001
I0926 15:32:47.464834  4911 solver.cpp:218] Iteration 15800 (6.82359 iter/s, 14.655s/100 iters), loss = 0.314789
I0926 15:32:47.464875  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314789 (* 1 = 0.314789 loss)
I0926 15:32:47.464881  4911 sgd_solver.cpp:105] Iteration 15800, lr = 0.0001
I0926 15:33:02.122099  4911 solver.cpp:218] Iteration 15900 (6.82259 iter/s, 14.6572s/100 iters), loss = 0.269328
I0926 15:33:02.122139  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269328 (* 1 = 0.269328 loss)
I0926 15:33:02.122146  4911 sgd_solver.cpp:105] Iteration 15900, lr = 0.0001
I0926 15:33:16.065759  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:33:16.651593  4911 solver.cpp:330] Iteration 16000, Testing net (#0)
I0926 15:33:20.073298  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:33:20.215628  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8595
I0926 15:33:20.215653  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.407943 (* 1 = 0.407943 loss)
I0926 15:33:20.360389  4911 solver.cpp:218] Iteration 16000 (5.483 iter/s, 18.2382s/100 iters), loss = 0.229198
I0926 15:33:20.360419  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229198 (* 1 = 0.229198 loss)
I0926 15:33:20.360436  4911 sgd_solver.cpp:105] Iteration 16000, lr = 0.0001
I0926 15:33:34.995682  4911 solver.cpp:218] Iteration 16100 (6.83283 iter/s, 14.6352s/100 iters), loss = 0.288985
I0926 15:33:34.995717  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288985 (* 1 = 0.288985 loss)
I0926 15:33:34.995723  4911 sgd_solver.cpp:105] Iteration 16100, lr = 0.0001
I0926 15:33:49.630302  4911 solver.cpp:218] Iteration 16200 (6.83314 iter/s, 14.6346s/100 iters), loss = 0.297584
I0926 15:33:49.630414  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297584 (* 1 = 0.297584 loss)
I0926 15:33:49.630422  4911 sgd_solver.cpp:105] Iteration 16200, lr = 0.0001
I0926 15:34:04.298935  4911 solver.cpp:218] Iteration 16300 (6.81733 iter/s, 14.6685s/100 iters), loss = 0.382274
I0926 15:34:04.298967  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.382274 (* 1 = 0.382274 loss)
I0926 15:34:04.298972  4911 sgd_solver.cpp:105] Iteration 16300, lr = 0.0001
I0926 15:34:18.934296  4911 solver.cpp:218] Iteration 16400 (6.8328 iter/s, 14.6353s/100 iters), loss = 0.227676
I0926 15:34:18.934331  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227676 (* 1 = 0.227676 loss)
I0926 15:34:18.934339  4911 sgd_solver.cpp:105] Iteration 16400, lr = 0.0001
I0926 15:34:32.841922  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:34:33.428017  4911 solver.cpp:330] Iteration 16500, Testing net (#0)
I0926 15:34:36.857707  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:34:37.002838  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8613
I0926 15:34:37.002866  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.408957 (* 1 = 0.408957 loss)
I0926 15:34:37.147713  4911 solver.cpp:218] Iteration 16500 (5.49048 iter/s, 18.2133s/100 iters), loss = 0.231158
I0926 15:34:37.147742  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231158 (* 1 = 0.231158 loss)
I0926 15:34:37.147749  4911 sgd_solver.cpp:105] Iteration 16500, lr = 0.0001
I0926 15:34:51.809007  4911 solver.cpp:218] Iteration 16600 (6.82071 iter/s, 14.6612s/100 iters), loss = 0.31019
I0926 15:34:51.809037  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31019 (* 1 = 0.31019 loss)
I0926 15:34:51.809044  4911 sgd_solver.cpp:105] Iteration 16600, lr = 0.0001
I0926 15:35:06.472496  4911 solver.cpp:218] Iteration 16700 (6.81969 iter/s, 14.6634s/100 iters), loss = 0.325742
I0926 15:35:06.472676  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325741 (* 1 = 0.325741 loss)
I0926 15:35:06.472685  4911 sgd_solver.cpp:105] Iteration 16700, lr = 0.0001
I0926 15:35:21.140115  4911 solver.cpp:218] Iteration 16800 (6.81783 iter/s, 14.6674s/100 iters), loss = 0.288444
I0926 15:35:21.140147  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288444 (* 1 = 0.288444 loss)
I0926 15:35:21.140154  4911 sgd_solver.cpp:105] Iteration 16800, lr = 0.0001
I0926 15:35:35.791429  4911 solver.cpp:218] Iteration 16900 (6.82536 iter/s, 14.6512s/100 iters), loss = 0.298137
I0926 15:35:35.791460  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298137 (* 1 = 0.298137 loss)
I0926 15:35:35.791466  4911 sgd_solver.cpp:105] Iteration 16900, lr = 0.0001
I0926 15:35:49.705237  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:35:50.290066  4911 solver.cpp:330] Iteration 17000, Testing net (#0)
I0926 15:35:53.709964  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:35:53.853225  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8605
I0926 15:35:53.853262  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.40657 (* 1 = 0.40657 loss)
I0926 15:35:54.002702  4911 solver.cpp:218] Iteration 17000 (5.49113 iter/s, 18.2112s/100 iters), loss = 0.282386
I0926 15:35:54.002737  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282386 (* 1 = 0.282386 loss)
I0926 15:35:54.002744  4911 sgd_solver.cpp:105] Iteration 17000, lr = 0.0001
I0926 15:36:08.662014  4911 solver.cpp:218] Iteration 17100 (6.82164 iter/s, 14.6592s/100 iters), loss = 0.336501
I0926 15:36:08.662045  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.3365 (* 1 = 0.3365 loss)
I0926 15:36:08.662052  4911 sgd_solver.cpp:105] Iteration 17100, lr = 0.0001
I0926 15:36:23.298384  4911 solver.cpp:218] Iteration 17200 (6.83233 iter/s, 14.6363s/100 iters), loss = 0.348721
I0926 15:36:23.298501  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.348721 (* 1 = 0.348721 loss)
I0926 15:36:23.298508  4911 sgd_solver.cpp:105] Iteration 17200, lr = 0.0001
I0926 15:36:37.957195  4911 solver.cpp:218] Iteration 17300 (6.8219 iter/s, 14.6587s/100 iters), loss = 0.335489
I0926 15:36:37.957227  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335489 (* 1 = 0.335489 loss)
I0926 15:36:37.957234  4911 sgd_solver.cpp:105] Iteration 17300, lr = 0.0001
I0926 15:36:52.589749  4911 solver.cpp:218] Iteration 17400 (6.83411 iter/s, 14.6325s/100 iters), loss = 0.243884
I0926 15:36:52.589783  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243884 (* 1 = 0.243884 loss)
I0926 15:36:52.589792  4911 sgd_solver.cpp:105] Iteration 17400, lr = 0.0001
I0926 15:37:06.501602  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:37:07.088631  4911 solver.cpp:330] Iteration 17500, Testing net (#0)
I0926 15:37:10.517755  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:37:10.659773  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8617
I0926 15:37:10.659799  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.406911 (* 1 = 0.406911 loss)
I0926 15:37:10.804250  4911 solver.cpp:218] Iteration 17500 (5.49015 iter/s, 18.2144s/100 iters), loss = 0.223142
I0926 15:37:10.804280  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223142 (* 1 = 0.223142 loss)
I0926 15:37:10.804287  4911 sgd_solver.cpp:105] Iteration 17500, lr = 0.0001
I0926 15:37:25.469729  4911 solver.cpp:218] Iteration 17600 (6.81876 iter/s, 14.6654s/100 iters), loss = 0.334137
I0926 15:37:25.469759  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.334137 (* 1 = 0.334137 loss)
I0926 15:37:25.469765  4911 sgd_solver.cpp:105] Iteration 17600, lr = 0.0001
I0926 15:37:40.119464  4911 solver.cpp:218] Iteration 17700 (6.82609 iter/s, 14.6497s/100 iters), loss = 0.28238
I0926 15:37:40.119609  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28238 (* 1 = 0.28238 loss)
I0926 15:37:40.119618  4911 sgd_solver.cpp:105] Iteration 17700, lr = 0.0001
I0926 15:37:54.772131  4911 solver.cpp:218] Iteration 17800 (6.82478 iter/s, 14.6525s/100 iters), loss = 0.369694
I0926 15:37:54.772172  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.369694 (* 1 = 0.369694 loss)
I0926 15:37:54.772178  4911 sgd_solver.cpp:105] Iteration 17800, lr = 0.0001
I0926 15:38:09.435057  4911 solver.cpp:218] Iteration 17900 (6.81996 iter/s, 14.6629s/100 iters), loss = 0.225007
I0926 15:38:09.435106  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225007 (* 1 = 0.225007 loss)
I0926 15:38:09.435122  4911 sgd_solver.cpp:105] Iteration 17900, lr = 0.0001
I0926 15:38:23.351943  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:38:23.937808  4911 solver.cpp:330] Iteration 18000, Testing net (#0)
I0926 15:38:27.360329  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:38:27.502316  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.861
I0926 15:38:27.502341  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.405515 (* 1 = 0.405515 loss)
I0926 15:38:27.647146  4911 solver.cpp:218] Iteration 18000 (5.49088 iter/s, 18.212s/100 iters), loss = 0.255599
I0926 15:38:27.647178  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255599 (* 1 = 0.255599 loss)
I0926 15:38:27.647186  4911 sgd_solver.cpp:105] Iteration 18000, lr = 0.0001
I0926 15:38:42.308030  4911 solver.cpp:218] Iteration 18100 (6.8209 iter/s, 14.6608s/100 iters), loss = 0.216542
I0926 15:38:42.308063  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216542 (* 1 = 0.216542 loss)
I0926 15:38:42.308069  4911 sgd_solver.cpp:105] Iteration 18100, lr = 0.0001
I0926 15:38:56.961189  4911 solver.cpp:218] Iteration 18200 (6.8245 iter/s, 14.6531s/100 iters), loss = 0.302169
I0926 15:38:56.961302  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302169 (* 1 = 0.302169 loss)
I0926 15:38:56.961318  4911 sgd_solver.cpp:105] Iteration 18200, lr = 0.0001
I0926 15:39:11.612200  4911 solver.cpp:218] Iteration 18300 (6.82553 iter/s, 14.6509s/100 iters), loss = 0.332076
I0926 15:39:11.612232  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.332075 (* 1 = 0.332075 loss)
I0926 15:39:11.612239  4911 sgd_solver.cpp:105] Iteration 18300, lr = 0.0001
I0926 15:39:26.271378  4911 solver.cpp:218] Iteration 18400 (6.8217 iter/s, 14.6591s/100 iters), loss = 0.309777
I0926 15:39:26.271409  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309777 (* 1 = 0.309777 loss)
I0926 15:39:26.271415  4911 sgd_solver.cpp:105] Iteration 18400, lr = 0.0001
I0926 15:39:40.203008  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:39:40.788579  4911 solver.cpp:330] Iteration 18500, Testing net (#0)
I0926 15:39:44.205976  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:39:44.348433  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8583
I0926 15:39:44.348467  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.40719 (* 1 = 0.40719 loss)
I0926 15:39:44.493280  4911 solver.cpp:218] Iteration 18500 (5.48792 iter/s, 18.2218s/100 iters), loss = 0.202506
I0926 15:39:44.493312  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202506 (* 1 = 0.202506 loss)
I0926 15:39:44.493319  4911 sgd_solver.cpp:105] Iteration 18500, lr = 0.0001
I0926 15:39:59.128756  4911 solver.cpp:218] Iteration 18600 (6.83274 iter/s, 14.6354s/100 iters), loss = 0.266741
I0926 15:39:59.128788  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266741 (* 1 = 0.266741 loss)
I0926 15:39:59.128794  4911 sgd_solver.cpp:105] Iteration 18600, lr = 0.0001
I0926 15:40:13.776749  4911 solver.cpp:218] Iteration 18700 (6.82691 iter/s, 14.6479s/100 iters), loss = 0.327205
I0926 15:40:13.776885  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327205 (* 1 = 0.327205 loss)
I0926 15:40:13.776892  4911 sgd_solver.cpp:105] Iteration 18700, lr = 0.0001
I0926 15:40:28.426455  4911 solver.cpp:218] Iteration 18800 (6.82615 iter/s, 14.6495s/100 iters), loss = 0.331934
I0926 15:40:28.426497  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331933 (* 1 = 0.331933 loss)
I0926 15:40:28.426504  4911 sgd_solver.cpp:105] Iteration 18800, lr = 0.0001
I0926 15:40:43.071090  4911 solver.cpp:218] Iteration 18900 (6.82847 iter/s, 14.6446s/100 iters), loss = 0.371605
I0926 15:40:43.071122  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371605 (* 1 = 0.371605 loss)
I0926 15:40:43.071128  4911 sgd_solver.cpp:105] Iteration 18900, lr = 0.0001
I0926 15:40:56.969795  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:40:57.554934  4911 solver.cpp:330] Iteration 19000, Testing net (#0)
I0926 15:41:00.970130  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:41:01.112593  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8605
I0926 15:41:01.112618  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.40569 (* 1 = 0.40569 loss)
I0926 15:41:01.256934  4911 solver.cpp:218] Iteration 19000 (5.4988 iter/s, 18.1858s/100 iters), loss = 0.265052
I0926 15:41:01.256965  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265052 (* 1 = 0.265052 loss)
I0926 15:41:01.256973  4911 sgd_solver.cpp:105] Iteration 19000, lr = 0.0001
I0926 15:41:15.892590  4911 solver.cpp:218] Iteration 19100 (6.83266 iter/s, 14.6356s/100 iters), loss = 0.25158
I0926 15:41:15.892622  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25158 (* 1 = 0.25158 loss)
I0926 15:41:15.892639  4911 sgd_solver.cpp:105] Iteration 19100, lr = 0.0001
I0926 15:41:30.519795  4911 solver.cpp:218] Iteration 19200 (6.83661 iter/s, 14.6271s/100 iters), loss = 0.308211
I0926 15:41:30.519878  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30821 (* 1 = 0.30821 loss)
I0926 15:41:30.519896  4911 sgd_solver.cpp:105] Iteration 19200, lr = 0.0001
I0926 15:41:45.154647  4911 solver.cpp:218] Iteration 19300 (6.83306 iter/s, 14.6347s/100 iters), loss = 0.36396
I0926 15:41:45.154677  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.36396 (* 1 = 0.36396 loss)
I0926 15:41:45.154700  4911 sgd_solver.cpp:105] Iteration 19300, lr = 0.0001
I0926 15:41:59.803416  4911 solver.cpp:218] Iteration 19400 (6.82654 iter/s, 14.6487s/100 iters), loss = 0.279809
I0926 15:41:59.803448  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279809 (* 1 = 0.279809 loss)
I0926 15:41:59.803455  4911 sgd_solver.cpp:105] Iteration 19400, lr = 0.0001
I0926 15:42:13.726606  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:42:14.313015  4911 solver.cpp:330] Iteration 19500, Testing net (#0)
I0926 15:42:17.729483  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:42:17.873657  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.861
I0926 15:42:17.873684  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.405636 (* 1 = 0.405636 loss)
I0926 15:42:18.022249  4911 solver.cpp:218] Iteration 19500 (5.48885 iter/s, 18.2188s/100 iters), loss = 0.293448
I0926 15:42:18.022294  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293448 (* 1 = 0.293448 loss)
I0926 15:42:18.022300  4911 sgd_solver.cpp:105] Iteration 19500, lr = 0.0001
I0926 15:42:32.692423  4911 solver.cpp:218] Iteration 19600 (6.81659 iter/s, 14.6701s/100 iters), loss = 0.323967
I0926 15:42:32.692453  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323967 (* 1 = 0.323967 loss)
I0926 15:42:32.692461  4911 sgd_solver.cpp:105] Iteration 19600, lr = 0.0001
I0926 15:42:47.347537  4911 solver.cpp:218] Iteration 19700 (6.82359 iter/s, 14.655s/100 iters), loss = 0.290359
I0926 15:42:47.347656  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290359 (* 1 = 0.290359 loss)
I0926 15:42:47.347673  4911 sgd_solver.cpp:105] Iteration 19700, lr = 0.0001
I0926 15:43:01.976915  4911 solver.cpp:218] Iteration 19800 (6.83563 iter/s, 14.6292s/100 iters), loss = 0.270822
I0926 15:43:01.976945  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270822 (* 1 = 0.270822 loss)
I0926 15:43:01.976951  4911 sgd_solver.cpp:105] Iteration 19800, lr = 0.0001
I0926 15:43:16.603162  4911 solver.cpp:218] Iteration 19900 (6.83705 iter/s, 14.6262s/100 iters), loss = 0.269941
I0926 15:43:16.603193  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26994 (* 1 = 0.26994 loss)
I0926 15:43:16.603199  4911 sgd_solver.cpp:105] Iteration 19900, lr = 0.0001
I0926 15:43:30.528724  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:43:31.117117  4911 solver.cpp:330] Iteration 20000, Testing net (#0)
I0926 15:43:34.543606  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:43:34.687142  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8614
I0926 15:43:34.687167  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.403985 (* 1 = 0.403985 loss)
I0926 15:43:34.832262  4911 solver.cpp:218] Iteration 20000 (5.48576 iter/s, 18.229s/100 iters), loss = 0.234024
I0926 15:43:34.832306  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234024 (* 1 = 0.234024 loss)
I0926 15:43:34.832312  4911 sgd_solver.cpp:46] MultiStep Status: Iteration 20000, step = 2
I0926 15:43:34.832315  4911 sgd_solver.cpp:105] Iteration 20000, lr = 1e-05
I0926 15:43:49.487845  4911 solver.cpp:218] Iteration 20100 (6.82338 iter/s, 14.6555s/100 iters), loss = 0.289538
I0926 15:43:49.487876  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289538 (* 1 = 0.289538 loss)
I0926 15:43:49.487892  4911 sgd_solver.cpp:105] Iteration 20100, lr = 1e-05
I0926 15:44:04.144969  4911 solver.cpp:218] Iteration 20200 (6.82265 iter/s, 14.6571s/100 iters), loss = 0.290342
I0926 15:44:04.145103  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290342 (* 1 = 0.290342 loss)
I0926 15:44:04.145112  4911 sgd_solver.cpp:105] Iteration 20200, lr = 1e-05
I0926 15:44:18.820001  4911 solver.cpp:218] Iteration 20300 (6.81437 iter/s, 14.6749s/100 iters), loss = 0.411722
I0926 15:44:18.820031  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.411721 (* 1 = 0.411721 loss)
I0926 15:44:18.820037  4911 sgd_solver.cpp:105] Iteration 20300, lr = 1e-05
I0926 15:44:33.441098  4911 solver.cpp:218] Iteration 20400 (6.83946 iter/s, 14.621s/100 iters), loss = 0.217662
I0926 15:44:33.441130  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217662 (* 1 = 0.217662 loss)
I0926 15:44:33.441138  4911 sgd_solver.cpp:105] Iteration 20400, lr = 1e-05
I0926 15:44:47.326637  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:44:47.911669  4911 solver.cpp:330] Iteration 20500, Testing net (#0)
I0926 15:44:51.327893  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:44:51.470770  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8616
I0926 15:44:51.470794  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.403786 (* 1 = 0.403786 loss)
I0926 15:44:51.615677  4911 solver.cpp:218] Iteration 20500 (5.50221 iter/s, 18.1745s/100 iters), loss = 0.204063
I0926 15:44:51.615708  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204062 (* 1 = 0.204062 loss)
I0926 15:44:51.615715  4911 sgd_solver.cpp:105] Iteration 20500, lr = 1e-05
I0926 15:45:06.225464  4911 solver.cpp:218] Iteration 20600 (6.84476 iter/s, 14.6097s/100 iters), loss = 0.278548
I0926 15:45:06.225494  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278548 (* 1 = 0.278548 loss)
I0926 15:45:06.225500  4911 sgd_solver.cpp:105] Iteration 20600, lr = 1e-05
I0926 15:45:20.837595  4911 solver.cpp:218] Iteration 20700 (6.84366 iter/s, 14.6121s/100 iters), loss = 0.23239
I0926 15:45:20.837697  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23239 (* 1 = 0.23239 loss)
I0926 15:45:20.837713  4911 sgd_solver.cpp:105] Iteration 20700, lr = 1e-05
I0926 15:45:35.448797  4911 solver.cpp:218] Iteration 20800 (6.84413 iter/s, 14.6111s/100 iters), loss = 0.367205
I0926 15:45:35.448825  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.367205 (* 1 = 0.367205 loss)
I0926 15:45:35.448832  4911 sgd_solver.cpp:105] Iteration 20800, lr = 1e-05
I0926 15:45:50.064409  4911 solver.cpp:218] Iteration 20900 (6.84203 iter/s, 14.6155s/100 iters), loss = 0.270678
I0926 15:45:50.064438  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270678 (* 1 = 0.270678 loss)
I0926 15:45:50.064445  4911 sgd_solver.cpp:105] Iteration 20900, lr = 1e-05
I0926 15:46:03.952157  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:46:04.536363  4911 solver.cpp:330] Iteration 21000, Testing net (#0)
I0926 15:46:07.952455  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:46:08.094872  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8617
I0926 15:46:08.094907  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.403452 (* 1 = 0.403452 loss)
I0926 15:46:08.239136  4911 solver.cpp:218] Iteration 21000 (5.50217 iter/s, 18.1747s/100 iters), loss = 0.205041
I0926 15:46:08.239166  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205041 (* 1 = 0.205041 loss)
I0926 15:46:08.239172  4911 sgd_solver.cpp:105] Iteration 21000, lr = 1e-05
I0926 15:46:22.834237  4911 solver.cpp:218] Iteration 21100 (6.85164 iter/s, 14.595s/100 iters), loss = 0.24327
I0926 15:46:22.834277  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24327 (* 1 = 0.24327 loss)
I0926 15:46:22.834283  4911 sgd_solver.cpp:105] Iteration 21100, lr = 1e-05
I0926 15:46:37.432646  4911 solver.cpp:218] Iteration 21200 (6.8501 iter/s, 14.5983s/100 iters), loss = 0.302745
I0926 15:46:37.432750  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302745 (* 1 = 0.302745 loss)
I0926 15:46:37.432757  4911 sgd_solver.cpp:105] Iteration 21200, lr = 1e-05
I0926 15:46:52.035634  4911 solver.cpp:218] Iteration 21300 (6.84798 iter/s, 14.6028s/100 iters), loss = 0.390665
I0926 15:46:52.035676  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.390665 (* 1 = 0.390665 loss)
I0926 15:46:52.035683  4911 sgd_solver.cpp:105] Iteration 21300, lr = 1e-05
I0926 15:47:06.630606  4911 solver.cpp:218] Iteration 21400 (6.85171 iter/s, 14.5949s/100 iters), loss = 0.227951
I0926 15:47:06.630647  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227951 (* 1 = 0.227951 loss)
I0926 15:47:06.630653  4911 sgd_solver.cpp:105] Iteration 21400, lr = 1e-05
I0926 15:47:20.510957  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:47:21.094602  4911 solver.cpp:330] Iteration 21500, Testing net (#0)
I0926 15:47:24.508098  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:47:24.650810  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8612
I0926 15:47:24.650846  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.403375 (* 1 = 0.403375 loss)
I0926 15:47:24.795635  4911 solver.cpp:218] Iteration 21500 (5.50511 iter/s, 18.1649s/100 iters), loss = 0.194755
I0926 15:47:24.795667  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194755 (* 1 = 0.194755 loss)
I0926 15:47:24.795675  4911 sgd_solver.cpp:105] Iteration 21500, lr = 1e-05
I0926 15:47:39.407408  4911 solver.cpp:218] Iteration 21600 (6.84383 iter/s, 14.6117s/100 iters), loss = 0.292352
I0926 15:47:39.407449  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292351 (* 1 = 0.292351 loss)
I0926 15:47:39.407454  4911 sgd_solver.cpp:105] Iteration 21600, lr = 1e-05
I0926 15:47:54.016235  4911 solver.cpp:218] Iteration 21700 (6.84521 iter/s, 14.6088s/100 iters), loss = 0.207517
I0926 15:47:54.016412  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207517 (* 1 = 0.207517 loss)
I0926 15:47:54.016422  4911 sgd_solver.cpp:105] Iteration 21700, lr = 1e-05
I0926 15:48:08.621434  4911 solver.cpp:218] Iteration 21800 (6.84697 iter/s, 14.605s/100 iters), loss = 0.354213
I0926 15:48:08.621465  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.354213 (* 1 = 0.354213 loss)
I0926 15:48:08.621472  4911 sgd_solver.cpp:105] Iteration 21800, lr = 1e-05
I0926 15:48:23.219662  4911 solver.cpp:218] Iteration 21900 (6.85018 iter/s, 14.5982s/100 iters), loss = 0.341119
I0926 15:48:23.219693  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.341119 (* 1 = 0.341119 loss)
I0926 15:48:23.219699  4911 sgd_solver.cpp:105] Iteration 21900, lr = 1e-05
I0926 15:48:37.101387  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:48:37.684847  4911 solver.cpp:330] Iteration 22000, Testing net (#0)
I0926 15:48:41.099828  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:48:41.242249  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8618
I0926 15:48:41.242285  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.403032 (* 1 = 0.403032 loss)
I0926 15:48:41.387547  4911 solver.cpp:218] Iteration 22000 (5.50424 iter/s, 18.1678s/100 iters), loss = 0.276378
I0926 15:48:41.387576  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276378 (* 1 = 0.276378 loss)
I0926 15:48:41.387583  4911 sgd_solver.cpp:105] Iteration 22000, lr = 1e-05
I0926 15:48:55.984520  4911 solver.cpp:218] Iteration 22100 (6.85077 iter/s, 14.5969s/100 iters), loss = 0.326479
I0926 15:48:55.984550  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326479 (* 1 = 0.326479 loss)
I0926 15:48:55.984556  4911 sgd_solver.cpp:105] Iteration 22100, lr = 1e-05
I0926 15:49:10.595423  4911 solver.cpp:218] Iteration 22200 (6.84423 iter/s, 14.6108s/100 iters), loss = 0.289594
I0926 15:49:10.595566  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289594 (* 1 = 0.289594 loss)
I0926 15:49:10.595574  4911 sgd_solver.cpp:105] Iteration 22200, lr = 1e-05
I0926 15:49:25.198359  4911 solver.cpp:218] Iteration 22300 (6.84802 iter/s, 14.6028s/100 iters), loss = 0.364648
I0926 15:49:25.198390  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.364648 (* 1 = 0.364648 loss)
I0926 15:49:25.198396  4911 sgd_solver.cpp:105] Iteration 22300, lr = 1e-05
I0926 15:49:39.805631  4911 solver.cpp:218] Iteration 22400 (6.84594 iter/s, 14.6072s/100 iters), loss = 0.236153
I0926 15:49:39.805660  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236153 (* 1 = 0.236153 loss)
I0926 15:49:39.805666  4911 sgd_solver.cpp:105] Iteration 22400, lr = 1e-05
I0926 15:49:53.690930  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:49:54.275293  4911 solver.cpp:330] Iteration 22500, Testing net (#0)
I0926 15:49:57.689822  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:49:57.832240  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8621
I0926 15:49:57.832267  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.402793 (* 1 = 0.402793 loss)
I0926 15:49:57.977308  4911 solver.cpp:218] Iteration 22500 (5.50309 iter/s, 18.1716s/100 iters), loss = 0.233544
I0926 15:49:57.977336  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233543 (* 1 = 0.233543 loss)
I0926 15:49:57.977344  4911 sgd_solver.cpp:105] Iteration 22500, lr = 1e-05
I0926 15:50:12.581145  4911 solver.cpp:218] Iteration 22600 (6.84755 iter/s, 14.6038s/100 iters), loss = 0.314158
I0926 15:50:12.581176  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314158 (* 1 = 0.314158 loss)
I0926 15:50:12.581182  4911 sgd_solver.cpp:105] Iteration 22600, lr = 1e-05
I0926 15:50:27.189859  4911 solver.cpp:218] Iteration 22700 (6.84526 iter/s, 14.6086s/100 iters), loss = 0.325868
I0926 15:50:27.190007  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325868 (* 1 = 0.325868 loss)
I0926 15:50:27.190026  4911 sgd_solver.cpp:105] Iteration 22700, lr = 1e-05
I0926 15:50:41.793047  4911 solver.cpp:218] Iteration 22800 (6.84791 iter/s, 14.603s/100 iters), loss = 0.346677
I0926 15:50:41.793078  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.346677 (* 1 = 0.346677 loss)
I0926 15:50:41.793084  4911 sgd_solver.cpp:105] Iteration 22800, lr = 1e-05
I0926 15:50:56.403234  4911 solver.cpp:218] Iteration 22900 (6.84457 iter/s, 14.6101s/100 iters), loss = 0.316992
I0926 15:50:56.403264  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316992 (* 1 = 0.316992 loss)
I0926 15:50:56.403280  4911 sgd_solver.cpp:105] Iteration 22900, lr = 1e-05
I0926 15:51:10.290828  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:51:10.876101  4911 solver.cpp:330] Iteration 23000, Testing net (#0)
I0926 15:51:14.291558  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:51:14.434022  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8616
I0926 15:51:14.434058  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.402762 (* 1 = 0.402762 loss)
I0926 15:51:14.578390  4911 solver.cpp:218] Iteration 23000 (5.50204 iter/s, 18.1751s/100 iters), loss = 0.196084
I0926 15:51:14.578420  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196084 (* 1 = 0.196084 loss)
I0926 15:51:14.578428  4911 sgd_solver.cpp:105] Iteration 23000, lr = 1e-05
I0926 15:51:29.186039  4911 solver.cpp:218] Iteration 23100 (6.84576 iter/s, 14.6076s/100 iters), loss = 0.266293
I0926 15:51:29.186080  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266293 (* 1 = 0.266293 loss)
I0926 15:51:29.186086  4911 sgd_solver.cpp:105] Iteration 23100, lr = 1e-05
I0926 15:51:43.799967  4911 solver.cpp:218] Iteration 23200 (6.84282 iter/s, 14.6139s/100 iters), loss = 0.317794
I0926 15:51:43.800072  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317794 (* 1 = 0.317794 loss)
I0926 15:51:43.800091  4911 sgd_solver.cpp:105] Iteration 23200, lr = 1e-05
I0926 15:51:58.408733  4911 solver.cpp:218] Iteration 23300 (6.84527 iter/s, 14.6086s/100 iters), loss = 0.354769
I0926 15:51:58.408774  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.354769 (* 1 = 0.354769 loss)
I0926 15:51:58.408780  4911 sgd_solver.cpp:105] Iteration 23300, lr = 1e-05
I0926 15:52:13.021438  4911 solver.cpp:218] Iteration 23400 (6.8434 iter/s, 14.6126s/100 iters), loss = 0.27059
I0926 15:52:13.021481  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27059 (* 1 = 0.27059 loss)
I0926 15:52:13.021487  4911 sgd_solver.cpp:105] Iteration 23400, lr = 1e-05
I0926 15:52:26.906255  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:52:27.489820  4911 solver.cpp:330] Iteration 23500, Testing net (#0)
I0926 15:52:30.904609  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:52:31.046892  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8619
I0926 15:52:31.046917  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.402927 (* 1 = 0.402927 loss)
I0926 15:52:31.191337  4911 solver.cpp:218] Iteration 23500 (5.50363 iter/s, 18.1698s/100 iters), loss = 0.234688
I0926 15:52:31.191367  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234688 (* 1 = 0.234688 loss)
I0926 15:52:31.191373  4911 sgd_solver.cpp:105] Iteration 23500, lr = 1e-05
I0926 15:52:45.786308  4911 solver.cpp:218] Iteration 23600 (6.85171 iter/s, 14.5949s/100 iters), loss = 0.285852
I0926 15:52:45.786350  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285852 (* 1 = 0.285852 loss)
I0926 15:52:45.786355  4911 sgd_solver.cpp:105] Iteration 23600, lr = 1e-05
I0926 15:53:00.383069  4911 solver.cpp:218] Iteration 23700 (6.85087 iter/s, 14.5967s/100 iters), loss = 0.312704
I0926 15:53:00.383198  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312704 (* 1 = 0.312704 loss)
I0926 15:53:00.383216  4911 sgd_solver.cpp:105] Iteration 23700, lr = 1e-05
I0926 15:53:14.977614  4911 solver.cpp:218] Iteration 23800 (6.85195 iter/s, 14.5944s/100 iters), loss = 0.296867
I0926 15:53:14.977645  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296867 (* 1 = 0.296867 loss)
I0926 15:53:14.977651  4911 sgd_solver.cpp:105] Iteration 23800, lr = 1e-05
I0926 15:53:29.569394  4911 solver.cpp:218] Iteration 23900 (6.85321 iter/s, 14.5917s/100 iters), loss = 0.297949
I0926 15:53:29.569424  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297948 (* 1 = 0.297948 loss)
I0926 15:53:29.569430  4911 sgd_solver.cpp:105] Iteration 23900, lr = 1e-05
I0926 15:53:43.435257  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:53:44.020769  4911 solver.cpp:330] Iteration 24000, Testing net (#0)
I0926 15:53:47.435290  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:53:47.577530  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8619
I0926 15:53:47.577567  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.403012 (* 1 = 0.403012 loss)
I0926 15:53:47.722523  4911 solver.cpp:218] Iteration 24000 (5.50871 iter/s, 18.1531s/100 iters), loss = 0.199218
I0926 15:53:47.722553  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199218 (* 1 = 0.199218 loss)
I0926 15:53:47.722559  4911 sgd_solver.cpp:105] Iteration 24000, lr = 1e-05
I0926 15:54:02.322532  4911 solver.cpp:218] Iteration 24100 (6.84935 iter/s, 14.5999s/100 iters), loss = 0.295097
I0926 15:54:02.322583  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295097 (* 1 = 0.295097 loss)
I0926 15:54:02.322599  4911 sgd_solver.cpp:105] Iteration 24100, lr = 1e-05
I0926 15:54:16.935686  4911 solver.cpp:218] Iteration 24200 (6.84319 iter/s, 14.6131s/100 iters), loss = 0.267357
I0926 15:54:16.935773  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267356 (* 1 = 0.267356 loss)
I0926 15:54:16.935791  4911 sgd_solver.cpp:105] Iteration 24200, lr = 1e-05
I0926 15:54:31.539083  4911 solver.cpp:218] Iteration 24300 (6.84777 iter/s, 14.6033s/100 iters), loss = 0.297313
I0926 15:54:31.539113  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297313 (* 1 = 0.297313 loss)
I0926 15:54:31.539119  4911 sgd_solver.cpp:105] Iteration 24300, lr = 1e-05
I0926 15:54:46.168895  4911 solver.cpp:218] Iteration 24400 (6.83539 iter/s, 14.6297s/100 iters), loss = 0.255993
I0926 15:54:46.168926  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255992 (* 1 = 0.255992 loss)
I0926 15:54:46.168931  4911 sgd_solver.cpp:105] Iteration 24400, lr = 1e-05
I0926 15:55:00.062248  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:55:00.645798  4911 solver.cpp:330] Iteration 24500, Testing net (#0)
I0926 15:55:04.060699  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:55:04.202358  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8616
I0926 15:55:04.202384  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.402926 (* 1 = 0.402926 loss)
I0926 15:55:04.347390  4911 solver.cpp:218] Iteration 24500 (5.50103 iter/s, 18.1784s/100 iters), loss = 0.282785
I0926 15:55:04.347424  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282785 (* 1 = 0.282785 loss)
I0926 15:55:04.347430  4911 sgd_solver.cpp:105] Iteration 24500, lr = 1e-05
I0926 15:55:18.957418  4911 solver.cpp:218] Iteration 24600 (6.84465 iter/s, 14.61s/100 iters), loss = 0.350156
I0926 15:55:18.957449  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350156 (* 1 = 0.350156 loss)
I0926 15:55:18.957456  4911 sgd_solver.cpp:105] Iteration 24600, lr = 1e-05
I0926 15:55:33.678277  4911 solver.cpp:218] Iteration 24700 (6.79311 iter/s, 14.7208s/100 iters), loss = 0.289567
I0926 15:55:33.678402  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289567 (* 1 = 0.289567 loss)
I0926 15:55:33.678411  4911 sgd_solver.cpp:105] Iteration 24700, lr = 1e-05
I0926 15:55:48.427146  4911 solver.cpp:218] Iteration 24800 (6.78025 iter/s, 14.7487s/100 iters), loss = 0.349757
I0926 15:55:48.427186  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349757 (* 1 = 0.349757 loss)
I0926 15:55:48.427192  4911 sgd_solver.cpp:105] Iteration 24800, lr = 1e-05
I0926 15:56:03.041116  4911 solver.cpp:218] Iteration 24900 (6.8428 iter/s, 14.6139s/100 iters), loss = 0.248515
I0926 15:56:03.041152  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248514 (* 1 = 0.248514 loss)
I0926 15:56:03.041160  4911 sgd_solver.cpp:105] Iteration 24900, lr = 1e-05
I0926 15:56:17.165468  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:56:17.763135  4911 solver.cpp:330] Iteration 25000, Testing net (#0)
I0926 15:56:21.190675  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:56:21.332746  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8616
I0926 15:56:21.332782  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.402812 (* 1 = 0.402812 loss)
I0926 15:56:21.477064  4911 solver.cpp:218] Iteration 25000 (5.42421 iter/s, 18.4359s/100 iters), loss = 0.208751
I0926 15:56:21.477093  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208751 (* 1 = 0.208751 loss)
I0926 15:56:21.477099  4911 sgd_solver.cpp:105] Iteration 25000, lr = 1e-05
I0926 15:56:36.239339  4911 solver.cpp:218] Iteration 25100 (6.77405 iter/s, 14.7622s/100 iters), loss = 0.322962
I0926 15:56:36.239375  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322962 (* 1 = 0.322962 loss)
I0926 15:56:36.239385  4911 sgd_solver.cpp:105] Iteration 25100, lr = 1e-05
I0926 15:56:50.950716  4911 solver.cpp:218] Iteration 25200 (6.79749 iter/s, 14.7113s/100 iters), loss = 0.280134
I0926 15:56:50.950840  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280133 (* 1 = 0.280133 loss)
I0926 15:56:50.950858  4911 sgd_solver.cpp:105] Iteration 25200, lr = 1e-05
I0926 15:57:05.642092  4911 solver.cpp:218] Iteration 25300 (6.80678 iter/s, 14.6912s/100 iters), loss = 0.362907
I0926 15:57:05.642124  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362906 (* 1 = 0.362906 loss)
I0926 15:57:05.642130  4911 sgd_solver.cpp:105] Iteration 25300, lr = 1e-05
I0926 15:57:20.288283  4911 solver.cpp:218] Iteration 25400 (6.82774 iter/s, 14.6461s/100 iters), loss = 0.328227
I0926 15:57:20.288313  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328227 (* 1 = 0.328227 loss)
I0926 15:57:20.288329  4911 sgd_solver.cpp:105] Iteration 25400, lr = 1e-05
I0926 15:57:34.181362  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:57:34.766628  4911 solver.cpp:330] Iteration 25500, Testing net (#0)
I0926 15:57:38.182456  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:57:38.324734  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8619
I0926 15:57:38.324770  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.402801 (* 1 = 0.402801 loss)
I0926 15:57:38.470043  4911 solver.cpp:218] Iteration 25500 (5.50004 iter/s, 18.1817s/100 iters), loss = 0.214933
I0926 15:57:38.470073  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214933 (* 1 = 0.214933 loss)
I0926 15:57:38.470080  4911 sgd_solver.cpp:105] Iteration 25500, lr = 1e-05
I0926 15:57:53.070924  4911 solver.cpp:218] Iteration 25600 (6.84893 iter/s, 14.6008s/100 iters), loss = 0.335261
I0926 15:57:53.070966  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.33526 (* 1 = 0.33526 loss)
I0926 15:57:53.070971  4911 sgd_solver.cpp:105] Iteration 25600, lr = 1e-05
I0926 15:58:07.679344  4911 solver.cpp:218] Iteration 25700 (6.8454 iter/s, 14.6083s/100 iters), loss = 0.287033
I0926 15:58:07.679476  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287033 (* 1 = 0.287033 loss)
I0926 15:58:07.679496  4911 sgd_solver.cpp:105] Iteration 25700, lr = 1e-05
I0926 15:58:22.289499  4911 solver.cpp:218] Iteration 25800 (6.84463 iter/s, 14.61s/100 iters), loss = 0.33978
I0926 15:58:22.289528  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.33978 (* 1 = 0.33978 loss)
I0926 15:58:22.289544  4911 sgd_solver.cpp:105] Iteration 25800, lr = 1e-05
I0926 15:58:36.899510  4911 solver.cpp:218] Iteration 25900 (6.84465 iter/s, 14.6099s/100 iters), loss = 0.253576
I0926 15:58:36.899543  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253576 (* 1 = 0.253576 loss)
I0926 15:58:36.899559  4911 sgd_solver.cpp:105] Iteration 25900, lr = 1e-05
I0926 15:58:50.782125  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:58:51.367776  4911 solver.cpp:330] Iteration 26000, Testing net (#0)
I0926 15:58:54.782740  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 15:58:54.925350  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8619
I0926 15:58:54.925376  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.402605 (* 1 = 0.402605 loss)
I0926 15:58:55.070183  4911 solver.cpp:218] Iteration 26000 (5.5034 iter/s, 18.1706s/100 iters), loss = 0.225892
I0926 15:58:55.070214  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225892 (* 1 = 0.225892 loss)
I0926 15:58:55.070221  4911 sgd_solver.cpp:105] Iteration 26000, lr = 1e-05
I0926 15:59:09.666671  4911 solver.cpp:218] Iteration 26100 (6.851 iter/s, 14.5964s/100 iters), loss = 0.310059
I0926 15:59:09.666700  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310059 (* 1 = 0.310059 loss)
I0926 15:59:09.666716  4911 sgd_solver.cpp:105] Iteration 26100, lr = 1e-05
I0926 15:59:24.269160  4911 solver.cpp:218] Iteration 26200 (6.84818 iter/s, 14.6024s/100 iters), loss = 0.256292
I0926 15:59:24.269295  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256292 (* 1 = 0.256292 loss)
I0926 15:59:24.269302  4911 sgd_solver.cpp:105] Iteration 26200, lr = 1e-05
I0926 15:59:38.875649  4911 solver.cpp:218] Iteration 26300 (6.84635 iter/s, 14.6063s/100 iters), loss = 0.312915
I0926 15:59:38.875690  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312915 (* 1 = 0.312915 loss)
I0926 15:59:38.875696  4911 sgd_solver.cpp:105] Iteration 26300, lr = 1e-05
I0926 15:59:53.472568  4911 solver.cpp:218] Iteration 26400 (6.8508 iter/s, 14.5968s/100 iters), loss = 0.381087
I0926 15:59:53.472599  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.381086 (* 1 = 0.381086 loss)
I0926 15:59:53.472615  4911 sgd_solver.cpp:105] Iteration 26400, lr = 1e-05
I0926 16:00:07.349658  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 16:00:07.934118  4911 solver.cpp:330] Iteration 26500, Testing net (#0)
I0926 16:00:11.349169  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 16:00:11.491749  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8621
I0926 16:00:11.491785  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.402537 (* 1 = 0.402537 loss)
I0926 16:00:11.637140  4911 solver.cpp:218] Iteration 26500 (5.50524 iter/s, 18.1645s/100 iters), loss = 0.242981
I0926 16:00:11.637171  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24298 (* 1 = 0.24298 loss)
I0926 16:00:11.637178  4911 sgd_solver.cpp:105] Iteration 26500, lr = 1e-05
I0926 16:00:26.232146  4911 solver.cpp:218] Iteration 26600 (6.85169 iter/s, 14.5949s/100 iters), loss = 0.255181
I0926 16:00:26.232177  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255181 (* 1 = 0.255181 loss)
I0926 16:00:26.232183  4911 sgd_solver.cpp:105] Iteration 26600, lr = 1e-05
I0926 16:00:40.835041  4911 solver.cpp:218] Iteration 26700 (6.84799 iter/s, 14.6028s/100 iters), loss = 0.316111
I0926 16:00:40.835180  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316111 (* 1 = 0.316111 loss)
I0926 16:00:40.835196  4911 sgd_solver.cpp:105] Iteration 26700, lr = 1e-05
I0926 16:00:55.443153  4911 solver.cpp:218] Iteration 26800 (6.84559 iter/s, 14.6079s/100 iters), loss = 0.354289
I0926 16:00:55.443194  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.354288 (* 1 = 0.354288 loss)
I0926 16:00:55.443200  4911 sgd_solver.cpp:105] Iteration 26800, lr = 1e-05
I0926 16:01:10.055603  4911 solver.cpp:218] Iteration 26900 (6.84352 iter/s, 14.6124s/100 iters), loss = 0.26782
I0926 16:01:10.055644  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26782 (* 1 = 0.26782 loss)
I0926 16:01:10.055649  4911 sgd_solver.cpp:105] Iteration 26900, lr = 1e-05
I0926 16:01:23.937366  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 16:01:24.520598  4911 solver.cpp:330] Iteration 27000, Testing net (#0)
I0926 16:01:27.936698  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 16:01:28.078773  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8623
I0926 16:01:28.078810  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.402322 (* 1 = 0.402322 loss)
I0926 16:01:28.223609  4911 solver.cpp:218] Iteration 27000 (5.50421 iter/s, 18.1679s/100 iters), loss = 0.206351
I0926 16:01:28.223639  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206351 (* 1 = 0.206351 loss)
I0926 16:01:28.223646  4911 sgd_solver.cpp:105] Iteration 27000, lr = 1e-05
I0926 16:01:42.823101  4911 solver.cpp:218] Iteration 27100 (6.84959 iter/s, 14.5994s/100 iters), loss = 0.262126
I0926 16:01:42.823130  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262125 (* 1 = 0.262125 loss)
I0926 16:01:42.823137  4911 sgd_solver.cpp:105] Iteration 27100, lr = 1e-05
I0926 16:01:57.425390  4911 solver.cpp:218] Iteration 27200 (6.84827 iter/s, 14.6022s/100 iters), loss = 0.330459
I0926 16:01:57.425503  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330458 (* 1 = 0.330458 loss)
I0926 16:01:57.425510  4911 sgd_solver.cpp:105] Iteration 27200, lr = 1e-05
I0926 16:02:12.029774  4911 solver.cpp:218] Iteration 27300 (6.84732 iter/s, 14.6042s/100 iters), loss = 0.314129
I0926 16:02:12.029804  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314129 (* 1 = 0.314129 loss)
I0926 16:02:12.029810  4911 sgd_solver.cpp:105] Iteration 27300, lr = 1e-05
I0926 16:02:26.631948  4911 solver.cpp:218] Iteration 27400 (6.84833 iter/s, 14.6021s/100 iters), loss = 0.295054
I0926 16:02:26.631990  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295053 (* 1 = 0.295053 loss)
I0926 16:02:26.631996  4911 sgd_solver.cpp:105] Iteration 27400, lr = 1e-05
I0926 16:02:40.514356  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 16:02:41.098086  4911 solver.cpp:330] Iteration 27500, Testing net (#0)
I0926 16:02:44.514926  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 16:02:44.657776  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8625
I0926 16:02:44.657804  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.402291 (* 1 = 0.402291 loss)
I0926 16:02:44.802564  4911 solver.cpp:218] Iteration 27500 (5.50342 iter/s, 18.1705s/100 iters), loss = 0.242811
I0926 16:02:44.802594  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242811 (* 1 = 0.242811 loss)
I0926 16:02:44.802601  4911 sgd_solver.cpp:105] Iteration 27500, lr = 1e-05
I0926 16:02:59.410997  4911 solver.cpp:218] Iteration 27600 (6.84539 iter/s, 14.6084s/100 iters), loss = 0.277278
I0926 16:02:59.411028  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277277 (* 1 = 0.277277 loss)
I0926 16:02:59.411034  4911 sgd_solver.cpp:105] Iteration 27600, lr = 1e-05
I0926 16:03:14.026823  4911 solver.cpp:218] Iteration 27700 (6.84193 iter/s, 14.6157s/100 iters), loss = 0.297747
I0926 16:03:14.026955  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297747 (* 1 = 0.297747 loss)
I0926 16:03:14.026973  4911 sgd_solver.cpp:105] Iteration 27700, lr = 1e-05
I0926 16:03:28.633350  4911 solver.cpp:218] Iteration 27800 (6.84633 iter/s, 14.6064s/100 iters), loss = 0.317504
I0926 16:03:28.633381  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317504 (* 1 = 0.317504 loss)
I0926 16:03:28.633388  4911 sgd_solver.cpp:105] Iteration 27800, lr = 1e-05
I0926 16:03:43.242306  4911 solver.cpp:218] Iteration 27900 (6.84515 iter/s, 14.6089s/100 iters), loss = 0.242452
I0926 16:03:43.242336  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242451 (* 1 = 0.242451 loss)
I0926 16:03:43.242342  4911 sgd_solver.cpp:105] Iteration 27900, lr = 1e-05
I0926 16:03:57.129510  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 16:03:57.714246  4911 solver.cpp:330] Iteration 28000, Testing net (#0)
I0926 16:04:01.128918  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 16:04:01.271328  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.862
I0926 16:04:01.271364  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.402131 (* 1 = 0.402131 loss)
I0926 16:04:01.416173  4911 solver.cpp:218] Iteration 28000 (5.50243 iter/s, 18.1738s/100 iters), loss = 0.178131
I0926 16:04:01.416204  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17813 (* 1 = 0.17813 loss)
I0926 16:04:01.416210  4911 sgd_solver.cpp:105] Iteration 28000, lr = 1e-05
I0926 16:04:16.025219  4911 solver.cpp:218] Iteration 28100 (6.84511 iter/s, 14.609s/100 iters), loss = 0.30314
I0926 16:04:16.025261  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30314 (* 1 = 0.30314 loss)
I0926 16:04:16.025269  4911 sgd_solver.cpp:105] Iteration 28100, lr = 1e-05
I0926 16:04:30.639915  4911 solver.cpp:218] Iteration 28200 (6.84246 iter/s, 14.6146s/100 iters), loss = 0.282055
I0926 16:04:30.640069  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282054 (* 1 = 0.282054 loss)
I0926 16:04:30.640075  4911 sgd_solver.cpp:105] Iteration 28200, lr = 1e-05
I0926 16:04:45.262527  4911 solver.cpp:218] Iteration 28300 (6.83881 iter/s, 14.6224s/100 iters), loss = 0.319635
I0926 16:04:45.262569  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319634 (* 1 = 0.319634 loss)
I0926 16:04:45.262575  4911 sgd_solver.cpp:105] Iteration 28300, lr = 1e-05
I0926 16:04:59.884145  4911 solver.cpp:218] Iteration 28400 (6.83923 iter/s, 14.6215s/100 iters), loss = 0.273114
I0926 16:04:59.884186  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273114 (* 1 = 0.273114 loss)
I0926 16:04:59.884191  4911 sgd_solver.cpp:105] Iteration 28400, lr = 1e-05
I0926 16:05:13.779700  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 16:05:14.363448  4911 solver.cpp:330] Iteration 28500, Testing net (#0)
I0926 16:05:17.777465  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 16:05:17.919790  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8614
I0926 16:05:17.919826  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.402257 (* 1 = 0.402257 loss)
I0926 16:05:18.065337  4911 solver.cpp:218] Iteration 28500 (5.50021 iter/s, 18.1811s/100 iters), loss = 0.254605
I0926 16:05:18.065368  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254605 (* 1 = 0.254605 loss)
I0926 16:05:18.065376  4911 sgd_solver.cpp:105] Iteration 28500, lr = 1e-05
I0926 16:05:32.664084  4911 solver.cpp:218] Iteration 28600 (6.84993 iter/s, 14.5987s/100 iters), loss = 0.30913
I0926 16:05:32.664125  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30913 (* 1 = 0.30913 loss)
I0926 16:05:32.664131  4911 sgd_solver.cpp:105] Iteration 28600, lr = 1e-05
I0926 16:05:47.263197  4911 solver.cpp:218] Iteration 28700 (6.84977 iter/s, 14.599s/100 iters), loss = 0.299866
I0926 16:05:47.263331  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299865 (* 1 = 0.299865 loss)
I0926 16:05:47.263339  4911 sgd_solver.cpp:105] Iteration 28700, lr = 1e-05
I0926 16:06:01.858970  4911 solver.cpp:218] Iteration 28800 (6.85138 iter/s, 14.5956s/100 iters), loss = 0.315203
I0926 16:06:01.859002  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315202 (* 1 = 0.315202 loss)
I0926 16:06:01.859009  4911 sgd_solver.cpp:105] Iteration 28800, lr = 1e-05
I0926 16:06:16.458353  4911 solver.cpp:218] Iteration 28900 (6.84964 iter/s, 14.5993s/100 iters), loss = 0.304035
I0926 16:06:16.458384  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304035 (* 1 = 0.304035 loss)
I0926 16:06:16.458400  4911 sgd_solver.cpp:105] Iteration 28900, lr = 1e-05
I0926 16:06:30.330140  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 16:06:30.914013  4911 solver.cpp:330] Iteration 29000, Testing net (#0)
I0926 16:06:34.328291  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 16:06:34.470903  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8619
I0926 16:06:34.470938  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.402308 (* 1 = 0.402308 loss)
I0926 16:06:34.615334  4911 solver.cpp:218] Iteration 29000 (5.50755 iter/s, 18.1569s/100 iters), loss = 0.255367
I0926 16:06:34.615365  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255367 (* 1 = 0.255367 loss)
I0926 16:06:34.615371  4911 sgd_solver.cpp:105] Iteration 29000, lr = 1e-05
I0926 16:06:49.282011  4911 solver.cpp:218] Iteration 29100 (6.81821 iter/s, 14.6666s/100 iters), loss = 0.244476
I0926 16:06:49.282057  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244476 (* 1 = 0.244476 loss)
I0926 16:06:49.282065  4911 sgd_solver.cpp:105] Iteration 29100, lr = 1e-05
I0926 16:07:04.203531  4911 solver.cpp:218] Iteration 29200 (6.70177 iter/s, 14.9214s/100 iters), loss = 0.33996
I0926 16:07:04.203640  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.33996 (* 1 = 0.33996 loss)
I0926 16:07:04.203660  4911 sgd_solver.cpp:105] Iteration 29200, lr = 1e-05
I0926 16:07:19.183513  4911 solver.cpp:218] Iteration 29300 (6.67564 iter/s, 14.9798s/100 iters), loss = 0.319206
I0926 16:07:19.183547  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319206 (* 1 = 0.319206 loss)
I0926 16:07:19.183555  4911 sgd_solver.cpp:105] Iteration 29300, lr = 1e-05
I0926 16:07:34.163345  4911 solver.cpp:218] Iteration 29400 (6.67568 iter/s, 14.9798s/100 iters), loss = 0.323696
I0926 16:07:34.163394  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323696 (* 1 = 0.323696 loss)
I0926 16:07:34.163405  4911 sgd_solver.cpp:105] Iteration 29400, lr = 1e-05
I0926 16:07:48.421149  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 16:07:49.049245  4911 solver.cpp:330] Iteration 29500, Testing net (#0)
I0926 16:07:52.684917  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 16:07:52.835724  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8625
I0926 16:07:52.835758  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.402198 (* 1 = 0.402198 loss)
I0926 16:07:52.987543  4911 solver.cpp:218] Iteration 29500 (5.31234 iter/s, 18.8241s/100 iters), loss = 0.247007
I0926 16:07:52.987581  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247006 (* 1 = 0.247006 loss)
I0926 16:07:52.987601  4911 sgd_solver.cpp:105] Iteration 29500, lr = 1e-05
I0926 16:08:08.701529  4911 solver.cpp:218] Iteration 29600 (6.3638 iter/s, 15.7139s/100 iters), loss = 0.260512
I0926 16:08:08.701568  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260512 (* 1 = 0.260512 loss)
I0926 16:08:08.701575  4911 sgd_solver.cpp:105] Iteration 29600, lr = 1e-05
I0926 16:08:24.217676  4911 solver.cpp:218] Iteration 29700 (6.44495 iter/s, 15.516s/100 iters), loss = 0.283825
I0926 16:08:24.217803  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283825 (* 1 = 0.283825 loss)
I0926 16:08:24.217818  4911 sgd_solver.cpp:105] Iteration 29700, lr = 1e-05
I0926 16:08:39.893193  4911 solver.cpp:218] Iteration 29800 (6.37944 iter/s, 15.6753s/100 iters), loss = 0.319272
I0926 16:08:39.893291  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319272 (* 1 = 0.319272 loss)
I0926 16:08:39.893319  4911 sgd_solver.cpp:105] Iteration 29800, lr = 1e-05
I0926 16:08:55.652840  4911 solver.cpp:218] Iteration 29900 (6.34538 iter/s, 15.7595s/100 iters), loss = 0.267947
I0926 16:08:55.652981  4911 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267947 (* 1 = 0.267947 loss)
I0926 16:08:55.652992  4911 sgd_solver.cpp:105] Iteration 29900, lr = 1e-05
I0926 16:09:10.681607  4919 data_layer.cpp:73] Restarting data prefetching from start.
I0926 16:09:11.311344  4911 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res56_penlu_alpha2w_eta1w_gauss_iter_30000.caffemodel
I0926 16:09:11.360281  4911 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res56_penlu_alpha2w_eta1w_gauss_iter_30000.solverstate
I0926 16:09:11.405694  4911 solver.cpp:310] Iteration 30000, loss = 0.239255
I0926 16:09:11.405746  4911 solver.cpp:330] Iteration 30000, Testing net (#0)
I0926 16:09:15.082540  4920 data_layer.cpp:73] Restarting data prefetching from start.
I0926 16:09:15.234436  4911 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8617
I0926 16:09:15.234473  4911 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.402339 (* 1 = 0.402339 loss)
I0926 16:09:15.234480  4911 solver.cpp:315] Optimization Done.
I0926 16:09:15.234483  4911 caffe.cpp:259] Optimization Done.
