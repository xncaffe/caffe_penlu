I0924 21:06:08.643461  2642 caffe.cpp:218] Using GPUs 0
I0924 21:06:08.868567  2642 caffe.cpp:223] GPU 0: GeForce GTX 1080
I0924 21:06:10.794278  2642 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res56_relu"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res56_cifar_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I0924 21:06:10.802347  2642 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56_cifar_train_test.prototxt
I0924 21:06:10.817225  2642 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56_cifar_train_test.prototxt
I0924 21:06:10.817286  2642 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0924 21:06:10.818590  2642 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I0924 21:06:10.818996  2642 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I0924 21:06:10.823436  2642 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution21"
  top: "Convolution21"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution23"
  top: "Convolution23"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution24"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution25"
  top: "Convolution25"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution26"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution27"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "Convolution27"
  top: "Convolution27"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Convolution27"
  top: "Convolution28"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution28"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution29"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "Convolution29"
  top: "Convolution29"
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Convolution29"
  top: "Convolution30"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution30"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Eltwise14"
  top: "Convolution31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "Convolution31"
  top: "Convolution31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU30"
  type: "ReLU"
  bottom: "Convolution31"
  top: "Convolution31"
}
layer {
  name: "Convolution32"
  type: "Convolution"
  bottom: "Convolution31"
  top: "Convolution32"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "c
I0924 21:06:10.825698  2642 layer_factory.hpp:77] Creating layer Data1
I0924 21:06:10.886000  2642 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I0924 21:06:10.907925  2642 net.cpp:84] Creating Layer Data1
I0924 21:06:10.907939  2642 net.cpp:380] Data1 -> Data1
I0924 21:06:10.921319  2642 net.cpp:380] Data1 -> Data2
I0924 21:06:10.921337  2642 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0924 21:06:10.923339  2642 data_layer.cpp:45] output data size: 100,3,28,28
I0924 21:06:10.925916  2642 net.cpp:122] Setting up Data1
I0924 21:06:10.925935  2642 net.cpp:129] Top shape: 100 3 28 28 (235200)
I0924 21:06:10.925940  2642 net.cpp:129] Top shape: 100 (100)
I0924 21:06:10.925942  2642 net.cpp:137] Memory required for data: 941200
I0924 21:06:10.925951  2642 layer_factory.hpp:77] Creating layer Convolution1
I0924 21:06:10.926544  2642 net.cpp:84] Creating Layer Convolution1
I0924 21:06:10.926556  2642 net.cpp:406] Convolution1 <- Data1
I0924 21:06:10.926568  2642 net.cpp:380] Convolution1 -> Convolution1
I0924 21:06:13.593547  2642 net.cpp:122] Setting up Convolution1
I0924 21:06:13.593576  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.593581  2642 net.cpp:137] Memory required for data: 5958800
I0924 21:06:13.593600  2642 layer_factory.hpp:77] Creating layer BatchNorm1
I0924 21:06:13.593612  2642 net.cpp:84] Creating Layer BatchNorm1
I0924 21:06:13.593618  2642 net.cpp:406] BatchNorm1 <- Convolution1
I0924 21:06:13.593642  2642 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0924 21:06:13.593828  2642 net.cpp:122] Setting up BatchNorm1
I0924 21:06:13.593837  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.593840  2642 net.cpp:137] Memory required for data: 10976400
I0924 21:06:13.593852  2642 layer_factory.hpp:77] Creating layer Scale1
I0924 21:06:13.593863  2642 net.cpp:84] Creating Layer Scale1
I0924 21:06:13.593868  2642 net.cpp:406] Scale1 <- Convolution1
I0924 21:06:13.593873  2642 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0924 21:06:13.593916  2642 layer_factory.hpp:77] Creating layer Scale1
I0924 21:06:13.611248  2642 net.cpp:122] Setting up Scale1
I0924 21:06:13.611260  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.611263  2642 net.cpp:137] Memory required for data: 15994000
I0924 21:06:13.611268  2642 layer_factory.hpp:77] Creating layer ReLU1
I0924 21:06:13.611275  2642 net.cpp:84] Creating Layer ReLU1
I0924 21:06:13.611279  2642 net.cpp:406] ReLU1 <- Convolution1
I0924 21:06:13.611282  2642 net.cpp:367] ReLU1 -> Convolution1 (in-place)
I0924 21:06:13.611423  2642 net.cpp:122] Setting up ReLU1
I0924 21:06:13.611433  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.611435  2642 net.cpp:137] Memory required for data: 21011600
I0924 21:06:13.611438  2642 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0924 21:06:13.615128  2642 net.cpp:84] Creating Layer Convolution1_ReLU1_0_split
I0924 21:06:13.615139  2642 net.cpp:406] Convolution1_ReLU1_0_split <- Convolution1
I0924 21:06:13.615142  2642 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0924 21:06:13.615149  2642 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0924 21:06:13.615185  2642 net.cpp:122] Setting up Convolution1_ReLU1_0_split
I0924 21:06:13.615196  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.615203  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.615206  2642 net.cpp:137] Memory required for data: 31046800
I0924 21:06:13.615208  2642 layer_factory.hpp:77] Creating layer Convolution2
I0924 21:06:13.615217  2642 net.cpp:84] Creating Layer Convolution2
I0924 21:06:13.615221  2642 net.cpp:406] Convolution2 <- Convolution1_ReLU1_0_split_0
I0924 21:06:13.615226  2642 net.cpp:380] Convolution2 -> Convolution2
I0924 21:06:13.632261  2642 net.cpp:122] Setting up Convolution2
I0924 21:06:13.632273  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.632277  2642 net.cpp:137] Memory required for data: 36064400
I0924 21:06:13.632284  2642 layer_factory.hpp:77] Creating layer BatchNorm2
I0924 21:06:13.632290  2642 net.cpp:84] Creating Layer BatchNorm2
I0924 21:06:13.632293  2642 net.cpp:406] BatchNorm2 <- Convolution2
I0924 21:06:13.632297  2642 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0924 21:06:13.632441  2642 net.cpp:122] Setting up BatchNorm2
I0924 21:06:13.632449  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.632452  2642 net.cpp:137] Memory required for data: 41082000
I0924 21:06:13.632457  2642 layer_factory.hpp:77] Creating layer Scale2
I0924 21:06:13.632463  2642 net.cpp:84] Creating Layer Scale2
I0924 21:06:13.632467  2642 net.cpp:406] Scale2 <- Convolution2
I0924 21:06:13.632472  2642 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0924 21:06:13.632509  2642 layer_factory.hpp:77] Creating layer Scale2
I0924 21:06:13.632596  2642 net.cpp:122] Setting up Scale2
I0924 21:06:13.632603  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.632606  2642 net.cpp:137] Memory required for data: 46099600
I0924 21:06:13.632611  2642 layer_factory.hpp:77] Creating layer ReLU2
I0924 21:06:13.632616  2642 net.cpp:84] Creating Layer ReLU2
I0924 21:06:13.632617  2642 net.cpp:406] ReLU2 <- Convolution2
I0924 21:06:13.632622  2642 net.cpp:367] ReLU2 -> Convolution2 (in-place)
I0924 21:06:13.633116  2642 net.cpp:122] Setting up ReLU2
I0924 21:06:13.633126  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.633138  2642 net.cpp:137] Memory required for data: 51117200
I0924 21:06:13.633142  2642 layer_factory.hpp:77] Creating layer Convolution3
I0924 21:06:13.633152  2642 net.cpp:84] Creating Layer Convolution3
I0924 21:06:13.633159  2642 net.cpp:406] Convolution3 <- Convolution2
I0924 21:06:13.633167  2642 net.cpp:380] Convolution3 -> Convolution3
I0924 21:06:13.633705  2642 net.cpp:122] Setting up Convolution3
I0924 21:06:13.633714  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.633728  2642 net.cpp:137] Memory required for data: 56134800
I0924 21:06:13.633733  2642 layer_factory.hpp:77] Creating layer BatchNorm3
I0924 21:06:13.633738  2642 net.cpp:84] Creating Layer BatchNorm3
I0924 21:06:13.633744  2642 net.cpp:406] BatchNorm3 <- Convolution3
I0924 21:06:13.633764  2642 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0924 21:06:13.633904  2642 net.cpp:122] Setting up BatchNorm3
I0924 21:06:13.633911  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.633924  2642 net.cpp:137] Memory required for data: 61152400
I0924 21:06:13.633930  2642 layer_factory.hpp:77] Creating layer Scale3
I0924 21:06:13.633945  2642 net.cpp:84] Creating Layer Scale3
I0924 21:06:13.633949  2642 net.cpp:406] Scale3 <- Convolution3
I0924 21:06:13.633952  2642 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0924 21:06:13.634006  2642 layer_factory.hpp:77] Creating layer Scale3
I0924 21:06:13.634100  2642 net.cpp:122] Setting up Scale3
I0924 21:06:13.634106  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.634110  2642 net.cpp:137] Memory required for data: 66170000
I0924 21:06:13.634117  2642 layer_factory.hpp:77] Creating layer Eltwise1
I0924 21:06:13.634125  2642 net.cpp:84] Creating Layer Eltwise1
I0924 21:06:13.634143  2642 net.cpp:406] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0924 21:06:13.634150  2642 net.cpp:406] Eltwise1 <- Convolution3
I0924 21:06:13.634157  2642 net.cpp:380] Eltwise1 -> Eltwise1
I0924 21:06:13.634203  2642 net.cpp:122] Setting up Eltwise1
I0924 21:06:13.634218  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.634222  2642 net.cpp:137] Memory required for data: 71187600
I0924 21:06:13.634234  2642 layer_factory.hpp:77] Creating layer ReLU3
I0924 21:06:13.634239  2642 net.cpp:84] Creating Layer ReLU3
I0924 21:06:13.634243  2642 net.cpp:406] ReLU3 <- Eltwise1
I0924 21:06:13.634250  2642 net.cpp:367] ReLU3 -> Eltwise1 (in-place)
I0924 21:06:13.634698  2642 net.cpp:122] Setting up ReLU3
I0924 21:06:13.634708  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.634711  2642 net.cpp:137] Memory required for data: 76205200
I0924 21:06:13.634714  2642 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0924 21:06:13.634719  2642 net.cpp:84] Creating Layer Eltwise1_ReLU3_0_split
I0924 21:06:13.634722  2642 net.cpp:406] Eltwise1_ReLU3_0_split <- Eltwise1
I0924 21:06:13.634727  2642 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0924 21:06:13.634732  2642 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0924 21:06:13.634759  2642 net.cpp:122] Setting up Eltwise1_ReLU3_0_split
I0924 21:06:13.634764  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.634768  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.634770  2642 net.cpp:137] Memory required for data: 86240400
I0924 21:06:13.634773  2642 layer_factory.hpp:77] Creating layer Convolution4
I0924 21:06:13.634781  2642 net.cpp:84] Creating Layer Convolution4
I0924 21:06:13.634784  2642 net.cpp:406] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0924 21:06:13.634788  2642 net.cpp:380] Convolution4 -> Convolution4
I0924 21:06:13.635651  2642 net.cpp:122] Setting up Convolution4
I0924 21:06:13.635661  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.635665  2642 net.cpp:137] Memory required for data: 91258000
I0924 21:06:13.635670  2642 layer_factory.hpp:77] Creating layer BatchNorm4
I0924 21:06:13.635675  2642 net.cpp:84] Creating Layer BatchNorm4
I0924 21:06:13.635679  2642 net.cpp:406] BatchNorm4 <- Convolution4
I0924 21:06:13.635690  2642 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0924 21:06:13.635818  2642 net.cpp:122] Setting up BatchNorm4
I0924 21:06:13.635823  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.635826  2642 net.cpp:137] Memory required for data: 96275600
I0924 21:06:13.635831  2642 layer_factory.hpp:77] Creating layer Scale4
I0924 21:06:13.635836  2642 net.cpp:84] Creating Layer Scale4
I0924 21:06:13.635839  2642 net.cpp:406] Scale4 <- Convolution4
I0924 21:06:13.635843  2642 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0924 21:06:13.635869  2642 layer_factory.hpp:77] Creating layer Scale4
I0924 21:06:13.635941  2642 net.cpp:122] Setting up Scale4
I0924 21:06:13.635946  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.635949  2642 net.cpp:137] Memory required for data: 101293200
I0924 21:06:13.635953  2642 layer_factory.hpp:77] Creating layer ReLU4
I0924 21:06:13.635957  2642 net.cpp:84] Creating Layer ReLU4
I0924 21:06:13.635960  2642 net.cpp:406] ReLU4 <- Convolution4
I0924 21:06:13.635964  2642 net.cpp:367] ReLU4 -> Convolution4 (in-place)
I0924 21:06:13.636082  2642 net.cpp:122] Setting up ReLU4
I0924 21:06:13.636090  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.636092  2642 net.cpp:137] Memory required for data: 106310800
I0924 21:06:13.636095  2642 layer_factory.hpp:77] Creating layer Convolution5
I0924 21:06:13.636103  2642 net.cpp:84] Creating Layer Convolution5
I0924 21:06:13.636107  2642 net.cpp:406] Convolution5 <- Convolution4
I0924 21:06:13.636111  2642 net.cpp:380] Convolution5 -> Convolution5
I0924 21:06:13.637006  2642 net.cpp:122] Setting up Convolution5
I0924 21:06:13.637017  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.637019  2642 net.cpp:137] Memory required for data: 111328400
I0924 21:06:13.637024  2642 layer_factory.hpp:77] Creating layer BatchNorm5
I0924 21:06:13.637029  2642 net.cpp:84] Creating Layer BatchNorm5
I0924 21:06:13.637033  2642 net.cpp:406] BatchNorm5 <- Convolution5
I0924 21:06:13.637039  2642 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0924 21:06:13.637169  2642 net.cpp:122] Setting up BatchNorm5
I0924 21:06:13.637174  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.637177  2642 net.cpp:137] Memory required for data: 116346000
I0924 21:06:13.637187  2642 layer_factory.hpp:77] Creating layer Scale5
I0924 21:06:13.637192  2642 net.cpp:84] Creating Layer Scale5
I0924 21:06:13.637194  2642 net.cpp:406] Scale5 <- Convolution5
I0924 21:06:13.637197  2642 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0924 21:06:13.637225  2642 layer_factory.hpp:77] Creating layer Scale5
I0924 21:06:13.637303  2642 net.cpp:122] Setting up Scale5
I0924 21:06:13.637308  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.637311  2642 net.cpp:137] Memory required for data: 121363600
I0924 21:06:13.637315  2642 layer_factory.hpp:77] Creating layer Eltwise2
I0924 21:06:13.637320  2642 net.cpp:84] Creating Layer Eltwise2
I0924 21:06:13.637323  2642 net.cpp:406] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0924 21:06:13.637326  2642 net.cpp:406] Eltwise2 <- Convolution5
I0924 21:06:13.637331  2642 net.cpp:380] Eltwise2 -> Eltwise2
I0924 21:06:13.637346  2642 net.cpp:122] Setting up Eltwise2
I0924 21:06:13.637351  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.637353  2642 net.cpp:137] Memory required for data: 126381200
I0924 21:06:13.637356  2642 layer_factory.hpp:77] Creating layer ReLU5
I0924 21:06:13.637359  2642 net.cpp:84] Creating Layer ReLU5
I0924 21:06:13.637362  2642 net.cpp:406] ReLU5 <- Eltwise2
I0924 21:06:13.637365  2642 net.cpp:367] ReLU5 -> Eltwise2 (in-place)
I0924 21:06:13.637482  2642 net.cpp:122] Setting up ReLU5
I0924 21:06:13.637490  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.637493  2642 net.cpp:137] Memory required for data: 131398800
I0924 21:06:13.637495  2642 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0924 21:06:13.637501  2642 net.cpp:84] Creating Layer Eltwise2_ReLU5_0_split
I0924 21:06:13.637509  2642 net.cpp:406] Eltwise2_ReLU5_0_split <- Eltwise2
I0924 21:06:13.637513  2642 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0924 21:06:13.637518  2642 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0924 21:06:13.637547  2642 net.cpp:122] Setting up Eltwise2_ReLU5_0_split
I0924 21:06:13.637552  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.637554  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.637557  2642 net.cpp:137] Memory required for data: 141434000
I0924 21:06:13.637560  2642 layer_factory.hpp:77] Creating layer Convolution6
I0924 21:06:13.637567  2642 net.cpp:84] Creating Layer Convolution6
I0924 21:06:13.637570  2642 net.cpp:406] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0924 21:06:13.637575  2642 net.cpp:380] Convolution6 -> Convolution6
I0924 21:06:13.638468  2642 net.cpp:122] Setting up Convolution6
I0924 21:06:13.638478  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.638481  2642 net.cpp:137] Memory required for data: 146451600
I0924 21:06:13.638485  2642 layer_factory.hpp:77] Creating layer BatchNorm6
I0924 21:06:13.638492  2642 net.cpp:84] Creating Layer BatchNorm6
I0924 21:06:13.638495  2642 net.cpp:406] BatchNorm6 <- Convolution6
I0924 21:06:13.638500  2642 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0924 21:06:13.638633  2642 net.cpp:122] Setting up BatchNorm6
I0924 21:06:13.638638  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.638640  2642 net.cpp:137] Memory required for data: 151469200
I0924 21:06:13.638645  2642 layer_factory.hpp:77] Creating layer Scale6
I0924 21:06:13.638650  2642 net.cpp:84] Creating Layer Scale6
I0924 21:06:13.638653  2642 net.cpp:406] Scale6 <- Convolution6
I0924 21:06:13.638659  2642 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0924 21:06:13.638685  2642 layer_factory.hpp:77] Creating layer Scale6
I0924 21:06:13.638764  2642 net.cpp:122] Setting up Scale6
I0924 21:06:13.638769  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.638772  2642 net.cpp:137] Memory required for data: 156486800
I0924 21:06:13.638777  2642 layer_factory.hpp:77] Creating layer ReLU6
I0924 21:06:13.638780  2642 net.cpp:84] Creating Layer ReLU6
I0924 21:06:13.638783  2642 net.cpp:406] ReLU6 <- Convolution6
I0924 21:06:13.638787  2642 net.cpp:367] ReLU6 -> Convolution6 (in-place)
I0924 21:06:13.638903  2642 net.cpp:122] Setting up ReLU6
I0924 21:06:13.638909  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.638912  2642 net.cpp:137] Memory required for data: 161504400
I0924 21:06:13.638916  2642 layer_factory.hpp:77] Creating layer Convolution7
I0924 21:06:13.638923  2642 net.cpp:84] Creating Layer Convolution7
I0924 21:06:13.638927  2642 net.cpp:406] Convolution7 <- Convolution6
I0924 21:06:13.638931  2642 net.cpp:380] Convolution7 -> Convolution7
I0924 21:06:13.639832  2642 net.cpp:122] Setting up Convolution7
I0924 21:06:13.639844  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.639847  2642 net.cpp:137] Memory required for data: 166522000
I0924 21:06:13.639853  2642 layer_factory.hpp:77] Creating layer BatchNorm7
I0924 21:06:13.639858  2642 net.cpp:84] Creating Layer BatchNorm7
I0924 21:06:13.639863  2642 net.cpp:406] BatchNorm7 <- Convolution7
I0924 21:06:13.639866  2642 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0924 21:06:13.639999  2642 net.cpp:122] Setting up BatchNorm7
I0924 21:06:13.640005  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.640008  2642 net.cpp:137] Memory required for data: 171539600
I0924 21:06:13.640013  2642 layer_factory.hpp:77] Creating layer Scale7
I0924 21:06:13.640019  2642 net.cpp:84] Creating Layer Scale7
I0924 21:06:13.640023  2642 net.cpp:406] Scale7 <- Convolution7
I0924 21:06:13.640027  2642 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0924 21:06:13.640054  2642 layer_factory.hpp:77] Creating layer Scale7
I0924 21:06:13.640131  2642 net.cpp:122] Setting up Scale7
I0924 21:06:13.640137  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.640147  2642 net.cpp:137] Memory required for data: 176557200
I0924 21:06:13.640151  2642 layer_factory.hpp:77] Creating layer Eltwise3
I0924 21:06:13.640156  2642 net.cpp:84] Creating Layer Eltwise3
I0924 21:06:13.640161  2642 net.cpp:406] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0924 21:06:13.640163  2642 net.cpp:406] Eltwise3 <- Convolution7
I0924 21:06:13.640167  2642 net.cpp:380] Eltwise3 -> Eltwise3
I0924 21:06:13.640184  2642 net.cpp:122] Setting up Eltwise3
I0924 21:06:13.640189  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.640192  2642 net.cpp:137] Memory required for data: 181574800
I0924 21:06:13.640194  2642 layer_factory.hpp:77] Creating layer ReLU7
I0924 21:06:13.640198  2642 net.cpp:84] Creating Layer ReLU7
I0924 21:06:13.640202  2642 net.cpp:406] ReLU7 <- Eltwise3
I0924 21:06:13.640204  2642 net.cpp:367] ReLU7 -> Eltwise3 (in-place)
I0924 21:06:13.640322  2642 net.cpp:122] Setting up ReLU7
I0924 21:06:13.640329  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.640332  2642 net.cpp:137] Memory required for data: 186592400
I0924 21:06:13.640336  2642 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0924 21:06:13.640341  2642 net.cpp:84] Creating Layer Eltwise3_ReLU7_0_split
I0924 21:06:13.640343  2642 net.cpp:406] Eltwise3_ReLU7_0_split <- Eltwise3
I0924 21:06:13.640347  2642 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0924 21:06:13.640352  2642 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0924 21:06:13.640378  2642 net.cpp:122] Setting up Eltwise3_ReLU7_0_split
I0924 21:06:13.640383  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.640386  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.640389  2642 net.cpp:137] Memory required for data: 196627600
I0924 21:06:13.640391  2642 layer_factory.hpp:77] Creating layer Convolution8
I0924 21:06:13.640398  2642 net.cpp:84] Creating Layer Convolution8
I0924 21:06:13.640403  2642 net.cpp:406] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0924 21:06:13.640408  2642 net.cpp:380] Convolution8 -> Convolution8
I0924 21:06:13.641286  2642 net.cpp:122] Setting up Convolution8
I0924 21:06:13.641296  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.641299  2642 net.cpp:137] Memory required for data: 201645200
I0924 21:06:13.641304  2642 layer_factory.hpp:77] Creating layer BatchNorm8
I0924 21:06:13.641310  2642 net.cpp:84] Creating Layer BatchNorm8
I0924 21:06:13.641314  2642 net.cpp:406] BatchNorm8 <- Convolution8
I0924 21:06:13.641319  2642 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0924 21:06:13.641450  2642 net.cpp:122] Setting up BatchNorm8
I0924 21:06:13.641455  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.641458  2642 net.cpp:137] Memory required for data: 206662800
I0924 21:06:13.641463  2642 layer_factory.hpp:77] Creating layer Scale8
I0924 21:06:13.641468  2642 net.cpp:84] Creating Layer Scale8
I0924 21:06:13.641470  2642 net.cpp:406] Scale8 <- Convolution8
I0924 21:06:13.641474  2642 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0924 21:06:13.641500  2642 layer_factory.hpp:77] Creating layer Scale8
I0924 21:06:13.641580  2642 net.cpp:122] Setting up Scale8
I0924 21:06:13.641587  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.641589  2642 net.cpp:137] Memory required for data: 211680400
I0924 21:06:13.641593  2642 layer_factory.hpp:77] Creating layer ReLU8
I0924 21:06:13.641597  2642 net.cpp:84] Creating Layer ReLU8
I0924 21:06:13.641600  2642 net.cpp:406] ReLU8 <- Convolution8
I0924 21:06:13.641605  2642 net.cpp:367] ReLU8 -> Convolution8 (in-place)
I0924 21:06:13.642050  2642 net.cpp:122] Setting up ReLU8
I0924 21:06:13.642060  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.642062  2642 net.cpp:137] Memory required for data: 216698000
I0924 21:06:13.642066  2642 layer_factory.hpp:77] Creating layer Convolution9
I0924 21:06:13.642073  2642 net.cpp:84] Creating Layer Convolution9
I0924 21:06:13.642077  2642 net.cpp:406] Convolution9 <- Convolution8
I0924 21:06:13.642091  2642 net.cpp:380] Convolution9 -> Convolution9
I0924 21:06:13.642668  2642 net.cpp:122] Setting up Convolution9
I0924 21:06:13.642675  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.642678  2642 net.cpp:137] Memory required for data: 221715600
I0924 21:06:13.642683  2642 layer_factory.hpp:77] Creating layer BatchNorm9
I0924 21:06:13.642689  2642 net.cpp:84] Creating Layer BatchNorm9
I0924 21:06:13.642693  2642 net.cpp:406] BatchNorm9 <- Convolution9
I0924 21:06:13.642696  2642 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0924 21:06:13.642828  2642 net.cpp:122] Setting up BatchNorm9
I0924 21:06:13.642833  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.642837  2642 net.cpp:137] Memory required for data: 226733200
I0924 21:06:13.642841  2642 layer_factory.hpp:77] Creating layer Scale9
I0924 21:06:13.642846  2642 net.cpp:84] Creating Layer Scale9
I0924 21:06:13.642849  2642 net.cpp:406] Scale9 <- Convolution9
I0924 21:06:13.642853  2642 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0924 21:06:13.642879  2642 layer_factory.hpp:77] Creating layer Scale9
I0924 21:06:13.642958  2642 net.cpp:122] Setting up Scale9
I0924 21:06:13.642963  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.642966  2642 net.cpp:137] Memory required for data: 231750800
I0924 21:06:13.642971  2642 layer_factory.hpp:77] Creating layer Eltwise4
I0924 21:06:13.642976  2642 net.cpp:84] Creating Layer Eltwise4
I0924 21:06:13.642979  2642 net.cpp:406] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I0924 21:06:13.642982  2642 net.cpp:406] Eltwise4 <- Convolution9
I0924 21:06:13.642987  2642 net.cpp:380] Eltwise4 -> Eltwise4
I0924 21:06:13.643003  2642 net.cpp:122] Setting up Eltwise4
I0924 21:06:13.643008  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.643012  2642 net.cpp:137] Memory required for data: 236768400
I0924 21:06:13.643013  2642 layer_factory.hpp:77] Creating layer ReLU9
I0924 21:06:13.643018  2642 net.cpp:84] Creating Layer ReLU9
I0924 21:06:13.643020  2642 net.cpp:406] ReLU9 <- Eltwise4
I0924 21:06:13.643024  2642 net.cpp:367] ReLU9 -> Eltwise4 (in-place)
I0924 21:06:13.643468  2642 net.cpp:122] Setting up ReLU9
I0924 21:06:13.643478  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.643481  2642 net.cpp:137] Memory required for data: 241786000
I0924 21:06:13.643484  2642 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0924 21:06:13.643489  2642 net.cpp:84] Creating Layer Eltwise4_ReLU9_0_split
I0924 21:06:13.643493  2642 net.cpp:406] Eltwise4_ReLU9_0_split <- Eltwise4
I0924 21:06:13.643496  2642 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0924 21:06:13.643502  2642 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0924 21:06:13.643530  2642 net.cpp:122] Setting up Eltwise4_ReLU9_0_split
I0924 21:06:13.643535  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.643538  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.643541  2642 net.cpp:137] Memory required for data: 251821200
I0924 21:06:13.643543  2642 layer_factory.hpp:77] Creating layer Convolution10
I0924 21:06:13.643550  2642 net.cpp:84] Creating Layer Convolution10
I0924 21:06:13.643554  2642 net.cpp:406] Convolution10 <- Eltwise4_ReLU9_0_split_0
I0924 21:06:13.643559  2642 net.cpp:380] Convolution10 -> Convolution10
I0924 21:06:13.644456  2642 net.cpp:122] Setting up Convolution10
I0924 21:06:13.644466  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.644469  2642 net.cpp:137] Memory required for data: 256838800
I0924 21:06:13.644480  2642 layer_factory.hpp:77] Creating layer BatchNorm10
I0924 21:06:13.644486  2642 net.cpp:84] Creating Layer BatchNorm10
I0924 21:06:13.644490  2642 net.cpp:406] BatchNorm10 <- Convolution10
I0924 21:06:13.644495  2642 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0924 21:06:13.644629  2642 net.cpp:122] Setting up BatchNorm10
I0924 21:06:13.644634  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.644636  2642 net.cpp:137] Memory required for data: 261856400
I0924 21:06:13.644649  2642 layer_factory.hpp:77] Creating layer Scale10
I0924 21:06:13.644654  2642 net.cpp:84] Creating Layer Scale10
I0924 21:06:13.644657  2642 net.cpp:406] Scale10 <- Convolution10
I0924 21:06:13.644661  2642 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0924 21:06:13.644688  2642 layer_factory.hpp:77] Creating layer Scale10
I0924 21:06:13.644767  2642 net.cpp:122] Setting up Scale10
I0924 21:06:13.644771  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.644774  2642 net.cpp:137] Memory required for data: 266874000
I0924 21:06:13.644778  2642 layer_factory.hpp:77] Creating layer ReLU10
I0924 21:06:13.644783  2642 net.cpp:84] Creating Layer ReLU10
I0924 21:06:13.644785  2642 net.cpp:406] ReLU10 <- Convolution10
I0924 21:06:13.644789  2642 net.cpp:367] ReLU10 -> Convolution10 (in-place)
I0924 21:06:13.644909  2642 net.cpp:122] Setting up ReLU10
I0924 21:06:13.644920  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.644923  2642 net.cpp:137] Memory required for data: 271891600
I0924 21:06:13.644927  2642 layer_factory.hpp:77] Creating layer Convolution11
I0924 21:06:13.644933  2642 net.cpp:84] Creating Layer Convolution11
I0924 21:06:13.644937  2642 net.cpp:406] Convolution11 <- Convolution10
I0924 21:06:13.644942  2642 net.cpp:380] Convolution11 -> Convolution11
I0924 21:06:13.645843  2642 net.cpp:122] Setting up Convolution11
I0924 21:06:13.645853  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.645855  2642 net.cpp:137] Memory required for data: 276909200
I0924 21:06:13.645859  2642 layer_factory.hpp:77] Creating layer BatchNorm11
I0924 21:06:13.645865  2642 net.cpp:84] Creating Layer BatchNorm11
I0924 21:06:13.645867  2642 net.cpp:406] BatchNorm11 <- Convolution11
I0924 21:06:13.645872  2642 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0924 21:06:13.646005  2642 net.cpp:122] Setting up BatchNorm11
I0924 21:06:13.646010  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.646013  2642 net.cpp:137] Memory required for data: 281926800
I0924 21:06:13.646018  2642 layer_factory.hpp:77] Creating layer Scale11
I0924 21:06:13.646023  2642 net.cpp:84] Creating Layer Scale11
I0924 21:06:13.646025  2642 net.cpp:406] Scale11 <- Convolution11
I0924 21:06:13.646028  2642 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0924 21:06:13.646055  2642 layer_factory.hpp:77] Creating layer Scale11
I0924 21:06:13.646132  2642 net.cpp:122] Setting up Scale11
I0924 21:06:13.646136  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.646138  2642 net.cpp:137] Memory required for data: 286944400
I0924 21:06:13.646142  2642 layer_factory.hpp:77] Creating layer Eltwise5
I0924 21:06:13.646147  2642 net.cpp:84] Creating Layer Eltwise5
I0924 21:06:13.646149  2642 net.cpp:406] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I0924 21:06:13.646152  2642 net.cpp:406] Eltwise5 <- Convolution11
I0924 21:06:13.646155  2642 net.cpp:380] Eltwise5 -> Eltwise5
I0924 21:06:13.646173  2642 net.cpp:122] Setting up Eltwise5
I0924 21:06:13.646175  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.646178  2642 net.cpp:137] Memory required for data: 291962000
I0924 21:06:13.646180  2642 layer_factory.hpp:77] Creating layer ReLU11
I0924 21:06:13.646183  2642 net.cpp:84] Creating Layer ReLU11
I0924 21:06:13.646185  2642 net.cpp:406] ReLU11 <- Eltwise5
I0924 21:06:13.646189  2642 net.cpp:367] ReLU11 -> Eltwise5 (in-place)
I0924 21:06:13.646306  2642 net.cpp:122] Setting up ReLU11
I0924 21:06:13.646312  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.646315  2642 net.cpp:137] Memory required for data: 296979600
I0924 21:06:13.646317  2642 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0924 21:06:13.646322  2642 net.cpp:84] Creating Layer Eltwise5_ReLU11_0_split
I0924 21:06:13.646323  2642 net.cpp:406] Eltwise5_ReLU11_0_split <- Eltwise5
I0924 21:06:13.646327  2642 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0924 21:06:13.646332  2642 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0924 21:06:13.646365  2642 net.cpp:122] Setting up Eltwise5_ReLU11_0_split
I0924 21:06:13.646370  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.646373  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.646375  2642 net.cpp:137] Memory required for data: 307014800
I0924 21:06:13.646378  2642 layer_factory.hpp:77] Creating layer Convolution12
I0924 21:06:13.646384  2642 net.cpp:84] Creating Layer Convolution12
I0924 21:06:13.646386  2642 net.cpp:406] Convolution12 <- Eltwise5_ReLU11_0_split_0
I0924 21:06:13.646391  2642 net.cpp:380] Convolution12 -> Convolution12
I0924 21:06:13.647294  2642 net.cpp:122] Setting up Convolution12
I0924 21:06:13.647302  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.647305  2642 net.cpp:137] Memory required for data: 312032400
I0924 21:06:13.647310  2642 layer_factory.hpp:77] Creating layer BatchNorm12
I0924 21:06:13.647315  2642 net.cpp:84] Creating Layer BatchNorm12
I0924 21:06:13.647318  2642 net.cpp:406] BatchNorm12 <- Convolution12
I0924 21:06:13.647322  2642 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0924 21:06:13.647454  2642 net.cpp:122] Setting up BatchNorm12
I0924 21:06:13.647457  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.647460  2642 net.cpp:137] Memory required for data: 317050000
I0924 21:06:13.647466  2642 layer_factory.hpp:77] Creating layer Scale12
I0924 21:06:13.647470  2642 net.cpp:84] Creating Layer Scale12
I0924 21:06:13.647472  2642 net.cpp:406] Scale12 <- Convolution12
I0924 21:06:13.647476  2642 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0924 21:06:13.647502  2642 layer_factory.hpp:77] Creating layer Scale12
I0924 21:06:13.647581  2642 net.cpp:122] Setting up Scale12
I0924 21:06:13.647586  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.647588  2642 net.cpp:137] Memory required for data: 322067600
I0924 21:06:13.647593  2642 layer_factory.hpp:77] Creating layer ReLU12
I0924 21:06:13.647596  2642 net.cpp:84] Creating Layer ReLU12
I0924 21:06:13.647598  2642 net.cpp:406] ReLU12 <- Convolution12
I0924 21:06:13.647603  2642 net.cpp:367] ReLU12 -> Convolution12 (in-place)
I0924 21:06:13.647719  2642 net.cpp:122] Setting up ReLU12
I0924 21:06:13.647725  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.647727  2642 net.cpp:137] Memory required for data: 327085200
I0924 21:06:13.647729  2642 layer_factory.hpp:77] Creating layer Convolution13
I0924 21:06:13.647737  2642 net.cpp:84] Creating Layer Convolution13
I0924 21:06:13.647739  2642 net.cpp:406] Convolution13 <- Convolution12
I0924 21:06:13.647744  2642 net.cpp:380] Convolution13 -> Convolution13
I0924 21:06:13.648648  2642 net.cpp:122] Setting up Convolution13
I0924 21:06:13.648658  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.648660  2642 net.cpp:137] Memory required for data: 332102800
I0924 21:06:13.648664  2642 layer_factory.hpp:77] Creating layer BatchNorm13
I0924 21:06:13.648670  2642 net.cpp:84] Creating Layer BatchNorm13
I0924 21:06:13.648672  2642 net.cpp:406] BatchNorm13 <- Convolution13
I0924 21:06:13.648676  2642 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0924 21:06:13.648811  2642 net.cpp:122] Setting up BatchNorm13
I0924 21:06:13.648816  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.648818  2642 net.cpp:137] Memory required for data: 337120400
I0924 21:06:13.648823  2642 layer_factory.hpp:77] Creating layer Scale13
I0924 21:06:13.648828  2642 net.cpp:84] Creating Layer Scale13
I0924 21:06:13.648829  2642 net.cpp:406] Scale13 <- Convolution13
I0924 21:06:13.648833  2642 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0924 21:06:13.648860  2642 layer_factory.hpp:77] Creating layer Scale13
I0924 21:06:13.648955  2642 net.cpp:122] Setting up Scale13
I0924 21:06:13.648962  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.648963  2642 net.cpp:137] Memory required for data: 342138000
I0924 21:06:13.648967  2642 layer_factory.hpp:77] Creating layer Eltwise6
I0924 21:06:13.648978  2642 net.cpp:84] Creating Layer Eltwise6
I0924 21:06:13.648982  2642 net.cpp:406] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0924 21:06:13.648984  2642 net.cpp:406] Eltwise6 <- Convolution13
I0924 21:06:13.648988  2642 net.cpp:380] Eltwise6 -> Eltwise6
I0924 21:06:13.649005  2642 net.cpp:122] Setting up Eltwise6
I0924 21:06:13.649010  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.649013  2642 net.cpp:137] Memory required for data: 347155600
I0924 21:06:13.649014  2642 layer_factory.hpp:77] Creating layer ReLU13
I0924 21:06:13.649021  2642 net.cpp:84] Creating Layer ReLU13
I0924 21:06:13.649024  2642 net.cpp:406] ReLU13 <- Eltwise6
I0924 21:06:13.649027  2642 net.cpp:367] ReLU13 -> Eltwise6 (in-place)
I0924 21:06:13.649147  2642 net.cpp:122] Setting up ReLU13
I0924 21:06:13.649153  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.649157  2642 net.cpp:137] Memory required for data: 352173200
I0924 21:06:13.649159  2642 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0924 21:06:13.649163  2642 net.cpp:84] Creating Layer Eltwise6_ReLU13_0_split
I0924 21:06:13.649165  2642 net.cpp:406] Eltwise6_ReLU13_0_split <- Eltwise6
I0924 21:06:13.649168  2642 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0924 21:06:13.649173  2642 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0924 21:06:13.649199  2642 net.cpp:122] Setting up Eltwise6_ReLU13_0_split
I0924 21:06:13.649202  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.649205  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.649207  2642 net.cpp:137] Memory required for data: 362208400
I0924 21:06:13.649209  2642 layer_factory.hpp:77] Creating layer Convolution14
I0924 21:06:13.649215  2642 net.cpp:84] Creating Layer Convolution14
I0924 21:06:13.649219  2642 net.cpp:406] Convolution14 <- Eltwise6_ReLU13_0_split_0
I0924 21:06:13.649222  2642 net.cpp:380] Convolution14 -> Convolution14
I0924 21:06:13.650140  2642 net.cpp:122] Setting up Convolution14
I0924 21:06:13.650148  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.650151  2642 net.cpp:137] Memory required for data: 367226000
I0924 21:06:13.650156  2642 layer_factory.hpp:77] Creating layer BatchNorm14
I0924 21:06:13.650161  2642 net.cpp:84] Creating Layer BatchNorm14
I0924 21:06:13.650163  2642 net.cpp:406] BatchNorm14 <- Convolution14
I0924 21:06:13.650167  2642 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0924 21:06:13.650302  2642 net.cpp:122] Setting up BatchNorm14
I0924 21:06:13.650306  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.650308  2642 net.cpp:137] Memory required for data: 372243600
I0924 21:06:13.650313  2642 layer_factory.hpp:77] Creating layer Scale14
I0924 21:06:13.650317  2642 net.cpp:84] Creating Layer Scale14
I0924 21:06:13.650321  2642 net.cpp:406] Scale14 <- Convolution14
I0924 21:06:13.650323  2642 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0924 21:06:13.650351  2642 layer_factory.hpp:77] Creating layer Scale14
I0924 21:06:13.650429  2642 net.cpp:122] Setting up Scale14
I0924 21:06:13.650434  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.650435  2642 net.cpp:137] Memory required for data: 377261200
I0924 21:06:13.650439  2642 layer_factory.hpp:77] Creating layer ReLU14
I0924 21:06:13.650444  2642 net.cpp:84] Creating Layer ReLU14
I0924 21:06:13.650446  2642 net.cpp:406] ReLU14 <- Convolution14
I0924 21:06:13.650449  2642 net.cpp:367] ReLU14 -> Convolution14 (in-place)
I0924 21:06:13.650894  2642 net.cpp:122] Setting up ReLU14
I0924 21:06:13.650902  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.650905  2642 net.cpp:137] Memory required for data: 382278800
I0924 21:06:13.650907  2642 layer_factory.hpp:77] Creating layer Convolution15
I0924 21:06:13.650915  2642 net.cpp:84] Creating Layer Convolution15
I0924 21:06:13.650918  2642 net.cpp:406] Convolution15 <- Convolution14
I0924 21:06:13.650923  2642 net.cpp:380] Convolution15 -> Convolution15
I0924 21:06:13.651612  2642 net.cpp:122] Setting up Convolution15
I0924 21:06:13.651630  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.651634  2642 net.cpp:137] Memory required for data: 387296400
I0924 21:06:13.651643  2642 layer_factory.hpp:77] Creating layer BatchNorm15
I0924 21:06:13.651648  2642 net.cpp:84] Creating Layer BatchNorm15
I0924 21:06:13.651654  2642 net.cpp:406] BatchNorm15 <- Convolution15
I0924 21:06:13.651659  2642 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0924 21:06:13.651849  2642 net.cpp:122] Setting up BatchNorm15
I0924 21:06:13.651857  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.651861  2642 net.cpp:137] Memory required for data: 392314000
I0924 21:06:13.651870  2642 layer_factory.hpp:77] Creating layer Scale15
I0924 21:06:13.651875  2642 net.cpp:84] Creating Layer Scale15
I0924 21:06:13.651880  2642 net.cpp:406] Scale15 <- Convolution15
I0924 21:06:13.651885  2642 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0924 21:06:13.651922  2642 layer_factory.hpp:77] Creating layer Scale15
I0924 21:06:13.652035  2642 net.cpp:122] Setting up Scale15
I0924 21:06:13.652043  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.652047  2642 net.cpp:137] Memory required for data: 397331600
I0924 21:06:13.652053  2642 layer_factory.hpp:77] Creating layer Eltwise7
I0924 21:06:13.652060  2642 net.cpp:84] Creating Layer Eltwise7
I0924 21:06:13.652065  2642 net.cpp:406] Eltwise7 <- Eltwise6_ReLU13_0_split_1
I0924 21:06:13.652070  2642 net.cpp:406] Eltwise7 <- Convolution15
I0924 21:06:13.652074  2642 net.cpp:380] Eltwise7 -> Eltwise7
I0924 21:06:13.652096  2642 net.cpp:122] Setting up Eltwise7
I0924 21:06:13.652102  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.652107  2642 net.cpp:137] Memory required for data: 402349200
I0924 21:06:13.652110  2642 layer_factory.hpp:77] Creating layer ReLU15
I0924 21:06:13.652117  2642 net.cpp:84] Creating Layer ReLU15
I0924 21:06:13.652120  2642 net.cpp:406] ReLU15 <- Eltwise7
I0924 21:06:13.652125  2642 net.cpp:367] ReLU15 -> Eltwise7 (in-place)
I0924 21:06:13.652740  2642 net.cpp:122] Setting up ReLU15
I0924 21:06:13.652751  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.652756  2642 net.cpp:137] Memory required for data: 407366800
I0924 21:06:13.652760  2642 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0924 21:06:13.652768  2642 net.cpp:84] Creating Layer Eltwise7_ReLU15_0_split
I0924 21:06:13.652773  2642 net.cpp:406] Eltwise7_ReLU15_0_split <- Eltwise7
I0924 21:06:13.652779  2642 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0924 21:06:13.652787  2642 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0924 21:06:13.652830  2642 net.cpp:122] Setting up Eltwise7_ReLU15_0_split
I0924 21:06:13.652837  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.652842  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.652846  2642 net.cpp:137] Memory required for data: 417402000
I0924 21:06:13.652850  2642 layer_factory.hpp:77] Creating layer Convolution16
I0924 21:06:13.652860  2642 net.cpp:84] Creating Layer Convolution16
I0924 21:06:13.652864  2642 net.cpp:406] Convolution16 <- Eltwise7_ReLU15_0_split_0
I0924 21:06:13.652873  2642 net.cpp:380] Convolution16 -> Convolution16
I0924 21:06:13.654517  2642 net.cpp:122] Setting up Convolution16
I0924 21:06:13.654527  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.654531  2642 net.cpp:137] Memory required for data: 422419600
I0924 21:06:13.654534  2642 layer_factory.hpp:77] Creating layer BatchNorm16
I0924 21:06:13.654541  2642 net.cpp:84] Creating Layer BatchNorm16
I0924 21:06:13.654543  2642 net.cpp:406] BatchNorm16 <- Convolution16
I0924 21:06:13.654547  2642 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0924 21:06:13.654683  2642 net.cpp:122] Setting up BatchNorm16
I0924 21:06:13.654688  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.654690  2642 net.cpp:137] Memory required for data: 427437200
I0924 21:06:13.654695  2642 layer_factory.hpp:77] Creating layer Scale16
I0924 21:06:13.654708  2642 net.cpp:84] Creating Layer Scale16
I0924 21:06:13.654711  2642 net.cpp:406] Scale16 <- Convolution16
I0924 21:06:13.654714  2642 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0924 21:06:13.654743  2642 layer_factory.hpp:77] Creating layer Scale16
I0924 21:06:13.654824  2642 net.cpp:122] Setting up Scale16
I0924 21:06:13.654829  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.654831  2642 net.cpp:137] Memory required for data: 432454800
I0924 21:06:13.654836  2642 layer_factory.hpp:77] Creating layer ReLU16
I0924 21:06:13.654840  2642 net.cpp:84] Creating Layer ReLU16
I0924 21:06:13.654844  2642 net.cpp:406] ReLU16 <- Convolution16
I0924 21:06:13.654846  2642 net.cpp:367] ReLU16 -> Convolution16 (in-place)
I0924 21:06:13.654968  2642 net.cpp:122] Setting up ReLU16
I0924 21:06:13.654974  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.654976  2642 net.cpp:137] Memory required for data: 437472400
I0924 21:06:13.654978  2642 layer_factory.hpp:77] Creating layer Convolution17
I0924 21:06:13.654988  2642 net.cpp:84] Creating Layer Convolution17
I0924 21:06:13.654989  2642 net.cpp:406] Convolution17 <- Convolution16
I0924 21:06:13.654994  2642 net.cpp:380] Convolution17 -> Convolution17
I0924 21:06:13.655916  2642 net.cpp:122] Setting up Convolution17
I0924 21:06:13.655925  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.655928  2642 net.cpp:137] Memory required for data: 442490000
I0924 21:06:13.655932  2642 layer_factory.hpp:77] Creating layer BatchNorm17
I0924 21:06:13.655937  2642 net.cpp:84] Creating Layer BatchNorm17
I0924 21:06:13.655941  2642 net.cpp:406] BatchNorm17 <- Convolution17
I0924 21:06:13.655946  2642 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0924 21:06:13.656078  2642 net.cpp:122] Setting up BatchNorm17
I0924 21:06:13.656083  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.656085  2642 net.cpp:137] Memory required for data: 447507600
I0924 21:06:13.656090  2642 layer_factory.hpp:77] Creating layer Scale17
I0924 21:06:13.656095  2642 net.cpp:84] Creating Layer Scale17
I0924 21:06:13.656097  2642 net.cpp:406] Scale17 <- Convolution17
I0924 21:06:13.656100  2642 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0924 21:06:13.656126  2642 layer_factory.hpp:77] Creating layer Scale17
I0924 21:06:13.656204  2642 net.cpp:122] Setting up Scale17
I0924 21:06:13.656209  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.656211  2642 net.cpp:137] Memory required for data: 452525200
I0924 21:06:13.656214  2642 layer_factory.hpp:77] Creating layer Eltwise8
I0924 21:06:13.656219  2642 net.cpp:84] Creating Layer Eltwise8
I0924 21:06:13.656222  2642 net.cpp:406] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0924 21:06:13.656225  2642 net.cpp:406] Eltwise8 <- Convolution17
I0924 21:06:13.656229  2642 net.cpp:380] Eltwise8 -> Eltwise8
I0924 21:06:13.656244  2642 net.cpp:122] Setting up Eltwise8
I0924 21:06:13.656247  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.656250  2642 net.cpp:137] Memory required for data: 457542800
I0924 21:06:13.656251  2642 layer_factory.hpp:77] Creating layer ReLU17
I0924 21:06:13.656255  2642 net.cpp:84] Creating Layer ReLU17
I0924 21:06:13.656257  2642 net.cpp:406] ReLU17 <- Eltwise8
I0924 21:06:13.656261  2642 net.cpp:367] ReLU17 -> Eltwise8 (in-place)
I0924 21:06:13.656375  2642 net.cpp:122] Setting up ReLU17
I0924 21:06:13.656381  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.656383  2642 net.cpp:137] Memory required for data: 462560400
I0924 21:06:13.656385  2642 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0924 21:06:13.656390  2642 net.cpp:84] Creating Layer Eltwise8_ReLU17_0_split
I0924 21:06:13.656392  2642 net.cpp:406] Eltwise8_ReLU17_0_split <- Eltwise8
I0924 21:06:13.656395  2642 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0924 21:06:13.656399  2642 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0924 21:06:13.656435  2642 net.cpp:122] Setting up Eltwise8_ReLU17_0_split
I0924 21:06:13.656440  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.656442  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.656445  2642 net.cpp:137] Memory required for data: 472595600
I0924 21:06:13.656446  2642 layer_factory.hpp:77] Creating layer Convolution18
I0924 21:06:13.656452  2642 net.cpp:84] Creating Layer Convolution18
I0924 21:06:13.656455  2642 net.cpp:406] Convolution18 <- Eltwise8_ReLU17_0_split_0
I0924 21:06:13.656460  2642 net.cpp:380] Convolution18 -> Convolution18
I0924 21:06:13.657356  2642 net.cpp:122] Setting up Convolution18
I0924 21:06:13.657366  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.657368  2642 net.cpp:137] Memory required for data: 477613200
I0924 21:06:13.657372  2642 layer_factory.hpp:77] Creating layer BatchNorm18
I0924 21:06:13.657377  2642 net.cpp:84] Creating Layer BatchNorm18
I0924 21:06:13.657380  2642 net.cpp:406] BatchNorm18 <- Convolution18
I0924 21:06:13.657384  2642 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0924 21:06:13.657521  2642 net.cpp:122] Setting up BatchNorm18
I0924 21:06:13.657524  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.657526  2642 net.cpp:137] Memory required for data: 482630800
I0924 21:06:13.657531  2642 layer_factory.hpp:77] Creating layer Scale18
I0924 21:06:13.657536  2642 net.cpp:84] Creating Layer Scale18
I0924 21:06:13.657538  2642 net.cpp:406] Scale18 <- Convolution18
I0924 21:06:13.657541  2642 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0924 21:06:13.657568  2642 layer_factory.hpp:77] Creating layer Scale18
I0924 21:06:13.657646  2642 net.cpp:122] Setting up Scale18
I0924 21:06:13.657651  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.657654  2642 net.cpp:137] Memory required for data: 487648400
I0924 21:06:13.657657  2642 layer_factory.hpp:77] Creating layer ReLU18
I0924 21:06:13.657660  2642 net.cpp:84] Creating Layer ReLU18
I0924 21:06:13.657663  2642 net.cpp:406] ReLU18 <- Convolution18
I0924 21:06:13.657665  2642 net.cpp:367] ReLU18 -> Convolution18 (in-place)
I0924 21:06:13.657780  2642 net.cpp:122] Setting up ReLU18
I0924 21:06:13.657786  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.657788  2642 net.cpp:137] Memory required for data: 492666000
I0924 21:06:13.657791  2642 layer_factory.hpp:77] Creating layer Convolution19
I0924 21:06:13.657797  2642 net.cpp:84] Creating Layer Convolution19
I0924 21:06:13.657800  2642 net.cpp:406] Convolution19 <- Convolution18
I0924 21:06:13.657804  2642 net.cpp:380] Convolution19 -> Convolution19
I0924 21:06:13.658695  2642 net.cpp:122] Setting up Convolution19
I0924 21:06:13.658704  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.658706  2642 net.cpp:137] Memory required for data: 497683600
I0924 21:06:13.658710  2642 layer_factory.hpp:77] Creating layer BatchNorm19
I0924 21:06:13.658715  2642 net.cpp:84] Creating Layer BatchNorm19
I0924 21:06:13.658717  2642 net.cpp:406] BatchNorm19 <- Convolution19
I0924 21:06:13.658722  2642 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0924 21:06:13.658859  2642 net.cpp:122] Setting up BatchNorm19
I0924 21:06:13.658864  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.658866  2642 net.cpp:137] Memory required for data: 502701200
I0924 21:06:13.658882  2642 layer_factory.hpp:77] Creating layer Scale19
I0924 21:06:13.658888  2642 net.cpp:84] Creating Layer Scale19
I0924 21:06:13.658890  2642 net.cpp:406] Scale19 <- Convolution19
I0924 21:06:13.658893  2642 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0924 21:06:13.658922  2642 layer_factory.hpp:77] Creating layer Scale19
I0924 21:06:13.659003  2642 net.cpp:122] Setting up Scale19
I0924 21:06:13.659006  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.659009  2642 net.cpp:137] Memory required for data: 507718800
I0924 21:06:13.659013  2642 layer_factory.hpp:77] Creating layer Eltwise9
I0924 21:06:13.659016  2642 net.cpp:84] Creating Layer Eltwise9
I0924 21:06:13.659025  2642 net.cpp:406] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I0924 21:06:13.659029  2642 net.cpp:406] Eltwise9 <- Convolution19
I0924 21:06:13.659032  2642 net.cpp:380] Eltwise9 -> Eltwise9
I0924 21:06:13.659050  2642 net.cpp:122] Setting up Eltwise9
I0924 21:06:13.659054  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.659056  2642 net.cpp:137] Memory required for data: 512736400
I0924 21:06:13.659059  2642 layer_factory.hpp:77] Creating layer ReLU19
I0924 21:06:13.659061  2642 net.cpp:84] Creating Layer ReLU19
I0924 21:06:13.659065  2642 net.cpp:406] ReLU19 <- Eltwise9
I0924 21:06:13.659067  2642 net.cpp:367] ReLU19 -> Eltwise9 (in-place)
I0924 21:06:13.659183  2642 net.cpp:122] Setting up ReLU19
I0924 21:06:13.659188  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.659190  2642 net.cpp:137] Memory required for data: 517754000
I0924 21:06:13.659193  2642 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I0924 21:06:13.659198  2642 net.cpp:84] Creating Layer Eltwise9_ReLU19_0_split
I0924 21:06:13.659199  2642 net.cpp:406] Eltwise9_ReLU19_0_split <- Eltwise9
I0924 21:06:13.659204  2642 net.cpp:380] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I0924 21:06:13.659207  2642 net.cpp:380] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I0924 21:06:13.659235  2642 net.cpp:122] Setting up Eltwise9_ReLU19_0_split
I0924 21:06:13.659237  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.659240  2642 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0924 21:06:13.659242  2642 net.cpp:137] Memory required for data: 527789200
I0924 21:06:13.659245  2642 layer_factory.hpp:77] Creating layer Convolution20
I0924 21:06:13.659252  2642 net.cpp:84] Creating Layer Convolution20
I0924 21:06:13.659255  2642 net.cpp:406] Convolution20 <- Eltwise9_ReLU19_0_split_0
I0924 21:06:13.659260  2642 net.cpp:380] Convolution20 -> Convolution20
I0924 21:06:13.660429  2642 net.cpp:122] Setting up Convolution20
I0924 21:06:13.660436  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.660439  2642 net.cpp:137] Memory required for data: 530298000
I0924 21:06:13.660444  2642 layer_factory.hpp:77] Creating layer BatchNorm20
I0924 21:06:13.660449  2642 net.cpp:84] Creating Layer BatchNorm20
I0924 21:06:13.660451  2642 net.cpp:406] BatchNorm20 <- Convolution20
I0924 21:06:13.660455  2642 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0924 21:06:13.660600  2642 net.cpp:122] Setting up BatchNorm20
I0924 21:06:13.660604  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.660607  2642 net.cpp:137] Memory required for data: 532806800
I0924 21:06:13.660611  2642 layer_factory.hpp:77] Creating layer Scale20
I0924 21:06:13.660615  2642 net.cpp:84] Creating Layer Scale20
I0924 21:06:13.660619  2642 net.cpp:406] Scale20 <- Convolution20
I0924 21:06:13.660621  2642 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0924 21:06:13.660648  2642 layer_factory.hpp:77] Creating layer Scale20
I0924 21:06:13.660727  2642 net.cpp:122] Setting up Scale20
I0924 21:06:13.660732  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.660733  2642 net.cpp:137] Memory required for data: 535315600
I0924 21:06:13.660737  2642 layer_factory.hpp:77] Creating layer Convolution21
I0924 21:06:13.660743  2642 net.cpp:84] Creating Layer Convolution21
I0924 21:06:13.660746  2642 net.cpp:406] Convolution21 <- Eltwise9_ReLU19_0_split_1
I0924 21:06:13.660750  2642 net.cpp:380] Convolution21 -> Convolution21
I0924 21:06:13.662506  2642 net.cpp:122] Setting up Convolution21
I0924 21:06:13.662515  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.662518  2642 net.cpp:137] Memory required for data: 537824400
I0924 21:06:13.662523  2642 layer_factory.hpp:77] Creating layer BatchNorm21
I0924 21:06:13.662528  2642 net.cpp:84] Creating Layer BatchNorm21
I0924 21:06:13.662531  2642 net.cpp:406] BatchNorm21 <- Convolution21
I0924 21:06:13.662534  2642 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0924 21:06:13.662675  2642 net.cpp:122] Setting up BatchNorm21
I0924 21:06:13.662686  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.662689  2642 net.cpp:137] Memory required for data: 540333200
I0924 21:06:13.662694  2642 layer_factory.hpp:77] Creating layer Scale21
I0924 21:06:13.662699  2642 net.cpp:84] Creating Layer Scale21
I0924 21:06:13.662701  2642 net.cpp:406] Scale21 <- Convolution21
I0924 21:06:13.662705  2642 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0924 21:06:13.662734  2642 layer_factory.hpp:77] Creating layer Scale21
I0924 21:06:13.662812  2642 net.cpp:122] Setting up Scale21
I0924 21:06:13.662817  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.662818  2642 net.cpp:137] Memory required for data: 542842000
I0924 21:06:13.662822  2642 layer_factory.hpp:77] Creating layer ReLU20
I0924 21:06:13.662825  2642 net.cpp:84] Creating Layer ReLU20
I0924 21:06:13.662828  2642 net.cpp:406] ReLU20 <- Convolution21
I0924 21:06:13.662832  2642 net.cpp:367] ReLU20 -> Convolution21 (in-place)
I0924 21:06:13.662948  2642 net.cpp:122] Setting up ReLU20
I0924 21:06:13.662955  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.662956  2642 net.cpp:137] Memory required for data: 545350800
I0924 21:06:13.662958  2642 layer_factory.hpp:77] Creating layer Convolution22
I0924 21:06:13.662966  2642 net.cpp:84] Creating Layer Convolution22
I0924 21:06:13.662968  2642 net.cpp:406] Convolution22 <- Convolution21
I0924 21:06:13.662972  2642 net.cpp:380] Convolution22 -> Convolution22
I0924 21:06:13.674268  2642 net.cpp:122] Setting up Convolution22
I0924 21:06:13.674278  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.674280  2642 net.cpp:137] Memory required for data: 547859600
I0924 21:06:13.674285  2642 layer_factory.hpp:77] Creating layer BatchNorm22
I0924 21:06:13.674291  2642 net.cpp:84] Creating Layer BatchNorm22
I0924 21:06:13.674294  2642 net.cpp:406] BatchNorm22 <- Convolution22
I0924 21:06:13.674299  2642 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0924 21:06:13.674453  2642 net.cpp:122] Setting up BatchNorm22
I0924 21:06:13.674458  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.674459  2642 net.cpp:137] Memory required for data: 550368400
I0924 21:06:13.674465  2642 layer_factory.hpp:77] Creating layer Scale22
I0924 21:06:13.674470  2642 net.cpp:84] Creating Layer Scale22
I0924 21:06:13.674474  2642 net.cpp:406] Scale22 <- Convolution22
I0924 21:06:13.674476  2642 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0924 21:06:13.674506  2642 layer_factory.hpp:77] Creating layer Scale22
I0924 21:06:13.674592  2642 net.cpp:122] Setting up Scale22
I0924 21:06:13.674597  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.674599  2642 net.cpp:137] Memory required for data: 552877200
I0924 21:06:13.674603  2642 layer_factory.hpp:77] Creating layer Eltwise10
I0924 21:06:13.674608  2642 net.cpp:84] Creating Layer Eltwise10
I0924 21:06:13.674610  2642 net.cpp:406] Eltwise10 <- Convolution20
I0924 21:06:13.674614  2642 net.cpp:406] Eltwise10 <- Convolution22
I0924 21:06:13.674618  2642 net.cpp:380] Eltwise10 -> Eltwise10
I0924 21:06:13.674635  2642 net.cpp:122] Setting up Eltwise10
I0924 21:06:13.674639  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.674643  2642 net.cpp:137] Memory required for data: 555386000
I0924 21:06:13.674644  2642 layer_factory.hpp:77] Creating layer ReLU21
I0924 21:06:13.674649  2642 net.cpp:84] Creating Layer ReLU21
I0924 21:06:13.674650  2642 net.cpp:406] ReLU21 <- Eltwise10
I0924 21:06:13.674654  2642 net.cpp:367] ReLU21 -> Eltwise10 (in-place)
I0924 21:06:13.675130  2642 net.cpp:122] Setting up ReLU21
I0924 21:06:13.675139  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.675142  2642 net.cpp:137] Memory required for data: 557894800
I0924 21:06:13.675144  2642 layer_factory.hpp:77] Creating layer Eltwise10_ReLU21_0_split
I0924 21:06:13.675149  2642 net.cpp:84] Creating Layer Eltwise10_ReLU21_0_split
I0924 21:06:13.675153  2642 net.cpp:406] Eltwise10_ReLU21_0_split <- Eltwise10
I0924 21:06:13.675156  2642 net.cpp:380] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_0
I0924 21:06:13.675170  2642 net.cpp:380] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_1
I0924 21:06:13.675204  2642 net.cpp:122] Setting up Eltwise10_ReLU21_0_split
I0924 21:06:13.675209  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.675210  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.675213  2642 net.cpp:137] Memory required for data: 562912400
I0924 21:06:13.675215  2642 layer_factory.hpp:77] Creating layer Convolution23
I0924 21:06:13.675222  2642 net.cpp:84] Creating Layer Convolution23
I0924 21:06:13.675225  2642 net.cpp:406] Convolution23 <- Eltwise10_ReLU21_0_split_0
I0924 21:06:13.675230  2642 net.cpp:380] Convolution23 -> Convolution23
I0924 21:06:13.676332  2642 net.cpp:122] Setting up Convolution23
I0924 21:06:13.676342  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.676343  2642 net.cpp:137] Memory required for data: 565421200
I0924 21:06:13.676347  2642 layer_factory.hpp:77] Creating layer BatchNorm23
I0924 21:06:13.676353  2642 net.cpp:84] Creating Layer BatchNorm23
I0924 21:06:13.676355  2642 net.cpp:406] BatchNorm23 <- Convolution23
I0924 21:06:13.676359  2642 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0924 21:06:13.676494  2642 net.cpp:122] Setting up BatchNorm23
I0924 21:06:13.676499  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.676501  2642 net.cpp:137] Memory required for data: 567930000
I0924 21:06:13.676506  2642 layer_factory.hpp:77] Creating layer Scale23
I0924 21:06:13.676511  2642 net.cpp:84] Creating Layer Scale23
I0924 21:06:13.676513  2642 net.cpp:406] Scale23 <- Convolution23
I0924 21:06:13.676517  2642 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0924 21:06:13.676542  2642 layer_factory.hpp:77] Creating layer Scale23
I0924 21:06:13.676620  2642 net.cpp:122] Setting up Scale23
I0924 21:06:13.676623  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.676625  2642 net.cpp:137] Memory required for data: 570438800
I0924 21:06:13.676630  2642 layer_factory.hpp:77] Creating layer ReLU22
I0924 21:06:13.676633  2642 net.cpp:84] Creating Layer ReLU22
I0924 21:06:13.676636  2642 net.cpp:406] ReLU22 <- Convolution23
I0924 21:06:13.676640  2642 net.cpp:367] ReLU22 -> Convolution23 (in-place)
I0924 21:06:13.677073  2642 net.cpp:122] Setting up ReLU22
I0924 21:06:13.677081  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.677083  2642 net.cpp:137] Memory required for data: 572947600
I0924 21:06:13.677086  2642 layer_factory.hpp:77] Creating layer Convolution24
I0924 21:06:13.677093  2642 net.cpp:84] Creating Layer Convolution24
I0924 21:06:13.677096  2642 net.cpp:406] Convolution24 <- Convolution23
I0924 21:06:13.677100  2642 net.cpp:380] Convolution24 -> Convolution24
I0924 21:06:13.678136  2642 net.cpp:122] Setting up Convolution24
I0924 21:06:13.678144  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.678146  2642 net.cpp:137] Memory required for data: 575456400
I0924 21:06:13.678151  2642 layer_factory.hpp:77] Creating layer BatchNorm24
I0924 21:06:13.678155  2642 net.cpp:84] Creating Layer BatchNorm24
I0924 21:06:13.678158  2642 net.cpp:406] BatchNorm24 <- Convolution24
I0924 21:06:13.678164  2642 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0924 21:06:13.678298  2642 net.cpp:122] Setting up BatchNorm24
I0924 21:06:13.678303  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.678304  2642 net.cpp:137] Memory required for data: 577965200
I0924 21:06:13.678309  2642 layer_factory.hpp:77] Creating layer Scale24
I0924 21:06:13.678313  2642 net.cpp:84] Creating Layer Scale24
I0924 21:06:13.678315  2642 net.cpp:406] Scale24 <- Convolution24
I0924 21:06:13.678319  2642 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0924 21:06:13.678345  2642 layer_factory.hpp:77] Creating layer Scale24
I0924 21:06:13.678421  2642 net.cpp:122] Setting up Scale24
I0924 21:06:13.678424  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.678426  2642 net.cpp:137] Memory required for data: 580474000
I0924 21:06:13.678436  2642 layer_factory.hpp:77] Creating layer Eltwise11
I0924 21:06:13.678442  2642 net.cpp:84] Creating Layer Eltwise11
I0924 21:06:13.678443  2642 net.cpp:406] Eltwise11 <- Eltwise10_ReLU21_0_split_1
I0924 21:06:13.678447  2642 net.cpp:406] Eltwise11 <- Convolution24
I0924 21:06:13.678450  2642 net.cpp:380] Eltwise11 -> Eltwise11
I0924 21:06:13.678467  2642 net.cpp:122] Setting up Eltwise11
I0924 21:06:13.678472  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.678473  2642 net.cpp:137] Memory required for data: 582982800
I0924 21:06:13.678475  2642 layer_factory.hpp:77] Creating layer ReLU23
I0924 21:06:13.678478  2642 net.cpp:84] Creating Layer ReLU23
I0924 21:06:13.678480  2642 net.cpp:406] ReLU23 <- Eltwise11
I0924 21:06:13.678483  2642 net.cpp:367] ReLU23 -> Eltwise11 (in-place)
I0924 21:06:13.678601  2642 net.cpp:122] Setting up ReLU23
I0924 21:06:13.678606  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.678607  2642 net.cpp:137] Memory required for data: 585491600
I0924 21:06:13.678611  2642 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I0924 21:06:13.678613  2642 net.cpp:84] Creating Layer Eltwise11_ReLU23_0_split
I0924 21:06:13.678616  2642 net.cpp:406] Eltwise11_ReLU23_0_split <- Eltwise11
I0924 21:06:13.678619  2642 net.cpp:380] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I0924 21:06:13.678624  2642 net.cpp:380] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I0924 21:06:13.678650  2642 net.cpp:122] Setting up Eltwise11_ReLU23_0_split
I0924 21:06:13.678654  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.678658  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.678658  2642 net.cpp:137] Memory required for data: 590509200
I0924 21:06:13.678660  2642 layer_factory.hpp:77] Creating layer Convolution25
I0924 21:06:13.678668  2642 net.cpp:84] Creating Layer Convolution25
I0924 21:06:13.678670  2642 net.cpp:406] Convolution25 <- Eltwise11_ReLU23_0_split_0
I0924 21:06:13.678674  2642 net.cpp:380] Convolution25 -> Convolution25
I0924 21:06:13.679702  2642 net.cpp:122] Setting up Convolution25
I0924 21:06:13.679709  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.679711  2642 net.cpp:137] Memory required for data: 593018000
I0924 21:06:13.679716  2642 layer_factory.hpp:77] Creating layer BatchNorm25
I0924 21:06:13.679721  2642 net.cpp:84] Creating Layer BatchNorm25
I0924 21:06:13.679724  2642 net.cpp:406] BatchNorm25 <- Convolution25
I0924 21:06:13.679728  2642 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0924 21:06:13.679863  2642 net.cpp:122] Setting up BatchNorm25
I0924 21:06:13.679868  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.679870  2642 net.cpp:137] Memory required for data: 595526800
I0924 21:06:13.679875  2642 layer_factory.hpp:77] Creating layer Scale25
I0924 21:06:13.679879  2642 net.cpp:84] Creating Layer Scale25
I0924 21:06:13.679882  2642 net.cpp:406] Scale25 <- Convolution25
I0924 21:06:13.679885  2642 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0924 21:06:13.679911  2642 layer_factory.hpp:77] Creating layer Scale25
I0924 21:06:13.679989  2642 net.cpp:122] Setting up Scale25
I0924 21:06:13.679993  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.679996  2642 net.cpp:137] Memory required for data: 598035600
I0924 21:06:13.679998  2642 layer_factory.hpp:77] Creating layer ReLU24
I0924 21:06:13.680002  2642 net.cpp:84] Creating Layer ReLU24
I0924 21:06:13.680006  2642 net.cpp:406] ReLU24 <- Convolution25
I0924 21:06:13.680008  2642 net.cpp:367] ReLU24 -> Convolution25 (in-place)
I0924 21:06:13.680121  2642 net.cpp:122] Setting up ReLU24
I0924 21:06:13.680127  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.680130  2642 net.cpp:137] Memory required for data: 600544400
I0924 21:06:13.680131  2642 layer_factory.hpp:77] Creating layer Convolution26
I0924 21:06:13.680138  2642 net.cpp:84] Creating Layer Convolution26
I0924 21:06:13.680141  2642 net.cpp:406] Convolution26 <- Convolution25
I0924 21:06:13.680151  2642 net.cpp:380] Convolution26 -> Convolution26
I0924 21:06:13.681193  2642 net.cpp:122] Setting up Convolution26
I0924 21:06:13.681202  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.681205  2642 net.cpp:137] Memory required for data: 603053200
I0924 21:06:13.681210  2642 layer_factory.hpp:77] Creating layer BatchNorm26
I0924 21:06:13.681216  2642 net.cpp:84] Creating Layer BatchNorm26
I0924 21:06:13.681217  2642 net.cpp:406] BatchNorm26 <- Convolution26
I0924 21:06:13.681221  2642 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0924 21:06:13.681360  2642 net.cpp:122] Setting up BatchNorm26
I0924 21:06:13.681365  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.681366  2642 net.cpp:137] Memory required for data: 605562000
I0924 21:06:13.681371  2642 layer_factory.hpp:77] Creating layer Scale26
I0924 21:06:13.681375  2642 net.cpp:84] Creating Layer Scale26
I0924 21:06:13.681377  2642 net.cpp:406] Scale26 <- Convolution26
I0924 21:06:13.681380  2642 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0924 21:06:13.681408  2642 layer_factory.hpp:77] Creating layer Scale26
I0924 21:06:13.681485  2642 net.cpp:122] Setting up Scale26
I0924 21:06:13.681489  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.681491  2642 net.cpp:137] Memory required for data: 608070800
I0924 21:06:13.681495  2642 layer_factory.hpp:77] Creating layer Eltwise12
I0924 21:06:13.681499  2642 net.cpp:84] Creating Layer Eltwise12
I0924 21:06:13.681502  2642 net.cpp:406] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I0924 21:06:13.681505  2642 net.cpp:406] Eltwise12 <- Convolution26
I0924 21:06:13.681509  2642 net.cpp:380] Eltwise12 -> Eltwise12
I0924 21:06:13.681524  2642 net.cpp:122] Setting up Eltwise12
I0924 21:06:13.681527  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.681529  2642 net.cpp:137] Memory required for data: 610579600
I0924 21:06:13.681531  2642 layer_factory.hpp:77] Creating layer ReLU25
I0924 21:06:13.681535  2642 net.cpp:84] Creating Layer ReLU25
I0924 21:06:13.681537  2642 net.cpp:406] ReLU25 <- Eltwise12
I0924 21:06:13.681540  2642 net.cpp:367] ReLU25 -> Eltwise12 (in-place)
I0924 21:06:13.681655  2642 net.cpp:122] Setting up ReLU25
I0924 21:06:13.681661  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.681664  2642 net.cpp:137] Memory required for data: 613088400
I0924 21:06:13.681666  2642 layer_factory.hpp:77] Creating layer Eltwise12_ReLU25_0_split
I0924 21:06:13.681676  2642 net.cpp:84] Creating Layer Eltwise12_ReLU25_0_split
I0924 21:06:13.681679  2642 net.cpp:406] Eltwise12_ReLU25_0_split <- Eltwise12
I0924 21:06:13.681684  2642 net.cpp:380] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_0
I0924 21:06:13.681691  2642 net.cpp:380] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_1
I0924 21:06:13.681721  2642 net.cpp:122] Setting up Eltwise12_ReLU25_0_split
I0924 21:06:13.681727  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.681730  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.681731  2642 net.cpp:137] Memory required for data: 618106000
I0924 21:06:13.681735  2642 layer_factory.hpp:77] Creating layer Convolution27
I0924 21:06:13.681751  2642 net.cpp:84] Creating Layer Convolution27
I0924 21:06:13.681753  2642 net.cpp:406] Convolution27 <- Eltwise12_ReLU25_0_split_0
I0924 21:06:13.681772  2642 net.cpp:380] Convolution27 -> Convolution27
I0924 21:06:13.682854  2642 net.cpp:122] Setting up Convolution27
I0924 21:06:13.682863  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.682865  2642 net.cpp:137] Memory required for data: 620614800
I0924 21:06:13.682870  2642 layer_factory.hpp:77] Creating layer BatchNorm27
I0924 21:06:13.682875  2642 net.cpp:84] Creating Layer BatchNorm27
I0924 21:06:13.682878  2642 net.cpp:406] BatchNorm27 <- Convolution27
I0924 21:06:13.682881  2642 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0924 21:06:13.683051  2642 net.cpp:122] Setting up BatchNorm27
I0924 21:06:13.683056  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.683075  2642 net.cpp:137] Memory required for data: 623123600
I0924 21:06:13.683081  2642 layer_factory.hpp:77] Creating layer Scale27
I0924 21:06:13.683085  2642 net.cpp:84] Creating Layer Scale27
I0924 21:06:13.683087  2642 net.cpp:406] Scale27 <- Convolution27
I0924 21:06:13.683092  2642 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0924 21:06:13.683120  2642 layer_factory.hpp:77] Creating layer Scale27
I0924 21:06:13.683214  2642 net.cpp:122] Setting up Scale27
I0924 21:06:13.683219  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.683221  2642 net.cpp:137] Memory required for data: 625632400
I0924 21:06:13.683225  2642 layer_factory.hpp:77] Creating layer ReLU26
I0924 21:06:13.683229  2642 net.cpp:84] Creating Layer ReLU26
I0924 21:06:13.683231  2642 net.cpp:406] ReLU26 <- Convolution27
I0924 21:06:13.683235  2642 net.cpp:367] ReLU26 -> Convolution27 (in-place)
I0924 21:06:13.683357  2642 net.cpp:122] Setting up ReLU26
I0924 21:06:13.683362  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.683364  2642 net.cpp:137] Memory required for data: 628141200
I0924 21:06:13.683367  2642 layer_factory.hpp:77] Creating layer Convolution28
I0924 21:06:13.683374  2642 net.cpp:84] Creating Layer Convolution28
I0924 21:06:13.683385  2642 net.cpp:406] Convolution28 <- Convolution27
I0924 21:06:13.683390  2642 net.cpp:380] Convolution28 -> Convolution28
I0924 21:06:13.684643  2642 net.cpp:122] Setting up Convolution28
I0924 21:06:13.684653  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.684654  2642 net.cpp:137] Memory required for data: 630650000
I0924 21:06:13.684659  2642 layer_factory.hpp:77] Creating layer BatchNorm28
I0924 21:06:13.684664  2642 net.cpp:84] Creating Layer BatchNorm28
I0924 21:06:13.684667  2642 net.cpp:406] BatchNorm28 <- Convolution28
I0924 21:06:13.684671  2642 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0924 21:06:13.684809  2642 net.cpp:122] Setting up BatchNorm28
I0924 21:06:13.684814  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.684816  2642 net.cpp:137] Memory required for data: 633158800
I0924 21:06:13.684821  2642 layer_factory.hpp:77] Creating layer Scale28
I0924 21:06:13.684825  2642 net.cpp:84] Creating Layer Scale28
I0924 21:06:13.684828  2642 net.cpp:406] Scale28 <- Convolution28
I0924 21:06:13.684831  2642 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0924 21:06:13.684859  2642 layer_factory.hpp:77] Creating layer Scale28
I0924 21:06:13.684962  2642 net.cpp:122] Setting up Scale28
I0924 21:06:13.684968  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.684970  2642 net.cpp:137] Memory required for data: 635667600
I0924 21:06:13.684973  2642 layer_factory.hpp:77] Creating layer Eltwise13
I0924 21:06:13.684978  2642 net.cpp:84] Creating Layer Eltwise13
I0924 21:06:13.684981  2642 net.cpp:406] Eltwise13 <- Eltwise12_ReLU25_0_split_1
I0924 21:06:13.684984  2642 net.cpp:406] Eltwise13 <- Convolution28
I0924 21:06:13.684988  2642 net.cpp:380] Eltwise13 -> Eltwise13
I0924 21:06:13.685004  2642 net.cpp:122] Setting up Eltwise13
I0924 21:06:13.685009  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.685010  2642 net.cpp:137] Memory required for data: 638176400
I0924 21:06:13.685012  2642 layer_factory.hpp:77] Creating layer ReLU27
I0924 21:06:13.685016  2642 net.cpp:84] Creating Layer ReLU27
I0924 21:06:13.685019  2642 net.cpp:406] ReLU27 <- Eltwise13
I0924 21:06:13.685022  2642 net.cpp:367] ReLU27 -> Eltwise13 (in-place)
I0924 21:06:13.685518  2642 net.cpp:122] Setting up ReLU27
I0924 21:06:13.685525  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.685528  2642 net.cpp:137] Memory required for data: 640685200
I0924 21:06:13.685531  2642 layer_factory.hpp:77] Creating layer Eltwise13_ReLU27_0_split
I0924 21:06:13.685536  2642 net.cpp:84] Creating Layer Eltwise13_ReLU27_0_split
I0924 21:06:13.685539  2642 net.cpp:406] Eltwise13_ReLU27_0_split <- Eltwise13
I0924 21:06:13.685542  2642 net.cpp:380] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_0
I0924 21:06:13.685554  2642 net.cpp:380] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_1
I0924 21:06:13.685585  2642 net.cpp:122] Setting up Eltwise13_ReLU27_0_split
I0924 21:06:13.685590  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.685592  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.685595  2642 net.cpp:137] Memory required for data: 645702800
I0924 21:06:13.685597  2642 layer_factory.hpp:77] Creating layer Convolution29
I0924 21:06:13.685605  2642 net.cpp:84] Creating Layer Convolution29
I0924 21:06:13.685606  2642 net.cpp:406] Convolution29 <- Eltwise13_ReLU27_0_split_0
I0924 21:06:13.685611  2642 net.cpp:380] Convolution29 -> Convolution29
I0924 21:06:13.686352  2642 net.cpp:122] Setting up Convolution29
I0924 21:06:13.686359  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.686362  2642 net.cpp:137] Memory required for data: 648211600
I0924 21:06:13.686367  2642 layer_factory.hpp:77] Creating layer BatchNorm29
I0924 21:06:13.686372  2642 net.cpp:84] Creating Layer BatchNorm29
I0924 21:06:13.686374  2642 net.cpp:406] BatchNorm29 <- Convolution29
I0924 21:06:13.686378  2642 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0924 21:06:13.686512  2642 net.cpp:122] Setting up BatchNorm29
I0924 21:06:13.686517  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.686519  2642 net.cpp:137] Memory required for data: 650720400
I0924 21:06:13.686523  2642 layer_factory.hpp:77] Creating layer Scale29
I0924 21:06:13.686527  2642 net.cpp:84] Creating Layer Scale29
I0924 21:06:13.686530  2642 net.cpp:406] Scale29 <- Convolution29
I0924 21:06:13.686533  2642 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0924 21:06:13.686560  2642 layer_factory.hpp:77] Creating layer Scale29
I0924 21:06:13.686638  2642 net.cpp:122] Setting up Scale29
I0924 21:06:13.686642  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.686645  2642 net.cpp:137] Memory required for data: 653229200
I0924 21:06:13.686648  2642 layer_factory.hpp:77] Creating layer ReLU28
I0924 21:06:13.686653  2642 net.cpp:84] Creating Layer ReLU28
I0924 21:06:13.686655  2642 net.cpp:406] ReLU28 <- Convolution29
I0924 21:06:13.686658  2642 net.cpp:367] ReLU28 -> Convolution29 (in-place)
I0924 21:06:13.687084  2642 net.cpp:122] Setting up ReLU28
I0924 21:06:13.687093  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.687095  2642 net.cpp:137] Memory required for data: 655738000
I0924 21:06:13.687098  2642 layer_factory.hpp:77] Creating layer Convolution30
I0924 21:06:13.687104  2642 net.cpp:84] Creating Layer Convolution30
I0924 21:06:13.687108  2642 net.cpp:406] Convolution30 <- Convolution29
I0924 21:06:13.687111  2642 net.cpp:380] Convolution30 -> Convolution30
I0924 21:06:13.688170  2642 net.cpp:122] Setting up Convolution30
I0924 21:06:13.688179  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.688181  2642 net.cpp:137] Memory required for data: 658246800
I0924 21:06:13.688185  2642 layer_factory.hpp:77] Creating layer BatchNorm30
I0924 21:06:13.688191  2642 net.cpp:84] Creating Layer BatchNorm30
I0924 21:06:13.688194  2642 net.cpp:406] BatchNorm30 <- Convolution30
I0924 21:06:13.688199  2642 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0924 21:06:13.688335  2642 net.cpp:122] Setting up BatchNorm30
I0924 21:06:13.688340  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.688343  2642 net.cpp:137] Memory required for data: 660755600
I0924 21:06:13.688346  2642 layer_factory.hpp:77] Creating layer Scale30
I0924 21:06:13.688351  2642 net.cpp:84] Creating Layer Scale30
I0924 21:06:13.688354  2642 net.cpp:406] Scale30 <- Convolution30
I0924 21:06:13.688357  2642 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0924 21:06:13.688385  2642 layer_factory.hpp:77] Creating layer Scale30
I0924 21:06:13.688462  2642 net.cpp:122] Setting up Scale30
I0924 21:06:13.688467  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.688468  2642 net.cpp:137] Memory required for data: 663264400
I0924 21:06:13.688477  2642 layer_factory.hpp:77] Creating layer Eltwise14
I0924 21:06:13.688484  2642 net.cpp:84] Creating Layer Eltwise14
I0924 21:06:13.688488  2642 net.cpp:406] Eltwise14 <- Eltwise13_ReLU27_0_split_1
I0924 21:06:13.688490  2642 net.cpp:406] Eltwise14 <- Convolution30
I0924 21:06:13.688493  2642 net.cpp:380] Eltwise14 -> Eltwise14
I0924 21:06:13.688513  2642 net.cpp:122] Setting up Eltwise14
I0924 21:06:13.688516  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.688519  2642 net.cpp:137] Memory required for data: 665773200
I0924 21:06:13.688520  2642 layer_factory.hpp:77] Creating layer ReLU29
I0924 21:06:13.688524  2642 net.cpp:84] Creating Layer ReLU29
I0924 21:06:13.688525  2642 net.cpp:406] ReLU29 <- Eltwise14
I0924 21:06:13.688529  2642 net.cpp:367] ReLU29 -> Eltwise14 (in-place)
I0924 21:06:13.688643  2642 net.cpp:122] Setting up ReLU29
I0924 21:06:13.688649  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.688652  2642 net.cpp:137] Memory required for data: 668282000
I0924 21:06:13.688653  2642 layer_factory.hpp:77] Creating layer Eltwise14_ReLU29_0_split
I0924 21:06:13.688657  2642 net.cpp:84] Creating Layer Eltwise14_ReLU29_0_split
I0924 21:06:13.688659  2642 net.cpp:406] Eltwise14_ReLU29_0_split <- Eltwise14
I0924 21:06:13.688663  2642 net.cpp:380] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_0
I0924 21:06:13.688668  2642 net.cpp:380] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_1
I0924 21:06:13.688694  2642 net.cpp:122] Setting up Eltwise14_ReLU29_0_split
I0924 21:06:13.688699  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.688701  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.688702  2642 net.cpp:137] Memory required for data: 673299600
I0924 21:06:13.688705  2642 layer_factory.hpp:77] Creating layer Convolution31
I0924 21:06:13.688711  2642 net.cpp:84] Creating Layer Convolution31
I0924 21:06:13.688714  2642 net.cpp:406] Convolution31 <- Eltwise14_ReLU29_0_split_0
I0924 21:06:13.688719  2642 net.cpp:380] Convolution31 -> Convolution31
I0924 21:06:13.689764  2642 net.cpp:122] Setting up Convolution31
I0924 21:06:13.689772  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.689774  2642 net.cpp:137] Memory required for data: 675808400
I0924 21:06:13.689779  2642 layer_factory.hpp:77] Creating layer BatchNorm31
I0924 21:06:13.689785  2642 net.cpp:84] Creating Layer BatchNorm31
I0924 21:06:13.689786  2642 net.cpp:406] BatchNorm31 <- Convolution31
I0924 21:06:13.689790  2642 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0924 21:06:13.689926  2642 net.cpp:122] Setting up BatchNorm31
I0924 21:06:13.689930  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.689934  2642 net.cpp:137] Memory required for data: 678317200
I0924 21:06:13.689937  2642 layer_factory.hpp:77] Creating layer Scale31
I0924 21:06:13.689941  2642 net.cpp:84] Creating Layer Scale31
I0924 21:06:13.689944  2642 net.cpp:406] Scale31 <- Convolution31
I0924 21:06:13.689947  2642 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0924 21:06:13.689975  2642 layer_factory.hpp:77] Creating layer Scale31
I0924 21:06:13.690054  2642 net.cpp:122] Setting up Scale31
I0924 21:06:13.690058  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.690060  2642 net.cpp:137] Memory required for data: 680826000
I0924 21:06:13.690064  2642 layer_factory.hpp:77] Creating layer ReLU30
I0924 21:06:13.690068  2642 net.cpp:84] Creating Layer ReLU30
I0924 21:06:13.690070  2642 net.cpp:406] ReLU30 <- Convolution31
I0924 21:06:13.690073  2642 net.cpp:367] ReLU30 -> Convolution31 (in-place)
I0924 21:06:13.690191  2642 net.cpp:122] Setting up ReLU30
I0924 21:06:13.690196  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.690198  2642 net.cpp:137] Memory required for data: 683334800
I0924 21:06:13.690201  2642 layer_factory.hpp:77] Creating layer Convolution32
I0924 21:06:13.690207  2642 net.cpp:84] Creating Layer Convolution32
I0924 21:06:13.690209  2642 net.cpp:406] Convolution32 <- Convolution31
I0924 21:06:13.690214  2642 net.cpp:380] Convolution32 -> Convolution32
I0924 21:06:13.691262  2642 net.cpp:122] Setting up Convolution32
I0924 21:06:13.691269  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.691272  2642 net.cpp:137] Memory required for data: 685843600
I0924 21:06:13.691277  2642 layer_factory.hpp:77] Creating layer BatchNorm32
I0924 21:06:13.691282  2642 net.cpp:84] Creating Layer BatchNorm32
I0924 21:06:13.691284  2642 net.cpp:406] BatchNorm32 <- Convolution32
I0924 21:06:13.691288  2642 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I0924 21:06:13.691426  2642 net.cpp:122] Setting up BatchNorm32
I0924 21:06:13.691429  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.691432  2642 net.cpp:137] Memory required for data: 688352400
I0924 21:06:13.691437  2642 layer_factory.hpp:77] Creating layer Scale32
I0924 21:06:13.691440  2642 net.cpp:84] Creating Layer Scale32
I0924 21:06:13.691443  2642 net.cpp:406] Scale32 <- Convolution32
I0924 21:06:13.691447  2642 net.cpp:367] Scale32 -> Convolution32 (in-place)
I0924 21:06:13.691475  2642 layer_factory.hpp:77] Creating layer Scale32
I0924 21:06:13.691553  2642 net.cpp:122] Setting up Scale32
I0924 21:06:13.691558  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.691560  2642 net.cpp:137] Memory required for data: 690861200
I0924 21:06:13.691565  2642 layer_factory.hpp:77] Creating layer Eltwise15
I0924 21:06:13.691567  2642 net.cpp:84] Creating Layer Eltwise15
I0924 21:06:13.691570  2642 net.cpp:406] Eltwise15 <- Eltwise14_ReLU29_0_split_1
I0924 21:06:13.691573  2642 net.cpp:406] Eltwise15 <- Convolution32
I0924 21:06:13.691576  2642 net.cpp:380] Eltwise15 -> Eltwise15
I0924 21:06:13.691593  2642 net.cpp:122] Setting up Eltwise15
I0924 21:06:13.691596  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.691598  2642 net.cpp:137] Memory required for data: 693370000
I0924 21:06:13.691601  2642 layer_factory.hpp:77] Creating layer ReLU31
I0924 21:06:13.691604  2642 net.cpp:84] Creating Layer ReLU31
I0924 21:06:13.691607  2642 net.cpp:406] ReLU31 <- Eltwise15
I0924 21:06:13.691610  2642 net.cpp:367] ReLU31 -> Eltwise15 (in-place)
I0924 21:06:13.692031  2642 net.cpp:122] Setting up ReLU31
I0924 21:06:13.692039  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.692042  2642 net.cpp:137] Memory required for data: 695878800
I0924 21:06:13.692044  2642 layer_factory.hpp:77] Creating layer Eltwise15_ReLU31_0_split
I0924 21:06:13.692049  2642 net.cpp:84] Creating Layer Eltwise15_ReLU31_0_split
I0924 21:06:13.692051  2642 net.cpp:406] Eltwise15_ReLU31_0_split <- Eltwise15
I0924 21:06:13.692055  2642 net.cpp:380] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_0
I0924 21:06:13.692059  2642 net.cpp:380] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_1
I0924 21:06:13.692090  2642 net.cpp:122] Setting up Eltwise15_ReLU31_0_split
I0924 21:06:13.692093  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.692095  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.692098  2642 net.cpp:137] Memory required for data: 700896400
I0924 21:06:13.692101  2642 layer_factory.hpp:77] Creating layer Convolution33
I0924 21:06:13.692106  2642 net.cpp:84] Creating Layer Convolution33
I0924 21:06:13.692108  2642 net.cpp:406] Convolution33 <- Eltwise15_ReLU31_0_split_0
I0924 21:06:13.692113  2642 net.cpp:380] Convolution33 -> Convolution33
I0924 21:06:13.693457  2642 net.cpp:122] Setting up Convolution33
I0924 21:06:13.693466  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.693469  2642 net.cpp:137] Memory required for data: 703405200
I0924 21:06:13.693472  2642 layer_factory.hpp:77] Creating layer BatchNorm33
I0924 21:06:13.693478  2642 net.cpp:84] Creating Layer BatchNorm33
I0924 21:06:13.693480  2642 net.cpp:406] BatchNorm33 <- Convolution33
I0924 21:06:13.693485  2642 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I0924 21:06:13.693629  2642 net.cpp:122] Setting up BatchNorm33
I0924 21:06:13.693634  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.693641  2642 net.cpp:137] Memory required for data: 705914000
I0924 21:06:13.693646  2642 layer_factory.hpp:77] Creating layer Scale33
I0924 21:06:13.693652  2642 net.cpp:84] Creating Layer Scale33
I0924 21:06:13.693655  2642 net.cpp:406] Scale33 <- Convolution33
I0924 21:06:13.693658  2642 net.cpp:367] Scale33 -> Convolution33 (in-place)
I0924 21:06:13.693687  2642 layer_factory.hpp:77] Creating layer Scale33
I0924 21:06:13.693768  2642 net.cpp:122] Setting up Scale33
I0924 21:06:13.693773  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.693774  2642 net.cpp:137] Memory required for data: 708422800
I0924 21:06:13.693778  2642 layer_factory.hpp:77] Creating layer ReLU32
I0924 21:06:13.693781  2642 net.cpp:84] Creating Layer ReLU32
I0924 21:06:13.693784  2642 net.cpp:406] ReLU32 <- Convolution33
I0924 21:06:13.693787  2642 net.cpp:367] ReLU32 -> Convolution33 (in-place)
I0924 21:06:13.693904  2642 net.cpp:122] Setting up ReLU32
I0924 21:06:13.693909  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.693912  2642 net.cpp:137] Memory required for data: 710931600
I0924 21:06:13.693914  2642 layer_factory.hpp:77] Creating layer Convolution34
I0924 21:06:13.693922  2642 net.cpp:84] Creating Layer Convolution34
I0924 21:06:13.693924  2642 net.cpp:406] Convolution34 <- Convolution33
I0924 21:06:13.693928  2642 net.cpp:380] Convolution34 -> Convolution34
I0924 21:06:13.694972  2642 net.cpp:122] Setting up Convolution34
I0924 21:06:13.694979  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.694983  2642 net.cpp:137] Memory required for data: 713440400
I0924 21:06:13.694986  2642 layer_factory.hpp:77] Creating layer BatchNorm34
I0924 21:06:13.694991  2642 net.cpp:84] Creating Layer BatchNorm34
I0924 21:06:13.694994  2642 net.cpp:406] BatchNorm34 <- Convolution34
I0924 21:06:13.694998  2642 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I0924 21:06:13.695138  2642 net.cpp:122] Setting up BatchNorm34
I0924 21:06:13.695142  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.695144  2642 net.cpp:137] Memory required for data: 715949200
I0924 21:06:13.695149  2642 layer_factory.hpp:77] Creating layer Scale34
I0924 21:06:13.695154  2642 net.cpp:84] Creating Layer Scale34
I0924 21:06:13.695156  2642 net.cpp:406] Scale34 <- Convolution34
I0924 21:06:13.695159  2642 net.cpp:367] Scale34 -> Convolution34 (in-place)
I0924 21:06:13.695188  2642 layer_factory.hpp:77] Creating layer Scale34
I0924 21:06:13.695267  2642 net.cpp:122] Setting up Scale34
I0924 21:06:13.695271  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.695273  2642 net.cpp:137] Memory required for data: 718458000
I0924 21:06:13.695277  2642 layer_factory.hpp:77] Creating layer Eltwise16
I0924 21:06:13.695281  2642 net.cpp:84] Creating Layer Eltwise16
I0924 21:06:13.695283  2642 net.cpp:406] Eltwise16 <- Eltwise15_ReLU31_0_split_1
I0924 21:06:13.695286  2642 net.cpp:406] Eltwise16 <- Convolution34
I0924 21:06:13.695291  2642 net.cpp:380] Eltwise16 -> Eltwise16
I0924 21:06:13.695307  2642 net.cpp:122] Setting up Eltwise16
I0924 21:06:13.695310  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.695312  2642 net.cpp:137] Memory required for data: 720966800
I0924 21:06:13.695314  2642 layer_factory.hpp:77] Creating layer ReLU33
I0924 21:06:13.695318  2642 net.cpp:84] Creating Layer ReLU33
I0924 21:06:13.695320  2642 net.cpp:406] ReLU33 <- Eltwise16
I0924 21:06:13.695323  2642 net.cpp:367] ReLU33 -> Eltwise16 (in-place)
I0924 21:06:13.695750  2642 net.cpp:122] Setting up ReLU33
I0924 21:06:13.695758  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.695761  2642 net.cpp:137] Memory required for data: 723475600
I0924 21:06:13.695763  2642 layer_factory.hpp:77] Creating layer Eltwise16_ReLU33_0_split
I0924 21:06:13.695767  2642 net.cpp:84] Creating Layer Eltwise16_ReLU33_0_split
I0924 21:06:13.695770  2642 net.cpp:406] Eltwise16_ReLU33_0_split <- Eltwise16
I0924 21:06:13.695773  2642 net.cpp:380] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_0
I0924 21:06:13.695785  2642 net.cpp:380] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_1
I0924 21:06:13.695816  2642 net.cpp:122] Setting up Eltwise16_ReLU33_0_split
I0924 21:06:13.695819  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.695822  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.695823  2642 net.cpp:137] Memory required for data: 728493200
I0924 21:06:13.695827  2642 layer_factory.hpp:77] Creating layer Convolution35
I0924 21:06:13.695832  2642 net.cpp:84] Creating Layer Convolution35
I0924 21:06:13.695834  2642 net.cpp:406] Convolution35 <- Eltwise16_ReLU33_0_split_0
I0924 21:06:13.695839  2642 net.cpp:380] Convolution35 -> Convolution35
I0924 21:06:13.696555  2642 net.cpp:122] Setting up Convolution35
I0924 21:06:13.696563  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.696565  2642 net.cpp:137] Memory required for data: 731002000
I0924 21:06:13.696570  2642 layer_factory.hpp:77] Creating layer BatchNorm35
I0924 21:06:13.696574  2642 net.cpp:84] Creating Layer BatchNorm35
I0924 21:06:13.696578  2642 net.cpp:406] BatchNorm35 <- Convolution35
I0924 21:06:13.696581  2642 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I0924 21:06:13.696719  2642 net.cpp:122] Setting up BatchNorm35
I0924 21:06:13.696723  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.696725  2642 net.cpp:137] Memory required for data: 733510800
I0924 21:06:13.696730  2642 layer_factory.hpp:77] Creating layer Scale35
I0924 21:06:13.696734  2642 net.cpp:84] Creating Layer Scale35
I0924 21:06:13.696737  2642 net.cpp:406] Scale35 <- Convolution35
I0924 21:06:13.696739  2642 net.cpp:367] Scale35 -> Convolution35 (in-place)
I0924 21:06:13.696766  2642 layer_factory.hpp:77] Creating layer Scale35
I0924 21:06:13.696846  2642 net.cpp:122] Setting up Scale35
I0924 21:06:13.696851  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.696852  2642 net.cpp:137] Memory required for data: 736019600
I0924 21:06:13.696856  2642 layer_factory.hpp:77] Creating layer ReLU34
I0924 21:06:13.696859  2642 net.cpp:84] Creating Layer ReLU34
I0924 21:06:13.696862  2642 net.cpp:406] ReLU34 <- Convolution35
I0924 21:06:13.696866  2642 net.cpp:367] ReLU34 -> Convolution35 (in-place)
I0924 21:06:13.697295  2642 net.cpp:122] Setting up ReLU34
I0924 21:06:13.697304  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.697306  2642 net.cpp:137] Memory required for data: 738528400
I0924 21:06:13.697309  2642 layer_factory.hpp:77] Creating layer Convolution36
I0924 21:06:13.697316  2642 net.cpp:84] Creating Layer Convolution36
I0924 21:06:13.697319  2642 net.cpp:406] Convolution36 <- Convolution35
I0924 21:06:13.697324  2642 net.cpp:380] Convolution36 -> Convolution36
I0924 21:06:13.698362  2642 net.cpp:122] Setting up Convolution36
I0924 21:06:13.698370  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.698374  2642 net.cpp:137] Memory required for data: 741037200
I0924 21:06:13.698377  2642 layer_factory.hpp:77] Creating layer BatchNorm36
I0924 21:06:13.698382  2642 net.cpp:84] Creating Layer BatchNorm36
I0924 21:06:13.698385  2642 net.cpp:406] BatchNorm36 <- Convolution36
I0924 21:06:13.698390  2642 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I0924 21:06:13.698530  2642 net.cpp:122] Setting up BatchNorm36
I0924 21:06:13.698535  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.698537  2642 net.cpp:137] Memory required for data: 743546000
I0924 21:06:13.698542  2642 layer_factory.hpp:77] Creating layer Scale36
I0924 21:06:13.698546  2642 net.cpp:84] Creating Layer Scale36
I0924 21:06:13.698549  2642 net.cpp:406] Scale36 <- Convolution36
I0924 21:06:13.698552  2642 net.cpp:367] Scale36 -> Convolution36 (in-place)
I0924 21:06:13.698580  2642 layer_factory.hpp:77] Creating layer Scale36
I0924 21:06:13.698662  2642 net.cpp:122] Setting up Scale36
I0924 21:06:13.698665  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.698668  2642 net.cpp:137] Memory required for data: 746054800
I0924 21:06:13.698670  2642 layer_factory.hpp:77] Creating layer Eltwise17
I0924 21:06:13.698680  2642 net.cpp:84] Creating Layer Eltwise17
I0924 21:06:13.698684  2642 net.cpp:406] Eltwise17 <- Eltwise16_ReLU33_0_split_1
I0924 21:06:13.698688  2642 net.cpp:406] Eltwise17 <- Convolution36
I0924 21:06:13.698691  2642 net.cpp:380] Eltwise17 -> Eltwise17
I0924 21:06:13.698709  2642 net.cpp:122] Setting up Eltwise17
I0924 21:06:13.698712  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.698714  2642 net.cpp:137] Memory required for data: 748563600
I0924 21:06:13.698716  2642 layer_factory.hpp:77] Creating layer ReLU35
I0924 21:06:13.698721  2642 net.cpp:84] Creating Layer ReLU35
I0924 21:06:13.698724  2642 net.cpp:406] ReLU35 <- Eltwise17
I0924 21:06:13.698726  2642 net.cpp:367] ReLU35 -> Eltwise17 (in-place)
I0924 21:06:13.698839  2642 net.cpp:122] Setting up ReLU35
I0924 21:06:13.698844  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.698848  2642 net.cpp:137] Memory required for data: 751072400
I0924 21:06:13.698849  2642 layer_factory.hpp:77] Creating layer Eltwise17_ReLU35_0_split
I0924 21:06:13.698853  2642 net.cpp:84] Creating Layer Eltwise17_ReLU35_0_split
I0924 21:06:13.698855  2642 net.cpp:406] Eltwise17_ReLU35_0_split <- Eltwise17
I0924 21:06:13.698858  2642 net.cpp:380] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_0
I0924 21:06:13.698863  2642 net.cpp:380] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_1
I0924 21:06:13.698890  2642 net.cpp:122] Setting up Eltwise17_ReLU35_0_split
I0924 21:06:13.698894  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.698897  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.698899  2642 net.cpp:137] Memory required for data: 756090000
I0924 21:06:13.698900  2642 layer_factory.hpp:77] Creating layer Convolution37
I0924 21:06:13.698907  2642 net.cpp:84] Creating Layer Convolution37
I0924 21:06:13.698909  2642 net.cpp:406] Convolution37 <- Eltwise17_ReLU35_0_split_0
I0924 21:06:13.698915  2642 net.cpp:380] Convolution37 -> Convolution37
I0924 21:06:13.699951  2642 net.cpp:122] Setting up Convolution37
I0924 21:06:13.699959  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.699962  2642 net.cpp:137] Memory required for data: 758598800
I0924 21:06:13.699966  2642 layer_factory.hpp:77] Creating layer BatchNorm37
I0924 21:06:13.699971  2642 net.cpp:84] Creating Layer BatchNorm37
I0924 21:06:13.699975  2642 net.cpp:406] BatchNorm37 <- Convolution37
I0924 21:06:13.699978  2642 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I0924 21:06:13.700120  2642 net.cpp:122] Setting up BatchNorm37
I0924 21:06:13.700125  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.700127  2642 net.cpp:137] Memory required for data: 761107600
I0924 21:06:13.700150  2642 layer_factory.hpp:77] Creating layer Scale37
I0924 21:06:13.700155  2642 net.cpp:84] Creating Layer Scale37
I0924 21:06:13.700157  2642 net.cpp:406] Scale37 <- Convolution37
I0924 21:06:13.700160  2642 net.cpp:367] Scale37 -> Convolution37 (in-place)
I0924 21:06:13.700191  2642 layer_factory.hpp:77] Creating layer Scale37
I0924 21:06:13.700271  2642 net.cpp:122] Setting up Scale37
I0924 21:06:13.700275  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.700278  2642 net.cpp:137] Memory required for data: 763616400
I0924 21:06:13.700281  2642 layer_factory.hpp:77] Creating layer ReLU36
I0924 21:06:13.700285  2642 net.cpp:84] Creating Layer ReLU36
I0924 21:06:13.700287  2642 net.cpp:406] ReLU36 <- Convolution37
I0924 21:06:13.700290  2642 net.cpp:367] ReLU36 -> Convolution37 (in-place)
I0924 21:06:13.700407  2642 net.cpp:122] Setting up ReLU36
I0924 21:06:13.700414  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.700417  2642 net.cpp:137] Memory required for data: 766125200
I0924 21:06:13.700418  2642 layer_factory.hpp:77] Creating layer Convolution38
I0924 21:06:13.700425  2642 net.cpp:84] Creating Layer Convolution38
I0924 21:06:13.700428  2642 net.cpp:406] Convolution38 <- Convolution37
I0924 21:06:13.700431  2642 net.cpp:380] Convolution38 -> Convolution38
I0924 21:06:13.701493  2642 net.cpp:122] Setting up Convolution38
I0924 21:06:13.701503  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.701505  2642 net.cpp:137] Memory required for data: 768634000
I0924 21:06:13.701509  2642 layer_factory.hpp:77] Creating layer BatchNorm38
I0924 21:06:13.701514  2642 net.cpp:84] Creating Layer BatchNorm38
I0924 21:06:13.701519  2642 net.cpp:406] BatchNorm38 <- Convolution38
I0924 21:06:13.701522  2642 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I0924 21:06:13.701663  2642 net.cpp:122] Setting up BatchNorm38
I0924 21:06:13.701668  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.701669  2642 net.cpp:137] Memory required for data: 771142800
I0924 21:06:13.701674  2642 layer_factory.hpp:77] Creating layer Scale38
I0924 21:06:13.701678  2642 net.cpp:84] Creating Layer Scale38
I0924 21:06:13.701681  2642 net.cpp:406] Scale38 <- Convolution38
I0924 21:06:13.701684  2642 net.cpp:367] Scale38 -> Convolution38 (in-place)
I0924 21:06:13.701712  2642 layer_factory.hpp:77] Creating layer Scale38
I0924 21:06:13.701797  2642 net.cpp:122] Setting up Scale38
I0924 21:06:13.701802  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.701803  2642 net.cpp:137] Memory required for data: 773651600
I0924 21:06:13.701807  2642 layer_factory.hpp:77] Creating layer Eltwise18
I0924 21:06:13.701810  2642 net.cpp:84] Creating Layer Eltwise18
I0924 21:06:13.701813  2642 net.cpp:406] Eltwise18 <- Eltwise17_ReLU35_0_split_1
I0924 21:06:13.701817  2642 net.cpp:406] Eltwise18 <- Convolution38
I0924 21:06:13.701820  2642 net.cpp:380] Eltwise18 -> Eltwise18
I0924 21:06:13.701838  2642 net.cpp:122] Setting up Eltwise18
I0924 21:06:13.701840  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.701843  2642 net.cpp:137] Memory required for data: 776160400
I0924 21:06:13.701844  2642 layer_factory.hpp:77] Creating layer ReLU37
I0924 21:06:13.701848  2642 net.cpp:84] Creating Layer ReLU37
I0924 21:06:13.701851  2642 net.cpp:406] ReLU37 <- Eltwise18
I0924 21:06:13.701853  2642 net.cpp:367] ReLU37 -> Eltwise18 (in-place)
I0924 21:06:13.701970  2642 net.cpp:122] Setting up ReLU37
I0924 21:06:13.701977  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.701978  2642 net.cpp:137] Memory required for data: 778669200
I0924 21:06:13.701982  2642 layer_factory.hpp:77] Creating layer Eltwise18_ReLU37_0_split
I0924 21:06:13.701985  2642 net.cpp:84] Creating Layer Eltwise18_ReLU37_0_split
I0924 21:06:13.701987  2642 net.cpp:406] Eltwise18_ReLU37_0_split <- Eltwise18
I0924 21:06:13.701990  2642 net.cpp:380] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_0
I0924 21:06:13.701995  2642 net.cpp:380] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_1
I0924 21:06:13.702023  2642 net.cpp:122] Setting up Eltwise18_ReLU37_0_split
I0924 21:06:13.702028  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.702029  2642 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0924 21:06:13.702031  2642 net.cpp:137] Memory required for data: 783686800
I0924 21:06:13.702033  2642 layer_factory.hpp:77] Creating layer Convolution39
I0924 21:06:13.702040  2642 net.cpp:84] Creating Layer Convolution39
I0924 21:06:13.702042  2642 net.cpp:406] Convolution39 <- Eltwise18_ReLU37_0_split_0
I0924 21:06:13.702047  2642 net.cpp:380] Convolution39 -> Convolution39
I0924 21:06:13.702941  2642 net.cpp:122] Setting up Convolution39
I0924 21:06:13.702950  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.702953  2642 net.cpp:137] Memory required for data: 784941200
I0924 21:06:13.702957  2642 layer_factory.hpp:77] Creating layer BatchNorm39
I0924 21:06:13.702961  2642 net.cpp:84] Creating Layer BatchNorm39
I0924 21:06:13.702965  2642 net.cpp:406] BatchNorm39 <- Convolution39
I0924 21:06:13.702968  2642 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I0924 21:06:13.703107  2642 net.cpp:122] Setting up BatchNorm39
I0924 21:06:13.703111  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.703114  2642 net.cpp:137] Memory required for data: 786195600
I0924 21:06:13.703125  2642 layer_factory.hpp:77] Creating layer Scale39
I0924 21:06:13.703130  2642 net.cpp:84] Creating Layer Scale39
I0924 21:06:13.703131  2642 net.cpp:406] Scale39 <- Convolution39
I0924 21:06:13.703135  2642 net.cpp:367] Scale39 -> Convolution39 (in-place)
I0924 21:06:13.703163  2642 layer_factory.hpp:77] Creating layer Scale39
I0924 21:06:13.703244  2642 net.cpp:122] Setting up Scale39
I0924 21:06:13.703248  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.703250  2642 net.cpp:137] Memory required for data: 787450000
I0924 21:06:13.703254  2642 layer_factory.hpp:77] Creating layer Convolution40
I0924 21:06:13.703263  2642 net.cpp:84] Creating Layer Convolution40
I0924 21:06:13.703264  2642 net.cpp:406] Convolution40 <- Eltwise18_ReLU37_0_split_1
I0924 21:06:13.703269  2642 net.cpp:380] Convolution40 -> Convolution40
I0924 21:06:13.705024  2642 net.cpp:122] Setting up Convolution40
I0924 21:06:13.705032  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.705035  2642 net.cpp:137] Memory required for data: 788704400
I0924 21:06:13.705039  2642 layer_factory.hpp:77] Creating layer BatchNorm40
I0924 21:06:13.705044  2642 net.cpp:84] Creating Layer BatchNorm40
I0924 21:06:13.705046  2642 net.cpp:406] BatchNorm40 <- Convolution40
I0924 21:06:13.705051  2642 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I0924 21:06:13.705193  2642 net.cpp:122] Setting up BatchNorm40
I0924 21:06:13.705198  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.705199  2642 net.cpp:137] Memory required for data: 789958800
I0924 21:06:13.705204  2642 layer_factory.hpp:77] Creating layer Scale40
I0924 21:06:13.705207  2642 net.cpp:84] Creating Layer Scale40
I0924 21:06:13.705210  2642 net.cpp:406] Scale40 <- Convolution40
I0924 21:06:13.705214  2642 net.cpp:367] Scale40 -> Convolution40 (in-place)
I0924 21:06:13.705241  2642 layer_factory.hpp:77] Creating layer Scale40
I0924 21:06:13.705322  2642 net.cpp:122] Setting up Scale40
I0924 21:06:13.705327  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.705328  2642 net.cpp:137] Memory required for data: 791213200
I0924 21:06:13.705332  2642 layer_factory.hpp:77] Creating layer ReLU38
I0924 21:06:13.705335  2642 net.cpp:84] Creating Layer ReLU38
I0924 21:06:13.705338  2642 net.cpp:406] ReLU38 <- Convolution40
I0924 21:06:13.705340  2642 net.cpp:367] ReLU38 -> Convolution40 (in-place)
I0924 21:06:13.705461  2642 net.cpp:122] Setting up ReLU38
I0924 21:06:13.705466  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.705467  2642 net.cpp:137] Memory required for data: 792467600
I0924 21:06:13.705471  2642 layer_factory.hpp:77] Creating layer Convolution41
I0924 21:06:13.705476  2642 net.cpp:84] Creating Layer Convolution41
I0924 21:06:13.705479  2642 net.cpp:406] Convolution41 <- Convolution40
I0924 21:06:13.705484  2642 net.cpp:380] Convolution41 -> Convolution41
I0924 21:06:13.707430  2642 net.cpp:122] Setting up Convolution41
I0924 21:06:13.707438  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.707440  2642 net.cpp:137] Memory required for data: 793722000
I0924 21:06:13.707445  2642 layer_factory.hpp:77] Creating layer BatchNorm41
I0924 21:06:13.707450  2642 net.cpp:84] Creating Layer BatchNorm41
I0924 21:06:13.707453  2642 net.cpp:406] BatchNorm41 <- Convolution41
I0924 21:06:13.707456  2642 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I0924 21:06:13.707602  2642 net.cpp:122] Setting up BatchNorm41
I0924 21:06:13.707607  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.707608  2642 net.cpp:137] Memory required for data: 794976400
I0924 21:06:13.707613  2642 layer_factory.hpp:77] Creating layer Scale41
I0924 21:06:13.707617  2642 net.cpp:84] Creating Layer Scale41
I0924 21:06:13.707619  2642 net.cpp:406] Scale41 <- Convolution41
I0924 21:06:13.707623  2642 net.cpp:367] Scale41 -> Convolution41 (in-place)
I0924 21:06:13.707653  2642 layer_factory.hpp:77] Creating layer Scale41
I0924 21:06:13.707736  2642 net.cpp:122] Setting up Scale41
I0924 21:06:13.707746  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.707748  2642 net.cpp:137] Memory required for data: 796230800
I0924 21:06:13.707752  2642 layer_factory.hpp:77] Creating layer Eltwise19
I0924 21:06:13.707757  2642 net.cpp:84] Creating Layer Eltwise19
I0924 21:06:13.707759  2642 net.cpp:406] Eltwise19 <- Convolution39
I0924 21:06:13.707762  2642 net.cpp:406] Eltwise19 <- Convolution41
I0924 21:06:13.707765  2642 net.cpp:380] Eltwise19 -> Eltwise19
I0924 21:06:13.707784  2642 net.cpp:122] Setting up Eltwise19
I0924 21:06:13.707788  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.707790  2642 net.cpp:137] Memory required for data: 797485200
I0924 21:06:13.707792  2642 layer_factory.hpp:77] Creating layer ReLU39
I0924 21:06:13.707795  2642 net.cpp:84] Creating Layer ReLU39
I0924 21:06:13.707798  2642 net.cpp:406] ReLU39 <- Eltwise19
I0924 21:06:13.707801  2642 net.cpp:367] ReLU39 -> Eltwise19 (in-place)
I0924 21:06:13.707921  2642 net.cpp:122] Setting up ReLU39
I0924 21:06:13.707926  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.707928  2642 net.cpp:137] Memory required for data: 798739600
I0924 21:06:13.707931  2642 layer_factory.hpp:77] Creating layer Eltwise19_ReLU39_0_split
I0924 21:06:13.707934  2642 net.cpp:84] Creating Layer Eltwise19_ReLU39_0_split
I0924 21:06:13.707937  2642 net.cpp:406] Eltwise19_ReLU39_0_split <- Eltwise19
I0924 21:06:13.707942  2642 net.cpp:380] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_0
I0924 21:06:13.707945  2642 net.cpp:380] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_1
I0924 21:06:13.707973  2642 net.cpp:122] Setting up Eltwise19_ReLU39_0_split
I0924 21:06:13.707978  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.707980  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.707983  2642 net.cpp:137] Memory required for data: 801248400
I0924 21:06:13.707984  2642 layer_factory.hpp:77] Creating layer Convolution42
I0924 21:06:13.707991  2642 net.cpp:84] Creating Layer Convolution42
I0924 21:06:13.707993  2642 net.cpp:406] Convolution42 <- Eltwise19_ReLU39_0_split_0
I0924 21:06:13.707998  2642 net.cpp:380] Convolution42 -> Convolution42
I0924 21:06:13.709633  2642 net.cpp:122] Setting up Convolution42
I0924 21:06:13.709641  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.709645  2642 net.cpp:137] Memory required for data: 802502800
I0924 21:06:13.709648  2642 layer_factory.hpp:77] Creating layer BatchNorm42
I0924 21:06:13.709652  2642 net.cpp:84] Creating Layer BatchNorm42
I0924 21:06:13.709656  2642 net.cpp:406] BatchNorm42 <- Convolution42
I0924 21:06:13.709659  2642 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I0924 21:06:13.709800  2642 net.cpp:122] Setting up BatchNorm42
I0924 21:06:13.709805  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.709807  2642 net.cpp:137] Memory required for data: 803757200
I0924 21:06:13.709812  2642 layer_factory.hpp:77] Creating layer Scale42
I0924 21:06:13.709816  2642 net.cpp:84] Creating Layer Scale42
I0924 21:06:13.709820  2642 net.cpp:406] Scale42 <- Convolution42
I0924 21:06:13.709822  2642 net.cpp:367] Scale42 -> Convolution42 (in-place)
I0924 21:06:13.709851  2642 layer_factory.hpp:77] Creating layer Scale42
I0924 21:06:13.709931  2642 net.cpp:122] Setting up Scale42
I0924 21:06:13.709936  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.709939  2642 net.cpp:137] Memory required for data: 805011600
I0924 21:06:13.709941  2642 layer_factory.hpp:77] Creating layer ReLU40
I0924 21:06:13.709945  2642 net.cpp:84] Creating Layer ReLU40
I0924 21:06:13.709947  2642 net.cpp:406] ReLU40 <- Convolution42
I0924 21:06:13.709952  2642 net.cpp:367] ReLU40 -> Convolution42 (in-place)
I0924 21:06:13.710391  2642 net.cpp:122] Setting up ReLU40
I0924 21:06:13.710399  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.710402  2642 net.cpp:137] Memory required for data: 806266000
I0924 21:06:13.710404  2642 layer_factory.hpp:77] Creating layer Convolution43
I0924 21:06:13.710410  2642 net.cpp:84] Creating Layer Convolution43
I0924 21:06:13.710420  2642 net.cpp:406] Convolution43 <- Convolution42
I0924 21:06:13.710425  2642 net.cpp:380] Convolution43 -> Convolution43
I0924 21:06:13.712419  2642 net.cpp:122] Setting up Convolution43
I0924 21:06:13.712427  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.712430  2642 net.cpp:137] Memory required for data: 807520400
I0924 21:06:13.712435  2642 layer_factory.hpp:77] Creating layer BatchNorm43
I0924 21:06:13.712440  2642 net.cpp:84] Creating Layer BatchNorm43
I0924 21:06:13.712442  2642 net.cpp:406] BatchNorm43 <- Convolution43
I0924 21:06:13.712447  2642 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I0924 21:06:13.712602  2642 net.cpp:122] Setting up BatchNorm43
I0924 21:06:13.712607  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.712610  2642 net.cpp:137] Memory required for data: 808774800
I0924 21:06:13.712615  2642 layer_factory.hpp:77] Creating layer Scale43
I0924 21:06:13.712620  2642 net.cpp:84] Creating Layer Scale43
I0924 21:06:13.712622  2642 net.cpp:406] Scale43 <- Convolution43
I0924 21:06:13.712625  2642 net.cpp:367] Scale43 -> Convolution43 (in-place)
I0924 21:06:13.712656  2642 layer_factory.hpp:77] Creating layer Scale43
I0924 21:06:13.712743  2642 net.cpp:122] Setting up Scale43
I0924 21:06:13.712748  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.712749  2642 net.cpp:137] Memory required for data: 810029200
I0924 21:06:13.712754  2642 layer_factory.hpp:77] Creating layer Eltwise20
I0924 21:06:13.712759  2642 net.cpp:84] Creating Layer Eltwise20
I0924 21:06:13.712761  2642 net.cpp:406] Eltwise20 <- Eltwise19_ReLU39_0_split_1
I0924 21:06:13.712764  2642 net.cpp:406] Eltwise20 <- Convolution43
I0924 21:06:13.712769  2642 net.cpp:380] Eltwise20 -> Eltwise20
I0924 21:06:13.712785  2642 net.cpp:122] Setting up Eltwise20
I0924 21:06:13.712790  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.712791  2642 net.cpp:137] Memory required for data: 811283600
I0924 21:06:13.712793  2642 layer_factory.hpp:77] Creating layer ReLU41
I0924 21:06:13.712797  2642 net.cpp:84] Creating Layer ReLU41
I0924 21:06:13.712800  2642 net.cpp:406] ReLU41 <- Eltwise20
I0924 21:06:13.712803  2642 net.cpp:367] ReLU41 -> Eltwise20 (in-place)
I0924 21:06:13.712939  2642 net.cpp:122] Setting up ReLU41
I0924 21:06:13.712945  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.712947  2642 net.cpp:137] Memory required for data: 812538000
I0924 21:06:13.712950  2642 layer_factory.hpp:77] Creating layer Eltwise20_ReLU41_0_split
I0924 21:06:13.712954  2642 net.cpp:84] Creating Layer Eltwise20_ReLU41_0_split
I0924 21:06:13.712957  2642 net.cpp:406] Eltwise20_ReLU41_0_split <- Eltwise20
I0924 21:06:13.712960  2642 net.cpp:380] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_0
I0924 21:06:13.712965  2642 net.cpp:380] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_1
I0924 21:06:13.712996  2642 net.cpp:122] Setting up Eltwise20_ReLU41_0_split
I0924 21:06:13.713001  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.713003  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.713006  2642 net.cpp:137] Memory required for data: 815046800
I0924 21:06:13.713007  2642 layer_factory.hpp:77] Creating layer Convolution44
I0924 21:06:13.713013  2642 net.cpp:84] Creating Layer Convolution44
I0924 21:06:13.713016  2642 net.cpp:406] Convolution44 <- Eltwise20_ReLU41_0_split_0
I0924 21:06:13.713021  2642 net.cpp:380] Convolution44 -> Convolution44
I0924 21:06:13.715062  2642 net.cpp:122] Setting up Convolution44
I0924 21:06:13.715071  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.715075  2642 net.cpp:137] Memory required for data: 816301200
I0924 21:06:13.715078  2642 layer_factory.hpp:77] Creating layer BatchNorm44
I0924 21:06:13.715085  2642 net.cpp:84] Creating Layer BatchNorm44
I0924 21:06:13.715087  2642 net.cpp:406] BatchNorm44 <- Convolution44
I0924 21:06:13.715090  2642 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I0924 21:06:13.715242  2642 net.cpp:122] Setting up BatchNorm44
I0924 21:06:13.715255  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.715256  2642 net.cpp:137] Memory required for data: 817555600
I0924 21:06:13.715261  2642 layer_factory.hpp:77] Creating layer Scale44
I0924 21:06:13.715266  2642 net.cpp:84] Creating Layer Scale44
I0924 21:06:13.715270  2642 net.cpp:406] Scale44 <- Convolution44
I0924 21:06:13.715272  2642 net.cpp:367] Scale44 -> Convolution44 (in-place)
I0924 21:06:13.715304  2642 layer_factory.hpp:77] Creating layer Scale44
I0924 21:06:13.715390  2642 net.cpp:122] Setting up Scale44
I0924 21:06:13.715394  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.715396  2642 net.cpp:137] Memory required for data: 818810000
I0924 21:06:13.715400  2642 layer_factory.hpp:77] Creating layer ReLU42
I0924 21:06:13.715404  2642 net.cpp:84] Creating Layer ReLU42
I0924 21:06:13.715407  2642 net.cpp:406] ReLU42 <- Convolution44
I0924 21:06:13.715410  2642 net.cpp:367] ReLU42 -> Convolution44 (in-place)
I0924 21:06:13.715538  2642 net.cpp:122] Setting up ReLU42
I0924 21:06:13.715543  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.715545  2642 net.cpp:137] Memory required for data: 820064400
I0924 21:06:13.715548  2642 layer_factory.hpp:77] Creating layer Convolution45
I0924 21:06:13.715554  2642 net.cpp:84] Creating Layer Convolution45
I0924 21:06:13.715557  2642 net.cpp:406] Convolution45 <- Convolution44
I0924 21:06:13.715562  2642 net.cpp:380] Convolution45 -> Convolution45
I0924 21:06:13.717584  2642 net.cpp:122] Setting up Convolution45
I0924 21:06:13.717593  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.717595  2642 net.cpp:137] Memory required for data: 821318800
I0924 21:06:13.717602  2642 layer_factory.hpp:77] Creating layer BatchNorm45
I0924 21:06:13.717605  2642 net.cpp:84] Creating Layer BatchNorm45
I0924 21:06:13.717608  2642 net.cpp:406] BatchNorm45 <- Convolution45
I0924 21:06:13.717612  2642 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I0924 21:06:13.717759  2642 net.cpp:122] Setting up BatchNorm45
I0924 21:06:13.717764  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.717767  2642 net.cpp:137] Memory required for data: 822573200
I0924 21:06:13.717770  2642 layer_factory.hpp:77] Creating layer Scale45
I0924 21:06:13.717777  2642 net.cpp:84] Creating Layer Scale45
I0924 21:06:13.717779  2642 net.cpp:406] Scale45 <- Convolution45
I0924 21:06:13.717782  2642 net.cpp:367] Scale45 -> Convolution45 (in-place)
I0924 21:06:13.717813  2642 layer_factory.hpp:77] Creating layer Scale45
I0924 21:06:13.717896  2642 net.cpp:122] Setting up Scale45
I0924 21:06:13.717900  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.717902  2642 net.cpp:137] Memory required for data: 823827600
I0924 21:06:13.717906  2642 layer_factory.hpp:77] Creating layer Eltwise21
I0924 21:06:13.717911  2642 net.cpp:84] Creating Layer Eltwise21
I0924 21:06:13.717912  2642 net.cpp:406] Eltwise21 <- Eltwise20_ReLU41_0_split_1
I0924 21:06:13.717916  2642 net.cpp:406] Eltwise21 <- Convolution45
I0924 21:06:13.717919  2642 net.cpp:380] Eltwise21 -> Eltwise21
I0924 21:06:13.717936  2642 net.cpp:122] Setting up Eltwise21
I0924 21:06:13.717941  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.717941  2642 net.cpp:137] Memory required for data: 825082000
I0924 21:06:13.717944  2642 layer_factory.hpp:77] Creating layer ReLU43
I0924 21:06:13.717948  2642 net.cpp:84] Creating Layer ReLU43
I0924 21:06:13.717950  2642 net.cpp:406] ReLU43 <- Eltwise21
I0924 21:06:13.717953  2642 net.cpp:367] ReLU43 -> Eltwise21 (in-place)
I0924 21:06:13.718076  2642 net.cpp:122] Setting up ReLU43
I0924 21:06:13.718082  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.718085  2642 net.cpp:137] Memory required for data: 826336400
I0924 21:06:13.718086  2642 layer_factory.hpp:77] Creating layer Eltwise21_ReLU43_0_split
I0924 21:06:13.718091  2642 net.cpp:84] Creating Layer Eltwise21_ReLU43_0_split
I0924 21:06:13.718093  2642 net.cpp:406] Eltwise21_ReLU43_0_split <- Eltwise21
I0924 21:06:13.718096  2642 net.cpp:380] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_0
I0924 21:06:13.718107  2642 net.cpp:380] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_1
I0924 21:06:13.718137  2642 net.cpp:122] Setting up Eltwise21_ReLU43_0_split
I0924 21:06:13.718142  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.718143  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.718145  2642 net.cpp:137] Memory required for data: 828845200
I0924 21:06:13.718147  2642 layer_factory.hpp:77] Creating layer Convolution46
I0924 21:06:13.718154  2642 net.cpp:84] Creating Layer Convolution46
I0924 21:06:13.718158  2642 net.cpp:406] Convolution46 <- Eltwise21_ReLU43_0_split_0
I0924 21:06:13.718163  2642 net.cpp:380] Convolution46 -> Convolution46
I0924 21:06:13.719820  2642 net.cpp:122] Setting up Convolution46
I0924 21:06:13.719828  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.719831  2642 net.cpp:137] Memory required for data: 830099600
I0924 21:06:13.719835  2642 layer_factory.hpp:77] Creating layer BatchNorm46
I0924 21:06:13.719841  2642 net.cpp:84] Creating Layer BatchNorm46
I0924 21:06:13.719843  2642 net.cpp:406] BatchNorm46 <- Convolution46
I0924 21:06:13.719846  2642 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I0924 21:06:13.719990  2642 net.cpp:122] Setting up BatchNorm46
I0924 21:06:13.719995  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.719997  2642 net.cpp:137] Memory required for data: 831354000
I0924 21:06:13.720001  2642 layer_factory.hpp:77] Creating layer Scale46
I0924 21:06:13.720005  2642 net.cpp:84] Creating Layer Scale46
I0924 21:06:13.720008  2642 net.cpp:406] Scale46 <- Convolution46
I0924 21:06:13.720011  2642 net.cpp:367] Scale46 -> Convolution46 (in-place)
I0924 21:06:13.720041  2642 layer_factory.hpp:77] Creating layer Scale46
I0924 21:06:13.720124  2642 net.cpp:122] Setting up Scale46
I0924 21:06:13.720127  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.720129  2642 net.cpp:137] Memory required for data: 832608400
I0924 21:06:13.720134  2642 layer_factory.hpp:77] Creating layer ReLU44
I0924 21:06:13.720137  2642 net.cpp:84] Creating Layer ReLU44
I0924 21:06:13.720139  2642 net.cpp:406] ReLU44 <- Convolution46
I0924 21:06:13.720142  2642 net.cpp:367] ReLU44 -> Convolution46 (in-place)
I0924 21:06:13.720263  2642 net.cpp:122] Setting up ReLU44
I0924 21:06:13.720270  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.720273  2642 net.cpp:137] Memory required for data: 833862800
I0924 21:06:13.720274  2642 layer_factory.hpp:77] Creating layer Convolution47
I0924 21:06:13.720281  2642 net.cpp:84] Creating Layer Convolution47
I0924 21:06:13.720284  2642 net.cpp:406] Convolution47 <- Convolution46
I0924 21:06:13.720288  2642 net.cpp:380] Convolution47 -> Convolution47
I0924 21:06:13.722271  2642 net.cpp:122] Setting up Convolution47
I0924 21:06:13.722280  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.722282  2642 net.cpp:137] Memory required for data: 835117200
I0924 21:06:13.722286  2642 layer_factory.hpp:77] Creating layer BatchNorm47
I0924 21:06:13.722291  2642 net.cpp:84] Creating Layer BatchNorm47
I0924 21:06:13.722295  2642 net.cpp:406] BatchNorm47 <- Convolution47
I0924 21:06:13.722297  2642 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I0924 21:06:13.722448  2642 net.cpp:122] Setting up BatchNorm47
I0924 21:06:13.722452  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.722455  2642 net.cpp:137] Memory required for data: 836371600
I0924 21:06:13.722460  2642 layer_factory.hpp:77] Creating layer Scale47
I0924 21:06:13.722463  2642 net.cpp:84] Creating Layer Scale47
I0924 21:06:13.722465  2642 net.cpp:406] Scale47 <- Convolution47
I0924 21:06:13.722470  2642 net.cpp:367] Scale47 -> Convolution47 (in-place)
I0924 21:06:13.722498  2642 layer_factory.hpp:77] Creating layer Scale47
I0924 21:06:13.722584  2642 net.cpp:122] Setting up Scale47
I0924 21:06:13.722589  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.722590  2642 net.cpp:137] Memory required for data: 837626000
I0924 21:06:13.722600  2642 layer_factory.hpp:77] Creating layer Eltwise22
I0924 21:06:13.722605  2642 net.cpp:84] Creating Layer Eltwise22
I0924 21:06:13.722609  2642 net.cpp:406] Eltwise22 <- Eltwise21_ReLU43_0_split_1
I0924 21:06:13.722611  2642 net.cpp:406] Eltwise22 <- Convolution47
I0924 21:06:13.722615  2642 net.cpp:380] Eltwise22 -> Eltwise22
I0924 21:06:13.722633  2642 net.cpp:122] Setting up Eltwise22
I0924 21:06:13.722637  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.722638  2642 net.cpp:137] Memory required for data: 838880400
I0924 21:06:13.722640  2642 layer_factory.hpp:77] Creating layer ReLU45
I0924 21:06:13.722645  2642 net.cpp:84] Creating Layer ReLU45
I0924 21:06:13.722646  2642 net.cpp:406] ReLU45 <- Eltwise22
I0924 21:06:13.722649  2642 net.cpp:367] ReLU45 -> Eltwise22 (in-place)
I0924 21:06:13.722777  2642 net.cpp:122] Setting up ReLU45
I0924 21:06:13.722782  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.722784  2642 net.cpp:137] Memory required for data: 840134800
I0924 21:06:13.722787  2642 layer_factory.hpp:77] Creating layer Eltwise22_ReLU45_0_split
I0924 21:06:13.722790  2642 net.cpp:84] Creating Layer Eltwise22_ReLU45_0_split
I0924 21:06:13.722792  2642 net.cpp:406] Eltwise22_ReLU45_0_split <- Eltwise22
I0924 21:06:13.722797  2642 net.cpp:380] Eltwise22_ReLU45_0_split -> Eltwise22_ReLU45_0_split_0
I0924 21:06:13.722801  2642 net.cpp:380] Eltwise22_ReLU45_0_split -> Eltwise22_ReLU45_0_split_1
I0924 21:06:13.722831  2642 net.cpp:122] Setting up Eltwise22_ReLU45_0_split
I0924 21:06:13.722836  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.722837  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.722839  2642 net.cpp:137] Memory required for data: 842643600
I0924 21:06:13.722841  2642 layer_factory.hpp:77] Creating layer Convolution48
I0924 21:06:13.722848  2642 net.cpp:84] Creating Layer Convolution48
I0924 21:06:13.722851  2642 net.cpp:406] Convolution48 <- Eltwise22_ReLU45_0_split_0
I0924 21:06:13.722854  2642 net.cpp:380] Convolution48 -> Convolution48
I0924 21:06:13.724480  2642 net.cpp:122] Setting up Convolution48
I0924 21:06:13.724488  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.724491  2642 net.cpp:137] Memory required for data: 843898000
I0924 21:06:13.724495  2642 layer_factory.hpp:77] Creating layer BatchNorm48
I0924 21:06:13.724499  2642 net.cpp:84] Creating Layer BatchNorm48
I0924 21:06:13.724503  2642 net.cpp:406] BatchNorm48 <- Convolution48
I0924 21:06:13.724506  2642 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I0924 21:06:13.724654  2642 net.cpp:122] Setting up BatchNorm48
I0924 21:06:13.724659  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.724661  2642 net.cpp:137] Memory required for data: 845152400
I0924 21:06:13.724665  2642 layer_factory.hpp:77] Creating layer Scale48
I0924 21:06:13.724669  2642 net.cpp:84] Creating Layer Scale48
I0924 21:06:13.724673  2642 net.cpp:406] Scale48 <- Convolution48
I0924 21:06:13.724676  2642 net.cpp:367] Scale48 -> Convolution48 (in-place)
I0924 21:06:13.724704  2642 layer_factory.hpp:77] Creating layer Scale48
I0924 21:06:13.724787  2642 net.cpp:122] Setting up Scale48
I0924 21:06:13.724792  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.724793  2642 net.cpp:137] Memory required for data: 846406800
I0924 21:06:13.724797  2642 layer_factory.hpp:77] Creating layer ReLU46
I0924 21:06:13.724802  2642 net.cpp:84] Creating Layer ReLU46
I0924 21:06:13.724803  2642 net.cpp:406] ReLU46 <- Convolution48
I0924 21:06:13.724807  2642 net.cpp:367] ReLU46 -> Convolution48 (in-place)
I0924 21:06:13.725261  2642 net.cpp:122] Setting up ReLU46
I0924 21:06:13.725270  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.725272  2642 net.cpp:137] Memory required for data: 847661200
I0924 21:06:13.725275  2642 layer_factory.hpp:77] Creating layer Convolution49
I0924 21:06:13.725283  2642 net.cpp:84] Creating Layer Convolution49
I0924 21:06:13.725286  2642 net.cpp:406] Convolution49 <- Convolution48
I0924 21:06:13.725297  2642 net.cpp:380] Convolution49 -> Convolution49
I0924 21:06:13.727581  2642 net.cpp:122] Setting up Convolution49
I0924 21:06:13.727588  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.727591  2642 net.cpp:137] Memory required for data: 848915600
I0924 21:06:13.727596  2642 layer_factory.hpp:77] Creating layer BatchNorm49
I0924 21:06:13.727600  2642 net.cpp:84] Creating Layer BatchNorm49
I0924 21:06:13.727603  2642 net.cpp:406] BatchNorm49 <- Convolution49
I0924 21:06:13.727607  2642 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I0924 21:06:13.727759  2642 net.cpp:122] Setting up BatchNorm49
I0924 21:06:13.727764  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.727766  2642 net.cpp:137] Memory required for data: 850170000
I0924 21:06:13.727771  2642 layer_factory.hpp:77] Creating layer Scale49
I0924 21:06:13.727776  2642 net.cpp:84] Creating Layer Scale49
I0924 21:06:13.727777  2642 net.cpp:406] Scale49 <- Convolution49
I0924 21:06:13.727780  2642 net.cpp:367] Scale49 -> Convolution49 (in-place)
I0924 21:06:13.727811  2642 layer_factory.hpp:77] Creating layer Scale49
I0924 21:06:13.727896  2642 net.cpp:122] Setting up Scale49
I0924 21:06:13.727900  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.727902  2642 net.cpp:137] Memory required for data: 851424400
I0924 21:06:13.727906  2642 layer_factory.hpp:77] Creating layer Eltwise23
I0924 21:06:13.727910  2642 net.cpp:84] Creating Layer Eltwise23
I0924 21:06:13.727913  2642 net.cpp:406] Eltwise23 <- Eltwise22_ReLU45_0_split_1
I0924 21:06:13.727916  2642 net.cpp:406] Eltwise23 <- Convolution49
I0924 21:06:13.727919  2642 net.cpp:380] Eltwise23 -> Eltwise23
I0924 21:06:13.727937  2642 net.cpp:122] Setting up Eltwise23
I0924 21:06:13.727941  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.727942  2642 net.cpp:137] Memory required for data: 852678800
I0924 21:06:13.727944  2642 layer_factory.hpp:77] Creating layer ReLU47
I0924 21:06:13.727948  2642 net.cpp:84] Creating Layer ReLU47
I0924 21:06:13.727951  2642 net.cpp:406] ReLU47 <- Eltwise23
I0924 21:06:13.727954  2642 net.cpp:367] ReLU47 -> Eltwise23 (in-place)
I0924 21:06:13.728080  2642 net.cpp:122] Setting up ReLU47
I0924 21:06:13.728085  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.728087  2642 net.cpp:137] Memory required for data: 853933200
I0924 21:06:13.728090  2642 layer_factory.hpp:77] Creating layer Eltwise23_ReLU47_0_split
I0924 21:06:13.728092  2642 net.cpp:84] Creating Layer Eltwise23_ReLU47_0_split
I0924 21:06:13.728096  2642 net.cpp:406] Eltwise23_ReLU47_0_split <- Eltwise23
I0924 21:06:13.728099  2642 net.cpp:380] Eltwise23_ReLU47_0_split -> Eltwise23_ReLU47_0_split_0
I0924 21:06:13.728103  2642 net.cpp:380] Eltwise23_ReLU47_0_split -> Eltwise23_ReLU47_0_split_1
I0924 21:06:13.728133  2642 net.cpp:122] Setting up Eltwise23_ReLU47_0_split
I0924 21:06:13.728137  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.728140  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.728142  2642 net.cpp:137] Memory required for data: 856442000
I0924 21:06:13.728144  2642 layer_factory.hpp:77] Creating layer Convolution50
I0924 21:06:13.728150  2642 net.cpp:84] Creating Layer Convolution50
I0924 21:06:13.728152  2642 net.cpp:406] Convolution50 <- Eltwise23_ReLU47_0_split_0
I0924 21:06:13.728157  2642 net.cpp:380] Convolution50 -> Convolution50
I0924 21:06:13.729851  2642 net.cpp:122] Setting up Convolution50
I0924 21:06:13.729861  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.729862  2642 net.cpp:137] Memory required for data: 857696400
I0924 21:06:13.729866  2642 layer_factory.hpp:77] Creating layer BatchNorm50
I0924 21:06:13.729871  2642 net.cpp:84] Creating Layer BatchNorm50
I0924 21:06:13.729874  2642 net.cpp:406] BatchNorm50 <- Convolution50
I0924 21:06:13.729878  2642 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I0924 21:06:13.730029  2642 net.cpp:122] Setting up BatchNorm50
I0924 21:06:13.730034  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.730036  2642 net.cpp:137] Memory required for data: 858950800
I0924 21:06:13.730047  2642 layer_factory.hpp:77] Creating layer Scale50
I0924 21:06:13.730051  2642 net.cpp:84] Creating Layer Scale50
I0924 21:06:13.730054  2642 net.cpp:406] Scale50 <- Convolution50
I0924 21:06:13.730058  2642 net.cpp:367] Scale50 -> Convolution50 (in-place)
I0924 21:06:13.730088  2642 layer_factory.hpp:77] Creating layer Scale50
I0924 21:06:13.730173  2642 net.cpp:122] Setting up Scale50
I0924 21:06:13.730177  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.730180  2642 net.cpp:137] Memory required for data: 860205200
I0924 21:06:13.730183  2642 layer_factory.hpp:77] Creating layer ReLU48
I0924 21:06:13.730186  2642 net.cpp:84] Creating Layer ReLU48
I0924 21:06:13.730190  2642 net.cpp:406] ReLU48 <- Convolution50
I0924 21:06:13.730195  2642 net.cpp:367] ReLU48 -> Convolution50 (in-place)
I0924 21:06:13.730314  2642 net.cpp:122] Setting up ReLU48
I0924 21:06:13.730320  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.730322  2642 net.cpp:137] Memory required for data: 861459600
I0924 21:06:13.730324  2642 layer_factory.hpp:77] Creating layer Convolution51
I0924 21:06:13.730331  2642 net.cpp:84] Creating Layer Convolution51
I0924 21:06:13.730334  2642 net.cpp:406] Convolution51 <- Convolution50
I0924 21:06:13.730340  2642 net.cpp:380] Convolution51 -> Convolution51
I0924 21:06:13.732311  2642 net.cpp:122] Setting up Convolution51
I0924 21:06:13.732318  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.732321  2642 net.cpp:137] Memory required for data: 862714000
I0924 21:06:13.732326  2642 layer_factory.hpp:77] Creating layer BatchNorm51
I0924 21:06:13.732331  2642 net.cpp:84] Creating Layer BatchNorm51
I0924 21:06:13.732333  2642 net.cpp:406] BatchNorm51 <- Convolution51
I0924 21:06:13.732337  2642 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I0924 21:06:13.732491  2642 net.cpp:122] Setting up BatchNorm51
I0924 21:06:13.732494  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.732496  2642 net.cpp:137] Memory required for data: 863968400
I0924 21:06:13.732501  2642 layer_factory.hpp:77] Creating layer Scale51
I0924 21:06:13.732506  2642 net.cpp:84] Creating Layer Scale51
I0924 21:06:13.732507  2642 net.cpp:406] Scale51 <- Convolution51
I0924 21:06:13.732511  2642 net.cpp:367] Scale51 -> Convolution51 (in-place)
I0924 21:06:13.732540  2642 layer_factory.hpp:77] Creating layer Scale51
I0924 21:06:13.732625  2642 net.cpp:122] Setting up Scale51
I0924 21:06:13.732630  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.732631  2642 net.cpp:137] Memory required for data: 865222800
I0924 21:06:13.732635  2642 layer_factory.hpp:77] Creating layer Eltwise24
I0924 21:06:13.732640  2642 net.cpp:84] Creating Layer Eltwise24
I0924 21:06:13.732642  2642 net.cpp:406] Eltwise24 <- Eltwise23_ReLU47_0_split_1
I0924 21:06:13.732645  2642 net.cpp:406] Eltwise24 <- Convolution51
I0924 21:06:13.732648  2642 net.cpp:380] Eltwise24 -> Eltwise24
I0924 21:06:13.732666  2642 net.cpp:122] Setting up Eltwise24
I0924 21:06:13.732671  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.732672  2642 net.cpp:137] Memory required for data: 866477200
I0924 21:06:13.732674  2642 layer_factory.hpp:77] Creating layer ReLU49
I0924 21:06:13.732678  2642 net.cpp:84] Creating Layer ReLU49
I0924 21:06:13.732681  2642 net.cpp:406] ReLU49 <- Eltwise24
I0924 21:06:13.732683  2642 net.cpp:367] ReLU49 -> Eltwise24 (in-place)
I0924 21:06:13.732811  2642 net.cpp:122] Setting up ReLU49
I0924 21:06:13.732818  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.732820  2642 net.cpp:137] Memory required for data: 867731600
I0924 21:06:13.732822  2642 layer_factory.hpp:77] Creating layer Eltwise24_ReLU49_0_split
I0924 21:06:13.732826  2642 net.cpp:84] Creating Layer Eltwise24_ReLU49_0_split
I0924 21:06:13.732828  2642 net.cpp:406] Eltwise24_ReLU49_0_split <- Eltwise24
I0924 21:06:13.732831  2642 net.cpp:380] Eltwise24_ReLU49_0_split -> Eltwise24_ReLU49_0_split_0
I0924 21:06:13.732836  2642 net.cpp:380] Eltwise24_ReLU49_0_split -> Eltwise24_ReLU49_0_split_1
I0924 21:06:13.732873  2642 net.cpp:122] Setting up Eltwise24_ReLU49_0_split
I0924 21:06:13.732878  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.732880  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.732882  2642 net.cpp:137] Memory required for data: 870240400
I0924 21:06:13.732884  2642 layer_factory.hpp:77] Creating layer Convolution52
I0924 21:06:13.732892  2642 net.cpp:84] Creating Layer Convolution52
I0924 21:06:13.732894  2642 net.cpp:406] Convolution52 <- Eltwise24_ReLU49_0_split_0
I0924 21:06:13.732900  2642 net.cpp:380] Convolution52 -> Convolution52
I0924 21:06:13.734582  2642 net.cpp:122] Setting up Convolution52
I0924 21:06:13.734591  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.734593  2642 net.cpp:137] Memory required for data: 871494800
I0924 21:06:13.734598  2642 layer_factory.hpp:77] Creating layer BatchNorm52
I0924 21:06:13.734603  2642 net.cpp:84] Creating Layer BatchNorm52
I0924 21:06:13.734606  2642 net.cpp:406] BatchNorm52 <- Convolution52
I0924 21:06:13.734609  2642 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I0924 21:06:13.734761  2642 net.cpp:122] Setting up BatchNorm52
I0924 21:06:13.734766  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.734768  2642 net.cpp:137] Memory required for data: 872749200
I0924 21:06:13.734772  2642 layer_factory.hpp:77] Creating layer Scale52
I0924 21:06:13.734776  2642 net.cpp:84] Creating Layer Scale52
I0924 21:06:13.734779  2642 net.cpp:406] Scale52 <- Convolution52
I0924 21:06:13.734783  2642 net.cpp:367] Scale52 -> Convolution52 (in-place)
I0924 21:06:13.734812  2642 layer_factory.hpp:77] Creating layer Scale52
I0924 21:06:13.734897  2642 net.cpp:122] Setting up Scale52
I0924 21:06:13.734901  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.734904  2642 net.cpp:137] Memory required for data: 874003600
I0924 21:06:13.734907  2642 layer_factory.hpp:77] Creating layer ReLU50
I0924 21:06:13.734910  2642 net.cpp:84] Creating Layer ReLU50
I0924 21:06:13.734913  2642 net.cpp:406] ReLU50 <- Convolution52
I0924 21:06:13.734916  2642 net.cpp:367] ReLU50 -> Convolution52 (in-place)
I0924 21:06:13.735038  2642 net.cpp:122] Setting up ReLU50
I0924 21:06:13.735044  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.735046  2642 net.cpp:137] Memory required for data: 875258000
I0924 21:06:13.735049  2642 layer_factory.hpp:77] Creating layer Convolution53
I0924 21:06:13.735071  2642 net.cpp:84] Creating Layer Convolution53
I0924 21:06:13.742724  2642 net.cpp:406] Convolution53 <- Convolution52
I0924 21:06:13.742735  2642 net.cpp:380] Convolution53 -> Convolution53
I0924 21:06:13.745272  2642 net.cpp:122] Setting up Convolution53
I0924 21:06:13.745282  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.745285  2642 net.cpp:137] Memory required for data: 876512400
I0924 21:06:13.745290  2642 layer_factory.hpp:77] Creating layer BatchNorm53
I0924 21:06:13.745296  2642 net.cpp:84] Creating Layer BatchNorm53
I0924 21:06:13.745298  2642 net.cpp:406] BatchNorm53 <- Convolution53
I0924 21:06:13.745303  2642 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I0924 21:06:13.745465  2642 net.cpp:122] Setting up BatchNorm53
I0924 21:06:13.745470  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.745471  2642 net.cpp:137] Memory required for data: 877766800
I0924 21:06:13.745476  2642 layer_factory.hpp:77] Creating layer Scale53
I0924 21:06:13.745481  2642 net.cpp:84] Creating Layer Scale53
I0924 21:06:13.745484  2642 net.cpp:406] Scale53 <- Convolution53
I0924 21:06:13.745487  2642 net.cpp:367] Scale53 -> Convolution53 (in-place)
I0924 21:06:13.745519  2642 layer_factory.hpp:77] Creating layer Scale53
I0924 21:06:13.745609  2642 net.cpp:122] Setting up Scale53
I0924 21:06:13.745613  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.745615  2642 net.cpp:137] Memory required for data: 879021200
I0924 21:06:13.745620  2642 layer_factory.hpp:77] Creating layer Eltwise25
I0924 21:06:13.745631  2642 net.cpp:84] Creating Layer Eltwise25
I0924 21:06:13.745635  2642 net.cpp:406] Eltwise25 <- Eltwise24_ReLU49_0_split_1
I0924 21:06:13.745638  2642 net.cpp:406] Eltwise25 <- Convolution53
I0924 21:06:13.745642  2642 net.cpp:380] Eltwise25 -> Eltwise25
I0924 21:06:13.745661  2642 net.cpp:122] Setting up Eltwise25
I0924 21:06:13.745666  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.745667  2642 net.cpp:137] Memory required for data: 880275600
I0924 21:06:13.745669  2642 layer_factory.hpp:77] Creating layer ReLU51
I0924 21:06:13.745673  2642 net.cpp:84] Creating Layer ReLU51
I0924 21:06:13.745676  2642 net.cpp:406] ReLU51 <- Eltwise25
I0924 21:06:13.745678  2642 net.cpp:367] ReLU51 -> Eltwise25 (in-place)
I0924 21:06:13.745807  2642 net.cpp:122] Setting up ReLU51
I0924 21:06:13.745813  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.745816  2642 net.cpp:137] Memory required for data: 881530000
I0924 21:06:13.745818  2642 layer_factory.hpp:77] Creating layer Eltwise25_ReLU51_0_split
I0924 21:06:13.745823  2642 net.cpp:84] Creating Layer Eltwise25_ReLU51_0_split
I0924 21:06:13.745826  2642 net.cpp:406] Eltwise25_ReLU51_0_split <- Eltwise25
I0924 21:06:13.745829  2642 net.cpp:380] Eltwise25_ReLU51_0_split -> Eltwise25_ReLU51_0_split_0
I0924 21:06:13.745833  2642 net.cpp:380] Eltwise25_ReLU51_0_split -> Eltwise25_ReLU51_0_split_1
I0924 21:06:13.745878  2642 net.cpp:122] Setting up Eltwise25_ReLU51_0_split
I0924 21:06:13.745882  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.745894  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.745896  2642 net.cpp:137] Memory required for data: 884038800
I0924 21:06:13.745898  2642 layer_factory.hpp:77] Creating layer Convolution54
I0924 21:06:13.745918  2642 net.cpp:84] Creating Layer Convolution54
I0924 21:06:13.745919  2642 net.cpp:406] Convolution54 <- Eltwise25_ReLU51_0_split_0
I0924 21:06:13.745924  2642 net.cpp:380] Convolution54 -> Convolution54
I0924 21:06:13.748221  2642 net.cpp:122] Setting up Convolution54
I0924 21:06:13.748232  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.748234  2642 net.cpp:137] Memory required for data: 885293200
I0924 21:06:13.748239  2642 layer_factory.hpp:77] Creating layer BatchNorm54
I0924 21:06:13.748245  2642 net.cpp:84] Creating Layer BatchNorm54
I0924 21:06:13.748247  2642 net.cpp:406] BatchNorm54 <- Convolution54
I0924 21:06:13.748252  2642 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I0924 21:06:13.748407  2642 net.cpp:122] Setting up BatchNorm54
I0924 21:06:13.748412  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.748414  2642 net.cpp:137] Memory required for data: 886547600
I0924 21:06:13.748420  2642 layer_factory.hpp:77] Creating layer Scale54
I0924 21:06:13.748425  2642 net.cpp:84] Creating Layer Scale54
I0924 21:06:13.748426  2642 net.cpp:406] Scale54 <- Convolution54
I0924 21:06:13.748430  2642 net.cpp:367] Scale54 -> Convolution54 (in-place)
I0924 21:06:13.748462  2642 layer_factory.hpp:77] Creating layer Scale54
I0924 21:06:13.748551  2642 net.cpp:122] Setting up Scale54
I0924 21:06:13.748556  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.748558  2642 net.cpp:137] Memory required for data: 887802000
I0924 21:06:13.748562  2642 layer_factory.hpp:77] Creating layer ReLU52
I0924 21:06:13.748566  2642 net.cpp:84] Creating Layer ReLU52
I0924 21:06:13.748569  2642 net.cpp:406] ReLU52 <- Convolution54
I0924 21:06:13.748571  2642 net.cpp:367] ReLU52 -> Convolution54 (in-place)
I0924 21:06:13.749017  2642 net.cpp:122] Setting up ReLU52
I0924 21:06:13.749025  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.749028  2642 net.cpp:137] Memory required for data: 889056400
I0924 21:06:13.749030  2642 layer_factory.hpp:77] Creating layer Convolution55
I0924 21:06:13.749038  2642 net.cpp:84] Creating Layer Convolution55
I0924 21:06:13.749042  2642 net.cpp:406] Convolution55 <- Convolution54
I0924 21:06:13.749045  2642 net.cpp:380] Convolution55 -> Convolution55
I0924 21:06:13.751031  2642 net.cpp:122] Setting up Convolution55
I0924 21:06:13.751047  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.751050  2642 net.cpp:137] Memory required for data: 890310800
I0924 21:06:13.751055  2642 layer_factory.hpp:77] Creating layer BatchNorm55
I0924 21:06:13.751060  2642 net.cpp:84] Creating Layer BatchNorm55
I0924 21:06:13.751063  2642 net.cpp:406] BatchNorm55 <- Convolution55
I0924 21:06:13.751067  2642 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I0924 21:06:13.751224  2642 net.cpp:122] Setting up BatchNorm55
I0924 21:06:13.751227  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.751230  2642 net.cpp:137] Memory required for data: 891565200
I0924 21:06:13.751235  2642 layer_factory.hpp:77] Creating layer Scale55
I0924 21:06:13.751238  2642 net.cpp:84] Creating Layer Scale55
I0924 21:06:13.751241  2642 net.cpp:406] Scale55 <- Convolution55
I0924 21:06:13.751245  2642 net.cpp:367] Scale55 -> Convolution55 (in-place)
I0924 21:06:13.751276  2642 layer_factory.hpp:77] Creating layer Scale55
I0924 21:06:13.751363  2642 net.cpp:122] Setting up Scale55
I0924 21:06:13.751368  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.751370  2642 net.cpp:137] Memory required for data: 892819600
I0924 21:06:13.751374  2642 layer_factory.hpp:77] Creating layer Eltwise26
I0924 21:06:13.751379  2642 net.cpp:84] Creating Layer Eltwise26
I0924 21:06:13.751381  2642 net.cpp:406] Eltwise26 <- Eltwise25_ReLU51_0_split_1
I0924 21:06:13.751384  2642 net.cpp:406] Eltwise26 <- Convolution55
I0924 21:06:13.751387  2642 net.cpp:380] Eltwise26 -> Eltwise26
I0924 21:06:13.751406  2642 net.cpp:122] Setting up Eltwise26
I0924 21:06:13.751410  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.751412  2642 net.cpp:137] Memory required for data: 894074000
I0924 21:06:13.751415  2642 layer_factory.hpp:77] Creating layer ReLU53
I0924 21:06:13.751417  2642 net.cpp:84] Creating Layer ReLU53
I0924 21:06:13.751420  2642 net.cpp:406] ReLU53 <- Eltwise26
I0924 21:06:13.751423  2642 net.cpp:367] ReLU53 -> Eltwise26 (in-place)
I0924 21:06:13.751550  2642 net.cpp:122] Setting up ReLU53
I0924 21:06:13.751556  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.751559  2642 net.cpp:137] Memory required for data: 895328400
I0924 21:06:13.751560  2642 layer_factory.hpp:77] Creating layer Eltwise26_ReLU53_0_split
I0924 21:06:13.751564  2642 net.cpp:84] Creating Layer Eltwise26_ReLU53_0_split
I0924 21:06:13.751566  2642 net.cpp:406] Eltwise26_ReLU53_0_split <- Eltwise26
I0924 21:06:13.751571  2642 net.cpp:380] Eltwise26_ReLU53_0_split -> Eltwise26_ReLU53_0_split_0
I0924 21:06:13.751575  2642 net.cpp:380] Eltwise26_ReLU53_0_split -> Eltwise26_ReLU53_0_split_1
I0924 21:06:13.751606  2642 net.cpp:122] Setting up Eltwise26_ReLU53_0_split
I0924 21:06:13.751610  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.751613  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.751616  2642 net.cpp:137] Memory required for data: 897837200
I0924 21:06:13.751617  2642 layer_factory.hpp:77] Creating layer Convolution56
I0924 21:06:13.751624  2642 net.cpp:84] Creating Layer Convolution56
I0924 21:06:13.751626  2642 net.cpp:406] Convolution56 <- Eltwise26_ReLU53_0_split_0
I0924 21:06:13.751631  2642 net.cpp:380] Convolution56 -> Convolution56
I0924 21:06:13.753309  2642 net.cpp:122] Setting up Convolution56
I0924 21:06:13.753317  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.753320  2642 net.cpp:137] Memory required for data: 899091600
I0924 21:06:13.753324  2642 layer_factory.hpp:77] Creating layer BatchNorm56
I0924 21:06:13.753329  2642 net.cpp:84] Creating Layer BatchNorm56
I0924 21:06:13.753331  2642 net.cpp:406] BatchNorm56 <- Convolution56
I0924 21:06:13.753335  2642 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I0924 21:06:13.753492  2642 net.cpp:122] Setting up BatchNorm56
I0924 21:06:13.753496  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.753499  2642 net.cpp:137] Memory required for data: 900346000
I0924 21:06:13.753504  2642 layer_factory.hpp:77] Creating layer Scale56
I0924 21:06:13.753515  2642 net.cpp:84] Creating Layer Scale56
I0924 21:06:13.753517  2642 net.cpp:406] Scale56 <- Convolution56
I0924 21:06:13.753522  2642 net.cpp:367] Scale56 -> Convolution56 (in-place)
I0924 21:06:13.753553  2642 layer_factory.hpp:77] Creating layer Scale56
I0924 21:06:13.753641  2642 net.cpp:122] Setting up Scale56
I0924 21:06:13.753646  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.753648  2642 net.cpp:137] Memory required for data: 901600400
I0924 21:06:13.753651  2642 layer_factory.hpp:77] Creating layer ReLU54
I0924 21:06:13.753655  2642 net.cpp:84] Creating Layer ReLU54
I0924 21:06:13.753657  2642 net.cpp:406] ReLU54 <- Convolution56
I0924 21:06:13.753661  2642 net.cpp:367] ReLU54 -> Convolution56 (in-place)
I0924 21:06:13.753785  2642 net.cpp:122] Setting up ReLU54
I0924 21:06:13.753792  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.753793  2642 net.cpp:137] Memory required for data: 902854800
I0924 21:06:13.753795  2642 layer_factory.hpp:77] Creating layer Convolution57
I0924 21:06:13.753803  2642 net.cpp:84] Creating Layer Convolution57
I0924 21:06:13.753804  2642 net.cpp:406] Convolution57 <- Convolution56
I0924 21:06:13.753809  2642 net.cpp:380] Convolution57 -> Convolution57
I0924 21:06:13.755787  2642 net.cpp:122] Setting up Convolution57
I0924 21:06:13.755795  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.755798  2642 net.cpp:137] Memory required for data: 904109200
I0924 21:06:13.755803  2642 layer_factory.hpp:77] Creating layer BatchNorm57
I0924 21:06:13.755808  2642 net.cpp:84] Creating Layer BatchNorm57
I0924 21:06:13.755811  2642 net.cpp:406] BatchNorm57 <- Convolution57
I0924 21:06:13.755815  2642 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I0924 21:06:13.755972  2642 net.cpp:122] Setting up BatchNorm57
I0924 21:06:13.755977  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.755980  2642 net.cpp:137] Memory required for data: 905363600
I0924 21:06:13.755983  2642 layer_factory.hpp:77] Creating layer Scale57
I0924 21:06:13.755987  2642 net.cpp:84] Creating Layer Scale57
I0924 21:06:13.755990  2642 net.cpp:406] Scale57 <- Convolution57
I0924 21:06:13.755993  2642 net.cpp:367] Scale57 -> Convolution57 (in-place)
I0924 21:06:13.756026  2642 layer_factory.hpp:77] Creating layer Scale57
I0924 21:06:13.756111  2642 net.cpp:122] Setting up Scale57
I0924 21:06:13.756115  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.756117  2642 net.cpp:137] Memory required for data: 906618000
I0924 21:06:13.756121  2642 layer_factory.hpp:77] Creating layer Eltwise27
I0924 21:06:13.756127  2642 net.cpp:84] Creating Layer Eltwise27
I0924 21:06:13.756129  2642 net.cpp:406] Eltwise27 <- Eltwise26_ReLU53_0_split_1
I0924 21:06:13.756132  2642 net.cpp:406] Eltwise27 <- Convolution57
I0924 21:06:13.756135  2642 net.cpp:380] Eltwise27 -> Eltwise27
I0924 21:06:13.756155  2642 net.cpp:122] Setting up Eltwise27
I0924 21:06:13.756157  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.756160  2642 net.cpp:137] Memory required for data: 907872400
I0924 21:06:13.756161  2642 layer_factory.hpp:77] Creating layer ReLU55
I0924 21:06:13.756165  2642 net.cpp:84] Creating Layer ReLU55
I0924 21:06:13.756167  2642 net.cpp:406] ReLU55 <- Eltwise27
I0924 21:06:13.756170  2642 net.cpp:367] ReLU55 -> Eltwise27 (in-place)
I0924 21:06:13.756296  2642 net.cpp:122] Setting up ReLU55
I0924 21:06:13.756302  2642 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0924 21:06:13.756304  2642 net.cpp:137] Memory required for data: 909126800
I0924 21:06:13.756306  2642 layer_factory.hpp:77] Creating layer Pooling1
I0924 21:06:13.756312  2642 net.cpp:84] Creating Layer Pooling1
I0924 21:06:13.756314  2642 net.cpp:406] Pooling1 <- Eltwise27
I0924 21:06:13.756319  2642 net.cpp:380] Pooling1 -> Pooling1
I0924 21:06:13.756466  2642 net.cpp:122] Setting up Pooling1
I0924 21:06:13.756471  2642 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0924 21:06:13.756474  2642 net.cpp:137] Memory required for data: 909152400
I0924 21:06:13.756482  2642 layer_factory.hpp:77] Creating layer InnerProduct1
I0924 21:06:13.763305  2642 net.cpp:84] Creating Layer InnerProduct1
I0924 21:06:13.763315  2642 net.cpp:406] InnerProduct1 <- Pooling1
I0924 21:06:13.763321  2642 net.cpp:380] InnerProduct1 -> InnerProduct1
I0924 21:06:13.763450  2642 net.cpp:122] Setting up InnerProduct1
I0924 21:06:13.763458  2642 net.cpp:129] Top shape: 100 10 (1000)
I0924 21:06:13.763459  2642 net.cpp:137] Memory required for data: 909156400
I0924 21:06:13.763464  2642 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0924 21:06:13.763469  2642 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0924 21:06:13.763473  2642 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I0924 21:06:13.763475  2642 net.cpp:406] SoftmaxWithLoss1 <- Data2
I0924 21:06:13.763480  2642 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0924 21:06:13.763489  2642 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0924 21:06:13.764068  2642 net.cpp:122] Setting up SoftmaxWithLoss1
I0924 21:06:13.764077  2642 net.cpp:129] Top shape: (1)
I0924 21:06:13.764081  2642 net.cpp:132]     with loss weight 1
I0924 21:06:13.764093  2642 net.cpp:137] Memory required for data: 909156404
I0924 21:06:13.764096  2642 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0924 21:06:13.764099  2642 net.cpp:198] InnerProduct1 needs backward computation.
I0924 21:06:13.764101  2642 net.cpp:198] Pooling1 needs backward computation.
I0924 21:06:13.764103  2642 net.cpp:198] ReLU55 needs backward computation.
I0924 21:06:13.764106  2642 net.cpp:198] Eltwise27 needs backward computation.
I0924 21:06:13.764108  2642 net.cpp:198] Scale57 needs backward computation.
I0924 21:06:13.764111  2642 net.cpp:198] BatchNorm57 needs backward computation.
I0924 21:06:13.764112  2642 net.cpp:198] Convolution57 needs backward computation.
I0924 21:06:13.764116  2642 net.cpp:198] ReLU54 needs backward computation.
I0924 21:06:13.764117  2642 net.cpp:198] Scale56 needs backward computation.
I0924 21:06:13.764119  2642 net.cpp:198] BatchNorm56 needs backward computation.
I0924 21:06:13.764122  2642 net.cpp:198] Convolution56 needs backward computation.
I0924 21:06:13.764123  2642 net.cpp:198] Eltwise26_ReLU53_0_split needs backward computation.
I0924 21:06:13.764125  2642 net.cpp:198] ReLU53 needs backward computation.
I0924 21:06:13.764128  2642 net.cpp:198] Eltwise26 needs backward computation.
I0924 21:06:13.764130  2642 net.cpp:198] Scale55 needs backward computation.
I0924 21:06:13.773233  2642 net.cpp:198] BatchNorm55 needs backward computation.
I0924 21:06:13.773241  2642 net.cpp:198] Convolution55 needs backward computation.
I0924 21:06:13.773243  2642 net.cpp:198] ReLU52 needs backward computation.
I0924 21:06:13.773247  2642 net.cpp:198] Scale54 needs backward computation.
I0924 21:06:13.773248  2642 net.cpp:198] BatchNorm54 needs backward computation.
I0924 21:06:13.773250  2642 net.cpp:198] Convolution54 needs backward computation.
I0924 21:06:13.773252  2642 net.cpp:198] Eltwise25_ReLU51_0_split needs backward computation.
I0924 21:06:13.773255  2642 net.cpp:198] ReLU51 needs backward computation.
I0924 21:06:13.773257  2642 net.cpp:198] Eltwise25 needs backward computation.
I0924 21:06:13.773260  2642 net.cpp:198] Scale53 needs backward computation.
I0924 21:06:13.773262  2642 net.cpp:198] BatchNorm53 needs backward computation.
I0924 21:06:13.773265  2642 net.cpp:198] Convolution53 needs backward computation.
I0924 21:06:13.773267  2642 net.cpp:198] ReLU50 needs backward computation.
I0924 21:06:13.773269  2642 net.cpp:198] Scale52 needs backward computation.
I0924 21:06:13.773272  2642 net.cpp:198] BatchNorm52 needs backward computation.
I0924 21:06:13.773274  2642 net.cpp:198] Convolution52 needs backward computation.
I0924 21:06:13.773277  2642 net.cpp:198] Eltwise24_ReLU49_0_split needs backward computation.
I0924 21:06:13.773279  2642 net.cpp:198] ReLU49 needs backward computation.
I0924 21:06:13.773283  2642 net.cpp:198] Eltwise24 needs backward computation.
I0924 21:06:13.773285  2642 net.cpp:198] Scale51 needs backward computation.
I0924 21:06:13.773295  2642 net.cpp:198] BatchNorm51 needs backward computation.
I0924 21:06:13.773298  2642 net.cpp:198] Convolution51 needs backward computation.
I0924 21:06:13.773300  2642 net.cpp:198] ReLU48 needs backward computation.
I0924 21:06:13.773303  2642 net.cpp:198] Scale50 needs backward computation.
I0924 21:06:13.773304  2642 net.cpp:198] BatchNorm50 needs backward computation.
I0924 21:06:13.773308  2642 net.cpp:198] Convolution50 needs backward computation.
I0924 21:06:13.773309  2642 net.cpp:198] Eltwise23_ReLU47_0_split needs backward computation.
I0924 21:06:13.773313  2642 net.cpp:198] ReLU47 needs backward computation.
I0924 21:06:13.773314  2642 net.cpp:198] Eltwise23 needs backward computation.
I0924 21:06:13.773317  2642 net.cpp:198] Scale49 needs backward computation.
I0924 21:06:13.773320  2642 net.cpp:198] BatchNorm49 needs backward computation.
I0924 21:06:13.773322  2642 net.cpp:198] Convolution49 needs backward computation.
I0924 21:06:13.773325  2642 net.cpp:198] ReLU46 needs backward computation.
I0924 21:06:13.773327  2642 net.cpp:198] Scale48 needs backward computation.
I0924 21:06:13.773329  2642 net.cpp:198] BatchNorm48 needs backward computation.
I0924 21:06:13.773332  2642 net.cpp:198] Convolution48 needs backward computation.
I0924 21:06:13.773334  2642 net.cpp:198] Eltwise22_ReLU45_0_split needs backward computation.
I0924 21:06:13.773337  2642 net.cpp:198] ReLU45 needs backward computation.
I0924 21:06:13.773339  2642 net.cpp:198] Eltwise22 needs backward computation.
I0924 21:06:13.773342  2642 net.cpp:198] Scale47 needs backward computation.
I0924 21:06:13.773345  2642 net.cpp:198] BatchNorm47 needs backward computation.
I0924 21:06:13.773347  2642 net.cpp:198] Convolution47 needs backward computation.
I0924 21:06:13.773350  2642 net.cpp:198] ReLU44 needs backward computation.
I0924 21:06:13.773352  2642 net.cpp:198] Scale46 needs backward computation.
I0924 21:06:13.773355  2642 net.cpp:198] BatchNorm46 needs backward computation.
I0924 21:06:13.773356  2642 net.cpp:198] Convolution46 needs backward computation.
I0924 21:06:13.773360  2642 net.cpp:198] Eltwise21_ReLU43_0_split needs backward computation.
I0924 21:06:13.773361  2642 net.cpp:198] ReLU43 needs backward computation.
I0924 21:06:13.773365  2642 net.cpp:198] Eltwise21 needs backward computation.
I0924 21:06:13.773367  2642 net.cpp:198] Scale45 needs backward computation.
I0924 21:06:13.773370  2642 net.cpp:198] BatchNorm45 needs backward computation.
I0924 21:06:13.773372  2642 net.cpp:198] Convolution45 needs backward computation.
I0924 21:06:13.773376  2642 net.cpp:198] ReLU42 needs backward computation.
I0924 21:06:13.773378  2642 net.cpp:198] Scale44 needs backward computation.
I0924 21:06:13.773381  2642 net.cpp:198] BatchNorm44 needs backward computation.
I0924 21:06:13.773383  2642 net.cpp:198] Convolution44 needs backward computation.
I0924 21:06:13.773386  2642 net.cpp:198] Eltwise20_ReLU41_0_split needs backward computation.
I0924 21:06:13.773388  2642 net.cpp:198] ReLU41 needs backward computation.
I0924 21:06:13.773391  2642 net.cpp:198] Eltwise20 needs backward computation.
I0924 21:06:13.773393  2642 net.cpp:198] Scale43 needs backward computation.
I0924 21:06:13.773396  2642 net.cpp:198] BatchNorm43 needs backward computation.
I0924 21:06:13.773398  2642 net.cpp:198] Convolution43 needs backward computation.
I0924 21:06:13.773401  2642 net.cpp:198] ReLU40 needs backward computation.
I0924 21:06:13.773403  2642 net.cpp:198] Scale42 needs backward computation.
I0924 21:06:13.773406  2642 net.cpp:198] BatchNorm42 needs backward computation.
I0924 21:06:13.773408  2642 net.cpp:198] Convolution42 needs backward computation.
I0924 21:06:13.773411  2642 net.cpp:198] Eltwise19_ReLU39_0_split needs backward computation.
I0924 21:06:13.773413  2642 net.cpp:198] ReLU39 needs backward computation.
I0924 21:06:13.773416  2642 net.cpp:198] Eltwise19 needs backward computation.
I0924 21:06:13.773419  2642 net.cpp:198] Scale41 needs backward computation.
I0924 21:06:13.773422  2642 net.cpp:198] BatchNorm41 needs backward computation.
I0924 21:06:13.773427  2642 net.cpp:198] Convolution41 needs backward computation.
I0924 21:06:13.773430  2642 net.cpp:198] ReLU38 needs backward computation.
I0924 21:06:13.773432  2642 net.cpp:198] Scale40 needs backward computation.
I0924 21:06:13.773435  2642 net.cpp:198] BatchNorm40 needs backward computation.
I0924 21:06:13.773437  2642 net.cpp:198] Convolution40 needs backward computation.
I0924 21:06:13.773440  2642 net.cpp:198] Scale39 needs backward computation.
I0924 21:06:13.773442  2642 net.cpp:198] BatchNorm39 needs backward computation.
I0924 21:06:13.773445  2642 net.cpp:198] Convolution39 needs backward computation.
I0924 21:06:13.773447  2642 net.cpp:198] Eltwise18_ReLU37_0_split needs backward computation.
I0924 21:06:13.773450  2642 net.cpp:198] ReLU37 needs backward computation.
I0924 21:06:13.773452  2642 net.cpp:198] Eltwise18 needs backward computation.
I0924 21:06:13.773455  2642 net.cpp:198] Scale38 needs backward computation.
I0924 21:06:13.773458  2642 net.cpp:198] BatchNorm38 needs backward computation.
I0924 21:06:13.773460  2642 net.cpp:198] Convolution38 needs backward computation.
I0924 21:06:13.773463  2642 net.cpp:198] ReLU36 needs backward computation.
I0924 21:06:13.773465  2642 net.cpp:198] Scale37 needs backward computation.
I0924 21:06:13.773468  2642 net.cpp:198] BatchNorm37 needs backward computation.
I0924 21:06:13.773470  2642 net.cpp:198] Convolution37 needs backward computation.
I0924 21:06:13.773473  2642 net.cpp:198] Eltwise17_ReLU35_0_split needs backward computation.
I0924 21:06:13.773475  2642 net.cpp:198] ReLU35 needs backward computation.
I0924 21:06:13.773478  2642 net.cpp:198] Eltwise17 needs backward computation.
I0924 21:06:13.773480  2642 net.cpp:198] Scale36 needs backward computation.
I0924 21:06:13.773483  2642 net.cpp:198] BatchNorm36 needs backward computation.
I0924 21:06:13.773485  2642 net.cpp:198] Convolution36 needs backward computation.
I0924 21:06:13.773488  2642 net.cpp:198] ReLU34 needs backward computation.
I0924 21:06:13.773490  2642 net.cpp:198] Scale35 needs backward computation.
I0924 21:06:13.773494  2642 net.cpp:198] BatchNorm35 needs backward computation.
I0924 21:06:13.773495  2642 net.cpp:198] Convolution35 needs backward computation.
I0924 21:06:13.773499  2642 net.cpp:198] Eltwise16_ReLU33_0_split needs backward computation.
I0924 21:06:13.775385  2642 net.cpp:198] ReLU33 needs backward computation.
I0924 21:06:13.775393  2642 net.cpp:198] Eltwise16 needs backward computation.
I0924 21:06:13.775398  2642 net.cpp:198] Scale34 needs backward computation.
I0924 21:06:13.775399  2642 net.cpp:198] BatchNorm34 needs backward computation.
I0924 21:06:13.775401  2642 net.cpp:198] Convolution34 needs backward computation.
I0924 21:06:13.775404  2642 net.cpp:198] ReLU32 needs backward computation.
I0924 21:06:13.775406  2642 net.cpp:198] Scale33 needs backward computation.
I0924 21:06:13.775408  2642 net.cpp:198] BatchNorm33 needs backward computation.
I0924 21:06:13.775410  2642 net.cpp:198] Convolution33 needs backward computation.
I0924 21:06:13.775413  2642 net.cpp:198] Eltwise15_ReLU31_0_split needs backward computation.
I0924 21:06:13.775416  2642 net.cpp:198] ReLU31 needs backward computation.
I0924 21:06:13.775418  2642 net.cpp:198] Eltwise15 needs backward computation.
I0924 21:06:13.775421  2642 net.cpp:198] Scale32 needs backward computation.
I0924 21:06:13.775424  2642 net.cpp:198] BatchNorm32 needs backward computation.
I0924 21:06:13.775425  2642 net.cpp:198] Convolution32 needs backward computation.
I0924 21:06:13.775429  2642 net.cpp:198] ReLU30 needs backward computation.
I0924 21:06:13.775430  2642 net.cpp:198] Scale31 needs backward computation.
I0924 21:06:13.775432  2642 net.cpp:198] BatchNorm31 needs backward computation.
I0924 21:06:13.775434  2642 net.cpp:198] Convolution31 needs backward computation.
I0924 21:06:13.775437  2642 net.cpp:198] Eltwise14_ReLU29_0_split needs backward computation.
I0924 21:06:13.775439  2642 net.cpp:198] ReLU29 needs backward computation.
I0924 21:06:13.775441  2642 net.cpp:198] Eltwise14 needs backward computation.
I0924 21:06:13.775451  2642 net.cpp:198] Scale30 needs backward computation.
I0924 21:06:13.775455  2642 net.cpp:198] BatchNorm30 needs backward computation.
I0924 21:06:13.775457  2642 net.cpp:198] Convolution30 needs backward computation.
I0924 21:06:13.775460  2642 net.cpp:198] ReLU28 needs backward computation.
I0924 21:06:13.775462  2642 net.cpp:198] Scale29 needs backward computation.
I0924 21:06:13.775465  2642 net.cpp:198] BatchNorm29 needs backward computation.
I0924 21:06:13.775467  2642 net.cpp:198] Convolution29 needs backward computation.
I0924 21:06:13.775470  2642 net.cpp:198] Eltwise13_ReLU27_0_split needs backward computation.
I0924 21:06:13.775471  2642 net.cpp:198] ReLU27 needs backward computation.
I0924 21:06:13.775475  2642 net.cpp:198] Eltwise13 needs backward computation.
I0924 21:06:13.775476  2642 net.cpp:198] Scale28 needs backward computation.
I0924 21:06:13.775480  2642 net.cpp:198] BatchNorm28 needs backward computation.
I0924 21:06:13.775481  2642 net.cpp:198] Convolution28 needs backward computation.
I0924 21:06:13.775483  2642 net.cpp:198] ReLU26 needs backward computation.
I0924 21:06:13.775485  2642 net.cpp:198] Scale27 needs backward computation.
I0924 21:06:13.775487  2642 net.cpp:198] BatchNorm27 needs backward computation.
I0924 21:06:13.775490  2642 net.cpp:198] Convolution27 needs backward computation.
I0924 21:06:13.775492  2642 net.cpp:198] Eltwise12_ReLU25_0_split needs backward computation.
I0924 21:06:13.775494  2642 net.cpp:198] ReLU25 needs backward computation.
I0924 21:06:13.775497  2642 net.cpp:198] Eltwise12 needs backward computation.
I0924 21:06:13.775499  2642 net.cpp:198] Scale26 needs backward computation.
I0924 21:06:13.775501  2642 net.cpp:198] BatchNorm26 needs backward computation.
I0924 21:06:13.775504  2642 net.cpp:198] Convolution26 needs backward computation.
I0924 21:06:13.775506  2642 net.cpp:198] ReLU24 needs backward computation.
I0924 21:06:13.775508  2642 net.cpp:198] Scale25 needs backward computation.
I0924 21:06:13.775511  2642 net.cpp:198] BatchNorm25 needs backward computation.
I0924 21:06:13.775513  2642 net.cpp:198] Convolution25 needs backward computation.
I0924 21:06:13.775516  2642 net.cpp:198] Eltwise11_ReLU23_0_split needs backward computation.
I0924 21:06:13.775518  2642 net.cpp:198] ReLU23 needs backward computation.
I0924 21:06:13.775521  2642 net.cpp:198] Eltwise11 needs backward computation.
I0924 21:06:13.775523  2642 net.cpp:198] Scale24 needs backward computation.
I0924 21:06:13.775526  2642 net.cpp:198] BatchNorm24 needs backward computation.
I0924 21:06:13.775527  2642 net.cpp:198] Convolution24 needs backward computation.
I0924 21:06:13.775538  2642 net.cpp:198] ReLU22 needs backward computation.
I0924 21:06:13.775540  2642 net.cpp:198] Scale23 needs backward computation.
I0924 21:06:13.775543  2642 net.cpp:198] BatchNorm23 needs backward computation.
I0924 21:06:13.775545  2642 net.cpp:198] Convolution23 needs backward computation.
I0924 21:06:13.775548  2642 net.cpp:198] Eltwise10_ReLU21_0_split needs backward computation.
I0924 21:06:13.775550  2642 net.cpp:198] ReLU21 needs backward computation.
I0924 21:06:13.775552  2642 net.cpp:198] Eltwise10 needs backward computation.
I0924 21:06:13.775557  2642 net.cpp:198] Scale22 needs backward computation.
I0924 21:06:13.775558  2642 net.cpp:198] BatchNorm22 needs backward computation.
I0924 21:06:13.775560  2642 net.cpp:198] Convolution22 needs backward computation.
I0924 21:06:13.775563  2642 net.cpp:198] ReLU20 needs backward computation.
I0924 21:06:13.775566  2642 net.cpp:198] Scale21 needs backward computation.
I0924 21:06:13.775568  2642 net.cpp:198] BatchNorm21 needs backward computation.
I0924 21:06:13.775570  2642 net.cpp:198] Convolution21 needs backward computation.
I0924 21:06:13.775573  2642 net.cpp:198] Scale20 needs backward computation.
I0924 21:06:13.775575  2642 net.cpp:198] BatchNorm20 needs backward computation.
I0924 21:06:13.775578  2642 net.cpp:198] Convolution20 needs backward computation.
I0924 21:06:13.775580  2642 net.cpp:198] Eltwise9_ReLU19_0_split needs backward computation.
I0924 21:06:13.775586  2642 net.cpp:198] ReLU19 needs backward computation.
I0924 21:06:13.775589  2642 net.cpp:198] Eltwise9 needs backward computation.
I0924 21:06:13.775593  2642 net.cpp:198] Scale19 needs backward computation.
I0924 21:06:13.775594  2642 net.cpp:198] BatchNorm19 needs backward computation.
I0924 21:06:13.775598  2642 net.cpp:198] Convolution19 needs backward computation.
I0924 21:06:13.775599  2642 net.cpp:198] ReLU18 needs backward computation.
I0924 21:06:13.775602  2642 net.cpp:198] Scale18 needs backward computation.
I0924 21:06:13.775604  2642 net.cpp:198] BatchNorm18 needs backward computation.
I0924 21:06:13.775607  2642 net.cpp:198] Convolution18 needs backward computation.
I0924 21:06:13.775609  2642 net.cpp:198] Eltwise8_ReLU17_0_split needs backward computation.
I0924 21:06:13.775612  2642 net.cpp:198] ReLU17 needs backward computation.
I0924 21:06:13.775614  2642 net.cpp:198] Eltwise8 needs backward computation.
I0924 21:06:13.775617  2642 net.cpp:198] Scale17 needs backward computation.
I0924 21:06:13.775619  2642 net.cpp:198] BatchNorm17 needs backward computation.
I0924 21:06:13.775622  2642 net.cpp:198] Convolution17 needs backward computation.
I0924 21:06:13.775624  2642 net.cpp:198] ReLU16 needs backward computation.
I0924 21:06:13.775626  2642 net.cpp:198] Scale16 needs backward computation.
I0924 21:06:13.775629  2642 net.cpp:198] BatchNorm16 needs backward computation.
I0924 21:06:13.775631  2642 net.cpp:198] Convolution16 needs backward computation.
I0924 21:06:13.775635  2642 net.cpp:198] Eltwise7_ReLU15_0_split needs backward computation.
I0924 21:06:13.775636  2642 net.cpp:198] ReLU15 needs backward computation.
I0924 21:06:13.775638  2642 net.cpp:198] Eltwise7 needs backward computation.
I0924 21:06:13.775641  2642 net.cpp:198] Scale15 needs backward computation.
I0924 21:06:13.775645  2642 net.cpp:198] BatchNorm15 needs backward computation.
I0924 21:06:13.775646  2642 net.cpp:198] Convolution15 needs backward computation.
I0924 21:06:13.775648  2642 net.cpp:198] ReLU14 needs backward computation.
I0924 21:06:13.775651  2642 net.cpp:198] Scale14 needs backward computation.
I0924 21:06:13.803462  2642 net.cpp:198] BatchNorm14 needs backward computation.
I0924 21:06:13.803470  2642 net.cpp:198] Convolution14 needs backward computation.
I0924 21:06:13.803473  2642 net.cpp:198] Eltwise6_ReLU13_0_split needs backward computation.
I0924 21:06:13.803478  2642 net.cpp:198] ReLU13 needs backward computation.
I0924 21:06:13.803479  2642 net.cpp:198] Eltwise6 needs backward computation.
I0924 21:06:13.803483  2642 net.cpp:198] Scale13 needs backward computation.
I0924 21:06:13.803485  2642 net.cpp:198] BatchNorm13 needs backward computation.
I0924 21:06:13.803488  2642 net.cpp:198] Convolution13 needs backward computation.
I0924 21:06:13.803490  2642 net.cpp:198] ReLU12 needs backward computation.
I0924 21:06:13.803493  2642 net.cpp:198] Scale12 needs backward computation.
I0924 21:06:13.803495  2642 net.cpp:198] BatchNorm12 needs backward computation.
I0924 21:06:13.803498  2642 net.cpp:198] Convolution12 needs backward computation.
I0924 21:06:13.803500  2642 net.cpp:198] Eltwise5_ReLU11_0_split needs backward computation.
I0924 21:06:13.803503  2642 net.cpp:198] ReLU11 needs backward computation.
I0924 21:06:13.803505  2642 net.cpp:198] Eltwise5 needs backward computation.
I0924 21:06:13.803509  2642 net.cpp:198] Scale11 needs backward computation.
I0924 21:06:13.803511  2642 net.cpp:198] BatchNorm11 needs backward computation.
I0924 21:06:13.803514  2642 net.cpp:198] Convolution11 needs backward computation.
I0924 21:06:13.803516  2642 net.cpp:198] ReLU10 needs backward computation.
I0924 21:06:13.803519  2642 net.cpp:198] Scale10 needs backward computation.
I0924 21:06:13.803521  2642 net.cpp:198] BatchNorm10 needs backward computation.
I0924 21:06:13.803524  2642 net.cpp:198] Convolution10 needs backward computation.
I0924 21:06:13.803526  2642 net.cpp:198] Eltwise4_ReLU9_0_split needs backward computation.
I0924 21:06:13.803537  2642 net.cpp:198] ReLU9 needs backward computation.
I0924 21:06:13.803540  2642 net.cpp:198] Eltwise4 needs backward computation.
I0924 21:06:13.803545  2642 net.cpp:198] Scale9 needs backward computation.
I0924 21:06:13.803550  2642 net.cpp:198] BatchNorm9 needs backward computation.
I0924 21:06:13.803551  2642 net.cpp:198] Convolution9 needs backward computation.
I0924 21:06:13.803555  2642 net.cpp:198] ReLU8 needs backward computation.
I0924 21:06:13.803557  2642 net.cpp:198] Scale8 needs backward computation.
I0924 21:06:13.803560  2642 net.cpp:198] BatchNorm8 needs backward computation.
I0924 21:06:13.803561  2642 net.cpp:198] Convolution8 needs backward computation.
I0924 21:06:13.803565  2642 net.cpp:198] Eltwise3_ReLU7_0_split needs backward computation.
I0924 21:06:13.803567  2642 net.cpp:198] ReLU7 needs backward computation.
I0924 21:06:13.803570  2642 net.cpp:198] Eltwise3 needs backward computation.
I0924 21:06:13.803573  2642 net.cpp:198] Scale7 needs backward computation.
I0924 21:06:13.803576  2642 net.cpp:198] BatchNorm7 needs backward computation.
I0924 21:06:13.803578  2642 net.cpp:198] Convolution7 needs backward computation.
I0924 21:06:13.803580  2642 net.cpp:198] ReLU6 needs backward computation.
I0924 21:06:13.803583  2642 net.cpp:198] Scale6 needs backward computation.
I0924 21:06:13.803586  2642 net.cpp:198] BatchNorm6 needs backward computation.
I0924 21:06:13.803588  2642 net.cpp:198] Convolution6 needs backward computation.
I0924 21:06:13.803591  2642 net.cpp:198] Eltwise2_ReLU5_0_split needs backward computation.
I0924 21:06:13.803593  2642 net.cpp:198] ReLU5 needs backward computation.
I0924 21:06:13.803596  2642 net.cpp:198] Eltwise2 needs backward computation.
I0924 21:06:13.803599  2642 net.cpp:198] Scale5 needs backward computation.
I0924 21:06:13.803602  2642 net.cpp:198] BatchNorm5 needs backward computation.
I0924 21:06:13.803604  2642 net.cpp:198] Convolution5 needs backward computation.
I0924 21:06:13.803607  2642 net.cpp:198] ReLU4 needs backward computation.
I0924 21:06:13.803609  2642 net.cpp:198] Scale4 needs backward computation.
I0924 21:06:13.803611  2642 net.cpp:198] BatchNorm4 needs backward computation.
I0924 21:06:13.803614  2642 net.cpp:198] Convolution4 needs backward computation.
I0924 21:06:13.803617  2642 net.cpp:198] Eltwise1_ReLU3_0_split needs backward computation.
I0924 21:06:13.803620  2642 net.cpp:198] ReLU3 needs backward computation.
I0924 21:06:13.803622  2642 net.cpp:198] Eltwise1 needs backward computation.
I0924 21:06:13.803625  2642 net.cpp:198] Scale3 needs backward computation.
I0924 21:06:13.803628  2642 net.cpp:198] BatchNorm3 needs backward computation.
I0924 21:06:13.803630  2642 net.cpp:198] Convolution3 needs backward computation.
I0924 21:06:13.803633  2642 net.cpp:198] ReLU2 needs backward computation.
I0924 21:06:13.803635  2642 net.cpp:198] Scale2 needs backward computation.
I0924 21:06:13.803638  2642 net.cpp:198] BatchNorm2 needs backward computation.
I0924 21:06:13.803640  2642 net.cpp:198] Convolution2 needs backward computation.
I0924 21:06:13.803643  2642 net.cpp:198] Convolution1_ReLU1_0_split needs backward computation.
I0924 21:06:13.803645  2642 net.cpp:198] ReLU1 needs backward computation.
I0924 21:06:13.803648  2642 net.cpp:198] Scale1 needs backward computation.
I0924 21:06:13.803650  2642 net.cpp:198] BatchNorm1 needs backward computation.
I0924 21:06:13.803653  2642 net.cpp:198] Convolution1 needs backward computation.
I0924 21:06:13.803656  2642 net.cpp:200] Data1 does not need backward computation.
I0924 21:06:13.803658  2642 net.cpp:242] This network produces output SoftmaxWithLoss1
I0924 21:06:13.803764  2642 net.cpp:255] Network initialization done.
I0924 21:06:13.807528  2642 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56_cifar_train_test.prototxt
I0924 21:06:13.807540  2642 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0924 21:06:13.807545  2642 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56_cifar_train_test.prototxt
I0924 21:06:13.807725  2642 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I0924 21:06:13.808643  2642 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution21"
  top: "Convolution21"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution23"
  top: "Convolution23"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution24"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution25"
  top: "Convolution25"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution26"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution27"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "Convolution27"
  top: "Convolution27"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Convolution27"
  top: "Convolution28"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution28"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution29"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "Convolution29"
  top: "Convolution29"
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Convolution29"
  top: "Convolution30"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution30"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Eltwise14"
  top: "Convolution31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "Convolution31"
  top: "Convolution31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU30"
  type: "ReLU"
  bottom: "Convolution31"
  top: "Convolution31"
}
layer {
  name: "Convolution32"
  type: "Convolution"
  bottom: "Convolution31"
  top: "Convolution32"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNor
I0924 21:06:13.865312  2642 layer_factory.hpp:77] Creating layer Data1
I0924 21:06:13.907101  2642 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I0924 21:06:13.917927  2642 net.cpp:84] Creating Layer Data1
I0924 21:06:13.917938  2642 net.cpp:380] Data1 -> Data1
I0924 21:06:13.917948  2642 net.cpp:380] Data1 -> Data2
I0924 21:06:13.917954  2642 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0924 21:06:13.918150  2642 data_layer.cpp:45] output data size: 100,3,32,32
I0924 21:06:13.922539  2642 net.cpp:122] Setting up Data1
I0924 21:06:13.922551  2642 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0924 21:06:13.922555  2642 net.cpp:129] Top shape: 100 (100)
I0924 21:06:13.922557  2642 net.cpp:137] Memory required for data: 1229200
I0924 21:06:13.922560  2642 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0924 21:06:13.922567  2642 net.cpp:84] Creating Layer Data2_Data1_1_split
I0924 21:06:13.922570  2642 net.cpp:406] Data2_Data1_1_split <- Data2
I0924 21:06:13.922574  2642 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0924 21:06:13.922580  2642 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0924 21:06:13.922668  2642 net.cpp:122] Setting up Data2_Data1_1_split
I0924 21:06:13.922678  2642 net.cpp:129] Top shape: 100 (100)
I0924 21:06:13.922682  2642 net.cpp:129] Top shape: 100 (100)
I0924 21:06:13.922683  2642 net.cpp:137] Memory required for data: 1230000
I0924 21:06:13.922685  2642 layer_factory.hpp:77] Creating layer Convolution1
I0924 21:06:13.922695  2642 net.cpp:84] Creating Layer Convolution1
I0924 21:06:13.922698  2642 net.cpp:406] Convolution1 <- Data1
I0924 21:06:13.922703  2642 net.cpp:380] Convolution1 -> Convolution1
I0924 21:06:13.923991  2642 net.cpp:122] Setting up Convolution1
I0924 21:06:13.924005  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.924010  2642 net.cpp:137] Memory required for data: 7783600
I0924 21:06:13.924021  2642 layer_factory.hpp:77] Creating layer BatchNorm1
I0924 21:06:13.924028  2642 net.cpp:84] Creating Layer BatchNorm1
I0924 21:06:13.924034  2642 net.cpp:406] BatchNorm1 <- Convolution1
I0924 21:06:13.924041  2642 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0924 21:06:13.924299  2642 net.cpp:122] Setting up BatchNorm1
I0924 21:06:13.924307  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.924314  2642 net.cpp:137] Memory required for data: 14337200
I0924 21:06:13.924325  2642 layer_factory.hpp:77] Creating layer Scale1
I0924 21:06:13.924358  2642 net.cpp:84] Creating Layer Scale1
I0924 21:06:13.924363  2642 net.cpp:406] Scale1 <- Convolution1
I0924 21:06:13.924379  2642 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0924 21:06:13.924430  2642 layer_factory.hpp:77] Creating layer Scale1
I0924 21:06:13.924573  2642 net.cpp:122] Setting up Scale1
I0924 21:06:13.924582  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.924587  2642 net.cpp:137] Memory required for data: 20890800
I0924 21:06:13.924593  2642 layer_factory.hpp:77] Creating layer ReLU1
I0924 21:06:13.924599  2642 net.cpp:84] Creating Layer ReLU1
I0924 21:06:13.924603  2642 net.cpp:406] ReLU1 <- Convolution1
I0924 21:06:13.924608  2642 net.cpp:367] ReLU1 -> Convolution1 (in-place)
I0924 21:06:13.924796  2642 net.cpp:122] Setting up ReLU1
I0924 21:06:13.924806  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.924810  2642 net.cpp:137] Memory required for data: 27444400
I0924 21:06:13.924814  2642 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0924 21:06:13.924823  2642 net.cpp:84] Creating Layer Convolution1_ReLU1_0_split
I0924 21:06:13.924827  2642 net.cpp:406] Convolution1_ReLU1_0_split <- Convolution1
I0924 21:06:13.924832  2642 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0924 21:06:13.924839  2642 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0924 21:06:13.924887  2642 net.cpp:122] Setting up Convolution1_ReLU1_0_split
I0924 21:06:13.924893  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.924896  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.924898  2642 net.cpp:137] Memory required for data: 40551600
I0924 21:06:13.924901  2642 layer_factory.hpp:77] Creating layer Convolution2
I0924 21:06:13.924907  2642 net.cpp:84] Creating Layer Convolution2
I0924 21:06:13.924911  2642 net.cpp:406] Convolution2 <- Convolution1_ReLU1_0_split_0
I0924 21:06:13.924932  2642 net.cpp:380] Convolution2 -> Convolution2
I0924 21:06:13.926566  2642 net.cpp:122] Setting up Convolution2
I0924 21:06:13.926578  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.926584  2642 net.cpp:137] Memory required for data: 47105200
I0924 21:06:13.926594  2642 layer_factory.hpp:77] Creating layer BatchNorm2
I0924 21:06:13.926602  2642 net.cpp:84] Creating Layer BatchNorm2
I0924 21:06:13.926607  2642 net.cpp:406] BatchNorm2 <- Convolution2
I0924 21:06:13.926614  2642 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0924 21:06:13.926862  2642 net.cpp:122] Setting up BatchNorm2
I0924 21:06:13.926869  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.926873  2642 net.cpp:137] Memory required for data: 53658800
I0924 21:06:13.926882  2642 layer_factory.hpp:77] Creating layer Scale2
I0924 21:06:13.926888  2642 net.cpp:84] Creating Layer Scale2
I0924 21:06:13.926892  2642 net.cpp:406] Scale2 <- Convolution2
I0924 21:06:13.926900  2642 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0924 21:06:13.926960  2642 layer_factory.hpp:77] Creating layer Scale2
I0924 21:06:13.927124  2642 net.cpp:122] Setting up Scale2
I0924 21:06:13.927136  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.927140  2642 net.cpp:137] Memory required for data: 60212400
I0924 21:06:13.927147  2642 layer_factory.hpp:77] Creating layer ReLU2
I0924 21:06:13.927156  2642 net.cpp:84] Creating Layer ReLU2
I0924 21:06:13.927160  2642 net.cpp:406] ReLU2 <- Convolution2
I0924 21:06:13.927166  2642 net.cpp:367] ReLU2 -> Convolution2 (in-place)
I0924 21:06:13.927366  2642 net.cpp:122] Setting up ReLU2
I0924 21:06:13.927382  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.927386  2642 net.cpp:137] Memory required for data: 66766000
I0924 21:06:13.927397  2642 layer_factory.hpp:77] Creating layer Convolution3
I0924 21:06:13.927405  2642 net.cpp:84] Creating Layer Convolution3
I0924 21:06:13.927407  2642 net.cpp:406] Convolution3 <- Convolution2
I0924 21:06:13.927412  2642 net.cpp:380] Convolution3 -> Convolution3
I0924 21:06:13.929029  2642 net.cpp:122] Setting up Convolution3
I0924 21:06:13.929045  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.929050  2642 net.cpp:137] Memory required for data: 73319600
I0924 21:06:13.929062  2642 layer_factory.hpp:77] Creating layer BatchNorm3
I0924 21:06:13.929070  2642 net.cpp:84] Creating Layer BatchNorm3
I0924 21:06:13.929075  2642 net.cpp:406] BatchNorm3 <- Convolution3
I0924 21:06:13.929083  2642 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0924 21:06:13.929340  2642 net.cpp:122] Setting up BatchNorm3
I0924 21:06:13.929350  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.929355  2642 net.cpp:137] Memory required for data: 79873200
I0924 21:06:13.929368  2642 layer_factory.hpp:77] Creating layer Scale3
I0924 21:06:13.929374  2642 net.cpp:84] Creating Layer Scale3
I0924 21:06:13.929378  2642 net.cpp:406] Scale3 <- Convolution3
I0924 21:06:13.929388  2642 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0924 21:06:13.929438  2642 layer_factory.hpp:77] Creating layer Scale3
I0924 21:06:13.929587  2642 net.cpp:122] Setting up Scale3
I0924 21:06:13.929597  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.929601  2642 net.cpp:137] Memory required for data: 86426800
I0924 21:06:13.929610  2642 layer_factory.hpp:77] Creating layer Eltwise1
I0924 21:06:13.929617  2642 net.cpp:84] Creating Layer Eltwise1
I0924 21:06:13.929622  2642 net.cpp:406] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0924 21:06:13.929627  2642 net.cpp:406] Eltwise1 <- Convolution3
I0924 21:06:13.929633  2642 net.cpp:380] Eltwise1 -> Eltwise1
I0924 21:06:13.929663  2642 net.cpp:122] Setting up Eltwise1
I0924 21:06:13.929672  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.929677  2642 net.cpp:137] Memory required for data: 92980400
I0924 21:06:13.929682  2642 layer_factory.hpp:77] Creating layer ReLU3
I0924 21:06:13.929689  2642 net.cpp:84] Creating Layer ReLU3
I0924 21:06:13.929693  2642 net.cpp:406] ReLU3 <- Eltwise1
I0924 21:06:13.929700  2642 net.cpp:367] ReLU3 -> Eltwise1 (in-place)
I0924 21:06:13.930033  2642 net.cpp:122] Setting up ReLU3
I0924 21:06:13.930043  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.930047  2642 net.cpp:137] Memory required for data: 99534000
I0924 21:06:13.930052  2642 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0924 21:06:13.930063  2642 net.cpp:84] Creating Layer Eltwise1_ReLU3_0_split
I0924 21:06:13.930066  2642 net.cpp:406] Eltwise1_ReLU3_0_split <- Eltwise1
I0924 21:06:13.930073  2642 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0924 21:06:13.930085  2642 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0924 21:06:13.930135  2642 net.cpp:122] Setting up Eltwise1_ReLU3_0_split
I0924 21:06:13.930142  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.930147  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.930151  2642 net.cpp:137] Memory required for data: 112641200
I0924 21:06:13.930155  2642 layer_factory.hpp:77] Creating layer Convolution4
I0924 21:06:13.930166  2642 net.cpp:84] Creating Layer Convolution4
I0924 21:06:13.930171  2642 net.cpp:406] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0924 21:06:13.930178  2642 net.cpp:380] Convolution4 -> Convolution4
I0924 21:06:13.931593  2642 net.cpp:122] Setting up Convolution4
I0924 21:06:13.931605  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.931609  2642 net.cpp:137] Memory required for data: 119194800
I0924 21:06:13.931617  2642 layer_factory.hpp:77] Creating layer BatchNorm4
I0924 21:06:13.931624  2642 net.cpp:84] Creating Layer BatchNorm4
I0924 21:06:13.931628  2642 net.cpp:406] BatchNorm4 <- Convolution4
I0924 21:06:13.931637  2642 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0924 21:06:13.931897  2642 net.cpp:122] Setting up BatchNorm4
I0924 21:06:13.931905  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.931906  2642 net.cpp:137] Memory required for data: 125748400
I0924 21:06:13.931912  2642 layer_factory.hpp:77] Creating layer Scale4
I0924 21:06:13.931924  2642 net.cpp:84] Creating Layer Scale4
I0924 21:06:13.931927  2642 net.cpp:406] Scale4 <- Convolution4
I0924 21:06:13.931931  2642 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0924 21:06:13.931967  2642 layer_factory.hpp:77] Creating layer Scale4
I0924 21:06:13.932057  2642 net.cpp:122] Setting up Scale4
I0924 21:06:13.932061  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.932063  2642 net.cpp:137] Memory required for data: 132302000
I0924 21:06:13.932067  2642 layer_factory.hpp:77] Creating layer ReLU4
I0924 21:06:13.932072  2642 net.cpp:84] Creating Layer ReLU4
I0924 21:06:13.932075  2642 net.cpp:406] ReLU4 <- Convolution4
I0924 21:06:13.932077  2642 net.cpp:367] ReLU4 -> Convolution4 (in-place)
I0924 21:06:13.932206  2642 net.cpp:122] Setting up ReLU4
I0924 21:06:13.932212  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.932214  2642 net.cpp:137] Memory required for data: 138855600
I0924 21:06:13.932217  2642 layer_factory.hpp:77] Creating layer Convolution5
I0924 21:06:13.932224  2642 net.cpp:84] Creating Layer Convolution5
I0924 21:06:13.932226  2642 net.cpp:406] Convolution5 <- Convolution4
I0924 21:06:13.932231  2642 net.cpp:380] Convolution5 -> Convolution5
I0924 21:06:13.933240  2642 net.cpp:122] Setting up Convolution5
I0924 21:06:13.933250  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.933253  2642 net.cpp:137] Memory required for data: 145409200
I0924 21:06:13.933257  2642 layer_factory.hpp:77] Creating layer BatchNorm5
I0924 21:06:13.933264  2642 net.cpp:84] Creating Layer BatchNorm5
I0924 21:06:13.933266  2642 net.cpp:406] BatchNorm5 <- Convolution5
I0924 21:06:13.933269  2642 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0924 21:06:13.933428  2642 net.cpp:122] Setting up BatchNorm5
I0924 21:06:13.933431  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.933434  2642 net.cpp:137] Memory required for data: 151962800
I0924 21:06:13.933442  2642 layer_factory.hpp:77] Creating layer Scale5
I0924 21:06:13.933446  2642 net.cpp:84] Creating Layer Scale5
I0924 21:06:13.933449  2642 net.cpp:406] Scale5 <- Convolution5
I0924 21:06:13.933452  2642 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0924 21:06:13.933485  2642 layer_factory.hpp:77] Creating layer Scale5
I0924 21:06:13.933573  2642 net.cpp:122] Setting up Scale5
I0924 21:06:13.933578  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.933580  2642 net.cpp:137] Memory required for data: 158516400
I0924 21:06:13.933583  2642 layer_factory.hpp:77] Creating layer Eltwise2
I0924 21:06:13.933588  2642 net.cpp:84] Creating Layer Eltwise2
I0924 21:06:13.933591  2642 net.cpp:406] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0924 21:06:13.933594  2642 net.cpp:406] Eltwise2 <- Convolution5
I0924 21:06:13.933598  2642 net.cpp:380] Eltwise2 -> Eltwise2
I0924 21:06:13.933616  2642 net.cpp:122] Setting up Eltwise2
I0924 21:06:13.933620  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.933622  2642 net.cpp:137] Memory required for data: 165070000
I0924 21:06:13.933624  2642 layer_factory.hpp:77] Creating layer ReLU5
I0924 21:06:13.933627  2642 net.cpp:84] Creating Layer ReLU5
I0924 21:06:13.933629  2642 net.cpp:406] ReLU5 <- Eltwise2
I0924 21:06:13.933632  2642 net.cpp:367] ReLU5 -> Eltwise2 (in-place)
I0924 21:06:13.934096  2642 net.cpp:122] Setting up ReLU5
I0924 21:06:13.934104  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.934108  2642 net.cpp:137] Memory required for data: 171623600
I0924 21:06:13.934109  2642 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0924 21:06:13.934114  2642 net.cpp:84] Creating Layer Eltwise2_ReLU5_0_split
I0924 21:06:13.934116  2642 net.cpp:406] Eltwise2_ReLU5_0_split <- Eltwise2
I0924 21:06:13.934120  2642 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0924 21:06:13.934125  2642 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0924 21:06:13.934159  2642 net.cpp:122] Setting up Eltwise2_ReLU5_0_split
I0924 21:06:13.934171  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.934175  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.934177  2642 net.cpp:137] Memory required for data: 184730800
I0924 21:06:13.934180  2642 layer_factory.hpp:77] Creating layer Convolution6
I0924 21:06:13.934187  2642 net.cpp:84] Creating Layer Convolution6
I0924 21:06:13.934190  2642 net.cpp:406] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0924 21:06:13.934193  2642 net.cpp:380] Convolution6 -> Convolution6
I0924 21:06:13.934830  2642 net.cpp:122] Setting up Convolution6
I0924 21:06:13.934837  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.934840  2642 net.cpp:137] Memory required for data: 191284400
I0924 21:06:13.934844  2642 layer_factory.hpp:77] Creating layer BatchNorm6
I0924 21:06:13.934849  2642 net.cpp:84] Creating Layer BatchNorm6
I0924 21:06:13.934851  2642 net.cpp:406] BatchNorm6 <- Convolution6
I0924 21:06:13.934856  2642 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0924 21:06:13.935014  2642 net.cpp:122] Setting up BatchNorm6
I0924 21:06:13.935019  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.935021  2642 net.cpp:137] Memory required for data: 197838000
I0924 21:06:13.935025  2642 layer_factory.hpp:77] Creating layer Scale6
I0924 21:06:13.935029  2642 net.cpp:84] Creating Layer Scale6
I0924 21:06:13.935032  2642 net.cpp:406] Scale6 <- Convolution6
I0924 21:06:13.935035  2642 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0924 21:06:13.935067  2642 layer_factory.hpp:77] Creating layer Scale6
I0924 21:06:13.935155  2642 net.cpp:122] Setting up Scale6
I0924 21:06:13.935160  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.935163  2642 net.cpp:137] Memory required for data: 204391600
I0924 21:06:13.935165  2642 layer_factory.hpp:77] Creating layer ReLU6
I0924 21:06:13.935169  2642 net.cpp:84] Creating Layer ReLU6
I0924 21:06:13.935173  2642 net.cpp:406] ReLU6 <- Convolution6
I0924 21:06:13.935176  2642 net.cpp:367] ReLU6 -> Convolution6 (in-place)
I0924 21:06:13.935638  2642 net.cpp:122] Setting up ReLU6
I0924 21:06:13.935647  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.935649  2642 net.cpp:137] Memory required for data: 210945200
I0924 21:06:13.935652  2642 layer_factory.hpp:77] Creating layer Convolution7
I0924 21:06:13.935659  2642 net.cpp:84] Creating Layer Convolution7
I0924 21:06:13.935662  2642 net.cpp:406] Convolution7 <- Convolution6
I0924 21:06:13.935667  2642 net.cpp:380] Convolution7 -> Convolution7
I0924 21:06:13.936967  2642 net.cpp:122] Setting up Convolution7
I0924 21:06:13.936976  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.936980  2642 net.cpp:137] Memory required for data: 217498800
I0924 21:06:13.936983  2642 layer_factory.hpp:77] Creating layer BatchNorm7
I0924 21:06:13.936990  2642 net.cpp:84] Creating Layer BatchNorm7
I0924 21:06:13.936993  2642 net.cpp:406] BatchNorm7 <- Convolution7
I0924 21:06:13.936998  2642 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0924 21:06:13.937158  2642 net.cpp:122] Setting up BatchNorm7
I0924 21:06:13.937163  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.937165  2642 net.cpp:137] Memory required for data: 224052400
I0924 21:06:13.937170  2642 layer_factory.hpp:77] Creating layer Scale7
I0924 21:06:13.937175  2642 net.cpp:84] Creating Layer Scale7
I0924 21:06:13.937176  2642 net.cpp:406] Scale7 <- Convolution7
I0924 21:06:13.937180  2642 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0924 21:06:13.937211  2642 layer_factory.hpp:77] Creating layer Scale7
I0924 21:06:13.937302  2642 net.cpp:122] Setting up Scale7
I0924 21:06:13.937306  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.937309  2642 net.cpp:137] Memory required for data: 230606000
I0924 21:06:13.937312  2642 layer_factory.hpp:77] Creating layer Eltwise3
I0924 21:06:13.937317  2642 net.cpp:84] Creating Layer Eltwise3
I0924 21:06:13.937319  2642 net.cpp:406] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0924 21:06:13.937322  2642 net.cpp:406] Eltwise3 <- Convolution7
I0924 21:06:13.937333  2642 net.cpp:380] Eltwise3 -> Eltwise3
I0924 21:06:13.937353  2642 net.cpp:122] Setting up Eltwise3
I0924 21:06:13.937357  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.937360  2642 net.cpp:137] Memory required for data: 237159600
I0924 21:06:13.937362  2642 layer_factory.hpp:77] Creating layer ReLU7
I0924 21:06:13.937366  2642 net.cpp:84] Creating Layer ReLU7
I0924 21:06:13.937369  2642 net.cpp:406] ReLU7 <- Eltwise3
I0924 21:06:13.937372  2642 net.cpp:367] ReLU7 -> Eltwise3 (in-place)
I0924 21:06:13.937497  2642 net.cpp:122] Setting up ReLU7
I0924 21:06:13.937503  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.937505  2642 net.cpp:137] Memory required for data: 243713200
I0924 21:06:13.937507  2642 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0924 21:06:13.937512  2642 net.cpp:84] Creating Layer Eltwise3_ReLU7_0_split
I0924 21:06:13.937515  2642 net.cpp:406] Eltwise3_ReLU7_0_split <- Eltwise3
I0924 21:06:13.937518  2642 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0924 21:06:13.937522  2642 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0924 21:06:13.937553  2642 net.cpp:122] Setting up Eltwise3_ReLU7_0_split
I0924 21:06:13.937557  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.937561  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.937562  2642 net.cpp:137] Memory required for data: 256820400
I0924 21:06:13.937564  2642 layer_factory.hpp:77] Creating layer Convolution8
I0924 21:06:13.937572  2642 net.cpp:84] Creating Layer Convolution8
I0924 21:06:13.937573  2642 net.cpp:406] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0924 21:06:13.937578  2642 net.cpp:380] Convolution8 -> Convolution8
I0924 21:06:13.938542  2642 net.cpp:122] Setting up Convolution8
I0924 21:06:13.938551  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.938554  2642 net.cpp:137] Memory required for data: 263374000
I0924 21:06:13.938558  2642 layer_factory.hpp:77] Creating layer BatchNorm8
I0924 21:06:13.938565  2642 net.cpp:84] Creating Layer BatchNorm8
I0924 21:06:13.938567  2642 net.cpp:406] BatchNorm8 <- Convolution8
I0924 21:06:13.938571  2642 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0924 21:06:13.938730  2642 net.cpp:122] Setting up BatchNorm8
I0924 21:06:13.938735  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.938736  2642 net.cpp:137] Memory required for data: 269927600
I0924 21:06:13.938741  2642 layer_factory.hpp:77] Creating layer Scale8
I0924 21:06:13.938745  2642 net.cpp:84] Creating Layer Scale8
I0924 21:06:13.938748  2642 net.cpp:406] Scale8 <- Convolution8
I0924 21:06:13.938752  2642 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0924 21:06:13.938783  2642 layer_factory.hpp:77] Creating layer Scale8
I0924 21:06:13.938874  2642 net.cpp:122] Setting up Scale8
I0924 21:06:13.938879  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.938880  2642 net.cpp:137] Memory required for data: 276481200
I0924 21:06:13.938884  2642 layer_factory.hpp:77] Creating layer ReLU8
I0924 21:06:13.938887  2642 net.cpp:84] Creating Layer ReLU8
I0924 21:06:13.938890  2642 net.cpp:406] ReLU8 <- Convolution8
I0924 21:06:13.938894  2642 net.cpp:367] ReLU8 -> Convolution8 (in-place)
I0924 21:06:13.939020  2642 net.cpp:122] Setting up ReLU8
I0924 21:06:13.939025  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.939028  2642 net.cpp:137] Memory required for data: 283034800
I0924 21:06:13.939030  2642 layer_factory.hpp:77] Creating layer Convolution9
I0924 21:06:13.939038  2642 net.cpp:84] Creating Layer Convolution9
I0924 21:06:13.939040  2642 net.cpp:406] Convolution9 <- Convolution8
I0924 21:06:13.939044  2642 net.cpp:380] Convolution9 -> Convolution9
I0924 21:06:13.940012  2642 net.cpp:122] Setting up Convolution9
I0924 21:06:13.940021  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.940023  2642 net.cpp:137] Memory required for data: 289588400
I0924 21:06:13.940028  2642 layer_factory.hpp:77] Creating layer BatchNorm9
I0924 21:06:13.940040  2642 net.cpp:84] Creating Layer BatchNorm9
I0924 21:06:13.940043  2642 net.cpp:406] BatchNorm9 <- Convolution9
I0924 21:06:13.940047  2642 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0924 21:06:13.940207  2642 net.cpp:122] Setting up BatchNorm9
I0924 21:06:13.940212  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.940213  2642 net.cpp:137] Memory required for data: 296142000
I0924 21:06:13.940218  2642 layer_factory.hpp:77] Creating layer Scale9
I0924 21:06:13.940222  2642 net.cpp:84] Creating Layer Scale9
I0924 21:06:13.940224  2642 net.cpp:406] Scale9 <- Convolution9
I0924 21:06:13.940228  2642 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0924 21:06:13.940259  2642 layer_factory.hpp:77] Creating layer Scale9
I0924 21:06:13.940347  2642 net.cpp:122] Setting up Scale9
I0924 21:06:13.940352  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.940354  2642 net.cpp:137] Memory required for data: 302695600
I0924 21:06:13.940358  2642 layer_factory.hpp:77] Creating layer Eltwise4
I0924 21:06:13.940362  2642 net.cpp:84] Creating Layer Eltwise4
I0924 21:06:13.940366  2642 net.cpp:406] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I0924 21:06:13.940367  2642 net.cpp:406] Eltwise4 <- Convolution9
I0924 21:06:13.940371  2642 net.cpp:380] Eltwise4 -> Eltwise4
I0924 21:06:13.940390  2642 net.cpp:122] Setting up Eltwise4
I0924 21:06:13.940394  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.940397  2642 net.cpp:137] Memory required for data: 309249200
I0924 21:06:13.940398  2642 layer_factory.hpp:77] Creating layer ReLU9
I0924 21:06:13.940403  2642 net.cpp:84] Creating Layer ReLU9
I0924 21:06:13.940405  2642 net.cpp:406] ReLU9 <- Eltwise4
I0924 21:06:13.940408  2642 net.cpp:367] ReLU9 -> Eltwise4 (in-place)
I0924 21:06:13.940534  2642 net.cpp:122] Setting up ReLU9
I0924 21:06:13.940541  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.940542  2642 net.cpp:137] Memory required for data: 315802800
I0924 21:06:13.940544  2642 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0924 21:06:13.940549  2642 net.cpp:84] Creating Layer Eltwise4_ReLU9_0_split
I0924 21:06:13.940552  2642 net.cpp:406] Eltwise4_ReLU9_0_split <- Eltwise4
I0924 21:06:13.940556  2642 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0924 21:06:13.940560  2642 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0924 21:06:13.940593  2642 net.cpp:122] Setting up Eltwise4_ReLU9_0_split
I0924 21:06:13.940596  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.940598  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.940600  2642 net.cpp:137] Memory required for data: 328910000
I0924 21:06:13.940603  2642 layer_factory.hpp:77] Creating layer Convolution10
I0924 21:06:13.940609  2642 net.cpp:84] Creating Layer Convolution10
I0924 21:06:13.940611  2642 net.cpp:406] Convolution10 <- Eltwise4_ReLU9_0_split_0
I0924 21:06:13.940616  2642 net.cpp:380] Convolution10 -> Convolution10
I0924 21:06:13.941587  2642 net.cpp:122] Setting up Convolution10
I0924 21:06:13.941597  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.941599  2642 net.cpp:137] Memory required for data: 335463600
I0924 21:06:13.941610  2642 layer_factory.hpp:77] Creating layer BatchNorm10
I0924 21:06:13.941615  2642 net.cpp:84] Creating Layer BatchNorm10
I0924 21:06:13.941618  2642 net.cpp:406] BatchNorm10 <- Convolution10
I0924 21:06:13.941622  2642 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0924 21:06:13.941783  2642 net.cpp:122] Setting up BatchNorm10
I0924 21:06:13.941787  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.941790  2642 net.cpp:137] Memory required for data: 342017200
I0924 21:06:13.941795  2642 layer_factory.hpp:77] Creating layer Scale10
I0924 21:06:13.941799  2642 net.cpp:84] Creating Layer Scale10
I0924 21:06:13.941802  2642 net.cpp:406] Scale10 <- Convolution10
I0924 21:06:13.941804  2642 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0924 21:06:13.941846  2642 layer_factory.hpp:77] Creating layer Scale10
I0924 21:06:13.941937  2642 net.cpp:122] Setting up Scale10
I0924 21:06:13.941941  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.941943  2642 net.cpp:137] Memory required for data: 348570800
I0924 21:06:13.941947  2642 layer_factory.hpp:77] Creating layer ReLU10
I0924 21:06:13.941952  2642 net.cpp:84] Creating Layer ReLU10
I0924 21:06:13.941954  2642 net.cpp:406] ReLU10 <- Convolution10
I0924 21:06:13.941957  2642 net.cpp:367] ReLU10 -> Convolution10 (in-place)
I0924 21:06:13.942085  2642 net.cpp:122] Setting up ReLU10
I0924 21:06:13.942091  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.942093  2642 net.cpp:137] Memory required for data: 355124400
I0924 21:06:13.942096  2642 layer_factory.hpp:77] Creating layer Convolution11
I0924 21:06:13.942103  2642 net.cpp:84] Creating Layer Convolution11
I0924 21:06:13.942106  2642 net.cpp:406] Convolution11 <- Convolution10
I0924 21:06:13.942109  2642 net.cpp:380] Convolution11 -> Convolution11
I0924 21:06:13.943403  2642 net.cpp:122] Setting up Convolution11
I0924 21:06:13.943410  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.943413  2642 net.cpp:137] Memory required for data: 361678000
I0924 21:06:13.943418  2642 layer_factory.hpp:77] Creating layer BatchNorm11
I0924 21:06:13.943423  2642 net.cpp:84] Creating Layer BatchNorm11
I0924 21:06:13.943425  2642 net.cpp:406] BatchNorm11 <- Convolution11
I0924 21:06:13.943429  2642 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0924 21:06:13.943596  2642 net.cpp:122] Setting up BatchNorm11
I0924 21:06:13.943601  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.943603  2642 net.cpp:137] Memory required for data: 368231600
I0924 21:06:13.943608  2642 layer_factory.hpp:77] Creating layer Scale11
I0924 21:06:13.943612  2642 net.cpp:84] Creating Layer Scale11
I0924 21:06:13.943615  2642 net.cpp:406] Scale11 <- Convolution11
I0924 21:06:13.943619  2642 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0924 21:06:13.943650  2642 layer_factory.hpp:77] Creating layer Scale11
I0924 21:06:13.943740  2642 net.cpp:122] Setting up Scale11
I0924 21:06:13.943745  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.943747  2642 net.cpp:137] Memory required for data: 374785200
I0924 21:06:13.943752  2642 layer_factory.hpp:77] Creating layer Eltwise5
I0924 21:06:13.943755  2642 net.cpp:84] Creating Layer Eltwise5
I0924 21:06:13.943758  2642 net.cpp:406] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I0924 21:06:13.943761  2642 net.cpp:406] Eltwise5 <- Convolution11
I0924 21:06:13.943764  2642 net.cpp:380] Eltwise5 -> Eltwise5
I0924 21:06:13.943783  2642 net.cpp:122] Setting up Eltwise5
I0924 21:06:13.943787  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.943789  2642 net.cpp:137] Memory required for data: 381338800
I0924 21:06:13.943791  2642 layer_factory.hpp:77] Creating layer ReLU11
I0924 21:06:13.943795  2642 net.cpp:84] Creating Layer ReLU11
I0924 21:06:13.943797  2642 net.cpp:406] ReLU11 <- Eltwise5
I0924 21:06:13.943801  2642 net.cpp:367] ReLU11 -> Eltwise5 (in-place)
I0924 21:06:13.944260  2642 net.cpp:122] Setting up ReLU11
I0924 21:06:13.944269  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.944272  2642 net.cpp:137] Memory required for data: 387892400
I0924 21:06:13.944274  2642 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0924 21:06:13.944278  2642 net.cpp:84] Creating Layer Eltwise5_ReLU11_0_split
I0924 21:06:13.944280  2642 net.cpp:406] Eltwise5_ReLU11_0_split <- Eltwise5
I0924 21:06:13.944285  2642 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0924 21:06:13.944289  2642 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0924 21:06:13.944324  2642 net.cpp:122] Setting up Eltwise5_ReLU11_0_split
I0924 21:06:13.944327  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.944330  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.944332  2642 net.cpp:137] Memory required for data: 400999600
I0924 21:06:13.944340  2642 layer_factory.hpp:77] Creating layer Convolution12
I0924 21:06:13.944349  2642 net.cpp:84] Creating Layer Convolution12
I0924 21:06:13.944351  2642 net.cpp:406] Convolution12 <- Eltwise5_ReLU11_0_split_0
I0924 21:06:13.944355  2642 net.cpp:380] Convolution12 -> Convolution12
I0924 21:06:13.945004  2642 net.cpp:122] Setting up Convolution12
I0924 21:06:13.945013  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.945014  2642 net.cpp:137] Memory required for data: 407553200
I0924 21:06:13.945019  2642 layer_factory.hpp:77] Creating layer BatchNorm12
I0924 21:06:13.945024  2642 net.cpp:84] Creating Layer BatchNorm12
I0924 21:06:13.945026  2642 net.cpp:406] BatchNorm12 <- Convolution12
I0924 21:06:13.945030  2642 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0924 21:06:13.945190  2642 net.cpp:122] Setting up BatchNorm12
I0924 21:06:13.945194  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.945196  2642 net.cpp:137] Memory required for data: 414106800
I0924 21:06:13.945201  2642 layer_factory.hpp:77] Creating layer Scale12
I0924 21:06:13.945205  2642 net.cpp:84] Creating Layer Scale12
I0924 21:06:13.945207  2642 net.cpp:406] Scale12 <- Convolution12
I0924 21:06:13.945211  2642 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0924 21:06:13.945242  2642 layer_factory.hpp:77] Creating layer Scale12
I0924 21:06:13.945332  2642 net.cpp:122] Setting up Scale12
I0924 21:06:13.945335  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.945338  2642 net.cpp:137] Memory required for data: 420660400
I0924 21:06:13.945341  2642 layer_factory.hpp:77] Creating layer ReLU12
I0924 21:06:13.945346  2642 net.cpp:84] Creating Layer ReLU12
I0924 21:06:13.945349  2642 net.cpp:406] ReLU12 <- Convolution12
I0924 21:06:13.945353  2642 net.cpp:367] ReLU12 -> Convolution12 (in-place)
I0924 21:06:13.945812  2642 net.cpp:122] Setting up ReLU12
I0924 21:06:13.945821  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.945823  2642 net.cpp:137] Memory required for data: 427214000
I0924 21:06:13.945825  2642 layer_factory.hpp:77] Creating layer Convolution13
I0924 21:06:13.945833  2642 net.cpp:84] Creating Layer Convolution13
I0924 21:06:13.945837  2642 net.cpp:406] Convolution13 <- Convolution12
I0924 21:06:13.945840  2642 net.cpp:380] Convolution13 -> Convolution13
I0924 21:06:13.946825  2642 net.cpp:122] Setting up Convolution13
I0924 21:06:13.946832  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.946835  2642 net.cpp:137] Memory required for data: 433767600
I0924 21:06:13.946840  2642 layer_factory.hpp:77] Creating layer BatchNorm13
I0924 21:06:13.946844  2642 net.cpp:84] Creating Layer BatchNorm13
I0924 21:06:13.946847  2642 net.cpp:406] BatchNorm13 <- Convolution13
I0924 21:06:13.946851  2642 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0924 21:06:13.947012  2642 net.cpp:122] Setting up BatchNorm13
I0924 21:06:13.947017  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.947019  2642 net.cpp:137] Memory required for data: 440321200
I0924 21:06:13.947024  2642 layer_factory.hpp:77] Creating layer Scale13
I0924 21:06:13.947028  2642 net.cpp:84] Creating Layer Scale13
I0924 21:06:13.947031  2642 net.cpp:406] Scale13 <- Convolution13
I0924 21:06:13.947034  2642 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0924 21:06:13.947065  2642 layer_factory.hpp:77] Creating layer Scale13
I0924 21:06:13.947155  2642 net.cpp:122] Setting up Scale13
I0924 21:06:13.947160  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.947162  2642 net.cpp:137] Memory required for data: 446874800
I0924 21:06:13.947166  2642 layer_factory.hpp:77] Creating layer Eltwise6
I0924 21:06:13.947173  2642 net.cpp:84] Creating Layer Eltwise6
I0924 21:06:13.947176  2642 net.cpp:406] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0924 21:06:13.947180  2642 net.cpp:406] Eltwise6 <- Convolution13
I0924 21:06:13.947183  2642 net.cpp:380] Eltwise6 -> Eltwise6
I0924 21:06:13.947203  2642 net.cpp:122] Setting up Eltwise6
I0924 21:06:13.947213  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.947216  2642 net.cpp:137] Memory required for data: 453428400
I0924 21:06:13.947219  2642 layer_factory.hpp:77] Creating layer ReLU13
I0924 21:06:13.947222  2642 net.cpp:84] Creating Layer ReLU13
I0924 21:06:13.947226  2642 net.cpp:406] ReLU13 <- Eltwise6
I0924 21:06:13.947229  2642 net.cpp:367] ReLU13 -> Eltwise6 (in-place)
I0924 21:06:13.947360  2642 net.cpp:122] Setting up ReLU13
I0924 21:06:13.947365  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.947368  2642 net.cpp:137] Memory required for data: 459982000
I0924 21:06:13.947371  2642 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0924 21:06:13.947374  2642 net.cpp:84] Creating Layer Eltwise6_ReLU13_0_split
I0924 21:06:13.947376  2642 net.cpp:406] Eltwise6_ReLU13_0_split <- Eltwise6
I0924 21:06:13.947381  2642 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0924 21:06:13.947386  2642 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0924 21:06:13.947417  2642 net.cpp:122] Setting up Eltwise6_ReLU13_0_split
I0924 21:06:13.947422  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.947424  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.947425  2642 net.cpp:137] Memory required for data: 473089200
I0924 21:06:13.947428  2642 layer_factory.hpp:77] Creating layer Convolution14
I0924 21:06:13.947435  2642 net.cpp:84] Creating Layer Convolution14
I0924 21:06:13.947438  2642 net.cpp:406] Convolution14 <- Eltwise6_ReLU13_0_split_0
I0924 21:06:13.947443  2642 net.cpp:380] Convolution14 -> Convolution14
I0924 21:06:13.948417  2642 net.cpp:122] Setting up Convolution14
I0924 21:06:13.948426  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.948428  2642 net.cpp:137] Memory required for data: 479642800
I0924 21:06:13.948432  2642 layer_factory.hpp:77] Creating layer BatchNorm14
I0924 21:06:13.948438  2642 net.cpp:84] Creating Layer BatchNorm14
I0924 21:06:13.948441  2642 net.cpp:406] BatchNorm14 <- Convolution14
I0924 21:06:13.948446  2642 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0924 21:06:13.948607  2642 net.cpp:122] Setting up BatchNorm14
I0924 21:06:13.948612  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.948614  2642 net.cpp:137] Memory required for data: 486196400
I0924 21:06:13.948619  2642 layer_factory.hpp:77] Creating layer Scale14
I0924 21:06:13.948624  2642 net.cpp:84] Creating Layer Scale14
I0924 21:06:13.948626  2642 net.cpp:406] Scale14 <- Convolution14
I0924 21:06:13.948631  2642 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0924 21:06:13.948662  2642 layer_factory.hpp:77] Creating layer Scale14
I0924 21:06:13.948755  2642 net.cpp:122] Setting up Scale14
I0924 21:06:13.948758  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.948760  2642 net.cpp:137] Memory required for data: 492750000
I0924 21:06:13.948765  2642 layer_factory.hpp:77] Creating layer ReLU14
I0924 21:06:13.948768  2642 net.cpp:84] Creating Layer ReLU14
I0924 21:06:13.948770  2642 net.cpp:406] ReLU14 <- Convolution14
I0924 21:06:13.948774  2642 net.cpp:367] ReLU14 -> Convolution14 (in-place)
I0924 21:06:13.948900  2642 net.cpp:122] Setting up ReLU14
I0924 21:06:13.948906  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.948909  2642 net.cpp:137] Memory required for data: 499303600
I0924 21:06:13.948910  2642 layer_factory.hpp:77] Creating layer Convolution15
I0924 21:06:13.948927  2642 net.cpp:84] Creating Layer Convolution15
I0924 21:06:13.948930  2642 net.cpp:406] Convolution15 <- Convolution14
I0924 21:06:13.948935  2642 net.cpp:380] Convolution15 -> Convolution15
I0924 21:06:13.949923  2642 net.cpp:122] Setting up Convolution15
I0924 21:06:13.949930  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.949934  2642 net.cpp:137] Memory required for data: 505857200
I0924 21:06:13.949937  2642 layer_factory.hpp:77] Creating layer BatchNorm15
I0924 21:06:13.949944  2642 net.cpp:84] Creating Layer BatchNorm15
I0924 21:06:13.949952  2642 net.cpp:406] BatchNorm15 <- Convolution15
I0924 21:06:13.949957  2642 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0924 21:06:13.950120  2642 net.cpp:122] Setting up BatchNorm15
I0924 21:06:13.950124  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.950127  2642 net.cpp:137] Memory required for data: 512410800
I0924 21:06:13.950132  2642 layer_factory.hpp:77] Creating layer Scale15
I0924 21:06:13.950135  2642 net.cpp:84] Creating Layer Scale15
I0924 21:06:13.950139  2642 net.cpp:406] Scale15 <- Convolution15
I0924 21:06:13.950143  2642 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0924 21:06:13.950176  2642 layer_factory.hpp:77] Creating layer Scale15
I0924 21:06:13.950265  2642 net.cpp:122] Setting up Scale15
I0924 21:06:13.950270  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.950273  2642 net.cpp:137] Memory required for data: 518964400
I0924 21:06:13.950276  2642 layer_factory.hpp:77] Creating layer Eltwise7
I0924 21:06:13.950280  2642 net.cpp:84] Creating Layer Eltwise7
I0924 21:06:13.950284  2642 net.cpp:406] Eltwise7 <- Eltwise6_ReLU13_0_split_1
I0924 21:06:13.950286  2642 net.cpp:406] Eltwise7 <- Convolution15
I0924 21:06:13.950289  2642 net.cpp:380] Eltwise7 -> Eltwise7
I0924 21:06:13.950309  2642 net.cpp:122] Setting up Eltwise7
I0924 21:06:13.950314  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.950315  2642 net.cpp:137] Memory required for data: 525518000
I0924 21:06:13.950317  2642 layer_factory.hpp:77] Creating layer ReLU15
I0924 21:06:13.950320  2642 net.cpp:84] Creating Layer ReLU15
I0924 21:06:13.950322  2642 net.cpp:406] ReLU15 <- Eltwise7
I0924 21:06:13.950326  2642 net.cpp:367] ReLU15 -> Eltwise7 (in-place)
I0924 21:06:13.950453  2642 net.cpp:122] Setting up ReLU15
I0924 21:06:13.950459  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.950461  2642 net.cpp:137] Memory required for data: 532071600
I0924 21:06:13.950464  2642 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0924 21:06:13.950467  2642 net.cpp:84] Creating Layer Eltwise7_ReLU15_0_split
I0924 21:06:13.950469  2642 net.cpp:406] Eltwise7_ReLU15_0_split <- Eltwise7
I0924 21:06:13.950474  2642 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0924 21:06:13.950479  2642 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0924 21:06:13.950510  2642 net.cpp:122] Setting up Eltwise7_ReLU15_0_split
I0924 21:06:13.950515  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.950517  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.950520  2642 net.cpp:137] Memory required for data: 545178800
I0924 21:06:13.950521  2642 layer_factory.hpp:77] Creating layer Convolution16
I0924 21:06:13.950528  2642 net.cpp:84] Creating Layer Convolution16
I0924 21:06:13.950531  2642 net.cpp:406] Convolution16 <- Eltwise7_ReLU15_0_split_0
I0924 21:06:13.950534  2642 net.cpp:380] Convolution16 -> Convolution16
I0924 21:06:13.951508  2642 net.cpp:122] Setting up Convolution16
I0924 21:06:13.951515  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.951519  2642 net.cpp:137] Memory required for data: 551732400
I0924 21:06:13.951522  2642 layer_factory.hpp:77] Creating layer BatchNorm16
I0924 21:06:13.951529  2642 net.cpp:84] Creating Layer BatchNorm16
I0924 21:06:13.951530  2642 net.cpp:406] BatchNorm16 <- Convolution16
I0924 21:06:13.951534  2642 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0924 21:06:13.951699  2642 net.cpp:122] Setting up BatchNorm16
I0924 21:06:13.951702  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.951704  2642 net.cpp:137] Memory required for data: 558286000
I0924 21:06:13.951709  2642 layer_factory.hpp:77] Creating layer Scale16
I0924 21:06:13.951714  2642 net.cpp:84] Creating Layer Scale16
I0924 21:06:13.951716  2642 net.cpp:406] Scale16 <- Convolution16
I0924 21:06:13.951719  2642 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0924 21:06:13.951751  2642 layer_factory.hpp:77] Creating layer Scale16
I0924 21:06:13.951850  2642 net.cpp:122] Setting up Scale16
I0924 21:06:13.951855  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.951858  2642 net.cpp:137] Memory required for data: 564839600
I0924 21:06:13.951861  2642 layer_factory.hpp:77] Creating layer ReLU16
I0924 21:06:13.951865  2642 net.cpp:84] Creating Layer ReLU16
I0924 21:06:13.951869  2642 net.cpp:406] ReLU16 <- Convolution16
I0924 21:06:13.951871  2642 net.cpp:367] ReLU16 -> Convolution16 (in-place)
I0924 21:06:13.952002  2642 net.cpp:122] Setting up ReLU16
I0924 21:06:13.952008  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.952009  2642 net.cpp:137] Memory required for data: 571393200
I0924 21:06:13.952013  2642 layer_factory.hpp:77] Creating layer Convolution17
I0924 21:06:13.952019  2642 net.cpp:84] Creating Layer Convolution17
I0924 21:06:13.952023  2642 net.cpp:406] Convolution17 <- Convolution16
I0924 21:06:13.952026  2642 net.cpp:380] Convolution17 -> Convolution17
I0924 21:06:13.953008  2642 net.cpp:122] Setting up Convolution17
I0924 21:06:13.953017  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.953019  2642 net.cpp:137] Memory required for data: 577946800
I0924 21:06:13.953024  2642 layer_factory.hpp:77] Creating layer BatchNorm17
I0924 21:06:13.953029  2642 net.cpp:84] Creating Layer BatchNorm17
I0924 21:06:13.956328  2642 net.cpp:406] BatchNorm17 <- Convolution17
I0924 21:06:13.956332  2642 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0924 21:06:13.956511  2642 net.cpp:122] Setting up BatchNorm17
I0924 21:06:13.956516  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.956518  2642 net.cpp:137] Memory required for data: 584500400
I0924 21:06:13.956523  2642 layer_factory.hpp:77] Creating layer Scale17
I0924 21:06:13.956528  2642 net.cpp:84] Creating Layer Scale17
I0924 21:06:13.956532  2642 net.cpp:406] Scale17 <- Convolution17
I0924 21:06:13.956534  2642 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0924 21:06:13.956570  2642 layer_factory.hpp:77] Creating layer Scale17
I0924 21:06:13.956670  2642 net.cpp:122] Setting up Scale17
I0924 21:06:13.956676  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.956677  2642 net.cpp:137] Memory required for data: 591054000
I0924 21:06:13.956681  2642 layer_factory.hpp:77] Creating layer Eltwise8
I0924 21:06:13.956686  2642 net.cpp:84] Creating Layer Eltwise8
I0924 21:06:13.956688  2642 net.cpp:406] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0924 21:06:13.956691  2642 net.cpp:406] Eltwise8 <- Convolution17
I0924 21:06:13.956696  2642 net.cpp:380] Eltwise8 -> Eltwise8
I0924 21:06:13.956717  2642 net.cpp:122] Setting up Eltwise8
I0924 21:06:13.956722  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.956723  2642 net.cpp:137] Memory required for data: 597607600
I0924 21:06:13.956725  2642 layer_factory.hpp:77] Creating layer ReLU17
I0924 21:06:13.956729  2642 net.cpp:84] Creating Layer ReLU17
I0924 21:06:13.956732  2642 net.cpp:406] ReLU17 <- Eltwise8
I0924 21:06:13.956735  2642 net.cpp:367] ReLU17 -> Eltwise8 (in-place)
I0924 21:06:13.957239  2642 net.cpp:122] Setting up ReLU17
I0924 21:06:13.957249  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.957252  2642 net.cpp:137] Memory required for data: 604161200
I0924 21:06:13.957254  2642 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0924 21:06:13.957259  2642 net.cpp:84] Creating Layer Eltwise8_ReLU17_0_split
I0924 21:06:13.957262  2642 net.cpp:406] Eltwise8_ReLU17_0_split <- Eltwise8
I0924 21:06:13.957267  2642 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0924 21:06:13.957271  2642 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0924 21:06:13.957309  2642 net.cpp:122] Setting up Eltwise8_ReLU17_0_split
I0924 21:06:13.957314  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.957316  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.957319  2642 net.cpp:137] Memory required for data: 617268400
I0924 21:06:13.957320  2642 layer_factory.hpp:77] Creating layer Convolution18
I0924 21:06:13.957334  2642 net.cpp:84] Creating Layer Convolution18
I0924 21:06:13.957339  2642 net.cpp:406] Convolution18 <- Eltwise8_ReLU17_0_split_0
I0924 21:06:13.957343  2642 net.cpp:380] Convolution18 -> Convolution18
I0924 21:06:13.958065  2642 net.cpp:122] Setting up Convolution18
I0924 21:06:13.958071  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.958073  2642 net.cpp:137] Memory required for data: 623822000
I0924 21:06:13.958078  2642 layer_factory.hpp:77] Creating layer BatchNorm18
I0924 21:06:13.958083  2642 net.cpp:84] Creating Layer BatchNorm18
I0924 21:06:13.958086  2642 net.cpp:406] BatchNorm18 <- Convolution18
I0924 21:06:13.958089  2642 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0924 21:06:13.958253  2642 net.cpp:122] Setting up BatchNorm18
I0924 21:06:13.958258  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.958261  2642 net.cpp:137] Memory required for data: 630375600
I0924 21:06:13.958266  2642 layer_factory.hpp:77] Creating layer Scale18
I0924 21:06:13.958269  2642 net.cpp:84] Creating Layer Scale18
I0924 21:06:13.958271  2642 net.cpp:406] Scale18 <- Convolution18
I0924 21:06:13.958276  2642 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0924 21:06:13.958307  2642 layer_factory.hpp:77] Creating layer Scale18
I0924 21:06:13.958400  2642 net.cpp:122] Setting up Scale18
I0924 21:06:13.958413  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.958416  2642 net.cpp:137] Memory required for data: 636929200
I0924 21:06:13.958420  2642 layer_factory.hpp:77] Creating layer ReLU18
I0924 21:06:13.958425  2642 net.cpp:84] Creating Layer ReLU18
I0924 21:06:13.958427  2642 net.cpp:406] ReLU18 <- Convolution18
I0924 21:06:13.958431  2642 net.cpp:367] ReLU18 -> Convolution18 (in-place)
I0924 21:06:13.958904  2642 net.cpp:122] Setting up ReLU18
I0924 21:06:13.958912  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.958914  2642 net.cpp:137] Memory required for data: 643482800
I0924 21:06:13.958917  2642 layer_factory.hpp:77] Creating layer Convolution19
I0924 21:06:13.958925  2642 net.cpp:84] Creating Layer Convolution19
I0924 21:06:13.958927  2642 net.cpp:406] Convolution19 <- Convolution18
I0924 21:06:13.958932  2642 net.cpp:380] Convolution19 -> Convolution19
I0924 21:06:13.959945  2642 net.cpp:122] Setting up Convolution19
I0924 21:06:13.959954  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.959956  2642 net.cpp:137] Memory required for data: 650036400
I0924 21:06:13.959961  2642 layer_factory.hpp:77] Creating layer BatchNorm19
I0924 21:06:13.959966  2642 net.cpp:84] Creating Layer BatchNorm19
I0924 21:06:13.959969  2642 net.cpp:406] BatchNorm19 <- Convolution19
I0924 21:06:13.959975  2642 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0924 21:06:13.960186  2642 net.cpp:122] Setting up BatchNorm19
I0924 21:06:13.960191  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.960193  2642 net.cpp:137] Memory required for data: 656590000
I0924 21:06:13.960209  2642 layer_factory.hpp:77] Creating layer Scale19
I0924 21:06:13.960216  2642 net.cpp:84] Creating Layer Scale19
I0924 21:06:13.960217  2642 net.cpp:406] Scale19 <- Convolution19
I0924 21:06:13.960222  2642 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0924 21:06:13.960255  2642 layer_factory.hpp:77] Creating layer Scale19
I0924 21:06:13.960346  2642 net.cpp:122] Setting up Scale19
I0924 21:06:13.960350  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.960352  2642 net.cpp:137] Memory required for data: 663143600
I0924 21:06:13.960356  2642 layer_factory.hpp:77] Creating layer Eltwise9
I0924 21:06:13.960361  2642 net.cpp:84] Creating Layer Eltwise9
I0924 21:06:13.960363  2642 net.cpp:406] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I0924 21:06:13.960366  2642 net.cpp:406] Eltwise9 <- Convolution19
I0924 21:06:13.960368  2642 net.cpp:380] Eltwise9 -> Eltwise9
I0924 21:06:13.960388  2642 net.cpp:122] Setting up Eltwise9
I0924 21:06:13.960392  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.960399  2642 net.cpp:137] Memory required for data: 669697200
I0924 21:06:13.960402  2642 layer_factory.hpp:77] Creating layer ReLU19
I0924 21:06:13.960405  2642 net.cpp:84] Creating Layer ReLU19
I0924 21:06:13.960408  2642 net.cpp:406] ReLU19 <- Eltwise9
I0924 21:06:13.960412  2642 net.cpp:367] ReLU19 -> Eltwise9 (in-place)
I0924 21:06:13.960537  2642 net.cpp:122] Setting up ReLU19
I0924 21:06:13.960543  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.960546  2642 net.cpp:137] Memory required for data: 676250800
I0924 21:06:13.960547  2642 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I0924 21:06:13.960551  2642 net.cpp:84] Creating Layer Eltwise9_ReLU19_0_split
I0924 21:06:13.960554  2642 net.cpp:406] Eltwise9_ReLU19_0_split <- Eltwise9
I0924 21:06:13.960558  2642 net.cpp:380] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I0924 21:06:13.960562  2642 net.cpp:380] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I0924 21:06:13.960594  2642 net.cpp:122] Setting up Eltwise9_ReLU19_0_split
I0924 21:06:13.960598  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.960602  2642 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0924 21:06:13.960603  2642 net.cpp:137] Memory required for data: 689358000
I0924 21:06:13.960605  2642 layer_factory.hpp:77] Creating layer Convolution20
I0924 21:06:13.960611  2642 net.cpp:84] Creating Layer Convolution20
I0924 21:06:13.960614  2642 net.cpp:406] Convolution20 <- Eltwise9_ReLU19_0_split_0
I0924 21:06:13.960618  2642 net.cpp:380] Convolution20 -> Convolution20
I0924 21:06:13.961558  2642 net.cpp:122] Setting up Convolution20
I0924 21:06:13.961567  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.961570  2642 net.cpp:137] Memory required for data: 692634800
I0924 21:06:13.961575  2642 layer_factory.hpp:77] Creating layer BatchNorm20
I0924 21:06:13.961580  2642 net.cpp:84] Creating Layer BatchNorm20
I0924 21:06:13.961582  2642 net.cpp:406] BatchNorm20 <- Convolution20
I0924 21:06:13.961586  2642 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0924 21:06:13.961746  2642 net.cpp:122] Setting up BatchNorm20
I0924 21:06:13.961750  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.961752  2642 net.cpp:137] Memory required for data: 695911600
I0924 21:06:13.961757  2642 layer_factory.hpp:77] Creating layer Scale20
I0924 21:06:13.961761  2642 net.cpp:84] Creating Layer Scale20
I0924 21:06:13.961763  2642 net.cpp:406] Scale20 <- Convolution20
I0924 21:06:13.961767  2642 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0924 21:06:13.961799  2642 layer_factory.hpp:77] Creating layer Scale20
I0924 21:06:13.961889  2642 net.cpp:122] Setting up Scale20
I0924 21:06:13.961894  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.961895  2642 net.cpp:137] Memory required for data: 699188400
I0924 21:06:13.961899  2642 layer_factory.hpp:77] Creating layer Convolution21
I0924 21:06:13.961907  2642 net.cpp:84] Creating Layer Convolution21
I0924 21:06:13.961910  2642 net.cpp:406] Convolution21 <- Eltwise9_ReLU19_0_split_1
I0924 21:06:13.961915  2642 net.cpp:380] Convolution21 -> Convolution21
I0924 21:06:13.962929  2642 net.cpp:122] Setting up Convolution21
I0924 21:06:13.962939  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.962940  2642 net.cpp:137] Memory required for data: 702465200
I0924 21:06:13.962945  2642 layer_factory.hpp:77] Creating layer BatchNorm21
I0924 21:06:13.962950  2642 net.cpp:84] Creating Layer BatchNorm21
I0924 21:06:13.962952  2642 net.cpp:406] BatchNorm21 <- Convolution21
I0924 21:06:13.962956  2642 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0924 21:06:13.963114  2642 net.cpp:122] Setting up BatchNorm21
I0924 21:06:13.963119  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.963120  2642 net.cpp:137] Memory required for data: 705742000
I0924 21:06:13.963125  2642 layer_factory.hpp:77] Creating layer Scale21
I0924 21:06:13.963130  2642 net.cpp:84] Creating Layer Scale21
I0924 21:06:13.963132  2642 net.cpp:406] Scale21 <- Convolution21
I0924 21:06:13.963142  2642 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0924 21:06:13.963176  2642 layer_factory.hpp:77] Creating layer Scale21
I0924 21:06:13.963268  2642 net.cpp:122] Setting up Scale21
I0924 21:06:13.963273  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.963274  2642 net.cpp:137] Memory required for data: 709018800
I0924 21:06:13.963277  2642 layer_factory.hpp:77] Creating layer ReLU20
I0924 21:06:13.963282  2642 net.cpp:84] Creating Layer ReLU20
I0924 21:06:13.963284  2642 net.cpp:406] ReLU20 <- Convolution21
I0924 21:06:13.963287  2642 net.cpp:367] ReLU20 -> Convolution21 (in-place)
I0924 21:06:13.963413  2642 net.cpp:122] Setting up ReLU20
I0924 21:06:13.963418  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.963419  2642 net.cpp:137] Memory required for data: 712295600
I0924 21:06:13.963423  2642 layer_factory.hpp:77] Creating layer Convolution22
I0924 21:06:13.963429  2642 net.cpp:84] Creating Layer Convolution22
I0924 21:06:13.963431  2642 net.cpp:406] Convolution22 <- Convolution21
I0924 21:06:13.963435  2642 net.cpp:380] Convolution22 -> Convolution22
I0924 21:06:13.964550  2642 net.cpp:122] Setting up Convolution22
I0924 21:06:13.964558  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.964561  2642 net.cpp:137] Memory required for data: 715572400
I0924 21:06:13.964565  2642 layer_factory.hpp:77] Creating layer BatchNorm22
I0924 21:06:13.964570  2642 net.cpp:84] Creating Layer BatchNorm22
I0924 21:06:13.964574  2642 net.cpp:406] BatchNorm22 <- Convolution22
I0924 21:06:13.964578  2642 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0924 21:06:13.964735  2642 net.cpp:122] Setting up BatchNorm22
I0924 21:06:13.964740  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.964742  2642 net.cpp:137] Memory required for data: 718849200
I0924 21:06:13.964746  2642 layer_factory.hpp:77] Creating layer Scale22
I0924 21:06:13.964751  2642 net.cpp:84] Creating Layer Scale22
I0924 21:06:13.964753  2642 net.cpp:406] Scale22 <- Convolution22
I0924 21:06:13.964757  2642 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0924 21:06:13.964790  2642 layer_factory.hpp:77] Creating layer Scale22
I0924 21:06:13.964881  2642 net.cpp:122] Setting up Scale22
I0924 21:06:13.964886  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.964889  2642 net.cpp:137] Memory required for data: 722126000
I0924 21:06:13.964891  2642 layer_factory.hpp:77] Creating layer Eltwise10
I0924 21:06:13.964895  2642 net.cpp:84] Creating Layer Eltwise10
I0924 21:06:13.964898  2642 net.cpp:406] Eltwise10 <- Convolution20
I0924 21:06:13.964900  2642 net.cpp:406] Eltwise10 <- Convolution22
I0924 21:06:13.964905  2642 net.cpp:380] Eltwise10 -> Eltwise10
I0924 21:06:13.964926  2642 net.cpp:122] Setting up Eltwise10
I0924 21:06:13.964931  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.964932  2642 net.cpp:137] Memory required for data: 725402800
I0924 21:06:13.964934  2642 layer_factory.hpp:77] Creating layer ReLU21
I0924 21:06:13.964938  2642 net.cpp:84] Creating Layer ReLU21
I0924 21:06:13.964941  2642 net.cpp:406] ReLU21 <- Eltwise10
I0924 21:06:13.964943  2642 net.cpp:367] ReLU21 -> Eltwise10 (in-place)
I0924 21:06:13.965068  2642 net.cpp:122] Setting up ReLU21
I0924 21:06:13.965075  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.965076  2642 net.cpp:137] Memory required for data: 728679600
I0924 21:06:13.965080  2642 layer_factory.hpp:77] Creating layer Eltwise10_ReLU21_0_split
I0924 21:06:13.965082  2642 net.cpp:84] Creating Layer Eltwise10_ReLU21_0_split
I0924 21:06:13.965085  2642 net.cpp:406] Eltwise10_ReLU21_0_split <- Eltwise10
I0924 21:06:13.965088  2642 net.cpp:380] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_0
I0924 21:06:13.965092  2642 net.cpp:380] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_1
I0924 21:06:13.965124  2642 net.cpp:122] Setting up Eltwise10_ReLU21_0_split
I0924 21:06:13.965128  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.965138  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.965140  2642 net.cpp:137] Memory required for data: 735233200
I0924 21:06:13.965143  2642 layer_factory.hpp:77] Creating layer Convolution23
I0924 21:06:13.965149  2642 net.cpp:84] Creating Layer Convolution23
I0924 21:06:13.965152  2642 net.cpp:406] Convolution23 <- Eltwise10_ReLU21_0_split_0
I0924 21:06:13.965157  2642 net.cpp:380] Convolution23 -> Convolution23
I0924 21:06:13.966581  2642 net.cpp:122] Setting up Convolution23
I0924 21:06:13.966590  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.966593  2642 net.cpp:137] Memory required for data: 738510000
I0924 21:06:13.966596  2642 layer_factory.hpp:77] Creating layer BatchNorm23
I0924 21:06:13.966603  2642 net.cpp:84] Creating Layer BatchNorm23
I0924 21:06:13.966604  2642 net.cpp:406] BatchNorm23 <- Convolution23
I0924 21:06:13.966609  2642 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0924 21:06:13.966766  2642 net.cpp:122] Setting up BatchNorm23
I0924 21:06:13.966771  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.966773  2642 net.cpp:137] Memory required for data: 741786800
I0924 21:06:13.966778  2642 layer_factory.hpp:77] Creating layer Scale23
I0924 21:06:13.986778  2642 net.cpp:84] Creating Layer Scale23
I0924 21:06:13.986783  2642 net.cpp:406] Scale23 <- Convolution23
I0924 21:06:13.986786  2642 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0924 21:06:13.986830  2642 layer_factory.hpp:77] Creating layer Scale23
I0924 21:06:13.986932  2642 net.cpp:122] Setting up Scale23
I0924 21:06:13.986937  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.986940  2642 net.cpp:137] Memory required for data: 745063600
I0924 21:06:13.986944  2642 layer_factory.hpp:77] Creating layer ReLU22
I0924 21:06:13.986949  2642 net.cpp:84] Creating Layer ReLU22
I0924 21:06:13.986951  2642 net.cpp:406] ReLU22 <- Convolution23
I0924 21:06:13.986954  2642 net.cpp:367] ReLU22 -> Convolution23 (in-place)
I0924 21:06:13.987098  2642 net.cpp:122] Setting up ReLU22
I0924 21:06:13.987104  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.987107  2642 net.cpp:137] Memory required for data: 748340400
I0924 21:06:13.987109  2642 layer_factory.hpp:77] Creating layer Convolution24
I0924 21:06:13.987118  2642 net.cpp:84] Creating Layer Convolution24
I0924 21:06:13.987120  2642 net.cpp:406] Convolution24 <- Convolution23
I0924 21:06:13.987124  2642 net.cpp:380] Convolution24 -> Convolution24
I0924 21:06:13.988415  2642 net.cpp:122] Setting up Convolution24
I0924 21:06:13.988435  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.988437  2642 net.cpp:137] Memory required for data: 751617200
I0924 21:06:13.988441  2642 layer_factory.hpp:77] Creating layer BatchNorm24
I0924 21:06:13.988447  2642 net.cpp:84] Creating Layer BatchNorm24
I0924 21:06:13.988451  2642 net.cpp:406] BatchNorm24 <- Convolution24
I0924 21:06:13.988454  2642 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0924 21:06:13.988627  2642 net.cpp:122] Setting up BatchNorm24
I0924 21:06:13.988632  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.988634  2642 net.cpp:137] Memory required for data: 754894000
I0924 21:06:13.988639  2642 layer_factory.hpp:77] Creating layer Scale24
I0924 21:06:13.988643  2642 net.cpp:84] Creating Layer Scale24
I0924 21:06:13.988646  2642 net.cpp:406] Scale24 <- Convolution24
I0924 21:06:13.988649  2642 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0924 21:06:13.988682  2642 layer_factory.hpp:77] Creating layer Scale24
I0924 21:06:13.988776  2642 net.cpp:122] Setting up Scale24
I0924 21:06:13.988780  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.988782  2642 net.cpp:137] Memory required for data: 758170800
I0924 21:06:13.988786  2642 layer_factory.hpp:77] Creating layer Eltwise11
I0924 21:06:13.988790  2642 net.cpp:84] Creating Layer Eltwise11
I0924 21:06:13.988793  2642 net.cpp:406] Eltwise11 <- Eltwise10_ReLU21_0_split_1
I0924 21:06:13.988796  2642 net.cpp:406] Eltwise11 <- Convolution24
I0924 21:06:13.988806  2642 net.cpp:380] Eltwise11 -> Eltwise11
I0924 21:06:13.988826  2642 net.cpp:122] Setting up Eltwise11
I0924 21:06:13.988829  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.988831  2642 net.cpp:137] Memory required for data: 761447600
I0924 21:06:13.988833  2642 layer_factory.hpp:77] Creating layer ReLU23
I0924 21:06:13.988837  2642 net.cpp:84] Creating Layer ReLU23
I0924 21:06:13.988839  2642 net.cpp:406] ReLU23 <- Eltwise11
I0924 21:06:13.988842  2642 net.cpp:367] ReLU23 -> Eltwise11 (in-place)
I0924 21:06:13.989001  2642 net.cpp:122] Setting up ReLU23
I0924 21:06:13.989007  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.989009  2642 net.cpp:137] Memory required for data: 764724400
I0924 21:06:13.989012  2642 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I0924 21:06:13.989017  2642 net.cpp:84] Creating Layer Eltwise11_ReLU23_0_split
I0924 21:06:13.989019  2642 net.cpp:406] Eltwise11_ReLU23_0_split <- Eltwise11
I0924 21:06:13.989022  2642 net.cpp:380] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I0924 21:06:13.989027  2642 net.cpp:380] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I0924 21:06:13.989060  2642 net.cpp:122] Setting up Eltwise11_ReLU23_0_split
I0924 21:06:13.989064  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.989068  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.989069  2642 net.cpp:137] Memory required for data: 771278000
I0924 21:06:13.989071  2642 layer_factory.hpp:77] Creating layer Convolution25
I0924 21:06:13.989078  2642 net.cpp:84] Creating Layer Convolution25
I0924 21:06:13.989080  2642 net.cpp:406] Convolution25 <- Eltwise11_ReLU23_0_split_0
I0924 21:06:13.989084  2642 net.cpp:380] Convolution25 -> Convolution25
I0924 21:06:13.990242  2642 net.cpp:122] Setting up Convolution25
I0924 21:06:13.990250  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.990252  2642 net.cpp:137] Memory required for data: 774554800
I0924 21:06:13.990257  2642 layer_factory.hpp:77] Creating layer BatchNorm25
I0924 21:06:13.990262  2642 net.cpp:84] Creating Layer BatchNorm25
I0924 21:06:13.990265  2642 net.cpp:406] BatchNorm25 <- Convolution25
I0924 21:06:13.990269  2642 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0924 21:06:13.990435  2642 net.cpp:122] Setting up BatchNorm25
I0924 21:06:13.990440  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.990443  2642 net.cpp:137] Memory required for data: 777831600
I0924 21:06:13.990447  2642 layer_factory.hpp:77] Creating layer Scale25
I0924 21:06:13.990451  2642 net.cpp:84] Creating Layer Scale25
I0924 21:06:13.990454  2642 net.cpp:406] Scale25 <- Convolution25
I0924 21:06:13.990458  2642 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0924 21:06:13.990491  2642 layer_factory.hpp:77] Creating layer Scale25
I0924 21:06:13.990584  2642 net.cpp:122] Setting up Scale25
I0924 21:06:13.990588  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.990591  2642 net.cpp:137] Memory required for data: 781108400
I0924 21:06:13.990594  2642 layer_factory.hpp:77] Creating layer ReLU24
I0924 21:06:13.990599  2642 net.cpp:84] Creating Layer ReLU24
I0924 21:06:13.990602  2642 net.cpp:406] ReLU24 <- Convolution25
I0924 21:06:13.990604  2642 net.cpp:367] ReLU24 -> Convolution25 (in-place)
I0924 21:06:13.991068  2642 net.cpp:122] Setting up ReLU24
I0924 21:06:13.991076  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.991078  2642 net.cpp:137] Memory required for data: 784385200
I0924 21:06:13.991081  2642 layer_factory.hpp:77] Creating layer Convolution26
I0924 21:06:13.991091  2642 net.cpp:84] Creating Layer Convolution26
I0924 21:06:13.991093  2642 net.cpp:406] Convolution26 <- Convolution25
I0924 21:06:13.991097  2642 net.cpp:380] Convolution26 -> Convolution26
I0924 21:06:13.992244  2642 net.cpp:122] Setting up Convolution26
I0924 21:06:13.992254  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.992255  2642 net.cpp:137] Memory required for data: 787662000
I0924 21:06:13.992260  2642 layer_factory.hpp:77] Creating layer BatchNorm26
I0924 21:06:13.992272  2642 net.cpp:84] Creating Layer BatchNorm26
I0924 21:06:13.992275  2642 net.cpp:406] BatchNorm26 <- Convolution26
I0924 21:06:13.992278  2642 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0924 21:06:13.992444  2642 net.cpp:122] Setting up BatchNorm26
I0924 21:06:13.992447  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.992449  2642 net.cpp:137] Memory required for data: 790938800
I0924 21:06:13.992455  2642 layer_factory.hpp:77] Creating layer Scale26
I0924 21:06:13.992460  2642 net.cpp:84] Creating Layer Scale26
I0924 21:06:13.992462  2642 net.cpp:406] Scale26 <- Convolution26
I0924 21:06:13.992465  2642 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0924 21:06:13.992498  2642 layer_factory.hpp:77] Creating layer Scale26
I0924 21:06:13.992591  2642 net.cpp:122] Setting up Scale26
I0924 21:06:13.992596  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.992599  2642 net.cpp:137] Memory required for data: 794215600
I0924 21:06:13.992602  2642 layer_factory.hpp:77] Creating layer Eltwise12
I0924 21:06:13.992606  2642 net.cpp:84] Creating Layer Eltwise12
I0924 21:06:13.992609  2642 net.cpp:406] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I0924 21:06:13.992612  2642 net.cpp:406] Eltwise12 <- Convolution26
I0924 21:06:13.992615  2642 net.cpp:380] Eltwise12 -> Eltwise12
I0924 21:06:13.992632  2642 net.cpp:122] Setting up Eltwise12
I0924 21:06:13.992636  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.992638  2642 net.cpp:137] Memory required for data: 797492400
I0924 21:06:13.992640  2642 layer_factory.hpp:77] Creating layer ReLU25
I0924 21:06:13.992653  2642 net.cpp:84] Creating Layer ReLU25
I0924 21:06:13.992656  2642 net.cpp:406] ReLU25 <- Eltwise12
I0924 21:06:13.992660  2642 net.cpp:367] ReLU25 -> Eltwise12 (in-place)
I0924 21:06:13.992789  2642 net.cpp:122] Setting up ReLU25
I0924 21:06:13.992795  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.992797  2642 net.cpp:137] Memory required for data: 800769200
I0924 21:06:13.992800  2642 layer_factory.hpp:77] Creating layer Eltwise12_ReLU25_0_split
I0924 21:06:13.992805  2642 net.cpp:84] Creating Layer Eltwise12_ReLU25_0_split
I0924 21:06:13.992807  2642 net.cpp:406] Eltwise12_ReLU25_0_split <- Eltwise12
I0924 21:06:13.992810  2642 net.cpp:380] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_0
I0924 21:06:13.992815  2642 net.cpp:380] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_1
I0924 21:06:13.992849  2642 net.cpp:122] Setting up Eltwise12_ReLU25_0_split
I0924 21:06:13.992853  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.992856  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.992857  2642 net.cpp:137] Memory required for data: 807322800
I0924 21:06:13.992861  2642 layer_factory.hpp:77] Creating layer Convolution27
I0924 21:06:13.992866  2642 net.cpp:84] Creating Layer Convolution27
I0924 21:06:13.992869  2642 net.cpp:406] Convolution27 <- Eltwise12_ReLU25_0_split_0
I0924 21:06:13.992873  2642 net.cpp:380] Convolution27 -> Convolution27
I0924 21:06:13.994030  2642 net.cpp:122] Setting up Convolution27
I0924 21:06:13.994040  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.994041  2642 net.cpp:137] Memory required for data: 810599600
I0924 21:06:13.994045  2642 layer_factory.hpp:77] Creating layer BatchNorm27
I0924 21:06:13.994051  2642 net.cpp:84] Creating Layer BatchNorm27
I0924 21:06:13.994053  2642 net.cpp:406] BatchNorm27 <- Convolution27
I0924 21:06:13.994057  2642 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0924 21:06:13.994218  2642 net.cpp:122] Setting up BatchNorm27
I0924 21:06:13.994223  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.994225  2642 net.cpp:137] Memory required for data: 813876400
I0924 21:06:13.994230  2642 layer_factory.hpp:77] Creating layer Scale27
I0924 21:06:13.994233  2642 net.cpp:84] Creating Layer Scale27
I0924 21:06:13.994236  2642 net.cpp:406] Scale27 <- Convolution27
I0924 21:06:13.994240  2642 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0924 21:06:13.994280  2642 layer_factory.hpp:77] Creating layer Scale27
I0924 21:06:13.994372  2642 net.cpp:122] Setting up Scale27
I0924 21:06:13.994377  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.994379  2642 net.cpp:137] Memory required for data: 817153200
I0924 21:06:13.994384  2642 layer_factory.hpp:77] Creating layer ReLU26
I0924 21:06:13.994386  2642 net.cpp:84] Creating Layer ReLU26
I0924 21:06:13.994388  2642 net.cpp:406] ReLU26 <- Convolution27
I0924 21:06:13.994391  2642 net.cpp:367] ReLU26 -> Convolution27 (in-place)
I0924 21:06:13.994520  2642 net.cpp:122] Setting up ReLU26
I0924 21:06:13.994526  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.994529  2642 net.cpp:137] Memory required for data: 820430000
I0924 21:06:13.994531  2642 layer_factory.hpp:77] Creating layer Convolution28
I0924 21:06:13.994537  2642 net.cpp:84] Creating Layer Convolution28
I0924 21:06:13.994540  2642 net.cpp:406] Convolution28 <- Convolution27
I0924 21:06:13.994544  2642 net.cpp:380] Convolution28 -> Convolution28
I0924 21:06:13.995976  2642 net.cpp:122] Setting up Convolution28
I0924 21:06:13.995985  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.995987  2642 net.cpp:137] Memory required for data: 823706800
I0924 21:06:13.995992  2642 layer_factory.hpp:77] Creating layer BatchNorm28
I0924 21:06:13.995997  2642 net.cpp:84] Creating Layer BatchNorm28
I0924 21:06:13.996001  2642 net.cpp:406] BatchNorm28 <- Convolution28
I0924 21:06:13.996004  2642 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0924 21:06:13.996170  2642 net.cpp:122] Setting up BatchNorm28
I0924 21:06:13.996176  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.996177  2642 net.cpp:137] Memory required for data: 826983600
I0924 21:06:13.996182  2642 layer_factory.hpp:77] Creating layer Scale28
I0924 21:06:13.996186  2642 net.cpp:84] Creating Layer Scale28
I0924 21:06:13.996189  2642 net.cpp:406] Scale28 <- Convolution28
I0924 21:06:13.996192  2642 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0924 21:06:13.996225  2642 layer_factory.hpp:77] Creating layer Scale28
I0924 21:06:13.996318  2642 net.cpp:122] Setting up Scale28
I0924 21:06:13.996322  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.996325  2642 net.cpp:137] Memory required for data: 830260400
I0924 21:06:13.996328  2642 layer_factory.hpp:77] Creating layer Eltwise13
I0924 21:06:13.996332  2642 net.cpp:84] Creating Layer Eltwise13
I0924 21:06:13.996335  2642 net.cpp:406] Eltwise13 <- Eltwise12_ReLU25_0_split_1
I0924 21:06:13.996337  2642 net.cpp:406] Eltwise13 <- Convolution28
I0924 21:06:13.996341  2642 net.cpp:380] Eltwise13 -> Eltwise13
I0924 21:06:13.996357  2642 net.cpp:122] Setting up Eltwise13
I0924 21:06:13.996362  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.996364  2642 net.cpp:137] Memory required for data: 833537200
I0924 21:06:13.996366  2642 layer_factory.hpp:77] Creating layer ReLU27
I0924 21:06:13.996369  2642 net.cpp:84] Creating Layer ReLU27
I0924 21:06:13.996371  2642 net.cpp:406] ReLU27 <- Eltwise13
I0924 21:06:13.996374  2642 net.cpp:367] ReLU27 -> Eltwise13 (in-place)
I0924 21:06:13.996505  2642 net.cpp:122] Setting up ReLU27
I0924 21:06:13.996511  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.996513  2642 net.cpp:137] Memory required for data: 836814000
I0924 21:06:13.996516  2642 layer_factory.hpp:77] Creating layer Eltwise13_ReLU27_0_split
I0924 21:06:13.996520  2642 net.cpp:84] Creating Layer Eltwise13_ReLU27_0_split
I0924 21:06:13.996522  2642 net.cpp:406] Eltwise13_ReLU27_0_split <- Eltwise13
I0924 21:06:13.996526  2642 net.cpp:380] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_0
I0924 21:06:13.996531  2642 net.cpp:380] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_1
I0924 21:06:13.996564  2642 net.cpp:122] Setting up Eltwise13_ReLU27_0_split
I0924 21:06:13.996567  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.996570  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.996578  2642 net.cpp:137] Memory required for data: 843367600
I0924 21:06:13.996580  2642 layer_factory.hpp:77] Creating layer Convolution29
I0924 21:06:13.996587  2642 net.cpp:84] Creating Layer Convolution29
I0924 21:06:13.996590  2642 net.cpp:406] Convolution29 <- Eltwise13_ReLU27_0_split_0
I0924 21:06:13.996595  2642 net.cpp:380] Convolution29 -> Convolution29
I0924 21:06:13.997762  2642 net.cpp:122] Setting up Convolution29
I0924 21:06:13.997771  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:13.997773  2642 net.cpp:137] Memory required for data: 846644400
I0924 21:06:13.997777  2642 layer_factory.hpp:77] Creating layer BatchNorm29
I0924 21:06:13.997783  2642 net.cpp:84] Creating Layer BatchNorm29
I0924 21:06:13.997786  2642 net.cpp:406] BatchNorm29 <- Convolution29
I0924 21:06:13.997789  2642 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0924 21:06:13.997953  2642 net.cpp:122] Setting up BatchNorm29
I0924 21:06:13.997958  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.017558  2642 net.cpp:137] Memory required for data: 849921200
I0924 21:06:14.017565  2642 layer_factory.hpp:77] Creating layer Scale29
I0924 21:06:14.017570  2642 net.cpp:84] Creating Layer Scale29
I0924 21:06:14.017573  2642 net.cpp:406] Scale29 <- Convolution29
I0924 21:06:14.017577  2642 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0924 21:06:14.017621  2642 layer_factory.hpp:77] Creating layer Scale29
I0924 21:06:14.017724  2642 net.cpp:122] Setting up Scale29
I0924 21:06:14.017729  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.017731  2642 net.cpp:137] Memory required for data: 853198000
I0924 21:06:14.017735  2642 layer_factory.hpp:77] Creating layer ReLU28
I0924 21:06:14.017740  2642 net.cpp:84] Creating Layer ReLU28
I0924 21:06:14.017742  2642 net.cpp:406] ReLU28 <- Convolution29
I0924 21:06:14.017745  2642 net.cpp:367] ReLU28 -> Convolution29 (in-place)
I0924 21:06:14.017889  2642 net.cpp:122] Setting up ReLU28
I0924 21:06:14.017896  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.017899  2642 net.cpp:137] Memory required for data: 856474800
I0924 21:06:14.017901  2642 layer_factory.hpp:77] Creating layer Convolution30
I0924 21:06:14.017909  2642 net.cpp:84] Creating Layer Convolution30
I0924 21:06:14.017911  2642 net.cpp:406] Convolution30 <- Convolution29
I0924 21:06:14.017916  2642 net.cpp:380] Convolution30 -> Convolution30
I0924 21:06:14.019176  2642 net.cpp:122] Setting up Convolution30
I0924 21:06:14.019186  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.019189  2642 net.cpp:137] Memory required for data: 859751600
I0924 21:06:14.019194  2642 layer_factory.hpp:77] Creating layer BatchNorm30
I0924 21:06:14.019199  2642 net.cpp:84] Creating Layer BatchNorm30
I0924 21:06:14.019201  2642 net.cpp:406] BatchNorm30 <- Convolution30
I0924 21:06:14.019207  2642 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0924 21:06:14.019448  2642 net.cpp:122] Setting up BatchNorm30
I0924 21:06:14.019453  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.019454  2642 net.cpp:137] Memory required for data: 863028400
I0924 21:06:14.019459  2642 layer_factory.hpp:77] Creating layer Scale30
I0924 21:06:14.019464  2642 net.cpp:84] Creating Layer Scale30
I0924 21:06:14.019465  2642 net.cpp:406] Scale30 <- Convolution30
I0924 21:06:14.019469  2642 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0924 21:06:14.019501  2642 layer_factory.hpp:77] Creating layer Scale30
I0924 21:06:14.019593  2642 net.cpp:122] Setting up Scale30
I0924 21:06:14.019598  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.019599  2642 net.cpp:137] Memory required for data: 866305200
I0924 21:06:14.019603  2642 layer_factory.hpp:77] Creating layer Eltwise14
I0924 21:06:14.019608  2642 net.cpp:84] Creating Layer Eltwise14
I0924 21:06:14.019610  2642 net.cpp:406] Eltwise14 <- Eltwise13_ReLU27_0_split_1
I0924 21:06:14.019613  2642 net.cpp:406] Eltwise14 <- Convolution30
I0924 21:06:14.019618  2642 net.cpp:380] Eltwise14 -> Eltwise14
I0924 21:06:14.019642  2642 net.cpp:122] Setting up Eltwise14
I0924 21:06:14.019646  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.019649  2642 net.cpp:137] Memory required for data: 869582000
I0924 21:06:14.019650  2642 layer_factory.hpp:77] Creating layer ReLU29
I0924 21:06:14.019654  2642 net.cpp:84] Creating Layer ReLU29
I0924 21:06:14.019656  2642 net.cpp:406] ReLU29 <- Eltwise14
I0924 21:06:14.019659  2642 net.cpp:367] ReLU29 -> Eltwise14 (in-place)
I0924 21:06:14.019788  2642 net.cpp:122] Setting up ReLU29
I0924 21:06:14.019793  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.019795  2642 net.cpp:137] Memory required for data: 872858800
I0924 21:06:14.019798  2642 layer_factory.hpp:77] Creating layer Eltwise14_ReLU29_0_split
I0924 21:06:14.019803  2642 net.cpp:84] Creating Layer Eltwise14_ReLU29_0_split
I0924 21:06:14.019805  2642 net.cpp:406] Eltwise14_ReLU29_0_split <- Eltwise14
I0924 21:06:14.019809  2642 net.cpp:380] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_0
I0924 21:06:14.019812  2642 net.cpp:380] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_1
I0924 21:06:14.019846  2642 net.cpp:122] Setting up Eltwise14_ReLU29_0_split
I0924 21:06:14.019850  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.019852  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.019855  2642 net.cpp:137] Memory required for data: 879412400
I0924 21:06:14.019856  2642 layer_factory.hpp:77] Creating layer Convolution31
I0924 21:06:14.019863  2642 net.cpp:84] Creating Layer Convolution31
I0924 21:06:14.019865  2642 net.cpp:406] Convolution31 <- Eltwise14_ReLU29_0_split_0
I0924 21:06:14.019871  2642 net.cpp:380] Convolution31 -> Convolution31
I0924 21:06:14.021085  2642 net.cpp:122] Setting up Convolution31
I0924 21:06:14.021095  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.021096  2642 net.cpp:137] Memory required for data: 882689200
I0924 21:06:14.021101  2642 layer_factory.hpp:77] Creating layer BatchNorm31
I0924 21:06:14.021107  2642 net.cpp:84] Creating Layer BatchNorm31
I0924 21:06:14.021111  2642 net.cpp:406] BatchNorm31 <- Convolution31
I0924 21:06:14.021113  2642 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0924 21:06:14.021280  2642 net.cpp:122] Setting up BatchNorm31
I0924 21:06:14.021283  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.021286  2642 net.cpp:137] Memory required for data: 885966000
I0924 21:06:14.021291  2642 layer_factory.hpp:77] Creating layer Scale31
I0924 21:06:14.021296  2642 net.cpp:84] Creating Layer Scale31
I0924 21:06:14.021298  2642 net.cpp:406] Scale31 <- Convolution31
I0924 21:06:14.021301  2642 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0924 21:06:14.021337  2642 layer_factory.hpp:77] Creating layer Scale31
I0924 21:06:14.021432  2642 net.cpp:122] Setting up Scale31
I0924 21:06:14.021436  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.021438  2642 net.cpp:137] Memory required for data: 889242800
I0924 21:06:14.021442  2642 layer_factory.hpp:77] Creating layer ReLU30
I0924 21:06:14.021447  2642 net.cpp:84] Creating Layer ReLU30
I0924 21:06:14.021450  2642 net.cpp:406] ReLU30 <- Convolution31
I0924 21:06:14.021452  2642 net.cpp:367] ReLU30 -> Convolution31 (in-place)
I0924 21:06:14.021914  2642 net.cpp:122] Setting up ReLU30
I0924 21:06:14.021924  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.021926  2642 net.cpp:137] Memory required for data: 892519600
I0924 21:06:14.021929  2642 layer_factory.hpp:77] Creating layer Convolution32
I0924 21:06:14.021935  2642 net.cpp:84] Creating Layer Convolution32
I0924 21:06:14.021939  2642 net.cpp:406] Convolution32 <- Convolution31
I0924 21:06:14.021944  2642 net.cpp:380] Convolution32 -> Convolution32
I0924 21:06:14.023093  2642 net.cpp:122] Setting up Convolution32
I0924 21:06:14.023102  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.023104  2642 net.cpp:137] Memory required for data: 895796400
I0924 21:06:14.023109  2642 layer_factory.hpp:77] Creating layer BatchNorm32
I0924 21:06:14.023123  2642 net.cpp:84] Creating Layer BatchNorm32
I0924 21:06:14.023125  2642 net.cpp:406] BatchNorm32 <- Convolution32
I0924 21:06:14.023129  2642 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I0924 21:06:14.023298  2642 net.cpp:122] Setting up BatchNorm32
I0924 21:06:14.023303  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.023304  2642 net.cpp:137] Memory required for data: 899073200
I0924 21:06:14.023309  2642 layer_factory.hpp:77] Creating layer Scale32
I0924 21:06:14.023315  2642 net.cpp:84] Creating Layer Scale32
I0924 21:06:14.023319  2642 net.cpp:406] Scale32 <- Convolution32
I0924 21:06:14.023322  2642 net.cpp:367] Scale32 -> Convolution32 (in-place)
I0924 21:06:14.023356  2642 layer_factory.hpp:77] Creating layer Scale32
I0924 21:06:14.023452  2642 net.cpp:122] Setting up Scale32
I0924 21:06:14.023458  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.023459  2642 net.cpp:137] Memory required for data: 902350000
I0924 21:06:14.023463  2642 layer_factory.hpp:77] Creating layer Eltwise15
I0924 21:06:14.023468  2642 net.cpp:84] Creating Layer Eltwise15
I0924 21:06:14.023471  2642 net.cpp:406] Eltwise15 <- Eltwise14_ReLU29_0_split_1
I0924 21:06:14.023474  2642 net.cpp:406] Eltwise15 <- Convolution32
I0924 21:06:14.023478  2642 net.cpp:380] Eltwise15 -> Eltwise15
I0924 21:06:14.023494  2642 net.cpp:122] Setting up Eltwise15
I0924 21:06:14.023499  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.023500  2642 net.cpp:137] Memory required for data: 905626800
I0924 21:06:14.023502  2642 layer_factory.hpp:77] Creating layer ReLU31
I0924 21:06:14.023505  2642 net.cpp:84] Creating Layer ReLU31
I0924 21:06:14.023509  2642 net.cpp:406] ReLU31 <- Eltwise15
I0924 21:06:14.023511  2642 net.cpp:367] ReLU31 -> Eltwise15 (in-place)
I0924 21:06:14.023640  2642 net.cpp:122] Setting up ReLU31
I0924 21:06:14.023646  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.023648  2642 net.cpp:137] Memory required for data: 908903600
I0924 21:06:14.023650  2642 layer_factory.hpp:77] Creating layer Eltwise15_ReLU31_0_split
I0924 21:06:14.023654  2642 net.cpp:84] Creating Layer Eltwise15_ReLU31_0_split
I0924 21:06:14.023656  2642 net.cpp:406] Eltwise15_ReLU31_0_split <- Eltwise15
I0924 21:06:14.023660  2642 net.cpp:380] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_0
I0924 21:06:14.023665  2642 net.cpp:380] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_1
I0924 21:06:14.023699  2642 net.cpp:122] Setting up Eltwise15_ReLU31_0_split
I0924 21:06:14.023703  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.023706  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.023708  2642 net.cpp:137] Memory required for data: 915457200
I0924 21:06:14.023710  2642 layer_factory.hpp:77] Creating layer Convolution33
I0924 21:06:14.023717  2642 net.cpp:84] Creating Layer Convolution33
I0924 21:06:14.023720  2642 net.cpp:406] Convolution33 <- Eltwise15_ReLU31_0_split_0
I0924 21:06:14.023723  2642 net.cpp:380] Convolution33 -> Convolution33
I0924 21:06:14.024873  2642 net.cpp:122] Setting up Convolution33
I0924 21:06:14.024883  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.024884  2642 net.cpp:137] Memory required for data: 918734000
I0924 21:06:14.024889  2642 layer_factory.hpp:77] Creating layer BatchNorm33
I0924 21:06:14.024895  2642 net.cpp:84] Creating Layer BatchNorm33
I0924 21:06:14.024899  2642 net.cpp:406] BatchNorm33 <- Convolution33
I0924 21:06:14.024902  2642 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I0924 21:06:14.025096  2642 net.cpp:122] Setting up BatchNorm33
I0924 21:06:14.025101  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.025104  2642 net.cpp:137] Memory required for data: 922010800
I0924 21:06:14.025108  2642 layer_factory.hpp:77] Creating layer Scale33
I0924 21:06:14.025113  2642 net.cpp:84] Creating Layer Scale33
I0924 21:06:14.025116  2642 net.cpp:406] Scale33 <- Convolution33
I0924 21:06:14.025120  2642 net.cpp:367] Scale33 -> Convolution33 (in-place)
I0924 21:06:14.025163  2642 layer_factory.hpp:77] Creating layer Scale33
I0924 21:06:14.025260  2642 net.cpp:122] Setting up Scale33
I0924 21:06:14.025265  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.025267  2642 net.cpp:137] Memory required for data: 925287600
I0924 21:06:14.025271  2642 layer_factory.hpp:77] Creating layer ReLU32
I0924 21:06:14.025274  2642 net.cpp:84] Creating Layer ReLU32
I0924 21:06:14.025277  2642 net.cpp:406] ReLU32 <- Convolution33
I0924 21:06:14.025281  2642 net.cpp:367] ReLU32 -> Convolution33 (in-place)
I0924 21:06:14.025413  2642 net.cpp:122] Setting up ReLU32
I0924 21:06:14.025418  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.025420  2642 net.cpp:137] Memory required for data: 928564400
I0924 21:06:14.025423  2642 layer_factory.hpp:77] Creating layer Convolution34
I0924 21:06:14.025430  2642 net.cpp:84] Creating Layer Convolution34
I0924 21:06:14.025434  2642 net.cpp:406] Convolution34 <- Convolution33
I0924 21:06:14.025437  2642 net.cpp:380] Convolution34 -> Convolution34
I0924 21:06:14.026595  2642 net.cpp:122] Setting up Convolution34
I0924 21:06:14.026604  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.026607  2642 net.cpp:137] Memory required for data: 931841200
I0924 21:06:14.026612  2642 layer_factory.hpp:77] Creating layer BatchNorm34
I0924 21:06:14.026617  2642 net.cpp:84] Creating Layer BatchNorm34
I0924 21:06:14.026619  2642 net.cpp:406] BatchNorm34 <- Convolution34
I0924 21:06:14.026623  2642 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I0924 21:06:14.026792  2642 net.cpp:122] Setting up BatchNorm34
I0924 21:06:14.026795  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.026798  2642 net.cpp:137] Memory required for data: 935118000
I0924 21:06:14.026803  2642 layer_factory.hpp:77] Creating layer Scale34
I0924 21:06:14.026806  2642 net.cpp:84] Creating Layer Scale34
I0924 21:06:14.026809  2642 net.cpp:406] Scale34 <- Convolution34
I0924 21:06:14.026813  2642 net.cpp:367] Scale34 -> Convolution34 (in-place)
I0924 21:06:14.026846  2642 layer_factory.hpp:77] Creating layer Scale34
I0924 21:06:14.026945  2642 net.cpp:122] Setting up Scale34
I0924 21:06:14.026949  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.026952  2642 net.cpp:137] Memory required for data: 938394800
I0924 21:06:14.026955  2642 layer_factory.hpp:77] Creating layer Eltwise16
I0924 21:06:14.026960  2642 net.cpp:84] Creating Layer Eltwise16
I0924 21:06:14.026963  2642 net.cpp:406] Eltwise16 <- Eltwise15_ReLU31_0_split_1
I0924 21:06:14.026967  2642 net.cpp:406] Eltwise16 <- Convolution34
I0924 21:06:14.026969  2642 net.cpp:380] Eltwise16 -> Eltwise16
I0924 21:06:14.026985  2642 net.cpp:122] Setting up Eltwise16
I0924 21:06:14.026989  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.026991  2642 net.cpp:137] Memory required for data: 941671600
I0924 21:06:14.026993  2642 layer_factory.hpp:77] Creating layer ReLU33
I0924 21:06:14.026998  2642 net.cpp:84] Creating Layer ReLU33
I0924 21:06:14.027000  2642 net.cpp:406] ReLU33 <- Eltwise16
I0924 21:06:14.027004  2642 net.cpp:367] ReLU33 -> Eltwise16 (in-place)
I0924 21:06:14.027135  2642 net.cpp:122] Setting up ReLU33
I0924 21:06:14.027142  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.027143  2642 net.cpp:137] Memory required for data: 944948400
I0924 21:06:14.027145  2642 layer_factory.hpp:77] Creating layer Eltwise16_ReLU33_0_split
I0924 21:06:14.027149  2642 net.cpp:84] Creating Layer Eltwise16_ReLU33_0_split
I0924 21:06:14.027151  2642 net.cpp:406] Eltwise16_ReLU33_0_split <- Eltwise16
I0924 21:06:14.027155  2642 net.cpp:380] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_0
I0924 21:06:14.027160  2642 net.cpp:380] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_1
I0924 21:06:14.027195  2642 net.cpp:122] Setting up Eltwise16_ReLU33_0_split
I0924 21:06:14.027199  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.027204  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.027205  2642 net.cpp:137] Memory required for data: 951502000
I0924 21:06:14.027214  2642 layer_factory.hpp:77] Creating layer Convolution35
I0924 21:06:14.027220  2642 net.cpp:84] Creating Layer Convolution35
I0924 21:06:14.027223  2642 net.cpp:406] Convolution35 <- Eltwise16_ReLU33_0_split_0
I0924 21:06:14.027227  2642 net.cpp:380] Convolution35 -> Convolution35
I0924 21:06:14.028385  2642 net.cpp:122] Setting up Convolution35
I0924 21:06:14.028394  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.028398  2642 net.cpp:137] Memory required for data: 954778800
I0924 21:06:14.028401  2642 layer_factory.hpp:77] Creating layer BatchNorm35
I0924 21:06:14.028406  2642 net.cpp:84] Creating Layer BatchNorm35
I0924 21:06:14.028409  2642 net.cpp:406] BatchNorm35 <- Convolution35
I0924 21:06:14.028414  2642 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I0924 21:06:14.028585  2642 net.cpp:122] Setting up BatchNorm35
I0924 21:06:14.048498  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.048502  2642 net.cpp:137] Memory required for data: 958055600
I0924 21:06:14.048507  2642 layer_factory.hpp:77] Creating layer Scale35
I0924 21:06:14.048512  2642 net.cpp:84] Creating Layer Scale35
I0924 21:06:14.048516  2642 net.cpp:406] Scale35 <- Convolution35
I0924 21:06:14.048519  2642 net.cpp:367] Scale35 -> Convolution35 (in-place)
I0924 21:06:14.048563  2642 layer_factory.hpp:77] Creating layer Scale35
I0924 21:06:14.048669  2642 net.cpp:122] Setting up Scale35
I0924 21:06:14.048674  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.048676  2642 net.cpp:137] Memory required for data: 961332400
I0924 21:06:14.048681  2642 layer_factory.hpp:77] Creating layer ReLU34
I0924 21:06:14.048684  2642 net.cpp:84] Creating Layer ReLU34
I0924 21:06:14.048687  2642 net.cpp:406] ReLU34 <- Convolution35
I0924 21:06:14.048691  2642 net.cpp:367] ReLU34 -> Convolution35 (in-place)
I0924 21:06:14.048835  2642 net.cpp:122] Setting up ReLU34
I0924 21:06:14.048840  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.048843  2642 net.cpp:137] Memory required for data: 964609200
I0924 21:06:14.048846  2642 layer_factory.hpp:77] Creating layer Convolution36
I0924 21:06:14.048853  2642 net.cpp:84] Creating Layer Convolution36
I0924 21:06:14.048856  2642 net.cpp:406] Convolution36 <- Convolution35
I0924 21:06:14.048861  2642 net.cpp:380] Convolution36 -> Convolution36
I0924 21:06:14.050132  2642 net.cpp:122] Setting up Convolution36
I0924 21:06:14.050139  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.050143  2642 net.cpp:137] Memory required for data: 967886000
I0924 21:06:14.050148  2642 layer_factory.hpp:77] Creating layer BatchNorm36
I0924 21:06:14.050153  2642 net.cpp:84] Creating Layer BatchNorm36
I0924 21:06:14.050155  2642 net.cpp:406] BatchNorm36 <- Convolution36
I0924 21:06:14.050159  2642 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I0924 21:06:14.050334  2642 net.cpp:122] Setting up BatchNorm36
I0924 21:06:14.050339  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.050341  2642 net.cpp:137] Memory required for data: 971162800
I0924 21:06:14.050346  2642 layer_factory.hpp:77] Creating layer Scale36
I0924 21:06:14.050350  2642 net.cpp:84] Creating Layer Scale36
I0924 21:06:14.050354  2642 net.cpp:406] Scale36 <- Convolution36
I0924 21:06:14.050357  2642 net.cpp:367] Scale36 -> Convolution36 (in-place)
I0924 21:06:14.050395  2642 layer_factory.hpp:77] Creating layer Scale36
I0924 21:06:14.050547  2642 net.cpp:122] Setting up Scale36
I0924 21:06:14.050561  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.050564  2642 net.cpp:137] Memory required for data: 974439600
I0924 21:06:14.050567  2642 layer_factory.hpp:77] Creating layer Eltwise17
I0924 21:06:14.050572  2642 net.cpp:84] Creating Layer Eltwise17
I0924 21:06:14.050575  2642 net.cpp:406] Eltwise17 <- Eltwise16_ReLU33_0_split_1
I0924 21:06:14.050578  2642 net.cpp:406] Eltwise17 <- Convolution36
I0924 21:06:14.050581  2642 net.cpp:380] Eltwise17 -> Eltwise17
I0924 21:06:14.050599  2642 net.cpp:122] Setting up Eltwise17
I0924 21:06:14.050611  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.050612  2642 net.cpp:137] Memory required for data: 977716400
I0924 21:06:14.050616  2642 layer_factory.hpp:77] Creating layer ReLU35
I0924 21:06:14.050618  2642 net.cpp:84] Creating Layer ReLU35
I0924 21:06:14.050621  2642 net.cpp:406] ReLU35 <- Eltwise17
I0924 21:06:14.050624  2642 net.cpp:367] ReLU35 -> Eltwise17 (in-place)
I0924 21:06:14.050781  2642 net.cpp:122] Setting up ReLU35
I0924 21:06:14.050787  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.050789  2642 net.cpp:137] Memory required for data: 980993200
I0924 21:06:14.050791  2642 layer_factory.hpp:77] Creating layer Eltwise17_ReLU35_0_split
I0924 21:06:14.050796  2642 net.cpp:84] Creating Layer Eltwise17_ReLU35_0_split
I0924 21:06:14.050797  2642 net.cpp:406] Eltwise17_ReLU35_0_split <- Eltwise17
I0924 21:06:14.050802  2642 net.cpp:380] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_0
I0924 21:06:14.050806  2642 net.cpp:380] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_1
I0924 21:06:14.050840  2642 net.cpp:122] Setting up Eltwise17_ReLU35_0_split
I0924 21:06:14.050844  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.050846  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.050848  2642 net.cpp:137] Memory required for data: 987546800
I0924 21:06:14.050850  2642 layer_factory.hpp:77] Creating layer Convolution37
I0924 21:06:14.050858  2642 net.cpp:84] Creating Layer Convolution37
I0924 21:06:14.050860  2642 net.cpp:406] Convolution37 <- Eltwise17_ReLU35_0_split_0
I0924 21:06:14.050864  2642 net.cpp:380] Convolution37 -> Convolution37
I0924 21:06:14.052202  2642 net.cpp:122] Setting up Convolution37
I0924 21:06:14.052211  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.052214  2642 net.cpp:137] Memory required for data: 990823600
I0924 21:06:14.052218  2642 layer_factory.hpp:77] Creating layer BatchNorm37
I0924 21:06:14.052224  2642 net.cpp:84] Creating Layer BatchNorm37
I0924 21:06:14.052227  2642 net.cpp:406] BatchNorm37 <- Convolution37
I0924 21:06:14.052230  2642 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I0924 21:06:14.052877  2642 net.cpp:122] Setting up BatchNorm37
I0924 21:06:14.052886  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.052888  2642 net.cpp:137] Memory required for data: 994100400
I0924 21:06:14.052932  2642 layer_factory.hpp:77] Creating layer Scale37
I0924 21:06:14.052938  2642 net.cpp:84] Creating Layer Scale37
I0924 21:06:14.052942  2642 net.cpp:406] Scale37 <- Convolution37
I0924 21:06:14.052945  2642 net.cpp:367] Scale37 -> Convolution37 (in-place)
I0924 21:06:14.052984  2642 layer_factory.hpp:77] Creating layer Scale37
I0924 21:06:14.053057  2642 net.cpp:122] Setting up Scale37
I0924 21:06:14.053061  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.053063  2642 net.cpp:137] Memory required for data: 997377200
I0924 21:06:14.053067  2642 layer_factory.hpp:77] Creating layer ReLU36
I0924 21:06:14.053071  2642 net.cpp:84] Creating Layer ReLU36
I0924 21:06:14.053073  2642 net.cpp:406] ReLU36 <- Convolution37
I0924 21:06:14.053076  2642 net.cpp:367] ReLU36 -> Convolution37 (in-place)
I0924 21:06:14.053548  2642 net.cpp:122] Setting up ReLU36
I0924 21:06:14.053556  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.053558  2642 net.cpp:137] Memory required for data: 1000654000
I0924 21:06:14.053561  2642 layer_factory.hpp:77] Creating layer Convolution38
I0924 21:06:14.053568  2642 net.cpp:84] Creating Layer Convolution38
I0924 21:06:14.053571  2642 net.cpp:406] Convolution38 <- Convolution37
I0924 21:06:14.053577  2642 net.cpp:380] Convolution38 -> Convolution38
I0924 21:06:14.055003  2642 net.cpp:122] Setting up Convolution38
I0924 21:06:14.055012  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.055014  2642 net.cpp:137] Memory required for data: 1003930800
I0924 21:06:14.055019  2642 layer_factory.hpp:77] Creating layer BatchNorm38
I0924 21:06:14.055024  2642 net.cpp:84] Creating Layer BatchNorm38
I0924 21:06:14.055034  2642 net.cpp:406] BatchNorm38 <- Convolution38
I0924 21:06:14.055039  2642 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I0924 21:06:14.055166  2642 net.cpp:122] Setting up BatchNorm38
I0924 21:06:14.055171  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.055173  2642 net.cpp:137] Memory required for data: 1007207600
I0924 21:06:14.055178  2642 layer_factory.hpp:77] Creating layer Scale38
I0924 21:06:14.055182  2642 net.cpp:84] Creating Layer Scale38
I0924 21:06:14.055186  2642 net.cpp:406] Scale38 <- Convolution38
I0924 21:06:14.055188  2642 net.cpp:367] Scale38 -> Convolution38 (in-place)
I0924 21:06:14.055215  2642 layer_factory.hpp:77] Creating layer Scale38
I0924 21:06:14.055286  2642 net.cpp:122] Setting up Scale38
I0924 21:06:14.055291  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.055294  2642 net.cpp:137] Memory required for data: 1010484400
I0924 21:06:14.055297  2642 layer_factory.hpp:77] Creating layer Eltwise18
I0924 21:06:14.055301  2642 net.cpp:84] Creating Layer Eltwise18
I0924 21:06:14.055305  2642 net.cpp:406] Eltwise18 <- Eltwise17_ReLU35_0_split_1
I0924 21:06:14.055307  2642 net.cpp:406] Eltwise18 <- Convolution38
I0924 21:06:14.055310  2642 net.cpp:380] Eltwise18 -> Eltwise18
I0924 21:06:14.055321  2642 net.cpp:122] Setting up Eltwise18
I0924 21:06:14.055325  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.055327  2642 net.cpp:137] Memory required for data: 1013761200
I0924 21:06:14.055330  2642 layer_factory.hpp:77] Creating layer ReLU37
I0924 21:06:14.055333  2642 net.cpp:84] Creating Layer ReLU37
I0924 21:06:14.055336  2642 net.cpp:406] ReLU37 <- Eltwise18
I0924 21:06:14.055338  2642 net.cpp:367] ReLU37 -> Eltwise18 (in-place)
I0924 21:06:14.055472  2642 net.cpp:122] Setting up ReLU37
I0924 21:06:14.055480  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.055481  2642 net.cpp:137] Memory required for data: 1017038000
I0924 21:06:14.055485  2642 layer_factory.hpp:77] Creating layer Eltwise18_ReLU37_0_split
I0924 21:06:14.055487  2642 net.cpp:84] Creating Layer Eltwise18_ReLU37_0_split
I0924 21:06:14.055490  2642 net.cpp:406] Eltwise18_ReLU37_0_split <- Eltwise18
I0924 21:06:14.055495  2642 net.cpp:380] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_0
I0924 21:06:14.055498  2642 net.cpp:380] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_1
I0924 21:06:14.055524  2642 net.cpp:122] Setting up Eltwise18_ReLU37_0_split
I0924 21:06:14.055528  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.055531  2642 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0924 21:06:14.055533  2642 net.cpp:137] Memory required for data: 1023591600
I0924 21:06:14.055536  2642 layer_factory.hpp:77] Creating layer Convolution39
I0924 21:06:14.055542  2642 net.cpp:84] Creating Layer Convolution39
I0924 21:06:14.055544  2642 net.cpp:406] Convolution39 <- Eltwise18_ReLU37_0_split_0
I0924 21:06:14.055549  2642 net.cpp:380] Convolution39 -> Convolution39
I0924 21:06:14.057034  2642 net.cpp:122] Setting up Convolution39
I0924 21:06:14.057041  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.057044  2642 net.cpp:137] Memory required for data: 1025230000
I0924 21:06:14.057049  2642 layer_factory.hpp:77] Creating layer BatchNorm39
I0924 21:06:14.057054  2642 net.cpp:84] Creating Layer BatchNorm39
I0924 21:06:14.057057  2642 net.cpp:406] BatchNorm39 <- Convolution39
I0924 21:06:14.057061  2642 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I0924 21:06:14.057188  2642 net.cpp:122] Setting up BatchNorm39
I0924 21:06:14.057191  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.057193  2642 net.cpp:137] Memory required for data: 1026868400
I0924 21:06:14.057199  2642 layer_factory.hpp:77] Creating layer Scale39
I0924 21:06:14.057204  2642 net.cpp:84] Creating Layer Scale39
I0924 21:06:14.057205  2642 net.cpp:406] Scale39 <- Convolution39
I0924 21:06:14.057209  2642 net.cpp:367] Scale39 -> Convolution39 (in-place)
I0924 21:06:14.057235  2642 layer_factory.hpp:77] Creating layer Scale39
I0924 21:06:14.057314  2642 net.cpp:122] Setting up Scale39
I0924 21:06:14.057319  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.057322  2642 net.cpp:137] Memory required for data: 1028506800
I0924 21:06:14.057324  2642 layer_factory.hpp:77] Creating layer Convolution40
I0924 21:06:14.057332  2642 net.cpp:84] Creating Layer Convolution40
I0924 21:06:14.057334  2642 net.cpp:406] Convolution40 <- Eltwise18_ReLU37_0_split_1
I0924 21:06:14.057339  2642 net.cpp:380] Convolution40 -> Convolution40
I0924 21:06:14.058639  2642 net.cpp:122] Setting up Convolution40
I0924 21:06:14.058646  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.058650  2642 net.cpp:137] Memory required for data: 1030145200
I0924 21:06:14.058653  2642 layer_factory.hpp:77] Creating layer BatchNorm40
I0924 21:06:14.058660  2642 net.cpp:84] Creating Layer BatchNorm40
I0924 21:06:14.058662  2642 net.cpp:406] BatchNorm40 <- Convolution40
I0924 21:06:14.058665  2642 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I0924 21:06:14.058794  2642 net.cpp:122] Setting up BatchNorm40
I0924 21:06:14.058799  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.058801  2642 net.cpp:137] Memory required for data: 1031783600
I0924 21:06:14.058805  2642 layer_factory.hpp:77] Creating layer Scale40
I0924 21:06:14.058809  2642 net.cpp:84] Creating Layer Scale40
I0924 21:06:14.058811  2642 net.cpp:406] Scale40 <- Convolution40
I0924 21:06:14.058815  2642 net.cpp:367] Scale40 -> Convolution40 (in-place)
I0924 21:06:14.058842  2642 layer_factory.hpp:77] Creating layer Scale40
I0924 21:06:14.058914  2642 net.cpp:122] Setting up Scale40
I0924 21:06:14.058918  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.058920  2642 net.cpp:137] Memory required for data: 1033422000
I0924 21:06:14.058923  2642 layer_factory.hpp:77] Creating layer ReLU38
I0924 21:06:14.058928  2642 net.cpp:84] Creating Layer ReLU38
I0924 21:06:14.058930  2642 net.cpp:406] ReLU38 <- Convolution40
I0924 21:06:14.058933  2642 net.cpp:367] ReLU38 -> Convolution40 (in-place)
I0924 21:06:14.059062  2642 net.cpp:122] Setting up ReLU38
I0924 21:06:14.059067  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.059070  2642 net.cpp:137] Memory required for data: 1035060400
I0924 21:06:14.059072  2642 layer_factory.hpp:77] Creating layer Convolution41
I0924 21:06:14.059079  2642 net.cpp:84] Creating Layer Convolution41
I0924 21:06:14.059082  2642 net.cpp:406] Convolution41 <- Convolution40
I0924 21:06:14.059087  2642 net.cpp:380] Convolution41 -> Convolution41
I0924 21:06:14.060765  2642 net.cpp:122] Setting up Convolution41
I0924 21:06:14.060773  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.060775  2642 net.cpp:137] Memory required for data: 1036698800
I0924 21:06:14.060781  2642 layer_factory.hpp:77] Creating layer BatchNorm41
I0924 21:06:14.060786  2642 net.cpp:84] Creating Layer BatchNorm41
I0924 21:06:14.060787  2642 net.cpp:406] BatchNorm41 <- Convolution41
I0924 21:06:14.060792  2642 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I0924 21:06:14.060940  2642 net.cpp:122] Setting up BatchNorm41
I0924 21:06:14.060945  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.060947  2642 net.cpp:137] Memory required for data: 1038337200
I0924 21:06:14.060961  2642 layer_factory.hpp:77] Creating layer Scale41
I0924 21:06:14.060966  2642 net.cpp:84] Creating Layer Scale41
I0924 21:06:14.060968  2642 net.cpp:406] Scale41 <- Convolution41
I0924 21:06:14.060972  2642 net.cpp:367] Scale41 -> Convolution41 (in-place)
I0924 21:06:14.060997  2642 layer_factory.hpp:77] Creating layer Scale41
I0924 21:06:14.061069  2642 net.cpp:122] Setting up Scale41
I0924 21:06:14.061074  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.061076  2642 net.cpp:137] Memory required for data: 1039975600
I0924 21:06:14.061079  2642 layer_factory.hpp:77] Creating layer Eltwise19
I0924 21:06:14.061084  2642 net.cpp:84] Creating Layer Eltwise19
I0924 21:06:14.061085  2642 net.cpp:406] Eltwise19 <- Convolution39
I0924 21:06:14.061095  2642 net.cpp:406] Eltwise19 <- Convolution41
I0924 21:06:14.061100  2642 net.cpp:380] Eltwise19 -> Eltwise19
I0924 21:06:14.061117  2642 net.cpp:122] Setting up Eltwise19
I0924 21:06:14.061121  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.061123  2642 net.cpp:137] Memory required for data: 1041614000
I0924 21:06:14.061125  2642 layer_factory.hpp:77] Creating layer ReLU39
I0924 21:06:14.061130  2642 net.cpp:84] Creating Layer ReLU39
I0924 21:06:14.061131  2642 net.cpp:406] ReLU39 <- Eltwise19
I0924 21:06:14.061134  2642 net.cpp:367] ReLU39 -> Eltwise19 (in-place)
I0924 21:06:14.061264  2642 net.cpp:122] Setting up ReLU39
I0924 21:06:14.061269  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.061271  2642 net.cpp:137] Memory required for data: 1043252400
I0924 21:06:14.078743  2642 layer_factory.hpp:77] Creating layer Eltwise19_ReLU39_0_split
I0924 21:06:14.078753  2642 net.cpp:84] Creating Layer Eltwise19_ReLU39_0_split
I0924 21:06:14.078757  2642 net.cpp:406] Eltwise19_ReLU39_0_split <- Eltwise19
I0924 21:06:14.078760  2642 net.cpp:380] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_0
I0924 21:06:14.078766  2642 net.cpp:380] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_1
I0924 21:06:14.078802  2642 net.cpp:122] Setting up Eltwise19_ReLU39_0_split
I0924 21:06:14.078809  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.078811  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.078814  2642 net.cpp:137] Memory required for data: 1046529200
I0924 21:06:14.078816  2642 layer_factory.hpp:77] Creating layer Convolution42
I0924 21:06:14.078824  2642 net.cpp:84] Creating Layer Convolution42
I0924 21:06:14.078826  2642 net.cpp:406] Convolution42 <- Eltwise19_ReLU39_0_split_0
I0924 21:06:14.078831  2642 net.cpp:380] Convolution42 -> Convolution42
I0924 21:06:14.081010  2642 net.cpp:122] Setting up Convolution42
I0924 21:06:14.081020  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.081022  2642 net.cpp:137] Memory required for data: 1048167600
I0924 21:06:14.081027  2642 layer_factory.hpp:77] Creating layer BatchNorm42
I0924 21:06:14.081033  2642 net.cpp:84] Creating Layer BatchNorm42
I0924 21:06:14.081037  2642 net.cpp:406] BatchNorm42 <- Convolution42
I0924 21:06:14.081040  2642 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I0924 21:06:14.081181  2642 net.cpp:122] Setting up BatchNorm42
I0924 21:06:14.081185  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.081188  2642 net.cpp:137] Memory required for data: 1049806000
I0924 21:06:14.081192  2642 layer_factory.hpp:77] Creating layer Scale42
I0924 21:06:14.081198  2642 net.cpp:84] Creating Layer Scale42
I0924 21:06:14.081200  2642 net.cpp:406] Scale42 <- Convolution42
I0924 21:06:14.081204  2642 net.cpp:367] Scale42 -> Convolution42 (in-place)
I0924 21:06:14.081233  2642 layer_factory.hpp:77] Creating layer Scale42
I0924 21:06:14.081308  2642 net.cpp:122] Setting up Scale42
I0924 21:06:14.081312  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.081315  2642 net.cpp:137] Memory required for data: 1051444400
I0924 21:06:14.081318  2642 layer_factory.hpp:77] Creating layer ReLU40
I0924 21:06:14.081321  2642 net.cpp:84] Creating Layer ReLU40
I0924 21:06:14.081324  2642 net.cpp:406] ReLU40 <- Convolution42
I0924 21:06:14.081328  2642 net.cpp:367] ReLU40 -> Convolution42 (in-place)
I0924 21:06:14.081459  2642 net.cpp:122] Setting up ReLU40
I0924 21:06:14.081465  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.081467  2642 net.cpp:137] Memory required for data: 1053082800
I0924 21:06:14.081470  2642 layer_factory.hpp:77] Creating layer Convolution43
I0924 21:06:14.081478  2642 net.cpp:84] Creating Layer Convolution43
I0924 21:06:14.081481  2642 net.cpp:406] Convolution43 <- Convolution42
I0924 21:06:14.081485  2642 net.cpp:380] Convolution43 -> Convolution43
I0924 21:06:14.083353  2642 net.cpp:122] Setting up Convolution43
I0924 21:06:14.083361  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.083371  2642 net.cpp:137] Memory required for data: 1054721200
I0924 21:06:14.083376  2642 layer_factory.hpp:77] Creating layer BatchNorm43
I0924 21:06:14.083381  2642 net.cpp:84] Creating Layer BatchNorm43
I0924 21:06:14.083384  2642 net.cpp:406] BatchNorm43 <- Convolution43
I0924 21:06:14.083389  2642 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I0924 21:06:14.083516  2642 net.cpp:122] Setting up BatchNorm43
I0924 21:06:14.083521  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.083523  2642 net.cpp:137] Memory required for data: 1056359600
I0924 21:06:14.083528  2642 layer_factory.hpp:77] Creating layer Scale43
I0924 21:06:14.083533  2642 net.cpp:84] Creating Layer Scale43
I0924 21:06:14.083535  2642 net.cpp:406] Scale43 <- Convolution43
I0924 21:06:14.083539  2642 net.cpp:367] Scale43 -> Convolution43 (in-place)
I0924 21:06:14.083564  2642 layer_factory.hpp:77] Creating layer Scale43
I0924 21:06:14.083638  2642 net.cpp:122] Setting up Scale43
I0924 21:06:14.083642  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.083644  2642 net.cpp:137] Memory required for data: 1057998000
I0924 21:06:14.083648  2642 layer_factory.hpp:77] Creating layer Eltwise20
I0924 21:06:14.083652  2642 net.cpp:84] Creating Layer Eltwise20
I0924 21:06:14.083654  2642 net.cpp:406] Eltwise20 <- Eltwise19_ReLU39_0_split_1
I0924 21:06:14.083657  2642 net.cpp:406] Eltwise20 <- Convolution43
I0924 21:06:14.083662  2642 net.cpp:380] Eltwise20 -> Eltwise20
I0924 21:06:14.083676  2642 net.cpp:122] Setting up Eltwise20
I0924 21:06:14.083680  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.083683  2642 net.cpp:137] Memory required for data: 1059636400
I0924 21:06:14.083684  2642 layer_factory.hpp:77] Creating layer ReLU41
I0924 21:06:14.083688  2642 net.cpp:84] Creating Layer ReLU41
I0924 21:06:14.083691  2642 net.cpp:406] ReLU41 <- Eltwise20
I0924 21:06:14.083693  2642 net.cpp:367] ReLU41 -> Eltwise20 (in-place)
I0924 21:06:14.083822  2642 net.cpp:122] Setting up ReLU41
I0924 21:06:14.083827  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.083830  2642 net.cpp:137] Memory required for data: 1061274800
I0924 21:06:14.083832  2642 layer_factory.hpp:77] Creating layer Eltwise20_ReLU41_0_split
I0924 21:06:14.083837  2642 net.cpp:84] Creating Layer Eltwise20_ReLU41_0_split
I0924 21:06:14.083839  2642 net.cpp:406] Eltwise20_ReLU41_0_split <- Eltwise20
I0924 21:06:14.083842  2642 net.cpp:380] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_0
I0924 21:06:14.083847  2642 net.cpp:380] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_1
I0924 21:06:14.083873  2642 net.cpp:122] Setting up Eltwise20_ReLU41_0_split
I0924 21:06:14.083876  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.083878  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.083880  2642 net.cpp:137] Memory required for data: 1064551600
I0924 21:06:14.083883  2642 layer_factory.hpp:77] Creating layer Convolution44
I0924 21:06:14.083889  2642 net.cpp:84] Creating Layer Convolution44
I0924 21:06:14.083891  2642 net.cpp:406] Convolution44 <- Eltwise20_ReLU41_0_split_0
I0924 21:06:14.083896  2642 net.cpp:380] Convolution44 -> Convolution44
I0924 21:06:14.085911  2642 net.cpp:122] Setting up Convolution44
I0924 21:06:14.085919  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.085922  2642 net.cpp:137] Memory required for data: 1066190000
I0924 21:06:14.085927  2642 layer_factory.hpp:77] Creating layer BatchNorm44
I0924 21:06:14.085932  2642 net.cpp:84] Creating Layer BatchNorm44
I0924 21:06:14.085934  2642 net.cpp:406] BatchNorm44 <- Convolution44
I0924 21:06:14.085938  2642 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I0924 21:06:14.086069  2642 net.cpp:122] Setting up BatchNorm44
I0924 21:06:14.086073  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.086076  2642 net.cpp:137] Memory required for data: 1067828400
I0924 21:06:14.086081  2642 layer_factory.hpp:77] Creating layer Scale44
I0924 21:06:14.086084  2642 net.cpp:84] Creating Layer Scale44
I0924 21:06:14.086094  2642 net.cpp:406] Scale44 <- Convolution44
I0924 21:06:14.086098  2642 net.cpp:367] Scale44 -> Convolution44 (in-place)
I0924 21:06:14.086127  2642 layer_factory.hpp:77] Creating layer Scale44
I0924 21:06:14.086202  2642 net.cpp:122] Setting up Scale44
I0924 21:06:14.086206  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.086208  2642 net.cpp:137] Memory required for data: 1069466800
I0924 21:06:14.086212  2642 layer_factory.hpp:77] Creating layer ReLU42
I0924 21:06:14.086215  2642 net.cpp:84] Creating Layer ReLU42
I0924 21:06:14.086218  2642 net.cpp:406] ReLU42 <- Convolution44
I0924 21:06:14.086221  2642 net.cpp:367] ReLU42 -> Convolution44 (in-place)
I0924 21:06:14.086678  2642 net.cpp:122] Setting up ReLU42
I0924 21:06:14.086685  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.086688  2642 net.cpp:137] Memory required for data: 1071105200
I0924 21:06:14.086690  2642 layer_factory.hpp:77] Creating layer Convolution45
I0924 21:06:14.086697  2642 net.cpp:84] Creating Layer Convolution45
I0924 21:06:14.086700  2642 net.cpp:406] Convolution45 <- Convolution44
I0924 21:06:14.086705  2642 net.cpp:380] Convolution45 -> Convolution45
I0924 21:06:14.088048  2642 net.cpp:122] Setting up Convolution45
I0924 21:06:14.088057  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.088058  2642 net.cpp:137] Memory required for data: 1072743600
I0924 21:06:14.088063  2642 layer_factory.hpp:77] Creating layer BatchNorm45
I0924 21:06:14.088068  2642 net.cpp:84] Creating Layer BatchNorm45
I0924 21:06:14.088070  2642 net.cpp:406] BatchNorm45 <- Convolution45
I0924 21:06:14.088073  2642 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I0924 21:06:14.088202  2642 net.cpp:122] Setting up BatchNorm45
I0924 21:06:14.088207  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.088208  2642 net.cpp:137] Memory required for data: 1074382000
I0924 21:06:14.088213  2642 layer_factory.hpp:77] Creating layer Scale45
I0924 21:06:14.088217  2642 net.cpp:84] Creating Layer Scale45
I0924 21:06:14.088219  2642 net.cpp:406] Scale45 <- Convolution45
I0924 21:06:14.088222  2642 net.cpp:367] Scale45 -> Convolution45 (in-place)
I0924 21:06:14.088248  2642 layer_factory.hpp:77] Creating layer Scale45
I0924 21:06:14.088320  2642 net.cpp:122] Setting up Scale45
I0924 21:06:14.088325  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.088326  2642 net.cpp:137] Memory required for data: 1076020400
I0924 21:06:14.088330  2642 layer_factory.hpp:77] Creating layer Eltwise21
I0924 21:06:14.088333  2642 net.cpp:84] Creating Layer Eltwise21
I0924 21:06:14.088337  2642 net.cpp:406] Eltwise21 <- Eltwise20_ReLU41_0_split_1
I0924 21:06:14.088340  2642 net.cpp:406] Eltwise21 <- Convolution45
I0924 21:06:14.088343  2642 net.cpp:380] Eltwise21 -> Eltwise21
I0924 21:06:14.088358  2642 net.cpp:122] Setting up Eltwise21
I0924 21:06:14.088361  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.088363  2642 net.cpp:137] Memory required for data: 1077658800
I0924 21:06:14.088366  2642 layer_factory.hpp:77] Creating layer ReLU43
I0924 21:06:14.088371  2642 net.cpp:84] Creating Layer ReLU43
I0924 21:06:14.088372  2642 net.cpp:406] ReLU43 <- Eltwise21
I0924 21:06:14.088376  2642 net.cpp:367] ReLU43 -> Eltwise21 (in-place)
I0924 21:06:14.088831  2642 net.cpp:122] Setting up ReLU43
I0924 21:06:14.088840  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.088841  2642 net.cpp:137] Memory required for data: 1079297200
I0924 21:06:14.088845  2642 layer_factory.hpp:77] Creating layer Eltwise21_ReLU43_0_split
I0924 21:06:14.088848  2642 net.cpp:84] Creating Layer Eltwise21_ReLU43_0_split
I0924 21:06:14.088850  2642 net.cpp:406] Eltwise21_ReLU43_0_split <- Eltwise21
I0924 21:06:14.088855  2642 net.cpp:380] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_0
I0924 21:06:14.088860  2642 net.cpp:380] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_1
I0924 21:06:14.088887  2642 net.cpp:122] Setting up Eltwise21_ReLU43_0_split
I0924 21:06:14.088891  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.088901  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.088902  2642 net.cpp:137] Memory required for data: 1082574000
I0924 21:06:14.088904  2642 layer_factory.hpp:77] Creating layer Convolution46
I0924 21:06:14.088912  2642 net.cpp:84] Creating Layer Convolution46
I0924 21:06:14.088914  2642 net.cpp:406] Convolution46 <- Eltwise21_ReLU43_0_split_0
I0924 21:06:14.088934  2642 net.cpp:380] Convolution46 -> Convolution46
I0924 21:06:14.090947  2642 net.cpp:122] Setting up Convolution46
I0924 21:06:14.090956  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.090958  2642 net.cpp:137] Memory required for data: 1084212400
I0924 21:06:14.090963  2642 layer_factory.hpp:77] Creating layer BatchNorm46
I0924 21:06:14.090967  2642 net.cpp:84] Creating Layer BatchNorm46
I0924 21:06:14.090970  2642 net.cpp:406] BatchNorm46 <- Convolution46
I0924 21:06:14.090975  2642 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I0924 21:06:14.091112  2642 net.cpp:122] Setting up BatchNorm46
I0924 21:06:14.091117  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.091120  2642 net.cpp:137] Memory required for data: 1085850800
I0924 21:06:14.091125  2642 layer_factory.hpp:77] Creating layer Scale46
I0924 21:06:14.091128  2642 net.cpp:84] Creating Layer Scale46
I0924 21:06:14.091131  2642 net.cpp:406] Scale46 <- Convolution46
I0924 21:06:14.091135  2642 net.cpp:367] Scale46 -> Convolution46 (in-place)
I0924 21:06:14.091161  2642 layer_factory.hpp:77] Creating layer Scale46
I0924 21:06:14.091235  2642 net.cpp:122] Setting up Scale46
I0924 21:06:14.091240  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.091243  2642 net.cpp:137] Memory required for data: 1087489200
I0924 21:06:14.091245  2642 layer_factory.hpp:77] Creating layer ReLU44
I0924 21:06:14.091249  2642 net.cpp:84] Creating Layer ReLU44
I0924 21:06:14.091251  2642 net.cpp:406] ReLU44 <- Convolution46
I0924 21:06:14.091255  2642 net.cpp:367] ReLU44 -> Convolution46 (in-place)
I0924 21:06:14.091390  2642 net.cpp:122] Setting up ReLU44
I0924 21:06:14.091397  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.091398  2642 net.cpp:137] Memory required for data: 1089127600
I0924 21:06:14.091400  2642 layer_factory.hpp:77] Creating layer Convolution47
I0924 21:06:14.091408  2642 net.cpp:84] Creating Layer Convolution47
I0924 21:06:14.091410  2642 net.cpp:406] Convolution47 <- Convolution46
I0924 21:06:14.091414  2642 net.cpp:380] Convolution47 -> Convolution47
I0924 21:06:14.093123  2642 net.cpp:122] Setting up Convolution47
I0924 21:06:14.093132  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.093135  2642 net.cpp:137] Memory required for data: 1090766000
I0924 21:06:14.093139  2642 layer_factory.hpp:77] Creating layer BatchNorm47
I0924 21:06:14.093144  2642 net.cpp:84] Creating Layer BatchNorm47
I0924 21:06:14.093147  2642 net.cpp:406] BatchNorm47 <- Convolution47
I0924 21:06:14.093152  2642 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I0924 21:06:14.093279  2642 net.cpp:122] Setting up BatchNorm47
I0924 21:06:14.093284  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.093286  2642 net.cpp:137] Memory required for data: 1092404400
I0924 21:06:14.093291  2642 layer_factory.hpp:77] Creating layer Scale47
I0924 21:06:14.093296  2642 net.cpp:84] Creating Layer Scale47
I0924 21:06:14.093298  2642 net.cpp:406] Scale47 <- Convolution47
I0924 21:06:14.093302  2642 net.cpp:367] Scale47 -> Convolution47 (in-place)
I0924 21:06:14.093327  2642 layer_factory.hpp:77] Creating layer Scale47
I0924 21:06:14.093402  2642 net.cpp:122] Setting up Scale47
I0924 21:06:14.093406  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.093408  2642 net.cpp:137] Memory required for data: 1094042800
I0924 21:06:14.093412  2642 layer_factory.hpp:77] Creating layer Eltwise22
I0924 21:06:14.093416  2642 net.cpp:84] Creating Layer Eltwise22
I0924 21:06:14.093420  2642 net.cpp:406] Eltwise22 <- Eltwise21_ReLU43_0_split_1
I0924 21:06:14.093422  2642 net.cpp:406] Eltwise22 <- Convolution47
I0924 21:06:14.093433  2642 net.cpp:380] Eltwise22 -> Eltwise22
I0924 21:06:14.093451  2642 net.cpp:122] Setting up Eltwise22
I0924 21:06:14.093454  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.093456  2642 net.cpp:137] Memory required for data: 1095681200
I0924 21:06:14.093458  2642 layer_factory.hpp:77] Creating layer ReLU45
I0924 21:06:14.093462  2642 net.cpp:84] Creating Layer ReLU45
I0924 21:06:14.093464  2642 net.cpp:406] ReLU45 <- Eltwise22
I0924 21:06:14.093468  2642 net.cpp:367] ReLU45 -> Eltwise22 (in-place)
I0924 21:06:14.093606  2642 net.cpp:122] Setting up ReLU45
I0924 21:06:14.093612  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.109143  2642 net.cpp:137] Memory required for data: 1097319600
I0924 21:06:14.109150  2642 layer_factory.hpp:77] Creating layer Eltwise22_ReLU45_0_split
I0924 21:06:14.109155  2642 net.cpp:84] Creating Layer Eltwise22_ReLU45_0_split
I0924 21:06:14.109158  2642 net.cpp:406] Eltwise22_ReLU45_0_split <- Eltwise22
I0924 21:06:14.109165  2642 net.cpp:380] Eltwise22_ReLU45_0_split -> Eltwise22_ReLU45_0_split_0
I0924 21:06:14.109171  2642 net.cpp:380] Eltwise22_ReLU45_0_split -> Eltwise22_ReLU45_0_split_1
I0924 21:06:14.109207  2642 net.cpp:122] Setting up Eltwise22_ReLU45_0_split
I0924 21:06:14.109212  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.109216  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.109218  2642 net.cpp:137] Memory required for data: 1100596400
I0924 21:06:14.109220  2642 layer_factory.hpp:77] Creating layer Convolution48
I0924 21:06:14.109227  2642 net.cpp:84] Creating Layer Convolution48
I0924 21:06:14.109230  2642 net.cpp:406] Convolution48 <- Eltwise22_ReLU45_0_split_0
I0924 21:06:14.109236  2642 net.cpp:380] Convolution48 -> Convolution48
I0924 21:06:14.111629  2642 net.cpp:122] Setting up Convolution48
I0924 21:06:14.111637  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.111640  2642 net.cpp:137] Memory required for data: 1102234800
I0924 21:06:14.111645  2642 layer_factory.hpp:77] Creating layer BatchNorm48
I0924 21:06:14.111650  2642 net.cpp:84] Creating Layer BatchNorm48
I0924 21:06:14.111654  2642 net.cpp:406] BatchNorm48 <- Convolution48
I0924 21:06:14.111657  2642 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I0924 21:06:14.111794  2642 net.cpp:122] Setting up BatchNorm48
I0924 21:06:14.111799  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.111801  2642 net.cpp:137] Memory required for data: 1103873200
I0924 21:06:14.111806  2642 layer_factory.hpp:77] Creating layer Scale48
I0924 21:06:14.111810  2642 net.cpp:84] Creating Layer Scale48
I0924 21:06:14.111814  2642 net.cpp:406] Scale48 <- Convolution48
I0924 21:06:14.111817  2642 net.cpp:367] Scale48 -> Convolution48 (in-place)
I0924 21:06:14.111845  2642 layer_factory.hpp:77] Creating layer Scale48
I0924 21:06:14.111922  2642 net.cpp:122] Setting up Scale48
I0924 21:06:14.111927  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.111928  2642 net.cpp:137] Memory required for data: 1105511600
I0924 21:06:14.111932  2642 layer_factory.hpp:77] Creating layer ReLU46
I0924 21:06:14.111935  2642 net.cpp:84] Creating Layer ReLU46
I0924 21:06:14.111938  2642 net.cpp:406] ReLU46 <- Convolution48
I0924 21:06:14.111941  2642 net.cpp:367] ReLU46 -> Convolution48 (in-place)
I0924 21:06:14.112084  2642 net.cpp:122] Setting up ReLU46
I0924 21:06:14.112090  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.112092  2642 net.cpp:137] Memory required for data: 1107150000
I0924 21:06:14.112095  2642 layer_factory.hpp:77] Creating layer Convolution49
I0924 21:06:14.112102  2642 net.cpp:84] Creating Layer Convolution49
I0924 21:06:14.112105  2642 net.cpp:406] Convolution49 <- Convolution48
I0924 21:06:14.112109  2642 net.cpp:380] Convolution49 -> Convolution49
I0924 21:06:14.113963  2642 net.cpp:122] Setting up Convolution49
I0924 21:06:14.113972  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.113975  2642 net.cpp:137] Memory required for data: 1108788400
I0924 21:06:14.113987  2642 layer_factory.hpp:77] Creating layer BatchNorm49
I0924 21:06:14.113993  2642 net.cpp:84] Creating Layer BatchNorm49
I0924 21:06:14.113996  2642 net.cpp:406] BatchNorm49 <- Convolution49
I0924 21:06:14.114001  2642 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I0924 21:06:14.114136  2642 net.cpp:122] Setting up BatchNorm49
I0924 21:06:14.114140  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.114142  2642 net.cpp:137] Memory required for data: 1110426800
I0924 21:06:14.114147  2642 layer_factory.hpp:77] Creating layer Scale49
I0924 21:06:14.114152  2642 net.cpp:84] Creating Layer Scale49
I0924 21:06:14.114156  2642 net.cpp:406] Scale49 <- Convolution49
I0924 21:06:14.114158  2642 net.cpp:367] Scale49 -> Convolution49 (in-place)
I0924 21:06:14.114187  2642 layer_factory.hpp:77] Creating layer Scale49
I0924 21:06:14.114261  2642 net.cpp:122] Setting up Scale49
I0924 21:06:14.114266  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.114269  2642 net.cpp:137] Memory required for data: 1112065200
I0924 21:06:14.114272  2642 layer_factory.hpp:77] Creating layer Eltwise23
I0924 21:06:14.114276  2642 net.cpp:84] Creating Layer Eltwise23
I0924 21:06:14.114279  2642 net.cpp:406] Eltwise23 <- Eltwise22_ReLU45_0_split_1
I0924 21:06:14.114284  2642 net.cpp:406] Eltwise23 <- Convolution49
I0924 21:06:14.114287  2642 net.cpp:380] Eltwise23 -> Eltwise23
I0924 21:06:14.114303  2642 net.cpp:122] Setting up Eltwise23
I0924 21:06:14.114306  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.114308  2642 net.cpp:137] Memory required for data: 1113703600
I0924 21:06:14.114310  2642 layer_factory.hpp:77] Creating layer ReLU47
I0924 21:06:14.114315  2642 net.cpp:84] Creating Layer ReLU47
I0924 21:06:14.114317  2642 net.cpp:406] ReLU47 <- Eltwise23
I0924 21:06:14.114320  2642 net.cpp:367] ReLU47 -> Eltwise23 (in-place)
I0924 21:06:14.114451  2642 net.cpp:122] Setting up ReLU47
I0924 21:06:14.114457  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.114459  2642 net.cpp:137] Memory required for data: 1115342000
I0924 21:06:14.114461  2642 layer_factory.hpp:77] Creating layer Eltwise23_ReLU47_0_split
I0924 21:06:14.114467  2642 net.cpp:84] Creating Layer Eltwise23_ReLU47_0_split
I0924 21:06:14.114470  2642 net.cpp:406] Eltwise23_ReLU47_0_split <- Eltwise23
I0924 21:06:14.114473  2642 net.cpp:380] Eltwise23_ReLU47_0_split -> Eltwise23_ReLU47_0_split_0
I0924 21:06:14.114477  2642 net.cpp:380] Eltwise23_ReLU47_0_split -> Eltwise23_ReLU47_0_split_1
I0924 21:06:14.114506  2642 net.cpp:122] Setting up Eltwise23_ReLU47_0_split
I0924 21:06:14.114508  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.114511  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.114513  2642 net.cpp:137] Memory required for data: 1118618800
I0924 21:06:14.114516  2642 layer_factory.hpp:77] Creating layer Convolution50
I0924 21:06:14.114522  2642 net.cpp:84] Creating Layer Convolution50
I0924 21:06:14.114524  2642 net.cpp:406] Convolution50 <- Eltwise23_ReLU47_0_split_0
I0924 21:06:14.114529  2642 net.cpp:380] Convolution50 -> Convolution50
I0924 21:06:14.117118  2642 net.cpp:122] Setting up Convolution50
I0924 21:06:14.117127  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.117130  2642 net.cpp:137] Memory required for data: 1120257200
I0924 21:06:14.117136  2642 layer_factory.hpp:77] Creating layer BatchNorm50
I0924 21:06:14.117141  2642 net.cpp:84] Creating Layer BatchNorm50
I0924 21:06:14.117143  2642 net.cpp:406] BatchNorm50 <- Convolution50
I0924 21:06:14.117147  2642 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I0924 21:06:14.117290  2642 net.cpp:122] Setting up BatchNorm50
I0924 21:06:14.117295  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.117296  2642 net.cpp:137] Memory required for data: 1121895600
I0924 21:06:14.117301  2642 layer_factory.hpp:77] Creating layer Scale50
I0924 21:06:14.117305  2642 net.cpp:84] Creating Layer Scale50
I0924 21:06:14.117307  2642 net.cpp:406] Scale50 <- Convolution50
I0924 21:06:14.117318  2642 net.cpp:367] Scale50 -> Convolution50 (in-place)
I0924 21:06:14.117348  2642 layer_factory.hpp:77] Creating layer Scale50
I0924 21:06:14.117425  2642 net.cpp:122] Setting up Scale50
I0924 21:06:14.117429  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.117431  2642 net.cpp:137] Memory required for data: 1123534000
I0924 21:06:14.117435  2642 layer_factory.hpp:77] Creating layer ReLU48
I0924 21:06:14.117439  2642 net.cpp:84] Creating Layer ReLU48
I0924 21:06:14.117442  2642 net.cpp:406] ReLU48 <- Convolution50
I0924 21:06:14.117445  2642 net.cpp:367] ReLU48 -> Convolution50 (in-place)
I0924 21:06:14.139860  2642 net.cpp:122] Setting up ReLU48
I0924 21:06:14.139870  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.139873  2642 net.cpp:137] Memory required for data: 1125172400
I0924 21:06:14.139876  2642 layer_factory.hpp:77] Creating layer Convolution51
I0924 21:06:14.139885  2642 net.cpp:84] Creating Layer Convolution51
I0924 21:06:14.139889  2642 net.cpp:406] Convolution51 <- Convolution50
I0924 21:06:14.139894  2642 net.cpp:380] Convolution51 -> Convolution51
I0924 21:06:14.141671  2642 net.cpp:122] Setting up Convolution51
I0924 21:06:14.141680  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.141682  2642 net.cpp:137] Memory required for data: 1126810800
I0924 21:06:14.141686  2642 layer_factory.hpp:77] Creating layer BatchNorm51
I0924 21:06:14.141692  2642 net.cpp:84] Creating Layer BatchNorm51
I0924 21:06:14.141695  2642 net.cpp:406] BatchNorm51 <- Convolution51
I0924 21:06:14.141698  2642 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I0924 21:06:14.141830  2642 net.cpp:122] Setting up BatchNorm51
I0924 21:06:14.141834  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.141836  2642 net.cpp:137] Memory required for data: 1128449200
I0924 21:06:14.141841  2642 layer_factory.hpp:77] Creating layer Scale51
I0924 21:06:14.141845  2642 net.cpp:84] Creating Layer Scale51
I0924 21:06:14.141847  2642 net.cpp:406] Scale51 <- Convolution51
I0924 21:06:14.141852  2642 net.cpp:367] Scale51 -> Convolution51 (in-place)
I0924 21:06:14.141878  2642 layer_factory.hpp:77] Creating layer Scale51
I0924 21:06:14.141953  2642 net.cpp:122] Setting up Scale51
I0924 21:06:14.141957  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.141959  2642 net.cpp:137] Memory required for data: 1130087600
I0924 21:06:14.141963  2642 layer_factory.hpp:77] Creating layer Eltwise24
I0924 21:06:14.141968  2642 net.cpp:84] Creating Layer Eltwise24
I0924 21:06:14.141970  2642 net.cpp:406] Eltwise24 <- Eltwise23_ReLU47_0_split_1
I0924 21:06:14.141973  2642 net.cpp:406] Eltwise24 <- Convolution51
I0924 21:06:14.141978  2642 net.cpp:380] Eltwise24 -> Eltwise24
I0924 21:06:14.141994  2642 net.cpp:122] Setting up Eltwise24
I0924 21:06:14.141997  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.141999  2642 net.cpp:137] Memory required for data: 1131726000
I0924 21:06:14.142001  2642 layer_factory.hpp:77] Creating layer ReLU49
I0924 21:06:14.142005  2642 net.cpp:84] Creating Layer ReLU49
I0924 21:06:14.142007  2642 net.cpp:406] ReLU49 <- Eltwise24
I0924 21:06:14.142010  2642 net.cpp:367] ReLU49 -> Eltwise24 (in-place)
I0924 21:06:14.142489  2642 net.cpp:122] Setting up ReLU49
I0924 21:06:14.142498  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.142499  2642 net.cpp:137] Memory required for data: 1133364400
I0924 21:06:14.142503  2642 layer_factory.hpp:77] Creating layer Eltwise24_ReLU49_0_split
I0924 21:06:14.142506  2642 net.cpp:84] Creating Layer Eltwise24_ReLU49_0_split
I0924 21:06:14.142508  2642 net.cpp:406] Eltwise24_ReLU49_0_split <- Eltwise24
I0924 21:06:14.142513  2642 net.cpp:380] Eltwise24_ReLU49_0_split -> Eltwise24_ReLU49_0_split_0
I0924 21:06:14.142518  2642 net.cpp:380] Eltwise24_ReLU49_0_split -> Eltwise24_ReLU49_0_split_1
I0924 21:06:14.142566  2642 net.cpp:122] Setting up Eltwise24_ReLU49_0_split
I0924 21:06:14.142570  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.142575  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.142583  2642 net.cpp:137] Memory required for data: 1136641200
I0924 21:06:14.142586  2642 layer_factory.hpp:77] Creating layer Convolution52
I0924 21:06:14.142593  2642 net.cpp:84] Creating Layer Convolution52
I0924 21:06:14.142596  2642 net.cpp:406] Convolution52 <- Eltwise24_ReLU49_0_split_0
I0924 21:06:14.142611  2642 net.cpp:380] Convolution52 -> Convolution52
I0924 21:06:14.144738  2642 net.cpp:122] Setting up Convolution52
I0924 21:06:14.144747  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.144749  2642 net.cpp:137] Memory required for data: 1138279600
I0924 21:06:14.144754  2642 layer_factory.hpp:77] Creating layer BatchNorm52
I0924 21:06:14.144759  2642 net.cpp:84] Creating Layer BatchNorm52
I0924 21:06:14.144762  2642 net.cpp:406] BatchNorm52 <- Convolution52
I0924 21:06:14.144767  2642 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I0924 21:06:14.144901  2642 net.cpp:122] Setting up BatchNorm52
I0924 21:06:14.144906  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.144908  2642 net.cpp:137] Memory required for data: 1139918000
I0924 21:06:14.144912  2642 layer_factory.hpp:77] Creating layer Scale52
I0924 21:06:14.144932  2642 net.cpp:84] Creating Layer Scale52
I0924 21:06:14.144934  2642 net.cpp:406] Scale52 <- Convolution52
I0924 21:06:14.144937  2642 net.cpp:367] Scale52 -> Convolution52 (in-place)
I0924 21:06:14.144975  2642 layer_factory.hpp:77] Creating layer Scale52
I0924 21:06:14.145051  2642 net.cpp:122] Setting up Scale52
I0924 21:06:14.145056  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.145057  2642 net.cpp:137] Memory required for data: 1141556400
I0924 21:06:14.145061  2642 layer_factory.hpp:77] Creating layer ReLU50
I0924 21:06:14.145082  2642 net.cpp:84] Creating Layer ReLU50
I0924 21:06:14.145086  2642 net.cpp:406] ReLU50 <- Convolution52
I0924 21:06:14.145089  2642 net.cpp:367] ReLU50 -> Convolution52 (in-place)
I0924 21:06:14.145228  2642 net.cpp:122] Setting up ReLU50
I0924 21:06:14.145234  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.145236  2642 net.cpp:137] Memory required for data: 1143194800
I0924 21:06:14.145239  2642 layer_factory.hpp:77] Creating layer Convolution53
I0924 21:06:14.145246  2642 net.cpp:84] Creating Layer Convolution53
I0924 21:06:14.145248  2642 net.cpp:406] Convolution53 <- Convolution52
I0924 21:06:14.145253  2642 net.cpp:380] Convolution53 -> Convolution53
I0924 21:06:14.146946  2642 net.cpp:122] Setting up Convolution53
I0924 21:06:14.146955  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.146957  2642 net.cpp:137] Memory required for data: 1144833200
I0924 21:06:14.146961  2642 layer_factory.hpp:77] Creating layer BatchNorm53
I0924 21:06:14.146966  2642 net.cpp:84] Creating Layer BatchNorm53
I0924 21:06:14.146970  2642 net.cpp:406] BatchNorm53 <- Convolution53
I0924 21:06:14.146973  2642 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I0924 21:06:14.147104  2642 net.cpp:122] Setting up BatchNorm53
I0924 21:06:14.147109  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.147111  2642 net.cpp:137] Memory required for data: 1146471600
I0924 21:06:14.147115  2642 layer_factory.hpp:77] Creating layer Scale53
I0924 21:06:14.147119  2642 net.cpp:84] Creating Layer Scale53
I0924 21:06:14.147122  2642 net.cpp:406] Scale53 <- Convolution53
I0924 21:06:14.147127  2642 net.cpp:367] Scale53 -> Convolution53 (in-place)
I0924 21:06:14.147153  2642 layer_factory.hpp:77] Creating layer Scale53
I0924 21:06:14.147228  2642 net.cpp:122] Setting up Scale53
I0924 21:06:14.147233  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.147234  2642 net.cpp:137] Memory required for data: 1148110000
I0924 21:06:14.147238  2642 layer_factory.hpp:77] Creating layer Eltwise25
I0924 21:06:14.147243  2642 net.cpp:84] Creating Layer Eltwise25
I0924 21:06:14.147245  2642 net.cpp:406] Eltwise25 <- Eltwise24_ReLU49_0_split_1
I0924 21:06:14.147248  2642 net.cpp:406] Eltwise25 <- Convolution53
I0924 21:06:14.147253  2642 net.cpp:380] Eltwise25 -> Eltwise25
I0924 21:06:14.147277  2642 net.cpp:122] Setting up Eltwise25
I0924 21:06:14.147281  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.147284  2642 net.cpp:137] Memory required for data: 1149748400
I0924 21:06:14.147285  2642 layer_factory.hpp:77] Creating layer ReLU51
I0924 21:06:14.147289  2642 net.cpp:84] Creating Layer ReLU51
I0924 21:06:14.147291  2642 net.cpp:406] ReLU51 <- Eltwise25
I0924 21:06:14.147294  2642 net.cpp:367] ReLU51 -> Eltwise25 (in-place)
I0924 21:06:14.147428  2642 net.cpp:122] Setting up ReLU51
I0924 21:06:14.147433  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.147436  2642 net.cpp:137] Memory required for data: 1151386800
I0924 21:06:14.147439  2642 layer_factory.hpp:77] Creating layer Eltwise25_ReLU51_0_split
I0924 21:06:14.147442  2642 net.cpp:84] Creating Layer Eltwise25_ReLU51_0_split
I0924 21:06:14.147444  2642 net.cpp:406] Eltwise25_ReLU51_0_split <- Eltwise25
I0924 21:06:14.147449  2642 net.cpp:380] Eltwise25_ReLU51_0_split -> Eltwise25_ReLU51_0_split_0
I0924 21:06:14.147454  2642 net.cpp:380] Eltwise25_ReLU51_0_split -> Eltwise25_ReLU51_0_split_1
I0924 21:06:14.147480  2642 net.cpp:122] Setting up Eltwise25_ReLU51_0_split
I0924 21:06:14.147483  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.147485  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.147487  2642 net.cpp:137] Memory required for data: 1154663600
I0924 21:06:14.147490  2642 layer_factory.hpp:77] Creating layer Convolution54
I0924 21:06:14.147496  2642 net.cpp:84] Creating Layer Convolution54
I0924 21:06:14.147500  2642 net.cpp:406] Convolution54 <- Eltwise25_ReLU51_0_split_0
I0924 21:06:14.147503  2642 net.cpp:380] Convolution54 -> Convolution54
I0924 21:06:14.149528  2642 net.cpp:122] Setting up Convolution54
I0924 21:06:14.149536  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.149538  2642 net.cpp:137] Memory required for data: 1156302000
I0924 21:06:14.149544  2642 layer_factory.hpp:77] Creating layer BatchNorm54
I0924 21:06:14.149547  2642 net.cpp:84] Creating Layer BatchNorm54
I0924 21:06:14.149550  2642 net.cpp:406] BatchNorm54 <- Convolution54
I0924 21:06:14.149554  2642 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I0924 21:06:14.149705  2642 net.cpp:122] Setting up BatchNorm54
I0924 21:06:14.149709  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.149711  2642 net.cpp:137] Memory required for data: 1157940400
I0924 21:06:14.149716  2642 layer_factory.hpp:77] Creating layer Scale54
I0924 21:06:14.149720  2642 net.cpp:84] Creating Layer Scale54
I0924 21:06:14.149724  2642 net.cpp:406] Scale54 <- Convolution54
I0924 21:06:14.149729  2642 net.cpp:367] Scale54 -> Convolution54 (in-place)
I0924 21:06:14.149756  2642 layer_factory.hpp:77] Creating layer Scale54
I0924 21:06:14.149843  2642 net.cpp:122] Setting up Scale54
I0924 21:06:14.149847  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.149849  2642 net.cpp:137] Memory required for data: 1159578800
I0924 21:06:14.149853  2642 layer_factory.hpp:77] Creating layer ReLU52
I0924 21:06:14.149857  2642 net.cpp:84] Creating Layer ReLU52
I0924 21:06:14.149859  2642 net.cpp:406] ReLU52 <- Convolution54
I0924 21:06:14.149863  2642 net.cpp:367] ReLU52 -> Convolution54 (in-place)
I0924 21:06:14.149998  2642 net.cpp:122] Setting up ReLU52
I0924 21:06:14.150004  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.150007  2642 net.cpp:137] Memory required for data: 1161217200
I0924 21:06:14.150009  2642 layer_factory.hpp:77] Creating layer Convolution55
I0924 21:06:14.150017  2642 net.cpp:84] Creating Layer Convolution55
I0924 21:06:14.150019  2642 net.cpp:406] Convolution55 <- Convolution54
I0924 21:06:14.150023  2642 net.cpp:380] Convolution55 -> Convolution55
I0924 21:06:14.151736  2642 net.cpp:122] Setting up Convolution55
I0924 21:06:14.151744  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.151747  2642 net.cpp:137] Memory required for data: 1162855600
I0924 21:06:14.151751  2642 layer_factory.hpp:77] Creating layer BatchNorm55
I0924 21:06:14.151763  2642 net.cpp:84] Creating Layer BatchNorm55
I0924 21:06:14.151767  2642 net.cpp:406] BatchNorm55 <- Convolution55
I0924 21:06:14.151770  2642 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I0924 21:06:14.151919  2642 net.cpp:122] Setting up BatchNorm55
I0924 21:06:14.151932  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.151934  2642 net.cpp:137] Memory required for data: 1164494000
I0924 21:06:14.151939  2642 layer_factory.hpp:77] Creating layer Scale55
I0924 21:06:14.151944  2642 net.cpp:84] Creating Layer Scale55
I0924 21:06:14.151947  2642 net.cpp:406] Scale55 <- Convolution55
I0924 21:06:14.151950  2642 net.cpp:367] Scale55 -> Convolution55 (in-place)
I0924 21:06:14.151978  2642 layer_factory.hpp:77] Creating layer Scale55
I0924 21:06:14.152055  2642 net.cpp:122] Setting up Scale55
I0924 21:06:14.152058  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.152060  2642 net.cpp:137] Memory required for data: 1166132400
I0924 21:06:14.152065  2642 layer_factory.hpp:77] Creating layer Eltwise26
I0924 21:06:14.152070  2642 net.cpp:84] Creating Layer Eltwise26
I0924 21:06:14.152072  2642 net.cpp:406] Eltwise26 <- Eltwise25_ReLU51_0_split_1
I0924 21:06:14.152076  2642 net.cpp:406] Eltwise26 <- Convolution55
I0924 21:06:14.152078  2642 net.cpp:380] Eltwise26 -> Eltwise26
I0924 21:06:14.152094  2642 net.cpp:122] Setting up Eltwise26
I0924 21:06:14.152098  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.152101  2642 net.cpp:137] Memory required for data: 1167770800
I0924 21:06:14.152102  2642 layer_factory.hpp:77] Creating layer ReLU53
I0924 21:06:14.152107  2642 net.cpp:84] Creating Layer ReLU53
I0924 21:06:14.152108  2642 net.cpp:406] ReLU53 <- Eltwise26
I0924 21:06:14.152112  2642 net.cpp:367] ReLU53 -> Eltwise26 (in-place)
I0924 21:06:14.152560  2642 net.cpp:122] Setting up ReLU53
I0924 21:06:14.152568  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.152570  2642 net.cpp:137] Memory required for data: 1169409200
I0924 21:06:14.152572  2642 layer_factory.hpp:77] Creating layer Eltwise26_ReLU53_0_split
I0924 21:06:14.152577  2642 net.cpp:84] Creating Layer Eltwise26_ReLU53_0_split
I0924 21:06:14.152580  2642 net.cpp:406] Eltwise26_ReLU53_0_split <- Eltwise26
I0924 21:06:14.152583  2642 net.cpp:380] Eltwise26_ReLU53_0_split -> Eltwise26_ReLU53_0_split_0
I0924 21:06:14.152588  2642 net.cpp:380] Eltwise26_ReLU53_0_split -> Eltwise26_ReLU53_0_split_1
I0924 21:06:14.152618  2642 net.cpp:122] Setting up Eltwise26_ReLU53_0_split
I0924 21:06:14.152622  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.152624  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.152626  2642 net.cpp:137] Memory required for data: 1172686000
I0924 21:06:14.152628  2642 layer_factory.hpp:77] Creating layer Convolution56
I0924 21:06:14.152635  2642 net.cpp:84] Creating Layer Convolution56
I0924 21:06:14.152637  2642 net.cpp:406] Convolution56 <- Eltwise26_ReLU53_0_split_0
I0924 21:06:14.152642  2642 net.cpp:380] Convolution56 -> Convolution56
I0924 21:06:14.154673  2642 net.cpp:122] Setting up Convolution56
I0924 21:06:14.154682  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.154685  2642 net.cpp:137] Memory required for data: 1174324400
I0924 21:06:14.154690  2642 layer_factory.hpp:77] Creating layer BatchNorm56
I0924 21:06:14.154695  2642 net.cpp:84] Creating Layer BatchNorm56
I0924 21:06:14.154697  2642 net.cpp:406] BatchNorm56 <- Convolution56
I0924 21:06:14.154701  2642 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I0924 21:06:14.154839  2642 net.cpp:122] Setting up BatchNorm56
I0924 21:06:14.154844  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.154846  2642 net.cpp:137] Memory required for data: 1175962800
I0924 21:06:14.154850  2642 layer_factory.hpp:77] Creating layer Scale56
I0924 21:06:14.154855  2642 net.cpp:84] Creating Layer Scale56
I0924 21:06:14.154857  2642 net.cpp:406] Scale56 <- Convolution56
I0924 21:06:14.154860  2642 net.cpp:367] Scale56 -> Convolution56 (in-place)
I0924 21:06:14.154897  2642 layer_factory.hpp:77] Creating layer Scale56
I0924 21:06:14.154976  2642 net.cpp:122] Setting up Scale56
I0924 21:06:14.154980  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.154983  2642 net.cpp:137] Memory required for data: 1177601200
I0924 21:06:14.154986  2642 layer_factory.hpp:77] Creating layer ReLU54
I0924 21:06:14.154990  2642 net.cpp:84] Creating Layer ReLU54
I0924 21:06:14.154994  2642 net.cpp:406] ReLU54 <- Convolution56
I0924 21:06:14.169700  2642 net.cpp:367] ReLU54 -> Convolution56 (in-place)
I0924 21:06:14.170235  2642 net.cpp:122] Setting up ReLU54
I0924 21:06:14.170245  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.170248  2642 net.cpp:137] Memory required for data: 1179239600
I0924 21:06:14.170250  2642 layer_factory.hpp:77] Creating layer Convolution57
I0924 21:06:14.170259  2642 net.cpp:84] Creating Layer Convolution57
I0924 21:06:14.170262  2642 net.cpp:406] Convolution57 <- Convolution56
I0924 21:06:14.170267  2642 net.cpp:380] Convolution57 -> Convolution57
I0924 21:06:14.172089  2642 net.cpp:122] Setting up Convolution57
I0924 21:06:14.172098  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.172101  2642 net.cpp:137] Memory required for data: 1180878000
I0924 21:06:14.172106  2642 layer_factory.hpp:77] Creating layer BatchNorm57
I0924 21:06:14.172109  2642 net.cpp:84] Creating Layer BatchNorm57
I0924 21:06:14.172112  2642 net.cpp:406] BatchNorm57 <- Convolution57
I0924 21:06:14.172117  2642 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I0924 21:06:14.172256  2642 net.cpp:122] Setting up BatchNorm57
I0924 21:06:14.172261  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.172263  2642 net.cpp:137] Memory required for data: 1182516400
I0924 21:06:14.172267  2642 layer_factory.hpp:77] Creating layer Scale57
I0924 21:06:14.172271  2642 net.cpp:84] Creating Layer Scale57
I0924 21:06:14.172274  2642 net.cpp:406] Scale57 <- Convolution57
I0924 21:06:14.172277  2642 net.cpp:367] Scale57 -> Convolution57 (in-place)
I0924 21:06:14.172305  2642 layer_factory.hpp:77] Creating layer Scale57
I0924 21:06:14.172385  2642 net.cpp:122] Setting up Scale57
I0924 21:06:14.172390  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.172392  2642 net.cpp:137] Memory required for data: 1184154800
I0924 21:06:14.172396  2642 layer_factory.hpp:77] Creating layer Eltwise27
I0924 21:06:14.172399  2642 net.cpp:84] Creating Layer Eltwise27
I0924 21:06:14.172402  2642 net.cpp:406] Eltwise27 <- Eltwise26_ReLU53_0_split_1
I0924 21:06:14.172405  2642 net.cpp:406] Eltwise27 <- Convolution57
I0924 21:06:14.172410  2642 net.cpp:380] Eltwise27 -> Eltwise27
I0924 21:06:14.172426  2642 net.cpp:122] Setting up Eltwise27
I0924 21:06:14.172431  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.172433  2642 net.cpp:137] Memory required for data: 1185793200
I0924 21:06:14.172435  2642 layer_factory.hpp:77] Creating layer ReLU55
I0924 21:06:14.172439  2642 net.cpp:84] Creating Layer ReLU55
I0924 21:06:14.172441  2642 net.cpp:406] ReLU55 <- Eltwise27
I0924 21:06:14.172444  2642 net.cpp:367] ReLU55 -> Eltwise27 (in-place)
I0924 21:06:14.172927  2642 net.cpp:122] Setting up ReLU55
I0924 21:06:14.172936  2642 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0924 21:06:14.172938  2642 net.cpp:137] Memory required for data: 1187431600
I0924 21:06:14.172941  2642 layer_factory.hpp:77] Creating layer Pooling1
I0924 21:06:14.172947  2642 net.cpp:84] Creating Layer Pooling1
I0924 21:06:14.172950  2642 net.cpp:406] Pooling1 <- Eltwise27
I0924 21:06:14.172955  2642 net.cpp:380] Pooling1 -> Pooling1
I0924 21:06:14.173122  2642 net.cpp:122] Setting up Pooling1
I0924 21:06:14.173130  2642 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0924 21:06:14.173131  2642 net.cpp:137] Memory required for data: 1187457200
I0924 21:06:14.173133  2642 layer_factory.hpp:77] Creating layer InnerProduct1
I0924 21:06:14.173140  2642 net.cpp:84] Creating Layer InnerProduct1
I0924 21:06:14.173141  2642 net.cpp:406] InnerProduct1 <- Pooling1
I0924 21:06:14.173147  2642 net.cpp:380] InnerProduct1 -> InnerProduct1
I0924 21:06:14.173271  2642 net.cpp:122] Setting up InnerProduct1
I0924 21:06:14.173276  2642 net.cpp:129] Top shape: 100 10 (1000)
I0924 21:06:14.173279  2642 net.cpp:137] Memory required for data: 1187461200
I0924 21:06:14.173282  2642 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0924 21:06:14.173288  2642 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I0924 21:06:14.173290  2642 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0924 21:06:14.173295  2642 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0924 21:06:14.173300  2642 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0924 21:06:14.173324  2642 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I0924 21:06:14.173328  2642 net.cpp:129] Top shape: 100 10 (1000)
I0924 21:06:14.173331  2642 net.cpp:129] Top shape: 100 10 (1000)
I0924 21:06:14.173333  2642 net.cpp:137] Memory required for data: 1187469200
I0924 21:06:14.173336  2642 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0924 21:06:14.173339  2642 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0924 21:06:14.173342  2642 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I0924 21:06:14.173346  2642 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I0924 21:06:14.173348  2642 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0924 21:06:14.173353  2642 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0924 21:06:14.173584  2642 net.cpp:122] Setting up SoftmaxWithLoss1
I0924 21:06:14.173589  2642 net.cpp:129] Top shape: (1)
I0924 21:06:14.173593  2642 net.cpp:132]     with loss weight 1
I0924 21:06:14.173599  2642 net.cpp:137] Memory required for data: 1187469204
I0924 21:06:14.173601  2642 layer_factory.hpp:77] Creating layer Accuracy1
I0924 21:06:14.173606  2642 net.cpp:84] Creating Layer Accuracy1
I0924 21:06:14.173609  2642 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I0924 21:06:14.173612  2642 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I0924 21:06:14.173616  2642 net.cpp:380] Accuracy1 -> Accuracy1
I0924 21:06:14.173622  2642 net.cpp:122] Setting up Accuracy1
I0924 21:06:14.173625  2642 net.cpp:129] Top shape: (1)
I0924 21:06:14.173627  2642 net.cpp:137] Memory required for data: 1187469208
I0924 21:06:14.173629  2642 net.cpp:200] Accuracy1 does not need backward computation.
I0924 21:06:14.173632  2642 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0924 21:06:14.173635  2642 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0924 21:06:14.173637  2642 net.cpp:198] InnerProduct1 needs backward computation.
I0924 21:06:14.173640  2642 net.cpp:198] Pooling1 needs backward computation.
I0924 21:06:14.173641  2642 net.cpp:198] ReLU55 needs backward computation.
I0924 21:06:14.173643  2642 net.cpp:198] Eltwise27 needs backward computation.
I0924 21:06:14.173646  2642 net.cpp:198] Scale57 needs backward computation.
I0924 21:06:14.173648  2642 net.cpp:198] BatchNorm57 needs backward computation.
I0924 21:06:14.173650  2642 net.cpp:198] Convolution57 needs backward computation.
I0924 21:06:14.173652  2642 net.cpp:198] ReLU54 needs backward computation.
I0924 21:06:14.173655  2642 net.cpp:198] Scale56 needs backward computation.
I0924 21:06:14.173656  2642 net.cpp:198] BatchNorm56 needs backward computation.
I0924 21:06:14.173658  2642 net.cpp:198] Convolution56 needs backward computation.
I0924 21:06:14.173660  2642 net.cpp:198] Eltwise26_ReLU53_0_split needs backward computation.
I0924 21:06:14.173663  2642 net.cpp:198] ReLU53 needs backward computation.
I0924 21:06:14.173666  2642 net.cpp:198] Eltwise26 needs backward computation.
I0924 21:06:14.173667  2642 net.cpp:198] Scale55 needs backward computation.
I0924 21:06:14.173669  2642 net.cpp:198] BatchNorm55 needs backward computation.
I0924 21:06:14.173671  2642 net.cpp:198] Convolution55 needs backward computation.
I0924 21:06:14.173674  2642 net.cpp:198] ReLU52 needs backward computation.
I0924 21:06:14.173681  2642 net.cpp:198] Scale54 needs backward computation.
I0924 21:06:14.173684  2642 net.cpp:198] BatchNorm54 needs backward computation.
I0924 21:06:14.173686  2642 net.cpp:198] Convolution54 needs backward computation.
I0924 21:06:14.173688  2642 net.cpp:198] Eltwise25_ReLU51_0_split needs backward computation.
I0924 21:06:14.173691  2642 net.cpp:198] ReLU51 needs backward computation.
I0924 21:06:14.173693  2642 net.cpp:198] Eltwise25 needs backward computation.
I0924 21:06:14.173696  2642 net.cpp:198] Scale53 needs backward computation.
I0924 21:06:14.173697  2642 net.cpp:198] BatchNorm53 needs backward computation.
I0924 21:06:14.173699  2642 net.cpp:198] Convolution53 needs backward computation.
I0924 21:06:14.173702  2642 net.cpp:198] ReLU50 needs backward computation.
I0924 21:06:14.173703  2642 net.cpp:198] Scale52 needs backward computation.
I0924 21:06:14.173705  2642 net.cpp:198] BatchNorm52 needs backward computation.
I0924 21:06:14.173707  2642 net.cpp:198] Convolution52 needs backward computation.
I0924 21:06:14.173709  2642 net.cpp:198] Eltwise24_ReLU49_0_split needs backward computation.
I0924 21:06:14.173712  2642 net.cpp:198] ReLU49 needs backward computation.
I0924 21:06:14.173714  2642 net.cpp:198] Eltwise24 needs backward computation.
I0924 21:06:14.173717  2642 net.cpp:198] Scale51 needs backward computation.
I0924 21:06:14.173719  2642 net.cpp:198] BatchNorm51 needs backward computation.
I0924 21:06:14.173720  2642 net.cpp:198] Convolution51 needs backward computation.
I0924 21:06:14.173723  2642 net.cpp:198] ReLU48 needs backward computation.
I0924 21:06:14.173725  2642 net.cpp:198] Scale50 needs backward computation.
I0924 21:06:14.173727  2642 net.cpp:198] BatchNorm50 needs backward computation.
I0924 21:06:14.173729  2642 net.cpp:198] Convolution50 needs backward computation.
I0924 21:06:14.173732  2642 net.cpp:198] Eltwise23_ReLU47_0_split needs backward computation.
I0924 21:06:14.173734  2642 net.cpp:198] ReLU47 needs backward computation.
I0924 21:06:14.173737  2642 net.cpp:198] Eltwise23 needs backward computation.
I0924 21:06:14.173739  2642 net.cpp:198] Scale49 needs backward computation.
I0924 21:06:14.173741  2642 net.cpp:198] BatchNorm49 needs backward computation.
I0924 21:06:14.173743  2642 net.cpp:198] Convolution49 needs backward computation.
I0924 21:06:14.173746  2642 net.cpp:198] ReLU46 needs backward computation.
I0924 21:06:14.173748  2642 net.cpp:198] Scale48 needs backward computation.
I0924 21:06:14.173750  2642 net.cpp:198] BatchNorm48 needs backward computation.
I0924 21:06:14.173753  2642 net.cpp:198] Convolution48 needs backward computation.
I0924 21:06:14.173754  2642 net.cpp:198] Eltwise22_ReLU45_0_split needs backward computation.
I0924 21:06:14.173758  2642 net.cpp:198] ReLU45 needs backward computation.
I0924 21:06:14.173759  2642 net.cpp:198] Eltwise22 needs backward computation.
I0924 21:06:14.173761  2642 net.cpp:198] Scale47 needs backward computation.
I0924 21:06:14.173763  2642 net.cpp:198] BatchNorm47 needs backward computation.
I0924 21:06:14.173765  2642 net.cpp:198] Convolution47 needs backward computation.
I0924 21:06:14.173768  2642 net.cpp:198] ReLU44 needs backward computation.
I0924 21:06:14.173770  2642 net.cpp:198] Scale46 needs backward computation.
I0924 21:06:14.173773  2642 net.cpp:198] BatchNorm46 needs backward computation.
I0924 21:06:14.173774  2642 net.cpp:198] Convolution46 needs backward computation.
I0924 21:06:14.173776  2642 net.cpp:198] Eltwise21_ReLU43_0_split needs backward computation.
I0924 21:06:14.173779  2642 net.cpp:198] ReLU43 needs backward computation.
I0924 21:06:14.173781  2642 net.cpp:198] Eltwise21 needs backward computation.
I0924 21:06:14.173784  2642 net.cpp:198] Scale45 needs backward computation.
I0924 21:06:14.173786  2642 net.cpp:198] BatchNorm45 needs backward computation.
I0924 21:06:14.173789  2642 net.cpp:198] Convolution45 needs backward computation.
I0924 21:06:14.173791  2642 net.cpp:198] ReLU42 needs backward computation.
I0924 21:06:14.173794  2642 net.cpp:198] Scale44 needs backward computation.
I0924 21:06:14.173799  2642 net.cpp:198] BatchNorm44 needs backward computation.
I0924 21:06:14.173800  2642 net.cpp:198] Convolution44 needs backward computation.
I0924 21:06:14.173804  2642 net.cpp:198] Eltwise20_ReLU41_0_split needs backward computation.
I0924 21:06:14.173806  2642 net.cpp:198] ReLU41 needs backward computation.
I0924 21:06:14.173808  2642 net.cpp:198] Eltwise20 needs backward computation.
I0924 21:06:14.173811  2642 net.cpp:198] Scale43 needs backward computation.
I0924 21:06:14.173813  2642 net.cpp:198] BatchNorm43 needs backward computation.
I0924 21:06:14.173815  2642 net.cpp:198] Convolution43 needs backward computation.
I0924 21:06:14.173818  2642 net.cpp:198] ReLU40 needs backward computation.
I0924 21:06:14.173820  2642 net.cpp:198] Scale42 needs backward computation.
I0924 21:06:14.173822  2642 net.cpp:198] BatchNorm42 needs backward computation.
I0924 21:06:14.173825  2642 net.cpp:198] Convolution42 needs backward computation.
I0924 21:06:14.173827  2642 net.cpp:198] Eltwise19_ReLU39_0_split needs backward computation.
I0924 21:06:14.173830  2642 net.cpp:198] ReLU39 needs backward computation.
I0924 21:06:14.173832  2642 net.cpp:198] Eltwise19 needs backward computation.
I0924 21:06:14.173835  2642 net.cpp:198] Scale41 needs backward computation.
I0924 21:06:14.173837  2642 net.cpp:198] BatchNorm41 needs backward computation.
I0924 21:06:14.173840  2642 net.cpp:198] Convolution41 needs backward computation.
I0924 21:06:14.173841  2642 net.cpp:198] ReLU38 needs backward computation.
I0924 21:06:14.173843  2642 net.cpp:198] Scale40 needs backward computation.
I0924 21:06:14.173846  2642 net.cpp:198] BatchNorm40 needs backward computation.
I0924 21:06:14.173848  2642 net.cpp:198] Convolution40 needs backward computation.
I0924 21:06:14.173851  2642 net.cpp:198] Scale39 needs backward computation.
I0924 21:06:14.173853  2642 net.cpp:198] BatchNorm39 needs backward computation.
I0924 21:06:14.173856  2642 net.cpp:198] Convolution39 needs backward computation.
I0924 21:06:14.173858  2642 net.cpp:198] Eltwise18_ReLU37_0_split needs backward computation.
I0924 21:06:14.173861  2642 net.cpp:198] ReLU37 needs backward computation.
I0924 21:06:14.173862  2642 net.cpp:198] Eltwise18 needs backward computation.
I0924 21:06:14.173866  2642 net.cpp:198] Scale38 needs backward computation.
I0924 21:06:14.173867  2642 net.cpp:198] BatchNorm38 needs backward computation.
I0924 21:06:14.173869  2642 net.cpp:198] Convolution38 needs backward computation.
I0924 21:06:14.173872  2642 net.cpp:198] ReLU36 needs backward computation.
I0924 21:06:14.173874  2642 net.cpp:198] Scale37 needs backward computation.
I0924 21:06:14.173877  2642 net.cpp:198] BatchNorm37 needs backward computation.
I0924 21:06:14.173879  2642 net.cpp:198] Convolution37 needs backward computation.
I0924 21:06:14.173882  2642 net.cpp:198] Eltwise17_ReLU35_0_split needs backward computation.
I0924 21:06:14.173883  2642 net.cpp:198] ReLU35 needs backward computation.
I0924 21:06:14.173887  2642 net.cpp:198] Eltwise17 needs backward computation.
I0924 21:06:14.173888  2642 net.cpp:198] Scale36 needs backward computation.
I0924 21:06:14.173892  2642 net.cpp:198] BatchNorm36 needs backward computation.
I0924 21:06:14.173893  2642 net.cpp:198] Convolution36 needs backward computation.
I0924 21:06:14.173895  2642 net.cpp:198] ReLU34 needs backward computation.
I0924 21:06:14.173898  2642 net.cpp:198] Scale35 needs backward computation.
I0924 21:06:14.173900  2642 net.cpp:198] BatchNorm35 needs backward computation.
I0924 21:06:14.173902  2642 net.cpp:198] Convolution35 needs backward computation.
I0924 21:06:14.173904  2642 net.cpp:198] Eltwise16_ReLU33_0_split needs backward computation.
I0924 21:06:14.173907  2642 net.cpp:198] ReLU33 needs backward computation.
I0924 21:06:14.173909  2642 net.cpp:198] Eltwise16 needs backward computation.
I0924 21:06:14.173912  2642 net.cpp:198] Scale34 needs backward computation.
I0924 21:06:14.173914  2642 net.cpp:198] BatchNorm34 needs backward computation.
I0924 21:06:14.173919  2642 net.cpp:198] Convolution34 needs backward computation.
I0924 21:06:14.173921  2642 net.cpp:198] ReLU32 needs backward computation.
I0924 21:06:14.173923  2642 net.cpp:198] Scale33 needs backward computation.
I0924 21:06:14.200575  2642 net.cpp:198] BatchNorm33 needs backward computation.
I0924 21:06:14.200583  2642 net.cpp:198] Convolution33 needs backward computation.
I0924 21:06:14.200587  2642 net.cpp:198] Eltwise15_ReLU31_0_split needs backward computation.
I0924 21:06:14.200590  2642 net.cpp:198] ReLU31 needs backward computation.
I0924 21:06:14.200593  2642 net.cpp:198] Eltwise15 needs backward computation.
I0924 21:06:14.200597  2642 net.cpp:198] Scale32 needs backward computation.
I0924 21:06:14.200598  2642 net.cpp:198] BatchNorm32 needs backward computation.
I0924 21:06:14.200601  2642 net.cpp:198] Convolution32 needs backward computation.
I0924 21:06:14.200603  2642 net.cpp:198] ReLU30 needs backward computation.
I0924 21:06:14.200606  2642 net.cpp:198] Scale31 needs backward computation.
I0924 21:06:14.200608  2642 net.cpp:198] BatchNorm31 needs backward computation.
I0924 21:06:14.200611  2642 net.cpp:198] Convolution31 needs backward computation.
I0924 21:06:14.200614  2642 net.cpp:198] Eltwise14_ReLU29_0_split needs backward computation.
I0924 21:06:14.200616  2642 net.cpp:198] ReLU29 needs backward computation.
I0924 21:06:14.200619  2642 net.cpp:198] Eltwise14 needs backward computation.
I0924 21:06:14.200623  2642 net.cpp:198] Scale30 needs backward computation.
I0924 21:06:14.200624  2642 net.cpp:198] BatchNorm30 needs backward computation.
I0924 21:06:14.200628  2642 net.cpp:198] Convolution30 needs backward computation.
I0924 21:06:14.200629  2642 net.cpp:198] ReLU28 needs backward computation.
I0924 21:06:14.200634  2642 net.cpp:198] Scale29 needs backward computation.
I0924 21:06:14.200636  2642 net.cpp:198] BatchNorm29 needs backward computation.
I0924 21:06:14.200639  2642 net.cpp:198] Convolution29 needs backward computation.
I0924 21:06:14.200641  2642 net.cpp:198] Eltwise13_ReLU27_0_split needs backward computation.
I0924 21:06:14.200644  2642 net.cpp:198] ReLU27 needs backward computation.
I0924 21:06:14.200647  2642 net.cpp:198] Eltwise13 needs backward computation.
I0924 21:06:14.200650  2642 net.cpp:198] Scale28 needs backward computation.
I0924 21:06:14.200652  2642 net.cpp:198] BatchNorm28 needs backward computation.
I0924 21:06:14.200654  2642 net.cpp:198] Convolution28 needs backward computation.
I0924 21:06:14.200657  2642 net.cpp:198] ReLU26 needs backward computation.
I0924 21:06:14.200659  2642 net.cpp:198] Scale27 needs backward computation.
I0924 21:06:14.200661  2642 net.cpp:198] BatchNorm27 needs backward computation.
I0924 21:06:14.200664  2642 net.cpp:198] Convolution27 needs backward computation.
I0924 21:06:14.200667  2642 net.cpp:198] Eltwise12_ReLU25_0_split needs backward computation.
I0924 21:06:14.200670  2642 net.cpp:198] ReLU25 needs backward computation.
I0924 21:06:14.200672  2642 net.cpp:198] Eltwise12 needs backward computation.
I0924 21:06:14.200675  2642 net.cpp:198] Scale26 needs backward computation.
I0924 21:06:14.200678  2642 net.cpp:198] BatchNorm26 needs backward computation.
I0924 21:06:14.200680  2642 net.cpp:198] Convolution26 needs backward computation.
I0924 21:06:14.200683  2642 net.cpp:198] ReLU24 needs backward computation.
I0924 21:06:14.200685  2642 net.cpp:198] Scale25 needs backward computation.
I0924 21:06:14.200688  2642 net.cpp:198] BatchNorm25 needs backward computation.
I0924 21:06:14.200690  2642 net.cpp:198] Convolution25 needs backward computation.
I0924 21:06:14.200693  2642 net.cpp:198] Eltwise11_ReLU23_0_split needs backward computation.
I0924 21:06:14.200695  2642 net.cpp:198] ReLU23 needs backward computation.
I0924 21:06:14.200698  2642 net.cpp:198] Eltwise11 needs backward computation.
I0924 21:06:14.200700  2642 net.cpp:198] Scale24 needs backward computation.
I0924 21:06:14.200703  2642 net.cpp:198] BatchNorm24 needs backward computation.
I0924 21:06:14.200706  2642 net.cpp:198] Convolution24 needs backward computation.
I0924 21:06:14.200716  2642 net.cpp:198] ReLU22 needs backward computation.
I0924 21:06:14.200718  2642 net.cpp:198] Scale23 needs backward computation.
I0924 21:06:14.200721  2642 net.cpp:198] BatchNorm23 needs backward computation.
I0924 21:06:14.200723  2642 net.cpp:198] Convolution23 needs backward computation.
I0924 21:06:14.200726  2642 net.cpp:198] Eltwise10_ReLU21_0_split needs backward computation.
I0924 21:06:14.200729  2642 net.cpp:198] ReLU21 needs backward computation.
I0924 21:06:14.200731  2642 net.cpp:198] Eltwise10 needs backward computation.
I0924 21:06:14.200734  2642 net.cpp:198] Scale22 needs backward computation.
I0924 21:06:14.200736  2642 net.cpp:198] BatchNorm22 needs backward computation.
I0924 21:06:14.200739  2642 net.cpp:198] Convolution22 needs backward computation.
I0924 21:06:14.200742  2642 net.cpp:198] ReLU20 needs backward computation.
I0924 21:06:14.200744  2642 net.cpp:198] Scale21 needs backward computation.
I0924 21:06:14.200747  2642 net.cpp:198] BatchNorm21 needs backward computation.
I0924 21:06:14.200749  2642 net.cpp:198] Convolution21 needs backward computation.
I0924 21:06:14.200752  2642 net.cpp:198] Scale20 needs backward computation.
I0924 21:06:14.200754  2642 net.cpp:198] BatchNorm20 needs backward computation.
I0924 21:06:14.200757  2642 net.cpp:198] Convolution20 needs backward computation.
I0924 21:06:14.200759  2642 net.cpp:198] Eltwise9_ReLU19_0_split needs backward computation.
I0924 21:06:14.200762  2642 net.cpp:198] ReLU19 needs backward computation.
I0924 21:06:14.200764  2642 net.cpp:198] Eltwise9 needs backward computation.
I0924 21:06:14.200767  2642 net.cpp:198] Scale19 needs backward computation.
I0924 21:06:14.200770  2642 net.cpp:198] BatchNorm19 needs backward computation.
I0924 21:06:14.200773  2642 net.cpp:198] Convolution19 needs backward computation.
I0924 21:06:14.200775  2642 net.cpp:198] ReLU18 needs backward computation.
I0924 21:06:14.200778  2642 net.cpp:198] Scale18 needs backward computation.
I0924 21:06:14.200780  2642 net.cpp:198] BatchNorm18 needs backward computation.
I0924 21:06:14.200783  2642 net.cpp:198] Convolution18 needs backward computation.
I0924 21:06:14.200785  2642 net.cpp:198] Eltwise8_ReLU17_0_split needs backward computation.
I0924 21:06:14.200788  2642 net.cpp:198] ReLU17 needs backward computation.
I0924 21:06:14.200790  2642 net.cpp:198] Eltwise8 needs backward computation.
I0924 21:06:14.200793  2642 net.cpp:198] Scale17 needs backward computation.
I0924 21:06:14.200795  2642 net.cpp:198] BatchNorm17 needs backward computation.
I0924 21:06:14.200798  2642 net.cpp:198] Convolution17 needs backward computation.
I0924 21:06:14.200801  2642 net.cpp:198] ReLU16 needs backward computation.
I0924 21:06:14.200803  2642 net.cpp:198] Scale16 needs backward computation.
I0924 21:06:14.200805  2642 net.cpp:198] BatchNorm16 needs backward computation.
I0924 21:06:14.200809  2642 net.cpp:198] Convolution16 needs backward computation.
I0924 21:06:14.200810  2642 net.cpp:198] Eltwise7_ReLU15_0_split needs backward computation.
I0924 21:06:14.200814  2642 net.cpp:198] ReLU15 needs backward computation.
I0924 21:06:14.200815  2642 net.cpp:198] Eltwise7 needs backward computation.
I0924 21:06:14.200819  2642 net.cpp:198] Scale15 needs backward computation.
I0924 21:06:14.200821  2642 net.cpp:198] BatchNorm15 needs backward computation.
I0924 21:06:14.200824  2642 net.cpp:198] Convolution15 needs backward computation.
I0924 21:06:14.200826  2642 net.cpp:198] ReLU14 needs backward computation.
I0924 21:06:14.200829  2642 net.cpp:198] Scale14 needs backward computation.
I0924 21:06:14.200830  2642 net.cpp:198] BatchNorm14 needs backward computation.
I0924 21:06:14.200832  2642 net.cpp:198] Convolution14 needs backward computation.
I0924 21:06:14.200835  2642 net.cpp:198] Eltwise6_ReLU13_0_split needs backward computation.
I0924 21:06:14.200839  2642 net.cpp:198] ReLU13 needs backward computation.
I0924 21:06:14.200840  2642 net.cpp:198] Eltwise6 needs backward computation.
I0924 21:06:14.200844  2642 net.cpp:198] Scale13 needs backward computation.
I0924 21:06:14.200850  2642 net.cpp:198] BatchNorm13 needs backward computation.
I0924 21:06:14.202615  2642 net.cpp:198] Convolution13 needs backward computation.
I0924 21:06:14.202622  2642 net.cpp:198] ReLU12 needs backward computation.
I0924 21:06:14.202625  2642 net.cpp:198] Scale12 needs backward computation.
I0924 21:06:14.202627  2642 net.cpp:198] BatchNorm12 needs backward computation.
I0924 21:06:14.202630  2642 net.cpp:198] Convolution12 needs backward computation.
I0924 21:06:14.202633  2642 net.cpp:198] Eltwise5_ReLU11_0_split needs backward computation.
I0924 21:06:14.202636  2642 net.cpp:198] ReLU11 needs backward computation.
I0924 21:06:14.202638  2642 net.cpp:198] Eltwise5 needs backward computation.
I0924 21:06:14.202641  2642 net.cpp:198] Scale11 needs backward computation.
I0924 21:06:14.202644  2642 net.cpp:198] BatchNorm11 needs backward computation.
I0924 21:06:14.202646  2642 net.cpp:198] Convolution11 needs backward computation.
I0924 21:06:14.202649  2642 net.cpp:198] ReLU10 needs backward computation.
I0924 21:06:14.202651  2642 net.cpp:198] Scale10 needs backward computation.
I0924 21:06:14.202653  2642 net.cpp:198] BatchNorm10 needs backward computation.
I0924 21:06:14.202656  2642 net.cpp:198] Convolution10 needs backward computation.
I0924 21:06:14.202659  2642 net.cpp:198] Eltwise4_ReLU9_0_split needs backward computation.
I0924 21:06:14.202662  2642 net.cpp:198] ReLU9 needs backward computation.
I0924 21:06:14.202664  2642 net.cpp:198] Eltwise4 needs backward computation.
I0924 21:06:14.202668  2642 net.cpp:198] Scale9 needs backward computation.
I0924 21:06:14.202671  2642 net.cpp:198] BatchNorm9 needs backward computation.
I0924 21:06:14.202673  2642 net.cpp:198] Convolution9 needs backward computation.
I0924 21:06:14.202675  2642 net.cpp:198] ReLU8 needs backward computation.
I0924 21:06:14.202678  2642 net.cpp:198] Scale8 needs backward computation.
I0924 21:06:14.202680  2642 net.cpp:198] BatchNorm8 needs backward computation.
I0924 21:06:14.202682  2642 net.cpp:198] Convolution8 needs backward computation.
I0924 21:06:14.202688  2642 net.cpp:198] Eltwise3_ReLU7_0_split needs backward computation.
I0924 21:06:14.202692  2642 net.cpp:198] ReLU7 needs backward computation.
I0924 21:06:14.202693  2642 net.cpp:198] Eltwise3 needs backward computation.
I0924 21:06:14.202697  2642 net.cpp:198] Scale7 needs backward computation.
I0924 21:06:14.202699  2642 net.cpp:198] BatchNorm7 needs backward computation.
I0924 21:06:14.202702  2642 net.cpp:198] Convolution7 needs backward computation.
I0924 21:06:14.202703  2642 net.cpp:198] ReLU6 needs backward computation.
I0924 21:06:14.202706  2642 net.cpp:198] Scale6 needs backward computation.
I0924 21:06:14.202708  2642 net.cpp:198] BatchNorm6 needs backward computation.
I0924 21:06:14.202710  2642 net.cpp:198] Convolution6 needs backward computation.
I0924 21:06:14.202713  2642 net.cpp:198] Eltwise2_ReLU5_0_split needs backward computation.
I0924 21:06:14.202715  2642 net.cpp:198] ReLU5 needs backward computation.
I0924 21:06:14.202718  2642 net.cpp:198] Eltwise2 needs backward computation.
I0924 21:06:14.202721  2642 net.cpp:198] Scale5 needs backward computation.
I0924 21:06:14.202723  2642 net.cpp:198] BatchNorm5 needs backward computation.
I0924 21:06:14.202725  2642 net.cpp:198] Convolution5 needs backward computation.
I0924 21:06:14.202728  2642 net.cpp:198] ReLU4 needs backward computation.
I0924 21:06:14.202730  2642 net.cpp:198] Scale4 needs backward computation.
I0924 21:06:14.202733  2642 net.cpp:198] BatchNorm4 needs backward computation.
I0924 21:06:14.202734  2642 net.cpp:198] Convolution4 needs backward computation.
I0924 21:06:14.202738  2642 net.cpp:198] Eltwise1_ReLU3_0_split needs backward computation.
I0924 21:06:14.202740  2642 net.cpp:198] ReLU3 needs backward computation.
I0924 21:06:14.202742  2642 net.cpp:198] Eltwise1 needs backward computation.
I0924 21:06:14.202745  2642 net.cpp:198] Scale3 needs backward computation.
I0924 21:06:14.202749  2642 net.cpp:198] BatchNorm3 needs backward computation.
I0924 21:06:14.202757  2642 net.cpp:198] Convolution3 needs backward computation.
I0924 21:06:14.202760  2642 net.cpp:198] ReLU2 needs backward computation.
I0924 21:06:14.202762  2642 net.cpp:198] Scale2 needs backward computation.
I0924 21:06:14.202765  2642 net.cpp:198] BatchNorm2 needs backward computation.
I0924 21:06:14.202767  2642 net.cpp:198] Convolution2 needs backward computation.
I0924 21:06:14.202770  2642 net.cpp:198] Convolution1_ReLU1_0_split needs backward computation.
I0924 21:06:14.202772  2642 net.cpp:198] ReLU1 needs backward computation.
I0924 21:06:14.202775  2642 net.cpp:198] Scale1 needs backward computation.
I0924 21:06:14.202777  2642 net.cpp:198] BatchNorm1 needs backward computation.
I0924 21:06:14.202780  2642 net.cpp:198] Convolution1 needs backward computation.
I0924 21:06:14.202782  2642 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I0924 21:06:14.202785  2642 net.cpp:200] Data1 does not need backward computation.
I0924 21:06:14.202787  2642 net.cpp:242] This network produces output Accuracy1
I0924 21:06:14.202790  2642 net.cpp:242] This network produces output SoftmaxWithLoss1
I0924 21:06:14.202894  2642 net.cpp:255] Network initialization done.
I0924 21:06:14.203718  2642 solver.cpp:56] Solver scaffolding done.
I0924 21:06:14.213891  2642 caffe.cpp:248] Starting Optimization
I0924 21:06:14.213896  2642 solver.cpp:272] Solving resnet_cifar10
I0924 21:06:14.213898  2642 solver.cpp:273] Learning Rate Policy: multistep
I0924 21:06:14.219034  2642 solver.cpp:330] Iteration 0, Testing net (#0)
I0924 21:06:17.445551  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:06:17.573141  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I0924 21:06:17.573168  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I0924 21:06:17.746507  2642 solver.cpp:218] Iteration 0 (-9.73872e-33 iter/s, 3.53251s/100 iters), loss = 2.29799
I0924 21:06:17.746537  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.29799 (* 1 = 2.29799 loss)
I0924 21:06:17.746547  2642 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I0924 21:06:31.250500  2642 solver.cpp:218] Iteration 100 (7.4053 iter/s, 13.5038s/100 iters), loss = 2.04774
I0924 21:06:31.250530  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.04774 (* 1 = 2.04774 loss)
I0924 21:06:31.250536  2642 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I0924 21:06:44.613441  2642 solver.cpp:218] Iteration 200 (7.48347 iter/s, 13.3628s/100 iters), loss = 2.01893
I0924 21:06:44.613523  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.01893 (* 1 = 2.01893 loss)
I0924 21:06:44.613529  2642 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I0924 21:06:57.977083  2642 solver.cpp:218] Iteration 300 (7.48311 iter/s, 13.3634s/100 iters), loss = 1.70898
I0924 21:06:57.977113  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.70898 (* 1 = 1.70898 loss)
I0924 21:06:57.977118  2642 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I0924 21:07:11.344903  2642 solver.cpp:218] Iteration 400 (7.48074 iter/s, 13.3677s/100 iters), loss = 1.50132
I0924 21:07:11.344934  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.50132 (* 1 = 1.50132 loss)
I0924 21:07:11.344940  2642 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I0924 21:07:24.036757  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:07:24.571193  2642 solver.cpp:330] Iteration 500, Testing net (#0)
I0924 21:07:27.646868  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:07:27.774642  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1044
I0924 21:07:27.774668  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 5.58873 (* 1 = 5.58873 loss)
I0924 21:07:27.907325  2642 solver.cpp:218] Iteration 500 (6.03783 iter/s, 16.5622s/100 iters), loss = 1.67633
I0924 21:07:27.907351  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.67633 (* 1 = 1.67633 loss)
I0924 21:07:27.907357  2642 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I0924 21:07:41.253304  2642 solver.cpp:218] Iteration 600 (7.49298 iter/s, 13.3458s/100 iters), loss = 1.41089
I0924 21:07:41.253332  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.41089 (* 1 = 1.41089 loss)
I0924 21:07:41.253338  2642 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I0924 21:07:54.650461  2642 solver.cpp:218] Iteration 700 (7.46436 iter/s, 13.397s/100 iters), loss = 1.49317
I0924 21:07:54.650614  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.49317 (* 1 = 1.49317 loss)
I0924 21:07:54.650635  2642 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I0924 21:08:08.057818  2642 solver.cpp:218] Iteration 800 (7.45874 iter/s, 13.4071s/100 iters), loss = 1.30194
I0924 21:08:08.057860  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.30194 (* 1 = 1.30194 loss)
I0924 21:08:08.057865  2642 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I0924 21:08:21.421546  2642 solver.cpp:218] Iteration 900 (7.48303 iter/s, 13.3636s/100 iters), loss = 1.03805
I0924 21:08:21.421586  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.03805 (* 1 = 1.03805 loss)
I0924 21:08:21.421592  2642 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I0924 21:08:34.137008  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:08:34.672206  2642 solver.cpp:330] Iteration 1000, Testing net (#0)
I0924 21:08:37.754113  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:08:37.882767  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1284
I0924 21:08:37.882803  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 7.51442 (* 1 = 7.51442 loss)
I0924 21:08:38.016086  2642 solver.cpp:218] Iteration 1000 (6.02615 iter/s, 16.5944s/100 iters), loss = 1.17204
I0924 21:08:38.016113  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.17204 (* 1 = 1.17204 loss)
I0924 21:08:38.016120  2642 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I0924 21:08:51.397028  2642 solver.cpp:218] Iteration 1100 (7.4734 iter/s, 13.3808s/100 iters), loss = 1.17221
I0924 21:08:51.397068  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.17221 (* 1 = 1.17221 loss)
I0924 21:08:51.397074  2642 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I0924 21:09:04.780004  2642 solver.cpp:218] Iteration 1200 (7.47227 iter/s, 13.3828s/100 iters), loss = 1.10507
I0924 21:09:04.780102  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.10507 (* 1 = 1.10507 loss)
I0924 21:09:04.780108  2642 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I0924 21:09:18.164140  2642 solver.cpp:218] Iteration 1300 (7.47164 iter/s, 13.3839s/100 iters), loss = 0.973563
I0924 21:09:18.164181  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.973563 (* 1 = 0.973563 loss)
I0924 21:09:18.164187  2642 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I0924 21:09:31.547029  2642 solver.cpp:218] Iteration 1400 (7.47231 iter/s, 13.3827s/100 iters), loss = 0.783422
I0924 21:09:31.547070  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.783422 (* 1 = 0.783422 loss)
I0924 21:09:31.547075  2642 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I0924 21:09:44.266252  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:09:44.802628  2642 solver.cpp:330] Iteration 1500, Testing net (#0)
I0924 21:09:47.884618  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:09:48.012877  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3235
I0924 21:09:48.012913  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.30364 (* 1 = 3.30364 loss)
I0924 21:09:48.145973  2642 solver.cpp:218] Iteration 1500 (6.02454 iter/s, 16.5988s/100 iters), loss = 1.08532
I0924 21:09:48.145999  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.08532 (* 1 = 1.08532 loss)
I0924 21:09:48.146006  2642 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I0924 21:10:01.522897  2642 solver.cpp:218] Iteration 1600 (7.47563 iter/s, 13.3768s/100 iters), loss = 0.885796
I0924 21:10:01.522927  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.885796 (* 1 = 0.885796 loss)
I0924 21:10:01.522933  2642 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I0924 21:10:14.901221  2642 solver.cpp:218] Iteration 1700 (7.47485 iter/s, 13.3782s/100 iters), loss = 0.834776
I0924 21:10:14.901340  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.834776 (* 1 = 0.834776 loss)
I0924 21:10:14.901347  2642 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I0924 21:10:28.277941  2642 solver.cpp:218] Iteration 1800 (7.47579 iter/s, 13.3765s/100 iters), loss = 0.781585
I0924 21:10:28.277982  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.781585 (* 1 = 0.781585 loss)
I0924 21:10:28.277988  2642 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I0924 21:10:41.651243  2642 solver.cpp:218] Iteration 1900 (7.47766 iter/s, 13.3732s/100 iters), loss = 0.796729
I0924 21:10:41.651273  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.796729 (* 1 = 0.796729 loss)
I0924 21:10:41.651279  2642 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I0924 21:10:54.367458  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:10:54.903254  2642 solver.cpp:330] Iteration 2000, Testing net (#0)
I0924 21:10:57.986752  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:10:58.115098  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.362
I0924 21:10:58.115134  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.05849 (* 1 = 3.05849 loss)
I0924 21:10:58.247874  2642 solver.cpp:218] Iteration 2000 (6.02537 iter/s, 16.5965s/100 iters), loss = 0.963912
I0924 21:10:58.247900  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.963912 (* 1 = 0.963912 loss)
I0924 21:10:58.247907  2642 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I0924 21:11:11.626237  2642 solver.cpp:218] Iteration 2100 (7.47482 iter/s, 13.3783s/100 iters), loss = 0.716346
I0924 21:11:11.626278  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.716346 (* 1 = 0.716346 loss)
I0924 21:11:11.626284  2642 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I0924 21:11:25.005513  2642 solver.cpp:218] Iteration 2200 (7.47431 iter/s, 13.3792s/100 iters), loss = 0.723193
I0924 21:11:25.005581  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.723193 (* 1 = 0.723193 loss)
I0924 21:11:25.005589  2642 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I0924 21:11:38.382215  2642 solver.cpp:218] Iteration 2300 (7.47576 iter/s, 13.3766s/100 iters), loss = 0.761518
I0924 21:11:38.382256  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.761518 (* 1 = 0.761518 loss)
I0924 21:11:38.382261  2642 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I0924 21:11:51.765061  2642 solver.cpp:218] Iteration 2400 (7.47231 iter/s, 13.3827s/100 iters), loss = 0.681762
I0924 21:11:51.765102  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.681762 (* 1 = 0.681762 loss)
I0924 21:11:51.765108  2642 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I0924 21:12:04.479919  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:12:05.015599  2642 solver.cpp:330] Iteration 2500, Testing net (#0)
I0924 21:12:08.098708  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:12:08.227330  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5251
I0924 21:12:08.227356  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.50346 (* 1 = 1.50346 loss)
I0924 21:12:08.360050  2642 solver.cpp:218] Iteration 2500 (6.02596 iter/s, 16.5949s/100 iters), loss = 0.688347
I0924 21:12:08.360076  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.688347 (* 1 = 0.688347 loss)
I0924 21:12:08.360083  2642 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I0924 21:12:21.745244  2642 solver.cpp:218] Iteration 2600 (7.47099 iter/s, 13.3851s/100 iters), loss = 0.48811
I0924 21:12:21.745283  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.48811 (* 1 = 0.48811 loss)
I0924 21:12:21.745290  2642 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I0924 21:12:35.127391  2642 solver.cpp:218] Iteration 2700 (7.4727 iter/s, 13.382s/100 iters), loss = 0.620158
I0924 21:12:35.127518  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.620158 (* 1 = 0.620158 loss)
I0924 21:12:35.127526  2642 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I0924 21:12:48.513952  2642 solver.cpp:218] Iteration 2800 (7.47028 iter/s, 13.3864s/100 iters), loss = 0.715534
I0924 21:12:48.513984  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.715534 (* 1 = 0.715534 loss)
I0924 21:12:48.513990  2642 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I0924 21:13:01.903321  2642 solver.cpp:218] Iteration 2900 (7.46866 iter/s, 13.3893s/100 iters), loss = 0.603746
I0924 21:13:01.903350  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.603746 (* 1 = 0.603746 loss)
I0924 21:13:01.903357  2642 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I0924 21:13:14.621136  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:13:15.157335  2642 solver.cpp:330] Iteration 3000, Testing net (#0)
I0924 21:13:18.241330  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:13:18.370016  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.652
I0924 21:13:18.370052  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.01121 (* 1 = 1.01121 loss)
I0924 21:13:18.504089  2642 solver.cpp:218] Iteration 3000 (6.02385 iter/s, 16.6007s/100 iters), loss = 0.651093
I0924 21:13:18.504117  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.651093 (* 1 = 0.651093 loss)
I0924 21:13:18.504124  2642 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I0924 21:13:31.879938  2642 solver.cpp:218] Iteration 3100 (7.47621 iter/s, 13.3758s/100 iters), loss = 0.484725
I0924 21:13:31.879981  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.484725 (* 1 = 0.484725 loss)
I0924 21:13:31.879987  2642 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I0924 21:13:45.259652  2642 solver.cpp:218] Iteration 3200 (7.47406 iter/s, 13.3796s/100 iters), loss = 0.637954
I0924 21:13:45.259721  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.637954 (* 1 = 0.637954 loss)
I0924 21:13:45.259727  2642 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I0924 21:13:58.642094  2642 solver.cpp:218] Iteration 3300 (7.47255 iter/s, 13.3823s/100 iters), loss = 0.601836
I0924 21:13:58.642137  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.601836 (* 1 = 0.601836 loss)
I0924 21:13:58.642143  2642 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I0924 21:14:12.025234  2642 solver.cpp:218] Iteration 3400 (7.47214 iter/s, 13.383s/100 iters), loss = 0.617709
I0924 21:14:12.025274  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.617709 (* 1 = 0.617709 loss)
I0924 21:14:12.025280  2642 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I0924 21:14:24.743203  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:14:25.277918  2642 solver.cpp:330] Iteration 3500, Testing net (#0)
I0924 21:14:28.361138  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:14:28.489722  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5533
I0924 21:14:28.489758  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.23697 (* 1 = 1.23697 loss)
I0924 21:14:28.622762  2642 solver.cpp:218] Iteration 3500 (6.02503 iter/s, 16.5974s/100 iters), loss = 0.61593
I0924 21:14:28.622789  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.61593 (* 1 = 0.61593 loss)
I0924 21:14:28.622797  2642 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I0924 21:14:42.008028  2642 solver.cpp:218] Iteration 3600 (7.47095 iter/s, 13.3852s/100 iters), loss = 0.476261
I0924 21:14:42.008069  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.476261 (* 1 = 0.476261 loss)
I0924 21:14:42.008075  2642 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I0924 21:14:55.389863  2642 solver.cpp:218] Iteration 3700 (7.47287 iter/s, 13.3817s/100 iters), loss = 0.417745
I0924 21:14:55.389945  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.417745 (* 1 = 0.417745 loss)
I0924 21:14:55.389952  2642 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I0924 21:15:08.775588  2642 solver.cpp:218] Iteration 3800 (7.47072 iter/s, 13.3856s/100 iters), loss = 0.572869
I0924 21:15:08.775629  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.572869 (* 1 = 0.572869 loss)
I0924 21:15:08.775635  2642 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I0924 21:15:22.158247  2642 solver.cpp:218] Iteration 3900 (7.47241 iter/s, 13.3826s/100 iters), loss = 0.550447
I0924 21:15:22.158289  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.550447 (* 1 = 0.550447 loss)
I0924 21:15:22.158295  2642 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I0924 21:15:34.880043  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:15:35.416285  2642 solver.cpp:330] Iteration 4000, Testing net (#0)
I0924 21:15:38.500509  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:15:38.628641  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5515
I0924 21:15:38.628679  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.23179 (* 1 = 1.23179 loss)
I0924 21:15:38.761430  2642 solver.cpp:218] Iteration 4000 (6.02298 iter/s, 16.6031s/100 iters), loss = 0.481285
I0924 21:15:38.761457  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.481285 (* 1 = 0.481285 loss)
I0924 21:15:38.761463  2642 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I0924 21:15:52.142323  2642 solver.cpp:218] Iteration 4100 (7.47339 iter/s, 13.3808s/100 iters), loss = 0.389059
I0924 21:15:52.142364  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.389059 (* 1 = 0.389059 loss)
I0924 21:15:52.142369  2642 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I0924 21:16:05.529749  2642 solver.cpp:218] Iteration 4200 (7.46975 iter/s, 13.3873s/100 iters), loss = 0.468438
I0924 21:16:05.529819  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.468438 (* 1 = 0.468438 loss)
I0924 21:16:05.529825  2642 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I0924 21:16:18.910264  2642 solver.cpp:218] Iteration 4300 (7.47362 iter/s, 13.3804s/100 iters), loss = 0.50378
I0924 21:16:18.910295  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.50378 (* 1 = 0.50378 loss)
I0924 21:16:18.910301  2642 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I0924 21:16:32.294766  2642 solver.cpp:218] Iteration 4400 (7.47137 iter/s, 13.3844s/100 iters), loss = 0.442184
I0924 21:16:32.294807  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.442184 (* 1 = 0.442184 loss)
I0924 21:16:32.294813  2642 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I0924 21:16:45.018987  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:16:45.555352  2642 solver.cpp:330] Iteration 4500, Testing net (#0)
I0924 21:16:48.639161  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:16:48.767153  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6217
I0924 21:16:48.767189  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.02681 (* 1 = 1.02681 loss)
I0924 21:16:48.901156  2642 solver.cpp:218] Iteration 4500 (6.02182 iter/s, 16.6063s/100 iters), loss = 0.472314
I0924 21:16:48.901183  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.472314 (* 1 = 0.472314 loss)
I0924 21:16:48.901190  2642 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I0924 21:17:02.305584  2642 solver.cpp:218] Iteration 4600 (7.46027 iter/s, 13.4043s/100 iters), loss = 0.396195
I0924 21:17:02.305625  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.396195 (* 1 = 0.396195 loss)
I0924 21:17:02.305631  2642 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I0924 21:17:15.706041  2642 solver.cpp:218] Iteration 4700 (7.46248 iter/s, 13.4004s/100 iters), loss = 0.400166
I0924 21:17:15.706171  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.400167 (* 1 = 0.400167 loss)
I0924 21:17:15.706177  2642 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I0924 21:17:29.096637  2642 solver.cpp:218] Iteration 4800 (7.46802 iter/s, 13.3904s/100 iters), loss = 0.479229
I0924 21:17:29.096675  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.479229 (* 1 = 0.479229 loss)
I0924 21:17:29.096681  2642 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I0924 21:17:42.497334  2642 solver.cpp:218] Iteration 4900 (7.46235 iter/s, 13.4006s/100 iters), loss = 0.426145
I0924 21:17:42.497375  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.426146 (* 1 = 0.426146 loss)
I0924 21:17:42.497380  2642 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I0924 21:17:55.223860  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:17:55.759621  2642 solver.cpp:330] Iteration 5000, Testing net (#0)
I0924 21:17:58.846452  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:17:58.975072  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5409
I0924 21:17:58.975107  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.2751 (* 1 = 1.2751 loss)
I0924 21:17:59.108412  2642 solver.cpp:218] Iteration 5000 (6.02012 iter/s, 16.611s/100 iters), loss = 0.40538
I0924 21:17:59.108439  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.40538 (* 1 = 0.40538 loss)
I0924 21:17:59.108446  2642 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I0924 21:18:12.502348  2642 solver.cpp:218] Iteration 5100 (7.46611 iter/s, 13.3939s/100 iters), loss = 0.431721
I0924 21:18:12.502390  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.431721 (* 1 = 0.431721 loss)
I0924 21:18:12.502396  2642 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I0924 21:18:25.906255  2642 solver.cpp:218] Iteration 5200 (7.46056 iter/s, 13.4038s/100 iters), loss = 0.425786
I0924 21:18:25.906383  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.425786 (* 1 = 0.425786 loss)
I0924 21:18:25.906391  2642 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I0924 21:18:39.303880  2642 solver.cpp:218] Iteration 5300 (7.46411 iter/s, 13.3974s/100 iters), loss = 0.446494
I0924 21:18:39.303921  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.446494 (* 1 = 0.446494 loss)
I0924 21:18:39.303927  2642 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I0924 21:18:52.705243  2642 solver.cpp:218] Iteration 5400 (7.46198 iter/s, 13.4013s/100 iters), loss = 0.456942
I0924 21:18:52.705283  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.456942 (* 1 = 0.456942 loss)
I0924 21:18:52.705289  2642 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I0924 21:19:05.443403  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:19:05.979631  2642 solver.cpp:330] Iteration 5500, Testing net (#0)
I0924 21:19:09.066668  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:19:09.194819  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7109
I0924 21:19:09.194856  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.83091 (* 1 = 0.83091 loss)
I0924 21:19:09.328493  2642 solver.cpp:218] Iteration 5500 (6.01571 iter/s, 16.6231s/100 iters), loss = 0.324653
I0924 21:19:09.328521  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324653 (* 1 = 0.324653 loss)
I0924 21:19:09.328527  2642 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I0924 21:19:22.739878  2642 solver.cpp:218] Iteration 5600 (7.45639 iter/s, 13.4113s/100 iters), loss = 0.336474
I0924 21:19:22.739919  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336474 (* 1 = 0.336474 loss)
I0924 21:19:22.739925  2642 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I0924 21:19:36.152658  2642 solver.cpp:218] Iteration 5700 (7.45563 iter/s, 13.4127s/100 iters), loss = 0.441422
I0924 21:19:36.152763  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.441422 (* 1 = 0.441422 loss)
I0924 21:19:36.152770  2642 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I0924 21:19:49.564256  2642 solver.cpp:218] Iteration 5800 (7.45632 iter/s, 13.4114s/100 iters), loss = 0.394139
I0924 21:19:49.564299  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.39414 (* 1 = 0.39414 loss)
I0924 21:19:49.564304  2642 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I0924 21:20:02.975599  2642 solver.cpp:218] Iteration 5900 (7.45643 iter/s, 13.4113s/100 iters), loss = 0.405799
I0924 21:20:02.975639  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405799 (* 1 = 0.405799 loss)
I0924 21:20:02.975644  2642 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I0924 21:20:15.717037  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:20:16.253383  2642 solver.cpp:330] Iteration 6000, Testing net (#0)
I0924 21:20:19.340507  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:20:19.469687  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.605
I0924 21:20:19.469723  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.12816 (* 1 = 1.12816 loss)
I0924 21:20:19.603375  2642 solver.cpp:218] Iteration 6000 (6.01407 iter/s, 16.6277s/100 iters), loss = 0.424852
I0924 21:20:19.603401  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.424853 (* 1 = 0.424853 loss)
I0924 21:20:19.603408  2642 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I0924 21:20:33.007220  2642 solver.cpp:218] Iteration 6100 (7.46059 iter/s, 13.4038s/100 iters), loss = 0.357284
I0924 21:20:33.007261  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.357284 (* 1 = 0.357284 loss)
I0924 21:20:33.007266  2642 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I0924 21:20:46.417814  2642 solver.cpp:218] Iteration 6200 (7.45684 iter/s, 13.4105s/100 iters), loss = 0.388876
I0924 21:20:46.417886  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.388876 (* 1 = 0.388876 loss)
I0924 21:20:46.417892  2642 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I0924 21:20:59.825834  2642 solver.cpp:218] Iteration 6300 (7.45829 iter/s, 13.4079s/100 iters), loss = 0.429259
I0924 21:20:59.825867  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.429259 (* 1 = 0.429259 loss)
I0924 21:20:59.825875  2642 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I0924 21:21:13.234236  2642 solver.cpp:218] Iteration 6400 (7.45806 iter/s, 13.4083s/100 iters), loss = 0.359551
I0924 21:21:13.234277  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.359551 (* 1 = 0.359551 loss)
I0924 21:21:13.234282  2642 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I0924 21:21:25.973773  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:21:26.510670  2642 solver.cpp:330] Iteration 6500, Testing net (#0)
I0924 21:21:29.599063  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:21:29.727608  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6746
I0924 21:21:29.727644  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.933668 (* 1 = 0.933668 loss)
I0924 21:21:29.860788  2642 solver.cpp:218] Iteration 6500 (6.01451 iter/s, 16.6265s/100 iters), loss = 0.344207
I0924 21:21:29.860815  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344207 (* 1 = 0.344207 loss)
I0924 21:21:29.860821  2642 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I0924 21:21:43.266114  2642 solver.cpp:218] Iteration 6600 (7.45976 iter/s, 13.4052s/100 iters), loss = 0.27775
I0924 21:21:43.266155  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27775 (* 1 = 0.27775 loss)
I0924 21:21:43.266161  2642 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I0924 21:21:56.675009  2642 solver.cpp:218] Iteration 6700 (7.45779 iter/s, 13.4088s/100 iters), loss = 0.357921
I0924 21:21:56.675106  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.357921 (* 1 = 0.357921 loss)
I0924 21:21:56.675112  2642 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I0924 21:22:10.078436  2642 solver.cpp:218] Iteration 6800 (7.46085 iter/s, 13.4033s/100 iters), loss = 0.377096
I0924 21:22:10.078465  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.377096 (* 1 = 0.377096 loss)
I0924 21:22:10.078471  2642 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I0924 21:22:23.484369  2642 solver.cpp:218] Iteration 6900 (7.45943 iter/s, 13.4059s/100 iters), loss = 0.348421
I0924 21:22:23.484408  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.348421 (* 1 = 0.348421 loss)
I0924 21:22:23.484414  2642 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I0924 21:22:36.224050  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:22:36.761032  2642 solver.cpp:330] Iteration 7000, Testing net (#0)
I0924 21:22:39.848564  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:22:39.977325  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6651
I0924 21:22:39.977361  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.00678 (* 1 = 1.00678 loss)
I0924 21:22:40.110370  2642 solver.cpp:218] Iteration 7000 (6.01471 iter/s, 16.6259s/100 iters), loss = 0.330074
I0924 21:22:40.110396  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330074 (* 1 = 0.330074 loss)
I0924 21:22:40.110404  2642 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I0924 21:22:53.517928  2642 solver.cpp:218] Iteration 7100 (7.45852 iter/s, 13.4075s/100 iters), loss = 0.330585
I0924 21:22:53.517969  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330585 (* 1 = 0.330585 loss)
I0924 21:22:53.517976  2642 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I0924 21:23:06.924873  2642 solver.cpp:218] Iteration 7200 (7.45887 iter/s, 13.4069s/100 iters), loss = 0.344873
I0924 21:23:06.924950  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344873 (* 1 = 0.344873 loss)
I0924 21:23:06.924958  2642 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I0924 21:23:20.330634  2642 solver.cpp:218] Iteration 7300 (7.45955 iter/s, 13.4056s/100 iters), loss = 0.360933
I0924 21:23:20.330675  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.360933 (* 1 = 0.360933 loss)
I0924 21:23:20.330680  2642 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I0924 21:23:33.738907  2642 solver.cpp:218] Iteration 7400 (7.45813 iter/s, 13.4082s/100 iters), loss = 0.397846
I0924 21:23:33.738947  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.397846 (* 1 = 0.397846 loss)
I0924 21:23:33.738953  2642 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I0924 21:23:46.484248  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:23:47.020313  2642 solver.cpp:330] Iteration 7500, Testing net (#0)
I0924 21:23:50.108177  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:23:50.236068  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6396
I0924 21:23:50.236104  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.10384 (* 1 = 1.10384 loss)
I0924 21:23:50.369385  2642 solver.cpp:218] Iteration 7500 (6.01309 iter/s, 16.6304s/100 iters), loss = 0.337305
I0924 21:23:50.369410  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337305 (* 1 = 0.337305 loss)
I0924 21:23:50.369416  2642 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I0924 21:24:03.773205  2642 solver.cpp:218] Iteration 7600 (7.4606 iter/s, 13.4037s/100 iters), loss = 0.263593
I0924 21:24:03.773247  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263593 (* 1 = 0.263593 loss)
I0924 21:24:03.773252  2642 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I0924 21:24:17.180951  2642 solver.cpp:218] Iteration 7700 (7.45842 iter/s, 13.4077s/100 iters), loss = 0.412067
I0924 21:24:17.181051  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.412067 (* 1 = 0.412067 loss)
I0924 21:24:17.181057  2642 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I0924 21:24:30.588903  2642 solver.cpp:218] Iteration 7800 (7.45833 iter/s, 13.4078s/100 iters), loss = 0.40411
I0924 21:24:30.588934  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.404111 (* 1 = 0.404111 loss)
I0924 21:24:30.588939  2642 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I0924 21:24:43.989233  2642 solver.cpp:218] Iteration 7900 (7.46255 iter/s, 13.4003s/100 iters), loss = 0.370761
I0924 21:24:43.989272  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.370761 (* 1 = 0.370761 loss)
I0924 21:24:43.989277  2642 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I0924 21:24:56.729317  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:24:57.265708  2642 solver.cpp:330] Iteration 8000, Testing net (#0)
I0924 21:25:00.352208  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:25:00.480696  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4436
I0924 21:25:00.480722  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.90948 (* 1 = 1.90948 loss)
I0924 21:25:00.614037  2642 solver.cpp:218] Iteration 8000 (6.01514 iter/s, 16.6247s/100 iters), loss = 0.350766
I0924 21:25:00.614063  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350766 (* 1 = 0.350766 loss)
I0924 21:25:00.614068  2642 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I0924 21:25:14.020023  2642 solver.cpp:218] Iteration 8100 (7.45939 iter/s, 13.4059s/100 iters), loss = 0.31952
I0924 21:25:14.020051  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31952 (* 1 = 0.31952 loss)
I0924 21:25:14.020056  2642 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I0924 21:25:27.428033  2642 solver.cpp:218] Iteration 8200 (7.45827 iter/s, 13.4079s/100 iters), loss = 0.353414
I0924 21:25:27.428109  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.353414 (* 1 = 0.353414 loss)
I0924 21:25:27.428117  2642 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I0924 21:25:40.838320  2642 solver.cpp:218] Iteration 8300 (7.45703 iter/s, 13.4102s/100 iters), loss = 0.342732
I0924 21:25:40.838351  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342732 (* 1 = 0.342732 loss)
I0924 21:25:40.838356  2642 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I0924 21:25:54.247205  2642 solver.cpp:218] Iteration 8400 (7.45778 iter/s, 13.4088s/100 iters), loss = 0.313437
I0924 21:25:54.247242  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313437 (* 1 = 0.313437 loss)
I0924 21:25:54.247248  2642 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I0924 21:26:06.987990  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:26:07.525077  2642 solver.cpp:330] Iteration 8500, Testing net (#0)
I0924 21:26:10.610985  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:26:10.739776  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7903
I0924 21:26:10.739811  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.617575 (* 1 = 0.617575 loss)
I0924 21:26:10.873108  2642 solver.cpp:218] Iteration 8500 (6.01474 iter/s, 16.6258s/100 iters), loss = 0.260015
I0924 21:26:10.873134  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260015 (* 1 = 0.260015 loss)
I0924 21:26:10.873142  2642 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I0924 21:26:24.285362  2642 solver.cpp:218] Iteration 8600 (7.45591 iter/s, 13.4122s/100 iters), loss = 0.329694
I0924 21:26:24.285392  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329694 (* 1 = 0.329694 loss)
I0924 21:26:24.285408  2642 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I0924 21:26:37.698168  2642 solver.cpp:218] Iteration 8700 (7.4556 iter/s, 13.4127s/100 iters), loss = 0.280121
I0924 21:26:37.698258  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280121 (* 1 = 0.280121 loss)
I0924 21:26:37.698276  2642 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I0924 21:26:51.111117  2642 solver.cpp:218] Iteration 8800 (7.45556 iter/s, 13.4128s/100 iters), loss = 0.401328
I0924 21:26:51.111147  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.401328 (* 1 = 0.401328 loss)
I0924 21:26:51.111153  2642 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I0924 21:27:04.526393  2642 solver.cpp:218] Iteration 8900 (7.45423 iter/s, 13.4152s/100 iters), loss = 0.338212
I0924 21:27:04.526423  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338212 (* 1 = 0.338212 loss)
I0924 21:27:04.526438  2642 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I0924 21:27:17.266357  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:27:17.802973  2642 solver.cpp:330] Iteration 9000, Testing net (#0)
I0924 21:27:20.889659  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:27:21.018196  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7971
I0924 21:27:21.018232  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.597479 (* 1 = 0.597479 loss)
I0924 21:27:21.151115  2642 solver.cpp:218] Iteration 9000 (6.01517 iter/s, 16.6246s/100 iters), loss = 0.309531
I0924 21:27:21.151141  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309531 (* 1 = 0.309531 loss)
I0924 21:27:21.151149  2642 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I0924 21:27:34.561823  2642 solver.cpp:218] Iteration 9100 (7.45677 iter/s, 13.4106s/100 iters), loss = 0.368793
I0924 21:27:34.561853  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.368792 (* 1 = 0.368792 loss)
I0924 21:27:34.561859  2642 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I0924 21:27:47.969907  2642 solver.cpp:218] Iteration 9200 (7.45823 iter/s, 13.408s/100 iters), loss = 0.33226
I0924 21:27:47.969965  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.33226 (* 1 = 0.33226 loss)
I0924 21:27:47.969982  2642 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I0924 21:28:01.379056  2642 solver.cpp:218] Iteration 9300 (7.45765 iter/s, 13.409s/100 iters), loss = 0.296605
I0924 21:28:01.379088  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296605 (* 1 = 0.296605 loss)
I0924 21:28:01.379104  2642 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I0924 21:28:14.791185  2642 solver.cpp:218] Iteration 9400 (7.45598 iter/s, 13.4121s/100 iters), loss = 0.290387
I0924 21:28:14.791214  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290387 (* 1 = 0.290387 loss)
I0924 21:28:14.791219  2642 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I0924 21:28:27.527474  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:28:28.063534  2642 solver.cpp:330] Iteration 9500, Testing net (#0)
I0924 21:28:31.149854  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:28:31.278482  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7666
I0924 21:28:31.278518  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.699571 (* 1 = 0.699571 loss)
I0924 21:28:31.411530  2642 solver.cpp:218] Iteration 9500 (6.01675 iter/s, 16.6203s/100 iters), loss = 0.350604
I0924 21:28:31.411554  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350604 (* 1 = 0.350604 loss)
I0924 21:28:31.411561  2642 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I0924 21:28:44.809458  2642 solver.cpp:218] Iteration 9600 (7.46388 iter/s, 13.3979s/100 iters), loss = 0.367063
I0924 21:28:44.809489  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.367063 (* 1 = 0.367063 loss)
I0924 21:28:44.809494  2642 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I0924 21:28:58.214395  2642 solver.cpp:218] Iteration 9700 (7.45998 iter/s, 13.4049s/100 iters), loss = 0.308424
I0924 21:28:58.214452  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308424 (* 1 = 0.308424 loss)
I0924 21:28:58.214469  2642 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I0924 21:29:11.626072  2642 solver.cpp:218] Iteration 9800 (7.45624 iter/s, 13.4116s/100 iters), loss = 0.423122
I0924 21:29:11.626103  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.423122 (* 1 = 0.423122 loss)
I0924 21:29:11.626119  2642 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I0924 21:29:25.025468  2642 solver.cpp:218] Iteration 9900 (7.46307 iter/s, 13.3993s/100 iters), loss = 0.322301
I0924 21:29:25.025498  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322301 (* 1 = 0.322301 loss)
I0924 21:29:25.025504  2642 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I0924 21:29:37.762399  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:29:38.298507  2642 solver.cpp:330] Iteration 10000, Testing net (#0)
I0924 21:29:41.385016  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:29:41.513628  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7661
I0924 21:29:41.513664  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.708643 (* 1 = 0.708643 loss)
I0924 21:29:41.647084  2642 solver.cpp:218] Iteration 10000 (6.01629 iter/s, 16.6215s/100 iters), loss = 0.379973
I0924 21:29:41.647111  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.379972 (* 1 = 0.379972 loss)
I0924 21:29:41.647119  2642 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I0924 21:29:55.052701  2642 solver.cpp:218] Iteration 10100 (7.4596 iter/s, 13.4055s/100 iters), loss = 0.271324
I0924 21:29:55.052731  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271323 (* 1 = 0.271323 loss)
I0924 21:29:55.052737  2642 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I0924 21:30:08.460952  2642 solver.cpp:218] Iteration 10200 (7.45814 iter/s, 13.4082s/100 iters), loss = 0.220902
I0924 21:30:08.461016  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220902 (* 1 = 0.220902 loss)
I0924 21:30:08.461033  2642 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I0924 21:30:21.872071  2642 solver.cpp:218] Iteration 10300 (7.45656 iter/s, 13.411s/100 iters), loss = 0.284152
I0924 21:30:21.872102  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284152 (* 1 = 0.284152 loss)
I0924 21:30:21.872117  2642 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I0924 21:30:35.284947  2642 solver.cpp:218] Iteration 10400 (7.45556 iter/s, 13.4128s/100 iters), loss = 0.354429
I0924 21:30:35.284978  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.354429 (* 1 = 0.354429 loss)
I0924 21:30:35.284993  2642 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I0924 21:30:48.029958  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:30:48.566097  2642 solver.cpp:330] Iteration 10500, Testing net (#0)
I0924 21:30:51.652825  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:30:51.781630  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8174
I0924 21:30:51.781666  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.552476 (* 1 = 0.552476 loss)
I0924 21:30:51.915405  2642 solver.cpp:218] Iteration 10500 (6.01309 iter/s, 16.6304s/100 iters), loss = 0.252724
I0924 21:30:51.915431  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252724 (* 1 = 0.252724 loss)
I0924 21:30:51.915438  2642 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I0924 21:31:05.320457  2642 solver.cpp:218] Iteration 10600 (7.45991 iter/s, 13.405s/100 iters), loss = 0.261875
I0924 21:31:05.320487  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261875 (* 1 = 0.261875 loss)
I0924 21:31:05.320503  2642 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I0924 21:31:18.732548  2642 solver.cpp:218] Iteration 10700 (7.456 iter/s, 13.412s/100 iters), loss = 0.330574
I0924 21:31:18.732604  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330574 (* 1 = 0.330574 loss)
I0924 21:31:18.732611  2642 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I0924 21:31:32.136076  2642 solver.cpp:218] Iteration 10800 (7.46078 iter/s, 13.4034s/100 iters), loss = 0.330655
I0924 21:31:32.136108  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330655 (* 1 = 0.330655 loss)
I0924 21:31:32.136124  2642 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I0924 21:31:45.548619  2642 solver.cpp:218] Iteration 10900 (7.45575 iter/s, 13.4125s/100 iters), loss = 0.284038
I0924 21:31:45.548650  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284037 (* 1 = 0.284037 loss)
I0924 21:31:45.548666  2642 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I0924 21:31:58.289733  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:31:58.825886  2642 solver.cpp:330] Iteration 11000, Testing net (#0)
I0924 21:32:01.914849  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:32:02.043215  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7296
I0924 21:32:02.043251  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.807893 (* 1 = 0.807893 loss)
I0924 21:32:02.176120  2642 solver.cpp:218] Iteration 11000 (6.01416 iter/s, 16.6274s/100 iters), loss = 0.284048
I0924 21:32:02.176144  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284048 (* 1 = 0.284048 loss)
I0924 21:32:02.176151  2642 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I0924 21:32:15.575888  2642 solver.cpp:218] Iteration 11100 (7.46285 iter/s, 13.3997s/100 iters), loss = 0.32374
I0924 21:32:15.575919  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323739 (* 1 = 0.323739 loss)
I0924 21:32:15.575934  2642 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I0924 21:32:28.978678  2642 solver.cpp:218] Iteration 11200 (7.46117 iter/s, 13.4027s/100 iters), loss = 0.373683
I0924 21:32:28.978766  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.373683 (* 1 = 0.373683 loss)
I0924 21:32:28.978782  2642 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I0924 21:32:42.389089  2642 solver.cpp:218] Iteration 11300 (7.45696 iter/s, 13.4103s/100 iters), loss = 0.33988
I0924 21:32:42.389119  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.33988 (* 1 = 0.33988 loss)
I0924 21:32:42.389134  2642 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I0924 21:32:55.792758  2642 solver.cpp:218] Iteration 11400 (7.46068 iter/s, 13.4036s/100 iters), loss = 0.292753
I0924 21:32:55.792788  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292753 (* 1 = 0.292753 loss)
I0924 21:32:55.792804  2642 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I0924 21:33:08.533960  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:33:09.070961  2642 solver.cpp:330] Iteration 11500, Testing net (#0)
I0924 21:33:12.159338  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:33:12.287091  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7684
I0924 21:33:12.287127  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.664886 (* 1 = 0.664886 loss)
I0924 21:33:12.420217  2642 solver.cpp:218] Iteration 11500 (6.01418 iter/s, 16.6274s/100 iters), loss = 0.261957
I0924 21:33:12.420241  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261957 (* 1 = 0.261957 loss)
I0924 21:33:12.420248  2642 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I0924 21:33:25.833967  2642 solver.cpp:218] Iteration 11600 (7.45508 iter/s, 13.4137s/100 iters), loss = 0.215918
I0924 21:33:25.834007  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215918 (* 1 = 0.215918 loss)
I0924 21:33:25.834013  2642 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I0924 21:33:39.241468  2642 solver.cpp:218] Iteration 11700 (7.45856 iter/s, 13.4074s/100 iters), loss = 0.232208
I0924 21:33:39.241581  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232208 (* 1 = 0.232208 loss)
I0924 21:33:39.241600  2642 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I0924 21:33:52.649158  2642 solver.cpp:218] Iteration 11800 (7.45849 iter/s, 13.4075s/100 iters), loss = 0.322709
I0924 21:33:52.649199  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322709 (* 1 = 0.322709 loss)
I0924 21:33:52.649204  2642 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I0924 21:34:06.057840  2642 solver.cpp:218] Iteration 11900 (7.4579 iter/s, 13.4086s/100 iters), loss = 0.264727
I0924 21:34:06.057881  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264727 (* 1 = 0.264727 loss)
I0924 21:34:06.057886  2642 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I0924 21:34:18.802892  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:34:19.339794  2642 solver.cpp:330] Iteration 12000, Testing net (#0)
I0924 21:34:22.427357  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:34:22.555555  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8032
I0924 21:34:22.555593  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.609146 (* 1 = 0.609146 loss)
I0924 21:34:22.688838  2642 solver.cpp:218] Iteration 12000 (6.0129 iter/s, 16.6309s/100 iters), loss = 0.283212
I0924 21:34:22.688865  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283212 (* 1 = 0.283212 loss)
I0924 21:34:22.688872  2642 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I0924 21:34:36.085193  2642 solver.cpp:218] Iteration 12100 (7.46476 iter/s, 13.3963s/100 iters), loss = 0.232536
I0924 21:34:36.085223  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232536 (* 1 = 0.232536 loss)
I0924 21:34:36.085229  2642 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I0924 21:34:49.484400  2642 solver.cpp:218] Iteration 12200 (7.46317 iter/s, 13.3991s/100 iters), loss = 0.231093
I0924 21:34:49.484537  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231093 (* 1 = 0.231093 loss)
I0924 21:34:49.484545  2642 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I0924 21:35:02.880753  2642 solver.cpp:218] Iteration 12300 (7.46482 iter/s, 13.3962s/100 iters), loss = 0.381892
I0924 21:35:02.880791  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.381892 (* 1 = 0.381892 loss)
I0924 21:35:02.880797  2642 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I0924 21:35:16.280515  2642 solver.cpp:218] Iteration 12400 (7.46286 iter/s, 13.3997s/100 iters), loss = 0.341455
I0924 21:35:16.280546  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.341455 (* 1 = 0.341455 loss)
I0924 21:35:16.280552  2642 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I0924 21:35:29.016381  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:35:29.552202  2642 solver.cpp:330] Iteration 12500, Testing net (#0)
I0924 21:35:32.641175  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:35:32.769345  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.808
I0924 21:35:32.769381  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.596806 (* 1 = 0.596806 loss)
I0924 21:35:32.902281  2642 solver.cpp:218] Iteration 12500 (6.01624 iter/s, 16.6217s/100 iters), loss = 0.299303
I0924 21:35:32.902307  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299303 (* 1 = 0.299303 loss)
I0924 21:35:32.902313  2642 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I0924 21:35:46.308279  2642 solver.cpp:218] Iteration 12600 (7.45939 iter/s, 13.4059s/100 iters), loss = 0.259225
I0924 21:35:46.308320  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259225 (* 1 = 0.259225 loss)
I0924 21:35:46.308326  2642 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I0924 21:35:59.711278  2642 solver.cpp:218] Iteration 12700 (7.46106 iter/s, 13.4029s/100 iters), loss = 0.247781
I0924 21:35:59.711398  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247781 (* 1 = 0.247781 loss)
I0924 21:35:59.711416  2642 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I0924 21:36:13.121982  2642 solver.cpp:218] Iteration 12800 (7.45682 iter/s, 13.4105s/100 iters), loss = 0.306978
I0924 21:36:13.122012  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306978 (* 1 = 0.306978 loss)
I0924 21:36:13.122018  2642 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I0924 21:36:26.530350  2642 solver.cpp:218] Iteration 12900 (7.45807 iter/s, 13.4083s/100 iters), loss = 0.202031
I0924 21:36:26.530380  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202031 (* 1 = 0.202031 loss)
I0924 21:36:26.530386  2642 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I0924 21:36:39.271960  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:36:39.809132  2642 solver.cpp:330] Iteration 13000, Testing net (#0)
I0924 21:36:42.897212  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:36:43.025303  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6477
I0924 21:36:43.025339  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.29254 (* 1 = 1.29254 loss)
I0924 21:36:43.158443  2642 solver.cpp:218] Iteration 13000 (6.01395 iter/s, 16.628s/100 iters), loss = 0.226346
I0924 21:36:43.158470  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226347 (* 1 = 0.226347 loss)
I0924 21:36:43.158478  2642 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I0924 21:36:56.563499  2642 solver.cpp:218] Iteration 13100 (7.45991 iter/s, 13.405s/100 iters), loss = 0.329924
I0924 21:36:56.563541  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329924 (* 1 = 0.329924 loss)
I0924 21:36:56.563547  2642 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I0924 21:37:09.976069  2642 solver.cpp:218] Iteration 13200 (7.45574 iter/s, 13.4125s/100 iters), loss = 0.253301
I0924 21:37:09.976228  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253301 (* 1 = 0.253301 loss)
I0924 21:37:09.976246  2642 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I0924 21:37:23.384980  2642 solver.cpp:218] Iteration 13300 (7.45784 iter/s, 13.4087s/100 iters), loss = 0.263631
I0924 21:37:23.385020  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263631 (* 1 = 0.263631 loss)
I0924 21:37:23.385026  2642 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I0924 21:37:36.792516  2642 solver.cpp:218] Iteration 13400 (7.45854 iter/s, 13.4075s/100 iters), loss = 0.232228
I0924 21:37:36.792557  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232228 (* 1 = 0.232228 loss)
I0924 21:37:36.792562  2642 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I0924 21:37:49.536082  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:37:50.072337  2642 solver.cpp:330] Iteration 13500, Testing net (#0)
I0924 21:37:53.160248  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:37:53.288465  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8415
I0924 21:37:53.288492  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.481979 (* 1 = 0.481979 loss)
I0924 21:37:53.421963  2642 solver.cpp:218] Iteration 13500 (6.01346 iter/s, 16.6294s/100 iters), loss = 0.144976
I0924 21:37:53.421990  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144976 (* 1 = 0.144976 loss)
I0924 21:37:53.421996  2642 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I0924 21:38:06.825951  2642 solver.cpp:218] Iteration 13600 (7.4605 iter/s, 13.4039s/100 iters), loss = 0.267006
I0924 21:38:06.825990  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267006 (* 1 = 0.267006 loss)
I0924 21:38:06.825996  2642 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I0924 21:38:20.231320  2642 solver.cpp:218] Iteration 13700 (7.45974 iter/s, 13.4053s/100 iters), loss = 0.317439
I0924 21:38:20.231431  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317439 (* 1 = 0.317439 loss)
I0924 21:38:20.231438  2642 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I0924 21:38:33.638186  2642 solver.cpp:218] Iteration 13800 (7.45895 iter/s, 13.4067s/100 iters), loss = 0.294457
I0924 21:38:33.638217  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294457 (* 1 = 0.294457 loss)
I0924 21:38:33.638222  2642 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I0924 21:38:47.040305  2642 solver.cpp:218] Iteration 13900 (7.46155 iter/s, 13.402s/100 iters), loss = 0.285646
I0924 21:38:47.040344  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285646 (* 1 = 0.285646 loss)
I0924 21:38:47.040350  2642 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I0924 21:38:59.773634  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:39:00.310223  2642 solver.cpp:330] Iteration 14000, Testing net (#0)
I0924 21:39:03.397801  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:39:03.526443  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7992
I0924 21:39:03.526481  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.597619 (* 1 = 0.597619 loss)
I0924 21:39:03.659260  2642 solver.cpp:218] Iteration 14000 (6.01726 iter/s, 16.6189s/100 iters), loss = 0.254163
I0924 21:39:03.659284  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254163 (* 1 = 0.254163 loss)
I0924 21:39:03.659291  2642 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I0924 21:39:17.068753  2642 solver.cpp:218] Iteration 14100 (7.45744 iter/s, 13.4094s/100 iters), loss = 0.286549
I0924 21:39:17.068783  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286549 (* 1 = 0.286549 loss)
I0924 21:39:17.068789  2642 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I0924 21:39:30.489444  2642 solver.cpp:218] Iteration 14200 (7.45122 iter/s, 13.4206s/100 iters), loss = 0.286586
I0924 21:39:30.489575  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286586 (* 1 = 0.286586 loss)
I0924 21:39:30.489583  2642 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I0924 21:39:43.904999  2642 solver.cpp:218] Iteration 14300 (7.45413 iter/s, 13.4154s/100 iters), loss = 0.365788
I0924 21:39:43.905028  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365788 (* 1 = 0.365788 loss)
I0924 21:39:43.905035  2642 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I0924 21:39:57.324676  2642 solver.cpp:218] Iteration 14400 (7.45178 iter/s, 13.4196s/100 iters), loss = 0.182114
I0924 21:39:57.324717  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182114 (* 1 = 0.182114 loss)
I0924 21:39:57.324723  2642 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I0924 21:40:10.072964  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:40:10.609040  2642 solver.cpp:330] Iteration 14500, Testing net (#0)
I0924 21:40:13.697160  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:40:13.825268  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7811
I0924 21:40:13.825304  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.642246 (* 1 = 0.642246 loss)
I0924 21:40:13.958488  2642 solver.cpp:218] Iteration 14500 (6.01188 iter/s, 16.6337s/100 iters), loss = 0.218695
I0924 21:40:13.958514  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218695 (* 1 = 0.218695 loss)
I0924 21:40:13.958521  2642 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I0924 21:40:27.361642  2642 solver.cpp:218] Iteration 14600 (7.46097 iter/s, 13.4031s/100 iters), loss = 0.418954
I0924 21:40:27.361682  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.418954 (* 1 = 0.418954 loss)
I0924 21:40:27.361688  2642 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I0924 21:40:40.767902  2642 solver.cpp:218] Iteration 14700 (7.45925 iter/s, 13.4062s/100 iters), loss = 0.254223
I0924 21:40:40.767988  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254223 (* 1 = 0.254223 loss)
I0924 21:40:40.768005  2642 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I0924 21:40:54.177803  2642 solver.cpp:218] Iteration 14800 (7.45725 iter/s, 13.4098s/100 iters), loss = 0.318777
I0924 21:40:54.177834  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.318777 (* 1 = 0.318777 loss)
I0924 21:40:54.177839  2642 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I0924 21:41:07.590231  2642 solver.cpp:218] Iteration 14900 (7.45581 iter/s, 13.4124s/100 iters), loss = 0.235531
I0924 21:41:07.590262  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235531 (* 1 = 0.235531 loss)
I0924 21:41:07.590267  2642 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I0924 21:41:20.331374  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:41:20.868331  2642 solver.cpp:330] Iteration 15000, Testing net (#0)
I0924 21:41:23.956014  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:41:24.084987  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7945
I0924 21:41:24.085026  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.653058 (* 1 = 0.653058 loss)
I0924 21:41:24.218471  2642 solver.cpp:218] Iteration 15000 (6.0139 iter/s, 16.6282s/100 iters), loss = 0.227993
I0924 21:41:24.218497  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227993 (* 1 = 0.227993 loss)
I0924 21:41:24.218502  2642 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I0924 21:41:37.623172  2642 solver.cpp:218] Iteration 15100 (7.46011 iter/s, 13.4046s/100 iters), loss = 0.261423
I0924 21:41:37.623211  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261423 (* 1 = 0.261423 loss)
I0924 21:41:37.623217  2642 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I0924 21:41:51.027662  2642 solver.cpp:218] Iteration 15200 (7.46023 iter/s, 13.4044s/100 iters), loss = 0.238809
I0924 21:41:51.027796  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238809 (* 1 = 0.238809 loss)
I0924 21:41:51.027802  2642 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I0924 21:42:04.435518  2642 solver.cpp:218] Iteration 15300 (7.45841 iter/s, 13.4077s/100 iters), loss = 0.330266
I0924 21:42:04.435557  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330266 (* 1 = 0.330266 loss)
I0924 21:42:04.435564  2642 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I0924 21:42:17.846441  2642 solver.cpp:218] Iteration 15400 (7.45665 iter/s, 13.4108s/100 iters), loss = 0.209205
I0924 21:42:17.846472  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209205 (* 1 = 0.209205 loss)
I0924 21:42:17.846477  2642 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I0924 21:42:30.584594  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:42:31.121765  2642 solver.cpp:330] Iteration 15500, Testing net (#0)
I0924 21:42:34.209422  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:42:34.338202  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8017
I0924 21:42:34.338239  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.596687 (* 1 = 0.596687 loss)
I0924 21:42:34.471457  2642 solver.cpp:218] Iteration 15500 (6.01506 iter/s, 16.6249s/100 iters), loss = 0.200984
I0924 21:42:34.471483  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200984 (* 1 = 0.200984 loss)
I0924 21:42:34.471490  2642 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I0924 21:42:47.879694  2642 solver.cpp:218] Iteration 15600 (7.45814 iter/s, 13.4082s/100 iters), loss = 0.215989
I0924 21:42:47.879726  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215989 (* 1 = 0.215989 loss)
I0924 21:42:47.879734  2642 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I0924 21:43:01.283040  2642 solver.cpp:218] Iteration 15700 (7.46087 iter/s, 13.4033s/100 iters), loss = 0.286696
I0924 21:43:01.283123  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286696 (* 1 = 0.286696 loss)
I0924 21:43:01.283139  2642 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I0924 21:43:14.691059  2642 solver.cpp:218] Iteration 15800 (7.45829 iter/s, 13.4079s/100 iters), loss = 0.284066
I0924 21:43:14.691090  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284066 (* 1 = 0.284066 loss)
I0924 21:43:14.691095  2642 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I0924 21:43:28.099846  2642 solver.cpp:218] Iteration 15900 (7.45784 iter/s, 13.4087s/100 iters), loss = 0.212885
I0924 21:43:28.099887  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212885 (* 1 = 0.212885 loss)
I0924 21:43:28.099894  2642 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I0924 21:43:40.842095  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:43:41.378525  2642 solver.cpp:330] Iteration 16000, Testing net (#0)
I0924 21:43:44.465850  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:43:44.594365  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7482
I0924 21:43:44.594403  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.833066 (* 1 = 0.833066 loss)
I0924 21:43:44.727927  2642 solver.cpp:218] Iteration 16000 (6.01396 iter/s, 16.628s/100 iters), loss = 0.229656
I0924 21:43:44.727953  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229656 (* 1 = 0.229656 loss)
I0924 21:43:44.727960  2642 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I0924 21:43:58.131037  2642 solver.cpp:218] Iteration 16100 (7.461 iter/s, 13.403s/100 iters), loss = 0.205391
I0924 21:43:58.131078  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205391 (* 1 = 0.205391 loss)
I0924 21:43:58.131083  2642 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I0924 21:44:11.532820  2642 solver.cpp:218] Iteration 16200 (7.46174 iter/s, 13.4017s/100 iters), loss = 0.22366
I0924 21:44:11.532940  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22366 (* 1 = 0.22366 loss)
I0924 21:44:11.532948  2642 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I0924 21:44:24.936808  2642 solver.cpp:218] Iteration 16300 (7.46056 iter/s, 13.4038s/100 iters), loss = 0.357474
I0924 21:44:24.936838  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.357474 (* 1 = 0.357474 loss)
I0924 21:44:24.936844  2642 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I0924 21:44:38.346369  2642 solver.cpp:218] Iteration 16400 (7.45741 iter/s, 13.4095s/100 iters), loss = 0.224596
I0924 21:44:38.346410  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224596 (* 1 = 0.224596 loss)
I0924 21:44:38.346415  2642 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I0924 21:44:51.087544  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:44:51.623711  2642 solver.cpp:330] Iteration 16500, Testing net (#0)
I0924 21:44:54.710788  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:44:54.838646  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7742
I0924 21:44:54.838682  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.710057 (* 1 = 0.710057 loss)
I0924 21:44:54.972215  2642 solver.cpp:218] Iteration 16500 (6.01476 iter/s, 16.6258s/100 iters), loss = 0.201865
I0924 21:44:54.972241  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201865 (* 1 = 0.201865 loss)
I0924 21:44:54.972249  2642 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I0924 21:45:08.379568  2642 solver.cpp:218] Iteration 16600 (7.45863 iter/s, 13.4073s/100 iters), loss = 0.312976
I0924 21:45:08.379608  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312976 (* 1 = 0.312976 loss)
I0924 21:45:08.379614  2642 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I0924 21:45:21.791023  2642 solver.cpp:218] Iteration 16700 (7.45636 iter/s, 13.4114s/100 iters), loss = 0.176409
I0924 21:45:21.791121  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176409 (* 1 = 0.176409 loss)
I0924 21:45:21.791129  2642 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I0924 21:45:35.204550  2642 solver.cpp:218] Iteration 16800 (7.45524 iter/s, 13.4134s/100 iters), loss = 0.264199
I0924 21:45:35.204589  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264199 (* 1 = 0.264199 loss)
I0924 21:45:35.204596  2642 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I0924 21:45:48.621807  2642 solver.cpp:218] Iteration 16900 (7.45313 iter/s, 13.4172s/100 iters), loss = 0.224214
I0924 21:45:48.621848  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224214 (* 1 = 0.224214 loss)
I0924 21:45:48.621855  2642 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I0924 21:46:01.377460  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:46:01.913628  2642 solver.cpp:330] Iteration 17000, Testing net (#0)
I0924 21:46:05.000829  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:46:05.129138  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8163
I0924 21:46:05.129175  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.555251 (* 1 = 0.555251 loss)
I0924 21:46:05.262656  2642 solver.cpp:218] Iteration 17000 (6.00934 iter/s, 16.6408s/100 iters), loss = 0.191699
I0924 21:46:05.262683  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191699 (* 1 = 0.191699 loss)
I0924 21:46:05.262691  2642 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I0924 21:46:18.672972  2642 solver.cpp:218] Iteration 17100 (7.45699 iter/s, 13.4102s/100 iters), loss = 0.192239
I0924 21:46:18.673013  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192239 (* 1 = 0.192239 loss)
I0924 21:46:18.673019  2642 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I0924 21:46:32.090637  2642 solver.cpp:218] Iteration 17200 (7.45291 iter/s, 13.4176s/100 iters), loss = 0.30835
I0924 21:46:32.090792  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30835 (* 1 = 0.30835 loss)
I0924 21:46:32.090809  2642 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I0924 21:46:45.507479  2642 solver.cpp:218] Iteration 17300 (7.45342 iter/s, 13.4167s/100 iters), loss = 0.19364
I0924 21:46:45.507519  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19364 (* 1 = 0.19364 loss)
I0924 21:46:45.507525  2642 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I0924 21:46:58.923501  2642 solver.cpp:218] Iteration 17400 (7.45382 iter/s, 13.4159s/100 iters), loss = 0.268191
I0924 21:46:58.923532  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268191 (* 1 = 0.268191 loss)
I0924 21:46:58.923537  2642 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I0924 21:47:11.673779  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:47:12.210269  2642 solver.cpp:330] Iteration 17500, Testing net (#0)
I0924 21:47:15.297586  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:47:15.425698  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8163
I0924 21:47:15.425732  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.551248 (* 1 = 0.551248 loss)
I0924 21:47:15.559866  2642 solver.cpp:218] Iteration 17500 (6.01096 iter/s, 16.6363s/100 iters), loss = 0.195744
I0924 21:47:15.559892  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195744 (* 1 = 0.195744 loss)
I0924 21:47:15.559898  2642 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I0924 21:47:28.966425  2642 solver.cpp:218] Iteration 17600 (7.45908 iter/s, 13.4065s/100 iters), loss = 0.18356
I0924 21:47:28.966466  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18356 (* 1 = 0.18356 loss)
I0924 21:47:28.966471  2642 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I0924 21:47:42.381968  2642 solver.cpp:218] Iteration 17700 (7.45409 iter/s, 13.4155s/100 iters), loss = 0.300599
I0924 21:47:42.382078  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300599 (* 1 = 0.300599 loss)
I0924 21:47:42.382086  2642 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I0924 21:47:55.793572  2642 solver.cpp:218] Iteration 17800 (7.45631 iter/s, 13.4115s/100 iters), loss = 0.18318
I0924 21:47:55.793612  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18318 (* 1 = 0.18318 loss)
I0924 21:47:55.793617  2642 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I0924 21:48:09.198457  2642 solver.cpp:218] Iteration 17900 (7.46001 iter/s, 13.4048s/100 iters), loss = 0.184978
I0924 21:48:09.198496  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184978 (* 1 = 0.184978 loss)
I0924 21:48:09.198503  2642 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I0924 21:48:21.939008  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:48:22.477041  2642 solver.cpp:330] Iteration 18000, Testing net (#0)
I0924 21:48:25.564247  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:48:25.692323  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7429
I0924 21:48:25.692361  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.776695 (* 1 = 0.776695 loss)
I0924 21:48:25.826357  2642 solver.cpp:218] Iteration 18000 (6.01402 iter/s, 16.6278s/100 iters), loss = 0.174252
I0924 21:48:25.826385  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174252 (* 1 = 0.174252 loss)
I0924 21:48:25.826390  2642 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I0924 21:48:39.229928  2642 solver.cpp:218] Iteration 18100 (7.46074 iter/s, 13.4035s/100 iters), loss = 0.358555
I0924 21:48:39.229969  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.358555 (* 1 = 0.358555 loss)
I0924 21:48:39.229974  2642 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I0924 21:48:52.633023  2642 solver.cpp:218] Iteration 18200 (7.46101 iter/s, 13.403s/100 iters), loss = 0.279761
I0924 21:48:52.633184  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279761 (* 1 = 0.279761 loss)
I0924 21:48:52.633203  2642 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I0924 21:49:06.034893  2642 solver.cpp:218] Iteration 18300 (7.46175 iter/s, 13.4017s/100 iters), loss = 0.214003
I0924 21:49:06.034924  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214003 (* 1 = 0.214003 loss)
I0924 21:49:06.034929  2642 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I0924 21:49:19.436267  2642 solver.cpp:218] Iteration 18400 (7.46196 iter/s, 13.4013s/100 iters), loss = 0.272592
I0924 21:49:19.436307  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272592 (* 1 = 0.272592 loss)
I0924 21:49:19.436313  2642 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I0924 21:49:32.170737  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:49:32.707749  2642 solver.cpp:330] Iteration 18500, Testing net (#0)
I0924 21:49:35.795531  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:49:35.923949  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7864
I0924 21:49:35.923985  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.660337 (* 1 = 0.660337 loss)
I0924 21:49:36.056970  2642 solver.cpp:218] Iteration 18500 (6.01663 iter/s, 16.6206s/100 iters), loss = 0.162721
I0924 21:49:36.056998  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162721 (* 1 = 0.162721 loss)
I0924 21:49:36.057004  2642 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I0924 21:49:49.458135  2642 solver.cpp:218] Iteration 18600 (7.46208 iter/s, 13.4011s/100 iters), loss = 0.235467
I0924 21:49:49.458176  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235467 (* 1 = 0.235467 loss)
I0924 21:49:49.458183  2642 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I0924 21:50:02.862812  2642 solver.cpp:218] Iteration 18700 (7.46013 iter/s, 13.4046s/100 iters), loss = 0.296819
I0924 21:50:02.862931  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296819 (* 1 = 0.296819 loss)
I0924 21:50:02.862947  2642 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I0924 21:50:16.268543  2642 solver.cpp:218] Iteration 18800 (7.45959 iter/s, 13.4056s/100 iters), loss = 0.183409
I0924 21:50:16.268584  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183409 (* 1 = 0.183409 loss)
I0924 21:50:16.268589  2642 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I0924 21:50:29.675323  2642 solver.cpp:218] Iteration 18900 (7.45896 iter/s, 13.4067s/100 iters), loss = 0.217339
I0924 21:50:29.675364  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217339 (* 1 = 0.217339 loss)
I0924 21:50:29.675369  2642 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I0924 21:50:42.417418  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:50:42.954102  2642 solver.cpp:330] Iteration 19000, Testing net (#0)
I0924 21:50:46.041429  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:50:46.170051  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8126
I0924 21:50:46.170078  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.559183 (* 1 = 0.559183 loss)
I0924 21:50:46.303548  2642 solver.cpp:218] Iteration 19000 (6.0139 iter/s, 16.6281s/100 iters), loss = 0.211813
I0924 21:50:46.303576  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211813 (* 1 = 0.211813 loss)
I0924 21:50:46.303583  2642 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I0924 21:50:59.697731  2642 solver.cpp:218] Iteration 19100 (7.46597 iter/s, 13.3941s/100 iters), loss = 0.25043
I0924 21:50:59.697769  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25043 (* 1 = 0.25043 loss)
I0924 21:50:59.697775  2642 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I0924 21:51:13.100978  2642 solver.cpp:218] Iteration 19200 (7.46092 iter/s, 13.4032s/100 iters), loss = 0.188283
I0924 21:51:13.101137  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188283 (* 1 = 0.188283 loss)
I0924 21:51:13.101155  2642 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I0924 21:51:26.500149  2642 solver.cpp:218] Iteration 19300 (7.46325 iter/s, 13.399s/100 iters), loss = 0.319736
I0924 21:51:26.500190  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319735 (* 1 = 0.319735 loss)
I0924 21:51:26.500196  2642 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I0924 21:51:39.901175  2642 solver.cpp:218] Iteration 19400 (7.46216 iter/s, 13.4009s/100 iters), loss = 0.156807
I0924 21:51:39.901202  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156807 (* 1 = 0.156807 loss)
I0924 21:51:39.901207  2642 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I0924 21:51:52.627115  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:51:53.162971  2642 solver.cpp:330] Iteration 19500, Testing net (#0)
I0924 21:51:56.251353  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:51:56.379845  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7942
I0924 21:51:56.379881  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.663525 (* 1 = 0.663525 loss)
I0924 21:51:56.513595  2642 solver.cpp:218] Iteration 19500 (6.01962 iter/s, 16.6123s/100 iters), loss = 0.211127
I0924 21:51:56.513622  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211127 (* 1 = 0.211127 loss)
I0924 21:51:56.513628  2642 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I0924 21:52:09.926002  2642 solver.cpp:218] Iteration 19600 (7.45582 iter/s, 13.4123s/100 iters), loss = 0.247436
I0924 21:52:09.926033  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247436 (* 1 = 0.247436 loss)
I0924 21:52:09.926038  2642 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I0924 21:52:23.341749  2642 solver.cpp:218] Iteration 19700 (7.45397 iter/s, 13.4157s/100 iters), loss = 0.200446
I0924 21:52:23.341823  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200445 (* 1 = 0.200445 loss)
I0924 21:52:23.341830  2642 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I0924 21:52:36.755733  2642 solver.cpp:218] Iteration 19800 (7.45497 iter/s, 13.4139s/100 iters), loss = 0.230758
I0924 21:52:36.755774  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230758 (* 1 = 0.230758 loss)
I0924 21:52:36.755779  2642 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I0924 21:52:50.170611  2642 solver.cpp:218] Iteration 19900 (7.45446 iter/s, 13.4148s/100 iters), loss = 0.165138
I0924 21:52:50.170652  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165138 (* 1 = 0.165138 loss)
I0924 21:52:50.170658  2642 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I0924 21:53:02.920971  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:53:03.457212  2642 solver.cpp:330] Iteration 20000, Testing net (#0)
I0924 21:53:06.546291  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:53:06.674907  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8245
I0924 21:53:06.674943  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.537378 (* 1 = 0.537378 loss)
I0924 21:53:06.808281  2642 solver.cpp:218] Iteration 20000 (6.01049 iter/s, 16.6376s/100 iters), loss = 0.143429
I0924 21:53:06.808307  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143429 (* 1 = 0.143429 loss)
I0924 21:53:06.808315  2642 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I0924 21:53:20.211521  2642 solver.cpp:218] Iteration 20100 (7.46092 iter/s, 13.4032s/100 iters), loss = 0.279421
I0924 21:53:20.211560  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279421 (* 1 = 0.279421 loss)
I0924 21:53:20.211565  2642 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I0924 21:53:33.617259  2642 solver.cpp:218] Iteration 20200 (7.45954 iter/s, 13.4057s/100 iters), loss = 0.213885
I0924 21:53:33.617388  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213885 (* 1 = 0.213885 loss)
I0924 21:53:33.617395  2642 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I0924 21:53:47.021858  2642 solver.cpp:218] Iteration 20300 (7.46022 iter/s, 13.4044s/100 iters), loss = 0.350225
I0924 21:53:47.021899  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350225 (* 1 = 0.350225 loss)
I0924 21:53:47.021905  2642 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I0924 21:54:00.431476  2642 solver.cpp:218] Iteration 20400 (7.45738 iter/s, 13.4095s/100 iters), loss = 0.203305
I0924 21:54:00.431516  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203304 (* 1 = 0.203304 loss)
I0924 21:54:00.431522  2642 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I0924 21:54:13.173331  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:54:13.710433  2642 solver.cpp:330] Iteration 20500, Testing net (#0)
I0924 21:54:16.797894  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:54:16.926276  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8412
I0924 21:54:16.926312  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.477773 (* 1 = 0.477773 loss)
I0924 21:54:17.059666  2642 solver.cpp:218] Iteration 20500 (6.01392 iter/s, 16.6281s/100 iters), loss = 0.206539
I0924 21:54:17.059692  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206538 (* 1 = 0.206538 loss)
I0924 21:54:17.059700  2642 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I0924 21:54:30.465910  2642 solver.cpp:218] Iteration 20600 (7.45925 iter/s, 13.4062s/100 iters), loss = 0.188531
I0924 21:54:30.465951  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188531 (* 1 = 0.188531 loss)
I0924 21:54:30.465956  2642 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I0924 21:54:43.868500  2642 solver.cpp:218] Iteration 20700 (7.46129 iter/s, 13.4025s/100 iters), loss = 0.288894
I0924 21:54:43.868629  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288894 (* 1 = 0.288894 loss)
I0924 21:54:43.868638  2642 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I0924 21:54:57.269419  2642 solver.cpp:218] Iteration 20800 (7.46226 iter/s, 13.4008s/100 iters), loss = 0.197871
I0924 21:54:57.269460  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197871 (* 1 = 0.197871 loss)
I0924 21:54:57.269466  2642 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I0924 21:55:10.673831  2642 solver.cpp:218] Iteration 20900 (7.46028 iter/s, 13.4043s/100 iters), loss = 0.29077
I0924 21:55:10.673863  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29077 (* 1 = 0.29077 loss)
I0924 21:55:10.673868  2642 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I0924 21:55:23.412369  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:55:23.948779  2642 solver.cpp:330] Iteration 21000, Testing net (#0)
I0924 21:55:27.036087  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:55:27.165048  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.713
I0924 21:55:27.165084  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.95742 (* 1 = 0.95742 loss)
I0924 21:55:27.298746  2642 solver.cpp:218] Iteration 21000 (6.0151 iter/s, 16.6248s/100 iters), loss = 0.180948
I0924 21:55:27.298773  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180948 (* 1 = 0.180948 loss)
I0924 21:55:27.298779  2642 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I0924 21:55:40.700731  2642 solver.cpp:218] Iteration 21100 (7.46162 iter/s, 13.4019s/100 iters), loss = 0.121262
I0924 21:55:40.700760  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.121261 (* 1 = 0.121261 loss)
I0924 21:55:40.700765  2642 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I0924 21:55:54.113174  2642 solver.cpp:218] Iteration 21200 (7.4558 iter/s, 13.4124s/100 iters), loss = 0.245131
I0924 21:55:54.113322  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245131 (* 1 = 0.245131 loss)
I0924 21:55:54.113329  2642 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I0924 21:56:07.518785  2642 solver.cpp:218] Iteration 21300 (7.45967 iter/s, 13.4054s/100 iters), loss = 0.250586
I0924 21:56:07.518826  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250586 (* 1 = 0.250586 loss)
I0924 21:56:07.518831  2642 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I0924 21:56:20.926651  2642 solver.cpp:218] Iteration 21400 (7.45835 iter/s, 13.4078s/100 iters), loss = 0.174207
I0924 21:56:20.926681  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174207 (* 1 = 0.174207 loss)
I0924 21:56:20.926687  2642 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I0924 21:56:33.667690  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:56:34.205174  2642 solver.cpp:330] Iteration 21500, Testing net (#0)
I0924 21:56:37.291990  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:56:37.420467  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7851
I0924 21:56:37.420503  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.721431 (* 1 = 0.721431 loss)
I0924 21:56:37.553488  2642 solver.cpp:218] Iteration 21500 (6.0144 iter/s, 16.6268s/100 iters), loss = 0.28999
I0924 21:56:37.553514  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28999 (* 1 = 0.28999 loss)
I0924 21:56:37.553521  2642 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I0924 21:56:50.950134  2642 solver.cpp:218] Iteration 21600 (7.4646 iter/s, 13.3966s/100 iters), loss = 0.307046
I0924 21:56:50.950173  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307046 (* 1 = 0.307046 loss)
I0924 21:56:50.950179  2642 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I0924 21:57:04.353153  2642 solver.cpp:218] Iteration 21700 (7.46105 iter/s, 13.4029s/100 iters), loss = 0.289922
I0924 21:57:04.353225  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289922 (* 1 = 0.289922 loss)
I0924 21:57:04.353232  2642 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I0924 21:57:17.756217  2642 solver.cpp:218] Iteration 21800 (7.46104 iter/s, 13.4029s/100 iters), loss = 0.271102
I0924 21:57:17.756258  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271102 (* 1 = 0.271102 loss)
I0924 21:57:17.756263  2642 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I0924 21:57:31.157986  2642 solver.cpp:218] Iteration 21900 (7.46175 iter/s, 13.4017s/100 iters), loss = 0.206932
I0924 21:57:31.158026  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206932 (* 1 = 0.206932 loss)
I0924 21:57:31.158031  2642 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I0924 21:57:43.897294  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:57:44.433681  2642 solver.cpp:330] Iteration 22000, Testing net (#0)
I0924 21:57:47.520459  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:57:47.648361  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7236
I0924 21:57:47.648397  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.970621 (* 1 = 0.970621 loss)
I0924 21:57:47.781628  2642 solver.cpp:218] Iteration 22000 (6.01556 iter/s, 16.6236s/100 iters), loss = 0.242194
I0924 21:57:47.781656  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242193 (* 1 = 0.242193 loss)
I0924 21:57:47.781662  2642 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I0924 21:58:01.186396  2642 solver.cpp:218] Iteration 22100 (7.46007 iter/s, 13.4047s/100 iters), loss = 0.153613
I0924 21:58:01.186437  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153613 (* 1 = 0.153613 loss)
I0924 21:58:01.186444  2642 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I0924 21:58:14.603920  2642 solver.cpp:218] Iteration 22200 (7.45299 iter/s, 13.4174s/100 iters), loss = 0.231045
I0924 21:58:14.603978  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231045 (* 1 = 0.231045 loss)
I0924 21:58:14.603986  2642 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I0924 21:58:28.017642  2642 solver.cpp:218] Iteration 22300 (7.45511 iter/s, 13.4136s/100 iters), loss = 0.321912
I0924 21:58:28.017684  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.321911 (* 1 = 0.321911 loss)
I0924 21:58:28.017689  2642 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I0924 21:58:41.435964  2642 solver.cpp:218] Iteration 22400 (7.45254 iter/s, 13.4182s/100 iters), loss = 0.159078
I0924 21:58:41.436004  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159077 (* 1 = 0.159077 loss)
I0924 21:58:41.436010  2642 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I0924 21:58:54.183884  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:58:54.719595  2642 solver.cpp:330] Iteration 22500, Testing net (#0)
I0924 21:58:57.805908  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 21:58:57.934510  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.814
I0924 21:58:57.934546  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.554091 (* 1 = 0.554091 loss)
I0924 21:58:58.068516  2642 solver.cpp:218] Iteration 22500 (6.01234 iter/s, 16.6325s/100 iters), loss = 0.21432
I0924 21:58:58.068544  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21432 (* 1 = 0.21432 loss)
I0924 21:58:58.068550  2642 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I0924 21:59:11.472033  2642 solver.cpp:218] Iteration 22600 (7.46077 iter/s, 13.4034s/100 iters), loss = 0.244838
I0924 21:59:11.472074  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244838 (* 1 = 0.244838 loss)
I0924 21:59:11.472079  2642 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I0924 21:59:24.879890  2642 solver.cpp:218] Iteration 22700 (7.45836 iter/s, 13.4078s/100 iters), loss = 0.252912
I0924 21:59:24.879971  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252911 (* 1 = 0.252911 loss)
I0924 21:59:24.879978  2642 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I0924 21:59:38.291534  2642 solver.cpp:218] Iteration 22800 (7.45627 iter/s, 13.4115s/100 iters), loss = 0.275969
I0924 21:59:38.291575  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275969 (* 1 = 0.275969 loss)
I0924 21:59:38.291581  2642 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I0924 21:59:51.696914  2642 solver.cpp:218] Iteration 22900 (7.45974 iter/s, 13.4053s/100 iters), loss = 0.167037
I0924 21:59:51.696956  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167037 (* 1 = 0.167037 loss)
I0924 21:59:51.696964  2642 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I0924 22:00:04.440394  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:00:04.978473  2642 solver.cpp:330] Iteration 23000, Testing net (#0)
I0924 22:00:08.065387  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:00:08.194018  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7873
I0924 22:00:08.194052  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.654712 (* 1 = 0.654712 loss)
I0924 22:00:08.327392  2642 solver.cpp:218] Iteration 23000 (6.01309 iter/s, 16.6304s/100 iters), loss = 0.210832
I0924 22:00:08.327420  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210832 (* 1 = 0.210832 loss)
I0924 22:00:08.327427  2642 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I0924 22:00:21.727506  2642 solver.cpp:218] Iteration 23100 (7.46266 iter/s, 13.4s/100 iters), loss = 0.220341
I0924 22:00:21.727547  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220341 (* 1 = 0.220341 loss)
I0924 22:00:21.727553  2642 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I0924 22:00:35.131795  2642 solver.cpp:218] Iteration 23200 (7.46034 iter/s, 13.4042s/100 iters), loss = 0.226232
I0924 22:00:35.131930  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226232 (* 1 = 0.226232 loss)
I0924 22:00:35.131937  2642 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I0924 22:00:48.537237  2642 solver.cpp:218] Iteration 23300 (7.45975 iter/s, 13.4053s/100 iters), loss = 0.259191
I0924 22:00:48.537277  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25919 (* 1 = 0.25919 loss)
I0924 22:00:48.537283  2642 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I0924 22:01:01.939148  2642 solver.cpp:218] Iteration 23400 (7.46167 iter/s, 13.4018s/100 iters), loss = 0.23492
I0924 22:01:01.939177  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23492 (* 1 = 0.23492 loss)
I0924 22:01:01.939183  2642 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I0924 22:01:14.677659  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:01:15.214155  2642 solver.cpp:330] Iteration 23500, Testing net (#0)
I0924 22:01:18.301082  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:01:18.430248  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7943
I0924 22:01:18.430284  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.661262 (* 1 = 0.661262 loss)
I0924 22:01:18.564122  2642 solver.cpp:218] Iteration 23500 (6.01507 iter/s, 16.6249s/100 iters), loss = 0.183378
I0924 22:01:18.564151  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183378 (* 1 = 0.183378 loss)
I0924 22:01:18.564157  2642 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I0924 22:01:31.967020  2642 solver.cpp:218] Iteration 23600 (7.46111 iter/s, 13.4028s/100 iters), loss = 0.258559
I0924 22:01:31.967061  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258559 (* 1 = 0.258559 loss)
I0924 22:01:31.967067  2642 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I0924 22:01:45.379676  2642 solver.cpp:218] Iteration 23700 (7.45569 iter/s, 13.4126s/100 iters), loss = 0.118012
I0924 22:01:45.379739  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.118012 (* 1 = 0.118012 loss)
I0924 22:01:45.379745  2642 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I0924 22:01:58.784080  2642 solver.cpp:218] Iteration 23800 (7.46029 iter/s, 13.4043s/100 iters), loss = 0.245948
I0924 22:01:58.784121  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245947 (* 1 = 0.245947 loss)
I0924 22:01:58.784127  2642 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I0924 22:02:12.190737  2642 solver.cpp:218] Iteration 23900 (7.45903 iter/s, 13.4066s/100 iters), loss = 0.12245
I0924 22:02:12.190778  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12245 (* 1 = 0.12245 loss)
I0924 22:02:12.190784  2642 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I0924 22:02:24.930555  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:02:25.466271  2642 solver.cpp:330] Iteration 24000, Testing net (#0)
I0924 22:02:28.553294  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:02:28.681833  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7945
I0924 22:02:28.681867  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.678794 (* 1 = 0.678794 loss)
I0924 22:02:28.815754  2642 solver.cpp:218] Iteration 24000 (6.01506 iter/s, 16.6249s/100 iters), loss = 0.180276
I0924 22:02:28.815780  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180276 (* 1 = 0.180276 loss)
I0924 22:02:28.815788  2642 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I0924 22:02:42.215827  2642 solver.cpp:218] Iteration 24100 (7.46268 iter/s, 13.4s/100 iters), loss = 0.259996
I0924 22:02:42.215868  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259996 (* 1 = 0.259996 loss)
I0924 22:02:42.215874  2642 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I0924 22:02:55.620363  2642 solver.cpp:218] Iteration 24200 (7.46021 iter/s, 13.4045s/100 iters), loss = 0.236939
I0924 22:02:55.620447  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236939 (* 1 = 0.236939 loss)
I0924 22:02:55.620463  2642 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I0924 22:03:09.025501  2642 solver.cpp:218] Iteration 24300 (7.45989 iter/s, 13.405s/100 iters), loss = 0.246675
I0924 22:03:09.025540  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246675 (* 1 = 0.246675 loss)
I0924 22:03:09.025547  2642 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I0924 22:03:22.427469  2642 solver.cpp:218] Iteration 24400 (7.46164 iter/s, 13.4019s/100 iters), loss = 0.182884
I0924 22:03:22.427510  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182883 (* 1 = 0.182883 loss)
I0924 22:03:22.427515  2642 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I0924 22:03:35.169440  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:03:35.706702  2642 solver.cpp:330] Iteration 24500, Testing net (#0)
I0924 22:03:38.793613  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:03:38.921911  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8035
I0924 22:03:38.921937  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.5925 (* 1 = 0.5925 loss)
I0924 22:03:39.055604  2642 solver.cpp:218] Iteration 24500 (6.01394 iter/s, 16.628s/100 iters), loss = 0.25028
I0924 22:03:39.055631  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25028 (* 1 = 0.25028 loss)
I0924 22:03:39.055637  2642 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I0924 22:03:52.453621  2642 solver.cpp:218] Iteration 24600 (7.46383 iter/s, 13.3979s/100 iters), loss = 0.180733
I0924 22:03:52.453649  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180733 (* 1 = 0.180733 loss)
I0924 22:03:52.453655  2642 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I0924 22:04:05.855330  2642 solver.cpp:218] Iteration 24700 (7.46177 iter/s, 13.4016s/100 iters), loss = 0.145991
I0924 22:04:05.855391  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145991 (* 1 = 0.145991 loss)
I0924 22:04:05.855397  2642 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I0924 22:04:19.256942  2642 solver.cpp:218] Iteration 24800 (7.46184 iter/s, 13.4015s/100 iters), loss = 0.202993
I0924 22:04:19.256983  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202993 (* 1 = 0.202993 loss)
I0924 22:04:19.256988  2642 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I0924 22:04:32.664288  2642 solver.cpp:218] Iteration 24900 (7.45864 iter/s, 13.4073s/100 iters), loss = 0.239756
I0924 22:04:32.664327  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239756 (* 1 = 0.239756 loss)
I0924 22:04:32.664332  2642 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I0924 22:04:45.400393  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:04:45.936815  2642 solver.cpp:330] Iteration 25000, Testing net (#0)
I0924 22:04:49.023198  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:04:49.152091  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8041
I0924 22:04:49.152127  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.610784 (* 1 = 0.610784 loss)
I0924 22:04:49.285500  2642 solver.cpp:218] Iteration 25000 (6.01644 iter/s, 16.6211s/100 iters), loss = 0.166958
I0924 22:04:49.285524  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166957 (* 1 = 0.166957 loss)
I0924 22:04:49.285531  2642 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I0924 22:05:02.692920  2642 solver.cpp:218] Iteration 25100 (7.4586 iter/s, 13.4073s/100 iters), loss = 0.177825
I0924 22:05:02.692961  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177825 (* 1 = 0.177825 loss)
I0924 22:05:02.692967  2642 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I0924 22:05:16.096804  2642 solver.cpp:218] Iteration 25200 (7.46057 iter/s, 13.4038s/100 iters), loss = 0.140675
I0924 22:05:16.096853  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140675 (* 1 = 0.140675 loss)
I0924 22:05:16.096859  2642 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I0924 22:05:29.497882  2642 solver.cpp:218] Iteration 25300 (7.46214 iter/s, 13.401s/100 iters), loss = 0.129204
I0924 22:05:29.497913  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.129204 (* 1 = 0.129204 loss)
I0924 22:05:29.497918  2642 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I0924 22:05:42.902792  2642 solver.cpp:218] Iteration 25400 (7.45999 iter/s, 13.4048s/100 iters), loss = 0.170494
I0924 22:05:42.902833  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170494 (* 1 = 0.170494 loss)
I0924 22:05:42.902840  2642 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I0924 22:05:55.636718  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:05:56.173166  2642 solver.cpp:330] Iteration 25500, Testing net (#0)
I0924 22:05:59.258702  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:05:59.387141  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7999
I0924 22:05:59.387178  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.628897 (* 1 = 0.628897 loss)
I0924 22:05:59.519846  2642 solver.cpp:218] Iteration 25500 (6.01795 iter/s, 16.617s/100 iters), loss = 0.17
I0924 22:05:59.519873  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169999 (* 1 = 0.169999 loss)
I0924 22:05:59.519879  2642 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I0924 22:06:12.927880  2642 solver.cpp:218] Iteration 25600 (7.45825 iter/s, 13.408s/100 iters), loss = 0.172083
I0924 22:06:12.927919  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172083 (* 1 = 0.172083 loss)
I0924 22:06:12.927925  2642 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I0924 22:06:26.339344  2642 solver.cpp:218] Iteration 25700 (7.45635 iter/s, 13.4114s/100 iters), loss = 0.212121
I0924 22:06:26.339416  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212121 (* 1 = 0.212121 loss)
I0924 22:06:26.339421  2642 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I0924 22:06:39.752477  2642 solver.cpp:218] Iteration 25800 (7.45544 iter/s, 13.413s/100 iters), loss = 0.197314
I0924 22:06:39.752518  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197314 (* 1 = 0.197314 loss)
I0924 22:06:39.752524  2642 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I0924 22:06:53.159488  2642 solver.cpp:218] Iteration 25900 (7.45883 iter/s, 13.4069s/100 iters), loss = 0.225856
I0924 22:06:53.159529  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225856 (* 1 = 0.225856 loss)
I0924 22:06:53.159535  2642 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I0924 22:07:05.916260  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:07:06.452652  2642 solver.cpp:330] Iteration 26000, Testing net (#0)
I0924 22:07:09.541985  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:07:09.670449  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7873
I0924 22:07:09.670486  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.641917 (* 1 = 0.641917 loss)
I0924 22:07:09.804368  2642 solver.cpp:218] Iteration 26000 (6.00789 iter/s, 16.6448s/100 iters), loss = 0.153847
I0924 22:07:09.804404  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153847 (* 1 = 0.153847 loss)
I0924 22:07:09.804411  2642 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I0924 22:07:23.202791  2642 solver.cpp:218] Iteration 26100 (7.46361 iter/s, 13.3983s/100 iters), loss = 0.228913
I0924 22:07:23.202831  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228913 (* 1 = 0.228913 loss)
I0924 22:07:23.202837  2642 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I0924 22:07:36.613615  2642 solver.cpp:218] Iteration 26200 (7.45672 iter/s, 13.4107s/100 iters), loss = 0.15894
I0924 22:07:36.613731  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15894 (* 1 = 0.15894 loss)
I0924 22:07:36.613747  2642 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I0924 22:07:50.021740  2642 solver.cpp:218] Iteration 26300 (7.45825 iter/s, 13.408s/100 iters), loss = 0.225268
I0924 22:07:50.021781  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225268 (* 1 = 0.225268 loss)
I0924 22:07:50.021787  2642 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I0924 22:08:03.427458  2642 solver.cpp:218] Iteration 26400 (7.45955 iter/s, 13.4056s/100 iters), loss = 0.11549
I0924 22:08:03.427498  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115489 (* 1 = 0.115489 loss)
I0924 22:08:03.427505  2642 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I0924 22:08:16.167001  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:08:16.703989  2642 solver.cpp:330] Iteration 26500, Testing net (#0)
I0924 22:08:19.791728  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:08:19.920760  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7695
I0924 22:08:19.920796  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.710943 (* 1 = 0.710943 loss)
I0924 22:08:20.054110  2642 solver.cpp:218] Iteration 26500 (6.01447 iter/s, 16.6266s/100 iters), loss = 0.25633
I0924 22:08:20.054137  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25633 (* 1 = 0.25633 loss)
I0924 22:08:20.054143  2642 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I0924 22:08:33.454001  2642 solver.cpp:218] Iteration 26600 (7.46279 iter/s, 13.3998s/100 iters), loss = 0.160645
I0924 22:08:33.454041  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160644 (* 1 = 0.160644 loss)
I0924 22:08:33.454047  2642 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I0924 22:08:46.851734  2642 solver.cpp:218] Iteration 26700 (7.46399 iter/s, 13.3977s/100 iters), loss = 0.274425
I0924 22:08:46.851840  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274425 (* 1 = 0.274425 loss)
I0924 22:08:46.851857  2642 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I0924 22:09:00.251849  2642 solver.cpp:218] Iteration 26800 (7.4627 iter/s, 13.4s/100 iters), loss = 0.156212
I0924 22:09:00.251879  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156212 (* 1 = 0.156212 loss)
I0924 22:09:00.251885  2642 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I0924 22:09:13.649775  2642 solver.cpp:218] Iteration 26900 (7.46388 iter/s, 13.3979s/100 iters), loss = 0.211029
I0924 22:09:13.649816  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211029 (* 1 = 0.211029 loss)
I0924 22:09:13.649821  2642 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I0924 22:09:26.385313  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:09:26.921386  2642 solver.cpp:330] Iteration 27000, Testing net (#0)
I0924 22:09:30.009016  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:09:30.137733  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.81
I0924 22:09:30.137769  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.572578 (* 1 = 0.572578 loss)
I0924 22:09:30.271560  2642 solver.cpp:218] Iteration 27000 (6.01623 iter/s, 16.6217s/100 iters), loss = 0.134853
I0924 22:09:30.271587  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134853 (* 1 = 0.134853 loss)
I0924 22:09:30.271594  2642 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I0924 22:09:43.681954  2642 solver.cpp:218] Iteration 27100 (7.45694 iter/s, 13.4103s/100 iters), loss = 0.181124
I0924 22:09:43.681996  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181124 (* 1 = 0.181124 loss)
I0924 22:09:43.682001  2642 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I0924 22:09:57.088737  2642 solver.cpp:218] Iteration 27200 (7.45896 iter/s, 13.4067s/100 iters), loss = 0.230023
I0924 22:09:57.088809  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230023 (* 1 = 0.230023 loss)
I0924 22:09:57.088815  2642 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I0924 22:10:10.508116  2642 solver.cpp:218] Iteration 27300 (7.45197 iter/s, 13.4193s/100 iters), loss = 0.179682
I0924 22:10:10.508157  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179681 (* 1 = 0.179681 loss)
I0924 22:10:10.508162  2642 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I0924 22:10:23.922139  2642 solver.cpp:218] Iteration 27400 (7.45493 iter/s, 13.4139s/100 iters), loss = 0.224885
I0924 22:10:23.922169  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224885 (* 1 = 0.224885 loss)
I0924 22:10:23.922175  2642 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I0924 22:10:36.673079  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:10:37.209816  2642 solver.cpp:330] Iteration 27500, Testing net (#0)
I0924 22:10:40.296367  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:10:40.424695  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.714
I0924 22:10:40.424731  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.14419 (* 1 = 1.14419 loss)
I0924 22:10:40.558429  2642 solver.cpp:218] Iteration 27500 (6.01098 iter/s, 16.6362s/100 iters), loss = 0.186144
I0924 22:10:40.558455  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186144 (* 1 = 0.186144 loss)
I0924 22:10:40.558462  2642 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I0924 22:10:53.961110  2642 solver.cpp:218] Iteration 27600 (7.46123 iter/s, 13.4026s/100 iters), loss = 0.213759
I0924 22:10:53.961140  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213759 (* 1 = 0.213759 loss)
I0924 22:10:53.961146  2642 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I0924 22:11:07.371399  2642 solver.cpp:218] Iteration 27700 (7.457 iter/s, 13.4102s/100 iters), loss = 0.212122
I0924 22:11:07.371477  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212122 (* 1 = 0.212122 loss)
I0924 22:11:07.371484  2642 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I0924 22:11:20.779217  2642 solver.cpp:218] Iteration 27800 (7.4584 iter/s, 13.4077s/100 iters), loss = 0.210511
I0924 22:11:20.779247  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210511 (* 1 = 0.210511 loss)
I0924 22:11:20.779253  2642 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I0924 22:11:34.188695  2642 solver.cpp:218] Iteration 27900 (7.45745 iter/s, 13.4094s/100 iters), loss = 0.186093
I0924 22:11:34.188736  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186093 (* 1 = 0.186093 loss)
I0924 22:11:34.188742  2642 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I0924 22:11:46.936450  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:11:47.472950  2642 solver.cpp:330] Iteration 28000, Testing net (#0)
I0924 22:11:50.559082  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:11:50.687687  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7981
I0924 22:11:50.687723  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.631478 (* 1 = 0.631478 loss)
I0924 22:11:50.821292  2642 solver.cpp:218] Iteration 28000 (6.01232 iter/s, 16.6325s/100 iters), loss = 0.226548
I0924 22:11:50.821319  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226547 (* 1 = 0.226547 loss)
I0924 22:11:50.821326  2642 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I0924 22:12:04.225702  2642 solver.cpp:218] Iteration 28100 (7.46027 iter/s, 13.4043s/100 iters), loss = 0.203494
I0924 22:12:04.225742  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203494 (* 1 = 0.203494 loss)
I0924 22:12:04.225749  2642 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I0924 22:12:17.629964  2642 solver.cpp:218] Iteration 28200 (7.46036 iter/s, 13.4042s/100 iters), loss = 0.218433
I0924 22:12:17.630100  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218432 (* 1 = 0.218432 loss)
I0924 22:12:17.630106  2642 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I0924 22:12:31.041455  2642 solver.cpp:218] Iteration 28300 (7.45639 iter/s, 13.4113s/100 iters), loss = 0.209673
I0924 22:12:31.041496  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209672 (* 1 = 0.209672 loss)
I0924 22:12:31.041501  2642 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I0924 22:12:44.453497  2642 solver.cpp:218] Iteration 28400 (7.45603 iter/s, 13.412s/100 iters), loss = 0.179885
I0924 22:12:44.453529  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179885 (* 1 = 0.179885 loss)
I0924 22:12:44.453536  2642 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I0924 22:12:57.198123  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:12:57.735005  2642 solver.cpp:330] Iteration 28500, Testing net (#0)
I0924 22:13:00.823539  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:13:00.951925  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8164
I0924 22:13:00.951958  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.555777 (* 1 = 0.555777 loss)
I0924 22:13:01.085484  2642 solver.cpp:218] Iteration 28500 (6.01254 iter/s, 16.6319s/100 iters), loss = 0.161911
I0924 22:13:01.085510  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16191 (* 1 = 0.16191 loss)
I0924 22:13:01.085517  2642 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I0924 22:13:14.487421  2642 solver.cpp:218] Iteration 28600 (7.46165 iter/s, 13.4019s/100 iters), loss = 0.153894
I0924 22:13:14.487452  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153894 (* 1 = 0.153894 loss)
I0924 22:13:14.487457  2642 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I0924 22:13:27.891243  2642 solver.cpp:218] Iteration 28700 (7.4606 iter/s, 13.4037s/100 iters), loss = 0.181984
I0924 22:13:27.891361  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181984 (* 1 = 0.181984 loss)
I0924 22:13:27.891378  2642 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I0924 22:13:41.300262  2642 solver.cpp:218] Iteration 28800 (7.45775 iter/s, 13.4089s/100 iters), loss = 0.355165
I0924 22:13:41.300292  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355165 (* 1 = 0.355165 loss)
I0924 22:13:41.300307  2642 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I0924 22:13:54.705881  2642 solver.cpp:218] Iteration 28900 (7.4596 iter/s, 13.4055s/100 iters), loss = 0.191323
I0924 22:13:54.705912  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191322 (* 1 = 0.191322 loss)
I0924 22:13:54.705929  2642 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I0924 22:14:07.456480  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:14:07.992777  2642 solver.cpp:330] Iteration 29000, Testing net (#0)
I0924 22:14:11.080533  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:14:11.208961  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8492
I0924 22:14:11.208997  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.457753 (* 1 = 0.457753 loss)
I0924 22:14:11.341922  2642 solver.cpp:218] Iteration 29000 (6.01107 iter/s, 16.636s/100 iters), loss = 0.101496
I0924 22:14:11.341949  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.101496 (* 1 = 0.101496 loss)
I0924 22:14:11.341956  2642 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I0924 22:14:24.750177  2642 solver.cpp:218] Iteration 29100 (7.45813 iter/s, 13.4082s/100 iters), loss = 0.228325
I0924 22:14:24.750208  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228324 (* 1 = 0.228324 loss)
I0924 22:14:24.750214  2642 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I0924 22:14:38.159219  2642 solver.cpp:218] Iteration 29200 (7.45769 iter/s, 13.409s/100 iters), loss = 0.175327
I0924 22:14:38.159354  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175327 (* 1 = 0.175327 loss)
I0924 22:14:38.159361  2642 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I0924 22:14:51.569057  2642 solver.cpp:218] Iteration 29300 (7.45731 iter/s, 13.4097s/100 iters), loss = 0.299839
I0924 22:14:51.569098  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299838 (* 1 = 0.299838 loss)
I0924 22:14:51.569103  2642 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I0924 22:15:04.981317  2642 solver.cpp:218] Iteration 29400 (7.45591 iter/s, 13.4122s/100 iters), loss = 0.171732
I0924 22:15:04.981357  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171732 (* 1 = 0.171732 loss)
I0924 22:15:04.981364  2642 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I0924 22:15:17.724623  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:15:18.261111  2642 solver.cpp:330] Iteration 29500, Testing net (#0)
I0924 22:15:21.349522  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:15:21.478000  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7536
I0924 22:15:21.478036  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.90955 (* 1 = 0.90955 loss)
I0924 22:15:21.611531  2642 solver.cpp:218] Iteration 29500 (6.01318 iter/s, 16.6301s/100 iters), loss = 0.218329
I0924 22:15:21.611557  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218329 (* 1 = 0.218329 loss)
I0924 22:15:21.611563  2642 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I0924 22:15:35.015875  2642 solver.cpp:218] Iteration 29600 (7.46031 iter/s, 13.4043s/100 iters), loss = 0.176757
I0924 22:15:35.015916  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176756 (* 1 = 0.176756 loss)
I0924 22:15:35.015923  2642 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I0924 22:15:48.427814  2642 solver.cpp:218] Iteration 29700 (7.45609 iter/s, 13.4119s/100 iters), loss = 0.164817
I0924 22:15:48.427920  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164817 (* 1 = 0.164817 loss)
I0924 22:15:48.427937  2642 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I0924 22:16:01.841984  2642 solver.cpp:218] Iteration 29800 (7.45488 iter/s, 13.414s/100 iters), loss = 0.126895
I0924 22:16:01.842025  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126895 (* 1 = 0.126895 loss)
I0924 22:16:01.842031  2642 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I0924 22:16:15.255875  2642 solver.cpp:218] Iteration 29900 (7.455 iter/s, 13.4138s/100 iters), loss = 0.153638
I0924 22:16:15.255915  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153637 (* 1 = 0.153637 loss)
I0924 22:16:15.255921  2642 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I0924 22:16:28.000481  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:16:28.536337  2642 solver.cpp:330] Iteration 30000, Testing net (#0)
I0924 22:16:31.623016  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:16:31.751894  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.809
I0924 22:16:31.751931  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.633474 (* 1 = 0.633474 loss)
I0924 22:16:31.884722  2642 solver.cpp:218] Iteration 30000 (6.01368 iter/s, 16.6288s/100 iters), loss = 0.148324
I0924 22:16:31.884749  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148324 (* 1 = 0.148324 loss)
I0924 22:16:31.884757  2642 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I0924 22:16:45.290242  2642 solver.cpp:218] Iteration 30100 (7.45965 iter/s, 13.4055s/100 iters), loss = 0.182785
I0924 22:16:45.290282  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182784 (* 1 = 0.182784 loss)
I0924 22:16:45.290287  2642 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I0924 22:16:58.703934  2642 solver.cpp:218] Iteration 30200 (7.45511 iter/s, 13.4136s/100 iters), loss = 0.26797
I0924 22:16:58.704059  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26797 (* 1 = 0.26797 loss)
I0924 22:16:58.704066  2642 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I0924 22:17:12.120368  2642 solver.cpp:218] Iteration 30300 (7.45363 iter/s, 13.4163s/100 iters), loss = 0.14892
I0924 22:17:12.120409  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14892 (* 1 = 0.14892 loss)
I0924 22:17:12.120414  2642 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I0924 22:17:25.532445  2642 solver.cpp:218] Iteration 30400 (7.45601 iter/s, 13.412s/100 iters), loss = 0.203916
I0924 22:17:25.532485  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203916 (* 1 = 0.203916 loss)
I0924 22:17:25.532490  2642 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I0924 22:17:38.280185  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:17:38.817337  2642 solver.cpp:330] Iteration 30500, Testing net (#0)
I0924 22:17:41.905145  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:17:42.033776  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8063
I0924 22:17:42.033812  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.598616 (* 1 = 0.598616 loss)
I0924 22:17:42.167095  2642 solver.cpp:218] Iteration 30500 (6.01158 iter/s, 16.6346s/100 iters), loss = 0.136999
I0924 22:17:42.167124  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136998 (* 1 = 0.136998 loss)
I0924 22:17:42.167130  2642 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I0924 22:17:55.574802  2642 solver.cpp:218] Iteration 30600 (7.45844 iter/s, 13.4076s/100 iters), loss = 0.191233
I0924 22:17:55.574843  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191233 (* 1 = 0.191233 loss)
I0924 22:17:55.574849  2642 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I0924 22:18:08.984802  2642 solver.cpp:218] Iteration 30700 (7.45717 iter/s, 13.4099s/100 iters), loss = 0.191199
I0924 22:18:08.984959  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191199 (* 1 = 0.191199 loss)
I0924 22:18:08.984966  2642 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I0924 22:18:22.393782  2642 solver.cpp:218] Iteration 30800 (7.4578 iter/s, 13.4088s/100 iters), loss = 0.174852
I0924 22:18:22.393823  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174852 (* 1 = 0.174852 loss)
I0924 22:18:22.393829  2642 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I0924 22:18:35.804306  2642 solver.cpp:218] Iteration 30900 (7.45688 iter/s, 13.4104s/100 iters), loss = 0.224851
I0924 22:18:35.804347  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224851 (* 1 = 0.224851 loss)
I0924 22:18:35.804352  2642 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I0924 22:18:48.543985  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:18:49.080919  2642 solver.cpp:330] Iteration 31000, Testing net (#0)
I0924 22:18:52.168125  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:18:52.296337  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.739
I0924 22:18:52.296373  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.818262 (* 1 = 0.818262 loss)
I0924 22:18:52.429844  2642 solver.cpp:218] Iteration 31000 (6.01487 iter/s, 16.6255s/100 iters), loss = 0.137454
I0924 22:18:52.429872  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.137454 (* 1 = 0.137454 loss)
I0924 22:18:52.429878  2642 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I0924 22:19:05.832777  2642 solver.cpp:218] Iteration 31100 (7.46109 iter/s, 13.4029s/100 iters), loss = 0.119339
I0924 22:19:05.832815  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119338 (* 1 = 0.119338 loss)
I0924 22:19:05.832821  2642 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I0924 22:19:19.235456  2642 solver.cpp:218] Iteration 31200 (7.46124 iter/s, 13.4026s/100 iters), loss = 0.1523
I0924 22:19:19.235584  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1523 (* 1 = 0.1523 loss)
I0924 22:19:19.235591  2642 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I0924 22:19:32.635324  2642 solver.cpp:218] Iteration 31300 (7.46285 iter/s, 13.3997s/100 iters), loss = 0.198217
I0924 22:19:32.635365  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198217 (* 1 = 0.198217 loss)
I0924 22:19:32.635370  2642 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I0924 22:19:46.044885  2642 solver.cpp:218] Iteration 31400 (7.45741 iter/s, 13.4095s/100 iters), loss = 0.169552
I0924 22:19:46.044927  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169552 (* 1 = 0.169552 loss)
I0924 22:19:46.044934  2642 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I0924 22:19:58.787664  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:19:59.324162  2642 solver.cpp:330] Iteration 31500, Testing net (#0)
I0924 22:20:02.413554  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:20:02.542325  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.812
I0924 22:20:02.542361  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.602862 (* 1 = 0.602862 loss)
I0924 22:20:02.675220  2642 solver.cpp:218] Iteration 31500 (6.01314 iter/s, 16.6302s/100 iters), loss = 0.120892
I0924 22:20:02.675246  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120891 (* 1 = 0.120891 loss)
I0924 22:20:02.675253  2642 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I0924 22:20:16.074508  2642 solver.cpp:218] Iteration 31600 (7.46312 iter/s, 13.3992s/100 iters), loss = 0.238417
I0924 22:20:16.074548  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238417 (* 1 = 0.238417 loss)
I0924 22:20:16.074554  2642 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I0924 22:20:29.481108  2642 solver.cpp:218] Iteration 31700 (7.45906 iter/s, 13.4065s/100 iters), loss = 0.397159
I0924 22:20:29.481220  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.397159 (* 1 = 0.397159 loss)
I0924 22:20:29.481226  2642 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I0924 22:20:42.888497  2642 solver.cpp:218] Iteration 31800 (7.45866 iter/s, 13.4072s/100 iters), loss = 0.31779
I0924 22:20:42.888538  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31779 (* 1 = 0.31779 loss)
I0924 22:20:42.888545  2642 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I0924 22:20:56.294840  2642 solver.cpp:218] Iteration 31900 (7.4592 iter/s, 13.4063s/100 iters), loss = 0.273308
I0924 22:20:56.294881  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273307 (* 1 = 0.273307 loss)
I0924 22:20:56.294888  2642 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I0924 22:21:09.037542  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:21:09.574045  2642 solver.cpp:330] Iteration 32000, Testing net (#0)
I0924 22:21:12.661487  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:21:12.790153  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7778
I0924 22:21:12.790179  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.784261 (* 1 = 0.784261 loss)
I0924 22:21:12.923286  2642 solver.cpp:218] Iteration 32000 (6.01382 iter/s, 16.6284s/100 iters), loss = 0.156389
I0924 22:21:12.923315  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156389 (* 1 = 0.156389 loss)
I0924 22:21:12.923321  2642 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I0924 22:21:26.330435  2642 solver.cpp:218] Iteration 32100 (7.45875 iter/s, 13.4071s/100 iters), loss = 0.137442
I0924 22:21:26.330476  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.137441 (* 1 = 0.137441 loss)
I0924 22:21:26.330482  2642 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I0924 22:21:39.734539  2642 solver.cpp:218] Iteration 32200 (7.46045 iter/s, 13.404s/100 iters), loss = 0.202286
I0924 22:21:39.734606  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202286 (* 1 = 0.202286 loss)
I0924 22:21:39.734612  2642 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I0924 22:21:53.141868  2642 solver.cpp:218] Iteration 32300 (7.45867 iter/s, 13.4072s/100 iters), loss = 0.148072
I0924 22:21:53.141899  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148072 (* 1 = 0.148072 loss)
I0924 22:21:53.141904  2642 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I0924 22:22:06.544615  2642 solver.cpp:218] Iteration 32400 (7.4612 iter/s, 13.4027s/100 iters), loss = 0.161486
I0924 22:22:06.544646  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161485 (* 1 = 0.161485 loss)
I0924 22:22:06.544651  2642 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I0924 22:22:19.283898  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:22:19.820369  2642 solver.cpp:330] Iteration 32500, Testing net (#0)
I0924 22:22:22.906255  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:22:23.034970  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8411
I0924 22:22:23.035006  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.482507 (* 1 = 0.482507 loss)
I0924 22:22:23.168319  2642 solver.cpp:218] Iteration 32500 (6.01553 iter/s, 16.6236s/100 iters), loss = 0.192308
I0924 22:22:23.168345  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192307 (* 1 = 0.192307 loss)
I0924 22:22:23.168352  2642 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I0924 22:22:36.569967  2642 solver.cpp:218] Iteration 32600 (7.46181 iter/s, 13.4016s/100 iters), loss = 0.218948
I0924 22:22:36.570008  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218948 (* 1 = 0.218948 loss)
I0924 22:22:36.570013  2642 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I0924 22:22:49.980547  2642 solver.cpp:218] Iteration 32700 (7.45684 iter/s, 13.4105s/100 iters), loss = 0.203387
I0924 22:22:49.980706  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203386 (* 1 = 0.203386 loss)
I0924 22:22:49.980723  2642 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I0924 22:23:03.388046  2642 solver.cpp:218] Iteration 32800 (7.45862 iter/s, 13.4073s/100 iters), loss = 0.111136
I0924 22:23:03.388087  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.111135 (* 1 = 0.111135 loss)
I0924 22:23:03.388092  2642 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I0924 22:23:16.794066  2642 solver.cpp:218] Iteration 32900 (7.45938 iter/s, 13.4059s/100 iters), loss = 0.245404
I0924 22:23:16.794106  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245404 (* 1 = 0.245404 loss)
I0924 22:23:16.794112  2642 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I0924 22:23:29.533586  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:23:30.070909  2642 solver.cpp:330] Iteration 33000, Testing net (#0)
I0924 22:23:33.158648  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:23:33.287609  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8027
I0924 22:23:33.287647  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.647632 (* 1 = 0.647632 loss)
I0924 22:23:33.420675  2642 solver.cpp:218] Iteration 33000 (6.01449 iter/s, 16.6265s/100 iters), loss = 0.163089
I0924 22:23:33.420699  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163089 (* 1 = 0.163089 loss)
I0924 22:23:33.420706  2642 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I0924 22:23:46.823309  2642 solver.cpp:218] Iteration 33100 (7.46126 iter/s, 13.4026s/100 iters), loss = 0.143072
I0924 22:23:46.823339  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143072 (* 1 = 0.143072 loss)
I0924 22:23:46.823345  2642 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I0924 22:24:00.227830  2642 solver.cpp:218] Iteration 33200 (7.46021 iter/s, 13.4044s/100 iters), loss = 0.181179
I0924 22:24:00.227928  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181179 (* 1 = 0.181179 loss)
I0924 22:24:00.227934  2642 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I0924 22:24:13.632616  2642 solver.cpp:218] Iteration 33300 (7.4601 iter/s, 13.4046s/100 iters), loss = 0.142003
I0924 22:24:13.632658  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142002 (* 1 = 0.142002 loss)
I0924 22:24:13.632663  2642 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I0924 22:24:27.035095  2642 solver.cpp:218] Iteration 33400 (7.46135 iter/s, 13.4024s/100 iters), loss = 0.172778
I0924 22:24:27.035135  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172778 (* 1 = 0.172778 loss)
I0924 22:24:27.035141  2642 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I0924 22:24:39.773061  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:24:40.309226  2642 solver.cpp:330] Iteration 33500, Testing net (#0)
I0924 22:24:43.396826  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:24:43.525979  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7932
I0924 22:24:43.526013  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.622454 (* 1 = 0.622454 loss)
I0924 22:24:43.658920  2642 solver.cpp:218] Iteration 33500 (6.0155 iter/s, 16.6237s/100 iters), loss = 0.191275
I0924 22:24:43.658946  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191275 (* 1 = 0.191275 loss)
I0924 22:24:43.658951  2642 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I0924 22:24:57.061195  2642 solver.cpp:218] Iteration 33600 (7.46146 iter/s, 13.4022s/100 iters), loss = 0.172775
I0924 22:24:57.061236  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172775 (* 1 = 0.172775 loss)
I0924 22:24:57.061242  2642 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I0924 22:25:10.466691  2642 solver.cpp:218] Iteration 33700 (7.45967 iter/s, 13.4054s/100 iters), loss = 0.172847
I0924 22:25:10.466795  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172846 (* 1 = 0.172846 loss)
I0924 22:25:10.466811  2642 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I0924 22:25:23.870105  2642 solver.cpp:218] Iteration 33800 (7.46087 iter/s, 13.4033s/100 iters), loss = 0.155426
I0924 22:25:23.870146  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155426 (* 1 = 0.155426 loss)
I0924 22:25:23.870151  2642 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I0924 22:25:37.277587  2642 solver.cpp:218] Iteration 33900 (7.45857 iter/s, 13.4074s/100 iters), loss = 0.230956
I0924 22:25:37.277627  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230956 (* 1 = 0.230956 loss)
I0924 22:25:37.277633  2642 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I0924 22:25:50.021143  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:25:50.556704  2642 solver.cpp:330] Iteration 34000, Testing net (#0)
I0924 22:25:53.642582  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:25:53.771059  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8236
I0924 22:25:53.771093  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.54496 (* 1 = 0.54496 loss)
I0924 22:25:53.904037  2642 solver.cpp:218] Iteration 34000 (6.01454 iter/s, 16.6264s/100 iters), loss = 0.218317
I0924 22:25:53.904063  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218316 (* 1 = 0.218316 loss)
I0924 22:25:53.904069  2642 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I0924 22:26:07.310631  2642 solver.cpp:218] Iteration 34100 (7.45905 iter/s, 13.4065s/100 iters), loss = 0.175783
I0924 22:26:07.310672  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175782 (* 1 = 0.175782 loss)
I0924 22:26:07.310678  2642 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I0924 22:26:20.720784  2642 solver.cpp:218] Iteration 34200 (7.45708 iter/s, 13.4101s/100 iters), loss = 0.125856
I0924 22:26:20.720921  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.125856 (* 1 = 0.125856 loss)
I0924 22:26:20.720929  2642 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I0924 22:26:34.132336  2642 solver.cpp:218] Iteration 34300 (7.45635 iter/s, 13.4114s/100 iters), loss = 0.135774
I0924 22:26:34.132376  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135774 (* 1 = 0.135774 loss)
I0924 22:26:34.132382  2642 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I0924 22:26:47.541357  2642 solver.cpp:218] Iteration 34400 (7.45771 iter/s, 13.4089s/100 iters), loss = 0.195649
I0924 22:26:47.541396  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195649 (* 1 = 0.195649 loss)
I0924 22:26:47.541402  2642 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I0924 22:27:00.287142  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:27:00.823254  2642 solver.cpp:330] Iteration 34500, Testing net (#0)
I0924 22:27:03.909163  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:27:04.037892  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8343
I0924 22:27:04.037928  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.526401 (* 1 = 0.526401 loss)
I0924 22:27:04.171747  2642 solver.cpp:218] Iteration 34500 (6.01312 iter/s, 16.6303s/100 iters), loss = 0.125221
I0924 22:27:04.171773  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.125221 (* 1 = 0.125221 loss)
I0924 22:27:04.171779  2642 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I0924 22:27:17.574003  2642 solver.cpp:218] Iteration 34600 (7.46147 iter/s, 13.4022s/100 iters), loss = 0.243337
I0924 22:27:17.574044  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243337 (* 1 = 0.243337 loss)
I0924 22:27:17.574050  2642 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I0924 22:27:30.979938  2642 solver.cpp:218] Iteration 34700 (7.45943 iter/s, 13.4059s/100 iters), loss = 0.149717
I0924 22:27:30.980095  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149717 (* 1 = 0.149717 loss)
I0924 22:27:30.980113  2642 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I0924 22:27:44.389288  2642 solver.cpp:218] Iteration 34800 (7.45759 iter/s, 13.4092s/100 iters), loss = 0.162546
I0924 22:27:44.389319  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162546 (* 1 = 0.162546 loss)
I0924 22:27:44.389335  2642 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I0924 22:27:57.792362  2642 solver.cpp:218] Iteration 34900 (7.46102 iter/s, 13.403s/100 iters), loss = 0.163219
I0924 22:27:57.792393  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163218 (* 1 = 0.163218 loss)
I0924 22:27:57.792409  2642 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I0924 22:28:10.531471  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:28:11.068744  2642 solver.cpp:330] Iteration 35000, Testing net (#0)
I0924 22:28:14.155289  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:28:14.283351  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7491
I0924 22:28:14.283387  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.851616 (* 1 = 0.851616 loss)
I0924 22:28:14.416996  2642 solver.cpp:218] Iteration 35000 (6.0152 iter/s, 16.6246s/100 iters), loss = 0.212407
I0924 22:28:14.417021  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212407 (* 1 = 0.212407 loss)
I0924 22:28:14.417028  2642 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I0924 22:28:27.832530  2642 solver.cpp:218] Iteration 35100 (7.45408 iter/s, 13.4155s/100 iters), loss = 0.157636
I0924 22:28:27.832571  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157636 (* 1 = 0.157636 loss)
I0924 22:28:27.832576  2642 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I0924 22:28:41.252233  2642 solver.cpp:218] Iteration 35200 (7.45178 iter/s, 13.4196s/100 iters), loss = 0.166097
I0924 22:28:41.252305  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166097 (* 1 = 0.166097 loss)
I0924 22:28:41.252311  2642 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I0924 22:28:54.673804  2642 solver.cpp:218] Iteration 35300 (7.45075 iter/s, 13.4215s/100 iters), loss = 0.188124
I0924 22:28:54.673844  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188124 (* 1 = 0.188124 loss)
I0924 22:28:54.673851  2642 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I0924 22:29:08.091018  2642 solver.cpp:218] Iteration 35400 (7.45316 iter/s, 13.4171s/100 iters), loss = 0.23466
I0924 22:29:08.091058  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23466 (* 1 = 0.23466 loss)
I0924 22:29:08.091064  2642 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I0924 22:29:20.839793  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:29:21.376451  2642 solver.cpp:330] Iteration 35500, Testing net (#0)
I0924 22:29:24.464068  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:29:24.592660  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8314
I0924 22:29:24.592696  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.544029 (* 1 = 0.544029 loss)
I0924 22:29:24.725545  2642 solver.cpp:218] Iteration 35500 (6.01162 iter/s, 16.6344s/100 iters), loss = 0.170131
I0924 22:29:24.725571  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170131 (* 1 = 0.170131 loss)
I0924 22:29:24.725579  2642 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I0924 22:29:38.132352  2642 solver.cpp:218] Iteration 35600 (7.45893 iter/s, 13.4067s/100 iters), loss = 0.176665
I0924 22:29:38.132392  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176664 (* 1 = 0.176664 loss)
I0924 22:29:38.132397  2642 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I0924 22:29:51.539069  2642 solver.cpp:218] Iteration 35700 (7.45899 iter/s, 13.4066s/100 iters), loss = 0.161528
I0924 22:29:51.539152  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161527 (* 1 = 0.161527 loss)
I0924 22:29:51.539160  2642 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I0924 22:30:04.943866  2642 solver.cpp:218] Iteration 35800 (7.46008 iter/s, 13.4047s/100 iters), loss = 0.219339
I0924 22:30:04.943907  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219339 (* 1 = 0.219339 loss)
I0924 22:30:04.943913  2642 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I0924 22:30:18.345528  2642 solver.cpp:218] Iteration 35900 (7.46181 iter/s, 13.4016s/100 iters), loss = 0.184146
I0924 22:30:18.345568  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184146 (* 1 = 0.184146 loss)
I0924 22:30:18.345573  2642 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I0924 22:30:31.087859  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:30:31.624264  2642 solver.cpp:330] Iteration 36000, Testing net (#0)
I0924 22:30:34.711616  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:30:34.840191  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7307
I0924 22:30:34.840217  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.877484 (* 1 = 0.877484 loss)
I0924 22:30:34.973415  2642 solver.cpp:218] Iteration 36000 (6.01403 iter/s, 16.6278s/100 iters), loss = 0.131058
I0924 22:30:34.973443  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.131058 (* 1 = 0.131058 loss)
I0924 22:30:34.973448  2642 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I0924 22:30:48.372480  2642 solver.cpp:218] Iteration 36100 (7.46324 iter/s, 13.399s/100 iters), loss = 0.168872
I0924 22:30:48.372509  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168872 (* 1 = 0.168872 loss)
I0924 22:30:48.372515  2642 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I0924 22:31:01.776880  2642 solver.cpp:218] Iteration 36200 (7.46028 iter/s, 13.4043s/100 iters), loss = 0.157595
I0924 22:31:01.776983  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157595 (* 1 = 0.157595 loss)
I0924 22:31:01.776989  2642 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I0924 22:31:15.178791  2642 solver.cpp:218] Iteration 36300 (7.4617 iter/s, 13.4018s/100 iters), loss = 0.209768
I0924 22:31:15.178830  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209768 (* 1 = 0.209768 loss)
I0924 22:31:15.178836  2642 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I0924 22:31:28.577185  2642 solver.cpp:218] Iteration 36400 (7.46363 iter/s, 13.3983s/100 iters), loss = 0.146664
I0924 22:31:28.577215  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146663 (* 1 = 0.146663 loss)
I0924 22:31:28.577221  2642 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I0924 22:31:41.313329  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:31:41.849808  2642 solver.cpp:330] Iteration 36500, Testing net (#0)
I0924 22:31:44.935691  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:31:45.064172  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7155
I0924 22:31:45.064196  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.956513 (* 1 = 0.956513 loss)
I0924 22:31:45.197054  2642 solver.cpp:218] Iteration 36500 (6.01692 iter/s, 16.6198s/100 iters), loss = 0.17234
I0924 22:31:45.197082  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17234 (* 1 = 0.17234 loss)
I0924 22:31:45.197088  2642 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I0924 22:31:58.608211  2642 solver.cpp:218] Iteration 36600 (7.45652 iter/s, 13.4111s/100 iters), loss = 0.234603
I0924 22:31:58.608250  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234602 (* 1 = 0.234602 loss)
I0924 22:31:58.608256  2642 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I0924 22:32:12.020974  2642 solver.cpp:218] Iteration 36700 (7.45563 iter/s, 13.4127s/100 iters), loss = 0.167076
I0924 22:32:12.021119  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167076 (* 1 = 0.167076 loss)
I0924 22:32:12.021126  2642 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I0924 22:32:25.432811  2642 solver.cpp:218] Iteration 36800 (7.4562 iter/s, 13.4117s/100 iters), loss = 0.164974
I0924 22:32:25.432852  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164973 (* 1 = 0.164973 loss)
I0924 22:32:25.432857  2642 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I0924 22:32:38.842480  2642 solver.cpp:218] Iteration 36900 (7.45735 iter/s, 13.4096s/100 iters), loss = 0.135693
I0924 22:32:38.842521  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135692 (* 1 = 0.135692 loss)
I0924 22:32:38.842527  2642 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I0924 22:32:51.582901  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:32:52.120132  2642 solver.cpp:330] Iteration 37000, Testing net (#0)
I0924 22:32:55.207644  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:32:55.336633  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8436
I0924 22:32:55.336670  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.461015 (* 1 = 0.461015 loss)
I0924 22:32:55.470104  2642 solver.cpp:218] Iteration 37000 (6.01412 iter/s, 16.6275s/100 iters), loss = 0.160091
I0924 22:32:55.470132  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16009 (* 1 = 0.16009 loss)
I0924 22:32:55.470139  2642 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I0924 22:33:08.865281  2642 solver.cpp:218] Iteration 37100 (7.46542 iter/s, 13.3951s/100 iters), loss = 0.229028
I0924 22:33:08.865321  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229028 (* 1 = 0.229028 loss)
I0924 22:33:08.865327  2642 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I0924 22:33:22.262076  2642 solver.cpp:218] Iteration 37200 (7.46452 iter/s, 13.3967s/100 iters), loss = 0.165886
I0924 22:33:22.262198  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165886 (* 1 = 0.165886 loss)
I0924 22:33:22.262205  2642 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I0924 22:33:35.653333  2642 solver.cpp:218] Iteration 37300 (7.46765 iter/s, 13.3911s/100 iters), loss = 0.191155
I0924 22:33:35.653374  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191155 (* 1 = 0.191155 loss)
I0924 22:33:35.653380  2642 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I0924 22:33:49.055927  2642 solver.cpp:218] Iteration 37400 (7.46129 iter/s, 13.4025s/100 iters), loss = 0.18736
I0924 22:33:49.055955  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18736 (* 1 = 0.18736 loss)
I0924 22:33:49.055961  2642 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I0924 22:34:01.794960  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:34:02.329473  2642 solver.cpp:330] Iteration 37500, Testing net (#0)
I0924 22:34:05.416079  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:34:05.545065  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8197
I0924 22:34:05.545101  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.577162 (* 1 = 0.577162 loss)
I0924 22:34:05.678689  2642 solver.cpp:218] Iteration 37500 (6.01587 iter/s, 16.6227s/100 iters), loss = 0.237331
I0924 22:34:05.678715  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237331 (* 1 = 0.237331 loss)
I0924 22:34:05.678721  2642 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I0924 22:34:19.086647  2642 solver.cpp:218] Iteration 37600 (7.4583 iter/s, 13.4079s/100 iters), loss = 0.191498
I0924 22:34:19.086676  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191498 (* 1 = 0.191498 loss)
I0924 22:34:19.086683  2642 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I0924 22:34:32.492962  2642 solver.cpp:218] Iteration 37700 (7.45921 iter/s, 13.4062s/100 iters), loss = 0.244258
I0924 22:34:32.493057  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244257 (* 1 = 0.244257 loss)
I0924 22:34:32.493067  2642 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I0924 22:34:45.903844  2642 solver.cpp:218] Iteration 37800 (7.45671 iter/s, 13.4107s/100 iters), loss = 0.173769
I0924 22:34:45.903884  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173769 (* 1 = 0.173769 loss)
I0924 22:34:45.903890  2642 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I0924 22:34:59.314313  2642 solver.cpp:218] Iteration 37900 (7.45691 iter/s, 13.4104s/100 iters), loss = 0.235501
I0924 22:34:59.314354  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2355 (* 1 = 0.2355 loss)
I0924 22:34:59.314359  2642 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I0924 22:35:12.053184  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:35:12.589723  2642 solver.cpp:330] Iteration 38000, Testing net (#0)
I0924 22:35:15.677233  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:35:15.806023  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7834
I0924 22:35:15.806059  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.681433 (* 1 = 0.681433 loss)
I0924 22:35:15.939059  2642 solver.cpp:218] Iteration 38000 (6.01516 iter/s, 16.6247s/100 iters), loss = 0.13996
I0924 22:35:15.939086  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139959 (* 1 = 0.139959 loss)
I0924 22:35:15.939093  2642 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I0924 22:35:29.341766  2642 solver.cpp:218] Iteration 38100 (7.46122 iter/s, 13.4026s/100 iters), loss = 0.252566
I0924 22:35:29.341806  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252565 (* 1 = 0.252565 loss)
I0924 22:35:29.341812  2642 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I0924 22:35:42.751327  2642 solver.cpp:218] Iteration 38200 (7.45741 iter/s, 13.4095s/100 iters), loss = 0.193078
I0924 22:35:42.751394  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193078 (* 1 = 0.193078 loss)
I0924 22:35:42.751402  2642 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I0924 22:35:56.154213  2642 solver.cpp:218] Iteration 38300 (7.46114 iter/s, 13.4028s/100 iters), loss = 0.212566
I0924 22:35:56.154254  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212566 (* 1 = 0.212566 loss)
I0924 22:35:56.154260  2642 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I0924 22:36:09.566398  2642 solver.cpp:218] Iteration 38400 (7.45595 iter/s, 13.4121s/100 iters), loss = 0.201563
I0924 22:36:09.566439  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201562 (* 1 = 0.201562 loss)
I0924 22:36:09.566445  2642 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I0924 22:36:22.308720  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:36:22.845119  2642 solver.cpp:330] Iteration 38500, Testing net (#0)
I0924 22:36:25.932833  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:36:26.061833  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7288
I0924 22:36:26.061869  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.921793 (* 1 = 0.921793 loss)
I0924 22:36:26.194785  2642 solver.cpp:218] Iteration 38500 (6.01384 iter/s, 16.6283s/100 iters), loss = 0.168326
I0924 22:36:26.194813  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168326 (* 1 = 0.168326 loss)
I0924 22:36:26.194819  2642 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I0924 22:36:39.595180  2642 solver.cpp:218] Iteration 38600 (7.46251 iter/s, 13.4003s/100 iters), loss = 0.243783
I0924 22:36:39.595222  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243782 (* 1 = 0.243782 loss)
I0924 22:36:39.595227  2642 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I0924 22:36:52.999783  2642 solver.cpp:218] Iteration 38700 (7.46017 iter/s, 13.4045s/100 iters), loss = 0.14928
I0924 22:36:52.999907  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14928 (* 1 = 0.14928 loss)
I0924 22:36:52.999914  2642 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I0924 22:37:06.407038  2642 solver.cpp:218] Iteration 38800 (7.45874 iter/s, 13.4071s/100 iters), loss = 0.183906
I0924 22:37:06.407069  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183905 (* 1 = 0.183905 loss)
I0924 22:37:06.407075  2642 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I0924 22:37:19.811975  2642 solver.cpp:218] Iteration 38900 (7.45998 iter/s, 13.4049s/100 iters), loss = 0.143361
I0924 22:37:19.812017  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143361 (* 1 = 0.143361 loss)
I0924 22:37:19.812022  2642 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I0924 22:37:32.551656  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:37:33.088305  2642 solver.cpp:330] Iteration 39000, Testing net (#0)
I0924 22:37:36.174715  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:37:36.303652  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.752
I0924 22:37:36.303688  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.830107 (* 1 = 0.830107 loss)
I0924 22:37:36.436952  2642 solver.cpp:218] Iteration 39000 (6.01508 iter/s, 16.6249s/100 iters), loss = 0.13957
I0924 22:37:36.436980  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13957 (* 1 = 0.13957 loss)
I0924 22:37:36.436985  2642 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I0924 22:37:49.837159  2642 solver.cpp:218] Iteration 39100 (7.46261 iter/s, 13.4001s/100 iters), loss = 0.157557
I0924 22:37:49.837199  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157557 (* 1 = 0.157557 loss)
I0924 22:37:49.837205  2642 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I0924 22:38:03.244782  2642 solver.cpp:218] Iteration 39200 (7.45849 iter/s, 13.4075s/100 iters), loss = 0.153037
I0924 22:38:03.244912  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153037 (* 1 = 0.153037 loss)
I0924 22:38:03.244925  2642 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I0924 22:38:16.653605  2642 solver.cpp:218] Iteration 39300 (7.45787 iter/s, 13.4087s/100 iters), loss = 0.103707
I0924 22:38:16.653647  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103706 (* 1 = 0.103706 loss)
I0924 22:38:16.653652  2642 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I0924 22:38:30.061650  2642 solver.cpp:218] Iteration 39400 (7.45825 iter/s, 13.408s/100 iters), loss = 0.144483
I0924 22:38:30.061691  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144483 (* 1 = 0.144483 loss)
I0924 22:38:30.061697  2642 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I0924 22:38:42.801800  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:38:43.338650  2642 solver.cpp:330] Iteration 39500, Testing net (#0)
I0924 22:38:46.425879  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:38:46.554491  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8246
I0924 22:38:46.554517  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.566001 (* 1 = 0.566001 loss)
I0924 22:38:46.688422  2642 solver.cpp:218] Iteration 39500 (6.01443 iter/s, 16.6267s/100 iters), loss = 0.234811
I0924 22:38:46.688448  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234811 (* 1 = 0.234811 loss)
I0924 22:38:46.688454  2642 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I0924 22:39:00.093086  2642 solver.cpp:218] Iteration 39600 (7.46013 iter/s, 13.4046s/100 iters), loss = 0.169521
I0924 22:39:00.093127  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16952 (* 1 = 0.16952 loss)
I0924 22:39:00.093132  2642 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I0924 22:39:13.505524  2642 solver.cpp:218] Iteration 39700 (7.45581 iter/s, 13.4124s/100 iters), loss = 0.146447
I0924 22:39:13.505594  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146446 (* 1 = 0.146446 loss)
I0924 22:39:13.505600  2642 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I0924 22:39:26.910739  2642 solver.cpp:218] Iteration 39800 (7.45984 iter/s, 13.4051s/100 iters), loss = 0.197171
I0924 22:39:26.910780  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197171 (* 1 = 0.197171 loss)
I0924 22:39:26.910785  2642 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I0924 22:39:40.320353  2642 solver.cpp:218] Iteration 39900 (7.45738 iter/s, 13.4095s/100 iters), loss = 0.174127
I0924 22:39:40.320392  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174127 (* 1 = 0.174127 loss)
I0924 22:39:40.320399  2642 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I0924 22:39:53.059965  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:39:53.596071  2642 solver.cpp:330] Iteration 40000, Testing net (#0)
I0924 22:39:56.683217  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:39:56.811949  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8183
I0924 22:39:56.811985  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.586843 (* 1 = 0.586843 loss)
I0924 22:39:56.944643  2642 solver.cpp:218] Iteration 40000 (6.01533 iter/s, 16.6242s/100 iters), loss = 0.182224
I0924 22:39:56.944680  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182224 (* 1 = 0.182224 loss)
I0924 22:39:56.944685  2642 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I0924 22:39:56.944689  2642 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I0924 22:40:10.343333  2642 solver.cpp:218] Iteration 40100 (7.46346 iter/s, 13.3986s/100 iters), loss = 0.185318
I0924 22:40:10.343372  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185317 (* 1 = 0.185317 loss)
I0924 22:40:10.343379  2642 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I0924 22:40:23.740646  2642 solver.cpp:218] Iteration 40200 (7.46423 iter/s, 13.3972s/100 iters), loss = 0.142419
I0924 22:40:23.740748  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142419 (* 1 = 0.142419 loss)
I0924 22:40:23.740754  2642 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I0924 22:40:37.146288  2642 solver.cpp:218] Iteration 40300 (7.45962 iter/s, 13.4055s/100 iters), loss = 0.0858537
I0924 22:40:37.146328  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0858533 (* 1 = 0.0858533 loss)
I0924 22:40:37.146333  2642 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I0924 22:40:50.546824  2642 solver.cpp:218] Iteration 40400 (7.46243 iter/s, 13.4005s/100 iters), loss = 0.119202
I0924 22:40:50.546865  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119201 (* 1 = 0.119201 loss)
I0924 22:40:50.546871  2642 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I0924 22:41:03.282896  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:41:03.819566  2642 solver.cpp:330] Iteration 40500, Testing net (#0)
I0924 22:41:06.906074  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:41:07.034622  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.909
I0924 22:41:07.034658  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.264049 (* 1 = 0.264049 loss)
I0924 22:41:07.167469  2642 solver.cpp:218] Iteration 40500 (6.01665 iter/s, 16.6206s/100 iters), loss = 0.0813727
I0924 22:41:07.167496  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0813723 (* 1 = 0.0813723 loss)
I0924 22:41:07.167513  2642 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I0924 22:41:20.577847  2642 solver.cpp:218] Iteration 40600 (7.45695 iter/s, 13.4103s/100 iters), loss = 0.112444
I0924 22:41:20.577877  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.112443 (* 1 = 0.112443 loss)
I0924 22:41:20.577883  2642 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I0924 22:41:33.979303  2642 solver.cpp:218] Iteration 40700 (7.46191 iter/s, 13.4014s/100 iters), loss = 0.108069
I0924 22:41:33.979364  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.108068 (* 1 = 0.108068 loss)
I0924 22:41:33.979372  2642 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I0924 22:41:47.389725  2642 solver.cpp:218] Iteration 40800 (7.45694 iter/s, 13.4103s/100 iters), loss = 0.0355639
I0924 22:41:47.389756  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0355635 (* 1 = 0.0355635 loss)
I0924 22:41:47.389762  2642 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I0924 22:42:00.796720  2642 solver.cpp:218] Iteration 40900 (7.45883 iter/s, 13.4069s/100 iters), loss = 0.0690796
I0924 22:42:00.796761  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0690792 (* 1 = 0.0690792 loss)
I0924 22:42:00.796766  2642 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I0924 22:42:13.536284  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:42:14.072077  2642 solver.cpp:330] Iteration 41000, Testing net (#0)
I0924 22:42:17.157549  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:42:17.285778  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9148
I0924 22:42:17.285804  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.248727 (* 1 = 0.248727 loss)
I0924 22:42:17.419072  2642 solver.cpp:218] Iteration 41000 (6.01603 iter/s, 16.6223s/100 iters), loss = 0.0255832
I0924 22:42:17.419098  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0255828 (* 1 = 0.0255828 loss)
I0924 22:42:17.419106  2642 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I0924 22:42:30.823004  2642 solver.cpp:218] Iteration 41100 (7.46054 iter/s, 13.4039s/100 iters), loss = 0.135756
I0924 22:42:30.823043  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135756 (* 1 = 0.135756 loss)
I0924 22:42:30.823048  2642 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I0924 22:42:44.230346  2642 solver.cpp:218] Iteration 41200 (7.45864 iter/s, 13.4073s/100 iters), loss = 0.0896305
I0924 22:42:44.230449  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0896301 (* 1 = 0.0896301 loss)
I0924 22:42:44.230456  2642 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I0924 22:42:57.636044  2642 solver.cpp:218] Iteration 41300 (7.45959 iter/s, 13.4056s/100 iters), loss = 0.0526936
I0924 22:42:57.636085  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0526932 (* 1 = 0.0526932 loss)
I0924 22:42:57.636091  2642 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I0924 22:43:11.044531  2642 solver.cpp:218] Iteration 41400 (7.45801 iter/s, 13.4084s/100 iters), loss = 0.064056
I0924 22:43:11.044561  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0640557 (* 1 = 0.0640557 loss)
I0924 22:43:11.044567  2642 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I0924 22:43:23.786702  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:43:24.322835  2642 solver.cpp:330] Iteration 41500, Testing net (#0)
I0924 22:43:27.409482  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:43:27.537853  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9132
I0924 22:43:27.537889  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.255597 (* 1 = 0.255597 loss)
I0924 22:43:27.671026  2642 solver.cpp:218] Iteration 41500 (6.01453 iter/s, 16.6264s/100 iters), loss = 0.0399878
I0924 22:43:27.671053  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0399874 (* 1 = 0.0399874 loss)
I0924 22:43:27.671059  2642 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I0924 22:43:41.086696  2642 solver.cpp:218] Iteration 41600 (7.45401 iter/s, 13.4156s/100 iters), loss = 0.0914137
I0924 22:43:41.086726  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0914133 (* 1 = 0.0914133 loss)
I0924 22:43:41.086732  2642 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I0924 22:43:54.496311  2642 solver.cpp:218] Iteration 41700 (7.45737 iter/s, 13.4095s/100 iters), loss = 0.083826
I0924 22:43:54.496409  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0838256 (* 1 = 0.0838256 loss)
I0924 22:43:54.496417  2642 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I0924 22:44:07.913552  2642 solver.cpp:218] Iteration 41800 (7.45317 iter/s, 13.4171s/100 iters), loss = 0.0259301
I0924 22:44:07.913592  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0259297 (* 1 = 0.0259297 loss)
I0924 22:44:07.913599  2642 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I0924 22:44:21.316171  2642 solver.cpp:218] Iteration 41900 (7.46127 iter/s, 13.4025s/100 iters), loss = 0.0594941
I0924 22:44:21.316211  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0594937 (* 1 = 0.0594937 loss)
I0924 22:44:21.316217  2642 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I0924 22:44:34.059628  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:44:34.595278  2642 solver.cpp:330] Iteration 42000, Testing net (#0)
I0924 22:44:37.681363  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:44:37.810197  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9169
I0924 22:44:37.810235  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.256028 (* 1 = 0.256028 loss)
I0924 22:44:37.943557  2642 solver.cpp:218] Iteration 42000 (6.01421 iter/s, 16.6273s/100 iters), loss = 0.0416688
I0924 22:44:37.943585  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0416684 (* 1 = 0.0416684 loss)
I0924 22:44:37.943593  2642 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I0924 22:44:51.347118  2642 solver.cpp:218] Iteration 42100 (7.46074 iter/s, 13.4035s/100 iters), loss = 0.0808644
I0924 22:44:51.347157  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.080864 (* 1 = 0.080864 loss)
I0924 22:44:51.347163  2642 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I0924 22:45:04.756580  2642 solver.cpp:218] Iteration 42200 (7.45746 iter/s, 13.4094s/100 iters), loss = 0.0816714
I0924 22:45:04.756641  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.081671 (* 1 = 0.081671 loss)
I0924 22:45:04.756649  2642 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I0924 22:45:18.167994  2642 solver.cpp:218] Iteration 42300 (7.45639 iter/s, 13.4113s/100 iters), loss = 0.0355659
I0924 22:45:18.168035  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0355655 (* 1 = 0.0355655 loss)
I0924 22:45:18.168041  2642 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I0924 22:45:31.574911  2642 solver.cpp:218] Iteration 42400 (7.45888 iter/s, 13.4068s/100 iters), loss = 0.0472282
I0924 22:45:31.574952  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0472278 (* 1 = 0.0472278 loss)
I0924 22:45:31.574959  2642 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I0924 22:45:44.321604  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:45:44.857748  2642 solver.cpp:330] Iteration 42500, Testing net (#0)
I0924 22:45:47.943840  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:45:48.072582  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9188
I0924 22:45:48.072618  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.254437 (* 1 = 0.254437 loss)
I0924 22:45:48.206459  2642 solver.cpp:218] Iteration 42500 (6.0127 iter/s, 16.6315s/100 iters), loss = 0.0382451
I0924 22:45:48.206485  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0382446 (* 1 = 0.0382446 loss)
I0924 22:45:48.206491  2642 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I0924 22:46:01.619359  2642 solver.cpp:218] Iteration 42600 (7.45555 iter/s, 13.4128s/100 iters), loss = 0.0897395
I0924 22:46:01.619390  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.089739 (* 1 = 0.089739 loss)
I0924 22:46:01.619405  2642 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I0924 22:46:15.027405  2642 solver.cpp:218] Iteration 42700 (7.45825 iter/s, 13.408s/100 iters), loss = 0.0478838
I0924 22:46:15.027524  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0478834 (* 1 = 0.0478834 loss)
I0924 22:46:15.027531  2642 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I0924 22:46:28.439154  2642 solver.cpp:218] Iteration 42800 (7.45624 iter/s, 13.4116s/100 iters), loss = 0.0333048
I0924 22:46:28.439187  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0333043 (* 1 = 0.0333043 loss)
I0924 22:46:28.439201  2642 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I0924 22:46:41.852845  2642 solver.cpp:218] Iteration 42900 (7.45511 iter/s, 13.4136s/100 iters), loss = 0.0340867
I0924 22:46:41.852876  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0340862 (* 1 = 0.0340862 loss)
I0924 22:46:41.852892  2642 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I0924 22:46:54.599665  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:46:55.135700  2642 solver.cpp:330] Iteration 43000, Testing net (#0)
I0924 22:46:58.223006  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:46:58.351079  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9186
I0924 22:46:58.351115  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.251879 (* 1 = 0.251879 loss)
I0924 22:46:58.483953  2642 solver.cpp:218] Iteration 43000 (6.01286 iter/s, 16.631s/100 iters), loss = 0.030853
I0924 22:46:58.483979  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0308526 (* 1 = 0.0308526 loss)
I0924 22:46:58.483986  2642 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I0924 22:47:11.877712  2642 solver.cpp:218] Iteration 43100 (7.4662 iter/s, 13.3937s/100 iters), loss = 0.0740316
I0924 22:47:11.877753  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0740312 (* 1 = 0.0740312 loss)
I0924 22:47:11.877758  2642 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I0924 22:47:25.278074  2642 solver.cpp:218] Iteration 43200 (7.46253 iter/s, 13.4003s/100 iters), loss = 0.0628637
I0924 22:47:25.278146  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0628632 (* 1 = 0.0628632 loss)
I0924 22:47:25.278153  2642 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I0924 22:47:38.683885  2642 solver.cpp:218] Iteration 43300 (7.45951 iter/s, 13.4057s/100 iters), loss = 0.0160829
I0924 22:47:38.683926  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0160824 (* 1 = 0.0160824 loss)
I0924 22:47:38.683931  2642 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I0924 22:47:52.083611  2642 solver.cpp:218] Iteration 43400 (7.46288 iter/s, 13.3996s/100 iters), loss = 0.025498
I0924 22:47:52.083640  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0254975 (* 1 = 0.0254975 loss)
I0924 22:47:52.083647  2642 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I0924 22:48:04.823451  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:48:05.359480  2642 solver.cpp:330] Iteration 43500, Testing net (#0)
I0924 22:48:08.446966  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:48:08.576042  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9171
I0924 22:48:08.576078  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.26504 (* 1 = 0.26504 loss)
I0924 22:48:08.709853  2642 solver.cpp:218] Iteration 43500 (6.01462 iter/s, 16.6262s/100 iters), loss = 0.0187227
I0924 22:48:08.709880  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0187222 (* 1 = 0.0187222 loss)
I0924 22:48:08.709887  2642 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I0924 22:48:22.113385  2642 solver.cpp:218] Iteration 43600 (7.46076 iter/s, 13.4035s/100 iters), loss = 0.0244591
I0924 22:48:22.113426  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0244586 (* 1 = 0.0244586 loss)
I0924 22:48:22.113432  2642 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I0924 22:48:35.522450  2642 solver.cpp:218] Iteration 43700 (7.45769 iter/s, 13.409s/100 iters), loss = 0.0666131
I0924 22:48:35.522537  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0666125 (* 1 = 0.0666125 loss)
I0924 22:48:35.522553  2642 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I0924 22:48:48.923399  2642 solver.cpp:218] Iteration 43800 (7.46223 iter/s, 13.4008s/100 iters), loss = 0.0180936
I0924 22:48:48.923440  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0180931 (* 1 = 0.0180931 loss)
I0924 22:48:48.923446  2642 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I0924 22:49:02.338332  2642 solver.cpp:218] Iteration 43900 (7.45442 iter/s, 13.4149s/100 iters), loss = 0.0393492
I0924 22:49:02.338373  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0393486 (* 1 = 0.0393486 loss)
I0924 22:49:02.338378  2642 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I0924 22:49:15.085830  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:49:15.622382  2642 solver.cpp:330] Iteration 44000, Testing net (#0)
I0924 22:49:18.710014  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:49:18.839007  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9192
I0924 22:49:18.839043  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.258894 (* 1 = 0.258894 loss)
I0924 22:49:18.972333  2642 solver.cpp:218] Iteration 44000 (6.01182 iter/s, 16.6339s/100 iters), loss = 0.0294075
I0924 22:49:18.972360  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.029407 (* 1 = 0.029407 loss)
I0924 22:49:18.972368  2642 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I0924 22:49:32.376379  2642 solver.cpp:218] Iteration 44100 (7.46047 iter/s, 13.404s/100 iters), loss = 0.0436411
I0924 22:49:32.376420  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0436406 (* 1 = 0.0436406 loss)
I0924 22:49:32.376426  2642 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I0924 22:49:45.784711  2642 solver.cpp:218] Iteration 44200 (7.45809 iter/s, 13.4083s/100 iters), loss = 0.0142532
I0924 22:49:45.784785  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142527 (* 1 = 0.0142527 loss)
I0924 22:49:45.784791  2642 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I0924 22:49:59.189257  2642 solver.cpp:218] Iteration 44300 (7.46022 iter/s, 13.4044s/100 iters), loss = 0.0106896
I0924 22:49:59.189297  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106892 (* 1 = 0.0106892 loss)
I0924 22:49:59.189303  2642 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I0924 22:50:12.596294  2642 solver.cpp:218] Iteration 44400 (7.45881 iter/s, 13.407s/100 iters), loss = 0.0183913
I0924 22:50:12.596334  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0183908 (* 1 = 0.0183908 loss)
I0924 22:50:12.596340  2642 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I0924 22:50:25.340406  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:50:25.877655  2642 solver.cpp:330] Iteration 44500, Testing net (#0)
I0924 22:50:28.964366  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:50:29.093490  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9195
I0924 22:50:29.093525  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.258555 (* 1 = 0.258555 loss)
I0924 22:50:29.226918  2642 solver.cpp:218] Iteration 44500 (6.01303 iter/s, 16.6305s/100 iters), loss = 0.0126726
I0924 22:50:29.226955  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126721 (* 1 = 0.0126721 loss)
I0924 22:50:29.226963  2642 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I0924 22:50:42.628747  2642 solver.cpp:218] Iteration 44600 (7.46171 iter/s, 13.4017s/100 iters), loss = 0.055681
I0924 22:50:42.628778  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0556805 (* 1 = 0.0556805 loss)
I0924 22:50:42.628784  2642 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I0924 22:50:56.039849  2642 solver.cpp:218] Iteration 44700 (7.45655 iter/s, 13.411s/100 iters), loss = 0.103142
I0924 22:50:56.039908  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103142 (* 1 = 0.103142 loss)
I0924 22:50:56.039916  2642 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I0924 22:51:09.447540  2642 solver.cpp:218] Iteration 44800 (7.45846 iter/s, 13.4076s/100 iters), loss = 0.0157575
I0924 22:51:09.447578  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015757 (* 1 = 0.015757 loss)
I0924 22:51:09.447584  2642 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I0924 22:51:22.858069  2642 solver.cpp:218] Iteration 44900 (7.45687 iter/s, 13.4105s/100 iters), loss = 0.0264226
I0924 22:51:22.858109  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0264221 (* 1 = 0.0264221 loss)
I0924 22:51:22.858115  2642 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I0924 22:51:35.595821  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:51:36.132984  2642 solver.cpp:330] Iteration 45000, Testing net (#0)
I0924 22:51:39.221362  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:51:39.349758  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9166
I0924 22:51:39.349792  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.267174 (* 1 = 0.267174 loss)
I0924 22:51:39.483172  2642 solver.cpp:218] Iteration 45000 (6.01503 iter/s, 16.625s/100 iters), loss = 0.0453199
I0924 22:51:39.483198  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0453194 (* 1 = 0.0453194 loss)
I0924 22:51:39.483204  2642 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I0924 22:51:52.886050  2642 solver.cpp:218] Iteration 45100 (7.46112 iter/s, 13.4028s/100 iters), loss = 0.032537
I0924 22:51:52.886081  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0325366 (* 1 = 0.0325366 loss)
I0924 22:51:52.886087  2642 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I0924 22:52:06.293925  2642 solver.cpp:218] Iteration 45200 (7.45834 iter/s, 13.4078s/100 iters), loss = 0.0467227
I0924 22:52:06.293985  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0467222 (* 1 = 0.0467222 loss)
I0924 22:52:06.293992  2642 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I0924 22:52:19.708788  2642 solver.cpp:218] Iteration 45300 (7.45447 iter/s, 13.4148s/100 iters), loss = 0.030491
I0924 22:52:19.708828  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0304905 (* 1 = 0.0304905 loss)
I0924 22:52:19.708834  2642 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I0924 22:52:33.112752  2642 solver.cpp:218] Iteration 45400 (7.46052 iter/s, 13.4039s/100 iters), loss = 0.030355
I0924 22:52:33.112782  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0303545 (* 1 = 0.0303545 loss)
I0924 22:52:33.112788  2642 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I0924 22:52:45.853377  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:52:46.390300  2642 solver.cpp:330] Iteration 45500, Testing net (#0)
I0924 22:52:49.477305  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:52:49.606319  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9133
I0924 22:52:49.606355  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.280564 (* 1 = 0.280564 loss)
I0924 22:52:49.739369  2642 solver.cpp:218] Iteration 45500 (6.01448 iter/s, 16.6265s/100 iters), loss = 0.0158446
I0924 22:52:49.739406  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0158441 (* 1 = 0.0158441 loss)
I0924 22:52:49.739413  2642 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I0924 22:53:03.134110  2642 solver.cpp:218] Iteration 45600 (7.46566 iter/s, 13.3947s/100 iters), loss = 0.0423113
I0924 22:53:03.134151  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0423109 (* 1 = 0.0423109 loss)
I0924 22:53:03.134156  2642 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I0924 22:53:16.536620  2642 solver.cpp:218] Iteration 45700 (7.46133 iter/s, 13.4024s/100 iters), loss = 0.0432457
I0924 22:53:16.536690  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0432452 (* 1 = 0.0432452 loss)
I0924 22:53:16.536697  2642 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I0924 22:53:29.932921  2642 solver.cpp:218] Iteration 45800 (7.46481 iter/s, 13.3962s/100 iters), loss = 0.013585
I0924 22:53:29.932970  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0135845 (* 1 = 0.0135845 loss)
I0924 22:53:29.932978  2642 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I0924 22:53:43.337416  2642 solver.cpp:218] Iteration 45900 (7.46023 iter/s, 13.4044s/100 iters), loss = 0.045133
I0924 22:53:43.337458  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0451325 (* 1 = 0.0451325 loss)
I0924 22:53:43.337463  2642 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I0924 22:53:56.078332  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:53:56.614356  2642 solver.cpp:330] Iteration 46000, Testing net (#0)
I0924 22:53:59.702203  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:53:59.830371  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9187
I0924 22:53:59.830407  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.271762 (* 1 = 0.271762 loss)
I0924 22:53:59.963436  2642 solver.cpp:218] Iteration 46000 (6.0147 iter/s, 16.6259s/100 iters), loss = 0.0353132
I0924 22:53:59.963464  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0353127 (* 1 = 0.0353127 loss)
I0924 22:53:59.963469  2642 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I0924 22:54:13.372586  2642 solver.cpp:218] Iteration 46100 (7.45763 iter/s, 13.4091s/100 iters), loss = 0.0319407
I0924 22:54:13.372627  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0319402 (* 1 = 0.0319402 loss)
I0924 22:54:13.372632  2642 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I0924 22:54:26.784858  2642 solver.cpp:218] Iteration 46200 (7.4559 iter/s, 13.4122s/100 iters), loss = 0.0132852
I0924 22:54:26.784924  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132847 (* 1 = 0.0132847 loss)
I0924 22:54:26.784932  2642 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I0924 22:54:40.197690  2642 solver.cpp:218] Iteration 46300 (7.4556 iter/s, 13.4127s/100 iters), loss = 0.0428125
I0924 22:54:40.197731  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0428121 (* 1 = 0.0428121 loss)
I0924 22:54:40.197737  2642 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I0924 22:54:53.609570  2642 solver.cpp:218] Iteration 46400 (7.45612 iter/s, 13.4118s/100 iters), loss = 0.0511116
I0924 22:54:53.609611  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0511111 (* 1 = 0.0511111 loss)
I0924 22:54:53.609616  2642 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I0924 22:55:06.354146  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:55:06.891753  2642 solver.cpp:330] Iteration 46500, Testing net (#0)
I0924 22:55:09.979053  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:55:10.107833  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9202
I0924 22:55:10.107870  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.26917 (* 1 = 0.26917 loss)
I0924 22:55:10.241382  2642 solver.cpp:218] Iteration 46500 (6.01261 iter/s, 16.6317s/100 iters), loss = 0.0108798
I0924 22:55:10.241408  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108793 (* 1 = 0.0108793 loss)
I0924 22:55:10.241415  2642 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I0924 22:55:23.649482  2642 solver.cpp:218] Iteration 46600 (7.45822 iter/s, 13.408s/100 iters), loss = 0.0408069
I0924 22:55:23.649508  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0408064 (* 1 = 0.0408064 loss)
I0924 22:55:23.649515  2642 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I0924 22:55:37.058339  2642 solver.cpp:218] Iteration 46700 (7.4578 iter/s, 13.4088s/100 iters), loss = 0.0324774
I0924 22:55:37.058461  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0324769 (* 1 = 0.0324769 loss)
I0924 22:55:37.058468  2642 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I0924 22:55:50.470398  2642 solver.cpp:218] Iteration 46800 (7.45607 iter/s, 13.4119s/100 iters), loss = 0.0250393
I0924 22:55:50.470429  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0250388 (* 1 = 0.0250388 loss)
I0924 22:55:50.470438  2642 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I0924 22:56:03.883239  2642 solver.cpp:218] Iteration 46900 (7.45558 iter/s, 13.4128s/100 iters), loss = 0.0352876
I0924 22:56:03.883270  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0352872 (* 1 = 0.0352872 loss)
I0924 22:56:03.883285  2642 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I0924 22:56:16.626823  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:56:17.163933  2642 solver.cpp:330] Iteration 47000, Testing net (#0)
I0924 22:56:20.250325  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:56:20.378880  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9202
I0924 22:56:20.378917  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.275308 (* 1 = 0.275308 loss)
I0924 22:56:20.512938  2642 solver.cpp:218] Iteration 47000 (6.01337 iter/s, 16.6296s/100 iters), loss = 0.0136589
I0924 22:56:20.512966  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136585 (* 1 = 0.0136585 loss)
I0924 22:56:20.512972  2642 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I0924 22:56:33.924515  2642 solver.cpp:218] Iteration 47100 (7.45628 iter/s, 13.4115s/100 iters), loss = 0.0107379
I0924 22:56:33.924554  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107374 (* 1 = 0.0107374 loss)
I0924 22:56:33.924561  2642 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I0924 22:56:47.329555  2642 solver.cpp:218] Iteration 47200 (7.45993 iter/s, 13.405s/100 iters), loss = 0.013254
I0924 22:56:47.329632  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132536 (* 1 = 0.0132536 loss)
I0924 22:56:47.329638  2642 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I0924 22:57:00.742890  2642 solver.cpp:218] Iteration 47300 (7.45533 iter/s, 13.4132s/100 iters), loss = 0.0131693
I0924 22:57:00.742931  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131688 (* 1 = 0.0131688 loss)
I0924 22:57:00.742938  2642 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I0924 22:57:14.150780  2642 solver.cpp:218] Iteration 47400 (7.45834 iter/s, 13.4078s/100 iters), loss = 0.0559513
I0924 22:57:14.150810  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0559509 (* 1 = 0.0559509 loss)
I0924 22:57:14.150816  2642 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I0924 22:57:26.893810  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:57:27.431344  2642 solver.cpp:330] Iteration 47500, Testing net (#0)
I0924 22:57:30.518944  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:57:30.647781  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9212
I0924 22:57:30.647817  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.279297 (* 1 = 0.279297 loss)
I0924 22:57:30.780789  2642 solver.cpp:218] Iteration 47500 (6.01325 iter/s, 16.6299s/100 iters), loss = 0.00507414
I0924 22:57:30.780815  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00507368 (* 1 = 0.00507368 loss)
I0924 22:57:30.780822  2642 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I0924 22:57:44.183873  2642 solver.cpp:218] Iteration 47600 (7.46101 iter/s, 13.403s/100 iters), loss = 0.0368201
I0924 22:57:44.183914  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0368196 (* 1 = 0.0368196 loss)
I0924 22:57:44.183919  2642 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I0924 22:57:57.584190  2642 solver.cpp:218] Iteration 47700 (7.46256 iter/s, 13.4002s/100 iters), loss = 0.0340493
I0924 22:57:57.584264  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0340488 (* 1 = 0.0340488 loss)
I0924 22:57:57.584270  2642 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I0924 22:58:10.980640  2642 solver.cpp:218] Iteration 47800 (7.46473 iter/s, 13.3963s/100 iters), loss = 0.0239817
I0924 22:58:10.980681  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0239812 (* 1 = 0.0239812 loss)
I0924 22:58:10.980687  2642 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I0924 22:58:24.380270  2642 solver.cpp:218] Iteration 47900 (7.46294 iter/s, 13.3995s/100 iters), loss = 0.0309656
I0924 22:58:24.380312  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0309651 (* 1 = 0.0309651 loss)
I0924 22:58:24.380317  2642 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I0924 22:58:37.119742  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:58:37.655697  2642 solver.cpp:330] Iteration 48000, Testing net (#0)
I0924 22:58:40.742336  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:58:40.871347  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9207
I0924 22:58:40.871383  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.279859 (* 1 = 0.279859 loss)
I0924 22:58:41.005105  2642 solver.cpp:218] Iteration 48000 (6.01513 iter/s, 16.6247s/100 iters), loss = 0.00671561
I0924 22:58:41.005132  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00671515 (* 1 = 0.00671515 loss)
I0924 22:58:41.005139  2642 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I0924 22:58:54.411711  2642 solver.cpp:218] Iteration 48100 (7.45905 iter/s, 13.4065s/100 iters), loss = 0.0367482
I0924 22:58:54.411741  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0367478 (* 1 = 0.0367478 loss)
I0924 22:58:54.411747  2642 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I0924 22:59:07.822855  2642 solver.cpp:218] Iteration 48200 (7.45652 iter/s, 13.4111s/100 iters), loss = 0.0253943
I0924 22:59:07.822914  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0253938 (* 1 = 0.0253938 loss)
I0924 22:59:07.822921  2642 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I0924 22:59:21.238085  2642 solver.cpp:218] Iteration 48300 (7.45427 iter/s, 13.4151s/100 iters), loss = 0.0327614
I0924 22:59:21.238126  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0327609 (* 1 = 0.0327609 loss)
I0924 22:59:21.238132  2642 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I0924 22:59:34.649899  2642 solver.cpp:218] Iteration 48400 (7.45616 iter/s, 13.4117s/100 iters), loss = 0.0176736
I0924 22:59:34.649941  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176732 (* 1 = 0.0176732 loss)
I0924 22:59:34.649947  2642 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I0924 22:59:47.398532  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:59:47.935124  2642 solver.cpp:330] Iteration 48500, Testing net (#0)
I0924 22:59:51.022265  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 22:59:51.150153  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9174
I0924 22:59:51.150189  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.288635 (* 1 = 0.288635 loss)
I0924 22:59:51.283172  2642 solver.cpp:218] Iteration 48500 (6.01208 iter/s, 16.6332s/100 iters), loss = 0.0110833
I0924 22:59:51.283200  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110829 (* 1 = 0.0110829 loss)
I0924 22:59:51.283206  2642 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I0924 23:00:04.685969  2642 solver.cpp:218] Iteration 48600 (7.46117 iter/s, 13.4027s/100 iters), loss = 0.0108628
I0924 23:00:04.686010  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108624 (* 1 = 0.0108624 loss)
I0924 23:00:04.686017  2642 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I0924 23:00:18.092962  2642 solver.cpp:218] Iteration 48700 (7.45884 iter/s, 13.4069s/100 iters), loss = 0.0352746
I0924 23:00:18.093101  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0352741 (* 1 = 0.0352741 loss)
I0924 23:00:18.093107  2642 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I0924 23:00:31.496582  2642 solver.cpp:218] Iteration 48800 (7.46076 iter/s, 13.4035s/100 iters), loss = 0.0177787
I0924 23:00:31.496613  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177783 (* 1 = 0.0177783 loss)
I0924 23:00:31.496618  2642 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I0924 23:00:44.899881  2642 solver.cpp:218] Iteration 48900 (7.46089 iter/s, 13.4032s/100 iters), loss = 0.00575275
I0924 23:00:44.899921  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00575232 (* 1 = 0.00575232 loss)
I0924 23:00:44.899929  2642 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I0924 23:00:57.638273  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:00:58.174720  2642 solver.cpp:330] Iteration 49000, Testing net (#0)
I0924 23:01:01.263968  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:01:01.392698  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9216
I0924 23:01:01.392734  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.278157 (* 1 = 0.278157 loss)
I0924 23:01:01.525805  2642 solver.cpp:218] Iteration 49000 (6.01473 iter/s, 16.6258s/100 iters), loss = 0.0103565
I0924 23:01:01.525831  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010356 (* 1 = 0.010356 loss)
I0924 23:01:01.525838  2642 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I0924 23:01:14.931988  2642 solver.cpp:218] Iteration 49100 (7.45928 iter/s, 13.4061s/100 iters), loss = 0.0250436
I0924 23:01:14.932027  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0250432 (* 1 = 0.0250432 loss)
I0924 23:01:14.932034  2642 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I0924 23:01:28.336778  2642 solver.cpp:218] Iteration 49200 (7.46006 iter/s, 13.4047s/100 iters), loss = 0.0176484
I0924 23:01:28.336854  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176479 (* 1 = 0.0176479 loss)
I0924 23:01:28.336861  2642 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I0924 23:01:41.739759  2642 solver.cpp:218] Iteration 49300 (7.46109 iter/s, 13.4029s/100 iters), loss = 0.00672199
I0924 23:01:41.739799  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00672153 (* 1 = 0.00672153 loss)
I0924 23:01:41.739805  2642 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I0924 23:01:55.144840  2642 solver.cpp:218] Iteration 49400 (7.4599 iter/s, 13.405s/100 iters), loss = 0.0126481
I0924 23:01:55.144870  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126477 (* 1 = 0.0126477 loss)
I0924 23:01:55.144876  2642 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I0924 23:02:07.884760  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:02:08.421685  2642 solver.cpp:330] Iteration 49500, Testing net (#0)
I0924 23:02:11.509084  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:02:11.637634  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9207
I0924 23:02:11.637670  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.284905 (* 1 = 0.284905 loss)
I0924 23:02:11.770174  2642 solver.cpp:218] Iteration 49500 (6.01494 iter/s, 16.6253s/100 iters), loss = 0.0113109
I0924 23:02:11.770202  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113104 (* 1 = 0.0113104 loss)
I0924 23:02:11.770208  2642 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I0924 23:02:25.179872  2642 solver.cpp:218] Iteration 49600 (7.45733 iter/s, 13.4096s/100 iters), loss = 0.0253619
I0924 23:02:25.179913  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0253615 (* 1 = 0.0253615 loss)
I0924 23:02:25.179919  2642 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I0924 23:02:38.595345  2642 solver.cpp:218] Iteration 49700 (7.45412 iter/s, 13.4154s/100 iters), loss = 0.00568994
I0924 23:02:38.595432  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00568948 (* 1 = 0.00568948 loss)
I0924 23:02:38.595448  2642 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I0924 23:02:52.010783  2642 solver.cpp:218] Iteration 49800 (7.45417 iter/s, 13.4153s/100 iters), loss = 0.00604978
I0924 23:02:52.010824  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00604933 (* 1 = 0.00604933 loss)
I0924 23:02:52.010830  2642 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I0924 23:03:05.427109  2642 solver.cpp:218] Iteration 49900 (7.45365 iter/s, 13.4162s/100 iters), loss = 0.00665091
I0924 23:03:05.427150  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00665045 (* 1 = 0.00665045 loss)
I0924 23:03:05.427155  2642 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I0924 23:03:18.174070  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:03:18.710422  2642 solver.cpp:330] Iteration 50000, Testing net (#0)
I0924 23:03:21.798804  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:03:21.927708  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9202
I0924 23:03:21.927744  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.286128 (* 1 = 0.286128 loss)
I0924 23:03:22.061136  2642 solver.cpp:218] Iteration 50000 (6.0118 iter/s, 16.6339s/100 iters), loss = 0.00692555
I0924 23:03:22.061164  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00692508 (* 1 = 0.00692508 loss)
I0924 23:03:22.061170  2642 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I0924 23:03:35.464464  2642 solver.cpp:218] Iteration 50100 (7.46087 iter/s, 13.4033s/100 iters), loss = 0.0080835
I0924 23:03:35.464506  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00808303 (* 1 = 0.00808303 loss)
I0924 23:03:35.464512  2642 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I0924 23:03:48.873790  2642 solver.cpp:218] Iteration 50200 (7.45754 iter/s, 13.4092s/100 iters), loss = 0.0229679
I0924 23:03:48.873878  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0229674 (* 1 = 0.0229674 loss)
I0924 23:03:48.873895  2642 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I0924 23:04:02.277633  2642 solver.cpp:218] Iteration 50300 (7.46062 iter/s, 13.4037s/100 iters), loss = 0.00774627
I0924 23:04:02.277664  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00774582 (* 1 = 0.00774582 loss)
I0924 23:04:02.277670  2642 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I0924 23:04:15.680269  2642 solver.cpp:218] Iteration 50400 (7.46126 iter/s, 13.4026s/100 iters), loss = 0.0275641
I0924 23:04:15.680299  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0275636 (* 1 = 0.0275636 loss)
I0924 23:04:15.680305  2642 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I0924 23:04:28.420964  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:04:28.957504  2642 solver.cpp:330] Iteration 50500, Testing net (#0)
I0924 23:04:32.043933  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:04:32.172610  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9221
I0924 23:04:32.172644  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.280331 (* 1 = 0.280331 loss)
I0924 23:04:32.305748  2642 solver.cpp:218] Iteration 50500 (6.01489 iter/s, 16.6254s/100 iters), loss = 0.00409963
I0924 23:04:32.305775  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00409917 (* 1 = 0.00409917 loss)
I0924 23:04:32.305781  2642 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I0924 23:04:45.709111  2642 solver.cpp:218] Iteration 50600 (7.46085 iter/s, 13.4033s/100 iters), loss = 0.0232604
I0924 23:04:45.709152  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0232599 (* 1 = 0.0232599 loss)
I0924 23:04:45.709158  2642 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I0924 23:04:59.112566  2642 solver.cpp:218] Iteration 50700 (7.46081 iter/s, 13.4034s/100 iters), loss = 0.0137427
I0924 23:04:59.112690  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0137422 (* 1 = 0.0137422 loss)
I0924 23:04:59.112696  2642 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I0924 23:05:12.522629  2642 solver.cpp:218] Iteration 50800 (7.45718 iter/s, 13.4099s/100 iters), loss = 0.0242796
I0924 23:05:12.522670  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0242792 (* 1 = 0.0242792 loss)
I0924 23:05:12.522675  2642 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I0924 23:05:25.925981  2642 solver.cpp:218] Iteration 50900 (7.46086 iter/s, 13.4033s/100 iters), loss = 0.00991474
I0924 23:05:25.926013  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00991429 (* 1 = 0.00991429 loss)
I0924 23:05:25.926019  2642 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I0924 23:05:38.664413  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:05:39.200064  2642 solver.cpp:330] Iteration 51000, Testing net (#0)
I0924 23:05:42.287533  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:05:42.416146  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9222
I0924 23:05:42.416182  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.288815 (* 1 = 0.288815 loss)
I0924 23:05:42.549149  2642 solver.cpp:218] Iteration 51000 (6.01573 iter/s, 16.6231s/100 iters), loss = 0.00632213
I0924 23:05:42.549176  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00632169 (* 1 = 0.00632169 loss)
I0924 23:05:42.549182  2642 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I0924 23:05:55.952075  2642 solver.cpp:218] Iteration 51100 (7.4611 iter/s, 13.4029s/100 iters), loss = 0.0155458
I0924 23:05:55.952116  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155453 (* 1 = 0.0155453 loss)
I0924 23:05:55.952129  2642 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I0924 23:06:09.358846  2642 solver.cpp:218] Iteration 51200 (7.45896 iter/s, 13.4067s/100 iters), loss = 0.0257937
I0924 23:06:09.358954  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0257933 (* 1 = 0.0257933 loss)
I0924 23:06:09.358969  2642 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I0924 23:06:22.763150  2642 solver.cpp:218] Iteration 51300 (7.46036 iter/s, 13.4042s/100 iters), loss = 0.00737432
I0924 23:06:22.763180  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00737387 (* 1 = 0.00737387 loss)
I0924 23:06:22.763186  2642 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I0924 23:06:36.165748  2642 solver.cpp:218] Iteration 51400 (7.46128 iter/s, 13.4025s/100 iters), loss = 0.025371
I0924 23:06:36.165791  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0253706 (* 1 = 0.0253706 loss)
I0924 23:06:36.165796  2642 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I0924 23:06:48.900240  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:06:49.436440  2642 solver.cpp:330] Iteration 51500, Testing net (#0)
I0924 23:06:52.524926  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:06:52.653312  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9224
I0924 23:06:52.653338  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.285765 (* 1 = 0.285765 loss)
I0924 23:06:52.786865  2642 solver.cpp:218] Iteration 51500 (6.01647 iter/s, 16.621s/100 iters), loss = 0.00277473
I0924 23:06:52.786893  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00277429 (* 1 = 0.00277429 loss)
I0924 23:06:52.786900  2642 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I0924 23:07:06.185596  2642 solver.cpp:218] Iteration 51600 (7.46343 iter/s, 13.3987s/100 iters), loss = 0.00488475
I0924 23:07:06.185637  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00488431 (* 1 = 0.00488431 loss)
I0924 23:07:06.185643  2642 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I0924 23:07:19.590296  2642 solver.cpp:218] Iteration 51700 (7.46011 iter/s, 13.4046s/100 iters), loss = 0.0076031
I0924 23:07:19.590436  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00760266 (* 1 = 0.00760266 loss)
I0924 23:07:19.590445  2642 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I0924 23:07:32.993749  2642 solver.cpp:218] Iteration 51800 (7.46086 iter/s, 13.4033s/100 iters), loss = 0.0115438
I0924 23:07:32.993790  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115434 (* 1 = 0.0115434 loss)
I0924 23:07:32.993796  2642 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I0924 23:07:46.393215  2642 solver.cpp:218] Iteration 51900 (7.46303 iter/s, 13.3994s/100 iters), loss = 0.0270066
I0924 23:07:46.393256  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0270061 (* 1 = 0.0270061 loss)
I0924 23:07:46.393262  2642 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I0924 23:07:59.128440  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:07:59.665247  2642 solver.cpp:330] Iteration 52000, Testing net (#0)
I0924 23:08:02.752653  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:08:02.881884  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9222
I0924 23:08:02.881920  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.28732 (* 1 = 0.28732 loss)
I0924 23:08:03.015419  2642 solver.cpp:218] Iteration 52000 (6.01608 iter/s, 16.6221s/100 iters), loss = 0.00225323
I0924 23:08:03.015449  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00225278 (* 1 = 0.00225278 loss)
I0924 23:08:03.015455  2642 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I0924 23:08:16.424093  2642 solver.cpp:218] Iteration 52100 (7.4579 iter/s, 13.4086s/100 iters), loss = 0.0196242
I0924 23:08:16.424123  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0196237 (* 1 = 0.0196237 loss)
I0924 23:08:16.424129  2642 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I0924 23:08:29.834976  2642 solver.cpp:218] Iteration 52200 (7.45667 iter/s, 13.4108s/100 iters), loss = 0.0237624
I0924 23:08:29.835116  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0237619 (* 1 = 0.0237619 loss)
I0924 23:08:29.835124  2642 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I0924 23:08:43.234933  2642 solver.cpp:218] Iteration 52300 (7.46281 iter/s, 13.3998s/100 iters), loss = 0.00357907
I0924 23:08:43.234974  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00357863 (* 1 = 0.00357863 loss)
I0924 23:08:43.234980  2642 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I0924 23:08:56.642714  2642 solver.cpp:218] Iteration 52400 (7.4584 iter/s, 13.4077s/100 iters), loss = 0.00777979
I0924 23:08:56.642745  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00777935 (* 1 = 0.00777935 loss)
I0924 23:08:56.642750  2642 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I0924 23:09:09.383092  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:09:09.920194  2642 solver.cpp:330] Iteration 52500, Testing net (#0)
I0924 23:09:13.006384  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:09:13.135279  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9214
I0924 23:09:13.135315  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.292473 (* 1 = 0.292473 loss)
I0924 23:09:13.269230  2642 solver.cpp:218] Iteration 52500 (6.01452 iter/s, 16.6264s/100 iters), loss = 0.0260638
I0924 23:09:13.269258  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0260634 (* 1 = 0.0260634 loss)
I0924 23:09:13.269264  2642 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I0924 23:09:26.669437  2642 solver.cpp:218] Iteration 52600 (7.46261 iter/s, 13.4001s/100 iters), loss = 0.00604737
I0924 23:09:26.669478  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00604694 (* 1 = 0.00604694 loss)
I0924 23:09:26.669484  2642 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I0924 23:09:40.073992  2642 solver.cpp:218] Iteration 52700 (7.46019 iter/s, 13.4045s/100 iters), loss = 0.0111425
I0924 23:09:40.074064  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011142 (* 1 = 0.011142 loss)
I0924 23:09:40.074070  2642 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I0924 23:09:53.475575  2642 solver.cpp:218] Iteration 52800 (7.46186 iter/s, 13.4015s/100 iters), loss = 0.0104675
I0924 23:09:53.475616  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104671 (* 1 = 0.0104671 loss)
I0924 23:09:53.475622  2642 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I0924 23:10:06.878458  2642 solver.cpp:218] Iteration 52900 (7.46112 iter/s, 13.4028s/100 iters), loss = 0.00497601
I0924 23:10:06.878489  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00497558 (* 1 = 0.00497558 loss)
I0924 23:10:06.878494  2642 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I0924 23:10:19.614758  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:10:20.151257  2642 solver.cpp:330] Iteration 53000, Testing net (#0)
I0924 23:10:23.238435  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:10:23.367014  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9246
I0924 23:10:23.367051  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.281065 (* 1 = 0.281065 loss)
I0924 23:10:23.500665  2642 solver.cpp:218] Iteration 53000 (6.01607 iter/s, 16.6221s/100 iters), loss = 0.00470283
I0924 23:10:23.500694  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00470239 (* 1 = 0.00470239 loss)
I0924 23:10:23.500700  2642 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I0924 23:10:36.910580  2642 solver.cpp:218] Iteration 53100 (7.4572 iter/s, 13.4099s/100 iters), loss = 0.00929958
I0924 23:10:36.910620  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00929915 (* 1 = 0.00929915 loss)
I0924 23:10:36.910625  2642 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I0924 23:10:50.319131  2642 solver.cpp:218] Iteration 53200 (7.45797 iter/s, 13.4085s/100 iters), loss = 0.00500477
I0924 23:10:50.319227  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00500433 (* 1 = 0.00500433 loss)
I0924 23:10:50.319243  2642 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I0924 23:11:03.726709  2642 solver.cpp:218] Iteration 53300 (7.45854 iter/s, 13.4074s/100 iters), loss = 0.0257891
I0924 23:11:03.726750  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0257886 (* 1 = 0.0257886 loss)
I0924 23:11:03.726757  2642 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I0924 23:11:17.135929  2642 solver.cpp:218] Iteration 53400 (7.4576 iter/s, 13.4091s/100 iters), loss = 0.00302948
I0924 23:11:17.135960  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00302904 (* 1 = 0.00302904 loss)
I0924 23:11:17.135965  2642 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I0924 23:11:29.876164  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:11:30.411780  2642 solver.cpp:330] Iteration 53500, Testing net (#0)
I0924 23:11:33.500455  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:11:33.629110  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9237
I0924 23:11:33.629148  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.287751 (* 1 = 0.287751 loss)
I0924 23:11:33.762372  2642 solver.cpp:218] Iteration 53500 (6.01454 iter/s, 16.6264s/100 iters), loss = 0.0137399
I0924 23:11:33.762398  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0137394 (* 1 = 0.0137394 loss)
I0924 23:11:33.762405  2642 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I0924 23:11:47.171393  2642 solver.cpp:218] Iteration 53600 (7.4577 iter/s, 13.409s/100 iters), loss = 0.0127689
I0924 23:11:47.171424  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127685 (* 1 = 0.0127685 loss)
I0924 23:11:47.171430  2642 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I0924 23:12:00.580319  2642 solver.cpp:218] Iteration 53700 (7.45775 iter/s, 13.4089s/100 iters), loss = 0.0154865
I0924 23:12:00.580458  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0154861 (* 1 = 0.0154861 loss)
I0924 23:12:00.580467  2642 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I0924 23:12:13.994001  2642 solver.cpp:218] Iteration 53800 (7.45517 iter/s, 13.4135s/100 iters), loss = 0.00482707
I0924 23:12:13.994041  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00482662 (* 1 = 0.00482662 loss)
I0924 23:12:13.994047  2642 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I0924 23:12:27.405652  2642 solver.cpp:218] Iteration 53900 (7.45625 iter/s, 13.4116s/100 iters), loss = 0.00715685
I0924 23:12:27.405694  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00715641 (* 1 = 0.00715641 loss)
I0924 23:12:27.405699  2642 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I0924 23:12:40.146560  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:12:40.683374  2642 solver.cpp:330] Iteration 54000, Testing net (#0)
I0924 23:12:43.771308  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:12:43.899343  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9222
I0924 23:12:43.899379  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.292374 (* 1 = 0.292374 loss)
I0924 23:12:44.032367  2642 solver.cpp:218] Iteration 54000 (6.01445 iter/s, 16.6266s/100 iters), loss = 0.00272559
I0924 23:12:44.032394  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00272514 (* 1 = 0.00272514 loss)
I0924 23:12:44.032400  2642 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I0924 23:12:57.437741  2642 solver.cpp:218] Iteration 54100 (7.45973 iter/s, 13.4053s/100 iters), loss = 0.0288625
I0924 23:12:57.437780  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0288621 (* 1 = 0.0288621 loss)
I0924 23:12:57.437786  2642 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I0924 23:13:10.846640  2642 solver.cpp:218] Iteration 54200 (7.45778 iter/s, 13.4088s/100 iters), loss = 0.00592848
I0924 23:13:10.846797  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00592803 (* 1 = 0.00592803 loss)
I0924 23:13:10.846819  2642 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I0924 23:13:24.251837  2642 solver.cpp:218] Iteration 54300 (7.4599 iter/s, 13.405s/100 iters), loss = 0.00272142
I0924 23:13:24.251878  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00272098 (* 1 = 0.00272098 loss)
I0924 23:13:24.251883  2642 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I0924 23:13:37.654011  2642 solver.cpp:218] Iteration 54400 (7.46152 iter/s, 13.4021s/100 iters), loss = 0.00973794
I0924 23:13:37.654052  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00973749 (* 1 = 0.00973749 loss)
I0924 23:13:37.654057  2642 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I0924 23:13:50.394090  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:13:50.930719  2642 solver.cpp:330] Iteration 54500, Testing net (#0)
I0924 23:13:54.017323  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:13:54.146344  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9206
I0924 23:13:54.146380  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.294937 (* 1 = 0.294937 loss)
I0924 23:13:54.279836  2642 solver.cpp:218] Iteration 54500 (6.01477 iter/s, 16.6257s/100 iters), loss = 0.0175053
I0924 23:13:54.279863  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0175049 (* 1 = 0.0175049 loss)
I0924 23:13:54.279870  2642 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I0924 23:14:07.681715  2642 solver.cpp:218] Iteration 54600 (7.46168 iter/s, 13.4018s/100 iters), loss = 0.00332317
I0924 23:14:07.681756  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00332273 (* 1 = 0.00332273 loss)
I0924 23:14:07.681761  2642 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I0924 23:14:21.084364  2642 solver.cpp:218] Iteration 54700 (7.46125 iter/s, 13.4026s/100 iters), loss = 0.0105335
I0924 23:14:21.084492  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105331 (* 1 = 0.0105331 loss)
I0924 23:14:21.084501  2642 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I0924 23:14:34.487419  2642 solver.cpp:218] Iteration 54800 (7.46107 iter/s, 13.4029s/100 iters), loss = 0.0257633
I0924 23:14:34.487460  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0257629 (* 1 = 0.0257629 loss)
I0924 23:14:34.487468  2642 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I0924 23:14:47.894284  2642 solver.cpp:218] Iteration 54900 (7.45891 iter/s, 13.4068s/100 iters), loss = 0.0142093
I0924 23:14:47.894325  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142089 (* 1 = 0.0142089 loss)
I0924 23:14:47.894331  2642 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I0924 23:15:00.632349  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:15:01.169450  2642 solver.cpp:330] Iteration 55000, Testing net (#0)
I0924 23:15:04.256660  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:15:04.385305  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.925
I0924 23:15:04.385341  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.289616 (* 1 = 0.289616 loss)
I0924 23:15:04.518579  2642 solver.cpp:218] Iteration 55000 (6.01532 iter/s, 16.6242s/100 iters), loss = 0.00577475
I0924 23:15:04.518606  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00577432 (* 1 = 0.00577432 loss)
I0924 23:15:04.518613  2642 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I0924 23:15:17.926008  2642 solver.cpp:218] Iteration 55100 (7.45859 iter/s, 13.4074s/100 iters), loss = 0.00594674
I0924 23:15:17.926049  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00594631 (* 1 = 0.00594631 loss)
I0924 23:15:17.926055  2642 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I0924 23:15:31.327538  2642 solver.cpp:218] Iteration 55200 (7.46188 iter/s, 13.4015s/100 iters), loss = 0.021194
I0924 23:15:31.327639  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0211935 (* 1 = 0.0211935 loss)
I0924 23:15:31.327646  2642 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I0924 23:15:44.736820  2642 solver.cpp:218] Iteration 55300 (7.4576 iter/s, 13.4091s/100 iters), loss = 0.0144495
I0924 23:15:44.736862  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0144491 (* 1 = 0.0144491 loss)
I0924 23:15:44.736868  2642 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I0924 23:15:58.144565  2642 solver.cpp:218] Iteration 55400 (7.45842 iter/s, 13.4077s/100 iters), loss = 0.00654938
I0924 23:15:58.144608  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00654895 (* 1 = 0.00654895 loss)
I0924 23:15:58.144613  2642 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I0924 23:16:10.887815  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:16:11.425074  2642 solver.cpp:330] Iteration 55500, Testing net (#0)
I0924 23:16:14.513152  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:16:14.641820  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9265
I0924 23:16:14.641857  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295018 (* 1 = 0.295018 loss)
I0924 23:16:14.774555  2642 solver.cpp:218] Iteration 55500 (6.01326 iter/s, 16.6299s/100 iters), loss = 0.00449108
I0924 23:16:14.774582  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00449065 (* 1 = 0.00449065 loss)
I0924 23:16:14.774590  2642 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I0924 23:16:28.184303  2642 solver.cpp:218] Iteration 55600 (7.4573 iter/s, 13.4097s/100 iters), loss = 0.00403093
I0924 23:16:28.184345  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00403051 (* 1 = 0.00403051 loss)
I0924 23:16:28.184351  2642 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I0924 23:16:41.592880  2642 solver.cpp:218] Iteration 55700 (7.45795 iter/s, 13.4085s/100 iters), loss = 0.0142218
I0924 23:16:41.593015  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142214 (* 1 = 0.0142214 loss)
I0924 23:16:41.593024  2642 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I0924 23:16:55.005744  2642 solver.cpp:218] Iteration 55800 (7.45562 iter/s, 13.4127s/100 iters), loss = 0.00425334
I0924 23:16:55.005775  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00425292 (* 1 = 0.00425292 loss)
I0924 23:16:55.005780  2642 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I0924 23:17:08.415359  2642 solver.cpp:218] Iteration 55900 (7.45737 iter/s, 13.4095s/100 iters), loss = 0.00165265
I0924 23:17:08.415400  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00165223 (* 1 = 0.00165223 loss)
I0924 23:17:08.415405  2642 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I0924 23:17:21.162283  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:17:21.699442  2642 solver.cpp:330] Iteration 56000, Testing net (#0)
I0924 23:17:24.787307  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:17:24.916175  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9225
I0924 23:17:24.916199  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295186 (* 1 = 0.295186 loss)
I0924 23:17:25.049782  2642 solver.cpp:218] Iteration 56000 (6.01166 iter/s, 16.6343s/100 iters), loss = 0.00262022
I0924 23:17:25.049809  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0026198 (* 1 = 0.0026198 loss)
I0924 23:17:25.049816  2642 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I0924 23:17:38.460564  2642 solver.cpp:218] Iteration 56100 (7.45672 iter/s, 13.4107s/100 iters), loss = 0.0102034
I0924 23:17:38.460604  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010203 (* 1 = 0.010203 loss)
I0924 23:17:38.460610  2642 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I0924 23:17:51.871618  2642 solver.cpp:218] Iteration 56200 (7.45658 iter/s, 13.411s/100 iters), loss = 0.0101788
I0924 23:17:51.871755  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101784 (* 1 = 0.0101784 loss)
I0924 23:17:51.871762  2642 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I0924 23:18:05.283339  2642 solver.cpp:218] Iteration 56300 (7.45625 iter/s, 13.4116s/100 iters), loss = 0.00684585
I0924 23:18:05.283380  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00684545 (* 1 = 0.00684545 loss)
I0924 23:18:05.283385  2642 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I0924 23:18:18.694869  2642 solver.cpp:218] Iteration 56400 (7.45631 iter/s, 13.4115s/100 iters), loss = 0.00276138
I0924 23:18:18.694911  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00276098 (* 1 = 0.00276098 loss)
I0924 23:18:18.694916  2642 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I0924 23:18:31.439256  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:18:31.976483  2642 solver.cpp:330] Iteration 56500, Testing net (#0)
I0924 23:18:35.063192  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:18:35.192366  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.92
I0924 23:18:35.192404  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308189 (* 1 = 0.308189 loss)
I0924 23:18:35.325736  2642 solver.cpp:218] Iteration 56500 (6.01295 iter/s, 16.6308s/100 iters), loss = 0.00171541
I0924 23:18:35.325763  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00171501 (* 1 = 0.00171501 loss)
I0924 23:18:35.325769  2642 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I0924 23:18:48.725875  2642 solver.cpp:218] Iteration 56600 (7.46265 iter/s, 13.4001s/100 iters), loss = 0.0309882
I0924 23:18:48.725916  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0309878 (* 1 = 0.0309878 loss)
I0924 23:18:48.725922  2642 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I0924 23:19:02.134511  2642 solver.cpp:218] Iteration 56700 (7.45792 iter/s, 13.4086s/100 iters), loss = 0.00221987
I0924 23:19:02.134567  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00221946 (* 1 = 0.00221946 loss)
I0924 23:19:02.134573  2642 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I0924 23:19:15.538079  2642 solver.cpp:218] Iteration 56800 (7.46075 iter/s, 13.4035s/100 iters), loss = 0.0152909
I0924 23:19:15.538120  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152905 (* 1 = 0.0152905 loss)
I0924 23:19:15.538126  2642 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I0924 23:19:28.941215  2642 solver.cpp:218] Iteration 56900 (7.46098 iter/s, 13.4031s/100 iters), loss = 0.00829372
I0924 23:19:28.941246  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00829333 (* 1 = 0.00829333 loss)
I0924 23:19:28.941251  2642 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I0924 23:19:41.676517  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:19:42.211714  2642 solver.cpp:330] Iteration 57000, Testing net (#0)
I0924 23:19:45.298454  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:19:45.427101  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9208
I0924 23:19:45.427137  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305683 (* 1 = 0.305683 loss)
I0924 23:19:45.559649  2642 solver.cpp:218] Iteration 57000 (6.01744 iter/s, 16.6184s/100 iters), loss = 0.00496534
I0924 23:19:45.559675  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00496495 (* 1 = 0.00496495 loss)
I0924 23:19:45.559682  2642 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I0924 23:19:58.964365  2642 solver.cpp:218] Iteration 57100 (7.4601 iter/s, 13.4047s/100 iters), loss = 0.00604766
I0924 23:19:58.964406  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00604727 (* 1 = 0.00604727 loss)
I0924 23:19:58.964411  2642 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I0924 23:20:12.372431  2642 solver.cpp:218] Iteration 57200 (7.45824 iter/s, 13.408s/100 iters), loss = 0.00244437
I0924 23:20:12.372503  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00244398 (* 1 = 0.00244398 loss)
I0924 23:20:12.372509  2642 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I0924 23:20:25.777858  2642 solver.cpp:218] Iteration 57300 (7.45972 iter/s, 13.4053s/100 iters), loss = 0.00330906
I0924 23:20:25.777896  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00330867 (* 1 = 0.00330867 loss)
I0924 23:20:25.777902  2642 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I0924 23:20:39.187475  2642 solver.cpp:218] Iteration 57400 (7.45737 iter/s, 13.4095s/100 iters), loss = 0.00521726
I0924 23:20:39.187515  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00521686 (* 1 = 0.00521686 loss)
I0924 23:20:39.187521  2642 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I0924 23:20:51.922152  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:20:52.457567  2642 solver.cpp:330] Iteration 57500, Testing net (#0)
I0924 23:20:55.543674  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:20:55.672952  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9213
I0924 23:20:55.672989  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310591 (* 1 = 0.310591 loss)
I0924 23:20:55.806028  2642 solver.cpp:218] Iteration 57500 (6.0174 iter/s, 16.6185s/100 iters), loss = 0.00250717
I0924 23:20:55.806064  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00250677 (* 1 = 0.00250677 loss)
I0924 23:20:55.806071  2642 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I0924 23:21:09.212306  2642 solver.cpp:218] Iteration 57600 (7.45923 iter/s, 13.4062s/100 iters), loss = 0.00508009
I0924 23:21:09.212345  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00507969 (* 1 = 0.00507969 loss)
I0924 23:21:09.212352  2642 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I0924 23:21:22.618865  2642 solver.cpp:218] Iteration 57700 (7.45908 iter/s, 13.4065s/100 iters), loss = 0.00675115
I0924 23:21:22.618988  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00675075 (* 1 = 0.00675075 loss)
I0924 23:21:22.618995  2642 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I0924 23:21:36.029295  2642 solver.cpp:218] Iteration 57800 (7.45697 iter/s, 13.4103s/100 iters), loss = 0.00375263
I0924 23:21:36.029336  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00375224 (* 1 = 0.00375224 loss)
I0924 23:21:36.029342  2642 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I0924 23:21:49.431141  2642 solver.cpp:218] Iteration 57900 (7.4617 iter/s, 13.4018s/100 iters), loss = 0.0043784
I0924 23:21:49.431181  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00437801 (* 1 = 0.00437801 loss)
I0924 23:21:49.431187  2642 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I0924 23:22:02.175473  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:22:02.711771  2642 solver.cpp:330] Iteration 58000, Testing net (#0)
I0924 23:22:05.797724  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:22:05.926496  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9246
I0924 23:22:05.926532  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.294475 (* 1 = 0.294475 loss)
I0924 23:22:06.060320  2642 solver.cpp:218] Iteration 58000 (6.01356 iter/s, 16.6291s/100 iters), loss = 0.00195108
I0924 23:22:06.060348  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00195068 (* 1 = 0.00195068 loss)
I0924 23:22:06.060355  2642 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I0924 23:22:19.463367  2642 solver.cpp:218] Iteration 58100 (7.46103 iter/s, 13.403s/100 iters), loss = 0.00636983
I0924 23:22:19.463408  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00636943 (* 1 = 0.00636943 loss)
I0924 23:22:19.463414  2642 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I0924 23:22:32.870038  2642 solver.cpp:218] Iteration 58200 (7.45901 iter/s, 13.4066s/100 iters), loss = 0.0060478
I0924 23:22:32.870198  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0060474 (* 1 = 0.0060474 loss)
I0924 23:22:32.870206  2642 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I0924 23:22:46.279415  2642 solver.cpp:218] Iteration 58300 (7.45757 iter/s, 13.4092s/100 iters), loss = 0.00515568
I0924 23:22:46.279458  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00515529 (* 1 = 0.00515529 loss)
I0924 23:22:46.279464  2642 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I0924 23:22:59.683765  2642 solver.cpp:218] Iteration 58400 (7.46031 iter/s, 13.4043s/100 iters), loss = 0.00602511
I0924 23:22:59.683806  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00602472 (* 1 = 0.00602472 loss)
I0924 23:22:59.683812  2642 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I0924 23:23:12.425309  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:23:12.963012  2642 solver.cpp:330] Iteration 58500, Testing net (#0)
I0924 23:23:16.048820  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:23:16.177376  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9228
I0924 23:23:16.177412  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300781 (* 1 = 0.300781 loss)
I0924 23:23:16.311388  2642 solver.cpp:218] Iteration 58500 (6.01412 iter/s, 16.6275s/100 iters), loss = 0.00683811
I0924 23:23:16.311414  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00683773 (* 1 = 0.00683773 loss)
I0924 23:23:16.311420  2642 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I0924 23:23:29.715590  2642 solver.cpp:218] Iteration 58600 (7.46038 iter/s, 13.4041s/100 iters), loss = 0.00566071
I0924 23:23:29.715631  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00566032 (* 1 = 0.00566032 loss)
I0924 23:23:29.715636  2642 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I0924 23:23:43.117823  2642 solver.cpp:218] Iteration 58700 (7.46148 iter/s, 13.4022s/100 iters), loss = 0.0147994
I0924 23:23:43.117949  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014799 (* 1 = 0.014799 loss)
I0924 23:23:43.117955  2642 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I0924 23:23:56.518707  2642 solver.cpp:218] Iteration 58800 (7.46228 iter/s, 13.4007s/100 iters), loss = 0.00424061
I0924 23:23:56.518748  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00424023 (* 1 = 0.00424023 loss)
I0924 23:23:56.518754  2642 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I0924 23:24:09.925787  2642 solver.cpp:218] Iteration 58900 (7.45879 iter/s, 13.407s/100 iters), loss = 0.0103492
I0924 23:24:09.925827  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103488 (* 1 = 0.0103488 loss)
I0924 23:24:09.925833  2642 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I0924 23:24:22.663329  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:24:23.199522  2642 solver.cpp:330] Iteration 59000, Testing net (#0)
I0924 23:24:26.286561  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:24:26.415522  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9218
I0924 23:24:26.415558  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.297222 (* 1 = 0.297222 loss)
I0924 23:24:26.548949  2642 solver.cpp:218] Iteration 59000 (6.01574 iter/s, 16.6231s/100 iters), loss = 0.00372667
I0924 23:24:26.548985  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00372629 (* 1 = 0.00372629 loss)
I0924 23:24:26.548991  2642 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I0924 23:24:39.951805  2642 solver.cpp:218] Iteration 59100 (7.46114 iter/s, 13.4028s/100 iters), loss = 0.011289
I0924 23:24:39.951846  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112887 (* 1 = 0.0112887 loss)
I0924 23:24:39.951853  2642 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I0924 23:24:53.366397  2642 solver.cpp:218] Iteration 59200 (7.45461 iter/s, 13.4145s/100 iters), loss = 0.00271769
I0924 23:24:53.366513  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00271732 (* 1 = 0.00271732 loss)
I0924 23:24:53.366520  2642 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I0924 23:25:06.773836  2642 solver.cpp:218] Iteration 59300 (7.45863 iter/s, 13.4073s/100 iters), loss = 0.00762476
I0924 23:25:06.773877  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00762438 (* 1 = 0.00762438 loss)
I0924 23:25:06.773883  2642 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I0924 23:25:20.183161  2642 solver.cpp:218] Iteration 59400 (7.45754 iter/s, 13.4092s/100 iters), loss = 0.00152595
I0924 23:25:20.183202  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00152557 (* 1 = 0.00152557 loss)
I0924 23:25:20.183208  2642 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I0924 23:25:32.920379  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:25:33.456326  2642 solver.cpp:330] Iteration 59500, Testing net (#0)
I0924 23:25:36.543205  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:25:36.671831  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9235
I0924 23:25:36.671867  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.298571 (* 1 = 0.298571 loss)
I0924 23:25:36.805801  2642 solver.cpp:218] Iteration 59500 (6.01592 iter/s, 16.6226s/100 iters), loss = 0.00985878
I0924 23:25:36.805827  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0098584 (* 1 = 0.0098584 loss)
I0924 23:25:36.805835  2642 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I0924 23:25:50.210666  2642 solver.cpp:218] Iteration 59600 (7.46001 iter/s, 13.4048s/100 iters), loss = 0.00643356
I0924 23:25:50.210706  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00643318 (* 1 = 0.00643318 loss)
I0924 23:25:50.210712  2642 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I0924 23:26:03.619570  2642 solver.cpp:218] Iteration 59700 (7.45777 iter/s, 13.4088s/100 iters), loss = 0.0247644
I0924 23:26:03.619702  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.024764 (* 1 = 0.024764 loss)
I0924 23:26:03.619711  2642 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I0924 23:26:17.025681  2642 solver.cpp:218] Iteration 59800 (7.45937 iter/s, 13.406s/100 iters), loss = 0.00549923
I0924 23:26:17.025722  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00549884 (* 1 = 0.00549884 loss)
I0924 23:26:17.025728  2642 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I0924 23:26:30.432924  2642 solver.cpp:218] Iteration 59900 (7.4587 iter/s, 13.4072s/100 iters), loss = 0.00348868
I0924 23:26:30.432965  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0034883 (* 1 = 0.0034883 loss)
I0924 23:26:30.432971  2642 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I0924 23:26:43.178491  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:26:43.714578  2642 solver.cpp:330] Iteration 60000, Testing net (#0)
I0924 23:26:46.803166  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:26:46.931766  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9211
I0924 23:26:46.931803  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325364 (* 1 = 0.325364 loss)
I0924 23:26:47.065132  2642 solver.cpp:218] Iteration 60000 (6.01246 iter/s, 16.6321s/100 iters), loss = 0.0022301
I0924 23:26:47.065160  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00222972 (* 1 = 0.00222972 loss)
I0924 23:26:47.065166  2642 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I0924 23:27:00.471370  2642 solver.cpp:218] Iteration 60100 (7.45925 iter/s, 13.4062s/100 iters), loss = 0.00486916
I0924 23:27:00.471400  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00486878 (* 1 = 0.00486878 loss)
I0924 23:27:00.471406  2642 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I0924 23:27:13.884054  2642 solver.cpp:218] Iteration 60200 (7.45566 iter/s, 13.4126s/100 iters), loss = 0.0208351
I0924 23:27:13.884155  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0208347 (* 1 = 0.0208347 loss)
I0924 23:27:13.884172  2642 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I0924 23:27:27.298923  2642 solver.cpp:218] Iteration 60300 (7.45449 iter/s, 13.4147s/100 iters), loss = 0.0051894
I0924 23:27:27.298964  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00518901 (* 1 = 0.00518901 loss)
I0924 23:27:27.298969  2642 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I0924 23:27:40.709944  2642 solver.cpp:218] Iteration 60400 (7.45659 iter/s, 13.4109s/100 iters), loss = 0.00192677
I0924 23:27:40.709985  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00192639 (* 1 = 0.00192639 loss)
I0924 23:27:40.709990  2642 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I0924 23:27:53.452584  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:27:53.989151  2642 solver.cpp:330] Iteration 60500, Testing net (#0)
I0924 23:27:57.076053  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:27:57.204030  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9211
I0924 23:27:57.204066  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314731 (* 1 = 0.314731 loss)
I0924 23:27:57.337179  2642 solver.cpp:218] Iteration 60500 (6.01426 iter/s, 16.6272s/100 iters), loss = 0.00200954
I0924 23:27:57.337206  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00200916 (* 1 = 0.00200916 loss)
I0924 23:27:57.337213  2642 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I0924 23:28:10.753237  2642 solver.cpp:218] Iteration 60600 (7.45379 iter/s, 13.416s/100 iters), loss = 0.00589512
I0924 23:28:10.753267  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00589473 (* 1 = 0.00589473 loss)
I0924 23:28:10.753273  2642 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I0924 23:28:24.162135  2642 solver.cpp:218] Iteration 60700 (7.45777 iter/s, 13.4088s/100 iters), loss = 0.00169282
I0924 23:28:24.162266  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00169242 (* 1 = 0.00169242 loss)
I0924 23:28:24.162272  2642 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I0924 23:28:37.573062  2642 solver.cpp:218] Iteration 60800 (7.45669 iter/s, 13.4108s/100 iters), loss = 0.0256094
I0924 23:28:37.573103  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.025609 (* 1 = 0.025609 loss)
I0924 23:28:37.573109  2642 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I0924 23:28:50.983904  2642 solver.cpp:218] Iteration 60900 (7.45669 iter/s, 13.4108s/100 iters), loss = 0.00518619
I0924 23:28:50.983944  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0051858 (* 1 = 0.0051858 loss)
I0924 23:28:50.983950  2642 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I0924 23:29:03.728588  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:29:04.264503  2642 solver.cpp:330] Iteration 61000, Testing net (#0)
I0924 23:29:07.352071  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:29:07.481338  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9211
I0924 23:29:07.481374  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.306366 (* 1 = 0.306366 loss)
I0924 23:29:07.614881  2642 solver.cpp:218] Iteration 61000 (6.0129 iter/s, 16.6309s/100 iters), loss = 0.00216825
I0924 23:29:07.614907  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00216785 (* 1 = 0.00216785 loss)
I0924 23:29:07.614914  2642 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I0924 23:29:21.025128  2642 solver.cpp:218] Iteration 61100 (7.45702 iter/s, 13.4102s/100 iters), loss = 0.00757885
I0924 23:29:21.025169  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00757846 (* 1 = 0.00757846 loss)
I0924 23:29:21.025177  2642 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I0924 23:29:34.431257  2642 solver.cpp:218] Iteration 61200 (7.45932 iter/s, 13.4061s/100 iters), loss = 0.00295541
I0924 23:29:34.431352  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00295502 (* 1 = 0.00295502 loss)
I0924 23:29:34.431370  2642 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I0924 23:29:47.834199  2642 solver.cpp:218] Iteration 61300 (7.46112 iter/s, 13.4028s/100 iters), loss = 0.00259877
I0924 23:29:47.834241  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00259837 (* 1 = 0.00259837 loss)
I0924 23:29:47.834247  2642 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I0924 23:30:01.239876  2642 solver.cpp:218] Iteration 61400 (7.45957 iter/s, 13.4056s/100 iters), loss = 0.00342372
I0924 23:30:01.239917  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00342332 (* 1 = 0.00342332 loss)
I0924 23:30:01.239923  2642 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I0924 23:30:13.989698  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:30:14.527130  2642 solver.cpp:330] Iteration 61500, Testing net (#0)
I0924 23:30:17.613867  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:30:17.742753  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9232
I0924 23:30:17.742787  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307983 (* 1 = 0.307983 loss)
I0924 23:30:17.875474  2642 solver.cpp:218] Iteration 61500 (6.01123 iter/s, 16.6355s/100 iters), loss = 0.00126043
I0924 23:30:17.875501  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00126003 (* 1 = 0.00126003 loss)
I0924 23:30:17.875509  2642 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I0924 23:30:31.280009  2642 solver.cpp:218] Iteration 61600 (7.4602 iter/s, 13.4045s/100 iters), loss = 0.0127403
I0924 23:30:31.280050  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127399 (* 1 = 0.0127399 loss)
I0924 23:30:31.280055  2642 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I0924 23:30:44.689124  2642 solver.cpp:218] Iteration 61700 (7.45765 iter/s, 13.409s/100 iters), loss = 0.00260721
I0924 23:30:44.689195  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00260681 (* 1 = 0.00260681 loss)
I0924 23:30:44.689203  2642 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I0924 23:30:58.095178  2642 solver.cpp:218] Iteration 61800 (7.45937 iter/s, 13.406s/100 iters), loss = 0.000977215
I0924 23:30:58.095218  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000976818 (* 1 = 0.000976818 loss)
I0924 23:30:58.095224  2642 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I0924 23:31:11.503856  2642 solver.cpp:218] Iteration 61900 (7.4579 iter/s, 13.4086s/100 iters), loss = 0.00770884
I0924 23:31:11.503897  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00770845 (* 1 = 0.00770845 loss)
I0924 23:31:11.503903  2642 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I0924 23:31:24.247617  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:31:24.783375  2642 solver.cpp:330] Iteration 62000, Testing net (#0)
I0924 23:31:27.870810  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:31:27.999945  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9236
I0924 23:31:27.999981  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.306974 (* 1 = 0.306974 loss)
I0924 23:31:28.132903  2642 solver.cpp:218] Iteration 62000 (6.0136 iter/s, 16.629s/100 iters), loss = 0.00264169
I0924 23:31:28.132930  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00264129 (* 1 = 0.00264129 loss)
I0924 23:31:28.132937  2642 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I0924 23:31:41.534016  2642 solver.cpp:218] Iteration 62100 (7.4621 iter/s, 13.4011s/100 iters), loss = 0.0366065
I0924 23:31:41.534057  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0366061 (* 1 = 0.0366061 loss)
I0924 23:31:41.534063  2642 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I0924 23:31:54.936625  2642 solver.cpp:218] Iteration 62200 (7.46127 iter/s, 13.4025s/100 iters), loss = 0.0067423
I0924 23:31:54.936743  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0067419 (* 1 = 0.0067419 loss)
I0924 23:31:54.936751  2642 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I0924 23:32:08.340574  2642 solver.cpp:218] Iteration 62300 (7.46057 iter/s, 13.4038s/100 iters), loss = 0.00100115
I0924 23:32:08.340603  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100076 (* 1 = 0.00100076 loss)
I0924 23:32:08.340610  2642 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I0924 23:32:21.747248  2642 solver.cpp:218] Iteration 62400 (7.45901 iter/s, 13.4066s/100 iters), loss = 0.0293084
I0924 23:32:21.747289  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.029308 (* 1 = 0.029308 loss)
I0924 23:32:21.747295  2642 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I0924 23:32:34.486201  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:32:35.023797  2642 solver.cpp:330] Iteration 62500, Testing net (#0)
I0924 23:32:38.110663  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:32:38.239449  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9228
I0924 23:32:38.239485  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308241 (* 1 = 0.308241 loss)
I0924 23:32:38.372589  2642 solver.cpp:218] Iteration 62500 (6.01494 iter/s, 16.6253s/100 iters), loss = 0.00367753
I0924 23:32:38.372615  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00367714 (* 1 = 0.00367714 loss)
I0924 23:32:38.372622  2642 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I0924 23:32:51.778113  2642 solver.cpp:218] Iteration 62600 (7.45964 iter/s, 13.4055s/100 iters), loss = 0.00581805
I0924 23:32:51.778153  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00581766 (* 1 = 0.00581766 loss)
I0924 23:32:51.778159  2642 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I0924 23:33:05.184924  2642 solver.cpp:218] Iteration 62700 (7.45894 iter/s, 13.4067s/100 iters), loss = 0.00184762
I0924 23:33:05.184984  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00184723 (* 1 = 0.00184723 loss)
I0924 23:33:05.184993  2642 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I0924 23:33:18.598397  2642 solver.cpp:218] Iteration 62800 (7.45524 iter/s, 13.4134s/100 iters), loss = 0.00288763
I0924 23:33:18.598438  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00288724 (* 1 = 0.00288724 loss)
I0924 23:33:18.598444  2642 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I0924 23:33:32.005753  2642 solver.cpp:218] Iteration 62900 (7.45863 iter/s, 13.4073s/100 iters), loss = 0.00311468
I0924 23:33:32.005795  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00311428 (* 1 = 0.00311428 loss)
I0924 23:33:32.005800  2642 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I0924 23:33:44.752588  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:33:45.289532  2642 solver.cpp:330] Iteration 63000, Testing net (#0)
I0924 23:33:48.376822  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:33:48.505445  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9234
I0924 23:33:48.505482  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300087 (* 1 = 0.300087 loss)
I0924 23:33:48.638713  2642 solver.cpp:218] Iteration 63000 (6.01219 iter/s, 16.6329s/100 iters), loss = 0.00715125
I0924 23:33:48.638741  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00715085 (* 1 = 0.00715085 loss)
I0924 23:33:48.638747  2642 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I0924 23:34:02.047420  2642 solver.cpp:218] Iteration 63100 (7.45787 iter/s, 13.4086s/100 iters), loss = 0.00331983
I0924 23:34:02.047449  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00331943 (* 1 = 0.00331943 loss)
I0924 23:34:02.047466  2642 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I0924 23:34:15.460711  2642 solver.cpp:218] Iteration 63200 (7.45533 iter/s, 13.4132s/100 iters), loss = 0.019856
I0924 23:34:15.460793  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0198556 (* 1 = 0.0198556 loss)
I0924 23:34:15.460809  2642 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I0924 23:34:28.870817  2642 solver.cpp:218] Iteration 63300 (7.45712 iter/s, 13.41s/100 iters), loss = 0.00947149
I0924 23:34:28.870847  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00947109 (* 1 = 0.00947109 loss)
I0924 23:34:28.870863  2642 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I0924 23:34:42.282789  2642 solver.cpp:218] Iteration 63400 (7.45606 iter/s, 13.4119s/100 iters), loss = 0.00276111
I0924 23:34:42.282819  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00276071 (* 1 = 0.00276071 loss)
I0924 23:34:42.282824  2642 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I0924 23:34:55.026729  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:34:55.563266  2642 solver.cpp:330] Iteration 63500, Testing net (#0)
I0924 23:34:58.650049  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:34:58.778302  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9236
I0924 23:34:58.778339  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311489 (* 1 = 0.311489 loss)
I0924 23:34:58.911561  2642 solver.cpp:218] Iteration 63500 (6.0137 iter/s, 16.6287s/100 iters), loss = 0.000742564
I0924 23:34:58.911588  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000742162 (* 1 = 0.000742162 loss)
I0924 23:34:58.911595  2642 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I0924 23:35:12.327816  2642 solver.cpp:218] Iteration 63600 (7.45368 iter/s, 13.4162s/100 iters), loss = 0.00474585
I0924 23:35:12.327846  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00474545 (* 1 = 0.00474545 loss)
I0924 23:35:12.327862  2642 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I0924 23:35:25.748350  2642 solver.cpp:218] Iteration 63700 (7.4513 iter/s, 13.4205s/100 iters), loss = 0.00152885
I0924 23:35:25.748411  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00152845 (* 1 = 0.00152845 loss)
I0924 23:35:25.748428  2642 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I0924 23:35:39.172228  2642 solver.cpp:218] Iteration 63800 (7.44946 iter/s, 13.4238s/100 iters), loss = 0.00664753
I0924 23:35:39.172257  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00664713 (* 1 = 0.00664713 loss)
I0924 23:35:39.172262  2642 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I0924 23:35:52.592154  2642 solver.cpp:218] Iteration 63900 (7.45164 iter/s, 13.4199s/100 iters), loss = 0.00118442
I0924 23:35:52.592186  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00118402 (* 1 = 0.00118402 loss)
I0924 23:35:52.592201  2642 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I0924 23:36:05.347641  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:36:05.885181  2642 solver.cpp:330] Iteration 64000, Testing net (#0)
I0924 23:36:08.971639  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:36:09.100795  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9243
I0924 23:36:09.100831  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304298 (* 1 = 0.304298 loss)
I0924 23:36:09.234449  2642 solver.cpp:218] Iteration 64000 (6.00881 iter/s, 16.6422s/100 iters), loss = 0.00188754
I0924 23:36:09.234475  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188714 (* 1 = 0.00188714 loss)
I0924 23:36:09.234483  2642 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I0924 23:36:22.639137  2642 solver.cpp:218] Iteration 64100 (7.46011 iter/s, 13.4046s/100 iters), loss = 0.00677286
I0924 23:36:22.639168  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00677246 (* 1 = 0.00677246 loss)
I0924 23:36:22.639184  2642 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I0924 23:36:36.053647  2642 solver.cpp:218] Iteration 64200 (7.45465 iter/s, 13.4144s/100 iters), loss = 0.00398778
I0924 23:36:36.053725  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00398739 (* 1 = 0.00398739 loss)
I0924 23:36:36.053742  2642 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I0924 23:36:49.468895  2642 solver.cpp:218] Iteration 64300 (7.45426 iter/s, 13.4151s/100 iters), loss = 0.00184021
I0924 23:36:49.468927  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00183982 (* 1 = 0.00183982 loss)
I0924 23:36:49.468943  2642 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I0924 23:37:02.878718  2642 solver.cpp:218] Iteration 64400 (7.45726 iter/s, 13.4098s/100 iters), loss = 0.0041561
I0924 23:37:02.878748  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00415571 (* 1 = 0.00415571 loss)
I0924 23:37:02.878754  2642 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I0924 23:37:15.624941  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:37:16.161240  2642 solver.cpp:330] Iteration 64500, Testing net (#0)
I0924 23:37:19.249850  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:37:19.378304  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9234
I0924 23:37:19.378340  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312922 (* 1 = 0.312922 loss)
I0924 23:37:19.511730  2642 solver.cpp:218] Iteration 64500 (6.01216 iter/s, 16.6329s/100 iters), loss = 0.00267894
I0924 23:37:19.511757  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00267856 (* 1 = 0.00267856 loss)
I0924 23:37:19.511765  2642 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I0924 23:37:32.923954  2642 solver.cpp:218] Iteration 64600 (7.45592 iter/s, 13.4122s/100 iters), loss = 0.00937484
I0924 23:37:32.923995  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00937446 (* 1 = 0.00937446 loss)
I0924 23:37:32.924000  2642 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I0924 23:37:46.345306  2642 solver.cpp:218] Iteration 64700 (7.45085 iter/s, 13.4213s/100 iters), loss = 0.00085104
I0924 23:37:46.345441  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00085065 (* 1 = 0.00085065 loss)
I0924 23:37:46.345448  2642 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I0924 23:37:59.759088  2642 solver.cpp:218] Iteration 64800 (7.45511 iter/s, 13.4136s/100 iters), loss = 0.00260933
I0924 23:37:59.759120  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00260894 (* 1 = 0.00260894 loss)
I0924 23:37:59.759126  2642 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I0924 23:38:13.175391  2642 solver.cpp:218] Iteration 64900 (7.45365 iter/s, 13.4162s/100 iters), loss = 0.00157187
I0924 23:38:13.175433  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00157147 (* 1 = 0.00157147 loss)
I0924 23:38:13.175439  2642 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I0924 23:38:25.919416  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:38:26.456804  2642 solver.cpp:330] Iteration 65000, Testing net (#0)
I0924 23:38:29.545272  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:38:29.673560  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9221
I0924 23:38:29.673595  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318449 (* 1 = 0.318449 loss)
I0924 23:38:29.806823  2642 solver.cpp:218] Iteration 65000 (6.01274 iter/s, 16.6314s/100 iters), loss = 0.000914096
I0924 23:38:29.806850  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000913703 (* 1 = 0.000913703 loss)
I0924 23:38:29.806857  2642 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I0924 23:38:43.213860  2642 solver.cpp:218] Iteration 65100 (7.4588 iter/s, 13.407s/100 iters), loss = 0.00339292
I0924 23:38:43.213891  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00339252 (* 1 = 0.00339252 loss)
I0924 23:38:43.213896  2642 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I0924 23:38:56.615829  2642 solver.cpp:218] Iteration 65200 (7.46163 iter/s, 13.4019s/100 iters), loss = 0.00293379
I0924 23:38:56.615924  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00293339 (* 1 = 0.00293339 loss)
I0924 23:38:56.615931  2642 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I0924 23:39:10.021061  2642 solver.cpp:218] Iteration 65300 (7.45984 iter/s, 13.4051s/100 iters), loss = 0.0125962
I0924 23:39:10.021102  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125958 (* 1 = 0.0125958 loss)
I0924 23:39:10.021107  2642 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I0924 23:39:23.427392  2642 solver.cpp:218] Iteration 65400 (7.4592 iter/s, 13.4063s/100 iters), loss = 0.000818036
I0924 23:39:23.427431  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000817634 (* 1 = 0.000817634 loss)
I0924 23:39:23.427438  2642 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I0924 23:39:36.163686  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:39:36.700433  2642 solver.cpp:330] Iteration 65500, Testing net (#0)
I0924 23:39:39.789422  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:39:39.918431  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I0924 23:39:39.918467  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319628 (* 1 = 0.319628 loss)
I0924 23:39:40.051893  2642 solver.cpp:218] Iteration 65500 (6.01525 iter/s, 16.6244s/100 iters), loss = 0.00229063
I0924 23:39:40.051921  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00229022 (* 1 = 0.00229022 loss)
I0924 23:39:40.051928  2642 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I0924 23:39:53.462220  2642 solver.cpp:218] Iteration 65600 (7.45697 iter/s, 13.4103s/100 iters), loss = 0.00144226
I0924 23:39:53.462261  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00144185 (* 1 = 0.00144185 loss)
I0924 23:39:53.462267  2642 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I0924 23:40:06.873605  2642 solver.cpp:218] Iteration 65700 (7.45639 iter/s, 13.4113s/100 iters), loss = 0.00901282
I0924 23:40:06.873704  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00901242 (* 1 = 0.00901242 loss)
I0924 23:40:06.873713  2642 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I0924 23:40:20.287551  2642 solver.cpp:218] Iteration 65800 (7.45499 iter/s, 13.4138s/100 iters), loss = 0.00399198
I0924 23:40:20.287592  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00399158 (* 1 = 0.00399158 loss)
I0924 23:40:20.287597  2642 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I0924 23:40:33.702309  2642 solver.cpp:218] Iteration 65900 (7.45452 iter/s, 13.4147s/100 iters), loss = 0.00256452
I0924 23:40:33.702350  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00256412 (* 1 = 0.00256412 loss)
I0924 23:40:33.702356  2642 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I0924 23:40:46.455418  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:40:46.993196  2642 solver.cpp:330] Iteration 66000, Testing net (#0)
I0924 23:40:50.083324  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:40:50.212013  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9234
I0924 23:40:50.212049  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309531 (* 1 = 0.309531 loss)
I0924 23:40:50.345088  2642 solver.cpp:218] Iteration 66000 (6.00864 iter/s, 16.6427s/100 iters), loss = 0.00218189
I0924 23:40:50.345114  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00218149 (* 1 = 0.00218149 loss)
I0924 23:40:50.345120  2642 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I0924 23:41:03.760463  2642 solver.cpp:218] Iteration 66100 (7.45417 iter/s, 13.4153s/100 iters), loss = 0.0034317
I0924 23:41:03.760504  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00343129 (* 1 = 0.00343129 loss)
I0924 23:41:03.760510  2642 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I0924 23:41:17.178668  2642 solver.cpp:218] Iteration 66200 (7.4526 iter/s, 13.4181s/100 iters), loss = 0.00246828
I0924 23:41:17.178788  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00246787 (* 1 = 0.00246787 loss)
I0924 23:41:17.178795  2642 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I0924 23:41:30.596293  2642 solver.cpp:218] Iteration 66300 (7.45296 iter/s, 13.4175s/100 iters), loss = 0.00198381
I0924 23:41:30.596333  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0019834 (* 1 = 0.0019834 loss)
I0924 23:41:30.596339  2642 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I0924 23:41:44.013499  2642 solver.cpp:218] Iteration 66400 (7.45316 iter/s, 13.4171s/100 iters), loss = 0.00298235
I0924 23:41:44.013530  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00298195 (* 1 = 0.00298195 loss)
I0924 23:41:44.013535  2642 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I0924 23:41:56.762828  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:41:57.300041  2642 solver.cpp:330] Iteration 66500, Testing net (#0)
I0924 23:42:00.389816  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:42:00.518676  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9243
I0924 23:42:00.518712  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308599 (* 1 = 0.308599 loss)
I0924 23:42:00.651866  2642 solver.cpp:218] Iteration 66500 (6.01023 iter/s, 16.6383s/100 iters), loss = 0.0012514
I0924 23:42:00.651893  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00125101 (* 1 = 0.00125101 loss)
I0924 23:42:00.651901  2642 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I0924 23:42:14.085036  2642 solver.cpp:218] Iteration 66600 (7.44429 iter/s, 13.4331s/100 iters), loss = 0.00684986
I0924 23:42:14.085075  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00684946 (* 1 = 0.00684946 loss)
I0924 23:42:14.085081  2642 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I0924 23:42:27.517071  2642 solver.cpp:218] Iteration 66700 (7.44493 iter/s, 13.432s/100 iters), loss = 0.00483418
I0924 23:42:27.517144  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00483377 (* 1 = 0.00483377 loss)
I0924 23:42:27.517151  2642 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I0924 23:42:40.951066  2642 solver.cpp:218] Iteration 66800 (7.44386 iter/s, 13.4339s/100 iters), loss = 0.00188775
I0924 23:42:40.951107  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188735 (* 1 = 0.00188735 loss)
I0924 23:42:40.951112  2642 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I0924 23:42:54.387092  2642 solver.cpp:218] Iteration 66900 (7.44272 iter/s, 13.436s/100 iters), loss = 0.0139895
I0924 23:42:54.387135  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139891 (* 1 = 0.0139891 loss)
I0924 23:42:54.387141  2642 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I0924 23:43:07.154361  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:43:07.691525  2642 solver.cpp:330] Iteration 67000, Testing net (#0)
I0924 23:43:10.783188  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:43:10.911942  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9237
I0924 23:43:10.911978  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318568 (* 1 = 0.318568 loss)
I0924 23:43:11.045542  2642 solver.cpp:218] Iteration 67000 (6.00299 iter/s, 16.6584s/100 iters), loss = 0.00147366
I0924 23:43:11.045570  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00147326 (* 1 = 0.00147326 loss)
I0924 23:43:11.045577  2642 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I0924 23:43:24.471680  2642 solver.cpp:218] Iteration 67100 (7.44819 iter/s, 13.4261s/100 iters), loss = 0.0010366
I0924 23:43:24.471710  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103619 (* 1 = 0.00103619 loss)
I0924 23:43:24.471716  2642 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I0924 23:43:37.883468  2642 solver.cpp:218] Iteration 67200 (7.45616 iter/s, 13.4117s/100 iters), loss = 0.00367679
I0924 23:43:37.883589  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00367638 (* 1 = 0.00367638 loss)
I0924 23:43:37.883596  2642 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I0924 23:43:51.304525  2642 solver.cpp:218] Iteration 67300 (7.45106 iter/s, 13.4209s/100 iters), loss = 0.00281484
I0924 23:43:51.304556  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00281444 (* 1 = 0.00281444 loss)
I0924 23:43:51.304561  2642 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I0924 23:44:04.730487  2642 solver.cpp:218] Iteration 67400 (7.44829 iter/s, 13.4259s/100 iters), loss = 0.0021339
I0924 23:44:04.730528  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0021335 (* 1 = 0.0021335 loss)
I0924 23:44:04.730535  2642 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I0924 23:44:17.485980  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:44:18.023259  2642 solver.cpp:330] Iteration 67500, Testing net (#0)
I0924 23:44:21.113791  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:44:21.242578  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9232
I0924 23:44:21.242612  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309159 (* 1 = 0.309159 loss)
I0924 23:44:21.375788  2642 solver.cpp:218] Iteration 67500 (6.00773 iter/s, 16.6452s/100 iters), loss = 0.00105201
I0924 23:44:21.375818  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00105161 (* 1 = 0.00105161 loss)
I0924 23:44:21.375823  2642 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I0924 23:44:34.787793  2642 solver.cpp:218] Iteration 67600 (7.45604 iter/s, 13.4119s/100 iters), loss = 0.00246266
I0924 23:44:34.787833  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00246226 (* 1 = 0.00246226 loss)
I0924 23:44:34.787839  2642 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I0924 23:44:48.204355  2642 solver.cpp:218] Iteration 67700 (7.45352 iter/s, 13.4165s/100 iters), loss = 0.00216465
I0924 23:44:48.204481  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00216425 (* 1 = 0.00216425 loss)
I0924 23:44:48.204488  2642 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I0924 23:45:01.607786  2642 solver.cpp:218] Iteration 67800 (7.46086 iter/s, 13.4033s/100 iters), loss = 0.00466086
I0924 23:45:01.607827  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00466045 (* 1 = 0.00466045 loss)
I0924 23:45:01.607833  2642 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I0924 23:45:15.007907  2642 solver.cpp:218] Iteration 67900 (7.46266 iter/s, 13.4s/100 iters), loss = 0.00159482
I0924 23:45:15.007947  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00159441 (* 1 = 0.00159441 loss)
I0924 23:45:15.007953  2642 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I0924 23:45:27.744027  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:45:28.279814  2642 solver.cpp:330] Iteration 68000, Testing net (#0)
I0924 23:45:31.369874  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:45:31.498896  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9212
I0924 23:45:31.498932  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31773 (* 1 = 0.31773 loss)
I0924 23:45:31.632063  2642 solver.cpp:218] Iteration 68000 (6.01537 iter/s, 16.6241s/100 iters), loss = 0.00175338
I0924 23:45:31.632089  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00175297 (* 1 = 0.00175297 loss)
I0924 23:45:31.632097  2642 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I0924 23:45:45.057888  2642 solver.cpp:218] Iteration 68100 (7.44837 iter/s, 13.4258s/100 iters), loss = 0.00261193
I0924 23:45:45.057927  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00261152 (* 1 = 0.00261152 loss)
I0924 23:45:45.057934  2642 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I0924 23:45:58.488725  2642 solver.cpp:218] Iteration 68200 (7.44559 iter/s, 13.4308s/100 iters), loss = 0.00301744
I0924 23:45:58.488813  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00301703 (* 1 = 0.00301703 loss)
I0924 23:45:58.488831  2642 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I0924 23:46:11.921950  2642 solver.cpp:218] Iteration 68300 (7.44429 iter/s, 13.4331s/100 iters), loss = 0.00135399
I0924 23:46:11.921979  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00135358 (* 1 = 0.00135358 loss)
I0924 23:46:11.921985  2642 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I0924 23:46:25.352258  2642 solver.cpp:218] Iteration 68400 (7.44588 iter/s, 13.4302s/100 iters), loss = 0.00330833
I0924 23:46:25.352299  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00330793 (* 1 = 0.00330793 loss)
I0924 23:46:25.352304  2642 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I0924 23:46:38.115363  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:46:38.653633  2642 solver.cpp:330] Iteration 68500, Testing net (#0)
I0924 23:46:41.745762  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:46:41.874585  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9216
I0924 23:46:41.874621  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316752 (* 1 = 0.316752 loss)
I0924 23:46:42.008214  2642 solver.cpp:218] Iteration 68500 (6.00389 iter/s, 16.6559s/100 iters), loss = 0.0135841
I0924 23:46:42.008241  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0135837 (* 1 = 0.0135837 loss)
I0924 23:46:42.008249  2642 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I0924 23:46:55.431463  2642 solver.cpp:218] Iteration 68600 (7.4498 iter/s, 13.4232s/100 iters), loss = 0.00598061
I0924 23:46:55.431504  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00598021 (* 1 = 0.00598021 loss)
I0924 23:46:55.431510  2642 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I0924 23:47:08.859429  2642 solver.cpp:218] Iteration 68700 (7.44718 iter/s, 13.4279s/100 iters), loss = 0.00243408
I0924 23:47:08.859558  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00243367 (* 1 = 0.00243367 loss)
I0924 23:47:08.859567  2642 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I0924 23:47:22.282968  2642 solver.cpp:218] Iteration 68800 (7.44969 iter/s, 13.4234s/100 iters), loss = 0.00110532
I0924 23:47:22.283010  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00110492 (* 1 = 0.00110492 loss)
I0924 23:47:22.283015  2642 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I0924 23:47:35.711138  2642 solver.cpp:218] Iteration 68900 (7.44707 iter/s, 13.4281s/100 iters), loss = 0.00372783
I0924 23:47:35.711179  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00372742 (* 1 = 0.00372742 loss)
I0924 23:47:35.711184  2642 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I0924 23:47:48.468250  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:47:49.005429  2642 solver.cpp:330] Iteration 69000, Testing net (#0)
I0924 23:47:52.097273  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:47:52.224993  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9213
I0924 23:47:52.225029  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324772 (* 1 = 0.324772 loss)
I0924 23:47:52.358069  2642 solver.cpp:218] Iteration 69000 (6.00714 iter/s, 16.6469s/100 iters), loss = 0.00604295
I0924 23:47:52.358098  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00604254 (* 1 = 0.00604254 loss)
I0924 23:47:52.358103  2642 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I0924 23:48:05.788714  2642 solver.cpp:218] Iteration 69100 (7.44569 iter/s, 13.4306s/100 iters), loss = 0.00507589
I0924 23:48:05.788745  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00507548 (* 1 = 0.00507548 loss)
I0924 23:48:05.788751  2642 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I0924 23:48:19.212999  2642 solver.cpp:218] Iteration 69200 (7.44922 iter/s, 13.4242s/100 iters), loss = 0.00508235
I0924 23:48:19.213093  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00508195 (* 1 = 0.00508195 loss)
I0924 23:48:19.213099  2642 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I0924 23:48:32.640228  2642 solver.cpp:218] Iteration 69300 (7.44762 iter/s, 13.4271s/100 iters), loss = 0.00409316
I0924 23:48:32.640269  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00409275 (* 1 = 0.00409275 loss)
I0924 23:48:32.640275  2642 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I0924 23:48:46.049140  2642 solver.cpp:218] Iteration 69400 (7.45777 iter/s, 13.4088s/100 iters), loss = 0.00396053
I0924 23:48:46.049181  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00396012 (* 1 = 0.00396012 loss)
I0924 23:48:46.049187  2642 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I0924 23:48:58.790347  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:48:59.327296  2642 solver.cpp:330] Iteration 69500, Testing net (#0)
I0924 23:49:02.418678  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:49:02.548059  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9243
I0924 23:49:02.548096  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309098 (* 1 = 0.309098 loss)
I0924 23:49:02.681735  2642 solver.cpp:218] Iteration 69500 (6.01232 iter/s, 16.6325s/100 iters), loss = 0.000780828
I0924 23:49:02.681761  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000780427 (* 1 = 0.000780427 loss)
I0924 23:49:02.681767  2642 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I0924 23:49:16.114611  2642 solver.cpp:218] Iteration 69600 (7.44446 iter/s, 13.4328s/100 iters), loss = 0.004572
I0924 23:49:16.114652  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0045716 (* 1 = 0.0045716 loss)
I0924 23:49:16.114658  2642 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I0924 23:49:29.544688  2642 solver.cpp:218] Iteration 69700 (7.44601 iter/s, 13.43s/100 iters), loss = 0.0020085
I0924 23:49:29.544793  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0020081 (* 1 = 0.0020081 loss)
I0924 23:49:29.544809  2642 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I0924 23:49:42.973757  2642 solver.cpp:218] Iteration 69800 (7.4466 iter/s, 13.4289s/100 iters), loss = 0.00162767
I0924 23:49:42.973795  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00162727 (* 1 = 0.00162727 loss)
I0924 23:49:42.973801  2642 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I0924 23:49:56.402503  2642 solver.cpp:218] Iteration 69900 (7.44675 iter/s, 13.4287s/100 iters), loss = 0.00543589
I0924 23:49:56.402544  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00543549 (* 1 = 0.00543549 loss)
I0924 23:49:56.402549  2642 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I0924 23:50:09.163007  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:50:09.700258  2642 solver.cpp:330] Iteration 70000, Testing net (#0)
I0924 23:50:12.792894  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:50:12.921507  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I0924 23:50:12.921545  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311673 (* 1 = 0.311673 loss)
I0924 23:50:13.054579  2642 solver.cpp:218] Iteration 70000 (6.00529 iter/s, 16.652s/100 iters), loss = 0.0057029
I0924 23:50:13.054607  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0057025 (* 1 = 0.0057025 loss)
I0924 23:50:13.054613  2642 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I0924 23:50:26.477679  2642 solver.cpp:218] Iteration 70100 (7.44988 iter/s, 13.423s/100 iters), loss = 0.00764861
I0924 23:50:26.477720  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0076482 (* 1 = 0.0076482 loss)
I0924 23:50:26.477725  2642 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I0924 23:50:39.902775  2642 solver.cpp:218] Iteration 70200 (7.44878 iter/s, 13.425s/100 iters), loss = 0.00389101
I0924 23:50:39.902865  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0038906 (* 1 = 0.0038906 loss)
I0924 23:50:39.902873  2642 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I0924 23:50:53.336833  2642 solver.cpp:218] Iteration 70300 (7.44384 iter/s, 13.4339s/100 iters), loss = 0.00802385
I0924 23:50:53.336863  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00802344 (* 1 = 0.00802344 loss)
I0924 23:50:53.336869  2642 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I0924 23:51:06.761410  2642 solver.cpp:218] Iteration 70400 (7.44906 iter/s, 13.4245s/100 iters), loss = 0.00205358
I0924 23:51:06.761451  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00205317 (* 1 = 0.00205317 loss)
I0924 23:51:06.761457  2642 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I0924 23:51:19.517400  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:51:20.053761  2642 solver.cpp:330] Iteration 70500, Testing net (#0)
I0924 23:51:23.145373  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:51:23.274101  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.926
I0924 23:51:23.274138  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.30861 (* 1 = 0.30861 loss)
I0924 23:51:23.407049  2642 solver.cpp:218] Iteration 70500 (6.00761 iter/s, 16.6456s/100 iters), loss = 0.00363302
I0924 23:51:23.407076  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00363261 (* 1 = 0.00363261 loss)
I0924 23:51:23.407083  2642 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I0924 23:51:36.819047  2642 solver.cpp:218] Iteration 70600 (7.45605 iter/s, 13.4119s/100 iters), loss = 0.00230001
I0924 23:51:36.819077  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00229961 (* 1 = 0.00229961 loss)
I0924 23:51:36.819083  2642 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I0924 23:51:50.222323  2642 solver.cpp:218] Iteration 70700 (7.4609 iter/s, 13.4032s/100 iters), loss = 0.000779915
I0924 23:51:50.222451  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000779508 (* 1 = 0.000779508 loss)
I0924 23:51:50.222458  2642 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I0924 23:52:03.625555  2642 solver.cpp:218] Iteration 70800 (7.46097 iter/s, 13.4031s/100 iters), loss = 0.028213
I0924 23:52:03.625596  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0282126 (* 1 = 0.0282126 loss)
I0924 23:52:03.625602  2642 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I0924 23:52:17.028767  2642 solver.cpp:218] Iteration 70900 (7.46094 iter/s, 13.4031s/100 iters), loss = 0.0021303
I0924 23:52:17.028807  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00212989 (* 1 = 0.00212989 loss)
I0924 23:52:17.028813  2642 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I0924 23:52:29.771106  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:52:30.307225  2642 solver.cpp:330] Iteration 71000, Testing net (#0)
I0924 23:52:33.397080  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:52:33.526180  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9244
I0924 23:52:33.526216  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.317749 (* 1 = 0.317749 loss)
I0924 23:52:33.659436  2642 solver.cpp:218] Iteration 71000 (6.01302 iter/s, 16.6306s/100 iters), loss = 0.000334233
I0924 23:52:33.659463  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000333825 (* 1 = 0.000333825 loss)
I0924 23:52:33.659471  2642 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I0924 23:52:47.082482  2642 solver.cpp:218] Iteration 71100 (7.44991 iter/s, 13.423s/100 iters), loss = 0.00468493
I0924 23:52:47.082521  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00468452 (* 1 = 0.00468452 loss)
I0924 23:52:47.082527  2642 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I0924 23:53:00.512871  2642 solver.cpp:218] Iteration 71200 (7.44584 iter/s, 13.4303s/100 iters), loss = 0.0193646
I0924 23:53:00.512960  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0193642 (* 1 = 0.0193642 loss)
I0924 23:53:00.512979  2642 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I0924 23:53:13.935573  2642 solver.cpp:218] Iteration 71300 (7.45013 iter/s, 13.4226s/100 iters), loss = 0.000799431
I0924 23:53:13.935603  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00079903 (* 1 = 0.00079903 loss)
I0924 23:53:13.935609  2642 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I0924 23:53:27.360098  2642 solver.cpp:218] Iteration 71400 (7.44909 iter/s, 13.4245s/100 iters), loss = 0.00119603
I0924 23:53:27.360128  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00119563 (* 1 = 0.00119563 loss)
I0924 23:53:27.360136  2642 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I0924 23:53:40.120167  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:53:40.658023  2642 solver.cpp:330] Iteration 71500, Testing net (#0)
I0924 23:53:43.750035  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:53:43.878965  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9233
I0924 23:53:43.879001  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329301 (* 1 = 0.329301 loss)
I0924 23:53:44.012441  2642 solver.cpp:218] Iteration 71500 (6.00519 iter/s, 16.6523s/100 iters), loss = 0.00313164
I0924 23:53:44.012468  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00313124 (* 1 = 0.00313124 loss)
I0924 23:53:44.012475  2642 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I0924 23:53:57.440126  2642 solver.cpp:218] Iteration 71600 (7.44733 iter/s, 13.4276s/100 iters), loss = 0.00674009
I0924 23:53:57.440157  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00673968 (* 1 = 0.00673968 loss)
I0924 23:53:57.440173  2642 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I0924 23:54:10.867777  2642 solver.cpp:218] Iteration 71700 (7.44735 iter/s, 13.4276s/100 iters), loss = 0.0110351
I0924 23:54:10.867835  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110347 (* 1 = 0.0110347 loss)
I0924 23:54:10.867851  2642 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I0924 23:54:24.298197  2642 solver.cpp:218] Iteration 71800 (7.44583 iter/s, 13.4303s/100 iters), loss = 0.000841501
I0924 23:54:24.298228  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000841094 (* 1 = 0.000841094 loss)
I0924 23:54:24.298244  2642 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I0924 23:54:37.717947  2642 solver.cpp:218] Iteration 71900 (7.45174 iter/s, 13.4197s/100 iters), loss = 0.00113065
I0924 23:54:37.717977  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00113025 (* 1 = 0.00113025 loss)
I0924 23:54:37.717993  2642 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I0924 23:54:50.461380  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:54:50.998287  2642 solver.cpp:330] Iteration 72000, Testing net (#0)
I0924 23:54:54.089635  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:54:54.218796  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9225
I0924 23:54:54.218832  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329762 (* 1 = 0.329762 loss)
I0924 23:54:54.352363  2642 solver.cpp:218] Iteration 72000 (6.01166 iter/s, 16.6343s/100 iters), loss = 0.00117539
I0924 23:54:54.352391  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00117498 (* 1 = 0.00117498 loss)
I0924 23:54:54.352397  2642 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I0924 23:55:07.786636  2642 solver.cpp:218] Iteration 72100 (7.44368 iter/s, 13.4342s/100 iters), loss = 0.010199
I0924 23:55:07.786676  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101986 (* 1 = 0.0101986 loss)
I0924 23:55:07.786681  2642 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I0924 23:55:21.222236  2642 solver.cpp:218] Iteration 72200 (7.44295 iter/s, 13.4355s/100 iters), loss = 0.00362338
I0924 23:55:21.222326  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00362297 (* 1 = 0.00362297 loss)
I0924 23:55:21.222333  2642 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I0924 23:55:34.664700  2642 solver.cpp:218] Iteration 72300 (7.43918 iter/s, 13.4423s/100 iters), loss = 0.00280553
I0924 23:55:34.664741  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00280512 (* 1 = 0.00280512 loss)
I0924 23:55:34.664747  2642 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I0924 23:55:48.098861  2642 solver.cpp:218] Iteration 72400 (7.44375 iter/s, 13.4341s/100 iters), loss = 0.00712478
I0924 23:55:48.098891  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00712436 (* 1 = 0.00712436 loss)
I0924 23:55:48.098896  2642 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I0924 23:56:00.866139  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:56:01.403599  2642 solver.cpp:330] Iteration 72500, Testing net (#0)
I0924 23:56:04.495981  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:56:04.624377  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9218
I0924 23:56:04.624413  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.323572 (* 1 = 0.323572 loss)
I0924 23:56:04.757594  2642 solver.cpp:218] Iteration 72500 (6.00288 iter/s, 16.6587s/100 iters), loss = 0.00138179
I0924 23:56:04.757621  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00138138 (* 1 = 0.00138138 loss)
I0924 23:56:04.757627  2642 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I0924 23:56:18.174923  2642 solver.cpp:218] Iteration 72600 (7.45308 iter/s, 13.4173s/100 iters), loss = 0.00143217
I0924 23:56:18.174954  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00143176 (* 1 = 0.00143176 loss)
I0924 23:56:18.174960  2642 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I0924 23:56:31.603324  2642 solver.cpp:218] Iteration 72700 (7.44694 iter/s, 13.4283s/100 iters), loss = 0.00299325
I0924 23:56:31.603444  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00299284 (* 1 = 0.00299284 loss)
I0924 23:56:31.603452  2642 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I0924 23:56:45.029634  2642 solver.cpp:218] Iteration 72800 (7.44815 iter/s, 13.4262s/100 iters), loss = 0.00142759
I0924 23:56:45.029675  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00142718 (* 1 = 0.00142718 loss)
I0924 23:56:45.029681  2642 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I0924 23:56:58.457114  2642 solver.cpp:218] Iteration 72900 (7.44745 iter/s, 13.4274s/100 iters), loss = 0.00126669
I0924 23:56:58.457144  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00126628 (* 1 = 0.00126628 loss)
I0924 23:56:58.457150  2642 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I0924 23:57:11.217260  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:57:11.753651  2642 solver.cpp:330] Iteration 73000, Testing net (#0)
I0924 23:57:14.845105  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:57:14.974076  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9218
I0924 23:57:14.974112  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322245 (* 1 = 0.322245 loss)
I0924 23:57:15.107650  2642 solver.cpp:218] Iteration 73000 (6.00584 iter/s, 16.6505s/100 iters), loss = 0.00208547
I0924 23:57:15.107676  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00208507 (* 1 = 0.00208507 loss)
I0924 23:57:15.107683  2642 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I0924 23:57:28.530190  2642 solver.cpp:218] Iteration 73100 (7.45019 iter/s, 13.4225s/100 iters), loss = 0.00297349
I0924 23:57:28.530231  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00297308 (* 1 = 0.00297308 loss)
I0924 23:57:28.530237  2642 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I0924 23:57:41.953902  2642 solver.cpp:218] Iteration 73200 (7.44954 iter/s, 13.4236s/100 iters), loss = 0.0014189
I0924 23:57:41.954035  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00141849 (* 1 = 0.00141849 loss)
I0924 23:57:41.954043  2642 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I0924 23:57:55.374119  2642 solver.cpp:218] Iteration 73300 (7.45153 iter/s, 13.4201s/100 iters), loss = 0.00136895
I0924 23:57:55.374150  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00136854 (* 1 = 0.00136854 loss)
I0924 23:57:55.374155  2642 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I0924 23:58:08.802271  2642 solver.cpp:218] Iteration 73400 (7.44708 iter/s, 13.4281s/100 iters), loss = 0.000946289
I0924 23:58:08.802304  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000945881 (* 1 = 0.000945881 loss)
I0924 23:58:08.802320  2642 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I0924 23:58:21.549474  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:58:22.086364  2642 solver.cpp:330] Iteration 73500, Testing net (#0)
I0924 23:58:25.176136  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:58:25.305552  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9245
I0924 23:58:25.305589  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.30849 (* 1 = 0.30849 loss)
I0924 23:58:25.439579  2642 solver.cpp:218] Iteration 73500 (6.01061 iter/s, 16.6372s/100 iters), loss = 0.0120981
I0924 23:58:25.439606  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0120977 (* 1 = 0.0120977 loss)
I0924 23:58:25.439612  2642 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I0924 23:58:38.869125  2642 solver.cpp:218] Iteration 73600 (7.4463 iter/s, 13.4295s/100 iters), loss = 0.00259944
I0924 23:58:38.869166  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00259903 (* 1 = 0.00259903 loss)
I0924 23:58:38.869173  2642 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I0924 23:58:52.287652  2642 solver.cpp:218] Iteration 73700 (7.45242 iter/s, 13.4185s/100 iters), loss = 0.00677435
I0924 23:58:52.287781  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00677395 (* 1 = 0.00677395 loss)
I0924 23:58:52.287788  2642 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I0924 23:59:05.704632  2642 solver.cpp:218] Iteration 73800 (7.45332 iter/s, 13.4168s/100 iters), loss = 0.000774251
I0924 23:59:05.704661  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000773843 (* 1 = 0.000773843 loss)
I0924 23:59:05.704668  2642 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I0924 23:59:19.119696  2642 solver.cpp:218] Iteration 73900 (7.45434 iter/s, 13.415s/100 iters), loss = 0.00133771
I0924 23:59:19.119737  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0013373 (* 1 = 0.0013373 loss)
I0924 23:59:19.119743  2642 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I0924 23:59:31.871062  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:59:32.408488  2642 solver.cpp:330] Iteration 74000, Testing net (#0)
I0924 23:59:35.500095  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0924 23:59:35.628479  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9212
I0924 23:59:35.628515  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.336839 (* 1 = 0.336839 loss)
I0924 23:59:35.762064  2642 solver.cpp:218] Iteration 74000 (6.00879 iter/s, 16.6423s/100 iters), loss = 0.00093356
I0924 23:59:35.762091  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000933151 (* 1 = 0.000933151 loss)
I0924 23:59:35.762097  2642 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I0924 23:59:49.185662  2642 solver.cpp:218] Iteration 74100 (7.4496 iter/s, 13.4235s/100 iters), loss = 0.0376891
I0924 23:59:49.185691  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0376886 (* 1 = 0.0376886 loss)
I0924 23:59:49.185698  2642 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I0925 00:00:02.617729  2642 solver.cpp:218] Iteration 74200 (7.4449 iter/s, 13.432s/100 iters), loss = 0.0048862
I0925 00:00:02.617858  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00488579 (* 1 = 0.00488579 loss)
I0925 00:00:02.617866  2642 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I0925 00:00:16.041863  2642 solver.cpp:218] Iteration 74300 (7.44935 iter/s, 13.424s/100 iters), loss = 0.000932695
I0925 00:00:16.041904  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000932279 (* 1 = 0.000932279 loss)
I0925 00:00:16.041910  2642 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I0925 00:00:29.464574  2642 solver.cpp:218] Iteration 74400 (7.4501 iter/s, 13.4226s/100 iters), loss = 0.00592256
I0925 00:00:29.464615  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00592214 (* 1 = 0.00592214 loss)
I0925 00:00:29.464622  2642 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I0925 00:00:42.222384  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:00:42.758869  2642 solver.cpp:330] Iteration 74500, Testing net (#0)
I0925 00:00:45.850875  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:00:45.979554  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9225
I0925 00:00:45.979590  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319749 (* 1 = 0.319749 loss)
I0925 00:00:46.113051  2642 solver.cpp:218] Iteration 74500 (6.00658 iter/s, 16.6484s/100 iters), loss = 0.00485444
I0925 00:00:46.113078  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00485402 (* 1 = 0.00485402 loss)
I0925 00:00:46.113085  2642 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I0925 00:00:59.529633  2642 solver.cpp:218] Iteration 74600 (7.4535 iter/s, 13.4165s/100 iters), loss = 0.000751094
I0925 00:00:59.529675  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000750677 (* 1 = 0.000750677 loss)
I0925 00:00:59.529680  2642 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I0925 00:01:12.951179  2642 solver.cpp:218] Iteration 74700 (7.45075 iter/s, 13.4215s/100 iters), loss = 0.00117261
I0925 00:01:12.951313  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00117218 (* 1 = 0.00117218 loss)
I0925 00:01:12.951320  2642 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I0925 00:01:26.374783  2642 solver.cpp:218] Iteration 74800 (7.44965 iter/s, 13.4234s/100 iters), loss = 0.00127544
I0925 00:01:26.374814  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00127501 (* 1 = 0.00127501 loss)
I0925 00:01:26.374819  2642 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I0925 00:01:39.793339  2642 solver.cpp:218] Iteration 74900 (7.4524 iter/s, 13.4185s/100 iters), loss = 0.00397307
I0925 00:01:39.793378  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00397265 (* 1 = 0.00397265 loss)
I0925 00:01:39.793385  2642 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I0925 00:01:52.549926  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:01:53.087458  2642 solver.cpp:330] Iteration 75000, Testing net (#0)
I0925 00:01:56.178921  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:01:56.308055  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9238
I0925 00:01:56.308091  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314127 (* 1 = 0.314127 loss)
I0925 00:01:56.441640  2642 solver.cpp:218] Iteration 75000 (6.00665 iter/s, 16.6482s/100 iters), loss = 0.0018894
I0925 00:01:56.441666  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188898 (* 1 = 0.00188898 loss)
I0925 00:01:56.441673  2642 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I0925 00:02:09.868031  2642 solver.cpp:218] Iteration 75100 (7.44805 iter/s, 13.4263s/100 iters), loss = 0.0083323
I0925 00:02:09.868072  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00833187 (* 1 = 0.00833187 loss)
I0925 00:02:09.868078  2642 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I0925 00:02:23.298781  2642 solver.cpp:218] Iteration 75200 (7.44564 iter/s, 13.4307s/100 iters), loss = 0.00463106
I0925 00:02:23.298920  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00463063 (* 1 = 0.00463063 loss)
I0925 00:02:23.298928  2642 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I0925 00:02:36.726533  2642 solver.cpp:218] Iteration 75300 (7.44735 iter/s, 13.4276s/100 iters), loss = 0.00620038
I0925 00:02:36.726564  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00619994 (* 1 = 0.00619994 loss)
I0925 00:02:36.726570  2642 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I0925 00:02:50.145896  2642 solver.cpp:218] Iteration 75400 (7.45195 iter/s, 13.4193s/100 iters), loss = 0.0010188
I0925 00:02:50.145927  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00101836 (* 1 = 0.00101836 loss)
I0925 00:02:50.145933  2642 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I0925 00:03:02.906836  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:03:03.444072  2642 solver.cpp:330] Iteration 75500, Testing net (#0)
I0925 00:03:06.535445  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:03:06.664440  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I0925 00:03:06.664476  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338698 (* 1 = 0.338698 loss)
I0925 00:03:06.797528  2642 solver.cpp:218] Iteration 75500 (6.00544 iter/s, 16.6516s/100 iters), loss = 0.000956742
I0925 00:03:06.797554  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000956312 (* 1 = 0.000956312 loss)
I0925 00:03:06.797560  2642 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I0925 00:03:20.218319  2642 solver.cpp:218] Iteration 75600 (7.45116 iter/s, 13.4207s/100 iters), loss = 0.00687885
I0925 00:03:20.218360  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00687842 (* 1 = 0.00687842 loss)
I0925 00:03:20.218366  2642 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I0925 00:03:33.644933  2642 solver.cpp:218] Iteration 75700 (7.44793 iter/s, 13.4265s/100 iters), loss = 0.00488585
I0925 00:03:33.645009  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00488543 (* 1 = 0.00488543 loss)
I0925 00:03:33.645016  2642 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I0925 00:03:47.069102  2642 solver.cpp:218] Iteration 75800 (7.44931 iter/s, 13.4241s/100 iters), loss = 0.000880615
I0925 00:03:47.069142  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000880192 (* 1 = 0.000880192 loss)
I0925 00:03:47.069149  2642 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I0925 00:04:00.496837  2642 solver.cpp:218] Iteration 75900 (7.44731 iter/s, 13.4277s/100 iters), loss = 0.000993804
I0925 00:04:00.496867  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000993383 (* 1 = 0.000993383 loss)
I0925 00:04:00.496873  2642 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I0925 00:04:13.254700  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:04:13.792269  2642 solver.cpp:330] Iteration 76000, Testing net (#0)
I0925 00:04:16.884223  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:04:17.012989  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9213
I0925 00:04:17.013025  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329647 (* 1 = 0.329647 loss)
I0925 00:04:17.146111  2642 solver.cpp:218] Iteration 76000 (6.00629 iter/s, 16.6492s/100 iters), loss = 0.00289294
I0925 00:04:17.146137  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00289252 (* 1 = 0.00289252 loss)
I0925 00:04:17.146144  2642 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I0925 00:04:30.563452  2642 solver.cpp:218] Iteration 76100 (7.45307 iter/s, 13.4173s/100 iters), loss = 0.0016632
I0925 00:04:30.563493  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00166277 (* 1 = 0.00166277 loss)
I0925 00:04:30.563498  2642 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I0925 00:04:43.986349  2642 solver.cpp:218] Iteration 76200 (7.45 iter/s, 13.4228s/100 iters), loss = 0.0073004
I0925 00:04:43.986471  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00729998 (* 1 = 0.00729998 loss)
I0925 00:04:43.986479  2642 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I0925 00:04:57.416277  2642 solver.cpp:218] Iteration 76300 (7.44614 iter/s, 13.4298s/100 iters), loss = 0.00840033
I0925 00:04:57.416319  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00839991 (* 1 = 0.00839991 loss)
I0925 00:04:57.416326  2642 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I0925 00:05:10.842582  2642 solver.cpp:218] Iteration 76400 (7.44811 iter/s, 13.4262s/100 iters), loss = 0.00365278
I0925 00:05:10.842623  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00365236 (* 1 = 0.00365236 loss)
I0925 00:05:10.842629  2642 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I0925 00:05:23.599128  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:05:24.136647  2642 solver.cpp:330] Iteration 76500, Testing net (#0)
I0925 00:05:27.230523  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:05:27.359160  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I0925 00:05:27.359186  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32535 (* 1 = 0.32535 loss)
I0925 00:05:27.492743  2642 solver.cpp:218] Iteration 76500 (6.00598 iter/s, 16.6501s/100 iters), loss = 0.00656258
I0925 00:05:27.492770  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00656216 (* 1 = 0.00656216 loss)
I0925 00:05:27.492776  2642 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I0925 00:05:40.912386  2642 solver.cpp:218] Iteration 76600 (7.4518 iter/s, 13.4196s/100 iters), loss = 0.00776463
I0925 00:05:40.912426  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00776421 (* 1 = 0.00776421 loss)
I0925 00:05:40.912432  2642 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I0925 00:05:54.336902  2642 solver.cpp:218] Iteration 76700 (7.4491 iter/s, 13.4244s/100 iters), loss = 0.00209033
I0925 00:05:54.337007  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00208991 (* 1 = 0.00208991 loss)
I0925 00:05:54.337015  2642 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I0925 00:06:07.760087  2642 solver.cpp:218] Iteration 76800 (7.44987 iter/s, 13.423s/100 iters), loss = 0.00193193
I0925 00:06:07.760118  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0019315 (* 1 = 0.0019315 loss)
I0925 00:06:07.760123  2642 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I0925 00:06:21.187934  2642 solver.cpp:218] Iteration 76900 (7.44724 iter/s, 13.4278s/100 iters), loss = 0.00468031
I0925 00:06:21.187966  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00467989 (* 1 = 0.00467989 loss)
I0925 00:06:21.187971  2642 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I0925 00:06:33.947005  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:06:34.484369  2642 solver.cpp:330] Iteration 77000, Testing net (#0)
I0925 00:06:37.575844  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:06:37.704674  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9167
I0925 00:06:37.704710  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.357997 (* 1 = 0.357997 loss)
I0925 00:06:37.838606  2642 solver.cpp:218] Iteration 77000 (6.00579 iter/s, 16.6506s/100 iters), loss = 0.00158487
I0925 00:06:37.838634  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00158445 (* 1 = 0.00158445 loss)
I0925 00:06:37.838640  2642 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I0925 00:06:51.252655  2642 solver.cpp:218] Iteration 77100 (7.4549 iter/s, 13.414s/100 iters), loss = 0.00183981
I0925 00:06:51.252686  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00183939 (* 1 = 0.00183939 loss)
I0925 00:06:51.252691  2642 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I0925 00:07:04.670115  2642 solver.cpp:218] Iteration 77200 (7.45301 iter/s, 13.4174s/100 iters), loss = 0.00683572
I0925 00:07:04.670179  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0068353 (* 1 = 0.0068353 loss)
I0925 00:07:04.670197  2642 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I0925 00:07:18.094313  2642 solver.cpp:218] Iteration 77300 (7.44929 iter/s, 13.4241s/100 iters), loss = 0.00209443
I0925 00:07:18.094344  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00209401 (* 1 = 0.00209401 loss)
I0925 00:07:18.094360  2642 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I0925 00:07:31.509398  2642 solver.cpp:218] Iteration 77400 (7.45433 iter/s, 13.415s/100 iters), loss = 0.000843322
I0925 00:07:31.509430  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000842914 (* 1 = 0.000842914 loss)
I0925 00:07:31.509446  2642 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I0925 00:07:44.257772  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:07:44.794173  2642 solver.cpp:330] Iteration 77500, Testing net (#0)
I0925 00:07:47.886149  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:07:48.015323  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9238
I0925 00:07:48.015357  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333736 (* 1 = 0.333736 loss)
I0925 00:07:48.149063  2642 solver.cpp:218] Iteration 77500 (6.00976 iter/s, 16.6396s/100 iters), loss = 0.00212766
I0925 00:07:48.149091  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00212725 (* 1 = 0.00212725 loss)
I0925 00:07:48.149097  2642 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I0925 00:08:01.567593  2642 solver.cpp:218] Iteration 77600 (7.45241 iter/s, 13.4185s/100 iters), loss = 0.00435708
I0925 00:08:01.567634  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00435667 (* 1 = 0.00435667 loss)
I0925 00:08:01.567641  2642 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I0925 00:08:14.986515  2642 solver.cpp:218] Iteration 77700 (7.4522 iter/s, 13.4188s/100 iters), loss = 0.00336345
I0925 00:08:14.986629  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00336304 (* 1 = 0.00336304 loss)
I0925 00:08:14.986636  2642 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I0925 00:08:28.406646  2642 solver.cpp:218] Iteration 77800 (7.45157 iter/s, 13.42s/100 iters), loss = 0.000925398
I0925 00:08:28.406687  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000924986 (* 1 = 0.000924986 loss)
I0925 00:08:28.406692  2642 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I0925 00:08:41.828969  2642 solver.cpp:218] Iteration 77900 (7.45032 iter/s, 13.4222s/100 iters), loss = 0.00102412
I0925 00:08:41.829001  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010237 (* 1 = 0.0010237 loss)
I0925 00:08:41.829008  2642 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I0925 00:08:54.584604  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:08:55.121508  2642 solver.cpp:330] Iteration 78000, Testing net (#0)
I0925 00:08:58.213299  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:08:58.342296  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9218
I0925 00:08:58.342334  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327844 (* 1 = 0.327844 loss)
I0925 00:08:58.475967  2642 solver.cpp:218] Iteration 78000 (6.00711 iter/s, 16.6469s/100 iters), loss = 0.0127639
I0925 00:08:58.475993  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127635 (* 1 = 0.0127635 loss)
I0925 00:08:58.475999  2642 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I0925 00:09:11.901486  2642 solver.cpp:218] Iteration 78100 (7.44853 iter/s, 13.4255s/100 iters), loss = 0.0113541
I0925 00:09:11.901527  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113537 (* 1 = 0.0113537 loss)
I0925 00:09:11.901533  2642 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I0925 00:09:25.322571  2642 solver.cpp:218] Iteration 78200 (7.451 iter/s, 13.421s/100 iters), loss = 0.00680914
I0925 00:09:25.322644  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00680872 (* 1 = 0.00680872 loss)
I0925 00:09:25.322651  2642 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I0925 00:09:38.743531  2642 solver.cpp:218] Iteration 78300 (7.45109 iter/s, 13.4209s/100 iters), loss = 0.00900475
I0925 00:09:38.743562  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00900433 (* 1 = 0.00900433 loss)
I0925 00:09:38.743568  2642 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I0925 00:09:52.167804  2642 solver.cpp:218] Iteration 78400 (7.44923 iter/s, 13.4242s/100 iters), loss = 0.00346015
I0925 00:09:52.167834  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00345973 (* 1 = 0.00345973 loss)
I0925 00:09:52.167840  2642 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I0925 00:10:04.927364  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:10:05.464078  2642 solver.cpp:330] Iteration 78500, Testing net (#0)
I0925 00:10:08.557355  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:10:08.686259  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9226
I0925 00:10:08.686295  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325851 (* 1 = 0.325851 loss)
I0925 00:10:08.819114  2642 solver.cpp:218] Iteration 78500 (6.00556 iter/s, 16.6512s/100 iters), loss = 0.0164915
I0925 00:10:08.819141  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0164911 (* 1 = 0.0164911 loss)
I0925 00:10:08.819147  2642 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I0925 00:10:22.240803  2642 solver.cpp:218] Iteration 78600 (7.45066 iter/s, 13.4216s/100 iters), loss = 0.00115286
I0925 00:10:22.240844  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00115244 (* 1 = 0.00115244 loss)
I0925 00:10:22.240850  2642 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I0925 00:10:35.663300  2642 solver.cpp:218] Iteration 78700 (7.45022 iter/s, 13.4224s/100 iters), loss = 0.000720771
I0925 00:10:35.663388  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000720355 (* 1 = 0.000720355 loss)
I0925 00:10:35.663405  2642 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I0925 00:10:49.080646  2642 solver.cpp:218] Iteration 78800 (7.4531 iter/s, 13.4172s/100 iters), loss = 0.000894038
I0925 00:10:49.080685  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000893621 (* 1 = 0.000893621 loss)
I0925 00:10:49.080691  2642 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I0925 00:11:02.501912  2642 solver.cpp:218] Iteration 78900 (7.4509 iter/s, 13.4212s/100 iters), loss = 0.00915354
I0925 00:11:02.501952  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00915312 (* 1 = 0.00915312 loss)
I0925 00:11:02.501960  2642 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I0925 00:11:15.255656  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:11:15.792124  2642 solver.cpp:330] Iteration 79000, Testing net (#0)
I0925 00:11:18.883559  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:11:19.012709  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9233
I0925 00:11:19.012734  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325457 (* 1 = 0.325457 loss)
I0925 00:11:19.145992  2642 solver.cpp:218] Iteration 79000 (6.00817 iter/s, 16.644s/100 iters), loss = 0.00169781
I0925 00:11:19.146020  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00169739 (* 1 = 0.00169739 loss)
I0925 00:11:19.146026  2642 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I0925 00:11:32.571450  2642 solver.cpp:218] Iteration 79100 (7.44857 iter/s, 13.4254s/100 iters), loss = 0.0124484
I0925 00:11:32.571491  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012448 (* 1 = 0.012448 loss)
I0925 00:11:32.571496  2642 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I0925 00:11:46.002643  2642 solver.cpp:218] Iteration 79200 (7.44539 iter/s, 13.4311s/100 iters), loss = 0.00914507
I0925 00:11:46.002718  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00914465 (* 1 = 0.00914465 loss)
I0925 00:11:46.002725  2642 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I0925 00:11:59.433375  2642 solver.cpp:218] Iteration 79300 (7.44567 iter/s, 13.4306s/100 iters), loss = 0.00105076
I0925 00:11:59.433416  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00105034 (* 1 = 0.00105034 loss)
I0925 00:11:59.433423  2642 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I0925 00:12:12.861368  2642 solver.cpp:218] Iteration 79400 (7.44717 iter/s, 13.4279s/100 iters), loss = 0.00446807
I0925 00:12:12.861407  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00446765 (* 1 = 0.00446765 loss)
I0925 00:12:12.861413  2642 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I0925 00:12:25.623932  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:12:26.163447  2642 solver.cpp:330] Iteration 79500, Testing net (#0)
I0925 00:12:29.256305  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:12:29.384829  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9213
I0925 00:12:29.384865  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.330227 (* 1 = 0.330227 loss)
I0925 00:12:29.518317  2642 solver.cpp:218] Iteration 79500 (6.00353 iter/s, 16.6569s/100 iters), loss = 0.00082324
I0925 00:12:29.518343  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000822813 (* 1 = 0.000822813 loss)
I0925 00:12:29.518350  2642 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I0925 00:12:42.941319  2642 solver.cpp:218] Iteration 79600 (7.44993 iter/s, 13.4229s/100 iters), loss = 0.00296349
I0925 00:12:42.941359  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00296306 (* 1 = 0.00296306 loss)
I0925 00:12:42.941365  2642 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I0925 00:12:56.372952  2642 solver.cpp:218] Iteration 79700 (7.44515 iter/s, 13.4316s/100 iters), loss = 0.00290926
I0925 00:12:56.373029  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00290883 (* 1 = 0.00290883 loss)
I0925 00:12:56.373046  2642 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I0925 00:13:09.793784  2642 solver.cpp:218] Iteration 79800 (7.45116 iter/s, 13.4207s/100 iters), loss = 0.00123537
I0925 00:13:09.793825  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00123495 (* 1 = 0.00123495 loss)
I0925 00:13:09.793831  2642 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I0925 00:13:23.221002  2642 solver.cpp:218] Iteration 79900 (7.4476 iter/s, 13.4271s/100 iters), loss = 0.00894677
I0925 00:13:23.221034  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00894635 (* 1 = 0.00894635 loss)
I0925 00:13:23.221040  2642 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I0925 00:13:35.983537  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:13:36.521076  2642 solver.cpp:330] Iteration 80000, Testing net (#0)
I0925 00:13:39.612035  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:13:39.740842  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I0925 00:13:39.740880  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.317932 (* 1 = 0.317932 loss)
I0925 00:13:39.874434  2642 solver.cpp:218] Iteration 80000 (6.00479 iter/s, 16.6534s/100 iters), loss = 0.010933
I0925 00:13:39.874462  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109326 (* 1 = 0.0109326 loss)
I0925 00:13:39.874469  2642 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I0925 00:13:39.874472  2642 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I0925 00:13:53.301447  2642 solver.cpp:218] Iteration 80100 (7.44771 iter/s, 13.4269s/100 iters), loss = 0.0042138
I0925 00:13:53.301479  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00421338 (* 1 = 0.00421338 loss)
I0925 00:13:53.301486  2642 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I0925 00:14:06.730203  2642 solver.cpp:218] Iteration 80200 (7.44674 iter/s, 13.4287s/100 iters), loss = 0.00950113
I0925 00:14:06.730336  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00950071 (* 1 = 0.00950071 loss)
I0925 00:14:06.730345  2642 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I0925 00:14:20.160498  2642 solver.cpp:218] Iteration 80300 (7.44594 iter/s, 13.4301s/100 iters), loss = 0.000637172
I0925 00:14:20.160528  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000636751 (* 1 = 0.000636751 loss)
I0925 00:14:20.160534  2642 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I0925 00:14:33.586263  2642 solver.cpp:218] Iteration 80400 (7.4484 iter/s, 13.4257s/100 iters), loss = 0.00258626
I0925 00:14:33.586305  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00258584 (* 1 = 0.00258584 loss)
I0925 00:14:33.586311  2642 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I0925 00:14:46.349854  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:14:46.886456  2642 solver.cpp:330] Iteration 80500, Testing net (#0)
I0925 00:14:49.978047  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:14:50.107059  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9266
I0925 00:14:50.107084  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304436 (* 1 = 0.304436 loss)
I0925 00:14:50.239917  2642 solver.cpp:218] Iteration 80500 (6.00472 iter/s, 16.6536s/100 iters), loss = 0.00156317
I0925 00:14:50.239943  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00156275 (* 1 = 0.00156275 loss)
I0925 00:14:50.239950  2642 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I0925 00:15:03.671973  2642 solver.cpp:218] Iteration 80600 (7.44491 iter/s, 13.432s/100 iters), loss = 0.000478085
I0925 00:15:03.672015  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000477665 (* 1 = 0.000477665 loss)
I0925 00:15:03.672021  2642 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I0925 00:15:17.100059  2642 solver.cpp:218] Iteration 80700 (7.44712 iter/s, 13.428s/100 iters), loss = 0.00568439
I0925 00:15:17.100190  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00568397 (* 1 = 0.00568397 loss)
I0925 00:15:17.100198  2642 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I0925 00:15:30.534876  2642 solver.cpp:218] Iteration 80800 (7.44343 iter/s, 13.4347s/100 iters), loss = 0.000656939
I0925 00:15:30.534917  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000656517 (* 1 = 0.000656517 loss)
I0925 00:15:30.534922  2642 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I0925 00:15:43.967562  2642 solver.cpp:218] Iteration 80900 (7.44457 iter/s, 13.4326s/100 iters), loss = 0.00114827
I0925 00:15:43.967604  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00114784 (* 1 = 0.00114784 loss)
I0925 00:15:43.967610  2642 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I0925 00:15:56.732328  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:15:57.270450  2642 solver.cpp:330] Iteration 81000, Testing net (#0)
I0925 00:16:00.361642  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:16:00.490787  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9284
I0925 00:16:00.490810  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.299945 (* 1 = 0.299945 loss)
I0925 00:16:00.624263  2642 solver.cpp:218] Iteration 81000 (6.00362 iter/s, 16.6566s/100 iters), loss = 0.000654818
I0925 00:16:00.624289  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000654396 (* 1 = 0.000654396 loss)
I0925 00:16:00.624296  2642 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I0925 00:16:14.044493  2642 solver.cpp:218] Iteration 81100 (7.45147 iter/s, 13.4202s/100 iters), loss = 0.00127046
I0925 00:16:14.044533  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00127004 (* 1 = 0.00127004 loss)
I0925 00:16:14.044539  2642 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I0925 00:16:27.463692  2642 solver.cpp:218] Iteration 81200 (7.45205 iter/s, 13.4191s/100 iters), loss = 0.00214226
I0925 00:16:27.463773  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00214184 (* 1 = 0.00214184 loss)
I0925 00:16:27.463788  2642 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I0925 00:16:40.887042  2642 solver.cpp:218] Iteration 81300 (7.44977 iter/s, 13.4232s/100 iters), loss = 0.00188208
I0925 00:16:40.887082  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188166 (* 1 = 0.00188166 loss)
I0925 00:16:40.887089  2642 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I0925 00:16:54.313652  2642 solver.cpp:218] Iteration 81400 (7.44794 iter/s, 13.4265s/100 iters), loss = 0.00335093
I0925 00:16:54.313691  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00335051 (* 1 = 0.00335051 loss)
I0925 00:16:54.313697  2642 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I0925 00:17:07.064615  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:17:07.601408  2642 solver.cpp:330] Iteration 81500, Testing net (#0)
I0925 00:17:10.693409  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:17:10.822671  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9285
I0925 00:17:10.822698  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.299884 (* 1 = 0.299884 loss)
I0925 00:17:10.956730  2642 solver.cpp:218] Iteration 81500 (6.00853 iter/s, 16.643s/100 iters), loss = 0.0017505
I0925 00:17:10.956758  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00175008 (* 1 = 0.00175008 loss)
I0925 00:17:10.956765  2642 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I0925 00:17:24.385736  2642 solver.cpp:218] Iteration 81600 (7.4466 iter/s, 13.4289s/100 iters), loss = 0.000930459
I0925 00:17:24.385777  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000930042 (* 1 = 0.000930042 loss)
I0925 00:17:24.385784  2642 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I0925 00:17:37.815877  2642 solver.cpp:218] Iteration 81700 (7.44598 iter/s, 13.4301s/100 iters), loss = 0.00130038
I0925 00:17:37.815968  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00129997 (* 1 = 0.00129997 loss)
I0925 00:17:37.815984  2642 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I0925 00:17:51.243263  2642 solver.cpp:218] Iteration 81800 (7.44753 iter/s, 13.4273s/100 iters), loss = 0.00226096
I0925 00:17:51.243294  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00226055 (* 1 = 0.00226055 loss)
I0925 00:17:51.243299  2642 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I0925 00:18:04.670817  2642 solver.cpp:218] Iteration 81900 (7.44741 iter/s, 13.4275s/100 iters), loss = 0.00202247
I0925 00:18:04.670846  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00202205 (* 1 = 0.00202205 loss)
I0925 00:18:04.670851  2642 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I0925 00:18:17.432587  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:18:17.968968  2642 solver.cpp:330] Iteration 82000, Testing net (#0)
I0925 00:18:21.061249  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:18:21.190299  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9284
I0925 00:18:21.190335  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.298599 (* 1 = 0.298599 loss)
I0925 00:18:21.323314  2642 solver.cpp:218] Iteration 82000 (6.00513 iter/s, 16.6524s/100 iters), loss = 0.000601087
I0925 00:18:21.323340  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000600674 (* 1 = 0.000600674 loss)
I0925 00:18:21.323348  2642 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I0925 00:18:34.749205  2642 solver.cpp:218] Iteration 82100 (7.44833 iter/s, 13.4258s/100 iters), loss = 0.00512616
I0925 00:18:34.749248  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00512575 (* 1 = 0.00512575 loss)
I0925 00:18:34.749253  2642 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I0925 00:18:48.180161  2642 solver.cpp:218] Iteration 82200 (7.44553 iter/s, 13.4309s/100 iters), loss = 0.00101718
I0925 00:18:48.180238  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00101677 (* 1 = 0.00101677 loss)
I0925 00:18:48.180244  2642 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I0925 00:19:01.609663  2642 solver.cpp:218] Iteration 82300 (7.44635 iter/s, 13.4294s/100 iters), loss = 0.00143278
I0925 00:19:01.609705  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00143236 (* 1 = 0.00143236 loss)
I0925 00:19:01.609711  2642 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I0925 00:19:15.039438  2642 solver.cpp:218] Iteration 82400 (7.44618 iter/s, 13.4297s/100 iters), loss = 0.00109251
I0925 00:19:15.039479  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00109209 (* 1 = 0.00109209 loss)
I0925 00:19:15.039485  2642 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I0925 00:19:27.800575  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:19:28.338099  2642 solver.cpp:330] Iteration 82500, Testing net (#0)
I0925 00:19:31.430027  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:19:31.559000  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9289
I0925 00:19:31.559036  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296702 (* 1 = 0.296702 loss)
I0925 00:19:31.692824  2642 solver.cpp:218] Iteration 82500 (6.00481 iter/s, 16.6533s/100 iters), loss = 0.00109373
I0925 00:19:31.692852  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00109332 (* 1 = 0.00109332 loss)
I0925 00:19:31.692858  2642 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I0925 00:19:45.116886  2642 solver.cpp:218] Iteration 82600 (7.44934 iter/s, 13.424s/100 iters), loss = 0.00483231
I0925 00:19:45.116919  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0048319 (* 1 = 0.0048319 loss)
I0925 00:19:45.116925  2642 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I0925 00:19:58.535986  2642 solver.cpp:218] Iteration 82700 (7.4521 iter/s, 13.419s/100 iters), loss = 0.00321229
I0925 00:19:58.536068  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00321187 (* 1 = 0.00321187 loss)
I0925 00:19:58.536075  2642 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I0925 00:20:11.965198  2642 solver.cpp:218] Iteration 82800 (7.44652 iter/s, 13.4291s/100 iters), loss = 0.00146419
I0925 00:20:11.965240  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00146378 (* 1 = 0.00146378 loss)
I0925 00:20:11.965246  2642 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I0925 00:20:25.396016  2642 solver.cpp:218] Iteration 82900 (7.4456 iter/s, 13.4307s/100 iters), loss = 0.00145978
I0925 00:20:25.396056  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00145937 (* 1 = 0.00145937 loss)
I0925 00:20:25.396061  2642 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I0925 00:20:38.157143  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:20:38.695013  2642 solver.cpp:330] Iteration 83000, Testing net (#0)
I0925 00:20:41.786576  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:20:41.915400  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9297
I0925 00:20:41.915436  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.29659 (* 1 = 0.29659 loss)
I0925 00:20:42.049013  2642 solver.cpp:218] Iteration 83000 (6.00495 iter/s, 16.6529s/100 iters), loss = 0.000386109
I0925 00:20:42.049038  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000385697 (* 1 = 0.000385697 loss)
I0925 00:20:42.049046  2642 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I0925 00:20:55.467666  2642 solver.cpp:218] Iteration 83100 (7.45235 iter/s, 13.4186s/100 iters), loss = 0.000565697
I0925 00:20:55.467707  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000565285 (* 1 = 0.000565285 loss)
I0925 00:20:55.467712  2642 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I0925 00:21:08.894470  2642 solver.cpp:218] Iteration 83200 (7.44783 iter/s, 13.4267s/100 iters), loss = 0.00699601
I0925 00:21:08.894588  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0069956 (* 1 = 0.0069956 loss)
I0925 00:21:08.894598  2642 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I0925 00:21:22.318086  2642 solver.cpp:218] Iteration 83300 (7.44964 iter/s, 13.4235s/100 iters), loss = 0.00355773
I0925 00:21:22.318117  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00355732 (* 1 = 0.00355732 loss)
I0925 00:21:22.318123  2642 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I0925 00:21:35.746446  2642 solver.cpp:218] Iteration 83400 (7.44696 iter/s, 13.4283s/100 iters), loss = 0.00135802
I0925 00:21:35.746487  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00135761 (* 1 = 0.00135761 loss)
I0925 00:21:35.746493  2642 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I0925 00:21:48.499634  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:21:49.038374  2642 solver.cpp:330] Iteration 83500, Testing net (#0)
I0925 00:21:52.130437  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:21:52.259374  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9302
I0925 00:21:52.259410  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296696 (* 1 = 0.296696 loss)
I0925 00:21:52.393054  2642 solver.cpp:218] Iteration 83500 (6.00726 iter/s, 16.6465s/100 iters), loss = 0.00022054
I0925 00:21:52.393081  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000220129 (* 1 = 0.000220129 loss)
I0925 00:21:52.393087  2642 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I0925 00:22:05.819650  2642 solver.cpp:218] Iteration 83600 (7.44794 iter/s, 13.4265s/100 iters), loss = 0.00499063
I0925 00:22:05.819690  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00499021 (* 1 = 0.00499021 loss)
I0925 00:22:05.819696  2642 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I0925 00:22:19.247567  2642 solver.cpp:218] Iteration 83700 (7.44721 iter/s, 13.4278s/100 iters), loss = 0.000662742
I0925 00:22:19.247707  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000662331 (* 1 = 0.000662331 loss)
I0925 00:22:19.247714  2642 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I0925 00:22:32.682920  2642 solver.cpp:218] Iteration 83800 (7.44314 iter/s, 13.4352s/100 iters), loss = 0.00226029
I0925 00:22:32.682961  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00225988 (* 1 = 0.00225988 loss)
I0925 00:22:32.682967  2642 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I0925 00:22:46.110247  2642 solver.cpp:218] Iteration 83900 (7.44754 iter/s, 13.4273s/100 iters), loss = 0.00188349
I0925 00:22:46.110290  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188308 (* 1 = 0.00188308 loss)
I0925 00:22:46.110296  2642 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I0925 00:22:58.873677  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:22:59.411023  2642 solver.cpp:330] Iteration 84000, Testing net (#0)
I0925 00:23:02.503423  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:23:02.632053  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9299
I0925 00:23:02.632089  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296149 (* 1 = 0.296149 loss)
I0925 00:23:02.764955  2642 solver.cpp:218] Iteration 84000 (6.00434 iter/s, 16.6546s/100 iters), loss = 0.000460209
I0925 00:23:02.764979  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0004598 (* 1 = 0.0004598 loss)
I0925 00:23:02.764986  2642 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I0925 00:23:16.177228  2642 solver.cpp:218] Iteration 84100 (7.45589 iter/s, 13.4122s/100 iters), loss = 0.00285819
I0925 00:23:16.177268  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00285778 (* 1 = 0.00285778 loss)
I0925 00:23:16.177274  2642 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I0925 00:23:29.593544  2642 solver.cpp:218] Iteration 84200 (7.45365 iter/s, 13.4162s/100 iters), loss = 0.00142819
I0925 00:23:29.593617  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00142778 (* 1 = 0.00142778 loss)
I0925 00:23:29.593623  2642 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I0925 00:23:43.015641  2642 solver.cpp:218] Iteration 84300 (7.45046 iter/s, 13.422s/100 iters), loss = 0.00341531
I0925 00:23:43.015681  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0034149 (* 1 = 0.0034149 loss)
I0925 00:23:43.015687  2642 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I0925 00:23:56.431700  2642 solver.cpp:218] Iteration 84400 (7.45379 iter/s, 13.416s/100 iters), loss = 0.00178411
I0925 00:23:56.431732  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0017837 (* 1 = 0.0017837 loss)
I0925 00:23:56.431748  2642 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I0925 00:24:09.187674  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:24:09.725983  2642 solver.cpp:330] Iteration 84500, Testing net (#0)
I0925 00:24:12.817739  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:24:12.946605  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9294
I0925 00:24:12.946640  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295763 (* 1 = 0.295763 loss)
I0925 00:24:13.079957  2642 solver.cpp:218] Iteration 84500 (6.00666 iter/s, 16.6482s/100 iters), loss = 0.000530332
I0925 00:24:13.079982  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000529917 (* 1 = 0.000529917 loss)
I0925 00:24:13.079989  2642 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I0925 00:24:26.500867  2642 solver.cpp:218] Iteration 84600 (7.45109 iter/s, 13.4208s/100 iters), loss = 0.00367822
I0925 00:24:26.500908  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00367781 (* 1 = 0.00367781 loss)
I0925 00:24:26.500915  2642 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I0925 00:24:39.925004  2642 solver.cpp:218] Iteration 84700 (7.44931 iter/s, 13.4241s/100 iters), loss = 0.000582641
I0925 00:24:39.925065  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000582225 (* 1 = 0.000582225 loss)
I0925 00:24:39.925071  2642 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I0925 00:24:53.348042  2642 solver.cpp:218] Iteration 84800 (7.44993 iter/s, 13.4229s/100 iters), loss = 0.00108683
I0925 00:24:53.348081  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108642 (* 1 = 0.00108642 loss)
I0925 00:24:53.348088  2642 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I0925 00:25:06.775743  2642 solver.cpp:218] Iteration 84900 (7.44733 iter/s, 13.4276s/100 iters), loss = 0.00077764
I0925 00:25:06.775784  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000777225 (* 1 = 0.000777225 loss)
I0925 00:25:06.775790  2642 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I0925 00:25:19.530329  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:25:20.068300  2642 solver.cpp:330] Iteration 85000, Testing net (#0)
I0925 00:25:23.160526  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:25:23.289743  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9302
I0925 00:25:23.289779  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296267 (* 1 = 0.296267 loss)
I0925 00:25:23.423391  2642 solver.cpp:218] Iteration 85000 (6.00688 iter/s, 16.6476s/100 iters), loss = 0.000552887
I0925 00:25:23.423418  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000552469 (* 1 = 0.000552469 loss)
I0925 00:25:23.423425  2642 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I0925 00:25:36.850554  2642 solver.cpp:218] Iteration 85100 (7.44762 iter/s, 13.4271s/100 iters), loss = 0.00372642
I0925 00:25:36.850595  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.003726 (* 1 = 0.003726 loss)
I0925 00:25:36.850601  2642 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I0925 00:25:50.274504  2642 solver.cpp:218] Iteration 85200 (7.44941 iter/s, 13.4239s/100 iters), loss = 0.00117015
I0925 00:25:50.274624  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00116973 (* 1 = 0.00116973 loss)
I0925 00:25:50.274641  2642 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I0925 00:26:03.701232  2642 solver.cpp:218] Iteration 85300 (7.44791 iter/s, 13.4266s/100 iters), loss = 0.00153125
I0925 00:26:03.701273  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153083 (* 1 = 0.00153083 loss)
I0925 00:26:03.701279  2642 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I0925 00:26:17.125547  2642 solver.cpp:218] Iteration 85400 (7.44921 iter/s, 13.4242s/100 iters), loss = 0.000633982
I0925 00:26:17.125587  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000633566 (* 1 = 0.000633566 loss)
I0925 00:26:17.125593  2642 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I0925 00:26:29.884503  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:26:30.421757  2642 solver.cpp:330] Iteration 85500, Testing net (#0)
I0925 00:26:33.514983  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:26:33.643560  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9309
I0925 00:26:33.643586  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.294809 (* 1 = 0.294809 loss)
I0925 00:26:33.776818  2642 solver.cpp:218] Iteration 85500 (6.00558 iter/s, 16.6512s/100 iters), loss = 0.0013977
I0925 00:26:33.776845  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00139728 (* 1 = 0.00139728 loss)
I0925 00:26:33.776852  2642 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I0925 00:26:47.200098  2642 solver.cpp:218] Iteration 85600 (7.44978 iter/s, 13.4232s/100 iters), loss = 0.0168619
I0925 00:26:47.200129  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0168614 (* 1 = 0.0168614 loss)
I0925 00:26:47.200135  2642 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I0925 00:27:00.626097  2642 solver.cpp:218] Iteration 85700 (7.44827 iter/s, 13.4259s/100 iters), loss = 0.000456524
I0925 00:27:00.626221  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000456108 (* 1 = 0.000456108 loss)
I0925 00:27:00.626238  2642 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I0925 00:27:14.052276  2642 solver.cpp:218] Iteration 85800 (7.44822 iter/s, 13.426s/100 iters), loss = 0.000656312
I0925 00:27:14.052316  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000655896 (* 1 = 0.000655896 loss)
I0925 00:27:14.052322  2642 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I0925 00:27:27.482214  2642 solver.cpp:218] Iteration 85900 (7.44609 iter/s, 13.4299s/100 iters), loss = 0.00301586
I0925 00:27:27.482255  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00301544 (* 1 = 0.00301544 loss)
I0925 00:27:27.482261  2642 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I0925 00:27:40.235569  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:27:40.771353  2642 solver.cpp:330] Iteration 86000, Testing net (#0)
I0925 00:27:43.863337  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:27:43.991968  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9304
I0925 00:27:43.992004  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295115 (* 1 = 0.295115 loss)
I0925 00:27:44.125398  2642 solver.cpp:218] Iteration 86000 (6.00849 iter/s, 16.6431s/100 iters), loss = 0.000752723
I0925 00:27:44.125427  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000752305 (* 1 = 0.000752305 loss)
I0925 00:27:44.125432  2642 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I0925 00:27:57.545480  2642 solver.cpp:218] Iteration 86100 (7.45155 iter/s, 13.42s/100 iters), loss = 0.00303544
I0925 00:27:57.545519  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00303503 (* 1 = 0.00303503 loss)
I0925 00:27:57.545526  2642 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I0925 00:28:10.969177  2642 solver.cpp:218] Iteration 86200 (7.44955 iter/s, 13.4236s/100 iters), loss = 0.00192102
I0925 00:28:10.969316  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00192061 (* 1 = 0.00192061 loss)
I0925 00:28:10.969322  2642 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I0925 00:28:24.388634  2642 solver.cpp:218] Iteration 86300 (7.45195 iter/s, 13.4193s/100 iters), loss = 0.000412956
I0925 00:28:24.388676  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000412539 (* 1 = 0.000412539 loss)
I0925 00:28:24.388682  2642 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I0925 00:28:37.811290  2642 solver.cpp:218] Iteration 86400 (7.45013 iter/s, 13.4226s/100 iters), loss = 0.00183915
I0925 00:28:37.811331  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00183874 (* 1 = 0.00183874 loss)
I0925 00:28:37.811336  2642 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I0925 00:28:50.569847  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:28:51.107040  2642 solver.cpp:330] Iteration 86500, Testing net (#0)
I0925 00:28:54.199476  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:28:54.328217  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9303
I0925 00:28:54.328253  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295512 (* 1 = 0.295512 loss)
I0925 00:28:54.461038  2642 solver.cpp:218] Iteration 86500 (6.00612 iter/s, 16.6497s/100 iters), loss = 0.000951797
I0925 00:28:54.461066  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000951383 (* 1 = 0.000951383 loss)
I0925 00:28:54.461071  2642 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I0925 00:29:07.871789  2642 solver.cpp:218] Iteration 86600 (7.45674 iter/s, 13.4107s/100 iters), loss = 0.00371579
I0925 00:29:07.871830  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00371538 (* 1 = 0.00371538 loss)
I0925 00:29:07.871836  2642 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I0925 00:29:21.295138  2642 solver.cpp:218] Iteration 86700 (7.44975 iter/s, 13.4233s/100 iters), loss = 0.00189799
I0925 00:29:21.295279  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00189757 (* 1 = 0.00189757 loss)
I0925 00:29:21.295286  2642 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I0925 00:29:34.716539  2642 solver.cpp:218] Iteration 86800 (7.45088 iter/s, 13.4212s/100 iters), loss = 0.00477412
I0925 00:29:34.716583  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0047737 (* 1 = 0.0047737 loss)
I0925 00:29:34.716588  2642 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I0925 00:29:48.140678  2642 solver.cpp:218] Iteration 86900 (7.44931 iter/s, 13.4241s/100 iters), loss = 0.0014584
I0925 00:29:48.140719  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00145798 (* 1 = 0.00145798 loss)
I0925 00:29:48.140724  2642 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I0925 00:30:00.904448  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:30:01.441591  2642 solver.cpp:330] Iteration 87000, Testing net (#0)
I0925 00:30:04.534495  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:30:04.663259  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9296
I0925 00:30:04.663295  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295637 (* 1 = 0.295637 loss)
I0925 00:30:04.797447  2642 solver.cpp:218] Iteration 87000 (6.00359 iter/s, 16.6567s/100 iters), loss = 0.000768558
I0925 00:30:04.797474  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000768143 (* 1 = 0.000768143 loss)
I0925 00:30:04.797482  2642 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I0925 00:30:18.219224  2642 solver.cpp:218] Iteration 87100 (7.45061 iter/s, 13.4217s/100 iters), loss = 0.00605457
I0925 00:30:18.219255  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00605415 (* 1 = 0.00605415 loss)
I0925 00:30:18.219261  2642 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I0925 00:30:31.651051  2642 solver.cpp:218] Iteration 87200 (7.44504 iter/s, 13.4318s/100 iters), loss = 0.000854414
I0925 00:30:31.651127  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000854001 (* 1 = 0.000854001 loss)
I0925 00:30:31.651134  2642 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I0925 00:30:45.080914  2642 solver.cpp:218] Iteration 87300 (7.44615 iter/s, 13.4298s/100 iters), loss = 0.00132692
I0925 00:30:45.080956  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00132651 (* 1 = 0.00132651 loss)
I0925 00:30:45.080962  2642 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I0925 00:30:58.506677  2642 solver.cpp:218] Iteration 87400 (7.44841 iter/s, 13.4257s/100 iters), loss = 0.0031082
I0925 00:30:58.506718  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00310778 (* 1 = 0.00310778 loss)
I0925 00:30:58.506724  2642 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I0925 00:31:11.269570  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:31:11.808220  2642 solver.cpp:330] Iteration 87500, Testing net (#0)
I0925 00:31:14.900944  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:31:15.029603  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9294
I0925 00:31:15.029639  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296072 (* 1 = 0.296072 loss)
I0925 00:31:15.163535  2642 solver.cpp:218] Iteration 87500 (6.00356 iter/s, 16.6568s/100 iters), loss = 0.000938819
I0925 00:31:15.163563  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000938406 (* 1 = 0.000938406 loss)
I0925 00:31:15.163569  2642 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I0925 00:31:28.579684  2642 solver.cpp:218] Iteration 87600 (7.45374 iter/s, 13.4161s/100 iters), loss = 0.000943596
I0925 00:31:28.579725  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000943183 (* 1 = 0.000943183 loss)
I0925 00:31:28.579732  2642 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I0925 00:31:42.001410  2642 solver.cpp:218] Iteration 87700 (7.45065 iter/s, 13.4217s/100 iters), loss = 0.00416415
I0925 00:31:42.001471  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00416374 (* 1 = 0.00416374 loss)
I0925 00:31:42.001478  2642 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I0925 00:31:55.426265  2642 solver.cpp:218] Iteration 87800 (7.44892 iter/s, 13.4248s/100 iters), loss = 0.00103652
I0925 00:31:55.426296  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010361 (* 1 = 0.0010361 loss)
I0925 00:31:55.426302  2642 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I0925 00:32:08.847860  2642 solver.cpp:218] Iteration 87900 (7.45071 iter/s, 13.4215s/100 iters), loss = 0.001714
I0925 00:32:08.847901  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00171359 (* 1 = 0.00171359 loss)
I0925 00:32:08.847908  2642 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I0925 00:32:21.603595  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:32:22.141574  2642 solver.cpp:330] Iteration 88000, Testing net (#0)
I0925 00:32:25.233021  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:32:25.361661  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9303
I0925 00:32:25.361697  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296216 (* 1 = 0.296216 loss)
I0925 00:32:25.495482  2642 solver.cpp:218] Iteration 88000 (6.00689 iter/s, 16.6475s/100 iters), loss = 0.000748852
I0925 00:32:25.495509  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00074844 (* 1 = 0.00074844 loss)
I0925 00:32:25.495515  2642 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I0925 00:32:38.918117  2642 solver.cpp:218] Iteration 88100 (7.45014 iter/s, 13.4226s/100 iters), loss = 0.00179345
I0925 00:32:38.918157  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00179304 (* 1 = 0.00179304 loss)
I0925 00:32:38.918164  2642 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I0925 00:32:52.341584  2642 solver.cpp:218] Iteration 88200 (7.44968 iter/s, 13.4234s/100 iters), loss = 0.00138699
I0925 00:32:52.341670  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00138658 (* 1 = 0.00138658 loss)
I0925 00:32:52.341675  2642 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I0925 00:33:05.765885  2642 solver.cpp:218] Iteration 88300 (7.44924 iter/s, 13.4242s/100 iters), loss = 0.0006637
I0925 00:33:05.765913  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000663286 (* 1 = 0.000663286 loss)
I0925 00:33:05.765919  2642 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I0925 00:33:19.188557  2642 solver.cpp:218] Iteration 88400 (7.45011 iter/s, 13.4226s/100 iters), loss = 0.00164889
I0925 00:33:19.188598  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00164848 (* 1 = 0.00164848 loss)
I0925 00:33:19.188603  2642 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I0925 00:33:31.945298  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:33:32.483180  2642 solver.cpp:330] Iteration 88500, Testing net (#0)
I0925 00:33:35.574843  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:33:35.704229  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9296
I0925 00:33:35.704265  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296245 (* 1 = 0.296245 loss)
I0925 00:33:35.837291  2642 solver.cpp:218] Iteration 88500 (6.00649 iter/s, 16.6487s/100 iters), loss = 0.00155908
I0925 00:33:35.837318  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00155867 (* 1 = 0.00155867 loss)
I0925 00:33:35.837326  2642 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I0925 00:33:49.259341  2642 solver.cpp:218] Iteration 88600 (7.45046 iter/s, 13.422s/100 iters), loss = 0.000830464
I0925 00:33:49.259371  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00083005 (* 1 = 0.00083005 loss)
I0925 00:33:49.259377  2642 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I0925 00:34:02.685739  2642 solver.cpp:218] Iteration 88700 (7.44805 iter/s, 13.4263s/100 iters), loss = 0.00252498
I0925 00:34:02.685804  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00252457 (* 1 = 0.00252457 loss)
I0925 00:34:02.685811  2642 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I0925 00:34:16.113339  2642 solver.cpp:218] Iteration 88800 (7.4474 iter/s, 13.4275s/100 iters), loss = 0.000592438
I0925 00:34:16.113380  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000592026 (* 1 = 0.000592026 loss)
I0925 00:34:16.113385  2642 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I0925 00:34:29.538336  2642 solver.cpp:218] Iteration 88900 (7.44883 iter/s, 13.4249s/100 iters), loss = 0.000934367
I0925 00:34:29.538378  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000933954 (* 1 = 0.000933954 loss)
I0925 00:34:29.538383  2642 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I0925 00:34:42.298982  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:34:42.835958  2642 solver.cpp:330] Iteration 89000, Testing net (#0)
I0925 00:34:45.927093  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:34:46.056125  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9298
I0925 00:34:46.056161  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295988 (* 1 = 0.295988 loss)
I0925 00:34:46.189409  2642 solver.cpp:218] Iteration 89000 (6.00565 iter/s, 16.651s/100 iters), loss = 0.00160721
I0925 00:34:46.189437  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0016068 (* 1 = 0.0016068 loss)
I0925 00:34:46.189443  2642 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I0925 00:34:59.606757  2642 solver.cpp:218] Iteration 89100 (7.45307 iter/s, 13.4173s/100 iters), loss = 0.00421939
I0925 00:34:59.606788  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00421898 (* 1 = 0.00421898 loss)
I0925 00:34:59.606804  2642 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I0925 00:35:13.026361  2642 solver.cpp:218] Iteration 89200 (7.45182 iter/s, 13.4195s/100 iters), loss = 0.000473478
I0925 00:35:13.026479  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000473068 (* 1 = 0.000473068 loss)
I0925 00:35:13.026495  2642 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I0925 00:35:26.446218  2642 solver.cpp:218] Iteration 89300 (7.45172 iter/s, 13.4197s/100 iters), loss = 0.00164631
I0925 00:35:26.446249  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0016459 (* 1 = 0.0016459 loss)
I0925 00:35:26.446265  2642 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I0925 00:35:39.860255  2642 solver.cpp:218] Iteration 89400 (7.45491 iter/s, 13.414s/100 iters), loss = 0.000468
I0925 00:35:39.860285  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000467592 (* 1 = 0.000467592 loss)
I0925 00:35:39.860291  2642 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I0925 00:35:52.613775  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:35:53.151417  2642 solver.cpp:330] Iteration 89500, Testing net (#0)
I0925 00:35:56.243227  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:35:56.372308  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9299
I0925 00:35:56.372344  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296241 (* 1 = 0.296241 loss)
I0925 00:35:56.506186  2642 solver.cpp:218] Iteration 89500 (6.0075 iter/s, 16.6459s/100 iters), loss = 0.000620062
I0925 00:35:56.506212  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000619654 (* 1 = 0.000619654 loss)
I0925 00:35:56.506219  2642 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I0925 00:36:09.919719  2642 solver.cpp:218] Iteration 89600 (7.45519 iter/s, 13.4135s/100 iters), loss = 0.00122659
I0925 00:36:09.919749  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00122618 (* 1 = 0.00122618 loss)
I0925 00:36:09.919754  2642 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I0925 00:36:23.342963  2642 solver.cpp:218] Iteration 89700 (7.4498 iter/s, 13.4232s/100 iters), loss = 0.000963815
I0925 00:36:23.343091  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000963408 (* 1 = 0.000963408 loss)
I0925 00:36:23.343097  2642 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I0925 00:36:36.767397  2642 solver.cpp:218] Iteration 89800 (7.44919 iter/s, 13.4243s/100 iters), loss = 0.000499171
I0925 00:36:36.767427  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000498764 (* 1 = 0.000498764 loss)
I0925 00:36:36.767433  2642 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I0925 00:36:50.188886  2642 solver.cpp:218] Iteration 89900 (7.45077 iter/s, 13.4214s/100 iters), loss = 0.0013541
I0925 00:36:50.188920  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00135369 (* 1 = 0.00135369 loss)
I0925 00:36:50.188925  2642 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I0925 00:37:02.943509  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:37:03.481148  2642 solver.cpp:330] Iteration 90000, Testing net (#0)
I0925 00:37:06.572252  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:37:06.700713  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9301
I0925 00:37:06.700749  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296936 (* 1 = 0.296936 loss)
I0925 00:37:06.833953  2642 solver.cpp:218] Iteration 90000 (6.00781 iter/s, 16.645s/100 iters), loss = 0.00234
I0925 00:37:06.833979  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0023396 (* 1 = 0.0023396 loss)
I0925 00:37:06.833986  2642 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I0925 00:37:20.246755  2642 solver.cpp:218] Iteration 90100 (7.4556 iter/s, 13.4127s/100 iters), loss = 0.00102674
I0925 00:37:20.246786  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102634 (* 1 = 0.00102634 loss)
I0925 00:37:20.246793  2642 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I0925 00:37:33.666539  2642 solver.cpp:218] Iteration 90200 (7.45172 iter/s, 13.4197s/100 iters), loss = 0.00438762
I0925 00:37:33.666668  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00438721 (* 1 = 0.00438721 loss)
I0925 00:37:33.666676  2642 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I0925 00:37:47.084621  2642 solver.cpp:218] Iteration 90300 (7.45272 iter/s, 13.4179s/100 iters), loss = 0.000693467
I0925 00:37:47.084663  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000693061 (* 1 = 0.000693061 loss)
I0925 00:37:47.084668  2642 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I0925 00:38:00.503710  2642 solver.cpp:218] Iteration 90400 (7.45211 iter/s, 13.419s/100 iters), loss = 0.00252181
I0925 00:38:00.503751  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00252141 (* 1 = 0.00252141 loss)
I0925 00:38:00.503756  2642 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I0925 00:38:13.256608  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:38:13.793265  2642 solver.cpp:330] Iteration 90500, Testing net (#0)
I0925 00:38:16.885763  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:38:17.014663  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9294
I0925 00:38:17.014699  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296084 (* 1 = 0.296084 loss)
I0925 00:38:17.148031  2642 solver.cpp:218] Iteration 90500 (6.00808 iter/s, 16.6442s/100 iters), loss = 0.00125038
I0925 00:38:17.148058  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00124997 (* 1 = 0.00124997 loss)
I0925 00:38:17.148066  2642 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I0925 00:38:30.569762  2642 solver.cpp:218] Iteration 90600 (7.45064 iter/s, 13.4217s/100 iters), loss = 0.00148236
I0925 00:38:30.569802  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00148195 (* 1 = 0.00148195 loss)
I0925 00:38:30.569808  2642 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I0925 00:38:43.992781  2642 solver.cpp:218] Iteration 90700 (7.44993 iter/s, 13.4229s/100 iters), loss = 0.000677054
I0925 00:38:43.992841  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000676648 (* 1 = 0.000676648 loss)
I0925 00:38:43.992847  2642 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I0925 00:38:57.417992  2642 solver.cpp:218] Iteration 90800 (7.44872 iter/s, 13.4251s/100 iters), loss = 0.00303226
I0925 00:38:57.418035  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00303186 (* 1 = 0.00303186 loss)
I0925 00:38:57.418040  2642 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I0925 00:39:10.847820  2642 solver.cpp:218] Iteration 90900 (7.44615 iter/s, 13.4298s/100 iters), loss = 0.000934525
I0925 00:39:10.847851  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000934121 (* 1 = 0.000934121 loss)
I0925 00:39:10.847856  2642 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I0925 00:39:23.610090  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:39:24.145982  2642 solver.cpp:330] Iteration 91000, Testing net (#0)
I0925 00:39:27.236464  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:39:27.365479  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.93
I0925 00:39:27.365516  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295867 (* 1 = 0.295867 loss)
I0925 00:39:27.499071  2642 solver.cpp:218] Iteration 91000 (6.00558 iter/s, 16.6512s/100 iters), loss = 0.000545657
I0925 00:39:27.499099  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000545253 (* 1 = 0.000545253 loss)
I0925 00:39:27.499106  2642 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I0925 00:39:40.913617  2642 solver.cpp:218] Iteration 91100 (7.45463 iter/s, 13.4145s/100 iters), loss = 0.00111307
I0925 00:39:40.913657  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00111266 (* 1 = 0.00111266 loss)
I0925 00:39:40.913663  2642 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I0925 00:39:54.330101  2642 solver.cpp:218] Iteration 91200 (7.45356 iter/s, 13.4164s/100 iters), loss = 0.000829105
I0925 00:39:54.330173  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0008287 (* 1 = 0.0008287 loss)
I0925 00:39:54.330178  2642 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I0925 00:40:07.752789  2642 solver.cpp:218] Iteration 91300 (7.45013 iter/s, 13.4226s/100 iters), loss = 0.0020809
I0925 00:40:07.752830  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0020805 (* 1 = 0.0020805 loss)
I0925 00:40:07.752835  2642 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I0925 00:40:21.172255  2642 solver.cpp:218] Iteration 91400 (7.4519 iter/s, 13.4194s/100 iters), loss = 0.00113787
I0925 00:40:21.172284  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00113747 (* 1 = 0.00113747 loss)
I0925 00:40:21.172291  2642 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I0925 00:40:33.930208  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:40:34.467679  2642 solver.cpp:330] Iteration 91500, Testing net (#0)
I0925 00:40:37.560233  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:40:37.689435  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9303
I0925 00:40:37.689471  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295702 (* 1 = 0.295702 loss)
I0925 00:40:37.823559  2642 solver.cpp:218] Iteration 91500 (6.00556 iter/s, 16.6512s/100 iters), loss = 0.00141403
I0925 00:40:37.823586  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00141362 (* 1 = 0.00141362 loss)
I0925 00:40:37.823593  2642 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I0925 00:40:51.245991  2642 solver.cpp:218] Iteration 91600 (7.45025 iter/s, 13.4224s/100 iters), loss = 0.00091135
I0925 00:40:51.246032  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000910944 (* 1 = 0.000910944 loss)
I0925 00:40:51.246038  2642 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I0925 00:41:04.669706  2642 solver.cpp:218] Iteration 91700 (7.44954 iter/s, 13.4236s/100 iters), loss = 0.000864627
I0925 00:41:04.669781  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000864221 (* 1 = 0.000864221 loss)
I0925 00:41:04.669788  2642 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I0925 00:41:18.092046  2642 solver.cpp:218] Iteration 91800 (7.45032 iter/s, 13.4222s/100 iters), loss = 0.000398649
I0925 00:41:18.092077  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000398243 (* 1 = 0.000398243 loss)
I0925 00:41:18.092082  2642 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I0925 00:41:31.516712  2642 solver.cpp:218] Iteration 91900 (7.44901 iter/s, 13.4246s/100 iters), loss = 0.00206474
I0925 00:41:31.516752  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00206434 (* 1 = 0.00206434 loss)
I0925 00:41:31.516758  2642 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I0925 00:41:44.279554  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:41:44.816054  2642 solver.cpp:330] Iteration 92000, Testing net (#0)
I0925 00:41:47.908880  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:41:48.037564  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.93
I0925 00:41:48.037600  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295914 (* 1 = 0.295914 loss)
I0925 00:41:48.171216  2642 solver.cpp:218] Iteration 92000 (6.00441 iter/s, 16.6544s/100 iters), loss = 0.000944299
I0925 00:41:48.171244  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000943892 (* 1 = 0.000943892 loss)
I0925 00:41:48.171252  2642 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I0925 00:42:01.599747  2642 solver.cpp:218] Iteration 92100 (7.44686 iter/s, 13.4285s/100 iters), loss = 0.00140698
I0925 00:42:01.599788  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00140657 (* 1 = 0.00140657 loss)
I0925 00:42:01.599794  2642 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I0925 00:42:15.032001  2642 solver.cpp:218] Iteration 92200 (7.44481 iter/s, 13.4322s/100 iters), loss = 0.00150215
I0925 00:42:15.032130  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00150175 (* 1 = 0.00150175 loss)
I0925 00:42:15.032138  2642 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I0925 00:42:28.457607  2642 solver.cpp:218] Iteration 92300 (7.44854 iter/s, 13.4255s/100 iters), loss = 0.0010141
I0925 00:42:28.457638  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00101369 (* 1 = 0.00101369 loss)
I0925 00:42:28.457644  2642 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I0925 00:42:41.889902  2642 solver.cpp:218] Iteration 92400 (7.44478 iter/s, 13.4322s/100 iters), loss = 0.00226692
I0925 00:42:41.889943  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00226652 (* 1 = 0.00226652 loss)
I0925 00:42:41.889948  2642 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I0925 00:42:54.653148  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:42:55.189394  2642 solver.cpp:330] Iteration 92500, Testing net (#0)
I0925 00:42:58.281637  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:42:58.410598  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9305
I0925 00:42:58.410635  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296509 (* 1 = 0.296509 loss)
I0925 00:42:58.544201  2642 solver.cpp:218] Iteration 92500 (6.00448 iter/s, 16.6542s/100 iters), loss = 0.000302087
I0925 00:42:58.544229  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000301681 (* 1 = 0.000301681 loss)
I0925 00:42:58.544235  2642 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I0925 00:43:11.967988  2642 solver.cpp:218] Iteration 92600 (7.4495 iter/s, 13.4237s/100 iters), loss = 0.00611815
I0925 00:43:11.968029  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00611775 (* 1 = 0.00611775 loss)
I0925 00:43:11.968034  2642 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I0925 00:43:25.392654  2642 solver.cpp:218] Iteration 92700 (7.44901 iter/s, 13.4246s/100 iters), loss = 0.00227606
I0925 00:43:25.392729  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00227566 (* 1 = 0.00227566 loss)
I0925 00:43:25.392736  2642 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I0925 00:43:38.818677  2642 solver.cpp:218] Iteration 92800 (7.44828 iter/s, 13.4259s/100 iters), loss = 0.0010434
I0925 00:43:38.818708  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00104299 (* 1 = 0.00104299 loss)
I0925 00:43:38.818714  2642 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I0925 00:43:52.241873  2642 solver.cpp:218] Iteration 92900 (7.44983 iter/s, 13.4231s/100 iters), loss = 0.00087851
I0925 00:43:52.241902  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000878105 (* 1 = 0.000878105 loss)
I0925 00:43:52.241909  2642 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I0925 00:44:05.000010  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:44:05.537346  2642 solver.cpp:330] Iteration 93000, Testing net (#0)
I0925 00:44:08.630676  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:44:08.759819  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9304
I0925 00:44:08.759855  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296825 (* 1 = 0.296825 loss)
I0925 00:44:08.893319  2642 solver.cpp:218] Iteration 93000 (6.00551 iter/s, 16.6514s/100 iters), loss = 0.00168238
I0925 00:44:08.893348  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168198 (* 1 = 0.00168198 loss)
I0925 00:44:08.893355  2642 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I0925 00:44:22.320874  2642 solver.cpp:218] Iteration 93100 (7.44741 iter/s, 13.4275s/100 iters), loss = 0.00203053
I0925 00:44:22.320904  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00203013 (* 1 = 0.00203013 loss)
I0925 00:44:22.320910  2642 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I0925 00:44:35.751054  2642 solver.cpp:218] Iteration 93200 (7.44595 iter/s, 13.4301s/100 iters), loss = 0.000883346
I0925 00:44:35.751121  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000882941 (* 1 = 0.000882941 loss)
I0925 00:44:35.751127  2642 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I0925 00:44:49.180248  2642 solver.cpp:218] Iteration 93300 (7.44652 iter/s, 13.4291s/100 iters), loss = 0.00082397
I0925 00:44:49.180289  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000823564 (* 1 = 0.000823564 loss)
I0925 00:44:49.180294  2642 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I0925 00:45:02.621546  2642 solver.cpp:218] Iteration 93400 (7.4398 iter/s, 13.4412s/100 iters), loss = 0.00121615
I0925 00:45:02.621585  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00121575 (* 1 = 0.00121575 loss)
I0925 00:45:02.621592  2642 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I0925 00:45:15.391788  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:45:15.929479  2642 solver.cpp:330] Iteration 93500, Testing net (#0)
I0925 00:45:19.023301  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:45:19.151962  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9305
I0925 00:45:19.151999  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296754 (* 1 = 0.296754 loss)
I0925 00:45:19.285207  2642 solver.cpp:218] Iteration 93500 (6.00111 iter/s, 16.6636s/100 iters), loss = 0.00063607
I0925 00:45:19.285233  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000635665 (* 1 = 0.000635665 loss)
I0925 00:45:19.285240  2642 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I0925 00:45:32.704916  2642 solver.cpp:218] Iteration 93600 (7.45176 iter/s, 13.4196s/100 iters), loss = 0.000341614
I0925 00:45:32.704946  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00034121 (* 1 = 0.00034121 loss)
I0925 00:45:32.704952  2642 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I0925 00:45:46.133875  2642 solver.cpp:218] Iteration 93700 (7.44663 iter/s, 13.4289s/100 iters), loss = 0.000616075
I0925 00:45:46.134003  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000615671 (* 1 = 0.000615671 loss)
I0925 00:45:46.134011  2642 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I0925 00:45:59.554122  2642 solver.cpp:218] Iteration 93800 (7.45151 iter/s, 13.4201s/100 iters), loss = 0.00106676
I0925 00:45:59.554163  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00106635 (* 1 = 0.00106635 loss)
I0925 00:45:59.554169  2642 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I0925 00:46:12.977289  2642 solver.cpp:218] Iteration 93900 (7.44985 iter/s, 13.4231s/100 iters), loss = 0.000774528
I0925 00:46:12.977329  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000774125 (* 1 = 0.000774125 loss)
I0925 00:46:12.977335  2642 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I0925 00:46:25.738476  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:46:26.275410  2642 solver.cpp:330] Iteration 94000, Testing net (#0)
I0925 00:46:29.367990  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:46:29.496294  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9302
I0925 00:46:29.496330  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296688 (* 1 = 0.296688 loss)
I0925 00:46:29.629789  2642 solver.cpp:218] Iteration 94000 (6.00513 iter/s, 16.6524s/100 iters), loss = 0.00136612
I0925 00:46:29.629815  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00136571 (* 1 = 0.00136571 loss)
I0925 00:46:29.629822  2642 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I0925 00:46:43.057883  2642 solver.cpp:218] Iteration 94100 (7.44711 iter/s, 13.428s/100 iters), loss = 0.00110598
I0925 00:46:43.057924  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00110558 (* 1 = 0.00110558 loss)
I0925 00:46:43.057929  2642 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I0925 00:46:56.486137  2642 solver.cpp:218] Iteration 94200 (7.44702 iter/s, 13.4282s/100 iters), loss = 0.000391394
I0925 00:46:56.486204  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000390988 (* 1 = 0.000390988 loss)
I0925 00:46:56.486212  2642 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I0925 00:47:09.912537  2642 solver.cpp:218] Iteration 94300 (7.44807 iter/s, 13.4263s/100 iters), loss = 0.00054805
I0925 00:47:09.912569  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000547644 (* 1 = 0.000547644 loss)
I0925 00:47:09.912573  2642 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I0925 00:47:23.335345  2642 solver.cpp:218] Iteration 94400 (7.45004 iter/s, 13.4227s/100 iters), loss = 0.000870198
I0925 00:47:23.335376  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000869792 (* 1 = 0.000869792 loss)
I0925 00:47:23.335382  2642 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I0925 00:47:36.099632  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:47:36.637176  2642 solver.cpp:330] Iteration 94500, Testing net (#0)
I0925 00:47:39.727368  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:47:39.856251  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9299
I0925 00:47:39.856287  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296442 (* 1 = 0.296442 loss)
I0925 00:47:39.989468  2642 solver.cpp:218] Iteration 94500 (6.00454 iter/s, 16.6541s/100 iters), loss = 0.000334146
I0925 00:47:39.989496  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000333739 (* 1 = 0.000333739 loss)
I0925 00:47:39.989503  2642 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I0925 00:47:53.416445  2642 solver.cpp:218] Iteration 94600 (7.44773 iter/s, 13.4269s/100 iters), loss = 0.000955302
I0925 00:47:53.416486  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000954896 (* 1 = 0.000954896 loss)
I0925 00:47:53.416492  2642 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I0925 00:48:06.845618  2642 solver.cpp:218] Iteration 94700 (7.44651 iter/s, 13.4291s/100 iters), loss = 0.00133848
I0925 00:48:06.845731  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00133807 (* 1 = 0.00133807 loss)
I0925 00:48:06.845739  2642 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I0925 00:48:20.267611  2642 solver.cpp:218] Iteration 94800 (7.45054 iter/s, 13.4219s/100 iters), loss = 0.000733816
I0925 00:48:20.267642  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000733408 (* 1 = 0.000733408 loss)
I0925 00:48:20.267657  2642 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I0925 00:48:33.689290  2642 solver.cpp:218] Iteration 94900 (7.45067 iter/s, 13.4216s/100 iters), loss = 0.000996918
I0925 00:48:33.689321  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00099651 (* 1 = 0.00099651 loss)
I0925 00:48:33.689337  2642 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I0925 00:48:46.448299  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:48:46.985153  2642 solver.cpp:330] Iteration 95000, Testing net (#0)
I0925 00:48:50.075865  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:48:50.205140  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9305
I0925 00:48:50.205176  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296868 (* 1 = 0.296868 loss)
I0925 00:48:50.339109  2642 solver.cpp:218] Iteration 95000 (6.00609 iter/s, 16.6498s/100 iters), loss = 0.000741189
I0925 00:48:50.339138  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00074078 (* 1 = 0.00074078 loss)
I0925 00:48:50.339144  2642 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I0925 00:49:03.772817  2642 solver.cpp:218] Iteration 95100 (7.44399 iter/s, 13.4336s/100 iters), loss = 0.000765845
I0925 00:49:03.772858  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000765437 (* 1 = 0.000765437 loss)
I0925 00:49:03.772864  2642 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I0925 00:49:17.212446  2642 solver.cpp:218] Iteration 95200 (7.44072 iter/s, 13.4396s/100 iters), loss = 0.000551997
I0925 00:49:17.212582  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000551589 (* 1 = 0.000551589 loss)
I0925 00:49:17.212589  2642 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I0925 00:49:30.641971  2642 solver.cpp:218] Iteration 95300 (7.44637 iter/s, 13.4294s/100 iters), loss = 0.0013427
I0925 00:49:30.642012  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0013423 (* 1 = 0.0013423 loss)
I0925 00:49:30.642019  2642 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I0925 00:49:44.079015  2642 solver.cpp:218] Iteration 95400 (7.44215 iter/s, 13.437s/100 iters), loss = 0.00137601
I0925 00:49:44.079056  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00137561 (* 1 = 0.00137561 loss)
I0925 00:49:44.079062  2642 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I0925 00:49:56.843374  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:49:57.380702  2642 solver.cpp:330] Iteration 95500, Testing net (#0)
I0925 00:50:00.473695  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:50:00.602485  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9302
I0925 00:50:00.602521  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.297084 (* 1 = 0.297084 loss)
I0925 00:50:00.735512  2642 solver.cpp:218] Iteration 95500 (6.00369 iter/s, 16.6564s/100 iters), loss = 0.00154049
I0925 00:50:00.735539  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154008 (* 1 = 0.00154008 loss)
I0925 00:50:00.735546  2642 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I0925 00:50:14.161110  2642 solver.cpp:218] Iteration 95600 (7.44849 iter/s, 13.4255s/100 iters), loss = 0.00152035
I0925 00:50:14.161151  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00151994 (* 1 = 0.00151994 loss)
I0925 00:50:14.161157  2642 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I0925 00:50:27.587761  2642 solver.cpp:218] Iteration 95700 (7.44791 iter/s, 13.4266s/100 iters), loss = 0.00168863
I0925 00:50:27.587895  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168822 (* 1 = 0.00168822 loss)
I0925 00:50:27.587904  2642 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I0925 00:50:41.013639  2642 solver.cpp:218] Iteration 95800 (7.44839 iter/s, 13.4257s/100 iters), loss = 0.000629282
I0925 00:50:41.013679  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000628872 (* 1 = 0.000628872 loss)
I0925 00:50:41.013685  2642 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I0925 00:50:54.439785  2642 solver.cpp:218] Iteration 95900 (7.44819 iter/s, 13.4261s/100 iters), loss = 0.0010081
I0925 00:50:54.439826  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100769 (* 1 = 0.00100769 loss)
I0925 00:50:54.439831  2642 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I0925 00:51:07.203887  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:51:07.740433  2642 solver.cpp:330] Iteration 96000, Testing net (#0)
I0925 00:51:10.831322  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:51:10.960034  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9299
I0925 00:51:10.960070  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.29689 (* 1 = 0.29689 loss)
I0925 00:51:11.093775  2642 solver.cpp:218] Iteration 96000 (6.00459 iter/s, 16.6539s/100 iters), loss = 0.00236001
I0925 00:51:11.093803  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0023596 (* 1 = 0.0023596 loss)
I0925 00:51:11.093809  2642 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I0925 00:51:24.525535  2642 solver.cpp:218] Iteration 96100 (7.44508 iter/s, 13.4317s/100 iters), loss = 0.000754657
I0925 00:51:24.525576  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000754247 (* 1 = 0.000754247 loss)
I0925 00:51:24.525583  2642 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I0925 00:51:37.959940  2642 solver.cpp:218] Iteration 96200 (7.44362 iter/s, 13.4343s/100 iters), loss = 0.00267532
I0925 00:51:37.960067  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00267491 (* 1 = 0.00267491 loss)
I0925 00:51:37.960074  2642 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I0925 00:51:51.386898  2642 solver.cpp:218] Iteration 96300 (7.44778 iter/s, 13.4268s/100 iters), loss = 0.000381266
I0925 00:51:51.386939  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000380855 (* 1 = 0.000380855 loss)
I0925 00:51:51.386945  2642 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I0925 00:52:04.819926  2642 solver.cpp:218] Iteration 96400 (7.44438 iter/s, 13.433s/100 iters), loss = 0.00121271
I0925 00:52:04.819967  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0012123 (* 1 = 0.0012123 loss)
I0925 00:52:04.819972  2642 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I0925 00:52:17.577605  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:52:18.116269  2642 solver.cpp:330] Iteration 96500, Testing net (#0)
I0925 00:52:21.209856  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:52:21.338670  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9302
I0925 00:52:21.338707  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296925 (* 1 = 0.296925 loss)
I0925 00:52:21.472498  2642 solver.cpp:218] Iteration 96500 (6.00511 iter/s, 16.6525s/100 iters), loss = 0.000680923
I0925 00:52:21.472525  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000680511 (* 1 = 0.000680511 loss)
I0925 00:52:21.472532  2642 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I0925 00:52:34.899046  2642 solver.cpp:218] Iteration 96600 (7.44796 iter/s, 13.4265s/100 iters), loss = 0.00177654
I0925 00:52:34.899085  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00177613 (* 1 = 0.00177613 loss)
I0925 00:52:34.899091  2642 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I0925 00:52:48.321655  2642 solver.cpp:218] Iteration 96700 (7.45015 iter/s, 13.4225s/100 iters), loss = 0.00150392
I0925 00:52:48.321725  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00150351 (* 1 = 0.00150351 loss)
I0925 00:52:48.321732  2642 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I0925 00:53:01.745764  2642 solver.cpp:218] Iteration 96800 (7.44934 iter/s, 13.424s/100 iters), loss = 0.000533906
I0925 00:53:01.745805  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000533492 (* 1 = 0.000533492 loss)
I0925 00:53:01.745811  2642 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I0925 00:53:15.175318  2642 solver.cpp:218] Iteration 96900 (7.4463 iter/s, 13.4295s/100 iters), loss = 0.000380232
I0925 00:53:15.175359  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00037982 (* 1 = 0.00037982 loss)
I0925 00:53:15.175364  2642 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I0925 00:53:27.929608  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:53:28.466596  2642 solver.cpp:330] Iteration 97000, Testing net (#0)
I0925 00:53:31.558400  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:53:31.687322  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9302
I0925 00:53:31.687360  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.297044 (* 1 = 0.297044 loss)
I0925 00:53:31.821682  2642 solver.cpp:218] Iteration 97000 (6.00734 iter/s, 16.6463s/100 iters), loss = 0.000545288
I0925 00:53:31.821710  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000544876 (* 1 = 0.000544876 loss)
I0925 00:53:31.821717  2642 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I0925 00:53:45.251526  2642 solver.cpp:218] Iteration 97100 (7.44614 iter/s, 13.4298s/100 iters), loss = 0.000981082
I0925 00:53:45.251567  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000980669 (* 1 = 0.000980669 loss)
I0925 00:53:45.251574  2642 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I0925 00:53:58.685106  2642 solver.cpp:218] Iteration 97200 (7.44407 iter/s, 13.4335s/100 iters), loss = 0.000544573
I0925 00:53:58.685175  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000544161 (* 1 = 0.000544161 loss)
I0925 00:53:58.685183  2642 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I0925 00:54:12.121397  2642 solver.cpp:218] Iteration 97300 (7.44258 iter/s, 13.4362s/100 iters), loss = 0.00133213
I0925 00:54:12.121426  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00133172 (* 1 = 0.00133172 loss)
I0925 00:54:12.121433  2642 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I0925 00:54:25.553342  2642 solver.cpp:218] Iteration 97400 (7.44497 iter/s, 13.4319s/100 iters), loss = 0.00216508
I0925 00:54:25.553385  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00216467 (* 1 = 0.00216467 loss)
I0925 00:54:25.553390  2642 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I0925 00:54:38.316046  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:54:38.853087  2642 solver.cpp:330] Iteration 97500, Testing net (#0)
I0925 00:54:41.945683  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:54:42.074564  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9303
I0925 00:54:42.074601  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.297296 (* 1 = 0.297296 loss)
I0925 00:54:42.207962  2642 solver.cpp:218] Iteration 97500 (6.00437 iter/s, 16.6545s/100 iters), loss = 0.000607871
I0925 00:54:42.207990  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000607459 (* 1 = 0.000607459 loss)
I0925 00:54:42.207998  2642 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I0925 00:54:55.622459  2642 solver.cpp:218] Iteration 97600 (7.45465 iter/s, 13.4144s/100 iters), loss = 0.00189509
I0925 00:54:55.622501  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00189468 (* 1 = 0.00189468 loss)
I0925 00:54:55.622508  2642 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I0925 00:55:09.039088  2642 solver.cpp:218] Iteration 97700 (7.45348 iter/s, 13.4166s/100 iters), loss = 0.00044835
I0925 00:55:09.039213  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000447937 (* 1 = 0.000447937 loss)
I0925 00:55:09.039221  2642 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I0925 00:55:22.455840  2642 solver.cpp:218] Iteration 97800 (7.45345 iter/s, 13.4166s/100 iters), loss = 0.000904595
I0925 00:55:22.455881  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000904182 (* 1 = 0.000904182 loss)
I0925 00:55:22.455888  2642 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I0925 00:55:35.873309  2642 solver.cpp:218] Iteration 97900 (7.45301 iter/s, 13.4174s/100 iters), loss = 0.000976505
I0925 00:55:35.873339  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000976093 (* 1 = 0.000976093 loss)
I0925 00:55:35.873345  2642 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I0925 00:55:48.625313  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:55:49.163122  2642 solver.cpp:330] Iteration 98000, Testing net (#0)
I0925 00:55:52.255753  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:55:52.383819  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9302
I0925 00:55:52.383857  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.297237 (* 1 = 0.297237 loss)
I0925 00:55:52.517688  2642 solver.cpp:218] Iteration 98000 (6.00806 iter/s, 16.6443s/100 iters), loss = 0.000879084
I0925 00:55:52.517715  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000878672 (* 1 = 0.000878672 loss)
I0925 00:55:52.517721  2642 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I0925 00:56:05.946923  2642 solver.cpp:218] Iteration 98100 (7.44647 iter/s, 13.4292s/100 iters), loss = 0.000965084
I0925 00:56:05.946964  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000964673 (* 1 = 0.000964673 loss)
I0925 00:56:05.946969  2642 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I0925 00:56:19.377532  2642 solver.cpp:218] Iteration 98200 (7.44572 iter/s, 13.4305s/100 iters), loss = 0.000722385
I0925 00:56:19.377605  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000721973 (* 1 = 0.000721973 loss)
I0925 00:56:19.377612  2642 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I0925 00:56:32.805577  2642 solver.cpp:218] Iteration 98300 (7.44716 iter/s, 13.4279s/100 iters), loss = 0.000646065
I0925 00:56:32.805619  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000645654 (* 1 = 0.000645654 loss)
I0925 00:56:32.805624  2642 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I0925 00:56:46.237634  2642 solver.cpp:218] Iteration 98400 (7.44491 iter/s, 13.432s/100 iters), loss = 0.00114434
I0925 00:56:46.237676  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00114393 (* 1 = 0.00114393 loss)
I0925 00:56:46.237682  2642 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I0925 00:56:58.997622  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:56:59.534754  2642 solver.cpp:330] Iteration 98500, Testing net (#0)
I0925 00:57:02.627604  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:57:02.756695  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9303
I0925 00:57:02.756731  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296861 (* 1 = 0.296861 loss)
I0925 00:57:02.890055  2642 solver.cpp:218] Iteration 98500 (6.00516 iter/s, 16.6523s/100 iters), loss = 0.00069653
I0925 00:57:02.890084  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000696118 (* 1 = 0.000696118 loss)
I0925 00:57:02.890091  2642 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I0925 00:57:16.303156  2642 solver.cpp:218] Iteration 98600 (7.45543 iter/s, 13.413s/100 iters), loss = 0.0019688
I0925 00:57:16.303197  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00196838 (* 1 = 0.00196838 loss)
I0925 00:57:16.303203  2642 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I0925 00:57:29.715276  2642 solver.cpp:218] Iteration 98700 (7.45598 iter/s, 13.412s/100 iters), loss = 0.00315917
I0925 00:57:29.715420  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00315876 (* 1 = 0.00315876 loss)
I0925 00:57:29.715427  2642 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I0925 00:57:43.134153  2642 solver.cpp:218] Iteration 98800 (7.45228 iter/s, 13.4187s/100 iters), loss = 0.000408024
I0925 00:57:43.134193  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000407612 (* 1 = 0.000407612 loss)
I0925 00:57:43.134199  2642 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I0925 00:57:56.551954  2642 solver.cpp:218] Iteration 98900 (7.45283 iter/s, 13.4177s/100 iters), loss = 0.000664489
I0925 00:57:56.551985  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000664078 (* 1 = 0.000664078 loss)
I0925 00:57:56.551991  2642 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I0925 00:58:09.299720  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:58:09.836998  2642 solver.cpp:330] Iteration 99000, Testing net (#0)
I0925 00:58:12.928254  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:58:13.057361  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9312
I0925 00:58:13.057397  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.297626 (* 1 = 0.297626 loss)
I0925 00:58:13.190454  2642 solver.cpp:218] Iteration 99000 (6.01018 iter/s, 16.6384s/100 iters), loss = 0.00108523
I0925 00:58:13.190481  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108481 (* 1 = 0.00108481 loss)
I0925 00:58:13.190488  2642 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I0925 00:58:26.611023  2642 solver.cpp:218] Iteration 99100 (7.45128 iter/s, 13.4205s/100 iters), loss = 0.000986086
I0925 00:58:26.611054  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000985673 (* 1 = 0.000985673 loss)
I0925 00:58:26.611060  2642 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I0925 00:58:40.039181  2642 solver.cpp:218] Iteration 99200 (7.44707 iter/s, 13.4281s/100 iters), loss = 0.000485197
I0925 00:58:40.039310  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000484784 (* 1 = 0.000484784 loss)
I0925 00:58:40.039317  2642 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I0925 00:58:53.466078  2642 solver.cpp:218] Iteration 99300 (7.44782 iter/s, 13.4267s/100 iters), loss = 0.000423015
I0925 00:58:53.466109  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000422602 (* 1 = 0.000422602 loss)
I0925 00:58:53.466114  2642 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I0925 00:59:06.894850  2642 solver.cpp:218] Iteration 99400 (7.44673 iter/s, 13.4287s/100 iters), loss = 0.00256451
I0925 00:59:06.894889  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0025641 (* 1 = 0.0025641 loss)
I0925 00:59:06.894896  2642 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I0925 00:59:19.656353  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:59:20.193786  2642 solver.cpp:330] Iteration 99500, Testing net (#0)
I0925 00:59:23.286439  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 00:59:23.415637  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9305
I0925 00:59:23.415674  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.297533 (* 1 = 0.297533 loss)
I0925 00:59:23.548827  2642 solver.cpp:218] Iteration 99500 (6.0046 iter/s, 16.6539s/100 iters), loss = 0.0010396
I0925 00:59:23.548854  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103919 (* 1 = 0.00103919 loss)
I0925 00:59:23.548861  2642 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I0925 00:59:36.973371  2642 solver.cpp:218] Iteration 99600 (7.44908 iter/s, 13.4245s/100 iters), loss = 0.000778774
I0925 00:59:36.973410  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000778361 (* 1 = 0.000778361 loss)
I0925 00:59:36.973415  2642 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I0925 00:59:50.401998  2642 solver.cpp:218] Iteration 99700 (7.44682 iter/s, 13.4286s/100 iters), loss = 0.000844286
I0925 00:59:50.402107  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000843873 (* 1 = 0.000843873 loss)
I0925 00:59:50.402113  2642 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I0925 01:00:03.838521  2642 solver.cpp:218] Iteration 99800 (7.44248 iter/s, 13.4364s/100 iters), loss = 0.00153102
I0925 01:00:03.838560  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153061 (* 1 = 0.00153061 loss)
I0925 01:00:03.838567  2642 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I0925 01:00:17.268193  2642 solver.cpp:218] Iteration 99900 (7.44624 iter/s, 13.4296s/100 iters), loss = 0.000793112
I0925 01:00:17.268224  2642 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000792699 (* 1 = 0.000792699 loss)
I0925 01:00:17.268229  2642 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I0925 01:00:30.030128  2651 data_layer.cpp:73] Restarting data prefetching from start.
I0925 01:00:30.567117  2642 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res56_relu_iter_100000.caffemodel
I0925 01:00:30.587237  2642 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res56_relu_iter_100000.solverstate
I0925 01:00:30.624454  2642 solver.cpp:310] Iteration 100000, loss = 0.00118191
I0925 01:00:30.624475  2642 solver.cpp:330] Iteration 100000, Testing net (#0)
I0925 01:00:33.715626  2653 data_layer.cpp:73] Restarting data prefetching from start.
I0925 01:00:33.844586  2642 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9307
I0925 01:00:33.844614  2642 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.297862 (* 1 = 0.297862 loss)
I0925 01:00:33.844629  2642 solver.cpp:315] Optimization Done.
I0925 01:00:33.844630  2642 caffe.cpp:259] Optimization Done.
