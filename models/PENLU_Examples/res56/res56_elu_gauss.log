I0930 11:17:09.570052  3537 caffe.cpp:218] Using GPUs 0
I0930 11:17:09.606041  3537 caffe.cpp:223] GPU 0: GeForce GTX 1080
I0930 11:17:09.835069  3537 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res56_elu_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_elu_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I0930 11:17:09.835201  3537 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_elu_train_test.prototxt
I0930 11:17:09.838399  3537 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_elu_train_test.prototxt
I0930 11:17:09.838414  3537 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0930 11:17:09.838630  3537 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I0930 11:17:09.838740  3537 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I0930 11:17:09.839612  3537 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv1"
  type: "ELU"
  bottom: "Convolution1"
  top: "Convolution1"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv2"
  type: "ELU"
  bottom: "Convolution2"
  top: "Convolution2"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu_conv3"
  type: "ELU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv4"
  type: "ELU"
  bottom: "Convolution4"
  top: "Convolution4"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu_conv5"
  type: "ELU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv6"
  type: "ELU"
  bottom: "Convolution6"
  top: "Convolution6"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu_conv7"
  type: "ELU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv8"
  type: "ELU"
  bottom: "Convolution8"
  top: "Convolution8"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu_conv9"
  type: "ELU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv10"
  type: "ELU"
  bottom: "Convolution10"
  top: "Convolution10"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu_conv11"
  type: "ELU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv12"
  type: "ELU"
  bottom: "Convolution12"
  top: "Convolution12"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu_conv13"
  type: "ELU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv14"
  type: "ELU"
  bottom: "Convolution14"
  top: "Convolution14"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu_conv15"
  type: "ELU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv16"
  type: "ELU"
  bottom: "Convolution16"
  top: "Convolution16"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu_conv17"
  type: "ELU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv18"
  type: "ELU"
  bottom: "Convolution18"
  top: "Convolution18"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu_conv19"
  type: "ELU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv20"
  type: "ELU"
  bottom: "Convolution21"
  top: "Convolution21"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu_conv21"
  type: "ELU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv22"
  type: "ELU"
  bottom: "Convolution23"
  top: "Convolution23"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution24"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu_conv23"
  type: "ELU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv24"
  type: "ELU"
  bottom: "Convolution25"
  top: "Convolution25"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution26"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu_conv25"
  type: "ELU"
  bottom: "Eltwise12"
  top: "Eltwise12"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution27"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv26"
  type: "ELU"
  bottom: "Convolution27"
  top: "Convolution27"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Convolution27"
  top: "Convolution28"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution28"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu_conv27"
  type: "ELU"
  bottom: "Eltwise13"
  top: "Eltwise13"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution29"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv28"
  type: "ELU"
  bottom: "Convolution29"
  top: "Convolution29"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Convolution29"
  top: "Convolution30"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution30"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu_conv29"
  type: "ELU"
  bottom: "Eltwise14"
  top: "Eltwise14"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Eltwise14"
  top: "Convolution31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stri
I0930 11:17:09.840320  3537 layer_factory.hpp:77] Creating layer Data1
I0930 11:17:09.840402  3537 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I0930 11:17:09.840421  3537 net.cpp:84] Creating Layer Data1
I0930 11:17:09.840426  3537 net.cpp:380] Data1 -> Data1
I0930 11:17:09.840445  3537 net.cpp:380] Data1 -> Data2
I0930 11:17:09.840456  3537 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0930 11:17:09.841876  3537 data_layer.cpp:45] output data size: 100,3,28,28
I0930 11:17:09.844220  3537 net.cpp:122] Setting up Data1
I0930 11:17:09.844234  3537 net.cpp:129] Top shape: 100 3 28 28 (235200)
I0930 11:17:09.844238  3537 net.cpp:129] Top shape: 100 (100)
I0930 11:17:09.844241  3537 net.cpp:137] Memory required for data: 941200
I0930 11:17:09.844247  3537 layer_factory.hpp:77] Creating layer Convolution1
I0930 11:17:09.844265  3537 net.cpp:84] Creating Layer Convolution1
I0930 11:17:09.844269  3537 net.cpp:406] Convolution1 <- Data1
I0930 11:17:09.844277  3537 net.cpp:380] Convolution1 -> Convolution1
I0930 11:17:09.992652  3537 net.cpp:122] Setting up Convolution1
I0930 11:17:09.992686  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.992689  3537 net.cpp:137] Memory required for data: 5958800
I0930 11:17:09.992704  3537 layer_factory.hpp:77] Creating layer BatchNorm1
I0930 11:17:09.992724  3537 net.cpp:84] Creating Layer BatchNorm1
I0930 11:17:09.992728  3537 net.cpp:406] BatchNorm1 <- Convolution1
I0930 11:17:09.992744  3537 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0930 11:17:09.992884  3537 net.cpp:122] Setting up BatchNorm1
I0930 11:17:09.992890  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.992903  3537 net.cpp:137] Memory required for data: 10976400
I0930 11:17:09.992910  3537 layer_factory.hpp:77] Creating layer Scale1
I0930 11:17:09.992931  3537 net.cpp:84] Creating Layer Scale1
I0930 11:17:09.992934  3537 net.cpp:406] Scale1 <- Convolution1
I0930 11:17:09.992938  3537 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0930 11:17:09.992990  3537 layer_factory.hpp:77] Creating layer Scale1
I0930 11:17:09.993103  3537 net.cpp:122] Setting up Scale1
I0930 11:17:09.993108  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.993120  3537 net.cpp:137] Memory required for data: 15994000
I0930 11:17:09.993125  3537 layer_factory.hpp:77] Creating layer elu_conv1
I0930 11:17:09.993134  3537 net.cpp:84] Creating Layer elu_conv1
I0930 11:17:09.993145  3537 net.cpp:406] elu_conv1 <- Convolution1
I0930 11:17:09.993149  3537 net.cpp:367] elu_conv1 -> Convolution1 (in-place)
I0930 11:17:09.993155  3537 net.cpp:122] Setting up elu_conv1
I0930 11:17:09.993158  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.993160  3537 net.cpp:137] Memory required for data: 21011600
I0930 11:17:09.993163  3537 layer_factory.hpp:77] Creating layer Convolution1_elu_conv1_0_split
I0930 11:17:09.993167  3537 net.cpp:84] Creating Layer Convolution1_elu_conv1_0_split
I0930 11:17:09.993170  3537 net.cpp:406] Convolution1_elu_conv1_0_split <- Convolution1
I0930 11:17:09.993172  3537 net.cpp:380] Convolution1_elu_conv1_0_split -> Convolution1_elu_conv1_0_split_0
I0930 11:17:09.993177  3537 net.cpp:380] Convolution1_elu_conv1_0_split -> Convolution1_elu_conv1_0_split_1
I0930 11:17:09.993213  3537 net.cpp:122] Setting up Convolution1_elu_conv1_0_split
I0930 11:17:09.993218  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.993230  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.993232  3537 net.cpp:137] Memory required for data: 31046800
I0930 11:17:09.993235  3537 layer_factory.hpp:77] Creating layer Convolution2
I0930 11:17:09.993253  3537 net.cpp:84] Creating Layer Convolution2
I0930 11:17:09.993255  3537 net.cpp:406] Convolution2 <- Convolution1_elu_conv1_0_split_0
I0930 11:17:09.993273  3537 net.cpp:380] Convolution2 -> Convolution2
I0930 11:17:09.994105  3537 net.cpp:122] Setting up Convolution2
I0930 11:17:09.994117  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.994129  3537 net.cpp:137] Memory required for data: 36064400
I0930 11:17:09.994138  3537 layer_factory.hpp:77] Creating layer BatchNorm2
I0930 11:17:09.994156  3537 net.cpp:84] Creating Layer BatchNorm2
I0930 11:17:09.994159  3537 net.cpp:406] BatchNorm2 <- Convolution2
I0930 11:17:09.994173  3537 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0930 11:17:09.994315  3537 net.cpp:122] Setting up BatchNorm2
I0930 11:17:09.994321  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.994333  3537 net.cpp:137] Memory required for data: 41082000
I0930 11:17:09.994340  3537 layer_factory.hpp:77] Creating layer Scale2
I0930 11:17:09.994359  3537 net.cpp:84] Creating Layer Scale2
I0930 11:17:09.994364  3537 net.cpp:406] Scale2 <- Convolution2
I0930 11:17:09.994369  3537 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0930 11:17:09.994407  3537 layer_factory.hpp:77] Creating layer Scale2
I0930 11:17:09.994498  3537 net.cpp:122] Setting up Scale2
I0930 11:17:09.994503  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.994508  3537 net.cpp:137] Memory required for data: 46099600
I0930 11:17:09.994532  3537 layer_factory.hpp:77] Creating layer elu_conv2
I0930 11:17:09.994545  3537 net.cpp:84] Creating Layer elu_conv2
I0930 11:17:09.994550  3537 net.cpp:406] elu_conv2 <- Convolution2
I0930 11:17:09.994555  3537 net.cpp:367] elu_conv2 -> Convolution2 (in-place)
I0930 11:17:09.994562  3537 net.cpp:122] Setting up elu_conv2
I0930 11:17:09.994593  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.994597  3537 net.cpp:137] Memory required for data: 51117200
I0930 11:17:09.994602  3537 layer_factory.hpp:77] Creating layer Convolution3
I0930 11:17:09.994611  3537 net.cpp:84] Creating Layer Convolution3
I0930 11:17:09.994614  3537 net.cpp:406] Convolution3 <- Convolution2
I0930 11:17:09.994621  3537 net.cpp:380] Convolution3 -> Convolution3
I0930 11:17:09.995424  3537 net.cpp:122] Setting up Convolution3
I0930 11:17:09.995434  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.995440  3537 net.cpp:137] Memory required for data: 56134800
I0930 11:17:09.995447  3537 layer_factory.hpp:77] Creating layer BatchNorm3
I0930 11:17:09.995455  3537 net.cpp:84] Creating Layer BatchNorm3
I0930 11:17:09.995458  3537 net.cpp:406] BatchNorm3 <- Convolution3
I0930 11:17:09.995465  3537 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0930 11:17:09.995575  3537 net.cpp:122] Setting up BatchNorm3
I0930 11:17:09.995581  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.995585  3537 net.cpp:137] Memory required for data: 61152400
I0930 11:17:09.995595  3537 layer_factory.hpp:77] Creating layer Scale3
I0930 11:17:09.995601  3537 net.cpp:84] Creating Layer Scale3
I0930 11:17:09.995605  3537 net.cpp:406] Scale3 <- Convolution3
I0930 11:17:09.995611  3537 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0930 11:17:09.995637  3537 layer_factory.hpp:77] Creating layer Scale3
I0930 11:17:09.995705  3537 net.cpp:122] Setting up Scale3
I0930 11:17:09.995710  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.995715  3537 net.cpp:137] Memory required for data: 66170000
I0930 11:17:09.995721  3537 layer_factory.hpp:77] Creating layer Eltwise1
I0930 11:17:09.995728  3537 net.cpp:84] Creating Layer Eltwise1
I0930 11:17:09.995733  3537 net.cpp:406] Eltwise1 <- Convolution1_elu_conv1_0_split_1
I0930 11:17:09.995738  3537 net.cpp:406] Eltwise1 <- Convolution3
I0930 11:17:09.995743  3537 net.cpp:380] Eltwise1 -> Eltwise1
I0930 11:17:09.995761  3537 net.cpp:122] Setting up Eltwise1
I0930 11:17:09.995766  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.995770  3537 net.cpp:137] Memory required for data: 71187600
I0930 11:17:09.995775  3537 layer_factory.hpp:77] Creating layer elu_conv3
I0930 11:17:09.995781  3537 net.cpp:84] Creating Layer elu_conv3
I0930 11:17:09.995785  3537 net.cpp:406] elu_conv3 <- Eltwise1
I0930 11:17:09.995790  3537 net.cpp:367] elu_conv3 -> Eltwise1 (in-place)
I0930 11:17:09.995796  3537 net.cpp:122] Setting up elu_conv3
I0930 11:17:09.995801  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.995805  3537 net.cpp:137] Memory required for data: 76205200
I0930 11:17:09.995810  3537 layer_factory.hpp:77] Creating layer Eltwise1_elu_conv3_0_split
I0930 11:17:09.995815  3537 net.cpp:84] Creating Layer Eltwise1_elu_conv3_0_split
I0930 11:17:09.995820  3537 net.cpp:406] Eltwise1_elu_conv3_0_split <- Eltwise1
I0930 11:17:09.995824  3537 net.cpp:380] Eltwise1_elu_conv3_0_split -> Eltwise1_elu_conv3_0_split_0
I0930 11:17:09.995831  3537 net.cpp:380] Eltwise1_elu_conv3_0_split -> Eltwise1_elu_conv3_0_split_1
I0930 11:17:09.995854  3537 net.cpp:122] Setting up Eltwise1_elu_conv3_0_split
I0930 11:17:09.995859  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.995864  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.995868  3537 net.cpp:137] Memory required for data: 86240400
I0930 11:17:09.995872  3537 layer_factory.hpp:77] Creating layer Convolution4
I0930 11:17:09.995882  3537 net.cpp:84] Creating Layer Convolution4
I0930 11:17:09.995887  3537 net.cpp:406] Convolution4 <- Eltwise1_elu_conv3_0_split_0
I0930 11:17:09.995893  3537 net.cpp:380] Convolution4 -> Convolution4
I0930 11:17:09.996688  3537 net.cpp:122] Setting up Convolution4
I0930 11:17:09.996700  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.996704  3537 net.cpp:137] Memory required for data: 91258000
I0930 11:17:09.996712  3537 layer_factory.hpp:77] Creating layer BatchNorm4
I0930 11:17:09.996726  3537 net.cpp:84] Creating Layer BatchNorm4
I0930 11:17:09.996729  3537 net.cpp:406] BatchNorm4 <- Convolution4
I0930 11:17:09.996736  3537 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0930 11:17:09.996845  3537 net.cpp:122] Setting up BatchNorm4
I0930 11:17:09.996851  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.996856  3537 net.cpp:137] Memory required for data: 96275600
I0930 11:17:09.996865  3537 layer_factory.hpp:77] Creating layer Scale4
I0930 11:17:09.996870  3537 net.cpp:84] Creating Layer Scale4
I0930 11:17:09.996875  3537 net.cpp:406] Scale4 <- Convolution4
I0930 11:17:09.996879  3537 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0930 11:17:09.996906  3537 layer_factory.hpp:77] Creating layer Scale4
I0930 11:17:09.996973  3537 net.cpp:122] Setting up Scale4
I0930 11:17:09.996978  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.996982  3537 net.cpp:137] Memory required for data: 101293200
I0930 11:17:09.996989  3537 layer_factory.hpp:77] Creating layer elu_conv4
I0930 11:17:09.996994  3537 net.cpp:84] Creating Layer elu_conv4
I0930 11:17:09.996999  3537 net.cpp:406] elu_conv4 <- Convolution4
I0930 11:17:09.997004  3537 net.cpp:367] elu_conv4 -> Convolution4 (in-place)
I0930 11:17:09.997010  3537 net.cpp:122] Setting up elu_conv4
I0930 11:17:09.997015  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.997020  3537 net.cpp:137] Memory required for data: 106310800
I0930 11:17:09.997023  3537 layer_factory.hpp:77] Creating layer Convolution5
I0930 11:17:09.997032  3537 net.cpp:84] Creating Layer Convolution5
I0930 11:17:09.997035  3537 net.cpp:406] Convolution5 <- Convolution4
I0930 11:17:09.997041  3537 net.cpp:380] Convolution5 -> Convolution5
I0930 11:17:09.997848  3537 net.cpp:122] Setting up Convolution5
I0930 11:17:09.997859  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.997864  3537 net.cpp:137] Memory required for data: 111328400
I0930 11:17:09.997871  3537 layer_factory.hpp:77] Creating layer BatchNorm5
I0930 11:17:09.997879  3537 net.cpp:84] Creating Layer BatchNorm5
I0930 11:17:09.997882  3537 net.cpp:406] BatchNorm5 <- Convolution5
I0930 11:17:09.997889  3537 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0930 11:17:09.998008  3537 net.cpp:122] Setting up BatchNorm5
I0930 11:17:09.998014  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.998018  3537 net.cpp:137] Memory required for data: 116346000
I0930 11:17:09.998029  3537 layer_factory.hpp:77] Creating layer Scale5
I0930 11:17:09.998035  3537 net.cpp:84] Creating Layer Scale5
I0930 11:17:09.998039  3537 net.cpp:406] Scale5 <- Convolution5
I0930 11:17:09.998044  3537 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0930 11:17:09.998071  3537 layer_factory.hpp:77] Creating layer Scale5
I0930 11:17:09.998144  3537 net.cpp:122] Setting up Scale5
I0930 11:17:09.998149  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.998153  3537 net.cpp:137] Memory required for data: 121363600
I0930 11:17:09.998160  3537 layer_factory.hpp:77] Creating layer Eltwise2
I0930 11:17:09.998167  3537 net.cpp:84] Creating Layer Eltwise2
I0930 11:17:09.998170  3537 net.cpp:406] Eltwise2 <- Eltwise1_elu_conv3_0_split_1
I0930 11:17:09.998175  3537 net.cpp:406] Eltwise2 <- Convolution5
I0930 11:17:09.998181  3537 net.cpp:380] Eltwise2 -> Eltwise2
I0930 11:17:09.998198  3537 net.cpp:122] Setting up Eltwise2
I0930 11:17:09.998203  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.998208  3537 net.cpp:137] Memory required for data: 126381200
I0930 11:17:09.998211  3537 layer_factory.hpp:77] Creating layer elu_conv5
I0930 11:17:09.998217  3537 net.cpp:84] Creating Layer elu_conv5
I0930 11:17:09.998221  3537 net.cpp:406] elu_conv5 <- Eltwise2
I0930 11:17:09.998227  3537 net.cpp:367] elu_conv5 -> Eltwise2 (in-place)
I0930 11:17:09.998232  3537 net.cpp:122] Setting up elu_conv5
I0930 11:17:09.998237  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.998241  3537 net.cpp:137] Memory required for data: 131398800
I0930 11:17:09.998252  3537 layer_factory.hpp:77] Creating layer Eltwise2_elu_conv5_0_split
I0930 11:17:09.998258  3537 net.cpp:84] Creating Layer Eltwise2_elu_conv5_0_split
I0930 11:17:09.998262  3537 net.cpp:406] Eltwise2_elu_conv5_0_split <- Eltwise2
I0930 11:17:09.998267  3537 net.cpp:380] Eltwise2_elu_conv5_0_split -> Eltwise2_elu_conv5_0_split_0
I0930 11:17:09.998273  3537 net.cpp:380] Eltwise2_elu_conv5_0_split -> Eltwise2_elu_conv5_0_split_1
I0930 11:17:09.998298  3537 net.cpp:122] Setting up Eltwise2_elu_conv5_0_split
I0930 11:17:09.998303  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.998308  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.998312  3537 net.cpp:137] Memory required for data: 141434000
I0930 11:17:09.998317  3537 layer_factory.hpp:77] Creating layer Convolution6
I0930 11:17:09.998325  3537 net.cpp:84] Creating Layer Convolution6
I0930 11:17:09.998328  3537 net.cpp:406] Convolution6 <- Eltwise2_elu_conv5_0_split_0
I0930 11:17:09.998337  3537 net.cpp:380] Convolution6 -> Convolution6
I0930 11:17:09.999189  3537 net.cpp:122] Setting up Convolution6
I0930 11:17:09.999199  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.999205  3537 net.cpp:137] Memory required for data: 146451600
I0930 11:17:09.999212  3537 layer_factory.hpp:77] Creating layer BatchNorm6
I0930 11:17:09.999220  3537 net.cpp:84] Creating Layer BatchNorm6
I0930 11:17:09.999223  3537 net.cpp:406] BatchNorm6 <- Convolution6
I0930 11:17:09.999229  3537 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0930 11:17:09.999354  3537 net.cpp:122] Setting up BatchNorm6
I0930 11:17:09.999361  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.999364  3537 net.cpp:137] Memory required for data: 151469200
I0930 11:17:09.999372  3537 layer_factory.hpp:77] Creating layer Scale6
I0930 11:17:09.999377  3537 net.cpp:84] Creating Layer Scale6
I0930 11:17:09.999382  3537 net.cpp:406] Scale6 <- Convolution6
I0930 11:17:09.999387  3537 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0930 11:17:09.999415  3537 layer_factory.hpp:77] Creating layer Scale6
I0930 11:17:09.999487  3537 net.cpp:122] Setting up Scale6
I0930 11:17:09.999493  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.999497  3537 net.cpp:137] Memory required for data: 156486800
I0930 11:17:09.999503  3537 layer_factory.hpp:77] Creating layer elu_conv6
I0930 11:17:09.999511  3537 net.cpp:84] Creating Layer elu_conv6
I0930 11:17:09.999514  3537 net.cpp:406] elu_conv6 <- Convolution6
I0930 11:17:09.999519  3537 net.cpp:367] elu_conv6 -> Convolution6 (in-place)
I0930 11:17:09.999526  3537 net.cpp:122] Setting up elu_conv6
I0930 11:17:09.999531  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:09.999534  3537 net.cpp:137] Memory required for data: 161504400
I0930 11:17:09.999538  3537 layer_factory.hpp:77] Creating layer Convolution7
I0930 11:17:09.999548  3537 net.cpp:84] Creating Layer Convolution7
I0930 11:17:09.999552  3537 net.cpp:406] Convolution7 <- Convolution6
I0930 11:17:09.999557  3537 net.cpp:380] Convolution7 -> Convolution7
I0930 11:17:10.000075  3537 net.cpp:122] Setting up Convolution7
I0930 11:17:10.000084  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.000089  3537 net.cpp:137] Memory required for data: 166522000
I0930 11:17:10.000097  3537 layer_factory.hpp:77] Creating layer BatchNorm7
I0930 11:17:10.000103  3537 net.cpp:84] Creating Layer BatchNorm7
I0930 11:17:10.000108  3537 net.cpp:406] BatchNorm7 <- Convolution7
I0930 11:17:10.000113  3537 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0930 11:17:10.000236  3537 net.cpp:122] Setting up BatchNorm7
I0930 11:17:10.000241  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.000246  3537 net.cpp:137] Memory required for data: 171539600
I0930 11:17:10.000253  3537 layer_factory.hpp:77] Creating layer Scale7
I0930 11:17:10.000260  3537 net.cpp:84] Creating Layer Scale7
I0930 11:17:10.000263  3537 net.cpp:406] Scale7 <- Convolution7
I0930 11:17:10.000270  3537 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0930 11:17:10.000305  3537 layer_factory.hpp:77] Creating layer Scale7
I0930 11:17:10.000380  3537 net.cpp:122] Setting up Scale7
I0930 11:17:10.000386  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.000391  3537 net.cpp:137] Memory required for data: 176557200
I0930 11:17:10.000397  3537 layer_factory.hpp:77] Creating layer Eltwise3
I0930 11:17:10.000403  3537 net.cpp:84] Creating Layer Eltwise3
I0930 11:17:10.000407  3537 net.cpp:406] Eltwise3 <- Eltwise2_elu_conv5_0_split_1
I0930 11:17:10.000412  3537 net.cpp:406] Eltwise3 <- Convolution7
I0930 11:17:10.000418  3537 net.cpp:380] Eltwise3 -> Eltwise3
I0930 11:17:10.000435  3537 net.cpp:122] Setting up Eltwise3
I0930 11:17:10.000442  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.000445  3537 net.cpp:137] Memory required for data: 181574800
I0930 11:17:10.000449  3537 layer_factory.hpp:77] Creating layer elu_conv7
I0930 11:17:10.000455  3537 net.cpp:84] Creating Layer elu_conv7
I0930 11:17:10.000459  3537 net.cpp:406] elu_conv7 <- Eltwise3
I0930 11:17:10.000464  3537 net.cpp:367] elu_conv7 -> Eltwise3 (in-place)
I0930 11:17:10.000470  3537 net.cpp:122] Setting up elu_conv7
I0930 11:17:10.000475  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.000479  3537 net.cpp:137] Memory required for data: 186592400
I0930 11:17:10.000483  3537 layer_factory.hpp:77] Creating layer Eltwise3_elu_conv7_0_split
I0930 11:17:10.000489  3537 net.cpp:84] Creating Layer Eltwise3_elu_conv7_0_split
I0930 11:17:10.000493  3537 net.cpp:406] Eltwise3_elu_conv7_0_split <- Eltwise3
I0930 11:17:10.000499  3537 net.cpp:380] Eltwise3_elu_conv7_0_split -> Eltwise3_elu_conv7_0_split_0
I0930 11:17:10.000504  3537 net.cpp:380] Eltwise3_elu_conv7_0_split -> Eltwise3_elu_conv7_0_split_1
I0930 11:17:10.000526  3537 net.cpp:122] Setting up Eltwise3_elu_conv7_0_split
I0930 11:17:10.000531  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.000536  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.000540  3537 net.cpp:137] Memory required for data: 196627600
I0930 11:17:10.000545  3537 layer_factory.hpp:77] Creating layer Convolution8
I0930 11:17:10.000555  3537 net.cpp:84] Creating Layer Convolution8
I0930 11:17:10.000558  3537 net.cpp:406] Convolution8 <- Eltwise3_elu_conv7_0_split_0
I0930 11:17:10.000564  3537 net.cpp:380] Convolution8 -> Convolution8
I0930 11:17:10.001402  3537 net.cpp:122] Setting up Convolution8
I0930 11:17:10.001413  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.001418  3537 net.cpp:137] Memory required for data: 201645200
I0930 11:17:10.001425  3537 layer_factory.hpp:77] Creating layer BatchNorm8
I0930 11:17:10.001433  3537 net.cpp:84] Creating Layer BatchNorm8
I0930 11:17:10.001436  3537 net.cpp:406] BatchNorm8 <- Convolution8
I0930 11:17:10.001442  3537 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0930 11:17:10.001569  3537 net.cpp:122] Setting up BatchNorm8
I0930 11:17:10.001574  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.001579  3537 net.cpp:137] Memory required for data: 206662800
I0930 11:17:10.001586  3537 layer_factory.hpp:77] Creating layer Scale8
I0930 11:17:10.001592  3537 net.cpp:84] Creating Layer Scale8
I0930 11:17:10.001596  3537 net.cpp:406] Scale8 <- Convolution8
I0930 11:17:10.001601  3537 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0930 11:17:10.001631  3537 layer_factory.hpp:77] Creating layer Scale8
I0930 11:17:10.001704  3537 net.cpp:122] Setting up Scale8
I0930 11:17:10.001709  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.001713  3537 net.cpp:137] Memory required for data: 211680400
I0930 11:17:10.001720  3537 layer_factory.hpp:77] Creating layer elu_conv8
I0930 11:17:10.001725  3537 net.cpp:84] Creating Layer elu_conv8
I0930 11:17:10.001730  3537 net.cpp:406] elu_conv8 <- Convolution8
I0930 11:17:10.001736  3537 net.cpp:367] elu_conv8 -> Convolution8 (in-place)
I0930 11:17:10.001742  3537 net.cpp:122] Setting up elu_conv8
I0930 11:17:10.001747  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.001757  3537 net.cpp:137] Memory required for data: 216698000
I0930 11:17:10.001762  3537 layer_factory.hpp:77] Creating layer Convolution9
I0930 11:17:10.001772  3537 net.cpp:84] Creating Layer Convolution9
I0930 11:17:10.001775  3537 net.cpp:406] Convolution9 <- Convolution8
I0930 11:17:10.001781  3537 net.cpp:380] Convolution9 -> Convolution9
I0930 11:17:10.002671  3537 net.cpp:122] Setting up Convolution9
I0930 11:17:10.002692  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.002696  3537 net.cpp:137] Memory required for data: 221715600
I0930 11:17:10.002701  3537 layer_factory.hpp:77] Creating layer BatchNorm9
I0930 11:17:10.002707  3537 net.cpp:84] Creating Layer BatchNorm9
I0930 11:17:10.002712  3537 net.cpp:406] BatchNorm9 <- Convolution9
I0930 11:17:10.002719  3537 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0930 11:17:10.002856  3537 net.cpp:122] Setting up BatchNorm9
I0930 11:17:10.002861  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.002873  3537 net.cpp:137] Memory required for data: 226733200
I0930 11:17:10.002879  3537 layer_factory.hpp:77] Creating layer Scale9
I0930 11:17:10.002885  3537 net.cpp:84] Creating Layer Scale9
I0930 11:17:10.002888  3537 net.cpp:406] Scale9 <- Convolution9
I0930 11:17:10.002893  3537 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0930 11:17:10.002930  3537 layer_factory.hpp:77] Creating layer Scale9
I0930 11:17:10.003017  3537 net.cpp:122] Setting up Scale9
I0930 11:17:10.003023  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.003027  3537 net.cpp:137] Memory required for data: 231750800
I0930 11:17:10.003034  3537 layer_factory.hpp:77] Creating layer Eltwise4
I0930 11:17:10.003041  3537 net.cpp:84] Creating Layer Eltwise4
I0930 11:17:10.003044  3537 net.cpp:406] Eltwise4 <- Eltwise3_elu_conv7_0_split_1
I0930 11:17:10.003049  3537 net.cpp:406] Eltwise4 <- Convolution9
I0930 11:17:10.003057  3537 net.cpp:380] Eltwise4 -> Eltwise4
I0930 11:17:10.003073  3537 net.cpp:122] Setting up Eltwise4
I0930 11:17:10.003079  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.003083  3537 net.cpp:137] Memory required for data: 236768400
I0930 11:17:10.003087  3537 layer_factory.hpp:77] Creating layer elu_conv9
I0930 11:17:10.003090  3537 net.cpp:84] Creating Layer elu_conv9
I0930 11:17:10.003093  3537 net.cpp:406] elu_conv9 <- Eltwise4
I0930 11:17:10.003096  3537 net.cpp:367] elu_conv9 -> Eltwise4 (in-place)
I0930 11:17:10.003099  3537 net.cpp:122] Setting up elu_conv9
I0930 11:17:10.003103  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.003105  3537 net.cpp:137] Memory required for data: 241786000
I0930 11:17:10.003108  3537 layer_factory.hpp:77] Creating layer Eltwise4_elu_conv9_0_split
I0930 11:17:10.003110  3537 net.cpp:84] Creating Layer Eltwise4_elu_conv9_0_split
I0930 11:17:10.003113  3537 net.cpp:406] Eltwise4_elu_conv9_0_split <- Eltwise4
I0930 11:17:10.003116  3537 net.cpp:380] Eltwise4_elu_conv9_0_split -> Eltwise4_elu_conv9_0_split_0
I0930 11:17:10.003120  3537 net.cpp:380] Eltwise4_elu_conv9_0_split -> Eltwise4_elu_conv9_0_split_1
I0930 11:17:10.003141  3537 net.cpp:122] Setting up Eltwise4_elu_conv9_0_split
I0930 11:17:10.003144  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.003147  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.003150  3537 net.cpp:137] Memory required for data: 251821200
I0930 11:17:10.003152  3537 layer_factory.hpp:77] Creating layer Convolution10
I0930 11:17:10.003159  3537 net.cpp:84] Creating Layer Convolution10
I0930 11:17:10.003161  3537 net.cpp:406] Convolution10 <- Eltwise4_elu_conv9_0_split_0
I0930 11:17:10.003165  3537 net.cpp:380] Convolution10 -> Convolution10
I0930 11:17:10.004057  3537 net.cpp:122] Setting up Convolution10
I0930 11:17:10.004067  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.004081  3537 net.cpp:137] Memory required for data: 256838800
I0930 11:17:10.004093  3537 layer_factory.hpp:77] Creating layer BatchNorm10
I0930 11:17:10.004107  3537 net.cpp:84] Creating Layer BatchNorm10
I0930 11:17:10.004112  3537 net.cpp:406] BatchNorm10 <- Convolution10
I0930 11:17:10.004114  3537 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0930 11:17:10.004251  3537 net.cpp:122] Setting up BatchNorm10
I0930 11:17:10.004256  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.004258  3537 net.cpp:137] Memory required for data: 261856400
I0930 11:17:10.004274  3537 layer_factory.hpp:77] Creating layer Scale10
I0930 11:17:10.004279  3537 net.cpp:84] Creating Layer Scale10
I0930 11:17:10.004281  3537 net.cpp:406] Scale10 <- Convolution10
I0930 11:17:10.004286  3537 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0930 11:17:10.004324  3537 layer_factory.hpp:77] Creating layer Scale10
I0930 11:17:10.004431  3537 net.cpp:122] Setting up Scale10
I0930 11:17:10.004437  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.004441  3537 net.cpp:137] Memory required for data: 266874000
I0930 11:17:10.004444  3537 layer_factory.hpp:77] Creating layer elu_conv10
I0930 11:17:10.004448  3537 net.cpp:84] Creating Layer elu_conv10
I0930 11:17:10.004451  3537 net.cpp:406] elu_conv10 <- Convolution10
I0930 11:17:10.004456  3537 net.cpp:367] elu_conv10 -> Convolution10 (in-place)
I0930 11:17:10.004461  3537 net.cpp:122] Setting up elu_conv10
I0930 11:17:10.004463  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.004467  3537 net.cpp:137] Memory required for data: 271891600
I0930 11:17:10.004469  3537 layer_factory.hpp:77] Creating layer Convolution11
I0930 11:17:10.004477  3537 net.cpp:84] Creating Layer Convolution11
I0930 11:17:10.004480  3537 net.cpp:406] Convolution11 <- Convolution10
I0930 11:17:10.004484  3537 net.cpp:380] Convolution11 -> Convolution11
I0930 11:17:10.005434  3537 net.cpp:122] Setting up Convolution11
I0930 11:17:10.005445  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.005448  3537 net.cpp:137] Memory required for data: 276909200
I0930 11:17:10.005453  3537 layer_factory.hpp:77] Creating layer BatchNorm11
I0930 11:17:10.005458  3537 net.cpp:84] Creating Layer BatchNorm11
I0930 11:17:10.005461  3537 net.cpp:406] BatchNorm11 <- Convolution11
I0930 11:17:10.005465  3537 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0930 11:17:10.005592  3537 net.cpp:122] Setting up BatchNorm11
I0930 11:17:10.005597  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.005600  3537 net.cpp:137] Memory required for data: 281926800
I0930 11:17:10.005605  3537 layer_factory.hpp:77] Creating layer Scale11
I0930 11:17:10.005609  3537 net.cpp:84] Creating Layer Scale11
I0930 11:17:10.005612  3537 net.cpp:406] Scale11 <- Convolution11
I0930 11:17:10.005617  3537 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0930 11:17:10.005641  3537 layer_factory.hpp:77] Creating layer Scale11
I0930 11:17:10.005714  3537 net.cpp:122] Setting up Scale11
I0930 11:17:10.005719  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.005722  3537 net.cpp:137] Memory required for data: 286944400
I0930 11:17:10.005726  3537 layer_factory.hpp:77] Creating layer Eltwise5
I0930 11:17:10.005731  3537 net.cpp:84] Creating Layer Eltwise5
I0930 11:17:10.005734  3537 net.cpp:406] Eltwise5 <- Eltwise4_elu_conv9_0_split_1
I0930 11:17:10.005738  3537 net.cpp:406] Eltwise5 <- Convolution11
I0930 11:17:10.005743  3537 net.cpp:380] Eltwise5 -> Eltwise5
I0930 11:17:10.005756  3537 net.cpp:122] Setting up Eltwise5
I0930 11:17:10.005762  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.005764  3537 net.cpp:137] Memory required for data: 291962000
I0930 11:17:10.005767  3537 layer_factory.hpp:77] Creating layer elu_conv11
I0930 11:17:10.005770  3537 net.cpp:84] Creating Layer elu_conv11
I0930 11:17:10.005774  3537 net.cpp:406] elu_conv11 <- Eltwise5
I0930 11:17:10.005776  3537 net.cpp:367] elu_conv11 -> Eltwise5 (in-place)
I0930 11:17:10.005780  3537 net.cpp:122] Setting up elu_conv11
I0930 11:17:10.005784  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.005787  3537 net.cpp:137] Memory required for data: 296979600
I0930 11:17:10.005796  3537 layer_factory.hpp:77] Creating layer Eltwise5_elu_conv11_0_split
I0930 11:17:10.005800  3537 net.cpp:84] Creating Layer Eltwise5_elu_conv11_0_split
I0930 11:17:10.005802  3537 net.cpp:406] Eltwise5_elu_conv11_0_split <- Eltwise5
I0930 11:17:10.005807  3537 net.cpp:380] Eltwise5_elu_conv11_0_split -> Eltwise5_elu_conv11_0_split_0
I0930 11:17:10.005811  3537 net.cpp:380] Eltwise5_elu_conv11_0_split -> Eltwise5_elu_conv11_0_split_1
I0930 11:17:10.005833  3537 net.cpp:122] Setting up Eltwise5_elu_conv11_0_split
I0930 11:17:10.005837  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.005841  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.005844  3537 net.cpp:137] Memory required for data: 307014800
I0930 11:17:10.005847  3537 layer_factory.hpp:77] Creating layer Convolution12
I0930 11:17:10.005853  3537 net.cpp:84] Creating Layer Convolution12
I0930 11:17:10.005856  3537 net.cpp:406] Convolution12 <- Eltwise5_elu_conv11_0_split_0
I0930 11:17:10.005861  3537 net.cpp:380] Convolution12 -> Convolution12
I0930 11:17:10.006768  3537 net.cpp:122] Setting up Convolution12
I0930 11:17:10.006779  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.006783  3537 net.cpp:137] Memory required for data: 312032400
I0930 11:17:10.006788  3537 layer_factory.hpp:77] Creating layer BatchNorm12
I0930 11:17:10.006794  3537 net.cpp:84] Creating Layer BatchNorm12
I0930 11:17:10.006798  3537 net.cpp:406] BatchNorm12 <- Convolution12
I0930 11:17:10.006803  3537 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0930 11:17:10.006930  3537 net.cpp:122] Setting up BatchNorm12
I0930 11:17:10.006937  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.006939  3537 net.cpp:137] Memory required for data: 317050000
I0930 11:17:10.006944  3537 layer_factory.hpp:77] Creating layer Scale12
I0930 11:17:10.006949  3537 net.cpp:84] Creating Layer Scale12
I0930 11:17:10.006953  3537 net.cpp:406] Scale12 <- Convolution12
I0930 11:17:10.006956  3537 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0930 11:17:10.006983  3537 layer_factory.hpp:77] Creating layer Scale12
I0930 11:17:10.007058  3537 net.cpp:122] Setting up Scale12
I0930 11:17:10.007063  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.007066  3537 net.cpp:137] Memory required for data: 322067600
I0930 11:17:10.007071  3537 layer_factory.hpp:77] Creating layer elu_conv12
I0930 11:17:10.007076  3537 net.cpp:84] Creating Layer elu_conv12
I0930 11:17:10.007078  3537 net.cpp:406] elu_conv12 <- Convolution12
I0930 11:17:10.007081  3537 net.cpp:367] elu_conv12 -> Convolution12 (in-place)
I0930 11:17:10.007086  3537 net.cpp:122] Setting up elu_conv12
I0930 11:17:10.007091  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.007092  3537 net.cpp:137] Memory required for data: 327085200
I0930 11:17:10.007095  3537 layer_factory.hpp:77] Creating layer Convolution13
I0930 11:17:10.007102  3537 net.cpp:84] Creating Layer Convolution13
I0930 11:17:10.007104  3537 net.cpp:406] Convolution13 <- Convolution12
I0930 11:17:10.007109  3537 net.cpp:380] Convolution13 -> Convolution13
I0930 11:17:10.007994  3537 net.cpp:122] Setting up Convolution13
I0930 11:17:10.008007  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.008009  3537 net.cpp:137] Memory required for data: 332102800
I0930 11:17:10.008014  3537 layer_factory.hpp:77] Creating layer BatchNorm13
I0930 11:17:10.008019  3537 net.cpp:84] Creating Layer BatchNorm13
I0930 11:17:10.008023  3537 net.cpp:406] BatchNorm13 <- Convolution13
I0930 11:17:10.008028  3537 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0930 11:17:10.008157  3537 net.cpp:122] Setting up BatchNorm13
I0930 11:17:10.008162  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.008165  3537 net.cpp:137] Memory required for data: 337120400
I0930 11:17:10.008170  3537 layer_factory.hpp:77] Creating layer Scale13
I0930 11:17:10.008175  3537 net.cpp:84] Creating Layer Scale13
I0930 11:17:10.008185  3537 net.cpp:406] Scale13 <- Convolution13
I0930 11:17:10.008190  3537 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0930 11:17:10.008219  3537 layer_factory.hpp:77] Creating layer Scale13
I0930 11:17:10.008298  3537 net.cpp:122] Setting up Scale13
I0930 11:17:10.008303  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.008306  3537 net.cpp:137] Memory required for data: 342138000
I0930 11:17:10.008311  3537 layer_factory.hpp:77] Creating layer Eltwise6
I0930 11:17:10.008316  3537 net.cpp:84] Creating Layer Eltwise6
I0930 11:17:10.008318  3537 net.cpp:406] Eltwise6 <- Eltwise5_elu_conv11_0_split_1
I0930 11:17:10.008322  3537 net.cpp:406] Eltwise6 <- Convolution13
I0930 11:17:10.008327  3537 net.cpp:380] Eltwise6 -> Eltwise6
I0930 11:17:10.008347  3537 net.cpp:122] Setting up Eltwise6
I0930 11:17:10.008352  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.008355  3537 net.cpp:137] Memory required for data: 347155600
I0930 11:17:10.008358  3537 layer_factory.hpp:77] Creating layer elu_conv13
I0930 11:17:10.008365  3537 net.cpp:84] Creating Layer elu_conv13
I0930 11:17:10.008368  3537 net.cpp:406] elu_conv13 <- Eltwise6
I0930 11:17:10.008373  3537 net.cpp:367] elu_conv13 -> Eltwise6 (in-place)
I0930 11:17:10.008376  3537 net.cpp:122] Setting up elu_conv13
I0930 11:17:10.008380  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.008383  3537 net.cpp:137] Memory required for data: 352173200
I0930 11:17:10.008385  3537 layer_factory.hpp:77] Creating layer Eltwise6_elu_conv13_0_split
I0930 11:17:10.008389  3537 net.cpp:84] Creating Layer Eltwise6_elu_conv13_0_split
I0930 11:17:10.008393  3537 net.cpp:406] Eltwise6_elu_conv13_0_split <- Eltwise6
I0930 11:17:10.008396  3537 net.cpp:380] Eltwise6_elu_conv13_0_split -> Eltwise6_elu_conv13_0_split_0
I0930 11:17:10.008400  3537 net.cpp:380] Eltwise6_elu_conv13_0_split -> Eltwise6_elu_conv13_0_split_1
I0930 11:17:10.008422  3537 net.cpp:122] Setting up Eltwise6_elu_conv13_0_split
I0930 11:17:10.008426  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.008430  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.008431  3537 net.cpp:137] Memory required for data: 362208400
I0930 11:17:10.008433  3537 layer_factory.hpp:77] Creating layer Convolution14
I0930 11:17:10.008441  3537 net.cpp:84] Creating Layer Convolution14
I0930 11:17:10.008445  3537 net.cpp:406] Convolution14 <- Eltwise6_elu_conv13_0_split_0
I0930 11:17:10.008450  3537 net.cpp:380] Convolution14 -> Convolution14
I0930 11:17:10.009341  3537 net.cpp:122] Setting up Convolution14
I0930 11:17:10.009351  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.009353  3537 net.cpp:137] Memory required for data: 367226000
I0930 11:17:10.009357  3537 layer_factory.hpp:77] Creating layer BatchNorm14
I0930 11:17:10.009362  3537 net.cpp:84] Creating Layer BatchNorm14
I0930 11:17:10.009364  3537 net.cpp:406] BatchNorm14 <- Convolution14
I0930 11:17:10.009369  3537 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0930 11:17:10.009502  3537 net.cpp:122] Setting up BatchNorm14
I0930 11:17:10.009506  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.009508  3537 net.cpp:137] Memory required for data: 372243600
I0930 11:17:10.009513  3537 layer_factory.hpp:77] Creating layer Scale14
I0930 11:17:10.009518  3537 net.cpp:84] Creating Layer Scale14
I0930 11:17:10.009521  3537 net.cpp:406] Scale14 <- Convolution14
I0930 11:17:10.009524  3537 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0930 11:17:10.009549  3537 layer_factory.hpp:77] Creating layer Scale14
I0930 11:17:10.009626  3537 net.cpp:122] Setting up Scale14
I0930 11:17:10.009631  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.009634  3537 net.cpp:137] Memory required for data: 377261200
I0930 11:17:10.009637  3537 layer_factory.hpp:77] Creating layer elu_conv14
I0930 11:17:10.009641  3537 net.cpp:84] Creating Layer elu_conv14
I0930 11:17:10.009644  3537 net.cpp:406] elu_conv14 <- Convolution14
I0930 11:17:10.009647  3537 net.cpp:367] elu_conv14 -> Convolution14 (in-place)
I0930 11:17:10.009658  3537 net.cpp:122] Setting up elu_conv14
I0930 11:17:10.009662  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.009665  3537 net.cpp:137] Memory required for data: 382278800
I0930 11:17:10.009666  3537 layer_factory.hpp:77] Creating layer Convolution15
I0930 11:17:10.009675  3537 net.cpp:84] Creating Layer Convolution15
I0930 11:17:10.009676  3537 net.cpp:406] Convolution15 <- Convolution14
I0930 11:17:10.009680  3537 net.cpp:380] Convolution15 -> Convolution15
I0930 11:17:10.010584  3537 net.cpp:122] Setting up Convolution15
I0930 11:17:10.010592  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.010596  3537 net.cpp:137] Memory required for data: 387296400
I0930 11:17:10.010601  3537 layer_factory.hpp:77] Creating layer BatchNorm15
I0930 11:17:10.010607  3537 net.cpp:84] Creating Layer BatchNorm15
I0930 11:17:10.010608  3537 net.cpp:406] BatchNorm15 <- Convolution15
I0930 11:17:10.010612  3537 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0930 11:17:10.010742  3537 net.cpp:122] Setting up BatchNorm15
I0930 11:17:10.010747  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.010749  3537 net.cpp:137] Memory required for data: 392314000
I0930 11:17:10.010754  3537 layer_factory.hpp:77] Creating layer Scale15
I0930 11:17:10.010759  3537 net.cpp:84] Creating Layer Scale15
I0930 11:17:10.010761  3537 net.cpp:406] Scale15 <- Convolution15
I0930 11:17:10.010764  3537 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0930 11:17:10.010789  3537 layer_factory.hpp:77] Creating layer Scale15
I0930 11:17:10.010872  3537 net.cpp:122] Setting up Scale15
I0930 11:17:10.010876  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.010879  3537 net.cpp:137] Memory required for data: 397331600
I0930 11:17:10.010884  3537 layer_factory.hpp:77] Creating layer Eltwise7
I0930 11:17:10.010886  3537 net.cpp:84] Creating Layer Eltwise7
I0930 11:17:10.010890  3537 net.cpp:406] Eltwise7 <- Eltwise6_elu_conv13_0_split_1
I0930 11:17:10.010892  3537 net.cpp:406] Eltwise7 <- Convolution15
I0930 11:17:10.010896  3537 net.cpp:380] Eltwise7 -> Eltwise7
I0930 11:17:10.010910  3537 net.cpp:122] Setting up Eltwise7
I0930 11:17:10.010913  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.010915  3537 net.cpp:137] Memory required for data: 402349200
I0930 11:17:10.010917  3537 layer_factory.hpp:77] Creating layer elu_conv15
I0930 11:17:10.010922  3537 net.cpp:84] Creating Layer elu_conv15
I0930 11:17:10.010924  3537 net.cpp:406] elu_conv15 <- Eltwise7
I0930 11:17:10.010927  3537 net.cpp:367] elu_conv15 -> Eltwise7 (in-place)
I0930 11:17:10.010931  3537 net.cpp:122] Setting up elu_conv15
I0930 11:17:10.010934  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.010936  3537 net.cpp:137] Memory required for data: 407366800
I0930 11:17:10.010938  3537 layer_factory.hpp:77] Creating layer Eltwise7_elu_conv15_0_split
I0930 11:17:10.010941  3537 net.cpp:84] Creating Layer Eltwise7_elu_conv15_0_split
I0930 11:17:10.010943  3537 net.cpp:406] Eltwise7_elu_conv15_0_split <- Eltwise7
I0930 11:17:10.010946  3537 net.cpp:380] Eltwise7_elu_conv15_0_split -> Eltwise7_elu_conv15_0_split_0
I0930 11:17:10.010951  3537 net.cpp:380] Eltwise7_elu_conv15_0_split -> Eltwise7_elu_conv15_0_split_1
I0930 11:17:10.010972  3537 net.cpp:122] Setting up Eltwise7_elu_conv15_0_split
I0930 11:17:10.010975  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.010977  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.010979  3537 net.cpp:137] Memory required for data: 417402000
I0930 11:17:10.010982  3537 layer_factory.hpp:77] Creating layer Convolution16
I0930 11:17:10.010988  3537 net.cpp:84] Creating Layer Convolution16
I0930 11:17:10.010990  3537 net.cpp:406] Convolution16 <- Eltwise7_elu_conv15_0_split_0
I0930 11:17:10.010994  3537 net.cpp:380] Convolution16 -> Convolution16
I0930 11:17:10.011842  3537 net.cpp:122] Setting up Convolution16
I0930 11:17:10.011850  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.011859  3537 net.cpp:137] Memory required for data: 422419600
I0930 11:17:10.011864  3537 layer_factory.hpp:77] Creating layer BatchNorm16
I0930 11:17:10.011869  3537 net.cpp:84] Creating Layer BatchNorm16
I0930 11:17:10.011873  3537 net.cpp:406] BatchNorm16 <- Convolution16
I0930 11:17:10.011875  3537 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0930 11:17:10.012004  3537 net.cpp:122] Setting up BatchNorm16
I0930 11:17:10.012008  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.012012  3537 net.cpp:137] Memory required for data: 427437200
I0930 11:17:10.012015  3537 layer_factory.hpp:77] Creating layer Scale16
I0930 11:17:10.012019  3537 net.cpp:84] Creating Layer Scale16
I0930 11:17:10.012022  3537 net.cpp:406] Scale16 <- Convolution16
I0930 11:17:10.012027  3537 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0930 11:17:10.012049  3537 layer_factory.hpp:77] Creating layer Scale16
I0930 11:17:10.012123  3537 net.cpp:122] Setting up Scale16
I0930 11:17:10.012127  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.012130  3537 net.cpp:137] Memory required for data: 432454800
I0930 11:17:10.012133  3537 layer_factory.hpp:77] Creating layer elu_conv16
I0930 11:17:10.012136  3537 net.cpp:84] Creating Layer elu_conv16
I0930 11:17:10.012140  3537 net.cpp:406] elu_conv16 <- Convolution16
I0930 11:17:10.012143  3537 net.cpp:367] elu_conv16 -> Convolution16 (in-place)
I0930 11:17:10.012147  3537 net.cpp:122] Setting up elu_conv16
I0930 11:17:10.012151  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.012152  3537 net.cpp:137] Memory required for data: 437472400
I0930 11:17:10.012154  3537 layer_factory.hpp:77] Creating layer Convolution17
I0930 11:17:10.012161  3537 net.cpp:84] Creating Layer Convolution17
I0930 11:17:10.012163  3537 net.cpp:406] Convolution17 <- Convolution16
I0930 11:17:10.012167  3537 net.cpp:380] Convolution17 -> Convolution17
I0930 11:17:10.012706  3537 net.cpp:122] Setting up Convolution17
I0930 11:17:10.012712  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.012715  3537 net.cpp:137] Memory required for data: 442490000
I0930 11:17:10.012719  3537 layer_factory.hpp:77] Creating layer BatchNorm17
I0930 11:17:10.012723  3537 net.cpp:84] Creating Layer BatchNorm17
I0930 11:17:10.012725  3537 net.cpp:406] BatchNorm17 <- Convolution17
I0930 11:17:10.012729  3537 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0930 11:17:10.012856  3537 net.cpp:122] Setting up BatchNorm17
I0930 11:17:10.012859  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.012861  3537 net.cpp:137] Memory required for data: 447507600
I0930 11:17:10.012866  3537 layer_factory.hpp:77] Creating layer Scale17
I0930 11:17:10.012869  3537 net.cpp:84] Creating Layer Scale17
I0930 11:17:10.012872  3537 net.cpp:406] Scale17 <- Convolution17
I0930 11:17:10.012876  3537 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0930 11:17:10.012899  3537 layer_factory.hpp:77] Creating layer Scale17
I0930 11:17:10.012972  3537 net.cpp:122] Setting up Scale17
I0930 11:17:10.012976  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.012979  3537 net.cpp:137] Memory required for data: 452525200
I0930 11:17:10.012982  3537 layer_factory.hpp:77] Creating layer Eltwise8
I0930 11:17:10.012986  3537 net.cpp:84] Creating Layer Eltwise8
I0930 11:17:10.012989  3537 net.cpp:406] Eltwise8 <- Eltwise7_elu_conv15_0_split_1
I0930 11:17:10.012991  3537 net.cpp:406] Eltwise8 <- Convolution17
I0930 11:17:10.012995  3537 net.cpp:380] Eltwise8 -> Eltwise8
I0930 11:17:10.013008  3537 net.cpp:122] Setting up Eltwise8
I0930 11:17:10.013013  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.013015  3537 net.cpp:137] Memory required for data: 457542800
I0930 11:17:10.013017  3537 layer_factory.hpp:77] Creating layer elu_conv17
I0930 11:17:10.013020  3537 net.cpp:84] Creating Layer elu_conv17
I0930 11:17:10.013022  3537 net.cpp:406] elu_conv17 <- Eltwise8
I0930 11:17:10.013025  3537 net.cpp:367] elu_conv17 -> Eltwise8 (in-place)
I0930 11:17:10.013036  3537 net.cpp:122] Setting up elu_conv17
I0930 11:17:10.013038  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.013041  3537 net.cpp:137] Memory required for data: 462560400
I0930 11:17:10.013042  3537 layer_factory.hpp:77] Creating layer Eltwise8_elu_conv17_0_split
I0930 11:17:10.013046  3537 net.cpp:84] Creating Layer Eltwise8_elu_conv17_0_split
I0930 11:17:10.013048  3537 net.cpp:406] Eltwise8_elu_conv17_0_split <- Eltwise8
I0930 11:17:10.013052  3537 net.cpp:380] Eltwise8_elu_conv17_0_split -> Eltwise8_elu_conv17_0_split_0
I0930 11:17:10.013056  3537 net.cpp:380] Eltwise8_elu_conv17_0_split -> Eltwise8_elu_conv17_0_split_1
I0930 11:17:10.013077  3537 net.cpp:122] Setting up Eltwise8_elu_conv17_0_split
I0930 11:17:10.013080  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.013083  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.013085  3537 net.cpp:137] Memory required for data: 472595600
I0930 11:17:10.013087  3537 layer_factory.hpp:77] Creating layer Convolution18
I0930 11:17:10.013094  3537 net.cpp:84] Creating Layer Convolution18
I0930 11:17:10.013097  3537 net.cpp:406] Convolution18 <- Eltwise8_elu_conv17_0_split_0
I0930 11:17:10.013100  3537 net.cpp:380] Convolution18 -> Convolution18
I0930 11:17:10.013947  3537 net.cpp:122] Setting up Convolution18
I0930 11:17:10.013954  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.013957  3537 net.cpp:137] Memory required for data: 477613200
I0930 11:17:10.013962  3537 layer_factory.hpp:77] Creating layer BatchNorm18
I0930 11:17:10.013967  3537 net.cpp:84] Creating Layer BatchNorm18
I0930 11:17:10.013969  3537 net.cpp:406] BatchNorm18 <- Convolution18
I0930 11:17:10.013973  3537 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0930 11:17:10.014101  3537 net.cpp:122] Setting up BatchNorm18
I0930 11:17:10.014106  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.014108  3537 net.cpp:137] Memory required for data: 482630800
I0930 11:17:10.014112  3537 layer_factory.hpp:77] Creating layer Scale18
I0930 11:17:10.014117  3537 net.cpp:84] Creating Layer Scale18
I0930 11:17:10.014119  3537 net.cpp:406] Scale18 <- Convolution18
I0930 11:17:10.014122  3537 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0930 11:17:10.014147  3537 layer_factory.hpp:77] Creating layer Scale18
I0930 11:17:10.014221  3537 net.cpp:122] Setting up Scale18
I0930 11:17:10.014225  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.014227  3537 net.cpp:137] Memory required for data: 487648400
I0930 11:17:10.014231  3537 layer_factory.hpp:77] Creating layer elu_conv18
I0930 11:17:10.014235  3537 net.cpp:84] Creating Layer elu_conv18
I0930 11:17:10.014238  3537 net.cpp:406] elu_conv18 <- Convolution18
I0930 11:17:10.014240  3537 net.cpp:367] elu_conv18 -> Convolution18 (in-place)
I0930 11:17:10.014256  3537 net.cpp:122] Setting up elu_conv18
I0930 11:17:10.014258  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.014261  3537 net.cpp:137] Memory required for data: 492666000
I0930 11:17:10.014262  3537 layer_factory.hpp:77] Creating layer Convolution19
I0930 11:17:10.014279  3537 net.cpp:84] Creating Layer Convolution19
I0930 11:17:10.014281  3537 net.cpp:406] Convolution19 <- Convolution18
I0930 11:17:10.014286  3537 net.cpp:380] Convolution19 -> Convolution19
I0930 11:17:10.015174  3537 net.cpp:122] Setting up Convolution19
I0930 11:17:10.015183  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.015187  3537 net.cpp:137] Memory required for data: 497683600
I0930 11:17:10.015190  3537 layer_factory.hpp:77] Creating layer BatchNorm19
I0930 11:17:10.015195  3537 net.cpp:84] Creating Layer BatchNorm19
I0930 11:17:10.015198  3537 net.cpp:406] BatchNorm19 <- Convolution19
I0930 11:17:10.015202  3537 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0930 11:17:10.015328  3537 net.cpp:122] Setting up BatchNorm19
I0930 11:17:10.015332  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.015334  3537 net.cpp:137] Memory required for data: 502701200
I0930 11:17:10.015355  3537 layer_factory.hpp:77] Creating layer Scale19
I0930 11:17:10.015360  3537 net.cpp:84] Creating Layer Scale19
I0930 11:17:10.015363  3537 net.cpp:406] Scale19 <- Convolution19
I0930 11:17:10.015367  3537 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0930 11:17:10.015393  3537 layer_factory.hpp:77] Creating layer Scale19
I0930 11:17:10.015470  3537 net.cpp:122] Setting up Scale19
I0930 11:17:10.015473  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.015475  3537 net.cpp:137] Memory required for data: 507718800
I0930 11:17:10.015480  3537 layer_factory.hpp:77] Creating layer Eltwise9
I0930 11:17:10.015483  3537 net.cpp:84] Creating Layer Eltwise9
I0930 11:17:10.015486  3537 net.cpp:406] Eltwise9 <- Eltwise8_elu_conv17_0_split_1
I0930 11:17:10.015488  3537 net.cpp:406] Eltwise9 <- Convolution19
I0930 11:17:10.015491  3537 net.cpp:380] Eltwise9 -> Eltwise9
I0930 11:17:10.015506  3537 net.cpp:122] Setting up Eltwise9
I0930 11:17:10.015511  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.015512  3537 net.cpp:137] Memory required for data: 512736400
I0930 11:17:10.015514  3537 layer_factory.hpp:77] Creating layer elu_conv19
I0930 11:17:10.015518  3537 net.cpp:84] Creating Layer elu_conv19
I0930 11:17:10.015521  3537 net.cpp:406] elu_conv19 <- Eltwise9
I0930 11:17:10.015523  3537 net.cpp:367] elu_conv19 -> Eltwise9 (in-place)
I0930 11:17:10.015527  3537 net.cpp:122] Setting up elu_conv19
I0930 11:17:10.015530  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.015532  3537 net.cpp:137] Memory required for data: 517754000
I0930 11:17:10.015534  3537 layer_factory.hpp:77] Creating layer Eltwise9_elu_conv19_0_split
I0930 11:17:10.015537  3537 net.cpp:84] Creating Layer Eltwise9_elu_conv19_0_split
I0930 11:17:10.015540  3537 net.cpp:406] Eltwise9_elu_conv19_0_split <- Eltwise9
I0930 11:17:10.015543  3537 net.cpp:380] Eltwise9_elu_conv19_0_split -> Eltwise9_elu_conv19_0_split_0
I0930 11:17:10.015547  3537 net.cpp:380] Eltwise9_elu_conv19_0_split -> Eltwise9_elu_conv19_0_split_1
I0930 11:17:10.015568  3537 net.cpp:122] Setting up Eltwise9_elu_conv19_0_split
I0930 11:17:10.015571  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.015574  3537 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 11:17:10.015576  3537 net.cpp:137] Memory required for data: 527789200
I0930 11:17:10.015578  3537 layer_factory.hpp:77] Creating layer Convolution20
I0930 11:17:10.015584  3537 net.cpp:84] Creating Layer Convolution20
I0930 11:17:10.015588  3537 net.cpp:406] Convolution20 <- Eltwise9_elu_conv19_0_split_0
I0930 11:17:10.015590  3537 net.cpp:380] Convolution20 -> Convolution20
I0930 11:17:10.016719  3537 net.cpp:122] Setting up Convolution20
I0930 11:17:10.016727  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.016731  3537 net.cpp:137] Memory required for data: 530298000
I0930 11:17:10.016736  3537 layer_factory.hpp:77] Creating layer BatchNorm20
I0930 11:17:10.016739  3537 net.cpp:84] Creating Layer BatchNorm20
I0930 11:17:10.016742  3537 net.cpp:406] BatchNorm20 <- Convolution20
I0930 11:17:10.016746  3537 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0930 11:17:10.016881  3537 net.cpp:122] Setting up BatchNorm20
I0930 11:17:10.016886  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.016888  3537 net.cpp:137] Memory required for data: 532806800
I0930 11:17:10.016893  3537 layer_factory.hpp:77] Creating layer Scale20
I0930 11:17:10.016897  3537 net.cpp:84] Creating Layer Scale20
I0930 11:17:10.016899  3537 net.cpp:406] Scale20 <- Convolution20
I0930 11:17:10.016903  3537 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0930 11:17:10.016927  3537 layer_factory.hpp:77] Creating layer Scale20
I0930 11:17:10.016999  3537 net.cpp:122] Setting up Scale20
I0930 11:17:10.017004  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.017005  3537 net.cpp:137] Memory required for data: 535315600
I0930 11:17:10.017009  3537 layer_factory.hpp:77] Creating layer Convolution21
I0930 11:17:10.017021  3537 net.cpp:84] Creating Layer Convolution21
I0930 11:17:10.017024  3537 net.cpp:406] Convolution21 <- Eltwise9_elu_conv19_0_split_1
I0930 11:17:10.017029  3537 net.cpp:380] Convolution21 -> Convolution21
I0930 11:17:10.019111  3537 net.cpp:122] Setting up Convolution21
I0930 11:17:10.019132  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.019135  3537 net.cpp:137] Memory required for data: 537824400
I0930 11:17:10.019140  3537 layer_factory.hpp:77] Creating layer BatchNorm21
I0930 11:17:10.019145  3537 net.cpp:84] Creating Layer BatchNorm21
I0930 11:17:10.019157  3537 net.cpp:406] BatchNorm21 <- Convolution21
I0930 11:17:10.019161  3537 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0930 11:17:10.019297  3537 net.cpp:122] Setting up BatchNorm21
I0930 11:17:10.019302  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.019304  3537 net.cpp:137] Memory required for data: 540333200
I0930 11:17:10.019309  3537 layer_factory.hpp:77] Creating layer Scale21
I0930 11:17:10.019314  3537 net.cpp:84] Creating Layer Scale21
I0930 11:17:10.019315  3537 net.cpp:406] Scale21 <- Convolution21
I0930 11:17:10.019320  3537 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0930 11:17:10.019345  3537 layer_factory.hpp:77] Creating layer Scale21
I0930 11:17:10.019423  3537 net.cpp:122] Setting up Scale21
I0930 11:17:10.019426  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.019428  3537 net.cpp:137] Memory required for data: 542842000
I0930 11:17:10.019433  3537 layer_factory.hpp:77] Creating layer elu_conv20
I0930 11:17:10.019436  3537 net.cpp:84] Creating Layer elu_conv20
I0930 11:17:10.019439  3537 net.cpp:406] elu_conv20 <- Convolution21
I0930 11:17:10.019443  3537 net.cpp:367] elu_conv20 -> Convolution21 (in-place)
I0930 11:17:10.019448  3537 net.cpp:122] Setting up elu_conv20
I0930 11:17:10.019450  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.019453  3537 net.cpp:137] Memory required for data: 545350800
I0930 11:17:10.019454  3537 layer_factory.hpp:77] Creating layer Convolution22
I0930 11:17:10.019461  3537 net.cpp:84] Creating Layer Convolution22
I0930 11:17:10.019464  3537 net.cpp:406] Convolution22 <- Convolution21
I0930 11:17:10.019467  3537 net.cpp:380] Convolution22 -> Convolution22
I0930 11:17:10.020562  3537 net.cpp:122] Setting up Convolution22
I0930 11:17:10.020582  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.020586  3537 net.cpp:137] Memory required for data: 547859600
I0930 11:17:10.020591  3537 layer_factory.hpp:77] Creating layer BatchNorm22
I0930 11:17:10.020596  3537 net.cpp:84] Creating Layer BatchNorm22
I0930 11:17:10.020598  3537 net.cpp:406] BatchNorm22 <- Convolution22
I0930 11:17:10.020603  3537 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0930 11:17:10.020740  3537 net.cpp:122] Setting up BatchNorm22
I0930 11:17:10.020745  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.020746  3537 net.cpp:137] Memory required for data: 550368400
I0930 11:17:10.020751  3537 layer_factory.hpp:77] Creating layer Scale22
I0930 11:17:10.020757  3537 net.cpp:84] Creating Layer Scale22
I0930 11:17:10.020759  3537 net.cpp:406] Scale22 <- Convolution22
I0930 11:17:10.020763  3537 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0930 11:17:10.020790  3537 layer_factory.hpp:77] Creating layer Scale22
I0930 11:17:10.020886  3537 net.cpp:122] Setting up Scale22
I0930 11:17:10.020891  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.020894  3537 net.cpp:137] Memory required for data: 552877200
I0930 11:17:10.020897  3537 layer_factory.hpp:77] Creating layer Eltwise10
I0930 11:17:10.020903  3537 net.cpp:84] Creating Layer Eltwise10
I0930 11:17:10.020905  3537 net.cpp:406] Eltwise10 <- Convolution20
I0930 11:17:10.020908  3537 net.cpp:406] Eltwise10 <- Convolution22
I0930 11:17:10.020912  3537 net.cpp:380] Eltwise10 -> Eltwise10
I0930 11:17:10.020928  3537 net.cpp:122] Setting up Eltwise10
I0930 11:17:10.020932  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.020942  3537 net.cpp:137] Memory required for data: 555386000
I0930 11:17:10.020944  3537 layer_factory.hpp:77] Creating layer elu_conv21
I0930 11:17:10.020948  3537 net.cpp:84] Creating Layer elu_conv21
I0930 11:17:10.020951  3537 net.cpp:406] elu_conv21 <- Eltwise10
I0930 11:17:10.020954  3537 net.cpp:367] elu_conv21 -> Eltwise10 (in-place)
I0930 11:17:10.020959  3537 net.cpp:122] Setting up elu_conv21
I0930 11:17:10.020962  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.020964  3537 net.cpp:137] Memory required for data: 557894800
I0930 11:17:10.020967  3537 layer_factory.hpp:77] Creating layer Eltwise10_elu_conv21_0_split
I0930 11:17:10.020970  3537 net.cpp:84] Creating Layer Eltwise10_elu_conv21_0_split
I0930 11:17:10.020972  3537 net.cpp:406] Eltwise10_elu_conv21_0_split <- Eltwise10
I0930 11:17:10.020975  3537 net.cpp:380] Eltwise10_elu_conv21_0_split -> Eltwise10_elu_conv21_0_split_0
I0930 11:17:10.020979  3537 net.cpp:380] Eltwise10_elu_conv21_0_split -> Eltwise10_elu_conv21_0_split_1
I0930 11:17:10.021004  3537 net.cpp:122] Setting up Eltwise10_elu_conv21_0_split
I0930 11:17:10.021008  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.021011  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.021013  3537 net.cpp:137] Memory required for data: 562912400
I0930 11:17:10.021015  3537 layer_factory.hpp:77] Creating layer Convolution23
I0930 11:17:10.021021  3537 net.cpp:84] Creating Layer Convolution23
I0930 11:17:10.021024  3537 net.cpp:406] Convolution23 <- Eltwise10_elu_conv21_0_split_0
I0930 11:17:10.021029  3537 net.cpp:380] Convolution23 -> Convolution23
I0930 11:17:10.022457  3537 net.cpp:122] Setting up Convolution23
I0930 11:17:10.022465  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.022469  3537 net.cpp:137] Memory required for data: 565421200
I0930 11:17:10.022474  3537 layer_factory.hpp:77] Creating layer BatchNorm23
I0930 11:17:10.022480  3537 net.cpp:84] Creating Layer BatchNorm23
I0930 11:17:10.022481  3537 net.cpp:406] BatchNorm23 <- Convolution23
I0930 11:17:10.022485  3537 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0930 11:17:10.022656  3537 net.cpp:122] Setting up BatchNorm23
I0930 11:17:10.022662  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.022665  3537 net.cpp:137] Memory required for data: 567930000
I0930 11:17:10.022670  3537 layer_factory.hpp:77] Creating layer Scale23
I0930 11:17:10.022675  3537 net.cpp:84] Creating Layer Scale23
I0930 11:17:10.022676  3537 net.cpp:406] Scale23 <- Convolution23
I0930 11:17:10.022680  3537 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0930 11:17:10.022714  3537 layer_factory.hpp:77] Creating layer Scale23
I0930 11:17:10.022789  3537 net.cpp:122] Setting up Scale23
I0930 11:17:10.022792  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.022794  3537 net.cpp:137] Memory required for data: 570438800
I0930 11:17:10.022799  3537 layer_factory.hpp:77] Creating layer elu_conv22
I0930 11:17:10.022802  3537 net.cpp:84] Creating Layer elu_conv22
I0930 11:17:10.022804  3537 net.cpp:406] elu_conv22 <- Convolution23
I0930 11:17:10.022809  3537 net.cpp:367] elu_conv22 -> Convolution23 (in-place)
I0930 11:17:10.022812  3537 net.cpp:122] Setting up elu_conv22
I0930 11:17:10.022815  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.022817  3537 net.cpp:137] Memory required for data: 572947600
I0930 11:17:10.022819  3537 layer_factory.hpp:77] Creating layer Convolution24
I0930 11:17:10.022827  3537 net.cpp:84] Creating Layer Convolution24
I0930 11:17:10.022830  3537 net.cpp:406] Convolution24 <- Convolution23
I0930 11:17:10.022833  3537 net.cpp:380] Convolution24 -> Convolution24
I0930 11:17:10.023965  3537 net.cpp:122] Setting up Convolution24
I0930 11:17:10.023973  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.023977  3537 net.cpp:137] Memory required for data: 575456400
I0930 11:17:10.023980  3537 layer_factory.hpp:77] Creating layer BatchNorm24
I0930 11:17:10.023985  3537 net.cpp:84] Creating Layer BatchNorm24
I0930 11:17:10.023995  3537 net.cpp:406] BatchNorm24 <- Convolution24
I0930 11:17:10.024001  3537 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0930 11:17:10.024132  3537 net.cpp:122] Setting up BatchNorm24
I0930 11:17:10.024137  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.024138  3537 net.cpp:137] Memory required for data: 577965200
I0930 11:17:10.024142  3537 layer_factory.hpp:77] Creating layer Scale24
I0930 11:17:10.024147  3537 net.cpp:84] Creating Layer Scale24
I0930 11:17:10.024149  3537 net.cpp:406] Scale24 <- Convolution24
I0930 11:17:10.024153  3537 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0930 11:17:10.024178  3537 layer_factory.hpp:77] Creating layer Scale24
I0930 11:17:10.024251  3537 net.cpp:122] Setting up Scale24
I0930 11:17:10.024255  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.024257  3537 net.cpp:137] Memory required for data: 580474000
I0930 11:17:10.024261  3537 layer_factory.hpp:77] Creating layer Eltwise11
I0930 11:17:10.024266  3537 net.cpp:84] Creating Layer Eltwise11
I0930 11:17:10.024267  3537 net.cpp:406] Eltwise11 <- Eltwise10_elu_conv21_0_split_1
I0930 11:17:10.024271  3537 net.cpp:406] Eltwise11 <- Convolution24
I0930 11:17:10.024276  3537 net.cpp:380] Eltwise11 -> Eltwise11
I0930 11:17:10.024291  3537 net.cpp:122] Setting up Eltwise11
I0930 11:17:10.024296  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.024297  3537 net.cpp:137] Memory required for data: 582982800
I0930 11:17:10.024299  3537 layer_factory.hpp:77] Creating layer elu_conv23
I0930 11:17:10.024302  3537 net.cpp:84] Creating Layer elu_conv23
I0930 11:17:10.024305  3537 net.cpp:406] elu_conv23 <- Eltwise11
I0930 11:17:10.024307  3537 net.cpp:367] elu_conv23 -> Eltwise11 (in-place)
I0930 11:17:10.024312  3537 net.cpp:122] Setting up elu_conv23
I0930 11:17:10.024314  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.024317  3537 net.cpp:137] Memory required for data: 585491600
I0930 11:17:10.024318  3537 layer_factory.hpp:77] Creating layer Eltwise11_elu_conv23_0_split
I0930 11:17:10.024322  3537 net.cpp:84] Creating Layer Eltwise11_elu_conv23_0_split
I0930 11:17:10.024324  3537 net.cpp:406] Eltwise11_elu_conv23_0_split <- Eltwise11
I0930 11:17:10.024328  3537 net.cpp:380] Eltwise11_elu_conv23_0_split -> Eltwise11_elu_conv23_0_split_0
I0930 11:17:10.024333  3537 net.cpp:380] Eltwise11_elu_conv23_0_split -> Eltwise11_elu_conv23_0_split_1
I0930 11:17:10.024354  3537 net.cpp:122] Setting up Eltwise11_elu_conv23_0_split
I0930 11:17:10.024358  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.024360  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.024363  3537 net.cpp:137] Memory required for data: 590509200
I0930 11:17:10.024365  3537 layer_factory.hpp:77] Creating layer Convolution25
I0930 11:17:10.024370  3537 net.cpp:84] Creating Layer Convolution25
I0930 11:17:10.024374  3537 net.cpp:406] Convolution25 <- Eltwise11_elu_conv23_0_split_0
I0930 11:17:10.024377  3537 net.cpp:380] Convolution25 -> Convolution25
I0930 11:17:10.025388  3537 net.cpp:122] Setting up Convolution25
I0930 11:17:10.025398  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.025399  3537 net.cpp:137] Memory required for data: 593018000
I0930 11:17:10.025404  3537 layer_factory.hpp:77] Creating layer BatchNorm25
I0930 11:17:10.025409  3537 net.cpp:84] Creating Layer BatchNorm25
I0930 11:17:10.025413  3537 net.cpp:406] BatchNorm25 <- Convolution25
I0930 11:17:10.025416  3537 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0930 11:17:10.025547  3537 net.cpp:122] Setting up BatchNorm25
I0930 11:17:10.025550  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.025552  3537 net.cpp:137] Memory required for data: 595526800
I0930 11:17:10.025557  3537 layer_factory.hpp:77] Creating layer Scale25
I0930 11:17:10.025562  3537 net.cpp:84] Creating Layer Scale25
I0930 11:17:10.025564  3537 net.cpp:406] Scale25 <- Convolution25
I0930 11:17:10.025568  3537 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0930 11:17:10.025600  3537 layer_factory.hpp:77] Creating layer Scale25
I0930 11:17:10.025674  3537 net.cpp:122] Setting up Scale25
I0930 11:17:10.025678  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.025681  3537 net.cpp:137] Memory required for data: 598035600
I0930 11:17:10.025684  3537 layer_factory.hpp:77] Creating layer elu_conv24
I0930 11:17:10.025688  3537 net.cpp:84] Creating Layer elu_conv24
I0930 11:17:10.025691  3537 net.cpp:406] elu_conv24 <- Convolution25
I0930 11:17:10.025694  3537 net.cpp:367] elu_conv24 -> Convolution25 (in-place)
I0930 11:17:10.025698  3537 net.cpp:122] Setting up elu_conv24
I0930 11:17:10.025701  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.025703  3537 net.cpp:137] Memory required for data: 600544400
I0930 11:17:10.025705  3537 layer_factory.hpp:77] Creating layer Convolution26
I0930 11:17:10.025713  3537 net.cpp:84] Creating Layer Convolution26
I0930 11:17:10.025715  3537 net.cpp:406] Convolution26 <- Convolution25
I0930 11:17:10.025719  3537 net.cpp:380] Convolution26 -> Convolution26
I0930 11:17:10.026764  3537 net.cpp:122] Setting up Convolution26
I0930 11:17:10.026772  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.026775  3537 net.cpp:137] Memory required for data: 603053200
I0930 11:17:10.026779  3537 layer_factory.hpp:77] Creating layer BatchNorm26
I0930 11:17:10.026784  3537 net.cpp:84] Creating Layer BatchNorm26
I0930 11:17:10.026787  3537 net.cpp:406] BatchNorm26 <- Convolution26
I0930 11:17:10.026790  3537 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0930 11:17:10.026924  3537 net.cpp:122] Setting up BatchNorm26
I0930 11:17:10.026929  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.026932  3537 net.cpp:137] Memory required for data: 605562000
I0930 11:17:10.026935  3537 layer_factory.hpp:77] Creating layer Scale26
I0930 11:17:10.026940  3537 net.cpp:84] Creating Layer Scale26
I0930 11:17:10.026942  3537 net.cpp:406] Scale26 <- Convolution26
I0930 11:17:10.026947  3537 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0930 11:17:10.026971  3537 layer_factory.hpp:77] Creating layer Scale26
I0930 11:17:10.027046  3537 net.cpp:122] Setting up Scale26
I0930 11:17:10.027050  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.027052  3537 net.cpp:137] Memory required for data: 608070800
I0930 11:17:10.027055  3537 layer_factory.hpp:77] Creating layer Eltwise12
I0930 11:17:10.027060  3537 net.cpp:84] Creating Layer Eltwise12
I0930 11:17:10.027062  3537 net.cpp:406] Eltwise12 <- Eltwise11_elu_conv23_0_split_1
I0930 11:17:10.027065  3537 net.cpp:406] Eltwise12 <- Convolution26
I0930 11:17:10.027070  3537 net.cpp:380] Eltwise12 -> Eltwise12
I0930 11:17:10.027084  3537 net.cpp:122] Setting up Eltwise12
I0930 11:17:10.027088  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.027091  3537 net.cpp:137] Memory required for data: 610579600
I0930 11:17:10.027092  3537 layer_factory.hpp:77] Creating layer elu_conv25
I0930 11:17:10.027096  3537 net.cpp:84] Creating Layer elu_conv25
I0930 11:17:10.027098  3537 net.cpp:406] elu_conv25 <- Eltwise12
I0930 11:17:10.027101  3537 net.cpp:367] elu_conv25 -> Eltwise12 (in-place)
I0930 11:17:10.027104  3537 net.cpp:122] Setting up elu_conv25
I0930 11:17:10.027107  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.027109  3537 net.cpp:137] Memory required for data: 613088400
I0930 11:17:10.027112  3537 layer_factory.hpp:77] Creating layer Eltwise12_elu_conv25_0_split
I0930 11:17:10.027123  3537 net.cpp:84] Creating Layer Eltwise12_elu_conv25_0_split
I0930 11:17:10.027125  3537 net.cpp:406] Eltwise12_elu_conv25_0_split <- Eltwise12
I0930 11:17:10.027129  3537 net.cpp:380] Eltwise12_elu_conv25_0_split -> Eltwise12_elu_conv25_0_split_0
I0930 11:17:10.027137  3537 net.cpp:380] Eltwise12_elu_conv25_0_split -> Eltwise12_elu_conv25_0_split_1
I0930 11:17:10.027160  3537 net.cpp:122] Setting up Eltwise12_elu_conv25_0_split
I0930 11:17:10.027164  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.027168  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.027176  3537 net.cpp:137] Memory required for data: 618106000
I0930 11:17:10.027179  3537 layer_factory.hpp:77] Creating layer Convolution27
I0930 11:17:10.027186  3537 net.cpp:84] Creating Layer Convolution27
I0930 11:17:10.027189  3537 net.cpp:406] Convolution27 <- Eltwise12_elu_conv25_0_split_0
I0930 11:17:10.027194  3537 net.cpp:380] Convolution27 -> Convolution27
I0930 11:17:10.027894  3537 net.cpp:122] Setting up Convolution27
I0930 11:17:10.027900  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.027902  3537 net.cpp:137] Memory required for data: 620614800
I0930 11:17:10.027907  3537 layer_factory.hpp:77] Creating layer BatchNorm27
I0930 11:17:10.027912  3537 net.cpp:84] Creating Layer BatchNorm27
I0930 11:17:10.027915  3537 net.cpp:406] BatchNorm27 <- Convolution27
I0930 11:17:10.027918  3537 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0930 11:17:10.028048  3537 net.cpp:122] Setting up BatchNorm27
I0930 11:17:10.028053  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.028054  3537 net.cpp:137] Memory required for data: 623123600
I0930 11:17:10.028059  3537 layer_factory.hpp:77] Creating layer Scale27
I0930 11:17:10.028064  3537 net.cpp:84] Creating Layer Scale27
I0930 11:17:10.028066  3537 net.cpp:406] Scale27 <- Convolution27
I0930 11:17:10.028069  3537 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0930 11:17:10.028095  3537 layer_factory.hpp:77] Creating layer Scale27
I0930 11:17:10.028170  3537 net.cpp:122] Setting up Scale27
I0930 11:17:10.028174  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.028177  3537 net.cpp:137] Memory required for data: 625632400
I0930 11:17:10.028180  3537 layer_factory.hpp:77] Creating layer elu_conv26
I0930 11:17:10.028184  3537 net.cpp:84] Creating Layer elu_conv26
I0930 11:17:10.028187  3537 net.cpp:406] elu_conv26 <- Convolution27
I0930 11:17:10.028190  3537 net.cpp:367] elu_conv26 -> Convolution27 (in-place)
I0930 11:17:10.028193  3537 net.cpp:122] Setting up elu_conv26
I0930 11:17:10.028197  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.028199  3537 net.cpp:137] Memory required for data: 628141200
I0930 11:17:10.028201  3537 layer_factory.hpp:77] Creating layer Convolution28
I0930 11:17:10.028208  3537 net.cpp:84] Creating Layer Convolution28
I0930 11:17:10.028209  3537 net.cpp:406] Convolution28 <- Convolution27
I0930 11:17:10.028215  3537 net.cpp:380] Convolution28 -> Convolution28
I0930 11:17:10.029264  3537 net.cpp:122] Setting up Convolution28
I0930 11:17:10.029273  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.029275  3537 net.cpp:137] Memory required for data: 630650000
I0930 11:17:10.029280  3537 layer_factory.hpp:77] Creating layer BatchNorm28
I0930 11:17:10.029284  3537 net.cpp:84] Creating Layer BatchNorm28
I0930 11:17:10.029287  3537 net.cpp:406] BatchNorm28 <- Convolution28
I0930 11:17:10.029291  3537 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0930 11:17:10.029422  3537 net.cpp:122] Setting up BatchNorm28
I0930 11:17:10.029425  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.029428  3537 net.cpp:137] Memory required for data: 633158800
I0930 11:17:10.029433  3537 layer_factory.hpp:77] Creating layer Scale28
I0930 11:17:10.029436  3537 net.cpp:84] Creating Layer Scale28
I0930 11:17:10.029439  3537 net.cpp:406] Scale28 <- Convolution28
I0930 11:17:10.029443  3537 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0930 11:17:10.029469  3537 layer_factory.hpp:77] Creating layer Scale28
I0930 11:17:10.029542  3537 net.cpp:122] Setting up Scale28
I0930 11:17:10.029546  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.029548  3537 net.cpp:137] Memory required for data: 635667600
I0930 11:17:10.029552  3537 layer_factory.hpp:77] Creating layer Eltwise13
I0930 11:17:10.029556  3537 net.cpp:84] Creating Layer Eltwise13
I0930 11:17:10.029559  3537 net.cpp:406] Eltwise13 <- Eltwise12_elu_conv25_0_split_1
I0930 11:17:10.029562  3537 net.cpp:406] Eltwise13 <- Convolution28
I0930 11:17:10.029572  3537 net.cpp:380] Eltwise13 -> Eltwise13
I0930 11:17:10.029588  3537 net.cpp:122] Setting up Eltwise13
I0930 11:17:10.029592  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.029594  3537 net.cpp:137] Memory required for data: 638176400
I0930 11:17:10.029597  3537 layer_factory.hpp:77] Creating layer elu_conv27
I0930 11:17:10.029600  3537 net.cpp:84] Creating Layer elu_conv27
I0930 11:17:10.029603  3537 net.cpp:406] elu_conv27 <- Eltwise13
I0930 11:17:10.029606  3537 net.cpp:367] elu_conv27 -> Eltwise13 (in-place)
I0930 11:17:10.029609  3537 net.cpp:122] Setting up elu_conv27
I0930 11:17:10.029613  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.029614  3537 net.cpp:137] Memory required for data: 640685200
I0930 11:17:10.029618  3537 layer_factory.hpp:77] Creating layer Eltwise13_elu_conv27_0_split
I0930 11:17:10.029620  3537 net.cpp:84] Creating Layer Eltwise13_elu_conv27_0_split
I0930 11:17:10.029623  3537 net.cpp:406] Eltwise13_elu_conv27_0_split <- Eltwise13
I0930 11:17:10.029625  3537 net.cpp:380] Eltwise13_elu_conv27_0_split -> Eltwise13_elu_conv27_0_split_0
I0930 11:17:10.029629  3537 net.cpp:380] Eltwise13_elu_conv27_0_split -> Eltwise13_elu_conv27_0_split_1
I0930 11:17:10.029651  3537 net.cpp:122] Setting up Eltwise13_elu_conv27_0_split
I0930 11:17:10.029655  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.029659  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.029660  3537 net.cpp:137] Memory required for data: 645702800
I0930 11:17:10.029662  3537 layer_factory.hpp:77] Creating layer Convolution29
I0930 11:17:10.029670  3537 net.cpp:84] Creating Layer Convolution29
I0930 11:17:10.029671  3537 net.cpp:406] Convolution29 <- Eltwise13_elu_conv27_0_split_0
I0930 11:17:10.029675  3537 net.cpp:380] Convolution29 -> Convolution29
I0930 11:17:10.030716  3537 net.cpp:122] Setting up Convolution29
I0930 11:17:10.030725  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.030727  3537 net.cpp:137] Memory required for data: 648211600
I0930 11:17:10.030732  3537 layer_factory.hpp:77] Creating layer BatchNorm29
I0930 11:17:10.030737  3537 net.cpp:84] Creating Layer BatchNorm29
I0930 11:17:10.030740  3537 net.cpp:406] BatchNorm29 <- Convolution29
I0930 11:17:10.030745  3537 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0930 11:17:10.030879  3537 net.cpp:122] Setting up BatchNorm29
I0930 11:17:10.030882  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.030884  3537 net.cpp:137] Memory required for data: 650720400
I0930 11:17:10.030889  3537 layer_factory.hpp:77] Creating layer Scale29
I0930 11:17:10.030894  3537 net.cpp:84] Creating Layer Scale29
I0930 11:17:10.030896  3537 net.cpp:406] Scale29 <- Convolution29
I0930 11:17:10.030900  3537 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0930 11:17:10.030925  3537 layer_factory.hpp:77] Creating layer Scale29
I0930 11:17:10.031002  3537 net.cpp:122] Setting up Scale29
I0930 11:17:10.031006  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.031008  3537 net.cpp:137] Memory required for data: 653229200
I0930 11:17:10.031013  3537 layer_factory.hpp:77] Creating layer elu_conv28
I0930 11:17:10.031016  3537 net.cpp:84] Creating Layer elu_conv28
I0930 11:17:10.031018  3537 net.cpp:406] elu_conv28 <- Convolution29
I0930 11:17:10.031021  3537 net.cpp:367] elu_conv28 -> Convolution29 (in-place)
I0930 11:17:10.031025  3537 net.cpp:122] Setting up elu_conv28
I0930 11:17:10.031028  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.031030  3537 net.cpp:137] Memory required for data: 655738000
I0930 11:17:10.031033  3537 layer_factory.hpp:77] Creating layer Convolution30
I0930 11:17:10.031039  3537 net.cpp:84] Creating Layer Convolution30
I0930 11:17:10.031041  3537 net.cpp:406] Convolution30 <- Convolution29
I0930 11:17:10.031045  3537 net.cpp:380] Convolution30 -> Convolution30
I0930 11:17:10.032059  3537 net.cpp:122] Setting up Convolution30
I0930 11:17:10.032068  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.032070  3537 net.cpp:137] Memory required for data: 658246800
I0930 11:17:10.032081  3537 layer_factory.hpp:77] Creating layer BatchNorm30
I0930 11:17:10.032088  3537 net.cpp:84] Creating Layer BatchNorm30
I0930 11:17:10.032090  3537 net.cpp:406] BatchNorm30 <- Convolution30
I0930 11:17:10.032094  3537 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0930 11:17:10.032227  3537 net.cpp:122] Setting up BatchNorm30
I0930 11:17:10.032232  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.032234  3537 net.cpp:137] Memory required for data: 660755600
I0930 11:17:10.032239  3537 layer_factory.hpp:77] Creating layer Scale30
I0930 11:17:10.032243  3537 net.cpp:84] Creating Layer Scale30
I0930 11:17:10.032245  3537 net.cpp:406] Scale30 <- Convolution30
I0930 11:17:10.032248  3537 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0930 11:17:10.032275  3537 layer_factory.hpp:77] Creating layer Scale30
I0930 11:17:10.032351  3537 net.cpp:122] Setting up Scale30
I0930 11:17:10.032356  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.032358  3537 net.cpp:137] Memory required for data: 663264400
I0930 11:17:10.032361  3537 layer_factory.hpp:77] Creating layer Eltwise14
I0930 11:17:10.032367  3537 net.cpp:84] Creating Layer Eltwise14
I0930 11:17:10.032371  3537 net.cpp:406] Eltwise14 <- Eltwise13_elu_conv27_0_split_1
I0930 11:17:10.032372  3537 net.cpp:406] Eltwise14 <- Convolution30
I0930 11:17:10.032377  3537 net.cpp:380] Eltwise14 -> Eltwise14
I0930 11:17:10.032392  3537 net.cpp:122] Setting up Eltwise14
I0930 11:17:10.032395  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.032397  3537 net.cpp:137] Memory required for data: 665773200
I0930 11:17:10.032400  3537 layer_factory.hpp:77] Creating layer elu_conv29
I0930 11:17:10.032403  3537 net.cpp:84] Creating Layer elu_conv29
I0930 11:17:10.032407  3537 net.cpp:406] elu_conv29 <- Eltwise14
I0930 11:17:10.032409  3537 net.cpp:367] elu_conv29 -> Eltwise14 (in-place)
I0930 11:17:10.032413  3537 net.cpp:122] Setting up elu_conv29
I0930 11:17:10.032416  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.032418  3537 net.cpp:137] Memory required for data: 668282000
I0930 11:17:10.032420  3537 layer_factory.hpp:77] Creating layer Eltwise14_elu_conv29_0_split
I0930 11:17:10.032423  3537 net.cpp:84] Creating Layer Eltwise14_elu_conv29_0_split
I0930 11:17:10.032425  3537 net.cpp:406] Eltwise14_elu_conv29_0_split <- Eltwise14
I0930 11:17:10.032428  3537 net.cpp:380] Eltwise14_elu_conv29_0_split -> Eltwise14_elu_conv29_0_split_0
I0930 11:17:10.032433  3537 net.cpp:380] Eltwise14_elu_conv29_0_split -> Eltwise14_elu_conv29_0_split_1
I0930 11:17:10.032455  3537 net.cpp:122] Setting up Eltwise14_elu_conv29_0_split
I0930 11:17:10.032459  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.032461  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.032464  3537 net.cpp:137] Memory required for data: 673299600
I0930 11:17:10.032465  3537 layer_factory.hpp:77] Creating layer Convolution31
I0930 11:17:10.032472  3537 net.cpp:84] Creating Layer Convolution31
I0930 11:17:10.032474  3537 net.cpp:406] Convolution31 <- Eltwise14_elu_conv29_0_split_0
I0930 11:17:10.032479  3537 net.cpp:380] Convolution31 -> Convolution31
I0930 11:17:10.033501  3537 net.cpp:122] Setting up Convolution31
I0930 11:17:10.033510  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.033514  3537 net.cpp:137] Memory required for data: 675808400
I0930 11:17:10.033517  3537 layer_factory.hpp:77] Creating layer BatchNorm31
I0930 11:17:10.033524  3537 net.cpp:84] Creating Layer BatchNorm31
I0930 11:17:10.033525  3537 net.cpp:406] BatchNorm31 <- Convolution31
I0930 11:17:10.033530  3537 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0930 11:17:10.033663  3537 net.cpp:122] Setting up BatchNorm31
I0930 11:17:10.033668  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.033669  3537 net.cpp:137] Memory required for data: 678317200
I0930 11:17:10.033674  3537 layer_factory.hpp:77] Creating layer Scale31
I0930 11:17:10.033679  3537 net.cpp:84] Creating Layer Scale31
I0930 11:17:10.033687  3537 net.cpp:406] Scale31 <- Convolution31
I0930 11:17:10.033690  3537 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0930 11:17:10.033718  3537 layer_factory.hpp:77] Creating layer Scale31
I0930 11:17:10.033793  3537 net.cpp:122] Setting up Scale31
I0930 11:17:10.033798  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.033800  3537 net.cpp:137] Memory required for data: 680826000
I0930 11:17:10.033803  3537 layer_factory.hpp:77] Creating layer elu_conv30
I0930 11:17:10.033808  3537 net.cpp:84] Creating Layer elu_conv30
I0930 11:17:10.033810  3537 net.cpp:406] elu_conv30 <- Convolution31
I0930 11:17:10.033813  3537 net.cpp:367] elu_conv30 -> Convolution31 (in-place)
I0930 11:17:10.033818  3537 net.cpp:122] Setting up elu_conv30
I0930 11:17:10.033820  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.033823  3537 net.cpp:137] Memory required for data: 683334800
I0930 11:17:10.033824  3537 layer_factory.hpp:77] Creating layer Convolution32
I0930 11:17:10.033830  3537 net.cpp:84] Creating Layer Convolution32
I0930 11:17:10.033833  3537 net.cpp:406] Convolution32 <- Convolution31
I0930 11:17:10.033838  3537 net.cpp:380] Convolution32 -> Convolution32
I0930 11:17:10.034885  3537 net.cpp:122] Setting up Convolution32
I0930 11:17:10.034893  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.034896  3537 net.cpp:137] Memory required for data: 685843600
I0930 11:17:10.034903  3537 layer_factory.hpp:77] Creating layer BatchNorm32
I0930 11:17:10.034907  3537 net.cpp:84] Creating Layer BatchNorm32
I0930 11:17:10.034910  3537 net.cpp:406] BatchNorm32 <- Convolution32
I0930 11:17:10.034914  3537 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I0930 11:17:10.035048  3537 net.cpp:122] Setting up BatchNorm32
I0930 11:17:10.035053  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.035054  3537 net.cpp:137] Memory required for data: 688352400
I0930 11:17:10.035059  3537 layer_factory.hpp:77] Creating layer Scale32
I0930 11:17:10.035063  3537 net.cpp:84] Creating Layer Scale32
I0930 11:17:10.035065  3537 net.cpp:406] Scale32 <- Convolution32
I0930 11:17:10.035068  3537 net.cpp:367] Scale32 -> Convolution32 (in-place)
I0930 11:17:10.035095  3537 layer_factory.hpp:77] Creating layer Scale32
I0930 11:17:10.035171  3537 net.cpp:122] Setting up Scale32
I0930 11:17:10.035176  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.035178  3537 net.cpp:137] Memory required for data: 690861200
I0930 11:17:10.035182  3537 layer_factory.hpp:77] Creating layer Eltwise15
I0930 11:17:10.035187  3537 net.cpp:84] Creating Layer Eltwise15
I0930 11:17:10.035188  3537 net.cpp:406] Eltwise15 <- Eltwise14_elu_conv29_0_split_1
I0930 11:17:10.035192  3537 net.cpp:406] Eltwise15 <- Convolution32
I0930 11:17:10.035194  3537 net.cpp:380] Eltwise15 -> Eltwise15
I0930 11:17:10.035231  3537 net.cpp:122] Setting up Eltwise15
I0930 11:17:10.035235  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.035238  3537 net.cpp:137] Memory required for data: 693370000
I0930 11:17:10.035248  3537 layer_factory.hpp:77] Creating layer elu_conv31
I0930 11:17:10.035253  3537 net.cpp:84] Creating Layer elu_conv31
I0930 11:17:10.035255  3537 net.cpp:406] elu_conv31 <- Eltwise15
I0930 11:17:10.035259  3537 net.cpp:367] elu_conv31 -> Eltwise15 (in-place)
I0930 11:17:10.035262  3537 net.cpp:122] Setting up elu_conv31
I0930 11:17:10.035265  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.035267  3537 net.cpp:137] Memory required for data: 695878800
I0930 11:17:10.035269  3537 layer_factory.hpp:77] Creating layer Eltwise15_elu_conv31_0_split
I0930 11:17:10.035274  3537 net.cpp:84] Creating Layer Eltwise15_elu_conv31_0_split
I0930 11:17:10.035275  3537 net.cpp:406] Eltwise15_elu_conv31_0_split <- Eltwise15
I0930 11:17:10.035279  3537 net.cpp:380] Eltwise15_elu_conv31_0_split -> Eltwise15_elu_conv31_0_split_0
I0930 11:17:10.035282  3537 net.cpp:380] Eltwise15_elu_conv31_0_split -> Eltwise15_elu_conv31_0_split_1
I0930 11:17:10.035322  3537 net.cpp:122] Setting up Eltwise15_elu_conv31_0_split
I0930 11:17:10.035326  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.035329  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.035331  3537 net.cpp:137] Memory required for data: 700896400
I0930 11:17:10.035333  3537 layer_factory.hpp:77] Creating layer Convolution33
I0930 11:17:10.035341  3537 net.cpp:84] Creating Layer Convolution33
I0930 11:17:10.035342  3537 net.cpp:406] Convolution33 <- Eltwise15_elu_conv31_0_split_0
I0930 11:17:10.035346  3537 net.cpp:380] Convolution33 -> Convolution33
I0930 11:17:10.036680  3537 net.cpp:122] Setting up Convolution33
I0930 11:17:10.036689  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.036691  3537 net.cpp:137] Memory required for data: 703405200
I0930 11:17:10.036696  3537 layer_factory.hpp:77] Creating layer BatchNorm33
I0930 11:17:10.036701  3537 net.cpp:84] Creating Layer BatchNorm33
I0930 11:17:10.036703  3537 net.cpp:406] BatchNorm33 <- Convolution33
I0930 11:17:10.036707  3537 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I0930 11:17:10.036847  3537 net.cpp:122] Setting up BatchNorm33
I0930 11:17:10.036851  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.036854  3537 net.cpp:137] Memory required for data: 705914000
I0930 11:17:10.036859  3537 layer_factory.hpp:77] Creating layer Scale33
I0930 11:17:10.036862  3537 net.cpp:84] Creating Layer Scale33
I0930 11:17:10.036865  3537 net.cpp:406] Scale33 <- Convolution33
I0930 11:17:10.036869  3537 net.cpp:367] Scale33 -> Convolution33 (in-place)
I0930 11:17:10.036895  3537 layer_factory.hpp:77] Creating layer Scale33
I0930 11:17:10.036972  3537 net.cpp:122] Setting up Scale33
I0930 11:17:10.036976  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.036979  3537 net.cpp:137] Memory required for data: 708422800
I0930 11:17:10.036983  3537 layer_factory.hpp:77] Creating layer elu_conv32
I0930 11:17:10.036986  3537 net.cpp:84] Creating Layer elu_conv32
I0930 11:17:10.036988  3537 net.cpp:406] elu_conv32 <- Convolution33
I0930 11:17:10.036991  3537 net.cpp:367] elu_conv32 -> Convolution33 (in-place)
I0930 11:17:10.036995  3537 net.cpp:122] Setting up elu_conv32
I0930 11:17:10.036998  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.037000  3537 net.cpp:137] Memory required for data: 710931600
I0930 11:17:10.037003  3537 layer_factory.hpp:77] Creating layer Convolution34
I0930 11:17:10.037010  3537 net.cpp:84] Creating Layer Convolution34
I0930 11:17:10.037012  3537 net.cpp:406] Convolution34 <- Convolution33
I0930 11:17:10.037027  3537 net.cpp:380] Convolution34 -> Convolution34
I0930 11:17:10.038069  3537 net.cpp:122] Setting up Convolution34
I0930 11:17:10.038077  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.038080  3537 net.cpp:137] Memory required for data: 713440400
I0930 11:17:10.038084  3537 layer_factory.hpp:77] Creating layer BatchNorm34
I0930 11:17:10.038090  3537 net.cpp:84] Creating Layer BatchNorm34
I0930 11:17:10.038094  3537 net.cpp:406] BatchNorm34 <- Convolution34
I0930 11:17:10.038097  3537 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I0930 11:17:10.038231  3537 net.cpp:122] Setting up BatchNorm34
I0930 11:17:10.038235  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.038238  3537 net.cpp:137] Memory required for data: 715949200
I0930 11:17:10.038242  3537 layer_factory.hpp:77] Creating layer Scale34
I0930 11:17:10.038247  3537 net.cpp:84] Creating Layer Scale34
I0930 11:17:10.038249  3537 net.cpp:406] Scale34 <- Convolution34
I0930 11:17:10.038252  3537 net.cpp:367] Scale34 -> Convolution34 (in-place)
I0930 11:17:10.038278  3537 layer_factory.hpp:77] Creating layer Scale34
I0930 11:17:10.038354  3537 net.cpp:122] Setting up Scale34
I0930 11:17:10.038359  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.038362  3537 net.cpp:137] Memory required for data: 718458000
I0930 11:17:10.038365  3537 layer_factory.hpp:77] Creating layer Eltwise16
I0930 11:17:10.038369  3537 net.cpp:84] Creating Layer Eltwise16
I0930 11:17:10.038379  3537 net.cpp:406] Eltwise16 <- Eltwise15_elu_conv31_0_split_1
I0930 11:17:10.038383  3537 net.cpp:406] Eltwise16 <- Convolution34
I0930 11:17:10.038386  3537 net.cpp:380] Eltwise16 -> Eltwise16
I0930 11:17:10.038403  3537 net.cpp:122] Setting up Eltwise16
I0930 11:17:10.038408  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.038409  3537 net.cpp:137] Memory required for data: 720966800
I0930 11:17:10.038411  3537 layer_factory.hpp:77] Creating layer elu_conv33
I0930 11:17:10.038414  3537 net.cpp:84] Creating Layer elu_conv33
I0930 11:17:10.038417  3537 net.cpp:406] elu_conv33 <- Eltwise16
I0930 11:17:10.038421  3537 net.cpp:367] elu_conv33 -> Eltwise16 (in-place)
I0930 11:17:10.038424  3537 net.cpp:122] Setting up elu_conv33
I0930 11:17:10.038427  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.038429  3537 net.cpp:137] Memory required for data: 723475600
I0930 11:17:10.038432  3537 layer_factory.hpp:77] Creating layer Eltwise16_elu_conv33_0_split
I0930 11:17:10.038435  3537 net.cpp:84] Creating Layer Eltwise16_elu_conv33_0_split
I0930 11:17:10.038437  3537 net.cpp:406] Eltwise16_elu_conv33_0_split <- Eltwise16
I0930 11:17:10.038440  3537 net.cpp:380] Eltwise16_elu_conv33_0_split -> Eltwise16_elu_conv33_0_split_0
I0930 11:17:10.038444  3537 net.cpp:380] Eltwise16_elu_conv33_0_split -> Eltwise16_elu_conv33_0_split_1
I0930 11:17:10.038466  3537 net.cpp:122] Setting up Eltwise16_elu_conv33_0_split
I0930 11:17:10.038470  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.038473  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.038475  3537 net.cpp:137] Memory required for data: 728493200
I0930 11:17:10.038477  3537 layer_factory.hpp:77] Creating layer Convolution35
I0930 11:17:10.038483  3537 net.cpp:84] Creating Layer Convolution35
I0930 11:17:10.038486  3537 net.cpp:406] Convolution35 <- Eltwise16_elu_conv33_0_split_0
I0930 11:17:10.038491  3537 net.cpp:380] Convolution35 -> Convolution35
I0930 11:17:10.039543  3537 net.cpp:122] Setting up Convolution35
I0930 11:17:10.039552  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.039556  3537 net.cpp:137] Memory required for data: 731002000
I0930 11:17:10.039559  3537 layer_factory.hpp:77] Creating layer BatchNorm35
I0930 11:17:10.039564  3537 net.cpp:84] Creating Layer BatchNorm35
I0930 11:17:10.039566  3537 net.cpp:406] BatchNorm35 <- Convolution35
I0930 11:17:10.039571  3537 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I0930 11:17:10.039707  3537 net.cpp:122] Setting up BatchNorm35
I0930 11:17:10.039711  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.039713  3537 net.cpp:137] Memory required for data: 733510800
I0930 11:17:10.039718  3537 layer_factory.hpp:77] Creating layer Scale35
I0930 11:17:10.039722  3537 net.cpp:84] Creating Layer Scale35
I0930 11:17:10.039724  3537 net.cpp:406] Scale35 <- Convolution35
I0930 11:17:10.039728  3537 net.cpp:367] Scale35 -> Convolution35 (in-place)
I0930 11:17:10.039754  3537 layer_factory.hpp:77] Creating layer Scale35
I0930 11:17:10.039830  3537 net.cpp:122] Setting up Scale35
I0930 11:17:10.039834  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.039836  3537 net.cpp:137] Memory required for data: 736019600
I0930 11:17:10.039839  3537 layer_factory.hpp:77] Creating layer elu_conv34
I0930 11:17:10.039844  3537 net.cpp:84] Creating Layer elu_conv34
I0930 11:17:10.039845  3537 net.cpp:406] elu_conv34 <- Convolution35
I0930 11:17:10.039849  3537 net.cpp:367] elu_conv34 -> Convolution35 (in-place)
I0930 11:17:10.039852  3537 net.cpp:122] Setting up elu_conv34
I0930 11:17:10.039855  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.039858  3537 net.cpp:137] Memory required for data: 738528400
I0930 11:17:10.039860  3537 layer_factory.hpp:77] Creating layer Convolution36
I0930 11:17:10.039867  3537 net.cpp:84] Creating Layer Convolution36
I0930 11:17:10.039870  3537 net.cpp:406] Convolution36 <- Convolution35
I0930 11:17:10.039873  3537 net.cpp:380] Convolution36 -> Convolution36
I0930 11:17:10.040915  3537 net.cpp:122] Setting up Convolution36
I0930 11:17:10.040923  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.040925  3537 net.cpp:137] Memory required for data: 741037200
I0930 11:17:10.040930  3537 layer_factory.hpp:77] Creating layer BatchNorm36
I0930 11:17:10.040935  3537 net.cpp:84] Creating Layer BatchNorm36
I0930 11:17:10.040938  3537 net.cpp:406] BatchNorm36 <- Convolution36
I0930 11:17:10.040942  3537 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I0930 11:17:10.041079  3537 net.cpp:122] Setting up BatchNorm36
I0930 11:17:10.041083  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.041085  3537 net.cpp:137] Memory required for data: 743546000
I0930 11:17:10.041090  3537 layer_factory.hpp:77] Creating layer Scale36
I0930 11:17:10.041095  3537 net.cpp:84] Creating Layer Scale36
I0930 11:17:10.041097  3537 net.cpp:406] Scale36 <- Convolution36
I0930 11:17:10.041100  3537 net.cpp:367] Scale36 -> Convolution36 (in-place)
I0930 11:17:10.041127  3537 layer_factory.hpp:77] Creating layer Scale36
I0930 11:17:10.041204  3537 net.cpp:122] Setting up Scale36
I0930 11:17:10.041208  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.041210  3537 net.cpp:137] Memory required for data: 746054800
I0930 11:17:10.041214  3537 layer_factory.hpp:77] Creating layer Eltwise17
I0930 11:17:10.041219  3537 net.cpp:84] Creating Layer Eltwise17
I0930 11:17:10.041221  3537 net.cpp:406] Eltwise17 <- Eltwise16_elu_conv33_0_split_1
I0930 11:17:10.041224  3537 net.cpp:406] Eltwise17 <- Convolution36
I0930 11:17:10.041227  3537 net.cpp:380] Eltwise17 -> Eltwise17
I0930 11:17:10.041244  3537 net.cpp:122] Setting up Eltwise17
I0930 11:17:10.041247  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.041249  3537 net.cpp:137] Memory required for data: 748563600
I0930 11:17:10.041251  3537 layer_factory.hpp:77] Creating layer elu_conv35
I0930 11:17:10.041255  3537 net.cpp:84] Creating Layer elu_conv35
I0930 11:17:10.041257  3537 net.cpp:406] elu_conv35 <- Eltwise17
I0930 11:17:10.041260  3537 net.cpp:367] elu_conv35 -> Eltwise17 (in-place)
I0930 11:17:10.041265  3537 net.cpp:122] Setting up elu_conv35
I0930 11:17:10.041267  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.041270  3537 net.cpp:137] Memory required for data: 751072400
I0930 11:17:10.041271  3537 layer_factory.hpp:77] Creating layer Eltwise17_elu_conv35_0_split
I0930 11:17:10.041275  3537 net.cpp:84] Creating Layer Eltwise17_elu_conv35_0_split
I0930 11:17:10.041277  3537 net.cpp:406] Eltwise17_elu_conv35_0_split <- Eltwise17
I0930 11:17:10.041280  3537 net.cpp:380] Eltwise17_elu_conv35_0_split -> Eltwise17_elu_conv35_0_split_0
I0930 11:17:10.041283  3537 net.cpp:380] Eltwise17_elu_conv35_0_split -> Eltwise17_elu_conv35_0_split_1
I0930 11:17:10.041306  3537 net.cpp:122] Setting up Eltwise17_elu_conv35_0_split
I0930 11:17:10.041311  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.041312  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.041314  3537 net.cpp:137] Memory required for data: 756090000
I0930 11:17:10.041316  3537 layer_factory.hpp:77] Creating layer Convolution37
I0930 11:17:10.041322  3537 net.cpp:84] Creating Layer Convolution37
I0930 11:17:10.041324  3537 net.cpp:406] Convolution37 <- Eltwise17_elu_conv35_0_split_0
I0930 11:17:10.041329  3537 net.cpp:380] Convolution37 -> Convolution37
I0930 11:17:10.042037  3537 net.cpp:122] Setting up Convolution37
I0930 11:17:10.042044  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.042047  3537 net.cpp:137] Memory required for data: 758598800
I0930 11:17:10.042050  3537 layer_factory.hpp:77] Creating layer BatchNorm37
I0930 11:17:10.042055  3537 net.cpp:84] Creating Layer BatchNorm37
I0930 11:17:10.042058  3537 net.cpp:406] BatchNorm37 <- Convolution37
I0930 11:17:10.042062  3537 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I0930 11:17:10.042196  3537 net.cpp:122] Setting up BatchNorm37
I0930 11:17:10.042201  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.042208  3537 net.cpp:137] Memory required for data: 761107600
I0930 11:17:10.042233  3537 layer_factory.hpp:77] Creating layer Scale37
I0930 11:17:10.042238  3537 net.cpp:84] Creating Layer Scale37
I0930 11:17:10.042242  3537 net.cpp:406] Scale37 <- Convolution37
I0930 11:17:10.042244  3537 net.cpp:367] Scale37 -> Convolution37 (in-place)
I0930 11:17:10.042273  3537 layer_factory.hpp:77] Creating layer Scale37
I0930 11:17:10.042351  3537 net.cpp:122] Setting up Scale37
I0930 11:17:10.042354  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.042357  3537 net.cpp:137] Memory required for data: 763616400
I0930 11:17:10.042361  3537 layer_factory.hpp:77] Creating layer elu_conv36
I0930 11:17:10.042364  3537 net.cpp:84] Creating Layer elu_conv36
I0930 11:17:10.042366  3537 net.cpp:406] elu_conv36 <- Convolution37
I0930 11:17:10.042371  3537 net.cpp:367] elu_conv36 -> Convolution37 (in-place)
I0930 11:17:10.042374  3537 net.cpp:122] Setting up elu_conv36
I0930 11:17:10.042377  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.042379  3537 net.cpp:137] Memory required for data: 766125200
I0930 11:17:10.042382  3537 layer_factory.hpp:77] Creating layer Convolution38
I0930 11:17:10.042388  3537 net.cpp:84] Creating Layer Convolution38
I0930 11:17:10.042390  3537 net.cpp:406] Convolution38 <- Convolution37
I0930 11:17:10.042394  3537 net.cpp:380] Convolution38 -> Convolution38
I0930 11:17:10.043483  3537 net.cpp:122] Setting up Convolution38
I0930 11:17:10.043493  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.043494  3537 net.cpp:137] Memory required for data: 768634000
I0930 11:17:10.043499  3537 layer_factory.hpp:77] Creating layer BatchNorm38
I0930 11:17:10.043504  3537 net.cpp:84] Creating Layer BatchNorm38
I0930 11:17:10.043507  3537 net.cpp:406] BatchNorm38 <- Convolution38
I0930 11:17:10.043511  3537 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I0930 11:17:10.043647  3537 net.cpp:122] Setting up BatchNorm38
I0930 11:17:10.043650  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.043653  3537 net.cpp:137] Memory required for data: 771142800
I0930 11:17:10.043658  3537 layer_factory.hpp:77] Creating layer Scale38
I0930 11:17:10.043661  3537 net.cpp:84] Creating Layer Scale38
I0930 11:17:10.043664  3537 net.cpp:406] Scale38 <- Convolution38
I0930 11:17:10.043668  3537 net.cpp:367] Scale38 -> Convolution38 (in-place)
I0930 11:17:10.043694  3537 layer_factory.hpp:77] Creating layer Scale38
I0930 11:17:10.043771  3537 net.cpp:122] Setting up Scale38
I0930 11:17:10.043774  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.043777  3537 net.cpp:137] Memory required for data: 773651600
I0930 11:17:10.043781  3537 layer_factory.hpp:77] Creating layer Eltwise18
I0930 11:17:10.043786  3537 net.cpp:84] Creating Layer Eltwise18
I0930 11:17:10.043787  3537 net.cpp:406] Eltwise18 <- Eltwise17_elu_conv35_0_split_1
I0930 11:17:10.043790  3537 net.cpp:406] Eltwise18 <- Convolution38
I0930 11:17:10.043793  3537 net.cpp:380] Eltwise18 -> Eltwise18
I0930 11:17:10.043809  3537 net.cpp:122] Setting up Eltwise18
I0930 11:17:10.043812  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.043815  3537 net.cpp:137] Memory required for data: 776160400
I0930 11:17:10.043817  3537 layer_factory.hpp:77] Creating layer elu_conv37
I0930 11:17:10.043820  3537 net.cpp:84] Creating Layer elu_conv37
I0930 11:17:10.043823  3537 net.cpp:406] elu_conv37 <- Eltwise18
I0930 11:17:10.043828  3537 net.cpp:367] elu_conv37 -> Eltwise18 (in-place)
I0930 11:17:10.043830  3537 net.cpp:122] Setting up elu_conv37
I0930 11:17:10.043833  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.043835  3537 net.cpp:137] Memory required for data: 778669200
I0930 11:17:10.043838  3537 layer_factory.hpp:77] Creating layer Eltwise18_elu_conv37_0_split
I0930 11:17:10.043841  3537 net.cpp:84] Creating Layer Eltwise18_elu_conv37_0_split
I0930 11:17:10.043843  3537 net.cpp:406] Eltwise18_elu_conv37_0_split <- Eltwise18
I0930 11:17:10.043853  3537 net.cpp:380] Eltwise18_elu_conv37_0_split -> Eltwise18_elu_conv37_0_split_0
I0930 11:17:10.043857  3537 net.cpp:380] Eltwise18_elu_conv37_0_split -> Eltwise18_elu_conv37_0_split_1
I0930 11:17:10.043881  3537 net.cpp:122] Setting up Eltwise18_elu_conv37_0_split
I0930 11:17:10.043885  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.043889  3537 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 11:17:10.043890  3537 net.cpp:137] Memory required for data: 783686800
I0930 11:17:10.043892  3537 layer_factory.hpp:77] Creating layer Convolution39
I0930 11:17:10.043898  3537 net.cpp:84] Creating Layer Convolution39
I0930 11:17:10.043900  3537 net.cpp:406] Convolution39 <- Eltwise18_elu_conv37_0_split_0
I0930 11:17:10.043905  3537 net.cpp:380] Convolution39 -> Convolution39
I0930 11:17:10.044783  3537 net.cpp:122] Setting up Convolution39
I0930 11:17:10.044792  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.044795  3537 net.cpp:137] Memory required for data: 784941200
I0930 11:17:10.044800  3537 layer_factory.hpp:77] Creating layer BatchNorm39
I0930 11:17:10.044805  3537 net.cpp:84] Creating Layer BatchNorm39
I0930 11:17:10.044807  3537 net.cpp:406] BatchNorm39 <- Convolution39
I0930 11:17:10.044811  3537 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I0930 11:17:10.044948  3537 net.cpp:122] Setting up BatchNorm39
I0930 11:17:10.044952  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.044955  3537 net.cpp:137] Memory required for data: 786195600
I0930 11:17:10.044960  3537 layer_factory.hpp:77] Creating layer Scale39
I0930 11:17:10.044963  3537 net.cpp:84] Creating Layer Scale39
I0930 11:17:10.044966  3537 net.cpp:406] Scale39 <- Convolution39
I0930 11:17:10.044970  3537 net.cpp:367] Scale39 -> Convolution39 (in-place)
I0930 11:17:10.044996  3537 layer_factory.hpp:77] Creating layer Scale39
I0930 11:17:10.045074  3537 net.cpp:122] Setting up Scale39
I0930 11:17:10.045079  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.045081  3537 net.cpp:137] Memory required for data: 787450000
I0930 11:17:10.045085  3537 layer_factory.hpp:77] Creating layer Convolution40
I0930 11:17:10.045091  3537 net.cpp:84] Creating Layer Convolution40
I0930 11:17:10.045094  3537 net.cpp:406] Convolution40 <- Eltwise18_elu_conv37_0_split_1
I0930 11:17:10.045099  3537 net.cpp:380] Convolution40 -> Convolution40
I0930 11:17:10.046859  3537 net.cpp:122] Setting up Convolution40
I0930 11:17:10.046867  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.046870  3537 net.cpp:137] Memory required for data: 788704400
I0930 11:17:10.046875  3537 layer_factory.hpp:77] Creating layer BatchNorm40
I0930 11:17:10.046880  3537 net.cpp:84] Creating Layer BatchNorm40
I0930 11:17:10.046881  3537 net.cpp:406] BatchNorm40 <- Convolution40
I0930 11:17:10.046886  3537 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I0930 11:17:10.047024  3537 net.cpp:122] Setting up BatchNorm40
I0930 11:17:10.047029  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.047030  3537 net.cpp:137] Memory required for data: 789958800
I0930 11:17:10.047035  3537 layer_factory.hpp:77] Creating layer Scale40
I0930 11:17:10.047039  3537 net.cpp:84] Creating Layer Scale40
I0930 11:17:10.047041  3537 net.cpp:406] Scale40 <- Convolution40
I0930 11:17:10.047045  3537 net.cpp:367] Scale40 -> Convolution40 (in-place)
I0930 11:17:10.047071  3537 layer_factory.hpp:77] Creating layer Scale40
I0930 11:17:10.047148  3537 net.cpp:122] Setting up Scale40
I0930 11:17:10.047152  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.047155  3537 net.cpp:137] Memory required for data: 791213200
I0930 11:17:10.047158  3537 layer_factory.hpp:77] Creating layer elu_conv38
I0930 11:17:10.047163  3537 net.cpp:84] Creating Layer elu_conv38
I0930 11:17:10.047164  3537 net.cpp:406] elu_conv38 <- Convolution40
I0930 11:17:10.047169  3537 net.cpp:367] elu_conv38 -> Convolution40 (in-place)
I0930 11:17:10.047173  3537 net.cpp:122] Setting up elu_conv38
I0930 11:17:10.047175  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.047184  3537 net.cpp:137] Memory required for data: 792467600
I0930 11:17:10.047186  3537 layer_factory.hpp:77] Creating layer Convolution41
I0930 11:17:10.047194  3537 net.cpp:84] Creating Layer Convolution41
I0930 11:17:10.047195  3537 net.cpp:406] Convolution41 <- Convolution40
I0930 11:17:10.047199  3537 net.cpp:380] Convolution41 -> Convolution41
I0930 11:17:10.049149  3537 net.cpp:122] Setting up Convolution41
I0930 11:17:10.049159  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.049161  3537 net.cpp:137] Memory required for data: 793722000
I0930 11:17:10.049166  3537 layer_factory.hpp:77] Creating layer BatchNorm41
I0930 11:17:10.049170  3537 net.cpp:84] Creating Layer BatchNorm41
I0930 11:17:10.049173  3537 net.cpp:406] BatchNorm41 <- Convolution41
I0930 11:17:10.049177  3537 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I0930 11:17:10.049319  3537 net.cpp:122] Setting up BatchNorm41
I0930 11:17:10.049324  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.049326  3537 net.cpp:137] Memory required for data: 794976400
I0930 11:17:10.049330  3537 layer_factory.hpp:77] Creating layer Scale41
I0930 11:17:10.049335  3537 net.cpp:84] Creating Layer Scale41
I0930 11:17:10.049337  3537 net.cpp:406] Scale41 <- Convolution41
I0930 11:17:10.049342  3537 net.cpp:367] Scale41 -> Convolution41 (in-place)
I0930 11:17:10.049370  3537 layer_factory.hpp:77] Creating layer Scale41
I0930 11:17:10.049448  3537 net.cpp:122] Setting up Scale41
I0930 11:17:10.049453  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.049455  3537 net.cpp:137] Memory required for data: 796230800
I0930 11:17:10.049459  3537 layer_factory.hpp:77] Creating layer Eltwise19
I0930 11:17:10.049463  3537 net.cpp:84] Creating Layer Eltwise19
I0930 11:17:10.049465  3537 net.cpp:406] Eltwise19 <- Convolution39
I0930 11:17:10.049468  3537 net.cpp:406] Eltwise19 <- Convolution41
I0930 11:17:10.049473  3537 net.cpp:380] Eltwise19 -> Eltwise19
I0930 11:17:10.049489  3537 net.cpp:122] Setting up Eltwise19
I0930 11:17:10.049492  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.049494  3537 net.cpp:137] Memory required for data: 797485200
I0930 11:17:10.049496  3537 layer_factory.hpp:77] Creating layer elu_conv39
I0930 11:17:10.049500  3537 net.cpp:84] Creating Layer elu_conv39
I0930 11:17:10.049502  3537 net.cpp:406] elu_conv39 <- Eltwise19
I0930 11:17:10.049505  3537 net.cpp:367] elu_conv39 -> Eltwise19 (in-place)
I0930 11:17:10.049510  3537 net.cpp:122] Setting up elu_conv39
I0930 11:17:10.049512  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.049515  3537 net.cpp:137] Memory required for data: 798739600
I0930 11:17:10.049516  3537 layer_factory.hpp:77] Creating layer Eltwise19_elu_conv39_0_split
I0930 11:17:10.049520  3537 net.cpp:84] Creating Layer Eltwise19_elu_conv39_0_split
I0930 11:17:10.049521  3537 net.cpp:406] Eltwise19_elu_conv39_0_split <- Eltwise19
I0930 11:17:10.049526  3537 net.cpp:380] Eltwise19_elu_conv39_0_split -> Eltwise19_elu_conv39_0_split_0
I0930 11:17:10.049530  3537 net.cpp:380] Eltwise19_elu_conv39_0_split -> Eltwise19_elu_conv39_0_split_1
I0930 11:17:10.049552  3537 net.cpp:122] Setting up Eltwise19_elu_conv39_0_split
I0930 11:17:10.049556  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.049558  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.049561  3537 net.cpp:137] Memory required for data: 801248400
I0930 11:17:10.049563  3537 layer_factory.hpp:77] Creating layer Convolution42
I0930 11:17:10.049569  3537 net.cpp:84] Creating Layer Convolution42
I0930 11:17:10.049572  3537 net.cpp:406] Convolution42 <- Eltwise19_elu_conv39_0_split_0
I0930 11:17:10.049576  3537 net.cpp:380] Convolution42 -> Convolution42
I0930 11:17:10.051211  3537 net.cpp:122] Setting up Convolution42
I0930 11:17:10.051219  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.051223  3537 net.cpp:137] Memory required for data: 802502800
I0930 11:17:10.051228  3537 layer_factory.hpp:77] Creating layer BatchNorm42
I0930 11:17:10.051239  3537 net.cpp:84] Creating Layer BatchNorm42
I0930 11:17:10.051241  3537 net.cpp:406] BatchNorm42 <- Convolution42
I0930 11:17:10.051245  3537 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I0930 11:17:10.051384  3537 net.cpp:122] Setting up BatchNorm42
I0930 11:17:10.051389  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.051391  3537 net.cpp:137] Memory required for data: 803757200
I0930 11:17:10.051396  3537 layer_factory.hpp:77] Creating layer Scale42
I0930 11:17:10.051400  3537 net.cpp:84] Creating Layer Scale42
I0930 11:17:10.051403  3537 net.cpp:406] Scale42 <- Convolution42
I0930 11:17:10.051406  3537 net.cpp:367] Scale42 -> Convolution42 (in-place)
I0930 11:17:10.051434  3537 layer_factory.hpp:77] Creating layer Scale42
I0930 11:17:10.051513  3537 net.cpp:122] Setting up Scale42
I0930 11:17:10.051517  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.051519  3537 net.cpp:137] Memory required for data: 805011600
I0930 11:17:10.051523  3537 layer_factory.hpp:77] Creating layer elu_conv40
I0930 11:17:10.051527  3537 net.cpp:84] Creating Layer elu_conv40
I0930 11:17:10.051529  3537 net.cpp:406] elu_conv40 <- Convolution42
I0930 11:17:10.051533  3537 net.cpp:367] elu_conv40 -> Convolution42 (in-place)
I0930 11:17:10.051537  3537 net.cpp:122] Setting up elu_conv40
I0930 11:17:10.051540  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.051542  3537 net.cpp:137] Memory required for data: 806266000
I0930 11:17:10.051544  3537 layer_factory.hpp:77] Creating layer Convolution43
I0930 11:17:10.051550  3537 net.cpp:84] Creating Layer Convolution43
I0930 11:17:10.051553  3537 net.cpp:406] Convolution43 <- Convolution42
I0930 11:17:10.051556  3537 net.cpp:380] Convolution43 -> Convolution43
I0930 11:17:10.054055  3537 net.cpp:122] Setting up Convolution43
I0930 11:17:10.054067  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.054070  3537 net.cpp:137] Memory required for data: 807520400
I0930 11:17:10.054076  3537 layer_factory.hpp:77] Creating layer BatchNorm43
I0930 11:17:10.054082  3537 net.cpp:84] Creating Layer BatchNorm43
I0930 11:17:10.054085  3537 net.cpp:406] BatchNorm43 <- Convolution43
I0930 11:17:10.054090  3537 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I0930 11:17:10.054281  3537 net.cpp:122] Setting up BatchNorm43
I0930 11:17:10.054286  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.054289  3537 net.cpp:137] Memory required for data: 808774800
I0930 11:17:10.054293  3537 layer_factory.hpp:77] Creating layer Scale43
I0930 11:17:10.054298  3537 net.cpp:84] Creating Layer Scale43
I0930 11:17:10.054301  3537 net.cpp:406] Scale43 <- Convolution43
I0930 11:17:10.054306  3537 net.cpp:367] Scale43 -> Convolution43 (in-place)
I0930 11:17:10.054374  3537 layer_factory.hpp:77] Creating layer Scale43
I0930 11:17:10.054486  3537 net.cpp:122] Setting up Scale43
I0930 11:17:10.054491  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.054494  3537 net.cpp:137] Memory required for data: 810029200
I0930 11:17:10.054498  3537 layer_factory.hpp:77] Creating layer Eltwise20
I0930 11:17:10.054502  3537 net.cpp:84] Creating Layer Eltwise20
I0930 11:17:10.054505  3537 net.cpp:406] Eltwise20 <- Eltwise19_elu_conv39_0_split_1
I0930 11:17:10.054509  3537 net.cpp:406] Eltwise20 <- Convolution43
I0930 11:17:10.054528  3537 net.cpp:380] Eltwise20 -> Eltwise20
I0930 11:17:10.054548  3537 net.cpp:122] Setting up Eltwise20
I0930 11:17:10.054563  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.054564  3537 net.cpp:137] Memory required for data: 811283600
I0930 11:17:10.054566  3537 layer_factory.hpp:77] Creating layer elu_conv41
I0930 11:17:10.054570  3537 net.cpp:84] Creating Layer elu_conv41
I0930 11:17:10.054572  3537 net.cpp:406] elu_conv41 <- Eltwise20
I0930 11:17:10.054576  3537 net.cpp:367] elu_conv41 -> Eltwise20 (in-place)
I0930 11:17:10.054589  3537 net.cpp:122] Setting up elu_conv41
I0930 11:17:10.054592  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.054594  3537 net.cpp:137] Memory required for data: 812538000
I0930 11:17:10.054603  3537 layer_factory.hpp:77] Creating layer Eltwise20_elu_conv41_0_split
I0930 11:17:10.054607  3537 net.cpp:84] Creating Layer Eltwise20_elu_conv41_0_split
I0930 11:17:10.054610  3537 net.cpp:406] Eltwise20_elu_conv41_0_split <- Eltwise20
I0930 11:17:10.054612  3537 net.cpp:380] Eltwise20_elu_conv41_0_split -> Eltwise20_elu_conv41_0_split_0
I0930 11:17:10.054616  3537 net.cpp:380] Eltwise20_elu_conv41_0_split -> Eltwise20_elu_conv41_0_split_1
I0930 11:17:10.054642  3537 net.cpp:122] Setting up Eltwise20_elu_conv41_0_split
I0930 11:17:10.054646  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.054649  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.054651  3537 net.cpp:137] Memory required for data: 815046800
I0930 11:17:10.054653  3537 layer_factory.hpp:77] Creating layer Convolution44
I0930 11:17:10.054659  3537 net.cpp:84] Creating Layer Convolution44
I0930 11:17:10.054662  3537 net.cpp:406] Convolution44 <- Eltwise20_elu_conv41_0_split_0
I0930 11:17:10.054666  3537 net.cpp:380] Convolution44 -> Convolution44
I0930 11:17:10.056371  3537 net.cpp:122] Setting up Convolution44
I0930 11:17:10.056380  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.056382  3537 net.cpp:137] Memory required for data: 816301200
I0930 11:17:10.056387  3537 layer_factory.hpp:77] Creating layer BatchNorm44
I0930 11:17:10.056393  3537 net.cpp:84] Creating Layer BatchNorm44
I0930 11:17:10.056396  3537 net.cpp:406] BatchNorm44 <- Convolution44
I0930 11:17:10.056401  3537 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I0930 11:17:10.056545  3537 net.cpp:122] Setting up BatchNorm44
I0930 11:17:10.056550  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.056552  3537 net.cpp:137] Memory required for data: 817555600
I0930 11:17:10.056557  3537 layer_factory.hpp:77] Creating layer Scale44
I0930 11:17:10.056561  3537 net.cpp:84] Creating Layer Scale44
I0930 11:17:10.056563  3537 net.cpp:406] Scale44 <- Convolution44
I0930 11:17:10.056567  3537 net.cpp:367] Scale44 -> Convolution44 (in-place)
I0930 11:17:10.056596  3537 layer_factory.hpp:77] Creating layer Scale44
I0930 11:17:10.056679  3537 net.cpp:122] Setting up Scale44
I0930 11:17:10.056682  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.056684  3537 net.cpp:137] Memory required for data: 818810000
I0930 11:17:10.056689  3537 layer_factory.hpp:77] Creating layer elu_conv42
I0930 11:17:10.056692  3537 net.cpp:84] Creating Layer elu_conv42
I0930 11:17:10.056695  3537 net.cpp:406] elu_conv42 <- Convolution44
I0930 11:17:10.056699  3537 net.cpp:367] elu_conv42 -> Convolution44 (in-place)
I0930 11:17:10.056702  3537 net.cpp:122] Setting up elu_conv42
I0930 11:17:10.056705  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.056707  3537 net.cpp:137] Memory required for data: 820064400
I0930 11:17:10.056710  3537 layer_factory.hpp:77] Creating layer Convolution45
I0930 11:17:10.056716  3537 net.cpp:84] Creating Layer Convolution45
I0930 11:17:10.056720  3537 net.cpp:406] Convolution45 <- Convolution44
I0930 11:17:10.056723  3537 net.cpp:380] Convolution45 -> Convolution45
I0930 11:17:10.058698  3537 net.cpp:122] Setting up Convolution45
I0930 11:17:10.058706  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.058709  3537 net.cpp:137] Memory required for data: 821318800
I0930 11:17:10.058714  3537 layer_factory.hpp:77] Creating layer BatchNorm45
I0930 11:17:10.058719  3537 net.cpp:84] Creating Layer BatchNorm45
I0930 11:17:10.058722  3537 net.cpp:406] BatchNorm45 <- Convolution45
I0930 11:17:10.058725  3537 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I0930 11:17:10.058871  3537 net.cpp:122] Setting up BatchNorm45
I0930 11:17:10.058876  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.058878  3537 net.cpp:137] Memory required for data: 822573200
I0930 11:17:10.058882  3537 layer_factory.hpp:77] Creating layer Scale45
I0930 11:17:10.058887  3537 net.cpp:84] Creating Layer Scale45
I0930 11:17:10.058889  3537 net.cpp:406] Scale45 <- Convolution45
I0930 11:17:10.058899  3537 net.cpp:367] Scale45 -> Convolution45 (in-place)
I0930 11:17:10.058930  3537 layer_factory.hpp:77] Creating layer Scale45
I0930 11:17:10.059011  3537 net.cpp:122] Setting up Scale45
I0930 11:17:10.059015  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.059017  3537 net.cpp:137] Memory required for data: 823827600
I0930 11:17:10.059021  3537 layer_factory.hpp:77] Creating layer Eltwise21
I0930 11:17:10.059026  3537 net.cpp:84] Creating Layer Eltwise21
I0930 11:17:10.059029  3537 net.cpp:406] Eltwise21 <- Eltwise20_elu_conv41_0_split_1
I0930 11:17:10.059031  3537 net.cpp:406] Eltwise21 <- Convolution45
I0930 11:17:10.059036  3537 net.cpp:380] Eltwise21 -> Eltwise21
I0930 11:17:10.059051  3537 net.cpp:122] Setting up Eltwise21
I0930 11:17:10.059056  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.059057  3537 net.cpp:137] Memory required for data: 825082000
I0930 11:17:10.059059  3537 layer_factory.hpp:77] Creating layer elu_conv43
I0930 11:17:10.059063  3537 net.cpp:84] Creating Layer elu_conv43
I0930 11:17:10.059065  3537 net.cpp:406] elu_conv43 <- Eltwise21
I0930 11:17:10.059069  3537 net.cpp:367] elu_conv43 -> Eltwise21 (in-place)
I0930 11:17:10.059073  3537 net.cpp:122] Setting up elu_conv43
I0930 11:17:10.059077  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.059078  3537 net.cpp:137] Memory required for data: 826336400
I0930 11:17:10.059080  3537 layer_factory.hpp:77] Creating layer Eltwise21_elu_conv43_0_split
I0930 11:17:10.059084  3537 net.cpp:84] Creating Layer Eltwise21_elu_conv43_0_split
I0930 11:17:10.059087  3537 net.cpp:406] Eltwise21_elu_conv43_0_split <- Eltwise21
I0930 11:17:10.059089  3537 net.cpp:380] Eltwise21_elu_conv43_0_split -> Eltwise21_elu_conv43_0_split_0
I0930 11:17:10.059093  3537 net.cpp:380] Eltwise21_elu_conv43_0_split -> Eltwise21_elu_conv43_0_split_1
I0930 11:17:10.059118  3537 net.cpp:122] Setting up Eltwise21_elu_conv43_0_split
I0930 11:17:10.059120  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.059123  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.059125  3537 net.cpp:137] Memory required for data: 828845200
I0930 11:17:10.059128  3537 layer_factory.hpp:77] Creating layer Convolution46
I0930 11:17:10.059135  3537 net.cpp:84] Creating Layer Convolution46
I0930 11:17:10.059139  3537 net.cpp:406] Convolution46 <- Eltwise21_elu_conv43_0_split_0
I0930 11:17:10.059141  3537 net.cpp:380] Convolution46 -> Convolution46
I0930 11:17:10.060817  3537 net.cpp:122] Setting up Convolution46
I0930 11:17:10.060825  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.060827  3537 net.cpp:137] Memory required for data: 830099600
I0930 11:17:10.060832  3537 layer_factory.hpp:77] Creating layer BatchNorm46
I0930 11:17:10.060837  3537 net.cpp:84] Creating Layer BatchNorm46
I0930 11:17:10.060840  3537 net.cpp:406] BatchNorm46 <- Convolution46
I0930 11:17:10.060843  3537 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I0930 11:17:10.060986  3537 net.cpp:122] Setting up BatchNorm46
I0930 11:17:10.060989  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.060992  3537 net.cpp:137] Memory required for data: 831354000
I0930 11:17:10.060997  3537 layer_factory.hpp:77] Creating layer Scale46
I0930 11:17:10.061002  3537 net.cpp:84] Creating Layer Scale46
I0930 11:17:10.061003  3537 net.cpp:406] Scale46 <- Convolution46
I0930 11:17:10.061007  3537 net.cpp:367] Scale46 -> Convolution46 (in-place)
I0930 11:17:10.061034  3537 layer_factory.hpp:77] Creating layer Scale46
I0930 11:17:10.061112  3537 net.cpp:122] Setting up Scale46
I0930 11:17:10.061116  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.061118  3537 net.cpp:137] Memory required for data: 832608400
I0930 11:17:10.061122  3537 layer_factory.hpp:77] Creating layer elu_conv44
I0930 11:17:10.061126  3537 net.cpp:84] Creating Layer elu_conv44
I0930 11:17:10.061128  3537 net.cpp:406] elu_conv44 <- Convolution46
I0930 11:17:10.061132  3537 net.cpp:367] elu_conv44 -> Convolution46 (in-place)
I0930 11:17:10.061141  3537 net.cpp:122] Setting up elu_conv44
I0930 11:17:10.061146  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.061147  3537 net.cpp:137] Memory required for data: 833862800
I0930 11:17:10.061149  3537 layer_factory.hpp:77] Creating layer Convolution47
I0930 11:17:10.061156  3537 net.cpp:84] Creating Layer Convolution47
I0930 11:17:10.061158  3537 net.cpp:406] Convolution47 <- Convolution46
I0930 11:17:10.061163  3537 net.cpp:380] Convolution47 -> Convolution47
I0930 11:17:10.062791  3537 net.cpp:122] Setting up Convolution47
I0930 11:17:10.062799  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.062803  3537 net.cpp:137] Memory required for data: 835117200
I0930 11:17:10.062808  3537 layer_factory.hpp:77] Creating layer BatchNorm47
I0930 11:17:10.062813  3537 net.cpp:84] Creating Layer BatchNorm47
I0930 11:17:10.062815  3537 net.cpp:406] BatchNorm47 <- Convolution47
I0930 11:17:10.062819  3537 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I0930 11:17:10.062964  3537 net.cpp:122] Setting up BatchNorm47
I0930 11:17:10.062968  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.062971  3537 net.cpp:137] Memory required for data: 836371600
I0930 11:17:10.062975  3537 layer_factory.hpp:77] Creating layer Scale47
I0930 11:17:10.062980  3537 net.cpp:84] Creating Layer Scale47
I0930 11:17:10.062983  3537 net.cpp:406] Scale47 <- Convolution47
I0930 11:17:10.062985  3537 net.cpp:367] Scale47 -> Convolution47 (in-place)
I0930 11:17:10.063014  3537 layer_factory.hpp:77] Creating layer Scale47
I0930 11:17:10.063097  3537 net.cpp:122] Setting up Scale47
I0930 11:17:10.063102  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.063104  3537 net.cpp:137] Memory required for data: 837626000
I0930 11:17:10.063108  3537 layer_factory.hpp:77] Creating layer Eltwise22
I0930 11:17:10.063112  3537 net.cpp:84] Creating Layer Eltwise22
I0930 11:17:10.063115  3537 net.cpp:406] Eltwise22 <- Eltwise21_elu_conv43_0_split_1
I0930 11:17:10.063118  3537 net.cpp:406] Eltwise22 <- Convolution47
I0930 11:17:10.063122  3537 net.cpp:380] Eltwise22 -> Eltwise22
I0930 11:17:10.063138  3537 net.cpp:122] Setting up Eltwise22
I0930 11:17:10.063141  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.063143  3537 net.cpp:137] Memory required for data: 838880400
I0930 11:17:10.063145  3537 layer_factory.hpp:77] Creating layer elu_conv45
I0930 11:17:10.063149  3537 net.cpp:84] Creating Layer elu_conv45
I0930 11:17:10.063153  3537 net.cpp:406] elu_conv45 <- Eltwise22
I0930 11:17:10.063155  3537 net.cpp:367] elu_conv45 -> Eltwise22 (in-place)
I0930 11:17:10.063158  3537 net.cpp:122] Setting up elu_conv45
I0930 11:17:10.063161  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.063163  3537 net.cpp:137] Memory required for data: 840134800
I0930 11:17:10.063165  3537 layer_factory.hpp:77] Creating layer Eltwise22_elu_conv45_0_split
I0930 11:17:10.063169  3537 net.cpp:84] Creating Layer Eltwise22_elu_conv45_0_split
I0930 11:17:10.063171  3537 net.cpp:406] Eltwise22_elu_conv45_0_split <- Eltwise22
I0930 11:17:10.063174  3537 net.cpp:380] Eltwise22_elu_conv45_0_split -> Eltwise22_elu_conv45_0_split_0
I0930 11:17:10.063179  3537 net.cpp:380] Eltwise22_elu_conv45_0_split -> Eltwise22_elu_conv45_0_split_1
I0930 11:17:10.063201  3537 net.cpp:122] Setting up Eltwise22_elu_conv45_0_split
I0930 11:17:10.063205  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.063208  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.063210  3537 net.cpp:137] Memory required for data: 842643600
I0930 11:17:10.063212  3537 layer_factory.hpp:77] Creating layer Convolution48
I0930 11:17:10.063218  3537 net.cpp:84] Creating Layer Convolution48
I0930 11:17:10.063220  3537 net.cpp:406] Convolution48 <- Eltwise22_elu_conv45_0_split_0
I0930 11:17:10.063225  3537 net.cpp:380] Convolution48 -> Convolution48
I0930 11:17:10.064851  3537 net.cpp:122] Setting up Convolution48
I0930 11:17:10.064858  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.064862  3537 net.cpp:137] Memory required for data: 843898000
I0930 11:17:10.064872  3537 layer_factory.hpp:77] Creating layer BatchNorm48
I0930 11:17:10.064877  3537 net.cpp:84] Creating Layer BatchNorm48
I0930 11:17:10.064880  3537 net.cpp:406] BatchNorm48 <- Convolution48
I0930 11:17:10.064884  3537 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I0930 11:17:10.065028  3537 net.cpp:122] Setting up BatchNorm48
I0930 11:17:10.065032  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.065035  3537 net.cpp:137] Memory required for data: 845152400
I0930 11:17:10.065039  3537 layer_factory.hpp:77] Creating layer Scale48
I0930 11:17:10.065044  3537 net.cpp:84] Creating Layer Scale48
I0930 11:17:10.065047  3537 net.cpp:406] Scale48 <- Convolution48
I0930 11:17:10.065050  3537 net.cpp:367] Scale48 -> Convolution48 (in-place)
I0930 11:17:10.065078  3537 layer_factory.hpp:77] Creating layer Scale48
I0930 11:17:10.065158  3537 net.cpp:122] Setting up Scale48
I0930 11:17:10.065162  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.065165  3537 net.cpp:137] Memory required for data: 846406800
I0930 11:17:10.065168  3537 layer_factory.hpp:77] Creating layer elu_conv46
I0930 11:17:10.065173  3537 net.cpp:84] Creating Layer elu_conv46
I0930 11:17:10.065176  3537 net.cpp:406] elu_conv46 <- Convolution48
I0930 11:17:10.065179  3537 net.cpp:367] elu_conv46 -> Convolution48 (in-place)
I0930 11:17:10.065182  3537 net.cpp:122] Setting up elu_conv46
I0930 11:17:10.065186  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.065188  3537 net.cpp:137] Memory required for data: 847661200
I0930 11:17:10.065191  3537 layer_factory.hpp:77] Creating layer Convolution49
I0930 11:17:10.065196  3537 net.cpp:84] Creating Layer Convolution49
I0930 11:17:10.065198  3537 net.cpp:406] Convolution49 <- Convolution48
I0930 11:17:10.065202  3537 net.cpp:380] Convolution49 -> Convolution49
I0930 11:17:10.067147  3537 net.cpp:122] Setting up Convolution49
I0930 11:17:10.067157  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.067158  3537 net.cpp:137] Memory required for data: 848915600
I0930 11:17:10.067163  3537 layer_factory.hpp:77] Creating layer BatchNorm49
I0930 11:17:10.067168  3537 net.cpp:84] Creating Layer BatchNorm49
I0930 11:17:10.067172  3537 net.cpp:406] BatchNorm49 <- Convolution49
I0930 11:17:10.067175  3537 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I0930 11:17:10.067323  3537 net.cpp:122] Setting up BatchNorm49
I0930 11:17:10.067328  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.067330  3537 net.cpp:137] Memory required for data: 850170000
I0930 11:17:10.067335  3537 layer_factory.hpp:77] Creating layer Scale49
I0930 11:17:10.067340  3537 net.cpp:84] Creating Layer Scale49
I0930 11:17:10.067342  3537 net.cpp:406] Scale49 <- Convolution49
I0930 11:17:10.067347  3537 net.cpp:367] Scale49 -> Convolution49 (in-place)
I0930 11:17:10.067374  3537 layer_factory.hpp:77] Creating layer Scale49
I0930 11:17:10.067456  3537 net.cpp:122] Setting up Scale49
I0930 11:17:10.067461  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.067462  3537 net.cpp:137] Memory required for data: 851424400
I0930 11:17:10.067466  3537 layer_factory.hpp:77] Creating layer Eltwise23
I0930 11:17:10.067471  3537 net.cpp:84] Creating Layer Eltwise23
I0930 11:17:10.067473  3537 net.cpp:406] Eltwise23 <- Eltwise22_elu_conv45_0_split_1
I0930 11:17:10.067476  3537 net.cpp:406] Eltwise23 <- Convolution49
I0930 11:17:10.067481  3537 net.cpp:380] Eltwise23 -> Eltwise23
I0930 11:17:10.067497  3537 net.cpp:122] Setting up Eltwise23
I0930 11:17:10.067500  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.067502  3537 net.cpp:137] Memory required for data: 852678800
I0930 11:17:10.067504  3537 layer_factory.hpp:77] Creating layer elu_conv47
I0930 11:17:10.067508  3537 net.cpp:84] Creating Layer elu_conv47
I0930 11:17:10.067510  3537 net.cpp:406] elu_conv47 <- Eltwise23
I0930 11:17:10.067514  3537 net.cpp:367] elu_conv47 -> Eltwise23 (in-place)
I0930 11:17:10.067518  3537 net.cpp:122] Setting up elu_conv47
I0930 11:17:10.067528  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.067530  3537 net.cpp:137] Memory required for data: 853933200
I0930 11:17:10.067533  3537 layer_factory.hpp:77] Creating layer Eltwise23_elu_conv47_0_split
I0930 11:17:10.067535  3537 net.cpp:84] Creating Layer Eltwise23_elu_conv47_0_split
I0930 11:17:10.067538  3537 net.cpp:406] Eltwise23_elu_conv47_0_split <- Eltwise23
I0930 11:17:10.067541  3537 net.cpp:380] Eltwise23_elu_conv47_0_split -> Eltwise23_elu_conv47_0_split_0
I0930 11:17:10.067545  3537 net.cpp:380] Eltwise23_elu_conv47_0_split -> Eltwise23_elu_conv47_0_split_1
I0930 11:17:10.067571  3537 net.cpp:122] Setting up Eltwise23_elu_conv47_0_split
I0930 11:17:10.067575  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.067577  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.067579  3537 net.cpp:137] Memory required for data: 856442000
I0930 11:17:10.067582  3537 layer_factory.hpp:77] Creating layer Convolution50
I0930 11:17:10.067589  3537 net.cpp:84] Creating Layer Convolution50
I0930 11:17:10.067591  3537 net.cpp:406] Convolution50 <- Eltwise23_elu_conv47_0_split_0
I0930 11:17:10.067595  3537 net.cpp:380] Convolution50 -> Convolution50
I0930 11:17:10.084450  3537 net.cpp:122] Setting up Convolution50
I0930 11:17:10.084465  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.084467  3537 net.cpp:137] Memory required for data: 857696400
I0930 11:17:10.084473  3537 layer_factory.hpp:77] Creating layer BatchNorm50
I0930 11:17:10.084480  3537 net.cpp:84] Creating Layer BatchNorm50
I0930 11:17:10.084482  3537 net.cpp:406] BatchNorm50 <- Convolution50
I0930 11:17:10.084487  3537 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I0930 11:17:10.084643  3537 net.cpp:122] Setting up BatchNorm50
I0930 11:17:10.084648  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.084650  3537 net.cpp:137] Memory required for data: 858950800
I0930 11:17:10.084656  3537 layer_factory.hpp:77] Creating layer Scale50
I0930 11:17:10.084661  3537 net.cpp:84] Creating Layer Scale50
I0930 11:17:10.084663  3537 net.cpp:406] Scale50 <- Convolution50
I0930 11:17:10.084667  3537 net.cpp:367] Scale50 -> Convolution50 (in-place)
I0930 11:17:10.084698  3537 layer_factory.hpp:77] Creating layer Scale50
I0930 11:17:10.084786  3537 net.cpp:122] Setting up Scale50
I0930 11:17:10.084791  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.084794  3537 net.cpp:137] Memory required for data: 860205200
I0930 11:17:10.084797  3537 layer_factory.hpp:77] Creating layer elu_conv48
I0930 11:17:10.084802  3537 net.cpp:84] Creating Layer elu_conv48
I0930 11:17:10.084805  3537 net.cpp:406] elu_conv48 <- Convolution50
I0930 11:17:10.084810  3537 net.cpp:367] elu_conv48 -> Convolution50 (in-place)
I0930 11:17:10.084813  3537 net.cpp:122] Setting up elu_conv48
I0930 11:17:10.084816  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.084818  3537 net.cpp:137] Memory required for data: 861459600
I0930 11:17:10.084821  3537 layer_factory.hpp:77] Creating layer Convolution51
I0930 11:17:10.084828  3537 net.cpp:84] Creating Layer Convolution51
I0930 11:17:10.084830  3537 net.cpp:406] Convolution51 <- Convolution50
I0930 11:17:10.084836  3537 net.cpp:380] Convolution51 -> Convolution51
I0930 11:17:10.087152  3537 net.cpp:122] Setting up Convolution51
I0930 11:17:10.087164  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.087167  3537 net.cpp:137] Memory required for data: 862714000
I0930 11:17:10.087172  3537 layer_factory.hpp:77] Creating layer BatchNorm51
I0930 11:17:10.087178  3537 net.cpp:84] Creating Layer BatchNorm51
I0930 11:17:10.087182  3537 net.cpp:406] BatchNorm51 <- Convolution51
I0930 11:17:10.087186  3537 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I0930 11:17:10.087343  3537 net.cpp:122] Setting up BatchNorm51
I0930 11:17:10.087348  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.087350  3537 net.cpp:137] Memory required for data: 863968400
I0930 11:17:10.087355  3537 layer_factory.hpp:77] Creating layer Scale51
I0930 11:17:10.087370  3537 net.cpp:84] Creating Layer Scale51
I0930 11:17:10.087373  3537 net.cpp:406] Scale51 <- Convolution51
I0930 11:17:10.087378  3537 net.cpp:367] Scale51 -> Convolution51 (in-place)
I0930 11:17:10.087409  3537 layer_factory.hpp:77] Creating layer Scale51
I0930 11:17:10.087496  3537 net.cpp:122] Setting up Scale51
I0930 11:17:10.087501  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.087502  3537 net.cpp:137] Memory required for data: 865222800
I0930 11:17:10.087507  3537 layer_factory.hpp:77] Creating layer Eltwise24
I0930 11:17:10.087512  3537 net.cpp:84] Creating Layer Eltwise24
I0930 11:17:10.087514  3537 net.cpp:406] Eltwise24 <- Eltwise23_elu_conv47_0_split_1
I0930 11:17:10.087517  3537 net.cpp:406] Eltwise24 <- Convolution51
I0930 11:17:10.087522  3537 net.cpp:380] Eltwise24 -> Eltwise24
I0930 11:17:10.087540  3537 net.cpp:122] Setting up Eltwise24
I0930 11:17:10.087544  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.087546  3537 net.cpp:137] Memory required for data: 866477200
I0930 11:17:10.087548  3537 layer_factory.hpp:77] Creating layer elu_conv49
I0930 11:17:10.087553  3537 net.cpp:84] Creating Layer elu_conv49
I0930 11:17:10.087555  3537 net.cpp:406] elu_conv49 <- Eltwise24
I0930 11:17:10.087558  3537 net.cpp:367] elu_conv49 -> Eltwise24 (in-place)
I0930 11:17:10.087561  3537 net.cpp:122] Setting up elu_conv49
I0930 11:17:10.087565  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.087568  3537 net.cpp:137] Memory required for data: 867731600
I0930 11:17:10.087569  3537 layer_factory.hpp:77] Creating layer Eltwise24_elu_conv49_0_split
I0930 11:17:10.087574  3537 net.cpp:84] Creating Layer Eltwise24_elu_conv49_0_split
I0930 11:17:10.087576  3537 net.cpp:406] Eltwise24_elu_conv49_0_split <- Eltwise24
I0930 11:17:10.087579  3537 net.cpp:380] Eltwise24_elu_conv49_0_split -> Eltwise24_elu_conv49_0_split_0
I0930 11:17:10.087584  3537 net.cpp:380] Eltwise24_elu_conv49_0_split -> Eltwise24_elu_conv49_0_split_1
I0930 11:17:10.087610  3537 net.cpp:122] Setting up Eltwise24_elu_conv49_0_split
I0930 11:17:10.087613  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.087616  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.087618  3537 net.cpp:137] Memory required for data: 870240400
I0930 11:17:10.087620  3537 layer_factory.hpp:77] Creating layer Convolution52
I0930 11:17:10.087626  3537 net.cpp:84] Creating Layer Convolution52
I0930 11:17:10.087630  3537 net.cpp:406] Convolution52 <- Eltwise24_elu_conv49_0_split_0
I0930 11:17:10.087633  3537 net.cpp:380] Convolution52 -> Convolution52
I0930 11:17:10.089335  3537 net.cpp:122] Setting up Convolution52
I0930 11:17:10.089344  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.089347  3537 net.cpp:137] Memory required for data: 871494800
I0930 11:17:10.089352  3537 layer_factory.hpp:77] Creating layer BatchNorm52
I0930 11:17:10.089359  3537 net.cpp:84] Creating Layer BatchNorm52
I0930 11:17:10.089361  3537 net.cpp:406] BatchNorm52 <- Convolution52
I0930 11:17:10.089365  3537 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I0930 11:17:10.089512  3537 net.cpp:122] Setting up BatchNorm52
I0930 11:17:10.089516  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.089519  3537 net.cpp:137] Memory required for data: 872749200
I0930 11:17:10.089524  3537 layer_factory.hpp:77] Creating layer Scale52
I0930 11:17:10.089527  3537 net.cpp:84] Creating Layer Scale52
I0930 11:17:10.089530  3537 net.cpp:406] Scale52 <- Convolution52
I0930 11:17:10.089534  3537 net.cpp:367] Scale52 -> Convolution52 (in-place)
I0930 11:17:10.089562  3537 layer_factory.hpp:77] Creating layer Scale52
I0930 11:17:10.089646  3537 net.cpp:122] Setting up Scale52
I0930 11:17:10.089650  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.089653  3537 net.cpp:137] Memory required for data: 874003600
I0930 11:17:10.089656  3537 layer_factory.hpp:77] Creating layer elu_conv50
I0930 11:17:10.089660  3537 net.cpp:84] Creating Layer elu_conv50
I0930 11:17:10.089668  3537 net.cpp:406] elu_conv50 <- Convolution52
I0930 11:17:10.089673  3537 net.cpp:367] elu_conv50 -> Convolution52 (in-place)
I0930 11:17:10.089678  3537 net.cpp:122] Setting up elu_conv50
I0930 11:17:10.089680  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.089682  3537 net.cpp:137] Memory required for data: 875258000
I0930 11:17:10.089684  3537 layer_factory.hpp:77] Creating layer Convolution53
I0930 11:17:10.089710  3537 net.cpp:84] Creating Layer Convolution53
I0930 11:17:10.089714  3537 net.cpp:406] Convolution53 <- Convolution52
I0930 11:17:10.089717  3537 net.cpp:380] Convolution53 -> Convolution53
I0930 11:17:10.091763  3537 net.cpp:122] Setting up Convolution53
I0930 11:17:10.091773  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.091775  3537 net.cpp:137] Memory required for data: 876512400
I0930 11:17:10.091780  3537 layer_factory.hpp:77] Creating layer BatchNorm53
I0930 11:17:10.091785  3537 net.cpp:84] Creating Layer BatchNorm53
I0930 11:17:10.091789  3537 net.cpp:406] BatchNorm53 <- Convolution53
I0930 11:17:10.091794  3537 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I0930 11:17:10.091946  3537 net.cpp:122] Setting up BatchNorm53
I0930 11:17:10.091951  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.091954  3537 net.cpp:137] Memory required for data: 877766800
I0930 11:17:10.091959  3537 layer_factory.hpp:77] Creating layer Scale53
I0930 11:17:10.091964  3537 net.cpp:84] Creating Layer Scale53
I0930 11:17:10.091965  3537 net.cpp:406] Scale53 <- Convolution53
I0930 11:17:10.091969  3537 net.cpp:367] Scale53 -> Convolution53 (in-place)
I0930 11:17:10.091998  3537 layer_factory.hpp:77] Creating layer Scale53
I0930 11:17:10.092085  3537 net.cpp:122] Setting up Scale53
I0930 11:17:10.092090  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.092092  3537 net.cpp:137] Memory required for data: 879021200
I0930 11:17:10.092097  3537 layer_factory.hpp:77] Creating layer Eltwise25
I0930 11:17:10.092100  3537 net.cpp:84] Creating Layer Eltwise25
I0930 11:17:10.092103  3537 net.cpp:406] Eltwise25 <- Eltwise24_elu_conv49_0_split_1
I0930 11:17:10.092106  3537 net.cpp:406] Eltwise25 <- Convolution53
I0930 11:17:10.092110  3537 net.cpp:380] Eltwise25 -> Eltwise25
I0930 11:17:10.092128  3537 net.cpp:122] Setting up Eltwise25
I0930 11:17:10.092131  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.092133  3537 net.cpp:137] Memory required for data: 880275600
I0930 11:17:10.092136  3537 layer_factory.hpp:77] Creating layer elu_conv51
I0930 11:17:10.092139  3537 net.cpp:84] Creating Layer elu_conv51
I0930 11:17:10.092142  3537 net.cpp:406] elu_conv51 <- Eltwise25
I0930 11:17:10.092145  3537 net.cpp:367] elu_conv51 -> Eltwise25 (in-place)
I0930 11:17:10.092149  3537 net.cpp:122] Setting up elu_conv51
I0930 11:17:10.092151  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.092154  3537 net.cpp:137] Memory required for data: 881530000
I0930 11:17:10.092156  3537 layer_factory.hpp:77] Creating layer Eltwise25_elu_conv51_0_split
I0930 11:17:10.092159  3537 net.cpp:84] Creating Layer Eltwise25_elu_conv51_0_split
I0930 11:17:10.092161  3537 net.cpp:406] Eltwise25_elu_conv51_0_split <- Eltwise25
I0930 11:17:10.092165  3537 net.cpp:380] Eltwise25_elu_conv51_0_split -> Eltwise25_elu_conv51_0_split_0
I0930 11:17:10.092170  3537 net.cpp:380] Eltwise25_elu_conv51_0_split -> Eltwise25_elu_conv51_0_split_1
I0930 11:17:10.092195  3537 net.cpp:122] Setting up Eltwise25_elu_conv51_0_split
I0930 11:17:10.092198  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.092200  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.092203  3537 net.cpp:137] Memory required for data: 884038800
I0930 11:17:10.092206  3537 layer_factory.hpp:77] Creating layer Convolution54
I0930 11:17:10.092211  3537 net.cpp:84] Creating Layer Convolution54
I0930 11:17:10.092213  3537 net.cpp:406] Convolution54 <- Eltwise25_elu_conv51_0_split_0
I0930 11:17:10.092218  3537 net.cpp:380] Convolution54 -> Convolution54
I0930 11:17:10.094422  3537 net.cpp:122] Setting up Convolution54
I0930 11:17:10.094439  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.094442  3537 net.cpp:137] Memory required for data: 885293200
I0930 11:17:10.094447  3537 layer_factory.hpp:77] Creating layer BatchNorm54
I0930 11:17:10.094454  3537 net.cpp:84] Creating Layer BatchNorm54
I0930 11:17:10.094456  3537 net.cpp:406] BatchNorm54 <- Convolution54
I0930 11:17:10.094460  3537 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I0930 11:17:10.094637  3537 net.cpp:122] Setting up BatchNorm54
I0930 11:17:10.094642  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.094645  3537 net.cpp:137] Memory required for data: 886547600
I0930 11:17:10.094650  3537 layer_factory.hpp:77] Creating layer Scale54
I0930 11:17:10.094655  3537 net.cpp:84] Creating Layer Scale54
I0930 11:17:10.094657  3537 net.cpp:406] Scale54 <- Convolution54
I0930 11:17:10.094661  3537 net.cpp:367] Scale54 -> Convolution54 (in-place)
I0930 11:17:10.094691  3537 layer_factory.hpp:77] Creating layer Scale54
I0930 11:17:10.094779  3537 net.cpp:122] Setting up Scale54
I0930 11:17:10.094782  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.094785  3537 net.cpp:137] Memory required for data: 887802000
I0930 11:17:10.094789  3537 layer_factory.hpp:77] Creating layer elu_conv52
I0930 11:17:10.094792  3537 net.cpp:84] Creating Layer elu_conv52
I0930 11:17:10.094795  3537 net.cpp:406] elu_conv52 <- Convolution54
I0930 11:17:10.094799  3537 net.cpp:367] elu_conv52 -> Convolution54 (in-place)
I0930 11:17:10.094802  3537 net.cpp:122] Setting up elu_conv52
I0930 11:17:10.094806  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.094808  3537 net.cpp:137] Memory required for data: 889056400
I0930 11:17:10.094810  3537 layer_factory.hpp:77] Creating layer Convolution55
I0930 11:17:10.094817  3537 net.cpp:84] Creating Layer Convolution55
I0930 11:17:10.094820  3537 net.cpp:406] Convolution55 <- Convolution54
I0930 11:17:10.094823  3537 net.cpp:380] Convolution55 -> Convolution55
I0930 11:17:10.096837  3537 net.cpp:122] Setting up Convolution55
I0930 11:17:10.096845  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.096848  3537 net.cpp:137] Memory required for data: 890310800
I0930 11:17:10.096853  3537 layer_factory.hpp:77] Creating layer BatchNorm55
I0930 11:17:10.096858  3537 net.cpp:84] Creating Layer BatchNorm55
I0930 11:17:10.096860  3537 net.cpp:406] BatchNorm55 <- Convolution55
I0930 11:17:10.096864  3537 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I0930 11:17:10.097018  3537 net.cpp:122] Setting up BatchNorm55
I0930 11:17:10.097023  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.097025  3537 net.cpp:137] Memory required for data: 891565200
I0930 11:17:10.097030  3537 layer_factory.hpp:77] Creating layer Scale55
I0930 11:17:10.097035  3537 net.cpp:84] Creating Layer Scale55
I0930 11:17:10.097038  3537 net.cpp:406] Scale55 <- Convolution55
I0930 11:17:10.097041  3537 net.cpp:367] Scale55 -> Convolution55 (in-place)
I0930 11:17:10.097070  3537 layer_factory.hpp:77] Creating layer Scale55
I0930 11:17:10.097157  3537 net.cpp:122] Setting up Scale55
I0930 11:17:10.097162  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.097163  3537 net.cpp:137] Memory required for data: 892819600
I0930 11:17:10.097167  3537 layer_factory.hpp:77] Creating layer Eltwise26
I0930 11:17:10.097172  3537 net.cpp:84] Creating Layer Eltwise26
I0930 11:17:10.097174  3537 net.cpp:406] Eltwise26 <- Eltwise25_elu_conv51_0_split_1
I0930 11:17:10.097177  3537 net.cpp:406] Eltwise26 <- Convolution55
I0930 11:17:10.097180  3537 net.cpp:380] Eltwise26 -> Eltwise26
I0930 11:17:10.097198  3537 net.cpp:122] Setting up Eltwise26
I0930 11:17:10.097203  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.097204  3537 net.cpp:137] Memory required for data: 894074000
I0930 11:17:10.097206  3537 layer_factory.hpp:77] Creating layer elu_conv53
I0930 11:17:10.097210  3537 net.cpp:84] Creating Layer elu_conv53
I0930 11:17:10.097213  3537 net.cpp:406] elu_conv53 <- Eltwise26
I0930 11:17:10.097223  3537 net.cpp:367] elu_conv53 -> Eltwise26 (in-place)
I0930 11:17:10.097228  3537 net.cpp:122] Setting up elu_conv53
I0930 11:17:10.097230  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.097232  3537 net.cpp:137] Memory required for data: 895328400
I0930 11:17:10.097235  3537 layer_factory.hpp:77] Creating layer Eltwise26_elu_conv53_0_split
I0930 11:17:10.097239  3537 net.cpp:84] Creating Layer Eltwise26_elu_conv53_0_split
I0930 11:17:10.097240  3537 net.cpp:406] Eltwise26_elu_conv53_0_split <- Eltwise26
I0930 11:17:10.097244  3537 net.cpp:380] Eltwise26_elu_conv53_0_split -> Eltwise26_elu_conv53_0_split_0
I0930 11:17:10.097247  3537 net.cpp:380] Eltwise26_elu_conv53_0_split -> Eltwise26_elu_conv53_0_split_1
I0930 11:17:10.097275  3537 net.cpp:122] Setting up Eltwise26_elu_conv53_0_split
I0930 11:17:10.097278  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.097281  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.097283  3537 net.cpp:137] Memory required for data: 897837200
I0930 11:17:10.097285  3537 layer_factory.hpp:77] Creating layer Convolution56
I0930 11:17:10.113245  3537 net.cpp:84] Creating Layer Convolution56
I0930 11:17:10.113251  3537 net.cpp:406] Convolution56 <- Eltwise26_elu_conv53_0_split_0
I0930 11:17:10.113261  3537 net.cpp:380] Convolution56 -> Convolution56
I0930 11:17:10.115165  3537 net.cpp:122] Setting up Convolution56
I0930 11:17:10.115176  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.115180  3537 net.cpp:137] Memory required for data: 899091600
I0930 11:17:10.115185  3537 layer_factory.hpp:77] Creating layer BatchNorm56
I0930 11:17:10.115190  3537 net.cpp:84] Creating Layer BatchNorm56
I0930 11:17:10.115192  3537 net.cpp:406] BatchNorm56 <- Convolution56
I0930 11:17:10.115196  3537 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I0930 11:17:10.115350  3537 net.cpp:122] Setting up BatchNorm56
I0930 11:17:10.115355  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.115357  3537 net.cpp:137] Memory required for data: 900346000
I0930 11:17:10.115362  3537 layer_factory.hpp:77] Creating layer Scale56
I0930 11:17:10.115366  3537 net.cpp:84] Creating Layer Scale56
I0930 11:17:10.115370  3537 net.cpp:406] Scale56 <- Convolution56
I0930 11:17:10.115372  3537 net.cpp:367] Scale56 -> Convolution56 (in-place)
I0930 11:17:10.115402  3537 layer_factory.hpp:77] Creating layer Scale56
I0930 11:17:10.115489  3537 net.cpp:122] Setting up Scale56
I0930 11:17:10.115494  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.115496  3537 net.cpp:137] Memory required for data: 901600400
I0930 11:17:10.115499  3537 layer_factory.hpp:77] Creating layer elu_conv54
I0930 11:17:10.115504  3537 net.cpp:84] Creating Layer elu_conv54
I0930 11:17:10.115506  3537 net.cpp:406] elu_conv54 <- Convolution56
I0930 11:17:10.115509  3537 net.cpp:367] elu_conv54 -> Convolution56 (in-place)
I0930 11:17:10.115514  3537 net.cpp:122] Setting up elu_conv54
I0930 11:17:10.115516  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.115520  3537 net.cpp:137] Memory required for data: 902854800
I0930 11:17:10.115521  3537 layer_factory.hpp:77] Creating layer Convolution57
I0930 11:17:10.115530  3537 net.cpp:84] Creating Layer Convolution57
I0930 11:17:10.115532  3537 net.cpp:406] Convolution57 <- Convolution56
I0930 11:17:10.115536  3537 net.cpp:380] Convolution57 -> Convolution57
I0930 11:17:10.117343  3537 net.cpp:122] Setting up Convolution57
I0930 11:17:10.117352  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.117354  3537 net.cpp:137] Memory required for data: 904109200
I0930 11:17:10.117359  3537 layer_factory.hpp:77] Creating layer BatchNorm57
I0930 11:17:10.117365  3537 net.cpp:84] Creating Layer BatchNorm57
I0930 11:17:10.117368  3537 net.cpp:406] BatchNorm57 <- Convolution57
I0930 11:17:10.117373  3537 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I0930 11:17:10.117542  3537 net.cpp:122] Setting up BatchNorm57
I0930 11:17:10.117558  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.117578  3537 net.cpp:137] Memory required for data: 905363600
I0930 11:17:10.117583  3537 layer_factory.hpp:77] Creating layer Scale57
I0930 11:17:10.117588  3537 net.cpp:84] Creating Layer Scale57
I0930 11:17:10.117590  3537 net.cpp:406] Scale57 <- Convolution57
I0930 11:17:10.117594  3537 net.cpp:367] Scale57 -> Convolution57 (in-place)
I0930 11:17:10.117624  3537 layer_factory.hpp:77] Creating layer Scale57
I0930 11:17:10.117712  3537 net.cpp:122] Setting up Scale57
I0930 11:17:10.117717  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.117718  3537 net.cpp:137] Memory required for data: 906618000
I0930 11:17:10.117722  3537 layer_factory.hpp:77] Creating layer Eltwise27
I0930 11:17:10.117727  3537 net.cpp:84] Creating Layer Eltwise27
I0930 11:17:10.117730  3537 net.cpp:406] Eltwise27 <- Eltwise26_elu_conv53_0_split_1
I0930 11:17:10.117733  3537 net.cpp:406] Eltwise27 <- Convolution57
I0930 11:17:10.117738  3537 net.cpp:380] Eltwise27 -> Eltwise27
I0930 11:17:10.117755  3537 net.cpp:122] Setting up Eltwise27
I0930 11:17:10.117759  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.117761  3537 net.cpp:137] Memory required for data: 907872400
I0930 11:17:10.117763  3537 layer_factory.hpp:77] Creating layer elu_conv55
I0930 11:17:10.117768  3537 net.cpp:84] Creating Layer elu_conv55
I0930 11:17:10.117769  3537 net.cpp:406] elu_conv55 <- Eltwise27
I0930 11:17:10.117774  3537 net.cpp:367] elu_conv55 -> Eltwise27 (in-place)
I0930 11:17:10.117777  3537 net.cpp:122] Setting up elu_conv55
I0930 11:17:10.117780  3537 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 11:17:10.117782  3537 net.cpp:137] Memory required for data: 909126800
I0930 11:17:10.117784  3537 layer_factory.hpp:77] Creating layer Pooling1
I0930 11:17:10.117789  3537 net.cpp:84] Creating Layer Pooling1
I0930 11:17:10.117791  3537 net.cpp:406] Pooling1 <- Eltwise27
I0930 11:17:10.117794  3537 net.cpp:380] Pooling1 -> Pooling1
I0930 11:17:10.118273  3537 net.cpp:122] Setting up Pooling1
I0930 11:17:10.118281  3537 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0930 11:17:10.118284  3537 net.cpp:137] Memory required for data: 909152400
I0930 11:17:10.118288  3537 layer_factory.hpp:77] Creating layer InnerProduct1
I0930 11:17:10.118297  3537 net.cpp:84] Creating Layer InnerProduct1
I0930 11:17:10.118300  3537 net.cpp:406] InnerProduct1 <- Pooling1
I0930 11:17:10.118304  3537 net.cpp:380] InnerProduct1 -> InnerProduct1
I0930 11:17:10.118415  3537 net.cpp:122] Setting up InnerProduct1
I0930 11:17:10.118419  3537 net.cpp:129] Top shape: 100 10 (1000)
I0930 11:17:10.118422  3537 net.cpp:137] Memory required for data: 909156400
I0930 11:17:10.118427  3537 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0930 11:17:10.118430  3537 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0930 11:17:10.118432  3537 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I0930 11:17:10.118436  3537 net.cpp:406] SoftmaxWithLoss1 <- Data2
I0930 11:17:10.118441  3537 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0930 11:17:10.118446  3537 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0930 11:17:10.118664  3537 net.cpp:122] Setting up SoftmaxWithLoss1
I0930 11:17:10.118671  3537 net.cpp:129] Top shape: (1)
I0930 11:17:10.118674  3537 net.cpp:132]     with loss weight 1
I0930 11:17:10.118687  3537 net.cpp:137] Memory required for data: 909156404
I0930 11:17:10.118690  3537 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0930 11:17:10.118692  3537 net.cpp:198] InnerProduct1 needs backward computation.
I0930 11:17:10.118695  3537 net.cpp:198] Pooling1 needs backward computation.
I0930 11:17:10.118697  3537 net.cpp:198] elu_conv55 needs backward computation.
I0930 11:17:10.118700  3537 net.cpp:198] Eltwise27 needs backward computation.
I0930 11:17:10.118701  3537 net.cpp:198] Scale57 needs backward computation.
I0930 11:17:10.118705  3537 net.cpp:198] BatchNorm57 needs backward computation.
I0930 11:17:10.118706  3537 net.cpp:198] Convolution57 needs backward computation.
I0930 11:17:10.118708  3537 net.cpp:198] elu_conv54 needs backward computation.
I0930 11:17:10.118716  3537 net.cpp:198] Scale56 needs backward computation.
I0930 11:17:10.118719  3537 net.cpp:198] BatchNorm56 needs backward computation.
I0930 11:17:10.118721  3537 net.cpp:198] Convolution56 needs backward computation.
I0930 11:17:10.118723  3537 net.cpp:198] Eltwise26_elu_conv53_0_split needs backward computation.
I0930 11:17:10.118726  3537 net.cpp:198] elu_conv53 needs backward computation.
I0930 11:17:10.118728  3537 net.cpp:198] Eltwise26 needs backward computation.
I0930 11:17:10.118731  3537 net.cpp:198] Scale55 needs backward computation.
I0930 11:17:10.118733  3537 net.cpp:198] BatchNorm55 needs backward computation.
I0930 11:17:10.118736  3537 net.cpp:198] Convolution55 needs backward computation.
I0930 11:17:10.118737  3537 net.cpp:198] elu_conv52 needs backward computation.
I0930 11:17:10.118739  3537 net.cpp:198] Scale54 needs backward computation.
I0930 11:17:10.118741  3537 net.cpp:198] BatchNorm54 needs backward computation.
I0930 11:17:10.118743  3537 net.cpp:198] Convolution54 needs backward computation.
I0930 11:17:10.118746  3537 net.cpp:198] Eltwise25_elu_conv51_0_split needs backward computation.
I0930 11:17:10.118749  3537 net.cpp:198] elu_conv51 needs backward computation.
I0930 11:17:10.118752  3537 net.cpp:198] Eltwise25 needs backward computation.
I0930 11:17:10.118753  3537 net.cpp:198] Scale53 needs backward computation.
I0930 11:17:10.118757  3537 net.cpp:198] BatchNorm53 needs backward computation.
I0930 11:17:10.118758  3537 net.cpp:198] Convolution53 needs backward computation.
I0930 11:17:10.118760  3537 net.cpp:198] elu_conv50 needs backward computation.
I0930 11:17:10.118762  3537 net.cpp:198] Scale52 needs backward computation.
I0930 11:17:10.118764  3537 net.cpp:198] BatchNorm52 needs backward computation.
I0930 11:17:10.118767  3537 net.cpp:198] Convolution52 needs backward computation.
I0930 11:17:10.118769  3537 net.cpp:198] Eltwise24_elu_conv49_0_split needs backward computation.
I0930 11:17:10.118772  3537 net.cpp:198] elu_conv49 needs backward computation.
I0930 11:17:10.118774  3537 net.cpp:198] Eltwise24 needs backward computation.
I0930 11:17:10.118777  3537 net.cpp:198] Scale51 needs backward computation.
I0930 11:17:10.118779  3537 net.cpp:198] BatchNorm51 needs backward computation.
I0930 11:17:10.118782  3537 net.cpp:198] Convolution51 needs backward computation.
I0930 11:17:10.118784  3537 net.cpp:198] elu_conv48 needs backward computation.
I0930 11:17:10.118787  3537 net.cpp:198] Scale50 needs backward computation.
I0930 11:17:10.118788  3537 net.cpp:198] BatchNorm50 needs backward computation.
I0930 11:17:10.118790  3537 net.cpp:198] Convolution50 needs backward computation.
I0930 11:17:10.118793  3537 net.cpp:198] Eltwise23_elu_conv47_0_split needs backward computation.
I0930 11:17:10.118795  3537 net.cpp:198] elu_conv47 needs backward computation.
I0930 11:17:10.118798  3537 net.cpp:198] Eltwise23 needs backward computation.
I0930 11:17:10.118800  3537 net.cpp:198] Scale49 needs backward computation.
I0930 11:17:10.118803  3537 net.cpp:198] BatchNorm49 needs backward computation.
I0930 11:17:10.118805  3537 net.cpp:198] Convolution49 needs backward computation.
I0930 11:17:10.118808  3537 net.cpp:198] elu_conv46 needs backward computation.
I0930 11:17:10.118809  3537 net.cpp:198] Scale48 needs backward computation.
I0930 11:17:10.118813  3537 net.cpp:198] BatchNorm48 needs backward computation.
I0930 11:17:10.118814  3537 net.cpp:198] Convolution48 needs backward computation.
I0930 11:17:10.118816  3537 net.cpp:198] Eltwise22_elu_conv45_0_split needs backward computation.
I0930 11:17:10.118819  3537 net.cpp:198] elu_conv45 needs backward computation.
I0930 11:17:10.118821  3537 net.cpp:198] Eltwise22 needs backward computation.
I0930 11:17:10.118824  3537 net.cpp:198] Scale47 needs backward computation.
I0930 11:17:10.118826  3537 net.cpp:198] BatchNorm47 needs backward computation.
I0930 11:17:10.118829  3537 net.cpp:198] Convolution47 needs backward computation.
I0930 11:17:10.118831  3537 net.cpp:198] elu_conv44 needs backward computation.
I0930 11:17:10.118836  3537 net.cpp:198] Scale46 needs backward computation.
I0930 11:17:10.118839  3537 net.cpp:198] BatchNorm46 needs backward computation.
I0930 11:17:10.118840  3537 net.cpp:198] Convolution46 needs backward computation.
I0930 11:17:10.118844  3537 net.cpp:198] Eltwise21_elu_conv43_0_split needs backward computation.
I0930 11:17:10.118845  3537 net.cpp:198] elu_conv43 needs backward computation.
I0930 11:17:10.118849  3537 net.cpp:198] Eltwise21 needs backward computation.
I0930 11:17:10.118851  3537 net.cpp:198] Scale45 needs backward computation.
I0930 11:17:10.118854  3537 net.cpp:198] BatchNorm45 needs backward computation.
I0930 11:17:10.118855  3537 net.cpp:198] Convolution45 needs backward computation.
I0930 11:17:10.118857  3537 net.cpp:198] elu_conv42 needs backward computation.
I0930 11:17:10.118860  3537 net.cpp:198] Scale44 needs backward computation.
I0930 11:17:10.118862  3537 net.cpp:198] BatchNorm44 needs backward computation.
I0930 11:17:10.118865  3537 net.cpp:198] Convolution44 needs backward computation.
I0930 11:17:10.118867  3537 net.cpp:198] Eltwise20_elu_conv41_0_split needs backward computation.
I0930 11:17:10.118870  3537 net.cpp:198] elu_conv41 needs backward computation.
I0930 11:17:10.118871  3537 net.cpp:198] Eltwise20 needs backward computation.
I0930 11:17:10.118875  3537 net.cpp:198] Scale43 needs backward computation.
I0930 11:17:10.118877  3537 net.cpp:198] BatchNorm43 needs backward computation.
I0930 11:17:10.118880  3537 net.cpp:198] Convolution43 needs backward computation.
I0930 11:17:10.118881  3537 net.cpp:198] elu_conv40 needs backward computation.
I0930 11:17:10.118883  3537 net.cpp:198] Scale42 needs backward computation.
I0930 11:17:10.118886  3537 net.cpp:198] BatchNorm42 needs backward computation.
I0930 11:17:10.118888  3537 net.cpp:198] Convolution42 needs backward computation.
I0930 11:17:10.118891  3537 net.cpp:198] Eltwise19_elu_conv39_0_split needs backward computation.
I0930 11:17:10.118893  3537 net.cpp:198] elu_conv39 needs backward computation.
I0930 11:17:10.118896  3537 net.cpp:198] Eltwise19 needs backward computation.
I0930 11:17:10.118898  3537 net.cpp:198] Scale41 needs backward computation.
I0930 11:17:10.118901  3537 net.cpp:198] BatchNorm41 needs backward computation.
I0930 11:17:10.118903  3537 net.cpp:198] Convolution41 needs backward computation.
I0930 11:17:10.118906  3537 net.cpp:198] elu_conv38 needs backward computation.
I0930 11:17:10.118908  3537 net.cpp:198] Scale40 needs backward computation.
I0930 11:17:10.118911  3537 net.cpp:198] BatchNorm40 needs backward computation.
I0930 11:17:10.118912  3537 net.cpp:198] Convolution40 needs backward computation.
I0930 11:17:10.118916  3537 net.cpp:198] Scale39 needs backward computation.
I0930 11:17:10.118918  3537 net.cpp:198] BatchNorm39 needs backward computation.
I0930 11:17:10.118921  3537 net.cpp:198] Convolution39 needs backward computation.
I0930 11:17:10.118923  3537 net.cpp:198] Eltwise18_elu_conv37_0_split needs backward computation.
I0930 11:17:10.118927  3537 net.cpp:198] elu_conv37 needs backward computation.
I0930 11:17:10.118929  3537 net.cpp:198] Eltwise18 needs backward computation.
I0930 11:17:10.118932  3537 net.cpp:198] Scale38 needs backward computation.
I0930 11:17:10.118934  3537 net.cpp:198] BatchNorm38 needs backward computation.
I0930 11:17:10.118937  3537 net.cpp:198] Convolution38 needs backward computation.
I0930 11:17:10.118939  3537 net.cpp:198] elu_conv36 needs backward computation.
I0930 11:17:10.118942  3537 net.cpp:198] Scale37 needs backward computation.
I0930 11:17:10.118943  3537 net.cpp:198] BatchNorm37 needs backward computation.
I0930 11:17:10.118947  3537 net.cpp:198] Convolution37 needs backward computation.
I0930 11:17:10.118948  3537 net.cpp:198] Eltwise17_elu_conv35_0_split needs backward computation.
I0930 11:17:10.118952  3537 net.cpp:198] elu_conv35 needs backward computation.
I0930 11:17:10.118953  3537 net.cpp:198] Eltwise17 needs backward computation.
I0930 11:17:10.118957  3537 net.cpp:198] Scale36 needs backward computation.
I0930 11:17:10.118962  3537 net.cpp:198] BatchNorm36 needs backward computation.
I0930 11:17:10.118964  3537 net.cpp:198] Convolution36 needs backward computation.
I0930 11:17:10.118966  3537 net.cpp:198] elu_conv34 needs backward computation.
I0930 11:17:10.118969  3537 net.cpp:198] Scale35 needs backward computation.
I0930 11:17:10.118971  3537 net.cpp:198] BatchNorm35 needs backward computation.
I0930 11:17:10.118973  3537 net.cpp:198] Convolution35 needs backward computation.
I0930 11:17:10.118976  3537 net.cpp:198] Eltwise16_elu_conv33_0_split needs backward computation.
I0930 11:17:10.118978  3537 net.cpp:198] elu_conv33 needs backward computation.
I0930 11:17:10.118981  3537 net.cpp:198] Eltwise16 needs backward computation.
I0930 11:17:10.118983  3537 net.cpp:198] Scale34 needs backward computation.
I0930 11:17:10.118986  3537 net.cpp:198] BatchNorm34 needs backward computation.
I0930 11:17:10.118988  3537 net.cpp:198] Convolution34 needs backward computation.
I0930 11:17:10.143985  3537 net.cpp:198] elu_conv32 needs backward computation.
I0930 11:17:10.143990  3537 net.cpp:198] Scale33 needs backward computation.
I0930 11:17:10.143996  3537 net.cpp:198] BatchNorm33 needs backward computation.
I0930 11:17:10.143998  3537 net.cpp:198] Convolution33 needs backward computation.
I0930 11:17:10.144003  3537 net.cpp:198] Eltwise15_elu_conv31_0_split needs backward computation.
I0930 11:17:10.144007  3537 net.cpp:198] elu_conv31 needs backward computation.
I0930 11:17:10.144011  3537 net.cpp:198] Eltwise15 needs backward computation.
I0930 11:17:10.144016  3537 net.cpp:198] Scale32 needs backward computation.
I0930 11:17:10.144019  3537 net.cpp:198] BatchNorm32 needs backward computation.
I0930 11:17:10.144023  3537 net.cpp:198] Convolution32 needs backward computation.
I0930 11:17:10.144028  3537 net.cpp:198] elu_conv30 needs backward computation.
I0930 11:17:10.144032  3537 net.cpp:198] Scale31 needs backward computation.
I0930 11:17:10.144037  3537 net.cpp:198] BatchNorm31 needs backward computation.
I0930 11:17:10.144040  3537 net.cpp:198] Convolution31 needs backward computation.
I0930 11:17:10.144043  3537 net.cpp:198] Eltwise14_elu_conv29_0_split needs backward computation.
I0930 11:17:10.144047  3537 net.cpp:198] elu_conv29 needs backward computation.
I0930 11:17:10.144049  3537 net.cpp:198] Eltwise14 needs backward computation.
I0930 11:17:10.144052  3537 net.cpp:198] Scale30 needs backward computation.
I0930 11:17:10.144054  3537 net.cpp:198] BatchNorm30 needs backward computation.
I0930 11:17:10.144057  3537 net.cpp:198] Convolution30 needs backward computation.
I0930 11:17:10.144059  3537 net.cpp:198] elu_conv28 needs backward computation.
I0930 11:17:10.144062  3537 net.cpp:198] Scale29 needs backward computation.
I0930 11:17:10.144064  3537 net.cpp:198] BatchNorm29 needs backward computation.
I0930 11:17:10.144067  3537 net.cpp:198] Convolution29 needs backward computation.
I0930 11:17:10.144069  3537 net.cpp:198] Eltwise13_elu_conv27_0_split needs backward computation.
I0930 11:17:10.144073  3537 net.cpp:198] elu_conv27 needs backward computation.
I0930 11:17:10.144074  3537 net.cpp:198] Eltwise13 needs backward computation.
I0930 11:17:10.144078  3537 net.cpp:198] Scale28 needs backward computation.
I0930 11:17:10.144080  3537 net.cpp:198] BatchNorm28 needs backward computation.
I0930 11:17:10.144083  3537 net.cpp:198] Convolution28 needs backward computation.
I0930 11:17:10.144085  3537 net.cpp:198] elu_conv26 needs backward computation.
I0930 11:17:10.144088  3537 net.cpp:198] Scale27 needs backward computation.
I0930 11:17:10.144090  3537 net.cpp:198] BatchNorm27 needs backward computation.
I0930 11:17:10.144093  3537 net.cpp:198] Convolution27 needs backward computation.
I0930 11:17:10.144095  3537 net.cpp:198] Eltwise12_elu_conv25_0_split needs backward computation.
I0930 11:17:10.144098  3537 net.cpp:198] elu_conv25 needs backward computation.
I0930 11:17:10.144100  3537 net.cpp:198] Eltwise12 needs backward computation.
I0930 11:17:10.144104  3537 net.cpp:198] Scale26 needs backward computation.
I0930 11:17:10.144111  3537 net.cpp:198] BatchNorm26 needs backward computation.
I0930 11:17:10.144114  3537 net.cpp:198] Convolution26 needs backward computation.
I0930 11:17:10.144116  3537 net.cpp:198] elu_conv24 needs backward computation.
I0930 11:17:10.144119  3537 net.cpp:198] Scale25 needs backward computation.
I0930 11:17:10.144121  3537 net.cpp:198] BatchNorm25 needs backward computation.
I0930 11:17:10.144124  3537 net.cpp:198] Convolution25 needs backward computation.
I0930 11:17:10.144127  3537 net.cpp:198] Eltwise11_elu_conv23_0_split needs backward computation.
I0930 11:17:10.144131  3537 net.cpp:198] elu_conv23 needs backward computation.
I0930 11:17:10.144134  3537 net.cpp:198] Eltwise11 needs backward computation.
I0930 11:17:10.144136  3537 net.cpp:198] Scale24 needs backward computation.
I0930 11:17:10.144140  3537 net.cpp:198] BatchNorm24 needs backward computation.
I0930 11:17:10.144141  3537 net.cpp:198] Convolution24 needs backward computation.
I0930 11:17:10.144145  3537 net.cpp:198] elu_conv22 needs backward computation.
I0930 11:17:10.144147  3537 net.cpp:198] Scale23 needs backward computation.
I0930 11:17:10.144150  3537 net.cpp:198] BatchNorm23 needs backward computation.
I0930 11:17:10.144152  3537 net.cpp:198] Convolution23 needs backward computation.
I0930 11:17:10.144155  3537 net.cpp:198] Eltwise10_elu_conv21_0_split needs backward computation.
I0930 11:17:10.144157  3537 net.cpp:198] elu_conv21 needs backward computation.
I0930 11:17:10.144160  3537 net.cpp:198] Eltwise10 needs backward computation.
I0930 11:17:10.144163  3537 net.cpp:198] Scale22 needs backward computation.
I0930 11:17:10.144165  3537 net.cpp:198] BatchNorm22 needs backward computation.
I0930 11:17:10.144168  3537 net.cpp:198] Convolution22 needs backward computation.
I0930 11:17:10.144170  3537 net.cpp:198] elu_conv20 needs backward computation.
I0930 11:17:10.144173  3537 net.cpp:198] Scale21 needs backward computation.
I0930 11:17:10.144176  3537 net.cpp:198] BatchNorm21 needs backward computation.
I0930 11:17:10.144178  3537 net.cpp:198] Convolution21 needs backward computation.
I0930 11:17:10.144181  3537 net.cpp:198] Scale20 needs backward computation.
I0930 11:17:10.144183  3537 net.cpp:198] BatchNorm20 needs backward computation.
I0930 11:17:10.144186  3537 net.cpp:198] Convolution20 needs backward computation.
I0930 11:17:10.144188  3537 net.cpp:198] Eltwise9_elu_conv19_0_split needs backward computation.
I0930 11:17:10.144191  3537 net.cpp:198] elu_conv19 needs backward computation.
I0930 11:17:10.144193  3537 net.cpp:198] Eltwise9 needs backward computation.
I0930 11:17:10.144197  3537 net.cpp:198] Scale19 needs backward computation.
I0930 11:17:10.144199  3537 net.cpp:198] BatchNorm19 needs backward computation.
I0930 11:17:10.144202  3537 net.cpp:198] Convolution19 needs backward computation.
I0930 11:17:10.144204  3537 net.cpp:198] elu_conv18 needs backward computation.
I0930 11:17:10.144207  3537 net.cpp:198] Scale18 needs backward computation.
I0930 11:17:10.144209  3537 net.cpp:198] BatchNorm18 needs backward computation.
I0930 11:17:10.144212  3537 net.cpp:198] Convolution18 needs backward computation.
I0930 11:17:10.144215  3537 net.cpp:198] Eltwise8_elu_conv17_0_split needs backward computation.
I0930 11:17:10.144218  3537 net.cpp:198] elu_conv17 needs backward computation.
I0930 11:17:10.144220  3537 net.cpp:198] Eltwise8 needs backward computation.
I0930 11:17:10.144223  3537 net.cpp:198] Scale17 needs backward computation.
I0930 11:17:10.144227  3537 net.cpp:198] BatchNorm17 needs backward computation.
I0930 11:17:10.144228  3537 net.cpp:198] Convolution17 needs backward computation.
I0930 11:17:10.144232  3537 net.cpp:198] elu_conv16 needs backward computation.
I0930 11:17:10.144233  3537 net.cpp:198] Scale16 needs backward computation.
I0930 11:17:10.144237  3537 net.cpp:198] BatchNorm16 needs backward computation.
I0930 11:17:10.144238  3537 net.cpp:198] Convolution16 needs backward computation.
I0930 11:17:10.144242  3537 net.cpp:198] Eltwise7_elu_conv15_0_split needs backward computation.
I0930 11:17:10.144246  3537 net.cpp:198] elu_conv15 needs backward computation.
I0930 11:17:10.144249  3537 net.cpp:198] Eltwise7 needs backward computation.
I0930 11:17:10.144253  3537 net.cpp:198] Scale15 needs backward computation.
I0930 11:17:10.144255  3537 net.cpp:198] BatchNorm15 needs backward computation.
I0930 11:17:10.144258  3537 net.cpp:198] Convolution15 needs backward computation.
I0930 11:17:10.144260  3537 net.cpp:198] elu_conv14 needs backward computation.
I0930 11:17:10.144263  3537 net.cpp:198] Scale14 needs backward computation.
I0930 11:17:10.144265  3537 net.cpp:198] BatchNorm14 needs backward computation.
I0930 11:17:10.144268  3537 net.cpp:198] Convolution14 needs backward computation.
I0930 11:17:10.144270  3537 net.cpp:198] Eltwise6_elu_conv13_0_split needs backward computation.
I0930 11:17:10.144273  3537 net.cpp:198] elu_conv13 needs backward computation.
I0930 11:17:10.144275  3537 net.cpp:198] Eltwise6 needs backward computation.
I0930 11:17:10.146466  3537 net.cpp:198] Scale13 needs backward computation.
I0930 11:17:10.146472  3537 net.cpp:198] BatchNorm13 needs backward computation.
I0930 11:17:10.146476  3537 net.cpp:198] Convolution13 needs backward computation.
I0930 11:17:10.146479  3537 net.cpp:198] elu_conv12 needs backward computation.
I0930 11:17:10.146483  3537 net.cpp:198] Scale12 needs backward computation.
I0930 11:17:10.146487  3537 net.cpp:198] BatchNorm12 needs backward computation.
I0930 11:17:10.146492  3537 net.cpp:198] Convolution12 needs backward computation.
I0930 11:17:10.146497  3537 net.cpp:198] Eltwise5_elu_conv11_0_split needs backward computation.
I0930 11:17:10.146500  3537 net.cpp:198] elu_conv11 needs backward computation.
I0930 11:17:10.146504  3537 net.cpp:198] Eltwise5 needs backward computation.
I0930 11:17:10.146508  3537 net.cpp:198] Scale11 needs backward computation.
I0930 11:17:10.146512  3537 net.cpp:198] BatchNorm11 needs backward computation.
I0930 11:17:10.146513  3537 net.cpp:198] Convolution11 needs backward computation.
I0930 11:17:10.146517  3537 net.cpp:198] elu_conv10 needs backward computation.
I0930 11:17:10.146519  3537 net.cpp:198] Scale10 needs backward computation.
I0930 11:17:10.146531  3537 net.cpp:198] BatchNorm10 needs backward computation.
I0930 11:17:10.146534  3537 net.cpp:198] Convolution10 needs backward computation.
I0930 11:17:10.146538  3537 net.cpp:198] Eltwise4_elu_conv9_0_split needs backward computation.
I0930 11:17:10.146540  3537 net.cpp:198] elu_conv9 needs backward computation.
I0930 11:17:10.146543  3537 net.cpp:198] Eltwise4 needs backward computation.
I0930 11:17:10.146546  3537 net.cpp:198] Scale9 needs backward computation.
I0930 11:17:10.146549  3537 net.cpp:198] BatchNorm9 needs backward computation.
I0930 11:17:10.146551  3537 net.cpp:198] Convolution9 needs backward computation.
I0930 11:17:10.146554  3537 net.cpp:198] elu_conv8 needs backward computation.
I0930 11:17:10.146558  3537 net.cpp:198] Scale8 needs backward computation.
I0930 11:17:10.146559  3537 net.cpp:198] BatchNorm8 needs backward computation.
I0930 11:17:10.146562  3537 net.cpp:198] Convolution8 needs backward computation.
I0930 11:17:10.146565  3537 net.cpp:198] Eltwise3_elu_conv7_0_split needs backward computation.
I0930 11:17:10.146569  3537 net.cpp:198] elu_conv7 needs backward computation.
I0930 11:17:10.146570  3537 net.cpp:198] Eltwise3 needs backward computation.
I0930 11:17:10.146574  3537 net.cpp:198] Scale7 needs backward computation.
I0930 11:17:10.146576  3537 net.cpp:198] BatchNorm7 needs backward computation.
I0930 11:17:10.146579  3537 net.cpp:198] Convolution7 needs backward computation.
I0930 11:17:10.146582  3537 net.cpp:198] elu_conv6 needs backward computation.
I0930 11:17:10.146584  3537 net.cpp:198] Scale6 needs backward computation.
I0930 11:17:10.146587  3537 net.cpp:198] BatchNorm6 needs backward computation.
I0930 11:17:10.146589  3537 net.cpp:198] Convolution6 needs backward computation.
I0930 11:17:10.146592  3537 net.cpp:198] Eltwise2_elu_conv5_0_split needs backward computation.
I0930 11:17:10.146602  3537 net.cpp:198] elu_conv5 needs backward computation.
I0930 11:17:10.146605  3537 net.cpp:198] Eltwise2 needs backward computation.
I0930 11:17:10.146608  3537 net.cpp:198] Scale5 needs backward computation.
I0930 11:17:10.146611  3537 net.cpp:198] BatchNorm5 needs backward computation.
I0930 11:17:10.146613  3537 net.cpp:198] Convolution5 needs backward computation.
I0930 11:17:10.146616  3537 net.cpp:198] elu_conv4 needs backward computation.
I0930 11:17:10.146618  3537 net.cpp:198] Scale4 needs backward computation.
I0930 11:17:10.146621  3537 net.cpp:198] BatchNorm4 needs backward computation.
I0930 11:17:10.146623  3537 net.cpp:198] Convolution4 needs backward computation.
I0930 11:17:10.146626  3537 net.cpp:198] Eltwise1_elu_conv3_0_split needs backward computation.
I0930 11:17:10.146631  3537 net.cpp:198] elu_conv3 needs backward computation.
I0930 11:17:10.146633  3537 net.cpp:198] Eltwise1 needs backward computation.
I0930 11:17:10.146636  3537 net.cpp:198] Scale3 needs backward computation.
I0930 11:17:10.146639  3537 net.cpp:198] BatchNorm3 needs backward computation.
I0930 11:17:10.146641  3537 net.cpp:198] Convolution3 needs backward computation.
I0930 11:17:10.146644  3537 net.cpp:198] elu_conv2 needs backward computation.
I0930 11:17:10.146647  3537 net.cpp:198] Scale2 needs backward computation.
I0930 11:17:10.146649  3537 net.cpp:198] BatchNorm2 needs backward computation.
I0930 11:17:10.146651  3537 net.cpp:198] Convolution2 needs backward computation.
I0930 11:17:10.146654  3537 net.cpp:198] Convolution1_elu_conv1_0_split needs backward computation.
I0930 11:17:10.146657  3537 net.cpp:198] elu_conv1 needs backward computation.
I0930 11:17:10.146661  3537 net.cpp:198] Scale1 needs backward computation.
I0930 11:17:10.146662  3537 net.cpp:198] BatchNorm1 needs backward computation.
I0930 11:17:10.146664  3537 net.cpp:198] Convolution1 needs backward computation.
I0930 11:17:10.146667  3537 net.cpp:200] Data1 does not need backward computation.
I0930 11:17:10.146670  3537 net.cpp:242] This network produces output SoftmaxWithLoss1
I0930 11:17:10.146771  3537 net.cpp:255] Network initialization done.
I0930 11:17:10.150430  3537 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_elu_train_test.prototxt
I0930 11:17:10.150444  3537 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0930 11:17:10.150447  3537 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_elu_train_test.prototxt
I0930 11:17:10.150629  3537 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I0930 11:17:10.151702  3537 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv1"
  type: "ELU"
  bottom: "Convolution1"
  top: "Convolution1"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv2"
  type: "ELU"
  bottom: "Convolution2"
  top: "Convolution2"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu_conv3"
  type: "ELU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv4"
  type: "ELU"
  bottom: "Convolution4"
  top: "Convolution4"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu_conv5"
  type: "ELU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv6"
  type: "ELU"
  bottom: "Convolution6"
  top: "Convolution6"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu_conv7"
  type: "ELU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv8"
  type: "ELU"
  bottom: "Convolution8"
  top: "Convolution8"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu_conv9"
  type: "ELU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv10"
  type: "ELU"
  bottom: "Convolution10"
  top: "Convolution10"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu_conv11"
  type: "ELU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv12"
  type: "ELU"
  bottom: "Convolution12"
  top: "Convolution12"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu_conv13"
  type: "ELU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv14"
  type: "ELU"
  bottom: "Convolution14"
  top: "Convolution14"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu_conv15"
  type: "ELU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv16"
  type: "ELU"
  bottom: "Convolution16"
  top: "Convolution16"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu_conv17"
  type: "ELU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv18"
  type: "ELU"
  bottom: "Convolution18"
  top: "Convolution18"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu_conv19"
  type: "ELU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv20"
  type: "ELU"
  bottom: "Convolution21"
  top: "Convolution21"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu_conv21"
  type: "ELU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv22"
  type: "ELU"
  bottom: "Convolution23"
  top: "Convolution23"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution24"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu_conv23"
  type: "ELU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv24"
  type: "ELU"
  bottom: "Convolution25"
  top: "Convolution25"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution26"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu_conv25"
  type: "ELU"
  bottom: "Eltwise12"
  top: "Eltwise12"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution27"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv26"
  type: "ELU"
  bottom: "Convolution27"
  top: "Convolution27"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Convolution27"
  top: "Convolution28"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution28"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu_conv27"
  type: "ELU"
  bottom: "Eltwise13"
  top: "Eltwise13"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution29"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu_conv28"
  type: "ELU"
  bottom: "Convolution29"
  top: "Convolution29"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Convolution29"
  top: "Convolution30"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution30"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu_conv29"
  type: "ELU"
  bottom: "Eltwise14"
  top: "Eltwise14"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Eltwise14"
  top: "Convolution31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0
I0930 11:17:10.208415  3537 layer_factory.hpp:77] Creating layer Data1
I0930 11:17:10.208473  3537 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I0930 11:17:10.208485  3537 net.cpp:84] Creating Layer Data1
I0930 11:17:10.208490  3537 net.cpp:380] Data1 -> Data1
I0930 11:17:10.208499  3537 net.cpp:380] Data1 -> Data2
I0930 11:17:10.208505  3537 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0930 11:17:10.208700  3537 data_layer.cpp:45] output data size: 100,3,32,32
I0930 11:17:10.212862  3537 net.cpp:122] Setting up Data1
I0930 11:17:10.212883  3537 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0930 11:17:10.212888  3537 net.cpp:129] Top shape: 100 (100)
I0930 11:17:10.212890  3537 net.cpp:137] Memory required for data: 1229200
I0930 11:17:10.212896  3537 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0930 11:17:10.212906  3537 net.cpp:84] Creating Layer Data2_Data1_1_split
I0930 11:17:10.212909  3537 net.cpp:406] Data2_Data1_1_split <- Data2
I0930 11:17:10.212914  3537 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0930 11:17:10.212923  3537 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0930 11:17:10.213002  3537 net.cpp:122] Setting up Data2_Data1_1_split
I0930 11:17:10.213013  3537 net.cpp:129] Top shape: 100 (100)
I0930 11:17:10.213017  3537 net.cpp:129] Top shape: 100 (100)
I0930 11:17:10.213019  3537 net.cpp:137] Memory required for data: 1230000
I0930 11:17:10.213022  3537 layer_factory.hpp:77] Creating layer Convolution1
I0930 11:17:10.213033  3537 net.cpp:84] Creating Layer Convolution1
I0930 11:17:10.213037  3537 net.cpp:406] Convolution1 <- Data1
I0930 11:17:10.213042  3537 net.cpp:380] Convolution1 -> Convolution1
I0930 11:17:10.214248  3537 net.cpp:122] Setting up Convolution1
I0930 11:17:10.214257  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.214260  3537 net.cpp:137] Memory required for data: 7783600
I0930 11:17:10.214268  3537 layer_factory.hpp:77] Creating layer BatchNorm1
I0930 11:17:10.214274  3537 net.cpp:84] Creating Layer BatchNorm1
I0930 11:17:10.214277  3537 net.cpp:406] BatchNorm1 <- Convolution1
I0930 11:17:10.214282  3537 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0930 11:17:10.214440  3537 net.cpp:122] Setting up BatchNorm1
I0930 11:17:10.214445  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.214447  3537 net.cpp:137] Memory required for data: 14337200
I0930 11:17:10.214455  3537 layer_factory.hpp:77] Creating layer Scale1
I0930 11:17:10.214460  3537 net.cpp:84] Creating Layer Scale1
I0930 11:17:10.214463  3537 net.cpp:406] Scale1 <- Convolution1
I0930 11:17:10.214468  3537 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0930 11:17:10.214503  3537 layer_factory.hpp:77] Creating layer Scale1
I0930 11:17:10.214603  3537 net.cpp:122] Setting up Scale1
I0930 11:17:10.214609  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.214612  3537 net.cpp:137] Memory required for data: 20890800
I0930 11:17:10.214617  3537 layer_factory.hpp:77] Creating layer elu_conv1
I0930 11:17:10.214622  3537 net.cpp:84] Creating Layer elu_conv1
I0930 11:17:10.214625  3537 net.cpp:406] elu_conv1 <- Convolution1
I0930 11:17:10.214629  3537 net.cpp:367] elu_conv1 -> Convolution1 (in-place)
I0930 11:17:10.214634  3537 net.cpp:122] Setting up elu_conv1
I0930 11:17:10.214637  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.214639  3537 net.cpp:137] Memory required for data: 27444400
I0930 11:17:10.214643  3537 layer_factory.hpp:77] Creating layer Convolution1_elu_conv1_0_split
I0930 11:17:10.214646  3537 net.cpp:84] Creating Layer Convolution1_elu_conv1_0_split
I0930 11:17:10.214648  3537 net.cpp:406] Convolution1_elu_conv1_0_split <- Convolution1
I0930 11:17:10.214653  3537 net.cpp:380] Convolution1_elu_conv1_0_split -> Convolution1_elu_conv1_0_split_0
I0930 11:17:10.214656  3537 net.cpp:380] Convolution1_elu_conv1_0_split -> Convolution1_elu_conv1_0_split_1
I0930 11:17:10.214685  3537 net.cpp:122] Setting up Convolution1_elu_conv1_0_split
I0930 11:17:10.235833  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.235846  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.235849  3537 net.cpp:137] Memory required for data: 40551600
I0930 11:17:10.235853  3537 layer_factory.hpp:77] Creating layer Convolution2
I0930 11:17:10.235863  3537 net.cpp:84] Creating Layer Convolution2
I0930 11:17:10.235867  3537 net.cpp:406] Convolution2 <- Convolution1_elu_conv1_0_split_0
I0930 11:17:10.235875  3537 net.cpp:380] Convolution2 -> Convolution2
I0930 11:17:10.237089  3537 net.cpp:122] Setting up Convolution2
I0930 11:17:10.237098  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.237102  3537 net.cpp:137] Memory required for data: 47105200
I0930 11:17:10.237110  3537 layer_factory.hpp:77] Creating layer BatchNorm2
I0930 11:17:10.237118  3537 net.cpp:84] Creating Layer BatchNorm2
I0930 11:17:10.237120  3537 net.cpp:406] BatchNorm2 <- Convolution2
I0930 11:17:10.237124  3537 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0930 11:17:10.237288  3537 net.cpp:122] Setting up BatchNorm2
I0930 11:17:10.237293  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.237295  3537 net.cpp:137] Memory required for data: 53658800
I0930 11:17:10.237301  3537 layer_factory.hpp:77] Creating layer Scale2
I0930 11:17:10.237316  3537 net.cpp:84] Creating Layer Scale2
I0930 11:17:10.237319  3537 net.cpp:406] Scale2 <- Convolution2
I0930 11:17:10.237323  3537 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0930 11:17:10.237367  3537 layer_factory.hpp:77] Creating layer Scale2
I0930 11:17:10.237457  3537 net.cpp:122] Setting up Scale2
I0930 11:17:10.237462  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.237463  3537 net.cpp:137] Memory required for data: 60212400
I0930 11:17:10.237468  3537 layer_factory.hpp:77] Creating layer elu_conv2
I0930 11:17:10.237473  3537 net.cpp:84] Creating Layer elu_conv2
I0930 11:17:10.237474  3537 net.cpp:406] elu_conv2 <- Convolution2
I0930 11:17:10.237478  3537 net.cpp:367] elu_conv2 -> Convolution2 (in-place)
I0930 11:17:10.237483  3537 net.cpp:122] Setting up elu_conv2
I0930 11:17:10.237486  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.237488  3537 net.cpp:137] Memory required for data: 66766000
I0930 11:17:10.237491  3537 layer_factory.hpp:77] Creating layer Convolution3
I0930 11:17:10.237498  3537 net.cpp:84] Creating Layer Convolution3
I0930 11:17:10.237501  3537 net.cpp:406] Convolution3 <- Convolution2
I0930 11:17:10.237505  3537 net.cpp:380] Convolution3 -> Convolution3
I0930 11:17:10.238963  3537 net.cpp:122] Setting up Convolution3
I0930 11:17:10.238972  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.238976  3537 net.cpp:137] Memory required for data: 73319600
I0930 11:17:10.238981  3537 layer_factory.hpp:77] Creating layer BatchNorm3
I0930 11:17:10.238987  3537 net.cpp:84] Creating Layer BatchNorm3
I0930 11:17:10.238989  3537 net.cpp:406] BatchNorm3 <- Convolution3
I0930 11:17:10.238993  3537 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0930 11:17:10.239146  3537 net.cpp:122] Setting up BatchNorm3
I0930 11:17:10.239151  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.239153  3537 net.cpp:137] Memory required for data: 79873200
I0930 11:17:10.239161  3537 layer_factory.hpp:77] Creating layer Scale3
I0930 11:17:10.239166  3537 net.cpp:84] Creating Layer Scale3
I0930 11:17:10.239169  3537 net.cpp:406] Scale3 <- Convolution3
I0930 11:17:10.239172  3537 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0930 11:17:10.239203  3537 layer_factory.hpp:77] Creating layer Scale3
I0930 11:17:10.239287  3537 net.cpp:122] Setting up Scale3
I0930 11:17:10.239292  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.239295  3537 net.cpp:137] Memory required for data: 86426800
I0930 11:17:10.239298  3537 layer_factory.hpp:77] Creating layer Eltwise1
I0930 11:17:10.239303  3537 net.cpp:84] Creating Layer Eltwise1
I0930 11:17:10.239306  3537 net.cpp:406] Eltwise1 <- Convolution1_elu_conv1_0_split_1
I0930 11:17:10.239317  3537 net.cpp:406] Eltwise1 <- Convolution3
I0930 11:17:10.239322  3537 net.cpp:380] Eltwise1 -> Eltwise1
I0930 11:17:10.239351  3537 net.cpp:122] Setting up Eltwise1
I0930 11:17:10.239356  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.239358  3537 net.cpp:137] Memory required for data: 92980400
I0930 11:17:10.239361  3537 layer_factory.hpp:77] Creating layer elu_conv3
I0930 11:17:10.239364  3537 net.cpp:84] Creating Layer elu_conv3
I0930 11:17:10.239367  3537 net.cpp:406] elu_conv3 <- Eltwise1
I0930 11:17:10.239370  3537 net.cpp:367] elu_conv3 -> Eltwise1 (in-place)
I0930 11:17:10.239374  3537 net.cpp:122] Setting up elu_conv3
I0930 11:17:10.239377  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.239379  3537 net.cpp:137] Memory required for data: 99534000
I0930 11:17:10.239382  3537 layer_factory.hpp:77] Creating layer Eltwise1_elu_conv3_0_split
I0930 11:17:10.239387  3537 net.cpp:84] Creating Layer Eltwise1_elu_conv3_0_split
I0930 11:17:10.239389  3537 net.cpp:406] Eltwise1_elu_conv3_0_split <- Eltwise1
I0930 11:17:10.239392  3537 net.cpp:380] Eltwise1_elu_conv3_0_split -> Eltwise1_elu_conv3_0_split_0
I0930 11:17:10.239397  3537 net.cpp:380] Eltwise1_elu_conv3_0_split -> Eltwise1_elu_conv3_0_split_1
I0930 11:17:10.239423  3537 net.cpp:122] Setting up Eltwise1_elu_conv3_0_split
I0930 11:17:10.239428  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.239430  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.239433  3537 net.cpp:137] Memory required for data: 112641200
I0930 11:17:10.239434  3537 layer_factory.hpp:77] Creating layer Convolution4
I0930 11:17:10.239441  3537 net.cpp:84] Creating Layer Convolution4
I0930 11:17:10.239444  3537 net.cpp:406] Convolution4 <- Eltwise1_elu_conv3_0_split_0
I0930 11:17:10.239449  3537 net.cpp:380] Convolution4 -> Convolution4
I0930 11:17:10.240505  3537 net.cpp:122] Setting up Convolution4
I0930 11:17:10.240516  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.240520  3537 net.cpp:137] Memory required for data: 119194800
I0930 11:17:10.240523  3537 layer_factory.hpp:77] Creating layer BatchNorm4
I0930 11:17:10.240528  3537 net.cpp:84] Creating Layer BatchNorm4
I0930 11:17:10.240531  3537 net.cpp:406] BatchNorm4 <- Convolution4
I0930 11:17:10.240536  3537 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0930 11:17:10.240689  3537 net.cpp:122] Setting up BatchNorm4
I0930 11:17:10.240694  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.240696  3537 net.cpp:137] Memory required for data: 125748400
I0930 11:17:10.240701  3537 layer_factory.hpp:77] Creating layer Scale4
I0930 11:17:10.240705  3537 net.cpp:84] Creating Layer Scale4
I0930 11:17:10.240707  3537 net.cpp:406] Scale4 <- Convolution4
I0930 11:17:10.240711  3537 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0930 11:17:10.240741  3537 layer_factory.hpp:77] Creating layer Scale4
I0930 11:17:10.240824  3537 net.cpp:122] Setting up Scale4
I0930 11:17:10.240828  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.240830  3537 net.cpp:137] Memory required for data: 132302000
I0930 11:17:10.240834  3537 layer_factory.hpp:77] Creating layer elu_conv4
I0930 11:17:10.240839  3537 net.cpp:84] Creating Layer elu_conv4
I0930 11:17:10.240840  3537 net.cpp:406] elu_conv4 <- Convolution4
I0930 11:17:10.240844  3537 net.cpp:367] elu_conv4 -> Convolution4 (in-place)
I0930 11:17:10.240849  3537 net.cpp:122] Setting up elu_conv4
I0930 11:17:10.240851  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.240854  3537 net.cpp:137] Memory required for data: 138855600
I0930 11:17:10.240855  3537 layer_factory.hpp:77] Creating layer Convolution5
I0930 11:17:10.240862  3537 net.cpp:84] Creating Layer Convolution5
I0930 11:17:10.240865  3537 net.cpp:406] Convolution5 <- Convolution4
I0930 11:17:10.240869  3537 net.cpp:380] Convolution5 -> Convolution5
I0930 11:17:10.241827  3537 net.cpp:122] Setting up Convolution5
I0930 11:17:10.241837  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.241847  3537 net.cpp:137] Memory required for data: 145409200
I0930 11:17:10.241852  3537 layer_factory.hpp:77] Creating layer BatchNorm5
I0930 11:17:10.241858  3537 net.cpp:84] Creating Layer BatchNorm5
I0930 11:17:10.241859  3537 net.cpp:406] BatchNorm5 <- Convolution5
I0930 11:17:10.241863  3537 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0930 11:17:10.242017  3537 net.cpp:122] Setting up BatchNorm5
I0930 11:17:10.242022  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.242024  3537 net.cpp:137] Memory required for data: 151962800
I0930 11:17:10.242033  3537 layer_factory.hpp:77] Creating layer Scale5
I0930 11:17:10.242036  3537 net.cpp:84] Creating Layer Scale5
I0930 11:17:10.242038  3537 net.cpp:406] Scale5 <- Convolution5
I0930 11:17:10.242043  3537 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0930 11:17:10.242072  3537 layer_factory.hpp:77] Creating layer Scale5
I0930 11:17:10.242156  3537 net.cpp:122] Setting up Scale5
I0930 11:17:10.242161  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.242162  3537 net.cpp:137] Memory required for data: 158516400
I0930 11:17:10.242166  3537 layer_factory.hpp:77] Creating layer Eltwise2
I0930 11:17:10.242172  3537 net.cpp:84] Creating Layer Eltwise2
I0930 11:17:10.242174  3537 net.cpp:406] Eltwise2 <- Eltwise1_elu_conv3_0_split_1
I0930 11:17:10.242177  3537 net.cpp:406] Eltwise2 <- Convolution5
I0930 11:17:10.242182  3537 net.cpp:380] Eltwise2 -> Eltwise2
I0930 11:17:10.242198  3537 net.cpp:122] Setting up Eltwise2
I0930 11:17:10.242202  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.242204  3537 net.cpp:137] Memory required for data: 165070000
I0930 11:17:10.242207  3537 layer_factory.hpp:77] Creating layer elu_conv5
I0930 11:17:10.242210  3537 net.cpp:84] Creating Layer elu_conv5
I0930 11:17:10.242213  3537 net.cpp:406] elu_conv5 <- Eltwise2
I0930 11:17:10.242215  3537 net.cpp:367] elu_conv5 -> Eltwise2 (in-place)
I0930 11:17:10.242219  3537 net.cpp:122] Setting up elu_conv5
I0930 11:17:10.242223  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.242224  3537 net.cpp:137] Memory required for data: 171623600
I0930 11:17:10.242226  3537 layer_factory.hpp:77] Creating layer Eltwise2_elu_conv5_0_split
I0930 11:17:10.242230  3537 net.cpp:84] Creating Layer Eltwise2_elu_conv5_0_split
I0930 11:17:10.242233  3537 net.cpp:406] Eltwise2_elu_conv5_0_split <- Eltwise2
I0930 11:17:10.242235  3537 net.cpp:380] Eltwise2_elu_conv5_0_split -> Eltwise2_elu_conv5_0_split_0
I0930 11:17:10.242239  3537 net.cpp:380] Eltwise2_elu_conv5_0_split -> Eltwise2_elu_conv5_0_split_1
I0930 11:17:10.242265  3537 net.cpp:122] Setting up Eltwise2_elu_conv5_0_split
I0930 11:17:10.242269  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.242272  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.242274  3537 net.cpp:137] Memory required for data: 184730800
I0930 11:17:10.242277  3537 layer_factory.hpp:77] Creating layer Convolution6
I0930 11:17:10.242283  3537 net.cpp:84] Creating Layer Convolution6
I0930 11:17:10.242286  3537 net.cpp:406] Convolution6 <- Eltwise2_elu_conv5_0_split_0
I0930 11:17:10.242290  3537 net.cpp:380] Convolution6 -> Convolution6
I0930 11:17:10.243245  3537 net.cpp:122] Setting up Convolution6
I0930 11:17:10.243254  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.243257  3537 net.cpp:137] Memory required for data: 191284400
I0930 11:17:10.243261  3537 layer_factory.hpp:77] Creating layer BatchNorm6
I0930 11:17:10.243266  3537 net.cpp:84] Creating Layer BatchNorm6
I0930 11:17:10.243269  3537 net.cpp:406] BatchNorm6 <- Convolution6
I0930 11:17:10.243274  3537 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0930 11:17:10.243423  3537 net.cpp:122] Setting up BatchNorm6
I0930 11:17:10.243428  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.243430  3537 net.cpp:137] Memory required for data: 197838000
I0930 11:17:10.243435  3537 layer_factory.hpp:77] Creating layer Scale6
I0930 11:17:10.243439  3537 net.cpp:84] Creating Layer Scale6
I0930 11:17:10.243448  3537 net.cpp:406] Scale6 <- Convolution6
I0930 11:17:10.243453  3537 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0930 11:17:10.243484  3537 layer_factory.hpp:77] Creating layer Scale6
I0930 11:17:10.243568  3537 net.cpp:122] Setting up Scale6
I0930 11:17:10.243573  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.243576  3537 net.cpp:137] Memory required for data: 204391600
I0930 11:17:10.243579  3537 layer_factory.hpp:77] Creating layer elu_conv6
I0930 11:17:10.243583  3537 net.cpp:84] Creating Layer elu_conv6
I0930 11:17:10.243585  3537 net.cpp:406] elu_conv6 <- Convolution6
I0930 11:17:10.243588  3537 net.cpp:367] elu_conv6 -> Convolution6 (in-place)
I0930 11:17:10.243592  3537 net.cpp:122] Setting up elu_conv6
I0930 11:17:10.243595  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.243597  3537 net.cpp:137] Memory required for data: 210945200
I0930 11:17:10.243599  3537 layer_factory.hpp:77] Creating layer Convolution7
I0930 11:17:10.243607  3537 net.cpp:84] Creating Layer Convolution7
I0930 11:17:10.243609  3537 net.cpp:406] Convolution7 <- Convolution6
I0930 11:17:10.243613  3537 net.cpp:380] Convolution7 -> Convolution7
I0930 11:17:10.244551  3537 net.cpp:122] Setting up Convolution7
I0930 11:17:10.244560  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.244563  3537 net.cpp:137] Memory required for data: 217498800
I0930 11:17:10.244567  3537 layer_factory.hpp:77] Creating layer BatchNorm7
I0930 11:17:10.244575  3537 net.cpp:84] Creating Layer BatchNorm7
I0930 11:17:10.244577  3537 net.cpp:406] BatchNorm7 <- Convolution7
I0930 11:17:10.244581  3537 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0930 11:17:10.244735  3537 net.cpp:122] Setting up BatchNorm7
I0930 11:17:10.244738  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.244741  3537 net.cpp:137] Memory required for data: 224052400
I0930 11:17:10.244745  3537 layer_factory.hpp:77] Creating layer Scale7
I0930 11:17:10.244750  3537 net.cpp:84] Creating Layer Scale7
I0930 11:17:10.244753  3537 net.cpp:406] Scale7 <- Convolution7
I0930 11:17:10.244756  3537 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0930 11:17:10.244786  3537 layer_factory.hpp:77] Creating layer Scale7
I0930 11:17:10.244871  3537 net.cpp:122] Setting up Scale7
I0930 11:17:10.244875  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.244879  3537 net.cpp:137] Memory required for data: 230606000
I0930 11:17:10.244881  3537 layer_factory.hpp:77] Creating layer Eltwise3
I0930 11:17:10.244885  3537 net.cpp:84] Creating Layer Eltwise3
I0930 11:17:10.244889  3537 net.cpp:406] Eltwise3 <- Eltwise2_elu_conv5_0_split_1
I0930 11:17:10.244891  3537 net.cpp:406] Eltwise3 <- Convolution7
I0930 11:17:10.244895  3537 net.cpp:380] Eltwise3 -> Eltwise3
I0930 11:17:10.244912  3537 net.cpp:122] Setting up Eltwise3
I0930 11:17:10.244916  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.244918  3537 net.cpp:137] Memory required for data: 237159600
I0930 11:17:10.244920  3537 layer_factory.hpp:77] Creating layer elu_conv7
I0930 11:17:10.244925  3537 net.cpp:84] Creating Layer elu_conv7
I0930 11:17:10.244926  3537 net.cpp:406] elu_conv7 <- Eltwise3
I0930 11:17:10.244930  3537 net.cpp:367] elu_conv7 -> Eltwise3 (in-place)
I0930 11:17:10.244933  3537 net.cpp:122] Setting up elu_conv7
I0930 11:17:10.244936  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.244938  3537 net.cpp:137] Memory required for data: 243713200
I0930 11:17:10.244940  3537 layer_factory.hpp:77] Creating layer Eltwise3_elu_conv7_0_split
I0930 11:17:10.244945  3537 net.cpp:84] Creating Layer Eltwise3_elu_conv7_0_split
I0930 11:17:10.244946  3537 net.cpp:406] Eltwise3_elu_conv7_0_split <- Eltwise3
I0930 11:17:10.244951  3537 net.cpp:380] Eltwise3_elu_conv7_0_split -> Eltwise3_elu_conv7_0_split_0
I0930 11:17:10.266501  3537 net.cpp:380] Eltwise3_elu_conv7_0_split -> Eltwise3_elu_conv7_0_split_1
I0930 11:17:10.266566  3537 net.cpp:122] Setting up Eltwise3_elu_conv7_0_split
I0930 11:17:10.266582  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.266585  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.266588  3537 net.cpp:137] Memory required for data: 256820400
I0930 11:17:10.266590  3537 layer_factory.hpp:77] Creating layer Convolution8
I0930 11:17:10.266600  3537 net.cpp:84] Creating Layer Convolution8
I0930 11:17:10.266603  3537 net.cpp:406] Convolution8 <- Eltwise3_elu_conv7_0_split_0
I0930 11:17:10.266608  3537 net.cpp:380] Convolution8 -> Convolution8
I0930 11:17:10.267652  3537 net.cpp:122] Setting up Convolution8
I0930 11:17:10.267673  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.267675  3537 net.cpp:137] Memory required for data: 263374000
I0930 11:17:10.267680  3537 layer_factory.hpp:77] Creating layer BatchNorm8
I0930 11:17:10.267686  3537 net.cpp:84] Creating Layer BatchNorm8
I0930 11:17:10.267688  3537 net.cpp:406] BatchNorm8 <- Convolution8
I0930 11:17:10.267693  3537 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0930 11:17:10.267856  3537 net.cpp:122] Setting up BatchNorm8
I0930 11:17:10.267861  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.267863  3537 net.cpp:137] Memory required for data: 269927600
I0930 11:17:10.267868  3537 layer_factory.hpp:77] Creating layer Scale8
I0930 11:17:10.267874  3537 net.cpp:84] Creating Layer Scale8
I0930 11:17:10.267876  3537 net.cpp:406] Scale8 <- Convolution8
I0930 11:17:10.267879  3537 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0930 11:17:10.267910  3537 layer_factory.hpp:77] Creating layer Scale8
I0930 11:17:10.268008  3537 net.cpp:122] Setting up Scale8
I0930 11:17:10.268013  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.268015  3537 net.cpp:137] Memory required for data: 276481200
I0930 11:17:10.268019  3537 layer_factory.hpp:77] Creating layer elu_conv8
I0930 11:17:10.268023  3537 net.cpp:84] Creating Layer elu_conv8
I0930 11:17:10.268025  3537 net.cpp:406] elu_conv8 <- Convolution8
I0930 11:17:10.268038  3537 net.cpp:367] elu_conv8 -> Convolution8 (in-place)
I0930 11:17:10.268041  3537 net.cpp:122] Setting up elu_conv8
I0930 11:17:10.268044  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.268048  3537 net.cpp:137] Memory required for data: 283034800
I0930 11:17:10.268049  3537 layer_factory.hpp:77] Creating layer Convolution9
I0930 11:17:10.268059  3537 net.cpp:84] Creating Layer Convolution9
I0930 11:17:10.268060  3537 net.cpp:406] Convolution9 <- Convolution8
I0930 11:17:10.268064  3537 net.cpp:380] Convolution9 -> Convolution9
I0930 11:17:10.269240  3537 net.cpp:122] Setting up Convolution9
I0930 11:17:10.269249  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.269253  3537 net.cpp:137] Memory required for data: 289588400
I0930 11:17:10.269256  3537 layer_factory.hpp:77] Creating layer BatchNorm9
I0930 11:17:10.269261  3537 net.cpp:84] Creating Layer BatchNorm9
I0930 11:17:10.269264  3537 net.cpp:406] BatchNorm9 <- Convolution9
I0930 11:17:10.269269  3537 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0930 11:17:10.269460  3537 net.cpp:122] Setting up BatchNorm9
I0930 11:17:10.269464  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.269467  3537 net.cpp:137] Memory required for data: 296142000
I0930 11:17:10.269471  3537 layer_factory.hpp:77] Creating layer Scale9
I0930 11:17:10.269475  3537 net.cpp:84] Creating Layer Scale9
I0930 11:17:10.269479  3537 net.cpp:406] Scale9 <- Convolution9
I0930 11:17:10.269482  3537 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0930 11:17:10.269511  3537 layer_factory.hpp:77] Creating layer Scale9
I0930 11:17:10.269593  3537 net.cpp:122] Setting up Scale9
I0930 11:17:10.269598  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.269599  3537 net.cpp:137] Memory required for data: 302695600
I0930 11:17:10.269603  3537 layer_factory.hpp:77] Creating layer Eltwise4
I0930 11:17:10.269608  3537 net.cpp:84] Creating Layer Eltwise4
I0930 11:17:10.269610  3537 net.cpp:406] Eltwise4 <- Eltwise3_elu_conv7_0_split_1
I0930 11:17:10.269620  3537 net.cpp:406] Eltwise4 <- Convolution9
I0930 11:17:10.269624  3537 net.cpp:380] Eltwise4 -> Eltwise4
I0930 11:17:10.269644  3537 net.cpp:122] Setting up Eltwise4
I0930 11:17:10.269647  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.269649  3537 net.cpp:137] Memory required for data: 309249200
I0930 11:17:10.269652  3537 layer_factory.hpp:77] Creating layer elu_conv9
I0930 11:17:10.269656  3537 net.cpp:84] Creating Layer elu_conv9
I0930 11:17:10.269659  3537 net.cpp:406] elu_conv9 <- Eltwise4
I0930 11:17:10.269661  3537 net.cpp:367] elu_conv9 -> Eltwise4 (in-place)
I0930 11:17:10.269665  3537 net.cpp:122] Setting up elu_conv9
I0930 11:17:10.269668  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.269670  3537 net.cpp:137] Memory required for data: 315802800
I0930 11:17:10.269672  3537 layer_factory.hpp:77] Creating layer Eltwise4_elu_conv9_0_split
I0930 11:17:10.269676  3537 net.cpp:84] Creating Layer Eltwise4_elu_conv9_0_split
I0930 11:17:10.269678  3537 net.cpp:406] Eltwise4_elu_conv9_0_split <- Eltwise4
I0930 11:17:10.269682  3537 net.cpp:380] Eltwise4_elu_conv9_0_split -> Eltwise4_elu_conv9_0_split_0
I0930 11:17:10.269685  3537 net.cpp:380] Eltwise4_elu_conv9_0_split -> Eltwise4_elu_conv9_0_split_1
I0930 11:17:10.269711  3537 net.cpp:122] Setting up Eltwise4_elu_conv9_0_split
I0930 11:17:10.269713  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.269716  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.269718  3537 net.cpp:137] Memory required for data: 328910000
I0930 11:17:10.269721  3537 layer_factory.hpp:77] Creating layer Convolution10
I0930 11:17:10.269727  3537 net.cpp:84] Creating Layer Convolution10
I0930 11:17:10.269729  3537 net.cpp:406] Convolution10 <- Eltwise4_elu_conv9_0_split_0
I0930 11:17:10.269733  3537 net.cpp:380] Convolution10 -> Convolution10
I0930 11:17:10.270736  3537 net.cpp:122] Setting up Convolution10
I0930 11:17:10.270746  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.270750  3537 net.cpp:137] Memory required for data: 335463600
I0930 11:17:10.270766  3537 layer_factory.hpp:77] Creating layer BatchNorm10
I0930 11:17:10.270771  3537 net.cpp:84] Creating Layer BatchNorm10
I0930 11:17:10.270774  3537 net.cpp:406] BatchNorm10 <- Convolution10
I0930 11:17:10.270779  3537 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0930 11:17:10.270936  3537 net.cpp:122] Setting up BatchNorm10
I0930 11:17:10.270941  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.270942  3537 net.cpp:137] Memory required for data: 342017200
I0930 11:17:10.270947  3537 layer_factory.hpp:77] Creating layer Scale10
I0930 11:17:10.270952  3537 net.cpp:84] Creating Layer Scale10
I0930 11:17:10.270954  3537 net.cpp:406] Scale10 <- Convolution10
I0930 11:17:10.270957  3537 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0930 11:17:10.270989  3537 layer_factory.hpp:77] Creating layer Scale10
I0930 11:17:10.271095  3537 net.cpp:122] Setting up Scale10
I0930 11:17:10.271098  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.271100  3537 net.cpp:137] Memory required for data: 348570800
I0930 11:17:10.271104  3537 layer_factory.hpp:77] Creating layer elu_conv10
I0930 11:17:10.271109  3537 net.cpp:84] Creating Layer elu_conv10
I0930 11:17:10.271111  3537 net.cpp:406] elu_conv10 <- Convolution10
I0930 11:17:10.271114  3537 net.cpp:367] elu_conv10 -> Convolution10 (in-place)
I0930 11:17:10.271118  3537 net.cpp:122] Setting up elu_conv10
I0930 11:17:10.271121  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.271124  3537 net.cpp:137] Memory required for data: 355124400
I0930 11:17:10.271126  3537 layer_factory.hpp:77] Creating layer Convolution11
I0930 11:17:10.271133  3537 net.cpp:84] Creating Layer Convolution11
I0930 11:17:10.271136  3537 net.cpp:406] Convolution11 <- Convolution10
I0930 11:17:10.271140  3537 net.cpp:380] Convolution11 -> Convolution11
I0930 11:17:10.272420  3537 net.cpp:122] Setting up Convolution11
I0930 11:17:10.272428  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.272440  3537 net.cpp:137] Memory required for data: 361678000
I0930 11:17:10.272445  3537 layer_factory.hpp:77] Creating layer BatchNorm11
I0930 11:17:10.272450  3537 net.cpp:84] Creating Layer BatchNorm11
I0930 11:17:10.272454  3537 net.cpp:406] BatchNorm11 <- Convolution11
I0930 11:17:10.272457  3537 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0930 11:17:10.272616  3537 net.cpp:122] Setting up BatchNorm11
I0930 11:17:10.272620  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.272624  3537 net.cpp:137] Memory required for data: 368231600
I0930 11:17:10.272629  3537 layer_factory.hpp:77] Creating layer Scale11
I0930 11:17:10.272632  3537 net.cpp:84] Creating Layer Scale11
I0930 11:17:10.272635  3537 net.cpp:406] Scale11 <- Convolution11
I0930 11:17:10.272639  3537 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0930 11:17:10.272670  3537 layer_factory.hpp:77] Creating layer Scale11
I0930 11:17:10.272756  3537 net.cpp:122] Setting up Scale11
I0930 11:17:10.272760  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.272763  3537 net.cpp:137] Memory required for data: 374785200
I0930 11:17:10.272766  3537 layer_factory.hpp:77] Creating layer Eltwise5
I0930 11:17:10.272771  3537 net.cpp:84] Creating Layer Eltwise5
I0930 11:17:10.272774  3537 net.cpp:406] Eltwise5 <- Eltwise4_elu_conv9_0_split_1
I0930 11:17:10.272778  3537 net.cpp:406] Eltwise5 <- Convolution11
I0930 11:17:10.272780  3537 net.cpp:380] Eltwise5 -> Eltwise5
I0930 11:17:10.272799  3537 net.cpp:122] Setting up Eltwise5
I0930 11:17:10.272804  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.272805  3537 net.cpp:137] Memory required for data: 381338800
I0930 11:17:10.272807  3537 layer_factory.hpp:77] Creating layer elu_conv11
I0930 11:17:10.272810  3537 net.cpp:84] Creating Layer elu_conv11
I0930 11:17:10.272814  3537 net.cpp:406] elu_conv11 <- Eltwise5
I0930 11:17:10.272819  3537 net.cpp:367] elu_conv11 -> Eltwise5 (in-place)
I0930 11:17:10.272821  3537 net.cpp:122] Setting up elu_conv11
I0930 11:17:10.272825  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.272827  3537 net.cpp:137] Memory required for data: 387892400
I0930 11:17:10.272830  3537 layer_factory.hpp:77] Creating layer Eltwise5_elu_conv11_0_split
I0930 11:17:10.272832  3537 net.cpp:84] Creating Layer Eltwise5_elu_conv11_0_split
I0930 11:17:10.272835  3537 net.cpp:406] Eltwise5_elu_conv11_0_split <- Eltwise5
I0930 11:17:10.272837  3537 net.cpp:380] Eltwise5_elu_conv11_0_split -> Eltwise5_elu_conv11_0_split_0
I0930 11:17:10.272841  3537 net.cpp:380] Eltwise5_elu_conv11_0_split -> Eltwise5_elu_conv11_0_split_1
I0930 11:17:10.272867  3537 net.cpp:122] Setting up Eltwise5_elu_conv11_0_split
I0930 11:17:10.272871  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.272874  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.272876  3537 net.cpp:137] Memory required for data: 400999600
I0930 11:17:10.272879  3537 layer_factory.hpp:77] Creating layer Convolution12
I0930 11:17:10.272884  3537 net.cpp:84] Creating Layer Convolution12
I0930 11:17:10.272887  3537 net.cpp:406] Convolution12 <- Eltwise5_elu_conv11_0_split_0
I0930 11:17:10.272891  3537 net.cpp:380] Convolution12 -> Convolution12
I0930 11:17:10.273851  3537 net.cpp:122] Setting up Convolution12
I0930 11:17:10.273860  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.273864  3537 net.cpp:137] Memory required for data: 407553200
I0930 11:17:10.273869  3537 layer_factory.hpp:77] Creating layer BatchNorm12
I0930 11:17:10.273872  3537 net.cpp:84] Creating Layer BatchNorm12
I0930 11:17:10.273875  3537 net.cpp:406] BatchNorm12 <- Convolution12
I0930 11:17:10.273880  3537 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0930 11:17:10.274032  3537 net.cpp:122] Setting up BatchNorm12
I0930 11:17:10.274037  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.274039  3537 net.cpp:137] Memory required for data: 414106800
I0930 11:17:10.274044  3537 layer_factory.hpp:77] Creating layer Scale12
I0930 11:17:10.274055  3537 net.cpp:84] Creating Layer Scale12
I0930 11:17:10.274057  3537 net.cpp:406] Scale12 <- Convolution12
I0930 11:17:10.274061  3537 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0930 11:17:10.274092  3537 layer_factory.hpp:77] Creating layer Scale12
I0930 11:17:10.274179  3537 net.cpp:122] Setting up Scale12
I0930 11:17:10.274184  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.274186  3537 net.cpp:137] Memory required for data: 420660400
I0930 11:17:10.274190  3537 layer_factory.hpp:77] Creating layer elu_conv12
I0930 11:17:10.274194  3537 net.cpp:84] Creating Layer elu_conv12
I0930 11:17:10.274196  3537 net.cpp:406] elu_conv12 <- Convolution12
I0930 11:17:10.274200  3537 net.cpp:367] elu_conv12 -> Convolution12 (in-place)
I0930 11:17:10.274204  3537 net.cpp:122] Setting up elu_conv12
I0930 11:17:10.274207  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.274209  3537 net.cpp:137] Memory required for data: 427214000
I0930 11:17:10.274211  3537 layer_factory.hpp:77] Creating layer Convolution13
I0930 11:17:10.274217  3537 net.cpp:84] Creating Layer Convolution13
I0930 11:17:10.274220  3537 net.cpp:406] Convolution13 <- Convolution12
I0930 11:17:10.274224  3537 net.cpp:380] Convolution13 -> Convolution13
I0930 11:17:10.275214  3537 net.cpp:122] Setting up Convolution13
I0930 11:17:10.275223  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.275225  3537 net.cpp:137] Memory required for data: 433767600
I0930 11:17:10.275230  3537 layer_factory.hpp:77] Creating layer BatchNorm13
I0930 11:17:10.275236  3537 net.cpp:84] Creating Layer BatchNorm13
I0930 11:17:10.275238  3537 net.cpp:406] BatchNorm13 <- Convolution13
I0930 11:17:10.275243  3537 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0930 11:17:10.275399  3537 net.cpp:122] Setting up BatchNorm13
I0930 11:17:10.275404  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.275406  3537 net.cpp:137] Memory required for data: 440321200
I0930 11:17:10.275410  3537 layer_factory.hpp:77] Creating layer Scale13
I0930 11:17:10.275415  3537 net.cpp:84] Creating Layer Scale13
I0930 11:17:10.275418  3537 net.cpp:406] Scale13 <- Convolution13
I0930 11:17:10.275420  3537 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0930 11:17:10.275451  3537 layer_factory.hpp:77] Creating layer Scale13
I0930 11:17:10.275537  3537 net.cpp:122] Setting up Scale13
I0930 11:17:10.275542  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.275544  3537 net.cpp:137] Memory required for data: 446874800
I0930 11:17:10.275547  3537 layer_factory.hpp:77] Creating layer Eltwise6
I0930 11:17:10.275557  3537 net.cpp:84] Creating Layer Eltwise6
I0930 11:17:10.275559  3537 net.cpp:406] Eltwise6 <- Eltwise5_elu_conv11_0_split_1
I0930 11:17:10.275563  3537 net.cpp:406] Eltwise6 <- Convolution13
I0930 11:17:10.275566  3537 net.cpp:380] Eltwise6 -> Eltwise6
I0930 11:17:10.275584  3537 net.cpp:122] Setting up Eltwise6
I0930 11:17:10.275588  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.275590  3537 net.cpp:137] Memory required for data: 453428400
I0930 11:17:10.275593  3537 layer_factory.hpp:77] Creating layer elu_conv13
I0930 11:17:10.275596  3537 net.cpp:84] Creating Layer elu_conv13
I0930 11:17:10.275599  3537 net.cpp:406] elu_conv13 <- Eltwise6
I0930 11:17:10.275601  3537 net.cpp:367] elu_conv13 -> Eltwise6 (in-place)
I0930 11:17:10.275605  3537 net.cpp:122] Setting up elu_conv13
I0930 11:17:10.275609  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.275610  3537 net.cpp:137] Memory required for data: 459982000
I0930 11:17:10.275612  3537 layer_factory.hpp:77] Creating layer Eltwise6_elu_conv13_0_split
I0930 11:17:10.297169  3537 net.cpp:84] Creating Layer Eltwise6_elu_conv13_0_split
I0930 11:17:10.297176  3537 net.cpp:406] Eltwise6_elu_conv13_0_split <- Eltwise6
I0930 11:17:10.297183  3537 net.cpp:380] Eltwise6_elu_conv13_0_split -> Eltwise6_elu_conv13_0_split_0
I0930 11:17:10.297190  3537 net.cpp:380] Eltwise6_elu_conv13_0_split -> Eltwise6_elu_conv13_0_split_1
I0930 11:17:10.297247  3537 net.cpp:122] Setting up Eltwise6_elu_conv13_0_split
I0930 11:17:10.297255  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.297260  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.297264  3537 net.cpp:137] Memory required for data: 473089200
I0930 11:17:10.297268  3537 layer_factory.hpp:77] Creating layer Convolution14
I0930 11:17:10.297278  3537 net.cpp:84] Creating Layer Convolution14
I0930 11:17:10.297283  3537 net.cpp:406] Convolution14 <- Eltwise6_elu_conv13_0_split_0
I0930 11:17:10.297291  3537 net.cpp:380] Convolution14 -> Convolution14
I0930 11:17:10.298367  3537 net.cpp:122] Setting up Convolution14
I0930 11:17:10.298375  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.298378  3537 net.cpp:137] Memory required for data: 479642800
I0930 11:17:10.298383  3537 layer_factory.hpp:77] Creating layer BatchNorm14
I0930 11:17:10.298389  3537 net.cpp:84] Creating Layer BatchNorm14
I0930 11:17:10.298393  3537 net.cpp:406] BatchNorm14 <- Convolution14
I0930 11:17:10.298396  3537 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0930 11:17:10.298576  3537 net.cpp:122] Setting up BatchNorm14
I0930 11:17:10.298583  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.298585  3537 net.cpp:137] Memory required for data: 486196400
I0930 11:17:10.298590  3537 layer_factory.hpp:77] Creating layer Scale14
I0930 11:17:10.298595  3537 net.cpp:84] Creating Layer Scale14
I0930 11:17:10.298599  3537 net.cpp:406] Scale14 <- Convolution14
I0930 11:17:10.298602  3537 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0930 11:17:10.298636  3537 layer_factory.hpp:77] Creating layer Scale14
I0930 11:17:10.298730  3537 net.cpp:122] Setting up Scale14
I0930 11:17:10.298735  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.298738  3537 net.cpp:137] Memory required for data: 492750000
I0930 11:17:10.298743  3537 layer_factory.hpp:77] Creating layer elu_conv14
I0930 11:17:10.298748  3537 net.cpp:84] Creating Layer elu_conv14
I0930 11:17:10.298749  3537 net.cpp:406] elu_conv14 <- Convolution14
I0930 11:17:10.298753  3537 net.cpp:367] elu_conv14 -> Convolution14 (in-place)
I0930 11:17:10.298758  3537 net.cpp:122] Setting up elu_conv14
I0930 11:17:10.298760  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.298763  3537 net.cpp:137] Memory required for data: 499303600
I0930 11:17:10.298765  3537 layer_factory.hpp:77] Creating layer Convolution15
I0930 11:17:10.298773  3537 net.cpp:84] Creating Layer Convolution15
I0930 11:17:10.298774  3537 net.cpp:406] Convolution15 <- Convolution14
I0930 11:17:10.298779  3537 net.cpp:380] Convolution15 -> Convolution15
I0930 11:17:10.300509  3537 net.cpp:122] Setting up Convolution15
I0930 11:17:10.300518  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.300520  3537 net.cpp:137] Memory required for data: 505857200
I0930 11:17:10.300524  3537 layer_factory.hpp:77] Creating layer BatchNorm15
I0930 11:17:10.300529  3537 net.cpp:84] Creating Layer BatchNorm15
I0930 11:17:10.300532  3537 net.cpp:406] BatchNorm15 <- Convolution15
I0930 11:17:10.300536  3537 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0930 11:17:10.300690  3537 net.cpp:122] Setting up BatchNorm15
I0930 11:17:10.300694  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.300698  3537 net.cpp:137] Memory required for data: 512410800
I0930 11:17:10.300701  3537 layer_factory.hpp:77] Creating layer Scale15
I0930 11:17:10.300705  3537 net.cpp:84] Creating Layer Scale15
I0930 11:17:10.300709  3537 net.cpp:406] Scale15 <- Convolution15
I0930 11:17:10.300711  3537 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0930 11:17:10.300741  3537 layer_factory.hpp:77] Creating layer Scale15
I0930 11:17:10.300827  3537 net.cpp:122] Setting up Scale15
I0930 11:17:10.300842  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.300843  3537 net.cpp:137] Memory required for data: 518964400
I0930 11:17:10.300848  3537 layer_factory.hpp:77] Creating layer Eltwise7
I0930 11:17:10.300860  3537 net.cpp:84] Creating Layer Eltwise7
I0930 11:17:10.300863  3537 net.cpp:406] Eltwise7 <- Eltwise6_elu_conv13_0_split_1
I0930 11:17:10.300866  3537 net.cpp:406] Eltwise7 <- Convolution15
I0930 11:17:10.300869  3537 net.cpp:380] Eltwise7 -> Eltwise7
I0930 11:17:10.300889  3537 net.cpp:122] Setting up Eltwise7
I0930 11:17:10.300894  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.300895  3537 net.cpp:137] Memory required for data: 525518000
I0930 11:17:10.300897  3537 layer_factory.hpp:77] Creating layer elu_conv15
I0930 11:17:10.300901  3537 net.cpp:84] Creating Layer elu_conv15
I0930 11:17:10.300904  3537 net.cpp:406] elu_conv15 <- Eltwise7
I0930 11:17:10.300907  3537 net.cpp:367] elu_conv15 -> Eltwise7 (in-place)
I0930 11:17:10.300910  3537 net.cpp:122] Setting up elu_conv15
I0930 11:17:10.300914  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.300916  3537 net.cpp:137] Memory required for data: 532071600
I0930 11:17:10.300918  3537 layer_factory.hpp:77] Creating layer Eltwise7_elu_conv15_0_split
I0930 11:17:10.300921  3537 net.cpp:84] Creating Layer Eltwise7_elu_conv15_0_split
I0930 11:17:10.300925  3537 net.cpp:406] Eltwise7_elu_conv15_0_split <- Eltwise7
I0930 11:17:10.300927  3537 net.cpp:380] Eltwise7_elu_conv15_0_split -> Eltwise7_elu_conv15_0_split_0
I0930 11:17:10.300930  3537 net.cpp:380] Eltwise7_elu_conv15_0_split -> Eltwise7_elu_conv15_0_split_1
I0930 11:17:10.300957  3537 net.cpp:122] Setting up Eltwise7_elu_conv15_0_split
I0930 11:17:10.300961  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.300963  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.300966  3537 net.cpp:137] Memory required for data: 545178800
I0930 11:17:10.300968  3537 layer_factory.hpp:77] Creating layer Convolution16
I0930 11:17:10.300974  3537 net.cpp:84] Creating Layer Convolution16
I0930 11:17:10.300977  3537 net.cpp:406] Convolution16 <- Eltwise7_elu_conv15_0_split_0
I0930 11:17:10.300981  3537 net.cpp:380] Convolution16 -> Convolution16
I0930 11:17:10.301625  3537 net.cpp:122] Setting up Convolution16
I0930 11:17:10.301633  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.301635  3537 net.cpp:137] Memory required for data: 551732400
I0930 11:17:10.301640  3537 layer_factory.hpp:77] Creating layer BatchNorm16
I0930 11:17:10.301645  3537 net.cpp:84] Creating Layer BatchNorm16
I0930 11:17:10.301647  3537 net.cpp:406] BatchNorm16 <- Convolution16
I0930 11:17:10.301652  3537 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0930 11:17:10.301807  3537 net.cpp:122] Setting up BatchNorm16
I0930 11:17:10.301812  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.301815  3537 net.cpp:137] Memory required for data: 558286000
I0930 11:17:10.301820  3537 layer_factory.hpp:77] Creating layer Scale16
I0930 11:17:10.301823  3537 net.cpp:84] Creating Layer Scale16
I0930 11:17:10.301826  3537 net.cpp:406] Scale16 <- Convolution16
I0930 11:17:10.301829  3537 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0930 11:17:10.301861  3537 layer_factory.hpp:77] Creating layer Scale16
I0930 11:17:10.301947  3537 net.cpp:122] Setting up Scale16
I0930 11:17:10.301951  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.301954  3537 net.cpp:137] Memory required for data: 564839600
I0930 11:17:10.301957  3537 layer_factory.hpp:77] Creating layer elu_conv16
I0930 11:17:10.301960  3537 net.cpp:84] Creating Layer elu_conv16
I0930 11:17:10.301964  3537 net.cpp:406] elu_conv16 <- Convolution16
I0930 11:17:10.301966  3537 net.cpp:367] elu_conv16 -> Convolution16 (in-place)
I0930 11:17:10.301971  3537 net.cpp:122] Setting up elu_conv16
I0930 11:17:10.301975  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.301976  3537 net.cpp:137] Memory required for data: 571393200
I0930 11:17:10.301978  3537 layer_factory.hpp:77] Creating layer Convolution17
I0930 11:17:10.301985  3537 net.cpp:84] Creating Layer Convolution17
I0930 11:17:10.301987  3537 net.cpp:406] Convolution17 <- Convolution16
I0930 11:17:10.301996  3537 net.cpp:380] Convolution17 -> Convolution17
I0930 11:17:10.302989  3537 net.cpp:122] Setting up Convolution17
I0930 11:17:10.302997  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.303000  3537 net.cpp:137] Memory required for data: 577946800
I0930 11:17:10.303005  3537 layer_factory.hpp:77] Creating layer BatchNorm17
I0930 11:17:10.303010  3537 net.cpp:84] Creating Layer BatchNorm17
I0930 11:17:10.303014  3537 net.cpp:406] BatchNorm17 <- Convolution17
I0930 11:17:10.303017  3537 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0930 11:17:10.303176  3537 net.cpp:122] Setting up BatchNorm17
I0930 11:17:10.303181  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.303184  3537 net.cpp:137] Memory required for data: 584500400
I0930 11:17:10.303189  3537 layer_factory.hpp:77] Creating layer Scale17
I0930 11:17:10.303194  3537 net.cpp:84] Creating Layer Scale17
I0930 11:17:10.303196  3537 net.cpp:406] Scale17 <- Convolution17
I0930 11:17:10.303200  3537 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0930 11:17:10.303231  3537 layer_factory.hpp:77] Creating layer Scale17
I0930 11:17:10.303319  3537 net.cpp:122] Setting up Scale17
I0930 11:17:10.303323  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.303325  3537 net.cpp:137] Memory required for data: 591054000
I0930 11:17:10.303329  3537 layer_factory.hpp:77] Creating layer Eltwise8
I0930 11:17:10.303333  3537 net.cpp:84] Creating Layer Eltwise8
I0930 11:17:10.303336  3537 net.cpp:406] Eltwise8 <- Eltwise7_elu_conv15_0_split_1
I0930 11:17:10.303339  3537 net.cpp:406] Eltwise8 <- Convolution17
I0930 11:17:10.303344  3537 net.cpp:380] Eltwise8 -> Eltwise8
I0930 11:17:10.303361  3537 net.cpp:122] Setting up Eltwise8
I0930 11:17:10.303366  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.303369  3537 net.cpp:137] Memory required for data: 597607600
I0930 11:17:10.303370  3537 layer_factory.hpp:77] Creating layer elu_conv17
I0930 11:17:10.303373  3537 net.cpp:84] Creating Layer elu_conv17
I0930 11:17:10.303376  3537 net.cpp:406] elu_conv17 <- Eltwise8
I0930 11:17:10.303378  3537 net.cpp:367] elu_conv17 -> Eltwise8 (in-place)
I0930 11:17:10.303382  3537 net.cpp:122] Setting up elu_conv17
I0930 11:17:10.303385  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.303387  3537 net.cpp:137] Memory required for data: 604161200
I0930 11:17:10.303390  3537 layer_factory.hpp:77] Creating layer Eltwise8_elu_conv17_0_split
I0930 11:17:10.303393  3537 net.cpp:84] Creating Layer Eltwise8_elu_conv17_0_split
I0930 11:17:10.303395  3537 net.cpp:406] Eltwise8_elu_conv17_0_split <- Eltwise8
I0930 11:17:10.303400  3537 net.cpp:380] Eltwise8_elu_conv17_0_split -> Eltwise8_elu_conv17_0_split_0
I0930 11:17:10.303403  3537 net.cpp:380] Eltwise8_elu_conv17_0_split -> Eltwise8_elu_conv17_0_split_1
I0930 11:17:10.303429  3537 net.cpp:122] Setting up Eltwise8_elu_conv17_0_split
I0930 11:17:10.303433  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.303436  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.303438  3537 net.cpp:137] Memory required for data: 617268400
I0930 11:17:10.303441  3537 layer_factory.hpp:77] Creating layer Convolution18
I0930 11:17:10.303447  3537 net.cpp:84] Creating Layer Convolution18
I0930 11:17:10.303449  3537 net.cpp:406] Convolution18 <- Eltwise8_elu_conv17_0_split_0
I0930 11:17:10.303453  3537 net.cpp:380] Convolution18 -> Convolution18
I0930 11:17:10.304458  3537 net.cpp:122] Setting up Convolution18
I0930 11:17:10.304467  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.304471  3537 net.cpp:137] Memory required for data: 623822000
I0930 11:17:10.304476  3537 layer_factory.hpp:77] Creating layer BatchNorm18
I0930 11:17:10.304481  3537 net.cpp:84] Creating Layer BatchNorm18
I0930 11:17:10.304483  3537 net.cpp:406] BatchNorm18 <- Convolution18
I0930 11:17:10.304487  3537 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0930 11:17:10.304647  3537 net.cpp:122] Setting up BatchNorm18
I0930 11:17:10.304651  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.304661  3537 net.cpp:137] Memory required for data: 630375600
I0930 11:17:10.304667  3537 layer_factory.hpp:77] Creating layer Scale18
I0930 11:17:10.304672  3537 net.cpp:84] Creating Layer Scale18
I0930 11:17:10.304673  3537 net.cpp:406] Scale18 <- Convolution18
I0930 11:17:10.304677  3537 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0930 11:17:10.304708  3537 layer_factory.hpp:77] Creating layer Scale18
I0930 11:17:10.304793  3537 net.cpp:122] Setting up Scale18
I0930 11:17:10.304797  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.304800  3537 net.cpp:137] Memory required for data: 636929200
I0930 11:17:10.304803  3537 layer_factory.hpp:77] Creating layer elu_conv18
I0930 11:17:10.304807  3537 net.cpp:84] Creating Layer elu_conv18
I0930 11:17:10.304810  3537 net.cpp:406] elu_conv18 <- Convolution18
I0930 11:17:10.304812  3537 net.cpp:367] elu_conv18 -> Convolution18 (in-place)
I0930 11:17:10.304816  3537 net.cpp:122] Setting up elu_conv18
I0930 11:17:10.304819  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.304821  3537 net.cpp:137] Memory required for data: 643482800
I0930 11:17:10.304823  3537 layer_factory.hpp:77] Creating layer Convolution19
I0930 11:17:10.304831  3537 net.cpp:84] Creating Layer Convolution19
I0930 11:17:10.304832  3537 net.cpp:406] Convolution19 <- Convolution18
I0930 11:17:10.304836  3537 net.cpp:380] Convolution19 -> Convolution19
I0930 11:17:10.305770  3537 net.cpp:122] Setting up Convolution19
I0930 11:17:10.305778  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.305781  3537 net.cpp:137] Memory required for data: 650036400
I0930 11:17:10.305786  3537 layer_factory.hpp:77] Creating layer BatchNorm19
I0930 11:17:10.305791  3537 net.cpp:84] Creating Layer BatchNorm19
I0930 11:17:10.305794  3537 net.cpp:406] BatchNorm19 <- Convolution19
I0930 11:17:10.305799  3537 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0930 11:17:10.305951  3537 net.cpp:122] Setting up BatchNorm19
I0930 11:17:10.305955  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.305958  3537 net.cpp:137] Memory required for data: 656590000
I0930 11:17:10.305974  3537 layer_factory.hpp:77] Creating layer Scale19
I0930 11:17:10.305979  3537 net.cpp:84] Creating Layer Scale19
I0930 11:17:10.305981  3537 net.cpp:406] Scale19 <- Convolution19
I0930 11:17:10.305984  3537 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0930 11:17:10.306016  3537 layer_factory.hpp:77] Creating layer Scale19
I0930 11:17:10.306102  3537 net.cpp:122] Setting up Scale19
I0930 11:17:10.306107  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.306109  3537 net.cpp:137] Memory required for data: 663143600
I0930 11:17:10.306113  3537 layer_factory.hpp:77] Creating layer Eltwise9
I0930 11:17:10.306118  3537 net.cpp:84] Creating Layer Eltwise9
I0930 11:17:10.306119  3537 net.cpp:406] Eltwise9 <- Eltwise8_elu_conv17_0_split_1
I0930 11:17:10.306123  3537 net.cpp:406] Eltwise9 <- Convolution19
I0930 11:17:10.306125  3537 net.cpp:380] Eltwise9 -> Eltwise9
I0930 11:17:10.306143  3537 net.cpp:122] Setting up Eltwise9
I0930 11:17:10.306146  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.306149  3537 net.cpp:137] Memory required for data: 669697200
I0930 11:17:10.306150  3537 layer_factory.hpp:77] Creating layer elu_conv19
I0930 11:17:10.306154  3537 net.cpp:84] Creating Layer elu_conv19
I0930 11:17:10.306157  3537 net.cpp:406] elu_conv19 <- Eltwise9
I0930 11:17:10.306160  3537 net.cpp:367] elu_conv19 -> Eltwise9 (in-place)
I0930 11:17:10.328092  3537 net.cpp:122] Setting up elu_conv19
I0930 11:17:10.328100  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.328104  3537 net.cpp:137] Memory required for data: 676250800
I0930 11:17:10.328109  3537 layer_factory.hpp:77] Creating layer Eltwise9_elu_conv19_0_split
I0930 11:17:10.328114  3537 net.cpp:84] Creating Layer Eltwise9_elu_conv19_0_split
I0930 11:17:10.328117  3537 net.cpp:406] Eltwise9_elu_conv19_0_split <- Eltwise9
I0930 11:17:10.328132  3537 net.cpp:380] Eltwise9_elu_conv19_0_split -> Eltwise9_elu_conv19_0_split_0
I0930 11:17:10.328140  3537 net.cpp:380] Eltwise9_elu_conv19_0_split -> Eltwise9_elu_conv19_0_split_1
I0930 11:17:10.328187  3537 net.cpp:122] Setting up Eltwise9_elu_conv19_0_split
I0930 11:17:10.328194  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.328200  3537 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 11:17:10.328204  3537 net.cpp:137] Memory required for data: 689358000
I0930 11:17:10.328207  3537 layer_factory.hpp:77] Creating layer Convolution20
I0930 11:17:10.328218  3537 net.cpp:84] Creating Layer Convolution20
I0930 11:17:10.328222  3537 net.cpp:406] Convolution20 <- Eltwise9_elu_conv19_0_split_0
I0930 11:17:10.328228  3537 net.cpp:380] Convolution20 -> Convolution20
I0930 11:17:10.329262  3537 net.cpp:122] Setting up Convolution20
I0930 11:17:10.329272  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.329275  3537 net.cpp:137] Memory required for data: 692634800
I0930 11:17:10.329280  3537 layer_factory.hpp:77] Creating layer BatchNorm20
I0930 11:17:10.329286  3537 net.cpp:84] Creating Layer BatchNorm20
I0930 11:17:10.329289  3537 net.cpp:406] BatchNorm20 <- Convolution20
I0930 11:17:10.329294  3537 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0930 11:17:10.329488  3537 net.cpp:122] Setting up BatchNorm20
I0930 11:17:10.329493  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.329494  3537 net.cpp:137] Memory required for data: 695911600
I0930 11:17:10.329499  3537 layer_factory.hpp:77] Creating layer Scale20
I0930 11:17:10.329504  3537 net.cpp:84] Creating Layer Scale20
I0930 11:17:10.329505  3537 net.cpp:406] Scale20 <- Convolution20
I0930 11:17:10.329510  3537 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0930 11:17:10.329541  3537 layer_factory.hpp:77] Creating layer Scale20
I0930 11:17:10.329643  3537 net.cpp:122] Setting up Scale20
I0930 11:17:10.329648  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.329649  3537 net.cpp:137] Memory required for data: 699188400
I0930 11:17:10.329653  3537 layer_factory.hpp:77] Creating layer Convolution21
I0930 11:17:10.329660  3537 net.cpp:84] Creating Layer Convolution21
I0930 11:17:10.329663  3537 net.cpp:406] Convolution21 <- Eltwise9_elu_conv19_0_split_1
I0930 11:17:10.329668  3537 net.cpp:380] Convolution21 -> Convolution21
I0930 11:17:10.330848  3537 net.cpp:122] Setting up Convolution21
I0930 11:17:10.330857  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.330860  3537 net.cpp:137] Memory required for data: 702465200
I0930 11:17:10.330864  3537 layer_factory.hpp:77] Creating layer BatchNorm21
I0930 11:17:10.330869  3537 net.cpp:84] Creating Layer BatchNorm21
I0930 11:17:10.330873  3537 net.cpp:406] BatchNorm21 <- Convolution21
I0930 11:17:10.330876  3537 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0930 11:17:10.331038  3537 net.cpp:122] Setting up BatchNorm21
I0930 11:17:10.331043  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.331045  3537 net.cpp:137] Memory required for data: 705742000
I0930 11:17:10.331049  3537 layer_factory.hpp:77] Creating layer Scale21
I0930 11:17:10.331054  3537 net.cpp:84] Creating Layer Scale21
I0930 11:17:10.331056  3537 net.cpp:406] Scale21 <- Convolution21
I0930 11:17:10.331069  3537 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0930 11:17:10.331116  3537 layer_factory.hpp:77] Creating layer Scale21
I0930 11:17:10.331215  3537 net.cpp:122] Setting up Scale21
I0930 11:17:10.331219  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.331221  3537 net.cpp:137] Memory required for data: 709018800
I0930 11:17:10.331225  3537 layer_factory.hpp:77] Creating layer elu_conv20
I0930 11:17:10.331229  3537 net.cpp:84] Creating Layer elu_conv20
I0930 11:17:10.331233  3537 net.cpp:406] elu_conv20 <- Convolution21
I0930 11:17:10.331235  3537 net.cpp:367] elu_conv20 -> Convolution21 (in-place)
I0930 11:17:10.331240  3537 net.cpp:122] Setting up elu_conv20
I0930 11:17:10.331243  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.331251  3537 net.cpp:137] Memory required for data: 712295600
I0930 11:17:10.331254  3537 layer_factory.hpp:77] Creating layer Convolution22
I0930 11:17:10.331260  3537 net.cpp:84] Creating Layer Convolution22
I0930 11:17:10.331264  3537 net.cpp:406] Convolution22 <- Convolution21
I0930 11:17:10.331267  3537 net.cpp:380] Convolution22 -> Convolution22
I0930 11:17:10.332422  3537 net.cpp:122] Setting up Convolution22
I0930 11:17:10.332430  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.332433  3537 net.cpp:137] Memory required for data: 715572400
I0930 11:17:10.332438  3537 layer_factory.hpp:77] Creating layer BatchNorm22
I0930 11:17:10.332442  3537 net.cpp:84] Creating Layer BatchNorm22
I0930 11:17:10.332445  3537 net.cpp:406] BatchNorm22 <- Convolution22
I0930 11:17:10.332449  3537 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0930 11:17:10.332607  3537 net.cpp:122] Setting up BatchNorm22
I0930 11:17:10.332612  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.332613  3537 net.cpp:137] Memory required for data: 718849200
I0930 11:17:10.332618  3537 layer_factory.hpp:77] Creating layer Scale22
I0930 11:17:10.332623  3537 net.cpp:84] Creating Layer Scale22
I0930 11:17:10.332625  3537 net.cpp:406] Scale22 <- Convolution22
I0930 11:17:10.332628  3537 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0930 11:17:10.332669  3537 layer_factory.hpp:77] Creating layer Scale22
I0930 11:17:10.332757  3537 net.cpp:122] Setting up Scale22
I0930 11:17:10.332762  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.332763  3537 net.cpp:137] Memory required for data: 722126000
I0930 11:17:10.332767  3537 layer_factory.hpp:77] Creating layer Eltwise10
I0930 11:17:10.332772  3537 net.cpp:84] Creating Layer Eltwise10
I0930 11:17:10.332773  3537 net.cpp:406] Eltwise10 <- Convolution20
I0930 11:17:10.332777  3537 net.cpp:406] Eltwise10 <- Convolution22
I0930 11:17:10.332780  3537 net.cpp:380] Eltwise10 -> Eltwise10
I0930 11:17:10.332795  3537 net.cpp:122] Setting up Eltwise10
I0930 11:17:10.332799  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.332801  3537 net.cpp:137] Memory required for data: 725402800
I0930 11:17:10.332803  3537 layer_factory.hpp:77] Creating layer elu_conv21
I0930 11:17:10.332806  3537 net.cpp:84] Creating Layer elu_conv21
I0930 11:17:10.332808  3537 net.cpp:406] elu_conv21 <- Eltwise10
I0930 11:17:10.332813  3537 net.cpp:367] elu_conv21 -> Eltwise10 (in-place)
I0930 11:17:10.332816  3537 net.cpp:122] Setting up elu_conv21
I0930 11:17:10.332819  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.332821  3537 net.cpp:137] Memory required for data: 728679600
I0930 11:17:10.332823  3537 layer_factory.hpp:77] Creating layer Eltwise10_elu_conv21_0_split
I0930 11:17:10.332828  3537 net.cpp:84] Creating Layer Eltwise10_elu_conv21_0_split
I0930 11:17:10.332829  3537 net.cpp:406] Eltwise10_elu_conv21_0_split <- Eltwise10
I0930 11:17:10.332832  3537 net.cpp:380] Eltwise10_elu_conv21_0_split -> Eltwise10_elu_conv21_0_split_0
I0930 11:17:10.332836  3537 net.cpp:380] Eltwise10_elu_conv21_0_split -> Eltwise10_elu_conv21_0_split_1
I0930 11:17:10.332862  3537 net.cpp:122] Setting up Eltwise10_elu_conv21_0_split
I0930 11:17:10.332866  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.332870  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.332871  3537 net.cpp:137] Memory required for data: 735233200
I0930 11:17:10.332873  3537 layer_factory.hpp:77] Creating layer Convolution23
I0930 11:17:10.332880  3537 net.cpp:84] Creating Layer Convolution23
I0930 11:17:10.332881  3537 net.cpp:406] Convolution23 <- Eltwise10_elu_conv21_0_split_0
I0930 11:17:10.332886  3537 net.cpp:380] Convolution23 -> Convolution23
I0930 11:17:10.333981  3537 net.cpp:122] Setting up Convolution23
I0930 11:17:10.333991  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.333992  3537 net.cpp:137] Memory required for data: 738510000
I0930 11:17:10.333997  3537 layer_factory.hpp:77] Creating layer BatchNorm23
I0930 11:17:10.334008  3537 net.cpp:84] Creating Layer BatchNorm23
I0930 11:17:10.334012  3537 net.cpp:406] BatchNorm23 <- Convolution23
I0930 11:17:10.334015  3537 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0930 11:17:10.334168  3537 net.cpp:122] Setting up BatchNorm23
I0930 11:17:10.334172  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.334174  3537 net.cpp:137] Memory required for data: 741786800
I0930 11:17:10.334179  3537 layer_factory.hpp:77] Creating layer Scale23
I0930 11:17:10.334183  3537 net.cpp:84] Creating Layer Scale23
I0930 11:17:10.334187  3537 net.cpp:406] Scale23 <- Convolution23
I0930 11:17:10.334189  3537 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0930 11:17:10.334220  3537 layer_factory.hpp:77] Creating layer Scale23
I0930 11:17:10.334306  3537 net.cpp:122] Setting up Scale23
I0930 11:17:10.334311  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.334313  3537 net.cpp:137] Memory required for data: 745063600
I0930 11:17:10.334316  3537 layer_factory.hpp:77] Creating layer elu_conv22
I0930 11:17:10.334321  3537 net.cpp:84] Creating Layer elu_conv22
I0930 11:17:10.334322  3537 net.cpp:406] elu_conv22 <- Convolution23
I0930 11:17:10.334326  3537 net.cpp:367] elu_conv22 -> Convolution23 (in-place)
I0930 11:17:10.334329  3537 net.cpp:122] Setting up elu_conv22
I0930 11:17:10.334333  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.334336  3537 net.cpp:137] Memory required for data: 748340400
I0930 11:17:10.334337  3537 layer_factory.hpp:77] Creating layer Convolution24
I0930 11:17:10.334343  3537 net.cpp:84] Creating Layer Convolution24
I0930 11:17:10.334345  3537 net.cpp:406] Convolution24 <- Convolution23
I0930 11:17:10.334349  3537 net.cpp:380] Convolution24 -> Convolution24
I0930 11:17:10.335450  3537 net.cpp:122] Setting up Convolution24
I0930 11:17:10.335459  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.335461  3537 net.cpp:137] Memory required for data: 751617200
I0930 11:17:10.335466  3537 layer_factory.hpp:77] Creating layer BatchNorm24
I0930 11:17:10.335471  3537 net.cpp:84] Creating Layer BatchNorm24
I0930 11:17:10.335474  3537 net.cpp:406] BatchNorm24 <- Convolution24
I0930 11:17:10.335477  3537 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0930 11:17:10.335631  3537 net.cpp:122] Setting up BatchNorm24
I0930 11:17:10.335635  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.335638  3537 net.cpp:137] Memory required for data: 754894000
I0930 11:17:10.335642  3537 layer_factory.hpp:77] Creating layer Scale24
I0930 11:17:10.335647  3537 net.cpp:84] Creating Layer Scale24
I0930 11:17:10.335649  3537 net.cpp:406] Scale24 <- Convolution24
I0930 11:17:10.335654  3537 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0930 11:17:10.335693  3537 layer_factory.hpp:77] Creating layer Scale24
I0930 11:17:10.335803  3537 net.cpp:122] Setting up Scale24
I0930 11:17:10.335808  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.335809  3537 net.cpp:137] Memory required for data: 758170800
I0930 11:17:10.335813  3537 layer_factory.hpp:77] Creating layer Eltwise11
I0930 11:17:10.335817  3537 net.cpp:84] Creating Layer Eltwise11
I0930 11:17:10.335820  3537 net.cpp:406] Eltwise11 <- Eltwise10_elu_conv21_0_split_1
I0930 11:17:10.335824  3537 net.cpp:406] Eltwise11 <- Convolution24
I0930 11:17:10.335826  3537 net.cpp:380] Eltwise11 -> Eltwise11
I0930 11:17:10.335851  3537 net.cpp:122] Setting up Eltwise11
I0930 11:17:10.335855  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.335857  3537 net.cpp:137] Memory required for data: 761447600
I0930 11:17:10.335860  3537 layer_factory.hpp:77] Creating layer elu_conv23
I0930 11:17:10.335862  3537 net.cpp:84] Creating Layer elu_conv23
I0930 11:17:10.335865  3537 net.cpp:406] elu_conv23 <- Eltwise11
I0930 11:17:10.335870  3537 net.cpp:367] elu_conv23 -> Eltwise11 (in-place)
I0930 11:17:10.335872  3537 net.cpp:122] Setting up elu_conv23
I0930 11:17:10.335875  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.335885  3537 net.cpp:137] Memory required for data: 764724400
I0930 11:17:10.335886  3537 layer_factory.hpp:77] Creating layer Eltwise11_elu_conv23_0_split
I0930 11:17:10.335889  3537 net.cpp:84] Creating Layer Eltwise11_elu_conv23_0_split
I0930 11:17:10.335892  3537 net.cpp:406] Eltwise11_elu_conv23_0_split <- Eltwise11
I0930 11:17:10.335896  3537 net.cpp:380] Eltwise11_elu_conv23_0_split -> Eltwise11_elu_conv23_0_split_0
I0930 11:17:10.335899  3537 net.cpp:380] Eltwise11_elu_conv23_0_split -> Eltwise11_elu_conv23_0_split_1
I0930 11:17:10.335927  3537 net.cpp:122] Setting up Eltwise11_elu_conv23_0_split
I0930 11:17:10.335932  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.335934  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.335937  3537 net.cpp:137] Memory required for data: 771278000
I0930 11:17:10.335938  3537 layer_factory.hpp:77] Creating layer Convolution25
I0930 11:17:10.335943  3537 net.cpp:84] Creating Layer Convolution25
I0930 11:17:10.335947  3537 net.cpp:406] Convolution25 <- Eltwise11_elu_conv23_0_split_0
I0930 11:17:10.335952  3537 net.cpp:380] Convolution25 -> Convolution25
I0930 11:17:10.337045  3537 net.cpp:122] Setting up Convolution25
I0930 11:17:10.337054  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.337056  3537 net.cpp:137] Memory required for data: 774554800
I0930 11:17:10.337060  3537 layer_factory.hpp:77] Creating layer BatchNorm25
I0930 11:17:10.337065  3537 net.cpp:84] Creating Layer BatchNorm25
I0930 11:17:10.337069  3537 net.cpp:406] BatchNorm25 <- Convolution25
I0930 11:17:10.337071  3537 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0930 11:17:10.337224  3537 net.cpp:122] Setting up BatchNorm25
I0930 11:17:10.337229  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.337230  3537 net.cpp:137] Memory required for data: 777831600
I0930 11:17:10.337235  3537 layer_factory.hpp:77] Creating layer Scale25
I0930 11:17:10.337239  3537 net.cpp:84] Creating Layer Scale25
I0930 11:17:10.337242  3537 net.cpp:406] Scale25 <- Convolution25
I0930 11:17:10.337245  3537 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0930 11:17:10.337275  3537 layer_factory.hpp:77] Creating layer Scale25
I0930 11:17:10.337363  3537 net.cpp:122] Setting up Scale25
I0930 11:17:10.337368  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.337369  3537 net.cpp:137] Memory required for data: 781108400
I0930 11:17:10.337373  3537 layer_factory.hpp:77] Creating layer elu_conv24
I0930 11:17:10.337378  3537 net.cpp:84] Creating Layer elu_conv24
I0930 11:17:10.337380  3537 net.cpp:406] elu_conv24 <- Convolution25
I0930 11:17:10.337383  3537 net.cpp:367] elu_conv24 -> Convolution25 (in-place)
I0930 11:17:10.337386  3537 net.cpp:122] Setting up elu_conv24
I0930 11:17:10.337389  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.337391  3537 net.cpp:137] Memory required for data: 784385200
I0930 11:17:10.337394  3537 layer_factory.hpp:77] Creating layer Convolution26
I0930 11:17:10.337400  3537 net.cpp:84] Creating Layer Convolution26
I0930 11:17:10.337402  3537 net.cpp:406] Convolution26 <- Convolution25
I0930 11:17:10.337406  3537 net.cpp:380] Convolution26 -> Convolution26
I0930 11:17:10.338193  3537 net.cpp:122] Setting up Convolution26
I0930 11:17:10.338201  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.338203  3537 net.cpp:137] Memory required for data: 787662000
I0930 11:17:10.358160  3537 layer_factory.hpp:77] Creating layer BatchNorm26
I0930 11:17:10.358170  3537 net.cpp:84] Creating Layer BatchNorm26
I0930 11:17:10.358176  3537 net.cpp:406] BatchNorm26 <- Convolution26
I0930 11:17:10.358182  3537 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0930 11:17:10.358361  3537 net.cpp:122] Setting up BatchNorm26
I0930 11:17:10.358366  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.358367  3537 net.cpp:137] Memory required for data: 790938800
I0930 11:17:10.358373  3537 layer_factory.hpp:77] Creating layer Scale26
I0930 11:17:10.358378  3537 net.cpp:84] Creating Layer Scale26
I0930 11:17:10.358388  3537 net.cpp:406] Scale26 <- Convolution26
I0930 11:17:10.358392  3537 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0930 11:17:10.358428  3537 layer_factory.hpp:77] Creating layer Scale26
I0930 11:17:10.358534  3537 net.cpp:122] Setting up Scale26
I0930 11:17:10.358541  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.358542  3537 net.cpp:137] Memory required for data: 794215600
I0930 11:17:10.358547  3537 layer_factory.hpp:77] Creating layer Eltwise12
I0930 11:17:10.358552  3537 net.cpp:84] Creating Layer Eltwise12
I0930 11:17:10.358554  3537 net.cpp:406] Eltwise12 <- Eltwise11_elu_conv23_0_split_1
I0930 11:17:10.358558  3537 net.cpp:406] Eltwise12 <- Convolution26
I0930 11:17:10.358562  3537 net.cpp:380] Eltwise12 -> Eltwise12
I0930 11:17:10.358579  3537 net.cpp:122] Setting up Eltwise12
I0930 11:17:10.358584  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.358587  3537 net.cpp:137] Memory required for data: 797492400
I0930 11:17:10.358589  3537 layer_factory.hpp:77] Creating layer elu_conv25
I0930 11:17:10.358602  3537 net.cpp:84] Creating Layer elu_conv25
I0930 11:17:10.358603  3537 net.cpp:406] elu_conv25 <- Eltwise12
I0930 11:17:10.358608  3537 net.cpp:367] elu_conv25 -> Eltwise12 (in-place)
I0930 11:17:10.358611  3537 net.cpp:122] Setting up elu_conv25
I0930 11:17:10.358614  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.358618  3537 net.cpp:137] Memory required for data: 800769200
I0930 11:17:10.358619  3537 layer_factory.hpp:77] Creating layer Eltwise12_elu_conv25_0_split
I0930 11:17:10.358623  3537 net.cpp:84] Creating Layer Eltwise12_elu_conv25_0_split
I0930 11:17:10.358625  3537 net.cpp:406] Eltwise12_elu_conv25_0_split <- Eltwise12
I0930 11:17:10.358629  3537 net.cpp:380] Eltwise12_elu_conv25_0_split -> Eltwise12_elu_conv25_0_split_0
I0930 11:17:10.358633  3537 net.cpp:380] Eltwise12_elu_conv25_0_split -> Eltwise12_elu_conv25_0_split_1
I0930 11:17:10.358664  3537 net.cpp:122] Setting up Eltwise12_elu_conv25_0_split
I0930 11:17:10.358669  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.358671  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.358675  3537 net.cpp:137] Memory required for data: 807322800
I0930 11:17:10.358676  3537 layer_factory.hpp:77] Creating layer Convolution27
I0930 11:17:10.358683  3537 net.cpp:84] Creating Layer Convolution27
I0930 11:17:10.358686  3537 net.cpp:406] Convolution27 <- Eltwise12_elu_conv25_0_split_0
I0930 11:17:10.358690  3537 net.cpp:380] Convolution27 -> Convolution27
I0930 11:17:10.360343  3537 net.cpp:122] Setting up Convolution27
I0930 11:17:10.360352  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.360354  3537 net.cpp:137] Memory required for data: 810599600
I0930 11:17:10.360359  3537 layer_factory.hpp:77] Creating layer BatchNorm27
I0930 11:17:10.360364  3537 net.cpp:84] Creating Layer BatchNorm27
I0930 11:17:10.360368  3537 net.cpp:406] BatchNorm27 <- Convolution27
I0930 11:17:10.360371  3537 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0930 11:17:10.360527  3537 net.cpp:122] Setting up BatchNorm27
I0930 11:17:10.360532  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.360534  3537 net.cpp:137] Memory required for data: 813876400
I0930 11:17:10.360538  3537 layer_factory.hpp:77] Creating layer Scale27
I0930 11:17:10.360543  3537 net.cpp:84] Creating Layer Scale27
I0930 11:17:10.360546  3537 net.cpp:406] Scale27 <- Convolution27
I0930 11:17:10.360549  3537 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0930 11:17:10.360581  3537 layer_factory.hpp:77] Creating layer Scale27
I0930 11:17:10.360669  3537 net.cpp:122] Setting up Scale27
I0930 11:17:10.360673  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.360676  3537 net.cpp:137] Memory required for data: 817153200
I0930 11:17:10.360679  3537 layer_factory.hpp:77] Creating layer elu_conv26
I0930 11:17:10.360683  3537 net.cpp:84] Creating Layer elu_conv26
I0930 11:17:10.360687  3537 net.cpp:406] elu_conv26 <- Convolution27
I0930 11:17:10.360695  3537 net.cpp:367] elu_conv26 -> Convolution27 (in-place)
I0930 11:17:10.360702  3537 net.cpp:122] Setting up elu_conv26
I0930 11:17:10.360704  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.360707  3537 net.cpp:137] Memory required for data: 820430000
I0930 11:17:10.360708  3537 layer_factory.hpp:77] Creating layer Convolution28
I0930 11:17:10.360714  3537 net.cpp:84] Creating Layer Convolution28
I0930 11:17:10.360716  3537 net.cpp:406] Convolution28 <- Convolution27
I0930 11:17:10.360723  3537 net.cpp:380] Convolution28 -> Convolution28
I0930 11:17:10.362280  3537 net.cpp:122] Setting up Convolution28
I0930 11:17:10.362289  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.362293  3537 net.cpp:137] Memory required for data: 823706800
I0930 11:17:10.362298  3537 layer_factory.hpp:77] Creating layer BatchNorm28
I0930 11:17:10.362303  3537 net.cpp:84] Creating Layer BatchNorm28
I0930 11:17:10.362305  3537 net.cpp:406] BatchNorm28 <- Convolution28
I0930 11:17:10.362309  3537 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0930 11:17:10.362473  3537 net.cpp:122] Setting up BatchNorm28
I0930 11:17:10.362478  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.362480  3537 net.cpp:137] Memory required for data: 826983600
I0930 11:17:10.362485  3537 layer_factory.hpp:77] Creating layer Scale28
I0930 11:17:10.362489  3537 net.cpp:84] Creating Layer Scale28
I0930 11:17:10.362493  3537 net.cpp:406] Scale28 <- Convolution28
I0930 11:17:10.362496  3537 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0930 11:17:10.362537  3537 layer_factory.hpp:77] Creating layer Scale28
I0930 11:17:10.362632  3537 net.cpp:122] Setting up Scale28
I0930 11:17:10.362637  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.362639  3537 net.cpp:137] Memory required for data: 830260400
I0930 11:17:10.362643  3537 layer_factory.hpp:77] Creating layer Eltwise13
I0930 11:17:10.362648  3537 net.cpp:84] Creating Layer Eltwise13
I0930 11:17:10.362650  3537 net.cpp:406] Eltwise13 <- Eltwise12_elu_conv25_0_split_1
I0930 11:17:10.362653  3537 net.cpp:406] Eltwise13 <- Convolution28
I0930 11:17:10.362656  3537 net.cpp:380] Eltwise13 -> Eltwise13
I0930 11:17:10.362673  3537 net.cpp:122] Setting up Eltwise13
I0930 11:17:10.362676  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.362679  3537 net.cpp:137] Memory required for data: 833537200
I0930 11:17:10.362680  3537 layer_factory.hpp:77] Creating layer elu_conv27
I0930 11:17:10.362684  3537 net.cpp:84] Creating Layer elu_conv27
I0930 11:17:10.362687  3537 net.cpp:406] elu_conv27 <- Eltwise13
I0930 11:17:10.362690  3537 net.cpp:367] elu_conv27 -> Eltwise13 (in-place)
I0930 11:17:10.362694  3537 net.cpp:122] Setting up elu_conv27
I0930 11:17:10.362697  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.362699  3537 net.cpp:137] Memory required for data: 836814000
I0930 11:17:10.362701  3537 layer_factory.hpp:77] Creating layer Eltwise13_elu_conv27_0_split
I0930 11:17:10.362705  3537 net.cpp:84] Creating Layer Eltwise13_elu_conv27_0_split
I0930 11:17:10.362707  3537 net.cpp:406] Eltwise13_elu_conv27_0_split <- Eltwise13
I0930 11:17:10.362710  3537 net.cpp:380] Eltwise13_elu_conv27_0_split -> Eltwise13_elu_conv27_0_split_0
I0930 11:17:10.362715  3537 net.cpp:380] Eltwise13_elu_conv27_0_split -> Eltwise13_elu_conv27_0_split_1
I0930 11:17:10.362742  3537 net.cpp:122] Setting up Eltwise13_elu_conv27_0_split
I0930 11:17:10.362746  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.362749  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.362751  3537 net.cpp:137] Memory required for data: 843367600
I0930 11:17:10.362753  3537 layer_factory.hpp:77] Creating layer Convolution29
I0930 11:17:10.362759  3537 net.cpp:84] Creating Layer Convolution29
I0930 11:17:10.362762  3537 net.cpp:406] Convolution29 <- Eltwise13_elu_conv27_0_split_0
I0930 11:17:10.362766  3537 net.cpp:380] Convolution29 -> Convolution29
I0930 11:17:10.363896  3537 net.cpp:122] Setting up Convolution29
I0930 11:17:10.363912  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.363915  3537 net.cpp:137] Memory required for data: 846644400
I0930 11:17:10.363920  3537 layer_factory.hpp:77] Creating layer BatchNorm29
I0930 11:17:10.363925  3537 net.cpp:84] Creating Layer BatchNorm29
I0930 11:17:10.363929  3537 net.cpp:406] BatchNorm29 <- Convolution29
I0930 11:17:10.363931  3537 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0930 11:17:10.364087  3537 net.cpp:122] Setting up BatchNorm29
I0930 11:17:10.364092  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.364094  3537 net.cpp:137] Memory required for data: 849921200
I0930 11:17:10.364099  3537 layer_factory.hpp:77] Creating layer Scale29
I0930 11:17:10.364102  3537 net.cpp:84] Creating Layer Scale29
I0930 11:17:10.364105  3537 net.cpp:406] Scale29 <- Convolution29
I0930 11:17:10.364109  3537 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0930 11:17:10.364140  3537 layer_factory.hpp:77] Creating layer Scale29
I0930 11:17:10.364228  3537 net.cpp:122] Setting up Scale29
I0930 11:17:10.364233  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.364234  3537 net.cpp:137] Memory required for data: 853198000
I0930 11:17:10.364238  3537 layer_factory.hpp:77] Creating layer elu_conv28
I0930 11:17:10.364241  3537 net.cpp:84] Creating Layer elu_conv28
I0930 11:17:10.364244  3537 net.cpp:406] elu_conv28 <- Convolution29
I0930 11:17:10.364248  3537 net.cpp:367] elu_conv28 -> Convolution29 (in-place)
I0930 11:17:10.364250  3537 net.cpp:122] Setting up elu_conv28
I0930 11:17:10.364253  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.364255  3537 net.cpp:137] Memory required for data: 856474800
I0930 11:17:10.364259  3537 layer_factory.hpp:77] Creating layer Convolution30
I0930 11:17:10.364264  3537 net.cpp:84] Creating Layer Convolution30
I0930 11:17:10.364266  3537 net.cpp:406] Convolution30 <- Convolution29
I0930 11:17:10.364270  3537 net.cpp:380] Convolution30 -> Convolution30
I0930 11:17:10.365365  3537 net.cpp:122] Setting up Convolution30
I0930 11:17:10.365373  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.365375  3537 net.cpp:137] Memory required for data: 859751600
I0930 11:17:10.365381  3537 layer_factory.hpp:77] Creating layer BatchNorm30
I0930 11:17:10.365386  3537 net.cpp:84] Creating Layer BatchNorm30
I0930 11:17:10.365388  3537 net.cpp:406] BatchNorm30 <- Convolution30
I0930 11:17:10.365391  3537 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0930 11:17:10.365547  3537 net.cpp:122] Setting up BatchNorm30
I0930 11:17:10.365552  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.365555  3537 net.cpp:137] Memory required for data: 863028400
I0930 11:17:10.365558  3537 layer_factory.hpp:77] Creating layer Scale30
I0930 11:17:10.365562  3537 net.cpp:84] Creating Layer Scale30
I0930 11:17:10.365566  3537 net.cpp:406] Scale30 <- Convolution30
I0930 11:17:10.365568  3537 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0930 11:17:10.365599  3537 layer_factory.hpp:77] Creating layer Scale30
I0930 11:17:10.365686  3537 net.cpp:122] Setting up Scale30
I0930 11:17:10.365694  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.365695  3537 net.cpp:137] Memory required for data: 866305200
I0930 11:17:10.365700  3537 layer_factory.hpp:77] Creating layer Eltwise14
I0930 11:17:10.365703  3537 net.cpp:84] Creating Layer Eltwise14
I0930 11:17:10.365705  3537 net.cpp:406] Eltwise14 <- Eltwise13_elu_conv27_0_split_1
I0930 11:17:10.365708  3537 net.cpp:406] Eltwise14 <- Convolution30
I0930 11:17:10.365711  3537 net.cpp:380] Eltwise14 -> Eltwise14
I0930 11:17:10.365727  3537 net.cpp:122] Setting up Eltwise14
I0930 11:17:10.365731  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.365732  3537 net.cpp:137] Memory required for data: 869582000
I0930 11:17:10.365736  3537 layer_factory.hpp:77] Creating layer elu_conv29
I0930 11:17:10.365738  3537 net.cpp:84] Creating Layer elu_conv29
I0930 11:17:10.365741  3537 net.cpp:406] elu_conv29 <- Eltwise14
I0930 11:17:10.365751  3537 net.cpp:367] elu_conv29 -> Eltwise14 (in-place)
I0930 11:17:10.365754  3537 net.cpp:122] Setting up elu_conv29
I0930 11:17:10.365757  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.365759  3537 net.cpp:137] Memory required for data: 872858800
I0930 11:17:10.365762  3537 layer_factory.hpp:77] Creating layer Eltwise14_elu_conv29_0_split
I0930 11:17:10.365766  3537 net.cpp:84] Creating Layer Eltwise14_elu_conv29_0_split
I0930 11:17:10.365767  3537 net.cpp:406] Eltwise14_elu_conv29_0_split <- Eltwise14
I0930 11:17:10.365770  3537 net.cpp:380] Eltwise14_elu_conv29_0_split -> Eltwise14_elu_conv29_0_split_0
I0930 11:17:10.365774  3537 net.cpp:380] Eltwise14_elu_conv29_0_split -> Eltwise14_elu_conv29_0_split_1
I0930 11:17:10.365803  3537 net.cpp:122] Setting up Eltwise14_elu_conv29_0_split
I0930 11:17:10.365808  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.365809  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.365811  3537 net.cpp:137] Memory required for data: 879412400
I0930 11:17:10.365814  3537 layer_factory.hpp:77] Creating layer Convolution31
I0930 11:17:10.365820  3537 net.cpp:84] Creating Layer Convolution31
I0930 11:17:10.365823  3537 net.cpp:406] Convolution31 <- Eltwise14_elu_conv29_0_split_0
I0930 11:17:10.365826  3537 net.cpp:380] Convolution31 -> Convolution31
I0930 11:17:10.366963  3537 net.cpp:122] Setting up Convolution31
I0930 11:17:10.366972  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.366974  3537 net.cpp:137] Memory required for data: 882689200
I0930 11:17:10.366979  3537 layer_factory.hpp:77] Creating layer BatchNorm31
I0930 11:17:10.366984  3537 net.cpp:84] Creating Layer BatchNorm31
I0930 11:17:10.366987  3537 net.cpp:406] BatchNorm31 <- Convolution31
I0930 11:17:10.366991  3537 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0930 11:17:10.367148  3537 net.cpp:122] Setting up BatchNorm31
I0930 11:17:10.367153  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.367156  3537 net.cpp:137] Memory required for data: 885966000
I0930 11:17:10.367161  3537 layer_factory.hpp:77] Creating layer Scale31
I0930 11:17:10.367164  3537 net.cpp:84] Creating Layer Scale31
I0930 11:17:10.367167  3537 net.cpp:406] Scale31 <- Convolution31
I0930 11:17:10.367172  3537 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0930 11:17:10.367203  3537 layer_factory.hpp:77] Creating layer Scale31
I0930 11:17:10.367295  3537 net.cpp:122] Setting up Scale31
I0930 11:17:10.367300  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.367301  3537 net.cpp:137] Memory required for data: 889242800
I0930 11:17:10.367305  3537 layer_factory.hpp:77] Creating layer elu_conv30
I0930 11:17:10.367310  3537 net.cpp:84] Creating Layer elu_conv30
I0930 11:17:10.367311  3537 net.cpp:406] elu_conv30 <- Convolution31
I0930 11:17:10.367314  3537 net.cpp:367] elu_conv30 -> Convolution31 (in-place)
I0930 11:17:10.367318  3537 net.cpp:122] Setting up elu_conv30
I0930 11:17:10.367321  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.367323  3537 net.cpp:137] Memory required for data: 892519600
I0930 11:17:10.367326  3537 layer_factory.hpp:77] Creating layer Convolution32
I0930 11:17:10.367332  3537 net.cpp:84] Creating Layer Convolution32
I0930 11:17:10.367334  3537 net.cpp:406] Convolution32 <- Convolution31
I0930 11:17:10.388326  3537 net.cpp:380] Convolution32 -> Convolution32
I0930 11:17:10.389575  3537 net.cpp:122] Setting up Convolution32
I0930 11:17:10.389585  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.389587  3537 net.cpp:137] Memory required for data: 895796400
I0930 11:17:10.389592  3537 layer_factory.hpp:77] Creating layer BatchNorm32
I0930 11:17:10.389596  3537 net.cpp:84] Creating Layer BatchNorm32
I0930 11:17:10.389600  3537 net.cpp:406] BatchNorm32 <- Convolution32
I0930 11:17:10.389605  3537 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I0930 11:17:10.389784  3537 net.cpp:122] Setting up BatchNorm32
I0930 11:17:10.389789  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.389798  3537 net.cpp:137] Memory required for data: 899073200
I0930 11:17:10.389803  3537 layer_factory.hpp:77] Creating layer Scale32
I0930 11:17:10.389808  3537 net.cpp:84] Creating Layer Scale32
I0930 11:17:10.389811  3537 net.cpp:406] Scale32 <- Convolution32
I0930 11:17:10.389814  3537 net.cpp:367] Scale32 -> Convolution32 (in-place)
I0930 11:17:10.389849  3537 layer_factory.hpp:77] Creating layer Scale32
I0930 11:17:10.389963  3537 net.cpp:122] Setting up Scale32
I0930 11:17:10.389967  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.389971  3537 net.cpp:137] Memory required for data: 902350000
I0930 11:17:10.389973  3537 layer_factory.hpp:77] Creating layer Eltwise15
I0930 11:17:10.389978  3537 net.cpp:84] Creating Layer Eltwise15
I0930 11:17:10.389992  3537 net.cpp:406] Eltwise15 <- Eltwise14_elu_conv29_0_split_1
I0930 11:17:10.389995  3537 net.cpp:406] Eltwise15 <- Convolution32
I0930 11:17:10.389998  3537 net.cpp:380] Eltwise15 -> Eltwise15
I0930 11:17:10.390024  3537 net.cpp:122] Setting up Eltwise15
I0930 11:17:10.390028  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.390030  3537 net.cpp:137] Memory required for data: 905626800
I0930 11:17:10.390033  3537 layer_factory.hpp:77] Creating layer elu_conv31
I0930 11:17:10.390036  3537 net.cpp:84] Creating Layer elu_conv31
I0930 11:17:10.390039  3537 net.cpp:406] elu_conv31 <- Eltwise15
I0930 11:17:10.390043  3537 net.cpp:367] elu_conv31 -> Eltwise15 (in-place)
I0930 11:17:10.390055  3537 net.cpp:122] Setting up elu_conv31
I0930 11:17:10.390058  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.390061  3537 net.cpp:137] Memory required for data: 908903600
I0930 11:17:10.390064  3537 layer_factory.hpp:77] Creating layer Eltwise15_elu_conv31_0_split
I0930 11:17:10.390067  3537 net.cpp:84] Creating Layer Eltwise15_elu_conv31_0_split
I0930 11:17:10.390069  3537 net.cpp:406] Eltwise15_elu_conv31_0_split <- Eltwise15
I0930 11:17:10.390074  3537 net.cpp:380] Eltwise15_elu_conv31_0_split -> Eltwise15_elu_conv31_0_split_0
I0930 11:17:10.390077  3537 net.cpp:380] Eltwise15_elu_conv31_0_split -> Eltwise15_elu_conv31_0_split_1
I0930 11:17:10.390106  3537 net.cpp:122] Setting up Eltwise15_elu_conv31_0_split
I0930 11:17:10.390110  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.390113  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.390115  3537 net.cpp:137] Memory required for data: 915457200
I0930 11:17:10.390117  3537 layer_factory.hpp:77] Creating layer Convolution33
I0930 11:17:10.390125  3537 net.cpp:84] Creating Layer Convolution33
I0930 11:17:10.390127  3537 net.cpp:406] Convolution33 <- Eltwise15_elu_conv31_0_split_0
I0930 11:17:10.390131  3537 net.cpp:380] Convolution33 -> Convolution33
I0930 11:17:10.391510  3537 net.cpp:122] Setting up Convolution33
I0930 11:17:10.391518  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.391521  3537 net.cpp:137] Memory required for data: 918734000
I0930 11:17:10.391525  3537 layer_factory.hpp:77] Creating layer BatchNorm33
I0930 11:17:10.391530  3537 net.cpp:84] Creating Layer BatchNorm33
I0930 11:17:10.391532  3537 net.cpp:406] BatchNorm33 <- Convolution33
I0930 11:17:10.391537  3537 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I0930 11:17:10.391692  3537 net.cpp:122] Setting up BatchNorm33
I0930 11:17:10.391696  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.391698  3537 net.cpp:137] Memory required for data: 922010800
I0930 11:17:10.391703  3537 layer_factory.hpp:77] Creating layer Scale33
I0930 11:17:10.391707  3537 net.cpp:84] Creating Layer Scale33
I0930 11:17:10.391710  3537 net.cpp:406] Scale33 <- Convolution33
I0930 11:17:10.391713  3537 net.cpp:367] Scale33 -> Convolution33 (in-place)
I0930 11:17:10.391744  3537 layer_factory.hpp:77] Creating layer Scale33
I0930 11:17:10.391832  3537 net.cpp:122] Setting up Scale33
I0930 11:17:10.391836  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.391839  3537 net.cpp:137] Memory required for data: 925287600
I0930 11:17:10.391849  3537 layer_factory.hpp:77] Creating layer elu_conv32
I0930 11:17:10.391855  3537 net.cpp:84] Creating Layer elu_conv32
I0930 11:17:10.391857  3537 net.cpp:406] elu_conv32 <- Convolution33
I0930 11:17:10.391860  3537 net.cpp:367] elu_conv32 -> Convolution33 (in-place)
I0930 11:17:10.391865  3537 net.cpp:122] Setting up elu_conv32
I0930 11:17:10.391867  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.391870  3537 net.cpp:137] Memory required for data: 928564400
I0930 11:17:10.391871  3537 layer_factory.hpp:77] Creating layer Convolution34
I0930 11:17:10.391878  3537 net.cpp:84] Creating Layer Convolution34
I0930 11:17:10.391880  3537 net.cpp:406] Convolution34 <- Convolution33
I0930 11:17:10.391885  3537 net.cpp:380] Convolution34 -> Convolution34
I0930 11:17:10.393206  3537 net.cpp:122] Setting up Convolution34
I0930 11:17:10.393215  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.393218  3537 net.cpp:137] Memory required for data: 931841200
I0930 11:17:10.393224  3537 layer_factory.hpp:77] Creating layer BatchNorm34
I0930 11:17:10.393227  3537 net.cpp:84] Creating Layer BatchNorm34
I0930 11:17:10.393230  3537 net.cpp:406] BatchNorm34 <- Convolution34
I0930 11:17:10.393234  3537 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I0930 11:17:10.393391  3537 net.cpp:122] Setting up BatchNorm34
I0930 11:17:10.393396  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.393399  3537 net.cpp:137] Memory required for data: 935118000
I0930 11:17:10.393402  3537 layer_factory.hpp:77] Creating layer Scale34
I0930 11:17:10.393406  3537 net.cpp:84] Creating Layer Scale34
I0930 11:17:10.393409  3537 net.cpp:406] Scale34 <- Convolution34
I0930 11:17:10.393412  3537 net.cpp:367] Scale34 -> Convolution34 (in-place)
I0930 11:17:10.393445  3537 layer_factory.hpp:77] Creating layer Scale34
I0930 11:17:10.393535  3537 net.cpp:122] Setting up Scale34
I0930 11:17:10.393540  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.393543  3537 net.cpp:137] Memory required for data: 938394800
I0930 11:17:10.393546  3537 layer_factory.hpp:77] Creating layer Eltwise16
I0930 11:17:10.393549  3537 net.cpp:84] Creating Layer Eltwise16
I0930 11:17:10.393553  3537 net.cpp:406] Eltwise16 <- Eltwise15_elu_conv31_0_split_1
I0930 11:17:10.393555  3537 net.cpp:406] Eltwise16 <- Convolution34
I0930 11:17:10.393559  3537 net.cpp:380] Eltwise16 -> Eltwise16
I0930 11:17:10.393574  3537 net.cpp:122] Setting up Eltwise16
I0930 11:17:10.393579  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.393580  3537 net.cpp:137] Memory required for data: 941671600
I0930 11:17:10.393582  3537 layer_factory.hpp:77] Creating layer elu_conv33
I0930 11:17:10.393585  3537 net.cpp:84] Creating Layer elu_conv33
I0930 11:17:10.393587  3537 net.cpp:406] elu_conv33 <- Eltwise16
I0930 11:17:10.393592  3537 net.cpp:367] elu_conv33 -> Eltwise16 (in-place)
I0930 11:17:10.393595  3537 net.cpp:122] Setting up elu_conv33
I0930 11:17:10.393599  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.393600  3537 net.cpp:137] Memory required for data: 944948400
I0930 11:17:10.393602  3537 layer_factory.hpp:77] Creating layer Eltwise16_elu_conv33_0_split
I0930 11:17:10.393606  3537 net.cpp:84] Creating Layer Eltwise16_elu_conv33_0_split
I0930 11:17:10.393609  3537 net.cpp:406] Eltwise16_elu_conv33_0_split <- Eltwise16
I0930 11:17:10.393611  3537 net.cpp:380] Eltwise16_elu_conv33_0_split -> Eltwise16_elu_conv33_0_split_0
I0930 11:17:10.393615  3537 net.cpp:380] Eltwise16_elu_conv33_0_split -> Eltwise16_elu_conv33_0_split_1
I0930 11:17:10.393642  3537 net.cpp:122] Setting up Eltwise16_elu_conv33_0_split
I0930 11:17:10.393646  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.393649  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.393651  3537 net.cpp:137] Memory required for data: 951502000
I0930 11:17:10.393653  3537 layer_factory.hpp:77] Creating layer Convolution35
I0930 11:17:10.393659  3537 net.cpp:84] Creating Layer Convolution35
I0930 11:17:10.393661  3537 net.cpp:406] Convolution35 <- Eltwise16_elu_conv33_0_split_0
I0930 11:17:10.393672  3537 net.cpp:380] Convolution35 -> Convolution35
I0930 11:17:10.394809  3537 net.cpp:122] Setting up Convolution35
I0930 11:17:10.394819  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.394822  3537 net.cpp:137] Memory required for data: 954778800
I0930 11:17:10.394826  3537 layer_factory.hpp:77] Creating layer BatchNorm35
I0930 11:17:10.394831  3537 net.cpp:84] Creating Layer BatchNorm35
I0930 11:17:10.394834  3537 net.cpp:406] BatchNorm35 <- Convolution35
I0930 11:17:10.394839  3537 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I0930 11:17:10.394997  3537 net.cpp:122] Setting up BatchNorm35
I0930 11:17:10.395001  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.395004  3537 net.cpp:137] Memory required for data: 958055600
I0930 11:17:10.395009  3537 layer_factory.hpp:77] Creating layer Scale35
I0930 11:17:10.395012  3537 net.cpp:84] Creating Layer Scale35
I0930 11:17:10.395015  3537 net.cpp:406] Scale35 <- Convolution35
I0930 11:17:10.395018  3537 net.cpp:367] Scale35 -> Convolution35 (in-place)
I0930 11:17:10.395050  3537 layer_factory.hpp:77] Creating layer Scale35
I0930 11:17:10.395140  3537 net.cpp:122] Setting up Scale35
I0930 11:17:10.395144  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.395146  3537 net.cpp:137] Memory required for data: 961332400
I0930 11:17:10.395150  3537 layer_factory.hpp:77] Creating layer elu_conv34
I0930 11:17:10.395153  3537 net.cpp:84] Creating Layer elu_conv34
I0930 11:17:10.395156  3537 net.cpp:406] elu_conv34 <- Convolution35
I0930 11:17:10.395159  3537 net.cpp:367] elu_conv34 -> Convolution35 (in-place)
I0930 11:17:10.395164  3537 net.cpp:122] Setting up elu_conv34
I0930 11:17:10.395166  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.395169  3537 net.cpp:137] Memory required for data: 964609200
I0930 11:17:10.395171  3537 layer_factory.hpp:77] Creating layer Convolution36
I0930 11:17:10.395177  3537 net.cpp:84] Creating Layer Convolution36
I0930 11:17:10.395179  3537 net.cpp:406] Convolution36 <- Convolution35
I0930 11:17:10.395184  3537 net.cpp:380] Convolution36 -> Convolution36
I0930 11:17:10.395951  3537 net.cpp:122] Setting up Convolution36
I0930 11:17:10.395958  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.395961  3537 net.cpp:137] Memory required for data: 967886000
I0930 11:17:10.395964  3537 layer_factory.hpp:77] Creating layer BatchNorm36
I0930 11:17:10.395969  3537 net.cpp:84] Creating Layer BatchNorm36
I0930 11:17:10.395972  3537 net.cpp:406] BatchNorm36 <- Convolution36
I0930 11:17:10.395977  3537 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I0930 11:17:10.396131  3537 net.cpp:122] Setting up BatchNorm36
I0930 11:17:10.396136  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.396138  3537 net.cpp:137] Memory required for data: 971162800
I0930 11:17:10.396142  3537 layer_factory.hpp:77] Creating layer Scale36
I0930 11:17:10.396147  3537 net.cpp:84] Creating Layer Scale36
I0930 11:17:10.396149  3537 net.cpp:406] Scale36 <- Convolution36
I0930 11:17:10.396152  3537 net.cpp:367] Scale36 -> Convolution36 (in-place)
I0930 11:17:10.396183  3537 layer_factory.hpp:77] Creating layer Scale36
I0930 11:17:10.396273  3537 net.cpp:122] Setting up Scale36
I0930 11:17:10.396278  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.396281  3537 net.cpp:137] Memory required for data: 974439600
I0930 11:17:10.396283  3537 layer_factory.hpp:77] Creating layer Eltwise17
I0930 11:17:10.396287  3537 net.cpp:84] Creating Layer Eltwise17
I0930 11:17:10.396291  3537 net.cpp:406] Eltwise17 <- Eltwise16_elu_conv33_0_split_1
I0930 11:17:10.396293  3537 net.cpp:406] Eltwise17 <- Convolution36
I0930 11:17:10.396297  3537 net.cpp:380] Eltwise17 -> Eltwise17
I0930 11:17:10.396311  3537 net.cpp:122] Setting up Eltwise17
I0930 11:17:10.396315  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.396317  3537 net.cpp:137] Memory required for data: 977716400
I0930 11:17:10.396325  3537 layer_factory.hpp:77] Creating layer elu_conv35
I0930 11:17:10.396330  3537 net.cpp:84] Creating Layer elu_conv35
I0930 11:17:10.396333  3537 net.cpp:406] elu_conv35 <- Eltwise17
I0930 11:17:10.396337  3537 net.cpp:367] elu_conv35 -> Eltwise17 (in-place)
I0930 11:17:10.396340  3537 net.cpp:122] Setting up elu_conv35
I0930 11:17:10.396343  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.396345  3537 net.cpp:137] Memory required for data: 980993200
I0930 11:17:10.396347  3537 layer_factory.hpp:77] Creating layer Eltwise17_elu_conv35_0_split
I0930 11:17:10.396350  3537 net.cpp:84] Creating Layer Eltwise17_elu_conv35_0_split
I0930 11:17:10.396353  3537 net.cpp:406] Eltwise17_elu_conv35_0_split <- Eltwise17
I0930 11:17:10.396356  3537 net.cpp:380] Eltwise17_elu_conv35_0_split -> Eltwise17_elu_conv35_0_split_0
I0930 11:17:10.396360  3537 net.cpp:380] Eltwise17_elu_conv35_0_split -> Eltwise17_elu_conv35_0_split_1
I0930 11:17:10.396389  3537 net.cpp:122] Setting up Eltwise17_elu_conv35_0_split
I0930 11:17:10.396392  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.396395  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.396397  3537 net.cpp:137] Memory required for data: 987546800
I0930 11:17:10.396399  3537 layer_factory.hpp:77] Creating layer Convolution37
I0930 11:17:10.396407  3537 net.cpp:84] Creating Layer Convolution37
I0930 11:17:10.396409  3537 net.cpp:406] Convolution37 <- Eltwise17_elu_conv35_0_split_0
I0930 11:17:10.396414  3537 net.cpp:380] Convolution37 -> Convolution37
I0930 11:17:10.397513  3537 net.cpp:122] Setting up Convolution37
I0930 11:17:10.397521  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.397524  3537 net.cpp:137] Memory required for data: 990823600
I0930 11:17:10.397528  3537 layer_factory.hpp:77] Creating layer BatchNorm37
I0930 11:17:10.397534  3537 net.cpp:84] Creating Layer BatchNorm37
I0930 11:17:10.397537  3537 net.cpp:406] BatchNorm37 <- Convolution37
I0930 11:17:10.397541  3537 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I0930 11:17:10.398169  3537 net.cpp:122] Setting up BatchNorm37
I0930 11:17:10.398177  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.398180  3537 net.cpp:137] Memory required for data: 994100400
I0930 11:17:10.398207  3537 layer_factory.hpp:77] Creating layer Scale37
I0930 11:17:10.398213  3537 net.cpp:84] Creating Layer Scale37
I0930 11:17:10.398216  3537 net.cpp:406] Scale37 <- Convolution37
I0930 11:17:10.398219  3537 net.cpp:367] Scale37 -> Convolution37 (in-place)
I0930 11:17:10.398247  3537 layer_factory.hpp:77] Creating layer Scale37
I0930 11:17:10.398317  3537 net.cpp:122] Setting up Scale37
I0930 11:17:10.398322  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.398324  3537 net.cpp:137] Memory required for data: 997377200
I0930 11:17:10.398329  3537 layer_factory.hpp:77] Creating layer elu_conv36
I0930 11:17:10.398332  3537 net.cpp:84] Creating Layer elu_conv36
I0930 11:17:10.398334  3537 net.cpp:406] elu_conv36 <- Convolution37
I0930 11:17:10.398337  3537 net.cpp:367] elu_conv36 -> Convolution37 (in-place)
I0930 11:17:10.421875  3537 net.cpp:122] Setting up elu_conv36
I0930 11:17:10.421888  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.421893  3537 net.cpp:137] Memory required for data: 1000654000
I0930 11:17:10.421897  3537 layer_factory.hpp:77] Creating layer Convolution38
I0930 11:17:10.421921  3537 net.cpp:84] Creating Layer Convolution38
I0930 11:17:10.421926  3537 net.cpp:406] Convolution38 <- Convolution37
I0930 11:17:10.421934  3537 net.cpp:380] Convolution38 -> Convolution38
I0930 11:17:10.423686  3537 net.cpp:122] Setting up Convolution38
I0930 11:17:10.423696  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.423699  3537 net.cpp:137] Memory required for data: 1003930800
I0930 11:17:10.423705  3537 layer_factory.hpp:77] Creating layer BatchNorm38
I0930 11:17:10.423720  3537 net.cpp:84] Creating Layer BatchNorm38
I0930 11:17:10.423723  3537 net.cpp:406] BatchNorm38 <- Convolution38
I0930 11:17:10.423745  3537 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I0930 11:17:10.423892  3537 net.cpp:122] Setting up BatchNorm38
I0930 11:17:10.423897  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.423898  3537 net.cpp:137] Memory required for data: 1007207600
I0930 11:17:10.423903  3537 layer_factory.hpp:77] Creating layer Scale38
I0930 11:17:10.423908  3537 net.cpp:84] Creating Layer Scale38
I0930 11:17:10.423912  3537 net.cpp:406] Scale38 <- Convolution38
I0930 11:17:10.423914  3537 net.cpp:367] Scale38 -> Convolution38 (in-place)
I0930 11:17:10.423944  3537 layer_factory.hpp:77] Creating layer Scale38
I0930 11:17:10.424016  3537 net.cpp:122] Setting up Scale38
I0930 11:17:10.424021  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.424022  3537 net.cpp:137] Memory required for data: 1010484400
I0930 11:17:10.424026  3537 layer_factory.hpp:77] Creating layer Eltwise18
I0930 11:17:10.424031  3537 net.cpp:84] Creating Layer Eltwise18
I0930 11:17:10.424036  3537 net.cpp:406] Eltwise18 <- Eltwise17_elu_conv35_0_split_1
I0930 11:17:10.424038  3537 net.cpp:406] Eltwise18 <- Convolution38
I0930 11:17:10.424042  3537 net.cpp:380] Eltwise18 -> Eltwise18
I0930 11:17:10.424053  3537 net.cpp:122] Setting up Eltwise18
I0930 11:17:10.424057  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.424059  3537 net.cpp:137] Memory required for data: 1013761200
I0930 11:17:10.424062  3537 layer_factory.hpp:77] Creating layer elu_conv37
I0930 11:17:10.424065  3537 net.cpp:84] Creating Layer elu_conv37
I0930 11:17:10.424067  3537 net.cpp:406] elu_conv37 <- Eltwise18
I0930 11:17:10.424070  3537 net.cpp:367] elu_conv37 -> Eltwise18 (in-place)
I0930 11:17:10.424074  3537 net.cpp:122] Setting up elu_conv37
I0930 11:17:10.424077  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.424079  3537 net.cpp:137] Memory required for data: 1017038000
I0930 11:17:10.424082  3537 layer_factory.hpp:77] Creating layer Eltwise18_elu_conv37_0_split
I0930 11:17:10.424085  3537 net.cpp:84] Creating Layer Eltwise18_elu_conv37_0_split
I0930 11:17:10.424088  3537 net.cpp:406] Eltwise18_elu_conv37_0_split <- Eltwise18
I0930 11:17:10.424090  3537 net.cpp:380] Eltwise18_elu_conv37_0_split -> Eltwise18_elu_conv37_0_split_0
I0930 11:17:10.424094  3537 net.cpp:380] Eltwise18_elu_conv37_0_split -> Eltwise18_elu_conv37_0_split_1
I0930 11:17:10.424115  3537 net.cpp:122] Setting up Eltwise18_elu_conv37_0_split
I0930 11:17:10.424119  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.424123  3537 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 11:17:10.424124  3537 net.cpp:137] Memory required for data: 1023591600
I0930 11:17:10.424126  3537 layer_factory.hpp:77] Creating layer Convolution39
I0930 11:17:10.424132  3537 net.cpp:84] Creating Layer Convolution39
I0930 11:17:10.424135  3537 net.cpp:406] Convolution39 <- Eltwise18_elu_conv37_0_split_0
I0930 11:17:10.424140  3537 net.cpp:380] Convolution39 -> Convolution39
I0930 11:17:10.425112  3537 net.cpp:122] Setting up Convolution39
I0930 11:17:10.425123  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.425127  3537 net.cpp:137] Memory required for data: 1025230000
I0930 11:17:10.425132  3537 layer_factory.hpp:77] Creating layer BatchNorm39
I0930 11:17:10.425137  3537 net.cpp:84] Creating Layer BatchNorm39
I0930 11:17:10.425139  3537 net.cpp:406] BatchNorm39 <- Convolution39
I0930 11:17:10.425144  3537 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I0930 11:17:10.425282  3537 net.cpp:122] Setting up BatchNorm39
I0930 11:17:10.425287  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.425289  3537 net.cpp:137] Memory required for data: 1026868400
I0930 11:17:10.425294  3537 layer_factory.hpp:77] Creating layer Scale39
I0930 11:17:10.425298  3537 net.cpp:84] Creating Layer Scale39
I0930 11:17:10.425302  3537 net.cpp:406] Scale39 <- Convolution39
I0930 11:17:10.425305  3537 net.cpp:367] Scale39 -> Convolution39 (in-place)
I0930 11:17:10.425333  3537 layer_factory.hpp:77] Creating layer Scale39
I0930 11:17:10.425420  3537 net.cpp:122] Setting up Scale39
I0930 11:17:10.425426  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.425428  3537 net.cpp:137] Memory required for data: 1028506800
I0930 11:17:10.425432  3537 layer_factory.hpp:77] Creating layer Convolution40
I0930 11:17:10.425439  3537 net.cpp:84] Creating Layer Convolution40
I0930 11:17:10.425442  3537 net.cpp:406] Convolution40 <- Eltwise18_elu_conv37_0_split_1
I0930 11:17:10.425448  3537 net.cpp:380] Convolution40 -> Convolution40
I0930 11:17:10.426776  3537 net.cpp:122] Setting up Convolution40
I0930 11:17:10.426785  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.426789  3537 net.cpp:137] Memory required for data: 1030145200
I0930 11:17:10.426792  3537 layer_factory.hpp:77] Creating layer BatchNorm40
I0930 11:17:10.426798  3537 net.cpp:84] Creating Layer BatchNorm40
I0930 11:17:10.426800  3537 net.cpp:406] BatchNorm40 <- Convolution40
I0930 11:17:10.426805  3537 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I0930 11:17:10.426931  3537 net.cpp:122] Setting up BatchNorm40
I0930 11:17:10.426936  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.426939  3537 net.cpp:137] Memory required for data: 1031783600
I0930 11:17:10.426944  3537 layer_factory.hpp:77] Creating layer Scale40
I0930 11:17:10.426947  3537 net.cpp:84] Creating Layer Scale40
I0930 11:17:10.426949  3537 net.cpp:406] Scale40 <- Convolution40
I0930 11:17:10.426954  3537 net.cpp:367] Scale40 -> Convolution40 (in-place)
I0930 11:17:10.426978  3537 layer_factory.hpp:77] Creating layer Scale40
I0930 11:17:10.427050  3537 net.cpp:122] Setting up Scale40
I0930 11:17:10.427054  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.427057  3537 net.cpp:137] Memory required for data: 1033422000
I0930 11:17:10.427060  3537 layer_factory.hpp:77] Creating layer elu_conv38
I0930 11:17:10.427063  3537 net.cpp:84] Creating Layer elu_conv38
I0930 11:17:10.427067  3537 net.cpp:406] elu_conv38 <- Convolution40
I0930 11:17:10.427069  3537 net.cpp:367] elu_conv38 -> Convolution40 (in-place)
I0930 11:17:10.427073  3537 net.cpp:122] Setting up elu_conv38
I0930 11:17:10.427076  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.427078  3537 net.cpp:137] Memory required for data: 1035060400
I0930 11:17:10.427081  3537 layer_factory.hpp:77] Creating layer Convolution41
I0930 11:17:10.427088  3537 net.cpp:84] Creating Layer Convolution41
I0930 11:17:10.427090  3537 net.cpp:406] Convolution41 <- Convolution40
I0930 11:17:10.427093  3537 net.cpp:380] Convolution41 -> Convolution41
I0930 11:17:10.428755  3537 net.cpp:122] Setting up Convolution41
I0930 11:17:10.428764  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.428766  3537 net.cpp:137] Memory required for data: 1036698800
I0930 11:17:10.428771  3537 layer_factory.hpp:77] Creating layer BatchNorm41
I0930 11:17:10.428776  3537 net.cpp:84] Creating Layer BatchNorm41
I0930 11:17:10.428779  3537 net.cpp:406] BatchNorm41 <- Convolution41
I0930 11:17:10.428783  3537 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I0930 11:17:10.428907  3537 net.cpp:122] Setting up BatchNorm41
I0930 11:17:10.428911  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.428915  3537 net.cpp:137] Memory required for data: 1038337200
I0930 11:17:10.428918  3537 layer_factory.hpp:77] Creating layer Scale41
I0930 11:17:10.428922  3537 net.cpp:84] Creating Layer Scale41
I0930 11:17:10.428925  3537 net.cpp:406] Scale41 <- Convolution41
I0930 11:17:10.428928  3537 net.cpp:367] Scale41 -> Convolution41 (in-place)
I0930 11:17:10.428954  3537 layer_factory.hpp:77] Creating layer Scale41
I0930 11:17:10.429024  3537 net.cpp:122] Setting up Scale41
I0930 11:17:10.429028  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.429030  3537 net.cpp:137] Memory required for data: 1039975600
I0930 11:17:10.429034  3537 layer_factory.hpp:77] Creating layer Eltwise19
I0930 11:17:10.429039  3537 net.cpp:84] Creating Layer Eltwise19
I0930 11:17:10.429041  3537 net.cpp:406] Eltwise19 <- Convolution39
I0930 11:17:10.429050  3537 net.cpp:406] Eltwise19 <- Convolution41
I0930 11:17:10.429054  3537 net.cpp:380] Eltwise19 -> Eltwise19
I0930 11:17:10.429070  3537 net.cpp:122] Setting up Eltwise19
I0930 11:17:10.429075  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.429076  3537 net.cpp:137] Memory required for data: 1041614000
I0930 11:17:10.429078  3537 layer_factory.hpp:77] Creating layer elu_conv39
I0930 11:17:10.429082  3537 net.cpp:84] Creating Layer elu_conv39
I0930 11:17:10.429085  3537 net.cpp:406] elu_conv39 <- Eltwise19
I0930 11:17:10.429088  3537 net.cpp:367] elu_conv39 -> Eltwise19 (in-place)
I0930 11:17:10.429091  3537 net.cpp:122] Setting up elu_conv39
I0930 11:17:10.429095  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.429097  3537 net.cpp:137] Memory required for data: 1043252400
I0930 11:17:10.429100  3537 layer_factory.hpp:77] Creating layer Eltwise19_elu_conv39_0_split
I0930 11:17:10.429102  3537 net.cpp:84] Creating Layer Eltwise19_elu_conv39_0_split
I0930 11:17:10.429105  3537 net.cpp:406] Eltwise19_elu_conv39_0_split <- Eltwise19
I0930 11:17:10.429107  3537 net.cpp:380] Eltwise19_elu_conv39_0_split -> Eltwise19_elu_conv39_0_split_0
I0930 11:17:10.429111  3537 net.cpp:380] Eltwise19_elu_conv39_0_split -> Eltwise19_elu_conv39_0_split_1
I0930 11:17:10.429133  3537 net.cpp:122] Setting up Eltwise19_elu_conv39_0_split
I0930 11:17:10.429136  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.429139  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.429141  3537 net.cpp:137] Memory required for data: 1046529200
I0930 11:17:10.429143  3537 layer_factory.hpp:77] Creating layer Convolution42
I0930 11:17:10.429149  3537 net.cpp:84] Creating Layer Convolution42
I0930 11:17:10.429152  3537 net.cpp:406] Convolution42 <- Eltwise19_elu_conv39_0_split_0
I0930 11:17:10.429157  3537 net.cpp:380] Convolution42 -> Convolution42
I0930 11:17:10.430831  3537 net.cpp:122] Setting up Convolution42
I0930 11:17:10.430840  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.430843  3537 net.cpp:137] Memory required for data: 1048167600
I0930 11:17:10.430847  3537 layer_factory.hpp:77] Creating layer BatchNorm42
I0930 11:17:10.430852  3537 net.cpp:84] Creating Layer BatchNorm42
I0930 11:17:10.430855  3537 net.cpp:406] BatchNorm42 <- Convolution42
I0930 11:17:10.430860  3537 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I0930 11:17:10.430984  3537 net.cpp:122] Setting up BatchNorm42
I0930 11:17:10.430987  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.430989  3537 net.cpp:137] Memory required for data: 1049806000
I0930 11:17:10.430994  3537 layer_factory.hpp:77] Creating layer Scale42
I0930 11:17:10.430999  3537 net.cpp:84] Creating Layer Scale42
I0930 11:17:10.431000  3537 net.cpp:406] Scale42 <- Convolution42
I0930 11:17:10.431005  3537 net.cpp:367] Scale42 -> Convolution42 (in-place)
I0930 11:17:10.431030  3537 layer_factory.hpp:77] Creating layer Scale42
I0930 11:17:10.431102  3537 net.cpp:122] Setting up Scale42
I0930 11:17:10.431107  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.431108  3537 net.cpp:137] Memory required for data: 1051444400
I0930 11:17:10.431113  3537 layer_factory.hpp:77] Creating layer elu_conv40
I0930 11:17:10.431115  3537 net.cpp:84] Creating Layer elu_conv40
I0930 11:17:10.431118  3537 net.cpp:406] elu_conv40 <- Convolution42
I0930 11:17:10.431121  3537 net.cpp:367] elu_conv40 -> Convolution42 (in-place)
I0930 11:17:10.431125  3537 net.cpp:122] Setting up elu_conv40
I0930 11:17:10.431128  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.431130  3537 net.cpp:137] Memory required for data: 1053082800
I0930 11:17:10.431133  3537 layer_factory.hpp:77] Creating layer Convolution43
I0930 11:17:10.431139  3537 net.cpp:84] Creating Layer Convolution43
I0930 11:17:10.431141  3537 net.cpp:406] Convolution43 <- Convolution42
I0930 11:17:10.431145  3537 net.cpp:380] Convolution43 -> Convolution43
I0930 11:17:10.432803  3537 net.cpp:122] Setting up Convolution43
I0930 11:17:10.432812  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.432821  3537 net.cpp:137] Memory required for data: 1054721200
I0930 11:17:10.432826  3537 layer_factory.hpp:77] Creating layer BatchNorm43
I0930 11:17:10.432832  3537 net.cpp:84] Creating Layer BatchNorm43
I0930 11:17:10.432834  3537 net.cpp:406] BatchNorm43 <- Convolution43
I0930 11:17:10.432838  3537 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I0930 11:17:10.432965  3537 net.cpp:122] Setting up BatchNorm43
I0930 11:17:10.432968  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.432971  3537 net.cpp:137] Memory required for data: 1056359600
I0930 11:17:10.432976  3537 layer_factory.hpp:77] Creating layer Scale43
I0930 11:17:10.432979  3537 net.cpp:84] Creating Layer Scale43
I0930 11:17:10.432981  3537 net.cpp:406] Scale43 <- Convolution43
I0930 11:17:10.432984  3537 net.cpp:367] Scale43 -> Convolution43 (in-place)
I0930 11:17:10.433010  3537 layer_factory.hpp:77] Creating layer Scale43
I0930 11:17:10.433084  3537 net.cpp:122] Setting up Scale43
I0930 11:17:10.433089  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.433090  3537 net.cpp:137] Memory required for data: 1057998000
I0930 11:17:10.433094  3537 layer_factory.hpp:77] Creating layer Eltwise20
I0930 11:17:10.433099  3537 net.cpp:84] Creating Layer Eltwise20
I0930 11:17:10.433101  3537 net.cpp:406] Eltwise20 <- Eltwise19_elu_conv39_0_split_1
I0930 11:17:10.433104  3537 net.cpp:406] Eltwise20 <- Convolution43
I0930 11:17:10.433107  3537 net.cpp:380] Eltwise20 -> Eltwise20
I0930 11:17:10.433123  3537 net.cpp:122] Setting up Eltwise20
I0930 11:17:10.433126  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.433128  3537 net.cpp:137] Memory required for data: 1059636400
I0930 11:17:10.433130  3537 layer_factory.hpp:77] Creating layer elu_conv41
I0930 11:17:10.433135  3537 net.cpp:84] Creating Layer elu_conv41
I0930 11:17:10.433136  3537 net.cpp:406] elu_conv41 <- Eltwise20
I0930 11:17:10.433140  3537 net.cpp:367] elu_conv41 -> Eltwise20 (in-place)
I0930 11:17:10.433143  3537 net.cpp:122] Setting up elu_conv41
I0930 11:17:10.433146  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.433148  3537 net.cpp:137] Memory required for data: 1061274800
I0930 11:17:10.433151  3537 layer_factory.hpp:77] Creating layer Eltwise20_elu_conv41_0_split
I0930 11:17:10.433153  3537 net.cpp:84] Creating Layer Eltwise20_elu_conv41_0_split
I0930 11:17:10.433156  3537 net.cpp:406] Eltwise20_elu_conv41_0_split <- Eltwise20
I0930 11:17:10.433158  3537 net.cpp:380] Eltwise20_elu_conv41_0_split -> Eltwise20_elu_conv41_0_split_0
I0930 11:17:10.433162  3537 net.cpp:380] Eltwise20_elu_conv41_0_split -> Eltwise20_elu_conv41_0_split_1
I0930 11:17:10.433184  3537 net.cpp:122] Setting up Eltwise20_elu_conv41_0_split
I0930 11:17:10.433187  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.433190  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.450027  3537 net.cpp:137] Memory required for data: 1064551600
I0930 11:17:10.450036  3537 layer_factory.hpp:77] Creating layer Convolution44
I0930 11:17:10.450047  3537 net.cpp:84] Creating Layer Convolution44
I0930 11:17:10.450052  3537 net.cpp:406] Convolution44 <- Eltwise20_elu_conv41_0_split_0
I0930 11:17:10.450057  3537 net.cpp:380] Convolution44 -> Convolution44
I0930 11:17:10.452311  3537 net.cpp:122] Setting up Convolution44
I0930 11:17:10.452322  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.452323  3537 net.cpp:137] Memory required for data: 1066190000
I0930 11:17:10.452329  3537 layer_factory.hpp:77] Creating layer BatchNorm44
I0930 11:17:10.452343  3537 net.cpp:84] Creating Layer BatchNorm44
I0930 11:17:10.452347  3537 net.cpp:406] BatchNorm44 <- Convolution44
I0930 11:17:10.452350  3537 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I0930 11:17:10.452504  3537 net.cpp:122] Setting up BatchNorm44
I0930 11:17:10.452508  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.452512  3537 net.cpp:137] Memory required for data: 1067828400
I0930 11:17:10.452515  3537 layer_factory.hpp:77] Creating layer Scale44
I0930 11:17:10.452527  3537 net.cpp:84] Creating Layer Scale44
I0930 11:17:10.452540  3537 net.cpp:406] Scale44 <- Convolution44
I0930 11:17:10.452544  3537 net.cpp:367] Scale44 -> Convolution44 (in-place)
I0930 11:17:10.452586  3537 layer_factory.hpp:77] Creating layer Scale44
I0930 11:17:10.452680  3537 net.cpp:122] Setting up Scale44
I0930 11:17:10.452687  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.452688  3537 net.cpp:137] Memory required for data: 1069466800
I0930 11:17:10.452692  3537 layer_factory.hpp:77] Creating layer elu_conv42
I0930 11:17:10.452697  3537 net.cpp:84] Creating Layer elu_conv42
I0930 11:17:10.452699  3537 net.cpp:406] elu_conv42 <- Convolution44
I0930 11:17:10.452702  3537 net.cpp:367] elu_conv42 -> Convolution44 (in-place)
I0930 11:17:10.452706  3537 net.cpp:122] Setting up elu_conv42
I0930 11:17:10.452709  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.452711  3537 net.cpp:137] Memory required for data: 1071105200
I0930 11:17:10.452713  3537 layer_factory.hpp:77] Creating layer Convolution45
I0930 11:17:10.452720  3537 net.cpp:84] Creating Layer Convolution45
I0930 11:17:10.452723  3537 net.cpp:406] Convolution45 <- Convolution44
I0930 11:17:10.452728  3537 net.cpp:380] Convolution45 -> Convolution45
I0930 11:17:10.454668  3537 net.cpp:122] Setting up Convolution45
I0930 11:17:10.454677  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.454680  3537 net.cpp:137] Memory required for data: 1072743600
I0930 11:17:10.454685  3537 layer_factory.hpp:77] Creating layer BatchNorm45
I0930 11:17:10.454692  3537 net.cpp:84] Creating Layer BatchNorm45
I0930 11:17:10.454695  3537 net.cpp:406] BatchNorm45 <- Convolution45
I0930 11:17:10.454699  3537 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I0930 11:17:10.454828  3537 net.cpp:122] Setting up BatchNorm45
I0930 11:17:10.454833  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.454834  3537 net.cpp:137] Memory required for data: 1074382000
I0930 11:17:10.454839  3537 layer_factory.hpp:77] Creating layer Scale45
I0930 11:17:10.454843  3537 net.cpp:84] Creating Layer Scale45
I0930 11:17:10.454846  3537 net.cpp:406] Scale45 <- Convolution45
I0930 11:17:10.454849  3537 net.cpp:367] Scale45 -> Convolution45 (in-place)
I0930 11:17:10.454875  3537 layer_factory.hpp:77] Creating layer Scale45
I0930 11:17:10.454948  3537 net.cpp:122] Setting up Scale45
I0930 11:17:10.454952  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.454955  3537 net.cpp:137] Memory required for data: 1076020400
I0930 11:17:10.454958  3537 layer_factory.hpp:77] Creating layer Eltwise21
I0930 11:17:10.454963  3537 net.cpp:84] Creating Layer Eltwise21
I0930 11:17:10.454967  3537 net.cpp:406] Eltwise21 <- Eltwise20_elu_conv41_0_split_1
I0930 11:17:10.454969  3537 net.cpp:406] Eltwise21 <- Convolution45
I0930 11:17:10.454972  3537 net.cpp:380] Eltwise21 -> Eltwise21
I0930 11:17:10.454988  3537 net.cpp:122] Setting up Eltwise21
I0930 11:17:10.454993  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.454994  3537 net.cpp:137] Memory required for data: 1077658800
I0930 11:17:10.454996  3537 layer_factory.hpp:77] Creating layer elu_conv43
I0930 11:17:10.454999  3537 net.cpp:84] Creating Layer elu_conv43
I0930 11:17:10.455003  3537 net.cpp:406] elu_conv43 <- Eltwise21
I0930 11:17:10.455005  3537 net.cpp:367] elu_conv43 -> Eltwise21 (in-place)
I0930 11:17:10.455009  3537 net.cpp:122] Setting up elu_conv43
I0930 11:17:10.455013  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.455014  3537 net.cpp:137] Memory required for data: 1079297200
I0930 11:17:10.455016  3537 layer_factory.hpp:77] Creating layer Eltwise21_elu_conv43_0_split
I0930 11:17:10.455020  3537 net.cpp:84] Creating Layer Eltwise21_elu_conv43_0_split
I0930 11:17:10.455023  3537 net.cpp:406] Eltwise21_elu_conv43_0_split <- Eltwise21
I0930 11:17:10.455025  3537 net.cpp:380] Eltwise21_elu_conv43_0_split -> Eltwise21_elu_conv43_0_split_0
I0930 11:17:10.455029  3537 net.cpp:380] Eltwise21_elu_conv43_0_split -> Eltwise21_elu_conv43_0_split_1
I0930 11:17:10.455061  3537 net.cpp:122] Setting up Eltwise21_elu_conv43_0_split
I0930 11:17:10.455065  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.455068  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.455070  3537 net.cpp:137] Memory required for data: 1082574000
I0930 11:17:10.455073  3537 layer_factory.hpp:77] Creating layer Convolution46
I0930 11:17:10.455080  3537 net.cpp:84] Creating Layer Convolution46
I0930 11:17:10.455081  3537 net.cpp:406] Convolution46 <- Eltwise21_elu_conv43_0_split_0
I0930 11:17:10.455087  3537 net.cpp:380] Convolution46 -> Convolution46
I0930 11:17:10.456743  3537 net.cpp:122] Setting up Convolution46
I0930 11:17:10.456753  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.456754  3537 net.cpp:137] Memory required for data: 1084212400
I0930 11:17:10.456759  3537 layer_factory.hpp:77] Creating layer BatchNorm46
I0930 11:17:10.456764  3537 net.cpp:84] Creating Layer BatchNorm46
I0930 11:17:10.456766  3537 net.cpp:406] BatchNorm46 <- Convolution46
I0930 11:17:10.456771  3537 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I0930 11:17:10.456902  3537 net.cpp:122] Setting up BatchNorm46
I0930 11:17:10.456905  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.456907  3537 net.cpp:137] Memory required for data: 1085850800
I0930 11:17:10.456912  3537 layer_factory.hpp:77] Creating layer Scale46
I0930 11:17:10.456917  3537 net.cpp:84] Creating Layer Scale46
I0930 11:17:10.456919  3537 net.cpp:406] Scale46 <- Convolution46
I0930 11:17:10.456923  3537 net.cpp:367] Scale46 -> Convolution46 (in-place)
I0930 11:17:10.456948  3537 layer_factory.hpp:77] Creating layer Scale46
I0930 11:17:10.457020  3537 net.cpp:122] Setting up Scale46
I0930 11:17:10.457026  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.457027  3537 net.cpp:137] Memory required for data: 1087489200
I0930 11:17:10.457031  3537 layer_factory.hpp:77] Creating layer elu_conv44
I0930 11:17:10.457034  3537 net.cpp:84] Creating Layer elu_conv44
I0930 11:17:10.457036  3537 net.cpp:406] elu_conv44 <- Convolution46
I0930 11:17:10.457039  3537 net.cpp:367] elu_conv44 -> Convolution46 (in-place)
I0930 11:17:10.457043  3537 net.cpp:122] Setting up elu_conv44
I0930 11:17:10.457046  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.457048  3537 net.cpp:137] Memory required for data: 1089127600
I0930 11:17:10.457051  3537 layer_factory.hpp:77] Creating layer Convolution47
I0930 11:17:10.457057  3537 net.cpp:84] Creating Layer Convolution47
I0930 11:17:10.457059  3537 net.cpp:406] Convolution47 <- Convolution46
I0930 11:17:10.457063  3537 net.cpp:380] Convolution47 -> Convolution47
I0930 11:17:10.458746  3537 net.cpp:122] Setting up Convolution47
I0930 11:17:10.458755  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.458758  3537 net.cpp:137] Memory required for data: 1090766000
I0930 11:17:10.458763  3537 layer_factory.hpp:77] Creating layer BatchNorm47
I0930 11:17:10.458768  3537 net.cpp:84] Creating Layer BatchNorm47
I0930 11:17:10.458771  3537 net.cpp:406] BatchNorm47 <- Convolution47
I0930 11:17:10.458775  3537 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I0930 11:17:10.458900  3537 net.cpp:122] Setting up BatchNorm47
I0930 11:17:10.458905  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.458907  3537 net.cpp:137] Memory required for data: 1092404400
I0930 11:17:10.458911  3537 layer_factory.hpp:77] Creating layer Scale47
I0930 11:17:10.458916  3537 net.cpp:84] Creating Layer Scale47
I0930 11:17:10.458920  3537 net.cpp:406] Scale47 <- Convolution47
I0930 11:17:10.458922  3537 net.cpp:367] Scale47 -> Convolution47 (in-place)
I0930 11:17:10.458947  3537 layer_factory.hpp:77] Creating layer Scale47
I0930 11:17:10.459020  3537 net.cpp:122] Setting up Scale47
I0930 11:17:10.459024  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.459026  3537 net.cpp:137] Memory required for data: 1094042800
I0930 11:17:10.459030  3537 layer_factory.hpp:77] Creating layer Eltwise22
I0930 11:17:10.459041  3537 net.cpp:84] Creating Layer Eltwise22
I0930 11:17:10.459044  3537 net.cpp:406] Eltwise22 <- Eltwise21_elu_conv43_0_split_1
I0930 11:17:10.459046  3537 net.cpp:406] Eltwise22 <- Convolution47
I0930 11:17:10.459050  3537 net.cpp:380] Eltwise22 -> Eltwise22
I0930 11:17:10.459066  3537 net.cpp:122] Setting up Eltwise22
I0930 11:17:10.459070  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.459072  3537 net.cpp:137] Memory required for data: 1095681200
I0930 11:17:10.459074  3537 layer_factory.hpp:77] Creating layer elu_conv45
I0930 11:17:10.459079  3537 net.cpp:84] Creating Layer elu_conv45
I0930 11:17:10.459081  3537 net.cpp:406] elu_conv45 <- Eltwise22
I0930 11:17:10.459084  3537 net.cpp:367] elu_conv45 -> Eltwise22 (in-place)
I0930 11:17:10.459087  3537 net.cpp:122] Setting up elu_conv45
I0930 11:17:10.459090  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.459092  3537 net.cpp:137] Memory required for data: 1097319600
I0930 11:17:10.459095  3537 layer_factory.hpp:77] Creating layer Eltwise22_elu_conv45_0_split
I0930 11:17:10.459098  3537 net.cpp:84] Creating Layer Eltwise22_elu_conv45_0_split
I0930 11:17:10.459100  3537 net.cpp:406] Eltwise22_elu_conv45_0_split <- Eltwise22
I0930 11:17:10.459103  3537 net.cpp:380] Eltwise22_elu_conv45_0_split -> Eltwise22_elu_conv45_0_split_0
I0930 11:17:10.459107  3537 net.cpp:380] Eltwise22_elu_conv45_0_split -> Eltwise22_elu_conv45_0_split_1
I0930 11:17:10.459128  3537 net.cpp:122] Setting up Eltwise22_elu_conv45_0_split
I0930 11:17:10.459132  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.459136  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.459137  3537 net.cpp:137] Memory required for data: 1100596400
I0930 11:17:10.459139  3537 layer_factory.hpp:77] Creating layer Convolution48
I0930 11:17:10.459146  3537 net.cpp:84] Creating Layer Convolution48
I0930 11:17:10.459148  3537 net.cpp:406] Convolution48 <- Eltwise22_elu_conv45_0_split_0
I0930 11:17:10.459152  3537 net.cpp:380] Convolution48 -> Convolution48
I0930 11:17:10.461122  3537 net.cpp:122] Setting up Convolution48
I0930 11:17:10.461129  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.461133  3537 net.cpp:137] Memory required for data: 1102234800
I0930 11:17:10.461136  3537 layer_factory.hpp:77] Creating layer BatchNorm48
I0930 11:17:10.461143  3537 net.cpp:84] Creating Layer BatchNorm48
I0930 11:17:10.461145  3537 net.cpp:406] BatchNorm48 <- Convolution48
I0930 11:17:10.461149  3537 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I0930 11:17:10.461278  3537 net.cpp:122] Setting up BatchNorm48
I0930 11:17:10.461283  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.461285  3537 net.cpp:137] Memory required for data: 1103873200
I0930 11:17:10.461290  3537 layer_factory.hpp:77] Creating layer Scale48
I0930 11:17:10.461295  3537 net.cpp:84] Creating Layer Scale48
I0930 11:17:10.461297  3537 net.cpp:406] Scale48 <- Convolution48
I0930 11:17:10.461300  3537 net.cpp:367] Scale48 -> Convolution48 (in-place)
I0930 11:17:10.461326  3537 layer_factory.hpp:77] Creating layer Scale48
I0930 11:17:10.461400  3537 net.cpp:122] Setting up Scale48
I0930 11:17:10.461403  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.461406  3537 net.cpp:137] Memory required for data: 1105511600
I0930 11:17:10.461410  3537 layer_factory.hpp:77] Creating layer elu_conv46
I0930 11:17:10.461413  3537 net.cpp:84] Creating Layer elu_conv46
I0930 11:17:10.461416  3537 net.cpp:406] elu_conv46 <- Convolution48
I0930 11:17:10.461419  3537 net.cpp:367] elu_conv46 -> Convolution48 (in-place)
I0930 11:17:10.461423  3537 net.cpp:122] Setting up elu_conv46
I0930 11:17:10.461426  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.461428  3537 net.cpp:137] Memory required for data: 1107150000
I0930 11:17:10.461431  3537 layer_factory.hpp:77] Creating layer Convolution49
I0930 11:17:10.461437  3537 net.cpp:84] Creating Layer Convolution49
I0930 11:17:10.461439  3537 net.cpp:406] Convolution49 <- Convolution48
I0930 11:17:10.461450  3537 net.cpp:380] Convolution49 -> Convolution49
I0930 11:17:10.463462  3537 net.cpp:122] Setting up Convolution49
I0930 11:17:10.463471  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.463474  3537 net.cpp:137] Memory required for data: 1108788400
I0930 11:17:10.463479  3537 layer_factory.hpp:77] Creating layer BatchNorm49
I0930 11:17:10.463485  3537 net.cpp:84] Creating Layer BatchNorm49
I0930 11:17:10.463487  3537 net.cpp:406] BatchNorm49 <- Convolution49
I0930 11:17:10.463491  3537 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I0930 11:17:10.463618  3537 net.cpp:122] Setting up BatchNorm49
I0930 11:17:10.463623  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.463624  3537 net.cpp:137] Memory required for data: 1110426800
I0930 11:17:10.463629  3537 layer_factory.hpp:77] Creating layer Scale49
I0930 11:17:10.463634  3537 net.cpp:84] Creating Layer Scale49
I0930 11:17:10.463636  3537 net.cpp:406] Scale49 <- Convolution49
I0930 11:17:10.463640  3537 net.cpp:367] Scale49 -> Convolution49 (in-place)
I0930 11:17:10.463665  3537 layer_factory.hpp:77] Creating layer Scale49
I0930 11:17:10.463739  3537 net.cpp:122] Setting up Scale49
I0930 11:17:10.463743  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.463745  3537 net.cpp:137] Memory required for data: 1112065200
I0930 11:17:10.463749  3537 layer_factory.hpp:77] Creating layer Eltwise23
I0930 11:17:10.463753  3537 net.cpp:84] Creating Layer Eltwise23
I0930 11:17:10.463757  3537 net.cpp:406] Eltwise23 <- Eltwise22_elu_conv45_0_split_1
I0930 11:17:10.463758  3537 net.cpp:406] Eltwise23 <- Convolution49
I0930 11:17:10.463763  3537 net.cpp:380] Eltwise23 -> Eltwise23
I0930 11:17:10.463778  3537 net.cpp:122] Setting up Eltwise23
I0930 11:17:10.463781  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.463783  3537 net.cpp:137] Memory required for data: 1113703600
I0930 11:17:10.463785  3537 layer_factory.hpp:77] Creating layer elu_conv47
I0930 11:17:10.463789  3537 net.cpp:84] Creating Layer elu_conv47
I0930 11:17:10.463793  3537 net.cpp:406] elu_conv47 <- Eltwise23
I0930 11:17:10.463794  3537 net.cpp:367] elu_conv47 -> Eltwise23 (in-place)
I0930 11:17:10.463798  3537 net.cpp:122] Setting up elu_conv47
I0930 11:17:10.463801  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.463804  3537 net.cpp:137] Memory required for data: 1115342000
I0930 11:17:10.463805  3537 layer_factory.hpp:77] Creating layer Eltwise23_elu_conv47_0_split
I0930 11:17:10.463809  3537 net.cpp:84] Creating Layer Eltwise23_elu_conv47_0_split
I0930 11:17:10.463811  3537 net.cpp:406] Eltwise23_elu_conv47_0_split <- Eltwise23
I0930 11:17:10.463814  3537 net.cpp:380] Eltwise23_elu_conv47_0_split -> Eltwise23_elu_conv47_0_split_0
I0930 11:17:10.463819  3537 net.cpp:380] Eltwise23_elu_conv47_0_split -> Eltwise23_elu_conv47_0_split_1
I0930 11:17:10.480749  3537 net.cpp:122] Setting up Eltwise23_elu_conv47_0_split
I0930 11:17:10.480756  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.480760  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.480762  3537 net.cpp:137] Memory required for data: 1118618800
I0930 11:17:10.480764  3537 layer_factory.hpp:77] Creating layer Convolution50
I0930 11:17:10.480773  3537 net.cpp:84] Creating Layer Convolution50
I0930 11:17:10.480777  3537 net.cpp:406] Convolution50 <- Eltwise23_elu_conv47_0_split_0
I0930 11:17:10.480782  3537 net.cpp:380] Convolution50 -> Convolution50
I0930 11:17:10.483861  3537 net.cpp:122] Setting up Convolution50
I0930 11:17:10.483871  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.483875  3537 net.cpp:137] Memory required for data: 1120257200
I0930 11:17:10.483880  3537 layer_factory.hpp:77] Creating layer BatchNorm50
I0930 11:17:10.483886  3537 net.cpp:84] Creating Layer BatchNorm50
I0930 11:17:10.483887  3537 net.cpp:406] BatchNorm50 <- Convolution50
I0930 11:17:10.483891  3537 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I0930 11:17:10.484027  3537 net.cpp:122] Setting up BatchNorm50
I0930 11:17:10.484032  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.484041  3537 net.cpp:137] Memory required for data: 1121895600
I0930 11:17:10.484046  3537 layer_factory.hpp:77] Creating layer Scale50
I0930 11:17:10.484051  3537 net.cpp:84] Creating Layer Scale50
I0930 11:17:10.484053  3537 net.cpp:406] Scale50 <- Convolution50
I0930 11:17:10.484057  3537 net.cpp:367] Scale50 -> Convolution50 (in-place)
I0930 11:17:10.484086  3537 layer_factory.hpp:77] Creating layer Scale50
I0930 11:17:10.484160  3537 net.cpp:122] Setting up Scale50
I0930 11:17:10.484164  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.484167  3537 net.cpp:137] Memory required for data: 1123534000
I0930 11:17:10.484170  3537 layer_factory.hpp:77] Creating layer elu_conv48
I0930 11:17:10.484174  3537 net.cpp:84] Creating Layer elu_conv48
I0930 11:17:10.484177  3537 net.cpp:406] elu_conv48 <- Convolution50
I0930 11:17:10.484180  3537 net.cpp:367] elu_conv48 -> Convolution50 (in-place)
I0930 11:17:10.484184  3537 net.cpp:122] Setting up elu_conv48
I0930 11:17:10.484187  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.484189  3537 net.cpp:137] Memory required for data: 1125172400
I0930 11:17:10.484191  3537 layer_factory.hpp:77] Creating layer Convolution51
I0930 11:17:10.484199  3537 net.cpp:84] Creating Layer Convolution51
I0930 11:17:10.484200  3537 net.cpp:406] Convolution51 <- Convolution50
I0930 11:17:10.484205  3537 net.cpp:380] Convolution51 -> Convolution51
I0930 11:17:10.486039  3537 net.cpp:122] Setting up Convolution51
I0930 11:17:10.486048  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.486050  3537 net.cpp:137] Memory required for data: 1126810800
I0930 11:17:10.486055  3537 layer_factory.hpp:77] Creating layer BatchNorm51
I0930 11:17:10.486060  3537 net.cpp:84] Creating Layer BatchNorm51
I0930 11:17:10.486063  3537 net.cpp:406] BatchNorm51 <- Convolution51
I0930 11:17:10.486068  3537 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I0930 11:17:10.486194  3537 net.cpp:122] Setting up BatchNorm51
I0930 11:17:10.486198  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.486201  3537 net.cpp:137] Memory required for data: 1128449200
I0930 11:17:10.486205  3537 layer_factory.hpp:77] Creating layer Scale51
I0930 11:17:10.486209  3537 net.cpp:84] Creating Layer Scale51
I0930 11:17:10.486212  3537 net.cpp:406] Scale51 <- Convolution51
I0930 11:17:10.486215  3537 net.cpp:367] Scale51 -> Convolution51 (in-place)
I0930 11:17:10.486243  3537 layer_factory.hpp:77] Creating layer Scale51
I0930 11:17:10.486315  3537 net.cpp:122] Setting up Scale51
I0930 11:17:10.486320  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.486321  3537 net.cpp:137] Memory required for data: 1130087600
I0930 11:17:10.486325  3537 layer_factory.hpp:77] Creating layer Eltwise24
I0930 11:17:10.486331  3537 net.cpp:84] Creating Layer Eltwise24
I0930 11:17:10.486335  3537 net.cpp:406] Eltwise24 <- Eltwise23_elu_conv47_0_split_1
I0930 11:17:10.486337  3537 net.cpp:406] Eltwise24 <- Convolution51
I0930 11:17:10.486341  3537 net.cpp:380] Eltwise24 -> Eltwise24
I0930 11:17:10.486356  3537 net.cpp:122] Setting up Eltwise24
I0930 11:17:10.486361  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.486362  3537 net.cpp:137] Memory required for data: 1131726000
I0930 11:17:10.486364  3537 layer_factory.hpp:77] Creating layer elu_conv49
I0930 11:17:10.486368  3537 net.cpp:84] Creating Layer elu_conv49
I0930 11:17:10.486371  3537 net.cpp:406] elu_conv49 <- Eltwise24
I0930 11:17:10.486374  3537 net.cpp:367] elu_conv49 -> Eltwise24 (in-place)
I0930 11:17:10.486378  3537 net.cpp:122] Setting up elu_conv49
I0930 11:17:10.486382  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.486383  3537 net.cpp:137] Memory required for data: 1133364400
I0930 11:17:10.486385  3537 layer_factory.hpp:77] Creating layer Eltwise24_elu_conv49_0_split
I0930 11:17:10.486389  3537 net.cpp:84] Creating Layer Eltwise24_elu_conv49_0_split
I0930 11:17:10.486392  3537 net.cpp:406] Eltwise24_elu_conv49_0_split <- Eltwise24
I0930 11:17:10.486400  3537 net.cpp:380] Eltwise24_elu_conv49_0_split -> Eltwise24_elu_conv49_0_split_0
I0930 11:17:10.486404  3537 net.cpp:380] Eltwise24_elu_conv49_0_split -> Eltwise24_elu_conv49_0_split_1
I0930 11:17:10.486439  3537 net.cpp:122] Setting up Eltwise24_elu_conv49_0_split
I0930 11:17:10.486443  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.486448  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.486449  3537 net.cpp:137] Memory required for data: 1136641200
I0930 11:17:10.486452  3537 layer_factory.hpp:77] Creating layer Convolution52
I0930 11:17:10.486459  3537 net.cpp:84] Creating Layer Convolution52
I0930 11:17:10.486462  3537 net.cpp:406] Convolution52 <- Eltwise24_elu_conv49_0_split_0
I0930 11:17:10.486467  3537 net.cpp:380] Convolution52 -> Convolution52
I0930 11:17:10.488467  3537 net.cpp:122] Setting up Convolution52
I0930 11:17:10.488476  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.488478  3537 net.cpp:137] Memory required for data: 1138279600
I0930 11:17:10.488483  3537 layer_factory.hpp:77] Creating layer BatchNorm52
I0930 11:17:10.488488  3537 net.cpp:84] Creating Layer BatchNorm52
I0930 11:17:10.488492  3537 net.cpp:406] BatchNorm52 <- Convolution52
I0930 11:17:10.488495  3537 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I0930 11:17:10.488629  3537 net.cpp:122] Setting up BatchNorm52
I0930 11:17:10.488634  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.488636  3537 net.cpp:137] Memory required for data: 1139918000
I0930 11:17:10.488641  3537 layer_factory.hpp:77] Creating layer Scale52
I0930 11:17:10.488644  3537 net.cpp:84] Creating Layer Scale52
I0930 11:17:10.488647  3537 net.cpp:406] Scale52 <- Convolution52
I0930 11:17:10.488651  3537 net.cpp:367] Scale52 -> Convolution52 (in-place)
I0930 11:17:10.488677  3537 layer_factory.hpp:77] Creating layer Scale52
I0930 11:17:10.488751  3537 net.cpp:122] Setting up Scale52
I0930 11:17:10.488755  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.488757  3537 net.cpp:137] Memory required for data: 1141556400
I0930 11:17:10.488761  3537 layer_factory.hpp:77] Creating layer elu_conv50
I0930 11:17:10.488790  3537 net.cpp:84] Creating Layer elu_conv50
I0930 11:17:10.488792  3537 net.cpp:406] elu_conv50 <- Convolution52
I0930 11:17:10.488795  3537 net.cpp:367] elu_conv50 -> Convolution52 (in-place)
I0930 11:17:10.488800  3537 net.cpp:122] Setting up elu_conv50
I0930 11:17:10.488802  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.488804  3537 net.cpp:137] Memory required for data: 1143194800
I0930 11:17:10.488807  3537 layer_factory.hpp:77] Creating layer Convolution53
I0930 11:17:10.488812  3537 net.cpp:84] Creating Layer Convolution53
I0930 11:17:10.488816  3537 net.cpp:406] Convolution53 <- Convolution52
I0930 11:17:10.488819  3537 net.cpp:380] Convolution53 -> Convolution53
I0930 11:17:10.490492  3537 net.cpp:122] Setting up Convolution53
I0930 11:17:10.490501  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.490504  3537 net.cpp:137] Memory required for data: 1144833200
I0930 11:17:10.490509  3537 layer_factory.hpp:77] Creating layer BatchNorm53
I0930 11:17:10.490515  3537 net.cpp:84] Creating Layer BatchNorm53
I0930 11:17:10.490519  3537 net.cpp:406] BatchNorm53 <- Convolution53
I0930 11:17:10.490525  3537 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I0930 11:17:10.490655  3537 net.cpp:122] Setting up BatchNorm53
I0930 11:17:10.490659  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.490662  3537 net.cpp:137] Memory required for data: 1146471600
I0930 11:17:10.490666  3537 layer_factory.hpp:77] Creating layer Scale53
I0930 11:17:10.490670  3537 net.cpp:84] Creating Layer Scale53
I0930 11:17:10.490674  3537 net.cpp:406] Scale53 <- Convolution53
I0930 11:17:10.490676  3537 net.cpp:367] Scale53 -> Convolution53 (in-place)
I0930 11:17:10.490702  3537 layer_factory.hpp:77] Creating layer Scale53
I0930 11:17:10.490777  3537 net.cpp:122] Setting up Scale53
I0930 11:17:10.490780  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.490788  3537 net.cpp:137] Memory required for data: 1148110000
I0930 11:17:10.490793  3537 layer_factory.hpp:77] Creating layer Eltwise25
I0930 11:17:10.490797  3537 net.cpp:84] Creating Layer Eltwise25
I0930 11:17:10.490800  3537 net.cpp:406] Eltwise25 <- Eltwise24_elu_conv49_0_split_1
I0930 11:17:10.490803  3537 net.cpp:406] Eltwise25 <- Convolution53
I0930 11:17:10.490806  3537 net.cpp:380] Eltwise25 -> Eltwise25
I0930 11:17:10.490823  3537 net.cpp:122] Setting up Eltwise25
I0930 11:17:10.490828  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.490829  3537 net.cpp:137] Memory required for data: 1149748400
I0930 11:17:10.490831  3537 layer_factory.hpp:77] Creating layer elu_conv51
I0930 11:17:10.490834  3537 net.cpp:84] Creating Layer elu_conv51
I0930 11:17:10.490838  3537 net.cpp:406] elu_conv51 <- Eltwise25
I0930 11:17:10.490840  3537 net.cpp:367] elu_conv51 -> Eltwise25 (in-place)
I0930 11:17:10.490844  3537 net.cpp:122] Setting up elu_conv51
I0930 11:17:10.490846  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.490849  3537 net.cpp:137] Memory required for data: 1151386800
I0930 11:17:10.490851  3537 layer_factory.hpp:77] Creating layer Eltwise25_elu_conv51_0_split
I0930 11:17:10.490854  3537 net.cpp:84] Creating Layer Eltwise25_elu_conv51_0_split
I0930 11:17:10.490856  3537 net.cpp:406] Eltwise25_elu_conv51_0_split <- Eltwise25
I0930 11:17:10.490859  3537 net.cpp:380] Eltwise25_elu_conv51_0_split -> Eltwise25_elu_conv51_0_split_0
I0930 11:17:10.490864  3537 net.cpp:380] Eltwise25_elu_conv51_0_split -> Eltwise25_elu_conv51_0_split_1
I0930 11:17:10.490886  3537 net.cpp:122] Setting up Eltwise25_elu_conv51_0_split
I0930 11:17:10.490890  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.490893  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.490895  3537 net.cpp:137] Memory required for data: 1154663600
I0930 11:17:10.490897  3537 layer_factory.hpp:77] Creating layer Convolution54
I0930 11:17:10.490905  3537 net.cpp:84] Creating Layer Convolution54
I0930 11:17:10.490906  3537 net.cpp:406] Convolution54 <- Eltwise25_elu_conv51_0_split_0
I0930 11:17:10.490911  3537 net.cpp:380] Convolution54 -> Convolution54
I0930 11:17:10.492892  3537 net.cpp:122] Setting up Convolution54
I0930 11:17:10.492899  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.492902  3537 net.cpp:137] Memory required for data: 1156302000
I0930 11:17:10.492908  3537 layer_factory.hpp:77] Creating layer BatchNorm54
I0930 11:17:10.492913  3537 net.cpp:84] Creating Layer BatchNorm54
I0930 11:17:10.492915  3537 net.cpp:406] BatchNorm54 <- Convolution54
I0930 11:17:10.492919  3537 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I0930 11:17:10.493055  3537 net.cpp:122] Setting up BatchNorm54
I0930 11:17:10.493060  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.493062  3537 net.cpp:137] Memory required for data: 1157940400
I0930 11:17:10.493067  3537 layer_factory.hpp:77] Creating layer Scale54
I0930 11:17:10.493072  3537 net.cpp:84] Creating Layer Scale54
I0930 11:17:10.493073  3537 net.cpp:406] Scale54 <- Convolution54
I0930 11:17:10.493077  3537 net.cpp:367] Scale54 -> Convolution54 (in-place)
I0930 11:17:10.493104  3537 layer_factory.hpp:77] Creating layer Scale54
I0930 11:17:10.493180  3537 net.cpp:122] Setting up Scale54
I0930 11:17:10.493185  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.493187  3537 net.cpp:137] Memory required for data: 1159578800
I0930 11:17:10.493191  3537 layer_factory.hpp:77] Creating layer elu_conv52
I0930 11:17:10.493196  3537 net.cpp:84] Creating Layer elu_conv52
I0930 11:17:10.493197  3537 net.cpp:406] elu_conv52 <- Convolution54
I0930 11:17:10.493201  3537 net.cpp:367] elu_conv52 -> Convolution54 (in-place)
I0930 11:17:10.493203  3537 net.cpp:122] Setting up elu_conv52
I0930 11:17:10.493207  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.493209  3537 net.cpp:137] Memory required for data: 1161217200
I0930 11:17:10.493211  3537 layer_factory.hpp:77] Creating layer Convolution55
I0930 11:17:10.493224  3537 net.cpp:84] Creating Layer Convolution55
I0930 11:17:10.493227  3537 net.cpp:406] Convolution55 <- Convolution54
I0930 11:17:10.493232  3537 net.cpp:380] Convolution55 -> Convolution55
I0930 11:17:10.494912  3537 net.cpp:122] Setting up Convolution55
I0930 11:17:10.494921  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.494923  3537 net.cpp:137] Memory required for data: 1162855600
I0930 11:17:10.494928  3537 layer_factory.hpp:77] Creating layer BatchNorm55
I0930 11:17:10.494933  3537 net.cpp:84] Creating Layer BatchNorm55
I0930 11:17:10.494936  3537 net.cpp:406] BatchNorm55 <- Convolution55
I0930 11:17:10.494940  3537 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I0930 11:17:10.495072  3537 net.cpp:122] Setting up BatchNorm55
I0930 11:17:10.495076  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.495079  3537 net.cpp:137] Memory required for data: 1164494000
I0930 11:17:10.495084  3537 layer_factory.hpp:77] Creating layer Scale55
I0930 11:17:10.495088  3537 net.cpp:84] Creating Layer Scale55
I0930 11:17:10.495091  3537 net.cpp:406] Scale55 <- Convolution55
I0930 11:17:10.495095  3537 net.cpp:367] Scale55 -> Convolution55 (in-place)
I0930 11:17:10.495120  3537 layer_factory.hpp:77] Creating layer Scale55
I0930 11:17:10.495194  3537 net.cpp:122] Setting up Scale55
I0930 11:17:10.495198  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.495200  3537 net.cpp:137] Memory required for data: 1166132400
I0930 11:17:10.495204  3537 layer_factory.hpp:77] Creating layer Eltwise26
I0930 11:17:10.495208  3537 net.cpp:84] Creating Layer Eltwise26
I0930 11:17:10.495211  3537 net.cpp:406] Eltwise26 <- Eltwise25_elu_conv51_0_split_1
I0930 11:17:10.495214  3537 net.cpp:406] Eltwise26 <- Convolution55
I0930 11:17:10.495218  3537 net.cpp:380] Eltwise26 -> Eltwise26
I0930 11:17:10.495232  3537 net.cpp:122] Setting up Eltwise26
I0930 11:17:10.495236  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.495239  3537 net.cpp:137] Memory required for data: 1167770800
I0930 11:17:10.495240  3537 layer_factory.hpp:77] Creating layer elu_conv53
I0930 11:17:10.495244  3537 net.cpp:84] Creating Layer elu_conv53
I0930 11:17:10.495246  3537 net.cpp:406] elu_conv53 <- Eltwise26
I0930 11:17:10.495250  3537 net.cpp:367] elu_conv53 -> Eltwise26 (in-place)
I0930 11:17:10.495254  3537 net.cpp:122] Setting up elu_conv53
I0930 11:17:10.495257  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.495260  3537 net.cpp:137] Memory required for data: 1169409200
I0930 11:17:10.495261  3537 layer_factory.hpp:77] Creating layer Eltwise26_elu_conv53_0_split
I0930 11:17:10.495265  3537 net.cpp:84] Creating Layer Eltwise26_elu_conv53_0_split
I0930 11:17:10.511576  3537 net.cpp:406] Eltwise26_elu_conv53_0_split <- Eltwise26
I0930 11:17:10.511586  3537 net.cpp:380] Eltwise26_elu_conv53_0_split -> Eltwise26_elu_conv53_0_split_0
I0930 11:17:10.511593  3537 net.cpp:380] Eltwise26_elu_conv53_0_split -> Eltwise26_elu_conv53_0_split_1
I0930 11:17:10.511631  3537 net.cpp:122] Setting up Eltwise26_elu_conv53_0_split
I0930 11:17:10.511636  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.511639  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.511641  3537 net.cpp:137] Memory required for data: 1172686000
I0930 11:17:10.511644  3537 layer_factory.hpp:77] Creating layer Convolution56
I0930 11:17:10.511651  3537 net.cpp:84] Creating Layer Convolution56
I0930 11:17:10.511654  3537 net.cpp:406] Convolution56 <- Eltwise26_elu_conv53_0_split_0
I0930 11:17:10.511659  3537 net.cpp:380] Convolution56 -> Convolution56
I0930 11:17:10.513521  3537 net.cpp:122] Setting up Convolution56
I0930 11:17:10.513530  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.513533  3537 net.cpp:137] Memory required for data: 1174324400
I0930 11:17:10.513540  3537 layer_factory.hpp:77] Creating layer BatchNorm56
I0930 11:17:10.513545  3537 net.cpp:84] Creating Layer BatchNorm56
I0930 11:17:10.513548  3537 net.cpp:406] BatchNorm56 <- Convolution56
I0930 11:17:10.513561  3537 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I0930 11:17:10.513702  3537 net.cpp:122] Setting up BatchNorm56
I0930 11:17:10.513707  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.513710  3537 net.cpp:137] Memory required for data: 1175962800
I0930 11:17:10.513715  3537 layer_factory.hpp:77] Creating layer Scale56
I0930 11:17:10.513720  3537 net.cpp:84] Creating Layer Scale56
I0930 11:17:10.513721  3537 net.cpp:406] Scale56 <- Convolution56
I0930 11:17:10.513725  3537 net.cpp:367] Scale56 -> Convolution56 (in-place)
I0930 11:17:10.513753  3537 layer_factory.hpp:77] Creating layer Scale56
I0930 11:17:10.513833  3537 net.cpp:122] Setting up Scale56
I0930 11:17:10.513836  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.513839  3537 net.cpp:137] Memory required for data: 1177601200
I0930 11:17:10.513842  3537 layer_factory.hpp:77] Creating layer elu_conv54
I0930 11:17:10.513846  3537 net.cpp:84] Creating Layer elu_conv54
I0930 11:17:10.513849  3537 net.cpp:406] elu_conv54 <- Convolution56
I0930 11:17:10.513852  3537 net.cpp:367] elu_conv54 -> Convolution56 (in-place)
I0930 11:17:10.513855  3537 net.cpp:122] Setting up elu_conv54
I0930 11:17:10.513859  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.513861  3537 net.cpp:137] Memory required for data: 1179239600
I0930 11:17:10.513864  3537 layer_factory.hpp:77] Creating layer Convolution57
I0930 11:17:10.513870  3537 net.cpp:84] Creating Layer Convolution57
I0930 11:17:10.513873  3537 net.cpp:406] Convolution57 <- Convolution56
I0930 11:17:10.513877  3537 net.cpp:380] Convolution57 -> Convolution57
I0930 11:17:10.516026  3537 net.cpp:122] Setting up Convolution57
I0930 11:17:10.516036  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.516039  3537 net.cpp:137] Memory required for data: 1180878000
I0930 11:17:10.516044  3537 layer_factory.hpp:77] Creating layer BatchNorm57
I0930 11:17:10.516050  3537 net.cpp:84] Creating Layer BatchNorm57
I0930 11:17:10.516053  3537 net.cpp:406] BatchNorm57 <- Convolution57
I0930 11:17:10.516057  3537 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I0930 11:17:10.516191  3537 net.cpp:122] Setting up BatchNorm57
I0930 11:17:10.516196  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.516198  3537 net.cpp:137] Memory required for data: 1182516400
I0930 11:17:10.516202  3537 layer_factory.hpp:77] Creating layer Scale57
I0930 11:17:10.516207  3537 net.cpp:84] Creating Layer Scale57
I0930 11:17:10.516211  3537 net.cpp:406] Scale57 <- Convolution57
I0930 11:17:10.516213  3537 net.cpp:367] Scale57 -> Convolution57 (in-place)
I0930 11:17:10.516240  3537 layer_factory.hpp:77] Creating layer Scale57
I0930 11:17:10.516319  3537 net.cpp:122] Setting up Scale57
I0930 11:17:10.516322  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.516324  3537 net.cpp:137] Memory required for data: 1184154800
I0930 11:17:10.516329  3537 layer_factory.hpp:77] Creating layer Eltwise27
I0930 11:17:10.516333  3537 net.cpp:84] Creating Layer Eltwise27
I0930 11:17:10.516336  3537 net.cpp:406] Eltwise27 <- Eltwise26_elu_conv53_0_split_1
I0930 11:17:10.516340  3537 net.cpp:406] Eltwise27 <- Convolution57
I0930 11:17:10.516343  3537 net.cpp:380] Eltwise27 -> Eltwise27
I0930 11:17:10.516358  3537 net.cpp:122] Setting up Eltwise27
I0930 11:17:10.516362  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.516364  3537 net.cpp:137] Memory required for data: 1185793200
I0930 11:17:10.516366  3537 layer_factory.hpp:77] Creating layer elu_conv55
I0930 11:17:10.516371  3537 net.cpp:84] Creating Layer elu_conv55
I0930 11:17:10.516373  3537 net.cpp:406] elu_conv55 <- Eltwise27
I0930 11:17:10.516376  3537 net.cpp:367] elu_conv55 -> Eltwise27 (in-place)
I0930 11:17:10.516381  3537 net.cpp:122] Setting up elu_conv55
I0930 11:17:10.516383  3537 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 11:17:10.516386  3537 net.cpp:137] Memory required for data: 1187431600
I0930 11:17:10.516387  3537 layer_factory.hpp:77] Creating layer Pooling1
I0930 11:17:10.516391  3537 net.cpp:84] Creating Layer Pooling1
I0930 11:17:10.516402  3537 net.cpp:406] Pooling1 <- Eltwise27
I0930 11:17:10.516405  3537 net.cpp:380] Pooling1 -> Pooling1
I0930 11:17:10.516904  3537 net.cpp:122] Setting up Pooling1
I0930 11:17:10.516913  3537 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0930 11:17:10.516916  3537 net.cpp:137] Memory required for data: 1187457200
I0930 11:17:10.516918  3537 layer_factory.hpp:77] Creating layer InnerProduct1
I0930 11:17:10.516924  3537 net.cpp:84] Creating Layer InnerProduct1
I0930 11:17:10.516927  3537 net.cpp:406] InnerProduct1 <- Pooling1
I0930 11:17:10.516932  3537 net.cpp:380] InnerProduct1 -> InnerProduct1
I0930 11:17:10.517038  3537 net.cpp:122] Setting up InnerProduct1
I0930 11:17:10.517042  3537 net.cpp:129] Top shape: 100 10 (1000)
I0930 11:17:10.517045  3537 net.cpp:137] Memory required for data: 1187461200
I0930 11:17:10.517050  3537 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0930 11:17:10.517053  3537 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I0930 11:17:10.517056  3537 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0930 11:17:10.517060  3537 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0930 11:17:10.517065  3537 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0930 11:17:10.517088  3537 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I0930 11:17:10.517092  3537 net.cpp:129] Top shape: 100 10 (1000)
I0930 11:17:10.517096  3537 net.cpp:129] Top shape: 100 10 (1000)
I0930 11:17:10.517097  3537 net.cpp:137] Memory required for data: 1187469200
I0930 11:17:10.517099  3537 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0930 11:17:10.517104  3537 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0930 11:17:10.517107  3537 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I0930 11:17:10.517109  3537 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I0930 11:17:10.517113  3537 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0930 11:17:10.517117  3537 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0930 11:17:10.517308  3537 net.cpp:122] Setting up SoftmaxWithLoss1
I0930 11:17:10.517314  3537 net.cpp:129] Top shape: (1)
I0930 11:17:10.517316  3537 net.cpp:132]     with loss weight 1
I0930 11:17:10.517323  3537 net.cpp:137] Memory required for data: 1187469204
I0930 11:17:10.517325  3537 layer_factory.hpp:77] Creating layer Accuracy1
I0930 11:17:10.517331  3537 net.cpp:84] Creating Layer Accuracy1
I0930 11:17:10.517334  3537 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I0930 11:17:10.517338  3537 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I0930 11:17:10.517341  3537 net.cpp:380] Accuracy1 -> Accuracy1
I0930 11:17:10.517347  3537 net.cpp:122] Setting up Accuracy1
I0930 11:17:10.517350  3537 net.cpp:129] Top shape: (1)
I0930 11:17:10.517352  3537 net.cpp:137] Memory required for data: 1187469208
I0930 11:17:10.517354  3537 net.cpp:200] Accuracy1 does not need backward computation.
I0930 11:17:10.517357  3537 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0930 11:17:10.517359  3537 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0930 11:17:10.517362  3537 net.cpp:198] InnerProduct1 needs backward computation.
I0930 11:17:10.517364  3537 net.cpp:198] Pooling1 needs backward computation.
I0930 11:17:10.517366  3537 net.cpp:198] elu_conv55 needs backward computation.
I0930 11:17:10.517369  3537 net.cpp:198] Eltwise27 needs backward computation.
I0930 11:17:10.517371  3537 net.cpp:198] Scale57 needs backward computation.
I0930 11:17:10.517374  3537 net.cpp:198] BatchNorm57 needs backward computation.
I0930 11:17:10.517375  3537 net.cpp:198] Convolution57 needs backward computation.
I0930 11:17:10.517377  3537 net.cpp:198] elu_conv54 needs backward computation.
I0930 11:17:10.517379  3537 net.cpp:198] Scale56 needs backward computation.
I0930 11:17:10.517381  3537 net.cpp:198] BatchNorm56 needs backward computation.
I0930 11:17:10.517390  3537 net.cpp:198] Convolution56 needs backward computation.
I0930 11:17:10.517393  3537 net.cpp:198] Eltwise26_elu_conv53_0_split needs backward computation.
I0930 11:17:10.517395  3537 net.cpp:198] elu_conv53 needs backward computation.
I0930 11:17:10.517397  3537 net.cpp:198] Eltwise26 needs backward computation.
I0930 11:17:10.517400  3537 net.cpp:198] Scale55 needs backward computation.
I0930 11:17:10.517402  3537 net.cpp:198] BatchNorm55 needs backward computation.
I0930 11:17:10.517405  3537 net.cpp:198] Convolution55 needs backward computation.
I0930 11:17:10.517407  3537 net.cpp:198] elu_conv52 needs backward computation.
I0930 11:17:10.517410  3537 net.cpp:198] Scale54 needs backward computation.
I0930 11:17:10.517411  3537 net.cpp:198] BatchNorm54 needs backward computation.
I0930 11:17:10.517413  3537 net.cpp:198] Convolution54 needs backward computation.
I0930 11:17:10.517416  3537 net.cpp:198] Eltwise25_elu_conv51_0_split needs backward computation.
I0930 11:17:10.517419  3537 net.cpp:198] elu_conv51 needs backward computation.
I0930 11:17:10.517421  3537 net.cpp:198] Eltwise25 needs backward computation.
I0930 11:17:10.517424  3537 net.cpp:198] Scale53 needs backward computation.
I0930 11:17:10.517426  3537 net.cpp:198] BatchNorm53 needs backward computation.
I0930 11:17:10.517429  3537 net.cpp:198] Convolution53 needs backward computation.
I0930 11:17:10.517431  3537 net.cpp:198] elu_conv50 needs backward computation.
I0930 11:17:10.517433  3537 net.cpp:198] Scale52 needs backward computation.
I0930 11:17:10.517436  3537 net.cpp:198] BatchNorm52 needs backward computation.
I0930 11:17:10.517438  3537 net.cpp:198] Convolution52 needs backward computation.
I0930 11:17:10.517441  3537 net.cpp:198] Eltwise24_elu_conv49_0_split needs backward computation.
I0930 11:17:10.517443  3537 net.cpp:198] elu_conv49 needs backward computation.
I0930 11:17:10.517446  3537 net.cpp:198] Eltwise24 needs backward computation.
I0930 11:17:10.517448  3537 net.cpp:198] Scale51 needs backward computation.
I0930 11:17:10.517451  3537 net.cpp:198] BatchNorm51 needs backward computation.
I0930 11:17:10.517452  3537 net.cpp:198] Convolution51 needs backward computation.
I0930 11:17:10.517454  3537 net.cpp:198] elu_conv48 needs backward computation.
I0930 11:17:10.517457  3537 net.cpp:198] Scale50 needs backward computation.
I0930 11:17:10.517458  3537 net.cpp:198] BatchNorm50 needs backward computation.
I0930 11:17:10.517462  3537 net.cpp:198] Convolution50 needs backward computation.
I0930 11:17:10.517463  3537 net.cpp:198] Eltwise23_elu_conv47_0_split needs backward computation.
I0930 11:17:10.517467  3537 net.cpp:198] elu_conv47 needs backward computation.
I0930 11:17:10.517468  3537 net.cpp:198] Eltwise23 needs backward computation.
I0930 11:17:10.517472  3537 net.cpp:198] Scale49 needs backward computation.
I0930 11:17:10.517473  3537 net.cpp:198] BatchNorm49 needs backward computation.
I0930 11:17:10.517475  3537 net.cpp:198] Convolution49 needs backward computation.
I0930 11:17:10.517478  3537 net.cpp:198] elu_conv46 needs backward computation.
I0930 11:17:10.517480  3537 net.cpp:198] Scale48 needs backward computation.
I0930 11:17:10.517482  3537 net.cpp:198] BatchNorm48 needs backward computation.
I0930 11:17:10.517484  3537 net.cpp:198] Convolution48 needs backward computation.
I0930 11:17:10.517488  3537 net.cpp:198] Eltwise22_elu_conv45_0_split needs backward computation.
I0930 11:17:10.517490  3537 net.cpp:198] elu_conv45 needs backward computation.
I0930 11:17:10.517493  3537 net.cpp:198] Eltwise22 needs backward computation.
I0930 11:17:10.517495  3537 net.cpp:198] Scale47 needs backward computation.
I0930 11:17:10.517498  3537 net.cpp:198] BatchNorm47 needs backward computation.
I0930 11:17:10.517499  3537 net.cpp:198] Convolution47 needs backward computation.
I0930 11:17:10.517501  3537 net.cpp:198] elu_conv44 needs backward computation.
I0930 11:17:10.517504  3537 net.cpp:198] Scale46 needs backward computation.
I0930 11:17:10.517506  3537 net.cpp:198] BatchNorm46 needs backward computation.
I0930 11:17:10.517511  3537 net.cpp:198] Convolution46 needs backward computation.
I0930 11:17:10.517514  3537 net.cpp:198] Eltwise21_elu_conv43_0_split needs backward computation.
I0930 11:17:10.517516  3537 net.cpp:198] elu_conv43 needs backward computation.
I0930 11:17:10.517518  3537 net.cpp:198] Eltwise21 needs backward computation.
I0930 11:17:10.517521  3537 net.cpp:198] Scale45 needs backward computation.
I0930 11:17:10.517524  3537 net.cpp:198] BatchNorm45 needs backward computation.
I0930 11:17:10.517526  3537 net.cpp:198] Convolution45 needs backward computation.
I0930 11:17:10.517529  3537 net.cpp:198] elu_conv42 needs backward computation.
I0930 11:17:10.517530  3537 net.cpp:198] Scale44 needs backward computation.
I0930 11:17:10.517532  3537 net.cpp:198] BatchNorm44 needs backward computation.
I0930 11:17:10.517535  3537 net.cpp:198] Convolution44 needs backward computation.
I0930 11:17:10.517537  3537 net.cpp:198] Eltwise20_elu_conv41_0_split needs backward computation.
I0930 11:17:10.517539  3537 net.cpp:198] elu_conv41 needs backward computation.
I0930 11:17:10.517542  3537 net.cpp:198] Eltwise20 needs backward computation.
I0930 11:17:10.517545  3537 net.cpp:198] Scale43 needs backward computation.
I0930 11:17:10.517547  3537 net.cpp:198] BatchNorm43 needs backward computation.
I0930 11:17:10.517549  3537 net.cpp:198] Convolution43 needs backward computation.
I0930 11:17:10.517552  3537 net.cpp:198] elu_conv40 needs backward computation.
I0930 11:17:10.517554  3537 net.cpp:198] Scale42 needs backward computation.
I0930 11:17:10.517556  3537 net.cpp:198] BatchNorm42 needs backward computation.
I0930 11:17:10.517558  3537 net.cpp:198] Convolution42 needs backward computation.
I0930 11:17:10.517561  3537 net.cpp:198] Eltwise19_elu_conv39_0_split needs backward computation.
I0930 11:17:10.517565  3537 net.cpp:198] elu_conv39 needs backward computation.
I0930 11:17:10.517566  3537 net.cpp:198] Eltwise19 needs backward computation.
I0930 11:17:10.517570  3537 net.cpp:198] Scale41 needs backward computation.
I0930 11:17:10.517571  3537 net.cpp:198] BatchNorm41 needs backward computation.
I0930 11:17:10.517575  3537 net.cpp:198] Convolution41 needs backward computation.
I0930 11:17:10.517576  3537 net.cpp:198] elu_conv38 needs backward computation.
I0930 11:17:10.517578  3537 net.cpp:198] Scale40 needs backward computation.
I0930 11:17:10.517580  3537 net.cpp:198] BatchNorm40 needs backward computation.
I0930 11:17:10.517583  3537 net.cpp:198] Convolution40 needs backward computation.
I0930 11:17:10.517585  3537 net.cpp:198] Scale39 needs backward computation.
I0930 11:17:10.542291  3537 net.cpp:198] BatchNorm39 needs backward computation.
I0930 11:17:10.542300  3537 net.cpp:198] Convolution39 needs backward computation.
I0930 11:17:10.542304  3537 net.cpp:198] Eltwise18_elu_conv37_0_split needs backward computation.
I0930 11:17:10.542307  3537 net.cpp:198] elu_conv37 needs backward computation.
I0930 11:17:10.542310  3537 net.cpp:198] Eltwise18 needs backward computation.
I0930 11:17:10.542313  3537 net.cpp:198] Scale38 needs backward computation.
I0930 11:17:10.542316  3537 net.cpp:198] BatchNorm38 needs backward computation.
I0930 11:17:10.542318  3537 net.cpp:198] Convolution38 needs backward computation.
I0930 11:17:10.542321  3537 net.cpp:198] elu_conv36 needs backward computation.
I0930 11:17:10.542325  3537 net.cpp:198] Scale37 needs backward computation.
I0930 11:17:10.542326  3537 net.cpp:198] BatchNorm37 needs backward computation.
I0930 11:17:10.542330  3537 net.cpp:198] Convolution37 needs backward computation.
I0930 11:17:10.542332  3537 net.cpp:198] Eltwise17_elu_conv35_0_split needs backward computation.
I0930 11:17:10.542335  3537 net.cpp:198] elu_conv35 needs backward computation.
I0930 11:17:10.542337  3537 net.cpp:198] Eltwise17 needs backward computation.
I0930 11:17:10.542340  3537 net.cpp:198] Scale36 needs backward computation.
I0930 11:17:10.542342  3537 net.cpp:198] BatchNorm36 needs backward computation.
I0930 11:17:10.542346  3537 net.cpp:198] Convolution36 needs backward computation.
I0930 11:17:10.542356  3537 net.cpp:198] elu_conv34 needs backward computation.
I0930 11:17:10.542358  3537 net.cpp:198] Scale35 needs backward computation.
I0930 11:17:10.542361  3537 net.cpp:198] BatchNorm35 needs backward computation.
I0930 11:17:10.542363  3537 net.cpp:198] Convolution35 needs backward computation.
I0930 11:17:10.542366  3537 net.cpp:198] Eltwise16_elu_conv33_0_split needs backward computation.
I0930 11:17:10.542368  3537 net.cpp:198] elu_conv33 needs backward computation.
I0930 11:17:10.542371  3537 net.cpp:198] Eltwise16 needs backward computation.
I0930 11:17:10.542374  3537 net.cpp:198] Scale34 needs backward computation.
I0930 11:17:10.542376  3537 net.cpp:198] BatchNorm34 needs backward computation.
I0930 11:17:10.542379  3537 net.cpp:198] Convolution34 needs backward computation.
I0930 11:17:10.542382  3537 net.cpp:198] elu_conv32 needs backward computation.
I0930 11:17:10.542384  3537 net.cpp:198] Scale33 needs backward computation.
I0930 11:17:10.542387  3537 net.cpp:198] BatchNorm33 needs backward computation.
I0930 11:17:10.542389  3537 net.cpp:198] Convolution33 needs backward computation.
I0930 11:17:10.542392  3537 net.cpp:198] Eltwise15_elu_conv31_0_split needs backward computation.
I0930 11:17:10.542397  3537 net.cpp:198] elu_conv31 needs backward computation.
I0930 11:17:10.542399  3537 net.cpp:198] Eltwise15 needs backward computation.
I0930 11:17:10.542402  3537 net.cpp:198] Scale32 needs backward computation.
I0930 11:17:10.542404  3537 net.cpp:198] BatchNorm32 needs backward computation.
I0930 11:17:10.542407  3537 net.cpp:198] Convolution32 needs backward computation.
I0930 11:17:10.542409  3537 net.cpp:198] elu_conv30 needs backward computation.
I0930 11:17:10.542412  3537 net.cpp:198] Scale31 needs backward computation.
I0930 11:17:10.542414  3537 net.cpp:198] BatchNorm31 needs backward computation.
I0930 11:17:10.542418  3537 net.cpp:198] Convolution31 needs backward computation.
I0930 11:17:10.542419  3537 net.cpp:198] Eltwise14_elu_conv29_0_split needs backward computation.
I0930 11:17:10.542423  3537 net.cpp:198] elu_conv29 needs backward computation.
I0930 11:17:10.542425  3537 net.cpp:198] Eltwise14 needs backward computation.
I0930 11:17:10.542428  3537 net.cpp:198] Scale30 needs backward computation.
I0930 11:17:10.542430  3537 net.cpp:198] BatchNorm30 needs backward computation.
I0930 11:17:10.542433  3537 net.cpp:198] Convolution30 needs backward computation.
I0930 11:17:10.542436  3537 net.cpp:198] elu_conv28 needs backward computation.
I0930 11:17:10.542438  3537 net.cpp:198] Scale29 needs backward computation.
I0930 11:17:10.542441  3537 net.cpp:198] BatchNorm29 needs backward computation.
I0930 11:17:10.542443  3537 net.cpp:198] Convolution29 needs backward computation.
I0930 11:17:10.542446  3537 net.cpp:198] Eltwise13_elu_conv27_0_split needs backward computation.
I0930 11:17:10.542449  3537 net.cpp:198] elu_conv27 needs backward computation.
I0930 11:17:10.542451  3537 net.cpp:198] Eltwise13 needs backward computation.
I0930 11:17:10.542454  3537 net.cpp:198] Scale28 needs backward computation.
I0930 11:17:10.542457  3537 net.cpp:198] BatchNorm28 needs backward computation.
I0930 11:17:10.542459  3537 net.cpp:198] Convolution28 needs backward computation.
I0930 11:17:10.542462  3537 net.cpp:198] elu_conv26 needs backward computation.
I0930 11:17:10.542464  3537 net.cpp:198] Scale27 needs backward computation.
I0930 11:17:10.542467  3537 net.cpp:198] BatchNorm27 needs backward computation.
I0930 11:17:10.542469  3537 net.cpp:198] Convolution27 needs backward computation.
I0930 11:17:10.542472  3537 net.cpp:198] Eltwise12_elu_conv25_0_split needs backward computation.
I0930 11:17:10.542475  3537 net.cpp:198] elu_conv25 needs backward computation.
I0930 11:17:10.542477  3537 net.cpp:198] Eltwise12 needs backward computation.
I0930 11:17:10.542480  3537 net.cpp:198] Scale26 needs backward computation.
I0930 11:17:10.542484  3537 net.cpp:198] BatchNorm26 needs backward computation.
I0930 11:17:10.542485  3537 net.cpp:198] Convolution26 needs backward computation.
I0930 11:17:10.542491  3537 net.cpp:198] elu_conv24 needs backward computation.
I0930 11:17:10.542495  3537 net.cpp:198] Scale25 needs backward computation.
I0930 11:17:10.542496  3537 net.cpp:198] BatchNorm25 needs backward computation.
I0930 11:17:10.542500  3537 net.cpp:198] Convolution25 needs backward computation.
I0930 11:17:10.542501  3537 net.cpp:198] Eltwise11_elu_conv23_0_split needs backward computation.
I0930 11:17:10.542505  3537 net.cpp:198] elu_conv23 needs backward computation.
I0930 11:17:10.542507  3537 net.cpp:198] Eltwise11 needs backward computation.
I0930 11:17:10.542510  3537 net.cpp:198] Scale24 needs backward computation.
I0930 11:17:10.542512  3537 net.cpp:198] BatchNorm24 needs backward computation.
I0930 11:17:10.542515  3537 net.cpp:198] Convolution24 needs backward computation.
I0930 11:17:10.542517  3537 net.cpp:198] elu_conv22 needs backward computation.
I0930 11:17:10.542529  3537 net.cpp:198] Scale23 needs backward computation.
I0930 11:17:10.542534  3537 net.cpp:198] BatchNorm23 needs backward computation.
I0930 11:17:10.542538  3537 net.cpp:198] Convolution23 needs backward computation.
I0930 11:17:10.542542  3537 net.cpp:198] Eltwise10_elu_conv21_0_split needs backward computation.
I0930 11:17:10.542546  3537 net.cpp:198] elu_conv21 needs backward computation.
I0930 11:17:10.542551  3537 net.cpp:198] Eltwise10 needs backward computation.
I0930 11:17:10.542553  3537 net.cpp:198] Scale22 needs backward computation.
I0930 11:17:10.542557  3537 net.cpp:198] BatchNorm22 needs backward computation.
I0930 11:17:10.542559  3537 net.cpp:198] Convolution22 needs backward computation.
I0930 11:17:10.542562  3537 net.cpp:198] elu_conv20 needs backward computation.
I0930 11:17:10.542564  3537 net.cpp:198] Scale21 needs backward computation.
I0930 11:17:10.542567  3537 net.cpp:198] BatchNorm21 needs backward computation.
I0930 11:17:10.542569  3537 net.cpp:198] Convolution21 needs backward computation.
I0930 11:17:10.542572  3537 net.cpp:198] Scale20 needs backward computation.
I0930 11:17:10.542574  3537 net.cpp:198] BatchNorm20 needs backward computation.
I0930 11:17:10.542577  3537 net.cpp:198] Convolution20 needs backward computation.
I0930 11:17:10.542579  3537 net.cpp:198] Eltwise9_elu_conv19_0_split needs backward computation.
I0930 11:17:10.542582  3537 net.cpp:198] elu_conv19 needs backward computation.
I0930 11:17:10.542585  3537 net.cpp:198] Eltwise9 needs backward computation.
I0930 11:17:10.542588  3537 net.cpp:198] Scale19 needs backward computation.
I0930 11:17:10.542592  3537 net.cpp:198] BatchNorm19 needs backward computation.
I0930 11:17:10.573022  3537 net.cpp:198] Convolution19 needs backward computation.
I0930 11:17:10.573034  3537 net.cpp:198] elu_conv18 needs backward computation.
I0930 11:17:10.573042  3537 net.cpp:198] Scale18 needs backward computation.
I0930 11:17:10.573046  3537 net.cpp:198] BatchNorm18 needs backward computation.
I0930 11:17:10.573050  3537 net.cpp:198] Convolution18 needs backward computation.
I0930 11:17:10.573056  3537 net.cpp:198] Eltwise8_elu_conv17_0_split needs backward computation.
I0930 11:17:10.573060  3537 net.cpp:198] elu_conv17 needs backward computation.
I0930 11:17:10.573065  3537 net.cpp:198] Eltwise8 needs backward computation.
I0930 11:17:10.573067  3537 net.cpp:198] Scale17 needs backward computation.
I0930 11:17:10.573071  3537 net.cpp:198] BatchNorm17 needs backward computation.
I0930 11:17:10.573072  3537 net.cpp:198] Convolution17 needs backward computation.
I0930 11:17:10.573076  3537 net.cpp:198] elu_conv16 needs backward computation.
I0930 11:17:10.573077  3537 net.cpp:198] Scale16 needs backward computation.
I0930 11:17:10.573081  3537 net.cpp:198] BatchNorm16 needs backward computation.
I0930 11:17:10.573082  3537 net.cpp:198] Convolution16 needs backward computation.
I0930 11:17:10.573086  3537 net.cpp:198] Eltwise7_elu_conv15_0_split needs backward computation.
I0930 11:17:10.573088  3537 net.cpp:198] elu_conv15 needs backward computation.
I0930 11:17:10.573091  3537 net.cpp:198] Eltwise7 needs backward computation.
I0930 11:17:10.573101  3537 net.cpp:198] Scale15 needs backward computation.
I0930 11:17:10.573104  3537 net.cpp:198] BatchNorm15 needs backward computation.
I0930 11:17:10.573107  3537 net.cpp:198] Convolution15 needs backward computation.
I0930 11:17:10.573110  3537 net.cpp:198] elu_conv14 needs backward computation.
I0930 11:17:10.573112  3537 net.cpp:198] Scale14 needs backward computation.
I0930 11:17:10.573115  3537 net.cpp:198] BatchNorm14 needs backward computation.
I0930 11:17:10.573117  3537 net.cpp:198] Convolution14 needs backward computation.
I0930 11:17:10.573120  3537 net.cpp:198] Eltwise6_elu_conv13_0_split needs backward computation.
I0930 11:17:10.573123  3537 net.cpp:198] elu_conv13 needs backward computation.
I0930 11:17:10.573125  3537 net.cpp:198] Eltwise6 needs backward computation.
I0930 11:17:10.573128  3537 net.cpp:198] Scale13 needs backward computation.
I0930 11:17:10.573132  3537 net.cpp:198] BatchNorm13 needs backward computation.
I0930 11:17:10.573133  3537 net.cpp:198] Convolution13 needs backward computation.
I0930 11:17:10.573137  3537 net.cpp:198] elu_conv12 needs backward computation.
I0930 11:17:10.573138  3537 net.cpp:198] Scale12 needs backward computation.
I0930 11:17:10.573141  3537 net.cpp:198] BatchNorm12 needs backward computation.
I0930 11:17:10.573143  3537 net.cpp:198] Convolution12 needs backward computation.
I0930 11:17:10.573146  3537 net.cpp:198] Eltwise5_elu_conv11_0_split needs backward computation.
I0930 11:17:10.573149  3537 net.cpp:198] elu_conv11 needs backward computation.
I0930 11:17:10.573151  3537 net.cpp:198] Eltwise5 needs backward computation.
I0930 11:17:10.573154  3537 net.cpp:198] Scale11 needs backward computation.
I0930 11:17:10.573158  3537 net.cpp:198] BatchNorm11 needs backward computation.
I0930 11:17:10.573159  3537 net.cpp:198] Convolution11 needs backward computation.
I0930 11:17:10.573163  3537 net.cpp:198] elu_conv10 needs backward computation.
I0930 11:17:10.573165  3537 net.cpp:198] Scale10 needs backward computation.
I0930 11:17:10.573168  3537 net.cpp:198] BatchNorm10 needs backward computation.
I0930 11:17:10.573170  3537 net.cpp:198] Convolution10 needs backward computation.
I0930 11:17:10.573173  3537 net.cpp:198] Eltwise4_elu_conv9_0_split needs backward computation.
I0930 11:17:10.573175  3537 net.cpp:198] elu_conv9 needs backward computation.
I0930 11:17:10.573179  3537 net.cpp:198] Eltwise4 needs backward computation.
I0930 11:17:10.573182  3537 net.cpp:198] Scale9 needs backward computation.
I0930 11:17:10.573185  3537 net.cpp:198] BatchNorm9 needs backward computation.
I0930 11:17:10.573187  3537 net.cpp:198] Convolution9 needs backward computation.
I0930 11:17:10.573190  3537 net.cpp:198] elu_conv8 needs backward computation.
I0930 11:17:10.573194  3537 net.cpp:198] Scale8 needs backward computation.
I0930 11:17:10.573196  3537 net.cpp:198] BatchNorm8 needs backward computation.
I0930 11:17:10.573199  3537 net.cpp:198] Convolution8 needs backward computation.
I0930 11:17:10.573202  3537 net.cpp:198] Eltwise3_elu_conv7_0_split needs backward computation.
I0930 11:17:10.573205  3537 net.cpp:198] elu_conv7 needs backward computation.
I0930 11:17:10.573207  3537 net.cpp:198] Eltwise3 needs backward computation.
I0930 11:17:10.573210  3537 net.cpp:198] Scale7 needs backward computation.
I0930 11:17:10.573213  3537 net.cpp:198] BatchNorm7 needs backward computation.
I0930 11:17:10.573215  3537 net.cpp:198] Convolution7 needs backward computation.
I0930 11:17:10.573218  3537 net.cpp:198] elu_conv6 needs backward computation.
I0930 11:17:10.573221  3537 net.cpp:198] Scale6 needs backward computation.
I0930 11:17:10.573223  3537 net.cpp:198] BatchNorm6 needs backward computation.
I0930 11:17:10.573225  3537 net.cpp:198] Convolution6 needs backward computation.
I0930 11:17:10.573230  3537 net.cpp:198] Eltwise2_elu_conv5_0_split needs backward computation.
I0930 11:17:10.573231  3537 net.cpp:198] elu_conv5 needs backward computation.
I0930 11:17:10.573235  3537 net.cpp:198] Eltwise2 needs backward computation.
I0930 11:17:10.573237  3537 net.cpp:198] Scale5 needs backward computation.
I0930 11:17:10.573243  3537 net.cpp:198] BatchNorm5 needs backward computation.
I0930 11:17:10.573246  3537 net.cpp:198] Convolution5 needs backward computation.
I0930 11:17:10.573249  3537 net.cpp:198] elu_conv4 needs backward computation.
I0930 11:17:10.573251  3537 net.cpp:198] Scale4 needs backward computation.
I0930 11:17:10.573254  3537 net.cpp:198] BatchNorm4 needs backward computation.
I0930 11:17:10.573256  3537 net.cpp:198] Convolution4 needs backward computation.
I0930 11:17:10.573259  3537 net.cpp:198] Eltwise1_elu_conv3_0_split needs backward computation.
I0930 11:17:10.573262  3537 net.cpp:198] elu_conv3 needs backward computation.
I0930 11:17:10.573266  3537 net.cpp:198] Eltwise1 needs backward computation.
I0930 11:17:10.573268  3537 net.cpp:198] Scale3 needs backward computation.
I0930 11:17:10.573271  3537 net.cpp:198] BatchNorm3 needs backward computation.
I0930 11:17:10.573273  3537 net.cpp:198] Convolution3 needs backward computation.
I0930 11:17:10.573276  3537 net.cpp:198] elu_conv2 needs backward computation.
I0930 11:17:10.573278  3537 net.cpp:198] Scale2 needs backward computation.
I0930 11:17:10.573281  3537 net.cpp:198] BatchNorm2 needs backward computation.
I0930 11:17:10.573283  3537 net.cpp:198] Convolution2 needs backward computation.
I0930 11:17:10.573287  3537 net.cpp:198] Convolution1_elu_conv1_0_split needs backward computation.
I0930 11:17:10.573289  3537 net.cpp:198] elu_conv1 needs backward computation.
I0930 11:17:10.573292  3537 net.cpp:198] Scale1 needs backward computation.
I0930 11:17:10.573294  3537 net.cpp:198] BatchNorm1 needs backward computation.
I0930 11:17:10.573297  3537 net.cpp:198] Convolution1 needs backward computation.
I0930 11:17:10.573300  3537 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I0930 11:17:10.573303  3537 net.cpp:200] Data1 does not need backward computation.
I0930 11:17:10.573305  3537 net.cpp:242] This network produces output Accuracy1
I0930 11:17:10.573309  3537 net.cpp:242] This network produces output SoftmaxWithLoss1
I0930 11:17:10.573415  3537 net.cpp:255] Network initialization done.
I0930 11:17:10.574110  3537 solver.cpp:56] Solver scaffolding done.
I0930 11:17:10.583979  3537 caffe.cpp:248] Starting Optimization
I0930 11:17:10.583989  3537 solver.cpp:272] Solving resnet_cifar10
I0930 11:17:10.583992  3537 solver.cpp:273] Learning Rate Policy: multistep
I0930 11:17:10.588821  3537 solver.cpp:330] Iteration 0, Testing net (#0)
I0930 11:17:13.754290  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:17:13.882180  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I0930 11:17:13.882217  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I0930 11:17:14.054221  3537 solver.cpp:218] Iteration 0 (0 iter/s, 3.47013s/100 iters), loss = 2.35041
I0930 11:17:14.054251  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.35041 (* 1 = 2.35041 loss)
I0930 11:17:14.054268  3537 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I0930 11:17:27.478449  3537 solver.cpp:218] Iteration 100 (7.44931 iter/s, 13.4241s/100 iters), loss = 1.63666
I0930 11:17:27.478478  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.63666 (* 1 = 1.63666 loss)
I0930 11:17:27.478484  3537 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I0930 11:17:40.923213  3537 solver.cpp:218] Iteration 200 (7.43793 iter/s, 13.4446s/100 iters), loss = 1.66529
I0930 11:17:40.923413  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.66529 (* 1 = 1.66529 loss)
I0930 11:17:40.923421  3537 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I0930 11:17:54.345270  3537 solver.cpp:218] Iteration 300 (7.45061 iter/s, 13.4217s/100 iters), loss = 1.31202
I0930 11:17:54.345311  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.31202 (* 1 = 1.31202 loss)
I0930 11:17:54.345319  3537 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I0930 11:18:07.768826  3537 solver.cpp:218] Iteration 400 (7.44969 iter/s, 13.4234s/100 iters), loss = 1.17465
I0930 11:18:07.768856  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.17465 (* 1 = 1.17465 loss)
I0930 11:18:07.768862  3537 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I0930 11:18:20.523689  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:18:21.058302  3537 solver.cpp:330] Iteration 500, Testing net (#0)
I0930 11:18:24.157050  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:18:24.286522  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.2522
I0930 11:18:24.286548  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.58532 (* 1 = 3.58532 loss)
I0930 11:18:24.420106  3537 solver.cpp:218] Iteration 500 (6.00561 iter/s, 16.6511s/100 iters), loss = 1.19173
I0930 11:18:24.420136  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.19173 (* 1 = 1.19173 loss)
I0930 11:18:24.420143  3537 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I0930 11:18:37.869163  3537 solver.cpp:218] Iteration 600 (7.43555 iter/s, 13.4489s/100 iters), loss = 1.13139
I0930 11:18:37.869191  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.13139 (* 1 = 1.13139 loss)
I0930 11:18:37.869199  3537 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I0930 11:18:51.295315  3537 solver.cpp:218] Iteration 700 (7.44824 iter/s, 13.426s/100 iters), loss = 1.04862
I0930 11:18:51.295454  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.04862 (* 1 = 1.04862 loss)
I0930 11:18:51.295461  3537 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I0930 11:19:04.739800  3537 solver.cpp:218] Iteration 800 (7.43813 iter/s, 13.4442s/100 iters), loss = 1.01844
I0930 11:19:04.739830  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.01844 (* 1 = 1.01844 loss)
I0930 11:19:04.739836  3537 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I0930 11:19:18.177696  3537 solver.cpp:218] Iteration 900 (7.44173 iter/s, 13.4377s/100 iters), loss = 0.811541
I0930 11:19:18.177727  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.811541 (* 1 = 0.811541 loss)
I0930 11:19:18.177733  3537 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I0930 11:19:30.947765  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:19:31.486083  3537 solver.cpp:330] Iteration 1000, Testing net (#0)
I0930 11:19:34.587576  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:19:34.716512  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5247
I0930 11:19:34.716537  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.5864 (* 1 = 1.5864 loss)
I0930 11:19:34.850697  3537 solver.cpp:218] Iteration 1000 (5.99779 iter/s, 16.6728s/100 iters), loss = 1.11449
I0930 11:19:34.850730  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.11449 (* 1 = 1.11449 loss)
I0930 11:19:34.850738  3537 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I0930 11:19:48.271914  3537 solver.cpp:218] Iteration 1100 (7.45097 iter/s, 13.4211s/100 iters), loss = 0.747176
I0930 11:19:48.271944  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.747176 (* 1 = 0.747176 loss)
I0930 11:19:48.271951  3537 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I0930 11:20:01.720213  3537 solver.cpp:218] Iteration 1200 (7.43597 iter/s, 13.4481s/100 iters), loss = 0.907399
I0930 11:20:01.720329  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.907399 (* 1 = 0.907399 loss)
I0930 11:20:01.720335  3537 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I0930 11:20:15.165040  3537 solver.cpp:218] Iteration 1300 (7.43793 iter/s, 13.4446s/100 iters), loss = 0.857576
I0930 11:20:15.165071  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.857576 (* 1 = 0.857576 loss)
I0930 11:20:15.165077  3537 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I0930 11:20:28.614743  3537 solver.cpp:218] Iteration 1400 (7.43518 iter/s, 13.4496s/100 iters), loss = 0.685504
I0930 11:20:28.614775  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.685504 (* 1 = 0.685504 loss)
I0930 11:20:28.614781  3537 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I0930 11:20:41.389055  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:20:41.926070  3537 solver.cpp:330] Iteration 1500, Testing net (#0)
I0930 11:20:45.029862  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:20:45.159178  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4973
I0930 11:20:45.159204  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.83225 (* 1 = 1.83225 loss)
I0930 11:20:45.292920  3537 solver.cpp:218] Iteration 1500 (5.99592 iter/s, 16.678s/100 iters), loss = 0.880891
I0930 11:20:45.292951  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.880891 (* 1 = 0.880891 loss)
I0930 11:20:45.292958  3537 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I0930 11:20:58.740914  3537 solver.cpp:218] Iteration 1600 (7.43612 iter/s, 13.4479s/100 iters), loss = 0.552176
I0930 11:20:58.740945  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.552176 (* 1 = 0.552176 loss)
I0930 11:20:58.740954  3537 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I0930 11:21:12.170352  3537 solver.cpp:218] Iteration 1700 (7.44639 iter/s, 13.4293s/100 iters), loss = 0.674933
I0930 11:21:12.170469  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.674933 (* 1 = 0.674933 loss)
I0930 11:21:12.170487  3537 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I0930 11:21:25.610754  3537 solver.cpp:218] Iteration 1800 (7.44037 iter/s, 13.4402s/100 iters), loss = 0.698364
I0930 11:21:25.610785  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.698364 (* 1 = 0.698364 loss)
I0930 11:21:25.610807  3537 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I0930 11:21:39.057020  3537 solver.cpp:218] Iteration 1900 (7.43707 iter/s, 13.4462s/100 iters), loss = 0.700988
I0930 11:21:39.057054  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.700988 (* 1 = 0.700988 loss)
I0930 11:21:39.057061  3537 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I0930 11:21:51.835469  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:21:52.375383  3537 solver.cpp:330] Iteration 2000, Testing net (#0)
I0930 11:21:55.474481  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:21:55.603713  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6814
I0930 11:21:55.603739  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.958514 (* 1 = 0.958514 loss)
I0930 11:21:55.736701  3537 solver.cpp:218] Iteration 2000 (5.99536 iter/s, 16.6796s/100 iters), loss = 0.746062
I0930 11:21:55.736732  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.746062 (* 1 = 0.746062 loss)
I0930 11:21:55.736738  3537 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I0930 11:22:09.171413  3537 solver.cpp:218] Iteration 2100 (7.44346 iter/s, 13.4346s/100 iters), loss = 0.512819
I0930 11:22:09.171444  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.512819 (* 1 = 0.512819 loss)
I0930 11:22:09.171452  3537 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I0930 11:22:22.627526  3537 solver.cpp:218] Iteration 2200 (7.43162 iter/s, 13.456s/100 iters), loss = 0.61165
I0930 11:22:22.627671  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.61165 (* 1 = 0.61165 loss)
I0930 11:22:22.627679  3537 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I0930 11:22:36.067307  3537 solver.cpp:218] Iteration 2300 (7.44071 iter/s, 13.4396s/100 iters), loss = 0.690005
I0930 11:22:36.067337  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.690005 (* 1 = 0.690005 loss)
I0930 11:22:36.067354  3537 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I0930 11:22:49.505838  3537 solver.cpp:218] Iteration 2400 (7.44135 iter/s, 13.4384s/100 iters), loss = 0.512078
I0930 11:22:49.505882  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.512078 (* 1 = 0.512078 loss)
I0930 11:22:49.505900  3537 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I0930 11:23:02.274188  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:23:02.811053  3537 solver.cpp:330] Iteration 2500, Testing net (#0)
I0930 11:23:05.910363  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:23:06.039451  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6621
I0930 11:23:06.039477  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.948556 (* 1 = 0.948556 loss)
I0930 11:23:06.172507  3537 solver.cpp:218] Iteration 2500 (6.00004 iter/s, 16.6665s/100 iters), loss = 0.716432
I0930 11:23:06.172543  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.716432 (* 1 = 0.716432 loss)
I0930 11:23:06.172552  3537 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I0930 11:23:19.614276  3537 solver.cpp:218] Iteration 2600 (7.43955 iter/s, 13.4417s/100 iters), loss = 0.509488
I0930 11:23:19.614315  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.509488 (* 1 = 0.509488 loss)
I0930 11:23:19.614322  3537 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I0930 11:23:33.045575  3537 solver.cpp:218] Iteration 2700 (7.44535 iter/s, 13.4312s/100 iters), loss = 0.517214
I0930 11:23:33.045689  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.517214 (* 1 = 0.517214 loss)
I0930 11:23:33.045697  3537 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I0930 11:23:46.487838  3537 solver.cpp:218] Iteration 2800 (7.43931 iter/s, 13.4421s/100 iters), loss = 0.652978
I0930 11:23:46.487874  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.652978 (* 1 = 0.652978 loss)
I0930 11:23:46.487882  3537 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I0930 11:23:59.929639  3537 solver.cpp:218] Iteration 2900 (7.43953 iter/s, 13.4417s/100 iters), loss = 0.613682
I0930 11:23:59.929669  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.613682 (* 1 = 0.613682 loss)
I0930 11:23:59.929685  3537 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I0930 11:24:12.706346  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:24:13.250952  3537 solver.cpp:330] Iteration 3000, Testing net (#0)
I0930 11:24:16.351462  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:24:16.480737  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6843
I0930 11:24:16.480773  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.893478 (* 1 = 0.893478 loss)
I0930 11:24:16.614622  3537 solver.cpp:218] Iteration 3000 (5.99345 iter/s, 16.6849s/100 iters), loss = 0.494686
I0930 11:24:16.614656  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.494686 (* 1 = 0.494686 loss)
I0930 11:24:16.614663  3537 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I0930 11:24:30.040338  3537 solver.cpp:218] Iteration 3100 (7.44844 iter/s, 13.4256s/100 iters), loss = 0.447366
I0930 11:24:30.040366  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.447366 (* 1 = 0.447366 loss)
I0930 11:24:30.040372  3537 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I0930 11:24:43.498549  3537 solver.cpp:218] Iteration 3200 (7.43046 iter/s, 13.4581s/100 iters), loss = 0.59047
I0930 11:24:43.498692  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.59047 (* 1 = 0.59047 loss)
I0930 11:24:43.498700  3537 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I0930 11:24:56.945801  3537 solver.cpp:218] Iteration 3300 (7.43657 iter/s, 13.4471s/100 iters), loss = 0.646491
I0930 11:24:56.945833  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.646491 (* 1 = 0.646491 loss)
I0930 11:24:56.945852  3537 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I0930 11:25:10.393009  3537 solver.cpp:218] Iteration 3400 (7.43654 iter/s, 13.4471s/100 iters), loss = 0.494817
I0930 11:25:10.393046  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.494817 (* 1 = 0.494817 loss)
I0930 11:25:10.393055  3537 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I0930 11:25:23.163753  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:25:23.699686  3537 solver.cpp:330] Iteration 3500, Testing net (#0)
I0930 11:25:26.802705  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:25:26.932076  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6865
I0930 11:25:26.932111  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.894469 (* 1 = 0.894469 loss)
I0930 11:25:27.065340  3537 solver.cpp:218] Iteration 3500 (5.998 iter/s, 16.6722s/100 iters), loss = 0.577282
I0930 11:25:27.065371  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.577282 (* 1 = 0.577282 loss)
I0930 11:25:27.065378  3537 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I0930 11:25:40.527124  3537 solver.cpp:218] Iteration 3600 (7.42849 iter/s, 13.4617s/100 iters), loss = 0.565961
I0930 11:25:40.527158  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.565961 (* 1 = 0.565961 loss)
I0930 11:25:40.527163  3537 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I0930 11:25:53.975152  3537 solver.cpp:218] Iteration 3700 (7.43608 iter/s, 13.4479s/100 iters), loss = 0.573357
I0930 11:25:53.975263  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.573357 (* 1 = 0.573357 loss)
I0930 11:25:53.975271  3537 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I0930 11:26:07.427966  3537 solver.cpp:218] Iteration 3800 (7.43348 iter/s, 13.4527s/100 iters), loss = 0.580415
I0930 11:26:07.428000  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.580415 (* 1 = 0.580415 loss)
I0930 11:26:07.428007  3537 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I0930 11:26:20.880430  3537 solver.cpp:218] Iteration 3900 (7.43363 iter/s, 13.4524s/100 iters), loss = 0.472905
I0930 11:26:20.880460  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.472905 (* 1 = 0.472905 loss)
I0930 11:26:20.880466  3537 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I0930 11:26:33.670363  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:26:34.216696  3537 solver.cpp:330] Iteration 4000, Testing net (#0)
I0930 11:26:37.321389  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:26:37.455464  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7262
I0930 11:26:37.455500  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.782728 (* 1 = 0.782728 loss)
I0930 11:26:37.589362  3537 solver.cpp:218] Iteration 4000 (5.98486 iter/s, 16.7088s/100 iters), loss = 0.437998
I0930 11:26:37.589397  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.437998 (* 1 = 0.437998 loss)
I0930 11:26:37.589404  3537 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I0930 11:26:51.029455  3537 solver.cpp:218] Iteration 4100 (7.44048 iter/s, 13.44s/100 iters), loss = 0.401253
I0930 11:26:51.029484  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.401253 (* 1 = 0.401253 loss)
I0930 11:26:51.029490  3537 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I0930 11:27:04.485049  3537 solver.cpp:218] Iteration 4200 (7.4319 iter/s, 13.4555s/100 iters), loss = 0.517781
I0930 11:27:04.485182  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.517781 (* 1 = 0.517781 loss)
I0930 11:27:04.485190  3537 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I0930 11:27:17.935802  3537 solver.cpp:218] Iteration 4300 (7.43463 iter/s, 13.4506s/100 iters), loss = 0.569326
I0930 11:27:17.935843  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.569326 (* 1 = 0.569326 loss)
I0930 11:27:17.935849  3537 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I0930 11:27:31.387748  3537 solver.cpp:218] Iteration 4400 (7.43392 iter/s, 13.4518s/100 iters), loss = 0.450349
I0930 11:27:31.387780  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.450349 (* 1 = 0.450349 loss)
I0930 11:27:31.387789  3537 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I0930 11:27:44.158280  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:27:44.694330  3537 solver.cpp:330] Iteration 4500, Testing net (#0)
I0930 11:27:47.800343  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:27:47.929036  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7003
I0930 11:27:47.929059  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.831441 (* 1 = 0.831441 loss)
I0930 11:27:48.063220  3537 solver.cpp:218] Iteration 4500 (5.99687 iter/s, 16.6754s/100 iters), loss = 0.410367
I0930 11:27:48.063249  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.410367 (* 1 = 0.410367 loss)
I0930 11:27:48.063256  3537 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I0930 11:28:01.527107  3537 solver.cpp:218] Iteration 4600 (7.42733 iter/s, 13.4638s/100 iters), loss = 0.408188
I0930 11:28:01.527137  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.408188 (* 1 = 0.408188 loss)
I0930 11:28:01.527144  3537 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I0930 11:28:14.985146  3537 solver.cpp:218] Iteration 4700 (7.43055 iter/s, 13.458s/100 iters), loss = 0.425669
I0930 11:28:14.985265  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.425669 (* 1 = 0.425669 loss)
I0930 11:28:14.985281  3537 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I0930 11:28:28.446455  3537 solver.cpp:218] Iteration 4800 (7.42879 iter/s, 13.4611s/100 iters), loss = 0.480931
I0930 11:28:28.446486  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.480931 (* 1 = 0.480931 loss)
I0930 11:28:28.446493  3537 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I0930 11:28:41.905800  3537 solver.cpp:218] Iteration 4900 (7.42983 iter/s, 13.4593s/100 iters), loss = 0.502868
I0930 11:28:41.905830  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.502868 (* 1 = 0.502868 loss)
I0930 11:28:41.905836  3537 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I0930 11:28:54.704666  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:28:55.252583  3537 solver.cpp:330] Iteration 5000, Testing net (#0)
I0930 11:28:58.359839  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:28:58.489315  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6801
I0930 11:28:58.489341  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.87686 (* 1 = 0.87686 loss)
I0930 11:28:58.623554  3537 solver.cpp:218] Iteration 5000 (5.9817 iter/s, 16.7177s/100 iters), loss = 0.411984
I0930 11:28:58.623600  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.411984 (* 1 = 0.411984 loss)
I0930 11:28:58.623607  3537 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I0930 11:29:12.065085  3537 solver.cpp:218] Iteration 5100 (7.43968 iter/s, 13.4414s/100 iters), loss = 0.345777
I0930 11:29:12.065114  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.345777 (* 1 = 0.345777 loss)
I0930 11:29:12.065121  3537 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I0930 11:29:25.523847  3537 solver.cpp:218] Iteration 5200 (7.43015 iter/s, 13.4587s/100 iters), loss = 0.407355
I0930 11:29:25.523993  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.407355 (* 1 = 0.407355 loss)
I0930 11:29:25.524003  3537 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I0930 11:29:38.977972  3537 solver.cpp:218] Iteration 5300 (7.43277 iter/s, 13.4539s/100 iters), loss = 0.5486
I0930 11:29:38.978003  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.5486 (* 1 = 0.5486 loss)
I0930 11:29:38.978008  3537 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I0930 11:29:52.433280  3537 solver.cpp:218] Iteration 5400 (7.43206 iter/s, 13.4552s/100 iters), loss = 0.38559
I0930 11:29:52.433311  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.38559 (* 1 = 0.38559 loss)
I0930 11:29:52.433320  3537 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I0930 11:30:05.212252  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:30:05.747344  3537 solver.cpp:330] Iteration 5500, Testing net (#0)
I0930 11:30:08.852216  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:30:08.980932  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7185
I0930 11:30:08.980967  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.803206 (* 1 = 0.803206 loss)
I0930 11:30:09.114526  3537 solver.cpp:218] Iteration 5500 (5.99479 iter/s, 16.6812s/100 iters), loss = 0.396819
I0930 11:30:09.114557  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.396819 (* 1 = 0.396819 loss)
I0930 11:30:09.114563  3537 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I0930 11:30:22.568747  3537 solver.cpp:218] Iteration 5600 (7.43266 iter/s, 13.4541s/100 iters), loss = 0.476921
I0930 11:30:22.568778  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.476921 (* 1 = 0.476921 loss)
I0930 11:30:22.568785  3537 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I0930 11:30:36.016337  3537 solver.cpp:218] Iteration 5700 (7.43632 iter/s, 13.4475s/100 iters), loss = 0.436796
I0930 11:30:36.016613  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.436796 (* 1 = 0.436796 loss)
I0930 11:30:36.016624  3537 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I0930 11:30:49.470677  3537 solver.cpp:218] Iteration 5800 (7.43273 iter/s, 13.454s/100 iters), loss = 0.519526
I0930 11:30:49.470719  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.519526 (* 1 = 0.519526 loss)
I0930 11:30:49.470726  3537 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I0930 11:31:02.919301  3537 solver.cpp:218] Iteration 5900 (7.43576 iter/s, 13.4485s/100 iters), loss = 0.479574
I0930 11:31:02.919332  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.479574 (* 1 = 0.479574 loss)
I0930 11:31:02.919339  3537 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I0930 11:31:15.707600  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:31:16.254361  3537 solver.cpp:330] Iteration 6000, Testing net (#0)
I0930 11:31:19.358685  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:31:19.488204  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7494
I0930 11:31:19.488229  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.697483 (* 1 = 0.697483 loss)
I0930 11:31:19.621906  3537 solver.cpp:218] Iteration 6000 (5.98712 iter/s, 16.7025s/100 iters), loss = 0.37557
I0930 11:31:19.621939  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.37557 (* 1 = 0.37557 loss)
I0930 11:31:19.621947  3537 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I0930 11:31:33.065259  3537 solver.cpp:218] Iteration 6100 (7.43867 iter/s, 13.4433s/100 iters), loss = 0.38178
I0930 11:31:33.065289  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.38178 (* 1 = 0.38178 loss)
I0930 11:31:33.065295  3537 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I0930 11:31:46.525012  3537 solver.cpp:218] Iteration 6200 (7.4296 iter/s, 13.4597s/100 iters), loss = 0.389274
I0930 11:31:46.525125  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.389274 (* 1 = 0.389274 loss)
I0930 11:31:46.525147  3537 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I0930 11:31:59.983814  3537 solver.cpp:218] Iteration 6300 (7.43017 iter/s, 13.4586s/100 iters), loss = 0.370351
I0930 11:31:59.983844  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.370351 (* 1 = 0.370351 loss)
I0930 11:31:59.983850  3537 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I0930 11:32:13.450464  3537 solver.cpp:218] Iteration 6400 (7.4258 iter/s, 13.4666s/100 iters), loss = 0.38061
I0930 11:32:13.450507  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.38061 (* 1 = 0.38061 loss)
I0930 11:32:13.450513  3537 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I0930 11:32:26.230945  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:32:26.766218  3537 solver.cpp:330] Iteration 6500, Testing net (#0)
I0930 11:32:29.869088  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:32:29.998303  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7895
I0930 11:32:29.998337  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.614559 (* 1 = 0.614559 loss)
I0930 11:32:30.132575  3537 solver.cpp:218] Iteration 6500 (5.99448 iter/s, 16.682s/100 iters), loss = 0.374435
I0930 11:32:30.132611  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.374435 (* 1 = 0.374435 loss)
I0930 11:32:30.132618  3537 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I0930 11:32:43.588104  3537 solver.cpp:218] Iteration 6600 (7.43194 iter/s, 13.4554s/100 iters), loss = 0.305206
I0930 11:32:43.588136  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305206 (* 1 = 0.305206 loss)
I0930 11:32:43.588143  3537 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I0930 11:32:57.029886  3537 solver.cpp:218] Iteration 6700 (7.43954 iter/s, 13.4417s/100 iters), loss = 0.562943
I0930 11:32:57.030017  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.562943 (* 1 = 0.562943 loss)
I0930 11:32:57.030035  3537 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I0930 11:33:10.484917  3537 solver.cpp:218] Iteration 6800 (7.43226 iter/s, 13.4549s/100 iters), loss = 0.408266
I0930 11:33:10.484949  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.408266 (* 1 = 0.408266 loss)
I0930 11:33:10.484956  3537 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I0930 11:33:23.929750  3537 solver.cpp:218] Iteration 6900 (7.43785 iter/s, 13.4448s/100 iters), loss = 0.365183
I0930 11:33:23.929781  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365183 (* 1 = 0.365183 loss)
I0930 11:33:23.929788  3537 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I0930 11:33:36.710881  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:33:37.258323  3537 solver.cpp:330] Iteration 7000, Testing net (#0)
I0930 11:33:40.364199  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:33:40.493695  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7614
I0930 11:33:40.493731  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.666509 (* 1 = 0.666509 loss)
I0930 11:33:40.626983  3537 solver.cpp:218] Iteration 7000 (5.98905 iter/s, 16.6971s/100 iters), loss = 0.425629
I0930 11:33:40.627017  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.425629 (* 1 = 0.425629 loss)
I0930 11:33:40.627023  3537 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I0930 11:33:54.070735  3537 solver.cpp:218] Iteration 7100 (7.43844 iter/s, 13.4437s/100 iters), loss = 0.386282
I0930 11:33:54.070766  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.386283 (* 1 = 0.386283 loss)
I0930 11:33:54.070772  3537 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I0930 11:34:07.514658  3537 solver.cpp:218] Iteration 7200 (7.43835 iter/s, 13.4438s/100 iters), loss = 0.462404
I0930 11:34:07.514776  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.462404 (* 1 = 0.462404 loss)
I0930 11:34:07.514786  3537 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I0930 11:34:20.972039  3537 solver.cpp:218] Iteration 7300 (7.43096 iter/s, 13.4572s/100 iters), loss = 0.42157
I0930 11:34:20.972079  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.42157 (* 1 = 0.42157 loss)
I0930 11:34:20.972085  3537 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I0930 11:34:34.437891  3537 solver.cpp:218] Iteration 7400 (7.42624 iter/s, 13.4658s/100 iters), loss = 0.364573
I0930 11:34:34.437924  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.364573 (* 1 = 0.364573 loss)
I0930 11:34:34.437932  3537 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I0930 11:34:47.213577  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:34:47.749465  3537 solver.cpp:330] Iteration 7500, Testing net (#0)
I0930 11:34:50.852815  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:34:50.982406  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8014
I0930 11:34:50.982441  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.573168 (* 1 = 0.573168 loss)
I0930 11:34:51.115351  3537 solver.cpp:218] Iteration 7500 (5.99615 iter/s, 16.6774s/100 iters), loss = 0.376218
I0930 11:34:51.115382  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.376218 (* 1 = 0.376218 loss)
I0930 11:34:51.115389  3537 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I0930 11:35:04.580447  3537 solver.cpp:218] Iteration 7600 (7.42665 iter/s, 13.465s/100 iters), loss = 0.381756
I0930 11:35:04.580479  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.381756 (* 1 = 0.381756 loss)
I0930 11:35:04.580487  3537 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I0930 11:35:18.036183  3537 solver.cpp:218] Iteration 7700 (7.43182 iter/s, 13.4557s/100 iters), loss = 0.484703
I0930 11:35:18.036314  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.484703 (* 1 = 0.484703 loss)
I0930 11:35:18.036332  3537 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I0930 11:35:31.499672  3537 solver.cpp:218] Iteration 7800 (7.42759 iter/s, 13.4633s/100 iters), loss = 0.511628
I0930 11:35:31.499704  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.511628 (* 1 = 0.511628 loss)
I0930 11:35:31.499711  3537 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I0930 11:35:44.949659  3537 solver.cpp:218] Iteration 7900 (7.435 iter/s, 13.4499s/100 iters), loss = 0.346289
I0930 11:35:44.949690  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34629 (* 1 = 0.34629 loss)
I0930 11:35:44.949697  3537 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I0930 11:35:57.738497  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:35:58.286398  3537 solver.cpp:330] Iteration 8000, Testing net (#0)
I0930 11:36:01.393759  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:36:01.522250  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7742
I0930 11:36:01.522285  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.647436 (* 1 = 0.647436 loss)
I0930 11:36:01.655690  3537 solver.cpp:218] Iteration 8000 (5.98589 iter/s, 16.7059s/100 iters), loss = 0.40361
I0930 11:36:01.655725  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.40361 (* 1 = 0.40361 loss)
I0930 11:36:01.655731  3537 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I0930 11:36:15.101032  3537 solver.cpp:218] Iteration 8100 (7.43757 iter/s, 13.4453s/100 iters), loss = 0.353607
I0930 11:36:15.101071  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.353608 (* 1 = 0.353608 loss)
I0930 11:36:15.101078  3537 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I0930 11:36:28.559566  3537 solver.cpp:218] Iteration 8200 (7.43028 iter/s, 13.4584s/100 iters), loss = 0.368149
I0930 11:36:28.559677  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.368149 (* 1 = 0.368149 loss)
I0930 11:36:28.559685  3537 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I0930 11:36:41.995225  3537 solver.cpp:218] Iteration 8300 (7.44296 iter/s, 13.4355s/100 iters), loss = 0.463865
I0930 11:36:41.995266  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.463865 (* 1 = 0.463865 loss)
I0930 11:36:41.995272  3537 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I0930 11:36:55.459852  3537 solver.cpp:218] Iteration 8400 (7.42692 iter/s, 13.4645s/100 iters), loss = 0.420949
I0930 11:36:55.459884  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.420949 (* 1 = 0.420949 loss)
I0930 11:36:55.459892  3537 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I0930 11:37:08.235889  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:37:08.775104  3537 solver.cpp:330] Iteration 8500, Testing net (#0)
I0930 11:37:11.876345  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:37:12.005203  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7597
I0930 11:37:12.005228  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.683721 (* 1 = 0.683721 loss)
I0930 11:37:12.138651  3537 solver.cpp:218] Iteration 8500 (5.99567 iter/s, 16.6787s/100 iters), loss = 0.317799
I0930 11:37:12.138682  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.3178 (* 1 = 0.3178 loss)
I0930 11:37:12.138689  3537 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I0930 11:37:25.592357  3537 solver.cpp:218] Iteration 8600 (7.43294 iter/s, 13.4536s/100 iters), loss = 0.314255
I0930 11:37:25.592388  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314255 (* 1 = 0.314255 loss)
I0930 11:37:25.592394  3537 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I0930 11:37:39.041821  3537 solver.cpp:218] Iteration 8700 (7.43528 iter/s, 13.4494s/100 iters), loss = 0.396031
I0930 11:37:39.041939  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.396031 (* 1 = 0.396031 loss)
I0930 11:37:39.041946  3537 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I0930 11:37:52.502269  3537 solver.cpp:218] Iteration 8800 (7.42926 iter/s, 13.4603s/100 iters), loss = 0.372563
I0930 11:37:52.502301  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.372563 (* 1 = 0.372563 loss)
I0930 11:37:52.502307  3537 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I0930 11:38:05.950475  3537 solver.cpp:218] Iteration 8900 (7.43598 iter/s, 13.4481s/100 iters), loss = 0.450301
I0930 11:38:05.950516  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.450301 (* 1 = 0.450301 loss)
I0930 11:38:05.950527  3537 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I0930 11:38:18.736199  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:38:19.281978  3537 solver.cpp:330] Iteration 9000, Testing net (#0)
I0930 11:38:22.387423  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:38:22.516717  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7979
I0930 11:38:22.516753  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.578517 (* 1 = 0.578517 loss)
I0930 11:38:22.650223  3537 solver.cpp:218] Iteration 9000 (5.98815 iter/s, 16.6996s/100 iters), loss = 0.365535
I0930 11:38:22.650256  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365535 (* 1 = 0.365535 loss)
I0930 11:38:22.650264  3537 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I0930 11:38:36.103816  3537 solver.cpp:218] Iteration 9100 (7.433 iter/s, 13.4535s/100 iters), loss = 0.298964
I0930 11:38:36.103855  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298964 (* 1 = 0.298964 loss)
I0930 11:38:36.103863  3537 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I0930 11:38:49.550266  3537 solver.cpp:218] Iteration 9200 (7.43695 iter/s, 13.4464s/100 iters), loss = 0.3831
I0930 11:38:49.550410  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.3831 (* 1 = 0.3831 loss)
I0930 11:38:49.550417  3537 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I0930 11:39:02.990597  3537 solver.cpp:218] Iteration 9300 (7.4404 iter/s, 13.4401s/100 iters), loss = 0.453231
I0930 11:39:02.990625  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.453231 (* 1 = 0.453231 loss)
I0930 11:39:02.990631  3537 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I0930 11:39:16.449060  3537 solver.cpp:218] Iteration 9400 (7.43031 iter/s, 13.4584s/100 iters), loss = 0.232022
I0930 11:39:16.449103  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232023 (* 1 = 0.232023 loss)
I0930 11:39:16.449110  3537 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I0930 11:39:29.226847  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:39:29.762099  3537 solver.cpp:330] Iteration 9500, Testing net (#0)
I0930 11:39:32.865749  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:39:32.994709  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7708
I0930 11:39:32.994745  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.653911 (* 1 = 0.653911 loss)
I0930 11:39:33.128180  3537 solver.cpp:218] Iteration 9500 (5.99556 iter/s, 16.679s/100 iters), loss = 0.325951
I0930 11:39:33.128211  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325951 (* 1 = 0.325951 loss)
I0930 11:39:33.128217  3537 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I0930 11:39:46.585072  3537 solver.cpp:218] Iteration 9600 (7.43118 iter/s, 13.4568s/100 iters), loss = 0.33783
I0930 11:39:46.585101  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337831 (* 1 = 0.337831 loss)
I0930 11:39:46.585108  3537 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I0930 11:40:00.030798  3537 solver.cpp:218] Iteration 9700 (7.43735 iter/s, 13.4457s/100 iters), loss = 0.37304
I0930 11:40:00.030930  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.37304 (* 1 = 0.37304 loss)
I0930 11:40:00.030938  3537 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I0930 11:40:13.497402  3537 solver.cpp:218] Iteration 9800 (7.42587 iter/s, 13.4664s/100 iters), loss = 0.393746
I0930 11:40:13.497433  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.393747 (* 1 = 0.393747 loss)
I0930 11:40:13.497440  3537 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I0930 11:40:26.940367  3537 solver.cpp:218] Iteration 9900 (7.43888 iter/s, 13.4429s/100 iters), loss = 0.361812
I0930 11:40:26.940395  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.361812 (* 1 = 0.361812 loss)
I0930 11:40:26.940402  3537 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I0930 11:40:39.722949  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:40:40.271630  3537 solver.cpp:330] Iteration 10000, Testing net (#0)
I0930 11:40:43.376670  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:40:43.505831  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7853
I0930 11:40:43.505867  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.638389 (* 1 = 0.638389 loss)
I0930 11:40:43.641589  3537 solver.cpp:218] Iteration 10000 (5.98762 iter/s, 16.7011s/100 iters), loss = 0.337163
I0930 11:40:43.641623  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337164 (* 1 = 0.337164 loss)
I0930 11:40:43.641630  3537 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I0930 11:40:57.080099  3537 solver.cpp:218] Iteration 10100 (7.44135 iter/s, 13.4384s/100 iters), loss = 0.316229
I0930 11:40:57.080129  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316229 (* 1 = 0.316229 loss)
I0930 11:40:57.080135  3537 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I0930 11:41:10.534798  3537 solver.cpp:218] Iteration 10200 (7.43239 iter/s, 13.4546s/100 iters), loss = 0.376313
I0930 11:41:10.534885  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.376313 (* 1 = 0.376313 loss)
I0930 11:41:10.534909  3537 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I0930 11:41:23.983441  3537 solver.cpp:218] Iteration 10300 (7.43577 iter/s, 13.4485s/100 iters), loss = 0.395448
I0930 11:41:23.983474  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.395448 (* 1 = 0.395448 loss)
I0930 11:41:23.983489  3537 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I0930 11:41:37.448468  3537 solver.cpp:218] Iteration 10400 (7.42669 iter/s, 13.4649s/100 iters), loss = 0.306773
I0930 11:41:37.448500  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306773 (* 1 = 0.306773 loss)
I0930 11:41:37.448508  3537 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I0930 11:41:50.241181  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:41:50.777169  3537 solver.cpp:330] Iteration 10500, Testing net (#0)
I0930 11:41:53.881036  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:41:54.009878  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7866
I0930 11:41:54.009913  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.622465 (* 1 = 0.622465 loss)
I0930 11:41:54.143663  3537 solver.cpp:218] Iteration 10500 (5.98978 iter/s, 16.6951s/100 iters), loss = 0.381202
I0930 11:41:54.143694  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.381202 (* 1 = 0.381202 loss)
I0930 11:41:54.143700  3537 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I0930 11:42:07.597185  3537 solver.cpp:218] Iteration 10600 (7.43304 iter/s, 13.4534s/100 iters), loss = 0.272439
I0930 11:42:07.597218  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272439 (* 1 = 0.272439 loss)
I0930 11:42:07.597234  3537 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I0930 11:42:21.058166  3537 solver.cpp:218] Iteration 10700 (7.42892 iter/s, 13.4609s/100 iters), loss = 0.421287
I0930 11:42:21.058300  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.421287 (* 1 = 0.421287 loss)
I0930 11:42:21.058316  3537 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I0930 11:42:34.523742  3537 solver.cpp:218] Iteration 10800 (7.42644 iter/s, 13.4654s/100 iters), loss = 0.322988
I0930 11:42:34.523780  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322988 (* 1 = 0.322988 loss)
I0930 11:42:34.523797  3537 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I0930 11:42:47.970607  3537 solver.cpp:218] Iteration 10900 (7.43672 iter/s, 13.4468s/100 iters), loss = 0.384887
I0930 11:42:47.970638  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.384887 (* 1 = 0.384887 loss)
I0930 11:42:47.970643  3537 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I0930 11:43:00.739820  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:43:01.287212  3537 solver.cpp:330] Iteration 11000, Testing net (#0)
I0930 11:43:04.391329  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:43:04.520450  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7338
I0930 11:43:04.520485  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.806531 (* 1 = 0.806531 loss)
I0930 11:43:04.654860  3537 solver.cpp:218] Iteration 11000 (5.99371 iter/s, 16.6842s/100 iters), loss = 0.2933
I0930 11:43:04.654894  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2933 (* 1 = 0.2933 loss)
I0930 11:43:04.654901  3537 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I0930 11:43:18.106197  3537 solver.cpp:218] Iteration 11100 (7.43425 iter/s, 13.4513s/100 iters), loss = 0.321676
I0930 11:43:18.106227  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.321676 (* 1 = 0.321676 loss)
I0930 11:43:18.106243  3537 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I0930 11:43:31.566733  3537 solver.cpp:218] Iteration 11200 (7.42917 iter/s, 13.4605s/100 iters), loss = 0.355244
I0930 11:43:31.566879  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355244 (* 1 = 0.355244 loss)
I0930 11:43:31.566889  3537 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I0930 11:43:45.010382  3537 solver.cpp:218] Iteration 11300 (7.43856 iter/s, 13.4435s/100 iters), loss = 0.434031
I0930 11:43:45.010413  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.434031 (* 1 = 0.434031 loss)
I0930 11:43:45.010419  3537 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I0930 11:43:58.480482  3537 solver.cpp:218] Iteration 11400 (7.42389 iter/s, 13.47s/100 iters), loss = 0.379256
I0930 11:43:58.480516  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.379256 (* 1 = 0.379256 loss)
I0930 11:43:58.480522  3537 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I0930 11:44:11.266150  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:44:11.802255  3537 solver.cpp:330] Iteration 11500, Testing net (#0)
I0930 11:44:14.906734  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:44:15.035609  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7981
I0930 11:44:15.035634  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.578632 (* 1 = 0.578632 loss)
I0930 11:44:15.169360  3537 solver.cpp:218] Iteration 11500 (5.99204 iter/s, 16.6888s/100 iters), loss = 0.246644
I0930 11:44:15.169390  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246644 (* 1 = 0.246644 loss)
I0930 11:44:15.169396  3537 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I0930 11:44:28.615723  3537 solver.cpp:218] Iteration 11600 (7.437 iter/s, 13.4463s/100 iters), loss = 0.33472
I0930 11:44:28.615756  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.334721 (* 1 = 0.334721 loss)
I0930 11:44:28.615763  3537 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I0930 11:44:42.070816  3537 solver.cpp:218] Iteration 11700 (7.43217 iter/s, 13.455s/100 iters), loss = 0.420048
I0930 11:44:42.070936  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.420048 (* 1 = 0.420048 loss)
I0930 11:44:42.070945  3537 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I0930 11:44:55.534862  3537 solver.cpp:218] Iteration 11800 (7.42728 iter/s, 13.4639s/100 iters), loss = 0.331459
I0930 11:44:55.534893  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331459 (* 1 = 0.331459 loss)
I0930 11:44:55.534899  3537 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I0930 11:45:08.984822  3537 solver.cpp:218] Iteration 11900 (7.43501 iter/s, 13.4499s/100 iters), loss = 0.343109
I0930 11:45:08.984853  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343109 (* 1 = 0.343109 loss)
I0930 11:45:08.984859  3537 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I0930 11:45:21.761548  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:45:22.308120  3537 solver.cpp:330] Iteration 12000, Testing net (#0)
I0930 11:45:25.412559  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:45:25.541857  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7995
I0930 11:45:25.541893  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.604098 (* 1 = 0.604098 loss)
I0930 11:45:25.675153  3537 solver.cpp:218] Iteration 12000 (5.99152 iter/s, 16.6902s/100 iters), loss = 0.375441
I0930 11:45:25.675189  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.375441 (* 1 = 0.375441 loss)
I0930 11:45:25.675196  3537 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I0930 11:45:39.125149  3537 solver.cpp:218] Iteration 12100 (7.43499 iter/s, 13.4499s/100 iters), loss = 0.381179
I0930 11:45:39.125178  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.381179 (* 1 = 0.381179 loss)
I0930 11:45:39.125185  3537 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I0930 11:45:52.591449  3537 solver.cpp:218] Iteration 12200 (7.42599 iter/s, 13.4662s/100 iters), loss = 0.425897
I0930 11:45:52.591559  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.425897 (* 1 = 0.425897 loss)
I0930 11:45:52.591567  3537 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I0930 11:46:06.038692  3537 solver.cpp:218] Iteration 12300 (7.43655 iter/s, 13.4471s/100 iters), loss = 0.357412
I0930 11:46:06.038722  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.357412 (* 1 = 0.357412 loss)
I0930 11:46:06.038728  3537 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I0930 11:46:19.507846  3537 solver.cpp:218] Iteration 12400 (7.42441 iter/s, 13.4691s/100 iters), loss = 0.279872
I0930 11:46:19.507879  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279872 (* 1 = 0.279872 loss)
I0930 11:46:19.507885  3537 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I0930 11:46:32.289902  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:46:32.828603  3537 solver.cpp:330] Iteration 12500, Testing net (#0)
I0930 11:46:35.936449  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:46:36.065404  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8164
I0930 11:46:36.065439  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.555169 (* 1 = 0.555169 loss)
I0930 11:46:36.198982  3537 solver.cpp:218] Iteration 12500 (5.99123 iter/s, 16.6911s/100 iters), loss = 0.32535
I0930 11:46:36.199012  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32535 (* 1 = 0.32535 loss)
I0930 11:46:36.199019  3537 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I0930 11:46:49.652292  3537 solver.cpp:218] Iteration 12600 (7.43316 iter/s, 13.4532s/100 iters), loss = 0.328143
I0930 11:46:49.652323  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328143 (* 1 = 0.328143 loss)
I0930 11:46:49.652330  3537 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I0930 11:47:03.098117  3537 solver.cpp:218] Iteration 12700 (7.43729 iter/s, 13.4458s/100 iters), loss = 0.402635
I0930 11:47:03.098220  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.402635 (* 1 = 0.402635 loss)
I0930 11:47:03.098237  3537 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I0930 11:47:16.562243  3537 solver.cpp:218] Iteration 12800 (7.42722 iter/s, 13.464s/100 iters), loss = 0.317192
I0930 11:47:16.562275  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317192 (* 1 = 0.317192 loss)
I0930 11:47:16.562283  3537 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I0930 11:47:30.018059  3537 solver.cpp:218] Iteration 12900 (7.43177 iter/s, 13.4557s/100 iters), loss = 0.35574
I0930 11:47:30.018088  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35574 (* 1 = 0.35574 loss)
I0930 11:47:30.018095  3537 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I0930 11:47:42.803042  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:47:43.347131  3537 solver.cpp:330] Iteration 13000, Testing net (#0)
I0930 11:47:46.452631  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:47:46.581778  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8199
I0930 11:47:46.581802  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.524817 (* 1 = 0.524817 loss)
I0930 11:47:46.715409  3537 solver.cpp:218] Iteration 13000 (5.989 iter/s, 16.6973s/100 iters), loss = 0.302795
I0930 11:47:46.715441  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302795 (* 1 = 0.302795 loss)
I0930 11:47:46.715448  3537 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I0930 11:48:00.151937  3537 solver.cpp:218] Iteration 13100 (7.44244 iter/s, 13.4364s/100 iters), loss = 0.25825
I0930 11:48:00.151970  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25825 (* 1 = 0.25825 loss)
I0930 11:48:00.151978  3537 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I0930 11:48:13.606925  3537 solver.cpp:218] Iteration 13200 (7.43223 iter/s, 13.4549s/100 iters), loss = 0.4947
I0930 11:48:13.607039  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.4947 (* 1 = 0.4947 loss)
I0930 11:48:13.607056  3537 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I0930 11:48:27.044616  3537 solver.cpp:218] Iteration 13300 (7.44184 iter/s, 13.4375s/100 iters), loss = 0.355135
I0930 11:48:27.044646  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355135 (* 1 = 0.355135 loss)
I0930 11:48:27.044662  3537 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I0930 11:48:40.499567  3537 solver.cpp:218] Iteration 13400 (7.43225 iter/s, 13.4549s/100 iters), loss = 0.239219
I0930 11:48:40.499609  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23922 (* 1 = 0.23922 loss)
I0930 11:48:40.499616  3537 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I0930 11:48:53.285118  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:48:53.821537  3537 solver.cpp:330] Iteration 13500, Testing net (#0)
I0930 11:48:56.928861  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:48:57.057579  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7854
I0930 11:48:57.057603  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.632378 (* 1 = 0.632378 loss)
I0930 11:48:57.191085  3537 solver.cpp:218] Iteration 13500 (5.9911 iter/s, 16.6914s/100 iters), loss = 0.339591
I0930 11:48:57.191115  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.339591 (* 1 = 0.339591 loss)
I0930 11:48:57.191123  3537 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I0930 11:49:10.652366  3537 solver.cpp:218] Iteration 13600 (7.42876 iter/s, 13.4612s/100 iters), loss = 0.293311
I0930 11:49:10.652410  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293311 (* 1 = 0.293311 loss)
I0930 11:49:10.652416  3537 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I0930 11:49:24.106772  3537 solver.cpp:218] Iteration 13700 (7.43256 iter/s, 13.4543s/100 iters), loss = 0.362042
I0930 11:49:24.106907  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362042 (* 1 = 0.362042 loss)
I0930 11:49:24.106915  3537 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I0930 11:49:37.572099  3537 solver.cpp:218] Iteration 13800 (7.42658 iter/s, 13.4651s/100 iters), loss = 0.34651
I0930 11:49:37.572144  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34651 (* 1 = 0.34651 loss)
I0930 11:49:37.572151  3537 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I0930 11:49:51.025537  3537 solver.cpp:218] Iteration 13900 (7.43309 iter/s, 13.4533s/100 iters), loss = 0.293648
I0930 11:49:51.025565  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293648 (* 1 = 0.293648 loss)
I0930 11:49:51.025573  3537 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I0930 11:50:03.805878  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:50:04.351667  3537 solver.cpp:330] Iteration 14000, Testing net (#0)
I0930 11:50:07.454083  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:50:07.582628  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8026
I0930 11:50:07.582664  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.617067 (* 1 = 0.617067 loss)
I0930 11:50:07.715718  3537 solver.cpp:218] Iteration 14000 (5.99158 iter/s, 16.6901s/100 iters), loss = 0.30066
I0930 11:50:07.715750  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30066 (* 1 = 0.30066 loss)
I0930 11:50:07.715757  3537 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I0930 11:50:21.170130  3537 solver.cpp:218] Iteration 14100 (7.43255 iter/s, 13.4543s/100 iters), loss = 0.262432
I0930 11:50:21.170161  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262432 (* 1 = 0.262432 loss)
I0930 11:50:21.170166  3537 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I0930 11:50:34.643635  3537 solver.cpp:218] Iteration 14200 (7.42202 iter/s, 13.4734s/100 iters), loss = 0.468162
I0930 11:50:34.643748  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.468162 (* 1 = 0.468162 loss)
I0930 11:50:34.643756  3537 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I0930 11:50:48.098600  3537 solver.cpp:218] Iteration 14300 (7.43229 iter/s, 13.4548s/100 iters), loss = 0.389346
I0930 11:50:48.098641  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.389346 (* 1 = 0.389346 loss)
I0930 11:50:48.098647  3537 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I0930 11:51:01.566581  3537 solver.cpp:218] Iteration 14400 (7.42507 iter/s, 13.4679s/100 iters), loss = 0.266449
I0930 11:51:01.566623  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266449 (* 1 = 0.266449 loss)
I0930 11:51:01.566642  3537 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I0930 11:51:14.367753  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:51:14.904824  3537 solver.cpp:330] Iteration 14500, Testing net (#0)
I0930 11:51:18.012818  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:51:18.142529  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8129
I0930 11:51:18.142554  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.557538 (* 1 = 0.557538 loss)
I0930 11:51:18.276108  3537 solver.cpp:218] Iteration 14500 (5.98464 iter/s, 16.7094s/100 iters), loss = 0.253216
I0930 11:51:18.276141  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253216 (* 1 = 0.253216 loss)
I0930 11:51:18.276149  3537 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I0930 11:51:31.729586  3537 solver.cpp:218] Iteration 14600 (7.43306 iter/s, 13.4534s/100 iters), loss = 0.296348
I0930 11:51:31.729617  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296348 (* 1 = 0.296348 loss)
I0930 11:51:31.729624  3537 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I0930 11:51:45.171581  3537 solver.cpp:218] Iteration 14700 (7.43941 iter/s, 13.4419s/100 iters), loss = 0.301982
I0930 11:51:45.171728  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301982 (* 1 = 0.301982 loss)
I0930 11:51:45.171737  3537 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I0930 11:51:58.638737  3537 solver.cpp:218] Iteration 14800 (7.42558 iter/s, 13.467s/100 iters), loss = 0.284068
I0930 11:51:58.638770  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284068 (* 1 = 0.284068 loss)
I0930 11:51:58.638777  3537 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I0930 11:52:12.091958  3537 solver.cpp:218] Iteration 14900 (7.43321 iter/s, 13.4531s/100 iters), loss = 0.458116
I0930 11:52:12.091989  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.458116 (* 1 = 0.458116 loss)
I0930 11:52:12.091995  3537 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I0930 11:52:24.876052  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:52:25.420271  3537 solver.cpp:330] Iteration 15000, Testing net (#0)
I0930 11:52:28.522387  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:52:28.651636  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7521
I0930 11:52:28.651672  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.788555 (* 1 = 0.788555 loss)
I0930 11:52:28.784932  3537 solver.cpp:218] Iteration 15000 (5.99057 iter/s, 16.6929s/100 iters), loss = 0.241718
I0930 11:52:28.784965  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241718 (* 1 = 0.241718 loss)
I0930 11:52:28.784971  3537 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I0930 11:52:42.217193  3537 solver.cpp:218] Iteration 15100 (7.44481 iter/s, 13.4322s/100 iters), loss = 0.329935
I0930 11:52:42.217222  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329935 (* 1 = 0.329935 loss)
I0930 11:52:42.217229  3537 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I0930 11:52:55.669929  3537 solver.cpp:218] Iteration 15200 (7.43347 iter/s, 13.4527s/100 iters), loss = 0.339414
I0930 11:52:55.670058  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.339414 (* 1 = 0.339414 loss)
I0930 11:52:55.670066  3537 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I0930 11:53:09.108800  3537 solver.cpp:218] Iteration 15300 (7.4412 iter/s, 13.4387s/100 iters), loss = 0.328898
I0930 11:53:09.108831  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328898 (* 1 = 0.328898 loss)
I0930 11:53:09.108839  3537 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I0930 11:53:22.556730  3537 solver.cpp:218] Iteration 15400 (7.43613 iter/s, 13.4479s/100 iters), loss = 0.212999
I0930 11:53:22.556762  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213 (* 1 = 0.213 loss)
I0930 11:53:22.556769  3537 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I0930 11:53:35.334632  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:53:35.871954  3537 solver.cpp:330] Iteration 15500, Testing net (#0)
I0930 11:53:38.976227  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:53:39.105195  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8126
I0930 11:53:39.105229  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.55207 (* 1 = 0.55207 loss)
I0930 11:53:39.238376  3537 solver.cpp:218] Iteration 15500 (5.99464 iter/s, 16.6816s/100 iters), loss = 0.255532
I0930 11:53:39.238407  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255532 (* 1 = 0.255532 loss)
I0930 11:53:39.238415  3537 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I0930 11:53:52.690670  3537 solver.cpp:218] Iteration 15600 (7.43372 iter/s, 13.4522s/100 iters), loss = 0.339396
I0930 11:53:52.690711  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.339397 (* 1 = 0.339397 loss)
I0930 11:53:52.690718  3537 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I0930 11:54:06.128557  3537 solver.cpp:218] Iteration 15700 (7.44169 iter/s, 13.4378s/100 iters), loss = 0.4389
I0930 11:54:06.128646  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.438901 (* 1 = 0.438901 loss)
I0930 11:54:06.128664  3537 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I0930 11:54:19.582021  3537 solver.cpp:218] Iteration 15800 (7.4331 iter/s, 13.4533s/100 iters), loss = 0.387278
I0930 11:54:19.582063  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.387278 (* 1 = 0.387278 loss)
I0930 11:54:19.582072  3537 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I0930 11:54:33.024519  3537 solver.cpp:218] Iteration 15900 (7.43914 iter/s, 13.4424s/100 iters), loss = 0.256104
I0930 11:54:33.024550  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256104 (* 1 = 0.256104 loss)
I0930 11:54:33.024556  3537 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I0930 11:54:45.801959  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:54:46.344938  3537 solver.cpp:330] Iteration 16000, Testing net (#0)
I0930 11:54:49.444903  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:54:49.573905  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8231
I0930 11:54:49.573941  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.542783 (* 1 = 0.542783 loss)
I0930 11:54:49.708817  3537 solver.cpp:218] Iteration 16000 (5.99369 iter/s, 16.6842s/100 iters), loss = 0.237597
I0930 11:54:49.708853  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237597 (* 1 = 0.237597 loss)
I0930 11:54:49.708858  3537 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I0930 11:55:03.158475  3537 solver.cpp:218] Iteration 16100 (7.43518 iter/s, 13.4496s/100 iters), loss = 0.246032
I0930 11:55:03.158506  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246032 (* 1 = 0.246032 loss)
I0930 11:55:03.158514  3537 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I0930 11:55:16.627274  3537 solver.cpp:218] Iteration 16200 (7.42461 iter/s, 13.4687s/100 iters), loss = 0.402017
I0930 11:55:16.627406  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.402017 (* 1 = 0.402017 loss)
I0930 11:55:16.627415  3537 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I0930 11:55:30.082633  3537 solver.cpp:218] Iteration 16300 (7.43208 iter/s, 13.4552s/100 iters), loss = 0.316056
I0930 11:55:30.082664  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316056 (* 1 = 0.316056 loss)
I0930 11:55:30.082680  3537 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I0930 11:55:43.545234  3537 solver.cpp:218] Iteration 16400 (7.42803 iter/s, 13.4625s/100 iters), loss = 0.301343
I0930 11:55:43.545269  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301343 (* 1 = 0.301343 loss)
I0930 11:55:43.545275  3537 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I0930 11:55:56.339380  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:55:56.876853  3537 solver.cpp:330] Iteration 16500, Testing net (#0)
I0930 11:55:59.982647  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:56:00.111738  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7864
I0930 11:56:00.111773  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.654087 (* 1 = 0.654087 loss)
I0930 11:56:00.245561  3537 solver.cpp:218] Iteration 16500 (5.98794 iter/s, 16.7002s/100 iters), loss = 0.240965
I0930 11:56:00.245594  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240966 (* 1 = 0.240966 loss)
I0930 11:56:00.245601  3537 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I0930 11:56:13.703621  3537 solver.cpp:218] Iteration 16600 (7.43054 iter/s, 13.458s/100 iters), loss = 0.34497
I0930 11:56:13.703654  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34497 (* 1 = 0.34497 loss)
I0930 11:56:13.703660  3537 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I0930 11:56:27.151939  3537 solver.cpp:218] Iteration 16700 (7.43591 iter/s, 13.4482s/100 iters), loss = 0.344116
I0930 11:56:27.152041  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344116 (* 1 = 0.344116 loss)
I0930 11:56:27.152061  3537 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I0930 11:56:40.614550  3537 solver.cpp:218] Iteration 16800 (7.42806 iter/s, 13.4625s/100 iters), loss = 0.370368
I0930 11:56:40.614585  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.370369 (* 1 = 0.370369 loss)
I0930 11:56:40.614593  3537 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I0930 11:56:54.071136  3537 solver.cpp:218] Iteration 16900 (7.43135 iter/s, 13.4565s/100 iters), loss = 0.199727
I0930 11:56:54.071168  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199727 (* 1 = 0.199727 loss)
I0930 11:56:54.071174  3537 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I0930 11:57:06.861903  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:57:07.406477  3537 solver.cpp:330] Iteration 17000, Testing net (#0)
I0930 11:57:10.508872  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:57:10.637856  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8305
I0930 11:57:10.637881  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.496599 (* 1 = 0.496599 loss)
I0930 11:57:10.771181  3537 solver.cpp:218] Iteration 17000 (5.98804 iter/s, 16.7s/100 iters), loss = 0.281291
I0930 11:57:10.771214  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281292 (* 1 = 0.281292 loss)
I0930 11:57:10.771221  3537 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I0930 11:57:24.209574  3537 solver.cpp:218] Iteration 17100 (7.44141 iter/s, 13.4383s/100 iters), loss = 0.269416
I0930 11:57:24.209605  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269416 (* 1 = 0.269416 loss)
I0930 11:57:24.209621  3537 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I0930 11:57:37.674302  3537 solver.cpp:218] Iteration 17200 (7.42685 iter/s, 13.4647s/100 iters), loss = 0.459178
I0930 11:57:37.674446  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.459178 (* 1 = 0.459178 loss)
I0930 11:57:37.674454  3537 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I0930 11:57:51.133064  3537 solver.cpp:218] Iteration 17300 (7.43021 iter/s, 13.4586s/100 iters), loss = 0.424343
I0930 11:57:51.133105  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.424343 (* 1 = 0.424343 loss)
I0930 11:57:51.133111  3537 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I0930 11:58:04.592102  3537 solver.cpp:218] Iteration 17400 (7.43 iter/s, 13.459s/100 iters), loss = 0.216216
I0930 11:58:04.592134  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216216 (* 1 = 0.216216 loss)
I0930 11:58:04.592141  3537 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I0930 11:58:17.377104  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:58:17.914947  3537 solver.cpp:330] Iteration 17500, Testing net (#0)
I0930 11:58:21.021649  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:58:21.151054  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8046
I0930 11:58:21.151089  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.629697 (* 1 = 0.629697 loss)
I0930 11:58:21.284153  3537 solver.cpp:218] Iteration 17500 (5.99091 iter/s, 16.692s/100 iters), loss = 0.226781
I0930 11:58:21.284194  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226781 (* 1 = 0.226781 loss)
I0930 11:58:21.284202  3537 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I0930 11:58:34.748420  3537 solver.cpp:218] Iteration 17600 (7.42712 iter/s, 13.4642s/100 iters), loss = 0.234825
I0930 11:58:34.748461  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234825 (* 1 = 0.234825 loss)
I0930 11:58:34.748468  3537 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I0930 11:58:48.201477  3537 solver.cpp:218] Iteration 17700 (7.4333 iter/s, 13.453s/100 iters), loss = 0.31785
I0930 11:58:48.201598  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31785 (* 1 = 0.31785 loss)
I0930 11:58:48.201616  3537 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I0930 11:59:01.668270  3537 solver.cpp:218] Iteration 17800 (7.42576 iter/s, 13.4666s/100 iters), loss = 0.278792
I0930 11:59:01.668303  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278792 (* 1 = 0.278792 loss)
I0930 11:59:01.668308  3537 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I0930 11:59:15.126410  3537 solver.cpp:218] Iteration 17900 (7.43049 iter/s, 13.4581s/100 iters), loss = 0.280873
I0930 11:59:15.126443  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280873 (* 1 = 0.280873 loss)
I0930 11:59:15.126451  3537 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I0930 11:59:27.919463  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:59:28.462321  3537 solver.cpp:330] Iteration 18000, Testing net (#0)
I0930 11:59:31.568428  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 11:59:31.698010  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8255
I0930 11:59:31.698046  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.536523 (* 1 = 0.536523 loss)
I0930 11:59:31.831625  3537 solver.cpp:218] Iteration 18000 (5.98619 iter/s, 16.7051s/100 iters), loss = 0.229394
I0930 11:59:31.831657  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229395 (* 1 = 0.229395 loss)
I0930 11:59:31.831665  3537 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I0930 11:59:45.272352  3537 solver.cpp:218] Iteration 18100 (7.44012 iter/s, 13.4407s/100 iters), loss = 0.224994
I0930 11:59:45.272397  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224995 (* 1 = 0.224995 loss)
I0930 11:59:45.272403  3537 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I0930 11:59:58.737238  3537 solver.cpp:218] Iteration 18200 (7.42677 iter/s, 13.4648s/100 iters), loss = 0.308962
I0930 11:59:58.737385  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308962 (* 1 = 0.308962 loss)
I0930 11:59:58.737392  3537 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I0930 12:00:12.195839  3537 solver.cpp:218] Iteration 18300 (7.43029 iter/s, 13.4584s/100 iters), loss = 0.235488
I0930 12:00:12.195869  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235488 (* 1 = 0.235488 loss)
I0930 12:00:12.195885  3537 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I0930 12:00:25.652433  3537 solver.cpp:218] Iteration 18400 (7.43134 iter/s, 13.4565s/100 iters), loss = 0.291544
I0930 12:00:25.652475  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291544 (* 1 = 0.291544 loss)
I0930 12:00:25.652482  3537 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I0930 12:00:38.434801  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:00:38.972107  3537 solver.cpp:330] Iteration 18500, Testing net (#0)
I0930 12:00:42.075095  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:00:42.203860  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8279
I0930 12:00:42.203894  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.532962 (* 1 = 0.532962 loss)
I0930 12:00:42.337517  3537 solver.cpp:218] Iteration 18500 (5.99341 iter/s, 16.685s/100 iters), loss = 0.196106
I0930 12:00:42.337549  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196106 (* 1 = 0.196106 loss)
I0930 12:00:42.337556  3537 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I0930 12:00:55.795652  3537 solver.cpp:218] Iteration 18600 (7.43049 iter/s, 13.4581s/100 iters), loss = 0.345393
I0930 12:00:55.795683  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.345393 (* 1 = 0.345393 loss)
I0930 12:00:55.795691  3537 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I0930 12:01:09.241065  3537 solver.cpp:218] Iteration 18700 (7.43752 iter/s, 13.4453s/100 iters), loss = 0.404306
I0930 12:01:09.241204  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.404306 (* 1 = 0.404306 loss)
I0930 12:01:09.241211  3537 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I0930 12:01:22.698024  3537 solver.cpp:218] Iteration 18800 (7.43119 iter/s, 13.4568s/100 iters), loss = 0.243253
I0930 12:01:22.698061  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243253 (* 1 = 0.243253 loss)
I0930 12:01:22.698068  3537 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I0930 12:01:36.152343  3537 solver.cpp:218] Iteration 18900 (7.4326 iter/s, 13.4542s/100 iters), loss = 0.220552
I0930 12:01:36.152371  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220553 (* 1 = 0.220553 loss)
I0930 12:01:36.152377  3537 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I0930 12:01:48.945401  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:01:49.490262  3537 solver.cpp:330] Iteration 19000, Testing net (#0)
I0930 12:01:52.593848  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:01:52.723181  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8229
I0930 12:01:52.723217  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.548826 (* 1 = 0.548826 loss)
I0930 12:01:52.857051  3537 solver.cpp:218] Iteration 19000 (5.98637 iter/s, 16.7046s/100 iters), loss = 0.224194
I0930 12:01:52.857084  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224194 (* 1 = 0.224194 loss)
I0930 12:01:52.857091  3537 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I0930 12:02:06.303964  3537 solver.cpp:218] Iteration 19100 (7.43669 iter/s, 13.4468s/100 iters), loss = 0.243799
I0930 12:02:06.303994  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243799 (* 1 = 0.243799 loss)
I0930 12:02:06.304000  3537 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I0930 12:02:19.772703  3537 solver.cpp:218] Iteration 19200 (7.42464 iter/s, 13.4687s/100 iters), loss = 0.35262
I0930 12:02:19.772858  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35262 (* 1 = 0.35262 loss)
I0930 12:02:19.772866  3537 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I0930 12:02:33.222040  3537 solver.cpp:218] Iteration 19300 (7.43542 iter/s, 13.4491s/100 iters), loss = 0.42828
I0930 12:02:33.222070  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.428281 (* 1 = 0.428281 loss)
I0930 12:02:33.222076  3537 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I0930 12:02:46.683562  3537 solver.cpp:218] Iteration 19400 (7.42862 iter/s, 13.4614s/100 iters), loss = 0.209553
I0930 12:02:46.683598  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209554 (* 1 = 0.209554 loss)
I0930 12:02:46.683604  3537 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I0930 12:02:59.463714  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:03:00.000380  3537 solver.cpp:330] Iteration 19500, Testing net (#0)
I0930 12:03:03.109617  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:03:03.238644  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.828
I0930 12:03:03.238679  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.544172 (* 1 = 0.544172 loss)
I0930 12:03:03.372567  3537 solver.cpp:218] Iteration 19500 (5.992 iter/s, 16.6889s/100 iters), loss = 0.24662
I0930 12:03:03.372601  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24662 (* 1 = 0.24662 loss)
I0930 12:03:03.372608  3537 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I0930 12:03:16.853152  3537 solver.cpp:218] Iteration 19600 (7.41812 iter/s, 13.4805s/100 iters), loss = 0.275309
I0930 12:03:16.853193  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275309 (* 1 = 0.275309 loss)
I0930 12:03:16.853200  3537 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I0930 12:03:30.319841  3537 solver.cpp:218] Iteration 19700 (7.42578 iter/s, 13.4666s/100 iters), loss = 0.326947
I0930 12:03:30.319948  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326947 (* 1 = 0.326947 loss)
I0930 12:03:30.319968  3537 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I0930 12:03:43.783308  3537 solver.cpp:218] Iteration 19800 (7.42759 iter/s, 13.4633s/100 iters), loss = 0.274031
I0930 12:03:43.783349  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274031 (* 1 = 0.274031 loss)
I0930 12:03:43.783356  3537 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I0930 12:03:57.233710  3537 solver.cpp:218] Iteration 19900 (7.43477 iter/s, 13.4503s/100 iters), loss = 0.229549
I0930 12:03:57.233739  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229549 (* 1 = 0.229549 loss)
I0930 12:03:57.233745  3537 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I0930 12:04:10.027602  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:04:10.571995  3537 solver.cpp:330] Iteration 20000, Testing net (#0)
I0930 12:04:13.676141  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:04:13.805326  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8104
I0930 12:04:13.805362  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.600979 (* 1 = 0.600979 loss)
I0930 12:04:13.938832  3537 solver.cpp:218] Iteration 20000 (5.98622 iter/s, 16.705s/100 iters), loss = 0.248363
I0930 12:04:13.938864  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248363 (* 1 = 0.248363 loss)
I0930 12:04:13.938871  3537 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I0930 12:04:27.384506  3537 solver.cpp:218] Iteration 20100 (7.43738 iter/s, 13.4456s/100 iters), loss = 0.306664
I0930 12:04:27.384536  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306664 (* 1 = 0.306664 loss)
I0930 12:04:27.384542  3537 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I0930 12:04:40.851189  3537 solver.cpp:218] Iteration 20200 (7.42578 iter/s, 13.4666s/100 iters), loss = 0.328328
I0930 12:04:40.851537  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328328 (* 1 = 0.328328 loss)
I0930 12:04:40.851560  3537 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I0930 12:04:54.306098  3537 solver.cpp:218] Iteration 20300 (7.43244 iter/s, 13.4545s/100 iters), loss = 0.266902
I0930 12:04:54.306129  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266903 (* 1 = 0.266903 loss)
I0930 12:04:54.306135  3537 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I0930 12:05:07.770735  3537 solver.cpp:218] Iteration 20400 (7.4269 iter/s, 13.4646s/100 iters), loss = 0.213793
I0930 12:05:07.770776  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213793 (* 1 = 0.213793 loss)
I0930 12:05:07.770782  3537 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I0930 12:05:20.553123  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:05:21.088215  3537 solver.cpp:330] Iteration 20500, Testing net (#0)
I0930 12:05:24.194485  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:05:24.323590  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7956
I0930 12:05:24.323613  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.605299 (* 1 = 0.605299 loss)
I0930 12:05:24.456881  3537 solver.cpp:218] Iteration 20500 (5.99303 iter/s, 16.6861s/100 iters), loss = 0.180328
I0930 12:05:24.456913  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180328 (* 1 = 0.180328 loss)
I0930 12:05:24.456920  3537 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I0930 12:05:37.928992  3537 solver.cpp:218] Iteration 20600 (7.42279 iter/s, 13.472s/100 iters), loss = 0.289174
I0930 12:05:37.929021  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289175 (* 1 = 0.289175 loss)
I0930 12:05:37.929028  3537 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I0930 12:05:51.383267  3537 solver.cpp:218] Iteration 20700 (7.43262 iter/s, 13.4542s/100 iters), loss = 0.328153
I0930 12:05:51.383388  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328153 (* 1 = 0.328153 loss)
I0930 12:05:51.383407  3537 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I0930 12:06:04.833695  3537 solver.cpp:218] Iteration 20800 (7.4348 iter/s, 13.4503s/100 iters), loss = 0.365613
I0930 12:06:04.833737  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365613 (* 1 = 0.365613 loss)
I0930 12:06:04.833745  3537 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I0930 12:06:18.292040  3537 solver.cpp:218] Iteration 20900 (7.43038 iter/s, 13.4583s/100 iters), loss = 0.147556
I0930 12:06:18.292070  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147556 (* 1 = 0.147556 loss)
I0930 12:06:18.292076  3537 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I0930 12:06:31.087299  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:06:31.629314  3537 solver.cpp:330] Iteration 21000, Testing net (#0)
I0930 12:06:34.737188  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:06:34.866493  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8063
I0930 12:06:34.866533  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.603963 (* 1 = 0.603963 loss)
I0930 12:06:35.000026  3537 solver.cpp:218] Iteration 21000 (5.98519 iter/s, 16.7079s/100 iters), loss = 0.190687
I0930 12:06:35.000056  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190687 (* 1 = 0.190687 loss)
I0930 12:06:35.000062  3537 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I0930 12:06:48.430517  3537 solver.cpp:218] Iteration 21100 (7.44579 iter/s, 13.4304s/100 iters), loss = 0.255874
I0930 12:06:48.430548  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255874 (* 1 = 0.255874 loss)
I0930 12:06:48.430565  3537 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I0930 12:07:01.878288  3537 solver.cpp:218] Iteration 21200 (7.43622 iter/s, 13.4477s/100 iters), loss = 0.248155
I0930 12:07:01.878422  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248155 (* 1 = 0.248155 loss)
I0930 12:07:01.878444  3537 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I0930 12:07:15.322932  3537 solver.cpp:218] Iteration 21300 (7.438 iter/s, 13.4445s/100 iters), loss = 0.359916
I0930 12:07:15.322963  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.359916 (* 1 = 0.359916 loss)
I0930 12:07:15.322969  3537 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I0930 12:07:28.788401  3537 solver.cpp:218] Iteration 21400 (7.42645 iter/s, 13.4654s/100 iters), loss = 0.244484
I0930 12:07:28.788434  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244484 (* 1 = 0.244484 loss)
I0930 12:07:28.788450  3537 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I0930 12:07:41.561244  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:07:42.097425  3537 solver.cpp:330] Iteration 21500, Testing net (#0)
I0930 12:07:45.201692  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:07:45.330744  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8393
I0930 12:07:45.330778  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.479234 (* 1 = 0.479234 loss)
I0930 12:07:45.464592  3537 solver.cpp:218] Iteration 21500 (5.9966 iter/s, 16.6761s/100 iters), loss = 0.203612
I0930 12:07:45.464628  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203612 (* 1 = 0.203612 loss)
I0930 12:07:45.464635  3537 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I0930 12:07:58.924881  3537 solver.cpp:218] Iteration 21600 (7.42931 iter/s, 13.4602s/100 iters), loss = 0.225408
I0930 12:07:58.924911  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225408 (* 1 = 0.225408 loss)
I0930 12:07:58.924917  3537 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I0930 12:08:12.386122  3537 solver.cpp:218] Iteration 21700 (7.42878 iter/s, 13.4612s/100 iters), loss = 0.311753
I0930 12:08:12.386266  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311753 (* 1 = 0.311753 loss)
I0930 12:08:12.386276  3537 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I0930 12:08:25.839486  3537 solver.cpp:218] Iteration 21800 (7.43319 iter/s, 13.4532s/100 iters), loss = 0.323952
I0930 12:08:25.839519  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323952 (* 1 = 0.323952 loss)
I0930 12:08:25.839525  3537 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I0930 12:08:39.295652  3537 solver.cpp:218] Iteration 21900 (7.43158 iter/s, 13.4561s/100 iters), loss = 0.189728
I0930 12:08:39.295683  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189728 (* 1 = 0.189728 loss)
I0930 12:08:39.295689  3537 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I0930 12:08:52.090596  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:08:52.633463  3537 solver.cpp:330] Iteration 22000, Testing net (#0)
I0930 12:08:55.738047  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:08:55.868243  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7795
I0930 12:08:55.868268  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.671063 (* 1 = 0.671063 loss)
I0930 12:08:56.001791  3537 solver.cpp:218] Iteration 22000 (5.98585 iter/s, 16.7061s/100 iters), loss = 0.203859
I0930 12:08:56.001822  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203859 (* 1 = 0.203859 loss)
I0930 12:08:56.001829  3537 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I0930 12:09:09.443104  3537 solver.cpp:218] Iteration 22100 (7.43979 iter/s, 13.4412s/100 iters), loss = 0.30816
I0930 12:09:09.443136  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30816 (* 1 = 0.30816 loss)
I0930 12:09:09.443142  3537 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I0930 12:09:22.902935  3537 solver.cpp:218] Iteration 22200 (7.42956 iter/s, 13.4598s/100 iters), loss = 0.283939
I0930 12:09:22.903069  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283939 (* 1 = 0.283939 loss)
I0930 12:09:22.903089  3537 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I0930 12:09:36.357702  3537 solver.cpp:218] Iteration 22300 (7.4324 iter/s, 13.4546s/100 iters), loss = 0.258913
I0930 12:09:36.357731  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258913 (* 1 = 0.258913 loss)
I0930 12:09:36.357738  3537 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I0930 12:09:49.822600  3537 solver.cpp:218] Iteration 22400 (7.42676 iter/s, 13.4648s/100 iters), loss = 0.14792
I0930 12:09:49.822633  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14792 (* 1 = 0.14792 loss)
I0930 12:09:49.822639  3537 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I0930 12:10:02.607807  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:10:03.143784  3537 solver.cpp:330] Iteration 22500, Testing net (#0)
I0930 12:10:06.247197  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:10:06.376163  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8424
I0930 12:10:06.376199  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.465249 (* 1 = 0.465249 loss)
I0930 12:10:06.509568  3537 solver.cpp:218] Iteration 22500 (5.99273 iter/s, 16.6869s/100 iters), loss = 0.205613
I0930 12:10:06.509601  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205613 (* 1 = 0.205613 loss)
I0930 12:10:06.509608  3537 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I0930 12:10:19.970903  3537 solver.cpp:218] Iteration 22600 (7.42873 iter/s, 13.4613s/100 iters), loss = 0.21374
I0930 12:10:19.970934  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213739 (* 1 = 0.213739 loss)
I0930 12:10:19.970940  3537 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I0930 12:10:33.426856  3537 solver.cpp:218] Iteration 22700 (7.4317 iter/s, 13.4559s/100 iters), loss = 0.295896
I0930 12:10:33.426970  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295895 (* 1 = 0.295895 loss)
I0930 12:10:33.426976  3537 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I0930 12:10:46.888690  3537 solver.cpp:218] Iteration 22800 (7.42849 iter/s, 13.4617s/100 iters), loss = 0.310198
I0930 12:10:46.888721  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310197 (* 1 = 0.310197 loss)
I0930 12:10:46.888727  3537 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I0930 12:11:00.334111  3537 solver.cpp:218] Iteration 22900 (7.43752 iter/s, 13.4453s/100 iters), loss = 0.282959
I0930 12:11:00.334141  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282959 (* 1 = 0.282959 loss)
I0930 12:11:00.334148  3537 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I0930 12:11:13.124886  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:11:13.665402  3537 solver.cpp:330] Iteration 23000, Testing net (#0)
I0930 12:11:16.772598  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:11:16.901595  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7656
I0930 12:11:16.901621  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.813473 (* 1 = 0.813473 loss)
I0930 12:11:17.035398  3537 solver.cpp:218] Iteration 23000 (5.98759 iter/s, 16.7012s/100 iters), loss = 0.194039
I0930 12:11:17.035432  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194039 (* 1 = 0.194039 loss)
I0930 12:11:17.035439  3537 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I0930 12:11:30.483806  3537 solver.cpp:218] Iteration 23100 (7.43587 iter/s, 13.4483s/100 iters), loss = 0.218593
I0930 12:11:30.483839  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218593 (* 1 = 0.218593 loss)
I0930 12:11:30.483846  3537 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I0930 12:11:43.940429  3537 solver.cpp:218] Iteration 23200 (7.43133 iter/s, 13.4565s/100 iters), loss = 0.265474
I0930 12:11:43.940560  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265473 (* 1 = 0.265473 loss)
I0930 12:11:43.940578  3537 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I0930 12:11:57.395136  3537 solver.cpp:218] Iteration 23300 (7.43243 iter/s, 13.4545s/100 iters), loss = 0.290027
I0930 12:11:57.395167  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290026 (* 1 = 0.290026 loss)
I0930 12:11:57.395174  3537 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I0930 12:12:10.857744  3537 solver.cpp:218] Iteration 23400 (7.42802 iter/s, 13.4625s/100 iters), loss = 0.143812
I0930 12:12:10.857779  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143812 (* 1 = 0.143812 loss)
I0930 12:12:10.857785  3537 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I0930 12:12:23.636471  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:12:24.174098  3537 solver.cpp:330] Iteration 23500, Testing net (#0)
I0930 12:12:27.276604  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:12:27.405524  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8282
I0930 12:12:27.405558  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.523157 (* 1 = 0.523157 loss)
I0930 12:12:27.539345  3537 solver.cpp:218] Iteration 23500 (5.99466 iter/s, 16.6815s/100 iters), loss = 0.279616
I0930 12:12:27.539373  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279616 (* 1 = 0.279616 loss)
I0930 12:12:27.539381  3537 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I0930 12:12:40.976074  3537 solver.cpp:218] Iteration 23600 (7.44233 iter/s, 13.4367s/100 iters), loss = 0.283646
I0930 12:12:40.976104  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283645 (* 1 = 0.283645 loss)
I0930 12:12:40.976111  3537 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I0930 12:12:54.421485  3537 solver.cpp:218] Iteration 23700 (7.43753 iter/s, 13.4453s/100 iters), loss = 0.239046
I0930 12:12:54.421636  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239046 (* 1 = 0.239046 loss)
I0930 12:12:54.421646  3537 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I0930 12:13:07.881525  3537 solver.cpp:218] Iteration 23800 (7.4295 iter/s, 13.4598s/100 iters), loss = 0.262569
I0930 12:13:07.881567  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262569 (* 1 = 0.262569 loss)
I0930 12:13:07.881574  3537 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I0930 12:13:21.321580  3537 solver.cpp:218] Iteration 23900 (7.44049 iter/s, 13.44s/100 iters), loss = 0.206969
I0930 12:13:21.321610  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206968 (* 1 = 0.206968 loss)
I0930 12:13:21.321616  3537 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I0930 12:13:34.105119  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:13:34.647698  3537 solver.cpp:330] Iteration 24000, Testing net (#0)
I0930 12:13:37.753175  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:13:37.882676  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8234
I0930 12:13:37.882712  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.538506 (* 1 = 0.538506 loss)
I0930 12:13:38.016610  3537 solver.cpp:218] Iteration 24000 (5.98984 iter/s, 16.6949s/100 iters), loss = 0.182806
I0930 12:13:38.016643  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182806 (* 1 = 0.182806 loss)
I0930 12:13:38.016665  3537 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I0930 12:13:51.484534  3537 solver.cpp:218] Iteration 24100 (7.42509 iter/s, 13.4678s/100 iters), loss = 0.301588
I0930 12:13:51.484575  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301588 (* 1 = 0.301588 loss)
I0930 12:13:51.484581  3537 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I0930 12:14:04.947073  3537 solver.cpp:218] Iteration 24200 (7.42807 iter/s, 13.4625s/100 iters), loss = 0.46864
I0930 12:14:04.947232  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.46864 (* 1 = 0.46864 loss)
I0930 12:14:04.947242  3537 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I0930 12:14:18.406919  3537 solver.cpp:218] Iteration 24300 (7.42961 iter/s, 13.4597s/100 iters), loss = 0.246351
I0930 12:14:18.406960  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246351 (* 1 = 0.246351 loss)
I0930 12:14:18.406967  3537 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I0930 12:14:31.881438  3537 solver.cpp:218] Iteration 24400 (7.42146 iter/s, 13.4744s/100 iters), loss = 0.163373
I0930 12:14:31.881469  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163372 (* 1 = 0.163372 loss)
I0930 12:14:31.881475  3537 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I0930 12:14:44.673686  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:14:45.209779  3537 solver.cpp:330] Iteration 24500, Testing net (#0)
I0930 12:14:48.313657  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:14:48.443161  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8143
I0930 12:14:48.443195  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.587069 (* 1 = 0.587069 loss)
I0930 12:14:48.576828  3537 solver.cpp:218] Iteration 24500 (5.98971 iter/s, 16.6953s/100 iters), loss = 0.192222
I0930 12:14:48.576860  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192221 (* 1 = 0.192221 loss)
I0930 12:14:48.576866  3537 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I0930 12:15:02.031708  3537 solver.cpp:218] Iteration 24600 (7.43229 iter/s, 13.4548s/100 iters), loss = 0.216994
I0930 12:15:02.031738  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216994 (* 1 = 0.216994 loss)
I0930 12:15:02.031744  3537 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I0930 12:15:15.481881  3537 solver.cpp:218] Iteration 24700 (7.43489 iter/s, 13.4501s/100 iters), loss = 0.328245
I0930 12:15:15.482007  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328244 (* 1 = 0.328244 loss)
I0930 12:15:15.482015  3537 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I0930 12:15:28.928824  3537 solver.cpp:218] Iteration 24800 (7.43673 iter/s, 13.4468s/100 iters), loss = 0.316493
I0930 12:15:28.928858  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316493 (* 1 = 0.316493 loss)
I0930 12:15:28.928864  3537 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I0930 12:15:42.367475  3537 solver.cpp:218] Iteration 24900 (7.44127 iter/s, 13.4386s/100 iters), loss = 0.240633
I0930 12:15:42.367503  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240633 (* 1 = 0.240633 loss)
I0930 12:15:42.367511  3537 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I0930 12:15:55.151252  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:15:55.692770  3537 solver.cpp:330] Iteration 25000, Testing net (#0)
I0930 12:15:58.799772  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:15:58.929165  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7278
I0930 12:15:58.929200  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.953042 (* 1 = 0.953042 loss)
I0930 12:15:59.062883  3537 solver.cpp:218] Iteration 25000 (5.9897 iter/s, 16.6953s/100 iters), loss = 0.313718
I0930 12:15:59.062913  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313717 (* 1 = 0.313717 loss)
I0930 12:15:59.062919  3537 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I0930 12:16:12.510363  3537 solver.cpp:218] Iteration 25100 (7.43638 iter/s, 13.4474s/100 iters), loss = 0.275924
I0930 12:16:12.510395  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275923 (* 1 = 0.275923 loss)
I0930 12:16:12.510401  3537 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I0930 12:16:25.958972  3537 solver.cpp:218] Iteration 25200 (7.43575 iter/s, 13.4485s/100 iters), loss = 0.240318
I0930 12:16:25.959131  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240317 (* 1 = 0.240317 loss)
I0930 12:16:25.959156  3537 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I0930 12:16:39.408007  3537 solver.cpp:218] Iteration 25300 (7.43559 iter/s, 13.4488s/100 iters), loss = 0.296028
I0930 12:16:39.408038  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296028 (* 1 = 0.296028 loss)
I0930 12:16:39.408044  3537 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I0930 12:16:52.875401  3537 solver.cpp:218] Iteration 25400 (7.42538 iter/s, 13.4673s/100 iters), loss = 0.245303
I0930 12:16:52.875433  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245302 (* 1 = 0.245302 loss)
I0930 12:16:52.875440  3537 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I0930 12:17:05.660676  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:17:06.198040  3537 solver.cpp:330] Iteration 25500, Testing net (#0)
I0930 12:17:09.303752  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:17:09.433233  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8284
I0930 12:17:09.433269  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.515429 (* 1 = 0.515429 loss)
I0930 12:17:09.566632  3537 solver.cpp:218] Iteration 25500 (5.9912 iter/s, 16.6911s/100 iters), loss = 0.272576
I0930 12:17:09.566663  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272576 (* 1 = 0.272576 loss)
I0930 12:17:09.566669  3537 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I0930 12:17:23.016137  3537 solver.cpp:218] Iteration 25600 (7.43526 iter/s, 13.4494s/100 iters), loss = 0.291212
I0930 12:17:23.016170  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291211 (* 1 = 0.291211 loss)
I0930 12:17:23.016175  3537 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I0930 12:17:36.474462  3537 solver.cpp:218] Iteration 25700 (7.43039 iter/s, 13.4583s/100 iters), loss = 0.335196
I0930 12:17:36.474609  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335196 (* 1 = 0.335196 loss)
I0930 12:17:36.474619  3537 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I0930 12:17:49.941431  3537 solver.cpp:218] Iteration 25800 (7.42568 iter/s, 13.4668s/100 iters), loss = 0.242424
I0930 12:17:49.941462  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242424 (* 1 = 0.242424 loss)
I0930 12:17:49.941468  3537 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I0930 12:18:03.388885  3537 solver.cpp:218] Iteration 25900 (7.43639 iter/s, 13.4474s/100 iters), loss = 0.223443
I0930 12:18:03.388916  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223443 (* 1 = 0.223443 loss)
I0930 12:18:03.388921  3537 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I0930 12:18:16.181716  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:18:16.724786  3537 solver.cpp:330] Iteration 26000, Testing net (#0)
I0930 12:18:19.831501  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:18:19.960714  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8113
I0930 12:18:19.960750  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.589534 (* 1 = 0.589534 loss)
I0930 12:18:20.094421  3537 solver.cpp:218] Iteration 26000 (5.98607 iter/s, 16.7055s/100 iters), loss = 0.142495
I0930 12:18:20.094455  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142495 (* 1 = 0.142495 loss)
I0930 12:18:20.094461  3537 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I0930 12:18:33.550699  3537 solver.cpp:218] Iteration 26100 (7.43152 iter/s, 13.4562s/100 iters), loss = 0.316701
I0930 12:18:33.550729  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.3167 (* 1 = 0.3167 loss)
I0930 12:18:33.550736  3537 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I0930 12:18:47.008226  3537 solver.cpp:218] Iteration 26200 (7.43083 iter/s, 13.4575s/100 iters), loss = 0.247361
I0930 12:18:47.008378  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247361 (* 1 = 0.247361 loss)
I0930 12:18:47.008397  3537 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I0930 12:19:00.454893  3537 solver.cpp:218] Iteration 26300 (7.43689 iter/s, 13.4465s/100 iters), loss = 0.339142
I0930 12:19:00.454934  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.339142 (* 1 = 0.339142 loss)
I0930 12:19:00.454941  3537 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I0930 12:19:13.921252  3537 solver.cpp:218] Iteration 26400 (7.42596 iter/s, 13.4663s/100 iters), loss = 0.15744
I0930 12:19:13.921295  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157439 (* 1 = 0.157439 loss)
I0930 12:19:13.921301  3537 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I0930 12:19:26.715979  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:19:27.252727  3537 solver.cpp:330] Iteration 26500, Testing net (#0)
I0930 12:19:30.355232  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:19:30.484189  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8048
I0930 12:19:30.484225  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.596162 (* 1 = 0.596162 loss)
I0930 12:19:30.616982  3537 solver.cpp:218] Iteration 26500 (5.98959 iter/s, 16.6956s/100 iters), loss = 0.200708
I0930 12:19:30.617012  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200708 (* 1 = 0.200708 loss)
I0930 12:19:30.617018  3537 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I0930 12:19:44.083462  3537 solver.cpp:218] Iteration 26600 (7.42589 iter/s, 13.4664s/100 iters), loss = 0.240785
I0930 12:19:44.083506  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240785 (* 1 = 0.240785 loss)
I0930 12:19:44.083513  3537 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I0930 12:19:57.553869  3537 solver.cpp:218] Iteration 26700 (7.42373 iter/s, 13.4703s/100 iters), loss = 0.278732
I0930 12:19:57.553997  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278732 (* 1 = 0.278732 loss)
I0930 12:19:57.554004  3537 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I0930 12:20:11.024747  3537 solver.cpp:218] Iteration 26800 (7.42352 iter/s, 13.4707s/100 iters), loss = 0.274046
I0930 12:20:11.024791  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274046 (* 1 = 0.274046 loss)
I0930 12:20:11.024801  3537 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I0930 12:20:24.480576  3537 solver.cpp:218] Iteration 26900 (7.43177 iter/s, 13.4557s/100 iters), loss = 0.193364
I0930 12:20:24.480609  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193364 (* 1 = 0.193364 loss)
I0930 12:20:24.480615  3537 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I0930 12:20:37.282814  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:20:37.821944  3537 solver.cpp:330] Iteration 27000, Testing net (#0)
I0930 12:20:40.926419  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:20:41.055487  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8091
I0930 12:20:41.055512  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.597148 (* 1 = 0.597148 loss)
I0930 12:20:41.189951  3537 solver.cpp:218] Iteration 27000 (5.98469 iter/s, 16.7093s/100 iters), loss = 0.26365
I0930 12:20:41.189987  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26365 (* 1 = 0.26365 loss)
I0930 12:20:41.189995  3537 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I0930 12:20:54.652108  3537 solver.cpp:218] Iteration 27100 (7.42828 iter/s, 13.4621s/100 iters), loss = 0.286121
I0930 12:20:54.652150  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286121 (* 1 = 0.286121 loss)
I0930 12:20:54.652156  3537 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I0930 12:21:08.131652  3537 solver.cpp:218] Iteration 27200 (7.41869 iter/s, 13.4795s/100 iters), loss = 0.263998
I0930 12:21:08.131772  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263998 (* 1 = 0.263998 loss)
I0930 12:21:08.131779  3537 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I0930 12:21:21.592191  3537 solver.cpp:218] Iteration 27300 (7.42921 iter/s, 13.4604s/100 iters), loss = 0.224916
I0930 12:21:21.592232  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224916 (* 1 = 0.224916 loss)
I0930 12:21:21.592239  3537 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I0930 12:21:35.070330  3537 solver.cpp:218] Iteration 27400 (7.41947 iter/s, 13.4781s/100 iters), loss = 0.16842
I0930 12:21:35.070371  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16842 (* 1 = 0.16842 loss)
I0930 12:21:35.070377  3537 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I0930 12:21:47.869936  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:21:48.407603  3537 solver.cpp:330] Iteration 27500, Testing net (#0)
I0930 12:21:51.512854  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:21:51.641973  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.829
I0930 12:21:51.642016  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.50609 (* 1 = 0.50609 loss)
I0930 12:21:51.777109  3537 solver.cpp:218] Iteration 27500 (5.98563 iter/s, 16.7067s/100 iters), loss = 0.259092
I0930 12:21:51.777143  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259091 (* 1 = 0.259091 loss)
I0930 12:21:51.777150  3537 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I0930 12:22:05.227638  3537 solver.cpp:218] Iteration 27600 (7.43469 iter/s, 13.4505s/100 iters), loss = 0.305782
I0930 12:22:05.227669  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305782 (* 1 = 0.305782 loss)
I0930 12:22:05.227676  3537 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I0930 12:22:18.682780  3537 solver.cpp:218] Iteration 27700 (7.43214 iter/s, 13.4551s/100 iters), loss = 0.259711
I0930 12:22:18.682917  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259711 (* 1 = 0.259711 loss)
I0930 12:22:18.682924  3537 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I0930 12:22:32.147392  3537 solver.cpp:218] Iteration 27800 (7.42697 iter/s, 13.4644s/100 iters), loss = 0.334846
I0930 12:22:32.147423  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.334846 (* 1 = 0.334846 loss)
I0930 12:22:32.147429  3537 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I0930 12:22:45.598073  3537 solver.cpp:218] Iteration 27900 (7.43461 iter/s, 13.4506s/100 iters), loss = 0.206298
I0930 12:22:45.598104  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206298 (* 1 = 0.206298 loss)
I0930 12:22:45.598110  3537 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I0930 12:22:58.386544  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:22:58.923089  3537 solver.cpp:330] Iteration 28000, Testing net (#0)
I0930 12:23:02.031836  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:23:02.160861  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8337
I0930 12:23:02.160884  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.526094 (* 1 = 0.526094 loss)
I0930 12:23:02.294462  3537 solver.cpp:218] Iteration 28000 (5.98935 iter/s, 16.6963s/100 iters), loss = 0.177832
I0930 12:23:02.294497  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177832 (* 1 = 0.177832 loss)
I0930 12:23:02.294504  3537 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I0930 12:23:15.740803  3537 solver.cpp:218] Iteration 28100 (7.43701 iter/s, 13.4463s/100 iters), loss = 0.254987
I0930 12:23:15.740833  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254987 (* 1 = 0.254987 loss)
I0930 12:23:15.740839  3537 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I0930 12:23:29.193976  3537 solver.cpp:218] Iteration 28200 (7.43323 iter/s, 13.4531s/100 iters), loss = 0.378852
I0930 12:23:29.194141  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378852 (* 1 = 0.378852 loss)
I0930 12:23:29.194150  3537 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I0930 12:23:42.638352  3537 solver.cpp:218] Iteration 28300 (7.43817 iter/s, 13.4442s/100 iters), loss = 0.230047
I0930 12:23:42.638384  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230047 (* 1 = 0.230047 loss)
I0930 12:23:42.638391  3537 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I0930 12:23:56.087386  3537 solver.cpp:218] Iteration 28400 (7.43552 iter/s, 13.449s/100 iters), loss = 0.173659
I0930 12:23:56.087427  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173659 (* 1 = 0.173659 loss)
I0930 12:23:56.087435  3537 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I0930 12:24:08.872776  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:24:09.409759  3537 solver.cpp:330] Iteration 28500, Testing net (#0)
I0930 12:24:12.517664  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:24:12.646132  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7883
I0930 12:24:12.646167  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.687689 (* 1 = 0.687689 loss)
I0930 12:24:12.779886  3537 solver.cpp:218] Iteration 28500 (5.99075 iter/s, 16.6924s/100 iters), loss = 0.217679
I0930 12:24:12.779917  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217679 (* 1 = 0.217679 loss)
I0930 12:24:12.779925  3537 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I0930 12:24:26.248107  3537 solver.cpp:218] Iteration 28600 (7.42493 iter/s, 13.4681s/100 iters), loss = 0.239206
I0930 12:24:26.248149  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239205 (* 1 = 0.239205 loss)
I0930 12:24:26.248155  3537 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I0930 12:24:39.709903  3537 solver.cpp:218] Iteration 28700 (7.42848 iter/s, 13.4617s/100 iters), loss = 0.246099
I0930 12:24:39.710047  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246098 (* 1 = 0.246098 loss)
I0930 12:24:39.710057  3537 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I0930 12:24:53.181891  3537 solver.cpp:218] Iteration 28800 (7.42291 iter/s, 13.4718s/100 iters), loss = 0.236772
I0930 12:24:53.181927  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236772 (* 1 = 0.236772 loss)
I0930 12:24:53.181934  3537 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I0930 12:25:06.643788  3537 solver.cpp:218] Iteration 28900 (7.42842 iter/s, 13.4618s/100 iters), loss = 0.191402
I0930 12:25:06.643818  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191402 (* 1 = 0.191402 loss)
I0930 12:25:06.643836  3537 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I0930 12:25:19.441910  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:25:19.978973  3537 solver.cpp:330] Iteration 29000, Testing net (#0)
I0930 12:25:23.083856  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:25:23.212726  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7299
I0930 12:25:23.212761  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.882591 (* 1 = 0.882591 loss)
I0930 12:25:23.346007  3537 solver.cpp:218] Iteration 29000 (5.98726 iter/s, 16.7021s/100 iters), loss = 0.194649
I0930 12:25:23.346041  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194649 (* 1 = 0.194649 loss)
I0930 12:25:23.346048  3537 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I0930 12:25:36.792131  3537 solver.cpp:218] Iteration 29100 (7.43713 iter/s, 13.446s/100 iters), loss = 0.242926
I0930 12:25:36.792161  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242926 (* 1 = 0.242926 loss)
I0930 12:25:36.792167  3537 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I0930 12:25:50.251487  3537 solver.cpp:218] Iteration 29200 (7.42982 iter/s, 13.4593s/100 iters), loss = 0.353225
I0930 12:25:50.251657  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.353225 (* 1 = 0.353225 loss)
I0930 12:25:50.251667  3537 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I0930 12:26:03.692039  3537 solver.cpp:218] Iteration 29300 (7.44029 iter/s, 13.4403s/100 iters), loss = 0.274912
I0930 12:26:03.692070  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274912 (* 1 = 0.274912 loss)
I0930 12:26:03.692075  3537 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I0930 12:26:17.143227  3537 solver.cpp:218] Iteration 29400 (7.43433 iter/s, 13.4511s/100 iters), loss = 0.185448
I0930 12:26:17.143259  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185448 (* 1 = 0.185448 loss)
I0930 12:26:17.143265  3537 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I0930 12:26:29.923773  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:26:30.460930  3537 solver.cpp:330] Iteration 29500, Testing net (#0)
I0930 12:26:33.567764  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:26:33.696779  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.833
I0930 12:26:33.696815  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.509799 (* 1 = 0.509799 loss)
I0930 12:26:33.830293  3537 solver.cpp:218] Iteration 29500 (5.99269 iter/s, 16.687s/100 iters), loss = 0.257608
I0930 12:26:33.830327  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257608 (* 1 = 0.257608 loss)
I0930 12:26:33.830333  3537 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I0930 12:26:47.285702  3537 solver.cpp:218] Iteration 29600 (7.432 iter/s, 13.4553s/100 iters), loss = 0.259967
I0930 12:26:47.285734  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259967 (* 1 = 0.259967 loss)
I0930 12:26:47.285740  3537 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I0930 12:27:00.747606  3537 solver.cpp:218] Iteration 29700 (7.42841 iter/s, 13.4618s/100 iters), loss = 0.246847
I0930 12:27:00.747720  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246846 (* 1 = 0.246846 loss)
I0930 12:27:00.747740  3537 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I0930 12:27:14.219894  3537 solver.cpp:218] Iteration 29800 (7.42273 iter/s, 13.4721s/100 iters), loss = 0.199398
I0930 12:27:14.219925  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199398 (* 1 = 0.199398 loss)
I0930 12:27:14.219933  3537 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I0930 12:27:27.682502  3537 solver.cpp:218] Iteration 29900 (7.42802 iter/s, 13.4625s/100 iters), loss = 0.172443
I0930 12:27:27.682536  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172443 (* 1 = 0.172443 loss)
I0930 12:27:27.682543  3537 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I0930 12:27:40.466540  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:27:41.003680  3537 solver.cpp:330] Iteration 30000, Testing net (#0)
I0930 12:27:44.108621  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:27:44.238191  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8369
I0930 12:27:44.238229  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.501949 (* 1 = 0.501949 loss)
I0930 12:27:44.372561  3537 solver.cpp:218] Iteration 30000 (5.99162 iter/s, 16.69s/100 iters), loss = 0.223744
I0930 12:27:44.372596  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223744 (* 1 = 0.223744 loss)
I0930 12:27:44.372602  3537 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I0930 12:27:57.816371  3537 solver.cpp:218] Iteration 30100 (7.43841 iter/s, 13.4437s/100 iters), loss = 0.248022
I0930 12:27:57.816401  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248022 (* 1 = 0.248022 loss)
I0930 12:27:57.816406  3537 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I0930 12:28:11.277181  3537 solver.cpp:218] Iteration 30200 (7.42901 iter/s, 13.4607s/100 iters), loss = 0.305361
I0930 12:28:11.277282  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305361 (* 1 = 0.305361 loss)
I0930 12:28:11.277289  3537 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I0930 12:28:24.722021  3537 solver.cpp:218] Iteration 30300 (7.43788 iter/s, 13.4447s/100 iters), loss = 0.350551
I0930 12:28:24.722060  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350551 (* 1 = 0.350551 loss)
I0930 12:28:24.722079  3537 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I0930 12:28:38.176642  3537 solver.cpp:218] Iteration 30400 (7.43243 iter/s, 13.4545s/100 iters), loss = 0.224577
I0930 12:28:38.176673  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224577 (* 1 = 0.224577 loss)
I0930 12:28:38.176679  3537 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I0930 12:28:50.966347  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:28:51.502769  3537 solver.cpp:330] Iteration 30500, Testing net (#0)
I0930 12:28:54.609009  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:28:54.738571  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8232
I0930 12:28:54.738607  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.549282 (* 1 = 0.549282 loss)
I0930 12:28:54.872712  3537 solver.cpp:218] Iteration 30500 (5.98946 iter/s, 16.696s/100 iters), loss = 0.200662
I0930 12:28:54.872745  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200661 (* 1 = 0.200661 loss)
I0930 12:28:54.872752  3537 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I0930 12:29:08.329567  3537 solver.cpp:218] Iteration 30600 (7.4312 iter/s, 13.4568s/100 iters), loss = 0.139453
I0930 12:29:08.329598  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139453 (* 1 = 0.139453 loss)
I0930 12:29:08.329605  3537 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I0930 12:29:21.779424  3537 solver.cpp:218] Iteration 30700 (7.43506 iter/s, 13.4498s/100 iters), loss = 0.277182
I0930 12:29:21.779578  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277182 (* 1 = 0.277182 loss)
I0930 12:29:21.779585  3537 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I0930 12:29:35.241802  3537 solver.cpp:218] Iteration 30800 (7.42821 iter/s, 13.4622s/100 iters), loss = 0.269173
I0930 12:29:35.241838  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269173 (* 1 = 0.269173 loss)
I0930 12:29:35.241845  3537 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I0930 12:29:48.697532  3537 solver.cpp:218] Iteration 30900 (7.43182 iter/s, 13.4557s/100 iters), loss = 0.165647
I0930 12:29:48.697566  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165647 (* 1 = 0.165647 loss)
I0930 12:29:48.697571  3537 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I0930 12:30:01.488824  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:30:02.025590  3537 solver.cpp:330] Iteration 31000, Testing net (#0)
I0930 12:30:05.127944  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:30:05.257086  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8517
I0930 12:30:05.257122  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.443831 (* 1 = 0.443831 loss)
I0930 12:30:05.390602  3537 solver.cpp:218] Iteration 31000 (5.99054 iter/s, 16.693s/100 iters), loss = 0.211457
I0930 12:30:05.390636  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211457 (* 1 = 0.211457 loss)
I0930 12:30:05.390642  3537 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I0930 12:30:18.830852  3537 solver.cpp:218] Iteration 31100 (7.44038 iter/s, 13.4402s/100 iters), loss = 0.204944
I0930 12:30:18.830881  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204944 (* 1 = 0.204944 loss)
I0930 12:30:18.830888  3537 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I0930 12:30:32.288599  3537 solver.cpp:218] Iteration 31200 (7.4307 iter/s, 13.4577s/100 iters), loss = 0.212098
I0930 12:30:32.288710  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212098 (* 1 = 0.212098 loss)
I0930 12:30:32.288722  3537 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I0930 12:30:45.729432  3537 solver.cpp:218] Iteration 31300 (7.44009 iter/s, 13.4407s/100 iters), loss = 0.295179
I0930 12:30:45.729465  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295179 (* 1 = 0.295179 loss)
I0930 12:30:45.729475  3537 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I0930 12:30:59.178984  3537 solver.cpp:218] Iteration 31400 (7.43523 iter/s, 13.4495s/100 iters), loss = 0.189754
I0930 12:30:59.179024  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189754 (* 1 = 0.189754 loss)
I0930 12:30:59.179044  3537 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I0930 12:31:11.966567  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:31:12.505713  3537 solver.cpp:330] Iteration 31500, Testing net (#0)
I0930 12:31:15.611831  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:31:15.741089  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8269
I0930 12:31:15.741116  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.550727 (* 1 = 0.550727 loss)
I0930 12:31:15.874963  3537 solver.cpp:218] Iteration 31500 (5.9895 iter/s, 16.6959s/100 iters), loss = 0.19833
I0930 12:31:15.874999  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19833 (* 1 = 0.19833 loss)
I0930 12:31:15.875007  3537 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I0930 12:31:29.334554  3537 solver.cpp:218] Iteration 31600 (7.42969 iter/s, 13.4595s/100 iters), loss = 0.245855
I0930 12:31:29.334585  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245855 (* 1 = 0.245855 loss)
I0930 12:31:29.334592  3537 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I0930 12:31:42.777329  3537 solver.cpp:218] Iteration 31700 (7.43898 iter/s, 13.4427s/100 iters), loss = 0.301165
I0930 12:31:42.777454  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301165 (* 1 = 0.301165 loss)
I0930 12:31:42.777473  3537 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I0930 12:31:56.233741  3537 solver.cpp:218] Iteration 31800 (7.43149 iter/s, 13.4562s/100 iters), loss = 0.319624
I0930 12:31:56.233772  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319624 (* 1 = 0.319624 loss)
I0930 12:31:56.233777  3537 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I0930 12:32:09.686719  3537 solver.cpp:218] Iteration 31900 (7.43334 iter/s, 13.4529s/100 iters), loss = 0.214154
I0930 12:32:09.686761  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214154 (* 1 = 0.214154 loss)
I0930 12:32:09.686769  3537 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I0930 12:32:22.474323  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:32:23.012130  3537 solver.cpp:330] Iteration 32000, Testing net (#0)
I0930 12:32:26.116570  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:32:26.245590  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8405
I0930 12:32:26.245615  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.492699 (* 1 = 0.492699 loss)
I0930 12:32:26.378927  3537 solver.cpp:218] Iteration 32000 (5.99085 iter/s, 16.6921s/100 iters), loss = 0.253737
I0930 12:32:26.378958  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253737 (* 1 = 0.253737 loss)
I0930 12:32:26.378965  3537 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I0930 12:32:39.825481  3537 solver.cpp:218] Iteration 32100 (7.43689 iter/s, 13.4465s/100 iters), loss = 0.204087
I0930 12:32:39.825513  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204087 (* 1 = 0.204087 loss)
I0930 12:32:39.825520  3537 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I0930 12:32:53.292320  3537 solver.cpp:218] Iteration 32200 (7.42569 iter/s, 13.4668s/100 iters), loss = 0.26314
I0930 12:32:53.292445  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26314 (* 1 = 0.26314 loss)
I0930 12:32:53.292454  3537 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I0930 12:33:06.747632  3537 solver.cpp:218] Iteration 32300 (7.4321 iter/s, 13.4551s/100 iters), loss = 0.272054
I0930 12:33:06.747663  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272054 (* 1 = 0.272054 loss)
I0930 12:33:06.747668  3537 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I0930 12:33:20.195958  3537 solver.cpp:218] Iteration 32400 (7.43591 iter/s, 13.4483s/100 iters), loss = 0.154033
I0930 12:33:20.195988  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154033 (* 1 = 0.154033 loss)
I0930 12:33:20.195994  3537 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I0930 12:33:32.982106  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:33:33.518700  3537 solver.cpp:330] Iteration 32500, Testing net (#0)
I0930 12:33:36.624299  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:33:36.752952  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7815
I0930 12:33:36.752977  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.708305 (* 1 = 0.708305 loss)
I0930 12:33:36.886708  3537 solver.cpp:218] Iteration 32500 (5.99137 iter/s, 16.6907s/100 iters), loss = 0.186472
I0930 12:33:36.886742  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186472 (* 1 = 0.186472 loss)
I0930 12:33:36.886749  3537 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I0930 12:33:50.351960  3537 solver.cpp:218] Iteration 32600 (7.42657 iter/s, 13.4652s/100 iters), loss = 0.304956
I0930 12:33:50.351991  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304956 (* 1 = 0.304956 loss)
I0930 12:33:50.351997  3537 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I0930 12:34:03.797041  3537 solver.cpp:218] Iteration 32700 (7.4377 iter/s, 13.445s/100 iters), loss = 0.268535
I0930 12:34:03.797159  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268535 (* 1 = 0.268535 loss)
I0930 12:34:03.797166  3537 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I0930 12:34:17.254055  3537 solver.cpp:218] Iteration 32800 (7.43115 iter/s, 13.4569s/100 iters), loss = 0.296544
I0930 12:34:17.254086  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296544 (* 1 = 0.296544 loss)
I0930 12:34:17.254091  3537 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I0930 12:34:30.707681  3537 solver.cpp:218] Iteration 32900 (7.43298 iter/s, 13.4536s/100 iters), loss = 0.182909
I0930 12:34:30.707710  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182909 (* 1 = 0.182909 loss)
I0930 12:34:30.707716  3537 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I0930 12:34:43.503664  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:34:44.040082  3537 solver.cpp:330] Iteration 33000, Testing net (#0)
I0930 12:34:47.142545  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:34:47.271934  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8028
I0930 12:34:47.271970  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.6198 (* 1 = 0.6198 loss)
I0930 12:34:47.405374  3537 solver.cpp:218] Iteration 33000 (5.98888 iter/s, 16.6976s/100 iters), loss = 0.226319
I0930 12:34:47.405407  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226319 (* 1 = 0.226319 loss)
I0930 12:34:47.405414  3537 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I0930 12:35:00.840677  3537 solver.cpp:218] Iteration 33100 (7.44312 iter/s, 13.4352s/100 iters), loss = 0.290302
I0930 12:35:00.840709  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290302 (* 1 = 0.290302 loss)
I0930 12:35:00.840715  3537 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I0930 12:35:14.298450  3537 solver.cpp:218] Iteration 33200 (7.43069 iter/s, 13.4577s/100 iters), loss = 0.285546
I0930 12:35:14.298569  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285545 (* 1 = 0.285545 loss)
I0930 12:35:14.298586  3537 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I0930 12:35:27.736856  3537 solver.cpp:218] Iteration 33300 (7.44145 iter/s, 13.4382s/100 iters), loss = 0.19418
I0930 12:35:27.736887  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19418 (* 1 = 0.19418 loss)
I0930 12:35:27.736894  3537 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I0930 12:35:41.174775  3537 solver.cpp:218] Iteration 33400 (7.44167 iter/s, 13.4378s/100 iters), loss = 0.232202
I0930 12:35:41.174808  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232202 (* 1 = 0.232202 loss)
I0930 12:35:41.174814  3537 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I0930 12:35:53.956377  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:35:54.492812  3537 solver.cpp:330] Iteration 33500, Testing net (#0)
I0930 12:35:57.596648  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:35:57.725806  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8077
I0930 12:35:57.725832  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.578665 (* 1 = 0.578665 loss)
I0930 12:35:57.861466  3537 solver.cpp:218] Iteration 33500 (5.99283 iter/s, 16.6866s/100 iters), loss = 0.24801
I0930 12:35:57.861500  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24801 (* 1 = 0.24801 loss)
I0930 12:35:57.861507  3537 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I0930 12:36:11.332062  3537 solver.cpp:218] Iteration 33600 (7.42362 iter/s, 13.4705s/100 iters), loss = 0.236301
I0930 12:36:11.332104  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236301 (* 1 = 0.236301 loss)
I0930 12:36:11.332111  3537 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I0930 12:36:24.789702  3537 solver.cpp:218] Iteration 33700 (7.43077 iter/s, 13.4576s/100 iters), loss = 0.196851
I0930 12:36:24.789849  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196851 (* 1 = 0.196851 loss)
I0930 12:36:24.789856  3537 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I0930 12:36:38.253911  3537 solver.cpp:218] Iteration 33800 (7.4272 iter/s, 13.464s/100 iters), loss = 0.252536
I0930 12:36:38.253939  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252536 (* 1 = 0.252536 loss)
I0930 12:36:38.253945  3537 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I0930 12:36:51.722877  3537 solver.cpp:218] Iteration 33900 (7.42451 iter/s, 13.4689s/100 iters), loss = 0.183267
I0930 12:36:51.722908  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183267 (* 1 = 0.183267 loss)
I0930 12:36:51.722913  3537 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I0930 12:37:04.521908  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:37:05.060611  3537 solver.cpp:330] Iteration 34000, Testing net (#0)
I0930 12:37:08.164135  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:37:08.292718  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8371
I0930 12:37:08.292753  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.513212 (* 1 = 0.513212 loss)
I0930 12:37:08.426219  3537 solver.cpp:218] Iteration 34000 (5.98685 iter/s, 16.7033s/100 iters), loss = 0.252454
I0930 12:37:08.426254  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252454 (* 1 = 0.252454 loss)
I0930 12:37:08.426260  3537 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I0930 12:37:21.869135  3537 solver.cpp:218] Iteration 34100 (7.43891 iter/s, 13.4428s/100 iters), loss = 0.180819
I0930 12:37:21.869166  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180819 (* 1 = 0.180819 loss)
I0930 12:37:21.869173  3537 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I0930 12:37:35.334631  3537 solver.cpp:218] Iteration 34200 (7.42643 iter/s, 13.4654s/100 iters), loss = 0.301336
I0930 12:37:35.334735  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301335 (* 1 = 0.301335 loss)
I0930 12:37:35.334751  3537 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I0930 12:37:48.790297  3537 solver.cpp:218] Iteration 34300 (7.43189 iter/s, 13.4555s/100 iters), loss = 0.162288
I0930 12:37:48.790338  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162288 (* 1 = 0.162288 loss)
I0930 12:37:48.790344  3537 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I0930 12:38:02.240739  3537 solver.cpp:218] Iteration 34400 (7.43475 iter/s, 13.4504s/100 iters), loss = 0.215715
I0930 12:38:02.240772  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215715 (* 1 = 0.215715 loss)
I0930 12:38:02.240778  3537 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I0930 12:38:15.019448  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:38:15.555763  3537 solver.cpp:330] Iteration 34500, Testing net (#0)
I0930 12:38:18.661417  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:38:18.790585  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8188
I0930 12:38:18.790611  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.562655 (* 1 = 0.562655 loss)
I0930 12:38:18.923637  3537 solver.cpp:218] Iteration 34500 (5.99419 iter/s, 16.6828s/100 iters), loss = 0.244703
I0930 12:38:18.923667  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244703 (* 1 = 0.244703 loss)
I0930 12:38:18.923674  3537 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I0930 12:38:32.377584  3537 solver.cpp:218] Iteration 34600 (7.4328 iter/s, 13.4539s/100 iters), loss = 0.278929
I0930 12:38:32.377614  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278929 (* 1 = 0.278929 loss)
I0930 12:38:32.377621  3537 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I0930 12:38:45.824662  3537 solver.cpp:218] Iteration 34700 (7.4366 iter/s, 13.447s/100 iters), loss = 0.320046
I0930 12:38:45.824766  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320046 (* 1 = 0.320046 loss)
I0930 12:38:45.824774  3537 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I0930 12:38:59.274936  3537 solver.cpp:218] Iteration 34800 (7.43487 iter/s, 13.4501s/100 iters), loss = 0.400678
I0930 12:38:59.274977  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.400678 (* 1 = 0.400678 loss)
I0930 12:38:59.274984  3537 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I0930 12:39:12.721709  3537 solver.cpp:218] Iteration 34900 (7.43678 iter/s, 13.4467s/100 iters), loss = 0.173093
I0930 12:39:12.721750  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173093 (* 1 = 0.173093 loss)
I0930 12:39:12.721755  3537 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I0930 12:39:25.514677  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:39:26.052357  3537 solver.cpp:330] Iteration 35000, Testing net (#0)
I0930 12:39:29.156261  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:39:29.285450  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7325
I0930 12:39:29.285485  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.927016 (* 1 = 0.927016 loss)
I0930 12:39:29.419558  3537 solver.cpp:218] Iteration 35000 (5.98883 iter/s, 16.6978s/100 iters), loss = 0.258279
I0930 12:39:29.419590  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258279 (* 1 = 0.258279 loss)
I0930 12:39:29.419597  3537 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I0930 12:39:42.857223  3537 solver.cpp:218] Iteration 35100 (7.44181 iter/s, 13.4376s/100 iters), loss = 0.280887
I0930 12:39:42.857252  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280887 (* 1 = 0.280887 loss)
I0930 12:39:42.857261  3537 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I0930 12:39:56.309202  3537 solver.cpp:218] Iteration 35200 (7.43389 iter/s, 13.4519s/100 iters), loss = 0.252291
I0930 12:39:56.309305  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252291 (* 1 = 0.252291 loss)
I0930 12:39:56.309324  3537 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I0930 12:40:09.756561  3537 solver.cpp:218] Iteration 35300 (7.43648 iter/s, 13.4472s/100 iters), loss = 0.353138
I0930 12:40:09.756592  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.353137 (* 1 = 0.353137 loss)
I0930 12:40:09.756598  3537 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I0930 12:40:23.212378  3537 solver.cpp:218] Iteration 35400 (7.43177 iter/s, 13.4557s/100 iters), loss = 0.159237
I0930 12:40:23.212409  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159237 (* 1 = 0.159237 loss)
I0930 12:40:23.212416  3537 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I0930 12:40:35.986255  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:40:36.519929  3537 solver.cpp:330] Iteration 35500, Testing net (#0)
I0930 12:40:39.622999  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:40:39.752336  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8227
I0930 12:40:39.752370  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.558209 (* 1 = 0.558209 loss)
I0930 12:40:39.885824  3537 solver.cpp:218] Iteration 35500 (5.99759 iter/s, 16.6734s/100 iters), loss = 0.204445
I0930 12:40:39.885859  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204445 (* 1 = 0.204445 loss)
I0930 12:40:39.885866  3537 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I0930 12:40:53.344741  3537 solver.cpp:218] Iteration 35600 (7.43006 iter/s, 13.4588s/100 iters), loss = 0.216346
I0930 12:40:53.344776  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216346 (* 1 = 0.216346 loss)
I0930 12:40:53.344785  3537 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I0930 12:41:06.788542  3537 solver.cpp:218] Iteration 35700 (7.43841 iter/s, 13.4437s/100 iters), loss = 0.267557
I0930 12:41:06.788642  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267557 (* 1 = 0.267557 loss)
I0930 12:41:06.788661  3537 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I0930 12:41:20.236707  3537 solver.cpp:218] Iteration 35800 (7.43604 iter/s, 13.448s/100 iters), loss = 0.307684
I0930 12:41:20.236739  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307684 (* 1 = 0.307684 loss)
I0930 12:41:20.236757  3537 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I0930 12:41:33.690277  3537 solver.cpp:218] Iteration 35900 (7.43301 iter/s, 13.4535s/100 iters), loss = 0.154383
I0930 12:41:33.690320  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154383 (* 1 = 0.154383 loss)
I0930 12:41:33.690326  3537 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I0930 12:41:46.483706  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:41:47.020406  3537 solver.cpp:330] Iteration 36000, Testing net (#0)
I0930 12:41:50.126288  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:41:50.255007  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8419
I0930 12:41:50.255033  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.493842 (* 1 = 0.493842 loss)
I0930 12:41:50.388519  3537 solver.cpp:218] Iteration 36000 (5.98869 iter/s, 16.6981s/100 iters), loss = 0.209022
I0930 12:41:50.388551  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209021 (* 1 = 0.209021 loss)
I0930 12:41:50.388559  3537 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I0930 12:42:03.829293  3537 solver.cpp:218] Iteration 36100 (7.44009 iter/s, 13.4407s/100 iters), loss = 0.162589
I0930 12:42:03.829324  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162589 (* 1 = 0.162589 loss)
I0930 12:42:03.829330  3537 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I0930 12:42:17.292871  3537 solver.cpp:218] Iteration 36200 (7.42749 iter/s, 13.4635s/100 iters), loss = 0.302141
I0930 12:42:17.292994  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302141 (* 1 = 0.302141 loss)
I0930 12:42:17.293004  3537 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I0930 12:42:30.744484  3537 solver.cpp:218] Iteration 36300 (7.43414 iter/s, 13.4515s/100 iters), loss = 0.280006
I0930 12:42:30.744514  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280006 (* 1 = 0.280006 loss)
I0930 12:42:30.744520  3537 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I0930 12:42:44.199584  3537 solver.cpp:218] Iteration 36400 (7.43217 iter/s, 13.455s/100 iters), loss = 0.237195
I0930 12:42:44.199616  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237195 (* 1 = 0.237195 loss)
I0930 12:42:44.199633  3537 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I0930 12:42:56.973595  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:42:57.510577  3537 solver.cpp:330] Iteration 36500, Testing net (#0)
I0930 12:43:00.617890  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:43:00.747229  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.842
I0930 12:43:00.747264  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.476863 (* 1 = 0.476863 loss)
I0930 12:43:00.881225  3537 solver.cpp:218] Iteration 36500 (5.99464 iter/s, 16.6816s/100 iters), loss = 0.20092
I0930 12:43:00.881256  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20092 (* 1 = 0.20092 loss)
I0930 12:43:00.881263  3537 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I0930 12:43:14.345212  3537 solver.cpp:218] Iteration 36600 (7.42726 iter/s, 13.4639s/100 iters), loss = 0.195838
I0930 12:43:14.345244  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195838 (* 1 = 0.195838 loss)
I0930 12:43:14.345250  3537 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I0930 12:43:27.799742  3537 solver.cpp:218] Iteration 36700 (7.43248 iter/s, 13.4545s/100 iters), loss = 0.26182
I0930 12:43:27.799870  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26182 (* 1 = 0.26182 loss)
I0930 12:43:27.799886  3537 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I0930 12:43:41.257618  3537 solver.cpp:218] Iteration 36800 (7.43069 iter/s, 13.4577s/100 iters), loss = 0.269451
I0930 12:43:41.257650  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269451 (* 1 = 0.269451 loss)
I0930 12:43:41.257656  3537 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I0930 12:43:54.709972  3537 solver.cpp:218] Iteration 36900 (7.43368 iter/s, 13.4523s/100 iters), loss = 0.22604
I0930 12:43:54.710003  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22604 (* 1 = 0.22604 loss)
I0930 12:43:54.710009  3537 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I0930 12:44:07.510255  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:44:08.046358  3537 solver.cpp:330] Iteration 37000, Testing net (#0)
I0930 12:44:11.152989  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:44:11.281817  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8304
I0930 12:44:11.281857  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.520956 (* 1 = 0.520956 loss)
I0930 12:44:11.415874  3537 solver.cpp:218] Iteration 37000 (5.98594 iter/s, 16.7058s/100 iters), loss = 0.229864
I0930 12:44:11.415913  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229864 (* 1 = 0.229864 loss)
I0930 12:44:11.415922  3537 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I0930 12:44:24.854461  3537 solver.cpp:218] Iteration 37100 (7.4413 iter/s, 13.4385s/100 iters), loss = 0.286348
I0930 12:44:24.854491  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286348 (* 1 = 0.286348 loss)
I0930 12:44:24.854497  3537 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I0930 12:44:38.303596  3537 solver.cpp:218] Iteration 37200 (7.43546 iter/s, 13.4491s/100 iters), loss = 0.223049
I0930 12:44:38.303694  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223049 (* 1 = 0.223049 loss)
I0930 12:44:38.303710  3537 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I0930 12:44:51.759500  3537 solver.cpp:218] Iteration 37300 (7.43176 iter/s, 13.4558s/100 iters), loss = 0.248376
I0930 12:44:51.759531  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248375 (* 1 = 0.248375 loss)
I0930 12:44:51.759547  3537 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I0930 12:45:05.222322  3537 solver.cpp:218] Iteration 37400 (7.4279 iter/s, 13.4627s/100 iters), loss = 0.16319
I0930 12:45:05.222353  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16319 (* 1 = 0.16319 loss)
I0930 12:45:05.222359  3537 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I0930 12:45:17.997048  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:45:18.535554  3537 solver.cpp:330] Iteration 37500, Testing net (#0)
I0930 12:45:21.636497  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:45:21.765579  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7993
I0930 12:45:21.765614  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.661298 (* 1 = 0.661298 loss)
I0930 12:45:21.899492  3537 solver.cpp:218] Iteration 37500 (5.99625 iter/s, 16.6771s/100 iters), loss = 0.229628
I0930 12:45:21.899521  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229628 (* 1 = 0.229628 loss)
I0930 12:45:21.899528  3537 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I0930 12:45:35.365725  3537 solver.cpp:218] Iteration 37600 (7.42602 iter/s, 13.4662s/100 iters), loss = 0.19444
I0930 12:45:35.365769  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19444 (* 1 = 0.19444 loss)
I0930 12:45:35.365777  3537 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I0930 12:45:48.827714  3537 solver.cpp:218] Iteration 37700 (7.42837 iter/s, 13.4619s/100 iters), loss = 0.330243
I0930 12:45:48.827859  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330243 (* 1 = 0.330243 loss)
I0930 12:45:48.827867  3537 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I0930 12:46:02.286593  3537 solver.cpp:218] Iteration 37800 (7.43014 iter/s, 13.4587s/100 iters), loss = 0.250396
I0930 12:46:02.286626  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250396 (* 1 = 0.250396 loss)
I0930 12:46:02.286633  3537 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I0930 12:46:15.737989  3537 solver.cpp:218] Iteration 37900 (7.43421 iter/s, 13.4513s/100 iters), loss = 0.227934
I0930 12:46:15.738019  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227934 (* 1 = 0.227934 loss)
I0930 12:46:15.738026  3537 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I0930 12:46:28.531014  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:46:29.068980  3537 solver.cpp:330] Iteration 38000, Testing net (#0)
I0930 12:46:32.175317  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:46:32.304654  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8398
I0930 12:46:32.304682  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.513368 (* 1 = 0.513368 loss)
I0930 12:46:32.438261  3537 solver.cpp:218] Iteration 38000 (5.98796 iter/s, 16.7002s/100 iters), loss = 0.290467
I0930 12:46:32.438294  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290467 (* 1 = 0.290467 loss)
I0930 12:46:32.438302  3537 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I0930 12:46:45.874315  3537 solver.cpp:218] Iteration 38100 (7.4427 iter/s, 13.436s/100 iters), loss = 0.17174
I0930 12:46:45.874343  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17174 (* 1 = 0.17174 loss)
I0930 12:46:45.874349  3537 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I0930 12:46:59.322080  3537 solver.cpp:218] Iteration 38200 (7.43622 iter/s, 13.4477s/100 iters), loss = 0.28284
I0930 12:46:59.322187  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28284 (* 1 = 0.28284 loss)
I0930 12:46:59.322196  3537 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I0930 12:47:12.776207  3537 solver.cpp:218] Iteration 38300 (7.43274 iter/s, 13.454s/100 iters), loss = 0.254185
I0930 12:47:12.776237  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254185 (* 1 = 0.254185 loss)
I0930 12:47:12.776243  3537 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I0930 12:47:26.239809  3537 solver.cpp:218] Iteration 38400 (7.42747 iter/s, 13.4635s/100 iters), loss = 0.13728
I0930 12:47:26.239843  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13728 (* 1 = 0.13728 loss)
I0930 12:47:26.239851  3537 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I0930 12:47:39.016003  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:47:39.552613  3537 solver.cpp:330] Iteration 38500, Testing net (#0)
I0930 12:47:42.654218  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:47:42.783269  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7987
I0930 12:47:42.783294  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.65233 (* 1 = 0.65233 loss)
I0930 12:47:42.916932  3537 solver.cpp:218] Iteration 38500 (5.99627 iter/s, 16.677s/100 iters), loss = 0.221076
I0930 12:47:42.916968  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221076 (* 1 = 0.221076 loss)
I0930 12:47:42.916977  3537 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I0930 12:47:56.460872  3537 solver.cpp:218] Iteration 38600 (7.38342 iter/s, 13.5439s/100 iters), loss = 0.220581
I0930 12:47:56.460906  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220581 (* 1 = 0.220581 loss)
I0930 12:47:56.460914  3537 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I0930 12:48:09.988639  3537 solver.cpp:218] Iteration 38700 (7.39224 iter/s, 13.5277s/100 iters), loss = 0.274684
I0930 12:48:09.988807  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274684 (* 1 = 0.274684 loss)
I0930 12:48:09.988819  3537 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I0930 12:48:23.559429  3537 solver.cpp:218] Iteration 38800 (7.36888 iter/s, 13.5706s/100 iters), loss = 0.28294
I0930 12:48:23.559463  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28294 (* 1 = 0.28294 loss)
I0930 12:48:23.559473  3537 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I0930 12:48:36.994994  3537 solver.cpp:218] Iteration 38900 (7.44297 iter/s, 13.4355s/100 iters), loss = 0.181055
I0930 12:48:36.995026  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181055 (* 1 = 0.181055 loss)
I0930 12:48:36.995045  3537 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I0930 12:48:49.789518  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:48:50.326781  3537 solver.cpp:330] Iteration 39000, Testing net (#0)
I0930 12:48:53.432827  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:48:53.562137  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8363
I0930 12:48:53.562165  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.493927 (* 1 = 0.493927 loss)
I0930 12:48:53.695623  3537 solver.cpp:218] Iteration 39000 (5.98783 iter/s, 16.7005s/100 iters), loss = 0.200824
I0930 12:48:53.695659  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200824 (* 1 = 0.200824 loss)
I0930 12:48:53.695669  3537 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I0930 12:49:07.154050  3537 solver.cpp:218] Iteration 39100 (7.43034 iter/s, 13.4583s/100 iters), loss = 0.256509
I0930 12:49:07.154088  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256509 (* 1 = 0.256509 loss)
I0930 12:49:07.154095  3537 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I0930 12:49:20.617741  3537 solver.cpp:218] Iteration 39200 (7.42743 iter/s, 13.4636s/100 iters), loss = 0.231084
I0930 12:49:20.617883  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231084 (* 1 = 0.231084 loss)
I0930 12:49:20.617905  3537 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I0930 12:49:34.080206  3537 solver.cpp:218] Iteration 39300 (7.42815 iter/s, 13.4623s/100 iters), loss = 0.267046
I0930 12:49:34.080240  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267046 (* 1 = 0.267046 loss)
I0930 12:49:34.080257  3537 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I0930 12:49:47.551640  3537 solver.cpp:218] Iteration 39400 (7.42315 iter/s, 13.4714s/100 iters), loss = 0.135346
I0930 12:49:47.551672  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135346 (* 1 = 0.135346 loss)
I0930 12:49:47.551681  3537 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I0930 12:50:00.337249  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:50:00.875346  3537 solver.cpp:330] Iteration 39500, Testing net (#0)
I0930 12:50:03.979506  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:50:04.108947  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8254
I0930 12:50:04.108973  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.53806 (* 1 = 0.53806 loss)
I0930 12:50:04.242560  3537 solver.cpp:218] Iteration 39500 (5.99131 iter/s, 16.6908s/100 iters), loss = 0.200142
I0930 12:50:04.242604  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200141 (* 1 = 0.200141 loss)
I0930 12:50:04.242624  3537 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I0930 12:50:17.698716  3537 solver.cpp:218] Iteration 39600 (7.43159 iter/s, 13.4561s/100 iters), loss = 0.191947
I0930 12:50:17.698751  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191947 (* 1 = 0.191947 loss)
I0930 12:50:17.698770  3537 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I0930 12:50:31.155237  3537 solver.cpp:218] Iteration 39700 (7.43138 iter/s, 13.4564s/100 iters), loss = 0.22943
I0930 12:50:31.155402  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22943 (* 1 = 0.22943 loss)
I0930 12:50:31.155427  3537 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I0930 12:50:44.620551  3537 solver.cpp:218] Iteration 39800 (7.4266 iter/s, 13.4651s/100 iters), loss = 0.329924
I0930 12:50:44.620586  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329924 (* 1 = 0.329924 loss)
I0930 12:50:44.620595  3537 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I0930 12:50:58.059628  3537 solver.cpp:218] Iteration 39900 (7.44103 iter/s, 13.439s/100 iters), loss = 0.17832
I0930 12:50:58.059659  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17832 (* 1 = 0.17832 loss)
I0930 12:50:58.059667  3537 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I0930 12:51:10.859064  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:51:11.395464  3537 solver.cpp:330] Iteration 40000, Testing net (#0)
I0930 12:51:14.502761  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:51:14.631974  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7812
I0930 12:51:14.632010  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.715641 (* 1 = 0.715641 loss)
I0930 12:51:14.765676  3537 solver.cpp:218] Iteration 40000 (5.98589 iter/s, 16.706s/100 iters), loss = 0.249811
I0930 12:51:14.765709  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249811 (* 1 = 0.249811 loss)
I0930 12:51:14.765715  3537 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I0930 12:51:14.765718  3537 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I0930 12:51:28.209189  3537 solver.cpp:218] Iteration 40100 (7.43857 iter/s, 13.4434s/100 iters), loss = 0.21079
I0930 12:51:28.209230  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21079 (* 1 = 0.21079 loss)
I0930 12:51:28.209236  3537 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I0930 12:51:41.669167  3537 solver.cpp:218] Iteration 40200 (7.42948 iter/s, 13.4599s/100 iters), loss = 0.18215
I0930 12:51:41.669268  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18215 (* 1 = 0.18215 loss)
I0930 12:51:41.669286  3537 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I0930 12:51:55.120615  3537 solver.cpp:218] Iteration 40300 (7.43422 iter/s, 13.4513s/100 iters), loss = 0.128483
I0930 12:51:55.120645  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128483 (* 1 = 0.128483 loss)
I0930 12:51:55.120651  3537 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I0930 12:52:08.590610  3537 solver.cpp:218] Iteration 40400 (7.42395 iter/s, 13.4699s/100 iters), loss = 0.138852
I0930 12:52:08.590641  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.138852 (* 1 = 0.138852 loss)
I0930 12:52:08.590646  3537 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I0930 12:52:21.380740  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:52:21.917758  3537 solver.cpp:330] Iteration 40500, Testing net (#0)
I0930 12:52:25.021687  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:52:25.151021  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8923
I0930 12:52:25.151057  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313771 (* 1 = 0.313771 loss)
I0930 12:52:25.285006  3537 solver.cpp:218] Iteration 40500 (5.99006 iter/s, 16.6943s/100 iters), loss = 0.0658047
I0930 12:52:25.285053  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0658046 (* 1 = 0.0658046 loss)
I0930 12:52:25.285060  3537 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I0930 12:52:38.735685  3537 solver.cpp:218] Iteration 40600 (7.43464 iter/s, 13.4506s/100 iters), loss = 0.170673
I0930 12:52:38.735715  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170673 (* 1 = 0.170673 loss)
I0930 12:52:38.735721  3537 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I0930 12:52:52.184244  3537 solver.cpp:218] Iteration 40700 (7.43578 iter/s, 13.4485s/100 iters), loss = 0.201638
I0930 12:52:52.184428  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201638 (* 1 = 0.201638 loss)
I0930 12:52:52.184437  3537 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I0930 12:53:05.635458  3537 solver.cpp:218] Iteration 40800 (7.43439 iter/s, 13.451s/100 iters), loss = 0.0918141
I0930 12:53:05.635489  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.091814 (* 1 = 0.091814 loss)
I0930 12:53:05.635505  3537 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I0930 12:53:19.077894  3537 solver.cpp:218] Iteration 40900 (7.43917 iter/s, 13.4424s/100 iters), loss = 0.118815
I0930 12:53:19.077934  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.118815 (* 1 = 0.118815 loss)
I0930 12:53:19.077941  3537 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I0930 12:53:31.875351  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:53:32.412539  3537 solver.cpp:330] Iteration 41000, Testing net (#0)
I0930 12:53:35.518035  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:53:35.647191  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.893
I0930 12:53:35.647225  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31244 (* 1 = 0.31244 loss)
I0930 12:53:35.780964  3537 solver.cpp:218] Iteration 41000 (5.98695 iter/s, 16.703s/100 iters), loss = 0.0871776
I0930 12:53:35.780998  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0871776 (* 1 = 0.0871776 loss)
I0930 12:53:35.781005  3537 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I0930 12:53:49.237256  3537 solver.cpp:218] Iteration 41100 (7.43151 iter/s, 13.4562s/100 iters), loss = 0.14926
I0930 12:53:49.237300  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14926 (* 1 = 0.14926 loss)
I0930 12:53:49.237308  3537 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I0930 12:54:02.698640  3537 solver.cpp:218] Iteration 41200 (7.4287 iter/s, 13.4613s/100 iters), loss = 0.156416
I0930 12:54:02.698750  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156416 (* 1 = 0.156416 loss)
I0930 12:54:02.698757  3537 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I0930 12:54:16.152097  3537 solver.cpp:218] Iteration 41300 (7.43311 iter/s, 13.4533s/100 iters), loss = 0.134886
I0930 12:54:16.152139  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134886 (* 1 = 0.134886 loss)
I0930 12:54:16.152145  3537 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I0930 12:54:29.612355  3537 solver.cpp:218] Iteration 41400 (7.42932 iter/s, 13.4602s/100 iters), loss = 0.0538579
I0930 12:54:29.612396  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0538578 (* 1 = 0.0538578 loss)
I0930 12:54:29.612402  3537 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I0930 12:54:42.394673  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:54:42.930984  3537 solver.cpp:330] Iteration 41500, Testing net (#0)
I0930 12:54:46.036211  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:54:46.164862  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8927
I0930 12:54:46.164887  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320147 (* 1 = 0.320147 loss)
I0930 12:54:46.299821  3537 solver.cpp:218] Iteration 41500 (5.99255 iter/s, 16.6874s/100 iters), loss = 0.0504866
I0930 12:54:46.299868  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0504865 (* 1 = 0.0504865 loss)
I0930 12:54:46.299886  3537 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I0930 12:54:59.745414  3537 solver.cpp:218] Iteration 41600 (7.43745 iter/s, 13.4455s/100 iters), loss = 0.130891
I0930 12:54:59.745445  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.130891 (* 1 = 0.130891 loss)
I0930 12:54:59.745451  3537 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I0930 12:55:13.202056  3537 solver.cpp:218] Iteration 41700 (7.43131 iter/s, 13.4566s/100 iters), loss = 0.148623
I0930 12:55:13.202162  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148623 (* 1 = 0.148623 loss)
I0930 12:55:13.202178  3537 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I0930 12:55:26.666771  3537 solver.cpp:218] Iteration 41800 (7.4269 iter/s, 13.4646s/100 iters), loss = 0.059268
I0930 12:55:26.666802  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0592679 (* 1 = 0.0592679 loss)
I0930 12:55:26.666810  3537 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I0930 12:55:40.111347  3537 solver.cpp:218] Iteration 41900 (7.43798 iter/s, 13.4445s/100 iters), loss = 0.140702
I0930 12:55:40.111379  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140702 (* 1 = 0.140702 loss)
I0930 12:55:40.111387  3537 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I0930 12:55:52.900239  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:55:53.436806  3537 solver.cpp:330] Iteration 42000, Testing net (#0)
I0930 12:55:56.543107  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:55:56.671958  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8931
I0930 12:55:56.671993  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324382 (* 1 = 0.324382 loss)
I0930 12:55:56.805519  3537 solver.cpp:218] Iteration 42000 (5.99014 iter/s, 16.6941s/100 iters), loss = 0.0429221
I0930 12:55:56.805552  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.042922 (* 1 = 0.042922 loss)
I0930 12:55:56.805557  3537 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I0930 12:56:10.256186  3537 solver.cpp:218] Iteration 42100 (7.43462 iter/s, 13.4506s/100 iters), loss = 0.0936636
I0930 12:56:10.256217  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0936635 (* 1 = 0.0936635 loss)
I0930 12:56:10.256222  3537 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I0930 12:56:23.712476  3537 solver.cpp:218] Iteration 42200 (7.43151 iter/s, 13.4562s/100 iters), loss = 0.114586
I0930 12:56:23.712589  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114586 (* 1 = 0.114586 loss)
I0930 12:56:23.712597  3537 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I0930 12:56:37.164633  3537 solver.cpp:218] Iteration 42300 (7.43384 iter/s, 13.452s/100 iters), loss = 0.109999
I0930 12:56:37.164674  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.109999 (* 1 = 0.109999 loss)
I0930 12:56:37.164680  3537 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I0930 12:56:50.630615  3537 solver.cpp:218] Iteration 42400 (7.42617 iter/s, 13.4659s/100 iters), loss = 0.0724054
I0930 12:56:50.630645  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0724052 (* 1 = 0.0724052 loss)
I0930 12:56:50.630651  3537 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I0930 12:57:03.424942  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:57:03.962363  3537 solver.cpp:330] Iteration 42500, Testing net (#0)
I0930 12:57:07.065227  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:57:07.194810  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.896
I0930 12:57:07.194845  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308655 (* 1 = 0.308655 loss)
I0930 12:57:07.330279  3537 solver.cpp:218] Iteration 42500 (5.98817 iter/s, 16.6996s/100 iters), loss = 0.0639411
I0930 12:57:07.330314  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.063941 (* 1 = 0.063941 loss)
I0930 12:57:07.330322  3537 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I0930 12:57:20.789017  3537 solver.cpp:218] Iteration 42600 (7.43016 iter/s, 13.4587s/100 iters), loss = 0.1081
I0930 12:57:20.789049  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1081 (* 1 = 0.1081 loss)
I0930 12:57:20.789055  3537 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I0930 12:57:34.259367  3537 solver.cpp:218] Iteration 42700 (7.42375 iter/s, 13.4703s/100 iters), loss = 0.140379
I0930 12:57:34.259495  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140379 (* 1 = 0.140379 loss)
I0930 12:57:34.259505  3537 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I0930 12:57:47.798640  3537 solver.cpp:218] Iteration 42800 (7.38601 iter/s, 13.5391s/100 iters), loss = 0.0838517
I0930 12:57:47.798674  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0838515 (* 1 = 0.0838515 loss)
I0930 12:57:47.798681  3537 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I0930 12:58:01.274516  3537 solver.cpp:218] Iteration 42900 (7.42071 iter/s, 13.4758s/100 iters), loss = 0.0371291
I0930 12:58:01.274549  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0371289 (* 1 = 0.0371289 loss)
I0930 12:58:01.274556  3537 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I0930 12:58:14.077908  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:58:14.617439  3537 solver.cpp:330] Iteration 43000, Testing net (#0)
I0930 12:58:17.723225  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:58:17.852375  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8967
I0930 12:58:17.852398  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313249 (* 1 = 0.313249 loss)
I0930 12:58:17.986351  3537 solver.cpp:218] Iteration 43000 (5.98381 iter/s, 16.7118s/100 iters), loss = 0.0644261
I0930 12:58:17.986385  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.064426 (* 1 = 0.064426 loss)
I0930 12:58:17.986392  3537 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I0930 12:58:31.448937  3537 solver.cpp:218] Iteration 43100 (7.42804 iter/s, 13.4625s/100 iters), loss = 0.0980493
I0930 12:58:31.448976  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0980492 (* 1 = 0.0980492 loss)
I0930 12:58:31.448984  3537 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I0930 12:58:44.912420  3537 solver.cpp:218] Iteration 43200 (7.42754 iter/s, 13.4634s/100 iters), loss = 0.133407
I0930 12:58:44.912533  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133407 (* 1 = 0.133407 loss)
I0930 12:58:44.912549  3537 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I0930 12:58:58.364418  3537 solver.cpp:218] Iteration 43300 (7.43392 iter/s, 13.4519s/100 iters), loss = 0.0779683
I0930 12:58:58.364456  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0779682 (* 1 = 0.0779682 loss)
I0930 12:58:58.364465  3537 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I0930 12:59:11.834506  3537 solver.cpp:218] Iteration 43400 (7.42392 iter/s, 13.47s/100 iters), loss = 0.0443898
I0930 12:59:11.834538  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0443897 (* 1 = 0.0443897 loss)
I0930 12:59:11.834544  3537 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I0930 12:59:24.629837  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:59:25.167265  3537 solver.cpp:330] Iteration 43500, Testing net (#0)
I0930 12:59:28.272208  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 12:59:28.404434  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8955
I0930 12:59:28.404460  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320538 (* 1 = 0.320538 loss)
I0930 12:59:28.541752  3537 solver.cpp:218] Iteration 43500 (5.98546 iter/s, 16.7072s/100 iters), loss = 0.0679537
I0930 12:59:28.541800  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0679536 (* 1 = 0.0679536 loss)
I0930 12:59:28.541816  3537 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I0930 12:59:41.979395  3537 solver.cpp:218] Iteration 43600 (7.44185 iter/s, 13.4375s/100 iters), loss = 0.127101
I0930 12:59:41.979425  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1271 (* 1 = 0.1271 loss)
I0930 12:59:41.979431  3537 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I0930 12:59:55.428333  3537 solver.cpp:218] Iteration 43700 (7.43557 iter/s, 13.4489s/100 iters), loss = 0.0742863
I0930 12:59:55.428529  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0742861 (* 1 = 0.0742861 loss)
I0930 12:59:55.428551  3537 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I0930 13:00:08.878453  3537 solver.cpp:218] Iteration 43800 (7.43502 iter/s, 13.4499s/100 iters), loss = 0.10325
I0930 13:00:08.878484  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10325 (* 1 = 0.10325 loss)
I0930 13:00:08.878500  3537 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I0930 13:00:22.325122  3537 solver.cpp:218] Iteration 43900 (7.43683 iter/s, 13.4466s/100 iters), loss = 0.0513172
I0930 13:00:22.325157  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0513171 (* 1 = 0.0513171 loss)
I0930 13:00:22.325175  3537 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I0930 13:00:35.111429  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:00:35.646832  3537 solver.cpp:330] Iteration 44000, Testing net (#0)
I0930 13:00:38.753249  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:00:38.882611  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8984
I0930 13:00:38.882644  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307833 (* 1 = 0.307833 loss)
I0930 13:00:39.016103  3537 solver.cpp:218] Iteration 44000 (5.9913 iter/s, 16.6909s/100 iters), loss = 0.0424313
I0930 13:00:39.016136  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0424311 (* 1 = 0.0424311 loss)
I0930 13:00:39.016144  3537 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I0930 13:00:52.484557  3537 solver.cpp:218] Iteration 44100 (7.4248 iter/s, 13.4684s/100 iters), loss = 0.12375
I0930 13:00:52.484606  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12375 (* 1 = 0.12375 loss)
I0930 13:00:52.484613  3537 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I0930 13:01:05.946288  3537 solver.cpp:218] Iteration 44200 (7.42853 iter/s, 13.4616s/100 iters), loss = 0.0824564
I0930 13:01:05.946395  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0824562 (* 1 = 0.0824562 loss)
I0930 13:01:05.946403  3537 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I0930 13:01:19.395543  3537 solver.cpp:218] Iteration 44300 (7.43544 iter/s, 13.4491s/100 iters), loss = 0.068069
I0930 13:01:19.395591  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0680687 (* 1 = 0.0680687 loss)
I0930 13:01:19.395598  3537 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I0930 13:01:32.854138  3537 solver.cpp:218] Iteration 44400 (7.43026 iter/s, 13.4585s/100 iters), loss = 0.106343
I0930 13:01:32.854180  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106343 (* 1 = 0.106343 loss)
I0930 13:01:32.854187  3537 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I0930 13:01:45.652724  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:01:46.189527  3537 solver.cpp:330] Iteration 44500, Testing net (#0)
I0930 13:01:49.299409  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:01:49.431867  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8939
I0930 13:01:49.431895  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329326 (* 1 = 0.329326 loss)
I0930 13:01:49.569232  3537 solver.cpp:218] Iteration 44500 (5.98265 iter/s, 16.715s/100 iters), loss = 0.0630452
I0930 13:01:49.569267  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.063045 (* 1 = 0.063045 loss)
I0930 13:01:49.569275  3537 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I0930 13:02:03.021661  3537 solver.cpp:218] Iteration 44600 (7.43365 iter/s, 13.4524s/100 iters), loss = 0.122485
I0930 13:02:03.021692  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.122485 (* 1 = 0.122485 loss)
I0930 13:02:03.021699  3537 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I0930 13:02:16.475337  3537 solver.cpp:218] Iteration 44700 (7.43295 iter/s, 13.4536s/100 iters), loss = 0.139457
I0930 13:02:16.475520  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139457 (* 1 = 0.139457 loss)
I0930 13:02:16.475543  3537 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I0930 13:02:29.936640  3537 solver.cpp:218] Iteration 44800 (7.42882 iter/s, 13.4611s/100 iters), loss = 0.0752155
I0930 13:02:29.936671  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0752153 (* 1 = 0.0752153 loss)
I0930 13:02:29.936678  3537 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I0930 13:02:43.390919  3537 solver.cpp:218] Iteration 44900 (7.43262 iter/s, 13.4542s/100 iters), loss = 0.0575738
I0930 13:02:43.390956  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0575736 (* 1 = 0.0575736 loss)
I0930 13:02:43.390964  3537 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I0930 13:02:56.178063  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:02:56.715195  3537 solver.cpp:330] Iteration 45000, Testing net (#0)
I0930 13:02:59.820559  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:02:59.950985  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8957
I0930 13:02:59.951011  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328401 (* 1 = 0.328401 loss)
I0930 13:03:00.083995  3537 solver.cpp:218] Iteration 45000 (5.99054 iter/s, 16.693s/100 iters), loss = 0.047733
I0930 13:03:00.084025  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0477328 (* 1 = 0.0477328 loss)
I0930 13:03:00.084031  3537 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I0930 13:03:13.544575  3537 solver.cpp:218] Iteration 45100 (7.42914 iter/s, 13.4605s/100 iters), loss = 0.0680909
I0930 13:03:13.544622  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0680907 (* 1 = 0.0680907 loss)
I0930 13:03:13.544631  3537 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I0930 13:03:26.999141  3537 solver.cpp:218] Iteration 45200 (7.43249 iter/s, 13.4544s/100 iters), loss = 0.100748
I0930 13:03:26.999253  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.100748 (* 1 = 0.100748 loss)
I0930 13:03:26.999271  3537 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I0930 13:03:40.449793  3537 solver.cpp:218] Iteration 45300 (7.43466 iter/s, 13.4505s/100 iters), loss = 0.053737
I0930 13:03:40.449828  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0537368 (* 1 = 0.0537368 loss)
I0930 13:03:40.449836  3537 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I0930 13:03:53.900583  3537 solver.cpp:218] Iteration 45400 (7.43455 iter/s, 13.4507s/100 iters), loss = 0.0616109
I0930 13:03:53.900614  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0616107 (* 1 = 0.0616107 loss)
I0930 13:03:53.900619  3537 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I0930 13:04:06.686643  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:04:07.223412  3537 solver.cpp:330] Iteration 45500, Testing net (#0)
I0930 13:04:10.331394  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:04:10.464470  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9023
I0930 13:04:10.464529  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308023 (* 1 = 0.308023 loss)
I0930 13:04:10.600751  3537 solver.cpp:218] Iteration 45500 (5.98799 iter/s, 16.7001s/100 iters), loss = 0.0643113
I0930 13:04:10.600788  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0643111 (* 1 = 0.0643111 loss)
I0930 13:04:10.600795  3537 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I0930 13:04:24.052857  3537 solver.cpp:218] Iteration 45600 (7.43383 iter/s, 13.452s/100 iters), loss = 0.0841831
I0930 13:04:24.052887  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0841829 (* 1 = 0.0841829 loss)
I0930 13:04:24.052894  3537 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I0930 13:04:37.522763  3537 solver.cpp:218] Iteration 45700 (7.424 iter/s, 13.4698s/100 iters), loss = 0.0998499
I0930 13:04:37.522922  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0998497 (* 1 = 0.0998497 loss)
I0930 13:04:37.522941  3537 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I0930 13:04:50.995842  3537 solver.cpp:218] Iteration 45800 (7.42233 iter/s, 13.4729s/100 iters), loss = 0.0911014
I0930 13:04:50.995873  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0911012 (* 1 = 0.0911012 loss)
I0930 13:04:50.995880  3537 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I0930 13:05:04.459450  3537 solver.cpp:218] Iteration 45900 (7.42747 iter/s, 13.4635s/100 iters), loss = 0.031539
I0930 13:05:04.459486  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0315388 (* 1 = 0.0315388 loss)
I0930 13:05:04.459494  3537 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I0930 13:05:17.261492  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:05:17.799409  3537 solver.cpp:330] Iteration 46000, Testing net (#0)
I0930 13:05:20.907999  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:05:21.037693  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8955
I0930 13:05:21.037716  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.332747 (* 1 = 0.332747 loss)
I0930 13:05:21.171968  3537 solver.cpp:218] Iteration 46000 (5.98357 iter/s, 16.7124s/100 iters), loss = 0.0437957
I0930 13:05:21.172000  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0437955 (* 1 = 0.0437955 loss)
I0930 13:05:21.172008  3537 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I0930 13:05:34.628836  3537 solver.cpp:218] Iteration 46100 (7.43119 iter/s, 13.4568s/100 iters), loss = 0.133419
I0930 13:05:34.628885  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133419 (* 1 = 0.133419 loss)
I0930 13:05:34.628893  3537 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I0930 13:05:48.083026  3537 solver.cpp:218] Iteration 46200 (7.43269 iter/s, 13.4541s/100 iters), loss = 0.103413
I0930 13:05:48.083112  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103413 (* 1 = 0.103413 loss)
I0930 13:05:48.083119  3537 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I0930 13:06:01.530936  3537 solver.cpp:218] Iteration 46300 (7.43617 iter/s, 13.4478s/100 iters), loss = 0.0488264
I0930 13:06:01.530984  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0488262 (* 1 = 0.0488262 loss)
I0930 13:06:01.530992  3537 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I0930 13:06:14.984164  3537 solver.cpp:218] Iteration 46400 (7.43323 iter/s, 13.4531s/100 iters), loss = 0.0918561
I0930 13:06:14.984196  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0918559 (* 1 = 0.0918559 loss)
I0930 13:06:14.984202  3537 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I0930 13:06:27.763835  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:06:28.300056  3537 solver.cpp:330] Iteration 46500, Testing net (#0)
I0930 13:06:31.408771  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:06:31.544138  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8975
I0930 13:06:31.544167  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325902 (* 1 = 0.325902 loss)
I0930 13:06:31.680847  3537 solver.cpp:218] Iteration 46500 (5.98924 iter/s, 16.6966s/100 iters), loss = 0.0247999
I0930 13:06:31.680882  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0247996 (* 1 = 0.0247996 loss)
I0930 13:06:31.680891  3537 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I0930 13:06:45.129871  3537 solver.cpp:218] Iteration 46600 (7.43553 iter/s, 13.4489s/100 iters), loss = 0.102006
I0930 13:06:45.129902  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102006 (* 1 = 0.102006 loss)
I0930 13:06:45.129909  3537 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I0930 13:06:58.580312  3537 solver.cpp:218] Iteration 46700 (7.43474 iter/s, 13.4504s/100 iters), loss = 0.0761491
I0930 13:06:58.580449  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0761488 (* 1 = 0.0761488 loss)
I0930 13:06:58.580458  3537 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I0930 13:07:12.047170  3537 solver.cpp:218] Iteration 46800 (7.42573 iter/s, 13.4667s/100 iters), loss = 0.0279119
I0930 13:07:12.047199  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0279116 (* 1 = 0.0279116 loss)
I0930 13:07:12.047205  3537 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I0930 13:07:25.509861  3537 solver.cpp:218] Iteration 46900 (7.42798 iter/s, 13.4626s/100 iters), loss = 0.0616976
I0930 13:07:25.509899  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0616973 (* 1 = 0.0616973 loss)
I0930 13:07:25.509907  3537 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I0930 13:07:38.289798  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:07:38.826822  3537 solver.cpp:330] Iteration 47000, Testing net (#0)
I0930 13:07:41.930467  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:07:42.059193  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8962
I0930 13:07:42.059228  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324822 (* 1 = 0.324822 loss)
I0930 13:07:42.193169  3537 solver.cpp:218] Iteration 47000 (5.99405 iter/s, 16.6832s/100 iters), loss = 0.0392156
I0930 13:07:42.193199  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0392153 (* 1 = 0.0392153 loss)
I0930 13:07:42.193207  3537 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I0930 13:07:55.663938  3537 solver.cpp:218] Iteration 47100 (7.42352 iter/s, 13.4707s/100 iters), loss = 0.0751931
I0930 13:07:55.663975  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0751929 (* 1 = 0.0751929 loss)
I0930 13:07:55.663982  3537 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I0930 13:08:09.118831  3537 solver.cpp:218] Iteration 47200 (7.43228 iter/s, 13.4548s/100 iters), loss = 0.0781675
I0930 13:08:09.118978  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0781673 (* 1 = 0.0781673 loss)
I0930 13:08:09.118985  3537 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I0930 13:08:22.581893  3537 solver.cpp:218] Iteration 47300 (7.42783 iter/s, 13.4629s/100 iters), loss = 0.0765444
I0930 13:08:22.581930  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0765442 (* 1 = 0.0765442 loss)
I0930 13:08:22.581939  3537 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I0930 13:08:36.045871  3537 solver.cpp:218] Iteration 47400 (7.42727 iter/s, 13.4639s/100 iters), loss = 0.0758024
I0930 13:08:36.045899  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0758022 (* 1 = 0.0758022 loss)
I0930 13:08:36.045907  3537 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I0930 13:08:48.843004  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:08:49.379886  3537 solver.cpp:330] Iteration 47500, Testing net (#0)
I0930 13:08:52.487135  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:08:52.620223  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9002
I0930 13:08:52.620249  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318822 (* 1 = 0.318822 loss)
I0930 13:08:52.754926  3537 solver.cpp:218] Iteration 47500 (5.98481 iter/s, 16.709s/100 iters), loss = 0.0424456
I0930 13:08:52.754962  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0424454 (* 1 = 0.0424454 loss)
I0930 13:08:52.754971  3537 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I0930 13:09:06.208518  3537 solver.cpp:218] Iteration 47600 (7.433 iter/s, 13.4535s/100 iters), loss = 0.0275203
I0930 13:09:06.208547  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0275201 (* 1 = 0.0275201 loss)
I0930 13:09:06.208554  3537 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I0930 13:09:19.661881  3537 solver.cpp:218] Iteration 47700 (7.43313 iter/s, 13.4533s/100 iters), loss = 0.0234842
I0930 13:09:19.662012  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.023484 (* 1 = 0.023484 loss)
I0930 13:09:19.662021  3537 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I0930 13:09:33.105958  3537 solver.cpp:218] Iteration 47800 (7.43833 iter/s, 13.4439s/100 iters), loss = 0.0429764
I0930 13:09:33.105999  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0429762 (* 1 = 0.0429762 loss)
I0930 13:09:33.106005  3537 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I0930 13:09:46.576542  3537 solver.cpp:218] Iteration 47900 (7.42363 iter/s, 13.4705s/100 iters), loss = 0.0373329
I0930 13:09:46.576582  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0373327 (* 1 = 0.0373327 loss)
I0930 13:09:46.576589  3537 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I0930 13:09:59.361568  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:09:59.897739  3537 solver.cpp:330] Iteration 48000, Testing net (#0)
I0930 13:10:03.004303  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:10:03.133540  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8901
I0930 13:10:03.133575  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.356024 (* 1 = 0.356024 loss)
I0930 13:10:03.267063  3537 solver.cpp:218] Iteration 48000 (5.99146 iter/s, 16.6904s/100 iters), loss = 0.0182692
I0930 13:10:03.267094  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0182691 (* 1 = 0.0182691 loss)
I0930 13:10:03.267102  3537 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I0930 13:10:16.726394  3537 solver.cpp:218] Iteration 48100 (7.42983 iter/s, 13.4593s/100 iters), loss = 0.0786691
I0930 13:10:16.726429  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.078669 (* 1 = 0.078669 loss)
I0930 13:10:16.726436  3537 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I0930 13:10:30.176664  3537 solver.cpp:218] Iteration 48200 (7.43484 iter/s, 13.4502s/100 iters), loss = 0.0696273
I0930 13:10:30.176771  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0696271 (* 1 = 0.0696271 loss)
I0930 13:10:30.176779  3537 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I0930 13:10:43.628543  3537 solver.cpp:218] Iteration 48300 (7.43399 iter/s, 13.4517s/100 iters), loss = 0.0433293
I0930 13:10:43.628577  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0433292 (* 1 = 0.0433292 loss)
I0930 13:10:43.628585  3537 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I0930 13:10:57.059521  3537 solver.cpp:218] Iteration 48400 (7.44552 iter/s, 13.4309s/100 iters), loss = 0.0448929
I0930 13:10:57.059553  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0448928 (* 1 = 0.0448928 loss)
I0930 13:10:57.059559  3537 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I0930 13:11:09.840862  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:11:10.379947  3537 solver.cpp:330] Iteration 48500, Testing net (#0)
I0930 13:11:13.492673  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:11:13.626580  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8987
I0930 13:11:13.626606  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334425 (* 1 = 0.334425 loss)
I0930 13:11:13.761361  3537 solver.cpp:218] Iteration 48500 (5.98739 iter/s, 16.7018s/100 iters), loss = 0.0368371
I0930 13:11:13.761396  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0368369 (* 1 = 0.0368369 loss)
I0930 13:11:13.761404  3537 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I0930 13:11:27.214081  3537 solver.cpp:218] Iteration 48600 (7.43348 iter/s, 13.4526s/100 iters), loss = 0.131255
I0930 13:11:27.214112  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.131255 (* 1 = 0.131255 loss)
I0930 13:11:27.214118  3537 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I0930 13:11:40.667361  3537 solver.cpp:218] Iteration 48700 (7.43318 iter/s, 13.4532s/100 iters), loss = 0.0908039
I0930 13:11:40.667487  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0908037 (* 1 = 0.0908037 loss)
I0930 13:11:40.667506  3537 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I0930 13:11:54.117702  3537 solver.cpp:218] Iteration 48800 (7.43487 iter/s, 13.4501s/100 iters), loss = 0.0193447
I0930 13:11:54.117733  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0193446 (* 1 = 0.0193446 loss)
I0930 13:11:54.117738  3537 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I0930 13:12:07.577776  3537 solver.cpp:218] Iteration 48900 (7.42942 iter/s, 13.46s/100 iters), loss = 0.023501
I0930 13:12:07.577812  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0235009 (* 1 = 0.0235009 loss)
I0930 13:12:07.577829  3537 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I0930 13:12:20.369550  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:12:20.906975  3537 solver.cpp:330] Iteration 49000, Testing net (#0)
I0930 13:12:24.009140  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:12:24.138362  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8989
I0930 13:12:24.138397  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335743 (* 1 = 0.335743 loss)
I0930 13:12:24.271679  3537 solver.cpp:218] Iteration 49000 (5.99026 iter/s, 16.6938s/100 iters), loss = 0.0777163
I0930 13:12:24.271709  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0777162 (* 1 = 0.0777162 loss)
I0930 13:12:24.271715  3537 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I0930 13:12:37.715127  3537 solver.cpp:218] Iteration 49100 (7.43861 iter/s, 13.4434s/100 iters), loss = 0.0556567
I0930 13:12:37.715162  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0556566 (* 1 = 0.0556566 loss)
I0930 13:12:37.715169  3537 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I0930 13:12:51.168941  3537 solver.cpp:218] Iteration 49200 (7.43288 iter/s, 13.4537s/100 iters), loss = 0.0563338
I0930 13:12:51.169088  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0563337 (* 1 = 0.0563337 loss)
I0930 13:12:51.169097  3537 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I0930 13:13:04.626638  3537 solver.cpp:218] Iteration 49300 (7.4308 iter/s, 13.4575s/100 iters), loss = 0.0564254
I0930 13:13:04.626684  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0564253 (* 1 = 0.0564253 loss)
I0930 13:13:04.626693  3537 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I0930 13:13:18.072489  3537 solver.cpp:218] Iteration 49400 (7.4373 iter/s, 13.4457s/100 iters), loss = 0.0170551
I0930 13:13:18.072520  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.017055 (* 1 = 0.017055 loss)
I0930 13:13:18.072526  3537 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I0930 13:13:30.848093  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:13:31.383507  3537 solver.cpp:330] Iteration 49500, Testing net (#0)
I0930 13:13:34.492051  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:13:34.625293  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.898
I0930 13:13:34.625332  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.337828 (* 1 = 0.337828 loss)
I0930 13:13:34.760679  3537 solver.cpp:218] Iteration 49500 (5.99229 iter/s, 16.6881s/100 iters), loss = 0.0498936
I0930 13:13:34.760712  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0498935 (* 1 = 0.0498935 loss)
I0930 13:13:34.760720  3537 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I0930 13:13:48.206231  3537 solver.cpp:218] Iteration 49600 (7.43745 iter/s, 13.4455s/100 iters), loss = 0.0900036
I0930 13:13:48.206260  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0900035 (* 1 = 0.0900035 loss)
I0930 13:13:48.206266  3537 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I0930 13:14:01.654402  3537 solver.cpp:218] Iteration 49700 (7.436 iter/s, 13.4481s/100 iters), loss = 0.0858814
I0930 13:14:01.654528  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0858813 (* 1 = 0.0858813 loss)
I0930 13:14:01.654537  3537 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I0930 13:14:15.102341  3537 solver.cpp:218] Iteration 49800 (7.43617 iter/s, 13.4478s/100 iters), loss = 0.0790519
I0930 13:14:15.102383  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0790518 (* 1 = 0.0790518 loss)
I0930 13:14:15.102390  3537 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I0930 13:14:28.555234  3537 solver.cpp:218] Iteration 49900 (7.43339 iter/s, 13.4528s/100 iters), loss = 0.0222508
I0930 13:14:28.555289  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0222506 (* 1 = 0.0222506 loss)
I0930 13:14:28.555308  3537 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I0930 13:14:41.341946  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:14:41.878093  3537 solver.cpp:330] Iteration 50000, Testing net (#0)
I0930 13:14:44.980437  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:14:45.109613  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8944
I0930 13:14:45.109648  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369076 (* 1 = 0.369076 loss)
I0930 13:14:45.243381  3537 solver.cpp:218] Iteration 50000 (5.99238 iter/s, 16.6879s/100 iters), loss = 0.0493451
I0930 13:14:45.243414  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.049345 (* 1 = 0.049345 loss)
I0930 13:14:45.243422  3537 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I0930 13:14:58.688796  3537 solver.cpp:218] Iteration 50100 (7.43752 iter/s, 13.4453s/100 iters), loss = 0.0553767
I0930 13:14:58.688846  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0553765 (* 1 = 0.0553765 loss)
I0930 13:14:58.688854  3537 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I0930 13:15:12.138221  3537 solver.cpp:218] Iteration 50200 (7.43533 iter/s, 13.4493s/100 iters), loss = 0.0953841
I0930 13:15:12.138357  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.095384 (* 1 = 0.095384 loss)
I0930 13:15:12.138365  3537 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I0930 13:15:25.597395  3537 solver.cpp:218] Iteration 50300 (7.42998 iter/s, 13.459s/100 iters), loss = 0.0344189
I0930 13:15:25.597445  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0344188 (* 1 = 0.0344188 loss)
I0930 13:15:25.597452  3537 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I0930 13:15:39.039091  3537 solver.cpp:218] Iteration 50400 (7.4396 iter/s, 13.4416s/100 iters), loss = 0.0364284
I0930 13:15:39.039132  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0364283 (* 1 = 0.0364283 loss)
I0930 13:15:39.039139  3537 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I0930 13:15:51.817380  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:15:52.353544  3537 solver.cpp:330] Iteration 50500, Testing net (#0)
I0930 13:15:55.460577  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:15:55.594648  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9001
I0930 13:15:55.594699  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34584 (* 1 = 0.34584 loss)
I0930 13:15:55.731329  3537 solver.cpp:218] Iteration 50500 (5.99084 iter/s, 16.6921s/100 iters), loss = 0.0240909
I0930 13:15:55.731364  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0240908 (* 1 = 0.0240908 loss)
I0930 13:15:55.731371  3537 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I0930 13:16:09.181058  3537 solver.cpp:218] Iteration 50600 (7.43514 iter/s, 13.4497s/100 iters), loss = 0.0340169
I0930 13:16:09.181089  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0340168 (* 1 = 0.0340168 loss)
I0930 13:16:09.181095  3537 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I0930 13:16:22.632207  3537 solver.cpp:218] Iteration 50700 (7.43435 iter/s, 13.4511s/100 iters), loss = 0.0827063
I0930 13:16:22.632339  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0827062 (* 1 = 0.0827062 loss)
I0930 13:16:22.632361  3537 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I0930 13:16:36.074793  3537 solver.cpp:218] Iteration 50800 (7.43915 iter/s, 13.4424s/100 iters), loss = 0.0327876
I0930 13:16:36.074833  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0327875 (* 1 = 0.0327875 loss)
I0930 13:16:36.074841  3537 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I0930 13:16:49.537286  3537 solver.cpp:218] Iteration 50900 (7.42809 iter/s, 13.4624s/100 iters), loss = 0.074048
I0930 13:16:49.537323  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.074048 (* 1 = 0.074048 loss)
I0930 13:16:49.537331  3537 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I0930 13:17:02.333323  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:17:02.869704  3537 solver.cpp:330] Iteration 51000, Testing net (#0)
I0930 13:17:05.972610  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:17:06.101665  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8963
I0930 13:17:06.101701  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.346511 (* 1 = 0.346511 loss)
I0930 13:17:06.235728  3537 solver.cpp:218] Iteration 51000 (5.98861 iter/s, 16.6984s/100 iters), loss = 0.0247305
I0930 13:17:06.235759  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0247304 (* 1 = 0.0247304 loss)
I0930 13:17:06.235766  3537 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I0930 13:17:19.683346  3537 solver.cpp:218] Iteration 51100 (7.4363 iter/s, 13.4475s/100 iters), loss = 0.0726078
I0930 13:17:19.683382  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0726078 (* 1 = 0.0726078 loss)
I0930 13:17:19.683389  3537 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I0930 13:17:33.142055  3537 solver.cpp:218] Iteration 51200 (7.43018 iter/s, 13.4586s/100 iters), loss = 0.0583805
I0930 13:17:33.142148  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0583805 (* 1 = 0.0583805 loss)
I0930 13:17:33.142165  3537 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I0930 13:17:46.604290  3537 solver.cpp:218] Iteration 51300 (7.42826 iter/s, 13.4621s/100 iters), loss = 0.046056
I0930 13:17:46.604341  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0460559 (* 1 = 0.0460559 loss)
I0930 13:17:46.604347  3537 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I0930 13:18:00.055367  3537 solver.cpp:218] Iteration 51400 (7.43441 iter/s, 13.451s/100 iters), loss = 0.0486286
I0930 13:18:00.055402  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0486285 (* 1 = 0.0486285 loss)
I0930 13:18:00.055410  3537 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I0930 13:18:12.841938  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:18:13.378165  3537 solver.cpp:330] Iteration 51500, Testing net (#0)
I0930 13:18:16.488715  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:18:16.623492  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.896
I0930 13:18:16.623522  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.361375 (* 1 = 0.361375 loss)
I0930 13:18:16.759703  3537 solver.cpp:218] Iteration 51500 (5.9865 iter/s, 16.7043s/100 iters), loss = 0.025257
I0930 13:18:16.759742  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.025257 (* 1 = 0.025257 loss)
I0930 13:18:16.759750  3537 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I0930 13:18:30.212033  3537 solver.cpp:218] Iteration 51600 (7.4337 iter/s, 13.4522s/100 iters), loss = 0.0382895
I0930 13:18:30.212065  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0382895 (* 1 = 0.0382895 loss)
I0930 13:18:30.212083  3537 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I0930 13:18:43.672417  3537 solver.cpp:218] Iteration 51700 (7.42925 iter/s, 13.4603s/100 iters), loss = 0.0765197
I0930 13:18:43.672551  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0765196 (* 1 = 0.0765196 loss)
I0930 13:18:43.672576  3537 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I0930 13:18:57.121645  3537 solver.cpp:218] Iteration 51800 (7.43548 iter/s, 13.449s/100 iters), loss = 0.0467171
I0930 13:18:57.121680  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0467171 (* 1 = 0.0467171 loss)
I0930 13:18:57.121688  3537 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I0930 13:19:10.584197  3537 solver.cpp:218] Iteration 51900 (7.42806 iter/s, 13.4625s/100 iters), loss = 0.0295032
I0930 13:19:10.584247  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0295031 (* 1 = 0.0295031 loss)
I0930 13:19:10.584267  3537 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I0930 13:19:23.378486  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:19:23.915175  3537 solver.cpp:330] Iteration 52000, Testing net (#0)
I0930 13:19:27.019877  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:19:27.148974  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8971
I0930 13:19:27.149009  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.360574 (* 1 = 0.360574 loss)
I0930 13:19:27.282821  3537 solver.cpp:218] Iteration 52000 (5.98856 iter/s, 16.6985s/100 iters), loss = 0.0225473
I0930 13:19:27.282853  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0225472 (* 1 = 0.0225472 loss)
I0930 13:19:27.282860  3537 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I0930 13:19:40.741274  3537 solver.cpp:218] Iteration 52100 (7.43032 iter/s, 13.4584s/100 iters), loss = 0.0825901
I0930 13:19:40.741312  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.08259 (* 1 = 0.08259 loss)
I0930 13:19:40.741319  3537 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I0930 13:19:54.204816  3537 solver.cpp:218] Iteration 52200 (7.42751 iter/s, 13.4635s/100 iters), loss = 0.0557799
I0930 13:19:54.204957  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0557798 (* 1 = 0.0557798 loss)
I0930 13:19:54.204965  3537 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I0930 13:20:07.675133  3537 solver.cpp:218] Iteration 52300 (7.42383 iter/s, 13.4701s/100 iters), loss = 0.0314132
I0930 13:20:07.675168  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0314132 (* 1 = 0.0314132 loss)
I0930 13:20:07.675175  3537 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I0930 13:20:21.122828  3537 solver.cpp:218] Iteration 52400 (7.43626 iter/s, 13.4476s/100 iters), loss = 0.0157864
I0930 13:20:21.122884  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0157863 (* 1 = 0.0157863 loss)
I0930 13:20:21.122895  3537 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I0930 13:20:33.903396  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:20:34.440516  3537 solver.cpp:330] Iteration 52500, Testing net (#0)
I0930 13:20:37.551264  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:20:37.684775  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8963
I0930 13:20:37.684803  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.371237 (* 1 = 0.371237 loss)
I0930 13:20:37.820569  3537 solver.cpp:218] Iteration 52500 (5.98887 iter/s, 16.6976s/100 iters), loss = 0.0146424
I0930 13:20:37.820602  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146424 (* 1 = 0.0146424 loss)
I0930 13:20:37.820610  3537 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I0930 13:20:51.259094  3537 solver.cpp:218] Iteration 52600 (7.44133 iter/s, 13.4385s/100 iters), loss = 0.023312
I0930 13:20:51.259124  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0233119 (* 1 = 0.0233119 loss)
I0930 13:20:51.259131  3537 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I0930 13:21:04.712816  3537 solver.cpp:218] Iteration 52700 (7.43293 iter/s, 13.4536s/100 iters), loss = 0.035501
I0930 13:21:04.712909  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0355009 (* 1 = 0.0355009 loss)
I0930 13:21:04.712929  3537 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I0930 13:21:18.157677  3537 solver.cpp:218] Iteration 52800 (7.43786 iter/s, 13.4447s/100 iters), loss = 0.0283893
I0930 13:21:18.157708  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0283893 (* 1 = 0.0283893 loss)
I0930 13:21:18.157716  3537 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I0930 13:21:31.607767  3537 solver.cpp:218] Iteration 52900 (7.43494 iter/s, 13.45s/100 iters), loss = 0.0665937
I0930 13:21:31.607805  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0665936 (* 1 = 0.0665936 loss)
I0930 13:21:31.607811  3537 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I0930 13:21:44.394309  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:21:44.932528  3537 solver.cpp:330] Iteration 53000, Testing net (#0)
I0930 13:21:48.039319  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:21:48.168898  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8989
I0930 13:21:48.168934  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.357868 (* 1 = 0.357868 loss)
I0930 13:21:48.302497  3537 solver.cpp:218] Iteration 53000 (5.98994 iter/s, 16.6946s/100 iters), loss = 0.0158643
I0930 13:21:48.302531  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0158642 (* 1 = 0.0158642 loss)
I0930 13:21:48.302537  3537 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I0930 13:22:01.754593  3537 solver.cpp:218] Iteration 53100 (7.43383 iter/s, 13.452s/100 iters), loss = 0.0515758
I0930 13:22:01.754631  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0515757 (* 1 = 0.0515757 loss)
I0930 13:22:01.754638  3537 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I0930 13:22:15.207854  3537 solver.cpp:218] Iteration 53200 (7.43319 iter/s, 13.4532s/100 iters), loss = 0.050441
I0930 13:22:15.208019  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0504409 (* 1 = 0.0504409 loss)
I0930 13:22:15.208027  3537 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I0930 13:22:28.674885  3537 solver.cpp:218] Iteration 53300 (7.42566 iter/s, 13.4668s/100 iters), loss = 0.0515779
I0930 13:22:28.674934  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0515779 (* 1 = 0.0515779 loss)
I0930 13:22:28.674942  3537 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I0930 13:22:42.124094  3537 solver.cpp:218] Iteration 53400 (7.43545 iter/s, 13.4491s/100 iters), loss = 0.0141082
I0930 13:22:42.124135  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141081 (* 1 = 0.0141081 loss)
I0930 13:22:42.124142  3537 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I0930 13:22:54.905859  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:22:55.442200  3537 solver.cpp:330] Iteration 53500, Testing net (#0)
I0930 13:22:58.546747  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:22:58.678778  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8979
I0930 13:22:58.678838  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367402 (* 1 = 0.367402 loss)
I0930 13:22:58.814690  3537 solver.cpp:218] Iteration 53500 (5.99143 iter/s, 16.6905s/100 iters), loss = 0.0384357
I0930 13:22:58.814725  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0384356 (* 1 = 0.0384356 loss)
I0930 13:22:58.814733  3537 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I0930 13:23:12.275491  3537 solver.cpp:218] Iteration 53600 (7.42902 iter/s, 13.4607s/100 iters), loss = 0.0180582
I0930 13:23:12.275521  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0180581 (* 1 = 0.0180581 loss)
I0930 13:23:12.275538  3537 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I0930 13:23:25.742185  3537 solver.cpp:218] Iteration 53700 (7.42577 iter/s, 13.4666s/100 iters), loss = 0.0465998
I0930 13:23:25.742288  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0465997 (* 1 = 0.0465997 loss)
I0930 13:23:25.742306  3537 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I0930 13:23:39.189815  3537 solver.cpp:218] Iteration 53800 (7.43633 iter/s, 13.4475s/100 iters), loss = 0.0278931
I0930 13:23:39.189846  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0278929 (* 1 = 0.0278929 loss)
I0930 13:23:39.189852  3537 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I0930 13:23:52.639597  3537 solver.cpp:218] Iteration 53900 (7.43511 iter/s, 13.4497s/100 iters), loss = 0.00538036
I0930 13:23:52.639637  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00538025 (* 1 = 0.00538025 loss)
I0930 13:23:52.639644  3537 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I0930 13:24:05.427995  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:24:05.965651  3537 solver.cpp:330] Iteration 54000, Testing net (#0)
I0930 13:24:09.071277  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:24:09.200489  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8944
I0930 13:24:09.200523  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.386594 (* 1 = 0.386594 loss)
I0930 13:24:09.334359  3537 solver.cpp:218] Iteration 54000 (5.98993 iter/s, 16.6947s/100 iters), loss = 0.020642
I0930 13:24:09.334388  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0206418 (* 1 = 0.0206418 loss)
I0930 13:24:09.334394  3537 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I0930 13:24:22.787137  3537 solver.cpp:218] Iteration 54100 (7.43345 iter/s, 13.4527s/100 iters), loss = 0.0446373
I0930 13:24:22.787171  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0446371 (* 1 = 0.0446371 loss)
I0930 13:24:22.787179  3537 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I0930 13:24:36.233691  3537 solver.cpp:218] Iteration 54200 (7.43689 iter/s, 13.4465s/100 iters), loss = 0.0571439
I0930 13:24:36.233819  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0571438 (* 1 = 0.0571438 loss)
I0930 13:24:36.233825  3537 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I0930 13:24:49.706423  3537 solver.cpp:218] Iteration 54300 (7.42249 iter/s, 13.4726s/100 iters), loss = 0.0176747
I0930 13:24:49.706459  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176745 (* 1 = 0.0176745 loss)
I0930 13:24:49.706467  3537 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I0930 13:25:03.163864  3537 solver.cpp:218] Iteration 54400 (7.43088 iter/s, 13.4574s/100 iters), loss = 0.0270845
I0930 13:25:03.163895  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0270844 (* 1 = 0.0270844 loss)
I0930 13:25:03.163902  3537 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I0930 13:25:15.941371  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:25:16.477975  3537 solver.cpp:330] Iteration 54500, Testing net (#0)
I0930 13:25:19.586418  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:25:19.719552  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.893
I0930 13:25:19.719589  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.382155 (* 1 = 0.382155 loss)
I0930 13:25:19.854830  3537 solver.cpp:218] Iteration 54500 (5.99129 iter/s, 16.6909s/100 iters), loss = 0.0217268
I0930 13:25:19.854866  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0217267 (* 1 = 0.0217267 loss)
I0930 13:25:19.854872  3537 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I0930 13:25:33.304049  3537 solver.cpp:218] Iteration 54600 (7.43542 iter/s, 13.4491s/100 iters), loss = 0.0212102
I0930 13:25:33.304078  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0212101 (* 1 = 0.0212101 loss)
I0930 13:25:33.304085  3537 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I0930 13:25:46.762291  3537 solver.cpp:218] Iteration 54700 (7.43043 iter/s, 13.4582s/100 iters), loss = 0.0553978
I0930 13:25:46.762398  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0553977 (* 1 = 0.0553977 loss)
I0930 13:25:46.762418  3537 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I0930 13:26:00.214457  3537 solver.cpp:218] Iteration 54800 (7.43384 iter/s, 13.452s/100 iters), loss = 0.0764024
I0930 13:26:00.214490  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0764023 (* 1 = 0.0764023 loss)
I0930 13:26:00.214496  3537 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I0930 13:26:13.669703  3537 solver.cpp:218] Iteration 54900 (7.43209 iter/s, 13.4552s/100 iters), loss = 0.0211869
I0930 13:26:13.669742  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0211868 (* 1 = 0.0211868 loss)
I0930 13:26:13.669759  3537 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I0930 13:26:26.456382  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:26:26.995121  3537 solver.cpp:330] Iteration 55000, Testing net (#0)
I0930 13:26:30.100911  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:26:30.230538  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8971
I0930 13:26:30.230563  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367311 (* 1 = 0.367311 loss)
I0930 13:26:30.363956  3537 solver.cpp:218] Iteration 55000 (5.99013 iter/s, 16.6941s/100 iters), loss = 0.0230901
I0930 13:26:30.363987  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.02309 (* 1 = 0.02309 loss)
I0930 13:26:30.363993  3537 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I0930 13:26:43.805763  3537 solver.cpp:218] Iteration 55100 (7.43952 iter/s, 13.4417s/100 iters), loss = 0.0579887
I0930 13:26:43.805807  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0579886 (* 1 = 0.0579886 loss)
I0930 13:26:43.805816  3537 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I0930 13:26:57.252843  3537 solver.cpp:218] Iteration 55200 (7.4366 iter/s, 13.447s/100 iters), loss = 0.0495742
I0930 13:26:57.252967  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.049574 (* 1 = 0.049574 loss)
I0930 13:26:57.252988  3537 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I0930 13:27:10.725921  3537 solver.cpp:218] Iteration 55300 (7.4223 iter/s, 13.4729s/100 iters), loss = 0.0286517
I0930 13:27:10.725967  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0286516 (* 1 = 0.0286516 loss)
I0930 13:27:10.725975  3537 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I0930 13:27:24.187592  3537 solver.cpp:218] Iteration 55400 (7.42856 iter/s, 13.4616s/100 iters), loss = 0.0712353
I0930 13:27:24.187633  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0712351 (* 1 = 0.0712351 loss)
I0930 13:27:24.187638  3537 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I0930 13:27:36.969247  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:27:37.508030  3537 solver.cpp:330] Iteration 55500, Testing net (#0)
I0930 13:27:40.609052  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:27:40.740741  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8971
I0930 13:27:40.740775  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372103 (* 1 = 0.372103 loss)
I0930 13:27:40.875635  3537 solver.cpp:218] Iteration 55500 (5.99235 iter/s, 16.688s/100 iters), loss = 0.0271969
I0930 13:27:40.875669  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0271968 (* 1 = 0.0271968 loss)
I0930 13:27:40.875676  3537 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I0930 13:27:54.326506  3537 solver.cpp:218] Iteration 55600 (7.43451 iter/s, 13.4508s/100 iters), loss = 0.0430775
I0930 13:27:54.326550  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0430773 (* 1 = 0.0430773 loss)
I0930 13:27:54.326555  3537 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I0930 13:28:07.795289  3537 solver.cpp:218] Iteration 55700 (7.42462 iter/s, 13.4687s/100 iters), loss = 0.0487135
I0930 13:28:07.795424  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0487134 (* 1 = 0.0487134 loss)
I0930 13:28:07.795433  3537 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I0930 13:28:21.253458  3537 solver.cpp:218] Iteration 55800 (7.43053 iter/s, 13.458s/100 iters), loss = 0.0257355
I0930 13:28:21.253497  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0257353 (* 1 = 0.0257353 loss)
I0930 13:28:21.253504  3537 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I0930 13:28:34.709919  3537 solver.cpp:218] Iteration 55900 (7.43142 iter/s, 13.4564s/100 iters), loss = 0.0212243
I0930 13:28:34.709955  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0212242 (* 1 = 0.0212242 loss)
I0930 13:28:34.709962  3537 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I0930 13:28:47.506060  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:28:48.043196  3537 solver.cpp:330] Iteration 56000, Testing net (#0)
I0930 13:28:51.148944  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:28:51.278224  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9028
I0930 13:28:51.278249  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.359048 (* 1 = 0.359048 loss)
I0930 13:28:51.412742  3537 solver.cpp:218] Iteration 56000 (5.98704 iter/s, 16.7027s/100 iters), loss = 0.0518523
I0930 13:28:51.412775  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0518522 (* 1 = 0.0518522 loss)
I0930 13:28:51.412781  3537 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I0930 13:29:04.882442  3537 solver.cpp:218] Iteration 56100 (7.42411 iter/s, 13.4696s/100 iters), loss = 0.0311537
I0930 13:29:04.882478  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0311535 (* 1 = 0.0311535 loss)
I0930 13:29:04.882486  3537 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I0930 13:29:18.327298  3537 solver.cpp:218] Iteration 56200 (7.43783 iter/s, 13.4448s/100 iters), loss = 0.114757
I0930 13:29:18.327441  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114757 (* 1 = 0.114757 loss)
I0930 13:29:18.327448  3537 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I0930 13:29:31.786587  3537 solver.cpp:218] Iteration 56300 (7.42991 iter/s, 13.4591s/100 iters), loss = 0.0305295
I0930 13:29:31.786635  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0305293 (* 1 = 0.0305293 loss)
I0930 13:29:31.786643  3537 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I0930 13:29:45.245352  3537 solver.cpp:218] Iteration 56400 (7.43017 iter/s, 13.4586s/100 iters), loss = 0.0713362
I0930 13:29:45.245381  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.071336 (* 1 = 0.071336 loss)
I0930 13:29:45.245388  3537 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I0930 13:29:58.031327  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:29:58.570006  3537 solver.cpp:330] Iteration 56500, Testing net (#0)
I0930 13:30:01.677106  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:30:01.809275  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8931
I0930 13:30:01.809303  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.389326 (* 1 = 0.389326 loss)
I0930 13:30:01.943862  3537 solver.cpp:218] Iteration 56500 (5.98859 iter/s, 16.6984s/100 iters), loss = 0.0137811
I0930 13:30:01.943897  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013781 (* 1 = 0.013781 loss)
I0930 13:30:01.943903  3537 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I0930 13:30:15.397855  3537 solver.cpp:218] Iteration 56600 (7.43278 iter/s, 13.4539s/100 iters), loss = 0.0416385
I0930 13:30:15.397886  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0416384 (* 1 = 0.0416384 loss)
I0930 13:30:15.397902  3537 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I0930 13:30:28.870188  3537 solver.cpp:218] Iteration 56700 (7.42266 iter/s, 13.4723s/100 iters), loss = 0.0359811
I0930 13:30:28.870316  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.035981 (* 1 = 0.035981 loss)
I0930 13:30:28.870326  3537 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I0930 13:30:42.337209  3537 solver.cpp:218] Iteration 56800 (7.42564 iter/s, 13.4669s/100 iters), loss = 0.0467091
I0930 13:30:42.337242  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.046709 (* 1 = 0.046709 loss)
I0930 13:30:42.337249  3537 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I0930 13:30:55.796008  3537 solver.cpp:218] Iteration 56900 (7.43012 iter/s, 13.4587s/100 iters), loss = 0.0420386
I0930 13:30:55.796044  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0420385 (* 1 = 0.0420385 loss)
I0930 13:30:55.796061  3537 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I0930 13:31:08.592782  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:31:09.129528  3537 solver.cpp:330] Iteration 57000, Testing net (#0)
I0930 13:31:12.235616  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:31:12.366407  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.899
I0930 13:31:12.366432  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.374853 (* 1 = 0.374853 loss)
I0930 13:31:12.499007  3537 solver.cpp:218] Iteration 57000 (5.98699 iter/s, 16.7029s/100 iters), loss = 0.0186745
I0930 13:31:12.499037  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0186744 (* 1 = 0.0186744 loss)
I0930 13:31:12.499042  3537 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I0930 13:31:25.957209  3537 solver.cpp:218] Iteration 57100 (7.43045 iter/s, 13.4581s/100 iters), loss = 0.0470691
I0930 13:31:25.957252  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.047069 (* 1 = 0.047069 loss)
I0930 13:31:25.957258  3537 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I0930 13:31:39.402887  3537 solver.cpp:218] Iteration 57200 (7.43738 iter/s, 13.4456s/100 iters), loss = 0.0368345
I0930 13:31:39.403003  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0368344 (* 1 = 0.0368344 loss)
I0930 13:31:39.403013  3537 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I0930 13:31:52.860441  3537 solver.cpp:218] Iteration 57300 (7.43085 iter/s, 13.4574s/100 iters), loss = 0.0331545
I0930 13:31:52.860476  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0331544 (* 1 = 0.0331544 loss)
I0930 13:31:52.860483  3537 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I0930 13:32:06.313433  3537 solver.cpp:218] Iteration 57400 (7.43333 iter/s, 13.4529s/100 iters), loss = 0.0509327
I0930 13:32:06.313462  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0509326 (* 1 = 0.0509326 loss)
I0930 13:32:06.313468  3537 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I0930 13:32:19.102638  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:32:19.641484  3537 solver.cpp:330] Iteration 57500, Testing net (#0)
I0930 13:32:22.749328  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:32:22.880713  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8968
I0930 13:32:22.880748  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.38927 (* 1 = 0.38927 loss)
I0930 13:32:23.014307  3537 solver.cpp:218] Iteration 57500 (5.98774 iter/s, 16.7008s/100 iters), loss = 0.0154106
I0930 13:32:23.014339  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0154105 (* 1 = 0.0154105 loss)
I0930 13:32:23.014346  3537 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I0930 13:32:36.459372  3537 solver.cpp:218] Iteration 57600 (7.43772 iter/s, 13.445s/100 iters), loss = 0.0266601
I0930 13:32:36.459403  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.02666 (* 1 = 0.02666 loss)
I0930 13:32:36.459408  3537 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I0930 13:32:49.928443  3537 solver.cpp:218] Iteration 57700 (7.42446 iter/s, 13.469s/100 iters), loss = 0.0504642
I0930 13:32:49.928558  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.050464 (* 1 = 0.050464 loss)
I0930 13:32:49.928566  3537 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I0930 13:33:03.385617  3537 solver.cpp:218] Iteration 57800 (7.43106 iter/s, 13.457s/100 iters), loss = 0.0134389
I0930 13:33:03.385645  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134388 (* 1 = 0.0134388 loss)
I0930 13:33:03.385651  3537 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I0930 13:33:16.846274  3537 solver.cpp:218] Iteration 57900 (7.4291 iter/s, 13.4606s/100 iters), loss = 0.0107964
I0930 13:33:16.846310  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107963 (* 1 = 0.0107963 loss)
I0930 13:33:16.846318  3537 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I0930 13:33:29.628219  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:33:30.165001  3537 solver.cpp:330] Iteration 58000, Testing net (#0)
I0930 13:33:33.274540  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:33:33.403769  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8972
I0930 13:33:33.403792  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.384789 (* 1 = 0.384789 loss)
I0930 13:33:33.537858  3537 solver.cpp:218] Iteration 58000 (5.99107 iter/s, 16.6915s/100 iters), loss = 0.0182734
I0930 13:33:33.537892  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0182732 (* 1 = 0.0182732 loss)
I0930 13:33:33.537899  3537 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I0930 13:33:47.004113  3537 solver.cpp:218] Iteration 58100 (7.42601 iter/s, 13.4662s/100 iters), loss = 0.0303021
I0930 13:33:47.004145  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0303019 (* 1 = 0.0303019 loss)
I0930 13:33:47.004153  3537 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I0930 13:34:00.452600  3537 solver.cpp:218] Iteration 58200 (7.43582 iter/s, 13.4484s/100 iters), loss = 0.0233951
I0930 13:34:00.452747  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.023395 (* 1 = 0.023395 loss)
I0930 13:34:00.452755  3537 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I0930 13:34:13.908002  3537 solver.cpp:218] Iteration 58300 (7.43206 iter/s, 13.4552s/100 iters), loss = 0.0336751
I0930 13:34:13.908038  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0336749 (* 1 = 0.0336749 loss)
I0930 13:34:13.908046  3537 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I0930 13:34:27.361920  3537 solver.cpp:218] Iteration 58400 (7.43282 iter/s, 13.4538s/100 iters), loss = 0.00690411
I0930 13:34:27.361951  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00690395 (* 1 = 0.00690395 loss)
I0930 13:34:27.361958  3537 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I0930 13:34:40.146762  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:34:40.687569  3537 solver.cpp:330] Iteration 58500, Testing net (#0)
I0930 13:34:43.793448  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:34:43.923524  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8995
I0930 13:34:43.923549  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.378261 (* 1 = 0.378261 loss)
I0930 13:34:44.057370  3537 solver.cpp:218] Iteration 58500 (5.98968 iter/s, 16.6954s/100 iters), loss = 0.013919
I0930 13:34:44.057404  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139189 (* 1 = 0.0139189 loss)
I0930 13:34:44.057410  3537 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I0930 13:34:57.498831  3537 solver.cpp:218] Iteration 58600 (7.43971 iter/s, 13.4414s/100 iters), loss = 0.01404
I0930 13:34:57.498870  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0140399 (* 1 = 0.0140399 loss)
I0930 13:34:57.498877  3537 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I0930 13:35:10.961272  3537 solver.cpp:218] Iteration 58700 (7.42812 iter/s, 13.4624s/100 iters), loss = 0.0885221
I0930 13:35:10.961387  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.088522 (* 1 = 0.088522 loss)
I0930 13:35:10.961396  3537 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I0930 13:35:24.420379  3537 solver.cpp:218] Iteration 58800 (7.42999 iter/s, 13.459s/100 iters), loss = 0.0774081
I0930 13:35:24.420410  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.077408 (* 1 = 0.077408 loss)
I0930 13:35:24.420416  3537 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I0930 13:35:37.874027  3537 solver.cpp:218] Iteration 58900 (7.43297 iter/s, 13.4536s/100 iters), loss = 0.00849828
I0930 13:35:37.874063  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00849815 (* 1 = 0.00849815 loss)
I0930 13:35:37.874070  3537 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I0930 13:35:50.661202  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:35:51.198690  3537 solver.cpp:330] Iteration 59000, Testing net (#0)
I0930 13:35:54.306054  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:35:54.434782  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8962
I0930 13:35:54.434805  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.384214 (* 1 = 0.384214 loss)
I0930 13:35:54.568874  3537 solver.cpp:218] Iteration 59000 (5.9899 iter/s, 16.6948s/100 iters), loss = 0.00837316
I0930 13:35:54.568904  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00837302 (* 1 = 0.00837302 loss)
I0930 13:35:54.568910  3537 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I0930 13:36:08.033891  3537 solver.cpp:218] Iteration 59100 (7.42669 iter/s, 13.4649s/100 iters), loss = 0.014618
I0930 13:36:08.033932  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146179 (* 1 = 0.0146179 loss)
I0930 13:36:08.033939  3537 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I0930 13:36:21.488144  3537 solver.cpp:218] Iteration 59200 (7.43264 iter/s, 13.4542s/100 iters), loss = 0.0322896
I0930 13:36:21.488291  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0322895 (* 1 = 0.0322895 loss)
I0930 13:36:21.488301  3537 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I0930 13:36:34.942412  3537 solver.cpp:218] Iteration 59300 (7.43269 iter/s, 13.4541s/100 iters), loss = 0.0533653
I0930 13:36:34.942446  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0533652 (* 1 = 0.0533652 loss)
I0930 13:36:34.942453  3537 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I0930 13:36:48.399608  3537 solver.cpp:218] Iteration 59400 (7.43101 iter/s, 13.4571s/100 iters), loss = 0.0297126
I0930 13:36:48.399638  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0297125 (* 1 = 0.0297125 loss)
I0930 13:36:48.399646  3537 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I0930 13:37:01.185199  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:37:01.727771  3537 solver.cpp:330] Iteration 59500, Testing net (#0)
I0930 13:37:04.834209  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:37:04.964092  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8928
I0930 13:37:04.964117  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.412634 (* 1 = 0.412634 loss)
I0930 13:37:05.097841  3537 solver.cpp:218] Iteration 59500 (5.98869 iter/s, 16.6982s/100 iters), loss = 0.0315595
I0930 13:37:05.097872  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0315594 (* 1 = 0.0315594 loss)
I0930 13:37:05.097879  3537 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I0930 13:37:18.544073  3537 solver.cpp:218] Iteration 59600 (7.43707 iter/s, 13.4462s/100 iters), loss = 0.0158847
I0930 13:37:18.544113  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0158847 (* 1 = 0.0158847 loss)
I0930 13:37:18.544121  3537 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I0930 13:37:32.002969  3537 solver.cpp:218] Iteration 59700 (7.43007 iter/s, 13.4588s/100 iters), loss = 0.064094
I0930 13:37:32.003078  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0640939 (* 1 = 0.0640939 loss)
I0930 13:37:32.003096  3537 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I0930 13:37:45.449012  3537 solver.cpp:218] Iteration 59800 (7.43721 iter/s, 13.4459s/100 iters), loss = 0.0259244
I0930 13:37:45.449041  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0259243 (* 1 = 0.0259243 loss)
I0930 13:37:45.449048  3537 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I0930 13:37:58.902885  3537 solver.cpp:218] Iteration 59900 (7.43284 iter/s, 13.4538s/100 iters), loss = 0.0106871
I0930 13:37:58.902920  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010687 (* 1 = 0.010687 loss)
I0930 13:37:58.902928  3537 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I0930 13:38:11.682601  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:38:12.219347  3537 solver.cpp:330] Iteration 60000, Testing net (#0)
I0930 13:38:15.325716  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:38:15.455139  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8952
I0930 13:38:15.455163  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.41272 (* 1 = 0.41272 loss)
I0930 13:38:15.588317  3537 solver.cpp:218] Iteration 60000 (5.99328 iter/s, 16.6854s/100 iters), loss = 0.0337942
I0930 13:38:15.588348  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0337941 (* 1 = 0.0337941 loss)
I0930 13:38:15.588356  3537 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I0930 13:38:29.049336  3537 solver.cpp:218] Iteration 60100 (7.4289 iter/s, 13.4609s/100 iters), loss = 0.0333871
I0930 13:38:29.049368  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.033387 (* 1 = 0.033387 loss)
I0930 13:38:29.049376  3537 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I0930 13:38:42.502161  3537 solver.cpp:218] Iteration 60200 (7.43342 iter/s, 13.4528s/100 iters), loss = 0.0385328
I0930 13:38:42.502293  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0385328 (* 1 = 0.0385328 loss)
I0930 13:38:42.502301  3537 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I0930 13:38:55.965793  3537 solver.cpp:218] Iteration 60300 (7.42751 iter/s, 13.4635s/100 iters), loss = 0.0403271
I0930 13:38:55.965827  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.040327 (* 1 = 0.040327 loss)
I0930 13:38:55.965834  3537 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I0930 13:39:09.429208  3537 solver.cpp:218] Iteration 60400 (7.42758 iter/s, 13.4633s/100 iters), loss = 0.00624685
I0930 13:39:09.429249  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00624677 (* 1 = 0.00624677 loss)
I0930 13:39:09.429255  3537 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I0930 13:39:22.215808  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:39:22.759732  3537 solver.cpp:330] Iteration 60500, Testing net (#0)
I0930 13:39:25.867851  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:39:25.997313  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.891
I0930 13:39:25.997337  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.409566 (* 1 = 0.409566 loss)
I0930 13:39:26.131197  3537 solver.cpp:218] Iteration 60500 (5.98734 iter/s, 16.7019s/100 iters), loss = 0.070242
I0930 13:39:26.131232  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0702419 (* 1 = 0.0702419 loss)
I0930 13:39:26.131238  3537 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I0930 13:39:39.579797  3537 solver.cpp:218] Iteration 60600 (7.43576 iter/s, 13.4485s/100 iters), loss = 0.0473579
I0930 13:39:39.579826  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0473579 (* 1 = 0.0473579 loss)
I0930 13:39:39.579833  3537 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I0930 13:39:53.040069  3537 solver.cpp:218] Iteration 60700 (7.42931 iter/s, 13.4602s/100 iters), loss = 0.0122746
I0930 13:39:53.040180  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122746 (* 1 = 0.0122746 loss)
I0930 13:39:53.040189  3537 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I0930 13:40:06.498208  3537 solver.cpp:218] Iteration 60800 (7.43052 iter/s, 13.458s/100 iters), loss = 0.0156379
I0930 13:40:06.498239  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156378 (* 1 = 0.0156378 loss)
I0930 13:40:06.498245  3537 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I0930 13:40:19.960305  3537 solver.cpp:218] Iteration 60900 (7.4283 iter/s, 13.462s/100 iters), loss = 0.00841075
I0930 13:40:19.960351  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00841072 (* 1 = 0.00841072 loss)
I0930 13:40:19.960371  3537 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I0930 13:40:32.734664  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:40:33.272536  3537 solver.cpp:330] Iteration 61000, Testing net (#0)
I0930 13:40:36.376008  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:40:36.505231  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8963
I0930 13:40:36.505266  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.399321 (* 1 = 0.399321 loss)
I0930 13:40:36.638530  3537 solver.cpp:218] Iteration 61000 (5.99588 iter/s, 16.6781s/100 iters), loss = 0.0311705
I0930 13:40:36.638559  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0311705 (* 1 = 0.0311705 loss)
I0930 13:40:36.638566  3537 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I0930 13:40:50.105578  3537 solver.cpp:218] Iteration 61100 (7.42557 iter/s, 13.467s/100 iters), loss = 0.0175919
I0930 13:40:50.105609  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0175918 (* 1 = 0.0175918 loss)
I0930 13:40:50.105617  3537 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I0930 13:41:03.569456  3537 solver.cpp:218] Iteration 61200 (7.42732 iter/s, 13.4638s/100 iters), loss = 0.0354063
I0930 13:41:03.569595  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0354062 (* 1 = 0.0354062 loss)
I0930 13:41:03.569603  3537 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I0930 13:41:17.026854  3537 solver.cpp:218] Iteration 61300 (7.43095 iter/s, 13.4572s/100 iters), loss = 0.0200984
I0930 13:41:17.026885  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0200984 (* 1 = 0.0200984 loss)
I0930 13:41:17.026892  3537 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I0930 13:41:30.484515  3537 solver.cpp:218] Iteration 61400 (7.43075 iter/s, 13.4576s/100 iters), loss = 0.0293587
I0930 13:41:30.484555  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0293586 (* 1 = 0.0293586 loss)
I0930 13:41:30.484561  3537 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I0930 13:41:43.277271  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:41:43.822340  3537 solver.cpp:330] Iteration 61500, Testing net (#0)
I0930 13:41:46.929213  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:41:47.058229  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8984
I0930 13:41:47.058254  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.389137 (* 1 = 0.389137 loss)
I0930 13:41:47.192673  3537 solver.cpp:218] Iteration 61500 (5.98513 iter/s, 16.7081s/100 iters), loss = 0.00479025
I0930 13:41:47.192708  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00479021 (* 1 = 0.00479021 loss)
I0930 13:41:47.192714  3537 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I0930 13:42:00.649339  3537 solver.cpp:218] Iteration 61600 (7.4313 iter/s, 13.4566s/100 iters), loss = 0.0256207
I0930 13:42:00.649370  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0256207 (* 1 = 0.0256207 loss)
I0930 13:42:00.649376  3537 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I0930 13:42:14.115782  3537 solver.cpp:218] Iteration 61700 (7.42591 iter/s, 13.4664s/100 iters), loss = 0.0126124
I0930 13:42:14.115906  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126124 (* 1 = 0.0126124 loss)
I0930 13:42:14.115913  3537 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I0930 13:42:27.577224  3537 solver.cpp:218] Iteration 61800 (7.42871 iter/s, 13.4613s/100 iters), loss = 0.052373
I0930 13:42:27.577253  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0523729 (* 1 = 0.0523729 loss)
I0930 13:42:27.577260  3537 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I0930 13:42:41.046401  3537 solver.cpp:218] Iteration 61900 (7.4244 iter/s, 13.4691s/100 iters), loss = 0.0282578
I0930 13:42:41.046433  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0282577 (* 1 = 0.0282577 loss)
I0930 13:42:41.046440  3537 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I0930 13:42:53.829634  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:42:54.366325  3537 solver.cpp:330] Iteration 62000, Testing net (#0)
I0930 13:42:57.468526  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:42:57.597929  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9004
I0930 13:42:57.597951  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37463 (* 1 = 0.37463 loss)
I0930 13:42:57.732095  3537 solver.cpp:218] Iteration 62000 (5.99319 iter/s, 16.6856s/100 iters), loss = 0.0165174
I0930 13:42:57.732126  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0165174 (* 1 = 0.0165174 loss)
I0930 13:42:57.732133  3537 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I0930 13:43:11.194815  3537 solver.cpp:218] Iteration 62100 (7.42796 iter/s, 13.4626s/100 iters), loss = 0.0221534
I0930 13:43:11.194849  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0221534 (* 1 = 0.0221534 loss)
I0930 13:43:11.194855  3537 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I0930 13:43:24.648371  3537 solver.cpp:218] Iteration 62200 (7.43302 iter/s, 13.4535s/100 iters), loss = 0.0241041
I0930 13:43:24.648501  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.024104 (* 1 = 0.024104 loss)
I0930 13:43:24.648509  3537 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I0930 13:43:38.102438  3537 solver.cpp:218] Iteration 62300 (7.43279 iter/s, 13.4539s/100 iters), loss = 0.0331781
I0930 13:43:38.102469  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0331781 (* 1 = 0.0331781 loss)
I0930 13:43:38.102475  3537 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I0930 13:43:51.549862  3537 solver.cpp:218] Iteration 62400 (7.43641 iter/s, 13.4474s/100 iters), loss = 0.0647674
I0930 13:43:51.549891  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0647674 (* 1 = 0.0647674 loss)
I0930 13:43:51.549897  3537 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I0930 13:44:04.328210  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:44:04.871981  3537 solver.cpp:330] Iteration 62500, Testing net (#0)
I0930 13:44:07.978538  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:44:08.107764  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8958
I0930 13:44:08.107800  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.414751 (* 1 = 0.414751 loss)
I0930 13:44:08.241662  3537 solver.cpp:218] Iteration 62500 (5.99099 iter/s, 16.6917s/100 iters), loss = 0.0569316
I0930 13:44:08.241698  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0569316 (* 1 = 0.0569316 loss)
I0930 13:44:08.241705  3537 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I0930 13:44:21.688766  3537 solver.cpp:218] Iteration 62600 (7.43659 iter/s, 13.447s/100 iters), loss = 0.0552779
I0930 13:44:21.688796  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0552779 (* 1 = 0.0552779 loss)
I0930 13:44:21.688803  3537 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I0930 13:44:35.144992  3537 solver.cpp:218] Iteration 62700 (7.43155 iter/s, 13.4562s/100 iters), loss = 0.0781659
I0930 13:44:35.145107  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0781658 (* 1 = 0.0781658 loss)
I0930 13:44:35.145115  3537 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I0930 13:44:48.607102  3537 solver.cpp:218] Iteration 62800 (7.42834 iter/s, 13.462s/100 iters), loss = 0.0153319
I0930 13:44:48.607136  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0153319 (* 1 = 0.0153319 loss)
I0930 13:44:48.607141  3537 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I0930 13:45:02.070325  3537 solver.cpp:218] Iteration 62900 (7.42768 iter/s, 13.4631s/100 iters), loss = 0.00576437
I0930 13:45:02.070355  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00576437 (* 1 = 0.00576437 loss)
I0930 13:45:02.070363  3537 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I0930 13:45:14.855710  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:45:15.392877  3537 solver.cpp:330] Iteration 63000, Testing net (#0)
I0930 13:45:18.498076  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:45:18.628415  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8947
I0930 13:45:18.628450  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.419776 (* 1 = 0.419776 loss)
I0930 13:45:18.762392  3537 solver.cpp:218] Iteration 63000 (5.9909 iter/s, 16.692s/100 iters), loss = 0.0187973
I0930 13:45:18.762423  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0187973 (* 1 = 0.0187973 loss)
I0930 13:45:18.762430  3537 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I0930 13:45:32.221622  3537 solver.cpp:218] Iteration 63100 (7.42989 iter/s, 13.4592s/100 iters), loss = 0.0473982
I0930 13:45:32.221657  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0473982 (* 1 = 0.0473982 loss)
I0930 13:45:32.221664  3537 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I0930 13:45:45.682221  3537 solver.cpp:218] Iteration 63200 (7.42913 iter/s, 13.4605s/100 iters), loss = 0.0359115
I0930 13:45:45.682343  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0359115 (* 1 = 0.0359115 loss)
I0930 13:45:45.682350  3537 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I0930 13:45:59.141428  3537 solver.cpp:218] Iteration 63300 (7.42995 iter/s, 13.459s/100 iters), loss = 0.0357057
I0930 13:45:59.141458  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0357057 (* 1 = 0.0357057 loss)
I0930 13:45:59.141465  3537 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I0930 13:46:12.589452  3537 solver.cpp:218] Iteration 63400 (7.43608 iter/s, 13.448s/100 iters), loss = 0.0450682
I0930 13:46:12.589493  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0450682 (* 1 = 0.0450682 loss)
I0930 13:46:12.589498  3537 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I0930 13:46:25.382167  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:46:25.930083  3537 solver.cpp:330] Iteration 63500, Testing net (#0)
I0930 13:46:29.036147  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:46:29.165364  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8977
I0930 13:46:29.165398  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.405541 (* 1 = 0.405541 loss)
I0930 13:46:29.299422  3537 solver.cpp:218] Iteration 63500 (5.98448 iter/s, 16.7099s/100 iters), loss = 0.014837
I0930 13:46:29.299455  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148369 (* 1 = 0.0148369 loss)
I0930 13:46:29.299463  3537 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I0930 13:46:42.750931  3537 solver.cpp:218] Iteration 63600 (7.43415 iter/s, 13.4514s/100 iters), loss = 0.0491634
I0930 13:46:42.750960  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0491634 (* 1 = 0.0491634 loss)
I0930 13:46:42.750967  3537 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I0930 13:46:56.198774  3537 solver.cpp:218] Iteration 63700 (7.43618 iter/s, 13.4478s/100 iters), loss = 0.0206521
I0930 13:46:56.198885  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.020652 (* 1 = 0.020652 loss)
I0930 13:46:56.198904  3537 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I0930 13:47:09.650547  3537 solver.cpp:218] Iteration 63800 (7.43405 iter/s, 13.4516s/100 iters), loss = 0.0249635
I0930 13:47:09.650586  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0249635 (* 1 = 0.0249635 loss)
I0930 13:47:09.650593  3537 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I0930 13:47:23.109211  3537 solver.cpp:218] Iteration 63900 (7.4302 iter/s, 13.4586s/100 iters), loss = 0.0165747
I0930 13:47:23.109242  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0165747 (* 1 = 0.0165747 loss)
I0930 13:47:23.109249  3537 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I0930 13:47:35.890377  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:47:36.427270  3537 solver.cpp:330] Iteration 64000, Testing net (#0)
I0930 13:47:39.532716  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:47:39.661897  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8969
I0930 13:47:39.661931  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.394156 (* 1 = 0.394156 loss)
I0930 13:47:39.795634  3537 solver.cpp:218] Iteration 64000 (5.99292 iter/s, 16.6863s/100 iters), loss = 0.0336428
I0930 13:47:39.795665  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0336428 (* 1 = 0.0336428 loss)
I0930 13:47:39.795671  3537 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I0930 13:47:53.243883  3537 solver.cpp:218] Iteration 64100 (7.43595 iter/s, 13.4482s/100 iters), loss = 0.0148028
I0930 13:47:53.243917  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148028 (* 1 = 0.0148028 loss)
I0930 13:47:53.243927  3537 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I0930 13:48:06.696806  3537 solver.cpp:218] Iteration 64200 (7.43337 iter/s, 13.4528s/100 iters), loss = 0.0762466
I0930 13:48:06.696940  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0762466 (* 1 = 0.0762466 loss)
I0930 13:48:06.696952  3537 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I0930 13:48:20.157194  3537 solver.cpp:218] Iteration 64300 (7.4293 iter/s, 13.4602s/100 iters), loss = 0.0626298
I0930 13:48:20.157227  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0626298 (* 1 = 0.0626298 loss)
I0930 13:48:20.157246  3537 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I0930 13:48:33.593749  3537 solver.cpp:218] Iteration 64400 (7.44242 iter/s, 13.4365s/100 iters), loss = 0.0485784
I0930 13:48:33.593780  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0485784 (* 1 = 0.0485784 loss)
I0930 13:48:33.593798  3537 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I0930 13:48:46.380548  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:48:46.926188  3537 solver.cpp:330] Iteration 64500, Testing net (#0)
I0930 13:48:50.035903  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:48:50.165494  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8937
I0930 13:48:50.165520  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.411014 (* 1 = 0.411014 loss)
I0930 13:48:50.299504  3537 solver.cpp:218] Iteration 64500 (5.98599 iter/s, 16.7057s/100 iters), loss = 0.0154578
I0930 13:48:50.299540  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0154578 (* 1 = 0.0154578 loss)
I0930 13:48:50.299549  3537 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I0930 13:49:03.740221  3537 solver.cpp:218] Iteration 64600 (7.44012 iter/s, 13.4406s/100 iters), loss = 0.0394105
I0930 13:49:03.740252  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0394105 (* 1 = 0.0394105 loss)
I0930 13:49:03.740257  3537 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I0930 13:49:17.187923  3537 solver.cpp:218] Iteration 64700 (7.43625 iter/s, 13.4476s/100 iters), loss = 0.0394167
I0930 13:49:17.188040  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0394167 (* 1 = 0.0394167 loss)
I0930 13:49:17.188048  3537 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I0930 13:49:30.640154  3537 solver.cpp:218] Iteration 64800 (7.4338 iter/s, 13.4521s/100 iters), loss = 0.0121275
I0930 13:49:30.640194  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121275 (* 1 = 0.0121275 loss)
I0930 13:49:30.640200  3537 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I0930 13:49:44.102318  3537 solver.cpp:218] Iteration 64900 (7.42827 iter/s, 13.4621s/100 iters), loss = 0.0272649
I0930 13:49:44.102349  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0272649 (* 1 = 0.0272649 loss)
I0930 13:49:44.102355  3537 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I0930 13:49:56.886975  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:49:57.424613  3537 solver.cpp:330] Iteration 65000, Testing net (#0)
I0930 13:50:00.531388  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:50:00.660275  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8879
I0930 13:50:00.660310  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.460758 (* 1 = 0.460758 loss)
I0930 13:50:00.794147  3537 solver.cpp:218] Iteration 65000 (5.99098 iter/s, 16.6917s/100 iters), loss = 0.0234042
I0930 13:50:00.794178  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0234041 (* 1 = 0.0234041 loss)
I0930 13:50:00.794185  3537 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I0930 13:50:14.248268  3537 solver.cpp:218] Iteration 65100 (7.43271 iter/s, 13.454s/100 iters), loss = 0.020078
I0930 13:50:14.248311  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0200779 (* 1 = 0.0200779 loss)
I0930 13:50:14.248318  3537 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I0930 13:50:27.695013  3537 solver.cpp:218] Iteration 65200 (7.43679 iter/s, 13.4467s/100 iters), loss = 0.0203545
I0930 13:50:27.695139  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0203545 (* 1 = 0.0203545 loss)
I0930 13:50:27.695147  3537 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I0930 13:50:41.154989  3537 solver.cpp:218] Iteration 65300 (7.42953 iter/s, 13.4598s/100 iters), loss = 0.0390807
I0930 13:50:41.155037  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0390806 (* 1 = 0.0390806 loss)
I0930 13:50:41.155045  3537 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I0930 13:50:54.597549  3537 solver.cpp:218] Iteration 65400 (7.43911 iter/s, 13.4425s/100 iters), loss = 0.0455926
I0930 13:50:54.597589  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0455926 (* 1 = 0.0455926 loss)
I0930 13:50:54.597595  3537 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I0930 13:51:07.375741  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:51:07.921844  3537 solver.cpp:330] Iteration 65500, Testing net (#0)
I0930 13:51:11.028365  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:51:11.157805  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8901
I0930 13:51:11.157841  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.427514 (* 1 = 0.427514 loss)
I0930 13:51:11.291488  3537 solver.cpp:218] Iteration 65500 (5.99023 iter/s, 16.6938s/100 iters), loss = 0.023731
I0930 13:51:11.291522  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.023731 (* 1 = 0.023731 loss)
I0930 13:51:11.291528  3537 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I0930 13:51:24.741495  3537 solver.cpp:218] Iteration 65600 (7.43498 iter/s, 13.4499s/100 iters), loss = 0.01722
I0930 13:51:24.741525  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0172199 (* 1 = 0.0172199 loss)
I0930 13:51:24.741531  3537 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I0930 13:51:38.192545  3537 solver.cpp:218] Iteration 65700 (7.4344 iter/s, 13.451s/100 iters), loss = 0.0408071
I0930 13:51:38.192634  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.040807 (* 1 = 0.040807 loss)
I0930 13:51:38.192656  3537 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I0930 13:51:51.639935  3537 solver.cpp:218] Iteration 65800 (7.43646 iter/s, 13.4473s/100 iters), loss = 0.0176956
I0930 13:51:51.639964  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176956 (* 1 = 0.0176956 loss)
I0930 13:51:51.639971  3537 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I0930 13:52:05.109519  3537 solver.cpp:218] Iteration 65900 (7.42417 iter/s, 13.4695s/100 iters), loss = 0.010862
I0930 13:52:05.109562  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010862 (* 1 = 0.010862 loss)
I0930 13:52:05.109570  3537 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I0930 13:52:17.896219  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:52:18.432235  3537 solver.cpp:330] Iteration 66000, Testing net (#0)
I0930 13:52:21.535619  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:52:21.664866  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8942
I0930 13:52:21.664891  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.415022 (* 1 = 0.415022 loss)
I0930 13:52:21.798705  3537 solver.cpp:218] Iteration 66000 (5.99194 iter/s, 16.6891s/100 iters), loss = 0.0314995
I0930 13:52:21.798740  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0314994 (* 1 = 0.0314994 loss)
I0930 13:52:21.798748  3537 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I0930 13:52:35.248575  3537 solver.cpp:218] Iteration 66100 (7.43506 iter/s, 13.4498s/100 iters), loss = 0.0401521
I0930 13:52:35.248607  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.040152 (* 1 = 0.040152 loss)
I0930 13:52:35.248613  3537 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I0930 13:52:48.701225  3537 solver.cpp:218] Iteration 66200 (7.43352 iter/s, 13.4526s/100 iters), loss = 0.0236304
I0930 13:52:48.701386  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0236304 (* 1 = 0.0236304 loss)
I0930 13:52:48.701395  3537 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I0930 13:53:02.161248  3537 solver.cpp:218] Iteration 66300 (7.42952 iter/s, 13.4598s/100 iters), loss = 0.0273503
I0930 13:53:02.161279  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0273502 (* 1 = 0.0273502 loss)
I0930 13:53:02.161286  3537 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I0930 13:53:15.606578  3537 solver.cpp:218] Iteration 66400 (7.43757 iter/s, 13.4453s/100 iters), loss = 0.0391704
I0930 13:53:15.606608  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0391704 (* 1 = 0.0391704 loss)
I0930 13:53:15.606614  3537 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I0930 13:53:28.389125  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:53:28.934538  3537 solver.cpp:330] Iteration 66500, Testing net (#0)
I0930 13:53:32.042321  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:53:32.171615  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8974
I0930 13:53:32.171650  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.414858 (* 1 = 0.414858 loss)
I0930 13:53:32.305527  3537 solver.cpp:218] Iteration 66500 (5.98843 iter/s, 16.6989s/100 iters), loss = 0.017148
I0930 13:53:32.305560  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.017148 (* 1 = 0.017148 loss)
I0930 13:53:32.305567  3537 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I0930 13:53:45.771229  3537 solver.cpp:218] Iteration 66600 (7.42632 iter/s, 13.4656s/100 iters), loss = 0.0357964
I0930 13:53:45.771270  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0357963 (* 1 = 0.0357963 loss)
I0930 13:53:45.771275  3537 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I0930 13:53:59.237913  3537 solver.cpp:218] Iteration 66700 (7.42578 iter/s, 13.4666s/100 iters), loss = 0.0218834
I0930 13:53:59.238020  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0218833 (* 1 = 0.0218833 loss)
I0930 13:53:59.238029  3537 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I0930 13:54:12.701740  3537 solver.cpp:218] Iteration 66800 (7.42738 iter/s, 13.4637s/100 iters), loss = 0.0531687
I0930 13:54:12.701768  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0531686 (* 1 = 0.0531686 loss)
I0930 13:54:12.701774  3537 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I0930 13:54:26.179345  3537 solver.cpp:218] Iteration 66900 (7.41975 iter/s, 13.4775s/100 iters), loss = 0.0213377
I0930 13:54:26.179380  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0213376 (* 1 = 0.0213376 loss)
I0930 13:54:26.179388  3537 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I0930 13:54:38.974436  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:54:39.513303  3537 solver.cpp:330] Iteration 67000, Testing net (#0)
I0930 13:54:42.617517  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:54:42.746773  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8864
I0930 13:54:42.746798  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.458267 (* 1 = 0.458267 loss)
I0930 13:54:42.880306  3537 solver.cpp:218] Iteration 67000 (5.98771 iter/s, 16.7009s/100 iters), loss = 0.0353963
I0930 13:54:42.880336  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0353962 (* 1 = 0.0353962 loss)
I0930 13:54:42.880344  3537 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I0930 13:54:56.331188  3537 solver.cpp:218] Iteration 67100 (7.4345 iter/s, 13.4508s/100 iters), loss = 0.0168055
I0930 13:54:56.331223  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0168054 (* 1 = 0.0168054 loss)
I0930 13:54:56.331228  3537 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I0930 13:55:09.788624  3537 solver.cpp:218] Iteration 67200 (7.43088 iter/s, 13.4574s/100 iters), loss = 0.00866513
I0930 13:55:09.788761  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00866506 (* 1 = 0.00866506 loss)
I0930 13:55:09.788780  3537 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I0930 13:55:23.251287  3537 solver.cpp:218] Iteration 67300 (7.42805 iter/s, 13.4625s/100 iters), loss = 0.0126513
I0930 13:55:23.251332  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126512 (* 1 = 0.0126512 loss)
I0930 13:55:23.251338  3537 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I0930 13:55:36.702322  3537 solver.cpp:218] Iteration 67400 (7.43442 iter/s, 13.451s/100 iters), loss = 0.0121129
I0930 13:55:36.702352  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121128 (* 1 = 0.0121128 loss)
I0930 13:55:36.702358  3537 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I0930 13:55:49.484390  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:55:50.032104  3537 solver.cpp:330] Iteration 67500, Testing net (#0)
I0930 13:55:53.139408  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:55:53.267969  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8873
I0930 13:55:53.267994  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.474864 (* 1 = 0.474864 loss)
I0930 13:55:53.401679  3537 solver.cpp:218] Iteration 67500 (5.98828 iter/s, 16.6993s/100 iters), loss = 0.0202665
I0930 13:55:53.401712  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0202665 (* 1 = 0.0202665 loss)
I0930 13:55:53.401721  3537 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I0930 13:56:06.856508  3537 solver.cpp:218] Iteration 67600 (7.43231 iter/s, 13.4548s/100 iters), loss = 0.0138452
I0930 13:56:06.856537  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138451 (* 1 = 0.0138451 loss)
I0930 13:56:06.856544  3537 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I0930 13:56:20.327966  3537 solver.cpp:218] Iteration 67700 (7.42314 iter/s, 13.4714s/100 iters), loss = 0.0192486
I0930 13:56:20.328069  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0192485 (* 1 = 0.0192485 loss)
I0930 13:56:20.328078  3537 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I0930 13:56:33.777143  3537 solver.cpp:218] Iteration 67800 (7.43548 iter/s, 13.449s/100 iters), loss = 0.0272079
I0930 13:56:33.777184  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0272078 (* 1 = 0.0272078 loss)
I0930 13:56:33.777190  3537 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I0930 13:56:47.249364  3537 solver.cpp:218] Iteration 67900 (7.42273 iter/s, 13.4721s/100 iters), loss = 0.00666269
I0930 13:56:47.249405  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00666257 (* 1 = 0.00666257 loss)
I0930 13:56:47.249413  3537 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I0930 13:57:00.045425  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:57:00.583472  3537 solver.cpp:330] Iteration 68000, Testing net (#0)
I0930 13:57:03.688570  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:57:03.818081  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8845
I0930 13:57:03.818117  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.464271 (* 1 = 0.464271 loss)
I0930 13:57:03.951915  3537 solver.cpp:218] Iteration 68000 (5.98714 iter/s, 16.7025s/100 iters), loss = 0.00812018
I0930 13:57:03.951946  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00812007 (* 1 = 0.00812007 loss)
I0930 13:57:03.951952  3537 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I0930 13:57:17.406184  3537 solver.cpp:218] Iteration 68100 (7.43262 iter/s, 13.4542s/100 iters), loss = 0.0557223
I0930 13:57:17.406215  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0557222 (* 1 = 0.0557222 loss)
I0930 13:57:17.406224  3537 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I0930 13:57:30.852205  3537 solver.cpp:218] Iteration 68200 (7.43718 iter/s, 13.4459s/100 iters), loss = 0.0451969
I0930 13:57:30.852388  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0451968 (* 1 = 0.0451968 loss)
I0930 13:57:30.852406  3537 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I0930 13:57:44.316349  3537 solver.cpp:218] Iteration 68300 (7.42726 iter/s, 13.4639s/100 iters), loss = 0.0128713
I0930 13:57:44.316382  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128711 (* 1 = 0.0128711 loss)
I0930 13:57:44.316390  3537 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I0930 13:57:57.753767  3537 solver.cpp:218] Iteration 68400 (7.44195 iter/s, 13.4373s/100 iters), loss = 0.0201088
I0930 13:57:57.753798  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0201087 (* 1 = 0.0201087 loss)
I0930 13:57:57.753804  3537 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I0930 13:58:10.523794  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:58:11.068699  3537 solver.cpp:330] Iteration 68500, Testing net (#0)
I0930 13:58:14.174037  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:58:14.302850  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8962
I0930 13:58:14.302886  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.420962 (* 1 = 0.420962 loss)
I0930 13:58:14.435907  3537 solver.cpp:218] Iteration 68500 (5.99446 iter/s, 16.6821s/100 iters), loss = 0.0123678
I0930 13:58:14.435951  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0123677 (* 1 = 0.0123677 loss)
I0930 13:58:14.435958  3537 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I0930 13:58:27.892166  3537 solver.cpp:218] Iteration 68600 (7.43153 iter/s, 13.4562s/100 iters), loss = 0.0401451
I0930 13:58:27.892196  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.040145 (* 1 = 0.040145 loss)
I0930 13:58:27.892202  3537 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I0930 13:58:41.352259  3537 solver.cpp:218] Iteration 68700 (7.42941 iter/s, 13.46s/100 iters), loss = 0.0357113
I0930 13:58:41.352413  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0357112 (* 1 = 0.0357112 loss)
I0930 13:58:41.352433  3537 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I0930 13:58:54.808840  3537 solver.cpp:218] Iteration 68800 (7.43141 iter/s, 13.4564s/100 iters), loss = 0.0552957
I0930 13:58:54.808872  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0552956 (* 1 = 0.0552956 loss)
I0930 13:58:54.808879  3537 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I0930 13:59:08.274061  3537 solver.cpp:218] Iteration 68900 (7.42658 iter/s, 13.4651s/100 iters), loss = 0.0307986
I0930 13:59:08.274093  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0307985 (* 1 = 0.0307985 loss)
I0930 13:59:08.274101  3537 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I0930 13:59:21.065994  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:59:21.602741  3537 solver.cpp:330] Iteration 69000, Testing net (#0)
I0930 13:59:24.707785  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 13:59:24.838078  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8922
I0930 13:59:24.838112  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.435102 (* 1 = 0.435102 loss)
I0930 13:59:24.971560  3537 solver.cpp:218] Iteration 69000 (5.98895 iter/s, 16.6974s/100 iters), loss = 0.024788
I0930 13:59:24.971590  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0247879 (* 1 = 0.0247879 loss)
I0930 13:59:24.971596  3537 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I0930 13:59:38.430594  3537 solver.cpp:218] Iteration 69100 (7.42999 iter/s, 13.459s/100 iters), loss = 0.0115031
I0930 13:59:38.430626  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011503 (* 1 = 0.011503 loss)
I0930 13:59:38.430634  3537 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I0930 13:59:51.882949  3537 solver.cpp:218] Iteration 69200 (7.43368 iter/s, 13.4523s/100 iters), loss = 0.0544027
I0930 13:59:51.883106  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0544026 (* 1 = 0.0544026 loss)
I0930 13:59:51.883126  3537 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I0930 14:00:05.348212  3537 solver.cpp:218] Iteration 69300 (7.42663 iter/s, 13.4651s/100 iters), loss = 0.0389163
I0930 14:00:05.348245  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0389163 (* 1 = 0.0389163 loss)
I0930 14:00:05.348261  3537 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I0930 14:00:18.795437  3537 solver.cpp:218] Iteration 69400 (7.43652 iter/s, 13.4472s/100 iters), loss = 0.0415157
I0930 14:00:18.795467  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0415157 (* 1 = 0.0415157 loss)
I0930 14:00:18.795473  3537 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I0930 14:00:31.578559  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:00:32.123286  3537 solver.cpp:330] Iteration 69500, Testing net (#0)
I0930 14:00:35.229382  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:00:35.359254  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8859
I0930 14:00:35.359290  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.463332 (* 1 = 0.463332 loss)
I0930 14:00:35.493134  3537 solver.cpp:218] Iteration 69500 (5.98888 iter/s, 16.6976s/100 iters), loss = 0.00816024
I0930 14:00:35.493167  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00816015 (* 1 = 0.00816015 loss)
I0930 14:00:35.493175  3537 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I0930 14:00:48.945957  3537 solver.cpp:218] Iteration 69600 (7.43342 iter/s, 13.4528s/100 iters), loss = 0.0689604
I0930 14:00:48.945987  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0689603 (* 1 = 0.0689603 loss)
I0930 14:00:48.945993  3537 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I0930 14:01:02.417368  3537 solver.cpp:218] Iteration 69700 (7.42317 iter/s, 13.4713s/100 iters), loss = 0.0230134
I0930 14:01:02.417510  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0230133 (* 1 = 0.0230133 loss)
I0930 14:01:02.417518  3537 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I0930 14:01:15.861093  3537 solver.cpp:218] Iteration 69800 (7.43851 iter/s, 13.4435s/100 iters), loss = 0.0288023
I0930 14:01:15.861124  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0288022 (* 1 = 0.0288022 loss)
I0930 14:01:15.861140  3537 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I0930 14:01:29.320317  3537 solver.cpp:218] Iteration 69900 (7.42989 iter/s, 13.4592s/100 iters), loss = 0.0310295
I0930 14:01:29.320349  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0310294 (* 1 = 0.0310294 loss)
I0930 14:01:29.320356  3537 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I0930 14:01:42.113827  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:01:42.649731  3537 solver.cpp:330] Iteration 70000, Testing net (#0)
I0930 14:01:45.759169  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:01:45.888464  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8875
I0930 14:01:45.888489  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.445326 (* 1 = 0.445326 loss)
I0930 14:01:46.021996  3537 solver.cpp:218] Iteration 70000 (5.98745 iter/s, 16.7016s/100 iters), loss = 0.0177293
I0930 14:01:46.022025  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177292 (* 1 = 0.0177292 loss)
I0930 14:01:46.022032  3537 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I0930 14:01:59.475729  3537 solver.cpp:218] Iteration 70100 (7.43292 iter/s, 13.4537s/100 iters), loss = 0.0103943
I0930 14:01:59.475760  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103942 (* 1 = 0.0103942 loss)
I0930 14:01:59.475767  3537 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I0930 14:02:12.917743  3537 solver.cpp:218] Iteration 70200 (7.4394 iter/s, 13.4419s/100 iters), loss = 0.0306074
I0930 14:02:12.917882  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0306073 (* 1 = 0.0306073 loss)
I0930 14:02:12.917901  3537 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I0930 14:02:26.380017  3537 solver.cpp:218] Iteration 70300 (7.42826 iter/s, 13.4621s/100 iters), loss = 0.0107083
I0930 14:02:26.380060  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107082 (* 1 = 0.0107082 loss)
I0930 14:02:26.380067  3537 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I0930 14:02:39.834861  3537 solver.cpp:218] Iteration 70400 (7.43231 iter/s, 13.4548s/100 iters), loss = 0.0425839
I0930 14:02:39.834900  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0425839 (* 1 = 0.0425839 loss)
I0930 14:02:39.834908  3537 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I0930 14:02:52.624946  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:02:53.169353  3537 solver.cpp:330] Iteration 70500, Testing net (#0)
I0930 14:02:56.271833  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:02:56.400992  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8973
I0930 14:02:56.401027  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.413903 (* 1 = 0.413903 loss)
I0930 14:02:56.535158  3537 solver.cpp:218] Iteration 70500 (5.98795 iter/s, 16.7002s/100 iters), loss = 0.0248138
I0930 14:02:56.535192  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0248137 (* 1 = 0.0248137 loss)
I0930 14:02:56.535198  3537 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I0930 14:03:09.994072  3537 solver.cpp:218] Iteration 70600 (7.43006 iter/s, 13.4588s/100 iters), loss = 0.0153896
I0930 14:03:09.994102  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0153895 (* 1 = 0.0153895 loss)
I0930 14:03:09.994107  3537 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I0930 14:03:23.469197  3537 solver.cpp:218] Iteration 70700 (7.42112 iter/s, 13.4751s/100 iters), loss = 0.0142793
I0930 14:03:23.469341  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142793 (* 1 = 0.0142793 loss)
I0930 14:03:23.469352  3537 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I0930 14:03:36.918510  3537 solver.cpp:218] Iteration 70800 (7.43542 iter/s, 13.4491s/100 iters), loss = 0.0141085
I0930 14:03:36.918542  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141084 (* 1 = 0.0141084 loss)
I0930 14:03:36.918558  3537 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I0930 14:03:50.374817  3537 solver.cpp:218] Iteration 70900 (7.4315 iter/s, 13.4562s/100 iters), loss = 0.0097402
I0930 14:03:50.374850  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00974014 (* 1 = 0.00974014 loss)
I0930 14:03:50.374856  3537 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I0930 14:04:03.162240  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:04:03.698849  3537 solver.cpp:330] Iteration 71000, Testing net (#0)
I0930 14:04:06.806558  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:04:06.935873  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8941
I0930 14:04:06.935909  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.431402 (* 1 = 0.431402 loss)
I0930 14:04:07.069888  3537 solver.cpp:218] Iteration 71000 (5.98982 iter/s, 16.695s/100 iters), loss = 0.00981276
I0930 14:04:07.069919  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00981271 (* 1 = 0.00981271 loss)
I0930 14:04:07.069926  3537 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I0930 14:04:20.524174  3537 solver.cpp:218] Iteration 71100 (7.43262 iter/s, 13.4542s/100 iters), loss = 0.0341046
I0930 14:04:20.524207  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0341045 (* 1 = 0.0341045 loss)
I0930 14:04:20.524214  3537 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I0930 14:04:33.965029  3537 solver.cpp:218] Iteration 71200 (7.44004 iter/s, 13.4408s/100 iters), loss = 0.0716823
I0930 14:04:33.965162  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0716822 (* 1 = 0.0716822 loss)
I0930 14:04:33.965169  3537 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I0930 14:04:47.424701  3537 solver.cpp:218] Iteration 71300 (7.4297 iter/s, 13.4595s/100 iters), loss = 0.0658175
I0930 14:04:47.424734  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0658175 (* 1 = 0.0658175 loss)
I0930 14:04:47.424741  3537 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I0930 14:05:00.876564  3537 solver.cpp:218] Iteration 71400 (7.43396 iter/s, 13.4518s/100 iters), loss = 0.0562116
I0930 14:05:00.876603  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0562116 (* 1 = 0.0562116 loss)
I0930 14:05:00.876610  3537 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I0930 14:05:13.653591  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:05:14.198046  3537 solver.cpp:330] Iteration 71500, Testing net (#0)
I0930 14:05:17.302723  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:05:17.432207  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.894
I0930 14:05:17.432232  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.42029 (* 1 = 0.42029 loss)
I0930 14:05:17.565027  3537 solver.cpp:218] Iteration 71500 (5.9922 iter/s, 16.6884s/100 iters), loss = 0.0269237
I0930 14:05:17.565062  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0269237 (* 1 = 0.0269237 loss)
I0930 14:05:17.565068  3537 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I0930 14:05:31.010370  3537 solver.cpp:218] Iteration 71600 (7.43756 iter/s, 13.4453s/100 iters), loss = 0.0604195
I0930 14:05:31.010411  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0604195 (* 1 = 0.0604195 loss)
I0930 14:05:31.010417  3537 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I0930 14:05:44.477618  3537 solver.cpp:218] Iteration 71700 (7.42547 iter/s, 13.4672s/100 iters), loss = 0.0309594
I0930 14:05:44.477720  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0309594 (* 1 = 0.0309594 loss)
I0930 14:05:44.477731  3537 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I0930 14:05:57.927240  3537 solver.cpp:218] Iteration 71800 (7.43523 iter/s, 13.4495s/100 iters), loss = 0.056063
I0930 14:05:57.927281  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0560629 (* 1 = 0.0560629 loss)
I0930 14:05:57.927289  3537 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I0930 14:06:11.383293  3537 solver.cpp:218] Iteration 71900 (7.43165 iter/s, 13.456s/100 iters), loss = 0.0468978
I0930 14:06:11.383327  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0468977 (* 1 = 0.0468977 loss)
I0930 14:06:11.383334  3537 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I0930 14:06:24.170752  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:06:24.707979  3537 solver.cpp:330] Iteration 72000, Testing net (#0)
I0930 14:06:27.816601  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:06:27.945654  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8799
I0930 14:06:27.945688  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.484367 (* 1 = 0.484367 loss)
I0930 14:06:28.079303  3537 solver.cpp:218] Iteration 72000 (5.98948 iter/s, 16.6959s/100 iters), loss = 0.0139444
I0930 14:06:28.079332  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139444 (* 1 = 0.0139444 loss)
I0930 14:06:28.079339  3537 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I0930 14:06:41.542351  3537 solver.cpp:218] Iteration 72100 (7.42778 iter/s, 13.463s/100 iters), loss = 0.0393113
I0930 14:06:41.542393  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0393112 (* 1 = 0.0393112 loss)
I0930 14:06:41.542400  3537 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I0930 14:06:55.001417  3537 solver.cpp:218] Iteration 72200 (7.42998 iter/s, 13.459s/100 iters), loss = 0.0739017
I0930 14:06:55.001546  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0739016 (* 1 = 0.0739016 loss)
I0930 14:06:55.001554  3537 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I0930 14:07:08.472667  3537 solver.cpp:218] Iteration 72300 (7.42331 iter/s, 13.4711s/100 iters), loss = 0.014103
I0930 14:07:08.472699  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014103 (* 1 = 0.014103 loss)
I0930 14:07:08.472707  3537 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I0930 14:07:21.930836  3537 solver.cpp:218] Iteration 72400 (7.43047 iter/s, 13.4581s/100 iters), loss = 0.0180193
I0930 14:07:21.930871  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0180193 (* 1 = 0.0180193 loss)
I0930 14:07:21.930881  3537 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I0930 14:07:34.712793  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:07:35.257105  3537 solver.cpp:330] Iteration 72500, Testing net (#0)
I0930 14:07:38.363032  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:07:38.492379  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8924
I0930 14:07:38.492406  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.43405 (* 1 = 0.43405 loss)
I0930 14:07:38.626389  3537 solver.cpp:218] Iteration 72500 (5.98965 iter/s, 16.6955s/100 iters), loss = 0.0307862
I0930 14:07:38.626427  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0307861 (* 1 = 0.0307861 loss)
I0930 14:07:38.626436  3537 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I0930 14:07:52.077778  3537 solver.cpp:218] Iteration 72600 (7.43422 iter/s, 13.4513s/100 iters), loss = 0.0381985
I0930 14:07:52.077811  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0381985 (* 1 = 0.0381985 loss)
I0930 14:07:52.077819  3537 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I0930 14:08:05.547475  3537 solver.cpp:218] Iteration 72700 (7.42411 iter/s, 13.4696s/100 iters), loss = 0.0146402
I0930 14:08:05.547607  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146402 (* 1 = 0.0146402 loss)
I0930 14:08:05.547621  3537 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I0930 14:08:19.006573  3537 solver.cpp:218] Iteration 72800 (7.43001 iter/s, 13.4589s/100 iters), loss = 0.0190719
I0930 14:08:19.006608  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0190719 (* 1 = 0.0190719 loss)
I0930 14:08:19.006625  3537 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I0930 14:08:32.470091  3537 solver.cpp:218] Iteration 72900 (7.42752 iter/s, 13.4634s/100 iters), loss = 0.0192902
I0930 14:08:32.470125  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0192901 (* 1 = 0.0192901 loss)
I0930 14:08:32.470132  3537 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I0930 14:08:45.266149  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:08:45.804733  3537 solver.cpp:330] Iteration 73000, Testing net (#0)
I0930 14:08:48.910862  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:08:49.039808  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8947
I0930 14:08:49.039842  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.410272 (* 1 = 0.410272 loss)
I0930 14:08:49.173118  3537 solver.cpp:218] Iteration 73000 (5.98697 iter/s, 16.7029s/100 iters), loss = 0.0271791
I0930 14:08:49.173152  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0271791 (* 1 = 0.0271791 loss)
I0930 14:08:49.173159  3537 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I0930 14:09:02.630774  3537 solver.cpp:218] Iteration 73100 (7.43076 iter/s, 13.4576s/100 iters), loss = 0.04878
I0930 14:09:02.630805  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.04878 (* 1 = 0.04878 loss)
I0930 14:09:02.630811  3537 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I0930 14:09:16.066061  3537 solver.cpp:218] Iteration 73200 (7.44313 iter/s, 13.4352s/100 iters), loss = 0.0101491
I0930 14:09:16.066197  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101491 (* 1 = 0.0101491 loss)
I0930 14:09:16.066215  3537 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I0930 14:09:29.516826  3537 solver.cpp:218] Iteration 73300 (7.43461 iter/s, 13.4506s/100 iters), loss = 0.0518976
I0930 14:09:29.516860  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0518976 (* 1 = 0.0518976 loss)
I0930 14:09:29.516866  3537 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I0930 14:09:42.967031  3537 solver.cpp:218] Iteration 73400 (7.43487 iter/s, 13.4501s/100 iters), loss = 0.0401251
I0930 14:09:42.967063  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.040125 (* 1 = 0.040125 loss)
I0930 14:09:42.967070  3537 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I0930 14:09:55.748726  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:09:56.292974  3537 solver.cpp:330] Iteration 73500, Testing net (#0)
I0930 14:09:59.398141  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:09:59.526643  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8952
I0930 14:09:59.526679  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.42688 (* 1 = 0.42688 loss)
I0930 14:09:59.660008  3537 solver.cpp:218] Iteration 73500 (5.99057 iter/s, 16.6929s/100 iters), loss = 0.0301988
I0930 14:09:59.660042  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0301987 (* 1 = 0.0301987 loss)
I0930 14:09:59.660048  3537 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I0930 14:10:13.108177  3537 solver.cpp:218] Iteration 73600 (7.436 iter/s, 13.4481s/100 iters), loss = 0.00965391
I0930 14:10:13.108208  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00965386 (* 1 = 0.00965386 loss)
I0930 14:10:13.108214  3537 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I0930 14:10:26.579777  3537 solver.cpp:218] Iteration 73700 (7.42306 iter/s, 13.4715s/100 iters), loss = 0.00879661
I0930 14:10:26.579924  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00879656 (* 1 = 0.00879656 loss)
I0930 14:10:26.579943  3537 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I0930 14:10:40.046646  3537 solver.cpp:218] Iteration 73800 (7.42573 iter/s, 13.4667s/100 iters), loss = 0.00600601
I0930 14:10:40.046676  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00600595 (* 1 = 0.00600595 loss)
I0930 14:10:40.046682  3537 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I0930 14:10:53.503327  3537 solver.cpp:218] Iteration 73900 (7.43129 iter/s, 13.4566s/100 iters), loss = 0.0240755
I0930 14:10:53.503360  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0240755 (* 1 = 0.0240755 loss)
I0930 14:10:53.503366  3537 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I0930 14:11:06.290882  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:11:06.827968  3537 solver.cpp:330] Iteration 74000, Testing net (#0)
I0930 14:11:09.932613  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:11:10.061738  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.898
I0930 14:11:10.061764  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.412462 (* 1 = 0.412462 loss)
I0930 14:11:10.195317  3537 solver.cpp:218] Iteration 74000 (5.99093 iter/s, 16.6919s/100 iters), loss = 0.0612864
I0930 14:11:10.195345  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0612863 (* 1 = 0.0612863 loss)
I0930 14:11:10.195353  3537 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I0930 14:11:23.659081  3537 solver.cpp:218] Iteration 74100 (7.42738 iter/s, 13.4637s/100 iters), loss = 0.0459564
I0930 14:11:23.659118  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0459563 (* 1 = 0.0459563 loss)
I0930 14:11:23.659126  3537 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I0930 14:11:37.108449  3537 solver.cpp:218] Iteration 74200 (7.43534 iter/s, 13.4493s/100 iters), loss = 0.090826
I0930 14:11:37.108579  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0908259 (* 1 = 0.0908259 loss)
I0930 14:11:37.108590  3537 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I0930 14:11:50.570327  3537 solver.cpp:218] Iteration 74300 (7.42847 iter/s, 13.4617s/100 iters), loss = 0.0132391
I0930 14:11:50.570361  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013239 (* 1 = 0.013239 loss)
I0930 14:11:50.570370  3537 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I0930 14:12:04.019784  3537 solver.cpp:218] Iteration 74400 (7.43529 iter/s, 13.4494s/100 iters), loss = 0.0294817
I0930 14:12:04.019817  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0294816 (* 1 = 0.0294816 loss)
I0930 14:12:04.019826  3537 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I0930 14:12:16.808650  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:12:17.353266  3537 solver.cpp:330] Iteration 74500, Testing net (#0)
I0930 14:12:20.453349  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:12:20.582808  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8918
I0930 14:12:20.582844  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.438959 (* 1 = 0.438959 loss)
I0930 14:12:20.715682  3537 solver.cpp:218] Iteration 74500 (5.98952 iter/s, 16.6958s/100 iters), loss = 0.00792155
I0930 14:12:20.715716  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00792145 (* 1 = 0.00792145 loss)
I0930 14:12:20.715723  3537 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I0930 14:12:34.152016  3537 solver.cpp:218] Iteration 74600 (7.44255 iter/s, 13.4363s/100 iters), loss = 0.0262457
I0930 14:12:34.152045  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0262455 (* 1 = 0.0262455 loss)
I0930 14:12:34.152051  3537 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I0930 14:12:47.613587  3537 solver.cpp:218] Iteration 74700 (7.42859 iter/s, 13.4615s/100 iters), loss = 0.0550502
I0930 14:12:47.613699  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0550501 (* 1 = 0.0550501 loss)
I0930 14:12:47.613708  3537 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I0930 14:13:01.068416  3537 solver.cpp:218] Iteration 74800 (7.43235 iter/s, 13.4547s/100 iters), loss = 0.0241319
I0930 14:13:01.068447  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0241318 (* 1 = 0.0241318 loss)
I0930 14:13:01.068454  3537 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I0930 14:13:14.523865  3537 solver.cpp:218] Iteration 74900 (7.43197 iter/s, 13.4554s/100 iters), loss = 0.0224027
I0930 14:13:14.523900  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0224026 (* 1 = 0.0224026 loss)
I0930 14:13:14.523907  3537 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I0930 14:13:27.305693  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:13:27.842840  3537 solver.cpp:330] Iteration 75000, Testing net (#0)
I0930 14:13:30.948374  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:13:31.078979  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8944
I0930 14:13:31.079015  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.429959 (* 1 = 0.429959 loss)
I0930 14:13:31.212255  3537 solver.cpp:218] Iteration 75000 (5.99222 iter/s, 16.6883s/100 iters), loss = 0.0703371
I0930 14:13:31.212286  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.070337 (* 1 = 0.070337 loss)
I0930 14:13:31.212292  3537 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I0930 14:13:44.680865  3537 solver.cpp:218] Iteration 75100 (7.42471 iter/s, 13.4685s/100 iters), loss = 0.0217557
I0930 14:13:44.680896  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0217556 (* 1 = 0.0217556 loss)
I0930 14:13:44.680902  3537 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I0930 14:13:58.128870  3537 solver.cpp:218] Iteration 75200 (7.43609 iter/s, 13.4479s/100 iters), loss = 0.0225809
I0930 14:13:58.129032  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0225809 (* 1 = 0.0225809 loss)
I0930 14:13:58.129041  3537 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I0930 14:14:11.586349  3537 solver.cpp:218] Iteration 75300 (7.43092 iter/s, 13.4573s/100 iters), loss = 0.0522093
I0930 14:14:11.586381  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0522092 (* 1 = 0.0522092 loss)
I0930 14:14:11.586388  3537 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I0930 14:14:25.036592  3537 solver.cpp:218] Iteration 75400 (7.43485 iter/s, 13.4502s/100 iters), loss = 0.00599335
I0930 14:14:25.036623  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0059933 (* 1 = 0.0059933 loss)
I0930 14:14:25.036628  3537 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I0930 14:14:37.833389  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:14:38.376915  3537 solver.cpp:330] Iteration 75500, Testing net (#0)
I0930 14:14:41.481971  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:14:41.610175  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8844
I0930 14:14:41.610199  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.474801 (* 1 = 0.474801 loss)
I0930 14:14:41.743865  3537 solver.cpp:218] Iteration 75500 (5.98545 iter/s, 16.7072s/100 iters), loss = 0.00752177
I0930 14:14:41.743897  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00752172 (* 1 = 0.00752172 loss)
I0930 14:14:41.743914  3537 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I0930 14:14:55.182036  3537 solver.cpp:218] Iteration 75600 (7.44153 iter/s, 13.4381s/100 iters), loss = 0.024158
I0930 14:14:55.182066  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0241579 (* 1 = 0.0241579 loss)
I0930 14:14:55.182072  3537 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I0930 14:15:08.642940  3537 solver.cpp:218] Iteration 75700 (7.42896 iter/s, 13.4608s/100 iters), loss = 0.0540224
I0930 14:15:08.643064  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0540224 (* 1 = 0.0540224 loss)
I0930 14:15:08.643071  3537 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I0930 14:15:22.098500  3537 solver.cpp:218] Iteration 75800 (7.43196 iter/s, 13.4554s/100 iters), loss = 0.0346037
I0930 14:15:22.098531  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0346037 (* 1 = 0.0346037 loss)
I0930 14:15:22.098538  3537 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I0930 14:15:35.546301  3537 solver.cpp:218] Iteration 75900 (7.4362 iter/s, 13.4477s/100 iters), loss = 0.0364102
I0930 14:15:35.546344  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0364102 (* 1 = 0.0364102 loss)
I0930 14:15:35.546351  3537 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I0930 14:15:48.325664  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:15:48.862128  3537 solver.cpp:330] Iteration 76000, Testing net (#0)
I0930 14:15:51.970638  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:15:52.099275  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8924
I0930 14:15:52.099299  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.43923 (* 1 = 0.43923 loss)
I0930 14:15:52.232661  3537 solver.cpp:218] Iteration 76000 (5.99295 iter/s, 16.6863s/100 iters), loss = 0.0102884
I0930 14:15:52.232694  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102884 (* 1 = 0.0102884 loss)
I0930 14:15:52.232702  3537 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I0930 14:16:05.697055  3537 solver.cpp:218] Iteration 76100 (7.42704 iter/s, 13.4643s/100 iters), loss = 0.0130452
I0930 14:16:05.697085  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130452 (* 1 = 0.0130452 loss)
I0930 14:16:05.697093  3537 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I0930 14:16:19.148846  3537 solver.cpp:218] Iteration 76200 (7.43399 iter/s, 13.4517s/100 iters), loss = 0.0396553
I0930 14:16:19.148950  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0396553 (* 1 = 0.0396553 loss)
I0930 14:16:19.148967  3537 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I0930 14:16:32.597270  3537 solver.cpp:218] Iteration 76300 (7.43589 iter/s, 13.4483s/100 iters), loss = 0.0374237
I0930 14:16:32.597302  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0374237 (* 1 = 0.0374237 loss)
I0930 14:16:32.597309  3537 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I0930 14:16:46.041149  3537 solver.cpp:218] Iteration 76400 (7.43837 iter/s, 13.4438s/100 iters), loss = 0.0156458
I0930 14:16:46.041189  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156458 (* 1 = 0.0156458 loss)
I0930 14:16:46.041195  3537 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I0930 14:16:58.831833  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:16:59.377674  3537 solver.cpp:330] Iteration 76500, Testing net (#0)
I0930 14:17:02.481992  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:17:02.611488  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8906
I0930 14:17:02.611524  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.442558 (* 1 = 0.442558 loss)
I0930 14:17:02.745039  3537 solver.cpp:218] Iteration 76500 (5.98666 iter/s, 16.7038s/100 iters), loss = 0.0241535
I0930 14:17:02.745074  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0241535 (* 1 = 0.0241535 loss)
I0930 14:17:02.745081  3537 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I0930 14:17:16.183816  3537 solver.cpp:218] Iteration 76600 (7.4412 iter/s, 13.4387s/100 iters), loss = 0.0206828
I0930 14:17:16.183846  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0206828 (* 1 = 0.0206828 loss)
I0930 14:17:16.183852  3537 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I0930 14:17:29.645148  3537 solver.cpp:218] Iteration 76700 (7.42872 iter/s, 13.4613s/100 iters), loss = 0.0194307
I0930 14:17:29.645300  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0194307 (* 1 = 0.0194307 loss)
I0930 14:17:29.645309  3537 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I0930 14:17:43.098383  3537 solver.cpp:218] Iteration 76800 (7.43326 iter/s, 13.453s/100 iters), loss = 0.0144088
I0930 14:17:43.098414  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0144088 (* 1 = 0.0144088 loss)
I0930 14:17:43.098420  3537 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I0930 14:17:56.549859  3537 solver.cpp:218] Iteration 76900 (7.43417 iter/s, 13.4514s/100 iters), loss = 0.0143321
I0930 14:17:56.549895  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143322 (* 1 = 0.0143322 loss)
I0930 14:17:56.549902  3537 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I0930 14:18:09.326400  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:18:09.862962  3537 solver.cpp:330] Iteration 77000, Testing net (#0)
I0930 14:18:12.967583  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:18:13.096640  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8908
I0930 14:18:13.096676  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.446753 (* 1 = 0.446753 loss)
I0930 14:18:13.229404  3537 solver.cpp:218] Iteration 77000 (5.9954 iter/s, 16.6795s/100 iters), loss = 0.0240638
I0930 14:18:13.229434  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0240638 (* 1 = 0.0240638 loss)
I0930 14:18:13.229440  3537 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I0930 14:18:26.678994  3537 solver.cpp:218] Iteration 77100 (7.43521 iter/s, 13.4495s/100 iters), loss = 0.031954
I0930 14:18:26.679026  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.031954 (* 1 = 0.031954 loss)
I0930 14:18:26.679033  3537 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I0930 14:18:40.126952  3537 solver.cpp:218] Iteration 77200 (7.43611 iter/s, 13.4479s/100 iters), loss = 0.0701049
I0930 14:18:40.127097  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0701049 (* 1 = 0.0701049 loss)
I0930 14:18:40.127104  3537 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I0930 14:18:53.571774  3537 solver.cpp:218] Iteration 77300 (7.43791 iter/s, 13.4446s/100 iters), loss = 0.0333544
I0930 14:18:53.571805  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0333545 (* 1 = 0.0333545 loss)
I0930 14:18:53.571810  3537 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I0930 14:19:07.013633  3537 solver.cpp:218] Iteration 77400 (7.43949 iter/s, 13.4418s/100 iters), loss = 0.0178398
I0930 14:19:07.013662  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0178398 (* 1 = 0.0178398 loss)
I0930 14:19:07.013669  3537 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I0930 14:19:19.798925  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:19:20.345721  3537 solver.cpp:330] Iteration 77500, Testing net (#0)
I0930 14:19:23.452713  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:19:23.582372  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8955
I0930 14:19:23.582408  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.432427 (* 1 = 0.432427 loss)
I0930 14:19:23.716389  3537 solver.cpp:218] Iteration 77500 (5.98706 iter/s, 16.7027s/100 iters), loss = 0.0325129
I0930 14:19:23.716425  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.032513 (* 1 = 0.032513 loss)
I0930 14:19:23.716433  3537 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I0930 14:19:37.159162  3537 solver.cpp:218] Iteration 77600 (7.43898 iter/s, 13.4427s/100 iters), loss = 0.0118516
I0930 14:19:37.159193  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118516 (* 1 = 0.0118516 loss)
I0930 14:19:37.159198  3537 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I0930 14:19:50.610178  3537 solver.cpp:218] Iteration 77700 (7.43442 iter/s, 13.4509s/100 iters), loss = 0.0353085
I0930 14:19:50.610280  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0353085 (* 1 = 0.0353085 loss)
I0930 14:19:50.610288  3537 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I0930 14:20:04.062072  3537 solver.cpp:218] Iteration 77800 (7.43398 iter/s, 13.4518s/100 iters), loss = 0.0207631
I0930 14:20:04.062110  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0207631 (* 1 = 0.0207631 loss)
I0930 14:20:04.062117  3537 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I0930 14:20:17.519659  3537 solver.cpp:218] Iteration 77900 (7.4308 iter/s, 13.4575s/100 iters), loss = 0.0386634
I0930 14:20:17.519691  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0386634 (* 1 = 0.0386634 loss)
I0930 14:20:17.519698  3537 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I0930 14:20:30.290105  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:20:30.826035  3537 solver.cpp:330] Iteration 78000, Testing net (#0)
I0930 14:20:33.929381  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:20:34.058475  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8917
I0930 14:20:34.058511  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.443529 (* 1 = 0.443529 loss)
I0930 14:20:34.191866  3537 solver.cpp:218] Iteration 78000 (5.99804 iter/s, 16.6721s/100 iters), loss = 0.0164966
I0930 14:20:34.191897  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0164966 (* 1 = 0.0164966 loss)
I0930 14:20:34.191905  3537 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I0930 14:20:47.649101  3537 solver.cpp:218] Iteration 78100 (7.43099 iter/s, 13.4572s/100 iters), loss = 0.0347695
I0930 14:20:47.649132  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0347695 (* 1 = 0.0347695 loss)
I0930 14:20:47.649139  3537 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I0930 14:21:01.105757  3537 solver.cpp:218] Iteration 78200 (7.43131 iter/s, 13.4566s/100 iters), loss = 0.0295337
I0930 14:21:01.105881  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0295337 (* 1 = 0.0295337 loss)
I0930 14:21:01.105888  3537 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I0930 14:21:14.556962  3537 solver.cpp:218] Iteration 78300 (7.43437 iter/s, 13.451s/100 iters), loss = 0.0226287
I0930 14:21:14.556996  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0226287 (* 1 = 0.0226287 loss)
I0930 14:21:14.557003  3537 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I0930 14:21:28.002265  3537 solver.cpp:218] Iteration 78400 (7.43758 iter/s, 13.4452s/100 iters), loss = 0.0128562
I0930 14:21:28.002296  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128562 (* 1 = 0.0128562 loss)
I0930 14:21:28.002302  3537 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I0930 14:21:40.789333  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:21:41.337023  3537 solver.cpp:330] Iteration 78500, Testing net (#0)
I0930 14:21:44.445159  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:21:44.574146  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8922
I0930 14:21:44.574172  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.457245 (* 1 = 0.457245 loss)
I0930 14:21:44.708348  3537 solver.cpp:218] Iteration 78500 (5.98587 iter/s, 16.706s/100 iters), loss = 0.00651941
I0930 14:21:44.708392  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00651941 (* 1 = 0.00651941 loss)
I0930 14:21:44.708401  3537 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I0930 14:21:58.157907  3537 solver.cpp:218] Iteration 78600 (7.43523 iter/s, 13.4495s/100 iters), loss = 0.0680294
I0930 14:21:58.157938  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0680294 (* 1 = 0.0680294 loss)
I0930 14:21:58.157954  3537 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I0930 14:22:11.608798  3537 solver.cpp:218] Iteration 78700 (7.43449 iter/s, 13.4508s/100 iters), loss = 0.0848325
I0930 14:22:11.608911  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0848324 (* 1 = 0.0848324 loss)
I0930 14:22:11.608928  3537 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I0930 14:22:25.060199  3537 solver.cpp:218] Iteration 78800 (7.43425 iter/s, 13.4513s/100 iters), loss = 0.018639
I0930 14:22:25.060228  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.018639 (* 1 = 0.018639 loss)
I0930 14:22:25.060235  3537 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I0930 14:22:38.514323  3537 solver.cpp:218] Iteration 78900 (7.4327 iter/s, 13.4541s/100 iters), loss = 0.0410439
I0930 14:22:38.514356  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0410438 (* 1 = 0.0410438 loss)
I0930 14:22:38.514364  3537 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I0930 14:22:51.292438  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:22:51.829725  3537 solver.cpp:330] Iteration 79000, Testing net (#0)
I0930 14:22:54.935330  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:22:55.064592  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8818
I0930 14:22:55.064628  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.465374 (* 1 = 0.465374 loss)
I0930 14:22:55.198488  3537 solver.cpp:218] Iteration 79000 (5.99374 iter/s, 16.6841s/100 iters), loss = 0.0309708
I0930 14:22:55.198518  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0309708 (* 1 = 0.0309708 loss)
I0930 14:22:55.198527  3537 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I0930 14:23:08.653141  3537 solver.cpp:218] Iteration 79100 (7.43241 iter/s, 13.4546s/100 iters), loss = 0.0420947
I0930 14:23:08.653172  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0420947 (* 1 = 0.0420947 loss)
I0930 14:23:08.653178  3537 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I0930 14:23:22.104760  3537 solver.cpp:218] Iteration 79200 (7.43409 iter/s, 13.4515s/100 iters), loss = 0.005651
I0930 14:23:22.104856  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00565098 (* 1 = 0.00565098 loss)
I0930 14:23:22.104873  3537 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I0930 14:23:35.555440  3537 solver.cpp:218] Iteration 79300 (7.43464 iter/s, 13.4505s/100 iters), loss = 0.0364888
I0930 14:23:35.555472  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0364888 (* 1 = 0.0364888 loss)
I0930 14:23:35.555479  3537 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I0930 14:23:49.001098  3537 solver.cpp:218] Iteration 79400 (7.43739 iter/s, 13.4456s/100 iters), loss = 0.0325947
I0930 14:23:49.001129  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0325946 (* 1 = 0.0325946 loss)
I0930 14:23:49.001137  3537 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I0930 14:24:01.787071  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:24:02.334206  3537 solver.cpp:330] Iteration 79500, Testing net (#0)
I0930 14:24:05.439607  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:24:05.569083  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8925
I0930 14:24:05.569118  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.464864 (* 1 = 0.464864 loss)
I0930 14:24:05.703176  3537 solver.cpp:218] Iteration 79500 (5.98731 iter/s, 16.702s/100 iters), loss = 0.0646754
I0930 14:24:05.703208  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0646753 (* 1 = 0.0646753 loss)
I0930 14:24:05.703224  3537 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I0930 14:24:19.152130  3537 solver.cpp:218] Iteration 79600 (7.43556 iter/s, 13.4489s/100 iters), loss = 0.0140073
I0930 14:24:19.152160  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0140072 (* 1 = 0.0140072 loss)
I0930 14:24:19.152166  3537 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I0930 14:24:32.599529  3537 solver.cpp:218] Iteration 79700 (7.43642 iter/s, 13.4473s/100 iters), loss = 0.0572764
I0930 14:24:32.599650  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0572764 (* 1 = 0.0572764 loss)
I0930 14:24:32.599668  3537 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I0930 14:24:46.050614  3537 solver.cpp:218] Iteration 79800 (7.43443 iter/s, 13.4509s/100 iters), loss = 0.00977939
I0930 14:24:46.050647  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00977934 (* 1 = 0.00977934 loss)
I0930 14:24:46.050652  3537 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I0930 14:24:59.509127  3537 solver.cpp:218] Iteration 79900 (7.43028 iter/s, 13.4584s/100 iters), loss = 0.015134
I0930 14:24:59.509160  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0151339 (* 1 = 0.0151339 loss)
I0930 14:24:59.509167  3537 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I0930 14:25:12.284426  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:25:12.820711  3537 solver.cpp:330] Iteration 80000, Testing net (#0)
I0930 14:25:15.923833  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:25:16.052924  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8874
I0930 14:25:16.052959  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.457134 (* 1 = 0.457134 loss)
I0930 14:25:16.186658  3537 solver.cpp:218] Iteration 80000 (5.99612 iter/s, 16.6774s/100 iters), loss = 0.0226927
I0930 14:25:16.186689  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0226927 (* 1 = 0.0226927 loss)
I0930 14:25:16.186695  3537 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I0930 14:25:16.186698  3537 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I0930 14:25:29.636229  3537 solver.cpp:218] Iteration 80100 (7.43522 iter/s, 13.4495s/100 iters), loss = 0.0535895
I0930 14:25:29.636260  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0535895 (* 1 = 0.0535895 loss)
I0930 14:25:29.636266  3537 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I0930 14:25:43.085140  3537 solver.cpp:218] Iteration 80200 (7.43559 iter/s, 13.4488s/100 iters), loss = 0.0357411
I0930 14:25:43.085253  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.035741 (* 1 = 0.035741 loss)
I0930 14:25:43.085260  3537 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I0930 14:25:56.545213  3537 solver.cpp:218] Iteration 80300 (7.42946 iter/s, 13.4599s/100 iters), loss = 0.00609115
I0930 14:25:56.545245  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00609112 (* 1 = 0.00609112 loss)
I0930 14:25:56.545251  3537 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I0930 14:26:09.997092  3537 solver.cpp:218] Iteration 80400 (7.43395 iter/s, 13.4518s/100 iters), loss = 0.0186739
I0930 14:26:09.997123  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0186739 (* 1 = 0.0186739 loss)
I0930 14:26:09.997128  3537 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I0930 14:26:22.786883  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:26:23.333164  3537 solver.cpp:330] Iteration 80500, Testing net (#0)
I0930 14:26:26.439754  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:26:26.568981  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9054
I0930 14:26:26.569005  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368715 (* 1 = 0.368715 loss)
I0930 14:26:26.702692  3537 solver.cpp:218] Iteration 80500 (5.98605 iter/s, 16.7055s/100 iters), loss = 0.0187793
I0930 14:26:26.702726  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0187793 (* 1 = 0.0187793 loss)
I0930 14:26:26.702733  3537 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I0930 14:26:40.160168  3537 solver.cpp:218] Iteration 80600 (7.43085 iter/s, 13.4574s/100 iters), loss = 0.0199318
I0930 14:26:40.160198  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0199318 (* 1 = 0.0199318 loss)
I0930 14:26:40.160204  3537 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I0930 14:26:53.611897  3537 solver.cpp:218] Iteration 80700 (7.43403 iter/s, 13.4517s/100 iters), loss = 0.00991034
I0930 14:26:53.611989  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00991033 (* 1 = 0.00991033 loss)
I0930 14:26:53.612006  3537 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I0930 14:27:07.064784  3537 solver.cpp:218] Iteration 80800 (7.43342 iter/s, 13.4528s/100 iters), loss = 0.0046691
I0930 14:27:07.064816  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0046691 (* 1 = 0.0046691 loss)
I0930 14:27:07.064822  3537 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I0930 14:27:20.532896  3537 solver.cpp:218] Iteration 80900 (7.42499 iter/s, 13.468s/100 iters), loss = 0.007527
I0930 14:27:20.532927  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00752701 (* 1 = 0.00752701 loss)
I0930 14:27:20.532934  3537 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I0930 14:27:33.319941  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:27:33.856727  3537 solver.cpp:330] Iteration 81000, Testing net (#0)
I0930 14:27:36.961423  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:27:37.091315  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.909
I0930 14:27:37.091349  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.357729 (* 1 = 0.357729 loss)
I0930 14:27:37.224736  3537 solver.cpp:218] Iteration 81000 (5.99098 iter/s, 16.6918s/100 iters), loss = 0.00359631
I0930 14:27:37.224766  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00359631 (* 1 = 0.00359631 loss)
I0930 14:27:37.224774  3537 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I0930 14:27:50.670951  3537 solver.cpp:218] Iteration 81100 (7.43708 iter/s, 13.4461s/100 iters), loss = 0.0178773
I0930 14:27:50.670982  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0178773 (* 1 = 0.0178773 loss)
I0930 14:27:50.670989  3537 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I0930 14:28:04.119040  3537 solver.cpp:218] Iteration 81200 (7.43604 iter/s, 13.448s/100 iters), loss = 0.0263708
I0930 14:28:04.119173  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0263708 (* 1 = 0.0263708 loss)
I0930 14:28:04.119179  3537 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I0930 14:28:17.579077  3537 solver.cpp:218] Iteration 81300 (7.4295 iter/s, 13.4599s/100 iters), loss = 0.0621017
I0930 14:28:17.579113  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0621017 (* 1 = 0.0621017 loss)
I0930 14:28:17.579129  3537 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I0930 14:28:31.019655  3537 solver.cpp:218] Iteration 81400 (7.4402 iter/s, 13.4405s/100 iters), loss = 0.00193834
I0930 14:28:31.019685  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00193834 (* 1 = 0.00193834 loss)
I0930 14:28:31.019702  3537 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I0930 14:28:43.799075  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:28:44.346247  3537 solver.cpp:330] Iteration 81500, Testing net (#0)
I0930 14:28:47.454726  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:28:47.583598  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9107
I0930 14:28:47.583634  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.355051 (* 1 = 0.355051 loss)
I0930 14:28:47.717159  3537 solver.cpp:218] Iteration 81500 (5.98895 iter/s, 16.6974s/100 iters), loss = 0.00628501
I0930 14:28:47.717191  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.006285 (* 1 = 0.006285 loss)
I0930 14:28:47.717200  3537 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I0930 14:29:01.162230  3537 solver.cpp:218] Iteration 81600 (7.43771 iter/s, 13.445s/100 iters), loss = 0.0130542
I0930 14:29:01.162259  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130542 (* 1 = 0.0130542 loss)
I0930 14:29:01.162266  3537 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I0930 14:29:14.616394  3537 solver.cpp:218] Iteration 81700 (7.43268 iter/s, 13.4541s/100 iters), loss = 0.0364377
I0930 14:29:14.616509  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0364377 (* 1 = 0.0364377 loss)
I0930 14:29:14.616528  3537 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I0930 14:29:28.071704  3537 solver.cpp:218] Iteration 81800 (7.43209 iter/s, 13.4552s/100 iters), loss = 0.0131467
I0930 14:29:28.071745  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131467 (* 1 = 0.0131467 loss)
I0930 14:29:28.071753  3537 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I0930 14:29:41.537173  3537 solver.cpp:218] Iteration 81900 (7.42645 iter/s, 13.4654s/100 iters), loss = 0.0167118
I0930 14:29:41.537216  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0167119 (* 1 = 0.0167119 loss)
I0930 14:29:41.537231  3537 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I0930 14:29:54.323823  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:29:54.860103  3537 solver.cpp:330] Iteration 82000, Testing net (#0)
I0930 14:29:57.964335  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:29:58.093525  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9113
I0930 14:29:58.093559  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358148 (* 1 = 0.358148 loss)
I0930 14:29:58.227618  3537 solver.cpp:218] Iteration 82000 (5.99148 iter/s, 16.6904s/100 iters), loss = 0.00815313
I0930 14:29:58.227648  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00815314 (* 1 = 0.00815314 loss)
I0930 14:29:58.227654  3537 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I0930 14:30:11.679392  3537 solver.cpp:218] Iteration 82100 (7.434 iter/s, 13.4517s/100 iters), loss = 0.0353182
I0930 14:30:11.679424  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0353182 (* 1 = 0.0353182 loss)
I0930 14:30:11.679430  3537 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I0930 14:30:25.139653  3537 solver.cpp:218] Iteration 82200 (7.42931 iter/s, 13.4602s/100 iters), loss = 0.0513482
I0930 14:30:25.139761  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0513482 (* 1 = 0.0513482 loss)
I0930 14:30:25.139770  3537 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I0930 14:30:38.606343  3537 solver.cpp:218] Iteration 82300 (7.42581 iter/s, 13.4666s/100 iters), loss = 0.0118713
I0930 14:30:38.606374  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118713 (* 1 = 0.0118713 loss)
I0930 14:30:38.606380  3537 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I0930 14:30:52.056675  3537 solver.cpp:218] Iteration 82400 (7.4348 iter/s, 13.4503s/100 iters), loss = 0.0183414
I0930 14:30:52.056705  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0183414 (* 1 = 0.0183414 loss)
I0930 14:30:52.056712  3537 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I0930 14:31:04.848665  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:31:05.398056  3537 solver.cpp:330] Iteration 82500, Testing net (#0)
I0930 14:31:08.504894  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:31:08.635012  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9106
I0930 14:31:08.635047  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.359114 (* 1 = 0.359114 loss)
I0930 14:31:08.768708  3537 solver.cpp:218] Iteration 82500 (5.98374 iter/s, 16.712s/100 iters), loss = 0.00446147
I0930 14:31:08.768741  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00446148 (* 1 = 0.00446148 loss)
I0930 14:31:08.768748  3537 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I0930 14:31:22.214829  3537 solver.cpp:218] Iteration 82600 (7.43713 iter/s, 13.446s/100 iters), loss = 0.00274298
I0930 14:31:22.214860  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00274299 (* 1 = 0.00274299 loss)
I0930 14:31:22.214866  3537 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I0930 14:31:35.666810  3537 solver.cpp:218] Iteration 82700 (7.43389 iter/s, 13.4519s/100 iters), loss = 0.00412142
I0930 14:31:35.666954  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00412142 (* 1 = 0.00412142 loss)
I0930 14:31:35.666961  3537 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I0930 14:31:49.108393  3537 solver.cpp:218] Iteration 82800 (7.4397 iter/s, 13.4414s/100 iters), loss = 0.00502853
I0930 14:31:49.108423  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00502853 (* 1 = 0.00502853 loss)
I0930 14:31:49.108429  3537 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I0930 14:32:02.567133  3537 solver.cpp:218] Iteration 82900 (7.43015 iter/s, 13.4587s/100 iters), loss = 0.012643
I0930 14:32:02.567167  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012643 (* 1 = 0.012643 loss)
I0930 14:32:02.567173  3537 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I0930 14:32:15.347862  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:32:15.883975  3537 solver.cpp:330] Iteration 83000, Testing net (#0)
I0930 14:32:18.987536  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:32:19.116840  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9111
I0930 14:32:19.116875  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358099 (* 1 = 0.358099 loss)
I0930 14:32:19.250226  3537 solver.cpp:218] Iteration 83000 (5.99412 iter/s, 16.683s/100 iters), loss = 0.00551988
I0930 14:32:19.250257  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00551988 (* 1 = 0.00551988 loss)
I0930 14:32:19.250263  3537 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I0930 14:32:32.692373  3537 solver.cpp:218] Iteration 83100 (7.43933 iter/s, 13.4421s/100 iters), loss = 0.00733675
I0930 14:32:32.692404  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00733675 (* 1 = 0.00733675 loss)
I0930 14:32:32.692411  3537 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I0930 14:32:46.143896  3537 solver.cpp:218] Iteration 83200 (7.43414 iter/s, 13.4515s/100 iters), loss = 0.025517
I0930 14:32:46.144016  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.025517 (* 1 = 0.025517 loss)
I0930 14:32:46.144032  3537 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I0930 14:32:59.608570  3537 solver.cpp:218] Iteration 83300 (7.42693 iter/s, 13.4645s/100 iters), loss = 0.00321582
I0930 14:32:59.608614  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00321583 (* 1 = 0.00321583 loss)
I0930 14:32:59.608621  3537 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I0930 14:33:13.054463  3537 solver.cpp:218] Iteration 83400 (7.43726 iter/s, 13.4458s/100 iters), loss = 0.00154648
I0930 14:33:13.054493  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154648 (* 1 = 0.00154648 loss)
I0930 14:33:13.054500  3537 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I0930 14:33:25.831413  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:33:26.378685  3537 solver.cpp:330] Iteration 83500, Testing net (#0)
I0930 14:33:29.486631  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:33:29.616364  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9108
I0930 14:33:29.616400  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.357574 (* 1 = 0.357574 loss)
I0930 14:33:29.749922  3537 solver.cpp:218] Iteration 83500 (5.98968 iter/s, 16.6954s/100 iters), loss = 0.00233679
I0930 14:33:29.749955  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0023368 (* 1 = 0.0023368 loss)
I0930 14:33:29.749963  3537 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I0930 14:33:43.216642  3537 solver.cpp:218] Iteration 83600 (7.42575 iter/s, 13.4666s/100 iters), loss = 0.0026527
I0930 14:33:43.216672  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00265272 (* 1 = 0.00265272 loss)
I0930 14:33:43.216680  3537 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I0930 14:33:56.689137  3537 solver.cpp:218] Iteration 83700 (7.42257 iter/s, 13.4724s/100 iters), loss = 0.011481
I0930 14:33:56.689252  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011481 (* 1 = 0.011481 loss)
I0930 14:33:56.689260  3537 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I0930 14:34:10.146503  3537 solver.cpp:218] Iteration 83800 (7.43095 iter/s, 13.4572s/100 iters), loss = 0.00776523
I0930 14:34:10.146534  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00776525 (* 1 = 0.00776525 loss)
I0930 14:34:10.146540  3537 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I0930 14:34:23.624655  3537 solver.cpp:218] Iteration 83900 (7.41946 iter/s, 13.4781s/100 iters), loss = 0.00187925
I0930 14:34:23.624691  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00187927 (* 1 = 0.00187927 loss)
I0930 14:34:23.624699  3537 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I0930 14:34:36.417497  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:34:36.955736  3537 solver.cpp:330] Iteration 84000, Testing net (#0)
I0930 14:34:40.060549  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:34:40.189596  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9126
I0930 14:34:40.189622  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.356435 (* 1 = 0.356435 loss)
I0930 14:34:40.323123  3537 solver.cpp:218] Iteration 84000 (5.9886 iter/s, 16.6984s/100 iters), loss = 0.00159839
I0930 14:34:40.323156  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00159841 (* 1 = 0.00159841 loss)
I0930 14:34:40.323165  3537 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I0930 14:34:53.772234  3537 solver.cpp:218] Iteration 84100 (7.43548 iter/s, 13.449s/100 iters), loss = 0.0076542
I0930 14:34:53.772269  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00765423 (* 1 = 0.00765423 loss)
I0930 14:34:53.772279  3537 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I0930 14:35:07.215477  3537 solver.cpp:218] Iteration 84200 (7.43872 iter/s, 13.4432s/100 iters), loss = 0.00404951
I0930 14:35:07.215579  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00404953 (* 1 = 0.00404953 loss)
I0930 14:35:07.215589  3537 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I0930 14:35:20.677084  3537 solver.cpp:218] Iteration 84300 (7.42861 iter/s, 13.4615s/100 iters), loss = 0.00280046
I0930 14:35:20.677120  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00280047 (* 1 = 0.00280047 loss)
I0930 14:35:20.677129  3537 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I0930 14:35:34.124717  3537 solver.cpp:218] Iteration 84400 (7.43629 iter/s, 13.4476s/100 iters), loss = 0.00753223
I0930 14:35:34.124750  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00753225 (* 1 = 0.00753225 loss)
I0930 14:35:34.124758  3537 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I0930 14:35:46.901374  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:35:47.446437  3537 solver.cpp:330] Iteration 84500, Testing net (#0)
I0930 14:35:50.554760  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:35:50.684268  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9107
I0930 14:35:50.684295  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.35965 (* 1 = 0.35965 loss)
I0930 14:35:50.817113  3537 solver.cpp:218] Iteration 84500 (5.99078 iter/s, 16.6923s/100 iters), loss = 0.00348849
I0930 14:35:50.817150  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0034885 (* 1 = 0.0034885 loss)
I0930 14:35:50.817160  3537 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I0930 14:36:04.270895  3537 solver.cpp:218] Iteration 84600 (7.4329 iter/s, 13.4537s/100 iters), loss = 0.0137743
I0930 14:36:04.270927  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0137743 (* 1 = 0.0137743 loss)
I0930 14:36:04.270936  3537 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I0930 14:36:17.727855  3537 solver.cpp:218] Iteration 84700 (7.43114 iter/s, 13.4569s/100 iters), loss = 0.00204177
I0930 14:36:17.727962  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00204179 (* 1 = 0.00204179 loss)
I0930 14:36:17.727969  3537 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I0930 14:36:31.166716  3537 solver.cpp:218] Iteration 84800 (7.44119 iter/s, 13.4387s/100 iters), loss = 0.00169514
I0930 14:36:31.166746  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00169515 (* 1 = 0.00169515 loss)
I0930 14:36:31.166752  3537 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I0930 14:36:44.628747  3537 solver.cpp:218] Iteration 84900 (7.42834 iter/s, 13.462s/100 iters), loss = 0.00791854
I0930 14:36:44.628780  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00791855 (* 1 = 0.00791855 loss)
I0930 14:36:44.628787  3537 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I0930 14:36:57.416065  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:36:57.953814  3537 solver.cpp:330] Iteration 85000, Testing net (#0)
I0930 14:37:01.063038  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:37:01.192232  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9111
I0930 14:37:01.192257  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358214 (* 1 = 0.358214 loss)
I0930 14:37:01.325443  3537 solver.cpp:218] Iteration 85000 (5.98924 iter/s, 16.6966s/100 iters), loss = 0.00299858
I0930 14:37:01.325471  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00299858 (* 1 = 0.00299858 loss)
I0930 14:37:01.325479  3537 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I0930 14:37:14.776842  3537 solver.cpp:218] Iteration 85100 (7.43421 iter/s, 13.4513s/100 iters), loss = 0.00558989
I0930 14:37:14.776875  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00558989 (* 1 = 0.00558989 loss)
I0930 14:37:14.776880  3537 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I0930 14:37:28.224625  3537 solver.cpp:218] Iteration 85200 (7.43621 iter/s, 13.4477s/100 iters), loss = 0.00127741
I0930 14:37:28.224764  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00127741 (* 1 = 0.00127741 loss)
I0930 14:37:28.224771  3537 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I0930 14:37:41.686506  3537 solver.cpp:218] Iteration 85300 (7.42848 iter/s, 13.4617s/100 iters), loss = 0.00497512
I0930 14:37:41.686552  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00497513 (* 1 = 0.00497513 loss)
I0930 14:37:41.686559  3537 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I0930 14:37:55.133054  3537 solver.cpp:218] Iteration 85400 (7.4369 iter/s, 13.4465s/100 iters), loss = 0.00420935
I0930 14:37:55.133085  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00420936 (* 1 = 0.00420936 loss)
I0930 14:37:55.133091  3537 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I0930 14:38:07.905586  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:38:08.450075  3537 solver.cpp:330] Iteration 85500, Testing net (#0)
I0930 14:38:11.554433  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:38:11.683689  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9121
I0930 14:38:11.683727  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.357478 (* 1 = 0.357478 loss)
I0930 14:38:11.817574  3537 solver.cpp:218] Iteration 85500 (5.99361 iter/s, 16.6844s/100 iters), loss = 0.00302903
I0930 14:38:11.817606  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00302903 (* 1 = 0.00302903 loss)
I0930 14:38:11.817613  3537 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I0930 14:38:25.270790  3537 solver.cpp:218] Iteration 85600 (7.43321 iter/s, 13.4531s/100 iters), loss = 0.00572986
I0930 14:38:25.270819  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00572987 (* 1 = 0.00572987 loss)
I0930 14:38:25.270825  3537 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I0930 14:38:38.740109  3537 solver.cpp:218] Iteration 85700 (7.42432 iter/s, 13.4692s/100 iters), loss = 0.00356708
I0930 14:38:38.740237  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00356709 (* 1 = 0.00356709 loss)
I0930 14:38:38.740255  3537 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I0930 14:38:52.191355  3537 solver.cpp:218] Iteration 85800 (7.43434 iter/s, 13.4511s/100 iters), loss = 0.0054235
I0930 14:38:52.191388  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00542351 (* 1 = 0.00542351 loss)
I0930 14:38:52.191395  3537 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I0930 14:39:05.651370  3537 solver.cpp:218] Iteration 85900 (7.42945 iter/s, 13.4599s/100 iters), loss = 0.0124563
I0930 14:39:05.651412  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124563 (* 1 = 0.0124563 loss)
I0930 14:39:05.651419  3537 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I0930 14:39:18.442193  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:39:18.978315  3537 solver.cpp:330] Iteration 86000, Testing net (#0)
I0930 14:39:22.080164  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:39:22.209390  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9119
I0930 14:39:22.209415  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.357446 (* 1 = 0.357446 loss)
I0930 14:39:22.343189  3537 solver.cpp:218] Iteration 86000 (5.99099 iter/s, 16.6917s/100 iters), loss = 0.00358842
I0930 14:39:22.343220  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00358844 (* 1 = 0.00358844 loss)
I0930 14:39:22.343227  3537 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I0930 14:39:35.798110  3537 solver.cpp:218] Iteration 86100 (7.43227 iter/s, 13.4548s/100 iters), loss = 0.00241785
I0930 14:39:35.798141  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00241786 (* 1 = 0.00241786 loss)
I0930 14:39:35.798147  3537 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I0930 14:39:49.244719  3537 solver.cpp:218] Iteration 86200 (7.43686 iter/s, 13.4465s/100 iters), loss = 0.00556376
I0930 14:39:49.244813  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00556377 (* 1 = 0.00556377 loss)
I0930 14:39:49.244820  3537 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I0930 14:40:02.705267  3537 solver.cpp:218] Iteration 86300 (7.42919 iter/s, 13.4604s/100 iters), loss = 0.00909889
I0930 14:40:02.705299  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00909889 (* 1 = 0.00909889 loss)
I0930 14:40:02.705307  3537 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I0930 14:40:16.155144  3537 solver.cpp:218] Iteration 86400 (7.43505 iter/s, 13.4498s/100 iters), loss = 0.0100371
I0930 14:40:16.155176  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100371 (* 1 = 0.0100371 loss)
I0930 14:40:16.155182  3537 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I0930 14:40:28.938752  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:40:29.484388  3537 solver.cpp:330] Iteration 86500, Testing net (#0)
I0930 14:40:32.588861  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:40:32.718052  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.912
I0930 14:40:32.718088  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.361562 (* 1 = 0.361562 loss)
I0930 14:40:32.851425  3537 solver.cpp:218] Iteration 86500 (5.98939 iter/s, 16.6962s/100 iters), loss = 0.0105414
I0930 14:40:32.851459  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105414 (* 1 = 0.0105414 loss)
I0930 14:40:32.851465  3537 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I0930 14:40:46.299433  3537 solver.cpp:218] Iteration 86600 (7.43609 iter/s, 13.4479s/100 iters), loss = 0.00444277
I0930 14:40:46.299464  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00444278 (* 1 = 0.00444278 loss)
I0930 14:40:46.299470  3537 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I0930 14:40:59.768496  3537 solver.cpp:218] Iteration 86700 (7.42446 iter/s, 13.469s/100 iters), loss = 0.00413024
I0930 14:40:59.768635  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00413024 (* 1 = 0.00413024 loss)
I0930 14:40:59.768652  3537 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I0930 14:41:13.213461  3537 solver.cpp:218] Iteration 86800 (7.43783 iter/s, 13.4448s/100 iters), loss = 0.00540092
I0930 14:41:13.213491  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00540092 (* 1 = 0.00540092 loss)
I0930 14:41:13.213497  3537 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I0930 14:41:26.667527  3537 solver.cpp:218] Iteration 86900 (7.43274 iter/s, 13.454s/100 iters), loss = 0.01667
I0930 14:41:26.667560  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01667 (* 1 = 0.01667 loss)
I0930 14:41:26.667567  3537 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I0930 14:41:39.451761  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:41:39.987284  3537 solver.cpp:330] Iteration 87000, Testing net (#0)
I0930 14:41:43.094347  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:41:43.223620  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9124
I0930 14:41:43.223655  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358868 (* 1 = 0.358868 loss)
I0930 14:41:43.357306  3537 solver.cpp:218] Iteration 87000 (5.99172 iter/s, 16.6897s/100 iters), loss = 0.00455851
I0930 14:41:43.357336  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00455851 (* 1 = 0.00455851 loss)
I0930 14:41:43.357342  3537 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I0930 14:41:56.808295  3537 solver.cpp:218] Iteration 87100 (7.43444 iter/s, 13.4509s/100 iters), loss = 0.0109586
I0930 14:41:56.808344  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109586 (* 1 = 0.0109586 loss)
I0930 14:41:56.808353  3537 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I0930 14:42:10.249469  3537 solver.cpp:218] Iteration 87200 (7.43988 iter/s, 13.4411s/100 iters), loss = 0.00598137
I0930 14:42:10.249578  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00598138 (* 1 = 0.00598138 loss)
I0930 14:42:10.249586  3537 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I0930 14:42:23.715086  3537 solver.cpp:218] Iteration 87300 (7.4264 iter/s, 13.4655s/100 iters), loss = 0.00319264
I0930 14:42:23.715131  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00319264 (* 1 = 0.00319264 loss)
I0930 14:42:23.715138  3537 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I0930 14:42:37.166440  3537 solver.cpp:218] Iteration 87400 (7.43424 iter/s, 13.4513s/100 iters), loss = 0.0333748
I0930 14:42:37.166471  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0333748 (* 1 = 0.0333748 loss)
I0930 14:42:37.166486  3537 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I0930 14:42:49.948030  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:42:50.491601  3537 solver.cpp:330] Iteration 87500, Testing net (#0)
I0930 14:42:53.593466  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:42:53.722923  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9119
I0930 14:42:53.722947  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358287 (* 1 = 0.358287 loss)
I0930 14:42:53.856801  3537 solver.cpp:218] Iteration 87500 (5.99151 iter/s, 16.6903s/100 iters), loss = 0.00291008
I0930 14:42:53.856834  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00291009 (* 1 = 0.00291009 loss)
I0930 14:42:53.856842  3537 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I0930 14:43:07.313454  3537 solver.cpp:218] Iteration 87600 (7.43131 iter/s, 13.4566s/100 iters), loss = 0.00479772
I0930 14:43:07.313486  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00479773 (* 1 = 0.00479773 loss)
I0930 14:43:07.313493  3537 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I0930 14:43:20.784494  3537 solver.cpp:218] Iteration 87700 (7.42337 iter/s, 13.471s/100 iters), loss = 0.00265718
I0930 14:43:20.784610  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00265719 (* 1 = 0.00265719 loss)
I0930 14:43:20.784628  3537 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I0930 14:43:34.233683  3537 solver.cpp:218] Iteration 87800 (7.43547 iter/s, 13.449s/100 iters), loss = 0.00707504
I0930 14:43:34.233713  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00707505 (* 1 = 0.00707505 loss)
I0930 14:43:34.233719  3537 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I0930 14:43:47.689023  3537 solver.cpp:218] Iteration 87900 (7.43203 iter/s, 13.4553s/100 iters), loss = 0.00910384
I0930 14:43:47.689056  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00910385 (* 1 = 0.00910385 loss)
I0930 14:43:47.689062  3537 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I0930 14:44:00.483789  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:44:01.020537  3537 solver.cpp:330] Iteration 88000, Testing net (#0)
I0930 14:44:04.128121  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:44:04.257134  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9141
I0930 14:44:04.257158  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.354779 (* 1 = 0.354779 loss)
I0930 14:44:04.391489  3537 solver.cpp:218] Iteration 88000 (5.98717 iter/s, 16.7024s/100 iters), loss = 0.00183714
I0930 14:44:04.391518  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00183715 (* 1 = 0.00183715 loss)
I0930 14:44:04.391525  3537 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I0930 14:44:17.853703  3537 solver.cpp:218] Iteration 88100 (7.42824 iter/s, 13.4621s/100 iters), loss = 0.00573498
I0930 14:44:17.853734  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00573498 (* 1 = 0.00573498 loss)
I0930 14:44:17.853740  3537 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I0930 14:44:31.300793  3537 solver.cpp:218] Iteration 88200 (7.43659 iter/s, 13.447s/100 iters), loss = 0.002872
I0930 14:44:31.300933  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.002872 (* 1 = 0.002872 loss)
I0930 14:44:31.300942  3537 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I0930 14:44:44.772176  3537 solver.cpp:218] Iteration 88300 (7.42323 iter/s, 13.4712s/100 iters), loss = 0.00890969
I0930 14:44:44.772218  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00890969 (* 1 = 0.00890969 loss)
I0930 14:44:44.772225  3537 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I0930 14:44:58.221742  3537 solver.cpp:218] Iteration 88400 (7.43523 iter/s, 13.4495s/100 iters), loss = 0.0129936
I0930 14:44:58.221782  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0129936 (* 1 = 0.0129936 loss)
I0930 14:44:58.221788  3537 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I0930 14:45:11.013881  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:45:11.557965  3537 solver.cpp:330] Iteration 88500, Testing net (#0)
I0930 14:45:14.661949  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:45:14.791196  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9133
I0930 14:45:14.791234  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.357571 (* 1 = 0.357571 loss)
I0930 14:45:14.925166  3537 solver.cpp:218] Iteration 88500 (5.98683 iter/s, 16.7033s/100 iters), loss = 0.00209449
I0930 14:45:14.925200  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0020945 (* 1 = 0.0020945 loss)
I0930 14:45:14.925207  3537 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I0930 14:45:28.370590  3537 solver.cpp:218] Iteration 88600 (7.43752 iter/s, 13.4453s/100 iters), loss = 0.00509712
I0930 14:45:28.370631  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00509712 (* 1 = 0.00509712 loss)
I0930 14:45:28.370637  3537 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I0930 14:45:41.833257  3537 solver.cpp:218] Iteration 88700 (7.42799 iter/s, 13.4626s/100 iters), loss = 0.00252771
I0930 14:45:41.833398  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00252772 (* 1 = 0.00252772 loss)
I0930 14:45:41.833406  3537 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I0930 14:45:55.279837  3537 solver.cpp:218] Iteration 88800 (7.43693 iter/s, 13.4464s/100 iters), loss = 0.00369729
I0930 14:45:55.279867  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00369729 (* 1 = 0.00369729 loss)
I0930 14:45:55.279873  3537 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I0930 14:46:08.730475  3537 solver.cpp:218] Iteration 88900 (7.43463 iter/s, 13.4506s/100 iters), loss = 0.00776883
I0930 14:46:08.730518  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00776884 (* 1 = 0.00776884 loss)
I0930 14:46:08.730527  3537 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I0930 14:46:21.514679  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:46:22.051204  3537 solver.cpp:330] Iteration 89000, Testing net (#0)
I0930 14:46:25.157593  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:46:25.286666  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9134
I0930 14:46:25.286702  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358446 (* 1 = 0.358446 loss)
I0930 14:46:25.419992  3537 solver.cpp:218] Iteration 89000 (5.99182 iter/s, 16.6894s/100 iters), loss = 0.00171731
I0930 14:46:25.420024  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00171732 (* 1 = 0.00171732 loss)
I0930 14:46:25.420032  3537 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I0930 14:46:38.869678  3537 solver.cpp:218] Iteration 89100 (7.43516 iter/s, 13.4496s/100 iters), loss = 0.00275939
I0930 14:46:38.869709  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0027594 (* 1 = 0.0027594 loss)
I0930 14:46:38.869715  3537 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I0930 14:46:52.309223  3537 solver.cpp:218] Iteration 89200 (7.44077 iter/s, 13.4395s/100 iters), loss = 0.00752941
I0930 14:46:52.309324  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00752942 (* 1 = 0.00752942 loss)
I0930 14:46:52.309340  3537 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I0930 14:47:05.768288  3537 solver.cpp:218] Iteration 89300 (7.43001 iter/s, 13.4589s/100 iters), loss = 0.00303858
I0930 14:47:05.768321  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00303859 (* 1 = 0.00303859 loss)
I0930 14:47:05.768326  3537 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I0930 14:47:19.226433  3537 solver.cpp:218] Iteration 89400 (7.43048 iter/s, 13.4581s/100 iters), loss = 0.00134119
I0930 14:47:19.226464  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0013412 (* 1 = 0.0013412 loss)
I0930 14:47:19.226471  3537 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I0930 14:47:32.008318  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:47:32.553975  3537 solver.cpp:330] Iteration 89500, Testing net (#0)
I0930 14:47:35.657076  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:47:35.786242  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9131
I0930 14:47:35.786276  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.359885 (* 1 = 0.359885 loss)
I0930 14:47:35.920140  3537 solver.cpp:218] Iteration 89500 (5.99031 iter/s, 16.6936s/100 iters), loss = 0.0029314
I0930 14:47:35.920173  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00293141 (* 1 = 0.00293141 loss)
I0930 14:47:35.920181  3537 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I0930 14:47:49.351649  3537 solver.cpp:218] Iteration 89600 (7.44522 iter/s, 13.4314s/100 iters), loss = 0.00292923
I0930 14:47:49.351680  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00292924 (* 1 = 0.00292924 loss)
I0930 14:47:49.351686  3537 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I0930 14:48:02.805372  3537 solver.cpp:218] Iteration 89700 (7.43293 iter/s, 13.4537s/100 iters), loss = 0.00278135
I0930 14:48:02.805480  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00278135 (* 1 = 0.00278135 loss)
I0930 14:48:02.805497  3537 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I0930 14:48:16.256131  3537 solver.cpp:218] Iteration 89800 (7.4346 iter/s, 13.4506s/100 iters), loss = 0.00498286
I0930 14:48:16.256161  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00498286 (* 1 = 0.00498286 loss)
I0930 14:48:16.256167  3537 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I0930 14:48:29.693801  3537 solver.cpp:218] Iteration 89900 (7.44181 iter/s, 13.4376s/100 iters), loss = 0.00145894
I0930 14:48:29.693832  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00145895 (* 1 = 0.00145895 loss)
I0930 14:48:29.693838  3537 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I0930 14:48:42.470350  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:48:43.005662  3537 solver.cpp:330] Iteration 90000, Testing net (#0)
I0930 14:48:46.115715  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:48:46.245254  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9134
I0930 14:48:46.245280  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358503 (* 1 = 0.358503 loss)
I0930 14:48:46.378181  3537 solver.cpp:218] Iteration 90000 (5.99366 iter/s, 16.6843s/100 iters), loss = 0.00122215
I0930 14:48:46.378211  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00122215 (* 1 = 0.00122215 loss)
I0930 14:48:46.378217  3537 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I0930 14:48:59.856300  3537 solver.cpp:218] Iteration 90100 (7.41947 iter/s, 13.4781s/100 iters), loss = 0.00341304
I0930 14:48:59.856331  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00341305 (* 1 = 0.00341305 loss)
I0930 14:48:59.856338  3537 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I0930 14:49:13.389389  3537 solver.cpp:218] Iteration 90200 (7.38934 iter/s, 13.533s/100 iters), loss = 0.00177451
I0930 14:49:13.389503  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00177452 (* 1 = 0.00177452 loss)
I0930 14:49:13.389514  3537 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I0930 14:49:26.941233  3537 solver.cpp:218] Iteration 90300 (7.37915 iter/s, 13.5517s/100 iters), loss = 0.00514063
I0930 14:49:26.941267  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00514064 (* 1 = 0.00514064 loss)
I0930 14:49:26.941277  3537 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I0930 14:49:40.393416  3537 solver.cpp:218] Iteration 90400 (7.43378 iter/s, 13.4521s/100 iters), loss = 0.00353532
I0930 14:49:40.393450  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00353533 (* 1 = 0.00353533 loss)
I0930 14:49:40.393458  3537 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I0930 14:49:53.183791  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:49:53.725718  3537 solver.cpp:330] Iteration 90500, Testing net (#0)
I0930 14:49:56.831658  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:49:56.961114  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9128
I0930 14:49:56.961141  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.36213 (* 1 = 0.36213 loss)
I0930 14:49:57.094841  3537 solver.cpp:218] Iteration 90500 (5.98754 iter/s, 16.7013s/100 iters), loss = 0.00535952
I0930 14:49:57.094877  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00535953 (* 1 = 0.00535953 loss)
I0930 14:49:57.094887  3537 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I0930 14:50:10.539578  3537 solver.cpp:218] Iteration 90600 (7.4379 iter/s, 13.4447s/100 iters), loss = 0.00763445
I0930 14:50:10.539611  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00763445 (* 1 = 0.00763445 loss)
I0930 14:50:10.539619  3537 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I0930 14:50:24.002737  3537 solver.cpp:218] Iteration 90700 (7.42772 iter/s, 13.4631s/100 iters), loss = 0.00543415
I0930 14:50:24.002853  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00543414 (* 1 = 0.00543414 loss)
I0930 14:50:24.002871  3537 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I0930 14:50:37.462841  3537 solver.cpp:218] Iteration 90800 (7.42944 iter/s, 13.46s/100 iters), loss = 0.00513603
I0930 14:50:37.462872  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00513602 (* 1 = 0.00513602 loss)
I0930 14:50:37.462879  3537 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I0930 14:50:50.925869  3537 solver.cpp:218] Iteration 90900 (7.42779 iter/s, 13.463s/100 iters), loss = 0.00288049
I0930 14:50:50.925904  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00288048 (* 1 = 0.00288048 loss)
I0930 14:50:50.925911  3537 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I0930 14:51:03.708708  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:51:04.245278  3537 solver.cpp:330] Iteration 91000, Testing net (#0)
I0930 14:51:07.353708  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:51:07.482650  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.914
I0930 14:51:07.482686  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.361758 (* 1 = 0.361758 loss)
I0930 14:51:07.615916  3537 solver.cpp:218] Iteration 91000 (5.99162 iter/s, 16.69s/100 iters), loss = 0.00236024
I0930 14:51:07.615950  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00236023 (* 1 = 0.00236023 loss)
I0930 14:51:07.615958  3537 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I0930 14:51:21.072136  3537 solver.cpp:218] Iteration 91100 (7.43155 iter/s, 13.4561s/100 iters), loss = 0.00309204
I0930 14:51:21.072168  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00309203 (* 1 = 0.00309203 loss)
I0930 14:51:21.072175  3537 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I0930 14:51:34.515857  3537 solver.cpp:218] Iteration 91200 (7.43846 iter/s, 13.4437s/100 iters), loss = 0.00484153
I0930 14:51:34.515960  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00484153 (* 1 = 0.00484153 loss)
I0930 14:51:34.515969  3537 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I0930 14:51:47.967190  3537 solver.cpp:218] Iteration 91300 (7.43428 iter/s, 13.4512s/100 iters), loss = 0.00808189
I0930 14:51:47.967231  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00808189 (* 1 = 0.00808189 loss)
I0930 14:51:47.967238  3537 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I0930 14:52:01.413378  3537 solver.cpp:218] Iteration 91400 (7.4371 iter/s, 13.4461s/100 iters), loss = 0.00443393
I0930 14:52:01.413408  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00443392 (* 1 = 0.00443392 loss)
I0930 14:52:01.413425  3537 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I0930 14:52:14.198170  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:52:14.739864  3537 solver.cpp:330] Iteration 91500, Testing net (#0)
I0930 14:52:17.843293  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:52:17.972254  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9136
I0930 14:52:17.972277  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.361659 (* 1 = 0.361659 loss)
I0930 14:52:18.106488  3537 solver.cpp:218] Iteration 91500 (5.99052 iter/s, 16.693s/100 iters), loss = 0.00207505
I0930 14:52:18.106518  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00207504 (* 1 = 0.00207504 loss)
I0930 14:52:18.106529  3537 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I0930 14:52:31.545599  3537 solver.cpp:218] Iteration 91600 (7.44101 iter/s, 13.439s/100 iters), loss = 0.00449519
I0930 14:52:31.545637  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00449518 (* 1 = 0.00449518 loss)
I0930 14:52:31.545645  3537 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I0930 14:52:45.005982  3537 solver.cpp:218] Iteration 91700 (7.42925 iter/s, 13.4603s/100 iters), loss = 0.00419645
I0930 14:52:45.006103  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00419644 (* 1 = 0.00419644 loss)
I0930 14:52:45.006120  3537 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I0930 14:52:58.455986  3537 solver.cpp:218] Iteration 91800 (7.43503 iter/s, 13.4499s/100 iters), loss = 0.00451121
I0930 14:52:58.456017  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00451119 (* 1 = 0.00451119 loss)
I0930 14:52:58.456022  3537 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I0930 14:53:11.911152  3537 solver.cpp:218] Iteration 91900 (7.43213 iter/s, 13.4551s/100 iters), loss = 0.0045247
I0930 14:53:11.911185  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00452469 (* 1 = 0.00452469 loss)
I0930 14:53:11.911191  3537 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I0930 14:53:24.680209  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:53:25.217346  3537 solver.cpp:330] Iteration 92000, Testing net (#0)
I0930 14:53:28.323503  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:53:28.452694  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9139
I0930 14:53:28.452730  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.359932 (* 1 = 0.359932 loss)
I0930 14:53:28.587232  3537 solver.cpp:218] Iteration 92000 (5.99664 iter/s, 16.676s/100 iters), loss = 0.00614064
I0930 14:53:28.587266  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00614063 (* 1 = 0.00614063 loss)
I0930 14:53:28.587275  3537 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I0930 14:53:42.044493  3537 solver.cpp:218] Iteration 92100 (7.43097 iter/s, 13.4572s/100 iters), loss = 0.00882878
I0930 14:53:42.044523  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00882877 (* 1 = 0.00882877 loss)
I0930 14:53:42.044529  3537 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I0930 14:53:55.488605  3537 solver.cpp:218] Iteration 92200 (7.43824 iter/s, 13.444s/100 iters), loss = 0.00385859
I0930 14:53:55.488734  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00385857 (* 1 = 0.00385857 loss)
I0930 14:53:55.488741  3537 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I0930 14:54:08.941052  3537 solver.cpp:218] Iteration 92300 (7.43368 iter/s, 13.4523s/100 iters), loss = 0.00306373
I0930 14:54:08.941084  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00306372 (* 1 = 0.00306372 loss)
I0930 14:54:08.941090  3537 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I0930 14:54:22.396247  3537 solver.cpp:218] Iteration 92400 (7.43211 iter/s, 13.4551s/100 iters), loss = 0.0018805
I0930 14:54:22.396278  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188049 (* 1 = 0.00188049 loss)
I0930 14:54:22.396294  3537 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I0930 14:54:35.190835  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:54:35.733450  3537 solver.cpp:330] Iteration 92500, Testing net (#0)
I0930 14:54:38.838923  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:54:38.968174  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9136
I0930 14:54:38.968200  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.360566 (* 1 = 0.360566 loss)
I0930 14:54:39.101498  3537 solver.cpp:218] Iteration 92500 (5.98617 iter/s, 16.7052s/100 iters), loss = 0.00661991
I0930 14:54:39.101531  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0066199 (* 1 = 0.0066199 loss)
I0930 14:54:39.101538  3537 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I0930 14:54:52.543377  3537 solver.cpp:218] Iteration 92600 (7.43948 iter/s, 13.4418s/100 iters), loss = 0.00250074
I0930 14:54:52.543412  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00250073 (* 1 = 0.00250073 loss)
I0930 14:54:52.543421  3537 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I0930 14:55:06.002075  3537 solver.cpp:218] Iteration 92700 (7.43018 iter/s, 13.4586s/100 iters), loss = 0.00236305
I0930 14:55:06.002179  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00236304 (* 1 = 0.00236304 loss)
I0930 14:55:06.002187  3537 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I0930 14:55:19.449218  3537 solver.cpp:218] Iteration 92800 (7.4366 iter/s, 13.447s/100 iters), loss = 0.0158269
I0930 14:55:19.449249  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0158269 (* 1 = 0.0158269 loss)
I0930 14:55:19.449255  3537 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I0930 14:55:32.910975  3537 solver.cpp:218] Iteration 92900 (7.42849 iter/s, 13.4617s/100 iters), loss = 0.00160094
I0930 14:55:32.911008  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00160093 (* 1 = 0.00160093 loss)
I0930 14:55:32.911017  3537 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I0930 14:55:45.689507  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:55:46.226837  3537 solver.cpp:330] Iteration 93000, Testing net (#0)
I0930 14:55:49.328385  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:55:49.457878  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.913
I0930 14:55:49.457903  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358646 (* 1 = 0.358646 loss)
I0930 14:55:49.591501  3537 solver.cpp:218] Iteration 93000 (5.99504 iter/s, 16.6804s/100 iters), loss = 0.0032519
I0930 14:55:49.591534  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00325189 (* 1 = 0.00325189 loss)
I0930 14:55:49.591542  3537 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I0930 14:56:03.053998  3537 solver.cpp:218] Iteration 93100 (7.42809 iter/s, 13.4624s/100 iters), loss = 0.00315927
I0930 14:56:03.054028  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00315926 (* 1 = 0.00315926 loss)
I0930 14:56:03.054035  3537 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I0930 14:56:16.510515  3537 solver.cpp:218] Iteration 93200 (7.43138 iter/s, 13.4564s/100 iters), loss = 0.0011683
I0930 14:56:16.510613  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00116829 (* 1 = 0.00116829 loss)
I0930 14:56:16.510632  3537 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I0930 14:56:29.967800  3537 solver.cpp:218] Iteration 93300 (7.431 iter/s, 13.4571s/100 iters), loss = 0.00104352
I0930 14:56:29.967840  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010435 (* 1 = 0.0010435 loss)
I0930 14:56:29.967847  3537 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I0930 14:56:43.420435  3537 solver.cpp:218] Iteration 93400 (7.43353 iter/s, 13.4526s/100 iters), loss = 0.00228685
I0930 14:56:43.420464  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00228684 (* 1 = 0.00228684 loss)
I0930 14:56:43.420470  3537 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I0930 14:56:56.218858  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:56:56.760195  3537 solver.cpp:330] Iteration 93500, Testing net (#0)
I0930 14:56:59.866767  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:56:59.995779  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9138
I0930 14:56:59.995803  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.359159 (* 1 = 0.359159 loss)
I0930 14:57:00.131019  3537 solver.cpp:218] Iteration 93500 (5.98426 iter/s, 16.7105s/100 iters), loss = 0.00226867
I0930 14:57:00.131052  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00226866 (* 1 = 0.00226866 loss)
I0930 14:57:00.131058  3537 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I0930 14:57:13.570893  3537 solver.cpp:218] Iteration 93600 (7.44059 iter/s, 13.4398s/100 iters), loss = 0.00523628
I0930 14:57:13.570924  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00523627 (* 1 = 0.00523627 loss)
I0930 14:57:13.570930  3537 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I0930 14:57:27.024915  3537 solver.cpp:218] Iteration 93700 (7.43276 iter/s, 13.454s/100 iters), loss = 0.0130602
I0930 14:57:27.025039  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130602 (* 1 = 0.0130602 loss)
I0930 14:57:27.025058  3537 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I0930 14:57:40.477129  3537 solver.cpp:218] Iteration 93800 (7.43381 iter/s, 13.4521s/100 iters), loss = 0.0207611
I0930 14:57:40.477160  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0207611 (* 1 = 0.0207611 loss)
I0930 14:57:40.477166  3537 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I0930 14:57:53.936151  3537 solver.cpp:218] Iteration 93900 (7.43 iter/s, 13.4589s/100 iters), loss = 0.00422764
I0930 14:57:53.936182  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00422762 (* 1 = 0.00422762 loss)
I0930 14:57:53.936189  3537 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I0930 14:58:06.726511  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:58:07.262554  3537 solver.cpp:330] Iteration 94000, Testing net (#0)
I0930 14:58:10.368806  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:58:10.498173  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9136
I0930 14:58:10.498208  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.359593 (* 1 = 0.359593 loss)
I0930 14:58:10.631901  3537 solver.cpp:218] Iteration 94000 (5.98958 iter/s, 16.6957s/100 iters), loss = 0.00179324
I0930 14:58:10.631933  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00179322 (* 1 = 0.00179322 loss)
I0930 14:58:10.631940  3537 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I0930 14:58:24.100208  3537 solver.cpp:218] Iteration 94100 (7.42488 iter/s, 13.4682s/100 iters), loss = 0.00184952
I0930 14:58:24.100237  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00184951 (* 1 = 0.00184951 loss)
I0930 14:58:24.100244  3537 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I0930 14:58:37.566226  3537 solver.cpp:218] Iteration 94200 (7.42614 iter/s, 13.4659s/100 iters), loss = 0.00304967
I0930 14:58:37.566344  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00304966 (* 1 = 0.00304966 loss)
I0930 14:58:37.566352  3537 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I0930 14:58:51.023712  3537 solver.cpp:218] Iteration 94300 (7.43089 iter/s, 13.4573s/100 iters), loss = 0.0100642
I0930 14:58:51.023746  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100642 (* 1 = 0.0100642 loss)
I0930 14:58:51.023751  3537 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I0930 14:59:04.477999  3537 solver.cpp:218] Iteration 94400 (7.43262 iter/s, 13.4542s/100 iters), loss = 0.00435654
I0930 14:59:04.478039  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00435652 (* 1 = 0.00435652 loss)
I0930 14:59:04.478045  3537 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I0930 14:59:17.282582  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:59:17.822974  3537 solver.cpp:330] Iteration 94500, Testing net (#0)
I0930 14:59:20.932287  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 14:59:21.061616  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9136
I0930 14:59:21.061652  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.362345 (* 1 = 0.362345 loss)
I0930 14:59:21.195945  3537 solver.cpp:218] Iteration 94500 (5.98163 iter/s, 16.7179s/100 iters), loss = 0.00219404
I0930 14:59:21.195983  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00219403 (* 1 = 0.00219403 loss)
I0930 14:59:21.195992  3537 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I0930 14:59:34.638248  3537 solver.cpp:218] Iteration 94600 (7.43924 iter/s, 13.4422s/100 iters), loss = 0.00429579
I0930 14:59:34.638281  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00429577 (* 1 = 0.00429577 loss)
I0930 14:59:34.638290  3537 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I0930 14:59:48.148825  3537 solver.cpp:218] Iteration 94700 (7.40165 iter/s, 13.5105s/100 iters), loss = 0.00857818
I0930 14:59:48.148974  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00857816 (* 1 = 0.00857816 loss)
I0930 14:59:48.149003  3537 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I0930 15:00:01.770475  3537 solver.cpp:218] Iteration 94800 (7.34137 iter/s, 13.6214s/100 iters), loss = 0.00486209
I0930 15:00:01.770512  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00486207 (* 1 = 0.00486207 loss)
I0930 15:00:01.770525  3537 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I0930 15:00:15.321357  3537 solver.cpp:218] Iteration 94900 (7.37964 iter/s, 13.5508s/100 iters), loss = 0.00203109
I0930 15:00:15.321389  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00203107 (* 1 = 0.00203107 loss)
I0930 15:00:15.321395  3537 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I0930 15:00:28.095639  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 15:00:28.632982  3537 solver.cpp:330] Iteration 95000, Testing net (#0)
I0930 15:00:31.738376  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 15:00:31.867748  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9133
I0930 15:00:31.867772  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.362808 (* 1 = 0.362808 loss)
I0930 15:00:32.000861  3537 solver.cpp:218] Iteration 95000 (5.99541 iter/s, 16.6794s/100 iters), loss = 0.00370817
I0930 15:00:32.000891  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00370815 (* 1 = 0.00370815 loss)
I0930 15:00:32.000898  3537 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I0930 15:00:45.469503  3537 solver.cpp:218] Iteration 95100 (7.42469 iter/s, 13.4686s/100 iters), loss = 0.00546783
I0930 15:00:45.469537  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00546782 (* 1 = 0.00546782 loss)
I0930 15:00:45.469544  3537 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I0930 15:00:58.925528  3537 solver.cpp:218] Iteration 95200 (7.43165 iter/s, 13.456s/100 iters), loss = 0.00876106
I0930 15:00:58.925667  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00876104 (* 1 = 0.00876104 loss)
I0930 15:00:58.925673  3537 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I0930 15:01:12.389729  3537 solver.cpp:218] Iteration 95300 (7.4272 iter/s, 13.464s/100 iters), loss = 0.00211472
I0930 15:01:12.389760  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0021147 (* 1 = 0.0021147 loss)
I0930 15:01:12.389776  3537 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I0930 15:01:25.840842  3537 solver.cpp:218] Iteration 95400 (7.43437 iter/s, 13.451s/100 iters), loss = 0.00119425
I0930 15:01:25.840873  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00119423 (* 1 = 0.00119423 loss)
I0930 15:01:25.840879  3537 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I0930 15:01:38.639609  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 15:01:39.177603  3537 solver.cpp:330] Iteration 95500, Testing net (#0)
I0930 15:01:42.286203  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 15:01:42.415457  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9137
I0930 15:01:42.415480  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364551 (* 1 = 0.364551 loss)
I0930 15:01:42.548923  3537 solver.cpp:218] Iteration 95500 (5.98516 iter/s, 16.708s/100 iters), loss = 0.00316543
I0930 15:01:42.548954  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00316542 (* 1 = 0.00316542 loss)
I0930 15:01:42.548960  3537 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I0930 15:01:56.006662  3537 solver.cpp:218] Iteration 95600 (7.43071 iter/s, 13.4577s/100 iters), loss = 0.00197011
I0930 15:01:56.006693  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0019701 (* 1 = 0.0019701 loss)
I0930 15:01:56.006700  3537 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I0930 15:02:09.465778  3537 solver.cpp:218] Iteration 95700 (7.42995 iter/s, 13.459s/100 iters), loss = 0.00434457
I0930 15:02:09.465924  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00434456 (* 1 = 0.00434456 loss)
I0930 15:02:09.465931  3537 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I0930 15:02:22.930649  3537 solver.cpp:218] Iteration 95800 (7.42683 iter/s, 13.4647s/100 iters), loss = 0.0108322
I0930 15:02:22.930690  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108322 (* 1 = 0.0108322 loss)
I0930 15:02:22.930696  3537 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I0930 15:02:36.401602  3537 solver.cpp:218] Iteration 95900 (7.42343 iter/s, 13.4709s/100 iters), loss = 0.00193823
I0930 15:02:36.401635  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00193822 (* 1 = 0.00193822 loss)
I0930 15:02:36.401654  3537 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I0930 15:02:49.191107  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 15:02:49.728785  3537 solver.cpp:330] Iteration 96000, Testing net (#0)
I0930 15:02:52.832484  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 15:02:52.961558  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9136
I0930 15:02:52.961593  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366841 (* 1 = 0.366841 loss)
I0930 15:02:53.095700  3537 solver.cpp:218] Iteration 96000 (5.99017 iter/s, 16.694s/100 iters), loss = 0.00191227
I0930 15:02:53.095731  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00191226 (* 1 = 0.00191226 loss)
I0930 15:02:53.095737  3537 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I0930 15:03:06.554553  3537 solver.cpp:218] Iteration 96100 (7.43009 iter/s, 13.4588s/100 iters), loss = 0.0161427
I0930 15:03:06.554594  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0161427 (* 1 = 0.0161427 loss)
I0930 15:03:06.554615  3537 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I0930 15:03:20.000514  3537 solver.cpp:218] Iteration 96200 (7.43722 iter/s, 13.4459s/100 iters), loss = 0.0177388
I0930 15:03:20.000623  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177387 (* 1 = 0.0177387 loss)
I0930 15:03:20.000632  3537 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I0930 15:03:33.463207  3537 solver.cpp:218] Iteration 96300 (7.42801 iter/s, 13.4626s/100 iters), loss = 0.00130566
I0930 15:03:33.463238  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00130564 (* 1 = 0.00130564 loss)
I0930 15:03:33.463244  3537 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I0930 15:03:46.912837  3537 solver.cpp:218] Iteration 96400 (7.43519 iter/s, 13.4496s/100 iters), loss = 0.00150062
I0930 15:03:46.912868  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0015006 (* 1 = 0.0015006 loss)
I0930 15:03:46.912873  3537 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I0930 15:03:59.709993  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 15:04:00.248438  3537 solver.cpp:330] Iteration 96500, Testing net (#0)
I0930 15:04:03.356784  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 15:04:03.485884  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9133
I0930 15:04:03.485919  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366609 (* 1 = 0.366609 loss)
I0930 15:04:03.618952  3537 solver.cpp:218] Iteration 96500 (5.98586 iter/s, 16.706s/100 iters), loss = 0.00141353
I0930 15:04:03.618985  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00141351 (* 1 = 0.00141351 loss)
I0930 15:04:03.618993  3537 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I0930 15:04:17.063611  3537 solver.cpp:218] Iteration 96600 (7.43794 iter/s, 13.4446s/100 iters), loss = 0.00466965
I0930 15:04:17.063640  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00466963 (* 1 = 0.00466963 loss)
I0930 15:04:17.063647  3537 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I0930 15:04:30.511152  3537 solver.cpp:218] Iteration 96700 (7.43634 iter/s, 13.4475s/100 iters), loss = 0.00523722
I0930 15:04:30.511330  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0052372 (* 1 = 0.0052372 loss)
I0930 15:04:30.511343  3537 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I0930 15:04:43.958165  3537 solver.cpp:218] Iteration 96800 (7.43671 iter/s, 13.4468s/100 iters), loss = 0.00726211
I0930 15:04:43.958195  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00726209 (* 1 = 0.00726209 loss)
I0930 15:04:43.958201  3537 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I0930 15:04:57.416872  3537 solver.cpp:218] Iteration 96900 (7.43017 iter/s, 13.4586s/100 iters), loss = 0.00291609
I0930 15:04:57.416903  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00291607 (* 1 = 0.00291607 loss)
I0930 15:04:57.416910  3537 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I0930 15:05:10.206816  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 15:05:10.744630  3537 solver.cpp:330] Iteration 97000, Testing net (#0)
I0930 15:05:13.851321  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 15:05:13.980303  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9135
I0930 15:05:13.980337  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.362674 (* 1 = 0.362674 loss)
I0930 15:05:14.114208  3537 solver.cpp:218] Iteration 97000 (5.98901 iter/s, 16.6973s/100 iters), loss = 0.00219296
I0930 15:05:14.114238  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00219293 (* 1 = 0.00219293 loss)
I0930 15:05:14.114244  3537 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I0930 15:05:27.572185  3537 solver.cpp:218] Iteration 97100 (7.43058 iter/s, 13.4579s/100 iters), loss = 0.00331124
I0930 15:05:27.572214  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00331121 (* 1 = 0.00331121 loss)
I0930 15:05:27.572221  3537 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I0930 15:05:41.036813  3537 solver.cpp:218] Iteration 97200 (7.4269 iter/s, 13.4646s/100 iters), loss = 0.00262477
I0930 15:05:41.036891  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00262475 (* 1 = 0.00262475 loss)
I0930 15:05:41.036908  3537 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I0930 15:05:54.505527  3537 solver.cpp:218] Iteration 97300 (7.42468 iter/s, 13.4686s/100 iters), loss = 0.0105266
I0930 15:05:54.505568  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105265 (* 1 = 0.0105265 loss)
I0930 15:05:54.505573  3537 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I0930 15:06:07.960283  3537 solver.cpp:218] Iteration 97400 (7.43236 iter/s, 13.4547s/100 iters), loss = 0.00690619
I0930 15:06:07.960325  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00690617 (* 1 = 0.00690617 loss)
I0930 15:06:07.960331  3537 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I0930 15:06:20.761430  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 15:06:21.300324  3537 solver.cpp:330] Iteration 97500, Testing net (#0)
I0930 15:06:24.405460  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 15:06:24.534471  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9136
I0930 15:06:24.534505  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364224 (* 1 = 0.364224 loss)
I0930 15:06:24.668120  3537 solver.cpp:218] Iteration 97500 (5.98525 iter/s, 16.7077s/100 iters), loss = 0.00610025
I0930 15:06:24.668154  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00610023 (* 1 = 0.00610023 loss)
I0930 15:06:24.668160  3537 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I0930 15:06:38.115802  3537 solver.cpp:218] Iteration 97600 (7.43627 iter/s, 13.4476s/100 iters), loss = 0.00556847
I0930 15:06:38.115831  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00556846 (* 1 = 0.00556846 loss)
I0930 15:06:38.115838  3537 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I0930 15:06:51.571267  3537 solver.cpp:218] Iteration 97700 (7.43196 iter/s, 13.4554s/100 iters), loss = 0.0231562
I0930 15:06:51.571442  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0231562 (* 1 = 0.0231562 loss)
I0930 15:06:51.571452  3537 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I0930 15:07:05.018474  3537 solver.cpp:218] Iteration 97800 (7.4366 iter/s, 13.447s/100 iters), loss = 0.00589701
I0930 15:07:05.018506  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00589699 (* 1 = 0.00589699 loss)
I0930 15:07:05.018512  3537 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I0930 15:07:18.482012  3537 solver.cpp:218] Iteration 97900 (7.42751 iter/s, 13.4635s/100 iters), loss = 0.00844614
I0930 15:07:18.482041  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00844612 (* 1 = 0.00844612 loss)
I0930 15:07:18.482048  3537 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I0930 15:07:31.264379  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 15:07:31.801074  3537 solver.cpp:330] Iteration 98000, Testing net (#0)
I0930 15:07:34.904834  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 15:07:35.033907  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9125
I0930 15:07:35.033941  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364579 (* 1 = 0.364579 loss)
I0930 15:07:35.168225  3537 solver.cpp:218] Iteration 98000 (5.993 iter/s, 16.6861s/100 iters), loss = 0.00199028
I0930 15:07:35.168269  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00199027 (* 1 = 0.00199027 loss)
I0930 15:07:35.168277  3537 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I0930 15:07:48.629595  3537 solver.cpp:218] Iteration 98100 (7.42877 iter/s, 13.4612s/100 iters), loss = 0.00266349
I0930 15:07:48.629626  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00266347 (* 1 = 0.00266347 loss)
I0930 15:07:48.629631  3537 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I0930 15:08:02.095564  3537 solver.cpp:218] Iteration 98200 (7.42617 iter/s, 13.4659s/100 iters), loss = 0.0118001
I0930 15:08:02.095666  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118001 (* 1 = 0.0118001 loss)
I0930 15:08:02.095674  3537 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I0930 15:08:15.564651  3537 solver.cpp:218] Iteration 98300 (7.42448 iter/s, 13.469s/100 iters), loss = 0.0149535
I0930 15:08:15.564682  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149535 (* 1 = 0.0149535 loss)
I0930 15:08:15.564687  3537 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I0930 15:08:29.016075  3537 solver.cpp:218] Iteration 98400 (7.4342 iter/s, 13.4514s/100 iters), loss = 0.00159734
I0930 15:08:29.016115  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00159731 (* 1 = 0.00159731 loss)
I0930 15:08:29.016121  3537 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I0930 15:08:41.817095  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 15:08:42.355939  3537 solver.cpp:330] Iteration 98500, Testing net (#0)
I0930 15:08:45.461686  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 15:08:45.591120  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9119
I0930 15:08:45.591154  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365442 (* 1 = 0.365442 loss)
I0930 15:08:45.724653  3537 solver.cpp:218] Iteration 98500 (5.98498 iter/s, 16.7085s/100 iters), loss = 0.00154371
I0930 15:08:45.724685  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154369 (* 1 = 0.00154369 loss)
I0930 15:08:45.724692  3537 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I0930 15:08:59.172828  3537 solver.cpp:218] Iteration 98600 (7.436 iter/s, 13.4481s/100 iters), loss = 0.00183519
I0930 15:08:59.172864  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00183517 (* 1 = 0.00183517 loss)
I0930 15:08:59.172873  3537 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I0930 15:09:12.626862  3537 solver.cpp:218] Iteration 98700 (7.43277 iter/s, 13.4539s/100 iters), loss = 0.00315489
I0930 15:09:12.627025  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00315487 (* 1 = 0.00315487 loss)
I0930 15:09:12.627034  3537 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I0930 15:09:26.074468  3537 solver.cpp:218] Iteration 98800 (7.43637 iter/s, 13.4474s/100 iters), loss = 0.00535752
I0930 15:09:26.074499  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0053575 (* 1 = 0.0053575 loss)
I0930 15:09:26.074515  3537 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I0930 15:09:39.533068  3537 solver.cpp:218] Iteration 98900 (7.43023 iter/s, 13.4585s/100 iters), loss = 0.0130748
I0930 15:09:39.533126  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130748 (* 1 = 0.0130748 loss)
I0930 15:09:39.533135  3537 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I0930 15:09:52.316668  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 15:09:52.853148  3537 solver.cpp:330] Iteration 99000, Testing net (#0)
I0930 15:09:55.955438  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 15:09:56.084463  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9127
I0930 15:09:56.084488  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364442 (* 1 = 0.364442 loss)
I0930 15:09:56.219303  3537 solver.cpp:218] Iteration 99000 (5.993 iter/s, 16.6861s/100 iters), loss = 0.00338051
I0930 15:09:56.219348  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00338049 (* 1 = 0.00338049 loss)
I0930 15:09:56.219357  3537 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I0930 15:10:09.671078  3537 solver.cpp:218] Iteration 99100 (7.43401 iter/s, 13.4517s/100 iters), loss = 0.00099312
I0930 15:10:09.671120  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000993103 (* 1 = 0.000993103 loss)
I0930 15:10:09.671128  3537 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I0930 15:10:23.135279  3537 solver.cpp:218] Iteration 99200 (7.42715 iter/s, 13.4641s/100 iters), loss = 0.000871742
I0930 15:10:23.135421  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000871729 (* 1 = 0.000871729 loss)
I0930 15:10:23.135428  3537 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I0930 15:10:36.608274  3537 solver.cpp:218] Iteration 99300 (7.42235 iter/s, 13.4728s/100 iters), loss = 0.00467752
I0930 15:10:36.608306  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0046775 (* 1 = 0.0046775 loss)
I0930 15:10:36.608314  3537 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I0930 15:10:50.058308  3537 solver.cpp:218] Iteration 99400 (7.43497 iter/s, 13.45s/100 iters), loss = 0.00868495
I0930 15:10:50.058337  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00868493 (* 1 = 0.00868493 loss)
I0930 15:10:50.058343  3537 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I0930 15:11:02.858330  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 15:11:03.395262  3537 solver.cpp:330] Iteration 99500, Testing net (#0)
I0930 15:11:06.502385  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 15:11:06.631255  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9129
I0930 15:11:06.631290  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366125 (* 1 = 0.366125 loss)
I0930 15:11:06.765913  3537 solver.cpp:218] Iteration 99500 (5.98533 iter/s, 16.7075s/100 iters), loss = 0.000792705
I0930 15:11:06.765944  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000792692 (* 1 = 0.000792692 loss)
I0930 15:11:06.765951  3537 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I0930 15:11:20.232815  3537 solver.cpp:218] Iteration 99600 (7.42565 iter/s, 13.4668s/100 iters), loss = 0.00513735
I0930 15:11:20.232852  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00513734 (* 1 = 0.00513734 loss)
I0930 15:11:20.232861  3537 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I0930 15:11:33.698660  3537 solver.cpp:218] Iteration 99700 (7.42626 iter/s, 13.4657s/100 iters), loss = 0.00901903
I0930 15:11:33.698796  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00901902 (* 1 = 0.00901902 loss)
I0930 15:11:33.698803  3537 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I0930 15:11:47.151155  3537 solver.cpp:218] Iteration 99800 (7.43365 iter/s, 13.4523s/100 iters), loss = 0.00562094
I0930 15:11:47.151185  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00562092 (* 1 = 0.00562092 loss)
I0930 15:11:47.151190  3537 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I0930 15:12:00.608692  3537 solver.cpp:218] Iteration 99900 (7.43082 iter/s, 13.4575s/100 iters), loss = 0.00274637
I0930 15:12:00.608724  3537 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00274635 (* 1 = 0.00274635 loss)
I0930 15:12:00.608731  3537 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I0930 15:12:13.399101  3545 data_layer.cpp:73] Restarting data prefetching from start.
I0930 15:12:13.934559  3537 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res56_elu_gauss_iter_100000.caffemodel
I0930 15:12:13.955139  3537 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res56_elu_gauss_iter_100000.solverstate
I0930 15:12:13.992905  3537 solver.cpp:310] Iteration 100000, loss = 0.00586061
I0930 15:12:13.992929  3537 solver.cpp:330] Iteration 100000, Testing net (#0)
I0930 15:12:17.098917  3546 data_layer.cpp:73] Restarting data prefetching from start.
I0930 15:12:17.229930  3537 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9129
I0930 15:12:17.229967  3537 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366836 (* 1 = 0.366836 loss)
I0930 15:12:17.229972  3537 solver.cpp:315] Optimization Done.
I0930 15:12:17.229984  3537 caffe.cpp:259] Optimization Done.
