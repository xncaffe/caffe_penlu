I1003 09:37:44.733188  7223 caffe.cpp:218] Using GPUs 0
I1003 09:37:44.756625  7223 caffe.cpp:223] GPU 0: GeForce GTX 1080
I1003 09:37:44.986835  7223 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res56_mpelu_alpha2_beta1_2study_nodecay_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_mpelu_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I1003 09:37:44.986970  7223 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_mpelu_train_test.prototxt
I1003 09:37:44.990767  7223 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_mpelu_train_test.prototxt
I1003 09:37:44.990782  7223 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1003 09:37:44.991008  7223 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I1003 09:37:44.991128  7223 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I1003 09:37:44.992193  7223 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU1"
  type: "M2PELU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU2"
  type: "M2PELU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU3"
  type: "M2PELU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU4"
  type: "M2PELU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU5"
  type: "M2PELU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU6"
  type: "M2PELU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU7"
  type: "M2PELU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU8"
  type: "M2PELU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU9"
  type: "M2PELU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU10"
  type: "M2PELU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU11"
  type: "M2PELU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU12"
  type: "M2PELU"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU13"
  type: "M2PELU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU14"
  type: "M2PELU"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU15"
  type: "M2PELU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU16"
  type: "M2PELU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU17"
  type: "M2PELU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU18"
  type: "M2PELU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU19"
  type: "M2PELU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU20"
  type: "M2PELU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU21"
  type: "M2PELU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU22"
  type: "M2PELU"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution24"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU23"
  type: "M2PELU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU24"
  type: "M2PELU"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
I1003 09:37:44.992919  7223 layer_factory.hpp:77] Creating layer Data1
I1003 09:37:44.993000  7223 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I1003 09:37:44.993021  7223 net.cpp:84] Creating Layer Data1
I1003 09:37:44.993026  7223 net.cpp:380] Data1 -> Data1
I1003 09:37:44.993044  7223 net.cpp:380] Data1 -> Data2
I1003 09:37:44.993052  7223 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1003 09:37:44.994518  7223 data_layer.cpp:45] output data size: 100,3,28,28
I1003 09:37:44.997054  7223 net.cpp:122] Setting up Data1
I1003 09:37:44.997076  7223 net.cpp:129] Top shape: 100 3 28 28 (235200)
I1003 09:37:44.997081  7223 net.cpp:129] Top shape: 100 (100)
I1003 09:37:44.997082  7223 net.cpp:137] Memory required for data: 941200
I1003 09:37:44.997087  7223 layer_factory.hpp:77] Creating layer Convolution1
I1003 09:37:44.997102  7223 net.cpp:84] Creating Layer Convolution1
I1003 09:37:44.997107  7223 net.cpp:406] Convolution1 <- Data1
I1003 09:37:44.997114  7223 net.cpp:380] Convolution1 -> Convolution1
I1003 09:37:45.144860  7223 net.cpp:122] Setting up Convolution1
I1003 09:37:45.144883  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.144886  7223 net.cpp:137] Memory required for data: 5958800
I1003 09:37:45.144912  7223 layer_factory.hpp:77] Creating layer BatchNorm1
I1003 09:37:45.144938  7223 net.cpp:84] Creating Layer BatchNorm1
I1003 09:37:45.144961  7223 net.cpp:406] BatchNorm1 <- Convolution1
I1003 09:37:45.144966  7223 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1003 09:37:45.145104  7223 net.cpp:122] Setting up BatchNorm1
I1003 09:37:45.145109  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.145112  7223 net.cpp:137] Memory required for data: 10976400
I1003 09:37:45.145130  7223 layer_factory.hpp:77] Creating layer Scale1
I1003 09:37:45.145139  7223 net.cpp:84] Creating Layer Scale1
I1003 09:37:45.145143  7223 net.cpp:406] Scale1 <- Convolution1
I1003 09:37:45.145146  7223 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1003 09:37:45.145196  7223 layer_factory.hpp:77] Creating layer Scale1
I1003 09:37:45.145311  7223 net.cpp:122] Setting up Scale1
I1003 09:37:45.145316  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.145318  7223 net.cpp:137] Memory required for data: 15994000
I1003 09:37:45.145323  7223 layer_factory.hpp:77] Creating layer M2PELU1
I1003 09:37:45.145334  7223 net.cpp:84] Creating Layer M2PELU1
I1003 09:37:45.145336  7223 net.cpp:406] M2PELU1 <- Convolution1
I1003 09:37:45.145341  7223 net.cpp:367] M2PELU1 -> Convolution1 (in-place)
I1003 09:37:45.145953  7223 net.cpp:122] Setting up M2PELU1
I1003 09:37:45.145964  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.145967  7223 net.cpp:137] Memory required for data: 21011600
I1003 09:37:45.145984  7223 layer_factory.hpp:77] Creating layer Convolution1_M2PELU1_0_split
I1003 09:37:45.145992  7223 net.cpp:84] Creating Layer Convolution1_M2PELU1_0_split
I1003 09:37:45.145994  7223 net.cpp:406] Convolution1_M2PELU1_0_split <- Convolution1
I1003 09:37:45.145998  7223 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_0
I1003 09:37:45.146003  7223 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_1
I1003 09:37:45.146028  7223 net.cpp:122] Setting up Convolution1_M2PELU1_0_split
I1003 09:37:45.146034  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.146037  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.146040  7223 net.cpp:137] Memory required for data: 31046800
I1003 09:37:45.146044  7223 layer_factory.hpp:77] Creating layer Convolution2
I1003 09:37:45.146050  7223 net.cpp:84] Creating Layer Convolution2
I1003 09:37:45.146054  7223 net.cpp:406] Convolution2 <- Convolution1_M2PELU1_0_split_0
I1003 09:37:45.146059  7223 net.cpp:380] Convolution2 -> Convolution2
I1003 09:37:45.146971  7223 net.cpp:122] Setting up Convolution2
I1003 09:37:45.146982  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.146986  7223 net.cpp:137] Memory required for data: 36064400
I1003 09:37:45.146991  7223 layer_factory.hpp:77] Creating layer BatchNorm2
I1003 09:37:45.146997  7223 net.cpp:84] Creating Layer BatchNorm2
I1003 09:37:45.147001  7223 net.cpp:406] BatchNorm2 <- Convolution2
I1003 09:37:45.147004  7223 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1003 09:37:45.147131  7223 net.cpp:122] Setting up BatchNorm2
I1003 09:37:45.147136  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.147140  7223 net.cpp:137] Memory required for data: 41082000
I1003 09:37:45.147145  7223 layer_factory.hpp:77] Creating layer Scale2
I1003 09:37:45.147150  7223 net.cpp:84] Creating Layer Scale2
I1003 09:37:45.147153  7223 net.cpp:406] Scale2 <- Convolution2
I1003 09:37:45.147156  7223 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1003 09:37:45.147186  7223 layer_factory.hpp:77] Creating layer Scale2
I1003 09:37:45.147270  7223 net.cpp:122] Setting up Scale2
I1003 09:37:45.147275  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.147279  7223 net.cpp:137] Memory required for data: 46099600
I1003 09:37:45.147294  7223 layer_factory.hpp:77] Creating layer M2PELU2
I1003 09:37:45.147298  7223 net.cpp:84] Creating Layer M2PELU2
I1003 09:37:45.147301  7223 net.cpp:406] M2PELU2 <- Convolution2
I1003 09:37:45.147305  7223 net.cpp:367] M2PELU2 -> Convolution2 (in-place)
I1003 09:37:45.147385  7223 net.cpp:122] Setting up M2PELU2
I1003 09:37:45.147398  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.147402  7223 net.cpp:137] Memory required for data: 51117200
I1003 09:37:45.147409  7223 layer_factory.hpp:77] Creating layer Convolution3
I1003 09:37:45.147418  7223 net.cpp:84] Creating Layer Convolution3
I1003 09:37:45.147420  7223 net.cpp:406] Convolution3 <- Convolution2
I1003 09:37:45.147424  7223 net.cpp:380] Convolution3 -> Convolution3
I1003 09:37:45.148316  7223 net.cpp:122] Setting up Convolution3
I1003 09:37:45.148326  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.148329  7223 net.cpp:137] Memory required for data: 56134800
I1003 09:37:45.148334  7223 layer_factory.hpp:77] Creating layer BatchNorm3
I1003 09:37:45.148339  7223 net.cpp:84] Creating Layer BatchNorm3
I1003 09:37:45.148342  7223 net.cpp:406] BatchNorm3 <- Convolution3
I1003 09:37:45.148347  7223 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1003 09:37:45.148473  7223 net.cpp:122] Setting up BatchNorm3
I1003 09:37:45.148478  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.148480  7223 net.cpp:137] Memory required for data: 61152400
I1003 09:37:45.148485  7223 layer_factory.hpp:77] Creating layer Scale3
I1003 09:37:45.148490  7223 net.cpp:84] Creating Layer Scale3
I1003 09:37:45.148494  7223 net.cpp:406] Scale3 <- Convolution3
I1003 09:37:45.148497  7223 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1003 09:37:45.148522  7223 layer_factory.hpp:77] Creating layer Scale3
I1003 09:37:45.148598  7223 net.cpp:122] Setting up Scale3
I1003 09:37:45.148604  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.148607  7223 net.cpp:137] Memory required for data: 66170000
I1003 09:37:45.148612  7223 layer_factory.hpp:77] Creating layer Eltwise1
I1003 09:37:45.148617  7223 net.cpp:84] Creating Layer Eltwise1
I1003 09:37:45.148619  7223 net.cpp:406] Eltwise1 <- Convolution1_M2PELU1_0_split_1
I1003 09:37:45.148622  7223 net.cpp:406] Eltwise1 <- Convolution3
I1003 09:37:45.148627  7223 net.cpp:380] Eltwise1 -> Eltwise1
I1003 09:37:45.148645  7223 net.cpp:122] Setting up Eltwise1
I1003 09:37:45.148650  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.148653  7223 net.cpp:137] Memory required for data: 71187600
I1003 09:37:45.148655  7223 layer_factory.hpp:77] Creating layer M2PELU3
I1003 09:37:45.148660  7223 net.cpp:84] Creating Layer M2PELU3
I1003 09:37:45.148663  7223 net.cpp:406] M2PELU3 <- Eltwise1
I1003 09:37:45.148668  7223 net.cpp:367] M2PELU3 -> Eltwise1 (in-place)
I1003 09:37:45.148749  7223 net.cpp:122] Setting up M2PELU3
I1003 09:37:45.148754  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.148757  7223 net.cpp:137] Memory required for data: 76205200
I1003 09:37:45.148761  7223 layer_factory.hpp:77] Creating layer Eltwise1_M2PELU3_0_split
I1003 09:37:45.148766  7223 net.cpp:84] Creating Layer Eltwise1_M2PELU3_0_split
I1003 09:37:45.148769  7223 net.cpp:406] Eltwise1_M2PELU3_0_split <- Eltwise1
I1003 09:37:45.148773  7223 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_0
I1003 09:37:45.148778  7223 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_1
I1003 09:37:45.148802  7223 net.cpp:122] Setting up Eltwise1_M2PELU3_0_split
I1003 09:37:45.148807  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.148809  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.148811  7223 net.cpp:137] Memory required for data: 86240400
I1003 09:37:45.148814  7223 layer_factory.hpp:77] Creating layer Convolution4
I1003 09:37:45.148821  7223 net.cpp:84] Creating Layer Convolution4
I1003 09:37:45.148824  7223 net.cpp:406] Convolution4 <- Eltwise1_M2PELU3_0_split_0
I1003 09:37:45.148830  7223 net.cpp:380] Convolution4 -> Convolution4
I1003 09:37:45.149709  7223 net.cpp:122] Setting up Convolution4
I1003 09:37:45.149718  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.149722  7223 net.cpp:137] Memory required for data: 91258000
I1003 09:37:45.149727  7223 layer_factory.hpp:77] Creating layer BatchNorm4
I1003 09:37:45.149739  7223 net.cpp:84] Creating Layer BatchNorm4
I1003 09:37:45.149744  7223 net.cpp:406] BatchNorm4 <- Convolution4
I1003 09:37:45.149747  7223 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1003 09:37:45.149873  7223 net.cpp:122] Setting up BatchNorm4
I1003 09:37:45.149878  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.149880  7223 net.cpp:137] Memory required for data: 96275600
I1003 09:37:45.149885  7223 layer_factory.hpp:77] Creating layer Scale4
I1003 09:37:45.149890  7223 net.cpp:84] Creating Layer Scale4
I1003 09:37:45.149893  7223 net.cpp:406] Scale4 <- Convolution4
I1003 09:37:45.149896  7223 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1003 09:37:45.149922  7223 layer_factory.hpp:77] Creating layer Scale4
I1003 09:37:45.149996  7223 net.cpp:122] Setting up Scale4
I1003 09:37:45.149999  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.150002  7223 net.cpp:137] Memory required for data: 101293200
I1003 09:37:45.150012  7223 layer_factory.hpp:77] Creating layer M2PELU4
I1003 09:37:45.150017  7223 net.cpp:84] Creating Layer M2PELU4
I1003 09:37:45.150020  7223 net.cpp:406] M2PELU4 <- Convolution4
I1003 09:37:45.150024  7223 net.cpp:367] M2PELU4 -> Convolution4 (in-place)
I1003 09:37:45.150104  7223 net.cpp:122] Setting up M2PELU4
I1003 09:37:45.150110  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.150112  7223 net.cpp:137] Memory required for data: 106310800
I1003 09:37:45.150116  7223 layer_factory.hpp:77] Creating layer Convolution5
I1003 09:37:45.150123  7223 net.cpp:84] Creating Layer Convolution5
I1003 09:37:45.150126  7223 net.cpp:406] Convolution5 <- Convolution4
I1003 09:37:45.150130  7223 net.cpp:380] Convolution5 -> Convolution5
I1003 09:37:45.151022  7223 net.cpp:122] Setting up Convolution5
I1003 09:37:45.151032  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.151036  7223 net.cpp:137] Memory required for data: 111328400
I1003 09:37:45.151041  7223 layer_factory.hpp:77] Creating layer BatchNorm5
I1003 09:37:45.151046  7223 net.cpp:84] Creating Layer BatchNorm5
I1003 09:37:45.151051  7223 net.cpp:406] BatchNorm5 <- Convolution5
I1003 09:37:45.151054  7223 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1003 09:37:45.151177  7223 net.cpp:122] Setting up BatchNorm5
I1003 09:37:45.151183  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.151186  7223 net.cpp:137] Memory required for data: 116346000
I1003 09:37:45.151191  7223 layer_factory.hpp:77] Creating layer Scale5
I1003 09:37:45.151196  7223 net.cpp:84] Creating Layer Scale5
I1003 09:37:45.151199  7223 net.cpp:406] Scale5 <- Convolution5
I1003 09:37:45.151202  7223 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1003 09:37:45.151229  7223 layer_factory.hpp:77] Creating layer Scale5
I1003 09:37:45.151304  7223 net.cpp:122] Setting up Scale5
I1003 09:37:45.151309  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.151311  7223 net.cpp:137] Memory required for data: 121363600
I1003 09:37:45.151315  7223 layer_factory.hpp:77] Creating layer Eltwise2
I1003 09:37:45.151321  7223 net.cpp:84] Creating Layer Eltwise2
I1003 09:37:45.151324  7223 net.cpp:406] Eltwise2 <- Eltwise1_M2PELU3_0_split_1
I1003 09:37:45.151327  7223 net.cpp:406] Eltwise2 <- Convolution5
I1003 09:37:45.151331  7223 net.cpp:380] Eltwise2 -> Eltwise2
I1003 09:37:45.151346  7223 net.cpp:122] Setting up Eltwise2
I1003 09:37:45.151351  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.151355  7223 net.cpp:137] Memory required for data: 126381200
I1003 09:37:45.151356  7223 layer_factory.hpp:77] Creating layer M2PELU5
I1003 09:37:45.151362  7223 net.cpp:84] Creating Layer M2PELU5
I1003 09:37:45.151365  7223 net.cpp:406] M2PELU5 <- Eltwise2
I1003 09:37:45.151368  7223 net.cpp:367] M2PELU5 -> Eltwise2 (in-place)
I1003 09:37:45.151450  7223 net.cpp:122] Setting up M2PELU5
I1003 09:37:45.151455  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.151458  7223 net.cpp:137] Memory required for data: 131398800
I1003 09:37:45.151463  7223 layer_factory.hpp:77] Creating layer Eltwise2_M2PELU5_0_split
I1003 09:37:45.151474  7223 net.cpp:84] Creating Layer Eltwise2_M2PELU5_0_split
I1003 09:37:45.151477  7223 net.cpp:406] Eltwise2_M2PELU5_0_split <- Eltwise2
I1003 09:37:45.151481  7223 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_0
I1003 09:37:45.151485  7223 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_1
I1003 09:37:45.151510  7223 net.cpp:122] Setting up Eltwise2_M2PELU5_0_split
I1003 09:37:45.151515  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.151518  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.151521  7223 net.cpp:137] Memory required for data: 141434000
I1003 09:37:45.151523  7223 layer_factory.hpp:77] Creating layer Convolution6
I1003 09:37:45.151530  7223 net.cpp:84] Creating Layer Convolution6
I1003 09:37:45.151533  7223 net.cpp:406] Convolution6 <- Eltwise2_M2PELU5_0_split_0
I1003 09:37:45.151537  7223 net.cpp:380] Convolution6 -> Convolution6
I1003 09:37:45.152426  7223 net.cpp:122] Setting up Convolution6
I1003 09:37:45.152436  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.152438  7223 net.cpp:137] Memory required for data: 146451600
I1003 09:37:45.152443  7223 layer_factory.hpp:77] Creating layer BatchNorm6
I1003 09:37:45.152449  7223 net.cpp:84] Creating Layer BatchNorm6
I1003 09:37:45.152452  7223 net.cpp:406] BatchNorm6 <- Convolution6
I1003 09:37:45.152456  7223 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1003 09:37:45.152590  7223 net.cpp:122] Setting up BatchNorm6
I1003 09:37:45.152595  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.152597  7223 net.cpp:137] Memory required for data: 151469200
I1003 09:37:45.152602  7223 layer_factory.hpp:77] Creating layer Scale6
I1003 09:37:45.152607  7223 net.cpp:84] Creating Layer Scale6
I1003 09:37:45.152611  7223 net.cpp:406] Scale6 <- Convolution6
I1003 09:37:45.152614  7223 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1003 09:37:45.152639  7223 layer_factory.hpp:77] Creating layer Scale6
I1003 09:37:45.152719  7223 net.cpp:122] Setting up Scale6
I1003 09:37:45.152724  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.152726  7223 net.cpp:137] Memory required for data: 156486800
I1003 09:37:45.152730  7223 layer_factory.hpp:77] Creating layer M2PELU6
I1003 09:37:45.152735  7223 net.cpp:84] Creating Layer M2PELU6
I1003 09:37:45.152739  7223 net.cpp:406] M2PELU6 <- Convolution6
I1003 09:37:45.152743  7223 net.cpp:367] M2PELU6 -> Convolution6 (in-place)
I1003 09:37:45.152827  7223 net.cpp:122] Setting up M2PELU6
I1003 09:37:45.152832  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.152835  7223 net.cpp:137] Memory required for data: 161504400
I1003 09:37:45.152838  7223 layer_factory.hpp:77] Creating layer Convolution7
I1003 09:37:45.152846  7223 net.cpp:84] Creating Layer Convolution7
I1003 09:37:45.152849  7223 net.cpp:406] Convolution7 <- Convolution6
I1003 09:37:45.152853  7223 net.cpp:380] Convolution7 -> Convolution7
I1003 09:37:45.153409  7223 net.cpp:122] Setting up Convolution7
I1003 09:37:45.153417  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.153420  7223 net.cpp:137] Memory required for data: 166522000
I1003 09:37:45.153425  7223 layer_factory.hpp:77] Creating layer BatchNorm7
I1003 09:37:45.153430  7223 net.cpp:84] Creating Layer BatchNorm7
I1003 09:37:45.153434  7223 net.cpp:406] BatchNorm7 <- Convolution7
I1003 09:37:45.153439  7223 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1003 09:37:45.153566  7223 net.cpp:122] Setting up BatchNorm7
I1003 09:37:45.153573  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.153574  7223 net.cpp:137] Memory required for data: 171539600
I1003 09:37:45.153579  7223 layer_factory.hpp:77] Creating layer Scale7
I1003 09:37:45.153586  7223 net.cpp:84] Creating Layer Scale7
I1003 09:37:45.153590  7223 net.cpp:406] Scale7 <- Convolution7
I1003 09:37:45.153594  7223 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1003 09:37:45.153620  7223 layer_factory.hpp:77] Creating layer Scale7
I1003 09:37:45.153707  7223 net.cpp:122] Setting up Scale7
I1003 09:37:45.153712  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.153715  7223 net.cpp:137] Memory required for data: 176557200
I1003 09:37:45.153719  7223 layer_factory.hpp:77] Creating layer Eltwise3
I1003 09:37:45.153724  7223 net.cpp:84] Creating Layer Eltwise3
I1003 09:37:45.153728  7223 net.cpp:406] Eltwise3 <- Eltwise2_M2PELU5_0_split_1
I1003 09:37:45.153730  7223 net.cpp:406] Eltwise3 <- Convolution7
I1003 09:37:45.153735  7223 net.cpp:380] Eltwise3 -> Eltwise3
I1003 09:37:45.153750  7223 net.cpp:122] Setting up Eltwise3
I1003 09:37:45.153755  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.153759  7223 net.cpp:137] Memory required for data: 181574800
I1003 09:37:45.153760  7223 layer_factory.hpp:77] Creating layer M2PELU7
I1003 09:37:45.153765  7223 net.cpp:84] Creating Layer M2PELU7
I1003 09:37:45.153769  7223 net.cpp:406] M2PELU7 <- Eltwise3
I1003 09:37:45.153772  7223 net.cpp:367] M2PELU7 -> Eltwise3 (in-place)
I1003 09:37:45.153856  7223 net.cpp:122] Setting up M2PELU7
I1003 09:37:45.153861  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.153863  7223 net.cpp:137] Memory required for data: 186592400
I1003 09:37:45.153867  7223 layer_factory.hpp:77] Creating layer Eltwise3_M2PELU7_0_split
I1003 09:37:45.153872  7223 net.cpp:84] Creating Layer Eltwise3_M2PELU7_0_split
I1003 09:37:45.153877  7223 net.cpp:406] Eltwise3_M2PELU7_0_split <- Eltwise3
I1003 09:37:45.153879  7223 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_0
I1003 09:37:45.153884  7223 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_1
I1003 09:37:45.153906  7223 net.cpp:122] Setting up Eltwise3_M2PELU7_0_split
I1003 09:37:45.153911  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.153915  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.153918  7223 net.cpp:137] Memory required for data: 196627600
I1003 09:37:45.153920  7223 layer_factory.hpp:77] Creating layer Convolution8
I1003 09:37:45.153926  7223 net.cpp:84] Creating Layer Convolution8
I1003 09:37:45.153929  7223 net.cpp:406] Convolution8 <- Eltwise3_M2PELU7_0_split_0
I1003 09:37:45.153934  7223 net.cpp:380] Convolution8 -> Convolution8
I1003 09:37:45.154821  7223 net.cpp:122] Setting up Convolution8
I1003 09:37:45.154831  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.154834  7223 net.cpp:137] Memory required for data: 201645200
I1003 09:37:45.154845  7223 layer_factory.hpp:77] Creating layer BatchNorm8
I1003 09:37:45.154851  7223 net.cpp:84] Creating Layer BatchNorm8
I1003 09:37:45.154865  7223 net.cpp:406] BatchNorm8 <- Convolution8
I1003 09:37:45.154880  7223 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1003 09:37:45.155016  7223 net.cpp:122] Setting up BatchNorm8
I1003 09:37:45.155021  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.155025  7223 net.cpp:137] Memory required for data: 206662800
I1003 09:37:45.155040  7223 layer_factory.hpp:77] Creating layer Scale8
I1003 09:37:45.155045  7223 net.cpp:84] Creating Layer Scale8
I1003 09:37:45.155057  7223 net.cpp:406] Scale8 <- Convolution8
I1003 09:37:45.155062  7223 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1003 09:37:45.155115  7223 layer_factory.hpp:77] Creating layer Scale8
I1003 09:37:45.155210  7223 net.cpp:122] Setting up Scale8
I1003 09:37:45.155215  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.155217  7223 net.cpp:137] Memory required for data: 211680400
I1003 09:37:45.155231  7223 layer_factory.hpp:77] Creating layer M2PELU8
I1003 09:37:45.155236  7223 net.cpp:84] Creating Layer M2PELU8
I1003 09:37:45.155239  7223 net.cpp:406] M2PELU8 <- Convolution8
I1003 09:37:45.155243  7223 net.cpp:367] M2PELU8 -> Convolution8 (in-place)
I1003 09:37:45.155326  7223 net.cpp:122] Setting up M2PELU8
I1003 09:37:45.155331  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.155334  7223 net.cpp:137] Memory required for data: 216698000
I1003 09:37:45.155345  7223 layer_factory.hpp:77] Creating layer Convolution9
I1003 09:37:45.155354  7223 net.cpp:84] Creating Layer Convolution9
I1003 09:37:45.155356  7223 net.cpp:406] Convolution9 <- Convolution8
I1003 09:37:45.155360  7223 net.cpp:380] Convolution9 -> Convolution9
I1003 09:37:45.156297  7223 net.cpp:122] Setting up Convolution9
I1003 09:37:45.156308  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.156311  7223 net.cpp:137] Memory required for data: 221715600
I1003 09:37:45.156316  7223 layer_factory.hpp:77] Creating layer BatchNorm9
I1003 09:37:45.156322  7223 net.cpp:84] Creating Layer BatchNorm9
I1003 09:37:45.156327  7223 net.cpp:406] BatchNorm9 <- Convolution9
I1003 09:37:45.156332  7223 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1003 09:37:45.156481  7223 net.cpp:122] Setting up BatchNorm9
I1003 09:37:45.156493  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.156497  7223 net.cpp:137] Memory required for data: 226733200
I1003 09:37:45.156502  7223 layer_factory.hpp:77] Creating layer Scale9
I1003 09:37:45.156507  7223 net.cpp:84] Creating Layer Scale9
I1003 09:37:45.156514  7223 net.cpp:406] Scale9 <- Convolution9
I1003 09:37:45.156518  7223 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1003 09:37:45.156549  7223 layer_factory.hpp:77] Creating layer Scale9
I1003 09:37:45.156631  7223 net.cpp:122] Setting up Scale9
I1003 09:37:45.156637  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.156639  7223 net.cpp:137] Memory required for data: 231750800
I1003 09:37:45.156643  7223 layer_factory.hpp:77] Creating layer Eltwise4
I1003 09:37:45.156649  7223 net.cpp:84] Creating Layer Eltwise4
I1003 09:37:45.156653  7223 net.cpp:406] Eltwise4 <- Eltwise3_M2PELU7_0_split_1
I1003 09:37:45.156656  7223 net.cpp:406] Eltwise4 <- Convolution9
I1003 09:37:45.156659  7223 net.cpp:380] Eltwise4 -> Eltwise4
I1003 09:37:45.156677  7223 net.cpp:122] Setting up Eltwise4
I1003 09:37:45.156682  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.156693  7223 net.cpp:137] Memory required for data: 236768400
I1003 09:37:45.156697  7223 layer_factory.hpp:77] Creating layer M2PELU9
I1003 09:37:45.156713  7223 net.cpp:84] Creating Layer M2PELU9
I1003 09:37:45.156716  7223 net.cpp:406] M2PELU9 <- Eltwise4
I1003 09:37:45.156719  7223 net.cpp:367] M2PELU9 -> Eltwise4 (in-place)
I1003 09:37:45.156812  7223 net.cpp:122] Setting up M2PELU9
I1003 09:37:45.156817  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.156821  7223 net.cpp:137] Memory required for data: 241786000
I1003 09:37:45.156836  7223 layer_factory.hpp:77] Creating layer Eltwise4_M2PELU9_0_split
I1003 09:37:45.156839  7223 net.cpp:84] Creating Layer Eltwise4_M2PELU9_0_split
I1003 09:37:45.156842  7223 net.cpp:406] Eltwise4_M2PELU9_0_split <- Eltwise4
I1003 09:37:45.156847  7223 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_0
I1003 09:37:45.156852  7223 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_1
I1003 09:37:45.156875  7223 net.cpp:122] Setting up Eltwise4_M2PELU9_0_split
I1003 09:37:45.156880  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.156884  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.156888  7223 net.cpp:137] Memory required for data: 251821200
I1003 09:37:45.156889  7223 layer_factory.hpp:77] Creating layer Convolution10
I1003 09:37:45.156895  7223 net.cpp:84] Creating Layer Convolution10
I1003 09:37:45.156898  7223 net.cpp:406] Convolution10 <- Eltwise4_M2PELU9_0_split_0
I1003 09:37:45.156903  7223 net.cpp:380] Convolution10 -> Convolution10
I1003 09:37:45.157804  7223 net.cpp:122] Setting up Convolution10
I1003 09:37:45.157814  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.157817  7223 net.cpp:137] Memory required for data: 256838800
I1003 09:37:45.157822  7223 layer_factory.hpp:77] Creating layer BatchNorm10
I1003 09:37:45.157827  7223 net.cpp:84] Creating Layer BatchNorm10
I1003 09:37:45.157831  7223 net.cpp:406] BatchNorm10 <- Convolution10
I1003 09:37:45.157843  7223 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1003 09:37:45.157975  7223 net.cpp:122] Setting up BatchNorm10
I1003 09:37:45.157980  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.157984  7223 net.cpp:137] Memory required for data: 261856400
I1003 09:37:45.157989  7223 layer_factory.hpp:77] Creating layer Scale10
I1003 09:37:45.157994  7223 net.cpp:84] Creating Layer Scale10
I1003 09:37:45.157996  7223 net.cpp:406] Scale10 <- Convolution10
I1003 09:37:45.158000  7223 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1003 09:37:45.158026  7223 layer_factory.hpp:77] Creating layer Scale10
I1003 09:37:45.158103  7223 net.cpp:122] Setting up Scale10
I1003 09:37:45.158108  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.158112  7223 net.cpp:137] Memory required for data: 266874000
I1003 09:37:45.158115  7223 layer_factory.hpp:77] Creating layer M2PELU10
I1003 09:37:45.158121  7223 net.cpp:84] Creating Layer M2PELU10
I1003 09:37:45.158124  7223 net.cpp:406] M2PELU10 <- Convolution10
I1003 09:37:45.158128  7223 net.cpp:367] M2PELU10 -> Convolution10 (in-place)
I1003 09:37:45.158213  7223 net.cpp:122] Setting up M2PELU10
I1003 09:37:45.158218  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.158221  7223 net.cpp:137] Memory required for data: 271891600
I1003 09:37:45.158226  7223 layer_factory.hpp:77] Creating layer Convolution11
I1003 09:37:45.158233  7223 net.cpp:84] Creating Layer Convolution11
I1003 09:37:45.158236  7223 net.cpp:406] Convolution11 <- Convolution10
I1003 09:37:45.158241  7223 net.cpp:380] Convolution11 -> Convolution11
I1003 09:37:45.159147  7223 net.cpp:122] Setting up Convolution11
I1003 09:37:45.159157  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.159168  7223 net.cpp:137] Memory required for data: 276909200
I1003 09:37:45.159173  7223 layer_factory.hpp:77] Creating layer BatchNorm11
I1003 09:37:45.159179  7223 net.cpp:84] Creating Layer BatchNorm11
I1003 09:37:45.159183  7223 net.cpp:406] BatchNorm11 <- Convolution11
I1003 09:37:45.159188  7223 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1003 09:37:45.159327  7223 net.cpp:122] Setting up BatchNorm11
I1003 09:37:45.159332  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.159344  7223 net.cpp:137] Memory required for data: 281926800
I1003 09:37:45.159349  7223 layer_factory.hpp:77] Creating layer Scale11
I1003 09:37:45.159354  7223 net.cpp:84] Creating Layer Scale11
I1003 09:37:45.159358  7223 net.cpp:406] Scale11 <- Convolution11
I1003 09:37:45.159360  7223 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1003 09:37:45.159396  7223 layer_factory.hpp:77] Creating layer Scale11
I1003 09:37:45.159493  7223 net.cpp:122] Setting up Scale11
I1003 09:37:45.159498  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.159500  7223 net.cpp:137] Memory required for data: 286944400
I1003 09:37:45.159513  7223 layer_factory.hpp:77] Creating layer Eltwise5
I1003 09:37:45.159518  7223 net.cpp:84] Creating Layer Eltwise5
I1003 09:37:45.159521  7223 net.cpp:406] Eltwise5 <- Eltwise4_M2PELU9_0_split_1
I1003 09:37:45.159525  7223 net.cpp:406] Eltwise5 <- Convolution11
I1003 09:37:45.159530  7223 net.cpp:380] Eltwise5 -> Eltwise5
I1003 09:37:45.159546  7223 net.cpp:122] Setting up Eltwise5
I1003 09:37:45.159550  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.159554  7223 net.cpp:137] Memory required for data: 291962000
I1003 09:37:45.159555  7223 layer_factory.hpp:77] Creating layer M2PELU11
I1003 09:37:45.159561  7223 net.cpp:84] Creating Layer M2PELU11
I1003 09:37:45.159564  7223 net.cpp:406] M2PELU11 <- Eltwise5
I1003 09:37:45.159567  7223 net.cpp:367] M2PELU11 -> Eltwise5 (in-place)
I1003 09:37:45.159653  7223 net.cpp:122] Setting up M2PELU11
I1003 09:37:45.159658  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.159662  7223 net.cpp:137] Memory required for data: 296979600
I1003 09:37:45.159665  7223 layer_factory.hpp:77] Creating layer Eltwise5_M2PELU11_0_split
I1003 09:37:45.159669  7223 net.cpp:84] Creating Layer Eltwise5_M2PELU11_0_split
I1003 09:37:45.159680  7223 net.cpp:406] Eltwise5_M2PELU11_0_split <- Eltwise5
I1003 09:37:45.159685  7223 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_0
I1003 09:37:45.159690  7223 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_1
I1003 09:37:45.159715  7223 net.cpp:122] Setting up Eltwise5_M2PELU11_0_split
I1003 09:37:45.159719  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.159723  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.159726  7223 net.cpp:137] Memory required for data: 307014800
I1003 09:37:45.159729  7223 layer_factory.hpp:77] Creating layer Convolution12
I1003 09:37:45.159735  7223 net.cpp:84] Creating Layer Convolution12
I1003 09:37:45.159739  7223 net.cpp:406] Convolution12 <- Eltwise5_M2PELU11_0_split_0
I1003 09:37:45.159744  7223 net.cpp:380] Convolution12 -> Convolution12
I1003 09:37:45.160645  7223 net.cpp:122] Setting up Convolution12
I1003 09:37:45.160655  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.160660  7223 net.cpp:137] Memory required for data: 312032400
I1003 09:37:45.160663  7223 layer_factory.hpp:77] Creating layer BatchNorm12
I1003 09:37:45.160668  7223 net.cpp:84] Creating Layer BatchNorm12
I1003 09:37:45.160672  7223 net.cpp:406] BatchNorm12 <- Convolution12
I1003 09:37:45.160677  7223 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1003 09:37:45.160815  7223 net.cpp:122] Setting up BatchNorm12
I1003 09:37:45.160820  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.160822  7223 net.cpp:137] Memory required for data: 317050000
I1003 09:37:45.160827  7223 layer_factory.hpp:77] Creating layer Scale12
I1003 09:37:45.160832  7223 net.cpp:84] Creating Layer Scale12
I1003 09:37:45.160835  7223 net.cpp:406] Scale12 <- Convolution12
I1003 09:37:45.160840  7223 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1003 09:37:45.160866  7223 layer_factory.hpp:77] Creating layer Scale12
I1003 09:37:45.160948  7223 net.cpp:122] Setting up Scale12
I1003 09:37:45.160953  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.160955  7223 net.cpp:137] Memory required for data: 322067600
I1003 09:37:45.160959  7223 layer_factory.hpp:77] Creating layer M2PELU12
I1003 09:37:45.160964  7223 net.cpp:84] Creating Layer M2PELU12
I1003 09:37:45.160967  7223 net.cpp:406] M2PELU12 <- Convolution12
I1003 09:37:45.160972  7223 net.cpp:367] M2PELU12 -> Convolution12 (in-place)
I1003 09:37:45.161058  7223 net.cpp:122] Setting up M2PELU12
I1003 09:37:45.161063  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.161067  7223 net.cpp:137] Memory required for data: 327085200
I1003 09:37:45.161070  7223 layer_factory.hpp:77] Creating layer Convolution13
I1003 09:37:45.161078  7223 net.cpp:84] Creating Layer Convolution13
I1003 09:37:45.161082  7223 net.cpp:406] Convolution13 <- Convolution12
I1003 09:37:45.161085  7223 net.cpp:380] Convolution13 -> Convolution13
I1003 09:37:45.161988  7223 net.cpp:122] Setting up Convolution13
I1003 09:37:45.161998  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.162001  7223 net.cpp:137] Memory required for data: 332102800
I1003 09:37:45.162006  7223 layer_factory.hpp:77] Creating layer BatchNorm13
I1003 09:37:45.162012  7223 net.cpp:84] Creating Layer BatchNorm13
I1003 09:37:45.162015  7223 net.cpp:406] BatchNorm13 <- Convolution13
I1003 09:37:45.162021  7223 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1003 09:37:45.162154  7223 net.cpp:122] Setting up BatchNorm13
I1003 09:37:45.162160  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.162163  7223 net.cpp:137] Memory required for data: 337120400
I1003 09:37:45.162168  7223 layer_factory.hpp:77] Creating layer Scale13
I1003 09:37:45.162173  7223 net.cpp:84] Creating Layer Scale13
I1003 09:37:45.162176  7223 net.cpp:406] Scale13 <- Convolution13
I1003 09:37:45.162180  7223 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1003 09:37:45.162207  7223 layer_factory.hpp:77] Creating layer Scale13
I1003 09:37:45.162297  7223 net.cpp:122] Setting up Scale13
I1003 09:37:45.162303  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.162307  7223 net.cpp:137] Memory required for data: 342138000
I1003 09:37:45.162310  7223 layer_factory.hpp:77] Creating layer Eltwise6
I1003 09:37:45.162314  7223 net.cpp:84] Creating Layer Eltwise6
I1003 09:37:45.162318  7223 net.cpp:406] Eltwise6 <- Eltwise5_M2PELU11_0_split_1
I1003 09:37:45.162322  7223 net.cpp:406] Eltwise6 <- Convolution13
I1003 09:37:45.162326  7223 net.cpp:380] Eltwise6 -> Eltwise6
I1003 09:37:45.162345  7223 net.cpp:122] Setting up Eltwise6
I1003 09:37:45.162350  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.162353  7223 net.cpp:137] Memory required for data: 347155600
I1003 09:37:45.162355  7223 layer_factory.hpp:77] Creating layer M2PELU13
I1003 09:37:45.162364  7223 net.cpp:84] Creating Layer M2PELU13
I1003 09:37:45.162367  7223 net.cpp:406] M2PELU13 <- Eltwise6
I1003 09:37:45.162372  7223 net.cpp:367] M2PELU13 -> Eltwise6 (in-place)
I1003 09:37:45.162461  7223 net.cpp:122] Setting up M2PELU13
I1003 09:37:45.162466  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.162468  7223 net.cpp:137] Memory required for data: 352173200
I1003 09:37:45.162472  7223 layer_factory.hpp:77] Creating layer Eltwise6_M2PELU13_0_split
I1003 09:37:45.162477  7223 net.cpp:84] Creating Layer Eltwise6_M2PELU13_0_split
I1003 09:37:45.162480  7223 net.cpp:406] Eltwise6_M2PELU13_0_split <- Eltwise6
I1003 09:37:45.162484  7223 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_0
I1003 09:37:45.162489  7223 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_1
I1003 09:37:45.162513  7223 net.cpp:122] Setting up Eltwise6_M2PELU13_0_split
I1003 09:37:45.162518  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.162528  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.162530  7223 net.cpp:137] Memory required for data: 362208400
I1003 09:37:45.162533  7223 layer_factory.hpp:77] Creating layer Convolution14
I1003 09:37:45.162539  7223 net.cpp:84] Creating Layer Convolution14
I1003 09:37:45.162540  7223 net.cpp:406] Convolution14 <- Eltwise6_M2PELU13_0_split_0
I1003 09:37:45.162546  7223 net.cpp:380] Convolution14 -> Convolution14
I1003 09:37:45.163450  7223 net.cpp:122] Setting up Convolution14
I1003 09:37:45.163458  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.163461  7223 net.cpp:137] Memory required for data: 367226000
I1003 09:37:45.163465  7223 layer_factory.hpp:77] Creating layer BatchNorm14
I1003 09:37:45.163473  7223 net.cpp:84] Creating Layer BatchNorm14
I1003 09:37:45.163476  7223 net.cpp:406] BatchNorm14 <- Convolution14
I1003 09:37:45.163480  7223 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1003 09:37:45.163615  7223 net.cpp:122] Setting up BatchNorm14
I1003 09:37:45.163620  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.163622  7223 net.cpp:137] Memory required for data: 372243600
I1003 09:37:45.163628  7223 layer_factory.hpp:77] Creating layer Scale14
I1003 09:37:45.163632  7223 net.cpp:84] Creating Layer Scale14
I1003 09:37:45.163635  7223 net.cpp:406] Scale14 <- Convolution14
I1003 09:37:45.163638  7223 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1003 09:37:45.163664  7223 layer_factory.hpp:77] Creating layer Scale14
I1003 09:37:45.163743  7223 net.cpp:122] Setting up Scale14
I1003 09:37:45.163748  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.163750  7223 net.cpp:137] Memory required for data: 377261200
I1003 09:37:45.163754  7223 layer_factory.hpp:77] Creating layer M2PELU14
I1003 09:37:45.163760  7223 net.cpp:84] Creating Layer M2PELU14
I1003 09:37:45.163763  7223 net.cpp:406] M2PELU14 <- Convolution14
I1003 09:37:45.163766  7223 net.cpp:367] M2PELU14 -> Convolution14 (in-place)
I1003 09:37:45.163852  7223 net.cpp:122] Setting up M2PELU14
I1003 09:37:45.163856  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.163858  7223 net.cpp:137] Memory required for data: 382278800
I1003 09:37:45.163869  7223 layer_factory.hpp:77] Creating layer Convolution15
I1003 09:37:45.163877  7223 net.cpp:84] Creating Layer Convolution15
I1003 09:37:45.163879  7223 net.cpp:406] Convolution15 <- Convolution14
I1003 09:37:45.163883  7223 net.cpp:380] Convolution15 -> Convolution15
I1003 09:37:45.164793  7223 net.cpp:122] Setting up Convolution15
I1003 09:37:45.164803  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.164804  7223 net.cpp:137] Memory required for data: 387296400
I1003 09:37:45.164809  7223 layer_factory.hpp:77] Creating layer BatchNorm15
I1003 09:37:45.164813  7223 net.cpp:84] Creating Layer BatchNorm15
I1003 09:37:45.164816  7223 net.cpp:406] BatchNorm15 <- Convolution15
I1003 09:37:45.164821  7223 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1003 09:37:45.164958  7223 net.cpp:122] Setting up BatchNorm15
I1003 09:37:45.164961  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.164963  7223 net.cpp:137] Memory required for data: 392314000
I1003 09:37:45.164978  7223 layer_factory.hpp:77] Creating layer Scale15
I1003 09:37:45.164984  7223 net.cpp:84] Creating Layer Scale15
I1003 09:37:45.164986  7223 net.cpp:406] Scale15 <- Convolution15
I1003 09:37:45.164989  7223 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1003 09:37:45.165017  7223 layer_factory.hpp:77] Creating layer Scale15
I1003 09:37:45.165097  7223 net.cpp:122] Setting up Scale15
I1003 09:37:45.165102  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.165103  7223 net.cpp:137] Memory required for data: 397331600
I1003 09:37:45.165107  7223 layer_factory.hpp:77] Creating layer Eltwise7
I1003 09:37:45.165112  7223 net.cpp:84] Creating Layer Eltwise7
I1003 09:37:45.165114  7223 net.cpp:406] Eltwise7 <- Eltwise6_M2PELU13_0_split_1
I1003 09:37:45.165117  7223 net.cpp:406] Eltwise7 <- Convolution15
I1003 09:37:45.165120  7223 net.cpp:380] Eltwise7 -> Eltwise7
I1003 09:37:45.165138  7223 net.cpp:122] Setting up Eltwise7
I1003 09:37:45.165141  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.165143  7223 net.cpp:137] Memory required for data: 402349200
I1003 09:37:45.165145  7223 layer_factory.hpp:77] Creating layer M2PELU15
I1003 09:37:45.165151  7223 net.cpp:84] Creating Layer M2PELU15
I1003 09:37:45.165153  7223 net.cpp:406] M2PELU15 <- Eltwise7
I1003 09:37:45.165156  7223 net.cpp:367] M2PELU15 -> Eltwise7 (in-place)
I1003 09:37:45.165243  7223 net.cpp:122] Setting up M2PELU15
I1003 09:37:45.165247  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.165249  7223 net.cpp:137] Memory required for data: 407366800
I1003 09:37:45.165253  7223 layer_factory.hpp:77] Creating layer Eltwise7_M2PELU15_0_split
I1003 09:37:45.165256  7223 net.cpp:84] Creating Layer Eltwise7_M2PELU15_0_split
I1003 09:37:45.165259  7223 net.cpp:406] Eltwise7_M2PELU15_0_split <- Eltwise7
I1003 09:37:45.165262  7223 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_0
I1003 09:37:45.165267  7223 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_1
I1003 09:37:45.165289  7223 net.cpp:122] Setting up Eltwise7_M2PELU15_0_split
I1003 09:37:45.165293  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.165297  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.165298  7223 net.cpp:137] Memory required for data: 417402000
I1003 09:37:45.165300  7223 layer_factory.hpp:77] Creating layer Convolution16
I1003 09:37:45.165307  7223 net.cpp:84] Creating Layer Convolution16
I1003 09:37:45.165309  7223 net.cpp:406] Convolution16 <- Eltwise7_M2PELU15_0_split_0
I1003 09:37:45.165313  7223 net.cpp:380] Convolution16 -> Convolution16
I1003 09:37:45.166214  7223 net.cpp:122] Setting up Convolution16
I1003 09:37:45.166223  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.166225  7223 net.cpp:137] Memory required for data: 422419600
I1003 09:37:45.166230  7223 layer_factory.hpp:77] Creating layer BatchNorm16
I1003 09:37:45.166235  7223 net.cpp:84] Creating Layer BatchNorm16
I1003 09:37:45.166239  7223 net.cpp:406] BatchNorm16 <- Convolution16
I1003 09:37:45.166250  7223 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1003 09:37:45.166386  7223 net.cpp:122] Setting up BatchNorm16
I1003 09:37:45.166390  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.166393  7223 net.cpp:137] Memory required for data: 427437200
I1003 09:37:45.166398  7223 layer_factory.hpp:77] Creating layer Scale16
I1003 09:37:45.166402  7223 net.cpp:84] Creating Layer Scale16
I1003 09:37:45.166405  7223 net.cpp:406] Scale16 <- Convolution16
I1003 09:37:45.166409  7223 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1003 09:37:45.166435  7223 layer_factory.hpp:77] Creating layer Scale16
I1003 09:37:45.166512  7223 net.cpp:122] Setting up Scale16
I1003 09:37:45.166517  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.166519  7223 net.cpp:137] Memory required for data: 432454800
I1003 09:37:45.166529  7223 layer_factory.hpp:77] Creating layer M2PELU16
I1003 09:37:45.166535  7223 net.cpp:84] Creating Layer M2PELU16
I1003 09:37:45.166538  7223 net.cpp:406] M2PELU16 <- Convolution16
I1003 09:37:45.166543  7223 net.cpp:367] M2PELU16 -> Convolution16 (in-place)
I1003 09:37:45.166627  7223 net.cpp:122] Setting up M2PELU16
I1003 09:37:45.166633  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.166635  7223 net.cpp:137] Memory required for data: 437472400
I1003 09:37:45.166640  7223 layer_factory.hpp:77] Creating layer Convolution17
I1003 09:37:45.166646  7223 net.cpp:84] Creating Layer Convolution17
I1003 09:37:45.166647  7223 net.cpp:406] Convolution17 <- Convolution16
I1003 09:37:45.166652  7223 net.cpp:380] Convolution17 -> Convolution17
I1003 09:37:45.167227  7223 net.cpp:122] Setting up Convolution17
I1003 09:37:45.167234  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.167237  7223 net.cpp:137] Memory required for data: 442490000
I1003 09:37:45.167242  7223 layer_factory.hpp:77] Creating layer BatchNorm17
I1003 09:37:45.167246  7223 net.cpp:84] Creating Layer BatchNorm17
I1003 09:37:45.167249  7223 net.cpp:406] BatchNorm17 <- Convolution17
I1003 09:37:45.167253  7223 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1003 09:37:45.167388  7223 net.cpp:122] Setting up BatchNorm17
I1003 09:37:45.167393  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.167395  7223 net.cpp:137] Memory required for data: 447507600
I1003 09:37:45.167400  7223 layer_factory.hpp:77] Creating layer Scale17
I1003 09:37:45.167407  7223 net.cpp:84] Creating Layer Scale17
I1003 09:37:45.167408  7223 net.cpp:406] Scale17 <- Convolution17
I1003 09:37:45.167412  7223 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1003 09:37:45.167438  7223 layer_factory.hpp:77] Creating layer Scale17
I1003 09:37:45.167516  7223 net.cpp:122] Setting up Scale17
I1003 09:37:45.167520  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.167522  7223 net.cpp:137] Memory required for data: 452525200
I1003 09:37:45.167526  7223 layer_factory.hpp:77] Creating layer Eltwise8
I1003 09:37:45.167531  7223 net.cpp:84] Creating Layer Eltwise8
I1003 09:37:45.167534  7223 net.cpp:406] Eltwise8 <- Eltwise7_M2PELU15_0_split_1
I1003 09:37:45.167536  7223 net.cpp:406] Eltwise8 <- Convolution17
I1003 09:37:45.167541  7223 net.cpp:380] Eltwise8 -> Eltwise8
I1003 09:37:45.167556  7223 net.cpp:122] Setting up Eltwise8
I1003 09:37:45.167559  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.167562  7223 net.cpp:137] Memory required for data: 457542800
I1003 09:37:45.167563  7223 layer_factory.hpp:77] Creating layer M2PELU17
I1003 09:37:45.167568  7223 net.cpp:84] Creating Layer M2PELU17
I1003 09:37:45.167572  7223 net.cpp:406] M2PELU17 <- Eltwise8
I1003 09:37:45.167574  7223 net.cpp:367] M2PELU17 -> Eltwise8 (in-place)
I1003 09:37:45.167662  7223 net.cpp:122] Setting up M2PELU17
I1003 09:37:45.167666  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.167668  7223 net.cpp:137] Memory required for data: 462560400
I1003 09:37:45.167672  7223 layer_factory.hpp:77] Creating layer Eltwise8_M2PELU17_0_split
I1003 09:37:45.167682  7223 net.cpp:84] Creating Layer Eltwise8_M2PELU17_0_split
I1003 09:37:45.167685  7223 net.cpp:406] Eltwise8_M2PELU17_0_split <- Eltwise8
I1003 09:37:45.167690  7223 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_0
I1003 09:37:45.167693  7223 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_1
I1003 09:37:45.167717  7223 net.cpp:122] Setting up Eltwise8_M2PELU17_0_split
I1003 09:37:45.167721  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.167724  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.167726  7223 net.cpp:137] Memory required for data: 472595600
I1003 09:37:45.167729  7223 layer_factory.hpp:77] Creating layer Convolution18
I1003 09:37:45.167734  7223 net.cpp:84] Creating Layer Convolution18
I1003 09:37:45.167737  7223 net.cpp:406] Convolution18 <- Eltwise8_M2PELU17_0_split_0
I1003 09:37:45.167742  7223 net.cpp:380] Convolution18 -> Convolution18
I1003 09:37:45.168645  7223 net.cpp:122] Setting up Convolution18
I1003 09:37:45.168655  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.168658  7223 net.cpp:137] Memory required for data: 477613200
I1003 09:37:45.168663  7223 layer_factory.hpp:77] Creating layer BatchNorm18
I1003 09:37:45.168666  7223 net.cpp:84] Creating Layer BatchNorm18
I1003 09:37:45.168669  7223 net.cpp:406] BatchNorm18 <- Convolution18
I1003 09:37:45.168673  7223 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1003 09:37:45.168809  7223 net.cpp:122] Setting up BatchNorm18
I1003 09:37:45.168813  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.168815  7223 net.cpp:137] Memory required for data: 482630800
I1003 09:37:45.168820  7223 layer_factory.hpp:77] Creating layer Scale18
I1003 09:37:45.168825  7223 net.cpp:84] Creating Layer Scale18
I1003 09:37:45.168828  7223 net.cpp:406] Scale18 <- Convolution18
I1003 09:37:45.168830  7223 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1003 09:37:45.168857  7223 layer_factory.hpp:77] Creating layer Scale18
I1003 09:37:45.168938  7223 net.cpp:122] Setting up Scale18
I1003 09:37:45.168942  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.168946  7223 net.cpp:137] Memory required for data: 487648400
I1003 09:37:45.168948  7223 layer_factory.hpp:77] Creating layer M2PELU18
I1003 09:37:45.168953  7223 net.cpp:84] Creating Layer M2PELU18
I1003 09:37:45.168956  7223 net.cpp:406] M2PELU18 <- Convolution18
I1003 09:37:45.168959  7223 net.cpp:367] M2PELU18 -> Convolution18 (in-place)
I1003 09:37:45.169047  7223 net.cpp:122] Setting up M2PELU18
I1003 09:37:45.169051  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.169054  7223 net.cpp:137] Memory required for data: 492666000
I1003 09:37:45.169057  7223 layer_factory.hpp:77] Creating layer Convolution19
I1003 09:37:45.169066  7223 net.cpp:84] Creating Layer Convolution19
I1003 09:37:45.169068  7223 net.cpp:406] Convolution19 <- Convolution18
I1003 09:37:45.169072  7223 net.cpp:380] Convolution19 -> Convolution19
I1003 09:37:45.169982  7223 net.cpp:122] Setting up Convolution19
I1003 09:37:45.169991  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.169994  7223 net.cpp:137] Memory required for data: 497683600
I1003 09:37:45.169998  7223 layer_factory.hpp:77] Creating layer BatchNorm19
I1003 09:37:45.170004  7223 net.cpp:84] Creating Layer BatchNorm19
I1003 09:37:45.170007  7223 net.cpp:406] BatchNorm19 <- Convolution19
I1003 09:37:45.170011  7223 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1003 09:37:45.170145  7223 net.cpp:122] Setting up BatchNorm19
I1003 09:37:45.170150  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.170152  7223 net.cpp:137] Memory required for data: 502701200
I1003 09:37:45.170157  7223 layer_factory.hpp:77] Creating layer Scale19
I1003 09:37:45.170161  7223 net.cpp:84] Creating Layer Scale19
I1003 09:37:45.170164  7223 net.cpp:406] Scale19 <- Convolution19
I1003 09:37:45.170167  7223 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1003 09:37:45.170202  7223 layer_factory.hpp:77] Creating layer Scale19
I1003 09:37:45.170281  7223 net.cpp:122] Setting up Scale19
I1003 09:37:45.170286  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.170289  7223 net.cpp:137] Memory required for data: 507718800
I1003 09:37:45.170292  7223 layer_factory.hpp:77] Creating layer Eltwise9
I1003 09:37:45.170296  7223 net.cpp:84] Creating Layer Eltwise9
I1003 09:37:45.170298  7223 net.cpp:406] Eltwise9 <- Eltwise8_M2PELU17_0_split_1
I1003 09:37:45.170301  7223 net.cpp:406] Eltwise9 <- Convolution19
I1003 09:37:45.170305  7223 net.cpp:380] Eltwise9 -> Eltwise9
I1003 09:37:45.170321  7223 net.cpp:122] Setting up Eltwise9
I1003 09:37:45.170325  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.170326  7223 net.cpp:137] Memory required for data: 512736400
I1003 09:37:45.170330  7223 layer_factory.hpp:77] Creating layer M2PELU19
I1003 09:37:45.170336  7223 net.cpp:84] Creating Layer M2PELU19
I1003 09:37:45.170338  7223 net.cpp:406] M2PELU19 <- Eltwise9
I1003 09:37:45.170341  7223 net.cpp:367] M2PELU19 -> Eltwise9 (in-place)
I1003 09:37:45.170428  7223 net.cpp:122] Setting up M2PELU19
I1003 09:37:45.170433  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.170434  7223 net.cpp:137] Memory required for data: 517754000
I1003 09:37:45.170439  7223 layer_factory.hpp:77] Creating layer Eltwise9_M2PELU19_0_split
I1003 09:37:45.170441  7223 net.cpp:84] Creating Layer Eltwise9_M2PELU19_0_split
I1003 09:37:45.170444  7223 net.cpp:406] Eltwise9_M2PELU19_0_split <- Eltwise9
I1003 09:37:45.170449  7223 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_0
I1003 09:37:45.170452  7223 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_1
I1003 09:37:45.170475  7223 net.cpp:122] Setting up Eltwise9_M2PELU19_0_split
I1003 09:37:45.170480  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.170482  7223 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1003 09:37:45.170485  7223 net.cpp:137] Memory required for data: 527789200
I1003 09:37:45.170486  7223 layer_factory.hpp:77] Creating layer Convolution20
I1003 09:37:45.170493  7223 net.cpp:84] Creating Layer Convolution20
I1003 09:37:45.170496  7223 net.cpp:406] Convolution20 <- Eltwise9_M2PELU19_0_split_0
I1003 09:37:45.170500  7223 net.cpp:380] Convolution20 -> Convolution20
I1003 09:37:45.171717  7223 net.cpp:122] Setting up Convolution20
I1003 09:37:45.171725  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.171728  7223 net.cpp:137] Memory required for data: 530298000
I1003 09:37:45.171733  7223 layer_factory.hpp:77] Creating layer BatchNorm20
I1003 09:37:45.171738  7223 net.cpp:84] Creating Layer BatchNorm20
I1003 09:37:45.171741  7223 net.cpp:406] BatchNorm20 <- Convolution20
I1003 09:37:45.171746  7223 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1003 09:37:45.171890  7223 net.cpp:122] Setting up BatchNorm20
I1003 09:37:45.171895  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.171896  7223 net.cpp:137] Memory required for data: 532806800
I1003 09:37:45.171901  7223 layer_factory.hpp:77] Creating layer Scale20
I1003 09:37:45.171905  7223 net.cpp:84] Creating Layer Scale20
I1003 09:37:45.171907  7223 net.cpp:406] Scale20 <- Convolution20
I1003 09:37:45.171911  7223 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1003 09:37:45.171938  7223 layer_factory.hpp:77] Creating layer Scale20
I1003 09:37:45.172029  7223 net.cpp:122] Setting up Scale20
I1003 09:37:45.172036  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.172039  7223 net.cpp:137] Memory required for data: 535315600
I1003 09:37:45.172042  7223 layer_factory.hpp:77] Creating layer Convolution21
I1003 09:37:45.172049  7223 net.cpp:84] Creating Layer Convolution21
I1003 09:37:45.172052  7223 net.cpp:406] Convolution21 <- Eltwise9_M2PELU19_0_split_1
I1003 09:37:45.172057  7223 net.cpp:380] Convolution21 -> Convolution21
I1003 09:37:45.173738  7223 net.cpp:122] Setting up Convolution21
I1003 09:37:45.173746  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.173756  7223 net.cpp:137] Memory required for data: 537824400
I1003 09:37:45.173761  7223 layer_factory.hpp:77] Creating layer BatchNorm21
I1003 09:37:45.173766  7223 net.cpp:84] Creating Layer BatchNorm21
I1003 09:37:45.173769  7223 net.cpp:406] BatchNorm21 <- Convolution21
I1003 09:37:45.173774  7223 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1003 09:37:45.173913  7223 net.cpp:122] Setting up BatchNorm21
I1003 09:37:45.173918  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.173919  7223 net.cpp:137] Memory required for data: 540333200
I1003 09:37:45.173924  7223 layer_factory.hpp:77] Creating layer Scale21
I1003 09:37:45.173928  7223 net.cpp:84] Creating Layer Scale21
I1003 09:37:45.173930  7223 net.cpp:406] Scale21 <- Convolution21
I1003 09:37:45.173933  7223 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1003 09:37:45.173961  7223 layer_factory.hpp:77] Creating layer Scale21
I1003 09:37:45.174038  7223 net.cpp:122] Setting up Scale21
I1003 09:37:45.174042  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.174044  7223 net.cpp:137] Memory required for data: 542842000
I1003 09:37:45.174048  7223 layer_factory.hpp:77] Creating layer M2PELU20
I1003 09:37:45.174053  7223 net.cpp:84] Creating Layer M2PELU20
I1003 09:37:45.174055  7223 net.cpp:406] M2PELU20 <- Convolution21
I1003 09:37:45.174059  7223 net.cpp:367] M2PELU20 -> Convolution21 (in-place)
I1003 09:37:45.174144  7223 net.cpp:122] Setting up M2PELU20
I1003 09:37:45.174149  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.174150  7223 net.cpp:137] Memory required for data: 545350800
I1003 09:37:45.174154  7223 layer_factory.hpp:77] Creating layer Convolution22
I1003 09:37:45.174161  7223 net.cpp:84] Creating Layer Convolution22
I1003 09:37:45.174165  7223 net.cpp:406] Convolution22 <- Convolution21
I1003 09:37:45.174167  7223 net.cpp:380] Convolution22 -> Convolution22
I1003 09:37:45.175247  7223 net.cpp:122] Setting up Convolution22
I1003 09:37:45.175256  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.175258  7223 net.cpp:137] Memory required for data: 547859600
I1003 09:37:45.175262  7223 layer_factory.hpp:77] Creating layer BatchNorm22
I1003 09:37:45.175268  7223 net.cpp:84] Creating Layer BatchNorm22
I1003 09:37:45.175271  7223 net.cpp:406] BatchNorm22 <- Convolution22
I1003 09:37:45.175274  7223 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1003 09:37:45.175407  7223 net.cpp:122] Setting up BatchNorm22
I1003 09:37:45.175411  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.175413  7223 net.cpp:137] Memory required for data: 550368400
I1003 09:37:45.175418  7223 layer_factory.hpp:77] Creating layer Scale22
I1003 09:37:45.175423  7223 net.cpp:84] Creating Layer Scale22
I1003 09:37:45.175426  7223 net.cpp:406] Scale22 <- Convolution22
I1003 09:37:45.175428  7223 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1003 09:37:45.175456  7223 layer_factory.hpp:77] Creating layer Scale22
I1003 09:37:45.175529  7223 net.cpp:122] Setting up Scale22
I1003 09:37:45.175534  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.175536  7223 net.cpp:137] Memory required for data: 552877200
I1003 09:37:45.175540  7223 layer_factory.hpp:77] Creating layer Eltwise10
I1003 09:37:45.175544  7223 net.cpp:84] Creating Layer Eltwise10
I1003 09:37:45.175547  7223 net.cpp:406] Eltwise10 <- Convolution20
I1003 09:37:45.175549  7223 net.cpp:406] Eltwise10 <- Convolution22
I1003 09:37:45.175554  7223 net.cpp:380] Eltwise10 -> Eltwise10
I1003 09:37:45.175570  7223 net.cpp:122] Setting up Eltwise10
I1003 09:37:45.175573  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.175575  7223 net.cpp:137] Memory required for data: 555386000
I1003 09:37:45.175577  7223 layer_factory.hpp:77] Creating layer M2PELU21
I1003 09:37:45.175582  7223 net.cpp:84] Creating Layer M2PELU21
I1003 09:37:45.175585  7223 net.cpp:406] M2PELU21 <- Eltwise10
I1003 09:37:45.175587  7223 net.cpp:367] M2PELU21 -> Eltwise10 (in-place)
I1003 09:37:45.175669  7223 net.cpp:122] Setting up M2PELU21
I1003 09:37:45.175680  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.175683  7223 net.cpp:137] Memory required for data: 557894800
I1003 09:37:45.175686  7223 layer_factory.hpp:77] Creating layer Eltwise10_M2PELU21_0_split
I1003 09:37:45.175690  7223 net.cpp:84] Creating Layer Eltwise10_M2PELU21_0_split
I1003 09:37:45.175693  7223 net.cpp:406] Eltwise10_M2PELU21_0_split <- Eltwise10
I1003 09:37:45.175696  7223 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_0
I1003 09:37:45.175701  7223 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_1
I1003 09:37:45.175724  7223 net.cpp:122] Setting up Eltwise10_M2PELU21_0_split
I1003 09:37:45.175729  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.175730  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.175732  7223 net.cpp:137] Memory required for data: 562912400
I1003 09:37:45.175735  7223 layer_factory.hpp:77] Creating layer Convolution23
I1003 09:37:45.175740  7223 net.cpp:84] Creating Layer Convolution23
I1003 09:37:45.175743  7223 net.cpp:406] Convolution23 <- Eltwise10_M2PELU21_0_split_0
I1003 09:37:45.175747  7223 net.cpp:380] Convolution23 -> Convolution23
I1003 09:37:45.177069  7223 net.cpp:122] Setting up Convolution23
I1003 09:37:45.177078  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.177080  7223 net.cpp:137] Memory required for data: 565421200
I1003 09:37:45.177084  7223 layer_factory.hpp:77] Creating layer BatchNorm23
I1003 09:37:45.177090  7223 net.cpp:84] Creating Layer BatchNorm23
I1003 09:37:45.177093  7223 net.cpp:406] BatchNorm23 <- Convolution23
I1003 09:37:45.177098  7223 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1003 09:37:45.177232  7223 net.cpp:122] Setting up BatchNorm23
I1003 09:37:45.177237  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.177238  7223 net.cpp:137] Memory required for data: 567930000
I1003 09:37:45.177242  7223 layer_factory.hpp:77] Creating layer Scale23
I1003 09:37:45.177248  7223 net.cpp:84] Creating Layer Scale23
I1003 09:37:45.177249  7223 net.cpp:406] Scale23 <- Convolution23
I1003 09:37:45.177253  7223 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1003 09:37:45.177278  7223 layer_factory.hpp:77] Creating layer Scale23
I1003 09:37:45.177356  7223 net.cpp:122] Setting up Scale23
I1003 09:37:45.177361  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.177362  7223 net.cpp:137] Memory required for data: 570438800
I1003 09:37:45.177366  7223 layer_factory.hpp:77] Creating layer M2PELU22
I1003 09:37:45.177371  7223 net.cpp:84] Creating Layer M2PELU22
I1003 09:37:45.177373  7223 net.cpp:406] M2PELU22 <- Convolution23
I1003 09:37:45.177376  7223 net.cpp:367] M2PELU22 -> Convolution23 (in-place)
I1003 09:37:45.177456  7223 net.cpp:122] Setting up M2PELU22
I1003 09:37:45.177461  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.177464  7223 net.cpp:137] Memory required for data: 572947600
I1003 09:37:45.177466  7223 layer_factory.hpp:77] Creating layer Convolution24
I1003 09:37:45.177474  7223 net.cpp:84] Creating Layer Convolution24
I1003 09:37:45.177475  7223 net.cpp:406] Convolution24 <- Convolution23
I1003 09:37:45.177479  7223 net.cpp:380] Convolution24 -> Convolution24
I1003 09:37:45.178514  7223 net.cpp:122] Setting up Convolution24
I1003 09:37:45.178526  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.178529  7223 net.cpp:137] Memory required for data: 575456400
I1003 09:37:45.178534  7223 layer_factory.hpp:77] Creating layer BatchNorm24
I1003 09:37:45.178547  7223 net.cpp:84] Creating Layer BatchNorm24
I1003 09:37:45.178550  7223 net.cpp:406] BatchNorm24 <- Convolution24
I1003 09:37:45.178555  7223 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1003 09:37:45.178688  7223 net.cpp:122] Setting up BatchNorm24
I1003 09:37:45.178691  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.178694  7223 net.cpp:137] Memory required for data: 577965200
I1003 09:37:45.178699  7223 layer_factory.hpp:77] Creating layer Scale24
I1003 09:37:45.178709  7223 net.cpp:84] Creating Layer Scale24
I1003 09:37:45.178711  7223 net.cpp:406] Scale24 <- Convolution24
I1003 09:37:45.178715  7223 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1003 09:37:45.178742  7223 layer_factory.hpp:77] Creating layer Scale24
I1003 09:37:45.178818  7223 net.cpp:122] Setting up Scale24
I1003 09:37:45.178823  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.178825  7223 net.cpp:137] Memory required for data: 580474000
I1003 09:37:45.178829  7223 layer_factory.hpp:77] Creating layer Eltwise11
I1003 09:37:45.178833  7223 net.cpp:84] Creating Layer Eltwise11
I1003 09:37:45.178835  7223 net.cpp:406] Eltwise11 <- Eltwise10_M2PELU21_0_split_1
I1003 09:37:45.178838  7223 net.cpp:406] Eltwise11 <- Convolution24
I1003 09:37:45.178843  7223 net.cpp:380] Eltwise11 -> Eltwise11
I1003 09:37:45.178858  7223 net.cpp:122] Setting up Eltwise11
I1003 09:37:45.178861  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.178864  7223 net.cpp:137] Memory required for data: 582982800
I1003 09:37:45.178866  7223 layer_factory.hpp:77] Creating layer M2PELU23
I1003 09:37:45.178870  7223 net.cpp:84] Creating Layer M2PELU23
I1003 09:37:45.178872  7223 net.cpp:406] M2PELU23 <- Eltwise11
I1003 09:37:45.178876  7223 net.cpp:367] M2PELU23 -> Eltwise11 (in-place)
I1003 09:37:45.178959  7223 net.cpp:122] Setting up M2PELU23
I1003 09:37:45.178963  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.178966  7223 net.cpp:137] Memory required for data: 585491600
I1003 09:37:45.178968  7223 layer_factory.hpp:77] Creating layer Eltwise11_M2PELU23_0_split
I1003 09:37:45.178972  7223 net.cpp:84] Creating Layer Eltwise11_M2PELU23_0_split
I1003 09:37:45.178974  7223 net.cpp:406] Eltwise11_M2PELU23_0_split <- Eltwise11
I1003 09:37:45.178978  7223 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_0
I1003 09:37:45.178982  7223 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_1
I1003 09:37:45.179008  7223 net.cpp:122] Setting up Eltwise11_M2PELU23_0_split
I1003 09:37:45.179010  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.179013  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.179015  7223 net.cpp:137] Memory required for data: 590509200
I1003 09:37:45.179018  7223 layer_factory.hpp:77] Creating layer Convolution25
I1003 09:37:45.179023  7223 net.cpp:84] Creating Layer Convolution25
I1003 09:37:45.179026  7223 net.cpp:406] Convolution25 <- Eltwise11_M2PELU23_0_split_0
I1003 09:37:45.179029  7223 net.cpp:380] Convolution25 -> Convolution25
I1003 09:37:45.180052  7223 net.cpp:122] Setting up Convolution25
I1003 09:37:45.180059  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.180063  7223 net.cpp:137] Memory required for data: 593018000
I1003 09:37:45.180066  7223 layer_factory.hpp:77] Creating layer BatchNorm25
I1003 09:37:45.180071  7223 net.cpp:84] Creating Layer BatchNorm25
I1003 09:37:45.180074  7223 net.cpp:406] BatchNorm25 <- Convolution25
I1003 09:37:45.180078  7223 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1003 09:37:45.180212  7223 net.cpp:122] Setting up BatchNorm25
I1003 09:37:45.180215  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.180217  7223 net.cpp:137] Memory required for data: 595526800
I1003 09:37:45.180222  7223 layer_factory.hpp:77] Creating layer Scale25
I1003 09:37:45.180227  7223 net.cpp:84] Creating Layer Scale25
I1003 09:37:45.180229  7223 net.cpp:406] Scale25 <- Convolution25
I1003 09:37:45.180233  7223 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1003 09:37:45.180258  7223 layer_factory.hpp:77] Creating layer Scale25
I1003 09:37:45.180336  7223 net.cpp:122] Setting up Scale25
I1003 09:37:45.180341  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.180342  7223 net.cpp:137] Memory required for data: 598035600
I1003 09:37:45.180346  7223 layer_factory.hpp:77] Creating layer M2PELU24
I1003 09:37:45.180352  7223 net.cpp:84] Creating Layer M2PELU24
I1003 09:37:45.180354  7223 net.cpp:406] M2PELU24 <- Convolution25
I1003 09:37:45.180363  7223 net.cpp:367] M2PELU24 -> Convolution25 (in-place)
I1003 09:37:45.180446  7223 net.cpp:122] Setting up M2PELU24
I1003 09:37:45.180451  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.180454  7223 net.cpp:137] Memory required for data: 600544400
I1003 09:37:45.180457  7223 layer_factory.hpp:77] Creating layer Convolution26
I1003 09:37:45.180464  7223 net.cpp:84] Creating Layer Convolution26
I1003 09:37:45.180466  7223 net.cpp:406] Convolution26 <- Convolution25
I1003 09:37:45.180470  7223 net.cpp:380] Convolution26 -> Convolution26
I1003 09:37:45.181493  7223 net.cpp:122] Setting up Convolution26
I1003 09:37:45.181501  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.181504  7223 net.cpp:137] Memory required for data: 603053200
I1003 09:37:45.181509  7223 layer_factory.hpp:77] Creating layer BatchNorm26
I1003 09:37:45.181514  7223 net.cpp:84] Creating Layer BatchNorm26
I1003 09:37:45.181515  7223 net.cpp:406] BatchNorm26 <- Convolution26
I1003 09:37:45.181519  7223 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1003 09:37:45.181655  7223 net.cpp:122] Setting up BatchNorm26
I1003 09:37:45.181660  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.181663  7223 net.cpp:137] Memory required for data: 605562000
I1003 09:37:45.181666  7223 layer_factory.hpp:77] Creating layer Scale26
I1003 09:37:45.181670  7223 net.cpp:84] Creating Layer Scale26
I1003 09:37:45.181674  7223 net.cpp:406] Scale26 <- Convolution26
I1003 09:37:45.181677  7223 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1003 09:37:45.181702  7223 layer_factory.hpp:77] Creating layer Scale26
I1003 09:37:45.181779  7223 net.cpp:122] Setting up Scale26
I1003 09:37:45.181783  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.181785  7223 net.cpp:137] Memory required for data: 608070800
I1003 09:37:45.181789  7223 layer_factory.hpp:77] Creating layer Eltwise12
I1003 09:37:45.181793  7223 net.cpp:84] Creating Layer Eltwise12
I1003 09:37:45.181795  7223 net.cpp:406] Eltwise12 <- Eltwise11_M2PELU23_0_split_1
I1003 09:37:45.181798  7223 net.cpp:406] Eltwise12 <- Convolution26
I1003 09:37:45.181802  7223 net.cpp:380] Eltwise12 -> Eltwise12
I1003 09:37:45.181818  7223 net.cpp:122] Setting up Eltwise12
I1003 09:37:45.181821  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.181823  7223 net.cpp:137] Memory required for data: 610579600
I1003 09:37:45.181825  7223 layer_factory.hpp:77] Creating layer M2PELU25
I1003 09:37:45.181829  7223 net.cpp:84] Creating Layer M2PELU25
I1003 09:37:45.181831  7223 net.cpp:406] M2PELU25 <- Eltwise12
I1003 09:37:45.181835  7223 net.cpp:367] M2PELU25 -> Eltwise12 (in-place)
I1003 09:37:45.181919  7223 net.cpp:122] Setting up M2PELU25
I1003 09:37:45.181923  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.181926  7223 net.cpp:137] Memory required for data: 613088400
I1003 09:37:45.181928  7223 layer_factory.hpp:77] Creating layer Eltwise12_M2PELU25_0_split
I1003 09:37:45.181941  7223 net.cpp:84] Creating Layer Eltwise12_M2PELU25_0_split
I1003 09:37:45.181943  7223 net.cpp:406] Eltwise12_M2PELU25_0_split <- Eltwise12
I1003 09:37:45.181946  7223 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_0
I1003 09:37:45.181954  7223 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_1
I1003 09:37:45.181978  7223 net.cpp:122] Setting up Eltwise12_M2PELU25_0_split
I1003 09:37:45.181983  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.181985  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.181988  7223 net.cpp:137] Memory required for data: 618106000
I1003 09:37:45.181990  7223 layer_factory.hpp:77] Creating layer Convolution27
I1003 09:37:45.181995  7223 net.cpp:84] Creating Layer Convolution27
I1003 09:37:45.181998  7223 net.cpp:406] Convolution27 <- Eltwise12_M2PELU25_0_split_0
I1003 09:37:45.182003  7223 net.cpp:380] Convolution27 -> Convolution27
I1003 09:37:45.182732  7223 net.cpp:122] Setting up Convolution27
I1003 09:37:45.182745  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.182749  7223 net.cpp:137] Memory required for data: 620614800
I1003 09:37:45.182752  7223 layer_factory.hpp:77] Creating layer BatchNorm27
I1003 09:37:45.182759  7223 net.cpp:84] Creating Layer BatchNorm27
I1003 09:37:45.182761  7223 net.cpp:406] BatchNorm27 <- Convolution27
I1003 09:37:45.182765  7223 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1003 09:37:45.182899  7223 net.cpp:122] Setting up BatchNorm27
I1003 09:37:45.182904  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.182905  7223 net.cpp:137] Memory required for data: 623123600
I1003 09:37:45.182910  7223 layer_factory.hpp:77] Creating layer Scale27
I1003 09:37:45.182915  7223 net.cpp:84] Creating Layer Scale27
I1003 09:37:45.182919  7223 net.cpp:406] Scale27 <- Convolution27
I1003 09:37:45.182921  7223 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1003 09:37:45.182947  7223 layer_factory.hpp:77] Creating layer Scale27
I1003 09:37:45.183022  7223 net.cpp:122] Setting up Scale27
I1003 09:37:45.183025  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.183027  7223 net.cpp:137] Memory required for data: 625632400
I1003 09:37:45.183032  7223 layer_factory.hpp:77] Creating layer M2PELU26
I1003 09:37:45.183037  7223 net.cpp:84] Creating Layer M2PELU26
I1003 09:37:45.183038  7223 net.cpp:406] M2PELU26 <- Convolution27
I1003 09:37:45.183043  7223 net.cpp:367] M2PELU26 -> Convolution27 (in-place)
I1003 09:37:45.183123  7223 net.cpp:122] Setting up M2PELU26
I1003 09:37:45.183127  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.183130  7223 net.cpp:137] Memory required for data: 628141200
I1003 09:37:45.183133  7223 layer_factory.hpp:77] Creating layer Convolution28
I1003 09:37:45.183140  7223 net.cpp:84] Creating Layer Convolution28
I1003 09:37:45.183142  7223 net.cpp:406] Convolution28 <- Convolution27
I1003 09:37:45.183147  7223 net.cpp:380] Convolution28 -> Convolution28
I1003 09:37:45.184166  7223 net.cpp:122] Setting up Convolution28
I1003 09:37:45.184175  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.184177  7223 net.cpp:137] Memory required for data: 630650000
I1003 09:37:45.184181  7223 layer_factory.hpp:77] Creating layer BatchNorm28
I1003 09:37:45.184186  7223 net.cpp:84] Creating Layer BatchNorm28
I1003 09:37:45.184190  7223 net.cpp:406] BatchNorm28 <- Convolution28
I1003 09:37:45.184192  7223 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1003 09:37:45.184327  7223 net.cpp:122] Setting up BatchNorm28
I1003 09:37:45.184332  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.184334  7223 net.cpp:137] Memory required for data: 633158800
I1003 09:37:45.184339  7223 layer_factory.hpp:77] Creating layer Scale28
I1003 09:37:45.184342  7223 net.cpp:84] Creating Layer Scale28
I1003 09:37:45.184345  7223 net.cpp:406] Scale28 <- Convolution28
I1003 09:37:45.184347  7223 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1003 09:37:45.184375  7223 layer_factory.hpp:77] Creating layer Scale28
I1003 09:37:45.184451  7223 net.cpp:122] Setting up Scale28
I1003 09:37:45.184455  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.184458  7223 net.cpp:137] Memory required for data: 635667600
I1003 09:37:45.184461  7223 layer_factory.hpp:77] Creating layer Eltwise13
I1003 09:37:45.184466  7223 net.cpp:84] Creating Layer Eltwise13
I1003 09:37:45.184468  7223 net.cpp:406] Eltwise13 <- Eltwise12_M2PELU25_0_split_1
I1003 09:37:45.184471  7223 net.cpp:406] Eltwise13 <- Convolution28
I1003 09:37:45.184474  7223 net.cpp:380] Eltwise13 -> Eltwise13
I1003 09:37:45.184490  7223 net.cpp:122] Setting up Eltwise13
I1003 09:37:45.184494  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.184496  7223 net.cpp:137] Memory required for data: 638176400
I1003 09:37:45.184499  7223 layer_factory.hpp:77] Creating layer M2PELU27
I1003 09:37:45.184504  7223 net.cpp:84] Creating Layer M2PELU27
I1003 09:37:45.184506  7223 net.cpp:406] M2PELU27 <- Eltwise13
I1003 09:37:45.184510  7223 net.cpp:367] M2PELU27 -> Eltwise13 (in-place)
I1003 09:37:45.184602  7223 net.cpp:122] Setting up M2PELU27
I1003 09:37:45.184607  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.184608  7223 net.cpp:137] Memory required for data: 640685200
I1003 09:37:45.184612  7223 layer_factory.hpp:77] Creating layer Eltwise13_M2PELU27_0_split
I1003 09:37:45.184615  7223 net.cpp:84] Creating Layer Eltwise13_M2PELU27_0_split
I1003 09:37:45.184617  7223 net.cpp:406] Eltwise13_M2PELU27_0_split <- Eltwise13
I1003 09:37:45.184622  7223 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_0
I1003 09:37:45.184625  7223 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_1
I1003 09:37:45.184649  7223 net.cpp:122] Setting up Eltwise13_M2PELU27_0_split
I1003 09:37:45.184653  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.184655  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.184659  7223 net.cpp:137] Memory required for data: 645702800
I1003 09:37:45.184660  7223 layer_factory.hpp:77] Creating layer Convolution29
I1003 09:37:45.184666  7223 net.cpp:84] Creating Layer Convolution29
I1003 09:37:45.184669  7223 net.cpp:406] Convolution29 <- Eltwise13_M2PELU27_0_split_0
I1003 09:37:45.184674  7223 net.cpp:380] Convolution29 -> Convolution29
I1003 09:37:45.185700  7223 net.cpp:122] Setting up Convolution29
I1003 09:37:45.185709  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.185711  7223 net.cpp:137] Memory required for data: 648211600
I1003 09:37:45.185716  7223 layer_factory.hpp:77] Creating layer BatchNorm29
I1003 09:37:45.185721  7223 net.cpp:84] Creating Layer BatchNorm29
I1003 09:37:45.185724  7223 net.cpp:406] BatchNorm29 <- Convolution29
I1003 09:37:45.185729  7223 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1003 09:37:45.185863  7223 net.cpp:122] Setting up BatchNorm29
I1003 09:37:45.185868  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.185869  7223 net.cpp:137] Memory required for data: 650720400
I1003 09:37:45.185873  7223 layer_factory.hpp:77] Creating layer Scale29
I1003 09:37:45.185878  7223 net.cpp:84] Creating Layer Scale29
I1003 09:37:45.185880  7223 net.cpp:406] Scale29 <- Convolution29
I1003 09:37:45.185883  7223 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1003 09:37:45.185910  7223 layer_factory.hpp:77] Creating layer Scale29
I1003 09:37:45.185987  7223 net.cpp:122] Setting up Scale29
I1003 09:37:45.185992  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.185994  7223 net.cpp:137] Memory required for data: 653229200
I1003 09:37:45.186014  7223 layer_factory.hpp:77] Creating layer M2PELU28
I1003 09:37:45.186020  7223 net.cpp:84] Creating Layer M2PELU28
I1003 09:37:45.186023  7223 net.cpp:406] M2PELU28 <- Convolution29
I1003 09:37:45.186027  7223 net.cpp:367] M2PELU28 -> Convolution29 (in-place)
I1003 09:37:45.186115  7223 net.cpp:122] Setting up M2PELU28
I1003 09:37:45.186118  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.186120  7223 net.cpp:137] Memory required for data: 655738000
I1003 09:37:45.186125  7223 layer_factory.hpp:77] Creating layer Convolution30
I1003 09:37:45.186131  7223 net.cpp:84] Creating Layer Convolution30
I1003 09:37:45.186133  7223 net.cpp:406] Convolution30 <- Convolution29
I1003 09:37:45.186138  7223 net.cpp:380] Convolution30 -> Convolution30
I1003 09:37:45.187189  7223 net.cpp:122] Setting up Convolution30
I1003 09:37:45.187197  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.187201  7223 net.cpp:137] Memory required for data: 658246800
I1003 09:37:45.187204  7223 layer_factory.hpp:77] Creating layer BatchNorm30
I1003 09:37:45.187211  7223 net.cpp:84] Creating Layer BatchNorm30
I1003 09:37:45.187212  7223 net.cpp:406] BatchNorm30 <- Convolution30
I1003 09:37:45.187216  7223 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1003 09:37:45.187350  7223 net.cpp:122] Setting up BatchNorm30
I1003 09:37:45.187355  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.187356  7223 net.cpp:137] Memory required for data: 660755600
I1003 09:37:45.187367  7223 layer_factory.hpp:77] Creating layer Scale30
I1003 09:37:45.187372  7223 net.cpp:84] Creating Layer Scale30
I1003 09:37:45.187376  7223 net.cpp:406] Scale30 <- Convolution30
I1003 09:37:45.187378  7223 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1003 09:37:45.187407  7223 layer_factory.hpp:77] Creating layer Scale30
I1003 09:37:45.187482  7223 net.cpp:122] Setting up Scale30
I1003 09:37:45.187486  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.187489  7223 net.cpp:137] Memory required for data: 663264400
I1003 09:37:45.187492  7223 layer_factory.hpp:77] Creating layer Eltwise14
I1003 09:37:45.187497  7223 net.cpp:84] Creating Layer Eltwise14
I1003 09:37:45.187500  7223 net.cpp:406] Eltwise14 <- Eltwise13_M2PELU27_0_split_1
I1003 09:37:45.187502  7223 net.cpp:406] Eltwise14 <- Convolution30
I1003 09:37:45.187505  7223 net.cpp:380] Eltwise14 -> Eltwise14
I1003 09:37:45.187521  7223 net.cpp:122] Setting up Eltwise14
I1003 09:37:45.187525  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.187527  7223 net.cpp:137] Memory required for data: 665773200
I1003 09:37:45.187530  7223 layer_factory.hpp:77] Creating layer M2PELU29
I1003 09:37:45.187533  7223 net.cpp:84] Creating Layer M2PELU29
I1003 09:37:45.187536  7223 net.cpp:406] M2PELU29 <- Eltwise14
I1003 09:37:45.187539  7223 net.cpp:367] M2PELU29 -> Eltwise14 (in-place)
I1003 09:37:45.187623  7223 net.cpp:122] Setting up M2PELU29
I1003 09:37:45.187626  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.187628  7223 net.cpp:137] Memory required for data: 668282000
I1003 09:37:45.187631  7223 layer_factory.hpp:77] Creating layer Eltwise14_M2PELU29_0_split
I1003 09:37:45.187636  7223 net.cpp:84] Creating Layer Eltwise14_M2PELU29_0_split
I1003 09:37:45.187638  7223 net.cpp:406] Eltwise14_M2PELU29_0_split <- Eltwise14
I1003 09:37:45.187641  7223 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_0
I1003 09:37:45.187645  7223 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_1
I1003 09:37:45.187669  7223 net.cpp:122] Setting up Eltwise14_M2PELU29_0_split
I1003 09:37:45.187672  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.187675  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.187677  7223 net.cpp:137] Memory required for data: 673299600
I1003 09:37:45.187680  7223 layer_factory.hpp:77] Creating layer Convolution31
I1003 09:37:45.187685  7223 net.cpp:84] Creating Layer Convolution31
I1003 09:37:45.187687  7223 net.cpp:406] Convolution31 <- Eltwise14_M2PELU29_0_split_0
I1003 09:37:45.187691  7223 net.cpp:380] Convolution31 -> Convolution31
I1003 09:37:45.188719  7223 net.cpp:122] Setting up Convolution31
I1003 09:37:45.188727  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.188730  7223 net.cpp:137] Memory required for data: 675808400
I1003 09:37:45.188735  7223 layer_factory.hpp:77] Creating layer BatchNorm31
I1003 09:37:45.188740  7223 net.cpp:84] Creating Layer BatchNorm31
I1003 09:37:45.188743  7223 net.cpp:406] BatchNorm31 <- Convolution31
I1003 09:37:45.188747  7223 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1003 09:37:45.188882  7223 net.cpp:122] Setting up BatchNorm31
I1003 09:37:45.188887  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.188889  7223 net.cpp:137] Memory required for data: 678317200
I1003 09:37:45.188894  7223 layer_factory.hpp:77] Creating layer Scale31
I1003 09:37:45.188897  7223 net.cpp:84] Creating Layer Scale31
I1003 09:37:45.188900  7223 net.cpp:406] Scale31 <- Convolution31
I1003 09:37:45.188904  7223 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1003 09:37:45.188930  7223 layer_factory.hpp:77] Creating layer Scale31
I1003 09:37:45.189007  7223 net.cpp:122] Setting up Scale31
I1003 09:37:45.189013  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.189014  7223 net.cpp:137] Memory required for data: 680826000
I1003 09:37:45.189018  7223 layer_factory.hpp:77] Creating layer M2PELU30
I1003 09:37:45.189028  7223 net.cpp:84] Creating Layer M2PELU30
I1003 09:37:45.189031  7223 net.cpp:406] M2PELU30 <- Convolution31
I1003 09:37:45.189035  7223 net.cpp:367] M2PELU30 -> Convolution31 (in-place)
I1003 09:37:45.189121  7223 net.cpp:122] Setting up M2PELU30
I1003 09:37:45.189126  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.189127  7223 net.cpp:137] Memory required for data: 683334800
I1003 09:37:45.189131  7223 layer_factory.hpp:77] Creating layer Convolution32
I1003 09:37:45.189138  7223 net.cpp:84] Creating Layer Convolution32
I1003 09:37:45.189141  7223 net.cpp:406] Convolution32 <- Convolution31
I1003 09:37:45.189146  7223 net.cpp:380] Convolution32 -> Convolution32
I1003 09:37:45.190171  7223 net.cpp:122] Setting up Convolution32
I1003 09:37:45.190179  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.190182  7223 net.cpp:137] Memory required for data: 685843600
I1003 09:37:45.190186  7223 layer_factory.hpp:77] Creating layer BatchNorm32
I1003 09:37:45.190191  7223 net.cpp:84] Creating Layer BatchNorm32
I1003 09:37:45.190194  7223 net.cpp:406] BatchNorm32 <- Convolution32
I1003 09:37:45.190198  7223 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1003 09:37:45.190333  7223 net.cpp:122] Setting up BatchNorm32
I1003 09:37:45.190337  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.190340  7223 net.cpp:137] Memory required for data: 688352400
I1003 09:37:45.190345  7223 layer_factory.hpp:77] Creating layer Scale32
I1003 09:37:45.190349  7223 net.cpp:84] Creating Layer Scale32
I1003 09:37:45.190352  7223 net.cpp:406] Scale32 <- Convolution32
I1003 09:37:45.190356  7223 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1003 09:37:45.190382  7223 layer_factory.hpp:77] Creating layer Scale32
I1003 09:37:45.190459  7223 net.cpp:122] Setting up Scale32
I1003 09:37:45.190464  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.190465  7223 net.cpp:137] Memory required for data: 690861200
I1003 09:37:45.190469  7223 layer_factory.hpp:77] Creating layer Eltwise15
I1003 09:37:45.190474  7223 net.cpp:84] Creating Layer Eltwise15
I1003 09:37:45.190476  7223 net.cpp:406] Eltwise15 <- Eltwise14_M2PELU29_0_split_1
I1003 09:37:45.190479  7223 net.cpp:406] Eltwise15 <- Convolution32
I1003 09:37:45.190481  7223 net.cpp:380] Eltwise15 -> Eltwise15
I1003 09:37:45.190498  7223 net.cpp:122] Setting up Eltwise15
I1003 09:37:45.190501  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.190503  7223 net.cpp:137] Memory required for data: 693370000
I1003 09:37:45.190505  7223 layer_factory.hpp:77] Creating layer M2PELU31
I1003 09:37:45.190510  7223 net.cpp:84] Creating Layer M2PELU31
I1003 09:37:45.190513  7223 net.cpp:406] M2PELU31 <- Eltwise15
I1003 09:37:45.190516  7223 net.cpp:367] M2PELU31 -> Eltwise15 (in-place)
I1003 09:37:45.190626  7223 net.cpp:122] Setting up M2PELU31
I1003 09:37:45.190631  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.190634  7223 net.cpp:137] Memory required for data: 695878800
I1003 09:37:45.190637  7223 layer_factory.hpp:77] Creating layer Eltwise15_M2PELU31_0_split
I1003 09:37:45.190640  7223 net.cpp:84] Creating Layer Eltwise15_M2PELU31_0_split
I1003 09:37:45.190644  7223 net.cpp:406] Eltwise15_M2PELU31_0_split <- Eltwise15
I1003 09:37:45.190647  7223 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_0
I1003 09:37:45.190651  7223 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_1
I1003 09:37:45.190675  7223 net.cpp:122] Setting up Eltwise15_M2PELU31_0_split
I1003 09:37:45.190678  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.190681  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.190683  7223 net.cpp:137] Memory required for data: 700896400
I1003 09:37:45.190685  7223 layer_factory.hpp:77] Creating layer Convolution33
I1003 09:37:45.190690  7223 net.cpp:84] Creating Layer Convolution33
I1003 09:37:45.190693  7223 net.cpp:406] Convolution33 <- Eltwise15_M2PELU31_0_split_0
I1003 09:37:45.190697  7223 net.cpp:380] Convolution33 -> Convolution33
I1003 09:37:45.192046  7223 net.cpp:122] Setting up Convolution33
I1003 09:37:45.192054  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.192056  7223 net.cpp:137] Memory required for data: 703405200
I1003 09:37:45.192061  7223 layer_factory.hpp:77] Creating layer BatchNorm33
I1003 09:37:45.192067  7223 net.cpp:84] Creating Layer BatchNorm33
I1003 09:37:45.192070  7223 net.cpp:406] BatchNorm33 <- Convolution33
I1003 09:37:45.192075  7223 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1003 09:37:45.192214  7223 net.cpp:122] Setting up BatchNorm33
I1003 09:37:45.192219  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.192221  7223 net.cpp:137] Memory required for data: 705914000
I1003 09:37:45.192225  7223 layer_factory.hpp:77] Creating layer Scale33
I1003 09:37:45.192230  7223 net.cpp:84] Creating Layer Scale33
I1003 09:37:45.192232  7223 net.cpp:406] Scale33 <- Convolution33
I1003 09:37:45.192235  7223 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1003 09:37:45.192262  7223 layer_factory.hpp:77] Creating layer Scale33
I1003 09:37:45.192342  7223 net.cpp:122] Setting up Scale33
I1003 09:37:45.192347  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.192348  7223 net.cpp:137] Memory required for data: 708422800
I1003 09:37:45.192353  7223 layer_factory.hpp:77] Creating layer M2PELU32
I1003 09:37:45.192358  7223 net.cpp:84] Creating Layer M2PELU32
I1003 09:37:45.192359  7223 net.cpp:406] M2PELU32 <- Convolution33
I1003 09:37:45.192363  7223 net.cpp:367] M2PELU32 -> Convolution33 (in-place)
I1003 09:37:45.192447  7223 net.cpp:122] Setting up M2PELU32
I1003 09:37:45.192451  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.192453  7223 net.cpp:137] Memory required for data: 710931600
I1003 09:37:45.192457  7223 layer_factory.hpp:77] Creating layer Convolution34
I1003 09:37:45.192463  7223 net.cpp:84] Creating Layer Convolution34
I1003 09:37:45.192466  7223 net.cpp:406] Convolution34 <- Convolution33
I1003 09:37:45.192471  7223 net.cpp:380] Convolution34 -> Convolution34
I1003 09:37:45.193505  7223 net.cpp:122] Setting up Convolution34
I1003 09:37:45.193513  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.193516  7223 net.cpp:137] Memory required for data: 713440400
I1003 09:37:45.193521  7223 layer_factory.hpp:77] Creating layer BatchNorm34
I1003 09:37:45.193526  7223 net.cpp:84] Creating Layer BatchNorm34
I1003 09:37:45.193527  7223 net.cpp:406] BatchNorm34 <- Convolution34
I1003 09:37:45.193532  7223 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I1003 09:37:45.193670  7223 net.cpp:122] Setting up BatchNorm34
I1003 09:37:45.193675  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.193676  7223 net.cpp:137] Memory required for data: 715949200
I1003 09:37:45.193681  7223 layer_factory.hpp:77] Creating layer Scale34
I1003 09:37:45.193686  7223 net.cpp:84] Creating Layer Scale34
I1003 09:37:45.193687  7223 net.cpp:406] Scale34 <- Convolution34
I1003 09:37:45.193691  7223 net.cpp:367] Scale34 -> Convolution34 (in-place)
I1003 09:37:45.193717  7223 layer_factory.hpp:77] Creating layer Scale34
I1003 09:37:45.193794  7223 net.cpp:122] Setting up Scale34
I1003 09:37:45.193797  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.193799  7223 net.cpp:137] Memory required for data: 718458000
I1003 09:37:45.193804  7223 layer_factory.hpp:77] Creating layer Eltwise16
I1003 09:37:45.193807  7223 net.cpp:84] Creating Layer Eltwise16
I1003 09:37:45.193809  7223 net.cpp:406] Eltwise16 <- Eltwise15_M2PELU31_0_split_1
I1003 09:37:45.193812  7223 net.cpp:406] Eltwise16 <- Convolution34
I1003 09:37:45.193815  7223 net.cpp:380] Eltwise16 -> Eltwise16
I1003 09:37:45.193833  7223 net.cpp:122] Setting up Eltwise16
I1003 09:37:45.193837  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.193840  7223 net.cpp:137] Memory required for data: 720966800
I1003 09:37:45.193841  7223 layer_factory.hpp:77] Creating layer M2PELU33
I1003 09:37:45.193846  7223 net.cpp:84] Creating Layer M2PELU33
I1003 09:37:45.193856  7223 net.cpp:406] M2PELU33 <- Eltwise16
I1003 09:37:45.193859  7223 net.cpp:367] M2PELU33 -> Eltwise16 (in-place)
I1003 09:37:45.193948  7223 net.cpp:122] Setting up M2PELU33
I1003 09:37:45.193951  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.193953  7223 net.cpp:137] Memory required for data: 723475600
I1003 09:37:45.193958  7223 layer_factory.hpp:77] Creating layer Eltwise16_M2PELU33_0_split
I1003 09:37:45.193960  7223 net.cpp:84] Creating Layer Eltwise16_M2PELU33_0_split
I1003 09:37:45.193963  7223 net.cpp:406] Eltwise16_M2PELU33_0_split <- Eltwise16
I1003 09:37:45.193966  7223 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_0
I1003 09:37:45.193970  7223 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_1
I1003 09:37:45.193994  7223 net.cpp:122] Setting up Eltwise16_M2PELU33_0_split
I1003 09:37:45.193997  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.194000  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.194001  7223 net.cpp:137] Memory required for data: 728493200
I1003 09:37:45.194003  7223 layer_factory.hpp:77] Creating layer Convolution35
I1003 09:37:45.194010  7223 net.cpp:84] Creating Layer Convolution35
I1003 09:37:45.194012  7223 net.cpp:406] Convolution35 <- Eltwise16_M2PELU33_0_split_0
I1003 09:37:45.194016  7223 net.cpp:380] Convolution35 -> Convolution35
I1003 09:37:45.195081  7223 net.cpp:122] Setting up Convolution35
I1003 09:37:45.195089  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.195092  7223 net.cpp:137] Memory required for data: 731002000
I1003 09:37:45.195096  7223 layer_factory.hpp:77] Creating layer BatchNorm35
I1003 09:37:45.195102  7223 net.cpp:84] Creating Layer BatchNorm35
I1003 09:37:45.195106  7223 net.cpp:406] BatchNorm35 <- Convolution35
I1003 09:37:45.195108  7223 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I1003 09:37:45.195243  7223 net.cpp:122] Setting up BatchNorm35
I1003 09:37:45.195248  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.195250  7223 net.cpp:137] Memory required for data: 733510800
I1003 09:37:45.195255  7223 layer_factory.hpp:77] Creating layer Scale35
I1003 09:37:45.195260  7223 net.cpp:84] Creating Layer Scale35
I1003 09:37:45.195261  7223 net.cpp:406] Scale35 <- Convolution35
I1003 09:37:45.195264  7223 net.cpp:367] Scale35 -> Convolution35 (in-place)
I1003 09:37:45.195291  7223 layer_factory.hpp:77] Creating layer Scale35
I1003 09:37:45.195369  7223 net.cpp:122] Setting up Scale35
I1003 09:37:45.195372  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.195374  7223 net.cpp:137] Memory required for data: 736019600
I1003 09:37:45.195379  7223 layer_factory.hpp:77] Creating layer M2PELU34
I1003 09:37:45.195384  7223 net.cpp:84] Creating Layer M2PELU34
I1003 09:37:45.195385  7223 net.cpp:406] M2PELU34 <- Convolution35
I1003 09:37:45.195389  7223 net.cpp:367] M2PELU34 -> Convolution35 (in-place)
I1003 09:37:45.195472  7223 net.cpp:122] Setting up M2PELU34
I1003 09:37:45.195477  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.195478  7223 net.cpp:137] Memory required for data: 738528400
I1003 09:37:45.195482  7223 layer_factory.hpp:77] Creating layer Convolution36
I1003 09:37:45.195488  7223 net.cpp:84] Creating Layer Convolution36
I1003 09:37:45.195492  7223 net.cpp:406] Convolution36 <- Convolution35
I1003 09:37:45.195495  7223 net.cpp:380] Convolution36 -> Convolution36
I1003 09:37:45.196530  7223 net.cpp:122] Setting up Convolution36
I1003 09:37:45.196538  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.196542  7223 net.cpp:137] Memory required for data: 741037200
I1003 09:37:45.196547  7223 layer_factory.hpp:77] Creating layer BatchNorm36
I1003 09:37:45.196550  7223 net.cpp:84] Creating Layer BatchNorm36
I1003 09:37:45.196553  7223 net.cpp:406] BatchNorm36 <- Convolution36
I1003 09:37:45.196557  7223 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I1003 09:37:45.196694  7223 net.cpp:122] Setting up BatchNorm36
I1003 09:37:45.196699  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.196707  7223 net.cpp:137] Memory required for data: 743546000
I1003 09:37:45.196712  7223 layer_factory.hpp:77] Creating layer Scale36
I1003 09:37:45.196717  7223 net.cpp:84] Creating Layer Scale36
I1003 09:37:45.196719  7223 net.cpp:406] Scale36 <- Convolution36
I1003 09:37:45.196722  7223 net.cpp:367] Scale36 -> Convolution36 (in-place)
I1003 09:37:45.196750  7223 layer_factory.hpp:77] Creating layer Scale36
I1003 09:37:45.196828  7223 net.cpp:122] Setting up Scale36
I1003 09:37:45.196832  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.196835  7223 net.cpp:137] Memory required for data: 746054800
I1003 09:37:45.196838  7223 layer_factory.hpp:77] Creating layer Eltwise17
I1003 09:37:45.196842  7223 net.cpp:84] Creating Layer Eltwise17
I1003 09:37:45.196844  7223 net.cpp:406] Eltwise17 <- Eltwise16_M2PELU33_0_split_1
I1003 09:37:45.196847  7223 net.cpp:406] Eltwise17 <- Convolution36
I1003 09:37:45.196851  7223 net.cpp:380] Eltwise17 -> Eltwise17
I1003 09:37:45.196867  7223 net.cpp:122] Setting up Eltwise17
I1003 09:37:45.196871  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.196873  7223 net.cpp:137] Memory required for data: 748563600
I1003 09:37:45.196876  7223 layer_factory.hpp:77] Creating layer M2PELU35
I1003 09:37:45.196880  7223 net.cpp:84] Creating Layer M2PELU35
I1003 09:37:45.196882  7223 net.cpp:406] M2PELU35 <- Eltwise17
I1003 09:37:45.196887  7223 net.cpp:367] M2PELU35 -> Eltwise17 (in-place)
I1003 09:37:45.196971  7223 net.cpp:122] Setting up M2PELU35
I1003 09:37:45.196975  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.196977  7223 net.cpp:137] Memory required for data: 751072400
I1003 09:37:45.196980  7223 layer_factory.hpp:77] Creating layer Eltwise17_M2PELU35_0_split
I1003 09:37:45.196985  7223 net.cpp:84] Creating Layer Eltwise17_M2PELU35_0_split
I1003 09:37:45.196986  7223 net.cpp:406] Eltwise17_M2PELU35_0_split <- Eltwise17
I1003 09:37:45.196990  7223 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_0
I1003 09:37:45.196995  7223 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_1
I1003 09:37:45.197018  7223 net.cpp:122] Setting up Eltwise17_M2PELU35_0_split
I1003 09:37:45.197021  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.197024  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.197026  7223 net.cpp:137] Memory required for data: 756090000
I1003 09:37:45.197028  7223 layer_factory.hpp:77] Creating layer Convolution37
I1003 09:37:45.197034  7223 net.cpp:84] Creating Layer Convolution37
I1003 09:37:45.197037  7223 net.cpp:406] Convolution37 <- Eltwise17_M2PELU35_0_split_0
I1003 09:37:45.197041  7223 net.cpp:380] Convolution37 -> Convolution37
I1003 09:37:45.197752  7223 net.cpp:122] Setting up Convolution37
I1003 09:37:45.197759  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.197762  7223 net.cpp:137] Memory required for data: 758598800
I1003 09:37:45.197765  7223 layer_factory.hpp:77] Creating layer BatchNorm37
I1003 09:37:45.197769  7223 net.cpp:84] Creating Layer BatchNorm37
I1003 09:37:45.197772  7223 net.cpp:406] BatchNorm37 <- Convolution37
I1003 09:37:45.197777  7223 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I1003 09:37:45.197912  7223 net.cpp:122] Setting up BatchNorm37
I1003 09:37:45.197916  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.197918  7223 net.cpp:137] Memory required for data: 761107600
I1003 09:37:45.197922  7223 layer_factory.hpp:77] Creating layer Scale37
I1003 09:37:45.197926  7223 net.cpp:84] Creating Layer Scale37
I1003 09:37:45.197929  7223 net.cpp:406] Scale37 <- Convolution37
I1003 09:37:45.197932  7223 net.cpp:367] Scale37 -> Convolution37 (in-place)
I1003 09:37:45.197957  7223 layer_factory.hpp:77] Creating layer Scale37
I1003 09:37:45.198035  7223 net.cpp:122] Setting up Scale37
I1003 09:37:45.198038  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.198040  7223 net.cpp:137] Memory required for data: 763616400
I1003 09:37:45.198050  7223 layer_factory.hpp:77] Creating layer M2PELU36
I1003 09:37:45.198055  7223 net.cpp:84] Creating Layer M2PELU36
I1003 09:37:45.198057  7223 net.cpp:406] M2PELU36 <- Convolution37
I1003 09:37:45.198061  7223 net.cpp:367] M2PELU36 -> Convolution37 (in-place)
I1003 09:37:45.198148  7223 net.cpp:122] Setting up M2PELU36
I1003 09:37:45.198153  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.198154  7223 net.cpp:137] Memory required for data: 766125200
I1003 09:37:45.198158  7223 layer_factory.hpp:77] Creating layer Convolution38
I1003 09:37:45.198164  7223 net.cpp:84] Creating Layer Convolution38
I1003 09:37:45.198166  7223 net.cpp:406] Convolution38 <- Convolution37
I1003 09:37:45.198170  7223 net.cpp:380] Convolution38 -> Convolution38
I1003 09:37:45.199221  7223 net.cpp:122] Setting up Convolution38
I1003 09:37:45.199229  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.199232  7223 net.cpp:137] Memory required for data: 768634000
I1003 09:37:45.199236  7223 layer_factory.hpp:77] Creating layer BatchNorm38
I1003 09:37:45.199241  7223 net.cpp:84] Creating Layer BatchNorm38
I1003 09:37:45.199244  7223 net.cpp:406] BatchNorm38 <- Convolution38
I1003 09:37:45.199249  7223 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I1003 09:37:45.199385  7223 net.cpp:122] Setting up BatchNorm38
I1003 09:37:45.199390  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.199393  7223 net.cpp:137] Memory required for data: 771142800
I1003 09:37:45.199398  7223 layer_factory.hpp:77] Creating layer Scale38
I1003 09:37:45.199401  7223 net.cpp:84] Creating Layer Scale38
I1003 09:37:45.199404  7223 net.cpp:406] Scale38 <- Convolution38
I1003 09:37:45.199407  7223 net.cpp:367] Scale38 -> Convolution38 (in-place)
I1003 09:37:45.199434  7223 layer_factory.hpp:77] Creating layer Scale38
I1003 09:37:45.199510  7223 net.cpp:122] Setting up Scale38
I1003 09:37:45.199514  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.199517  7223 net.cpp:137] Memory required for data: 773651600
I1003 09:37:45.199520  7223 layer_factory.hpp:77] Creating layer Eltwise18
I1003 09:37:45.199524  7223 net.cpp:84] Creating Layer Eltwise18
I1003 09:37:45.199527  7223 net.cpp:406] Eltwise18 <- Eltwise17_M2PELU35_0_split_1
I1003 09:37:45.199530  7223 net.cpp:406] Eltwise18 <- Convolution38
I1003 09:37:45.199533  7223 net.cpp:380] Eltwise18 -> Eltwise18
I1003 09:37:45.199549  7223 net.cpp:122] Setting up Eltwise18
I1003 09:37:45.199553  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.199555  7223 net.cpp:137] Memory required for data: 776160400
I1003 09:37:45.199558  7223 layer_factory.hpp:77] Creating layer M2PELU37
I1003 09:37:45.199563  7223 net.cpp:84] Creating Layer M2PELU37
I1003 09:37:45.199565  7223 net.cpp:406] M2PELU37 <- Eltwise18
I1003 09:37:45.199568  7223 net.cpp:367] M2PELU37 -> Eltwise18 (in-place)
I1003 09:37:45.199652  7223 net.cpp:122] Setting up M2PELU37
I1003 09:37:45.199656  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.199658  7223 net.cpp:137] Memory required for data: 778669200
I1003 09:37:45.199662  7223 layer_factory.hpp:77] Creating layer Eltwise18_M2PELU37_0_split
I1003 09:37:45.199666  7223 net.cpp:84] Creating Layer Eltwise18_M2PELU37_0_split
I1003 09:37:45.199667  7223 net.cpp:406] Eltwise18_M2PELU37_0_split <- Eltwise18
I1003 09:37:45.199671  7223 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_0
I1003 09:37:45.199676  7223 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_1
I1003 09:37:45.199698  7223 net.cpp:122] Setting up Eltwise18_M2PELU37_0_split
I1003 09:37:45.199702  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.199704  7223 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1003 09:37:45.199707  7223 net.cpp:137] Memory required for data: 783686800
I1003 09:37:45.199709  7223 layer_factory.hpp:77] Creating layer Convolution39
I1003 09:37:45.199715  7223 net.cpp:84] Creating Layer Convolution39
I1003 09:37:45.199717  7223 net.cpp:406] Convolution39 <- Eltwise18_M2PELU37_0_split_0
I1003 09:37:45.199728  7223 net.cpp:380] Convolution39 -> Convolution39
I1003 09:37:45.200613  7223 net.cpp:122] Setting up Convolution39
I1003 09:37:45.200621  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.200624  7223 net.cpp:137] Memory required for data: 784941200
I1003 09:37:45.200628  7223 layer_factory.hpp:77] Creating layer BatchNorm39
I1003 09:37:45.200634  7223 net.cpp:84] Creating Layer BatchNorm39
I1003 09:37:45.200635  7223 net.cpp:406] BatchNorm39 <- Convolution39
I1003 09:37:45.200640  7223 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I1003 09:37:45.200773  7223 net.cpp:122] Setting up BatchNorm39
I1003 09:37:45.200778  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.200779  7223 net.cpp:137] Memory required for data: 786195600
I1003 09:37:45.200784  7223 layer_factory.hpp:77] Creating layer Scale39
I1003 09:37:45.200788  7223 net.cpp:84] Creating Layer Scale39
I1003 09:37:45.200790  7223 net.cpp:406] Scale39 <- Convolution39
I1003 09:37:45.200794  7223 net.cpp:367] Scale39 -> Convolution39 (in-place)
I1003 09:37:45.200819  7223 layer_factory.hpp:77] Creating layer Scale39
I1003 09:37:45.200897  7223 net.cpp:122] Setting up Scale39
I1003 09:37:45.200902  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.200904  7223 net.cpp:137] Memory required for data: 787450000
I1003 09:37:45.200908  7223 layer_factory.hpp:77] Creating layer Convolution40
I1003 09:37:45.200914  7223 net.cpp:84] Creating Layer Convolution40
I1003 09:37:45.200917  7223 net.cpp:406] Convolution40 <- Eltwise18_M2PELU37_0_split_1
I1003 09:37:45.200922  7223 net.cpp:380] Convolution40 -> Convolution40
I1003 09:37:45.202666  7223 net.cpp:122] Setting up Convolution40
I1003 09:37:45.202674  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.202677  7223 net.cpp:137] Memory required for data: 788704400
I1003 09:37:45.202682  7223 layer_factory.hpp:77] Creating layer BatchNorm40
I1003 09:37:45.202687  7223 net.cpp:84] Creating Layer BatchNorm40
I1003 09:37:45.202688  7223 net.cpp:406] BatchNorm40 <- Convolution40
I1003 09:37:45.202693  7223 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I1003 09:37:45.202828  7223 net.cpp:122] Setting up BatchNorm40
I1003 09:37:45.202833  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.202836  7223 net.cpp:137] Memory required for data: 789958800
I1003 09:37:45.202841  7223 layer_factory.hpp:77] Creating layer Scale40
I1003 09:37:45.202844  7223 net.cpp:84] Creating Layer Scale40
I1003 09:37:45.202847  7223 net.cpp:406] Scale40 <- Convolution40
I1003 09:37:45.202850  7223 net.cpp:367] Scale40 -> Convolution40 (in-place)
I1003 09:37:45.202877  7223 layer_factory.hpp:77] Creating layer Scale40
I1003 09:37:45.202955  7223 net.cpp:122] Setting up Scale40
I1003 09:37:45.202960  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.202961  7223 net.cpp:137] Memory required for data: 791213200
I1003 09:37:45.202965  7223 layer_factory.hpp:77] Creating layer M2PELU38
I1003 09:37:45.202970  7223 net.cpp:84] Creating Layer M2PELU38
I1003 09:37:45.202972  7223 net.cpp:406] M2PELU38 <- Convolution40
I1003 09:37:45.202976  7223 net.cpp:367] M2PELU38 -> Convolution40 (in-place)
I1003 09:37:45.203073  7223 net.cpp:122] Setting up M2PELU38
I1003 09:37:45.203076  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.203078  7223 net.cpp:137] Memory required for data: 792467600
I1003 09:37:45.203083  7223 layer_factory.hpp:77] Creating layer Convolution41
I1003 09:37:45.203099  7223 net.cpp:84] Creating Layer Convolution41
I1003 09:37:45.203101  7223 net.cpp:406] Convolution41 <- Convolution40
I1003 09:37:45.203115  7223 net.cpp:380] Convolution41 -> Convolution41
I1003 09:37:45.205260  7223 net.cpp:122] Setting up Convolution41
I1003 09:37:45.205268  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.205271  7223 net.cpp:137] Memory required for data: 793722000
I1003 09:37:45.205276  7223 layer_factory.hpp:77] Creating layer BatchNorm41
I1003 09:37:45.205281  7223 net.cpp:84] Creating Layer BatchNorm41
I1003 09:37:45.205291  7223 net.cpp:406] BatchNorm41 <- Convolution41
I1003 09:37:45.205296  7223 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I1003 09:37:45.205473  7223 net.cpp:122] Setting up BatchNorm41
I1003 09:37:45.205478  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.205480  7223 net.cpp:137] Memory required for data: 794976400
I1003 09:37:45.205485  7223 layer_factory.hpp:77] Creating layer Scale41
I1003 09:37:45.205489  7223 net.cpp:84] Creating Layer Scale41
I1003 09:37:45.205492  7223 net.cpp:406] Scale41 <- Convolution41
I1003 09:37:45.205497  7223 net.cpp:367] Scale41 -> Convolution41 (in-place)
I1003 09:37:45.205544  7223 layer_factory.hpp:77] Creating layer Scale41
I1003 09:37:45.205646  7223 net.cpp:122] Setting up Scale41
I1003 09:37:45.205651  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.205652  7223 net.cpp:137] Memory required for data: 796230800
I1003 09:37:45.205657  7223 layer_factory.hpp:77] Creating layer Eltwise19
I1003 09:37:45.205660  7223 net.cpp:84] Creating Layer Eltwise19
I1003 09:37:45.205662  7223 net.cpp:406] Eltwise19 <- Convolution39
I1003 09:37:45.205665  7223 net.cpp:406] Eltwise19 <- Convolution41
I1003 09:37:45.205669  7223 net.cpp:380] Eltwise19 -> Eltwise19
I1003 09:37:45.205685  7223 net.cpp:122] Setting up Eltwise19
I1003 09:37:45.205690  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.205693  7223 net.cpp:137] Memory required for data: 797485200
I1003 09:37:45.205694  7223 layer_factory.hpp:77] Creating layer M2PELU39
I1003 09:37:45.205698  7223 net.cpp:84] Creating Layer M2PELU39
I1003 09:37:45.205700  7223 net.cpp:406] M2PELU39 <- Eltwise19
I1003 09:37:45.205704  7223 net.cpp:367] M2PELU39 -> Eltwise19 (in-place)
I1003 09:37:45.205790  7223 net.cpp:122] Setting up M2PELU39
I1003 09:37:45.205795  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.205796  7223 net.cpp:137] Memory required for data: 798739600
I1003 09:37:45.205801  7223 layer_factory.hpp:77] Creating layer Eltwise19_M2PELU39_0_split
I1003 09:37:45.205804  7223 net.cpp:84] Creating Layer Eltwise19_M2PELU39_0_split
I1003 09:37:45.205806  7223 net.cpp:406] Eltwise19_M2PELU39_0_split <- Eltwise19
I1003 09:37:45.205811  7223 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_0
I1003 09:37:45.205814  7223 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_1
I1003 09:37:45.205838  7223 net.cpp:122] Setting up Eltwise19_M2PELU39_0_split
I1003 09:37:45.205842  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.205844  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.205847  7223 net.cpp:137] Memory required for data: 801248400
I1003 09:37:45.205849  7223 layer_factory.hpp:77] Creating layer Convolution42
I1003 09:37:45.205854  7223 net.cpp:84] Creating Layer Convolution42
I1003 09:37:45.205857  7223 net.cpp:406] Convolution42 <- Eltwise19_M2PELU39_0_split_0
I1003 09:37:45.205862  7223 net.cpp:380] Convolution42 -> Convolution42
I1003 09:37:45.207574  7223 net.cpp:122] Setting up Convolution42
I1003 09:37:45.207583  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.207587  7223 net.cpp:137] Memory required for data: 802502800
I1003 09:37:45.207590  7223 layer_factory.hpp:77] Creating layer BatchNorm42
I1003 09:37:45.207595  7223 net.cpp:84] Creating Layer BatchNorm42
I1003 09:37:45.207598  7223 net.cpp:406] BatchNorm42 <- Convolution42
I1003 09:37:45.207602  7223 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I1003 09:37:45.207741  7223 net.cpp:122] Setting up BatchNorm42
I1003 09:37:45.207744  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.207746  7223 net.cpp:137] Memory required for data: 803757200
I1003 09:37:45.207751  7223 layer_factory.hpp:77] Creating layer Scale42
I1003 09:37:45.207756  7223 net.cpp:84] Creating Layer Scale42
I1003 09:37:45.207757  7223 net.cpp:406] Scale42 <- Convolution42
I1003 09:37:45.207761  7223 net.cpp:367] Scale42 -> Convolution42 (in-place)
I1003 09:37:45.207788  7223 layer_factory.hpp:77] Creating layer Scale42
I1003 09:37:45.207877  7223 net.cpp:122] Setting up Scale42
I1003 09:37:45.207882  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.207885  7223 net.cpp:137] Memory required for data: 805011600
I1003 09:37:45.207888  7223 layer_factory.hpp:77] Creating layer M2PELU40
I1003 09:37:45.207893  7223 net.cpp:84] Creating Layer M2PELU40
I1003 09:37:45.207896  7223 net.cpp:406] M2PELU40 <- Convolution42
I1003 09:37:45.207900  7223 net.cpp:367] M2PELU40 -> Convolution42 (in-place)
I1003 09:37:45.207988  7223 net.cpp:122] Setting up M2PELU40
I1003 09:37:45.207993  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.207994  7223 net.cpp:137] Memory required for data: 806266000
I1003 09:37:45.207998  7223 layer_factory.hpp:77] Creating layer Convolution43
I1003 09:37:45.208004  7223 net.cpp:84] Creating Layer Convolution43
I1003 09:37:45.208008  7223 net.cpp:406] Convolution43 <- Convolution42
I1003 09:37:45.208011  7223 net.cpp:380] Convolution43 -> Convolution43
I1003 09:37:45.210260  7223 net.cpp:122] Setting up Convolution43
I1003 09:37:45.210268  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.210271  7223 net.cpp:137] Memory required for data: 807520400
I1003 09:37:45.210276  7223 layer_factory.hpp:77] Creating layer BatchNorm43
I1003 09:37:45.210281  7223 net.cpp:84] Creating Layer BatchNorm43
I1003 09:37:45.210284  7223 net.cpp:406] BatchNorm43 <- Convolution43
I1003 09:37:45.210289  7223 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I1003 09:37:45.210428  7223 net.cpp:122] Setting up BatchNorm43
I1003 09:37:45.210433  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.210434  7223 net.cpp:137] Memory required for data: 808774800
I1003 09:37:45.210439  7223 layer_factory.hpp:77] Creating layer Scale43
I1003 09:37:45.210444  7223 net.cpp:84] Creating Layer Scale43
I1003 09:37:45.210446  7223 net.cpp:406] Scale43 <- Convolution43
I1003 09:37:45.210449  7223 net.cpp:367] Scale43 -> Convolution43 (in-place)
I1003 09:37:45.210476  7223 layer_factory.hpp:77] Creating layer Scale43
I1003 09:37:45.210562  7223 net.cpp:122] Setting up Scale43
I1003 09:37:45.210567  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.210569  7223 net.cpp:137] Memory required for data: 810029200
I1003 09:37:45.210573  7223 layer_factory.hpp:77] Creating layer Eltwise20
I1003 09:37:45.210577  7223 net.cpp:84] Creating Layer Eltwise20
I1003 09:37:45.210579  7223 net.cpp:406] Eltwise20 <- Eltwise19_M2PELU39_0_split_1
I1003 09:37:45.210582  7223 net.cpp:406] Eltwise20 <- Convolution43
I1003 09:37:45.210587  7223 net.cpp:380] Eltwise20 -> Eltwise20
I1003 09:37:45.210602  7223 net.cpp:122] Setting up Eltwise20
I1003 09:37:45.210606  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.210608  7223 net.cpp:137] Memory required for data: 811283600
I1003 09:37:45.210610  7223 layer_factory.hpp:77] Creating layer M2PELU41
I1003 09:37:45.210615  7223 net.cpp:84] Creating Layer M2PELU41
I1003 09:37:45.210618  7223 net.cpp:406] M2PELU41 <- Eltwise20
I1003 09:37:45.210621  7223 net.cpp:367] M2PELU41 -> Eltwise20 (in-place)
I1003 09:37:45.210708  7223 net.cpp:122] Setting up M2PELU41
I1003 09:37:45.210712  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.210714  7223 net.cpp:137] Memory required for data: 812538000
I1003 09:37:45.210718  7223 layer_factory.hpp:77] Creating layer Eltwise20_M2PELU41_0_split
I1003 09:37:45.210722  7223 net.cpp:84] Creating Layer Eltwise20_M2PELU41_0_split
I1003 09:37:45.210724  7223 net.cpp:406] Eltwise20_M2PELU41_0_split <- Eltwise20
I1003 09:37:45.210727  7223 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_0
I1003 09:37:45.210731  7223 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_1
I1003 09:37:45.210755  7223 net.cpp:122] Setting up Eltwise20_M2PELU41_0_split
I1003 09:37:45.210758  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.210762  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.210763  7223 net.cpp:137] Memory required for data: 815046800
I1003 09:37:45.210772  7223 layer_factory.hpp:77] Creating layer Convolution44
I1003 09:37:45.210778  7223 net.cpp:84] Creating Layer Convolution44
I1003 09:37:45.210781  7223 net.cpp:406] Convolution44 <- Eltwise20_M2PELU41_0_split_0
I1003 09:37:45.210785  7223 net.cpp:380] Convolution44 -> Convolution44
I1003 09:37:45.212455  7223 net.cpp:122] Setting up Convolution44
I1003 09:37:45.212462  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.212466  7223 net.cpp:137] Memory required for data: 816301200
I1003 09:37:45.212469  7223 layer_factory.hpp:77] Creating layer BatchNorm44
I1003 09:37:45.212473  7223 net.cpp:84] Creating Layer BatchNorm44
I1003 09:37:45.212476  7223 net.cpp:406] BatchNorm44 <- Convolution44
I1003 09:37:45.212481  7223 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I1003 09:37:45.212620  7223 net.cpp:122] Setting up BatchNorm44
I1003 09:37:45.212625  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.212627  7223 net.cpp:137] Memory required for data: 817555600
I1003 09:37:45.212631  7223 layer_factory.hpp:77] Creating layer Scale44
I1003 09:37:45.212635  7223 net.cpp:84] Creating Layer Scale44
I1003 09:37:45.212638  7223 net.cpp:406] Scale44 <- Convolution44
I1003 09:37:45.212642  7223 net.cpp:367] Scale44 -> Convolution44 (in-place)
I1003 09:37:45.212668  7223 layer_factory.hpp:77] Creating layer Scale44
I1003 09:37:45.212748  7223 net.cpp:122] Setting up Scale44
I1003 09:37:45.212752  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.212754  7223 net.cpp:137] Memory required for data: 818810000
I1003 09:37:45.212757  7223 layer_factory.hpp:77] Creating layer M2PELU42
I1003 09:37:45.212764  7223 net.cpp:84] Creating Layer M2PELU42
I1003 09:37:45.212765  7223 net.cpp:406] M2PELU42 <- Convolution44
I1003 09:37:45.212769  7223 net.cpp:367] M2PELU42 -> Convolution44 (in-place)
I1003 09:37:45.212857  7223 net.cpp:122] Setting up M2PELU42
I1003 09:37:45.212860  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.212862  7223 net.cpp:137] Memory required for data: 820064400
I1003 09:37:45.212865  7223 layer_factory.hpp:77] Creating layer Convolution45
I1003 09:37:45.212872  7223 net.cpp:84] Creating Layer Convolution45
I1003 09:37:45.212875  7223 net.cpp:406] Convolution45 <- Convolution44
I1003 09:37:45.212879  7223 net.cpp:380] Convolution45 -> Convolution45
I1003 09:37:45.214845  7223 net.cpp:122] Setting up Convolution45
I1003 09:37:45.214854  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.214857  7223 net.cpp:137] Memory required for data: 821318800
I1003 09:37:45.214861  7223 layer_factory.hpp:77] Creating layer BatchNorm45
I1003 09:37:45.214866  7223 net.cpp:84] Creating Layer BatchNorm45
I1003 09:37:45.214869  7223 net.cpp:406] BatchNorm45 <- Convolution45
I1003 09:37:45.214874  7223 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I1003 09:37:45.215018  7223 net.cpp:122] Setting up BatchNorm45
I1003 09:37:45.215021  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.215023  7223 net.cpp:137] Memory required for data: 822573200
I1003 09:37:45.215029  7223 layer_factory.hpp:77] Creating layer Scale45
I1003 09:37:45.215034  7223 net.cpp:84] Creating Layer Scale45
I1003 09:37:45.215035  7223 net.cpp:406] Scale45 <- Convolution45
I1003 09:37:45.215039  7223 net.cpp:367] Scale45 -> Convolution45 (in-place)
I1003 09:37:45.215066  7223 layer_factory.hpp:77] Creating layer Scale45
I1003 09:37:45.215148  7223 net.cpp:122] Setting up Scale45
I1003 09:37:45.215153  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.215155  7223 net.cpp:137] Memory required for data: 823827600
I1003 09:37:45.215158  7223 layer_factory.hpp:77] Creating layer Eltwise21
I1003 09:37:45.215163  7223 net.cpp:84] Creating Layer Eltwise21
I1003 09:37:45.215167  7223 net.cpp:406] Eltwise21 <- Eltwise20_M2PELU41_0_split_1
I1003 09:37:45.215168  7223 net.cpp:406] Eltwise21 <- Convolution45
I1003 09:37:45.215173  7223 net.cpp:380] Eltwise21 -> Eltwise21
I1003 09:37:45.215189  7223 net.cpp:122] Setting up Eltwise21
I1003 09:37:45.215200  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.215203  7223 net.cpp:137] Memory required for data: 825082000
I1003 09:37:45.215204  7223 layer_factory.hpp:77] Creating layer M2PELU43
I1003 09:37:45.215210  7223 net.cpp:84] Creating Layer M2PELU43
I1003 09:37:45.215212  7223 net.cpp:406] M2PELU43 <- Eltwise21
I1003 09:37:45.215215  7223 net.cpp:367] M2PELU43 -> Eltwise21 (in-place)
I1003 09:37:45.215306  7223 net.cpp:122] Setting up M2PELU43
I1003 09:37:45.215309  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.215312  7223 net.cpp:137] Memory required for data: 826336400
I1003 09:37:45.215315  7223 layer_factory.hpp:77] Creating layer Eltwise21_M2PELU43_0_split
I1003 09:37:45.215319  7223 net.cpp:84] Creating Layer Eltwise21_M2PELU43_0_split
I1003 09:37:45.215322  7223 net.cpp:406] Eltwise21_M2PELU43_0_split <- Eltwise21
I1003 09:37:45.215325  7223 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_0
I1003 09:37:45.215329  7223 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_1
I1003 09:37:45.215353  7223 net.cpp:122] Setting up Eltwise21_M2PELU43_0_split
I1003 09:37:45.215358  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.215359  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.215363  7223 net.cpp:137] Memory required for data: 828845200
I1003 09:37:45.215364  7223 layer_factory.hpp:77] Creating layer Convolution46
I1003 09:37:45.215370  7223 net.cpp:84] Creating Layer Convolution46
I1003 09:37:45.215373  7223 net.cpp:406] Convolution46 <- Eltwise21_M2PELU43_0_split_0
I1003 09:37:45.215376  7223 net.cpp:380] Convolution46 -> Convolution46
I1003 09:37:45.217030  7223 net.cpp:122] Setting up Convolution46
I1003 09:37:45.217038  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.217041  7223 net.cpp:137] Memory required for data: 830099600
I1003 09:37:45.217046  7223 layer_factory.hpp:77] Creating layer BatchNorm46
I1003 09:37:45.217051  7223 net.cpp:84] Creating Layer BatchNorm46
I1003 09:37:45.217053  7223 net.cpp:406] BatchNorm46 <- Convolution46
I1003 09:37:45.217057  7223 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I1003 09:37:45.217198  7223 net.cpp:122] Setting up BatchNorm46
I1003 09:37:45.217203  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.217206  7223 net.cpp:137] Memory required for data: 831354000
I1003 09:37:45.217211  7223 layer_factory.hpp:77] Creating layer Scale46
I1003 09:37:45.217213  7223 net.cpp:84] Creating Layer Scale46
I1003 09:37:45.217216  7223 net.cpp:406] Scale46 <- Convolution46
I1003 09:37:45.217219  7223 net.cpp:367] Scale46 -> Convolution46 (in-place)
I1003 09:37:45.217247  7223 layer_factory.hpp:77] Creating layer Scale46
I1003 09:37:45.217329  7223 net.cpp:122] Setting up Scale46
I1003 09:37:45.217332  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.217334  7223 net.cpp:137] Memory required for data: 832608400
I1003 09:37:45.217339  7223 layer_factory.hpp:77] Creating layer M2PELU44
I1003 09:37:45.217342  7223 net.cpp:84] Creating Layer M2PELU44
I1003 09:37:45.217345  7223 net.cpp:406] M2PELU44 <- Convolution46
I1003 09:37:45.217350  7223 net.cpp:367] M2PELU44 -> Convolution46 (in-place)
I1003 09:37:45.217438  7223 net.cpp:122] Setting up M2PELU44
I1003 09:37:45.217442  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.217444  7223 net.cpp:137] Memory required for data: 833862800
I1003 09:37:45.217448  7223 layer_factory.hpp:77] Creating layer Convolution47
I1003 09:37:45.217455  7223 net.cpp:84] Creating Layer Convolution47
I1003 09:37:45.217458  7223 net.cpp:406] Convolution47 <- Convolution46
I1003 09:37:45.217461  7223 net.cpp:380] Convolution47 -> Convolution47
I1003 09:37:45.219096  7223 net.cpp:122] Setting up Convolution47
I1003 09:37:45.219105  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.219107  7223 net.cpp:137] Memory required for data: 835117200
I1003 09:37:45.219112  7223 layer_factory.hpp:77] Creating layer BatchNorm47
I1003 09:37:45.219117  7223 net.cpp:84] Creating Layer BatchNorm47
I1003 09:37:45.219126  7223 net.cpp:406] BatchNorm47 <- Convolution47
I1003 09:37:45.219130  7223 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I1003 09:37:45.219274  7223 net.cpp:122] Setting up BatchNorm47
I1003 09:37:45.219279  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.219280  7223 net.cpp:137] Memory required for data: 836371600
I1003 09:37:45.219285  7223 layer_factory.hpp:77] Creating layer Scale47
I1003 09:37:45.219290  7223 net.cpp:84] Creating Layer Scale47
I1003 09:37:45.219291  7223 net.cpp:406] Scale47 <- Convolution47
I1003 09:37:45.219295  7223 net.cpp:367] Scale47 -> Convolution47 (in-place)
I1003 09:37:45.219323  7223 layer_factory.hpp:77] Creating layer Scale47
I1003 09:37:45.219403  7223 net.cpp:122] Setting up Scale47
I1003 09:37:45.219408  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.219409  7223 net.cpp:137] Memory required for data: 837626000
I1003 09:37:45.219413  7223 layer_factory.hpp:77] Creating layer Eltwise22
I1003 09:37:45.219418  7223 net.cpp:84] Creating Layer Eltwise22
I1003 09:37:45.219420  7223 net.cpp:406] Eltwise22 <- Eltwise21_M2PELU43_0_split_1
I1003 09:37:45.219424  7223 net.cpp:406] Eltwise22 <- Convolution47
I1003 09:37:45.219426  7223 net.cpp:380] Eltwise22 -> Eltwise22
I1003 09:37:45.219444  7223 net.cpp:122] Setting up Eltwise22
I1003 09:37:45.219447  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.219449  7223 net.cpp:137] Memory required for data: 838880400
I1003 09:37:45.219451  7223 layer_factory.hpp:77] Creating layer M2PELU45
I1003 09:37:45.219456  7223 net.cpp:84] Creating Layer M2PELU45
I1003 09:37:45.219458  7223 net.cpp:406] M2PELU45 <- Eltwise22
I1003 09:37:45.219462  7223 net.cpp:367] M2PELU45 -> Eltwise22 (in-place)
I1003 09:37:45.219552  7223 net.cpp:122] Setting up M2PELU45
I1003 09:37:45.219555  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.219558  7223 net.cpp:137] Memory required for data: 840134800
I1003 09:37:45.219561  7223 layer_factory.hpp:77] Creating layer Eltwise22_M2PELU45_0_split
I1003 09:37:45.219564  7223 net.cpp:84] Creating Layer Eltwise22_M2PELU45_0_split
I1003 09:37:45.219566  7223 net.cpp:406] Eltwise22_M2PELU45_0_split <- Eltwise22
I1003 09:37:45.219570  7223 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_0
I1003 09:37:45.219575  7223 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_1
I1003 09:37:45.219599  7223 net.cpp:122] Setting up Eltwise22_M2PELU45_0_split
I1003 09:37:45.219602  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.219605  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.219607  7223 net.cpp:137] Memory required for data: 842643600
I1003 09:37:45.219609  7223 layer_factory.hpp:77] Creating layer Convolution48
I1003 09:37:45.219615  7223 net.cpp:84] Creating Layer Convolution48
I1003 09:37:45.219619  7223 net.cpp:406] Convolution48 <- Eltwise22_M2PELU45_0_split_0
I1003 09:37:45.219622  7223 net.cpp:380] Convolution48 -> Convolution48
I1003 09:37:45.221258  7223 net.cpp:122] Setting up Convolution48
I1003 09:37:45.221266  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.221269  7223 net.cpp:137] Memory required for data: 843898000
I1003 09:37:45.221273  7223 layer_factory.hpp:77] Creating layer BatchNorm48
I1003 09:37:45.221279  7223 net.cpp:84] Creating Layer BatchNorm48
I1003 09:37:45.221282  7223 net.cpp:406] BatchNorm48 <- Convolution48
I1003 09:37:45.221287  7223 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I1003 09:37:45.221428  7223 net.cpp:122] Setting up BatchNorm48
I1003 09:37:45.221432  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.221434  7223 net.cpp:137] Memory required for data: 845152400
I1003 09:37:45.221439  7223 layer_factory.hpp:77] Creating layer Scale48
I1003 09:37:45.221444  7223 net.cpp:84] Creating Layer Scale48
I1003 09:37:45.221446  7223 net.cpp:406] Scale48 <- Convolution48
I1003 09:37:45.221451  7223 net.cpp:367] Scale48 -> Convolution48 (in-place)
I1003 09:37:45.221478  7223 layer_factory.hpp:77] Creating layer Scale48
I1003 09:37:45.221570  7223 net.cpp:122] Setting up Scale48
I1003 09:37:45.221575  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.221578  7223 net.cpp:137] Memory required for data: 846406800
I1003 09:37:45.221581  7223 layer_factory.hpp:77] Creating layer M2PELU46
I1003 09:37:45.221587  7223 net.cpp:84] Creating Layer M2PELU46
I1003 09:37:45.221590  7223 net.cpp:406] M2PELU46 <- Convolution48
I1003 09:37:45.221593  7223 net.cpp:367] M2PELU46 -> Convolution48 (in-place)
I1003 09:37:45.221681  7223 net.cpp:122] Setting up M2PELU46
I1003 09:37:45.221685  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.221688  7223 net.cpp:137] Memory required for data: 847661200
I1003 09:37:45.221691  7223 layer_factory.hpp:77] Creating layer Convolution49
I1003 09:37:45.221698  7223 net.cpp:84] Creating Layer Convolution49
I1003 09:37:45.221700  7223 net.cpp:406] Convolution49 <- Convolution48
I1003 09:37:45.221704  7223 net.cpp:380] Convolution49 -> Convolution49
I1003 09:37:45.223661  7223 net.cpp:122] Setting up Convolution49
I1003 09:37:45.223670  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.223672  7223 net.cpp:137] Memory required for data: 848915600
I1003 09:37:45.223677  7223 layer_factory.hpp:77] Creating layer BatchNorm49
I1003 09:37:45.223683  7223 net.cpp:84] Creating Layer BatchNorm49
I1003 09:37:45.223685  7223 net.cpp:406] BatchNorm49 <- Convolution49
I1003 09:37:45.223690  7223 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I1003 09:37:45.223834  7223 net.cpp:122] Setting up BatchNorm49
I1003 09:37:45.223839  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.223841  7223 net.cpp:137] Memory required for data: 850170000
I1003 09:37:45.223845  7223 layer_factory.hpp:77] Creating layer Scale49
I1003 09:37:45.223850  7223 net.cpp:84] Creating Layer Scale49
I1003 09:37:45.223852  7223 net.cpp:406] Scale49 <- Convolution49
I1003 09:37:45.223855  7223 net.cpp:367] Scale49 -> Convolution49 (in-place)
I1003 09:37:45.223884  7223 layer_factory.hpp:77] Creating layer Scale49
I1003 09:37:45.223966  7223 net.cpp:122] Setting up Scale49
I1003 09:37:45.223971  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.223973  7223 net.cpp:137] Memory required for data: 851424400
I1003 09:37:45.223978  7223 layer_factory.hpp:77] Creating layer Eltwise23
I1003 09:37:45.223981  7223 net.cpp:84] Creating Layer Eltwise23
I1003 09:37:45.223984  7223 net.cpp:406] Eltwise23 <- Eltwise22_M2PELU45_0_split_1
I1003 09:37:45.223987  7223 net.cpp:406] Eltwise23 <- Convolution49
I1003 09:37:45.223990  7223 net.cpp:380] Eltwise23 -> Eltwise23
I1003 09:37:45.224006  7223 net.cpp:122] Setting up Eltwise23
I1003 09:37:45.224010  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.224012  7223 net.cpp:137] Memory required for data: 852678800
I1003 09:37:45.224014  7223 layer_factory.hpp:77] Creating layer M2PELU47
I1003 09:37:45.224020  7223 net.cpp:84] Creating Layer M2PELU47
I1003 09:37:45.224022  7223 net.cpp:406] M2PELU47 <- Eltwise23
I1003 09:37:45.224025  7223 net.cpp:367] M2PELU47 -> Eltwise23 (in-place)
I1003 09:37:45.224114  7223 net.cpp:122] Setting up M2PELU47
I1003 09:37:45.224118  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.224120  7223 net.cpp:137] Memory required for data: 853933200
I1003 09:37:45.224124  7223 layer_factory.hpp:77] Creating layer Eltwise23_M2PELU47_0_split
I1003 09:37:45.224128  7223 net.cpp:84] Creating Layer Eltwise23_M2PELU47_0_split
I1003 09:37:45.224129  7223 net.cpp:406] Eltwise23_M2PELU47_0_split <- Eltwise23
I1003 09:37:45.224133  7223 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_0
I1003 09:37:45.224138  7223 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_1
I1003 09:37:45.224162  7223 net.cpp:122] Setting up Eltwise23_M2PELU47_0_split
I1003 09:37:45.224166  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.224169  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.224170  7223 net.cpp:137] Memory required for data: 856442000
I1003 09:37:45.224179  7223 layer_factory.hpp:77] Creating layer Convolution50
I1003 09:37:45.224186  7223 net.cpp:84] Creating Layer Convolution50
I1003 09:37:45.224189  7223 net.cpp:406] Convolution50 <- Eltwise23_M2PELU47_0_split_0
I1003 09:37:45.224194  7223 net.cpp:380] Convolution50 -> Convolution50
I1003 09:37:45.225847  7223 net.cpp:122] Setting up Convolution50
I1003 09:37:45.225854  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.225857  7223 net.cpp:137] Memory required for data: 857696400
I1003 09:37:45.225862  7223 layer_factory.hpp:77] Creating layer BatchNorm50
I1003 09:37:45.225867  7223 net.cpp:84] Creating Layer BatchNorm50
I1003 09:37:45.225870  7223 net.cpp:406] BatchNorm50 <- Convolution50
I1003 09:37:45.225874  7223 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I1003 09:37:45.226019  7223 net.cpp:122] Setting up BatchNorm50
I1003 09:37:45.226023  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.233743  7223 net.cpp:137] Memory required for data: 858950800
I1003 09:37:45.233755  7223 layer_factory.hpp:77] Creating layer Scale50
I1003 09:37:45.233762  7223 net.cpp:84] Creating Layer Scale50
I1003 09:37:45.233767  7223 net.cpp:406] Scale50 <- Convolution50
I1003 09:37:45.233770  7223 net.cpp:367] Scale50 -> Convolution50 (in-place)
I1003 09:37:45.233814  7223 layer_factory.hpp:77] Creating layer Scale50
I1003 09:37:45.233911  7223 net.cpp:122] Setting up Scale50
I1003 09:37:45.233916  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.233918  7223 net.cpp:137] Memory required for data: 860205200
I1003 09:37:45.233922  7223 layer_factory.hpp:77] Creating layer M2PELU48
I1003 09:37:45.233928  7223 net.cpp:84] Creating Layer M2PELU48
I1003 09:37:45.233932  7223 net.cpp:406] M2PELU48 <- Convolution50
I1003 09:37:45.233935  7223 net.cpp:367] M2PELU48 -> Convolution50 (in-place)
I1003 09:37:45.234036  7223 net.cpp:122] Setting up M2PELU48
I1003 09:37:45.234042  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.234045  7223 net.cpp:137] Memory required for data: 861459600
I1003 09:37:45.234048  7223 layer_factory.hpp:77] Creating layer Convolution51
I1003 09:37:45.234055  7223 net.cpp:84] Creating Layer Convolution51
I1003 09:37:45.234058  7223 net.cpp:406] Convolution51 <- Convolution50
I1003 09:37:45.234062  7223 net.cpp:380] Convolution51 -> Convolution51
I1003 09:37:45.236452  7223 net.cpp:122] Setting up Convolution51
I1003 09:37:45.236462  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.236465  7223 net.cpp:137] Memory required for data: 862714000
I1003 09:37:45.236470  7223 layer_factory.hpp:77] Creating layer BatchNorm51
I1003 09:37:45.236476  7223 net.cpp:84] Creating Layer BatchNorm51
I1003 09:37:45.236479  7223 net.cpp:406] BatchNorm51 <- Convolution51
I1003 09:37:45.236482  7223 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I1003 09:37:45.236631  7223 net.cpp:122] Setting up BatchNorm51
I1003 09:37:45.236636  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.236639  7223 net.cpp:137] Memory required for data: 863968400
I1003 09:37:45.236644  7223 layer_factory.hpp:77] Creating layer Scale51
I1003 09:37:45.236647  7223 net.cpp:84] Creating Layer Scale51
I1003 09:37:45.236649  7223 net.cpp:406] Scale51 <- Convolution51
I1003 09:37:45.236652  7223 net.cpp:367] Scale51 -> Convolution51 (in-place)
I1003 09:37:45.236682  7223 layer_factory.hpp:77] Creating layer Scale51
I1003 09:37:45.236768  7223 net.cpp:122] Setting up Scale51
I1003 09:37:45.236773  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.236775  7223 net.cpp:137] Memory required for data: 865222800
I1003 09:37:45.236778  7223 layer_factory.hpp:77] Creating layer Eltwise24
I1003 09:37:45.236783  7223 net.cpp:84] Creating Layer Eltwise24
I1003 09:37:45.236786  7223 net.cpp:406] Eltwise24 <- Eltwise23_M2PELU47_0_split_1
I1003 09:37:45.236789  7223 net.cpp:406] Eltwise24 <- Convolution51
I1003 09:37:45.236793  7223 net.cpp:380] Eltwise24 -> Eltwise24
I1003 09:37:45.236809  7223 net.cpp:122] Setting up Eltwise24
I1003 09:37:45.236820  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.236824  7223 net.cpp:137] Memory required for data: 866477200
I1003 09:37:45.236825  7223 layer_factory.hpp:77] Creating layer M2PELU49
I1003 09:37:45.236830  7223 net.cpp:84] Creating Layer M2PELU49
I1003 09:37:45.236834  7223 net.cpp:406] M2PELU49 <- Eltwise24
I1003 09:37:45.236836  7223 net.cpp:367] M2PELU49 -> Eltwise24 (in-place)
I1003 09:37:45.236930  7223 net.cpp:122] Setting up M2PELU49
I1003 09:37:45.236934  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.236937  7223 net.cpp:137] Memory required for data: 867731600
I1003 09:37:45.236940  7223 layer_factory.hpp:77] Creating layer Eltwise24_M2PELU49_0_split
I1003 09:37:45.236944  7223 net.cpp:84] Creating Layer Eltwise24_M2PELU49_0_split
I1003 09:37:45.236946  7223 net.cpp:406] Eltwise24_M2PELU49_0_split <- Eltwise24
I1003 09:37:45.236949  7223 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_0
I1003 09:37:45.236953  7223 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_1
I1003 09:37:45.236979  7223 net.cpp:122] Setting up Eltwise24_M2PELU49_0_split
I1003 09:37:45.236984  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.236985  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.236987  7223 net.cpp:137] Memory required for data: 870240400
I1003 09:37:45.236989  7223 layer_factory.hpp:77] Creating layer Convolution52
I1003 09:37:45.236996  7223 net.cpp:84] Creating Layer Convolution52
I1003 09:37:45.236999  7223 net.cpp:406] Convolution52 <- Eltwise24_M2PELU49_0_split_0
I1003 09:37:45.237002  7223 net.cpp:380] Convolution52 -> Convolution52
I1003 09:37:45.238755  7223 net.cpp:122] Setting up Convolution52
I1003 09:37:45.238765  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.238766  7223 net.cpp:137] Memory required for data: 871494800
I1003 09:37:45.238771  7223 layer_factory.hpp:77] Creating layer BatchNorm52
I1003 09:37:45.238776  7223 net.cpp:84] Creating Layer BatchNorm52
I1003 09:37:45.238778  7223 net.cpp:406] BatchNorm52 <- Convolution52
I1003 09:37:45.238782  7223 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I1003 09:37:45.238927  7223 net.cpp:122] Setting up BatchNorm52
I1003 09:37:45.238932  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.238934  7223 net.cpp:137] Memory required for data: 872749200
I1003 09:37:45.238940  7223 layer_factory.hpp:77] Creating layer Scale52
I1003 09:37:45.238943  7223 net.cpp:84] Creating Layer Scale52
I1003 09:37:45.238946  7223 net.cpp:406] Scale52 <- Convolution52
I1003 09:37:45.238950  7223 net.cpp:367] Scale52 -> Convolution52 (in-place)
I1003 09:37:45.238978  7223 layer_factory.hpp:77] Creating layer Scale52
I1003 09:37:45.239063  7223 net.cpp:122] Setting up Scale52
I1003 09:37:45.239066  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.239068  7223 net.cpp:137] Memory required for data: 874003600
I1003 09:37:45.239073  7223 layer_factory.hpp:77] Creating layer M2PELU50
I1003 09:37:45.239078  7223 net.cpp:84] Creating Layer M2PELU50
I1003 09:37:45.239080  7223 net.cpp:406] M2PELU50 <- Convolution52
I1003 09:37:45.239084  7223 net.cpp:367] M2PELU50 -> Convolution52 (in-place)
I1003 09:37:45.239174  7223 net.cpp:122] Setting up M2PELU50
I1003 09:37:45.239178  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.239181  7223 net.cpp:137] Memory required for data: 875258000
I1003 09:37:45.239184  7223 layer_factory.hpp:77] Creating layer Convolution53
I1003 09:37:45.239208  7223 net.cpp:84] Creating Layer Convolution53
I1003 09:37:45.239212  7223 net.cpp:406] Convolution53 <- Convolution52
I1003 09:37:45.239215  7223 net.cpp:380] Convolution53 -> Convolution53
I1003 09:37:45.241192  7223 net.cpp:122] Setting up Convolution53
I1003 09:37:45.241202  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.241205  7223 net.cpp:137] Memory required for data: 876512400
I1003 09:37:45.241209  7223 layer_factory.hpp:77] Creating layer BatchNorm53
I1003 09:37:45.241214  7223 net.cpp:84] Creating Layer BatchNorm53
I1003 09:37:45.241225  7223 net.cpp:406] BatchNorm53 <- Convolution53
I1003 09:37:45.241228  7223 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I1003 09:37:45.241377  7223 net.cpp:122] Setting up BatchNorm53
I1003 09:37:45.241382  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.241384  7223 net.cpp:137] Memory required for data: 877766800
I1003 09:37:45.241389  7223 layer_factory.hpp:77] Creating layer Scale53
I1003 09:37:45.241394  7223 net.cpp:84] Creating Layer Scale53
I1003 09:37:45.241395  7223 net.cpp:406] Scale53 <- Convolution53
I1003 09:37:45.241400  7223 net.cpp:367] Scale53 -> Convolution53 (in-place)
I1003 09:37:45.241428  7223 layer_factory.hpp:77] Creating layer Scale53
I1003 09:37:45.241511  7223 net.cpp:122] Setting up Scale53
I1003 09:37:45.241518  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.241519  7223 net.cpp:137] Memory required for data: 879021200
I1003 09:37:45.241523  7223 layer_factory.hpp:77] Creating layer Eltwise25
I1003 09:37:45.241528  7223 net.cpp:84] Creating Layer Eltwise25
I1003 09:37:45.241530  7223 net.cpp:406] Eltwise25 <- Eltwise24_M2PELU49_0_split_1
I1003 09:37:45.241533  7223 net.cpp:406] Eltwise25 <- Convolution53
I1003 09:37:45.241536  7223 net.cpp:380] Eltwise25 -> Eltwise25
I1003 09:37:45.241554  7223 net.cpp:122] Setting up Eltwise25
I1003 09:37:45.241557  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.241559  7223 net.cpp:137] Memory required for data: 880275600
I1003 09:37:45.241561  7223 layer_factory.hpp:77] Creating layer M2PELU51
I1003 09:37:45.241566  7223 net.cpp:84] Creating Layer M2PELU51
I1003 09:37:45.241569  7223 net.cpp:406] M2PELU51 <- Eltwise25
I1003 09:37:45.241571  7223 net.cpp:367] M2PELU51 -> Eltwise25 (in-place)
I1003 09:37:45.241663  7223 net.cpp:122] Setting up M2PELU51
I1003 09:37:45.241667  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.241669  7223 net.cpp:137] Memory required for data: 881530000
I1003 09:37:45.241673  7223 layer_factory.hpp:77] Creating layer Eltwise25_M2PELU51_0_split
I1003 09:37:45.241677  7223 net.cpp:84] Creating Layer Eltwise25_M2PELU51_0_split
I1003 09:37:45.241679  7223 net.cpp:406] Eltwise25_M2PELU51_0_split <- Eltwise25
I1003 09:37:45.241683  7223 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_0
I1003 09:37:45.241686  7223 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_1
I1003 09:37:45.241711  7223 net.cpp:122] Setting up Eltwise25_M2PELU51_0_split
I1003 09:37:45.241714  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.241717  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.241719  7223 net.cpp:137] Memory required for data: 884038800
I1003 09:37:45.241721  7223 layer_factory.hpp:77] Creating layer Convolution54
I1003 09:37:45.241727  7223 net.cpp:84] Creating Layer Convolution54
I1003 09:37:45.241730  7223 net.cpp:406] Convolution54 <- Eltwise25_M2PELU51_0_split_0
I1003 09:37:45.241734  7223 net.cpp:380] Convolution54 -> Convolution54
I1003 09:37:45.243897  7223 net.cpp:122] Setting up Convolution54
I1003 09:37:45.243906  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.243909  7223 net.cpp:137] Memory required for data: 885293200
I1003 09:37:45.243913  7223 layer_factory.hpp:77] Creating layer BatchNorm54
I1003 09:37:45.243918  7223 net.cpp:84] Creating Layer BatchNorm54
I1003 09:37:45.243921  7223 net.cpp:406] BatchNorm54 <- Convolution54
I1003 09:37:45.243926  7223 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I1003 09:37:45.244073  7223 net.cpp:122] Setting up BatchNorm54
I1003 09:37:45.244077  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.244079  7223 net.cpp:137] Memory required for data: 886547600
I1003 09:37:45.244084  7223 layer_factory.hpp:77] Creating layer Scale54
I1003 09:37:45.244088  7223 net.cpp:84] Creating Layer Scale54
I1003 09:37:45.244091  7223 net.cpp:406] Scale54 <- Convolution54
I1003 09:37:45.244094  7223 net.cpp:367] Scale54 -> Convolution54 (in-place)
I1003 09:37:45.244123  7223 layer_factory.hpp:77] Creating layer Scale54
I1003 09:37:45.244217  7223 net.cpp:122] Setting up Scale54
I1003 09:37:45.244222  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.244225  7223 net.cpp:137] Memory required for data: 887802000
I1003 09:37:45.244228  7223 layer_factory.hpp:77] Creating layer M2PELU52
I1003 09:37:45.244233  7223 net.cpp:84] Creating Layer M2PELU52
I1003 09:37:45.244236  7223 net.cpp:406] M2PELU52 <- Convolution54
I1003 09:37:45.244240  7223 net.cpp:367] M2PELU52 -> Convolution54 (in-place)
I1003 09:37:45.244333  7223 net.cpp:122] Setting up M2PELU52
I1003 09:37:45.244336  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.244338  7223 net.cpp:137] Memory required for data: 889056400
I1003 09:37:45.244343  7223 layer_factory.hpp:77] Creating layer Convolution55
I1003 09:37:45.244349  7223 net.cpp:84] Creating Layer Convolution55
I1003 09:37:45.244351  7223 net.cpp:406] Convolution55 <- Convolution54
I1003 09:37:45.244356  7223 net.cpp:380] Convolution55 -> Convolution55
I1003 09:37:45.246350  7223 net.cpp:122] Setting up Convolution55
I1003 09:37:45.246357  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.246361  7223 net.cpp:137] Memory required for data: 890310800
I1003 09:37:45.246366  7223 layer_factory.hpp:77] Creating layer BatchNorm55
I1003 09:37:45.246371  7223 net.cpp:84] Creating Layer BatchNorm55
I1003 09:37:45.246373  7223 net.cpp:406] BatchNorm55 <- Convolution55
I1003 09:37:45.246377  7223 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I1003 09:37:45.246533  7223 net.cpp:122] Setting up BatchNorm55
I1003 09:37:45.246538  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.246541  7223 net.cpp:137] Memory required for data: 891565200
I1003 09:37:45.246546  7223 layer_factory.hpp:77] Creating layer Scale55
I1003 09:37:45.246549  7223 net.cpp:84] Creating Layer Scale55
I1003 09:37:45.246552  7223 net.cpp:406] Scale55 <- Convolution55
I1003 09:37:45.246556  7223 net.cpp:367] Scale55 -> Convolution55 (in-place)
I1003 09:37:45.246585  7223 layer_factory.hpp:77] Creating layer Scale55
I1003 09:37:45.246672  7223 net.cpp:122] Setting up Scale55
I1003 09:37:45.246676  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.246680  7223 net.cpp:137] Memory required for data: 892819600
I1003 09:37:45.246682  7223 layer_factory.hpp:77] Creating layer Eltwise26
I1003 09:37:45.246687  7223 net.cpp:84] Creating Layer Eltwise26
I1003 09:37:45.246690  7223 net.cpp:406] Eltwise26 <- Eltwise25_M2PELU51_0_split_1
I1003 09:37:45.246693  7223 net.cpp:406] Eltwise26 <- Convolution55
I1003 09:37:45.246696  7223 net.cpp:380] Eltwise26 -> Eltwise26
I1003 09:37:45.246714  7223 net.cpp:122] Setting up Eltwise26
I1003 09:37:45.246718  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.246721  7223 net.cpp:137] Memory required for data: 894074000
I1003 09:37:45.246722  7223 layer_factory.hpp:77] Creating layer M2PELU53
I1003 09:37:45.246727  7223 net.cpp:84] Creating Layer M2PELU53
I1003 09:37:45.246729  7223 net.cpp:406] M2PELU53 <- Eltwise26
I1003 09:37:45.246733  7223 net.cpp:367] M2PELU53 -> Eltwise26 (in-place)
I1003 09:37:45.246825  7223 net.cpp:122] Setting up M2PELU53
I1003 09:37:45.246829  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.246831  7223 net.cpp:137] Memory required for data: 895328400
I1003 09:37:45.246834  7223 layer_factory.hpp:77] Creating layer Eltwise26_M2PELU53_0_split
I1003 09:37:45.246839  7223 net.cpp:84] Creating Layer Eltwise26_M2PELU53_0_split
I1003 09:37:45.246841  7223 net.cpp:406] Eltwise26_M2PELU53_0_split <- Eltwise26
I1003 09:37:45.246845  7223 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_0
I1003 09:37:45.246848  7223 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_1
I1003 09:37:45.246873  7223 net.cpp:122] Setting up Eltwise26_M2PELU53_0_split
I1003 09:37:45.246877  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.246879  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.246881  7223 net.cpp:137] Memory required for data: 897837200
I1003 09:37:45.246891  7223 layer_factory.hpp:77] Creating layer Convolution56
I1003 09:37:45.246896  7223 net.cpp:84] Creating Layer Convolution56
I1003 09:37:45.246899  7223 net.cpp:406] Convolution56 <- Eltwise26_M2PELU53_0_split_0
I1003 09:37:45.246903  7223 net.cpp:380] Convolution56 -> Convolution56
I1003 09:37:45.248569  7223 net.cpp:122] Setting up Convolution56
I1003 09:37:45.248579  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.248580  7223 net.cpp:137] Memory required for data: 899091600
I1003 09:37:45.248585  7223 layer_factory.hpp:77] Creating layer BatchNorm56
I1003 09:37:45.248591  7223 net.cpp:84] Creating Layer BatchNorm56
I1003 09:37:45.248594  7223 net.cpp:406] BatchNorm56 <- Convolution56
I1003 09:37:45.248597  7223 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I1003 09:37:45.264379  7223 net.cpp:122] Setting up BatchNorm56
I1003 09:37:45.264389  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.264392  7223 net.cpp:137] Memory required for data: 900346000
I1003 09:37:45.264398  7223 layer_factory.hpp:77] Creating layer Scale56
I1003 09:37:45.264403  7223 net.cpp:84] Creating Layer Scale56
I1003 09:37:45.264406  7223 net.cpp:406] Scale56 <- Convolution56
I1003 09:37:45.264411  7223 net.cpp:367] Scale56 -> Convolution56 (in-place)
I1003 09:37:45.264444  7223 layer_factory.hpp:77] Creating layer Scale56
I1003 09:37:45.264539  7223 net.cpp:122] Setting up Scale56
I1003 09:37:45.264544  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.264546  7223 net.cpp:137] Memory required for data: 901600400
I1003 09:37:45.264550  7223 layer_factory.hpp:77] Creating layer M2PELU54
I1003 09:37:45.264556  7223 net.cpp:84] Creating Layer M2PELU54
I1003 09:37:45.264559  7223 net.cpp:406] M2PELU54 <- Convolution56
I1003 09:37:45.264562  7223 net.cpp:367] M2PELU54 -> Convolution56 (in-place)
I1003 09:37:45.264668  7223 net.cpp:122] Setting up M2PELU54
I1003 09:37:45.264673  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.264675  7223 net.cpp:137] Memory required for data: 902854800
I1003 09:37:45.264679  7223 layer_factory.hpp:77] Creating layer Convolution57
I1003 09:37:45.264686  7223 net.cpp:84] Creating Layer Convolution57
I1003 09:37:45.264689  7223 net.cpp:406] Convolution57 <- Convolution56
I1003 09:37:45.264694  7223 net.cpp:380] Convolution57 -> Convolution57
I1003 09:37:45.266973  7223 net.cpp:122] Setting up Convolution57
I1003 09:37:45.266983  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.266985  7223 net.cpp:137] Memory required for data: 904109200
I1003 09:37:45.266990  7223 layer_factory.hpp:77] Creating layer BatchNorm57
I1003 09:37:45.266995  7223 net.cpp:84] Creating Layer BatchNorm57
I1003 09:37:45.266999  7223 net.cpp:406] BatchNorm57 <- Convolution57
I1003 09:37:45.267001  7223 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I1003 09:37:45.267155  7223 net.cpp:122] Setting up BatchNorm57
I1003 09:37:45.267159  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.267161  7223 net.cpp:137] Memory required for data: 905363600
I1003 09:37:45.267166  7223 layer_factory.hpp:77] Creating layer Scale57
I1003 09:37:45.267170  7223 net.cpp:84] Creating Layer Scale57
I1003 09:37:45.267172  7223 net.cpp:406] Scale57 <- Convolution57
I1003 09:37:45.267175  7223 net.cpp:367] Scale57 -> Convolution57 (in-place)
I1003 09:37:45.267206  7223 layer_factory.hpp:77] Creating layer Scale57
I1003 09:37:45.267292  7223 net.cpp:122] Setting up Scale57
I1003 09:37:45.267297  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.267299  7223 net.cpp:137] Memory required for data: 906618000
I1003 09:37:45.267303  7223 layer_factory.hpp:77] Creating layer Eltwise27
I1003 09:37:45.267307  7223 net.cpp:84] Creating Layer Eltwise27
I1003 09:37:45.267310  7223 net.cpp:406] Eltwise27 <- Eltwise26_M2PELU53_0_split_1
I1003 09:37:45.267313  7223 net.cpp:406] Eltwise27 <- Convolution57
I1003 09:37:45.267316  7223 net.cpp:380] Eltwise27 -> Eltwise27
I1003 09:37:45.267335  7223 net.cpp:122] Setting up Eltwise27
I1003 09:37:45.267346  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.267349  7223 net.cpp:137] Memory required for data: 907872400
I1003 09:37:45.267350  7223 layer_factory.hpp:77] Creating layer M2PELU55
I1003 09:37:45.267355  7223 net.cpp:84] Creating Layer M2PELU55
I1003 09:37:45.267359  7223 net.cpp:406] M2PELU55 <- Eltwise27
I1003 09:37:45.267361  7223 net.cpp:367] M2PELU55 -> Eltwise27 (in-place)
I1003 09:37:45.267458  7223 net.cpp:122] Setting up M2PELU55
I1003 09:37:45.267462  7223 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1003 09:37:45.267464  7223 net.cpp:137] Memory required for data: 909126800
I1003 09:37:45.267468  7223 layer_factory.hpp:77] Creating layer Pooling1
I1003 09:37:45.267472  7223 net.cpp:84] Creating Layer Pooling1
I1003 09:37:45.267474  7223 net.cpp:406] Pooling1 <- Eltwise27
I1003 09:37:45.267478  7223 net.cpp:380] Pooling1 -> Pooling1
I1003 09:37:45.268106  7223 net.cpp:122] Setting up Pooling1
I1003 09:37:45.268116  7223 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1003 09:37:45.268120  7223 net.cpp:137] Memory required for data: 909152400
I1003 09:37:45.268121  7223 layer_factory.hpp:77] Creating layer InnerProduct1
I1003 09:37:45.268132  7223 net.cpp:84] Creating Layer InnerProduct1
I1003 09:37:45.268136  7223 net.cpp:406] InnerProduct1 <- Pooling1
I1003 09:37:45.268139  7223 net.cpp:380] InnerProduct1 -> InnerProduct1
I1003 09:37:45.268250  7223 net.cpp:122] Setting up InnerProduct1
I1003 09:37:45.268255  7223 net.cpp:129] Top shape: 100 10 (1000)
I1003 09:37:45.268257  7223 net.cpp:137] Memory required for data: 909156400
I1003 09:37:45.268261  7223 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1003 09:37:45.268275  7223 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1003 09:37:45.268277  7223 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I1003 09:37:45.268280  7223 net.cpp:406] SoftmaxWithLoss1 <- Data2
I1003 09:37:45.268285  7223 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1003 09:37:45.268290  7223 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1003 09:37:45.268478  7223 net.cpp:122] Setting up SoftmaxWithLoss1
I1003 09:37:45.268484  7223 net.cpp:129] Top shape: (1)
I1003 09:37:45.268486  7223 net.cpp:132]     with loss weight 1
I1003 09:37:45.268498  7223 net.cpp:137] Memory required for data: 909156404
I1003 09:37:45.268501  7223 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1003 09:37:45.268503  7223 net.cpp:198] InnerProduct1 needs backward computation.
I1003 09:37:45.268506  7223 net.cpp:198] Pooling1 needs backward computation.
I1003 09:37:45.268508  7223 net.cpp:198] M2PELU55 needs backward computation.
I1003 09:37:45.268510  7223 net.cpp:198] Eltwise27 needs backward computation.
I1003 09:37:45.268512  7223 net.cpp:198] Scale57 needs backward computation.
I1003 09:37:45.268514  7223 net.cpp:198] BatchNorm57 needs backward computation.
I1003 09:37:45.268517  7223 net.cpp:198] Convolution57 needs backward computation.
I1003 09:37:45.268519  7223 net.cpp:198] M2PELU54 needs backward computation.
I1003 09:37:45.268522  7223 net.cpp:198] Scale56 needs backward computation.
I1003 09:37:45.268523  7223 net.cpp:198] BatchNorm56 needs backward computation.
I1003 09:37:45.268525  7223 net.cpp:198] Convolution56 needs backward computation.
I1003 09:37:45.268528  7223 net.cpp:198] Eltwise26_M2PELU53_0_split needs backward computation.
I1003 09:37:45.268530  7223 net.cpp:198] M2PELU53 needs backward computation.
I1003 09:37:45.268532  7223 net.cpp:198] Eltwise26 needs backward computation.
I1003 09:37:45.268535  7223 net.cpp:198] Scale55 needs backward computation.
I1003 09:37:45.268537  7223 net.cpp:198] BatchNorm55 needs backward computation.
I1003 09:37:45.268539  7223 net.cpp:198] Convolution55 needs backward computation.
I1003 09:37:45.268541  7223 net.cpp:198] M2PELU52 needs backward computation.
I1003 09:37:45.268543  7223 net.cpp:198] Scale54 needs backward computation.
I1003 09:37:45.268545  7223 net.cpp:198] BatchNorm54 needs backward computation.
I1003 09:37:45.268548  7223 net.cpp:198] Convolution54 needs backward computation.
I1003 09:37:45.268556  7223 net.cpp:198] Eltwise25_M2PELU51_0_split needs backward computation.
I1003 09:37:45.268559  7223 net.cpp:198] M2PELU51 needs backward computation.
I1003 09:37:45.268561  7223 net.cpp:198] Eltwise25 needs backward computation.
I1003 09:37:45.268563  7223 net.cpp:198] Scale53 needs backward computation.
I1003 09:37:45.268565  7223 net.cpp:198] BatchNorm53 needs backward computation.
I1003 09:37:45.268568  7223 net.cpp:198] Convolution53 needs backward computation.
I1003 09:37:45.268570  7223 net.cpp:198] M2PELU50 needs backward computation.
I1003 09:37:45.268573  7223 net.cpp:198] Scale52 needs backward computation.
I1003 09:37:45.268574  7223 net.cpp:198] BatchNorm52 needs backward computation.
I1003 09:37:45.268577  7223 net.cpp:198] Convolution52 needs backward computation.
I1003 09:37:45.268579  7223 net.cpp:198] Eltwise24_M2PELU49_0_split needs backward computation.
I1003 09:37:45.268581  7223 net.cpp:198] M2PELU49 needs backward computation.
I1003 09:37:45.268584  7223 net.cpp:198] Eltwise24 needs backward computation.
I1003 09:37:45.268586  7223 net.cpp:198] Scale51 needs backward computation.
I1003 09:37:45.268589  7223 net.cpp:198] BatchNorm51 needs backward computation.
I1003 09:37:45.268591  7223 net.cpp:198] Convolution51 needs backward computation.
I1003 09:37:45.268594  7223 net.cpp:198] M2PELU48 needs backward computation.
I1003 09:37:45.268595  7223 net.cpp:198] Scale50 needs backward computation.
I1003 09:37:45.268597  7223 net.cpp:198] BatchNorm50 needs backward computation.
I1003 09:37:45.268600  7223 net.cpp:198] Convolution50 needs backward computation.
I1003 09:37:45.268602  7223 net.cpp:198] Eltwise23_M2PELU47_0_split needs backward computation.
I1003 09:37:45.268605  7223 net.cpp:198] M2PELU47 needs backward computation.
I1003 09:37:45.268607  7223 net.cpp:198] Eltwise23 needs backward computation.
I1003 09:37:45.268610  7223 net.cpp:198] Scale49 needs backward computation.
I1003 09:37:45.268612  7223 net.cpp:198] BatchNorm49 needs backward computation.
I1003 09:37:45.268615  7223 net.cpp:198] Convolution49 needs backward computation.
I1003 09:37:45.268617  7223 net.cpp:198] M2PELU46 needs backward computation.
I1003 09:37:45.268620  7223 net.cpp:198] Scale48 needs backward computation.
I1003 09:37:45.268621  7223 net.cpp:198] BatchNorm48 needs backward computation.
I1003 09:37:45.268623  7223 net.cpp:198] Convolution48 needs backward computation.
I1003 09:37:45.268626  7223 net.cpp:198] Eltwise22_M2PELU45_0_split needs backward computation.
I1003 09:37:45.268628  7223 net.cpp:198] M2PELU45 needs backward computation.
I1003 09:37:45.268630  7223 net.cpp:198] Eltwise22 needs backward computation.
I1003 09:37:45.268633  7223 net.cpp:198] Scale47 needs backward computation.
I1003 09:37:45.268635  7223 net.cpp:198] BatchNorm47 needs backward computation.
I1003 09:37:45.268638  7223 net.cpp:198] Convolution47 needs backward computation.
I1003 09:37:45.268640  7223 net.cpp:198] M2PELU44 needs backward computation.
I1003 09:37:45.268642  7223 net.cpp:198] Scale46 needs backward computation.
I1003 09:37:45.268646  7223 net.cpp:198] BatchNorm46 needs backward computation.
I1003 09:37:45.268647  7223 net.cpp:198] Convolution46 needs backward computation.
I1003 09:37:45.268649  7223 net.cpp:198] Eltwise21_M2PELU43_0_split needs backward computation.
I1003 09:37:45.268652  7223 net.cpp:198] M2PELU43 needs backward computation.
I1003 09:37:45.268654  7223 net.cpp:198] Eltwise21 needs backward computation.
I1003 09:37:45.268657  7223 net.cpp:198] Scale45 needs backward computation.
I1003 09:37:45.268659  7223 net.cpp:198] BatchNorm45 needs backward computation.
I1003 09:37:45.268661  7223 net.cpp:198] Convolution45 needs backward computation.
I1003 09:37:45.268664  7223 net.cpp:198] M2PELU42 needs backward computation.
I1003 09:37:45.268666  7223 net.cpp:198] Scale44 needs backward computation.
I1003 09:37:45.268668  7223 net.cpp:198] BatchNorm44 needs backward computation.
I1003 09:37:45.268671  7223 net.cpp:198] Convolution44 needs backward computation.
I1003 09:37:45.268676  7223 net.cpp:198] Eltwise20_M2PELU41_0_split needs backward computation.
I1003 09:37:45.268678  7223 net.cpp:198] M2PELU41 needs backward computation.
I1003 09:37:45.268681  7223 net.cpp:198] Eltwise20 needs backward computation.
I1003 09:37:45.268683  7223 net.cpp:198] Scale43 needs backward computation.
I1003 09:37:45.268687  7223 net.cpp:198] BatchNorm43 needs backward computation.
I1003 09:37:45.268689  7223 net.cpp:198] Convolution43 needs backward computation.
I1003 09:37:45.268692  7223 net.cpp:198] M2PELU40 needs backward computation.
I1003 09:37:45.268693  7223 net.cpp:198] Scale42 needs backward computation.
I1003 09:37:45.268695  7223 net.cpp:198] BatchNorm42 needs backward computation.
I1003 09:37:45.268698  7223 net.cpp:198] Convolution42 needs backward computation.
I1003 09:37:45.268700  7223 net.cpp:198] Eltwise19_M2PELU39_0_split needs backward computation.
I1003 09:37:45.268703  7223 net.cpp:198] M2PELU39 needs backward computation.
I1003 09:37:45.268705  7223 net.cpp:198] Eltwise19 needs backward computation.
I1003 09:37:45.268708  7223 net.cpp:198] Scale41 needs backward computation.
I1003 09:37:45.268710  7223 net.cpp:198] BatchNorm41 needs backward computation.
I1003 09:37:45.268713  7223 net.cpp:198] Convolution41 needs backward computation.
I1003 09:37:45.268715  7223 net.cpp:198] M2PELU38 needs backward computation.
I1003 09:37:45.268718  7223 net.cpp:198] Scale40 needs backward computation.
I1003 09:37:45.268719  7223 net.cpp:198] BatchNorm40 needs backward computation.
I1003 09:37:45.268723  7223 net.cpp:198] Convolution40 needs backward computation.
I1003 09:37:45.268724  7223 net.cpp:198] Scale39 needs backward computation.
I1003 09:37:45.268728  7223 net.cpp:198] BatchNorm39 needs backward computation.
I1003 09:37:45.268729  7223 net.cpp:198] Convolution39 needs backward computation.
I1003 09:37:45.268731  7223 net.cpp:198] Eltwise18_M2PELU37_0_split needs backward computation.
I1003 09:37:45.268734  7223 net.cpp:198] M2PELU37 needs backward computation.
I1003 09:37:45.268736  7223 net.cpp:198] Eltwise18 needs backward computation.
I1003 09:37:45.268739  7223 net.cpp:198] Scale38 needs backward computation.
I1003 09:37:45.268741  7223 net.cpp:198] BatchNorm38 needs backward computation.
I1003 09:37:45.268744  7223 net.cpp:198] Convolution38 needs backward computation.
I1003 09:37:45.268746  7223 net.cpp:198] M2PELU36 needs backward computation.
I1003 09:37:45.268748  7223 net.cpp:198] Scale37 needs backward computation.
I1003 09:37:45.268751  7223 net.cpp:198] BatchNorm37 needs backward computation.
I1003 09:37:45.268754  7223 net.cpp:198] Convolution37 needs backward computation.
I1003 09:37:45.268755  7223 net.cpp:198] Eltwise17_M2PELU35_0_split needs backward computation.
I1003 09:37:45.268759  7223 net.cpp:198] M2PELU35 needs backward computation.
I1003 09:37:45.268760  7223 net.cpp:198] Eltwise17 needs backward computation.
I1003 09:37:45.268764  7223 net.cpp:198] Scale36 needs backward computation.
I1003 09:37:45.268765  7223 net.cpp:198] BatchNorm36 needs backward computation.
I1003 09:37:45.268767  7223 net.cpp:198] Convolution36 needs backward computation.
I1003 09:37:45.268770  7223 net.cpp:198] M2PELU34 needs backward computation.
I1003 09:37:45.268772  7223 net.cpp:198] Scale35 needs backward computation.
I1003 09:37:45.268774  7223 net.cpp:198] BatchNorm35 needs backward computation.
I1003 09:37:45.268776  7223 net.cpp:198] Convolution35 needs backward computation.
I1003 09:37:45.268779  7223 net.cpp:198] Eltwise16_M2PELU33_0_split needs backward computation.
I1003 09:37:45.268781  7223 net.cpp:198] M2PELU33 needs backward computation.
I1003 09:37:45.268784  7223 net.cpp:198] Eltwise16 needs backward computation.
I1003 09:37:45.268786  7223 net.cpp:198] Scale34 needs backward computation.
I1003 09:37:45.268790  7223 net.cpp:198] BatchNorm34 needs backward computation.
I1003 09:37:45.268791  7223 net.cpp:198] Convolution34 needs backward computation.
I1003 09:37:45.268793  7223 net.cpp:198] M2PELU32 needs backward computation.
I1003 09:37:45.268795  7223 net.cpp:198] Scale33 needs backward computation.
I1003 09:37:45.268800  7223 net.cpp:198] BatchNorm33 needs backward computation.
I1003 09:37:45.268803  7223 net.cpp:198] Convolution33 needs backward computation.
I1003 09:37:45.268806  7223 net.cpp:198] Eltwise15_M2PELU31_0_split needs backward computation.
I1003 09:37:45.268808  7223 net.cpp:198] M2PELU31 needs backward computation.
I1003 09:37:45.268810  7223 net.cpp:198] Eltwise15 needs backward computation.
I1003 09:37:45.268813  7223 net.cpp:198] Scale32 needs backward computation.
I1003 09:37:45.268815  7223 net.cpp:198] BatchNorm32 needs backward computation.
I1003 09:37:45.268818  7223 net.cpp:198] Convolution32 needs backward computation.
I1003 09:37:45.294708  7223 net.cpp:198] M2PELU30 needs backward computation.
I1003 09:37:45.294716  7223 net.cpp:198] Scale31 needs backward computation.
I1003 09:37:45.294719  7223 net.cpp:198] BatchNorm31 needs backward computation.
I1003 09:37:45.294721  7223 net.cpp:198] Convolution31 needs backward computation.
I1003 09:37:45.294724  7223 net.cpp:198] Eltwise14_M2PELU29_0_split needs backward computation.
I1003 09:37:45.294728  7223 net.cpp:198] M2PELU29 needs backward computation.
I1003 09:37:45.294730  7223 net.cpp:198] Eltwise14 needs backward computation.
I1003 09:37:45.294734  7223 net.cpp:198] Scale30 needs backward computation.
I1003 09:37:45.294736  7223 net.cpp:198] BatchNorm30 needs backward computation.
I1003 09:37:45.294739  7223 net.cpp:198] Convolution30 needs backward computation.
I1003 09:37:45.294741  7223 net.cpp:198] M2PELU28 needs backward computation.
I1003 09:37:45.294744  7223 net.cpp:198] Scale29 needs backward computation.
I1003 09:37:45.294746  7223 net.cpp:198] BatchNorm29 needs backward computation.
I1003 09:37:45.294749  7223 net.cpp:198] Convolution29 needs backward computation.
I1003 09:37:45.294752  7223 net.cpp:198] Eltwise13_M2PELU27_0_split needs backward computation.
I1003 09:37:45.294755  7223 net.cpp:198] M2PELU27 needs backward computation.
I1003 09:37:45.294757  7223 net.cpp:198] Eltwise13 needs backward computation.
I1003 09:37:45.294761  7223 net.cpp:198] Scale28 needs backward computation.
I1003 09:37:45.294764  7223 net.cpp:198] BatchNorm28 needs backward computation.
I1003 09:37:45.294766  7223 net.cpp:198] Convolution28 needs backward computation.
I1003 09:37:45.294769  7223 net.cpp:198] M2PELU26 needs backward computation.
I1003 09:37:45.294771  7223 net.cpp:198] Scale27 needs backward computation.
I1003 09:37:45.294773  7223 net.cpp:198] BatchNorm27 needs backward computation.
I1003 09:37:45.294776  7223 net.cpp:198] Convolution27 needs backward computation.
I1003 09:37:45.294778  7223 net.cpp:198] Eltwise12_M2PELU25_0_split needs backward computation.
I1003 09:37:45.294781  7223 net.cpp:198] M2PELU25 needs backward computation.
I1003 09:37:45.294785  7223 net.cpp:198] Eltwise12 needs backward computation.
I1003 09:37:45.294787  7223 net.cpp:198] Scale26 needs backward computation.
I1003 09:37:45.294790  7223 net.cpp:198] BatchNorm26 needs backward computation.
I1003 09:37:45.294791  7223 net.cpp:198] Convolution26 needs backward computation.
I1003 09:37:45.294795  7223 net.cpp:198] M2PELU24 needs backward computation.
I1003 09:37:45.294797  7223 net.cpp:198] Scale25 needs backward computation.
I1003 09:37:45.294800  7223 net.cpp:198] BatchNorm25 needs backward computation.
I1003 09:37:45.294802  7223 net.cpp:198] Convolution25 needs backward computation.
I1003 09:37:45.294806  7223 net.cpp:198] Eltwise11_M2PELU23_0_split needs backward computation.
I1003 09:37:45.294807  7223 net.cpp:198] M2PELU23 needs backward computation.
I1003 09:37:45.294811  7223 net.cpp:198] Eltwise11 needs backward computation.
I1003 09:37:45.294813  7223 net.cpp:198] Scale24 needs backward computation.
I1003 09:37:45.294816  7223 net.cpp:198] BatchNorm24 needs backward computation.
I1003 09:37:45.294818  7223 net.cpp:198] Convolution24 needs backward computation.
I1003 09:37:45.294821  7223 net.cpp:198] M2PELU22 needs backward computation.
I1003 09:37:45.294823  7223 net.cpp:198] Scale23 needs backward computation.
I1003 09:37:45.294833  7223 net.cpp:198] BatchNorm23 needs backward computation.
I1003 09:37:45.294836  7223 net.cpp:198] Convolution23 needs backward computation.
I1003 09:37:45.294838  7223 net.cpp:198] Eltwise10_M2PELU21_0_split needs backward computation.
I1003 09:37:45.294842  7223 net.cpp:198] M2PELU21 needs backward computation.
I1003 09:37:45.294844  7223 net.cpp:198] Eltwise10 needs backward computation.
I1003 09:37:45.294849  7223 net.cpp:198] Scale22 needs backward computation.
I1003 09:37:45.294852  7223 net.cpp:198] BatchNorm22 needs backward computation.
I1003 09:37:45.294854  7223 net.cpp:198] Convolution22 needs backward computation.
I1003 09:37:45.294857  7223 net.cpp:198] M2PELU20 needs backward computation.
I1003 09:37:45.294860  7223 net.cpp:198] Scale21 needs backward computation.
I1003 09:37:45.294862  7223 net.cpp:198] BatchNorm21 needs backward computation.
I1003 09:37:45.294865  7223 net.cpp:198] Convolution21 needs backward computation.
I1003 09:37:45.294868  7223 net.cpp:198] Scale20 needs backward computation.
I1003 09:37:45.294870  7223 net.cpp:198] BatchNorm20 needs backward computation.
I1003 09:37:45.294873  7223 net.cpp:198] Convolution20 needs backward computation.
I1003 09:37:45.294875  7223 net.cpp:198] Eltwise9_M2PELU19_0_split needs backward computation.
I1003 09:37:45.294878  7223 net.cpp:198] M2PELU19 needs backward computation.
I1003 09:37:45.294881  7223 net.cpp:198] Eltwise9 needs backward computation.
I1003 09:37:45.294884  7223 net.cpp:198] Scale19 needs backward computation.
I1003 09:37:45.294886  7223 net.cpp:198] BatchNorm19 needs backward computation.
I1003 09:37:45.294889  7223 net.cpp:198] Convolution19 needs backward computation.
I1003 09:37:45.294893  7223 net.cpp:198] M2PELU18 needs backward computation.
I1003 09:37:45.294894  7223 net.cpp:198] Scale18 needs backward computation.
I1003 09:37:45.294898  7223 net.cpp:198] BatchNorm18 needs backward computation.
I1003 09:37:45.294899  7223 net.cpp:198] Convolution18 needs backward computation.
I1003 09:37:45.294903  7223 net.cpp:198] Eltwise8_M2PELU17_0_split needs backward computation.
I1003 09:37:45.294905  7223 net.cpp:198] M2PELU17 needs backward computation.
I1003 09:37:45.294908  7223 net.cpp:198] Eltwise8 needs backward computation.
I1003 09:37:45.294910  7223 net.cpp:198] Scale17 needs backward computation.
I1003 09:37:45.294914  7223 net.cpp:198] BatchNorm17 needs backward computation.
I1003 09:37:45.294915  7223 net.cpp:198] Convolution17 needs backward computation.
I1003 09:37:45.294919  7223 net.cpp:198] M2PELU16 needs backward computation.
I1003 09:37:45.294920  7223 net.cpp:198] Scale16 needs backward computation.
I1003 09:37:45.294924  7223 net.cpp:198] BatchNorm16 needs backward computation.
I1003 09:37:45.294925  7223 net.cpp:198] Convolution16 needs backward computation.
I1003 09:37:45.294929  7223 net.cpp:198] Eltwise7_M2PELU15_0_split needs backward computation.
I1003 09:37:45.294931  7223 net.cpp:198] M2PELU15 needs backward computation.
I1003 09:37:45.294934  7223 net.cpp:198] Eltwise7 needs backward computation.
I1003 09:37:45.294936  7223 net.cpp:198] Scale15 needs backward computation.
I1003 09:37:45.294939  7223 net.cpp:198] BatchNorm15 needs backward computation.
I1003 09:37:45.294941  7223 net.cpp:198] Convolution15 needs backward computation.
I1003 09:37:45.294945  7223 net.cpp:198] M2PELU14 needs backward computation.
I1003 09:37:45.294947  7223 net.cpp:198] Scale14 needs backward computation.
I1003 09:37:45.294950  7223 net.cpp:198] BatchNorm14 needs backward computation.
I1003 09:37:45.294952  7223 net.cpp:198] Convolution14 needs backward computation.
I1003 09:37:45.294955  7223 net.cpp:198] Eltwise6_M2PELU13_0_split needs backward computation.
I1003 09:37:45.294957  7223 net.cpp:198] M2PELU13 needs backward computation.
I1003 09:37:45.294960  7223 net.cpp:198] Eltwise6 needs backward computation.
I1003 09:37:45.294963  7223 net.cpp:198] Scale13 needs backward computation.
I1003 09:37:45.294965  7223 net.cpp:198] BatchNorm13 needs backward computation.
I1003 09:37:45.294968  7223 net.cpp:198] Convolution13 needs backward computation.
I1003 09:37:45.294975  7223 net.cpp:198] M2PELU12 needs backward computation.
I1003 09:37:45.294976  7223 net.cpp:198] Scale12 needs backward computation.
I1003 09:37:45.294980  7223 net.cpp:198] BatchNorm12 needs backward computation.
I1003 09:37:45.294981  7223 net.cpp:198] Convolution12 needs backward computation.
I1003 09:37:45.294984  7223 net.cpp:198] Eltwise5_M2PELU11_0_split needs backward computation.
I1003 09:37:45.294987  7223 net.cpp:198] M2PELU11 needs backward computation.
I1003 09:37:45.294989  7223 net.cpp:198] Eltwise5 needs backward computation.
I1003 09:37:45.296996  7223 net.cpp:198] Scale11 needs backward computation.
I1003 09:37:45.297004  7223 net.cpp:198] BatchNorm11 needs backward computation.
I1003 09:37:45.297006  7223 net.cpp:198] Convolution11 needs backward computation.
I1003 09:37:45.297009  7223 net.cpp:198] M2PELU10 needs backward computation.
I1003 09:37:45.297013  7223 net.cpp:198] Scale10 needs backward computation.
I1003 09:37:45.297014  7223 net.cpp:198] BatchNorm10 needs backward computation.
I1003 09:37:45.297017  7223 net.cpp:198] Convolution10 needs backward computation.
I1003 09:37:45.297020  7223 net.cpp:198] Eltwise4_M2PELU9_0_split needs backward computation.
I1003 09:37:45.297024  7223 net.cpp:198] M2PELU9 needs backward computation.
I1003 09:37:45.297026  7223 net.cpp:198] Eltwise4 needs backward computation.
I1003 09:37:45.297029  7223 net.cpp:198] Scale9 needs backward computation.
I1003 09:37:45.297032  7223 net.cpp:198] BatchNorm9 needs backward computation.
I1003 09:37:45.297035  7223 net.cpp:198] Convolution9 needs backward computation.
I1003 09:37:45.297039  7223 net.cpp:198] M2PELU8 needs backward computation.
I1003 09:37:45.297041  7223 net.cpp:198] Scale8 needs backward computation.
I1003 09:37:45.297044  7223 net.cpp:198] BatchNorm8 needs backward computation.
I1003 09:37:45.297046  7223 net.cpp:198] Convolution8 needs backward computation.
I1003 09:37:45.297049  7223 net.cpp:198] Eltwise3_M2PELU7_0_split needs backward computation.
I1003 09:37:45.297052  7223 net.cpp:198] M2PELU7 needs backward computation.
I1003 09:37:45.297056  7223 net.cpp:198] Eltwise3 needs backward computation.
I1003 09:37:45.297060  7223 net.cpp:198] Scale7 needs backward computation.
I1003 09:37:45.297062  7223 net.cpp:198] BatchNorm7 needs backward computation.
I1003 09:37:45.297065  7223 net.cpp:198] Convolution7 needs backward computation.
I1003 09:37:45.297068  7223 net.cpp:198] M2PELU6 needs backward computation.
I1003 09:37:45.297070  7223 net.cpp:198] Scale6 needs backward computation.
I1003 09:37:45.297072  7223 net.cpp:198] BatchNorm6 needs backward computation.
I1003 09:37:45.297075  7223 net.cpp:198] Convolution6 needs backward computation.
I1003 09:37:45.297078  7223 net.cpp:198] Eltwise2_M2PELU5_0_split needs backward computation.
I1003 09:37:45.297081  7223 net.cpp:198] M2PELU5 needs backward computation.
I1003 09:37:45.297083  7223 net.cpp:198] Eltwise2 needs backward computation.
I1003 09:37:45.297087  7223 net.cpp:198] Scale5 needs backward computation.
I1003 09:37:45.297089  7223 net.cpp:198] BatchNorm5 needs backward computation.
I1003 09:37:45.297092  7223 net.cpp:198] Convolution5 needs backward computation.
I1003 09:37:45.297094  7223 net.cpp:198] M2PELU4 needs backward computation.
I1003 09:37:45.297097  7223 net.cpp:198] Scale4 needs backward computation.
I1003 09:37:45.297099  7223 net.cpp:198] BatchNorm4 needs backward computation.
I1003 09:37:45.297102  7223 net.cpp:198] Convolution4 needs backward computation.
I1003 09:37:45.297104  7223 net.cpp:198] Eltwise1_M2PELU3_0_split needs backward computation.
I1003 09:37:45.297107  7223 net.cpp:198] M2PELU3 needs backward computation.
I1003 09:37:45.297111  7223 net.cpp:198] Eltwise1 needs backward computation.
I1003 09:37:45.297113  7223 net.cpp:198] Scale3 needs backward computation.
I1003 09:37:45.297116  7223 net.cpp:198] BatchNorm3 needs backward computation.
I1003 09:37:45.297118  7223 net.cpp:198] Convolution3 needs backward computation.
I1003 09:37:45.297128  7223 net.cpp:198] M2PELU2 needs backward computation.
I1003 09:37:45.297132  7223 net.cpp:198] Scale2 needs backward computation.
I1003 09:37:45.297134  7223 net.cpp:198] BatchNorm2 needs backward computation.
I1003 09:37:45.297137  7223 net.cpp:198] Convolution2 needs backward computation.
I1003 09:37:45.297139  7223 net.cpp:198] Convolution1_M2PELU1_0_split needs backward computation.
I1003 09:37:45.297142  7223 net.cpp:198] M2PELU1 needs backward computation.
I1003 09:37:45.297145  7223 net.cpp:198] Scale1 needs backward computation.
I1003 09:37:45.297147  7223 net.cpp:198] BatchNorm1 needs backward computation.
I1003 09:37:45.297150  7223 net.cpp:198] Convolution1 needs backward computation.
I1003 09:37:45.297153  7223 net.cpp:200] Data1 does not need backward computation.
I1003 09:37:45.297155  7223 net.cpp:242] This network produces output SoftmaxWithLoss1
I1003 09:37:45.297255  7223 net.cpp:255] Network initialization done.
I1003 09:37:45.301717  7223 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_mpelu_train_test.prototxt
I1003 09:37:45.301731  7223 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1003 09:37:45.301736  7223 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_mpelu_train_test.prototxt
I1003 09:37:45.301921  7223 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I1003 09:37:45.303186  7223 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU1"
  type: "M2PELU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU2"
  type: "M2PELU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU3"
  type: "M2PELU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU4"
  type: "M2PELU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU5"
  type: "M2PELU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU6"
  type: "M2PELU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU7"
  type: "M2PELU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU8"
  type: "M2PELU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU9"
  type: "M2PELU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU10"
  type: "M2PELU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU11"
  type: "M2PELU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU12"
  type: "M2PELU"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU13"
  type: "M2PELU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU14"
  type: "M2PELU"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU15"
  type: "M2PELU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU16"
  type: "M2PELU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU17"
  type: "M2PELU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU18"
  type: "M2PELU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU19"
  type: "M2PELU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU20"
  type: "M2PELU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU21"
  type: "M2PELU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU22"
  type: "M2PELU"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution24"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU23"
  type: "M2PELU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU24"
  type: "M2PELU"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      t
I1003 09:37:45.358517  7223 layer_factory.hpp:77] Creating layer Data1
I1003 09:37:45.358582  7223 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I1003 09:37:45.358594  7223 net.cpp:84] Creating Layer Data1
I1003 09:37:45.358599  7223 net.cpp:380] Data1 -> Data1
I1003 09:37:45.358608  7223 net.cpp:380] Data1 -> Data2
I1003 09:37:45.358614  7223 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1003 09:37:45.358804  7223 data_layer.cpp:45] output data size: 100,3,32,32
I1003 09:37:45.362926  7223 net.cpp:122] Setting up Data1
I1003 09:37:45.362946  7223 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1003 09:37:45.362951  7223 net.cpp:129] Top shape: 100 (100)
I1003 09:37:45.362953  7223 net.cpp:137] Memory required for data: 1229200
I1003 09:37:45.362958  7223 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I1003 09:37:45.362967  7223 net.cpp:84] Creating Layer Data2_Data1_1_split
I1003 09:37:45.362970  7223 net.cpp:406] Data2_Data1_1_split <- Data2
I1003 09:37:45.362977  7223 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I1003 09:37:45.362983  7223 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I1003 09:37:45.363040  7223 net.cpp:122] Setting up Data2_Data1_1_split
I1003 09:37:45.363046  7223 net.cpp:129] Top shape: 100 (100)
I1003 09:37:45.363049  7223 net.cpp:129] Top shape: 100 (100)
I1003 09:37:45.363051  7223 net.cpp:137] Memory required for data: 1230000
I1003 09:37:45.363054  7223 layer_factory.hpp:77] Creating layer Convolution1
I1003 09:37:45.363065  7223 net.cpp:84] Creating Layer Convolution1
I1003 09:37:45.363067  7223 net.cpp:406] Convolution1 <- Data1
I1003 09:37:45.363071  7223 net.cpp:380] Convolution1 -> Convolution1
I1003 09:37:45.364308  7223 net.cpp:122] Setting up Convolution1
I1003 09:37:45.364318  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.364321  7223 net.cpp:137] Memory required for data: 7783600
I1003 09:37:45.364329  7223 layer_factory.hpp:77] Creating layer BatchNorm1
I1003 09:37:45.364336  7223 net.cpp:84] Creating Layer BatchNorm1
I1003 09:37:45.364337  7223 net.cpp:406] BatchNorm1 <- Convolution1
I1003 09:37:45.364343  7223 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1003 09:37:45.364495  7223 net.cpp:122] Setting up BatchNorm1
I1003 09:37:45.364500  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.364502  7223 net.cpp:137] Memory required for data: 14337200
I1003 09:37:45.364508  7223 layer_factory.hpp:77] Creating layer Scale1
I1003 09:37:45.364516  7223 net.cpp:84] Creating Layer Scale1
I1003 09:37:45.364517  7223 net.cpp:406] Scale1 <- Convolution1
I1003 09:37:45.364521  7223 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1003 09:37:45.364553  7223 layer_factory.hpp:77] Creating layer Scale1
I1003 09:37:45.364639  7223 net.cpp:122] Setting up Scale1
I1003 09:37:45.364644  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.364646  7223 net.cpp:137] Memory required for data: 20890800
I1003 09:37:45.364650  7223 layer_factory.hpp:77] Creating layer M2PELU1
I1003 09:37:45.364657  7223 net.cpp:84] Creating Layer M2PELU1
I1003 09:37:45.364660  7223 net.cpp:406] M2PELU1 <- Convolution1
I1003 09:37:45.364663  7223 net.cpp:367] M2PELU1 -> Convolution1 (in-place)
I1003 09:37:45.365276  7223 net.cpp:122] Setting up M2PELU1
I1003 09:37:45.365285  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.365288  7223 net.cpp:137] Memory required for data: 27444400
I1003 09:37:45.365293  7223 layer_factory.hpp:77] Creating layer Convolution1_M2PELU1_0_split
I1003 09:37:45.365298  7223 net.cpp:84] Creating Layer Convolution1_M2PELU1_0_split
I1003 09:37:45.365301  7223 net.cpp:406] Convolution1_M2PELU1_0_split <- Convolution1
I1003 09:37:45.365305  7223 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_0
I1003 09:37:45.365310  7223 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_1
I1003 09:37:45.365339  7223 net.cpp:122] Setting up Convolution1_M2PELU1_0_split
I1003 09:37:45.385933  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.385941  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.385944  7223 net.cpp:137] Memory required for data: 40551600
I1003 09:37:45.385947  7223 layer_factory.hpp:77] Creating layer Convolution2
I1003 09:37:45.385958  7223 net.cpp:84] Creating Layer Convolution2
I1003 09:37:45.385962  7223 net.cpp:406] Convolution2 <- Convolution1_M2PELU1_0_split_0
I1003 09:37:45.385967  7223 net.cpp:380] Convolution2 -> Convolution2
I1003 09:37:45.387166  7223 net.cpp:122] Setting up Convolution2
I1003 09:37:45.387174  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.387177  7223 net.cpp:137] Memory required for data: 47105200
I1003 09:37:45.387182  7223 layer_factory.hpp:77] Creating layer BatchNorm2
I1003 09:37:45.387189  7223 net.cpp:84] Creating Layer BatchNorm2
I1003 09:37:45.387192  7223 net.cpp:406] BatchNorm2 <- Convolution2
I1003 09:37:45.387195  7223 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1003 09:37:45.387373  7223 net.cpp:122] Setting up BatchNorm2
I1003 09:37:45.387379  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.387382  7223 net.cpp:137] Memory required for data: 53658800
I1003 09:37:45.387397  7223 layer_factory.hpp:77] Creating layer Scale2
I1003 09:37:45.387403  7223 net.cpp:84] Creating Layer Scale2
I1003 09:37:45.387405  7223 net.cpp:406] Scale2 <- Convolution2
I1003 09:37:45.387408  7223 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1003 09:37:45.387456  7223 layer_factory.hpp:77] Creating layer Scale2
I1003 09:37:45.387595  7223 net.cpp:122] Setting up Scale2
I1003 09:37:45.387603  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.387604  7223 net.cpp:137] Memory required for data: 60212400
I1003 09:37:45.387609  7223 layer_factory.hpp:77] Creating layer M2PELU2
I1003 09:37:45.387615  7223 net.cpp:84] Creating Layer M2PELU2
I1003 09:37:45.387619  7223 net.cpp:406] M2PELU2 <- Convolution2
I1003 09:37:45.387622  7223 net.cpp:367] M2PELU2 -> Convolution2 (in-place)
I1003 09:37:45.387755  7223 net.cpp:122] Setting up M2PELU2
I1003 09:37:45.387760  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.387763  7223 net.cpp:137] Memory required for data: 66766000
I1003 09:37:45.387769  7223 layer_factory.hpp:77] Creating layer Convolution3
I1003 09:37:45.387778  7223 net.cpp:84] Creating Layer Convolution3
I1003 09:37:45.387779  7223 net.cpp:406] Convolution3 <- Convolution2
I1003 09:37:45.387794  7223 net.cpp:380] Convolution3 -> Convolution3
I1003 09:37:45.388908  7223 net.cpp:122] Setting up Convolution3
I1003 09:37:45.388917  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.388921  7223 net.cpp:137] Memory required for data: 73319600
I1003 09:37:45.388924  7223 layer_factory.hpp:77] Creating layer BatchNorm3
I1003 09:37:45.388929  7223 net.cpp:84] Creating Layer BatchNorm3
I1003 09:37:45.388931  7223 net.cpp:406] BatchNorm3 <- Convolution3
I1003 09:37:45.388936  7223 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1003 09:37:45.389094  7223 net.cpp:122] Setting up BatchNorm3
I1003 09:37:45.389099  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.389101  7223 net.cpp:137] Memory required for data: 79873200
I1003 09:37:45.389106  7223 layer_factory.hpp:77] Creating layer Scale3
I1003 09:37:45.389111  7223 net.cpp:84] Creating Layer Scale3
I1003 09:37:45.389112  7223 net.cpp:406] Scale3 <- Convolution3
I1003 09:37:45.389116  7223 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1003 09:37:45.389147  7223 layer_factory.hpp:77] Creating layer Scale3
I1003 09:37:45.389232  7223 net.cpp:122] Setting up Scale3
I1003 09:37:45.389236  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.389240  7223 net.cpp:137] Memory required for data: 86426800
I1003 09:37:45.389243  7223 layer_factory.hpp:77] Creating layer Eltwise1
I1003 09:37:45.389248  7223 net.cpp:84] Creating Layer Eltwise1
I1003 09:37:45.389250  7223 net.cpp:406] Eltwise1 <- Convolution1_M2PELU1_0_split_1
I1003 09:37:45.389253  7223 net.cpp:406] Eltwise1 <- Convolution3
I1003 09:37:45.389257  7223 net.cpp:380] Eltwise1 -> Eltwise1
I1003 09:37:45.389276  7223 net.cpp:122] Setting up Eltwise1
I1003 09:37:45.389281  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.389283  7223 net.cpp:137] Memory required for data: 92980400
I1003 09:37:45.389286  7223 layer_factory.hpp:77] Creating layer M2PELU3
I1003 09:37:45.389289  7223 net.cpp:84] Creating Layer M2PELU3
I1003 09:37:45.389293  7223 net.cpp:406] M2PELU3 <- Eltwise1
I1003 09:37:45.389297  7223 net.cpp:367] M2PELU3 -> Eltwise1 (in-place)
I1003 09:37:45.389421  7223 net.cpp:122] Setting up M2PELU3
I1003 09:37:45.389426  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.389428  7223 net.cpp:137] Memory required for data: 99534000
I1003 09:37:45.389432  7223 layer_factory.hpp:77] Creating layer Eltwise1_M2PELU3_0_split
I1003 09:37:45.389437  7223 net.cpp:84] Creating Layer Eltwise1_M2PELU3_0_split
I1003 09:37:45.389439  7223 net.cpp:406] Eltwise1_M2PELU3_0_split <- Eltwise1
I1003 09:37:45.389453  7223 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_0
I1003 09:37:45.389457  7223 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_1
I1003 09:37:45.389503  7223 net.cpp:122] Setting up Eltwise1_M2PELU3_0_split
I1003 09:37:45.389508  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.389520  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.389523  7223 net.cpp:137] Memory required for data: 112641200
I1003 09:37:45.389524  7223 layer_factory.hpp:77] Creating layer Convolution4
I1003 09:37:45.389531  7223 net.cpp:84] Creating Layer Convolution4
I1003 09:37:45.389534  7223 net.cpp:406] Convolution4 <- Eltwise1_M2PELU3_0_split_0
I1003 09:37:45.389539  7223 net.cpp:380] Convolution4 -> Convolution4
I1003 09:37:45.390770  7223 net.cpp:122] Setting up Convolution4
I1003 09:37:45.390779  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.390781  7223 net.cpp:137] Memory required for data: 119194800
I1003 09:37:45.390786  7223 layer_factory.hpp:77] Creating layer BatchNorm4
I1003 09:37:45.390791  7223 net.cpp:84] Creating Layer BatchNorm4
I1003 09:37:45.390794  7223 net.cpp:406] BatchNorm4 <- Convolution4
I1003 09:37:45.390799  7223 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1003 09:37:45.390951  7223 net.cpp:122] Setting up BatchNorm4
I1003 09:37:45.390955  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.390957  7223 net.cpp:137] Memory required for data: 125748400
I1003 09:37:45.390962  7223 layer_factory.hpp:77] Creating layer Scale4
I1003 09:37:45.390965  7223 net.cpp:84] Creating Layer Scale4
I1003 09:37:45.390969  7223 net.cpp:406] Scale4 <- Convolution4
I1003 09:37:45.390972  7223 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1003 09:37:45.391001  7223 layer_factory.hpp:77] Creating layer Scale4
I1003 09:37:45.391084  7223 net.cpp:122] Setting up Scale4
I1003 09:37:45.391089  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.391091  7223 net.cpp:137] Memory required for data: 132302000
I1003 09:37:45.391098  7223 layer_factory.hpp:77] Creating layer M2PELU4
I1003 09:37:45.391103  7223 net.cpp:84] Creating Layer M2PELU4
I1003 09:37:45.391106  7223 net.cpp:406] M2PELU4 <- Convolution4
I1003 09:37:45.391110  7223 net.cpp:367] M2PELU4 -> Convolution4 (in-place)
I1003 09:37:45.391211  7223 net.cpp:122] Setting up M2PELU4
I1003 09:37:45.391214  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.391216  7223 net.cpp:137] Memory required for data: 138855600
I1003 09:37:45.391221  7223 layer_factory.hpp:77] Creating layer Convolution5
I1003 09:37:45.391227  7223 net.cpp:84] Creating Layer Convolution5
I1003 09:37:45.391229  7223 net.cpp:406] Convolution5 <- Convolution4
I1003 09:37:45.391234  7223 net.cpp:380] Convolution5 -> Convolution5
I1003 09:37:45.392174  7223 net.cpp:122] Setting up Convolution5
I1003 09:37:45.392181  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.392184  7223 net.cpp:137] Memory required for data: 145409200
I1003 09:37:45.392189  7223 layer_factory.hpp:77] Creating layer BatchNorm5
I1003 09:37:45.392194  7223 net.cpp:84] Creating Layer BatchNorm5
I1003 09:37:45.392196  7223 net.cpp:406] BatchNorm5 <- Convolution5
I1003 09:37:45.392200  7223 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1003 09:37:45.392355  7223 net.cpp:122] Setting up BatchNorm5
I1003 09:37:45.392360  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.392362  7223 net.cpp:137] Memory required for data: 151962800
I1003 09:37:45.392366  7223 layer_factory.hpp:77] Creating layer Scale5
I1003 09:37:45.392371  7223 net.cpp:84] Creating Layer Scale5
I1003 09:37:45.392374  7223 net.cpp:406] Scale5 <- Convolution5
I1003 09:37:45.392376  7223 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1003 09:37:45.392407  7223 layer_factory.hpp:77] Creating layer Scale5
I1003 09:37:45.392491  7223 net.cpp:122] Setting up Scale5
I1003 09:37:45.392495  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.392498  7223 net.cpp:137] Memory required for data: 158516400
I1003 09:37:45.392501  7223 layer_factory.hpp:77] Creating layer Eltwise2
I1003 09:37:45.392505  7223 net.cpp:84] Creating Layer Eltwise2
I1003 09:37:45.392515  7223 net.cpp:406] Eltwise2 <- Eltwise1_M2PELU3_0_split_1
I1003 09:37:45.392518  7223 net.cpp:406] Eltwise2 <- Convolution5
I1003 09:37:45.392523  7223 net.cpp:380] Eltwise2 -> Eltwise2
I1003 09:37:45.392541  7223 net.cpp:122] Setting up Eltwise2
I1003 09:37:45.392546  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.392549  7223 net.cpp:137] Memory required for data: 165070000
I1003 09:37:45.392550  7223 layer_factory.hpp:77] Creating layer M2PELU5
I1003 09:37:45.392554  7223 net.cpp:84] Creating Layer M2PELU5
I1003 09:37:45.392557  7223 net.cpp:406] M2PELU5 <- Eltwise2
I1003 09:37:45.392560  7223 net.cpp:367] M2PELU5 -> Eltwise2 (in-place)
I1003 09:37:45.392663  7223 net.cpp:122] Setting up M2PELU5
I1003 09:37:45.392666  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.392668  7223 net.cpp:137] Memory required for data: 171623600
I1003 09:37:45.392673  7223 layer_factory.hpp:77] Creating layer Eltwise2_M2PELU5_0_split
I1003 09:37:45.392676  7223 net.cpp:84] Creating Layer Eltwise2_M2PELU5_0_split
I1003 09:37:45.392678  7223 net.cpp:406] Eltwise2_M2PELU5_0_split <- Eltwise2
I1003 09:37:45.392683  7223 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_0
I1003 09:37:45.392685  7223 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_1
I1003 09:37:45.392714  7223 net.cpp:122] Setting up Eltwise2_M2PELU5_0_split
I1003 09:37:45.392719  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.392721  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.392724  7223 net.cpp:137] Memory required for data: 184730800
I1003 09:37:45.392725  7223 layer_factory.hpp:77] Creating layer Convolution6
I1003 09:37:45.392731  7223 net.cpp:84] Creating Layer Convolution6
I1003 09:37:45.392734  7223 net.cpp:406] Convolution6 <- Eltwise2_M2PELU5_0_split_0
I1003 09:37:45.392737  7223 net.cpp:380] Convolution6 -> Convolution6
I1003 09:37:45.393674  7223 net.cpp:122] Setting up Convolution6
I1003 09:37:45.393682  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.393685  7223 net.cpp:137] Memory required for data: 191284400
I1003 09:37:45.393692  7223 layer_factory.hpp:77] Creating layer BatchNorm6
I1003 09:37:45.393697  7223 net.cpp:84] Creating Layer BatchNorm6
I1003 09:37:45.393698  7223 net.cpp:406] BatchNorm6 <- Convolution6
I1003 09:37:45.393702  7223 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1003 09:37:45.393854  7223 net.cpp:122] Setting up BatchNorm6
I1003 09:37:45.393858  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.393860  7223 net.cpp:137] Memory required for data: 197838000
I1003 09:37:45.393865  7223 layer_factory.hpp:77] Creating layer Scale6
I1003 09:37:45.393869  7223 net.cpp:84] Creating Layer Scale6
I1003 09:37:45.393872  7223 net.cpp:406] Scale6 <- Convolution6
I1003 09:37:45.393875  7223 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1003 09:37:45.393905  7223 layer_factory.hpp:77] Creating layer Scale6
I1003 09:37:45.393990  7223 net.cpp:122] Setting up Scale6
I1003 09:37:45.393996  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.393997  7223 net.cpp:137] Memory required for data: 204391600
I1003 09:37:45.394001  7223 layer_factory.hpp:77] Creating layer M2PELU6
I1003 09:37:45.394006  7223 net.cpp:84] Creating Layer M2PELU6
I1003 09:37:45.394008  7223 net.cpp:406] M2PELU6 <- Convolution6
I1003 09:37:45.394012  7223 net.cpp:367] M2PELU6 -> Convolution6 (in-place)
I1003 09:37:45.394111  7223 net.cpp:122] Setting up M2PELU6
I1003 09:37:45.394115  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.394117  7223 net.cpp:137] Memory required for data: 210945200
I1003 09:37:45.394121  7223 layer_factory.hpp:77] Creating layer Convolution7
I1003 09:37:45.394127  7223 net.cpp:84] Creating Layer Convolution7
I1003 09:37:45.394130  7223 net.cpp:406] Convolution7 <- Convolution6
I1003 09:37:45.394134  7223 net.cpp:380] Convolution7 -> Convolution7
I1003 09:37:45.395133  7223 net.cpp:122] Setting up Convolution7
I1003 09:37:45.395143  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.395151  7223 net.cpp:137] Memory required for data: 217498800
I1003 09:37:45.395156  7223 layer_factory.hpp:77] Creating layer BatchNorm7
I1003 09:37:45.395164  7223 net.cpp:84] Creating Layer BatchNorm7
I1003 09:37:45.395166  7223 net.cpp:406] BatchNorm7 <- Convolution7
I1003 09:37:45.395170  7223 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1003 09:37:45.395323  7223 net.cpp:122] Setting up BatchNorm7
I1003 09:37:45.395328  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.395330  7223 net.cpp:137] Memory required for data: 224052400
I1003 09:37:45.395334  7223 layer_factory.hpp:77] Creating layer Scale7
I1003 09:37:45.395339  7223 net.cpp:84] Creating Layer Scale7
I1003 09:37:45.395341  7223 net.cpp:406] Scale7 <- Convolution7
I1003 09:37:45.395344  7223 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1003 09:37:45.395375  7223 layer_factory.hpp:77] Creating layer Scale7
I1003 09:37:45.395460  7223 net.cpp:122] Setting up Scale7
I1003 09:37:45.395464  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.395467  7223 net.cpp:137] Memory required for data: 230606000
I1003 09:37:45.395470  7223 layer_factory.hpp:77] Creating layer Eltwise3
I1003 09:37:45.395474  7223 net.cpp:84] Creating Layer Eltwise3
I1003 09:37:45.395478  7223 net.cpp:406] Eltwise3 <- Eltwise2_M2PELU5_0_split_1
I1003 09:37:45.395480  7223 net.cpp:406] Eltwise3 <- Convolution7
I1003 09:37:45.395483  7223 net.cpp:380] Eltwise3 -> Eltwise3
I1003 09:37:45.395501  7223 net.cpp:122] Setting up Eltwise3
I1003 09:37:45.395505  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.395508  7223 net.cpp:137] Memory required for data: 237159600
I1003 09:37:45.395509  7223 layer_factory.hpp:77] Creating layer M2PELU7
I1003 09:37:45.395514  7223 net.cpp:84] Creating Layer M2PELU7
I1003 09:37:45.395516  7223 net.cpp:406] M2PELU7 <- Eltwise3
I1003 09:37:45.395519  7223 net.cpp:367] M2PELU7 -> Eltwise3 (in-place)
I1003 09:37:45.395622  7223 net.cpp:122] Setting up M2PELU7
I1003 09:37:45.395627  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.395628  7223 net.cpp:137] Memory required for data: 243713200
I1003 09:37:45.395632  7223 layer_factory.hpp:77] Creating layer Eltwise3_M2PELU7_0_split
I1003 09:37:45.395635  7223 net.cpp:84] Creating Layer Eltwise3_M2PELU7_0_split
I1003 09:37:45.395637  7223 net.cpp:406] Eltwise3_M2PELU7_0_split <- Eltwise3
I1003 09:37:45.395640  7223 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_0
I1003 09:37:45.395645  7223 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_1
I1003 09:37:45.395671  7223 net.cpp:122] Setting up Eltwise3_M2PELU7_0_split
I1003 09:37:45.395675  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.416563  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.416569  7223 net.cpp:137] Memory required for data: 256820400
I1003 09:37:45.416573  7223 layer_factory.hpp:77] Creating layer Convolution8
I1003 09:37:45.416579  7223 net.cpp:84] Creating Layer Convolution8
I1003 09:37:45.416584  7223 net.cpp:406] Convolution8 <- Eltwise3_M2PELU7_0_split_0
I1003 09:37:45.416590  7223 net.cpp:380] Convolution8 -> Convolution8
I1003 09:37:45.417652  7223 net.cpp:122] Setting up Convolution8
I1003 09:37:45.417671  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.417673  7223 net.cpp:137] Memory required for data: 263374000
I1003 09:37:45.417685  7223 layer_factory.hpp:77] Creating layer BatchNorm8
I1003 09:37:45.417701  7223 net.cpp:84] Creating Layer BatchNorm8
I1003 09:37:45.417703  7223 net.cpp:406] BatchNorm8 <- Convolution8
I1003 09:37:45.417707  7223 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1003 09:37:45.417887  7223 net.cpp:122] Setting up BatchNorm8
I1003 09:37:45.417894  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.417896  7223 net.cpp:137] Memory required for data: 269927600
I1003 09:37:45.417901  7223 layer_factory.hpp:77] Creating layer Scale8
I1003 09:37:45.417906  7223 net.cpp:84] Creating Layer Scale8
I1003 09:37:45.417917  7223 net.cpp:406] Scale8 <- Convolution8
I1003 09:37:45.417920  7223 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1003 09:37:45.417961  7223 layer_factory.hpp:77] Creating layer Scale8
I1003 09:37:45.418087  7223 net.cpp:122] Setting up Scale8
I1003 09:37:45.418093  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.418095  7223 net.cpp:137] Memory required for data: 276481200
I1003 09:37:45.418099  7223 layer_factory.hpp:77] Creating layer M2PELU8
I1003 09:37:45.418105  7223 net.cpp:84] Creating Layer M2PELU8
I1003 09:37:45.418108  7223 net.cpp:406] M2PELU8 <- Convolution8
I1003 09:37:45.418112  7223 net.cpp:367] M2PELU8 -> Convolution8 (in-place)
I1003 09:37:45.418237  7223 net.cpp:122] Setting up M2PELU8
I1003 09:37:45.418242  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.418253  7223 net.cpp:137] Memory required for data: 283034800
I1003 09:37:45.418257  7223 layer_factory.hpp:77] Creating layer Convolution9
I1003 09:37:45.418265  7223 net.cpp:84] Creating Layer Convolution9
I1003 09:37:45.418267  7223 net.cpp:406] Convolution9 <- Convolution8
I1003 09:37:45.418272  7223 net.cpp:380] Convolution9 -> Convolution9
I1003 09:37:45.419389  7223 net.cpp:122] Setting up Convolution9
I1003 09:37:45.419397  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.419400  7223 net.cpp:137] Memory required for data: 289588400
I1003 09:37:45.419404  7223 layer_factory.hpp:77] Creating layer BatchNorm9
I1003 09:37:45.419411  7223 net.cpp:84] Creating Layer BatchNorm9
I1003 09:37:45.419414  7223 net.cpp:406] BatchNorm9 <- Convolution9
I1003 09:37:45.419420  7223 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1003 09:37:45.419575  7223 net.cpp:122] Setting up BatchNorm9
I1003 09:37:45.419579  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.419581  7223 net.cpp:137] Memory required for data: 296142000
I1003 09:37:45.419586  7223 layer_factory.hpp:77] Creating layer Scale9
I1003 09:37:45.419591  7223 net.cpp:84] Creating Layer Scale9
I1003 09:37:45.419594  7223 net.cpp:406] Scale9 <- Convolution9
I1003 09:37:45.419596  7223 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1003 09:37:45.419627  7223 layer_factory.hpp:77] Creating layer Scale9
I1003 09:37:45.419715  7223 net.cpp:122] Setting up Scale9
I1003 09:37:45.419719  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.419721  7223 net.cpp:137] Memory required for data: 302695600
I1003 09:37:45.419725  7223 layer_factory.hpp:77] Creating layer Eltwise4
I1003 09:37:45.419729  7223 net.cpp:84] Creating Layer Eltwise4
I1003 09:37:45.419733  7223 net.cpp:406] Eltwise4 <- Eltwise3_M2PELU7_0_split_1
I1003 09:37:45.419735  7223 net.cpp:406] Eltwise4 <- Convolution9
I1003 09:37:45.419739  7223 net.cpp:380] Eltwise4 -> Eltwise4
I1003 09:37:45.419757  7223 net.cpp:122] Setting up Eltwise4
I1003 09:37:45.419762  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.419764  7223 net.cpp:137] Memory required for data: 309249200
I1003 09:37:45.419766  7223 layer_factory.hpp:77] Creating layer M2PELU9
I1003 09:37:45.419771  7223 net.cpp:84] Creating Layer M2PELU9
I1003 09:37:45.419775  7223 net.cpp:406] M2PELU9 <- Eltwise4
I1003 09:37:45.419778  7223 net.cpp:367] M2PELU9 -> Eltwise4 (in-place)
I1003 09:37:45.419900  7223 net.cpp:122] Setting up M2PELU9
I1003 09:37:45.419904  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.419906  7223 net.cpp:137] Memory required for data: 315802800
I1003 09:37:45.419910  7223 layer_factory.hpp:77] Creating layer Eltwise4_M2PELU9_0_split
I1003 09:37:45.419914  7223 net.cpp:84] Creating Layer Eltwise4_M2PELU9_0_split
I1003 09:37:45.419916  7223 net.cpp:406] Eltwise4_M2PELU9_0_split <- Eltwise4
I1003 09:37:45.419920  7223 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_0
I1003 09:37:45.419924  7223 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_1
I1003 09:37:45.419951  7223 net.cpp:122] Setting up Eltwise4_M2PELU9_0_split
I1003 09:37:45.419955  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.419965  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.419967  7223 net.cpp:137] Memory required for data: 328910000
I1003 09:37:45.419970  7223 layer_factory.hpp:77] Creating layer Convolution10
I1003 09:37:45.419976  7223 net.cpp:84] Creating Layer Convolution10
I1003 09:37:45.419978  7223 net.cpp:406] Convolution10 <- Eltwise4_M2PELU9_0_split_0
I1003 09:37:45.419982  7223 net.cpp:380] Convolution10 -> Convolution10
I1003 09:37:45.421062  7223 net.cpp:122] Setting up Convolution10
I1003 09:37:45.421072  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.421074  7223 net.cpp:137] Memory required for data: 335463600
I1003 09:37:45.421079  7223 layer_factory.hpp:77] Creating layer BatchNorm10
I1003 09:37:45.421084  7223 net.cpp:84] Creating Layer BatchNorm10
I1003 09:37:45.421087  7223 net.cpp:406] BatchNorm10 <- Convolution10
I1003 09:37:45.421092  7223 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1003 09:37:45.421247  7223 net.cpp:122] Setting up BatchNorm10
I1003 09:37:45.421252  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.421254  7223 net.cpp:137] Memory required for data: 342017200
I1003 09:37:45.421259  7223 layer_factory.hpp:77] Creating layer Scale10
I1003 09:37:45.421264  7223 net.cpp:84] Creating Layer Scale10
I1003 09:37:45.421267  7223 net.cpp:406] Scale10 <- Convolution10
I1003 09:37:45.421269  7223 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1003 09:37:45.421300  7223 layer_factory.hpp:77] Creating layer Scale10
I1003 09:37:45.421386  7223 net.cpp:122] Setting up Scale10
I1003 09:37:45.421389  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.421391  7223 net.cpp:137] Memory required for data: 348570800
I1003 09:37:45.421396  7223 layer_factory.hpp:77] Creating layer M2PELU10
I1003 09:37:45.421401  7223 net.cpp:84] Creating Layer M2PELU10
I1003 09:37:45.421402  7223 net.cpp:406] M2PELU10 <- Convolution10
I1003 09:37:45.421406  7223 net.cpp:367] M2PELU10 -> Convolution10 (in-place)
I1003 09:37:45.421506  7223 net.cpp:122] Setting up M2PELU10
I1003 09:37:45.421510  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.421512  7223 net.cpp:137] Memory required for data: 355124400
I1003 09:37:45.421516  7223 layer_factory.hpp:77] Creating layer Convolution11
I1003 09:37:45.421524  7223 net.cpp:84] Creating Layer Convolution11
I1003 09:37:45.421525  7223 net.cpp:406] Convolution11 <- Convolution10
I1003 09:37:45.421530  7223 net.cpp:380] Convolution11 -> Convolution11
I1003 09:37:45.422793  7223 net.cpp:122] Setting up Convolution11
I1003 09:37:45.422802  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.422806  7223 net.cpp:137] Memory required for data: 361678000
I1003 09:37:45.422811  7223 layer_factory.hpp:77] Creating layer BatchNorm11
I1003 09:37:45.422816  7223 net.cpp:84] Creating Layer BatchNorm11
I1003 09:37:45.422818  7223 net.cpp:406] BatchNorm11 <- Convolution11
I1003 09:37:45.422823  7223 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1003 09:37:45.422981  7223 net.cpp:122] Setting up BatchNorm11
I1003 09:37:45.422986  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.422987  7223 net.cpp:137] Memory required for data: 368231600
I1003 09:37:45.422991  7223 layer_factory.hpp:77] Creating layer Scale11
I1003 09:37:45.422996  7223 net.cpp:84] Creating Layer Scale11
I1003 09:37:45.422998  7223 net.cpp:406] Scale11 <- Convolution11
I1003 09:37:45.423002  7223 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1003 09:37:45.423032  7223 layer_factory.hpp:77] Creating layer Scale11
I1003 09:37:45.423120  7223 net.cpp:122] Setting up Scale11
I1003 09:37:45.423125  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.423126  7223 net.cpp:137] Memory required for data: 374785200
I1003 09:37:45.423130  7223 layer_factory.hpp:77] Creating layer Eltwise5
I1003 09:37:45.423135  7223 net.cpp:84] Creating Layer Eltwise5
I1003 09:37:45.423137  7223 net.cpp:406] Eltwise5 <- Eltwise4_M2PELU9_0_split_1
I1003 09:37:45.423147  7223 net.cpp:406] Eltwise5 <- Convolution11
I1003 09:37:45.423152  7223 net.cpp:380] Eltwise5 -> Eltwise5
I1003 09:37:45.423171  7223 net.cpp:122] Setting up Eltwise5
I1003 09:37:45.423174  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.423177  7223 net.cpp:137] Memory required for data: 381338800
I1003 09:37:45.423178  7223 layer_factory.hpp:77] Creating layer M2PELU11
I1003 09:37:45.423184  7223 net.cpp:84] Creating Layer M2PELU11
I1003 09:37:45.423187  7223 net.cpp:406] M2PELU11 <- Eltwise5
I1003 09:37:45.423190  7223 net.cpp:367] M2PELU11 -> Eltwise5 (in-place)
I1003 09:37:45.423291  7223 net.cpp:122] Setting up M2PELU11
I1003 09:37:45.423295  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.423297  7223 net.cpp:137] Memory required for data: 387892400
I1003 09:37:45.423301  7223 layer_factory.hpp:77] Creating layer Eltwise5_M2PELU11_0_split
I1003 09:37:45.423305  7223 net.cpp:84] Creating Layer Eltwise5_M2PELU11_0_split
I1003 09:37:45.423308  7223 net.cpp:406] Eltwise5_M2PELU11_0_split <- Eltwise5
I1003 09:37:45.423311  7223 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_0
I1003 09:37:45.423316  7223 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_1
I1003 09:37:45.423341  7223 net.cpp:122] Setting up Eltwise5_M2PELU11_0_split
I1003 09:37:45.423344  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.423347  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.423349  7223 net.cpp:137] Memory required for data: 400999600
I1003 09:37:45.423352  7223 layer_factory.hpp:77] Creating layer Convolution12
I1003 09:37:45.423358  7223 net.cpp:84] Creating Layer Convolution12
I1003 09:37:45.423360  7223 net.cpp:406] Convolution12 <- Eltwise5_M2PELU11_0_split_0
I1003 09:37:45.423364  7223 net.cpp:380] Convolution12 -> Convolution12
I1003 09:37:45.424312  7223 net.cpp:122] Setting up Convolution12
I1003 09:37:45.424321  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.424324  7223 net.cpp:137] Memory required for data: 407553200
I1003 09:37:45.424329  7223 layer_factory.hpp:77] Creating layer BatchNorm12
I1003 09:37:45.424334  7223 net.cpp:84] Creating Layer BatchNorm12
I1003 09:37:45.424335  7223 net.cpp:406] BatchNorm12 <- Convolution12
I1003 09:37:45.424340  7223 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1003 09:37:45.424492  7223 net.cpp:122] Setting up BatchNorm12
I1003 09:37:45.424496  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.424499  7223 net.cpp:137] Memory required for data: 414106800
I1003 09:37:45.424504  7223 layer_factory.hpp:77] Creating layer Scale12
I1003 09:37:45.424507  7223 net.cpp:84] Creating Layer Scale12
I1003 09:37:45.424510  7223 net.cpp:406] Scale12 <- Convolution12
I1003 09:37:45.424515  7223 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1003 09:37:45.424543  7223 layer_factory.hpp:77] Creating layer Scale12
I1003 09:37:45.424628  7223 net.cpp:122] Setting up Scale12
I1003 09:37:45.424633  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.424635  7223 net.cpp:137] Memory required for data: 420660400
I1003 09:37:45.424638  7223 layer_factory.hpp:77] Creating layer M2PELU12
I1003 09:37:45.424643  7223 net.cpp:84] Creating Layer M2PELU12
I1003 09:37:45.424646  7223 net.cpp:406] M2PELU12 <- Convolution12
I1003 09:37:45.424650  7223 net.cpp:367] M2PELU12 -> Convolution12 (in-place)
I1003 09:37:45.424751  7223 net.cpp:122] Setting up M2PELU12
I1003 09:37:45.424756  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.424757  7223 net.cpp:137] Memory required for data: 427214000
I1003 09:37:45.424760  7223 layer_factory.hpp:77] Creating layer Convolution13
I1003 09:37:45.424767  7223 net.cpp:84] Creating Layer Convolution13
I1003 09:37:45.424770  7223 net.cpp:406] Convolution13 <- Convolution12
I1003 09:37:45.424775  7223 net.cpp:380] Convolution13 -> Convolution13
I1003 09:37:45.425719  7223 net.cpp:122] Setting up Convolution13
I1003 09:37:45.425729  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.425737  7223 net.cpp:137] Memory required for data: 433767600
I1003 09:37:45.425741  7223 layer_factory.hpp:77] Creating layer BatchNorm13
I1003 09:37:45.425746  7223 net.cpp:84] Creating Layer BatchNorm13
I1003 09:37:45.425750  7223 net.cpp:406] BatchNorm13 <- Convolution13
I1003 09:37:45.425755  7223 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1003 09:37:45.425909  7223 net.cpp:122] Setting up BatchNorm13
I1003 09:37:45.425915  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.425916  7223 net.cpp:137] Memory required for data: 440321200
I1003 09:37:45.425921  7223 layer_factory.hpp:77] Creating layer Scale13
I1003 09:37:45.425925  7223 net.cpp:84] Creating Layer Scale13
I1003 09:37:45.425927  7223 net.cpp:406] Scale13 <- Convolution13
I1003 09:37:45.425930  7223 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1003 09:37:45.425961  7223 layer_factory.hpp:77] Creating layer Scale13
I1003 09:37:45.426045  7223 net.cpp:122] Setting up Scale13
I1003 09:37:45.426049  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.426053  7223 net.cpp:137] Memory required for data: 446874800
I1003 09:37:45.426056  7223 layer_factory.hpp:77] Creating layer Eltwise6
I1003 09:37:45.426064  7223 net.cpp:84] Creating Layer Eltwise6
I1003 09:37:45.426066  7223 net.cpp:406] Eltwise6 <- Eltwise5_M2PELU11_0_split_1
I1003 09:37:45.426069  7223 net.cpp:406] Eltwise6 <- Convolution13
I1003 09:37:45.426072  7223 net.cpp:380] Eltwise6 -> Eltwise6
I1003 09:37:45.426092  7223 net.cpp:122] Setting up Eltwise6
I1003 09:37:45.426096  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.426098  7223 net.cpp:137] Memory required for data: 453428400
I1003 09:37:45.426100  7223 layer_factory.hpp:77] Creating layer M2PELU13
I1003 09:37:45.426105  7223 net.cpp:84] Creating Layer M2PELU13
I1003 09:37:45.426107  7223 net.cpp:406] M2PELU13 <- Eltwise6
I1003 09:37:45.426111  7223 net.cpp:367] M2PELU13 -> Eltwise6 (in-place)
I1003 09:37:45.426213  7223 net.cpp:122] Setting up M2PELU13
I1003 09:37:45.426218  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.426219  7223 net.cpp:137] Memory required for data: 459982000
I1003 09:37:45.426223  7223 layer_factory.hpp:77] Creating layer Eltwise6_M2PELU13_0_split
I1003 09:37:45.426226  7223 net.cpp:84] Creating Layer Eltwise6_M2PELU13_0_split
I1003 09:37:45.426229  7223 net.cpp:406] Eltwise6_M2PELU13_0_split <- Eltwise6
I1003 09:37:45.426232  7223 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_0
I1003 09:37:45.426237  7223 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_1
I1003 09:37:45.426264  7223 net.cpp:122] Setting up Eltwise6_M2PELU13_0_split
I1003 09:37:45.447070  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.447077  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.447080  7223 net.cpp:137] Memory required for data: 473089200
I1003 09:37:45.447082  7223 layer_factory.hpp:77] Creating layer Convolution14
I1003 09:37:45.447091  7223 net.cpp:84] Creating Layer Convolution14
I1003 09:37:45.447095  7223 net.cpp:406] Convolution14 <- Eltwise6_M2PELU13_0_split_0
I1003 09:37:45.447099  7223 net.cpp:380] Convolution14 -> Convolution14
I1003 09:37:45.448112  7223 net.cpp:122] Setting up Convolution14
I1003 09:37:45.448120  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.448123  7223 net.cpp:137] Memory required for data: 479642800
I1003 09:37:45.448128  7223 layer_factory.hpp:77] Creating layer BatchNorm14
I1003 09:37:45.448134  7223 net.cpp:84] Creating Layer BatchNorm14
I1003 09:37:45.448137  7223 net.cpp:406] BatchNorm14 <- Convolution14
I1003 09:37:45.448141  7223 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1003 09:37:45.448336  7223 net.cpp:122] Setting up BatchNorm14
I1003 09:37:45.448343  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.448345  7223 net.cpp:137] Memory required for data: 486196400
I1003 09:37:45.448351  7223 layer_factory.hpp:77] Creating layer Scale14
I1003 09:37:45.448356  7223 net.cpp:84] Creating Layer Scale14
I1003 09:37:45.448366  7223 net.cpp:406] Scale14 <- Convolution14
I1003 09:37:45.448370  7223 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1003 09:37:45.448416  7223 layer_factory.hpp:77] Creating layer Scale14
I1003 09:37:45.448523  7223 net.cpp:122] Setting up Scale14
I1003 09:37:45.448542  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.448546  7223 net.cpp:137] Memory required for data: 492750000
I1003 09:37:45.448552  7223 layer_factory.hpp:77] Creating layer M2PELU14
I1003 09:37:45.448570  7223 net.cpp:84] Creating Layer M2PELU14
I1003 09:37:45.448575  7223 net.cpp:406] M2PELU14 <- Convolution14
I1003 09:37:45.448580  7223 net.cpp:367] M2PELU14 -> Convolution14 (in-place)
I1003 09:37:45.448693  7223 net.cpp:122] Setting up M2PELU14
I1003 09:37:45.448698  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.448700  7223 net.cpp:137] Memory required for data: 499303600
I1003 09:37:45.448704  7223 layer_factory.hpp:77] Creating layer Convolution15
I1003 09:37:45.448711  7223 net.cpp:84] Creating Layer Convolution15
I1003 09:37:45.448714  7223 net.cpp:406] Convolution15 <- Convolution14
I1003 09:37:45.448719  7223 net.cpp:380] Convolution15 -> Convolution15
I1003 09:37:45.449923  7223 net.cpp:122] Setting up Convolution15
I1003 09:37:45.449931  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.449934  7223 net.cpp:137] Memory required for data: 505857200
I1003 09:37:45.449939  7223 layer_factory.hpp:77] Creating layer BatchNorm15
I1003 09:37:45.449944  7223 net.cpp:84] Creating Layer BatchNorm15
I1003 09:37:45.449946  7223 net.cpp:406] BatchNorm15 <- Convolution15
I1003 09:37:45.449951  7223 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1003 09:37:45.450109  7223 net.cpp:122] Setting up BatchNorm15
I1003 09:37:45.450114  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.450115  7223 net.cpp:137] Memory required for data: 512410800
I1003 09:37:45.450131  7223 layer_factory.hpp:77] Creating layer Scale15
I1003 09:37:45.450139  7223 net.cpp:84] Creating Layer Scale15
I1003 09:37:45.450140  7223 net.cpp:406] Scale15 <- Convolution15
I1003 09:37:45.450145  7223 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1003 09:37:45.450177  7223 layer_factory.hpp:77] Creating layer Scale15
I1003 09:37:45.450265  7223 net.cpp:122] Setting up Scale15
I1003 09:37:45.450269  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.450271  7223 net.cpp:137] Memory required for data: 518964400
I1003 09:37:45.450275  7223 layer_factory.hpp:77] Creating layer Eltwise7
I1003 09:37:45.450279  7223 net.cpp:84] Creating Layer Eltwise7
I1003 09:37:45.450283  7223 net.cpp:406] Eltwise7 <- Eltwise6_M2PELU13_0_split_1
I1003 09:37:45.450285  7223 net.cpp:406] Eltwise7 <- Convolution15
I1003 09:37:45.450289  7223 net.cpp:380] Eltwise7 -> Eltwise7
I1003 09:37:45.450307  7223 net.cpp:122] Setting up Eltwise7
I1003 09:37:45.450310  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.450312  7223 net.cpp:137] Memory required for data: 525518000
I1003 09:37:45.450314  7223 layer_factory.hpp:77] Creating layer M2PELU15
I1003 09:37:45.450330  7223 net.cpp:84] Creating Layer M2PELU15
I1003 09:37:45.450333  7223 net.cpp:406] M2PELU15 <- Eltwise7
I1003 09:37:45.450336  7223 net.cpp:367] M2PELU15 -> Eltwise7 (in-place)
I1003 09:37:45.450445  7223 net.cpp:122] Setting up M2PELU15
I1003 09:37:45.450450  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.450453  7223 net.cpp:137] Memory required for data: 532071600
I1003 09:37:45.450456  7223 layer_factory.hpp:77] Creating layer Eltwise7_M2PELU15_0_split
I1003 09:37:45.450460  7223 net.cpp:84] Creating Layer Eltwise7_M2PELU15_0_split
I1003 09:37:45.450462  7223 net.cpp:406] Eltwise7_M2PELU15_0_split <- Eltwise7
I1003 09:37:45.450465  7223 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_0
I1003 09:37:45.450469  7223 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_1
I1003 09:37:45.450498  7223 net.cpp:122] Setting up Eltwise7_M2PELU15_0_split
I1003 09:37:45.450510  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.450512  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.450515  7223 net.cpp:137] Memory required for data: 545178800
I1003 09:37:45.450517  7223 layer_factory.hpp:77] Creating layer Convolution16
I1003 09:37:45.450536  7223 net.cpp:84] Creating Layer Convolution16
I1003 09:37:45.450541  7223 net.cpp:406] Convolution16 <- Eltwise7_M2PELU15_0_split_0
I1003 09:37:45.450544  7223 net.cpp:380] Convolution16 -> Convolution16
I1003 09:37:45.451205  7223 net.cpp:122] Setting up Convolution16
I1003 09:37:45.451212  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.451215  7223 net.cpp:137] Memory required for data: 551732400
I1003 09:37:45.451220  7223 layer_factory.hpp:77] Creating layer BatchNorm16
I1003 09:37:45.451225  7223 net.cpp:84] Creating Layer BatchNorm16
I1003 09:37:45.451227  7223 net.cpp:406] BatchNorm16 <- Convolution16
I1003 09:37:45.451231  7223 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1003 09:37:45.451387  7223 net.cpp:122] Setting up BatchNorm16
I1003 09:37:45.451392  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.451395  7223 net.cpp:137] Memory required for data: 558286000
I1003 09:37:45.451400  7223 layer_factory.hpp:77] Creating layer Scale16
I1003 09:37:45.451403  7223 net.cpp:84] Creating Layer Scale16
I1003 09:37:45.451406  7223 net.cpp:406] Scale16 <- Convolution16
I1003 09:37:45.451409  7223 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1003 09:37:45.451442  7223 layer_factory.hpp:77] Creating layer Scale16
I1003 09:37:45.451531  7223 net.cpp:122] Setting up Scale16
I1003 09:37:45.451536  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.451539  7223 net.cpp:137] Memory required for data: 564839600
I1003 09:37:45.451542  7223 layer_factory.hpp:77] Creating layer M2PELU16
I1003 09:37:45.451547  7223 net.cpp:84] Creating Layer M2PELU16
I1003 09:37:45.451550  7223 net.cpp:406] M2PELU16 <- Convolution16
I1003 09:37:45.451553  7223 net.cpp:367] M2PELU16 -> Convolution16 (in-place)
I1003 09:37:45.451658  7223 net.cpp:122] Setting up M2PELU16
I1003 09:37:45.451663  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.451664  7223 net.cpp:137] Memory required for data: 571393200
I1003 09:37:45.451668  7223 layer_factory.hpp:77] Creating layer Convolution17
I1003 09:37:45.451674  7223 net.cpp:84] Creating Layer Convolution17
I1003 09:37:45.451676  7223 net.cpp:406] Convolution17 <- Convolution16
I1003 09:37:45.451680  7223 net.cpp:380] Convolution17 -> Convolution17
I1003 09:37:45.452653  7223 net.cpp:122] Setting up Convolution17
I1003 09:37:45.452662  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.452664  7223 net.cpp:137] Memory required for data: 577946800
I1003 09:37:45.452669  7223 layer_factory.hpp:77] Creating layer BatchNorm17
I1003 09:37:45.452674  7223 net.cpp:84] Creating Layer BatchNorm17
I1003 09:37:45.452677  7223 net.cpp:406] BatchNorm17 <- Convolution17
I1003 09:37:45.452682  7223 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1003 09:37:45.452839  7223 net.cpp:122] Setting up BatchNorm17
I1003 09:37:45.452843  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.452846  7223 net.cpp:137] Memory required for data: 584500400
I1003 09:37:45.452850  7223 layer_factory.hpp:77] Creating layer Scale17
I1003 09:37:45.452854  7223 net.cpp:84] Creating Layer Scale17
I1003 09:37:45.452857  7223 net.cpp:406] Scale17 <- Convolution17
I1003 09:37:45.452860  7223 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1003 09:37:45.452891  7223 layer_factory.hpp:77] Creating layer Scale17
I1003 09:37:45.452981  7223 net.cpp:122] Setting up Scale17
I1003 09:37:45.452986  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.452987  7223 net.cpp:137] Memory required for data: 591054000
I1003 09:37:45.452991  7223 layer_factory.hpp:77] Creating layer Eltwise8
I1003 09:37:45.452996  7223 net.cpp:84] Creating Layer Eltwise8
I1003 09:37:45.452997  7223 net.cpp:406] Eltwise8 <- Eltwise7_M2PELU15_0_split_1
I1003 09:37:45.453007  7223 net.cpp:406] Eltwise8 <- Convolution17
I1003 09:37:45.453011  7223 net.cpp:380] Eltwise8 -> Eltwise8
I1003 09:37:45.453032  7223 net.cpp:122] Setting up Eltwise8
I1003 09:37:45.453037  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.453038  7223 net.cpp:137] Memory required for data: 597607600
I1003 09:37:45.453040  7223 layer_factory.hpp:77] Creating layer M2PELU17
I1003 09:37:45.453045  7223 net.cpp:84] Creating Layer M2PELU17
I1003 09:37:45.453047  7223 net.cpp:406] M2PELU17 <- Eltwise8
I1003 09:37:45.453052  7223 net.cpp:367] M2PELU17 -> Eltwise8 (in-place)
I1003 09:37:45.453156  7223 net.cpp:122] Setting up M2PELU17
I1003 09:37:45.453161  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.453162  7223 net.cpp:137] Memory required for data: 604161200
I1003 09:37:45.453166  7223 layer_factory.hpp:77] Creating layer Eltwise8_M2PELU17_0_split
I1003 09:37:45.453171  7223 net.cpp:84] Creating Layer Eltwise8_M2PELU17_0_split
I1003 09:37:45.453172  7223 net.cpp:406] Eltwise8_M2PELU17_0_split <- Eltwise8
I1003 09:37:45.453176  7223 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_0
I1003 09:37:45.453181  7223 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_1
I1003 09:37:45.453208  7223 net.cpp:122] Setting up Eltwise8_M2PELU17_0_split
I1003 09:37:45.453213  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.453217  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.453218  7223 net.cpp:137] Memory required for data: 617268400
I1003 09:37:45.453220  7223 layer_factory.hpp:77] Creating layer Convolution18
I1003 09:37:45.453227  7223 net.cpp:84] Creating Layer Convolution18
I1003 09:37:45.453228  7223 net.cpp:406] Convolution18 <- Eltwise8_M2PELU17_0_split_0
I1003 09:37:45.453233  7223 net.cpp:380] Convolution18 -> Convolution18
I1003 09:37:45.454237  7223 net.cpp:122] Setting up Convolution18
I1003 09:37:45.454246  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.454249  7223 net.cpp:137] Memory required for data: 623822000
I1003 09:37:45.454253  7223 layer_factory.hpp:77] Creating layer BatchNorm18
I1003 09:37:45.454258  7223 net.cpp:84] Creating Layer BatchNorm18
I1003 09:37:45.454262  7223 net.cpp:406] BatchNorm18 <- Convolution18
I1003 09:37:45.454265  7223 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1003 09:37:45.454418  7223 net.cpp:122] Setting up BatchNorm18
I1003 09:37:45.454423  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.454426  7223 net.cpp:137] Memory required for data: 630375600
I1003 09:37:45.454430  7223 layer_factory.hpp:77] Creating layer Scale18
I1003 09:37:45.454434  7223 net.cpp:84] Creating Layer Scale18
I1003 09:37:45.454437  7223 net.cpp:406] Scale18 <- Convolution18
I1003 09:37:45.454440  7223 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1003 09:37:45.454471  7223 layer_factory.hpp:77] Creating layer Scale18
I1003 09:37:45.454566  7223 net.cpp:122] Setting up Scale18
I1003 09:37:45.454571  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.454573  7223 net.cpp:137] Memory required for data: 636929200
I1003 09:37:45.454577  7223 layer_factory.hpp:77] Creating layer M2PELU18
I1003 09:37:45.454582  7223 net.cpp:84] Creating Layer M2PELU18
I1003 09:37:45.454584  7223 net.cpp:406] M2PELU18 <- Convolution18
I1003 09:37:45.454588  7223 net.cpp:367] M2PELU18 -> Convolution18 (in-place)
I1003 09:37:45.454696  7223 net.cpp:122] Setting up M2PELU18
I1003 09:37:45.454700  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.454702  7223 net.cpp:137] Memory required for data: 643482800
I1003 09:37:45.454706  7223 layer_factory.hpp:77] Creating layer Convolution19
I1003 09:37:45.454712  7223 net.cpp:84] Creating Layer Convolution19
I1003 09:37:45.454715  7223 net.cpp:406] Convolution19 <- Convolution18
I1003 09:37:45.454718  7223 net.cpp:380] Convolution19 -> Convolution19
I1003 09:37:45.455683  7223 net.cpp:122] Setting up Convolution19
I1003 09:37:45.455693  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.455701  7223 net.cpp:137] Memory required for data: 650036400
I1003 09:37:45.455706  7223 layer_factory.hpp:77] Creating layer BatchNorm19
I1003 09:37:45.455713  7223 net.cpp:84] Creating Layer BatchNorm19
I1003 09:37:45.455715  7223 net.cpp:406] BatchNorm19 <- Convolution19
I1003 09:37:45.455719  7223 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1003 09:37:45.455880  7223 net.cpp:122] Setting up BatchNorm19
I1003 09:37:45.455884  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.455886  7223 net.cpp:137] Memory required for data: 656590000
I1003 09:37:45.455891  7223 layer_factory.hpp:77] Creating layer Scale19
I1003 09:37:45.455896  7223 net.cpp:84] Creating Layer Scale19
I1003 09:37:45.455899  7223 net.cpp:406] Scale19 <- Convolution19
I1003 09:37:45.455902  7223 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1003 09:37:45.455934  7223 layer_factory.hpp:77] Creating layer Scale19
I1003 09:37:45.456023  7223 net.cpp:122] Setting up Scale19
I1003 09:37:45.456027  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.456029  7223 net.cpp:137] Memory required for data: 663143600
I1003 09:37:45.456033  7223 layer_factory.hpp:77] Creating layer Eltwise9
I1003 09:37:45.456037  7223 net.cpp:84] Creating Layer Eltwise9
I1003 09:37:45.456039  7223 net.cpp:406] Eltwise9 <- Eltwise8_M2PELU17_0_split_1
I1003 09:37:45.456043  7223 net.cpp:406] Eltwise9 <- Convolution19
I1003 09:37:45.456046  7223 net.cpp:380] Eltwise9 -> Eltwise9
I1003 09:37:45.456064  7223 net.cpp:122] Setting up Eltwise9
I1003 09:37:45.456068  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.456070  7223 net.cpp:137] Memory required for data: 669697200
I1003 09:37:45.456073  7223 layer_factory.hpp:77] Creating layer M2PELU19
I1003 09:37:45.456079  7223 net.cpp:84] Creating Layer M2PELU19
I1003 09:37:45.456080  7223 net.cpp:406] M2PELU19 <- Eltwise9
I1003 09:37:45.456084  7223 net.cpp:367] M2PELU19 -> Eltwise9 (in-place)
I1003 09:37:45.456190  7223 net.cpp:122] Setting up M2PELU19
I1003 09:37:45.456194  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.456197  7223 net.cpp:137] Memory required for data: 676250800
I1003 09:37:45.456200  7223 layer_factory.hpp:77] Creating layer Eltwise9_M2PELU19_0_split
I1003 09:37:45.456204  7223 net.cpp:84] Creating Layer Eltwise9_M2PELU19_0_split
I1003 09:37:45.456207  7223 net.cpp:406] Eltwise9_M2PELU19_0_split <- Eltwise9
I1003 09:37:45.456212  7223 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_0
I1003 09:37:45.477567  7223 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_1
I1003 09:37:45.477617  7223 net.cpp:122] Setting up Eltwise9_M2PELU19_0_split
I1003 09:37:45.477622  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.477625  7223 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1003 09:37:45.477627  7223 net.cpp:137] Memory required for data: 689358000
I1003 09:37:45.477630  7223 layer_factory.hpp:77] Creating layer Convolution20
I1003 09:37:45.477638  7223 net.cpp:84] Creating Layer Convolution20
I1003 09:37:45.477640  7223 net.cpp:406] Convolution20 <- Eltwise9_M2PELU19_0_split_0
I1003 09:37:45.477646  7223 net.cpp:380] Convolution20 -> Convolution20
I1003 09:37:45.478716  7223 net.cpp:122] Setting up Convolution20
I1003 09:37:45.478725  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.478729  7223 net.cpp:137] Memory required for data: 692634800
I1003 09:37:45.478732  7223 layer_factory.hpp:77] Creating layer BatchNorm20
I1003 09:37:45.478739  7223 net.cpp:84] Creating Layer BatchNorm20
I1003 09:37:45.478741  7223 net.cpp:406] BatchNorm20 <- Convolution20
I1003 09:37:45.478745  7223 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1003 09:37:45.478925  7223 net.cpp:122] Setting up BatchNorm20
I1003 09:37:45.478932  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.478935  7223 net.cpp:137] Memory required for data: 695911600
I1003 09:37:45.478940  7223 layer_factory.hpp:77] Creating layer Scale20
I1003 09:37:45.478952  7223 net.cpp:84] Creating Layer Scale20
I1003 09:37:45.478955  7223 net.cpp:406] Scale20 <- Convolution20
I1003 09:37:45.478960  7223 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1003 09:37:45.479007  7223 layer_factory.hpp:77] Creating layer Scale20
I1003 09:37:45.479125  7223 net.cpp:122] Setting up Scale20
I1003 09:37:45.479131  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.479133  7223 net.cpp:137] Memory required for data: 699188400
I1003 09:37:45.479138  7223 layer_factory.hpp:77] Creating layer Convolution21
I1003 09:37:45.479146  7223 net.cpp:84] Creating Layer Convolution21
I1003 09:37:45.479148  7223 net.cpp:406] Convolution21 <- Eltwise9_M2PELU19_0_split_1
I1003 09:37:45.479153  7223 net.cpp:380] Convolution21 -> Convolution21
I1003 09:37:45.480222  7223 net.cpp:122] Setting up Convolution21
I1003 09:37:45.480232  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.480233  7223 net.cpp:137] Memory required for data: 702465200
I1003 09:37:45.480238  7223 layer_factory.hpp:77] Creating layer BatchNorm21
I1003 09:37:45.480243  7223 net.cpp:84] Creating Layer BatchNorm21
I1003 09:37:45.480247  7223 net.cpp:406] BatchNorm21 <- Convolution21
I1003 09:37:45.480250  7223 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1003 09:37:45.480440  7223 net.cpp:122] Setting up BatchNorm21
I1003 09:37:45.480444  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.480448  7223 net.cpp:137] Memory required for data: 705742000
I1003 09:37:45.480453  7223 layer_factory.hpp:77] Creating layer Scale21
I1003 09:37:45.480456  7223 net.cpp:84] Creating Layer Scale21
I1003 09:37:45.480458  7223 net.cpp:406] Scale21 <- Convolution21
I1003 09:37:45.480463  7223 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1003 09:37:45.480502  7223 layer_factory.hpp:77] Creating layer Scale21
I1003 09:37:45.480592  7223 net.cpp:122] Setting up Scale21
I1003 09:37:45.480597  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.480599  7223 net.cpp:137] Memory required for data: 709018800
I1003 09:37:45.480603  7223 layer_factory.hpp:77] Creating layer M2PELU20
I1003 09:37:45.480618  7223 net.cpp:84] Creating Layer M2PELU20
I1003 09:37:45.480621  7223 net.cpp:406] M2PELU20 <- Convolution21
I1003 09:37:45.480625  7223 net.cpp:367] M2PELU20 -> Convolution21 (in-place)
I1003 09:37:45.480734  7223 net.cpp:122] Setting up M2PELU20
I1003 09:37:45.480739  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.480741  7223 net.cpp:137] Memory required for data: 712295600
I1003 09:37:45.480746  7223 layer_factory.hpp:77] Creating layer Convolution22
I1003 09:37:45.480752  7223 net.cpp:84] Creating Layer Convolution22
I1003 09:37:45.480754  7223 net.cpp:406] Convolution22 <- Convolution21
I1003 09:37:45.480759  7223 net.cpp:380] Convolution22 -> Convolution22
I1003 09:37:45.481911  7223 net.cpp:122] Setting up Convolution22
I1003 09:37:45.481920  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.481922  7223 net.cpp:137] Memory required for data: 715572400
I1003 09:37:45.481926  7223 layer_factory.hpp:77] Creating layer BatchNorm22
I1003 09:37:45.481931  7223 net.cpp:84] Creating Layer BatchNorm22
I1003 09:37:45.481935  7223 net.cpp:406] BatchNorm22 <- Convolution22
I1003 09:37:45.481938  7223 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1003 09:37:45.482095  7223 net.cpp:122] Setting up BatchNorm22
I1003 09:37:45.482100  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.482101  7223 net.cpp:137] Memory required for data: 718849200
I1003 09:37:45.482106  7223 layer_factory.hpp:77] Creating layer Scale22
I1003 09:37:45.482110  7223 net.cpp:84] Creating Layer Scale22
I1003 09:37:45.482112  7223 net.cpp:406] Scale22 <- Convolution22
I1003 09:37:45.482115  7223 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1003 09:37:45.482147  7223 layer_factory.hpp:77] Creating layer Scale22
I1003 09:37:45.482239  7223 net.cpp:122] Setting up Scale22
I1003 09:37:45.482244  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.482252  7223 net.cpp:137] Memory required for data: 722126000
I1003 09:37:45.482256  7223 layer_factory.hpp:77] Creating layer Eltwise10
I1003 09:37:45.482261  7223 net.cpp:84] Creating Layer Eltwise10
I1003 09:37:45.482264  7223 net.cpp:406] Eltwise10 <- Convolution20
I1003 09:37:45.482266  7223 net.cpp:406] Eltwise10 <- Convolution22
I1003 09:37:45.482270  7223 net.cpp:380] Eltwise10 -> Eltwise10
I1003 09:37:45.482288  7223 net.cpp:122] Setting up Eltwise10
I1003 09:37:45.482292  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.482295  7223 net.cpp:137] Memory required for data: 725402800
I1003 09:37:45.482296  7223 layer_factory.hpp:77] Creating layer M2PELU21
I1003 09:37:45.482302  7223 net.cpp:84] Creating Layer M2PELU21
I1003 09:37:45.482305  7223 net.cpp:406] M2PELU21 <- Eltwise10
I1003 09:37:45.482308  7223 net.cpp:367] M2PELU21 -> Eltwise10 (in-place)
I1003 09:37:45.482410  7223 net.cpp:122] Setting up M2PELU21
I1003 09:37:45.482414  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.482417  7223 net.cpp:137] Memory required for data: 728679600
I1003 09:37:45.482420  7223 layer_factory.hpp:77] Creating layer Eltwise10_M2PELU21_0_split
I1003 09:37:45.482424  7223 net.cpp:84] Creating Layer Eltwise10_M2PELU21_0_split
I1003 09:37:45.482427  7223 net.cpp:406] Eltwise10_M2PELU21_0_split <- Eltwise10
I1003 09:37:45.482430  7223 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_0
I1003 09:37:45.482434  7223 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_1
I1003 09:37:45.482462  7223 net.cpp:122] Setting up Eltwise10_M2PELU21_0_split
I1003 09:37:45.482466  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.482470  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.482471  7223 net.cpp:137] Memory required for data: 735233200
I1003 09:37:45.482473  7223 layer_factory.hpp:77] Creating layer Convolution23
I1003 09:37:45.482481  7223 net.cpp:84] Creating Layer Convolution23
I1003 09:37:45.482482  7223 net.cpp:406] Convolution23 <- Eltwise10_M2PELU21_0_split_0
I1003 09:37:45.482486  7223 net.cpp:380] Convolution23 -> Convolution23
I1003 09:37:45.483639  7223 net.cpp:122] Setting up Convolution23
I1003 09:37:45.483647  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.483649  7223 net.cpp:137] Memory required for data: 738510000
I1003 09:37:45.483654  7223 layer_factory.hpp:77] Creating layer BatchNorm23
I1003 09:37:45.483659  7223 net.cpp:84] Creating Layer BatchNorm23
I1003 09:37:45.483662  7223 net.cpp:406] BatchNorm23 <- Convolution23
I1003 09:37:45.483666  7223 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1003 09:37:45.483824  7223 net.cpp:122] Setting up BatchNorm23
I1003 09:37:45.483829  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.483831  7223 net.cpp:137] Memory required for data: 741786800
I1003 09:37:45.483836  7223 layer_factory.hpp:77] Creating layer Scale23
I1003 09:37:45.483839  7223 net.cpp:84] Creating Layer Scale23
I1003 09:37:45.483842  7223 net.cpp:406] Scale23 <- Convolution23
I1003 09:37:45.483846  7223 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1003 09:37:45.483877  7223 layer_factory.hpp:77] Creating layer Scale23
I1003 09:37:45.483968  7223 net.cpp:122] Setting up Scale23
I1003 09:37:45.483973  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.483975  7223 net.cpp:137] Memory required for data: 745063600
I1003 09:37:45.483979  7223 layer_factory.hpp:77] Creating layer M2PELU22
I1003 09:37:45.483983  7223 net.cpp:84] Creating Layer M2PELU22
I1003 09:37:45.483986  7223 net.cpp:406] M2PELU22 <- Convolution23
I1003 09:37:45.483990  7223 net.cpp:367] M2PELU22 -> Convolution23 (in-place)
I1003 09:37:45.484091  7223 net.cpp:122] Setting up M2PELU22
I1003 09:37:45.484094  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.484097  7223 net.cpp:137] Memory required for data: 748340400
I1003 09:37:45.484099  7223 layer_factory.hpp:77] Creating layer Convolution24
I1003 09:37:45.484107  7223 net.cpp:84] Creating Layer Convolution24
I1003 09:37:45.484115  7223 net.cpp:406] Convolution24 <- Convolution23
I1003 09:37:45.484122  7223 net.cpp:380] Convolution24 -> Convolution24
I1003 09:37:45.485257  7223 net.cpp:122] Setting up Convolution24
I1003 09:37:45.485266  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.485268  7223 net.cpp:137] Memory required for data: 751617200
I1003 09:37:45.485273  7223 layer_factory.hpp:77] Creating layer BatchNorm24
I1003 09:37:45.485277  7223 net.cpp:84] Creating Layer BatchNorm24
I1003 09:37:45.485280  7223 net.cpp:406] BatchNorm24 <- Convolution24
I1003 09:37:45.485285  7223 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1003 09:37:45.485932  7223 net.cpp:122] Setting up BatchNorm24
I1003 09:37:45.485940  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.485944  7223 net.cpp:137] Memory required for data: 754894000
I1003 09:37:45.485949  7223 layer_factory.hpp:77] Creating layer Scale24
I1003 09:37:45.485954  7223 net.cpp:84] Creating Layer Scale24
I1003 09:37:45.485957  7223 net.cpp:406] Scale24 <- Convolution24
I1003 09:37:45.485960  7223 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1003 09:37:45.485988  7223 layer_factory.hpp:77] Creating layer Scale24
I1003 09:37:45.486060  7223 net.cpp:122] Setting up Scale24
I1003 09:37:45.486065  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.486068  7223 net.cpp:137] Memory required for data: 758170800
I1003 09:37:45.486071  7223 layer_factory.hpp:77] Creating layer Eltwise11
I1003 09:37:45.486075  7223 net.cpp:84] Creating Layer Eltwise11
I1003 09:37:45.486078  7223 net.cpp:406] Eltwise11 <- Eltwise10_M2PELU21_0_split_1
I1003 09:37:45.486081  7223 net.cpp:406] Eltwise11 <- Convolution24
I1003 09:37:45.486085  7223 net.cpp:380] Eltwise11 -> Eltwise11
I1003 09:37:45.486096  7223 net.cpp:122] Setting up Eltwise11
I1003 09:37:45.486100  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.486102  7223 net.cpp:137] Memory required for data: 761447600
I1003 09:37:45.486104  7223 layer_factory.hpp:77] Creating layer M2PELU23
I1003 09:37:45.486109  7223 net.cpp:84] Creating Layer M2PELU23
I1003 09:37:45.486111  7223 net.cpp:406] M2PELU23 <- Eltwise11
I1003 09:37:45.486115  7223 net.cpp:367] M2PELU23 -> Eltwise11 (in-place)
I1003 09:37:45.486197  7223 net.cpp:122] Setting up M2PELU23
I1003 09:37:45.486202  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.486204  7223 net.cpp:137] Memory required for data: 764724400
I1003 09:37:45.486208  7223 layer_factory.hpp:77] Creating layer Eltwise11_M2PELU23_0_split
I1003 09:37:45.486212  7223 net.cpp:84] Creating Layer Eltwise11_M2PELU23_0_split
I1003 09:37:45.486214  7223 net.cpp:406] Eltwise11_M2PELU23_0_split <- Eltwise11
I1003 09:37:45.486218  7223 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_0
I1003 09:37:45.486222  7223 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_1
I1003 09:37:45.486244  7223 net.cpp:122] Setting up Eltwise11_M2PELU23_0_split
I1003 09:37:45.486248  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.486251  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.486253  7223 net.cpp:137] Memory required for data: 771278000
I1003 09:37:45.486255  7223 layer_factory.hpp:77] Creating layer Convolution25
I1003 09:37:45.486261  7223 net.cpp:84] Creating Layer Convolution25
I1003 09:37:45.486264  7223 net.cpp:406] Convolution25 <- Eltwise11_M2PELU23_0_split_0
I1003 09:37:45.486268  7223 net.cpp:380] Convolution25 -> Convolution25
I1003 09:37:45.487406  7223 net.cpp:122] Setting up Convolution25
I1003 09:37:45.487416  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.487419  7223 net.cpp:137] Memory required for data: 774554800
I1003 09:37:45.487423  7223 layer_factory.hpp:77] Creating layer BatchNorm25
I1003 09:37:45.487428  7223 net.cpp:84] Creating Layer BatchNorm25
I1003 09:37:45.487432  7223 net.cpp:406] BatchNorm25 <- Convolution25
I1003 09:37:45.487435  7223 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1003 09:37:45.487568  7223 net.cpp:122] Setting up BatchNorm25
I1003 09:37:45.487573  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.487576  7223 net.cpp:137] Memory required for data: 777831600
I1003 09:37:45.487581  7223 layer_factory.hpp:77] Creating layer Scale25
I1003 09:37:45.487586  7223 net.cpp:84] Creating Layer Scale25
I1003 09:37:45.487588  7223 net.cpp:406] Scale25 <- Convolution25
I1003 09:37:45.487591  7223 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1003 09:37:45.487617  7223 layer_factory.hpp:77] Creating layer Scale25
I1003 09:37:45.487689  7223 net.cpp:122] Setting up Scale25
I1003 09:37:45.487694  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.487695  7223 net.cpp:137] Memory required for data: 781108400
I1003 09:37:45.487699  7223 layer_factory.hpp:77] Creating layer M2PELU24
I1003 09:37:45.487704  7223 net.cpp:84] Creating Layer M2PELU24
I1003 09:37:45.487706  7223 net.cpp:406] M2PELU24 <- Convolution25
I1003 09:37:45.487710  7223 net.cpp:367] M2PELU24 -> Convolution25 (in-place)
I1003 09:37:45.487790  7223 net.cpp:122] Setting up M2PELU24
I1003 09:37:45.487795  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.487797  7223 net.cpp:137] Memory required for data: 784385200
I1003 09:37:45.487800  7223 layer_factory.hpp:77] Creating layer Convolution26
I1003 09:37:45.487809  7223 net.cpp:84] Creating Layer Convolution26
I1003 09:37:45.487812  7223 net.cpp:406] Convolution26 <- Convolution25
I1003 09:37:45.487815  7223 net.cpp:380] Convolution26 -> Convolution26
I1003 09:37:45.488570  7223 net.cpp:122] Setting up Convolution26
I1003 09:37:45.488577  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.488580  7223 net.cpp:137] Memory required for data: 787662000
I1003 09:37:45.488584  7223 layer_factory.hpp:77] Creating layer BatchNorm26
I1003 09:37:45.488590  7223 net.cpp:84] Creating Layer BatchNorm26
I1003 09:37:45.488592  7223 net.cpp:406] BatchNorm26 <- Convolution26
I1003 09:37:45.488596  7223 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1003 09:37:45.488719  7223 net.cpp:122] Setting up BatchNorm26
I1003 09:37:45.488723  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.488725  7223 net.cpp:137] Memory required for data: 790938800
I1003 09:37:45.488730  7223 layer_factory.hpp:77] Creating layer Scale26
I1003 09:37:45.488734  7223 net.cpp:84] Creating Layer Scale26
I1003 09:37:45.508498  7223 net.cpp:406] Scale26 <- Convolution26
I1003 09:37:45.508512  7223 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1003 09:37:45.508549  7223 layer_factory.hpp:77] Creating layer Scale26
I1003 09:37:45.508633  7223 net.cpp:122] Setting up Scale26
I1003 09:37:45.508638  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.508641  7223 net.cpp:137] Memory required for data: 794215600
I1003 09:37:45.508646  7223 layer_factory.hpp:77] Creating layer Eltwise12
I1003 09:37:45.508651  7223 net.cpp:84] Creating Layer Eltwise12
I1003 09:37:45.508652  7223 net.cpp:406] Eltwise12 <- Eltwise11_M2PELU23_0_split_1
I1003 09:37:45.508656  7223 net.cpp:406] Eltwise12 <- Convolution26
I1003 09:37:45.508659  7223 net.cpp:380] Eltwise12 -> Eltwise12
I1003 09:37:45.508672  7223 net.cpp:122] Setting up Eltwise12
I1003 09:37:45.508677  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.508679  7223 net.cpp:137] Memory required for data: 797492400
I1003 09:37:45.508682  7223 layer_factory.hpp:77] Creating layer M2PELU25
I1003 09:37:45.508697  7223 net.cpp:84] Creating Layer M2PELU25
I1003 09:37:45.508700  7223 net.cpp:406] M2PELU25 <- Eltwise12
I1003 09:37:45.508704  7223 net.cpp:367] M2PELU25 -> Eltwise12 (in-place)
I1003 09:37:45.508798  7223 net.cpp:122] Setting up M2PELU25
I1003 09:37:45.508803  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.508805  7223 net.cpp:137] Memory required for data: 800769200
I1003 09:37:45.508810  7223 layer_factory.hpp:77] Creating layer Eltwise12_M2PELU25_0_split
I1003 09:37:45.508815  7223 net.cpp:84] Creating Layer Eltwise12_M2PELU25_0_split
I1003 09:37:45.508826  7223 net.cpp:406] Eltwise12_M2PELU25_0_split <- Eltwise12
I1003 09:37:45.508829  7223 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_0
I1003 09:37:45.508834  7223 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_1
I1003 09:37:45.508862  7223 net.cpp:122] Setting up Eltwise12_M2PELU25_0_split
I1003 09:37:45.508867  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.508869  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.508872  7223 net.cpp:137] Memory required for data: 807322800
I1003 09:37:45.508874  7223 layer_factory.hpp:77] Creating layer Convolution27
I1003 09:37:45.508882  7223 net.cpp:84] Creating Layer Convolution27
I1003 09:37:45.508884  7223 net.cpp:406] Convolution27 <- Eltwise12_M2PELU25_0_split_0
I1003 09:37:45.508888  7223 net.cpp:380] Convolution27 -> Convolution27
I1003 09:37:45.510483  7223 net.cpp:122] Setting up Convolution27
I1003 09:37:45.510491  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.510494  7223 net.cpp:137] Memory required for data: 810599600
I1003 09:37:45.510499  7223 layer_factory.hpp:77] Creating layer BatchNorm27
I1003 09:37:45.510505  7223 net.cpp:84] Creating Layer BatchNorm27
I1003 09:37:45.510509  7223 net.cpp:406] BatchNorm27 <- Convolution27
I1003 09:37:45.510512  7223 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1003 09:37:45.510653  7223 net.cpp:122] Setting up BatchNorm27
I1003 09:37:45.510658  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.510660  7223 net.cpp:137] Memory required for data: 813876400
I1003 09:37:45.510665  7223 layer_factory.hpp:77] Creating layer Scale27
I1003 09:37:45.510670  7223 net.cpp:84] Creating Layer Scale27
I1003 09:37:45.510673  7223 net.cpp:406] Scale27 <- Convolution27
I1003 09:37:45.510676  7223 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1003 09:37:45.510704  7223 layer_factory.hpp:77] Creating layer Scale27
I1003 09:37:45.510774  7223 net.cpp:122] Setting up Scale27
I1003 09:37:45.510778  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.510781  7223 net.cpp:137] Memory required for data: 817153200
I1003 09:37:45.510784  7223 layer_factory.hpp:77] Creating layer M2PELU26
I1003 09:37:45.510789  7223 net.cpp:84] Creating Layer M2PELU26
I1003 09:37:45.510792  7223 net.cpp:406] M2PELU26 <- Convolution27
I1003 09:37:45.510797  7223 net.cpp:367] M2PELU26 -> Convolution27 (in-place)
I1003 09:37:45.510875  7223 net.cpp:122] Setting up M2PELU26
I1003 09:37:45.510879  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.510881  7223 net.cpp:137] Memory required for data: 820430000
I1003 09:37:45.510885  7223 layer_factory.hpp:77] Creating layer Convolution28
I1003 09:37:45.510892  7223 net.cpp:84] Creating Layer Convolution28
I1003 09:37:45.510895  7223 net.cpp:406] Convolution28 <- Convolution27
I1003 09:37:45.510898  7223 net.cpp:380] Convolution28 -> Convolution28
I1003 09:37:45.512493  7223 net.cpp:122] Setting up Convolution28
I1003 09:37:45.512503  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.512506  7223 net.cpp:137] Memory required for data: 823706800
I1003 09:37:45.512511  7223 layer_factory.hpp:77] Creating layer BatchNorm28
I1003 09:37:45.512516  7223 net.cpp:84] Creating Layer BatchNorm28
I1003 09:37:45.512519  7223 net.cpp:406] BatchNorm28 <- Convolution28
I1003 09:37:45.512523  7223 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1003 09:37:45.512655  7223 net.cpp:122] Setting up BatchNorm28
I1003 09:37:45.512660  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.512661  7223 net.cpp:137] Memory required for data: 826983600
I1003 09:37:45.512666  7223 layer_factory.hpp:77] Creating layer Scale28
I1003 09:37:45.512671  7223 net.cpp:84] Creating Layer Scale28
I1003 09:37:45.512673  7223 net.cpp:406] Scale28 <- Convolution28
I1003 09:37:45.512676  7223 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1003 09:37:45.512703  7223 layer_factory.hpp:77] Creating layer Scale28
I1003 09:37:45.512778  7223 net.cpp:122] Setting up Scale28
I1003 09:37:45.512789  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.512792  7223 net.cpp:137] Memory required for data: 830260400
I1003 09:37:45.512796  7223 layer_factory.hpp:77] Creating layer Eltwise13
I1003 09:37:45.512801  7223 net.cpp:84] Creating Layer Eltwise13
I1003 09:37:45.512804  7223 net.cpp:406] Eltwise13 <- Eltwise12_M2PELU25_0_split_1
I1003 09:37:45.512807  7223 net.cpp:406] Eltwise13 <- Convolution28
I1003 09:37:45.512811  7223 net.cpp:380] Eltwise13 -> Eltwise13
I1003 09:37:45.512823  7223 net.cpp:122] Setting up Eltwise13
I1003 09:37:45.512827  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.512830  7223 net.cpp:137] Memory required for data: 833537200
I1003 09:37:45.512831  7223 layer_factory.hpp:77] Creating layer M2PELU27
I1003 09:37:45.512836  7223 net.cpp:84] Creating Layer M2PELU27
I1003 09:37:45.512840  7223 net.cpp:406] M2PELU27 <- Eltwise13
I1003 09:37:45.512843  7223 net.cpp:367] M2PELU27 -> Eltwise13 (in-place)
I1003 09:37:45.512928  7223 net.cpp:122] Setting up M2PELU27
I1003 09:37:45.512933  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.512935  7223 net.cpp:137] Memory required for data: 836814000
I1003 09:37:45.512939  7223 layer_factory.hpp:77] Creating layer Eltwise13_M2PELU27_0_split
I1003 09:37:45.512943  7223 net.cpp:84] Creating Layer Eltwise13_M2PELU27_0_split
I1003 09:37:45.512945  7223 net.cpp:406] Eltwise13_M2PELU27_0_split <- Eltwise13
I1003 09:37:45.512948  7223 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_0
I1003 09:37:45.512953  7223 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_1
I1003 09:37:45.512976  7223 net.cpp:122] Setting up Eltwise13_M2PELU27_0_split
I1003 09:37:45.512980  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.512984  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.512985  7223 net.cpp:137] Memory required for data: 843367600
I1003 09:37:45.512987  7223 layer_factory.hpp:77] Creating layer Convolution29
I1003 09:37:45.512995  7223 net.cpp:84] Creating Layer Convolution29
I1003 09:37:45.512996  7223 net.cpp:406] Convolution29 <- Eltwise13_M2PELU27_0_split_0
I1003 09:37:45.513000  7223 net.cpp:380] Convolution29 -> Convolution29
I1003 09:37:45.514097  7223 net.cpp:122] Setting up Convolution29
I1003 09:37:45.514106  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.514108  7223 net.cpp:137] Memory required for data: 846644400
I1003 09:37:45.514113  7223 layer_factory.hpp:77] Creating layer BatchNorm29
I1003 09:37:45.514118  7223 net.cpp:84] Creating Layer BatchNorm29
I1003 09:37:45.514122  7223 net.cpp:406] BatchNorm29 <- Convolution29
I1003 09:37:45.514127  7223 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1003 09:37:45.514251  7223 net.cpp:122] Setting up BatchNorm29
I1003 09:37:45.514256  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.514257  7223 net.cpp:137] Memory required for data: 849921200
I1003 09:37:45.514262  7223 layer_factory.hpp:77] Creating layer Scale29
I1003 09:37:45.514266  7223 net.cpp:84] Creating Layer Scale29
I1003 09:37:45.514269  7223 net.cpp:406] Scale29 <- Convolution29
I1003 09:37:45.514272  7223 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1003 09:37:45.514298  7223 layer_factory.hpp:77] Creating layer Scale29
I1003 09:37:45.514369  7223 net.cpp:122] Setting up Scale29
I1003 09:37:45.514372  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.514375  7223 net.cpp:137] Memory required for data: 853198000
I1003 09:37:45.514400  7223 layer_factory.hpp:77] Creating layer M2PELU28
I1003 09:37:45.514406  7223 net.cpp:84] Creating Layer M2PELU28
I1003 09:37:45.514410  7223 net.cpp:406] M2PELU28 <- Convolution29
I1003 09:37:45.514412  7223 net.cpp:367] M2PELU28 -> Convolution29 (in-place)
I1003 09:37:45.514497  7223 net.cpp:122] Setting up M2PELU28
I1003 09:37:45.514500  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.514503  7223 net.cpp:137] Memory required for data: 856474800
I1003 09:37:45.514506  7223 layer_factory.hpp:77] Creating layer Convolution30
I1003 09:37:45.514538  7223 net.cpp:84] Creating Layer Convolution30
I1003 09:37:45.514542  7223 net.cpp:406] Convolution30 <- Convolution29
I1003 09:37:45.514547  7223 net.cpp:380] Convolution30 -> Convolution30
I1003 09:37:45.515661  7223 net.cpp:122] Setting up Convolution30
I1003 09:37:45.515669  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.515671  7223 net.cpp:137] Memory required for data: 859751600
I1003 09:37:45.515676  7223 layer_factory.hpp:77] Creating layer BatchNorm30
I1003 09:37:45.515681  7223 net.cpp:84] Creating Layer BatchNorm30
I1003 09:37:45.515684  7223 net.cpp:406] BatchNorm30 <- Convolution30
I1003 09:37:45.515687  7223 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1003 09:37:45.515808  7223 net.cpp:122] Setting up BatchNorm30
I1003 09:37:45.515812  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.515815  7223 net.cpp:137] Memory required for data: 863028400
I1003 09:37:45.515820  7223 layer_factory.hpp:77] Creating layer Scale30
I1003 09:37:45.515825  7223 net.cpp:84] Creating Layer Scale30
I1003 09:37:45.515826  7223 net.cpp:406] Scale30 <- Convolution30
I1003 09:37:45.515830  7223 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1003 09:37:45.515854  7223 layer_factory.hpp:77] Creating layer Scale30
I1003 09:37:45.515924  7223 net.cpp:122] Setting up Scale30
I1003 09:37:45.515929  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.515931  7223 net.cpp:137] Memory required for data: 866305200
I1003 09:37:45.515934  7223 layer_factory.hpp:77] Creating layer Eltwise14
I1003 09:37:45.515938  7223 net.cpp:84] Creating Layer Eltwise14
I1003 09:37:45.515941  7223 net.cpp:406] Eltwise14 <- Eltwise13_M2PELU27_0_split_1
I1003 09:37:45.515944  7223 net.cpp:406] Eltwise14 <- Convolution30
I1003 09:37:45.515947  7223 net.cpp:380] Eltwise14 -> Eltwise14
I1003 09:37:45.515959  7223 net.cpp:122] Setting up Eltwise14
I1003 09:37:45.515964  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.515965  7223 net.cpp:137] Memory required for data: 869582000
I1003 09:37:45.515967  7223 layer_factory.hpp:77] Creating layer M2PELU29
I1003 09:37:45.515971  7223 net.cpp:84] Creating Layer M2PELU29
I1003 09:37:45.515974  7223 net.cpp:406] M2PELU29 <- Eltwise14
I1003 09:37:45.515977  7223 net.cpp:367] M2PELU29 -> Eltwise14 (in-place)
I1003 09:37:45.516062  7223 net.cpp:122] Setting up M2PELU29
I1003 09:37:45.516065  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.516067  7223 net.cpp:137] Memory required for data: 872858800
I1003 09:37:45.516072  7223 layer_factory.hpp:77] Creating layer Eltwise14_M2PELU29_0_split
I1003 09:37:45.516074  7223 net.cpp:84] Creating Layer Eltwise14_M2PELU29_0_split
I1003 09:37:45.516077  7223 net.cpp:406] Eltwise14_M2PELU29_0_split <- Eltwise14
I1003 09:37:45.516082  7223 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_0
I1003 09:37:45.516085  7223 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_1
I1003 09:37:45.516108  7223 net.cpp:122] Setting up Eltwise14_M2PELU29_0_split
I1003 09:37:45.516110  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.516113  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.516115  7223 net.cpp:137] Memory required for data: 879412400
I1003 09:37:45.516118  7223 layer_factory.hpp:77] Creating layer Convolution31
I1003 09:37:45.516124  7223 net.cpp:84] Creating Layer Convolution31
I1003 09:37:45.516126  7223 net.cpp:406] Convolution31 <- Eltwise14_M2PELU29_0_split_0
I1003 09:37:45.516130  7223 net.cpp:380] Convolution31 -> Convolution31
I1003 09:37:45.517189  7223 net.cpp:122] Setting up Convolution31
I1003 09:37:45.517197  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.517199  7223 net.cpp:137] Memory required for data: 882689200
I1003 09:37:45.517204  7223 layer_factory.hpp:77] Creating layer BatchNorm31
I1003 09:37:45.517210  7223 net.cpp:84] Creating Layer BatchNorm31
I1003 09:37:45.517212  7223 net.cpp:406] BatchNorm31 <- Convolution31
I1003 09:37:45.517222  7223 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1003 09:37:45.517343  7223 net.cpp:122] Setting up BatchNorm31
I1003 09:37:45.517347  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.517349  7223 net.cpp:137] Memory required for data: 885966000
I1003 09:37:45.517354  7223 layer_factory.hpp:77] Creating layer Scale31
I1003 09:37:45.517359  7223 net.cpp:84] Creating Layer Scale31
I1003 09:37:45.517361  7223 net.cpp:406] Scale31 <- Convolution31
I1003 09:37:45.517365  7223 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1003 09:37:45.517390  7223 layer_factory.hpp:77] Creating layer Scale31
I1003 09:37:45.517460  7223 net.cpp:122] Setting up Scale31
I1003 09:37:45.517464  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.517467  7223 net.cpp:137] Memory required for data: 889242800
I1003 09:37:45.517469  7223 layer_factory.hpp:77] Creating layer M2PELU30
I1003 09:37:45.517474  7223 net.cpp:84] Creating Layer M2PELU30
I1003 09:37:45.517477  7223 net.cpp:406] M2PELU30 <- Convolution31
I1003 09:37:45.517482  7223 net.cpp:367] M2PELU30 -> Convolution31 (in-place)
I1003 09:37:45.517558  7223 net.cpp:122] Setting up M2PELU30
I1003 09:37:45.517562  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.517565  7223 net.cpp:137] Memory required for data: 892519600
I1003 09:37:45.517567  7223 layer_factory.hpp:77] Creating layer Convolution32
I1003 09:37:45.517575  7223 net.cpp:84] Creating Layer Convolution32
I1003 09:37:45.517577  7223 net.cpp:406] Convolution32 <- Convolution31
I1003 09:37:45.517581  7223 net.cpp:380] Convolution32 -> Convolution32
I1003 09:37:45.518672  7223 net.cpp:122] Setting up Convolution32
I1003 09:37:45.518682  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.518683  7223 net.cpp:137] Memory required for data: 895796400
I1003 09:37:45.518688  7223 layer_factory.hpp:77] Creating layer BatchNorm32
I1003 09:37:45.518693  7223 net.cpp:84] Creating Layer BatchNorm32
I1003 09:37:45.518697  7223 net.cpp:406] BatchNorm32 <- Convolution32
I1003 09:37:45.518700  7223 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1003 09:37:45.518822  7223 net.cpp:122] Setting up BatchNorm32
I1003 09:37:45.518827  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.538614  7223 net.cpp:137] Memory required for data: 899073200
I1003 09:37:45.538626  7223 layer_factory.hpp:77] Creating layer Scale32
I1003 09:37:45.538632  7223 net.cpp:84] Creating Layer Scale32
I1003 09:37:45.538635  7223 net.cpp:406] Scale32 <- Convolution32
I1003 09:37:45.538641  7223 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1003 09:37:45.538679  7223 layer_factory.hpp:77] Creating layer Scale32
I1003 09:37:45.538763  7223 net.cpp:122] Setting up Scale32
I1003 09:37:45.538769  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.538771  7223 net.cpp:137] Memory required for data: 902350000
I1003 09:37:45.538775  7223 layer_factory.hpp:77] Creating layer Eltwise15
I1003 09:37:45.538779  7223 net.cpp:84] Creating Layer Eltwise15
I1003 09:37:45.538782  7223 net.cpp:406] Eltwise15 <- Eltwise14_M2PELU29_0_split_1
I1003 09:37:45.538786  7223 net.cpp:406] Eltwise15 <- Convolution32
I1003 09:37:45.538790  7223 net.cpp:380] Eltwise15 -> Eltwise15
I1003 09:37:45.538802  7223 net.cpp:122] Setting up Eltwise15
I1003 09:37:45.538806  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.538810  7223 net.cpp:137] Memory required for data: 905626800
I1003 09:37:45.538811  7223 layer_factory.hpp:77] Creating layer M2PELU31
I1003 09:37:45.538817  7223 net.cpp:84] Creating Layer M2PELU31
I1003 09:37:45.538820  7223 net.cpp:406] M2PELU31 <- Eltwise15
I1003 09:37:45.538823  7223 net.cpp:367] M2PELU31 -> Eltwise15 (in-place)
I1003 09:37:45.538916  7223 net.cpp:122] Setting up M2PELU31
I1003 09:37:45.538920  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.538923  7223 net.cpp:137] Memory required for data: 908903600
I1003 09:37:45.538928  7223 layer_factory.hpp:77] Creating layer Eltwise15_M2PELU31_0_split
I1003 09:37:45.538931  7223 net.cpp:84] Creating Layer Eltwise15_M2PELU31_0_split
I1003 09:37:45.538941  7223 net.cpp:406] Eltwise15_M2PELU31_0_split <- Eltwise15
I1003 09:37:45.538945  7223 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_0
I1003 09:37:45.538951  7223 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_1
I1003 09:37:45.538977  7223 net.cpp:122] Setting up Eltwise15_M2PELU31_0_split
I1003 09:37:45.538981  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.538985  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.538987  7223 net.cpp:137] Memory required for data: 915457200
I1003 09:37:45.538990  7223 layer_factory.hpp:77] Creating layer Convolution33
I1003 09:37:45.538996  7223 net.cpp:84] Creating Layer Convolution33
I1003 09:37:45.539000  7223 net.cpp:406] Convolution33 <- Eltwise15_M2PELU31_0_split_0
I1003 09:37:45.539005  7223 net.cpp:380] Convolution33 -> Convolution33
I1003 09:37:45.540235  7223 net.cpp:122] Setting up Convolution33
I1003 09:37:45.540246  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.540247  7223 net.cpp:137] Memory required for data: 918734000
I1003 09:37:45.540261  7223 layer_factory.hpp:77] Creating layer BatchNorm33
I1003 09:37:45.540266  7223 net.cpp:84] Creating Layer BatchNorm33
I1003 09:37:45.540269  7223 net.cpp:406] BatchNorm33 <- Convolution33
I1003 09:37:45.540284  7223 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1003 09:37:45.540439  7223 net.cpp:122] Setting up BatchNorm33
I1003 09:37:45.540444  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.540446  7223 net.cpp:137] Memory required for data: 922010800
I1003 09:37:45.540451  7223 layer_factory.hpp:77] Creating layer Scale33
I1003 09:37:45.540454  7223 net.cpp:84] Creating Layer Scale33
I1003 09:37:45.540457  7223 net.cpp:406] Scale33 <- Convolution33
I1003 09:37:45.540462  7223 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1003 09:37:45.540488  7223 layer_factory.hpp:77] Creating layer Scale33
I1003 09:37:45.540560  7223 net.cpp:122] Setting up Scale33
I1003 09:37:45.540565  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.540566  7223 net.cpp:137] Memory required for data: 925287600
I1003 09:37:45.540570  7223 layer_factory.hpp:77] Creating layer M2PELU32
I1003 09:37:45.540575  7223 net.cpp:84] Creating Layer M2PELU32
I1003 09:37:45.540577  7223 net.cpp:406] M2PELU32 <- Convolution33
I1003 09:37:45.540582  7223 net.cpp:367] M2PELU32 -> Convolution33 (in-place)
I1003 09:37:45.540663  7223 net.cpp:122] Setting up M2PELU32
I1003 09:37:45.540666  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.540668  7223 net.cpp:137] Memory required for data: 928564400
I1003 09:37:45.540671  7223 layer_factory.hpp:77] Creating layer Convolution34
I1003 09:37:45.540678  7223 net.cpp:84] Creating Layer Convolution34
I1003 09:37:45.540681  7223 net.cpp:406] Convolution34 <- Convolution33
I1003 09:37:45.540685  7223 net.cpp:380] Convolution34 -> Convolution34
I1003 09:37:45.542511  7223 net.cpp:122] Setting up Convolution34
I1003 09:37:45.542541  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.542554  7223 net.cpp:137] Memory required for data: 931841200
I1003 09:37:45.542559  7223 layer_factory.hpp:77] Creating layer BatchNorm34
I1003 09:37:45.542567  7223 net.cpp:84] Creating Layer BatchNorm34
I1003 09:37:45.542578  7223 net.cpp:406] BatchNorm34 <- Convolution34
I1003 09:37:45.542583  7223 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I1003 09:37:45.542742  7223 net.cpp:122] Setting up BatchNorm34
I1003 09:37:45.542745  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.542747  7223 net.cpp:137] Memory required for data: 935118000
I1003 09:37:45.542752  7223 layer_factory.hpp:77] Creating layer Scale34
I1003 09:37:45.542757  7223 net.cpp:84] Creating Layer Scale34
I1003 09:37:45.542759  7223 net.cpp:406] Scale34 <- Convolution34
I1003 09:37:45.542762  7223 net.cpp:367] Scale34 -> Convolution34 (in-place)
I1003 09:37:45.542789  7223 layer_factory.hpp:77] Creating layer Scale34
I1003 09:37:45.542871  7223 net.cpp:122] Setting up Scale34
I1003 09:37:45.542876  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.542878  7223 net.cpp:137] Memory required for data: 938394800
I1003 09:37:45.542882  7223 layer_factory.hpp:77] Creating layer Eltwise16
I1003 09:37:45.542886  7223 net.cpp:84] Creating Layer Eltwise16
I1003 09:37:45.542889  7223 net.cpp:406] Eltwise16 <- Eltwise15_M2PELU31_0_split_1
I1003 09:37:45.542892  7223 net.cpp:406] Eltwise16 <- Convolution34
I1003 09:37:45.542896  7223 net.cpp:380] Eltwise16 -> Eltwise16
I1003 09:37:45.542908  7223 net.cpp:122] Setting up Eltwise16
I1003 09:37:45.542912  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.542913  7223 net.cpp:137] Memory required for data: 941671600
I1003 09:37:45.542915  7223 layer_factory.hpp:77] Creating layer M2PELU33
I1003 09:37:45.542922  7223 net.cpp:84] Creating Layer M2PELU33
I1003 09:37:45.542923  7223 net.cpp:406] M2PELU33 <- Eltwise16
I1003 09:37:45.542927  7223 net.cpp:367] M2PELU33 -> Eltwise16 (in-place)
I1003 09:37:45.543009  7223 net.cpp:122] Setting up M2PELU33
I1003 09:37:45.543014  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.543015  7223 net.cpp:137] Memory required for data: 944948400
I1003 09:37:45.543020  7223 layer_factory.hpp:77] Creating layer Eltwise16_M2PELU33_0_split
I1003 09:37:45.543022  7223 net.cpp:84] Creating Layer Eltwise16_M2PELU33_0_split
I1003 09:37:45.543025  7223 net.cpp:406] Eltwise16_M2PELU33_0_split <- Eltwise16
I1003 09:37:45.543028  7223 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_0
I1003 09:37:45.543032  7223 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_1
I1003 09:37:45.543056  7223 net.cpp:122] Setting up Eltwise16_M2PELU33_0_split
I1003 09:37:45.543061  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.543063  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.543066  7223 net.cpp:137] Memory required for data: 951502000
I1003 09:37:45.543067  7223 layer_factory.hpp:77] Creating layer Convolution35
I1003 09:37:45.543072  7223 net.cpp:84] Creating Layer Convolution35
I1003 09:37:45.569164  7223 net.cpp:406] Convolution35 <- Eltwise16_M2PELU33_0_split_0
I1003 09:37:45.569178  7223 net.cpp:380] Convolution35 -> Convolution35
I1003 09:37:45.570407  7223 net.cpp:122] Setting up Convolution35
I1003 09:37:45.570418  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.570421  7223 net.cpp:137] Memory required for data: 954778800
I1003 09:37:45.570426  7223 layer_factory.hpp:77] Creating layer BatchNorm35
I1003 09:37:45.570431  7223 net.cpp:84] Creating Layer BatchNorm35
I1003 09:37:45.570435  7223 net.cpp:406] BatchNorm35 <- Convolution35
I1003 09:37:45.570439  7223 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I1003 09:37:45.570595  7223 net.cpp:122] Setting up BatchNorm35
I1003 09:37:45.570605  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.570610  7223 net.cpp:137] Memory required for data: 958055600
I1003 09:37:45.570618  7223 layer_factory.hpp:77] Creating layer Scale35
I1003 09:37:45.570626  7223 net.cpp:84] Creating Layer Scale35
I1003 09:37:45.570631  7223 net.cpp:406] Scale35 <- Convolution35
I1003 09:37:45.570636  7223 net.cpp:367] Scale35 -> Convolution35 (in-place)
I1003 09:37:45.570672  7223 layer_factory.hpp:77] Creating layer Scale35
I1003 09:37:45.570755  7223 net.cpp:122] Setting up Scale35
I1003 09:37:45.570760  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.570761  7223 net.cpp:137] Memory required for data: 961332400
I1003 09:37:45.570765  7223 layer_factory.hpp:77] Creating layer M2PELU34
I1003 09:37:45.570771  7223 net.cpp:84] Creating Layer M2PELU34
I1003 09:37:45.570773  7223 net.cpp:406] M2PELU34 <- Convolution35
I1003 09:37:45.570777  7223 net.cpp:367] M2PELU34 -> Convolution35 (in-place)
I1003 09:37:45.570863  7223 net.cpp:122] Setting up M2PELU34
I1003 09:37:45.570868  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.570869  7223 net.cpp:137] Memory required for data: 964609200
I1003 09:37:45.570881  7223 layer_factory.hpp:77] Creating layer Convolution36
I1003 09:37:45.570889  7223 net.cpp:84] Creating Layer Convolution36
I1003 09:37:45.570893  7223 net.cpp:406] Convolution36 <- Convolution35
I1003 09:37:45.570899  7223 net.cpp:380] Convolution36 -> Convolution36
I1003 09:37:45.571728  7223 net.cpp:122] Setting up Convolution36
I1003 09:37:45.571737  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.571738  7223 net.cpp:137] Memory required for data: 967886000
I1003 09:37:45.571743  7223 layer_factory.hpp:77] Creating layer BatchNorm36
I1003 09:37:45.571748  7223 net.cpp:84] Creating Layer BatchNorm36
I1003 09:37:45.571750  7223 net.cpp:406] BatchNorm36 <- Convolution36
I1003 09:37:45.571754  7223 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I1003 09:37:45.571883  7223 net.cpp:122] Setting up BatchNorm36
I1003 09:37:45.571887  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.571889  7223 net.cpp:137] Memory required for data: 971162800
I1003 09:37:45.571894  7223 layer_factory.hpp:77] Creating layer Scale36
I1003 09:37:45.571898  7223 net.cpp:84] Creating Layer Scale36
I1003 09:37:45.571900  7223 net.cpp:406] Scale36 <- Convolution36
I1003 09:37:45.571904  7223 net.cpp:367] Scale36 -> Convolution36 (in-place)
I1003 09:37:45.571930  7223 layer_factory.hpp:77] Creating layer Scale36
I1003 09:37:45.572006  7223 net.cpp:122] Setting up Scale36
I1003 09:37:45.572010  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.572012  7223 net.cpp:137] Memory required for data: 974439600
I1003 09:37:45.572016  7223 layer_factory.hpp:77] Creating layer Eltwise17
I1003 09:37:45.572021  7223 net.cpp:84] Creating Layer Eltwise17
I1003 09:37:45.572023  7223 net.cpp:406] Eltwise17 <- Eltwise16_M2PELU33_0_split_1
I1003 09:37:45.572026  7223 net.cpp:406] Eltwise17 <- Convolution36
I1003 09:37:45.572031  7223 net.cpp:380] Eltwise17 -> Eltwise17
I1003 09:37:45.572042  7223 net.cpp:122] Setting up Eltwise17
I1003 09:37:45.572046  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.572048  7223 net.cpp:137] Memory required for data: 977716400
I1003 09:37:45.572051  7223 layer_factory.hpp:77] Creating layer M2PELU35
I1003 09:37:45.572055  7223 net.cpp:84] Creating Layer M2PELU35
I1003 09:37:45.572058  7223 net.cpp:406] M2PELU35 <- Eltwise17
I1003 09:37:45.572062  7223 net.cpp:367] M2PELU35 -> Eltwise17 (in-place)
I1003 09:37:45.572149  7223 net.cpp:122] Setting up M2PELU35
I1003 09:37:45.572152  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.572154  7223 net.cpp:137] Memory required for data: 980993200
I1003 09:37:45.572158  7223 layer_factory.hpp:77] Creating layer Eltwise17_M2PELU35_0_split
I1003 09:37:45.572162  7223 net.cpp:84] Creating Layer Eltwise17_M2PELU35_0_split
I1003 09:37:45.572165  7223 net.cpp:406] Eltwise17_M2PELU35_0_split <- Eltwise17
I1003 09:37:45.572168  7223 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_0
I1003 09:37:45.572172  7223 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_1
I1003 09:37:45.572196  7223 net.cpp:122] Setting up Eltwise17_M2PELU35_0_split
I1003 09:37:45.572201  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.572202  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.572204  7223 net.cpp:137] Memory required for data: 987546800
I1003 09:37:45.572207  7223 layer_factory.hpp:77] Creating layer Convolution37
I1003 09:37:45.572213  7223 net.cpp:84] Creating Layer Convolution37
I1003 09:37:45.572216  7223 net.cpp:406] Convolution37 <- Eltwise17_M2PELU35_0_split_0
I1003 09:37:45.572219  7223 net.cpp:380] Convolution37 -> Convolution37
I1003 09:37:45.573431  7223 net.cpp:122] Setting up Convolution37
I1003 09:37:45.573441  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.573444  7223 net.cpp:137] Memory required for data: 990823600
I1003 09:37:45.573448  7223 layer_factory.hpp:77] Creating layer BatchNorm37
I1003 09:37:45.573454  7223 net.cpp:84] Creating Layer BatchNorm37
I1003 09:37:45.573463  7223 net.cpp:406] BatchNorm37 <- Convolution37
I1003 09:37:45.573469  7223 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I1003 09:37:45.573597  7223 net.cpp:122] Setting up BatchNorm37
I1003 09:37:45.573602  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.573604  7223 net.cpp:137] Memory required for data: 994100400
I1003 09:37:45.573609  7223 layer_factory.hpp:77] Creating layer Scale37
I1003 09:37:45.573613  7223 net.cpp:84] Creating Layer Scale37
I1003 09:37:45.573616  7223 net.cpp:406] Scale37 <- Convolution37
I1003 09:37:45.573619  7223 net.cpp:367] Scale37 -> Convolution37 (in-place)
I1003 09:37:45.573645  7223 layer_factory.hpp:77] Creating layer Scale37
I1003 09:37:45.573719  7223 net.cpp:122] Setting up Scale37
I1003 09:37:45.573722  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.573724  7223 net.cpp:137] Memory required for data: 997377200
I1003 09:37:45.573729  7223 layer_factory.hpp:77] Creating layer M2PELU36
I1003 09:37:45.573734  7223 net.cpp:84] Creating Layer M2PELU36
I1003 09:37:45.573735  7223 net.cpp:406] M2PELU36 <- Convolution37
I1003 09:37:45.573740  7223 net.cpp:367] M2PELU36 -> Convolution37 (in-place)
I1003 09:37:45.573820  7223 net.cpp:122] Setting up M2PELU36
I1003 09:37:45.573824  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.573827  7223 net.cpp:137] Memory required for data: 1000654000
I1003 09:37:45.573830  7223 layer_factory.hpp:77] Creating layer Convolution38
I1003 09:37:45.573837  7223 net.cpp:84] Creating Layer Convolution38
I1003 09:37:45.573839  7223 net.cpp:406] Convolution38 <- Convolution37
I1003 09:37:45.573845  7223 net.cpp:380] Convolution38 -> Convolution38
I1003 09:37:45.575289  7223 net.cpp:122] Setting up Convolution38
I1003 09:37:45.575299  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.575300  7223 net.cpp:137] Memory required for data: 1003930800
I1003 09:37:45.575306  7223 layer_factory.hpp:77] Creating layer BatchNorm38
I1003 09:37:45.575310  7223 net.cpp:84] Creating Layer BatchNorm38
I1003 09:37:45.575314  7223 net.cpp:406] BatchNorm38 <- Convolution38
I1003 09:37:45.575317  7223 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I1003 09:37:45.575449  7223 net.cpp:122] Setting up BatchNorm38
I1003 09:37:45.575453  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.575455  7223 net.cpp:137] Memory required for data: 1007207600
I1003 09:37:45.575460  7223 layer_factory.hpp:77] Creating layer Scale38
I1003 09:37:45.575464  7223 net.cpp:84] Creating Layer Scale38
I1003 09:37:45.575466  7223 net.cpp:406] Scale38 <- Convolution38
I1003 09:37:45.575469  7223 net.cpp:367] Scale38 -> Convolution38 (in-place)
I1003 09:37:45.575496  7223 layer_factory.hpp:77] Creating layer Scale38
I1003 09:37:45.575572  7223 net.cpp:122] Setting up Scale38
I1003 09:37:45.575575  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.575577  7223 net.cpp:137] Memory required for data: 1010484400
I1003 09:37:45.575582  7223 layer_factory.hpp:77] Creating layer Eltwise18
I1003 09:37:45.575587  7223 net.cpp:84] Creating Layer Eltwise18
I1003 09:37:45.575590  7223 net.cpp:406] Eltwise18 <- Eltwise17_M2PELU35_0_split_1
I1003 09:37:45.575593  7223 net.cpp:406] Eltwise18 <- Convolution38
I1003 09:37:45.575598  7223 net.cpp:380] Eltwise18 -> Eltwise18
I1003 09:37:45.575609  7223 net.cpp:122] Setting up Eltwise18
I1003 09:37:45.575613  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.575614  7223 net.cpp:137] Memory required for data: 1013761200
I1003 09:37:45.575616  7223 layer_factory.hpp:77] Creating layer M2PELU37
I1003 09:37:45.575623  7223 net.cpp:84] Creating Layer M2PELU37
I1003 09:37:45.575624  7223 net.cpp:406] M2PELU37 <- Eltwise18
I1003 09:37:45.575628  7223 net.cpp:367] M2PELU37 -> Eltwise18 (in-place)
I1003 09:37:45.575713  7223 net.cpp:122] Setting up M2PELU37
I1003 09:37:45.575717  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.575719  7223 net.cpp:137] Memory required for data: 1017038000
I1003 09:37:45.575723  7223 layer_factory.hpp:77] Creating layer Eltwise18_M2PELU37_0_split
I1003 09:37:45.575733  7223 net.cpp:84] Creating Layer Eltwise18_M2PELU37_0_split
I1003 09:37:45.575736  7223 net.cpp:406] Eltwise18_M2PELU37_0_split <- Eltwise18
I1003 09:37:45.575740  7223 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_0
I1003 09:37:45.575745  7223 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_1
I1003 09:37:45.575769  7223 net.cpp:122] Setting up Eltwise18_M2PELU37_0_split
I1003 09:37:45.575773  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.575775  7223 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1003 09:37:45.575778  7223 net.cpp:137] Memory required for data: 1023591600
I1003 09:37:45.575779  7223 layer_factory.hpp:77] Creating layer Convolution39
I1003 09:37:45.575785  7223 net.cpp:84] Creating Layer Convolution39
I1003 09:37:45.575788  7223 net.cpp:406] Convolution39 <- Eltwise18_M2PELU37_0_split_0
I1003 09:37:45.575793  7223 net.cpp:380] Convolution39 -> Convolution39
I1003 09:37:45.576752  7223 net.cpp:122] Setting up Convolution39
I1003 09:37:45.576761  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.576763  7223 net.cpp:137] Memory required for data: 1025230000
I1003 09:37:45.576768  7223 layer_factory.hpp:77] Creating layer BatchNorm39
I1003 09:37:45.576772  7223 net.cpp:84] Creating Layer BatchNorm39
I1003 09:37:45.576776  7223 net.cpp:406] BatchNorm39 <- Convolution39
I1003 09:37:45.576781  7223 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I1003 09:37:45.576913  7223 net.cpp:122] Setting up BatchNorm39
I1003 09:37:45.576917  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.576920  7223 net.cpp:137] Memory required for data: 1026868400
I1003 09:37:45.576925  7223 layer_factory.hpp:77] Creating layer Scale39
I1003 09:37:45.576927  7223 net.cpp:84] Creating Layer Scale39
I1003 09:37:45.576930  7223 net.cpp:406] Scale39 <- Convolution39
I1003 09:37:45.576934  7223 net.cpp:367] Scale39 -> Convolution39 (in-place)
I1003 09:37:45.576959  7223 layer_factory.hpp:77] Creating layer Scale39
I1003 09:37:45.577034  7223 net.cpp:122] Setting up Scale39
I1003 09:37:45.577039  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.577040  7223 net.cpp:137] Memory required for data: 1028506800
I1003 09:37:45.577044  7223 layer_factory.hpp:77] Creating layer Convolution40
I1003 09:37:45.577051  7223 net.cpp:84] Creating Layer Convolution40
I1003 09:37:45.577054  7223 net.cpp:406] Convolution40 <- Eltwise18_M2PELU37_0_split_1
I1003 09:37:45.577059  7223 net.cpp:380] Convolution40 -> Convolution40
I1003 09:37:45.578353  7223 net.cpp:122] Setting up Convolution40
I1003 09:37:45.578361  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.578364  7223 net.cpp:137] Memory required for data: 1030145200
I1003 09:37:45.578368  7223 layer_factory.hpp:77] Creating layer BatchNorm40
I1003 09:37:45.578373  7223 net.cpp:84] Creating Layer BatchNorm40
I1003 09:37:45.578377  7223 net.cpp:406] BatchNorm40 <- Convolution40
I1003 09:37:45.578380  7223 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I1003 09:37:45.578542  7223 net.cpp:122] Setting up BatchNorm40
I1003 09:37:45.578547  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.578560  7223 net.cpp:137] Memory required for data: 1031783600
I1003 09:37:45.578565  7223 layer_factory.hpp:77] Creating layer Scale40
I1003 09:37:45.578582  7223 net.cpp:84] Creating Layer Scale40
I1003 09:37:45.578584  7223 net.cpp:406] Scale40 <- Convolution40
I1003 09:37:45.578588  7223 net.cpp:367] Scale40 -> Convolution40 (in-place)
I1003 09:37:45.578614  7223 layer_factory.hpp:77] Creating layer Scale40
I1003 09:37:45.578689  7223 net.cpp:122] Setting up Scale40
I1003 09:37:45.578694  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.578696  7223 net.cpp:137] Memory required for data: 1033422000
I1003 09:37:45.578701  7223 layer_factory.hpp:77] Creating layer M2PELU38
I1003 09:37:45.578706  7223 net.cpp:84] Creating Layer M2PELU38
I1003 09:37:45.578707  7223 net.cpp:406] M2PELU38 <- Convolution40
I1003 09:37:45.578718  7223 net.cpp:367] M2PELU38 -> Convolution40 (in-place)
I1003 09:37:45.578809  7223 net.cpp:122] Setting up M2PELU38
I1003 09:37:45.578814  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.578816  7223 net.cpp:137] Memory required for data: 1035060400
I1003 09:37:45.578820  7223 layer_factory.hpp:77] Creating layer Convolution41
I1003 09:37:45.578826  7223 net.cpp:84] Creating Layer Convolution41
I1003 09:37:45.578830  7223 net.cpp:406] Convolution41 <- Convolution40
I1003 09:37:45.578835  7223 net.cpp:380] Convolution41 -> Convolution41
I1003 09:37:45.580516  7223 net.cpp:122] Setting up Convolution41
I1003 09:37:45.580524  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.580528  7223 net.cpp:137] Memory required for data: 1036698800
I1003 09:37:45.580531  7223 layer_factory.hpp:77] Creating layer BatchNorm41
I1003 09:37:45.580536  7223 net.cpp:84] Creating Layer BatchNorm41
I1003 09:37:45.580539  7223 net.cpp:406] BatchNorm41 <- Convolution41
I1003 09:37:45.580543  7223 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I1003 09:37:45.580673  7223 net.cpp:122] Setting up BatchNorm41
I1003 09:37:45.580678  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.580680  7223 net.cpp:137] Memory required for data: 1038337200
I1003 09:37:45.580684  7223 layer_factory.hpp:77] Creating layer Scale41
I1003 09:37:45.580688  7223 net.cpp:84] Creating Layer Scale41
I1003 09:37:45.580690  7223 net.cpp:406] Scale41 <- Convolution41
I1003 09:37:45.580693  7223 net.cpp:367] Scale41 -> Convolution41 (in-place)
I1003 09:37:45.580721  7223 layer_factory.hpp:77] Creating layer Scale41
I1003 09:37:45.580796  7223 net.cpp:122] Setting up Scale41
I1003 09:37:45.580799  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.580801  7223 net.cpp:137] Memory required for data: 1039975600
I1003 09:37:45.580806  7223 layer_factory.hpp:77] Creating layer Eltwise19
I1003 09:37:45.580809  7223 net.cpp:84] Creating Layer Eltwise19
I1003 09:37:45.580812  7223 net.cpp:406] Eltwise19 <- Convolution39
I1003 09:37:45.580816  7223 net.cpp:406] Eltwise19 <- Convolution41
I1003 09:37:45.580819  7223 net.cpp:380] Eltwise19 -> Eltwise19
I1003 09:37:45.580834  7223 net.cpp:122] Setting up Eltwise19
I1003 09:37:45.580838  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.580840  7223 net.cpp:137] Memory required for data: 1041614000
I1003 09:37:45.580842  7223 layer_factory.hpp:77] Creating layer M2PELU39
I1003 09:37:45.580847  7223 net.cpp:84] Creating Layer M2PELU39
I1003 09:37:45.580850  7223 net.cpp:406] M2PELU39 <- Eltwise19
I1003 09:37:45.580853  7223 net.cpp:367] M2PELU39 -> Eltwise19 (in-place)
I1003 09:37:45.580942  7223 net.cpp:122] Setting up M2PELU39
I1003 09:37:45.580946  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.580948  7223 net.cpp:137] Memory required for data: 1043252400
I1003 09:37:45.580952  7223 layer_factory.hpp:77] Creating layer Eltwise19_M2PELU39_0_split
I1003 09:37:45.580956  7223 net.cpp:84] Creating Layer Eltwise19_M2PELU39_0_split
I1003 09:37:45.580958  7223 net.cpp:406] Eltwise19_M2PELU39_0_split <- Eltwise19
I1003 09:37:45.580961  7223 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_0
I1003 09:37:45.580965  7223 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_1
I1003 09:37:45.580988  7223 net.cpp:122] Setting up Eltwise19_M2PELU39_0_split
I1003 09:37:45.580992  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.580996  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.580997  7223 net.cpp:137] Memory required for data: 1046529200
I1003 09:37:45.580999  7223 layer_factory.hpp:77] Creating layer Convolution42
I1003 09:37:45.581007  7223 net.cpp:84] Creating Layer Convolution42
I1003 09:37:45.581010  7223 net.cpp:406] Convolution42 <- Eltwise19_M2PELU39_0_split_0
I1003 09:37:45.581014  7223 net.cpp:380] Convolution42 -> Convolution42
I1003 09:37:45.582722  7223 net.cpp:122] Setting up Convolution42
I1003 09:37:45.582731  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.582741  7223 net.cpp:137] Memory required for data: 1048167600
I1003 09:37:45.582744  7223 layer_factory.hpp:77] Creating layer BatchNorm42
I1003 09:37:45.582751  7223 net.cpp:84] Creating Layer BatchNorm42
I1003 09:37:45.582753  7223 net.cpp:406] BatchNorm42 <- Convolution42
I1003 09:37:45.582756  7223 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I1003 09:37:45.582887  7223 net.cpp:122] Setting up BatchNorm42
I1003 09:37:45.582891  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.582893  7223 net.cpp:137] Memory required for data: 1049806000
I1003 09:37:45.582898  7223 layer_factory.hpp:77] Creating layer Scale42
I1003 09:37:45.582901  7223 net.cpp:84] Creating Layer Scale42
I1003 09:37:45.582904  7223 net.cpp:406] Scale42 <- Convolution42
I1003 09:37:45.582908  7223 net.cpp:367] Scale42 -> Convolution42 (in-place)
I1003 09:37:45.582934  7223 layer_factory.hpp:77] Creating layer Scale42
I1003 09:37:45.583009  7223 net.cpp:122] Setting up Scale42
I1003 09:37:45.583012  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.583014  7223 net.cpp:137] Memory required for data: 1051444400
I1003 09:37:45.583019  7223 layer_factory.hpp:77] Creating layer M2PELU40
I1003 09:37:45.583024  7223 net.cpp:84] Creating Layer M2PELU40
I1003 09:37:45.583026  7223 net.cpp:406] M2PELU40 <- Convolution42
I1003 09:37:45.583030  7223 net.cpp:367] M2PELU40 -> Convolution42 (in-place)
I1003 09:37:45.583117  7223 net.cpp:122] Setting up M2PELU40
I1003 09:37:45.583120  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.583122  7223 net.cpp:137] Memory required for data: 1053082800
I1003 09:37:45.583127  7223 layer_factory.hpp:77] Creating layer Convolution43
I1003 09:37:45.583132  7223 net.cpp:84] Creating Layer Convolution43
I1003 09:37:45.583135  7223 net.cpp:406] Convolution43 <- Convolution42
I1003 09:37:45.583139  7223 net.cpp:380] Convolution43 -> Convolution43
I1003 09:37:45.584815  7223 net.cpp:122] Setting up Convolution43
I1003 09:37:45.584823  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.584825  7223 net.cpp:137] Memory required for data: 1054721200
I1003 09:37:45.584830  7223 layer_factory.hpp:77] Creating layer BatchNorm43
I1003 09:37:45.584836  7223 net.cpp:84] Creating Layer BatchNorm43
I1003 09:37:45.584838  7223 net.cpp:406] BatchNorm43 <- Convolution43
I1003 09:37:45.584841  7223 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I1003 09:37:45.584975  7223 net.cpp:122] Setting up BatchNorm43
I1003 09:37:45.584978  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.584980  7223 net.cpp:137] Memory required for data: 1056359600
I1003 09:37:45.584985  7223 layer_factory.hpp:77] Creating layer Scale43
I1003 09:37:45.584988  7223 net.cpp:84] Creating Layer Scale43
I1003 09:37:45.584991  7223 net.cpp:406] Scale43 <- Convolution43
I1003 09:37:45.584995  7223 net.cpp:367] Scale43 -> Convolution43 (in-place)
I1003 09:37:45.585021  7223 layer_factory.hpp:77] Creating layer Scale43
I1003 09:37:45.585096  7223 net.cpp:122] Setting up Scale43
I1003 09:37:45.585100  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.585103  7223 net.cpp:137] Memory required for data: 1057998000
I1003 09:37:45.585106  7223 layer_factory.hpp:77] Creating layer Eltwise20
I1003 09:37:45.585111  7223 net.cpp:84] Creating Layer Eltwise20
I1003 09:37:45.585114  7223 net.cpp:406] Eltwise20 <- Eltwise19_M2PELU39_0_split_1
I1003 09:37:45.585116  7223 net.cpp:406] Eltwise20 <- Convolution43
I1003 09:37:45.585120  7223 net.cpp:380] Eltwise20 -> Eltwise20
I1003 09:37:45.585136  7223 net.cpp:122] Setting up Eltwise20
I1003 09:37:45.585140  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.585142  7223 net.cpp:137] Memory required for data: 1059636400
I1003 09:37:45.585144  7223 layer_factory.hpp:77] Creating layer M2PELU41
I1003 09:37:45.585150  7223 net.cpp:84] Creating Layer M2PELU41
I1003 09:37:45.585151  7223 net.cpp:406] M2PELU41 <- Eltwise20
I1003 09:37:45.585155  7223 net.cpp:367] M2PELU41 -> Eltwise20 (in-place)
I1003 09:37:45.585252  7223 net.cpp:122] Setting up M2PELU41
I1003 09:37:45.585256  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.585258  7223 net.cpp:137] Memory required for data: 1061274800
I1003 09:37:45.585261  7223 layer_factory.hpp:77] Creating layer Eltwise20_M2PELU41_0_split
I1003 09:37:45.585265  7223 net.cpp:84] Creating Layer Eltwise20_M2PELU41_0_split
I1003 09:37:45.585268  7223 net.cpp:406] Eltwise20_M2PELU41_0_split <- Eltwise20
I1003 09:37:45.585270  7223 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_0
I1003 09:37:45.585274  7223 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_1
I1003 09:37:45.585299  7223 net.cpp:122] Setting up Eltwise20_M2PELU41_0_split
I1003 09:37:45.585302  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.585305  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.585307  7223 net.cpp:137] Memory required for data: 1064551600
I1003 09:37:45.585309  7223 layer_factory.hpp:77] Creating layer Convolution44
I1003 09:37:45.585315  7223 net.cpp:84] Creating Layer Convolution44
I1003 09:37:45.585317  7223 net.cpp:406] Convolution44 <- Eltwise20_M2PELU41_0_split_0
I1003 09:37:45.585321  7223 net.cpp:380] Convolution44 -> Convolution44
I1003 09:37:45.587334  7223 net.cpp:122] Setting up Convolution44
I1003 09:37:45.587342  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.587345  7223 net.cpp:137] Memory required for data: 1066190000
I1003 09:37:45.587350  7223 layer_factory.hpp:77] Creating layer BatchNorm44
I1003 09:37:45.587355  7223 net.cpp:84] Creating Layer BatchNorm44
I1003 09:37:45.587357  7223 net.cpp:406] BatchNorm44 <- Convolution44
I1003 09:37:45.587363  7223 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I1003 09:37:45.587501  7223 net.cpp:122] Setting up BatchNorm44
I1003 09:37:45.587504  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.587507  7223 net.cpp:137] Memory required for data: 1067828400
I1003 09:37:45.599545  7223 layer_factory.hpp:77] Creating layer Scale44
I1003 09:37:45.599555  7223 net.cpp:84] Creating Layer Scale44
I1003 09:37:45.599560  7223 net.cpp:406] Scale44 <- Convolution44
I1003 09:37:45.599563  7223 net.cpp:367] Scale44 -> Convolution44 (in-place)
I1003 09:37:45.599606  7223 layer_factory.hpp:77] Creating layer Scale44
I1003 09:37:45.599701  7223 net.cpp:122] Setting up Scale44
I1003 09:37:45.599706  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.599709  7223 net.cpp:137] Memory required for data: 1069466800
I1003 09:37:45.599714  7223 layer_factory.hpp:77] Creating layer M2PELU42
I1003 09:37:45.599719  7223 net.cpp:84] Creating Layer M2PELU42
I1003 09:37:45.599721  7223 net.cpp:406] M2PELU42 <- Convolution44
I1003 09:37:45.599725  7223 net.cpp:367] M2PELU42 -> Convolution44 (in-place)
I1003 09:37:45.599826  7223 net.cpp:122] Setting up M2PELU42
I1003 09:37:45.599831  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.599834  7223 net.cpp:137] Memory required for data: 1071105200
I1003 09:37:45.599838  7223 layer_factory.hpp:77] Creating layer Convolution45
I1003 09:37:45.599846  7223 net.cpp:84] Creating Layer Convolution45
I1003 09:37:45.599848  7223 net.cpp:406] Convolution45 <- Convolution44
I1003 09:37:45.599853  7223 net.cpp:380] Convolution45 -> Convolution45
I1003 09:37:45.601924  7223 net.cpp:122] Setting up Convolution45
I1003 09:37:45.601933  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.601936  7223 net.cpp:137] Memory required for data: 1072743600
I1003 09:37:45.601940  7223 layer_factory.hpp:77] Creating layer BatchNorm45
I1003 09:37:45.601948  7223 net.cpp:84] Creating Layer BatchNorm45
I1003 09:37:45.601951  7223 net.cpp:406] BatchNorm45 <- Convolution45
I1003 09:37:45.601955  7223 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I1003 09:37:45.602092  7223 net.cpp:122] Setting up BatchNorm45
I1003 09:37:45.602097  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.602098  7223 net.cpp:137] Memory required for data: 1074382000
I1003 09:37:45.602113  7223 layer_factory.hpp:77] Creating layer Scale45
I1003 09:37:45.602118  7223 net.cpp:84] Creating Layer Scale45
I1003 09:37:45.602120  7223 net.cpp:406] Scale45 <- Convolution45
I1003 09:37:45.602124  7223 net.cpp:367] Scale45 -> Convolution45 (in-place)
I1003 09:37:45.602154  7223 layer_factory.hpp:77] Creating layer Scale45
I1003 09:37:45.602231  7223 net.cpp:122] Setting up Scale45
I1003 09:37:45.602236  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.602237  7223 net.cpp:137] Memory required for data: 1076020400
I1003 09:37:45.602241  7223 layer_factory.hpp:77] Creating layer Eltwise21
I1003 09:37:45.602246  7223 net.cpp:84] Creating Layer Eltwise21
I1003 09:37:45.602248  7223 net.cpp:406] Eltwise21 <- Eltwise20_M2PELU41_0_split_1
I1003 09:37:45.602252  7223 net.cpp:406] Eltwise21 <- Convolution45
I1003 09:37:45.602254  7223 net.cpp:380] Eltwise21 -> Eltwise21
I1003 09:37:45.602272  7223 net.cpp:122] Setting up Eltwise21
I1003 09:37:45.602275  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.602277  7223 net.cpp:137] Memory required for data: 1077658800
I1003 09:37:45.602279  7223 layer_factory.hpp:77] Creating layer M2PELU43
I1003 09:37:45.602285  7223 net.cpp:84] Creating Layer M2PELU43
I1003 09:37:45.602288  7223 net.cpp:406] M2PELU43 <- Eltwise21
I1003 09:37:45.602290  7223 net.cpp:367] M2PELU43 -> Eltwise21 (in-place)
I1003 09:37:45.602381  7223 net.cpp:122] Setting up M2PELU43
I1003 09:37:45.602385  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.602387  7223 net.cpp:137] Memory required for data: 1079297200
I1003 09:37:45.602391  7223 layer_factory.hpp:77] Creating layer Eltwise21_M2PELU43_0_split
I1003 09:37:45.602396  7223 net.cpp:84] Creating Layer Eltwise21_M2PELU43_0_split
I1003 09:37:45.602397  7223 net.cpp:406] Eltwise21_M2PELU43_0_split <- Eltwise21
I1003 09:37:45.602401  7223 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_0
I1003 09:37:45.602406  7223 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_1
I1003 09:37:45.602429  7223 net.cpp:122] Setting up Eltwise21_M2PELU43_0_split
I1003 09:37:45.602432  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.602435  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.602437  7223 net.cpp:137] Memory required for data: 1082574000
I1003 09:37:45.602439  7223 layer_factory.hpp:77] Creating layer Convolution46
I1003 09:37:45.602445  7223 net.cpp:84] Creating Layer Convolution46
I1003 09:37:45.602447  7223 net.cpp:406] Convolution46 <- Eltwise21_M2PELU43_0_split_0
I1003 09:37:45.602452  7223 net.cpp:380] Convolution46 -> Convolution46
I1003 09:37:45.604287  7223 net.cpp:122] Setting up Convolution46
I1003 09:37:45.604296  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.604300  7223 net.cpp:137] Memory required for data: 1084212400
I1003 09:37:45.604305  7223 layer_factory.hpp:77] Creating layer BatchNorm46
I1003 09:37:45.604308  7223 net.cpp:84] Creating Layer BatchNorm46
I1003 09:37:45.604311  7223 net.cpp:406] BatchNorm46 <- Convolution46
I1003 09:37:45.604315  7223 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I1003 09:37:45.604455  7223 net.cpp:122] Setting up BatchNorm46
I1003 09:37:45.604460  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.604462  7223 net.cpp:137] Memory required for data: 1085850800
I1003 09:37:45.604466  7223 layer_factory.hpp:77] Creating layer Scale46
I1003 09:37:45.604470  7223 net.cpp:84] Creating Layer Scale46
I1003 09:37:45.604473  7223 net.cpp:406] Scale46 <- Convolution46
I1003 09:37:45.604477  7223 net.cpp:367] Scale46 -> Convolution46 (in-place)
I1003 09:37:45.604503  7223 layer_factory.hpp:77] Creating layer Scale46
I1003 09:37:45.604583  7223 net.cpp:122] Setting up Scale46
I1003 09:37:45.604586  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.604589  7223 net.cpp:137] Memory required for data: 1087489200
I1003 09:37:45.604593  7223 layer_factory.hpp:77] Creating layer M2PELU44
I1003 09:37:45.604598  7223 net.cpp:84] Creating Layer M2PELU44
I1003 09:37:45.604607  7223 net.cpp:406] M2PELU44 <- Convolution46
I1003 09:37:45.604612  7223 net.cpp:367] M2PELU44 -> Convolution46 (in-place)
I1003 09:37:45.604704  7223 net.cpp:122] Setting up M2PELU44
I1003 09:37:45.604708  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.604710  7223 net.cpp:137] Memory required for data: 1089127600
I1003 09:37:45.604714  7223 layer_factory.hpp:77] Creating layer Convolution47
I1003 09:37:45.604722  7223 net.cpp:84] Creating Layer Convolution47
I1003 09:37:45.604724  7223 net.cpp:406] Convolution47 <- Convolution46
I1003 09:37:45.604728  7223 net.cpp:380] Convolution47 -> Convolution47
I1003 09:37:45.606413  7223 net.cpp:122] Setting up Convolution47
I1003 09:37:45.606421  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.606425  7223 net.cpp:137] Memory required for data: 1090766000
I1003 09:37:45.606428  7223 layer_factory.hpp:77] Creating layer BatchNorm47
I1003 09:37:45.606433  7223 net.cpp:84] Creating Layer BatchNorm47
I1003 09:37:45.606437  7223 net.cpp:406] BatchNorm47 <- Convolution47
I1003 09:37:45.606441  7223 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I1003 09:37:45.606578  7223 net.cpp:122] Setting up BatchNorm47
I1003 09:37:45.606582  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.606585  7223 net.cpp:137] Memory required for data: 1092404400
I1003 09:37:45.606590  7223 layer_factory.hpp:77] Creating layer Scale47
I1003 09:37:45.606595  7223 net.cpp:84] Creating Layer Scale47
I1003 09:37:45.606596  7223 net.cpp:406] Scale47 <- Convolution47
I1003 09:37:45.606600  7223 net.cpp:367] Scale47 -> Convolution47 (in-place)
I1003 09:37:45.606626  7223 layer_factory.hpp:77] Creating layer Scale47
I1003 09:37:45.606703  7223 net.cpp:122] Setting up Scale47
I1003 09:37:45.606709  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.606710  7223 net.cpp:137] Memory required for data: 1094042800
I1003 09:37:45.606714  7223 layer_factory.hpp:77] Creating layer Eltwise22
I1003 09:37:45.606719  7223 net.cpp:84] Creating Layer Eltwise22
I1003 09:37:45.606720  7223 net.cpp:406] Eltwise22 <- Eltwise21_M2PELU43_0_split_1
I1003 09:37:45.606724  7223 net.cpp:406] Eltwise22 <- Convolution47
I1003 09:37:45.606729  7223 net.cpp:380] Eltwise22 -> Eltwise22
I1003 09:37:45.606744  7223 net.cpp:122] Setting up Eltwise22
I1003 09:37:45.606747  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.606750  7223 net.cpp:137] Memory required for data: 1095681200
I1003 09:37:45.606751  7223 layer_factory.hpp:77] Creating layer M2PELU45
I1003 09:37:45.606756  7223 net.cpp:84] Creating Layer M2PELU45
I1003 09:37:45.606760  7223 net.cpp:406] M2PELU45 <- Eltwise22
I1003 09:37:45.606762  7223 net.cpp:367] M2PELU45 -> Eltwise22 (in-place)
I1003 09:37:45.606853  7223 net.cpp:122] Setting up M2PELU45
I1003 09:37:45.606856  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.606858  7223 net.cpp:137] Memory required for data: 1097319600
I1003 09:37:45.606861  7223 layer_factory.hpp:77] Creating layer Eltwise22_M2PELU45_0_split
I1003 09:37:45.606866  7223 net.cpp:84] Creating Layer Eltwise22_M2PELU45_0_split
I1003 09:37:45.606868  7223 net.cpp:406] Eltwise22_M2PELU45_0_split <- Eltwise22
I1003 09:37:45.606871  7223 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_0
I1003 09:37:45.606876  7223 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_1
I1003 09:37:45.606899  7223 net.cpp:122] Setting up Eltwise22_M2PELU45_0_split
I1003 09:37:45.606902  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.606905  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.606907  7223 net.cpp:137] Memory required for data: 1100596400
I1003 09:37:45.606909  7223 layer_factory.hpp:77] Creating layer Convolution48
I1003 09:37:45.606915  7223 net.cpp:84] Creating Layer Convolution48
I1003 09:37:45.606917  7223 net.cpp:406] Convolution48 <- Eltwise22_M2PELU45_0_split_0
I1003 09:37:45.606921  7223 net.cpp:380] Convolution48 -> Convolution48
I1003 09:37:45.608948  7223 net.cpp:122] Setting up Convolution48
I1003 09:37:45.608963  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.608968  7223 net.cpp:137] Memory required for data: 1102234800
I1003 09:37:45.608971  7223 layer_factory.hpp:77] Creating layer BatchNorm48
I1003 09:37:45.608978  7223 net.cpp:84] Creating Layer BatchNorm48
I1003 09:37:45.608981  7223 net.cpp:406] BatchNorm48 <- Convolution48
I1003 09:37:45.608985  7223 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I1003 09:37:45.609125  7223 net.cpp:122] Setting up BatchNorm48
I1003 09:37:45.609130  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.609133  7223 net.cpp:137] Memory required for data: 1103873200
I1003 09:37:45.609138  7223 layer_factory.hpp:77] Creating layer Scale48
I1003 09:37:45.609141  7223 net.cpp:84] Creating Layer Scale48
I1003 09:37:45.609144  7223 net.cpp:406] Scale48 <- Convolution48
I1003 09:37:45.609148  7223 net.cpp:367] Scale48 -> Convolution48 (in-place)
I1003 09:37:45.609175  7223 layer_factory.hpp:77] Creating layer Scale48
I1003 09:37:45.609253  7223 net.cpp:122] Setting up Scale48
I1003 09:37:45.609258  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.609261  7223 net.cpp:137] Memory required for data: 1105511600
I1003 09:37:45.609263  7223 layer_factory.hpp:77] Creating layer M2PELU46
I1003 09:37:45.609268  7223 net.cpp:84] Creating Layer M2PELU46
I1003 09:37:45.609272  7223 net.cpp:406] M2PELU46 <- Convolution48
I1003 09:37:45.609274  7223 net.cpp:367] M2PELU46 -> Convolution48 (in-place)
I1003 09:37:45.609364  7223 net.cpp:122] Setting up M2PELU46
I1003 09:37:45.609369  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.609370  7223 net.cpp:137] Memory required for data: 1107150000
I1003 09:37:45.609374  7223 layer_factory.hpp:77] Creating layer Convolution49
I1003 09:37:45.609380  7223 net.cpp:84] Creating Layer Convolution49
I1003 09:37:45.609382  7223 net.cpp:406] Convolution49 <- Convolution48
I1003 09:37:45.609386  7223 net.cpp:380] Convolution49 -> Convolution49
I1003 09:37:45.611405  7223 net.cpp:122] Setting up Convolution49
I1003 09:37:45.611414  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.611416  7223 net.cpp:137] Memory required for data: 1108788400
I1003 09:37:45.611420  7223 layer_factory.hpp:77] Creating layer BatchNorm49
I1003 09:37:45.611426  7223 net.cpp:84] Creating Layer BatchNorm49
I1003 09:37:45.611429  7223 net.cpp:406] BatchNorm49 <- Convolution49
I1003 09:37:45.611433  7223 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I1003 09:37:45.611568  7223 net.cpp:122] Setting up BatchNorm49
I1003 09:37:45.611572  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.611574  7223 net.cpp:137] Memory required for data: 1110426800
I1003 09:37:45.611580  7223 layer_factory.hpp:77] Creating layer Scale49
I1003 09:37:45.611584  7223 net.cpp:84] Creating Layer Scale49
I1003 09:37:45.611587  7223 net.cpp:406] Scale49 <- Convolution49
I1003 09:37:45.611589  7223 net.cpp:367] Scale49 -> Convolution49 (in-place)
I1003 09:37:45.611616  7223 layer_factory.hpp:77] Creating layer Scale49
I1003 09:37:45.611711  7223 net.cpp:122] Setting up Scale49
I1003 09:37:45.611724  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.611726  7223 net.cpp:137] Memory required for data: 1112065200
I1003 09:37:45.611730  7223 layer_factory.hpp:77] Creating layer Eltwise23
I1003 09:37:45.611734  7223 net.cpp:84] Creating Layer Eltwise23
I1003 09:37:45.611737  7223 net.cpp:406] Eltwise23 <- Eltwise22_M2PELU45_0_split_1
I1003 09:37:45.611739  7223 net.cpp:406] Eltwise23 <- Convolution49
I1003 09:37:45.611743  7223 net.cpp:380] Eltwise23 -> Eltwise23
I1003 09:37:45.611760  7223 net.cpp:122] Setting up Eltwise23
I1003 09:37:45.611763  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.611765  7223 net.cpp:137] Memory required for data: 1113703600
I1003 09:37:45.611768  7223 layer_factory.hpp:77] Creating layer M2PELU47
I1003 09:37:45.611773  7223 net.cpp:84] Creating Layer M2PELU47
I1003 09:37:45.611775  7223 net.cpp:406] M2PELU47 <- Eltwise23
I1003 09:37:45.611778  7223 net.cpp:367] M2PELU47 -> Eltwise23 (in-place)
I1003 09:37:45.611878  7223 net.cpp:122] Setting up M2PELU47
I1003 09:37:45.611883  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.611886  7223 net.cpp:137] Memory required for data: 1115342000
I1003 09:37:45.611889  7223 layer_factory.hpp:77] Creating layer Eltwise23_M2PELU47_0_split
I1003 09:37:45.611893  7223 net.cpp:84] Creating Layer Eltwise23_M2PELU47_0_split
I1003 09:37:45.611896  7223 net.cpp:406] Eltwise23_M2PELU47_0_split <- Eltwise23
I1003 09:37:45.611899  7223 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_0
I1003 09:37:45.611903  7223 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_1
I1003 09:37:45.611927  7223 net.cpp:122] Setting up Eltwise23_M2PELU47_0_split
I1003 09:37:45.611932  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.611934  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.611937  7223 net.cpp:137] Memory required for data: 1118618800
I1003 09:37:45.611938  7223 layer_factory.hpp:77] Creating layer Convolution50
I1003 09:37:45.611944  7223 net.cpp:84] Creating Layer Convolution50
I1003 09:37:45.611948  7223 net.cpp:406] Convolution50 <- Eltwise23_M2PELU47_0_split_0
I1003 09:37:45.611951  7223 net.cpp:380] Convolution50 -> Convolution50
I1003 09:37:45.614490  7223 net.cpp:122] Setting up Convolution50
I1003 09:37:45.614498  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.614500  7223 net.cpp:137] Memory required for data: 1120257200
I1003 09:37:45.614506  7223 layer_factory.hpp:77] Creating layer BatchNorm50
I1003 09:37:45.614511  7223 net.cpp:84] Creating Layer BatchNorm50
I1003 09:37:45.614513  7223 net.cpp:406] BatchNorm50 <- Convolution50
I1003 09:37:45.614517  7223 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I1003 09:37:45.630151  7223 net.cpp:122] Setting up BatchNorm50
I1003 09:37:45.630162  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.630163  7223 net.cpp:137] Memory required for data: 1121895600
I1003 09:37:45.630170  7223 layer_factory.hpp:77] Creating layer Scale50
I1003 09:37:45.630175  7223 net.cpp:84] Creating Layer Scale50
I1003 09:37:45.630178  7223 net.cpp:406] Scale50 <- Convolution50
I1003 09:37:45.630183  7223 net.cpp:367] Scale50 -> Convolution50 (in-place)
I1003 09:37:45.630215  7223 layer_factory.hpp:77] Creating layer Scale50
I1003 09:37:45.630303  7223 net.cpp:122] Setting up Scale50
I1003 09:37:45.630308  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.630311  7223 net.cpp:137] Memory required for data: 1123534000
I1003 09:37:45.630316  7223 layer_factory.hpp:77] Creating layer M2PELU48
I1003 09:37:45.630321  7223 net.cpp:84] Creating Layer M2PELU48
I1003 09:37:45.630323  7223 net.cpp:406] M2PELU48 <- Convolution50
I1003 09:37:45.630328  7223 net.cpp:367] M2PELU48 -> Convolution50 (in-place)
I1003 09:37:45.630429  7223 net.cpp:122] Setting up M2PELU48
I1003 09:37:45.630434  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.630436  7223 net.cpp:137] Memory required for data: 1125172400
I1003 09:37:45.630440  7223 layer_factory.hpp:77] Creating layer Convolution51
I1003 09:37:45.630447  7223 net.cpp:84] Creating Layer Convolution51
I1003 09:37:45.630450  7223 net.cpp:406] Convolution51 <- Convolution50
I1003 09:37:45.630455  7223 net.cpp:380] Convolution51 -> Convolution51
I1003 09:37:45.632475  7223 net.cpp:122] Setting up Convolution51
I1003 09:37:45.632484  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.632486  7223 net.cpp:137] Memory required for data: 1126810800
I1003 09:37:45.632491  7223 layer_factory.hpp:77] Creating layer BatchNorm51
I1003 09:37:45.632496  7223 net.cpp:84] Creating Layer BatchNorm51
I1003 09:37:45.632499  7223 net.cpp:406] BatchNorm51 <- Convolution51
I1003 09:37:45.632503  7223 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I1003 09:37:45.632642  7223 net.cpp:122] Setting up BatchNorm51
I1003 09:37:45.632647  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.632648  7223 net.cpp:137] Memory required for data: 1128449200
I1003 09:37:45.632661  7223 layer_factory.hpp:77] Creating layer Scale51
I1003 09:37:45.632665  7223 net.cpp:84] Creating Layer Scale51
I1003 09:37:45.632668  7223 net.cpp:406] Scale51 <- Convolution51
I1003 09:37:45.632671  7223 net.cpp:367] Scale51 -> Convolution51 (in-place)
I1003 09:37:45.632701  7223 layer_factory.hpp:77] Creating layer Scale51
I1003 09:37:45.632781  7223 net.cpp:122] Setting up Scale51
I1003 09:37:45.632786  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.632788  7223 net.cpp:137] Memory required for data: 1130087600
I1003 09:37:45.632791  7223 layer_factory.hpp:77] Creating layer Eltwise24
I1003 09:37:45.632797  7223 net.cpp:84] Creating Layer Eltwise24
I1003 09:37:45.632800  7223 net.cpp:406] Eltwise24 <- Eltwise23_M2PELU47_0_split_1
I1003 09:37:45.632803  7223 net.cpp:406] Eltwise24 <- Convolution51
I1003 09:37:45.632807  7223 net.cpp:380] Eltwise24 -> Eltwise24
I1003 09:37:45.632823  7223 net.cpp:122] Setting up Eltwise24
I1003 09:37:45.632827  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.632828  7223 net.cpp:137] Memory required for data: 1131726000
I1003 09:37:45.632830  7223 layer_factory.hpp:77] Creating layer M2PELU49
I1003 09:37:45.632836  7223 net.cpp:84] Creating Layer M2PELU49
I1003 09:37:45.632839  7223 net.cpp:406] M2PELU49 <- Eltwise24
I1003 09:37:45.632843  7223 net.cpp:367] M2PELU49 -> Eltwise24 (in-place)
I1003 09:37:45.632936  7223 net.cpp:122] Setting up M2PELU49
I1003 09:37:45.632941  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.632942  7223 net.cpp:137] Memory required for data: 1133364400
I1003 09:37:45.632946  7223 layer_factory.hpp:77] Creating layer Eltwise24_M2PELU49_0_split
I1003 09:37:45.632951  7223 net.cpp:84] Creating Layer Eltwise24_M2PELU49_0_split
I1003 09:37:45.632952  7223 net.cpp:406] Eltwise24_M2PELU49_0_split <- Eltwise24
I1003 09:37:45.632956  7223 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_0
I1003 09:37:45.632961  7223 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_1
I1003 09:37:45.632994  7223 net.cpp:122] Setting up Eltwise24_M2PELU49_0_split
I1003 09:37:45.632999  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.633002  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.633004  7223 net.cpp:137] Memory required for data: 1136641200
I1003 09:37:45.633007  7223 layer_factory.hpp:77] Creating layer Convolution52
I1003 09:37:45.633013  7223 net.cpp:84] Creating Layer Convolution52
I1003 09:37:45.633016  7223 net.cpp:406] Convolution52 <- Eltwise24_M2PELU49_0_split_0
I1003 09:37:45.633020  7223 net.cpp:380] Convolution52 -> Convolution52
I1003 09:37:45.635179  7223 net.cpp:122] Setting up Convolution52
I1003 09:37:45.635188  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.635191  7223 net.cpp:137] Memory required for data: 1138279600
I1003 09:37:45.635197  7223 layer_factory.hpp:77] Creating layer BatchNorm52
I1003 09:37:45.635202  7223 net.cpp:84] Creating Layer BatchNorm52
I1003 09:37:45.635205  7223 net.cpp:406] BatchNorm52 <- Convolution52
I1003 09:37:45.635210  7223 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I1003 09:37:45.635355  7223 net.cpp:122] Setting up BatchNorm52
I1003 09:37:45.635360  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.635362  7223 net.cpp:137] Memory required for data: 1139918000
I1003 09:37:45.635367  7223 layer_factory.hpp:77] Creating layer Scale52
I1003 09:37:45.635371  7223 net.cpp:84] Creating Layer Scale52
I1003 09:37:45.635373  7223 net.cpp:406] Scale52 <- Convolution52
I1003 09:37:45.635377  7223 net.cpp:367] Scale52 -> Convolution52 (in-place)
I1003 09:37:45.635406  7223 layer_factory.hpp:77] Creating layer Scale52
I1003 09:37:45.635488  7223 net.cpp:122] Setting up Scale52
I1003 09:37:45.635493  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.635495  7223 net.cpp:137] Memory required for data: 1141556400
I1003 09:37:45.635499  7223 layer_factory.hpp:77] Creating layer M2PELU50
I1003 09:37:45.635521  7223 net.cpp:84] Creating Layer M2PELU50
I1003 09:37:45.635531  7223 net.cpp:406] M2PELU50 <- Convolution52
I1003 09:37:45.635535  7223 net.cpp:367] M2PELU50 -> Convolution52 (in-place)
I1003 09:37:45.635635  7223 net.cpp:122] Setting up M2PELU50
I1003 09:37:45.635640  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.635643  7223 net.cpp:137] Memory required for data: 1143194800
I1003 09:37:45.635646  7223 layer_factory.hpp:77] Creating layer Convolution53
I1003 09:37:45.635653  7223 net.cpp:84] Creating Layer Convolution53
I1003 09:37:45.635656  7223 net.cpp:406] Convolution53 <- Convolution52
I1003 09:37:45.635660  7223 net.cpp:380] Convolution53 -> Convolution53
I1003 09:37:45.637370  7223 net.cpp:122] Setting up Convolution53
I1003 09:37:45.637379  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.637382  7223 net.cpp:137] Memory required for data: 1144833200
I1003 09:37:45.637387  7223 layer_factory.hpp:77] Creating layer BatchNorm53
I1003 09:37:45.637392  7223 net.cpp:84] Creating Layer BatchNorm53
I1003 09:37:45.637394  7223 net.cpp:406] BatchNorm53 <- Convolution53
I1003 09:37:45.637398  7223 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I1003 09:37:45.637539  7223 net.cpp:122] Setting up BatchNorm53
I1003 09:37:45.637543  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.637545  7223 net.cpp:137] Memory required for data: 1146471600
I1003 09:37:45.637550  7223 layer_factory.hpp:77] Creating layer Scale53
I1003 09:37:45.637554  7223 net.cpp:84] Creating Layer Scale53
I1003 09:37:45.637557  7223 net.cpp:406] Scale53 <- Convolution53
I1003 09:37:45.637559  7223 net.cpp:367] Scale53 -> Convolution53 (in-place)
I1003 09:37:45.637588  7223 layer_factory.hpp:77] Creating layer Scale53
I1003 09:37:45.637667  7223 net.cpp:122] Setting up Scale53
I1003 09:37:45.637671  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.637673  7223 net.cpp:137] Memory required for data: 1148110000
I1003 09:37:45.637677  7223 layer_factory.hpp:77] Creating layer Eltwise25
I1003 09:37:45.637682  7223 net.cpp:84] Creating Layer Eltwise25
I1003 09:37:45.637684  7223 net.cpp:406] Eltwise25 <- Eltwise24_M2PELU49_0_split_1
I1003 09:37:45.637687  7223 net.cpp:406] Eltwise25 <- Convolution53
I1003 09:37:45.637691  7223 net.cpp:380] Eltwise25 -> Eltwise25
I1003 09:37:45.637708  7223 net.cpp:122] Setting up Eltwise25
I1003 09:37:45.637712  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.637714  7223 net.cpp:137] Memory required for data: 1149748400
I1003 09:37:45.637717  7223 layer_factory.hpp:77] Creating layer M2PELU51
I1003 09:37:45.637722  7223 net.cpp:84] Creating Layer M2PELU51
I1003 09:37:45.637723  7223 net.cpp:406] M2PELU51 <- Eltwise25
I1003 09:37:45.637727  7223 net.cpp:367] M2PELU51 -> Eltwise25 (in-place)
I1003 09:37:45.637818  7223 net.cpp:122] Setting up M2PELU51
I1003 09:37:45.637822  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.637825  7223 net.cpp:137] Memory required for data: 1151386800
I1003 09:37:45.637828  7223 layer_factory.hpp:77] Creating layer Eltwise25_M2PELU51_0_split
I1003 09:37:45.637831  7223 net.cpp:84] Creating Layer Eltwise25_M2PELU51_0_split
I1003 09:37:45.637835  7223 net.cpp:406] Eltwise25_M2PELU51_0_split <- Eltwise25
I1003 09:37:45.637837  7223 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_0
I1003 09:37:45.637841  7223 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_1
I1003 09:37:45.637866  7223 net.cpp:122] Setting up Eltwise25_M2PELU51_0_split
I1003 09:37:45.637871  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.637872  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.637876  7223 net.cpp:137] Memory required for data: 1154663600
I1003 09:37:45.637877  7223 layer_factory.hpp:77] Creating layer Convolution54
I1003 09:37:45.637883  7223 net.cpp:84] Creating Layer Convolution54
I1003 09:37:45.637887  7223 net.cpp:406] Convolution54 <- Eltwise25_M2PELU51_0_split_0
I1003 09:37:45.637890  7223 net.cpp:380] Convolution54 -> Convolution54
I1003 09:37:45.639935  7223 net.cpp:122] Setting up Convolution54
I1003 09:37:45.639945  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.639947  7223 net.cpp:137] Memory required for data: 1156302000
I1003 09:37:45.639952  7223 layer_factory.hpp:77] Creating layer BatchNorm54
I1003 09:37:45.639956  7223 net.cpp:84] Creating Layer BatchNorm54
I1003 09:37:45.639960  7223 net.cpp:406] BatchNorm54 <- Convolution54
I1003 09:37:45.639963  7223 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I1003 09:37:45.640110  7223 net.cpp:122] Setting up BatchNorm54
I1003 09:37:45.640113  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.640115  7223 net.cpp:137] Memory required for data: 1157940400
I1003 09:37:45.640120  7223 layer_factory.hpp:77] Creating layer Scale54
I1003 09:37:45.640125  7223 net.cpp:84] Creating Layer Scale54
I1003 09:37:45.640127  7223 net.cpp:406] Scale54 <- Convolution54
I1003 09:37:45.640130  7223 net.cpp:367] Scale54 -> Convolution54 (in-place)
I1003 09:37:45.640158  7223 layer_factory.hpp:77] Creating layer Scale54
I1003 09:37:45.640241  7223 net.cpp:122] Setting up Scale54
I1003 09:37:45.640245  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.640249  7223 net.cpp:137] Memory required for data: 1159578800
I1003 09:37:45.640251  7223 layer_factory.hpp:77] Creating layer M2PELU52
I1003 09:37:45.640256  7223 net.cpp:84] Creating Layer M2PELU52
I1003 09:37:45.640259  7223 net.cpp:406] M2PELU52 <- Convolution54
I1003 09:37:45.640262  7223 net.cpp:367] M2PELU52 -> Convolution54 (in-place)
I1003 09:37:45.640357  7223 net.cpp:122] Setting up M2PELU52
I1003 09:37:45.640360  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.640363  7223 net.cpp:137] Memory required for data: 1161217200
I1003 09:37:45.640367  7223 layer_factory.hpp:77] Creating layer Convolution55
I1003 09:37:45.640374  7223 net.cpp:84] Creating Layer Convolution55
I1003 09:37:45.640377  7223 net.cpp:406] Convolution55 <- Convolution54
I1003 09:37:45.640380  7223 net.cpp:380] Convolution55 -> Convolution55
I1003 09:37:45.642088  7223 net.cpp:122] Setting up Convolution55
I1003 09:37:45.642097  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.642099  7223 net.cpp:137] Memory required for data: 1162855600
I1003 09:37:45.642104  7223 layer_factory.hpp:77] Creating layer BatchNorm55
I1003 09:37:45.642109  7223 net.cpp:84] Creating Layer BatchNorm55
I1003 09:37:45.642112  7223 net.cpp:406] BatchNorm55 <- Convolution55
I1003 09:37:45.642117  7223 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I1003 09:37:45.642256  7223 net.cpp:122] Setting up BatchNorm55
I1003 09:37:45.642261  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.642263  7223 net.cpp:137] Memory required for data: 1164494000
I1003 09:37:45.642268  7223 layer_factory.hpp:77] Creating layer Scale55
I1003 09:37:45.642272  7223 net.cpp:84] Creating Layer Scale55
I1003 09:37:45.642276  7223 net.cpp:406] Scale55 <- Convolution55
I1003 09:37:45.642278  7223 net.cpp:367] Scale55 -> Convolution55 (in-place)
I1003 09:37:45.642307  7223 layer_factory.hpp:77] Creating layer Scale55
I1003 09:37:45.642390  7223 net.cpp:122] Setting up Scale55
I1003 09:37:45.642393  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.642395  7223 net.cpp:137] Memory required for data: 1166132400
I1003 09:37:45.642400  7223 layer_factory.hpp:77] Creating layer Eltwise26
I1003 09:37:45.642403  7223 net.cpp:84] Creating Layer Eltwise26
I1003 09:37:45.642406  7223 net.cpp:406] Eltwise26 <- Eltwise25_M2PELU51_0_split_1
I1003 09:37:45.642410  7223 net.cpp:406] Eltwise26 <- Convolution55
I1003 09:37:45.642413  7223 net.cpp:380] Eltwise26 -> Eltwise26
I1003 09:37:45.642429  7223 net.cpp:122] Setting up Eltwise26
I1003 09:37:45.642433  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.642436  7223 net.cpp:137] Memory required for data: 1167770800
I1003 09:37:45.642437  7223 layer_factory.hpp:77] Creating layer M2PELU53
I1003 09:37:45.642442  7223 net.cpp:84] Creating Layer M2PELU53
I1003 09:37:45.642444  7223 net.cpp:406] M2PELU53 <- Eltwise26
I1003 09:37:45.642455  7223 net.cpp:367] M2PELU53 -> Eltwise26 (in-place)
I1003 09:37:45.642578  7223 net.cpp:122] Setting up M2PELU53
I1003 09:37:45.642583  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.642585  7223 net.cpp:137] Memory required for data: 1169409200
I1003 09:37:45.642590  7223 layer_factory.hpp:77] Creating layer Eltwise26_M2PELU53_0_split
I1003 09:37:45.642593  7223 net.cpp:84] Creating Layer Eltwise26_M2PELU53_0_split
I1003 09:37:45.642596  7223 net.cpp:406] Eltwise26_M2PELU53_0_split <- Eltwise26
I1003 09:37:45.642601  7223 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_0
I1003 09:37:45.642606  7223 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_1
I1003 09:37:45.642630  7223 net.cpp:122] Setting up Eltwise26_M2PELU53_0_split
I1003 09:37:45.642633  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.642637  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.642638  7223 net.cpp:137] Memory required for data: 1172686000
I1003 09:37:45.642640  7223 layer_factory.hpp:77] Creating layer Convolution56
I1003 09:37:45.642647  7223 net.cpp:84] Creating Layer Convolution56
I1003 09:37:45.642649  7223 net.cpp:406] Convolution56 <- Eltwise26_M2PELU53_0_split_0
I1003 09:37:45.642653  7223 net.cpp:380] Convolution56 -> Convolution56
I1003 09:37:45.644335  7223 net.cpp:122] Setting up Convolution56
I1003 09:37:45.644342  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.644345  7223 net.cpp:137] Memory required for data: 1174324400
I1003 09:37:45.644349  7223 layer_factory.hpp:77] Creating layer BatchNorm56
I1003 09:37:45.662544  7223 net.cpp:84] Creating Layer BatchNorm56
I1003 09:37:45.662564  7223 net.cpp:406] BatchNorm56 <- Convolution56
I1003 09:37:45.662573  7223 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I1003 09:37:45.662760  7223 net.cpp:122] Setting up BatchNorm56
I1003 09:37:45.662766  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.662768  7223 net.cpp:137] Memory required for data: 1175962800
I1003 09:37:45.662775  7223 layer_factory.hpp:77] Creating layer Scale56
I1003 09:37:45.662780  7223 net.cpp:84] Creating Layer Scale56
I1003 09:37:45.662781  7223 net.cpp:406] Scale56 <- Convolution56
I1003 09:37:45.662786  7223 net.cpp:367] Scale56 -> Convolution56 (in-place)
I1003 09:37:45.662817  7223 layer_factory.hpp:77] Creating layer Scale56
I1003 09:37:45.662905  7223 net.cpp:122] Setting up Scale56
I1003 09:37:45.662910  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.662912  7223 net.cpp:137] Memory required for data: 1177601200
I1003 09:37:45.662916  7223 layer_factory.hpp:77] Creating layer M2PELU54
I1003 09:37:45.662922  7223 net.cpp:84] Creating Layer M2PELU54
I1003 09:37:45.662925  7223 net.cpp:406] M2PELU54 <- Convolution56
I1003 09:37:45.662928  7223 net.cpp:367] M2PELU54 -> Convolution56 (in-place)
I1003 09:37:45.663030  7223 net.cpp:122] Setting up M2PELU54
I1003 09:37:45.663035  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.663038  7223 net.cpp:137] Memory required for data: 1179239600
I1003 09:37:45.663041  7223 layer_factory.hpp:77] Creating layer Convolution57
I1003 09:37:45.663048  7223 net.cpp:84] Creating Layer Convolution57
I1003 09:37:45.663051  7223 net.cpp:406] Convolution57 <- Convolution56
I1003 09:37:45.663056  7223 net.cpp:380] Convolution57 -> Convolution57
I1003 09:37:45.664904  7223 net.cpp:122] Setting up Convolution57
I1003 09:37:45.664913  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.664916  7223 net.cpp:137] Memory required for data: 1180878000
I1003 09:37:45.664921  7223 layer_factory.hpp:77] Creating layer BatchNorm57
I1003 09:37:45.664927  7223 net.cpp:84] Creating Layer BatchNorm57
I1003 09:37:45.664929  7223 net.cpp:406] BatchNorm57 <- Convolution57
I1003 09:37:45.664932  7223 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I1003 09:37:45.665076  7223 net.cpp:122] Setting up BatchNorm57
I1003 09:37:45.665081  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.665091  7223 net.cpp:137] Memory required for data: 1182516400
I1003 09:37:45.665096  7223 layer_factory.hpp:77] Creating layer Scale57
I1003 09:37:45.665100  7223 net.cpp:84] Creating Layer Scale57
I1003 09:37:45.665103  7223 net.cpp:406] Scale57 <- Convolution57
I1003 09:37:45.665107  7223 net.cpp:367] Scale57 -> Convolution57 (in-place)
I1003 09:37:45.665136  7223 layer_factory.hpp:77] Creating layer Scale57
I1003 09:37:45.665218  7223 net.cpp:122] Setting up Scale57
I1003 09:37:45.665222  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.665225  7223 net.cpp:137] Memory required for data: 1184154800
I1003 09:37:45.665228  7223 layer_factory.hpp:77] Creating layer Eltwise27
I1003 09:37:45.665232  7223 net.cpp:84] Creating Layer Eltwise27
I1003 09:37:45.665235  7223 net.cpp:406] Eltwise27 <- Eltwise26_M2PELU53_0_split_1
I1003 09:37:45.665238  7223 net.cpp:406] Eltwise27 <- Convolution57
I1003 09:37:45.665242  7223 net.cpp:380] Eltwise27 -> Eltwise27
I1003 09:37:45.665259  7223 net.cpp:122] Setting up Eltwise27
I1003 09:37:45.665262  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.665264  7223 net.cpp:137] Memory required for data: 1185793200
I1003 09:37:45.665266  7223 layer_factory.hpp:77] Creating layer M2PELU55
I1003 09:37:45.665271  7223 net.cpp:84] Creating Layer M2PELU55
I1003 09:37:45.665274  7223 net.cpp:406] M2PELU55 <- Eltwise27
I1003 09:37:45.665277  7223 net.cpp:367] M2PELU55 -> Eltwise27 (in-place)
I1003 09:37:45.665371  7223 net.cpp:122] Setting up M2PELU55
I1003 09:37:45.665375  7223 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1003 09:37:45.665379  7223 net.cpp:137] Memory required for data: 1187431600
I1003 09:37:45.665381  7223 layer_factory.hpp:77] Creating layer Pooling1
I1003 09:37:45.665386  7223 net.cpp:84] Creating Layer Pooling1
I1003 09:37:45.665388  7223 net.cpp:406] Pooling1 <- Eltwise27
I1003 09:37:45.665392  7223 net.cpp:380] Pooling1 -> Pooling1
I1003 09:37:45.665877  7223 net.cpp:122] Setting up Pooling1
I1003 09:37:45.665886  7223 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1003 09:37:45.665889  7223 net.cpp:137] Memory required for data: 1187457200
I1003 09:37:45.665891  7223 layer_factory.hpp:77] Creating layer InnerProduct1
I1003 09:37:45.665896  7223 net.cpp:84] Creating Layer InnerProduct1
I1003 09:37:45.665899  7223 net.cpp:406] InnerProduct1 <- Pooling1
I1003 09:37:45.665904  7223 net.cpp:380] InnerProduct1 -> InnerProduct1
I1003 09:37:45.666013  7223 net.cpp:122] Setting up InnerProduct1
I1003 09:37:45.666016  7223 net.cpp:129] Top shape: 100 10 (1000)
I1003 09:37:45.666018  7223 net.cpp:137] Memory required for data: 1187461200
I1003 09:37:45.666023  7223 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I1003 09:37:45.666028  7223 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I1003 09:37:45.666030  7223 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I1003 09:37:45.666034  7223 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I1003 09:37:45.666038  7223 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I1003 09:37:45.666065  7223 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I1003 09:37:45.666069  7223 net.cpp:129] Top shape: 100 10 (1000)
I1003 09:37:45.666071  7223 net.cpp:129] Top shape: 100 10 (1000)
I1003 09:37:45.666074  7223 net.cpp:137] Memory required for data: 1187469200
I1003 09:37:45.666075  7223 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1003 09:37:45.666079  7223 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1003 09:37:45.666081  7223 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I1003 09:37:45.666085  7223 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I1003 09:37:45.666088  7223 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1003 09:37:45.666093  7223 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1003 09:37:45.666292  7223 net.cpp:122] Setting up SoftmaxWithLoss1
I1003 09:37:45.666299  7223 net.cpp:129] Top shape: (1)
I1003 09:37:45.666307  7223 net.cpp:132]     with loss weight 1
I1003 09:37:45.666316  7223 net.cpp:137] Memory required for data: 1187469204
I1003 09:37:45.666317  7223 layer_factory.hpp:77] Creating layer Accuracy1
I1003 09:37:45.666323  7223 net.cpp:84] Creating Layer Accuracy1
I1003 09:37:45.666326  7223 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I1003 09:37:45.666329  7223 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I1003 09:37:45.666333  7223 net.cpp:380] Accuracy1 -> Accuracy1
I1003 09:37:45.666339  7223 net.cpp:122] Setting up Accuracy1
I1003 09:37:45.666342  7223 net.cpp:129] Top shape: (1)
I1003 09:37:45.666344  7223 net.cpp:137] Memory required for data: 1187469208
I1003 09:37:45.666347  7223 net.cpp:200] Accuracy1 does not need backward computation.
I1003 09:37:45.666349  7223 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1003 09:37:45.666352  7223 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I1003 09:37:45.666354  7223 net.cpp:198] InnerProduct1 needs backward computation.
I1003 09:37:45.666357  7223 net.cpp:198] Pooling1 needs backward computation.
I1003 09:37:45.666358  7223 net.cpp:198] M2PELU55 needs backward computation.
I1003 09:37:45.666360  7223 net.cpp:198] Eltwise27 needs backward computation.
I1003 09:37:45.666363  7223 net.cpp:198] Scale57 needs backward computation.
I1003 09:37:45.666365  7223 net.cpp:198] BatchNorm57 needs backward computation.
I1003 09:37:45.666368  7223 net.cpp:198] Convolution57 needs backward computation.
I1003 09:37:45.666370  7223 net.cpp:198] M2PELU54 needs backward computation.
I1003 09:37:45.666373  7223 net.cpp:198] Scale56 needs backward computation.
I1003 09:37:45.666374  7223 net.cpp:198] BatchNorm56 needs backward computation.
I1003 09:37:45.666376  7223 net.cpp:198] Convolution56 needs backward computation.
I1003 09:37:45.666378  7223 net.cpp:198] Eltwise26_M2PELU53_0_split needs backward computation.
I1003 09:37:45.666380  7223 net.cpp:198] M2PELU53 needs backward computation.
I1003 09:37:45.666383  7223 net.cpp:198] Eltwise26 needs backward computation.
I1003 09:37:45.666385  7223 net.cpp:198] Scale55 needs backward computation.
I1003 09:37:45.666388  7223 net.cpp:198] BatchNorm55 needs backward computation.
I1003 09:37:45.666389  7223 net.cpp:198] Convolution55 needs backward computation.
I1003 09:37:45.666391  7223 net.cpp:198] M2PELU52 needs backward computation.
I1003 09:37:45.666394  7223 net.cpp:198] Scale54 needs backward computation.
I1003 09:37:45.666396  7223 net.cpp:198] BatchNorm54 needs backward computation.
I1003 09:37:45.666399  7223 net.cpp:198] Convolution54 needs backward computation.
I1003 09:37:45.666400  7223 net.cpp:198] Eltwise25_M2PELU51_0_split needs backward computation.
I1003 09:37:45.666402  7223 net.cpp:198] M2PELU51 needs backward computation.
I1003 09:37:45.666405  7223 net.cpp:198] Eltwise25 needs backward computation.
I1003 09:37:45.666407  7223 net.cpp:198] Scale53 needs backward computation.
I1003 09:37:45.666410  7223 net.cpp:198] BatchNorm53 needs backward computation.
I1003 09:37:45.666412  7223 net.cpp:198] Convolution53 needs backward computation.
I1003 09:37:45.666414  7223 net.cpp:198] M2PELU50 needs backward computation.
I1003 09:37:45.666416  7223 net.cpp:198] Scale52 needs backward computation.
I1003 09:37:45.666419  7223 net.cpp:198] BatchNorm52 needs backward computation.
I1003 09:37:45.666420  7223 net.cpp:198] Convolution52 needs backward computation.
I1003 09:37:45.666424  7223 net.cpp:198] Eltwise24_M2PELU49_0_split needs backward computation.
I1003 09:37:45.666425  7223 net.cpp:198] M2PELU49 needs backward computation.
I1003 09:37:45.666429  7223 net.cpp:198] Eltwise24 needs backward computation.
I1003 09:37:45.666430  7223 net.cpp:198] Scale51 needs backward computation.
I1003 09:37:45.666432  7223 net.cpp:198] BatchNorm51 needs backward computation.
I1003 09:37:45.666435  7223 net.cpp:198] Convolution51 needs backward computation.
I1003 09:37:45.666436  7223 net.cpp:198] M2PELU48 needs backward computation.
I1003 09:37:45.666438  7223 net.cpp:198] Scale50 needs backward computation.
I1003 09:37:45.666445  7223 net.cpp:198] BatchNorm50 needs backward computation.
I1003 09:37:45.666447  7223 net.cpp:198] Convolution50 needs backward computation.
I1003 09:37:45.666450  7223 net.cpp:198] Eltwise23_M2PELU47_0_split needs backward computation.
I1003 09:37:45.666452  7223 net.cpp:198] M2PELU47 needs backward computation.
I1003 09:37:45.666455  7223 net.cpp:198] Eltwise23 needs backward computation.
I1003 09:37:45.666457  7223 net.cpp:198] Scale49 needs backward computation.
I1003 09:37:45.666460  7223 net.cpp:198] BatchNorm49 needs backward computation.
I1003 09:37:45.666462  7223 net.cpp:198] Convolution49 needs backward computation.
I1003 09:37:45.666465  7223 net.cpp:198] M2PELU46 needs backward computation.
I1003 09:37:45.666466  7223 net.cpp:198] Scale48 needs backward computation.
I1003 09:37:45.666468  7223 net.cpp:198] BatchNorm48 needs backward computation.
I1003 09:37:45.666471  7223 net.cpp:198] Convolution48 needs backward computation.
I1003 09:37:45.666473  7223 net.cpp:198] Eltwise22_M2PELU45_0_split needs backward computation.
I1003 09:37:45.666476  7223 net.cpp:198] M2PELU45 needs backward computation.
I1003 09:37:45.666477  7223 net.cpp:198] Eltwise22 needs backward computation.
I1003 09:37:45.666481  7223 net.cpp:198] Scale47 needs backward computation.
I1003 09:37:45.666482  7223 net.cpp:198] BatchNorm47 needs backward computation.
I1003 09:37:45.666486  7223 net.cpp:198] Convolution47 needs backward computation.
I1003 09:37:45.666487  7223 net.cpp:198] M2PELU44 needs backward computation.
I1003 09:37:45.666489  7223 net.cpp:198] Scale46 needs backward computation.
I1003 09:37:45.666492  7223 net.cpp:198] BatchNorm46 needs backward computation.
I1003 09:37:45.666494  7223 net.cpp:198] Convolution46 needs backward computation.
I1003 09:37:45.666496  7223 net.cpp:198] Eltwise21_M2PELU43_0_split needs backward computation.
I1003 09:37:45.666499  7223 net.cpp:198] M2PELU43 needs backward computation.
I1003 09:37:45.666501  7223 net.cpp:198] Eltwise21 needs backward computation.
I1003 09:37:45.666504  7223 net.cpp:198] Scale45 needs backward computation.
I1003 09:37:45.666507  7223 net.cpp:198] BatchNorm45 needs backward computation.
I1003 09:37:45.666508  7223 net.cpp:198] Convolution45 needs backward computation.
I1003 09:37:45.666510  7223 net.cpp:198] M2PELU42 needs backward computation.
I1003 09:37:45.666512  7223 net.cpp:198] Scale44 needs backward computation.
I1003 09:37:45.666515  7223 net.cpp:198] BatchNorm44 needs backward computation.
I1003 09:37:45.666517  7223 net.cpp:198] Convolution44 needs backward computation.
I1003 09:37:45.666528  7223 net.cpp:198] Eltwise20_M2PELU41_0_split needs backward computation.
I1003 09:37:45.666541  7223 net.cpp:198] M2PELU41 needs backward computation.
I1003 09:37:45.666544  7223 net.cpp:198] Eltwise20 needs backward computation.
I1003 09:37:45.666548  7223 net.cpp:198] Scale43 needs backward computation.
I1003 09:37:45.666549  7223 net.cpp:198] BatchNorm43 needs backward computation.
I1003 09:37:45.666551  7223 net.cpp:198] Convolution43 needs backward computation.
I1003 09:37:45.666554  7223 net.cpp:198] M2PELU40 needs backward computation.
I1003 09:37:45.666556  7223 net.cpp:198] Scale42 needs backward computation.
I1003 09:37:45.666568  7223 net.cpp:198] BatchNorm42 needs backward computation.
I1003 09:37:45.666569  7223 net.cpp:198] Convolution42 needs backward computation.
I1003 09:37:45.666573  7223 net.cpp:198] Eltwise19_M2PELU39_0_split needs backward computation.
I1003 09:37:45.666574  7223 net.cpp:198] M2PELU39 needs backward computation.
I1003 09:37:45.666577  7223 net.cpp:198] Eltwise19 needs backward computation.
I1003 09:37:45.666580  7223 net.cpp:198] Scale41 needs backward computation.
I1003 09:37:45.666582  7223 net.cpp:198] BatchNorm41 needs backward computation.
I1003 09:37:45.666584  7223 net.cpp:198] Convolution41 needs backward computation.
I1003 09:37:45.666587  7223 net.cpp:198] M2PELU38 needs backward computation.
I1003 09:37:45.666589  7223 net.cpp:198] Scale40 needs backward computation.
I1003 09:37:45.666595  7223 net.cpp:198] BatchNorm40 needs backward computation.
I1003 09:37:45.666599  7223 net.cpp:198] Convolution40 needs backward computation.
I1003 09:37:45.666600  7223 net.cpp:198] Scale39 needs backward computation.
I1003 09:37:45.666604  7223 net.cpp:198] BatchNorm39 needs backward computation.
I1003 09:37:45.666605  7223 net.cpp:198] Convolution39 needs backward computation.
I1003 09:37:45.666609  7223 net.cpp:198] Eltwise18_M2PELU37_0_split needs backward computation.
I1003 09:37:45.666610  7223 net.cpp:198] M2PELU37 needs backward computation.
I1003 09:37:45.666612  7223 net.cpp:198] Eltwise18 needs backward computation.
I1003 09:37:45.666615  7223 net.cpp:198] Scale38 needs backward computation.
I1003 09:37:45.666618  7223 net.cpp:198] BatchNorm38 needs backward computation.
I1003 09:37:45.666620  7223 net.cpp:198] Convolution38 needs backward computation.
I1003 09:37:45.666625  7223 net.cpp:198] M2PELU36 needs backward computation.
I1003 09:37:45.666626  7223 net.cpp:198] Scale37 needs backward computation.
I1003 09:37:45.666628  7223 net.cpp:198] BatchNorm37 needs backward computation.
I1003 09:37:45.666630  7223 net.cpp:198] Convolution37 needs backward computation.
I1003 09:37:45.666633  7223 net.cpp:198] Eltwise17_M2PELU35_0_split needs backward computation.
I1003 09:37:45.666636  7223 net.cpp:198] M2PELU35 needs backward computation.
I1003 09:37:45.666638  7223 net.cpp:198] Eltwise17 needs backward computation.
I1003 09:37:45.692858  7223 net.cpp:198] Scale36 needs backward computation.
I1003 09:37:45.692868  7223 net.cpp:198] BatchNorm36 needs backward computation.
I1003 09:37:45.692873  7223 net.cpp:198] Convolution36 needs backward computation.
I1003 09:37:45.692876  7223 net.cpp:198] M2PELU34 needs backward computation.
I1003 09:37:45.692881  7223 net.cpp:198] Scale35 needs backward computation.
I1003 09:37:45.692884  7223 net.cpp:198] BatchNorm35 needs backward computation.
I1003 09:37:45.692888  7223 net.cpp:198] Convolution35 needs backward computation.
I1003 09:37:45.692893  7223 net.cpp:198] Eltwise16_M2PELU33_0_split needs backward computation.
I1003 09:37:45.692896  7223 net.cpp:198] M2PELU33 needs backward computation.
I1003 09:37:45.692901  7223 net.cpp:198] Eltwise16 needs backward computation.
I1003 09:37:45.692903  7223 net.cpp:198] Scale34 needs backward computation.
I1003 09:37:45.692908  7223 net.cpp:198] BatchNorm34 needs backward computation.
I1003 09:37:45.692911  7223 net.cpp:198] Convolution34 needs backward computation.
I1003 09:37:45.692915  7223 net.cpp:198] M2PELU32 needs backward computation.
I1003 09:37:45.692919  7223 net.cpp:198] Scale33 needs backward computation.
I1003 09:37:45.692920  7223 net.cpp:198] BatchNorm33 needs backward computation.
I1003 09:37:45.692922  7223 net.cpp:198] Convolution33 needs backward computation.
I1003 09:37:45.692934  7223 net.cpp:198] Eltwise15_M2PELU31_0_split needs backward computation.
I1003 09:37:45.692937  7223 net.cpp:198] M2PELU31 needs backward computation.
I1003 09:37:45.692940  7223 net.cpp:198] Eltwise15 needs backward computation.
I1003 09:37:45.692942  7223 net.cpp:198] Scale32 needs backward computation.
I1003 09:37:45.692945  7223 net.cpp:198] BatchNorm32 needs backward computation.
I1003 09:37:45.692947  7223 net.cpp:198] Convolution32 needs backward computation.
I1003 09:37:45.692950  7223 net.cpp:198] M2PELU30 needs backward computation.
I1003 09:37:45.692952  7223 net.cpp:198] Scale31 needs backward computation.
I1003 09:37:45.692955  7223 net.cpp:198] BatchNorm31 needs backward computation.
I1003 09:37:45.692956  7223 net.cpp:198] Convolution31 needs backward computation.
I1003 09:37:45.692960  7223 net.cpp:198] Eltwise14_M2PELU29_0_split needs backward computation.
I1003 09:37:45.692961  7223 net.cpp:198] M2PELU29 needs backward computation.
I1003 09:37:45.692963  7223 net.cpp:198] Eltwise14 needs backward computation.
I1003 09:37:45.692966  7223 net.cpp:198] Scale30 needs backward computation.
I1003 09:37:45.692968  7223 net.cpp:198] BatchNorm30 needs backward computation.
I1003 09:37:45.692978  7223 net.cpp:198] Convolution30 needs backward computation.
I1003 09:37:45.692981  7223 net.cpp:198] M2PELU28 needs backward computation.
I1003 09:37:45.692983  7223 net.cpp:198] Scale29 needs backward computation.
I1003 09:37:45.692986  7223 net.cpp:198] BatchNorm29 needs backward computation.
I1003 09:37:45.692988  7223 net.cpp:198] Convolution29 needs backward computation.
I1003 09:37:45.692991  7223 net.cpp:198] Eltwise13_M2PELU27_0_split needs backward computation.
I1003 09:37:45.692993  7223 net.cpp:198] M2PELU27 needs backward computation.
I1003 09:37:45.692996  7223 net.cpp:198] Eltwise13 needs backward computation.
I1003 09:37:45.692998  7223 net.cpp:198] Scale28 needs backward computation.
I1003 09:37:45.693001  7223 net.cpp:198] BatchNorm28 needs backward computation.
I1003 09:37:45.693002  7223 net.cpp:198] Convolution28 needs backward computation.
I1003 09:37:45.693006  7223 net.cpp:198] M2PELU26 needs backward computation.
I1003 09:37:45.693007  7223 net.cpp:198] Scale27 needs backward computation.
I1003 09:37:45.693009  7223 net.cpp:198] BatchNorm27 needs backward computation.
I1003 09:37:45.693012  7223 net.cpp:198] Convolution27 needs backward computation.
I1003 09:37:45.693014  7223 net.cpp:198] Eltwise12_M2PELU25_0_split needs backward computation.
I1003 09:37:45.693017  7223 net.cpp:198] M2PELU25 needs backward computation.
I1003 09:37:45.693019  7223 net.cpp:198] Eltwise12 needs backward computation.
I1003 09:37:45.693022  7223 net.cpp:198] Scale26 needs backward computation.
I1003 09:37:45.693024  7223 net.cpp:198] BatchNorm26 needs backward computation.
I1003 09:37:45.693027  7223 net.cpp:198] Convolution26 needs backward computation.
I1003 09:37:45.693029  7223 net.cpp:198] M2PELU24 needs backward computation.
I1003 09:37:45.693032  7223 net.cpp:198] Scale25 needs backward computation.
I1003 09:37:45.693033  7223 net.cpp:198] BatchNorm25 needs backward computation.
I1003 09:37:45.693037  7223 net.cpp:198] Convolution25 needs backward computation.
I1003 09:37:45.693038  7223 net.cpp:198] Eltwise11_M2PELU23_0_split needs backward computation.
I1003 09:37:45.693042  7223 net.cpp:198] M2PELU23 needs backward computation.
I1003 09:37:45.693043  7223 net.cpp:198] Eltwise11 needs backward computation.
I1003 09:37:45.693047  7223 net.cpp:198] Scale24 needs backward computation.
I1003 09:37:45.693049  7223 net.cpp:198] BatchNorm24 needs backward computation.
I1003 09:37:45.693053  7223 net.cpp:198] Convolution24 needs backward computation.
I1003 09:37:45.693054  7223 net.cpp:198] M2PELU22 needs backward computation.
I1003 09:37:45.693056  7223 net.cpp:198] Scale23 needs backward computation.
I1003 09:37:45.693059  7223 net.cpp:198] BatchNorm23 needs backward computation.
I1003 09:37:45.693061  7223 net.cpp:198] Convolution23 needs backward computation.
I1003 09:37:45.693064  7223 net.cpp:198] Eltwise10_M2PELU21_0_split needs backward computation.
I1003 09:37:45.693066  7223 net.cpp:198] M2PELU21 needs backward computation.
I1003 09:37:45.693068  7223 net.cpp:198] Eltwise10 needs backward computation.
I1003 09:37:45.693071  7223 net.cpp:198] Scale22 needs backward computation.
I1003 09:37:45.693074  7223 net.cpp:198] BatchNorm22 needs backward computation.
I1003 09:37:45.693076  7223 net.cpp:198] Convolution22 needs backward computation.
I1003 09:37:45.693079  7223 net.cpp:198] M2PELU20 needs backward computation.
I1003 09:37:45.693081  7223 net.cpp:198] Scale21 needs backward computation.
I1003 09:37:45.693084  7223 net.cpp:198] BatchNorm21 needs backward computation.
I1003 09:37:45.693085  7223 net.cpp:198] Convolution21 needs backward computation.
I1003 09:37:45.693089  7223 net.cpp:198] Scale20 needs backward computation.
I1003 09:37:45.693090  7223 net.cpp:198] BatchNorm20 needs backward computation.
I1003 09:37:45.693092  7223 net.cpp:198] Convolution20 needs backward computation.
I1003 09:37:45.693095  7223 net.cpp:198] Eltwise9_M2PELU19_0_split needs backward computation.
I1003 09:37:45.693106  7223 net.cpp:198] M2PELU19 needs backward computation.
I1003 09:37:45.693109  7223 net.cpp:198] Eltwise9 needs backward computation.
I1003 09:37:45.693115  7223 net.cpp:198] Scale19 needs backward computation.
I1003 09:37:45.693120  7223 net.cpp:198] BatchNorm19 needs backward computation.
I1003 09:37:45.693121  7223 net.cpp:198] Convolution19 needs backward computation.
I1003 09:37:45.693125  7223 net.cpp:198] M2PELU18 needs backward computation.
I1003 09:37:45.693126  7223 net.cpp:198] Scale18 needs backward computation.
I1003 09:37:45.693130  7223 net.cpp:198] BatchNorm18 needs backward computation.
I1003 09:37:45.693131  7223 net.cpp:198] Convolution18 needs backward computation.
I1003 09:37:45.693135  7223 net.cpp:198] Eltwise8_M2PELU17_0_split needs backward computation.
I1003 09:37:45.693137  7223 net.cpp:198] M2PELU17 needs backward computation.
I1003 09:37:45.693140  7223 net.cpp:198] Eltwise8 needs backward computation.
I1003 09:37:45.693142  7223 net.cpp:198] Scale17 needs backward computation.
I1003 09:37:45.693145  7223 net.cpp:198] BatchNorm17 needs backward computation.
I1003 09:37:45.693147  7223 net.cpp:198] Convolution17 needs backward computation.
I1003 09:37:45.693150  7223 net.cpp:198] M2PELU16 needs backward computation.
I1003 09:37:45.693153  7223 net.cpp:198] Scale16 needs backward computation.
I1003 09:37:45.693156  7223 net.cpp:198] BatchNorm16 needs backward computation.
I1003 09:37:45.693158  7223 net.cpp:198] Convolution16 needs backward computation.
I1003 09:37:45.693161  7223 net.cpp:198] Eltwise7_M2PELU15_0_split needs backward computation.
I1003 09:37:45.693163  7223 net.cpp:198] M2PELU15 needs backward computation.
I1003 09:37:45.693166  7223 net.cpp:198] Eltwise7 needs backward computation.
I1003 09:37:45.693169  7223 net.cpp:198] Scale15 needs backward computation.
I1003 09:37:45.693172  7223 net.cpp:198] BatchNorm15 needs backward computation.
I1003 09:37:45.693174  7223 net.cpp:198] Convolution15 needs backward computation.
I1003 09:37:45.693177  7223 net.cpp:198] M2PELU14 needs backward computation.
I1003 09:37:45.693179  7223 net.cpp:198] Scale14 needs backward computation.
I1003 09:37:45.693182  7223 net.cpp:198] BatchNorm14 needs backward computation.
I1003 09:37:45.693184  7223 net.cpp:198] Convolution14 needs backward computation.
I1003 09:37:45.693187  7223 net.cpp:198] Eltwise6_M2PELU13_0_split needs backward computation.
I1003 09:37:45.693190  7223 net.cpp:198] M2PELU13 needs backward computation.
I1003 09:37:45.693193  7223 net.cpp:198] Eltwise6 needs backward computation.
I1003 09:37:45.693197  7223 net.cpp:198] Scale13 needs backward computation.
I1003 09:37:45.693198  7223 net.cpp:198] BatchNorm13 needs backward computation.
I1003 09:37:45.693202  7223 net.cpp:198] Convolution13 needs backward computation.
I1003 09:37:45.693203  7223 net.cpp:198] M2PELU12 needs backward computation.
I1003 09:37:45.693207  7223 net.cpp:198] Scale12 needs backward computation.
I1003 09:37:45.693208  7223 net.cpp:198] BatchNorm12 needs backward computation.
I1003 09:37:45.693212  7223 net.cpp:198] Convolution12 needs backward computation.
I1003 09:37:45.693214  7223 net.cpp:198] Eltwise5_M2PELU11_0_split needs backward computation.
I1003 09:37:45.693217  7223 net.cpp:198] M2PELU11 needs backward computation.
I1003 09:37:45.693219  7223 net.cpp:198] Eltwise5 needs backward computation.
I1003 09:37:45.693222  7223 net.cpp:198] Scale11 needs backward computation.
I1003 09:37:45.693225  7223 net.cpp:198] BatchNorm11 needs backward computation.
I1003 09:37:45.693228  7223 net.cpp:198] Convolution11 needs backward computation.
I1003 09:37:45.693230  7223 net.cpp:198] M2PELU10 needs backward computation.
I1003 09:37:45.693233  7223 net.cpp:198] Scale10 needs backward computation.
I1003 09:37:45.693234  7223 net.cpp:198] BatchNorm10 needs backward computation.
I1003 09:37:45.693238  7223 net.cpp:198] Convolution10 needs backward computation.
I1003 09:37:45.693240  7223 net.cpp:198] Eltwise4_M2PELU9_0_split needs backward computation.
I1003 09:37:45.693243  7223 net.cpp:198] M2PELU9 needs backward computation.
I1003 09:37:45.693246  7223 net.cpp:198] Eltwise4 needs backward computation.
I1003 09:37:45.693253  7223 net.cpp:198] Scale9 needs backward computation.
I1003 09:37:45.693255  7223 net.cpp:198] BatchNorm9 needs backward computation.
I1003 09:37:45.693259  7223 net.cpp:198] Convolution9 needs backward computation.
I1003 09:37:45.693261  7223 net.cpp:198] M2PELU8 needs backward computation.
I1003 09:37:45.693264  7223 net.cpp:198] Scale8 needs backward computation.
I1003 09:37:45.693266  7223 net.cpp:198] BatchNorm8 needs backward computation.
I1003 09:37:45.693269  7223 net.cpp:198] Convolution8 needs backward computation.
I1003 09:37:45.693271  7223 net.cpp:198] Eltwise3_M2PELU7_0_split needs backward computation.
I1003 09:37:45.693274  7223 net.cpp:198] M2PELU7 needs backward computation.
I1003 09:37:45.693277  7223 net.cpp:198] Eltwise3 needs backward computation.
I1003 09:37:45.693280  7223 net.cpp:198] Scale7 needs backward computation.
I1003 09:37:45.693284  7223 net.cpp:198] BatchNorm7 needs backward computation.
I1003 09:37:45.693286  7223 net.cpp:198] Convolution7 needs backward computation.
I1003 09:37:45.693289  7223 net.cpp:198] M2PELU6 needs backward computation.
I1003 09:37:45.693291  7223 net.cpp:198] Scale6 needs backward computation.
I1003 09:37:45.693294  7223 net.cpp:198] BatchNorm6 needs backward computation.
I1003 09:37:45.693296  7223 net.cpp:198] Convolution6 needs backward computation.
I1003 09:37:45.693301  7223 net.cpp:198] Eltwise2_M2PELU5_0_split needs backward computation.
I1003 09:37:45.693303  7223 net.cpp:198] M2PELU5 needs backward computation.
I1003 09:37:45.693306  7223 net.cpp:198] Eltwise2 needs backward computation.
I1003 09:37:45.693310  7223 net.cpp:198] Scale5 needs backward computation.
I1003 09:37:45.693312  7223 net.cpp:198] BatchNorm5 needs backward computation.
I1003 09:37:45.693315  7223 net.cpp:198] Convolution5 needs backward computation.
I1003 09:37:45.693317  7223 net.cpp:198] M2PELU4 needs backward computation.
I1003 09:37:45.693320  7223 net.cpp:198] Scale4 needs backward computation.
I1003 09:37:45.693322  7223 net.cpp:198] BatchNorm4 needs backward computation.
I1003 09:37:45.693325  7223 net.cpp:198] Convolution4 needs backward computation.
I1003 09:37:45.693327  7223 net.cpp:198] Eltwise1_M2PELU3_0_split needs backward computation.
I1003 09:37:45.693331  7223 net.cpp:198] M2PELU3 needs backward computation.
I1003 09:37:45.693333  7223 net.cpp:198] Eltwise1 needs backward computation.
I1003 09:37:45.693336  7223 net.cpp:198] Scale3 needs backward computation.
I1003 09:37:45.693339  7223 net.cpp:198] BatchNorm3 needs backward computation.
I1003 09:37:45.693341  7223 net.cpp:198] Convolution3 needs backward computation.
I1003 09:37:45.693346  7223 net.cpp:198] M2PELU2 needs backward computation.
I1003 09:37:45.693348  7223 net.cpp:198] Scale2 needs backward computation.
I1003 09:37:45.693351  7223 net.cpp:198] BatchNorm2 needs backward computation.
I1003 09:37:45.693352  7223 net.cpp:198] Convolution2 needs backward computation.
I1003 09:37:45.693356  7223 net.cpp:198] Convolution1_M2PELU1_0_split needs backward computation.
I1003 09:37:45.693358  7223 net.cpp:198] M2PELU1 needs backward computation.
I1003 09:37:45.693361  7223 net.cpp:198] Scale1 needs backward computation.
I1003 09:37:45.693363  7223 net.cpp:198] BatchNorm1 needs backward computation.
I1003 09:37:45.693367  7223 net.cpp:198] Convolution1 needs backward computation.
I1003 09:37:45.693369  7223 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I1003 09:37:45.693372  7223 net.cpp:200] Data1 does not need backward computation.
I1003 09:37:45.693375  7223 net.cpp:242] This network produces output Accuracy1
I1003 09:37:45.693378  7223 net.cpp:242] This network produces output SoftmaxWithLoss1
I1003 09:37:45.693480  7223 net.cpp:255] Network initialization done.
I1003 09:37:45.694536  7223 solver.cpp:56] Solver scaffolding done.
I1003 09:37:45.707099  7223 caffe.cpp:248] Starting Optimization
I1003 09:37:45.707106  7223 solver.cpp:272] Solving resnet_cifar10
I1003 09:37:45.707108  7223 solver.cpp:273] Learning Rate Policy: multistep
I1003 09:37:45.713039  7223 solver.cpp:330] Iteration 0, Testing net (#0)
I1003 09:37:49.161387  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:37:49.302464  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I1003 09:37:49.302500  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I1003 09:37:49.500283  7223 solver.cpp:218] Iteration 0 (0 iter/s, 3.79308s/100 iters), loss = 2.30774
I1003 09:37:49.500313  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.30774 (* 1 = 2.30774 loss)
I1003 09:37:49.500329  7223 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1003 09:38:03.707602  7223 solver.cpp:218] Iteration 100 (7.03871 iter/s, 14.2072s/100 iters), loss = 1.65637
I1003 09:38:03.707643  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.65637 (* 1 = 1.65637 loss)
I1003 09:38:03.707648  7223 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1003 09:38:17.916518  7223 solver.cpp:218] Iteration 200 (7.03792 iter/s, 14.2087s/100 iters), loss = 1.56977
I1003 09:38:17.916616  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.56977 (* 1 = 1.56977 loss)
I1003 09:38:17.916633  7223 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1003 09:38:32.114862  7223 solver.cpp:218] Iteration 300 (7.04319 iter/s, 14.1981s/100 iters), loss = 1.27218
I1003 09:38:32.114892  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.27218 (* 1 = 1.27218 loss)
I1003 09:38:32.114897  7223 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1003 09:38:46.323169  7223 solver.cpp:218] Iteration 400 (7.03821 iter/s, 14.2082s/100 iters), loss = 1.09787
I1003 09:38:46.323204  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.09787 (* 1 = 1.09787 loss)
I1003 09:38:46.323211  7223 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1003 09:38:59.827224  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:39:00.394371  7223 solver.cpp:330] Iteration 500, Testing net (#0)
I1003 09:39:03.755952  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:39:03.895848  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.2746
I1003 09:39:03.895884  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.46542 (* 1 = 3.46542 loss)
I1003 09:39:04.038818  7223 solver.cpp:218] Iteration 500 (5.64479 iter/s, 17.7155s/100 iters), loss = 1.14844
I1003 09:39:04.038866  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.14844 (* 1 = 1.14844 loss)
I1003 09:39:04.038873  7223 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1003 09:39:18.253857  7223 solver.cpp:218] Iteration 600 (7.0349 iter/s, 14.2148s/100 iters), loss = 1.13308
I1003 09:39:18.253902  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.13308 (* 1 = 1.13308 loss)
I1003 09:39:18.253911  7223 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1003 09:39:32.472990  7223 solver.cpp:218] Iteration 700 (7.03286 iter/s, 14.219s/100 iters), loss = 1.10936
I1003 09:39:32.473101  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.10936 (* 1 = 1.10936 loss)
I1003 09:39:32.473119  7223 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1003 09:39:46.706138  7223 solver.cpp:218] Iteration 800 (7.02596 iter/s, 14.2329s/100 iters), loss = 1.03572
I1003 09:39:46.706181  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.03572 (* 1 = 1.03572 loss)
I1003 09:39:46.706187  7223 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1003 09:40:00.925719  7223 solver.cpp:218] Iteration 900 (7.03263 iter/s, 14.2194s/100 iters), loss = 0.869994
I1003 09:40:00.925747  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.869994 (* 1 = 0.869994 loss)
I1003 09:40:00.925753  7223 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1003 09:40:14.444149  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:40:15.010921  7223 solver.cpp:330] Iteration 1000, Testing net (#0)
I1003 09:40:18.374507  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:40:18.514472  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4273
I1003 09:40:18.514508  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.29672 (* 1 = 2.29672 loss)
I1003 09:40:18.654472  7223 solver.cpp:218] Iteration 1000 (5.64061 iter/s, 17.7286s/100 iters), loss = 1.02428
I1003 09:40:18.654505  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.02428 (* 1 = 1.02428 loss)
I1003 09:40:18.654510  7223 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1003 09:40:32.876358  7223 solver.cpp:218] Iteration 1100 (7.03148 iter/s, 14.2218s/100 iters), loss = 0.889168
I1003 09:40:32.876390  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.889168 (* 1 = 0.889168 loss)
I1003 09:40:32.876407  7223 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1003 09:40:47.102360  7223 solver.cpp:218] Iteration 1200 (7.02944 iter/s, 14.2259s/100 iters), loss = 0.76513
I1003 09:40:47.102519  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.76513 (* 1 = 0.76513 loss)
I1003 09:40:47.102543  7223 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1003 09:41:01.316342  7223 solver.cpp:218] Iteration 1300 (7.03544 iter/s, 14.2137s/100 iters), loss = 0.948189
I1003 09:41:01.316377  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.948189 (* 1 = 0.948189 loss)
I1003 09:41:01.316385  7223 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1003 09:41:15.526536  7223 solver.cpp:218] Iteration 1400 (7.03726 iter/s, 14.2101s/100 iters), loss = 0.802183
I1003 09:41:15.526579  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.802183 (* 1 = 0.802183 loss)
I1003 09:41:15.526587  7223 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1003 09:41:29.046453  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:41:29.613415  7223 solver.cpp:330] Iteration 1500, Testing net (#0)
I1003 09:41:32.978560  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:41:33.119133  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.571
I1003 09:41:33.119160  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.40924 (* 1 = 1.40924 loss)
I1003 09:41:33.259493  7223 solver.cpp:218] Iteration 1500 (5.63926 iter/s, 17.7328s/100 iters), loss = 0.859151
I1003 09:41:33.259526  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.859151 (* 1 = 0.859151 loss)
I1003 09:41:33.259533  7223 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1003 09:41:47.483992  7223 solver.cpp:218] Iteration 1600 (7.03017 iter/s, 14.2244s/100 iters), loss = 0.639899
I1003 09:41:47.484024  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.639899 (* 1 = 0.639899 loss)
I1003 09:41:47.484030  7223 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1003 09:42:01.721421  7223 solver.cpp:218] Iteration 1700 (7.02379 iter/s, 14.2373s/100 iters), loss = 0.80109
I1003 09:42:01.721536  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.80109 (* 1 = 0.80109 loss)
I1003 09:42:01.721547  7223 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1003 09:42:15.946331  7223 solver.cpp:218] Iteration 1800 (7.03001 iter/s, 14.2247s/100 iters), loss = 0.754198
I1003 09:42:15.946359  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.754198 (* 1 = 0.754198 loss)
I1003 09:42:15.946365  7223 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1003 09:42:30.175892  7223 solver.cpp:218] Iteration 1900 (7.02767 iter/s, 14.2295s/100 iters), loss = 0.704599
I1003 09:42:30.175922  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.704599 (* 1 = 0.704599 loss)
I1003 09:42:30.175928  7223 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1003 09:42:43.706768  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:42:44.274132  7223 solver.cpp:330] Iteration 2000, Testing net (#0)
I1003 09:42:47.638196  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:42:47.777837  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.626
I1003 09:42:47.777863  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.16451 (* 1 = 1.16451 loss)
I1003 09:42:47.918910  7223 solver.cpp:218] Iteration 2000 (5.63605 iter/s, 17.7429s/100 iters), loss = 0.824412
I1003 09:42:47.918943  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.824412 (* 1 = 0.824412 loss)
I1003 09:42:47.918951  7223 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1003 09:43:02.160269  7223 solver.cpp:218] Iteration 2100 (7.02185 iter/s, 14.2413s/100 iters), loss = 0.694591
I1003 09:43:02.160298  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.694591 (* 1 = 0.694591 loss)
I1003 09:43:02.160305  7223 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1003 09:43:16.395692  7223 solver.cpp:218] Iteration 2200 (7.02478 iter/s, 14.2353s/100 iters), loss = 0.690089
I1003 09:43:16.395828  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.690089 (* 1 = 0.690089 loss)
I1003 09:43:16.395836  7223 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1003 09:43:30.619961  7223 solver.cpp:218] Iteration 2300 (7.03033 iter/s, 14.2241s/100 iters), loss = 0.785575
I1003 09:43:30.620004  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.785575 (* 1 = 0.785575 loss)
I1003 09:43:30.620012  7223 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1003 09:43:44.864912  7223 solver.cpp:218] Iteration 2400 (7.02008 iter/s, 14.2448s/100 iters), loss = 0.647894
I1003 09:43:44.864943  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.647894 (* 1 = 0.647894 loss)
I1003 09:43:44.864961  7223 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1003 09:43:58.403825  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:43:58.972990  7223 solver.cpp:330] Iteration 2500, Testing net (#0)
I1003 09:44:02.337757  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:44:02.477977  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6975
I1003 09:44:02.478013  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.862373 (* 1 = 0.862373 loss)
I1003 09:44:02.619217  7223 solver.cpp:218] Iteration 2500 (5.63247 iter/s, 17.7542s/100 iters), loss = 0.717439
I1003 09:44:02.619251  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.717439 (* 1 = 0.717439 loss)
I1003 09:44:02.619258  7223 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1003 09:44:16.857951  7223 solver.cpp:218] Iteration 2600 (7.02314 iter/s, 14.2386s/100 iters), loss = 0.57836
I1003 09:44:16.857983  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.57836 (* 1 = 0.57836 loss)
I1003 09:44:16.857990  7223 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1003 09:44:31.101954  7223 solver.cpp:218] Iteration 2700 (7.02055 iter/s, 14.2439s/100 iters), loss = 0.593831
I1003 09:44:31.102072  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.593831 (* 1 = 0.593831 loss)
I1003 09:44:31.102090  7223 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1003 09:44:45.345623  7223 solver.cpp:218] Iteration 2800 (7.02075 iter/s, 14.2435s/100 iters), loss = 0.806254
I1003 09:44:45.345652  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.806254 (* 1 = 0.806254 loss)
I1003 09:44:45.345659  7223 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1003 09:44:59.584132  7223 solver.cpp:218] Iteration 2900 (7.02325 iter/s, 14.2384s/100 iters), loss = 0.612495
I1003 09:44:59.584163  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.612495 (* 1 = 0.612495 loss)
I1003 09:44:59.584170  7223 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1003 09:45:13.111188  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:45:13.684116  7223 solver.cpp:330] Iteration 3000, Testing net (#0)
I1003 09:45:17.048364  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:45:17.187683  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7039
I1003 09:45:17.187718  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.883965 (* 1 = 0.883965 loss)
I1003 09:45:17.328100  7223 solver.cpp:218] Iteration 3000 (5.63575 iter/s, 17.7439s/100 iters), loss = 0.77456
I1003 09:45:17.328161  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.77456 (* 1 = 0.77456 loss)
I1003 09:45:17.328181  7223 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1003 09:45:31.563722  7223 solver.cpp:218] Iteration 3100 (7.02472 iter/s, 14.2354s/100 iters), loss = 0.517459
I1003 09:45:31.563765  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.517459 (* 1 = 0.517459 loss)
I1003 09:45:31.563771  7223 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1003 09:45:45.798092  7223 solver.cpp:218] Iteration 3200 (7.0253 iter/s, 14.2343s/100 iters), loss = 0.605868
I1003 09:45:45.798223  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.605868 (* 1 = 0.605868 loss)
I1003 09:45:45.798241  7223 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1003 09:46:00.040587  7223 solver.cpp:218] Iteration 3300 (7.02133 iter/s, 14.2423s/100 iters), loss = 0.654781
I1003 09:46:00.040617  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.654781 (* 1 = 0.654781 loss)
I1003 09:46:00.040624  7223 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1003 09:46:14.292032  7223 solver.cpp:218] Iteration 3400 (7.01688 iter/s, 14.2514s/100 iters), loss = 0.5977
I1003 09:46:14.292063  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.5977 (* 1 = 0.5977 loss)
I1003 09:46:14.292070  7223 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1003 09:46:27.815204  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:46:28.390507  7223 solver.cpp:330] Iteration 3500, Testing net (#0)
I1003 09:46:31.754467  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:46:31.894320  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6385
I1003 09:46:31.894356  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.07211 (* 1 = 1.07211 loss)
I1003 09:46:32.035259  7223 solver.cpp:218] Iteration 3500 (5.63598 iter/s, 17.7431s/100 iters), loss = 0.724231
I1003 09:46:32.035289  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.724231 (* 1 = 0.724231 loss)
I1003 09:46:32.035295  7223 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1003 09:46:46.260825  7223 solver.cpp:218] Iteration 3600 (7.02973 iter/s, 14.2253s/100 iters), loss = 0.534092
I1003 09:46:46.260861  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.534092 (* 1 = 0.534092 loss)
I1003 09:46:46.260870  7223 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1003 09:47:00.502276  7223 solver.cpp:218] Iteration 3700 (7.0218 iter/s, 14.2414s/100 iters), loss = 0.529047
I1003 09:47:00.502388  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.529047 (* 1 = 0.529047 loss)
I1003 09:47:00.502406  7223 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1003 09:47:14.749047  7223 solver.cpp:218] Iteration 3800 (7.01922 iter/s, 14.2466s/100 iters), loss = 0.660649
I1003 09:47:14.749090  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.660649 (* 1 = 0.660649 loss)
I1003 09:47:14.749097  7223 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1003 09:47:28.990068  7223 solver.cpp:218] Iteration 3900 (7.02202 iter/s, 14.2409s/100 iters), loss = 0.584665
I1003 09:47:28.990113  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.584665 (* 1 = 0.584665 loss)
I1003 09:47:28.990121  7223 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1003 09:47:42.522867  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:47:43.093935  7223 solver.cpp:330] Iteration 4000, Testing net (#0)
I1003 09:47:46.469635  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:47:46.609835  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6762
I1003 09:47:46.609863  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.970643 (* 1 = 0.970643 loss)
I1003 09:47:46.751209  7223 solver.cpp:218] Iteration 4000 (5.6303 iter/s, 17.761s/100 iters), loss = 0.675155
I1003 09:47:46.751245  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.675155 (* 1 = 0.675155 loss)
I1003 09:47:46.751255  7223 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1003 09:48:01.009007  7223 solver.cpp:218] Iteration 4100 (7.01375 iter/s, 14.2577s/100 iters), loss = 0.479946
I1003 09:48:01.009043  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.479946 (* 1 = 0.479946 loss)
I1003 09:48:01.009052  7223 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1003 09:48:15.269296  7223 solver.cpp:218] Iteration 4200 (7.01252 iter/s, 14.2602s/100 iters), loss = 0.610419
I1003 09:48:15.269444  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.610419 (* 1 = 0.610419 loss)
I1003 09:48:15.269454  7223 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1003 09:48:29.540127  7223 solver.cpp:218] Iteration 4300 (7.0074 iter/s, 14.2706s/100 iters), loss = 0.551023
I1003 09:48:29.540160  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.551023 (* 1 = 0.551023 loss)
I1003 09:48:29.540179  7223 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1003 09:48:43.811600  7223 solver.cpp:218] Iteration 4400 (7.00703 iter/s, 14.2714s/100 iters), loss = 0.565343
I1003 09:48:43.811635  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.565343 (* 1 = 0.565343 loss)
I1003 09:48:43.811653  7223 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1003 09:48:57.362542  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:48:57.930918  7223 solver.cpp:330] Iteration 4500, Testing net (#0)
I1003 09:49:01.309098  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:49:01.449553  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7403
I1003 09:49:01.449580  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.775309 (* 1 = 0.775309 loss)
I1003 09:49:01.591122  7223 solver.cpp:218] Iteration 4500 (5.62448 iter/s, 17.7794s/100 iters), loss = 0.572778
I1003 09:49:01.591156  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.572778 (* 1 = 0.572778 loss)
I1003 09:49:01.591166  7223 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1003 09:49:15.848237  7223 solver.cpp:218] Iteration 4600 (7.01409 iter/s, 14.257s/100 iters), loss = 0.509104
I1003 09:49:15.848269  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.509104 (* 1 = 0.509104 loss)
I1003 09:49:15.848286  7223 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1003 09:49:30.115322  7223 solver.cpp:218] Iteration 4700 (7.00918 iter/s, 14.267s/100 iters), loss = 0.497243
I1003 09:49:30.115468  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.497243 (* 1 = 0.497243 loss)
I1003 09:49:30.115496  7223 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1003 09:49:44.378113  7223 solver.cpp:218] Iteration 4800 (7.01134 iter/s, 14.2626s/100 iters), loss = 0.560113
I1003 09:49:44.378144  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.560113 (* 1 = 0.560113 loss)
I1003 09:49:44.378152  7223 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1003 09:49:58.634480  7223 solver.cpp:218] Iteration 4900 (7.01445 iter/s, 14.2563s/100 iters), loss = 0.541145
I1003 09:49:58.634516  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.541145 (* 1 = 0.541145 loss)
I1003 09:49:58.634528  7223 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1003 09:50:12.177115  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:50:12.744601  7223 solver.cpp:330] Iteration 5000, Testing net (#0)
I1003 09:50:16.121445  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:50:16.266449  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7258
I1003 09:50:16.266489  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.781053 (* 1 = 0.781053 loss)
I1003 09:50:16.409404  7223 solver.cpp:218] Iteration 5000 (5.62593 iter/s, 17.7748s/100 iters), loss = 0.537811
I1003 09:50:16.409442  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.537811 (* 1 = 0.537811 loss)
I1003 09:50:16.409452  7223 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I1003 09:50:30.665376  7223 solver.cpp:218] Iteration 5100 (7.01465 iter/s, 14.2559s/100 iters), loss = 0.462532
I1003 09:50:30.665412  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.462532 (* 1 = 0.462532 loss)
I1003 09:50:30.665431  7223 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I1003 09:50:44.922430  7223 solver.cpp:218] Iteration 5200 (7.01411 iter/s, 14.257s/100 iters), loss = 0.529891
I1003 09:50:44.922559  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.529891 (* 1 = 0.529891 loss)
I1003 09:50:44.922572  7223 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I1003 09:50:59.194381  7223 solver.cpp:218] Iteration 5300 (7.00684 iter/s, 14.2718s/100 iters), loss = 0.573277
I1003 09:50:59.194416  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.573277 (* 1 = 0.573277 loss)
I1003 09:50:59.194433  7223 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I1003 09:51:13.469246  7223 solver.cpp:218] Iteration 5400 (7.00536 iter/s, 14.2748s/100 iters), loss = 0.542136
I1003 09:51:13.469280  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.542136 (* 1 = 0.542136 loss)
I1003 09:51:13.469290  7223 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I1003 09:51:27.013859  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:51:27.582993  7223 solver.cpp:330] Iteration 5500, Testing net (#0)
I1003 09:51:30.953701  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:51:31.096295  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7223
I1003 09:51:31.096325  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.807232 (* 1 = 0.807232 loss)
I1003 09:51:31.241740  7223 solver.cpp:218] Iteration 5500 (5.6267 iter/s, 17.7724s/100 iters), loss = 0.53284
I1003 09:51:31.241781  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.53284 (* 1 = 0.53284 loss)
I1003 09:51:31.241801  7223 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I1003 09:51:45.489789  7223 solver.cpp:218] Iteration 5600 (7.01857 iter/s, 14.2479s/100 iters), loss = 0.530148
I1003 09:51:45.489822  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.530148 (* 1 = 0.530148 loss)
I1003 09:51:45.489845  7223 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I1003 09:51:59.752967  7223 solver.cpp:218] Iteration 5700 (7.0111 iter/s, 14.2631s/100 iters), loss = 0.467858
I1003 09:51:59.753108  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.467858 (* 1 = 0.467858 loss)
I1003 09:51:59.753129  7223 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I1003 09:52:14.005795  7223 solver.cpp:218] Iteration 5800 (7.01624 iter/s, 14.2527s/100 iters), loss = 0.568735
I1003 09:52:14.005826  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.568735 (* 1 = 0.568735 loss)
I1003 09:52:14.005836  7223 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I1003 09:52:28.257342  7223 solver.cpp:218] Iteration 5900 (7.01682 iter/s, 14.2515s/100 iters), loss = 0.620292
I1003 09:52:28.257382  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.620292 (* 1 = 0.620292 loss)
I1003 09:52:28.257392  7223 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I1003 09:52:41.809623  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:52:42.377485  7223 solver.cpp:330] Iteration 6000, Testing net (#0)
I1003 09:52:45.750639  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:52:45.890468  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7225
I1003 09:52:45.890496  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.789437 (* 1 = 0.789437 loss)
I1003 09:52:46.031595  7223 solver.cpp:218] Iteration 6000 (5.62614 iter/s, 17.7742s/100 iters), loss = 0.588679
I1003 09:52:46.031628  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.588679 (* 1 = 0.588679 loss)
I1003 09:52:46.031637  7223 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I1003 09:53:00.291806  7223 solver.cpp:218] Iteration 6100 (7.01256 iter/s, 14.2601s/100 iters), loss = 0.459295
I1003 09:53:00.291839  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.459295 (* 1 = 0.459295 loss)
I1003 09:53:00.291846  7223 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I1003 09:53:14.564121  7223 solver.cpp:218] Iteration 6200 (7.00661 iter/s, 14.2722s/100 iters), loss = 0.494064
I1003 09:53:14.564273  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.494064 (* 1 = 0.494064 loss)
I1003 09:53:14.564282  7223 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I1003 09:53:28.841264  7223 solver.cpp:218] Iteration 6300 (7.0043 iter/s, 14.2769s/100 iters), loss = 0.557492
I1003 09:53:28.841300  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.557492 (* 1 = 0.557492 loss)
I1003 09:53:28.841307  7223 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I1003 09:53:43.099537  7223 solver.cpp:218] Iteration 6400 (7.01351 iter/s, 14.2582s/100 iters), loss = 0.451741
I1003 09:53:43.099575  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.451741 (* 1 = 0.451741 loss)
I1003 09:53:43.099583  7223 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I1003 09:53:56.653478  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:53:57.222702  7223 solver.cpp:330] Iteration 6500, Testing net (#0)
I1003 09:54:00.598130  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:54:00.738418  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7393
I1003 09:54:00.738445  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.75941 (* 1 = 0.75941 loss)
I1003 09:54:00.880240  7223 solver.cpp:218] Iteration 6500 (5.6241 iter/s, 17.7806s/100 iters), loss = 0.567053
I1003 09:54:00.880275  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.567053 (* 1 = 0.567053 loss)
I1003 09:54:00.880283  7223 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I1003 09:54:15.142454  7223 solver.cpp:218] Iteration 6600 (7.01157 iter/s, 14.2621s/100 iters), loss = 0.485599
I1003 09:54:15.142489  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.485599 (* 1 = 0.485599 loss)
I1003 09:54:15.142498  7223 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I1003 09:54:29.398845  7223 solver.cpp:218] Iteration 6700 (7.01444 iter/s, 14.2563s/100 iters), loss = 0.526156
I1003 09:54:29.398947  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.526156 (* 1 = 0.526156 loss)
I1003 09:54:29.398957  7223 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I1003 09:54:43.645787  7223 solver.cpp:218] Iteration 6800 (7.01912 iter/s, 14.2468s/100 iters), loss = 0.504702
I1003 09:54:43.645823  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.504702 (* 1 = 0.504702 loss)
I1003 09:54:43.645843  7223 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I1003 09:54:57.900425  7223 solver.cpp:218] Iteration 6900 (7.0153 iter/s, 14.2546s/100 iters), loss = 0.501863
I1003 09:54:57.900456  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.501863 (* 1 = 0.501863 loss)
I1003 09:54:57.900475  7223 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I1003 09:55:11.463109  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:55:12.030944  7223 solver.cpp:330] Iteration 7000, Testing net (#0)
I1003 09:55:15.399349  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:55:15.539458  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.737
I1003 09:55:15.539494  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.792843 (* 1 = 0.792843 loss)
I1003 09:55:15.680465  7223 solver.cpp:218] Iteration 7000 (5.62431 iter/s, 17.78s/100 iters), loss = 0.568728
I1003 09:55:15.680495  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.568728 (* 1 = 0.568728 loss)
I1003 09:55:15.680502  7223 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I1003 09:55:29.941062  7223 solver.cpp:218] Iteration 7100 (7.01236 iter/s, 14.2605s/100 iters), loss = 0.393685
I1003 09:55:29.941103  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.393685 (* 1 = 0.393685 loss)
I1003 09:55:29.941110  7223 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I1003 09:55:44.225155  7223 solver.cpp:218] Iteration 7200 (7.00084 iter/s, 14.284s/100 iters), loss = 0.535865
I1003 09:55:44.225283  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.535865 (* 1 = 0.535865 loss)
I1003 09:55:44.225292  7223 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I1003 09:55:58.501947  7223 solver.cpp:218] Iteration 7300 (7.00446 iter/s, 14.2766s/100 iters), loss = 0.472941
I1003 09:55:58.501991  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.472941 (* 1 = 0.472941 loss)
I1003 09:55:58.501997  7223 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I1003 09:56:12.747632  7223 solver.cpp:218] Iteration 7400 (7.01971 iter/s, 14.2456s/100 iters), loss = 0.469643
I1003 09:56:12.747663  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.469643 (* 1 = 0.469643 loss)
I1003 09:56:12.747668  7223 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I1003 09:56:26.303006  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:56:26.871949  7223 solver.cpp:330] Iteration 7500, Testing net (#0)
I1003 09:56:30.243639  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:56:30.384048  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7687
I1003 09:56:30.384085  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.667967 (* 1 = 0.667967 loss)
I1003 09:56:30.525900  7223 solver.cpp:218] Iteration 7500 (5.62487 iter/s, 17.7782s/100 iters), loss = 0.557674
I1003 09:56:30.525931  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.557674 (* 1 = 0.557674 loss)
I1003 09:56:30.525938  7223 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I1003 09:56:44.783021  7223 solver.cpp:218] Iteration 7600 (7.01407 iter/s, 14.257s/100 iters), loss = 0.469045
I1003 09:56:44.783053  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.469045 (* 1 = 0.469045 loss)
I1003 09:56:44.783061  7223 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I1003 09:56:59.041640  7223 solver.cpp:218] Iteration 7700 (7.01334 iter/s, 14.2585s/100 iters), loss = 0.459337
I1003 09:56:59.041743  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.459337 (* 1 = 0.459337 loss)
I1003 09:56:59.041750  7223 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I1003 09:57:13.296308  7223 solver.cpp:218] Iteration 7800 (7.01532 iter/s, 14.2545s/100 iters), loss = 0.488235
I1003 09:57:13.296366  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.488235 (* 1 = 0.488235 loss)
I1003 09:57:13.296375  7223 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I1003 09:57:27.560135  7223 solver.cpp:218] Iteration 7900 (7.0108 iter/s, 14.2637s/100 iters), loss = 0.523264
I1003 09:57:27.560176  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.523264 (* 1 = 0.523264 loss)
I1003 09:57:27.560183  7223 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I1003 09:57:41.118535  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:57:41.686594  7223 solver.cpp:330] Iteration 8000, Testing net (#0)
I1003 09:57:45.058351  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:57:45.198576  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.74
I1003 09:57:45.198612  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.771085 (* 1 = 0.771085 loss)
I1003 09:57:45.340711  7223 solver.cpp:218] Iteration 8000 (5.62414 iter/s, 17.7805s/100 iters), loss = 0.350983
I1003 09:57:45.340744  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350983 (* 1 = 0.350983 loss)
I1003 09:57:45.340750  7223 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I1003 09:57:59.598721  7223 solver.cpp:218] Iteration 8100 (7.01364 iter/s, 14.2579s/100 iters), loss = 0.411007
I1003 09:57:59.598752  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.411007 (* 1 = 0.411007 loss)
I1003 09:57:59.598757  7223 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I1003 09:58:13.867785  7223 solver.cpp:218] Iteration 8200 (7.0082 iter/s, 14.269s/100 iters), loss = 0.391928
I1003 09:58:13.867947  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.391928 (* 1 = 0.391928 loss)
I1003 09:58:13.867966  7223 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I1003 09:58:28.119894  7223 solver.cpp:218] Iteration 8300 (7.0166 iter/s, 14.2519s/100 iters), loss = 0.583866
I1003 09:58:28.119930  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.583866 (* 1 = 0.583866 loss)
I1003 09:58:28.119936  7223 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I1003 09:58:42.373685  7223 solver.cpp:218] Iteration 8400 (7.01571 iter/s, 14.2537s/100 iters), loss = 0.428806
I1003 09:58:42.373716  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.428806 (* 1 = 0.428806 loss)
I1003 09:58:42.373723  7223 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I1003 09:58:55.932011  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:58:56.500443  7223 solver.cpp:330] Iteration 8500, Testing net (#0)
I1003 09:58:59.872681  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 09:59:00.013053  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6809
I1003 09:59:00.013088  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.918949 (* 1 = 0.918949 loss)
I1003 09:59:00.154950  7223 solver.cpp:218] Iteration 8500 (5.62392 iter/s, 17.7812s/100 iters), loss = 0.453723
I1003 09:59:00.154994  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.453723 (* 1 = 0.453723 loss)
I1003 09:59:00.155001  7223 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I1003 09:59:14.404613  7223 solver.cpp:218] Iteration 8600 (7.01777 iter/s, 14.2495s/100 iters), loss = 0.397649
I1003 09:59:14.404642  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.397649 (* 1 = 0.397649 loss)
I1003 09:59:14.404649  7223 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I1003 09:59:28.655493  7223 solver.cpp:218] Iteration 8700 (7.01715 iter/s, 14.2508s/100 iters), loss = 0.403963
I1003 09:59:28.655604  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.403963 (* 1 = 0.403963 loss)
I1003 09:59:28.655611  7223 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I1003 09:59:42.903760  7223 solver.cpp:218] Iteration 8800 (7.01846 iter/s, 14.2481s/100 iters), loss = 0.492972
I1003 09:59:42.903790  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.492972 (* 1 = 0.492972 loss)
I1003 09:59:42.903795  7223 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I1003 09:59:57.171161  7223 solver.cpp:218] Iteration 8900 (7.00902 iter/s, 14.2673s/100 iters), loss = 0.415212
I1003 09:59:57.171193  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.415212 (* 1 = 0.415212 loss)
I1003 09:59:57.171198  7223 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I1003 10:00:10.726449  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:00:11.294988  7223 solver.cpp:330] Iteration 9000, Testing net (#0)
I1003 10:00:14.665417  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:00:14.805800  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7431
I1003 10:00:14.805838  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.770775 (* 1 = 0.770775 loss)
I1003 10:00:14.947809  7223 solver.cpp:218] Iteration 9000 (5.62538 iter/s, 17.7766s/100 iters), loss = 0.464213
I1003 10:00:14.947842  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.464213 (* 1 = 0.464213 loss)
I1003 10:00:14.947849  7223 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I1003 10:00:29.204612  7223 solver.cpp:218] Iteration 9100 (7.01423 iter/s, 14.2567s/100 iters), loss = 0.45471
I1003 10:00:29.204653  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.45471 (* 1 = 0.45471 loss)
I1003 10:00:29.204659  7223 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I1003 10:00:43.472609  7223 solver.cpp:218] Iteration 9200 (7.00873 iter/s, 14.2679s/100 iters), loss = 0.405452
I1003 10:00:43.472764  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405452 (* 1 = 0.405452 loss)
I1003 10:00:43.472774  7223 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I1003 10:00:57.715965  7223 solver.cpp:218] Iteration 9300 (7.02091 iter/s, 14.2432s/100 iters), loss = 0.559472
I1003 10:00:57.716006  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.559472 (* 1 = 0.559472 loss)
I1003 10:00:57.716012  7223 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I1003 10:01:11.970916  7223 solver.cpp:218] Iteration 9400 (7.01514 iter/s, 14.2549s/100 iters), loss = 0.401776
I1003 10:01:11.970959  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.401776 (* 1 = 0.401776 loss)
I1003 10:01:11.970965  7223 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I1003 10:01:25.528905  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:01:26.096710  7223 solver.cpp:330] Iteration 9500, Testing net (#0)
I1003 10:01:29.468221  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:01:29.608094  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7021
I1003 10:01:29.608131  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.894279 (* 1 = 0.894279 loss)
I1003 10:01:29.749402  7223 solver.cpp:218] Iteration 9500 (5.6248 iter/s, 17.7784s/100 iters), loss = 0.43088
I1003 10:01:29.749435  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.43088 (* 1 = 0.43088 loss)
I1003 10:01:29.749442  7223 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I1003 10:01:43.991323  7223 solver.cpp:218] Iteration 9600 (7.02156 iter/s, 14.2419s/100 iters), loss = 0.509589
I1003 10:01:43.991353  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.509589 (* 1 = 0.509589 loss)
I1003 10:01:43.991359  7223 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I1003 10:01:58.234201  7223 solver.cpp:218] Iteration 9700 (7.02109 iter/s, 14.2428s/100 iters), loss = 0.307516
I1003 10:01:58.234338  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307516 (* 1 = 0.307516 loss)
I1003 10:01:58.234347  7223 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I1003 10:02:12.483841  7223 solver.cpp:218] Iteration 9800 (7.01782 iter/s, 14.2494s/100 iters), loss = 0.502572
I1003 10:02:12.483872  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.502572 (* 1 = 0.502572 loss)
I1003 10:02:12.483878  7223 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I1003 10:02:26.741955  7223 solver.cpp:218] Iteration 9900 (7.01358 iter/s, 14.258s/100 iters), loss = 0.367912
I1003 10:02:26.741986  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.367912 (* 1 = 0.367912 loss)
I1003 10:02:26.741993  7223 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I1003 10:02:40.283295  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:02:40.853469  7223 solver.cpp:330] Iteration 10000, Testing net (#0)
I1003 10:02:44.223574  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:02:44.363653  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7777
I1003 10:02:44.363689  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.658129 (* 1 = 0.658129 loss)
I1003 10:02:44.505677  7223 solver.cpp:218] Iteration 10000 (5.62948 iter/s, 17.7636s/100 iters), loss = 0.416278
I1003 10:02:44.505709  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.416278 (* 1 = 0.416278 loss)
I1003 10:02:44.505717  7223 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I1003 10:02:58.768060  7223 solver.cpp:218] Iteration 10100 (7.0115 iter/s, 14.2623s/100 iters), loss = 0.421197
I1003 10:02:58.768102  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.421197 (* 1 = 0.421197 loss)
I1003 10:02:58.768108  7223 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I1003 10:03:13.022681  7223 solver.cpp:218] Iteration 10200 (7.01531 iter/s, 14.2545s/100 iters), loss = 0.417721
I1003 10:03:13.022778  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.417721 (* 1 = 0.417721 loss)
I1003 10:03:13.022785  7223 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I1003 10:03:27.277246  7223 solver.cpp:218] Iteration 10300 (7.01536 iter/s, 14.2544s/100 iters), loss = 0.376268
I1003 10:03:27.277277  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.376268 (* 1 = 0.376268 loss)
I1003 10:03:27.277283  7223 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I1003 10:03:41.537699  7223 solver.cpp:218] Iteration 10400 (7.01243 iter/s, 14.2604s/100 iters), loss = 0.47827
I1003 10:03:41.537729  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.47827 (* 1 = 0.47827 loss)
I1003 10:03:41.537735  7223 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I1003 10:03:55.084862  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:03:55.663316  7223 solver.cpp:330] Iteration 10500, Testing net (#0)
I1003 10:03:59.033742  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:03:59.173972  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7632
I1003 10:03:59.173997  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.697355 (* 1 = 0.697355 loss)
I1003 10:03:59.316079  7223 solver.cpp:218] Iteration 10500 (5.62483 iter/s, 17.7783s/100 iters), loss = 0.452341
I1003 10:03:59.316110  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.452341 (* 1 = 0.452341 loss)
I1003 10:03:59.316117  7223 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I1003 10:04:13.567101  7223 solver.cpp:218] Iteration 10600 (7.01707 iter/s, 14.251s/100 iters), loss = 0.449201
I1003 10:04:13.567136  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.449201 (* 1 = 0.449201 loss)
I1003 10:04:13.567142  7223 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I1003 10:04:27.824395  7223 solver.cpp:218] Iteration 10700 (7.01399 iter/s, 14.2572s/100 iters), loss = 0.391978
I1003 10:04:27.824525  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.391978 (* 1 = 0.391978 loss)
I1003 10:04:27.824542  7223 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I1003 10:04:42.088157  7223 solver.cpp:218] Iteration 10800 (7.01085 iter/s, 14.2636s/100 iters), loss = 0.608935
I1003 10:04:42.088187  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.608935 (* 1 = 0.608935 loss)
I1003 10:04:42.088193  7223 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I1003 10:04:56.346456  7223 solver.cpp:218] Iteration 10900 (7.01349 iter/s, 14.2582s/100 iters), loss = 0.321083
I1003 10:04:56.346485  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.321083 (* 1 = 0.321083 loss)
I1003 10:04:56.346491  7223 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I1003 10:05:09.893802  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:05:10.474040  7223 solver.cpp:330] Iteration 11000, Testing net (#0)
I1003 10:05:13.843811  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:05:13.984194  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7702
I1003 10:05:13.984230  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.665351 (* 1 = 0.665351 loss)
I1003 10:05:14.126178  7223 solver.cpp:218] Iteration 11000 (5.62441 iter/s, 17.7796s/100 iters), loss = 0.383133
I1003 10:05:14.126219  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.383133 (* 1 = 0.383133 loss)
I1003 10:05:14.126226  7223 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I1003 10:05:28.378973  7223 solver.cpp:218] Iteration 11100 (7.01621 iter/s, 14.2527s/100 iters), loss = 0.484149
I1003 10:05:28.379009  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.484149 (* 1 = 0.484149 loss)
I1003 10:05:28.379017  7223 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I1003 10:05:42.620327  7223 solver.cpp:218] Iteration 11200 (7.02184 iter/s, 14.2413s/100 iters), loss = 0.460236
I1003 10:05:42.620441  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.460236 (* 1 = 0.460236 loss)
I1003 10:05:42.620448  7223 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I1003 10:05:56.873291  7223 solver.cpp:218] Iteration 11300 (7.01615 iter/s, 14.2528s/100 iters), loss = 0.438468
I1003 10:05:56.873323  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.438468 (* 1 = 0.438468 loss)
I1003 10:05:56.873329  7223 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I1003 10:06:11.140790  7223 solver.cpp:218] Iteration 11400 (7.00897 iter/s, 14.2674s/100 iters), loss = 0.406293
I1003 10:06:11.140820  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.406293 (* 1 = 0.406293 loss)
I1003 10:06:11.140826  7223 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I1003 10:06:24.680116  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:06:25.251240  7223 solver.cpp:330] Iteration 11500, Testing net (#0)
I1003 10:06:28.624722  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:06:28.764869  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7825
I1003 10:06:28.764905  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.634082 (* 1 = 0.634082 loss)
I1003 10:06:28.906265  7223 solver.cpp:218] Iteration 11500 (5.62892 iter/s, 17.7654s/100 iters), loss = 0.369599
I1003 10:06:28.906296  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.369599 (* 1 = 0.369599 loss)
I1003 10:06:28.906302  7223 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I1003 10:06:43.160773  7223 solver.cpp:218] Iteration 11600 (7.01536 iter/s, 14.2544s/100 iters), loss = 0.456398
I1003 10:06:43.160818  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.456398 (* 1 = 0.456398 loss)
I1003 10:06:43.160826  7223 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I1003 10:06:57.435413  7223 solver.cpp:218] Iteration 11700 (7.00547 iter/s, 14.2746s/100 iters), loss = 0.430593
I1003 10:06:57.435559  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.430593 (* 1 = 0.430593 loss)
I1003 10:06:57.435567  7223 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I1003 10:07:11.702620  7223 solver.cpp:218] Iteration 11800 (7.00917 iter/s, 14.267s/100 iters), loss = 0.555375
I1003 10:07:11.702653  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.555375 (* 1 = 0.555375 loss)
I1003 10:07:11.702659  7223 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I1003 10:07:25.963726  7223 solver.cpp:218] Iteration 11900 (7.01211 iter/s, 14.261s/100 iters), loss = 0.392596
I1003 10:07:25.963758  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.392596 (* 1 = 0.392596 loss)
I1003 10:07:25.963764  7223 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I1003 10:07:39.519500  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:07:40.088220  7223 solver.cpp:330] Iteration 12000, Testing net (#0)
I1003 10:07:43.469053  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:07:43.609091  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.74
I1003 10:07:43.609118  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.772562 (* 1 = 0.772562 loss)
I1003 10:07:43.750886  7223 solver.cpp:218] Iteration 12000 (5.62206 iter/s, 17.7871s/100 iters), loss = 0.308483
I1003 10:07:43.750923  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308483 (* 1 = 0.308483 loss)
I1003 10:07:43.750929  7223 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I1003 10:07:58.002364  7223 solver.cpp:218] Iteration 12100 (7.01685 iter/s, 14.2514s/100 iters), loss = 0.38905
I1003 10:07:58.002403  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.38905 (* 1 = 0.38905 loss)
I1003 10:07:58.002409  7223 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I1003 10:08:12.248785  7223 solver.cpp:218] Iteration 12200 (7.01935 iter/s, 14.2463s/100 iters), loss = 0.355098
I1003 10:08:12.248919  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355098 (* 1 = 0.355098 loss)
I1003 10:08:12.248939  7223 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I1003 10:08:26.503825  7223 solver.cpp:218] Iteration 12300 (7.01515 iter/s, 14.2549s/100 iters), loss = 0.524427
I1003 10:08:26.503854  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.524427 (* 1 = 0.524427 loss)
I1003 10:08:26.503861  7223 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I1003 10:08:40.765900  7223 solver.cpp:218] Iteration 12400 (7.01164 iter/s, 14.262s/100 iters), loss = 0.451055
I1003 10:08:40.765943  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.451055 (* 1 = 0.451055 loss)
I1003 10:08:40.765949  7223 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I1003 10:08:54.313024  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:08:54.881148  7223 solver.cpp:330] Iteration 12500, Testing net (#0)
I1003 10:08:58.254186  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:08:58.397811  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7726
I1003 10:08:58.397837  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.652286 (* 1 = 0.652286 loss)
I1003 10:08:58.540618  7223 solver.cpp:218] Iteration 12500 (5.626 iter/s, 17.7746s/100 iters), loss = 0.463325
I1003 10:08:58.540652  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.463325 (* 1 = 0.463325 loss)
I1003 10:08:58.540659  7223 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I1003 10:09:12.792585  7223 solver.cpp:218] Iteration 12600 (7.01661 iter/s, 14.2519s/100 iters), loss = 0.337402
I1003 10:09:12.792628  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337402 (* 1 = 0.337402 loss)
I1003 10:09:12.792634  7223 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I1003 10:09:27.071805  7223 solver.cpp:218] Iteration 12700 (7.00322 iter/s, 14.2791s/100 iters), loss = 0.401039
I1003 10:09:27.071921  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.401039 (* 1 = 0.401039 loss)
I1003 10:09:27.071928  7223 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I1003 10:09:41.341307  7223 solver.cpp:218] Iteration 12800 (7.00803 iter/s, 14.2693s/100 iters), loss = 0.488364
I1003 10:09:41.341348  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.488364 (* 1 = 0.488364 loss)
I1003 10:09:41.341354  7223 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I1003 10:09:55.607617  7223 solver.cpp:218] Iteration 12900 (7.00956 iter/s, 14.2662s/100 iters), loss = 0.379889
I1003 10:09:55.607650  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.379889 (* 1 = 0.379889 loss)
I1003 10:09:55.607656  7223 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I1003 10:10:09.167800  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:10:09.737140  7223 solver.cpp:330] Iteration 13000, Testing net (#0)
I1003 10:10:13.108909  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:10:13.253953  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8052
I1003 10:10:13.253980  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.555968 (* 1 = 0.555968 loss)
I1003 10:10:13.399265  7223 solver.cpp:218] Iteration 13000 (5.62064 iter/s, 17.7916s/100 iters), loss = 0.342413
I1003 10:10:13.399300  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342413 (* 1 = 0.342413 loss)
I1003 10:10:13.399308  7223 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I1003 10:10:27.672008  7223 solver.cpp:218] Iteration 13100 (7.0064 iter/s, 14.2727s/100 iters), loss = 0.394798
I1003 10:10:27.672040  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.394798 (* 1 = 0.394798 loss)
I1003 10:10:27.672046  7223 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I1003 10:10:41.942778  7223 solver.cpp:218] Iteration 13200 (7.00736 iter/s, 14.2707s/100 iters), loss = 0.325621
I1003 10:10:41.942870  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325621 (* 1 = 0.325621 loss)
I1003 10:10:41.942878  7223 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I1003 10:10:56.223346  7223 solver.cpp:218] Iteration 13300 (7.00259 iter/s, 14.2804s/100 iters), loss = 0.47901
I1003 10:10:56.223388  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.47901 (* 1 = 0.47901 loss)
I1003 10:10:56.223394  7223 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I1003 10:11:10.505647  7223 solver.cpp:218] Iteration 13400 (7.00171 iter/s, 14.2822s/100 iters), loss = 0.395759
I1003 10:11:10.505684  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.395759 (* 1 = 0.395759 loss)
I1003 10:11:10.505692  7223 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I1003 10:11:24.057236  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:11:24.626018  7223 solver.cpp:330] Iteration 13500, Testing net (#0)
I1003 10:11:27.993752  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:11:28.133811  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7612
I1003 10:11:28.133846  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.706989 (* 1 = 0.706989 loss)
I1003 10:11:28.277518  7223 solver.cpp:218] Iteration 13500 (5.6269 iter/s, 17.7718s/100 iters), loss = 0.401239
I1003 10:11:28.277554  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.401239 (* 1 = 0.401239 loss)
I1003 10:11:28.277562  7223 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I1003 10:11:42.538331  7223 solver.cpp:218] Iteration 13600 (7.01226 iter/s, 14.2607s/100 iters), loss = 0.333644
I1003 10:11:42.538373  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333644 (* 1 = 0.333644 loss)
I1003 10:11:42.538379  7223 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I1003 10:11:56.804417  7223 solver.cpp:218] Iteration 13700 (7.00967 iter/s, 14.266s/100 iters), loss = 0.384355
I1003 10:11:56.804523  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.384355 (* 1 = 0.384355 loss)
I1003 10:11:56.804531  7223 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I1003 10:12:11.062875  7223 solver.cpp:218] Iteration 13800 (7.01345 iter/s, 14.2583s/100 iters), loss = 0.491635
I1003 10:12:11.062907  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.491635 (* 1 = 0.491635 loss)
I1003 10:12:11.062913  7223 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I1003 10:12:25.322616  7223 solver.cpp:218] Iteration 13900 (7.01279 iter/s, 14.2597s/100 iters), loss = 0.395869
I1003 10:12:25.322674  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.395869 (* 1 = 0.395869 loss)
I1003 10:12:25.322684  7223 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I1003 10:12:38.869014  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:12:39.437644  7223 solver.cpp:330] Iteration 14000, Testing net (#0)
I1003 10:12:42.808378  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:12:42.948765  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7414
I1003 10:12:42.948792  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.78732 (* 1 = 0.78732 loss)
I1003 10:12:43.089874  7223 solver.cpp:218] Iteration 14000 (5.62837 iter/s, 17.7671s/100 iters), loss = 0.349878
I1003 10:12:43.089905  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349878 (* 1 = 0.349878 loss)
I1003 10:12:43.089910  7223 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I1003 10:12:57.357339  7223 solver.cpp:218] Iteration 14100 (7.00899 iter/s, 14.2674s/100 iters), loss = 0.37599
I1003 10:12:57.357372  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.37599 (* 1 = 0.37599 loss)
I1003 10:12:57.357388  7223 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I1003 10:13:11.623484  7223 solver.cpp:218] Iteration 14200 (7.00964 iter/s, 14.2661s/100 iters), loss = 0.404489
I1003 10:13:11.623589  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.404489 (* 1 = 0.404489 loss)
I1003 10:13:11.623608  7223 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I1003 10:13:25.894531  7223 solver.cpp:218] Iteration 14300 (7.00726 iter/s, 14.2709s/100 iters), loss = 0.542955
I1003 10:13:25.894563  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.542955 (* 1 = 0.542955 loss)
I1003 10:13:25.894579  7223 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I1003 10:13:40.151140  7223 solver.cpp:218] Iteration 14400 (7.01433 iter/s, 14.2565s/100 iters), loss = 0.350116
I1003 10:13:40.151171  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350116 (* 1 = 0.350116 loss)
I1003 10:13:40.151187  7223 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I1003 10:13:53.702841  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:13:54.272467  7223 solver.cpp:330] Iteration 14500, Testing net (#0)
I1003 10:13:57.642138  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:13:57.781842  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7025
I1003 10:13:57.781877  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.895956 (* 1 = 0.895956 loss)
I1003 10:13:57.923441  7223 solver.cpp:218] Iteration 14500 (5.62676 iter/s, 17.7722s/100 iters), loss = 0.40106
I1003 10:13:57.923470  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.40106 (* 1 = 0.40106 loss)
I1003 10:13:57.923476  7223 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I1003 10:14:12.178009  7223 solver.cpp:218] Iteration 14600 (7.01535 iter/s, 14.2545s/100 iters), loss = 0.427909
I1003 10:14:12.178040  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.427909 (* 1 = 0.427909 loss)
I1003 10:14:12.178045  7223 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I1003 10:14:26.426879  7223 solver.cpp:218] Iteration 14700 (7.01814 iter/s, 14.2488s/100 iters), loss = 0.391354
I1003 10:14:26.427011  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.391354 (* 1 = 0.391354 loss)
I1003 10:14:26.427021  7223 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I1003 10:14:40.674187  7223 solver.cpp:218] Iteration 14800 (7.01895 iter/s, 14.2471s/100 iters), loss = 0.488548
I1003 10:14:40.674219  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.488548 (* 1 = 0.488548 loss)
I1003 10:14:40.674226  7223 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I1003 10:14:54.916038  7223 solver.cpp:218] Iteration 14900 (7.02159 iter/s, 14.2418s/100 iters), loss = 0.390661
I1003 10:14:54.916066  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.390661 (* 1 = 0.390661 loss)
I1003 10:14:54.916072  7223 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I1003 10:15:08.463829  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:15:09.031199  7223 solver.cpp:330] Iteration 15000, Testing net (#0)
I1003 10:15:12.402348  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:15:12.542223  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7988
I1003 10:15:12.542259  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.585906 (* 1 = 0.585906 loss)
I1003 10:15:12.683167  7223 solver.cpp:218] Iteration 15000 (5.6284 iter/s, 17.767s/100 iters), loss = 0.338565
I1003 10:15:12.683198  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338565 (* 1 = 0.338565 loss)
I1003 10:15:12.683205  7223 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I1003 10:15:26.924175  7223 solver.cpp:218] Iteration 15100 (7.02201 iter/s, 14.2409s/100 iters), loss = 0.378611
I1003 10:15:26.924203  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378611 (* 1 = 0.378611 loss)
I1003 10:15:26.924209  7223 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I1003 10:15:41.177407  7223 solver.cpp:218] Iteration 15200 (7.01599 iter/s, 14.2532s/100 iters), loss = 0.440168
I1003 10:15:41.177556  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.440168 (* 1 = 0.440168 loss)
I1003 10:15:41.177564  7223 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I1003 10:15:55.431965  7223 solver.cpp:218] Iteration 15300 (7.01539 iter/s, 14.2544s/100 iters), loss = 0.474121
I1003 10:15:55.432001  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.474121 (* 1 = 0.474121 loss)
I1003 10:15:55.432008  7223 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I1003 10:16:09.672571  7223 solver.cpp:218] Iteration 15400 (7.02221 iter/s, 14.2405s/100 iters), loss = 0.407459
I1003 10:16:09.672601  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.407459 (* 1 = 0.407459 loss)
I1003 10:16:09.672606  7223 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I1003 10:16:23.224005  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:16:23.793026  7223 solver.cpp:330] Iteration 15500, Testing net (#0)
I1003 10:16:27.162863  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:16:27.303306  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.797
I1003 10:16:27.303350  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.58687 (* 1 = 0.58687 loss)
I1003 10:16:27.444981  7223 solver.cpp:218] Iteration 15500 (5.62673 iter/s, 17.7723s/100 iters), loss = 0.399298
I1003 10:16:27.445013  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.399298 (* 1 = 0.399298 loss)
I1003 10:16:27.445019  7223 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I1003 10:16:41.712985  7223 solver.cpp:218] Iteration 15600 (7.00873 iter/s, 14.2679s/100 iters), loss = 0.429843
I1003 10:16:41.713016  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.429843 (* 1 = 0.429843 loss)
I1003 10:16:41.713022  7223 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I1003 10:16:55.979351  7223 solver.cpp:218] Iteration 15700 (7.00953 iter/s, 14.2663s/100 iters), loss = 0.311228
I1003 10:16:55.979470  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311228 (* 1 = 0.311228 loss)
I1003 10:16:55.979488  7223 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I1003 10:17:10.239807  7223 solver.cpp:218] Iteration 15800 (7.01247 iter/s, 14.2603s/100 iters), loss = 0.425378
I1003 10:17:10.239866  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.425378 (* 1 = 0.425378 loss)
I1003 10:17:10.239882  7223 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I1003 10:17:24.510047  7223 solver.cpp:218] Iteration 15900 (7.00764 iter/s, 14.2701s/100 iters), loss = 0.376366
I1003 10:17:24.510078  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.376366 (* 1 = 0.376366 loss)
I1003 10:17:24.510084  7223 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I1003 10:17:38.078311  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:17:38.647308  7223 solver.cpp:330] Iteration 16000, Testing net (#0)
I1003 10:17:42.014866  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:17:42.154587  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7982
I1003 10:17:42.154623  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.585764 (* 1 = 0.585764 loss)
I1003 10:17:42.296072  7223 solver.cpp:218] Iteration 16000 (5.62242 iter/s, 17.7859s/100 iters), loss = 0.422011
I1003 10:17:42.296104  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.422011 (* 1 = 0.422011 loss)
I1003 10:17:42.296111  7223 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I1003 10:17:56.548729  7223 solver.cpp:218] Iteration 16100 (7.01627 iter/s, 14.2526s/100 iters), loss = 0.45882
I1003 10:17:56.548760  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.45882 (* 1 = 0.45882 loss)
I1003 10:17:56.548766  7223 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I1003 10:18:10.817927  7223 solver.cpp:218] Iteration 16200 (7.00814 iter/s, 14.2691s/100 iters), loss = 0.395748
I1003 10:18:10.818034  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.395749 (* 1 = 0.395749 loss)
I1003 10:18:10.818042  7223 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I1003 10:18:25.072481  7223 solver.cpp:218] Iteration 16300 (7.01537 iter/s, 14.2544s/100 iters), loss = 0.403018
I1003 10:18:25.072511  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.403018 (* 1 = 0.403018 loss)
I1003 10:18:25.072517  7223 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I1003 10:18:39.330035  7223 solver.cpp:218] Iteration 16400 (7.01386 iter/s, 14.2575s/100 iters), loss = 0.387039
I1003 10:18:39.330065  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.387039 (* 1 = 0.387039 loss)
I1003 10:18:39.330070  7223 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I1003 10:18:52.883891  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:18:53.453935  7223 solver.cpp:330] Iteration 16500, Testing net (#0)
I1003 10:18:56.824074  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:18:56.964680  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8048
I1003 10:18:56.964716  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.582982 (* 1 = 0.582982 loss)
I1003 10:18:57.106542  7223 solver.cpp:218] Iteration 16500 (5.62543 iter/s, 17.7764s/100 iters), loss = 0.332464
I1003 10:18:57.106573  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.332464 (* 1 = 0.332464 loss)
I1003 10:18:57.106580  7223 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I1003 10:19:11.378109  7223 solver.cpp:218] Iteration 16600 (7.00697 iter/s, 14.2715s/100 iters), loss = 0.338696
I1003 10:19:11.378139  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338697 (* 1 = 0.338697 loss)
I1003 10:19:11.378145  7223 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I1003 10:19:25.634902  7223 solver.cpp:218] Iteration 16700 (7.01424 iter/s, 14.2567s/100 iters), loss = 0.347163
I1003 10:19:25.635052  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.347163 (* 1 = 0.347163 loss)
I1003 10:19:25.635061  7223 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I1003 10:19:39.895957  7223 solver.cpp:218] Iteration 16800 (7.0122 iter/s, 14.2609s/100 iters), loss = 0.438671
I1003 10:19:39.895987  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.438671 (* 1 = 0.438671 loss)
I1003 10:19:39.895994  7223 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I1003 10:19:54.170073  7223 solver.cpp:218] Iteration 16900 (7.00572 iter/s, 14.274s/100 iters), loss = 0.362653
I1003 10:19:54.170102  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362654 (* 1 = 0.362654 loss)
I1003 10:19:54.170109  7223 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I1003 10:20:07.725860  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:20:08.295009  7223 solver.cpp:330] Iteration 17000, Testing net (#0)
I1003 10:20:11.663272  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:20:11.803408  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7792
I1003 10:20:11.803444  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.648843 (* 1 = 0.648843 loss)
I1003 10:20:11.945003  7223 solver.cpp:218] Iteration 17000 (5.62593 iter/s, 17.7748s/100 iters), loss = 0.348276
I1003 10:20:11.945037  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.348276 (* 1 = 0.348276 loss)
I1003 10:20:11.945044  7223 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I1003 10:20:26.194281  7223 solver.cpp:218] Iteration 17100 (7.018 iter/s, 14.2491s/100 iters), loss = 0.465401
I1003 10:20:26.194313  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.465401 (* 1 = 0.465401 loss)
I1003 10:20:26.194319  7223 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I1003 10:20:40.449095  7223 solver.cpp:218] Iteration 17200 (7.01521 iter/s, 14.2547s/100 iters), loss = 0.409368
I1003 10:20:40.449249  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.409368 (* 1 = 0.409368 loss)
I1003 10:20:40.449268  7223 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I1003 10:20:54.690855  7223 solver.cpp:218] Iteration 17300 (7.0217 iter/s, 14.2416s/100 iters), loss = 0.445095
I1003 10:20:54.690886  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.445095 (* 1 = 0.445095 loss)
I1003 10:20:54.690892  7223 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I1003 10:21:08.944770  7223 solver.cpp:218] Iteration 17400 (7.01565 iter/s, 14.2538s/100 iters), loss = 0.310119
I1003 10:21:08.944802  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310119 (* 1 = 0.310119 loss)
I1003 10:21:08.944808  7223 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I1003 10:21:22.495795  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:21:23.065119  7223 solver.cpp:330] Iteration 17500, Testing net (#0)
I1003 10:21:26.434397  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:21:26.574250  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7252
I1003 10:21:26.574285  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.848507 (* 1 = 0.848507 loss)
I1003 10:21:26.715677  7223 solver.cpp:218] Iteration 17500 (5.6272 iter/s, 17.7708s/100 iters), loss = 0.373002
I1003 10:21:26.715706  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.373002 (* 1 = 0.373002 loss)
I1003 10:21:26.715713  7223 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I1003 10:21:40.978955  7223 solver.cpp:218] Iteration 17600 (7.01104 iter/s, 14.2632s/100 iters), loss = 0.454626
I1003 10:21:40.978987  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.454626 (* 1 = 0.454626 loss)
I1003 10:21:40.978993  7223 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I1003 10:21:55.232010  7223 solver.cpp:218] Iteration 17700 (7.01608 iter/s, 14.253s/100 iters), loss = 0.369329
I1003 10:21:55.232161  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.369329 (* 1 = 0.369329 loss)
I1003 10:21:55.232169  7223 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I1003 10:22:09.495406  7223 solver.cpp:218] Iteration 17800 (7.01104 iter/s, 14.2632s/100 iters), loss = 0.445636
I1003 10:22:09.495437  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.445636 (* 1 = 0.445636 loss)
I1003 10:22:09.495443  7223 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I1003 10:22:23.760268  7223 solver.cpp:218] Iteration 17900 (7.01027 iter/s, 14.2648s/100 iters), loss = 0.369179
I1003 10:22:23.760298  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.369179 (* 1 = 0.369179 loss)
I1003 10:22:23.760304  7223 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I1003 10:22:37.289420  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:22:37.863245  7223 solver.cpp:330] Iteration 18000, Testing net (#0)
I1003 10:22:41.231432  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:22:41.370671  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7524
I1003 10:22:41.370707  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.746439 (* 1 = 0.746439 loss)
I1003 10:22:41.511955  7223 solver.cpp:218] Iteration 18000 (5.63329 iter/s, 17.7516s/100 iters), loss = 0.272418
I1003 10:22:41.511984  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272418 (* 1 = 0.272418 loss)
I1003 10:22:41.511992  7223 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I1003 10:22:55.780508  7223 solver.cpp:218] Iteration 18100 (7.00845 iter/s, 14.2685s/100 iters), loss = 0.270433
I1003 10:22:55.780551  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270433 (* 1 = 0.270433 loss)
I1003 10:22:55.780558  7223 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I1003 10:23:10.045181  7223 solver.cpp:218] Iteration 18200 (7.01037 iter/s, 14.2646s/100 iters), loss = 0.335571
I1003 10:23:10.045291  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335571 (* 1 = 0.335571 loss)
I1003 10:23:10.045300  7223 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I1003 10:23:24.312083  7223 solver.cpp:218] Iteration 18300 (7.00931 iter/s, 14.2667s/100 iters), loss = 0.380008
I1003 10:23:24.312134  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.380008 (* 1 = 0.380008 loss)
I1003 10:23:24.312151  7223 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I1003 10:23:38.584936  7223 solver.cpp:218] Iteration 18400 (7.00635 iter/s, 14.2728s/100 iters), loss = 0.352492
I1003 10:23:38.584976  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.352492 (* 1 = 0.352492 loss)
I1003 10:23:38.584982  7223 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I1003 10:23:52.150040  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:23:52.729987  7223 solver.cpp:330] Iteration 18500, Testing net (#0)
I1003 10:23:56.099685  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:23:56.239498  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6777
I1003 10:23:56.239533  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.01196 (* 1 = 1.01196 loss)
I1003 10:23:56.380908  7223 solver.cpp:218] Iteration 18500 (5.61928 iter/s, 17.7959s/100 iters), loss = 0.298186
I1003 10:23:56.380936  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298186 (* 1 = 0.298186 loss)
I1003 10:23:56.380944  7223 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I1003 10:24:10.629268  7223 solver.cpp:218] Iteration 18600 (7.01839 iter/s, 14.2483s/100 iters), loss = 0.335096
I1003 10:24:10.629303  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335096 (* 1 = 0.335096 loss)
I1003 10:24:10.629312  7223 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I1003 10:24:24.881326  7223 solver.cpp:218] Iteration 18700 (7.01657 iter/s, 14.252s/100 iters), loss = 0.392202
I1003 10:24:24.881458  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.392202 (* 1 = 0.392202 loss)
I1003 10:24:24.881465  7223 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I1003 10:24:39.147748  7223 solver.cpp:218] Iteration 18800 (7.00955 iter/s, 14.2662s/100 iters), loss = 0.40036
I1003 10:24:39.147791  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.40036 (* 1 = 0.40036 loss)
I1003 10:24:39.147797  7223 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I1003 10:24:53.405782  7223 solver.cpp:218] Iteration 18900 (7.01363 iter/s, 14.2579s/100 iters), loss = 0.34633
I1003 10:24:53.405823  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34633 (* 1 = 0.34633 loss)
I1003 10:24:53.405830  7223 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I1003 10:25:06.949120  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:25:07.524453  7223 solver.cpp:330] Iteration 19000, Testing net (#0)
I1003 10:25:10.894023  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:25:11.033629  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.712
I1003 10:25:11.033665  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.921919 (* 1 = 0.921919 loss)
I1003 10:25:11.174613  7223 solver.cpp:218] Iteration 19000 (5.62786 iter/s, 17.7687s/100 iters), loss = 0.385904
I1003 10:25:11.174641  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.385904 (* 1 = 0.385904 loss)
I1003 10:25:11.174649  7223 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I1003 10:25:25.440382  7223 solver.cpp:218] Iteration 19100 (7.00982 iter/s, 14.2657s/100 iters), loss = 0.460652
I1003 10:25:25.440434  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.460652 (* 1 = 0.460652 loss)
I1003 10:25:25.440443  7223 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I1003 10:25:39.704303  7223 solver.cpp:218] Iteration 19200 (7.01076 iter/s, 14.2638s/100 iters), loss = 0.331307
I1003 10:25:39.704442  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331307 (* 1 = 0.331307 loss)
I1003 10:25:39.704460  7223 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I1003 10:25:53.962715  7223 solver.cpp:218] Iteration 19300 (7.01349 iter/s, 14.2582s/100 iters), loss = 0.436727
I1003 10:25:53.962749  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.436727 (* 1 = 0.436727 loss)
I1003 10:25:53.962765  7223 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I1003 10:26:08.235636  7223 solver.cpp:218] Iteration 19400 (7.00631 iter/s, 14.2728s/100 iters), loss = 0.268918
I1003 10:26:08.235673  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268918 (* 1 = 0.268918 loss)
I1003 10:26:08.235692  7223 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I1003 10:26:21.796233  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:26:22.369534  7223 solver.cpp:330] Iteration 19500, Testing net (#0)
I1003 10:26:25.742892  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:26:25.882827  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7732
I1003 10:26:25.882851  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.661074 (* 1 = 0.661074 loss)
I1003 10:26:26.023988  7223 solver.cpp:218] Iteration 19500 (5.62169 iter/s, 17.7883s/100 iters), loss = 0.375537
I1003 10:26:26.024019  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.375537 (* 1 = 0.375537 loss)
I1003 10:26:26.024026  7223 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I1003 10:26:40.260718  7223 solver.cpp:218] Iteration 19600 (7.02412 iter/s, 14.2367s/100 iters), loss = 0.387019
I1003 10:26:40.260754  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.387019 (* 1 = 0.387019 loss)
I1003 10:26:40.260762  7223 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I1003 10:26:54.512466  7223 solver.cpp:218] Iteration 19700 (7.01672 iter/s, 14.2517s/100 iters), loss = 0.389713
I1003 10:26:54.512609  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.389713 (* 1 = 0.389713 loss)
I1003 10:26:54.512621  7223 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I1003 10:27:08.763669  7223 solver.cpp:218] Iteration 19800 (7.01705 iter/s, 14.251s/100 iters), loss = 0.526623
I1003 10:27:08.763731  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.526623 (* 1 = 0.526623 loss)
I1003 10:27:08.763738  7223 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I1003 10:27:23.016427  7223 solver.cpp:218] Iteration 19900 (7.01624 iter/s, 14.2527s/100 iters), loss = 0.407623
I1003 10:27:23.016472  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.407623 (* 1 = 0.407623 loss)
I1003 10:27:23.016480  7223 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I1003 10:27:36.551702  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:27:37.118396  7223 solver.cpp:330] Iteration 20000, Testing net (#0)
I1003 10:27:40.495537  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:27:40.637203  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7925
I1003 10:27:40.637230  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.629636 (* 1 = 0.629636 loss)
I1003 10:27:40.778487  7223 solver.cpp:218] Iteration 20000 (5.63001 iter/s, 17.762s/100 iters), loss = 0.3734
I1003 10:27:40.778530  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.3734 (* 1 = 0.3734 loss)
I1003 10:27:40.778539  7223 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I1003 10:27:55.032531  7223 solver.cpp:218] Iteration 20100 (7.01559 iter/s, 14.254s/100 iters), loss = 0.55966
I1003 10:27:55.032562  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.55966 (* 1 = 0.55966 loss)
I1003 10:27:55.032569  7223 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I1003 10:28:09.290498  7223 solver.cpp:218] Iteration 20200 (7.01366 iter/s, 14.2579s/100 iters), loss = 0.327024
I1003 10:28:09.290640  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327024 (* 1 = 0.327024 loss)
I1003 10:28:09.290648  7223 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I1003 10:28:23.537250  7223 solver.cpp:218] Iteration 20300 (7.01923 iter/s, 14.2466s/100 iters), loss = 0.471423
I1003 10:28:23.537281  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.471423 (* 1 = 0.471423 loss)
I1003 10:28:23.537286  7223 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I1003 10:28:37.797333  7223 solver.cpp:218] Iteration 20400 (7.01262 iter/s, 14.26s/100 iters), loss = 0.378831
I1003 10:28:37.797363  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378831 (* 1 = 0.378831 loss)
I1003 10:28:37.797370  7223 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I1003 10:28:51.339299  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:28:51.907920  7223 solver.cpp:330] Iteration 20500, Testing net (#0)
I1003 10:28:55.275408  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:28:55.419301  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7976
I1003 10:28:55.419328  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.583817 (* 1 = 0.583817 loss)
I1003 10:28:55.563056  7223 solver.cpp:218] Iteration 20500 (5.62884 iter/s, 17.7656s/100 iters), loss = 0.338841
I1003 10:28:55.563102  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338841 (* 1 = 0.338841 loss)
I1003 10:28:55.563110  7223 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I1003 10:29:09.815855  7223 solver.cpp:218] Iteration 20600 (7.01623 iter/s, 14.2527s/100 iters), loss = 0.457761
I1003 10:29:09.815888  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.457761 (* 1 = 0.457761 loss)
I1003 10:29:09.815894  7223 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I1003 10:29:24.092814  7223 solver.cpp:218] Iteration 20700 (7.00433 iter/s, 14.2769s/100 iters), loss = 0.361248
I1003 10:29:24.092955  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.361248 (* 1 = 0.361248 loss)
I1003 10:29:24.092974  7223 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I1003 10:29:38.364857  7223 solver.cpp:218] Iteration 20800 (7.00679 iter/s, 14.2719s/100 iters), loss = 0.367242
I1003 10:29:38.364898  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.367242 (* 1 = 0.367242 loss)
I1003 10:29:38.364905  7223 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I1003 10:29:52.632936  7223 solver.cpp:218] Iteration 20900 (7.00869 iter/s, 14.268s/100 iters), loss = 0.396002
I1003 10:29:52.632972  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.396002 (* 1 = 0.396002 loss)
I1003 10:29:52.632979  7223 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I1003 10:30:06.188222  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:30:06.756335  7223 solver.cpp:330] Iteration 21000, Testing net (#0)
I1003 10:30:10.127840  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:30:10.267877  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7885
I1003 10:30:10.267913  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.63686 (* 1 = 0.63686 loss)
I1003 10:30:10.414624  7223 solver.cpp:218] Iteration 21000 (5.62379 iter/s, 17.7816s/100 iters), loss = 0.322
I1003 10:30:10.414665  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322 (* 1 = 0.322 loss)
I1003 10:30:10.414674  7223 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I1003 10:30:24.672001  7223 solver.cpp:218] Iteration 21100 (7.01406 iter/s, 14.2571s/100 iters), loss = 0.355635
I1003 10:30:24.672032  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355635 (* 1 = 0.355635 loss)
I1003 10:30:24.672039  7223 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I1003 10:30:38.924912  7223 solver.cpp:218] Iteration 21200 (7.01615 iter/s, 14.2528s/100 iters), loss = 0.265124
I1003 10:30:38.925024  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265123 (* 1 = 0.265123 loss)
I1003 10:30:38.925030  7223 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I1003 10:30:53.196308  7223 solver.cpp:218] Iteration 21300 (7.0071 iter/s, 14.2712s/100 iters), loss = 0.43778
I1003 10:30:53.196341  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.43778 (* 1 = 0.43778 loss)
I1003 10:30:53.196346  7223 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I1003 10:31:07.457211  7223 solver.cpp:218] Iteration 21400 (7.01222 iter/s, 14.2608s/100 iters), loss = 0.395155
I1003 10:31:07.457248  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.395155 (* 1 = 0.395155 loss)
I1003 10:31:07.457257  7223 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I1003 10:31:21.000258  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:31:21.568153  7223 solver.cpp:330] Iteration 21500, Testing net (#0)
I1003 10:31:24.934422  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:31:25.074504  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8069
I1003 10:31:25.074537  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.568325 (* 1 = 0.568325 loss)
I1003 10:31:25.215663  7223 solver.cpp:218] Iteration 21500 (5.63115 iter/s, 17.7584s/100 iters), loss = 0.274435
I1003 10:31:25.215695  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274435 (* 1 = 0.274435 loss)
I1003 10:31:25.215703  7223 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I1003 10:31:39.482312  7223 solver.cpp:218] Iteration 21600 (7.00939 iter/s, 14.2666s/100 iters), loss = 0.393766
I1003 10:31:39.482342  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.393766 (* 1 = 0.393766 loss)
I1003 10:31:39.482348  7223 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I1003 10:31:53.747475  7223 solver.cpp:218] Iteration 21700 (7.01012 iter/s, 14.2651s/100 iters), loss = 0.337598
I1003 10:31:53.747637  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337598 (* 1 = 0.337598 loss)
I1003 10:31:53.747647  7223 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I1003 10:32:08.002454  7223 solver.cpp:218] Iteration 21800 (7.01519 iter/s, 14.2548s/100 iters), loss = 0.435629
I1003 10:32:08.002486  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.435629 (* 1 = 0.435629 loss)
I1003 10:32:08.002503  7223 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I1003 10:32:22.247714  7223 solver.cpp:218] Iteration 21900 (7.01992 iter/s, 14.2452s/100 iters), loss = 0.345644
I1003 10:32:22.247742  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.345644 (* 1 = 0.345644 loss)
I1003 10:32:22.247758  7223 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I1003 10:32:35.801172  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:32:36.369906  7223 solver.cpp:330] Iteration 22000, Testing net (#0)
I1003 10:32:39.738873  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:32:39.878814  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8023
I1003 10:32:39.878849  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.591639 (* 1 = 0.591639 loss)
I1003 10:32:40.020370  7223 solver.cpp:218] Iteration 22000 (5.62665 iter/s, 17.7726s/100 iters), loss = 0.260008
I1003 10:32:40.020401  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260008 (* 1 = 0.260008 loss)
I1003 10:32:40.020407  7223 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I1003 10:32:54.285392  7223 solver.cpp:218] Iteration 22100 (7.01019 iter/s, 14.2649s/100 iters), loss = 0.327563
I1003 10:32:54.285423  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327563 (* 1 = 0.327563 loss)
I1003 10:32:54.285429  7223 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I1003 10:33:08.537238  7223 solver.cpp:218] Iteration 22200 (7.01667 iter/s, 14.2518s/100 iters), loss = 0.320892
I1003 10:33:08.537335  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320892 (* 1 = 0.320892 loss)
I1003 10:33:08.537343  7223 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I1003 10:33:22.809427  7223 solver.cpp:218] Iteration 22300 (7.0067 iter/s, 14.272s/100 iters), loss = 0.494749
I1003 10:33:22.809461  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.494749 (* 1 = 0.494749 loss)
I1003 10:33:22.809468  7223 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I1003 10:33:37.075059  7223 solver.cpp:218] Iteration 22400 (7.00989 iter/s, 14.2656s/100 iters), loss = 0.277737
I1003 10:33:37.075089  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277737 (* 1 = 0.277737 loss)
I1003 10:33:37.075094  7223 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I1003 10:33:50.635682  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:33:51.204847  7223 solver.cpp:330] Iteration 22500, Testing net (#0)
I1003 10:33:54.572216  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:33:54.712215  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7621
I1003 10:33:54.712252  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.726135 (* 1 = 0.726135 loss)
I1003 10:33:54.854287  7223 solver.cpp:218] Iteration 22500 (5.62457 iter/s, 17.7791s/100 iters), loss = 0.3376
I1003 10:33:54.854351  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.3376 (* 1 = 0.3376 loss)
I1003 10:33:54.854357  7223 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I1003 10:34:09.122478  7223 solver.cpp:218] Iteration 22600 (7.00876 iter/s, 14.2679s/100 iters), loss = 0.464975
I1003 10:34:09.122511  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.464975 (* 1 = 0.464975 loss)
I1003 10:34:09.122519  7223 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I1003 10:34:23.395319  7223 solver.cpp:218] Iteration 22700 (7.00635 iter/s, 14.2728s/100 iters), loss = 0.346259
I1003 10:34:23.395465  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.346259 (* 1 = 0.346259 loss)
I1003 10:34:23.395474  7223 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I1003 10:34:37.657862  7223 solver.cpp:218] Iteration 22800 (7.01146 iter/s, 14.2624s/100 iters), loss = 0.413044
I1003 10:34:37.657896  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.413044 (* 1 = 0.413044 loss)
I1003 10:34:37.657903  7223 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I1003 10:34:51.906201  7223 solver.cpp:218] Iteration 22900 (7.0184 iter/s, 14.2483s/100 iters), loss = 0.364022
I1003 10:34:51.906234  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.364022 (* 1 = 0.364022 loss)
I1003 10:34:51.906239  7223 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I1003 10:35:05.465972  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:35:06.034349  7223 solver.cpp:330] Iteration 23000, Testing net (#0)
I1003 10:35:09.404042  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:35:09.544641  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8009
I1003 10:35:09.544667  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.59384 (* 1 = 0.59384 loss)
I1003 10:35:09.685637  7223 solver.cpp:218] Iteration 23000 (5.6245 iter/s, 17.7794s/100 iters), loss = 0.403509
I1003 10:35:09.685667  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.403509 (* 1 = 0.403509 loss)
I1003 10:35:09.685673  7223 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I1003 10:35:23.928913  7223 solver.cpp:218] Iteration 23100 (7.02098 iter/s, 14.243s/100 iters), loss = 0.271928
I1003 10:35:23.928946  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271928 (* 1 = 0.271928 loss)
I1003 10:35:23.928953  7223 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I1003 10:35:38.187721  7223 solver.cpp:218] Iteration 23200 (7.01325 iter/s, 14.2587s/100 iters), loss = 0.306878
I1003 10:35:38.187866  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306878 (* 1 = 0.306878 loss)
I1003 10:35:38.187875  7223 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I1003 10:35:52.437260  7223 solver.cpp:218] Iteration 23300 (7.01787 iter/s, 14.2493s/100 iters), loss = 0.353401
I1003 10:35:52.437299  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.353401 (* 1 = 0.353401 loss)
I1003 10:35:52.437307  7223 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I1003 10:36:06.684674  7223 solver.cpp:218] Iteration 23400 (7.01886 iter/s, 14.2473s/100 iters), loss = 0.311351
I1003 10:36:06.684706  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311351 (* 1 = 0.311351 loss)
I1003 10:36:06.684712  7223 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I1003 10:36:20.235811  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:36:20.805065  7223 solver.cpp:330] Iteration 23500, Testing net (#0)
I1003 10:36:24.173184  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:36:24.313163  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7898
I1003 10:36:24.313200  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.619437 (* 1 = 0.619437 loss)
I1003 10:36:24.453860  7223 solver.cpp:218] Iteration 23500 (5.62775 iter/s, 17.7691s/100 iters), loss = 0.290403
I1003 10:36:24.453908  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290403 (* 1 = 0.290403 loss)
I1003 10:36:24.453925  7223 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I1003 10:36:38.716967  7223 solver.cpp:218] Iteration 23600 (7.01118 iter/s, 14.2629s/100 iters), loss = 0.31883
I1003 10:36:38.716998  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31883 (* 1 = 0.31883 loss)
I1003 10:36:38.717005  7223 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I1003 10:36:52.972854  7223 solver.cpp:218] Iteration 23700 (7.01468 iter/s, 14.2558s/100 iters), loss = 0.361032
I1003 10:36:52.972987  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.361032 (* 1 = 0.361032 loss)
I1003 10:36:52.972995  7223 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I1003 10:37:07.217257  7223 solver.cpp:218] Iteration 23800 (7.02039 iter/s, 14.2442s/100 iters), loss = 0.265708
I1003 10:37:07.217288  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265708 (* 1 = 0.265708 loss)
I1003 10:37:07.217293  7223 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I1003 10:37:21.479475  7223 solver.cpp:218] Iteration 23900 (7.01157 iter/s, 14.2621s/100 iters), loss = 0.325871
I1003 10:37:21.479509  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325871 (* 1 = 0.325871 loss)
I1003 10:37:21.479516  7223 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I1003 10:37:35.031814  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:37:35.600430  7223 solver.cpp:330] Iteration 24000, Testing net (#0)
I1003 10:37:38.969691  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:37:39.109411  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7532
I1003 10:37:39.109437  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.806091 (* 1 = 0.806091 loss)
I1003 10:37:39.250684  7223 solver.cpp:218] Iteration 24000 (5.62711 iter/s, 17.7711s/100 iters), loss = 0.320203
I1003 10:37:39.250717  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320203 (* 1 = 0.320203 loss)
I1003 10:37:39.250725  7223 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I1003 10:37:53.496068  7223 solver.cpp:218] Iteration 24100 (7.01986 iter/s, 14.2453s/100 iters), loss = 0.312753
I1003 10:37:53.496098  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312753 (* 1 = 0.312753 loss)
I1003 10:37:53.496104  7223 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I1003 10:38:07.756070  7223 solver.cpp:218] Iteration 24200 (7.01266 iter/s, 14.2599s/100 iters), loss = 0.319568
I1003 10:38:07.756188  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319568 (* 1 = 0.319568 loss)
I1003 10:38:07.756196  7223 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I1003 10:38:22.006150  7223 solver.cpp:218] Iteration 24300 (7.01758 iter/s, 14.2499s/100 iters), loss = 0.307775
I1003 10:38:22.006180  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307775 (* 1 = 0.307775 loss)
I1003 10:38:22.006186  7223 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I1003 10:38:36.246127  7223 solver.cpp:218] Iteration 24400 (7.02252 iter/s, 14.2399s/100 iters), loss = 0.357831
I1003 10:38:36.246156  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35783 (* 1 = 0.35783 loss)
I1003 10:38:36.246163  7223 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I1003 10:38:49.783687  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:38:50.351837  7223 solver.cpp:330] Iteration 24500, Testing net (#0)
I1003 10:38:53.720018  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:38:53.859992  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7435
I1003 10:38:53.860028  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.786821 (* 1 = 0.786821 loss)
I1003 10:38:54.001528  7223 solver.cpp:218] Iteration 24500 (5.63212 iter/s, 17.7553s/100 iters), loss = 0.288128
I1003 10:38:54.001632  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288127 (* 1 = 0.288127 loss)
I1003 10:38:54.001641  7223 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I1003 10:39:08.272781  7223 solver.cpp:218] Iteration 24600 (7.00718 iter/s, 14.2711s/100 iters), loss = 0.480228
I1003 10:39:08.272811  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.480228 (* 1 = 0.480228 loss)
I1003 10:39:08.272819  7223 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I1003 10:39:22.539819  7223 solver.cpp:218] Iteration 24700 (7.0092 iter/s, 14.267s/100 iters), loss = 0.311121
I1003 10:39:22.539965  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311121 (* 1 = 0.311121 loss)
I1003 10:39:22.539976  7223 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I1003 10:39:36.800853  7223 solver.cpp:218] Iteration 24800 (7.0122 iter/s, 14.2609s/100 iters), loss = 0.446545
I1003 10:39:36.800894  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.446545 (* 1 = 0.446545 loss)
I1003 10:39:36.800901  7223 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I1003 10:39:51.074618  7223 solver.cpp:218] Iteration 24900 (7.0059 iter/s, 14.2737s/100 iters), loss = 0.344082
I1003 10:39:51.074652  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344082 (* 1 = 0.344082 loss)
I1003 10:39:51.074659  7223 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I1003 10:40:04.638092  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:40:05.207994  7223 solver.cpp:330] Iteration 25000, Testing net (#0)
I1003 10:40:08.574448  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:40:08.714428  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8069
I1003 10:40:08.714463  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.582471 (* 1 = 0.582471 loss)
I1003 10:40:08.855577  7223 solver.cpp:218] Iteration 25000 (5.62402 iter/s, 17.7809s/100 iters), loss = 0.284261
I1003 10:40:08.855619  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28426 (* 1 = 0.28426 loss)
I1003 10:40:08.855626  7223 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I1003 10:40:23.110102  7223 solver.cpp:218] Iteration 25100 (7.01543 iter/s, 14.2543s/100 iters), loss = 0.333066
I1003 10:40:23.110132  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333065 (* 1 = 0.333065 loss)
I1003 10:40:23.110137  7223 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I1003 10:40:37.367593  7223 solver.cpp:218] Iteration 25200 (7.01389 iter/s, 14.2574s/100 iters), loss = 0.357568
I1003 10:40:37.367709  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.357568 (* 1 = 0.357568 loss)
I1003 10:40:37.367719  7223 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I1003 10:40:51.631738  7223 solver.cpp:218] Iteration 25300 (7.01067 iter/s, 14.264s/100 iters), loss = 0.433026
I1003 10:40:51.631781  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.433026 (* 1 = 0.433026 loss)
I1003 10:40:51.631788  7223 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I1003 10:41:05.890056  7223 solver.cpp:218] Iteration 25400 (7.01349 iter/s, 14.2582s/100 iters), loss = 0.264695
I1003 10:41:05.890094  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264695 (* 1 = 0.264695 loss)
I1003 10:41:05.890103  7223 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I1003 10:41:19.439507  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:41:20.013459  7223 solver.cpp:330] Iteration 25500, Testing net (#0)
I1003 10:41:23.382623  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:41:23.522444  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8001
I1003 10:41:23.522470  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.598463 (* 1 = 0.598463 loss)
I1003 10:41:23.663345  7223 solver.cpp:218] Iteration 25500 (5.62645 iter/s, 17.7732s/100 iters), loss = 0.360855
I1003 10:41:23.663378  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.360855 (* 1 = 0.360855 loss)
I1003 10:41:23.663388  7223 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I1003 10:41:37.917654  7223 solver.cpp:218] Iteration 25600 (7.01546 iter/s, 14.2542s/100 iters), loss = 0.350734
I1003 10:41:37.917690  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350734 (* 1 = 0.350734 loss)
I1003 10:41:37.917699  7223 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I1003 10:41:52.161201  7223 solver.cpp:218] Iteration 25700 (7.02076 iter/s, 14.2435s/100 iters), loss = 0.290383
I1003 10:41:52.161314  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290383 (* 1 = 0.290383 loss)
I1003 10:41:52.161322  7223 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I1003 10:42:06.423604  7223 solver.cpp:218] Iteration 25800 (7.01151 iter/s, 14.2623s/100 iters), loss = 0.393535
I1003 10:42:06.423637  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.393535 (* 1 = 0.393535 loss)
I1003 10:42:06.423646  7223 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I1003 10:42:20.683972  7223 solver.cpp:218] Iteration 25900 (7.01248 iter/s, 14.2603s/100 iters), loss = 0.374166
I1003 10:42:20.684005  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.374166 (* 1 = 0.374166 loss)
I1003 10:42:20.684022  7223 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I1003 10:42:34.225648  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:42:34.802686  7223 solver.cpp:330] Iteration 26000, Testing net (#0)
I1003 10:42:38.168929  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:42:38.308668  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7621
I1003 10:42:38.308699  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.728065 (* 1 = 0.728065 loss)
I1003 10:42:38.449607  7223 solver.cpp:218] Iteration 26000 (5.62887 iter/s, 17.7656s/100 iters), loss = 0.340735
I1003 10:42:38.449640  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340735 (* 1 = 0.340735 loss)
I1003 10:42:38.449648  7223 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I1003 10:42:52.701614  7223 solver.cpp:218] Iteration 26100 (7.01659 iter/s, 14.2519s/100 iters), loss = 0.261139
I1003 10:42:52.701654  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261139 (* 1 = 0.261139 loss)
I1003 10:42:52.701664  7223 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I1003 10:43:06.948648  7223 solver.cpp:218] Iteration 26200 (7.01905 iter/s, 14.2469s/100 iters), loss = 0.295462
I1003 10:43:06.948796  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295461 (* 1 = 0.295461 loss)
I1003 10:43:06.948806  7223 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I1003 10:43:21.200361  7223 solver.cpp:218] Iteration 26300 (7.01679 iter/s, 14.2515s/100 iters), loss = 0.382706
I1003 10:43:21.200392  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.382706 (* 1 = 0.382706 loss)
I1003 10:43:21.200397  7223 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I1003 10:43:35.457881  7223 solver.cpp:218] Iteration 26400 (7.01388 iter/s, 14.2574s/100 iters), loss = 0.294474
I1003 10:43:35.457912  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294473 (* 1 = 0.294473 loss)
I1003 10:43:35.457917  7223 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I1003 10:43:49.005074  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:43:49.583549  7223 solver.cpp:330] Iteration 26500, Testing net (#0)
I1003 10:43:52.954885  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:43:53.094424  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7896
I1003 10:43:53.094449  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.639982 (* 1 = 0.639982 loss)
I1003 10:43:53.236078  7223 solver.cpp:218] Iteration 26500 (5.62489 iter/s, 17.7781s/100 iters), loss = 0.33235
I1003 10:43:53.236112  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.33235 (* 1 = 0.33235 loss)
I1003 10:43:53.236119  7223 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I1003 10:44:07.477491  7223 solver.cpp:218] Iteration 26600 (7.02181 iter/s, 14.2413s/100 iters), loss = 0.375842
I1003 10:44:07.477530  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.375842 (* 1 = 0.375842 loss)
I1003 10:44:07.477537  7223 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I1003 10:44:21.727705  7223 solver.cpp:218] Iteration 26700 (7.01748 iter/s, 14.2501s/100 iters), loss = 0.42126
I1003 10:44:21.727782  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.42126 (* 1 = 0.42126 loss)
I1003 10:44:21.727799  7223 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I1003 10:44:35.985851  7223 solver.cpp:218] Iteration 26800 (7.01359 iter/s, 14.258s/100 iters), loss = 0.419052
I1003 10:44:35.985883  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.419052 (* 1 = 0.419052 loss)
I1003 10:44:35.985889  7223 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I1003 10:44:50.245777  7223 solver.cpp:218] Iteration 26900 (7.0127 iter/s, 14.2598s/100 iters), loss = 0.350816
I1003 10:44:50.245820  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350816 (* 1 = 0.350816 loss)
I1003 10:44:50.245826  7223 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I1003 10:45:03.778736  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:45:04.346408  7223 solver.cpp:330] Iteration 27000, Testing net (#0)
I1003 10:45:07.721256  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:45:07.860939  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7993
I1003 10:45:07.860965  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.592006 (* 1 = 0.592006 loss)
I1003 10:45:08.002043  7223 solver.cpp:218] Iteration 27000 (5.63184 iter/s, 17.7562s/100 iters), loss = 0.30528
I1003 10:45:08.002076  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30528 (* 1 = 0.30528 loss)
I1003 10:45:08.002084  7223 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I1003 10:45:22.262046  7223 solver.cpp:218] Iteration 27100 (7.01266 iter/s, 14.2599s/100 iters), loss = 0.444999
I1003 10:45:22.262078  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.444999 (* 1 = 0.444999 loss)
I1003 10:45:22.262084  7223 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I1003 10:45:36.534848  7223 solver.cpp:218] Iteration 27200 (7.00637 iter/s, 14.2727s/100 iters), loss = 0.355096
I1003 10:45:36.535003  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355096 (* 1 = 0.355096 loss)
I1003 10:45:36.535012  7223 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I1003 10:45:50.802721  7223 solver.cpp:218] Iteration 27300 (7.00885 iter/s, 14.2677s/100 iters), loss = 0.371305
I1003 10:45:50.802752  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371305 (* 1 = 0.371305 loss)
I1003 10:45:50.802757  7223 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I1003 10:46:05.068506  7223 solver.cpp:218] Iteration 27400 (7.00982 iter/s, 14.2657s/100 iters), loss = 0.338195
I1003 10:46:05.068548  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338195 (* 1 = 0.338195 loss)
I1003 10:46:05.068554  7223 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I1003 10:46:18.623927  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:46:19.192159  7223 solver.cpp:330] Iteration 27500, Testing net (#0)
I1003 10:46:22.567224  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:46:22.710225  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8121
I1003 10:46:22.710263  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.561339 (* 1 = 0.561339 loss)
I1003 10:46:22.851665  7223 solver.cpp:218] Iteration 27500 (5.62333 iter/s, 17.7831s/100 iters), loss = 0.275077
I1003 10:46:22.851699  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275077 (* 1 = 0.275077 loss)
I1003 10:46:22.851706  7223 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I1003 10:46:37.110034  7223 solver.cpp:218] Iteration 27600 (7.01346 iter/s, 14.2583s/100 iters), loss = 0.304602
I1003 10:46:37.110075  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304602 (* 1 = 0.304602 loss)
I1003 10:46:37.110081  7223 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I1003 10:46:51.379318  7223 solver.cpp:218] Iteration 27700 (7.0081 iter/s, 14.2692s/100 iters), loss = 0.344157
I1003 10:46:51.379436  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344157 (* 1 = 0.344157 loss)
I1003 10:46:51.379452  7223 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I1003 10:47:05.650595  7223 solver.cpp:218] Iteration 27800 (7.00716 iter/s, 14.2711s/100 iters), loss = 0.366704
I1003 10:47:05.650635  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366704 (* 1 = 0.366704 loss)
I1003 10:47:05.650642  7223 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I1003 10:47:19.911895  7223 solver.cpp:218] Iteration 27900 (7.01203 iter/s, 14.2612s/100 iters), loss = 0.262591
I1003 10:47:19.911929  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262591 (* 1 = 0.262591 loss)
I1003 10:47:19.911936  7223 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I1003 10:47:33.456351  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:47:34.024142  7223 solver.cpp:330] Iteration 28000, Testing net (#0)
I1003 10:47:37.391459  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:47:37.536615  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7978
I1003 10:47:37.536653  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.608901 (* 1 = 0.608901 loss)
I1003 10:47:37.681180  7223 solver.cpp:218] Iteration 28000 (5.62772 iter/s, 17.7692s/100 iters), loss = 0.264173
I1003 10:47:37.681219  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264173 (* 1 = 0.264173 loss)
I1003 10:47:37.681237  7223 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I1003 10:47:51.924186  7223 solver.cpp:218] Iteration 28100 (7.02105 iter/s, 14.2429s/100 iters), loss = 0.268976
I1003 10:47:51.924216  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268976 (* 1 = 0.268976 loss)
I1003 10:47:51.924222  7223 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I1003 10:48:06.176048  7223 solver.cpp:218] Iteration 28200 (7.01666 iter/s, 14.2518s/100 iters), loss = 0.277239
I1003 10:48:06.176174  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277239 (* 1 = 0.277239 loss)
I1003 10:48:06.176182  7223 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I1003 10:48:20.422158  7223 solver.cpp:218] Iteration 28300 (7.01954 iter/s, 14.2459s/100 iters), loss = 0.343235
I1003 10:48:20.422188  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343235 (* 1 = 0.343235 loss)
I1003 10:48:20.422194  7223 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I1003 10:48:34.679311  7223 solver.cpp:218] Iteration 28400 (7.01406 iter/s, 14.2571s/100 iters), loss = 0.317921
I1003 10:48:34.679350  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317921 (* 1 = 0.317921 loss)
I1003 10:48:34.679368  7223 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I1003 10:48:48.223801  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:48:48.791695  7223 solver.cpp:330] Iteration 28500, Testing net (#0)
I1003 10:48:52.157066  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:48:52.296808  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7913
I1003 10:48:52.296844  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.617581 (* 1 = 0.617581 loss)
I1003 10:48:52.438735  7223 solver.cpp:218] Iteration 28500 (5.63085 iter/s, 17.7593s/100 iters), loss = 0.310592
I1003 10:48:52.438768  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310592 (* 1 = 0.310592 loss)
I1003 10:48:52.438776  7223 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I1003 10:49:06.686339  7223 solver.cpp:218] Iteration 28600 (7.01876 iter/s, 14.2475s/100 iters), loss = 0.267328
I1003 10:49:06.686372  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267328 (* 1 = 0.267328 loss)
I1003 10:49:06.686378  7223 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I1003 10:49:20.944952  7223 solver.cpp:218] Iteration 28700 (7.01334 iter/s, 14.2585s/100 iters), loss = 0.330137
I1003 10:49:20.945060  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330137 (* 1 = 0.330137 loss)
I1003 10:49:20.945067  7223 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I1003 10:49:35.205729  7223 solver.cpp:218] Iteration 28800 (7.01232 iter/s, 14.2606s/100 iters), loss = 0.351455
I1003 10:49:35.205760  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351455 (* 1 = 0.351455 loss)
I1003 10:49:35.205767  7223 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I1003 10:49:49.448492  7223 solver.cpp:218] Iteration 28900 (7.02115 iter/s, 14.2427s/100 iters), loss = 0.279524
I1003 10:49:49.448526  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279524 (* 1 = 0.279524 loss)
I1003 10:49:49.448534  7223 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I1003 10:50:02.995909  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:50:03.564118  7223 solver.cpp:330] Iteration 29000, Testing net (#0)
I1003 10:50:06.930464  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:50:07.070163  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7988
I1003 10:50:07.070188  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.577169 (* 1 = 0.577169 loss)
I1003 10:50:07.210813  7223 solver.cpp:218] Iteration 29000 (5.62992 iter/s, 17.7622s/100 iters), loss = 0.282965
I1003 10:50:07.210840  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282964 (* 1 = 0.282964 loss)
I1003 10:50:07.210847  7223 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I1003 10:50:21.465478  7223 solver.cpp:218] Iteration 29100 (7.01528 iter/s, 14.2546s/100 iters), loss = 0.29782
I1003 10:50:21.465519  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29782 (* 1 = 0.29782 loss)
I1003 10:50:21.465526  7223 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I1003 10:50:35.708886  7223 solver.cpp:218] Iteration 29200 (7.02083 iter/s, 14.2433s/100 iters), loss = 0.345887
I1003 10:50:35.708999  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.345887 (* 1 = 0.345887 loss)
I1003 10:50:35.709007  7223 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I1003 10:50:49.963063  7223 solver.cpp:218] Iteration 29300 (7.01556 iter/s, 14.254s/100 iters), loss = 0.315536
I1003 10:50:49.963099  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315536 (* 1 = 0.315536 loss)
I1003 10:50:49.963106  7223 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I1003 10:51:04.211216  7223 solver.cpp:218] Iteration 29400 (7.0185 iter/s, 14.2481s/100 iters), loss = 0.350488
I1003 10:51:04.211247  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350488 (* 1 = 0.350488 loss)
I1003 10:51:04.211253  7223 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I1003 10:51:17.767110  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:51:18.336663  7223 solver.cpp:330] Iteration 29500, Testing net (#0)
I1003 10:51:21.701809  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:51:21.841496  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7338
I1003 10:51:21.841532  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.825142 (* 1 = 0.825142 loss)
I1003 10:51:21.982772  7223 solver.cpp:218] Iteration 29500 (5.627 iter/s, 17.7715s/100 iters), loss = 0.284555
I1003 10:51:21.982803  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284555 (* 1 = 0.284555 loss)
I1003 10:51:21.982810  7223 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I1003 10:51:36.244103  7223 solver.cpp:218] Iteration 29600 (7.012 iter/s, 14.2613s/100 iters), loss = 0.366543
I1003 10:51:36.244134  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366543 (* 1 = 0.366543 loss)
I1003 10:51:36.244140  7223 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I1003 10:51:50.520057  7223 solver.cpp:218] Iteration 29700 (7.00482 iter/s, 14.2759s/100 iters), loss = 0.425312
I1003 10:51:50.520170  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.425312 (* 1 = 0.425312 loss)
I1003 10:51:50.520179  7223 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I1003 10:52:04.787447  7223 solver.cpp:218] Iteration 29800 (7.00906 iter/s, 14.2672s/100 iters), loss = 0.321464
I1003 10:52:04.787482  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.321463 (* 1 = 0.321463 loss)
I1003 10:52:04.787489  7223 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I1003 10:52:19.043040  7223 solver.cpp:218] Iteration 29900 (7.01483 iter/s, 14.2555s/100 iters), loss = 0.170982
I1003 10:52:19.043071  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170981 (* 1 = 0.170981 loss)
I1003 10:52:19.043076  7223 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I1003 10:52:32.610941  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:52:33.180496  7223 solver.cpp:330] Iteration 30000, Testing net (#0)
I1003 10:52:36.548988  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:52:36.689376  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7779
I1003 10:52:36.689414  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.651616 (* 1 = 0.651616 loss)
I1003 10:52:36.830688  7223 solver.cpp:218] Iteration 30000 (5.6219 iter/s, 17.7876s/100 iters), loss = 0.356502
I1003 10:52:36.830721  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.356502 (* 1 = 0.356502 loss)
I1003 10:52:36.830729  7223 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I1003 10:52:51.085990  7223 solver.cpp:218] Iteration 30100 (7.01498 iter/s, 14.2552s/100 iters), loss = 0.405775
I1003 10:52:51.086035  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405775 (* 1 = 0.405775 loss)
I1003 10:52:51.086040  7223 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I1003 10:53:05.340545  7223 solver.cpp:218] Iteration 30200 (7.01534 iter/s, 14.2545s/100 iters), loss = 0.327375
I1003 10:53:05.340689  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327375 (* 1 = 0.327375 loss)
I1003 10:53:05.340698  7223 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I1003 10:53:19.600297  7223 solver.cpp:218] Iteration 30300 (7.01284 iter/s, 14.2596s/100 iters), loss = 0.38459
I1003 10:53:19.600347  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.38459 (* 1 = 0.38459 loss)
I1003 10:53:19.600354  7223 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I1003 10:53:33.862846  7223 solver.cpp:218] Iteration 30400 (7.01144 iter/s, 14.2624s/100 iters), loss = 0.200181
I1003 10:53:33.862876  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200181 (* 1 = 0.200181 loss)
I1003 10:53:33.862882  7223 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I1003 10:53:47.410143  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:53:47.977908  7223 solver.cpp:330] Iteration 30500, Testing net (#0)
I1003 10:53:51.344007  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:53:51.484041  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8103
I1003 10:53:51.484078  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.558786 (* 1 = 0.558786 loss)
I1003 10:53:51.625025  7223 solver.cpp:218] Iteration 30500 (5.62997 iter/s, 17.7621s/100 iters), loss = 0.235987
I1003 10:53:51.625057  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235987 (* 1 = 0.235987 loss)
I1003 10:53:51.625064  7223 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I1003 10:54:05.875625  7223 solver.cpp:218] Iteration 30600 (7.01729 iter/s, 14.2505s/100 iters), loss = 0.305594
I1003 10:54:05.875666  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305594 (* 1 = 0.305594 loss)
I1003 10:54:05.875674  7223 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I1003 10:54:20.137982  7223 solver.cpp:218] Iteration 30700 (7.01151 iter/s, 14.2623s/100 iters), loss = 0.293355
I1003 10:54:20.138123  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293355 (* 1 = 0.293355 loss)
I1003 10:54:20.138131  7223 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I1003 10:54:34.381108  7223 solver.cpp:218] Iteration 30800 (7.02102 iter/s, 14.2429s/100 iters), loss = 0.344603
I1003 10:54:34.381139  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344603 (* 1 = 0.344603 loss)
I1003 10:54:34.381145  7223 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I1003 10:54:48.630806  7223 solver.cpp:218] Iteration 30900 (7.01773 iter/s, 14.2496s/100 iters), loss = 0.238775
I1003 10:54:48.630839  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238775 (* 1 = 0.238775 loss)
I1003 10:54:48.630846  7223 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I1003 10:55:02.184828  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:55:02.753960  7223 solver.cpp:330] Iteration 31000, Testing net (#0)
I1003 10:55:06.123026  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:55:06.262985  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7776
I1003 10:55:06.263021  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.6775 (* 1 = 0.6775 loss)
I1003 10:55:06.404369  7223 solver.cpp:218] Iteration 31000 (5.62636 iter/s, 17.7735s/100 iters), loss = 0.276122
I1003 10:55:06.404399  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276122 (* 1 = 0.276122 loss)
I1003 10:55:06.404407  7223 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I1003 10:55:20.650545  7223 solver.cpp:218] Iteration 31100 (7.01947 iter/s, 14.2461s/100 iters), loss = 0.314897
I1003 10:55:20.650595  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314897 (* 1 = 0.314897 loss)
I1003 10:55:20.650610  7223 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I1003 10:55:34.893323  7223 solver.cpp:218] Iteration 31200 (7.02115 iter/s, 14.2427s/100 iters), loss = 0.278946
I1003 10:55:34.893446  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278946 (* 1 = 0.278946 loss)
I1003 10:55:34.893465  7223 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I1003 10:55:49.141708  7223 solver.cpp:218] Iteration 31300 (7.01841 iter/s, 14.2482s/100 iters), loss = 0.279046
I1003 10:55:49.141739  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279046 (* 1 = 0.279046 loss)
I1003 10:55:49.141746  7223 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I1003 10:56:03.388396  7223 solver.cpp:218] Iteration 31400 (7.01922 iter/s, 14.2466s/100 iters), loss = 0.267567
I1003 10:56:03.388427  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267567 (* 1 = 0.267567 loss)
I1003 10:56:03.388434  7223 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I1003 10:56:16.936743  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:56:17.504933  7223 solver.cpp:330] Iteration 31500, Testing net (#0)
I1003 10:56:20.871753  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:56:21.011898  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7385
I1003 10:56:21.011924  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.858085 (* 1 = 0.858085 loss)
I1003 10:56:21.152837  7223 solver.cpp:218] Iteration 31500 (5.62925 iter/s, 17.7644s/100 iters), loss = 0.258962
I1003 10:56:21.152868  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258962 (* 1 = 0.258962 loss)
I1003 10:56:21.152876  7223 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I1003 10:56:35.407245  7223 solver.cpp:218] Iteration 31600 (7.01541 iter/s, 14.2543s/100 iters), loss = 0.265329
I1003 10:56:35.407289  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265329 (* 1 = 0.265329 loss)
I1003 10:56:35.407297  7223 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I1003 10:56:49.663628  7223 solver.cpp:218] Iteration 31700 (7.01445 iter/s, 14.2563s/100 iters), loss = 0.324638
I1003 10:56:49.663794  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324638 (* 1 = 0.324638 loss)
I1003 10:56:49.663812  7223 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I1003 10:57:03.909343  7223 solver.cpp:218] Iteration 31800 (7.01977 iter/s, 14.2455s/100 iters), loss = 0.416759
I1003 10:57:03.909373  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.416759 (* 1 = 0.416759 loss)
I1003 10:57:03.909379  7223 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I1003 10:57:18.162413  7223 solver.cpp:218] Iteration 31900 (7.01607 iter/s, 14.253s/100 iters), loss = 0.248419
I1003 10:57:18.162458  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248419 (* 1 = 0.248419 loss)
I1003 10:57:18.162467  7223 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I1003 10:57:31.724834  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:57:32.293433  7223 solver.cpp:330] Iteration 32000, Testing net (#0)
I1003 10:57:35.660334  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:57:35.800251  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7806
I1003 10:57:35.800277  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.644044 (* 1 = 0.644044 loss)
I1003 10:57:35.941182  7223 solver.cpp:218] Iteration 32000 (5.62472 iter/s, 17.7787s/100 iters), loss = 0.238225
I1003 10:57:35.941213  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238225 (* 1 = 0.238225 loss)
I1003 10:57:35.941220  7223 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I1003 10:57:50.197372  7223 solver.cpp:218] Iteration 32100 (7.01453 iter/s, 14.2561s/100 iters), loss = 0.380195
I1003 10:57:50.197407  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.380195 (* 1 = 0.380195 loss)
I1003 10:57:50.197413  7223 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I1003 10:58:04.451242  7223 solver.cpp:218] Iteration 32200 (7.01568 iter/s, 14.2538s/100 iters), loss = 0.199638
I1003 10:58:04.451380  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199638 (* 1 = 0.199638 loss)
I1003 10:58:04.451388  7223 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I1003 10:58:18.727439  7223 solver.cpp:218] Iteration 32300 (7.00476 iter/s, 14.276s/100 iters), loss = 0.339575
I1003 10:58:18.727471  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.339575 (* 1 = 0.339575 loss)
I1003 10:58:18.727478  7223 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I1003 10:58:32.988299  7223 solver.cpp:218] Iteration 32400 (7.01224 iter/s, 14.2608s/100 iters), loss = 0.268091
I1003 10:58:32.988330  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268091 (* 1 = 0.268091 loss)
I1003 10:58:32.988337  7223 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I1003 10:58:46.541236  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:58:47.115346  7223 solver.cpp:330] Iteration 32500, Testing net (#0)
I1003 10:58:50.485620  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 10:58:50.625828  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.787
I1003 10:58:50.625852  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.626771 (* 1 = 0.626771 loss)
I1003 10:58:50.767345  7223 solver.cpp:218] Iteration 32500 (5.62463 iter/s, 17.779s/100 iters), loss = 0.318043
I1003 10:58:50.767374  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.318042 (* 1 = 0.318042 loss)
I1003 10:58:50.767380  7223 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I1003 10:59:05.031047  7223 solver.cpp:218] Iteration 32600 (7.01084 iter/s, 14.2636s/100 iters), loss = 0.303154
I1003 10:59:05.031090  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303154 (* 1 = 0.303154 loss)
I1003 10:59:05.031096  7223 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I1003 10:59:19.288517  7223 solver.cpp:218] Iteration 32700 (7.01391 iter/s, 14.2574s/100 iters), loss = 0.278686
I1003 10:59:19.288661  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278686 (* 1 = 0.278686 loss)
I1003 10:59:19.288671  7223 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I1003 10:59:33.542368  7223 solver.cpp:218] Iteration 32800 (7.01574 iter/s, 14.2537s/100 iters), loss = 0.442116
I1003 10:59:33.542409  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.442116 (* 1 = 0.442116 loss)
I1003 10:59:33.542415  7223 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I1003 10:59:47.804042  7223 solver.cpp:218] Iteration 32900 (7.01184 iter/s, 14.2616s/100 iters), loss = 0.279946
I1003 10:59:47.804083  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279946 (* 1 = 0.279946 loss)
I1003 10:59:47.804090  7223 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I1003 11:00:01.352393  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:00:01.928778  7223 solver.cpp:330] Iteration 33000, Testing net (#0)
I1003 11:00:05.294114  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:00:05.434588  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8065
I1003 11:00:05.434614  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.586589 (* 1 = 0.586589 loss)
I1003 11:00:05.575834  7223 solver.cpp:218] Iteration 33000 (5.62692 iter/s, 17.7717s/100 iters), loss = 0.272045
I1003 11:00:05.575863  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272045 (* 1 = 0.272045 loss)
I1003 11:00:05.575870  7223 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I1003 11:00:19.824534  7223 solver.cpp:218] Iteration 33100 (7.01822 iter/s, 14.2486s/100 iters), loss = 0.375258
I1003 11:00:19.824570  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.375258 (* 1 = 0.375258 loss)
I1003 11:00:19.824578  7223 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I1003 11:00:34.074827  7223 solver.cpp:218] Iteration 33200 (7.01744 iter/s, 14.2502s/100 iters), loss = 0.308706
I1003 11:00:34.074928  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308706 (* 1 = 0.308706 loss)
I1003 11:00:34.074935  7223 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I1003 11:00:48.335428  7223 solver.cpp:218] Iteration 33300 (7.0124 iter/s, 14.2605s/100 iters), loss = 0.341254
I1003 11:00:48.335461  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.341253 (* 1 = 0.341253 loss)
I1003 11:00:48.335469  7223 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I1003 11:01:02.586963  7223 solver.cpp:218] Iteration 33400 (7.01682 iter/s, 14.2515s/100 iters), loss = 0.289609
I1003 11:01:02.586994  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289609 (* 1 = 0.289609 loss)
I1003 11:01:02.587010  7223 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I1003 11:01:16.130123  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:01:16.706868  7223 solver.cpp:330] Iteration 33500, Testing net (#0)
I1003 11:01:20.078886  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:01:20.218775  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7786
I1003 11:01:20.218799  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.635989 (* 1 = 0.635989 loss)
I1003 11:01:20.359863  7223 solver.cpp:218] Iteration 33500 (5.62657 iter/s, 17.7728s/100 iters), loss = 0.306061
I1003 11:01:20.359896  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306061 (* 1 = 0.306061 loss)
I1003 11:01:20.359905  7223 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I1003 11:01:34.616209  7223 solver.cpp:218] Iteration 33600 (7.01446 iter/s, 14.2563s/100 iters), loss = 0.274419
I1003 11:01:34.616255  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274418 (* 1 = 0.274418 loss)
I1003 11:01:34.616263  7223 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I1003 11:01:48.864468  7223 solver.cpp:218] Iteration 33700 (7.01846 iter/s, 14.2481s/100 iters), loss = 0.259349
I1003 11:01:48.864588  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259348 (* 1 = 0.259348 loss)
I1003 11:01:48.864604  7223 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I1003 11:02:03.117149  7223 solver.cpp:218] Iteration 33800 (7.0163 iter/s, 14.2525s/100 iters), loss = 0.367188
I1003 11:02:03.117182  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.367188 (* 1 = 0.367188 loss)
I1003 11:02:03.117187  7223 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I1003 11:02:17.380990  7223 solver.cpp:218] Iteration 33900 (7.01077 iter/s, 14.2638s/100 iters), loss = 0.260808
I1003 11:02:17.381022  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260807 (* 1 = 0.260807 loss)
I1003 11:02:17.381029  7223 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I1003 11:02:30.922392  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:02:31.490960  7223 solver.cpp:330] Iteration 34000, Testing net (#0)
I1003 11:02:34.864323  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:02:35.004709  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6759
I1003 11:02:35.004735  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.13611 (* 1 = 1.13611 loss)
I1003 11:02:35.145747  7223 solver.cpp:218] Iteration 34000 (5.62915 iter/s, 17.7647s/100 iters), loss = 0.239128
I1003 11:02:35.145778  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239128 (* 1 = 0.239128 loss)
I1003 11:02:35.145786  7223 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I1003 11:02:49.387792  7223 solver.cpp:218] Iteration 34100 (7.0215 iter/s, 14.242s/100 iters), loss = 0.269341
I1003 11:02:49.387823  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269341 (* 1 = 0.269341 loss)
I1003 11:02:49.387830  7223 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I1003 11:03:03.651554  7223 solver.cpp:218] Iteration 34200 (7.01081 iter/s, 14.2637s/100 iters), loss = 0.334985
I1003 11:03:03.651696  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.334985 (* 1 = 0.334985 loss)
I1003 11:03:03.651747  7223 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I1003 11:03:17.903379  7223 solver.cpp:218] Iteration 34300 (7.01673 iter/s, 14.2516s/100 iters), loss = 0.351363
I1003 11:03:17.903409  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351363 (* 1 = 0.351363 loss)
I1003 11:03:17.903415  7223 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I1003 11:03:32.159124  7223 solver.cpp:218] Iteration 34400 (7.01475 iter/s, 14.2557s/100 iters), loss = 0.305857
I1003 11:03:32.159154  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305857 (* 1 = 0.305857 loss)
I1003 11:03:32.159160  7223 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I1003 11:03:45.703913  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:03:46.272676  7223 solver.cpp:330] Iteration 34500, Testing net (#0)
I1003 11:03:49.647248  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:03:49.791079  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7875
I1003 11:03:49.791116  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.6637 (* 1 = 0.6637 loss)
I1003 11:03:49.932019  7223 solver.cpp:218] Iteration 34500 (5.62657 iter/s, 17.7728s/100 iters), loss = 0.266732
I1003 11:03:49.932054  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266732 (* 1 = 0.266732 loss)
I1003 11:03:49.932061  7223 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I1003 11:04:04.184898  7223 solver.cpp:218] Iteration 34600 (7.01618 iter/s, 14.2528s/100 iters), loss = 0.365861
I1003 11:04:04.184928  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.36586 (* 1 = 0.36586 loss)
I1003 11:04:04.184934  7223 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I1003 11:04:18.441421  7223 solver.cpp:218] Iteration 34700 (7.01437 iter/s, 14.2564s/100 iters), loss = 0.414231
I1003 11:04:18.441545  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.41423 (* 1 = 0.41423 loss)
I1003 11:04:18.441552  7223 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I1003 11:04:32.708659  7223 solver.cpp:218] Iteration 34800 (7.00915 iter/s, 14.2671s/100 iters), loss = 0.317446
I1003 11:04:32.708690  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317446 (* 1 = 0.317446 loss)
I1003 11:04:32.708698  7223 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I1003 11:04:46.986536  7223 solver.cpp:218] Iteration 34900 (7.00388 iter/s, 14.2778s/100 iters), loss = 0.291323
I1003 11:04:46.986570  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291323 (* 1 = 0.291323 loss)
I1003 11:04:46.986577  7223 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I1003 11:05:00.538934  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:05:01.107188  7223 solver.cpp:330] Iteration 35000, Testing net (#0)
I1003 11:05:04.473891  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:05:04.616833  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.752
I1003 11:05:04.616861  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.780956 (* 1 = 0.780956 loss)
I1003 11:05:04.761662  7223 solver.cpp:218] Iteration 35000 (5.62587 iter/s, 17.775s/100 iters), loss = 0.344071
I1003 11:05:04.761700  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344071 (* 1 = 0.344071 loss)
I1003 11:05:04.761708  7223 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I1003 11:05:19.006012  7223 solver.cpp:218] Iteration 35100 (7.02037 iter/s, 14.2443s/100 iters), loss = 0.247752
I1003 11:05:19.006045  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247751 (* 1 = 0.247751 loss)
I1003 11:05:19.006052  7223 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I1003 11:05:33.257566  7223 solver.cpp:218] Iteration 35200 (7.01682 iter/s, 14.2515s/100 iters), loss = 0.336873
I1003 11:05:33.257745  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336873 (* 1 = 0.336873 loss)
I1003 11:05:33.257755  7223 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I1003 11:05:47.505591  7223 solver.cpp:218] Iteration 35300 (7.01862 iter/s, 14.2478s/100 iters), loss = 0.430305
I1003 11:05:47.505625  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.430305 (* 1 = 0.430305 loss)
I1003 11:05:47.505631  7223 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I1003 11:06:01.755524  7223 solver.cpp:218] Iteration 35400 (7.01761 iter/s, 14.2499s/100 iters), loss = 0.21594
I1003 11:06:01.755561  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21594 (* 1 = 0.21594 loss)
I1003 11:06:01.755569  7223 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I1003 11:06:15.296875  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:06:15.864579  7223 solver.cpp:330] Iteration 35500, Testing net (#0)
I1003 11:06:19.233880  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:06:19.374147  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8192
I1003 11:06:19.374173  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.53411 (* 1 = 0.53411 loss)
I1003 11:06:19.515771  7223 solver.cpp:218] Iteration 35500 (5.63058 iter/s, 17.7602s/100 iters), loss = 0.230691
I1003 11:06:19.515807  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23069 (* 1 = 0.23069 loss)
I1003 11:06:19.515827  7223 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I1003 11:06:33.772682  7223 solver.cpp:218] Iteration 35600 (7.01426 iter/s, 14.2567s/100 iters), loss = 0.277886
I1003 11:06:33.772723  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277886 (* 1 = 0.277886 loss)
I1003 11:06:33.772729  7223 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I1003 11:06:48.036109  7223 solver.cpp:218] Iteration 35700 (7.01098 iter/s, 14.2633s/100 iters), loss = 0.22664
I1003 11:06:48.036247  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22664 (* 1 = 0.22664 loss)
I1003 11:06:48.036254  7223 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I1003 11:07:02.308593  7223 solver.cpp:218] Iteration 35800 (7.00657 iter/s, 14.2723s/100 iters), loss = 0.26967
I1003 11:07:02.308625  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26967 (* 1 = 0.26967 loss)
I1003 11:07:02.308631  7223 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I1003 11:07:16.570967  7223 solver.cpp:218] Iteration 35900 (7.01149 iter/s, 14.2623s/100 iters), loss = 0.297486
I1003 11:07:16.571002  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297486 (* 1 = 0.297486 loss)
I1003 11:07:16.571010  7223 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I1003 11:07:30.120507  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:07:30.691241  7223 solver.cpp:330] Iteration 36000, Testing net (#0)
I1003 11:07:34.059612  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:07:34.199689  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7392
I1003 11:07:34.199724  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.835593 (* 1 = 0.835593 loss)
I1003 11:07:34.341030  7223 solver.cpp:218] Iteration 36000 (5.62747 iter/s, 17.77s/100 iters), loss = 0.284188
I1003 11:07:34.341058  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284188 (* 1 = 0.284188 loss)
I1003 11:07:34.341063  7223 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I1003 11:07:48.601519  7223 solver.cpp:218] Iteration 36100 (7.01242 iter/s, 14.2604s/100 iters), loss = 0.308674
I1003 11:07:48.601553  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308674 (* 1 = 0.308674 loss)
I1003 11:07:48.601560  7223 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I1003 11:08:02.857112  7223 solver.cpp:218] Iteration 36200 (7.01483 iter/s, 14.2555s/100 iters), loss = 0.400212
I1003 11:08:02.857288  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.400212 (* 1 = 0.400212 loss)
I1003 11:08:02.857307  7223 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I1003 11:08:17.106391  7223 solver.cpp:218] Iteration 36300 (7.01801 iter/s, 14.2491s/100 iters), loss = 0.404959
I1003 11:08:17.106423  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.404959 (* 1 = 0.404959 loss)
I1003 11:08:17.106431  7223 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I1003 11:08:31.357964  7223 solver.cpp:218] Iteration 36400 (7.01681 iter/s, 14.2515s/100 iters), loss = 0.238236
I1003 11:08:31.357995  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238236 (* 1 = 0.238236 loss)
I1003 11:08:31.358000  7223 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I1003 11:08:44.914469  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:08:45.482074  7223 solver.cpp:330] Iteration 36500, Testing net (#0)
I1003 11:08:48.850219  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:08:48.990464  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8315
I1003 11:08:48.990492  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.50214 (* 1 = 0.50214 loss)
I1003 11:08:49.131567  7223 solver.cpp:218] Iteration 36500 (5.62635 iter/s, 17.7735s/100 iters), loss = 0.269268
I1003 11:08:49.131608  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269268 (* 1 = 0.269268 loss)
I1003 11:08:49.131625  7223 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I1003 11:09:03.377547  7223 solver.cpp:218] Iteration 36600 (7.01957 iter/s, 14.2459s/100 iters), loss = 0.391698
I1003 11:09:03.377583  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.391698 (* 1 = 0.391698 loss)
I1003 11:09:03.377593  7223 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I1003 11:09:17.627674  7223 solver.cpp:218] Iteration 36700 (7.01752 iter/s, 14.25s/100 iters), loss = 0.285925
I1003 11:09:17.627825  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285925 (* 1 = 0.285925 loss)
I1003 11:09:17.627840  7223 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I1003 11:09:31.884693  7223 solver.cpp:218] Iteration 36800 (7.01418 iter/s, 14.2568s/100 iters), loss = 0.303169
I1003 11:09:31.884729  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303168 (* 1 = 0.303168 loss)
I1003 11:09:31.884737  7223 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I1003 11:09:46.117924  7223 solver.cpp:218] Iteration 36900 (7.02585 iter/s, 14.2332s/100 iters), loss = 0.246511
I1003 11:09:46.117952  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246511 (* 1 = 0.246511 loss)
I1003 11:09:46.117959  7223 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I1003 11:09:59.659104  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:10:00.228335  7223 solver.cpp:330] Iteration 37000, Testing net (#0)
I1003 11:10:03.597599  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:10:03.737085  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7448
I1003 11:10:03.737121  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.814589 (* 1 = 0.814589 loss)
I1003 11:10:03.878352  7223 solver.cpp:218] Iteration 37000 (5.63052 iter/s, 17.7603s/100 iters), loss = 0.24768
I1003 11:10:03.878412  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24768 (* 1 = 0.24768 loss)
I1003 11:10:03.878417  7223 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I1003 11:10:18.146095  7223 solver.cpp:218] Iteration 37100 (7.00894 iter/s, 14.2675s/100 iters), loss = 0.43182
I1003 11:10:18.146126  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.43182 (* 1 = 0.43182 loss)
I1003 11:10:18.146132  7223 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I1003 11:10:32.406787  7223 solver.cpp:218] Iteration 37200 (7.01232 iter/s, 14.2606s/100 iters), loss = 0.252576
I1003 11:10:32.406954  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252576 (* 1 = 0.252576 loss)
I1003 11:10:32.406962  7223 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I1003 11:10:46.661893  7223 solver.cpp:218] Iteration 37300 (7.01514 iter/s, 14.2549s/100 iters), loss = 0.313662
I1003 11:10:46.661943  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313662 (* 1 = 0.313662 loss)
I1003 11:10:46.661950  7223 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I1003 11:11:00.925608  7223 solver.cpp:218] Iteration 37400 (7.01086 iter/s, 14.2636s/100 iters), loss = 0.250782
I1003 11:11:00.925638  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250782 (* 1 = 0.250782 loss)
I1003 11:11:00.925644  7223 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I1003 11:11:14.479468  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:11:15.048841  7223 solver.cpp:330] Iteration 37500, Testing net (#0)
I1003 11:11:18.413959  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:11:18.553664  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8246
I1003 11:11:18.553701  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.517292 (* 1 = 0.517292 loss)
I1003 11:11:18.694735  7223 solver.cpp:218] Iteration 37500 (5.62777 iter/s, 17.769s/100 iters), loss = 0.254588
I1003 11:11:18.694768  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254587 (* 1 = 0.254587 loss)
I1003 11:11:18.694774  7223 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I1003 11:11:32.934432  7223 solver.cpp:218] Iteration 37600 (7.02266 iter/s, 14.2396s/100 iters), loss = 0.348746
I1003 11:11:32.934464  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.348746 (* 1 = 0.348746 loss)
I1003 11:11:32.934480  7223 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I1003 11:11:47.197358  7223 solver.cpp:218] Iteration 37700 (7.01122 iter/s, 14.2628s/100 iters), loss = 0.320365
I1003 11:11:47.197486  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320365 (* 1 = 0.320365 loss)
I1003 11:11:47.197505  7223 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I1003 11:12:01.441689  7223 solver.cpp:218] Iteration 37800 (7.02041 iter/s, 14.2442s/100 iters), loss = 0.31134
I1003 11:12:01.441720  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311339 (* 1 = 0.311339 loss)
I1003 11:12:01.441725  7223 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I1003 11:12:15.681224  7223 solver.cpp:218] Iteration 37900 (7.02274 iter/s, 14.2395s/100 iters), loss = 0.259923
I1003 11:12:15.681258  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259923 (* 1 = 0.259923 loss)
I1003 11:12:15.681265  7223 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I1003 11:12:29.228215  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:12:29.796743  7223 solver.cpp:330] Iteration 38000, Testing net (#0)
I1003 11:12:33.166350  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:12:33.306385  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7994
I1003 11:12:33.306421  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.621791 (* 1 = 0.621791 loss)
I1003 11:12:33.447765  7223 solver.cpp:218] Iteration 38000 (5.62858 iter/s, 17.7665s/100 iters), loss = 0.301835
I1003 11:12:33.447801  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301835 (* 1 = 0.301835 loss)
I1003 11:12:33.447809  7223 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I1003 11:12:47.713593  7223 solver.cpp:218] Iteration 38100 (7.0098 iter/s, 14.2657s/100 iters), loss = 0.332412
I1003 11:12:47.713634  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.332412 (* 1 = 0.332412 loss)
I1003 11:12:47.713641  7223 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I1003 11:13:01.965253  7223 solver.cpp:218] Iteration 38200 (7.01677 iter/s, 14.2516s/100 iters), loss = 0.340729
I1003 11:13:01.965378  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340729 (* 1 = 0.340729 loss)
I1003 11:13:01.965385  7223 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I1003 11:13:16.216810  7223 solver.cpp:218] Iteration 38300 (7.01686 iter/s, 14.2514s/100 iters), loss = 0.286221
I1003 11:13:16.216852  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28622 (* 1 = 0.28622 loss)
I1003 11:13:16.216858  7223 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I1003 11:13:30.479485  7223 solver.cpp:218] Iteration 38400 (7.01135 iter/s, 14.2626s/100 iters), loss = 0.20786
I1003 11:13:30.479518  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207859 (* 1 = 0.207859 loss)
I1003 11:13:30.479526  7223 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I1003 11:13:44.024451  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:13:44.592268  7223 solver.cpp:330] Iteration 38500, Testing net (#0)
I1003 11:13:47.957852  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:13:48.098044  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8184
I1003 11:13:48.098083  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.525984 (* 1 = 0.525984 loss)
I1003 11:13:48.239786  7223 solver.cpp:218] Iteration 38500 (5.63056 iter/s, 17.7602s/100 iters), loss = 0.339315
I1003 11:13:48.239820  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.339314 (* 1 = 0.339314 loss)
I1003 11:13:48.239826  7223 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I1003 11:14:02.495499  7223 solver.cpp:218] Iteration 38600 (7.01477 iter/s, 14.2556s/100 iters), loss = 0.261434
I1003 11:14:02.495530  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261433 (* 1 = 0.261433 loss)
I1003 11:14:02.495537  7223 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I1003 11:14:16.754573  7223 solver.cpp:218] Iteration 38700 (7.01312 iter/s, 14.259s/100 iters), loss = 0.225692
I1003 11:14:16.754680  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225692 (* 1 = 0.225692 loss)
I1003 11:14:16.754699  7223 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I1003 11:14:31.009392  7223 solver.cpp:218] Iteration 38800 (7.01528 iter/s, 14.2546s/100 iters), loss = 0.329243
I1003 11:14:31.009423  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329243 (* 1 = 0.329243 loss)
I1003 11:14:31.009428  7223 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I1003 11:14:45.260176  7223 solver.cpp:218] Iteration 38900 (7.0172 iter/s, 14.2507s/100 iters), loss = 0.277404
I1003 11:14:45.260208  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277403 (* 1 = 0.277403 loss)
I1003 11:14:45.260215  7223 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I1003 11:14:58.817005  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:14:59.386873  7223 solver.cpp:330] Iteration 39000, Testing net (#0)
I1003 11:15:02.755973  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:15:02.896119  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8203
I1003 11:15:02.896154  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.542877 (* 1 = 0.542877 loss)
I1003 11:15:03.037263  7223 solver.cpp:218] Iteration 39000 (5.62525 iter/s, 17.777s/100 iters), loss = 0.187411
I1003 11:15:03.037297  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18741 (* 1 = 0.18741 loss)
I1003 11:15:03.037304  7223 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I1003 11:15:17.290485  7223 solver.cpp:218] Iteration 39100 (7.01599 iter/s, 14.2531s/100 iters), loss = 0.24815
I1003 11:15:17.290518  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24815 (* 1 = 0.24815 loss)
I1003 11:15:17.290526  7223 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I1003 11:15:31.538640  7223 solver.cpp:218] Iteration 39200 (7.01849 iter/s, 14.2481s/100 iters), loss = 0.294287
I1003 11:15:31.538779  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294286 (* 1 = 0.294286 loss)
I1003 11:15:31.538796  7223 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I1003 11:15:45.795274  7223 solver.cpp:218] Iteration 39300 (7.01436 iter/s, 14.2565s/100 iters), loss = 0.385303
I1003 11:15:45.795306  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.385303 (* 1 = 0.385303 loss)
I1003 11:15:45.795313  7223 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I1003 11:16:00.054764  7223 solver.cpp:218] Iteration 39400 (7.01291 iter/s, 14.2594s/100 iters), loss = 0.323626
I1003 11:16:00.054795  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323625 (* 1 = 0.323625 loss)
I1003 11:16:00.054801  7223 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I1003 11:16:13.586969  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:16:14.162760  7223 solver.cpp:330] Iteration 39500, Testing net (#0)
I1003 11:16:17.527634  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:16:17.667265  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7864
I1003 11:16:17.667301  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.650502 (* 1 = 0.650502 loss)
I1003 11:16:17.808701  7223 solver.cpp:218] Iteration 39500 (5.63258 iter/s, 17.7539s/100 iters), loss = 0.249876
I1003 11:16:17.808730  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249875 (* 1 = 0.249875 loss)
I1003 11:16:17.808737  7223 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I1003 11:16:32.073480  7223 solver.cpp:218] Iteration 39600 (7.01031 iter/s, 14.2647s/100 iters), loss = 0.346048
I1003 11:16:32.073510  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.346047 (* 1 = 0.346047 loss)
I1003 11:16:32.073518  7223 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I1003 11:16:46.335283  7223 solver.cpp:218] Iteration 39700 (7.01177 iter/s, 14.2617s/100 iters), loss = 0.300882
I1003 11:16:46.335423  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300881 (* 1 = 0.300881 loss)
I1003 11:16:46.335433  7223 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I1003 11:17:00.591626  7223 solver.cpp:218] Iteration 39800 (7.01451 iter/s, 14.2562s/100 iters), loss = 0.260937
I1003 11:17:00.591660  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260936 (* 1 = 0.260936 loss)
I1003 11:17:00.591666  7223 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I1003 11:17:14.853273  7223 solver.cpp:218] Iteration 39900 (7.01185 iter/s, 14.2616s/100 iters), loss = 0.250152
I1003 11:17:14.853314  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250151 (* 1 = 0.250151 loss)
I1003 11:17:14.853320  7223 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I1003 11:17:28.395666  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:17:28.974786  7223 solver.cpp:330] Iteration 40000, Testing net (#0)
I1003 11:17:32.343466  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:17:32.483320  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8013
I1003 11:17:32.483356  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.59783 (* 1 = 0.59783 loss)
I1003 11:17:32.624658  7223 solver.cpp:218] Iteration 40000 (5.62705 iter/s, 17.7713s/100 iters), loss = 0.221743
I1003 11:17:32.624688  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221743 (* 1 = 0.221743 loss)
I1003 11:17:32.624694  7223 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I1003 11:17:32.624697  7223 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I1003 11:17:46.875401  7223 solver.cpp:218] Iteration 40100 (7.01721 iter/s, 14.2507s/100 iters), loss = 0.22231
I1003 11:17:46.875448  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22231 (* 1 = 0.22231 loss)
I1003 11:17:46.875457  7223 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I1003 11:18:01.121356  7223 solver.cpp:218] Iteration 40200 (7.0196 iter/s, 14.2458s/100 iters), loss = 0.174484
I1003 11:18:01.121529  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174484 (* 1 = 0.174484 loss)
I1003 11:18:01.121548  7223 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I1003 11:18:15.380043  7223 solver.cpp:218] Iteration 40300 (7.01338 iter/s, 14.2585s/100 iters), loss = 0.314798
I1003 11:18:15.380072  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314797 (* 1 = 0.314797 loss)
I1003 11:18:15.380079  7223 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I1003 11:18:29.630336  7223 solver.cpp:218] Iteration 40400 (7.01744 iter/s, 14.2502s/100 iters), loss = 0.149743
I1003 11:18:29.630367  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149742 (* 1 = 0.149742 loss)
I1003 11:18:29.630373  7223 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I1003 11:18:43.167210  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:18:43.740553  7223 solver.cpp:330] Iteration 40500, Testing net (#0)
I1003 11:18:47.115345  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:18:47.254845  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8644
I1003 11:18:47.254871  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.394492 (* 1 = 0.394492 loss)
I1003 11:18:47.396095  7223 solver.cpp:218] Iteration 40500 (5.62883 iter/s, 17.7657s/100 iters), loss = 0.134314
I1003 11:18:47.396129  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134314 (* 1 = 0.134314 loss)
I1003 11:18:47.396136  7223 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I1003 11:19:01.645124  7223 solver.cpp:218] Iteration 40600 (7.01806 iter/s, 14.249s/100 iters), loss = 0.164044
I1003 11:19:01.645160  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164043 (* 1 = 0.164043 loss)
I1003 11:19:01.645167  7223 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I1003 11:19:15.902844  7223 solver.cpp:218] Iteration 40700 (7.01378 iter/s, 14.2576s/100 iters), loss = 0.232948
I1003 11:19:15.902950  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232947 (* 1 = 0.232947 loss)
I1003 11:19:15.902957  7223 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I1003 11:19:30.159080  7223 solver.cpp:218] Iteration 40800 (7.01455 iter/s, 14.2561s/100 iters), loss = 0.200134
I1003 11:19:30.159112  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200134 (* 1 = 0.200134 loss)
I1003 11:19:30.159119  7223 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I1003 11:19:44.412931  7223 solver.cpp:218] Iteration 40900 (7.01568 iter/s, 14.2538s/100 iters), loss = 0.142636
I1003 11:19:44.412962  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142635 (* 1 = 0.142635 loss)
I1003 11:19:44.412969  7223 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I1003 11:19:57.957702  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:19:58.526187  7223 solver.cpp:330] Iteration 41000, Testing net (#0)
I1003 11:20:01.903570  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:20:02.043601  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8584
I1003 11:20:02.043637  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.411726 (* 1 = 0.411726 loss)
I1003 11:20:02.185019  7223 solver.cpp:218] Iteration 41000 (5.62683 iter/s, 17.772s/100 iters), loss = 0.133764
I1003 11:20:02.185058  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133763 (* 1 = 0.133763 loss)
I1003 11:20:02.185065  7223 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I1003 11:20:16.423378  7223 solver.cpp:218] Iteration 41100 (7.02332 iter/s, 14.2383s/100 iters), loss = 0.178495
I1003 11:20:16.423408  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178494 (* 1 = 0.178494 loss)
I1003 11:20:16.423414  7223 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I1003 11:20:30.688143  7223 solver.cpp:218] Iteration 41200 (7.01032 iter/s, 14.2647s/100 iters), loss = 0.217585
I1003 11:20:30.688319  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217584 (* 1 = 0.217584 loss)
I1003 11:20:30.688329  7223 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I1003 11:20:44.950798  7223 solver.cpp:218] Iteration 41300 (7.01142 iter/s, 14.2624s/100 iters), loss = 0.171495
I1003 11:20:44.950840  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171494 (* 1 = 0.171494 loss)
I1003 11:20:44.950847  7223 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I1003 11:20:59.201964  7223 solver.cpp:218] Iteration 41400 (7.01701 iter/s, 14.2511s/100 iters), loss = 0.140116
I1003 11:20:59.201997  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140115 (* 1 = 0.140115 loss)
I1003 11:20:59.202003  7223 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I1003 11:21:12.753867  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:21:13.321141  7223 solver.cpp:330] Iteration 41500, Testing net (#0)
I1003 11:21:16.693135  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:21:16.837728  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8687
I1003 11:21:16.837754  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.389745 (* 1 = 0.389745 loss)
I1003 11:21:16.979959  7223 solver.cpp:218] Iteration 41500 (5.62496 iter/s, 17.7779s/100 iters), loss = 0.0805246
I1003 11:21:16.979995  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0805238 (* 1 = 0.0805238 loss)
I1003 11:21:16.980003  7223 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I1003 11:21:31.235113  7223 solver.cpp:218] Iteration 41600 (7.01504 iter/s, 14.2551s/100 iters), loss = 0.199848
I1003 11:21:31.235154  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199847 (* 1 = 0.199847 loss)
I1003 11:21:31.235162  7223 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I1003 11:21:45.497468  7223 solver.cpp:218] Iteration 41700 (7.01151 iter/s, 14.2623s/100 iters), loss = 0.150753
I1003 11:21:45.497561  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.150752 (* 1 = 0.150752 loss)
I1003 11:21:45.497578  7223 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I1003 11:21:59.758401  7223 solver.cpp:218] Iteration 41800 (7.01223 iter/s, 14.2608s/100 iters), loss = 0.15857
I1003 11:21:59.758443  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15857 (* 1 = 0.15857 loss)
I1003 11:21:59.758450  7223 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I1003 11:22:14.024067  7223 solver.cpp:218] Iteration 41900 (7.00988 iter/s, 14.2656s/100 iters), loss = 0.142051
I1003 11:22:14.024111  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14205 (* 1 = 0.14205 loss)
I1003 11:22:14.024118  7223 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I1003 11:22:27.570994  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:22:28.139066  7223 solver.cpp:330] Iteration 42000, Testing net (#0)
I1003 11:22:31.503767  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:22:31.645542  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8764
I1003 11:22:31.645578  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.363532 (* 1 = 0.363532 loss)
I1003 11:22:31.789448  7223 solver.cpp:218] Iteration 42000 (5.62896 iter/s, 17.7653s/100 iters), loss = 0.119838
I1003 11:22:31.789499  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119837 (* 1 = 0.119837 loss)
I1003 11:22:31.789505  7223 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I1003 11:22:46.039489  7223 solver.cpp:218] Iteration 42100 (7.01759 iter/s, 14.2499s/100 iters), loss = 0.174692
I1003 11:22:46.039535  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174691 (* 1 = 0.174691 loss)
I1003 11:22:46.039543  7223 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I1003 11:23:00.310638  7223 solver.cpp:218] Iteration 42200 (7.00719 iter/s, 14.2711s/100 iters), loss = 0.176741
I1003 11:23:00.310762  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17674 (* 1 = 0.17674 loss)
I1003 11:23:00.310771  7223 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I1003 11:23:14.583109  7223 solver.cpp:218] Iteration 42300 (7.00658 iter/s, 14.2723s/100 iters), loss = 0.151253
I1003 11:23:14.583150  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151253 (* 1 = 0.151253 loss)
I1003 11:23:14.583156  7223 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I1003 11:23:28.834452  7223 solver.cpp:218] Iteration 42400 (7.01693 iter/s, 14.2513s/100 iters), loss = 0.162173
I1003 11:23:28.834488  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162172 (* 1 = 0.162172 loss)
I1003 11:23:28.834496  7223 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I1003 11:23:42.384898  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:23:42.952908  7223 solver.cpp:330] Iteration 42500, Testing net (#0)
I1003 11:23:46.323463  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:23:46.463413  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8679
I1003 11:23:46.463448  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.385531 (* 1 = 0.385531 loss)
I1003 11:23:46.604404  7223 solver.cpp:218] Iteration 42500 (5.62751 iter/s, 17.7699s/100 iters), loss = 0.146385
I1003 11:23:46.604434  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146385 (* 1 = 0.146385 loss)
I1003 11:23:46.604441  7223 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I1003 11:24:00.872786  7223 solver.cpp:218] Iteration 42600 (7.00854 iter/s, 14.2683s/100 iters), loss = 0.126005
I1003 11:24:00.872828  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126004 (* 1 = 0.126004 loss)
I1003 11:24:00.872834  7223 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I1003 11:24:15.132148  7223 solver.cpp:218] Iteration 42700 (7.01298 iter/s, 14.2593s/100 iters), loss = 0.165974
I1003 11:24:15.132251  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165973 (* 1 = 0.165973 loss)
I1003 11:24:15.132267  7223 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I1003 11:24:29.396277  7223 solver.cpp:218] Iteration 42800 (7.01066 iter/s, 14.264s/100 iters), loss = 0.163971
I1003 11:24:29.396308  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16397 (* 1 = 0.16397 loss)
I1003 11:24:29.396314  7223 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I1003 11:24:43.659274  7223 solver.cpp:218] Iteration 42900 (7.01119 iter/s, 14.2629s/100 iters), loss = 0.0924791
I1003 11:24:43.659309  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0924782 (* 1 = 0.0924782 loss)
I1003 11:24:43.659315  7223 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I1003 11:24:57.212975  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:24:57.783033  7223 solver.cpp:330] Iteration 43000, Testing net (#0)
I1003 11:25:01.148125  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:25:01.288179  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.872
I1003 11:25:01.288214  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.379686 (* 1 = 0.379686 loss)
I1003 11:25:01.428814  7223 solver.cpp:218] Iteration 43000 (5.62764 iter/s, 17.7695s/100 iters), loss = 0.0965996
I1003 11:25:01.428843  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0965988 (* 1 = 0.0965988 loss)
I1003 11:25:01.428848  7223 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I1003 11:25:15.679946  7223 solver.cpp:218] Iteration 43100 (7.01702 iter/s, 14.2511s/100 iters), loss = 0.151201
I1003 11:25:15.679978  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1512 (* 1 = 0.1512 loss)
I1003 11:25:15.679985  7223 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I1003 11:25:29.937377  7223 solver.cpp:218] Iteration 43200 (7.01393 iter/s, 14.2573s/100 iters), loss = 0.0860155
I1003 11:25:29.937505  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0860146 (* 1 = 0.0860146 loss)
I1003 11:25:29.937511  7223 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I1003 11:25:44.186781  7223 solver.cpp:218] Iteration 43300 (7.01792 iter/s, 14.2492s/100 iters), loss = 0.161463
I1003 11:25:44.186815  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161462 (* 1 = 0.161462 loss)
I1003 11:25:44.186821  7223 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I1003 11:25:58.437249  7223 solver.cpp:218] Iteration 43400 (7.01735 iter/s, 14.2504s/100 iters), loss = 0.0821992
I1003 11:25:58.437290  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0821984 (* 1 = 0.0821984 loss)
I1003 11:25:58.437296  7223 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I1003 11:26:11.996273  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:26:12.564894  7223 solver.cpp:330] Iteration 43500, Testing net (#0)
I1003 11:26:15.933446  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:26:16.073709  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8705
I1003 11:26:16.073745  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.386994 (* 1 = 0.386994 loss)
I1003 11:26:16.213840  7223 solver.cpp:218] Iteration 43500 (5.62541 iter/s, 17.7765s/100 iters), loss = 0.0762766
I1003 11:26:16.213873  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0762758 (* 1 = 0.0762758 loss)
I1003 11:26:16.213881  7223 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I1003 11:26:30.483952  7223 solver.cpp:218] Iteration 43600 (7.00771 iter/s, 14.27s/100 iters), loss = 0.139758
I1003 11:26:30.483994  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139758 (* 1 = 0.139758 loss)
I1003 11:26:30.484000  7223 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I1003 11:26:44.742115  7223 solver.cpp:218] Iteration 43700 (7.01357 iter/s, 14.2581s/100 iters), loss = 0.163215
I1003 11:26:44.742220  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163214 (* 1 = 0.163214 loss)
I1003 11:26:44.742238  7223 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I1003 11:26:59.012612  7223 solver.cpp:218] Iteration 43800 (7.00754 iter/s, 14.2703s/100 iters), loss = 0.145742
I1003 11:26:59.012655  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145742 (* 1 = 0.145742 loss)
I1003 11:26:59.012663  7223 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I1003 11:27:13.269729  7223 solver.cpp:218] Iteration 43900 (7.01408 iter/s, 14.257s/100 iters), loss = 0.138046
I1003 11:27:13.269762  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.138045 (* 1 = 0.138045 loss)
I1003 11:27:13.269768  7223 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I1003 11:27:26.819363  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:27:27.388337  7223 solver.cpp:330] Iteration 44000, Testing net (#0)
I1003 11:27:30.753099  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:27:30.892608  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8776
I1003 11:27:30.892644  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.359784 (* 1 = 0.359784 loss)
I1003 11:27:31.033495  7223 solver.cpp:218] Iteration 44000 (5.62946 iter/s, 17.7637s/100 iters), loss = 0.10252
I1003 11:27:31.033526  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102519 (* 1 = 0.102519 loss)
I1003 11:27:31.033534  7223 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I1003 11:27:45.308398  7223 solver.cpp:218] Iteration 44100 (7.00534 iter/s, 14.2748s/100 iters), loss = 0.0629958
I1003 11:27:45.308439  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.062995 (* 1 = 0.062995 loss)
I1003 11:27:45.308446  7223 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I1003 11:27:59.580855  7223 solver.cpp:218] Iteration 44200 (7.00654 iter/s, 14.2724s/100 iters), loss = 0.0943004
I1003 11:27:59.581012  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0942995 (* 1 = 0.0942995 loss)
I1003 11:27:59.581022  7223 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I1003 11:28:13.840258  7223 solver.cpp:218] Iteration 44300 (7.01301 iter/s, 14.2592s/100 iters), loss = 0.105991
I1003 11:28:13.840296  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10599 (* 1 = 0.10599 loss)
I1003 11:28:13.840306  7223 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I1003 11:28:28.102599  7223 solver.cpp:218] Iteration 44400 (7.01151 iter/s, 14.2623s/100 iters), loss = 0.157486
I1003 11:28:28.102629  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157486 (* 1 = 0.157486 loss)
I1003 11:28:28.102635  7223 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I1003 11:28:41.672181  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:28:42.240838  7223 solver.cpp:330] Iteration 44500, Testing net (#0)
I1003 11:28:45.609235  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:28:45.749583  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8821
I1003 11:28:45.749619  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.351591 (* 1 = 0.351591 loss)
I1003 11:28:45.890067  7223 solver.cpp:218] Iteration 44500 (5.62196 iter/s, 17.7874s/100 iters), loss = 0.0572391
I1003 11:28:45.890100  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0572384 (* 1 = 0.0572384 loss)
I1003 11:28:45.890108  7223 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I1003 11:29:00.138227  7223 solver.cpp:218] Iteration 44600 (7.0185 iter/s, 14.2481s/100 iters), loss = 0.0907929
I1003 11:29:00.138258  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0907922 (* 1 = 0.0907922 loss)
I1003 11:29:00.138264  7223 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I1003 11:29:14.391191  7223 solver.cpp:218] Iteration 44700 (7.01612 iter/s, 14.2529s/100 iters), loss = 0.128481
I1003 11:29:14.391324  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12848 (* 1 = 0.12848 loss)
I1003 11:29:14.391332  7223 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I1003 11:29:28.646001  7223 solver.cpp:218] Iteration 44800 (7.01526 iter/s, 14.2546s/100 iters), loss = 0.125086
I1003 11:29:28.646044  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.125085 (* 1 = 0.125085 loss)
I1003 11:29:28.646050  7223 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I1003 11:29:42.903018  7223 solver.cpp:218] Iteration 44900 (7.01413 iter/s, 14.2569s/100 iters), loss = 0.118716
I1003 11:29:42.903060  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.118715 (* 1 = 0.118715 loss)
I1003 11:29:42.903066  7223 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I1003 11:29:56.453687  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:29:57.022475  7223 solver.cpp:330] Iteration 45000, Testing net (#0)
I1003 11:30:00.393941  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:30:00.534052  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8802
I1003 11:30:00.534080  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37168 (* 1 = 0.37168 loss)
I1003 11:30:00.675500  7223 solver.cpp:218] Iteration 45000 (5.62671 iter/s, 17.7724s/100 iters), loss = 0.0667103
I1003 11:30:00.675529  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0667095 (* 1 = 0.0667095 loss)
I1003 11:30:00.675536  7223 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I1003 11:30:14.938998  7223 solver.cpp:218] Iteration 45100 (7.01094 iter/s, 14.2634s/100 iters), loss = 0.109566
I1003 11:30:14.939038  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.109565 (* 1 = 0.109565 loss)
I1003 11:30:14.939044  7223 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I1003 11:30:29.194854  7223 solver.cpp:218] Iteration 45200 (7.0147 iter/s, 14.2558s/100 iters), loss = 0.11202
I1003 11:30:29.194974  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.112019 (* 1 = 0.112019 loss)
I1003 11:30:29.194991  7223 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I1003 11:30:43.444454  7223 solver.cpp:218] Iteration 45300 (7.01782 iter/s, 14.2494s/100 iters), loss = 0.120845
I1003 11:30:43.444495  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120845 (* 1 = 0.120845 loss)
I1003 11:30:43.444501  7223 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I1003 11:30:57.708324  7223 solver.cpp:218] Iteration 45400 (7.01076 iter/s, 14.2638s/100 iters), loss = 0.0820202
I1003 11:30:57.708369  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0820194 (* 1 = 0.0820194 loss)
I1003 11:30:57.708375  7223 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I1003 11:31:11.271824  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:31:11.840486  7223 solver.cpp:330] Iteration 45500, Testing net (#0)
I1003 11:31:15.205127  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:31:15.345212  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.879
I1003 11:31:15.345247  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367846 (* 1 = 0.367846 loss)
I1003 11:31:15.486058  7223 solver.cpp:218] Iteration 45500 (5.62504 iter/s, 17.7776s/100 iters), loss = 0.070507
I1003 11:31:15.486093  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0705063 (* 1 = 0.0705063 loss)
I1003 11:31:15.486099  7223 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I1003 11:31:29.728376  7223 solver.cpp:218] Iteration 45600 (7.02137 iter/s, 14.2422s/100 iters), loss = 0.0965306
I1003 11:31:29.728407  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0965298 (* 1 = 0.0965298 loss)
I1003 11:31:29.728412  7223 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I1003 11:31:43.988013  7223 solver.cpp:218] Iteration 45700 (7.01284 iter/s, 14.2596s/100 iters), loss = 0.152385
I1003 11:31:43.988157  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152384 (* 1 = 0.152384 loss)
I1003 11:31:43.988165  7223 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I1003 11:31:58.234112  7223 solver.cpp:218] Iteration 45800 (7.01956 iter/s, 14.2459s/100 iters), loss = 0.161078
I1003 11:31:58.234141  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161077 (* 1 = 0.161077 loss)
I1003 11:31:58.234148  7223 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I1003 11:32:12.475188  7223 solver.cpp:218] Iteration 45900 (7.02198 iter/s, 14.241s/100 iters), loss = 0.104158
I1003 11:32:12.475221  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.104157 (* 1 = 0.104157 loss)
I1003 11:32:12.475227  7223 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I1003 11:32:26.018340  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:32:26.586479  7223 solver.cpp:330] Iteration 46000, Testing net (#0)
I1003 11:32:29.955332  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:32:30.094876  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8813
I1003 11:32:30.094899  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370805 (* 1 = 0.370805 loss)
I1003 11:32:30.236172  7223 solver.cpp:218] Iteration 46000 (5.63035 iter/s, 17.7609s/100 iters), loss = 0.0931001
I1003 11:32:30.236281  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0930993 (* 1 = 0.0930993 loss)
I1003 11:32:30.236292  7223 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I1003 11:32:44.494597  7223 solver.cpp:218] Iteration 46100 (7.01348 iter/s, 14.2582s/100 iters), loss = 0.137773
I1003 11:32:44.494629  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.137772 (* 1 = 0.137772 loss)
I1003 11:32:44.494635  7223 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I1003 11:32:58.737143  7223 solver.cpp:218] Iteration 46200 (7.02125 iter/s, 14.2425s/100 iters), loss = 0.189364
I1003 11:32:58.737289  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189363 (* 1 = 0.189363 loss)
I1003 11:32:58.737298  7223 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I1003 11:33:12.998998  7223 solver.cpp:218] Iteration 46300 (7.0118 iter/s, 14.2617s/100 iters), loss = 0.128062
I1003 11:33:12.999028  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128062 (* 1 = 0.128062 loss)
I1003 11:33:12.999034  7223 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I1003 11:33:27.261705  7223 solver.cpp:218] Iteration 46400 (7.01133 iter/s, 14.2626s/100 iters), loss = 0.148227
I1003 11:33:27.261737  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148226 (* 1 = 0.148226 loss)
I1003 11:33:27.261744  7223 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I1003 11:33:40.814661  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:33:41.386673  7223 solver.cpp:330] Iteration 46500, Testing net (#0)
I1003 11:33:44.750949  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:33:44.890823  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8878
I1003 11:33:44.890858  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.342882 (* 1 = 0.342882 loss)
I1003 11:33:45.030894  7223 solver.cpp:218] Iteration 46500 (5.62775 iter/s, 17.7691s/100 iters), loss = 0.101997
I1003 11:33:45.030941  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.101996 (* 1 = 0.101996 loss)
I1003 11:33:45.030958  7223 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I1003 11:33:59.287029  7223 solver.cpp:218] Iteration 46600 (7.01459 iter/s, 14.256s/100 iters), loss = 0.0982007
I1003 11:33:59.287070  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0982 (* 1 = 0.0982 loss)
I1003 11:33:59.287077  7223 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I1003 11:34:13.538311  7223 solver.cpp:218] Iteration 46700 (7.01695 iter/s, 14.2512s/100 iters), loss = 0.158149
I1003 11:34:13.538452  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158149 (* 1 = 0.158149 loss)
I1003 11:34:13.538460  7223 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I1003 11:34:27.792724  7223 solver.cpp:218] Iteration 46800 (7.01546 iter/s, 14.2542s/100 iters), loss = 0.105924
I1003 11:34:27.792757  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.105923 (* 1 = 0.105923 loss)
I1003 11:34:27.792763  7223 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I1003 11:34:42.035791  7223 solver.cpp:218] Iteration 46900 (7.021 iter/s, 14.243s/100 iters), loss = 0.0794722
I1003 11:34:42.035821  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0794714 (* 1 = 0.0794714 loss)
I1003 11:34:42.035827  7223 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I1003 11:34:55.578418  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:34:56.157634  7223 solver.cpp:330] Iteration 47000, Testing net (#0)
I1003 11:34:59.526316  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:34:59.665968  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8893
I1003 11:34:59.665994  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34836 (* 1 = 0.34836 loss)
I1003 11:34:59.807356  7223 solver.cpp:218] Iteration 47000 (5.62699 iter/s, 17.7715s/100 iters), loss = 0.0648065
I1003 11:34:59.807385  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0648057 (* 1 = 0.0648057 loss)
I1003 11:34:59.807394  7223 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I1003 11:35:14.047314  7223 solver.cpp:218] Iteration 47100 (7.02253 iter/s, 14.2399s/100 iters), loss = 0.117024
I1003 11:35:14.047350  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.117023 (* 1 = 0.117023 loss)
I1003 11:35:14.047358  7223 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I1003 11:35:28.279350  7223 solver.cpp:218] Iteration 47200 (7.02644 iter/s, 14.232s/100 iters), loss = 0.107297
I1003 11:35:28.279464  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.107296 (* 1 = 0.107296 loss)
I1003 11:35:28.279480  7223 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I1003 11:35:42.521136  7223 solver.cpp:218] Iteration 47300 (7.02166 iter/s, 14.2416s/100 iters), loss = 0.108812
I1003 11:35:42.521180  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.108812 (* 1 = 0.108812 loss)
I1003 11:35:42.521188  7223 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I1003 11:35:56.769299  7223 solver.cpp:218] Iteration 47400 (7.01849 iter/s, 14.2481s/100 iters), loss = 0.058205
I1003 11:35:56.769328  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0582042 (* 1 = 0.0582042 loss)
I1003 11:35:56.769335  7223 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I1003 11:36:10.296872  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:36:10.867426  7223 solver.cpp:330] Iteration 47500, Testing net (#0)
I1003 11:36:14.236757  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:36:14.376807  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8867
I1003 11:36:14.376844  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.345443 (* 1 = 0.345443 loss)
I1003 11:36:14.517351  7223 solver.cpp:218] Iteration 47500 (5.63445 iter/s, 17.748s/100 iters), loss = 0.106273
I1003 11:36:14.517385  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106272 (* 1 = 0.106272 loss)
I1003 11:36:14.517391  7223 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I1003 11:36:28.773409  7223 solver.cpp:218] Iteration 47600 (7.01469 iter/s, 14.2558s/100 iters), loss = 0.0919603
I1003 11:36:28.773463  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0919595 (* 1 = 0.0919595 loss)
I1003 11:36:28.773483  7223 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I1003 11:36:43.042296  7223 solver.cpp:218] Iteration 47700 (7.00832 iter/s, 14.2688s/100 iters), loss = 0.128101
I1003 11:36:43.042387  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1281 (* 1 = 0.1281 loss)
I1003 11:36:43.042394  7223 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I1003 11:36:57.310729  7223 solver.cpp:218] Iteration 47800 (7.00855 iter/s, 14.2683s/100 iters), loss = 0.0987772
I1003 11:36:57.310772  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0987763 (* 1 = 0.0987763 loss)
I1003 11:36:57.310780  7223 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I1003 11:37:11.574165  7223 solver.cpp:218] Iteration 47900 (7.01098 iter/s, 14.2633s/100 iters), loss = 0.0572718
I1003 11:37:11.574208  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.057271 (* 1 = 0.057271 loss)
I1003 11:37:11.574214  7223 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I1003 11:37:25.136221  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:37:25.705435  7223 solver.cpp:330] Iteration 48000, Testing net (#0)
I1003 11:37:29.083475  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:37:29.223381  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8949
I1003 11:37:29.223407  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33563 (* 1 = 0.33563 loss)
I1003 11:37:29.364569  7223 solver.cpp:218] Iteration 48000 (5.62104 iter/s, 17.7903s/100 iters), loss = 0.0716414
I1003 11:37:29.364603  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0716406 (* 1 = 0.0716406 loss)
I1003 11:37:29.364610  7223 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I1003 11:37:43.619490  7223 solver.cpp:218] Iteration 48100 (7.01516 iter/s, 14.2548s/100 iters), loss = 0.0679245
I1003 11:37:43.619530  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0679237 (* 1 = 0.0679237 loss)
I1003 11:37:43.619536  7223 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I1003 11:37:57.884040  7223 solver.cpp:218] Iteration 48200 (7.01043 iter/s, 14.2645s/100 iters), loss = 0.104501
I1003 11:37:57.884177  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1045 (* 1 = 0.1045 loss)
I1003 11:37:57.884186  7223 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I1003 11:38:12.157439  7223 solver.cpp:218] Iteration 48300 (7.00613 iter/s, 14.2732s/100 iters), loss = 0.120824
I1003 11:38:12.157481  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120823 (* 1 = 0.120823 loss)
I1003 11:38:12.157487  7223 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I1003 11:38:26.416695  7223 solver.cpp:218] Iteration 48400 (7.01303 iter/s, 14.2592s/100 iters), loss = 0.0737404
I1003 11:38:26.416738  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0737396 (* 1 = 0.0737396 loss)
I1003 11:38:26.416743  7223 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I1003 11:38:39.960362  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:38:40.528389  7223 solver.cpp:330] Iteration 48500, Testing net (#0)
I1003 11:38:43.900511  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:38:44.042311  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8918
I1003 11:38:44.042347  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338349 (* 1 = 0.338349 loss)
I1003 11:38:44.183295  7223 solver.cpp:218] Iteration 48500 (5.62857 iter/s, 17.7665s/100 iters), loss = 0.121087
I1003 11:38:44.183329  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.121087 (* 1 = 0.121087 loss)
I1003 11:38:44.183336  7223 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I1003 11:38:58.437438  7223 solver.cpp:218] Iteration 48600 (7.01554 iter/s, 14.2541s/100 iters), loss = 0.119679
I1003 11:38:58.437469  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119678 (* 1 = 0.119678 loss)
I1003 11:38:58.437475  7223 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I1003 11:39:12.701915  7223 solver.cpp:218] Iteration 48700 (7.01046 iter/s, 14.2644s/100 iters), loss = 0.130571
I1003 11:39:12.702054  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.130571 (* 1 = 0.130571 loss)
I1003 11:39:12.702061  7223 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I1003 11:39:26.958875  7223 solver.cpp:218] Iteration 48800 (7.0142 iter/s, 14.2568s/100 iters), loss = 0.0581051
I1003 11:39:26.958915  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0581044 (* 1 = 0.0581044 loss)
I1003 11:39:26.958921  7223 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I1003 11:39:41.217020  7223 solver.cpp:218] Iteration 48900 (7.01358 iter/s, 14.2581s/100 iters), loss = 0.108935
I1003 11:39:41.217061  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.108934 (* 1 = 0.108934 loss)
I1003 11:39:41.217068  7223 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I1003 11:39:54.773718  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:39:55.342464  7223 solver.cpp:330] Iteration 49000, Testing net (#0)
I1003 11:39:58.710746  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:39:58.856518  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.885
I1003 11:39:58.856545  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364238 (* 1 = 0.364238 loss)
I1003 11:39:59.000658  7223 solver.cpp:218] Iteration 49000 (5.62318 iter/s, 17.7835s/100 iters), loss = 0.0944351
I1003 11:39:59.000705  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0944344 (* 1 = 0.0944344 loss)
I1003 11:39:59.000712  7223 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I1003 11:40:13.245448  7223 solver.cpp:218] Iteration 49100 (7.02017 iter/s, 14.2447s/100 iters), loss = 0.084253
I1003 11:40:13.245481  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0842523 (* 1 = 0.0842523 loss)
I1003 11:40:13.245488  7223 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I1003 11:40:27.503638  7223 solver.cpp:218] Iteration 49200 (7.01355 iter/s, 14.2581s/100 iters), loss = 0.11772
I1003 11:40:27.503762  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.117719 (* 1 = 0.117719 loss)
I1003 11:40:27.503780  7223 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I1003 11:40:41.762814  7223 solver.cpp:218] Iteration 49300 (7.01311 iter/s, 14.259s/100 iters), loss = 0.0669071
I1003 11:40:41.762845  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0669063 (* 1 = 0.0669063 loss)
I1003 11:40:41.762850  7223 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I1003 11:40:56.016515  7223 solver.cpp:218] Iteration 49400 (7.01576 iter/s, 14.2536s/100 iters), loss = 0.0850655
I1003 11:40:56.016551  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0850647 (* 1 = 0.0850647 loss)
I1003 11:40:56.016558  7223 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I1003 11:41:09.557312  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:41:10.125944  7223 solver.cpp:330] Iteration 49500, Testing net (#0)
I1003 11:41:13.492156  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:41:13.632501  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8949
I1003 11:41:13.632536  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334384 (* 1 = 0.334384 loss)
I1003 11:41:13.775055  7223 solver.cpp:218] Iteration 49500 (5.63113 iter/s, 17.7584s/100 iters), loss = 0.0538515
I1003 11:41:13.775092  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0538508 (* 1 = 0.0538508 loss)
I1003 11:41:13.775100  7223 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I1003 11:41:28.014777  7223 solver.cpp:218] Iteration 49600 (7.02265 iter/s, 14.2396s/100 iters), loss = 0.101705
I1003 11:41:28.014818  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.101705 (* 1 = 0.101705 loss)
I1003 11:41:28.014824  7223 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I1003 11:41:42.266535  7223 solver.cpp:218] Iteration 49700 (7.01672 iter/s, 14.2517s/100 iters), loss = 0.0628418
I1003 11:41:42.266664  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.062841 (* 1 = 0.062841 loss)
I1003 11:41:42.266672  7223 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I1003 11:41:56.514691  7223 solver.cpp:218] Iteration 49800 (7.01854 iter/s, 14.248s/100 iters), loss = 0.141618
I1003 11:41:56.514724  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.141617 (* 1 = 0.141617 loss)
I1003 11:41:56.514732  7223 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I1003 11:42:10.756611  7223 solver.cpp:218] Iteration 49900 (7.02156 iter/s, 14.2418s/100 iters), loss = 0.0809714
I1003 11:42:10.756646  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0809707 (* 1 = 0.0809707 loss)
I1003 11:42:10.756664  7223 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I1003 11:42:24.300988  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:42:24.869465  7223 solver.cpp:330] Iteration 50000, Testing net (#0)
I1003 11:42:28.233507  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:42:28.373636  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8928
I1003 11:42:28.373672  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348816 (* 1 = 0.348816 loss)
I1003 11:42:28.514127  7223 solver.cpp:218] Iteration 50000 (5.63146 iter/s, 17.7574s/100 iters), loss = 0.0721718
I1003 11:42:28.514155  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0721711 (* 1 = 0.0721711 loss)
I1003 11:42:28.514163  7223 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I1003 11:42:42.762512  7223 solver.cpp:218] Iteration 50100 (7.01837 iter/s, 14.2483s/100 iters), loss = 0.103778
I1003 11:42:42.762547  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103777 (* 1 = 0.103777 loss)
I1003 11:42:42.762553  7223 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I1003 11:42:57.021044  7223 solver.cpp:218] Iteration 50200 (7.01338 iter/s, 14.2585s/100 iters), loss = 0.0866309
I1003 11:42:57.021167  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0866302 (* 1 = 0.0866302 loss)
I1003 11:42:57.021174  7223 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I1003 11:43:11.289252  7223 solver.cpp:218] Iteration 50300 (7.00867 iter/s, 14.268s/100 iters), loss = 0.0735623
I1003 11:43:11.289283  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0735616 (* 1 = 0.0735616 loss)
I1003 11:43:11.289289  7223 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I1003 11:43:25.534085  7223 solver.cpp:218] Iteration 50400 (7.02013 iter/s, 14.2448s/100 iters), loss = 0.0990786
I1003 11:43:25.534116  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0990778 (* 1 = 0.0990778 loss)
I1003 11:43:25.534123  7223 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I1003 11:43:39.093367  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:43:39.660918  7223 solver.cpp:330] Iteration 50500, Testing net (#0)
I1003 11:43:43.027549  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:43:43.167851  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8961
I1003 11:43:43.167877  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329985 (* 1 = 0.329985 loss)
I1003 11:43:43.308724  7223 solver.cpp:218] Iteration 50500 (5.62602 iter/s, 17.7746s/100 iters), loss = 0.0756253
I1003 11:43:43.308755  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0756246 (* 1 = 0.0756246 loss)
I1003 11:43:43.308763  7223 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I1003 11:43:57.560974  7223 solver.cpp:218] Iteration 50600 (7.01647 iter/s, 14.2522s/100 iters), loss = 0.0606624
I1003 11:43:57.561012  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0606617 (* 1 = 0.0606617 loss)
I1003 11:43:57.561019  7223 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I1003 11:44:11.810183  7223 solver.cpp:218] Iteration 50700 (7.01797 iter/s, 14.2491s/100 iters), loss = 0.146917
I1003 11:44:11.810298  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146917 (* 1 = 0.146917 loss)
I1003 11:44:11.810307  7223 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I1003 11:44:26.062178  7223 solver.cpp:218] Iteration 50800 (7.01664 iter/s, 14.2518s/100 iters), loss = 0.0745001
I1003 11:44:26.062216  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0744994 (* 1 = 0.0744994 loss)
I1003 11:44:26.062222  7223 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I1003 11:44:40.311542  7223 solver.cpp:218] Iteration 50900 (7.0179 iter/s, 14.2493s/100 iters), loss = 0.100531
I1003 11:44:40.311573  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10053 (* 1 = 0.10053 loss)
I1003 11:44:40.311578  7223 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I1003 11:44:53.853754  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:44:54.422130  7223 solver.cpp:330] Iteration 51000, Testing net (#0)
I1003 11:44:57.788605  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:44:57.928952  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8879
I1003 11:44:57.928978  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.356161 (* 1 = 0.356161 loss)
I1003 11:44:58.069232  7223 solver.cpp:218] Iteration 51000 (5.63139 iter/s, 17.7576s/100 iters), loss = 0.037125
I1003 11:44:58.069263  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0371243 (* 1 = 0.0371243 loss)
I1003 11:44:58.069270  7223 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I1003 11:45:12.330266  7223 solver.cpp:218] Iteration 51100 (7.01215 iter/s, 14.261s/100 iters), loss = 0.0609004
I1003 11:45:12.330299  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0608997 (* 1 = 0.0608997 loss)
I1003 11:45:12.330307  7223 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I1003 11:45:26.597079  7223 solver.cpp:218] Iteration 51200 (7.00931 iter/s, 14.2667s/100 iters), loss = 0.124932
I1003 11:45:26.597177  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.124931 (* 1 = 0.124931 loss)
I1003 11:45:26.597185  7223 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I1003 11:45:40.855124  7223 solver.cpp:218] Iteration 51300 (7.01365 iter/s, 14.2579s/100 iters), loss = 0.0946305
I1003 11:45:40.855159  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0946298 (* 1 = 0.0946298 loss)
I1003 11:45:40.855167  7223 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I1003 11:45:55.105546  7223 solver.cpp:218] Iteration 51400 (7.01737 iter/s, 14.2503s/100 iters), loss = 0.0924877
I1003 11:45:55.105577  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.092487 (* 1 = 0.092487 loss)
I1003 11:45:55.105583  7223 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I1003 11:46:08.663723  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:46:09.232692  7223 solver.cpp:330] Iteration 51500, Testing net (#0)
I1003 11:46:12.601375  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:46:12.741713  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8946
I1003 11:46:12.741749  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.341649 (* 1 = 0.341649 loss)
I1003 11:46:12.883007  7223 solver.cpp:218] Iteration 51500 (5.62513 iter/s, 17.7774s/100 iters), loss = 0.0226162
I1003 11:46:12.883038  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0226155 (* 1 = 0.0226155 loss)
I1003 11:46:12.883045  7223 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I1003 11:46:27.130226  7223 solver.cpp:218] Iteration 51600 (7.01895 iter/s, 14.2471s/100 iters), loss = 0.127588
I1003 11:46:27.130256  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127587 (* 1 = 0.127587 loss)
I1003 11:46:27.130262  7223 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I1003 11:46:41.374053  7223 solver.cpp:218] Iteration 51700 (7.02062 iter/s, 14.2438s/100 iters), loss = 0.0837321
I1003 11:46:41.374169  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0837314 (* 1 = 0.0837314 loss)
I1003 11:46:41.374188  7223 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I1003 11:46:55.625746  7223 solver.cpp:218] Iteration 51800 (7.01678 iter/s, 14.2515s/100 iters), loss = 0.0900952
I1003 11:46:55.625787  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0900945 (* 1 = 0.0900945 loss)
I1003 11:46:55.625793  7223 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I1003 11:47:09.892426  7223 solver.cpp:218] Iteration 51900 (7.00938 iter/s, 14.2666s/100 iters), loss = 0.103481
I1003 11:47:09.892470  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10348 (* 1 = 0.10348 loss)
I1003 11:47:09.892477  7223 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I1003 11:47:23.441570  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:47:24.010550  7223 solver.cpp:330] Iteration 52000, Testing net (#0)
I1003 11:47:27.377043  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:47:27.517050  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8898
I1003 11:47:27.517076  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.375862 (* 1 = 0.375862 loss)
I1003 11:47:27.657534  7223 solver.cpp:218] Iteration 52000 (5.62904 iter/s, 17.765s/100 iters), loss = 0.0686257
I1003 11:47:27.657567  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0686249 (* 1 = 0.0686249 loss)
I1003 11:47:27.657575  7223 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I1003 11:47:41.900269  7223 solver.cpp:218] Iteration 52100 (7.02116 iter/s, 14.2427s/100 iters), loss = 0.109725
I1003 11:47:41.900300  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.109724 (* 1 = 0.109724 loss)
I1003 11:47:41.900306  7223 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I1003 11:47:56.154058  7223 solver.cpp:218] Iteration 52200 (7.01571 iter/s, 14.2537s/100 iters), loss = 0.110253
I1003 11:47:56.154175  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.110253 (* 1 = 0.110253 loss)
I1003 11:47:56.154183  7223 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I1003 11:48:10.385675  7223 solver.cpp:218] Iteration 52300 (7.02668 iter/s, 14.2315s/100 iters), loss = 0.0629475
I1003 11:48:10.385704  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0629467 (* 1 = 0.0629467 loss)
I1003 11:48:10.385710  7223 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I1003 11:48:24.633584  7223 solver.cpp:218] Iteration 52400 (7.01861 iter/s, 14.2478s/100 iters), loss = 0.0791392
I1003 11:48:24.633613  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0791384 (* 1 = 0.0791384 loss)
I1003 11:48:24.633620  7223 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I1003 11:48:38.179613  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:48:38.750869  7223 solver.cpp:330] Iteration 52500, Testing net (#0)
I1003 11:48:42.120570  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:48:42.260741  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8949
I1003 11:48:42.260777  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.352868 (* 1 = 0.352868 loss)
I1003 11:48:42.401378  7223 solver.cpp:218] Iteration 52500 (5.62818 iter/s, 17.7677s/100 iters), loss = 0.0408072
I1003 11:48:42.401415  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0408065 (* 1 = 0.0408065 loss)
I1003 11:48:42.401423  7223 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I1003 11:48:56.654575  7223 solver.cpp:218] Iteration 52600 (7.01601 iter/s, 14.2531s/100 iters), loss = 0.148709
I1003 11:48:56.654618  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148708 (* 1 = 0.148708 loss)
I1003 11:48:56.654624  7223 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I1003 11:49:10.905820  7223 solver.cpp:218] Iteration 52700 (7.01697 iter/s, 14.2512s/100 iters), loss = 0.136965
I1003 11:49:10.905939  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136965 (* 1 = 0.136965 loss)
I1003 11:49:10.905959  7223 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I1003 11:49:25.168484  7223 solver.cpp:218] Iteration 52800 (7.0114 iter/s, 14.2625s/100 iters), loss = 0.0738726
I1003 11:49:25.168516  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0738717 (* 1 = 0.0738717 loss)
I1003 11:49:25.168522  7223 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I1003 11:49:39.428689  7223 solver.cpp:218] Iteration 52900 (7.01256 iter/s, 14.2601s/100 iters), loss = 0.0756712
I1003 11:49:39.428721  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0756703 (* 1 = 0.0756703 loss)
I1003 11:49:39.428738  7223 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I1003 11:49:52.972523  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:49:53.545541  7223 solver.cpp:330] Iteration 53000, Testing net (#0)
I1003 11:49:56.912194  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:49:57.052197  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8936
I1003 11:49:57.052232  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34843 (* 1 = 0.34843 loss)
I1003 11:49:57.192760  7223 solver.cpp:218] Iteration 53000 (5.62936 iter/s, 17.764s/100 iters), loss = 0.102592
I1003 11:49:57.192793  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102591 (* 1 = 0.102591 loss)
I1003 11:49:57.192800  7223 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I1003 11:50:11.449055  7223 solver.cpp:218] Iteration 53100 (7.01448 iter/s, 14.2562s/100 iters), loss = 0.091669
I1003 11:50:11.449087  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0916682 (* 1 = 0.0916682 loss)
I1003 11:50:11.449103  7223 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I1003 11:50:25.695511  7223 solver.cpp:218] Iteration 53200 (7.01932 iter/s, 14.2464s/100 iters), loss = 0.171594
I1003 11:50:25.695636  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171594 (* 1 = 0.171594 loss)
I1003 11:50:25.695643  7223 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I1003 11:50:39.944895  7223 solver.cpp:218] Iteration 53300 (7.01793 iter/s, 14.2492s/100 iters), loss = 0.0497914
I1003 11:50:39.944926  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0497906 (* 1 = 0.0497906 loss)
I1003 11:50:39.944942  7223 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I1003 11:50:54.202397  7223 solver.cpp:218] Iteration 53400 (7.01388 iter/s, 14.2574s/100 iters), loss = 0.0425267
I1003 11:50:54.202427  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0425259 (* 1 = 0.0425259 loss)
I1003 11:50:54.202435  7223 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I1003 11:51:07.746425  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:51:08.325078  7223 solver.cpp:330] Iteration 53500, Testing net (#0)
I1003 11:51:11.691516  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:51:11.831239  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8918
I1003 11:51:11.831275  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358718 (* 1 = 0.358718 loss)
I1003 11:51:11.973103  7223 solver.cpp:218] Iteration 53500 (5.62726 iter/s, 17.7706s/100 iters), loss = 0.0449096
I1003 11:51:11.973132  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0449088 (* 1 = 0.0449088 loss)
I1003 11:51:11.973140  7223 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I1003 11:51:26.223271  7223 solver.cpp:218] Iteration 53600 (7.01749 iter/s, 14.2501s/100 iters), loss = 0.106408
I1003 11:51:26.223304  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106407 (* 1 = 0.106407 loss)
I1003 11:51:26.223310  7223 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I1003 11:51:40.474773  7223 solver.cpp:218] Iteration 53700 (7.01684 iter/s, 14.2514s/100 iters), loss = 0.0566591
I1003 11:51:40.474853  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0566582 (* 1 = 0.0566582 loss)
I1003 11:51:40.474872  7223 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I1003 11:51:54.742615  7223 solver.cpp:218] Iteration 53800 (7.00882 iter/s, 14.2677s/100 iters), loss = 0.0842129
I1003 11:51:54.742656  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.084212 (* 1 = 0.084212 loss)
I1003 11:51:54.742663  7223 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I1003 11:52:09.002037  7223 solver.cpp:218] Iteration 53900 (7.01295 iter/s, 14.2593s/100 iters), loss = 0.0611568
I1003 11:52:09.002079  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0611559 (* 1 = 0.0611559 loss)
I1003 11:52:09.002084  7223 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I1003 11:52:22.543454  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:52:23.122220  7223 solver.cpp:330] Iteration 54000, Testing net (#0)
I1003 11:52:26.492041  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:52:26.631805  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8954
I1003 11:52:26.631841  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.361816 (* 1 = 0.361816 loss)
I1003 11:52:26.772543  7223 solver.cpp:218] Iteration 54000 (5.62733 iter/s, 17.7704s/100 iters), loss = 0.0963447
I1003 11:52:26.772572  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0963438 (* 1 = 0.0963438 loss)
I1003 11:52:26.772579  7223 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I1003 11:52:41.029606  7223 solver.cpp:218] Iteration 54100 (7.01412 iter/s, 14.257s/100 iters), loss = 0.0642931
I1003 11:52:41.029644  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0642922 (* 1 = 0.0642922 loss)
I1003 11:52:41.029651  7223 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I1003 11:52:55.284128  7223 solver.cpp:218] Iteration 54200 (7.01535 iter/s, 14.2544s/100 iters), loss = 0.105786
I1003 11:52:55.284235  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.105785 (* 1 = 0.105785 loss)
I1003 11:52:55.284242  7223 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I1003 11:53:09.548151  7223 solver.cpp:218] Iteration 54300 (7.01071 iter/s, 14.2639s/100 iters), loss = 0.0708613
I1003 11:53:09.548194  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0708604 (* 1 = 0.0708604 loss)
I1003 11:53:09.548202  7223 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I1003 11:53:23.817534  7223 solver.cpp:218] Iteration 54400 (7.00805 iter/s, 14.2693s/100 iters), loss = 0.0653254
I1003 11:53:23.817576  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0653244 (* 1 = 0.0653244 loss)
I1003 11:53:23.817584  7223 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I1003 11:53:37.374161  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:53:37.947255  7223 solver.cpp:330] Iteration 54500, Testing net (#0)
I1003 11:53:41.318434  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:53:41.458833  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8868
I1003 11:53:41.458869  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376131 (* 1 = 0.376131 loss)
I1003 11:53:41.600528  7223 solver.cpp:218] Iteration 54500 (5.62338 iter/s, 17.7829s/100 iters), loss = 0.0759564
I1003 11:53:41.600563  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0759554 (* 1 = 0.0759554 loss)
I1003 11:53:41.600569  7223 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I1003 11:53:55.849313  7223 solver.cpp:218] Iteration 54600 (7.01818 iter/s, 14.2487s/100 iters), loss = 0.0314053
I1003 11:53:55.849349  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0314043 (* 1 = 0.0314043 loss)
I1003 11:53:55.849355  7223 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I1003 11:54:10.102944  7223 solver.cpp:218] Iteration 54700 (7.01579 iter/s, 14.2536s/100 iters), loss = 0.057155
I1003 11:54:10.103126  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0571541 (* 1 = 0.0571541 loss)
I1003 11:54:10.103133  7223 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I1003 11:54:24.356423  7223 solver.cpp:218] Iteration 54800 (7.01593 iter/s, 14.2533s/100 iters), loss = 0.0697136
I1003 11:54:24.356454  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0697126 (* 1 = 0.0697126 loss)
I1003 11:54:24.356462  7223 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I1003 11:54:38.604418  7223 solver.cpp:218] Iteration 54900 (7.01856 iter/s, 14.2479s/100 iters), loss = 0.059561
I1003 11:54:38.604449  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.05956 (* 1 = 0.05956 loss)
I1003 11:54:38.604455  7223 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I1003 11:54:52.138394  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:54:52.706140  7223 solver.cpp:330] Iteration 55000, Testing net (#0)
I1003 11:54:56.085424  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:54:56.225322  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8897
I1003 11:54:56.225358  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.378805 (* 1 = 0.378805 loss)
I1003 11:54:56.366578  7223 solver.cpp:218] Iteration 55000 (5.62997 iter/s, 17.7621s/100 iters), loss = 0.0349755
I1003 11:54:56.366611  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0349745 (* 1 = 0.0349745 loss)
I1003 11:54:56.366616  7223 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I1003 11:55:10.617534  7223 solver.cpp:218] Iteration 55100 (7.01711 iter/s, 14.2509s/100 iters), loss = 0.0991879
I1003 11:55:10.617574  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0991869 (* 1 = 0.0991869 loss)
I1003 11:55:10.617579  7223 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I1003 11:55:24.874157  7223 solver.cpp:218] Iteration 55200 (7.01432 iter/s, 14.2566s/100 iters), loss = 0.107507
I1003 11:55:24.874261  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.107506 (* 1 = 0.107506 loss)
I1003 11:55:24.874269  7223 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I1003 11:55:39.136518  7223 solver.cpp:218] Iteration 55300 (7.01153 iter/s, 14.2622s/100 iters), loss = 0.0766834
I1003 11:55:39.136548  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0766824 (* 1 = 0.0766824 loss)
I1003 11:55:39.136554  7223 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I1003 11:55:53.404211  7223 solver.cpp:218] Iteration 55400 (7.00887 iter/s, 14.2676s/100 iters), loss = 0.0273519
I1003 11:55:53.404243  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0273509 (* 1 = 0.0273509 loss)
I1003 11:55:53.404250  7223 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I1003 11:56:06.944110  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:56:07.513052  7223 solver.cpp:330] Iteration 55500, Testing net (#0)
I1003 11:56:10.883288  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:56:11.026638  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8934
I1003 11:56:11.026664  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368942 (* 1 = 0.368942 loss)
I1003 11:56:11.170003  7223 solver.cpp:218] Iteration 55500 (5.62882 iter/s, 17.7657s/100 iters), loss = 0.0456706
I1003 11:56:11.170048  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0456696 (* 1 = 0.0456696 loss)
I1003 11:56:11.170055  7223 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I1003 11:56:25.410498  7223 solver.cpp:218] Iteration 55600 (7.02226 iter/s, 14.2404s/100 iters), loss = 0.0906178
I1003 11:56:25.410529  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0906168 (* 1 = 0.0906168 loss)
I1003 11:56:25.410537  7223 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I1003 11:56:39.674612  7223 solver.cpp:218] Iteration 55700 (7.01064 iter/s, 14.264s/100 iters), loss = 0.135889
I1003 11:56:39.674746  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135888 (* 1 = 0.135888 loss)
I1003 11:56:39.674754  7223 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I1003 11:56:53.928884  7223 solver.cpp:218] Iteration 55800 (7.01552 iter/s, 14.2541s/100 iters), loss = 0.0546258
I1003 11:56:53.928912  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0546248 (* 1 = 0.0546248 loss)
I1003 11:56:53.928918  7223 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I1003 11:57:08.186650  7223 solver.cpp:218] Iteration 55900 (7.01375 iter/s, 14.2577s/100 iters), loss = 0.0828839
I1003 11:57:08.186687  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0828829 (* 1 = 0.0828829 loss)
I1003 11:57:08.186695  7223 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I1003 11:57:21.738945  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:57:22.308567  7223 solver.cpp:330] Iteration 56000, Testing net (#0)
I1003 11:57:25.678472  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:57:25.819066  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8858
I1003 11:57:25.819102  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.391927 (* 1 = 0.391927 loss)
I1003 11:57:25.963826  7223 solver.cpp:218] Iteration 56000 (5.62522 iter/s, 17.7771s/100 iters), loss = 0.0433295
I1003 11:57:25.963881  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0433285 (* 1 = 0.0433285 loss)
I1003 11:57:25.963891  7223 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I1003 11:57:40.222026  7223 solver.cpp:218] Iteration 56100 (7.01357 iter/s, 14.2581s/100 iters), loss = 0.0719957
I1003 11:57:40.222059  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0719947 (* 1 = 0.0719947 loss)
I1003 11:57:40.222065  7223 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I1003 11:57:54.478528  7223 solver.cpp:218] Iteration 56200 (7.01438 iter/s, 14.2564s/100 iters), loss = 0.127197
I1003 11:57:54.478675  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127196 (* 1 = 0.127196 loss)
I1003 11:57:54.478684  7223 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I1003 11:58:08.754261  7223 solver.cpp:218] Iteration 56300 (7.00498 iter/s, 14.2756s/100 iters), loss = 0.0454196
I1003 11:58:08.754292  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0454187 (* 1 = 0.0454187 loss)
I1003 11:58:08.754298  7223 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I1003 11:58:23.018573  7223 solver.cpp:218] Iteration 56400 (7.01053 iter/s, 14.2642s/100 iters), loss = 0.0292121
I1003 11:58:23.018611  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0292111 (* 1 = 0.0292111 loss)
I1003 11:58:23.018620  7223 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I1003 11:58:36.566920  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:58:37.135191  7223 solver.cpp:330] Iteration 56500, Testing net (#0)
I1003 11:58:40.501971  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:58:40.642309  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8865
I1003 11:58:40.642334  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.409987 (* 1 = 0.409987 loss)
I1003 11:58:40.783130  7223 solver.cpp:218] Iteration 56500 (5.62921 iter/s, 17.7645s/100 iters), loss = 0.0782531
I1003 11:58:40.783156  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0782521 (* 1 = 0.0782521 loss)
I1003 11:58:40.783164  7223 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I1003 11:58:55.045773  7223 solver.cpp:218] Iteration 56600 (7.01135 iter/s, 14.2626s/100 iters), loss = 0.0831125
I1003 11:58:55.045805  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0831115 (* 1 = 0.0831115 loss)
I1003 11:58:55.045811  7223 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I1003 11:59:09.301522  7223 solver.cpp:218] Iteration 56700 (7.01474 iter/s, 14.2557s/100 iters), loss = 0.0953034
I1003 11:59:09.301661  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0953023 (* 1 = 0.0953023 loss)
I1003 11:59:09.301671  7223 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I1003 11:59:23.550025  7223 solver.cpp:218] Iteration 56800 (7.01836 iter/s, 14.2483s/100 iters), loss = 0.0669273
I1003 11:59:23.550057  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0669263 (* 1 = 0.0669263 loss)
I1003 11:59:23.550065  7223 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I1003 11:59:37.803594  7223 solver.cpp:218] Iteration 56900 (7.01582 iter/s, 14.2535s/100 iters), loss = 0.0750296
I1003 11:59:37.803625  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0750286 (* 1 = 0.0750286 loss)
I1003 11:59:37.803632  7223 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I1003 11:59:51.365602  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:59:51.934093  7223 solver.cpp:330] Iteration 57000, Testing net (#0)
I1003 11:59:55.304229  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 11:59:55.444445  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.892
I1003 11:59:55.444471  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.387582 (* 1 = 0.387582 loss)
I1003 11:59:55.585690  7223 solver.cpp:218] Iteration 57000 (5.62366 iter/s, 17.782s/100 iters), loss = 0.0818743
I1003 11:59:55.585721  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0818733 (* 1 = 0.0818733 loss)
I1003 11:59:55.585727  7223 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I1003 12:00:09.839448  7223 solver.cpp:218] Iteration 57100 (7.01572 iter/s, 14.2537s/100 iters), loss = 0.102963
I1003 12:00:09.839479  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102962 (* 1 = 0.102962 loss)
I1003 12:00:09.839485  7223 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I1003 12:00:24.096302  7223 solver.cpp:218] Iteration 57200 (7.0142 iter/s, 14.2568s/100 iters), loss = 0.0931475
I1003 12:00:24.096392  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0931466 (* 1 = 0.0931466 loss)
I1003 12:00:24.096410  7223 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I1003 12:00:38.359236  7223 solver.cpp:218] Iteration 57300 (7.01124 iter/s, 14.2628s/100 iters), loss = 0.0542462
I1003 12:00:38.359272  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0542453 (* 1 = 0.0542453 loss)
I1003 12:00:38.359280  7223 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I1003 12:00:52.613098  7223 solver.cpp:218] Iteration 57400 (7.01567 iter/s, 14.2538s/100 iters), loss = 0.0252948
I1003 12:00:52.613129  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0252939 (* 1 = 0.0252939 loss)
I1003 12:00:52.613137  7223 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I1003 12:01:06.165733  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:01:06.735559  7223 solver.cpp:330] Iteration 57500, Testing net (#0)
I1003 12:01:10.103209  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:01:10.243302  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.893
I1003 12:01:10.243330  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.371872 (* 1 = 0.371872 loss)
I1003 12:01:10.384656  7223 solver.cpp:218] Iteration 57500 (5.62699 iter/s, 17.7715s/100 iters), loss = 0.04694
I1003 12:01:10.384693  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.046939 (* 1 = 0.046939 loss)
I1003 12:01:10.384703  7223 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I1003 12:01:24.648744  7223 solver.cpp:218] Iteration 57600 (7.01072 iter/s, 14.2639s/100 iters), loss = 0.060866
I1003 12:01:24.648780  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0608651 (* 1 = 0.0608651 loss)
I1003 12:01:24.648789  7223 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I1003 12:01:38.909708  7223 solver.cpp:218] Iteration 57700 (7.01218 iter/s, 14.2609s/100 iters), loss = 0.026933
I1003 12:01:38.909842  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.026932 (* 1 = 0.026932 loss)
I1003 12:01:38.909853  7223 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I1003 12:01:53.164546  7223 solver.cpp:218] Iteration 57800 (7.01524 iter/s, 14.2547s/100 iters), loss = 0.0377812
I1003 12:01:53.164587  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0377803 (* 1 = 0.0377803 loss)
I1003 12:01:53.164597  7223 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I1003 12:02:07.418946  7223 solver.cpp:218] Iteration 57900 (7.01541 iter/s, 14.2543s/100 iters), loss = 0.0584121
I1003 12:02:07.418979  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0584111 (* 1 = 0.0584111 loss)
I1003 12:02:07.418998  7223 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I1003 12:02:20.976791  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:02:21.545469  7223 solver.cpp:330] Iteration 58000, Testing net (#0)
I1003 12:02:24.912016  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:02:25.051995  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.894
I1003 12:02:25.052021  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.379658 (* 1 = 0.379658 loss)
I1003 12:02:25.192848  7223 solver.cpp:218] Iteration 58000 (5.62625 iter/s, 17.7738s/100 iters), loss = 0.0289608
I1003 12:02:25.192884  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0289598 (* 1 = 0.0289598 loss)
I1003 12:02:25.192894  7223 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I1003 12:02:39.440973  7223 solver.cpp:218] Iteration 58100 (7.0185 iter/s, 14.2481s/100 iters), loss = 0.051246
I1003 12:02:39.441017  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0512451 (* 1 = 0.0512451 loss)
I1003 12:02:39.441025  7223 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I1003 12:02:53.712544  7223 solver.cpp:218] Iteration 58200 (7.00697 iter/s, 14.2715s/100 iters), loss = 0.110323
I1003 12:02:53.712651  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.110322 (* 1 = 0.110322 loss)
I1003 12:02:53.712671  7223 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I1003 12:03:07.984843  7223 solver.cpp:218] Iteration 58300 (7.00665 iter/s, 14.2722s/100 iters), loss = 0.0959518
I1003 12:03:07.984881  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0959509 (* 1 = 0.0959509 loss)
I1003 12:03:07.984889  7223 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I1003 12:03:22.248503  7223 solver.cpp:218] Iteration 58400 (7.01086 iter/s, 14.2636s/100 iters), loss = 0.0443435
I1003 12:03:22.248533  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0443426 (* 1 = 0.0443426 loss)
I1003 12:03:22.248539  7223 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I1003 12:03:35.806057  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:03:36.374884  7223 solver.cpp:330] Iteration 58500, Testing net (#0)
I1003 12:03:39.740967  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:03:39.880964  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.895
I1003 12:03:39.880998  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367836 (* 1 = 0.367836 loss)
I1003 12:03:40.021672  7223 solver.cpp:218] Iteration 58500 (5.62648 iter/s, 17.7731s/100 iters), loss = 0.060093
I1003 12:03:40.021703  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0600921 (* 1 = 0.0600921 loss)
I1003 12:03:40.021710  7223 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I1003 12:03:54.285547  7223 solver.cpp:218] Iteration 58600 (7.01075 iter/s, 14.2638s/100 iters), loss = 0.0115515
I1003 12:03:54.285588  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115507 (* 1 = 0.0115507 loss)
I1003 12:03:54.285595  7223 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I1003 12:04:08.545464  7223 solver.cpp:218] Iteration 58700 (7.0127 iter/s, 14.2598s/100 iters), loss = 0.0553822
I1003 12:04:08.545568  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0553813 (* 1 = 0.0553813 loss)
I1003 12:04:08.545578  7223 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I1003 12:04:22.793598  7223 solver.cpp:218] Iteration 58800 (7.01853 iter/s, 14.248s/100 iters), loss = 0.0807447
I1003 12:04:22.793639  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0807438 (* 1 = 0.0807438 loss)
I1003 12:04:22.793645  7223 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I1003 12:04:37.056350  7223 solver.cpp:218] Iteration 58900 (7.0113 iter/s, 14.2627s/100 iters), loss = 0.0596116
I1003 12:04:37.056392  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0596107 (* 1 = 0.0596107 loss)
I1003 12:04:37.056398  7223 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I1003 12:04:50.610141  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:04:51.178804  7223 solver.cpp:330] Iteration 59000, Testing net (#0)
I1003 12:04:54.546300  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:04:54.686342  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8875
I1003 12:04:54.686368  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.405857 (* 1 = 0.405857 loss)
I1003 12:04:54.826818  7223 solver.cpp:218] Iteration 59000 (5.62734 iter/s, 17.7704s/100 iters), loss = 0.0235843
I1003 12:04:54.826849  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0235834 (* 1 = 0.0235834 loss)
I1003 12:04:54.826856  7223 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I1003 12:05:09.072401  7223 solver.cpp:218] Iteration 59100 (7.01975 iter/s, 14.2455s/100 iters), loss = 0.0545947
I1003 12:05:09.072441  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0545938 (* 1 = 0.0545938 loss)
I1003 12:05:09.072448  7223 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I1003 12:05:23.331301  7223 solver.cpp:218] Iteration 59200 (7.0132 iter/s, 14.2588s/100 iters), loss = 0.0615351
I1003 12:05:23.331403  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0615342 (* 1 = 0.0615342 loss)
I1003 12:05:23.331421  7223 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I1003 12:05:37.574542  7223 solver.cpp:218] Iteration 59300 (7.02094 iter/s, 14.2431s/100 iters), loss = 0.0832765
I1003 12:05:37.574584  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0832756 (* 1 = 0.0832756 loss)
I1003 12:05:37.574589  7223 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I1003 12:05:51.827967  7223 solver.cpp:218] Iteration 59400 (7.01589 iter/s, 14.2534s/100 iters), loss = 0.0644955
I1003 12:05:51.828008  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0644945 (* 1 = 0.0644945 loss)
I1003 12:05:51.828016  7223 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I1003 12:06:05.385701  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:06:05.953413  7223 solver.cpp:330] Iteration 59500, Testing net (#0)
I1003 12:06:09.322511  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:06:09.462668  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8895
I1003 12:06:09.462693  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.395774 (* 1 = 0.395774 loss)
I1003 12:06:09.604179  7223 solver.cpp:218] Iteration 59500 (5.62552 iter/s, 17.7761s/100 iters), loss = 0.0545899
I1003 12:06:09.604215  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0545889 (* 1 = 0.0545889 loss)
I1003 12:06:09.604223  7223 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I1003 12:06:23.867442  7223 solver.cpp:218] Iteration 59600 (7.01105 iter/s, 14.2632s/100 iters), loss = 0.033065
I1003 12:06:23.867475  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0330641 (* 1 = 0.0330641 loss)
I1003 12:06:23.867480  7223 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I1003 12:06:38.114159  7223 solver.cpp:218] Iteration 59700 (7.01919 iter/s, 14.2467s/100 iters), loss = 0.0766061
I1003 12:06:38.114310  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0766051 (* 1 = 0.0766051 loss)
I1003 12:06:38.114321  7223 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I1003 12:06:52.370039  7223 solver.cpp:218] Iteration 59800 (7.01475 iter/s, 14.2557s/100 iters), loss = 0.0273313
I1003 12:06:52.370071  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0273304 (* 1 = 0.0273304 loss)
I1003 12:06:52.370079  7223 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I1003 12:07:06.627990  7223 solver.cpp:218] Iteration 59900 (7.01366 iter/s, 14.2579s/100 iters), loss = 0.0297389
I1003 12:07:06.628021  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.029738 (* 1 = 0.029738 loss)
I1003 12:07:06.628027  7223 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I1003 12:07:20.180207  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:07:20.748536  7223 solver.cpp:330] Iteration 60000, Testing net (#0)
I1003 12:07:24.113554  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:07:24.253756  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8942
I1003 12:07:24.253798  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.378311 (* 1 = 0.378311 loss)
I1003 12:07:24.394990  7223 solver.cpp:218] Iteration 60000 (5.62843 iter/s, 17.7669s/100 iters), loss = 0.0432062
I1003 12:07:24.395022  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0432052 (* 1 = 0.0432052 loss)
I1003 12:07:24.395028  7223 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I1003 12:07:38.643091  7223 solver.cpp:218] Iteration 60100 (7.01851 iter/s, 14.248s/100 iters), loss = 0.0878583
I1003 12:07:38.643124  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0878574 (* 1 = 0.0878574 loss)
I1003 12:07:38.643131  7223 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I1003 12:07:52.894542  7223 solver.cpp:218] Iteration 60200 (7.01686 iter/s, 14.2514s/100 iters), loss = 0.0460867
I1003 12:07:52.894615  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0460858 (* 1 = 0.0460858 loss)
I1003 12:07:52.894623  7223 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I1003 12:08:07.154666  7223 solver.cpp:218] Iteration 60300 (7.01261 iter/s, 14.26s/100 iters), loss = 0.0374704
I1003 12:08:07.154697  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0374695 (* 1 = 0.0374695 loss)
I1003 12:08:07.154703  7223 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I1003 12:08:21.411933  7223 solver.cpp:218] Iteration 60400 (7.014 iter/s, 14.2572s/100 iters), loss = 0.0363645
I1003 12:08:21.411965  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0363636 (* 1 = 0.0363636 loss)
I1003 12:08:21.411972  7223 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I1003 12:08:34.963330  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:08:35.539736  7223 solver.cpp:330] Iteration 60500, Testing net (#0)
I1003 12:08:38.907655  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:08:39.048094  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8928
I1003 12:08:39.048118  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372028 (* 1 = 0.372028 loss)
I1003 12:08:39.189122  7223 solver.cpp:218] Iteration 60500 (5.62521 iter/s, 17.7771s/100 iters), loss = 0.0313748
I1003 12:08:39.189153  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0313738 (* 1 = 0.0313738 loss)
I1003 12:08:39.189159  7223 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I1003 12:08:53.446907  7223 solver.cpp:218] Iteration 60600 (7.01376 iter/s, 14.2577s/100 iters), loss = 0.0116752
I1003 12:08:53.446939  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116742 (* 1 = 0.0116742 loss)
I1003 12:08:53.446945  7223 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I1003 12:09:07.689165  7223 solver.cpp:218] Iteration 60700 (7.02139 iter/s, 14.2422s/100 iters), loss = 0.0735434
I1003 12:09:07.689342  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0735425 (* 1 = 0.0735425 loss)
I1003 12:09:07.689350  7223 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I1003 12:09:21.957564  7223 solver.cpp:218] Iteration 60800 (7.0086 iter/s, 14.2682s/100 iters), loss = 0.0721218
I1003 12:09:21.957595  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0721208 (* 1 = 0.0721208 loss)
I1003 12:09:21.957602  7223 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I1003 12:09:36.222939  7223 solver.cpp:218] Iteration 60900 (7.01001 iter/s, 14.2653s/100 iters), loss = 0.015108
I1003 12:09:36.222970  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015107 (* 1 = 0.015107 loss)
I1003 12:09:36.222975  7223 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I1003 12:09:49.770746  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:09:50.346609  7223 solver.cpp:330] Iteration 61000, Testing net (#0)
I1003 12:09:53.710813  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:09:53.850440  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8921
I1003 12:09:53.850476  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.394972 (* 1 = 0.394972 loss)
I1003 12:09:53.991227  7223 solver.cpp:218] Iteration 61000 (5.62803 iter/s, 17.7682s/100 iters), loss = 0.0123075
I1003 12:09:53.991258  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0123065 (* 1 = 0.0123065 loss)
I1003 12:09:53.991264  7223 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I1003 12:10:08.247248  7223 solver.cpp:218] Iteration 61100 (7.01461 iter/s, 14.256s/100 iters), loss = 0.113651
I1003 12:10:08.247284  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.11365 (* 1 = 0.11365 loss)
I1003 12:10:08.247292  7223 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I1003 12:10:22.495282  7223 solver.cpp:218] Iteration 61200 (7.01855 iter/s, 14.248s/100 iters), loss = 0.0766281
I1003 12:10:22.495399  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0766271 (* 1 = 0.0766271 loss)
I1003 12:10:22.495406  7223 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I1003 12:10:36.739564  7223 solver.cpp:218] Iteration 61300 (7.02043 iter/s, 14.2441s/100 iters), loss = 0.0456425
I1003 12:10:36.739609  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0456416 (* 1 = 0.0456416 loss)
I1003 12:10:36.739615  7223 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I1003 12:10:50.987087  7223 solver.cpp:218] Iteration 61400 (7.0188 iter/s, 14.2475s/100 iters), loss = 0.0242322
I1003 12:10:50.987118  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0242312 (* 1 = 0.0242312 loss)
I1003 12:10:50.987123  7223 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I1003 12:11:04.532644  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:11:05.108714  7223 solver.cpp:330] Iteration 61500, Testing net (#0)
I1003 12:11:08.480350  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:11:08.620640  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8888
I1003 12:11:08.620666  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.412529 (* 1 = 0.412529 loss)
I1003 12:11:08.761677  7223 solver.cpp:218] Iteration 61500 (5.62603 iter/s, 17.7745s/100 iters), loss = 0.0340655
I1003 12:11:08.761711  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0340645 (* 1 = 0.0340645 loss)
I1003 12:11:08.761718  7223 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I1003 12:11:23.002223  7223 solver.cpp:218] Iteration 61600 (7.02224 iter/s, 14.2405s/100 iters), loss = 0.0402465
I1003 12:11:23.002271  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0402455 (* 1 = 0.0402455 loss)
I1003 12:11:23.002279  7223 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I1003 12:11:37.251560  7223 solver.cpp:218] Iteration 61700 (7.01792 iter/s, 14.2492s/100 iters), loss = 0.0402731
I1003 12:11:37.251679  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0402721 (* 1 = 0.0402721 loss)
I1003 12:11:37.251688  7223 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I1003 12:11:51.511236  7223 solver.cpp:218] Iteration 61800 (7.01285 iter/s, 14.2595s/100 iters), loss = 0.015041
I1003 12:11:51.511268  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01504 (* 1 = 0.01504 loss)
I1003 12:11:51.511274  7223 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I1003 12:12:05.759774  7223 solver.cpp:218] Iteration 61900 (7.01829 iter/s, 14.2485s/100 iters), loss = 0.0564714
I1003 12:12:05.759804  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0564704 (* 1 = 0.0564704 loss)
I1003 12:12:05.759810  7223 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I1003 12:12:19.294054  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:12:19.862385  7223 solver.cpp:330] Iteration 62000, Testing net (#0)
I1003 12:12:23.244258  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:12:23.384296  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8863
I1003 12:12:23.384331  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.420525 (* 1 = 0.420525 loss)
I1003 12:12:23.525805  7223 solver.cpp:218] Iteration 62000 (5.62874 iter/s, 17.766s/100 iters), loss = 0.0635577
I1003 12:12:23.525838  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0635566 (* 1 = 0.0635566 loss)
I1003 12:12:23.525845  7223 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I1003 12:12:37.770747  7223 solver.cpp:218] Iteration 62100 (7.02006 iter/s, 14.2449s/100 iters), loss = 0.121079
I1003 12:12:37.770774  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.121078 (* 1 = 0.121078 loss)
I1003 12:12:37.770781  7223 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I1003 12:12:52.029301  7223 solver.cpp:218] Iteration 62200 (7.01336 iter/s, 14.2585s/100 iters), loss = 0.0251095
I1003 12:12:52.029422  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0251085 (* 1 = 0.0251085 loss)
I1003 12:12:52.029430  7223 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I1003 12:13:06.277127  7223 solver.cpp:218] Iteration 62300 (7.01869 iter/s, 14.2477s/100 iters), loss = 0.0655567
I1003 12:13:06.277156  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0655557 (* 1 = 0.0655557 loss)
I1003 12:13:06.277163  7223 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I1003 12:13:20.534281  7223 solver.cpp:218] Iteration 62400 (7.01405 iter/s, 14.2571s/100 iters), loss = 0.0274423
I1003 12:13:20.534317  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0274412 (* 1 = 0.0274412 loss)
I1003 12:13:20.534324  7223 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I1003 12:13:34.072721  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:13:34.640614  7223 solver.cpp:330] Iteration 62500, Testing net (#0)
I1003 12:13:38.011471  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:13:38.155087  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8876
I1003 12:13:38.155117  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.40532 (* 1 = 0.40532 loss)
I1003 12:13:38.298480  7223 solver.cpp:218] Iteration 62500 (5.62932 iter/s, 17.7641s/100 iters), loss = 0.0292128
I1003 12:13:38.298516  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0292117 (* 1 = 0.0292117 loss)
I1003 12:13:38.298526  7223 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I1003 12:13:52.539361  7223 solver.cpp:218] Iteration 62600 (7.02207 iter/s, 14.2408s/100 iters), loss = 0.0579434
I1003 12:13:52.539391  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0579423 (* 1 = 0.0579423 loss)
I1003 12:13:52.539398  7223 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I1003 12:14:06.803645  7223 solver.cpp:218] Iteration 62700 (7.01055 iter/s, 14.2642s/100 iters), loss = 0.0640541
I1003 12:14:06.803819  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.064053 (* 1 = 0.064053 loss)
I1003 12:14:06.803828  7223 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I1003 12:14:21.067358  7223 solver.cpp:218] Iteration 62800 (7.01089 iter/s, 14.2635s/100 iters), loss = 0.0300643
I1003 12:14:21.067389  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0300632 (* 1 = 0.0300632 loss)
I1003 12:14:21.067394  7223 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I1003 12:14:35.322408  7223 solver.cpp:218] Iteration 62900 (7.01509 iter/s, 14.255s/100 iters), loss = 0.0393431
I1003 12:14:35.322443  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.039342 (* 1 = 0.039342 loss)
I1003 12:14:35.322450  7223 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I1003 12:14:48.868083  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:14:49.437366  7223 solver.cpp:330] Iteration 63000, Testing net (#0)
I1003 12:14:52.805863  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:14:52.945634  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8957
I1003 12:14:52.945672  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367788 (* 1 = 0.367788 loss)
I1003 12:14:53.090505  7223 solver.cpp:218] Iteration 63000 (5.62809 iter/s, 17.768s/100 iters), loss = 0.0923254
I1003 12:14:53.090555  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0923244 (* 1 = 0.0923244 loss)
I1003 12:14:53.090574  7223 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I1003 12:15:07.358916  7223 solver.cpp:218] Iteration 63100 (7.00854 iter/s, 14.2683s/100 iters), loss = 0.0281631
I1003 12:15:07.358958  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.028162 (* 1 = 0.028162 loss)
I1003 12:15:07.358964  7223 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I1003 12:15:21.624450  7223 solver.cpp:218] Iteration 63200 (7.00994 iter/s, 14.2655s/100 iters), loss = 0.0491593
I1003 12:15:21.624560  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0491582 (* 1 = 0.0491582 loss)
I1003 12:15:21.624578  7223 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I1003 12:15:35.892639  7223 solver.cpp:218] Iteration 63300 (7.00866 iter/s, 14.2681s/100 iters), loss = 0.0740619
I1003 12:15:35.892669  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0740608 (* 1 = 0.0740608 loss)
I1003 12:15:35.892675  7223 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I1003 12:15:50.166481  7223 solver.cpp:218] Iteration 63400 (7.00585 iter/s, 14.2738s/100 iters), loss = 0.0228594
I1003 12:15:50.166519  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0228583 (* 1 = 0.0228583 loss)
I1003 12:15:50.166529  7223 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I1003 12:16:03.723415  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:16:04.291893  7223 solver.cpp:330] Iteration 63500, Testing net (#0)
I1003 12:16:07.659324  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:16:07.799690  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8839
I1003 12:16:07.799726  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.44569 (* 1 = 0.44569 loss)
I1003 12:16:07.940722  7223 solver.cpp:218] Iteration 63500 (5.62615 iter/s, 17.7741s/100 iters), loss = 0.0321442
I1003 12:16:07.940753  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0321431 (* 1 = 0.0321431 loss)
I1003 12:16:07.940760  7223 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I1003 12:16:22.187279  7223 solver.cpp:218] Iteration 63600 (7.01927 iter/s, 14.2465s/100 iters), loss = 0.108593
I1003 12:16:22.187320  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.108592 (* 1 = 0.108592 loss)
I1003 12:16:22.187326  7223 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I1003 12:16:36.442065  7223 solver.cpp:218] Iteration 63700 (7.01522 iter/s, 14.2547s/100 iters), loss = 0.118972
I1003 12:16:36.442199  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.118971 (* 1 = 0.118971 loss)
I1003 12:16:36.442207  7223 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I1003 12:16:50.701007  7223 solver.cpp:218] Iteration 63800 (7.01322 iter/s, 14.2588s/100 iters), loss = 0.0570314
I1003 12:16:50.701037  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0570303 (* 1 = 0.0570303 loss)
I1003 12:16:50.701045  7223 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I1003 12:17:04.940220  7223 solver.cpp:218] Iteration 63900 (7.02289 iter/s, 14.2392s/100 iters), loss = 0.0210003
I1003 12:17:04.940261  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0209992 (* 1 = 0.0209992 loss)
I1003 12:17:04.940268  7223 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I1003 12:17:18.496213  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:17:19.066537  7223 solver.cpp:330] Iteration 64000, Testing net (#0)
I1003 12:17:22.435781  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:17:22.576076  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8814
I1003 12:17:22.576112  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.444843 (* 1 = 0.444843 loss)
I1003 12:17:22.717057  7223 solver.cpp:218] Iteration 64000 (5.62532 iter/s, 17.7768s/100 iters), loss = 0.0554052
I1003 12:17:22.717087  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0554041 (* 1 = 0.0554041 loss)
I1003 12:17:22.717092  7223 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I1003 12:17:36.962476  7223 solver.cpp:218] Iteration 64100 (7.01983 iter/s, 14.2454s/100 iters), loss = 0.029175
I1003 12:17:36.962507  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0291739 (* 1 = 0.0291739 loss)
I1003 12:17:36.962512  7223 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I1003 12:17:51.211189  7223 solver.cpp:218] Iteration 64200 (7.01821 iter/s, 14.2487s/100 iters), loss = 0.0359814
I1003 12:17:51.211284  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0359803 (* 1 = 0.0359803 loss)
I1003 12:17:51.211302  7223 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I1003 12:18:05.466622  7223 solver.cpp:218] Iteration 64300 (7.01493 iter/s, 14.2553s/100 iters), loss = 0.0435727
I1003 12:18:05.466653  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0435716 (* 1 = 0.0435716 loss)
I1003 12:18:05.466660  7223 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I1003 12:18:19.724550  7223 solver.cpp:218] Iteration 64400 (7.01367 iter/s, 14.2579s/100 iters), loss = 0.0513308
I1003 12:18:19.724581  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0513297 (* 1 = 0.0513297 loss)
I1003 12:18:19.724587  7223 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I1003 12:18:33.275110  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:18:33.843531  7223 solver.cpp:330] Iteration 64500, Testing net (#0)
I1003 12:18:37.211127  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:18:37.351372  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8913
I1003 12:18:37.351397  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.409971 (* 1 = 0.409971 loss)
I1003 12:18:37.492276  7223 solver.cpp:218] Iteration 64500 (5.6282 iter/s, 17.7677s/100 iters), loss = 0.04458
I1003 12:18:37.492310  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0445789 (* 1 = 0.0445789 loss)
I1003 12:18:37.492316  7223 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I1003 12:18:51.755915  7223 solver.cpp:218] Iteration 64600 (7.01087 iter/s, 14.2636s/100 iters), loss = 0.0423209
I1003 12:18:51.755947  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0423198 (* 1 = 0.0423198 loss)
I1003 12:18:51.755954  7223 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I1003 12:19:06.022948  7223 solver.cpp:218] Iteration 64700 (7.00919 iter/s, 14.267s/100 iters), loss = 0.0610697
I1003 12:19:06.023051  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0610685 (* 1 = 0.0610685 loss)
I1003 12:19:06.023068  7223 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I1003 12:19:20.294121  7223 solver.cpp:218] Iteration 64800 (7.0072 iter/s, 14.271s/100 iters), loss = 0.0516932
I1003 12:19:20.294157  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0516921 (* 1 = 0.0516921 loss)
I1003 12:19:20.294165  7223 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I1003 12:19:34.544101  7223 solver.cpp:218] Iteration 64900 (7.01759 iter/s, 14.2499s/100 iters), loss = 0.0278769
I1003 12:19:34.544142  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0278758 (* 1 = 0.0278758 loss)
I1003 12:19:34.544149  7223 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I1003 12:19:48.108976  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:19:48.677896  7223 solver.cpp:330] Iteration 65000, Testing net (#0)
I1003 12:19:52.046139  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:19:52.185930  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8894
I1003 12:19:52.185964  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.440222 (* 1 = 0.440222 loss)
I1003 12:19:52.327708  7223 solver.cpp:218] Iteration 65000 (5.62318 iter/s, 17.7835s/100 iters), loss = 0.17501
I1003 12:19:52.327736  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175009 (* 1 = 0.175009 loss)
I1003 12:19:52.327744  7223 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I1003 12:20:06.583546  7223 solver.cpp:218] Iteration 65100 (7.0147 iter/s, 14.2558s/100 iters), loss = 0.0460934
I1003 12:20:06.583580  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0460923 (* 1 = 0.0460923 loss)
I1003 12:20:06.583586  7223 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I1003 12:20:20.840142  7223 solver.cpp:218] Iteration 65200 (7.01433 iter/s, 14.2565s/100 iters), loss = 0.0656944
I1003 12:20:20.840241  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0656932 (* 1 = 0.0656932 loss)
I1003 12:20:20.840260  7223 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I1003 12:20:35.096592  7223 solver.cpp:218] Iteration 65300 (7.01443 iter/s, 14.2563s/100 iters), loss = 0.0346649
I1003 12:20:35.096629  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0346638 (* 1 = 0.0346638 loss)
I1003 12:20:35.096638  7223 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I1003 12:20:49.353215  7223 solver.cpp:218] Iteration 65400 (7.01431 iter/s, 14.2566s/100 iters), loss = 0.0367048
I1003 12:20:49.353245  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0367036 (* 1 = 0.0367036 loss)
I1003 12:20:49.353251  7223 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I1003 12:21:02.903270  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:21:03.471756  7223 solver.cpp:330] Iteration 65500, Testing net (#0)
I1003 12:21:06.837110  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:21:06.977136  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8865
I1003 12:21:06.977172  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.420536 (* 1 = 0.420536 loss)
I1003 12:21:07.118248  7223 solver.cpp:218] Iteration 65500 (5.62906 iter/s, 17.765s/100 iters), loss = 0.0399837
I1003 12:21:07.118278  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0399825 (* 1 = 0.0399825 loss)
I1003 12:21:07.118285  7223 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I1003 12:21:21.388352  7223 solver.cpp:218] Iteration 65600 (7.00769 iter/s, 14.27s/100 iters), loss = 0.0932069
I1003 12:21:21.388383  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0932057 (* 1 = 0.0932057 loss)
I1003 12:21:21.388389  7223 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I1003 12:21:35.665755  7223 solver.cpp:218] Iteration 65700 (7.0041 iter/s, 14.2773s/100 iters), loss = 0.0351505
I1003 12:21:35.665904  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0351493 (* 1 = 0.0351493 loss)
I1003 12:21:35.665928  7223 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I1003 12:21:49.916549  7223 solver.cpp:218] Iteration 65800 (7.01724 iter/s, 14.2506s/100 iters), loss = 0.0196983
I1003 12:21:49.916580  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0196971 (* 1 = 0.0196971 loss)
I1003 12:21:49.916596  7223 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I1003 12:22:04.188376  7223 solver.cpp:218] Iteration 65900 (7.00684 iter/s, 14.2718s/100 iters), loss = 0.0136576
I1003 12:22:04.188406  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136565 (* 1 = 0.0136565 loss)
I1003 12:22:04.188413  7223 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I1003 12:22:17.758553  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:22:18.327577  7223 solver.cpp:330] Iteration 66000, Testing net (#0)
I1003 12:22:21.696858  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:22:21.836659  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8814
I1003 12:22:21.836696  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.450427 (* 1 = 0.450427 loss)
I1003 12:22:21.978124  7223 solver.cpp:218] Iteration 66000 (5.62124 iter/s, 17.7897s/100 iters), loss = 0.0116327
I1003 12:22:21.978157  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116316 (* 1 = 0.0116316 loss)
I1003 12:22:21.978164  7223 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I1003 12:22:36.224706  7223 solver.cpp:218] Iteration 66100 (7.01926 iter/s, 14.2465s/100 iters), loss = 0.0282662
I1003 12:22:36.224746  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.028265 (* 1 = 0.028265 loss)
I1003 12:22:36.224752  7223 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I1003 12:22:50.479888  7223 solver.cpp:218] Iteration 66200 (7.01503 iter/s, 14.2551s/100 iters), loss = 0.0712347
I1003 12:22:50.479970  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0712335 (* 1 = 0.0712335 loss)
I1003 12:22:50.479979  7223 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I1003 12:23:04.729172  7223 solver.cpp:218] Iteration 66300 (7.01795 iter/s, 14.2492s/100 iters), loss = 0.0625514
I1003 12:23:04.729202  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0625502 (* 1 = 0.0625502 loss)
I1003 12:23:04.729210  7223 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I1003 12:23:18.981264  7223 solver.cpp:218] Iteration 66400 (7.01654 iter/s, 14.252s/100 iters), loss = 0.0535197
I1003 12:23:18.981307  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0535185 (* 1 = 0.0535185 loss)
I1003 12:23:18.981314  7223 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I1003 12:23:32.519016  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:23:33.087651  7223 solver.cpp:330] Iteration 66500, Testing net (#0)
I1003 12:23:36.456418  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:23:36.596149  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8915
I1003 12:23:36.596175  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.400279 (* 1 = 0.400279 loss)
I1003 12:23:36.737109  7223 solver.cpp:218] Iteration 66500 (5.63197 iter/s, 17.7558s/100 iters), loss = 0.0347604
I1003 12:23:36.737143  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0347592 (* 1 = 0.0347592 loss)
I1003 12:23:36.737149  7223 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I1003 12:23:50.991325  7223 solver.cpp:218] Iteration 66600 (7.0155 iter/s, 14.2542s/100 iters), loss = 0.0554069
I1003 12:23:50.991355  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0554057 (* 1 = 0.0554057 loss)
I1003 12:23:50.991361  7223 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I1003 12:24:05.240977  7223 solver.cpp:218] Iteration 66700 (7.01775 iter/s, 14.2496s/100 iters), loss = 0.0654938
I1003 12:24:05.241147  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0654926 (* 1 = 0.0654926 loss)
I1003 12:24:05.241158  7223 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I1003 12:24:19.484597  7223 solver.cpp:218] Iteration 66800 (7.02078 iter/s, 14.2434s/100 iters), loss = 0.06628
I1003 12:24:19.484632  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0662788 (* 1 = 0.0662788 loss)
I1003 12:24:19.484638  7223 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I1003 12:24:33.735124  7223 solver.cpp:218] Iteration 66900 (7.01732 iter/s, 14.2505s/100 iters), loss = 0.0821657
I1003 12:24:33.735155  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0821645 (* 1 = 0.0821645 loss)
I1003 12:24:33.735162  7223 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I1003 12:24:47.278609  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:24:47.848239  7223 solver.cpp:330] Iteration 67000, Testing net (#0)
I1003 12:24:51.212846  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:24:51.352902  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8874
I1003 12:24:51.352927  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.415701 (* 1 = 0.415701 loss)
I1003 12:24:51.493755  7223 solver.cpp:218] Iteration 67000 (5.63108 iter/s, 17.7586s/100 iters), loss = 0.0430614
I1003 12:24:51.493788  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0430602 (* 1 = 0.0430602 loss)
I1003 12:24:51.493794  7223 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I1003 12:25:05.733691  7223 solver.cpp:218] Iteration 67100 (7.02253 iter/s, 14.2399s/100 iters), loss = 0.0433436
I1003 12:25:05.733724  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0433424 (* 1 = 0.0433424 loss)
I1003 12:25:05.733731  7223 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I1003 12:25:19.984138  7223 solver.cpp:218] Iteration 67200 (7.01735 iter/s, 14.2504s/100 iters), loss = 0.0864546
I1003 12:25:19.984230  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0864534 (* 1 = 0.0864534 loss)
I1003 12:25:19.984236  7223 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I1003 12:25:34.238114  7223 solver.cpp:218] Iteration 67300 (7.01564 iter/s, 14.2539s/100 iters), loss = 0.0385579
I1003 12:25:34.238157  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0385567 (* 1 = 0.0385567 loss)
I1003 12:25:34.238162  7223 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I1003 12:25:48.484408  7223 solver.cpp:218] Iteration 67400 (7.0194 iter/s, 14.2462s/100 iters), loss = 0.0150916
I1003 12:25:48.484442  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0150904 (* 1 = 0.0150904 loss)
I1003 12:25:48.484449  7223 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I1003 12:26:02.020256  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:26:02.596976  7223 solver.cpp:330] Iteration 67500, Testing net (#0)
I1003 12:26:05.963186  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:26:06.103173  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8907
I1003 12:26:06.103207  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.392214 (* 1 = 0.392214 loss)
I1003 12:26:06.244865  7223 solver.cpp:218] Iteration 67500 (5.63051 iter/s, 17.7604s/100 iters), loss = 0.0216638
I1003 12:26:06.244897  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0216626 (* 1 = 0.0216626 loss)
I1003 12:26:06.244904  7223 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I1003 12:26:20.507208  7223 solver.cpp:218] Iteration 67600 (7.0115 iter/s, 14.2623s/100 iters), loss = 0.0199869
I1003 12:26:20.507241  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0199858 (* 1 = 0.0199858 loss)
I1003 12:26:20.507248  7223 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I1003 12:26:34.759734  7223 solver.cpp:218] Iteration 67700 (7.01633 iter/s, 14.2525s/100 iters), loss = 0.0692146
I1003 12:26:34.759905  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0692134 (* 1 = 0.0692134 loss)
I1003 12:26:34.759915  7223 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I1003 12:26:49.024094  7223 solver.cpp:218] Iteration 67800 (7.01058 iter/s, 14.2642s/100 iters), loss = 0.0150338
I1003 12:26:49.024137  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0150326 (* 1 = 0.0150326 loss)
I1003 12:26:49.024144  7223 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I1003 12:27:03.296535  7223 solver.cpp:218] Iteration 67900 (7.00654 iter/s, 14.2724s/100 iters), loss = 0.0276942
I1003 12:27:03.296576  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.027693 (* 1 = 0.027693 loss)
I1003 12:27:03.296583  7223 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I1003 12:27:16.843756  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:27:17.419898  7223 solver.cpp:330] Iteration 68000, Testing net (#0)
I1003 12:27:20.784855  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:27:20.925142  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8832
I1003 12:27:20.925168  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.443998 (* 1 = 0.443998 loss)
I1003 12:27:21.066120  7223 solver.cpp:218] Iteration 68000 (5.62761 iter/s, 17.7695s/100 iters), loss = 0.0364099
I1003 12:27:21.066149  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0364088 (* 1 = 0.0364088 loss)
I1003 12:27:21.066165  7223 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I1003 12:27:35.323379  7223 solver.cpp:218] Iteration 68100 (7.014 iter/s, 14.2572s/100 iters), loss = 0.0231596
I1003 12:27:35.323415  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0231584 (* 1 = 0.0231584 loss)
I1003 12:27:35.323421  7223 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I1003 12:27:49.589340  7223 solver.cpp:218] Iteration 68200 (7.00972 iter/s, 14.2659s/100 iters), loss = 0.0472108
I1003 12:27:49.589452  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0472096 (* 1 = 0.0472096 loss)
I1003 12:27:49.589458  7223 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I1003 12:28:03.860471  7223 solver.cpp:218] Iteration 68300 (7.00722 iter/s, 14.271s/100 iters), loss = 0.0438722
I1003 12:28:03.860502  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0438709 (* 1 = 0.0438709 loss)
I1003 12:28:03.860509  7223 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I1003 12:28:18.122853  7223 solver.cpp:218] Iteration 68400 (7.01148 iter/s, 14.2623s/100 iters), loss = 0.0727907
I1003 12:28:18.122895  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0727895 (* 1 = 0.0727895 loss)
I1003 12:28:18.122901  7223 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I1003 12:28:31.675837  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:28:32.253573  7223 solver.cpp:330] Iteration 68500, Testing net (#0)
I1003 12:28:35.625293  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:28:35.765465  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8919
I1003 12:28:35.765502  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.399 (* 1 = 0.399 loss)
I1003 12:28:35.907038  7223 solver.cpp:218] Iteration 68500 (5.623 iter/s, 17.7841s/100 iters), loss = 0.0851088
I1003 12:28:35.907071  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0851076 (* 1 = 0.0851076 loss)
I1003 12:28:35.907078  7223 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I1003 12:28:50.158042  7223 solver.cpp:218] Iteration 68600 (7.01708 iter/s, 14.2509s/100 iters), loss = 0.0135441
I1003 12:28:50.158090  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0135429 (* 1 = 0.0135429 loss)
I1003 12:28:50.158097  7223 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I1003 12:29:04.407326  7223 solver.cpp:218] Iteration 68700 (7.01795 iter/s, 14.2492s/100 iters), loss = 0.0385815
I1003 12:29:04.407467  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0385803 (* 1 = 0.0385803 loss)
I1003 12:29:04.407492  7223 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I1003 12:29:18.662456  7223 solver.cpp:218] Iteration 68800 (7.01509 iter/s, 14.255s/100 iters), loss = 0.0532828
I1003 12:29:18.662488  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0532816 (* 1 = 0.0532816 loss)
I1003 12:29:18.662494  7223 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I1003 12:29:32.921499  7223 solver.cpp:218] Iteration 68900 (7.01312 iter/s, 14.259s/100 iters), loss = 0.0615421
I1003 12:29:32.921530  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0615409 (* 1 = 0.0615409 loss)
I1003 12:29:32.921535  7223 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I1003 12:29:46.459249  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:29:47.027114  7223 solver.cpp:330] Iteration 69000, Testing net (#0)
I1003 12:29:50.401598  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:29:50.541622  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8839
I1003 12:29:50.541648  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.455845 (* 1 = 0.455845 loss)
I1003 12:29:50.682981  7223 solver.cpp:218] Iteration 69000 (5.63018 iter/s, 17.7614s/100 iters), loss = 0.0542291
I1003 12:29:50.683013  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0542279 (* 1 = 0.0542279 loss)
I1003 12:29:50.683019  7223 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I1003 12:30:04.936615  7223 solver.cpp:218] Iteration 69100 (7.01578 iter/s, 14.2536s/100 iters), loss = 0.0183167
I1003 12:30:04.936645  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0183155 (* 1 = 0.0183155 loss)
I1003 12:30:04.936650  7223 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I1003 12:30:19.203819  7223 solver.cpp:218] Iteration 69200 (7.00911 iter/s, 14.2671s/100 iters), loss = 0.0412157
I1003 12:30:19.203969  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0412145 (* 1 = 0.0412145 loss)
I1003 12:30:19.203979  7223 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I1003 12:30:33.454424  7223 solver.cpp:218] Iteration 69300 (7.01733 iter/s, 14.2504s/100 iters), loss = 0.0506912
I1003 12:30:33.454460  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.05069 (* 1 = 0.05069 loss)
I1003 12:30:33.454478  7223 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I1003 12:30:47.711125  7223 solver.cpp:218] Iteration 69400 (7.01428 iter/s, 14.2566s/100 iters), loss = 0.0137234
I1003 12:30:47.711172  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0137222 (* 1 = 0.0137222 loss)
I1003 12:30:47.711179  7223 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I1003 12:31:01.266819  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:31:01.835903  7223 solver.cpp:330] Iteration 69500, Testing net (#0)
I1003 12:31:05.211261  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:31:05.355293  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8887
I1003 12:31:05.355322  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.456257 (* 1 = 0.456257 loss)
I1003 12:31:05.496714  7223 solver.cpp:218] Iteration 69500 (5.62255 iter/s, 17.7855s/100 iters), loss = 0.0187865
I1003 12:31:05.496748  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0187853 (* 1 = 0.0187853 loss)
I1003 12:31:05.496757  7223 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I1003 12:31:19.740363  7223 solver.cpp:218] Iteration 69600 (7.02071 iter/s, 14.2436s/100 iters), loss = 0.0562828
I1003 12:31:19.740393  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0562816 (* 1 = 0.0562816 loss)
I1003 12:31:19.740399  7223 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I1003 12:31:33.989058  7223 solver.cpp:218] Iteration 69700 (7.01822 iter/s, 14.2486s/100 iters), loss = 0.038687
I1003 12:31:33.989183  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0386858 (* 1 = 0.0386858 loss)
I1003 12:31:33.989202  7223 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I1003 12:31:48.257828  7223 solver.cpp:218] Iteration 69800 (7.00838 iter/s, 14.2686s/100 iters), loss = 0.0628699
I1003 12:31:48.257859  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0628687 (* 1 = 0.0628687 loss)
I1003 12:31:48.257865  7223 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I1003 12:32:02.518710  7223 solver.cpp:218] Iteration 69900 (7.01222 iter/s, 14.2608s/100 iters), loss = 0.0240972
I1003 12:32:02.518743  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.024096 (* 1 = 0.024096 loss)
I1003 12:32:02.518749  7223 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I1003 12:32:16.056021  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:32:16.624552  7223 solver.cpp:330] Iteration 70000, Testing net (#0)
I1003 12:32:19.991463  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:32:20.134618  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8937
I1003 12:32:20.134660  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.407036 (* 1 = 0.407036 loss)
I1003 12:32:20.279357  7223 solver.cpp:218] Iteration 70000 (5.63045 iter/s, 17.7606s/100 iters), loss = 0.0239042
I1003 12:32:20.279405  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.023903 (* 1 = 0.023903 loss)
I1003 12:32:20.279423  7223 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I1003 12:32:34.535372  7223 solver.cpp:218] Iteration 70100 (7.01464 iter/s, 14.2559s/100 iters), loss = 0.0644839
I1003 12:32:34.535413  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0644827 (* 1 = 0.0644827 loss)
I1003 12:32:34.535419  7223 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I1003 12:32:48.804240  7223 solver.cpp:218] Iteration 70200 (7.0083 iter/s, 14.2688s/100 iters), loss = 0.0207235
I1003 12:32:48.804356  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0207222 (* 1 = 0.0207222 loss)
I1003 12:32:48.804374  7223 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I1003 12:33:03.065313  7223 solver.cpp:218] Iteration 70300 (7.01216 iter/s, 14.2609s/100 iters), loss = 0.0258684
I1003 12:33:03.065354  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0258672 (* 1 = 0.0258672 loss)
I1003 12:33:03.065361  7223 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I1003 12:33:17.323786  7223 solver.cpp:218] Iteration 70400 (7.01341 iter/s, 14.2584s/100 iters), loss = 0.0193154
I1003 12:33:17.323834  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0193142 (* 1 = 0.0193142 loss)
I1003 12:33:17.323843  7223 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I1003 12:33:30.878576  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:33:31.446580  7223 solver.cpp:330] Iteration 70500, Testing net (#0)
I1003 12:33:34.816674  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:33:34.957165  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8813
I1003 12:33:34.957201  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.47375 (* 1 = 0.47375 loss)
I1003 12:33:35.099416  7223 solver.cpp:218] Iteration 70500 (5.6257 iter/s, 17.7756s/100 iters), loss = 0.0823552
I1003 12:33:35.099452  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.082354 (* 1 = 0.082354 loss)
I1003 12:33:35.099462  7223 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I1003 12:33:49.343325  7223 solver.cpp:218] Iteration 70600 (7.02058 iter/s, 14.2438s/100 iters), loss = 0.0575634
I1003 12:33:49.343370  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0575623 (* 1 = 0.0575623 loss)
I1003 12:33:49.343377  7223 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I1003 12:34:03.590373  7223 solver.cpp:218] Iteration 70700 (7.01903 iter/s, 14.247s/100 iters), loss = 0.0595221
I1003 12:34:03.590488  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0595209 (* 1 = 0.0595209 loss)
I1003 12:34:03.590507  7223 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I1003 12:34:17.847838  7223 solver.cpp:218] Iteration 70800 (7.01393 iter/s, 14.2573s/100 iters), loss = 0.0532311
I1003 12:34:17.847882  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.05323 (* 1 = 0.05323 loss)
I1003 12:34:17.847889  7223 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I1003 12:34:32.092185  7223 solver.cpp:218] Iteration 70900 (7.02036 iter/s, 14.2443s/100 iters), loss = 0.0422555
I1003 12:34:32.092229  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0422544 (* 1 = 0.0422544 loss)
I1003 12:34:32.092236  7223 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I1003 12:34:45.632486  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:34:46.201241  7223 solver.cpp:330] Iteration 71000, Testing net (#0)
I1003 12:34:49.570086  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:34:49.710492  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8839
I1003 12:34:49.710531  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.470276 (* 1 = 0.470276 loss)
I1003 12:34:49.850944  7223 solver.cpp:218] Iteration 71000 (5.63106 iter/s, 17.7586s/100 iters), loss = 0.0562121
I1003 12:34:49.850975  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.056211 (* 1 = 0.056211 loss)
I1003 12:34:49.850981  7223 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I1003 12:35:04.107277  7223 solver.cpp:218] Iteration 71100 (7.01454 iter/s, 14.2561s/100 iters), loss = 0.0280244
I1003 12:35:04.107308  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0280233 (* 1 = 0.0280233 loss)
I1003 12:35:04.107314  7223 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I1003 12:35:18.352337  7223 solver.cpp:218] Iteration 71200 (7.02001 iter/s, 14.245s/100 iters), loss = 0.0691398
I1003 12:35:18.352443  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0691386 (* 1 = 0.0691386 loss)
I1003 12:35:18.352452  7223 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I1003 12:35:32.589660  7223 solver.cpp:218] Iteration 71300 (7.02385 iter/s, 14.2372s/100 iters), loss = 0.0271642
I1003 12:35:32.589692  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0271631 (* 1 = 0.0271631 loss)
I1003 12:35:32.589699  7223 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I1003 12:35:46.831346  7223 solver.cpp:218] Iteration 71400 (7.02167 iter/s, 14.2416s/100 iters), loss = 0.0536475
I1003 12:35:46.831377  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0536463 (* 1 = 0.0536463 loss)
I1003 12:35:46.831382  7223 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I1003 12:36:00.383169  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:36:00.952142  7223 solver.cpp:330] Iteration 71500, Testing net (#0)
I1003 12:36:04.319608  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:36:04.459811  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8905
I1003 12:36:04.459836  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.432086 (* 1 = 0.432086 loss)
I1003 12:36:04.600801  7223 solver.cpp:218] Iteration 71500 (5.62766 iter/s, 17.7694s/100 iters), loss = 0.0316358
I1003 12:36:04.600833  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0316347 (* 1 = 0.0316347 loss)
I1003 12:36:04.600841  7223 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I1003 12:36:18.836674  7223 solver.cpp:218] Iteration 71600 (7.02454 iter/s, 14.2358s/100 iters), loss = 0.0535965
I1003 12:36:18.836705  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0535953 (* 1 = 0.0535953 loss)
I1003 12:36:18.836712  7223 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I1003 12:36:33.093237  7223 solver.cpp:218] Iteration 71700 (7.01434 iter/s, 14.2565s/100 iters), loss = 0.0232706
I1003 12:36:33.093358  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0232694 (* 1 = 0.0232694 loss)
I1003 12:36:33.093375  7223 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I1003 12:36:47.347971  7223 solver.cpp:218] Iteration 71800 (7.01529 iter/s, 14.2546s/100 iters), loss = 0.043428
I1003 12:36:47.348006  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0434268 (* 1 = 0.0434268 loss)
I1003 12:36:47.348013  7223 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I1003 12:37:01.589820  7223 solver.cpp:218] Iteration 71900 (7.02159 iter/s, 14.2418s/100 iters), loss = 0.00963566
I1003 12:37:01.589850  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0096345 (* 1 = 0.0096345 loss)
I1003 12:37:01.589856  7223 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I1003 12:37:15.129405  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:37:15.696004  7223 solver.cpp:330] Iteration 72000, Testing net (#0)
I1003 12:37:19.067437  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:37:19.207608  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8905
I1003 12:37:19.207644  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.427563 (* 1 = 0.427563 loss)
I1003 12:37:19.348915  7223 solver.cpp:218] Iteration 72000 (5.63094 iter/s, 17.759s/100 iters), loss = 0.0274659
I1003 12:37:19.348950  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0274648 (* 1 = 0.0274648 loss)
I1003 12:37:19.348958  7223 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I1003 12:37:33.598457  7223 solver.cpp:218] Iteration 72100 (7.01789 iter/s, 14.2493s/100 iters), loss = 0.0935027
I1003 12:37:33.598501  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0935015 (* 1 = 0.0935015 loss)
I1003 12:37:33.598508  7223 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I1003 12:37:47.850054  7223 solver.cpp:218] Iteration 72200 (7.01679 iter/s, 14.2515s/100 iters), loss = 0.0805776
I1003 12:37:47.850184  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0805764 (* 1 = 0.0805764 loss)
I1003 12:37:47.850195  7223 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I1003 12:38:02.094840  7223 solver.cpp:218] Iteration 72300 (7.02018 iter/s, 14.2446s/100 iters), loss = 0.0352472
I1003 12:38:02.094883  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.035246 (* 1 = 0.035246 loss)
I1003 12:38:02.094890  7223 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I1003 12:38:16.350172  7223 solver.cpp:218] Iteration 72400 (7.01496 iter/s, 14.2553s/100 iters), loss = 0.0572311
I1003 12:38:16.350203  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0572299 (* 1 = 0.0572299 loss)
I1003 12:38:16.350209  7223 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I1003 12:38:29.897292  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:38:30.464500  7223 solver.cpp:330] Iteration 72500, Testing net (#0)
I1003 12:38:33.829584  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:38:33.969957  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8757
I1003 12:38:33.969982  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.480958 (* 1 = 0.480958 loss)
I1003 12:38:34.110293  7223 solver.cpp:218] Iteration 72500 (5.63061 iter/s, 17.7601s/100 iters), loss = 0.0548618
I1003 12:38:34.110324  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0548606 (* 1 = 0.0548606 loss)
I1003 12:38:34.110332  7223 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I1003 12:38:48.365321  7223 solver.cpp:218] Iteration 72600 (7.0151 iter/s, 14.255s/100 iters), loss = 0.0347275
I1003 12:38:48.365352  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0347263 (* 1 = 0.0347263 loss)
I1003 12:38:48.365358  7223 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I1003 12:39:02.634464  7223 solver.cpp:218] Iteration 72700 (7.00816 iter/s, 14.2691s/100 iters), loss = 0.0395291
I1003 12:39:02.634582  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.039528 (* 1 = 0.039528 loss)
I1003 12:39:02.634590  7223 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I1003 12:39:16.885102  7223 solver.cpp:218] Iteration 72800 (7.0173 iter/s, 14.2505s/100 iters), loss = 0.0316323
I1003 12:39:16.885131  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0316312 (* 1 = 0.0316312 loss)
I1003 12:39:16.885138  7223 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I1003 12:39:31.134758  7223 solver.cpp:218] Iteration 72900 (7.01774 iter/s, 14.2496s/100 iters), loss = 0.0359182
I1003 12:39:31.134790  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.035917 (* 1 = 0.035917 loss)
I1003 12:39:31.134798  7223 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I1003 12:39:44.693375  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:39:45.262361  7223 solver.cpp:330] Iteration 73000, Testing net (#0)
I1003 12:39:48.632237  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:39:48.772532  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8863
I1003 12:39:48.772569  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.442879 (* 1 = 0.442879 loss)
I1003 12:39:48.913463  7223 solver.cpp:218] Iteration 73000 (5.62473 iter/s, 17.7786s/100 iters), loss = 0.0650399
I1003 12:39:48.913498  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0650388 (* 1 = 0.0650388 loss)
I1003 12:39:48.913506  7223 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I1003 12:40:03.164957  7223 solver.cpp:218] Iteration 73100 (7.01693 iter/s, 14.2513s/100 iters), loss = 0.0134432
I1003 12:40:03.164988  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013442 (* 1 = 0.013442 loss)
I1003 12:40:03.164994  7223 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I1003 12:40:17.415102  7223 solver.cpp:218] Iteration 73200 (7.0175 iter/s, 14.2501s/100 iters), loss = 0.0505005
I1003 12:40:17.415232  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0504994 (* 1 = 0.0504994 loss)
I1003 12:40:17.415242  7223 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I1003 12:40:31.667716  7223 solver.cpp:218] Iteration 73300 (7.01633 iter/s, 14.2525s/100 iters), loss = 0.0217157
I1003 12:40:31.667747  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0217146 (* 1 = 0.0217146 loss)
I1003 12:40:31.667752  7223 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I1003 12:40:45.926426  7223 solver.cpp:218] Iteration 73400 (7.0133 iter/s, 14.2586s/100 iters), loss = 0.0171853
I1003 12:40:45.926486  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0171842 (* 1 = 0.0171842 loss)
I1003 12:40:45.926493  7223 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I1003 12:40:59.468392  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:41:00.036912  7223 solver.cpp:330] Iteration 73500, Testing net (#0)
I1003 12:41:03.403661  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:41:03.544160  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8899
I1003 12:41:03.544185  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.431543 (* 1 = 0.431543 loss)
I1003 12:41:03.685034  7223 solver.cpp:218] Iteration 73500 (5.6311 iter/s, 17.7585s/100 iters), loss = 0.0106541
I1003 12:41:03.685096  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010653 (* 1 = 0.010653 loss)
I1003 12:41:03.685107  7223 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I1003 12:41:17.940908  7223 solver.cpp:218] Iteration 73600 (7.01469 iter/s, 14.2558s/100 iters), loss = 0.0633632
I1003 12:41:17.940943  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.063362 (* 1 = 0.063362 loss)
I1003 12:41:17.940950  7223 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I1003 12:41:32.192687  7223 solver.cpp:218] Iteration 73700 (7.0167 iter/s, 14.2517s/100 iters), loss = 0.0180678
I1003 12:41:32.192836  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0180666 (* 1 = 0.0180666 loss)
I1003 12:41:32.192844  7223 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I1003 12:41:46.449810  7223 solver.cpp:218] Iteration 73800 (7.01414 iter/s, 14.2569s/100 iters), loss = 0.0167219
I1003 12:41:46.449846  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0167208 (* 1 = 0.0167208 loss)
I1003 12:41:46.449854  7223 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I1003 12:42:00.696189  7223 solver.cpp:218] Iteration 73900 (7.01936 iter/s, 14.2463s/100 iters), loss = 0.0154716
I1003 12:42:00.696223  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0154704 (* 1 = 0.0154704 loss)
I1003 12:42:00.696229  7223 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I1003 12:42:14.252832  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:42:14.826314  7223 solver.cpp:330] Iteration 74000, Testing net (#0)
I1003 12:42:18.194435  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:42:18.334143  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8896
I1003 12:42:18.334179  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.427618 (* 1 = 0.427618 loss)
I1003 12:42:18.475750  7223 solver.cpp:218] Iteration 74000 (5.62446 iter/s, 17.7795s/100 iters), loss = 0.0379316
I1003 12:42:18.475785  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0379304 (* 1 = 0.0379304 loss)
I1003 12:42:18.475793  7223 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I1003 12:42:32.722363  7223 solver.cpp:218] Iteration 74100 (7.01924 iter/s, 14.2465s/100 iters), loss = 0.0736741
I1003 12:42:32.722394  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0736729 (* 1 = 0.0736729 loss)
I1003 12:42:32.722400  7223 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I1003 12:42:46.973016  7223 solver.cpp:218] Iteration 74200 (7.01726 iter/s, 14.2506s/100 iters), loss = 0.0504815
I1003 12:42:46.973145  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0504803 (* 1 = 0.0504803 loss)
I1003 12:42:46.973155  7223 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I1003 12:43:01.242769  7223 solver.cpp:218] Iteration 74300 (7.00791 iter/s, 14.2696s/100 iters), loss = 0.0386256
I1003 12:43:01.242812  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0386244 (* 1 = 0.0386244 loss)
I1003 12:43:01.242820  7223 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I1003 12:43:15.503554  7223 solver.cpp:218] Iteration 74400 (7.01227 iter/s, 14.2607s/100 iters), loss = 0.0372782
I1003 12:43:15.503584  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.037277 (* 1 = 0.037277 loss)
I1003 12:43:15.503590  7223 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I1003 12:43:29.040071  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:43:29.617735  7223 solver.cpp:330] Iteration 74500, Testing net (#0)
I1003 12:43:32.985823  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:43:33.125639  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8789
I1003 12:43:33.125674  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.466256 (* 1 = 0.466256 loss)
I1003 12:43:33.266958  7223 solver.cpp:218] Iteration 74500 (5.62957 iter/s, 17.7633s/100 iters), loss = 0.056964
I1003 12:43:33.266988  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0569628 (* 1 = 0.0569628 loss)
I1003 12:43:33.266995  7223 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I1003 12:43:47.531931  7223 solver.cpp:218] Iteration 74600 (7.01021 iter/s, 14.2649s/100 iters), loss = 0.0346293
I1003 12:43:47.531965  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0346281 (* 1 = 0.0346281 loss)
I1003 12:43:47.531972  7223 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I1003 12:44:01.789455  7223 solver.cpp:218] Iteration 74700 (7.01387 iter/s, 14.2575s/100 iters), loss = 0.0447815
I1003 12:44:01.789599  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0447802 (* 1 = 0.0447802 loss)
I1003 12:44:01.789607  7223 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I1003 12:44:16.034684  7223 solver.cpp:218] Iteration 74800 (7.01997 iter/s, 14.2451s/100 iters), loss = 0.161807
I1003 12:44:16.034716  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161806 (* 1 = 0.161806 loss)
I1003 12:44:16.034723  7223 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I1003 12:44:30.297106  7223 solver.cpp:218] Iteration 74900 (7.01146 iter/s, 14.2624s/100 iters), loss = 0.0613954
I1003 12:44:30.297137  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0613942 (* 1 = 0.0613942 loss)
I1003 12:44:30.297142  7223 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I1003 12:44:43.840673  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:44:44.418458  7223 solver.cpp:330] Iteration 75000, Testing net (#0)
I1003 12:44:47.786272  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:44:47.926306  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8786
I1003 12:44:47.926332  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.461139 (* 1 = 0.461139 loss)
I1003 12:44:48.068171  7223 solver.cpp:218] Iteration 75000 (5.62715 iter/s, 17.771s/100 iters), loss = 0.0505775
I1003 12:44:48.068217  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0505762 (* 1 = 0.0505762 loss)
I1003 12:44:48.068225  7223 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I1003 12:45:02.315573  7223 solver.cpp:218] Iteration 75100 (7.01886 iter/s, 14.2473s/100 iters), loss = 0.0705895
I1003 12:45:02.315608  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0705882 (* 1 = 0.0705882 loss)
I1003 12:45:02.315615  7223 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I1003 12:45:16.571763  7223 solver.cpp:218] Iteration 75200 (7.01453 iter/s, 14.2561s/100 iters), loss = 0.0238636
I1003 12:45:16.571912  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0238623 (* 1 = 0.0238623 loss)
I1003 12:45:16.571919  7223 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I1003 12:45:30.832128  7223 solver.cpp:218] Iteration 75300 (7.01253 iter/s, 14.2602s/100 iters), loss = 0.0947231
I1003 12:45:30.832160  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0947219 (* 1 = 0.0947219 loss)
I1003 12:45:30.832166  7223 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I1003 12:45:45.089867  7223 solver.cpp:218] Iteration 75400 (7.01377 iter/s, 14.2577s/100 iters), loss = 0.0324887
I1003 12:45:45.089908  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0324874 (* 1 = 0.0324874 loss)
I1003 12:45:45.089915  7223 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I1003 12:45:58.630676  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:45:59.202695  7223 solver.cpp:330] Iteration 75500, Testing net (#0)
I1003 12:46:02.579493  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:46:02.719988  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.884
I1003 12:46:02.720013  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.475326 (* 1 = 0.475326 loss)
I1003 12:46:02.861517  7223 solver.cpp:218] Iteration 75500 (5.62697 iter/s, 17.7716s/100 iters), loss = 0.0300862
I1003 12:46:02.861548  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.030085 (* 1 = 0.030085 loss)
I1003 12:46:02.861555  7223 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I1003 12:46:17.106917  7223 solver.cpp:218] Iteration 75600 (7.01984 iter/s, 14.2453s/100 iters), loss = 0.0495139
I1003 12:46:17.106947  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0495126 (* 1 = 0.0495126 loss)
I1003 12:46:17.106953  7223 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I1003 12:46:31.359805  7223 solver.cpp:218] Iteration 75700 (7.01615 iter/s, 14.2528s/100 iters), loss = 0.0949492
I1003 12:46:31.359920  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0949479 (* 1 = 0.0949479 loss)
I1003 12:46:31.359928  7223 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I1003 12:46:45.614672  7223 solver.cpp:218] Iteration 75800 (7.01522 iter/s, 14.2547s/100 iters), loss = 0.0471868
I1003 12:46:45.614706  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0471855 (* 1 = 0.0471855 loss)
I1003 12:46:45.614712  7223 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I1003 12:46:59.875870  7223 solver.cpp:218] Iteration 75900 (7.01207 iter/s, 14.2611s/100 iters), loss = 0.0310067
I1003 12:46:59.875901  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0310054 (* 1 = 0.0310054 loss)
I1003 12:46:59.875907  7223 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I1003 12:47:13.416081  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:47:13.984818  7223 solver.cpp:330] Iteration 76000, Testing net (#0)
I1003 12:47:17.356673  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:47:17.499025  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8888
I1003 12:47:17.499053  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.438881 (* 1 = 0.438881 loss)
I1003 12:47:17.639884  7223 solver.cpp:218] Iteration 76000 (5.62938 iter/s, 17.7639s/100 iters), loss = 0.034145
I1003 12:47:17.639920  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0341437 (* 1 = 0.0341437 loss)
I1003 12:47:17.639928  7223 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I1003 12:47:31.875607  7223 solver.cpp:218] Iteration 76100 (7.02462 iter/s, 14.2357s/100 iters), loss = 0.0317805
I1003 12:47:31.875648  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0317793 (* 1 = 0.0317793 loss)
I1003 12:47:31.875653  7223 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I1003 12:47:46.126281  7223 solver.cpp:218] Iteration 76200 (7.01725 iter/s, 14.2506s/100 iters), loss = 0.0456705
I1003 12:47:46.126394  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0456692 (* 1 = 0.0456692 loss)
I1003 12:47:46.126400  7223 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I1003 12:48:00.382920  7223 solver.cpp:218] Iteration 76300 (7.01434 iter/s, 14.2565s/100 iters), loss = 0.0183906
I1003 12:48:00.382951  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0183894 (* 1 = 0.0183894 loss)
I1003 12:48:00.382957  7223 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I1003 12:48:14.624742  7223 solver.cpp:218] Iteration 76400 (7.02161 iter/s, 14.2418s/100 iters), loss = 0.0163463
I1003 12:48:14.624783  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.016345 (* 1 = 0.016345 loss)
I1003 12:48:14.624790  7223 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I1003 12:48:28.164212  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:48:28.732889  7223 solver.cpp:330] Iteration 76500, Testing net (#0)
I1003 12:48:32.101194  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:48:32.243697  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8815
I1003 12:48:32.243739  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.492721 (* 1 = 0.492721 loss)
I1003 12:48:32.389739  7223 solver.cpp:218] Iteration 76500 (5.62907 iter/s, 17.7649s/100 iters), loss = 0.0493729
I1003 12:48:32.389780  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0493717 (* 1 = 0.0493717 loss)
I1003 12:48:32.389801  7223 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I1003 12:48:46.643383  7223 solver.cpp:218] Iteration 76600 (7.01589 iter/s, 14.2534s/100 iters), loss = 0.0549554
I1003 12:48:46.643424  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0549542 (* 1 = 0.0549542 loss)
I1003 12:48:46.643430  7223 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I1003 12:49:00.890450  7223 solver.cpp:218] Iteration 76700 (7.01903 iter/s, 14.247s/100 iters), loss = 0.0356365
I1003 12:49:00.890552  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0356353 (* 1 = 0.0356353 loss)
I1003 12:49:00.890560  7223 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I1003 12:49:15.147090  7223 solver.cpp:218] Iteration 76800 (7.01434 iter/s, 14.2565s/100 iters), loss = 0.031092
I1003 12:49:15.147132  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0310909 (* 1 = 0.0310909 loss)
I1003 12:49:15.147138  7223 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I1003 12:49:29.403198  7223 solver.cpp:218] Iteration 76900 (7.01458 iter/s, 14.256s/100 iters), loss = 0.052583
I1003 12:49:29.403246  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0525818 (* 1 = 0.0525818 loss)
I1003 12:49:29.403254  7223 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I1003 12:49:42.938087  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:49:43.505863  7223 solver.cpp:330] Iteration 77000, Testing net (#0)
I1003 12:49:46.873860  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:49:47.014199  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8936
I1003 12:49:47.014235  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.42998 (* 1 = 0.42998 loss)
I1003 12:49:47.155153  7223 solver.cpp:218] Iteration 77000 (5.63322 iter/s, 17.7518s/100 iters), loss = 0.0336444
I1003 12:49:47.155192  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0336432 (* 1 = 0.0336432 loss)
I1003 12:49:47.155199  7223 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I1003 12:50:01.405901  7223 solver.cpp:218] Iteration 77100 (7.01726 iter/s, 14.2506s/100 iters), loss = 0.0252915
I1003 12:50:01.405933  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0252904 (* 1 = 0.0252904 loss)
I1003 12:50:01.405939  7223 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I1003 12:50:15.667685  7223 solver.cpp:218] Iteration 77200 (7.01178 iter/s, 14.2617s/100 iters), loss = 0.150807
I1003 12:50:15.667803  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.150806 (* 1 = 0.150806 loss)
I1003 12:50:15.667809  7223 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I1003 12:50:29.926337  7223 solver.cpp:218] Iteration 77300 (7.01336 iter/s, 14.2585s/100 iters), loss = 0.0210233
I1003 12:50:29.926379  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0210221 (* 1 = 0.0210221 loss)
I1003 12:50:29.926385  7223 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I1003 12:50:44.168179  7223 solver.cpp:218] Iteration 77400 (7.0216 iter/s, 14.2418s/100 iters), loss = 0.032905
I1003 12:50:44.168218  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0329039 (* 1 = 0.0329039 loss)
I1003 12:50:44.168225  7223 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I1003 12:50:57.724979  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:50:58.294162  7223 solver.cpp:330] Iteration 77500, Testing net (#0)
I1003 12:51:01.664206  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:51:01.804349  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.879
I1003 12:51:01.804385  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.453734 (* 1 = 0.453734 loss)
I1003 12:51:01.945847  7223 solver.cpp:218] Iteration 77500 (5.62506 iter/s, 17.7776s/100 iters), loss = 0.0491021
I1003 12:51:01.945875  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0491009 (* 1 = 0.0491009 loss)
I1003 12:51:01.945883  7223 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I1003 12:51:16.201203  7223 solver.cpp:218] Iteration 77600 (7.01494 iter/s, 14.2553s/100 iters), loss = 0.0146803
I1003 12:51:16.201236  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146791 (* 1 = 0.0146791 loss)
I1003 12:51:16.201252  7223 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I1003 12:51:30.452198  7223 solver.cpp:218] Iteration 77700 (7.01709 iter/s, 14.2509s/100 iters), loss = 0.0521073
I1003 12:51:30.452316  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0521061 (* 1 = 0.0521061 loss)
I1003 12:51:30.452337  7223 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I1003 12:51:44.712669  7223 solver.cpp:218] Iteration 77800 (7.01246 iter/s, 14.2603s/100 iters), loss = 0.0283993
I1003 12:51:44.712702  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0283981 (* 1 = 0.0283981 loss)
I1003 12:51:44.712718  7223 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I1003 12:51:58.961707  7223 solver.cpp:218] Iteration 77900 (7.01805 iter/s, 14.249s/100 iters), loss = 0.0230751
I1003 12:51:58.961738  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0230739 (* 1 = 0.0230739 loss)
I1003 12:51:58.961745  7223 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I1003 12:52:12.509326  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:52:13.078387  7223 solver.cpp:330] Iteration 78000, Testing net (#0)
I1003 12:52:16.443536  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:52:16.583616  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8902
I1003 12:52:16.583652  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.4379 (* 1 = 0.4379 loss)
I1003 12:52:16.724293  7223 solver.cpp:218] Iteration 78000 (5.62983 iter/s, 17.7625s/100 iters), loss = 0.0304813
I1003 12:52:16.724326  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0304801 (* 1 = 0.0304801 loss)
I1003 12:52:16.724333  7223 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I1003 12:52:30.969684  7223 solver.cpp:218] Iteration 78100 (7.01985 iter/s, 14.2453s/100 iters), loss = 0.0640833
I1003 12:52:30.969715  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0640821 (* 1 = 0.0640821 loss)
I1003 12:52:30.969722  7223 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I1003 12:52:45.226750  7223 solver.cpp:218] Iteration 78200 (7.0141 iter/s, 14.257s/100 iters), loss = 0.0594544
I1003 12:52:45.226897  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0594532 (* 1 = 0.0594532 loss)
I1003 12:52:45.226904  7223 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I1003 12:52:59.475677  7223 solver.cpp:218] Iteration 78300 (7.01816 iter/s, 14.2487s/100 iters), loss = 0.00956459
I1003 12:52:59.475723  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00956342 (* 1 = 0.00956342 loss)
I1003 12:52:59.475731  7223 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I1003 12:53:13.718008  7223 solver.cpp:218] Iteration 78400 (7.02138 iter/s, 14.2422s/100 iters), loss = 0.0108888
I1003 12:53:13.718039  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108877 (* 1 = 0.0108877 loss)
I1003 12:53:13.718045  7223 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I1003 12:53:27.266885  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:53:27.834183  7223 solver.cpp:330] Iteration 78500, Testing net (#0)
I1003 12:53:31.201300  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:53:31.341742  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.883
I1003 12:53:31.341778  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.45124 (* 1 = 0.45124 loss)
I1003 12:53:31.482332  7223 solver.cpp:218] Iteration 78500 (5.62928 iter/s, 17.7642s/100 iters), loss = 0.016363
I1003 12:53:31.482360  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0163619 (* 1 = 0.0163619 loss)
I1003 12:53:31.482367  7223 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I1003 12:53:45.725785  7223 solver.cpp:218] Iteration 78600 (7.0208 iter/s, 14.2434s/100 iters), loss = 0.0209676
I1003 12:53:45.725816  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0209665 (* 1 = 0.0209665 loss)
I1003 12:53:45.725822  7223 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I1003 12:53:59.980885  7223 solver.cpp:218] Iteration 78700 (7.01507 iter/s, 14.255s/100 iters), loss = 0.0238203
I1003 12:53:59.981003  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0238192 (* 1 = 0.0238192 loss)
I1003 12:53:59.981010  7223 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I1003 12:54:14.234086  7223 solver.cpp:218] Iteration 78800 (7.01604 iter/s, 14.253s/100 iters), loss = 0.026421
I1003 12:54:14.234122  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0264199 (* 1 = 0.0264199 loss)
I1003 12:54:14.234128  7223 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I1003 12:54:28.486351  7223 solver.cpp:218] Iteration 78900 (7.01646 iter/s, 14.2522s/100 iters), loss = 0.0402603
I1003 12:54:28.486383  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0402591 (* 1 = 0.0402591 loss)
I1003 12:54:28.486389  7223 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I1003 12:54:42.027420  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:54:42.596238  7223 solver.cpp:330] Iteration 79000, Testing net (#0)
I1003 12:54:45.961869  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:54:46.101701  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8863
I1003 12:54:46.101737  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.4447 (* 1 = 0.4447 loss)
I1003 12:54:46.243165  7223 solver.cpp:218] Iteration 79000 (5.63167 iter/s, 17.7567s/100 iters), loss = 0.0883266
I1003 12:54:46.243193  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0883255 (* 1 = 0.0883255 loss)
I1003 12:54:46.243201  7223 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I1003 12:55:00.497874  7223 solver.cpp:218] Iteration 79100 (7.01526 iter/s, 14.2546s/100 iters), loss = 0.036669
I1003 12:55:00.497905  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0366678 (* 1 = 0.0366678 loss)
I1003 12:55:00.497910  7223 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I1003 12:55:14.750955  7223 solver.cpp:218] Iteration 79200 (7.01606 iter/s, 14.253s/100 iters), loss = 0.0423456
I1003 12:55:14.751073  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0423445 (* 1 = 0.0423445 loss)
I1003 12:55:14.751091  7223 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I1003 12:55:28.994566  7223 solver.cpp:218] Iteration 79300 (7.02077 iter/s, 14.2435s/100 iters), loss = 0.00888089
I1003 12:55:28.994626  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00887974 (* 1 = 0.00887974 loss)
I1003 12:55:28.994633  7223 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I1003 12:55:43.251793  7223 solver.cpp:218] Iteration 79400 (7.01403 iter/s, 14.2571s/100 iters), loss = 0.0231923
I1003 12:55:43.251827  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0231911 (* 1 = 0.0231911 loss)
I1003 12:55:43.251832  7223 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I1003 12:55:56.807096  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:55:57.376605  7223 solver.cpp:330] Iteration 79500, Testing net (#0)
I1003 12:56:00.745031  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:56:00.885092  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.888
I1003 12:56:00.885118  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.428323 (* 1 = 0.428323 loss)
I1003 12:56:01.026549  7223 solver.cpp:218] Iteration 79500 (5.62598 iter/s, 17.7747s/100 iters), loss = 0.0499266
I1003 12:56:01.026583  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0499255 (* 1 = 0.0499255 loss)
I1003 12:56:01.026590  7223 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I1003 12:56:15.274324  7223 solver.cpp:218] Iteration 79600 (7.01869 iter/s, 14.2477s/100 iters), loss = 0.0507151
I1003 12:56:15.274355  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.050714 (* 1 = 0.050714 loss)
I1003 12:56:15.274361  7223 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I1003 12:56:29.542872  7223 solver.cpp:218] Iteration 79700 (7.00846 iter/s, 14.2685s/100 iters), loss = 0.0293035
I1003 12:56:29.542989  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0293023 (* 1 = 0.0293023 loss)
I1003 12:56:29.543009  7223 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I1003 12:56:43.801229  7223 solver.cpp:218] Iteration 79800 (7.0135 iter/s, 14.2582s/100 iters), loss = 0.0309971
I1003 12:56:43.801278  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.030996 (* 1 = 0.030996 loss)
I1003 12:56:43.801285  7223 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I1003 12:56:58.057636  7223 solver.cpp:218] Iteration 79900 (7.01443 iter/s, 14.2563s/100 iters), loss = 0.0158666
I1003 12:56:58.057667  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0158655 (* 1 = 0.0158655 loss)
I1003 12:56:58.057673  7223 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I1003 12:57:11.614663  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:57:12.182307  7223 solver.cpp:330] Iteration 80000, Testing net (#0)
I1003 12:57:15.549448  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:57:15.689628  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8888
I1003 12:57:15.689664  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.424034 (* 1 = 0.424034 loss)
I1003 12:57:15.830883  7223 solver.cpp:218] Iteration 80000 (5.62646 iter/s, 17.7732s/100 iters), loss = 0.0359866
I1003 12:57:15.830916  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0359855 (* 1 = 0.0359855 loss)
I1003 12:57:15.830924  7223 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I1003 12:57:15.830927  7223 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I1003 12:57:30.093499  7223 solver.cpp:218] Iteration 80100 (7.01137 iter/s, 14.2625s/100 iters), loss = 0.0371639
I1003 12:57:30.093531  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0371627 (* 1 = 0.0371627 loss)
I1003 12:57:30.093538  7223 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I1003 12:57:44.342527  7223 solver.cpp:218] Iteration 80200 (7.01806 iter/s, 14.249s/100 iters), loss = 0.0432453
I1003 12:57:44.342679  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0432442 (* 1 = 0.0432442 loss)
I1003 12:57:44.342687  7223 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I1003 12:57:58.595494  7223 solver.cpp:218] Iteration 80300 (7.01618 iter/s, 14.2528s/100 iters), loss = 0.00670695
I1003 12:57:58.595525  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00670583 (* 1 = 0.00670583 loss)
I1003 12:57:58.595531  7223 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I1003 12:58:12.854509  7223 solver.cpp:218] Iteration 80400 (7.01314 iter/s, 14.2589s/100 iters), loss = 0.0349656
I1003 12:58:12.854544  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0349645 (* 1 = 0.0349645 loss)
I1003 12:58:12.854550  7223 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I1003 12:58:26.402570  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:58:26.974377  7223 solver.cpp:330] Iteration 80500, Testing net (#0)
I1003 12:58:30.338294  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:58:30.478940  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9039
I1003 12:58:30.478976  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.359591 (* 1 = 0.359591 loss)
I1003 12:58:30.620084  7223 solver.cpp:218] Iteration 80500 (5.62889 iter/s, 17.7655s/100 iters), loss = 0.0293173
I1003 12:58:30.620128  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0293162 (* 1 = 0.0293162 loss)
I1003 12:58:30.620148  7223 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I1003 12:58:44.863935  7223 solver.cpp:218] Iteration 80600 (7.02073 iter/s, 14.2435s/100 iters), loss = 0.0409806
I1003 12:58:44.863967  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0409795 (* 1 = 0.0409795 loss)
I1003 12:58:44.863975  7223 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I1003 12:58:59.118178  7223 solver.cpp:218] Iteration 80700 (7.01549 iter/s, 14.2542s/100 iters), loss = 0.0206894
I1003 12:58:59.118293  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0206882 (* 1 = 0.0206882 loss)
I1003 12:58:59.118299  7223 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I1003 12:59:13.373606  7223 solver.cpp:218] Iteration 80800 (7.01494 iter/s, 14.2553s/100 iters), loss = 0.0111367
I1003 12:59:13.373638  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111356 (* 1 = 0.0111356 loss)
I1003 12:59:13.373644  7223 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I1003 12:59:27.614877  7223 solver.cpp:218] Iteration 80900 (7.02188 iter/s, 14.2412s/100 iters), loss = 0.0167373
I1003 12:59:27.614909  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0167362 (* 1 = 0.0167362 loss)
I1003 12:59:27.614915  7223 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I1003 12:59:41.148059  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:59:41.726790  7223 solver.cpp:330] Iteration 81000, Testing net (#0)
I1003 12:59:45.095947  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:59:45.236096  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.907
I1003 12:59:45.236133  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.355603 (* 1 = 0.355603 loss)
I1003 12:59:45.377076  7223 solver.cpp:218] Iteration 81000 (5.62996 iter/s, 17.7621s/100 iters), loss = 0.0288257
I1003 12:59:45.377106  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0288246 (* 1 = 0.0288246 loss)
I1003 12:59:45.377113  7223 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I1003 12:59:59.624034  7223 solver.cpp:218] Iteration 81100 (7.0191 iter/s, 14.2468s/100 iters), loss = 0.0170155
I1003 12:59:59.624069  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0170144 (* 1 = 0.0170144 loss)
I1003 12:59:59.624076  7223 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I1003 13:00:13.858469  7223 solver.cpp:218] Iteration 81200 (7.02525 iter/s, 14.2344s/100 iters), loss = 0.00755794
I1003 13:00:13.858592  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00755684 (* 1 = 0.00755684 loss)
I1003 13:00:13.858600  7223 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I1003 13:00:28.104503  7223 solver.cpp:218] Iteration 81300 (7.01957 iter/s, 14.2459s/100 iters), loss = 0.00338606
I1003 13:00:28.104534  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00338496 (* 1 = 0.00338496 loss)
I1003 13:00:28.104540  7223 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I1003 13:00:42.348976  7223 solver.cpp:218] Iteration 81400 (7.0203 iter/s, 14.2444s/100 iters), loss = 0.0449371
I1003 13:00:42.349006  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.044936 (* 1 = 0.044936 loss)
I1003 13:00:42.349012  7223 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I1003 13:00:55.885792  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:00:56.459491  7223 solver.cpp:330] Iteration 81500, Testing net (#0)
I1003 13:00:59.827338  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:00:59.967638  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9083
I1003 13:00:59.967664  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358151 (* 1 = 0.358151 loss)
I1003 13:01:00.109118  7223 solver.cpp:218] Iteration 81500 (5.63061 iter/s, 17.7601s/100 iters), loss = 0.0210442
I1003 13:01:00.109151  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0210431 (* 1 = 0.0210431 loss)
I1003 13:01:00.109158  7223 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I1003 13:01:14.354490  7223 solver.cpp:218] Iteration 81600 (7.01986 iter/s, 14.2453s/100 iters), loss = 0.0248857
I1003 13:01:14.354529  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0248846 (* 1 = 0.0248846 loss)
I1003 13:01:14.354537  7223 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I1003 13:01:28.607535  7223 solver.cpp:218] Iteration 81700 (7.01608 iter/s, 14.253s/100 iters), loss = 0.0293138
I1003 13:01:28.607655  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0293127 (* 1 = 0.0293127 loss)
I1003 13:01:28.607661  7223 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I1003 13:01:42.852960  7223 solver.cpp:218] Iteration 81800 (7.01988 iter/s, 14.2453s/100 iters), loss = 0.00548491
I1003 13:01:42.852993  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00548383 (* 1 = 0.00548383 loss)
I1003 13:01:42.852999  7223 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I1003 13:01:57.106709  7223 solver.cpp:218] Iteration 81900 (7.01573 iter/s, 14.2537s/100 iters), loss = 0.00726948
I1003 13:01:57.106740  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0072684 (* 1 = 0.0072684 loss)
I1003 13:01:57.106746  7223 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I1003 13:02:10.645776  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:02:11.212980  7223 solver.cpp:330] Iteration 82000, Testing net (#0)
I1003 13:02:14.591859  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:02:14.731921  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9069
I1003 13:02:14.731957  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.360944 (* 1 = 0.360944 loss)
I1003 13:02:14.873189  7223 solver.cpp:218] Iteration 82000 (5.6286 iter/s, 17.7664s/100 iters), loss = 0.00505217
I1003 13:02:14.873224  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00505109 (* 1 = 0.00505109 loss)
I1003 13:02:14.873230  7223 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I1003 13:02:29.117964  7223 solver.cpp:218] Iteration 82100 (7.02015 iter/s, 14.2447s/100 iters), loss = 0.0456907
I1003 13:02:29.117995  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0456896 (* 1 = 0.0456896 loss)
I1003 13:02:29.118001  7223 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I1003 13:02:43.371024  7223 solver.cpp:218] Iteration 82200 (7.01607 iter/s, 14.253s/100 iters), loss = 0.0146833
I1003 13:02:43.371196  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146822 (* 1 = 0.0146822 loss)
I1003 13:02:43.371206  7223 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I1003 13:02:57.626718  7223 solver.cpp:218] Iteration 82300 (7.01484 iter/s, 14.2555s/100 iters), loss = 0.00443434
I1003 13:02:57.626747  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00443325 (* 1 = 0.00443325 loss)
I1003 13:02:57.626752  7223 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I1003 13:03:11.885712  7223 solver.cpp:218] Iteration 82400 (7.01315 iter/s, 14.2589s/100 iters), loss = 0.0252793
I1003 13:03:11.885741  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0252782 (* 1 = 0.0252782 loss)
I1003 13:03:11.885747  7223 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I1003 13:03:25.416081  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:03:25.983817  7223 solver.cpp:330] Iteration 82500, Testing net (#0)
I1003 13:03:29.352136  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:03:29.495923  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9076
I1003 13:03:29.495950  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.361541 (* 1 = 0.361541 loss)
I1003 13:03:29.638459  7223 solver.cpp:218] Iteration 82500 (5.63296 iter/s, 17.7527s/100 iters), loss = 0.0526629
I1003 13:03:29.638496  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0526618 (* 1 = 0.0526618 loss)
I1003 13:03:29.638504  7223 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I1003 13:03:43.888077  7223 solver.cpp:218] Iteration 82600 (7.01777 iter/s, 14.2495s/100 iters), loss = 0.0324402
I1003 13:03:43.888118  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0324391 (* 1 = 0.0324391 loss)
I1003 13:03:43.888124  7223 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I1003 13:03:58.147464  7223 solver.cpp:218] Iteration 82700 (7.01296 iter/s, 14.2593s/100 iters), loss = 0.015834
I1003 13:03:58.147577  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0158329 (* 1 = 0.0158329 loss)
I1003 13:03:58.147583  7223 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I1003 13:04:12.406826  7223 solver.cpp:218] Iteration 82800 (7.01301 iter/s, 14.2592s/100 iters), loss = 0.00903365
I1003 13:04:12.406857  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00903255 (* 1 = 0.00903255 loss)
I1003 13:04:12.406862  7223 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I1003 13:04:26.674105  7223 solver.cpp:218] Iteration 82900 (7.00908 iter/s, 14.2672s/100 iters), loss = 0.00774422
I1003 13:04:26.674149  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00774312 (* 1 = 0.00774312 loss)
I1003 13:04:26.674155  7223 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I1003 13:04:40.220124  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:04:40.788880  7223 solver.cpp:330] Iteration 83000, Testing net (#0)
I1003 13:04:44.157017  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:04:44.299211  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9082
I1003 13:04:44.299249  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.362262 (* 1 = 0.362262 loss)
I1003 13:04:44.444437  7223 solver.cpp:218] Iteration 83000 (5.62739 iter/s, 17.7702s/100 iters), loss = 0.0137692
I1003 13:04:44.444483  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0137681 (* 1 = 0.0137681 loss)
I1003 13:04:44.444490  7223 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I1003 13:04:58.687613  7223 solver.cpp:218] Iteration 83100 (7.02096 iter/s, 14.2431s/100 iters), loss = 0.024308
I1003 13:04:58.687644  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0243069 (* 1 = 0.0243069 loss)
I1003 13:04:58.687650  7223 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I1003 13:05:12.949723  7223 solver.cpp:218] Iteration 83200 (7.01162 iter/s, 14.262s/100 iters), loss = 0.0133983
I1003 13:05:12.949848  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0133973 (* 1 = 0.0133973 loss)
I1003 13:05:12.949857  7223 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I1003 13:05:27.216174  7223 solver.cpp:218] Iteration 83300 (7.00953 iter/s, 14.2663s/100 iters), loss = 0.0353101
I1003 13:05:27.216207  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.035309 (* 1 = 0.035309 loss)
I1003 13:05:27.216213  7223 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I1003 13:05:41.470322  7223 solver.cpp:218] Iteration 83400 (7.01554 iter/s, 14.2541s/100 iters), loss = 0.0100517
I1003 13:05:41.470360  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100506 (* 1 = 0.0100506 loss)
I1003 13:05:41.470367  7223 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I1003 13:05:55.006201  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:05:55.575866  7223 solver.cpp:330] Iteration 83500, Testing net (#0)
I1003 13:05:58.943181  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:05:59.083370  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9089
I1003 13:05:59.083406  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.360538 (* 1 = 0.360538 loss)
I1003 13:05:59.224436  7223 solver.cpp:218] Iteration 83500 (5.63252 iter/s, 17.754s/100 iters), loss = 0.0203714
I1003 13:05:59.224464  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0203703 (* 1 = 0.0203703 loss)
I1003 13:05:59.224470  7223 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I1003 13:06:13.479518  7223 solver.cpp:218] Iteration 83600 (7.01514 iter/s, 14.2549s/100 iters), loss = 0.0063888
I1003 13:06:13.479550  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0063877 (* 1 = 0.0063877 loss)
I1003 13:06:13.479557  7223 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I1003 13:06:27.733822  7223 solver.cpp:218] Iteration 83700 (7.01546 iter/s, 14.2542s/100 iters), loss = 0.0309885
I1003 13:06:27.733937  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0309874 (* 1 = 0.0309874 loss)
I1003 13:06:27.733947  7223 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I1003 13:06:41.980278  7223 solver.cpp:218] Iteration 83800 (7.01936 iter/s, 14.2463s/100 iters), loss = 0.018366
I1003 13:06:41.980310  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0183649 (* 1 = 0.0183649 loss)
I1003 13:06:41.980319  7223 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I1003 13:06:56.224144  7223 solver.cpp:218] Iteration 83900 (7.0206 iter/s, 14.2438s/100 iters), loss = 0.00458106
I1003 13:06:56.224177  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00457995 (* 1 = 0.00457995 loss)
I1003 13:06:56.224185  7223 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I1003 13:07:09.782958  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:07:10.352392  7223 solver.cpp:330] Iteration 84000, Testing net (#0)
I1003 13:07:13.720582  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:07:13.861043  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9079
I1003 13:07:13.861069  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.363158 (* 1 = 0.363158 loss)
I1003 13:07:14.002157  7223 solver.cpp:218] Iteration 84000 (5.62495 iter/s, 17.7779s/100 iters), loss = 0.00992424
I1003 13:07:14.002189  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00992313 (* 1 = 0.00992313 loss)
I1003 13:07:14.002199  7223 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I1003 13:07:28.241444  7223 solver.cpp:218] Iteration 84100 (7.02286 iter/s, 14.2392s/100 iters), loss = 0.0304575
I1003 13:07:28.241475  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0304564 (* 1 = 0.0304564 loss)
I1003 13:07:28.241482  7223 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I1003 13:07:42.499493  7223 solver.cpp:218] Iteration 84200 (7.01362 iter/s, 14.258s/100 iters), loss = 0.0235876
I1003 13:07:42.499600  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0235865 (* 1 = 0.0235865 loss)
I1003 13:07:42.499608  7223 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I1003 13:07:56.753008  7223 solver.cpp:218] Iteration 84300 (7.01588 iter/s, 14.2534s/100 iters), loss = 0.00863437
I1003 13:07:56.753043  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00863326 (* 1 = 0.00863326 loss)
I1003 13:07:56.753059  7223 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I1003 13:08:10.987354  7223 solver.cpp:218] Iteration 84400 (7.0253 iter/s, 14.2343s/100 iters), loss = 0.0202559
I1003 13:08:10.987385  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0202548 (* 1 = 0.0202548 loss)
I1003 13:08:10.987402  7223 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I1003 13:08:24.535563  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:08:25.104202  7223 solver.cpp:330] Iteration 84500, Testing net (#0)
I1003 13:08:28.474957  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:08:28.615226  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9088
I1003 13:08:28.615262  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364532 (* 1 = 0.364532 loss)
I1003 13:08:28.756623  7223 solver.cpp:218] Iteration 84500 (5.62772 iter/s, 17.7692s/100 iters), loss = 0.0145446
I1003 13:08:28.756656  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145435 (* 1 = 0.0145435 loss)
I1003 13:08:28.756664  7223 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I1003 13:08:43.019701  7223 solver.cpp:218] Iteration 84600 (7.01115 iter/s, 14.263s/100 iters), loss = 0.02582
I1003 13:08:43.019733  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0258189 (* 1 = 0.0258189 loss)
I1003 13:08:43.019739  7223 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I1003 13:08:57.286253  7223 solver.cpp:218] Iteration 84700 (7.00944 iter/s, 14.2665s/100 iters), loss = 0.0363547
I1003 13:08:57.286361  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0363536 (* 1 = 0.0363536 loss)
I1003 13:08:57.286368  7223 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I1003 13:09:11.547865  7223 solver.cpp:218] Iteration 84800 (7.01191 iter/s, 14.2615s/100 iters), loss = 0.00314359
I1003 13:09:11.547901  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00314249 (* 1 = 0.00314249 loss)
I1003 13:09:11.547910  7223 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I1003 13:09:25.811908  7223 solver.cpp:218] Iteration 84900 (7.01067 iter/s, 14.264s/100 iters), loss = 0.00700165
I1003 13:09:25.811949  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00700055 (* 1 = 0.00700055 loss)
I1003 13:09:25.811955  7223 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I1003 13:09:39.370443  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:09:39.939168  7223 solver.cpp:330] Iteration 85000, Testing net (#0)
I1003 13:09:43.305712  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:09:43.445955  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9087
I1003 13:09:43.445989  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367077 (* 1 = 0.367077 loss)
I1003 13:09:43.587126  7223 solver.cpp:218] Iteration 85000 (5.62584 iter/s, 17.7751s/100 iters), loss = 0.0138351
I1003 13:09:43.587155  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013834 (* 1 = 0.013834 loss)
I1003 13:09:43.587162  7223 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I1003 13:09:57.845238  7223 solver.cpp:218] Iteration 85100 (7.0136 iter/s, 14.258s/100 iters), loss = 0.0441968
I1003 13:09:57.845280  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0441957 (* 1 = 0.0441957 loss)
I1003 13:09:57.845286  7223 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I1003 13:10:12.114540  7223 solver.cpp:218] Iteration 85200 (7.0081 iter/s, 14.2692s/100 iters), loss = 0.0364443
I1003 13:10:12.114667  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0364432 (* 1 = 0.0364432 loss)
I1003 13:10:12.114686  7223 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I1003 13:10:26.371186  7223 solver.cpp:218] Iteration 85300 (7.01435 iter/s, 14.2565s/100 iters), loss = 0.0143052
I1003 13:10:26.371233  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143041 (* 1 = 0.0143041 loss)
I1003 13:10:26.371242  7223 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I1003 13:10:40.619367  7223 solver.cpp:218] Iteration 85400 (7.0185 iter/s, 14.2481s/100 iters), loss = 0.00279912
I1003 13:10:40.619397  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00279803 (* 1 = 0.00279803 loss)
I1003 13:10:40.619403  7223 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I1003 13:10:54.182575  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:10:54.750538  7223 solver.cpp:330] Iteration 85500, Testing net (#0)
I1003 13:10:58.119693  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:10:58.260053  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9082
I1003 13:10:58.260089  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365479 (* 1 = 0.365479 loss)
I1003 13:10:58.401126  7223 solver.cpp:218] Iteration 85500 (5.62377 iter/s, 17.7817s/100 iters), loss = 0.0335378
I1003 13:10:58.401157  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0335367 (* 1 = 0.0335367 loss)
I1003 13:10:58.401165  7223 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I1003 13:11:12.655908  7223 solver.cpp:218] Iteration 85600 (7.01523 iter/s, 14.2547s/100 iters), loss = 0.00373266
I1003 13:11:12.655948  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00373155 (* 1 = 0.00373155 loss)
I1003 13:11:12.655954  7223 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I1003 13:11:26.904150  7223 solver.cpp:218] Iteration 85700 (7.01845 iter/s, 14.2482s/100 iters), loss = 0.00857565
I1003 13:11:26.904254  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00857455 (* 1 = 0.00857455 loss)
I1003 13:11:26.904261  7223 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I1003 13:11:41.149276  7223 solver.cpp:218] Iteration 85800 (7.02001 iter/s, 14.245s/100 iters), loss = 0.0211794
I1003 13:11:41.149303  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0211783 (* 1 = 0.0211783 loss)
I1003 13:11:41.149309  7223 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I1003 13:11:55.408411  7223 solver.cpp:218] Iteration 85900 (7.01308 iter/s, 14.2591s/100 iters), loss = 0.014229
I1003 13:11:55.408443  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142279 (* 1 = 0.0142279 loss)
I1003 13:11:55.408459  7223 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I1003 13:12:08.955732  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:12:09.523864  7223 solver.cpp:330] Iteration 86000, Testing net (#0)
I1003 13:12:12.891260  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:12:13.031467  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9073
I1003 13:12:13.031492  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366391 (* 1 = 0.366391 loss)
I1003 13:12:13.172472  7223 solver.cpp:218] Iteration 86000 (5.62937 iter/s, 17.764s/100 iters), loss = 0.00251001
I1003 13:12:13.172504  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00250889 (* 1 = 0.00250889 loss)
I1003 13:12:13.172511  7223 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I1003 13:12:27.417707  7223 solver.cpp:218] Iteration 86100 (7.01993 iter/s, 14.2452s/100 iters), loss = 0.00679363
I1003 13:12:27.417744  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00679251 (* 1 = 0.00679251 loss)
I1003 13:12:27.417752  7223 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I1003 13:12:41.667467  7223 solver.cpp:218] Iteration 86200 (7.0177 iter/s, 14.2497s/100 iters), loss = 0.0227949
I1003 13:12:41.667608  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227938 (* 1 = 0.0227938 loss)
I1003 13:12:41.667616  7223 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I1003 13:12:55.903254  7223 solver.cpp:218] Iteration 86300 (7.02464 iter/s, 14.2356s/100 iters), loss = 0.00645555
I1003 13:12:55.903285  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00645444 (* 1 = 0.00645444 loss)
I1003 13:12:55.903290  7223 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I1003 13:13:10.150120  7223 solver.cpp:218] Iteration 86400 (7.01912 iter/s, 14.2468s/100 iters), loss = 0.00581304
I1003 13:13:10.150166  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00581193 (* 1 = 0.00581193 loss)
I1003 13:13:10.150173  7223 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I1003 13:13:23.694731  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:13:24.262430  7223 solver.cpp:330] Iteration 86500, Testing net (#0)
I1003 13:13:27.630820  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:13:27.770746  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9067
I1003 13:13:27.770782  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367344 (* 1 = 0.367344 loss)
I1003 13:13:27.911869  7223 solver.cpp:218] Iteration 86500 (5.63011 iter/s, 17.7617s/100 iters), loss = 0.0227139
I1003 13:13:27.911900  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227128 (* 1 = 0.0227128 loss)
I1003 13:13:27.911907  7223 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I1003 13:13:42.160935  7223 solver.cpp:218] Iteration 86600 (7.01804 iter/s, 14.249s/100 iters), loss = 0.00391617
I1003 13:13:42.160966  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00391505 (* 1 = 0.00391505 loss)
I1003 13:13:42.160972  7223 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I1003 13:13:56.403291  7223 solver.cpp:218] Iteration 86700 (7.02135 iter/s, 14.2423s/100 iters), loss = 0.0151735
I1003 13:13:56.403415  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0151724 (* 1 = 0.0151724 loss)
I1003 13:13:56.403434  7223 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I1003 13:14:10.653108  7223 solver.cpp:218] Iteration 86800 (7.01773 iter/s, 14.2496s/100 iters), loss = 0.00645628
I1003 13:14:10.653139  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00645516 (* 1 = 0.00645516 loss)
I1003 13:14:10.653146  7223 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I1003 13:14:24.902920  7223 solver.cpp:218] Iteration 86900 (7.01768 iter/s, 14.2497s/100 iters), loss = 0.00977901
I1003 13:14:24.902954  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00977788 (* 1 = 0.00977788 loss)
I1003 13:14:24.902961  7223 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I1003 13:14:38.437019  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:14:39.010463  7223 solver.cpp:330] Iteration 87000, Testing net (#0)
I1003 13:14:42.375833  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:14:42.516181  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.909
I1003 13:14:42.516207  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368802 (* 1 = 0.368802 loss)
I1003 13:14:42.657956  7223 solver.cpp:218] Iteration 87000 (5.63223 iter/s, 17.755s/100 iters), loss = 0.00915497
I1003 13:14:42.657985  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00915385 (* 1 = 0.00915385 loss)
I1003 13:14:42.657992  7223 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I1003 13:14:56.921347  7223 solver.cpp:218] Iteration 87100 (7.01099 iter/s, 14.2633s/100 iters), loss = 0.00468123
I1003 13:14:56.921378  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00468009 (* 1 = 0.00468009 loss)
I1003 13:14:56.921385  7223 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I1003 13:15:11.182363  7223 solver.cpp:218] Iteration 87200 (7.01216 iter/s, 14.2609s/100 iters), loss = 0.034219
I1003 13:15:11.182490  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0342179 (* 1 = 0.0342179 loss)
I1003 13:15:11.182497  7223 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I1003 13:15:25.432911  7223 solver.cpp:218] Iteration 87300 (7.01735 iter/s, 14.2504s/100 iters), loss = 0.00540358
I1003 13:15:25.432941  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00540244 (* 1 = 0.00540244 loss)
I1003 13:15:25.432947  7223 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I1003 13:15:39.691061  7223 solver.cpp:218] Iteration 87400 (7.01357 iter/s, 14.2581s/100 iters), loss = 0.0157861
I1003 13:15:39.691090  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015785 (* 1 = 0.015785 loss)
I1003 13:15:39.691097  7223 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I1003 13:15:53.238703  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:15:53.817322  7223 solver.cpp:330] Iteration 87500, Testing net (#0)
I1003 13:15:57.186280  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:15:57.326424  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9089
I1003 13:15:57.326459  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369307 (* 1 = 0.369307 loss)
I1003 13:15:57.467368  7223 solver.cpp:218] Iteration 87500 (5.62549 iter/s, 17.7762s/100 iters), loss = 0.00618518
I1003 13:15:57.467397  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00618403 (* 1 = 0.00618403 loss)
I1003 13:15:57.467404  7223 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I1003 13:16:11.720073  7223 solver.cpp:218] Iteration 87600 (7.01625 iter/s, 14.2526s/100 iters), loss = 0.0105426
I1003 13:16:11.720119  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105414 (* 1 = 0.0105414 loss)
I1003 13:16:11.720126  7223 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I1003 13:16:25.973345  7223 solver.cpp:218] Iteration 87700 (7.01597 iter/s, 14.2532s/100 iters), loss = 0.0176905
I1003 13:16:25.973459  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176893 (* 1 = 0.0176893 loss)
I1003 13:16:25.973475  7223 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I1003 13:16:40.238833  7223 solver.cpp:218] Iteration 87800 (7.01 iter/s, 14.2653s/100 iters), loss = 0.0179838
I1003 13:16:40.238865  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0179826 (* 1 = 0.0179826 loss)
I1003 13:16:40.238871  7223 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I1003 13:16:54.500946  7223 solver.cpp:218] Iteration 87900 (7.01162 iter/s, 14.262s/100 iters), loss = 0.0105677
I1003 13:16:54.500977  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105666 (* 1 = 0.0105666 loss)
I1003 13:16:54.500983  7223 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I1003 13:17:08.046594  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:17:08.623195  7223 solver.cpp:330] Iteration 88000, Testing net (#0)
I1003 13:17:11.994065  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:17:12.134330  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9081
I1003 13:17:12.134366  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367661 (* 1 = 0.367661 loss)
I1003 13:17:12.275730  7223 solver.cpp:218] Iteration 88000 (5.62597 iter/s, 17.7747s/100 iters), loss = 0.00779221
I1003 13:17:12.275761  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00779106 (* 1 = 0.00779106 loss)
I1003 13:17:12.275768  7223 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I1003 13:17:26.533049  7223 solver.cpp:218] Iteration 88100 (7.01398 iter/s, 14.2572s/100 iters), loss = 0.0049539
I1003 13:17:26.533087  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00495276 (* 1 = 0.00495276 loss)
I1003 13:17:26.533095  7223 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I1003 13:17:40.788589  7223 solver.cpp:218] Iteration 88200 (7.01486 iter/s, 14.2555s/100 iters), loss = 0.0298707
I1003 13:17:40.788717  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0298695 (* 1 = 0.0298695 loss)
I1003 13:17:40.788727  7223 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I1003 13:17:55.044353  7223 solver.cpp:218] Iteration 88300 (7.01478 iter/s, 14.2556s/100 iters), loss = 0.0675897
I1003 13:17:55.044385  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0675885 (* 1 = 0.0675885 loss)
I1003 13:17:55.044391  7223 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I1003 13:18:09.306803  7223 solver.cpp:218] Iteration 88400 (7.01146 iter/s, 14.2624s/100 iters), loss = 0.000864279
I1003 13:18:09.306838  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000863136 (* 1 = 0.000863136 loss)
I1003 13:18:09.306848  7223 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I1003 13:18:22.850636  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:18:23.421864  7223 solver.cpp:330] Iteration 88500, Testing net (#0)
I1003 13:18:26.794013  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:18:26.934304  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9072
I1003 13:18:26.934330  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367961 (* 1 = 0.367961 loss)
I1003 13:18:27.075598  7223 solver.cpp:218] Iteration 88500 (5.62787 iter/s, 17.7687s/100 iters), loss = 0.00936347
I1003 13:18:27.075629  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00936233 (* 1 = 0.00936233 loss)
I1003 13:18:27.075637  7223 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I1003 13:18:41.303923  7223 solver.cpp:218] Iteration 88600 (7.02827 iter/s, 14.2283s/100 iters), loss = 0.0117233
I1003 13:18:41.303963  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117222 (* 1 = 0.0117222 loss)
I1003 13:18:41.303969  7223 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I1003 13:18:55.556881  7223 solver.cpp:218] Iteration 88700 (7.01613 iter/s, 14.2529s/100 iters), loss = 0.0102615
I1003 13:18:55.556994  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102603 (* 1 = 0.0102603 loss)
I1003 13:18:55.557003  7223 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I1003 13:19:09.816190  7223 solver.cpp:218] Iteration 88800 (7.01304 iter/s, 14.2592s/100 iters), loss = 0.0078776
I1003 13:19:09.816220  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00787644 (* 1 = 0.00787644 loss)
I1003 13:19:09.816226  7223 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I1003 13:19:24.063702  7223 solver.cpp:218] Iteration 88900 (7.0188 iter/s, 14.2474s/100 iters), loss = 0.00515002
I1003 13:19:24.063733  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00514887 (* 1 = 0.00514887 loss)
I1003 13:19:24.063740  7223 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I1003 13:19:37.597458  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:19:38.165355  7223 solver.cpp:330] Iteration 89000, Testing net (#0)
I1003 13:19:41.542839  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:19:41.685350  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9082
I1003 13:19:41.685387  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370768 (* 1 = 0.370768 loss)
I1003 13:19:41.826206  7223 solver.cpp:218] Iteration 89000 (5.62986 iter/s, 17.7624s/100 iters), loss = 0.0164609
I1003 13:19:41.826241  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0164598 (* 1 = 0.0164598 loss)
I1003 13:19:41.826248  7223 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I1003 13:19:56.071962  7223 solver.cpp:218] Iteration 89100 (7.01967 iter/s, 14.2457s/100 iters), loss = 0.0171124
I1003 13:19:56.071992  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0171113 (* 1 = 0.0171113 loss)
I1003 13:19:56.072000  7223 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I1003 13:20:10.323519  7223 solver.cpp:218] Iteration 89200 (7.01681 iter/s, 14.2515s/100 iters), loss = 0.0149607
I1003 13:20:10.323662  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149596 (* 1 = 0.0149596 loss)
I1003 13:20:10.323681  7223 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I1003 13:20:24.569766  7223 solver.cpp:218] Iteration 89300 (7.01948 iter/s, 14.2461s/100 iters), loss = 0.0258722
I1003 13:20:24.569795  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.025871 (* 1 = 0.025871 loss)
I1003 13:20:24.569802  7223 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I1003 13:20:38.822882  7223 solver.cpp:218] Iteration 89400 (7.01605 iter/s, 14.253s/100 iters), loss = 0.00408043
I1003 13:20:38.822916  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00407927 (* 1 = 0.00407927 loss)
I1003 13:20:38.822922  7223 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I1003 13:20:52.364821  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:20:52.933065  7223 solver.cpp:330] Iteration 89500, Testing net (#0)
I1003 13:20:56.298687  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:20:56.440963  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9074
I1003 13:20:56.441006  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368319 (* 1 = 0.368319 loss)
I1003 13:20:56.584995  7223 solver.cpp:218] Iteration 89500 (5.62999 iter/s, 17.762s/100 iters), loss = 0.00434482
I1003 13:20:56.585041  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00434365 (* 1 = 0.00434365 loss)
I1003 13:20:56.585048  7223 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I1003 13:21:10.833565  7223 solver.cpp:218] Iteration 89600 (7.01831 iter/s, 14.2485s/100 iters), loss = 0.00579983
I1003 13:21:10.833596  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00579866 (* 1 = 0.00579866 loss)
I1003 13:21:10.833601  7223 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I1003 13:21:25.095027  7223 solver.cpp:218] Iteration 89700 (7.01194 iter/s, 14.2614s/100 iters), loss = 0.0064443
I1003 13:21:25.095134  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00644313 (* 1 = 0.00644313 loss)
I1003 13:21:25.095144  7223 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I1003 13:21:39.354720  7223 solver.cpp:218] Iteration 89800 (7.01285 iter/s, 14.2595s/100 iters), loss = 0.0057248
I1003 13:21:39.354753  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00572364 (* 1 = 0.00572364 loss)
I1003 13:21:39.354758  7223 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I1003 13:21:53.608276  7223 solver.cpp:218] Iteration 89900 (7.01583 iter/s, 14.2535s/100 iters), loss = 0.00322358
I1003 13:21:53.608314  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00322241 (* 1 = 0.00322241 loss)
I1003 13:21:53.608320  7223 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I1003 13:22:07.159245  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:22:07.727303  7223 solver.cpp:330] Iteration 90000, Testing net (#0)
I1003 13:22:11.097076  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:22:11.237614  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9075
I1003 13:22:11.237640  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368896 (* 1 = 0.368896 loss)
I1003 13:22:11.378917  7223 solver.cpp:218] Iteration 90000 (5.62729 iter/s, 17.7705s/100 iters), loss = 0.00855555
I1003 13:22:11.378965  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00855439 (* 1 = 0.00855439 loss)
I1003 13:22:11.378973  7223 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I1003 13:22:25.651083  7223 solver.cpp:218] Iteration 90100 (7.0067 iter/s, 14.272s/100 iters), loss = 0.0575497
I1003 13:22:25.651118  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0575485 (* 1 = 0.0575485 loss)
I1003 13:22:25.651124  7223 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I1003 13:22:39.906014  7223 solver.cpp:218] Iteration 90200 (7.01516 iter/s, 14.2549s/100 iters), loss = 0.0148231
I1003 13:22:39.906141  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148219 (* 1 = 0.0148219 loss)
I1003 13:22:39.906149  7223 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I1003 13:22:54.170090  7223 solver.cpp:218] Iteration 90300 (7.0107 iter/s, 14.2639s/100 iters), loss = 0.0281402
I1003 13:22:54.170121  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0281391 (* 1 = 0.0281391 loss)
I1003 13:22:54.170127  7223 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I1003 13:23:08.429229  7223 solver.cpp:218] Iteration 90400 (7.01308 iter/s, 14.2591s/100 iters), loss = 0.0105363
I1003 13:23:08.429267  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105352 (* 1 = 0.0105352 loss)
I1003 13:23:08.429275  7223 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I1003 13:23:21.974648  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:23:22.543735  7223 solver.cpp:330] Iteration 90500, Testing net (#0)
I1003 13:23:25.910779  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:23:26.051038  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.907
I1003 13:23:26.051074  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367795 (* 1 = 0.367795 loss)
I1003 13:23:26.192407  7223 solver.cpp:218] Iteration 90500 (5.62965 iter/s, 17.7631s/100 iters), loss = 0.00956771
I1003 13:23:26.192448  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00956654 (* 1 = 0.00956654 loss)
I1003 13:23:26.192456  7223 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I1003 13:23:40.447943  7223 solver.cpp:218] Iteration 90600 (7.01489 iter/s, 14.2554s/100 iters), loss = 0.0156965
I1003 13:23:40.447974  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156953 (* 1 = 0.0156953 loss)
I1003 13:23:40.447981  7223 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I1003 13:23:54.702039  7223 solver.cpp:218] Iteration 90700 (7.01556 iter/s, 14.254s/100 iters), loss = 0.00309734
I1003 13:23:54.702183  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00309617 (* 1 = 0.00309617 loss)
I1003 13:23:54.702193  7223 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I1003 13:24:08.955109  7223 solver.cpp:218] Iteration 90800 (7.01612 iter/s, 14.2529s/100 iters), loss = 0.00552431
I1003 13:24:08.955140  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00552315 (* 1 = 0.00552315 loss)
I1003 13:24:08.955147  7223 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I1003 13:24:23.200460  7223 solver.cpp:218] Iteration 90900 (7.01987 iter/s, 14.2453s/100 iters), loss = 0.00762528
I1003 13:24:23.200501  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00762412 (* 1 = 0.00762412 loss)
I1003 13:24:23.200507  7223 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I1003 13:24:36.755911  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:24:37.324497  7223 solver.cpp:330] Iteration 91000, Testing net (#0)
I1003 13:24:40.689391  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:24:40.829509  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9082
I1003 13:24:40.829545  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367343 (* 1 = 0.367343 loss)
I1003 13:24:40.970244  7223 solver.cpp:218] Iteration 91000 (5.62756 iter/s, 17.7697s/100 iters), loss = 0.00430679
I1003 13:24:40.970271  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00430563 (* 1 = 0.00430563 loss)
I1003 13:24:40.970278  7223 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I1003 13:24:55.215968  7223 solver.cpp:218] Iteration 91100 (7.01968 iter/s, 14.2457s/100 iters), loss = 0.00419664
I1003 13:24:55.216001  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00419548 (* 1 = 0.00419548 loss)
I1003 13:24:55.216007  7223 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I1003 13:25:09.460598  7223 solver.cpp:218] Iteration 91200 (7.02023 iter/s, 14.2446s/100 iters), loss = 0.00798129
I1003 13:25:09.460781  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00798012 (* 1 = 0.00798012 loss)
I1003 13:25:09.460790  7223 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I1003 13:25:23.716387  7223 solver.cpp:218] Iteration 91300 (7.01479 iter/s, 14.2556s/100 iters), loss = 0.00271206
I1003 13:25:23.716421  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00271089 (* 1 = 0.00271089 loss)
I1003 13:25:23.716429  7223 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I1003 13:25:37.967815  7223 solver.cpp:218] Iteration 91400 (7.01688 iter/s, 14.2514s/100 iters), loss = 0.00447051
I1003 13:25:37.967845  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00446935 (* 1 = 0.00446935 loss)
I1003 13:25:37.967851  7223 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I1003 13:25:51.508805  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:25:52.077497  7223 solver.cpp:330] Iteration 91500, Testing net (#0)
I1003 13:25:55.445055  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:25:55.585541  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9074
I1003 13:25:55.585566  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370895 (* 1 = 0.370895 loss)
I1003 13:25:55.726938  7223 solver.cpp:218] Iteration 91500 (5.63093 iter/s, 17.759s/100 iters), loss = 0.0140912
I1003 13:25:55.726982  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01409 (* 1 = 0.01409 loss)
I1003 13:25:55.726989  7223 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I1003 13:26:09.985116  7223 solver.cpp:218] Iteration 91600 (7.01359 iter/s, 14.258s/100 iters), loss = 0.00863895
I1003 13:26:09.985147  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00863778 (* 1 = 0.00863778 loss)
I1003 13:26:09.985154  7223 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I1003 13:26:24.242558  7223 solver.cpp:218] Iteration 91700 (7.01392 iter/s, 14.2574s/100 iters), loss = 0.00812454
I1003 13:26:24.242631  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00812337 (* 1 = 0.00812337 loss)
I1003 13:26:24.242640  7223 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I1003 13:26:38.489140  7223 solver.cpp:218] Iteration 91800 (7.01928 iter/s, 14.2465s/100 iters), loss = 0.00636334
I1003 13:26:38.489178  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00636218 (* 1 = 0.00636218 loss)
I1003 13:26:38.489187  7223 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I1003 13:26:52.736707  7223 solver.cpp:218] Iteration 91900 (7.01878 iter/s, 14.2475s/100 iters), loss = 0.004593
I1003 13:26:52.736738  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00459183 (* 1 = 0.00459183 loss)
I1003 13:26:52.736744  7223 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I1003 13:27:06.296700  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:27:06.864727  7223 solver.cpp:330] Iteration 92000, Testing net (#0)
I1003 13:27:10.235075  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:27:10.375207  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9075
I1003 13:27:10.375243  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369557 (* 1 = 0.369557 loss)
I1003 13:27:10.517235  7223 solver.cpp:218] Iteration 92000 (5.62416 iter/s, 17.7804s/100 iters), loss = 0.0044279
I1003 13:27:10.517278  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00442674 (* 1 = 0.00442674 loss)
I1003 13:27:10.517287  7223 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I1003 13:27:24.769183  7223 solver.cpp:218] Iteration 92100 (7.01663 iter/s, 14.2519s/100 iters), loss = 0.00487415
I1003 13:27:24.769213  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00487299 (* 1 = 0.00487299 loss)
I1003 13:27:24.769219  7223 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I1003 13:27:39.027953  7223 solver.cpp:218] Iteration 92200 (7.01326 iter/s, 14.2587s/100 iters), loss = 0.018564
I1003 13:27:39.028074  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0185629 (* 1 = 0.0185629 loss)
I1003 13:27:39.028082  7223 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I1003 13:27:53.291342  7223 solver.cpp:218] Iteration 92300 (7.01104 iter/s, 14.2632s/100 iters), loss = 0.0135515
I1003 13:27:53.291371  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0135504 (* 1 = 0.0135504 loss)
I1003 13:27:53.291378  7223 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I1003 13:28:07.559229  7223 solver.cpp:218] Iteration 92400 (7.00878 iter/s, 14.2678s/100 iters), loss = 0.00453919
I1003 13:28:07.559262  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00453803 (* 1 = 0.00453803 loss)
I1003 13:28:07.559268  7223 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I1003 13:28:21.110760  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:28:21.679342  7223 solver.cpp:330] Iteration 92500, Testing net (#0)
I1003 13:28:25.047071  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:28:25.187013  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9085
I1003 13:28:25.187038  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369189 (* 1 = 0.369189 loss)
I1003 13:28:25.327525  7223 solver.cpp:218] Iteration 92500 (5.62803 iter/s, 17.7682s/100 iters), loss = 0.00395819
I1003 13:28:25.327570  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00395702 (* 1 = 0.00395702 loss)
I1003 13:28:25.327591  7223 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I1003 13:28:39.588232  7223 solver.cpp:218] Iteration 92600 (7.01236 iter/s, 14.2605s/100 iters), loss = 0.00311629
I1003 13:28:39.588264  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00311512 (* 1 = 0.00311512 loss)
I1003 13:28:39.588271  7223 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I1003 13:28:53.852461  7223 solver.cpp:218] Iteration 92700 (7.01058 iter/s, 14.2642s/100 iters), loss = 0.0126881
I1003 13:28:53.852576  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126869 (* 1 = 0.0126869 loss)
I1003 13:28:53.852592  7223 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I1003 13:29:08.100673  7223 solver.cpp:218] Iteration 92800 (7.0185 iter/s, 14.2481s/100 iters), loss = 0.0135752
I1003 13:29:08.100714  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013574 (* 1 = 0.013574 loss)
I1003 13:29:08.100720  7223 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I1003 13:29:22.361101  7223 solver.cpp:218] Iteration 92900 (7.01245 iter/s, 14.2603s/100 iters), loss = 0.00333473
I1003 13:29:22.361133  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00333356 (* 1 = 0.00333356 loss)
I1003 13:29:22.361140  7223 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I1003 13:29:35.921378  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:29:36.490614  7223 solver.cpp:330] Iteration 93000, Testing net (#0)
I1003 13:29:39.857746  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:29:39.998512  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9084
I1003 13:29:39.998538  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.371036 (* 1 = 0.371036 loss)
I1003 13:29:40.139334  7223 solver.cpp:218] Iteration 93000 (5.62488 iter/s, 17.7781s/100 iters), loss = 0.00989358
I1003 13:29:40.139376  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00989241 (* 1 = 0.00989241 loss)
I1003 13:29:40.139384  7223 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I1003 13:29:54.391165  7223 solver.cpp:218] Iteration 93100 (7.01672 iter/s, 14.2517s/100 iters), loss = 0.0103012
I1003 13:29:54.391196  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103 (* 1 = 0.0103 loss)
I1003 13:29:54.391201  7223 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I1003 13:30:08.650838  7223 solver.cpp:218] Iteration 93200 (7.01282 iter/s, 14.2596s/100 iters), loss = 0.0307172
I1003 13:30:08.650976  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0307161 (* 1 = 0.0307161 loss)
I1003 13:30:08.650985  7223 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I1003 13:30:22.900748  7223 solver.cpp:218] Iteration 93300 (7.01767 iter/s, 14.2497s/100 iters), loss = 0.0108166
I1003 13:30:22.900779  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108154 (* 1 = 0.0108154 loss)
I1003 13:30:22.900786  7223 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I1003 13:30:37.154821  7223 solver.cpp:218] Iteration 93400 (7.01557 iter/s, 14.254s/100 iters), loss = 0.0151013
I1003 13:30:37.154852  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0151001 (* 1 = 0.0151001 loss)
I1003 13:30:37.154858  7223 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I1003 13:30:50.709151  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:30:51.276603  7223 solver.cpp:330] Iteration 93500, Testing net (#0)
I1003 13:30:54.646129  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:30:54.786398  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9096
I1003 13:30:54.786423  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372302 (* 1 = 0.372302 loss)
I1003 13:30:54.926329  7223 solver.cpp:218] Iteration 93500 (5.62701 iter/s, 17.7714s/100 iters), loss = 0.0093463
I1003 13:30:54.926358  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00934514 (* 1 = 0.00934514 loss)
I1003 13:30:54.926365  7223 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I1003 13:31:09.180467  7223 solver.cpp:218] Iteration 93600 (7.01556 iter/s, 14.254s/100 iters), loss = 0.03272
I1003 13:31:09.180498  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0327189 (* 1 = 0.0327189 loss)
I1003 13:31:09.180516  7223 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I1003 13:31:23.424229  7223 solver.cpp:218] Iteration 93700 (7.02066 iter/s, 14.2437s/100 iters), loss = 0.0150079
I1003 13:31:23.424336  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0150068 (* 1 = 0.0150068 loss)
I1003 13:31:23.424346  7223 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I1003 13:31:37.675969  7223 solver.cpp:218] Iteration 93800 (7.01676 iter/s, 14.2516s/100 iters), loss = 0.00346688
I1003 13:31:37.676002  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00346571 (* 1 = 0.00346571 loss)
I1003 13:31:37.676007  7223 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I1003 13:31:51.933352  7223 solver.cpp:218] Iteration 93900 (7.01395 iter/s, 14.2573s/100 iters), loss = 0.0123378
I1003 13:31:51.933383  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0123366 (* 1 = 0.0123366 loss)
I1003 13:31:51.933400  7223 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I1003 13:32:05.476718  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:32:06.052551  7223 solver.cpp:330] Iteration 94000, Testing net (#0)
I1003 13:32:09.419385  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:32:09.558921  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9076
I1003 13:32:09.558948  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370341 (* 1 = 0.370341 loss)
I1003 13:32:09.700230  7223 solver.cpp:218] Iteration 94000 (5.62848 iter/s, 17.7668s/100 iters), loss = 0.00663137
I1003 13:32:09.700259  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0066302 (* 1 = 0.0066302 loss)
I1003 13:32:09.700266  7223 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I1003 13:32:23.947674  7223 solver.cpp:218] Iteration 94100 (7.01884 iter/s, 14.2474s/100 iters), loss = 0.00713832
I1003 13:32:23.947716  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00713715 (* 1 = 0.00713715 loss)
I1003 13:32:23.947722  7223 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I1003 13:32:38.189880  7223 solver.cpp:218] Iteration 94200 (7.02143 iter/s, 14.2421s/100 iters), loss = 0.0146222
I1003 13:32:38.190011  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014621 (* 1 = 0.014621 loss)
I1003 13:32:38.190028  7223 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I1003 13:32:52.447234  7223 solver.cpp:218] Iteration 94300 (7.014 iter/s, 14.2572s/100 iters), loss = 0.0116073
I1003 13:32:52.447265  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116062 (* 1 = 0.0116062 loss)
I1003 13:32:52.447271  7223 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I1003 13:33:06.691504  7223 solver.cpp:218] Iteration 94400 (7.0204 iter/s, 14.2442s/100 iters), loss = 0.00743415
I1003 13:33:06.691534  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00743298 (* 1 = 0.00743298 loss)
I1003 13:33:06.691540  7223 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I1003 13:33:20.233512  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:33:20.812476  7223 solver.cpp:330] Iteration 94500, Testing net (#0)
I1003 13:33:24.183336  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:33:24.322875  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9075
I1003 13:33:24.322909  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370372 (* 1 = 0.370372 loss)
I1003 13:33:24.464382  7223 solver.cpp:218] Iteration 94500 (5.62658 iter/s, 17.7728s/100 iters), loss = 0.00844499
I1003 13:33:24.464413  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00844383 (* 1 = 0.00844383 loss)
I1003 13:33:24.464421  7223 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I1003 13:33:38.723397  7223 solver.cpp:218] Iteration 94600 (7.01315 iter/s, 14.2589s/100 iters), loss = 0.00496131
I1003 13:33:38.723444  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00496014 (* 1 = 0.00496014 loss)
I1003 13:33:38.723455  7223 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I1003 13:33:52.973719  7223 solver.cpp:218] Iteration 94700 (7.01745 iter/s, 14.2502s/100 iters), loss = 0.00586918
I1003 13:33:52.973832  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00586801 (* 1 = 0.00586801 loss)
I1003 13:33:52.973851  7223 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I1003 13:34:07.230484  7223 solver.cpp:218] Iteration 94800 (7.01429 iter/s, 14.2566s/100 iters), loss = 0.00236466
I1003 13:34:07.230518  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00236349 (* 1 = 0.00236349 loss)
I1003 13:34:07.230527  7223 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I1003 13:34:21.497542  7223 solver.cpp:218] Iteration 94900 (7.00919 iter/s, 14.267s/100 iters), loss = 0.00761578
I1003 13:34:21.497576  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00761461 (* 1 = 0.00761461 loss)
I1003 13:34:21.497586  7223 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I1003 13:34:35.039036  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:34:35.610591  7223 solver.cpp:330] Iteration 95000, Testing net (#0)
I1003 13:34:38.980265  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:34:39.120138  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9083
I1003 13:34:39.120165  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.371227 (* 1 = 0.371227 loss)
I1003 13:34:39.261109  7223 solver.cpp:218] Iteration 95000 (5.62953 iter/s, 17.7635s/100 iters), loss = 0.00706139
I1003 13:34:39.261145  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00706021 (* 1 = 0.00706021 loss)
I1003 13:34:39.261154  7223 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1003 13:34:53.513626  7223 solver.cpp:218] Iteration 95100 (7.01634 iter/s, 14.2524s/100 iters), loss = 0.0107246
I1003 13:34:53.513670  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107234 (* 1 = 0.0107234 loss)
I1003 13:34:53.513680  7223 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1003 13:35:07.772153  7223 solver.cpp:218] Iteration 95200 (7.01339 iter/s, 14.2584s/100 iters), loss = 0.00466769
I1003 13:35:07.772291  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00466651 (* 1 = 0.00466651 loss)
I1003 13:35:07.772303  7223 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1003 13:35:22.032752  7223 solver.cpp:218] Iteration 95300 (7.01242 iter/s, 14.2604s/100 iters), loss = 0.0165305
I1003 13:35:22.032785  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0165293 (* 1 = 0.0165293 loss)
I1003 13:35:22.032794  7223 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1003 13:35:36.289770  7223 solver.cpp:218] Iteration 95400 (7.01412 iter/s, 14.2569s/100 iters), loss = 0.00739383
I1003 13:35:36.289803  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00739265 (* 1 = 0.00739265 loss)
I1003 13:35:36.289813  7223 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1003 13:35:49.835161  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:35:50.402420  7223 solver.cpp:330] Iteration 95500, Testing net (#0)
I1003 13:35:53.780534  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:35:53.920153  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9077
I1003 13:35:53.920181  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373784 (* 1 = 0.373784 loss)
I1003 13:35:54.061311  7223 solver.cpp:218] Iteration 95500 (5.627 iter/s, 17.7715s/100 iters), loss = 0.00601051
I1003 13:35:54.061348  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00600933 (* 1 = 0.00600933 loss)
I1003 13:35:54.061358  7223 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1003 13:36:08.292855  7223 solver.cpp:218] Iteration 95600 (7.02669 iter/s, 14.2315s/100 iters), loss = 0.0252979
I1003 13:36:08.292887  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0252967 (* 1 = 0.0252967 loss)
I1003 13:36:08.292894  7223 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1003 13:36:22.540423  7223 solver.cpp:218] Iteration 95700 (7.01878 iter/s, 14.2475s/100 iters), loss = 0.0119632
I1003 13:36:22.540524  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011962 (* 1 = 0.011962 loss)
I1003 13:36:22.540535  7223 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1003 13:36:36.791431  7223 solver.cpp:218] Iteration 95800 (7.01712 iter/s, 14.2509s/100 iters), loss = 0.00968819
I1003 13:36:36.791465  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.009687 (* 1 = 0.009687 loss)
I1003 13:36:36.791472  7223 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1003 13:36:51.040300  7223 solver.cpp:218] Iteration 95900 (7.01814 iter/s, 14.2488s/100 iters), loss = 0.0281983
I1003 13:36:51.040333  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0281971 (* 1 = 0.0281971 loss)
I1003 13:36:51.040343  7223 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1003 13:37:04.569262  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:37:05.137465  7223 solver.cpp:330] Iteration 96000, Testing net (#0)
I1003 13:37:08.505836  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:37:08.649732  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9079
I1003 13:37:08.649763  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370395 (* 1 = 0.370395 loss)
I1003 13:37:08.793138  7223 solver.cpp:218] Iteration 96000 (5.63293 iter/s, 17.7528s/100 iters), loss = 0.00311993
I1003 13:37:08.793177  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00311874 (* 1 = 0.00311874 loss)
I1003 13:37:08.793187  7223 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1003 13:37:23.058604  7223 solver.cpp:218] Iteration 96100 (7.00998 iter/s, 14.2654s/100 iters), loss = 0.0139101
I1003 13:37:23.058639  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013909 (* 1 = 0.013909 loss)
I1003 13:37:23.058656  7223 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1003 13:37:37.328133  7223 solver.cpp:218] Iteration 96200 (7.00798 iter/s, 14.2695s/100 iters), loss = 0.0149717
I1003 13:37:37.328320  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149705 (* 1 = 0.0149705 loss)
I1003 13:37:37.328343  7223 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1003 13:37:51.587765  7223 solver.cpp:218] Iteration 96300 (7.01291 iter/s, 14.2594s/100 iters), loss = 0.00407021
I1003 13:37:51.587798  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00406902 (* 1 = 0.00406902 loss)
I1003 13:37:51.587816  7223 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1003 13:38:05.844705  7223 solver.cpp:218] Iteration 96400 (7.01417 iter/s, 14.2569s/100 iters), loss = 0.00886584
I1003 13:38:05.844743  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00886465 (* 1 = 0.00886465 loss)
I1003 13:38:05.844763  7223 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1003 13:38:19.386502  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:38:19.954919  7223 solver.cpp:330] Iteration 96500, Testing net (#0)
I1003 13:38:23.321893  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:38:23.461921  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.908
I1003 13:38:23.461951  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372983 (* 1 = 0.372983 loss)
I1003 13:38:23.607048  7223 solver.cpp:218] Iteration 96500 (5.62992 iter/s, 17.7623s/100 iters), loss = 0.00451887
I1003 13:38:23.607096  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00451769 (* 1 = 0.00451769 loss)
I1003 13:38:23.607116  7223 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1003 13:38:37.848737  7223 solver.cpp:218] Iteration 96600 (7.02169 iter/s, 14.2416s/100 iters), loss = 0.00847834
I1003 13:38:37.848773  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00847716 (* 1 = 0.00847716 loss)
I1003 13:38:37.848791  7223 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1003 13:38:52.106551  7223 solver.cpp:218] Iteration 96700 (7.01373 iter/s, 14.2577s/100 iters), loss = 0.0272241
I1003 13:38:52.106669  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0272229 (* 1 = 0.0272229 loss)
I1003 13:38:52.106678  7223 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1003 13:39:06.377446  7223 solver.cpp:218] Iteration 96800 (7.00735 iter/s, 14.2707s/100 iters), loss = 0.0370392
I1003 13:39:06.377476  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0370381 (* 1 = 0.0370381 loss)
I1003 13:39:06.377483  7223 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1003 13:39:20.636770  7223 solver.cpp:218] Iteration 96900 (7.01299 iter/s, 14.2592s/100 iters), loss = 0.00711093
I1003 13:39:20.636804  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00710975 (* 1 = 0.00710975 loss)
I1003 13:39:20.636811  7223 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1003 13:39:34.173573  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:39:34.744393  7223 solver.cpp:330] Iteration 97000, Testing net (#0)
I1003 13:39:38.114130  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:39:38.253654  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9076
I1003 13:39:38.253689  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373355 (* 1 = 0.373355 loss)
I1003 13:39:38.395539  7223 solver.cpp:218] Iteration 97000 (5.63105 iter/s, 17.7587s/100 iters), loss = 0.00474615
I1003 13:39:38.395566  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00474496 (* 1 = 0.00474496 loss)
I1003 13:39:38.395573  7223 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1003 13:39:52.658687  7223 solver.cpp:218] Iteration 97100 (7.01111 iter/s, 14.2631s/100 iters), loss = 0.0122258
I1003 13:39:52.658730  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122246 (* 1 = 0.0122246 loss)
I1003 13:39:52.658736  7223 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1003 13:40:06.921667  7223 solver.cpp:218] Iteration 97200 (7.0112 iter/s, 14.2629s/100 iters), loss = 0.00637441
I1003 13:40:06.921771  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00637322 (* 1 = 0.00637322 loss)
I1003 13:40:06.921782  7223 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1003 13:40:21.172253  7223 solver.cpp:218] Iteration 97300 (7.01732 iter/s, 14.2504s/100 iters), loss = 0.00679553
I1003 13:40:21.172287  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00679433 (* 1 = 0.00679433 loss)
I1003 13:40:21.172305  7223 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1003 13:40:35.422423  7223 solver.cpp:218] Iteration 97400 (7.0175 iter/s, 14.2501s/100 iters), loss = 0.0100013
I1003 13:40:35.422454  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100001 (* 1 = 0.0100001 loss)
I1003 13:40:35.422462  7223 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1003 13:40:48.975399  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:40:49.545032  7223 solver.cpp:330] Iteration 97500, Testing net (#0)
I1003 13:40:52.913908  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:40:53.054158  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9083
I1003 13:40:53.054184  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373073 (* 1 = 0.373073 loss)
I1003 13:40:53.195261  7223 solver.cpp:218] Iteration 97500 (5.62659 iter/s, 17.7728s/100 iters), loss = 0.0375496
I1003 13:40:53.195293  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0375484 (* 1 = 0.0375484 loss)
I1003 13:40:53.195302  7223 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1003 13:41:07.449965  7223 solver.cpp:218] Iteration 97600 (7.01527 iter/s, 14.2546s/100 iters), loss = 0.00760811
I1003 13:41:07.449998  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00760691 (* 1 = 0.00760691 loss)
I1003 13:41:07.450007  7223 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1003 13:41:21.715628  7223 solver.cpp:218] Iteration 97700 (7.00987 iter/s, 14.2656s/100 iters), loss = 0.0148379
I1003 13:41:21.715749  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148367 (* 1 = 0.0148367 loss)
I1003 13:41:21.715770  7223 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1003 13:41:35.979038  7223 solver.cpp:218] Iteration 97800 (7.01102 iter/s, 14.2633s/100 iters), loss = 0.00757717
I1003 13:41:35.979074  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00757597 (* 1 = 0.00757597 loss)
I1003 13:41:35.979084  7223 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1003 13:41:50.226359  7223 solver.cpp:218] Iteration 97900 (7.0189 iter/s, 14.2472s/100 iters), loss = 0.00736301
I1003 13:41:50.226392  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00736181 (* 1 = 0.00736181 loss)
I1003 13:41:50.226402  7223 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1003 13:42:03.784409  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:42:04.354161  7223 solver.cpp:330] Iteration 98000, Testing net (#0)
I1003 13:42:07.721496  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:42:07.861407  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9079
I1003 13:42:07.861443  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37485 (* 1 = 0.37485 loss)
I1003 13:42:08.002872  7223 solver.cpp:218] Iteration 98000 (5.62543 iter/s, 17.7764s/100 iters), loss = 0.00736263
I1003 13:42:08.002907  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00736143 (* 1 = 0.00736143 loss)
I1003 13:42:08.002916  7223 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1003 13:42:22.257103  7223 solver.cpp:218] Iteration 98100 (7.0155 iter/s, 14.2542s/100 iters), loss = 0.0053654
I1003 13:42:22.257138  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0053642 (* 1 = 0.0053642 loss)
I1003 13:42:22.257143  7223 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1003 13:42:36.505879  7223 solver.cpp:218] Iteration 98200 (7.01819 iter/s, 14.2487s/100 iters), loss = 0.00401282
I1003 13:42:36.506042  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00401161 (* 1 = 0.00401161 loss)
I1003 13:42:36.506049  7223 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1003 13:42:50.758591  7223 solver.cpp:218] Iteration 98300 (7.01631 iter/s, 14.2525s/100 iters), loss = 0.00648618
I1003 13:42:50.758626  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00648497 (* 1 = 0.00648497 loss)
I1003 13:42:50.758635  7223 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1003 13:43:05.008011  7223 solver.cpp:218] Iteration 98400 (7.01787 iter/s, 14.2493s/100 iters), loss = 0.002726
I1003 13:43:05.008041  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0027248 (* 1 = 0.0027248 loss)
I1003 13:43:05.008049  7223 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1003 13:43:18.554889  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:43:19.123612  7223 solver.cpp:330] Iteration 98500, Testing net (#0)
I1003 13:43:22.492794  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:43:22.633265  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9077
I1003 13:43:22.633291  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.375879 (* 1 = 0.375879 loss)
I1003 13:43:22.774863  7223 solver.cpp:218] Iteration 98500 (5.62849 iter/s, 17.7668s/100 iters), loss = 0.00294896
I1003 13:43:22.774894  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00294776 (* 1 = 0.00294776 loss)
I1003 13:43:22.774902  7223 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1003 13:43:37.019580  7223 solver.cpp:218] Iteration 98600 (7.02018 iter/s, 14.2446s/100 iters), loss = 0.0486442
I1003 13:43:37.019611  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.048643 (* 1 = 0.048643 loss)
I1003 13:43:37.019629  7223 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1003 13:43:51.279304  7223 solver.cpp:218] Iteration 98700 (7.0128 iter/s, 14.2596s/100 iters), loss = 0.00672871
I1003 13:43:51.279448  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0067275 (* 1 = 0.0067275 loss)
I1003 13:43:51.279458  7223 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1003 13:44:05.524904  7223 solver.cpp:218] Iteration 98800 (7.0198 iter/s, 14.2454s/100 iters), loss = 0.0155872
I1003 13:44:05.524940  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015586 (* 1 = 0.015586 loss)
I1003 13:44:05.524946  7223 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1003 13:44:19.772894  7223 solver.cpp:218] Iteration 98900 (7.01857 iter/s, 14.2479s/100 iters), loss = 0.00436336
I1003 13:44:19.772930  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00436215 (* 1 = 0.00436215 loss)
I1003 13:44:19.772938  7223 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1003 13:44:33.324288  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:44:33.891398  7223 solver.cpp:330] Iteration 99000, Testing net (#0)
I1003 13:44:37.261066  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:44:37.401700  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9076
I1003 13:44:37.401726  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.374489 (* 1 = 0.374489 loss)
I1003 13:44:37.543135  7223 solver.cpp:218] Iteration 99000 (5.62741 iter/s, 17.7702s/100 iters), loss = 0.012116
I1003 13:44:37.543164  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121148 (* 1 = 0.0121148 loss)
I1003 13:44:37.543170  7223 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1003 13:44:51.812455  7223 solver.cpp:218] Iteration 99100 (7.00815 iter/s, 14.2691s/100 iters), loss = 0.00280294
I1003 13:44:51.812486  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00280173 (* 1 = 0.00280173 loss)
I1003 13:44:51.812492  7223 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1003 13:45:06.074219  7223 solver.cpp:218] Iteration 99200 (7.01179 iter/s, 14.2617s/100 iters), loss = 0.0112738
I1003 13:45:06.074355  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112726 (* 1 = 0.0112726 loss)
I1003 13:45:06.074374  7223 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1003 13:45:20.338932  7223 solver.cpp:218] Iteration 99300 (7.01039 iter/s, 14.2645s/100 iters), loss = 0.00493827
I1003 13:45:20.338964  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00493707 (* 1 = 0.00493707 loss)
I1003 13:45:20.338971  7223 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1003 13:45:34.610478  7223 solver.cpp:218] Iteration 99400 (7.00699 iter/s, 14.2715s/100 iters), loss = 0.00915461
I1003 13:45:34.610512  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00915341 (* 1 = 0.00915341 loss)
I1003 13:45:34.610532  7223 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1003 13:45:48.166967  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:45:48.736755  7223 solver.cpp:330] Iteration 99500, Testing net (#0)
I1003 13:45:52.103287  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:45:52.243638  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.908
I1003 13:45:52.243674  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37555 (* 1 = 0.37555 loss)
I1003 13:45:52.384663  7223 solver.cpp:218] Iteration 99500 (5.62617 iter/s, 17.7741s/100 iters), loss = 0.00386792
I1003 13:45:52.384696  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00386672 (* 1 = 0.00386672 loss)
I1003 13:45:52.384703  7223 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1003 13:46:06.650058  7223 solver.cpp:218] Iteration 99600 (7.01001 iter/s, 14.2653s/100 iters), loss = 0.00361165
I1003 13:46:06.650089  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00361043 (* 1 = 0.00361043 loss)
I1003 13:46:06.650094  7223 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1003 13:46:20.922017  7223 solver.cpp:218] Iteration 99700 (7.00678 iter/s, 14.2719s/100 iters), loss = 0.00931607
I1003 13:46:20.922135  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00931486 (* 1 = 0.00931486 loss)
I1003 13:46:20.922153  7223 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1003 13:46:35.177472  7223 solver.cpp:218] Iteration 99800 (7.01493 iter/s, 14.2553s/100 iters), loss = 0.00454831
I1003 13:46:35.177511  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0045471 (* 1 = 0.0045471 loss)
I1003 13:46:35.177518  7223 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1003 13:46:49.439044  7223 solver.cpp:218] Iteration 99900 (7.01189 iter/s, 14.2615s/100 iters), loss = 0.0110074
I1003 13:46:49.439087  7223 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110062 (* 1 = 0.0110062 loss)
I1003 13:46:49.439093  7223 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1003 13:47:03.000207  7232 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:47:03.567756  7223 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res56_mpelu_alpha2_beta1_2study_nodecay_gauss_iter_100000.caffemodel
I1003 13:47:03.594753  7223 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res56_mpelu_alpha2_beta1_2study_nodecay_gauss_iter_100000.solverstate
I1003 13:47:03.635396  7223 solver.cpp:310] Iteration 100000, loss = 0.00352315
I1003 13:47:03.635417  7223 solver.cpp:330] Iteration 100000, Testing net (#0)
I1003 13:47:07.003150  7233 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:47:07.143350  7223 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9066
I1003 13:47:07.143386  7223 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376898 (* 1 = 0.376898 loss)
I1003 13:47:07.143393  7223 solver.cpp:315] Optimization Done.
I1003 13:47:07.143394  7223 caffe.cpp:259] Optimization Done.
