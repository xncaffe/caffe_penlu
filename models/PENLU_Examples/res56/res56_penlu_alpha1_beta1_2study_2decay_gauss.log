I1001 19:09:21.588781  5547 caffe.cpp:218] Using GPUs 0
I1001 19:09:21.613621  5547 caffe.cpp:223] GPU 0: GeForce GTX 1080
I1001 19:09:21.845561  5547 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res56_mpelu_alpha1_beta1_2study_2decay_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_mpelu_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I1001 19:09:21.845691  5547 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_mpelu_train_test.prototxt
I1001 19:09:21.849300  5547 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_mpelu_train_test.prototxt
I1001 19:09:21.849314  5547 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1001 19:09:21.849586  5547 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I1001 19:09:21.849710  5547 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I1001 19:09:21.850801  5547 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU1"
  type: "M2PELU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU2"
  type: "M2PELU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU3"
  type: "M2PELU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU4"
  type: "M2PELU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU5"
  type: "M2PELU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU6"
  type: "M2PELU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU7"
  type: "M2PELU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU8"
  type: "M2PELU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU9"
  type: "M2PELU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU10"
  type: "M2PELU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU11"
  type: "M2PELU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU12"
  type: "M2PELU"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU13"
  type: "M2PELU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU14"
  type: "M2PELU"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU15"
  type: "M2PELU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU16"
  type: "M2PELU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU17"
  type: "M2PELU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU18"
  type: "M2PELU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU19"
  type: "M2PELU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU20"
  type: "M2PELU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU21"
  type: "M2PELU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU22"
  type: "M2PELU"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution24"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU23"
  type: "M2PELU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU24"
  type: "M2PELU"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
I1001 19:09:21.851615  5547 layer_factory.hpp:77] Creating layer Data1
I1001 19:09:21.851702  5547 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I1001 19:09:21.851722  5547 net.cpp:84] Creating Layer Data1
I1001 19:09:21.851728  5547 net.cpp:380] Data1 -> Data1
I1001 19:09:21.851744  5547 net.cpp:380] Data1 -> Data2
I1001 19:09:21.851763  5547 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1001 19:09:21.853214  5547 data_layer.cpp:45] output data size: 100,3,28,28
I1001 19:09:21.855530  5547 net.cpp:122] Setting up Data1
I1001 19:09:21.855553  5547 net.cpp:129] Top shape: 100 3 28 28 (235200)
I1001 19:09:21.855558  5547 net.cpp:129] Top shape: 100 (100)
I1001 19:09:21.855561  5547 net.cpp:137] Memory required for data: 941200
I1001 19:09:21.855566  5547 layer_factory.hpp:77] Creating layer Convolution1
I1001 19:09:21.855584  5547 net.cpp:84] Creating Layer Convolution1
I1001 19:09:21.855589  5547 net.cpp:406] Convolution1 <- Data1
I1001 19:09:21.855598  5547 net.cpp:380] Convolution1 -> Convolution1
I1001 19:09:22.007545  5547 net.cpp:122] Setting up Convolution1
I1001 19:09:22.007570  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.007573  5547 net.cpp:137] Memory required for data: 5958800
I1001 19:09:22.007598  5547 layer_factory.hpp:77] Creating layer BatchNorm1
I1001 19:09:22.007608  5547 net.cpp:84] Creating Layer BatchNorm1
I1001 19:09:22.007635  5547 net.cpp:406] BatchNorm1 <- Convolution1
I1001 19:09:22.007642  5547 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1001 19:09:22.007791  5547 net.cpp:122] Setting up BatchNorm1
I1001 19:09:22.007797  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.007800  5547 net.cpp:137] Memory required for data: 10976400
I1001 19:09:22.007807  5547 layer_factory.hpp:77] Creating layer Scale1
I1001 19:09:22.007827  5547 net.cpp:84] Creating Layer Scale1
I1001 19:09:22.007832  5547 net.cpp:406] Scale1 <- Convolution1
I1001 19:09:22.007834  5547 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1001 19:09:22.007894  5547 layer_factory.hpp:77] Creating layer Scale1
I1001 19:09:22.008014  5547 net.cpp:122] Setting up Scale1
I1001 19:09:22.008019  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.008021  5547 net.cpp:137] Memory required for data: 15994000
I1001 19:09:22.008025  5547 layer_factory.hpp:77] Creating layer M2PELU1
I1001 19:09:22.008034  5547 net.cpp:84] Creating Layer M2PELU1
I1001 19:09:22.008036  5547 net.cpp:406] M2PELU1 <- Convolution1
I1001 19:09:22.008040  5547 net.cpp:367] M2PELU1 -> Convolution1 (in-place)
I1001 19:09:22.008677  5547 net.cpp:122] Setting up M2PELU1
I1001 19:09:22.008685  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.008688  5547 net.cpp:137] Memory required for data: 21011600
I1001 19:09:22.008695  5547 layer_factory.hpp:77] Creating layer Convolution1_M2PELU1_0_split
I1001 19:09:22.008700  5547 net.cpp:84] Creating Layer Convolution1_M2PELU1_0_split
I1001 19:09:22.008702  5547 net.cpp:406] Convolution1_M2PELU1_0_split <- Convolution1
I1001 19:09:22.008707  5547 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_0
I1001 19:09:22.008723  5547 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_1
I1001 19:09:22.008754  5547 net.cpp:122] Setting up Convolution1_M2PELU1_0_split
I1001 19:09:22.008759  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.008772  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.008774  5547 net.cpp:137] Memory required for data: 31046800
I1001 19:09:22.008776  5547 layer_factory.hpp:77] Creating layer Convolution2
I1001 19:09:22.008792  5547 net.cpp:84] Creating Layer Convolution2
I1001 19:09:22.008795  5547 net.cpp:406] Convolution2 <- Convolution1_M2PELU1_0_split_0
I1001 19:09:22.008810  5547 net.cpp:380] Convolution2 -> Convolution2
I1001 19:09:22.009665  5547 net.cpp:122] Setting up Convolution2
I1001 19:09:22.009675  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.009678  5547 net.cpp:137] Memory required for data: 36064400
I1001 19:09:22.009693  5547 layer_factory.hpp:77] Creating layer BatchNorm2
I1001 19:09:22.009698  5547 net.cpp:84] Creating Layer BatchNorm2
I1001 19:09:22.009701  5547 net.cpp:406] BatchNorm2 <- Convolution2
I1001 19:09:22.009706  5547 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1001 19:09:22.009829  5547 net.cpp:122] Setting up BatchNorm2
I1001 19:09:22.009833  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.009836  5547 net.cpp:137] Memory required for data: 41082000
I1001 19:09:22.009850  5547 layer_factory.hpp:77] Creating layer Scale2
I1001 19:09:22.009857  5547 net.cpp:84] Creating Layer Scale2
I1001 19:09:22.009860  5547 net.cpp:406] Scale2 <- Convolution2
I1001 19:09:22.009863  5547 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1001 19:09:22.009901  5547 layer_factory.hpp:77] Creating layer Scale2
I1001 19:09:22.009989  5547 net.cpp:122] Setting up Scale2
I1001 19:09:22.009994  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.009996  5547 net.cpp:137] Memory required for data: 46099600
I1001 19:09:22.010010  5547 layer_factory.hpp:77] Creating layer M2PELU2
I1001 19:09:22.010016  5547 net.cpp:84] Creating Layer M2PELU2
I1001 19:09:22.010020  5547 net.cpp:406] M2PELU2 <- Convolution2
I1001 19:09:22.010022  5547 net.cpp:367] M2PELU2 -> Convolution2 (in-place)
I1001 19:09:22.010107  5547 net.cpp:122] Setting up M2PELU2
I1001 19:09:22.010120  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.010123  5547 net.cpp:137] Memory required for data: 51117200
I1001 19:09:22.010129  5547 layer_factory.hpp:77] Creating layer Convolution3
I1001 19:09:22.010138  5547 net.cpp:84] Creating Layer Convolution3
I1001 19:09:22.010140  5547 net.cpp:406] Convolution3 <- Convolution2
I1001 19:09:22.010144  5547 net.cpp:380] Convolution3 -> Convolution3
I1001 19:09:22.011001  5547 net.cpp:122] Setting up Convolution3
I1001 19:09:22.011011  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.011015  5547 net.cpp:137] Memory required for data: 56134800
I1001 19:09:22.011020  5547 layer_factory.hpp:77] Creating layer BatchNorm3
I1001 19:09:22.011025  5547 net.cpp:84] Creating Layer BatchNorm3
I1001 19:09:22.011029  5547 net.cpp:406] BatchNorm3 <- Convolution3
I1001 19:09:22.011034  5547 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1001 19:09:22.011150  5547 net.cpp:122] Setting up BatchNorm3
I1001 19:09:22.011155  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.011157  5547 net.cpp:137] Memory required for data: 61152400
I1001 19:09:22.011162  5547 layer_factory.hpp:77] Creating layer Scale3
I1001 19:09:22.011168  5547 net.cpp:84] Creating Layer Scale3
I1001 19:09:22.011169  5547 net.cpp:406] Scale3 <- Convolution3
I1001 19:09:22.011173  5547 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1001 19:09:22.011198  5547 layer_factory.hpp:77] Creating layer Scale3
I1001 19:09:22.011265  5547 net.cpp:122] Setting up Scale3
I1001 19:09:22.011270  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.011272  5547 net.cpp:137] Memory required for data: 66170000
I1001 19:09:22.011276  5547 layer_factory.hpp:77] Creating layer Eltwise1
I1001 19:09:22.011281  5547 net.cpp:84] Creating Layer Eltwise1
I1001 19:09:22.011284  5547 net.cpp:406] Eltwise1 <- Convolution1_M2PELU1_0_split_1
I1001 19:09:22.011287  5547 net.cpp:406] Eltwise1 <- Convolution3
I1001 19:09:22.011291  5547 net.cpp:380] Eltwise1 -> Eltwise1
I1001 19:09:22.011307  5547 net.cpp:122] Setting up Eltwise1
I1001 19:09:22.011310  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.011313  5547 net.cpp:137] Memory required for data: 71187600
I1001 19:09:22.011315  5547 layer_factory.hpp:77] Creating layer M2PELU3
I1001 19:09:22.011319  5547 net.cpp:84] Creating Layer M2PELU3
I1001 19:09:22.011323  5547 net.cpp:406] M2PELU3 <- Eltwise1
I1001 19:09:22.011327  5547 net.cpp:367] M2PELU3 -> Eltwise1 (in-place)
I1001 19:09:22.011407  5547 net.cpp:122] Setting up M2PELU3
I1001 19:09:22.011412  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.011415  5547 net.cpp:137] Memory required for data: 76205200
I1001 19:09:22.011420  5547 layer_factory.hpp:77] Creating layer Eltwise1_M2PELU3_0_split
I1001 19:09:22.011425  5547 net.cpp:84] Creating Layer Eltwise1_M2PELU3_0_split
I1001 19:09:22.011426  5547 net.cpp:406] Eltwise1_M2PELU3_0_split <- Eltwise1
I1001 19:09:22.011430  5547 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_0
I1001 19:09:22.011435  5547 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_1
I1001 19:09:22.011456  5547 net.cpp:122] Setting up Eltwise1_M2PELU3_0_split
I1001 19:09:22.011461  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.011466  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.011467  5547 net.cpp:137] Memory required for data: 86240400
I1001 19:09:22.011469  5547 layer_factory.hpp:77] Creating layer Convolution4
I1001 19:09:22.011477  5547 net.cpp:84] Creating Layer Convolution4
I1001 19:09:22.011481  5547 net.cpp:406] Convolution4 <- Eltwise1_M2PELU3_0_split_0
I1001 19:09:22.011484  5547 net.cpp:380] Convolution4 -> Convolution4
I1001 19:09:22.012331  5547 net.cpp:122] Setting up Convolution4
I1001 19:09:22.012341  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.012343  5547 net.cpp:137] Memory required for data: 91258000
I1001 19:09:22.012348  5547 layer_factory.hpp:77] Creating layer BatchNorm4
I1001 19:09:22.012362  5547 net.cpp:84] Creating Layer BatchNorm4
I1001 19:09:22.012365  5547 net.cpp:406] BatchNorm4 <- Convolution4
I1001 19:09:22.012369  5547 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1001 19:09:22.012488  5547 net.cpp:122] Setting up BatchNorm4
I1001 19:09:22.012493  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.012496  5547 net.cpp:137] Memory required for data: 96275600
I1001 19:09:22.012501  5547 layer_factory.hpp:77] Creating layer Scale4
I1001 19:09:22.012506  5547 net.cpp:84] Creating Layer Scale4
I1001 19:09:22.012509  5547 net.cpp:406] Scale4 <- Convolution4
I1001 19:09:22.012512  5547 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1001 19:09:22.012537  5547 layer_factory.hpp:77] Creating layer Scale4
I1001 19:09:22.012606  5547 net.cpp:122] Setting up Scale4
I1001 19:09:22.012611  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.012614  5547 net.cpp:137] Memory required for data: 101293200
I1001 19:09:22.012622  5547 layer_factory.hpp:77] Creating layer M2PELU4
I1001 19:09:22.012627  5547 net.cpp:84] Creating Layer M2PELU4
I1001 19:09:22.012630  5547 net.cpp:406] M2PELU4 <- Convolution4
I1001 19:09:22.012634  5547 net.cpp:367] M2PELU4 -> Convolution4 (in-place)
I1001 19:09:22.012712  5547 net.cpp:122] Setting up M2PELU4
I1001 19:09:22.012717  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.012720  5547 net.cpp:137] Memory required for data: 106310800
I1001 19:09:22.012724  5547 layer_factory.hpp:77] Creating layer Convolution5
I1001 19:09:22.012732  5547 net.cpp:84] Creating Layer Convolution5
I1001 19:09:22.012735  5547 net.cpp:406] Convolution5 <- Convolution4
I1001 19:09:22.012739  5547 net.cpp:380] Convolution5 -> Convolution5
I1001 19:09:22.013583  5547 net.cpp:122] Setting up Convolution5
I1001 19:09:22.013593  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.013597  5547 net.cpp:137] Memory required for data: 111328400
I1001 19:09:22.013602  5547 layer_factory.hpp:77] Creating layer BatchNorm5
I1001 19:09:22.013607  5547 net.cpp:84] Creating Layer BatchNorm5
I1001 19:09:22.013610  5547 net.cpp:406] BatchNorm5 <- Convolution5
I1001 19:09:22.013614  5547 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1001 19:09:22.013736  5547 net.cpp:122] Setting up BatchNorm5
I1001 19:09:22.013741  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.013744  5547 net.cpp:137] Memory required for data: 116346000
I1001 19:09:22.013749  5547 layer_factory.hpp:77] Creating layer Scale5
I1001 19:09:22.013754  5547 net.cpp:84] Creating Layer Scale5
I1001 19:09:22.013757  5547 net.cpp:406] Scale5 <- Convolution5
I1001 19:09:22.013761  5547 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1001 19:09:22.013787  5547 layer_factory.hpp:77] Creating layer Scale5
I1001 19:09:22.013859  5547 net.cpp:122] Setting up Scale5
I1001 19:09:22.013862  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.013866  5547 net.cpp:137] Memory required for data: 121363600
I1001 19:09:22.013870  5547 layer_factory.hpp:77] Creating layer Eltwise2
I1001 19:09:22.013875  5547 net.cpp:84] Creating Layer Eltwise2
I1001 19:09:22.013878  5547 net.cpp:406] Eltwise2 <- Eltwise1_M2PELU3_0_split_1
I1001 19:09:22.013880  5547 net.cpp:406] Eltwise2 <- Convolution5
I1001 19:09:22.013885  5547 net.cpp:380] Eltwise2 -> Eltwise2
I1001 19:09:22.013898  5547 net.cpp:122] Setting up Eltwise2
I1001 19:09:22.013902  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.013906  5547 net.cpp:137] Memory required for data: 126381200
I1001 19:09:22.013907  5547 layer_factory.hpp:77] Creating layer M2PELU5
I1001 19:09:22.013912  5547 net.cpp:84] Creating Layer M2PELU5
I1001 19:09:22.013916  5547 net.cpp:406] M2PELU5 <- Eltwise2
I1001 19:09:22.013918  5547 net.cpp:367] M2PELU5 -> Eltwise2 (in-place)
I1001 19:09:22.013996  5547 net.cpp:122] Setting up M2PELU5
I1001 19:09:22.014001  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.014003  5547 net.cpp:137] Memory required for data: 131398800
I1001 19:09:22.014008  5547 layer_factory.hpp:77] Creating layer Eltwise2_M2PELU5_0_split
I1001 19:09:22.014017  5547 net.cpp:84] Creating Layer Eltwise2_M2PELU5_0_split
I1001 19:09:22.014020  5547 net.cpp:406] Eltwise2_M2PELU5_0_split <- Eltwise2
I1001 19:09:22.014024  5547 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_0
I1001 19:09:22.014029  5547 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_1
I1001 19:09:22.014051  5547 net.cpp:122] Setting up Eltwise2_M2PELU5_0_split
I1001 19:09:22.014055  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.014060  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.014063  5547 net.cpp:137] Memory required for data: 141434000
I1001 19:09:22.014065  5547 layer_factory.hpp:77] Creating layer Convolution6
I1001 19:09:22.014071  5547 net.cpp:84] Creating Layer Convolution6
I1001 19:09:22.014075  5547 net.cpp:406] Convolution6 <- Eltwise2_M2PELU5_0_split_0
I1001 19:09:22.014080  5547 net.cpp:380] Convolution6 -> Convolution6
I1001 19:09:22.014961  5547 net.cpp:122] Setting up Convolution6
I1001 19:09:22.014971  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.014976  5547 net.cpp:137] Memory required for data: 146451600
I1001 19:09:22.014981  5547 layer_factory.hpp:77] Creating layer BatchNorm6
I1001 19:09:22.014986  5547 net.cpp:84] Creating Layer BatchNorm6
I1001 19:09:22.014989  5547 net.cpp:406] BatchNorm6 <- Convolution6
I1001 19:09:22.014992  5547 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1001 19:09:22.015116  5547 net.cpp:122] Setting up BatchNorm6
I1001 19:09:22.015121  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.015125  5547 net.cpp:137] Memory required for data: 151469200
I1001 19:09:22.015130  5547 layer_factory.hpp:77] Creating layer Scale6
I1001 19:09:22.015135  5547 net.cpp:84] Creating Layer Scale6
I1001 19:09:22.015137  5547 net.cpp:406] Scale6 <- Convolution6
I1001 19:09:22.015141  5547 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1001 19:09:22.015166  5547 layer_factory.hpp:77] Creating layer Scale6
I1001 19:09:22.015239  5547 net.cpp:122] Setting up Scale6
I1001 19:09:22.015245  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.015249  5547 net.cpp:137] Memory required for data: 156486800
I1001 19:09:22.015252  5547 layer_factory.hpp:77] Creating layer M2PELU6
I1001 19:09:22.015257  5547 net.cpp:84] Creating Layer M2PELU6
I1001 19:09:22.015260  5547 net.cpp:406] M2PELU6 <- Convolution6
I1001 19:09:22.015264  5547 net.cpp:367] M2PELU6 -> Convolution6 (in-place)
I1001 19:09:22.015347  5547 net.cpp:122] Setting up M2PELU6
I1001 19:09:22.015352  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.015353  5547 net.cpp:137] Memory required for data: 161504400
I1001 19:09:22.015357  5547 layer_factory.hpp:77] Creating layer Convolution7
I1001 19:09:22.015365  5547 net.cpp:84] Creating Layer Convolution7
I1001 19:09:22.015368  5547 net.cpp:406] Convolution7 <- Convolution6
I1001 19:09:22.015372  5547 net.cpp:380] Convolution7 -> Convolution7
I1001 19:09:22.015907  5547 net.cpp:122] Setting up Convolution7
I1001 19:09:22.015916  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.015919  5547 net.cpp:137] Memory required for data: 166522000
I1001 19:09:22.015924  5547 layer_factory.hpp:77] Creating layer BatchNorm7
I1001 19:09:22.015929  5547 net.cpp:84] Creating Layer BatchNorm7
I1001 19:09:22.015933  5547 net.cpp:406] BatchNorm7 <- Convolution7
I1001 19:09:22.015936  5547 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1001 19:09:22.016060  5547 net.cpp:122] Setting up BatchNorm7
I1001 19:09:22.016065  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.016068  5547 net.cpp:137] Memory required for data: 171539600
I1001 19:09:22.016073  5547 layer_factory.hpp:77] Creating layer Scale7
I1001 19:09:22.016079  5547 net.cpp:84] Creating Layer Scale7
I1001 19:09:22.016083  5547 net.cpp:406] Scale7 <- Convolution7
I1001 19:09:22.016086  5547 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1001 19:09:22.016111  5547 layer_factory.hpp:77] Creating layer Scale7
I1001 19:09:22.016192  5547 net.cpp:122] Setting up Scale7
I1001 19:09:22.016197  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.016201  5547 net.cpp:137] Memory required for data: 176557200
I1001 19:09:22.016206  5547 layer_factory.hpp:77] Creating layer Eltwise3
I1001 19:09:22.016209  5547 net.cpp:84] Creating Layer Eltwise3
I1001 19:09:22.016212  5547 net.cpp:406] Eltwise3 <- Eltwise2_M2PELU5_0_split_1
I1001 19:09:22.016216  5547 net.cpp:406] Eltwise3 <- Convolution7
I1001 19:09:22.016221  5547 net.cpp:380] Eltwise3 -> Eltwise3
I1001 19:09:22.016237  5547 net.cpp:122] Setting up Eltwise3
I1001 19:09:22.016242  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.016243  5547 net.cpp:137] Memory required for data: 181574800
I1001 19:09:22.016245  5547 layer_factory.hpp:77] Creating layer M2PELU7
I1001 19:09:22.016250  5547 net.cpp:84] Creating Layer M2PELU7
I1001 19:09:22.016253  5547 net.cpp:406] M2PELU7 <- Eltwise3
I1001 19:09:22.016258  5547 net.cpp:367] M2PELU7 -> Eltwise3 (in-place)
I1001 19:09:22.016338  5547 net.cpp:122] Setting up M2PELU7
I1001 19:09:22.016343  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.016345  5547 net.cpp:137] Memory required for data: 186592400
I1001 19:09:22.016348  5547 layer_factory.hpp:77] Creating layer Eltwise3_M2PELU7_0_split
I1001 19:09:22.016355  5547 net.cpp:84] Creating Layer Eltwise3_M2PELU7_0_split
I1001 19:09:22.016357  5547 net.cpp:406] Eltwise3_M2PELU7_0_split <- Eltwise3
I1001 19:09:22.016360  5547 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_0
I1001 19:09:22.016364  5547 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_1
I1001 19:09:22.016386  5547 net.cpp:122] Setting up Eltwise3_M2PELU7_0_split
I1001 19:09:22.016391  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.016393  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.016396  5547 net.cpp:137] Memory required for data: 196627600
I1001 19:09:22.016399  5547 layer_factory.hpp:77] Creating layer Convolution8
I1001 19:09:22.016404  5547 net.cpp:84] Creating Layer Convolution8
I1001 19:09:22.016407  5547 net.cpp:406] Convolution8 <- Eltwise3_M2PELU7_0_split_0
I1001 19:09:22.016412  5547 net.cpp:380] Convolution8 -> Convolution8
I1001 19:09:22.017251  5547 net.cpp:122] Setting up Convolution8
I1001 19:09:22.017261  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.017264  5547 net.cpp:137] Memory required for data: 201645200
I1001 19:09:22.017274  5547 layer_factory.hpp:77] Creating layer BatchNorm8
I1001 19:09:22.017280  5547 net.cpp:84] Creating Layer BatchNorm8
I1001 19:09:22.017284  5547 net.cpp:406] BatchNorm8 <- Convolution8
I1001 19:09:22.017287  5547 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1001 19:09:22.017410  5547 net.cpp:122] Setting up BatchNorm8
I1001 19:09:22.017416  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.017418  5547 net.cpp:137] Memory required for data: 206662800
I1001 19:09:22.017433  5547 layer_factory.hpp:77] Creating layer Scale8
I1001 19:09:22.017438  5547 net.cpp:84] Creating Layer Scale8
I1001 19:09:22.017441  5547 net.cpp:406] Scale8 <- Convolution8
I1001 19:09:22.017446  5547 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1001 19:09:22.017480  5547 layer_factory.hpp:77] Creating layer Scale8
I1001 19:09:22.017572  5547 net.cpp:122] Setting up Scale8
I1001 19:09:22.017577  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.017580  5547 net.cpp:137] Memory required for data: 211680400
I1001 19:09:22.017594  5547 layer_factory.hpp:77] Creating layer M2PELU8
I1001 19:09:22.017601  5547 net.cpp:84] Creating Layer M2PELU8
I1001 19:09:22.017603  5547 net.cpp:406] M2PELU8 <- Convolution8
I1001 19:09:22.017607  5547 net.cpp:367] M2PELU8 -> Convolution8 (in-place)
I1001 19:09:22.017688  5547 net.cpp:122] Setting up M2PELU8
I1001 19:09:22.017693  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.017696  5547 net.cpp:137] Memory required for data: 216698000
I1001 19:09:22.017706  5547 layer_factory.hpp:77] Creating layer Convolution9
I1001 19:09:22.017714  5547 net.cpp:84] Creating Layer Convolution9
I1001 19:09:22.017717  5547 net.cpp:406] Convolution9 <- Convolution8
I1001 19:09:22.017722  5547 net.cpp:380] Convolution9 -> Convolution9
I1001 19:09:22.018630  5547 net.cpp:122] Setting up Convolution9
I1001 19:09:22.018640  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.018643  5547 net.cpp:137] Memory required for data: 221715600
I1001 19:09:22.018648  5547 layer_factory.hpp:77] Creating layer BatchNorm9
I1001 19:09:22.018653  5547 net.cpp:84] Creating Layer BatchNorm9
I1001 19:09:22.018657  5547 net.cpp:406] BatchNorm9 <- Convolution9
I1001 19:09:22.018662  5547 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1001 19:09:22.018793  5547 net.cpp:122] Setting up BatchNorm9
I1001 19:09:22.018798  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.018801  5547 net.cpp:137] Memory required for data: 226733200
I1001 19:09:22.018806  5547 layer_factory.hpp:77] Creating layer Scale9
I1001 19:09:22.018811  5547 net.cpp:84] Creating Layer Scale9
I1001 19:09:22.018815  5547 net.cpp:406] Scale9 <- Convolution9
I1001 19:09:22.018818  5547 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1001 19:09:22.018844  5547 layer_factory.hpp:77] Creating layer Scale9
I1001 19:09:22.018924  5547 net.cpp:122] Setting up Scale9
I1001 19:09:22.018929  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.018934  5547 net.cpp:137] Memory required for data: 231750800
I1001 19:09:22.018937  5547 layer_factory.hpp:77] Creating layer Eltwise4
I1001 19:09:22.018941  5547 net.cpp:84] Creating Layer Eltwise4
I1001 19:09:22.018944  5547 net.cpp:406] Eltwise4 <- Eltwise3_M2PELU7_0_split_1
I1001 19:09:22.018947  5547 net.cpp:406] Eltwise4 <- Convolution9
I1001 19:09:22.018954  5547 net.cpp:380] Eltwise4 -> Eltwise4
I1001 19:09:22.018968  5547 net.cpp:122] Setting up Eltwise4
I1001 19:09:22.018973  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.018975  5547 net.cpp:137] Memory required for data: 236768400
I1001 19:09:22.018978  5547 layer_factory.hpp:77] Creating layer M2PELU9
I1001 19:09:22.018983  5547 net.cpp:84] Creating Layer M2PELU9
I1001 19:09:22.018985  5547 net.cpp:406] M2PELU9 <- Eltwise4
I1001 19:09:22.018990  5547 net.cpp:367] M2PELU9 -> Eltwise4 (in-place)
I1001 19:09:22.019074  5547 net.cpp:122] Setting up M2PELU9
I1001 19:09:22.019079  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.019083  5547 net.cpp:137] Memory required for data: 241786000
I1001 19:09:22.019085  5547 layer_factory.hpp:77] Creating layer Eltwise4_M2PELU9_0_split
I1001 19:09:22.019089  5547 net.cpp:84] Creating Layer Eltwise4_M2PELU9_0_split
I1001 19:09:22.019091  5547 net.cpp:406] Eltwise4_M2PELU9_0_split <- Eltwise4
I1001 19:09:22.019095  5547 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_0
I1001 19:09:22.019099  5547 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_1
I1001 19:09:22.019121  5547 net.cpp:122] Setting up Eltwise4_M2PELU9_0_split
I1001 19:09:22.019126  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.019129  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.019131  5547 net.cpp:137] Memory required for data: 251821200
I1001 19:09:22.019134  5547 layer_factory.hpp:77] Creating layer Convolution10
I1001 19:09:22.019142  5547 net.cpp:84] Creating Layer Convolution10
I1001 19:09:22.019145  5547 net.cpp:406] Convolution10 <- Eltwise4_M2PELU9_0_split_0
I1001 19:09:22.019150  5547 net.cpp:380] Convolution10 -> Convolution10
I1001 19:09:22.020115  5547 net.cpp:122] Setting up Convolution10
I1001 19:09:22.020126  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.020129  5547 net.cpp:137] Memory required for data: 256838800
I1001 19:09:22.020143  5547 layer_factory.hpp:77] Creating layer BatchNorm10
I1001 19:09:22.020150  5547 net.cpp:84] Creating Layer BatchNorm10
I1001 19:09:22.020153  5547 net.cpp:406] BatchNorm10 <- Convolution10
I1001 19:09:22.020166  5547 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1001 19:09:22.020323  5547 net.cpp:122] Setting up BatchNorm10
I1001 19:09:22.020328  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.020330  5547 net.cpp:137] Memory required for data: 261856400
I1001 19:09:22.020346  5547 layer_factory.hpp:77] Creating layer Scale10
I1001 19:09:22.020351  5547 net.cpp:84] Creating Layer Scale10
I1001 19:09:22.020354  5547 net.cpp:406] Scale10 <- Convolution10
I1001 19:09:22.020359  5547 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1001 19:09:22.020395  5547 layer_factory.hpp:77] Creating layer Scale10
I1001 19:09:22.020491  5547 net.cpp:122] Setting up Scale10
I1001 19:09:22.020496  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.020509  5547 net.cpp:137] Memory required for data: 266874000
I1001 19:09:22.020514  5547 layer_factory.hpp:77] Creating layer M2PELU10
I1001 19:09:22.020519  5547 net.cpp:84] Creating Layer M2PELU10
I1001 19:09:22.020521  5547 net.cpp:406] M2PELU10 <- Convolution10
I1001 19:09:22.020524  5547 net.cpp:367] M2PELU10 -> Convolution10 (in-place)
I1001 19:09:22.020608  5547 net.cpp:122] Setting up M2PELU10
I1001 19:09:22.020614  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.020617  5547 net.cpp:137] Memory required for data: 271891600
I1001 19:09:22.020620  5547 layer_factory.hpp:77] Creating layer Convolution11
I1001 19:09:22.020629  5547 net.cpp:84] Creating Layer Convolution11
I1001 19:09:22.020632  5547 net.cpp:406] Convolution11 <- Convolution10
I1001 19:09:22.020637  5547 net.cpp:380] Convolution11 -> Convolution11
I1001 19:09:22.021555  5547 net.cpp:122] Setting up Convolution11
I1001 19:09:22.021566  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.021569  5547 net.cpp:137] Memory required for data: 276909200
I1001 19:09:22.021574  5547 layer_factory.hpp:77] Creating layer BatchNorm11
I1001 19:09:22.021580  5547 net.cpp:84] Creating Layer BatchNorm11
I1001 19:09:22.021584  5547 net.cpp:406] BatchNorm11 <- Convolution11
I1001 19:09:22.021587  5547 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1001 19:09:22.021728  5547 net.cpp:122] Setting up BatchNorm11
I1001 19:09:22.021733  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.021736  5547 net.cpp:137] Memory required for data: 281926800
I1001 19:09:22.021750  5547 layer_factory.hpp:77] Creating layer Scale11
I1001 19:09:22.021755  5547 net.cpp:84] Creating Layer Scale11
I1001 19:09:22.021759  5547 net.cpp:406] Scale11 <- Convolution11
I1001 19:09:22.021772  5547 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1001 19:09:22.021798  5547 layer_factory.hpp:77] Creating layer Scale11
I1001 19:09:22.021877  5547 net.cpp:122] Setting up Scale11
I1001 19:09:22.021883  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.021885  5547 net.cpp:137] Memory required for data: 286944400
I1001 19:09:22.021889  5547 layer_factory.hpp:77] Creating layer Eltwise5
I1001 19:09:22.021893  5547 net.cpp:84] Creating Layer Eltwise5
I1001 19:09:22.021898  5547 net.cpp:406] Eltwise5 <- Eltwise4_M2PELU9_0_split_1
I1001 19:09:22.021900  5547 net.cpp:406] Eltwise5 <- Convolution11
I1001 19:09:22.021904  5547 net.cpp:380] Eltwise5 -> Eltwise5
I1001 19:09:22.021921  5547 net.cpp:122] Setting up Eltwise5
I1001 19:09:22.021925  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.021929  5547 net.cpp:137] Memory required for data: 291962000
I1001 19:09:22.021931  5547 layer_factory.hpp:77] Creating layer M2PELU11
I1001 19:09:22.021935  5547 net.cpp:84] Creating Layer M2PELU11
I1001 19:09:22.021939  5547 net.cpp:406] M2PELU11 <- Eltwise5
I1001 19:09:22.021942  5547 net.cpp:367] M2PELU11 -> Eltwise5 (in-place)
I1001 19:09:22.022027  5547 net.cpp:122] Setting up M2PELU11
I1001 19:09:22.022032  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.022035  5547 net.cpp:137] Memory required for data: 296979600
I1001 19:09:22.022039  5547 layer_factory.hpp:77] Creating layer Eltwise5_M2PELU11_0_split
I1001 19:09:22.022044  5547 net.cpp:84] Creating Layer Eltwise5_M2PELU11_0_split
I1001 19:09:22.022053  5547 net.cpp:406] Eltwise5_M2PELU11_0_split <- Eltwise5
I1001 19:09:22.022058  5547 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_0
I1001 19:09:22.022063  5547 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_1
I1001 19:09:22.022086  5547 net.cpp:122] Setting up Eltwise5_M2PELU11_0_split
I1001 19:09:22.022091  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.022095  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.022097  5547 net.cpp:137] Memory required for data: 307014800
I1001 19:09:22.022101  5547 layer_factory.hpp:77] Creating layer Convolution12
I1001 19:09:22.022106  5547 net.cpp:84] Creating Layer Convolution12
I1001 19:09:22.022110  5547 net.cpp:406] Convolution12 <- Eltwise5_M2PELU11_0_split_0
I1001 19:09:22.022114  5547 net.cpp:380] Convolution12 -> Convolution12
I1001 19:09:22.023027  5547 net.cpp:122] Setting up Convolution12
I1001 19:09:22.023038  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.023041  5547 net.cpp:137] Memory required for data: 312032400
I1001 19:09:22.023046  5547 layer_factory.hpp:77] Creating layer BatchNorm12
I1001 19:09:22.023052  5547 net.cpp:84] Creating Layer BatchNorm12
I1001 19:09:22.023056  5547 net.cpp:406] BatchNorm12 <- Convolution12
I1001 19:09:22.023059  5547 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1001 19:09:22.023191  5547 net.cpp:122] Setting up BatchNorm12
I1001 19:09:22.023197  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.023200  5547 net.cpp:137] Memory required for data: 317050000
I1001 19:09:22.023205  5547 layer_factory.hpp:77] Creating layer Scale12
I1001 19:09:22.023210  5547 net.cpp:84] Creating Layer Scale12
I1001 19:09:22.023213  5547 net.cpp:406] Scale12 <- Convolution12
I1001 19:09:22.023216  5547 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1001 19:09:22.023243  5547 layer_factory.hpp:77] Creating layer Scale12
I1001 19:09:22.023320  5547 net.cpp:122] Setting up Scale12
I1001 19:09:22.023325  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.023329  5547 net.cpp:137] Memory required for data: 322067600
I1001 19:09:22.023332  5547 layer_factory.hpp:77] Creating layer M2PELU12
I1001 19:09:22.023339  5547 net.cpp:84] Creating Layer M2PELU12
I1001 19:09:22.023341  5547 net.cpp:406] M2PELU12 <- Convolution12
I1001 19:09:22.023345  5547 net.cpp:367] M2PELU12 -> Convolution12 (in-place)
I1001 19:09:22.023428  5547 net.cpp:122] Setting up M2PELU12
I1001 19:09:22.023433  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.023437  5547 net.cpp:137] Memory required for data: 327085200
I1001 19:09:22.023440  5547 layer_factory.hpp:77] Creating layer Convolution13
I1001 19:09:22.023448  5547 net.cpp:84] Creating Layer Convolution13
I1001 19:09:22.023452  5547 net.cpp:406] Convolution13 <- Convolution12
I1001 19:09:22.023455  5547 net.cpp:380] Convolution13 -> Convolution13
I1001 19:09:22.024343  5547 net.cpp:122] Setting up Convolution13
I1001 19:09:22.024353  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.024356  5547 net.cpp:137] Memory required for data: 332102800
I1001 19:09:22.024360  5547 layer_factory.hpp:77] Creating layer BatchNorm13
I1001 19:09:22.024369  5547 net.cpp:84] Creating Layer BatchNorm13
I1001 19:09:22.024371  5547 net.cpp:406] BatchNorm13 <- Convolution13
I1001 19:09:22.024375  5547 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1001 19:09:22.024507  5547 net.cpp:122] Setting up BatchNorm13
I1001 19:09:22.024511  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.024514  5547 net.cpp:137] Memory required for data: 337120400
I1001 19:09:22.024519  5547 layer_factory.hpp:77] Creating layer Scale13
I1001 19:09:22.024524  5547 net.cpp:84] Creating Layer Scale13
I1001 19:09:22.024528  5547 net.cpp:406] Scale13 <- Convolution13
I1001 19:09:22.024533  5547 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1001 19:09:22.024559  5547 layer_factory.hpp:77] Creating layer Scale13
I1001 19:09:22.024646  5547 net.cpp:122] Setting up Scale13
I1001 19:09:22.024652  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.024654  5547 net.cpp:137] Memory required for data: 342138000
I1001 19:09:22.024658  5547 layer_factory.hpp:77] Creating layer Eltwise6
I1001 19:09:22.024662  5547 net.cpp:84] Creating Layer Eltwise6
I1001 19:09:22.024667  5547 net.cpp:406] Eltwise6 <- Eltwise5_M2PELU11_0_split_1
I1001 19:09:22.024669  5547 net.cpp:406] Eltwise6 <- Convolution13
I1001 19:09:22.024673  5547 net.cpp:380] Eltwise6 -> Eltwise6
I1001 19:09:22.024691  5547 net.cpp:122] Setting up Eltwise6
I1001 19:09:22.024696  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.024699  5547 net.cpp:137] Memory required for data: 347155600
I1001 19:09:22.024703  5547 layer_factory.hpp:77] Creating layer M2PELU13
I1001 19:09:22.024711  5547 net.cpp:84] Creating Layer M2PELU13
I1001 19:09:22.024714  5547 net.cpp:406] M2PELU13 <- Eltwise6
I1001 19:09:22.024718  5547 net.cpp:367] M2PELU13 -> Eltwise6 (in-place)
I1001 19:09:22.024806  5547 net.cpp:122] Setting up M2PELU13
I1001 19:09:22.024811  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.024813  5547 net.cpp:137] Memory required for data: 352173200
I1001 19:09:22.024817  5547 layer_factory.hpp:77] Creating layer Eltwise6_M2PELU13_0_split
I1001 19:09:22.024821  5547 net.cpp:84] Creating Layer Eltwise6_M2PELU13_0_split
I1001 19:09:22.024824  5547 net.cpp:406] Eltwise6_M2PELU13_0_split <- Eltwise6
I1001 19:09:22.024828  5547 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_0
I1001 19:09:22.024832  5547 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_1
I1001 19:09:22.024855  5547 net.cpp:122] Setting up Eltwise6_M2PELU13_0_split
I1001 19:09:22.024860  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.024863  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.024866  5547 net.cpp:137] Memory required for data: 362208400
I1001 19:09:22.024868  5547 layer_factory.hpp:77] Creating layer Convolution14
I1001 19:09:22.024875  5547 net.cpp:84] Creating Layer Convolution14
I1001 19:09:22.024878  5547 net.cpp:406] Convolution14 <- Eltwise6_M2PELU13_0_split_0
I1001 19:09:22.024881  5547 net.cpp:380] Convolution14 -> Convolution14
I1001 19:09:22.025764  5547 net.cpp:122] Setting up Convolution14
I1001 19:09:22.025774  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.025775  5547 net.cpp:137] Memory required for data: 367226000
I1001 19:09:22.025780  5547 layer_factory.hpp:77] Creating layer BatchNorm14
I1001 19:09:22.025786  5547 net.cpp:84] Creating Layer BatchNorm14
I1001 19:09:22.025789  5547 net.cpp:406] BatchNorm14 <- Convolution14
I1001 19:09:22.025792  5547 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1001 19:09:22.025924  5547 net.cpp:122] Setting up BatchNorm14
I1001 19:09:22.025928  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.025930  5547 net.cpp:137] Memory required for data: 372243600
I1001 19:09:22.025935  5547 layer_factory.hpp:77] Creating layer Scale14
I1001 19:09:22.025940  5547 net.cpp:84] Creating Layer Scale14
I1001 19:09:22.025943  5547 net.cpp:406] Scale14 <- Convolution14
I1001 19:09:22.025945  5547 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1001 19:09:22.025971  5547 layer_factory.hpp:77] Creating layer Scale14
I1001 19:09:22.026051  5547 net.cpp:122] Setting up Scale14
I1001 19:09:22.026055  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.026058  5547 net.cpp:137] Memory required for data: 377261200
I1001 19:09:22.026062  5547 layer_factory.hpp:77] Creating layer M2PELU14
I1001 19:09:22.026067  5547 net.cpp:84] Creating Layer M2PELU14
I1001 19:09:22.026069  5547 net.cpp:406] M2PELU14 <- Convolution14
I1001 19:09:22.026073  5547 net.cpp:367] M2PELU14 -> Convolution14 (in-place)
I1001 19:09:22.026156  5547 net.cpp:122] Setting up M2PELU14
I1001 19:09:22.026160  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.026162  5547 net.cpp:137] Memory required for data: 382278800
I1001 19:09:22.026172  5547 layer_factory.hpp:77] Creating layer Convolution15
I1001 19:09:22.026180  5547 net.cpp:84] Creating Layer Convolution15
I1001 19:09:22.026182  5547 net.cpp:406] Convolution15 <- Convolution14
I1001 19:09:22.026186  5547 net.cpp:380] Convolution15 -> Convolution15
I1001 19:09:22.027076  5547 net.cpp:122] Setting up Convolution15
I1001 19:09:22.027086  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.027088  5547 net.cpp:137] Memory required for data: 387296400
I1001 19:09:22.027092  5547 layer_factory.hpp:77] Creating layer BatchNorm15
I1001 19:09:22.027098  5547 net.cpp:84] Creating Layer BatchNorm15
I1001 19:09:22.027101  5547 net.cpp:406] BatchNorm15 <- Convolution15
I1001 19:09:22.027104  5547 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1001 19:09:22.027236  5547 net.cpp:122] Setting up BatchNorm15
I1001 19:09:22.027240  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.027242  5547 net.cpp:137] Memory required for data: 392314000
I1001 19:09:22.027258  5547 layer_factory.hpp:77] Creating layer Scale15
I1001 19:09:22.027262  5547 net.cpp:84] Creating Layer Scale15
I1001 19:09:22.027264  5547 net.cpp:406] Scale15 <- Convolution15
I1001 19:09:22.027268  5547 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1001 19:09:22.027295  5547 layer_factory.hpp:77] Creating layer Scale15
I1001 19:09:22.027374  5547 net.cpp:122] Setting up Scale15
I1001 19:09:22.027379  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.027381  5547 net.cpp:137] Memory required for data: 397331600
I1001 19:09:22.027384  5547 layer_factory.hpp:77] Creating layer Eltwise7
I1001 19:09:22.027389  5547 net.cpp:84] Creating Layer Eltwise7
I1001 19:09:22.027391  5547 net.cpp:406] Eltwise7 <- Eltwise6_M2PELU13_0_split_1
I1001 19:09:22.027395  5547 net.cpp:406] Eltwise7 <- Convolution15
I1001 19:09:22.027397  5547 net.cpp:380] Eltwise7 -> Eltwise7
I1001 19:09:22.027411  5547 net.cpp:122] Setting up Eltwise7
I1001 19:09:22.027415  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.027417  5547 net.cpp:137] Memory required for data: 402349200
I1001 19:09:22.027420  5547 layer_factory.hpp:77] Creating layer M2PELU15
I1001 19:09:22.027425  5547 net.cpp:84] Creating Layer M2PELU15
I1001 19:09:22.027426  5547 net.cpp:406] M2PELU15 <- Eltwise7
I1001 19:09:22.027431  5547 net.cpp:367] M2PELU15 -> Eltwise7 (in-place)
I1001 19:09:22.027518  5547 net.cpp:122] Setting up M2PELU15
I1001 19:09:22.027521  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.027523  5547 net.cpp:137] Memory required for data: 407366800
I1001 19:09:22.027526  5547 layer_factory.hpp:77] Creating layer Eltwise7_M2PELU15_0_split
I1001 19:09:22.027530  5547 net.cpp:84] Creating Layer Eltwise7_M2PELU15_0_split
I1001 19:09:22.027534  5547 net.cpp:406] Eltwise7_M2PELU15_0_split <- Eltwise7
I1001 19:09:22.027536  5547 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_0
I1001 19:09:22.027540  5547 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_1
I1001 19:09:22.027562  5547 net.cpp:122] Setting up Eltwise7_M2PELU15_0_split
I1001 19:09:22.027566  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.027570  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.027571  5547 net.cpp:137] Memory required for data: 417402000
I1001 19:09:22.027573  5547 layer_factory.hpp:77] Creating layer Convolution16
I1001 19:09:22.027580  5547 net.cpp:84] Creating Layer Convolution16
I1001 19:09:22.027582  5547 net.cpp:406] Convolution16 <- Eltwise7_M2PELU15_0_split_0
I1001 19:09:22.027586  5547 net.cpp:380] Convolution16 -> Convolution16
I1001 19:09:22.028468  5547 net.cpp:122] Setting up Convolution16
I1001 19:09:22.028477  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.028481  5547 net.cpp:137] Memory required for data: 422419600
I1001 19:09:22.028484  5547 layer_factory.hpp:77] Creating layer BatchNorm16
I1001 19:09:22.028489  5547 net.cpp:84] Creating Layer BatchNorm16
I1001 19:09:22.028491  5547 net.cpp:406] BatchNorm16 <- Convolution16
I1001 19:09:22.028502  5547 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1001 19:09:22.028637  5547 net.cpp:122] Setting up BatchNorm16
I1001 19:09:22.028642  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.028645  5547 net.cpp:137] Memory required for data: 427437200
I1001 19:09:22.028650  5547 layer_factory.hpp:77] Creating layer Scale16
I1001 19:09:22.028653  5547 net.cpp:84] Creating Layer Scale16
I1001 19:09:22.028656  5547 net.cpp:406] Scale16 <- Convolution16
I1001 19:09:22.028659  5547 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1001 19:09:22.028684  5547 layer_factory.hpp:77] Creating layer Scale16
I1001 19:09:22.028761  5547 net.cpp:122] Setting up Scale16
I1001 19:09:22.028765  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.028767  5547 net.cpp:137] Memory required for data: 432454800
I1001 19:09:22.028771  5547 layer_factory.hpp:77] Creating layer M2PELU16
I1001 19:09:22.028776  5547 net.cpp:84] Creating Layer M2PELU16
I1001 19:09:22.028779  5547 net.cpp:406] M2PELU16 <- Convolution16
I1001 19:09:22.028782  5547 net.cpp:367] M2PELU16 -> Convolution16 (in-place)
I1001 19:09:22.028869  5547 net.cpp:122] Setting up M2PELU16
I1001 19:09:22.028873  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.028875  5547 net.cpp:137] Memory required for data: 437472400
I1001 19:09:22.028879  5547 layer_factory.hpp:77] Creating layer Convolution17
I1001 19:09:22.028885  5547 net.cpp:84] Creating Layer Convolution17
I1001 19:09:22.028888  5547 net.cpp:406] Convolution17 <- Convolution16
I1001 19:09:22.028892  5547 net.cpp:380] Convolution17 -> Convolution17
I1001 19:09:22.029451  5547 net.cpp:122] Setting up Convolution17
I1001 19:09:22.029459  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.029462  5547 net.cpp:137] Memory required for data: 442490000
I1001 19:09:22.029466  5547 layer_factory.hpp:77] Creating layer BatchNorm17
I1001 19:09:22.029470  5547 net.cpp:84] Creating Layer BatchNorm17
I1001 19:09:22.029474  5547 net.cpp:406] BatchNorm17 <- Convolution17
I1001 19:09:22.029477  5547 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1001 19:09:22.029608  5547 net.cpp:122] Setting up BatchNorm17
I1001 19:09:22.029613  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.029614  5547 net.cpp:137] Memory required for data: 447507600
I1001 19:09:22.029619  5547 layer_factory.hpp:77] Creating layer Scale17
I1001 19:09:22.029623  5547 net.cpp:84] Creating Layer Scale17
I1001 19:09:22.029625  5547 net.cpp:406] Scale17 <- Convolution17
I1001 19:09:22.029629  5547 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1001 19:09:22.029654  5547 layer_factory.hpp:77] Creating layer Scale17
I1001 19:09:22.029731  5547 net.cpp:122] Setting up Scale17
I1001 19:09:22.029736  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.029737  5547 net.cpp:137] Memory required for data: 452525200
I1001 19:09:22.029742  5547 layer_factory.hpp:77] Creating layer Eltwise8
I1001 19:09:22.029745  5547 net.cpp:84] Creating Layer Eltwise8
I1001 19:09:22.029748  5547 net.cpp:406] Eltwise8 <- Eltwise7_M2PELU15_0_split_1
I1001 19:09:22.029750  5547 net.cpp:406] Eltwise8 <- Convolution17
I1001 19:09:22.029754  5547 net.cpp:380] Eltwise8 -> Eltwise8
I1001 19:09:22.029769  5547 net.cpp:122] Setting up Eltwise8
I1001 19:09:22.029773  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.029775  5547 net.cpp:137] Memory required for data: 457542800
I1001 19:09:22.029778  5547 layer_factory.hpp:77] Creating layer M2PELU17
I1001 19:09:22.029783  5547 net.cpp:84] Creating Layer M2PELU17
I1001 19:09:22.029784  5547 net.cpp:406] M2PELU17 <- Eltwise8
I1001 19:09:22.029788  5547 net.cpp:367] M2PELU17 -> Eltwise8 (in-place)
I1001 19:09:22.029875  5547 net.cpp:122] Setting up M2PELU17
I1001 19:09:22.029878  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.029881  5547 net.cpp:137] Memory required for data: 462560400
I1001 19:09:22.029884  5547 layer_factory.hpp:77] Creating layer Eltwise8_M2PELU17_0_split
I1001 19:09:22.029893  5547 net.cpp:84] Creating Layer Eltwise8_M2PELU17_0_split
I1001 19:09:22.029896  5547 net.cpp:406] Eltwise8_M2PELU17_0_split <- Eltwise8
I1001 19:09:22.029901  5547 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_0
I1001 19:09:22.029904  5547 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_1
I1001 19:09:22.029927  5547 net.cpp:122] Setting up Eltwise8_M2PELU17_0_split
I1001 19:09:22.029932  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.029934  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.029937  5547 net.cpp:137] Memory required for data: 472595600
I1001 19:09:22.029938  5547 layer_factory.hpp:77] Creating layer Convolution18
I1001 19:09:22.029944  5547 net.cpp:84] Creating Layer Convolution18
I1001 19:09:22.029947  5547 net.cpp:406] Convolution18 <- Eltwise8_M2PELU17_0_split_0
I1001 19:09:22.029950  5547 net.cpp:380] Convolution18 -> Convolution18
I1001 19:09:22.030839  5547 net.cpp:122] Setting up Convolution18
I1001 19:09:22.030848  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.030851  5547 net.cpp:137] Memory required for data: 477613200
I1001 19:09:22.030855  5547 layer_factory.hpp:77] Creating layer BatchNorm18
I1001 19:09:22.030860  5547 net.cpp:84] Creating Layer BatchNorm18
I1001 19:09:22.030864  5547 net.cpp:406] BatchNorm18 <- Convolution18
I1001 19:09:22.030867  5547 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1001 19:09:22.030998  5547 net.cpp:122] Setting up BatchNorm18
I1001 19:09:22.031003  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.031005  5547 net.cpp:137] Memory required for data: 482630800
I1001 19:09:22.031009  5547 layer_factory.hpp:77] Creating layer Scale18
I1001 19:09:22.031014  5547 net.cpp:84] Creating Layer Scale18
I1001 19:09:22.031016  5547 net.cpp:406] Scale18 <- Convolution18
I1001 19:09:22.031019  5547 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1001 19:09:22.031045  5547 layer_factory.hpp:77] Creating layer Scale18
I1001 19:09:22.031123  5547 net.cpp:122] Setting up Scale18
I1001 19:09:22.031127  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.031129  5547 net.cpp:137] Memory required for data: 487648400
I1001 19:09:22.031133  5547 layer_factory.hpp:77] Creating layer M2PELU18
I1001 19:09:22.031138  5547 net.cpp:84] Creating Layer M2PELU18
I1001 19:09:22.031141  5547 net.cpp:406] M2PELU18 <- Convolution18
I1001 19:09:22.031143  5547 net.cpp:367] M2PELU18 -> Convolution18 (in-place)
I1001 19:09:22.031226  5547 net.cpp:122] Setting up M2PELU18
I1001 19:09:22.031231  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.031234  5547 net.cpp:137] Memory required for data: 492666000
I1001 19:09:22.031236  5547 layer_factory.hpp:77] Creating layer Convolution19
I1001 19:09:22.031244  5547 net.cpp:84] Creating Layer Convolution19
I1001 19:09:22.031246  5547 net.cpp:406] Convolution19 <- Convolution18
I1001 19:09:22.031250  5547 net.cpp:380] Convolution19 -> Convolution19
I1001 19:09:22.032148  5547 net.cpp:122] Setting up Convolution19
I1001 19:09:22.032157  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.032160  5547 net.cpp:137] Memory required for data: 497683600
I1001 19:09:22.032165  5547 layer_factory.hpp:77] Creating layer BatchNorm19
I1001 19:09:22.032169  5547 net.cpp:84] Creating Layer BatchNorm19
I1001 19:09:22.032172  5547 net.cpp:406] BatchNorm19 <- Convolution19
I1001 19:09:22.032176  5547 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1001 19:09:22.032310  5547 net.cpp:122] Setting up BatchNorm19
I1001 19:09:22.032315  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.032317  5547 net.cpp:137] Memory required for data: 502701200
I1001 19:09:22.032321  5547 layer_factory.hpp:77] Creating layer Scale19
I1001 19:09:22.032325  5547 net.cpp:84] Creating Layer Scale19
I1001 19:09:22.032328  5547 net.cpp:406] Scale19 <- Convolution19
I1001 19:09:22.032332  5547 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1001 19:09:22.032366  5547 layer_factory.hpp:77] Creating layer Scale19
I1001 19:09:22.032444  5547 net.cpp:122] Setting up Scale19
I1001 19:09:22.032447  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.032449  5547 net.cpp:137] Memory required for data: 507718800
I1001 19:09:22.032454  5547 layer_factory.hpp:77] Creating layer Eltwise9
I1001 19:09:22.032457  5547 net.cpp:84] Creating Layer Eltwise9
I1001 19:09:22.032460  5547 net.cpp:406] Eltwise9 <- Eltwise8_M2PELU17_0_split_1
I1001 19:09:22.032464  5547 net.cpp:406] Eltwise9 <- Convolution19
I1001 19:09:22.032466  5547 net.cpp:380] Eltwise9 -> Eltwise9
I1001 19:09:22.032482  5547 net.cpp:122] Setting up Eltwise9
I1001 19:09:22.032485  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.032487  5547 net.cpp:137] Memory required for data: 512736400
I1001 19:09:22.032490  5547 layer_factory.hpp:77] Creating layer M2PELU19
I1001 19:09:22.032495  5547 net.cpp:84] Creating Layer M2PELU19
I1001 19:09:22.032496  5547 net.cpp:406] M2PELU19 <- Eltwise9
I1001 19:09:22.032500  5547 net.cpp:367] M2PELU19 -> Eltwise9 (in-place)
I1001 19:09:22.032584  5547 net.cpp:122] Setting up M2PELU19
I1001 19:09:22.032589  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.032591  5547 net.cpp:137] Memory required for data: 517754000
I1001 19:09:22.032594  5547 layer_factory.hpp:77] Creating layer Eltwise9_M2PELU19_0_split
I1001 19:09:22.032599  5547 net.cpp:84] Creating Layer Eltwise9_M2PELU19_0_split
I1001 19:09:22.032601  5547 net.cpp:406] Eltwise9_M2PELU19_0_split <- Eltwise9
I1001 19:09:22.032604  5547 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_0
I1001 19:09:22.032608  5547 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_1
I1001 19:09:22.032632  5547 net.cpp:122] Setting up Eltwise9_M2PELU19_0_split
I1001 19:09:22.032636  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.032639  5547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 19:09:22.032641  5547 net.cpp:137] Memory required for data: 527789200
I1001 19:09:22.032644  5547 layer_factory.hpp:77] Creating layer Convolution20
I1001 19:09:22.032649  5547 net.cpp:84] Creating Layer Convolution20
I1001 19:09:22.032651  5547 net.cpp:406] Convolution20 <- Eltwise9_M2PELU19_0_split_0
I1001 19:09:22.032655  5547 net.cpp:380] Convolution20 -> Convolution20
I1001 19:09:22.033843  5547 net.cpp:122] Setting up Convolution20
I1001 19:09:22.033850  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.033854  5547 net.cpp:137] Memory required for data: 530298000
I1001 19:09:22.033859  5547 layer_factory.hpp:77] Creating layer BatchNorm20
I1001 19:09:22.033864  5547 net.cpp:84] Creating Layer BatchNorm20
I1001 19:09:22.033866  5547 net.cpp:406] BatchNorm20 <- Convolution20
I1001 19:09:22.033871  5547 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1001 19:09:22.034013  5547 net.cpp:122] Setting up BatchNorm20
I1001 19:09:22.034018  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.034020  5547 net.cpp:137] Memory required for data: 532806800
I1001 19:09:22.034025  5547 layer_factory.hpp:77] Creating layer Scale20
I1001 19:09:22.034031  5547 net.cpp:84] Creating Layer Scale20
I1001 19:09:22.034034  5547 net.cpp:406] Scale20 <- Convolution20
I1001 19:09:22.034037  5547 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1001 19:09:22.034066  5547 layer_factory.hpp:77] Creating layer Scale20
I1001 19:09:22.034145  5547 net.cpp:122] Setting up Scale20
I1001 19:09:22.034149  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.034152  5547 net.cpp:137] Memory required for data: 535315600
I1001 19:09:22.034157  5547 layer_factory.hpp:77] Creating layer Convolution21
I1001 19:09:22.034163  5547 net.cpp:84] Creating Layer Convolution21
I1001 19:09:22.034166  5547 net.cpp:406] Convolution21 <- Eltwise9_M2PELU19_0_split_1
I1001 19:09:22.034170  5547 net.cpp:380] Convolution21 -> Convolution21
I1001 19:09:22.035851  5547 net.cpp:122] Setting up Convolution21
I1001 19:09:22.035861  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.035871  5547 net.cpp:137] Memory required for data: 537824400
I1001 19:09:22.035876  5547 layer_factory.hpp:77] Creating layer BatchNorm21
I1001 19:09:22.035882  5547 net.cpp:84] Creating Layer BatchNorm21
I1001 19:09:22.035886  5547 net.cpp:406] BatchNorm21 <- Convolution21
I1001 19:09:22.035888  5547 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1001 19:09:22.036026  5547 net.cpp:122] Setting up BatchNorm21
I1001 19:09:22.036031  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.036032  5547 net.cpp:137] Memory required for data: 540333200
I1001 19:09:22.036037  5547 layer_factory.hpp:77] Creating layer Scale21
I1001 19:09:22.036041  5547 net.cpp:84] Creating Layer Scale21
I1001 19:09:22.036043  5547 net.cpp:406] Scale21 <- Convolution21
I1001 19:09:22.036046  5547 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1001 19:09:22.036073  5547 layer_factory.hpp:77] Creating layer Scale21
I1001 19:09:22.036149  5547 net.cpp:122] Setting up Scale21
I1001 19:09:22.036154  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.036155  5547 net.cpp:137] Memory required for data: 542842000
I1001 19:09:22.036159  5547 layer_factory.hpp:77] Creating layer M2PELU20
I1001 19:09:22.036164  5547 net.cpp:84] Creating Layer M2PELU20
I1001 19:09:22.036167  5547 net.cpp:406] M2PELU20 <- Convolution21
I1001 19:09:22.036170  5547 net.cpp:367] M2PELU20 -> Convolution21 (in-place)
I1001 19:09:22.036252  5547 net.cpp:122] Setting up M2PELU20
I1001 19:09:22.036257  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.036258  5547 net.cpp:137] Memory required for data: 545350800
I1001 19:09:22.036262  5547 layer_factory.hpp:77] Creating layer Convolution22
I1001 19:09:22.036269  5547 net.cpp:84] Creating Layer Convolution22
I1001 19:09:22.036272  5547 net.cpp:406] Convolution22 <- Convolution21
I1001 19:09:22.036278  5547 net.cpp:380] Convolution22 -> Convolution22
I1001 19:09:22.037430  5547 net.cpp:122] Setting up Convolution22
I1001 19:09:22.037448  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.037451  5547 net.cpp:137] Memory required for data: 547859600
I1001 19:09:22.037456  5547 layer_factory.hpp:77] Creating layer BatchNorm22
I1001 19:09:22.037461  5547 net.cpp:84] Creating Layer BatchNorm22
I1001 19:09:22.037463  5547 net.cpp:406] BatchNorm22 <- Convolution22
I1001 19:09:22.037467  5547 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1001 19:09:22.037609  5547 net.cpp:122] Setting up BatchNorm22
I1001 19:09:22.037614  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.037616  5547 net.cpp:137] Memory required for data: 550368400
I1001 19:09:22.037621  5547 layer_factory.hpp:77] Creating layer Scale22
I1001 19:09:22.037624  5547 net.cpp:84] Creating Layer Scale22
I1001 19:09:22.037627  5547 net.cpp:406] Scale22 <- Convolution22
I1001 19:09:22.037631  5547 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1001 19:09:22.037657  5547 layer_factory.hpp:77] Creating layer Scale22
I1001 19:09:22.037730  5547 net.cpp:122] Setting up Scale22
I1001 19:09:22.037734  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.037736  5547 net.cpp:137] Memory required for data: 552877200
I1001 19:09:22.037740  5547 layer_factory.hpp:77] Creating layer Eltwise10
I1001 19:09:22.037744  5547 net.cpp:84] Creating Layer Eltwise10
I1001 19:09:22.037746  5547 net.cpp:406] Eltwise10 <- Convolution20
I1001 19:09:22.037750  5547 net.cpp:406] Eltwise10 <- Convolution22
I1001 19:09:22.037753  5547 net.cpp:380] Eltwise10 -> Eltwise10
I1001 19:09:22.037767  5547 net.cpp:122] Setting up Eltwise10
I1001 19:09:22.037772  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.037775  5547 net.cpp:137] Memory required for data: 555386000
I1001 19:09:22.037776  5547 layer_factory.hpp:77] Creating layer M2PELU21
I1001 19:09:22.037781  5547 net.cpp:84] Creating Layer M2PELU21
I1001 19:09:22.037782  5547 net.cpp:406] M2PELU21 <- Eltwise10
I1001 19:09:22.037786  5547 net.cpp:367] M2PELU21 -> Eltwise10 (in-place)
I1001 19:09:22.037868  5547 net.cpp:122] Setting up M2PELU21
I1001 19:09:22.037878  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.037880  5547 net.cpp:137] Memory required for data: 557894800
I1001 19:09:22.037884  5547 layer_factory.hpp:77] Creating layer Eltwise10_M2PELU21_0_split
I1001 19:09:22.037889  5547 net.cpp:84] Creating Layer Eltwise10_M2PELU21_0_split
I1001 19:09:22.037890  5547 net.cpp:406] Eltwise10_M2PELU21_0_split <- Eltwise10
I1001 19:09:22.037895  5547 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_0
I1001 19:09:22.037899  5547 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_1
I1001 19:09:22.037922  5547 net.cpp:122] Setting up Eltwise10_M2PELU21_0_split
I1001 19:09:22.037926  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.037928  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.037930  5547 net.cpp:137] Memory required for data: 562912400
I1001 19:09:22.037933  5547 layer_factory.hpp:77] Creating layer Convolution23
I1001 19:09:22.037940  5547 net.cpp:84] Creating Layer Convolution23
I1001 19:09:22.037941  5547 net.cpp:406] Convolution23 <- Eltwise10_M2PELU21_0_split_0
I1001 19:09:22.037945  5547 net.cpp:380] Convolution23 -> Convolution23
I1001 19:09:22.039279  5547 net.cpp:122] Setting up Convolution23
I1001 19:09:22.039288  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.039290  5547 net.cpp:137] Memory required for data: 565421200
I1001 19:09:22.039295  5547 layer_factory.hpp:77] Creating layer BatchNorm23
I1001 19:09:22.039301  5547 net.cpp:84] Creating Layer BatchNorm23
I1001 19:09:22.039304  5547 net.cpp:406] BatchNorm23 <- Convolution23
I1001 19:09:22.039309  5547 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1001 19:09:22.039444  5547 net.cpp:122] Setting up BatchNorm23
I1001 19:09:22.039448  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.039450  5547 net.cpp:137] Memory required for data: 567930000
I1001 19:09:22.039455  5547 layer_factory.hpp:77] Creating layer Scale23
I1001 19:09:22.039459  5547 net.cpp:84] Creating Layer Scale23
I1001 19:09:22.039461  5547 net.cpp:406] Scale23 <- Convolution23
I1001 19:09:22.039465  5547 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1001 19:09:22.039490  5547 layer_factory.hpp:77] Creating layer Scale23
I1001 19:09:22.039566  5547 net.cpp:122] Setting up Scale23
I1001 19:09:22.039571  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.039572  5547 net.cpp:137] Memory required for data: 570438800
I1001 19:09:22.039577  5547 layer_factory.hpp:77] Creating layer M2PELU22
I1001 19:09:22.039582  5547 net.cpp:84] Creating Layer M2PELU22
I1001 19:09:22.039583  5547 net.cpp:406] M2PELU22 <- Convolution23
I1001 19:09:22.039587  5547 net.cpp:367] M2PELU22 -> Convolution23 (in-place)
I1001 19:09:22.039669  5547 net.cpp:122] Setting up M2PELU22
I1001 19:09:22.039674  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.039675  5547 net.cpp:137] Memory required for data: 572947600
I1001 19:09:22.039679  5547 layer_factory.hpp:77] Creating layer Convolution24
I1001 19:09:22.039685  5547 net.cpp:84] Creating Layer Convolution24
I1001 19:09:22.039687  5547 net.cpp:406] Convolution24 <- Convolution23
I1001 19:09:22.039692  5547 net.cpp:380] Convolution24 -> Convolution24
I1001 19:09:22.040721  5547 net.cpp:122] Setting up Convolution24
I1001 19:09:22.040730  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.040732  5547 net.cpp:137] Memory required for data: 575456400
I1001 19:09:22.040737  5547 layer_factory.hpp:77] Creating layer BatchNorm24
I1001 19:09:22.040742  5547 net.cpp:84] Creating Layer BatchNorm24
I1001 19:09:22.040745  5547 net.cpp:406] BatchNorm24 <- Convolution24
I1001 19:09:22.040748  5547 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1001 19:09:22.040882  5547 net.cpp:122] Setting up BatchNorm24
I1001 19:09:22.040887  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.040889  5547 net.cpp:137] Memory required for data: 577965200
I1001 19:09:22.040894  5547 layer_factory.hpp:77] Creating layer Scale24
I1001 19:09:22.040904  5547 net.cpp:84] Creating Layer Scale24
I1001 19:09:22.040906  5547 net.cpp:406] Scale24 <- Convolution24
I1001 19:09:22.040910  5547 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1001 19:09:22.040940  5547 layer_factory.hpp:77] Creating layer Scale24
I1001 19:09:22.041016  5547 net.cpp:122] Setting up Scale24
I1001 19:09:22.041020  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.041023  5547 net.cpp:137] Memory required for data: 580474000
I1001 19:09:22.041026  5547 layer_factory.hpp:77] Creating layer Eltwise11
I1001 19:09:22.041031  5547 net.cpp:84] Creating Layer Eltwise11
I1001 19:09:22.041034  5547 net.cpp:406] Eltwise11 <- Eltwise10_M2PELU21_0_split_1
I1001 19:09:22.041036  5547 net.cpp:406] Eltwise11 <- Convolution24
I1001 19:09:22.041039  5547 net.cpp:380] Eltwise11 -> Eltwise11
I1001 19:09:22.041055  5547 net.cpp:122] Setting up Eltwise11
I1001 19:09:22.041059  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.041061  5547 net.cpp:137] Memory required for data: 582982800
I1001 19:09:22.041064  5547 layer_factory.hpp:77] Creating layer M2PELU23
I1001 19:09:22.041069  5547 net.cpp:84] Creating Layer M2PELU23
I1001 19:09:22.041070  5547 net.cpp:406] M2PELU23 <- Eltwise11
I1001 19:09:22.041074  5547 net.cpp:367] M2PELU23 -> Eltwise11 (in-place)
I1001 19:09:22.041157  5547 net.cpp:122] Setting up M2PELU23
I1001 19:09:22.041160  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.041162  5547 net.cpp:137] Memory required for data: 585491600
I1001 19:09:22.041167  5547 layer_factory.hpp:77] Creating layer Eltwise11_M2PELU23_0_split
I1001 19:09:22.041169  5547 net.cpp:84] Creating Layer Eltwise11_M2PELU23_0_split
I1001 19:09:22.041172  5547 net.cpp:406] Eltwise11_M2PELU23_0_split <- Eltwise11
I1001 19:09:22.041175  5547 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_0
I1001 19:09:22.041178  5547 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_1
I1001 19:09:22.041201  5547 net.cpp:122] Setting up Eltwise11_M2PELU23_0_split
I1001 19:09:22.041205  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.041208  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.041210  5547 net.cpp:137] Memory required for data: 590509200
I1001 19:09:22.041213  5547 layer_factory.hpp:77] Creating layer Convolution25
I1001 19:09:22.041218  5547 net.cpp:84] Creating Layer Convolution25
I1001 19:09:22.041221  5547 net.cpp:406] Convolution25 <- Eltwise11_M2PELU23_0_split_0
I1001 19:09:22.041224  5547 net.cpp:380] Convolution25 -> Convolution25
I1001 19:09:22.042249  5547 net.cpp:122] Setting up Convolution25
I1001 19:09:22.042258  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.042260  5547 net.cpp:137] Memory required for data: 593018000
I1001 19:09:22.042264  5547 layer_factory.hpp:77] Creating layer BatchNorm25
I1001 19:09:22.042269  5547 net.cpp:84] Creating Layer BatchNorm25
I1001 19:09:22.042273  5547 net.cpp:406] BatchNorm25 <- Convolution25
I1001 19:09:22.042275  5547 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1001 19:09:22.042419  5547 net.cpp:122] Setting up BatchNorm25
I1001 19:09:22.042425  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.042428  5547 net.cpp:137] Memory required for data: 595526800
I1001 19:09:22.042433  5547 layer_factory.hpp:77] Creating layer Scale25
I1001 19:09:22.042438  5547 net.cpp:84] Creating Layer Scale25
I1001 19:09:22.042439  5547 net.cpp:406] Scale25 <- Convolution25
I1001 19:09:22.042443  5547 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1001 19:09:22.042469  5547 layer_factory.hpp:77] Creating layer Scale25
I1001 19:09:22.042562  5547 net.cpp:122] Setting up Scale25
I1001 19:09:22.042567  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.042569  5547 net.cpp:137] Memory required for data: 598035600
I1001 19:09:22.042573  5547 layer_factory.hpp:77] Creating layer M2PELU24
I1001 19:09:22.042579  5547 net.cpp:84] Creating Layer M2PELU24
I1001 19:09:22.042582  5547 net.cpp:406] M2PELU24 <- Convolution25
I1001 19:09:22.042593  5547 net.cpp:367] M2PELU24 -> Convolution25 (in-place)
I1001 19:09:22.042678  5547 net.cpp:122] Setting up M2PELU24
I1001 19:09:22.042682  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.042685  5547 net.cpp:137] Memory required for data: 600544400
I1001 19:09:22.042688  5547 layer_factory.hpp:77] Creating layer Convolution26
I1001 19:09:22.042695  5547 net.cpp:84] Creating Layer Convolution26
I1001 19:09:22.042697  5547 net.cpp:406] Convolution26 <- Convolution25
I1001 19:09:22.042701  5547 net.cpp:380] Convolution26 -> Convolution26
I1001 19:09:22.043728  5547 net.cpp:122] Setting up Convolution26
I1001 19:09:22.043736  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.043740  5547 net.cpp:137] Memory required for data: 603053200
I1001 19:09:22.043743  5547 layer_factory.hpp:77] Creating layer BatchNorm26
I1001 19:09:22.043748  5547 net.cpp:84] Creating Layer BatchNorm26
I1001 19:09:22.043751  5547 net.cpp:406] BatchNorm26 <- Convolution26
I1001 19:09:22.043756  5547 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1001 19:09:22.043887  5547 net.cpp:122] Setting up BatchNorm26
I1001 19:09:22.043892  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.043895  5547 net.cpp:137] Memory required for data: 605562000
I1001 19:09:22.043898  5547 layer_factory.hpp:77] Creating layer Scale26
I1001 19:09:22.043902  5547 net.cpp:84] Creating Layer Scale26
I1001 19:09:22.043905  5547 net.cpp:406] Scale26 <- Convolution26
I1001 19:09:22.043907  5547 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1001 19:09:22.043934  5547 layer_factory.hpp:77] Creating layer Scale26
I1001 19:09:22.044010  5547 net.cpp:122] Setting up Scale26
I1001 19:09:22.044014  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.044016  5547 net.cpp:137] Memory required for data: 608070800
I1001 19:09:22.044020  5547 layer_factory.hpp:77] Creating layer Eltwise12
I1001 19:09:22.044024  5547 net.cpp:84] Creating Layer Eltwise12
I1001 19:09:22.044028  5547 net.cpp:406] Eltwise12 <- Eltwise11_M2PELU23_0_split_1
I1001 19:09:22.044029  5547 net.cpp:406] Eltwise12 <- Convolution26
I1001 19:09:22.044034  5547 net.cpp:380] Eltwise12 -> Eltwise12
I1001 19:09:22.044049  5547 net.cpp:122] Setting up Eltwise12
I1001 19:09:22.044051  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.044054  5547 net.cpp:137] Memory required for data: 610579600
I1001 19:09:22.044055  5547 layer_factory.hpp:77] Creating layer M2PELU25
I1001 19:09:22.044060  5547 net.cpp:84] Creating Layer M2PELU25
I1001 19:09:22.044064  5547 net.cpp:406] M2PELU25 <- Eltwise12
I1001 19:09:22.044066  5547 net.cpp:367] M2PELU25 -> Eltwise12 (in-place)
I1001 19:09:22.044148  5547 net.cpp:122] Setting up M2PELU25
I1001 19:09:22.044153  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.044155  5547 net.cpp:137] Memory required for data: 613088400
I1001 19:09:22.044159  5547 layer_factory.hpp:77] Creating layer Eltwise12_M2PELU25_0_split
I1001 19:09:22.044175  5547 net.cpp:84] Creating Layer Eltwise12_M2PELU25_0_split
I1001 19:09:22.044178  5547 net.cpp:406] Eltwise12_M2PELU25_0_split <- Eltwise12
I1001 19:09:22.044181  5547 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_0
I1001 19:09:22.044189  5547 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_1
I1001 19:09:22.044212  5547 net.cpp:122] Setting up Eltwise12_M2PELU25_0_split
I1001 19:09:22.044216  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.044219  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.044221  5547 net.cpp:137] Memory required for data: 618106000
I1001 19:09:22.044224  5547 layer_factory.hpp:77] Creating layer Convolution27
I1001 19:09:22.044230  5547 net.cpp:84] Creating Layer Convolution27
I1001 19:09:22.044232  5547 net.cpp:406] Convolution27 <- Eltwise12_M2PELU25_0_split_0
I1001 19:09:22.044236  5547 net.cpp:380] Convolution27 -> Convolution27
I1001 19:09:22.044940  5547 net.cpp:122] Setting up Convolution27
I1001 19:09:22.044955  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.044957  5547 net.cpp:137] Memory required for data: 620614800
I1001 19:09:22.044961  5547 layer_factory.hpp:77] Creating layer BatchNorm27
I1001 19:09:22.044965  5547 net.cpp:84] Creating Layer BatchNorm27
I1001 19:09:22.044968  5547 net.cpp:406] BatchNorm27 <- Convolution27
I1001 19:09:22.044973  5547 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1001 19:09:22.045109  5547 net.cpp:122] Setting up BatchNorm27
I1001 19:09:22.045114  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.045116  5547 net.cpp:137] Memory required for data: 623123600
I1001 19:09:22.045120  5547 layer_factory.hpp:77] Creating layer Scale27
I1001 19:09:22.045125  5547 net.cpp:84] Creating Layer Scale27
I1001 19:09:22.045127  5547 net.cpp:406] Scale27 <- Convolution27
I1001 19:09:22.045130  5547 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1001 19:09:22.045156  5547 layer_factory.hpp:77] Creating layer Scale27
I1001 19:09:22.045231  5547 net.cpp:122] Setting up Scale27
I1001 19:09:22.045235  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.045238  5547 net.cpp:137] Memory required for data: 625632400
I1001 19:09:22.045241  5547 layer_factory.hpp:77] Creating layer M2PELU26
I1001 19:09:22.045245  5547 net.cpp:84] Creating Layer M2PELU26
I1001 19:09:22.045248  5547 net.cpp:406] M2PELU26 <- Convolution27
I1001 19:09:22.045251  5547 net.cpp:367] M2PELU26 -> Convolution27 (in-place)
I1001 19:09:22.045334  5547 net.cpp:122] Setting up M2PELU26
I1001 19:09:22.045338  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.045341  5547 net.cpp:137] Memory required for data: 628141200
I1001 19:09:22.045344  5547 layer_factory.hpp:77] Creating layer Convolution28
I1001 19:09:22.045351  5547 net.cpp:84] Creating Layer Convolution28
I1001 19:09:22.045354  5547 net.cpp:406] Convolution28 <- Convolution27
I1001 19:09:22.045357  5547 net.cpp:380] Convolution28 -> Convolution28
I1001 19:09:22.046378  5547 net.cpp:122] Setting up Convolution28
I1001 19:09:22.046386  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.046389  5547 net.cpp:137] Memory required for data: 630650000
I1001 19:09:22.046393  5547 layer_factory.hpp:77] Creating layer BatchNorm28
I1001 19:09:22.046399  5547 net.cpp:84] Creating Layer BatchNorm28
I1001 19:09:22.046401  5547 net.cpp:406] BatchNorm28 <- Convolution28
I1001 19:09:22.046406  5547 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1001 19:09:22.046546  5547 net.cpp:122] Setting up BatchNorm28
I1001 19:09:22.046551  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.046553  5547 net.cpp:137] Memory required for data: 633158800
I1001 19:09:22.046558  5547 layer_factory.hpp:77] Creating layer Scale28
I1001 19:09:22.046563  5547 net.cpp:84] Creating Layer Scale28
I1001 19:09:22.046566  5547 net.cpp:406] Scale28 <- Convolution28
I1001 19:09:22.046568  5547 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1001 19:09:22.046596  5547 layer_factory.hpp:77] Creating layer Scale28
I1001 19:09:22.046671  5547 net.cpp:122] Setting up Scale28
I1001 19:09:22.046675  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.046677  5547 net.cpp:137] Memory required for data: 635667600
I1001 19:09:22.046681  5547 layer_factory.hpp:77] Creating layer Eltwise13
I1001 19:09:22.046686  5547 net.cpp:84] Creating Layer Eltwise13
I1001 19:09:22.046689  5547 net.cpp:406] Eltwise13 <- Eltwise12_M2PELU25_0_split_1
I1001 19:09:22.046692  5547 net.cpp:406] Eltwise13 <- Convolution28
I1001 19:09:22.046696  5547 net.cpp:380] Eltwise13 -> Eltwise13
I1001 19:09:22.046711  5547 net.cpp:122] Setting up Eltwise13
I1001 19:09:22.046715  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.046717  5547 net.cpp:137] Memory required for data: 638176400
I1001 19:09:22.046720  5547 layer_factory.hpp:77] Creating layer M2PELU27
I1001 19:09:22.046725  5547 net.cpp:84] Creating Layer M2PELU27
I1001 19:09:22.046726  5547 net.cpp:406] M2PELU27 <- Eltwise13
I1001 19:09:22.046730  5547 net.cpp:367] M2PELU27 -> Eltwise13 (in-place)
I1001 19:09:22.046821  5547 net.cpp:122] Setting up M2PELU27
I1001 19:09:22.046825  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.046828  5547 net.cpp:137] Memory required for data: 640685200
I1001 19:09:22.046831  5547 layer_factory.hpp:77] Creating layer Eltwise13_M2PELU27_0_split
I1001 19:09:22.046835  5547 net.cpp:84] Creating Layer Eltwise13_M2PELU27_0_split
I1001 19:09:22.046838  5547 net.cpp:406] Eltwise13_M2PELU27_0_split <- Eltwise13
I1001 19:09:22.046841  5547 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_0
I1001 19:09:22.046845  5547 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_1
I1001 19:09:22.046869  5547 net.cpp:122] Setting up Eltwise13_M2PELU27_0_split
I1001 19:09:22.046871  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.046875  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.046876  5547 net.cpp:137] Memory required for data: 645702800
I1001 19:09:22.046878  5547 layer_factory.hpp:77] Creating layer Convolution29
I1001 19:09:22.046885  5547 net.cpp:84] Creating Layer Convolution29
I1001 19:09:22.046887  5547 net.cpp:406] Convolution29 <- Eltwise13_M2PELU27_0_split_0
I1001 19:09:22.046891  5547 net.cpp:380] Convolution29 -> Convolution29
I1001 19:09:22.047924  5547 net.cpp:122] Setting up Convolution29
I1001 19:09:22.047932  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.047935  5547 net.cpp:137] Memory required for data: 648211600
I1001 19:09:22.047940  5547 layer_factory.hpp:77] Creating layer BatchNorm29
I1001 19:09:22.047945  5547 net.cpp:84] Creating Layer BatchNorm29
I1001 19:09:22.047947  5547 net.cpp:406] BatchNorm29 <- Convolution29
I1001 19:09:22.047951  5547 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1001 19:09:22.048087  5547 net.cpp:122] Setting up BatchNorm29
I1001 19:09:22.048092  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.048094  5547 net.cpp:137] Memory required for data: 650720400
I1001 19:09:22.048099  5547 layer_factory.hpp:77] Creating layer Scale29
I1001 19:09:22.048102  5547 net.cpp:84] Creating Layer Scale29
I1001 19:09:22.048105  5547 net.cpp:406] Scale29 <- Convolution29
I1001 19:09:22.048110  5547 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1001 19:09:22.048135  5547 layer_factory.hpp:77] Creating layer Scale29
I1001 19:09:22.048213  5547 net.cpp:122] Setting up Scale29
I1001 19:09:22.048218  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.048219  5547 net.cpp:137] Memory required for data: 653229200
I1001 19:09:22.048243  5547 layer_factory.hpp:77] Creating layer M2PELU28
I1001 19:09:22.048247  5547 net.cpp:84] Creating Layer M2PELU28
I1001 19:09:22.048249  5547 net.cpp:406] M2PELU28 <- Convolution29
I1001 19:09:22.048254  5547 net.cpp:367] M2PELU28 -> Convolution29 (in-place)
I1001 19:09:22.048339  5547 net.cpp:122] Setting up M2PELU28
I1001 19:09:22.048343  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.048346  5547 net.cpp:137] Memory required for data: 655738000
I1001 19:09:22.048349  5547 layer_factory.hpp:77] Creating layer Convolution30
I1001 19:09:22.048355  5547 net.cpp:84] Creating Layer Convolution30
I1001 19:09:22.048358  5547 net.cpp:406] Convolution30 <- Convolution29
I1001 19:09:22.048362  5547 net.cpp:380] Convolution30 -> Convolution30
I1001 19:09:22.049402  5547 net.cpp:122] Setting up Convolution30
I1001 19:09:22.049412  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.049414  5547 net.cpp:137] Memory required for data: 658246800
I1001 19:09:22.049418  5547 layer_factory.hpp:77] Creating layer BatchNorm30
I1001 19:09:22.049424  5547 net.cpp:84] Creating Layer BatchNorm30
I1001 19:09:22.049427  5547 net.cpp:406] BatchNorm30 <- Convolution30
I1001 19:09:22.049432  5547 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1001 19:09:22.049567  5547 net.cpp:122] Setting up BatchNorm30
I1001 19:09:22.049571  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.049574  5547 net.cpp:137] Memory required for data: 660755600
I1001 19:09:22.049584  5547 layer_factory.hpp:77] Creating layer Scale30
I1001 19:09:22.049588  5547 net.cpp:84] Creating Layer Scale30
I1001 19:09:22.049592  5547 net.cpp:406] Scale30 <- Convolution30
I1001 19:09:22.049594  5547 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1001 19:09:22.049623  5547 layer_factory.hpp:77] Creating layer Scale30
I1001 19:09:22.049702  5547 net.cpp:122] Setting up Scale30
I1001 19:09:22.049706  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.049710  5547 net.cpp:137] Memory required for data: 663264400
I1001 19:09:22.049712  5547 layer_factory.hpp:77] Creating layer Eltwise14
I1001 19:09:22.049716  5547 net.cpp:84] Creating Layer Eltwise14
I1001 19:09:22.049720  5547 net.cpp:406] Eltwise14 <- Eltwise13_M2PELU27_0_split_1
I1001 19:09:22.049721  5547 net.cpp:406] Eltwise14 <- Convolution30
I1001 19:09:22.049726  5547 net.cpp:380] Eltwise14 -> Eltwise14
I1001 19:09:22.049741  5547 net.cpp:122] Setting up Eltwise14
I1001 19:09:22.049744  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.049746  5547 net.cpp:137] Memory required for data: 665773200
I1001 19:09:22.049748  5547 layer_factory.hpp:77] Creating layer M2PELU29
I1001 19:09:22.049753  5547 net.cpp:84] Creating Layer M2PELU29
I1001 19:09:22.049756  5547 net.cpp:406] M2PELU29 <- Eltwise14
I1001 19:09:22.049758  5547 net.cpp:367] M2PELU29 -> Eltwise14 (in-place)
I1001 19:09:22.049842  5547 net.cpp:122] Setting up M2PELU29
I1001 19:09:22.049847  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.049849  5547 net.cpp:137] Memory required for data: 668282000
I1001 19:09:22.049852  5547 layer_factory.hpp:77] Creating layer Eltwise14_M2PELU29_0_split
I1001 19:09:22.049856  5547 net.cpp:84] Creating Layer Eltwise14_M2PELU29_0_split
I1001 19:09:22.049859  5547 net.cpp:406] Eltwise14_M2PELU29_0_split <- Eltwise14
I1001 19:09:22.049861  5547 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_0
I1001 19:09:22.049866  5547 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_1
I1001 19:09:22.049890  5547 net.cpp:122] Setting up Eltwise14_M2PELU29_0_split
I1001 19:09:22.049892  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.049896  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.049897  5547 net.cpp:137] Memory required for data: 673299600
I1001 19:09:22.049899  5547 layer_factory.hpp:77] Creating layer Convolution31
I1001 19:09:22.049906  5547 net.cpp:84] Creating Layer Convolution31
I1001 19:09:22.049908  5547 net.cpp:406] Convolution31 <- Eltwise14_M2PELU29_0_split_0
I1001 19:09:22.049912  5547 net.cpp:380] Convolution31 -> Convolution31
I1001 19:09:22.050947  5547 net.cpp:122] Setting up Convolution31
I1001 19:09:22.050956  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.050958  5547 net.cpp:137] Memory required for data: 675808400
I1001 19:09:22.050963  5547 layer_factory.hpp:77] Creating layer BatchNorm31
I1001 19:09:22.050968  5547 net.cpp:84] Creating Layer BatchNorm31
I1001 19:09:22.050971  5547 net.cpp:406] BatchNorm31 <- Convolution31
I1001 19:09:22.050976  5547 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1001 19:09:22.051110  5547 net.cpp:122] Setting up BatchNorm31
I1001 19:09:22.051115  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.051116  5547 net.cpp:137] Memory required for data: 678317200
I1001 19:09:22.051120  5547 layer_factory.hpp:77] Creating layer Scale31
I1001 19:09:22.051126  5547 net.cpp:84] Creating Layer Scale31
I1001 19:09:22.051128  5547 net.cpp:406] Scale31 <- Convolution31
I1001 19:09:22.051131  5547 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1001 19:09:22.051157  5547 layer_factory.hpp:77] Creating layer Scale31
I1001 19:09:22.051236  5547 net.cpp:122] Setting up Scale31
I1001 19:09:22.051240  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.051242  5547 net.cpp:137] Memory required for data: 680826000
I1001 19:09:22.051246  5547 layer_factory.hpp:77] Creating layer M2PELU30
I1001 19:09:22.051259  5547 net.cpp:84] Creating Layer M2PELU30
I1001 19:09:22.051261  5547 net.cpp:406] M2PELU30 <- Convolution31
I1001 19:09:22.051265  5547 net.cpp:367] M2PELU30 -> Convolution31 (in-place)
I1001 19:09:22.051349  5547 net.cpp:122] Setting up M2PELU30
I1001 19:09:22.051354  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.051357  5547 net.cpp:137] Memory required for data: 683334800
I1001 19:09:22.051360  5547 layer_factory.hpp:77] Creating layer Convolution32
I1001 19:09:22.051367  5547 net.cpp:84] Creating Layer Convolution32
I1001 19:09:22.051369  5547 net.cpp:406] Convolution32 <- Convolution31
I1001 19:09:22.051373  5547 net.cpp:380] Convolution32 -> Convolution32
I1001 19:09:22.052403  5547 net.cpp:122] Setting up Convolution32
I1001 19:09:22.052412  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.052414  5547 net.cpp:137] Memory required for data: 685843600
I1001 19:09:22.052419  5547 layer_factory.hpp:77] Creating layer BatchNorm32
I1001 19:09:22.052424  5547 net.cpp:84] Creating Layer BatchNorm32
I1001 19:09:22.052426  5547 net.cpp:406] BatchNorm32 <- Convolution32
I1001 19:09:22.052431  5547 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1001 19:09:22.052565  5547 net.cpp:122] Setting up BatchNorm32
I1001 19:09:22.052570  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.052572  5547 net.cpp:137] Memory required for data: 688352400
I1001 19:09:22.052577  5547 layer_factory.hpp:77] Creating layer Scale32
I1001 19:09:22.052582  5547 net.cpp:84] Creating Layer Scale32
I1001 19:09:22.052583  5547 net.cpp:406] Scale32 <- Convolution32
I1001 19:09:22.052587  5547 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1001 19:09:22.052613  5547 layer_factory.hpp:77] Creating layer Scale32
I1001 19:09:22.052690  5547 net.cpp:122] Setting up Scale32
I1001 19:09:22.052693  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.052695  5547 net.cpp:137] Memory required for data: 690861200
I1001 19:09:22.052698  5547 layer_factory.hpp:77] Creating layer Eltwise15
I1001 19:09:22.052702  5547 net.cpp:84] Creating Layer Eltwise15
I1001 19:09:22.052706  5547 net.cpp:406] Eltwise15 <- Eltwise14_M2PELU29_0_split_1
I1001 19:09:22.052707  5547 net.cpp:406] Eltwise15 <- Convolution32
I1001 19:09:22.052711  5547 net.cpp:380] Eltwise15 -> Eltwise15
I1001 19:09:22.052726  5547 net.cpp:122] Setting up Eltwise15
I1001 19:09:22.052731  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.052733  5547 net.cpp:137] Memory required for data: 693370000
I1001 19:09:22.052736  5547 layer_factory.hpp:77] Creating layer M2PELU31
I1001 19:09:22.052739  5547 net.cpp:84] Creating Layer M2PELU31
I1001 19:09:22.052742  5547 net.cpp:406] M2PELU31 <- Eltwise15
I1001 19:09:22.052745  5547 net.cpp:367] M2PELU31 -> Eltwise15 (in-place)
I1001 19:09:22.052829  5547 net.cpp:122] Setting up M2PELU31
I1001 19:09:22.052832  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.052834  5547 net.cpp:137] Memory required for data: 695878800
I1001 19:09:22.052839  5547 layer_factory.hpp:77] Creating layer Eltwise15_M2PELU31_0_split
I1001 19:09:22.052841  5547 net.cpp:84] Creating Layer Eltwise15_M2PELU31_0_split
I1001 19:09:22.052844  5547 net.cpp:406] Eltwise15_M2PELU31_0_split <- Eltwise15
I1001 19:09:22.052847  5547 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_0
I1001 19:09:22.052851  5547 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_1
I1001 19:09:22.052875  5547 net.cpp:122] Setting up Eltwise15_M2PELU31_0_split
I1001 19:09:22.052878  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.052881  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.052883  5547 net.cpp:137] Memory required for data: 700896400
I1001 19:09:22.052886  5547 layer_factory.hpp:77] Creating layer Convolution33
I1001 19:09:22.052891  5547 net.cpp:84] Creating Layer Convolution33
I1001 19:09:22.052894  5547 net.cpp:406] Convolution33 <- Eltwise15_M2PELU31_0_split_0
I1001 19:09:22.052898  5547 net.cpp:380] Convolution33 -> Convolution33
I1001 19:09:22.054252  5547 net.cpp:122] Setting up Convolution33
I1001 19:09:22.054260  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.054263  5547 net.cpp:137] Memory required for data: 703405200
I1001 19:09:22.054268  5547 layer_factory.hpp:77] Creating layer BatchNorm33
I1001 19:09:22.054273  5547 net.cpp:84] Creating Layer BatchNorm33
I1001 19:09:22.054275  5547 net.cpp:406] BatchNorm33 <- Convolution33
I1001 19:09:22.054280  5547 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1001 19:09:22.054420  5547 net.cpp:122] Setting up BatchNorm33
I1001 19:09:22.054425  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.054427  5547 net.cpp:137] Memory required for data: 705914000
I1001 19:09:22.054431  5547 layer_factory.hpp:77] Creating layer Scale33
I1001 19:09:22.054435  5547 net.cpp:84] Creating Layer Scale33
I1001 19:09:22.054438  5547 net.cpp:406] Scale33 <- Convolution33
I1001 19:09:22.054441  5547 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1001 19:09:22.054467  5547 layer_factory.hpp:77] Creating layer Scale33
I1001 19:09:22.054579  5547 net.cpp:122] Setting up Scale33
I1001 19:09:22.054584  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.054585  5547 net.cpp:137] Memory required for data: 708422800
I1001 19:09:22.054589  5547 layer_factory.hpp:77] Creating layer M2PELU32
I1001 19:09:22.054595  5547 net.cpp:84] Creating Layer M2PELU32
I1001 19:09:22.054597  5547 net.cpp:406] M2PELU32 <- Convolution33
I1001 19:09:22.054601  5547 net.cpp:367] M2PELU32 -> Convolution33 (in-place)
I1001 19:09:22.054694  5547 net.cpp:122] Setting up M2PELU32
I1001 19:09:22.054699  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.054702  5547 net.cpp:137] Memory required for data: 710931600
I1001 19:09:22.054705  5547 layer_factory.hpp:77] Creating layer Convolution34
I1001 19:09:22.054713  5547 net.cpp:84] Creating Layer Convolution34
I1001 19:09:22.054715  5547 net.cpp:406] Convolution34 <- Convolution33
I1001 19:09:22.054719  5547 net.cpp:380] Convolution34 -> Convolution34
I1001 19:09:22.055765  5547 net.cpp:122] Setting up Convolution34
I1001 19:09:22.055773  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.055776  5547 net.cpp:137] Memory required for data: 713440400
I1001 19:09:22.055780  5547 layer_factory.hpp:77] Creating layer BatchNorm34
I1001 19:09:22.055786  5547 net.cpp:84] Creating Layer BatchNorm34
I1001 19:09:22.055789  5547 net.cpp:406] BatchNorm34 <- Convolution34
I1001 19:09:22.055793  5547 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I1001 19:09:22.055930  5547 net.cpp:122] Setting up BatchNorm34
I1001 19:09:22.055934  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.055936  5547 net.cpp:137] Memory required for data: 715949200
I1001 19:09:22.055941  5547 layer_factory.hpp:77] Creating layer Scale34
I1001 19:09:22.055945  5547 net.cpp:84] Creating Layer Scale34
I1001 19:09:22.055948  5547 net.cpp:406] Scale34 <- Convolution34
I1001 19:09:22.055950  5547 net.cpp:367] Scale34 -> Convolution34 (in-place)
I1001 19:09:22.055977  5547 layer_factory.hpp:77] Creating layer Scale34
I1001 19:09:22.056053  5547 net.cpp:122] Setting up Scale34
I1001 19:09:22.056058  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.056061  5547 net.cpp:137] Memory required for data: 718458000
I1001 19:09:22.056064  5547 layer_factory.hpp:77] Creating layer Eltwise16
I1001 19:09:22.056068  5547 net.cpp:84] Creating Layer Eltwise16
I1001 19:09:22.056071  5547 net.cpp:406] Eltwise16 <- Eltwise15_M2PELU31_0_split_1
I1001 19:09:22.056074  5547 net.cpp:406] Eltwise16 <- Convolution34
I1001 19:09:22.056077  5547 net.cpp:380] Eltwise16 -> Eltwise16
I1001 19:09:22.056092  5547 net.cpp:122] Setting up Eltwise16
I1001 19:09:22.056097  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.056098  5547 net.cpp:137] Memory required for data: 720966800
I1001 19:09:22.056100  5547 layer_factory.hpp:77] Creating layer M2PELU33
I1001 19:09:22.056105  5547 net.cpp:84] Creating Layer M2PELU33
I1001 19:09:22.056114  5547 net.cpp:406] M2PELU33 <- Eltwise16
I1001 19:09:22.056118  5547 net.cpp:367] M2PELU33 -> Eltwise16 (in-place)
I1001 19:09:22.056202  5547 net.cpp:122] Setting up M2PELU33
I1001 19:09:22.056207  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.056210  5547 net.cpp:137] Memory required for data: 723475600
I1001 19:09:22.056213  5547 layer_factory.hpp:77] Creating layer Eltwise16_M2PELU33_0_split
I1001 19:09:22.056217  5547 net.cpp:84] Creating Layer Eltwise16_M2PELU33_0_split
I1001 19:09:22.056219  5547 net.cpp:406] Eltwise16_M2PELU33_0_split <- Eltwise16
I1001 19:09:22.056222  5547 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_0
I1001 19:09:22.056226  5547 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_1
I1001 19:09:22.056249  5547 net.cpp:122] Setting up Eltwise16_M2PELU33_0_split
I1001 19:09:22.056253  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.056257  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.056258  5547 net.cpp:137] Memory required for data: 728493200
I1001 19:09:22.056260  5547 layer_factory.hpp:77] Creating layer Convolution35
I1001 19:09:22.056267  5547 net.cpp:84] Creating Layer Convolution35
I1001 19:09:22.056269  5547 net.cpp:406] Convolution35 <- Eltwise16_M2PELU33_0_split_0
I1001 19:09:22.056273  5547 net.cpp:380] Convolution35 -> Convolution35
I1001 19:09:22.057309  5547 net.cpp:122] Setting up Convolution35
I1001 19:09:22.057318  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.057322  5547 net.cpp:137] Memory required for data: 731002000
I1001 19:09:22.057325  5547 layer_factory.hpp:77] Creating layer BatchNorm35
I1001 19:09:22.057330  5547 net.cpp:84] Creating Layer BatchNorm35
I1001 19:09:22.057333  5547 net.cpp:406] BatchNorm35 <- Convolution35
I1001 19:09:22.057337  5547 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I1001 19:09:22.057472  5547 net.cpp:122] Setting up BatchNorm35
I1001 19:09:22.057477  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.057479  5547 net.cpp:137] Memory required for data: 733510800
I1001 19:09:22.057483  5547 layer_factory.hpp:77] Creating layer Scale35
I1001 19:09:22.057488  5547 net.cpp:84] Creating Layer Scale35
I1001 19:09:22.057490  5547 net.cpp:406] Scale35 <- Convolution35
I1001 19:09:22.057493  5547 net.cpp:367] Scale35 -> Convolution35 (in-place)
I1001 19:09:22.057519  5547 layer_factory.hpp:77] Creating layer Scale35
I1001 19:09:22.057597  5547 net.cpp:122] Setting up Scale35
I1001 19:09:22.057601  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.057605  5547 net.cpp:137] Memory required for data: 736019600
I1001 19:09:22.057607  5547 layer_factory.hpp:77] Creating layer M2PELU34
I1001 19:09:22.057612  5547 net.cpp:84] Creating Layer M2PELU34
I1001 19:09:22.057615  5547 net.cpp:406] M2PELU34 <- Convolution35
I1001 19:09:22.057620  5547 net.cpp:367] M2PELU34 -> Convolution35 (in-place)
I1001 19:09:22.057701  5547 net.cpp:122] Setting up M2PELU34
I1001 19:09:22.057705  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.057708  5547 net.cpp:137] Memory required for data: 738528400
I1001 19:09:22.057710  5547 layer_factory.hpp:77] Creating layer Convolution36
I1001 19:09:22.057718  5547 net.cpp:84] Creating Layer Convolution36
I1001 19:09:22.057719  5547 net.cpp:406] Convolution36 <- Convolution35
I1001 19:09:22.057723  5547 net.cpp:380] Convolution36 -> Convolution36
I1001 19:09:22.058765  5547 net.cpp:122] Setting up Convolution36
I1001 19:09:22.058775  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.058778  5547 net.cpp:137] Memory required for data: 741037200
I1001 19:09:22.058782  5547 layer_factory.hpp:77] Creating layer BatchNorm36
I1001 19:09:22.058787  5547 net.cpp:84] Creating Layer BatchNorm36
I1001 19:09:22.058789  5547 net.cpp:406] BatchNorm36 <- Convolution36
I1001 19:09:22.058794  5547 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I1001 19:09:22.058929  5547 net.cpp:122] Setting up BatchNorm36
I1001 19:09:22.058933  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.058943  5547 net.cpp:137] Memory required for data: 743546000
I1001 19:09:22.058948  5547 layer_factory.hpp:77] Creating layer Scale36
I1001 19:09:22.058951  5547 net.cpp:84] Creating Layer Scale36
I1001 19:09:22.058954  5547 net.cpp:406] Scale36 <- Convolution36
I1001 19:09:22.058957  5547 net.cpp:367] Scale36 -> Convolution36 (in-place)
I1001 19:09:22.058985  5547 layer_factory.hpp:77] Creating layer Scale36
I1001 19:09:22.059062  5547 net.cpp:122] Setting up Scale36
I1001 19:09:22.059067  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.059068  5547 net.cpp:137] Memory required for data: 746054800
I1001 19:09:22.059072  5547 layer_factory.hpp:77] Creating layer Eltwise17
I1001 19:09:22.059077  5547 net.cpp:84] Creating Layer Eltwise17
I1001 19:09:22.059079  5547 net.cpp:406] Eltwise17 <- Eltwise16_M2PELU33_0_split_1
I1001 19:09:22.059082  5547 net.cpp:406] Eltwise17 <- Convolution36
I1001 19:09:22.059085  5547 net.cpp:380] Eltwise17 -> Eltwise17
I1001 19:09:22.059100  5547 net.cpp:122] Setting up Eltwise17
I1001 19:09:22.059104  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.059106  5547 net.cpp:137] Memory required for data: 748563600
I1001 19:09:22.059108  5547 layer_factory.hpp:77] Creating layer M2PELU35
I1001 19:09:22.059113  5547 net.cpp:84] Creating Layer M2PELU35
I1001 19:09:22.059116  5547 net.cpp:406] M2PELU35 <- Eltwise17
I1001 19:09:22.059119  5547 net.cpp:367] M2PELU35 -> Eltwise17 (in-place)
I1001 19:09:22.059204  5547 net.cpp:122] Setting up M2PELU35
I1001 19:09:22.059208  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.059211  5547 net.cpp:137] Memory required for data: 751072400
I1001 19:09:22.059214  5547 layer_factory.hpp:77] Creating layer Eltwise17_M2PELU35_0_split
I1001 19:09:22.059218  5547 net.cpp:84] Creating Layer Eltwise17_M2PELU35_0_split
I1001 19:09:22.059221  5547 net.cpp:406] Eltwise17_M2PELU35_0_split <- Eltwise17
I1001 19:09:22.059223  5547 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_0
I1001 19:09:22.059227  5547 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_1
I1001 19:09:22.059252  5547 net.cpp:122] Setting up Eltwise17_M2PELU35_0_split
I1001 19:09:22.059254  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.059257  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.059259  5547 net.cpp:137] Memory required for data: 756090000
I1001 19:09:22.059262  5547 layer_factory.hpp:77] Creating layer Convolution37
I1001 19:09:22.059267  5547 net.cpp:84] Creating Layer Convolution37
I1001 19:09:22.059270  5547 net.cpp:406] Convolution37 <- Eltwise17_M2PELU35_0_split_0
I1001 19:09:22.059274  5547 net.cpp:380] Convolution37 -> Convolution37
I1001 19:09:22.059989  5547 net.cpp:122] Setting up Convolution37
I1001 19:09:22.059998  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.059999  5547 net.cpp:137] Memory required for data: 758598800
I1001 19:09:22.060003  5547 layer_factory.hpp:77] Creating layer BatchNorm37
I1001 19:09:22.060009  5547 net.cpp:84] Creating Layer BatchNorm37
I1001 19:09:22.060011  5547 net.cpp:406] BatchNorm37 <- Convolution37
I1001 19:09:22.060014  5547 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I1001 19:09:22.060149  5547 net.cpp:122] Setting up BatchNorm37
I1001 19:09:22.060153  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.060156  5547 net.cpp:137] Memory required for data: 761107600
I1001 19:09:22.060160  5547 layer_factory.hpp:77] Creating layer Scale37
I1001 19:09:22.060164  5547 net.cpp:84] Creating Layer Scale37
I1001 19:09:22.060166  5547 net.cpp:406] Scale37 <- Convolution37
I1001 19:09:22.060169  5547 net.cpp:367] Scale37 -> Convolution37 (in-place)
I1001 19:09:22.060195  5547 layer_factory.hpp:77] Creating layer Scale37
I1001 19:09:22.060271  5547 net.cpp:122] Setting up Scale37
I1001 19:09:22.060276  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.060277  5547 net.cpp:137] Memory required for data: 763616400
I1001 19:09:22.060286  5547 layer_factory.hpp:77] Creating layer M2PELU36
I1001 19:09:22.060292  5547 net.cpp:84] Creating Layer M2PELU36
I1001 19:09:22.060294  5547 net.cpp:406] M2PELU36 <- Convolution37
I1001 19:09:22.060298  5547 net.cpp:367] M2PELU36 -> Convolution37 (in-place)
I1001 19:09:22.060384  5547 net.cpp:122] Setting up M2PELU36
I1001 19:09:22.060387  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.060389  5547 net.cpp:137] Memory required for data: 766125200
I1001 19:09:22.060394  5547 layer_factory.hpp:77] Creating layer Convolution38
I1001 19:09:22.060401  5547 net.cpp:84] Creating Layer Convolution38
I1001 19:09:22.060405  5547 net.cpp:406] Convolution38 <- Convolution37
I1001 19:09:22.060408  5547 net.cpp:380] Convolution38 -> Convolution38
I1001 19:09:22.061463  5547 net.cpp:122] Setting up Convolution38
I1001 19:09:22.061471  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.061475  5547 net.cpp:137] Memory required for data: 768634000
I1001 19:09:22.061478  5547 layer_factory.hpp:77] Creating layer BatchNorm38
I1001 19:09:22.061483  5547 net.cpp:84] Creating Layer BatchNorm38
I1001 19:09:22.061486  5547 net.cpp:406] BatchNorm38 <- Convolution38
I1001 19:09:22.061491  5547 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I1001 19:09:22.061626  5547 net.cpp:122] Setting up BatchNorm38
I1001 19:09:22.061630  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.061632  5547 net.cpp:137] Memory required for data: 771142800
I1001 19:09:22.061637  5547 layer_factory.hpp:77] Creating layer Scale38
I1001 19:09:22.061640  5547 net.cpp:84] Creating Layer Scale38
I1001 19:09:22.061643  5547 net.cpp:406] Scale38 <- Convolution38
I1001 19:09:22.061646  5547 net.cpp:367] Scale38 -> Convolution38 (in-place)
I1001 19:09:22.061672  5547 layer_factory.hpp:77] Creating layer Scale38
I1001 19:09:22.061749  5547 net.cpp:122] Setting up Scale38
I1001 19:09:22.061753  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.061755  5547 net.cpp:137] Memory required for data: 773651600
I1001 19:09:22.061758  5547 layer_factory.hpp:77] Creating layer Eltwise18
I1001 19:09:22.061763  5547 net.cpp:84] Creating Layer Eltwise18
I1001 19:09:22.061765  5547 net.cpp:406] Eltwise18 <- Eltwise17_M2PELU35_0_split_1
I1001 19:09:22.061767  5547 net.cpp:406] Eltwise18 <- Convolution38
I1001 19:09:22.061771  5547 net.cpp:380] Eltwise18 -> Eltwise18
I1001 19:09:22.061787  5547 net.cpp:122] Setting up Eltwise18
I1001 19:09:22.061791  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.061794  5547 net.cpp:137] Memory required for data: 776160400
I1001 19:09:22.061795  5547 layer_factory.hpp:77] Creating layer M2PELU37
I1001 19:09:22.061800  5547 net.cpp:84] Creating Layer M2PELU37
I1001 19:09:22.061801  5547 net.cpp:406] M2PELU37 <- Eltwise18
I1001 19:09:22.061805  5547 net.cpp:367] M2PELU37 -> Eltwise18 (in-place)
I1001 19:09:22.061890  5547 net.cpp:122] Setting up M2PELU37
I1001 19:09:22.061894  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.061897  5547 net.cpp:137] Memory required for data: 778669200
I1001 19:09:22.061899  5547 layer_factory.hpp:77] Creating layer Eltwise18_M2PELU37_0_split
I1001 19:09:22.061903  5547 net.cpp:84] Creating Layer Eltwise18_M2PELU37_0_split
I1001 19:09:22.061905  5547 net.cpp:406] Eltwise18_M2PELU37_0_split <- Eltwise18
I1001 19:09:22.061909  5547 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_0
I1001 19:09:22.061913  5547 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_1
I1001 19:09:22.061936  5547 net.cpp:122] Setting up Eltwise18_M2PELU37_0_split
I1001 19:09:22.061940  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.061944  5547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 19:09:22.061945  5547 net.cpp:137] Memory required for data: 783686800
I1001 19:09:22.061947  5547 layer_factory.hpp:77] Creating layer Convolution39
I1001 19:09:22.061952  5547 net.cpp:84] Creating Layer Convolution39
I1001 19:09:22.061955  5547 net.cpp:406] Convolution39 <- Eltwise18_M2PELU37_0_split_0
I1001 19:09:22.061967  5547 net.cpp:380] Convolution39 -> Convolution39
I1001 19:09:22.062862  5547 net.cpp:122] Setting up Convolution39
I1001 19:09:22.062870  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.062873  5547 net.cpp:137] Memory required for data: 784941200
I1001 19:09:22.062878  5547 layer_factory.hpp:77] Creating layer BatchNorm39
I1001 19:09:22.062883  5547 net.cpp:84] Creating Layer BatchNorm39
I1001 19:09:22.062886  5547 net.cpp:406] BatchNorm39 <- Convolution39
I1001 19:09:22.062889  5547 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I1001 19:09:22.063024  5547 net.cpp:122] Setting up BatchNorm39
I1001 19:09:22.063030  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.063031  5547 net.cpp:137] Memory required for data: 786195600
I1001 19:09:22.063035  5547 layer_factory.hpp:77] Creating layer Scale39
I1001 19:09:22.063040  5547 net.cpp:84] Creating Layer Scale39
I1001 19:09:22.063042  5547 net.cpp:406] Scale39 <- Convolution39
I1001 19:09:22.063045  5547 net.cpp:367] Scale39 -> Convolution39 (in-place)
I1001 19:09:22.063071  5547 layer_factory.hpp:77] Creating layer Scale39
I1001 19:09:22.063148  5547 net.cpp:122] Setting up Scale39
I1001 19:09:22.063153  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.063154  5547 net.cpp:137] Memory required for data: 787450000
I1001 19:09:22.063158  5547 layer_factory.hpp:77] Creating layer Convolution40
I1001 19:09:22.063164  5547 net.cpp:84] Creating Layer Convolution40
I1001 19:09:22.063168  5547 net.cpp:406] Convolution40 <- Eltwise18_M2PELU37_0_split_1
I1001 19:09:22.063171  5547 net.cpp:380] Convolution40 -> Convolution40
I1001 19:09:22.064927  5547 net.cpp:122] Setting up Convolution40
I1001 19:09:22.064936  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.064939  5547 net.cpp:137] Memory required for data: 788704400
I1001 19:09:22.064944  5547 layer_factory.hpp:77] Creating layer BatchNorm40
I1001 19:09:22.064949  5547 net.cpp:84] Creating Layer BatchNorm40
I1001 19:09:22.064951  5547 net.cpp:406] BatchNorm40 <- Convolution40
I1001 19:09:22.064955  5547 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I1001 19:09:22.065089  5547 net.cpp:122] Setting up BatchNorm40
I1001 19:09:22.065094  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.065096  5547 net.cpp:137] Memory required for data: 789958800
I1001 19:09:22.065101  5547 layer_factory.hpp:77] Creating layer Scale40
I1001 19:09:22.065105  5547 net.cpp:84] Creating Layer Scale40
I1001 19:09:22.065107  5547 net.cpp:406] Scale40 <- Convolution40
I1001 19:09:22.065110  5547 net.cpp:367] Scale40 -> Convolution40 (in-place)
I1001 19:09:22.065138  5547 layer_factory.hpp:77] Creating layer Scale40
I1001 19:09:22.065215  5547 net.cpp:122] Setting up Scale40
I1001 19:09:22.065222  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.065223  5547 net.cpp:137] Memory required for data: 791213200
I1001 19:09:22.065227  5547 layer_factory.hpp:77] Creating layer M2PELU38
I1001 19:09:22.065232  5547 net.cpp:84] Creating Layer M2PELU38
I1001 19:09:22.065233  5547 net.cpp:406] M2PELU38 <- Convolution40
I1001 19:09:22.065237  5547 net.cpp:367] M2PELU38 -> Convolution40 (in-place)
I1001 19:09:22.065323  5547 net.cpp:122] Setting up M2PELU38
I1001 19:09:22.065327  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.065330  5547 net.cpp:137] Memory required for data: 792467600
I1001 19:09:22.065333  5547 layer_factory.hpp:77] Creating layer Convolution41
I1001 19:09:22.065340  5547 net.cpp:84] Creating Layer Convolution41
I1001 19:09:22.065342  5547 net.cpp:406] Convolution41 <- Convolution40
I1001 19:09:22.065347  5547 net.cpp:380] Convolution41 -> Convolution41
I1001 19:09:22.067487  5547 net.cpp:122] Setting up Convolution41
I1001 19:09:22.067495  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.067498  5547 net.cpp:137] Memory required for data: 793722000
I1001 19:09:22.067503  5547 layer_factory.hpp:77] Creating layer BatchNorm41
I1001 19:09:22.067508  5547 net.cpp:84] Creating Layer BatchNorm41
I1001 19:09:22.067519  5547 net.cpp:406] BatchNorm41 <- Convolution41
I1001 19:09:22.067523  5547 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I1001 19:09:22.067719  5547 net.cpp:122] Setting up BatchNorm41
I1001 19:09:22.067726  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.067728  5547 net.cpp:137] Memory required for data: 794976400
I1001 19:09:22.067734  5547 layer_factory.hpp:77] Creating layer Scale41
I1001 19:09:22.067739  5547 net.cpp:84] Creating Layer Scale41
I1001 19:09:22.067740  5547 net.cpp:406] Scale41 <- Convolution41
I1001 19:09:22.067744  5547 net.cpp:367] Scale41 -> Convolution41 (in-place)
I1001 19:09:22.067783  5547 layer_factory.hpp:77] Creating layer Scale41
I1001 19:09:22.067873  5547 net.cpp:122] Setting up Scale41
I1001 19:09:22.067890  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.067893  5547 net.cpp:137] Memory required for data: 796230800
I1001 19:09:22.067896  5547 layer_factory.hpp:77] Creating layer Eltwise19
I1001 19:09:22.067901  5547 net.cpp:84] Creating Layer Eltwise19
I1001 19:09:22.067919  5547 net.cpp:406] Eltwise19 <- Convolution39
I1001 19:09:22.067921  5547 net.cpp:406] Eltwise19 <- Convolution41
I1001 19:09:22.067925  5547 net.cpp:380] Eltwise19 -> Eltwise19
I1001 19:09:22.067944  5547 net.cpp:122] Setting up Eltwise19
I1001 19:09:22.067946  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.067950  5547 net.cpp:137] Memory required for data: 797485200
I1001 19:09:22.067951  5547 layer_factory.hpp:77] Creating layer M2PELU39
I1001 19:09:22.067956  5547 net.cpp:84] Creating Layer M2PELU39
I1001 19:09:22.067958  5547 net.cpp:406] M2PELU39 <- Eltwise19
I1001 19:09:22.067962  5547 net.cpp:367] M2PELU39 -> Eltwise19 (in-place)
I1001 19:09:22.068061  5547 net.cpp:122] Setting up M2PELU39
I1001 19:09:22.068065  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.068068  5547 net.cpp:137] Memory required for data: 798739600
I1001 19:09:22.068071  5547 layer_factory.hpp:77] Creating layer Eltwise19_M2PELU39_0_split
I1001 19:09:22.068074  5547 net.cpp:84] Creating Layer Eltwise19_M2PELU39_0_split
I1001 19:09:22.068078  5547 net.cpp:406] Eltwise19_M2PELU39_0_split <- Eltwise19
I1001 19:09:22.068080  5547 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_0
I1001 19:09:22.068085  5547 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_1
I1001 19:09:22.068109  5547 net.cpp:122] Setting up Eltwise19_M2PELU39_0_split
I1001 19:09:22.068112  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.068115  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.068117  5547 net.cpp:137] Memory required for data: 801248400
I1001 19:09:22.068120  5547 layer_factory.hpp:77] Creating layer Convolution42
I1001 19:09:22.068126  5547 net.cpp:84] Creating Layer Convolution42
I1001 19:09:22.068128  5547 net.cpp:406] Convolution42 <- Eltwise19_M2PELU39_0_split_0
I1001 19:09:22.068132  5547 net.cpp:380] Convolution42 -> Convolution42
I1001 19:09:22.069937  5547 net.cpp:122] Setting up Convolution42
I1001 19:09:22.069947  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.069950  5547 net.cpp:137] Memory required for data: 802502800
I1001 19:09:22.069954  5547 layer_factory.hpp:77] Creating layer BatchNorm42
I1001 19:09:22.069959  5547 net.cpp:84] Creating Layer BatchNorm42
I1001 19:09:22.069962  5547 net.cpp:406] BatchNorm42 <- Convolution42
I1001 19:09:22.069967  5547 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I1001 19:09:22.070111  5547 net.cpp:122] Setting up BatchNorm42
I1001 19:09:22.070116  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.070117  5547 net.cpp:137] Memory required for data: 803757200
I1001 19:09:22.070122  5547 layer_factory.hpp:77] Creating layer Scale42
I1001 19:09:22.070127  5547 net.cpp:84] Creating Layer Scale42
I1001 19:09:22.070129  5547 net.cpp:406] Scale42 <- Convolution42
I1001 19:09:22.070132  5547 net.cpp:367] Scale42 -> Convolution42 (in-place)
I1001 19:09:22.070160  5547 layer_factory.hpp:77] Creating layer Scale42
I1001 19:09:22.070252  5547 net.cpp:122] Setting up Scale42
I1001 19:09:22.070258  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.070261  5547 net.cpp:137] Memory required for data: 805011600
I1001 19:09:22.070264  5547 layer_factory.hpp:77] Creating layer M2PELU40
I1001 19:09:22.070269  5547 net.cpp:84] Creating Layer M2PELU40
I1001 19:09:22.070271  5547 net.cpp:406] M2PELU40 <- Convolution42
I1001 19:09:22.070276  5547 net.cpp:367] M2PELU40 -> Convolution42 (in-place)
I1001 19:09:22.070363  5547 net.cpp:122] Setting up M2PELU40
I1001 19:09:22.070369  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.070370  5547 net.cpp:137] Memory required for data: 806266000
I1001 19:09:22.070374  5547 layer_factory.hpp:77] Creating layer Convolution43
I1001 19:09:22.070380  5547 net.cpp:84] Creating Layer Convolution43
I1001 19:09:22.070384  5547 net.cpp:406] Convolution43 <- Convolution42
I1001 19:09:22.070386  5547 net.cpp:380] Convolution43 -> Convolution43
I1001 19:09:22.072692  5547 net.cpp:122] Setting up Convolution43
I1001 19:09:22.072700  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.072703  5547 net.cpp:137] Memory required for data: 807520400
I1001 19:09:22.072708  5547 layer_factory.hpp:77] Creating layer BatchNorm43
I1001 19:09:22.072715  5547 net.cpp:84] Creating Layer BatchNorm43
I1001 19:09:22.072717  5547 net.cpp:406] BatchNorm43 <- Convolution43
I1001 19:09:22.072721  5547 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I1001 19:09:22.072863  5547 net.cpp:122] Setting up BatchNorm43
I1001 19:09:22.072868  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.072870  5547 net.cpp:137] Memory required for data: 808774800
I1001 19:09:22.072875  5547 layer_factory.hpp:77] Creating layer Scale43
I1001 19:09:22.072880  5547 net.cpp:84] Creating Layer Scale43
I1001 19:09:22.072882  5547 net.cpp:406] Scale43 <- Convolution43
I1001 19:09:22.072885  5547 net.cpp:367] Scale43 -> Convolution43 (in-place)
I1001 19:09:22.072912  5547 layer_factory.hpp:77] Creating layer Scale43
I1001 19:09:22.072993  5547 net.cpp:122] Setting up Scale43
I1001 19:09:22.072998  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.072999  5547 net.cpp:137] Memory required for data: 810029200
I1001 19:09:22.073004  5547 layer_factory.hpp:77] Creating layer Eltwise20
I1001 19:09:22.073009  5547 net.cpp:84] Creating Layer Eltwise20
I1001 19:09:22.073010  5547 net.cpp:406] Eltwise20 <- Eltwise19_M2PELU39_0_split_1
I1001 19:09:22.073014  5547 net.cpp:406] Eltwise20 <- Convolution43
I1001 19:09:22.073016  5547 net.cpp:380] Eltwise20 -> Eltwise20
I1001 19:09:22.073034  5547 net.cpp:122] Setting up Eltwise20
I1001 19:09:22.073037  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.073040  5547 net.cpp:137] Memory required for data: 811283600
I1001 19:09:22.073041  5547 layer_factory.hpp:77] Creating layer M2PELU41
I1001 19:09:22.073045  5547 net.cpp:84] Creating Layer M2PELU41
I1001 19:09:22.073048  5547 net.cpp:406] M2PELU41 <- Eltwise20
I1001 19:09:22.073051  5547 net.cpp:367] M2PELU41 -> Eltwise20 (in-place)
I1001 19:09:22.073138  5547 net.cpp:122] Setting up M2PELU41
I1001 19:09:22.073143  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.073144  5547 net.cpp:137] Memory required for data: 812538000
I1001 19:09:22.073148  5547 layer_factory.hpp:77] Creating layer Eltwise20_M2PELU41_0_split
I1001 19:09:22.073151  5547 net.cpp:84] Creating Layer Eltwise20_M2PELU41_0_split
I1001 19:09:22.073153  5547 net.cpp:406] Eltwise20_M2PELU41_0_split <- Eltwise20
I1001 19:09:22.073158  5547 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_0
I1001 19:09:22.073161  5547 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_1
I1001 19:09:22.073184  5547 net.cpp:122] Setting up Eltwise20_M2PELU41_0_split
I1001 19:09:22.073189  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.073191  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.073194  5547 net.cpp:137] Memory required for data: 815046800
I1001 19:09:22.073201  5547 layer_factory.hpp:77] Creating layer Convolution44
I1001 19:09:22.073207  5547 net.cpp:84] Creating Layer Convolution44
I1001 19:09:22.073210  5547 net.cpp:406] Convolution44 <- Eltwise20_M2PELU41_0_split_0
I1001 19:09:22.073215  5547 net.cpp:380] Convolution44 -> Convolution44
I1001 19:09:22.074895  5547 net.cpp:122] Setting up Convolution44
I1001 19:09:22.074904  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.074908  5547 net.cpp:137] Memory required for data: 816301200
I1001 19:09:22.074911  5547 layer_factory.hpp:77] Creating layer BatchNorm44
I1001 19:09:22.074916  5547 net.cpp:84] Creating Layer BatchNorm44
I1001 19:09:22.074919  5547 net.cpp:406] BatchNorm44 <- Convolution44
I1001 19:09:22.074923  5547 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I1001 19:09:22.075065  5547 net.cpp:122] Setting up BatchNorm44
I1001 19:09:22.075069  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.075073  5547 net.cpp:137] Memory required for data: 817555600
I1001 19:09:22.075076  5547 layer_factory.hpp:77] Creating layer Scale44
I1001 19:09:22.075080  5547 net.cpp:84] Creating Layer Scale44
I1001 19:09:22.075083  5547 net.cpp:406] Scale44 <- Convolution44
I1001 19:09:22.075086  5547 net.cpp:367] Scale44 -> Convolution44 (in-place)
I1001 19:09:22.075114  5547 layer_factory.hpp:77] Creating layer Scale44
I1001 19:09:22.075193  5547 net.cpp:122] Setting up Scale44
I1001 19:09:22.075198  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.075201  5547 net.cpp:137] Memory required for data: 818810000
I1001 19:09:22.075204  5547 layer_factory.hpp:77] Creating layer M2PELU42
I1001 19:09:22.075208  5547 net.cpp:84] Creating Layer M2PELU42
I1001 19:09:22.075212  5547 net.cpp:406] M2PELU42 <- Convolution44
I1001 19:09:22.075215  5547 net.cpp:367] M2PELU42 -> Convolution44 (in-place)
I1001 19:09:22.075304  5547 net.cpp:122] Setting up M2PELU42
I1001 19:09:22.075309  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.075310  5547 net.cpp:137] Memory required for data: 820064400
I1001 19:09:22.075314  5547 layer_factory.hpp:77] Creating layer Convolution45
I1001 19:09:22.075321  5547 net.cpp:84] Creating Layer Convolution45
I1001 19:09:22.075323  5547 net.cpp:406] Convolution45 <- Convolution44
I1001 19:09:22.075327  5547 net.cpp:380] Convolution45 -> Convolution45
I1001 19:09:22.077323  5547 net.cpp:122] Setting up Convolution45
I1001 19:09:22.077332  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.077334  5547 net.cpp:137] Memory required for data: 821318800
I1001 19:09:22.077339  5547 layer_factory.hpp:77] Creating layer BatchNorm45
I1001 19:09:22.077343  5547 net.cpp:84] Creating Layer BatchNorm45
I1001 19:09:22.077347  5547 net.cpp:406] BatchNorm45 <- Convolution45
I1001 19:09:22.077350  5547 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I1001 19:09:22.077505  5547 net.cpp:122] Setting up BatchNorm45
I1001 19:09:22.077510  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.077512  5547 net.cpp:137] Memory required for data: 822573200
I1001 19:09:22.077517  5547 layer_factory.hpp:77] Creating layer Scale45
I1001 19:09:22.077520  5547 net.cpp:84] Creating Layer Scale45
I1001 19:09:22.077523  5547 net.cpp:406] Scale45 <- Convolution45
I1001 19:09:22.077527  5547 net.cpp:367] Scale45 -> Convolution45 (in-place)
I1001 19:09:22.077554  5547 layer_factory.hpp:77] Creating layer Scale45
I1001 19:09:22.077637  5547 net.cpp:122] Setting up Scale45
I1001 19:09:22.077642  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.077644  5547 net.cpp:137] Memory required for data: 823827600
I1001 19:09:22.077648  5547 layer_factory.hpp:77] Creating layer Eltwise21
I1001 19:09:22.077651  5547 net.cpp:84] Creating Layer Eltwise21
I1001 19:09:22.077654  5547 net.cpp:406] Eltwise21 <- Eltwise20_M2PELU41_0_split_1
I1001 19:09:22.077657  5547 net.cpp:406] Eltwise21 <- Convolution45
I1001 19:09:22.077661  5547 net.cpp:380] Eltwise21 -> Eltwise21
I1001 19:09:22.077678  5547 net.cpp:122] Setting up Eltwise21
I1001 19:09:22.077689  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.077692  5547 net.cpp:137] Memory required for data: 825082000
I1001 19:09:22.077693  5547 layer_factory.hpp:77] Creating layer M2PELU43
I1001 19:09:22.077698  5547 net.cpp:84] Creating Layer M2PELU43
I1001 19:09:22.077700  5547 net.cpp:406] M2PELU43 <- Eltwise21
I1001 19:09:22.077704  5547 net.cpp:367] M2PELU43 -> Eltwise21 (in-place)
I1001 19:09:22.077796  5547 net.cpp:122] Setting up M2PELU43
I1001 19:09:22.077800  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.077802  5547 net.cpp:137] Memory required for data: 826336400
I1001 19:09:22.077806  5547 layer_factory.hpp:77] Creating layer Eltwise21_M2PELU43_0_split
I1001 19:09:22.077811  5547 net.cpp:84] Creating Layer Eltwise21_M2PELU43_0_split
I1001 19:09:22.077812  5547 net.cpp:406] Eltwise21_M2PELU43_0_split <- Eltwise21
I1001 19:09:22.077816  5547 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_0
I1001 19:09:22.077821  5547 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_1
I1001 19:09:22.077844  5547 net.cpp:122] Setting up Eltwise21_M2PELU43_0_split
I1001 19:09:22.077848  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.077852  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.077853  5547 net.cpp:137] Memory required for data: 828845200
I1001 19:09:22.077855  5547 layer_factory.hpp:77] Creating layer Convolution46
I1001 19:09:22.077860  5547 net.cpp:84] Creating Layer Convolution46
I1001 19:09:22.077863  5547 net.cpp:406] Convolution46 <- Eltwise21_M2PELU43_0_split_0
I1001 19:09:22.077869  5547 net.cpp:380] Convolution46 -> Convolution46
I1001 19:09:22.079555  5547 net.cpp:122] Setting up Convolution46
I1001 19:09:22.079565  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.079566  5547 net.cpp:137] Memory required for data: 830099600
I1001 19:09:22.079571  5547 layer_factory.hpp:77] Creating layer BatchNorm46
I1001 19:09:22.079576  5547 net.cpp:84] Creating Layer BatchNorm46
I1001 19:09:22.079579  5547 net.cpp:406] BatchNorm46 <- Convolution46
I1001 19:09:22.079582  5547 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I1001 19:09:22.079725  5547 net.cpp:122] Setting up BatchNorm46
I1001 19:09:22.079730  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.079731  5547 net.cpp:137] Memory required for data: 831354000
I1001 19:09:22.079735  5547 layer_factory.hpp:77] Creating layer Scale46
I1001 19:09:22.079740  5547 net.cpp:84] Creating Layer Scale46
I1001 19:09:22.079742  5547 net.cpp:406] Scale46 <- Convolution46
I1001 19:09:22.079746  5547 net.cpp:367] Scale46 -> Convolution46 (in-place)
I1001 19:09:22.079773  5547 layer_factory.hpp:77] Creating layer Scale46
I1001 19:09:22.079854  5547 net.cpp:122] Setting up Scale46
I1001 19:09:22.079859  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.079860  5547 net.cpp:137] Memory required for data: 832608400
I1001 19:09:22.079864  5547 layer_factory.hpp:77] Creating layer M2PELU44
I1001 19:09:22.079869  5547 net.cpp:84] Creating Layer M2PELU44
I1001 19:09:22.079871  5547 net.cpp:406] M2PELU44 <- Convolution46
I1001 19:09:22.079874  5547 net.cpp:367] M2PELU44 -> Convolution46 (in-place)
I1001 19:09:22.079964  5547 net.cpp:122] Setting up M2PELU44
I1001 19:09:22.079968  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.079970  5547 net.cpp:137] Memory required for data: 833862800
I1001 19:09:22.079974  5547 layer_factory.hpp:77] Creating layer Convolution47
I1001 19:09:22.079982  5547 net.cpp:84] Creating Layer Convolution47
I1001 19:09:22.079983  5547 net.cpp:406] Convolution47 <- Convolution46
I1001 19:09:22.079988  5547 net.cpp:380] Convolution47 -> Convolution47
I1001 19:09:22.081621  5547 net.cpp:122] Setting up Convolution47
I1001 19:09:22.081629  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.081632  5547 net.cpp:137] Memory required for data: 835117200
I1001 19:09:22.081636  5547 layer_factory.hpp:77] Creating layer BatchNorm47
I1001 19:09:22.081643  5547 net.cpp:84] Creating Layer BatchNorm47
I1001 19:09:22.081652  5547 net.cpp:406] BatchNorm47 <- Convolution47
I1001 19:09:22.081656  5547 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I1001 19:09:22.081802  5547 net.cpp:122] Setting up BatchNorm47
I1001 19:09:22.081806  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.081809  5547 net.cpp:137] Memory required for data: 836371600
I1001 19:09:22.081814  5547 layer_factory.hpp:77] Creating layer Scale47
I1001 19:09:22.081818  5547 net.cpp:84] Creating Layer Scale47
I1001 19:09:22.081820  5547 net.cpp:406] Scale47 <- Convolution47
I1001 19:09:22.081823  5547 net.cpp:367] Scale47 -> Convolution47 (in-place)
I1001 19:09:22.081851  5547 layer_factory.hpp:77] Creating layer Scale47
I1001 19:09:22.081933  5547 net.cpp:122] Setting up Scale47
I1001 19:09:22.081938  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.081939  5547 net.cpp:137] Memory required for data: 837626000
I1001 19:09:22.081943  5547 layer_factory.hpp:77] Creating layer Eltwise22
I1001 19:09:22.081948  5547 net.cpp:84] Creating Layer Eltwise22
I1001 19:09:22.081950  5547 net.cpp:406] Eltwise22 <- Eltwise21_M2PELU43_0_split_1
I1001 19:09:22.081954  5547 net.cpp:406] Eltwise22 <- Convolution47
I1001 19:09:22.081957  5547 net.cpp:380] Eltwise22 -> Eltwise22
I1001 19:09:22.081974  5547 net.cpp:122] Setting up Eltwise22
I1001 19:09:22.081976  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.081979  5547 net.cpp:137] Memory required for data: 838880400
I1001 19:09:22.081980  5547 layer_factory.hpp:77] Creating layer M2PELU45
I1001 19:09:22.081985  5547 net.cpp:84] Creating Layer M2PELU45
I1001 19:09:22.081989  5547 net.cpp:406] M2PELU45 <- Eltwise22
I1001 19:09:22.081991  5547 net.cpp:367] M2PELU45 -> Eltwise22 (in-place)
I1001 19:09:22.082079  5547 net.cpp:122] Setting up M2PELU45
I1001 19:09:22.082083  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.082085  5547 net.cpp:137] Memory required for data: 840134800
I1001 19:09:22.082088  5547 layer_factory.hpp:77] Creating layer Eltwise22_M2PELU45_0_split
I1001 19:09:22.082093  5547 net.cpp:84] Creating Layer Eltwise22_M2PELU45_0_split
I1001 19:09:22.082095  5547 net.cpp:406] Eltwise22_M2PELU45_0_split <- Eltwise22
I1001 19:09:22.082098  5547 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_0
I1001 19:09:22.082103  5547 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_1
I1001 19:09:22.082126  5547 net.cpp:122] Setting up Eltwise22_M2PELU45_0_split
I1001 19:09:22.082129  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.082132  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.082134  5547 net.cpp:137] Memory required for data: 842643600
I1001 19:09:22.082136  5547 layer_factory.hpp:77] Creating layer Convolution48
I1001 19:09:22.082144  5547 net.cpp:84] Creating Layer Convolution48
I1001 19:09:22.082145  5547 net.cpp:406] Convolution48 <- Eltwise22_M2PELU45_0_split_0
I1001 19:09:22.082149  5547 net.cpp:380] Convolution48 -> Convolution48
I1001 19:09:22.083824  5547 net.cpp:122] Setting up Convolution48
I1001 19:09:22.083833  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.083835  5547 net.cpp:137] Memory required for data: 843898000
I1001 19:09:22.083840  5547 layer_factory.hpp:77] Creating layer BatchNorm48
I1001 19:09:22.083845  5547 net.cpp:84] Creating Layer BatchNorm48
I1001 19:09:22.083848  5547 net.cpp:406] BatchNorm48 <- Convolution48
I1001 19:09:22.083851  5547 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I1001 19:09:22.083994  5547 net.cpp:122] Setting up BatchNorm48
I1001 19:09:22.083999  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.084002  5547 net.cpp:137] Memory required for data: 845152400
I1001 19:09:22.084005  5547 layer_factory.hpp:77] Creating layer Scale48
I1001 19:09:22.084010  5547 net.cpp:84] Creating Layer Scale48
I1001 19:09:22.084012  5547 net.cpp:406] Scale48 <- Convolution48
I1001 19:09:22.084017  5547 net.cpp:367] Scale48 -> Convolution48 (in-place)
I1001 19:09:22.084044  5547 layer_factory.hpp:77] Creating layer Scale48
I1001 19:09:22.084137  5547 net.cpp:122] Setting up Scale48
I1001 19:09:22.084143  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.084146  5547 net.cpp:137] Memory required for data: 846406800
I1001 19:09:22.084149  5547 layer_factory.hpp:77] Creating layer M2PELU46
I1001 19:09:22.084154  5547 net.cpp:84] Creating Layer M2PELU46
I1001 19:09:22.084156  5547 net.cpp:406] M2PELU46 <- Convolution48
I1001 19:09:22.084161  5547 net.cpp:367] M2PELU46 -> Convolution48 (in-place)
I1001 19:09:22.084249  5547 net.cpp:122] Setting up M2PELU46
I1001 19:09:22.084252  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.084254  5547 net.cpp:137] Memory required for data: 847661200
I1001 19:09:22.084257  5547 layer_factory.hpp:77] Creating layer Convolution49
I1001 19:09:22.084264  5547 net.cpp:84] Creating Layer Convolution49
I1001 19:09:22.084266  5547 net.cpp:406] Convolution49 <- Convolution48
I1001 19:09:22.084271  5547 net.cpp:380] Convolution49 -> Convolution49
I1001 19:09:22.086242  5547 net.cpp:122] Setting up Convolution49
I1001 19:09:22.086251  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.086253  5547 net.cpp:137] Memory required for data: 848915600
I1001 19:09:22.086258  5547 layer_factory.hpp:77] Creating layer BatchNorm49
I1001 19:09:22.086263  5547 net.cpp:84] Creating Layer BatchNorm49
I1001 19:09:22.086266  5547 net.cpp:406] BatchNorm49 <- Convolution49
I1001 19:09:22.086271  5547 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I1001 19:09:22.086416  5547 net.cpp:122] Setting up BatchNorm49
I1001 19:09:22.086421  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.086423  5547 net.cpp:137] Memory required for data: 850170000
I1001 19:09:22.086427  5547 layer_factory.hpp:77] Creating layer Scale49
I1001 19:09:22.086432  5547 net.cpp:84] Creating Layer Scale49
I1001 19:09:22.086434  5547 net.cpp:406] Scale49 <- Convolution49
I1001 19:09:22.086437  5547 net.cpp:367] Scale49 -> Convolution49 (in-place)
I1001 19:09:22.086465  5547 layer_factory.hpp:77] Creating layer Scale49
I1001 19:09:22.086580  5547 net.cpp:122] Setting up Scale49
I1001 19:09:22.086585  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.086586  5547 net.cpp:137] Memory required for data: 851424400
I1001 19:09:22.086591  5547 layer_factory.hpp:77] Creating layer Eltwise23
I1001 19:09:22.086596  5547 net.cpp:84] Creating Layer Eltwise23
I1001 19:09:22.086598  5547 net.cpp:406] Eltwise23 <- Eltwise22_M2PELU45_0_split_1
I1001 19:09:22.086601  5547 net.cpp:406] Eltwise23 <- Convolution49
I1001 19:09:22.086603  5547 net.cpp:380] Eltwise23 -> Eltwise23
I1001 19:09:22.086621  5547 net.cpp:122] Setting up Eltwise23
I1001 19:09:22.086625  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.086627  5547 net.cpp:137] Memory required for data: 852678800
I1001 19:09:22.086629  5547 layer_factory.hpp:77] Creating layer M2PELU47
I1001 19:09:22.086635  5547 net.cpp:84] Creating Layer M2PELU47
I1001 19:09:22.086638  5547 net.cpp:406] M2PELU47 <- Eltwise23
I1001 19:09:22.086642  5547 net.cpp:367] M2PELU47 -> Eltwise23 (in-place)
I1001 19:09:22.086730  5547 net.cpp:122] Setting up M2PELU47
I1001 19:09:22.086735  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.086736  5547 net.cpp:137] Memory required for data: 853933200
I1001 19:09:22.086740  5547 layer_factory.hpp:77] Creating layer Eltwise23_M2PELU47_0_split
I1001 19:09:22.086743  5547 net.cpp:84] Creating Layer Eltwise23_M2PELU47_0_split
I1001 19:09:22.086746  5547 net.cpp:406] Eltwise23_M2PELU47_0_split <- Eltwise23
I1001 19:09:22.086750  5547 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_0
I1001 19:09:22.086753  5547 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_1
I1001 19:09:22.086777  5547 net.cpp:122] Setting up Eltwise23_M2PELU47_0_split
I1001 19:09:22.086781  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.086784  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.086786  5547 net.cpp:137] Memory required for data: 856442000
I1001 19:09:22.086794  5547 layer_factory.hpp:77] Creating layer Convolution50
I1001 19:09:22.086802  5547 net.cpp:84] Creating Layer Convolution50
I1001 19:09:22.086804  5547 net.cpp:406] Convolution50 <- Eltwise23_M2PELU47_0_split_0
I1001 19:09:22.086808  5547 net.cpp:380] Convolution50 -> Convolution50
I1001 19:09:22.088462  5547 net.cpp:122] Setting up Convolution50
I1001 19:09:22.088470  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.088474  5547 net.cpp:137] Memory required for data: 857696400
I1001 19:09:22.088477  5547 layer_factory.hpp:77] Creating layer BatchNorm50
I1001 19:09:22.088482  5547 net.cpp:84] Creating Layer BatchNorm50
I1001 19:09:22.088485  5547 net.cpp:406] BatchNorm50 <- Convolution50
I1001 19:09:22.088490  5547 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I1001 19:09:22.088634  5547 net.cpp:122] Setting up BatchNorm50
I1001 19:09:22.088639  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.096057  5547 net.cpp:137] Memory required for data: 858950800
I1001 19:09:22.096065  5547 layer_factory.hpp:77] Creating layer Scale50
I1001 19:09:22.096069  5547 net.cpp:84] Creating Layer Scale50
I1001 19:09:22.096072  5547 net.cpp:406] Scale50 <- Convolution50
I1001 19:09:22.096077  5547 net.cpp:367] Scale50 -> Convolution50 (in-place)
I1001 19:09:22.096113  5547 layer_factory.hpp:77] Creating layer Scale50
I1001 19:09:22.096205  5547 net.cpp:122] Setting up Scale50
I1001 19:09:22.096210  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.096213  5547 net.cpp:137] Memory required for data: 860205200
I1001 19:09:22.096217  5547 layer_factory.hpp:77] Creating layer M2PELU48
I1001 19:09:22.096223  5547 net.cpp:84] Creating Layer M2PELU48
I1001 19:09:22.096226  5547 net.cpp:406] M2PELU48 <- Convolution50
I1001 19:09:22.096230  5547 net.cpp:367] M2PELU48 -> Convolution50 (in-place)
I1001 19:09:22.096330  5547 net.cpp:122] Setting up M2PELU48
I1001 19:09:22.096334  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.096338  5547 net.cpp:137] Memory required for data: 861459600
I1001 19:09:22.096340  5547 layer_factory.hpp:77] Creating layer Convolution51
I1001 19:09:22.096349  5547 net.cpp:84] Creating Layer Convolution51
I1001 19:09:22.096351  5547 net.cpp:406] Convolution51 <- Convolution50
I1001 19:09:22.096355  5547 net.cpp:380] Convolution51 -> Convolution51
I1001 19:09:22.098687  5547 net.cpp:122] Setting up Convolution51
I1001 19:09:22.098697  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.098701  5547 net.cpp:137] Memory required for data: 862714000
I1001 19:09:22.098706  5547 layer_factory.hpp:77] Creating layer BatchNorm51
I1001 19:09:22.098711  5547 net.cpp:84] Creating Layer BatchNorm51
I1001 19:09:22.098713  5547 net.cpp:406] BatchNorm51 <- Convolution51
I1001 19:09:22.098718  5547 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I1001 19:09:22.098870  5547 net.cpp:122] Setting up BatchNorm51
I1001 19:09:22.098875  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.098877  5547 net.cpp:137] Memory required for data: 863968400
I1001 19:09:22.098881  5547 layer_factory.hpp:77] Creating layer Scale51
I1001 19:09:22.098886  5547 net.cpp:84] Creating Layer Scale51
I1001 19:09:22.098889  5547 net.cpp:406] Scale51 <- Convolution51
I1001 19:09:22.098892  5547 net.cpp:367] Scale51 -> Convolution51 (in-place)
I1001 19:09:22.098922  5547 layer_factory.hpp:77] Creating layer Scale51
I1001 19:09:22.099009  5547 net.cpp:122] Setting up Scale51
I1001 19:09:22.099014  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.099015  5547 net.cpp:137] Memory required for data: 865222800
I1001 19:09:22.099020  5547 layer_factory.hpp:77] Creating layer Eltwise24
I1001 19:09:22.099025  5547 net.cpp:84] Creating Layer Eltwise24
I1001 19:09:22.099027  5547 net.cpp:406] Eltwise24 <- Eltwise23_M2PELU47_0_split_1
I1001 19:09:22.099030  5547 net.cpp:406] Eltwise24 <- Convolution51
I1001 19:09:22.099033  5547 net.cpp:380] Eltwise24 -> Eltwise24
I1001 19:09:22.099051  5547 net.cpp:122] Setting up Eltwise24
I1001 19:09:22.099062  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.099064  5547 net.cpp:137] Memory required for data: 866477200
I1001 19:09:22.099067  5547 layer_factory.hpp:77] Creating layer M2PELU49
I1001 19:09:22.099072  5547 net.cpp:84] Creating Layer M2PELU49
I1001 19:09:22.099074  5547 net.cpp:406] M2PELU49 <- Eltwise24
I1001 19:09:22.099077  5547 net.cpp:367] M2PELU49 -> Eltwise24 (in-place)
I1001 19:09:22.099174  5547 net.cpp:122] Setting up M2PELU49
I1001 19:09:22.099177  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.099179  5547 net.cpp:137] Memory required for data: 867731600
I1001 19:09:22.099184  5547 layer_factory.hpp:77] Creating layer Eltwise24_M2PELU49_0_split
I1001 19:09:22.099187  5547 net.cpp:84] Creating Layer Eltwise24_M2PELU49_0_split
I1001 19:09:22.099189  5547 net.cpp:406] Eltwise24_M2PELU49_0_split <- Eltwise24
I1001 19:09:22.099194  5547 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_0
I1001 19:09:22.099197  5547 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_1
I1001 19:09:22.099232  5547 net.cpp:122] Setting up Eltwise24_M2PELU49_0_split
I1001 19:09:22.099236  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.099239  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.099241  5547 net.cpp:137] Memory required for data: 870240400
I1001 19:09:22.099244  5547 layer_factory.hpp:77] Creating layer Convolution52
I1001 19:09:22.099251  5547 net.cpp:84] Creating Layer Convolution52
I1001 19:09:22.099253  5547 net.cpp:406] Convolution52 <- Eltwise24_M2PELU49_0_split_0
I1001 19:09:22.099257  5547 net.cpp:380] Convolution52 -> Convolution52
I1001 19:09:22.101032  5547 net.cpp:122] Setting up Convolution52
I1001 19:09:22.101042  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.101044  5547 net.cpp:137] Memory required for data: 871494800
I1001 19:09:22.101049  5547 layer_factory.hpp:77] Creating layer BatchNorm52
I1001 19:09:22.101054  5547 net.cpp:84] Creating Layer BatchNorm52
I1001 19:09:22.101056  5547 net.cpp:406] BatchNorm52 <- Convolution52
I1001 19:09:22.101061  5547 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I1001 19:09:22.101214  5547 net.cpp:122] Setting up BatchNorm52
I1001 19:09:22.101219  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.101222  5547 net.cpp:137] Memory required for data: 872749200
I1001 19:09:22.101225  5547 layer_factory.hpp:77] Creating layer Scale52
I1001 19:09:22.101229  5547 net.cpp:84] Creating Layer Scale52
I1001 19:09:22.101233  5547 net.cpp:406] Scale52 <- Convolution52
I1001 19:09:22.101235  5547 net.cpp:367] Scale52 -> Convolution52 (in-place)
I1001 19:09:22.101264  5547 layer_factory.hpp:77] Creating layer Scale52
I1001 19:09:22.101351  5547 net.cpp:122] Setting up Scale52
I1001 19:09:22.101354  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.101357  5547 net.cpp:137] Memory required for data: 874003600
I1001 19:09:22.101361  5547 layer_factory.hpp:77] Creating layer M2PELU50
I1001 19:09:22.101366  5547 net.cpp:84] Creating Layer M2PELU50
I1001 19:09:22.101367  5547 net.cpp:406] M2PELU50 <- Convolution52
I1001 19:09:22.101372  5547 net.cpp:367] M2PELU50 -> Convolution52 (in-place)
I1001 19:09:22.101465  5547 net.cpp:122] Setting up M2PELU50
I1001 19:09:22.101469  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.101472  5547 net.cpp:137] Memory required for data: 875258000
I1001 19:09:22.101475  5547 layer_factory.hpp:77] Creating layer Convolution53
I1001 19:09:22.101503  5547 net.cpp:84] Creating Layer Convolution53
I1001 19:09:22.101506  5547 net.cpp:406] Convolution53 <- Convolution52
I1001 19:09:22.101510  5547 net.cpp:380] Convolution53 -> Convolution53
I1001 19:09:22.103530  5547 net.cpp:122] Setting up Convolution53
I1001 19:09:22.103540  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.103543  5547 net.cpp:137] Memory required for data: 876512400
I1001 19:09:22.103549  5547 layer_factory.hpp:77] Creating layer BatchNorm53
I1001 19:09:22.103554  5547 net.cpp:84] Creating Layer BatchNorm53
I1001 19:09:22.103564  5547 net.cpp:406] BatchNorm53 <- Convolution53
I1001 19:09:22.103567  5547 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I1001 19:09:22.103720  5547 net.cpp:122] Setting up BatchNorm53
I1001 19:09:22.103725  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.103727  5547 net.cpp:137] Memory required for data: 877766800
I1001 19:09:22.103734  5547 layer_factory.hpp:77] Creating layer Scale53
I1001 19:09:22.103739  5547 net.cpp:84] Creating Layer Scale53
I1001 19:09:22.103740  5547 net.cpp:406] Scale53 <- Convolution53
I1001 19:09:22.103744  5547 net.cpp:367] Scale53 -> Convolution53 (in-place)
I1001 19:09:22.103773  5547 layer_factory.hpp:77] Creating layer Scale53
I1001 19:09:22.103859  5547 net.cpp:122] Setting up Scale53
I1001 19:09:22.103863  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.103865  5547 net.cpp:137] Memory required for data: 879021200
I1001 19:09:22.103869  5547 layer_factory.hpp:77] Creating layer Eltwise25
I1001 19:09:22.103873  5547 net.cpp:84] Creating Layer Eltwise25
I1001 19:09:22.103876  5547 net.cpp:406] Eltwise25 <- Eltwise24_M2PELU49_0_split_1
I1001 19:09:22.103879  5547 net.cpp:406] Eltwise25 <- Convolution53
I1001 19:09:22.103883  5547 net.cpp:380] Eltwise25 -> Eltwise25
I1001 19:09:22.103900  5547 net.cpp:122] Setting up Eltwise25
I1001 19:09:22.103904  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.103905  5547 net.cpp:137] Memory required for data: 880275600
I1001 19:09:22.103909  5547 layer_factory.hpp:77] Creating layer M2PELU51
I1001 19:09:22.103914  5547 net.cpp:84] Creating Layer M2PELU51
I1001 19:09:22.103915  5547 net.cpp:406] M2PELU51 <- Eltwise25
I1001 19:09:22.103919  5547 net.cpp:367] M2PELU51 -> Eltwise25 (in-place)
I1001 19:09:22.104012  5547 net.cpp:122] Setting up M2PELU51
I1001 19:09:22.104017  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.104018  5547 net.cpp:137] Memory required for data: 881530000
I1001 19:09:22.104022  5547 layer_factory.hpp:77] Creating layer Eltwise25_M2PELU51_0_split
I1001 19:09:22.104025  5547 net.cpp:84] Creating Layer Eltwise25_M2PELU51_0_split
I1001 19:09:22.104027  5547 net.cpp:406] Eltwise25_M2PELU51_0_split <- Eltwise25
I1001 19:09:22.104032  5547 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_0
I1001 19:09:22.104035  5547 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_1
I1001 19:09:22.104060  5547 net.cpp:122] Setting up Eltwise25_M2PELU51_0_split
I1001 19:09:22.104064  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.104068  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.104069  5547 net.cpp:137] Memory required for data: 884038800
I1001 19:09:22.104071  5547 layer_factory.hpp:77] Creating layer Convolution54
I1001 19:09:22.104077  5547 net.cpp:84] Creating Layer Convolution54
I1001 19:09:22.104080  5547 net.cpp:406] Convolution54 <- Eltwise25_M2PELU51_0_split_0
I1001 19:09:22.104084  5547 net.cpp:380] Convolution54 -> Convolution54
I1001 19:09:22.106309  5547 net.cpp:122] Setting up Convolution54
I1001 19:09:22.106320  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.106323  5547 net.cpp:137] Memory required for data: 885293200
I1001 19:09:22.106328  5547 layer_factory.hpp:77] Creating layer BatchNorm54
I1001 19:09:22.106334  5547 net.cpp:84] Creating Layer BatchNorm54
I1001 19:09:22.106338  5547 net.cpp:406] BatchNorm54 <- Convolution54
I1001 19:09:22.106341  5547 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I1001 19:09:22.106501  5547 net.cpp:122] Setting up BatchNorm54
I1001 19:09:22.106505  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.106508  5547 net.cpp:137] Memory required for data: 886547600
I1001 19:09:22.106513  5547 layer_factory.hpp:77] Creating layer Scale54
I1001 19:09:22.106516  5547 net.cpp:84] Creating Layer Scale54
I1001 19:09:22.106518  5547 net.cpp:406] Scale54 <- Convolution54
I1001 19:09:22.106537  5547 net.cpp:367] Scale54 -> Convolution54 (in-place)
I1001 19:09:22.106580  5547 layer_factory.hpp:77] Creating layer Scale54
I1001 19:09:22.106673  5547 net.cpp:122] Setting up Scale54
I1001 19:09:22.106678  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.106680  5547 net.cpp:137] Memory required for data: 887802000
I1001 19:09:22.106684  5547 layer_factory.hpp:77] Creating layer M2PELU52
I1001 19:09:22.106689  5547 net.cpp:84] Creating Layer M2PELU52
I1001 19:09:22.106691  5547 net.cpp:406] M2PELU52 <- Convolution54
I1001 19:09:22.106695  5547 net.cpp:367] M2PELU52 -> Convolution54 (in-place)
I1001 19:09:22.106788  5547 net.cpp:122] Setting up M2PELU52
I1001 19:09:22.106792  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.106794  5547 net.cpp:137] Memory required for data: 889056400
I1001 19:09:22.106798  5547 layer_factory.hpp:77] Creating layer Convolution55
I1001 19:09:22.106806  5547 net.cpp:84] Creating Layer Convolution55
I1001 19:09:22.106808  5547 net.cpp:406] Convolution55 <- Convolution54
I1001 19:09:22.106812  5547 net.cpp:380] Convolution55 -> Convolution55
I1001 19:09:22.108844  5547 net.cpp:122] Setting up Convolution55
I1001 19:09:22.108853  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.108856  5547 net.cpp:137] Memory required for data: 890310800
I1001 19:09:22.108860  5547 layer_factory.hpp:77] Creating layer BatchNorm55
I1001 19:09:22.108865  5547 net.cpp:84] Creating Layer BatchNorm55
I1001 19:09:22.108867  5547 net.cpp:406] BatchNorm55 <- Convolution55
I1001 19:09:22.108871  5547 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I1001 19:09:22.109025  5547 net.cpp:122] Setting up BatchNorm55
I1001 19:09:22.109030  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.109031  5547 net.cpp:137] Memory required for data: 891565200
I1001 19:09:22.109036  5547 layer_factory.hpp:77] Creating layer Scale55
I1001 19:09:22.109040  5547 net.cpp:84] Creating Layer Scale55
I1001 19:09:22.109042  5547 net.cpp:406] Scale55 <- Convolution55
I1001 19:09:22.109045  5547 net.cpp:367] Scale55 -> Convolution55 (in-place)
I1001 19:09:22.109074  5547 layer_factory.hpp:77] Creating layer Scale55
I1001 19:09:22.109160  5547 net.cpp:122] Setting up Scale55
I1001 19:09:22.109164  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.109166  5547 net.cpp:137] Memory required for data: 892819600
I1001 19:09:22.109170  5547 layer_factory.hpp:77] Creating layer Eltwise26
I1001 19:09:22.109174  5547 net.cpp:84] Creating Layer Eltwise26
I1001 19:09:22.109177  5547 net.cpp:406] Eltwise26 <- Eltwise25_M2PELU51_0_split_1
I1001 19:09:22.109180  5547 net.cpp:406] Eltwise26 <- Convolution55
I1001 19:09:22.109184  5547 net.cpp:380] Eltwise26 -> Eltwise26
I1001 19:09:22.109201  5547 net.cpp:122] Setting up Eltwise26
I1001 19:09:22.109205  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.109207  5547 net.cpp:137] Memory required for data: 894074000
I1001 19:09:22.109210  5547 layer_factory.hpp:77] Creating layer M2PELU53
I1001 19:09:22.109213  5547 net.cpp:84] Creating Layer M2PELU53
I1001 19:09:22.109215  5547 net.cpp:406] M2PELU53 <- Eltwise26
I1001 19:09:22.109220  5547 net.cpp:367] M2PELU53 -> Eltwise26 (in-place)
I1001 19:09:22.109313  5547 net.cpp:122] Setting up M2PELU53
I1001 19:09:22.109318  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.109319  5547 net.cpp:137] Memory required for data: 895328400
I1001 19:09:22.109323  5547 layer_factory.hpp:77] Creating layer Eltwise26_M2PELU53_0_split
I1001 19:09:22.109326  5547 net.cpp:84] Creating Layer Eltwise26_M2PELU53_0_split
I1001 19:09:22.109329  5547 net.cpp:406] Eltwise26_M2PELU53_0_split <- Eltwise26
I1001 19:09:22.109333  5547 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_0
I1001 19:09:22.109336  5547 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_1
I1001 19:09:22.109361  5547 net.cpp:122] Setting up Eltwise26_M2PELU53_0_split
I1001 19:09:22.109365  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.109369  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.109370  5547 net.cpp:137] Memory required for data: 897837200
I1001 19:09:22.109378  5547 layer_factory.hpp:77] Creating layer Convolution56
I1001 19:09:22.109385  5547 net.cpp:84] Creating Layer Convolution56
I1001 19:09:22.109386  5547 net.cpp:406] Convolution56 <- Eltwise26_M2PELU53_0_split_0
I1001 19:09:22.109392  5547 net.cpp:380] Convolution56 -> Convolution56
I1001 19:09:22.111130  5547 net.cpp:122] Setting up Convolution56
I1001 19:09:22.111140  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.111141  5547 net.cpp:137] Memory required for data: 899091600
I1001 19:09:22.111146  5547 layer_factory.hpp:77] Creating layer BatchNorm56
I1001 19:09:22.111151  5547 net.cpp:84] Creating Layer BatchNorm56
I1001 19:09:22.111153  5547 net.cpp:406] BatchNorm56 <- Convolution56
I1001 19:09:22.111157  5547 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I1001 19:09:22.126634  5547 net.cpp:122] Setting up BatchNorm56
I1001 19:09:22.126643  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.126646  5547 net.cpp:137] Memory required for data: 900346000
I1001 19:09:22.126652  5547 layer_factory.hpp:77] Creating layer Scale56
I1001 19:09:22.126657  5547 net.cpp:84] Creating Layer Scale56
I1001 19:09:22.126660  5547 net.cpp:406] Scale56 <- Convolution56
I1001 19:09:22.126664  5547 net.cpp:367] Scale56 -> Convolution56 (in-place)
I1001 19:09:22.126699  5547 layer_factory.hpp:77] Creating layer Scale56
I1001 19:09:22.126794  5547 net.cpp:122] Setting up Scale56
I1001 19:09:22.126801  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.126802  5547 net.cpp:137] Memory required for data: 901600400
I1001 19:09:22.126807  5547 layer_factory.hpp:77] Creating layer M2PELU54
I1001 19:09:22.126811  5547 net.cpp:84] Creating Layer M2PELU54
I1001 19:09:22.126814  5547 net.cpp:406] M2PELU54 <- Convolution56
I1001 19:09:22.126818  5547 net.cpp:367] M2PELU54 -> Convolution56 (in-place)
I1001 19:09:22.126921  5547 net.cpp:122] Setting up M2PELU54
I1001 19:09:22.126926  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.126929  5547 net.cpp:137] Memory required for data: 902854800
I1001 19:09:22.126932  5547 layer_factory.hpp:77] Creating layer Convolution57
I1001 19:09:22.126941  5547 net.cpp:84] Creating Layer Convolution57
I1001 19:09:22.126943  5547 net.cpp:406] Convolution57 <- Convolution56
I1001 19:09:22.126947  5547 net.cpp:380] Convolution57 -> Convolution57
I1001 19:09:22.129216  5547 net.cpp:122] Setting up Convolution57
I1001 19:09:22.129225  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.129228  5547 net.cpp:137] Memory required for data: 904109200
I1001 19:09:22.129233  5547 layer_factory.hpp:77] Creating layer BatchNorm57
I1001 19:09:22.129238  5547 net.cpp:84] Creating Layer BatchNorm57
I1001 19:09:22.129241  5547 net.cpp:406] BatchNorm57 <- Convolution57
I1001 19:09:22.129245  5547 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I1001 19:09:22.129400  5547 net.cpp:122] Setting up BatchNorm57
I1001 19:09:22.129405  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.129407  5547 net.cpp:137] Memory required for data: 905363600
I1001 19:09:22.129412  5547 layer_factory.hpp:77] Creating layer Scale57
I1001 19:09:22.129416  5547 net.cpp:84] Creating Layer Scale57
I1001 19:09:22.129420  5547 net.cpp:406] Scale57 <- Convolution57
I1001 19:09:22.129422  5547 net.cpp:367] Scale57 -> Convolution57 (in-place)
I1001 19:09:22.129451  5547 layer_factory.hpp:77] Creating layer Scale57
I1001 19:09:22.129539  5547 net.cpp:122] Setting up Scale57
I1001 19:09:22.129544  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.129546  5547 net.cpp:137] Memory required for data: 906618000
I1001 19:09:22.129549  5547 layer_factory.hpp:77] Creating layer Eltwise27
I1001 19:09:22.129554  5547 net.cpp:84] Creating Layer Eltwise27
I1001 19:09:22.129557  5547 net.cpp:406] Eltwise27 <- Eltwise26_M2PELU53_0_split_1
I1001 19:09:22.129560  5547 net.cpp:406] Eltwise27 <- Convolution57
I1001 19:09:22.129565  5547 net.cpp:380] Eltwise27 -> Eltwise27
I1001 19:09:22.129581  5547 net.cpp:122] Setting up Eltwise27
I1001 19:09:22.129593  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.129595  5547 net.cpp:137] Memory required for data: 907872400
I1001 19:09:22.129597  5547 layer_factory.hpp:77] Creating layer M2PELU55
I1001 19:09:22.129602  5547 net.cpp:84] Creating Layer M2PELU55
I1001 19:09:22.129606  5547 net.cpp:406] M2PELU55 <- Eltwise27
I1001 19:09:22.129618  5547 net.cpp:367] M2PELU55 -> Eltwise27 (in-place)
I1001 19:09:22.129737  5547 net.cpp:122] Setting up M2PELU55
I1001 19:09:22.129741  5547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 19:09:22.129743  5547 net.cpp:137] Memory required for data: 909126800
I1001 19:09:22.129747  5547 layer_factory.hpp:77] Creating layer Pooling1
I1001 19:09:22.129753  5547 net.cpp:84] Creating Layer Pooling1
I1001 19:09:22.129755  5547 net.cpp:406] Pooling1 <- Eltwise27
I1001 19:09:22.129760  5547 net.cpp:380] Pooling1 -> Pooling1
I1001 19:09:22.130285  5547 net.cpp:122] Setting up Pooling1
I1001 19:09:22.130295  5547 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1001 19:09:22.130297  5547 net.cpp:137] Memory required for data: 909152400
I1001 19:09:22.130300  5547 layer_factory.hpp:77] Creating layer InnerProduct1
I1001 19:09:22.130308  5547 net.cpp:84] Creating Layer InnerProduct1
I1001 19:09:22.130311  5547 net.cpp:406] InnerProduct1 <- Pooling1
I1001 19:09:22.130316  5547 net.cpp:380] InnerProduct1 -> InnerProduct1
I1001 19:09:22.130426  5547 net.cpp:122] Setting up InnerProduct1
I1001 19:09:22.130431  5547 net.cpp:129] Top shape: 100 10 (1000)
I1001 19:09:22.130434  5547 net.cpp:137] Memory required for data: 909156400
I1001 19:09:22.130437  5547 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1001 19:09:22.130442  5547 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1001 19:09:22.130445  5547 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I1001 19:09:22.130448  5547 net.cpp:406] SoftmaxWithLoss1 <- Data2
I1001 19:09:22.130452  5547 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1001 19:09:22.130457  5547 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1001 19:09:22.130676  5547 net.cpp:122] Setting up SoftmaxWithLoss1
I1001 19:09:22.130682  5547 net.cpp:129] Top shape: (1)
I1001 19:09:22.130686  5547 net.cpp:132]     with loss weight 1
I1001 19:09:22.130697  5547 net.cpp:137] Memory required for data: 909156404
I1001 19:09:22.130700  5547 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1001 19:09:22.130702  5547 net.cpp:198] InnerProduct1 needs backward computation.
I1001 19:09:22.130704  5547 net.cpp:198] Pooling1 needs backward computation.
I1001 19:09:22.130707  5547 net.cpp:198] M2PELU55 needs backward computation.
I1001 19:09:22.130708  5547 net.cpp:198] Eltwise27 needs backward computation.
I1001 19:09:22.130712  5547 net.cpp:198] Scale57 needs backward computation.
I1001 19:09:22.130713  5547 net.cpp:198] BatchNorm57 needs backward computation.
I1001 19:09:22.130715  5547 net.cpp:198] Convolution57 needs backward computation.
I1001 19:09:22.130717  5547 net.cpp:198] M2PELU54 needs backward computation.
I1001 19:09:22.130719  5547 net.cpp:198] Scale56 needs backward computation.
I1001 19:09:22.130722  5547 net.cpp:198] BatchNorm56 needs backward computation.
I1001 19:09:22.130723  5547 net.cpp:198] Convolution56 needs backward computation.
I1001 19:09:22.130725  5547 net.cpp:198] Eltwise26_M2PELU53_0_split needs backward computation.
I1001 19:09:22.130728  5547 net.cpp:198] M2PELU53 needs backward computation.
I1001 19:09:22.130729  5547 net.cpp:198] Eltwise26 needs backward computation.
I1001 19:09:22.130733  5547 net.cpp:198] Scale55 needs backward computation.
I1001 19:09:22.130734  5547 net.cpp:198] BatchNorm55 needs backward computation.
I1001 19:09:22.130736  5547 net.cpp:198] Convolution55 needs backward computation.
I1001 19:09:22.130738  5547 net.cpp:198] M2PELU52 needs backward computation.
I1001 19:09:22.130740  5547 net.cpp:198] Scale54 needs backward computation.
I1001 19:09:22.130743  5547 net.cpp:198] BatchNorm54 needs backward computation.
I1001 19:09:22.130744  5547 net.cpp:198] Convolution54 needs backward computation.
I1001 19:09:22.130753  5547 net.cpp:198] Eltwise25_M2PELU51_0_split needs backward computation.
I1001 19:09:22.130756  5547 net.cpp:198] M2PELU51 needs backward computation.
I1001 19:09:22.130759  5547 net.cpp:198] Eltwise25 needs backward computation.
I1001 19:09:22.130760  5547 net.cpp:198] Scale53 needs backward computation.
I1001 19:09:22.130764  5547 net.cpp:198] BatchNorm53 needs backward computation.
I1001 19:09:22.130765  5547 net.cpp:198] Convolution53 needs backward computation.
I1001 19:09:22.130767  5547 net.cpp:198] M2PELU50 needs backward computation.
I1001 19:09:22.130770  5547 net.cpp:198] Scale52 needs backward computation.
I1001 19:09:22.130772  5547 net.cpp:198] BatchNorm52 needs backward computation.
I1001 19:09:22.130774  5547 net.cpp:198] Convolution52 needs backward computation.
I1001 19:09:22.130776  5547 net.cpp:198] Eltwise24_M2PELU49_0_split needs backward computation.
I1001 19:09:22.130779  5547 net.cpp:198] M2PELU49 needs backward computation.
I1001 19:09:22.130781  5547 net.cpp:198] Eltwise24 needs backward computation.
I1001 19:09:22.130784  5547 net.cpp:198] Scale51 needs backward computation.
I1001 19:09:22.130786  5547 net.cpp:198] BatchNorm51 needs backward computation.
I1001 19:09:22.130789  5547 net.cpp:198] Convolution51 needs backward computation.
I1001 19:09:22.130790  5547 net.cpp:198] M2PELU48 needs backward computation.
I1001 19:09:22.130792  5547 net.cpp:198] Scale50 needs backward computation.
I1001 19:09:22.130795  5547 net.cpp:198] BatchNorm50 needs backward computation.
I1001 19:09:22.130796  5547 net.cpp:198] Convolution50 needs backward computation.
I1001 19:09:22.130800  5547 net.cpp:198] Eltwise23_M2PELU47_0_split needs backward computation.
I1001 19:09:22.130801  5547 net.cpp:198] M2PELU47 needs backward computation.
I1001 19:09:22.130803  5547 net.cpp:198] Eltwise23 needs backward computation.
I1001 19:09:22.130806  5547 net.cpp:198] Scale49 needs backward computation.
I1001 19:09:22.130808  5547 net.cpp:198] BatchNorm49 needs backward computation.
I1001 19:09:22.130810  5547 net.cpp:198] Convolution49 needs backward computation.
I1001 19:09:22.130813  5547 net.cpp:198] M2PELU46 needs backward computation.
I1001 19:09:22.130815  5547 net.cpp:198] Scale48 needs backward computation.
I1001 19:09:22.130817  5547 net.cpp:198] BatchNorm48 needs backward computation.
I1001 19:09:22.130820  5547 net.cpp:198] Convolution48 needs backward computation.
I1001 19:09:22.130822  5547 net.cpp:198] Eltwise22_M2PELU45_0_split needs backward computation.
I1001 19:09:22.130825  5547 net.cpp:198] M2PELU45 needs backward computation.
I1001 19:09:22.130826  5547 net.cpp:198] Eltwise22 needs backward computation.
I1001 19:09:22.130830  5547 net.cpp:198] Scale47 needs backward computation.
I1001 19:09:22.130831  5547 net.cpp:198] BatchNorm47 needs backward computation.
I1001 19:09:22.130833  5547 net.cpp:198] Convolution47 needs backward computation.
I1001 19:09:22.130836  5547 net.cpp:198] M2PELU44 needs backward computation.
I1001 19:09:22.130838  5547 net.cpp:198] Scale46 needs backward computation.
I1001 19:09:22.130841  5547 net.cpp:198] BatchNorm46 needs backward computation.
I1001 19:09:22.130842  5547 net.cpp:198] Convolution46 needs backward computation.
I1001 19:09:22.130846  5547 net.cpp:198] Eltwise21_M2PELU43_0_split needs backward computation.
I1001 19:09:22.130848  5547 net.cpp:198] M2PELU43 needs backward computation.
I1001 19:09:22.130851  5547 net.cpp:198] Eltwise21 needs backward computation.
I1001 19:09:22.130853  5547 net.cpp:198] Scale45 needs backward computation.
I1001 19:09:22.130856  5547 net.cpp:198] BatchNorm45 needs backward computation.
I1001 19:09:22.130857  5547 net.cpp:198] Convolution45 needs backward computation.
I1001 19:09:22.130859  5547 net.cpp:198] M2PELU42 needs backward computation.
I1001 19:09:22.130861  5547 net.cpp:198] Scale44 needs backward computation.
I1001 19:09:22.130864  5547 net.cpp:198] BatchNorm44 needs backward computation.
I1001 19:09:22.130867  5547 net.cpp:198] Convolution44 needs backward computation.
I1001 19:09:22.130872  5547 net.cpp:198] Eltwise20_M2PELU41_0_split needs backward computation.
I1001 19:09:22.130874  5547 net.cpp:198] M2PELU41 needs backward computation.
I1001 19:09:22.130877  5547 net.cpp:198] Eltwise20 needs backward computation.
I1001 19:09:22.130879  5547 net.cpp:198] Scale43 needs backward computation.
I1001 19:09:22.130882  5547 net.cpp:198] BatchNorm43 needs backward computation.
I1001 19:09:22.130883  5547 net.cpp:198] Convolution43 needs backward computation.
I1001 19:09:22.130885  5547 net.cpp:198] M2PELU40 needs backward computation.
I1001 19:09:22.130887  5547 net.cpp:198] Scale42 needs backward computation.
I1001 19:09:22.130890  5547 net.cpp:198] BatchNorm42 needs backward computation.
I1001 19:09:22.130893  5547 net.cpp:198] Convolution42 needs backward computation.
I1001 19:09:22.130897  5547 net.cpp:198] Eltwise19_M2PELU39_0_split needs backward computation.
I1001 19:09:22.130898  5547 net.cpp:198] M2PELU39 needs backward computation.
I1001 19:09:22.130901  5547 net.cpp:198] Eltwise19 needs backward computation.
I1001 19:09:22.130903  5547 net.cpp:198] Scale41 needs backward computation.
I1001 19:09:22.130906  5547 net.cpp:198] BatchNorm41 needs backward computation.
I1001 19:09:22.130908  5547 net.cpp:198] Convolution41 needs backward computation.
I1001 19:09:22.130910  5547 net.cpp:198] M2PELU38 needs backward computation.
I1001 19:09:22.130913  5547 net.cpp:198] Scale40 needs backward computation.
I1001 19:09:22.130914  5547 net.cpp:198] BatchNorm40 needs backward computation.
I1001 19:09:22.130916  5547 net.cpp:198] Convolution40 needs backward computation.
I1001 19:09:22.130919  5547 net.cpp:198] Scale39 needs backward computation.
I1001 19:09:22.130921  5547 net.cpp:198] BatchNorm39 needs backward computation.
I1001 19:09:22.130923  5547 net.cpp:198] Convolution39 needs backward computation.
I1001 19:09:22.130926  5547 net.cpp:198] Eltwise18_M2PELU37_0_split needs backward computation.
I1001 19:09:22.130928  5547 net.cpp:198] M2PELU37 needs backward computation.
I1001 19:09:22.130930  5547 net.cpp:198] Eltwise18 needs backward computation.
I1001 19:09:22.130934  5547 net.cpp:198] Scale38 needs backward computation.
I1001 19:09:22.130936  5547 net.cpp:198] BatchNorm38 needs backward computation.
I1001 19:09:22.130939  5547 net.cpp:198] Convolution38 needs backward computation.
I1001 19:09:22.130940  5547 net.cpp:198] M2PELU36 needs backward computation.
I1001 19:09:22.130942  5547 net.cpp:198] Scale37 needs backward computation.
I1001 19:09:22.130944  5547 net.cpp:198] BatchNorm37 needs backward computation.
I1001 19:09:22.130946  5547 net.cpp:198] Convolution37 needs backward computation.
I1001 19:09:22.130949  5547 net.cpp:198] Eltwise17_M2PELU35_0_split needs backward computation.
I1001 19:09:22.130951  5547 net.cpp:198] M2PELU35 needs backward computation.
I1001 19:09:22.130954  5547 net.cpp:198] Eltwise17 needs backward computation.
I1001 19:09:22.130956  5547 net.cpp:198] Scale36 needs backward computation.
I1001 19:09:22.130959  5547 net.cpp:198] BatchNorm36 needs backward computation.
I1001 19:09:22.130961  5547 net.cpp:198] Convolution36 needs backward computation.
I1001 19:09:22.130964  5547 net.cpp:198] M2PELU34 needs backward computation.
I1001 19:09:22.130965  5547 net.cpp:198] Scale35 needs backward computation.
I1001 19:09:22.130967  5547 net.cpp:198] BatchNorm35 needs backward computation.
I1001 19:09:22.130970  5547 net.cpp:198] Convolution35 needs backward computation.
I1001 19:09:22.130972  5547 net.cpp:198] Eltwise16_M2PELU33_0_split needs backward computation.
I1001 19:09:22.130975  5547 net.cpp:198] M2PELU33 needs backward computation.
I1001 19:09:22.130977  5547 net.cpp:198] Eltwise16 needs backward computation.
I1001 19:09:22.130980  5547 net.cpp:198] Scale34 needs backward computation.
I1001 19:09:22.130981  5547 net.cpp:198] BatchNorm34 needs backward computation.
I1001 19:09:22.130985  5547 net.cpp:198] Convolution34 needs backward computation.
I1001 19:09:22.130986  5547 net.cpp:198] M2PELU32 needs backward computation.
I1001 19:09:22.130988  5547 net.cpp:198] Scale33 needs backward computation.
I1001 19:09:22.130993  5547 net.cpp:198] BatchNorm33 needs backward computation.
I1001 19:09:22.130995  5547 net.cpp:198] Convolution33 needs backward computation.
I1001 19:09:22.130998  5547 net.cpp:198] Eltwise15_M2PELU31_0_split needs backward computation.
I1001 19:09:22.131000  5547 net.cpp:198] M2PELU31 needs backward computation.
I1001 19:09:22.131002  5547 net.cpp:198] Eltwise15 needs backward computation.
I1001 19:09:22.131006  5547 net.cpp:198] Scale32 needs backward computation.
I1001 19:09:22.131008  5547 net.cpp:198] BatchNorm32 needs backward computation.
I1001 19:09:22.131011  5547 net.cpp:198] Convolution32 needs backward computation.
I1001 19:09:22.156746  5547 net.cpp:198] M2PELU30 needs backward computation.
I1001 19:09:22.156754  5547 net.cpp:198] Scale31 needs backward computation.
I1001 19:09:22.156756  5547 net.cpp:198] BatchNorm31 needs backward computation.
I1001 19:09:22.156759  5547 net.cpp:198] Convolution31 needs backward computation.
I1001 19:09:22.156762  5547 net.cpp:198] Eltwise14_M2PELU29_0_split needs backward computation.
I1001 19:09:22.156765  5547 net.cpp:198] M2PELU29 needs backward computation.
I1001 19:09:22.156767  5547 net.cpp:198] Eltwise14 needs backward computation.
I1001 19:09:22.156770  5547 net.cpp:198] Scale30 needs backward computation.
I1001 19:09:22.156774  5547 net.cpp:198] BatchNorm30 needs backward computation.
I1001 19:09:22.156775  5547 net.cpp:198] Convolution30 needs backward computation.
I1001 19:09:22.156779  5547 net.cpp:198] M2PELU28 needs backward computation.
I1001 19:09:22.156780  5547 net.cpp:198] Scale29 needs backward computation.
I1001 19:09:22.156783  5547 net.cpp:198] BatchNorm29 needs backward computation.
I1001 19:09:22.156785  5547 net.cpp:198] Convolution29 needs backward computation.
I1001 19:09:22.156788  5547 net.cpp:198] Eltwise13_M2PELU27_0_split needs backward computation.
I1001 19:09:22.156791  5547 net.cpp:198] M2PELU27 needs backward computation.
I1001 19:09:22.156793  5547 net.cpp:198] Eltwise13 needs backward computation.
I1001 19:09:22.156796  5547 net.cpp:198] Scale28 needs backward computation.
I1001 19:09:22.156800  5547 net.cpp:198] BatchNorm28 needs backward computation.
I1001 19:09:22.156801  5547 net.cpp:198] Convolution28 needs backward computation.
I1001 19:09:22.156805  5547 net.cpp:198] M2PELU26 needs backward computation.
I1001 19:09:22.156806  5547 net.cpp:198] Scale27 needs backward computation.
I1001 19:09:22.156810  5547 net.cpp:198] BatchNorm27 needs backward computation.
I1001 19:09:22.156811  5547 net.cpp:198] Convolution27 needs backward computation.
I1001 19:09:22.156814  5547 net.cpp:198] Eltwise12_M2PELU25_0_split needs backward computation.
I1001 19:09:22.156816  5547 net.cpp:198] M2PELU25 needs backward computation.
I1001 19:09:22.156819  5547 net.cpp:198] Eltwise12 needs backward computation.
I1001 19:09:22.156822  5547 net.cpp:198] Scale26 needs backward computation.
I1001 19:09:22.156824  5547 net.cpp:198] BatchNorm26 needs backward computation.
I1001 19:09:22.156827  5547 net.cpp:198] Convolution26 needs backward computation.
I1001 19:09:22.156829  5547 net.cpp:198] M2PELU24 needs backward computation.
I1001 19:09:22.156832  5547 net.cpp:198] Scale25 needs backward computation.
I1001 19:09:22.156834  5547 net.cpp:198] BatchNorm25 needs backward computation.
I1001 19:09:22.156836  5547 net.cpp:198] Convolution25 needs backward computation.
I1001 19:09:22.156839  5547 net.cpp:198] Eltwise11_M2PELU23_0_split needs backward computation.
I1001 19:09:22.156842  5547 net.cpp:198] M2PELU23 needs backward computation.
I1001 19:09:22.156844  5547 net.cpp:198] Eltwise11 needs backward computation.
I1001 19:09:22.156847  5547 net.cpp:198] Scale24 needs backward computation.
I1001 19:09:22.156849  5547 net.cpp:198] BatchNorm24 needs backward computation.
I1001 19:09:22.156852  5547 net.cpp:198] Convolution24 needs backward computation.
I1001 19:09:22.156854  5547 net.cpp:198] M2PELU22 needs backward computation.
I1001 19:09:22.156857  5547 net.cpp:198] Scale23 needs backward computation.
I1001 19:09:22.156867  5547 net.cpp:198] BatchNorm23 needs backward computation.
I1001 19:09:22.156869  5547 net.cpp:198] Convolution23 needs backward computation.
I1001 19:09:22.156872  5547 net.cpp:198] Eltwise10_M2PELU21_0_split needs backward computation.
I1001 19:09:22.156875  5547 net.cpp:198] M2PELU21 needs backward computation.
I1001 19:09:22.156877  5547 net.cpp:198] Eltwise10 needs backward computation.
I1001 19:09:22.156880  5547 net.cpp:198] Scale22 needs backward computation.
I1001 19:09:22.156883  5547 net.cpp:198] BatchNorm22 needs backward computation.
I1001 19:09:22.156885  5547 net.cpp:198] Convolution22 needs backward computation.
I1001 19:09:22.156888  5547 net.cpp:198] M2PELU20 needs backward computation.
I1001 19:09:22.156891  5547 net.cpp:198] Scale21 needs backward computation.
I1001 19:09:22.156893  5547 net.cpp:198] BatchNorm21 needs backward computation.
I1001 19:09:22.156895  5547 net.cpp:198] Convolution21 needs backward computation.
I1001 19:09:22.156898  5547 net.cpp:198] Scale20 needs backward computation.
I1001 19:09:22.156901  5547 net.cpp:198] BatchNorm20 needs backward computation.
I1001 19:09:22.156903  5547 net.cpp:198] Convolution20 needs backward computation.
I1001 19:09:22.156906  5547 net.cpp:198] Eltwise9_M2PELU19_0_split needs backward computation.
I1001 19:09:22.156908  5547 net.cpp:198] M2PELU19 needs backward computation.
I1001 19:09:22.156911  5547 net.cpp:198] Eltwise9 needs backward computation.
I1001 19:09:22.156914  5547 net.cpp:198] Scale19 needs backward computation.
I1001 19:09:22.156916  5547 net.cpp:198] BatchNorm19 needs backward computation.
I1001 19:09:22.156919  5547 net.cpp:198] Convolution19 needs backward computation.
I1001 19:09:22.156921  5547 net.cpp:198] M2PELU18 needs backward computation.
I1001 19:09:22.156924  5547 net.cpp:198] Scale18 needs backward computation.
I1001 19:09:22.156926  5547 net.cpp:198] BatchNorm18 needs backward computation.
I1001 19:09:22.156929  5547 net.cpp:198] Convolution18 needs backward computation.
I1001 19:09:22.156931  5547 net.cpp:198] Eltwise8_M2PELU17_0_split needs backward computation.
I1001 19:09:22.156934  5547 net.cpp:198] M2PELU17 needs backward computation.
I1001 19:09:22.156936  5547 net.cpp:198] Eltwise8 needs backward computation.
I1001 19:09:22.156939  5547 net.cpp:198] Scale17 needs backward computation.
I1001 19:09:22.156941  5547 net.cpp:198] BatchNorm17 needs backward computation.
I1001 19:09:22.156944  5547 net.cpp:198] Convolution17 needs backward computation.
I1001 19:09:22.156946  5547 net.cpp:198] M2PELU16 needs backward computation.
I1001 19:09:22.156949  5547 net.cpp:198] Scale16 needs backward computation.
I1001 19:09:22.156951  5547 net.cpp:198] BatchNorm16 needs backward computation.
I1001 19:09:22.156954  5547 net.cpp:198] Convolution16 needs backward computation.
I1001 19:09:22.156956  5547 net.cpp:198] Eltwise7_M2PELU15_0_split needs backward computation.
I1001 19:09:22.156958  5547 net.cpp:198] M2PELU15 needs backward computation.
I1001 19:09:22.156961  5547 net.cpp:198] Eltwise7 needs backward computation.
I1001 19:09:22.156965  5547 net.cpp:198] Scale15 needs backward computation.
I1001 19:09:22.156966  5547 net.cpp:198] BatchNorm15 needs backward computation.
I1001 19:09:22.156970  5547 net.cpp:198] Convolution15 needs backward computation.
I1001 19:09:22.156971  5547 net.cpp:198] M2PELU14 needs backward computation.
I1001 19:09:22.156975  5547 net.cpp:198] Scale14 needs backward computation.
I1001 19:09:22.156976  5547 net.cpp:198] BatchNorm14 needs backward computation.
I1001 19:09:22.156980  5547 net.cpp:198] Convolution14 needs backward computation.
I1001 19:09:22.156981  5547 net.cpp:198] Eltwise6_M2PELU13_0_split needs backward computation.
I1001 19:09:22.156985  5547 net.cpp:198] M2PELU13 needs backward computation.
I1001 19:09:22.156986  5547 net.cpp:198] Eltwise6 needs backward computation.
I1001 19:09:22.156989  5547 net.cpp:198] Scale13 needs backward computation.
I1001 19:09:22.156992  5547 net.cpp:198] BatchNorm13 needs backward computation.
I1001 19:09:22.156994  5547 net.cpp:198] Convolution13 needs backward computation.
I1001 19:09:22.157002  5547 net.cpp:198] M2PELU12 needs backward computation.
I1001 19:09:22.157004  5547 net.cpp:198] Scale12 needs backward computation.
I1001 19:09:22.157006  5547 net.cpp:198] BatchNorm12 needs backward computation.
I1001 19:09:22.157009  5547 net.cpp:198] Convolution12 needs backward computation.
I1001 19:09:22.157011  5547 net.cpp:198] Eltwise5_M2PELU11_0_split needs backward computation.
I1001 19:09:22.157014  5547 net.cpp:198] M2PELU11 needs backward computation.
I1001 19:09:22.157016  5547 net.cpp:198] Eltwise5 needs backward computation.
I1001 19:09:22.158810  5547 net.cpp:198] Scale11 needs backward computation.
I1001 19:09:22.158818  5547 net.cpp:198] BatchNorm11 needs backward computation.
I1001 19:09:22.158820  5547 net.cpp:198] Convolution11 needs backward computation.
I1001 19:09:22.158824  5547 net.cpp:198] M2PELU10 needs backward computation.
I1001 19:09:22.158828  5547 net.cpp:198] Scale10 needs backward computation.
I1001 19:09:22.158829  5547 net.cpp:198] BatchNorm10 needs backward computation.
I1001 19:09:22.158841  5547 net.cpp:198] Convolution10 needs backward computation.
I1001 19:09:22.158844  5547 net.cpp:198] Eltwise4_M2PELU9_0_split needs backward computation.
I1001 19:09:22.158846  5547 net.cpp:198] M2PELU9 needs backward computation.
I1001 19:09:22.158849  5547 net.cpp:198] Eltwise4 needs backward computation.
I1001 19:09:22.158861  5547 net.cpp:198] Scale9 needs backward computation.
I1001 19:09:22.158864  5547 net.cpp:198] BatchNorm9 needs backward computation.
I1001 19:09:22.158866  5547 net.cpp:198] Convolution9 needs backward computation.
I1001 19:09:22.158869  5547 net.cpp:198] M2PELU8 needs backward computation.
I1001 19:09:22.158871  5547 net.cpp:198] Scale8 needs backward computation.
I1001 19:09:22.158874  5547 net.cpp:198] BatchNorm8 needs backward computation.
I1001 19:09:22.158875  5547 net.cpp:198] Convolution8 needs backward computation.
I1001 19:09:22.158879  5547 net.cpp:198] Eltwise3_M2PELU7_0_split needs backward computation.
I1001 19:09:22.158880  5547 net.cpp:198] M2PELU7 needs backward computation.
I1001 19:09:22.158882  5547 net.cpp:198] Eltwise3 needs backward computation.
I1001 19:09:22.158885  5547 net.cpp:198] Scale7 needs backward computation.
I1001 19:09:22.158887  5547 net.cpp:198] BatchNorm7 needs backward computation.
I1001 19:09:22.158890  5547 net.cpp:198] Convolution7 needs backward computation.
I1001 19:09:22.158892  5547 net.cpp:198] M2PELU6 needs backward computation.
I1001 19:09:22.158895  5547 net.cpp:198] Scale6 needs backward computation.
I1001 19:09:22.158896  5547 net.cpp:198] BatchNorm6 needs backward computation.
I1001 19:09:22.158898  5547 net.cpp:198] Convolution6 needs backward computation.
I1001 19:09:22.158901  5547 net.cpp:198] Eltwise2_M2PELU5_0_split needs backward computation.
I1001 19:09:22.158903  5547 net.cpp:198] M2PELU5 needs backward computation.
I1001 19:09:22.158905  5547 net.cpp:198] Eltwise2 needs backward computation.
I1001 19:09:22.158908  5547 net.cpp:198] Scale5 needs backward computation.
I1001 19:09:22.158910  5547 net.cpp:198] BatchNorm5 needs backward computation.
I1001 19:09:22.158913  5547 net.cpp:198] Convolution5 needs backward computation.
I1001 19:09:22.158915  5547 net.cpp:198] M2PELU4 needs backward computation.
I1001 19:09:22.158917  5547 net.cpp:198] Scale4 needs backward computation.
I1001 19:09:22.158920  5547 net.cpp:198] BatchNorm4 needs backward computation.
I1001 19:09:22.158921  5547 net.cpp:198] Convolution4 needs backward computation.
I1001 19:09:22.158924  5547 net.cpp:198] Eltwise1_M2PELU3_0_split needs backward computation.
I1001 19:09:22.158927  5547 net.cpp:198] M2PELU3 needs backward computation.
I1001 19:09:22.158929  5547 net.cpp:198] Eltwise1 needs backward computation.
I1001 19:09:22.158932  5547 net.cpp:198] Scale3 needs backward computation.
I1001 19:09:22.158934  5547 net.cpp:198] BatchNorm3 needs backward computation.
I1001 19:09:22.158936  5547 net.cpp:198] Convolution3 needs backward computation.
I1001 19:09:22.158946  5547 net.cpp:198] M2PELU2 needs backward computation.
I1001 19:09:22.158947  5547 net.cpp:198] Scale2 needs backward computation.
I1001 19:09:22.158949  5547 net.cpp:198] BatchNorm2 needs backward computation.
I1001 19:09:22.158952  5547 net.cpp:198] Convolution2 needs backward computation.
I1001 19:09:22.158954  5547 net.cpp:198] Convolution1_M2PELU1_0_split needs backward computation.
I1001 19:09:22.158957  5547 net.cpp:198] M2PELU1 needs backward computation.
I1001 19:09:22.158959  5547 net.cpp:198] Scale1 needs backward computation.
I1001 19:09:22.158962  5547 net.cpp:198] BatchNorm1 needs backward computation.
I1001 19:09:22.158963  5547 net.cpp:198] Convolution1 needs backward computation.
I1001 19:09:22.158967  5547 net.cpp:200] Data1 does not need backward computation.
I1001 19:09:22.158968  5547 net.cpp:242] This network produces output SoftmaxWithLoss1
I1001 19:09:22.159056  5547 net.cpp:255] Network initialization done.
I1001 19:09:22.163558  5547 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_mpelu_train_test.prototxt
I1001 19:09:22.163571  5547 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1001 19:09:22.163576  5547 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_mpelu_train_test.prototxt
I1001 19:09:22.163770  5547 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I1001 19:09:22.165079  5547 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU1"
  type: "M2PELU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU2"
  type: "M2PELU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU3"
  type: "M2PELU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU4"
  type: "M2PELU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU5"
  type: "M2PELU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU6"
  type: "M2PELU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU7"
  type: "M2PELU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU8"
  type: "M2PELU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU9"
  type: "M2PELU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU10"
  type: "M2PELU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU11"
  type: "M2PELU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU12"
  type: "M2PELU"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU13"
  type: "M2PELU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU14"
  type: "M2PELU"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU15"
  type: "M2PELU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU16"
  type: "M2PELU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU17"
  type: "M2PELU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU18"
  type: "M2PELU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU19"
  type: "M2PELU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU20"
  type: "M2PELU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU21"
  type: "M2PELU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU22"
  type: "M2PELU"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution24"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU23"
  type: "M2PELU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU24"
  type: "M2PELU"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      t
I1001 19:09:22.220072  5547 layer_factory.hpp:77] Creating layer Data1
I1001 19:09:22.220120  5547 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I1001 19:09:22.220131  5547 net.cpp:84] Creating Layer Data1
I1001 19:09:22.220135  5547 net.cpp:380] Data1 -> Data1
I1001 19:09:22.220144  5547 net.cpp:380] Data1 -> Data2
I1001 19:09:22.220149  5547 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1001 19:09:22.220317  5547 data_layer.cpp:45] output data size: 100,3,32,32
I1001 19:09:22.224783  5547 net.cpp:122] Setting up Data1
I1001 19:09:22.224803  5547 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1001 19:09:22.224809  5547 net.cpp:129] Top shape: 100 (100)
I1001 19:09:22.224812  5547 net.cpp:137] Memory required for data: 1229200
I1001 19:09:22.224817  5547 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I1001 19:09:22.224824  5547 net.cpp:84] Creating Layer Data2_Data1_1_split
I1001 19:09:22.224828  5547 net.cpp:406] Data2_Data1_1_split <- Data2
I1001 19:09:22.224833  5547 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I1001 19:09:22.224839  5547 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I1001 19:09:22.224943  5547 net.cpp:122] Setting up Data2_Data1_1_split
I1001 19:09:22.224954  5547 net.cpp:129] Top shape: 100 (100)
I1001 19:09:22.224957  5547 net.cpp:129] Top shape: 100 (100)
I1001 19:09:22.224959  5547 net.cpp:137] Memory required for data: 1230000
I1001 19:09:22.224962  5547 layer_factory.hpp:77] Creating layer Convolution1
I1001 19:09:22.224972  5547 net.cpp:84] Creating Layer Convolution1
I1001 19:09:22.224975  5547 net.cpp:406] Convolution1 <- Data1
I1001 19:09:22.224980  5547 net.cpp:380] Convolution1 -> Convolution1
I1001 19:09:22.226222  5547 net.cpp:122] Setting up Convolution1
I1001 19:09:22.226233  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.226235  5547 net.cpp:137] Memory required for data: 7783600
I1001 19:09:22.226243  5547 layer_factory.hpp:77] Creating layer BatchNorm1
I1001 19:09:22.226249  5547 net.cpp:84] Creating Layer BatchNorm1
I1001 19:09:22.226251  5547 net.cpp:406] BatchNorm1 <- Convolution1
I1001 19:09:22.226256  5547 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1001 19:09:22.226416  5547 net.cpp:122] Setting up BatchNorm1
I1001 19:09:22.226421  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.226424  5547 net.cpp:137] Memory required for data: 14337200
I1001 19:09:22.226433  5547 layer_factory.hpp:77] Creating layer Scale1
I1001 19:09:22.226441  5547 net.cpp:84] Creating Layer Scale1
I1001 19:09:22.226444  5547 net.cpp:406] Scale1 <- Convolution1
I1001 19:09:22.226447  5547 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1001 19:09:22.226482  5547 layer_factory.hpp:77] Creating layer Scale1
I1001 19:09:22.226583  5547 net.cpp:122] Setting up Scale1
I1001 19:09:22.226589  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.226591  5547 net.cpp:137] Memory required for data: 20890800
I1001 19:09:22.226596  5547 layer_factory.hpp:77] Creating layer M2PELU1
I1001 19:09:22.226603  5547 net.cpp:84] Creating Layer M2PELU1
I1001 19:09:22.226605  5547 net.cpp:406] M2PELU1 <- Convolution1
I1001 19:09:22.226609  5547 net.cpp:367] M2PELU1 -> Convolution1 (in-place)
I1001 19:09:22.227254  5547 net.cpp:122] Setting up M2PELU1
I1001 19:09:22.227263  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.227267  5547 net.cpp:137] Memory required for data: 27444400
I1001 19:09:22.227272  5547 layer_factory.hpp:77] Creating layer Convolution1_M2PELU1_0_split
I1001 19:09:22.227279  5547 net.cpp:84] Creating Layer Convolution1_M2PELU1_0_split
I1001 19:09:22.227283  5547 net.cpp:406] Convolution1_M2PELU1_0_split <- Convolution1
I1001 19:09:22.227286  5547 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_0
I1001 19:09:22.227291  5547 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_1
I1001 19:09:22.227324  5547 net.cpp:122] Setting up Convolution1_M2PELU1_0_split
I1001 19:09:22.247552  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.247560  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.247563  5547 net.cpp:137] Memory required for data: 40551600
I1001 19:09:22.247566  5547 layer_factory.hpp:77] Creating layer Convolution2
I1001 19:09:22.247575  5547 net.cpp:84] Creating Layer Convolution2
I1001 19:09:22.247578  5547 net.cpp:406] Convolution2 <- Convolution1_M2PELU1_0_split_0
I1001 19:09:22.247586  5547 net.cpp:380] Convolution2 -> Convolution2
I1001 19:09:22.248777  5547 net.cpp:122] Setting up Convolution2
I1001 19:09:22.248787  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.248791  5547 net.cpp:137] Memory required for data: 47105200
I1001 19:09:22.248796  5547 layer_factory.hpp:77] Creating layer BatchNorm2
I1001 19:09:22.248805  5547 net.cpp:84] Creating Layer BatchNorm2
I1001 19:09:22.248807  5547 net.cpp:406] BatchNorm2 <- Convolution2
I1001 19:09:22.248811  5547 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1001 19:09:22.249028  5547 net.cpp:122] Setting up BatchNorm2
I1001 19:09:22.249038  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.249042  5547 net.cpp:137] Memory required for data: 53658800
I1001 19:09:22.249071  5547 layer_factory.hpp:77] Creating layer Scale2
I1001 19:09:22.249081  5547 net.cpp:84] Creating Layer Scale2
I1001 19:09:22.249086  5547 net.cpp:406] Scale2 <- Convolution2
I1001 19:09:22.249092  5547 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1001 19:09:22.249153  5547 layer_factory.hpp:77] Creating layer Scale2
I1001 19:09:22.249253  5547 net.cpp:122] Setting up Scale2
I1001 19:09:22.249258  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.249260  5547 net.cpp:137] Memory required for data: 60212400
I1001 19:09:22.249264  5547 layer_factory.hpp:77] Creating layer M2PELU2
I1001 19:09:22.249271  5547 net.cpp:84] Creating Layer M2PELU2
I1001 19:09:22.249274  5547 net.cpp:406] M2PELU2 <- Convolution2
I1001 19:09:22.249277  5547 net.cpp:367] M2PELU2 -> Convolution2 (in-place)
I1001 19:09:22.249392  5547 net.cpp:122] Setting up M2PELU2
I1001 19:09:22.249397  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.249398  5547 net.cpp:137] Memory required for data: 66766000
I1001 19:09:22.249405  5547 layer_factory.hpp:77] Creating layer Convolution3
I1001 19:09:22.249413  5547 net.cpp:84] Creating Layer Convolution3
I1001 19:09:22.249414  5547 net.cpp:406] Convolution3 <- Convolution2
I1001 19:09:22.249419  5547 net.cpp:380] Convolution3 -> Convolution3
I1001 19:09:22.250458  5547 net.cpp:122] Setting up Convolution3
I1001 19:09:22.250468  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.250470  5547 net.cpp:137] Memory required for data: 73319600
I1001 19:09:22.250474  5547 layer_factory.hpp:77] Creating layer BatchNorm3
I1001 19:09:22.250480  5547 net.cpp:84] Creating Layer BatchNorm3
I1001 19:09:22.250483  5547 net.cpp:406] BatchNorm3 <- Convolution3
I1001 19:09:22.250486  5547 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1001 19:09:22.250654  5547 net.cpp:122] Setting up BatchNorm3
I1001 19:09:22.250660  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.250663  5547 net.cpp:137] Memory required for data: 79873200
I1001 19:09:22.250668  5547 layer_factory.hpp:77] Creating layer Scale3
I1001 19:09:22.250671  5547 net.cpp:84] Creating Layer Scale3
I1001 19:09:22.250674  5547 net.cpp:406] Scale3 <- Convolution3
I1001 19:09:22.250677  5547 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1001 19:09:22.250708  5547 layer_factory.hpp:77] Creating layer Scale3
I1001 19:09:22.250792  5547 net.cpp:122] Setting up Scale3
I1001 19:09:22.250797  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.250799  5547 net.cpp:137] Memory required for data: 86426800
I1001 19:09:22.250813  5547 layer_factory.hpp:77] Creating layer Eltwise1
I1001 19:09:22.250820  5547 net.cpp:84] Creating Layer Eltwise1
I1001 19:09:22.250823  5547 net.cpp:406] Eltwise1 <- Convolution1_M2PELU1_0_split_1
I1001 19:09:22.250826  5547 net.cpp:406] Eltwise1 <- Convolution3
I1001 19:09:22.250829  5547 net.cpp:380] Eltwise1 -> Eltwise1
I1001 19:09:22.250849  5547 net.cpp:122] Setting up Eltwise1
I1001 19:09:22.250852  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.250854  5547 net.cpp:137] Memory required for data: 92980400
I1001 19:09:22.250857  5547 layer_factory.hpp:77] Creating layer M2PELU3
I1001 19:09:22.250862  5547 net.cpp:84] Creating Layer M2PELU3
I1001 19:09:22.250864  5547 net.cpp:406] M2PELU3 <- Eltwise1
I1001 19:09:22.250869  5547 net.cpp:367] M2PELU3 -> Eltwise1 (in-place)
I1001 19:09:22.250979  5547 net.cpp:122] Setting up M2PELU3
I1001 19:09:22.250984  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.250988  5547 net.cpp:137] Memory required for data: 99534000
I1001 19:09:22.250991  5547 layer_factory.hpp:77] Creating layer Eltwise1_M2PELU3_0_split
I1001 19:09:22.250996  5547 net.cpp:84] Creating Layer Eltwise1_M2PELU3_0_split
I1001 19:09:22.250998  5547 net.cpp:406] Eltwise1_M2PELU3_0_split <- Eltwise1
I1001 19:09:22.251003  5547 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_0
I1001 19:09:22.251008  5547 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_1
I1001 19:09:22.251042  5547 net.cpp:122] Setting up Eltwise1_M2PELU3_0_split
I1001 19:09:22.251046  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.251049  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.251051  5547 net.cpp:137] Memory required for data: 112641200
I1001 19:09:22.251055  5547 layer_factory.hpp:77] Creating layer Convolution4
I1001 19:09:22.251060  5547 net.cpp:84] Creating Layer Convolution4
I1001 19:09:22.251063  5547 net.cpp:406] Convolution4 <- Eltwise1_M2PELU3_0_split_0
I1001 19:09:22.251067  5547 net.cpp:380] Convolution4 -> Convolution4
I1001 19:09:22.252117  5547 net.cpp:122] Setting up Convolution4
I1001 19:09:22.252127  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.252130  5547 net.cpp:137] Memory required for data: 119194800
I1001 19:09:22.252135  5547 layer_factory.hpp:77] Creating layer BatchNorm4
I1001 19:09:22.252140  5547 net.cpp:84] Creating Layer BatchNorm4
I1001 19:09:22.252142  5547 net.cpp:406] BatchNorm4 <- Convolution4
I1001 19:09:22.252147  5547 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1001 19:09:22.252302  5547 net.cpp:122] Setting up BatchNorm4
I1001 19:09:22.252306  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.252310  5547 net.cpp:137] Memory required for data: 125748400
I1001 19:09:22.252313  5547 layer_factory.hpp:77] Creating layer Scale4
I1001 19:09:22.252318  5547 net.cpp:84] Creating Layer Scale4
I1001 19:09:22.252321  5547 net.cpp:406] Scale4 <- Convolution4
I1001 19:09:22.252323  5547 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1001 19:09:22.252354  5547 layer_factory.hpp:77] Creating layer Scale4
I1001 19:09:22.252439  5547 net.cpp:122] Setting up Scale4
I1001 19:09:22.252444  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.252445  5547 net.cpp:137] Memory required for data: 132302000
I1001 19:09:22.252454  5547 layer_factory.hpp:77] Creating layer M2PELU4
I1001 19:09:22.252459  5547 net.cpp:84] Creating Layer M2PELU4
I1001 19:09:22.252460  5547 net.cpp:406] M2PELU4 <- Convolution4
I1001 19:09:22.252465  5547 net.cpp:367] M2PELU4 -> Convolution4 (in-place)
I1001 19:09:22.252566  5547 net.cpp:122] Setting up M2PELU4
I1001 19:09:22.252570  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.252573  5547 net.cpp:137] Memory required for data: 138855600
I1001 19:09:22.252576  5547 layer_factory.hpp:77] Creating layer Convolution5
I1001 19:09:22.252584  5547 net.cpp:84] Creating Layer Convolution5
I1001 19:09:22.252586  5547 net.cpp:406] Convolution5 <- Convolution4
I1001 19:09:22.252590  5547 net.cpp:380] Convolution5 -> Convolution5
I1001 19:09:22.253530  5547 net.cpp:122] Setting up Convolution5
I1001 19:09:22.253538  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.253541  5547 net.cpp:137] Memory required for data: 145409200
I1001 19:09:22.253546  5547 layer_factory.hpp:77] Creating layer BatchNorm5
I1001 19:09:22.253551  5547 net.cpp:84] Creating Layer BatchNorm5
I1001 19:09:22.253554  5547 net.cpp:406] BatchNorm5 <- Convolution5
I1001 19:09:22.253557  5547 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1001 19:09:22.253713  5547 net.cpp:122] Setting up BatchNorm5
I1001 19:09:22.253718  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.253720  5547 net.cpp:137] Memory required for data: 151962800
I1001 19:09:22.253724  5547 layer_factory.hpp:77] Creating layer Scale5
I1001 19:09:22.253729  5547 net.cpp:84] Creating Layer Scale5
I1001 19:09:22.253731  5547 net.cpp:406] Scale5 <- Convolution5
I1001 19:09:22.253736  5547 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1001 19:09:22.253764  5547 layer_factory.hpp:77] Creating layer Scale5
I1001 19:09:22.253846  5547 net.cpp:122] Setting up Scale5
I1001 19:09:22.253851  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.253854  5547 net.cpp:137] Memory required for data: 158516400
I1001 19:09:22.253856  5547 layer_factory.hpp:77] Creating layer Eltwise2
I1001 19:09:22.253861  5547 net.cpp:84] Creating Layer Eltwise2
I1001 19:09:22.253870  5547 net.cpp:406] Eltwise2 <- Eltwise1_M2PELU3_0_split_1
I1001 19:09:22.253873  5547 net.cpp:406] Eltwise2 <- Convolution5
I1001 19:09:22.253876  5547 net.cpp:380] Eltwise2 -> Eltwise2
I1001 19:09:22.253895  5547 net.cpp:122] Setting up Eltwise2
I1001 19:09:22.253899  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.253901  5547 net.cpp:137] Memory required for data: 165070000
I1001 19:09:22.253903  5547 layer_factory.hpp:77] Creating layer M2PELU5
I1001 19:09:22.253908  5547 net.cpp:84] Creating Layer M2PELU5
I1001 19:09:22.253911  5547 net.cpp:406] M2PELU5 <- Eltwise2
I1001 19:09:22.253914  5547 net.cpp:367] M2PELU5 -> Eltwise2 (in-place)
I1001 19:09:22.254016  5547 net.cpp:122] Setting up M2PELU5
I1001 19:09:22.254020  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.254022  5547 net.cpp:137] Memory required for data: 171623600
I1001 19:09:22.254026  5547 layer_factory.hpp:77] Creating layer Eltwise2_M2PELU5_0_split
I1001 19:09:22.254030  5547 net.cpp:84] Creating Layer Eltwise2_M2PELU5_0_split
I1001 19:09:22.254032  5547 net.cpp:406] Eltwise2_M2PELU5_0_split <- Eltwise2
I1001 19:09:22.254035  5547 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_0
I1001 19:09:22.254040  5547 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_1
I1001 19:09:22.254067  5547 net.cpp:122] Setting up Eltwise2_M2PELU5_0_split
I1001 19:09:22.254071  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.254075  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.254076  5547 net.cpp:137] Memory required for data: 184730800
I1001 19:09:22.254078  5547 layer_factory.hpp:77] Creating layer Convolution6
I1001 19:09:22.254086  5547 net.cpp:84] Creating Layer Convolution6
I1001 19:09:22.254087  5547 net.cpp:406] Convolution6 <- Eltwise2_M2PELU5_0_split_0
I1001 19:09:22.254091  5547 net.cpp:380] Convolution6 -> Convolution6
I1001 19:09:22.255061  5547 net.cpp:122] Setting up Convolution6
I1001 19:09:22.255070  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.255074  5547 net.cpp:137] Memory required for data: 191284400
I1001 19:09:22.255077  5547 layer_factory.hpp:77] Creating layer BatchNorm6
I1001 19:09:22.255082  5547 net.cpp:84] Creating Layer BatchNorm6
I1001 19:09:22.255085  5547 net.cpp:406] BatchNorm6 <- Convolution6
I1001 19:09:22.255089  5547 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1001 19:09:22.255239  5547 net.cpp:122] Setting up BatchNorm6
I1001 19:09:22.255244  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.255246  5547 net.cpp:137] Memory required for data: 197838000
I1001 19:09:22.255250  5547 layer_factory.hpp:77] Creating layer Scale6
I1001 19:09:22.255254  5547 net.cpp:84] Creating Layer Scale6
I1001 19:09:22.255257  5547 net.cpp:406] Scale6 <- Convolution6
I1001 19:09:22.255261  5547 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1001 19:09:22.255290  5547 layer_factory.hpp:77] Creating layer Scale6
I1001 19:09:22.255373  5547 net.cpp:122] Setting up Scale6
I1001 19:09:22.255378  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.255380  5547 net.cpp:137] Memory required for data: 204391600
I1001 19:09:22.255383  5547 layer_factory.hpp:77] Creating layer M2PELU6
I1001 19:09:22.255388  5547 net.cpp:84] Creating Layer M2PELU6
I1001 19:09:22.255390  5547 net.cpp:406] M2PELU6 <- Convolution6
I1001 19:09:22.255394  5547 net.cpp:367] M2PELU6 -> Convolution6 (in-place)
I1001 19:09:22.255494  5547 net.cpp:122] Setting up M2PELU6
I1001 19:09:22.255498  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.255501  5547 net.cpp:137] Memory required for data: 210945200
I1001 19:09:22.255503  5547 layer_factory.hpp:77] Creating layer Convolution7
I1001 19:09:22.255511  5547 net.cpp:84] Creating Layer Convolution7
I1001 19:09:22.255512  5547 net.cpp:406] Convolution7 <- Convolution6
I1001 19:09:22.255517  5547 net.cpp:380] Convolution7 -> Convolution7
I1001 19:09:22.256446  5547 net.cpp:122] Setting up Convolution7
I1001 19:09:22.256454  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.256464  5547 net.cpp:137] Memory required for data: 217498800
I1001 19:09:22.256469  5547 layer_factory.hpp:77] Creating layer BatchNorm7
I1001 19:09:22.256475  5547 net.cpp:84] Creating Layer BatchNorm7
I1001 19:09:22.256479  5547 net.cpp:406] BatchNorm7 <- Convolution7
I1001 19:09:22.256482  5547 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1001 19:09:22.256635  5547 net.cpp:122] Setting up BatchNorm7
I1001 19:09:22.256639  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.256641  5547 net.cpp:137] Memory required for data: 224052400
I1001 19:09:22.256646  5547 layer_factory.hpp:77] Creating layer Scale7
I1001 19:09:22.256651  5547 net.cpp:84] Creating Layer Scale7
I1001 19:09:22.256654  5547 net.cpp:406] Scale7 <- Convolution7
I1001 19:09:22.256656  5547 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1001 19:09:22.256685  5547 layer_factory.hpp:77] Creating layer Scale7
I1001 19:09:22.256770  5547 net.cpp:122] Setting up Scale7
I1001 19:09:22.256774  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.256777  5547 net.cpp:137] Memory required for data: 230606000
I1001 19:09:22.256780  5547 layer_factory.hpp:77] Creating layer Eltwise3
I1001 19:09:22.256784  5547 net.cpp:84] Creating Layer Eltwise3
I1001 19:09:22.256786  5547 net.cpp:406] Eltwise3 <- Eltwise2_M2PELU5_0_split_1
I1001 19:09:22.256789  5547 net.cpp:406] Eltwise3 <- Convolution7
I1001 19:09:22.256793  5547 net.cpp:380] Eltwise3 -> Eltwise3
I1001 19:09:22.256809  5547 net.cpp:122] Setting up Eltwise3
I1001 19:09:22.256814  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.256816  5547 net.cpp:137] Memory required for data: 237159600
I1001 19:09:22.256819  5547 layer_factory.hpp:77] Creating layer M2PELU7
I1001 19:09:22.256822  5547 net.cpp:84] Creating Layer M2PELU7
I1001 19:09:22.256825  5547 net.cpp:406] M2PELU7 <- Eltwise3
I1001 19:09:22.256829  5547 net.cpp:367] M2PELU7 -> Eltwise3 (in-place)
I1001 19:09:22.256929  5547 net.cpp:122] Setting up M2PELU7
I1001 19:09:22.256933  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.256935  5547 net.cpp:137] Memory required for data: 243713200
I1001 19:09:22.256939  5547 layer_factory.hpp:77] Creating layer Eltwise3_M2PELU7_0_split
I1001 19:09:22.256942  5547 net.cpp:84] Creating Layer Eltwise3_M2PELU7_0_split
I1001 19:09:22.256944  5547 net.cpp:406] Eltwise3_M2PELU7_0_split <- Eltwise3
I1001 19:09:22.256948  5547 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_0
I1001 19:09:22.256953  5547 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_1
I1001 19:09:22.256978  5547 net.cpp:122] Setting up Eltwise3_M2PELU7_0_split
I1001 19:09:22.256981  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.277992  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.277999  5547 net.cpp:137] Memory required for data: 256820400
I1001 19:09:22.278002  5547 layer_factory.hpp:77] Creating layer Convolution8
I1001 19:09:22.278012  5547 net.cpp:84] Creating Layer Convolution8
I1001 19:09:22.278015  5547 net.cpp:406] Convolution8 <- Eltwise3_M2PELU7_0_split_0
I1001 19:09:22.278020  5547 net.cpp:380] Convolution8 -> Convolution8
I1001 19:09:22.279093  5547 net.cpp:122] Setting up Convolution8
I1001 19:09:22.279103  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.279106  5547 net.cpp:137] Memory required for data: 263374000
I1001 19:09:22.279119  5547 layer_factory.hpp:77] Creating layer BatchNorm8
I1001 19:09:22.279124  5547 net.cpp:84] Creating Layer BatchNorm8
I1001 19:09:22.279127  5547 net.cpp:406] BatchNorm8 <- Convolution8
I1001 19:09:22.279131  5547 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1001 19:09:22.279301  5547 net.cpp:122] Setting up BatchNorm8
I1001 19:09:22.279306  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.279309  5547 net.cpp:137] Memory required for data: 269927600
I1001 19:09:22.279314  5547 layer_factory.hpp:77] Creating layer Scale8
I1001 19:09:22.279319  5547 net.cpp:84] Creating Layer Scale8
I1001 19:09:22.279330  5547 net.cpp:406] Scale8 <- Convolution8
I1001 19:09:22.279335  5547 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1001 19:09:22.279369  5547 layer_factory.hpp:77] Creating layer Scale8
I1001 19:09:22.279465  5547 net.cpp:122] Setting up Scale8
I1001 19:09:22.279471  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.279474  5547 net.cpp:137] Memory required for data: 276481200
I1001 19:09:22.279479  5547 layer_factory.hpp:77] Creating layer M2PELU8
I1001 19:09:22.279484  5547 net.cpp:84] Creating Layer M2PELU8
I1001 19:09:22.279485  5547 net.cpp:406] M2PELU8 <- Convolution8
I1001 19:09:22.279490  5547 net.cpp:367] M2PELU8 -> Convolution8 (in-place)
I1001 19:09:22.279616  5547 net.cpp:122] Setting up M2PELU8
I1001 19:09:22.279620  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.279623  5547 net.cpp:137] Memory required for data: 283034800
I1001 19:09:22.279626  5547 layer_factory.hpp:77] Creating layer Convolution9
I1001 19:09:22.279644  5547 net.cpp:84] Creating Layer Convolution9
I1001 19:09:22.279646  5547 net.cpp:406] Convolution9 <- Convolution8
I1001 19:09:22.279650  5547 net.cpp:380] Convolution9 -> Convolution9
I1001 19:09:22.280712  5547 net.cpp:122] Setting up Convolution9
I1001 19:09:22.280721  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.280725  5547 net.cpp:137] Memory required for data: 289588400
I1001 19:09:22.280730  5547 layer_factory.hpp:77] Creating layer BatchNorm9
I1001 19:09:22.280735  5547 net.cpp:84] Creating Layer BatchNorm9
I1001 19:09:22.280737  5547 net.cpp:406] BatchNorm9 <- Convolution9
I1001 19:09:22.280741  5547 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1001 19:09:22.280896  5547 net.cpp:122] Setting up BatchNorm9
I1001 19:09:22.280901  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.280903  5547 net.cpp:137] Memory required for data: 296142000
I1001 19:09:22.280908  5547 layer_factory.hpp:77] Creating layer Scale9
I1001 19:09:22.280912  5547 net.cpp:84] Creating Layer Scale9
I1001 19:09:22.280915  5547 net.cpp:406] Scale9 <- Convolution9
I1001 19:09:22.280918  5547 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1001 19:09:22.280947  5547 layer_factory.hpp:77] Creating layer Scale9
I1001 19:09:22.281033  5547 net.cpp:122] Setting up Scale9
I1001 19:09:22.281036  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.281038  5547 net.cpp:137] Memory required for data: 302695600
I1001 19:09:22.281042  5547 layer_factory.hpp:77] Creating layer Eltwise4
I1001 19:09:22.281047  5547 net.cpp:84] Creating Layer Eltwise4
I1001 19:09:22.281060  5547 net.cpp:406] Eltwise4 <- Eltwise3_M2PELU7_0_split_1
I1001 19:09:22.281064  5547 net.cpp:406] Eltwise4 <- Convolution9
I1001 19:09:22.281066  5547 net.cpp:380] Eltwise4 -> Eltwise4
I1001 19:09:22.281085  5547 net.cpp:122] Setting up Eltwise4
I1001 19:09:22.281090  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.281091  5547 net.cpp:137] Memory required for data: 309249200
I1001 19:09:22.281093  5547 layer_factory.hpp:77] Creating layer M2PELU9
I1001 19:09:22.281100  5547 net.cpp:84] Creating Layer M2PELU9
I1001 19:09:22.281103  5547 net.cpp:406] M2PELU9 <- Eltwise4
I1001 19:09:22.281106  5547 net.cpp:367] M2PELU9 -> Eltwise4 (in-place)
I1001 19:09:22.281230  5547 net.cpp:122] Setting up M2PELU9
I1001 19:09:22.281235  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.281237  5547 net.cpp:137] Memory required for data: 315802800
I1001 19:09:22.281241  5547 layer_factory.hpp:77] Creating layer Eltwise4_M2PELU9_0_split
I1001 19:09:22.281245  5547 net.cpp:84] Creating Layer Eltwise4_M2PELU9_0_split
I1001 19:09:22.281247  5547 net.cpp:406] Eltwise4_M2PELU9_0_split <- Eltwise4
I1001 19:09:22.281250  5547 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_0
I1001 19:09:22.281255  5547 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_1
I1001 19:09:22.281281  5547 net.cpp:122] Setting up Eltwise4_M2PELU9_0_split
I1001 19:09:22.281286  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.281296  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.281297  5547 net.cpp:137] Memory required for data: 328910000
I1001 19:09:22.281301  5547 layer_factory.hpp:77] Creating layer Convolution10
I1001 19:09:22.281306  5547 net.cpp:84] Creating Layer Convolution10
I1001 19:09:22.281309  5547 net.cpp:406] Convolution10 <- Eltwise4_M2PELU9_0_split_0
I1001 19:09:22.281313  5547 net.cpp:380] Convolution10 -> Convolution10
I1001 19:09:22.282413  5547 net.cpp:122] Setting up Convolution10
I1001 19:09:22.282421  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.282424  5547 net.cpp:137] Memory required for data: 335463600
I1001 19:09:22.282428  5547 layer_factory.hpp:77] Creating layer BatchNorm10
I1001 19:09:22.282433  5547 net.cpp:84] Creating Layer BatchNorm10
I1001 19:09:22.282436  5547 net.cpp:406] BatchNorm10 <- Convolution10
I1001 19:09:22.282440  5547 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1001 19:09:22.282622  5547 net.cpp:122] Setting up BatchNorm10
I1001 19:09:22.282627  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.282630  5547 net.cpp:137] Memory required for data: 342017200
I1001 19:09:22.282634  5547 layer_factory.hpp:77] Creating layer Scale10
I1001 19:09:22.282639  5547 net.cpp:84] Creating Layer Scale10
I1001 19:09:22.282641  5547 net.cpp:406] Scale10 <- Convolution10
I1001 19:09:22.282644  5547 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1001 19:09:22.282675  5547 layer_factory.hpp:77] Creating layer Scale10
I1001 19:09:22.282759  5547 net.cpp:122] Setting up Scale10
I1001 19:09:22.282763  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.282765  5547 net.cpp:137] Memory required for data: 348570800
I1001 19:09:22.282769  5547 layer_factory.hpp:77] Creating layer M2PELU10
I1001 19:09:22.282774  5547 net.cpp:84] Creating Layer M2PELU10
I1001 19:09:22.282776  5547 net.cpp:406] M2PELU10 <- Convolution10
I1001 19:09:22.282779  5547 net.cpp:367] M2PELU10 -> Convolution10 (in-place)
I1001 19:09:22.282878  5547 net.cpp:122] Setting up M2PELU10
I1001 19:09:22.282882  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.282884  5547 net.cpp:137] Memory required for data: 355124400
I1001 19:09:22.282888  5547 layer_factory.hpp:77] Creating layer Convolution11
I1001 19:09:22.282896  5547 net.cpp:84] Creating Layer Convolution11
I1001 19:09:22.282897  5547 net.cpp:406] Convolution11 <- Convolution10
I1001 19:09:22.282902  5547 net.cpp:380] Convolution11 -> Convolution11
I1001 19:09:22.284160  5547 net.cpp:122] Setting up Convolution11
I1001 19:09:22.284168  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.284171  5547 net.cpp:137] Memory required for data: 361678000
I1001 19:09:22.284176  5547 layer_factory.hpp:77] Creating layer BatchNorm11
I1001 19:09:22.284181  5547 net.cpp:84] Creating Layer BatchNorm11
I1001 19:09:22.284184  5547 net.cpp:406] BatchNorm11 <- Convolution11
I1001 19:09:22.284188  5547 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1001 19:09:22.284342  5547 net.cpp:122] Setting up BatchNorm11
I1001 19:09:22.284346  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.284348  5547 net.cpp:137] Memory required for data: 368231600
I1001 19:09:22.284353  5547 layer_factory.hpp:77] Creating layer Scale11
I1001 19:09:22.284358  5547 net.cpp:84] Creating Layer Scale11
I1001 19:09:22.284360  5547 net.cpp:406] Scale11 <- Convolution11
I1001 19:09:22.284363  5547 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1001 19:09:22.284392  5547 layer_factory.hpp:77] Creating layer Scale11
I1001 19:09:22.284477  5547 net.cpp:122] Setting up Scale11
I1001 19:09:22.284482  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.284483  5547 net.cpp:137] Memory required for data: 374785200
I1001 19:09:22.284487  5547 layer_factory.hpp:77] Creating layer Eltwise5
I1001 19:09:22.284492  5547 net.cpp:84] Creating Layer Eltwise5
I1001 19:09:22.284494  5547 net.cpp:406] Eltwise5 <- Eltwise4_M2PELU9_0_split_1
I1001 19:09:22.284504  5547 net.cpp:406] Eltwise5 <- Convolution11
I1001 19:09:22.284507  5547 net.cpp:380] Eltwise5 -> Eltwise5
I1001 19:09:22.284526  5547 net.cpp:122] Setting up Eltwise5
I1001 19:09:22.284530  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.284533  5547 net.cpp:137] Memory required for data: 381338800
I1001 19:09:22.284534  5547 layer_factory.hpp:77] Creating layer M2PELU11
I1001 19:09:22.284539  5547 net.cpp:84] Creating Layer M2PELU11
I1001 19:09:22.284541  5547 net.cpp:406] M2PELU11 <- Eltwise5
I1001 19:09:22.284545  5547 net.cpp:367] M2PELU11 -> Eltwise5 (in-place)
I1001 19:09:22.284648  5547 net.cpp:122] Setting up M2PELU11
I1001 19:09:22.284652  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.284654  5547 net.cpp:137] Memory required for data: 387892400
I1001 19:09:22.284658  5547 layer_factory.hpp:77] Creating layer Eltwise5_M2PELU11_0_split
I1001 19:09:22.284662  5547 net.cpp:84] Creating Layer Eltwise5_M2PELU11_0_split
I1001 19:09:22.284665  5547 net.cpp:406] Eltwise5_M2PELU11_0_split <- Eltwise5
I1001 19:09:22.284668  5547 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_0
I1001 19:09:22.284672  5547 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_1
I1001 19:09:22.284698  5547 net.cpp:122] Setting up Eltwise5_M2PELU11_0_split
I1001 19:09:22.284703  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.284704  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.284708  5547 net.cpp:137] Memory required for data: 400999600
I1001 19:09:22.284709  5547 layer_factory.hpp:77] Creating layer Convolution12
I1001 19:09:22.284714  5547 net.cpp:84] Creating Layer Convolution12
I1001 19:09:22.284718  5547 net.cpp:406] Convolution12 <- Eltwise5_M2PELU11_0_split_0
I1001 19:09:22.284723  5547 net.cpp:380] Convolution12 -> Convolution12
I1001 19:09:22.285672  5547 net.cpp:122] Setting up Convolution12
I1001 19:09:22.285682  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.285686  5547 net.cpp:137] Memory required for data: 407553200
I1001 19:09:22.285689  5547 layer_factory.hpp:77] Creating layer BatchNorm12
I1001 19:09:22.285694  5547 net.cpp:84] Creating Layer BatchNorm12
I1001 19:09:22.285696  5547 net.cpp:406] BatchNorm12 <- Convolution12
I1001 19:09:22.285701  5547 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1001 19:09:22.285854  5547 net.cpp:122] Setting up BatchNorm12
I1001 19:09:22.285858  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.285861  5547 net.cpp:137] Memory required for data: 414106800
I1001 19:09:22.285866  5547 layer_factory.hpp:77] Creating layer Scale12
I1001 19:09:22.285871  5547 net.cpp:84] Creating Layer Scale12
I1001 19:09:22.285872  5547 net.cpp:406] Scale12 <- Convolution12
I1001 19:09:22.285876  5547 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1001 19:09:22.285905  5547 layer_factory.hpp:77] Creating layer Scale12
I1001 19:09:22.285990  5547 net.cpp:122] Setting up Scale12
I1001 19:09:22.285995  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.285996  5547 net.cpp:137] Memory required for data: 420660400
I1001 19:09:22.286000  5547 layer_factory.hpp:77] Creating layer M2PELU12
I1001 19:09:22.286005  5547 net.cpp:84] Creating Layer M2PELU12
I1001 19:09:22.286007  5547 net.cpp:406] M2PELU12 <- Convolution12
I1001 19:09:22.286010  5547 net.cpp:367] M2PELU12 -> Convolution12 (in-place)
I1001 19:09:22.286109  5547 net.cpp:122] Setting up M2PELU12
I1001 19:09:22.286114  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.286116  5547 net.cpp:137] Memory required for data: 427214000
I1001 19:09:22.286120  5547 layer_factory.hpp:77] Creating layer Convolution13
I1001 19:09:22.286126  5547 net.cpp:84] Creating Layer Convolution13
I1001 19:09:22.286129  5547 net.cpp:406] Convolution13 <- Convolution12
I1001 19:09:22.286133  5547 net.cpp:380] Convolution13 -> Convolution13
I1001 19:09:22.287104  5547 net.cpp:122] Setting up Convolution13
I1001 19:09:22.287113  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.287122  5547 net.cpp:137] Memory required for data: 433767600
I1001 19:09:22.287127  5547 layer_factory.hpp:77] Creating layer BatchNorm13
I1001 19:09:22.287132  5547 net.cpp:84] Creating Layer BatchNorm13
I1001 19:09:22.287135  5547 net.cpp:406] BatchNorm13 <- Convolution13
I1001 19:09:22.287138  5547 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1001 19:09:22.287292  5547 net.cpp:122] Setting up BatchNorm13
I1001 19:09:22.287295  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.287297  5547 net.cpp:137] Memory required for data: 440321200
I1001 19:09:22.287302  5547 layer_factory.hpp:77] Creating layer Scale13
I1001 19:09:22.287307  5547 net.cpp:84] Creating Layer Scale13
I1001 19:09:22.287308  5547 net.cpp:406] Scale13 <- Convolution13
I1001 19:09:22.287312  5547 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1001 19:09:22.287341  5547 layer_factory.hpp:77] Creating layer Scale13
I1001 19:09:22.287426  5547 net.cpp:122] Setting up Scale13
I1001 19:09:22.287431  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.287433  5547 net.cpp:137] Memory required for data: 446874800
I1001 19:09:22.287436  5547 layer_factory.hpp:77] Creating layer Eltwise6
I1001 19:09:22.287447  5547 net.cpp:84] Creating Layer Eltwise6
I1001 19:09:22.287451  5547 net.cpp:406] Eltwise6 <- Eltwise5_M2PELU11_0_split_1
I1001 19:09:22.287453  5547 net.cpp:406] Eltwise6 <- Convolution13
I1001 19:09:22.287456  5547 net.cpp:380] Eltwise6 -> Eltwise6
I1001 19:09:22.287475  5547 net.cpp:122] Setting up Eltwise6
I1001 19:09:22.287478  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.287480  5547 net.cpp:137] Memory required for data: 453428400
I1001 19:09:22.287483  5547 layer_factory.hpp:77] Creating layer M2PELU13
I1001 19:09:22.287487  5547 net.cpp:84] Creating Layer M2PELU13
I1001 19:09:22.287489  5547 net.cpp:406] M2PELU13 <- Eltwise6
I1001 19:09:22.287492  5547 net.cpp:367] M2PELU13 -> Eltwise6 (in-place)
I1001 19:09:22.287592  5547 net.cpp:122] Setting up M2PELU13
I1001 19:09:22.287597  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.287600  5547 net.cpp:137] Memory required for data: 459982000
I1001 19:09:22.287603  5547 layer_factory.hpp:77] Creating layer Eltwise6_M2PELU13_0_split
I1001 19:09:22.287606  5547 net.cpp:84] Creating Layer Eltwise6_M2PELU13_0_split
I1001 19:09:22.287609  5547 net.cpp:406] Eltwise6_M2PELU13_0_split <- Eltwise6
I1001 19:09:22.287612  5547 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_0
I1001 19:09:22.287616  5547 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_1
I1001 19:09:22.287642  5547 net.cpp:122] Setting up Eltwise6_M2PELU13_0_split
I1001 19:09:22.308348  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.308357  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.308358  5547 net.cpp:137] Memory required for data: 473089200
I1001 19:09:22.308362  5547 layer_factory.hpp:77] Creating layer Convolution14
I1001 19:09:22.308370  5547 net.cpp:84] Creating Layer Convolution14
I1001 19:09:22.308374  5547 net.cpp:406] Convolution14 <- Eltwise6_M2PELU13_0_split_0
I1001 19:09:22.308379  5547 net.cpp:380] Convolution14 -> Convolution14
I1001 19:09:22.309473  5547 net.cpp:122] Setting up Convolution14
I1001 19:09:22.309484  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.309486  5547 net.cpp:137] Memory required for data: 479642800
I1001 19:09:22.309491  5547 layer_factory.hpp:77] Creating layer BatchNorm14
I1001 19:09:22.309497  5547 net.cpp:84] Creating Layer BatchNorm14
I1001 19:09:22.309500  5547 net.cpp:406] BatchNorm14 <- Convolution14
I1001 19:09:22.309504  5547 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1001 19:09:22.309674  5547 net.cpp:122] Setting up BatchNorm14
I1001 19:09:22.309677  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.309680  5547 net.cpp:137] Memory required for data: 486196400
I1001 19:09:22.309685  5547 layer_factory.hpp:77] Creating layer Scale14
I1001 19:09:22.309689  5547 net.cpp:84] Creating Layer Scale14
I1001 19:09:22.309700  5547 net.cpp:406] Scale14 <- Convolution14
I1001 19:09:22.309705  5547 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1001 19:09:22.309739  5547 layer_factory.hpp:77] Creating layer Scale14
I1001 19:09:22.309834  5547 net.cpp:122] Setting up Scale14
I1001 19:09:22.309839  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.309840  5547 net.cpp:137] Memory required for data: 492750000
I1001 19:09:22.309844  5547 layer_factory.hpp:77] Creating layer M2PELU14
I1001 19:09:22.309850  5547 net.cpp:84] Creating Layer M2PELU14
I1001 19:09:22.309854  5547 net.cpp:406] M2PELU14 <- Convolution14
I1001 19:09:22.309857  5547 net.cpp:367] M2PELU14 -> Convolution14 (in-place)
I1001 19:09:22.309970  5547 net.cpp:122] Setting up M2PELU14
I1001 19:09:22.309975  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.309978  5547 net.cpp:137] Memory required for data: 499303600
I1001 19:09:22.309981  5547 layer_factory.hpp:77] Creating layer Convolution15
I1001 19:09:22.309989  5547 net.cpp:84] Creating Layer Convolution15
I1001 19:09:22.309991  5547 net.cpp:406] Convolution15 <- Convolution14
I1001 19:09:22.309996  5547 net.cpp:380] Convolution15 -> Convolution15
I1001 19:09:22.311084  5547 net.cpp:122] Setting up Convolution15
I1001 19:09:22.311094  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.311096  5547 net.cpp:137] Memory required for data: 505857200
I1001 19:09:22.311101  5547 layer_factory.hpp:77] Creating layer BatchNorm15
I1001 19:09:22.311106  5547 net.cpp:84] Creating Layer BatchNorm15
I1001 19:09:22.311108  5547 net.cpp:406] BatchNorm15 <- Convolution15
I1001 19:09:22.311113  5547 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1001 19:09:22.311270  5547 net.cpp:122] Setting up BatchNorm15
I1001 19:09:22.311275  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.311277  5547 net.cpp:137] Memory required for data: 512410800
I1001 19:09:22.311293  5547 layer_factory.hpp:77] Creating layer Scale15
I1001 19:09:22.311297  5547 net.cpp:84] Creating Layer Scale15
I1001 19:09:22.311300  5547 net.cpp:406] Scale15 <- Convolution15
I1001 19:09:22.311305  5547 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1001 19:09:22.311338  5547 layer_factory.hpp:77] Creating layer Scale15
I1001 19:09:22.311436  5547 net.cpp:122] Setting up Scale15
I1001 19:09:22.311440  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.311442  5547 net.cpp:137] Memory required for data: 518964400
I1001 19:09:22.311446  5547 layer_factory.hpp:77] Creating layer Eltwise7
I1001 19:09:22.311451  5547 net.cpp:84] Creating Layer Eltwise7
I1001 19:09:22.311455  5547 net.cpp:406] Eltwise7 <- Eltwise6_M2PELU13_0_split_1
I1001 19:09:22.311457  5547 net.cpp:406] Eltwise7 <- Convolution15
I1001 19:09:22.311460  5547 net.cpp:380] Eltwise7 -> Eltwise7
I1001 19:09:22.311478  5547 net.cpp:122] Setting up Eltwise7
I1001 19:09:22.311482  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.311484  5547 net.cpp:137] Memory required for data: 525518000
I1001 19:09:22.311486  5547 layer_factory.hpp:77] Creating layer M2PELU15
I1001 19:09:22.311501  5547 net.cpp:84] Creating Layer M2PELU15
I1001 19:09:22.311503  5547 net.cpp:406] M2PELU15 <- Eltwise7
I1001 19:09:22.311517  5547 net.cpp:367] M2PELU15 -> Eltwise7 (in-place)
I1001 19:09:22.311625  5547 net.cpp:122] Setting up M2PELU15
I1001 19:09:22.311630  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.311631  5547 net.cpp:137] Memory required for data: 532071600
I1001 19:09:22.311635  5547 layer_factory.hpp:77] Creating layer Eltwise7_M2PELU15_0_split
I1001 19:09:22.311638  5547 net.cpp:84] Creating Layer Eltwise7_M2PELU15_0_split
I1001 19:09:22.311641  5547 net.cpp:406] Eltwise7_M2PELU15_0_split <- Eltwise7
I1001 19:09:22.311645  5547 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_0
I1001 19:09:22.311650  5547 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_1
I1001 19:09:22.311676  5547 net.cpp:122] Setting up Eltwise7_M2PELU15_0_split
I1001 19:09:22.311687  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.311691  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.311693  5547 net.cpp:137] Memory required for data: 545178800
I1001 19:09:22.311695  5547 layer_factory.hpp:77] Creating layer Convolution16
I1001 19:09:22.311702  5547 net.cpp:84] Creating Layer Convolution16
I1001 19:09:22.311704  5547 net.cpp:406] Convolution16 <- Eltwise7_M2PELU15_0_split_0
I1001 19:09:22.311708  5547 net.cpp:380] Convolution16 -> Convolution16
I1001 19:09:22.312423  5547 net.cpp:122] Setting up Convolution16
I1001 19:09:22.312432  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.312434  5547 net.cpp:137] Memory required for data: 551732400
I1001 19:09:22.312438  5547 layer_factory.hpp:77] Creating layer BatchNorm16
I1001 19:09:22.312443  5547 net.cpp:84] Creating Layer BatchNorm16
I1001 19:09:22.312446  5547 net.cpp:406] BatchNorm16 <- Convolution16
I1001 19:09:22.312450  5547 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1001 19:09:22.312611  5547 net.cpp:122] Setting up BatchNorm16
I1001 19:09:22.312616  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.312618  5547 net.cpp:137] Memory required for data: 558286000
I1001 19:09:22.312623  5547 layer_factory.hpp:77] Creating layer Scale16
I1001 19:09:22.312628  5547 net.cpp:84] Creating Layer Scale16
I1001 19:09:22.312629  5547 net.cpp:406] Scale16 <- Convolution16
I1001 19:09:22.312633  5547 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1001 19:09:22.312664  5547 layer_factory.hpp:77] Creating layer Scale16
I1001 19:09:22.312753  5547 net.cpp:122] Setting up Scale16
I1001 19:09:22.312758  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.312762  5547 net.cpp:137] Memory required for data: 564839600
I1001 19:09:22.312765  5547 layer_factory.hpp:77] Creating layer M2PELU16
I1001 19:09:22.312769  5547 net.cpp:84] Creating Layer M2PELU16
I1001 19:09:22.312772  5547 net.cpp:406] M2PELU16 <- Convolution16
I1001 19:09:22.312775  5547 net.cpp:367] M2PELU16 -> Convolution16 (in-place)
I1001 19:09:22.312885  5547 net.cpp:122] Setting up M2PELU16
I1001 19:09:22.312888  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.312891  5547 net.cpp:137] Memory required for data: 571393200
I1001 19:09:22.312894  5547 layer_factory.hpp:77] Creating layer Convolution17
I1001 19:09:22.312901  5547 net.cpp:84] Creating Layer Convolution17
I1001 19:09:22.312904  5547 net.cpp:406] Convolution17 <- Convolution16
I1001 19:09:22.312908  5547 net.cpp:380] Convolution17 -> Convolution17
I1001 19:09:22.313910  5547 net.cpp:122] Setting up Convolution17
I1001 19:09:22.313920  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.313922  5547 net.cpp:137] Memory required for data: 577946800
I1001 19:09:22.313927  5547 layer_factory.hpp:77] Creating layer BatchNorm17
I1001 19:09:22.313932  5547 net.cpp:84] Creating Layer BatchNorm17
I1001 19:09:22.313935  5547 net.cpp:406] BatchNorm17 <- Convolution17
I1001 19:09:22.313938  5547 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1001 19:09:22.314102  5547 net.cpp:122] Setting up BatchNorm17
I1001 19:09:22.314107  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.314110  5547 net.cpp:137] Memory required for data: 584500400
I1001 19:09:22.314115  5547 layer_factory.hpp:77] Creating layer Scale17
I1001 19:09:22.314118  5547 net.cpp:84] Creating Layer Scale17
I1001 19:09:22.314121  5547 net.cpp:406] Scale17 <- Convolution17
I1001 19:09:22.314126  5547 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1001 19:09:22.314157  5547 layer_factory.hpp:77] Creating layer Scale17
I1001 19:09:22.314247  5547 net.cpp:122] Setting up Scale17
I1001 19:09:22.314254  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.314255  5547 net.cpp:137] Memory required for data: 591054000
I1001 19:09:22.314260  5547 layer_factory.hpp:77] Creating layer Eltwise8
I1001 19:09:22.314263  5547 net.cpp:84] Creating Layer Eltwise8
I1001 19:09:22.314266  5547 net.cpp:406] Eltwise8 <- Eltwise7_M2PELU15_0_split_1
I1001 19:09:22.314276  5547 net.cpp:406] Eltwise8 <- Convolution17
I1001 19:09:22.314280  5547 net.cpp:380] Eltwise8 -> Eltwise8
I1001 19:09:22.314301  5547 net.cpp:122] Setting up Eltwise8
I1001 19:09:22.314304  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.314306  5547 net.cpp:137] Memory required for data: 597607600
I1001 19:09:22.314309  5547 layer_factory.hpp:77] Creating layer M2PELU17
I1001 19:09:22.314314  5547 net.cpp:84] Creating Layer M2PELU17
I1001 19:09:22.314316  5547 net.cpp:406] M2PELU17 <- Eltwise8
I1001 19:09:22.314319  5547 net.cpp:367] M2PELU17 -> Eltwise8 (in-place)
I1001 19:09:22.314429  5547 net.cpp:122] Setting up M2PELU17
I1001 19:09:22.314432  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.314435  5547 net.cpp:137] Memory required for data: 604161200
I1001 19:09:22.314438  5547 layer_factory.hpp:77] Creating layer Eltwise8_M2PELU17_0_split
I1001 19:09:22.314441  5547 net.cpp:84] Creating Layer Eltwise8_M2PELU17_0_split
I1001 19:09:22.314445  5547 net.cpp:406] Eltwise8_M2PELU17_0_split <- Eltwise8
I1001 19:09:22.314447  5547 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_0
I1001 19:09:22.314451  5547 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_1
I1001 19:09:22.314479  5547 net.cpp:122] Setting up Eltwise8_M2PELU17_0_split
I1001 19:09:22.314483  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.314486  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.314488  5547 net.cpp:137] Memory required for data: 617268400
I1001 19:09:22.314491  5547 layer_factory.hpp:77] Creating layer Convolution18
I1001 19:09:22.314497  5547 net.cpp:84] Creating Layer Convolution18
I1001 19:09:22.314501  5547 net.cpp:406] Convolution18 <- Eltwise8_M2PELU17_0_split_0
I1001 19:09:22.314504  5547 net.cpp:380] Convolution18 -> Convolution18
I1001 19:09:22.315549  5547 net.cpp:122] Setting up Convolution18
I1001 19:09:22.315558  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.315562  5547 net.cpp:137] Memory required for data: 623822000
I1001 19:09:22.315567  5547 layer_factory.hpp:77] Creating layer BatchNorm18
I1001 19:09:22.315572  5547 net.cpp:84] Creating Layer BatchNorm18
I1001 19:09:22.315574  5547 net.cpp:406] BatchNorm18 <- Convolution18
I1001 19:09:22.315578  5547 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1001 19:09:22.315735  5547 net.cpp:122] Setting up BatchNorm18
I1001 19:09:22.315740  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.315743  5547 net.cpp:137] Memory required for data: 630375600
I1001 19:09:22.315748  5547 layer_factory.hpp:77] Creating layer Scale18
I1001 19:09:22.315752  5547 net.cpp:84] Creating Layer Scale18
I1001 19:09:22.315755  5547 net.cpp:406] Scale18 <- Convolution18
I1001 19:09:22.315758  5547 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1001 19:09:22.315789  5547 layer_factory.hpp:77] Creating layer Scale18
I1001 19:09:22.315879  5547 net.cpp:122] Setting up Scale18
I1001 19:09:22.315884  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.315886  5547 net.cpp:137] Memory required for data: 636929200
I1001 19:09:22.315891  5547 layer_factory.hpp:77] Creating layer M2PELU18
I1001 19:09:22.315896  5547 net.cpp:84] Creating Layer M2PELU18
I1001 19:09:22.315898  5547 net.cpp:406] M2PELU18 <- Convolution18
I1001 19:09:22.315901  5547 net.cpp:367] M2PELU18 -> Convolution18 (in-place)
I1001 19:09:22.316011  5547 net.cpp:122] Setting up M2PELU18
I1001 19:09:22.316015  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.316017  5547 net.cpp:137] Memory required for data: 643482800
I1001 19:09:22.316021  5547 layer_factory.hpp:77] Creating layer Convolution19
I1001 19:09:22.316028  5547 net.cpp:84] Creating Layer Convolution19
I1001 19:09:22.316030  5547 net.cpp:406] Convolution19 <- Convolution18
I1001 19:09:22.316035  5547 net.cpp:380] Convolution19 -> Convolution19
I1001 19:09:22.317025  5547 net.cpp:122] Setting up Convolution19
I1001 19:09:22.317034  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.317044  5547 net.cpp:137] Memory required for data: 650036400
I1001 19:09:22.317049  5547 layer_factory.hpp:77] Creating layer BatchNorm19
I1001 19:09:22.317054  5547 net.cpp:84] Creating Layer BatchNorm19
I1001 19:09:22.317056  5547 net.cpp:406] BatchNorm19 <- Convolution19
I1001 19:09:22.317061  5547 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1001 19:09:22.317227  5547 net.cpp:122] Setting up BatchNorm19
I1001 19:09:22.317232  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.317234  5547 net.cpp:137] Memory required for data: 656590000
I1001 19:09:22.317239  5547 layer_factory.hpp:77] Creating layer Scale19
I1001 19:09:22.317243  5547 net.cpp:84] Creating Layer Scale19
I1001 19:09:22.317245  5547 net.cpp:406] Scale19 <- Convolution19
I1001 19:09:22.317248  5547 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1001 19:09:22.317281  5547 layer_factory.hpp:77] Creating layer Scale19
I1001 19:09:22.317373  5547 net.cpp:122] Setting up Scale19
I1001 19:09:22.317376  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.317379  5547 net.cpp:137] Memory required for data: 663143600
I1001 19:09:22.317384  5547 layer_factory.hpp:77] Creating layer Eltwise9
I1001 19:09:22.317387  5547 net.cpp:84] Creating Layer Eltwise9
I1001 19:09:22.317390  5547 net.cpp:406] Eltwise9 <- Eltwise8_M2PELU17_0_split_1
I1001 19:09:22.317394  5547 net.cpp:406] Eltwise9 <- Convolution19
I1001 19:09:22.317396  5547 net.cpp:380] Eltwise9 -> Eltwise9
I1001 19:09:22.317415  5547 net.cpp:122] Setting up Eltwise9
I1001 19:09:22.317420  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.317421  5547 net.cpp:137] Memory required for data: 669697200
I1001 19:09:22.317423  5547 layer_factory.hpp:77] Creating layer M2PELU19
I1001 19:09:22.317428  5547 net.cpp:84] Creating Layer M2PELU19
I1001 19:09:22.317431  5547 net.cpp:406] M2PELU19 <- Eltwise9
I1001 19:09:22.317435  5547 net.cpp:367] M2PELU19 -> Eltwise9 (in-place)
I1001 19:09:22.317544  5547 net.cpp:122] Setting up M2PELU19
I1001 19:09:22.317549  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.317551  5547 net.cpp:137] Memory required for data: 676250800
I1001 19:09:22.317555  5547 layer_factory.hpp:77] Creating layer Eltwise9_M2PELU19_0_split
I1001 19:09:22.317559  5547 net.cpp:84] Creating Layer Eltwise9_M2PELU19_0_split
I1001 19:09:22.317561  5547 net.cpp:406] Eltwise9_M2PELU19_0_split <- Eltwise9
I1001 19:09:22.317565  5547 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_0
I1001 19:09:22.338732  5547 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_1
I1001 19:09:22.338794  5547 net.cpp:122] Setting up Eltwise9_M2PELU19_0_split
I1001 19:09:22.338804  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.338809  5547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 19:09:22.338814  5547 net.cpp:137] Memory required for data: 689358000
I1001 19:09:22.338819  5547 layer_factory.hpp:77] Creating layer Convolution20
I1001 19:09:22.338829  5547 net.cpp:84] Creating Layer Convolution20
I1001 19:09:22.338834  5547 net.cpp:406] Convolution20 <- Eltwise9_M2PELU19_0_split_0
I1001 19:09:22.338841  5547 net.cpp:380] Convolution20 -> Convolution20
I1001 19:09:22.339871  5547 net.cpp:122] Setting up Convolution20
I1001 19:09:22.339880  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.339884  5547 net.cpp:137] Memory required for data: 692634800
I1001 19:09:22.339887  5547 layer_factory.hpp:77] Creating layer BatchNorm20
I1001 19:09:22.339893  5547 net.cpp:84] Creating Layer BatchNorm20
I1001 19:09:22.339895  5547 net.cpp:406] BatchNorm20 <- Convolution20
I1001 19:09:22.339900  5547 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1001 19:09:22.340108  5547 net.cpp:122] Setting up BatchNorm20
I1001 19:09:22.340113  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.340116  5547 net.cpp:137] Memory required for data: 695911600
I1001 19:09:22.340121  5547 layer_factory.hpp:77] Creating layer Scale20
I1001 19:09:22.340132  5547 net.cpp:84] Creating Layer Scale20
I1001 19:09:22.340135  5547 net.cpp:406] Scale20 <- Convolution20
I1001 19:09:22.340139  5547 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1001 19:09:22.340173  5547 layer_factory.hpp:77] Creating layer Scale20
I1001 19:09:22.340266  5547 net.cpp:122] Setting up Scale20
I1001 19:09:22.340270  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.340273  5547 net.cpp:137] Memory required for data: 699188400
I1001 19:09:22.340277  5547 layer_factory.hpp:77] Creating layer Convolution21
I1001 19:09:22.340284  5547 net.cpp:84] Creating Layer Convolution21
I1001 19:09:22.340286  5547 net.cpp:406] Convolution21 <- Eltwise9_M2PELU19_0_split_1
I1001 19:09:22.340301  5547 net.cpp:380] Convolution21 -> Convolution21
I1001 19:09:22.341424  5547 net.cpp:122] Setting up Convolution21
I1001 19:09:22.341434  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.341437  5547 net.cpp:137] Memory required for data: 702465200
I1001 19:09:22.341442  5547 layer_factory.hpp:77] Creating layer BatchNorm21
I1001 19:09:22.341446  5547 net.cpp:84] Creating Layer BatchNorm21
I1001 19:09:22.341449  5547 net.cpp:406] BatchNorm21 <- Convolution21
I1001 19:09:22.341454  5547 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1001 19:09:22.341609  5547 net.cpp:122] Setting up BatchNorm21
I1001 19:09:22.341614  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.341616  5547 net.cpp:137] Memory required for data: 705742000
I1001 19:09:22.341621  5547 layer_factory.hpp:77] Creating layer Scale21
I1001 19:09:22.341625  5547 net.cpp:84] Creating Layer Scale21
I1001 19:09:22.341627  5547 net.cpp:406] Scale21 <- Convolution21
I1001 19:09:22.341630  5547 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1001 19:09:22.341662  5547 layer_factory.hpp:77] Creating layer Scale21
I1001 19:09:22.341749  5547 net.cpp:122] Setting up Scale21
I1001 19:09:22.341753  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.341755  5547 net.cpp:137] Memory required for data: 709018800
I1001 19:09:22.341759  5547 layer_factory.hpp:77] Creating layer M2PELU20
I1001 19:09:22.341764  5547 net.cpp:84] Creating Layer M2PELU20
I1001 19:09:22.341766  5547 net.cpp:406] M2PELU20 <- Convolution21
I1001 19:09:22.341770  5547 net.cpp:367] M2PELU20 -> Convolution21 (in-place)
I1001 19:09:22.341868  5547 net.cpp:122] Setting up M2PELU20
I1001 19:09:22.341873  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.341876  5547 net.cpp:137] Memory required for data: 712295600
I1001 19:09:22.341879  5547 layer_factory.hpp:77] Creating layer Convolution22
I1001 19:09:22.341886  5547 net.cpp:84] Creating Layer Convolution22
I1001 19:09:22.341888  5547 net.cpp:406] Convolution22 <- Convolution21
I1001 19:09:22.341892  5547 net.cpp:380] Convolution22 -> Convolution22
I1001 19:09:22.343062  5547 net.cpp:122] Setting up Convolution22
I1001 19:09:22.343072  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.343075  5547 net.cpp:137] Memory required for data: 715572400
I1001 19:09:22.343080  5547 layer_factory.hpp:77] Creating layer BatchNorm22
I1001 19:09:22.343085  5547 net.cpp:84] Creating Layer BatchNorm22
I1001 19:09:22.343087  5547 net.cpp:406] BatchNorm22 <- Convolution22
I1001 19:09:22.343091  5547 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1001 19:09:22.343247  5547 net.cpp:122] Setting up BatchNorm22
I1001 19:09:22.343251  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.343255  5547 net.cpp:137] Memory required for data: 718849200
I1001 19:09:22.343260  5547 layer_factory.hpp:77] Creating layer Scale22
I1001 19:09:22.343263  5547 net.cpp:84] Creating Layer Scale22
I1001 19:09:22.343266  5547 net.cpp:406] Scale22 <- Convolution22
I1001 19:09:22.343268  5547 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1001 19:09:22.343299  5547 layer_factory.hpp:77] Creating layer Scale22
I1001 19:09:22.343390  5547 net.cpp:122] Setting up Scale22
I1001 19:09:22.343394  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.343403  5547 net.cpp:137] Memory required for data: 722126000
I1001 19:09:22.343407  5547 layer_factory.hpp:77] Creating layer Eltwise10
I1001 19:09:22.343412  5547 net.cpp:84] Creating Layer Eltwise10
I1001 19:09:22.343415  5547 net.cpp:406] Eltwise10 <- Convolution20
I1001 19:09:22.343417  5547 net.cpp:406] Eltwise10 <- Convolution22
I1001 19:09:22.343421  5547 net.cpp:380] Eltwise10 -> Eltwise10
I1001 19:09:22.343437  5547 net.cpp:122] Setting up Eltwise10
I1001 19:09:22.343441  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.343443  5547 net.cpp:137] Memory required for data: 725402800
I1001 19:09:22.343446  5547 layer_factory.hpp:77] Creating layer M2PELU21
I1001 19:09:22.343451  5547 net.cpp:84] Creating Layer M2PELU21
I1001 19:09:22.343453  5547 net.cpp:406] M2PELU21 <- Eltwise10
I1001 19:09:22.343457  5547 net.cpp:367] M2PELU21 -> Eltwise10 (in-place)
I1001 19:09:22.343559  5547 net.cpp:122] Setting up M2PELU21
I1001 19:09:22.343564  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.343565  5547 net.cpp:137] Memory required for data: 728679600
I1001 19:09:22.343569  5547 layer_factory.hpp:77] Creating layer Eltwise10_M2PELU21_0_split
I1001 19:09:22.343574  5547 net.cpp:84] Creating Layer Eltwise10_M2PELU21_0_split
I1001 19:09:22.343575  5547 net.cpp:406] Eltwise10_M2PELU21_0_split <- Eltwise10
I1001 19:09:22.343580  5547 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_0
I1001 19:09:22.343583  5547 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_1
I1001 19:09:22.343611  5547 net.cpp:122] Setting up Eltwise10_M2PELU21_0_split
I1001 19:09:22.343614  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.343617  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.343619  5547 net.cpp:137] Memory required for data: 735233200
I1001 19:09:22.343621  5547 layer_factory.hpp:77] Creating layer Convolution23
I1001 19:09:22.343628  5547 net.cpp:84] Creating Layer Convolution23
I1001 19:09:22.343631  5547 net.cpp:406] Convolution23 <- Eltwise10_M2PELU21_0_split_0
I1001 19:09:22.343634  5547 net.cpp:380] Convolution23 -> Convolution23
I1001 19:09:22.344763  5547 net.cpp:122] Setting up Convolution23
I1001 19:09:22.344772  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.344775  5547 net.cpp:137] Memory required for data: 738510000
I1001 19:09:22.344780  5547 layer_factory.hpp:77] Creating layer BatchNorm23
I1001 19:09:22.344785  5547 net.cpp:84] Creating Layer BatchNorm23
I1001 19:09:22.344787  5547 net.cpp:406] BatchNorm23 <- Convolution23
I1001 19:09:22.344792  5547 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1001 19:09:22.344949  5547 net.cpp:122] Setting up BatchNorm23
I1001 19:09:22.344954  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.344955  5547 net.cpp:137] Memory required for data: 741786800
I1001 19:09:22.344960  5547 layer_factory.hpp:77] Creating layer Scale23
I1001 19:09:22.344964  5547 net.cpp:84] Creating Layer Scale23
I1001 19:09:22.344967  5547 net.cpp:406] Scale23 <- Convolution23
I1001 19:09:22.344970  5547 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1001 19:09:22.345001  5547 layer_factory.hpp:77] Creating layer Scale23
I1001 19:09:22.345090  5547 net.cpp:122] Setting up Scale23
I1001 19:09:22.345095  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.345098  5547 net.cpp:137] Memory required for data: 745063600
I1001 19:09:22.345101  5547 layer_factory.hpp:77] Creating layer M2PELU22
I1001 19:09:22.345106  5547 net.cpp:84] Creating Layer M2PELU22
I1001 19:09:22.345109  5547 net.cpp:406] M2PELU22 <- Convolution23
I1001 19:09:22.345113  5547 net.cpp:367] M2PELU22 -> Convolution23 (in-place)
I1001 19:09:22.345209  5547 net.cpp:122] Setting up M2PELU22
I1001 19:09:22.345216  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.345217  5547 net.cpp:137] Memory required for data: 748340400
I1001 19:09:22.345221  5547 layer_factory.hpp:77] Creating layer Convolution24
I1001 19:09:22.345227  5547 net.cpp:84] Creating Layer Convolution24
I1001 19:09:22.345235  5547 net.cpp:406] Convolution24 <- Convolution23
I1001 19:09:22.345240  5547 net.cpp:380] Convolution24 -> Convolution24
I1001 19:09:22.346379  5547 net.cpp:122] Setting up Convolution24
I1001 19:09:22.346386  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.346390  5547 net.cpp:137] Memory required for data: 751617200
I1001 19:09:22.346395  5547 layer_factory.hpp:77] Creating layer BatchNorm24
I1001 19:09:22.346400  5547 net.cpp:84] Creating Layer BatchNorm24
I1001 19:09:22.346402  5547 net.cpp:406] BatchNorm24 <- Convolution24
I1001 19:09:22.346405  5547 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1001 19:09:22.347076  5547 net.cpp:122] Setting up BatchNorm24
I1001 19:09:22.347085  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.347087  5547 net.cpp:137] Memory required for data: 754894000
I1001 19:09:22.347093  5547 layer_factory.hpp:77] Creating layer Scale24
I1001 19:09:22.347097  5547 net.cpp:84] Creating Layer Scale24
I1001 19:09:22.347100  5547 net.cpp:406] Scale24 <- Convolution24
I1001 19:09:22.347103  5547 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1001 19:09:22.347132  5547 layer_factory.hpp:77] Creating layer Scale24
I1001 19:09:22.347203  5547 net.cpp:122] Setting up Scale24
I1001 19:09:22.347208  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.347209  5547 net.cpp:137] Memory required for data: 758170800
I1001 19:09:22.347213  5547 layer_factory.hpp:77] Creating layer Eltwise11
I1001 19:09:22.347218  5547 net.cpp:84] Creating Layer Eltwise11
I1001 19:09:22.347220  5547 net.cpp:406] Eltwise11 <- Eltwise10_M2PELU21_0_split_1
I1001 19:09:22.347223  5547 net.cpp:406] Eltwise11 <- Convolution24
I1001 19:09:22.347226  5547 net.cpp:380] Eltwise11 -> Eltwise11
I1001 19:09:22.347237  5547 net.cpp:122] Setting up Eltwise11
I1001 19:09:22.347241  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.347244  5547 net.cpp:137] Memory required for data: 761447600
I1001 19:09:22.347245  5547 layer_factory.hpp:77] Creating layer M2PELU23
I1001 19:09:22.347250  5547 net.cpp:84] Creating Layer M2PELU23
I1001 19:09:22.347252  5547 net.cpp:406] M2PELU23 <- Eltwise11
I1001 19:09:22.347255  5547 net.cpp:367] M2PELU23 -> Eltwise11 (in-place)
I1001 19:09:22.347337  5547 net.cpp:122] Setting up M2PELU23
I1001 19:09:22.347342  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.347344  5547 net.cpp:137] Memory required for data: 764724400
I1001 19:09:22.347347  5547 layer_factory.hpp:77] Creating layer Eltwise11_M2PELU23_0_split
I1001 19:09:22.347352  5547 net.cpp:84] Creating Layer Eltwise11_M2PELU23_0_split
I1001 19:09:22.347354  5547 net.cpp:406] Eltwise11_M2PELU23_0_split <- Eltwise11
I1001 19:09:22.347357  5547 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_0
I1001 19:09:22.347362  5547 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_1
I1001 19:09:22.347383  5547 net.cpp:122] Setting up Eltwise11_M2PELU23_0_split
I1001 19:09:22.347388  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.347390  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.347393  5547 net.cpp:137] Memory required for data: 771278000
I1001 19:09:22.347394  5547 layer_factory.hpp:77] Creating layer Convolution25
I1001 19:09:22.347403  5547 net.cpp:84] Creating Layer Convolution25
I1001 19:09:22.347405  5547 net.cpp:406] Convolution25 <- Eltwise11_M2PELU23_0_split_0
I1001 19:09:22.347409  5547 net.cpp:380] Convolution25 -> Convolution25
I1001 19:09:22.348516  5547 net.cpp:122] Setting up Convolution25
I1001 19:09:22.348526  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.348528  5547 net.cpp:137] Memory required for data: 774554800
I1001 19:09:22.348532  5547 layer_factory.hpp:77] Creating layer BatchNorm25
I1001 19:09:22.348537  5547 net.cpp:84] Creating Layer BatchNorm25
I1001 19:09:22.348541  5547 net.cpp:406] BatchNorm25 <- Convolution25
I1001 19:09:22.348546  5547 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1001 19:09:22.348677  5547 net.cpp:122] Setting up BatchNorm25
I1001 19:09:22.348682  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.348685  5547 net.cpp:137] Memory required for data: 777831600
I1001 19:09:22.348690  5547 layer_factory.hpp:77] Creating layer Scale25
I1001 19:09:22.348693  5547 net.cpp:84] Creating Layer Scale25
I1001 19:09:22.348696  5547 net.cpp:406] Scale25 <- Convolution25
I1001 19:09:22.348701  5547 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1001 19:09:22.348726  5547 layer_factory.hpp:77] Creating layer Scale25
I1001 19:09:22.348798  5547 net.cpp:122] Setting up Scale25
I1001 19:09:22.348801  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.348803  5547 net.cpp:137] Memory required for data: 781108400
I1001 19:09:22.348808  5547 layer_factory.hpp:77] Creating layer M2PELU24
I1001 19:09:22.348811  5547 net.cpp:84] Creating Layer M2PELU24
I1001 19:09:22.348814  5547 net.cpp:406] M2PELU24 <- Convolution25
I1001 19:09:22.348817  5547 net.cpp:367] M2PELU24 -> Convolution25 (in-place)
I1001 19:09:22.348898  5547 net.cpp:122] Setting up M2PELU24
I1001 19:09:22.348902  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.348904  5547 net.cpp:137] Memory required for data: 784385200
I1001 19:09:22.348907  5547 layer_factory.hpp:77] Creating layer Convolution26
I1001 19:09:22.348915  5547 net.cpp:84] Creating Layer Convolution26
I1001 19:09:22.348917  5547 net.cpp:406] Convolution26 <- Convolution25
I1001 19:09:22.348922  5547 net.cpp:380] Convolution26 -> Convolution26
I1001 19:09:22.349678  5547 net.cpp:122] Setting up Convolution26
I1001 19:09:22.349685  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.349689  5547 net.cpp:137] Memory required for data: 787662000
I1001 19:09:22.349692  5547 layer_factory.hpp:77] Creating layer BatchNorm26
I1001 19:09:22.349696  5547 net.cpp:84] Creating Layer BatchNorm26
I1001 19:09:22.349699  5547 net.cpp:406] BatchNorm26 <- Convolution26
I1001 19:09:22.349704  5547 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1001 19:09:22.349828  5547 net.cpp:122] Setting up BatchNorm26
I1001 19:09:22.349831  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.349833  5547 net.cpp:137] Memory required for data: 790938800
I1001 19:09:22.349838  5547 layer_factory.hpp:77] Creating layer Scale26
I1001 19:09:22.349843  5547 net.cpp:84] Creating Layer Scale26
I1001 19:09:22.369673  5547 net.cpp:406] Scale26 <- Convolution26
I1001 19:09:22.369685  5547 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1001 19:09:22.369727  5547 layer_factory.hpp:77] Creating layer Scale26
I1001 19:09:22.369810  5547 net.cpp:122] Setting up Scale26
I1001 19:09:22.369815  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.369818  5547 net.cpp:137] Memory required for data: 794215600
I1001 19:09:22.369822  5547 layer_factory.hpp:77] Creating layer Eltwise12
I1001 19:09:22.369827  5547 net.cpp:84] Creating Layer Eltwise12
I1001 19:09:22.369830  5547 net.cpp:406] Eltwise12 <- Eltwise11_M2PELU23_0_split_1
I1001 19:09:22.369834  5547 net.cpp:406] Eltwise12 <- Convolution26
I1001 19:09:22.369837  5547 net.cpp:380] Eltwise12 -> Eltwise12
I1001 19:09:22.369849  5547 net.cpp:122] Setting up Eltwise12
I1001 19:09:22.369853  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.369855  5547 net.cpp:137] Memory required for data: 797492400
I1001 19:09:22.369858  5547 layer_factory.hpp:77] Creating layer M2PELU25
I1001 19:09:22.369873  5547 net.cpp:84] Creating Layer M2PELU25
I1001 19:09:22.369875  5547 net.cpp:406] M2PELU25 <- Eltwise12
I1001 19:09:22.369879  5547 net.cpp:367] M2PELU25 -> Eltwise12 (in-place)
I1001 19:09:22.369971  5547 net.cpp:122] Setting up M2PELU25
I1001 19:09:22.369976  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.369978  5547 net.cpp:137] Memory required for data: 800769200
I1001 19:09:22.369982  5547 layer_factory.hpp:77] Creating layer Eltwise12_M2PELU25_0_split
I1001 19:09:22.369987  5547 net.cpp:84] Creating Layer Eltwise12_M2PELU25_0_split
I1001 19:09:22.369998  5547 net.cpp:406] Eltwise12_M2PELU25_0_split <- Eltwise12
I1001 19:09:22.370002  5547 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_0
I1001 19:09:22.370007  5547 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_1
I1001 19:09:22.370034  5547 net.cpp:122] Setting up Eltwise12_M2PELU25_0_split
I1001 19:09:22.370038  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.370043  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.370044  5547 net.cpp:137] Memory required for data: 807322800
I1001 19:09:22.370046  5547 layer_factory.hpp:77] Creating layer Convolution27
I1001 19:09:22.370054  5547 net.cpp:84] Creating Layer Convolution27
I1001 19:09:22.370055  5547 net.cpp:406] Convolution27 <- Eltwise12_M2PELU25_0_split_0
I1001 19:09:22.370060  5547 net.cpp:380] Convolution27 -> Convolution27
I1001 19:09:22.371671  5547 net.cpp:122] Setting up Convolution27
I1001 19:09:22.371682  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.371685  5547 net.cpp:137] Memory required for data: 810599600
I1001 19:09:22.371690  5547 layer_factory.hpp:77] Creating layer BatchNorm27
I1001 19:09:22.371695  5547 net.cpp:84] Creating Layer BatchNorm27
I1001 19:09:22.371698  5547 net.cpp:406] BatchNorm27 <- Convolution27
I1001 19:09:22.371702  5547 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1001 19:09:22.371829  5547 net.cpp:122] Setting up BatchNorm27
I1001 19:09:22.371834  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.371836  5547 net.cpp:137] Memory required for data: 813876400
I1001 19:09:22.371840  5547 layer_factory.hpp:77] Creating layer Scale27
I1001 19:09:22.371845  5547 net.cpp:84] Creating Layer Scale27
I1001 19:09:22.371847  5547 net.cpp:406] Scale27 <- Convolution27
I1001 19:09:22.371851  5547 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1001 19:09:22.371876  5547 layer_factory.hpp:77] Creating layer Scale27
I1001 19:09:22.371948  5547 net.cpp:122] Setting up Scale27
I1001 19:09:22.371953  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.371954  5547 net.cpp:137] Memory required for data: 817153200
I1001 19:09:22.371958  5547 layer_factory.hpp:77] Creating layer M2PELU26
I1001 19:09:22.371963  5547 net.cpp:84] Creating Layer M2PELU26
I1001 19:09:22.371965  5547 net.cpp:406] M2PELU26 <- Convolution27
I1001 19:09:22.371969  5547 net.cpp:367] M2PELU26 -> Convolution27 (in-place)
I1001 19:09:22.372050  5547 net.cpp:122] Setting up M2PELU26
I1001 19:09:22.372053  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.372056  5547 net.cpp:137] Memory required for data: 820430000
I1001 19:09:22.372058  5547 layer_factory.hpp:77] Creating layer Convolution28
I1001 19:09:22.372066  5547 net.cpp:84] Creating Layer Convolution28
I1001 19:09:22.372068  5547 net.cpp:406] Convolution28 <- Convolution27
I1001 19:09:22.372072  5547 net.cpp:380] Convolution28 -> Convolution28
I1001 19:09:22.373546  5547 net.cpp:122] Setting up Convolution28
I1001 19:09:22.373554  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.373558  5547 net.cpp:137] Memory required for data: 823706800
I1001 19:09:22.373564  5547 layer_factory.hpp:77] Creating layer BatchNorm28
I1001 19:09:22.373567  5547 net.cpp:84] Creating Layer BatchNorm28
I1001 19:09:22.373570  5547 net.cpp:406] BatchNorm28 <- Convolution28
I1001 19:09:22.373574  5547 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1001 19:09:22.373698  5547 net.cpp:122] Setting up BatchNorm28
I1001 19:09:22.373703  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.373705  5547 net.cpp:137] Memory required for data: 826983600
I1001 19:09:22.373710  5547 layer_factory.hpp:77] Creating layer Scale28
I1001 19:09:22.373714  5547 net.cpp:84] Creating Layer Scale28
I1001 19:09:22.373716  5547 net.cpp:406] Scale28 <- Convolution28
I1001 19:09:22.373719  5547 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1001 19:09:22.373745  5547 layer_factory.hpp:77] Creating layer Scale28
I1001 19:09:22.373872  5547 net.cpp:122] Setting up Scale28
I1001 19:09:22.373891  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.373905  5547 net.cpp:137] Memory required for data: 830260400
I1001 19:09:22.373913  5547 layer_factory.hpp:77] Creating layer Eltwise13
I1001 19:09:22.373919  5547 net.cpp:84] Creating Layer Eltwise13
I1001 19:09:22.373924  5547 net.cpp:406] Eltwise13 <- Eltwise12_M2PELU25_0_split_1
I1001 19:09:22.373929  5547 net.cpp:406] Eltwise13 <- Convolution28
I1001 19:09:22.373935  5547 net.cpp:380] Eltwise13 -> Eltwise13
I1001 19:09:22.373955  5547 net.cpp:122] Setting up Eltwise13
I1001 19:09:22.373963  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.373966  5547 net.cpp:137] Memory required for data: 833537200
I1001 19:09:22.373970  5547 layer_factory.hpp:77] Creating layer M2PELU27
I1001 19:09:22.373975  5547 net.cpp:84] Creating Layer M2PELU27
I1001 19:09:22.373977  5547 net.cpp:406] M2PELU27 <- Eltwise13
I1001 19:09:22.373980  5547 net.cpp:367] M2PELU27 -> Eltwise13 (in-place)
I1001 19:09:22.374068  5547 net.cpp:122] Setting up M2PELU27
I1001 19:09:22.374073  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.374074  5547 net.cpp:137] Memory required for data: 836814000
I1001 19:09:22.374078  5547 layer_factory.hpp:77] Creating layer Eltwise13_M2PELU27_0_split
I1001 19:09:22.374083  5547 net.cpp:84] Creating Layer Eltwise13_M2PELU27_0_split
I1001 19:09:22.374084  5547 net.cpp:406] Eltwise13_M2PELU27_0_split <- Eltwise13
I1001 19:09:22.374089  5547 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_0
I1001 19:09:22.374092  5547 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_1
I1001 19:09:22.374115  5547 net.cpp:122] Setting up Eltwise13_M2PELU27_0_split
I1001 19:09:22.374119  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.374122  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.374125  5547 net.cpp:137] Memory required for data: 843367600
I1001 19:09:22.374126  5547 layer_factory.hpp:77] Creating layer Convolution29
I1001 19:09:22.374132  5547 net.cpp:84] Creating Layer Convolution29
I1001 19:09:22.374135  5547 net.cpp:406] Convolution29 <- Eltwise13_M2PELU27_0_split_0
I1001 19:09:22.374140  5547 net.cpp:380] Convolution29 -> Convolution29
I1001 19:09:22.375237  5547 net.cpp:122] Setting up Convolution29
I1001 19:09:22.375247  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.375250  5547 net.cpp:137] Memory required for data: 846644400
I1001 19:09:22.375254  5547 layer_factory.hpp:77] Creating layer BatchNorm29
I1001 19:09:22.375262  5547 net.cpp:84] Creating Layer BatchNorm29
I1001 19:09:22.375263  5547 net.cpp:406] BatchNorm29 <- Convolution29
I1001 19:09:22.375267  5547 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1001 19:09:22.375391  5547 net.cpp:122] Setting up BatchNorm29
I1001 19:09:22.375396  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.375398  5547 net.cpp:137] Memory required for data: 849921200
I1001 19:09:22.375402  5547 layer_factory.hpp:77] Creating layer Scale29
I1001 19:09:22.375407  5547 net.cpp:84] Creating Layer Scale29
I1001 19:09:22.375409  5547 net.cpp:406] Scale29 <- Convolution29
I1001 19:09:22.375412  5547 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1001 19:09:22.375437  5547 layer_factory.hpp:77] Creating layer Scale29
I1001 19:09:22.375509  5547 net.cpp:122] Setting up Scale29
I1001 19:09:22.375512  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.375514  5547 net.cpp:137] Memory required for data: 853198000
I1001 19:09:22.375537  5547 layer_factory.hpp:77] Creating layer M2PELU28
I1001 19:09:22.375543  5547 net.cpp:84] Creating Layer M2PELU28
I1001 19:09:22.375546  5547 net.cpp:406] M2PELU28 <- Convolution29
I1001 19:09:22.375550  5547 net.cpp:367] M2PELU28 -> Convolution29 (in-place)
I1001 19:09:22.375632  5547 net.cpp:122] Setting up M2PELU28
I1001 19:09:22.375635  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.375638  5547 net.cpp:137] Memory required for data: 856474800
I1001 19:09:22.375641  5547 layer_factory.hpp:77] Creating layer Convolution30
I1001 19:09:22.375654  5547 net.cpp:84] Creating Layer Convolution30
I1001 19:09:22.375658  5547 net.cpp:406] Convolution30 <- Convolution29
I1001 19:09:22.375661  5547 net.cpp:380] Convolution30 -> Convolution30
I1001 19:09:22.376731  5547 net.cpp:122] Setting up Convolution30
I1001 19:09:22.376739  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.376742  5547 net.cpp:137] Memory required for data: 859751600
I1001 19:09:22.376746  5547 layer_factory.hpp:77] Creating layer BatchNorm30
I1001 19:09:22.376752  5547 net.cpp:84] Creating Layer BatchNorm30
I1001 19:09:22.376754  5547 net.cpp:406] BatchNorm30 <- Convolution30
I1001 19:09:22.376758  5547 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1001 19:09:22.376883  5547 net.cpp:122] Setting up BatchNorm30
I1001 19:09:22.376888  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.376889  5547 net.cpp:137] Memory required for data: 863028400
I1001 19:09:22.376894  5547 layer_factory.hpp:77] Creating layer Scale30
I1001 19:09:22.376899  5547 net.cpp:84] Creating Layer Scale30
I1001 19:09:22.376901  5547 net.cpp:406] Scale30 <- Convolution30
I1001 19:09:22.376904  5547 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1001 19:09:22.376929  5547 layer_factory.hpp:77] Creating layer Scale30
I1001 19:09:22.376997  5547 net.cpp:122] Setting up Scale30
I1001 19:09:22.377002  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.377004  5547 net.cpp:137] Memory required for data: 866305200
I1001 19:09:22.377008  5547 layer_factory.hpp:77] Creating layer Eltwise14
I1001 19:09:22.377012  5547 net.cpp:84] Creating Layer Eltwise14
I1001 19:09:22.377014  5547 net.cpp:406] Eltwise14 <- Eltwise13_M2PELU27_0_split_1
I1001 19:09:22.377017  5547 net.cpp:406] Eltwise14 <- Convolution30
I1001 19:09:22.377020  5547 net.cpp:380] Eltwise14 -> Eltwise14
I1001 19:09:22.377032  5547 net.cpp:122] Setting up Eltwise14
I1001 19:09:22.377035  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.377038  5547 net.cpp:137] Memory required for data: 869582000
I1001 19:09:22.377040  5547 layer_factory.hpp:77] Creating layer M2PELU29
I1001 19:09:22.377044  5547 net.cpp:84] Creating Layer M2PELU29
I1001 19:09:22.377048  5547 net.cpp:406] M2PELU29 <- Eltwise14
I1001 19:09:22.377050  5547 net.cpp:367] M2PELU29 -> Eltwise14 (in-place)
I1001 19:09:22.377133  5547 net.cpp:122] Setting up M2PELU29
I1001 19:09:22.377137  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.377140  5547 net.cpp:137] Memory required for data: 872858800
I1001 19:09:22.377143  5547 layer_factory.hpp:77] Creating layer Eltwise14_M2PELU29_0_split
I1001 19:09:22.377146  5547 net.cpp:84] Creating Layer Eltwise14_M2PELU29_0_split
I1001 19:09:22.377148  5547 net.cpp:406] Eltwise14_M2PELU29_0_split <- Eltwise14
I1001 19:09:22.377151  5547 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_0
I1001 19:09:22.377156  5547 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_1
I1001 19:09:22.377178  5547 net.cpp:122] Setting up Eltwise14_M2PELU29_0_split
I1001 19:09:22.377182  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.377184  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.377187  5547 net.cpp:137] Memory required for data: 879412400
I1001 19:09:22.377188  5547 layer_factory.hpp:77] Creating layer Convolution31
I1001 19:09:22.377195  5547 net.cpp:84] Creating Layer Convolution31
I1001 19:09:22.377197  5547 net.cpp:406] Convolution31 <- Eltwise14_M2PELU29_0_split_0
I1001 19:09:22.377202  5547 net.cpp:380] Convolution31 -> Convolution31
I1001 19:09:22.378267  5547 net.cpp:122] Setting up Convolution31
I1001 19:09:22.378275  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.378278  5547 net.cpp:137] Memory required for data: 882689200
I1001 19:09:22.378283  5547 layer_factory.hpp:77] Creating layer BatchNorm31
I1001 19:09:22.378288  5547 net.cpp:84] Creating Layer BatchNorm31
I1001 19:09:22.378290  5547 net.cpp:406] BatchNorm31 <- Convolution31
I1001 19:09:22.378300  5547 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1001 19:09:22.378420  5547 net.cpp:122] Setting up BatchNorm31
I1001 19:09:22.378425  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.378427  5547 net.cpp:137] Memory required for data: 885966000
I1001 19:09:22.378432  5547 layer_factory.hpp:77] Creating layer Scale31
I1001 19:09:22.378435  5547 net.cpp:84] Creating Layer Scale31
I1001 19:09:22.378438  5547 net.cpp:406] Scale31 <- Convolution31
I1001 19:09:22.378443  5547 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1001 19:09:22.378466  5547 layer_factory.hpp:77] Creating layer Scale31
I1001 19:09:22.378554  5547 net.cpp:122] Setting up Scale31
I1001 19:09:22.378569  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.378571  5547 net.cpp:137] Memory required for data: 889242800
I1001 19:09:22.378584  5547 layer_factory.hpp:77] Creating layer M2PELU30
I1001 19:09:22.378589  5547 net.cpp:84] Creating Layer M2PELU30
I1001 19:09:22.378592  5547 net.cpp:406] M2PELU30 <- Convolution31
I1001 19:09:22.378595  5547 net.cpp:367] M2PELU30 -> Convolution31 (in-place)
I1001 19:09:22.378674  5547 net.cpp:122] Setting up M2PELU30
I1001 19:09:22.378677  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.378679  5547 net.cpp:137] Memory required for data: 892519600
I1001 19:09:22.378684  5547 layer_factory.hpp:77] Creating layer Convolution32
I1001 19:09:22.378690  5547 net.cpp:84] Creating Layer Convolution32
I1001 19:09:22.378692  5547 net.cpp:406] Convolution32 <- Convolution31
I1001 19:09:22.378696  5547 net.cpp:380] Convolution32 -> Convolution32
I1001 19:09:22.379761  5547 net.cpp:122] Setting up Convolution32
I1001 19:09:22.379770  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.379772  5547 net.cpp:137] Memory required for data: 895796400
I1001 19:09:22.379777  5547 layer_factory.hpp:77] Creating layer BatchNorm32
I1001 19:09:22.379782  5547 net.cpp:84] Creating Layer BatchNorm32
I1001 19:09:22.379786  5547 net.cpp:406] BatchNorm32 <- Convolution32
I1001 19:09:22.379788  5547 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1001 19:09:22.379909  5547 net.cpp:122] Setting up BatchNorm32
I1001 19:09:22.379914  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.399814  5547 net.cpp:137] Memory required for data: 899073200
I1001 19:09:22.399827  5547 layer_factory.hpp:77] Creating layer Scale32
I1001 19:09:22.399835  5547 net.cpp:84] Creating Layer Scale32
I1001 19:09:22.399840  5547 net.cpp:406] Scale32 <- Convolution32
I1001 19:09:22.399847  5547 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1001 19:09:22.399888  5547 layer_factory.hpp:77] Creating layer Scale32
I1001 19:09:22.400001  5547 net.cpp:122] Setting up Scale32
I1001 19:09:22.400009  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.400012  5547 net.cpp:137] Memory required for data: 902350000
I1001 19:09:22.400017  5547 layer_factory.hpp:77] Creating layer Eltwise15
I1001 19:09:22.400022  5547 net.cpp:84] Creating Layer Eltwise15
I1001 19:09:22.400025  5547 net.cpp:406] Eltwise15 <- Eltwise14_M2PELU29_0_split_1
I1001 19:09:22.400028  5547 net.cpp:406] Eltwise15 <- Convolution32
I1001 19:09:22.400032  5547 net.cpp:380] Eltwise15 -> Eltwise15
I1001 19:09:22.400045  5547 net.cpp:122] Setting up Eltwise15
I1001 19:09:22.400049  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.400051  5547 net.cpp:137] Memory required for data: 905626800
I1001 19:09:22.400054  5547 layer_factory.hpp:77] Creating layer M2PELU31
I1001 19:09:22.400059  5547 net.cpp:84] Creating Layer M2PELU31
I1001 19:09:22.400063  5547 net.cpp:406] M2PELU31 <- Eltwise15
I1001 19:09:22.400066  5547 net.cpp:367] M2PELU31 -> Eltwise15 (in-place)
I1001 19:09:22.400159  5547 net.cpp:122] Setting up M2PELU31
I1001 19:09:22.400164  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.400166  5547 net.cpp:137] Memory required for data: 908903600
I1001 19:09:22.400171  5547 layer_factory.hpp:77] Creating layer Eltwise15_M2PELU31_0_split
I1001 19:09:22.400177  5547 net.cpp:84] Creating Layer Eltwise15_M2PELU31_0_split
I1001 19:09:22.400187  5547 net.cpp:406] Eltwise15_M2PELU31_0_split <- Eltwise15
I1001 19:09:22.400190  5547 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_0
I1001 19:09:22.400195  5547 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_1
I1001 19:09:22.400223  5547 net.cpp:122] Setting up Eltwise15_M2PELU31_0_split
I1001 19:09:22.400226  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.400229  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.400233  5547 net.cpp:137] Memory required for data: 915457200
I1001 19:09:22.400234  5547 layer_factory.hpp:77] Creating layer Convolution33
I1001 19:09:22.400241  5547 net.cpp:84] Creating Layer Convolution33
I1001 19:09:22.400244  5547 net.cpp:406] Convolution33 <- Eltwise15_M2PELU31_0_split_0
I1001 19:09:22.400249  5547 net.cpp:380] Convolution33 -> Convolution33
I1001 19:09:22.401465  5547 net.cpp:122] Setting up Convolution33
I1001 19:09:22.401475  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.401479  5547 net.cpp:137] Memory required for data: 918734000
I1001 19:09:22.401484  5547 layer_factory.hpp:77] Creating layer BatchNorm33
I1001 19:09:22.401489  5547 net.cpp:84] Creating Layer BatchNorm33
I1001 19:09:22.401492  5547 net.cpp:406] BatchNorm33 <- Convolution33
I1001 19:09:22.401496  5547 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1001 19:09:22.401640  5547 net.cpp:122] Setting up BatchNorm33
I1001 19:09:22.401645  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.401648  5547 net.cpp:137] Memory required for data: 922010800
I1001 19:09:22.401652  5547 layer_factory.hpp:77] Creating layer Scale33
I1001 19:09:22.401656  5547 net.cpp:84] Creating Layer Scale33
I1001 19:09:22.401659  5547 net.cpp:406] Scale33 <- Convolution33
I1001 19:09:22.401661  5547 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1001 19:09:22.401690  5547 layer_factory.hpp:77] Creating layer Scale33
I1001 19:09:22.401762  5547 net.cpp:122] Setting up Scale33
I1001 19:09:22.401765  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.401767  5547 net.cpp:137] Memory required for data: 925287600
I1001 19:09:22.401772  5547 layer_factory.hpp:77] Creating layer M2PELU32
I1001 19:09:22.401777  5547 net.cpp:84] Creating Layer M2PELU32
I1001 19:09:22.401779  5547 net.cpp:406] M2PELU32 <- Convolution33
I1001 19:09:22.401783  5547 net.cpp:367] M2PELU32 -> Convolution33 (in-place)
I1001 19:09:22.401877  5547 net.cpp:122] Setting up M2PELU32
I1001 19:09:22.401881  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.401883  5547 net.cpp:137] Memory required for data: 928564400
I1001 19:09:22.401887  5547 layer_factory.hpp:77] Creating layer Convolution34
I1001 19:09:22.401895  5547 net.cpp:84] Creating Layer Convolution34
I1001 19:09:22.401896  5547 net.cpp:406] Convolution34 <- Convolution33
I1001 19:09:22.401901  5547 net.cpp:380] Convolution34 -> Convolution34
I1001 19:09:22.403728  5547 net.cpp:122] Setting up Convolution34
I1001 19:09:22.403738  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.403741  5547 net.cpp:137] Memory required for data: 931841200
I1001 19:09:22.403746  5547 layer_factory.hpp:77] Creating layer BatchNorm34
I1001 19:09:22.403753  5547 net.cpp:84] Creating Layer BatchNorm34
I1001 19:09:22.403756  5547 net.cpp:406] BatchNorm34 <- Convolution34
I1001 19:09:22.403760  5547 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I1001 19:09:22.403887  5547 net.cpp:122] Setting up BatchNorm34
I1001 19:09:22.403892  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.403893  5547 net.cpp:137] Memory required for data: 935118000
I1001 19:09:22.403898  5547 layer_factory.hpp:77] Creating layer Scale34
I1001 19:09:22.403903  5547 net.cpp:84] Creating Layer Scale34
I1001 19:09:22.403906  5547 net.cpp:406] Scale34 <- Convolution34
I1001 19:09:22.403909  5547 net.cpp:367] Scale34 -> Convolution34 (in-place)
I1001 19:09:22.403936  5547 layer_factory.hpp:77] Creating layer Scale34
I1001 19:09:22.404022  5547 net.cpp:122] Setting up Scale34
I1001 19:09:22.404027  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.404029  5547 net.cpp:137] Memory required for data: 938394800
I1001 19:09:22.404033  5547 layer_factory.hpp:77] Creating layer Eltwise16
I1001 19:09:22.404039  5547 net.cpp:84] Creating Layer Eltwise16
I1001 19:09:22.404043  5547 net.cpp:406] Eltwise16 <- Eltwise15_M2PELU31_0_split_1
I1001 19:09:22.404047  5547 net.cpp:406] Eltwise16 <- Convolution34
I1001 19:09:22.404049  5547 net.cpp:380] Eltwise16 -> Eltwise16
I1001 19:09:22.404062  5547 net.cpp:122] Setting up Eltwise16
I1001 19:09:22.404067  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.404068  5547 net.cpp:137] Memory required for data: 941671600
I1001 19:09:22.404070  5547 layer_factory.hpp:77] Creating layer M2PELU33
I1001 19:09:22.404075  5547 net.cpp:84] Creating Layer M2PELU33
I1001 19:09:22.404078  5547 net.cpp:406] M2PELU33 <- Eltwise16
I1001 19:09:22.404081  5547 net.cpp:367] M2PELU33 -> Eltwise16 (in-place)
I1001 19:09:22.404165  5547 net.cpp:122] Setting up M2PELU33
I1001 19:09:22.404170  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.404171  5547 net.cpp:137] Memory required for data: 944948400
I1001 19:09:22.404175  5547 layer_factory.hpp:77] Creating layer Eltwise16_M2PELU33_0_split
I1001 19:09:22.404180  5547 net.cpp:84] Creating Layer Eltwise16_M2PELU33_0_split
I1001 19:09:22.404181  5547 net.cpp:406] Eltwise16_M2PELU33_0_split <- Eltwise16
I1001 19:09:22.404186  5547 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_0
I1001 19:09:22.404189  5547 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_1
I1001 19:09:22.404212  5547 net.cpp:122] Setting up Eltwise16_M2PELU33_0_split
I1001 19:09:22.404217  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.404219  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.404222  5547 net.cpp:137] Memory required for data: 951502000
I1001 19:09:22.404223  5547 layer_factory.hpp:77] Creating layer Convolution35
I1001 19:09:22.404232  5547 net.cpp:84] Creating Layer Convolution35
I1001 19:09:22.404234  5547 net.cpp:406] Convolution35 <- Eltwise16_M2PELU33_0_split_0
I1001 19:09:22.404238  5547 net.cpp:380] Convolution35 -> Convolution35
I1001 19:09:22.405351  5547 net.cpp:122] Setting up Convolution35
I1001 19:09:22.405360  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.405364  5547 net.cpp:137] Memory required for data: 954778800
I1001 19:09:22.405367  5547 layer_factory.hpp:77] Creating layer BatchNorm35
I1001 19:09:22.405372  5547 net.cpp:84] Creating Layer BatchNorm35
I1001 19:09:22.405375  5547 net.cpp:406] BatchNorm35 <- Convolution35
I1001 19:09:22.405380  5547 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I1001 19:09:22.405508  5547 net.cpp:122] Setting up BatchNorm35
I1001 19:09:22.405513  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.405514  5547 net.cpp:137] Memory required for data: 958055600
I1001 19:09:22.405519  5547 layer_factory.hpp:77] Creating layer Scale35
I1001 19:09:22.405524  5547 net.cpp:84] Creating Layer Scale35
I1001 19:09:22.405526  5547 net.cpp:406] Scale35 <- Convolution35
I1001 19:09:22.405529  5547 net.cpp:367] Scale35 -> Convolution35 (in-place)
I1001 19:09:22.405556  5547 layer_factory.hpp:77] Creating layer Scale35
I1001 19:09:22.405630  5547 net.cpp:122] Setting up Scale35
I1001 19:09:22.405634  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.405637  5547 net.cpp:137] Memory required for data: 961332400
I1001 19:09:22.405640  5547 layer_factory.hpp:77] Creating layer M2PELU34
I1001 19:09:22.405645  5547 net.cpp:84] Creating Layer M2PELU34
I1001 19:09:22.405648  5547 net.cpp:406] M2PELU34 <- Convolution35
I1001 19:09:22.405652  5547 net.cpp:367] M2PELU34 -> Convolution35 (in-place)
I1001 19:09:22.405731  5547 net.cpp:122] Setting up M2PELU34
I1001 19:09:22.405735  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.405737  5547 net.cpp:137] Memory required for data: 964609200
I1001 19:09:22.405746  5547 layer_factory.hpp:77] Creating layer Convolution36
I1001 19:09:22.405755  5547 net.cpp:84] Creating Layer Convolution36
I1001 19:09:22.405757  5547 net.cpp:406] Convolution36 <- Convolution35
I1001 19:09:22.405761  5547 net.cpp:380] Convolution36 -> Convolution36
I1001 19:09:22.406538  5547 net.cpp:122] Setting up Convolution36
I1001 19:09:22.406548  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.406549  5547 net.cpp:137] Memory required for data: 967886000
I1001 19:09:22.406554  5547 layer_factory.hpp:77] Creating layer BatchNorm36
I1001 19:09:22.406559  5547 net.cpp:84] Creating Layer BatchNorm36
I1001 19:09:22.406563  5547 net.cpp:406] BatchNorm36 <- Convolution36
I1001 19:09:22.406575  5547 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I1001 19:09:22.406703  5547 net.cpp:122] Setting up BatchNorm36
I1001 19:09:22.406708  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.406710  5547 net.cpp:137] Memory required for data: 971162800
I1001 19:09:22.406714  5547 layer_factory.hpp:77] Creating layer Scale36
I1001 19:09:22.406718  5547 net.cpp:84] Creating Layer Scale36
I1001 19:09:22.406720  5547 net.cpp:406] Scale36 <- Convolution36
I1001 19:09:22.406723  5547 net.cpp:367] Scale36 -> Convolution36 (in-place)
I1001 19:09:22.406750  5547 layer_factory.hpp:77] Creating layer Scale36
I1001 19:09:22.406823  5547 net.cpp:122] Setting up Scale36
I1001 19:09:22.406828  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.406831  5547 net.cpp:137] Memory required for data: 974439600
I1001 19:09:22.406834  5547 layer_factory.hpp:77] Creating layer Eltwise17
I1001 19:09:22.406838  5547 net.cpp:84] Creating Layer Eltwise17
I1001 19:09:22.406841  5547 net.cpp:406] Eltwise17 <- Eltwise16_M2PELU33_0_split_1
I1001 19:09:22.406844  5547 net.cpp:406] Eltwise17 <- Convolution36
I1001 19:09:22.406847  5547 net.cpp:380] Eltwise17 -> Eltwise17
I1001 19:09:22.406858  5547 net.cpp:122] Setting up Eltwise17
I1001 19:09:22.406862  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.406864  5547 net.cpp:137] Memory required for data: 977716400
I1001 19:09:22.406867  5547 layer_factory.hpp:77] Creating layer M2PELU35
I1001 19:09:22.406872  5547 net.cpp:84] Creating Layer M2PELU35
I1001 19:09:22.406874  5547 net.cpp:406] M2PELU35 <- Eltwise17
I1001 19:09:22.406877  5547 net.cpp:367] M2PELU35 -> Eltwise17 (in-place)
I1001 19:09:22.406966  5547 net.cpp:122] Setting up M2PELU35
I1001 19:09:22.406970  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.406972  5547 net.cpp:137] Memory required for data: 980993200
I1001 19:09:22.406976  5547 layer_factory.hpp:77] Creating layer Eltwise17_M2PELU35_0_split
I1001 19:09:22.406980  5547 net.cpp:84] Creating Layer Eltwise17_M2PELU35_0_split
I1001 19:09:22.406982  5547 net.cpp:406] Eltwise17_M2PELU35_0_split <- Eltwise17
I1001 19:09:22.406986  5547 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_0
I1001 19:09:22.406991  5547 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_1
I1001 19:09:22.407023  5547 net.cpp:122] Setting up Eltwise17_M2PELU35_0_split
I1001 19:09:22.407027  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.407030  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.407032  5547 net.cpp:137] Memory required for data: 987546800
I1001 19:09:22.407034  5547 layer_factory.hpp:77] Creating layer Convolution37
I1001 19:09:22.407040  5547 net.cpp:84] Creating Layer Convolution37
I1001 19:09:22.407052  5547 net.cpp:406] Convolution37 <- Eltwise17_M2PELU35_0_split_0
I1001 19:09:22.407057  5547 net.cpp:380] Convolution37 -> Convolution37
I1001 19:09:22.408223  5547 net.cpp:122] Setting up Convolution37
I1001 19:09:22.408232  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.408236  5547 net.cpp:137] Memory required for data: 990823600
I1001 19:09:22.408239  5547 layer_factory.hpp:77] Creating layer BatchNorm37
I1001 19:09:22.408244  5547 net.cpp:84] Creating Layer BatchNorm37
I1001 19:09:22.408253  5547 net.cpp:406] BatchNorm37 <- Convolution37
I1001 19:09:22.408258  5547 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I1001 19:09:22.408390  5547 net.cpp:122] Setting up BatchNorm37
I1001 19:09:22.408396  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.408397  5547 net.cpp:137] Memory required for data: 994100400
I1001 19:09:22.408402  5547 layer_factory.hpp:77] Creating layer Scale37
I1001 19:09:22.408406  5547 net.cpp:84] Creating Layer Scale37
I1001 19:09:22.408408  5547 net.cpp:406] Scale37 <- Convolution37
I1001 19:09:22.408411  5547 net.cpp:367] Scale37 -> Convolution37 (in-place)
I1001 19:09:22.408438  5547 layer_factory.hpp:77] Creating layer Scale37
I1001 19:09:22.408514  5547 net.cpp:122] Setting up Scale37
I1001 19:09:22.408517  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.408519  5547 net.cpp:137] Memory required for data: 997377200
I1001 19:09:22.408524  5547 layer_factory.hpp:77] Creating layer M2PELU36
I1001 19:09:22.408529  5547 net.cpp:84] Creating Layer M2PELU36
I1001 19:09:22.408531  5547 net.cpp:406] M2PELU36 <- Convolution37
I1001 19:09:22.408535  5547 net.cpp:367] M2PELU36 -> Convolution37 (in-place)
I1001 19:09:22.408617  5547 net.cpp:122] Setting up M2PELU36
I1001 19:09:22.408620  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.408622  5547 net.cpp:137] Memory required for data: 1000654000
I1001 19:09:22.408627  5547 layer_factory.hpp:77] Creating layer Convolution38
I1001 19:09:22.408632  5547 net.cpp:84] Creating Layer Convolution38
I1001 19:09:22.408634  5547 net.cpp:406] Convolution38 <- Convolution37
I1001 19:09:22.408638  5547 net.cpp:380] Convolution38 -> Convolution38
I1001 19:09:22.410516  5547 net.cpp:122] Setting up Convolution38
I1001 19:09:22.410547  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.410552  5547 net.cpp:137] Memory required for data: 1003930800
I1001 19:09:22.410571  5547 layer_factory.hpp:77] Creating layer BatchNorm38
I1001 19:09:22.410579  5547 net.cpp:84] Creating Layer BatchNorm38
I1001 19:09:22.410584  5547 net.cpp:406] BatchNorm38 <- Convolution38
I1001 19:09:22.430215  5547 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I1001 19:09:22.430378  5547 net.cpp:122] Setting up BatchNorm38
I1001 19:09:22.430384  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.430387  5547 net.cpp:137] Memory required for data: 1007207600
I1001 19:09:22.430392  5547 layer_factory.hpp:77] Creating layer Scale38
I1001 19:09:22.430398  5547 net.cpp:84] Creating Layer Scale38
I1001 19:09:22.430402  5547 net.cpp:406] Scale38 <- Convolution38
I1001 19:09:22.430405  5547 net.cpp:367] Scale38 -> Convolution38 (in-place)
I1001 19:09:22.430435  5547 layer_factory.hpp:77] Creating layer Scale38
I1001 19:09:22.430528  5547 net.cpp:122] Setting up Scale38
I1001 19:09:22.430533  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.430536  5547 net.cpp:137] Memory required for data: 1010484400
I1001 19:09:22.430541  5547 layer_factory.hpp:77] Creating layer Eltwise18
I1001 19:09:22.430544  5547 net.cpp:84] Creating Layer Eltwise18
I1001 19:09:22.430548  5547 net.cpp:406] Eltwise18 <- Eltwise17_M2PELU35_0_split_1
I1001 19:09:22.430554  5547 net.cpp:406] Eltwise18 <- Convolution38
I1001 19:09:22.430558  5547 net.cpp:380] Eltwise18 -> Eltwise18
I1001 19:09:22.430572  5547 net.cpp:122] Setting up Eltwise18
I1001 19:09:22.430577  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.430580  5547 net.cpp:137] Memory required for data: 1013761200
I1001 19:09:22.430583  5547 layer_factory.hpp:77] Creating layer M2PELU37
I1001 19:09:22.430588  5547 net.cpp:84] Creating Layer M2PELU37
I1001 19:09:22.430589  5547 net.cpp:406] M2PELU37 <- Eltwise18
I1001 19:09:22.430594  5547 net.cpp:367] M2PELU37 -> Eltwise18 (in-place)
I1001 19:09:22.430690  5547 net.cpp:122] Setting up M2PELU37
I1001 19:09:22.430693  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.430696  5547 net.cpp:137] Memory required for data: 1017038000
I1001 19:09:22.430701  5547 layer_factory.hpp:77] Creating layer Eltwise18_M2PELU37_0_split
I1001 19:09:22.430711  5547 net.cpp:84] Creating Layer Eltwise18_M2PELU37_0_split
I1001 19:09:22.430714  5547 net.cpp:406] Eltwise18_M2PELU37_0_split <- Eltwise18
I1001 19:09:22.430719  5547 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_0
I1001 19:09:22.430723  5547 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_1
I1001 19:09:22.430750  5547 net.cpp:122] Setting up Eltwise18_M2PELU37_0_split
I1001 19:09:22.430754  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.430757  5547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 19:09:22.430760  5547 net.cpp:137] Memory required for data: 1023591600
I1001 19:09:22.430763  5547 layer_factory.hpp:77] Creating layer Convolution39
I1001 19:09:22.430769  5547 net.cpp:84] Creating Layer Convolution39
I1001 19:09:22.430773  5547 net.cpp:406] Convolution39 <- Eltwise18_M2PELU37_0_split_0
I1001 19:09:22.430776  5547 net.cpp:380] Convolution39 -> Convolution39
I1001 19:09:22.431919  5547 net.cpp:122] Setting up Convolution39
I1001 19:09:22.431929  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.431931  5547 net.cpp:137] Memory required for data: 1025230000
I1001 19:09:22.431936  5547 layer_factory.hpp:77] Creating layer BatchNorm39
I1001 19:09:22.431942  5547 net.cpp:84] Creating Layer BatchNorm39
I1001 19:09:22.431946  5547 net.cpp:406] BatchNorm39 <- Convolution39
I1001 19:09:22.431949  5547 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I1001 19:09:22.432092  5547 net.cpp:122] Setting up BatchNorm39
I1001 19:09:22.432096  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.432098  5547 net.cpp:137] Memory required for data: 1026868400
I1001 19:09:22.432103  5547 layer_factory.hpp:77] Creating layer Scale39
I1001 19:09:22.432107  5547 net.cpp:84] Creating Layer Scale39
I1001 19:09:22.432111  5547 net.cpp:406] Scale39 <- Convolution39
I1001 19:09:22.432113  5547 net.cpp:367] Scale39 -> Convolution39 (in-place)
I1001 19:09:22.432142  5547 layer_factory.hpp:77] Creating layer Scale39
I1001 19:09:22.432216  5547 net.cpp:122] Setting up Scale39
I1001 19:09:22.432220  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.432224  5547 net.cpp:137] Memory required for data: 1028506800
I1001 19:09:22.432226  5547 layer_factory.hpp:77] Creating layer Convolution40
I1001 19:09:22.432234  5547 net.cpp:84] Creating Layer Convolution40
I1001 19:09:22.432236  5547 net.cpp:406] Convolution40 <- Eltwise18_M2PELU37_0_split_1
I1001 19:09:22.432241  5547 net.cpp:380] Convolution40 -> Convolution40
I1001 19:09:22.433670  5547 net.cpp:122] Setting up Convolution40
I1001 19:09:22.433689  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.433692  5547 net.cpp:137] Memory required for data: 1030145200
I1001 19:09:22.433706  5547 layer_factory.hpp:77] Creating layer BatchNorm40
I1001 19:09:22.433710  5547 net.cpp:84] Creating Layer BatchNorm40
I1001 19:09:22.433713  5547 net.cpp:406] BatchNorm40 <- Convolution40
I1001 19:09:22.433717  5547 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I1001 19:09:22.433848  5547 net.cpp:122] Setting up BatchNorm40
I1001 19:09:22.433852  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.433854  5547 net.cpp:137] Memory required for data: 1031783600
I1001 19:09:22.433859  5547 layer_factory.hpp:77] Creating layer Scale40
I1001 19:09:22.433863  5547 net.cpp:84] Creating Layer Scale40
I1001 19:09:22.433866  5547 net.cpp:406] Scale40 <- Convolution40
I1001 19:09:22.433868  5547 net.cpp:367] Scale40 -> Convolution40 (in-place)
I1001 19:09:22.433895  5547 layer_factory.hpp:77] Creating layer Scale40
I1001 19:09:22.434007  5547 net.cpp:122] Setting up Scale40
I1001 19:09:22.434026  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.434028  5547 net.cpp:137] Memory required for data: 1033422000
I1001 19:09:22.434041  5547 layer_factory.hpp:77] Creating layer M2PELU38
I1001 19:09:22.434046  5547 net.cpp:84] Creating Layer M2PELU38
I1001 19:09:22.434047  5547 net.cpp:406] M2PELU38 <- Convolution40
I1001 19:09:22.434068  5547 net.cpp:367] M2PELU38 -> Convolution40 (in-place)
I1001 19:09:22.434171  5547 net.cpp:122] Setting up M2PELU38
I1001 19:09:22.434175  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.434177  5547 net.cpp:137] Memory required for data: 1035060400
I1001 19:09:22.434180  5547 layer_factory.hpp:77] Creating layer Convolution41
I1001 19:09:22.434188  5547 net.cpp:84] Creating Layer Convolution41
I1001 19:09:22.434191  5547 net.cpp:406] Convolution41 <- Convolution40
I1001 19:09:22.434195  5547 net.cpp:380] Convolution41 -> Convolution41
I1001 19:09:22.435935  5547 net.cpp:122] Setting up Convolution41
I1001 19:09:22.435943  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.435946  5547 net.cpp:137] Memory required for data: 1036698800
I1001 19:09:22.435950  5547 layer_factory.hpp:77] Creating layer BatchNorm41
I1001 19:09:22.435956  5547 net.cpp:84] Creating Layer BatchNorm41
I1001 19:09:22.435958  5547 net.cpp:406] BatchNorm41 <- Convolution41
I1001 19:09:22.435963  5547 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I1001 19:09:22.436092  5547 net.cpp:122] Setting up BatchNorm41
I1001 19:09:22.436096  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.436098  5547 net.cpp:137] Memory required for data: 1038337200
I1001 19:09:22.436103  5547 layer_factory.hpp:77] Creating layer Scale41
I1001 19:09:22.436108  5547 net.cpp:84] Creating Layer Scale41
I1001 19:09:22.436110  5547 net.cpp:406] Scale41 <- Convolution41
I1001 19:09:22.436113  5547 net.cpp:367] Scale41 -> Convolution41 (in-place)
I1001 19:09:22.436139  5547 layer_factory.hpp:77] Creating layer Scale41
I1001 19:09:22.436214  5547 net.cpp:122] Setting up Scale41
I1001 19:09:22.436218  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.436220  5547 net.cpp:137] Memory required for data: 1039975600
I1001 19:09:22.436224  5547 layer_factory.hpp:77] Creating layer Eltwise19
I1001 19:09:22.436228  5547 net.cpp:84] Creating Layer Eltwise19
I1001 19:09:22.436231  5547 net.cpp:406] Eltwise19 <- Convolution39
I1001 19:09:22.436234  5547 net.cpp:406] Eltwise19 <- Convolution41
I1001 19:09:22.436239  5547 net.cpp:380] Eltwise19 -> Eltwise19
I1001 19:09:22.436254  5547 net.cpp:122] Setting up Eltwise19
I1001 19:09:22.436256  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.436259  5547 net.cpp:137] Memory required for data: 1041614000
I1001 19:09:22.436260  5547 layer_factory.hpp:77] Creating layer M2PELU39
I1001 19:09:22.436265  5547 net.cpp:84] Creating Layer M2PELU39
I1001 19:09:22.436269  5547 net.cpp:406] M2PELU39 <- Eltwise19
I1001 19:09:22.436271  5547 net.cpp:367] M2PELU39 -> Eltwise19 (in-place)
I1001 19:09:22.436365  5547 net.cpp:122] Setting up M2PELU39
I1001 19:09:22.436373  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.436377  5547 net.cpp:137] Memory required for data: 1043252400
I1001 19:09:22.436383  5547 layer_factory.hpp:77] Creating layer Eltwise19_M2PELU39_0_split
I1001 19:09:22.436388  5547 net.cpp:84] Creating Layer Eltwise19_M2PELU39_0_split
I1001 19:09:22.436393  5547 net.cpp:406] Eltwise19_M2PELU39_0_split <- Eltwise19
I1001 19:09:22.436399  5547 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_0
I1001 19:09:22.436406  5547 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_1
I1001 19:09:22.436439  5547 net.cpp:122] Setting up Eltwise19_M2PELU39_0_split
I1001 19:09:22.436444  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.436446  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.436449  5547 net.cpp:137] Memory required for data: 1046529200
I1001 19:09:22.436450  5547 layer_factory.hpp:77] Creating layer Convolution42
I1001 19:09:22.436458  5547 net.cpp:84] Creating Layer Convolution42
I1001 19:09:22.436461  5547 net.cpp:406] Convolution42 <- Eltwise19_M2PELU39_0_split_0
I1001 19:09:22.436465  5547 net.cpp:380] Convolution42 -> Convolution42
I1001 19:09:22.438150  5547 net.cpp:122] Setting up Convolution42
I1001 19:09:22.438158  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.438169  5547 net.cpp:137] Memory required for data: 1048167600
I1001 19:09:22.438174  5547 layer_factory.hpp:77] Creating layer BatchNorm42
I1001 19:09:22.438179  5547 net.cpp:84] Creating Layer BatchNorm42
I1001 19:09:22.438181  5547 net.cpp:406] BatchNorm42 <- Convolution42
I1001 19:09:22.438185  5547 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I1001 19:09:22.438316  5547 net.cpp:122] Setting up BatchNorm42
I1001 19:09:22.438320  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.438323  5547 net.cpp:137] Memory required for data: 1049806000
I1001 19:09:22.438328  5547 layer_factory.hpp:77] Creating layer Scale42
I1001 19:09:22.438331  5547 net.cpp:84] Creating Layer Scale42
I1001 19:09:22.438333  5547 net.cpp:406] Scale42 <- Convolution42
I1001 19:09:22.438336  5547 net.cpp:367] Scale42 -> Convolution42 (in-place)
I1001 19:09:22.438364  5547 layer_factory.hpp:77] Creating layer Scale42
I1001 19:09:22.438438  5547 net.cpp:122] Setting up Scale42
I1001 19:09:22.438442  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.438444  5547 net.cpp:137] Memory required for data: 1051444400
I1001 19:09:22.438448  5547 layer_factory.hpp:77] Creating layer M2PELU40
I1001 19:09:22.438452  5547 net.cpp:84] Creating Layer M2PELU40
I1001 19:09:22.438454  5547 net.cpp:406] M2PELU40 <- Convolution42
I1001 19:09:22.438458  5547 net.cpp:367] M2PELU40 -> Convolution42 (in-place)
I1001 19:09:22.438549  5547 net.cpp:122] Setting up M2PELU40
I1001 19:09:22.438555  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.438556  5547 net.cpp:137] Memory required for data: 1053082800
I1001 19:09:22.438560  5547 layer_factory.hpp:77] Creating layer Convolution43
I1001 19:09:22.438567  5547 net.cpp:84] Creating Layer Convolution43
I1001 19:09:22.438570  5547 net.cpp:406] Convolution43 <- Convolution42
I1001 19:09:22.438573  5547 net.cpp:380] Convolution43 -> Convolution43
I1001 19:09:22.440251  5547 net.cpp:122] Setting up Convolution43
I1001 19:09:22.440260  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.440263  5547 net.cpp:137] Memory required for data: 1054721200
I1001 19:09:22.440268  5547 layer_factory.hpp:77] Creating layer BatchNorm43
I1001 19:09:22.440274  5547 net.cpp:84] Creating Layer BatchNorm43
I1001 19:09:22.440275  5547 net.cpp:406] BatchNorm43 <- Convolution43
I1001 19:09:22.440280  5547 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I1001 19:09:22.440410  5547 net.cpp:122] Setting up BatchNorm43
I1001 19:09:22.440414  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.440418  5547 net.cpp:137] Memory required for data: 1056359600
I1001 19:09:22.440421  5547 layer_factory.hpp:77] Creating layer Scale43
I1001 19:09:22.440426  5547 net.cpp:84] Creating Layer Scale43
I1001 19:09:22.440428  5547 net.cpp:406] Scale43 <- Convolution43
I1001 19:09:22.440431  5547 net.cpp:367] Scale43 -> Convolution43 (in-place)
I1001 19:09:22.440457  5547 layer_factory.hpp:77] Creating layer Scale43
I1001 19:09:22.440531  5547 net.cpp:122] Setting up Scale43
I1001 19:09:22.440536  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.440537  5547 net.cpp:137] Memory required for data: 1057998000
I1001 19:09:22.440541  5547 layer_factory.hpp:77] Creating layer Eltwise20
I1001 19:09:22.440548  5547 net.cpp:84] Creating Layer Eltwise20
I1001 19:09:22.440551  5547 net.cpp:406] Eltwise20 <- Eltwise19_M2PELU39_0_split_1
I1001 19:09:22.440553  5547 net.cpp:406] Eltwise20 <- Convolution43
I1001 19:09:22.440557  5547 net.cpp:380] Eltwise20 -> Eltwise20
I1001 19:09:22.440572  5547 net.cpp:122] Setting up Eltwise20
I1001 19:09:22.440577  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.440578  5547 net.cpp:137] Memory required for data: 1059636400
I1001 19:09:22.440580  5547 layer_factory.hpp:77] Creating layer M2PELU41
I1001 19:09:22.440585  5547 net.cpp:84] Creating Layer M2PELU41
I1001 19:09:22.440588  5547 net.cpp:406] M2PELU41 <- Eltwise20
I1001 19:09:22.440592  5547 net.cpp:367] M2PELU41 -> Eltwise20 (in-place)
I1001 19:09:22.440687  5547 net.cpp:122] Setting up M2PELU41
I1001 19:09:22.440691  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.440693  5547 net.cpp:137] Memory required for data: 1061274800
I1001 19:09:22.440697  5547 layer_factory.hpp:77] Creating layer Eltwise20_M2PELU41_0_split
I1001 19:09:22.440701  5547 net.cpp:84] Creating Layer Eltwise20_M2PELU41_0_split
I1001 19:09:22.440703  5547 net.cpp:406] Eltwise20_M2PELU41_0_split <- Eltwise20
I1001 19:09:22.440707  5547 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_0
I1001 19:09:22.440711  5547 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_1
I1001 19:09:22.440734  5547 net.cpp:122] Setting up Eltwise20_M2PELU41_0_split
I1001 19:09:22.440737  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.440740  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.440742  5547 net.cpp:137] Memory required for data: 1064551600
I1001 19:09:22.440744  5547 layer_factory.hpp:77] Creating layer Convolution44
I1001 19:09:22.440750  5547 net.cpp:84] Creating Layer Convolution44
I1001 19:09:22.440753  5547 net.cpp:406] Convolution44 <- Eltwise20_M2PELU41_0_split_0
I1001 19:09:22.440757  5547 net.cpp:380] Convolution44 -> Convolution44
I1001 19:09:22.442781  5547 net.cpp:122] Setting up Convolution44
I1001 19:09:22.442790  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.442792  5547 net.cpp:137] Memory required for data: 1066190000
I1001 19:09:22.442797  5547 layer_factory.hpp:77] Creating layer BatchNorm44
I1001 19:09:22.442802  5547 net.cpp:84] Creating Layer BatchNorm44
I1001 19:09:22.442806  5547 net.cpp:406] BatchNorm44 <- Convolution44
I1001 19:09:22.442808  5547 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I1001 19:09:22.442945  5547 net.cpp:122] Setting up BatchNorm44
I1001 19:09:22.442950  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.442952  5547 net.cpp:137] Memory required for data: 1067828400
I1001 19:09:22.460767  5547 layer_factory.hpp:77] Creating layer Scale44
I1001 19:09:22.460779  5547 net.cpp:84] Creating Layer Scale44
I1001 19:09:22.460784  5547 net.cpp:406] Scale44 <- Convolution44
I1001 19:09:22.460790  5547 net.cpp:367] Scale44 -> Convolution44 (in-place)
I1001 19:09:22.460835  5547 layer_factory.hpp:77] Creating layer Scale44
I1001 19:09:22.460927  5547 net.cpp:122] Setting up Scale44
I1001 19:09:22.460932  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.460934  5547 net.cpp:137] Memory required for data: 1069466800
I1001 19:09:22.460939  5547 layer_factory.hpp:77] Creating layer M2PELU42
I1001 19:09:22.460944  5547 net.cpp:84] Creating Layer M2PELU42
I1001 19:09:22.460947  5547 net.cpp:406] M2PELU42 <- Convolution44
I1001 19:09:22.460952  5547 net.cpp:367] M2PELU42 -> Convolution44 (in-place)
I1001 19:09:22.461050  5547 net.cpp:122] Setting up M2PELU42
I1001 19:09:22.461053  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.461056  5547 net.cpp:137] Memory required for data: 1071105200
I1001 19:09:22.461061  5547 layer_factory.hpp:77] Creating layer Convolution45
I1001 19:09:22.461067  5547 net.cpp:84] Creating Layer Convolution45
I1001 19:09:22.461071  5547 net.cpp:406] Convolution45 <- Convolution44
I1001 19:09:22.461076  5547 net.cpp:380] Convolution45 -> Convolution45
I1001 19:09:22.463064  5547 net.cpp:122] Setting up Convolution45
I1001 19:09:22.463075  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.463079  5547 net.cpp:137] Memory required for data: 1072743600
I1001 19:09:22.463086  5547 layer_factory.hpp:77] Creating layer BatchNorm45
I1001 19:09:22.463091  5547 net.cpp:84] Creating Layer BatchNorm45
I1001 19:09:22.463104  5547 net.cpp:406] BatchNorm45 <- Convolution45
I1001 19:09:22.463114  5547 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I1001 19:09:22.463264  5547 net.cpp:122] Setting up BatchNorm45
I1001 19:09:22.463269  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.463273  5547 net.cpp:137] Memory required for data: 1074382000
I1001 19:09:22.463284  5547 layer_factory.hpp:77] Creating layer Scale45
I1001 19:09:22.463289  5547 net.cpp:84] Creating Layer Scale45
I1001 19:09:22.463291  5547 net.cpp:406] Scale45 <- Convolution45
I1001 19:09:22.463295  5547 net.cpp:367] Scale45 -> Convolution45 (in-place)
I1001 19:09:22.463325  5547 layer_factory.hpp:77] Creating layer Scale45
I1001 19:09:22.463402  5547 net.cpp:122] Setting up Scale45
I1001 19:09:22.463405  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.463408  5547 net.cpp:137] Memory required for data: 1076020400
I1001 19:09:22.463412  5547 layer_factory.hpp:77] Creating layer Eltwise21
I1001 19:09:22.463415  5547 net.cpp:84] Creating Layer Eltwise21
I1001 19:09:22.463418  5547 net.cpp:406] Eltwise21 <- Eltwise20_M2PELU41_0_split_1
I1001 19:09:22.463421  5547 net.cpp:406] Eltwise21 <- Convolution45
I1001 19:09:22.463425  5547 net.cpp:380] Eltwise21 -> Eltwise21
I1001 19:09:22.463441  5547 net.cpp:122] Setting up Eltwise21
I1001 19:09:22.463445  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.463448  5547 net.cpp:137] Memory required for data: 1077658800
I1001 19:09:22.463450  5547 layer_factory.hpp:77] Creating layer M2PELU43
I1001 19:09:22.463454  5547 net.cpp:84] Creating Layer M2PELU43
I1001 19:09:22.463456  5547 net.cpp:406] M2PELU43 <- Eltwise21
I1001 19:09:22.463460  5547 net.cpp:367] M2PELU43 -> Eltwise21 (in-place)
I1001 19:09:22.463552  5547 net.cpp:122] Setting up M2PELU43
I1001 19:09:22.463557  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.463558  5547 net.cpp:137] Memory required for data: 1079297200
I1001 19:09:22.463562  5547 layer_factory.hpp:77] Creating layer Eltwise21_M2PELU43_0_split
I1001 19:09:22.463567  5547 net.cpp:84] Creating Layer Eltwise21_M2PELU43_0_split
I1001 19:09:22.463568  5547 net.cpp:406] Eltwise21_M2PELU43_0_split <- Eltwise21
I1001 19:09:22.463572  5547 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_0
I1001 19:09:22.463577  5547 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_1
I1001 19:09:22.463600  5547 net.cpp:122] Setting up Eltwise21_M2PELU43_0_split
I1001 19:09:22.463604  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.463606  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.463609  5547 net.cpp:137] Memory required for data: 1082574000
I1001 19:09:22.463611  5547 layer_factory.hpp:77] Creating layer Convolution46
I1001 19:09:22.463618  5547 net.cpp:84] Creating Layer Convolution46
I1001 19:09:22.463620  5547 net.cpp:406] Convolution46 <- Eltwise21_M2PELU43_0_split_0
I1001 19:09:22.463624  5547 net.cpp:380] Convolution46 -> Convolution46
I1001 19:09:22.465432  5547 net.cpp:122] Setting up Convolution46
I1001 19:09:22.465440  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.465443  5547 net.cpp:137] Memory required for data: 1084212400
I1001 19:09:22.465448  5547 layer_factory.hpp:77] Creating layer BatchNorm46
I1001 19:09:22.465453  5547 net.cpp:84] Creating Layer BatchNorm46
I1001 19:09:22.465456  5547 net.cpp:406] BatchNorm46 <- Convolution46
I1001 19:09:22.465461  5547 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I1001 19:09:22.465598  5547 net.cpp:122] Setting up BatchNorm46
I1001 19:09:22.465602  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.465605  5547 net.cpp:137] Memory required for data: 1085850800
I1001 19:09:22.465610  5547 layer_factory.hpp:77] Creating layer Scale46
I1001 19:09:22.465613  5547 net.cpp:84] Creating Layer Scale46
I1001 19:09:22.465615  5547 net.cpp:406] Scale46 <- Convolution46
I1001 19:09:22.465618  5547 net.cpp:367] Scale46 -> Convolution46 (in-place)
I1001 19:09:22.465646  5547 layer_factory.hpp:77] Creating layer Scale46
I1001 19:09:22.465723  5547 net.cpp:122] Setting up Scale46
I1001 19:09:22.465728  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.465730  5547 net.cpp:137] Memory required for data: 1087489200
I1001 19:09:22.465734  5547 layer_factory.hpp:77] Creating layer M2PELU44
I1001 19:09:22.465739  5547 net.cpp:84] Creating Layer M2PELU44
I1001 19:09:22.465749  5547 net.cpp:406] M2PELU44 <- Convolution46
I1001 19:09:22.465752  5547 net.cpp:367] M2PELU44 -> Convolution46 (in-place)
I1001 19:09:22.465843  5547 net.cpp:122] Setting up M2PELU44
I1001 19:09:22.465848  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.465850  5547 net.cpp:137] Memory required for data: 1089127600
I1001 19:09:22.465853  5547 layer_factory.hpp:77] Creating layer Convolution47
I1001 19:09:22.465860  5547 net.cpp:84] Creating Layer Convolution47
I1001 19:09:22.465862  5547 net.cpp:406] Convolution47 <- Convolution46
I1001 19:09:22.465867  5547 net.cpp:380] Convolution47 -> Convolution47
I1001 19:09:22.467551  5547 net.cpp:122] Setting up Convolution47
I1001 19:09:22.467561  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.467563  5547 net.cpp:137] Memory required for data: 1090766000
I1001 19:09:22.467567  5547 layer_factory.hpp:77] Creating layer BatchNorm47
I1001 19:09:22.467573  5547 net.cpp:84] Creating Layer BatchNorm47
I1001 19:09:22.467576  5547 net.cpp:406] BatchNorm47 <- Convolution47
I1001 19:09:22.467579  5547 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I1001 19:09:22.467710  5547 net.cpp:122] Setting up BatchNorm47
I1001 19:09:22.467715  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.467716  5547 net.cpp:137] Memory required for data: 1092404400
I1001 19:09:22.467720  5547 layer_factory.hpp:77] Creating layer Scale47
I1001 19:09:22.467725  5547 net.cpp:84] Creating Layer Scale47
I1001 19:09:22.467728  5547 net.cpp:406] Scale47 <- Convolution47
I1001 19:09:22.467731  5547 net.cpp:367] Scale47 -> Convolution47 (in-place)
I1001 19:09:22.467757  5547 layer_factory.hpp:77] Creating layer Scale47
I1001 19:09:22.467834  5547 net.cpp:122] Setting up Scale47
I1001 19:09:22.467839  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.467840  5547 net.cpp:137] Memory required for data: 1094042800
I1001 19:09:22.467844  5547 layer_factory.hpp:77] Creating layer Eltwise22
I1001 19:09:22.467849  5547 net.cpp:84] Creating Layer Eltwise22
I1001 19:09:22.467852  5547 net.cpp:406] Eltwise22 <- Eltwise21_M2PELU43_0_split_1
I1001 19:09:22.467855  5547 net.cpp:406] Eltwise22 <- Convolution47
I1001 19:09:22.467859  5547 net.cpp:380] Eltwise22 -> Eltwise22
I1001 19:09:22.467875  5547 net.cpp:122] Setting up Eltwise22
I1001 19:09:22.467880  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.467881  5547 net.cpp:137] Memory required for data: 1095681200
I1001 19:09:22.467883  5547 layer_factory.hpp:77] Creating layer M2PELU45
I1001 19:09:22.467887  5547 net.cpp:84] Creating Layer M2PELU45
I1001 19:09:22.467890  5547 net.cpp:406] M2PELU45 <- Eltwise22
I1001 19:09:22.467893  5547 net.cpp:367] M2PELU45 -> Eltwise22 (in-place)
I1001 19:09:22.467980  5547 net.cpp:122] Setting up M2PELU45
I1001 19:09:22.467984  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.467986  5547 net.cpp:137] Memory required for data: 1097319600
I1001 19:09:22.467990  5547 layer_factory.hpp:77] Creating layer Eltwise22_M2PELU45_0_split
I1001 19:09:22.467994  5547 net.cpp:84] Creating Layer Eltwise22_M2PELU45_0_split
I1001 19:09:22.467998  5547 net.cpp:406] Eltwise22_M2PELU45_0_split <- Eltwise22
I1001 19:09:22.468000  5547 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_0
I1001 19:09:22.468005  5547 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_1
I1001 19:09:22.468027  5547 net.cpp:122] Setting up Eltwise22_M2PELU45_0_split
I1001 19:09:22.468031  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.468034  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.468036  5547 net.cpp:137] Memory required for data: 1100596400
I1001 19:09:22.468039  5547 layer_factory.hpp:77] Creating layer Convolution48
I1001 19:09:22.468044  5547 net.cpp:84] Creating Layer Convolution48
I1001 19:09:22.468046  5547 net.cpp:406] Convolution48 <- Eltwise22_M2PELU45_0_split_0
I1001 19:09:22.468051  5547 net.cpp:380] Convolution48 -> Convolution48
I1001 19:09:22.470037  5547 net.cpp:122] Setting up Convolution48
I1001 19:09:22.470052  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.470055  5547 net.cpp:137] Memory required for data: 1102234800
I1001 19:09:22.470060  5547 layer_factory.hpp:77] Creating layer BatchNorm48
I1001 19:09:22.470067  5547 net.cpp:84] Creating Layer BatchNorm48
I1001 19:09:22.470070  5547 net.cpp:406] BatchNorm48 <- Convolution48
I1001 19:09:22.470073  5547 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I1001 19:09:22.470211  5547 net.cpp:122] Setting up BatchNorm48
I1001 19:09:22.470216  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.470217  5547 net.cpp:137] Memory required for data: 1103873200
I1001 19:09:22.470221  5547 layer_factory.hpp:77] Creating layer Scale48
I1001 19:09:22.470226  5547 net.cpp:84] Creating Layer Scale48
I1001 19:09:22.470228  5547 net.cpp:406] Scale48 <- Convolution48
I1001 19:09:22.470232  5547 net.cpp:367] Scale48 -> Convolution48 (in-place)
I1001 19:09:22.470258  5547 layer_factory.hpp:77] Creating layer Scale48
I1001 19:09:22.470335  5547 net.cpp:122] Setting up Scale48
I1001 19:09:22.470340  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.470341  5547 net.cpp:137] Memory required for data: 1105511600
I1001 19:09:22.470345  5547 layer_factory.hpp:77] Creating layer M2PELU46
I1001 19:09:22.470350  5547 net.cpp:84] Creating Layer M2PELU46
I1001 19:09:22.470353  5547 net.cpp:406] M2PELU46 <- Convolution48
I1001 19:09:22.470356  5547 net.cpp:367] M2PELU46 -> Convolution48 (in-place)
I1001 19:09:22.470446  5547 net.cpp:122] Setting up M2PELU46
I1001 19:09:22.470451  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.470453  5547 net.cpp:137] Memory required for data: 1107150000
I1001 19:09:22.470456  5547 layer_factory.hpp:77] Creating layer Convolution49
I1001 19:09:22.470463  5547 net.cpp:84] Creating Layer Convolution49
I1001 19:09:22.470465  5547 net.cpp:406] Convolution49 <- Convolution48
I1001 19:09:22.470469  5547 net.cpp:380] Convolution49 -> Convolution49
I1001 19:09:22.472529  5547 net.cpp:122] Setting up Convolution49
I1001 19:09:22.472542  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.472544  5547 net.cpp:137] Memory required for data: 1108788400
I1001 19:09:22.472549  5547 layer_factory.hpp:77] Creating layer BatchNorm49
I1001 19:09:22.472554  5547 net.cpp:84] Creating Layer BatchNorm49
I1001 19:09:22.472558  5547 net.cpp:406] BatchNorm49 <- Convolution49
I1001 19:09:22.472560  5547 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I1001 19:09:22.472695  5547 net.cpp:122] Setting up BatchNorm49
I1001 19:09:22.472699  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.472702  5547 net.cpp:137] Memory required for data: 1110426800
I1001 19:09:22.472707  5547 layer_factory.hpp:77] Creating layer Scale49
I1001 19:09:22.472712  5547 net.cpp:84] Creating Layer Scale49
I1001 19:09:22.472713  5547 net.cpp:406] Scale49 <- Convolution49
I1001 19:09:22.472717  5547 net.cpp:367] Scale49 -> Convolution49 (in-place)
I1001 19:09:22.472743  5547 layer_factory.hpp:77] Creating layer Scale49
I1001 19:09:22.472820  5547 net.cpp:122] Setting up Scale49
I1001 19:09:22.472825  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.472826  5547 net.cpp:137] Memory required for data: 1112065200
I1001 19:09:22.472831  5547 layer_factory.hpp:77] Creating layer Eltwise23
I1001 19:09:22.472836  5547 net.cpp:84] Creating Layer Eltwise23
I1001 19:09:22.472839  5547 net.cpp:406] Eltwise23 <- Eltwise22_M2PELU45_0_split_1
I1001 19:09:22.472842  5547 net.cpp:406] Eltwise23 <- Convolution49
I1001 19:09:22.472846  5547 net.cpp:380] Eltwise23 -> Eltwise23
I1001 19:09:22.472862  5547 net.cpp:122] Setting up Eltwise23
I1001 19:09:22.472867  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.472868  5547 net.cpp:137] Memory required for data: 1113703600
I1001 19:09:22.472870  5547 layer_factory.hpp:77] Creating layer M2PELU47
I1001 19:09:22.472877  5547 net.cpp:84] Creating Layer M2PELU47
I1001 19:09:22.472878  5547 net.cpp:406] M2PELU47 <- Eltwise23
I1001 19:09:22.472882  5547 net.cpp:367] M2PELU47 -> Eltwise23 (in-place)
I1001 19:09:22.472980  5547 net.cpp:122] Setting up M2PELU47
I1001 19:09:22.472985  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.472987  5547 net.cpp:137] Memory required for data: 1115342000
I1001 19:09:22.472991  5547 layer_factory.hpp:77] Creating layer Eltwise23_M2PELU47_0_split
I1001 19:09:22.472995  5547 net.cpp:84] Creating Layer Eltwise23_M2PELU47_0_split
I1001 19:09:22.472997  5547 net.cpp:406] Eltwise23_M2PELU47_0_split <- Eltwise23
I1001 19:09:22.473001  5547 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_0
I1001 19:09:22.473006  5547 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_1
I1001 19:09:22.473028  5547 net.cpp:122] Setting up Eltwise23_M2PELU47_0_split
I1001 19:09:22.473032  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.473036  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.473037  5547 net.cpp:137] Memory required for data: 1118618800
I1001 19:09:22.473039  5547 layer_factory.hpp:77] Creating layer Convolution50
I1001 19:09:22.473044  5547 net.cpp:84] Creating Layer Convolution50
I1001 19:09:22.473047  5547 net.cpp:406] Convolution50 <- Eltwise23_M2PELU47_0_split_0
I1001 19:09:22.473052  5547 net.cpp:380] Convolution50 -> Convolution50
I1001 19:09:22.475798  5547 net.cpp:122] Setting up Convolution50
I1001 19:09:22.475810  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.475812  5547 net.cpp:137] Memory required for data: 1120257200
I1001 19:09:22.475817  5547 layer_factory.hpp:77] Creating layer BatchNorm50
I1001 19:09:22.475822  5547 net.cpp:84] Creating Layer BatchNorm50
I1001 19:09:22.475826  5547 net.cpp:406] BatchNorm50 <- Convolution50
I1001 19:09:22.475831  5547 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I1001 19:09:22.491492  5547 net.cpp:122] Setting up BatchNorm50
I1001 19:09:22.491502  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.491504  5547 net.cpp:137] Memory required for data: 1121895600
I1001 19:09:22.491510  5547 layer_factory.hpp:77] Creating layer Scale50
I1001 19:09:22.491515  5547 net.cpp:84] Creating Layer Scale50
I1001 19:09:22.491518  5547 net.cpp:406] Scale50 <- Convolution50
I1001 19:09:22.491523  5547 net.cpp:367] Scale50 -> Convolution50 (in-place)
I1001 19:09:22.491555  5547 layer_factory.hpp:77] Creating layer Scale50
I1001 19:09:22.491644  5547 net.cpp:122] Setting up Scale50
I1001 19:09:22.491649  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.491652  5547 net.cpp:137] Memory required for data: 1123534000
I1001 19:09:22.491655  5547 layer_factory.hpp:77] Creating layer M2PELU48
I1001 19:09:22.491660  5547 net.cpp:84] Creating Layer M2PELU48
I1001 19:09:22.491663  5547 net.cpp:406] M2PELU48 <- Convolution50
I1001 19:09:22.491667  5547 net.cpp:367] M2PELU48 -> Convolution50 (in-place)
I1001 19:09:22.491770  5547 net.cpp:122] Setting up M2PELU48
I1001 19:09:22.491775  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.491776  5547 net.cpp:137] Memory required for data: 1125172400
I1001 19:09:22.491780  5547 layer_factory.hpp:77] Creating layer Convolution51
I1001 19:09:22.491789  5547 net.cpp:84] Creating Layer Convolution51
I1001 19:09:22.491792  5547 net.cpp:406] Convolution51 <- Convolution50
I1001 19:09:22.491796  5547 net.cpp:380] Convolution51 -> Convolution51
I1001 19:09:22.493644  5547 net.cpp:122] Setting up Convolution51
I1001 19:09:22.493654  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.493657  5547 net.cpp:137] Memory required for data: 1126810800
I1001 19:09:22.493662  5547 layer_factory.hpp:77] Creating layer BatchNorm51
I1001 19:09:22.493669  5547 net.cpp:84] Creating Layer BatchNorm51
I1001 19:09:22.493672  5547 net.cpp:406] BatchNorm51 <- Convolution51
I1001 19:09:22.493677  5547 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I1001 19:09:22.493821  5547 net.cpp:122] Setting up BatchNorm51
I1001 19:09:22.493825  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.493827  5547 net.cpp:137] Memory required for data: 1128449200
I1001 19:09:22.493841  5547 layer_factory.hpp:77] Creating layer Scale51
I1001 19:09:22.493846  5547 net.cpp:84] Creating Layer Scale51
I1001 19:09:22.493849  5547 net.cpp:406] Scale51 <- Convolution51
I1001 19:09:22.493852  5547 net.cpp:367] Scale51 -> Convolution51 (in-place)
I1001 19:09:22.493883  5547 layer_factory.hpp:77] Creating layer Scale51
I1001 19:09:22.493968  5547 net.cpp:122] Setting up Scale51
I1001 19:09:22.493973  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.493974  5547 net.cpp:137] Memory required for data: 1130087600
I1001 19:09:22.493978  5547 layer_factory.hpp:77] Creating layer Eltwise24
I1001 19:09:22.493983  5547 net.cpp:84] Creating Layer Eltwise24
I1001 19:09:22.493985  5547 net.cpp:406] Eltwise24 <- Eltwise23_M2PELU47_0_split_1
I1001 19:09:22.493988  5547 net.cpp:406] Eltwise24 <- Convolution51
I1001 19:09:22.493993  5547 net.cpp:380] Eltwise24 -> Eltwise24
I1001 19:09:22.494009  5547 net.cpp:122] Setting up Eltwise24
I1001 19:09:22.494014  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.494015  5547 net.cpp:137] Memory required for data: 1131726000
I1001 19:09:22.494017  5547 layer_factory.hpp:77] Creating layer M2PELU49
I1001 19:09:22.494024  5547 net.cpp:84] Creating Layer M2PELU49
I1001 19:09:22.494025  5547 net.cpp:406] M2PELU49 <- Eltwise24
I1001 19:09:22.494029  5547 net.cpp:367] M2PELU49 -> Eltwise24 (in-place)
I1001 19:09:22.494127  5547 net.cpp:122] Setting up M2PELU49
I1001 19:09:22.494130  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.494132  5547 net.cpp:137] Memory required for data: 1133364400
I1001 19:09:22.494137  5547 layer_factory.hpp:77] Creating layer Eltwise24_M2PELU49_0_split
I1001 19:09:22.494140  5547 net.cpp:84] Creating Layer Eltwise24_M2PELU49_0_split
I1001 19:09:22.494144  5547 net.cpp:406] Eltwise24_M2PELU49_0_split <- Eltwise24
I1001 19:09:22.494148  5547 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_0
I1001 19:09:22.494151  5547 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_1
I1001 19:09:22.494189  5547 net.cpp:122] Setting up Eltwise24_M2PELU49_0_split
I1001 19:09:22.494192  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.494196  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.494199  5547 net.cpp:137] Memory required for data: 1136641200
I1001 19:09:22.494201  5547 layer_factory.hpp:77] Creating layer Convolution52
I1001 19:09:22.494207  5547 net.cpp:84] Creating Layer Convolution52
I1001 19:09:22.494210  5547 net.cpp:406] Convolution52 <- Eltwise24_M2PELU49_0_split_0
I1001 19:09:22.494215  5547 net.cpp:380] Convolution52 -> Convolution52
I1001 19:09:22.496351  5547 net.cpp:122] Setting up Convolution52
I1001 19:09:22.496359  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.496362  5547 net.cpp:137] Memory required for data: 1138279600
I1001 19:09:22.496368  5547 layer_factory.hpp:77] Creating layer BatchNorm52
I1001 19:09:22.496373  5547 net.cpp:84] Creating Layer BatchNorm52
I1001 19:09:22.496377  5547 net.cpp:406] BatchNorm52 <- Convolution52
I1001 19:09:22.496381  5547 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I1001 19:09:22.496531  5547 net.cpp:122] Setting up BatchNorm52
I1001 19:09:22.496536  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.496537  5547 net.cpp:137] Memory required for data: 1139918000
I1001 19:09:22.496542  5547 layer_factory.hpp:77] Creating layer Scale52
I1001 19:09:22.496546  5547 net.cpp:84] Creating Layer Scale52
I1001 19:09:22.496549  5547 net.cpp:406] Scale52 <- Convolution52
I1001 19:09:22.496552  5547 net.cpp:367] Scale52 -> Convolution52 (in-place)
I1001 19:09:22.496582  5547 layer_factory.hpp:77] Creating layer Scale52
I1001 19:09:22.496667  5547 net.cpp:122] Setting up Scale52
I1001 19:09:22.496672  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.496675  5547 net.cpp:137] Memory required for data: 1141556400
I1001 19:09:22.496678  5547 layer_factory.hpp:77] Creating layer M2PELU50
I1001 19:09:22.496701  5547 net.cpp:84] Creating Layer M2PELU50
I1001 19:09:22.496711  5547 net.cpp:406] M2PELU50 <- Convolution52
I1001 19:09:22.496716  5547 net.cpp:367] M2PELU50 -> Convolution52 (in-place)
I1001 19:09:22.496819  5547 net.cpp:122] Setting up M2PELU50
I1001 19:09:22.496824  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.496826  5547 net.cpp:137] Memory required for data: 1143194800
I1001 19:09:22.496830  5547 layer_factory.hpp:77] Creating layer Convolution53
I1001 19:09:22.496837  5547 net.cpp:84] Creating Layer Convolution53
I1001 19:09:22.496840  5547 net.cpp:406] Convolution53 <- Convolution52
I1001 19:09:22.496845  5547 net.cpp:380] Convolution53 -> Convolution53
I1001 19:09:22.498639  5547 net.cpp:122] Setting up Convolution53
I1001 19:09:22.498648  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.498651  5547 net.cpp:137] Memory required for data: 1144833200
I1001 19:09:22.498656  5547 layer_factory.hpp:77] Creating layer BatchNorm53
I1001 19:09:22.498662  5547 net.cpp:84] Creating Layer BatchNorm53
I1001 19:09:22.498666  5547 net.cpp:406] BatchNorm53 <- Convolution53
I1001 19:09:22.498672  5547 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I1001 19:09:22.498814  5547 net.cpp:122] Setting up BatchNorm53
I1001 19:09:22.498819  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.498821  5547 net.cpp:137] Memory required for data: 1146471600
I1001 19:09:22.498826  5547 layer_factory.hpp:77] Creating layer Scale53
I1001 19:09:22.498831  5547 net.cpp:84] Creating Layer Scale53
I1001 19:09:22.498833  5547 net.cpp:406] Scale53 <- Convolution53
I1001 19:09:22.498836  5547 net.cpp:367] Scale53 -> Convolution53 (in-place)
I1001 19:09:22.498864  5547 layer_factory.hpp:77] Creating layer Scale53
I1001 19:09:22.498950  5547 net.cpp:122] Setting up Scale53
I1001 19:09:22.498955  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.498956  5547 net.cpp:137] Memory required for data: 1148110000
I1001 19:09:22.498960  5547 layer_factory.hpp:77] Creating layer Eltwise25
I1001 19:09:22.498965  5547 net.cpp:84] Creating Layer Eltwise25
I1001 19:09:22.498967  5547 net.cpp:406] Eltwise25 <- Eltwise24_M2PELU49_0_split_1
I1001 19:09:22.498970  5547 net.cpp:406] Eltwise25 <- Convolution53
I1001 19:09:22.498975  5547 net.cpp:380] Eltwise25 -> Eltwise25
I1001 19:09:22.498991  5547 net.cpp:122] Setting up Eltwise25
I1001 19:09:22.498996  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.498997  5547 net.cpp:137] Memory required for data: 1149748400
I1001 19:09:22.499001  5547 layer_factory.hpp:77] Creating layer M2PELU51
I1001 19:09:22.499006  5547 net.cpp:84] Creating Layer M2PELU51
I1001 19:09:22.499007  5547 net.cpp:406] M2PELU51 <- Eltwise25
I1001 19:09:22.499011  5547 net.cpp:367] M2PELU51 -> Eltwise25 (in-place)
I1001 19:09:22.499106  5547 net.cpp:122] Setting up M2PELU51
I1001 19:09:22.499111  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.499114  5547 net.cpp:137] Memory required for data: 1151386800
I1001 19:09:22.499117  5547 layer_factory.hpp:77] Creating layer Eltwise25_M2PELU51_0_split
I1001 19:09:22.499121  5547 net.cpp:84] Creating Layer Eltwise25_M2PELU51_0_split
I1001 19:09:22.499124  5547 net.cpp:406] Eltwise25_M2PELU51_0_split <- Eltwise25
I1001 19:09:22.499127  5547 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_0
I1001 19:09:22.499131  5547 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_1
I1001 19:09:22.499156  5547 net.cpp:122] Setting up Eltwise25_M2PELU51_0_split
I1001 19:09:22.499161  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.499163  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.499166  5547 net.cpp:137] Memory required for data: 1154663600
I1001 19:09:22.499167  5547 layer_factory.hpp:77] Creating layer Convolution54
I1001 19:09:22.499174  5547 net.cpp:84] Creating Layer Convolution54
I1001 19:09:22.499177  5547 net.cpp:406] Convolution54 <- Eltwise25_M2PELU51_0_split_0
I1001 19:09:22.499181  5547 net.cpp:380] Convolution54 -> Convolution54
I1001 19:09:22.501302  5547 net.cpp:122] Setting up Convolution54
I1001 19:09:22.501310  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.501313  5547 net.cpp:137] Memory required for data: 1156302000
I1001 19:09:22.501318  5547 layer_factory.hpp:77] Creating layer BatchNorm54
I1001 19:09:22.501323  5547 net.cpp:84] Creating Layer BatchNorm54
I1001 19:09:22.501327  5547 net.cpp:406] BatchNorm54 <- Convolution54
I1001 19:09:22.501330  5547 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I1001 19:09:22.501482  5547 net.cpp:122] Setting up BatchNorm54
I1001 19:09:22.501487  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.501488  5547 net.cpp:137] Memory required for data: 1157940400
I1001 19:09:22.501493  5547 layer_factory.hpp:77] Creating layer Scale54
I1001 19:09:22.501497  5547 net.cpp:84] Creating Layer Scale54
I1001 19:09:22.501500  5547 net.cpp:406] Scale54 <- Convolution54
I1001 19:09:22.501503  5547 net.cpp:367] Scale54 -> Convolution54 (in-place)
I1001 19:09:22.501533  5547 layer_factory.hpp:77] Creating layer Scale54
I1001 19:09:22.501617  5547 net.cpp:122] Setting up Scale54
I1001 19:09:22.501621  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.501623  5547 net.cpp:137] Memory required for data: 1159578800
I1001 19:09:22.501627  5547 layer_factory.hpp:77] Creating layer M2PELU52
I1001 19:09:22.501633  5547 net.cpp:84] Creating Layer M2PELU52
I1001 19:09:22.501636  5547 net.cpp:406] M2PELU52 <- Convolution54
I1001 19:09:22.501639  5547 net.cpp:367] M2PELU52 -> Convolution54 (in-place)
I1001 19:09:22.501736  5547 net.cpp:122] Setting up M2PELU52
I1001 19:09:22.501740  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.501742  5547 net.cpp:137] Memory required for data: 1161217200
I1001 19:09:22.501746  5547 layer_factory.hpp:77] Creating layer Convolution55
I1001 19:09:22.501754  5547 net.cpp:84] Creating Layer Convolution55
I1001 19:09:22.501756  5547 net.cpp:406] Convolution55 <- Convolution54
I1001 19:09:22.501760  5547 net.cpp:380] Convolution55 -> Convolution55
I1001 19:09:22.503556  5547 net.cpp:122] Setting up Convolution55
I1001 19:09:22.503566  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.503567  5547 net.cpp:137] Memory required for data: 1162855600
I1001 19:09:22.503572  5547 layer_factory.hpp:77] Creating layer BatchNorm55
I1001 19:09:22.503578  5547 net.cpp:84] Creating Layer BatchNorm55
I1001 19:09:22.503582  5547 net.cpp:406] BatchNorm55 <- Convolution55
I1001 19:09:22.503585  5547 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I1001 19:09:22.503731  5547 net.cpp:122] Setting up BatchNorm55
I1001 19:09:22.503736  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.503738  5547 net.cpp:137] Memory required for data: 1164494000
I1001 19:09:22.503743  5547 layer_factory.hpp:77] Creating layer Scale55
I1001 19:09:22.503747  5547 net.cpp:84] Creating Layer Scale55
I1001 19:09:22.503751  5547 net.cpp:406] Scale55 <- Convolution55
I1001 19:09:22.503753  5547 net.cpp:367] Scale55 -> Convolution55 (in-place)
I1001 19:09:22.503782  5547 layer_factory.hpp:77] Creating layer Scale55
I1001 19:09:22.503868  5547 net.cpp:122] Setting up Scale55
I1001 19:09:22.503873  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.503875  5547 net.cpp:137] Memory required for data: 1166132400
I1001 19:09:22.503880  5547 layer_factory.hpp:77] Creating layer Eltwise26
I1001 19:09:22.503885  5547 net.cpp:84] Creating Layer Eltwise26
I1001 19:09:22.503887  5547 net.cpp:406] Eltwise26 <- Eltwise25_M2PELU51_0_split_1
I1001 19:09:22.503890  5547 net.cpp:406] Eltwise26 <- Convolution55
I1001 19:09:22.503893  5547 net.cpp:380] Eltwise26 -> Eltwise26
I1001 19:09:22.503911  5547 net.cpp:122] Setting up Eltwise26
I1001 19:09:22.503916  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.503917  5547 net.cpp:137] Memory required for data: 1167770800
I1001 19:09:22.503919  5547 layer_factory.hpp:77] Creating layer M2PELU53
I1001 19:09:22.503924  5547 net.cpp:84] Creating Layer M2PELU53
I1001 19:09:22.503927  5547 net.cpp:406] M2PELU53 <- Eltwise26
I1001 19:09:22.503938  5547 net.cpp:367] M2PELU53 -> Eltwise26 (in-place)
I1001 19:09:22.504037  5547 net.cpp:122] Setting up M2PELU53
I1001 19:09:22.504041  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.504045  5547 net.cpp:137] Memory required for data: 1169409200
I1001 19:09:22.504048  5547 layer_factory.hpp:77] Creating layer Eltwise26_M2PELU53_0_split
I1001 19:09:22.504052  5547 net.cpp:84] Creating Layer Eltwise26_M2PELU53_0_split
I1001 19:09:22.504055  5547 net.cpp:406] Eltwise26_M2PELU53_0_split <- Eltwise26
I1001 19:09:22.504058  5547 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_0
I1001 19:09:22.504062  5547 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_1
I1001 19:09:22.504088  5547 net.cpp:122] Setting up Eltwise26_M2PELU53_0_split
I1001 19:09:22.504092  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.504096  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.504097  5547 net.cpp:137] Memory required for data: 1172686000
I1001 19:09:22.504099  5547 layer_factory.hpp:77] Creating layer Convolution56
I1001 19:09:22.504106  5547 net.cpp:84] Creating Layer Convolution56
I1001 19:09:22.504108  5547 net.cpp:406] Convolution56 <- Eltwise26_M2PELU53_0_split_0
I1001 19:09:22.504113  5547 net.cpp:380] Convolution56 -> Convolution56
I1001 19:09:22.505884  5547 net.cpp:122] Setting up Convolution56
I1001 19:09:22.505893  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.505895  5547 net.cpp:137] Memory required for data: 1174324400
I1001 19:09:22.505900  5547 layer_factory.hpp:77] Creating layer BatchNorm56
I1001 19:09:22.521754  5547 net.cpp:84] Creating Layer BatchNorm56
I1001 19:09:22.521762  5547 net.cpp:406] BatchNorm56 <- Convolution56
I1001 19:09:22.521766  5547 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I1001 19:09:22.521934  5547 net.cpp:122] Setting up BatchNorm56
I1001 19:09:22.521940  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.521944  5547 net.cpp:137] Memory required for data: 1175962800
I1001 19:09:22.521950  5547 layer_factory.hpp:77] Creating layer Scale56
I1001 19:09:22.521953  5547 net.cpp:84] Creating Layer Scale56
I1001 19:09:22.521956  5547 net.cpp:406] Scale56 <- Convolution56
I1001 19:09:22.521960  5547 net.cpp:367] Scale56 -> Convolution56 (in-place)
I1001 19:09:22.521992  5547 layer_factory.hpp:77] Creating layer Scale56
I1001 19:09:22.522080  5547 net.cpp:122] Setting up Scale56
I1001 19:09:22.522086  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.522089  5547 net.cpp:137] Memory required for data: 1177601200
I1001 19:09:22.522092  5547 layer_factory.hpp:77] Creating layer M2PELU54
I1001 19:09:22.522097  5547 net.cpp:84] Creating Layer M2PELU54
I1001 19:09:22.522100  5547 net.cpp:406] M2PELU54 <- Convolution56
I1001 19:09:22.522104  5547 net.cpp:367] M2PELU54 -> Convolution56 (in-place)
I1001 19:09:22.522209  5547 net.cpp:122] Setting up M2PELU54
I1001 19:09:22.522214  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.522217  5547 net.cpp:137] Memory required for data: 1179239600
I1001 19:09:22.522220  5547 layer_factory.hpp:77] Creating layer Convolution57
I1001 19:09:22.522228  5547 net.cpp:84] Creating Layer Convolution57
I1001 19:09:22.522230  5547 net.cpp:406] Convolution57 <- Convolution56
I1001 19:09:22.522235  5547 net.cpp:380] Convolution57 -> Convolution57
I1001 19:09:22.524227  5547 net.cpp:122] Setting up Convolution57
I1001 19:09:22.524237  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.524240  5547 net.cpp:137] Memory required for data: 1180878000
I1001 19:09:22.524245  5547 layer_factory.hpp:77] Creating layer BatchNorm57
I1001 19:09:22.524251  5547 net.cpp:84] Creating Layer BatchNorm57
I1001 19:09:22.524255  5547 net.cpp:406] BatchNorm57 <- Convolution57
I1001 19:09:22.524258  5547 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I1001 19:09:22.524405  5547 net.cpp:122] Setting up BatchNorm57
I1001 19:09:22.524408  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.524417  5547 net.cpp:137] Memory required for data: 1182516400
I1001 19:09:22.524422  5547 layer_factory.hpp:77] Creating layer Scale57
I1001 19:09:22.524428  5547 net.cpp:84] Creating Layer Scale57
I1001 19:09:22.524430  5547 net.cpp:406] Scale57 <- Convolution57
I1001 19:09:22.524433  5547 net.cpp:367] Scale57 -> Convolution57 (in-place)
I1001 19:09:22.524464  5547 layer_factory.hpp:77] Creating layer Scale57
I1001 19:09:22.524549  5547 net.cpp:122] Setting up Scale57
I1001 19:09:22.524552  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.524554  5547 net.cpp:137] Memory required for data: 1184154800
I1001 19:09:22.524559  5547 layer_factory.hpp:77] Creating layer Eltwise27
I1001 19:09:22.524564  5547 net.cpp:84] Creating Layer Eltwise27
I1001 19:09:22.524566  5547 net.cpp:406] Eltwise27 <- Eltwise26_M2PELU53_0_split_1
I1001 19:09:22.524569  5547 net.cpp:406] Eltwise27 <- Convolution57
I1001 19:09:22.524572  5547 net.cpp:380] Eltwise27 -> Eltwise27
I1001 19:09:22.524590  5547 net.cpp:122] Setting up Eltwise27
I1001 19:09:22.524595  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.524596  5547 net.cpp:137] Memory required for data: 1185793200
I1001 19:09:22.524598  5547 layer_factory.hpp:77] Creating layer M2PELU55
I1001 19:09:22.524603  5547 net.cpp:84] Creating Layer M2PELU55
I1001 19:09:22.524605  5547 net.cpp:406] M2PELU55 <- Eltwise27
I1001 19:09:22.524610  5547 net.cpp:367] M2PELU55 -> Eltwise27 (in-place)
I1001 19:09:22.524706  5547 net.cpp:122] Setting up M2PELU55
I1001 19:09:22.524710  5547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 19:09:22.524713  5547 net.cpp:137] Memory required for data: 1187431600
I1001 19:09:22.524716  5547 layer_factory.hpp:77] Creating layer Pooling1
I1001 19:09:22.524721  5547 net.cpp:84] Creating Layer Pooling1
I1001 19:09:22.524724  5547 net.cpp:406] Pooling1 <- Eltwise27
I1001 19:09:22.524727  5547 net.cpp:380] Pooling1 -> Pooling1
I1001 19:09:22.525359  5547 net.cpp:122] Setting up Pooling1
I1001 19:09:22.525367  5547 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1001 19:09:22.525370  5547 net.cpp:137] Memory required for data: 1187457200
I1001 19:09:22.525373  5547 layer_factory.hpp:77] Creating layer InnerProduct1
I1001 19:09:22.525379  5547 net.cpp:84] Creating Layer InnerProduct1
I1001 19:09:22.525382  5547 net.cpp:406] InnerProduct1 <- Pooling1
I1001 19:09:22.525385  5547 net.cpp:380] InnerProduct1 -> InnerProduct1
I1001 19:09:22.525498  5547 net.cpp:122] Setting up InnerProduct1
I1001 19:09:22.525503  5547 net.cpp:129] Top shape: 100 10 (1000)
I1001 19:09:22.525506  5547 net.cpp:137] Memory required for data: 1187461200
I1001 19:09:22.525509  5547 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I1001 19:09:22.525513  5547 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I1001 19:09:22.525516  5547 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I1001 19:09:22.525519  5547 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I1001 19:09:22.525523  5547 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I1001 19:09:22.525550  5547 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I1001 19:09:22.525554  5547 net.cpp:129] Top shape: 100 10 (1000)
I1001 19:09:22.525557  5547 net.cpp:129] Top shape: 100 10 (1000)
I1001 19:09:22.525559  5547 net.cpp:137] Memory required for data: 1187469200
I1001 19:09:22.525562  5547 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1001 19:09:22.525566  5547 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1001 19:09:22.525568  5547 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I1001 19:09:22.525573  5547 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I1001 19:09:22.525575  5547 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1001 19:09:22.525580  5547 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1001 19:09:22.525897  5547 net.cpp:122] Setting up SoftmaxWithLoss1
I1001 19:09:22.525907  5547 net.cpp:129] Top shape: (1)
I1001 19:09:22.525919  5547 net.cpp:132]     with loss weight 1
I1001 19:09:22.525930  5547 net.cpp:137] Memory required for data: 1187469204
I1001 19:09:22.525934  5547 layer_factory.hpp:77] Creating layer Accuracy1
I1001 19:09:22.525941  5547 net.cpp:84] Creating Layer Accuracy1
I1001 19:09:22.525945  5547 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I1001 19:09:22.525950  5547 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I1001 19:09:22.525957  5547 net.cpp:380] Accuracy1 -> Accuracy1
I1001 19:09:22.525967  5547 net.cpp:122] Setting up Accuracy1
I1001 19:09:22.525974  5547 net.cpp:129] Top shape: (1)
I1001 19:09:22.525977  5547 net.cpp:137] Memory required for data: 1187469208
I1001 19:09:22.525981  5547 net.cpp:200] Accuracy1 does not need backward computation.
I1001 19:09:22.525985  5547 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1001 19:09:22.525990  5547 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I1001 19:09:22.525993  5547 net.cpp:198] InnerProduct1 needs backward computation.
I1001 19:09:22.525997  5547 net.cpp:198] Pooling1 needs backward computation.
I1001 19:09:22.526001  5547 net.cpp:198] M2PELU55 needs backward computation.
I1001 19:09:22.526005  5547 net.cpp:198] Eltwise27 needs backward computation.
I1001 19:09:22.526010  5547 net.cpp:198] Scale57 needs backward computation.
I1001 19:09:22.526013  5547 net.cpp:198] BatchNorm57 needs backward computation.
I1001 19:09:22.526016  5547 net.cpp:198] Convolution57 needs backward computation.
I1001 19:09:22.526021  5547 net.cpp:198] M2PELU54 needs backward computation.
I1001 19:09:22.526026  5547 net.cpp:198] Scale56 needs backward computation.
I1001 19:09:22.526029  5547 net.cpp:198] BatchNorm56 needs backward computation.
I1001 19:09:22.526033  5547 net.cpp:198] Convolution56 needs backward computation.
I1001 19:09:22.526037  5547 net.cpp:198] Eltwise26_M2PELU53_0_split needs backward computation.
I1001 19:09:22.526041  5547 net.cpp:198] M2PELU53 needs backward computation.
I1001 19:09:22.526046  5547 net.cpp:198] Eltwise26 needs backward computation.
I1001 19:09:22.526049  5547 net.cpp:198] Scale55 needs backward computation.
I1001 19:09:22.526053  5547 net.cpp:198] BatchNorm55 needs backward computation.
I1001 19:09:22.526057  5547 net.cpp:198] Convolution55 needs backward computation.
I1001 19:09:22.526062  5547 net.cpp:198] M2PELU52 needs backward computation.
I1001 19:09:22.526065  5547 net.cpp:198] Scale54 needs backward computation.
I1001 19:09:22.526068  5547 net.cpp:198] BatchNorm54 needs backward computation.
I1001 19:09:22.526072  5547 net.cpp:198] Convolution54 needs backward computation.
I1001 19:09:22.526077  5547 net.cpp:198] Eltwise25_M2PELU51_0_split needs backward computation.
I1001 19:09:22.526082  5547 net.cpp:198] M2PELU51 needs backward computation.
I1001 19:09:22.526085  5547 net.cpp:198] Eltwise25 needs backward computation.
I1001 19:09:22.526089  5547 net.cpp:198] Scale53 needs backward computation.
I1001 19:09:22.526093  5547 net.cpp:198] BatchNorm53 needs backward computation.
I1001 19:09:22.526098  5547 net.cpp:198] Convolution53 needs backward computation.
I1001 19:09:22.526101  5547 net.cpp:198] M2PELU50 needs backward computation.
I1001 19:09:22.526105  5547 net.cpp:198] Scale52 needs backward computation.
I1001 19:09:22.526109  5547 net.cpp:198] BatchNorm52 needs backward computation.
I1001 19:09:22.526113  5547 net.cpp:198] Convolution52 needs backward computation.
I1001 19:09:22.526116  5547 net.cpp:198] Eltwise24_M2PELU49_0_split needs backward computation.
I1001 19:09:22.526121  5547 net.cpp:198] M2PELU49 needs backward computation.
I1001 19:09:22.526125  5547 net.cpp:198] Eltwise24 needs backward computation.
I1001 19:09:22.526129  5547 net.cpp:198] Scale51 needs backward computation.
I1001 19:09:22.526134  5547 net.cpp:198] BatchNorm51 needs backward computation.
I1001 19:09:22.526137  5547 net.cpp:198] Convolution51 needs backward computation.
I1001 19:09:22.526141  5547 net.cpp:198] M2PELU48 needs backward computation.
I1001 19:09:22.526144  5547 net.cpp:198] Scale50 needs backward computation.
I1001 19:09:22.526155  5547 net.cpp:198] BatchNorm50 needs backward computation.
I1001 19:09:22.526160  5547 net.cpp:198] Convolution50 needs backward computation.
I1001 19:09:22.526165  5547 net.cpp:198] Eltwise23_M2PELU47_0_split needs backward computation.
I1001 19:09:22.526168  5547 net.cpp:198] M2PELU47 needs backward computation.
I1001 19:09:22.526172  5547 net.cpp:198] Eltwise23 needs backward computation.
I1001 19:09:22.526176  5547 net.cpp:198] Scale49 needs backward computation.
I1001 19:09:22.526182  5547 net.cpp:198] BatchNorm49 needs backward computation.
I1001 19:09:22.526186  5547 net.cpp:198] Convolution49 needs backward computation.
I1001 19:09:22.526190  5547 net.cpp:198] M2PELU46 needs backward computation.
I1001 19:09:22.526195  5547 net.cpp:198] Scale48 needs backward computation.
I1001 19:09:22.526198  5547 net.cpp:198] BatchNorm48 needs backward computation.
I1001 19:09:22.526202  5547 net.cpp:198] Convolution48 needs backward computation.
I1001 19:09:22.526207  5547 net.cpp:198] Eltwise22_M2PELU45_0_split needs backward computation.
I1001 19:09:22.526211  5547 net.cpp:198] M2PELU45 needs backward computation.
I1001 19:09:22.526216  5547 net.cpp:198] Eltwise22 needs backward computation.
I1001 19:09:22.526219  5547 net.cpp:198] Scale47 needs backward computation.
I1001 19:09:22.526222  5547 net.cpp:198] BatchNorm47 needs backward computation.
I1001 19:09:22.526226  5547 net.cpp:198] Convolution47 needs backward computation.
I1001 19:09:22.526231  5547 net.cpp:198] M2PELU44 needs backward computation.
I1001 19:09:22.526234  5547 net.cpp:198] Scale46 needs backward computation.
I1001 19:09:22.526238  5547 net.cpp:198] BatchNorm46 needs backward computation.
I1001 19:09:22.526242  5547 net.cpp:198] Convolution46 needs backward computation.
I1001 19:09:22.526245  5547 net.cpp:198] Eltwise21_M2PELU43_0_split needs backward computation.
I1001 19:09:22.526249  5547 net.cpp:198] M2PELU43 needs backward computation.
I1001 19:09:22.526253  5547 net.cpp:198] Eltwise21 needs backward computation.
I1001 19:09:22.526257  5547 net.cpp:198] Scale45 needs backward computation.
I1001 19:09:22.526262  5547 net.cpp:198] BatchNorm45 needs backward computation.
I1001 19:09:22.526265  5547 net.cpp:198] Convolution45 needs backward computation.
I1001 19:09:22.526269  5547 net.cpp:198] M2PELU42 needs backward computation.
I1001 19:09:22.526273  5547 net.cpp:198] Scale44 needs backward computation.
I1001 19:09:22.526276  5547 net.cpp:198] BatchNorm44 needs backward computation.
I1001 19:09:22.526279  5547 net.cpp:198] Convolution44 needs backward computation.
I1001 19:09:22.526283  5547 net.cpp:198] Eltwise20_M2PELU41_0_split needs backward computation.
I1001 19:09:22.526288  5547 net.cpp:198] M2PELU41 needs backward computation.
I1001 19:09:22.526293  5547 net.cpp:198] Eltwise20 needs backward computation.
I1001 19:09:22.526296  5547 net.cpp:198] Scale43 needs backward computation.
I1001 19:09:22.526300  5547 net.cpp:198] BatchNorm43 needs backward computation.
I1001 19:09:22.526304  5547 net.cpp:198] Convolution43 needs backward computation.
I1001 19:09:22.526309  5547 net.cpp:198] M2PELU40 needs backward computation.
I1001 19:09:22.526311  5547 net.cpp:198] Scale42 needs backward computation.
I1001 19:09:22.526315  5547 net.cpp:198] BatchNorm42 needs backward computation.
I1001 19:09:22.526319  5547 net.cpp:198] Convolution42 needs backward computation.
I1001 19:09:22.526324  5547 net.cpp:198] Eltwise19_M2PELU39_0_split needs backward computation.
I1001 19:09:22.526329  5547 net.cpp:198] M2PELU39 needs backward computation.
I1001 19:09:22.526332  5547 net.cpp:198] Eltwise19 needs backward computation.
I1001 19:09:22.526336  5547 net.cpp:198] Scale41 needs backward computation.
I1001 19:09:22.526340  5547 net.cpp:198] BatchNorm41 needs backward computation.
I1001 19:09:22.526345  5547 net.cpp:198] Convolution41 needs backward computation.
I1001 19:09:22.526348  5547 net.cpp:198] M2PELU38 needs backward computation.
I1001 19:09:22.526352  5547 net.cpp:198] Scale40 needs backward computation.
I1001 19:09:22.526362  5547 net.cpp:198] BatchNorm40 needs backward computation.
I1001 19:09:22.526366  5547 net.cpp:198] Convolution40 needs backward computation.
I1001 19:09:22.526371  5547 net.cpp:198] Scale39 needs backward computation.
I1001 19:09:22.526374  5547 net.cpp:198] BatchNorm39 needs backward computation.
I1001 19:09:22.526378  5547 net.cpp:198] Convolution39 needs backward computation.
I1001 19:09:22.526382  5547 net.cpp:198] Eltwise18_M2PELU37_0_split needs backward computation.
I1001 19:09:22.526386  5547 net.cpp:198] M2PELU37 needs backward computation.
I1001 19:09:22.526389  5547 net.cpp:198] Eltwise18 needs backward computation.
I1001 19:09:22.526393  5547 net.cpp:198] Scale38 needs backward computation.
I1001 19:09:22.526397  5547 net.cpp:198] BatchNorm38 needs backward computation.
I1001 19:09:22.526401  5547 net.cpp:198] Convolution38 needs backward computation.
I1001 19:09:22.526404  5547 net.cpp:198] M2PELU36 needs backward computation.
I1001 19:09:22.526408  5547 net.cpp:198] Scale37 needs backward computation.
I1001 19:09:22.526412  5547 net.cpp:198] BatchNorm37 needs backward computation.
I1001 19:09:22.526415  5547 net.cpp:198] Convolution37 needs backward computation.
I1001 19:09:22.526419  5547 net.cpp:198] Eltwise17_M2PELU35_0_split needs backward computation.
I1001 19:09:22.526423  5547 net.cpp:198] M2PELU35 needs backward computation.
I1001 19:09:22.526427  5547 net.cpp:198] Eltwise17 needs backward computation.
I1001 19:09:22.552245  5547 net.cpp:198] Scale36 needs backward computation.
I1001 19:09:22.552253  5547 net.cpp:198] BatchNorm36 needs backward computation.
I1001 19:09:22.552256  5547 net.cpp:198] Convolution36 needs backward computation.
I1001 19:09:22.552259  5547 net.cpp:198] M2PELU34 needs backward computation.
I1001 19:09:22.552261  5547 net.cpp:198] Scale35 needs backward computation.
I1001 19:09:22.552264  5547 net.cpp:198] BatchNorm35 needs backward computation.
I1001 19:09:22.552268  5547 net.cpp:198] Convolution35 needs backward computation.
I1001 19:09:22.552270  5547 net.cpp:198] Eltwise16_M2PELU33_0_split needs backward computation.
I1001 19:09:22.552273  5547 net.cpp:198] M2PELU33 needs backward computation.
I1001 19:09:22.552276  5547 net.cpp:198] Eltwise16 needs backward computation.
I1001 19:09:22.552279  5547 net.cpp:198] Scale34 needs backward computation.
I1001 19:09:22.552281  5547 net.cpp:198] BatchNorm34 needs backward computation.
I1001 19:09:22.552284  5547 net.cpp:198] Convolution34 needs backward computation.
I1001 19:09:22.552286  5547 net.cpp:198] M2PELU32 needs backward computation.
I1001 19:09:22.552289  5547 net.cpp:198] Scale33 needs backward computation.
I1001 19:09:22.552292  5547 net.cpp:198] BatchNorm33 needs backward computation.
I1001 19:09:22.552294  5547 net.cpp:198] Convolution33 needs backward computation.
I1001 19:09:22.552297  5547 net.cpp:198] Eltwise15_M2PELU31_0_split needs backward computation.
I1001 19:09:22.552300  5547 net.cpp:198] M2PELU31 needs backward computation.
I1001 19:09:22.552304  5547 net.cpp:198] Eltwise15 needs backward computation.
I1001 19:09:22.552306  5547 net.cpp:198] Scale32 needs backward computation.
I1001 19:09:22.552309  5547 net.cpp:198] BatchNorm32 needs backward computation.
I1001 19:09:22.552311  5547 net.cpp:198] Convolution32 needs backward computation.
I1001 19:09:22.552314  5547 net.cpp:198] M2PELU30 needs backward computation.
I1001 19:09:22.552316  5547 net.cpp:198] Scale31 needs backward computation.
I1001 19:09:22.552320  5547 net.cpp:198] BatchNorm31 needs backward computation.
I1001 19:09:22.552321  5547 net.cpp:198] Convolution31 needs backward computation.
I1001 19:09:22.552325  5547 net.cpp:198] Eltwise14_M2PELU29_0_split needs backward computation.
I1001 19:09:22.552327  5547 net.cpp:198] M2PELU29 needs backward computation.
I1001 19:09:22.552330  5547 net.cpp:198] Eltwise14 needs backward computation.
I1001 19:09:22.552333  5547 net.cpp:198] Scale30 needs backward computation.
I1001 19:09:22.552335  5547 net.cpp:198] BatchNorm30 needs backward computation.
I1001 19:09:22.552346  5547 net.cpp:198] Convolution30 needs backward computation.
I1001 19:09:22.552350  5547 net.cpp:198] M2PELU28 needs backward computation.
I1001 19:09:22.552352  5547 net.cpp:198] Scale29 needs backward computation.
I1001 19:09:22.552354  5547 net.cpp:198] BatchNorm29 needs backward computation.
I1001 19:09:22.552357  5547 net.cpp:198] Convolution29 needs backward computation.
I1001 19:09:22.552361  5547 net.cpp:198] Eltwise13_M2PELU27_0_split needs backward computation.
I1001 19:09:22.552363  5547 net.cpp:198] M2PELU27 needs backward computation.
I1001 19:09:22.552366  5547 net.cpp:198] Eltwise13 needs backward computation.
I1001 19:09:22.552371  5547 net.cpp:198] Scale28 needs backward computation.
I1001 19:09:22.552374  5547 net.cpp:198] BatchNorm28 needs backward computation.
I1001 19:09:22.552376  5547 net.cpp:198] Convolution28 needs backward computation.
I1001 19:09:22.552379  5547 net.cpp:198] M2PELU26 needs backward computation.
I1001 19:09:22.552381  5547 net.cpp:198] Scale27 needs backward computation.
I1001 19:09:22.552384  5547 net.cpp:198] BatchNorm27 needs backward computation.
I1001 19:09:22.552387  5547 net.cpp:198] Convolution27 needs backward computation.
I1001 19:09:22.552389  5547 net.cpp:198] Eltwise12_M2PELU25_0_split needs backward computation.
I1001 19:09:22.552392  5547 net.cpp:198] M2PELU25 needs backward computation.
I1001 19:09:22.552395  5547 net.cpp:198] Eltwise12 needs backward computation.
I1001 19:09:22.552398  5547 net.cpp:198] Scale26 needs backward computation.
I1001 19:09:22.552402  5547 net.cpp:198] BatchNorm26 needs backward computation.
I1001 19:09:22.552404  5547 net.cpp:198] Convolution26 needs backward computation.
I1001 19:09:22.552407  5547 net.cpp:198] M2PELU24 needs backward computation.
I1001 19:09:22.552409  5547 net.cpp:198] Scale25 needs backward computation.
I1001 19:09:22.552412  5547 net.cpp:198] BatchNorm25 needs backward computation.
I1001 19:09:22.552414  5547 net.cpp:198] Convolution25 needs backward computation.
I1001 19:09:22.552417  5547 net.cpp:198] Eltwise11_M2PELU23_0_split needs backward computation.
I1001 19:09:22.552420  5547 net.cpp:198] M2PELU23 needs backward computation.
I1001 19:09:22.552423  5547 net.cpp:198] Eltwise11 needs backward computation.
I1001 19:09:22.552425  5547 net.cpp:198] Scale24 needs backward computation.
I1001 19:09:22.552428  5547 net.cpp:198] BatchNorm24 needs backward computation.
I1001 19:09:22.552430  5547 net.cpp:198] Convolution24 needs backward computation.
I1001 19:09:22.552433  5547 net.cpp:198] M2PELU22 needs backward computation.
I1001 19:09:22.552435  5547 net.cpp:198] Scale23 needs backward computation.
I1001 19:09:22.552438  5547 net.cpp:198] BatchNorm23 needs backward computation.
I1001 19:09:22.552440  5547 net.cpp:198] Convolution23 needs backward computation.
I1001 19:09:22.552443  5547 net.cpp:198] Eltwise10_M2PELU21_0_split needs backward computation.
I1001 19:09:22.552446  5547 net.cpp:198] M2PELU21 needs backward computation.
I1001 19:09:22.552449  5547 net.cpp:198] Eltwise10 needs backward computation.
I1001 19:09:22.552453  5547 net.cpp:198] Scale22 needs backward computation.
I1001 19:09:22.552454  5547 net.cpp:198] BatchNorm22 needs backward computation.
I1001 19:09:22.552458  5547 net.cpp:198] Convolution22 needs backward computation.
I1001 19:09:22.552460  5547 net.cpp:198] M2PELU20 needs backward computation.
I1001 19:09:22.552464  5547 net.cpp:198] Scale21 needs backward computation.
I1001 19:09:22.552465  5547 net.cpp:198] BatchNorm21 needs backward computation.
I1001 19:09:22.552469  5547 net.cpp:198] Convolution21 needs backward computation.
I1001 19:09:22.552470  5547 net.cpp:198] Scale20 needs backward computation.
I1001 19:09:22.552474  5547 net.cpp:198] BatchNorm20 needs backward computation.
I1001 19:09:22.552475  5547 net.cpp:198] Convolution20 needs backward computation.
I1001 19:09:22.552479  5547 net.cpp:198] Eltwise9_M2PELU19_0_split needs backward computation.
I1001 19:09:22.552481  5547 net.cpp:198] M2PELU19 needs backward computation.
I1001 19:09:22.552484  5547 net.cpp:198] Eltwise9 needs backward computation.
I1001 19:09:22.552491  5547 net.cpp:198] Scale19 needs backward computation.
I1001 19:09:22.552495  5547 net.cpp:198] BatchNorm19 needs backward computation.
I1001 19:09:22.552496  5547 net.cpp:198] Convolution19 needs backward computation.
I1001 19:09:22.552500  5547 net.cpp:198] M2PELU18 needs backward computation.
I1001 19:09:22.552501  5547 net.cpp:198] Scale18 needs backward computation.
I1001 19:09:22.552505  5547 net.cpp:198] BatchNorm18 needs backward computation.
I1001 19:09:22.552507  5547 net.cpp:198] Convolution18 needs backward computation.
I1001 19:09:22.552510  5547 net.cpp:198] Eltwise8_M2PELU17_0_split needs backward computation.
I1001 19:09:22.552512  5547 net.cpp:198] M2PELU17 needs backward computation.
I1001 19:09:22.552515  5547 net.cpp:198] Eltwise8 needs backward computation.
I1001 19:09:22.552518  5547 net.cpp:198] Scale17 needs backward computation.
I1001 19:09:22.552521  5547 net.cpp:198] BatchNorm17 needs backward computation.
I1001 19:09:22.552523  5547 net.cpp:198] Convolution17 needs backward computation.
I1001 19:09:22.552526  5547 net.cpp:198] M2PELU16 needs backward computation.
I1001 19:09:22.552530  5547 net.cpp:198] Scale16 needs backward computation.
I1001 19:09:22.552531  5547 net.cpp:198] BatchNorm16 needs backward computation.
I1001 19:09:22.552533  5547 net.cpp:198] Convolution16 needs backward computation.
I1001 19:09:22.554610  5547 net.cpp:198] Eltwise7_M2PELU15_0_split needs backward computation.
I1001 19:09:22.554613  5547 net.cpp:198] M2PELU15 needs backward computation.
I1001 19:09:22.554616  5547 net.cpp:198] Eltwise7 needs backward computation.
I1001 19:09:22.554620  5547 net.cpp:198] Scale15 needs backward computation.
I1001 19:09:22.554622  5547 net.cpp:198] BatchNorm15 needs backward computation.
I1001 19:09:22.554625  5547 net.cpp:198] Convolution15 needs backward computation.
I1001 19:09:22.554627  5547 net.cpp:198] M2PELU14 needs backward computation.
I1001 19:09:22.554630  5547 net.cpp:198] Scale14 needs backward computation.
I1001 19:09:22.554632  5547 net.cpp:198] BatchNorm14 needs backward computation.
I1001 19:09:22.554635  5547 net.cpp:198] Convolution14 needs backward computation.
I1001 19:09:22.554637  5547 net.cpp:198] Eltwise6_M2PELU13_0_split needs backward computation.
I1001 19:09:22.554642  5547 net.cpp:198] M2PELU13 needs backward computation.
I1001 19:09:22.554644  5547 net.cpp:198] Eltwise6 needs backward computation.
I1001 19:09:22.554648  5547 net.cpp:198] Scale13 needs backward computation.
I1001 19:09:22.554651  5547 net.cpp:198] BatchNorm13 needs backward computation.
I1001 19:09:22.554653  5547 net.cpp:198] Convolution13 needs backward computation.
I1001 19:09:22.554656  5547 net.cpp:198] M2PELU12 needs backward computation.
I1001 19:09:22.554658  5547 net.cpp:198] Scale12 needs backward computation.
I1001 19:09:22.554661  5547 net.cpp:198] BatchNorm12 needs backward computation.
I1001 19:09:22.554663  5547 net.cpp:198] Convolution12 needs backward computation.
I1001 19:09:22.554666  5547 net.cpp:198] Eltwise5_M2PELU11_0_split needs backward computation.
I1001 19:09:22.554669  5547 net.cpp:198] M2PELU11 needs backward computation.
I1001 19:09:22.554672  5547 net.cpp:198] Eltwise5 needs backward computation.
I1001 19:09:22.554674  5547 net.cpp:198] Scale11 needs backward computation.
I1001 19:09:22.554677  5547 net.cpp:198] BatchNorm11 needs backward computation.
I1001 19:09:22.554679  5547 net.cpp:198] Convolution11 needs backward computation.
I1001 19:09:22.554682  5547 net.cpp:198] M2PELU10 needs backward computation.
I1001 19:09:22.554685  5547 net.cpp:198] Scale10 needs backward computation.
I1001 19:09:22.554687  5547 net.cpp:198] BatchNorm10 needs backward computation.
I1001 19:09:22.554690  5547 net.cpp:198] Convolution10 needs backward computation.
I1001 19:09:22.554693  5547 net.cpp:198] Eltwise4_M2PELU9_0_split needs backward computation.
I1001 19:09:22.554697  5547 net.cpp:198] M2PELU9 needs backward computation.
I1001 19:09:22.554698  5547 net.cpp:198] Eltwise4 needs backward computation.
I1001 19:09:22.554708  5547 net.cpp:198] Scale9 needs backward computation.
I1001 19:09:22.554710  5547 net.cpp:198] BatchNorm9 needs backward computation.
I1001 19:09:22.554713  5547 net.cpp:198] Convolution9 needs backward computation.
I1001 19:09:22.554715  5547 net.cpp:198] M2PELU8 needs backward computation.
I1001 19:09:22.554718  5547 net.cpp:198] Scale8 needs backward computation.
I1001 19:09:22.554721  5547 net.cpp:198] BatchNorm8 needs backward computation.
I1001 19:09:22.554723  5547 net.cpp:198] Convolution8 needs backward computation.
I1001 19:09:22.554726  5547 net.cpp:198] Eltwise3_M2PELU7_0_split needs backward computation.
I1001 19:09:22.554729  5547 net.cpp:198] M2PELU7 needs backward computation.
I1001 19:09:22.554733  5547 net.cpp:198] Eltwise3 needs backward computation.
I1001 19:09:22.554735  5547 net.cpp:198] Scale7 needs backward computation.
I1001 19:09:22.554738  5547 net.cpp:198] BatchNorm7 needs backward computation.
I1001 19:09:22.554740  5547 net.cpp:198] Convolution7 needs backward computation.
I1001 19:09:22.554742  5547 net.cpp:198] M2PELU6 needs backward computation.
I1001 19:09:22.554745  5547 net.cpp:198] Scale6 needs backward computation.
I1001 19:09:22.554749  5547 net.cpp:198] BatchNorm6 needs backward computation.
I1001 19:09:22.554750  5547 net.cpp:198] Convolution6 needs backward computation.
I1001 19:09:22.554754  5547 net.cpp:198] Eltwise2_M2PELU5_0_split needs backward computation.
I1001 19:09:22.554756  5547 net.cpp:198] M2PELU5 needs backward computation.
I1001 19:09:22.554759  5547 net.cpp:198] Eltwise2 needs backward computation.
I1001 19:09:22.554762  5547 net.cpp:198] Scale5 needs backward computation.
I1001 19:09:22.554765  5547 net.cpp:198] BatchNorm5 needs backward computation.
I1001 19:09:22.554769  5547 net.cpp:198] Convolution5 needs backward computation.
I1001 19:09:22.554770  5547 net.cpp:198] M2PELU4 needs backward computation.
I1001 19:09:22.554774  5547 net.cpp:198] Scale4 needs backward computation.
I1001 19:09:22.554775  5547 net.cpp:198] BatchNorm4 needs backward computation.
I1001 19:09:22.554778  5547 net.cpp:198] Convolution4 needs backward computation.
I1001 19:09:22.554781  5547 net.cpp:198] Eltwise1_M2PELU3_0_split needs backward computation.
I1001 19:09:22.554785  5547 net.cpp:198] M2PELU3 needs backward computation.
I1001 19:09:22.554786  5547 net.cpp:198] Eltwise1 needs backward computation.
I1001 19:09:22.554790  5547 net.cpp:198] Scale3 needs backward computation.
I1001 19:09:22.554792  5547 net.cpp:198] BatchNorm3 needs backward computation.
I1001 19:09:22.554795  5547 net.cpp:198] Convolution3 needs backward computation.
I1001 19:09:22.554798  5547 net.cpp:198] M2PELU2 needs backward computation.
I1001 19:09:22.554800  5547 net.cpp:198] Scale2 needs backward computation.
I1001 19:09:22.554803  5547 net.cpp:198] BatchNorm2 needs backward computation.
I1001 19:09:22.554805  5547 net.cpp:198] Convolution2 needs backward computation.
I1001 19:09:22.554808  5547 net.cpp:198] Convolution1_M2PELU1_0_split needs backward computation.
I1001 19:09:22.554812  5547 net.cpp:198] M2PELU1 needs backward computation.
I1001 19:09:22.554814  5547 net.cpp:198] Scale1 needs backward computation.
I1001 19:09:22.554817  5547 net.cpp:198] BatchNorm1 needs backward computation.
I1001 19:09:22.554819  5547 net.cpp:198] Convolution1 needs backward computation.
I1001 19:09:22.554823  5547 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I1001 19:09:22.554826  5547 net.cpp:200] Data1 does not need backward computation.
I1001 19:09:22.554829  5547 net.cpp:242] This network produces output Accuracy1
I1001 19:09:22.554832  5547 net.cpp:242] This network produces output SoftmaxWithLoss1
I1001 19:09:22.554939  5547 net.cpp:255] Network initialization done.
I1001 19:09:22.555781  5547 solver.cpp:56] Solver scaffolding done.
I1001 19:09:22.570284  5547 caffe.cpp:248] Starting Optimization
I1001 19:09:22.570293  5547 solver.cpp:272] Solving resnet_cifar10
I1001 19:09:22.570296  5547 solver.cpp:273] Learning Rate Policy: multistep
I1001 19:09:22.577029  5547 solver.cpp:330] Iteration 0, Testing net (#0)
I1001 19:09:26.022734  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:09:26.161907  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I1001 19:09:26.161932  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I1001 19:09:26.358616  5547 solver.cpp:218] Iteration 0 (0.0600938 iter/s, 3.78822s/100 iters), loss = 2.30286
I1001 19:09:26.358646  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.30286 (* 1 = 2.30286 loss)
I1001 19:09:26.358657  5547 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1001 19:09:40.593061  5547 solver.cpp:218] Iteration 100 (7.02529 iter/s, 14.2343s/100 iters), loss = 1.71138
I1001 19:09:40.593103  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.71138 (* 1 = 1.71138 loss)
I1001 19:09:40.593111  5547 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1001 19:09:54.828096  5547 solver.cpp:218] Iteration 200 (7.02501 iter/s, 14.2349s/100 iters), loss = 1.68476
I1001 19:09:54.828188  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.68476 (* 1 = 1.68476 loss)
I1001 19:09:54.828196  5547 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1001 19:10:09.054711  5547 solver.cpp:218] Iteration 300 (7.02919 iter/s, 14.2264s/100 iters), loss = 1.29042
I1001 19:10:09.054744  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.29042 (* 1 = 1.29042 loss)
I1001 19:10:09.054751  5547 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1001 19:10:23.278749  5547 solver.cpp:218] Iteration 400 (7.03043 iter/s, 14.2239s/100 iters), loss = 1.05883
I1001 19:10:23.278781  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.05883 (* 1 = 1.05883 loss)
I1001 19:10:23.278789  5547 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1001 19:10:36.819409  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:10:37.387598  5547 solver.cpp:330] Iteration 500, Testing net (#0)
I1001 19:10:40.753237  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:10:40.892937  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3363
I1001 19:10:40.892973  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.69148 (* 1 = 2.69148 loss)
I1001 19:10:41.033965  5547 solver.cpp:218] Iteration 500 (5.63221 iter/s, 17.755s/100 iters), loss = 1.16247
I1001 19:10:41.033993  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.16247 (* 1 = 1.16247 loss)
I1001 19:10:41.033999  5547 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1001 19:10:55.280758  5547 solver.cpp:218] Iteration 600 (7.0192 iter/s, 14.2466s/100 iters), loss = 1.02073
I1001 19:10:55.280799  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.02073 (* 1 = 1.02073 loss)
I1001 19:10:55.280805  5547 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1001 19:11:09.531579  5547 solver.cpp:218] Iteration 700 (7.01722 iter/s, 14.2507s/100 iters), loss = 1.13735
I1001 19:11:09.531679  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.13735 (* 1 = 1.13735 loss)
I1001 19:11:09.531687  5547 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1001 19:11:23.780814  5547 solver.cpp:218] Iteration 800 (7.01803 iter/s, 14.249s/100 iters), loss = 0.957983
I1001 19:11:23.780855  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.957983 (* 1 = 0.957983 loss)
I1001 19:11:23.780861  5547 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1001 19:11:38.036542  5547 solver.cpp:218] Iteration 900 (7.0148 iter/s, 14.2556s/100 iters), loss = 0.75878
I1001 19:11:38.036573  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.75878 (* 1 = 0.75878 loss)
I1001 19:11:38.036590  5547 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1001 19:11:51.576074  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:11:52.143931  5547 solver.cpp:330] Iteration 1000, Testing net (#0)
I1001 19:11:55.508543  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:11:55.648882  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4628
I1001 19:11:55.648917  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.58656 (* 1 = 1.58656 loss)
I1001 19:11:55.789497  5547 solver.cpp:218] Iteration 1000 (5.63292 iter/s, 17.7528s/100 iters), loss = 0.964778
I1001 19:11:55.789527  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.964778 (* 1 = 0.964778 loss)
I1001 19:11:55.789535  5547 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1001 19:12:10.042346  5547 solver.cpp:218] Iteration 1100 (7.01621 iter/s, 14.2527s/100 iters), loss = 0.72675
I1001 19:12:10.042376  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.72675 (* 1 = 0.72675 loss)
I1001 19:12:10.042383  5547 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1001 19:12:24.295668  5547 solver.cpp:218] Iteration 1200 (7.01598 iter/s, 14.2532s/100 iters), loss = 0.960863
I1001 19:12:24.295789  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.960863 (* 1 = 0.960863 loss)
I1001 19:12:24.295799  5547 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1001 19:12:38.541379  5547 solver.cpp:218] Iteration 1300 (7.01978 iter/s, 14.2455s/100 iters), loss = 0.853625
I1001 19:12:38.541411  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.853625 (* 1 = 0.853625 loss)
I1001 19:12:38.541417  5547 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1001 19:12:52.780508  5547 solver.cpp:218] Iteration 1400 (7.02297 iter/s, 14.239s/100 iters), loss = 0.659682
I1001 19:12:52.780549  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.659682 (* 1 = 0.659682 loss)
I1001 19:12:52.780555  5547 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1001 19:13:06.327317  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:13:06.896754  5547 solver.cpp:330] Iteration 1500, Testing net (#0)
I1001 19:13:10.262711  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:13:10.402683  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5357
I1001 19:13:10.402719  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.32819 (* 1 = 1.32819 loss)
I1001 19:13:10.543301  5547 solver.cpp:218] Iteration 1500 (5.6298 iter/s, 17.7626s/100 iters), loss = 0.925942
I1001 19:13:10.543335  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.925942 (* 1 = 0.925942 loss)
I1001 19:13:10.543342  5547 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1001 19:13:24.787916  5547 solver.cpp:218] Iteration 1600 (7.02027 iter/s, 14.2445s/100 iters), loss = 0.670777
I1001 19:13:24.787948  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.670777 (* 1 = 0.670777 loss)
I1001 19:13:24.787955  5547 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1001 19:13:39.027482  5547 solver.cpp:218] Iteration 1700 (7.02274 iter/s, 14.2395s/100 iters), loss = 0.708896
I1001 19:13:39.027627  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.708896 (* 1 = 0.708896 loss)
I1001 19:13:39.027647  5547 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1001 19:13:53.290076  5547 solver.cpp:218] Iteration 1800 (7.01145 iter/s, 14.2624s/100 iters), loss = 0.728465
I1001 19:13:53.290119  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.728465 (* 1 = 0.728465 loss)
I1001 19:13:53.290127  5547 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1001 19:14:07.551158  5547 solver.cpp:218] Iteration 1900 (7.01215 iter/s, 14.261s/100 iters), loss = 0.605027
I1001 19:14:07.551192  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.605027 (* 1 = 0.605027 loss)
I1001 19:14:07.551198  5547 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1001 19:14:21.085644  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:14:21.661968  5547 solver.cpp:330] Iteration 2000, Testing net (#0)
I1001 19:14:25.029615  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:14:25.169118  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6263
I1001 19:14:25.169153  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.1516 (* 1 = 1.1516 loss)
I1001 19:14:25.310322  5547 solver.cpp:218] Iteration 2000 (5.63093 iter/s, 17.7591s/100 iters), loss = 0.697991
I1001 19:14:25.310353  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.697991 (* 1 = 0.697991 loss)
I1001 19:14:25.310359  5547 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1001 19:14:39.568878  5547 solver.cpp:218] Iteration 2100 (7.01338 iter/s, 14.2585s/100 iters), loss = 0.591006
I1001 19:14:39.568912  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.591006 (* 1 = 0.591006 loss)
I1001 19:14:39.568918  5547 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1001 19:14:53.815742  5547 solver.cpp:218] Iteration 2200 (7.01913 iter/s, 14.2468s/100 iters), loss = 0.635241
I1001 19:14:53.815874  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.635241 (* 1 = 0.635241 loss)
I1001 19:14:53.815882  5547 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1001 19:15:08.063671  5547 solver.cpp:218] Iteration 2300 (7.01865 iter/s, 14.2477s/100 iters), loss = 0.632368
I1001 19:15:08.063714  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.632368 (* 1 = 0.632368 loss)
I1001 19:15:08.063719  5547 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1001 19:15:22.322440  5547 solver.cpp:218] Iteration 2400 (7.01328 iter/s, 14.2587s/100 iters), loss = 0.495641
I1001 19:15:22.322470  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.495641 (* 1 = 0.495641 loss)
I1001 19:15:22.322476  5547 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1001 19:15:35.864459  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:15:36.442617  5547 solver.cpp:330] Iteration 2500, Testing net (#0)
I1001 19:15:39.808349  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:15:39.948681  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5073
I1001 19:15:39.948717  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.29654 (* 1 = 1.29654 loss)
I1001 19:15:40.090324  5547 solver.cpp:218] Iteration 2500 (5.62816 iter/s, 17.7678s/100 iters), loss = 0.665221
I1001 19:15:40.090355  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.665221 (* 1 = 0.665221 loss)
I1001 19:15:40.090363  5547 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1001 19:15:54.353122  5547 solver.cpp:218] Iteration 2600 (7.01129 iter/s, 14.2627s/100 iters), loss = 0.511313
I1001 19:15:54.353173  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.511313 (* 1 = 0.511313 loss)
I1001 19:15:54.353180  5547 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1001 19:16:08.623355  5547 solver.cpp:218] Iteration 2700 (7.00765 iter/s, 14.2701s/100 iters), loss = 0.532115
I1001 19:16:08.623463  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.532115 (* 1 = 0.532115 loss)
I1001 19:16:08.623471  5547 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1001 19:16:22.905094  5547 solver.cpp:218] Iteration 2800 (7.00203 iter/s, 14.2816s/100 iters), loss = 0.554915
I1001 19:16:22.905135  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.554915 (* 1 = 0.554915 loss)
I1001 19:16:22.905141  5547 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1001 19:16:37.176571  5547 solver.cpp:218] Iteration 2900 (7.00703 iter/s, 14.2714s/100 iters), loss = 0.492508
I1001 19:16:37.176614  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.492508 (* 1 = 0.492508 loss)
I1001 19:16:37.176620  5547 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1001 19:16:50.721477  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:16:51.299490  5547 solver.cpp:330] Iteration 3000, Testing net (#0)
I1001 19:16:54.670848  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:16:54.810561  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5129
I1001 19:16:54.810597  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.42908 (* 1 = 1.42908 loss)
I1001 19:16:54.952163  5547 solver.cpp:218] Iteration 3000 (5.62573 iter/s, 17.7755s/100 iters), loss = 0.535449
I1001 19:16:54.952196  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.535449 (* 1 = 0.535449 loss)
I1001 19:16:54.952203  5547 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1001 19:17:09.223908  5547 solver.cpp:218] Iteration 3100 (7.00692 iter/s, 14.2716s/100 iters), loss = 0.384606
I1001 19:17:09.223945  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.384606 (* 1 = 0.384606 loss)
I1001 19:17:09.223953  5547 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1001 19:17:23.493718  5547 solver.cpp:218] Iteration 3200 (7.00785 iter/s, 14.2697s/100 iters), loss = 0.486905
I1001 19:17:23.493896  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.486905 (* 1 = 0.486905 loss)
I1001 19:17:23.493904  5547 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1001 19:17:37.769192  5547 solver.cpp:218] Iteration 3300 (7.00513 iter/s, 14.2753s/100 iters), loss = 0.609208
I1001 19:17:37.769240  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.609208 (* 1 = 0.609208 loss)
I1001 19:17:37.769248  5547 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1001 19:17:52.059828  5547 solver.cpp:218] Iteration 3400 (6.99764 iter/s, 14.2905s/100 iters), loss = 0.446184
I1001 19:17:52.059859  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.446184 (* 1 = 0.446184 loss)
I1001 19:17:52.059865  5547 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1001 19:18:05.628255  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:18:06.199930  5547 solver.cpp:330] Iteration 3500, Testing net (#0)
I1001 19:18:09.571480  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:18:09.711714  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5392
I1001 19:18:09.711750  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.48041 (* 1 = 1.48041 loss)
I1001 19:18:09.853415  5547 solver.cpp:218] Iteration 3500 (5.62003 iter/s, 17.7935s/100 iters), loss = 0.547128
I1001 19:18:09.853448  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.547128 (* 1 = 0.547128 loss)
I1001 19:18:09.853456  5547 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1001 19:18:24.098011  5547 solver.cpp:218] Iteration 3600 (7.02025 iter/s, 14.2445s/100 iters), loss = 0.369079
I1001 19:18:24.098040  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.369079 (* 1 = 0.369079 loss)
I1001 19:18:24.098047  5547 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1001 19:18:38.372305  5547 solver.cpp:218] Iteration 3700 (7.00564 iter/s, 14.2742s/100 iters), loss = 0.47672
I1001 19:18:38.372416  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.47672 (* 1 = 0.47672 loss)
I1001 19:18:38.372427  5547 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1001 19:18:52.657943  5547 solver.cpp:218] Iteration 3800 (7.00011 iter/s, 14.2855s/100 iters), loss = 0.454981
I1001 19:18:52.657974  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.454981 (* 1 = 0.454981 loss)
I1001 19:18:52.657980  5547 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1001 19:19:06.923310  5547 solver.cpp:218] Iteration 3900 (7.01003 iter/s, 14.2653s/100 iters), loss = 0.510639
I1001 19:19:06.923352  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.510639 (* 1 = 0.510639 loss)
I1001 19:19:06.923359  5547 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1001 19:19:20.476541  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:19:21.045675  5547 solver.cpp:330] Iteration 4000, Testing net (#0)
I1001 19:19:24.426848  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:19:24.566829  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5973
I1001 19:19:24.566857  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.22539 (* 1 = 1.22539 loss)
I1001 19:19:24.708881  5547 solver.cpp:218] Iteration 4000 (5.62257 iter/s, 17.7855s/100 iters), loss = 0.47175
I1001 19:19:24.708927  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.47175 (* 1 = 0.47175 loss)
I1001 19:19:24.708935  5547 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1001 19:19:38.974951  5547 solver.cpp:218] Iteration 4100 (7.00969 iter/s, 14.266s/100 iters), loss = 0.329931
I1001 19:19:38.974982  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329931 (* 1 = 0.329931 loss)
I1001 19:19:38.974987  5547 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1001 19:19:53.237922  5547 solver.cpp:218] Iteration 4200 (7.0112 iter/s, 14.2629s/100 iters), loss = 0.41079
I1001 19:19:53.238092  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.41079 (* 1 = 0.41079 loss)
I1001 19:19:53.238101  5547 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1001 19:20:07.510175  5547 solver.cpp:218] Iteration 4300 (7.00671 iter/s, 14.272s/100 iters), loss = 0.499928
I1001 19:20:07.510207  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.499928 (* 1 = 0.499928 loss)
I1001 19:20:07.510213  5547 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1001 19:20:21.785969  5547 solver.cpp:218] Iteration 4400 (7.00491 iter/s, 14.2757s/100 iters), loss = 0.382605
I1001 19:20:21.786002  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.382605 (* 1 = 0.382605 loss)
I1001 19:20:21.786008  5547 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1001 19:20:35.334255  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:20:35.904899  5547 solver.cpp:330] Iteration 4500, Testing net (#0)
I1001 19:20:39.272405  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:20:39.414955  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4843
I1001 19:20:39.414981  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.53527 (* 1 = 1.53527 loss)
I1001 19:20:39.556823  5547 solver.cpp:218] Iteration 4500 (5.62722 iter/s, 17.7708s/100 iters), loss = 0.45466
I1001 19:20:39.556859  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.45466 (* 1 = 0.45466 loss)
I1001 19:20:39.556866  5547 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1001 19:20:53.802942  5547 solver.cpp:218] Iteration 4600 (7.0195 iter/s, 14.246s/100 iters), loss = 0.371065
I1001 19:20:53.802973  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371065 (* 1 = 0.371065 loss)
I1001 19:20:53.802978  5547 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1001 19:21:08.070901  5547 solver.cpp:218] Iteration 4700 (7.00875 iter/s, 14.2679s/100 iters), loss = 0.40172
I1001 19:21:08.071009  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.40172 (* 1 = 0.40172 loss)
I1001 19:21:08.071017  5547 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1001 19:21:22.333519  5547 solver.cpp:218] Iteration 4800 (7.01141 iter/s, 14.2625s/100 iters), loss = 0.511741
I1001 19:21:22.333554  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.511741 (* 1 = 0.511741 loss)
I1001 19:21:22.333564  5547 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1001 19:21:36.594249  5547 solver.cpp:218] Iteration 4900 (7.01231 iter/s, 14.2606s/100 iters), loss = 0.379428
I1001 19:21:36.594285  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.379428 (* 1 = 0.379428 loss)
I1001 19:21:36.594291  5547 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1001 19:21:50.147333  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:21:50.716359  5547 solver.cpp:330] Iteration 5000, Testing net (#0)
I1001 19:21:54.080987  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:21:54.224763  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4883
I1001 19:21:54.224804  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.4692 (* 1 = 1.4692 loss)
I1001 19:21:54.370276  5547 solver.cpp:218] Iteration 5000 (5.62559 iter/s, 17.7759s/100 iters), loss = 0.397662
I1001 19:21:54.370314  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.397662 (* 1 = 0.397662 loss)
I1001 19:21:54.370322  5547 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I1001 19:22:08.631628  5547 solver.cpp:218] Iteration 5100 (7.01202 iter/s, 14.2612s/100 iters), loss = 0.424503
I1001 19:22:08.631669  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.424503 (* 1 = 0.424503 loss)
I1001 19:22:08.631676  5547 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I1001 19:22:22.891487  5547 solver.cpp:218] Iteration 5200 (7.01273 iter/s, 14.2598s/100 iters), loss = 0.438311
I1001 19:22:22.891628  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.438311 (* 1 = 0.438311 loss)
I1001 19:22:22.891635  5547 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I1001 19:22:37.158808  5547 solver.cpp:218] Iteration 5300 (7.00912 iter/s, 14.2671s/100 iters), loss = 0.410473
I1001 19:22:37.158841  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.410473 (* 1 = 0.410473 loss)
I1001 19:22:37.158849  5547 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I1001 19:22:51.434303  5547 solver.cpp:218] Iteration 5400 (7.00506 iter/s, 14.2754s/100 iters), loss = 0.374635
I1001 19:22:51.434360  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.374635 (* 1 = 0.374635 loss)
I1001 19:22:51.434366  5547 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I1001 19:23:04.982105  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:23:05.550562  5547 solver.cpp:330] Iteration 5500, Testing net (#0)
I1001 19:23:08.912835  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:23:09.052498  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5803
I1001 19:23:09.052521  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.2858 (* 1 = 1.2858 loss)
I1001 19:23:09.194355  5547 solver.cpp:218] Iteration 5500 (5.63065 iter/s, 17.7599s/100 iters), loss = 0.370529
I1001 19:23:09.194391  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.370529 (* 1 = 0.370529 loss)
I1001 19:23:09.194397  5547 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I1001 19:23:23.454382  5547 solver.cpp:218] Iteration 5600 (7.01265 iter/s, 14.2599s/100 iters), loss = 0.368871
I1001 19:23:23.454413  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.368871 (* 1 = 0.368871 loss)
I1001 19:23:23.454419  5547 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I1001 19:23:37.725373  5547 solver.cpp:218] Iteration 5700 (7.00726 iter/s, 14.2709s/100 iters), loss = 0.355483
I1001 19:23:37.725497  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355483 (* 1 = 0.355483 loss)
I1001 19:23:37.725504  5547 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I1001 19:23:51.986321  5547 solver.cpp:218] Iteration 5800 (7.01224 iter/s, 14.2608s/100 iters), loss = 0.450199
I1001 19:23:51.986353  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.450199 (* 1 = 0.450199 loss)
I1001 19:23:51.986359  5547 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I1001 19:24:06.250115  5547 solver.cpp:218] Iteration 5900 (7.0108 iter/s, 14.2637s/100 iters), loss = 0.364476
I1001 19:24:06.250152  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.364476 (* 1 = 0.364476 loss)
I1001 19:24:06.250159  5547 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I1001 19:24:19.808768  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:24:20.378549  5547 solver.cpp:330] Iteration 6000, Testing net (#0)
I1001 19:24:23.743708  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:24:23.883020  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5877
I1001 19:24:23.883044  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.24393 (* 1 = 1.24393 loss)
I1001 19:24:24.023888  5547 solver.cpp:218] Iteration 6000 (5.6263 iter/s, 17.7737s/100 iters), loss = 0.37132
I1001 19:24:24.023918  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.37132 (* 1 = 0.37132 loss)
I1001 19:24:24.023926  5547 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I1001 19:24:38.282491  5547 solver.cpp:218] Iteration 6100 (7.01335 iter/s, 14.2585s/100 iters), loss = 0.37039
I1001 19:24:38.282534  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.37039 (* 1 = 0.37039 loss)
I1001 19:24:38.282541  5547 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I1001 19:24:52.537708  5547 solver.cpp:218] Iteration 6200 (7.01502 iter/s, 14.2551s/100 iters), loss = 0.4124
I1001 19:24:52.537886  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.4124 (* 1 = 0.4124 loss)
I1001 19:24:52.537895  5547 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I1001 19:25:06.809758  5547 solver.cpp:218] Iteration 6300 (7.00681 iter/s, 14.2718s/100 iters), loss = 0.418481
I1001 19:25:06.809801  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.418481 (* 1 = 0.418481 loss)
I1001 19:25:06.809808  5547 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I1001 19:25:21.065604  5547 solver.cpp:218] Iteration 6400 (7.01471 iter/s, 14.2558s/100 iters), loss = 0.300045
I1001 19:25:21.065634  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300045 (* 1 = 0.300045 loss)
I1001 19:25:21.065640  5547 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I1001 19:25:34.620048  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:25:35.188495  5547 solver.cpp:330] Iteration 6500, Testing net (#0)
I1001 19:25:38.551486  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:25:38.691479  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6551
I1001 19:25:38.691515  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.01883 (* 1 = 1.01883 loss)
I1001 19:25:38.832451  5547 solver.cpp:218] Iteration 6500 (5.62849 iter/s, 17.7668s/100 iters), loss = 0.385581
I1001 19:25:38.832480  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.385581 (* 1 = 0.385581 loss)
I1001 19:25:38.832487  5547 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I1001 19:25:53.097718  5547 solver.cpp:218] Iteration 6600 (7.01007 iter/s, 14.2652s/100 iters), loss = 0.309515
I1001 19:25:53.097748  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309515 (* 1 = 0.309515 loss)
I1001 19:25:53.097754  5547 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I1001 19:26:07.364332  5547 solver.cpp:218] Iteration 6700 (7.00941 iter/s, 14.2665s/100 iters), loss = 0.37968
I1001 19:26:07.364452  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.37968 (* 1 = 0.37968 loss)
I1001 19:26:07.364470  5547 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I1001 19:26:21.622375  5547 solver.cpp:218] Iteration 6800 (7.01366 iter/s, 14.2579s/100 iters), loss = 0.444465
I1001 19:26:21.622409  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.444465 (* 1 = 0.444465 loss)
I1001 19:26:21.622416  5547 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I1001 19:26:35.883893  5547 solver.cpp:218] Iteration 6900 (7.01191 iter/s, 14.2614s/100 iters), loss = 0.379341
I1001 19:26:35.883922  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.379341 (* 1 = 0.379341 loss)
I1001 19:26:35.883929  5547 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I1001 19:26:49.447701  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:26:50.016685  5547 solver.cpp:330] Iteration 7000, Testing net (#0)
I1001 19:26:53.379909  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:26:53.519526  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6367
I1001 19:26:53.519560  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.01496 (* 1 = 1.01496 loss)
I1001 19:26:53.660267  5547 solver.cpp:218] Iteration 7000 (5.62547 iter/s, 17.7763s/100 iters), loss = 0.361213
I1001 19:26:53.660301  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.361213 (* 1 = 0.361213 loss)
I1001 19:26:53.660308  5547 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I1001 19:27:07.920264  5547 solver.cpp:218] Iteration 7100 (7.01266 iter/s, 14.2599s/100 iters), loss = 0.301355
I1001 19:27:07.920294  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301355 (* 1 = 0.301355 loss)
I1001 19:27:07.920300  5547 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I1001 19:27:22.187259  5547 solver.cpp:218] Iteration 7200 (7.00922 iter/s, 14.2669s/100 iters), loss = 0.428688
I1001 19:27:22.187422  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.428688 (* 1 = 0.428688 loss)
I1001 19:27:22.187441  5547 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I1001 19:27:36.453361  5547 solver.cpp:218] Iteration 7300 (7.00973 iter/s, 14.2659s/100 iters), loss = 0.338816
I1001 19:27:36.453408  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338816 (* 1 = 0.338816 loss)
I1001 19:27:36.453415  5547 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I1001 19:27:50.705595  5547 solver.cpp:218] Iteration 7400 (7.01651 iter/s, 14.2521s/100 iters), loss = 0.302753
I1001 19:27:50.705636  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302753 (* 1 = 0.302753 loss)
I1001 19:27:50.705641  5547 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I1001 19:28:04.261134  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:28:04.830736  5547 solver.cpp:330] Iteration 7500, Testing net (#0)
I1001 19:28:08.194998  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:28:08.334528  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6815
I1001 19:28:08.334564  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.967947 (* 1 = 0.967947 loss)
I1001 19:28:08.475034  5547 solver.cpp:218] Iteration 7500 (5.62767 iter/s, 17.7693s/100 iters), loss = 0.318913
I1001 19:28:08.475069  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.318913 (* 1 = 0.318913 loss)
I1001 19:28:08.475075  5547 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I1001 19:28:22.745570  5547 solver.cpp:218] Iteration 7600 (7.00748 iter/s, 14.2705s/100 iters), loss = 0.357878
I1001 19:28:22.745599  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.357878 (* 1 = 0.357878 loss)
I1001 19:28:22.745606  5547 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I1001 19:28:37.014552  5547 solver.cpp:218] Iteration 7700 (7.00825 iter/s, 14.2689s/100 iters), loss = 0.408214
I1001 19:28:37.014629  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.408214 (* 1 = 0.408214 loss)
I1001 19:28:37.014637  5547 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I1001 19:28:51.276993  5547 solver.cpp:218] Iteration 7800 (7.01148 iter/s, 14.2623s/100 iters), loss = 0.415066
I1001 19:28:51.277029  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.415066 (* 1 = 0.415066 loss)
I1001 19:28:51.277036  5547 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I1001 19:29:05.544576  5547 solver.cpp:218] Iteration 7900 (7.00894 iter/s, 14.2675s/100 iters), loss = 0.393607
I1001 19:29:05.544616  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.393607 (* 1 = 0.393607 loss)
I1001 19:29:05.544622  5547 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I1001 19:29:19.111634  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:29:19.682333  5547 solver.cpp:330] Iteration 8000, Testing net (#0)
I1001 19:29:23.042372  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:29:23.182471  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.802
I1001 19:29:23.182507  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.621022 (* 1 = 0.621022 loss)
I1001 19:29:23.323151  5547 solver.cpp:218] Iteration 8000 (5.62478 iter/s, 17.7785s/100 iters), loss = 0.305462
I1001 19:29:23.323181  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305462 (* 1 = 0.305462 loss)
I1001 19:29:23.323189  5547 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I1001 19:29:37.577042  5547 solver.cpp:218] Iteration 8100 (7.01566 iter/s, 14.2538s/100 iters), loss = 0.230868
I1001 19:29:37.577072  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230868 (* 1 = 0.230868 loss)
I1001 19:29:37.577078  5547 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I1001 19:29:51.849236  5547 solver.cpp:218] Iteration 8200 (7.00667 iter/s, 14.2721s/100 iters), loss = 0.411323
I1001 19:29:51.849383  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.411323 (* 1 = 0.411323 loss)
I1001 19:29:51.849402  5547 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I1001 19:30:06.105185  5547 solver.cpp:218] Iteration 8300 (7.01471 iter/s, 14.2558s/100 iters), loss = 0.326464
I1001 19:30:06.105214  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326464 (* 1 = 0.326464 loss)
I1001 19:30:06.105221  5547 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I1001 19:30:20.360003  5547 solver.cpp:218] Iteration 8400 (7.01521 iter/s, 14.2547s/100 iters), loss = 0.31373
I1001 19:30:20.360033  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31373 (* 1 = 0.31373 loss)
I1001 19:30:20.360038  5547 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I1001 19:30:33.923020  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:30:34.491410  5547 solver.cpp:330] Iteration 8500, Testing net (#0)
I1001 19:30:37.855217  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:30:37.995246  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7421
I1001 19:30:37.995271  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.761064 (* 1 = 0.761064 loss)
I1001 19:30:38.136132  5547 solver.cpp:218] Iteration 8500 (5.62555 iter/s, 17.776s/100 iters), loss = 0.350534
I1001 19:30:38.136163  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350534 (* 1 = 0.350534 loss)
I1001 19:30:38.136170  5547 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I1001 19:30:52.401782  5547 solver.cpp:218] Iteration 8600 (7.00988 iter/s, 14.2656s/100 iters), loss = 0.250837
I1001 19:30:52.401813  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250837 (* 1 = 0.250837 loss)
I1001 19:30:52.401819  5547 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I1001 19:31:06.664311  5547 solver.cpp:218] Iteration 8700 (7.01142 iter/s, 14.2625s/100 iters), loss = 0.327777
I1001 19:31:06.664459  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327777 (* 1 = 0.327777 loss)
I1001 19:31:06.664469  5547 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I1001 19:31:20.926822  5547 solver.cpp:218] Iteration 8800 (7.01148 iter/s, 14.2623s/100 iters), loss = 0.421513
I1001 19:31:20.926853  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.421513 (* 1 = 0.421513 loss)
I1001 19:31:20.926859  5547 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I1001 19:31:35.204082  5547 solver.cpp:218] Iteration 8900 (7.00418 iter/s, 14.2772s/100 iters), loss = 0.227906
I1001 19:31:35.204113  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227906 (* 1 = 0.227906 loss)
I1001 19:31:35.204121  5547 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I1001 19:31:48.761044  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:31:49.329941  5547 solver.cpp:330] Iteration 9000, Testing net (#0)
I1001 19:31:52.694656  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:31:52.834488  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8022
I1001 19:31:52.834527  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.585141 (* 1 = 0.585141 loss)
I1001 19:31:52.975409  5547 solver.cpp:218] Iteration 9000 (5.62707 iter/s, 17.7712s/100 iters), loss = 0.287333
I1001 19:31:52.975447  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287333 (* 1 = 0.287333 loss)
I1001 19:31:52.975455  5547 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I1001 19:32:07.236894  5547 solver.cpp:218] Iteration 9100 (7.01193 iter/s, 14.2614s/100 iters), loss = 0.242486
I1001 19:32:07.236928  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242486 (* 1 = 0.242486 loss)
I1001 19:32:07.236946  5547 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I1001 19:32:21.511586  5547 solver.cpp:218] Iteration 9200 (7.00545 iter/s, 14.2746s/100 iters), loss = 0.331517
I1001 19:32:21.511732  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331517 (* 1 = 0.331517 loss)
I1001 19:32:21.511740  5547 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I1001 19:32:35.770493  5547 solver.cpp:218] Iteration 9300 (7.01325 iter/s, 14.2587s/100 iters), loss = 0.293729
I1001 19:32:35.770529  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293729 (* 1 = 0.293729 loss)
I1001 19:32:35.770535  5547 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I1001 19:32:50.033301  5547 solver.cpp:218] Iteration 9400 (7.01128 iter/s, 14.2627s/100 iters), loss = 0.245034
I1001 19:32:50.033331  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245034 (* 1 = 0.245034 loss)
I1001 19:32:50.033337  5547 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I1001 19:33:03.593590  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:33:04.162562  5547 solver.cpp:330] Iteration 9500, Testing net (#0)
I1001 19:33:07.528856  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:33:07.668782  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7879
I1001 19:33:07.668817  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.597177 (* 1 = 0.597177 loss)
I1001 19:33:07.809361  5547 solver.cpp:218] Iteration 9500 (5.62557 iter/s, 17.776s/100 iters), loss = 0.210565
I1001 19:33:07.809394  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210565 (* 1 = 0.210565 loss)
I1001 19:33:07.809401  5547 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I1001 19:33:22.078627  5547 solver.cpp:218] Iteration 9600 (7.00811 iter/s, 14.2692s/100 iters), loss = 0.28072
I1001 19:33:22.078658  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28072 (* 1 = 0.28072 loss)
I1001 19:33:22.078665  5547 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I1001 19:33:36.340445  5547 solver.cpp:218] Iteration 9700 (7.01177 iter/s, 14.2617s/100 iters), loss = 0.30579
I1001 19:33:36.340566  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30579 (* 1 = 0.30579 loss)
I1001 19:33:36.340586  5547 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I1001 19:33:50.615281  5547 solver.cpp:218] Iteration 9800 (7.00543 iter/s, 14.2746s/100 iters), loss = 0.28218
I1001 19:33:50.615322  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28218 (* 1 = 0.28218 loss)
I1001 19:33:50.615329  5547 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I1001 19:34:04.900846  5547 solver.cpp:218] Iteration 9900 (7.00011 iter/s, 14.2855s/100 iters), loss = 0.282979
I1001 19:34:04.900876  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28298 (* 1 = 0.28298 loss)
I1001 19:34:04.900883  5547 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I1001 19:34:18.459975  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:34:19.030097  5547 solver.cpp:330] Iteration 10000, Testing net (#0)
I1001 19:34:22.392760  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:34:22.532647  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8205
I1001 19:34:22.532682  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.537558 (* 1 = 0.537558 loss)
I1001 19:34:22.673290  5547 solver.cpp:218] Iteration 10000 (5.62672 iter/s, 17.7724s/100 iters), loss = 0.328964
I1001 19:34:22.673331  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328964 (* 1 = 0.328964 loss)
I1001 19:34:22.673339  5547 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I1001 19:34:36.942203  5547 solver.cpp:218] Iteration 10100 (7.00828 iter/s, 14.2688s/100 iters), loss = 0.322229
I1001 19:34:36.942234  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322229 (* 1 = 0.322229 loss)
I1001 19:34:36.942239  5547 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I1001 19:34:51.201388  5547 solver.cpp:218] Iteration 10200 (7.01306 iter/s, 14.2591s/100 iters), loss = 0.285825
I1001 19:34:51.201519  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285825 (* 1 = 0.285825 loss)
I1001 19:34:51.201526  5547 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I1001 19:35:05.457840  5547 solver.cpp:218] Iteration 10300 (7.01445 iter/s, 14.2563s/100 iters), loss = 0.310842
I1001 19:35:05.457870  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310842 (* 1 = 0.310842 loss)
I1001 19:35:05.457875  5547 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I1001 19:35:19.722183  5547 solver.cpp:218] Iteration 10400 (7.01052 iter/s, 14.2643s/100 iters), loss = 0.245717
I1001 19:35:19.722225  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245717 (* 1 = 0.245717 loss)
I1001 19:35:19.722231  5547 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I1001 19:35:33.273555  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:35:33.849297  5547 solver.cpp:330] Iteration 10500, Testing net (#0)
I1001 19:35:37.215585  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:35:37.355288  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7168
I1001 19:35:37.355314  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.948676 (* 1 = 0.948676 loss)
I1001 19:35:37.496184  5547 solver.cpp:218] Iteration 10500 (5.62622 iter/s, 17.7739s/100 iters), loss = 0.273586
I1001 19:35:37.496217  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273586 (* 1 = 0.273586 loss)
I1001 19:35:37.496223  5547 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I1001 19:35:51.745827  5547 solver.cpp:218] Iteration 10600 (7.01776 iter/s, 14.2496s/100 iters), loss = 0.333292
I1001 19:35:51.745862  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333292 (* 1 = 0.333292 loss)
I1001 19:35:51.745868  5547 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I1001 19:36:06.000974  5547 solver.cpp:218] Iteration 10700 (7.01505 iter/s, 14.2551s/100 iters), loss = 0.35066
I1001 19:36:06.001093  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35066 (* 1 = 0.35066 loss)
I1001 19:36:06.001101  5547 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I1001 19:36:20.270289  5547 solver.cpp:218] Iteration 10800 (7.00812 iter/s, 14.2692s/100 iters), loss = 0.351676
I1001 19:36:20.270319  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351676 (* 1 = 0.351676 loss)
I1001 19:36:20.270325  5547 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I1001 19:36:34.525539  5547 solver.cpp:218] Iteration 10900 (7.015 iter/s, 14.2552s/100 iters), loss = 0.19706
I1001 19:36:34.525569  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197061 (* 1 = 0.197061 loss)
I1001 19:36:34.525575  5547 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I1001 19:36:48.060758  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:36:48.639382  5547 solver.cpp:330] Iteration 11000, Testing net (#0)
I1001 19:36:52.006956  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:36:52.146613  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7884
I1001 19:36:52.146648  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.645854 (* 1 = 0.645854 loss)
I1001 19:36:52.287484  5547 solver.cpp:218] Iteration 11000 (5.63004 iter/s, 17.7619s/100 iters), loss = 0.256347
I1001 19:36:52.287520  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256347 (* 1 = 0.256347 loss)
I1001 19:36:52.287528  5547 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I1001 19:37:06.550817  5547 solver.cpp:218] Iteration 11100 (7.01102 iter/s, 14.2633s/100 iters), loss = 0.271212
I1001 19:37:06.550853  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271212 (* 1 = 0.271212 loss)
I1001 19:37:06.550860  5547 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I1001 19:37:20.804483  5547 solver.cpp:218] Iteration 11200 (7.01578 iter/s, 14.2536s/100 iters), loss = 0.208042
I1001 19:37:20.804594  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208043 (* 1 = 0.208043 loss)
I1001 19:37:20.804612  5547 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I1001 19:37:35.062755  5547 solver.cpp:218] Iteration 11300 (7.01354 iter/s, 14.2581s/100 iters), loss = 0.301791
I1001 19:37:35.062786  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301791 (* 1 = 0.301791 loss)
I1001 19:37:35.062793  5547 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I1001 19:37:49.327061  5547 solver.cpp:218] Iteration 11400 (7.01054 iter/s, 14.2642s/100 iters), loss = 0.310608
I1001 19:37:49.327093  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310608 (* 1 = 0.310608 loss)
I1001 19:37:49.327109  5547 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I1001 19:38:02.886670  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:38:03.462944  5547 solver.cpp:330] Iteration 11500, Testing net (#0)
I1001 19:38:06.826155  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:38:06.966040  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7282
I1001 19:38:06.966065  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.84287 (* 1 = 0.84287 loss)
I1001 19:38:07.106961  5547 solver.cpp:218] Iteration 11500 (5.62436 iter/s, 17.7798s/100 iters), loss = 0.217346
I1001 19:38:07.106995  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217346 (* 1 = 0.217346 loss)
I1001 19:38:07.107002  5547 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I1001 19:38:21.360349  5547 solver.cpp:218] Iteration 11600 (7.01591 iter/s, 14.2533s/100 iters), loss = 0.250987
I1001 19:38:21.360385  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250987 (* 1 = 0.250987 loss)
I1001 19:38:21.360404  5547 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I1001 19:38:35.630481  5547 solver.cpp:218] Iteration 11700 (7.0077 iter/s, 14.27s/100 iters), loss = 0.389263
I1001 19:38:35.630604  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.389263 (* 1 = 0.389263 loss)
I1001 19:38:35.630622  5547 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I1001 19:38:49.905854  5547 solver.cpp:218] Iteration 11800 (7.00515 iter/s, 14.2752s/100 iters), loss = 0.326768
I1001 19:38:49.905884  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326768 (* 1 = 0.326768 loss)
I1001 19:38:49.905890  5547 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I1001 19:39:04.167081  5547 solver.cpp:218] Iteration 11900 (7.01205 iter/s, 14.2612s/100 iters), loss = 0.199193
I1001 19:39:04.167112  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199194 (* 1 = 0.199194 loss)
I1001 19:39:04.167119  5547 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I1001 19:39:17.722098  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:39:18.292317  5547 solver.cpp:330] Iteration 12000, Testing net (#0)
I1001 19:39:21.666993  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:39:21.806912  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7859
I1001 19:39:21.806939  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.689126 (* 1 = 0.689126 loss)
I1001 19:39:21.947917  5547 solver.cpp:218] Iteration 12000 (5.62406 iter/s, 17.7808s/100 iters), loss = 0.240182
I1001 19:39:21.947952  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240182 (* 1 = 0.240182 loss)
I1001 19:39:21.947958  5547 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I1001 19:39:36.201521  5547 solver.cpp:218] Iteration 12100 (7.01581 iter/s, 14.2535s/100 iters), loss = 0.271937
I1001 19:39:36.201562  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271937 (* 1 = 0.271937 loss)
I1001 19:39:36.201568  5547 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I1001 19:39:50.458240  5547 solver.cpp:218] Iteration 12200 (7.01428 iter/s, 14.2566s/100 iters), loss = 0.342238
I1001 19:39:50.458351  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342238 (* 1 = 0.342238 loss)
I1001 19:39:50.458367  5547 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I1001 19:40:04.717710  5547 solver.cpp:218] Iteration 12300 (7.01296 iter/s, 14.2593s/100 iters), loss = 0.367042
I1001 19:40:04.717742  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.367042 (* 1 = 0.367042 loss)
I1001 19:40:04.717748  5547 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I1001 19:40:18.986280  5547 solver.cpp:218] Iteration 12400 (7.00845 iter/s, 14.2685s/100 iters), loss = 0.267561
I1001 19:40:18.986312  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267561 (* 1 = 0.267561 loss)
I1001 19:40:18.986320  5547 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I1001 19:40:32.533598  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:40:33.101763  5547 solver.cpp:330] Iteration 12500, Testing net (#0)
I1001 19:40:36.471951  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:40:36.613410  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.82
I1001 19:40:36.613445  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.561023 (* 1 = 0.561023 loss)
I1001 19:40:36.754655  5547 solver.cpp:218] Iteration 12500 (5.628 iter/s, 17.7683s/100 iters), loss = 0.261621
I1001 19:40:36.754691  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261621 (* 1 = 0.261621 loss)
I1001 19:40:36.754699  5547 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I1001 19:40:51.008777  5547 solver.cpp:218] Iteration 12600 (7.01556 iter/s, 14.254s/100 iters), loss = 0.244634
I1001 19:40:51.008819  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244634 (* 1 = 0.244634 loss)
I1001 19:40:51.008826  5547 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I1001 19:41:05.280145  5547 solver.cpp:218] Iteration 12700 (7.00708 iter/s, 14.2713s/100 iters), loss = 0.341155
I1001 19:41:05.280233  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.341156 (* 1 = 0.341156 loss)
I1001 19:41:05.280251  5547 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I1001 19:41:19.550843  5547 solver.cpp:218] Iteration 12800 (7.00743 iter/s, 14.2706s/100 iters), loss = 0.303586
I1001 19:41:19.550873  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303586 (* 1 = 0.303586 loss)
I1001 19:41:19.550879  5547 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I1001 19:41:33.806746  5547 solver.cpp:218] Iteration 12900 (7.01468 iter/s, 14.2558s/100 iters), loss = 0.218056
I1001 19:41:33.806788  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218056 (* 1 = 0.218056 loss)
I1001 19:41:33.806795  5547 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I1001 19:41:47.362715  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:41:47.931035  5547 solver.cpp:330] Iteration 13000, Testing net (#0)
I1001 19:41:51.299038  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:41:51.444211  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7641
I1001 19:41:51.444250  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.79174 (* 1 = 0.79174 loss)
I1001 19:41:51.587635  5547 solver.cpp:218] Iteration 13000 (5.62405 iter/s, 17.7808s/100 iters), loss = 0.211755
I1001 19:41:51.587671  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211756 (* 1 = 0.211756 loss)
I1001 19:41:51.587678  5547 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I1001 19:42:05.838994  5547 solver.cpp:218] Iteration 13100 (7.01691 iter/s, 14.2513s/100 iters), loss = 0.261543
I1001 19:42:05.839026  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261543 (* 1 = 0.261543 loss)
I1001 19:42:05.839032  5547 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I1001 19:42:20.097142  5547 solver.cpp:218] Iteration 13200 (7.01357 iter/s, 14.2581s/100 iters), loss = 0.310974
I1001 19:42:20.097262  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310975 (* 1 = 0.310975 loss)
I1001 19:42:20.097280  5547 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I1001 19:42:34.367987  5547 solver.cpp:218] Iteration 13300 (7.00737 iter/s, 14.2707s/100 iters), loss = 0.219544
I1001 19:42:34.368031  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219544 (* 1 = 0.219544 loss)
I1001 19:42:34.368036  5547 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I1001 19:42:48.643446  5547 solver.cpp:218] Iteration 13400 (7.00507 iter/s, 14.2754s/100 iters), loss = 0.258745
I1001 19:42:48.643481  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258745 (* 1 = 0.258745 loss)
I1001 19:42:48.643489  5547 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I1001 19:43:02.193723  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:43:02.762621  5547 solver.cpp:330] Iteration 13500, Testing net (#0)
I1001 19:43:06.124569  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:43:06.264516  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.715
I1001 19:43:06.264544  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.00217 (* 1 = 1.00217 loss)
I1001 19:43:06.409148  5547 solver.cpp:218] Iteration 13500 (5.62885 iter/s, 17.7656s/100 iters), loss = 0.317902
I1001 19:43:06.409183  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317902 (* 1 = 0.317902 loss)
I1001 19:43:06.409190  5547 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I1001 19:43:20.666946  5547 solver.cpp:218] Iteration 13600 (7.01375 iter/s, 14.2577s/100 iters), loss = 0.185566
I1001 19:43:20.666988  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185566 (* 1 = 0.185566 loss)
I1001 19:43:20.666995  5547 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I1001 19:43:34.943574  5547 solver.cpp:218] Iteration 13700 (7.0045 iter/s, 14.2765s/100 iters), loss = 0.433716
I1001 19:43:34.943686  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.433716 (* 1 = 0.433716 loss)
I1001 19:43:34.943693  5547 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I1001 19:43:49.202844  5547 solver.cpp:218] Iteration 13800 (7.01306 iter/s, 14.2591s/100 iters), loss = 0.213849
I1001 19:43:49.202877  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213849 (* 1 = 0.213849 loss)
I1001 19:43:49.202883  5547 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I1001 19:44:03.467295  5547 solver.cpp:218] Iteration 13900 (7.01047 iter/s, 14.2644s/100 iters), loss = 0.244221
I1001 19:44:03.467334  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244221 (* 1 = 0.244221 loss)
I1001 19:44:03.467340  5547 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I1001 19:44:17.022549  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:44:17.589709  5547 solver.cpp:330] Iteration 14000, Testing net (#0)
I1001 19:44:20.954948  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:44:21.094761  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7798
I1001 19:44:21.094797  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.657637 (* 1 = 0.657637 loss)
I1001 19:44:21.236177  5547 solver.cpp:218] Iteration 14000 (5.62784 iter/s, 17.7688s/100 iters), loss = 0.251888
I1001 19:44:21.236207  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251888 (* 1 = 0.251888 loss)
I1001 19:44:21.236214  5547 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I1001 19:44:35.530740  5547 solver.cpp:218] Iteration 14100 (6.9957 iter/s, 14.2945s/100 iters), loss = 0.258133
I1001 19:44:35.530771  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258133 (* 1 = 0.258133 loss)
I1001 19:44:35.530776  5547 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I1001 19:44:49.821672  5547 solver.cpp:218] Iteration 14200 (6.99748 iter/s, 14.2909s/100 iters), loss = 0.352108
I1001 19:44:49.821815  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.352109 (* 1 = 0.352109 loss)
I1001 19:44:49.821821  5547 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I1001 19:45:04.126613  5547 solver.cpp:218] Iteration 14300 (6.99068 iter/s, 14.3048s/100 iters), loss = 0.302323
I1001 19:45:04.126655  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302323 (* 1 = 0.302323 loss)
I1001 19:45:04.126662  5547 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I1001 19:45:18.414746  5547 solver.cpp:218] Iteration 14400 (6.99886 iter/s, 14.288s/100 iters), loss = 0.198854
I1001 19:45:18.414783  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198855 (* 1 = 0.198855 loss)
I1001 19:45:18.414789  5547 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I1001 19:45:31.995539  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:45:32.564797  5547 solver.cpp:330] Iteration 14500, Testing net (#0)
I1001 19:45:35.933143  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:45:36.073619  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7918
I1001 19:45:36.073644  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.619074 (* 1 = 0.619074 loss)
I1001 19:45:36.215431  5547 solver.cpp:218] Iteration 14500 (5.61779 iter/s, 17.8006s/100 iters), loss = 0.22915
I1001 19:45:36.215461  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22915 (* 1 = 0.22915 loss)
I1001 19:45:36.215467  5547 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I1001 19:45:50.507763  5547 solver.cpp:218] Iteration 14600 (6.99679 iter/s, 14.2923s/100 iters), loss = 0.197601
I1001 19:45:50.507794  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197601 (* 1 = 0.197601 loss)
I1001 19:45:50.507800  5547 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I1001 19:46:04.797950  5547 solver.cpp:218] Iteration 14700 (6.99784 iter/s, 14.2901s/100 iters), loss = 0.220866
I1001 19:46:04.798074  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220866 (* 1 = 0.220866 loss)
I1001 19:46:04.798082  5547 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I1001 19:46:19.080446  5547 solver.cpp:218] Iteration 14800 (7.00166 iter/s, 14.2823s/100 iters), loss = 0.252335
I1001 19:46:19.080487  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252336 (* 1 = 0.252336 loss)
I1001 19:46:19.080492  5547 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I1001 19:46:33.366456  5547 solver.cpp:218] Iteration 14900 (6.9999 iter/s, 14.2859s/100 iters), loss = 0.238967
I1001 19:46:33.366508  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238967 (* 1 = 0.238967 loss)
I1001 19:46:33.366516  5547 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I1001 19:46:46.948827  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:46:47.519317  5547 solver.cpp:330] Iteration 15000, Testing net (#0)
I1001 19:46:50.892091  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:46:51.031430  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8069
I1001 19:46:51.031466  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.611367 (* 1 = 0.611367 loss)
I1001 19:46:51.172703  5547 solver.cpp:218] Iteration 15000 (5.61605 iter/s, 17.8061s/100 iters), loss = 0.186509
I1001 19:46:51.172734  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186509 (* 1 = 0.186509 loss)
I1001 19:46:51.172741  5547 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I1001 19:47:05.451355  5547 solver.cpp:218] Iteration 15100 (7.0035 iter/s, 14.2786s/100 iters), loss = 0.174349
I1001 19:47:05.451396  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174349 (* 1 = 0.174349 loss)
I1001 19:47:05.451403  5547 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I1001 19:47:19.742027  5547 solver.cpp:218] Iteration 15200 (6.99761 iter/s, 14.2906s/100 iters), loss = 0.276648
I1001 19:47:19.742138  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276648 (* 1 = 0.276648 loss)
I1001 19:47:19.742146  5547 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I1001 19:47:34.033095  5547 solver.cpp:218] Iteration 15300 (6.99745 iter/s, 14.2909s/100 iters), loss = 0.253786
I1001 19:47:34.033128  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253786 (* 1 = 0.253786 loss)
I1001 19:47:34.033133  5547 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I1001 19:47:48.306569  5547 solver.cpp:218] Iteration 15400 (7.00604 iter/s, 14.2734s/100 iters), loss = 0.161565
I1001 19:47:48.306615  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161565 (* 1 = 0.161565 loss)
I1001 19:47:48.306623  5547 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I1001 19:48:01.883612  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:48:02.453140  5547 solver.cpp:330] Iteration 15500, Testing net (#0)
I1001 19:48:05.824209  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:48:05.964196  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.817
I1001 19:48:05.964221  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.54902 (* 1 = 0.54902 loss)
I1001 19:48:06.106011  5547 solver.cpp:218] Iteration 15500 (5.61819 iter/s, 17.7993s/100 iters), loss = 0.225711
I1001 19:48:06.106045  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225711 (* 1 = 0.225711 loss)
I1001 19:48:06.106051  5547 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I1001 19:48:20.388424  5547 solver.cpp:218] Iteration 15600 (7.00165 iter/s, 14.2823s/100 iters), loss = 0.22593
I1001 19:48:20.388465  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225931 (* 1 = 0.225931 loss)
I1001 19:48:20.388471  5547 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I1001 19:48:34.670728  5547 solver.cpp:218] Iteration 15700 (7.00171 iter/s, 14.2822s/100 iters), loss = 0.238903
I1001 19:48:34.670876  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238903 (* 1 = 0.238903 loss)
I1001 19:48:34.670882  5547 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I1001 19:48:48.947111  5547 solver.cpp:218] Iteration 15800 (7.00467 iter/s, 14.2762s/100 iters), loss = 0.32644
I1001 19:48:48.947152  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326441 (* 1 = 0.326441 loss)
I1001 19:48:48.947160  5547 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I1001 19:49:03.229619  5547 solver.cpp:218] Iteration 15900 (7.00161 iter/s, 14.2824s/100 iters), loss = 0.218323
I1001 19:49:03.229650  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218323 (* 1 = 0.218323 loss)
I1001 19:49:03.229656  5547 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I1001 19:49:16.803424  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:49:17.373778  5547 solver.cpp:330] Iteration 16000, Testing net (#0)
I1001 19:49:20.743124  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:49:20.882736  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7516
I1001 19:49:20.882771  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.756612 (* 1 = 0.756612 loss)
I1001 19:49:21.024336  5547 solver.cpp:218] Iteration 16000 (5.61967 iter/s, 17.7946s/100 iters), loss = 0.208205
I1001 19:49:21.024376  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208205 (* 1 = 0.208205 loss)
I1001 19:49:21.024384  5547 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I1001 19:49:35.300369  5547 solver.cpp:218] Iteration 16100 (7.00479 iter/s, 14.276s/100 iters), loss = 0.219867
I1001 19:49:35.300400  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219867 (* 1 = 0.219867 loss)
I1001 19:49:35.300406  5547 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I1001 19:49:49.592428  5547 solver.cpp:218] Iteration 16200 (6.99693 iter/s, 14.292s/100 iters), loss = 0.257154
I1001 19:49:49.592543  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257154 (* 1 = 0.257154 loss)
I1001 19:49:49.592550  5547 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I1001 19:50:03.887027  5547 solver.cpp:218] Iteration 16300 (6.99572 iter/s, 14.2945s/100 iters), loss = 0.274789
I1001 19:50:03.887060  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274789 (* 1 = 0.274789 loss)
I1001 19:50:03.887068  5547 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I1001 19:50:18.160648  5547 solver.cpp:218] Iteration 16400 (7.00597 iter/s, 14.2735s/100 iters), loss = 0.18242
I1001 19:50:18.160677  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18242 (* 1 = 0.18242 loss)
I1001 19:50:18.160683  5547 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I1001 19:50:31.745175  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:50:32.314755  5547 solver.cpp:330] Iteration 16500, Testing net (#0)
I1001 19:50:35.686565  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:50:35.826692  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6713
I1001 19:50:35.826728  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.12472 (* 1 = 1.12472 loss)
I1001 19:50:35.967737  5547 solver.cpp:218] Iteration 16500 (5.61577 iter/s, 17.807s/100 iters), loss = 0.256288
I1001 19:50:35.967768  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256288 (* 1 = 0.256288 loss)
I1001 19:50:35.967775  5547 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I1001 19:50:50.259577  5547 solver.cpp:218] Iteration 16600 (6.99704 iter/s, 14.2918s/100 iters), loss = 0.263815
I1001 19:50:50.259613  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263815 (* 1 = 0.263815 loss)
I1001 19:50:50.259619  5547 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I1001 19:51:04.539309  5547 solver.cpp:218] Iteration 16700 (7.00297 iter/s, 14.2797s/100 iters), loss = 0.300086
I1001 19:51:04.539489  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300086 (* 1 = 0.300086 loss)
I1001 19:51:04.539520  5547 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I1001 19:51:18.833051  5547 solver.cpp:218] Iteration 16800 (6.99617 iter/s, 14.2935s/100 iters), loss = 0.307684
I1001 19:51:18.833082  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307684 (* 1 = 0.307684 loss)
I1001 19:51:18.833089  5547 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I1001 19:51:33.116554  5547 solver.cpp:218] Iteration 16900 (7.00112 iter/s, 14.2834s/100 iters), loss = 0.159458
I1001 19:51:33.116583  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159458 (* 1 = 0.159458 loss)
I1001 19:51:33.116590  5547 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I1001 19:51:46.695848  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:51:47.265457  5547 solver.cpp:330] Iteration 17000, Testing net (#0)
I1001 19:51:50.635692  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:51:50.775563  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.82
I1001 19:51:50.775599  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.548245 (* 1 = 0.548245 loss)
I1001 19:51:50.916812  5547 solver.cpp:218] Iteration 17000 (5.61792 iter/s, 17.8002s/100 iters), loss = 0.217837
I1001 19:51:50.916843  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217837 (* 1 = 0.217837 loss)
I1001 19:51:50.916851  5547 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I1001 19:52:05.196815  5547 solver.cpp:218] Iteration 17100 (7.00283 iter/s, 14.2799s/100 iters), loss = 0.257805
I1001 19:52:05.196856  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257805 (* 1 = 0.257805 loss)
I1001 19:52:05.196863  5547 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I1001 19:52:19.475754  5547 solver.cpp:218] Iteration 17200 (7.00336 iter/s, 14.2789s/100 iters), loss = 0.245051
I1001 19:52:19.475878  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245051 (* 1 = 0.245051 loss)
I1001 19:52:19.475885  5547 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I1001 19:52:33.751612  5547 solver.cpp:218] Iteration 17300 (7.00491 iter/s, 14.2757s/100 iters), loss = 0.266551
I1001 19:52:33.751643  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266552 (* 1 = 0.266552 loss)
I1001 19:52:33.751651  5547 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I1001 19:52:48.015543  5547 solver.cpp:218] Iteration 17400 (7.01073 iter/s, 14.2639s/100 iters), loss = 0.284121
I1001 19:52:48.015573  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284121 (* 1 = 0.284121 loss)
I1001 19:52:48.015580  5547 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I1001 19:53:01.596808  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:53:02.167085  5547 solver.cpp:330] Iteration 17500, Testing net (#0)
I1001 19:53:05.539433  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:53:05.679250  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7487
I1001 19:53:05.679275  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.833318 (* 1 = 0.833318 loss)
I1001 19:53:05.820786  5547 solver.cpp:218] Iteration 17500 (5.61635 iter/s, 17.8052s/100 iters), loss = 0.183948
I1001 19:53:05.820821  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183948 (* 1 = 0.183948 loss)
I1001 19:53:05.820828  5547 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I1001 19:53:20.110432  5547 solver.cpp:218] Iteration 17600 (6.99811 iter/s, 14.2896s/100 iters), loss = 0.144979
I1001 19:53:20.110465  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144979 (* 1 = 0.144979 loss)
I1001 19:53:20.110471  5547 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I1001 19:53:34.400475  5547 solver.cpp:218] Iteration 17700 (6.99792 iter/s, 14.29s/100 iters), loss = 0.221483
I1001 19:53:34.400609  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221483 (* 1 = 0.221483 loss)
I1001 19:53:34.400617  5547 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I1001 19:53:48.700587  5547 solver.cpp:218] Iteration 17800 (6.99304 iter/s, 14.2999s/100 iters), loss = 0.200755
I1001 19:53:48.700621  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200755 (* 1 = 0.200755 loss)
I1001 19:53:48.700628  5547 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I1001 19:54:02.990685  5547 solver.cpp:218] Iteration 17900 (6.99789 iter/s, 14.29s/100 iters), loss = 0.165177
I1001 19:54:02.990715  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165178 (* 1 = 0.165178 loss)
I1001 19:54:02.990721  5547 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I1001 19:54:16.570803  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:54:17.141240  5547 solver.cpp:330] Iteration 18000, Testing net (#0)
I1001 19:54:20.510555  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:54:20.651146  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8436
I1001 19:54:20.651181  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.473158 (* 1 = 0.473158 loss)
I1001 19:54:20.793483  5547 solver.cpp:218] Iteration 18000 (5.61712 iter/s, 17.8027s/100 iters), loss = 0.242699
I1001 19:54:20.793519  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242699 (* 1 = 0.242699 loss)
I1001 19:54:20.793526  5547 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I1001 19:54:35.081382  5547 solver.cpp:218] Iteration 18100 (6.99897 iter/s, 14.2878s/100 iters), loss = 0.330852
I1001 19:54:35.081426  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330852 (* 1 = 0.330852 loss)
I1001 19:54:35.081434  5547 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I1001 19:54:49.376232  5547 solver.cpp:218] Iteration 18200 (6.99557 iter/s, 14.2948s/100 iters), loss = 0.182207
I1001 19:54:49.376376  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182207 (* 1 = 0.182207 loss)
I1001 19:54:49.376384  5547 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I1001 19:55:03.662433  5547 solver.cpp:218] Iteration 18300 (6.99985 iter/s, 14.286s/100 iters), loss = 0.366607
I1001 19:55:03.662468  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366607 (* 1 = 0.366607 loss)
I1001 19:55:03.662475  5547 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I1001 19:55:17.941663  5547 solver.cpp:218] Iteration 18400 (7.00322 iter/s, 14.2792s/100 iters), loss = 0.232932
I1001 19:55:17.941694  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232932 (* 1 = 0.232932 loss)
I1001 19:55:17.941701  5547 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I1001 19:55:31.533360  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:55:32.102638  5547 solver.cpp:330] Iteration 18500, Testing net (#0)
I1001 19:55:35.473238  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:55:35.612723  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8239
I1001 19:55:35.612748  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.515042 (* 1 = 0.515042 loss)
I1001 19:55:35.754088  5547 solver.cpp:218] Iteration 18500 (5.61409 iter/s, 17.8123s/100 iters), loss = 0.189837
I1001 19:55:35.754122  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189837 (* 1 = 0.189837 loss)
I1001 19:55:35.754129  5547 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I1001 19:55:50.031466  5547 solver.cpp:218] Iteration 18600 (7.00413 iter/s, 14.2773s/100 iters), loss = 0.244718
I1001 19:55:50.031499  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244718 (* 1 = 0.244718 loss)
I1001 19:55:50.031507  5547 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I1001 19:56:04.320464  5547 solver.cpp:218] Iteration 18700 (6.99843 iter/s, 14.2889s/100 iters), loss = 0.333007
I1001 19:56:04.320564  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333007 (* 1 = 0.333007 loss)
I1001 19:56:04.320588  5547 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I1001 19:56:18.615160  5547 solver.cpp:218] Iteration 18800 (6.99567 iter/s, 14.2945s/100 iters), loss = 0.289788
I1001 19:56:18.615196  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289787 (* 1 = 0.289787 loss)
I1001 19:56:18.615205  5547 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I1001 19:56:32.895746  5547 solver.cpp:218] Iteration 18900 (7.00255 iter/s, 14.2805s/100 iters), loss = 0.180806
I1001 19:56:32.895778  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180806 (* 1 = 0.180806 loss)
I1001 19:56:32.895786  5547 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I1001 19:56:46.467792  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:56:47.036830  5547 solver.cpp:330] Iteration 19000, Testing net (#0)
I1001 19:56:50.406666  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:56:50.545929  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7999
I1001 19:56:50.545964  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.646474 (* 1 = 0.646474 loss)
I1001 19:56:50.687708  5547 solver.cpp:218] Iteration 19000 (5.62054 iter/s, 17.7919s/100 iters), loss = 0.146588
I1001 19:56:50.687741  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146588 (* 1 = 0.146588 loss)
I1001 19:56:50.687748  5547 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I1001 19:57:04.970995  5547 solver.cpp:218] Iteration 19100 (7.00123 iter/s, 14.2832s/100 iters), loss = 0.219781
I1001 19:57:04.971026  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219781 (* 1 = 0.219781 loss)
I1001 19:57:04.971034  5547 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I1001 19:57:19.260984  5547 solver.cpp:218] Iteration 19200 (6.99794 iter/s, 14.2899s/100 iters), loss = 0.27711
I1001 19:57:19.261127  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27711 (* 1 = 0.27711 loss)
I1001 19:57:19.261137  5547 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I1001 19:57:33.531235  5547 solver.cpp:218] Iteration 19300 (7.00768 iter/s, 14.2701s/100 iters), loss = 0.153331
I1001 19:57:33.531282  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153331 (* 1 = 0.153331 loss)
I1001 19:57:33.531291  5547 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I1001 19:57:47.806708  5547 solver.cpp:218] Iteration 19400 (7.00508 iter/s, 14.2754s/100 iters), loss = 0.178969
I1001 19:57:47.806742  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178969 (* 1 = 0.178969 loss)
I1001 19:57:47.806748  5547 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I1001 19:58:01.378010  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:58:01.947448  5547 solver.cpp:330] Iteration 19500, Testing net (#0)
I1001 19:58:05.317369  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:58:05.457751  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.82
I1001 19:58:05.457774  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.569657 (* 1 = 0.569657 loss)
I1001 19:58:05.598537  5547 solver.cpp:218] Iteration 19500 (5.62058 iter/s, 17.7917s/100 iters), loss = 0.2198
I1001 19:58:05.598577  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2198 (* 1 = 0.2198 loss)
I1001 19:58:05.598593  5547 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I1001 19:58:19.872427  5547 solver.cpp:218] Iteration 19600 (7.00592 iter/s, 14.2736s/100 iters), loss = 0.167716
I1001 19:58:19.872470  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167716 (* 1 = 0.167716 loss)
I1001 19:58:19.872478  5547 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I1001 19:58:34.160509  5547 solver.cpp:218] Iteration 19700 (6.99888 iter/s, 14.288s/100 iters), loss = 0.151776
I1001 19:58:34.160668  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151776 (* 1 = 0.151776 loss)
I1001 19:58:34.160677  5547 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I1001 19:58:48.438869  5547 solver.cpp:218] Iteration 19800 (7.0037 iter/s, 14.2782s/100 iters), loss = 0.143518
I1001 19:58:48.438916  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143518 (* 1 = 0.143518 loss)
I1001 19:58:48.438925  5547 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I1001 19:59:02.710240  5547 solver.cpp:218] Iteration 19900 (7.0071 iter/s, 14.2712s/100 iters), loss = 0.208534
I1001 19:59:02.710275  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208534 (* 1 = 0.208534 loss)
I1001 19:59:02.710294  5547 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I1001 19:59:16.286881  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:59:16.856947  5547 solver.cpp:330] Iteration 20000, Testing net (#0)
I1001 19:59:20.228021  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 19:59:20.367280  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7993
I1001 19:59:20.367314  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.591094 (* 1 = 0.591094 loss)
I1001 19:59:20.508859  5547 solver.cpp:218] Iteration 20000 (5.61844 iter/s, 17.7985s/100 iters), loss = 0.226161
I1001 19:59:20.508889  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226161 (* 1 = 0.226161 loss)
I1001 19:59:20.508896  5547 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I1001 19:59:34.801627  5547 solver.cpp:218] Iteration 20100 (6.99658 iter/s, 14.2927s/100 iters), loss = 0.218482
I1001 19:59:34.801659  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218482 (* 1 = 0.218482 loss)
I1001 19:59:34.801666  5547 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I1001 19:59:49.088848  5547 solver.cpp:218] Iteration 20200 (6.9993 iter/s, 14.2871s/100 iters), loss = 0.217263
I1001 19:59:49.088954  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217263 (* 1 = 0.217263 loss)
I1001 19:59:49.088961  5547 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I1001 20:00:03.375998  5547 solver.cpp:218] Iteration 20300 (6.99937 iter/s, 14.287s/100 iters), loss = 0.257507
I1001 20:00:03.376044  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257507 (* 1 = 0.257507 loss)
I1001 20:00:03.376050  5547 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I1001 20:00:17.673501  5547 solver.cpp:218] Iteration 20400 (6.99429 iter/s, 14.2974s/100 iters), loss = 0.189331
I1001 20:00:17.673532  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189331 (* 1 = 0.189331 loss)
I1001 20:00:17.673538  5547 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I1001 20:00:31.254545  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:00:31.824599  5547 solver.cpp:330] Iteration 20500, Testing net (#0)
I1001 20:00:35.191614  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:00:35.331645  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8391
I1001 20:00:35.331670  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.478831 (* 1 = 0.478831 loss)
I1001 20:00:35.472988  5547 solver.cpp:218] Iteration 20500 (5.61817 iter/s, 17.7994s/100 iters), loss = 0.297643
I1001 20:00:35.473029  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297643 (* 1 = 0.297643 loss)
I1001 20:00:35.473047  5547 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I1001 20:00:49.747303  5547 solver.cpp:218] Iteration 20600 (7.00571 iter/s, 14.2741s/100 iters), loss = 0.183589
I1001 20:00:49.747337  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183589 (* 1 = 0.183589 loss)
I1001 20:00:49.747344  5547 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I1001 20:01:04.040871  5547 solver.cpp:218] Iteration 20700 (6.99619 iter/s, 14.2935s/100 iters), loss = 0.167928
I1001 20:01:04.040983  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167927 (* 1 = 0.167927 loss)
I1001 20:01:04.040992  5547 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I1001 20:01:18.330140  5547 solver.cpp:218] Iteration 20800 (6.99834 iter/s, 14.2891s/100 iters), loss = 0.263353
I1001 20:01:18.330170  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263353 (* 1 = 0.263353 loss)
I1001 20:01:18.330176  5547 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I1001 20:01:32.610582  5547 solver.cpp:218] Iteration 20900 (7.00262 iter/s, 14.2804s/100 iters), loss = 0.197392
I1001 20:01:32.610613  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197392 (* 1 = 0.197392 loss)
I1001 20:01:32.610620  5547 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I1001 20:01:46.193367  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:01:46.762472  5547 solver.cpp:330] Iteration 21000, Testing net (#0)
I1001 20:01:50.133621  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:01:50.273748  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8074
I1001 20:01:50.273787  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.618065 (* 1 = 0.618065 loss)
I1001 20:01:50.415961  5547 solver.cpp:218] Iteration 21000 (5.61631 iter/s, 17.8053s/100 iters), loss = 0.24317
I1001 20:01:50.415993  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24317 (* 1 = 0.24317 loss)
I1001 20:01:50.416010  5547 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I1001 20:02:04.707700  5547 solver.cpp:218] Iteration 21100 (6.99708 iter/s, 14.2917s/100 iters), loss = 0.24661
I1001 20:02:04.707731  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24661 (* 1 = 0.24661 loss)
I1001 20:02:04.707737  5547 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I1001 20:02:18.984231  5547 solver.cpp:218] Iteration 21200 (7.00454 iter/s, 14.2765s/100 iters), loss = 0.221244
I1001 20:02:18.984328  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221244 (* 1 = 0.221244 loss)
I1001 20:02:18.984336  5547 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I1001 20:02:33.261971  5547 solver.cpp:218] Iteration 21300 (7.00398 iter/s, 14.2776s/100 iters), loss = 0.269968
I1001 20:02:33.262001  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269968 (* 1 = 0.269968 loss)
I1001 20:02:33.262007  5547 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I1001 20:02:47.553966  5547 solver.cpp:218] Iteration 21400 (6.99696 iter/s, 14.2919s/100 iters), loss = 0.175636
I1001 20:02:47.553995  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175636 (* 1 = 0.175636 loss)
I1001 20:02:47.554002  5547 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I1001 20:03:01.135010  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:03:01.704617  5547 solver.cpp:330] Iteration 21500, Testing net (#0)
I1001 20:03:05.074514  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:03:05.214313  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.807
I1001 20:03:05.214349  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.608419 (* 1 = 0.608419 loss)
I1001 20:03:05.355727  5547 solver.cpp:218] Iteration 21500 (5.61745 iter/s, 17.8017s/100 iters), loss = 0.170441
I1001 20:03:05.355757  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170441 (* 1 = 0.170441 loss)
I1001 20:03:05.355763  5547 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I1001 20:03:19.634763  5547 solver.cpp:218] Iteration 21600 (7.00331 iter/s, 14.279s/100 iters), loss = 0.291125
I1001 20:03:19.634795  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291125 (* 1 = 0.291125 loss)
I1001 20:03:19.634802  5547 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I1001 20:03:33.913362  5547 solver.cpp:218] Iteration 21700 (7.00352 iter/s, 14.2785s/100 iters), loss = 0.462764
I1001 20:03:33.913508  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.462764 (* 1 = 0.462764 loss)
I1001 20:03:33.913518  5547 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I1001 20:03:48.181685  5547 solver.cpp:218] Iteration 21800 (7.00862 iter/s, 14.2681s/100 iters), loss = 0.203588
I1001 20:03:48.181715  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203588 (* 1 = 0.203588 loss)
I1001 20:03:48.181721  5547 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I1001 20:04:02.463968  5547 solver.cpp:218] Iteration 21900 (7.00172 iter/s, 14.2822s/100 iters), loss = 0.211212
I1001 20:04:02.463999  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211212 (* 1 = 0.211212 loss)
I1001 20:04:02.464005  5547 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I1001 20:04:16.048319  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:04:16.618546  5547 solver.cpp:330] Iteration 22000, Testing net (#0)
I1001 20:04:19.990489  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:04:20.130475  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.799
I1001 20:04:20.130499  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.682395 (* 1 = 0.682395 loss)
I1001 20:04:20.272086  5547 solver.cpp:218] Iteration 22000 (5.61544 iter/s, 17.808s/100 iters), loss = 0.274107
I1001 20:04:20.272122  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274107 (* 1 = 0.274107 loss)
I1001 20:04:20.272130  5547 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I1001 20:04:34.564401  5547 solver.cpp:218] Iteration 22100 (6.99681 iter/s, 14.2922s/100 iters), loss = 0.386811
I1001 20:04:34.564445  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.386811 (* 1 = 0.386811 loss)
I1001 20:04:34.564452  5547 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I1001 20:04:48.855819  5547 solver.cpp:218] Iteration 22200 (6.99725 iter/s, 14.2913s/100 iters), loss = 0.20727
I1001 20:04:48.855918  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20727 (* 1 = 0.20727 loss)
I1001 20:04:48.855936  5547 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I1001 20:05:03.150364  5547 solver.cpp:218] Iteration 22300 (6.99574 iter/s, 14.2944s/100 iters), loss = 0.190828
I1001 20:05:03.150395  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190828 (* 1 = 0.190828 loss)
I1001 20:05:03.150401  5547 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I1001 20:05:17.450865  5547 solver.cpp:218] Iteration 22400 (6.9928 iter/s, 14.3004s/100 iters), loss = 0.190756
I1001 20:05:17.450896  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190756 (* 1 = 0.190756 loss)
I1001 20:05:17.450902  5547 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I1001 20:05:31.036451  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:05:31.606420  5547 solver.cpp:330] Iteration 22500, Testing net (#0)
I1001 20:05:34.975229  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:05:35.114739  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7824
I1001 20:05:35.114775  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.697977 (* 1 = 0.697977 loss)
I1001 20:05:35.256126  5547 solver.cpp:218] Iteration 22500 (5.61634 iter/s, 17.8052s/100 iters), loss = 0.204248
I1001 20:05:35.256160  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204248 (* 1 = 0.204248 loss)
I1001 20:05:35.256168  5547 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I1001 20:05:49.543925  5547 solver.cpp:218] Iteration 22600 (6.99902 iter/s, 14.2877s/100 iters), loss = 0.192699
I1001 20:05:49.543958  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192699 (* 1 = 0.192699 loss)
I1001 20:05:49.543964  5547 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I1001 20:06:03.838804  5547 solver.cpp:218] Iteration 22700 (6.99555 iter/s, 14.2948s/100 iters), loss = 0.242784
I1001 20:06:03.838950  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242784 (* 1 = 0.242784 loss)
I1001 20:06:03.838969  5547 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I1001 20:06:18.115382  5547 solver.cpp:218] Iteration 22800 (7.00457 iter/s, 14.2764s/100 iters), loss = 0.201368
I1001 20:06:18.115414  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201368 (* 1 = 0.201368 loss)
I1001 20:06:18.115420  5547 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I1001 20:06:32.404275  5547 solver.cpp:218] Iteration 22900 (6.99848 iter/s, 14.2888s/100 iters), loss = 0.229133
I1001 20:06:32.404306  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229133 (* 1 = 0.229133 loss)
I1001 20:06:32.404312  5547 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I1001 20:06:45.994316  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:06:46.564067  5547 solver.cpp:330] Iteration 23000, Testing net (#0)
I1001 20:06:49.934412  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:06:50.074908  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7535
I1001 20:06:50.074944  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.768785 (* 1 = 0.768785 loss)
I1001 20:06:50.216418  5547 solver.cpp:218] Iteration 23000 (5.61417 iter/s, 17.8121s/100 iters), loss = 0.138935
I1001 20:06:50.216465  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.138935 (* 1 = 0.138935 loss)
I1001 20:06:50.216473  5547 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I1001 20:07:04.495529  5547 solver.cpp:218] Iteration 23100 (7.00328 iter/s, 14.279s/100 iters), loss = 0.234985
I1001 20:07:04.495563  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234985 (* 1 = 0.234985 loss)
I1001 20:07:04.495569  5547 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I1001 20:07:18.781019  5547 solver.cpp:218] Iteration 23200 (7.00015 iter/s, 14.2854s/100 iters), loss = 0.18611
I1001 20:07:18.781136  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18611 (* 1 = 0.18611 loss)
I1001 20:07:18.781144  5547 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I1001 20:07:33.063256  5547 solver.cpp:218] Iteration 23300 (7.00178 iter/s, 14.2821s/100 iters), loss = 0.200276
I1001 20:07:33.063285  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200276 (* 1 = 0.200276 loss)
I1001 20:07:33.063292  5547 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I1001 20:07:47.354601  5547 solver.cpp:218] Iteration 23400 (6.99728 iter/s, 14.2913s/100 iters), loss = 0.148496
I1001 20:07:47.354631  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148496 (* 1 = 0.148496 loss)
I1001 20:07:47.354637  5547 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I1001 20:08:00.934171  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:08:01.503718  5547 solver.cpp:330] Iteration 23500, Testing net (#0)
I1001 20:08:04.874460  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:08:05.014212  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8216
I1001 20:08:05.014236  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.539225 (* 1 = 0.539225 loss)
I1001 20:08:05.155616  5547 solver.cpp:218] Iteration 23500 (5.61768 iter/s, 17.8009s/100 iters), loss = 0.252872
I1001 20:08:05.155649  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252872 (* 1 = 0.252872 loss)
I1001 20:08:05.155655  5547 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I1001 20:08:19.442834  5547 solver.cpp:218] Iteration 23600 (6.9993 iter/s, 14.2871s/100 iters), loss = 0.186584
I1001 20:08:19.442864  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186584 (* 1 = 0.186584 loss)
I1001 20:08:19.442870  5547 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I1001 20:08:33.728601  5547 solver.cpp:218] Iteration 23700 (7.00001 iter/s, 14.2857s/100 iters), loss = 0.206017
I1001 20:08:33.728766  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206017 (* 1 = 0.206017 loss)
I1001 20:08:33.728787  5547 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I1001 20:08:47.995460  5547 solver.cpp:218] Iteration 23800 (7.00935 iter/s, 14.2667s/100 iters), loss = 0.156447
I1001 20:08:47.995496  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156447 (* 1 = 0.156447 loss)
I1001 20:08:47.995503  5547 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I1001 20:09:02.289942  5547 solver.cpp:218] Iteration 23900 (6.99574 iter/s, 14.2944s/100 iters), loss = 0.170854
I1001 20:09:02.289971  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170854 (* 1 = 0.170854 loss)
I1001 20:09:02.289978  5547 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I1001 20:09:15.868451  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:09:16.438053  5547 solver.cpp:330] Iteration 24000, Testing net (#0)
I1001 20:09:19.808369  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:09:19.948494  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7929
I1001 20:09:19.948520  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.657189 (* 1 = 0.657189 loss)
I1001 20:09:20.089725  5547 solver.cpp:218] Iteration 24000 (5.61807 iter/s, 17.7997s/100 iters), loss = 0.163234
I1001 20:09:20.089758  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163234 (* 1 = 0.163234 loss)
I1001 20:09:20.089766  5547 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I1001 20:09:34.366206  5547 solver.cpp:218] Iteration 24100 (7.00457 iter/s, 14.2764s/100 iters), loss = 0.172755
I1001 20:09:34.366247  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172755 (* 1 = 0.172755 loss)
I1001 20:09:34.366253  5547 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I1001 20:09:48.653792  5547 solver.cpp:218] Iteration 24200 (6.99913 iter/s, 14.2875s/100 iters), loss = 0.183108
I1001 20:09:48.653933  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183108 (* 1 = 0.183108 loss)
I1001 20:09:48.653964  5547 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I1001 20:10:02.937626  5547 solver.cpp:218] Iteration 24300 (7.00102 iter/s, 14.2836s/100 iters), loss = 0.143587
I1001 20:10:02.937671  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143587 (* 1 = 0.143587 loss)
I1001 20:10:02.937678  5547 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I1001 20:10:17.211827  5547 solver.cpp:218] Iteration 24400 (7.00569 iter/s, 14.2741s/100 iters), loss = 0.188406
I1001 20:10:17.211858  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188406 (* 1 = 0.188406 loss)
I1001 20:10:17.211864  5547 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I1001 20:10:30.792055  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:10:31.360352  5547 solver.cpp:330] Iteration 24500, Testing net (#0)
I1001 20:10:34.730043  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:10:34.870040  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7432
I1001 20:10:34.870066  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.816393 (* 1 = 0.816393 loss)
I1001 20:10:35.011873  5547 solver.cpp:218] Iteration 24500 (5.61799 iter/s, 17.8s/100 iters), loss = 0.164435
I1001 20:10:35.011905  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164435 (* 1 = 0.164435 loss)
I1001 20:10:35.011912  5547 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I1001 20:10:49.303849  5547 solver.cpp:218] Iteration 24600 (6.99697 iter/s, 14.2919s/100 iters), loss = 0.201501
I1001 20:10:49.303880  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201501 (* 1 = 0.201501 loss)
I1001 20:10:49.303886  5547 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I1001 20:11:03.590981  5547 solver.cpp:218] Iteration 24700 (6.99934 iter/s, 14.2871s/100 iters), loss = 0.191121
I1001 20:11:03.591164  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191121 (* 1 = 0.191121 loss)
I1001 20:11:03.591174  5547 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I1001 20:11:17.874629  5547 solver.cpp:218] Iteration 24800 (7.00112 iter/s, 14.2834s/100 iters), loss = 0.182692
I1001 20:11:17.874660  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182692 (* 1 = 0.182692 loss)
I1001 20:11:17.874666  5547 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I1001 20:11:32.169661  5547 solver.cpp:218] Iteration 24900 (6.99547 iter/s, 14.295s/100 iters), loss = 0.150659
I1001 20:11:32.169692  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.150659 (* 1 = 0.150659 loss)
I1001 20:11:32.169698  5547 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I1001 20:11:45.757153  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:11:46.327237  5547 solver.cpp:330] Iteration 25000, Testing net (#0)
I1001 20:11:49.696899  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:11:49.836910  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7113
I1001 20:11:49.836946  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.992592 (* 1 = 0.992592 loss)
I1001 20:11:49.978847  5547 solver.cpp:218] Iteration 25000 (5.61511 iter/s, 17.8091s/100 iters), loss = 0.195212
I1001 20:11:49.978883  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195212 (* 1 = 0.195212 loss)
I1001 20:11:49.978890  5547 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I1001 20:12:04.269793  5547 solver.cpp:218] Iteration 25100 (6.99748 iter/s, 14.2909s/100 iters), loss = 0.247161
I1001 20:12:04.269824  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247161 (* 1 = 0.247161 loss)
I1001 20:12:04.269831  5547 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I1001 20:12:18.559779  5547 solver.cpp:218] Iteration 25200 (6.99795 iter/s, 14.2899s/100 iters), loss = 0.3598
I1001 20:12:18.559898  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.3598 (* 1 = 0.3598 loss)
I1001 20:12:18.559917  5547 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I1001 20:12:32.851459  5547 solver.cpp:218] Iteration 25300 (6.99715 iter/s, 14.2915s/100 iters), loss = 0.228465
I1001 20:12:32.851490  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228465 (* 1 = 0.228465 loss)
I1001 20:12:32.851496  5547 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I1001 20:12:47.135593  5547 solver.cpp:218] Iteration 25400 (7.00081 iter/s, 14.2841s/100 iters), loss = 0.189053
I1001 20:12:47.135627  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189053 (* 1 = 0.189053 loss)
I1001 20:12:47.135633  5547 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I1001 20:13:00.726852  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:13:01.296228  5547 solver.cpp:330] Iteration 25500, Testing net (#0)
I1001 20:13:04.666479  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:13:04.806126  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7616
I1001 20:13:04.806161  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.747558 (* 1 = 0.747558 loss)
I1001 20:13:04.947899  5547 solver.cpp:218] Iteration 25500 (5.61412 iter/s, 17.8122s/100 iters), loss = 0.185601
I1001 20:13:04.947933  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185601 (* 1 = 0.185601 loss)
I1001 20:13:04.947940  5547 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I1001 20:13:19.234334  5547 solver.cpp:218] Iteration 25600 (6.99969 iter/s, 14.2864s/100 iters), loss = 0.245642
I1001 20:13:19.234366  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245643 (* 1 = 0.245643 loss)
I1001 20:13:19.234372  5547 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I1001 20:13:33.509670  5547 solver.cpp:218] Iteration 25700 (7.00513 iter/s, 14.2753s/100 iters), loss = 0.267195
I1001 20:13:33.509817  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267196 (* 1 = 0.267196 loss)
I1001 20:13:33.509826  5547 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I1001 20:13:47.793591  5547 solver.cpp:218] Iteration 25800 (7.00097 iter/s, 14.2837s/100 iters), loss = 0.227617
I1001 20:13:47.793622  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227617 (* 1 = 0.227617 loss)
I1001 20:13:47.793638  5547 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I1001 20:14:02.087106  5547 solver.cpp:218] Iteration 25900 (6.99622 iter/s, 14.2934s/100 iters), loss = 0.192703
I1001 20:14:02.087136  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192703 (* 1 = 0.192703 loss)
I1001 20:14:02.087142  5547 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I1001 20:14:15.658179  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:14:16.228981  5547 solver.cpp:330] Iteration 26000, Testing net (#0)
I1001 20:14:19.597883  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:14:19.738199  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7864
I1001 20:14:19.738225  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.696374 (* 1 = 0.696374 loss)
I1001 20:14:19.880512  5547 solver.cpp:218] Iteration 26000 (5.62009 iter/s, 17.7933s/100 iters), loss = 0.235117
I1001 20:14:19.880548  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235117 (* 1 = 0.235117 loss)
I1001 20:14:19.880555  5547 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I1001 20:14:34.166929  5547 solver.cpp:218] Iteration 26100 (6.9997 iter/s, 14.2863s/100 iters), loss = 0.112643
I1001 20:14:34.166961  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.112643 (* 1 = 0.112643 loss)
I1001 20:14:34.166978  5547 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I1001 20:14:48.447311  5547 solver.cpp:218] Iteration 26200 (7.00265 iter/s, 14.2803s/100 iters), loss = 0.221657
I1001 20:14:48.447422  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221657 (* 1 = 0.221657 loss)
I1001 20:14:48.447440  5547 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I1001 20:15:02.736279  5547 solver.cpp:218] Iteration 26300 (6.99848 iter/s, 14.2888s/100 iters), loss = 0.258432
I1001 20:15:02.736310  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258432 (* 1 = 0.258432 loss)
I1001 20:15:02.736315  5547 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I1001 20:15:17.019875  5547 solver.cpp:218] Iteration 26400 (7.00108 iter/s, 14.2835s/100 iters), loss = 0.172978
I1001 20:15:17.019917  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172978 (* 1 = 0.172978 loss)
I1001 20:15:17.019924  5547 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I1001 20:15:30.603910  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:15:31.177181  5547 solver.cpp:330] Iteration 26500, Testing net (#0)
I1001 20:15:34.548210  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:15:34.688068  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7982
I1001 20:15:34.688103  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.629907 (* 1 = 0.629907 loss)
I1001 20:15:34.829644  5547 solver.cpp:218] Iteration 26500 (5.61493 iter/s, 17.8097s/100 iters), loss = 0.172607
I1001 20:15:34.829679  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172607 (* 1 = 0.172607 loss)
I1001 20:15:34.829685  5547 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I1001 20:15:49.101207  5547 solver.cpp:218] Iteration 26600 (7.00698 iter/s, 14.2715s/100 iters), loss = 0.228575
I1001 20:15:49.101248  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228575 (* 1 = 0.228575 loss)
I1001 20:15:49.101254  5547 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I1001 20:16:03.373473  5547 solver.cpp:218] Iteration 26700 (7.00664 iter/s, 14.2722s/100 iters), loss = 0.206432
I1001 20:16:03.373553  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206432 (* 1 = 0.206432 loss)
I1001 20:16:03.373559  5547 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I1001 20:16:17.663724  5547 solver.cpp:218] Iteration 26800 (6.99784 iter/s, 14.2901s/100 iters), loss = 0.166005
I1001 20:16:17.663765  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166005 (* 1 = 0.166005 loss)
I1001 20:16:17.663771  5547 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I1001 20:16:31.952814  5547 solver.cpp:218] Iteration 26900 (6.99839 iter/s, 14.289s/100 iters), loss = 0.199846
I1001 20:16:31.952857  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199847 (* 1 = 0.199847 loss)
I1001 20:16:31.952863  5547 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I1001 20:16:45.521652  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:16:46.098134  5547 solver.cpp:330] Iteration 27000, Testing net (#0)
I1001 20:16:49.466236  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:16:49.606114  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7886
I1001 20:16:49.606151  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.65301 (* 1 = 0.65301 loss)
I1001 20:16:49.748001  5547 solver.cpp:218] Iteration 27000 (5.61953 iter/s, 17.7951s/100 iters), loss = 0.164625
I1001 20:16:49.748036  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164626 (* 1 = 0.164626 loss)
I1001 20:16:49.748044  5547 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I1001 20:17:04.060050  5547 solver.cpp:218] Iteration 27100 (6.98716 iter/s, 14.312s/100 iters), loss = 0.224904
I1001 20:17:04.060091  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224904 (* 1 = 0.224904 loss)
I1001 20:17:04.060098  5547 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I1001 20:17:18.358331  5547 solver.cpp:218] Iteration 27200 (6.99389 iter/s, 14.2982s/100 iters), loss = 0.136787
I1001 20:17:18.358479  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136787 (* 1 = 0.136787 loss)
I1001 20:17:18.358489  5547 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I1001 20:17:32.656291  5547 solver.cpp:218] Iteration 27300 (6.9941 iter/s, 14.2978s/100 iters), loss = 0.171316
I1001 20:17:32.656321  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171316 (* 1 = 0.171316 loss)
I1001 20:17:32.656327  5547 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I1001 20:17:46.963433  5547 solver.cpp:218] Iteration 27400 (6.98955 iter/s, 14.3071s/100 iters), loss = 0.144022
I1001 20:17:46.963474  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144022 (* 1 = 0.144022 loss)
I1001 20:17:46.963480  5547 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I1001 20:18:00.557883  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:18:01.135076  5547 solver.cpp:330] Iteration 27500, Testing net (#0)
I1001 20:18:04.506310  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:18:04.646528  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8432
I1001 20:18:04.646554  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.460716 (* 1 = 0.460716 loss)
I1001 20:18:04.788038  5547 solver.cpp:218] Iteration 27500 (5.61025 iter/s, 17.8245s/100 iters), loss = 0.211899
I1001 20:18:04.788074  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211899 (* 1 = 0.211899 loss)
I1001 20:18:04.788084  5547 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I1001 20:18:19.062999  5547 solver.cpp:218] Iteration 27600 (7.00531 iter/s, 14.2749s/100 iters), loss = 0.300747
I1001 20:18:19.063031  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300747 (* 1 = 0.300747 loss)
I1001 20:18:19.063040  5547 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I1001 20:18:33.344301  5547 solver.cpp:218] Iteration 27700 (7.0022 iter/s, 14.2812s/100 iters), loss = 0.176971
I1001 20:18:33.344420  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176971 (* 1 = 0.176971 loss)
I1001 20:18:33.344440  5547 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I1001 20:18:47.640456  5547 solver.cpp:218] Iteration 27800 (6.99496 iter/s, 14.296s/100 iters), loss = 0.201495
I1001 20:18:47.640488  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201495 (* 1 = 0.201495 loss)
I1001 20:18:47.640496  5547 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I1001 20:19:01.930212  5547 solver.cpp:218] Iteration 27900 (6.99806 iter/s, 14.2897s/100 iters), loss = 0.103881
I1001 20:19:01.930246  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103881 (* 1 = 0.103881 loss)
I1001 20:19:01.930255  5547 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I1001 20:19:15.495769  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:19:16.074596  5547 solver.cpp:330] Iteration 28000, Testing net (#0)
I1001 20:19:19.445683  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:19:19.585669  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8194
I1001 20:19:19.585697  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.577881 (* 1 = 0.577881 loss)
I1001 20:19:19.727033  5547 solver.cpp:218] Iteration 28000 (5.61901 iter/s, 17.7967s/100 iters), loss = 0.138504
I1001 20:19:19.727072  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.138504 (* 1 = 0.138504 loss)
I1001 20:19:19.727080  5547 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I1001 20:19:34.019269  5547 solver.cpp:218] Iteration 28100 (6.99685 iter/s, 14.2922s/100 iters), loss = 0.166853
I1001 20:19:34.019304  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166853 (* 1 = 0.166853 loss)
I1001 20:19:34.019323  5547 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I1001 20:19:48.297195  5547 solver.cpp:218] Iteration 28200 (7.00386 iter/s, 14.2779s/100 iters), loss = 0.194798
I1001 20:19:48.297272  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194798 (* 1 = 0.194798 loss)
I1001 20:19:48.297282  5547 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I1001 20:20:02.583431  5547 solver.cpp:218] Iteration 28300 (6.9998 iter/s, 14.2861s/100 iters), loss = 0.253436
I1001 20:20:02.583464  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253436 (* 1 = 0.253436 loss)
I1001 20:20:02.583472  5547 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I1001 20:20:16.871889  5547 solver.cpp:218] Iteration 28400 (6.99869 iter/s, 14.2884s/100 iters), loss = 0.177857
I1001 20:20:16.871927  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177857 (* 1 = 0.177857 loss)
I1001 20:20:16.871935  5547 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I1001 20:20:30.452677  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:20:31.029736  5547 solver.cpp:330] Iteration 28500, Testing net (#0)
I1001 20:20:34.398610  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:20:34.538808  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8295
I1001 20:20:34.538835  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.540091 (* 1 = 0.540091 loss)
I1001 20:20:34.680485  5547 solver.cpp:218] Iteration 28500 (5.61529 iter/s, 17.8085s/100 iters), loss = 0.183007
I1001 20:20:34.680521  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183008 (* 1 = 0.183008 loss)
I1001 20:20:34.680529  5547 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I1001 20:20:48.953723  5547 solver.cpp:218] Iteration 28600 (7.00616 iter/s, 14.2732s/100 iters), loss = 0.169131
I1001 20:20:48.953755  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169131 (* 1 = 0.169131 loss)
I1001 20:20:48.953761  5547 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I1001 20:21:03.232347  5547 solver.cpp:218] Iteration 28700 (7.00351 iter/s, 14.2785s/100 iters), loss = 0.348857
I1001 20:21:03.232484  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.348857 (* 1 = 0.348857 loss)
I1001 20:21:03.232491  5547 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I1001 20:21:17.514633  5547 solver.cpp:218] Iteration 28800 (7.00176 iter/s, 14.2821s/100 iters), loss = 0.263411
I1001 20:21:17.514664  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263412 (* 1 = 0.263412 loss)
I1001 20:21:17.514670  5547 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I1001 20:21:31.792987  5547 solver.cpp:218] Iteration 28900 (7.00364 iter/s, 14.2783s/100 iters), loss = 0.229794
I1001 20:21:31.793018  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229794 (* 1 = 0.229794 loss)
I1001 20:21:31.793025  5547 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I1001 20:21:45.362947  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:21:45.943867  5547 solver.cpp:330] Iteration 29000, Testing net (#0)
I1001 20:21:49.313506  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:21:49.453081  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7953
I1001 20:21:49.453106  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.659404 (* 1 = 0.659404 loss)
I1001 20:21:49.595026  5547 solver.cpp:218] Iteration 29000 (5.61736 iter/s, 17.802s/100 iters), loss = 0.116871
I1001 20:21:49.595063  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116872 (* 1 = 0.116872 loss)
I1001 20:21:49.595072  5547 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I1001 20:22:03.879464  5547 solver.cpp:218] Iteration 29100 (7.00068 iter/s, 14.2843s/100 iters), loss = 0.149144
I1001 20:22:03.879498  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149144 (* 1 = 0.149144 loss)
I1001 20:22:03.879505  5547 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I1001 20:22:18.148010  5547 solver.cpp:218] Iteration 29200 (7.00846 iter/s, 14.2685s/100 iters), loss = 0.212182
I1001 20:22:18.148130  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212182 (* 1 = 0.212182 loss)
I1001 20:22:18.148139  5547 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I1001 20:22:32.437659  5547 solver.cpp:218] Iteration 29300 (6.99815 iter/s, 14.2895s/100 iters), loss = 0.155307
I1001 20:22:32.437700  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155307 (* 1 = 0.155307 loss)
I1001 20:22:32.437706  5547 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I1001 20:22:46.724103  5547 solver.cpp:218] Iteration 29400 (6.99968 iter/s, 14.2864s/100 iters), loss = 0.207675
I1001 20:22:46.724146  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207675 (* 1 = 0.207675 loss)
I1001 20:22:46.724153  5547 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I1001 20:23:00.296521  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:23:00.872795  5547 solver.cpp:330] Iteration 29500, Testing net (#0)
I1001 20:23:04.241607  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:23:04.381830  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8126
I1001 20:23:04.381866  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.622061 (* 1 = 0.622061 loss)
I1001 20:23:04.523525  5547 solver.cpp:218] Iteration 29500 (5.61819 iter/s, 17.7993s/100 iters), loss = 0.104309
I1001 20:23:04.523557  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.104309 (* 1 = 0.104309 loss)
I1001 20:23:04.523566  5547 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I1001 20:23:18.792378  5547 solver.cpp:218] Iteration 29600 (7.00831 iter/s, 14.2688s/100 iters), loss = 0.137328
I1001 20:23:18.792425  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.137328 (* 1 = 0.137328 loss)
I1001 20:23:18.792433  5547 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I1001 20:23:33.070616  5547 solver.cpp:218] Iteration 29700 (7.00373 iter/s, 14.2781s/100 iters), loss = 0.253505
I1001 20:23:33.070734  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253505 (* 1 = 0.253505 loss)
I1001 20:23:33.070752  5547 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I1001 20:23:47.344586  5547 solver.cpp:218] Iteration 29800 (7.00583 iter/s, 14.2738s/100 iters), loss = 0.20252
I1001 20:23:47.344617  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20252 (* 1 = 0.20252 loss)
I1001 20:23:47.344633  5547 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I1001 20:24:01.621695  5547 solver.cpp:218] Iteration 29900 (7.00426 iter/s, 14.277s/100 iters), loss = 0.197333
I1001 20:24:01.621728  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197333 (* 1 = 0.197333 loss)
I1001 20:24:01.621745  5547 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I1001 20:24:15.189971  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:24:15.767758  5547 solver.cpp:330] Iteration 30000, Testing net (#0)
I1001 20:24:19.139302  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:24:19.279363  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.78
I1001 20:24:19.279399  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.709369 (* 1 = 0.709369 loss)
I1001 20:24:19.420339  5547 solver.cpp:218] Iteration 30000 (5.61843 iter/s, 17.7986s/100 iters), loss = 0.184944
I1001 20:24:19.420372  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184944 (* 1 = 0.184944 loss)
I1001 20:24:19.420378  5547 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I1001 20:24:33.690824  5547 solver.cpp:218] Iteration 30100 (7.00751 iter/s, 14.2704s/100 iters), loss = 0.244906
I1001 20:24:33.690862  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244906 (* 1 = 0.244906 loss)
I1001 20:24:33.690870  5547 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I1001 20:24:47.962749  5547 solver.cpp:218] Iteration 30200 (7.0068 iter/s, 14.2718s/100 iters), loss = 0.273792
I1001 20:24:47.962854  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273792 (* 1 = 0.273792 loss)
I1001 20:24:47.962872  5547 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I1001 20:25:02.251009  5547 solver.cpp:218] Iteration 30300 (6.99883 iter/s, 14.2881s/100 iters), loss = 0.122575
I1001 20:25:02.251044  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.122575 (* 1 = 0.122575 loss)
I1001 20:25:02.251061  5547 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I1001 20:25:16.544086  5547 solver.cpp:218] Iteration 30400 (6.99643 iter/s, 14.293s/100 iters), loss = 0.102531
I1001 20:25:16.544121  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102532 (* 1 = 0.102532 loss)
I1001 20:25:16.544127  5547 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I1001 20:25:30.115494  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:25:30.689296  5547 solver.cpp:330] Iteration 30500, Testing net (#0)
I1001 20:25:34.059352  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:25:34.200068  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7985
I1001 20:25:34.200105  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.643421 (* 1 = 0.643421 loss)
I1001 20:25:34.341569  5547 solver.cpp:218] Iteration 30500 (5.6188 iter/s, 17.7974s/100 iters), loss = 0.229045
I1001 20:25:34.341603  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229045 (* 1 = 0.229045 loss)
I1001 20:25:34.341609  5547 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I1001 20:25:48.625411  5547 solver.cpp:218] Iteration 30600 (7.00096 iter/s, 14.2838s/100 iters), loss = 0.20645
I1001 20:25:48.625460  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20645 (* 1 = 0.20645 loss)
I1001 20:25:48.625468  5547 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I1001 20:26:02.914196  5547 solver.cpp:218] Iteration 30700 (6.99856 iter/s, 14.2887s/100 iters), loss = 0.1238
I1001 20:26:02.914304  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1238 (* 1 = 0.1238 loss)
I1001 20:26:02.914312  5547 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I1001 20:26:17.199880  5547 solver.cpp:218] Iteration 30800 (7.00009 iter/s, 14.2855s/100 iters), loss = 0.195354
I1001 20:26:17.199915  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195354 (* 1 = 0.195354 loss)
I1001 20:26:17.199923  5547 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I1001 20:26:31.490197  5547 solver.cpp:218] Iteration 30900 (6.99778 iter/s, 14.2902s/100 iters), loss = 0.126754
I1001 20:26:31.490229  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126754 (* 1 = 0.126754 loss)
I1001 20:26:31.490236  5547 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I1001 20:26:45.063554  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:26:45.636381  5547 solver.cpp:330] Iteration 31000, Testing net (#0)
I1001 20:26:49.009280  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:26:49.149205  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8141
I1001 20:26:49.149241  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.551304 (* 1 = 0.551304 loss)
I1001 20:26:49.290875  5547 solver.cpp:218] Iteration 31000 (5.61779 iter/s, 17.8006s/100 iters), loss = 0.109437
I1001 20:26:49.290910  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.109437 (* 1 = 0.109437 loss)
I1001 20:26:49.290917  5547 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I1001 20:27:03.558820  5547 solver.cpp:218] Iteration 31100 (7.00876 iter/s, 14.2679s/100 iters), loss = 0.260717
I1001 20:27:03.558866  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260717 (* 1 = 0.260717 loss)
I1001 20:27:03.558872  5547 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I1001 20:27:17.836802  5547 solver.cpp:218] Iteration 31200 (7.00385 iter/s, 14.2779s/100 iters), loss = 0.175998
I1001 20:27:17.836943  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175998 (* 1 = 0.175998 loss)
I1001 20:27:17.836951  5547 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I1001 20:27:32.129703  5547 solver.cpp:218] Iteration 31300 (6.99657 iter/s, 14.2927s/100 iters), loss = 0.214361
I1001 20:27:32.129736  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214361 (* 1 = 0.214361 loss)
I1001 20:27:32.129742  5547 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I1001 20:27:46.410018  5547 solver.cpp:218] Iteration 31400 (7.00268 iter/s, 14.2802s/100 iters), loss = 0.274885
I1001 20:27:46.410050  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274885 (* 1 = 0.274885 loss)
I1001 20:27:46.410056  5547 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I1001 20:27:59.974308  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:28:00.544715  5547 solver.cpp:330] Iteration 31500, Testing net (#0)
I1001 20:28:03.923866  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:28:04.064334  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7839
I1001 20:28:04.064358  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.659222 (* 1 = 0.659222 loss)
I1001 20:28:04.205436  5547 solver.cpp:218] Iteration 31500 (5.61945 iter/s, 17.7953s/100 iters), loss = 0.113156
I1001 20:28:04.205471  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.113156 (* 1 = 0.113156 loss)
I1001 20:28:04.205477  5547 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I1001 20:28:18.474972  5547 solver.cpp:218] Iteration 31600 (7.00797 iter/s, 14.2695s/100 iters), loss = 0.266649
I1001 20:28:18.475000  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266649 (* 1 = 0.266649 loss)
I1001 20:28:18.475006  5547 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I1001 20:28:32.759963  5547 solver.cpp:218] Iteration 31700 (7.00039 iter/s, 14.2849s/100 iters), loss = 0.2009
I1001 20:28:32.760097  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2009 (* 1 = 0.2009 loss)
I1001 20:28:32.760115  5547 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I1001 20:28:47.033186  5547 solver.cpp:218] Iteration 31800 (7.00621 iter/s, 14.273s/100 iters), loss = 0.224752
I1001 20:28:47.033221  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224752 (* 1 = 0.224752 loss)
I1001 20:28:47.033227  5547 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I1001 20:29:01.318924  5547 solver.cpp:218] Iteration 31900 (7.00003 iter/s, 14.2857s/100 iters), loss = 0.160369
I1001 20:29:01.318954  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160369 (* 1 = 0.160369 loss)
I1001 20:29:01.318961  5547 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I1001 20:29:14.894946  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:29:15.464457  5547 solver.cpp:330] Iteration 32000, Testing net (#0)
I1001 20:29:18.842875  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:29:18.983201  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8015
I1001 20:29:18.983237  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.619011 (* 1 = 0.619011 loss)
I1001 20:29:19.124528  5547 solver.cpp:218] Iteration 32000 (5.61624 iter/s, 17.8055s/100 iters), loss = 0.118981
I1001 20:29:19.124579  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.118981 (* 1 = 0.118981 loss)
I1001 20:29:19.124588  5547 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I1001 20:29:33.380434  5547 solver.cpp:218] Iteration 32100 (7.01468 iter/s, 14.2558s/100 iters), loss = 0.186869
I1001 20:29:33.380463  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186869 (* 1 = 0.186869 loss)
I1001 20:29:33.380470  5547 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I1001 20:29:47.659447  5547 solver.cpp:218] Iteration 32200 (7.00332 iter/s, 14.2789s/100 iters), loss = 0.218773
I1001 20:29:47.659565  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218773 (* 1 = 0.218773 loss)
I1001 20:29:47.659572  5547 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I1001 20:30:01.942454  5547 solver.cpp:218] Iteration 32300 (7.0014 iter/s, 14.2828s/100 iters), loss = 0.163404
I1001 20:30:01.942487  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163404 (* 1 = 0.163404 loss)
I1001 20:30:01.942492  5547 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I1001 20:30:16.205461  5547 solver.cpp:218] Iteration 32400 (7.01118 iter/s, 14.2629s/100 iters), loss = 0.0974778
I1001 20:30:16.205493  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0974778 (* 1 = 0.0974778 loss)
I1001 20:30:16.205499  5547 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I1001 20:30:29.767410  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:30:30.337939  5547 solver.cpp:330] Iteration 32500, Testing net (#0)
I1001 20:30:33.713683  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:30:33.857344  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7683
I1001 20:30:33.857380  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.715537 (* 1 = 0.715537 loss)
I1001 20:30:33.998852  5547 solver.cpp:218] Iteration 32500 (5.62009 iter/s, 17.7933s/100 iters), loss = 0.153433
I1001 20:30:33.998888  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153433 (* 1 = 0.153433 loss)
I1001 20:30:33.998894  5547 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I1001 20:30:48.275017  5547 solver.cpp:218] Iteration 32600 (7.00473 iter/s, 14.2761s/100 iters), loss = 0.143926
I1001 20:30:48.275079  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143926 (* 1 = 0.143926 loss)
I1001 20:30:48.275084  5547 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I1001 20:31:02.561489  5547 solver.cpp:218] Iteration 32700 (6.99968 iter/s, 14.2864s/100 iters), loss = 0.182854
I1001 20:31:02.561627  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182854 (* 1 = 0.182854 loss)
I1001 20:31:02.561635  5547 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I1001 20:31:16.845597  5547 solver.cpp:218] Iteration 32800 (7.00087 iter/s, 14.2839s/100 iters), loss = 0.152523
I1001 20:31:16.845628  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152523 (* 1 = 0.152523 loss)
I1001 20:31:16.845634  5547 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I1001 20:31:31.136243  5547 solver.cpp:218] Iteration 32900 (6.99762 iter/s, 14.2906s/100 iters), loss = 0.123215
I1001 20:31:31.136274  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123214 (* 1 = 0.123214 loss)
I1001 20:31:31.136281  5547 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I1001 20:31:44.695543  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:31:45.264716  5547 solver.cpp:330] Iteration 33000, Testing net (#0)
I1001 20:31:48.633981  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:31:48.777777  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7806
I1001 20:31:48.777806  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.712504 (* 1 = 0.712504 loss)
I1001 20:31:48.921428  5547 solver.cpp:218] Iteration 33000 (5.62268 iter/s, 17.7851s/100 iters), loss = 0.129995
I1001 20:31:48.921465  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.129995 (* 1 = 0.129995 loss)
I1001 20:31:48.921473  5547 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I1001 20:32:03.197500  5547 solver.cpp:218] Iteration 33100 (7.00477 iter/s, 14.276s/100 iters), loss = 0.20822
I1001 20:32:03.197530  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20822 (* 1 = 0.20822 loss)
I1001 20:32:03.197536  5547 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I1001 20:32:17.499212  5547 solver.cpp:218] Iteration 33200 (6.99221 iter/s, 14.3016s/100 iters), loss = 0.26624
I1001 20:32:17.499328  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26624 (* 1 = 0.26624 loss)
I1001 20:32:17.499336  5547 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I1001 20:32:31.792806  5547 solver.cpp:218] Iteration 33300 (6.99622 iter/s, 14.2934s/100 iters), loss = 0.207275
I1001 20:32:31.792837  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207275 (* 1 = 0.207275 loss)
I1001 20:32:31.792845  5547 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I1001 20:32:46.075420  5547 solver.cpp:218] Iteration 33400 (7.00156 iter/s, 14.2825s/100 iters), loss = 0.176784
I1001 20:32:46.075453  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176784 (* 1 = 0.176784 loss)
I1001 20:32:46.075459  5547 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I1001 20:32:59.650830  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:33:00.222028  5547 solver.cpp:330] Iteration 33500, Testing net (#0)
I1001 20:33:03.590451  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:33:03.735283  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8088
I1001 20:33:03.735314  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.616749 (* 1 = 0.616749 loss)
I1001 20:33:03.879806  5547 solver.cpp:218] Iteration 33500 (5.61662 iter/s, 17.8043s/100 iters), loss = 0.159573
I1001 20:33:03.879842  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159573 (* 1 = 0.159573 loss)
I1001 20:33:03.879848  5547 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I1001 20:33:18.161659  5547 solver.cpp:218] Iteration 33600 (7.00193 iter/s, 14.2818s/100 iters), loss = 0.254637
I1001 20:33:18.161689  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254637 (* 1 = 0.254637 loss)
I1001 20:33:18.161695  5547 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I1001 20:33:32.448417  5547 solver.cpp:218] Iteration 33700 (6.99953 iter/s, 14.2867s/100 iters), loss = 0.255645
I1001 20:33:32.448525  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255645 (* 1 = 0.255645 loss)
I1001 20:33:32.448544  5547 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I1001 20:33:46.736358  5547 solver.cpp:218] Iteration 33800 (6.99899 iter/s, 14.2878s/100 iters), loss = 0.243494
I1001 20:33:46.736390  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243494 (* 1 = 0.243494 loss)
I1001 20:33:46.736397  5547 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I1001 20:34:01.035991  5547 solver.cpp:218] Iteration 33900 (6.99323 iter/s, 14.2996s/100 iters), loss = 0.137683
I1001 20:34:01.036025  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.137683 (* 1 = 0.137683 loss)
I1001 20:34:01.036031  5547 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I1001 20:34:14.604176  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:34:15.173063  5547 solver.cpp:330] Iteration 34000, Testing net (#0)
I1001 20:34:18.541050  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:34:18.683806  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7947
I1001 20:34:18.683833  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.666177 (* 1 = 0.666177 loss)
I1001 20:34:18.827975  5547 solver.cpp:218] Iteration 34000 (5.62054 iter/s, 17.7919s/100 iters), loss = 0.11376
I1001 20:34:18.828032  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.11376 (* 1 = 0.11376 loss)
I1001 20:34:18.828048  5547 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I1001 20:34:33.103482  5547 solver.cpp:218] Iteration 34100 (7.00505 iter/s, 14.2754s/100 iters), loss = 0.251562
I1001 20:34:33.103525  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251562 (* 1 = 0.251562 loss)
I1001 20:34:33.103533  5547 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I1001 20:34:47.392027  5547 solver.cpp:218] Iteration 34200 (6.99866 iter/s, 14.2885s/100 iters), loss = 0.158507
I1001 20:34:47.392213  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158507 (* 1 = 0.158507 loss)
I1001 20:34:47.392223  5547 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I1001 20:35:01.676098  5547 solver.cpp:218] Iteration 34300 (7.00091 iter/s, 14.2839s/100 iters), loss = 0.0711512
I1001 20:35:01.676129  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0711512 (* 1 = 0.0711512 loss)
I1001 20:35:01.676136  5547 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I1001 20:35:15.949112  5547 solver.cpp:218] Iteration 34400 (7.00626 iter/s, 14.2729s/100 iters), loss = 0.108865
I1001 20:35:15.949146  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.108865 (* 1 = 0.108865 loss)
I1001 20:35:15.949153  5547 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I1001 20:35:29.516741  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:35:30.085675  5547 solver.cpp:330] Iteration 34500, Testing net (#0)
I1001 20:35:33.457041  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:35:33.597363  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.776
I1001 20:35:33.597400  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.843556 (* 1 = 0.843556 loss)
I1001 20:35:33.743300  5547 solver.cpp:218] Iteration 34500 (5.61984 iter/s, 17.7941s/100 iters), loss = 0.181112
I1001 20:35:33.743336  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181112 (* 1 = 0.181112 loss)
I1001 20:35:33.743345  5547 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I1001 20:35:48.005178  5547 solver.cpp:218] Iteration 34600 (7.01174 iter/s, 14.2618s/100 iters), loss = 0.142947
I1001 20:35:48.005219  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142947 (* 1 = 0.142947 loss)
I1001 20:35:48.005225  5547 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I1001 20:36:02.279069  5547 solver.cpp:218] Iteration 34700 (7.00584 iter/s, 14.2738s/100 iters), loss = 0.184734
I1001 20:36:02.279201  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184734 (* 1 = 0.184734 loss)
I1001 20:36:02.279211  5547 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I1001 20:36:16.561496  5547 solver.cpp:218] Iteration 34800 (7.0017 iter/s, 14.2823s/100 iters), loss = 0.140625
I1001 20:36:16.561527  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140625 (* 1 = 0.140625 loss)
I1001 20:36:16.561534  5547 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I1001 20:36:30.837923  5547 solver.cpp:218] Iteration 34900 (7.00459 iter/s, 14.2763s/100 iters), loss = 0.200492
I1001 20:36:30.837958  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200492 (* 1 = 0.200492 loss)
I1001 20:36:30.837966  5547 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I1001 20:36:44.393854  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:36:44.962537  5547 solver.cpp:330] Iteration 35000, Testing net (#0)
I1001 20:36:48.328725  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:36:48.468338  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8466
I1001 20:36:48.468371  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.460437 (* 1 = 0.460437 loss)
I1001 20:36:48.609678  5547 solver.cpp:218] Iteration 35000 (5.62694 iter/s, 17.7717s/100 iters), loss = 0.0824266
I1001 20:36:48.609727  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0824267 (* 1 = 0.0824267 loss)
I1001 20:36:48.609735  5547 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I1001 20:37:02.894129  5547 solver.cpp:218] Iteration 35100 (7.00068 iter/s, 14.2843s/100 iters), loss = 0.126247
I1001 20:37:02.894170  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126248 (* 1 = 0.126248 loss)
I1001 20:37:02.894176  5547 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I1001 20:37:17.182270  5547 solver.cpp:218] Iteration 35200 (6.99885 iter/s, 14.2881s/100 iters), loss = 0.113249
I1001 20:37:17.182407  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.113249 (* 1 = 0.113249 loss)
I1001 20:37:17.182415  5547 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I1001 20:37:31.459924  5547 solver.cpp:218] Iteration 35300 (7.00403 iter/s, 14.2775s/100 iters), loss = 0.229009
I1001 20:37:31.459955  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229009 (* 1 = 0.229009 loss)
I1001 20:37:31.459962  5547 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I1001 20:37:45.731178  5547 solver.cpp:218] Iteration 35400 (7.00713 iter/s, 14.2712s/100 iters), loss = 0.154407
I1001 20:37:45.731232  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154407 (* 1 = 0.154407 loss)
I1001 20:37:45.731240  5547 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I1001 20:37:59.305549  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:37:59.874922  5547 solver.cpp:330] Iteration 35500, Testing net (#0)
I1001 20:38:03.243942  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:38:03.384155  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7967
I1001 20:38:03.384178  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.64357 (* 1 = 0.64357 loss)
I1001 20:38:03.525532  5547 solver.cpp:218] Iteration 35500 (5.6198 iter/s, 17.7942s/100 iters), loss = 0.151329
I1001 20:38:03.525560  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151329 (* 1 = 0.151329 loss)
I1001 20:38:03.525568  5547 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I1001 20:38:17.799804  5547 solver.cpp:218] Iteration 35600 (7.00565 iter/s, 14.2742s/100 iters), loss = 0.219945
I1001 20:38:17.799834  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219945 (* 1 = 0.219945 loss)
I1001 20:38:17.799840  5547 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I1001 20:38:32.085842  5547 solver.cpp:218] Iteration 35700 (6.99988 iter/s, 14.286s/100 iters), loss = 0.224002
I1001 20:38:32.085961  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224002 (* 1 = 0.224002 loss)
I1001 20:38:32.085969  5547 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I1001 20:38:46.384433  5547 solver.cpp:218] Iteration 35800 (6.99378 iter/s, 14.2984s/100 iters), loss = 0.203306
I1001 20:38:46.384464  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203306 (* 1 = 0.203306 loss)
I1001 20:38:46.384470  5547 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I1001 20:39:00.663919  5547 solver.cpp:218] Iteration 35900 (7.00309 iter/s, 14.2794s/100 iters), loss = 0.180826
I1001 20:39:00.663954  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180826 (* 1 = 0.180826 loss)
I1001 20:39:00.663960  5547 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I1001 20:39:14.239348  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:39:14.808529  5547 solver.cpp:330] Iteration 36000, Testing net (#0)
I1001 20:39:18.176942  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:39:18.316597  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7044
I1001 20:39:18.316632  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.05248 (* 1 = 1.05248 loss)
I1001 20:39:18.458595  5547 solver.cpp:218] Iteration 36000 (5.61968 iter/s, 17.7946s/100 iters), loss = 0.0757385
I1001 20:39:18.458626  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0757386 (* 1 = 0.0757386 loss)
I1001 20:39:18.458631  5547 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I1001 20:39:32.743418  5547 solver.cpp:218] Iteration 36100 (7.00047 iter/s, 14.2848s/100 iters), loss = 0.199294
I1001 20:39:32.743449  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199294 (* 1 = 0.199294 loss)
I1001 20:39:32.743455  5547 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I1001 20:39:47.027451  5547 solver.cpp:218] Iteration 36200 (7.00086 iter/s, 14.284s/100 iters), loss = 0.299032
I1001 20:39:47.027570  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299032 (* 1 = 0.299032 loss)
I1001 20:39:47.027577  5547 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I1001 20:40:01.309976  5547 solver.cpp:218] Iteration 36300 (7.00164 iter/s, 14.2824s/100 iters), loss = 0.137226
I1001 20:40:01.310009  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.137226 (* 1 = 0.137226 loss)
I1001 20:40:01.310014  5547 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I1001 20:40:15.577739  5547 solver.cpp:218] Iteration 36400 (7.00884 iter/s, 14.2677s/100 iters), loss = 0.102286
I1001 20:40:15.577769  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102286 (* 1 = 0.102286 loss)
I1001 20:40:15.577775  5547 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I1001 20:40:29.153451  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:40:29.723314  5547 solver.cpp:330] Iteration 36500, Testing net (#0)
I1001 20:40:33.088881  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:40:33.229218  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7986
I1001 20:40:33.229254  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.629374 (* 1 = 0.629374 loss)
I1001 20:40:33.370000  5547 solver.cpp:218] Iteration 36500 (5.62045 iter/s, 17.7922s/100 iters), loss = 0.134772
I1001 20:40:33.370041  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134772 (* 1 = 0.134772 loss)
I1001 20:40:33.370048  5547 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I1001 20:40:47.641685  5547 solver.cpp:218] Iteration 36600 (7.00694 iter/s, 14.2716s/100 iters), loss = 0.174223
I1001 20:40:47.641713  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174223 (* 1 = 0.174223 loss)
I1001 20:40:47.641719  5547 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I1001 20:41:01.929474  5547 solver.cpp:218] Iteration 36700 (6.99902 iter/s, 14.2877s/100 iters), loss = 0.250331
I1001 20:41:01.929606  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250331 (* 1 = 0.250331 loss)
I1001 20:41:01.929615  5547 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I1001 20:41:16.216949  5547 solver.cpp:218] Iteration 36800 (6.99922 iter/s, 14.2873s/100 iters), loss = 0.250242
I1001 20:41:16.216981  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250242 (* 1 = 0.250242 loss)
I1001 20:41:16.216987  5547 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I1001 20:41:30.485949  5547 solver.cpp:218] Iteration 36900 (7.00824 iter/s, 14.2689s/100 iters), loss = 0.138747
I1001 20:41:30.485980  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.138747 (* 1 = 0.138747 loss)
I1001 20:41:30.485986  5547 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I1001 20:41:44.061192  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:41:44.629966  5547 solver.cpp:330] Iteration 37000, Testing net (#0)
I1001 20:41:47.999825  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:41:48.139833  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8398
I1001 20:41:48.139868  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.502381 (* 1 = 0.502381 loss)
I1001 20:41:48.281560  5547 solver.cpp:218] Iteration 37000 (5.61939 iter/s, 17.7955s/100 iters), loss = 0.160555
I1001 20:41:48.281592  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160555 (* 1 = 0.160555 loss)
I1001 20:41:48.281599  5547 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I1001 20:42:02.565426  5547 solver.cpp:218] Iteration 37100 (7.00096 iter/s, 14.2838s/100 iters), loss = 0.108184
I1001 20:42:02.565460  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.108184 (* 1 = 0.108184 loss)
I1001 20:42:02.565466  5547 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I1001 20:42:16.836313  5547 solver.cpp:218] Iteration 37200 (7.00731 iter/s, 14.2708s/100 iters), loss = 0.186306
I1001 20:42:16.836436  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186307 (* 1 = 0.186307 loss)
I1001 20:42:16.836453  5547 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I1001 20:42:31.113390  5547 solver.cpp:218] Iteration 37300 (7.00432 iter/s, 14.2769s/100 iters), loss = 0.145632
I1001 20:42:31.113422  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145632 (* 1 = 0.145632 loss)
I1001 20:42:31.113430  5547 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I1001 20:42:45.388833  5547 solver.cpp:218] Iteration 37400 (7.00508 iter/s, 14.2754s/100 iters), loss = 0.188063
I1001 20:42:45.388873  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188063 (* 1 = 0.188063 loss)
I1001 20:42:45.388880  5547 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I1001 20:42:58.966775  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:42:59.536506  5547 solver.cpp:330] Iteration 37500, Testing net (#0)
I1001 20:43:02.904685  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:43:03.044827  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7316
I1001 20:43:03.044862  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.913351 (* 1 = 0.913351 loss)
I1001 20:43:03.185596  5547 solver.cpp:218] Iteration 37500 (5.61903 iter/s, 17.7967s/100 iters), loss = 0.17012
I1001 20:43:03.185631  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17012 (* 1 = 0.17012 loss)
I1001 20:43:03.185639  5547 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I1001 20:43:17.458654  5547 solver.cpp:218] Iteration 37600 (7.00636 iter/s, 14.2727s/100 iters), loss = 0.122088
I1001 20:43:17.458695  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.122088 (* 1 = 0.122088 loss)
I1001 20:43:17.458703  5547 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I1001 20:43:31.754797  5547 solver.cpp:218] Iteration 37700 (6.99494 iter/s, 14.2961s/100 iters), loss = 0.205641
I1001 20:43:31.754930  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205641 (* 1 = 0.205641 loss)
I1001 20:43:31.754938  5547 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I1001 20:43:46.051203  5547 solver.cpp:218] Iteration 37800 (6.99485 iter/s, 14.2962s/100 iters), loss = 0.202935
I1001 20:43:46.051237  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202935 (* 1 = 0.202935 loss)
I1001 20:43:46.051244  5547 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I1001 20:44:00.328591  5547 solver.cpp:218] Iteration 37900 (7.00412 iter/s, 14.2773s/100 iters), loss = 0.157547
I1001 20:44:00.328622  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157547 (* 1 = 0.157547 loss)
I1001 20:44:00.328629  5547 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I1001 20:44:13.911906  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:44:14.481348  5547 solver.cpp:330] Iteration 38000, Testing net (#0)
I1001 20:44:17.849244  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:44:17.988831  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7597
I1001 20:44:17.988865  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.858757 (* 1 = 0.858757 loss)
I1001 20:44:18.130203  5547 solver.cpp:218] Iteration 38000 (5.6175 iter/s, 17.8015s/100 iters), loss = 0.0999503
I1001 20:44:18.130314  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0999503 (* 1 = 0.0999503 loss)
I1001 20:44:18.130324  5547 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I1001 20:44:32.403417  5547 solver.cpp:218] Iteration 38100 (7.00622 iter/s, 14.273s/100 iters), loss = 0.121429
I1001 20:44:32.403450  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.121429 (* 1 = 0.121429 loss)
I1001 20:44:32.403456  5547 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I1001 20:44:46.674718  5547 solver.cpp:218] Iteration 38200 (7.00711 iter/s, 14.2712s/100 iters), loss = 0.213381
I1001 20:44:46.674866  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213381 (* 1 = 0.213381 loss)
I1001 20:44:46.674875  5547 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I1001 20:45:00.961817  5547 solver.cpp:218] Iteration 38300 (6.99942 iter/s, 14.2869s/100 iters), loss = 0.188551
I1001 20:45:00.961850  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188551 (* 1 = 0.188551 loss)
I1001 20:45:00.961858  5547 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I1001 20:45:15.239732  5547 solver.cpp:218] Iteration 38400 (7.00386 iter/s, 14.2778s/100 iters), loss = 0.188949
I1001 20:45:15.239760  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188949 (* 1 = 0.188949 loss)
I1001 20:45:15.239765  5547 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I1001 20:45:28.814129  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:45:29.384554  5547 solver.cpp:330] Iteration 38500, Testing net (#0)
I1001 20:45:32.751618  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:45:32.892099  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.835
I1001 20:45:32.892134  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.4874 (* 1 = 0.4874 loss)
I1001 20:45:33.034284  5547 solver.cpp:218] Iteration 38500 (5.61972 iter/s, 17.7945s/100 iters), loss = 0.139878
I1001 20:45:33.034317  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139878 (* 1 = 0.139878 loss)
I1001 20:45:33.034324  5547 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I1001 20:45:47.338781  5547 solver.cpp:218] Iteration 38600 (6.99085 iter/s, 14.3044s/100 iters), loss = 0.123155
I1001 20:45:47.338815  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123155 (* 1 = 0.123155 loss)
I1001 20:45:47.338822  5547 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I1001 20:46:01.653282  5547 solver.cpp:218] Iteration 38700 (6.98596 iter/s, 14.3144s/100 iters), loss = 0.236305
I1001 20:46:01.653426  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236305 (* 1 = 0.236305 loss)
I1001 20:46:01.653434  5547 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I1001 20:46:15.956912  5547 solver.cpp:218] Iteration 38800 (6.99132 iter/s, 14.3034s/100 iters), loss = 0.178637
I1001 20:46:15.956948  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178637 (* 1 = 0.178637 loss)
I1001 20:46:15.956955  5547 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I1001 20:46:30.246902  5547 solver.cpp:218] Iteration 38900 (6.99795 iter/s, 14.2899s/100 iters), loss = 0.104804
I1001 20:46:30.246940  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.104804 (* 1 = 0.104804 loss)
I1001 20:46:30.246948  5547 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I1001 20:46:43.842793  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:46:44.412573  5547 solver.cpp:330] Iteration 39000, Testing net (#0)
I1001 20:46:47.781144  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:46:47.921339  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7943
I1001 20:46:47.921373  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.679956 (* 1 = 0.679956 loss)
I1001 20:46:48.063074  5547 solver.cpp:218] Iteration 39000 (5.61291 iter/s, 17.8161s/100 iters), loss = 0.0929037
I1001 20:46:48.063103  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0929037 (* 1 = 0.0929037 loss)
I1001 20:46:48.063110  5547 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I1001 20:47:02.347967  5547 solver.cpp:218] Iteration 39100 (7.00044 iter/s, 14.2848s/100 iters), loss = 0.235742
I1001 20:47:02.348000  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235742 (* 1 = 0.235742 loss)
I1001 20:47:02.348006  5547 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I1001 20:47:16.638756  5547 solver.cpp:218] Iteration 39200 (6.99755 iter/s, 14.2907s/100 iters), loss = 0.155995
I1001 20:47:16.638902  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155995 (* 1 = 0.155995 loss)
I1001 20:47:16.638911  5547 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I1001 20:47:30.935885  5547 solver.cpp:218] Iteration 39300 (6.99451 iter/s, 14.2969s/100 iters), loss = 0.137048
I1001 20:47:30.935925  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.137048 (* 1 = 0.137048 loss)
I1001 20:47:30.935942  5547 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I1001 20:47:45.223356  5547 solver.cpp:218] Iteration 39400 (6.9992 iter/s, 14.2873s/100 iters), loss = 0.0975581
I1001 20:47:45.223399  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0975582 (* 1 = 0.0975582 loss)
I1001 20:47:45.223407  5547 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I1001 20:47:58.801707  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:47:59.372930  5547 solver.cpp:330] Iteration 39500, Testing net (#0)
I1001 20:48:02.741243  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:48:02.881106  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7173
I1001 20:48:02.881130  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.940711 (* 1 = 0.940711 loss)
I1001 20:48:03.021807  5547 solver.cpp:218] Iteration 39500 (5.6185 iter/s, 17.7984s/100 iters), loss = 0.182092
I1001 20:48:03.021839  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182092 (* 1 = 0.182092 loss)
I1001 20:48:03.021847  5547 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I1001 20:48:17.306061  5547 solver.cpp:218] Iteration 39600 (7.00083 iter/s, 14.284s/100 iters), loss = 0.229622
I1001 20:48:17.306093  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229622 (* 1 = 0.229622 loss)
I1001 20:48:17.306100  5547 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I1001 20:48:31.587486  5547 solver.cpp:218] Iteration 39700 (7.00214 iter/s, 14.2813s/100 iters), loss = 0.314521
I1001 20:48:31.587604  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314521 (* 1 = 0.314521 loss)
I1001 20:48:31.587612  5547 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I1001 20:48:45.849900  5547 solver.cpp:218] Iteration 39800 (7.01152 iter/s, 14.2623s/100 iters), loss = 0.215182
I1001 20:48:45.849936  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215182 (* 1 = 0.215182 loss)
I1001 20:48:45.849953  5547 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I1001 20:49:00.119681  5547 solver.cpp:218] Iteration 39900 (7.00788 iter/s, 14.2697s/100 iters), loss = 0.16237
I1001 20:49:00.119715  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16237 (* 1 = 0.16237 loss)
I1001 20:49:00.119724  5547 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I1001 20:49:13.689244  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:49:14.258402  5547 solver.cpp:330] Iteration 40000, Testing net (#0)
I1001 20:49:17.625288  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:49:17.765264  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7887
I1001 20:49:17.765300  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.680474 (* 1 = 0.680474 loss)
I1001 20:49:17.906662  5547 solver.cpp:218] Iteration 40000 (5.62212 iter/s, 17.7869s/100 iters), loss = 0.158537
I1001 20:49:17.906692  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158537 (* 1 = 0.158537 loss)
I1001 20:49:17.906697  5547 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I1001 20:49:17.906702  5547 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I1001 20:49:32.182489  5547 solver.cpp:218] Iteration 40100 (7.00488 iter/s, 14.2758s/100 iters), loss = 0.19283
I1001 20:49:32.182523  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19283 (* 1 = 0.19283 loss)
I1001 20:49:32.182530  5547 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I1001 20:49:46.466114  5547 solver.cpp:218] Iteration 40200 (7.00106 iter/s, 14.2835s/100 iters), loss = 0.136497
I1001 20:49:46.466253  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136497 (* 1 = 0.136497 loss)
I1001 20:49:46.466275  5547 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I1001 20:50:00.748738  5547 solver.cpp:218] Iteration 40300 (7.0016 iter/s, 14.2825s/100 iters), loss = 0.104168
I1001 20:50:00.748786  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.104168 (* 1 = 0.104168 loss)
I1001 20:50:00.748795  5547 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I1001 20:50:15.024893  5547 solver.cpp:218] Iteration 40400 (7.00475 iter/s, 14.276s/100 iters), loss = 0.0492698
I1001 20:50:15.024935  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0492699 (* 1 = 0.0492699 loss)
I1001 20:50:15.024941  5547 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I1001 20:50:28.605512  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:50:29.174722  5547 solver.cpp:330] Iteration 40500, Testing net (#0)
I1001 20:50:32.544102  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:50:32.684077  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9108
I1001 20:50:32.684113  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.259775 (* 1 = 0.259775 loss)
I1001 20:50:32.825366  5547 solver.cpp:218] Iteration 40500 (5.61786 iter/s, 17.8004s/100 iters), loss = 0.0516078
I1001 20:50:32.825397  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0516079 (* 1 = 0.0516079 loss)
I1001 20:50:32.825403  5547 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I1001 20:50:47.115165  5547 solver.cpp:218] Iteration 40600 (6.99804 iter/s, 14.2897s/100 iters), loss = 0.125035
I1001 20:50:47.115208  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.125035 (* 1 = 0.125035 loss)
I1001 20:50:47.115216  5547 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I1001 20:51:01.398995  5547 solver.cpp:218] Iteration 40700 (7.00097 iter/s, 14.2837s/100 iters), loss = 0.133368
I1001 20:51:01.399143  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133368 (* 1 = 0.133368 loss)
I1001 20:51:01.399176  5547 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I1001 20:51:15.673761  5547 solver.cpp:218] Iteration 40800 (7.00546 iter/s, 14.2746s/100 iters), loss = 0.0640434
I1001 20:51:15.673794  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0640434 (* 1 = 0.0640434 loss)
I1001 20:51:15.673801  5547 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I1001 20:51:29.961727  5547 solver.cpp:218] Iteration 40900 (6.99893 iter/s, 14.2879s/100 iters), loss = 0.054171
I1001 20:51:29.961760  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.054171 (* 1 = 0.054171 loss)
I1001 20:51:29.961766  5547 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I1001 20:51:43.534731  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:51:44.105007  5547 solver.cpp:330] Iteration 41000, Testing net (#0)
I1001 20:51:47.471441  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:51:47.611577  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9228
I1001 20:51:47.611600  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.235135 (* 1 = 0.235135 loss)
I1001 20:51:47.753283  5547 solver.cpp:218] Iteration 41000 (5.62067 iter/s, 17.7915s/100 iters), loss = 0.0331134
I1001 20:51:47.753316  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0331135 (* 1 = 0.0331135 loss)
I1001 20:51:47.753324  5547 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I1001 20:52:02.038213  5547 solver.cpp:218] Iteration 41100 (7.00049 iter/s, 14.2847s/100 iters), loss = 0.0529773
I1001 20:52:02.038252  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0529774 (* 1 = 0.0529774 loss)
I1001 20:52:02.038259  5547 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I1001 20:52:16.328665  5547 solver.cpp:218] Iteration 41200 (6.99772 iter/s, 14.2904s/100 iters), loss = 0.0518325
I1001 20:52:16.328793  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0518325 (* 1 = 0.0518325 loss)
I1001 20:52:16.328801  5547 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I1001 20:52:30.606283  5547 solver.cpp:218] Iteration 41300 (7.00405 iter/s, 14.2775s/100 iters), loss = 0.0567483
I1001 20:52:30.606323  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0567483 (* 1 = 0.0567483 loss)
I1001 20:52:30.606329  5547 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I1001 20:52:44.881999  5547 solver.cpp:218] Iteration 41400 (7.00494 iter/s, 14.2756s/100 iters), loss = 0.0257628
I1001 20:52:44.882030  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0257628 (* 1 = 0.0257628 loss)
I1001 20:52:44.882035  5547 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I1001 20:52:58.476296  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:52:59.045994  5547 solver.cpp:330] Iteration 41500, Testing net (#0)
I1001 20:53:02.415675  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:53:02.555759  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9207
I1001 20:53:02.555795  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.241365 (* 1 = 0.241365 loss)
I1001 20:53:02.696931  5547 solver.cpp:218] Iteration 41500 (5.6133 iter/s, 17.8148s/100 iters), loss = 0.0232594
I1001 20:53:02.696965  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0232594 (* 1 = 0.0232594 loss)
I1001 20:53:02.696972  5547 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I1001 20:53:16.994933  5547 solver.cpp:218] Iteration 41600 (6.99402 iter/s, 14.2979s/100 iters), loss = 0.0756981
I1001 20:53:16.994966  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0756981 (* 1 = 0.0756981 loss)
I1001 20:53:16.994972  5547 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I1001 20:53:31.287765  5547 solver.cpp:218] Iteration 41700 (6.99655 iter/s, 14.2928s/100 iters), loss = 0.0883027
I1001 20:53:31.287907  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0883027 (* 1 = 0.0883027 loss)
I1001 20:53:31.287915  5547 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I1001 20:53:45.579252  5547 solver.cpp:218] Iteration 41800 (6.99726 iter/s, 14.2913s/100 iters), loss = 0.0900096
I1001 20:53:45.579290  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0900096 (* 1 = 0.0900096 loss)
I1001 20:53:45.579298  5547 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I1001 20:53:59.881595  5547 solver.cpp:218] Iteration 41900 (6.9919 iter/s, 14.3023s/100 iters), loss = 0.0634077
I1001 20:53:59.881624  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0634077 (* 1 = 0.0634077 loss)
I1001 20:53:59.881630  5547 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I1001 20:54:13.471011  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:54:14.041658  5547 solver.cpp:330] Iteration 42000, Testing net (#0)
I1001 20:54:17.405689  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:54:17.545970  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9223
I1001 20:54:17.545996  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.239127 (* 1 = 0.239127 loss)
I1001 20:54:17.687326  5547 solver.cpp:218] Iteration 42000 (5.6162 iter/s, 17.8056s/100 iters), loss = 0.0168917
I1001 20:54:17.687361  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0168916 (* 1 = 0.0168916 loss)
I1001 20:54:17.687367  5547 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I1001 20:54:31.952692  5547 solver.cpp:218] Iteration 42100 (7.01002 iter/s, 14.2653s/100 iters), loss = 0.0464026
I1001 20:54:31.952734  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0464026 (* 1 = 0.0464026 loss)
I1001 20:54:31.952741  5547 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I1001 20:54:46.228396  5547 solver.cpp:218] Iteration 42200 (7.00495 iter/s, 14.2756s/100 iters), loss = 0.0599373
I1001 20:54:46.228535  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0599373 (* 1 = 0.0599373 loss)
I1001 20:54:46.228543  5547 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I1001 20:55:00.491927  5547 solver.cpp:218] Iteration 42300 (7.01097 iter/s, 14.2634s/100 iters), loss = 0.0619159
I1001 20:55:00.491957  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0619158 (* 1 = 0.0619158 loss)
I1001 20:55:00.491963  5547 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I1001 20:55:14.764824  5547 solver.cpp:218] Iteration 42400 (7.00632 iter/s, 14.2728s/100 iters), loss = 0.032623
I1001 20:55:14.764865  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.032623 (* 1 = 0.032623 loss)
I1001 20:55:14.764871  5547 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I1001 20:55:28.345564  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:55:28.915710  5547 solver.cpp:330] Iteration 42500, Testing net (#0)
I1001 20:55:32.283537  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:55:32.423910  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9221
I1001 20:55:32.423948  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.238769 (* 1 = 0.238769 loss)
I1001 20:55:32.565207  5547 solver.cpp:218] Iteration 42500 (5.61789 iter/s, 17.8003s/100 iters), loss = 0.0382619
I1001 20:55:32.565240  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0382618 (* 1 = 0.0382618 loss)
I1001 20:55:32.565248  5547 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I1001 20:55:46.840692  5547 solver.cpp:218] Iteration 42600 (7.00505 iter/s, 14.2754s/100 iters), loss = 0.0418001
I1001 20:55:46.840723  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0418 (* 1 = 0.0418 loss)
I1001 20:55:46.840730  5547 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I1001 20:56:01.115893  5547 solver.cpp:218] Iteration 42700 (7.00519 iter/s, 14.2751s/100 iters), loss = 0.0591274
I1001 20:56:01.116008  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0591274 (* 1 = 0.0591274 loss)
I1001 20:56:01.116015  5547 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I1001 20:56:15.388819  5547 solver.cpp:218] Iteration 42800 (7.00635 iter/s, 14.2728s/100 iters), loss = 0.0411364
I1001 20:56:15.388860  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0411364 (* 1 = 0.0411364 loss)
I1001 20:56:15.388866  5547 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I1001 20:56:29.678736  5547 solver.cpp:218] Iteration 42900 (6.99798 iter/s, 14.2898s/100 iters), loss = 0.0332135
I1001 20:56:29.678767  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0332135 (* 1 = 0.0332135 loss)
I1001 20:56:29.678773  5547 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I1001 20:56:43.246899  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:56:43.817239  5547 solver.cpp:330] Iteration 43000, Testing net (#0)
I1001 20:56:47.182730  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:56:47.322438  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9207
I1001 20:56:47.322474  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.249674 (* 1 = 0.249674 loss)
I1001 20:56:47.463443  5547 solver.cpp:218] Iteration 43000 (5.62284 iter/s, 17.7846s/100 iters), loss = 0.0221121
I1001 20:56:47.463497  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.022112 (* 1 = 0.022112 loss)
I1001 20:56:47.463513  5547 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I1001 20:57:01.746503  5547 solver.cpp:218] Iteration 43100 (7.00135 iter/s, 14.283s/100 iters), loss = 0.0760009
I1001 20:57:01.746546  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0760008 (* 1 = 0.0760008 loss)
I1001 20:57:01.746552  5547 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I1001 20:57:16.038079  5547 solver.cpp:218] Iteration 43200 (6.99717 iter/s, 14.2915s/100 iters), loss = 0.0925459
I1001 20:57:16.038221  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0925459 (* 1 = 0.0925459 loss)
I1001 20:57:16.038239  5547 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I1001 20:57:30.308809  5547 solver.cpp:218] Iteration 43300 (7.00743 iter/s, 14.2706s/100 iters), loss = 0.0404415
I1001 20:57:30.308850  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0404415 (* 1 = 0.0404415 loss)
I1001 20:57:30.308856  5547 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I1001 20:57:44.592064  5547 solver.cpp:218] Iteration 43400 (7.00125 iter/s, 14.2832s/100 iters), loss = 0.0101829
I1001 20:57:44.592094  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101828 (* 1 = 0.0101828 loss)
I1001 20:57:44.592100  5547 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I1001 20:57:58.163673  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:57:58.733794  5547 solver.cpp:330] Iteration 43500, Testing net (#0)
I1001 20:58:02.104990  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:58:02.244910  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9233
I1001 20:58:02.244935  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.247815 (* 1 = 0.247815 loss)
I1001 20:58:02.386637  5547 solver.cpp:218] Iteration 43500 (5.61972 iter/s, 17.7945s/100 iters), loss = 0.0417809
I1001 20:58:02.386668  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0417808 (* 1 = 0.0417808 loss)
I1001 20:58:02.386675  5547 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I1001 20:58:16.676844  5547 solver.cpp:218] Iteration 43600 (6.99784 iter/s, 14.2901s/100 iters), loss = 0.0457368
I1001 20:58:16.676874  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0457367 (* 1 = 0.0457367 loss)
I1001 20:58:16.676880  5547 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I1001 20:58:30.974858  5547 solver.cpp:218] Iteration 43700 (6.99402 iter/s, 14.2979s/100 iters), loss = 0.0307914
I1001 20:58:30.974973  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0307913 (* 1 = 0.0307913 loss)
I1001 20:58:30.974982  5547 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I1001 20:58:45.277823  5547 solver.cpp:218] Iteration 43800 (6.99163 iter/s, 14.3028s/100 iters), loss = 0.0321126
I1001 20:58:45.277863  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0321125 (* 1 = 0.0321125 loss)
I1001 20:58:45.277869  5547 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I1001 20:58:59.574162  5547 solver.cpp:218] Iteration 43900 (6.99484 iter/s, 14.2962s/100 iters), loss = 0.0359432
I1001 20:58:59.574204  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0359432 (* 1 = 0.0359432 loss)
I1001 20:58:59.574211  5547 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I1001 20:59:13.163044  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:59:13.734072  5547 solver.cpp:330] Iteration 44000, Testing net (#0)
I1001 20:59:17.104032  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 20:59:17.244076  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9268
I1001 20:59:17.244112  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.241788 (* 1 = 0.241788 loss)
I1001 20:59:17.386329  5547 solver.cpp:218] Iteration 44000 (5.61417 iter/s, 17.8121s/100 iters), loss = 0.0254118
I1001 20:59:17.386363  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0254117 (* 1 = 0.0254117 loss)
I1001 20:59:17.386371  5547 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I1001 20:59:31.683598  5547 solver.cpp:218] Iteration 44100 (6.99438 iter/s, 14.2972s/100 iters), loss = 0.0254151
I1001 20:59:31.683629  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.025415 (* 1 = 0.025415 loss)
I1001 20:59:31.683635  5547 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I1001 20:59:45.970876  5547 solver.cpp:218] Iteration 44200 (6.99927 iter/s, 14.2872s/100 iters), loss = 0.036114
I1001 20:59:45.971118  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0361139 (* 1 = 0.0361139 loss)
I1001 20:59:45.971138  5547 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I1001 21:00:00.252566  5547 solver.cpp:218] Iteration 44300 (7.00213 iter/s, 14.2814s/100 iters), loss = 0.0404295
I1001 21:00:00.252600  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0404294 (* 1 = 0.0404294 loss)
I1001 21:00:00.252607  5547 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I1001 21:00:14.550370  5547 solver.cpp:218] Iteration 44400 (6.99412 iter/s, 14.2977s/100 iters), loss = 0.023561
I1001 21:00:14.550401  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.023561 (* 1 = 0.023561 loss)
I1001 21:00:14.550417  5547 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I1001 21:00:28.142781  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:00:28.713121  5547 solver.cpp:330] Iteration 44500, Testing net (#0)
I1001 21:00:32.080555  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:00:32.220839  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9193
I1001 21:00:32.220862  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.264238 (* 1 = 0.264238 loss)
I1001 21:00:32.362275  5547 solver.cpp:218] Iteration 44500 (5.61425 iter/s, 17.8118s/100 iters), loss = 0.0291434
I1001 21:00:32.362304  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0291433 (* 1 = 0.0291433 loss)
I1001 21:00:32.362311  5547 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I1001 21:00:46.622903  5547 solver.cpp:218] Iteration 44600 (7.01235 iter/s, 14.2606s/100 iters), loss = 0.03114
I1001 21:00:46.622934  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0311399 (* 1 = 0.0311399 loss)
I1001 21:00:46.622941  5547 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I1001 21:01:00.897397  5547 solver.cpp:218] Iteration 44700 (7.00554 iter/s, 14.2744s/100 iters), loss = 0.0266728
I1001 21:01:00.897505  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0266727 (* 1 = 0.0266727 loss)
I1001 21:01:00.897513  5547 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I1001 21:01:15.173346  5547 solver.cpp:218] Iteration 44800 (7.00486 iter/s, 14.2758s/100 iters), loss = 0.0187116
I1001 21:01:15.173378  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0187115 (* 1 = 0.0187115 loss)
I1001 21:01:15.173384  5547 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I1001 21:01:29.447572  5547 solver.cpp:218] Iteration 44900 (7.00567 iter/s, 14.2741s/100 iters), loss = 0.0121147
I1001 21:01:29.447604  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121147 (* 1 = 0.0121147 loss)
I1001 21:01:29.447612  5547 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I1001 21:01:43.013993  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:01:43.584229  5547 solver.cpp:330] Iteration 45000, Testing net (#0)
I1001 21:01:46.953114  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:01:47.093551  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9191
I1001 21:01:47.093576  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.270088 (* 1 = 0.270088 loss)
I1001 21:01:47.235445  5547 solver.cpp:218] Iteration 45000 (5.62184 iter/s, 17.7878s/100 iters), loss = 0.0214308
I1001 21:01:47.235481  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0214308 (* 1 = 0.0214308 loss)
I1001 21:01:47.235487  5547 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I1001 21:02:01.519080  5547 solver.cpp:218] Iteration 45100 (7.00106 iter/s, 14.2836s/100 iters), loss = 0.0226443
I1001 21:02:01.519124  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0226443 (* 1 = 0.0226443 loss)
I1001 21:02:01.519129  5547 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I1001 21:02:15.791301  5547 solver.cpp:218] Iteration 45200 (7.00666 iter/s, 14.2721s/100 iters), loss = 0.018193
I1001 21:02:15.791473  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181929 (* 1 = 0.0181929 loss)
I1001 21:02:15.791482  5547 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I1001 21:02:30.073467  5547 solver.cpp:218] Iteration 45300 (7.00184 iter/s, 14.282s/100 iters), loss = 0.0461697
I1001 21:02:30.073508  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0461697 (* 1 = 0.0461697 loss)
I1001 21:02:30.073514  5547 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I1001 21:02:44.362640  5547 solver.cpp:218] Iteration 45400 (6.99835 iter/s, 14.2891s/100 iters), loss = 0.0149412
I1001 21:02:44.362669  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149411 (* 1 = 0.0149411 loss)
I1001 21:02:44.362675  5547 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I1001 21:02:57.931130  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:02:58.504935  5547 solver.cpp:330] Iteration 45500, Testing net (#0)
I1001 21:03:01.873831  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:03:02.013690  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9237
I1001 21:03:02.013716  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.254281 (* 1 = 0.254281 loss)
I1001 21:03:02.154754  5547 solver.cpp:218] Iteration 45500 (5.62049 iter/s, 17.792s/100 iters), loss = 0.0106725
I1001 21:03:02.154788  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106724 (* 1 = 0.0106724 loss)
I1001 21:03:02.154794  5547 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I1001 21:03:16.426527  5547 solver.cpp:218] Iteration 45600 (7.00688 iter/s, 14.2717s/100 iters), loss = 0.0109018
I1001 21:03:16.426558  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109018 (* 1 = 0.0109018 loss)
I1001 21:03:16.426564  5547 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I1001 21:03:30.701645  5547 solver.cpp:218] Iteration 45700 (7.00523 iter/s, 14.275s/100 iters), loss = 0.0514693
I1001 21:03:30.701781  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0514693 (* 1 = 0.0514693 loss)
I1001 21:03:30.701787  5547 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I1001 21:03:44.982868  5547 solver.cpp:218] Iteration 45800 (7.00229 iter/s, 14.281s/100 iters), loss = 0.024108
I1001 21:03:44.982909  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.024108 (* 1 = 0.024108 loss)
I1001 21:03:44.982915  5547 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I1001 21:03:59.252404  5547 solver.cpp:218] Iteration 45900 (7.00798 iter/s, 14.2694s/100 iters), loss = 0.0246704
I1001 21:03:59.252436  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0246703 (* 1 = 0.0246703 loss)
I1001 21:03:59.252442  5547 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I1001 21:04:12.818311  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:04:13.396422  5547 solver.cpp:330] Iteration 46000, Testing net (#0)
I1001 21:04:16.765358  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:04:16.905408  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9272
I1001 21:04:16.905444  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.246212 (* 1 = 0.246212 loss)
I1001 21:04:17.046878  5547 solver.cpp:218] Iteration 46000 (5.61975 iter/s, 17.7944s/100 iters), loss = 0.0396799
I1001 21:04:17.046914  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0396799 (* 1 = 0.0396799 loss)
I1001 21:04:17.046921  5547 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I1001 21:04:31.336647  5547 solver.cpp:218] Iteration 46100 (6.99805 iter/s, 14.2897s/100 iters), loss = 0.0315376
I1001 21:04:31.336678  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0315376 (* 1 = 0.0315376 loss)
I1001 21:04:31.336685  5547 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I1001 21:04:45.614955  5547 solver.cpp:218] Iteration 46200 (7.00367 iter/s, 14.2782s/100 iters), loss = 0.0382616
I1001 21:04:45.615093  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0382616 (* 1 = 0.0382616 loss)
I1001 21:04:45.615100  5547 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I1001 21:04:59.908737  5547 solver.cpp:218] Iteration 46300 (6.99614 iter/s, 14.2936s/100 iters), loss = 0.0071345
I1001 21:04:59.908767  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00713447 (* 1 = 0.00713447 loss)
I1001 21:04:59.908773  5547 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I1001 21:05:14.205421  5547 solver.cpp:218] Iteration 46400 (6.99467 iter/s, 14.2966s/100 iters), loss = 0.00801895
I1001 21:05:14.205456  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00801891 (* 1 = 0.00801891 loss)
I1001 21:05:14.205464  5547 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I1001 21:05:27.773751  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:05:28.351267  5547 solver.cpp:330] Iteration 46500, Testing net (#0)
I1001 21:05:31.717770  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:05:31.858135  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9265
I1001 21:05:31.858163  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.255625 (* 1 = 0.255625 loss)
I1001 21:05:31.999379  5547 solver.cpp:218] Iteration 46500 (5.61991 iter/s, 17.7939s/100 iters), loss = 0.00801212
I1001 21:05:31.999415  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00801205 (* 1 = 0.00801205 loss)
I1001 21:05:31.999424  5547 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I1001 21:05:46.295908  5547 solver.cpp:218] Iteration 46600 (6.99474 iter/s, 14.2964s/100 iters), loss = 0.031053
I1001 21:05:46.295945  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0310529 (* 1 = 0.0310529 loss)
I1001 21:05:46.295954  5547 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I1001 21:06:00.594705  5547 solver.cpp:218] Iteration 46700 (6.99364 iter/s, 14.2987s/100 iters), loss = 0.0347123
I1001 21:06:00.594825  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0347122 (* 1 = 0.0347122 loss)
I1001 21:06:00.594844  5547 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I1001 21:06:14.895417  5547 solver.cpp:218] Iteration 46800 (6.99273 iter/s, 14.3006s/100 iters), loss = 0.0164122
I1001 21:06:14.895448  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0164121 (* 1 = 0.0164121 loss)
I1001 21:06:14.895454  5547 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I1001 21:06:29.188383  5547 solver.cpp:218] Iteration 46900 (6.99649 iter/s, 14.2929s/100 iters), loss = 0.0359592
I1001 21:06:29.188415  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0359591 (* 1 = 0.0359591 loss)
I1001 21:06:29.188421  5547 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I1001 21:06:42.768241  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:06:43.347733  5547 solver.cpp:330] Iteration 47000, Testing net (#0)
I1001 21:06:46.714289  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:06:46.854841  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9247
I1001 21:06:46.854877  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.263809 (* 1 = 0.263809 loss)
I1001 21:06:46.996829  5547 solver.cpp:218] Iteration 47000 (5.61534 iter/s, 17.8084s/100 iters), loss = 0.0282953
I1001 21:06:46.996865  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0282953 (* 1 = 0.0282953 loss)
I1001 21:06:46.996871  5547 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I1001 21:07:01.271482  5547 solver.cpp:218] Iteration 47100 (7.00546 iter/s, 14.2746s/100 iters), loss = 0.069942
I1001 21:07:01.271517  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.069942 (* 1 = 0.069942 loss)
I1001 21:07:01.271524  5547 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I1001 21:07:15.534603  5547 solver.cpp:218] Iteration 47200 (7.01113 iter/s, 14.263s/100 iters), loss = 0.0384119
I1001 21:07:15.534692  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0384119 (* 1 = 0.0384119 loss)
I1001 21:07:15.534708  5547 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I1001 21:07:29.822365  5547 solver.cpp:218] Iteration 47300 (6.99906 iter/s, 14.2876s/100 iters), loss = 0.00775881
I1001 21:07:29.822396  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00775878 (* 1 = 0.00775878 loss)
I1001 21:07:29.822403  5547 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I1001 21:07:44.103703  5547 solver.cpp:218] Iteration 47400 (7.00219 iter/s, 14.2813s/100 iters), loss = 0.00849671
I1001 21:07:44.103744  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00849667 (* 1 = 0.00849667 loss)
I1001 21:07:44.103750  5547 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I1001 21:07:57.663049  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:07:58.240000  5547 solver.cpp:330] Iteration 47500, Testing net (#0)
I1001 21:08:01.608901  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:08:01.748754  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9252
I1001 21:08:01.748788  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.260321 (* 1 = 0.260321 loss)
I1001 21:08:01.890013  5547 solver.cpp:218] Iteration 47500 (5.62233 iter/s, 17.7862s/100 iters), loss = 0.00702646
I1001 21:08:01.890048  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00702641 (* 1 = 0.00702641 loss)
I1001 21:08:01.890055  5547 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I1001 21:08:16.176134  5547 solver.cpp:218] Iteration 47600 (6.99984 iter/s, 14.286s/100 iters), loss = 0.06134
I1001 21:08:16.176168  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0613399 (* 1 = 0.0613399 loss)
I1001 21:08:16.176175  5547 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I1001 21:08:30.454493  5547 solver.cpp:218] Iteration 47700 (7.00364 iter/s, 14.2783s/100 iters), loss = 0.0341862
I1001 21:08:30.454643  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0341861 (* 1 = 0.0341861 loss)
I1001 21:08:30.454649  5547 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I1001 21:08:44.729876  5547 solver.cpp:218] Iteration 47800 (7.00516 iter/s, 14.2752s/100 iters), loss = 0.0192985
I1001 21:08:44.729905  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0192985 (* 1 = 0.0192985 loss)
I1001 21:08:44.729910  5547 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I1001 21:08:59.019733  5547 solver.cpp:218] Iteration 47900 (6.99801 iter/s, 14.2898s/100 iters), loss = 0.0321625
I1001 21:08:59.019771  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0321624 (* 1 = 0.0321624 loss)
I1001 21:08:59.019780  5547 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I1001 21:09:12.590180  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:09:13.170004  5547 solver.cpp:330] Iteration 48000, Testing net (#0)
I1001 21:09:16.539399  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:09:16.679404  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9246
I1001 21:09:16.679430  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.26858 (* 1 = 0.26858 loss)
I1001 21:09:16.821249  5547 solver.cpp:218] Iteration 48000 (5.61753 iter/s, 17.8014s/100 iters), loss = 0.00770447
I1001 21:09:16.821283  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00770441 (* 1 = 0.00770441 loss)
I1001 21:09:16.821293  5547 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I1001 21:09:31.091545  5547 solver.cpp:218] Iteration 48100 (7.0076 iter/s, 14.2702s/100 iters), loss = 0.0724677
I1001 21:09:31.091584  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0724676 (* 1 = 0.0724676 loss)
I1001 21:09:31.091594  5547 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I1001 21:09:45.370962  5547 solver.cpp:218] Iteration 48200 (7.00313 iter/s, 14.2793s/100 iters), loss = 0.0122779
I1001 21:09:45.371105  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122778 (* 1 = 0.0122778 loss)
I1001 21:09:45.371117  5547 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I1001 21:09:59.658871  5547 solver.cpp:218] Iteration 48300 (6.99901 iter/s, 14.2877s/100 iters), loss = 0.010181
I1001 21:09:59.658906  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101809 (* 1 = 0.0101809 loss)
I1001 21:09:59.658915  5547 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I1001 21:10:13.939402  5547 solver.cpp:218] Iteration 48400 (7.00258 iter/s, 14.2804s/100 iters), loss = 0.0078713
I1001 21:10:13.939438  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00787122 (* 1 = 0.00787122 loss)
I1001 21:10:13.939447  5547 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I1001 21:10:27.504793  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:10:28.084472  5547 solver.cpp:330] Iteration 48500, Testing net (#0)
I1001 21:10:31.456348  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:10:31.596799  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9264
I1001 21:10:31.596827  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.266786 (* 1 = 0.266786 loss)
I1001 21:10:31.738741  5547 solver.cpp:218] Iteration 48500 (5.61821 iter/s, 17.7993s/100 iters), loss = 0.00303168
I1001 21:10:31.738777  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00303162 (* 1 = 0.00303162 loss)
I1001 21:10:31.738787  5547 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I1001 21:10:46.030514  5547 solver.cpp:218] Iteration 48600 (6.99707 iter/s, 14.2917s/100 iters), loss = 0.00608876
I1001 21:10:46.030556  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00608869 (* 1 = 0.00608869 loss)
I1001 21:10:46.030566  5547 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I1001 21:11:00.317739  5547 solver.cpp:218] Iteration 48700 (6.9993 iter/s, 14.2871s/100 iters), loss = 0.00527538
I1001 21:11:00.317857  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00527532 (* 1 = 0.00527532 loss)
I1001 21:11:00.317867  5547 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I1001 21:11:14.599390  5547 solver.cpp:218] Iteration 48800 (7.00207 iter/s, 14.2815s/100 iters), loss = 0.0100146
I1001 21:11:14.599423  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100146 (* 1 = 0.0100146 loss)
I1001 21:11:14.599431  5547 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I1001 21:11:28.898524  5547 solver.cpp:218] Iteration 48900 (6.99347 iter/s, 14.2991s/100 iters), loss = 0.0158062
I1001 21:11:28.898561  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0158061 (* 1 = 0.0158061 loss)
I1001 21:11:28.898571  5547 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I1001 21:11:42.480705  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:11:43.056759  5547 solver.cpp:330] Iteration 49000, Testing net (#0)
I1001 21:11:46.424729  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:11:46.564514  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9274
I1001 21:11:46.564540  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.267852 (* 1 = 0.267852 loss)
I1001 21:11:46.707165  5547 solver.cpp:218] Iteration 49000 (5.61528 iter/s, 17.8085s/100 iters), loss = 0.0317565
I1001 21:11:46.707201  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0317565 (* 1 = 0.0317565 loss)
I1001 21:11:46.707211  5547 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I1001 21:12:00.981322  5547 solver.cpp:218] Iteration 49100 (7.00571 iter/s, 14.2741s/100 iters), loss = 0.0371716
I1001 21:12:00.981361  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0371715 (* 1 = 0.0371715 loss)
I1001 21:12:00.981370  5547 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I1001 21:12:15.278009  5547 solver.cpp:218] Iteration 49200 (6.99467 iter/s, 14.2966s/100 iters), loss = 0.00370444
I1001 21:12:15.278159  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00370438 (* 1 = 0.00370438 loss)
I1001 21:12:15.278172  5547 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I1001 21:12:29.575311  5547 solver.cpp:218] Iteration 49300 (6.99442 iter/s, 14.2971s/100 iters), loss = 0.00949014
I1001 21:12:29.575347  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00949008 (* 1 = 0.00949008 loss)
I1001 21:12:29.575356  5547 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I1001 21:12:43.871227  5547 solver.cpp:218] Iteration 49400 (6.99505 iter/s, 14.2958s/100 iters), loss = 0.0238063
I1001 21:12:43.871263  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0238062 (* 1 = 0.0238062 loss)
I1001 21:12:43.871271  5547 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I1001 21:12:57.445737  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:12:58.021697  5547 solver.cpp:330] Iteration 49500, Testing net (#0)
I1001 21:13:01.395383  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:13:01.535805  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9239
I1001 21:13:01.535832  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.282886 (* 1 = 0.282886 loss)
I1001 21:13:01.677767  5547 solver.cpp:218] Iteration 49500 (5.61594 iter/s, 17.8065s/100 iters), loss = 0.0258575
I1001 21:13:01.677803  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0258574 (* 1 = 0.0258574 loss)
I1001 21:13:01.677811  5547 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I1001 21:13:15.953685  5547 solver.cpp:218] Iteration 49600 (7.00484 iter/s, 14.2758s/100 iters), loss = 0.0272125
I1001 21:13:15.953727  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0272124 (* 1 = 0.0272124 loss)
I1001 21:13:15.953747  5547 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I1001 21:13:30.228461  5547 solver.cpp:218] Iteration 49700 (7.00542 iter/s, 14.2747s/100 iters), loss = 0.00288999
I1001 21:13:30.228617  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00288992 (* 1 = 0.00288992 loss)
I1001 21:13:30.228631  5547 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I1001 21:13:44.507839  5547 solver.cpp:218] Iteration 49800 (7.0032 iter/s, 14.2792s/100 iters), loss = 0.0281387
I1001 21:13:44.507870  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0281387 (* 1 = 0.0281387 loss)
I1001 21:13:44.507876  5547 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I1001 21:13:58.794387  5547 solver.cpp:218] Iteration 49900 (6.99963 iter/s, 14.2865s/100 iters), loss = 0.0231412
I1001 21:13:58.794420  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0231411 (* 1 = 0.0231411 loss)
I1001 21:13:58.794427  5547 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I1001 21:14:12.361176  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:14:12.932752  5547 solver.cpp:330] Iteration 50000, Testing net (#0)
I1001 21:14:16.302440  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:14:16.442459  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9247
I1001 21:14:16.442494  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.281265 (* 1 = 0.281265 loss)
I1001 21:14:16.583622  5547 solver.cpp:218] Iteration 50000 (5.6214 iter/s, 17.7892s/100 iters), loss = 0.00482978
I1001 21:14:16.583659  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00482974 (* 1 = 0.00482974 loss)
I1001 21:14:16.583667  5547 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I1001 21:14:30.861825  5547 solver.cpp:218] Iteration 50100 (7.00372 iter/s, 14.2781s/100 iters), loss = 0.018211
I1001 21:14:30.861861  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0182109 (* 1 = 0.0182109 loss)
I1001 21:14:30.861868  5547 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I1001 21:14:45.145658  5547 solver.cpp:218] Iteration 50200 (7.00096 iter/s, 14.2838s/100 iters), loss = 0.00952823
I1001 21:14:45.145768  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00952819 (* 1 = 0.00952819 loss)
I1001 21:14:45.145776  5547 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I1001 21:14:59.421443  5547 solver.cpp:218] Iteration 50300 (7.00494 iter/s, 14.2756s/100 iters), loss = 0.0266502
I1001 21:14:59.421475  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0266502 (* 1 = 0.0266502 loss)
I1001 21:14:59.421492  5547 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I1001 21:15:13.699231  5547 solver.cpp:218] Iteration 50400 (7.00392 iter/s, 14.2777s/100 iters), loss = 0.00590683
I1001 21:15:13.699262  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00590677 (* 1 = 0.00590677 loss)
I1001 21:15:13.699270  5547 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I1001 21:15:27.268687  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:15:27.838870  5547 solver.cpp:330] Iteration 50500, Testing net (#0)
I1001 21:15:31.218109  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:15:31.358077  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.922
I1001 21:15:31.358114  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300147 (* 1 = 0.300147 loss)
I1001 21:15:31.499181  5547 solver.cpp:218] Iteration 50500 (5.61802 iter/s, 17.7999s/100 iters), loss = 0.00966413
I1001 21:15:31.499214  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00966406 (* 1 = 0.00966406 loss)
I1001 21:15:31.499222  5547 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I1001 21:15:45.765755  5547 solver.cpp:218] Iteration 50600 (7.00943 iter/s, 14.2665s/100 iters), loss = 0.0273403
I1001 21:15:45.765784  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0273402 (* 1 = 0.0273402 loss)
I1001 21:15:45.765791  5547 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I1001 21:16:00.044651  5547 solver.cpp:218] Iteration 50700 (7.00338 iter/s, 14.2788s/100 iters), loss = 0.00585927
I1001 21:16:00.044751  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0058592 (* 1 = 0.0058592 loss)
I1001 21:16:00.044759  5547 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I1001 21:16:14.341615  5547 solver.cpp:218] Iteration 50800 (6.99456 iter/s, 14.2968s/100 iters), loss = 0.00766237
I1001 21:16:14.341646  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00766231 (* 1 = 0.00766231 loss)
I1001 21:16:14.341652  5547 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I1001 21:16:28.629214  5547 solver.cpp:218] Iteration 50900 (6.99912 iter/s, 14.2875s/100 iters), loss = 0.00888054
I1001 21:16:28.629248  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00888048 (* 1 = 0.00888048 loss)
I1001 21:16:28.629266  5547 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I1001 21:16:42.188742  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:16:42.758265  5547 solver.cpp:330] Iteration 51000, Testing net (#0)
I1001 21:16:46.132697  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:16:46.272755  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9235
I1001 21:16:46.272781  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.293951 (* 1 = 0.293951 loss)
I1001 21:16:46.414261  5547 solver.cpp:218] Iteration 51000 (5.62273 iter/s, 17.785s/100 iters), loss = 0.00408407
I1001 21:16:46.414295  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00408402 (* 1 = 0.00408402 loss)
I1001 21:16:46.414302  5547 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I1001 21:17:00.701045  5547 solver.cpp:218] Iteration 51100 (6.99952 iter/s, 14.2867s/100 iters), loss = 0.0485691
I1001 21:17:00.701074  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.048569 (* 1 = 0.048569 loss)
I1001 21:17:00.701081  5547 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I1001 21:17:14.991313  5547 solver.cpp:218] Iteration 51200 (6.9978 iter/s, 14.2902s/100 iters), loss = 0.0266953
I1001 21:17:14.991441  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0266952 (* 1 = 0.0266952 loss)
I1001 21:17:14.991448  5547 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I1001 21:17:29.275069  5547 solver.cpp:218] Iteration 51300 (7.00104 iter/s, 14.2836s/100 iters), loss = 0.0142841
I1001 21:17:29.275104  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142841 (* 1 = 0.0142841 loss)
I1001 21:17:29.275110  5547 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I1001 21:17:43.571385  5547 solver.cpp:218] Iteration 51400 (6.99485 iter/s, 14.2962s/100 iters), loss = 0.021408
I1001 21:17:43.571416  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0214079 (* 1 = 0.0214079 loss)
I1001 21:17:43.571424  5547 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I1001 21:17:57.145332  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:17:57.715292  5547 solver.cpp:330] Iteration 51500, Testing net (#0)
I1001 21:18:01.095496  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:18:01.236618  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.922
I1001 21:18:01.236644  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291054 (* 1 = 0.291054 loss)
I1001 21:18:01.378096  5547 solver.cpp:218] Iteration 51500 (5.61589 iter/s, 17.8066s/100 iters), loss = 0.0412312
I1001 21:18:01.378129  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0412311 (* 1 = 0.0412311 loss)
I1001 21:18:01.378136  5547 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I1001 21:18:15.648699  5547 solver.cpp:218] Iteration 51600 (7.00745 iter/s, 14.2705s/100 iters), loss = 0.015007
I1001 21:18:15.648730  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015007 (* 1 = 0.015007 loss)
I1001 21:18:15.648736  5547 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I1001 21:18:29.933532  5547 solver.cpp:218] Iteration 51700 (7.00047 iter/s, 14.2848s/100 iters), loss = 0.0184736
I1001 21:18:29.933671  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0184735 (* 1 = 0.0184735 loss)
I1001 21:18:29.933679  5547 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I1001 21:18:44.228477  5547 solver.cpp:218] Iteration 51800 (6.99557 iter/s, 14.2948s/100 iters), loss = 0.00630231
I1001 21:18:44.228507  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00630226 (* 1 = 0.00630226 loss)
I1001 21:18:44.228514  5547 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I1001 21:18:58.515206  5547 solver.cpp:218] Iteration 51900 (6.99954 iter/s, 14.2867s/100 iters), loss = 0.00475493
I1001 21:18:58.515239  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00475488 (* 1 = 0.00475488 loss)
I1001 21:18:58.515245  5547 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I1001 21:19:12.081631  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:19:12.651878  5547 solver.cpp:330] Iteration 52000, Testing net (#0)
I1001 21:19:16.024683  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:19:16.168608  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9254
I1001 21:19:16.168634  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.28131 (* 1 = 0.28131 loss)
I1001 21:19:16.310559  5547 solver.cpp:218] Iteration 52000 (5.61947 iter/s, 17.7953s/100 iters), loss = 0.00256724
I1001 21:19:16.310592  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00256719 (* 1 = 0.00256719 loss)
I1001 21:19:16.310600  5547 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I1001 21:19:30.587775  5547 solver.cpp:218] Iteration 52100 (7.0042 iter/s, 14.2771s/100 iters), loss = 0.00460807
I1001 21:19:30.587806  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00460802 (* 1 = 0.00460802 loss)
I1001 21:19:30.587813  5547 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I1001 21:19:44.864691  5547 solver.cpp:218] Iteration 52200 (7.00435 iter/s, 14.2768s/100 iters), loss = 0.0220923
I1001 21:19:44.864804  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0220923 (* 1 = 0.0220923 loss)
I1001 21:19:44.864810  5547 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I1001 21:19:59.137262  5547 solver.cpp:218] Iteration 52300 (7.00652 iter/s, 14.2724s/100 iters), loss = 0.0134254
I1001 21:19:59.137293  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134254 (* 1 = 0.0134254 loss)
I1001 21:19:59.137300  5547 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I1001 21:20:13.425623  5547 solver.cpp:218] Iteration 52400 (6.99874 iter/s, 14.2883s/100 iters), loss = 0.00798802
I1001 21:20:13.425654  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00798797 (* 1 = 0.00798797 loss)
I1001 21:20:13.425662  5547 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I1001 21:20:26.995136  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:20:27.566310  5547 solver.cpp:330] Iteration 52500, Testing net (#0)
I1001 21:20:30.936296  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:20:31.078939  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9245
I1001 21:20:31.078965  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.297547 (* 1 = 0.297547 loss)
I1001 21:20:31.222029  5547 solver.cpp:218] Iteration 52500 (5.61914 iter/s, 17.7963s/100 iters), loss = 0.00370523
I1001 21:20:31.222064  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00370518 (* 1 = 0.00370518 loss)
I1001 21:20:31.222071  5547 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I1001 21:20:45.488490  5547 solver.cpp:218] Iteration 52600 (7.00948 iter/s, 14.2664s/100 iters), loss = 0.0225389
I1001 21:20:45.488520  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0225388 (* 1 = 0.0225388 loss)
I1001 21:20:45.488528  5547 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I1001 21:20:59.774015  5547 solver.cpp:218] Iteration 52700 (7.00013 iter/s, 14.2855s/100 iters), loss = 0.00161186
I1001 21:20:59.774119  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00161182 (* 1 = 0.00161182 loss)
I1001 21:20:59.774127  5547 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I1001 21:21:14.071475  5547 solver.cpp:218] Iteration 52800 (6.99432 iter/s, 14.2973s/100 iters), loss = 0.00389296
I1001 21:21:14.071507  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00389291 (* 1 = 0.00389291 loss)
I1001 21:21:14.071513  5547 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I1001 21:21:28.352125  5547 solver.cpp:218] Iteration 52900 (7.00252 iter/s, 14.2806s/100 iters), loss = 0.00448269
I1001 21:21:28.352157  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00448263 (* 1 = 0.00448263 loss)
I1001 21:21:28.352164  5547 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I1001 21:21:41.926880  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:21:42.498047  5547 solver.cpp:330] Iteration 53000, Testing net (#0)
I1001 21:21:45.867007  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:21:46.013052  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9268
I1001 21:21:46.013108  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.290873 (* 1 = 0.290873 loss)
I1001 21:21:46.157989  5547 solver.cpp:218] Iteration 53000 (5.61616 iter/s, 17.8058s/100 iters), loss = 0.00229139
I1001 21:21:46.158037  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00229133 (* 1 = 0.00229133 loss)
I1001 21:21:46.158056  5547 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I1001 21:22:00.459367  5547 solver.cpp:218] Iteration 53100 (6.9924 iter/s, 14.3012s/100 iters), loss = 0.0156989
I1001 21:22:00.459398  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156988 (* 1 = 0.0156988 loss)
I1001 21:22:00.459403  5547 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I1001 21:22:14.753597  5547 solver.cpp:218] Iteration 53200 (6.99587 iter/s, 14.2942s/100 iters), loss = 0.0118582
I1001 21:22:14.753706  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118582 (* 1 = 0.0118582 loss)
I1001 21:22:14.753715  5547 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I1001 21:22:29.055821  5547 solver.cpp:218] Iteration 53300 (6.99199 iter/s, 14.3021s/100 iters), loss = 0.00765122
I1001 21:22:29.055855  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00765118 (* 1 = 0.00765118 loss)
I1001 21:22:29.055862  5547 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I1001 21:22:43.371364  5547 solver.cpp:218] Iteration 53400 (6.98545 iter/s, 14.3155s/100 iters), loss = 0.00349479
I1001 21:22:43.371407  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00349474 (* 1 = 0.00349474 loss)
I1001 21:22:43.371413  5547 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I1001 21:22:56.960459  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:22:57.530555  5547 solver.cpp:330] Iteration 53500, Testing net (#0)
I1001 21:23:00.899114  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:23:01.042387  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.926
I1001 21:23:01.042415  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296374 (* 1 = 0.296374 loss)
I1001 21:23:01.187152  5547 solver.cpp:218] Iteration 53500 (5.61303 iter/s, 17.8157s/100 iters), loss = 0.0144343
I1001 21:23:01.187187  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0144343 (* 1 = 0.0144343 loss)
I1001 21:23:01.187196  5547 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I1001 21:23:15.460530  5547 solver.cpp:218] Iteration 53600 (7.00609 iter/s, 14.2733s/100 iters), loss = 0.0100485
I1001 21:23:15.460561  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100485 (* 1 = 0.0100485 loss)
I1001 21:23:15.460566  5547 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I1001 21:23:29.750762  5547 solver.cpp:218] Iteration 53700 (6.99782 iter/s, 14.2902s/100 iters), loss = 0.0105764
I1001 21:23:29.750872  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105763 (* 1 = 0.0105763 loss)
I1001 21:23:29.750880  5547 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I1001 21:23:44.033455  5547 solver.cpp:218] Iteration 53800 (7.00156 iter/s, 14.2825s/100 iters), loss = 0.0122084
I1001 21:23:44.033488  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122084 (* 1 = 0.0122084 loss)
I1001 21:23:44.033495  5547 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I1001 21:23:58.313596  5547 solver.cpp:218] Iteration 53900 (7.00277 iter/s, 14.2801s/100 iters), loss = 0.00512185
I1001 21:23:58.313628  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00512179 (* 1 = 0.00512179 loss)
I1001 21:23:58.313635  5547 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I1001 21:24:11.887576  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:24:12.458335  5547 solver.cpp:330] Iteration 54000, Testing net (#0)
I1001 21:24:15.827684  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:24:15.971772  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9262
I1001 21:24:15.971813  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296638 (* 1 = 0.296638 loss)
I1001 21:24:16.117115  5547 solver.cpp:218] Iteration 54000 (5.6169 iter/s, 17.8034s/100 iters), loss = 0.0541647
I1001 21:24:16.117166  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0541646 (* 1 = 0.0541646 loss)
I1001 21:24:16.117173  5547 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I1001 21:24:30.399961  5547 solver.cpp:218] Iteration 54100 (7.00147 iter/s, 14.2827s/100 iters), loss = 0.00600891
I1001 21:24:30.399994  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00600886 (* 1 = 0.00600886 loss)
I1001 21:24:30.400002  5547 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I1001 21:24:44.682922  5547 solver.cpp:218] Iteration 54200 (7.00139 iter/s, 14.2829s/100 iters), loss = 0.00727312
I1001 21:24:44.683043  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00727308 (* 1 = 0.00727308 loss)
I1001 21:24:44.683050  5547 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I1001 21:24:58.970746  5547 solver.cpp:218] Iteration 54300 (6.99905 iter/s, 14.2877s/100 iters), loss = 0.0124446
I1001 21:24:58.970779  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124445 (* 1 = 0.0124445 loss)
I1001 21:24:58.970796  5547 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I1001 21:25:13.266801  5547 solver.cpp:218] Iteration 54400 (6.99498 iter/s, 14.296s/100 iters), loss = 0.0287819
I1001 21:25:13.266834  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0287819 (* 1 = 0.0287819 loss)
I1001 21:25:13.266841  5547 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I1001 21:25:26.826421  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:25:27.396728  5547 solver.cpp:330] Iteration 54500, Testing net (#0)
I1001 21:25:30.764730  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:25:30.905875  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9226
I1001 21:25:30.905903  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.297937 (* 1 = 0.297937 loss)
I1001 21:25:31.050496  5547 solver.cpp:218] Iteration 54500 (5.62316 iter/s, 17.7836s/100 iters), loss = 0.00246679
I1001 21:25:31.050537  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00246674 (* 1 = 0.00246674 loss)
I1001 21:25:31.050545  5547 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I1001 21:25:45.324487  5547 solver.cpp:218] Iteration 54600 (7.00579 iter/s, 14.2739s/100 iters), loss = 0.00469403
I1001 21:25:45.324517  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00469397 (* 1 = 0.00469397 loss)
I1001 21:25:45.324523  5547 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I1001 21:25:59.608822  5547 solver.cpp:218] Iteration 54700 (7.00071 iter/s, 14.2843s/100 iters), loss = 0.00184858
I1001 21:25:59.608925  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00184853 (* 1 = 0.00184853 loss)
I1001 21:25:59.608948  5547 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I1001 21:26:13.885218  5547 solver.cpp:218] Iteration 54800 (7.00464 iter/s, 14.2763s/100 iters), loss = 0.0228322
I1001 21:26:13.885248  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0228321 (* 1 = 0.0228321 loss)
I1001 21:26:13.885254  5547 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I1001 21:26:28.160609  5547 solver.cpp:218] Iteration 54900 (7.0051 iter/s, 14.2753s/100 iters), loss = 0.0125285
I1001 21:26:28.160645  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125285 (* 1 = 0.0125285 loss)
I1001 21:26:28.160653  5547 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I1001 21:26:41.732677  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:26:42.302605  5547 solver.cpp:330] Iteration 55000, Testing net (#0)
I1001 21:26:45.670159  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:26:45.810799  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9252
I1001 21:26:45.810834  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291392 (* 1 = 0.291392 loss)
I1001 21:26:45.953639  5547 solver.cpp:218] Iteration 55000 (5.62021 iter/s, 17.7929s/100 iters), loss = 0.0018556
I1001 21:26:45.953675  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00185555 (* 1 = 0.00185555 loss)
I1001 21:26:45.953682  5547 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I1001 21:27:00.235129  5547 solver.cpp:218] Iteration 55100 (7.00211 iter/s, 14.2814s/100 iters), loss = 0.00677051
I1001 21:27:00.235162  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00677046 (* 1 = 0.00677046 loss)
I1001 21:27:00.235169  5547 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I1001 21:27:14.518337  5547 solver.cpp:218] Iteration 55200 (7.00127 iter/s, 14.2831s/100 iters), loss = 0.0030754
I1001 21:27:14.518453  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00307535 (* 1 = 0.00307535 loss)
I1001 21:27:14.518461  5547 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I1001 21:27:28.812430  5547 solver.cpp:218] Iteration 55300 (6.99597 iter/s, 14.2939s/100 iters), loss = 0.00849954
I1001 21:27:28.812463  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00849949 (* 1 = 0.00849949 loss)
I1001 21:27:28.812469  5547 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I1001 21:27:43.095682  5547 solver.cpp:218] Iteration 55400 (7.00125 iter/s, 14.2832s/100 iters), loss = 0.0261378
I1001 21:27:43.095731  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0261377 (* 1 = 0.0261377 loss)
I1001 21:27:43.095738  5547 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I1001 21:27:56.663630  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:27:57.232774  5547 solver.cpp:330] Iteration 55500, Testing net (#0)
I1001 21:28:00.600294  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:28:00.740211  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9261
I1001 21:28:00.740245  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.293526 (* 1 = 0.293526 loss)
I1001 21:28:00.881479  5547 solver.cpp:218] Iteration 55500 (5.6225 iter/s, 17.7857s/100 iters), loss = 0.00424795
I1001 21:28:00.881520  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0042479 (* 1 = 0.0042479 loss)
I1001 21:28:00.881527  5547 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I1001 21:28:15.170892  5547 solver.cpp:218] Iteration 55600 (6.99827 iter/s, 14.2893s/100 iters), loss = 0.0113583
I1001 21:28:15.170923  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113582 (* 1 = 0.0113582 loss)
I1001 21:28:15.170929  5547 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I1001 21:28:29.469033  5547 solver.cpp:218] Iteration 55700 (6.99395 iter/s, 14.2981s/100 iters), loss = 0.0038249
I1001 21:28:29.469154  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00382484 (* 1 = 0.00382484 loss)
I1001 21:28:29.469162  5547 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I1001 21:28:43.757227  5547 solver.cpp:218] Iteration 55800 (6.99886 iter/s, 14.288s/100 iters), loss = 0.00102915
I1001 21:28:43.757259  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010291 (* 1 = 0.0010291 loss)
I1001 21:28:43.757266  5547 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I1001 21:28:58.051744  5547 solver.cpp:218] Iteration 55900 (6.99573 iter/s, 14.2944s/100 iters), loss = 0.00271583
I1001 21:28:58.051805  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00271578 (* 1 = 0.00271578 loss)
I1001 21:28:58.051816  5547 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I1001 21:29:11.637779  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:29:12.207309  5547 solver.cpp:330] Iteration 56000, Testing net (#0)
I1001 21:29:15.575765  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:29:15.716085  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9262
I1001 21:29:15.716110  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.302638 (* 1 = 0.302638 loss)
I1001 21:29:15.857553  5547 solver.cpp:218] Iteration 56000 (5.61619 iter/s, 17.8057s/100 iters), loss = 0.00250364
I1001 21:29:15.857583  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0025036 (* 1 = 0.0025036 loss)
I1001 21:29:15.857590  5547 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I1001 21:29:30.140085  5547 solver.cpp:218] Iteration 56100 (7.0016 iter/s, 14.2825s/100 iters), loss = 0.0206847
I1001 21:29:30.140116  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0206847 (* 1 = 0.0206847 loss)
I1001 21:29:30.140122  5547 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I1001 21:29:44.427361  5547 solver.cpp:218] Iteration 56200 (6.99927 iter/s, 14.2872s/100 iters), loss = 0.0167249
I1001 21:29:44.427505  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0167249 (* 1 = 0.0167249 loss)
I1001 21:29:44.427515  5547 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I1001 21:29:58.723562  5547 solver.cpp:218] Iteration 56300 (6.99496 iter/s, 14.296s/100 iters), loss = 0.00919955
I1001 21:29:58.723603  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0091995 (* 1 = 0.0091995 loss)
I1001 21:29:58.723610  5547 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I1001 21:30:12.999079  5547 solver.cpp:218] Iteration 56400 (7.00504 iter/s, 14.2754s/100 iters), loss = 0.00326899
I1001 21:30:12.999128  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00326894 (* 1 = 0.00326894 loss)
I1001 21:30:12.999135  5547 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I1001 21:30:26.566948  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:30:27.136826  5547 solver.cpp:330] Iteration 56500, Testing net (#0)
I1001 21:30:30.506619  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:30:30.646908  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I1001 21:30:30.646945  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300732 (* 1 = 0.300732 loss)
I1001 21:30:30.787704  5547 solver.cpp:218] Iteration 56500 (5.62161 iter/s, 17.7885s/100 iters), loss = 0.0148286
I1001 21:30:30.787737  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148285 (* 1 = 0.0148285 loss)
I1001 21:30:30.787744  5547 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I1001 21:30:45.075371  5547 solver.cpp:218] Iteration 56600 (6.99908 iter/s, 14.2876s/100 iters), loss = 0.00895094
I1001 21:30:45.075402  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00895089 (* 1 = 0.00895089 loss)
I1001 21:30:45.075407  5547 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I1001 21:30:59.355599  5547 solver.cpp:218] Iteration 56700 (7.00273 iter/s, 14.2802s/100 iters), loss = 0.00952253
I1001 21:30:59.355726  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00952249 (* 1 = 0.00952249 loss)
I1001 21:30:59.355733  5547 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I1001 21:31:13.634610  5547 solver.cpp:218] Iteration 56800 (7.00337 iter/s, 14.2788s/100 iters), loss = 0.00113148
I1001 21:31:13.634644  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00113144 (* 1 = 0.00113144 loss)
I1001 21:31:13.634650  5547 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I1001 21:31:27.911044  5547 solver.cpp:218] Iteration 56900 (7.00459 iter/s, 14.2764s/100 iters), loss = 0.00396649
I1001 21:31:27.911074  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00396644 (* 1 = 0.00396644 loss)
I1001 21:31:27.911080  5547 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I1001 21:31:41.495157  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:31:42.065073  5547 solver.cpp:330] Iteration 57000, Testing net (#0)
I1001 21:31:45.431438  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:31:45.571352  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.925
I1001 21:31:45.571377  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304111 (* 1 = 0.304111 loss)
I1001 21:31:45.712282  5547 solver.cpp:218] Iteration 57000 (5.61761 iter/s, 17.8012s/100 iters), loss = 0.00300196
I1001 21:31:45.712323  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00300192 (* 1 = 0.00300192 loss)
I1001 21:31:45.712330  5547 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I1001 21:31:59.994360  5547 solver.cpp:218] Iteration 57100 (7.00187 iter/s, 14.2819s/100 iters), loss = 0.00197971
I1001 21:31:59.994391  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00197968 (* 1 = 0.00197968 loss)
I1001 21:31:59.994398  5547 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I1001 21:32:14.294872  5547 solver.cpp:218] Iteration 57200 (6.99279 iter/s, 14.3004s/100 iters), loss = 0.00650658
I1001 21:32:14.294978  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00650654 (* 1 = 0.00650654 loss)
I1001 21:32:14.294986  5547 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I1001 21:32:28.594621  5547 solver.cpp:218] Iteration 57300 (6.9932 iter/s, 14.2996s/100 iters), loss = 0.0140562
I1001 21:32:28.594653  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0140561 (* 1 = 0.0140561 loss)
I1001 21:32:28.594660  5547 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I1001 21:32:42.873636  5547 solver.cpp:218] Iteration 57400 (7.00332 iter/s, 14.2789s/100 iters), loss = 0.0141102
I1001 21:32:42.873664  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141101 (* 1 = 0.0141101 loss)
I1001 21:32:42.873670  5547 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I1001 21:32:56.461066  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:32:57.029954  5547 solver.cpp:330] Iteration 57500, Testing net (#0)
I1001 21:33:00.399233  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:33:00.539062  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9238
I1001 21:33:00.539096  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307401 (* 1 = 0.307401 loss)
I1001 21:33:00.680629  5547 solver.cpp:218] Iteration 57500 (5.6158 iter/s, 17.8069s/100 iters), loss = 0.00588729
I1001 21:33:00.680660  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00588726 (* 1 = 0.00588726 loss)
I1001 21:33:00.680667  5547 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I1001 21:33:14.977727  5547 solver.cpp:218] Iteration 57600 (6.99446 iter/s, 14.297s/100 iters), loss = 0.00308901
I1001 21:33:14.977768  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00308897 (* 1 = 0.00308897 loss)
I1001 21:33:14.977774  5547 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I1001 21:33:29.271819  5547 solver.cpp:218] Iteration 57700 (6.99594 iter/s, 14.294s/100 iters), loss = 0.011181
I1001 21:33:29.271966  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011181 (* 1 = 0.011181 loss)
I1001 21:33:29.271975  5547 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I1001 21:33:43.560864  5547 solver.cpp:218] Iteration 57800 (6.99846 iter/s, 14.2889s/100 iters), loss = 0.00681009
I1001 21:33:43.560897  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00681005 (* 1 = 0.00681005 loss)
I1001 21:33:43.560904  5547 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I1001 21:33:57.851307  5547 solver.cpp:218] Iteration 57900 (6.99772 iter/s, 14.2904s/100 iters), loss = 0.000945952
I1001 21:33:57.851336  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000945901 (* 1 = 0.000945901 loss)
I1001 21:33:57.851342  5547 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I1001 21:34:11.439388  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:34:12.008960  5547 solver.cpp:330] Iteration 58000, Testing net (#0)
I1001 21:34:15.374982  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:34:15.514927  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9276
I1001 21:34:15.514961  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.301371 (* 1 = 0.301371 loss)
I1001 21:34:15.656246  5547 solver.cpp:218] Iteration 58000 (5.61645 iter/s, 17.8049s/100 iters), loss = 0.00328034
I1001 21:34:15.656291  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00328029 (* 1 = 0.00328029 loss)
I1001 21:34:15.656306  5547 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I1001 21:34:29.931541  5547 solver.cpp:218] Iteration 58100 (7.00517 iter/s, 14.2752s/100 iters), loss = 0.00398639
I1001 21:34:29.931581  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00398635 (* 1 = 0.00398635 loss)
I1001 21:34:29.931588  5547 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I1001 21:34:44.212882  5547 solver.cpp:218] Iteration 58200 (7.00218 iter/s, 14.2813s/100 iters), loss = 0.00294375
I1001 21:34:44.212985  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00294371 (* 1 = 0.00294371 loss)
I1001 21:34:44.213002  5547 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I1001 21:34:58.496896  5547 solver.cpp:218] Iteration 58300 (7.00091 iter/s, 14.2839s/100 iters), loss = 0.00392507
I1001 21:34:58.496935  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00392502 (* 1 = 0.00392502 loss)
I1001 21:34:58.496942  5547 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I1001 21:35:12.769384  5547 solver.cpp:218] Iteration 58400 (7.00653 iter/s, 14.2724s/100 iters), loss = 0.00879365
I1001 21:35:12.769426  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0087936 (* 1 = 0.0087936 loss)
I1001 21:35:12.769433  5547 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I1001 21:35:26.344668  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:35:26.912923  5547 solver.cpp:330] Iteration 58500, Testing net (#0)
I1001 21:35:30.282361  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:35:30.422721  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9274
I1001 21:35:30.422757  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.301248 (* 1 = 0.301248 loss)
I1001 21:35:30.564019  5547 solver.cpp:218] Iteration 58500 (5.6197 iter/s, 17.7945s/100 iters), loss = 0.0151078
I1001 21:35:30.564050  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0151078 (* 1 = 0.0151078 loss)
I1001 21:35:30.564057  5547 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I1001 21:35:44.851140  5547 solver.cpp:218] Iteration 58600 (6.99935 iter/s, 14.287s/100 iters), loss = 0.00141439
I1001 21:35:44.851181  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00141434 (* 1 = 0.00141434 loss)
I1001 21:35:44.851187  5547 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I1001 21:35:59.129904  5547 solver.cpp:218] Iteration 58700 (7.00345 iter/s, 14.2787s/100 iters), loss = 0.0181665
I1001 21:35:59.130019  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181664 (* 1 = 0.0181664 loss)
I1001 21:35:59.130038  5547 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I1001 21:36:13.419349  5547 solver.cpp:218] Iteration 58800 (6.99825 iter/s, 14.2893s/100 iters), loss = 0.00459788
I1001 21:36:13.419383  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00459782 (* 1 = 0.00459782 loss)
I1001 21:36:13.419389  5547 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I1001 21:36:27.700945  5547 solver.cpp:218] Iteration 58900 (7.00206 iter/s, 14.2815s/100 iters), loss = 0.0108292
I1001 21:36:27.700978  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108291 (* 1 = 0.0108291 loss)
I1001 21:36:27.700985  5547 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I1001 21:36:41.277570  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:36:41.848558  5547 solver.cpp:330] Iteration 59000, Testing net (#0)
I1001 21:36:45.215463  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:36:45.355324  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9172
I1001 21:36:45.355348  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.354212 (* 1 = 0.354212 loss)
I1001 21:36:45.496424  5547 solver.cpp:218] Iteration 59000 (5.61943 iter/s, 17.7954s/100 iters), loss = 0.0094385
I1001 21:36:45.496464  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00943843 (* 1 = 0.00943843 loss)
I1001 21:36:45.496472  5547 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I1001 21:36:59.772555  5547 solver.cpp:218] Iteration 59100 (7.00474 iter/s, 14.276s/100 iters), loss = 0.00373799
I1001 21:36:59.772598  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00373792 (* 1 = 0.00373792 loss)
I1001 21:36:59.772605  5547 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I1001 21:37:14.055213  5547 solver.cpp:218] Iteration 59200 (7.00154 iter/s, 14.2826s/100 iters), loss = 0.000673117
I1001 21:37:14.055339  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000673054 (* 1 = 0.000673054 loss)
I1001 21:37:14.055346  5547 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I1001 21:37:28.324721  5547 solver.cpp:218] Iteration 59300 (7.00803 iter/s, 14.2693s/100 iters), loss = 0.00274327
I1001 21:37:28.324755  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00274321 (* 1 = 0.00274321 loss)
I1001 21:37:28.324762  5547 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I1001 21:37:42.597620  5547 solver.cpp:218] Iteration 59400 (7.00632 iter/s, 14.2728s/100 iters), loss = 0.000794098
I1001 21:37:42.597649  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000794031 (* 1 = 0.000794031 loss)
I1001 21:37:42.597656  5547 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I1001 21:37:56.172304  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:37:56.742048  5547 solver.cpp:330] Iteration 59500, Testing net (#0)
I1001 21:38:00.110800  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:38:00.251566  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9277
I1001 21:38:00.251592  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305117 (* 1 = 0.305117 loss)
I1001 21:38:00.392895  5547 solver.cpp:218] Iteration 59500 (5.61949 iter/s, 17.7952s/100 iters), loss = 0.0249182
I1001 21:38:00.392928  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0249181 (* 1 = 0.0249181 loss)
I1001 21:38:00.392935  5547 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I1001 21:38:14.682564  5547 solver.cpp:218] Iteration 59600 (6.9981 iter/s, 14.2896s/100 iters), loss = 0.0027352
I1001 21:38:14.682602  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00273514 (* 1 = 0.00273514 loss)
I1001 21:38:14.682610  5547 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I1001 21:38:28.971747  5547 solver.cpp:218] Iteration 59700 (6.99834 iter/s, 14.2891s/100 iters), loss = 0.00331962
I1001 21:38:28.971863  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00331955 (* 1 = 0.00331955 loss)
I1001 21:38:28.971870  5547 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I1001 21:38:43.264797  5547 solver.cpp:218] Iteration 59800 (6.99648 iter/s, 14.2929s/100 iters), loss = 0.00497393
I1001 21:38:43.264844  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00497387 (* 1 = 0.00497387 loss)
I1001 21:38:43.264852  5547 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I1001 21:38:57.545022  5547 solver.cpp:218] Iteration 59900 (7.00275 iter/s, 14.2801s/100 iters), loss = 0.0153403
I1001 21:38:57.545053  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0153402 (* 1 = 0.0153402 loss)
I1001 21:38:57.545060  5547 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I1001 21:39:11.118507  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:39:11.689054  5547 solver.cpp:330] Iteration 60000, Testing net (#0)
I1001 21:39:15.056351  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:39:15.196545  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.928
I1001 21:39:15.196570  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303 (* 1 = 0.303 loss)
I1001 21:39:15.338686  5547 solver.cpp:218] Iteration 60000 (5.62001 iter/s, 17.7936s/100 iters), loss = 0.00272677
I1001 21:39:15.338716  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00272671 (* 1 = 0.00272671 loss)
I1001 21:39:15.338723  5547 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I1001 21:39:29.632709  5547 solver.cpp:218] Iteration 60100 (6.99597 iter/s, 14.2939s/100 iters), loss = 0.0171928
I1001 21:39:29.632741  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0171927 (* 1 = 0.0171927 loss)
I1001 21:39:29.632748  5547 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I1001 21:39:43.927549  5547 solver.cpp:218] Iteration 60200 (6.99557 iter/s, 14.2948s/100 iters), loss = 0.025692
I1001 21:39:43.927666  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.025692 (* 1 = 0.025692 loss)
I1001 21:39:43.927673  5547 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I1001 21:39:58.220005  5547 solver.cpp:218] Iteration 60300 (6.99678 iter/s, 14.2923s/100 iters), loss = 0.00658638
I1001 21:39:58.220041  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00658632 (* 1 = 0.00658632 loss)
I1001 21:39:58.220047  5547 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I1001 21:40:12.505949  5547 solver.cpp:218] Iteration 60400 (6.99993 iter/s, 14.2859s/100 iters), loss = 0.00181888
I1001 21:40:12.505985  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00181882 (* 1 = 0.00181882 loss)
I1001 21:40:12.505990  5547 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I1001 21:40:26.097095  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:40:26.667294  5547 solver.cpp:330] Iteration 60500, Testing net (#0)
I1001 21:40:30.037170  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:40:30.177134  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I1001 21:40:30.177160  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.315828 (* 1 = 0.315828 loss)
I1001 21:40:30.317950  5547 solver.cpp:218] Iteration 60500 (5.61422 iter/s, 17.8119s/100 iters), loss = 0.00156139
I1001 21:40:30.317986  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00156134 (* 1 = 0.00156134 loss)
I1001 21:40:30.317993  5547 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I1001 21:40:44.593847  5547 solver.cpp:218] Iteration 60600 (7.00485 iter/s, 14.2758s/100 iters), loss = 0.0130493
I1001 21:40:44.593879  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130493 (* 1 = 0.0130493 loss)
I1001 21:40:44.593886  5547 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I1001 21:40:58.883850  5547 solver.cpp:218] Iteration 60700 (6.99794 iter/s, 14.2899s/100 iters), loss = 0.00365429
I1001 21:40:58.883993  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00365424 (* 1 = 0.00365424 loss)
I1001 21:40:58.884003  5547 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I1001 21:41:13.168911  5547 solver.cpp:218] Iteration 60800 (7.00041 iter/s, 14.2849s/100 iters), loss = 0.0247665
I1001 21:41:13.168958  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0247665 (* 1 = 0.0247665 loss)
I1001 21:41:13.168967  5547 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I1001 21:41:27.450088  5547 solver.cpp:218] Iteration 60900 (7.00228 iter/s, 14.2811s/100 iters), loss = 0.00154823
I1001 21:41:27.450120  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154818 (* 1 = 0.00154818 loss)
I1001 21:41:27.450126  5547 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I1001 21:41:41.028151  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:41:41.599944  5547 solver.cpp:330] Iteration 61000, Testing net (#0)
I1001 21:41:44.970937  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:41:45.110987  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9243
I1001 21:41:45.111022  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31136 (* 1 = 0.31136 loss)
I1001 21:41:45.252562  5547 solver.cpp:218] Iteration 61000 (5.61722 iter/s, 17.8024s/100 iters), loss = 0.00101095
I1001 21:41:45.252593  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010109 (* 1 = 0.0010109 loss)
I1001 21:41:45.252600  5547 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I1001 21:41:59.548287  5547 solver.cpp:218] Iteration 61100 (6.99513 iter/s, 14.2957s/100 iters), loss = 0.0100211
I1001 21:41:59.548321  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010021 (* 1 = 0.010021 loss)
I1001 21:41:59.548326  5547 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I1001 21:42:13.830606  5547 solver.cpp:218] Iteration 61200 (7.0017 iter/s, 14.2822s/100 iters), loss = 0.00106505
I1001 21:42:13.830721  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.001065 (* 1 = 0.001065 loss)
I1001 21:42:13.830729  5547 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I1001 21:42:28.107733  5547 solver.cpp:218] Iteration 61300 (7.00429 iter/s, 14.277s/100 iters), loss = 0.0128616
I1001 21:42:28.107769  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128615 (* 1 = 0.0128615 loss)
I1001 21:42:28.107779  5547 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I1001 21:42:42.393609  5547 solver.cpp:218] Iteration 61400 (6.99998 iter/s, 14.2858s/100 iters), loss = 0.00385985
I1001 21:42:42.393649  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00385979 (* 1 = 0.00385979 loss)
I1001 21:42:42.393656  5547 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I1001 21:42:55.971046  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:42:56.541330  5547 solver.cpp:330] Iteration 61500, Testing net (#0)
I1001 21:42:59.910373  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:43:00.050626  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9244
I1001 21:43:00.050660  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314636 (* 1 = 0.314636 loss)
I1001 21:43:00.192389  5547 solver.cpp:218] Iteration 61500 (5.61839 iter/s, 17.7987s/100 iters), loss = 0.0031914
I1001 21:43:00.192422  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00319135 (* 1 = 0.00319135 loss)
I1001 21:43:00.192430  5547 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I1001 21:43:14.471387  5547 solver.cpp:218] Iteration 61600 (7.00333 iter/s, 14.2789s/100 iters), loss = 0.00156727
I1001 21:43:14.471418  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00156721 (* 1 = 0.00156721 loss)
I1001 21:43:14.471434  5547 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I1001 21:43:28.765795  5547 solver.cpp:218] Iteration 61700 (6.99578 iter/s, 14.2943s/100 iters), loss = 0.0062417
I1001 21:43:28.765934  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00624165 (* 1 = 0.00624165 loss)
I1001 21:43:28.765955  5547 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I1001 21:43:43.045497  5547 solver.cpp:218] Iteration 61800 (7.00303 iter/s, 14.2795s/100 iters), loss = 0.00105769
I1001 21:43:43.045532  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00105764 (* 1 = 0.00105764 loss)
I1001 21:43:43.045539  5547 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I1001 21:43:57.330826  5547 solver.cpp:218] Iteration 61900 (7.00023 iter/s, 14.2853s/100 iters), loss = 0.00213755
I1001 21:43:57.330858  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00213751 (* 1 = 0.00213751 loss)
I1001 21:43:57.330864  5547 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I1001 21:44:10.913539  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:44:11.484024  5547 solver.cpp:330] Iteration 62000, Testing net (#0)
I1001 21:44:14.852103  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:44:14.992434  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9248
I1001 21:44:14.992460  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316901 (* 1 = 0.316901 loss)
I1001 21:44:15.134218  5547 solver.cpp:218] Iteration 62000 (5.61693 iter/s, 17.8033s/100 iters), loss = 0.0032549
I1001 21:44:15.134249  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00325485 (* 1 = 0.00325485 loss)
I1001 21:44:15.134255  5547 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I1001 21:44:29.417043  5547 solver.cpp:218] Iteration 62100 (7.00146 iter/s, 14.2827s/100 iters), loss = 0.00635928
I1001 21:44:29.417078  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00635924 (* 1 = 0.00635924 loss)
I1001 21:44:29.417083  5547 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I1001 21:44:43.703227  5547 solver.cpp:218] Iteration 62200 (6.99981 iter/s, 14.2861s/100 iters), loss = 0.00164863
I1001 21:44:43.703343  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00164858 (* 1 = 0.00164858 loss)
I1001 21:44:43.703351  5547 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I1001 21:44:57.988525  5547 solver.cpp:218] Iteration 62300 (7.00027 iter/s, 14.2852s/100 iters), loss = 0.0038355
I1001 21:44:57.988555  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00383545 (* 1 = 0.00383545 loss)
I1001 21:44:57.988561  5547 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I1001 21:45:12.284945  5547 solver.cpp:218] Iteration 62400 (6.99479 iter/s, 14.2963s/100 iters), loss = 0.00115459
I1001 21:45:12.284977  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00115454 (* 1 = 0.00115454 loss)
I1001 21:45:12.284983  5547 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I1001 21:45:25.862449  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:45:26.431807  5547 solver.cpp:330] Iteration 62500, Testing net (#0)
I1001 21:45:29.799015  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:45:29.939296  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9264
I1001 21:45:29.939321  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.306105 (* 1 = 0.306105 loss)
I1001 21:45:30.080696  5547 solver.cpp:218] Iteration 62500 (5.61935 iter/s, 17.7957s/100 iters), loss = 0.0012932
I1001 21:45:30.080727  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00129315 (* 1 = 0.00129315 loss)
I1001 21:45:30.080734  5547 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I1001 21:45:44.360816  5547 solver.cpp:218] Iteration 62600 (7.00278 iter/s, 14.28s/100 iters), loss = 0.00412429
I1001 21:45:44.360860  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00412424 (* 1 = 0.00412424 loss)
I1001 21:45:44.360867  5547 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I1001 21:45:58.654477  5547 solver.cpp:218] Iteration 62700 (6.99615 iter/s, 14.2936s/100 iters), loss = 0.00838404
I1001 21:45:58.654639  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00838399 (* 1 = 0.00838399 loss)
I1001 21:45:58.654657  5547 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I1001 21:46:12.935102  5547 solver.cpp:218] Iteration 62800 (7.00259 iter/s, 14.2804s/100 iters), loss = 0.00661346
I1001 21:46:12.935132  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0066134 (* 1 = 0.0066134 loss)
I1001 21:46:12.935138  5547 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I1001 21:46:27.215116  5547 solver.cpp:218] Iteration 62900 (7.00283 iter/s, 14.2799s/100 iters), loss = 0.00189176
I1001 21:46:27.215157  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0018917 (* 1 = 0.0018917 loss)
I1001 21:46:27.215162  5547 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I1001 21:46:40.800426  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:46:41.370282  5547 solver.cpp:330] Iteration 63000, Testing net (#0)
I1001 21:46:44.737699  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:46:44.878053  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9253
I1001 21:46:44.878087  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312136 (* 1 = 0.312136 loss)
I1001 21:46:45.019065  5547 solver.cpp:218] Iteration 63000 (5.61676 iter/s, 17.8039s/100 iters), loss = 0.00403598
I1001 21:46:45.019096  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00403593 (* 1 = 0.00403593 loss)
I1001 21:46:45.019104  5547 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I1001 21:46:59.298465  5547 solver.cpp:218] Iteration 63100 (7.00313 iter/s, 14.2793s/100 iters), loss = 0.0280508
I1001 21:46:59.298498  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0280507 (* 1 = 0.0280507 loss)
I1001 21:46:59.298506  5547 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I1001 21:47:13.573376  5547 solver.cpp:218] Iteration 63200 (7.00534 iter/s, 14.2748s/100 iters), loss = 0.00459988
I1001 21:47:13.573467  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00459983 (* 1 = 0.00459983 loss)
I1001 21:47:13.573485  5547 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I1001 21:47:27.844328  5547 solver.cpp:218] Iteration 63300 (7.00731 iter/s, 14.2708s/100 iters), loss = 0.0018028
I1001 21:47:27.844359  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00180275 (* 1 = 0.00180275 loss)
I1001 21:47:27.844365  5547 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I1001 21:47:42.128425  5547 solver.cpp:218] Iteration 63400 (7.00083 iter/s, 14.284s/100 iters), loss = 0.0011296
I1001 21:47:42.128465  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00112955 (* 1 = 0.00112955 loss)
I1001 21:47:42.128473  5547 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I1001 21:47:55.705858  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:47:56.275930  5547 solver.cpp:330] Iteration 63500, Testing net (#0)
I1001 21:47:59.642295  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:47:59.782294  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9232
I1001 21:47:59.782320  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322452 (* 1 = 0.322452 loss)
I1001 21:47:59.923275  5547 solver.cpp:218] Iteration 63500 (5.61963 iter/s, 17.7948s/100 iters), loss = 0.00577562
I1001 21:47:59.923319  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00577557 (* 1 = 0.00577557 loss)
I1001 21:47:59.923326  5547 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I1001 21:48:14.214337  5547 solver.cpp:218] Iteration 63600 (6.99749 iter/s, 14.2908s/100 iters), loss = 0.00224251
I1001 21:48:14.214370  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00224247 (* 1 = 0.00224247 loss)
I1001 21:48:14.214377  5547 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I1001 21:48:28.500361  5547 solver.cpp:218] Iteration 63700 (6.99989 iter/s, 14.2859s/100 iters), loss = 0.00926811
I1001 21:48:28.500537  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00926807 (* 1 = 0.00926807 loss)
I1001 21:48:28.500547  5547 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I1001 21:48:42.776283  5547 solver.cpp:218] Iteration 63800 (7.0049 iter/s, 14.2757s/100 iters), loss = 0.00311792
I1001 21:48:42.776321  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00311788 (* 1 = 0.00311788 loss)
I1001 21:48:42.776327  5547 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I1001 21:48:57.066771  5547 solver.cpp:218] Iteration 63900 (6.9977 iter/s, 14.2904s/100 iters), loss = 0.00255898
I1001 21:48:57.066804  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00255893 (* 1 = 0.00255893 loss)
I1001 21:48:57.066810  5547 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I1001 21:49:10.656422  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:49:11.225666  5547 solver.cpp:330] Iteration 64000, Testing net (#0)
I1001 21:49:14.593819  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:49:14.734195  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9214
I1001 21:49:14.734220  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.323069 (* 1 = 0.323069 loss)
I1001 21:49:14.875599  5547 solver.cpp:218] Iteration 64000 (5.61522 iter/s, 17.8087s/100 iters), loss = 0.00344912
I1001 21:49:14.875633  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00344906 (* 1 = 0.00344906 loss)
I1001 21:49:14.875639  5547 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I1001 21:49:29.155686  5547 solver.cpp:218] Iteration 64100 (7.0028 iter/s, 14.28s/100 iters), loss = 0.00443249
I1001 21:49:29.155719  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00443243 (* 1 = 0.00443243 loss)
I1001 21:49:29.155725  5547 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I1001 21:49:43.434417  5547 solver.cpp:218] Iteration 64200 (7.00346 iter/s, 14.2787s/100 iters), loss = 0.00409444
I1001 21:49:43.434540  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00409438 (* 1 = 0.00409438 loss)
I1001 21:49:43.434547  5547 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I1001 21:49:57.711254  5547 solver.cpp:218] Iteration 64300 (7.00443 iter/s, 14.2767s/100 iters), loss = 0.00203187
I1001 21:49:57.711287  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00203181 (* 1 = 0.00203181 loss)
I1001 21:49:57.711294  5547 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I1001 21:50:11.993896  5547 solver.cpp:218] Iteration 64400 (7.00154 iter/s, 14.2826s/100 iters), loss = 0.00287322
I1001 21:50:11.993938  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00287316 (* 1 = 0.00287316 loss)
I1001 21:50:11.993944  5547 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I1001 21:50:25.559937  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:50:26.128866  5547 solver.cpp:330] Iteration 64500, Testing net (#0)
I1001 21:50:29.497140  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:50:29.637152  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9243
I1001 21:50:29.637177  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320709 (* 1 = 0.320709 loss)
I1001 21:50:29.778693  5547 solver.cpp:218] Iteration 64500 (5.62281 iter/s, 17.7847s/100 iters), loss = 0.00385002
I1001 21:50:29.778728  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00384995 (* 1 = 0.00384995 loss)
I1001 21:50:29.778734  5547 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I1001 21:50:44.060258  5547 solver.cpp:218] Iteration 64600 (7.00217 iter/s, 14.2813s/100 iters), loss = 0.00178366
I1001 21:50:44.060299  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0017836 (* 1 = 0.0017836 loss)
I1001 21:50:44.060307  5547 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I1001 21:50:58.342916  5547 solver.cpp:218] Iteration 64700 (7.00154 iter/s, 14.2826s/100 iters), loss = 0.0030306
I1001 21:50:58.343053  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00303054 (* 1 = 0.00303054 loss)
I1001 21:50:58.343072  5547 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I1001 21:51:12.614913  5547 solver.cpp:218] Iteration 64800 (7.00682 iter/s, 14.2718s/100 iters), loss = 0.00302637
I1001 21:51:12.614945  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00302631 (* 1 = 0.00302631 loss)
I1001 21:51:12.614953  5547 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I1001 21:51:26.895428  5547 solver.cpp:218] Iteration 64900 (7.00259 iter/s, 14.2804s/100 iters), loss = 0.00156416
I1001 21:51:26.895459  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0015641 (* 1 = 0.0015641 loss)
I1001 21:51:26.895465  5547 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I1001 21:51:40.476799  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:51:41.046764  5547 solver.cpp:330] Iteration 65000, Testing net (#0)
I1001 21:51:44.413574  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:51:44.553619  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9246
I1001 21:51:44.553654  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313149 (* 1 = 0.313149 loss)
I1001 21:51:44.695377  5547 solver.cpp:218] Iteration 65000 (5.61802 iter/s, 17.7999s/100 iters), loss = 0.00044941
I1001 21:51:44.695411  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000449356 (* 1 = 0.000449356 loss)
I1001 21:51:44.695418  5547 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I1001 21:51:58.976521  5547 solver.cpp:218] Iteration 65100 (7.00228 iter/s, 14.2811s/100 iters), loss = 0.00204291
I1001 21:51:58.976552  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00204286 (* 1 = 0.00204286 loss)
I1001 21:51:58.976558  5547 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I1001 21:52:13.269670  5547 solver.cpp:218] Iteration 65200 (6.9964 iter/s, 14.2931s/100 iters), loss = 0.000399556
I1001 21:52:13.269793  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000399505 (* 1 = 0.000399505 loss)
I1001 21:52:13.269810  5547 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I1001 21:52:27.559064  5547 solver.cpp:218] Iteration 65300 (6.99827 iter/s, 14.2892s/100 iters), loss = 0.00246674
I1001 21:52:27.559095  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00246669 (* 1 = 0.00246669 loss)
I1001 21:52:27.559101  5547 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I1001 21:52:41.842283  5547 solver.cpp:218] Iteration 65400 (7.00126 iter/s, 14.2831s/100 iters), loss = 0.00268253
I1001 21:52:41.842314  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00268248 (* 1 = 0.00268248 loss)
I1001 21:52:41.842320  5547 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I1001 21:52:55.424379  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:52:55.995229  5547 solver.cpp:330] Iteration 65500, Testing net (#0)
I1001 21:52:59.363996  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:52:59.504243  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9262
I1001 21:52:59.504268  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32512 (* 1 = 0.32512 loss)
I1001 21:52:59.645469  5547 solver.cpp:218] Iteration 65500 (5.617 iter/s, 17.8031s/100 iters), loss = 0.00800451
I1001 21:52:59.645504  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00800446 (* 1 = 0.00800446 loss)
I1001 21:52:59.645511  5547 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I1001 21:53:13.929507  5547 solver.cpp:218] Iteration 65600 (7.00086 iter/s, 14.284s/100 iters), loss = 0.00161894
I1001 21:53:13.929538  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00161888 (* 1 = 0.00161888 loss)
I1001 21:53:13.929545  5547 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I1001 21:53:28.198786  5547 solver.cpp:218] Iteration 65700 (7.0081 iter/s, 14.2692s/100 iters), loss = 0.000783683
I1001 21:53:28.198925  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000783631 (* 1 = 0.000783631 loss)
I1001 21:53:28.198933  5547 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I1001 21:53:42.486110  5547 solver.cpp:218] Iteration 65800 (6.99929 iter/s, 14.2872s/100 iters), loss = 0.00358147
I1001 21:53:42.486143  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00358141 (* 1 = 0.00358141 loss)
I1001 21:53:42.486150  5547 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I1001 21:53:56.775915  5547 solver.cpp:218] Iteration 65900 (6.99804 iter/s, 14.2897s/100 iters), loss = 0.00121882
I1001 21:53:56.775957  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00121877 (* 1 = 0.00121877 loss)
I1001 21:53:56.775964  5547 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I1001 21:54:10.353423  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:54:10.923593  5547 solver.cpp:330] Iteration 66000, Testing net (#0)
I1001 21:54:14.290254  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:54:14.430671  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9207
I1001 21:54:14.430707  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338164 (* 1 = 0.338164 loss)
I1001 21:54:14.572263  5547 solver.cpp:218] Iteration 66000 (5.61916 iter/s, 17.7962s/100 iters), loss = 0.000682908
I1001 21:54:14.572296  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000682858 (* 1 = 0.000682858 loss)
I1001 21:54:14.572304  5547 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I1001 21:54:28.850500  5547 solver.cpp:218] Iteration 66100 (7.0037 iter/s, 14.2782s/100 iters), loss = 0.00488613
I1001 21:54:28.850548  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00488609 (* 1 = 0.00488609 loss)
I1001 21:54:28.850556  5547 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I1001 21:54:43.129246  5547 solver.cpp:218] Iteration 66200 (7.00346 iter/s, 14.2787s/100 iters), loss = 0.0041056
I1001 21:54:43.129354  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00410556 (* 1 = 0.00410556 loss)
I1001 21:54:43.129362  5547 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I1001 21:54:57.414031  5547 solver.cpp:218] Iteration 66300 (7.00054 iter/s, 14.2846s/100 iters), loss = 0.00211879
I1001 21:54:57.414072  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00211876 (* 1 = 0.00211876 loss)
I1001 21:54:57.414078  5547 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I1001 21:55:11.688055  5547 solver.cpp:218] Iteration 66400 (7.00577 iter/s, 14.2739s/100 iters), loss = 0.00231635
I1001 21:55:11.688097  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00231633 (* 1 = 0.00231633 loss)
I1001 21:55:11.688102  5547 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I1001 21:55:25.261734  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:55:25.834197  5547 solver.cpp:330] Iteration 66500, Testing net (#0)
I1001 21:55:29.204596  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:55:29.344876  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9188
I1001 21:55:29.344911  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.340233 (* 1 = 0.340233 loss)
I1001 21:55:29.486563  5547 solver.cpp:218] Iteration 66500 (5.61848 iter/s, 17.7984s/100 iters), loss = 0.00135206
I1001 21:55:29.486599  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00135204 (* 1 = 0.00135204 loss)
I1001 21:55:29.486606  5547 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I1001 21:55:43.770161  5547 solver.cpp:218] Iteration 66600 (7.00108 iter/s, 14.2835s/100 iters), loss = 0.00303593
I1001 21:55:43.770193  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0030359 (* 1 = 0.0030359 loss)
I1001 21:55:43.770200  5547 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I1001 21:55:58.045374  5547 solver.cpp:218] Iteration 66700 (7.00519 iter/s, 14.2751s/100 iters), loss = 0.00271476
I1001 21:55:58.045509  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00271473 (* 1 = 0.00271473 loss)
I1001 21:55:58.045528  5547 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I1001 21:56:12.333835  5547 solver.cpp:218] Iteration 66800 (6.99874 iter/s, 14.2883s/100 iters), loss = 0.00886918
I1001 21:56:12.333864  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00886915 (* 1 = 0.00886915 loss)
I1001 21:56:12.333870  5547 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I1001 21:56:26.622550  5547 solver.cpp:218] Iteration 66900 (6.99857 iter/s, 14.2886s/100 iters), loss = 0.00442019
I1001 21:56:26.622581  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00442015 (* 1 = 0.00442015 loss)
I1001 21:56:26.622587  5547 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I1001 21:56:40.179906  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:56:40.754889  5547 solver.cpp:330] Iteration 67000, Testing net (#0)
I1001 21:56:44.121160  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:56:44.261184  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9202
I1001 21:56:44.261211  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34125 (* 1 = 0.34125 loss)
I1001 21:56:44.403365  5547 solver.cpp:218] Iteration 67000 (5.62407 iter/s, 17.7807s/100 iters), loss = 0.00513991
I1001 21:56:44.403398  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00513988 (* 1 = 0.00513988 loss)
I1001 21:56:44.403405  5547 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I1001 21:56:58.689605  5547 solver.cpp:218] Iteration 67100 (6.99978 iter/s, 14.2862s/100 iters), loss = 0.00566218
I1001 21:56:58.689637  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00566214 (* 1 = 0.00566214 loss)
I1001 21:56:58.689644  5547 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I1001 21:57:12.980777  5547 solver.cpp:218] Iteration 67200 (6.99737 iter/s, 14.2911s/100 iters), loss = 0.00553702
I1001 21:57:12.980895  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00553698 (* 1 = 0.00553698 loss)
I1001 21:57:12.980903  5547 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I1001 21:57:27.271826  5547 solver.cpp:218] Iteration 67300 (6.99746 iter/s, 14.2909s/100 iters), loss = 0.0110481
I1001 21:57:27.271854  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110481 (* 1 = 0.0110481 loss)
I1001 21:57:27.271860  5547 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I1001 21:57:41.549147  5547 solver.cpp:218] Iteration 67400 (7.00415 iter/s, 14.2772s/100 iters), loss = 0.0144249
I1001 21:57:41.549181  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0144249 (* 1 = 0.0144249 loss)
I1001 21:57:41.549190  5547 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I1001 21:57:55.129514  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:57:55.707278  5547 solver.cpp:330] Iteration 67500, Testing net (#0)
I1001 21:57:59.076602  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:57:59.216390  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9276
I1001 21:57:59.216426  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.301161 (* 1 = 0.301161 loss)
I1001 21:57:59.357695  5547 solver.cpp:218] Iteration 67500 (5.61531 iter/s, 17.8085s/100 iters), loss = 0.000829032
I1001 21:57:59.357731  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000829005 (* 1 = 0.000829005 loss)
I1001 21:57:59.357738  5547 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I1001 21:58:13.639186  5547 solver.cpp:218] Iteration 67600 (7.00211 iter/s, 14.2814s/100 iters), loss = 0.00679529
I1001 21:58:13.639217  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00679527 (* 1 = 0.00679527 loss)
I1001 21:58:13.639225  5547 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I1001 21:58:27.914463  5547 solver.cpp:218] Iteration 67700 (7.00516 iter/s, 14.2752s/100 iters), loss = 0.00554384
I1001 21:58:27.914588  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00554381 (* 1 = 0.00554381 loss)
I1001 21:58:27.914597  5547 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I1001 21:58:42.208585  5547 solver.cpp:218] Iteration 67800 (6.99596 iter/s, 14.294s/100 iters), loss = 0.00855942
I1001 21:58:42.208617  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00855939 (* 1 = 0.00855939 loss)
I1001 21:58:42.208623  5547 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I1001 21:58:56.498715  5547 solver.cpp:218] Iteration 67900 (6.99788 iter/s, 14.2901s/100 iters), loss = 0.00422281
I1001 21:58:56.498757  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00422278 (* 1 = 0.00422278 loss)
I1001 21:58:56.498764  5547 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I1001 21:59:10.062503  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:59:10.640405  5547 solver.cpp:330] Iteration 68000, Testing net (#0)
I1001 21:59:14.008134  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 21:59:14.148073  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9252
I1001 21:59:14.148108  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324961 (* 1 = 0.324961 loss)
I1001 21:59:14.289305  5547 solver.cpp:218] Iteration 68000 (5.62098 iter/s, 17.7905s/100 iters), loss = 0.00195522
I1001 21:59:14.289340  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0019552 (* 1 = 0.0019552 loss)
I1001 21:59:14.289348  5547 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I1001 21:59:28.574971  5547 solver.cpp:218] Iteration 68100 (7.00007 iter/s, 14.2856s/100 iters), loss = 0.0136425
I1001 21:59:28.575014  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136425 (* 1 = 0.0136425 loss)
I1001 21:59:28.575021  5547 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I1001 21:59:42.859256  5547 solver.cpp:218] Iteration 68200 (7.00074 iter/s, 14.2842s/100 iters), loss = 0.0122768
I1001 21:59:42.859356  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122768 (* 1 = 0.0122768 loss)
I1001 21:59:42.859364  5547 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I1001 21:59:57.136754  5547 solver.cpp:218] Iteration 68300 (7.0041 iter/s, 14.2774s/100 iters), loss = 0.00189491
I1001 21:59:57.136786  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00189488 (* 1 = 0.00189488 loss)
I1001 21:59:57.136802  5547 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I1001 22:00:11.426483  5547 solver.cpp:218] Iteration 68400 (6.99807 iter/s, 14.2897s/100 iters), loss = 0.00263334
I1001 22:00:11.426513  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00263331 (* 1 = 0.00263331 loss)
I1001 22:00:11.426522  5547 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I1001 22:00:24.993834  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:00:25.573738  5547 solver.cpp:330] Iteration 68500, Testing net (#0)
I1001 22:00:28.942986  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:00:29.082583  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9257
I1001 22:00:29.082612  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318781 (* 1 = 0.318781 loss)
I1001 22:00:29.224737  5547 solver.cpp:218] Iteration 68500 (5.61856 iter/s, 17.7982s/100 iters), loss = 0.00860693
I1001 22:00:29.224792  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00860691 (* 1 = 0.00860691 loss)
I1001 22:00:29.224809  5547 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I1001 22:00:43.498941  5547 solver.cpp:218] Iteration 68600 (7.00569 iter/s, 14.2741s/100 iters), loss = 0.00332572
I1001 22:00:43.498975  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0033257 (* 1 = 0.0033257 loss)
I1001 22:00:43.498983  5547 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I1001 22:00:57.773627  5547 solver.cpp:218] Iteration 68700 (7.00545 iter/s, 14.2746s/100 iters), loss = 0.00372495
I1001 22:00:57.773759  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00372493 (* 1 = 0.00372493 loss)
I1001 22:00:57.773766  5547 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I1001 22:01:12.067051  5547 solver.cpp:218] Iteration 68800 (6.99631 iter/s, 14.2933s/100 iters), loss = 0.00276768
I1001 22:01:12.067081  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00276767 (* 1 = 0.00276767 loss)
I1001 22:01:12.067087  5547 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I1001 22:01:26.354281  5547 solver.cpp:218] Iteration 68900 (6.99929 iter/s, 14.2872s/100 iters), loss = 0.0014511
I1001 22:01:26.354323  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00145109 (* 1 = 0.00145109 loss)
I1001 22:01:26.354331  5547 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I1001 22:01:39.918805  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:01:40.498685  5547 solver.cpp:330] Iteration 69000, Testing net (#0)
I1001 22:01:43.867398  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:01:44.007532  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9258
I1001 22:01:44.007568  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312342 (* 1 = 0.312342 loss)
I1001 22:01:44.149238  5547 solver.cpp:218] Iteration 69000 (5.6196 iter/s, 17.7949s/100 iters), loss = 0.00827616
I1001 22:01:44.149271  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00827615 (* 1 = 0.00827615 loss)
I1001 22:01:44.149277  5547 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I1001 22:01:58.429544  5547 solver.cpp:218] Iteration 69100 (7.00269 iter/s, 14.2802s/100 iters), loss = 0.00274293
I1001 22:01:58.429580  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00274292 (* 1 = 0.00274292 loss)
I1001 22:01:58.429587  5547 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I1001 22:02:12.705149  5547 solver.cpp:218] Iteration 69200 (7.005 iter/s, 14.2755s/100 iters), loss = 0.0058396
I1001 22:02:12.705260  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00583959 (* 1 = 0.00583959 loss)
I1001 22:02:12.705267  5547 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I1001 22:02:26.986461  5547 solver.cpp:218] Iteration 69300 (7.00223 iter/s, 14.2812s/100 iters), loss = 0.00175755
I1001 22:02:26.986502  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00175755 (* 1 = 0.00175755 loss)
I1001 22:02:26.986510  5547 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I1001 22:02:41.272188  5547 solver.cpp:218] Iteration 69400 (7.00004 iter/s, 14.2856s/100 iters), loss = 0.00238204
I1001 22:02:41.272222  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00238203 (* 1 = 0.00238203 loss)
I1001 22:02:41.272228  5547 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I1001 22:02:54.840266  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:02:55.415096  5547 solver.cpp:330] Iteration 69500, Testing net (#0)
I1001 22:02:58.783082  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:02:58.922930  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.924
I1001 22:02:58.922966  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.317566 (* 1 = 0.317566 loss)
I1001 22:02:59.064235  5547 solver.cpp:218] Iteration 69500 (5.62052 iter/s, 17.792s/100 iters), loss = 0.00197791
I1001 22:02:59.064271  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00197789 (* 1 = 0.00197789 loss)
I1001 22:02:59.064280  5547 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I1001 22:03:13.338704  5547 solver.cpp:218] Iteration 69600 (7.00556 iter/s, 14.2744s/100 iters), loss = 0.00601114
I1001 22:03:13.338742  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00601114 (* 1 = 0.00601114 loss)
I1001 22:03:13.338749  5547 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I1001 22:03:27.615474  5547 solver.cpp:218] Iteration 69700 (7.00443 iter/s, 14.2767s/100 iters), loss = 0.00179315
I1001 22:03:27.615618  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00179314 (* 1 = 0.00179314 loss)
I1001 22:03:27.615627  5547 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I1001 22:03:41.899560  5547 solver.cpp:218] Iteration 69800 (7.00089 iter/s, 14.2839s/100 iters), loss = 0.00449593
I1001 22:03:41.899591  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00449592 (* 1 = 0.00449592 loss)
I1001 22:03:41.899597  5547 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I1001 22:03:56.169528  5547 solver.cpp:218] Iteration 69900 (7.00776 iter/s, 14.2699s/100 iters), loss = 0.00415002
I1001 22:03:56.169559  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00415001 (* 1 = 0.00415001 loss)
I1001 22:03:56.169565  5547 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I1001 22:04:09.734519  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:04:10.309234  5547 solver.cpp:330] Iteration 70000, Testing net (#0)
I1001 22:04:13.680286  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:04:13.820454  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9227
I1001 22:04:13.820489  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335698 (* 1 = 0.335698 loss)
I1001 22:04:13.961899  5547 solver.cpp:218] Iteration 70000 (5.62041 iter/s, 17.7923s/100 iters), loss = 0.00053914
I1001 22:04:13.961932  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000539131 (* 1 = 0.000539131 loss)
I1001 22:04:13.961940  5547 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I1001 22:04:28.249377  5547 solver.cpp:218] Iteration 70100 (6.99918 iter/s, 14.2874s/100 iters), loss = 0.00329215
I1001 22:04:28.249423  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00329215 (* 1 = 0.00329215 loss)
I1001 22:04:28.249431  5547 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I1001 22:04:42.525279  5547 solver.cpp:218] Iteration 70200 (7.00486 iter/s, 14.2758s/100 iters), loss = 0.00582797
I1001 22:04:42.525388  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00582797 (* 1 = 0.00582797 loss)
I1001 22:04:42.525395  5547 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I1001 22:04:56.812813  5547 solver.cpp:218] Iteration 70300 (6.99918 iter/s, 14.2874s/100 iters), loss = 0.00285806
I1001 22:04:56.812845  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00285805 (* 1 = 0.00285805 loss)
I1001 22:04:56.812851  5547 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I1001 22:05:11.101900  5547 solver.cpp:218] Iteration 70400 (6.99839 iter/s, 14.289s/100 iters), loss = 0.00148267
I1001 22:05:11.101932  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00148267 (* 1 = 0.00148267 loss)
I1001 22:05:11.101938  5547 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I1001 22:05:24.669317  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:05:25.242902  5547 solver.cpp:330] Iteration 70500, Testing net (#0)
I1001 22:05:28.618026  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:05:28.758306  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9249
I1001 22:05:28.758330  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327718 (* 1 = 0.327718 loss)
I1001 22:05:28.899577  5547 solver.cpp:218] Iteration 70500 (5.61874 iter/s, 17.7976s/100 iters), loss = 0.00153011
I1001 22:05:28.899612  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0015301 (* 1 = 0.0015301 loss)
I1001 22:05:28.899619  5547 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I1001 22:05:43.168171  5547 solver.cpp:218] Iteration 70600 (7.00844 iter/s, 14.2685s/100 iters), loss = 0.00239568
I1001 22:05:43.168215  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00239568 (* 1 = 0.00239568 loss)
I1001 22:05:43.168222  5547 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I1001 22:05:57.456929  5547 solver.cpp:218] Iteration 70700 (6.99857 iter/s, 14.2886s/100 iters), loss = 0.00650541
I1001 22:05:57.457034  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00650541 (* 1 = 0.00650541 loss)
I1001 22:05:57.457042  5547 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I1001 22:06:11.744386  5547 solver.cpp:218] Iteration 70800 (6.99921 iter/s, 14.2873s/100 iters), loss = 0.00396114
I1001 22:06:11.744416  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00396115 (* 1 = 0.00396115 loss)
I1001 22:06:11.744422  5547 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I1001 22:06:26.025137  5547 solver.cpp:218] Iteration 70900 (7.00247 iter/s, 14.2807s/100 iters), loss = 0.00256598
I1001 22:06:26.025171  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00256599 (* 1 = 0.00256599 loss)
I1001 22:06:26.025177  5547 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I1001 22:06:39.600662  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:06:40.171787  5547 solver.cpp:330] Iteration 71000, Testing net (#0)
I1001 22:06:43.551808  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:06:43.692206  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9261
I1001 22:06:43.692242  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.321525 (* 1 = 0.321525 loss)
I1001 22:06:43.833753  5547 solver.cpp:218] Iteration 71000 (5.61529 iter/s, 17.8085s/100 iters), loss = 0.00739122
I1001 22:06:43.833797  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00739122 (* 1 = 0.00739122 loss)
I1001 22:06:43.833804  5547 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I1001 22:06:58.101778  5547 solver.cpp:218] Iteration 71100 (7.00872 iter/s, 14.2679s/100 iters), loss = 0.00137667
I1001 22:06:58.101819  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00137666 (* 1 = 0.00137666 loss)
I1001 22:06:58.101826  5547 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I1001 22:07:12.383236  5547 solver.cpp:218] Iteration 71200 (7.00213 iter/s, 14.2814s/100 iters), loss = 0.0158096
I1001 22:07:12.383327  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0158096 (* 1 = 0.0158096 loss)
I1001 22:07:12.383334  5547 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I1001 22:07:26.667225  5547 solver.cpp:218] Iteration 71300 (7.00091 iter/s, 14.2839s/100 iters), loss = 0.0150258
I1001 22:07:26.667258  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0150258 (* 1 = 0.0150258 loss)
I1001 22:07:26.667263  5547 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I1001 22:07:40.943863  5547 solver.cpp:218] Iteration 71400 (7.00449 iter/s, 14.2766s/100 iters), loss = 0.00986625
I1001 22:07:40.943894  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00986625 (* 1 = 0.00986625 loss)
I1001 22:07:40.943902  5547 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I1001 22:07:54.494199  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:07:55.063632  5547 solver.cpp:330] Iteration 71500, Testing net (#0)
I1001 22:07:58.435864  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:07:58.576815  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I1001 22:07:58.576853  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.343896 (* 1 = 0.343896 loss)
I1001 22:07:58.718089  5547 solver.cpp:218] Iteration 71500 (5.62615 iter/s, 17.7741s/100 iters), loss = 0.000397887
I1001 22:07:58.718124  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000397891 (* 1 = 0.000397891 loss)
I1001 22:07:58.718132  5547 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I1001 22:08:12.992324  5547 solver.cpp:218] Iteration 71600 (7.00567 iter/s, 14.2742s/100 iters), loss = 0.00496028
I1001 22:08:12.992355  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00496028 (* 1 = 0.00496028 loss)
I1001 22:08:12.992362  5547 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I1001 22:08:27.285580  5547 solver.cpp:218] Iteration 71700 (6.99634 iter/s, 14.2932s/100 iters), loss = 0.00184696
I1001 22:08:27.285720  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00184696 (* 1 = 0.00184696 loss)
I1001 22:08:27.285728  5547 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I1001 22:08:41.574928  5547 solver.cpp:218] Iteration 71800 (6.99831 iter/s, 14.2892s/100 iters), loss = 0.000701853
I1001 22:08:41.574959  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000701857 (* 1 = 0.000701857 loss)
I1001 22:08:41.574966  5547 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I1001 22:08:55.862756  5547 solver.cpp:218] Iteration 71900 (6.999 iter/s, 14.2877s/100 iters), loss = 0.00261803
I1001 22:08:55.862788  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00261803 (* 1 = 0.00261803 loss)
I1001 22:08:55.862794  5547 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I1001 22:09:09.445973  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:09:10.016633  5547 solver.cpp:330] Iteration 72000, Testing net (#0)
I1001 22:09:13.396324  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:09:13.537909  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9176
I1001 22:09:13.537945  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.375053 (* 1 = 0.375053 loss)
I1001 22:09:13.679680  5547 solver.cpp:218] Iteration 72000 (5.61267 iter/s, 17.8168s/100 iters), loss = 0.000421614
I1001 22:09:13.679715  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000421617 (* 1 = 0.000421617 loss)
I1001 22:09:13.679723  5547 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I1001 22:09:27.941481  5547 solver.cpp:218] Iteration 72100 (7.01178 iter/s, 14.2617s/100 iters), loss = 0.002654
I1001 22:09:27.941514  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.002654 (* 1 = 0.002654 loss)
I1001 22:09:27.941519  5547 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I1001 22:09:42.221096  5547 solver.cpp:218] Iteration 72200 (7.00303 iter/s, 14.2795s/100 iters), loss = 0.00160951
I1001 22:09:42.221195  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00160951 (* 1 = 0.00160951 loss)
I1001 22:09:42.221211  5547 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I1001 22:09:56.508975  5547 solver.cpp:218] Iteration 72300 (6.99901 iter/s, 14.2877s/100 iters), loss = 0.00118087
I1001 22:09:56.509007  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00118088 (* 1 = 0.00118088 loss)
I1001 22:09:56.509013  5547 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I1001 22:10:10.791359  5547 solver.cpp:218] Iteration 72400 (7.00167 iter/s, 14.2823s/100 iters), loss = 0.000623346
I1001 22:10:10.791389  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000623356 (* 1 = 0.000623356 loss)
I1001 22:10:10.791396  5547 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I1001 22:10:24.355015  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:10:24.924347  5547 solver.cpp:330] Iteration 72500, Testing net (#0)
I1001 22:10:28.299057  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:10:28.443094  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9252
I1001 22:10:28.443120  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318475 (* 1 = 0.318475 loss)
I1001 22:10:28.585595  5547 solver.cpp:218] Iteration 72500 (5.61983 iter/s, 17.7941s/100 iters), loss = 0.00382072
I1001 22:10:28.585630  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00382073 (* 1 = 0.00382073 loss)
I1001 22:10:28.585638  5547 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I1001 22:10:42.866717  5547 solver.cpp:218] Iteration 72600 (7.00229 iter/s, 14.281s/100 iters), loss = 0.00108225
I1001 22:10:42.866750  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108226 (* 1 = 0.00108226 loss)
I1001 22:10:42.866757  5547 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I1001 22:10:57.152387  5547 solver.cpp:218] Iteration 72700 (7.00006 iter/s, 14.2856s/100 iters), loss = 0.00154186
I1001 22:10:57.152562  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154187 (* 1 = 0.00154187 loss)
I1001 22:10:57.152571  5547 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I1001 22:11:11.431442  5547 solver.cpp:218] Iteration 72800 (7.00337 iter/s, 14.2789s/100 iters), loss = 0.00543609
I1001 22:11:11.431473  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0054361 (* 1 = 0.0054361 loss)
I1001 22:11:11.431479  5547 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I1001 22:11:25.721547  5547 solver.cpp:218] Iteration 72900 (6.99789 iter/s, 14.29s/100 iters), loss = 0.000387919
I1001 22:11:25.721580  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000387927 (* 1 = 0.000387927 loss)
I1001 22:11:25.721587  5547 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I1001 22:11:39.304358  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:11:39.873898  5547 solver.cpp:330] Iteration 73000, Testing net (#0)
I1001 22:11:43.244429  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:11:43.388309  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9258
I1001 22:11:43.388337  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320029 (* 1 = 0.320029 loss)
I1001 22:11:43.532604  5547 solver.cpp:218] Iteration 73000 (5.61452 iter/s, 17.811s/100 iters), loss = 0.000716909
I1001 22:11:43.532651  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000716915 (* 1 = 0.000716915 loss)
I1001 22:11:43.532658  5547 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I1001 22:11:57.805351  5547 solver.cpp:218] Iteration 73100 (7.0064 iter/s, 14.2727s/100 iters), loss = 0.00208778
I1001 22:11:57.805383  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00208778 (* 1 = 0.00208778 loss)
I1001 22:11:57.805390  5547 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I1001 22:12:12.097456  5547 solver.cpp:218] Iteration 73200 (6.99691 iter/s, 14.292s/100 iters), loss = 0.00318763
I1001 22:12:12.097566  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00318764 (* 1 = 0.00318764 loss)
I1001 22:12:12.097573  5547 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I1001 22:12:26.391362  5547 solver.cpp:218] Iteration 73300 (6.99606 iter/s, 14.2938s/100 iters), loss = 0.000977036
I1001 22:12:26.391394  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000977041 (* 1 = 0.000977041 loss)
I1001 22:12:26.391412  5547 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I1001 22:12:40.673787  5547 solver.cpp:218] Iteration 73400 (7.00165 iter/s, 14.2823s/100 iters), loss = 0.00181445
I1001 22:12:40.673820  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00181445 (* 1 = 0.00181445 loss)
I1001 22:12:40.673825  5547 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I1001 22:12:54.242236  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:12:54.813005  5547 solver.cpp:330] Iteration 73500, Testing net (#0)
I1001 22:12:58.179780  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:12:58.324065  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9257
I1001 22:12:58.324096  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325402 (* 1 = 0.325402 loss)
I1001 22:12:58.468768  5547 solver.cpp:218] Iteration 73500 (5.61959 iter/s, 17.7949s/100 iters), loss = 0.00386203
I1001 22:12:58.468806  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00386203 (* 1 = 0.00386203 loss)
I1001 22:12:58.468812  5547 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I1001 22:13:12.749013  5547 solver.cpp:218] Iteration 73600 (7.00272 iter/s, 14.2802s/100 iters), loss = 0.00422357
I1001 22:13:12.749055  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00422357 (* 1 = 0.00422357 loss)
I1001 22:13:12.749063  5547 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I1001 22:13:27.030805  5547 solver.cpp:218] Iteration 73700 (7.00197 iter/s, 14.2817s/100 iters), loss = 0.00337029
I1001 22:13:27.030933  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00337029 (* 1 = 0.00337029 loss)
I1001 22:13:27.030941  5547 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I1001 22:13:41.319545  5547 solver.cpp:218] Iteration 73800 (6.9986 iter/s, 14.2886s/100 iters), loss = 0.00073189
I1001 22:13:41.319587  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000731897 (* 1 = 0.000731897 loss)
I1001 22:13:41.319594  5547 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I1001 22:13:55.613590  5547 solver.cpp:218] Iteration 73900 (6.99597 iter/s, 14.294s/100 iters), loss = 0.00784419
I1001 22:13:55.613625  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0078442 (* 1 = 0.0078442 loss)
I1001 22:13:55.613631  5547 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I1001 22:14:09.192258  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:14:09.761981  5547 solver.cpp:330] Iteration 74000, Testing net (#0)
I1001 22:14:13.127018  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:14:13.268574  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I1001 22:14:13.268613  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.342575 (* 1 = 0.342575 loss)
I1001 22:14:13.413532  5547 solver.cpp:218] Iteration 74000 (5.61802 iter/s, 17.7999s/100 iters), loss = 0.00286377
I1001 22:14:13.413569  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00286377 (* 1 = 0.00286377 loss)
I1001 22:14:13.413576  5547 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I1001 22:14:27.688190  5547 solver.cpp:218] Iteration 74100 (7.00546 iter/s, 14.2746s/100 iters), loss = 0.0116908
I1001 22:14:27.688221  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116908 (* 1 = 0.0116908 loss)
I1001 22:14:27.688227  5547 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I1001 22:14:41.986587  5547 solver.cpp:218] Iteration 74200 (6.99383 iter/s, 14.2983s/100 iters), loss = 0.00554857
I1001 22:14:41.986737  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00554856 (* 1 = 0.00554856 loss)
I1001 22:14:41.986743  5547 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I1001 22:14:56.277729  5547 solver.cpp:218] Iteration 74300 (6.99743 iter/s, 14.291s/100 iters), loss = 0.00446614
I1001 22:14:56.277762  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00446613 (* 1 = 0.00446613 loss)
I1001 22:14:56.277768  5547 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I1001 22:15:10.559412  5547 solver.cpp:218] Iteration 74400 (7.00202 iter/s, 14.2816s/100 iters), loss = 0.0143589
I1001 22:15:10.559445  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143589 (* 1 = 0.0143589 loss)
I1001 22:15:10.559453  5547 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I1001 22:15:24.136021  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:15:24.706152  5547 solver.cpp:330] Iteration 74500, Testing net (#0)
I1001 22:15:28.075947  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:15:28.215912  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9256
I1001 22:15:28.215939  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334881 (* 1 = 0.334881 loss)
I1001 22:15:28.361042  5547 solver.cpp:218] Iteration 74500 (5.61749 iter/s, 17.8015s/100 iters), loss = 0.00784775
I1001 22:15:28.361085  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00784775 (* 1 = 0.00784775 loss)
I1001 22:15:28.361094  5547 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I1001 22:15:42.638669  5547 solver.cpp:218] Iteration 74600 (7.00411 iter/s, 14.2773s/100 iters), loss = 0.00253964
I1001 22:15:42.638700  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00253964 (* 1 = 0.00253964 loss)
I1001 22:15:42.638706  5547 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I1001 22:15:56.916501  5547 solver.cpp:218] Iteration 74700 (7.0039 iter/s, 14.2778s/100 iters), loss = 0.00331866
I1001 22:15:56.916635  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00331865 (* 1 = 0.00331865 loss)
I1001 22:15:56.916651  5547 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I1001 22:16:11.202275  5547 solver.cpp:218] Iteration 74800 (7.00006 iter/s, 14.2856s/100 iters), loss = 0.00409441
I1001 22:16:11.202304  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00409441 (* 1 = 0.00409441 loss)
I1001 22:16:11.202311  5547 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I1001 22:16:25.492051  5547 solver.cpp:218] Iteration 74900 (6.99805 iter/s, 14.2897s/100 iters), loss = 0.00286416
I1001 22:16:25.492089  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00286415 (* 1 = 0.00286415 loss)
I1001 22:16:25.492095  5547 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I1001 22:16:39.069528  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:16:39.639318  5547 solver.cpp:330] Iteration 75000, Testing net (#0)
I1001 22:16:43.005367  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:16:43.146020  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9215
I1001 22:16:43.146057  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.343121 (* 1 = 0.343121 loss)
I1001 22:16:43.288882  5547 solver.cpp:218] Iteration 75000 (5.61901 iter/s, 17.7967s/100 iters), loss = 0.000687952
I1001 22:16:43.288920  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000687948 (* 1 = 0.000687948 loss)
I1001 22:16:43.288928  5547 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I1001 22:16:57.570605  5547 solver.cpp:218] Iteration 75100 (7.002 iter/s, 14.2816s/100 iters), loss = 0.00457081
I1001 22:16:57.570637  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00457081 (* 1 = 0.00457081 loss)
I1001 22:16:57.570644  5547 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I1001 22:17:11.863003  5547 solver.cpp:218] Iteration 75200 (6.99676 iter/s, 14.2923s/100 iters), loss = 0.00757847
I1001 22:17:11.863129  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00757848 (* 1 = 0.00757848 loss)
I1001 22:17:11.863137  5547 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I1001 22:17:26.143461  5547 solver.cpp:218] Iteration 75300 (7.00266 iter/s, 14.2803s/100 iters), loss = 0.00518413
I1001 22:17:26.143492  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00518413 (* 1 = 0.00518413 loss)
I1001 22:17:26.143498  5547 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I1001 22:17:40.426259  5547 solver.cpp:218] Iteration 75400 (7.00147 iter/s, 14.2827s/100 iters), loss = 0.00226003
I1001 22:17:40.426295  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00226002 (* 1 = 0.00226002 loss)
I1001 22:17:40.426302  5547 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I1001 22:17:54.005844  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:17:54.574661  5547 solver.cpp:330] Iteration 75500, Testing net (#0)
I1001 22:17:57.945348  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:17:58.085317  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9228
I1001 22:17:58.085351  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325364 (* 1 = 0.325364 loss)
I1001 22:17:58.225522  5547 solver.cpp:218] Iteration 75500 (5.61824 iter/s, 17.7992s/100 iters), loss = 0.00104966
I1001 22:17:58.225561  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00104965 (* 1 = 0.00104965 loss)
I1001 22:17:58.225569  5547 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I1001 22:18:12.504163  5547 solver.cpp:218] Iteration 75600 (7.0036 iter/s, 14.2784s/100 iters), loss = 0.00141212
I1001 22:18:12.504194  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00141212 (* 1 = 0.00141212 loss)
I1001 22:18:12.504201  5547 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I1001 22:18:26.777838  5547 solver.cpp:218] Iteration 75700 (7.00594 iter/s, 14.2736s/100 iters), loss = 0.00169988
I1001 22:18:26.777977  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00169987 (* 1 = 0.00169987 loss)
I1001 22:18:26.777986  5547 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I1001 22:18:41.060452  5547 solver.cpp:218] Iteration 75800 (7.00161 iter/s, 14.2824s/100 iters), loss = 0.00586379
I1001 22:18:41.060495  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00586378 (* 1 = 0.00586378 loss)
I1001 22:18:41.060501  5547 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I1001 22:18:55.341841  5547 solver.cpp:218] Iteration 75900 (7.00216 iter/s, 14.2813s/100 iters), loss = 0.0131475
I1001 22:18:55.341876  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131475 (* 1 = 0.0131475 loss)
I1001 22:18:55.341882  5547 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I1001 22:19:08.907187  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:19:09.476457  5547 solver.cpp:330] Iteration 76000, Testing net (#0)
I1001 22:19:12.841601  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:19:12.981905  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9243
I1001 22:19:12.981928  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320749 (* 1 = 0.320749 loss)
I1001 22:19:13.123114  5547 solver.cpp:218] Iteration 76000 (5.62392 iter/s, 17.7812s/100 iters), loss = 0.00179968
I1001 22:19:13.123167  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00179967 (* 1 = 0.00179967 loss)
I1001 22:19:13.123183  5547 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I1001 22:19:27.404057  5547 solver.cpp:218] Iteration 76100 (7.00239 iter/s, 14.2808s/100 iters), loss = 0.0107539
I1001 22:19:27.404098  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107539 (* 1 = 0.0107539 loss)
I1001 22:19:27.404103  5547 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I1001 22:19:41.689607  5547 solver.cpp:218] Iteration 76200 (7.00012 iter/s, 14.2855s/100 iters), loss = 0.00151239
I1001 22:19:41.689754  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00151238 (* 1 = 0.00151238 loss)
I1001 22:19:41.689762  5547 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I1001 22:19:55.965458  5547 solver.cpp:218] Iteration 76300 (7.00493 iter/s, 14.2757s/100 iters), loss = 0.00624597
I1001 22:19:55.965499  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00624596 (* 1 = 0.00624596 loss)
I1001 22:19:55.965505  5547 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I1001 22:20:10.243702  5547 solver.cpp:218] Iteration 76400 (7.00371 iter/s, 14.2782s/100 iters), loss = 0.00197879
I1001 22:20:10.243736  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00197878 (* 1 = 0.00197878 loss)
I1001 22:20:10.243743  5547 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I1001 22:20:23.826032  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:20:24.394737  5547 solver.cpp:330] Iteration 76500, Testing net (#0)
I1001 22:20:27.764642  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:20:27.904868  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9244
I1001 22:20:27.904903  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329859 (* 1 = 0.329859 loss)
I1001 22:20:28.046582  5547 solver.cpp:218] Iteration 76500 (5.6171 iter/s, 17.8028s/100 iters), loss = 0.00171457
I1001 22:20:28.046612  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00171457 (* 1 = 0.00171457 loss)
I1001 22:20:28.046619  5547 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I1001 22:20:42.321903  5547 solver.cpp:218] Iteration 76600 (7.00515 iter/s, 14.2752s/100 iters), loss = 0.0293919
I1001 22:20:42.321943  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0293919 (* 1 = 0.0293919 loss)
I1001 22:20:42.321950  5547 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I1001 22:20:56.603554  5547 solver.cpp:218] Iteration 76700 (7.00203 iter/s, 14.2816s/100 iters), loss = 0.00998344
I1001 22:20:56.603689  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00998343 (* 1 = 0.00998343 loss)
I1001 22:20:56.603696  5547 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I1001 22:21:10.891721  5547 solver.cpp:218] Iteration 76800 (6.99888 iter/s, 14.288s/100 iters), loss = 0.0016483
I1001 22:21:10.891754  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0016483 (* 1 = 0.0016483 loss)
I1001 22:21:10.891760  5547 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I1001 22:21:25.165582  5547 solver.cpp:218] Iteration 76900 (7.00585 iter/s, 14.2738s/100 iters), loss = 0.00164476
I1001 22:21:25.165622  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00164475 (* 1 = 0.00164475 loss)
I1001 22:21:25.165629  5547 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I1001 22:21:38.742672  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:21:39.310158  5547 solver.cpp:330] Iteration 77000, Testing net (#0)
I1001 22:21:42.678184  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:21:42.818394  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9234
I1001 22:21:42.818429  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.345175 (* 1 = 0.345175 loss)
I1001 22:21:42.958997  5547 solver.cpp:218] Iteration 77000 (5.62009 iter/s, 17.7933s/100 iters), loss = 0.0022127
I1001 22:21:42.959028  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0022127 (* 1 = 0.0022127 loss)
I1001 22:21:42.959035  5547 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I1001 22:21:57.242935  5547 solver.cpp:218] Iteration 77100 (7.00091 iter/s, 14.2839s/100 iters), loss = 0.0120696
I1001 22:21:57.242977  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0120696 (* 1 = 0.0120696 loss)
I1001 22:21:57.242985  5547 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I1001 22:22:11.534616  5547 solver.cpp:218] Iteration 77200 (6.99712 iter/s, 14.2916s/100 iters), loss = 0.0040956
I1001 22:22:11.534740  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00409559 (* 1 = 0.00409559 loss)
I1001 22:22:11.534759  5547 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I1001 22:22:25.815070  5547 solver.cpp:218] Iteration 77300 (7.00266 iter/s, 14.2803s/100 iters), loss = 0.00230893
I1001 22:22:25.815111  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00230893 (* 1 = 0.00230893 loss)
I1001 22:22:25.815119  5547 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I1001 22:22:40.097107  5547 solver.cpp:218] Iteration 77400 (7.00184 iter/s, 14.282s/100 iters), loss = 0.00361206
I1001 22:22:40.097146  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00361205 (* 1 = 0.00361205 loss)
I1001 22:22:40.097152  5547 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I1001 22:22:53.677753  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:22:54.247994  5547 solver.cpp:330] Iteration 77500, Testing net (#0)
I1001 22:22:57.615669  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:22:57.755540  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9227
I1001 22:22:57.755575  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.336631 (* 1 = 0.336631 loss)
I1001 22:22:57.896906  5547 solver.cpp:218] Iteration 77500 (5.61807 iter/s, 17.7997s/100 iters), loss = 0.00204887
I1001 22:22:57.896940  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00204886 (* 1 = 0.00204886 loss)
I1001 22:22:57.896946  5547 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I1001 22:23:12.185359  5547 solver.cpp:218] Iteration 77600 (6.99872 iter/s, 14.2883s/100 iters), loss = 0.0110487
I1001 22:23:12.185391  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110487 (* 1 = 0.0110487 loss)
I1001 22:23:12.185398  5547 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I1001 22:23:26.485000  5547 solver.cpp:218] Iteration 77700 (6.99322 iter/s, 14.2996s/100 iters), loss = 0.00137923
I1001 22:23:26.485126  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00137922 (* 1 = 0.00137922 loss)
I1001 22:23:26.485133  5547 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I1001 22:23:40.781733  5547 solver.cpp:218] Iteration 77800 (6.99469 iter/s, 14.2966s/100 iters), loss = 0.00576574
I1001 22:23:40.781775  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00576573 (* 1 = 0.00576573 loss)
I1001 22:23:40.781782  5547 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I1001 22:23:55.056959  5547 solver.cpp:218] Iteration 77900 (7.00519 iter/s, 14.2751s/100 iters), loss = 0.000880383
I1001 22:23:55.056999  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000880372 (* 1 = 0.000880372 loss)
I1001 22:23:55.057005  5547 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I1001 22:24:08.645117  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:24:09.215975  5547 solver.cpp:330] Iteration 78000, Testing net (#0)
I1001 22:24:12.584789  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:24:12.724534  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9154
I1001 22:24:12.724568  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.357517 (* 1 = 0.357517 loss)
I1001 22:24:12.866080  5547 solver.cpp:218] Iteration 78000 (5.61513 iter/s, 17.809s/100 iters), loss = 0.00298436
I1001 22:24:12.866111  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00298435 (* 1 = 0.00298435 loss)
I1001 22:24:12.866117  5547 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I1001 22:24:27.153460  5547 solver.cpp:218] Iteration 78100 (6.99922 iter/s, 14.2873s/100 iters), loss = 0.000564189
I1001 22:24:27.153491  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000564171 (* 1 = 0.000564171 loss)
I1001 22:24:27.153497  5547 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I1001 22:24:41.441203  5547 solver.cpp:218] Iteration 78200 (6.99904 iter/s, 14.2877s/100 iters), loss = 0.0160631
I1001 22:24:41.441339  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.016063 (* 1 = 0.016063 loss)
I1001 22:24:41.441359  5547 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I1001 22:24:55.725118  5547 solver.cpp:218] Iteration 78300 (7.00097 iter/s, 14.2837s/100 iters), loss = 0.00266505
I1001 22:24:55.725150  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00266503 (* 1 = 0.00266503 loss)
I1001 22:24:55.725157  5547 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I1001 22:25:10.007414  5547 solver.cpp:218] Iteration 78400 (7.00171 iter/s, 14.2822s/100 iters), loss = 0.0084444
I1001 22:25:10.007446  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00844437 (* 1 = 0.00844437 loss)
I1001 22:25:10.007452  5547 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I1001 22:25:23.586499  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:25:24.156507  5547 solver.cpp:330] Iteration 78500, Testing net (#0)
I1001 22:25:27.524670  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:25:27.664917  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9218
I1001 22:25:27.664942  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338441 (* 1 = 0.338441 loss)
I1001 22:25:27.806864  5547 solver.cpp:218] Iteration 78500 (5.61818 iter/s, 17.7994s/100 iters), loss = 0.00171073
I1001 22:25:27.806896  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0017107 (* 1 = 0.0017107 loss)
I1001 22:25:27.806903  5547 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I1001 22:25:42.089570  5547 solver.cpp:218] Iteration 78600 (7.00151 iter/s, 14.2826s/100 iters), loss = 0.0014641
I1001 22:25:42.089604  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00146407 (* 1 = 0.00146407 loss)
I1001 22:25:42.089612  5547 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I1001 22:25:56.379261  5547 solver.cpp:218] Iteration 78700 (6.99809 iter/s, 14.2896s/100 iters), loss = 0.00128912
I1001 22:25:56.379432  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128908 (* 1 = 0.00128908 loss)
I1001 22:25:56.379441  5547 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I1001 22:26:10.669504  5547 solver.cpp:218] Iteration 78800 (6.99789 iter/s, 14.29s/100 iters), loss = 0.00306121
I1001 22:26:10.669538  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00306117 (* 1 = 0.00306117 loss)
I1001 22:26:10.669545  5547 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I1001 22:26:24.937798  5547 solver.cpp:218] Iteration 78900 (7.00858 iter/s, 14.2682s/100 iters), loss = 0.0069184
I1001 22:26:24.937839  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00691836 (* 1 = 0.00691836 loss)
I1001 22:26:24.937844  5547 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I1001 22:26:38.520843  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:26:39.090260  5547 solver.cpp:330] Iteration 79000, Testing net (#0)
I1001 22:26:42.458978  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:26:42.599593  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9167
I1001 22:26:42.599620  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.350929 (* 1 = 0.350929 loss)
I1001 22:26:42.740550  5547 solver.cpp:218] Iteration 79000 (5.61714 iter/s, 17.8027s/100 iters), loss = 0.000866963
I1001 22:26:42.740595  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000866932 (* 1 = 0.000866932 loss)
I1001 22:26:42.740602  5547 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I1001 22:26:57.030795  5547 solver.cpp:218] Iteration 79100 (6.99783 iter/s, 14.2902s/100 iters), loss = 0.0022734
I1001 22:26:57.030828  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00227337 (* 1 = 0.00227337 loss)
I1001 22:26:57.030835  5547 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I1001 22:27:11.307819  5547 solver.cpp:218] Iteration 79200 (7.0043 iter/s, 14.2769s/100 iters), loss = 0.0017835
I1001 22:27:11.307934  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00178348 (* 1 = 0.00178348 loss)
I1001 22:27:11.307940  5547 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I1001 22:27:25.602473  5547 solver.cpp:218] Iteration 79300 (6.9957 iter/s, 14.2945s/100 iters), loss = 0.00126539
I1001 22:27:25.602509  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00126536 (* 1 = 0.00126536 loss)
I1001 22:27:25.602516  5547 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I1001 22:27:39.884721  5547 solver.cpp:218] Iteration 79400 (7.00174 iter/s, 14.2822s/100 iters), loss = 0.000356925
I1001 22:27:39.884752  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000356904 (* 1 = 0.000356904 loss)
I1001 22:27:39.884758  5547 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I1001 22:27:53.463753  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:27:54.033401  5547 solver.cpp:330] Iteration 79500, Testing net (#0)
I1001 22:27:57.398030  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:27:57.537999  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9233
I1001 22:27:57.538034  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.343434 (* 1 = 0.343434 loss)
I1001 22:27:57.678879  5547 solver.cpp:218] Iteration 79500 (5.61985 iter/s, 17.7941s/100 iters), loss = 0.00103533
I1001 22:27:57.678923  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103531 (* 1 = 0.00103531 loss)
I1001 22:27:57.678931  5547 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I1001 22:28:11.963989  5547 solver.cpp:218] Iteration 79600 (7.00034 iter/s, 14.285s/100 iters), loss = 0.00312589
I1001 22:28:11.964021  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00312588 (* 1 = 0.00312588 loss)
I1001 22:28:11.964028  5547 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I1001 22:28:26.256386  5547 solver.cpp:218] Iteration 79700 (6.99677 iter/s, 14.2923s/100 iters), loss = 0.00411081
I1001 22:28:26.256572  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00411079 (* 1 = 0.00411079 loss)
I1001 22:28:26.256580  5547 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I1001 22:28:40.541025  5547 solver.cpp:218] Iteration 79800 (7.00063 iter/s, 14.2844s/100 iters), loss = 0.00169735
I1001 22:28:40.541061  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00169733 (* 1 = 0.00169733 loss)
I1001 22:28:40.541069  5547 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I1001 22:28:54.818135  5547 solver.cpp:218] Iteration 79900 (7.00426 iter/s, 14.277s/100 iters), loss = 0.000965036
I1001 22:28:54.818166  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000965011 (* 1 = 0.000965011 loss)
I1001 22:28:54.818172  5547 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I1001 22:29:08.410442  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:29:08.981616  5547 solver.cpp:330] Iteration 80000, Testing net (#0)
I1001 22:29:12.352670  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:29:12.492615  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9198
I1001 22:29:12.492648  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.351831 (* 1 = 0.351831 loss)
I1001 22:29:12.634037  5547 solver.cpp:218] Iteration 80000 (5.61299 iter/s, 17.8158s/100 iters), loss = 0.0212251
I1001 22:29:12.634071  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0212251 (* 1 = 0.0212251 loss)
I1001 22:29:12.634078  5547 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I1001 22:29:12.634081  5547 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I1001 22:29:26.912619  5547 solver.cpp:218] Iteration 80100 (7.00354 iter/s, 14.2785s/100 iters), loss = 0.00774252
I1001 22:29:26.912650  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00774249 (* 1 = 0.00774249 loss)
I1001 22:29:26.912667  5547 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I1001 22:29:41.198606  5547 solver.cpp:218] Iteration 80200 (6.99991 iter/s, 14.2859s/100 iters), loss = 0.0132971
I1001 22:29:41.198761  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132971 (* 1 = 0.0132971 loss)
I1001 22:29:41.198770  5547 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I1001 22:29:55.493705  5547 solver.cpp:218] Iteration 80300 (6.9955 iter/s, 14.2949s/100 iters), loss = 0.00095082
I1001 22:29:55.493754  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000950792 (* 1 = 0.000950792 loss)
I1001 22:29:55.493762  5547 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I1001 22:30:09.781977  5547 solver.cpp:218] Iteration 80400 (6.99881 iter/s, 14.2881s/100 iters), loss = 0.000497994
I1001 22:30:09.782008  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000497967 (* 1 = 0.000497967 loss)
I1001 22:30:09.782016  5547 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I1001 22:30:23.347574  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:30:23.917176  5547 solver.cpp:330] Iteration 80500, Testing net (#0)
I1001 22:30:27.286974  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:30:27.426944  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9296
I1001 22:30:27.426980  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316263 (* 1 = 0.316263 loss)
I1001 22:30:27.568783  5547 solver.cpp:218] Iteration 80500 (5.62217 iter/s, 17.7867s/100 iters), loss = 0.00318993
I1001 22:30:27.568816  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00318989 (* 1 = 0.00318989 loss)
I1001 22:30:27.568823  5547 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I1001 22:30:41.847381  5547 solver.cpp:218] Iteration 80600 (7.00353 iter/s, 14.2785s/100 iters), loss = 0.00362027
I1001 22:30:41.847414  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00362023 (* 1 = 0.00362023 loss)
I1001 22:30:41.847419  5547 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I1001 22:30:56.126818  5547 solver.cpp:218] Iteration 80700 (7.00312 iter/s, 14.2794s/100 iters), loss = 0.00868709
I1001 22:30:56.126996  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00868705 (* 1 = 0.00868705 loss)
I1001 22:30:56.127005  5547 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I1001 22:31:10.393359  5547 solver.cpp:218] Iteration 80800 (7.00951 iter/s, 14.2663s/100 iters), loss = 0.00196842
I1001 22:31:10.393395  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00196838 (* 1 = 0.00196838 loss)
I1001 22:31:10.393402  5547 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I1001 22:31:24.675017  5547 solver.cpp:218] Iteration 80900 (7.00204 iter/s, 14.2815s/100 iters), loss = 0.000505546
I1001 22:31:24.675048  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000505508 (* 1 = 0.000505508 loss)
I1001 22:31:24.675065  5547 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I1001 22:31:38.260249  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:31:38.831044  5547 solver.cpp:330] Iteration 81000, Testing net (#0)
I1001 22:31:42.197724  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:31:42.338271  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9319
I1001 22:31:42.338307  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305679 (* 1 = 0.305679 loss)
I1001 22:31:42.479763  5547 solver.cpp:218] Iteration 81000 (5.61651 iter/s, 17.8047s/100 iters), loss = 0.0084187
I1001 22:31:42.479794  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00841866 (* 1 = 0.00841866 loss)
I1001 22:31:42.479800  5547 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I1001 22:31:56.754124  5547 solver.cpp:218] Iteration 81100 (7.0056 iter/s, 14.2743s/100 iters), loss = 0.00299999
I1001 22:31:56.754158  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00299995 (* 1 = 0.00299995 loss)
I1001 22:31:56.754174  5547 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I1001 22:32:11.043579  5547 solver.cpp:218] Iteration 81200 (6.99821 iter/s, 14.2894s/100 iters), loss = 0.00463297
I1001 22:32:11.043692  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00463294 (* 1 = 0.00463294 loss)
I1001 22:32:11.043700  5547 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I1001 22:32:25.322916  5547 solver.cpp:218] Iteration 81300 (7.0032 iter/s, 14.2792s/100 iters), loss = 0.00171723
I1001 22:32:25.322949  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0017172 (* 1 = 0.0017172 loss)
I1001 22:32:25.322957  5547 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I1001 22:32:39.606225  5547 solver.cpp:218] Iteration 81400 (7.00122 iter/s, 14.2832s/100 iters), loss = 0.000592598
I1001 22:32:39.606256  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000592562 (* 1 = 0.000592562 loss)
I1001 22:32:39.606261  5547 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I1001 22:32:53.182413  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:32:53.752022  5547 solver.cpp:330] Iteration 81500, Testing net (#0)
I1001 22:32:57.120981  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:32:57.261528  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9312
I1001 22:32:57.261567  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300853 (* 1 = 0.300853 loss)
I1001 22:32:57.403193  5547 solver.cpp:218] Iteration 81500 (5.61896 iter/s, 17.7969s/100 iters), loss = 0.00117337
I1001 22:32:57.403234  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00117333 (* 1 = 0.00117333 loss)
I1001 22:32:57.403241  5547 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I1001 22:33:11.686133  5547 solver.cpp:218] Iteration 81600 (7.0014 iter/s, 14.2829s/100 iters), loss = 0.00101153
I1001 22:33:11.686166  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00101149 (* 1 = 0.00101149 loss)
I1001 22:33:11.686172  5547 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I1001 22:33:25.965106  5547 solver.cpp:218] Iteration 81700 (7.00334 iter/s, 14.2789s/100 iters), loss = 0.0011161
I1001 22:33:25.965227  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00111607 (* 1 = 0.00111607 loss)
I1001 22:33:25.965234  5547 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I1001 22:33:40.243100  5547 solver.cpp:218] Iteration 81800 (7.00387 iter/s, 14.2778s/100 iters), loss = 0.00195269
I1001 22:33:40.243131  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00195266 (* 1 = 0.00195266 loss)
I1001 22:33:40.243136  5547 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I1001 22:33:54.538007  5547 solver.cpp:218] Iteration 81900 (6.99554 iter/s, 14.2948s/100 iters), loss = 0.00208366
I1001 22:33:54.538036  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00208363 (* 1 = 0.00208363 loss)
I1001 22:33:54.538041  5547 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I1001 22:34:08.122144  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:34:08.692443  5547 solver.cpp:330] Iteration 82000, Testing net (#0)
I1001 22:34:12.057581  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:34:12.197914  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9302
I1001 22:34:12.197949  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.299339 (* 1 = 0.299339 loss)
I1001 22:34:12.338577  5547 solver.cpp:218] Iteration 82000 (5.61783 iter/s, 17.8005s/100 iters), loss = 0.00124261
I1001 22:34:12.338610  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00124258 (* 1 = 0.00124258 loss)
I1001 22:34:12.338627  5547 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I1001 22:34:26.619848  5547 solver.cpp:218] Iteration 82100 (7.00222 iter/s, 14.2812s/100 iters), loss = 0.000817205
I1001 22:34:26.619880  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000817174 (* 1 = 0.000817174 loss)
I1001 22:34:26.619886  5547 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I1001 22:34:40.905243  5547 solver.cpp:218] Iteration 82200 (7.0002 iter/s, 14.2853s/100 iters), loss = 0.0106698
I1001 22:34:40.905382  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106698 (* 1 = 0.0106698 loss)
I1001 22:34:40.905390  5547 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I1001 22:34:55.186174  5547 solver.cpp:218] Iteration 82300 (7.00243 iter/s, 14.2808s/100 iters), loss = 0.000901149
I1001 22:34:55.186205  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000901112 (* 1 = 0.000901112 loss)
I1001 22:34:55.186211  5547 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I1001 22:35:09.462003  5547 solver.cpp:218] Iteration 82400 (7.00489 iter/s, 14.2757s/100 iters), loss = 0.00112023
I1001 22:35:09.462031  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00112019 (* 1 = 0.00112019 loss)
I1001 22:35:09.462038  5547 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I1001 22:35:23.039810  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:35:23.609884  5547 solver.cpp:330] Iteration 82500, Testing net (#0)
I1001 22:35:26.977249  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:35:27.117116  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9307
I1001 22:35:27.117142  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.298752 (* 1 = 0.298752 loss)
I1001 22:35:27.257658  5547 solver.cpp:218] Iteration 82500 (5.61938 iter/s, 17.7956s/100 iters), loss = 0.00330492
I1001 22:35:27.257724  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00330488 (* 1 = 0.00330488 loss)
I1001 22:35:27.257731  5547 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I1001 22:35:41.537993  5547 solver.cpp:218] Iteration 82600 (7.00273 iter/s, 14.2802s/100 iters), loss = 0.00317905
I1001 22:35:41.538025  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00317901 (* 1 = 0.00317901 loss)
I1001 22:35:41.538031  5547 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I1001 22:35:55.818722  5547 solver.cpp:218] Iteration 82700 (7.00248 iter/s, 14.2806s/100 iters), loss = 0.000780016
I1001 22:35:55.818882  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00077998 (* 1 = 0.00077998 loss)
I1001 22:35:55.818900  5547 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I1001 22:36:10.104281  5547 solver.cpp:218] Iteration 82800 (7.00017 iter/s, 14.2854s/100 iters), loss = 0.0116386
I1001 22:36:10.104310  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116386 (* 1 = 0.0116386 loss)
I1001 22:36:10.104316  5547 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I1001 22:36:24.390924  5547 solver.cpp:218] Iteration 82900 (6.99958 iter/s, 14.2866s/100 iters), loss = 0.000323441
I1001 22:36:24.390954  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000323406 (* 1 = 0.000323406 loss)
I1001 22:36:24.390959  5547 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I1001 22:36:37.971089  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:36:38.541687  5547 solver.cpp:330] Iteration 83000, Testing net (#0)
I1001 22:36:41.909226  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:36:42.049546  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9312
I1001 22:36:42.049581  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.298372 (* 1 = 0.298372 loss)
I1001 22:36:42.191426  5547 solver.cpp:218] Iteration 83000 (5.61785 iter/s, 17.8004s/100 iters), loss = 0.00159413
I1001 22:36:42.191468  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00159409 (* 1 = 0.00159409 loss)
I1001 22:36:42.191475  5547 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I1001 22:36:56.478909  5547 solver.cpp:218] Iteration 83100 (6.99918 iter/s, 14.2874s/100 iters), loss = 0.00224799
I1001 22:36:56.478941  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00224795 (* 1 = 0.00224795 loss)
I1001 22:36:56.478948  5547 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I1001 22:37:10.771549  5547 solver.cpp:218] Iteration 83200 (6.99665 iter/s, 14.2926s/100 iters), loss = 0.00143083
I1001 22:37:10.771679  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00143079 (* 1 = 0.00143079 loss)
I1001 22:37:10.771687  5547 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I1001 22:37:25.041507  5547 solver.cpp:218] Iteration 83300 (7.00781 iter/s, 14.2698s/100 iters), loss = 0.000799189
I1001 22:37:25.041537  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000799154 (* 1 = 0.000799154 loss)
I1001 22:37:25.041543  5547 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I1001 22:37:39.320323  5547 solver.cpp:218] Iteration 83400 (7.00342 iter/s, 14.2787s/100 iters), loss = 0.000437964
I1001 22:37:39.320354  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000437928 (* 1 = 0.000437928 loss)
I1001 22:37:39.320360  5547 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I1001 22:37:52.907810  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:37:53.477463  5547 solver.cpp:330] Iteration 83500, Testing net (#0)
I1001 22:37:56.847667  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:37:56.987679  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9317
I1001 22:37:56.987704  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.297544 (* 1 = 0.297544 loss)
I1001 22:37:57.128952  5547 solver.cpp:218] Iteration 83500 (5.61529 iter/s, 17.8085s/100 iters), loss = 0.00259302
I1001 22:37:57.128998  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00259299 (* 1 = 0.00259299 loss)
I1001 22:37:57.129005  5547 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I1001 22:38:11.405371  5547 solver.cpp:218] Iteration 83600 (7.0046 iter/s, 14.2763s/100 iters), loss = 0.00901048
I1001 22:38:11.405408  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00901045 (* 1 = 0.00901045 loss)
I1001 22:38:11.405416  5547 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I1001 22:38:25.683640  5547 solver.cpp:218] Iteration 83700 (7.00369 iter/s, 14.2782s/100 iters), loss = 0.000620505
I1001 22:38:25.683789  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000620468 (* 1 = 0.000620468 loss)
I1001 22:38:25.683807  5547 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I1001 22:38:39.961743  5547 solver.cpp:218] Iteration 83800 (7.00383 iter/s, 14.2779s/100 iters), loss = 0.00420361
I1001 22:38:39.961774  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00420357 (* 1 = 0.00420357 loss)
I1001 22:38:39.961781  5547 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I1001 22:38:54.248666  5547 solver.cpp:218] Iteration 83900 (6.99945 iter/s, 14.2868s/100 iters), loss = 0.000506262
I1001 22:38:54.248695  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000506226 (* 1 = 0.000506226 loss)
I1001 22:38:54.248702  5547 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I1001 22:39:07.818248  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:39:08.388491  5547 solver.cpp:330] Iteration 84000, Testing net (#0)
I1001 22:39:11.755079  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:39:11.895300  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9311
I1001 22:39:11.895325  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.297572 (* 1 = 0.297572 loss)
I1001 22:39:12.036911  5547 solver.cpp:218] Iteration 84000 (5.62172 iter/s, 17.7882s/100 iters), loss = 0.000264073
I1001 22:39:12.036942  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000264037 (* 1 = 0.000264037 loss)
I1001 22:39:12.036949  5547 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I1001 22:39:26.324322  5547 solver.cpp:218] Iteration 84100 (6.99928 iter/s, 14.2872s/100 iters), loss = 0.00218477
I1001 22:39:26.324353  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00218474 (* 1 = 0.00218474 loss)
I1001 22:39:26.324359  5547 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I1001 22:39:40.621650  5547 solver.cpp:218] Iteration 84200 (6.99435 iter/s, 14.2972s/100 iters), loss = 0.00146312
I1001 22:39:40.621765  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00146309 (* 1 = 0.00146309 loss)
I1001 22:39:40.621784  5547 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I1001 22:39:54.895704  5547 solver.cpp:218] Iteration 84300 (7.00579 iter/s, 14.2739s/100 iters), loss = 0.00155366
I1001 22:39:54.895742  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00155363 (* 1 = 0.00155363 loss)
I1001 22:39:54.895750  5547 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I1001 22:40:09.199091  5547 solver.cpp:218] Iteration 84400 (6.99139 iter/s, 14.3033s/100 iters), loss = 0.000581566
I1001 22:40:09.199132  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000581532 (* 1 = 0.000581532 loss)
I1001 22:40:09.199138  5547 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I1001 22:40:22.780992  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:40:23.350934  5547 solver.cpp:330] Iteration 84500, Testing net (#0)
I1001 22:40:26.721071  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:40:26.861486  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9314
I1001 22:40:26.861522  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.298463 (* 1 = 0.298463 loss)
I1001 22:40:27.002980  5547 solver.cpp:218] Iteration 84500 (5.61678 iter/s, 17.8038s/100 iters), loss = 0.000397962
I1001 22:40:27.003015  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000397927 (* 1 = 0.000397927 loss)
I1001 22:40:27.003022  5547 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I1001 22:40:41.282753  5547 solver.cpp:218] Iteration 84600 (7.00295 iter/s, 14.2797s/100 iters), loss = 0.0118869
I1001 22:40:41.282784  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118869 (* 1 = 0.0118869 loss)
I1001 22:40:41.282790  5547 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I1001 22:40:55.564249  5547 solver.cpp:218] Iteration 84700 (7.00211 iter/s, 14.2814s/100 iters), loss = 0.00131511
I1001 22:40:55.564389  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00131507 (* 1 = 0.00131507 loss)
I1001 22:40:55.564409  5547 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I1001 22:41:09.856029  5547 solver.cpp:218] Iteration 84800 (6.99712 iter/s, 14.2916s/100 iters), loss = 0.00123521
I1001 22:41:09.856060  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00123517 (* 1 = 0.00123517 loss)
I1001 22:41:09.856065  5547 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I1001 22:41:24.147563  5547 solver.cpp:218] Iteration 84900 (6.99719 iter/s, 14.2915s/100 iters), loss = 0.000291881
I1001 22:41:24.147605  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000291843 (* 1 = 0.000291843 loss)
I1001 22:41:24.147611  5547 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I1001 22:41:37.716354  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:41:38.285764  5547 solver.cpp:330] Iteration 85000, Testing net (#0)
I1001 22:41:41.656385  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:41:41.796347  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9317
I1001 22:41:41.796382  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.298091 (* 1 = 0.298091 loss)
I1001 22:41:41.937773  5547 solver.cpp:218] Iteration 85000 (5.6211 iter/s, 17.7901s/100 iters), loss = 0.000762487
I1001 22:41:41.937808  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00076245 (* 1 = 0.00076245 loss)
I1001 22:41:41.937816  5547 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I1001 22:41:56.231628  5547 solver.cpp:218] Iteration 85100 (6.99605 iter/s, 14.2938s/100 iters), loss = 0.00473046
I1001 22:41:56.231658  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00473042 (* 1 = 0.00473042 loss)
I1001 22:41:56.231665  5547 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I1001 22:42:10.513017  5547 solver.cpp:218] Iteration 85200 (7.00216 iter/s, 14.2813s/100 iters), loss = 0.00109841
I1001 22:42:10.513165  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00109837 (* 1 = 0.00109837 loss)
I1001 22:42:10.513175  5547 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I1001 22:42:24.788612  5547 solver.cpp:218] Iteration 85300 (7.00507 iter/s, 14.2754s/100 iters), loss = 0.00182616
I1001 22:42:24.788645  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00182612 (* 1 = 0.00182612 loss)
I1001 22:42:24.788651  5547 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I1001 22:42:39.075577  5547 solver.cpp:218] Iteration 85400 (6.99943 iter/s, 14.2869s/100 iters), loss = 0.00165113
I1001 22:42:39.075608  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00165109 (* 1 = 0.00165109 loss)
I1001 22:42:39.075614  5547 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I1001 22:42:52.657172  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:42:53.226475  5547 solver.cpp:330] Iteration 85500, Testing net (#0)
I1001 22:42:56.593513  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:42:56.734026  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.932
I1001 22:42:56.734062  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.297515 (* 1 = 0.297515 loss)
I1001 22:42:56.874332  5547 solver.cpp:218] Iteration 85500 (5.6184 iter/s, 17.7987s/100 iters), loss = 0.000694373
I1001 22:42:56.874367  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000694335 (* 1 = 0.000694335 loss)
I1001 22:42:56.874377  5547 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I1001 22:43:11.147364  5547 solver.cpp:218] Iteration 85600 (7.0064 iter/s, 14.2727s/100 iters), loss = 0.0047462
I1001 22:43:11.147397  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00474617 (* 1 = 0.00474617 loss)
I1001 22:43:11.147403  5547 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I1001 22:43:25.426021  5547 solver.cpp:218] Iteration 85700 (7.0035 iter/s, 14.2786s/100 iters), loss = 0.000644259
I1001 22:43:25.426148  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000644221 (* 1 = 0.000644221 loss)
I1001 22:43:25.426157  5547 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I1001 22:43:39.720504  5547 solver.cpp:218] Iteration 85800 (6.99579 iter/s, 14.2943s/100 iters), loss = 0.00142222
I1001 22:43:39.720547  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00142218 (* 1 = 0.00142218 loss)
I1001 22:43:39.720554  5547 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I1001 22:43:54.009882  5547 solver.cpp:218] Iteration 85900 (6.99825 iter/s, 14.2893s/100 iters), loss = 0.0118416
I1001 22:43:54.009922  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118416 (* 1 = 0.0118416 loss)
I1001 22:43:54.009929  5547 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I1001 22:44:07.595437  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:44:08.167033  5547 solver.cpp:330] Iteration 86000, Testing net (#0)
I1001 22:44:11.536161  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:44:11.676136  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9321
I1001 22:44:11.676161  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.298121 (* 1 = 0.298121 loss)
I1001 22:44:11.818284  5547 solver.cpp:218] Iteration 86000 (5.61536 iter/s, 17.8083s/100 iters), loss = 0.000462325
I1001 22:44:11.818317  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000462284 (* 1 = 0.000462284 loss)
I1001 22:44:11.818323  5547 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I1001 22:44:26.101104  5547 solver.cpp:218] Iteration 86100 (7.00146 iter/s, 14.2827s/100 iters), loss = 0.00103887
I1001 22:44:26.101135  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103883 (* 1 = 0.00103883 loss)
I1001 22:44:26.101142  5547 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I1001 22:44:40.375623  5547 solver.cpp:218] Iteration 86200 (7.00553 iter/s, 14.2744s/100 iters), loss = 0.00252385
I1001 22:44:40.375735  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00252381 (* 1 = 0.00252381 loss)
I1001 22:44:40.375742  5547 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I1001 22:44:54.653566  5547 solver.cpp:218] Iteration 86300 (7.00388 iter/s, 14.2778s/100 iters), loss = 0.00796264
I1001 22:44:54.653606  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0079626 (* 1 = 0.0079626 loss)
I1001 22:44:54.653612  5547 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I1001 22:45:08.938773  5547 solver.cpp:218] Iteration 86400 (7.00029 iter/s, 14.2851s/100 iters), loss = 0.000819124
I1001 22:45:08.938814  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000819082 (* 1 = 0.000819082 loss)
I1001 22:45:08.938822  5547 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I1001 22:45:22.509970  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:45:23.084251  5547 solver.cpp:330] Iteration 86500, Testing net (#0)
I1001 22:45:26.451779  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:45:26.592238  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9324
I1001 22:45:26.592273  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.298756 (* 1 = 0.298756 loss)
I1001 22:45:26.733155  5547 solver.cpp:218] Iteration 86500 (5.61978 iter/s, 17.7943s/100 iters), loss = 0.00107186
I1001 22:45:26.733188  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00107181 (* 1 = 0.00107181 loss)
I1001 22:45:26.733196  5547 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I1001 22:45:41.007093  5547 solver.cpp:218] Iteration 86600 (7.00582 iter/s, 14.2739s/100 iters), loss = 0.00118305
I1001 22:45:41.007125  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.001183 (* 1 = 0.001183 loss)
I1001 22:45:41.007143  5547 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I1001 22:45:55.280625  5547 solver.cpp:218] Iteration 86700 (7.00601 iter/s, 14.2735s/100 iters), loss = 0.00055774
I1001 22:45:55.280789  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000557699 (* 1 = 0.000557699 loss)
I1001 22:45:55.280797  5547 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I1001 22:46:09.566154  5547 solver.cpp:218] Iteration 86800 (7.00019 iter/s, 14.2853s/100 iters), loss = 0.000402756
I1001 22:46:09.566184  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000402716 (* 1 = 0.000402716 loss)
I1001 22:46:09.566190  5547 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I1001 22:46:23.836269  5547 solver.cpp:218] Iteration 86900 (7.00769 iter/s, 14.27s/100 iters), loss = 0.00261431
I1001 22:46:23.836302  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00261427 (* 1 = 0.00261427 loss)
I1001 22:46:23.836308  5547 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I1001 22:46:37.405949  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:46:37.984673  5547 solver.cpp:330] Iteration 87000, Testing net (#0)
I1001 22:46:41.351996  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:46:41.491876  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9315
I1001 22:46:41.491901  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300095 (* 1 = 0.300095 loss)
I1001 22:46:41.633620  5547 solver.cpp:218] Iteration 87000 (5.61884 iter/s, 17.7973s/100 iters), loss = 0.00571419
I1001 22:46:41.633653  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00571415 (* 1 = 0.00571415 loss)
I1001 22:46:41.633661  5547 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I1001 22:46:55.920945  5547 solver.cpp:218] Iteration 87100 (6.99927 iter/s, 14.2872s/100 iters), loss = 0.00233049
I1001 22:46:55.920986  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00233045 (* 1 = 0.00233045 loss)
I1001 22:46:55.920994  5547 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I1001 22:47:10.195823  5547 solver.cpp:218] Iteration 87200 (7.00536 iter/s, 14.2748s/100 iters), loss = 0.000510448
I1001 22:47:10.195936  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00051041 (* 1 = 0.00051041 loss)
I1001 22:47:10.195955  5547 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I1001 22:47:24.483448  5547 solver.cpp:218] Iteration 87300 (6.99914 iter/s, 14.2875s/100 iters), loss = 0.00217026
I1001 22:47:24.483479  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00217022 (* 1 = 0.00217022 loss)
I1001 22:47:24.483485  5547 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I1001 22:47:38.771389  5547 solver.cpp:218] Iteration 87400 (6.99895 iter/s, 14.2879s/100 iters), loss = 0.000725142
I1001 22:47:38.771430  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000725103 (* 1 = 0.000725103 loss)
I1001 22:47:38.771436  5547 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I1001 22:47:52.334280  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:47:52.911408  5547 solver.cpp:330] Iteration 87500, Testing net (#0)
I1001 22:47:56.279502  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:47:56.419898  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9321
I1001 22:47:56.419932  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.299668 (* 1 = 0.299668 loss)
I1001 22:47:56.561457  5547 solver.cpp:218] Iteration 87500 (5.62114 iter/s, 17.79s/100 iters), loss = 0.00189933
I1001 22:47:56.561492  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00189929 (* 1 = 0.00189929 loss)
I1001 22:47:56.561501  5547 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I1001 22:48:10.844758  5547 solver.cpp:218] Iteration 87600 (7.00122 iter/s, 14.2832s/100 iters), loss = 0.00167637
I1001 22:48:10.844789  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00167633 (* 1 = 0.00167633 loss)
I1001 22:48:10.844795  5547 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I1001 22:48:25.128743  5547 solver.cpp:218] Iteration 87700 (7.00088 iter/s, 14.2839s/100 iters), loss = 0.00156595
I1001 22:48:25.128876  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00156591 (* 1 = 0.00156591 loss)
I1001 22:48:25.128895  5547 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I1001 22:48:39.406864  5547 solver.cpp:218] Iteration 87800 (7.0038 iter/s, 14.278s/100 iters), loss = 0.00327415
I1001 22:48:39.406905  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00327412 (* 1 = 0.00327412 loss)
I1001 22:48:39.406911  5547 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I1001 22:48:53.686835  5547 solver.cpp:218] Iteration 87900 (7.00286 iter/s, 14.2799s/100 iters), loss = 0.00122381
I1001 22:48:53.686875  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00122378 (* 1 = 0.00122378 loss)
I1001 22:48:53.686882  5547 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I1001 22:49:07.257745  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:49:07.837975  5547 solver.cpp:330] Iteration 88000, Testing net (#0)
I1001 22:49:11.207729  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:49:11.348177  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9314
I1001 22:49:11.348212  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.299897 (* 1 = 0.299897 loss)
I1001 22:49:11.489388  5547 solver.cpp:218] Iteration 88000 (5.6172 iter/s, 17.8025s/100 iters), loss = 0.000359169
I1001 22:49:11.489420  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000359133 (* 1 = 0.000359133 loss)
I1001 22:49:11.489428  5547 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I1001 22:49:25.779152  5547 solver.cpp:218] Iteration 88100 (6.99805 iter/s, 14.2897s/100 iters), loss = 0.00557469
I1001 22:49:25.779186  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00557465 (* 1 = 0.00557465 loss)
I1001 22:49:25.779193  5547 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I1001 22:49:40.058128  5547 solver.cpp:218] Iteration 88200 (7.00334 iter/s, 14.2789s/100 iters), loss = 0.00641135
I1001 22:49:40.058264  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00641131 (* 1 = 0.00641131 loss)
I1001 22:49:40.058271  5547 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I1001 22:49:54.353391  5547 solver.cpp:218] Iteration 88300 (6.99541 iter/s, 14.2951s/100 iters), loss = 0.00459028
I1001 22:49:54.353431  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00459024 (* 1 = 0.00459024 loss)
I1001 22:49:54.353437  5547 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I1001 22:50:08.644668  5547 solver.cpp:218] Iteration 88400 (6.99732 iter/s, 14.2912s/100 iters), loss = 0.00026572
I1001 22:50:08.644709  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000265682 (* 1 = 0.000265682 loss)
I1001 22:50:08.644716  5547 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I1001 22:50:22.209342  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:50:22.785763  5547 solver.cpp:330] Iteration 88500, Testing net (#0)
I1001 22:50:26.154570  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:50:26.295070  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9313
I1001 22:50:26.295105  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.299459 (* 1 = 0.299459 loss)
I1001 22:50:26.435879  5547 solver.cpp:218] Iteration 88500 (5.62078 iter/s, 17.7911s/100 iters), loss = 0.000635932
I1001 22:50:26.435909  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000635895 (* 1 = 0.000635895 loss)
I1001 22:50:26.435915  5547 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I1001 22:50:40.718456  5547 solver.cpp:218] Iteration 88600 (7.00159 iter/s, 14.2825s/100 iters), loss = 0.000747271
I1001 22:50:40.718492  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000747234 (* 1 = 0.000747234 loss)
I1001 22:50:40.718499  5547 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I1001 22:50:54.987248  5547 solver.cpp:218] Iteration 88700 (7.00834 iter/s, 14.2687s/100 iters), loss = 0.000369251
I1001 22:50:54.987382  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000369213 (* 1 = 0.000369213 loss)
I1001 22:50:54.987401  5547 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I1001 22:51:09.261468  5547 solver.cpp:218] Iteration 88800 (7.00572 iter/s, 14.2741s/100 iters), loss = 0.00290291
I1001 22:51:09.261508  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00290287 (* 1 = 0.00290287 loss)
I1001 22:51:09.261514  5547 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I1001 22:51:23.540465  5547 solver.cpp:218] Iteration 88900 (7.00333 iter/s, 14.2789s/100 iters), loss = 0.00108144
I1001 22:51:23.540498  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108141 (* 1 = 0.00108141 loss)
I1001 22:51:23.540505  5547 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I1001 22:51:37.105692  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:51:37.682915  5547 solver.cpp:330] Iteration 89000, Testing net (#0)
I1001 22:51:41.051126  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:51:41.191309  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9316
I1001 22:51:41.191354  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.299488 (* 1 = 0.299488 loss)
I1001 22:51:41.332384  5547 solver.cpp:218] Iteration 89000 (5.62056 iter/s, 17.7918s/100 iters), loss = 0.00264033
I1001 22:51:41.332419  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00264029 (* 1 = 0.00264029 loss)
I1001 22:51:41.332427  5547 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I1001 22:51:55.597842  5547 solver.cpp:218] Iteration 89100 (7.00998 iter/s, 14.2654s/100 iters), loss = 0.00126666
I1001 22:51:55.597877  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00126662 (* 1 = 0.00126662 loss)
I1001 22:51:55.597884  5547 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I1001 22:52:09.875748  5547 solver.cpp:218] Iteration 89200 (7.00387 iter/s, 14.2778s/100 iters), loss = 0.00165954
I1001 22:52:09.875886  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0016595 (* 1 = 0.0016595 loss)
I1001 22:52:09.875893  5547 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I1001 22:52:24.160224  5547 solver.cpp:218] Iteration 89300 (7.00069 iter/s, 14.2843s/100 iters), loss = 0.0213079
I1001 22:52:24.160265  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0213079 (* 1 = 0.0213079 loss)
I1001 22:52:24.160271  5547 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I1001 22:52:38.434844  5547 solver.cpp:218] Iteration 89400 (7.00548 iter/s, 14.2745s/100 iters), loss = 0.00105654
I1001 22:52:38.434873  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010565 (* 1 = 0.0010565 loss)
I1001 22:52:38.434880  5547 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I1001 22:52:51.990720  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:52:52.562347  5547 solver.cpp:330] Iteration 89500, Testing net (#0)
I1001 22:52:55.936308  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:52:56.076927  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9313
I1001 22:52:56.076961  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300057 (* 1 = 0.300057 loss)
I1001 22:52:56.218371  5547 solver.cpp:218] Iteration 89500 (5.62321 iter/s, 17.7834s/100 iters), loss = 0.0032134
I1001 22:52:56.218406  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00321337 (* 1 = 0.00321337 loss)
I1001 22:52:56.218412  5547 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I1001 22:53:10.495626  5547 solver.cpp:218] Iteration 89600 (7.00418 iter/s, 14.2772s/100 iters), loss = 0.00150276
I1001 22:53:10.495663  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00150272 (* 1 = 0.00150272 loss)
I1001 22:53:10.495671  5547 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I1001 22:53:24.776473  5547 solver.cpp:218] Iteration 89700 (7.00243 iter/s, 14.2808s/100 iters), loss = 0.000236326
I1001 22:53:24.776603  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00023629 (* 1 = 0.00023629 loss)
I1001 22:53:24.776621  5547 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I1001 22:53:39.054702  5547 solver.cpp:218] Iteration 89800 (7.00376 iter/s, 14.2781s/100 iters), loss = 0.00557647
I1001 22:53:39.054734  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00557643 (* 1 = 0.00557643 loss)
I1001 22:53:39.054740  5547 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I1001 22:53:53.351084  5547 solver.cpp:218] Iteration 89900 (6.99481 iter/s, 14.2963s/100 iters), loss = 0.000995471
I1001 22:53:53.351114  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000995434 (* 1 = 0.000995434 loss)
I1001 22:53:53.351120  5547 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I1001 22:54:06.936447  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:54:07.507588  5547 solver.cpp:330] Iteration 90000, Testing net (#0)
I1001 22:54:10.878190  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:54:11.018447  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9312
I1001 22:54:11.018473  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300894 (* 1 = 0.300894 loss)
I1001 22:54:11.159965  5547 solver.cpp:218] Iteration 90000 (5.6152 iter/s, 17.8088s/100 iters), loss = 0.000518954
I1001 22:54:11.160003  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000518916 (* 1 = 0.000518916 loss)
I1001 22:54:11.160013  5547 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I1001 22:54:25.429976  5547 solver.cpp:218] Iteration 90100 (7.00774 iter/s, 14.2699s/100 iters), loss = 0.00318541
I1001 22:54:25.430008  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00318537 (* 1 = 0.00318537 loss)
I1001 22:54:25.430017  5547 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I1001 22:54:39.721735  5547 solver.cpp:218] Iteration 90200 (6.99707 iter/s, 14.2917s/100 iters), loss = 0.00270456
I1001 22:54:39.721884  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00270452 (* 1 = 0.00270452 loss)
I1001 22:54:39.721895  5547 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I1001 22:54:54.016207  5547 solver.cpp:218] Iteration 90300 (6.9958 iter/s, 14.2943s/100 iters), loss = 0.000810638
I1001 22:54:54.016240  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000810598 (* 1 = 0.000810598 loss)
I1001 22:54:54.016250  5547 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I1001 22:55:08.297662  5547 solver.cpp:218] Iteration 90400 (7.00212 iter/s, 14.2814s/100 iters), loss = 0.000629846
I1001 22:55:08.297696  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000629806 (* 1 = 0.000629806 loss)
I1001 22:55:08.297715  5547 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I1001 22:55:21.870714  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:55:22.440773  5547 solver.cpp:330] Iteration 90500, Testing net (#0)
I1001 22:55:25.820008  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:55:25.960500  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9314
I1001 22:55:25.960536  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300218 (* 1 = 0.300218 loss)
I1001 22:55:26.102042  5547 solver.cpp:218] Iteration 90500 (5.61662 iter/s, 17.8043s/100 iters), loss = 0.000422849
I1001 22:55:26.102077  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000422808 (* 1 = 0.000422808 loss)
I1001 22:55:26.102085  5547 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I1001 22:55:40.381256  5547 solver.cpp:218] Iteration 90600 (7.00322 iter/s, 14.2791s/100 iters), loss = 0.0002342
I1001 22:55:40.381286  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00023416 (* 1 = 0.00023416 loss)
I1001 22:55:40.381292  5547 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I1001 22:55:54.666410  5547 solver.cpp:218] Iteration 90700 (7.00031 iter/s, 14.2851s/100 iters), loss = 0.00143261
I1001 22:55:54.666546  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00143257 (* 1 = 0.00143257 loss)
I1001 22:55:54.666555  5547 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I1001 22:56:08.950203  5547 solver.cpp:218] Iteration 90800 (7.00103 iter/s, 14.2836s/100 iters), loss = 0.00973261
I1001 22:56:08.950234  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00973257 (* 1 = 0.00973257 loss)
I1001 22:56:08.950240  5547 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I1001 22:56:23.246832  5547 solver.cpp:218] Iteration 90900 (6.99469 iter/s, 14.2966s/100 iters), loss = 0.000662066
I1001 22:56:23.246876  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000662025 (* 1 = 0.000662025 loss)
I1001 22:56:23.246882  5547 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I1001 22:56:36.816939  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:56:37.387539  5547 solver.cpp:330] Iteration 91000, Testing net (#0)
I1001 22:56:40.762300  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:56:40.903268  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9319
I1001 22:56:40.903303  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.29994 (* 1 = 0.29994 loss)
I1001 22:56:41.044682  5547 solver.cpp:218] Iteration 91000 (5.61868 iter/s, 17.7978s/100 iters), loss = 0.00243895
I1001 22:56:41.044715  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00243891 (* 1 = 0.00243891 loss)
I1001 22:56:41.044723  5547 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I1001 22:56:55.310546  5547 solver.cpp:218] Iteration 91100 (7.00978 iter/s, 14.2658s/100 iters), loss = 0.00279517
I1001 22:56:55.310576  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00279513 (* 1 = 0.00279513 loss)
I1001 22:56:55.310582  5547 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I1001 22:57:09.596381  5547 solver.cpp:218] Iteration 91200 (6.99998 iter/s, 14.2858s/100 iters), loss = 0.00102502
I1001 22:57:09.596503  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102498 (* 1 = 0.00102498 loss)
I1001 22:57:09.596511  5547 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I1001 22:57:23.873105  5547 solver.cpp:218] Iteration 91300 (7.00449 iter/s, 14.2766s/100 iters), loss = 0.00742699
I1001 22:57:23.873136  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00742695 (* 1 = 0.00742695 loss)
I1001 22:57:23.873152  5547 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I1001 22:57:38.147264  5547 solver.cpp:218] Iteration 91400 (7.0057 iter/s, 14.2741s/100 iters), loss = 0.00101318
I1001 22:57:38.147297  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00101314 (* 1 = 0.00101314 loss)
I1001 22:57:38.147305  5547 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I1001 22:57:51.709682  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:57:52.279284  5547 solver.cpp:330] Iteration 91500, Testing net (#0)
I1001 22:57:55.655717  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:57:55.798820  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9311
I1001 22:57:55.798847  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.30046 (* 1 = 0.30046 loss)
I1001 22:57:55.940769  5547 solver.cpp:218] Iteration 91500 (5.62005 iter/s, 17.7934s/100 iters), loss = 0.00136246
I1001 22:57:55.940804  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00136242 (* 1 = 0.00136242 loss)
I1001 22:57:55.940810  5547 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I1001 22:58:10.208088  5547 solver.cpp:218] Iteration 91600 (7.00906 iter/s, 14.2672s/100 iters), loss = 0.00284985
I1001 22:58:10.208118  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00284981 (* 1 = 0.00284981 loss)
I1001 22:58:10.208124  5547 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I1001 22:58:24.477495  5547 solver.cpp:218] Iteration 91700 (7.00804 iter/s, 14.2693s/100 iters), loss = 0.00105347
I1001 22:58:24.477600  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00105343 (* 1 = 0.00105343 loss)
I1001 22:58:24.477607  5547 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I1001 22:58:38.756752  5547 solver.cpp:218] Iteration 91800 (7.00323 iter/s, 14.2791s/100 iters), loss = 0.0029926
I1001 22:58:38.756783  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00299256 (* 1 = 0.00299256 loss)
I1001 22:58:38.756789  5547 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I1001 22:58:53.035722  5547 solver.cpp:218] Iteration 91900 (7.00334 iter/s, 14.2789s/100 iters), loss = 0.000585421
I1001 22:58:53.035753  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00058538 (* 1 = 0.00058538 loss)
I1001 22:58:53.035759  5547 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I1001 22:59:06.590839  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:59:07.161166  5547 solver.cpp:330] Iteration 92000, Testing net (#0)
I1001 22:59:10.528992  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 22:59:10.673236  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.932
I1001 22:59:10.673264  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.299332 (* 1 = 0.299332 loss)
I1001 22:59:10.817466  5547 solver.cpp:218] Iteration 92000 (5.62377 iter/s, 17.7817s/100 iters), loss = 0.00120388
I1001 22:59:10.817502  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00120384 (* 1 = 0.00120384 loss)
I1001 22:59:10.817509  5547 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I1001 22:59:25.093771  5547 solver.cpp:218] Iteration 92100 (7.00465 iter/s, 14.2762s/100 iters), loss = 0.00173333
I1001 22:59:25.093801  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00173329 (* 1 = 0.00173329 loss)
I1001 22:59:25.093807  5547 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I1001 22:59:39.387450  5547 solver.cpp:218] Iteration 92200 (6.99614 iter/s, 14.2936s/100 iters), loss = 0.000634956
I1001 22:59:39.387562  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000634915 (* 1 = 0.000634915 loss)
I1001 22:59:39.387580  5547 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I1001 22:59:53.663769  5547 solver.cpp:218] Iteration 92300 (7.00468 iter/s, 14.2762s/100 iters), loss = 0.00227456
I1001 22:59:53.663801  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00227452 (* 1 = 0.00227452 loss)
I1001 22:59:53.663808  5547 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I1001 23:00:07.948637  5547 solver.cpp:218] Iteration 92400 (7.00045 iter/s, 14.2848s/100 iters), loss = 0.000636265
I1001 23:00:07.948678  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000636221 (* 1 = 0.000636221 loss)
I1001 23:00:07.948685  5547 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I1001 23:00:21.520732  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:00:22.090126  5547 solver.cpp:330] Iteration 92500, Testing net (#0)
I1001 23:00:25.456518  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:00:25.600648  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9316
I1001 23:00:25.600688  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.299458 (* 1 = 0.299458 loss)
I1001 23:00:25.745805  5547 solver.cpp:218] Iteration 92500 (5.6189 iter/s, 17.7971s/100 iters), loss = 0.0115022
I1001 23:00:25.745843  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115022 (* 1 = 0.0115022 loss)
I1001 23:00:25.745851  5547 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I1001 23:00:40.016893  5547 solver.cpp:218] Iteration 92600 (7.00721 iter/s, 14.271s/100 iters), loss = 0.000924501
I1001 23:00:40.016937  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000924462 (* 1 = 0.000924462 loss)
I1001 23:00:40.016942  5547 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I1001 23:00:54.296902  5547 solver.cpp:218] Iteration 92700 (7.00284 iter/s, 14.2799s/100 iters), loss = 0.000428858
I1001 23:00:54.297017  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000428817 (* 1 = 0.000428817 loss)
I1001 23:00:54.297024  5547 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I1001 23:01:08.585065  5547 solver.cpp:218] Iteration 92800 (6.99887 iter/s, 14.288s/100 iters), loss = 0.00475834
I1001 23:01:08.585098  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0047583 (* 1 = 0.0047583 loss)
I1001 23:01:08.585104  5547 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I1001 23:01:22.864920  5547 solver.cpp:218] Iteration 92900 (7.00291 iter/s, 14.2798s/100 iters), loss = 0.0015041
I1001 23:01:22.864955  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00150406 (* 1 = 0.00150406 loss)
I1001 23:01:22.864962  5547 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I1001 23:01:36.428778  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:01:36.997712  5547 solver.cpp:330] Iteration 93000, Testing net (#0)
I1001 23:01:40.366071  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:01:40.506359  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9319
I1001 23:01:40.506397  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.3009 (* 1 = 0.3009 loss)
I1001 23:01:40.652608  5547 solver.cpp:218] Iteration 93000 (5.62189 iter/s, 17.7876s/100 iters), loss = 0.000312875
I1001 23:01:40.652647  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000312832 (* 1 = 0.000312832 loss)
I1001 23:01:40.652654  5547 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I1001 23:01:54.937230  5547 solver.cpp:218] Iteration 93100 (7.00059 iter/s, 14.2845s/100 iters), loss = 0.00334361
I1001 23:01:54.937260  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00334357 (* 1 = 0.00334357 loss)
I1001 23:01:54.937266  5547 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I1001 23:02:09.223506  5547 solver.cpp:218] Iteration 93200 (6.99976 iter/s, 14.2862s/100 iters), loss = 0.00115349
I1001 23:02:09.223610  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00115345 (* 1 = 0.00115345 loss)
I1001 23:02:09.223626  5547 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I1001 23:02:23.508141  5547 solver.cpp:218] Iteration 93300 (7.0006 iter/s, 14.2845s/100 iters), loss = 0.00080069
I1001 23:02:23.508172  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00080065 (* 1 = 0.00080065 loss)
I1001 23:02:23.508177  5547 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I1001 23:02:37.803717  5547 solver.cpp:218] Iteration 93400 (6.99521 iter/s, 14.2955s/100 iters), loss = 0.000595876
I1001 23:02:37.803776  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000595835 (* 1 = 0.000595835 loss)
I1001 23:02:37.803782  5547 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I1001 23:02:51.378077  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:02:51.946601  5547 solver.cpp:330] Iteration 93500, Testing net (#0)
I1001 23:02:55.312614  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:02:55.452988  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9315
I1001 23:02:55.453012  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.301616 (* 1 = 0.301616 loss)
I1001 23:02:55.595913  5547 solver.cpp:218] Iteration 93500 (5.62047 iter/s, 17.7921s/100 iters), loss = 0.000671224
I1001 23:02:55.595958  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000671182 (* 1 = 0.000671182 loss)
I1001 23:02:55.595966  5547 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I1001 23:03:09.855070  5547 solver.cpp:218] Iteration 93600 (7.0131 iter/s, 14.259s/100 iters), loss = 0.000853849
I1001 23:03:09.855103  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000853808 (* 1 = 0.000853808 loss)
I1001 23:03:09.855108  5547 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I1001 23:03:24.130401  5547 solver.cpp:218] Iteration 93700 (7.00513 iter/s, 14.2753s/100 iters), loss = 0.000439487
I1001 23:03:24.130511  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000439446 (* 1 = 0.000439446 loss)
I1001 23:03:24.130518  5547 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I1001 23:03:38.409590  5547 solver.cpp:218] Iteration 93800 (7.00327 iter/s, 14.279s/100 iters), loss = 0.000513944
I1001 23:03:38.409621  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000513903 (* 1 = 0.000513903 loss)
I1001 23:03:38.409626  5547 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I1001 23:03:52.679442  5547 solver.cpp:218] Iteration 93900 (7.00782 iter/s, 14.2698s/100 iters), loss = 0.000323997
I1001 23:03:52.679478  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000323955 (* 1 = 0.000323955 loss)
I1001 23:03:52.679486  5547 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I1001 23:04:06.249912  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:04:06.819867  5547 solver.cpp:330] Iteration 94000, Testing net (#0)
I1001 23:04:10.188437  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:04:10.328507  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9318
I1001 23:04:10.328542  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300395 (* 1 = 0.300395 loss)
I1001 23:04:10.470269  5547 solver.cpp:218] Iteration 94000 (5.6209 iter/s, 17.7907s/100 iters), loss = 0.000618916
I1001 23:04:10.470300  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000618874 (* 1 = 0.000618874 loss)
I1001 23:04:10.470306  5547 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I1001 23:04:24.755627  5547 solver.cpp:218] Iteration 94100 (7.00021 iter/s, 14.2853s/100 iters), loss = 0.0013782
I1001 23:04:24.755656  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00137816 (* 1 = 0.00137816 loss)
I1001 23:04:24.755662  5547 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I1001 23:04:39.037081  5547 solver.cpp:218] Iteration 94200 (7.00212 iter/s, 14.2814s/100 iters), loss = 0.0018235
I1001 23:04:39.037225  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00182346 (* 1 = 0.00182346 loss)
I1001 23:04:39.037235  5547 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I1001 23:04:53.315663  5547 solver.cpp:218] Iteration 94300 (7.00358 iter/s, 14.2784s/100 iters), loss = 0.000263647
I1001 23:04:53.315696  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000263604 (* 1 = 0.000263604 loss)
I1001 23:04:53.315703  5547 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I1001 23:05:07.590798  5547 solver.cpp:218] Iteration 94400 (7.00522 iter/s, 14.2751s/100 iters), loss = 0.00151166
I1001 23:05:07.590837  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00151162 (* 1 = 0.00151162 loss)
I1001 23:05:07.590845  5547 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I1001 23:05:21.164222  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:05:21.733865  5547 solver.cpp:330] Iteration 94500, Testing net (#0)
I1001 23:05:25.101716  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:05:25.242007  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.932
I1001 23:05:25.242035  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.301349 (* 1 = 0.301349 loss)
I1001 23:05:25.383265  5547 solver.cpp:218] Iteration 94500 (5.62038 iter/s, 17.7924s/100 iters), loss = 0.000601411
I1001 23:05:25.383299  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000601367 (* 1 = 0.000601367 loss)
I1001 23:05:25.383309  5547 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I1001 23:05:39.664852  5547 solver.cpp:218] Iteration 94600 (7.00206 iter/s, 14.2815s/100 iters), loss = 0.000655973
I1001 23:05:39.664885  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00065593 (* 1 = 0.00065593 loss)
I1001 23:05:39.664892  5547 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I1001 23:05:53.954334  5547 solver.cpp:218] Iteration 94700 (6.99819 iter/s, 14.2894s/100 iters), loss = 0.00132471
I1001 23:05:53.954437  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00132466 (* 1 = 0.00132466 loss)
I1001 23:05:53.954465  5547 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I1001 23:06:08.241143  5547 solver.cpp:218] Iteration 94800 (6.99953 iter/s, 14.2867s/100 iters), loss = 0.000863089
I1001 23:06:08.241178  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000863045 (* 1 = 0.000863045 loss)
I1001 23:06:08.241186  5547 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I1001 23:06:22.508579  5547 solver.cpp:218] Iteration 94900 (7.009 iter/s, 14.2674s/100 iters), loss = 0.00178513
I1001 23:06:22.508611  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00178509 (* 1 = 0.00178509 loss)
I1001 23:06:22.508630  5547 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I1001 23:06:36.091562  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:06:36.661470  5547 solver.cpp:330] Iteration 95000, Testing net (#0)
I1001 23:06:40.030493  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:06:40.171015  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9314
I1001 23:06:40.171049  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.301458 (* 1 = 0.301458 loss)
I1001 23:06:40.312206  5547 solver.cpp:218] Iteration 95000 (5.61686 iter/s, 17.8035s/100 iters), loss = 0.00110119
I1001 23:06:40.312238  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00110115 (* 1 = 0.00110115 loss)
I1001 23:06:40.312244  5547 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1001 23:06:54.600241  5547 solver.cpp:218] Iteration 95100 (6.9989 iter/s, 14.288s/100 iters), loss = 0.000902415
I1001 23:06:54.600272  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000902373 (* 1 = 0.000902373 loss)
I1001 23:06:54.600277  5547 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1001 23:07:08.880254  5547 solver.cpp:218] Iteration 95200 (7.00283 iter/s, 14.2799s/100 iters), loss = 0.000451987
I1001 23:07:08.880347  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000451943 (* 1 = 0.000451943 loss)
I1001 23:07:08.880354  5547 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1001 23:07:23.168880  5547 solver.cpp:218] Iteration 95300 (6.99864 iter/s, 14.2885s/100 iters), loss = 0.00106227
I1001 23:07:23.168911  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00106223 (* 1 = 0.00106223 loss)
I1001 23:07:23.168917  5547 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1001 23:07:37.457432  5547 solver.cpp:218] Iteration 95400 (6.99864 iter/s, 14.2885s/100 iters), loss = 0.0010016
I1001 23:07:37.457473  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100156 (* 1 = 0.00100156 loss)
I1001 23:07:37.457479  5547 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1001 23:07:51.039012  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:07:51.608999  5547 solver.cpp:330] Iteration 95500, Testing net (#0)
I1001 23:07:54.975145  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:07:55.115075  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.932
I1001 23:07:55.115110  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.301478 (* 1 = 0.301478 loss)
I1001 23:07:55.255918  5547 solver.cpp:218] Iteration 95500 (5.61848 iter/s, 17.7984s/100 iters), loss = 0.000546639
I1001 23:07:55.255947  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000546596 (* 1 = 0.000546596 loss)
I1001 23:07:55.255954  5547 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1001 23:08:09.542614  5547 solver.cpp:218] Iteration 95600 (6.99957 iter/s, 14.2866s/100 iters), loss = 0.000827781
I1001 23:08:09.542644  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000827739 (* 1 = 0.000827739 loss)
I1001 23:08:09.542650  5547 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1001 23:08:23.829031  5547 solver.cpp:218] Iteration 95700 (6.99969 iter/s, 14.2863s/100 iters), loss = 0.000557665
I1001 23:08:23.829147  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000557623 (* 1 = 0.000557623 loss)
I1001 23:08:23.829155  5547 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1001 23:08:38.111816  5547 solver.cpp:218] Iteration 95800 (7.00151 iter/s, 14.2826s/100 iters), loss = 0.000813613
I1001 23:08:38.111858  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000813569 (* 1 = 0.000813569 loss)
I1001 23:08:38.111865  5547 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1001 23:08:52.385413  5547 solver.cpp:218] Iteration 95900 (7.00598 iter/s, 14.2735s/100 iters), loss = 0.000395609
I1001 23:08:52.385444  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000395566 (* 1 = 0.000395566 loss)
I1001 23:08:52.385449  5547 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1001 23:09:05.969532  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:09:06.538354  5547 solver.cpp:330] Iteration 96000, Testing net (#0)
I1001 23:09:09.908969  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:09:10.049134  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9319
I1001 23:09:10.049157  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.302275 (* 1 = 0.302275 loss)
I1001 23:09:10.190485  5547 solver.cpp:218] Iteration 96000 (5.6164 iter/s, 17.805s/100 iters), loss = 0.000828987
I1001 23:09:10.190515  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000828945 (* 1 = 0.000828945 loss)
I1001 23:09:10.190523  5547 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1001 23:09:24.463840  5547 solver.cpp:218] Iteration 96100 (7.00609 iter/s, 14.2733s/100 iters), loss = 0.00195266
I1001 23:09:24.463871  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00195261 (* 1 = 0.00195261 loss)
I1001 23:09:24.463876  5547 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1001 23:09:38.742307  5547 solver.cpp:218] Iteration 96200 (7.00358 iter/s, 14.2784s/100 iters), loss = 0.000967017
I1001 23:09:38.742431  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000966975 (* 1 = 0.000966975 loss)
I1001 23:09:38.742449  5547 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1001 23:09:53.017613  5547 solver.cpp:218] Iteration 96300 (7.00518 iter/s, 14.2752s/100 iters), loss = 0.000828029
I1001 23:09:53.017649  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000827988 (* 1 = 0.000827988 loss)
I1001 23:09:53.017657  5547 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1001 23:10:07.294675  5547 solver.cpp:218] Iteration 96400 (7.00428 iter/s, 14.277s/100 iters), loss = 0.000474427
I1001 23:10:07.294716  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000474386 (* 1 = 0.000474386 loss)
I1001 23:10:07.294723  5547 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1001 23:10:20.856992  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:10:21.426379  5547 solver.cpp:330] Iteration 96500, Testing net (#0)
I1001 23:10:24.793495  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:10:24.933903  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9326
I1001 23:10:24.933938  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.301038 (* 1 = 0.301038 loss)
I1001 23:10:25.075090  5547 solver.cpp:218] Iteration 96500 (5.62419 iter/s, 17.7803s/100 iters), loss = 0.000236078
I1001 23:10:25.075143  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000236036 (* 1 = 0.000236036 loss)
I1001 23:10:25.075153  5547 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1001 23:10:39.367214  5547 solver.cpp:218] Iteration 96600 (6.99695 iter/s, 14.2919s/100 iters), loss = 0.00293311
I1001 23:10:39.367244  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00293307 (* 1 = 0.00293307 loss)
I1001 23:10:39.367250  5547 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1001 23:10:53.659090  5547 solver.cpp:218] Iteration 96700 (6.99702 iter/s, 14.2918s/100 iters), loss = 0.00175769
I1001 23:10:53.659206  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00175765 (* 1 = 0.00175765 loss)
I1001 23:10:53.659214  5547 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1001 23:11:07.946596  5547 solver.cpp:218] Iteration 96800 (6.9992 iter/s, 14.2874s/100 iters), loss = 0.000643201
I1001 23:11:07.946630  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000643159 (* 1 = 0.000643159 loss)
I1001 23:11:07.946637  5547 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1001 23:11:22.228086  5547 solver.cpp:218] Iteration 96900 (7.0021 iter/s, 14.2814s/100 iters), loss = 0.00102649
I1001 23:11:22.228116  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102645 (* 1 = 0.00102645 loss)
I1001 23:11:22.228121  5547 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1001 23:11:35.815838  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:11:36.384999  5547 solver.cpp:330] Iteration 97000, Testing net (#0)
I1001 23:11:39.753077  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:11:39.893084  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9318
I1001 23:11:39.893117  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300753 (* 1 = 0.300753 loss)
I1001 23:11:40.033897  5547 solver.cpp:218] Iteration 97000 (5.61617 iter/s, 17.8057s/100 iters), loss = 0.00126354
I1001 23:11:40.033931  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0012635 (* 1 = 0.0012635 loss)
I1001 23:11:40.033939  5547 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1001 23:11:54.317910  5547 solver.cpp:218] Iteration 97100 (7.00087 iter/s, 14.2839s/100 iters), loss = 0.0030982
I1001 23:11:54.317951  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00309816 (* 1 = 0.00309816 loss)
I1001 23:11:54.317957  5547 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1001 23:12:08.616338  5547 solver.cpp:218] Iteration 97200 (6.99381 iter/s, 14.2983s/100 iters), loss = 0.00103922
I1001 23:12:08.616492  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103918 (* 1 = 0.00103918 loss)
I1001 23:12:08.616499  5547 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1001 23:12:22.921602  5547 solver.cpp:218] Iteration 97300 (6.99053 iter/s, 14.3051s/100 iters), loss = 0.0010931
I1001 23:12:22.921636  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00109306 (* 1 = 0.00109306 loss)
I1001 23:12:22.921643  5547 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1001 23:12:37.207959  5547 solver.cpp:218] Iteration 97400 (6.99972 iter/s, 14.2863s/100 iters), loss = 0.00071796
I1001 23:12:37.207989  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000717921 (* 1 = 0.000717921 loss)
I1001 23:12:37.207995  5547 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1001 23:12:50.792496  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:12:51.361945  5547 solver.cpp:330] Iteration 97500, Testing net (#0)
I1001 23:12:54.729777  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:12:54.869921  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9319
I1001 23:12:54.869947  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300882 (* 1 = 0.300882 loss)
I1001 23:12:55.011447  5547 solver.cpp:218] Iteration 97500 (5.6169 iter/s, 17.8034s/100 iters), loss = 0.0011347
I1001 23:12:55.011484  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00113467 (* 1 = 0.00113467 loss)
I1001 23:12:55.011493  5547 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1001 23:13:09.297683  5547 solver.cpp:218] Iteration 97600 (6.99987 iter/s, 14.286s/100 iters), loss = 0.000492042
I1001 23:13:09.297714  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000492003 (* 1 = 0.000492003 loss)
I1001 23:13:09.297720  5547 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1001 23:13:23.577733  5547 solver.cpp:218] Iteration 97700 (7.00281 iter/s, 14.28s/100 iters), loss = 0.000630961
I1001 23:13:23.577841  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000630922 (* 1 = 0.000630922 loss)
I1001 23:13:23.577857  5547 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1001 23:13:37.856825  5547 solver.cpp:218] Iteration 97800 (7.00331 iter/s, 14.279s/100 iters), loss = 0.00158716
I1001 23:13:37.856871  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00158713 (* 1 = 0.00158713 loss)
I1001 23:13:37.856879  5547 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1001 23:13:52.126117  5547 solver.cpp:218] Iteration 97900 (7.00811 iter/s, 14.2692s/100 iters), loss = 0.000216136
I1001 23:13:52.126147  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000216097 (* 1 = 0.000216097 loss)
I1001 23:13:52.126153  5547 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1001 23:14:05.705500  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:14:06.274631  5547 solver.cpp:330] Iteration 98000, Testing net (#0)
I1001 23:14:09.642871  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:14:09.782845  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9315
I1001 23:14:09.782881  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.301499 (* 1 = 0.301499 loss)
I1001 23:14:09.923667  5547 solver.cpp:218] Iteration 98000 (5.61878 iter/s, 17.7975s/100 iters), loss = 0.000777979
I1001 23:14:09.923714  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000777939 (* 1 = 0.000777939 loss)
I1001 23:14:09.923722  5547 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1001 23:14:24.191867  5547 solver.cpp:218] Iteration 98100 (7.00872 iter/s, 14.2679s/100 iters), loss = 0.00150581
I1001 23:14:24.191900  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00150577 (* 1 = 0.00150577 loss)
I1001 23:14:24.191905  5547 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1001 23:14:38.480285  5547 solver.cpp:218] Iteration 98200 (6.99871 iter/s, 14.2884s/100 iters), loss = 0.00144088
I1001 23:14:38.480432  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00144084 (* 1 = 0.00144084 loss)
I1001 23:14:38.480440  5547 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1001 23:14:52.759692  5547 solver.cpp:218] Iteration 98300 (7.00318 iter/s, 14.2792s/100 iters), loss = 0.00128492
I1001 23:14:52.759737  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128488 (* 1 = 0.00128488 loss)
I1001 23:14:52.759745  5547 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1001 23:15:07.031522  5547 solver.cpp:218] Iteration 98400 (7.00685 iter/s, 14.2717s/100 iters), loss = 0.000440917
I1001 23:15:07.031553  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000440877 (* 1 = 0.000440877 loss)
I1001 23:15:07.031559  5547 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1001 23:15:20.605144  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:15:21.175583  5547 solver.cpp:330] Iteration 98500, Testing net (#0)
I1001 23:15:24.545073  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:15:24.685262  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.932
I1001 23:15:24.685297  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.301041 (* 1 = 0.301041 loss)
I1001 23:15:24.826464  5547 solver.cpp:218] Iteration 98500 (5.6196 iter/s, 17.7949s/100 iters), loss = 0.000224803
I1001 23:15:24.826495  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000224763 (* 1 = 0.000224763 loss)
I1001 23:15:24.826501  5547 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1001 23:15:39.120069  5547 solver.cpp:218] Iteration 98600 (6.99617 iter/s, 14.2935s/100 iters), loss = 0.00139058
I1001 23:15:39.120100  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00139054 (* 1 = 0.00139054 loss)
I1001 23:15:39.120106  5547 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1001 23:15:53.410444  5547 solver.cpp:218] Iteration 98700 (6.99775 iter/s, 14.2903s/100 iters), loss = 0.000499875
I1001 23:15:53.410524  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000499834 (* 1 = 0.000499834 loss)
I1001 23:15:53.410533  5547 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1001 23:16:07.691292  5547 solver.cpp:218] Iteration 98800 (7.00244 iter/s, 14.2807s/100 iters), loss = 0.000700562
I1001 23:16:07.691328  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000700521 (* 1 = 0.000700521 loss)
I1001 23:16:07.691335  5547 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1001 23:16:21.975081  5547 solver.cpp:218] Iteration 98900 (7.00098 iter/s, 14.2837s/100 iters), loss = 0.000902357
I1001 23:16:21.975111  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000902316 (* 1 = 0.000902316 loss)
I1001 23:16:21.975117  5547 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1001 23:16:35.556548  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:16:36.126579  5547 solver.cpp:330] Iteration 99000, Testing net (#0)
I1001 23:16:39.491808  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:16:39.631733  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.932
I1001 23:16:39.631768  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.301167 (* 1 = 0.301167 loss)
I1001 23:16:39.773313  5547 solver.cpp:218] Iteration 99000 (5.61856 iter/s, 17.7982s/100 iters), loss = 0.000741688
I1001 23:16:39.773341  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000741647 (* 1 = 0.000741647 loss)
I1001 23:16:39.773349  5547 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1001 23:16:54.048902  5547 solver.cpp:218] Iteration 99100 (7.00502 iter/s, 14.2755s/100 iters), loss = 0.00176234
I1001 23:16:54.048933  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0017623 (* 1 = 0.0017623 loss)
I1001 23:16:54.048939  5547 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1001 23:17:08.332782  5547 solver.cpp:218] Iteration 99200 (7.00093 iter/s, 14.2838s/100 iters), loss = 0.000217963
I1001 23:17:08.332897  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000217921 (* 1 = 0.000217921 loss)
I1001 23:17:08.332914  5547 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1001 23:17:22.597982  5547 solver.cpp:218] Iteration 99300 (7.01014 iter/s, 14.2651s/100 iters), loss = 0.00106631
I1001 23:17:22.598016  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00106627 (* 1 = 0.00106627 loss)
I1001 23:17:22.598022  5547 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1001 23:17:36.875577  5547 solver.cpp:218] Iteration 99400 (7.00401 iter/s, 14.2775s/100 iters), loss = 0.000498848
I1001 23:17:36.875619  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000498806 (* 1 = 0.000498806 loss)
I1001 23:17:36.875625  5547 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1001 23:17:50.452612  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:17:51.022831  5547 solver.cpp:330] Iteration 99500, Testing net (#0)
I1001 23:17:54.391916  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:17:54.531826  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.931
I1001 23:17:54.531859  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300801 (* 1 = 0.300801 loss)
I1001 23:17:54.673710  5547 solver.cpp:218] Iteration 99500 (5.61859 iter/s, 17.798s/100 iters), loss = 0.00294105
I1001 23:17:54.673743  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00294101 (* 1 = 0.00294101 loss)
I1001 23:17:54.673749  5547 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1001 23:18:08.966856  5547 solver.cpp:218] Iteration 99600 (6.9964 iter/s, 14.2931s/100 iters), loss = 0.00110897
I1001 23:18:08.966886  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00110893 (* 1 = 0.00110893 loss)
I1001 23:18:08.966893  5547 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1001 23:18:23.242343  5547 solver.cpp:218] Iteration 99700 (7.00505 iter/s, 14.2754s/100 iters), loss = 0.000640611
I1001 23:18:23.242444  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000640573 (* 1 = 0.000640573 loss)
I1001 23:18:23.242461  5547 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1001 23:18:37.527868  5547 solver.cpp:218] Iteration 99800 (7.00016 iter/s, 14.2854s/100 iters), loss = 0.00256017
I1001 23:18:37.527897  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00256013 (* 1 = 0.00256013 loss)
I1001 23:18:37.527902  5547 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1001 23:18:51.819587  5547 solver.cpp:218] Iteration 99900 (6.99709 iter/s, 14.2917s/100 iters), loss = 0.000251686
I1001 23:18:51.819619  5547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000251648 (* 1 = 0.000251648 loss)
I1001 23:18:51.819625  5547 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1001 23:19:05.397931  5556 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:19:05.966918  5547 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res56_mpelu_alpha1_beta1_2study_2decay_gauss_iter_100000.caffemodel
I1001 23:19:05.992861  5547 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res56_mpelu_alpha1_beta1_2study_2decay_gauss_iter_100000.solverstate
I1001 23:19:06.033109  5547 solver.cpp:310] Iteration 100000, loss = 0.00160283
I1001 23:19:06.033131  5547 solver.cpp:330] Iteration 100000, Testing net (#0)
I1001 23:19:09.398733  5557 data_layer.cpp:73] Restarting data prefetching from start.
I1001 23:19:09.539253  5547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9316
I1001 23:19:09.539288  5547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300736 (* 1 = 0.300736 loss)
I1001 23:19:09.539293  5547 solver.cpp:315] Optimization Done.
I1001 23:19:09.539294  5547 caffe.cpp:259] Optimization Done.
