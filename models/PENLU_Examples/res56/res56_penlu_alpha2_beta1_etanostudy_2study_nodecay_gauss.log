I0928 19:59:16.711657  5237 caffe.cpp:218] Using GPUs 0
I0928 19:59:16.733795  5237 caffe.cpp:223] GPU 0: GeForce GTX 1080
I0928 19:59:16.944775  5237 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res56_penlu_alpha2_eta1_2study_nodecay_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_penlu_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I0928 19:59:16.944910  5237 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_penlu_train_test.prototxt
I0928 19:59:16.949023  5237 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_penlu_train_test.prototxt
I0928 19:59:16.949036  5237 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0928 19:59:16.949270  5237 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I0928 19:59:16.949394  5237 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I0928 19:59:16.950556  5237 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu20"
  type: "PENLU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu21"
  type: "PENLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu22"
  type: "PENLU"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std
I0928 19:59:16.951336  5237 layer_factory.hpp:77] Creating layer Data1
I0928 19:59:16.951409  5237 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I0928 19:59:16.951428  5237 net.cpp:84] Creating Layer Data1
I0928 19:59:16.951433  5237 net.cpp:380] Data1 -> Data1
I0928 19:59:16.951452  5237 net.cpp:380] Data1 -> Data2
I0928 19:59:16.951459  5237 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0928 19:59:16.952881  5237 data_layer.cpp:45] output data size: 100,3,28,28
I0928 19:59:16.955180  5237 net.cpp:122] Setting up Data1
I0928 19:59:16.955194  5237 net.cpp:129] Top shape: 100 3 28 28 (235200)
I0928 19:59:16.955199  5237 net.cpp:129] Top shape: 100 (100)
I0928 19:59:16.955200  5237 net.cpp:137] Memory required for data: 941200
I0928 19:59:16.955206  5237 layer_factory.hpp:77] Creating layer Convolution1
I0928 19:59:16.955224  5237 net.cpp:84] Creating Layer Convolution1
I0928 19:59:16.955229  5237 net.cpp:406] Convolution1 <- Data1
I0928 19:59:16.955237  5237 net.cpp:380] Convolution1 -> Convolution1
I0928 19:59:17.101800  5237 net.cpp:122] Setting up Convolution1
I0928 19:59:17.101824  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.101828  5237 net.cpp:137] Memory required for data: 5958800
I0928 19:59:17.101843  5237 layer_factory.hpp:77] Creating layer BatchNorm1
I0928 19:59:17.101867  5237 net.cpp:84] Creating Layer BatchNorm1
I0928 19:59:17.101893  5237 net.cpp:406] BatchNorm1 <- Convolution1
I0928 19:59:17.101909  5237 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0928 19:59:17.102066  5237 net.cpp:122] Setting up BatchNorm1
I0928 19:59:17.102071  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.102072  5237 net.cpp:137] Memory required for data: 10976400
I0928 19:59:17.102080  5237 layer_factory.hpp:77] Creating layer Scale1
I0928 19:59:17.102103  5237 net.cpp:84] Creating Layer Scale1
I0928 19:59:17.102107  5237 net.cpp:406] Scale1 <- Convolution1
I0928 19:59:17.102119  5237 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0928 19:59:17.102181  5237 layer_factory.hpp:77] Creating layer Scale1
I0928 19:59:17.102315  5237 net.cpp:122] Setting up Scale1
I0928 19:59:17.102319  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.102331  5237 net.cpp:137] Memory required for data: 15994000
I0928 19:59:17.102336  5237 layer_factory.hpp:77] Creating layer penlu1
I0928 19:59:17.102355  5237 net.cpp:84] Creating Layer penlu1
I0928 19:59:17.102358  5237 net.cpp:406] penlu1 <- Convolution1
I0928 19:59:17.102362  5237 net.cpp:367] penlu1 -> Convolution1 (in-place)
I0928 19:59:17.102982  5237 net.cpp:122] Setting up penlu1
I0928 19:59:17.102991  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.103004  5237 net.cpp:137] Memory required for data: 21011600
I0928 19:59:17.103011  5237 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I0928 19:59:17.103016  5237 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I0928 19:59:17.103034  5237 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I0928 19:59:17.103037  5237 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I0928 19:59:17.103044  5237 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I0928 19:59:17.103080  5237 net.cpp:122] Setting up Convolution1_penlu1_0_split
I0928 19:59:17.103085  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.103096  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.103098  5237 net.cpp:137] Memory required for data: 31046800
I0928 19:59:17.103101  5237 layer_factory.hpp:77] Creating layer Convolution2
I0928 19:59:17.103117  5237 net.cpp:84] Creating Layer Convolution2
I0928 19:59:17.103119  5237 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I0928 19:59:17.103123  5237 net.cpp:380] Convolution2 -> Convolution2
I0928 19:59:17.103996  5237 net.cpp:122] Setting up Convolution2
I0928 19:59:17.104007  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.104019  5237 net.cpp:137] Memory required for data: 36064400
I0928 19:59:17.104024  5237 layer_factory.hpp:77] Creating layer BatchNorm2
I0928 19:59:17.104029  5237 net.cpp:84] Creating Layer BatchNorm2
I0928 19:59:17.104032  5237 net.cpp:406] BatchNorm2 <- Convolution2
I0928 19:59:17.104037  5237 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0928 19:59:17.104171  5237 net.cpp:122] Setting up BatchNorm2
I0928 19:59:17.104176  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.104188  5237 net.cpp:137] Memory required for data: 41082000
I0928 19:59:17.104193  5237 layer_factory.hpp:77] Creating layer Scale2
I0928 19:59:17.104198  5237 net.cpp:84] Creating Layer Scale2
I0928 19:59:17.104210  5237 net.cpp:406] Scale2 <- Convolution2
I0928 19:59:17.104215  5237 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0928 19:59:17.104259  5237 layer_factory.hpp:77] Creating layer Scale2
I0928 19:59:17.104357  5237 net.cpp:122] Setting up Scale2
I0928 19:59:17.104362  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.104374  5237 net.cpp:137] Memory required for data: 46099600
I0928 19:59:17.104380  5237 layer_factory.hpp:77] Creating layer penlu2
I0928 19:59:17.104385  5237 net.cpp:84] Creating Layer penlu2
I0928 19:59:17.104398  5237 net.cpp:406] penlu2 <- Convolution2
I0928 19:59:17.104401  5237 net.cpp:367] penlu2 -> Convolution2 (in-place)
I0928 19:59:17.104506  5237 net.cpp:122] Setting up penlu2
I0928 19:59:17.104511  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.104531  5237 net.cpp:137] Memory required for data: 51117200
I0928 19:59:17.104535  5237 layer_factory.hpp:77] Creating layer Convolution3
I0928 19:59:17.104542  5237 net.cpp:84] Creating Layer Convolution3
I0928 19:59:17.104554  5237 net.cpp:406] Convolution3 <- Convolution2
I0928 19:59:17.104558  5237 net.cpp:380] Convolution3 -> Convolution3
I0928 19:59:17.107545  5237 net.cpp:122] Setting up Convolution3
I0928 19:59:17.107558  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.107560  5237 net.cpp:137] Memory required for data: 56134800
I0928 19:59:17.107565  5237 layer_factory.hpp:77] Creating layer BatchNorm3
I0928 19:59:17.107570  5237 net.cpp:84] Creating Layer BatchNorm3
I0928 19:59:17.107573  5237 net.cpp:406] BatchNorm3 <- Convolution3
I0928 19:59:17.107576  5237 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0928 19:59:17.107708  5237 net.cpp:122] Setting up BatchNorm3
I0928 19:59:17.107713  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.107717  5237 net.cpp:137] Memory required for data: 61152400
I0928 19:59:17.107722  5237 layer_factory.hpp:77] Creating layer Scale3
I0928 19:59:17.107727  5237 net.cpp:84] Creating Layer Scale3
I0928 19:59:17.107728  5237 net.cpp:406] Scale3 <- Convolution3
I0928 19:59:17.107733  5237 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0928 19:59:17.107756  5237 layer_factory.hpp:77] Creating layer Scale3
I0928 19:59:17.107830  5237 net.cpp:122] Setting up Scale3
I0928 19:59:17.107834  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.107837  5237 net.cpp:137] Memory required for data: 66170000
I0928 19:59:17.107841  5237 layer_factory.hpp:77] Creating layer Eltwise1
I0928 19:59:17.107846  5237 net.cpp:84] Creating Layer Eltwise1
I0928 19:59:17.107849  5237 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I0928 19:59:17.107852  5237 net.cpp:406] Eltwise1 <- Convolution3
I0928 19:59:17.107856  5237 net.cpp:380] Eltwise1 -> Eltwise1
I0928 19:59:17.107874  5237 net.cpp:122] Setting up Eltwise1
I0928 19:59:17.107878  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.107882  5237 net.cpp:137] Memory required for data: 71187600
I0928 19:59:17.107883  5237 layer_factory.hpp:77] Creating layer penlu3
I0928 19:59:17.107888  5237 net.cpp:84] Creating Layer penlu3
I0928 19:59:17.107892  5237 net.cpp:406] penlu3 <- Eltwise1
I0928 19:59:17.107894  5237 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I0928 19:59:17.108000  5237 net.cpp:122] Setting up penlu3
I0928 19:59:17.108005  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.108007  5237 net.cpp:137] Memory required for data: 76205200
I0928 19:59:17.108011  5237 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I0928 19:59:17.108016  5237 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I0928 19:59:17.108018  5237 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I0928 19:59:17.108021  5237 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I0928 19:59:17.108026  5237 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I0928 19:59:17.108048  5237 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I0928 19:59:17.108053  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.108057  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.108058  5237 net.cpp:137] Memory required for data: 86240400
I0928 19:59:17.108060  5237 layer_factory.hpp:77] Creating layer Convolution4
I0928 19:59:17.108067  5237 net.cpp:84] Creating Layer Convolution4
I0928 19:59:17.108070  5237 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I0928 19:59:17.108074  5237 net.cpp:380] Convolution4 -> Convolution4
I0928 19:59:17.108961  5237 net.cpp:122] Setting up Convolution4
I0928 19:59:17.108971  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.108974  5237 net.cpp:137] Memory required for data: 91258000
I0928 19:59:17.108978  5237 layer_factory.hpp:77] Creating layer BatchNorm4
I0928 19:59:17.108983  5237 net.cpp:84] Creating Layer BatchNorm4
I0928 19:59:17.109002  5237 net.cpp:406] BatchNorm4 <- Convolution4
I0928 19:59:17.109009  5237 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0928 19:59:17.109153  5237 net.cpp:122] Setting up BatchNorm4
I0928 19:59:17.109158  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.109160  5237 net.cpp:137] Memory required for data: 96275600
I0928 19:59:17.109169  5237 layer_factory.hpp:77] Creating layer Scale4
I0928 19:59:17.109174  5237 net.cpp:84] Creating Layer Scale4
I0928 19:59:17.109175  5237 net.cpp:406] Scale4 <- Convolution4
I0928 19:59:17.109189  5237 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0928 19:59:17.109223  5237 layer_factory.hpp:77] Creating layer Scale4
I0928 19:59:17.109310  5237 net.cpp:122] Setting up Scale4
I0928 19:59:17.109315  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.109318  5237 net.cpp:137] Memory required for data: 101293200
I0928 19:59:17.109331  5237 layer_factory.hpp:77] Creating layer penlu4
I0928 19:59:17.109335  5237 net.cpp:84] Creating Layer penlu4
I0928 19:59:17.109338  5237 net.cpp:406] penlu4 <- Convolution4
I0928 19:59:17.109342  5237 net.cpp:367] penlu4 -> Convolution4 (in-place)
I0928 19:59:17.109448  5237 net.cpp:122] Setting up penlu4
I0928 19:59:17.109453  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.109465  5237 net.cpp:137] Memory required for data: 106310800
I0928 19:59:17.109470  5237 layer_factory.hpp:77] Creating layer Convolution5
I0928 19:59:17.109478  5237 net.cpp:84] Creating Layer Convolution5
I0928 19:59:17.109480  5237 net.cpp:406] Convolution5 <- Convolution4
I0928 19:59:17.109485  5237 net.cpp:380] Convolution5 -> Convolution5
I0928 19:59:17.110342  5237 net.cpp:122] Setting up Convolution5
I0928 19:59:17.110352  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.110364  5237 net.cpp:137] Memory required for data: 111328400
I0928 19:59:17.110369  5237 layer_factory.hpp:77] Creating layer BatchNorm5
I0928 19:59:17.110374  5237 net.cpp:84] Creating Layer BatchNorm5
I0928 19:59:17.110378  5237 net.cpp:406] BatchNorm5 <- Convolution5
I0928 19:59:17.110380  5237 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0928 19:59:17.110509  5237 net.cpp:122] Setting up BatchNorm5
I0928 19:59:17.110514  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.110533  5237 net.cpp:137] Memory required for data: 116346000
I0928 19:59:17.110539  5237 layer_factory.hpp:77] Creating layer Scale5
I0928 19:59:17.110543  5237 net.cpp:84] Creating Layer Scale5
I0928 19:59:17.110546  5237 net.cpp:406] Scale5 <- Convolution5
I0928 19:59:17.110559  5237 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0928 19:59:17.110585  5237 layer_factory.hpp:77] Creating layer Scale5
I0928 19:59:17.110657  5237 net.cpp:122] Setting up Scale5
I0928 19:59:17.110662  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.110664  5237 net.cpp:137] Memory required for data: 121363600
I0928 19:59:17.110667  5237 layer_factory.hpp:77] Creating layer Eltwise2
I0928 19:59:17.110672  5237 net.cpp:84] Creating Layer Eltwise2
I0928 19:59:17.110676  5237 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I0928 19:59:17.110678  5237 net.cpp:406] Eltwise2 <- Convolution5
I0928 19:59:17.110682  5237 net.cpp:380] Eltwise2 -> Eltwise2
I0928 19:59:17.110697  5237 net.cpp:122] Setting up Eltwise2
I0928 19:59:17.110700  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.110702  5237 net.cpp:137] Memory required for data: 126381200
I0928 19:59:17.110704  5237 layer_factory.hpp:77] Creating layer penlu5
I0928 19:59:17.110709  5237 net.cpp:84] Creating Layer penlu5
I0928 19:59:17.110713  5237 net.cpp:406] penlu5 <- Eltwise2
I0928 19:59:17.110716  5237 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I0928 19:59:17.110816  5237 net.cpp:122] Setting up penlu5
I0928 19:59:17.110821  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.110823  5237 net.cpp:137] Memory required for data: 131398800
I0928 19:59:17.110827  5237 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I0928 19:59:17.110839  5237 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I0928 19:59:17.110842  5237 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I0928 19:59:17.110846  5237 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I0928 19:59:17.110849  5237 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I0928 19:59:17.110870  5237 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I0928 19:59:17.110875  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.110877  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.110879  5237 net.cpp:137] Memory required for data: 141434000
I0928 19:59:17.110882  5237 layer_factory.hpp:77] Creating layer Convolution6
I0928 19:59:17.110888  5237 net.cpp:84] Creating Layer Convolution6
I0928 19:59:17.110890  5237 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I0928 19:59:17.110895  5237 net.cpp:380] Convolution6 -> Convolution6
I0928 19:59:17.111743  5237 net.cpp:122] Setting up Convolution6
I0928 19:59:17.111752  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.111757  5237 net.cpp:137] Memory required for data: 146451600
I0928 19:59:17.111760  5237 layer_factory.hpp:77] Creating layer BatchNorm6
I0928 19:59:17.111766  5237 net.cpp:84] Creating Layer BatchNorm6
I0928 19:59:17.111769  5237 net.cpp:406] BatchNorm6 <- Convolution6
I0928 19:59:17.111773  5237 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0928 19:59:17.111896  5237 net.cpp:122] Setting up BatchNorm6
I0928 19:59:17.111901  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.111904  5237 net.cpp:137] Memory required for data: 151469200
I0928 19:59:17.111909  5237 layer_factory.hpp:77] Creating layer Scale6
I0928 19:59:17.111913  5237 net.cpp:84] Creating Layer Scale6
I0928 19:59:17.111917  5237 net.cpp:406] Scale6 <- Convolution6
I0928 19:59:17.111919  5237 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0928 19:59:17.111945  5237 layer_factory.hpp:77] Creating layer Scale6
I0928 19:59:17.112018  5237 net.cpp:122] Setting up Scale6
I0928 19:59:17.112022  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.112026  5237 net.cpp:137] Memory required for data: 156486800
I0928 19:59:17.112030  5237 layer_factory.hpp:77] Creating layer penlu6
I0928 19:59:17.112036  5237 net.cpp:84] Creating Layer penlu6
I0928 19:59:17.112038  5237 net.cpp:406] penlu6 <- Convolution6
I0928 19:59:17.112042  5237 net.cpp:367] penlu6 -> Convolution6 (in-place)
I0928 19:59:17.112143  5237 net.cpp:122] Setting up penlu6
I0928 19:59:17.112148  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.112149  5237 net.cpp:137] Memory required for data: 161504400
I0928 19:59:17.112154  5237 layer_factory.hpp:77] Creating layer Convolution7
I0928 19:59:17.112161  5237 net.cpp:84] Creating Layer Convolution7
I0928 19:59:17.112164  5237 net.cpp:406] Convolution7 <- Convolution6
I0928 19:59:17.112169  5237 net.cpp:380] Convolution7 -> Convolution7
I0928 19:59:17.112716  5237 net.cpp:122] Setting up Convolution7
I0928 19:59:17.112725  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.112728  5237 net.cpp:137] Memory required for data: 166522000
I0928 19:59:17.112732  5237 layer_factory.hpp:77] Creating layer BatchNorm7
I0928 19:59:17.112738  5237 net.cpp:84] Creating Layer BatchNorm7
I0928 19:59:17.112741  5237 net.cpp:406] BatchNorm7 <- Convolution7
I0928 19:59:17.112746  5237 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0928 19:59:17.112871  5237 net.cpp:122] Setting up BatchNorm7
I0928 19:59:17.112876  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.112879  5237 net.cpp:137] Memory required for data: 171539600
I0928 19:59:17.112888  5237 layer_factory.hpp:77] Creating layer Scale7
I0928 19:59:17.112895  5237 net.cpp:84] Creating Layer Scale7
I0928 19:59:17.112898  5237 net.cpp:406] Scale7 <- Convolution7
I0928 19:59:17.112902  5237 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0928 19:59:17.112928  5237 layer_factory.hpp:77] Creating layer Scale7
I0928 19:59:17.113001  5237 net.cpp:122] Setting up Scale7
I0928 19:59:17.113013  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.113016  5237 net.cpp:137] Memory required for data: 176557200
I0928 19:59:17.113020  5237 layer_factory.hpp:77] Creating layer Eltwise3
I0928 19:59:17.113025  5237 net.cpp:84] Creating Layer Eltwise3
I0928 19:59:17.113029  5237 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I0928 19:59:17.113031  5237 net.cpp:406] Eltwise3 <- Convolution7
I0928 19:59:17.113034  5237 net.cpp:380] Eltwise3 -> Eltwise3
I0928 19:59:17.113049  5237 net.cpp:122] Setting up Eltwise3
I0928 19:59:17.113054  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.113055  5237 net.cpp:137] Memory required for data: 181574800
I0928 19:59:17.113059  5237 layer_factory.hpp:77] Creating layer penlu7
I0928 19:59:17.113065  5237 net.cpp:84] Creating Layer penlu7
I0928 19:59:17.113067  5237 net.cpp:406] penlu7 <- Eltwise3
I0928 19:59:17.113070  5237 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I0928 19:59:17.113173  5237 net.cpp:122] Setting up penlu7
I0928 19:59:17.113178  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.113181  5237 net.cpp:137] Memory required for data: 186592400
I0928 19:59:17.113185  5237 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I0928 19:59:17.113190  5237 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I0928 19:59:17.113193  5237 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I0928 19:59:17.113196  5237 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I0928 19:59:17.113200  5237 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I0928 19:59:17.113241  5237 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I0928 19:59:17.113246  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.113248  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.113251  5237 net.cpp:137] Memory required for data: 196627600
I0928 19:59:17.113253  5237 layer_factory.hpp:77] Creating layer Convolution8
I0928 19:59:17.113260  5237 net.cpp:84] Creating Layer Convolution8
I0928 19:59:17.113263  5237 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I0928 19:59:17.113266  5237 net.cpp:380] Convolution8 -> Convolution8
I0928 19:59:17.114253  5237 net.cpp:122] Setting up Convolution8
I0928 19:59:17.114264  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.114266  5237 net.cpp:137] Memory required for data: 201645200
I0928 19:59:17.114271  5237 layer_factory.hpp:77] Creating layer BatchNorm8
I0928 19:59:17.114276  5237 net.cpp:84] Creating Layer BatchNorm8
I0928 19:59:17.114280  5237 net.cpp:406] BatchNorm8 <- Convolution8
I0928 19:59:17.114285  5237 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0928 19:59:17.114408  5237 net.cpp:122] Setting up BatchNorm8
I0928 19:59:17.114413  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.114416  5237 net.cpp:137] Memory required for data: 206662800
I0928 19:59:17.114421  5237 layer_factory.hpp:77] Creating layer Scale8
I0928 19:59:17.114428  5237 net.cpp:84] Creating Layer Scale8
I0928 19:59:17.114430  5237 net.cpp:406] Scale8 <- Convolution8
I0928 19:59:17.114434  5237 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0928 19:59:17.114459  5237 layer_factory.hpp:77] Creating layer Scale8
I0928 19:59:17.114547  5237 net.cpp:122] Setting up Scale8
I0928 19:59:17.114552  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.114563  5237 net.cpp:137] Memory required for data: 211680400
I0928 19:59:17.114567  5237 layer_factory.hpp:77] Creating layer penlu8
I0928 19:59:17.114573  5237 net.cpp:84] Creating Layer penlu8
I0928 19:59:17.114576  5237 net.cpp:406] penlu8 <- Convolution8
I0928 19:59:17.114580  5237 net.cpp:367] penlu8 -> Convolution8 (in-place)
I0928 19:59:17.114681  5237 net.cpp:122] Setting up penlu8
I0928 19:59:17.114686  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.114688  5237 net.cpp:137] Memory required for data: 216698000
I0928 19:59:17.114693  5237 layer_factory.hpp:77] Creating layer Convolution9
I0928 19:59:17.114707  5237 net.cpp:84] Creating Layer Convolution9
I0928 19:59:17.114711  5237 net.cpp:406] Convolution9 <- Convolution8
I0928 19:59:17.114714  5237 net.cpp:380] Convolution9 -> Convolution9
I0928 19:59:17.115725  5237 net.cpp:122] Setting up Convolution9
I0928 19:59:17.115736  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.115738  5237 net.cpp:137] Memory required for data: 221715600
I0928 19:59:17.115742  5237 layer_factory.hpp:77] Creating layer BatchNorm9
I0928 19:59:17.115748  5237 net.cpp:84] Creating Layer BatchNorm9
I0928 19:59:17.115751  5237 net.cpp:406] BatchNorm9 <- Convolution9
I0928 19:59:17.115756  5237 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0928 19:59:17.115885  5237 net.cpp:122] Setting up BatchNorm9
I0928 19:59:17.115890  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.115892  5237 net.cpp:137] Memory required for data: 226733200
I0928 19:59:17.115897  5237 layer_factory.hpp:77] Creating layer Scale9
I0928 19:59:17.115901  5237 net.cpp:84] Creating Layer Scale9
I0928 19:59:17.115905  5237 net.cpp:406] Scale9 <- Convolution9
I0928 19:59:17.115908  5237 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0928 19:59:17.115933  5237 layer_factory.hpp:77] Creating layer Scale9
I0928 19:59:17.116014  5237 net.cpp:122] Setting up Scale9
I0928 19:59:17.116019  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.116021  5237 net.cpp:137] Memory required for data: 231750800
I0928 19:59:17.116025  5237 layer_factory.hpp:77] Creating layer Eltwise4
I0928 19:59:17.116030  5237 net.cpp:84] Creating Layer Eltwise4
I0928 19:59:17.116034  5237 net.cpp:406] Eltwise4 <- Eltwise3_penlu7_0_split_1
I0928 19:59:17.116036  5237 net.cpp:406] Eltwise4 <- Convolution9
I0928 19:59:17.116040  5237 net.cpp:380] Eltwise4 -> Eltwise4
I0928 19:59:17.116056  5237 net.cpp:122] Setting up Eltwise4
I0928 19:59:17.116060  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.116062  5237 net.cpp:137] Memory required for data: 236768400
I0928 19:59:17.116065  5237 layer_factory.hpp:77] Creating layer penlu9
I0928 19:59:17.116070  5237 net.cpp:84] Creating Layer penlu9
I0928 19:59:17.116072  5237 net.cpp:406] penlu9 <- Eltwise4
I0928 19:59:17.116076  5237 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I0928 19:59:17.116181  5237 net.cpp:122] Setting up penlu9
I0928 19:59:17.116186  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.116189  5237 net.cpp:137] Memory required for data: 241786000
I0928 19:59:17.116194  5237 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I0928 19:59:17.116197  5237 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I0928 19:59:17.116200  5237 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I0928 19:59:17.116204  5237 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I0928 19:59:17.116209  5237 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I0928 19:59:17.116230  5237 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I0928 19:59:17.116235  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.116237  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.116240  5237 net.cpp:137] Memory required for data: 251821200
I0928 19:59:17.116241  5237 layer_factory.hpp:77] Creating layer Convolution10
I0928 19:59:17.116248  5237 net.cpp:84] Creating Layer Convolution10
I0928 19:59:17.116251  5237 net.cpp:406] Convolution10 <- Eltwise4_penlu9_0_split_0
I0928 19:59:17.116255  5237 net.cpp:380] Convolution10 -> Convolution10
I0928 19:59:17.117133  5237 net.cpp:122] Setting up Convolution10
I0928 19:59:17.117143  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.117146  5237 net.cpp:137] Memory required for data: 256838800
I0928 19:59:17.117151  5237 layer_factory.hpp:77] Creating layer BatchNorm10
I0928 19:59:17.117156  5237 net.cpp:84] Creating Layer BatchNorm10
I0928 19:59:17.117159  5237 net.cpp:406] BatchNorm10 <- Convolution10
I0928 19:59:17.117163  5237 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0928 19:59:17.117290  5237 net.cpp:122] Setting up BatchNorm10
I0928 19:59:17.117301  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.117305  5237 net.cpp:137] Memory required for data: 261856400
I0928 19:59:17.117310  5237 layer_factory.hpp:77] Creating layer Scale10
I0928 19:59:17.117314  5237 net.cpp:84] Creating Layer Scale10
I0928 19:59:17.117318  5237 net.cpp:406] Scale10 <- Convolution10
I0928 19:59:17.117322  5237 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0928 19:59:17.117347  5237 layer_factory.hpp:77] Creating layer Scale10
I0928 19:59:17.117422  5237 net.cpp:122] Setting up Scale10
I0928 19:59:17.117427  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.117430  5237 net.cpp:137] Memory required for data: 266874000
I0928 19:59:17.117434  5237 layer_factory.hpp:77] Creating layer penlu10
I0928 19:59:17.117441  5237 net.cpp:84] Creating Layer penlu10
I0928 19:59:17.117444  5237 net.cpp:406] penlu10 <- Convolution10
I0928 19:59:17.117449  5237 net.cpp:367] penlu10 -> Convolution10 (in-place)
I0928 19:59:17.117553  5237 net.cpp:122] Setting up penlu10
I0928 19:59:17.117559  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.117561  5237 net.cpp:137] Memory required for data: 271891600
I0928 19:59:17.117566  5237 layer_factory.hpp:77] Creating layer Convolution11
I0928 19:59:17.117575  5237 net.cpp:84] Creating Layer Convolution11
I0928 19:59:17.117578  5237 net.cpp:406] Convolution11 <- Convolution10
I0928 19:59:17.117583  5237 net.cpp:380] Convolution11 -> Convolution11
I0928 19:59:17.118463  5237 net.cpp:122] Setting up Convolution11
I0928 19:59:17.118474  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.118477  5237 net.cpp:137] Memory required for data: 276909200
I0928 19:59:17.118481  5237 layer_factory.hpp:77] Creating layer BatchNorm11
I0928 19:59:17.118487  5237 net.cpp:84] Creating Layer BatchNorm11
I0928 19:59:17.118490  5237 net.cpp:406] BatchNorm11 <- Convolution11
I0928 19:59:17.118494  5237 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0928 19:59:17.118655  5237 net.cpp:122] Setting up BatchNorm11
I0928 19:59:17.118661  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.118664  5237 net.cpp:137] Memory required for data: 281926800
I0928 19:59:17.118669  5237 layer_factory.hpp:77] Creating layer Scale11
I0928 19:59:17.118674  5237 net.cpp:84] Creating Layer Scale11
I0928 19:59:17.118676  5237 net.cpp:406] Scale11 <- Convolution11
I0928 19:59:17.118681  5237 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0928 19:59:17.118706  5237 layer_factory.hpp:77] Creating layer Scale11
I0928 19:59:17.118783  5237 net.cpp:122] Setting up Scale11
I0928 19:59:17.118788  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.118790  5237 net.cpp:137] Memory required for data: 286944400
I0928 19:59:17.118794  5237 layer_factory.hpp:77] Creating layer Eltwise5
I0928 19:59:17.118798  5237 net.cpp:84] Creating Layer Eltwise5
I0928 19:59:17.118801  5237 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I0928 19:59:17.118804  5237 net.cpp:406] Eltwise5 <- Convolution11
I0928 19:59:17.118808  5237 net.cpp:380] Eltwise5 -> Eltwise5
I0928 19:59:17.118824  5237 net.cpp:122] Setting up Eltwise5
I0928 19:59:17.118829  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.118831  5237 net.cpp:137] Memory required for data: 291962000
I0928 19:59:17.118834  5237 layer_factory.hpp:77] Creating layer penlu11
I0928 19:59:17.118837  5237 net.cpp:84] Creating Layer penlu11
I0928 19:59:17.118840  5237 net.cpp:406] penlu11 <- Eltwise5
I0928 19:59:17.118844  5237 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I0928 19:59:17.118953  5237 net.cpp:122] Setting up penlu11
I0928 19:59:17.118958  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.118960  5237 net.cpp:137] Memory required for data: 296979600
I0928 19:59:17.118965  5237 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I0928 19:59:17.118969  5237 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I0928 19:59:17.118971  5237 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I0928 19:59:17.118983  5237 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I0928 19:59:17.118988  5237 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I0928 19:59:17.119012  5237 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I0928 19:59:17.119016  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.119019  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.119022  5237 net.cpp:137] Memory required for data: 307014800
I0928 19:59:17.119024  5237 layer_factory.hpp:77] Creating layer Convolution12
I0928 19:59:17.119031  5237 net.cpp:84] Creating Layer Convolution12
I0928 19:59:17.119035  5237 net.cpp:406] Convolution12 <- Eltwise5_penlu11_0_split_0
I0928 19:59:17.119038  5237 net.cpp:380] Convolution12 -> Convolution12
I0928 19:59:17.119922  5237 net.cpp:122] Setting up Convolution12
I0928 19:59:17.119932  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.119935  5237 net.cpp:137] Memory required for data: 312032400
I0928 19:59:17.119940  5237 layer_factory.hpp:77] Creating layer BatchNorm12
I0928 19:59:17.119946  5237 net.cpp:84] Creating Layer BatchNorm12
I0928 19:59:17.119948  5237 net.cpp:406] BatchNorm12 <- Convolution12
I0928 19:59:17.119952  5237 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0928 19:59:17.120082  5237 net.cpp:122] Setting up BatchNorm12
I0928 19:59:17.120088  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.120090  5237 net.cpp:137] Memory required for data: 317050000
I0928 19:59:17.120095  5237 layer_factory.hpp:77] Creating layer Scale12
I0928 19:59:17.120100  5237 net.cpp:84] Creating Layer Scale12
I0928 19:59:17.120103  5237 net.cpp:406] Scale12 <- Convolution12
I0928 19:59:17.120106  5237 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0928 19:59:17.120136  5237 layer_factory.hpp:77] Creating layer Scale12
I0928 19:59:17.120213  5237 net.cpp:122] Setting up Scale12
I0928 19:59:17.120218  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.120221  5237 net.cpp:137] Memory required for data: 322067600
I0928 19:59:17.120225  5237 layer_factory.hpp:77] Creating layer penlu12
I0928 19:59:17.120230  5237 net.cpp:84] Creating Layer penlu12
I0928 19:59:17.120234  5237 net.cpp:406] penlu12 <- Convolution12
I0928 19:59:17.120237  5237 net.cpp:367] penlu12 -> Convolution12 (in-place)
I0928 19:59:17.120344  5237 net.cpp:122] Setting up penlu12
I0928 19:59:17.120349  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.120352  5237 net.cpp:137] Memory required for data: 327085200
I0928 19:59:17.120357  5237 layer_factory.hpp:77] Creating layer Convolution13
I0928 19:59:17.120364  5237 net.cpp:84] Creating Layer Convolution13
I0928 19:59:17.120368  5237 net.cpp:406] Convolution13 <- Convolution12
I0928 19:59:17.120373  5237 net.cpp:380] Convolution13 -> Convolution13
I0928 19:59:17.121250  5237 net.cpp:122] Setting up Convolution13
I0928 19:59:17.121260  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.121263  5237 net.cpp:137] Memory required for data: 332102800
I0928 19:59:17.121268  5237 layer_factory.hpp:77] Creating layer BatchNorm13
I0928 19:59:17.121274  5237 net.cpp:84] Creating Layer BatchNorm13
I0928 19:59:17.121278  5237 net.cpp:406] BatchNorm13 <- Convolution13
I0928 19:59:17.121281  5237 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0928 19:59:17.121412  5237 net.cpp:122] Setting up BatchNorm13
I0928 19:59:17.121418  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.121420  5237 net.cpp:137] Memory required for data: 337120400
I0928 19:59:17.121424  5237 layer_factory.hpp:77] Creating layer Scale13
I0928 19:59:17.121429  5237 net.cpp:84] Creating Layer Scale13
I0928 19:59:17.121431  5237 net.cpp:406] Scale13 <- Convolution13
I0928 19:59:17.121435  5237 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0928 19:59:17.121461  5237 layer_factory.hpp:77] Creating layer Scale13
I0928 19:59:17.121538  5237 net.cpp:122] Setting up Scale13
I0928 19:59:17.121543  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.121552  5237 net.cpp:137] Memory required for data: 342138000
I0928 19:59:17.121556  5237 layer_factory.hpp:77] Creating layer Eltwise6
I0928 19:59:17.121562  5237 net.cpp:84] Creating Layer Eltwise6
I0928 19:59:17.121565  5237 net.cpp:406] Eltwise6 <- Eltwise5_penlu11_0_split_1
I0928 19:59:17.121568  5237 net.cpp:406] Eltwise6 <- Convolution13
I0928 19:59:17.121572  5237 net.cpp:380] Eltwise6 -> Eltwise6
I0928 19:59:17.121590  5237 net.cpp:122] Setting up Eltwise6
I0928 19:59:17.121595  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.121598  5237 net.cpp:137] Memory required for data: 347155600
I0928 19:59:17.121600  5237 layer_factory.hpp:77] Creating layer penlu13
I0928 19:59:17.121609  5237 net.cpp:84] Creating Layer penlu13
I0928 19:59:17.121613  5237 net.cpp:406] penlu13 <- Eltwise6
I0928 19:59:17.121616  5237 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I0928 19:59:17.121726  5237 net.cpp:122] Setting up penlu13
I0928 19:59:17.121732  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.121736  5237 net.cpp:137] Memory required for data: 352173200
I0928 19:59:17.121748  5237 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I0928 19:59:17.121753  5237 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I0928 19:59:17.121757  5237 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I0928 19:59:17.121762  5237 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I0928 19:59:17.121767  5237 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I0928 19:59:17.121790  5237 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I0928 19:59:17.121794  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.121798  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.121800  5237 net.cpp:137] Memory required for data: 362208400
I0928 19:59:17.121803  5237 layer_factory.hpp:77] Creating layer Convolution14
I0928 19:59:17.121809  5237 net.cpp:84] Creating Layer Convolution14
I0928 19:59:17.121811  5237 net.cpp:406] Convolution14 <- Eltwise6_penlu13_0_split_0
I0928 19:59:17.121815  5237 net.cpp:380] Convolution14 -> Convolution14
I0928 19:59:17.122743  5237 net.cpp:122] Setting up Convolution14
I0928 19:59:17.122753  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.122756  5237 net.cpp:137] Memory required for data: 367226000
I0928 19:59:17.122761  5237 layer_factory.hpp:77] Creating layer BatchNorm14
I0928 19:59:17.122764  5237 net.cpp:84] Creating Layer BatchNorm14
I0928 19:59:17.122767  5237 net.cpp:406] BatchNorm14 <- Convolution14
I0928 19:59:17.122772  5237 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0928 19:59:17.122905  5237 net.cpp:122] Setting up BatchNorm14
I0928 19:59:17.122910  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.122911  5237 net.cpp:137] Memory required for data: 372243600
I0928 19:59:17.122916  5237 layer_factory.hpp:77] Creating layer Scale14
I0928 19:59:17.122920  5237 net.cpp:84] Creating Layer Scale14
I0928 19:59:17.122922  5237 net.cpp:406] Scale14 <- Convolution14
I0928 19:59:17.122926  5237 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0928 19:59:17.122951  5237 layer_factory.hpp:77] Creating layer Scale14
I0928 19:59:17.123028  5237 net.cpp:122] Setting up Scale14
I0928 19:59:17.123031  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.123034  5237 net.cpp:137] Memory required for data: 377261200
I0928 19:59:17.123037  5237 layer_factory.hpp:77] Creating layer penlu14
I0928 19:59:17.123041  5237 net.cpp:84] Creating Layer penlu14
I0928 19:59:17.123044  5237 net.cpp:406] penlu14 <- Convolution14
I0928 19:59:17.123049  5237 net.cpp:367] penlu14 -> Convolution14 (in-place)
I0928 19:59:17.123155  5237 net.cpp:122] Setting up penlu14
I0928 19:59:17.123160  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.123162  5237 net.cpp:137] Memory required for data: 382278800
I0928 19:59:17.123167  5237 layer_factory.hpp:77] Creating layer Convolution15
I0928 19:59:17.123172  5237 net.cpp:84] Creating Layer Convolution15
I0928 19:59:17.123181  5237 net.cpp:406] Convolution15 <- Convolution14
I0928 19:59:17.123188  5237 net.cpp:380] Convolution15 -> Convolution15
I0928 19:59:17.124065  5237 net.cpp:122] Setting up Convolution15
I0928 19:59:17.124074  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.124078  5237 net.cpp:137] Memory required for data: 387296400
I0928 19:59:17.124081  5237 layer_factory.hpp:77] Creating layer BatchNorm15
I0928 19:59:17.124086  5237 net.cpp:84] Creating Layer BatchNorm15
I0928 19:59:17.124089  5237 net.cpp:406] BatchNorm15 <- Convolution15
I0928 19:59:17.124094  5237 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0928 19:59:17.124225  5237 net.cpp:122] Setting up BatchNorm15
I0928 19:59:17.124229  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.124231  5237 net.cpp:137] Memory required for data: 392314000
I0928 19:59:17.124236  5237 layer_factory.hpp:77] Creating layer Scale15
I0928 19:59:17.124240  5237 net.cpp:84] Creating Layer Scale15
I0928 19:59:17.124243  5237 net.cpp:406] Scale15 <- Convolution15
I0928 19:59:17.124246  5237 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0928 19:59:17.124272  5237 layer_factory.hpp:77] Creating layer Scale15
I0928 19:59:17.124348  5237 net.cpp:122] Setting up Scale15
I0928 19:59:17.124352  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.124354  5237 net.cpp:137] Memory required for data: 397331600
I0928 19:59:17.124358  5237 layer_factory.hpp:77] Creating layer Eltwise7
I0928 19:59:17.124362  5237 net.cpp:84] Creating Layer Eltwise7
I0928 19:59:17.124364  5237 net.cpp:406] Eltwise7 <- Eltwise6_penlu13_0_split_1
I0928 19:59:17.124367  5237 net.cpp:406] Eltwise7 <- Convolution15
I0928 19:59:17.124370  5237 net.cpp:380] Eltwise7 -> Eltwise7
I0928 19:59:17.124385  5237 net.cpp:122] Setting up Eltwise7
I0928 19:59:17.124388  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.124392  5237 net.cpp:137] Memory required for data: 402349200
I0928 19:59:17.124393  5237 layer_factory.hpp:77] Creating layer penlu15
I0928 19:59:17.124398  5237 net.cpp:84] Creating Layer penlu15
I0928 19:59:17.124400  5237 net.cpp:406] penlu15 <- Eltwise7
I0928 19:59:17.124404  5237 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I0928 19:59:17.124512  5237 net.cpp:122] Setting up penlu15
I0928 19:59:17.124516  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.124518  5237 net.cpp:137] Memory required for data: 407366800
I0928 19:59:17.124523  5237 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I0928 19:59:17.124526  5237 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I0928 19:59:17.124528  5237 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I0928 19:59:17.124531  5237 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I0928 19:59:17.124536  5237 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I0928 19:59:17.124557  5237 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I0928 19:59:17.124560  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.124563  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.124565  5237 net.cpp:137] Memory required for data: 417402000
I0928 19:59:17.124567  5237 layer_factory.hpp:77] Creating layer Convolution16
I0928 19:59:17.124572  5237 net.cpp:84] Creating Layer Convolution16
I0928 19:59:17.124575  5237 net.cpp:406] Convolution16 <- Eltwise7_penlu15_0_split_0
I0928 19:59:17.124580  5237 net.cpp:380] Convolution16 -> Convolution16
I0928 19:59:17.125452  5237 net.cpp:122] Setting up Convolution16
I0928 19:59:17.125460  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.125463  5237 net.cpp:137] Memory required for data: 422419600
I0928 19:59:17.125468  5237 layer_factory.hpp:77] Creating layer BatchNorm16
I0928 19:59:17.125473  5237 net.cpp:84] Creating Layer BatchNorm16
I0928 19:59:17.125475  5237 net.cpp:406] BatchNorm16 <- Convolution16
I0928 19:59:17.125479  5237 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0928 19:59:17.125610  5237 net.cpp:122] Setting up BatchNorm16
I0928 19:59:17.125620  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.125623  5237 net.cpp:137] Memory required for data: 427437200
I0928 19:59:17.125628  5237 layer_factory.hpp:77] Creating layer Scale16
I0928 19:59:17.125633  5237 net.cpp:84] Creating Layer Scale16
I0928 19:59:17.125634  5237 net.cpp:406] Scale16 <- Convolution16
I0928 19:59:17.125638  5237 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0928 19:59:17.125664  5237 layer_factory.hpp:77] Creating layer Scale16
I0928 19:59:17.125741  5237 net.cpp:122] Setting up Scale16
I0928 19:59:17.125746  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.125747  5237 net.cpp:137] Memory required for data: 432454800
I0928 19:59:17.125751  5237 layer_factory.hpp:77] Creating layer penlu16
I0928 19:59:17.125756  5237 net.cpp:84] Creating Layer penlu16
I0928 19:59:17.125758  5237 net.cpp:406] penlu16 <- Convolution16
I0928 19:59:17.125762  5237 net.cpp:367] penlu16 -> Convolution16 (in-place)
I0928 19:59:17.125874  5237 net.cpp:122] Setting up penlu16
I0928 19:59:17.125879  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.125880  5237 net.cpp:137] Memory required for data: 437472400
I0928 19:59:17.125885  5237 layer_factory.hpp:77] Creating layer Convolution17
I0928 19:59:17.125891  5237 net.cpp:84] Creating Layer Convolution17
I0928 19:59:17.125895  5237 net.cpp:406] Convolution17 <- Convolution16
I0928 19:59:17.125898  5237 net.cpp:380] Convolution17 -> Convolution17
I0928 19:59:17.126457  5237 net.cpp:122] Setting up Convolution17
I0928 19:59:17.126464  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.126466  5237 net.cpp:137] Memory required for data: 442490000
I0928 19:59:17.126471  5237 layer_factory.hpp:77] Creating layer BatchNorm17
I0928 19:59:17.126474  5237 net.cpp:84] Creating Layer BatchNorm17
I0928 19:59:17.126477  5237 net.cpp:406] BatchNorm17 <- Convolution17
I0928 19:59:17.126482  5237 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0928 19:59:17.126638  5237 net.cpp:122] Setting up BatchNorm17
I0928 19:59:17.126643  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.126646  5237 net.cpp:137] Memory required for data: 447507600
I0928 19:59:17.126651  5237 layer_factory.hpp:77] Creating layer Scale17
I0928 19:59:17.126654  5237 net.cpp:84] Creating Layer Scale17
I0928 19:59:17.126657  5237 net.cpp:406] Scale17 <- Convolution17
I0928 19:59:17.126660  5237 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0928 19:59:17.126684  5237 layer_factory.hpp:77] Creating layer Scale17
I0928 19:59:17.126760  5237 net.cpp:122] Setting up Scale17
I0928 19:59:17.126765  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.126766  5237 net.cpp:137] Memory required for data: 452525200
I0928 19:59:17.126770  5237 layer_factory.hpp:77] Creating layer Eltwise8
I0928 19:59:17.126773  5237 net.cpp:84] Creating Layer Eltwise8
I0928 19:59:17.126776  5237 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I0928 19:59:17.126778  5237 net.cpp:406] Eltwise8 <- Convolution17
I0928 19:59:17.126782  5237 net.cpp:380] Eltwise8 -> Eltwise8
I0928 19:59:17.126797  5237 net.cpp:122] Setting up Eltwise8
I0928 19:59:17.126801  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.126803  5237 net.cpp:137] Memory required for data: 457542800
I0928 19:59:17.126806  5237 layer_factory.hpp:77] Creating layer penlu17
I0928 19:59:17.126809  5237 net.cpp:84] Creating Layer penlu17
I0928 19:59:17.126811  5237 net.cpp:406] penlu17 <- Eltwise8
I0928 19:59:17.126816  5237 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I0928 19:59:17.126924  5237 net.cpp:122] Setting up penlu17
I0928 19:59:17.126929  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.126930  5237 net.cpp:137] Memory required for data: 462560400
I0928 19:59:17.126935  5237 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I0928 19:59:17.126937  5237 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I0928 19:59:17.126940  5237 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I0928 19:59:17.126950  5237 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I0928 19:59:17.126955  5237 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I0928 19:59:17.126977  5237 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I0928 19:59:17.126981  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.126983  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.126986  5237 net.cpp:137] Memory required for data: 472595600
I0928 19:59:17.126987  5237 layer_factory.hpp:77] Creating layer Convolution18
I0928 19:59:17.126994  5237 net.cpp:84] Creating Layer Convolution18
I0928 19:59:17.126996  5237 net.cpp:406] Convolution18 <- Eltwise8_penlu17_0_split_0
I0928 19:59:17.127001  5237 net.cpp:380] Convolution18 -> Convolution18
I0928 19:59:17.127918  5237 net.cpp:122] Setting up Convolution18
I0928 19:59:17.127928  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.127929  5237 net.cpp:137] Memory required for data: 477613200
I0928 19:59:17.127933  5237 layer_factory.hpp:77] Creating layer BatchNorm18
I0928 19:59:17.127939  5237 net.cpp:84] Creating Layer BatchNorm18
I0928 19:59:17.127941  5237 net.cpp:406] BatchNorm18 <- Convolution18
I0928 19:59:17.127945  5237 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0928 19:59:17.128077  5237 net.cpp:122] Setting up BatchNorm18
I0928 19:59:17.128080  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.128082  5237 net.cpp:137] Memory required for data: 482630800
I0928 19:59:17.128087  5237 layer_factory.hpp:77] Creating layer Scale18
I0928 19:59:17.128090  5237 net.cpp:84] Creating Layer Scale18
I0928 19:59:17.128093  5237 net.cpp:406] Scale18 <- Convolution18
I0928 19:59:17.128098  5237 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0928 19:59:17.128123  5237 layer_factory.hpp:77] Creating layer Scale18
I0928 19:59:17.128201  5237 net.cpp:122] Setting up Scale18
I0928 19:59:17.128206  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.128207  5237 net.cpp:137] Memory required for data: 487648400
I0928 19:59:17.128211  5237 layer_factory.hpp:77] Creating layer penlu18
I0928 19:59:17.128216  5237 net.cpp:84] Creating Layer penlu18
I0928 19:59:17.128219  5237 net.cpp:406] penlu18 <- Convolution18
I0928 19:59:17.128223  5237 net.cpp:367] penlu18 -> Convolution18 (in-place)
I0928 19:59:17.128331  5237 net.cpp:122] Setting up penlu18
I0928 19:59:17.128335  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.128337  5237 net.cpp:137] Memory required for data: 492666000
I0928 19:59:17.128341  5237 layer_factory.hpp:77] Creating layer Convolution19
I0928 19:59:17.128348  5237 net.cpp:84] Creating Layer Convolution19
I0928 19:59:17.128351  5237 net.cpp:406] Convolution19 <- Convolution18
I0928 19:59:17.128355  5237 net.cpp:380] Convolution19 -> Convolution19
I0928 19:59:17.129297  5237 net.cpp:122] Setting up Convolution19
I0928 19:59:17.129308  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.129313  5237 net.cpp:137] Memory required for data: 497683600
I0928 19:59:17.129329  5237 layer_factory.hpp:77] Creating layer BatchNorm19
I0928 19:59:17.129335  5237 net.cpp:84] Creating Layer BatchNorm19
I0928 19:59:17.129340  5237 net.cpp:406] BatchNorm19 <- Convolution19
I0928 19:59:17.129348  5237 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0928 19:59:17.129535  5237 net.cpp:122] Setting up BatchNorm19
I0928 19:59:17.129542  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.129544  5237 net.cpp:137] Memory required for data: 502701200
I0928 19:59:17.129550  5237 layer_factory.hpp:77] Creating layer Scale19
I0928 19:59:17.129554  5237 net.cpp:84] Creating Layer Scale19
I0928 19:59:17.129557  5237 net.cpp:406] Scale19 <- Convolution19
I0928 19:59:17.129561  5237 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0928 19:59:17.129588  5237 layer_factory.hpp:77] Creating layer Scale19
I0928 19:59:17.129667  5237 net.cpp:122] Setting up Scale19
I0928 19:59:17.129672  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.129680  5237 net.cpp:137] Memory required for data: 507718800
I0928 19:59:17.129684  5237 layer_factory.hpp:77] Creating layer Eltwise9
I0928 19:59:17.129689  5237 net.cpp:84] Creating Layer Eltwise9
I0928 19:59:17.129691  5237 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I0928 19:59:17.129694  5237 net.cpp:406] Eltwise9 <- Convolution19
I0928 19:59:17.129698  5237 net.cpp:380] Eltwise9 -> Eltwise9
I0928 19:59:17.129716  5237 net.cpp:122] Setting up Eltwise9
I0928 19:59:17.129719  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.129721  5237 net.cpp:137] Memory required for data: 512736400
I0928 19:59:17.129724  5237 layer_factory.hpp:77] Creating layer penlu19
I0928 19:59:17.129729  5237 net.cpp:84] Creating Layer penlu19
I0928 19:59:17.129730  5237 net.cpp:406] penlu19 <- Eltwise9
I0928 19:59:17.129734  5237 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I0928 19:59:17.129850  5237 net.cpp:122] Setting up penlu19
I0928 19:59:17.129854  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.129856  5237 net.cpp:137] Memory required for data: 517754000
I0928 19:59:17.129861  5237 layer_factory.hpp:77] Creating layer Eltwise9_penlu19_0_split
I0928 19:59:17.129864  5237 net.cpp:84] Creating Layer Eltwise9_penlu19_0_split
I0928 19:59:17.129868  5237 net.cpp:406] Eltwise9_penlu19_0_split <- Eltwise9
I0928 19:59:17.129870  5237 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_0
I0928 19:59:17.129874  5237 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_1
I0928 19:59:17.129899  5237 net.cpp:122] Setting up Eltwise9_penlu19_0_split
I0928 19:59:17.129901  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.129904  5237 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0928 19:59:17.129906  5237 net.cpp:137] Memory required for data: 527789200
I0928 19:59:17.129909  5237 layer_factory.hpp:77] Creating layer Convolution20
I0928 19:59:17.129915  5237 net.cpp:84] Creating Layer Convolution20
I0928 19:59:17.129918  5237 net.cpp:406] Convolution20 <- Eltwise9_penlu19_0_split_0
I0928 19:59:17.129922  5237 net.cpp:380] Convolution20 -> Convolution20
I0928 19:59:17.131167  5237 net.cpp:122] Setting up Convolution20
I0928 19:59:17.131176  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.131180  5237 net.cpp:137] Memory required for data: 530298000
I0928 19:59:17.131183  5237 layer_factory.hpp:77] Creating layer BatchNorm20
I0928 19:59:17.131188  5237 net.cpp:84] Creating Layer BatchNorm20
I0928 19:59:17.131191  5237 net.cpp:406] BatchNorm20 <- Convolution20
I0928 19:59:17.131194  5237 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0928 19:59:17.131345  5237 net.cpp:122] Setting up BatchNorm20
I0928 19:59:17.131348  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.131351  5237 net.cpp:137] Memory required for data: 532806800
I0928 19:59:17.131356  5237 layer_factory.hpp:77] Creating layer Scale20
I0928 19:59:17.131359  5237 net.cpp:84] Creating Layer Scale20
I0928 19:59:17.131362  5237 net.cpp:406] Scale20 <- Convolution20
I0928 19:59:17.131366  5237 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0928 19:59:17.131392  5237 layer_factory.hpp:77] Creating layer Scale20
I0928 19:59:17.131469  5237 net.cpp:122] Setting up Scale20
I0928 19:59:17.131474  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.131475  5237 net.cpp:137] Memory required for data: 535315600
I0928 19:59:17.131479  5237 layer_factory.hpp:77] Creating layer Convolution21
I0928 19:59:17.131485  5237 net.cpp:84] Creating Layer Convolution21
I0928 19:59:17.131489  5237 net.cpp:406] Convolution21 <- Eltwise9_penlu19_0_split_1
I0928 19:59:17.131492  5237 net.cpp:380] Convolution21 -> Convolution21
I0928 19:59:17.133090  5237 net.cpp:122] Setting up Convolution21
I0928 19:59:17.133098  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.133101  5237 net.cpp:137] Memory required for data: 537824400
I0928 19:59:17.133106  5237 layer_factory.hpp:77] Creating layer BatchNorm21
I0928 19:59:17.133111  5237 net.cpp:84] Creating Layer BatchNorm21
I0928 19:59:17.133121  5237 net.cpp:406] BatchNorm21 <- Convolution21
I0928 19:59:17.133126  5237 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0928 19:59:17.133265  5237 net.cpp:122] Setting up BatchNorm21
I0928 19:59:17.133270  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.133271  5237 net.cpp:137] Memory required for data: 540333200
I0928 19:59:17.133276  5237 layer_factory.hpp:77] Creating layer Scale21
I0928 19:59:17.133280  5237 net.cpp:84] Creating Layer Scale21
I0928 19:59:17.133282  5237 net.cpp:406] Scale21 <- Convolution21
I0928 19:59:17.133285  5237 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0928 19:59:17.133313  5237 layer_factory.hpp:77] Creating layer Scale21
I0928 19:59:17.133391  5237 net.cpp:122] Setting up Scale21
I0928 19:59:17.133395  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.133397  5237 net.cpp:137] Memory required for data: 542842000
I0928 19:59:17.133401  5237 layer_factory.hpp:77] Creating layer penlu20
I0928 19:59:17.133406  5237 net.cpp:84] Creating Layer penlu20
I0928 19:59:17.133409  5237 net.cpp:406] penlu20 <- Convolution21
I0928 19:59:17.133412  5237 net.cpp:367] penlu20 -> Convolution21 (in-place)
I0928 19:59:17.133522  5237 net.cpp:122] Setting up penlu20
I0928 19:59:17.133527  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.133528  5237 net.cpp:137] Memory required for data: 545350800
I0928 19:59:17.133533  5237 layer_factory.hpp:77] Creating layer Convolution22
I0928 19:59:17.133540  5237 net.cpp:84] Creating Layer Convolution22
I0928 19:59:17.133543  5237 net.cpp:406] Convolution22 <- Convolution21
I0928 19:59:17.133548  5237 net.cpp:380] Convolution22 -> Convolution22
I0928 19:59:17.134624  5237 net.cpp:122] Setting up Convolution22
I0928 19:59:17.134631  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.134634  5237 net.cpp:137] Memory required for data: 547859600
I0928 19:59:17.134639  5237 layer_factory.hpp:77] Creating layer BatchNorm22
I0928 19:59:17.134644  5237 net.cpp:84] Creating Layer BatchNorm22
I0928 19:59:17.134646  5237 net.cpp:406] BatchNorm22 <- Convolution22
I0928 19:59:17.134649  5237 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0928 19:59:17.134781  5237 net.cpp:122] Setting up BatchNorm22
I0928 19:59:17.134785  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.134788  5237 net.cpp:137] Memory required for data: 550368400
I0928 19:59:17.134791  5237 layer_factory.hpp:77] Creating layer Scale22
I0928 19:59:17.134795  5237 net.cpp:84] Creating Layer Scale22
I0928 19:59:17.134798  5237 net.cpp:406] Scale22 <- Convolution22
I0928 19:59:17.134800  5237 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0928 19:59:17.134827  5237 layer_factory.hpp:77] Creating layer Scale22
I0928 19:59:17.134901  5237 net.cpp:122] Setting up Scale22
I0928 19:59:17.134904  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.134907  5237 net.cpp:137] Memory required for data: 552877200
I0928 19:59:17.134910  5237 layer_factory.hpp:77] Creating layer Eltwise10
I0928 19:59:17.134915  5237 net.cpp:84] Creating Layer Eltwise10
I0928 19:59:17.134917  5237 net.cpp:406] Eltwise10 <- Convolution20
I0928 19:59:17.134920  5237 net.cpp:406] Eltwise10 <- Convolution22
I0928 19:59:17.134923  5237 net.cpp:380] Eltwise10 -> Eltwise10
I0928 19:59:17.134938  5237 net.cpp:122] Setting up Eltwise10
I0928 19:59:17.134943  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.134944  5237 net.cpp:137] Memory required for data: 555386000
I0928 19:59:17.134946  5237 layer_factory.hpp:77] Creating layer penlu21
I0928 19:59:17.134951  5237 net.cpp:84] Creating Layer penlu21
I0928 19:59:17.134953  5237 net.cpp:406] penlu21 <- Eltwise10
I0928 19:59:17.134956  5237 net.cpp:367] penlu21 -> Eltwise10 (in-place)
I0928 19:59:17.135061  5237 net.cpp:122] Setting up penlu21
I0928 19:59:17.135066  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.135067  5237 net.cpp:137] Memory required for data: 557894800
I0928 19:59:17.135071  5237 layer_factory.hpp:77] Creating layer Eltwise10_penlu21_0_split
I0928 19:59:17.135082  5237 net.cpp:84] Creating Layer Eltwise10_penlu21_0_split
I0928 19:59:17.135084  5237 net.cpp:406] Eltwise10_penlu21_0_split <- Eltwise10
I0928 19:59:17.135088  5237 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_0
I0928 19:59:17.135092  5237 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_1
I0928 19:59:17.135115  5237 net.cpp:122] Setting up Eltwise10_penlu21_0_split
I0928 19:59:17.135118  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.135121  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.135123  5237 net.cpp:137] Memory required for data: 562912400
I0928 19:59:17.135125  5237 layer_factory.hpp:77] Creating layer Convolution23
I0928 19:59:17.135131  5237 net.cpp:84] Creating Layer Convolution23
I0928 19:59:17.135134  5237 net.cpp:406] Convolution23 <- Eltwise10_penlu21_0_split_0
I0928 19:59:17.135138  5237 net.cpp:380] Convolution23 -> Convolution23
I0928 19:59:17.136461  5237 net.cpp:122] Setting up Convolution23
I0928 19:59:17.136469  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.136472  5237 net.cpp:137] Memory required for data: 565421200
I0928 19:59:17.136476  5237 layer_factory.hpp:77] Creating layer BatchNorm23
I0928 19:59:17.136482  5237 net.cpp:84] Creating Layer BatchNorm23
I0928 19:59:17.136484  5237 net.cpp:406] BatchNorm23 <- Convolution23
I0928 19:59:17.136488  5237 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0928 19:59:17.136624  5237 net.cpp:122] Setting up BatchNorm23
I0928 19:59:17.136628  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.136631  5237 net.cpp:137] Memory required for data: 567930000
I0928 19:59:17.136636  5237 layer_factory.hpp:77] Creating layer Scale23
I0928 19:59:17.136642  5237 net.cpp:84] Creating Layer Scale23
I0928 19:59:17.136644  5237 net.cpp:406] Scale23 <- Convolution23
I0928 19:59:17.136647  5237 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0928 19:59:17.136674  5237 layer_factory.hpp:77] Creating layer Scale23
I0928 19:59:17.136750  5237 net.cpp:122] Setting up Scale23
I0928 19:59:17.136754  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.136756  5237 net.cpp:137] Memory required for data: 570438800
I0928 19:59:17.136760  5237 layer_factory.hpp:77] Creating layer penlu22
I0928 19:59:17.136765  5237 net.cpp:84] Creating Layer penlu22
I0928 19:59:17.136768  5237 net.cpp:406] penlu22 <- Convolution23
I0928 19:59:17.136772  5237 net.cpp:367] penlu22 -> Convolution23 (in-place)
I0928 19:59:17.136878  5237 net.cpp:122] Setting up penlu22
I0928 19:59:17.136881  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.136883  5237 net.cpp:137] Memory required for data: 572947600
I0928 19:59:17.136888  5237 layer_factory.hpp:77] Creating layer Convolution24
I0928 19:59:17.136894  5237 net.cpp:84] Creating Layer Convolution24
I0928 19:59:17.136896  5237 net.cpp:406] Convolution24 <- Convolution23
I0928 19:59:17.136900  5237 net.cpp:380] Convolution24 -> Convolution24
I0928 19:59:17.137928  5237 net.cpp:122] Setting up Convolution24
I0928 19:59:17.137938  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.137939  5237 net.cpp:137] Memory required for data: 575456400
I0928 19:59:17.137943  5237 layer_factory.hpp:77] Creating layer BatchNorm24
I0928 19:59:17.137949  5237 net.cpp:84] Creating Layer BatchNorm24
I0928 19:59:17.137951  5237 net.cpp:406] BatchNorm24 <- Convolution24
I0928 19:59:17.137955  5237 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0928 19:59:17.138088  5237 net.cpp:122] Setting up BatchNorm24
I0928 19:59:17.138092  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.138094  5237 net.cpp:137] Memory required for data: 577965200
I0928 19:59:17.138098  5237 layer_factory.hpp:77] Creating layer Scale24
I0928 19:59:17.138103  5237 net.cpp:84] Creating Layer Scale24
I0928 19:59:17.138105  5237 net.cpp:406] Scale24 <- Convolution24
I0928 19:59:17.138108  5237 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0928 19:59:17.138141  5237 layer_factory.hpp:77] Creating layer Scale24
I0928 19:59:17.138217  5237 net.cpp:122] Setting up Scale24
I0928 19:59:17.138222  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.138223  5237 net.cpp:137] Memory required for data: 580474000
I0928 19:59:17.138227  5237 layer_factory.hpp:77] Creating layer Eltwise11
I0928 19:59:17.138231  5237 net.cpp:84] Creating Layer Eltwise11
I0928 19:59:17.138234  5237 net.cpp:406] Eltwise11 <- Eltwise10_penlu21_0_split_1
I0928 19:59:17.138237  5237 net.cpp:406] Eltwise11 <- Convolution24
I0928 19:59:17.138240  5237 net.cpp:380] Eltwise11 -> Eltwise11
I0928 19:59:17.138257  5237 net.cpp:122] Setting up Eltwise11
I0928 19:59:17.138260  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.138262  5237 net.cpp:137] Memory required for data: 582982800
I0928 19:59:17.138264  5237 layer_factory.hpp:77] Creating layer penlu23
I0928 19:59:17.138270  5237 net.cpp:84] Creating Layer penlu23
I0928 19:59:17.138273  5237 net.cpp:406] penlu23 <- Eltwise11
I0928 19:59:17.138276  5237 net.cpp:367] penlu23 -> Eltwise11 (in-place)
I0928 19:59:17.138383  5237 net.cpp:122] Setting up penlu23
I0928 19:59:17.138387  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.138389  5237 net.cpp:137] Memory required for data: 585491600
I0928 19:59:17.138394  5237 layer_factory.hpp:77] Creating layer Eltwise11_penlu23_0_split
I0928 19:59:17.138397  5237 net.cpp:84] Creating Layer Eltwise11_penlu23_0_split
I0928 19:59:17.138399  5237 net.cpp:406] Eltwise11_penlu23_0_split <- Eltwise11
I0928 19:59:17.138402  5237 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_0
I0928 19:59:17.138407  5237 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_1
I0928 19:59:17.138429  5237 net.cpp:122] Setting up Eltwise11_penlu23_0_split
I0928 19:59:17.138433  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.138435  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.138438  5237 net.cpp:137] Memory required for data: 590509200
I0928 19:59:17.138440  5237 layer_factory.hpp:77] Creating layer Convolution25
I0928 19:59:17.138447  5237 net.cpp:84] Creating Layer Convolution25
I0928 19:59:17.138448  5237 net.cpp:406] Convolution25 <- Eltwise11_penlu23_0_split_0
I0928 19:59:17.138453  5237 net.cpp:380] Convolution25 -> Convolution25
I0928 19:59:17.139508  5237 net.cpp:122] Setting up Convolution25
I0928 19:59:17.139515  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.139518  5237 net.cpp:137] Memory required for data: 593018000
I0928 19:59:17.139523  5237 layer_factory.hpp:77] Creating layer BatchNorm25
I0928 19:59:17.139526  5237 net.cpp:84] Creating Layer BatchNorm25
I0928 19:59:17.139529  5237 net.cpp:406] BatchNorm25 <- Convolution25
I0928 19:59:17.139533  5237 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0928 19:59:17.139678  5237 net.cpp:122] Setting up BatchNorm25
I0928 19:59:17.139683  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.139685  5237 net.cpp:137] Memory required for data: 595526800
I0928 19:59:17.139690  5237 layer_factory.hpp:77] Creating layer Scale25
I0928 19:59:17.139694  5237 net.cpp:84] Creating Layer Scale25
I0928 19:59:17.139696  5237 net.cpp:406] Scale25 <- Convolution25
I0928 19:59:17.139700  5237 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0928 19:59:17.139727  5237 layer_factory.hpp:77] Creating layer Scale25
I0928 19:59:17.139802  5237 net.cpp:122] Setting up Scale25
I0928 19:59:17.139806  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.139807  5237 net.cpp:137] Memory required for data: 598035600
I0928 19:59:17.139811  5237 layer_factory.hpp:77] Creating layer penlu24
I0928 19:59:17.139816  5237 net.cpp:84] Creating Layer penlu24
I0928 19:59:17.139819  5237 net.cpp:406] penlu24 <- Convolution25
I0928 19:59:17.139822  5237 net.cpp:367] penlu24 -> Convolution25 (in-place)
I0928 19:59:17.139927  5237 net.cpp:122] Setting up penlu24
I0928 19:59:17.139931  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.139940  5237 net.cpp:137] Memory required for data: 600544400
I0928 19:59:17.139945  5237 layer_factory.hpp:77] Creating layer Convolution26
I0928 19:59:17.139952  5237 net.cpp:84] Creating Layer Convolution26
I0928 19:59:17.139955  5237 net.cpp:406] Convolution26 <- Convolution25
I0928 19:59:17.139960  5237 net.cpp:380] Convolution26 -> Convolution26
I0928 19:59:17.140981  5237 net.cpp:122] Setting up Convolution26
I0928 19:59:17.140990  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.140993  5237 net.cpp:137] Memory required for data: 603053200
I0928 19:59:17.140997  5237 layer_factory.hpp:77] Creating layer BatchNorm26
I0928 19:59:17.141002  5237 net.cpp:84] Creating Layer BatchNorm26
I0928 19:59:17.141005  5237 net.cpp:406] BatchNorm26 <- Convolution26
I0928 19:59:17.141010  5237 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0928 19:59:17.141144  5237 net.cpp:122] Setting up BatchNorm26
I0928 19:59:17.141149  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.141150  5237 net.cpp:137] Memory required for data: 605562000
I0928 19:59:17.141155  5237 layer_factory.hpp:77] Creating layer Scale26
I0928 19:59:17.141158  5237 net.cpp:84] Creating Layer Scale26
I0928 19:59:17.141161  5237 net.cpp:406] Scale26 <- Convolution26
I0928 19:59:17.141165  5237 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0928 19:59:17.141191  5237 layer_factory.hpp:77] Creating layer Scale26
I0928 19:59:17.141268  5237 net.cpp:122] Setting up Scale26
I0928 19:59:17.141273  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.141274  5237 net.cpp:137] Memory required for data: 608070800
I0928 19:59:17.141278  5237 layer_factory.hpp:77] Creating layer Eltwise12
I0928 19:59:17.141283  5237 net.cpp:84] Creating Layer Eltwise12
I0928 19:59:17.141284  5237 net.cpp:406] Eltwise12 <- Eltwise11_penlu23_0_split_1
I0928 19:59:17.141288  5237 net.cpp:406] Eltwise12 <- Convolution26
I0928 19:59:17.141290  5237 net.cpp:380] Eltwise12 -> Eltwise12
I0928 19:59:17.141306  5237 net.cpp:122] Setting up Eltwise12
I0928 19:59:17.141310  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.141312  5237 net.cpp:137] Memory required for data: 610579600
I0928 19:59:17.141314  5237 layer_factory.hpp:77] Creating layer penlu25
I0928 19:59:17.141319  5237 net.cpp:84] Creating Layer penlu25
I0928 19:59:17.141321  5237 net.cpp:406] penlu25 <- Eltwise12
I0928 19:59:17.141325  5237 net.cpp:367] penlu25 -> Eltwise12 (in-place)
I0928 19:59:17.141434  5237 net.cpp:122] Setting up penlu25
I0928 19:59:17.141438  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.141440  5237 net.cpp:137] Memory required for data: 613088400
I0928 19:59:17.141463  5237 layer_factory.hpp:77] Creating layer Eltwise12_penlu25_0_split
I0928 19:59:17.141474  5237 net.cpp:84] Creating Layer Eltwise12_penlu25_0_split
I0928 19:59:17.141476  5237 net.cpp:406] Eltwise12_penlu25_0_split <- Eltwise12
I0928 19:59:17.141479  5237 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_0
I0928 19:59:17.141489  5237 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_1
I0928 19:59:17.141512  5237 net.cpp:122] Setting up Eltwise12_penlu25_0_split
I0928 19:59:17.141517  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.141520  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.141521  5237 net.cpp:137] Memory required for data: 618106000
I0928 19:59:17.141525  5237 layer_factory.hpp:77] Creating layer Convolution27
I0928 19:59:17.141530  5237 net.cpp:84] Creating Layer Convolution27
I0928 19:59:17.141533  5237 net.cpp:406] Convolution27 <- Eltwise12_penlu25_0_split_0
I0928 19:59:17.141536  5237 net.cpp:380] Convolution27 -> Convolution27
I0928 19:59:17.142242  5237 net.cpp:122] Setting up Convolution27
I0928 19:59:17.142248  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.142251  5237 net.cpp:137] Memory required for data: 620614800
I0928 19:59:17.142256  5237 layer_factory.hpp:77] Creating layer BatchNorm27
I0928 19:59:17.142259  5237 net.cpp:84] Creating Layer BatchNorm27
I0928 19:59:17.142268  5237 net.cpp:406] BatchNorm27 <- Convolution27
I0928 19:59:17.142272  5237 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0928 19:59:17.142408  5237 net.cpp:122] Setting up BatchNorm27
I0928 19:59:17.142412  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.142415  5237 net.cpp:137] Memory required for data: 623123600
I0928 19:59:17.142419  5237 layer_factory.hpp:77] Creating layer Scale27
I0928 19:59:17.142422  5237 net.cpp:84] Creating Layer Scale27
I0928 19:59:17.142426  5237 net.cpp:406] Scale27 <- Convolution27
I0928 19:59:17.142428  5237 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0928 19:59:17.142454  5237 layer_factory.hpp:77] Creating layer Scale27
I0928 19:59:17.142546  5237 net.cpp:122] Setting up Scale27
I0928 19:59:17.142551  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.142554  5237 net.cpp:137] Memory required for data: 625632400
I0928 19:59:17.142566  5237 layer_factory.hpp:77] Creating layer penlu26
I0928 19:59:17.142571  5237 net.cpp:84] Creating Layer penlu26
I0928 19:59:17.142575  5237 net.cpp:406] penlu26 <- Convolution27
I0928 19:59:17.142578  5237 net.cpp:367] penlu26 -> Convolution27 (in-place)
I0928 19:59:17.142688  5237 net.cpp:122] Setting up penlu26
I0928 19:59:17.142693  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.142694  5237 net.cpp:137] Memory required for data: 628141200
I0928 19:59:17.142699  5237 layer_factory.hpp:77] Creating layer Convolution28
I0928 19:59:17.142704  5237 net.cpp:84] Creating Layer Convolution28
I0928 19:59:17.142707  5237 net.cpp:406] Convolution28 <- Convolution27
I0928 19:59:17.142711  5237 net.cpp:380] Convolution28 -> Convolution28
I0928 19:59:17.143726  5237 net.cpp:122] Setting up Convolution28
I0928 19:59:17.143735  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.143738  5237 net.cpp:137] Memory required for data: 630650000
I0928 19:59:17.143743  5237 layer_factory.hpp:77] Creating layer BatchNorm28
I0928 19:59:17.143746  5237 net.cpp:84] Creating Layer BatchNorm28
I0928 19:59:17.143748  5237 net.cpp:406] BatchNorm28 <- Convolution28
I0928 19:59:17.143754  5237 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0928 19:59:17.143889  5237 net.cpp:122] Setting up BatchNorm28
I0928 19:59:17.143893  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.143895  5237 net.cpp:137] Memory required for data: 633158800
I0928 19:59:17.143900  5237 layer_factory.hpp:77] Creating layer Scale28
I0928 19:59:17.143904  5237 net.cpp:84] Creating Layer Scale28
I0928 19:59:17.143906  5237 net.cpp:406] Scale28 <- Convolution28
I0928 19:59:17.143909  5237 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0928 19:59:17.143935  5237 layer_factory.hpp:77] Creating layer Scale28
I0928 19:59:17.144012  5237 net.cpp:122] Setting up Scale28
I0928 19:59:17.144016  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.144018  5237 net.cpp:137] Memory required for data: 635667600
I0928 19:59:17.144022  5237 layer_factory.hpp:77] Creating layer Eltwise13
I0928 19:59:17.144026  5237 net.cpp:84] Creating Layer Eltwise13
I0928 19:59:17.144028  5237 net.cpp:406] Eltwise13 <- Eltwise12_penlu25_0_split_1
I0928 19:59:17.144032  5237 net.cpp:406] Eltwise13 <- Convolution28
I0928 19:59:17.144034  5237 net.cpp:380] Eltwise13 -> Eltwise13
I0928 19:59:17.144050  5237 net.cpp:122] Setting up Eltwise13
I0928 19:59:17.144053  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.144055  5237 net.cpp:137] Memory required for data: 638176400
I0928 19:59:17.144057  5237 layer_factory.hpp:77] Creating layer penlu27
I0928 19:59:17.144063  5237 net.cpp:84] Creating Layer penlu27
I0928 19:59:17.144065  5237 net.cpp:406] penlu27 <- Eltwise13
I0928 19:59:17.144069  5237 net.cpp:367] penlu27 -> Eltwise13 (in-place)
I0928 19:59:17.144177  5237 net.cpp:122] Setting up penlu27
I0928 19:59:17.144181  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.144183  5237 net.cpp:137] Memory required for data: 640685200
I0928 19:59:17.144194  5237 layer_factory.hpp:77] Creating layer Eltwise13_penlu27_0_split
I0928 19:59:17.144198  5237 net.cpp:84] Creating Layer Eltwise13_penlu27_0_split
I0928 19:59:17.144201  5237 net.cpp:406] Eltwise13_penlu27_0_split <- Eltwise13
I0928 19:59:17.144203  5237 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_0
I0928 19:59:17.144207  5237 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_1
I0928 19:59:17.144232  5237 net.cpp:122] Setting up Eltwise13_penlu27_0_split
I0928 19:59:17.144235  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.144238  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.144239  5237 net.cpp:137] Memory required for data: 645702800
I0928 19:59:17.144243  5237 layer_factory.hpp:77] Creating layer Convolution29
I0928 19:59:17.144248  5237 net.cpp:84] Creating Layer Convolution29
I0928 19:59:17.144249  5237 net.cpp:406] Convolution29 <- Eltwise13_penlu27_0_split_0
I0928 19:59:17.144254  5237 net.cpp:380] Convolution29 -> Convolution29
I0928 19:59:17.145274  5237 net.cpp:122] Setting up Convolution29
I0928 19:59:17.145283  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.145287  5237 net.cpp:137] Memory required for data: 648211600
I0928 19:59:17.145290  5237 layer_factory.hpp:77] Creating layer BatchNorm29
I0928 19:59:17.145294  5237 net.cpp:84] Creating Layer BatchNorm29
I0928 19:59:17.145298  5237 net.cpp:406] BatchNorm29 <- Convolution29
I0928 19:59:17.145301  5237 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0928 19:59:17.145437  5237 net.cpp:122] Setting up BatchNorm29
I0928 19:59:17.145440  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.145442  5237 net.cpp:137] Memory required for data: 650720400
I0928 19:59:17.145447  5237 layer_factory.hpp:77] Creating layer Scale29
I0928 19:59:17.145452  5237 net.cpp:84] Creating Layer Scale29
I0928 19:59:17.145453  5237 net.cpp:406] Scale29 <- Convolution29
I0928 19:59:17.145457  5237 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0928 19:59:17.145483  5237 layer_factory.hpp:77] Creating layer Scale29
I0928 19:59:17.145561  5237 net.cpp:122] Setting up Scale29
I0928 19:59:17.145565  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.145567  5237 net.cpp:137] Memory required for data: 653229200
I0928 19:59:17.145571  5237 layer_factory.hpp:77] Creating layer penlu28
I0928 19:59:17.145576  5237 net.cpp:84] Creating Layer penlu28
I0928 19:59:17.145578  5237 net.cpp:406] penlu28 <- Convolution29
I0928 19:59:17.145582  5237 net.cpp:367] penlu28 -> Convolution29 (in-place)
I0928 19:59:17.145690  5237 net.cpp:122] Setting up penlu28
I0928 19:59:17.145695  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.145697  5237 net.cpp:137] Memory required for data: 655738000
I0928 19:59:17.145701  5237 layer_factory.hpp:77] Creating layer Convolution30
I0928 19:59:17.145707  5237 net.cpp:84] Creating Layer Convolution30
I0928 19:59:17.145710  5237 net.cpp:406] Convolution30 <- Convolution29
I0928 19:59:17.145714  5237 net.cpp:380] Convolution30 -> Convolution30
I0928 19:59:17.146742  5237 net.cpp:122] Setting up Convolution30
I0928 19:59:17.146750  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.146754  5237 net.cpp:137] Memory required for data: 658246800
I0928 19:59:17.146757  5237 layer_factory.hpp:77] Creating layer BatchNorm30
I0928 19:59:17.146762  5237 net.cpp:84] Creating Layer BatchNorm30
I0928 19:59:17.146765  5237 net.cpp:406] BatchNorm30 <- Convolution30
I0928 19:59:17.146769  5237 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0928 19:59:17.146901  5237 net.cpp:122] Setting up BatchNorm30
I0928 19:59:17.146905  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.146908  5237 net.cpp:137] Memory required for data: 660755600
I0928 19:59:17.146912  5237 layer_factory.hpp:77] Creating layer Scale30
I0928 19:59:17.146916  5237 net.cpp:84] Creating Layer Scale30
I0928 19:59:17.146919  5237 net.cpp:406] Scale30 <- Convolution30
I0928 19:59:17.146921  5237 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0928 19:59:17.146956  5237 layer_factory.hpp:77] Creating layer Scale30
I0928 19:59:17.147033  5237 net.cpp:122] Setting up Scale30
I0928 19:59:17.147037  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.147039  5237 net.cpp:137] Memory required for data: 663264400
I0928 19:59:17.147043  5237 layer_factory.hpp:77] Creating layer Eltwise14
I0928 19:59:17.147048  5237 net.cpp:84] Creating Layer Eltwise14
I0928 19:59:17.147050  5237 net.cpp:406] Eltwise14 <- Eltwise13_penlu27_0_split_1
I0928 19:59:17.147053  5237 net.cpp:406] Eltwise14 <- Convolution30
I0928 19:59:17.147056  5237 net.cpp:380] Eltwise14 -> Eltwise14
I0928 19:59:17.147073  5237 net.cpp:122] Setting up Eltwise14
I0928 19:59:17.147075  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.147078  5237 net.cpp:137] Memory required for data: 665773200
I0928 19:59:17.147079  5237 layer_factory.hpp:77] Creating layer penlu29
I0928 19:59:17.147085  5237 net.cpp:84] Creating Layer penlu29
I0928 19:59:17.147088  5237 net.cpp:406] penlu29 <- Eltwise14
I0928 19:59:17.147090  5237 net.cpp:367] penlu29 -> Eltwise14 (in-place)
I0928 19:59:17.147197  5237 net.cpp:122] Setting up penlu29
I0928 19:59:17.147202  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.147203  5237 net.cpp:137] Memory required for data: 668282000
I0928 19:59:17.147207  5237 layer_factory.hpp:77] Creating layer Eltwise14_penlu29_0_split
I0928 19:59:17.147210  5237 net.cpp:84] Creating Layer Eltwise14_penlu29_0_split
I0928 19:59:17.147213  5237 net.cpp:406] Eltwise14_penlu29_0_split <- Eltwise14
I0928 19:59:17.147217  5237 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_0
I0928 19:59:17.147222  5237 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_1
I0928 19:59:17.147243  5237 net.cpp:122] Setting up Eltwise14_penlu29_0_split
I0928 19:59:17.147246  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.147249  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.147251  5237 net.cpp:137] Memory required for data: 673299600
I0928 19:59:17.147253  5237 layer_factory.hpp:77] Creating layer Convolution31
I0928 19:59:17.147258  5237 net.cpp:84] Creating Layer Convolution31
I0928 19:59:17.147261  5237 net.cpp:406] Convolution31 <- Eltwise14_penlu29_0_split_0
I0928 19:59:17.147265  5237 net.cpp:380] Convolution31 -> Convolution31
I0928 19:59:17.148291  5237 net.cpp:122] Setting up Convolution31
I0928 19:59:17.148299  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.148301  5237 net.cpp:137] Memory required for data: 675808400
I0928 19:59:17.148306  5237 layer_factory.hpp:77] Creating layer BatchNorm31
I0928 19:59:17.148311  5237 net.cpp:84] Creating Layer BatchNorm31
I0928 19:59:17.148314  5237 net.cpp:406] BatchNorm31 <- Convolution31
I0928 19:59:17.148317  5237 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0928 19:59:17.148454  5237 net.cpp:122] Setting up BatchNorm31
I0928 19:59:17.148458  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.148460  5237 net.cpp:137] Memory required for data: 678317200
I0928 19:59:17.148465  5237 layer_factory.hpp:77] Creating layer Scale31
I0928 19:59:17.148469  5237 net.cpp:84] Creating Layer Scale31
I0928 19:59:17.148471  5237 net.cpp:406] Scale31 <- Convolution31
I0928 19:59:17.148474  5237 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0928 19:59:17.148500  5237 layer_factory.hpp:77] Creating layer Scale31
I0928 19:59:17.148576  5237 net.cpp:122] Setting up Scale31
I0928 19:59:17.148581  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.148582  5237 net.cpp:137] Memory required for data: 680826000
I0928 19:59:17.148586  5237 layer_factory.hpp:77] Creating layer penlu30
I0928 19:59:17.148591  5237 net.cpp:84] Creating Layer penlu30
I0928 19:59:17.148594  5237 net.cpp:406] penlu30 <- Convolution31
I0928 19:59:17.148598  5237 net.cpp:367] penlu30 -> Convolution31 (in-place)
I0928 19:59:17.148706  5237 net.cpp:122] Setting up penlu30
I0928 19:59:17.148711  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.148718  5237 net.cpp:137] Memory required for data: 683334800
I0928 19:59:17.148723  5237 layer_factory.hpp:77] Creating layer Convolution32
I0928 19:59:17.148730  5237 net.cpp:84] Creating Layer Convolution32
I0928 19:59:17.148733  5237 net.cpp:406] Convolution32 <- Convolution31
I0928 19:59:17.148737  5237 net.cpp:380] Convolution32 -> Convolution32
I0928 19:59:17.149767  5237 net.cpp:122] Setting up Convolution32
I0928 19:59:17.149776  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.149778  5237 net.cpp:137] Memory required for data: 685843600
I0928 19:59:17.149783  5237 layer_factory.hpp:77] Creating layer BatchNorm32
I0928 19:59:17.149788  5237 net.cpp:84] Creating Layer BatchNorm32
I0928 19:59:17.149791  5237 net.cpp:406] BatchNorm32 <- Convolution32
I0928 19:59:17.149794  5237 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I0928 19:59:17.149930  5237 net.cpp:122] Setting up BatchNorm32
I0928 19:59:17.149933  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.149935  5237 net.cpp:137] Memory required for data: 688352400
I0928 19:59:17.149940  5237 layer_factory.hpp:77] Creating layer Scale32
I0928 19:59:17.149945  5237 net.cpp:84] Creating Layer Scale32
I0928 19:59:17.149946  5237 net.cpp:406] Scale32 <- Convolution32
I0928 19:59:17.149950  5237 net.cpp:367] Scale32 -> Convolution32 (in-place)
I0928 19:59:17.149976  5237 layer_factory.hpp:77] Creating layer Scale32
I0928 19:59:17.150054  5237 net.cpp:122] Setting up Scale32
I0928 19:59:17.150058  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.150060  5237 net.cpp:137] Memory required for data: 690861200
I0928 19:59:17.150064  5237 layer_factory.hpp:77] Creating layer Eltwise15
I0928 19:59:17.150068  5237 net.cpp:84] Creating Layer Eltwise15
I0928 19:59:17.150071  5237 net.cpp:406] Eltwise15 <- Eltwise14_penlu29_0_split_1
I0928 19:59:17.150074  5237 net.cpp:406] Eltwise15 <- Convolution32
I0928 19:59:17.150077  5237 net.cpp:380] Eltwise15 -> Eltwise15
I0928 19:59:17.150094  5237 net.cpp:122] Setting up Eltwise15
I0928 19:59:17.150097  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.150099  5237 net.cpp:137] Memory required for data: 693370000
I0928 19:59:17.150101  5237 layer_factory.hpp:77] Creating layer penlu31
I0928 19:59:17.150106  5237 net.cpp:84] Creating Layer penlu31
I0928 19:59:17.150108  5237 net.cpp:406] penlu31 <- Eltwise15
I0928 19:59:17.150111  5237 net.cpp:367] penlu31 -> Eltwise15 (in-place)
I0928 19:59:17.150220  5237 net.cpp:122] Setting up penlu31
I0928 19:59:17.150224  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.150226  5237 net.cpp:137] Memory required for data: 695878800
I0928 19:59:17.150230  5237 layer_factory.hpp:77] Creating layer Eltwise15_penlu31_0_split
I0928 19:59:17.150234  5237 net.cpp:84] Creating Layer Eltwise15_penlu31_0_split
I0928 19:59:17.150236  5237 net.cpp:406] Eltwise15_penlu31_0_split <- Eltwise15
I0928 19:59:17.150240  5237 net.cpp:380] Eltwise15_penlu31_0_split -> Eltwise15_penlu31_0_split_0
I0928 19:59:17.150244  5237 net.cpp:380] Eltwise15_penlu31_0_split -> Eltwise15_penlu31_0_split_1
I0928 19:59:17.150266  5237 net.cpp:122] Setting up Eltwise15_penlu31_0_split
I0928 19:59:17.150269  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.150272  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.150274  5237 net.cpp:137] Memory required for data: 700896400
I0928 19:59:17.150276  5237 layer_factory.hpp:77] Creating layer Convolution33
I0928 19:59:17.150283  5237 net.cpp:84] Creating Layer Convolution33
I0928 19:59:17.150286  5237 net.cpp:406] Convolution33 <- Eltwise15_penlu31_0_split_0
I0928 19:59:17.150290  5237 net.cpp:380] Convolution33 -> Convolution33
I0928 19:59:17.151659  5237 net.cpp:122] Setting up Convolution33
I0928 19:59:17.151669  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.151671  5237 net.cpp:137] Memory required for data: 703405200
I0928 19:59:17.151675  5237 layer_factory.hpp:77] Creating layer BatchNorm33
I0928 19:59:17.151686  5237 net.cpp:84] Creating Layer BatchNorm33
I0928 19:59:17.151690  5237 net.cpp:406] BatchNorm33 <- Convolution33
I0928 19:59:17.151693  5237 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I0928 19:59:17.151834  5237 net.cpp:122] Setting up BatchNorm33
I0928 19:59:17.151837  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.151839  5237 net.cpp:137] Memory required for data: 705914000
I0928 19:59:17.151844  5237 layer_factory.hpp:77] Creating layer Scale33
I0928 19:59:17.151849  5237 net.cpp:84] Creating Layer Scale33
I0928 19:59:17.151850  5237 net.cpp:406] Scale33 <- Convolution33
I0928 19:59:17.151854  5237 net.cpp:367] Scale33 -> Convolution33 (in-place)
I0928 19:59:17.151880  5237 layer_factory.hpp:77] Creating layer Scale33
I0928 19:59:17.151958  5237 net.cpp:122] Setting up Scale33
I0928 19:59:17.151962  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.151964  5237 net.cpp:137] Memory required for data: 708422800
I0928 19:59:17.151968  5237 layer_factory.hpp:77] Creating layer penlu32
I0928 19:59:17.151973  5237 net.cpp:84] Creating Layer penlu32
I0928 19:59:17.151975  5237 net.cpp:406] penlu32 <- Convolution33
I0928 19:59:17.151979  5237 net.cpp:367] penlu32 -> Convolution33 (in-place)
I0928 19:59:17.152087  5237 net.cpp:122] Setting up penlu32
I0928 19:59:17.152092  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.152094  5237 net.cpp:137] Memory required for data: 710931600
I0928 19:59:17.152098  5237 layer_factory.hpp:77] Creating layer Convolution34
I0928 19:59:17.152104  5237 net.cpp:84] Creating Layer Convolution34
I0928 19:59:17.152107  5237 net.cpp:406] Convolution34 <- Convolution33
I0928 19:59:17.152110  5237 net.cpp:380] Convolution34 -> Convolution34
I0928 19:59:17.153149  5237 net.cpp:122] Setting up Convolution34
I0928 19:59:17.153158  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.153161  5237 net.cpp:137] Memory required for data: 713440400
I0928 19:59:17.153165  5237 layer_factory.hpp:77] Creating layer BatchNorm34
I0928 19:59:17.153169  5237 net.cpp:84] Creating Layer BatchNorm34
I0928 19:59:17.153172  5237 net.cpp:406] BatchNorm34 <- Convolution34
I0928 19:59:17.153178  5237 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I0928 19:59:17.153316  5237 net.cpp:122] Setting up BatchNorm34
I0928 19:59:17.153321  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.153322  5237 net.cpp:137] Memory required for data: 715949200
I0928 19:59:17.153326  5237 layer_factory.hpp:77] Creating layer Scale34
I0928 19:59:17.153331  5237 net.cpp:84] Creating Layer Scale34
I0928 19:59:17.153332  5237 net.cpp:406] Scale34 <- Convolution34
I0928 19:59:17.153336  5237 net.cpp:367] Scale34 -> Convolution34 (in-place)
I0928 19:59:17.153362  5237 layer_factory.hpp:77] Creating layer Scale34
I0928 19:59:17.153439  5237 net.cpp:122] Setting up Scale34
I0928 19:59:17.153442  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.153445  5237 net.cpp:137] Memory required for data: 718458000
I0928 19:59:17.153448  5237 layer_factory.hpp:77] Creating layer Eltwise16
I0928 19:59:17.153451  5237 net.cpp:84] Creating Layer Eltwise16
I0928 19:59:17.153455  5237 net.cpp:406] Eltwise16 <- Eltwise15_penlu31_0_split_1
I0928 19:59:17.153457  5237 net.cpp:406] Eltwise16 <- Convolution34
I0928 19:59:17.153460  5237 net.cpp:380] Eltwise16 -> Eltwise16
I0928 19:59:17.153476  5237 net.cpp:122] Setting up Eltwise16
I0928 19:59:17.153481  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.153481  5237 net.cpp:137] Memory required for data: 720966800
I0928 19:59:17.153484  5237 layer_factory.hpp:77] Creating layer penlu33
I0928 19:59:17.153489  5237 net.cpp:84] Creating Layer penlu33
I0928 19:59:17.153491  5237 net.cpp:406] penlu33 <- Eltwise16
I0928 19:59:17.153496  5237 net.cpp:367] penlu33 -> Eltwise16 (in-place)
I0928 19:59:17.153604  5237 net.cpp:122] Setting up penlu33
I0928 19:59:17.153609  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.153610  5237 net.cpp:137] Memory required for data: 723475600
I0928 19:59:17.153620  5237 layer_factory.hpp:77] Creating layer Eltwise16_penlu33_0_split
I0928 19:59:17.153625  5237 net.cpp:84] Creating Layer Eltwise16_penlu33_0_split
I0928 19:59:17.153627  5237 net.cpp:406] Eltwise16_penlu33_0_split <- Eltwise16
I0928 19:59:17.153630  5237 net.cpp:380] Eltwise16_penlu33_0_split -> Eltwise16_penlu33_0_split_0
I0928 19:59:17.153635  5237 net.cpp:380] Eltwise16_penlu33_0_split -> Eltwise16_penlu33_0_split_1
I0928 19:59:17.153658  5237 net.cpp:122] Setting up Eltwise16_penlu33_0_split
I0928 19:59:17.153662  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.153664  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.153666  5237 net.cpp:137] Memory required for data: 728493200
I0928 19:59:17.153669  5237 layer_factory.hpp:77] Creating layer Convolution35
I0928 19:59:17.153674  5237 net.cpp:84] Creating Layer Convolution35
I0928 19:59:17.153676  5237 net.cpp:406] Convolution35 <- Eltwise16_penlu33_0_split_0
I0928 19:59:17.153681  5237 net.cpp:380] Convolution35 -> Convolution35
I0928 19:59:17.154721  5237 net.cpp:122] Setting up Convolution35
I0928 19:59:17.154729  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.154732  5237 net.cpp:137] Memory required for data: 731002000
I0928 19:59:17.154736  5237 layer_factory.hpp:77] Creating layer BatchNorm35
I0928 19:59:17.154741  5237 net.cpp:84] Creating Layer BatchNorm35
I0928 19:59:17.154743  5237 net.cpp:406] BatchNorm35 <- Convolution35
I0928 19:59:17.154748  5237 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I0928 19:59:17.154891  5237 net.cpp:122] Setting up BatchNorm35
I0928 19:59:17.154896  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.154898  5237 net.cpp:137] Memory required for data: 733510800
I0928 19:59:17.154903  5237 layer_factory.hpp:77] Creating layer Scale35
I0928 19:59:17.154906  5237 net.cpp:84] Creating Layer Scale35
I0928 19:59:17.154909  5237 net.cpp:406] Scale35 <- Convolution35
I0928 19:59:17.154912  5237 net.cpp:367] Scale35 -> Convolution35 (in-place)
I0928 19:59:17.154939  5237 layer_factory.hpp:77] Creating layer Scale35
I0928 19:59:17.155019  5237 net.cpp:122] Setting up Scale35
I0928 19:59:17.155025  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.155025  5237 net.cpp:137] Memory required for data: 736019600
I0928 19:59:17.155030  5237 layer_factory.hpp:77] Creating layer penlu34
I0928 19:59:17.155035  5237 net.cpp:84] Creating Layer penlu34
I0928 19:59:17.155036  5237 net.cpp:406] penlu34 <- Convolution35
I0928 19:59:17.155040  5237 net.cpp:367] penlu34 -> Convolution35 (in-place)
I0928 19:59:17.155149  5237 net.cpp:122] Setting up penlu34
I0928 19:59:17.155153  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.155155  5237 net.cpp:137] Memory required for data: 738528400
I0928 19:59:17.155160  5237 layer_factory.hpp:77] Creating layer Convolution36
I0928 19:59:17.155166  5237 net.cpp:84] Creating Layer Convolution36
I0928 19:59:17.155169  5237 net.cpp:406] Convolution36 <- Convolution35
I0928 19:59:17.155174  5237 net.cpp:380] Convolution36 -> Convolution36
I0928 19:59:17.156213  5237 net.cpp:122] Setting up Convolution36
I0928 19:59:17.156222  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.156224  5237 net.cpp:137] Memory required for data: 741037200
I0928 19:59:17.156229  5237 layer_factory.hpp:77] Creating layer BatchNorm36
I0928 19:59:17.156234  5237 net.cpp:84] Creating Layer BatchNorm36
I0928 19:59:17.156236  5237 net.cpp:406] BatchNorm36 <- Convolution36
I0928 19:59:17.156240  5237 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I0928 19:59:17.156376  5237 net.cpp:122] Setting up BatchNorm36
I0928 19:59:17.156380  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.156383  5237 net.cpp:137] Memory required for data: 743546000
I0928 19:59:17.156388  5237 layer_factory.hpp:77] Creating layer Scale36
I0928 19:59:17.156391  5237 net.cpp:84] Creating Layer Scale36
I0928 19:59:17.156394  5237 net.cpp:406] Scale36 <- Convolution36
I0928 19:59:17.156396  5237 net.cpp:367] Scale36 -> Convolution36 (in-place)
I0928 19:59:17.156432  5237 layer_factory.hpp:77] Creating layer Scale36
I0928 19:59:17.156510  5237 net.cpp:122] Setting up Scale36
I0928 19:59:17.156514  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.156517  5237 net.cpp:137] Memory required for data: 746054800
I0928 19:59:17.156520  5237 layer_factory.hpp:77] Creating layer Eltwise17
I0928 19:59:17.156524  5237 net.cpp:84] Creating Layer Eltwise17
I0928 19:59:17.156527  5237 net.cpp:406] Eltwise17 <- Eltwise16_penlu33_0_split_1
I0928 19:59:17.156530  5237 net.cpp:406] Eltwise17 <- Convolution36
I0928 19:59:17.156533  5237 net.cpp:380] Eltwise17 -> Eltwise17
I0928 19:59:17.156550  5237 net.cpp:122] Setting up Eltwise17
I0928 19:59:17.156554  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.156556  5237 net.cpp:137] Memory required for data: 748563600
I0928 19:59:17.156558  5237 layer_factory.hpp:77] Creating layer penlu35
I0928 19:59:17.156563  5237 net.cpp:84] Creating Layer penlu35
I0928 19:59:17.156565  5237 net.cpp:406] penlu35 <- Eltwise17
I0928 19:59:17.156569  5237 net.cpp:367] penlu35 -> Eltwise17 (in-place)
I0928 19:59:17.156677  5237 net.cpp:122] Setting up penlu35
I0928 19:59:17.156682  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.156683  5237 net.cpp:137] Memory required for data: 751072400
I0928 19:59:17.156688  5237 layer_factory.hpp:77] Creating layer Eltwise17_penlu35_0_split
I0928 19:59:17.156692  5237 net.cpp:84] Creating Layer Eltwise17_penlu35_0_split
I0928 19:59:17.156694  5237 net.cpp:406] Eltwise17_penlu35_0_split <- Eltwise17
I0928 19:59:17.156697  5237 net.cpp:380] Eltwise17_penlu35_0_split -> Eltwise17_penlu35_0_split_0
I0928 19:59:17.156702  5237 net.cpp:380] Eltwise17_penlu35_0_split -> Eltwise17_penlu35_0_split_1
I0928 19:59:17.156723  5237 net.cpp:122] Setting up Eltwise17_penlu35_0_split
I0928 19:59:17.156728  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.156730  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.156733  5237 net.cpp:137] Memory required for data: 756090000
I0928 19:59:17.156734  5237 layer_factory.hpp:77] Creating layer Convolution37
I0928 19:59:17.156740  5237 net.cpp:84] Creating Layer Convolution37
I0928 19:59:17.156743  5237 net.cpp:406] Convolution37 <- Eltwise17_penlu35_0_split_0
I0928 19:59:17.156746  5237 net.cpp:380] Convolution37 -> Convolution37
I0928 19:59:17.157460  5237 net.cpp:122] Setting up Convolution37
I0928 19:59:17.157467  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.157470  5237 net.cpp:137] Memory required for data: 758598800
I0928 19:59:17.157474  5237 layer_factory.hpp:77] Creating layer BatchNorm37
I0928 19:59:17.157480  5237 net.cpp:84] Creating Layer BatchNorm37
I0928 19:59:17.157481  5237 net.cpp:406] BatchNorm37 <- Convolution37
I0928 19:59:17.157485  5237 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I0928 19:59:17.157621  5237 net.cpp:122] Setting up BatchNorm37
I0928 19:59:17.157625  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.157627  5237 net.cpp:137] Memory required for data: 761107600
I0928 19:59:17.157631  5237 layer_factory.hpp:77] Creating layer Scale37
I0928 19:59:17.157636  5237 net.cpp:84] Creating Layer Scale37
I0928 19:59:17.157639  5237 net.cpp:406] Scale37 <- Convolution37
I0928 19:59:17.157641  5237 net.cpp:367] Scale37 -> Convolution37 (in-place)
I0928 19:59:17.157667  5237 layer_factory.hpp:77] Creating layer Scale37
I0928 19:59:17.157744  5237 net.cpp:122] Setting up Scale37
I0928 19:59:17.157748  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.157750  5237 net.cpp:137] Memory required for data: 763616400
I0928 19:59:17.157753  5237 layer_factory.hpp:77] Creating layer penlu36
I0928 19:59:17.157759  5237 net.cpp:84] Creating Layer penlu36
I0928 19:59:17.157762  5237 net.cpp:406] penlu36 <- Convolution37
I0928 19:59:17.157765  5237 net.cpp:367] penlu36 -> Convolution37 (in-place)
I0928 19:59:17.157872  5237 net.cpp:122] Setting up penlu36
I0928 19:59:17.157876  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.157886  5237 net.cpp:137] Memory required for data: 766125200
I0928 19:59:17.157891  5237 layer_factory.hpp:77] Creating layer Convolution38
I0928 19:59:17.157896  5237 net.cpp:84] Creating Layer Convolution38
I0928 19:59:17.157899  5237 net.cpp:406] Convolution38 <- Convolution37
I0928 19:59:17.157902  5237 net.cpp:380] Convolution38 -> Convolution38
I0928 19:59:17.158953  5237 net.cpp:122] Setting up Convolution38
I0928 19:59:17.158962  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.158964  5237 net.cpp:137] Memory required for data: 768634000
I0928 19:59:17.158969  5237 layer_factory.hpp:77] Creating layer BatchNorm38
I0928 19:59:17.158973  5237 net.cpp:84] Creating Layer BatchNorm38
I0928 19:59:17.158975  5237 net.cpp:406] BatchNorm38 <- Convolution38
I0928 19:59:17.158980  5237 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I0928 19:59:17.159119  5237 net.cpp:122] Setting up BatchNorm38
I0928 19:59:17.159124  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.159126  5237 net.cpp:137] Memory required for data: 771142800
I0928 19:59:17.159132  5237 layer_factory.hpp:77] Creating layer Scale38
I0928 19:59:17.159134  5237 net.cpp:84] Creating Layer Scale38
I0928 19:59:17.159137  5237 net.cpp:406] Scale38 <- Convolution38
I0928 19:59:17.159140  5237 net.cpp:367] Scale38 -> Convolution38 (in-place)
I0928 19:59:17.159168  5237 layer_factory.hpp:77] Creating layer Scale38
I0928 19:59:17.159245  5237 net.cpp:122] Setting up Scale38
I0928 19:59:17.159250  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.159251  5237 net.cpp:137] Memory required for data: 773651600
I0928 19:59:17.159255  5237 layer_factory.hpp:77] Creating layer Eltwise18
I0928 19:59:17.159258  5237 net.cpp:84] Creating Layer Eltwise18
I0928 19:59:17.159261  5237 net.cpp:406] Eltwise18 <- Eltwise17_penlu35_0_split_1
I0928 19:59:17.159263  5237 net.cpp:406] Eltwise18 <- Convolution38
I0928 19:59:17.159267  5237 net.cpp:380] Eltwise18 -> Eltwise18
I0928 19:59:17.159282  5237 net.cpp:122] Setting up Eltwise18
I0928 19:59:17.159286  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.159288  5237 net.cpp:137] Memory required for data: 776160400
I0928 19:59:17.159291  5237 layer_factory.hpp:77] Creating layer penlu37
I0928 19:59:17.159296  5237 net.cpp:84] Creating Layer penlu37
I0928 19:59:17.159297  5237 net.cpp:406] penlu37 <- Eltwise18
I0928 19:59:17.159301  5237 net.cpp:367] penlu37 -> Eltwise18 (in-place)
I0928 19:59:17.159411  5237 net.cpp:122] Setting up penlu37
I0928 19:59:17.159415  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.159417  5237 net.cpp:137] Memory required for data: 778669200
I0928 19:59:17.159422  5237 layer_factory.hpp:77] Creating layer Eltwise18_penlu37_0_split
I0928 19:59:17.159425  5237 net.cpp:84] Creating Layer Eltwise18_penlu37_0_split
I0928 19:59:17.159427  5237 net.cpp:406] Eltwise18_penlu37_0_split <- Eltwise18
I0928 19:59:17.159431  5237 net.cpp:380] Eltwise18_penlu37_0_split -> Eltwise18_penlu37_0_split_0
I0928 19:59:17.159435  5237 net.cpp:380] Eltwise18_penlu37_0_split -> Eltwise18_penlu37_0_split_1
I0928 19:59:17.159458  5237 net.cpp:122] Setting up Eltwise18_penlu37_0_split
I0928 19:59:17.159461  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.159464  5237 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0928 19:59:17.159466  5237 net.cpp:137] Memory required for data: 783686800
I0928 19:59:17.159468  5237 layer_factory.hpp:77] Creating layer Convolution39
I0928 19:59:17.159473  5237 net.cpp:84] Creating Layer Convolution39
I0928 19:59:17.159476  5237 net.cpp:406] Convolution39 <- Eltwise18_penlu37_0_split_0
I0928 19:59:17.159481  5237 net.cpp:380] Convolution39 -> Convolution39
I0928 19:59:17.160411  5237 net.cpp:122] Setting up Convolution39
I0928 19:59:17.160429  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.160442  5237 net.cpp:137] Memory required for data: 784941200
I0928 19:59:17.160447  5237 layer_factory.hpp:77] Creating layer BatchNorm39
I0928 19:59:17.160459  5237 net.cpp:84] Creating Layer BatchNorm39
I0928 19:59:17.160461  5237 net.cpp:406] BatchNorm39 <- Convolution39
I0928 19:59:17.160465  5237 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I0928 19:59:17.160620  5237 net.cpp:122] Setting up BatchNorm39
I0928 19:59:17.160625  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.160627  5237 net.cpp:137] Memory required for data: 786195600
I0928 19:59:17.160631  5237 layer_factory.hpp:77] Creating layer Scale39
I0928 19:59:17.160635  5237 net.cpp:84] Creating Layer Scale39
I0928 19:59:17.160639  5237 net.cpp:406] Scale39 <- Convolution39
I0928 19:59:17.160641  5237 net.cpp:367] Scale39 -> Convolution39 (in-place)
I0928 19:59:17.160667  5237 layer_factory.hpp:77] Creating layer Scale39
I0928 19:59:17.160745  5237 net.cpp:122] Setting up Scale39
I0928 19:59:17.160749  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.160751  5237 net.cpp:137] Memory required for data: 787450000
I0928 19:59:17.160755  5237 layer_factory.hpp:77] Creating layer Convolution40
I0928 19:59:17.160761  5237 net.cpp:84] Creating Layer Convolution40
I0928 19:59:17.160764  5237 net.cpp:406] Convolution40 <- Eltwise18_penlu37_0_split_1
I0928 19:59:17.160768  5237 net.cpp:380] Convolution40 -> Convolution40
I0928 19:59:17.163326  5237 net.cpp:122] Setting up Convolution40
I0928 19:59:17.163336  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.163339  5237 net.cpp:137] Memory required for data: 788704400
I0928 19:59:17.163344  5237 layer_factory.hpp:77] Creating layer BatchNorm40
I0928 19:59:17.163349  5237 net.cpp:84] Creating Layer BatchNorm40
I0928 19:59:17.163352  5237 net.cpp:406] BatchNorm40 <- Convolution40
I0928 19:59:17.163357  5237 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I0928 19:59:17.163494  5237 net.cpp:122] Setting up BatchNorm40
I0928 19:59:17.163498  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.163501  5237 net.cpp:137] Memory required for data: 789958800
I0928 19:59:17.163506  5237 layer_factory.hpp:77] Creating layer Scale40
I0928 19:59:17.163509  5237 net.cpp:84] Creating Layer Scale40
I0928 19:59:17.163511  5237 net.cpp:406] Scale40 <- Convolution40
I0928 19:59:17.163516  5237 net.cpp:367] Scale40 -> Convolution40 (in-place)
I0928 19:59:17.163542  5237 layer_factory.hpp:77] Creating layer Scale40
I0928 19:59:17.163619  5237 net.cpp:122] Setting up Scale40
I0928 19:59:17.163624  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.163625  5237 net.cpp:137] Memory required for data: 791213200
I0928 19:59:17.163630  5237 layer_factory.hpp:77] Creating layer penlu38
I0928 19:59:17.163635  5237 net.cpp:84] Creating Layer penlu38
I0928 19:59:17.163637  5237 net.cpp:406] penlu38 <- Convolution40
I0928 19:59:17.163641  5237 net.cpp:367] penlu38 -> Convolution40 (in-place)
I0928 19:59:17.163749  5237 net.cpp:122] Setting up penlu38
I0928 19:59:17.163754  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.163756  5237 net.cpp:137] Memory required for data: 792467600
I0928 19:59:17.163760  5237 layer_factory.hpp:77] Creating layer Convolution41
I0928 19:59:17.163766  5237 net.cpp:84] Creating Layer Convolution41
I0928 19:59:17.163769  5237 net.cpp:406] Convolution41 <- Convolution40
I0928 19:59:17.163774  5237 net.cpp:380] Convolution41 -> Convolution41
I0928 19:59:17.165879  5237 net.cpp:122] Setting up Convolution41
I0928 19:59:17.165889  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.165891  5237 net.cpp:137] Memory required for data: 793722000
I0928 19:59:17.165896  5237 layer_factory.hpp:77] Creating layer BatchNorm41
I0928 19:59:17.165901  5237 net.cpp:84] Creating Layer BatchNorm41
I0928 19:59:17.165904  5237 net.cpp:406] BatchNorm41 <- Convolution41
I0928 19:59:17.165908  5237 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I0928 19:59:17.166052  5237 net.cpp:122] Setting up BatchNorm41
I0928 19:59:17.166057  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.166059  5237 net.cpp:137] Memory required for data: 794976400
I0928 19:59:17.166071  5237 layer_factory.hpp:77] Creating layer Scale41
I0928 19:59:17.166077  5237 net.cpp:84] Creating Layer Scale41
I0928 19:59:17.166079  5237 net.cpp:406] Scale41 <- Convolution41
I0928 19:59:17.166083  5237 net.cpp:367] Scale41 -> Convolution41 (in-place)
I0928 19:59:17.166112  5237 layer_factory.hpp:77] Creating layer Scale41
I0928 19:59:17.166195  5237 net.cpp:122] Setting up Scale41
I0928 19:59:17.166200  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.166203  5237 net.cpp:137] Memory required for data: 796230800
I0928 19:59:17.166206  5237 layer_factory.hpp:77] Creating layer Eltwise19
I0928 19:59:17.166211  5237 net.cpp:84] Creating Layer Eltwise19
I0928 19:59:17.166214  5237 net.cpp:406] Eltwise19 <- Convolution39
I0928 19:59:17.166218  5237 net.cpp:406] Eltwise19 <- Convolution41
I0928 19:59:17.166221  5237 net.cpp:380] Eltwise19 -> Eltwise19
I0928 19:59:17.166239  5237 net.cpp:122] Setting up Eltwise19
I0928 19:59:17.166242  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.166244  5237 net.cpp:137] Memory required for data: 797485200
I0928 19:59:17.166246  5237 layer_factory.hpp:77] Creating layer penlu39
I0928 19:59:17.166252  5237 net.cpp:84] Creating Layer penlu39
I0928 19:59:17.166254  5237 net.cpp:406] penlu39 <- Eltwise19
I0928 19:59:17.166257  5237 net.cpp:367] penlu39 -> Eltwise19 (in-place)
I0928 19:59:17.166371  5237 net.cpp:122] Setting up penlu39
I0928 19:59:17.166375  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.166378  5237 net.cpp:137] Memory required for data: 798739600
I0928 19:59:17.166383  5237 layer_factory.hpp:77] Creating layer Eltwise19_penlu39_0_split
I0928 19:59:17.166385  5237 net.cpp:84] Creating Layer Eltwise19_penlu39_0_split
I0928 19:59:17.166388  5237 net.cpp:406] Eltwise19_penlu39_0_split <- Eltwise19
I0928 19:59:17.166393  5237 net.cpp:380] Eltwise19_penlu39_0_split -> Eltwise19_penlu39_0_split_0
I0928 19:59:17.166396  5237 net.cpp:380] Eltwise19_penlu39_0_split -> Eltwise19_penlu39_0_split_1
I0928 19:59:17.166419  5237 net.cpp:122] Setting up Eltwise19_penlu39_0_split
I0928 19:59:17.166422  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.166425  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.166427  5237 net.cpp:137] Memory required for data: 801248400
I0928 19:59:17.166429  5237 layer_factory.hpp:77] Creating layer Convolution42
I0928 19:59:17.166437  5237 net.cpp:84] Creating Layer Convolution42
I0928 19:59:17.166440  5237 net.cpp:406] Convolution42 <- Eltwise19_penlu39_0_split_0
I0928 19:59:17.166443  5237 net.cpp:380] Convolution42 -> Convolution42
I0928 19:59:17.168107  5237 net.cpp:122] Setting up Convolution42
I0928 19:59:17.168117  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.168118  5237 net.cpp:137] Memory required for data: 802502800
I0928 19:59:17.168123  5237 layer_factory.hpp:77] Creating layer BatchNorm42
I0928 19:59:17.168128  5237 net.cpp:84] Creating Layer BatchNorm42
I0928 19:59:17.168130  5237 net.cpp:406] BatchNorm42 <- Convolution42
I0928 19:59:17.168135  5237 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I0928 19:59:17.168272  5237 net.cpp:122] Setting up BatchNorm42
I0928 19:59:17.168277  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.168278  5237 net.cpp:137] Memory required for data: 803757200
I0928 19:59:17.168283  5237 layer_factory.hpp:77] Creating layer Scale42
I0928 19:59:17.168288  5237 net.cpp:84] Creating Layer Scale42
I0928 19:59:17.168290  5237 net.cpp:406] Scale42 <- Convolution42
I0928 19:59:17.168293  5237 net.cpp:367] Scale42 -> Convolution42 (in-place)
I0928 19:59:17.168320  5237 layer_factory.hpp:77] Creating layer Scale42
I0928 19:59:17.168398  5237 net.cpp:122] Setting up Scale42
I0928 19:59:17.168402  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.168404  5237 net.cpp:137] Memory required for data: 805011600
I0928 19:59:17.168408  5237 layer_factory.hpp:77] Creating layer penlu40
I0928 19:59:17.168413  5237 net.cpp:84] Creating Layer penlu40
I0928 19:59:17.168416  5237 net.cpp:406] penlu40 <- Convolution42
I0928 19:59:17.168426  5237 net.cpp:367] penlu40 -> Convolution42 (in-place)
I0928 19:59:17.168539  5237 net.cpp:122] Setting up penlu40
I0928 19:59:17.168542  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.168545  5237 net.cpp:137] Memory required for data: 806266000
I0928 19:59:17.168548  5237 layer_factory.hpp:77] Creating layer Convolution43
I0928 19:59:17.168555  5237 net.cpp:84] Creating Layer Convolution43
I0928 19:59:17.168558  5237 net.cpp:406] Convolution43 <- Convolution42
I0928 19:59:17.168561  5237 net.cpp:380] Convolution43 -> Convolution43
I0928 19:59:17.170811  5237 net.cpp:122] Setting up Convolution43
I0928 19:59:17.170820  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.170824  5237 net.cpp:137] Memory required for data: 807520400
I0928 19:59:17.170828  5237 layer_factory.hpp:77] Creating layer BatchNorm43
I0928 19:59:17.170835  5237 net.cpp:84] Creating Layer BatchNorm43
I0928 19:59:17.170837  5237 net.cpp:406] BatchNorm43 <- Convolution43
I0928 19:59:17.170840  5237 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I0928 19:59:17.170984  5237 net.cpp:122] Setting up BatchNorm43
I0928 19:59:17.170989  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.170991  5237 net.cpp:137] Memory required for data: 808774800
I0928 19:59:17.170996  5237 layer_factory.hpp:77] Creating layer Scale43
I0928 19:59:17.171000  5237 net.cpp:84] Creating Layer Scale43
I0928 19:59:17.171003  5237 net.cpp:406] Scale43 <- Convolution43
I0928 19:59:17.171006  5237 net.cpp:367] Scale43 -> Convolution43 (in-place)
I0928 19:59:17.171034  5237 layer_factory.hpp:77] Creating layer Scale43
I0928 19:59:17.171115  5237 net.cpp:122] Setting up Scale43
I0928 19:59:17.171119  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.171121  5237 net.cpp:137] Memory required for data: 810029200
I0928 19:59:17.171125  5237 layer_factory.hpp:77] Creating layer Eltwise20
I0928 19:59:17.171129  5237 net.cpp:84] Creating Layer Eltwise20
I0928 19:59:17.171133  5237 net.cpp:406] Eltwise20 <- Eltwise19_penlu39_0_split_1
I0928 19:59:17.171135  5237 net.cpp:406] Eltwise20 <- Convolution43
I0928 19:59:17.171139  5237 net.cpp:380] Eltwise20 -> Eltwise20
I0928 19:59:17.171154  5237 net.cpp:122] Setting up Eltwise20
I0928 19:59:17.171157  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.171159  5237 net.cpp:137] Memory required for data: 811283600
I0928 19:59:17.171161  5237 layer_factory.hpp:77] Creating layer penlu41
I0928 19:59:17.171166  5237 net.cpp:84] Creating Layer penlu41
I0928 19:59:17.171169  5237 net.cpp:406] penlu41 <- Eltwise20
I0928 19:59:17.171172  5237 net.cpp:367] penlu41 -> Eltwise20 (in-place)
I0928 19:59:17.171285  5237 net.cpp:122] Setting up penlu41
I0928 19:59:17.171290  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.171293  5237 net.cpp:137] Memory required for data: 812538000
I0928 19:59:17.171296  5237 layer_factory.hpp:77] Creating layer Eltwise20_penlu41_0_split
I0928 19:59:17.171300  5237 net.cpp:84] Creating Layer Eltwise20_penlu41_0_split
I0928 19:59:17.171303  5237 net.cpp:406] Eltwise20_penlu41_0_split <- Eltwise20
I0928 19:59:17.171306  5237 net.cpp:380] Eltwise20_penlu41_0_split -> Eltwise20_penlu41_0_split_0
I0928 19:59:17.171310  5237 net.cpp:380] Eltwise20_penlu41_0_split -> Eltwise20_penlu41_0_split_1
I0928 19:59:17.171334  5237 net.cpp:122] Setting up Eltwise20_penlu41_0_split
I0928 19:59:17.171339  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.171340  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.171342  5237 net.cpp:137] Memory required for data: 815046800
I0928 19:59:17.171345  5237 layer_factory.hpp:77] Creating layer Convolution44
I0928 19:59:17.171350  5237 net.cpp:84] Creating Layer Convolution44
I0928 19:59:17.171352  5237 net.cpp:406] Convolution44 <- Eltwise20_penlu41_0_split_0
I0928 19:59:17.171357  5237 net.cpp:380] Convolution44 -> Convolution44
I0928 19:59:17.173012  5237 net.cpp:122] Setting up Convolution44
I0928 19:59:17.173020  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.173030  5237 net.cpp:137] Memory required for data: 816301200
I0928 19:59:17.173035  5237 layer_factory.hpp:77] Creating layer BatchNorm44
I0928 19:59:17.173040  5237 net.cpp:84] Creating Layer BatchNorm44
I0928 19:59:17.173043  5237 net.cpp:406] BatchNorm44 <- Convolution44
I0928 19:59:17.173048  5237 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I0928 19:59:17.173189  5237 net.cpp:122] Setting up BatchNorm44
I0928 19:59:17.173193  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.173195  5237 net.cpp:137] Memory required for data: 817555600
I0928 19:59:17.173200  5237 layer_factory.hpp:77] Creating layer Scale44
I0928 19:59:17.173204  5237 net.cpp:84] Creating Layer Scale44
I0928 19:59:17.173207  5237 net.cpp:406] Scale44 <- Convolution44
I0928 19:59:17.173209  5237 net.cpp:367] Scale44 -> Convolution44 (in-place)
I0928 19:59:17.173238  5237 layer_factory.hpp:77] Creating layer Scale44
I0928 19:59:17.173317  5237 net.cpp:122] Setting up Scale44
I0928 19:59:17.173322  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.173323  5237 net.cpp:137] Memory required for data: 818810000
I0928 19:59:17.173327  5237 layer_factory.hpp:77] Creating layer penlu42
I0928 19:59:17.173333  5237 net.cpp:84] Creating Layer penlu42
I0928 19:59:17.173336  5237 net.cpp:406] penlu42 <- Convolution44
I0928 19:59:17.173339  5237 net.cpp:367] penlu42 -> Convolution44 (in-place)
I0928 19:59:17.173452  5237 net.cpp:122] Setting up penlu42
I0928 19:59:17.173456  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.173458  5237 net.cpp:137] Memory required for data: 820064400
I0928 19:59:17.173462  5237 layer_factory.hpp:77] Creating layer Convolution45
I0928 19:59:17.173468  5237 net.cpp:84] Creating Layer Convolution45
I0928 19:59:17.173471  5237 net.cpp:406] Convolution45 <- Convolution44
I0928 19:59:17.173475  5237 net.cpp:380] Convolution45 -> Convolution45
I0928 19:59:17.175423  5237 net.cpp:122] Setting up Convolution45
I0928 19:59:17.175431  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.175434  5237 net.cpp:137] Memory required for data: 821318800
I0928 19:59:17.175439  5237 layer_factory.hpp:77] Creating layer BatchNorm45
I0928 19:59:17.175444  5237 net.cpp:84] Creating Layer BatchNorm45
I0928 19:59:17.175447  5237 net.cpp:406] BatchNorm45 <- Convolution45
I0928 19:59:17.175451  5237 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I0928 19:59:17.175595  5237 net.cpp:122] Setting up BatchNorm45
I0928 19:59:17.175599  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.175601  5237 net.cpp:137] Memory required for data: 822573200
I0928 19:59:17.175606  5237 layer_factory.hpp:77] Creating layer Scale45
I0928 19:59:17.175611  5237 net.cpp:84] Creating Layer Scale45
I0928 19:59:17.175613  5237 net.cpp:406] Scale45 <- Convolution45
I0928 19:59:17.175616  5237 net.cpp:367] Scale45 -> Convolution45 (in-place)
I0928 19:59:17.175644  5237 layer_factory.hpp:77] Creating layer Scale45
I0928 19:59:17.175726  5237 net.cpp:122] Setting up Scale45
I0928 19:59:17.175730  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.175734  5237 net.cpp:137] Memory required for data: 823827600
I0928 19:59:17.175736  5237 layer_factory.hpp:77] Creating layer Eltwise21
I0928 19:59:17.175741  5237 net.cpp:84] Creating Layer Eltwise21
I0928 19:59:17.175745  5237 net.cpp:406] Eltwise21 <- Eltwise20_penlu41_0_split_1
I0928 19:59:17.175746  5237 net.cpp:406] Eltwise21 <- Convolution45
I0928 19:59:17.175750  5237 net.cpp:380] Eltwise21 -> Eltwise21
I0928 19:59:17.175766  5237 net.cpp:122] Setting up Eltwise21
I0928 19:59:17.175770  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.175772  5237 net.cpp:137] Memory required for data: 825082000
I0928 19:59:17.175774  5237 layer_factory.hpp:77] Creating layer penlu43
I0928 19:59:17.175779  5237 net.cpp:84] Creating Layer penlu43
I0928 19:59:17.175781  5237 net.cpp:406] penlu43 <- Eltwise21
I0928 19:59:17.175784  5237 net.cpp:367] penlu43 -> Eltwise21 (in-place)
I0928 19:59:17.175907  5237 net.cpp:122] Setting up penlu43
I0928 19:59:17.175912  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.175915  5237 net.cpp:137] Memory required for data: 826336400
I0928 19:59:17.175918  5237 layer_factory.hpp:77] Creating layer Eltwise21_penlu43_0_split
I0928 19:59:17.175922  5237 net.cpp:84] Creating Layer Eltwise21_penlu43_0_split
I0928 19:59:17.175925  5237 net.cpp:406] Eltwise21_penlu43_0_split <- Eltwise21
I0928 19:59:17.175927  5237 net.cpp:380] Eltwise21_penlu43_0_split -> Eltwise21_penlu43_0_split_0
I0928 19:59:17.175932  5237 net.cpp:380] Eltwise21_penlu43_0_split -> Eltwise21_penlu43_0_split_1
I0928 19:59:17.175956  5237 net.cpp:122] Setting up Eltwise21_penlu43_0_split
I0928 19:59:17.175961  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.175963  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.175966  5237 net.cpp:137] Memory required for data: 828845200
I0928 19:59:17.175967  5237 layer_factory.hpp:77] Creating layer Convolution46
I0928 19:59:17.175973  5237 net.cpp:84] Creating Layer Convolution46
I0928 19:59:17.175976  5237 net.cpp:406] Convolution46 <- Eltwise21_penlu43_0_split_0
I0928 19:59:17.175979  5237 net.cpp:380] Convolution46 -> Convolution46
I0928 19:59:17.177629  5237 net.cpp:122] Setting up Convolution46
I0928 19:59:17.177637  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.177639  5237 net.cpp:137] Memory required for data: 830099600
I0928 19:59:17.177644  5237 layer_factory.hpp:77] Creating layer BatchNorm46
I0928 19:59:17.177649  5237 net.cpp:84] Creating Layer BatchNorm46
I0928 19:59:17.177651  5237 net.cpp:406] BatchNorm46 <- Convolution46
I0928 19:59:17.177655  5237 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I0928 19:59:17.177799  5237 net.cpp:122] Setting up BatchNorm46
I0928 19:59:17.177803  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.177805  5237 net.cpp:137] Memory required for data: 831354000
I0928 19:59:17.177810  5237 layer_factory.hpp:77] Creating layer Scale46
I0928 19:59:17.177814  5237 net.cpp:84] Creating Layer Scale46
I0928 19:59:17.177817  5237 net.cpp:406] Scale46 <- Convolution46
I0928 19:59:17.177820  5237 net.cpp:367] Scale46 -> Convolution46 (in-place)
I0928 19:59:17.177848  5237 layer_factory.hpp:77] Creating layer Scale46
I0928 19:59:17.177932  5237 net.cpp:122] Setting up Scale46
I0928 19:59:17.177935  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.177937  5237 net.cpp:137] Memory required for data: 832608400
I0928 19:59:17.177940  5237 layer_factory.hpp:77] Creating layer penlu44
I0928 19:59:17.177945  5237 net.cpp:84] Creating Layer penlu44
I0928 19:59:17.177948  5237 net.cpp:406] penlu44 <- Convolution46
I0928 19:59:17.177953  5237 net.cpp:367] penlu44 -> Convolution46 (in-place)
I0928 19:59:17.178066  5237 net.cpp:122] Setting up penlu44
I0928 19:59:17.178071  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.178072  5237 net.cpp:137] Memory required for data: 833862800
I0928 19:59:17.178076  5237 layer_factory.hpp:77] Creating layer Convolution47
I0928 19:59:17.178082  5237 net.cpp:84] Creating Layer Convolution47
I0928 19:59:17.178086  5237 net.cpp:406] Convolution47 <- Convolution46
I0928 19:59:17.178088  5237 net.cpp:380] Convolution47 -> Convolution47
I0928 19:59:17.179726  5237 net.cpp:122] Setting up Convolution47
I0928 19:59:17.179734  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.179738  5237 net.cpp:137] Memory required for data: 835117200
I0928 19:59:17.179741  5237 layer_factory.hpp:77] Creating layer BatchNorm47
I0928 19:59:17.179747  5237 net.cpp:84] Creating Layer BatchNorm47
I0928 19:59:17.179749  5237 net.cpp:406] BatchNorm47 <- Convolution47
I0928 19:59:17.179754  5237 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I0928 19:59:17.179898  5237 net.cpp:122] Setting up BatchNorm47
I0928 19:59:17.179903  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.179904  5237 net.cpp:137] Memory required for data: 836371600
I0928 19:59:17.179909  5237 layer_factory.hpp:77] Creating layer Scale47
I0928 19:59:17.179920  5237 net.cpp:84] Creating Layer Scale47
I0928 19:59:17.179924  5237 net.cpp:406] Scale47 <- Convolution47
I0928 19:59:17.179926  5237 net.cpp:367] Scale47 -> Convolution47 (in-place)
I0928 19:59:17.179955  5237 layer_factory.hpp:77] Creating layer Scale47
I0928 19:59:17.180038  5237 net.cpp:122] Setting up Scale47
I0928 19:59:17.180043  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.180045  5237 net.cpp:137] Memory required for data: 837626000
I0928 19:59:17.180049  5237 layer_factory.hpp:77] Creating layer Eltwise22
I0928 19:59:17.180053  5237 net.cpp:84] Creating Layer Eltwise22
I0928 19:59:17.180057  5237 net.cpp:406] Eltwise22 <- Eltwise21_penlu43_0_split_1
I0928 19:59:17.180059  5237 net.cpp:406] Eltwise22 <- Convolution47
I0928 19:59:17.180063  5237 net.cpp:380] Eltwise22 -> Eltwise22
I0928 19:59:17.180079  5237 net.cpp:122] Setting up Eltwise22
I0928 19:59:17.180083  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.180084  5237 net.cpp:137] Memory required for data: 838880400
I0928 19:59:17.180086  5237 layer_factory.hpp:77] Creating layer penlu45
I0928 19:59:17.180093  5237 net.cpp:84] Creating Layer penlu45
I0928 19:59:17.180094  5237 net.cpp:406] penlu45 <- Eltwise22
I0928 19:59:17.180097  5237 net.cpp:367] penlu45 -> Eltwise22 (in-place)
I0928 19:59:17.180212  5237 net.cpp:122] Setting up penlu45
I0928 19:59:17.180217  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.180218  5237 net.cpp:137] Memory required for data: 840134800
I0928 19:59:17.180222  5237 layer_factory.hpp:77] Creating layer Eltwise22_penlu45_0_split
I0928 19:59:17.180227  5237 net.cpp:84] Creating Layer Eltwise22_penlu45_0_split
I0928 19:59:17.180228  5237 net.cpp:406] Eltwise22_penlu45_0_split <- Eltwise22
I0928 19:59:17.180233  5237 net.cpp:380] Eltwise22_penlu45_0_split -> Eltwise22_penlu45_0_split_0
I0928 19:59:17.180236  5237 net.cpp:380] Eltwise22_penlu45_0_split -> Eltwise22_penlu45_0_split_1
I0928 19:59:17.180260  5237 net.cpp:122] Setting up Eltwise22_penlu45_0_split
I0928 19:59:17.180263  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.180266  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.180269  5237 net.cpp:137] Memory required for data: 842643600
I0928 19:59:17.180270  5237 layer_factory.hpp:77] Creating layer Convolution48
I0928 19:59:17.180276  5237 net.cpp:84] Creating Layer Convolution48
I0928 19:59:17.180279  5237 net.cpp:406] Convolution48 <- Eltwise22_penlu45_0_split_0
I0928 19:59:17.180284  5237 net.cpp:380] Convolution48 -> Convolution48
I0928 19:59:17.181918  5237 net.cpp:122] Setting up Convolution48
I0928 19:59:17.181926  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.181928  5237 net.cpp:137] Memory required for data: 843898000
I0928 19:59:17.181933  5237 layer_factory.hpp:77] Creating layer BatchNorm48
I0928 19:59:17.181938  5237 net.cpp:84] Creating Layer BatchNorm48
I0928 19:59:17.181941  5237 net.cpp:406] BatchNorm48 <- Convolution48
I0928 19:59:17.181944  5237 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I0928 19:59:17.182088  5237 net.cpp:122] Setting up BatchNorm48
I0928 19:59:17.182092  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.182095  5237 net.cpp:137] Memory required for data: 845152400
I0928 19:59:17.182101  5237 layer_factory.hpp:77] Creating layer Scale48
I0928 19:59:17.182104  5237 net.cpp:84] Creating Layer Scale48
I0928 19:59:17.182106  5237 net.cpp:406] Scale48 <- Convolution48
I0928 19:59:17.182109  5237 net.cpp:367] Scale48 -> Convolution48 (in-place)
I0928 19:59:17.182137  5237 layer_factory.hpp:77] Creating layer Scale48
I0928 19:59:17.182219  5237 net.cpp:122] Setting up Scale48
I0928 19:59:17.182224  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.182225  5237 net.cpp:137] Memory required for data: 846406800
I0928 19:59:17.182229  5237 layer_factory.hpp:77] Creating layer penlu46
I0928 19:59:17.182235  5237 net.cpp:84] Creating Layer penlu46
I0928 19:59:17.182236  5237 net.cpp:406] penlu46 <- Convolution48
I0928 19:59:17.182246  5237 net.cpp:367] penlu46 -> Convolution48 (in-place)
I0928 19:59:17.182363  5237 net.cpp:122] Setting up penlu46
I0928 19:59:17.182368  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.182369  5237 net.cpp:137] Memory required for data: 847661200
I0928 19:59:17.182374  5237 layer_factory.hpp:77] Creating layer Convolution49
I0928 19:59:17.182379  5237 net.cpp:84] Creating Layer Convolution49
I0928 19:59:17.182382  5237 net.cpp:406] Convolution49 <- Convolution48
I0928 19:59:17.182385  5237 net.cpp:380] Convolution49 -> Convolution49
I0928 19:59:17.184339  5237 net.cpp:122] Setting up Convolution49
I0928 19:59:17.184347  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.184350  5237 net.cpp:137] Memory required for data: 848915600
I0928 19:59:17.184355  5237 layer_factory.hpp:77] Creating layer BatchNorm49
I0928 19:59:17.184360  5237 net.cpp:84] Creating Layer BatchNorm49
I0928 19:59:17.184361  5237 net.cpp:406] BatchNorm49 <- Convolution49
I0928 19:59:17.184366  5237 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I0928 19:59:17.184514  5237 net.cpp:122] Setting up BatchNorm49
I0928 19:59:17.184517  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.184520  5237 net.cpp:137] Memory required for data: 850170000
I0928 19:59:17.184525  5237 layer_factory.hpp:77] Creating layer Scale49
I0928 19:59:17.184528  5237 net.cpp:84] Creating Layer Scale49
I0928 19:59:17.184530  5237 net.cpp:406] Scale49 <- Convolution49
I0928 19:59:17.184535  5237 net.cpp:367] Scale49 -> Convolution49 (in-place)
I0928 19:59:17.184561  5237 layer_factory.hpp:77] Creating layer Scale49
I0928 19:59:17.184644  5237 net.cpp:122] Setting up Scale49
I0928 19:59:17.184648  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.184650  5237 net.cpp:137] Memory required for data: 851424400
I0928 19:59:17.184653  5237 layer_factory.hpp:77] Creating layer Eltwise23
I0928 19:59:17.184658  5237 net.cpp:84] Creating Layer Eltwise23
I0928 19:59:17.184660  5237 net.cpp:406] Eltwise23 <- Eltwise22_penlu45_0_split_1
I0928 19:59:17.184662  5237 net.cpp:406] Eltwise23 <- Convolution49
I0928 19:59:17.184666  5237 net.cpp:380] Eltwise23 -> Eltwise23
I0928 19:59:17.184684  5237 net.cpp:122] Setting up Eltwise23
I0928 19:59:17.184687  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.184689  5237 net.cpp:137] Memory required for data: 852678800
I0928 19:59:17.184691  5237 layer_factory.hpp:77] Creating layer penlu47
I0928 19:59:17.184696  5237 net.cpp:84] Creating Layer penlu47
I0928 19:59:17.184698  5237 net.cpp:406] penlu47 <- Eltwise23
I0928 19:59:17.184702  5237 net.cpp:367] penlu47 -> Eltwise23 (in-place)
I0928 19:59:17.184818  5237 net.cpp:122] Setting up penlu47
I0928 19:59:17.184821  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.184823  5237 net.cpp:137] Memory required for data: 853933200
I0928 19:59:17.184828  5237 layer_factory.hpp:77] Creating layer Eltwise23_penlu47_0_split
I0928 19:59:17.184831  5237 net.cpp:84] Creating Layer Eltwise23_penlu47_0_split
I0928 19:59:17.184834  5237 net.cpp:406] Eltwise23_penlu47_0_split <- Eltwise23
I0928 19:59:17.184836  5237 net.cpp:380] Eltwise23_penlu47_0_split -> Eltwise23_penlu47_0_split_0
I0928 19:59:17.184841  5237 net.cpp:380] Eltwise23_penlu47_0_split -> Eltwise23_penlu47_0_split_1
I0928 19:59:17.184865  5237 net.cpp:122] Setting up Eltwise23_penlu47_0_split
I0928 19:59:17.184870  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.184871  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.184873  5237 net.cpp:137] Memory required for data: 856442000
I0928 19:59:17.184876  5237 layer_factory.hpp:77] Creating layer Convolution50
I0928 19:59:17.184881  5237 net.cpp:84] Creating Layer Convolution50
I0928 19:59:17.184885  5237 net.cpp:406] Convolution50 <- Eltwise23_penlu47_0_split_0
I0928 19:59:17.184888  5237 net.cpp:380] Convolution50 -> Convolution50
I0928 19:59:17.186537  5237 net.cpp:122] Setting up Convolution50
I0928 19:59:17.186544  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.186553  5237 net.cpp:137] Memory required for data: 857696400
I0928 19:59:17.186558  5237 layer_factory.hpp:77] Creating layer BatchNorm50
I0928 19:59:17.186563  5237 net.cpp:84] Creating Layer BatchNorm50
I0928 19:59:17.186566  5237 net.cpp:406] BatchNorm50 <- Convolution50
I0928 19:59:17.186569  5237 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I0928 19:59:17.186714  5237 net.cpp:122] Setting up BatchNorm50
I0928 19:59:17.186718  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.186720  5237 net.cpp:137] Memory required for data: 858950800
I0928 19:59:17.186724  5237 layer_factory.hpp:77] Creating layer Scale50
I0928 19:59:17.186729  5237 net.cpp:84] Creating Layer Scale50
I0928 19:59:17.186731  5237 net.cpp:406] Scale50 <- Convolution50
I0928 19:59:17.186734  5237 net.cpp:367] Scale50 -> Convolution50 (in-place)
I0928 19:59:17.186764  5237 layer_factory.hpp:77] Creating layer Scale50
I0928 19:59:17.186848  5237 net.cpp:122] Setting up Scale50
I0928 19:59:17.186852  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.191301  5237 net.cpp:137] Memory required for data: 860205200
I0928 19:59:17.191311  5237 layer_factory.hpp:77] Creating layer penlu48
I0928 19:59:17.191320  5237 net.cpp:84] Creating Layer penlu48
I0928 19:59:17.191323  5237 net.cpp:406] penlu48 <- Convolution50
I0928 19:59:17.191329  5237 net.cpp:367] penlu48 -> Convolution50 (in-place)
I0928 19:59:17.191471  5237 net.cpp:122] Setting up penlu48
I0928 19:59:17.191478  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.191479  5237 net.cpp:137] Memory required for data: 861459600
I0928 19:59:17.191484  5237 layer_factory.hpp:77] Creating layer Convolution51
I0928 19:59:17.191491  5237 net.cpp:84] Creating Layer Convolution51
I0928 19:59:17.191494  5237 net.cpp:406] Convolution51 <- Convolution50
I0928 19:59:17.191499  5237 net.cpp:380] Convolution51 -> Convolution51
I0928 19:59:17.194309  5237 net.cpp:122] Setting up Convolution51
I0928 19:59:17.194319  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.194320  5237 net.cpp:137] Memory required for data: 862714000
I0928 19:59:17.194326  5237 layer_factory.hpp:77] Creating layer BatchNorm51
I0928 19:59:17.194331  5237 net.cpp:84] Creating Layer BatchNorm51
I0928 19:59:17.194334  5237 net.cpp:406] BatchNorm51 <- Convolution51
I0928 19:59:17.194337  5237 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I0928 19:59:17.194489  5237 net.cpp:122] Setting up BatchNorm51
I0928 19:59:17.194494  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.194495  5237 net.cpp:137] Memory required for data: 863968400
I0928 19:59:17.194500  5237 layer_factory.hpp:77] Creating layer Scale51
I0928 19:59:17.194504  5237 net.cpp:84] Creating Layer Scale51
I0928 19:59:17.194506  5237 net.cpp:406] Scale51 <- Convolution51
I0928 19:59:17.194510  5237 net.cpp:367] Scale51 -> Convolution51 (in-place)
I0928 19:59:17.194551  5237 layer_factory.hpp:77] Creating layer Scale51
I0928 19:59:17.194635  5237 net.cpp:122] Setting up Scale51
I0928 19:59:17.194640  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.194643  5237 net.cpp:137] Memory required for data: 865222800
I0928 19:59:17.194646  5237 layer_factory.hpp:77] Creating layer Eltwise24
I0928 19:59:17.194650  5237 net.cpp:84] Creating Layer Eltwise24
I0928 19:59:17.194653  5237 net.cpp:406] Eltwise24 <- Eltwise23_penlu47_0_split_1
I0928 19:59:17.194656  5237 net.cpp:406] Eltwise24 <- Convolution51
I0928 19:59:17.194659  5237 net.cpp:380] Eltwise24 -> Eltwise24
I0928 19:59:17.194676  5237 net.cpp:122] Setting up Eltwise24
I0928 19:59:17.194680  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.194682  5237 net.cpp:137] Memory required for data: 866477200
I0928 19:59:17.194684  5237 layer_factory.hpp:77] Creating layer penlu49
I0928 19:59:17.194690  5237 net.cpp:84] Creating Layer penlu49
I0928 19:59:17.194692  5237 net.cpp:406] penlu49 <- Eltwise24
I0928 19:59:17.194696  5237 net.cpp:367] penlu49 -> Eltwise24 (in-place)
I0928 19:59:17.194815  5237 net.cpp:122] Setting up penlu49
I0928 19:59:17.194826  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.194839  5237 net.cpp:137] Memory required for data: 867731600
I0928 19:59:17.194844  5237 layer_factory.hpp:77] Creating layer Eltwise24_penlu49_0_split
I0928 19:59:17.194847  5237 net.cpp:84] Creating Layer Eltwise24_penlu49_0_split
I0928 19:59:17.194850  5237 net.cpp:406] Eltwise24_penlu49_0_split <- Eltwise24
I0928 19:59:17.194854  5237 net.cpp:380] Eltwise24_penlu49_0_split -> Eltwise24_penlu49_0_split_0
I0928 19:59:17.194859  5237 net.cpp:380] Eltwise24_penlu49_0_split -> Eltwise24_penlu49_0_split_1
I0928 19:59:17.194893  5237 net.cpp:122] Setting up Eltwise24_penlu49_0_split
I0928 19:59:17.194897  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.194900  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.194902  5237 net.cpp:137] Memory required for data: 870240400
I0928 19:59:17.194905  5237 layer_factory.hpp:77] Creating layer Convolution52
I0928 19:59:17.194911  5237 net.cpp:84] Creating Layer Convolution52
I0928 19:59:17.194923  5237 net.cpp:406] Convolution52 <- Eltwise24_penlu49_0_split_0
I0928 19:59:17.194928  5237 net.cpp:380] Convolution52 -> Convolution52
I0928 19:59:17.196780  5237 net.cpp:122] Setting up Convolution52
I0928 19:59:17.196789  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.196792  5237 net.cpp:137] Memory required for data: 871494800
I0928 19:59:17.196796  5237 layer_factory.hpp:77] Creating layer BatchNorm52
I0928 19:59:17.196801  5237 net.cpp:84] Creating Layer BatchNorm52
I0928 19:59:17.196805  5237 net.cpp:406] BatchNorm52 <- Convolution52
I0928 19:59:17.196808  5237 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I0928 19:59:17.196954  5237 net.cpp:122] Setting up BatchNorm52
I0928 19:59:17.196959  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.196961  5237 net.cpp:137] Memory required for data: 872749200
I0928 19:59:17.196965  5237 layer_factory.hpp:77] Creating layer Scale52
I0928 19:59:17.196969  5237 net.cpp:84] Creating Layer Scale52
I0928 19:59:17.196972  5237 net.cpp:406] Scale52 <- Convolution52
I0928 19:59:17.196975  5237 net.cpp:367] Scale52 -> Convolution52 (in-place)
I0928 19:59:17.197005  5237 layer_factory.hpp:77] Creating layer Scale52
I0928 19:59:17.197088  5237 net.cpp:122] Setting up Scale52
I0928 19:59:17.197093  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.197095  5237 net.cpp:137] Memory required for data: 874003600
I0928 19:59:17.197098  5237 layer_factory.hpp:77] Creating layer penlu50
I0928 19:59:17.197103  5237 net.cpp:84] Creating Layer penlu50
I0928 19:59:17.197105  5237 net.cpp:406] penlu50 <- Convolution52
I0928 19:59:17.197109  5237 net.cpp:367] penlu50 -> Convolution52 (in-place)
I0928 19:59:17.197227  5237 net.cpp:122] Setting up penlu50
I0928 19:59:17.197232  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.197234  5237 net.cpp:137] Memory required for data: 875258000
I0928 19:59:17.197278  5237 layer_factory.hpp:77] Creating layer Convolution53
I0928 19:59:17.197299  5237 net.cpp:84] Creating Layer Convolution53
I0928 19:59:17.197301  5237 net.cpp:406] Convolution53 <- Convolution52
I0928 19:59:17.197305  5237 net.cpp:380] Convolution53 -> Convolution53
I0928 19:59:17.199286  5237 net.cpp:122] Setting up Convolution53
I0928 19:59:17.199296  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.199300  5237 net.cpp:137] Memory required for data: 876512400
I0928 19:59:17.199303  5237 layer_factory.hpp:77] Creating layer BatchNorm53
I0928 19:59:17.199308  5237 net.cpp:84] Creating Layer BatchNorm53
I0928 19:59:17.199311  5237 net.cpp:406] BatchNorm53 <- Convolution53
I0928 19:59:17.199316  5237 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I0928 19:59:17.199466  5237 net.cpp:122] Setting up BatchNorm53
I0928 19:59:17.199470  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.199472  5237 net.cpp:137] Memory required for data: 877766800
I0928 19:59:17.199477  5237 layer_factory.hpp:77] Creating layer Scale53
I0928 19:59:17.199481  5237 net.cpp:84] Creating Layer Scale53
I0928 19:59:17.199492  5237 net.cpp:406] Scale53 <- Convolution53
I0928 19:59:17.199496  5237 net.cpp:367] Scale53 -> Convolution53 (in-place)
I0928 19:59:17.199527  5237 layer_factory.hpp:77] Creating layer Scale53
I0928 19:59:17.199610  5237 net.cpp:122] Setting up Scale53
I0928 19:59:17.199615  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.199616  5237 net.cpp:137] Memory required for data: 879021200
I0928 19:59:17.199620  5237 layer_factory.hpp:77] Creating layer Eltwise25
I0928 19:59:17.199625  5237 net.cpp:84] Creating Layer Eltwise25
I0928 19:59:17.199627  5237 net.cpp:406] Eltwise25 <- Eltwise24_penlu49_0_split_1
I0928 19:59:17.199630  5237 net.cpp:406] Eltwise25 <- Convolution53
I0928 19:59:17.199633  5237 net.cpp:380] Eltwise25 -> Eltwise25
I0928 19:59:17.199651  5237 net.cpp:122] Setting up Eltwise25
I0928 19:59:17.199654  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.199656  5237 net.cpp:137] Memory required for data: 880275600
I0928 19:59:17.199659  5237 layer_factory.hpp:77] Creating layer penlu51
I0928 19:59:17.199664  5237 net.cpp:84] Creating Layer penlu51
I0928 19:59:17.199666  5237 net.cpp:406] penlu51 <- Eltwise25
I0928 19:59:17.199671  5237 net.cpp:367] penlu51 -> Eltwise25 (in-place)
I0928 19:59:17.199786  5237 net.cpp:122] Setting up penlu51
I0928 19:59:17.199791  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.199793  5237 net.cpp:137] Memory required for data: 881530000
I0928 19:59:17.199797  5237 layer_factory.hpp:77] Creating layer Eltwise25_penlu51_0_split
I0928 19:59:17.199800  5237 net.cpp:84] Creating Layer Eltwise25_penlu51_0_split
I0928 19:59:17.199802  5237 net.cpp:406] Eltwise25_penlu51_0_split <- Eltwise25
I0928 19:59:17.199806  5237 net.cpp:380] Eltwise25_penlu51_0_split -> Eltwise25_penlu51_0_split_0
I0928 19:59:17.199810  5237 net.cpp:380] Eltwise25_penlu51_0_split -> Eltwise25_penlu51_0_split_1
I0928 19:59:17.199834  5237 net.cpp:122] Setting up Eltwise25_penlu51_0_split
I0928 19:59:17.199838  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.199841  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.199842  5237 net.cpp:137] Memory required for data: 884038800
I0928 19:59:17.199844  5237 layer_factory.hpp:77] Creating layer Convolution54
I0928 19:59:17.199851  5237 net.cpp:84] Creating Layer Convolution54
I0928 19:59:17.199853  5237 net.cpp:406] Convolution54 <- Eltwise25_penlu51_0_split_0
I0928 19:59:17.199857  5237 net.cpp:380] Convolution54 -> Convolution54
I0928 19:59:17.202006  5237 net.cpp:122] Setting up Convolution54
I0928 19:59:17.202015  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.202018  5237 net.cpp:137] Memory required for data: 885293200
I0928 19:59:17.202023  5237 layer_factory.hpp:77] Creating layer BatchNorm54
I0928 19:59:17.202028  5237 net.cpp:84] Creating Layer BatchNorm54
I0928 19:59:17.202031  5237 net.cpp:406] BatchNorm54 <- Convolution54
I0928 19:59:17.202035  5237 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I0928 19:59:17.202183  5237 net.cpp:122] Setting up BatchNorm54
I0928 19:59:17.202186  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.202189  5237 net.cpp:137] Memory required for data: 886547600
I0928 19:59:17.202193  5237 layer_factory.hpp:77] Creating layer Scale54
I0928 19:59:17.202198  5237 net.cpp:84] Creating Layer Scale54
I0928 19:59:17.202200  5237 net.cpp:406] Scale54 <- Convolution54
I0928 19:59:17.202203  5237 net.cpp:367] Scale54 -> Convolution54 (in-place)
I0928 19:59:17.202234  5237 layer_factory.hpp:77] Creating layer Scale54
I0928 19:59:17.202319  5237 net.cpp:122] Setting up Scale54
I0928 19:59:17.202323  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.202325  5237 net.cpp:137] Memory required for data: 887802000
I0928 19:59:17.202329  5237 layer_factory.hpp:77] Creating layer penlu52
I0928 19:59:17.202335  5237 net.cpp:84] Creating Layer penlu52
I0928 19:59:17.202337  5237 net.cpp:406] penlu52 <- Convolution54
I0928 19:59:17.202340  5237 net.cpp:367] penlu52 -> Convolution54 (in-place)
I0928 19:59:17.202466  5237 net.cpp:122] Setting up penlu52
I0928 19:59:17.202471  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.202472  5237 net.cpp:137] Memory required for data: 889056400
I0928 19:59:17.202477  5237 layer_factory.hpp:77] Creating layer Convolution55
I0928 19:59:17.202483  5237 net.cpp:84] Creating Layer Convolution55
I0928 19:59:17.202486  5237 net.cpp:406] Convolution55 <- Convolution54
I0928 19:59:17.202489  5237 net.cpp:380] Convolution55 -> Convolution55
I0928 19:59:17.204464  5237 net.cpp:122] Setting up Convolution55
I0928 19:59:17.204473  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.204476  5237 net.cpp:137] Memory required for data: 890310800
I0928 19:59:17.204480  5237 layer_factory.hpp:77] Creating layer BatchNorm55
I0928 19:59:17.204484  5237 net.cpp:84] Creating Layer BatchNorm55
I0928 19:59:17.204488  5237 net.cpp:406] BatchNorm55 <- Convolution55
I0928 19:59:17.204493  5237 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I0928 19:59:17.204644  5237 net.cpp:122] Setting up BatchNorm55
I0928 19:59:17.204649  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.204651  5237 net.cpp:137] Memory required for data: 891565200
I0928 19:59:17.204656  5237 layer_factory.hpp:77] Creating layer Scale55
I0928 19:59:17.204660  5237 net.cpp:84] Creating Layer Scale55
I0928 19:59:17.204663  5237 net.cpp:406] Scale55 <- Convolution55
I0928 19:59:17.204666  5237 net.cpp:367] Scale55 -> Convolution55 (in-place)
I0928 19:59:17.204694  5237 layer_factory.hpp:77] Creating layer Scale55
I0928 19:59:17.204780  5237 net.cpp:122] Setting up Scale55
I0928 19:59:17.204784  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.204787  5237 net.cpp:137] Memory required for data: 892819600
I0928 19:59:17.204790  5237 layer_factory.hpp:77] Creating layer Eltwise26
I0928 19:59:17.204794  5237 net.cpp:84] Creating Layer Eltwise26
I0928 19:59:17.204797  5237 net.cpp:406] Eltwise26 <- Eltwise25_penlu51_0_split_1
I0928 19:59:17.204799  5237 net.cpp:406] Eltwise26 <- Convolution55
I0928 19:59:17.204803  5237 net.cpp:380] Eltwise26 -> Eltwise26
I0928 19:59:17.204824  5237 net.cpp:122] Setting up Eltwise26
I0928 19:59:17.204830  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.204833  5237 net.cpp:137] Memory required for data: 894074000
I0928 19:59:17.204836  5237 layer_factory.hpp:77] Creating layer penlu53
I0928 19:59:17.204841  5237 net.cpp:84] Creating Layer penlu53
I0928 19:59:17.204843  5237 net.cpp:406] penlu53 <- Eltwise26
I0928 19:59:17.204847  5237 net.cpp:367] penlu53 -> Eltwise26 (in-place)
I0928 19:59:17.204972  5237 net.cpp:122] Setting up penlu53
I0928 19:59:17.204977  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.204978  5237 net.cpp:137] Memory required for data: 895328400
I0928 19:59:17.204982  5237 layer_factory.hpp:77] Creating layer Eltwise26_penlu53_0_split
I0928 19:59:17.204987  5237 net.cpp:84] Creating Layer Eltwise26_penlu53_0_split
I0928 19:59:17.204988  5237 net.cpp:406] Eltwise26_penlu53_0_split <- Eltwise26
I0928 19:59:17.204993  5237 net.cpp:380] Eltwise26_penlu53_0_split -> Eltwise26_penlu53_0_split_0
I0928 19:59:17.204996  5237 net.cpp:380] Eltwise26_penlu53_0_split -> Eltwise26_penlu53_0_split_1
I0928 19:59:17.205021  5237 net.cpp:122] Setting up Eltwise26_penlu53_0_split
I0928 19:59:17.205025  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.205027  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.205029  5237 net.cpp:137] Memory required for data: 897837200
I0928 19:59:17.205031  5237 layer_factory.hpp:77] Creating layer Convolution56
I0928 19:59:17.205037  5237 net.cpp:84] Creating Layer Convolution56
I0928 19:59:17.205040  5237 net.cpp:406] Convolution56 <- Eltwise26_penlu53_0_split_0
I0928 19:59:17.205044  5237 net.cpp:380] Convolution56 -> Convolution56
I0928 19:59:17.206717  5237 net.cpp:122] Setting up Convolution56
I0928 19:59:17.206727  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.206729  5237 net.cpp:137] Memory required for data: 899091600
I0928 19:59:17.206739  5237 layer_factory.hpp:77] Creating layer BatchNorm56
I0928 19:59:17.206745  5237 net.cpp:84] Creating Layer BatchNorm56
I0928 19:59:17.206748  5237 net.cpp:406] BatchNorm56 <- Convolution56
I0928 19:59:17.206753  5237 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I0928 19:59:17.206903  5237 net.cpp:122] Setting up BatchNorm56
I0928 19:59:17.206908  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.206910  5237 net.cpp:137] Memory required for data: 900346000
I0928 19:59:17.206914  5237 layer_factory.hpp:77] Creating layer Scale56
I0928 19:59:17.206919  5237 net.cpp:84] Creating Layer Scale56
I0928 19:59:17.206921  5237 net.cpp:406] Scale56 <- Convolution56
I0928 19:59:17.206924  5237 net.cpp:367] Scale56 -> Convolution56 (in-place)
I0928 19:59:17.206954  5237 layer_factory.hpp:77] Creating layer Scale56
I0928 19:59:17.222200  5237 net.cpp:122] Setting up Scale56
I0928 19:59:17.222209  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.222211  5237 net.cpp:137] Memory required for data: 901600400
I0928 19:59:17.222216  5237 layer_factory.hpp:77] Creating layer penlu54
I0928 19:59:17.222223  5237 net.cpp:84] Creating Layer penlu54
I0928 19:59:17.222226  5237 net.cpp:406] penlu54 <- Convolution56
I0928 19:59:17.222231  5237 net.cpp:367] penlu54 -> Convolution56 (in-place)
I0928 19:59:17.222368  5237 net.cpp:122] Setting up penlu54
I0928 19:59:17.222373  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.222374  5237 net.cpp:137] Memory required for data: 902854800
I0928 19:59:17.222379  5237 layer_factory.hpp:77] Creating layer Convolution57
I0928 19:59:17.222388  5237 net.cpp:84] Creating Layer Convolution57
I0928 19:59:17.222389  5237 net.cpp:406] Convolution57 <- Convolution56
I0928 19:59:17.222394  5237 net.cpp:380] Convolution57 -> Convolution57
I0928 19:59:17.224365  5237 net.cpp:122] Setting up Convolution57
I0928 19:59:17.224375  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.224377  5237 net.cpp:137] Memory required for data: 904109200
I0928 19:59:17.224381  5237 layer_factory.hpp:77] Creating layer BatchNorm57
I0928 19:59:17.224387  5237 net.cpp:84] Creating Layer BatchNorm57
I0928 19:59:17.224390  5237 net.cpp:406] BatchNorm57 <- Convolution57
I0928 19:59:17.224393  5237 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I0928 19:59:17.224550  5237 net.cpp:122] Setting up BatchNorm57
I0928 19:59:17.224555  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.224556  5237 net.cpp:137] Memory required for data: 905363600
I0928 19:59:17.224561  5237 layer_factory.hpp:77] Creating layer Scale57
I0928 19:59:17.224566  5237 net.cpp:84] Creating Layer Scale57
I0928 19:59:17.224568  5237 net.cpp:406] Scale57 <- Convolution57
I0928 19:59:17.224582  5237 net.cpp:367] Scale57 -> Convolution57 (in-place)
I0928 19:59:17.224614  5237 layer_factory.hpp:77] Creating layer Scale57
I0928 19:59:17.224733  5237 net.cpp:122] Setting up Scale57
I0928 19:59:17.224738  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.224740  5237 net.cpp:137] Memory required for data: 906618000
I0928 19:59:17.224753  5237 layer_factory.hpp:77] Creating layer Eltwise27
I0928 19:59:17.224758  5237 net.cpp:84] Creating Layer Eltwise27
I0928 19:59:17.224761  5237 net.cpp:406] Eltwise27 <- Eltwise26_penlu53_0_split_1
I0928 19:59:17.224764  5237 net.cpp:406] Eltwise27 <- Convolution57
I0928 19:59:17.224767  5237 net.cpp:380] Eltwise27 -> Eltwise27
I0928 19:59:17.224795  5237 net.cpp:122] Setting up Eltwise27
I0928 19:59:17.224812  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.224814  5237 net.cpp:137] Memory required for data: 907872400
I0928 19:59:17.224817  5237 layer_factory.hpp:77] Creating layer penlu55
I0928 19:59:17.224830  5237 net.cpp:84] Creating Layer penlu55
I0928 19:59:17.224833  5237 net.cpp:406] penlu55 <- Eltwise27
I0928 19:59:17.224836  5237 net.cpp:367] penlu55 -> Eltwise27 (in-place)
I0928 19:59:17.224956  5237 net.cpp:122] Setting up penlu55
I0928 19:59:17.224959  5237 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0928 19:59:17.224968  5237 net.cpp:137] Memory required for data: 909126800
I0928 19:59:17.224973  5237 layer_factory.hpp:77] Creating layer Pooling1
I0928 19:59:17.224978  5237 net.cpp:84] Creating Layer Pooling1
I0928 19:59:17.224980  5237 net.cpp:406] Pooling1 <- Eltwise27
I0928 19:59:17.224985  5237 net.cpp:380] Pooling1 -> Pooling1
I0928 19:59:17.225455  5237 net.cpp:122] Setting up Pooling1
I0928 19:59:17.225463  5237 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0928 19:59:17.225466  5237 net.cpp:137] Memory required for data: 909152400
I0928 19:59:17.225468  5237 layer_factory.hpp:77] Creating layer InnerProduct1
I0928 19:59:17.225477  5237 net.cpp:84] Creating Layer InnerProduct1
I0928 19:59:17.225481  5237 net.cpp:406] InnerProduct1 <- Pooling1
I0928 19:59:17.225486  5237 net.cpp:380] InnerProduct1 -> InnerProduct1
I0928 19:59:17.225591  5237 net.cpp:122] Setting up InnerProduct1
I0928 19:59:17.225596  5237 net.cpp:129] Top shape: 100 10 (1000)
I0928 19:59:17.225599  5237 net.cpp:137] Memory required for data: 909156400
I0928 19:59:17.225602  5237 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0928 19:59:17.225606  5237 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0928 19:59:17.225608  5237 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I0928 19:59:17.225611  5237 net.cpp:406] SoftmaxWithLoss1 <- Data2
I0928 19:59:17.225616  5237 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0928 19:59:17.225621  5237 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0928 19:59:17.225872  5237 net.cpp:122] Setting up SoftmaxWithLoss1
I0928 19:59:17.225889  5237 net.cpp:129] Top shape: (1)
I0928 19:59:17.225891  5237 net.cpp:132]     with loss weight 1
I0928 19:59:17.225913  5237 net.cpp:137] Memory required for data: 909156404
I0928 19:59:17.225915  5237 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0928 19:59:17.225917  5237 net.cpp:198] InnerProduct1 needs backward computation.
I0928 19:59:17.225919  5237 net.cpp:198] Pooling1 needs backward computation.
I0928 19:59:17.225921  5237 net.cpp:198] penlu55 needs backward computation.
I0928 19:59:17.225924  5237 net.cpp:198] Eltwise27 needs backward computation.
I0928 19:59:17.225926  5237 net.cpp:198] Scale57 needs backward computation.
I0928 19:59:17.225929  5237 net.cpp:198] BatchNorm57 needs backward computation.
I0928 19:59:17.225929  5237 net.cpp:198] Convolution57 needs backward computation.
I0928 19:59:17.225932  5237 net.cpp:198] penlu54 needs backward computation.
I0928 19:59:17.225934  5237 net.cpp:198] Scale56 needs backward computation.
I0928 19:59:17.225935  5237 net.cpp:198] BatchNorm56 needs backward computation.
I0928 19:59:17.225937  5237 net.cpp:198] Convolution56 needs backward computation.
I0928 19:59:17.225939  5237 net.cpp:198] Eltwise26_penlu53_0_split needs backward computation.
I0928 19:59:17.225942  5237 net.cpp:198] penlu53 needs backward computation.
I0928 19:59:17.225944  5237 net.cpp:198] Eltwise26 needs backward computation.
I0928 19:59:17.225949  5237 net.cpp:198] Scale55 needs backward computation.
I0928 19:59:17.225950  5237 net.cpp:198] BatchNorm55 needs backward computation.
I0928 19:59:17.225952  5237 net.cpp:198] Convolution55 needs backward computation.
I0928 19:59:17.225955  5237 net.cpp:198] penlu52 needs backward computation.
I0928 19:59:17.225956  5237 net.cpp:198] Scale54 needs backward computation.
I0928 19:59:17.225958  5237 net.cpp:198] BatchNorm54 needs backward computation.
I0928 19:59:17.225960  5237 net.cpp:198] Convolution54 needs backward computation.
I0928 19:59:17.225962  5237 net.cpp:198] Eltwise25_penlu51_0_split needs backward computation.
I0928 19:59:17.225965  5237 net.cpp:198] penlu51 needs backward computation.
I0928 19:59:17.225966  5237 net.cpp:198] Eltwise25 needs backward computation.
I0928 19:59:17.225970  5237 net.cpp:198] Scale53 needs backward computation.
I0928 19:59:17.225971  5237 net.cpp:198] BatchNorm53 needs backward computation.
I0928 19:59:17.225973  5237 net.cpp:198] Convolution53 needs backward computation.
I0928 19:59:17.225975  5237 net.cpp:198] penlu50 needs backward computation.
I0928 19:59:17.225985  5237 net.cpp:198] Scale52 needs backward computation.
I0928 19:59:17.225986  5237 net.cpp:198] BatchNorm52 needs backward computation.
I0928 19:59:17.225988  5237 net.cpp:198] Convolution52 needs backward computation.
I0928 19:59:17.225991  5237 net.cpp:198] Eltwise24_penlu49_0_split needs backward computation.
I0928 19:59:17.225993  5237 net.cpp:198] penlu49 needs backward computation.
I0928 19:59:17.225996  5237 net.cpp:198] Eltwise24 needs backward computation.
I0928 19:59:17.225997  5237 net.cpp:198] Scale51 needs backward computation.
I0928 19:59:17.225999  5237 net.cpp:198] BatchNorm51 needs backward computation.
I0928 19:59:17.226002  5237 net.cpp:198] Convolution51 needs backward computation.
I0928 19:59:17.226004  5237 net.cpp:198] penlu48 needs backward computation.
I0928 19:59:17.226006  5237 net.cpp:198] Scale50 needs backward computation.
I0928 19:59:17.226008  5237 net.cpp:198] BatchNorm50 needs backward computation.
I0928 19:59:17.226011  5237 net.cpp:198] Convolution50 needs backward computation.
I0928 19:59:17.226013  5237 net.cpp:198] Eltwise23_penlu47_0_split needs backward computation.
I0928 19:59:17.226016  5237 net.cpp:198] penlu47 needs backward computation.
I0928 19:59:17.226017  5237 net.cpp:198] Eltwise23 needs backward computation.
I0928 19:59:17.226020  5237 net.cpp:198] Scale49 needs backward computation.
I0928 19:59:17.226022  5237 net.cpp:198] BatchNorm49 needs backward computation.
I0928 19:59:17.226024  5237 net.cpp:198] Convolution49 needs backward computation.
I0928 19:59:17.226027  5237 net.cpp:198] penlu46 needs backward computation.
I0928 19:59:17.226028  5237 net.cpp:198] Scale48 needs backward computation.
I0928 19:59:17.226030  5237 net.cpp:198] BatchNorm48 needs backward computation.
I0928 19:59:17.226032  5237 net.cpp:198] Convolution48 needs backward computation.
I0928 19:59:17.226035  5237 net.cpp:198] Eltwise22_penlu45_0_split needs backward computation.
I0928 19:59:17.226037  5237 net.cpp:198] penlu45 needs backward computation.
I0928 19:59:17.226039  5237 net.cpp:198] Eltwise22 needs backward computation.
I0928 19:59:17.226042  5237 net.cpp:198] Scale47 needs backward computation.
I0928 19:59:17.226044  5237 net.cpp:198] BatchNorm47 needs backward computation.
I0928 19:59:17.226047  5237 net.cpp:198] Convolution47 needs backward computation.
I0928 19:59:17.226048  5237 net.cpp:198] penlu44 needs backward computation.
I0928 19:59:17.226050  5237 net.cpp:198] Scale46 needs backward computation.
I0928 19:59:17.226052  5237 net.cpp:198] BatchNorm46 needs backward computation.
I0928 19:59:17.226054  5237 net.cpp:198] Convolution46 needs backward computation.
I0928 19:59:17.226058  5237 net.cpp:198] Eltwise21_penlu43_0_split needs backward computation.
I0928 19:59:17.226059  5237 net.cpp:198] penlu43 needs backward computation.
I0928 19:59:17.226061  5237 net.cpp:198] Eltwise21 needs backward computation.
I0928 19:59:17.226063  5237 net.cpp:198] Scale45 needs backward computation.
I0928 19:59:17.226065  5237 net.cpp:198] BatchNorm45 needs backward computation.
I0928 19:59:17.226068  5237 net.cpp:198] Convolution45 needs backward computation.
I0928 19:59:17.226070  5237 net.cpp:198] penlu42 needs backward computation.
I0928 19:59:17.226073  5237 net.cpp:198] Scale44 needs backward computation.
I0928 19:59:17.226084  5237 net.cpp:198] BatchNorm44 needs backward computation.
I0928 19:59:17.226086  5237 net.cpp:198] Convolution44 needs backward computation.
I0928 19:59:17.226089  5237 net.cpp:198] Eltwise20_penlu41_0_split needs backward computation.
I0928 19:59:17.226090  5237 net.cpp:198] penlu41 needs backward computation.
I0928 19:59:17.226094  5237 net.cpp:198] Eltwise20 needs backward computation.
I0928 19:59:17.226105  5237 net.cpp:198] Scale43 needs backward computation.
I0928 19:59:17.226107  5237 net.cpp:198] BatchNorm43 needs backward computation.
I0928 19:59:17.226109  5237 net.cpp:198] Convolution43 needs backward computation.
I0928 19:59:17.226111  5237 net.cpp:198] penlu40 needs backward computation.
I0928 19:59:17.226127  5237 net.cpp:198] Scale42 needs backward computation.
I0928 19:59:17.226130  5237 net.cpp:198] BatchNorm42 needs backward computation.
I0928 19:59:17.226131  5237 net.cpp:198] Convolution42 needs backward computation.
I0928 19:59:17.226143  5237 net.cpp:198] Eltwise19_penlu39_0_split needs backward computation.
I0928 19:59:17.226145  5237 net.cpp:198] penlu39 needs backward computation.
I0928 19:59:17.226148  5237 net.cpp:198] Eltwise19 needs backward computation.
I0928 19:59:17.226150  5237 net.cpp:198] Scale41 needs backward computation.
I0928 19:59:17.226153  5237 net.cpp:198] BatchNorm41 needs backward computation.
I0928 19:59:17.226156  5237 net.cpp:198] Convolution41 needs backward computation.
I0928 19:59:17.226168  5237 net.cpp:198] penlu38 needs backward computation.
I0928 19:59:17.226171  5237 net.cpp:198] Scale40 needs backward computation.
I0928 19:59:17.226173  5237 net.cpp:198] BatchNorm40 needs backward computation.
I0928 19:59:17.226176  5237 net.cpp:198] Convolution40 needs backward computation.
I0928 19:59:17.226186  5237 net.cpp:198] Scale39 needs backward computation.
I0928 19:59:17.226188  5237 net.cpp:198] BatchNorm39 needs backward computation.
I0928 19:59:17.226191  5237 net.cpp:198] Convolution39 needs backward computation.
I0928 19:59:17.226193  5237 net.cpp:198] Eltwise18_penlu37_0_split needs backward computation.
I0928 19:59:17.226208  5237 net.cpp:198] penlu37 needs backward computation.
I0928 19:59:17.226210  5237 net.cpp:198] Eltwise18 needs backward computation.
I0928 19:59:17.226213  5237 net.cpp:198] Scale38 needs backward computation.
I0928 19:59:17.226215  5237 net.cpp:198] BatchNorm38 needs backward computation.
I0928 19:59:17.226227  5237 net.cpp:198] Convolution38 needs backward computation.
I0928 19:59:17.226229  5237 net.cpp:198] penlu36 needs backward computation.
I0928 19:59:17.226231  5237 net.cpp:198] Scale37 needs backward computation.
I0928 19:59:17.226233  5237 net.cpp:198] BatchNorm37 needs backward computation.
I0928 19:59:17.226235  5237 net.cpp:198] Convolution37 needs backward computation.
I0928 19:59:17.226238  5237 net.cpp:198] Eltwise17_penlu35_0_split needs backward computation.
I0928 19:59:17.226240  5237 net.cpp:198] penlu35 needs backward computation.
I0928 19:59:17.226243  5237 net.cpp:198] Eltwise17 needs backward computation.
I0928 19:59:17.226244  5237 net.cpp:198] Scale36 needs backward computation.
I0928 19:59:17.226246  5237 net.cpp:198] BatchNorm36 needs backward computation.
I0928 19:59:17.226249  5237 net.cpp:198] Convolution36 needs backward computation.
I0928 19:59:17.226251  5237 net.cpp:198] penlu34 needs backward computation.
I0928 19:59:17.226253  5237 net.cpp:198] Scale35 needs backward computation.
I0928 19:59:17.226255  5237 net.cpp:198] BatchNorm35 needs backward computation.
I0928 19:59:17.226258  5237 net.cpp:198] Convolution35 needs backward computation.
I0928 19:59:17.226260  5237 net.cpp:198] Eltwise16_penlu33_0_split needs backward computation.
I0928 19:59:17.226263  5237 net.cpp:198] penlu33 needs backward computation.
I0928 19:59:17.226264  5237 net.cpp:198] Eltwise16 needs backward computation.
I0928 19:59:17.226266  5237 net.cpp:198] Scale34 needs backward computation.
I0928 19:59:17.226269  5237 net.cpp:198] BatchNorm34 needs backward computation.
I0928 19:59:17.226271  5237 net.cpp:198] Convolution34 needs backward computation.
I0928 19:59:17.226274  5237 net.cpp:198] penlu32 needs backward computation.
I0928 19:59:17.226275  5237 net.cpp:198] Scale33 needs backward computation.
I0928 19:59:17.226279  5237 net.cpp:198] BatchNorm33 needs backward computation.
I0928 19:59:17.226280  5237 net.cpp:198] Convolution33 needs backward computation.
I0928 19:59:17.226282  5237 net.cpp:198] Eltwise15_penlu31_0_split needs backward computation.
I0928 19:59:17.226284  5237 net.cpp:198] penlu31 needs backward computation.
I0928 19:59:17.226286  5237 net.cpp:198] Eltwise15 needs backward computation.
I0928 19:59:17.226289  5237 net.cpp:198] Scale32 needs backward computation.
I0928 19:59:17.226291  5237 net.cpp:198] BatchNorm32 needs backward computation.
I0928 19:59:17.226296  5237 net.cpp:198] Convolution32 needs backward computation.
I0928 19:59:17.226299  5237 net.cpp:198] penlu30 needs backward computation.
I0928 19:59:17.226301  5237 net.cpp:198] Scale31 needs backward computation.
I0928 19:59:17.226303  5237 net.cpp:198] BatchNorm31 needs backward computation.
I0928 19:59:17.226305  5237 net.cpp:198] Convolution31 needs backward computation.
I0928 19:59:17.226308  5237 net.cpp:198] Eltwise14_penlu29_0_split needs backward computation.
I0928 19:59:17.226310  5237 net.cpp:198] penlu29 needs backward computation.
I0928 19:59:17.226312  5237 net.cpp:198] Eltwise14 needs backward computation.
I0928 19:59:17.226315  5237 net.cpp:198] Scale30 needs backward computation.
I0928 19:59:17.252909  5237 net.cpp:198] BatchNorm30 needs backward computation.
I0928 19:59:17.252916  5237 net.cpp:198] Convolution30 needs backward computation.
I0928 19:59:17.252920  5237 net.cpp:198] penlu28 needs backward computation.
I0928 19:59:17.252923  5237 net.cpp:198] Scale29 needs backward computation.
I0928 19:59:17.252925  5237 net.cpp:198] BatchNorm29 needs backward computation.
I0928 19:59:17.252928  5237 net.cpp:198] Convolution29 needs backward computation.
I0928 19:59:17.252930  5237 net.cpp:198] Eltwise13_penlu27_0_split needs backward computation.
I0928 19:59:17.252933  5237 net.cpp:198] penlu27 needs backward computation.
I0928 19:59:17.252936  5237 net.cpp:198] Eltwise13 needs backward computation.
I0928 19:59:17.252939  5237 net.cpp:198] Scale28 needs backward computation.
I0928 19:59:17.252941  5237 net.cpp:198] BatchNorm28 needs backward computation.
I0928 19:59:17.252944  5237 net.cpp:198] Convolution28 needs backward computation.
I0928 19:59:17.252946  5237 net.cpp:198] penlu26 needs backward computation.
I0928 19:59:17.252949  5237 net.cpp:198] Scale27 needs backward computation.
I0928 19:59:17.252951  5237 net.cpp:198] BatchNorm27 needs backward computation.
I0928 19:59:17.252954  5237 net.cpp:198] Convolution27 needs backward computation.
I0928 19:59:17.252956  5237 net.cpp:198] Eltwise12_penlu25_0_split needs backward computation.
I0928 19:59:17.252959  5237 net.cpp:198] penlu25 needs backward computation.
I0928 19:59:17.252961  5237 net.cpp:198] Eltwise12 needs backward computation.
I0928 19:59:17.252964  5237 net.cpp:198] Scale26 needs backward computation.
I0928 19:59:17.252967  5237 net.cpp:198] BatchNorm26 needs backward computation.
I0928 19:59:17.252969  5237 net.cpp:198] Convolution26 needs backward computation.
I0928 19:59:17.252971  5237 net.cpp:198] penlu24 needs backward computation.
I0928 19:59:17.252974  5237 net.cpp:198] Scale25 needs backward computation.
I0928 19:59:17.252976  5237 net.cpp:198] BatchNorm25 needs backward computation.
I0928 19:59:17.252979  5237 net.cpp:198] Convolution25 needs backward computation.
I0928 19:59:17.252981  5237 net.cpp:198] Eltwise11_penlu23_0_split needs backward computation.
I0928 19:59:17.252985  5237 net.cpp:198] penlu23 needs backward computation.
I0928 19:59:17.252986  5237 net.cpp:198] Eltwise11 needs backward computation.
I0928 19:59:17.252990  5237 net.cpp:198] Scale24 needs backward computation.
I0928 19:59:17.252991  5237 net.cpp:198] BatchNorm24 needs backward computation.
I0928 19:59:17.252995  5237 net.cpp:198] Convolution24 needs backward computation.
I0928 19:59:17.252996  5237 net.cpp:198] penlu22 needs backward computation.
I0928 19:59:17.252998  5237 net.cpp:198] Scale23 needs backward computation.
I0928 19:59:17.253001  5237 net.cpp:198] BatchNorm23 needs backward computation.
I0928 19:59:17.253003  5237 net.cpp:198] Convolution23 needs backward computation.
I0928 19:59:17.253006  5237 net.cpp:198] Eltwise10_penlu21_0_split needs backward computation.
I0928 19:59:17.253008  5237 net.cpp:198] penlu21 needs backward computation.
I0928 19:59:17.253011  5237 net.cpp:198] Eltwise10 needs backward computation.
I0928 19:59:17.253015  5237 net.cpp:198] Scale22 needs backward computation.
I0928 19:59:17.253016  5237 net.cpp:198] BatchNorm22 needs backward computation.
I0928 19:59:17.253026  5237 net.cpp:198] Convolution22 needs backward computation.
I0928 19:59:17.253029  5237 net.cpp:198] penlu20 needs backward computation.
I0928 19:59:17.253032  5237 net.cpp:198] Scale21 needs backward computation.
I0928 19:59:17.253034  5237 net.cpp:198] BatchNorm21 needs backward computation.
I0928 19:59:17.253036  5237 net.cpp:198] Convolution21 needs backward computation.
I0928 19:59:17.253039  5237 net.cpp:198] Scale20 needs backward computation.
I0928 19:59:17.253041  5237 net.cpp:198] BatchNorm20 needs backward computation.
I0928 19:59:17.253044  5237 net.cpp:198] Convolution20 needs backward computation.
I0928 19:59:17.253046  5237 net.cpp:198] Eltwise9_penlu19_0_split needs backward computation.
I0928 19:59:17.253051  5237 net.cpp:198] penlu19 needs backward computation.
I0928 19:59:17.253052  5237 net.cpp:198] Eltwise9 needs backward computation.
I0928 19:59:17.253057  5237 net.cpp:198] Scale19 needs backward computation.
I0928 19:59:17.253060  5237 net.cpp:198] BatchNorm19 needs backward computation.
I0928 19:59:17.253063  5237 net.cpp:198] Convolution19 needs backward computation.
I0928 19:59:17.253067  5237 net.cpp:198] penlu18 needs backward computation.
I0928 19:59:17.253068  5237 net.cpp:198] Scale18 needs backward computation.
I0928 19:59:17.253070  5237 net.cpp:198] BatchNorm18 needs backward computation.
I0928 19:59:17.253073  5237 net.cpp:198] Convolution18 needs backward computation.
I0928 19:59:17.253075  5237 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I0928 19:59:17.253078  5237 net.cpp:198] penlu17 needs backward computation.
I0928 19:59:17.253080  5237 net.cpp:198] Eltwise8 needs backward computation.
I0928 19:59:17.253083  5237 net.cpp:198] Scale17 needs backward computation.
I0928 19:59:17.253087  5237 net.cpp:198] BatchNorm17 needs backward computation.
I0928 19:59:17.253088  5237 net.cpp:198] Convolution17 needs backward computation.
I0928 19:59:17.253090  5237 net.cpp:198] penlu16 needs backward computation.
I0928 19:59:17.253093  5237 net.cpp:198] Scale16 needs backward computation.
I0928 19:59:17.253095  5237 net.cpp:198] BatchNorm16 needs backward computation.
I0928 19:59:17.253098  5237 net.cpp:198] Convolution16 needs backward computation.
I0928 19:59:17.253100  5237 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I0928 19:59:17.253103  5237 net.cpp:198] penlu15 needs backward computation.
I0928 19:59:17.253105  5237 net.cpp:198] Eltwise7 needs backward computation.
I0928 19:59:17.253108  5237 net.cpp:198] Scale15 needs backward computation.
I0928 19:59:17.253110  5237 net.cpp:198] BatchNorm15 needs backward computation.
I0928 19:59:17.253113  5237 net.cpp:198] Convolution15 needs backward computation.
I0928 19:59:17.253115  5237 net.cpp:198] penlu14 needs backward computation.
I0928 19:59:17.253118  5237 net.cpp:198] Scale14 needs backward computation.
I0928 19:59:17.253120  5237 net.cpp:198] BatchNorm14 needs backward computation.
I0928 19:59:17.253123  5237 net.cpp:198] Convolution14 needs backward computation.
I0928 19:59:17.253125  5237 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I0928 19:59:17.253129  5237 net.cpp:198] penlu13 needs backward computation.
I0928 19:59:17.253130  5237 net.cpp:198] Eltwise6 needs backward computation.
I0928 19:59:17.253134  5237 net.cpp:198] Scale13 needs backward computation.
I0928 19:59:17.253135  5237 net.cpp:198] BatchNorm13 needs backward computation.
I0928 19:59:17.253139  5237 net.cpp:198] Convolution13 needs backward computation.
I0928 19:59:17.253140  5237 net.cpp:198] penlu12 needs backward computation.
I0928 19:59:17.253142  5237 net.cpp:198] Scale12 needs backward computation.
I0928 19:59:17.253145  5237 net.cpp:198] BatchNorm12 needs backward computation.
I0928 19:59:17.253147  5237 net.cpp:198] Convolution12 needs backward computation.
I0928 19:59:17.253150  5237 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I0928 19:59:17.253152  5237 net.cpp:198] penlu11 needs backward computation.
I0928 19:59:17.253154  5237 net.cpp:198] Eltwise5 needs backward computation.
I0928 19:59:17.253161  5237 net.cpp:198] Scale11 needs backward computation.
I0928 19:59:17.253165  5237 net.cpp:198] BatchNorm11 needs backward computation.
I0928 19:59:17.253166  5237 net.cpp:198] Convolution11 needs backward computation.
I0928 19:59:17.253170  5237 net.cpp:198] penlu10 needs backward computation.
I0928 19:59:17.253171  5237 net.cpp:198] Scale10 needs backward computation.
I0928 19:59:17.253175  5237 net.cpp:198] BatchNorm10 needs backward computation.
I0928 19:59:17.253176  5237 net.cpp:198] Convolution10 needs backward computation.
I0928 19:59:17.253180  5237 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I0928 19:59:17.255411  5237 net.cpp:198] penlu9 needs backward computation.
I0928 19:59:17.255419  5237 net.cpp:198] Eltwise4 needs backward computation.
I0928 19:59:17.255422  5237 net.cpp:198] Scale9 needs backward computation.
I0928 19:59:17.255425  5237 net.cpp:198] BatchNorm9 needs backward computation.
I0928 19:59:17.255427  5237 net.cpp:198] Convolution9 needs backward computation.
I0928 19:59:17.255430  5237 net.cpp:198] penlu8 needs backward computation.
I0928 19:59:17.255432  5237 net.cpp:198] Scale8 needs backward computation.
I0928 19:59:17.255434  5237 net.cpp:198] BatchNorm8 needs backward computation.
I0928 19:59:17.255437  5237 net.cpp:198] Convolution8 needs backward computation.
I0928 19:59:17.255439  5237 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I0928 19:59:17.255442  5237 net.cpp:198] penlu7 needs backward computation.
I0928 19:59:17.255445  5237 net.cpp:198] Eltwise3 needs backward computation.
I0928 19:59:17.255447  5237 net.cpp:198] Scale7 needs backward computation.
I0928 19:59:17.255458  5237 net.cpp:198] BatchNorm7 needs backward computation.
I0928 19:59:17.255461  5237 net.cpp:198] Convolution7 needs backward computation.
I0928 19:59:17.255463  5237 net.cpp:198] penlu6 needs backward computation.
I0928 19:59:17.255465  5237 net.cpp:198] Scale6 needs backward computation.
I0928 19:59:17.255477  5237 net.cpp:198] BatchNorm6 needs backward computation.
I0928 19:59:17.255479  5237 net.cpp:198] Convolution6 needs backward computation.
I0928 19:59:17.255481  5237 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I0928 19:59:17.255486  5237 net.cpp:198] penlu5 needs backward computation.
I0928 19:59:17.255487  5237 net.cpp:198] Eltwise2 needs backward computation.
I0928 19:59:17.255491  5237 net.cpp:198] Scale5 needs backward computation.
I0928 19:59:17.255493  5237 net.cpp:198] BatchNorm5 needs backward computation.
I0928 19:59:17.255496  5237 net.cpp:198] Convolution5 needs backward computation.
I0928 19:59:17.255497  5237 net.cpp:198] penlu4 needs backward computation.
I0928 19:59:17.255499  5237 net.cpp:198] Scale4 needs backward computation.
I0928 19:59:17.255501  5237 net.cpp:198] BatchNorm4 needs backward computation.
I0928 19:59:17.255503  5237 net.cpp:198] Convolution4 needs backward computation.
I0928 19:59:17.255506  5237 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I0928 19:59:17.255508  5237 net.cpp:198] penlu3 needs backward computation.
I0928 19:59:17.255511  5237 net.cpp:198] Eltwise1 needs backward computation.
I0928 19:59:17.255513  5237 net.cpp:198] Scale3 needs backward computation.
I0928 19:59:17.255515  5237 net.cpp:198] BatchNorm3 needs backward computation.
I0928 19:59:17.255518  5237 net.cpp:198] Convolution3 needs backward computation.
I0928 19:59:17.255520  5237 net.cpp:198] penlu2 needs backward computation.
I0928 19:59:17.255522  5237 net.cpp:198] Scale2 needs backward computation.
I0928 19:59:17.255524  5237 net.cpp:198] BatchNorm2 needs backward computation.
I0928 19:59:17.255527  5237 net.cpp:198] Convolution2 needs backward computation.
I0928 19:59:17.255529  5237 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I0928 19:59:17.255532  5237 net.cpp:198] penlu1 needs backward computation.
I0928 19:59:17.255534  5237 net.cpp:198] Scale1 needs backward computation.
I0928 19:59:17.255537  5237 net.cpp:198] BatchNorm1 needs backward computation.
I0928 19:59:17.255544  5237 net.cpp:198] Convolution1 needs backward computation.
I0928 19:59:17.255548  5237 net.cpp:200] Data1 does not need backward computation.
I0928 19:59:17.255549  5237 net.cpp:242] This network produces output SoftmaxWithLoss1
I0928 19:59:17.255635  5237 net.cpp:255] Network initialization done.
I0928 19:59:17.260426  5237 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_penlu_train_test.prototxt
I0928 19:59:17.260440  5237 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0928 19:59:17.260444  5237 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_penlu_train_test.prototxt
I0928 19:59:17.260637  5237 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I0928 19:59:17.262022  5237 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu20"
  type: "PENLU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu21"
  type: "PENLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu22"
  type: "PENLU"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      
I0928 19:59:17.317361  5237 layer_factory.hpp:77] Creating layer Data1
I0928 19:59:17.317409  5237 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I0928 19:59:17.317421  5237 net.cpp:84] Creating Layer Data1
I0928 19:59:17.317425  5237 net.cpp:380] Data1 -> Data1
I0928 19:59:17.317435  5237 net.cpp:380] Data1 -> Data2
I0928 19:59:17.317440  5237 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0928 19:59:17.317617  5237 data_layer.cpp:45] output data size: 100,3,32,32
I0928 19:59:17.321708  5237 net.cpp:122] Setting up Data1
I0928 19:59:17.321728  5237 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0928 19:59:17.321732  5237 net.cpp:129] Top shape: 100 (100)
I0928 19:59:17.321734  5237 net.cpp:137] Memory required for data: 1229200
I0928 19:59:17.321738  5237 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0928 19:59:17.321748  5237 net.cpp:84] Creating Layer Data2_Data1_1_split
I0928 19:59:17.321751  5237 net.cpp:406] Data2_Data1_1_split <- Data2
I0928 19:59:17.321756  5237 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0928 19:59:17.321763  5237 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0928 19:59:17.321805  5237 net.cpp:122] Setting up Data2_Data1_1_split
I0928 19:59:17.321810  5237 net.cpp:129] Top shape: 100 (100)
I0928 19:59:17.321813  5237 net.cpp:129] Top shape: 100 (100)
I0928 19:59:17.321815  5237 net.cpp:137] Memory required for data: 1230000
I0928 19:59:17.321817  5237 layer_factory.hpp:77] Creating layer Convolution1
I0928 19:59:17.321827  5237 net.cpp:84] Creating Layer Convolution1
I0928 19:59:17.321830  5237 net.cpp:406] Convolution1 <- Data1
I0928 19:59:17.321833  5237 net.cpp:380] Convolution1 -> Convolution1
I0928 19:59:17.323060  5237 net.cpp:122] Setting up Convolution1
I0928 19:59:17.323084  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.323087  5237 net.cpp:137] Memory required for data: 7783600
I0928 19:59:17.323096  5237 layer_factory.hpp:77] Creating layer BatchNorm1
I0928 19:59:17.323101  5237 net.cpp:84] Creating Layer BatchNorm1
I0928 19:59:17.323103  5237 net.cpp:406] BatchNorm1 <- Convolution1
I0928 19:59:17.323107  5237 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0928 19:59:17.323257  5237 net.cpp:122] Setting up BatchNorm1
I0928 19:59:17.323261  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.323264  5237 net.cpp:137] Memory required for data: 14337200
I0928 19:59:17.323271  5237 layer_factory.hpp:77] Creating layer Scale1
I0928 19:59:17.323282  5237 net.cpp:84] Creating Layer Scale1
I0928 19:59:17.323284  5237 net.cpp:406] Scale1 <- Convolution1
I0928 19:59:17.323287  5237 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0928 19:59:17.323320  5237 layer_factory.hpp:77] Creating layer Scale1
I0928 19:59:17.323405  5237 net.cpp:122] Setting up Scale1
I0928 19:59:17.323410  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.323411  5237 net.cpp:137] Memory required for data: 20890800
I0928 19:59:17.323415  5237 layer_factory.hpp:77] Creating layer penlu1
I0928 19:59:17.323426  5237 net.cpp:84] Creating Layer penlu1
I0928 19:59:17.323429  5237 net.cpp:406] penlu1 <- Convolution1
I0928 19:59:17.323434  5237 net.cpp:367] penlu1 -> Convolution1 (in-place)
I0928 19:59:17.324060  5237 net.cpp:122] Setting up penlu1
I0928 19:59:17.324069  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.324071  5237 net.cpp:137] Memory required for data: 27444400
I0928 19:59:17.324079  5237 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I0928 19:59:17.324084  5237 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I0928 19:59:17.324086  5237 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I0928 19:59:17.324090  5237 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I0928 19:59:17.324096  5237 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I0928 19:59:17.324124  5237 net.cpp:122] Setting up Convolution1_penlu1_0_split
I0928 19:59:17.324128  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.344825  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.344832  5237 net.cpp:137] Memory required for data: 40551600
I0928 19:59:17.344836  5237 layer_factory.hpp:77] Creating layer Convolution2
I0928 19:59:17.344844  5237 net.cpp:84] Creating Layer Convolution2
I0928 19:59:17.344847  5237 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I0928 19:59:17.344854  5237 net.cpp:380] Convolution2 -> Convolution2
I0928 19:59:17.345990  5237 net.cpp:122] Setting up Convolution2
I0928 19:59:17.345999  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.346002  5237 net.cpp:137] Memory required for data: 47105200
I0928 19:59:17.346007  5237 layer_factory.hpp:77] Creating layer BatchNorm2
I0928 19:59:17.346014  5237 net.cpp:84] Creating Layer BatchNorm2
I0928 19:59:17.346016  5237 net.cpp:406] BatchNorm2 <- Convolution2
I0928 19:59:17.346021  5237 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0928 19:59:17.346181  5237 net.cpp:122] Setting up BatchNorm2
I0928 19:59:17.346186  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.346189  5237 net.cpp:137] Memory required for data: 53658800
I0928 19:59:17.346194  5237 layer_factory.hpp:77] Creating layer Scale2
I0928 19:59:17.346199  5237 net.cpp:84] Creating Layer Scale2
I0928 19:59:17.346201  5237 net.cpp:406] Scale2 <- Convolution2
I0928 19:59:17.346205  5237 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0928 19:59:17.346238  5237 layer_factory.hpp:77] Creating layer Scale2
I0928 19:59:17.346329  5237 net.cpp:122] Setting up Scale2
I0928 19:59:17.346333  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.346335  5237 net.cpp:137] Memory required for data: 60212400
I0928 19:59:17.346343  5237 layer_factory.hpp:77] Creating layer penlu2
I0928 19:59:17.346359  5237 net.cpp:84] Creating Layer penlu2
I0928 19:59:17.346362  5237 net.cpp:406] penlu2 <- Convolution2
I0928 19:59:17.346366  5237 net.cpp:367] penlu2 -> Convolution2 (in-place)
I0928 19:59:17.346532  5237 net.cpp:122] Setting up penlu2
I0928 19:59:17.346544  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.346549  5237 net.cpp:137] Memory required for data: 66766000
I0928 19:59:17.346556  5237 layer_factory.hpp:77] Creating layer Convolution3
I0928 19:59:17.346568  5237 net.cpp:84] Creating Layer Convolution3
I0928 19:59:17.346573  5237 net.cpp:406] Convolution3 <- Convolution2
I0928 19:59:17.346580  5237 net.cpp:380] Convolution3 -> Convolution3
I0928 19:59:17.348032  5237 net.cpp:122] Setting up Convolution3
I0928 19:59:17.348042  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.348045  5237 net.cpp:137] Memory required for data: 73319600
I0928 19:59:17.348049  5237 layer_factory.hpp:77] Creating layer BatchNorm3
I0928 19:59:17.348055  5237 net.cpp:84] Creating Layer BatchNorm3
I0928 19:59:17.348058  5237 net.cpp:406] BatchNorm3 <- Convolution3
I0928 19:59:17.348063  5237 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0928 19:59:17.348225  5237 net.cpp:122] Setting up BatchNorm3
I0928 19:59:17.348230  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.348232  5237 net.cpp:137] Memory required for data: 79873200
I0928 19:59:17.348237  5237 layer_factory.hpp:77] Creating layer Scale3
I0928 19:59:17.348242  5237 net.cpp:84] Creating Layer Scale3
I0928 19:59:17.348244  5237 net.cpp:406] Scale3 <- Convolution3
I0928 19:59:17.348248  5237 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0928 19:59:17.348280  5237 layer_factory.hpp:77] Creating layer Scale3
I0928 19:59:17.348369  5237 net.cpp:122] Setting up Scale3
I0928 19:59:17.348374  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.348376  5237 net.cpp:137] Memory required for data: 86426800
I0928 19:59:17.348381  5237 layer_factory.hpp:77] Creating layer Eltwise1
I0928 19:59:17.348386  5237 net.cpp:84] Creating Layer Eltwise1
I0928 19:59:17.348387  5237 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I0928 19:59:17.348390  5237 net.cpp:406] Eltwise1 <- Convolution3
I0928 19:59:17.348394  5237 net.cpp:380] Eltwise1 -> Eltwise1
I0928 19:59:17.348414  5237 net.cpp:122] Setting up Eltwise1
I0928 19:59:17.348418  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.348420  5237 net.cpp:137] Memory required for data: 92980400
I0928 19:59:17.348423  5237 layer_factory.hpp:77] Creating layer penlu3
I0928 19:59:17.348428  5237 net.cpp:84] Creating Layer penlu3
I0928 19:59:17.348430  5237 net.cpp:406] penlu3 <- Eltwise1
I0928 19:59:17.348435  5237 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I0928 19:59:17.348570  5237 net.cpp:122] Setting up penlu3
I0928 19:59:17.348575  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.348577  5237 net.cpp:137] Memory required for data: 99534000
I0928 19:59:17.348582  5237 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I0928 19:59:17.348587  5237 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I0928 19:59:17.348589  5237 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I0928 19:59:17.348593  5237 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I0928 19:59:17.348598  5237 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I0928 19:59:17.348625  5237 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I0928 19:59:17.348629  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.348631  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.348634  5237 net.cpp:137] Memory required for data: 112641200
I0928 19:59:17.348636  5237 layer_factory.hpp:77] Creating layer Convolution4
I0928 19:59:17.348644  5237 net.cpp:84] Creating Layer Convolution4
I0928 19:59:17.348645  5237 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I0928 19:59:17.348649  5237 net.cpp:380] Convolution4 -> Convolution4
I0928 19:59:17.349710  5237 net.cpp:122] Setting up Convolution4
I0928 19:59:17.349727  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.349731  5237 net.cpp:137] Memory required for data: 119194800
I0928 19:59:17.349736  5237 layer_factory.hpp:77] Creating layer BatchNorm4
I0928 19:59:17.349742  5237 net.cpp:84] Creating Layer BatchNorm4
I0928 19:59:17.349745  5237 net.cpp:406] BatchNorm4 <- Convolution4
I0928 19:59:17.349750  5237 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0928 19:59:17.349915  5237 net.cpp:122] Setting up BatchNorm4
I0928 19:59:17.349920  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.349922  5237 net.cpp:137] Memory required for data: 125748400
I0928 19:59:17.349931  5237 layer_factory.hpp:77] Creating layer Scale4
I0928 19:59:17.349936  5237 net.cpp:84] Creating Layer Scale4
I0928 19:59:17.349939  5237 net.cpp:406] Scale4 <- Convolution4
I0928 19:59:17.349942  5237 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0928 19:59:17.349977  5237 layer_factory.hpp:77] Creating layer Scale4
I0928 19:59:17.350069  5237 net.cpp:122] Setting up Scale4
I0928 19:59:17.350073  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.350075  5237 net.cpp:137] Memory required for data: 132302000
I0928 19:59:17.350080  5237 layer_factory.hpp:77] Creating layer penlu4
I0928 19:59:17.350085  5237 net.cpp:84] Creating Layer penlu4
I0928 19:59:17.350087  5237 net.cpp:406] penlu4 <- Convolution4
I0928 19:59:17.350091  5237 net.cpp:367] penlu4 -> Convolution4 (in-place)
I0928 19:59:17.350229  5237 net.cpp:122] Setting up penlu4
I0928 19:59:17.350234  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.350235  5237 net.cpp:137] Memory required for data: 138855600
I0928 19:59:17.350240  5237 layer_factory.hpp:77] Creating layer Convolution5
I0928 19:59:17.350247  5237 net.cpp:84] Creating Layer Convolution5
I0928 19:59:17.350250  5237 net.cpp:406] Convolution5 <- Convolution4
I0928 19:59:17.350255  5237 net.cpp:380] Convolution5 -> Convolution5
I0928 19:59:17.351274  5237 net.cpp:122] Setting up Convolution5
I0928 19:59:17.351284  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.351286  5237 net.cpp:137] Memory required for data: 145409200
I0928 19:59:17.351291  5237 layer_factory.hpp:77] Creating layer BatchNorm5
I0928 19:59:17.351296  5237 net.cpp:84] Creating Layer BatchNorm5
I0928 19:59:17.351300  5237 net.cpp:406] BatchNorm5 <- Convolution5
I0928 19:59:17.351305  5237 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0928 19:59:17.351466  5237 net.cpp:122] Setting up BatchNorm5
I0928 19:59:17.351471  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.351474  5237 net.cpp:137] Memory required for data: 151962800
I0928 19:59:17.351478  5237 layer_factory.hpp:77] Creating layer Scale5
I0928 19:59:17.351483  5237 net.cpp:84] Creating Layer Scale5
I0928 19:59:17.351486  5237 net.cpp:406] Scale5 <- Convolution5
I0928 19:59:17.351490  5237 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0928 19:59:17.351521  5237 layer_factory.hpp:77] Creating layer Scale5
I0928 19:59:17.351610  5237 net.cpp:122] Setting up Scale5
I0928 19:59:17.351615  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.351617  5237 net.cpp:137] Memory required for data: 158516400
I0928 19:59:17.351621  5237 layer_factory.hpp:77] Creating layer Eltwise2
I0928 19:59:17.351625  5237 net.cpp:84] Creating Layer Eltwise2
I0928 19:59:17.351627  5237 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I0928 19:59:17.351630  5237 net.cpp:406] Eltwise2 <- Convolution5
I0928 19:59:17.351635  5237 net.cpp:380] Eltwise2 -> Eltwise2
I0928 19:59:17.351655  5237 net.cpp:122] Setting up Eltwise2
I0928 19:59:17.351658  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.351660  5237 net.cpp:137] Memory required for data: 165070000
I0928 19:59:17.351663  5237 layer_factory.hpp:77] Creating layer penlu5
I0928 19:59:17.351668  5237 net.cpp:84] Creating Layer penlu5
I0928 19:59:17.351670  5237 net.cpp:406] penlu5 <- Eltwise2
I0928 19:59:17.351675  5237 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I0928 19:59:17.351820  5237 net.cpp:122] Setting up penlu5
I0928 19:59:17.351825  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.351827  5237 net.cpp:137] Memory required for data: 171623600
I0928 19:59:17.351832  5237 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I0928 19:59:17.351836  5237 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I0928 19:59:17.351838  5237 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I0928 19:59:17.351842  5237 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I0928 19:59:17.351846  5237 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I0928 19:59:17.351876  5237 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I0928 19:59:17.351881  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.351884  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.351886  5237 net.cpp:137] Memory required for data: 184730800
I0928 19:59:17.351888  5237 layer_factory.hpp:77] Creating layer Convolution6
I0928 19:59:17.351896  5237 net.cpp:84] Creating Layer Convolution6
I0928 19:59:17.351898  5237 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I0928 19:59:17.351902  5237 net.cpp:380] Convolution6 -> Convolution6
I0928 19:59:17.352906  5237 net.cpp:122] Setting up Convolution6
I0928 19:59:17.352916  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.352918  5237 net.cpp:137] Memory required for data: 191284400
I0928 19:59:17.352922  5237 layer_factory.hpp:77] Creating layer BatchNorm6
I0928 19:59:17.352927  5237 net.cpp:84] Creating Layer BatchNorm6
I0928 19:59:17.352931  5237 net.cpp:406] BatchNorm6 <- Convolution6
I0928 19:59:17.352936  5237 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0928 19:59:17.353097  5237 net.cpp:122] Setting up BatchNorm6
I0928 19:59:17.353102  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.353104  5237 net.cpp:137] Memory required for data: 197838000
I0928 19:59:17.353109  5237 layer_factory.hpp:77] Creating layer Scale6
I0928 19:59:17.353113  5237 net.cpp:84] Creating Layer Scale6
I0928 19:59:17.353116  5237 net.cpp:406] Scale6 <- Convolution6
I0928 19:59:17.353119  5237 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0928 19:59:17.353152  5237 layer_factory.hpp:77] Creating layer Scale6
I0928 19:59:17.353241  5237 net.cpp:122] Setting up Scale6
I0928 19:59:17.353245  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.353247  5237 net.cpp:137] Memory required for data: 204391600
I0928 19:59:17.353251  5237 layer_factory.hpp:77] Creating layer penlu6
I0928 19:59:17.353257  5237 net.cpp:84] Creating Layer penlu6
I0928 19:59:17.353260  5237 net.cpp:406] penlu6 <- Convolution6
I0928 19:59:17.353265  5237 net.cpp:367] penlu6 -> Convolution6 (in-place)
I0928 19:59:17.353400  5237 net.cpp:122] Setting up penlu6
I0928 19:59:17.353405  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.353407  5237 net.cpp:137] Memory required for data: 210945200
I0928 19:59:17.353412  5237 layer_factory.hpp:77] Creating layer Convolution7
I0928 19:59:17.353421  5237 net.cpp:84] Creating Layer Convolution7
I0928 19:59:17.353423  5237 net.cpp:406] Convolution7 <- Convolution6
I0928 19:59:17.353427  5237 net.cpp:380] Convolution7 -> Convolution7
I0928 19:59:17.354439  5237 net.cpp:122] Setting up Convolution7
I0928 19:59:17.354447  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.354450  5237 net.cpp:137] Memory required for data: 217498800
I0928 19:59:17.354454  5237 layer_factory.hpp:77] Creating layer BatchNorm7
I0928 19:59:17.354463  5237 net.cpp:84] Creating Layer BatchNorm7
I0928 19:59:17.354466  5237 net.cpp:406] BatchNorm7 <- Convolution7
I0928 19:59:17.354470  5237 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0928 19:59:17.354636  5237 net.cpp:122] Setting up BatchNorm7
I0928 19:59:17.354642  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.354645  5237 net.cpp:137] Memory required for data: 224052400
I0928 19:59:17.354655  5237 layer_factory.hpp:77] Creating layer Scale7
I0928 19:59:17.354667  5237 net.cpp:84] Creating Layer Scale7
I0928 19:59:17.354671  5237 net.cpp:406] Scale7 <- Convolution7
I0928 19:59:17.354674  5237 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0928 19:59:17.354709  5237 layer_factory.hpp:77] Creating layer Scale7
I0928 19:59:17.354804  5237 net.cpp:122] Setting up Scale7
I0928 19:59:17.354809  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.354811  5237 net.cpp:137] Memory required for data: 230606000
I0928 19:59:17.354815  5237 layer_factory.hpp:77] Creating layer Eltwise3
I0928 19:59:17.354820  5237 net.cpp:84] Creating Layer Eltwise3
I0928 19:59:17.354822  5237 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I0928 19:59:17.354825  5237 net.cpp:406] Eltwise3 <- Convolution7
I0928 19:59:17.354830  5237 net.cpp:380] Eltwise3 -> Eltwise3
I0928 19:59:17.354849  5237 net.cpp:122] Setting up Eltwise3
I0928 19:59:17.354853  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.354856  5237 net.cpp:137] Memory required for data: 237159600
I0928 19:59:17.354857  5237 layer_factory.hpp:77] Creating layer penlu7
I0928 19:59:17.354862  5237 net.cpp:84] Creating Layer penlu7
I0928 19:59:17.354864  5237 net.cpp:406] penlu7 <- Eltwise3
I0928 19:59:17.354868  5237 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I0928 19:59:17.355005  5237 net.cpp:122] Setting up penlu7
I0928 19:59:17.355010  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.355012  5237 net.cpp:137] Memory required for data: 243713200
I0928 19:59:17.355016  5237 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I0928 19:59:17.355020  5237 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I0928 19:59:17.355023  5237 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I0928 19:59:17.355026  5237 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I0928 19:59:17.355031  5237 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I0928 19:59:17.355067  5237 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I0928 19:59:17.355072  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.355074  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.375593  5237 net.cpp:137] Memory required for data: 256820400
I0928 19:59:17.375602  5237 layer_factory.hpp:77] Creating layer Convolution8
I0928 19:59:17.375612  5237 net.cpp:84] Creating Layer Convolution8
I0928 19:59:17.375614  5237 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I0928 19:59:17.375619  5237 net.cpp:380] Convolution8 -> Convolution8
I0928 19:59:17.376672  5237 net.cpp:122] Setting up Convolution8
I0928 19:59:17.376682  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.376684  5237 net.cpp:137] Memory required for data: 263374000
I0928 19:59:17.376689  5237 layer_factory.hpp:77] Creating layer BatchNorm8
I0928 19:59:17.376695  5237 net.cpp:84] Creating Layer BatchNorm8
I0928 19:59:17.376698  5237 net.cpp:406] BatchNorm8 <- Convolution8
I0928 19:59:17.376703  5237 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0928 19:59:17.376870  5237 net.cpp:122] Setting up BatchNorm8
I0928 19:59:17.376875  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.376878  5237 net.cpp:137] Memory required for data: 269927600
I0928 19:59:17.376883  5237 layer_factory.hpp:77] Creating layer Scale8
I0928 19:59:17.376888  5237 net.cpp:84] Creating Layer Scale8
I0928 19:59:17.376890  5237 net.cpp:406] Scale8 <- Convolution8
I0928 19:59:17.376894  5237 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0928 19:59:17.376927  5237 layer_factory.hpp:77] Creating layer Scale8
I0928 19:59:17.377020  5237 net.cpp:122] Setting up Scale8
I0928 19:59:17.377024  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.377027  5237 net.cpp:137] Memory required for data: 276481200
I0928 19:59:17.377032  5237 layer_factory.hpp:77] Creating layer penlu8
I0928 19:59:17.377038  5237 net.cpp:84] Creating Layer penlu8
I0928 19:59:17.377040  5237 net.cpp:406] penlu8 <- Convolution8
I0928 19:59:17.377044  5237 net.cpp:367] penlu8 -> Convolution8 (in-place)
I0928 19:59:17.377249  5237 net.cpp:122] Setting up penlu8
I0928 19:59:17.377256  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.377259  5237 net.cpp:137] Memory required for data: 283034800
I0928 19:59:17.377264  5237 layer_factory.hpp:77] Creating layer Convolution9
I0928 19:59:17.377271  5237 net.cpp:84] Creating Layer Convolution9
I0928 19:59:17.377274  5237 net.cpp:406] Convolution9 <- Convolution8
I0928 19:59:17.377279  5237 net.cpp:380] Convolution9 -> Convolution9
I0928 19:59:17.378263  5237 net.cpp:122] Setting up Convolution9
I0928 19:59:17.378273  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.378275  5237 net.cpp:137] Memory required for data: 289588400
I0928 19:59:17.378279  5237 layer_factory.hpp:77] Creating layer BatchNorm9
I0928 19:59:17.378284  5237 net.cpp:84] Creating Layer BatchNorm9
I0928 19:59:17.378288  5237 net.cpp:406] BatchNorm9 <- Convolution9
I0928 19:59:17.378291  5237 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0928 19:59:17.378453  5237 net.cpp:122] Setting up BatchNorm9
I0928 19:59:17.378458  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.378459  5237 net.cpp:137] Memory required for data: 296142000
I0928 19:59:17.378464  5237 layer_factory.hpp:77] Creating layer Scale9
I0928 19:59:17.378468  5237 net.cpp:84] Creating Layer Scale9
I0928 19:59:17.378470  5237 net.cpp:406] Scale9 <- Convolution9
I0928 19:59:17.378474  5237 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0928 19:59:17.378505  5237 layer_factory.hpp:77] Creating layer Scale9
I0928 19:59:17.378605  5237 net.cpp:122] Setting up Scale9
I0928 19:59:17.378610  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.378612  5237 net.cpp:137] Memory required for data: 302695600
I0928 19:59:17.378617  5237 layer_factory.hpp:77] Creating layer Eltwise4
I0928 19:59:17.378621  5237 net.cpp:84] Creating Layer Eltwise4
I0928 19:59:17.378624  5237 net.cpp:406] Eltwise4 <- Eltwise3_penlu7_0_split_1
I0928 19:59:17.378628  5237 net.cpp:406] Eltwise4 <- Convolution9
I0928 19:59:17.378630  5237 net.cpp:380] Eltwise4 -> Eltwise4
I0928 19:59:17.378649  5237 net.cpp:122] Setting up Eltwise4
I0928 19:59:17.378654  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.378655  5237 net.cpp:137] Memory required for data: 309249200
I0928 19:59:17.378657  5237 layer_factory.hpp:77] Creating layer penlu9
I0928 19:59:17.378664  5237 net.cpp:84] Creating Layer penlu9
I0928 19:59:17.378665  5237 net.cpp:406] penlu9 <- Eltwise4
I0928 19:59:17.378669  5237 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I0928 19:59:17.378803  5237 net.cpp:122] Setting up penlu9
I0928 19:59:17.378808  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.378810  5237 net.cpp:137] Memory required for data: 315802800
I0928 19:59:17.378814  5237 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I0928 19:59:17.378818  5237 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I0928 19:59:17.378820  5237 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I0928 19:59:17.378824  5237 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I0928 19:59:17.378829  5237 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I0928 19:59:17.378855  5237 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I0928 19:59:17.378859  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.378861  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.378864  5237 net.cpp:137] Memory required for data: 328910000
I0928 19:59:17.378865  5237 layer_factory.hpp:77] Creating layer Convolution10
I0928 19:59:17.378872  5237 net.cpp:84] Creating Layer Convolution10
I0928 19:59:17.378875  5237 net.cpp:406] Convolution10 <- Eltwise4_penlu9_0_split_0
I0928 19:59:17.378878  5237 net.cpp:380] Convolution10 -> Convolution10
I0928 19:59:17.379905  5237 net.cpp:122] Setting up Convolution10
I0928 19:59:17.379914  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.379917  5237 net.cpp:137] Memory required for data: 335463600
I0928 19:59:17.379930  5237 layer_factory.hpp:77] Creating layer BatchNorm10
I0928 19:59:17.379935  5237 net.cpp:84] Creating Layer BatchNorm10
I0928 19:59:17.379938  5237 net.cpp:406] BatchNorm10 <- Convolution10
I0928 19:59:17.379942  5237 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0928 19:59:17.380103  5237 net.cpp:122] Setting up BatchNorm10
I0928 19:59:17.380107  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.380110  5237 net.cpp:137] Memory required for data: 342017200
I0928 19:59:17.380115  5237 layer_factory.hpp:77] Creating layer Scale10
I0928 19:59:17.380120  5237 net.cpp:84] Creating Layer Scale10
I0928 19:59:17.380122  5237 net.cpp:406] Scale10 <- Convolution10
I0928 19:59:17.380125  5237 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0928 19:59:17.380159  5237 layer_factory.hpp:77] Creating layer Scale10
I0928 19:59:17.380249  5237 net.cpp:122] Setting up Scale10
I0928 19:59:17.380254  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.380256  5237 net.cpp:137] Memory required for data: 348570800
I0928 19:59:17.380260  5237 layer_factory.hpp:77] Creating layer penlu10
I0928 19:59:17.380264  5237 net.cpp:84] Creating Layer penlu10
I0928 19:59:17.380267  5237 net.cpp:406] penlu10 <- Convolution10
I0928 19:59:17.380271  5237 net.cpp:367] penlu10 -> Convolution10 (in-place)
I0928 19:59:17.380405  5237 net.cpp:122] Setting up penlu10
I0928 19:59:17.380410  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.380412  5237 net.cpp:137] Memory required for data: 355124400
I0928 19:59:17.380416  5237 layer_factory.hpp:77] Creating layer Convolution11
I0928 19:59:17.380424  5237 net.cpp:84] Creating Layer Convolution11
I0928 19:59:17.380426  5237 net.cpp:406] Convolution11 <- Convolution10
I0928 19:59:17.380431  5237 net.cpp:380] Convolution11 -> Convolution11
I0928 19:59:17.381743  5237 net.cpp:122] Setting up Convolution11
I0928 19:59:17.381752  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.381754  5237 net.cpp:137] Memory required for data: 361678000
I0928 19:59:17.381759  5237 layer_factory.hpp:77] Creating layer BatchNorm11
I0928 19:59:17.381765  5237 net.cpp:84] Creating Layer BatchNorm11
I0928 19:59:17.381768  5237 net.cpp:406] BatchNorm11 <- Convolution11
I0928 19:59:17.381772  5237 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0928 19:59:17.381937  5237 net.cpp:122] Setting up BatchNorm11
I0928 19:59:17.381942  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.381943  5237 net.cpp:137] Memory required for data: 368231600
I0928 19:59:17.381948  5237 layer_factory.hpp:77] Creating layer Scale11
I0928 19:59:17.381953  5237 net.cpp:84] Creating Layer Scale11
I0928 19:59:17.381955  5237 net.cpp:406] Scale11 <- Convolution11
I0928 19:59:17.381959  5237 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0928 19:59:17.381990  5237 layer_factory.hpp:77] Creating layer Scale11
I0928 19:59:17.382081  5237 net.cpp:122] Setting up Scale11
I0928 19:59:17.382084  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.382086  5237 net.cpp:137] Memory required for data: 374785200
I0928 19:59:17.382091  5237 layer_factory.hpp:77] Creating layer Eltwise5
I0928 19:59:17.382095  5237 net.cpp:84] Creating Layer Eltwise5
I0928 19:59:17.382097  5237 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I0928 19:59:17.382100  5237 net.cpp:406] Eltwise5 <- Convolution11
I0928 19:59:17.382103  5237 net.cpp:380] Eltwise5 -> Eltwise5
I0928 19:59:17.382122  5237 net.cpp:122] Setting up Eltwise5
I0928 19:59:17.382127  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.382128  5237 net.cpp:137] Memory required for data: 381338800
I0928 19:59:17.382130  5237 layer_factory.hpp:77] Creating layer penlu11
I0928 19:59:17.382136  5237 net.cpp:84] Creating Layer penlu11
I0928 19:59:17.382138  5237 net.cpp:406] penlu11 <- Eltwise5
I0928 19:59:17.382143  5237 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I0928 19:59:17.382282  5237 net.cpp:122] Setting up penlu11
I0928 19:59:17.382287  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.382294  5237 net.cpp:137] Memory required for data: 387892400
I0928 19:59:17.382300  5237 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I0928 19:59:17.382303  5237 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I0928 19:59:17.382306  5237 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I0928 19:59:17.382309  5237 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I0928 19:59:17.382313  5237 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I0928 19:59:17.382344  5237 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I0928 19:59:17.382349  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.382351  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.382354  5237 net.cpp:137] Memory required for data: 400999600
I0928 19:59:17.382355  5237 layer_factory.hpp:77] Creating layer Convolution12
I0928 19:59:17.382361  5237 net.cpp:84] Creating Layer Convolution12
I0928 19:59:17.382364  5237 net.cpp:406] Convolution12 <- Eltwise5_penlu11_0_split_0
I0928 19:59:17.382369  5237 net.cpp:380] Convolution12 -> Convolution12
I0928 19:59:17.383376  5237 net.cpp:122] Setting up Convolution12
I0928 19:59:17.383386  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.383388  5237 net.cpp:137] Memory required for data: 407553200
I0928 19:59:17.383394  5237 layer_factory.hpp:77] Creating layer BatchNorm12
I0928 19:59:17.383397  5237 net.cpp:84] Creating Layer BatchNorm12
I0928 19:59:17.383400  5237 net.cpp:406] BatchNorm12 <- Convolution12
I0928 19:59:17.383404  5237 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0928 19:59:17.383568  5237 net.cpp:122] Setting up BatchNorm12
I0928 19:59:17.383572  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.383574  5237 net.cpp:137] Memory required for data: 414106800
I0928 19:59:17.383579  5237 layer_factory.hpp:77] Creating layer Scale12
I0928 19:59:17.383584  5237 net.cpp:84] Creating Layer Scale12
I0928 19:59:17.383585  5237 net.cpp:406] Scale12 <- Convolution12
I0928 19:59:17.383589  5237 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0928 19:59:17.383620  5237 layer_factory.hpp:77] Creating layer Scale12
I0928 19:59:17.383710  5237 net.cpp:122] Setting up Scale12
I0928 19:59:17.383715  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.383718  5237 net.cpp:137] Memory required for data: 420660400
I0928 19:59:17.383721  5237 layer_factory.hpp:77] Creating layer penlu12
I0928 19:59:17.383726  5237 net.cpp:84] Creating Layer penlu12
I0928 19:59:17.383729  5237 net.cpp:406] penlu12 <- Convolution12
I0928 19:59:17.383733  5237 net.cpp:367] penlu12 -> Convolution12 (in-place)
I0928 19:59:17.383867  5237 net.cpp:122] Setting up penlu12
I0928 19:59:17.383872  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.383873  5237 net.cpp:137] Memory required for data: 427214000
I0928 19:59:17.383877  5237 layer_factory.hpp:77] Creating layer Convolution13
I0928 19:59:17.383885  5237 net.cpp:84] Creating Layer Convolution13
I0928 19:59:17.383888  5237 net.cpp:406] Convolution13 <- Convolution12
I0928 19:59:17.383891  5237 net.cpp:380] Convolution13 -> Convolution13
I0928 19:59:17.384886  5237 net.cpp:122] Setting up Convolution13
I0928 19:59:17.384894  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.384897  5237 net.cpp:137] Memory required for data: 433767600
I0928 19:59:17.384902  5237 layer_factory.hpp:77] Creating layer BatchNorm13
I0928 19:59:17.384907  5237 net.cpp:84] Creating Layer BatchNorm13
I0928 19:59:17.384910  5237 net.cpp:406] BatchNorm13 <- Convolution13
I0928 19:59:17.384913  5237 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0928 19:59:17.385076  5237 net.cpp:122] Setting up BatchNorm13
I0928 19:59:17.385079  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.385082  5237 net.cpp:137] Memory required for data: 440321200
I0928 19:59:17.385087  5237 layer_factory.hpp:77] Creating layer Scale13
I0928 19:59:17.385090  5237 net.cpp:84] Creating Layer Scale13
I0928 19:59:17.385093  5237 net.cpp:406] Scale13 <- Convolution13
I0928 19:59:17.385104  5237 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0928 19:59:17.385136  5237 layer_factory.hpp:77] Creating layer Scale13
I0928 19:59:17.385227  5237 net.cpp:122] Setting up Scale13
I0928 19:59:17.385232  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.385234  5237 net.cpp:137] Memory required for data: 446874800
I0928 19:59:17.385238  5237 layer_factory.hpp:77] Creating layer Eltwise6
I0928 19:59:17.385247  5237 net.cpp:84] Creating Layer Eltwise6
I0928 19:59:17.385251  5237 net.cpp:406] Eltwise6 <- Eltwise5_penlu11_0_split_1
I0928 19:59:17.385253  5237 net.cpp:406] Eltwise6 <- Convolution13
I0928 19:59:17.385257  5237 net.cpp:380] Eltwise6 -> Eltwise6
I0928 19:59:17.385277  5237 net.cpp:122] Setting up Eltwise6
I0928 19:59:17.385282  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.385283  5237 net.cpp:137] Memory required for data: 453428400
I0928 19:59:17.385285  5237 layer_factory.hpp:77] Creating layer penlu13
I0928 19:59:17.385290  5237 net.cpp:84] Creating Layer penlu13
I0928 19:59:17.385293  5237 net.cpp:406] penlu13 <- Eltwise6
I0928 19:59:17.385296  5237 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I0928 19:59:17.385433  5237 net.cpp:122] Setting up penlu13
I0928 19:59:17.385437  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.385439  5237 net.cpp:137] Memory required for data: 459982000
I0928 19:59:17.385452  5237 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I0928 19:59:17.385457  5237 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I0928 19:59:17.385459  5237 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I0928 19:59:17.385462  5237 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I0928 19:59:17.385468  5237 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I0928 19:59:17.385496  5237 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I0928 19:59:17.385500  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.385504  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.406178  5237 net.cpp:137] Memory required for data: 473089200
I0928 19:59:17.406186  5237 layer_factory.hpp:77] Creating layer Convolution14
I0928 19:59:17.406196  5237 net.cpp:84] Creating Layer Convolution14
I0928 19:59:17.406199  5237 net.cpp:406] Convolution14 <- Eltwise6_penlu13_0_split_0
I0928 19:59:17.406205  5237 net.cpp:380] Convolution14 -> Convolution14
I0928 19:59:17.407282  5237 net.cpp:122] Setting up Convolution14
I0928 19:59:17.407292  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.407295  5237 net.cpp:137] Memory required for data: 479642800
I0928 19:59:17.407300  5237 layer_factory.hpp:77] Creating layer BatchNorm14
I0928 19:59:17.407306  5237 net.cpp:84] Creating Layer BatchNorm14
I0928 19:59:17.407310  5237 net.cpp:406] BatchNorm14 <- Convolution14
I0928 19:59:17.407313  5237 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0928 19:59:17.407485  5237 net.cpp:122] Setting up BatchNorm14
I0928 19:59:17.407490  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.407492  5237 net.cpp:137] Memory required for data: 486196400
I0928 19:59:17.407498  5237 layer_factory.hpp:77] Creating layer Scale14
I0928 19:59:17.407502  5237 net.cpp:84] Creating Layer Scale14
I0928 19:59:17.407505  5237 net.cpp:406] Scale14 <- Convolution14
I0928 19:59:17.407508  5237 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0928 19:59:17.407552  5237 layer_factory.hpp:77] Creating layer Scale14
I0928 19:59:17.407640  5237 net.cpp:122] Setting up Scale14
I0928 19:59:17.407644  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.407646  5237 net.cpp:137] Memory required for data: 492750000
I0928 19:59:17.407650  5237 layer_factory.hpp:77] Creating layer penlu14
I0928 19:59:17.407657  5237 net.cpp:84] Creating Layer penlu14
I0928 19:59:17.407661  5237 net.cpp:406] penlu14 <- Convolution14
I0928 19:59:17.407667  5237 net.cpp:367] penlu14 -> Convolution14 (in-place)
I0928 19:59:17.407853  5237 net.cpp:122] Setting up penlu14
I0928 19:59:17.407869  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.407871  5237 net.cpp:137] Memory required for data: 499303600
I0928 19:59:17.407876  5237 layer_factory.hpp:77] Creating layer Convolution15
I0928 19:59:17.407884  5237 net.cpp:84] Creating Layer Convolution15
I0928 19:59:17.407887  5237 net.cpp:406] Convolution15 <- Convolution14
I0928 19:59:17.407891  5237 net.cpp:380] Convolution15 -> Convolution15
I0928 19:59:17.409255  5237 net.cpp:122] Setting up Convolution15
I0928 19:59:17.409263  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.409266  5237 net.cpp:137] Memory required for data: 505857200
I0928 19:59:17.409271  5237 layer_factory.hpp:77] Creating layer BatchNorm15
I0928 19:59:17.409276  5237 net.cpp:84] Creating Layer BatchNorm15
I0928 19:59:17.409277  5237 net.cpp:406] BatchNorm15 <- Convolution15
I0928 19:59:17.409282  5237 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0928 19:59:17.409446  5237 net.cpp:122] Setting up BatchNorm15
I0928 19:59:17.409451  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.409453  5237 net.cpp:137] Memory required for data: 512410800
I0928 19:59:17.409458  5237 layer_factory.hpp:77] Creating layer Scale15
I0928 19:59:17.409462  5237 net.cpp:84] Creating Layer Scale15
I0928 19:59:17.409464  5237 net.cpp:406] Scale15 <- Convolution15
I0928 19:59:17.409468  5237 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0928 19:59:17.409500  5237 layer_factory.hpp:77] Creating layer Scale15
I0928 19:59:17.409588  5237 net.cpp:122] Setting up Scale15
I0928 19:59:17.409593  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.409595  5237 net.cpp:137] Memory required for data: 518964400
I0928 19:59:17.409600  5237 layer_factory.hpp:77] Creating layer Eltwise7
I0928 19:59:17.409605  5237 net.cpp:84] Creating Layer Eltwise7
I0928 19:59:17.409607  5237 net.cpp:406] Eltwise7 <- Eltwise6_penlu13_0_split_1
I0928 19:59:17.409610  5237 net.cpp:406] Eltwise7 <- Convolution15
I0928 19:59:17.409613  5237 net.cpp:380] Eltwise7 -> Eltwise7
I0928 19:59:17.409632  5237 net.cpp:122] Setting up Eltwise7
I0928 19:59:17.409636  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.409638  5237 net.cpp:137] Memory required for data: 525518000
I0928 19:59:17.409641  5237 layer_factory.hpp:77] Creating layer penlu15
I0928 19:59:17.409646  5237 net.cpp:84] Creating Layer penlu15
I0928 19:59:17.409648  5237 net.cpp:406] penlu15 <- Eltwise7
I0928 19:59:17.409651  5237 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I0928 19:59:17.409790  5237 net.cpp:122] Setting up penlu15
I0928 19:59:17.409795  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.409796  5237 net.cpp:137] Memory required for data: 532071600
I0928 19:59:17.409801  5237 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I0928 19:59:17.409804  5237 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I0928 19:59:17.409806  5237 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I0928 19:59:17.409811  5237 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I0928 19:59:17.409816  5237 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I0928 19:59:17.409842  5237 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I0928 19:59:17.409845  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.409848  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.409850  5237 net.cpp:137] Memory required for data: 545178800
I0928 19:59:17.409852  5237 layer_factory.hpp:77] Creating layer Convolution16
I0928 19:59:17.409859  5237 net.cpp:84] Creating Layer Convolution16
I0928 19:59:17.409862  5237 net.cpp:406] Convolution16 <- Eltwise7_penlu15_0_split_0
I0928 19:59:17.409865  5237 net.cpp:380] Convolution16 -> Convolution16
I0928 19:59:17.410511  5237 net.cpp:122] Setting up Convolution16
I0928 19:59:17.410518  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.410526  5237 net.cpp:137] Memory required for data: 551732400
I0928 19:59:17.410531  5237 layer_factory.hpp:77] Creating layer BatchNorm16
I0928 19:59:17.410543  5237 net.cpp:84] Creating Layer BatchNorm16
I0928 19:59:17.410547  5237 net.cpp:406] BatchNorm16 <- Convolution16
I0928 19:59:17.410552  5237 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0928 19:59:17.410715  5237 net.cpp:122] Setting up BatchNorm16
I0928 19:59:17.410719  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.410722  5237 net.cpp:137] Memory required for data: 558286000
I0928 19:59:17.410727  5237 layer_factory.hpp:77] Creating layer Scale16
I0928 19:59:17.410730  5237 net.cpp:84] Creating Layer Scale16
I0928 19:59:17.410733  5237 net.cpp:406] Scale16 <- Convolution16
I0928 19:59:17.410737  5237 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0928 19:59:17.410768  5237 layer_factory.hpp:77] Creating layer Scale16
I0928 19:59:17.410861  5237 net.cpp:122] Setting up Scale16
I0928 19:59:17.410864  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.410866  5237 net.cpp:137] Memory required for data: 564839600
I0928 19:59:17.410871  5237 layer_factory.hpp:77] Creating layer penlu16
I0928 19:59:17.410876  5237 net.cpp:84] Creating Layer penlu16
I0928 19:59:17.410878  5237 net.cpp:406] penlu16 <- Convolution16
I0928 19:59:17.410882  5237 net.cpp:367] penlu16 -> Convolution16 (in-place)
I0928 19:59:17.411020  5237 net.cpp:122] Setting up penlu16
I0928 19:59:17.411025  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.411027  5237 net.cpp:137] Memory required for data: 571393200
I0928 19:59:17.411031  5237 layer_factory.hpp:77] Creating layer Convolution17
I0928 19:59:17.411038  5237 net.cpp:84] Creating Layer Convolution17
I0928 19:59:17.411041  5237 net.cpp:406] Convolution17 <- Convolution16
I0928 19:59:17.411044  5237 net.cpp:380] Convolution17 -> Convolution17
I0928 19:59:17.412039  5237 net.cpp:122] Setting up Convolution17
I0928 19:59:17.412046  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.412050  5237 net.cpp:137] Memory required for data: 577946800
I0928 19:59:17.412055  5237 layer_factory.hpp:77] Creating layer BatchNorm17
I0928 19:59:17.412060  5237 net.cpp:84] Creating Layer BatchNorm17
I0928 19:59:17.412062  5237 net.cpp:406] BatchNorm17 <- Convolution17
I0928 19:59:17.412066  5237 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0928 19:59:17.412228  5237 net.cpp:122] Setting up BatchNorm17
I0928 19:59:17.412232  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.412235  5237 net.cpp:137] Memory required for data: 584500400
I0928 19:59:17.412240  5237 layer_factory.hpp:77] Creating layer Scale17
I0928 19:59:17.412245  5237 net.cpp:84] Creating Layer Scale17
I0928 19:59:17.412246  5237 net.cpp:406] Scale17 <- Convolution17
I0928 19:59:17.412250  5237 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0928 19:59:17.412281  5237 layer_factory.hpp:77] Creating layer Scale17
I0928 19:59:17.412371  5237 net.cpp:122] Setting up Scale17
I0928 19:59:17.412377  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.412379  5237 net.cpp:137] Memory required for data: 591054000
I0928 19:59:17.412384  5237 layer_factory.hpp:77] Creating layer Eltwise8
I0928 19:59:17.412387  5237 net.cpp:84] Creating Layer Eltwise8
I0928 19:59:17.412389  5237 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I0928 19:59:17.412392  5237 net.cpp:406] Eltwise8 <- Convolution17
I0928 19:59:17.412396  5237 net.cpp:380] Eltwise8 -> Eltwise8
I0928 19:59:17.412415  5237 net.cpp:122] Setting up Eltwise8
I0928 19:59:17.412418  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.412420  5237 net.cpp:137] Memory required for data: 597607600
I0928 19:59:17.412422  5237 layer_factory.hpp:77] Creating layer penlu17
I0928 19:59:17.412428  5237 net.cpp:84] Creating Layer penlu17
I0928 19:59:17.412431  5237 net.cpp:406] penlu17 <- Eltwise8
I0928 19:59:17.412434  5237 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I0928 19:59:17.412575  5237 net.cpp:122] Setting up penlu17
I0928 19:59:17.412580  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.412588  5237 net.cpp:137] Memory required for data: 604161200
I0928 19:59:17.412593  5237 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I0928 19:59:17.412598  5237 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I0928 19:59:17.412600  5237 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I0928 19:59:17.412605  5237 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I0928 19:59:17.412608  5237 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I0928 19:59:17.412637  5237 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I0928 19:59:17.412642  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.412644  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.412647  5237 net.cpp:137] Memory required for data: 617268400
I0928 19:59:17.412648  5237 layer_factory.hpp:77] Creating layer Convolution18
I0928 19:59:17.412654  5237 net.cpp:84] Creating Layer Convolution18
I0928 19:59:17.412657  5237 net.cpp:406] Convolution18 <- Eltwise8_penlu17_0_split_0
I0928 19:59:17.412662  5237 net.cpp:380] Convolution18 -> Convolution18
I0928 19:59:17.413692  5237 net.cpp:122] Setting up Convolution18
I0928 19:59:17.413702  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.413704  5237 net.cpp:137] Memory required for data: 623822000
I0928 19:59:17.413708  5237 layer_factory.hpp:77] Creating layer BatchNorm18
I0928 19:59:17.413713  5237 net.cpp:84] Creating Layer BatchNorm18
I0928 19:59:17.413717  5237 net.cpp:406] BatchNorm18 <- Convolution18
I0928 19:59:17.413720  5237 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0928 19:59:17.413880  5237 net.cpp:122] Setting up BatchNorm18
I0928 19:59:17.413884  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.413887  5237 net.cpp:137] Memory required for data: 630375600
I0928 19:59:17.413892  5237 layer_factory.hpp:77] Creating layer Scale18
I0928 19:59:17.413897  5237 net.cpp:84] Creating Layer Scale18
I0928 19:59:17.413899  5237 net.cpp:406] Scale18 <- Convolution18
I0928 19:59:17.413902  5237 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0928 19:59:17.413933  5237 layer_factory.hpp:77] Creating layer Scale18
I0928 19:59:17.414023  5237 net.cpp:122] Setting up Scale18
I0928 19:59:17.414027  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.414031  5237 net.cpp:137] Memory required for data: 636929200
I0928 19:59:17.414034  5237 layer_factory.hpp:77] Creating layer penlu18
I0928 19:59:17.414039  5237 net.cpp:84] Creating Layer penlu18
I0928 19:59:17.414041  5237 net.cpp:406] penlu18 <- Convolution18
I0928 19:59:17.414046  5237 net.cpp:367] penlu18 -> Convolution18 (in-place)
I0928 19:59:17.414185  5237 net.cpp:122] Setting up penlu18
I0928 19:59:17.414188  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.414191  5237 net.cpp:137] Memory required for data: 643482800
I0928 19:59:17.414196  5237 layer_factory.hpp:77] Creating layer Convolution19
I0928 19:59:17.414202  5237 net.cpp:84] Creating Layer Convolution19
I0928 19:59:17.414204  5237 net.cpp:406] Convolution19 <- Convolution18
I0928 19:59:17.414208  5237 net.cpp:380] Convolution19 -> Convolution19
I0928 19:59:17.415199  5237 net.cpp:122] Setting up Convolution19
I0928 19:59:17.415207  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.415210  5237 net.cpp:137] Memory required for data: 650036400
I0928 19:59:17.415215  5237 layer_factory.hpp:77] Creating layer BatchNorm19
I0928 19:59:17.415220  5237 net.cpp:84] Creating Layer BatchNorm19
I0928 19:59:17.415223  5237 net.cpp:406] BatchNorm19 <- Convolution19
I0928 19:59:17.415226  5237 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0928 19:59:17.415392  5237 net.cpp:122] Setting up BatchNorm19
I0928 19:59:17.415396  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.415398  5237 net.cpp:137] Memory required for data: 656590000
I0928 19:59:17.415403  5237 layer_factory.hpp:77] Creating layer Scale19
I0928 19:59:17.415407  5237 net.cpp:84] Creating Layer Scale19
I0928 19:59:17.415410  5237 net.cpp:406] Scale19 <- Convolution19
I0928 19:59:17.415421  5237 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0928 19:59:17.415455  5237 layer_factory.hpp:77] Creating layer Scale19
I0928 19:59:17.415547  5237 net.cpp:122] Setting up Scale19
I0928 19:59:17.415552  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.415555  5237 net.cpp:137] Memory required for data: 663143600
I0928 19:59:17.415558  5237 layer_factory.hpp:77] Creating layer Eltwise9
I0928 19:59:17.415563  5237 net.cpp:84] Creating Layer Eltwise9
I0928 19:59:17.415566  5237 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I0928 19:59:17.415570  5237 net.cpp:406] Eltwise9 <- Convolution19
I0928 19:59:17.415573  5237 net.cpp:380] Eltwise9 -> Eltwise9
I0928 19:59:17.415591  5237 net.cpp:122] Setting up Eltwise9
I0928 19:59:17.415596  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.415597  5237 net.cpp:137] Memory required for data: 669697200
I0928 19:59:17.415599  5237 layer_factory.hpp:77] Creating layer penlu19
I0928 19:59:17.415606  5237 net.cpp:84] Creating Layer penlu19
I0928 19:59:17.415607  5237 net.cpp:406] penlu19 <- Eltwise9
I0928 19:59:17.415611  5237 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I0928 19:59:17.415751  5237 net.cpp:122] Setting up penlu19
I0928 19:59:17.415756  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.415758  5237 net.cpp:137] Memory required for data: 676250800
I0928 19:59:17.415763  5237 layer_factory.hpp:77] Creating layer Eltwise9_penlu19_0_split
I0928 19:59:17.415767  5237 net.cpp:84] Creating Layer Eltwise9_penlu19_0_split
I0928 19:59:17.415769  5237 net.cpp:406] Eltwise9_penlu19_0_split <- Eltwise9
I0928 19:59:17.415772  5237 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_0
I0928 19:59:17.415777  5237 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_1
I0928 19:59:17.415805  5237 net.cpp:122] Setting up Eltwise9_penlu19_0_split
I0928 19:59:17.436899  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.436908  5237 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0928 19:59:17.436910  5237 net.cpp:137] Memory required for data: 689358000
I0928 19:59:17.436913  5237 layer_factory.hpp:77] Creating layer Convolution20
I0928 19:59:17.436923  5237 net.cpp:84] Creating Layer Convolution20
I0928 19:59:17.436925  5237 net.cpp:406] Convolution20 <- Eltwise9_penlu19_0_split_0
I0928 19:59:17.436930  5237 net.cpp:380] Convolution20 -> Convolution20
I0928 19:59:17.438575  5237 net.cpp:122] Setting up Convolution20
I0928 19:59:17.438585  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.438588  5237 net.cpp:137] Memory required for data: 692634800
I0928 19:59:17.438593  5237 layer_factory.hpp:77] Creating layer BatchNorm20
I0928 19:59:17.438598  5237 net.cpp:84] Creating Layer BatchNorm20
I0928 19:59:17.438601  5237 net.cpp:406] BatchNorm20 <- Convolution20
I0928 19:59:17.438607  5237 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0928 19:59:17.438738  5237 net.cpp:122] Setting up BatchNorm20
I0928 19:59:17.438742  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.438745  5237 net.cpp:137] Memory required for data: 695911600
I0928 19:59:17.438750  5237 layer_factory.hpp:77] Creating layer Scale20
I0928 19:59:17.438755  5237 net.cpp:84] Creating Layer Scale20
I0928 19:59:17.438757  5237 net.cpp:406] Scale20 <- Convolution20
I0928 19:59:17.438760  5237 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0928 19:59:17.438788  5237 layer_factory.hpp:77] Creating layer Scale20
I0928 19:59:17.438863  5237 net.cpp:122] Setting up Scale20
I0928 19:59:17.438866  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.438868  5237 net.cpp:137] Memory required for data: 699188400
I0928 19:59:17.438872  5237 layer_factory.hpp:77] Creating layer Convolution21
I0928 19:59:17.438880  5237 net.cpp:84] Creating Layer Convolution21
I0928 19:59:17.438884  5237 net.cpp:406] Convolution21 <- Eltwise9_penlu19_0_split_1
I0928 19:59:17.438887  5237 net.cpp:380] Convolution21 -> Convolution21
I0928 19:59:17.439924  5237 net.cpp:122] Setting up Convolution21
I0928 19:59:17.439934  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.439936  5237 net.cpp:137] Memory required for data: 702465200
I0928 19:59:17.439941  5237 layer_factory.hpp:77] Creating layer BatchNorm21
I0928 19:59:17.439946  5237 net.cpp:84] Creating Layer BatchNorm21
I0928 19:59:17.439949  5237 net.cpp:406] BatchNorm21 <- Convolution21
I0928 19:59:17.439954  5237 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0928 19:59:17.440079  5237 net.cpp:122] Setting up BatchNorm21
I0928 19:59:17.440083  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.440085  5237 net.cpp:137] Memory required for data: 705742000
I0928 19:59:17.440090  5237 layer_factory.hpp:77] Creating layer Scale21
I0928 19:59:17.440095  5237 net.cpp:84] Creating Layer Scale21
I0928 19:59:17.440099  5237 net.cpp:406] Scale21 <- Convolution21
I0928 19:59:17.440101  5237 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0928 19:59:17.440127  5237 layer_factory.hpp:77] Creating layer Scale21
I0928 19:59:17.440201  5237 net.cpp:122] Setting up Scale21
I0928 19:59:17.440206  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.440207  5237 net.cpp:137] Memory required for data: 709018800
I0928 19:59:17.440212  5237 layer_factory.hpp:77] Creating layer penlu20
I0928 19:59:17.440217  5237 net.cpp:84] Creating Layer penlu20
I0928 19:59:17.440219  5237 net.cpp:406] penlu20 <- Convolution21
I0928 19:59:17.440223  5237 net.cpp:367] penlu20 -> Convolution21 (in-place)
I0928 19:59:17.440331  5237 net.cpp:122] Setting up penlu20
I0928 19:59:17.440337  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.440340  5237 net.cpp:137] Memory required for data: 712295600
I0928 19:59:17.440343  5237 layer_factory.hpp:77] Creating layer Convolution22
I0928 19:59:17.440349  5237 net.cpp:84] Creating Layer Convolution22
I0928 19:59:17.440352  5237 net.cpp:406] Convolution22 <- Convolution21
I0928 19:59:17.440357  5237 net.cpp:380] Convolution22 -> Convolution22
I0928 19:59:17.441496  5237 net.cpp:122] Setting up Convolution22
I0928 19:59:17.441505  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.441509  5237 net.cpp:137] Memory required for data: 715572400
I0928 19:59:17.441514  5237 layer_factory.hpp:77] Creating layer BatchNorm22
I0928 19:59:17.441517  5237 net.cpp:84] Creating Layer BatchNorm22
I0928 19:59:17.441520  5237 net.cpp:406] BatchNorm22 <- Convolution22
I0928 19:59:17.441525  5237 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0928 19:59:17.441653  5237 net.cpp:122] Setting up BatchNorm22
I0928 19:59:17.441658  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.441659  5237 net.cpp:137] Memory required for data: 718849200
I0928 19:59:17.441664  5237 layer_factory.hpp:77] Creating layer Scale22
I0928 19:59:17.441668  5237 net.cpp:84] Creating Layer Scale22
I0928 19:59:17.441670  5237 net.cpp:406] Scale22 <- Convolution22
I0928 19:59:17.441673  5237 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0928 19:59:17.441699  5237 layer_factory.hpp:77] Creating layer Scale22
I0928 19:59:17.441776  5237 net.cpp:122] Setting up Scale22
I0928 19:59:17.441779  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.441781  5237 net.cpp:137] Memory required for data: 722126000
I0928 19:59:17.441786  5237 layer_factory.hpp:77] Creating layer Eltwise10
I0928 19:59:17.441789  5237 net.cpp:84] Creating Layer Eltwise10
I0928 19:59:17.441792  5237 net.cpp:406] Eltwise10 <- Convolution20
I0928 19:59:17.441794  5237 net.cpp:406] Eltwise10 <- Convolution22
I0928 19:59:17.441799  5237 net.cpp:380] Eltwise10 -> Eltwise10
I0928 19:59:17.441812  5237 net.cpp:122] Setting up Eltwise10
I0928 19:59:17.441814  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.441817  5237 net.cpp:137] Memory required for data: 725402800
I0928 19:59:17.441818  5237 layer_factory.hpp:77] Creating layer penlu21
I0928 19:59:17.441824  5237 net.cpp:84] Creating Layer penlu21
I0928 19:59:17.441826  5237 net.cpp:406] penlu21 <- Eltwise10
I0928 19:59:17.441838  5237 net.cpp:367] penlu21 -> Eltwise10 (in-place)
I0928 19:59:17.441949  5237 net.cpp:122] Setting up penlu21
I0928 19:59:17.441953  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.441956  5237 net.cpp:137] Memory required for data: 728679600
I0928 19:59:17.441961  5237 layer_factory.hpp:77] Creating layer Eltwise10_penlu21_0_split
I0928 19:59:17.441964  5237 net.cpp:84] Creating Layer Eltwise10_penlu21_0_split
I0928 19:59:17.441967  5237 net.cpp:406] Eltwise10_penlu21_0_split <- Eltwise10
I0928 19:59:17.441970  5237 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_0
I0928 19:59:17.441974  5237 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_1
I0928 19:59:17.441996  5237 net.cpp:122] Setting up Eltwise10_penlu21_0_split
I0928 19:59:17.442000  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.442003  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.442005  5237 net.cpp:137] Memory required for data: 735233200
I0928 19:59:17.442008  5237 layer_factory.hpp:77] Creating layer Convolution23
I0928 19:59:17.442014  5237 net.cpp:84] Creating Layer Convolution23
I0928 19:59:17.442016  5237 net.cpp:406] Convolution23 <- Eltwise10_penlu21_0_split_0
I0928 19:59:17.442020  5237 net.cpp:380] Convolution23 -> Convolution23
I0928 19:59:17.443148  5237 net.cpp:122] Setting up Convolution23
I0928 19:59:17.443157  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.443161  5237 net.cpp:137] Memory required for data: 738510000
I0928 19:59:17.443164  5237 layer_factory.hpp:77] Creating layer BatchNorm23
I0928 19:59:17.443169  5237 net.cpp:84] Creating Layer BatchNorm23
I0928 19:59:17.443172  5237 net.cpp:406] BatchNorm23 <- Convolution23
I0928 19:59:17.443177  5237 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0928 19:59:17.443301  5237 net.cpp:122] Setting up BatchNorm23
I0928 19:59:17.443306  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.443308  5237 net.cpp:137] Memory required for data: 741786800
I0928 19:59:17.443313  5237 layer_factory.hpp:77] Creating layer Scale23
I0928 19:59:17.443317  5237 net.cpp:84] Creating Layer Scale23
I0928 19:59:17.443320  5237 net.cpp:406] Scale23 <- Convolution23
I0928 19:59:17.443323  5237 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0928 19:59:17.443348  5237 layer_factory.hpp:77] Creating layer Scale23
I0928 19:59:17.443423  5237 net.cpp:122] Setting up Scale23
I0928 19:59:17.443428  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.443430  5237 net.cpp:137] Memory required for data: 745063600
I0928 19:59:17.443434  5237 layer_factory.hpp:77] Creating layer penlu22
I0928 19:59:17.443439  5237 net.cpp:84] Creating Layer penlu22
I0928 19:59:17.443442  5237 net.cpp:406] penlu22 <- Convolution23
I0928 19:59:17.443445  5237 net.cpp:367] penlu22 -> Convolution23 (in-place)
I0928 19:59:17.443553  5237 net.cpp:122] Setting up penlu22
I0928 19:59:17.443557  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.443559  5237 net.cpp:137] Memory required for data: 748340400
I0928 19:59:17.443563  5237 layer_factory.hpp:77] Creating layer Convolution24
I0928 19:59:17.443570  5237 net.cpp:84] Creating Layer Convolution24
I0928 19:59:17.443572  5237 net.cpp:406] Convolution24 <- Convolution23
I0928 19:59:17.443578  5237 net.cpp:380] Convolution24 -> Convolution24
I0928 19:59:17.444694  5237 net.cpp:122] Setting up Convolution24
I0928 19:59:17.444705  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.444707  5237 net.cpp:137] Memory required for data: 751617200
I0928 19:59:17.444711  5237 layer_factory.hpp:77] Creating layer BatchNorm24
I0928 19:59:17.444717  5237 net.cpp:84] Creating Layer BatchNorm24
I0928 19:59:17.444720  5237 net.cpp:406] BatchNorm24 <- Convolution24
I0928 19:59:17.444723  5237 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0928 19:59:17.444851  5237 net.cpp:122] Setting up BatchNorm24
I0928 19:59:17.444855  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.444857  5237 net.cpp:137] Memory required for data: 754894000
I0928 19:59:17.444869  5237 layer_factory.hpp:77] Creating layer Scale24
I0928 19:59:17.444875  5237 net.cpp:84] Creating Layer Scale24
I0928 19:59:17.444877  5237 net.cpp:406] Scale24 <- Convolution24
I0928 19:59:17.444881  5237 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0928 19:59:17.444908  5237 layer_factory.hpp:77] Creating layer Scale24
I0928 19:59:17.444981  5237 net.cpp:122] Setting up Scale24
I0928 19:59:17.444985  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.444988  5237 net.cpp:137] Memory required for data: 758170800
I0928 19:59:17.444991  5237 layer_factory.hpp:77] Creating layer Eltwise11
I0928 19:59:17.444995  5237 net.cpp:84] Creating Layer Eltwise11
I0928 19:59:17.444998  5237 net.cpp:406] Eltwise11 <- Eltwise10_penlu21_0_split_1
I0928 19:59:17.445001  5237 net.cpp:406] Eltwise11 <- Convolution24
I0928 19:59:17.445005  5237 net.cpp:380] Eltwise11 -> Eltwise11
I0928 19:59:17.445016  5237 net.cpp:122] Setting up Eltwise11
I0928 19:59:17.445021  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.445024  5237 net.cpp:137] Memory required for data: 761447600
I0928 19:59:17.445025  5237 layer_factory.hpp:77] Creating layer penlu23
I0928 19:59:17.445030  5237 net.cpp:84] Creating Layer penlu23
I0928 19:59:17.445032  5237 net.cpp:406] penlu23 <- Eltwise11
I0928 19:59:17.445036  5237 net.cpp:367] penlu23 -> Eltwise11 (in-place)
I0928 19:59:17.445147  5237 net.cpp:122] Setting up penlu23
I0928 19:59:17.445152  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.445153  5237 net.cpp:137] Memory required for data: 764724400
I0928 19:59:17.445158  5237 layer_factory.hpp:77] Creating layer Eltwise11_penlu23_0_split
I0928 19:59:17.445161  5237 net.cpp:84] Creating Layer Eltwise11_penlu23_0_split
I0928 19:59:17.445163  5237 net.cpp:406] Eltwise11_penlu23_0_split <- Eltwise11
I0928 19:59:17.445168  5237 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_0
I0928 19:59:17.445171  5237 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_1
I0928 19:59:17.445194  5237 net.cpp:122] Setting up Eltwise11_penlu23_0_split
I0928 19:59:17.445197  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.445200  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.445201  5237 net.cpp:137] Memory required for data: 771278000
I0928 19:59:17.445204  5237 layer_factory.hpp:77] Creating layer Convolution25
I0928 19:59:17.445210  5237 net.cpp:84] Creating Layer Convolution25
I0928 19:59:17.445212  5237 net.cpp:406] Convolution25 <- Eltwise11_penlu23_0_split_0
I0928 19:59:17.445216  5237 net.cpp:380] Convolution25 -> Convolution25
I0928 19:59:17.446339  5237 net.cpp:122] Setting up Convolution25
I0928 19:59:17.446348  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.446350  5237 net.cpp:137] Memory required for data: 774554800
I0928 19:59:17.446355  5237 layer_factory.hpp:77] Creating layer BatchNorm25
I0928 19:59:17.446359  5237 net.cpp:84] Creating Layer BatchNorm25
I0928 19:59:17.446362  5237 net.cpp:406] BatchNorm25 <- Convolution25
I0928 19:59:17.446367  5237 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0928 19:59:17.446501  5237 net.cpp:122] Setting up BatchNorm25
I0928 19:59:17.446506  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.446507  5237 net.cpp:137] Memory required for data: 777831600
I0928 19:59:17.446512  5237 layer_factory.hpp:77] Creating layer Scale25
I0928 19:59:17.446516  5237 net.cpp:84] Creating Layer Scale25
I0928 19:59:17.446519  5237 net.cpp:406] Scale25 <- Convolution25
I0928 19:59:17.446528  5237 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0928 19:59:17.446557  5237 layer_factory.hpp:77] Creating layer Scale25
I0928 19:59:17.446631  5237 net.cpp:122] Setting up Scale25
I0928 19:59:17.446635  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.446637  5237 net.cpp:137] Memory required for data: 781108400
I0928 19:59:17.446641  5237 layer_factory.hpp:77] Creating layer penlu24
I0928 19:59:17.446655  5237 net.cpp:84] Creating Layer penlu24
I0928 19:59:17.446658  5237 net.cpp:406] penlu24 <- Convolution25
I0928 19:59:17.446662  5237 net.cpp:367] penlu24 -> Convolution25 (in-place)
I0928 19:59:17.446774  5237 net.cpp:122] Setting up penlu24
I0928 19:59:17.446777  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.446779  5237 net.cpp:137] Memory required for data: 784385200
I0928 19:59:17.446784  5237 layer_factory.hpp:77] Creating layer Convolution26
I0928 19:59:17.446791  5237 net.cpp:84] Creating Layer Convolution26
I0928 19:59:17.446794  5237 net.cpp:406] Convolution26 <- Convolution25
I0928 19:59:17.446799  5237 net.cpp:380] Convolution26 -> Convolution26
I0928 19:59:17.447576  5237 net.cpp:122] Setting up Convolution26
I0928 19:59:17.447583  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.447587  5237 net.cpp:137] Memory required for data: 787662000
I0928 19:59:17.447590  5237 layer_factory.hpp:77] Creating layer BatchNorm26
I0928 19:59:17.447595  5237 net.cpp:84] Creating Layer BatchNorm26
I0928 19:59:17.447598  5237 net.cpp:406] BatchNorm26 <- Convolution26
I0928 19:59:17.447602  5237 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0928 19:59:17.447731  5237 net.cpp:122] Setting up BatchNorm26
I0928 19:59:17.447736  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.447737  5237 net.cpp:137] Memory required for data: 790938800
I0928 19:59:17.447741  5237 layer_factory.hpp:77] Creating layer Scale26
I0928 19:59:17.447746  5237 net.cpp:84] Creating Layer Scale26
I0928 19:59:17.447748  5237 net.cpp:406] Scale26 <- Convolution26
I0928 19:59:17.447751  5237 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0928 19:59:17.447777  5237 layer_factory.hpp:77] Creating layer Scale26
I0928 19:59:17.467941  5237 net.cpp:122] Setting up Scale26
I0928 19:59:17.467949  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.467952  5237 net.cpp:137] Memory required for data: 794215600
I0928 19:59:17.467957  5237 layer_factory.hpp:77] Creating layer Eltwise12
I0928 19:59:17.467962  5237 net.cpp:84] Creating Layer Eltwise12
I0928 19:59:17.467965  5237 net.cpp:406] Eltwise12 <- Eltwise11_penlu23_0_split_1
I0928 19:59:17.467969  5237 net.cpp:406] Eltwise12 <- Convolution26
I0928 19:59:17.467973  5237 net.cpp:380] Eltwise12 -> Eltwise12
I0928 19:59:17.467986  5237 net.cpp:122] Setting up Eltwise12
I0928 19:59:17.467990  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.467993  5237 net.cpp:137] Memory required for data: 797492400
I0928 19:59:17.467995  5237 layer_factory.hpp:77] Creating layer penlu25
I0928 19:59:17.468009  5237 net.cpp:84] Creating Layer penlu25
I0928 19:59:17.468013  5237 net.cpp:406] penlu25 <- Eltwise12
I0928 19:59:17.468016  5237 net.cpp:367] penlu25 -> Eltwise12 (in-place)
I0928 19:59:17.468138  5237 net.cpp:122] Setting up penlu25
I0928 19:59:17.468143  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.468145  5237 net.cpp:137] Memory required for data: 800769200
I0928 19:59:17.468170  5237 layer_factory.hpp:77] Creating layer Eltwise12_penlu25_0_split
I0928 19:59:17.468174  5237 net.cpp:84] Creating Layer Eltwise12_penlu25_0_split
I0928 19:59:17.468178  5237 net.cpp:406] Eltwise12_penlu25_0_split <- Eltwise12
I0928 19:59:17.468181  5237 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_0
I0928 19:59:17.468185  5237 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_1
I0928 19:59:17.468212  5237 net.cpp:122] Setting up Eltwise12_penlu25_0_split
I0928 19:59:17.468216  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.468219  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.468221  5237 net.cpp:137] Memory required for data: 807322800
I0928 19:59:17.468224  5237 layer_factory.hpp:77] Creating layer Convolution27
I0928 19:59:17.468230  5237 net.cpp:84] Creating Layer Convolution27
I0928 19:59:17.468233  5237 net.cpp:406] Convolution27 <- Eltwise12_penlu25_0_split_0
I0928 19:59:17.468238  5237 net.cpp:380] Convolution27 -> Convolution27
I0928 19:59:17.469856  5237 net.cpp:122] Setting up Convolution27
I0928 19:59:17.469864  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.469867  5237 net.cpp:137] Memory required for data: 810599600
I0928 19:59:17.469871  5237 layer_factory.hpp:77] Creating layer BatchNorm27
I0928 19:59:17.469877  5237 net.cpp:84] Creating Layer BatchNorm27
I0928 19:59:17.469880  5237 net.cpp:406] BatchNorm27 <- Convolution27
I0928 19:59:17.469884  5237 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0928 19:59:17.470011  5237 net.cpp:122] Setting up BatchNorm27
I0928 19:59:17.470016  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.470017  5237 net.cpp:137] Memory required for data: 813876400
I0928 19:59:17.470022  5237 layer_factory.hpp:77] Creating layer Scale27
I0928 19:59:17.470026  5237 net.cpp:84] Creating Layer Scale27
I0928 19:59:17.470028  5237 net.cpp:406] Scale27 <- Convolution27
I0928 19:59:17.470032  5237 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0928 19:59:17.470057  5237 layer_factory.hpp:77] Creating layer Scale27
I0928 19:59:17.470131  5237 net.cpp:122] Setting up Scale27
I0928 19:59:17.470135  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.470137  5237 net.cpp:137] Memory required for data: 817153200
I0928 19:59:17.470141  5237 layer_factory.hpp:77] Creating layer penlu26
I0928 19:59:17.470146  5237 net.cpp:84] Creating Layer penlu26
I0928 19:59:17.470149  5237 net.cpp:406] penlu26 <- Convolution27
I0928 19:59:17.470152  5237 net.cpp:367] penlu26 -> Convolution27 (in-place)
I0928 19:59:17.470259  5237 net.cpp:122] Setting up penlu26
I0928 19:59:17.470264  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.470266  5237 net.cpp:137] Memory required for data: 820430000
I0928 19:59:17.470270  5237 layer_factory.hpp:77] Creating layer Convolution28
I0928 19:59:17.470278  5237 net.cpp:84] Creating Layer Convolution28
I0928 19:59:17.470280  5237 net.cpp:406] Convolution28 <- Convolution27
I0928 19:59:17.470284  5237 net.cpp:380] Convolution28 -> Convolution28
I0928 19:59:17.471822  5237 net.cpp:122] Setting up Convolution28
I0928 19:59:17.471832  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.471834  5237 net.cpp:137] Memory required for data: 823706800
I0928 19:59:17.471838  5237 layer_factory.hpp:77] Creating layer BatchNorm28
I0928 19:59:17.471844  5237 net.cpp:84] Creating Layer BatchNorm28
I0928 19:59:17.471846  5237 net.cpp:406] BatchNorm28 <- Convolution28
I0928 19:59:17.471850  5237 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0928 19:59:17.471982  5237 net.cpp:122] Setting up BatchNorm28
I0928 19:59:17.471987  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.471988  5237 net.cpp:137] Memory required for data: 826983600
I0928 19:59:17.471993  5237 layer_factory.hpp:77] Creating layer Scale28
I0928 19:59:17.471997  5237 net.cpp:84] Creating Layer Scale28
I0928 19:59:17.472000  5237 net.cpp:406] Scale28 <- Convolution28
I0928 19:59:17.472004  5237 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0928 19:59:17.472030  5237 layer_factory.hpp:77] Creating layer Scale28
I0928 19:59:17.472105  5237 net.cpp:122] Setting up Scale28
I0928 19:59:17.472110  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.472112  5237 net.cpp:137] Memory required for data: 830260400
I0928 19:59:17.472116  5237 layer_factory.hpp:77] Creating layer Eltwise13
I0928 19:59:17.472121  5237 net.cpp:84] Creating Layer Eltwise13
I0928 19:59:17.472123  5237 net.cpp:406] Eltwise13 <- Eltwise12_penlu25_0_split_1
I0928 19:59:17.472126  5237 net.cpp:406] Eltwise13 <- Convolution28
I0928 19:59:17.472129  5237 net.cpp:380] Eltwise13 -> Eltwise13
I0928 19:59:17.472141  5237 net.cpp:122] Setting up Eltwise13
I0928 19:59:17.472146  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.472147  5237 net.cpp:137] Memory required for data: 833537200
I0928 19:59:17.472149  5237 layer_factory.hpp:77] Creating layer penlu27
I0928 19:59:17.472154  5237 net.cpp:84] Creating Layer penlu27
I0928 19:59:17.472157  5237 net.cpp:406] penlu27 <- Eltwise13
I0928 19:59:17.472167  5237 net.cpp:367] penlu27 -> Eltwise13 (in-place)
I0928 19:59:17.472280  5237 net.cpp:122] Setting up penlu27
I0928 19:59:17.472285  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.472287  5237 net.cpp:137] Memory required for data: 836814000
I0928 19:59:17.472291  5237 layer_factory.hpp:77] Creating layer Eltwise13_penlu27_0_split
I0928 19:59:17.472295  5237 net.cpp:84] Creating Layer Eltwise13_penlu27_0_split
I0928 19:59:17.472298  5237 net.cpp:406] Eltwise13_penlu27_0_split <- Eltwise13
I0928 19:59:17.472301  5237 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_0
I0928 19:59:17.472306  5237 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_1
I0928 19:59:17.472328  5237 net.cpp:122] Setting up Eltwise13_penlu27_0_split
I0928 19:59:17.472332  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.472334  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.472337  5237 net.cpp:137] Memory required for data: 843367600
I0928 19:59:17.472338  5237 layer_factory.hpp:77] Creating layer Convolution29
I0928 19:59:17.472344  5237 net.cpp:84] Creating Layer Convolution29
I0928 19:59:17.472347  5237 net.cpp:406] Convolution29 <- Eltwise13_penlu27_0_split_0
I0928 19:59:17.472352  5237 net.cpp:380] Convolution29 -> Convolution29
I0928 19:59:17.473445  5237 net.cpp:122] Setting up Convolution29
I0928 19:59:17.473454  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.473456  5237 net.cpp:137] Memory required for data: 846644400
I0928 19:59:17.473461  5237 layer_factory.hpp:77] Creating layer BatchNorm29
I0928 19:59:17.473467  5237 net.cpp:84] Creating Layer BatchNorm29
I0928 19:59:17.473470  5237 net.cpp:406] BatchNorm29 <- Convolution29
I0928 19:59:17.473474  5237 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0928 19:59:17.473603  5237 net.cpp:122] Setting up BatchNorm29
I0928 19:59:17.473606  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.473608  5237 net.cpp:137] Memory required for data: 849921200
I0928 19:59:17.473613  5237 layer_factory.hpp:77] Creating layer Scale29
I0928 19:59:17.473618  5237 net.cpp:84] Creating Layer Scale29
I0928 19:59:17.473620  5237 net.cpp:406] Scale29 <- Convolution29
I0928 19:59:17.473623  5237 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0928 19:59:17.473651  5237 layer_factory.hpp:77] Creating layer Scale29
I0928 19:59:17.473726  5237 net.cpp:122] Setting up Scale29
I0928 19:59:17.473729  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.473731  5237 net.cpp:137] Memory required for data: 853198000
I0928 19:59:17.473736  5237 layer_factory.hpp:77] Creating layer penlu28
I0928 19:59:17.473742  5237 net.cpp:84] Creating Layer penlu28
I0928 19:59:17.473743  5237 net.cpp:406] penlu28 <- Convolution29
I0928 19:59:17.473747  5237 net.cpp:367] penlu28 -> Convolution29 (in-place)
I0928 19:59:17.473855  5237 net.cpp:122] Setting up penlu28
I0928 19:59:17.473858  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.473860  5237 net.cpp:137] Memory required for data: 856474800
I0928 19:59:17.473865  5237 layer_factory.hpp:77] Creating layer Convolution30
I0928 19:59:17.473871  5237 net.cpp:84] Creating Layer Convolution30
I0928 19:59:17.473873  5237 net.cpp:406] Convolution30 <- Convolution29
I0928 19:59:17.473878  5237 net.cpp:380] Convolution30 -> Convolution30
I0928 19:59:17.474993  5237 net.cpp:122] Setting up Convolution30
I0928 19:59:17.475002  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.475005  5237 net.cpp:137] Memory required for data: 859751600
I0928 19:59:17.475009  5237 layer_factory.hpp:77] Creating layer BatchNorm30
I0928 19:59:17.475014  5237 net.cpp:84] Creating Layer BatchNorm30
I0928 19:59:17.475016  5237 net.cpp:406] BatchNorm30 <- Convolution30
I0928 19:59:17.475021  5237 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0928 19:59:17.475147  5237 net.cpp:122] Setting up BatchNorm30
I0928 19:59:17.475152  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.475159  5237 net.cpp:137] Memory required for data: 863028400
I0928 19:59:17.475165  5237 layer_factory.hpp:77] Creating layer Scale30
I0928 19:59:17.475169  5237 net.cpp:84] Creating Layer Scale30
I0928 19:59:17.475172  5237 net.cpp:406] Scale30 <- Convolution30
I0928 19:59:17.475175  5237 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0928 19:59:17.475203  5237 layer_factory.hpp:77] Creating layer Scale30
I0928 19:59:17.475275  5237 net.cpp:122] Setting up Scale30
I0928 19:59:17.475280  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.475281  5237 net.cpp:137] Memory required for data: 866305200
I0928 19:59:17.475286  5237 layer_factory.hpp:77] Creating layer Eltwise14
I0928 19:59:17.475288  5237 net.cpp:84] Creating Layer Eltwise14
I0928 19:59:17.475291  5237 net.cpp:406] Eltwise14 <- Eltwise13_penlu27_0_split_1
I0928 19:59:17.475294  5237 net.cpp:406] Eltwise14 <- Convolution30
I0928 19:59:17.475298  5237 net.cpp:380] Eltwise14 -> Eltwise14
I0928 19:59:17.475309  5237 net.cpp:122] Setting up Eltwise14
I0928 19:59:17.475313  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.475314  5237 net.cpp:137] Memory required for data: 869582000
I0928 19:59:17.475317  5237 layer_factory.hpp:77] Creating layer penlu29
I0928 19:59:17.475322  5237 net.cpp:84] Creating Layer penlu29
I0928 19:59:17.475324  5237 net.cpp:406] penlu29 <- Eltwise14
I0928 19:59:17.475327  5237 net.cpp:367] penlu29 -> Eltwise14 (in-place)
I0928 19:59:17.475435  5237 net.cpp:122] Setting up penlu29
I0928 19:59:17.475440  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.475441  5237 net.cpp:137] Memory required for data: 872858800
I0928 19:59:17.475445  5237 layer_factory.hpp:77] Creating layer Eltwise14_penlu29_0_split
I0928 19:59:17.475450  5237 net.cpp:84] Creating Layer Eltwise14_penlu29_0_split
I0928 19:59:17.475451  5237 net.cpp:406] Eltwise14_penlu29_0_split <- Eltwise14
I0928 19:59:17.475455  5237 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_0
I0928 19:59:17.475458  5237 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_1
I0928 19:59:17.475481  5237 net.cpp:122] Setting up Eltwise14_penlu29_0_split
I0928 19:59:17.475484  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.475487  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.475489  5237 net.cpp:137] Memory required for data: 879412400
I0928 19:59:17.475492  5237 layer_factory.hpp:77] Creating layer Convolution31
I0928 19:59:17.475498  5237 net.cpp:84] Creating Layer Convolution31
I0928 19:59:17.475502  5237 net.cpp:406] Convolution31 <- Eltwise14_penlu29_0_split_0
I0928 19:59:17.475505  5237 net.cpp:380] Convolution31 -> Convolution31
I0928 19:59:17.476598  5237 net.cpp:122] Setting up Convolution31
I0928 19:59:17.476606  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.476608  5237 net.cpp:137] Memory required for data: 882689200
I0928 19:59:17.476613  5237 layer_factory.hpp:77] Creating layer BatchNorm31
I0928 19:59:17.476619  5237 net.cpp:84] Creating Layer BatchNorm31
I0928 19:59:17.476621  5237 net.cpp:406] BatchNorm31 <- Convolution31
I0928 19:59:17.476625  5237 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0928 19:59:17.476750  5237 net.cpp:122] Setting up BatchNorm31
I0928 19:59:17.476754  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.476757  5237 net.cpp:137] Memory required for data: 885966000
I0928 19:59:17.476760  5237 layer_factory.hpp:77] Creating layer Scale31
I0928 19:59:17.476764  5237 net.cpp:84] Creating Layer Scale31
I0928 19:59:17.476768  5237 net.cpp:406] Scale31 <- Convolution31
I0928 19:59:17.476771  5237 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0928 19:59:17.476796  5237 layer_factory.hpp:77] Creating layer Scale31
I0928 19:59:17.476867  5237 net.cpp:122] Setting up Scale31
I0928 19:59:17.476872  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.476874  5237 net.cpp:137] Memory required for data: 889242800
I0928 19:59:17.476877  5237 layer_factory.hpp:77] Creating layer penlu30
I0928 19:59:17.476889  5237 net.cpp:84] Creating Layer penlu30
I0928 19:59:17.476892  5237 net.cpp:406] penlu30 <- Convolution31
I0928 19:59:17.476897  5237 net.cpp:367] penlu30 -> Convolution31 (in-place)
I0928 19:59:17.477001  5237 net.cpp:122] Setting up penlu30
I0928 19:59:17.477005  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.477007  5237 net.cpp:137] Memory required for data: 892519600
I0928 19:59:17.477011  5237 layer_factory.hpp:77] Creating layer Convolution32
I0928 19:59:17.477018  5237 net.cpp:84] Creating Layer Convolution32
I0928 19:59:17.477021  5237 net.cpp:406] Convolution32 <- Convolution31
I0928 19:59:17.477025  5237 net.cpp:380] Convolution32 -> Convolution32
I0928 19:59:17.478121  5237 net.cpp:122] Setting up Convolution32
I0928 19:59:17.478138  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.478142  5237 net.cpp:137] Memory required for data: 895796400
I0928 19:59:17.478145  5237 layer_factory.hpp:77] Creating layer BatchNorm32
I0928 19:59:17.478150  5237 net.cpp:84] Creating Layer BatchNorm32
I0928 19:59:17.478153  5237 net.cpp:406] BatchNorm32 <- Convolution32
I0928 19:59:17.478157  5237 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I0928 19:59:17.478279  5237 net.cpp:122] Setting up BatchNorm32
I0928 19:59:17.478283  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.478286  5237 net.cpp:137] Memory required for data: 899073200
I0928 19:59:17.478291  5237 layer_factory.hpp:77] Creating layer Scale32
I0928 19:59:17.478294  5237 net.cpp:84] Creating Layer Scale32
I0928 19:59:17.478297  5237 net.cpp:406] Scale32 <- Convolution32
I0928 19:59:17.498847  5237 net.cpp:367] Scale32 -> Convolution32 (in-place)
I0928 19:59:17.498893  5237 layer_factory.hpp:77] Creating layer Scale32
I0928 19:59:17.498980  5237 net.cpp:122] Setting up Scale32
I0928 19:59:17.498986  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.498989  5237 net.cpp:137] Memory required for data: 902350000
I0928 19:59:17.498993  5237 layer_factory.hpp:77] Creating layer Eltwise15
I0928 19:59:17.498998  5237 net.cpp:84] Creating Layer Eltwise15
I0928 19:59:17.499001  5237 net.cpp:406] Eltwise15 <- Eltwise14_penlu29_0_split_1
I0928 19:59:17.499004  5237 net.cpp:406] Eltwise15 <- Convolution32
I0928 19:59:17.499008  5237 net.cpp:380] Eltwise15 -> Eltwise15
I0928 19:59:17.499022  5237 net.cpp:122] Setting up Eltwise15
I0928 19:59:17.499027  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.499028  5237 net.cpp:137] Memory required for data: 905626800
I0928 19:59:17.499032  5237 layer_factory.hpp:77] Creating layer penlu31
I0928 19:59:17.499037  5237 net.cpp:84] Creating Layer penlu31
I0928 19:59:17.499038  5237 net.cpp:406] penlu31 <- Eltwise15
I0928 19:59:17.499042  5237 net.cpp:367] penlu31 -> Eltwise15 (in-place)
I0928 19:59:17.499163  5237 net.cpp:122] Setting up penlu31
I0928 19:59:17.499168  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.499171  5237 net.cpp:137] Memory required for data: 908903600
I0928 19:59:17.499176  5237 layer_factory.hpp:77] Creating layer Eltwise15_penlu31_0_split
I0928 19:59:17.499178  5237 net.cpp:84] Creating Layer Eltwise15_penlu31_0_split
I0928 19:59:17.499181  5237 net.cpp:406] Eltwise15_penlu31_0_split <- Eltwise15
I0928 19:59:17.499184  5237 net.cpp:380] Eltwise15_penlu31_0_split -> Eltwise15_penlu31_0_split_0
I0928 19:59:17.499189  5237 net.cpp:380] Eltwise15_penlu31_0_split -> Eltwise15_penlu31_0_split_1
I0928 19:59:17.499213  5237 net.cpp:122] Setting up Eltwise15_penlu31_0_split
I0928 19:59:17.499217  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.499220  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.499222  5237 net.cpp:137] Memory required for data: 915457200
I0928 19:59:17.499224  5237 layer_factory.hpp:77] Creating layer Convolution33
I0928 19:59:17.499230  5237 net.cpp:84] Creating Layer Convolution33
I0928 19:59:17.499233  5237 net.cpp:406] Convolution33 <- Eltwise15_penlu31_0_split_0
I0928 19:59:17.499238  5237 net.cpp:380] Convolution33 -> Convolution33
I0928 19:59:17.500509  5237 net.cpp:122] Setting up Convolution33
I0928 19:59:17.500527  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.500530  5237 net.cpp:137] Memory required for data: 918734000
I0928 19:59:17.500545  5237 layer_factory.hpp:77] Creating layer BatchNorm33
I0928 19:59:17.500548  5237 net.cpp:84] Creating Layer BatchNorm33
I0928 19:59:17.500551  5237 net.cpp:406] BatchNorm33 <- Convolution33
I0928 19:59:17.500556  5237 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I0928 19:59:17.500682  5237 net.cpp:122] Setting up BatchNorm33
I0928 19:59:17.500686  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.500689  5237 net.cpp:137] Memory required for data: 922010800
I0928 19:59:17.500692  5237 layer_factory.hpp:77] Creating layer Scale33
I0928 19:59:17.500696  5237 net.cpp:84] Creating Layer Scale33
I0928 19:59:17.500699  5237 net.cpp:406] Scale33 <- Convolution33
I0928 19:59:17.500702  5237 net.cpp:367] Scale33 -> Convolution33 (in-place)
I0928 19:59:17.500730  5237 layer_factory.hpp:77] Creating layer Scale33
I0928 19:59:17.500800  5237 net.cpp:122] Setting up Scale33
I0928 19:59:17.500804  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.500807  5237 net.cpp:137] Memory required for data: 925287600
I0928 19:59:17.500810  5237 layer_factory.hpp:77] Creating layer penlu32
I0928 19:59:17.500815  5237 net.cpp:84] Creating Layer penlu32
I0928 19:59:17.500818  5237 net.cpp:406] penlu32 <- Convolution33
I0928 19:59:17.500821  5237 net.cpp:367] penlu32 -> Convolution33 (in-place)
I0928 19:59:17.500924  5237 net.cpp:122] Setting up penlu32
I0928 19:59:17.500929  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.500931  5237 net.cpp:137] Memory required for data: 928564400
I0928 19:59:17.500936  5237 layer_factory.hpp:77] Creating layer Convolution34
I0928 19:59:17.500941  5237 net.cpp:84] Creating Layer Convolution34
I0928 19:59:17.500943  5237 net.cpp:406] Convolution34 <- Convolution33
I0928 19:59:17.500948  5237 net.cpp:380] Convolution34 -> Convolution34
I0928 19:59:17.502833  5237 net.cpp:122] Setting up Convolution34
I0928 19:59:17.502845  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.502847  5237 net.cpp:137] Memory required for data: 931841200
I0928 19:59:17.502852  5237 layer_factory.hpp:77] Creating layer BatchNorm34
I0928 19:59:17.502858  5237 net.cpp:84] Creating Layer BatchNorm34
I0928 19:59:17.502861  5237 net.cpp:406] BatchNorm34 <- Convolution34
I0928 19:59:17.502866  5237 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I0928 19:59:17.503006  5237 net.cpp:122] Setting up BatchNorm34
I0928 19:59:17.503011  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.503013  5237 net.cpp:137] Memory required for data: 935118000
I0928 19:59:17.503018  5237 layer_factory.hpp:77] Creating layer Scale34
I0928 19:59:17.503023  5237 net.cpp:84] Creating Layer Scale34
I0928 19:59:17.503026  5237 net.cpp:406] Scale34 <- Convolution34
I0928 19:59:17.503029  5237 net.cpp:367] Scale34 -> Convolution34 (in-place)
I0928 19:59:17.503067  5237 layer_factory.hpp:77] Creating layer Scale34
I0928 19:59:17.503144  5237 net.cpp:122] Setting up Scale34
I0928 19:59:17.503149  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.503150  5237 net.cpp:137] Memory required for data: 938394800
I0928 19:59:17.503154  5237 layer_factory.hpp:77] Creating layer Eltwise16
I0928 19:59:17.503159  5237 net.cpp:84] Creating Layer Eltwise16
I0928 19:59:17.503162  5237 net.cpp:406] Eltwise16 <- Eltwise15_penlu31_0_split_1
I0928 19:59:17.503165  5237 net.cpp:406] Eltwise16 <- Convolution34
I0928 19:59:17.503168  5237 net.cpp:380] Eltwise16 -> Eltwise16
I0928 19:59:17.503181  5237 net.cpp:122] Setting up Eltwise16
I0928 19:59:17.503185  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.503187  5237 net.cpp:137] Memory required for data: 941671600
I0928 19:59:17.503190  5237 layer_factory.hpp:77] Creating layer penlu33
I0928 19:59:17.503195  5237 net.cpp:84] Creating Layer penlu33
I0928 19:59:17.503214  5237 net.cpp:406] penlu33 <- Eltwise16
I0928 19:59:17.503219  5237 net.cpp:367] penlu33 -> Eltwise16 (in-place)
I0928 19:59:17.503342  5237 net.cpp:122] Setting up penlu33
I0928 19:59:17.503347  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.503350  5237 net.cpp:137] Memory required for data: 944948400
I0928 19:59:17.503355  5237 layer_factory.hpp:77] Creating layer Eltwise16_penlu33_0_split
I0928 19:59:17.503358  5237 net.cpp:84] Creating Layer Eltwise16_penlu33_0_split
I0928 19:59:17.503361  5237 net.cpp:406] Eltwise16_penlu33_0_split <- Eltwise16
I0928 19:59:17.503365  5237 net.cpp:380] Eltwise16_penlu33_0_split -> Eltwise16_penlu33_0_split_0
I0928 19:59:17.503370  5237 net.cpp:380] Eltwise16_penlu33_0_split -> Eltwise16_penlu33_0_split_1
I0928 19:59:17.503396  5237 net.cpp:122] Setting up Eltwise16_penlu33_0_split
I0928 19:59:17.503399  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.503402  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.503404  5237 net.cpp:137] Memory required for data: 951502000
I0928 19:59:17.503407  5237 layer_factory.hpp:77] Creating layer Convolution35
I0928 19:59:17.503414  5237 net.cpp:84] Creating Layer Convolution35
I0928 19:59:17.503417  5237 net.cpp:406] Convolution35 <- Eltwise16_penlu33_0_split_0
I0928 19:59:17.503422  5237 net.cpp:380] Convolution35 -> Convolution35
I0928 19:59:17.504595  5237 net.cpp:122] Setting up Convolution35
I0928 19:59:17.504603  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.504606  5237 net.cpp:137] Memory required for data: 954778800
I0928 19:59:17.504611  5237 layer_factory.hpp:77] Creating layer BatchNorm35
I0928 19:59:17.504616  5237 net.cpp:84] Creating Layer BatchNorm35
I0928 19:59:17.504618  5237 net.cpp:406] BatchNorm35 <- Convolution35
I0928 19:59:17.504622  5237 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I0928 19:59:17.504750  5237 net.cpp:122] Setting up BatchNorm35
I0928 19:59:17.504753  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.504755  5237 net.cpp:137] Memory required for data: 958055600
I0928 19:59:17.504760  5237 layer_factory.hpp:77] Creating layer Scale35
I0928 19:59:17.504765  5237 net.cpp:84] Creating Layer Scale35
I0928 19:59:17.504766  5237 net.cpp:406] Scale35 <- Convolution35
I0928 19:59:17.504770  5237 net.cpp:367] Scale35 -> Convolution35 (in-place)
I0928 19:59:17.504796  5237 layer_factory.hpp:77] Creating layer Scale35
I0928 19:59:17.504871  5237 net.cpp:122] Setting up Scale35
I0928 19:59:17.504876  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.504878  5237 net.cpp:137] Memory required for data: 961332400
I0928 19:59:17.504883  5237 layer_factory.hpp:77] Creating layer penlu34
I0928 19:59:17.504887  5237 net.cpp:84] Creating Layer penlu34
I0928 19:59:17.504889  5237 net.cpp:406] penlu34 <- Convolution35
I0928 19:59:17.504894  5237 net.cpp:367] penlu34 -> Convolution35 (in-place)
I0928 19:59:17.504997  5237 net.cpp:122] Setting up penlu34
I0928 19:59:17.505002  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.505004  5237 net.cpp:137] Memory required for data: 964609200
I0928 19:59:17.505008  5237 layer_factory.hpp:77] Creating layer Convolution36
I0928 19:59:17.505017  5237 net.cpp:84] Creating Layer Convolution36
I0928 19:59:17.505018  5237 net.cpp:406] Convolution36 <- Convolution35
I0928 19:59:17.505023  5237 net.cpp:380] Convolution36 -> Convolution36
I0928 19:59:17.505765  5237 net.cpp:122] Setting up Convolution36
I0928 19:59:17.505772  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.505775  5237 net.cpp:137] Memory required for data: 967886000
I0928 19:59:17.505779  5237 layer_factory.hpp:77] Creating layer BatchNorm36
I0928 19:59:17.505784  5237 net.cpp:84] Creating Layer BatchNorm36
I0928 19:59:17.505785  5237 net.cpp:406] BatchNorm36 <- Convolution36
I0928 19:59:17.505789  5237 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I0928 19:59:17.505916  5237 net.cpp:122] Setting up BatchNorm36
I0928 19:59:17.505920  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.505929  5237 net.cpp:137] Memory required for data: 971162800
I0928 19:59:17.505934  5237 layer_factory.hpp:77] Creating layer Scale36
I0928 19:59:17.505939  5237 net.cpp:84] Creating Layer Scale36
I0928 19:59:17.505941  5237 net.cpp:406] Scale36 <- Convolution36
I0928 19:59:17.505944  5237 net.cpp:367] Scale36 -> Convolution36 (in-place)
I0928 19:59:17.505971  5237 layer_factory.hpp:77] Creating layer Scale36
I0928 19:59:17.506044  5237 net.cpp:122] Setting up Scale36
I0928 19:59:17.506048  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.506050  5237 net.cpp:137] Memory required for data: 974439600
I0928 19:59:17.506053  5237 layer_factory.hpp:77] Creating layer Eltwise17
I0928 19:59:17.506058  5237 net.cpp:84] Creating Layer Eltwise17
I0928 19:59:17.506060  5237 net.cpp:406] Eltwise17 <- Eltwise16_penlu33_0_split_1
I0928 19:59:17.506063  5237 net.cpp:406] Eltwise17 <- Convolution36
I0928 19:59:17.506067  5237 net.cpp:380] Eltwise17 -> Eltwise17
I0928 19:59:17.506078  5237 net.cpp:122] Setting up Eltwise17
I0928 19:59:17.506081  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.506083  5237 net.cpp:137] Memory required for data: 977716400
I0928 19:59:17.506085  5237 layer_factory.hpp:77] Creating layer penlu35
I0928 19:59:17.506090  5237 net.cpp:84] Creating Layer penlu35
I0928 19:59:17.506093  5237 net.cpp:406] penlu35 <- Eltwise17
I0928 19:59:17.506096  5237 net.cpp:367] penlu35 -> Eltwise17 (in-place)
I0928 19:59:17.506206  5237 net.cpp:122] Setting up penlu35
I0928 19:59:17.506209  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.506211  5237 net.cpp:137] Memory required for data: 980993200
I0928 19:59:17.506216  5237 layer_factory.hpp:77] Creating layer Eltwise17_penlu35_0_split
I0928 19:59:17.506219  5237 net.cpp:84] Creating Layer Eltwise17_penlu35_0_split
I0928 19:59:17.506222  5237 net.cpp:406] Eltwise17_penlu35_0_split <- Eltwise17
I0928 19:59:17.506225  5237 net.cpp:380] Eltwise17_penlu35_0_split -> Eltwise17_penlu35_0_split_0
I0928 19:59:17.506229  5237 net.cpp:380] Eltwise17_penlu35_0_split -> Eltwise17_penlu35_0_split_1
I0928 19:59:17.506252  5237 net.cpp:122] Setting up Eltwise17_penlu35_0_split
I0928 19:59:17.506255  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.506258  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.506259  5237 net.cpp:137] Memory required for data: 987546800
I0928 19:59:17.506261  5237 layer_factory.hpp:77] Creating layer Convolution37
I0928 19:59:17.506268  5237 net.cpp:84] Creating Layer Convolution37
I0928 19:59:17.506271  5237 net.cpp:406] Convolution37 <- Eltwise17_penlu35_0_split_0
I0928 19:59:17.506275  5237 net.cpp:380] Convolution37 -> Convolution37
I0928 19:59:17.507383  5237 net.cpp:122] Setting up Convolution37
I0928 19:59:17.507391  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.507395  5237 net.cpp:137] Memory required for data: 990823600
I0928 19:59:17.507398  5237 layer_factory.hpp:77] Creating layer BatchNorm37
I0928 19:59:17.507403  5237 net.cpp:84] Creating Layer BatchNorm37
I0928 19:59:17.507406  5237 net.cpp:406] BatchNorm37 <- Convolution37
I0928 19:59:17.507411  5237 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I0928 19:59:17.507537  5237 net.cpp:122] Setting up BatchNorm37
I0928 19:59:17.507541  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.507544  5237 net.cpp:137] Memory required for data: 994100400
I0928 19:59:17.507549  5237 layer_factory.hpp:77] Creating layer Scale37
I0928 19:59:17.507552  5237 net.cpp:84] Creating Layer Scale37
I0928 19:59:17.507555  5237 net.cpp:406] Scale37 <- Convolution37
I0928 19:59:17.507558  5237 net.cpp:367] Scale37 -> Convolution37 (in-place)
I0928 19:59:17.507583  5237 layer_factory.hpp:77] Creating layer Scale37
I0928 19:59:17.507658  5237 net.cpp:122] Setting up Scale37
I0928 19:59:17.507661  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.507663  5237 net.cpp:137] Memory required for data: 997377200
I0928 19:59:17.507668  5237 layer_factory.hpp:77] Creating layer penlu36
I0928 19:59:17.507689  5237 net.cpp:84] Creating Layer penlu36
I0928 19:59:17.507692  5237 net.cpp:406] penlu36 <- Convolution37
I0928 19:59:17.507705  5237 net.cpp:367] penlu36 -> Convolution37 (in-place)
I0928 19:59:17.507812  5237 net.cpp:122] Setting up penlu36
I0928 19:59:17.507817  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.507818  5237 net.cpp:137] Memory required for data: 1000654000
I0928 19:59:17.507822  5237 layer_factory.hpp:77] Creating layer Convolution38
I0928 19:59:17.507829  5237 net.cpp:84] Creating Layer Convolution38
I0928 19:59:17.507832  5237 net.cpp:406] Convolution38 <- Convolution37
I0928 19:59:17.507835  5237 net.cpp:380] Convolution38 -> Convolution38
I0928 19:59:17.509227  5237 net.cpp:122] Setting up Convolution38
I0928 19:59:17.509234  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.509238  5237 net.cpp:137] Memory required for data: 1003930800
I0928 19:59:17.509241  5237 layer_factory.hpp:77] Creating layer BatchNorm38
I0928 19:59:17.509246  5237 net.cpp:84] Creating Layer BatchNorm38
I0928 19:59:17.509249  5237 net.cpp:406] BatchNorm38 <- Convolution38
I0928 19:59:17.509255  5237 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I0928 19:59:17.509387  5237 net.cpp:122] Setting up BatchNorm38
I0928 19:59:17.509392  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.509393  5237 net.cpp:137] Memory required for data: 1007207600
I0928 19:59:17.529561  5237 layer_factory.hpp:77] Creating layer Scale38
I0928 19:59:17.529572  5237 net.cpp:84] Creating Layer Scale38
I0928 19:59:17.529574  5237 net.cpp:406] Scale38 <- Convolution38
I0928 19:59:17.529582  5237 net.cpp:367] Scale38 -> Convolution38 (in-place)
I0928 19:59:17.529621  5237 layer_factory.hpp:77] Creating layer Scale38
I0928 19:59:17.529712  5237 net.cpp:122] Setting up Scale38
I0928 19:59:17.529717  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.529721  5237 net.cpp:137] Memory required for data: 1010484400
I0928 19:59:17.529724  5237 layer_factory.hpp:77] Creating layer Eltwise18
I0928 19:59:17.529729  5237 net.cpp:84] Creating Layer Eltwise18
I0928 19:59:17.529731  5237 net.cpp:406] Eltwise18 <- Eltwise17_penlu35_0_split_1
I0928 19:59:17.529736  5237 net.cpp:406] Eltwise18 <- Convolution38
I0928 19:59:17.529738  5237 net.cpp:380] Eltwise18 -> Eltwise18
I0928 19:59:17.529753  5237 net.cpp:122] Setting up Eltwise18
I0928 19:59:17.529757  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.529759  5237 net.cpp:137] Memory required for data: 1013761200
I0928 19:59:17.529762  5237 layer_factory.hpp:77] Creating layer penlu37
I0928 19:59:17.529767  5237 net.cpp:84] Creating Layer penlu37
I0928 19:59:17.529770  5237 net.cpp:406] penlu37 <- Eltwise18
I0928 19:59:17.529773  5237 net.cpp:367] penlu37 -> Eltwise18 (in-place)
I0928 19:59:17.529896  5237 net.cpp:122] Setting up penlu37
I0928 19:59:17.529901  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.529902  5237 net.cpp:137] Memory required for data: 1017038000
I0928 19:59:17.529907  5237 layer_factory.hpp:77] Creating layer Eltwise18_penlu37_0_split
I0928 19:59:17.529912  5237 net.cpp:84] Creating Layer Eltwise18_penlu37_0_split
I0928 19:59:17.529914  5237 net.cpp:406] Eltwise18_penlu37_0_split <- Eltwise18
I0928 19:59:17.529918  5237 net.cpp:380] Eltwise18_penlu37_0_split -> Eltwise18_penlu37_0_split_0
I0928 19:59:17.529923  5237 net.cpp:380] Eltwise18_penlu37_0_split -> Eltwise18_penlu37_0_split_1
I0928 19:59:17.529948  5237 net.cpp:122] Setting up Eltwise18_penlu37_0_split
I0928 19:59:17.529953  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.529955  5237 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0928 19:59:17.529958  5237 net.cpp:137] Memory required for data: 1023591600
I0928 19:59:17.529959  5237 layer_factory.hpp:77] Creating layer Convolution39
I0928 19:59:17.529965  5237 net.cpp:84] Creating Layer Convolution39
I0928 19:59:17.529968  5237 net.cpp:406] Convolution39 <- Eltwise18_penlu37_0_split_0
I0928 19:59:17.529973  5237 net.cpp:380] Convolution39 -> Convolution39
I0928 19:59:17.531111  5237 net.cpp:122] Setting up Convolution39
I0928 19:59:17.531119  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.531121  5237 net.cpp:137] Memory required for data: 1025230000
I0928 19:59:17.531126  5237 layer_factory.hpp:77] Creating layer BatchNorm39
I0928 19:59:17.531132  5237 net.cpp:84] Creating Layer BatchNorm39
I0928 19:59:17.531136  5237 net.cpp:406] BatchNorm39 <- Convolution39
I0928 19:59:17.531139  5237 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I0928 19:59:17.531360  5237 net.cpp:122] Setting up BatchNorm39
I0928 19:59:17.531368  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.531370  5237 net.cpp:137] Memory required for data: 1026868400
I0928 19:59:17.531375  5237 layer_factory.hpp:77] Creating layer Scale39
I0928 19:59:17.531379  5237 net.cpp:84] Creating Layer Scale39
I0928 19:59:17.531383  5237 net.cpp:406] Scale39 <- Convolution39
I0928 19:59:17.531385  5237 net.cpp:367] Scale39 -> Convolution39 (in-place)
I0928 19:59:17.531416  5237 layer_factory.hpp:77] Creating layer Scale39
I0928 19:59:17.531494  5237 net.cpp:122] Setting up Scale39
I0928 19:59:17.531498  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.531500  5237 net.cpp:137] Memory required for data: 1028506800
I0928 19:59:17.531504  5237 layer_factory.hpp:77] Creating layer Convolution40
I0928 19:59:17.531512  5237 net.cpp:84] Creating Layer Convolution40
I0928 19:59:17.531514  5237 net.cpp:406] Convolution40 <- Eltwise18_penlu37_0_split_1
I0928 19:59:17.531519  5237 net.cpp:380] Convolution40 -> Convolution40
I0928 19:59:17.532907  5237 net.cpp:122] Setting up Convolution40
I0928 19:59:17.532914  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.532917  5237 net.cpp:137] Memory required for data: 1030145200
I0928 19:59:17.532922  5237 layer_factory.hpp:77] Creating layer BatchNorm40
I0928 19:59:17.532927  5237 net.cpp:84] Creating Layer BatchNorm40
I0928 19:59:17.532928  5237 net.cpp:406] BatchNorm40 <- Convolution40
I0928 19:59:17.532933  5237 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I0928 19:59:17.533125  5237 net.cpp:122] Setting up BatchNorm40
I0928 19:59:17.533133  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.533134  5237 net.cpp:137] Memory required for data: 1031783600
I0928 19:59:17.533139  5237 layer_factory.hpp:77] Creating layer Scale40
I0928 19:59:17.533143  5237 net.cpp:84] Creating Layer Scale40
I0928 19:59:17.533146  5237 net.cpp:406] Scale40 <- Convolution40
I0928 19:59:17.533150  5237 net.cpp:367] Scale40 -> Convolution40 (in-place)
I0928 19:59:17.533177  5237 layer_factory.hpp:77] Creating layer Scale40
I0928 19:59:17.533267  5237 net.cpp:122] Setting up Scale40
I0928 19:59:17.533270  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.533272  5237 net.cpp:137] Memory required for data: 1033422000
I0928 19:59:17.533277  5237 layer_factory.hpp:77] Creating layer penlu38
I0928 19:59:17.533282  5237 net.cpp:84] Creating Layer penlu38
I0928 19:59:17.533284  5237 net.cpp:406] penlu38 <- Convolution40
I0928 19:59:17.533288  5237 net.cpp:367] penlu38 -> Convolution40 (in-place)
I0928 19:59:17.533417  5237 net.cpp:122] Setting up penlu38
I0928 19:59:17.533422  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.533424  5237 net.cpp:137] Memory required for data: 1035060400
I0928 19:59:17.533429  5237 layer_factory.hpp:77] Creating layer Convolution41
I0928 19:59:17.533434  5237 net.cpp:84] Creating Layer Convolution41
I0928 19:59:17.533437  5237 net.cpp:406] Convolution41 <- Convolution40
I0928 19:59:17.533442  5237 net.cpp:380] Convolution41 -> Convolution41
I0928 19:59:17.535187  5237 net.cpp:122] Setting up Convolution41
I0928 19:59:17.535197  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.535198  5237 net.cpp:137] Memory required for data: 1036698800
I0928 19:59:17.535203  5237 layer_factory.hpp:77] Creating layer BatchNorm41
I0928 19:59:17.535207  5237 net.cpp:84] Creating Layer BatchNorm41
I0928 19:59:17.535210  5237 net.cpp:406] BatchNorm41 <- Convolution41
I0928 19:59:17.535223  5237 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I0928 19:59:17.535357  5237 net.cpp:122] Setting up BatchNorm41
I0928 19:59:17.535362  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.535363  5237 net.cpp:137] Memory required for data: 1038337200
I0928 19:59:17.535368  5237 layer_factory.hpp:77] Creating layer Scale41
I0928 19:59:17.535372  5237 net.cpp:84] Creating Layer Scale41
I0928 19:59:17.535374  5237 net.cpp:406] Scale41 <- Convolution41
I0928 19:59:17.535377  5237 net.cpp:367] Scale41 -> Convolution41 (in-place)
I0928 19:59:17.535405  5237 layer_factory.hpp:77] Creating layer Scale41
I0928 19:59:17.535482  5237 net.cpp:122] Setting up Scale41
I0928 19:59:17.535486  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.535488  5237 net.cpp:137] Memory required for data: 1039975600
I0928 19:59:17.535492  5237 layer_factory.hpp:77] Creating layer Eltwise19
I0928 19:59:17.535496  5237 net.cpp:84] Creating Layer Eltwise19
I0928 19:59:17.535500  5237 net.cpp:406] Eltwise19 <- Convolution39
I0928 19:59:17.535501  5237 net.cpp:406] Eltwise19 <- Convolution41
I0928 19:59:17.535506  5237 net.cpp:380] Eltwise19 -> Eltwise19
I0928 19:59:17.535521  5237 net.cpp:122] Setting up Eltwise19
I0928 19:59:17.535524  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.560232  5237 net.cpp:137] Memory required for data: 1041614000
I0928 19:59:17.560240  5237 layer_factory.hpp:77] Creating layer penlu39
I0928 19:59:17.560248  5237 net.cpp:84] Creating Layer penlu39
I0928 19:59:17.560251  5237 net.cpp:406] penlu39 <- Eltwise19
I0928 19:59:17.560257  5237 net.cpp:367] penlu39 -> Eltwise19 (in-place)
I0928 19:59:17.560408  5237 net.cpp:122] Setting up penlu39
I0928 19:59:17.560415  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.560417  5237 net.cpp:137] Memory required for data: 1043252400
I0928 19:59:17.560422  5237 layer_factory.hpp:77] Creating layer Eltwise19_penlu39_0_split
I0928 19:59:17.560427  5237 net.cpp:84] Creating Layer Eltwise19_penlu39_0_split
I0928 19:59:17.560430  5237 net.cpp:406] Eltwise19_penlu39_0_split <- Eltwise19
I0928 19:59:17.560433  5237 net.cpp:380] Eltwise19_penlu39_0_split -> Eltwise19_penlu39_0_split_0
I0928 19:59:17.560438  5237 net.cpp:380] Eltwise19_penlu39_0_split -> Eltwise19_penlu39_0_split_1
I0928 19:59:17.560465  5237 net.cpp:122] Setting up Eltwise19_penlu39_0_split
I0928 19:59:17.560469  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.560472  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.560475  5237 net.cpp:137] Memory required for data: 1046529200
I0928 19:59:17.560477  5237 layer_factory.hpp:77] Creating layer Convolution42
I0928 19:59:17.560483  5237 net.cpp:84] Creating Layer Convolution42
I0928 19:59:17.560487  5237 net.cpp:406] Convolution42 <- Eltwise19_penlu39_0_split_0
I0928 19:59:17.560492  5237 net.cpp:380] Convolution42 -> Convolution42
I0928 19:59:17.562680  5237 net.cpp:122] Setting up Convolution42
I0928 19:59:17.562690  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.562692  5237 net.cpp:137] Memory required for data: 1048167600
I0928 19:59:17.562696  5237 layer_factory.hpp:77] Creating layer BatchNorm42
I0928 19:59:17.562702  5237 net.cpp:84] Creating Layer BatchNorm42
I0928 19:59:17.562705  5237 net.cpp:406] BatchNorm42 <- Convolution42
I0928 19:59:17.562710  5237 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I0928 19:59:17.562847  5237 net.cpp:122] Setting up BatchNorm42
I0928 19:59:17.562851  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.562853  5237 net.cpp:137] Memory required for data: 1049806000
I0928 19:59:17.562858  5237 layer_factory.hpp:77] Creating layer Scale42
I0928 19:59:17.562862  5237 net.cpp:84] Creating Layer Scale42
I0928 19:59:17.562865  5237 net.cpp:406] Scale42 <- Convolution42
I0928 19:59:17.562867  5237 net.cpp:367] Scale42 -> Convolution42 (in-place)
I0928 19:59:17.562897  5237 layer_factory.hpp:77] Creating layer Scale42
I0928 19:59:17.562975  5237 net.cpp:122] Setting up Scale42
I0928 19:59:17.562988  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.562990  5237 net.cpp:137] Memory required for data: 1051444400
I0928 19:59:17.562994  5237 layer_factory.hpp:77] Creating layer penlu40
I0928 19:59:17.562999  5237 net.cpp:84] Creating Layer penlu40
I0928 19:59:17.563001  5237 net.cpp:406] penlu40 <- Convolution42
I0928 19:59:17.563005  5237 net.cpp:367] penlu40 -> Convolution42 (in-place)
I0928 19:59:17.563127  5237 net.cpp:122] Setting up penlu40
I0928 19:59:17.563132  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.563133  5237 net.cpp:137] Memory required for data: 1053082800
I0928 19:59:17.563138  5237 layer_factory.hpp:77] Creating layer Convolution43
I0928 19:59:17.563144  5237 net.cpp:84] Creating Layer Convolution43
I0928 19:59:17.563148  5237 net.cpp:406] Convolution43 <- Convolution42
I0928 19:59:17.563151  5237 net.cpp:380] Convolution43 -> Convolution43
I0928 19:59:17.564981  5237 net.cpp:122] Setting up Convolution43
I0928 19:59:17.564990  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.564992  5237 net.cpp:137] Memory required for data: 1054721200
I0928 19:59:17.564996  5237 layer_factory.hpp:77] Creating layer BatchNorm43
I0928 19:59:17.565001  5237 net.cpp:84] Creating Layer BatchNorm43
I0928 19:59:17.565006  5237 net.cpp:406] BatchNorm43 <- Convolution43
I0928 19:59:17.565008  5237 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I0928 19:59:17.565145  5237 net.cpp:122] Setting up BatchNorm43
I0928 19:59:17.565148  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.565151  5237 net.cpp:137] Memory required for data: 1056359600
I0928 19:59:17.565155  5237 layer_factory.hpp:77] Creating layer Scale43
I0928 19:59:17.565160  5237 net.cpp:84] Creating Layer Scale43
I0928 19:59:17.565162  5237 net.cpp:406] Scale43 <- Convolution43
I0928 19:59:17.565165  5237 net.cpp:367] Scale43 -> Convolution43 (in-place)
I0928 19:59:17.565193  5237 layer_factory.hpp:77] Creating layer Scale43
I0928 19:59:17.565270  5237 net.cpp:122] Setting up Scale43
I0928 19:59:17.565274  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.565276  5237 net.cpp:137] Memory required for data: 1057998000
I0928 19:59:17.565280  5237 layer_factory.hpp:77] Creating layer Eltwise20
I0928 19:59:17.565285  5237 net.cpp:84] Creating Layer Eltwise20
I0928 19:59:17.565289  5237 net.cpp:406] Eltwise20 <- Eltwise19_penlu39_0_split_1
I0928 19:59:17.565291  5237 net.cpp:406] Eltwise20 <- Convolution43
I0928 19:59:17.565294  5237 net.cpp:380] Eltwise20 -> Eltwise20
I0928 19:59:17.565311  5237 net.cpp:122] Setting up Eltwise20
I0928 19:59:17.565315  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.565317  5237 net.cpp:137] Memory required for data: 1059636400
I0928 19:59:17.565318  5237 layer_factory.hpp:77] Creating layer penlu41
I0928 19:59:17.565325  5237 net.cpp:84] Creating Layer penlu41
I0928 19:59:17.565326  5237 net.cpp:406] penlu41 <- Eltwise20
I0928 19:59:17.565330  5237 net.cpp:367] penlu41 -> Eltwise20 (in-place)
I0928 19:59:17.565448  5237 net.cpp:122] Setting up penlu41
I0928 19:59:17.565451  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.565454  5237 net.cpp:137] Memory required for data: 1061274800
I0928 19:59:17.565457  5237 layer_factory.hpp:77] Creating layer Eltwise20_penlu41_0_split
I0928 19:59:17.565461  5237 net.cpp:84] Creating Layer Eltwise20_penlu41_0_split
I0928 19:59:17.565464  5237 net.cpp:406] Eltwise20_penlu41_0_split <- Eltwise20
I0928 19:59:17.565467  5237 net.cpp:380] Eltwise20_penlu41_0_split -> Eltwise20_penlu41_0_split_0
I0928 19:59:17.565472  5237 net.cpp:380] Eltwise20_penlu41_0_split -> Eltwise20_penlu41_0_split_1
I0928 19:59:17.565495  5237 net.cpp:122] Setting up Eltwise20_penlu41_0_split
I0928 19:59:17.565498  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.565501  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.565503  5237 net.cpp:137] Memory required for data: 1064551600
I0928 19:59:17.565505  5237 layer_factory.hpp:77] Creating layer Convolution44
I0928 19:59:17.565517  5237 net.cpp:84] Creating Layer Convolution44
I0928 19:59:17.565521  5237 net.cpp:406] Convolution44 <- Eltwise20_penlu41_0_split_0
I0928 19:59:17.565526  5237 net.cpp:380] Convolution44 -> Convolution44
I0928 19:59:17.567589  5237 net.cpp:122] Setting up Convolution44
I0928 19:59:17.567596  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.567600  5237 net.cpp:137] Memory required for data: 1066190000
I0928 19:59:17.567605  5237 layer_factory.hpp:77] Creating layer BatchNorm44
I0928 19:59:17.567610  5237 net.cpp:84] Creating Layer BatchNorm44
I0928 19:59:17.567612  5237 net.cpp:406] BatchNorm44 <- Convolution44
I0928 19:59:17.567616  5237 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I0928 19:59:17.567761  5237 net.cpp:122] Setting up BatchNorm44
I0928 19:59:17.567765  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.567769  5237 net.cpp:137] Memory required for data: 1067828400
I0928 19:59:17.567772  5237 layer_factory.hpp:77] Creating layer Scale44
I0928 19:59:17.567777  5237 net.cpp:84] Creating Layer Scale44
I0928 19:59:17.567780  5237 net.cpp:406] Scale44 <- Convolution44
I0928 19:59:17.567783  5237 net.cpp:367] Scale44 -> Convolution44 (in-place)
I0928 19:59:17.567811  5237 layer_factory.hpp:77] Creating layer Scale44
I0928 19:59:17.567898  5237 net.cpp:122] Setting up Scale44
I0928 19:59:17.567903  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.567905  5237 net.cpp:137] Memory required for data: 1069466800
I0928 19:59:17.567909  5237 layer_factory.hpp:77] Creating layer penlu42
I0928 19:59:17.567914  5237 net.cpp:84] Creating Layer penlu42
I0928 19:59:17.567916  5237 net.cpp:406] penlu42 <- Convolution44
I0928 19:59:17.567920  5237 net.cpp:367] penlu42 -> Convolution44 (in-place)
I0928 19:59:17.568034  5237 net.cpp:122] Setting up penlu42
I0928 19:59:17.568038  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.568040  5237 net.cpp:137] Memory required for data: 1071105200
I0928 19:59:17.568044  5237 layer_factory.hpp:77] Creating layer Convolution45
I0928 19:59:17.568051  5237 net.cpp:84] Creating Layer Convolution45
I0928 19:59:17.568053  5237 net.cpp:406] Convolution45 <- Convolution44
I0928 19:59:17.568058  5237 net.cpp:380] Convolution45 -> Convolution45
I0928 19:59:17.569761  5237 net.cpp:122] Setting up Convolution45
I0928 19:59:17.569769  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.569772  5237 net.cpp:137] Memory required for data: 1072743600
I0928 19:59:17.569777  5237 layer_factory.hpp:77] Creating layer BatchNorm45
I0928 19:59:17.569780  5237 net.cpp:84] Creating Layer BatchNorm45
I0928 19:59:17.569783  5237 net.cpp:406] BatchNorm45 <- Convolution45
I0928 19:59:17.569787  5237 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I0928 19:59:17.569923  5237 net.cpp:122] Setting up BatchNorm45
I0928 19:59:17.569927  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.569929  5237 net.cpp:137] Memory required for data: 1074382000
I0928 19:59:17.569934  5237 layer_factory.hpp:77] Creating layer Scale45
I0928 19:59:17.569938  5237 net.cpp:84] Creating Layer Scale45
I0928 19:59:17.569941  5237 net.cpp:406] Scale45 <- Convolution45
I0928 19:59:17.569944  5237 net.cpp:367] Scale45 -> Convolution45 (in-place)
I0928 19:59:17.569970  5237 layer_factory.hpp:77] Creating layer Scale45
I0928 19:59:17.570047  5237 net.cpp:122] Setting up Scale45
I0928 19:59:17.570051  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.570053  5237 net.cpp:137] Memory required for data: 1076020400
I0928 19:59:17.570057  5237 layer_factory.hpp:77] Creating layer Eltwise21
I0928 19:59:17.570061  5237 net.cpp:84] Creating Layer Eltwise21
I0928 19:59:17.570063  5237 net.cpp:406] Eltwise21 <- Eltwise20_penlu41_0_split_1
I0928 19:59:17.570066  5237 net.cpp:406] Eltwise21 <- Convolution45
I0928 19:59:17.570070  5237 net.cpp:380] Eltwise21 -> Eltwise21
I0928 19:59:17.570086  5237 net.cpp:122] Setting up Eltwise21
I0928 19:59:17.570091  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.570099  5237 net.cpp:137] Memory required for data: 1077658800
I0928 19:59:17.570101  5237 layer_factory.hpp:77] Creating layer penlu43
I0928 19:59:17.570106  5237 net.cpp:84] Creating Layer penlu43
I0928 19:59:17.570108  5237 net.cpp:406] penlu43 <- Eltwise21
I0928 19:59:17.570112  5237 net.cpp:367] penlu43 -> Eltwise21 (in-place)
I0928 19:59:17.570228  5237 net.cpp:122] Setting up penlu43
I0928 19:59:17.570233  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.570235  5237 net.cpp:137] Memory required for data: 1079297200
I0928 19:59:17.570240  5237 layer_factory.hpp:77] Creating layer Eltwise21_penlu43_0_split
I0928 19:59:17.570243  5237 net.cpp:84] Creating Layer Eltwise21_penlu43_0_split
I0928 19:59:17.570245  5237 net.cpp:406] Eltwise21_penlu43_0_split <- Eltwise21
I0928 19:59:17.570248  5237 net.cpp:380] Eltwise21_penlu43_0_split -> Eltwise21_penlu43_0_split_0
I0928 19:59:17.570253  5237 net.cpp:380] Eltwise21_penlu43_0_split -> Eltwise21_penlu43_0_split_1
I0928 19:59:17.570276  5237 net.cpp:122] Setting up Eltwise21_penlu43_0_split
I0928 19:59:17.570281  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.570282  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.570284  5237 net.cpp:137] Memory required for data: 1082574000
I0928 19:59:17.570286  5237 layer_factory.hpp:77] Creating layer Convolution46
I0928 19:59:17.570293  5237 net.cpp:84] Creating Layer Convolution46
I0928 19:59:17.570296  5237 net.cpp:406] Convolution46 <- Eltwise21_penlu43_0_split_0
I0928 19:59:17.570299  5237 net.cpp:380] Convolution46 -> Convolution46
I0928 19:59:17.572041  5237 net.cpp:122] Setting up Convolution46
I0928 19:59:17.572049  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.572052  5237 net.cpp:137] Memory required for data: 1084212400
I0928 19:59:17.572057  5237 layer_factory.hpp:77] Creating layer BatchNorm46
I0928 19:59:17.572062  5237 net.cpp:84] Creating Layer BatchNorm46
I0928 19:59:17.572064  5237 net.cpp:406] BatchNorm46 <- Convolution46
I0928 19:59:17.572068  5237 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I0928 19:59:17.572207  5237 net.cpp:122] Setting up BatchNorm46
I0928 19:59:17.572212  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.572214  5237 net.cpp:137] Memory required for data: 1085850800
I0928 19:59:17.572219  5237 layer_factory.hpp:77] Creating layer Scale46
I0928 19:59:17.572222  5237 net.cpp:84] Creating Layer Scale46
I0928 19:59:17.572226  5237 net.cpp:406] Scale46 <- Convolution46
I0928 19:59:17.572229  5237 net.cpp:367] Scale46 -> Convolution46 (in-place)
I0928 19:59:17.572255  5237 layer_factory.hpp:77] Creating layer Scale46
I0928 19:59:17.572335  5237 net.cpp:122] Setting up Scale46
I0928 19:59:17.572338  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.572340  5237 net.cpp:137] Memory required for data: 1087489200
I0928 19:59:17.572345  5237 layer_factory.hpp:77] Creating layer penlu44
I0928 19:59:17.572350  5237 net.cpp:84] Creating Layer penlu44
I0928 19:59:17.572352  5237 net.cpp:406] penlu44 <- Convolution46
I0928 19:59:17.572355  5237 net.cpp:367] penlu44 -> Convolution46 (in-place)
I0928 19:59:17.572473  5237 net.cpp:122] Setting up penlu44
I0928 19:59:17.572476  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.572479  5237 net.cpp:137] Memory required for data: 1089127600
I0928 19:59:17.572484  5237 layer_factory.hpp:77] Creating layer Convolution47
I0928 19:59:17.572489  5237 net.cpp:84] Creating Layer Convolution47
I0928 19:59:17.572492  5237 net.cpp:406] Convolution47 <- Convolution46
I0928 19:59:17.572495  5237 net.cpp:380] Convolution47 -> Convolution47
I0928 19:59:17.574180  5237 net.cpp:122] Setting up Convolution47
I0928 19:59:17.574189  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.574192  5237 net.cpp:137] Memory required for data: 1090766000
I0928 19:59:17.574196  5237 layer_factory.hpp:77] Creating layer BatchNorm47
I0928 19:59:17.574200  5237 net.cpp:84] Creating Layer BatchNorm47
I0928 19:59:17.574203  5237 net.cpp:406] BatchNorm47 <- Convolution47
I0928 19:59:17.574214  5237 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I0928 19:59:17.574352  5237 net.cpp:122] Setting up BatchNorm47
I0928 19:59:17.574357  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.574358  5237 net.cpp:137] Memory required for data: 1092404400
I0928 19:59:17.574362  5237 layer_factory.hpp:77] Creating layer Scale47
I0928 19:59:17.574367  5237 net.cpp:84] Creating Layer Scale47
I0928 19:59:17.574369  5237 net.cpp:406] Scale47 <- Convolution47
I0928 19:59:17.574373  5237 net.cpp:367] Scale47 -> Convolution47 (in-place)
I0928 19:59:17.574399  5237 layer_factory.hpp:77] Creating layer Scale47
I0928 19:59:17.574476  5237 net.cpp:122] Setting up Scale47
I0928 19:59:17.574481  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.574482  5237 net.cpp:137] Memory required for data: 1094042800
I0928 19:59:17.574486  5237 layer_factory.hpp:77] Creating layer Eltwise22
I0928 19:59:17.574489  5237 net.cpp:84] Creating Layer Eltwise22
I0928 19:59:17.574492  5237 net.cpp:406] Eltwise22 <- Eltwise21_penlu43_0_split_1
I0928 19:59:17.574496  5237 net.cpp:406] Eltwise22 <- Convolution47
I0928 19:59:17.574499  5237 net.cpp:380] Eltwise22 -> Eltwise22
I0928 19:59:17.574517  5237 net.cpp:122] Setting up Eltwise22
I0928 19:59:17.574534  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.574537  5237 net.cpp:137] Memory required for data: 1095681200
I0928 19:59:17.574539  5237 layer_factory.hpp:77] Creating layer penlu45
I0928 19:59:17.574544  5237 net.cpp:84] Creating Layer penlu45
I0928 19:59:17.574546  5237 net.cpp:406] penlu45 <- Eltwise22
I0928 19:59:17.574550  5237 net.cpp:367] penlu45 -> Eltwise22 (in-place)
I0928 19:59:17.574676  5237 net.cpp:122] Setting up penlu45
I0928 19:59:17.574681  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.574682  5237 net.cpp:137] Memory required for data: 1097319600
I0928 19:59:17.574687  5237 layer_factory.hpp:77] Creating layer Eltwise22_penlu45_0_split
I0928 19:59:17.574689  5237 net.cpp:84] Creating Layer Eltwise22_penlu45_0_split
I0928 19:59:17.574692  5237 net.cpp:406] Eltwise22_penlu45_0_split <- Eltwise22
I0928 19:59:17.574695  5237 net.cpp:380] Eltwise22_penlu45_0_split -> Eltwise22_penlu45_0_split_0
I0928 19:59:17.574699  5237 net.cpp:380] Eltwise22_penlu45_0_split -> Eltwise22_penlu45_0_split_1
I0928 19:59:17.574723  5237 net.cpp:122] Setting up Eltwise22_penlu45_0_split
I0928 19:59:17.574728  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.574729  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.574731  5237 net.cpp:137] Memory required for data: 1100596400
I0928 19:59:17.574733  5237 layer_factory.hpp:77] Creating layer Convolution48
I0928 19:59:17.574740  5237 net.cpp:84] Creating Layer Convolution48
I0928 19:59:17.574743  5237 net.cpp:406] Convolution48 <- Eltwise22_penlu45_0_split_0
I0928 19:59:17.574746  5237 net.cpp:380] Convolution48 -> Convolution48
I0928 19:59:17.576788  5237 net.cpp:122] Setting up Convolution48
I0928 19:59:17.576797  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.576799  5237 net.cpp:137] Memory required for data: 1102234800
I0928 19:59:17.576804  5237 layer_factory.hpp:77] Creating layer BatchNorm48
I0928 19:59:17.576809  5237 net.cpp:84] Creating Layer BatchNorm48
I0928 19:59:17.576812  5237 net.cpp:406] BatchNorm48 <- Convolution48
I0928 19:59:17.576817  5237 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I0928 19:59:17.576957  5237 net.cpp:122] Setting up BatchNorm48
I0928 19:59:17.576962  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.576964  5237 net.cpp:137] Memory required for data: 1103873200
I0928 19:59:17.576969  5237 layer_factory.hpp:77] Creating layer Scale48
I0928 19:59:17.576973  5237 net.cpp:84] Creating Layer Scale48
I0928 19:59:17.576977  5237 net.cpp:406] Scale48 <- Convolution48
I0928 19:59:17.576979  5237 net.cpp:367] Scale48 -> Convolution48 (in-place)
I0928 19:59:17.577006  5237 layer_factory.hpp:77] Creating layer Scale48
I0928 19:59:17.577087  5237 net.cpp:122] Setting up Scale48
I0928 19:59:17.577098  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.577100  5237 net.cpp:137] Memory required for data: 1105511600
I0928 19:59:17.577105  5237 layer_factory.hpp:77] Creating layer penlu46
I0928 19:59:17.577111  5237 net.cpp:84] Creating Layer penlu46
I0928 19:59:17.577112  5237 net.cpp:406] penlu46 <- Convolution48
I0928 19:59:17.577116  5237 net.cpp:367] penlu46 -> Convolution48 (in-place)
I0928 19:59:17.577232  5237 net.cpp:122] Setting up penlu46
I0928 19:59:17.577237  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.577239  5237 net.cpp:137] Memory required for data: 1107150000
I0928 19:59:17.577244  5237 layer_factory.hpp:77] Creating layer Convolution49
I0928 19:59:17.577250  5237 net.cpp:84] Creating Layer Convolution49
I0928 19:59:17.577252  5237 net.cpp:406] Convolution49 <- Convolution48
I0928 19:59:17.577256  5237 net.cpp:380] Convolution49 -> Convolution49
I0928 19:59:17.579313  5237 net.cpp:122] Setting up Convolution49
I0928 19:59:17.579321  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.579324  5237 net.cpp:137] Memory required for data: 1108788400
I0928 19:59:17.579329  5237 layer_factory.hpp:77] Creating layer BatchNorm49
I0928 19:59:17.579334  5237 net.cpp:84] Creating Layer BatchNorm49
I0928 19:59:17.579336  5237 net.cpp:406] BatchNorm49 <- Convolution49
I0928 19:59:17.579340  5237 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I0928 19:59:17.579479  5237 net.cpp:122] Setting up BatchNorm49
I0928 19:59:17.579484  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.579486  5237 net.cpp:137] Memory required for data: 1110426800
I0928 19:59:17.579490  5237 layer_factory.hpp:77] Creating layer Scale49
I0928 19:59:17.579494  5237 net.cpp:84] Creating Layer Scale49
I0928 19:59:17.579497  5237 net.cpp:406] Scale49 <- Convolution49
I0928 19:59:17.579500  5237 net.cpp:367] Scale49 -> Convolution49 (in-place)
I0928 19:59:17.579529  5237 layer_factory.hpp:77] Creating layer Scale49
I0928 19:59:17.579607  5237 net.cpp:122] Setting up Scale49
I0928 19:59:17.579612  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.579614  5237 net.cpp:137] Memory required for data: 1112065200
I0928 19:59:17.579617  5237 layer_factory.hpp:77] Creating layer Eltwise23
I0928 19:59:17.579622  5237 net.cpp:84] Creating Layer Eltwise23
I0928 19:59:17.579624  5237 net.cpp:406] Eltwise23 <- Eltwise22_penlu45_0_split_1
I0928 19:59:17.579627  5237 net.cpp:406] Eltwise23 <- Convolution49
I0928 19:59:17.579630  5237 net.cpp:380] Eltwise23 -> Eltwise23
I0928 19:59:17.579648  5237 net.cpp:122] Setting up Eltwise23
I0928 19:59:17.579650  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.579653  5237 net.cpp:137] Memory required for data: 1113703600
I0928 19:59:17.579654  5237 layer_factory.hpp:77] Creating layer penlu47
I0928 19:59:17.579660  5237 net.cpp:84] Creating Layer penlu47
I0928 19:59:17.579663  5237 net.cpp:406] penlu47 <- Eltwise23
I0928 19:59:17.579666  5237 net.cpp:367] penlu47 -> Eltwise23 (in-place)
I0928 19:59:17.579783  5237 net.cpp:122] Setting up penlu47
I0928 19:59:17.579787  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.579789  5237 net.cpp:137] Memory required for data: 1115342000
I0928 19:59:17.579793  5237 layer_factory.hpp:77] Creating layer Eltwise23_penlu47_0_split
I0928 19:59:17.579797  5237 net.cpp:84] Creating Layer Eltwise23_penlu47_0_split
I0928 19:59:17.579800  5237 net.cpp:406] Eltwise23_penlu47_0_split <- Eltwise23
I0928 19:59:17.579803  5237 net.cpp:380] Eltwise23_penlu47_0_split -> Eltwise23_penlu47_0_split_0
I0928 19:59:17.579807  5237 net.cpp:380] Eltwise23_penlu47_0_split -> Eltwise23_penlu47_0_split_1
I0928 19:59:17.579833  5237 net.cpp:122] Setting up Eltwise23_penlu47_0_split
I0928 19:59:17.579835  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.579838  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.579840  5237 net.cpp:137] Memory required for data: 1118618800
I0928 19:59:17.579843  5237 layer_factory.hpp:77] Creating layer Convolution50
I0928 19:59:17.579854  5237 net.cpp:84] Creating Layer Convolution50
I0928 19:59:17.579857  5237 net.cpp:406] Convolution50 <- Eltwise23_penlu47_0_split_0
I0928 19:59:17.579862  5237 net.cpp:380] Convolution50 -> Convolution50
I0928 19:59:17.582412  5237 net.cpp:122] Setting up Convolution50
I0928 19:59:17.582420  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.582423  5237 net.cpp:137] Memory required for data: 1120257200
I0928 19:59:17.582427  5237 layer_factory.hpp:77] Creating layer BatchNorm50
I0928 19:59:17.582432  5237 net.cpp:84] Creating Layer BatchNorm50
I0928 19:59:17.582435  5237 net.cpp:406] BatchNorm50 <- Convolution50
I0928 19:59:17.582439  5237 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I0928 19:59:17.582618  5237 net.cpp:122] Setting up BatchNorm50
I0928 19:59:17.582624  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.582626  5237 net.cpp:137] Memory required for data: 1121895600
I0928 19:59:17.582631  5237 layer_factory.hpp:77] Creating layer Scale50
I0928 19:59:17.582635  5237 net.cpp:84] Creating Layer Scale50
I0928 19:59:17.582638  5237 net.cpp:406] Scale50 <- Convolution50
I0928 19:59:17.582641  5237 net.cpp:367] Scale50 -> Convolution50 (in-place)
I0928 19:59:17.582669  5237 layer_factory.hpp:77] Creating layer Scale50
I0928 19:59:17.582749  5237 net.cpp:122] Setting up Scale50
I0928 19:59:17.582753  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.582756  5237 net.cpp:137] Memory required for data: 1123534000
I0928 19:59:17.582759  5237 layer_factory.hpp:77] Creating layer penlu48
I0928 19:59:17.582763  5237 net.cpp:84] Creating Layer penlu48
I0928 19:59:17.582767  5237 net.cpp:406] penlu48 <- Convolution50
I0928 19:59:17.582770  5237 net.cpp:367] penlu48 -> Convolution50 (in-place)
I0928 19:59:17.582886  5237 net.cpp:122] Setting up penlu48
I0928 19:59:17.582890  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.582892  5237 net.cpp:137] Memory required for data: 1125172400
I0928 19:59:17.582896  5237 layer_factory.hpp:77] Creating layer Convolution51
I0928 19:59:17.582903  5237 net.cpp:84] Creating Layer Convolution51
I0928 19:59:17.582906  5237 net.cpp:406] Convolution51 <- Convolution50
I0928 19:59:17.582911  5237 net.cpp:380] Convolution51 -> Convolution51
I0928 19:59:17.584604  5237 net.cpp:122] Setting up Convolution51
I0928 19:59:17.584611  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.584614  5237 net.cpp:137] Memory required for data: 1126810800
I0928 19:59:17.584619  5237 layer_factory.hpp:77] Creating layer BatchNorm51
I0928 19:59:17.584623  5237 net.cpp:84] Creating Layer BatchNorm51
I0928 19:59:17.584626  5237 net.cpp:406] BatchNorm51 <- Convolution51
I0928 19:59:17.584630  5237 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I0928 19:59:17.584765  5237 net.cpp:122] Setting up BatchNorm51
I0928 19:59:17.584769  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.584771  5237 net.cpp:137] Memory required for data: 1128449200
I0928 19:59:17.584776  5237 layer_factory.hpp:77] Creating layer Scale51
I0928 19:59:17.584779  5237 net.cpp:84] Creating Layer Scale51
I0928 19:59:17.584782  5237 net.cpp:406] Scale51 <- Convolution51
I0928 19:59:17.584785  5237 net.cpp:367] Scale51 -> Convolution51 (in-place)
I0928 19:59:17.584813  5237 layer_factory.hpp:77] Creating layer Scale51
I0928 19:59:17.584890  5237 net.cpp:122] Setting up Scale51
I0928 19:59:17.584895  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.584897  5237 net.cpp:137] Memory required for data: 1130087600
I0928 19:59:17.584902  5237 layer_factory.hpp:77] Creating layer Eltwise24
I0928 19:59:17.584905  5237 net.cpp:84] Creating Layer Eltwise24
I0928 19:59:17.584908  5237 net.cpp:406] Eltwise24 <- Eltwise23_penlu47_0_split_1
I0928 19:59:17.584910  5237 net.cpp:406] Eltwise24 <- Convolution51
I0928 19:59:17.584914  5237 net.cpp:380] Eltwise24 -> Eltwise24
I0928 19:59:17.584930  5237 net.cpp:122] Setting up Eltwise24
I0928 19:59:17.584934  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.584935  5237 net.cpp:137] Memory required for data: 1131726000
I0928 19:59:17.584944  5237 layer_factory.hpp:77] Creating layer penlu49
I0928 19:59:17.584950  5237 net.cpp:84] Creating Layer penlu49
I0928 19:59:17.584954  5237 net.cpp:406] penlu49 <- Eltwise24
I0928 19:59:17.584957  5237 net.cpp:367] penlu49 -> Eltwise24 (in-place)
I0928 19:59:17.585073  5237 net.cpp:122] Setting up penlu49
I0928 19:59:17.585078  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.585079  5237 net.cpp:137] Memory required for data: 1133364400
I0928 19:59:17.585084  5237 layer_factory.hpp:77] Creating layer Eltwise24_penlu49_0_split
I0928 19:59:17.585088  5237 net.cpp:84] Creating Layer Eltwise24_penlu49_0_split
I0928 19:59:17.585090  5237 net.cpp:406] Eltwise24_penlu49_0_split <- Eltwise24
I0928 19:59:17.585094  5237 net.cpp:380] Eltwise24_penlu49_0_split -> Eltwise24_penlu49_0_split_0
I0928 19:59:17.585098  5237 net.cpp:380] Eltwise24_penlu49_0_split -> Eltwise24_penlu49_0_split_1
I0928 19:59:17.585132  5237 net.cpp:122] Setting up Eltwise24_penlu49_0_split
I0928 19:59:17.590718  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.590729  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.590732  5237 net.cpp:137] Memory required for data: 1136641200
I0928 19:59:17.590735  5237 layer_factory.hpp:77] Creating layer Convolution52
I0928 19:59:17.590744  5237 net.cpp:84] Creating Layer Convolution52
I0928 19:59:17.590746  5237 net.cpp:406] Convolution52 <- Eltwise24_penlu49_0_split_0
I0928 19:59:17.590752  5237 net.cpp:380] Convolution52 -> Convolution52
I0928 19:59:17.592988  5237 net.cpp:122] Setting up Convolution52
I0928 19:59:17.592998  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.593000  5237 net.cpp:137] Memory required for data: 1138279600
I0928 19:59:17.593005  5237 layer_factory.hpp:77] Creating layer BatchNorm52
I0928 19:59:17.593011  5237 net.cpp:84] Creating Layer BatchNorm52
I0928 19:59:17.593014  5237 net.cpp:406] BatchNorm52 <- Convolution52
I0928 19:59:17.593019  5237 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I0928 19:59:17.593209  5237 net.cpp:122] Setting up BatchNorm52
I0928 19:59:17.593214  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.593215  5237 net.cpp:137] Memory required for data: 1139918000
I0928 19:59:17.593220  5237 layer_factory.hpp:77] Creating layer Scale52
I0928 19:59:17.593226  5237 net.cpp:84] Creating Layer Scale52
I0928 19:59:17.593230  5237 net.cpp:406] Scale52 <- Convolution52
I0928 19:59:17.593233  5237 net.cpp:367] Scale52 -> Convolution52 (in-place)
I0928 19:59:17.593263  5237 layer_factory.hpp:77] Creating layer Scale52
I0928 19:59:17.593348  5237 net.cpp:122] Setting up Scale52
I0928 19:59:17.593351  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.593353  5237 net.cpp:137] Memory required for data: 1141556400
I0928 19:59:17.593358  5237 layer_factory.hpp:77] Creating layer penlu50
I0928 19:59:17.593379  5237 net.cpp:84] Creating Layer penlu50
I0928 19:59:17.593382  5237 net.cpp:406] penlu50 <- Convolution52
I0928 19:59:17.593386  5237 net.cpp:367] penlu50 -> Convolution52 (in-place)
I0928 19:59:17.593510  5237 net.cpp:122] Setting up penlu50
I0928 19:59:17.593515  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.593518  5237 net.cpp:137] Memory required for data: 1143194800
I0928 19:59:17.593561  5237 layer_factory.hpp:77] Creating layer Convolution53
I0928 19:59:17.593569  5237 net.cpp:84] Creating Layer Convolution53
I0928 19:59:17.593572  5237 net.cpp:406] Convolution53 <- Convolution52
I0928 19:59:17.593576  5237 net.cpp:380] Convolution53 -> Convolution53
I0928 19:59:17.595423  5237 net.cpp:122] Setting up Convolution53
I0928 19:59:17.595432  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.595435  5237 net.cpp:137] Memory required for data: 1144833200
I0928 19:59:17.595439  5237 layer_factory.hpp:77] Creating layer BatchNorm53
I0928 19:59:17.595445  5237 net.cpp:84] Creating Layer BatchNorm53
I0928 19:59:17.595448  5237 net.cpp:406] BatchNorm53 <- Convolution53
I0928 19:59:17.595460  5237 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I0928 19:59:17.595603  5237 net.cpp:122] Setting up BatchNorm53
I0928 19:59:17.595608  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.595610  5237 net.cpp:137] Memory required for data: 1146471600
I0928 19:59:17.595615  5237 layer_factory.hpp:77] Creating layer Scale53
I0928 19:59:17.595619  5237 net.cpp:84] Creating Layer Scale53
I0928 19:59:17.595623  5237 net.cpp:406] Scale53 <- Convolution53
I0928 19:59:17.595625  5237 net.cpp:367] Scale53 -> Convolution53 (in-place)
I0928 19:59:17.595654  5237 layer_factory.hpp:77] Creating layer Scale53
I0928 19:59:17.595737  5237 net.cpp:122] Setting up Scale53
I0928 19:59:17.595741  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.595744  5237 net.cpp:137] Memory required for data: 1148110000
I0928 19:59:17.595747  5237 layer_factory.hpp:77] Creating layer Eltwise25
I0928 19:59:17.595752  5237 net.cpp:84] Creating Layer Eltwise25
I0928 19:59:17.595755  5237 net.cpp:406] Eltwise25 <- Eltwise24_penlu49_0_split_1
I0928 19:59:17.595759  5237 net.cpp:406] Eltwise25 <- Convolution53
I0928 19:59:17.595762  5237 net.cpp:380] Eltwise25 -> Eltwise25
I0928 19:59:17.595779  5237 net.cpp:122] Setting up Eltwise25
I0928 19:59:17.595783  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.595784  5237 net.cpp:137] Memory required for data: 1149748400
I0928 19:59:17.595788  5237 layer_factory.hpp:77] Creating layer penlu51
I0928 19:59:17.595793  5237 net.cpp:84] Creating Layer penlu51
I0928 19:59:17.595795  5237 net.cpp:406] penlu51 <- Eltwise25
I0928 19:59:17.595798  5237 net.cpp:367] penlu51 -> Eltwise25 (in-place)
I0928 19:59:17.595919  5237 net.cpp:122] Setting up penlu51
I0928 19:59:17.595924  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.595927  5237 net.cpp:137] Memory required for data: 1151386800
I0928 19:59:17.595930  5237 layer_factory.hpp:77] Creating layer Eltwise25_penlu51_0_split
I0928 19:59:17.595934  5237 net.cpp:84] Creating Layer Eltwise25_penlu51_0_split
I0928 19:59:17.595937  5237 net.cpp:406] Eltwise25_penlu51_0_split <- Eltwise25
I0928 19:59:17.595940  5237 net.cpp:380] Eltwise25_penlu51_0_split -> Eltwise25_penlu51_0_split_0
I0928 19:59:17.595944  5237 net.cpp:380] Eltwise25_penlu51_0_split -> Eltwise25_penlu51_0_split_1
I0928 19:59:17.595968  5237 net.cpp:122] Setting up Eltwise25_penlu51_0_split
I0928 19:59:17.595971  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.595974  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.595976  5237 net.cpp:137] Memory required for data: 1154663600
I0928 19:59:17.595978  5237 layer_factory.hpp:77] Creating layer Convolution54
I0928 19:59:17.595985  5237 net.cpp:84] Creating Layer Convolution54
I0928 19:59:17.595988  5237 net.cpp:406] Convolution54 <- Eltwise25_penlu51_0_split_0
I0928 19:59:17.595991  5237 net.cpp:380] Convolution54 -> Convolution54
I0928 19:59:17.598053  5237 net.cpp:122] Setting up Convolution54
I0928 19:59:17.598062  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.598065  5237 net.cpp:137] Memory required for data: 1156302000
I0928 19:59:17.598069  5237 layer_factory.hpp:77] Creating layer BatchNorm54
I0928 19:59:17.598075  5237 net.cpp:84] Creating Layer BatchNorm54
I0928 19:59:17.598078  5237 net.cpp:406] BatchNorm54 <- Convolution54
I0928 19:59:17.598081  5237 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I0928 19:59:17.598230  5237 net.cpp:122] Setting up BatchNorm54
I0928 19:59:17.598234  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.598237  5237 net.cpp:137] Memory required for data: 1157940400
I0928 19:59:17.598242  5237 layer_factory.hpp:77] Creating layer Scale54
I0928 19:59:17.598246  5237 net.cpp:84] Creating Layer Scale54
I0928 19:59:17.598249  5237 net.cpp:406] Scale54 <- Convolution54
I0928 19:59:17.598253  5237 net.cpp:367] Scale54 -> Convolution54 (in-place)
I0928 19:59:17.598281  5237 layer_factory.hpp:77] Creating layer Scale54
I0928 19:59:17.598363  5237 net.cpp:122] Setting up Scale54
I0928 19:59:17.598374  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.598377  5237 net.cpp:137] Memory required for data: 1159578800
I0928 19:59:17.598381  5237 layer_factory.hpp:77] Creating layer penlu52
I0928 19:59:17.598387  5237 net.cpp:84] Creating Layer penlu52
I0928 19:59:17.598389  5237 net.cpp:406] penlu52 <- Convolution54
I0928 19:59:17.598393  5237 net.cpp:367] penlu52 -> Convolution54 (in-place)
I0928 19:59:17.598515  5237 net.cpp:122] Setting up penlu52
I0928 19:59:17.598520  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.598536  5237 net.cpp:137] Memory required for data: 1161217200
I0928 19:59:17.598541  5237 layer_factory.hpp:77] Creating layer Convolution55
I0928 19:59:17.598558  5237 net.cpp:84] Creating Layer Convolution55
I0928 19:59:17.598562  5237 net.cpp:406] Convolution55 <- Convolution54
I0928 19:59:17.598565  5237 net.cpp:380] Convolution55 -> Convolution55
I0928 19:59:17.600273  5237 net.cpp:122] Setting up Convolution55
I0928 19:59:17.600281  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.600284  5237 net.cpp:137] Memory required for data: 1162855600
I0928 19:59:17.600288  5237 layer_factory.hpp:77] Creating layer BatchNorm55
I0928 19:59:17.600294  5237 net.cpp:84] Creating Layer BatchNorm55
I0928 19:59:17.600296  5237 net.cpp:406] BatchNorm55 <- Convolution55
I0928 19:59:17.600301  5237 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I0928 19:59:17.600441  5237 net.cpp:122] Setting up BatchNorm55
I0928 19:59:17.600445  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.600447  5237 net.cpp:137] Memory required for data: 1164494000
I0928 19:59:17.600452  5237 layer_factory.hpp:77] Creating layer Scale55
I0928 19:59:17.600456  5237 net.cpp:84] Creating Layer Scale55
I0928 19:59:17.600458  5237 net.cpp:406] Scale55 <- Convolution55
I0928 19:59:17.600462  5237 net.cpp:367] Scale55 -> Convolution55 (in-place)
I0928 19:59:17.600489  5237 layer_factory.hpp:77] Creating layer Scale55
I0928 19:59:17.600569  5237 net.cpp:122] Setting up Scale55
I0928 19:59:17.600574  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.600575  5237 net.cpp:137] Memory required for data: 1166132400
I0928 19:59:17.600579  5237 layer_factory.hpp:77] Creating layer Eltwise26
I0928 19:59:17.600582  5237 net.cpp:84] Creating Layer Eltwise26
I0928 19:59:17.600585  5237 net.cpp:406] Eltwise26 <- Eltwise25_penlu51_0_split_1
I0928 19:59:17.600589  5237 net.cpp:406] Eltwise26 <- Convolution55
I0928 19:59:17.600591  5237 net.cpp:380] Eltwise26 -> Eltwise26
I0928 19:59:17.600608  5237 net.cpp:122] Setting up Eltwise26
I0928 19:59:17.600612  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.600613  5237 net.cpp:137] Memory required for data: 1167770800
I0928 19:59:17.600615  5237 layer_factory.hpp:77] Creating layer penlu53
I0928 19:59:17.600620  5237 net.cpp:84] Creating Layer penlu53
I0928 19:59:17.600622  5237 net.cpp:406] penlu53 <- Eltwise26
I0928 19:59:17.600626  5237 net.cpp:367] penlu53 -> Eltwise26 (in-place)
I0928 19:59:17.600744  5237 net.cpp:122] Setting up penlu53
I0928 19:59:17.600749  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.600750  5237 net.cpp:137] Memory required for data: 1169409200
I0928 19:59:17.600754  5237 layer_factory.hpp:77] Creating layer Eltwise26_penlu53_0_split
I0928 19:59:17.600757  5237 net.cpp:84] Creating Layer Eltwise26_penlu53_0_split
I0928 19:59:17.600760  5237 net.cpp:406] Eltwise26_penlu53_0_split <- Eltwise26
I0928 19:59:17.600764  5237 net.cpp:380] Eltwise26_penlu53_0_split -> Eltwise26_penlu53_0_split_0
I0928 19:59:17.600767  5237 net.cpp:380] Eltwise26_penlu53_0_split -> Eltwise26_penlu53_0_split_1
I0928 19:59:17.600791  5237 net.cpp:122] Setting up Eltwise26_penlu53_0_split
I0928 19:59:17.600795  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.600797  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.600800  5237 net.cpp:137] Memory required for data: 1172686000
I0928 19:59:17.600801  5237 layer_factory.hpp:77] Creating layer Convolution56
I0928 19:59:17.600814  5237 net.cpp:84] Creating Layer Convolution56
I0928 19:59:17.600817  5237 net.cpp:406] Convolution56 <- Eltwise26_penlu53_0_split_0
I0928 19:59:17.600832  5237 net.cpp:380] Convolution56 -> Convolution56
I0928 19:59:17.602537  5237 net.cpp:122] Setting up Convolution56
I0928 19:59:17.602546  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.602550  5237 net.cpp:137] Memory required for data: 1174324400
I0928 19:59:17.602553  5237 layer_factory.hpp:77] Creating layer BatchNorm56
I0928 19:59:17.602567  5237 net.cpp:84] Creating Layer BatchNorm56
I0928 19:59:17.602571  5237 net.cpp:406] BatchNorm56 <- Convolution56
I0928 19:59:17.602574  5237 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I0928 19:59:17.602720  5237 net.cpp:122] Setting up BatchNorm56
I0928 19:59:17.602725  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.602726  5237 net.cpp:137] Memory required for data: 1175962800
I0928 19:59:17.602731  5237 layer_factory.hpp:77] Creating layer Scale56
I0928 19:59:17.602735  5237 net.cpp:84] Creating Layer Scale56
I0928 19:59:17.602737  5237 net.cpp:406] Scale56 <- Convolution56
I0928 19:59:17.602742  5237 net.cpp:367] Scale56 -> Convolution56 (in-place)
I0928 19:59:17.602771  5237 layer_factory.hpp:77] Creating layer Scale56
I0928 19:59:17.602849  5237 net.cpp:122] Setting up Scale56
I0928 19:59:17.602854  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.602856  5237 net.cpp:137] Memory required for data: 1177601200
I0928 19:59:17.602859  5237 layer_factory.hpp:77] Creating layer penlu54
I0928 19:59:17.602865  5237 net.cpp:84] Creating Layer penlu54
I0928 19:59:17.602867  5237 net.cpp:406] penlu54 <- Convolution56
I0928 19:59:17.602871  5237 net.cpp:367] penlu54 -> Convolution56 (in-place)
I0928 19:59:17.603013  5237 net.cpp:122] Setting up penlu54
I0928 19:59:17.603019  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.603021  5237 net.cpp:137] Memory required for data: 1179239600
I0928 19:59:17.603025  5237 layer_factory.hpp:77] Creating layer Convolution57
I0928 19:59:17.603031  5237 net.cpp:84] Creating Layer Convolution57
I0928 19:59:17.603034  5237 net.cpp:406] Convolution57 <- Convolution56
I0928 19:59:17.603039  5237 net.cpp:380] Convolution57 -> Convolution57
I0928 19:59:17.604718  5237 net.cpp:122] Setting up Convolution57
I0928 19:59:17.604727  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.604729  5237 net.cpp:137] Memory required for data: 1180878000
I0928 19:59:17.604734  5237 layer_factory.hpp:77] Creating layer BatchNorm57
I0928 19:59:17.604738  5237 net.cpp:84] Creating Layer BatchNorm57
I0928 19:59:17.604742  5237 net.cpp:406] BatchNorm57 <- Convolution57
I0928 19:59:17.604745  5237 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I0928 19:59:17.604887  5237 net.cpp:122] Setting up BatchNorm57
I0928 19:59:17.604890  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.604892  5237 net.cpp:137] Memory required for data: 1182516400
I0928 19:59:17.604897  5237 layer_factory.hpp:77] Creating layer Scale57
I0928 19:59:17.604902  5237 net.cpp:84] Creating Layer Scale57
I0928 19:59:17.604903  5237 net.cpp:406] Scale57 <- Convolution57
I0928 19:59:17.604907  5237 net.cpp:367] Scale57 -> Convolution57 (in-place)
I0928 19:59:17.604934  5237 layer_factory.hpp:77] Creating layer Scale57
I0928 19:59:17.605015  5237 net.cpp:122] Setting up Scale57
I0928 19:59:17.605020  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.605021  5237 net.cpp:137] Memory required for data: 1184154800
I0928 19:59:17.605026  5237 layer_factory.hpp:77] Creating layer Eltwise27
I0928 19:59:17.605031  5237 net.cpp:84] Creating Layer Eltwise27
I0928 19:59:17.605033  5237 net.cpp:406] Eltwise27 <- Eltwise26_penlu53_0_split_1
I0928 19:59:17.605036  5237 net.cpp:406] Eltwise27 <- Convolution57
I0928 19:59:17.605039  5237 net.cpp:380] Eltwise27 -> Eltwise27
I0928 19:59:17.605057  5237 net.cpp:122] Setting up Eltwise27
I0928 19:59:17.605060  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.605062  5237 net.cpp:137] Memory required for data: 1185793200
I0928 19:59:17.605070  5237 layer_factory.hpp:77] Creating layer penlu55
I0928 19:59:17.605077  5237 net.cpp:84] Creating Layer penlu55
I0928 19:59:17.605078  5237 net.cpp:406] penlu55 <- Eltwise27
I0928 19:59:17.605082  5237 net.cpp:367] penlu55 -> Eltwise27 (in-place)
I0928 19:59:17.605204  5237 net.cpp:122] Setting up penlu55
I0928 19:59:17.605208  5237 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0928 19:59:17.605211  5237 net.cpp:137] Memory required for data: 1187431600
I0928 19:59:17.605216  5237 layer_factory.hpp:77] Creating layer Pooling1
I0928 19:59:17.605221  5237 net.cpp:84] Creating Layer Pooling1
I0928 19:59:17.605222  5237 net.cpp:406] Pooling1 <- Eltwise27
I0928 19:59:17.605226  5237 net.cpp:380] Pooling1 -> Pooling1
I0928 19:59:17.605700  5237 net.cpp:122] Setting up Pooling1
I0928 19:59:17.605708  5237 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0928 19:59:17.621479  5237 net.cpp:137] Memory required for data: 1187457200
I0928 19:59:17.621486  5237 layer_factory.hpp:77] Creating layer InnerProduct1
I0928 19:59:17.621495  5237 net.cpp:84] Creating Layer InnerProduct1
I0928 19:59:17.621497  5237 net.cpp:406] InnerProduct1 <- Pooling1
I0928 19:59:17.621502  5237 net.cpp:380] InnerProduct1 -> InnerProduct1
I0928 19:59:17.621630  5237 net.cpp:122] Setting up InnerProduct1
I0928 19:59:17.621636  5237 net.cpp:129] Top shape: 100 10 (1000)
I0928 19:59:17.621639  5237 net.cpp:137] Memory required for data: 1187461200
I0928 19:59:17.621644  5237 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0928 19:59:17.621647  5237 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I0928 19:59:17.621650  5237 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0928 19:59:17.621654  5237 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0928 19:59:17.621659  5237 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0928 19:59:17.621688  5237 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I0928 19:59:17.621692  5237 net.cpp:129] Top shape: 100 10 (1000)
I0928 19:59:17.621695  5237 net.cpp:129] Top shape: 100 10 (1000)
I0928 19:59:17.621697  5237 net.cpp:137] Memory required for data: 1187469200
I0928 19:59:17.621701  5237 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0928 19:59:17.621706  5237 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0928 19:59:17.621707  5237 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I0928 19:59:17.621711  5237 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I0928 19:59:17.621714  5237 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0928 19:59:17.621719  5237 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0928 19:59:17.621943  5237 net.cpp:122] Setting up SoftmaxWithLoss1
I0928 19:59:17.621950  5237 net.cpp:129] Top shape: (1)
I0928 19:59:17.621953  5237 net.cpp:132]     with loss weight 1
I0928 19:59:17.621960  5237 net.cpp:137] Memory required for data: 1187469204
I0928 19:59:17.621963  5237 layer_factory.hpp:77] Creating layer Accuracy1
I0928 19:59:17.621969  5237 net.cpp:84] Creating Layer Accuracy1
I0928 19:59:17.621973  5237 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I0928 19:59:17.621976  5237 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I0928 19:59:17.621979  5237 net.cpp:380] Accuracy1 -> Accuracy1
I0928 19:59:17.621985  5237 net.cpp:122] Setting up Accuracy1
I0928 19:59:17.621989  5237 net.cpp:129] Top shape: (1)
I0928 19:59:17.621991  5237 net.cpp:137] Memory required for data: 1187469208
I0928 19:59:17.621994  5237 net.cpp:200] Accuracy1 does not need backward computation.
I0928 19:59:17.621996  5237 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0928 19:59:17.621999  5237 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0928 19:59:17.622001  5237 net.cpp:198] InnerProduct1 needs backward computation.
I0928 19:59:17.622004  5237 net.cpp:198] Pooling1 needs backward computation.
I0928 19:59:17.622006  5237 net.cpp:198] penlu55 needs backward computation.
I0928 19:59:17.622016  5237 net.cpp:198] Eltwise27 needs backward computation.
I0928 19:59:17.622020  5237 net.cpp:198] Scale57 needs backward computation.
I0928 19:59:17.622022  5237 net.cpp:198] BatchNorm57 needs backward computation.
I0928 19:59:17.622025  5237 net.cpp:198] Convolution57 needs backward computation.
I0928 19:59:17.622026  5237 net.cpp:198] penlu54 needs backward computation.
I0928 19:59:17.622028  5237 net.cpp:198] Scale56 needs backward computation.
I0928 19:59:17.622030  5237 net.cpp:198] BatchNorm56 needs backward computation.
I0928 19:59:17.622032  5237 net.cpp:198] Convolution56 needs backward computation.
I0928 19:59:17.622035  5237 net.cpp:198] Eltwise26_penlu53_0_split needs backward computation.
I0928 19:59:17.622037  5237 net.cpp:198] penlu53 needs backward computation.
I0928 19:59:17.622040  5237 net.cpp:198] Eltwise26 needs backward computation.
I0928 19:59:17.622042  5237 net.cpp:198] Scale55 needs backward computation.
I0928 19:59:17.622045  5237 net.cpp:198] BatchNorm55 needs backward computation.
I0928 19:59:17.622047  5237 net.cpp:198] Convolution55 needs backward computation.
I0928 19:59:17.622050  5237 net.cpp:198] penlu52 needs backward computation.
I0928 19:59:17.622051  5237 net.cpp:198] Scale54 needs backward computation.
I0928 19:59:17.622053  5237 net.cpp:198] BatchNorm54 needs backward computation.
I0928 19:59:17.622056  5237 net.cpp:198] Convolution54 needs backward computation.
I0928 19:59:17.622057  5237 net.cpp:198] Eltwise25_penlu51_0_split needs backward computation.
I0928 19:59:17.622061  5237 net.cpp:198] penlu51 needs backward computation.
I0928 19:59:17.622062  5237 net.cpp:198] Eltwise25 needs backward computation.
I0928 19:59:17.622066  5237 net.cpp:198] Scale53 needs backward computation.
I0928 19:59:17.622067  5237 net.cpp:198] BatchNorm53 needs backward computation.
I0928 19:59:17.622069  5237 net.cpp:198] Convolution53 needs backward computation.
I0928 19:59:17.622071  5237 net.cpp:198] penlu50 needs backward computation.
I0928 19:59:17.622073  5237 net.cpp:198] Scale52 needs backward computation.
I0928 19:59:17.622076  5237 net.cpp:198] BatchNorm52 needs backward computation.
I0928 19:59:17.622078  5237 net.cpp:198] Convolution52 needs backward computation.
I0928 19:59:17.622081  5237 net.cpp:198] Eltwise24_penlu49_0_split needs backward computation.
I0928 19:59:17.622084  5237 net.cpp:198] penlu49 needs backward computation.
I0928 19:59:17.622087  5237 net.cpp:198] Eltwise24 needs backward computation.
I0928 19:59:17.622089  5237 net.cpp:198] Scale51 needs backward computation.
I0928 19:59:17.622092  5237 net.cpp:198] BatchNorm51 needs backward computation.
I0928 19:59:17.622093  5237 net.cpp:198] Convolution51 needs backward computation.
I0928 19:59:17.622095  5237 net.cpp:198] penlu48 needs backward computation.
I0928 19:59:17.622098  5237 net.cpp:198] Scale50 needs backward computation.
I0928 19:59:17.622100  5237 net.cpp:198] BatchNorm50 needs backward computation.
I0928 19:59:17.622102  5237 net.cpp:198] Convolution50 needs backward computation.
I0928 19:59:17.622104  5237 net.cpp:198] Eltwise23_penlu47_0_split needs backward computation.
I0928 19:59:17.622107  5237 net.cpp:198] penlu47 needs backward computation.
I0928 19:59:17.622109  5237 net.cpp:198] Eltwise23 needs backward computation.
I0928 19:59:17.622112  5237 net.cpp:198] Scale49 needs backward computation.
I0928 19:59:17.622114  5237 net.cpp:198] BatchNorm49 needs backward computation.
I0928 19:59:17.622117  5237 net.cpp:198] Convolution49 needs backward computation.
I0928 19:59:17.622119  5237 net.cpp:198] penlu46 needs backward computation.
I0928 19:59:17.622122  5237 net.cpp:198] Scale48 needs backward computation.
I0928 19:59:17.622124  5237 net.cpp:198] BatchNorm48 needs backward computation.
I0928 19:59:17.622126  5237 net.cpp:198] Convolution48 needs backward computation.
I0928 19:59:17.622128  5237 net.cpp:198] Eltwise22_penlu45_0_split needs backward computation.
I0928 19:59:17.622131  5237 net.cpp:198] penlu45 needs backward computation.
I0928 19:59:17.622138  5237 net.cpp:198] Eltwise22 needs backward computation.
I0928 19:59:17.622139  5237 net.cpp:198] Scale47 needs backward computation.
I0928 19:59:17.622143  5237 net.cpp:198] BatchNorm47 needs backward computation.
I0928 19:59:17.622144  5237 net.cpp:198] Convolution47 needs backward computation.
I0928 19:59:17.622148  5237 net.cpp:198] penlu44 needs backward computation.
I0928 19:59:17.622149  5237 net.cpp:198] Scale46 needs backward computation.
I0928 19:59:17.622151  5237 net.cpp:198] BatchNorm46 needs backward computation.
I0928 19:59:17.622153  5237 net.cpp:198] Convolution46 needs backward computation.
I0928 19:59:17.622156  5237 net.cpp:198] Eltwise21_penlu43_0_split needs backward computation.
I0928 19:59:17.622159  5237 net.cpp:198] penlu43 needs backward computation.
I0928 19:59:17.652020  5237 net.cpp:198] Eltwise21 needs backward computation.
I0928 19:59:17.652029  5237 net.cpp:198] Scale45 needs backward computation.
I0928 19:59:17.652032  5237 net.cpp:198] BatchNorm45 needs backward computation.
I0928 19:59:17.652035  5237 net.cpp:198] Convolution45 needs backward computation.
I0928 19:59:17.652037  5237 net.cpp:198] penlu42 needs backward computation.
I0928 19:59:17.652040  5237 net.cpp:198] Scale44 needs backward computation.
I0928 19:59:17.652042  5237 net.cpp:198] BatchNorm44 needs backward computation.
I0928 19:59:17.652045  5237 net.cpp:198] Convolution44 needs backward computation.
I0928 19:59:17.652047  5237 net.cpp:198] Eltwise20_penlu41_0_split needs backward computation.
I0928 19:59:17.652050  5237 net.cpp:198] penlu41 needs backward computation.
I0928 19:59:17.652052  5237 net.cpp:198] Eltwise20 needs backward computation.
I0928 19:59:17.652055  5237 net.cpp:198] Scale43 needs backward computation.
I0928 19:59:17.652058  5237 net.cpp:198] BatchNorm43 needs backward computation.
I0928 19:59:17.652060  5237 net.cpp:198] Convolution43 needs backward computation.
I0928 19:59:17.652062  5237 net.cpp:198] penlu40 needs backward computation.
I0928 19:59:17.652065  5237 net.cpp:198] Scale42 needs backward computation.
I0928 19:59:17.652067  5237 net.cpp:198] BatchNorm42 needs backward computation.
I0928 19:59:17.652070  5237 net.cpp:198] Convolution42 needs backward computation.
I0928 19:59:17.652073  5237 net.cpp:198] Eltwise19_penlu39_0_split needs backward computation.
I0928 19:59:17.652076  5237 net.cpp:198] penlu39 needs backward computation.
I0928 19:59:17.652078  5237 net.cpp:198] Eltwise19 needs backward computation.
I0928 19:59:17.652081  5237 net.cpp:198] Scale41 needs backward computation.
I0928 19:59:17.652083  5237 net.cpp:198] BatchNorm41 needs backward computation.
I0928 19:59:17.652086  5237 net.cpp:198] Convolution41 needs backward computation.
I0928 19:59:17.652089  5237 net.cpp:198] penlu38 needs backward computation.
I0928 19:59:17.652091  5237 net.cpp:198] Scale40 needs backward computation.
I0928 19:59:17.652093  5237 net.cpp:198] BatchNorm40 needs backward computation.
I0928 19:59:17.652096  5237 net.cpp:198] Convolution40 needs backward computation.
I0928 19:59:17.652099  5237 net.cpp:198] Scale39 needs backward computation.
I0928 19:59:17.652101  5237 net.cpp:198] BatchNorm39 needs backward computation.
I0928 19:59:17.652104  5237 net.cpp:198] Convolution39 needs backward computation.
I0928 19:59:17.652107  5237 net.cpp:198] Eltwise18_penlu37_0_split needs backward computation.
I0928 19:59:17.652109  5237 net.cpp:198] penlu37 needs backward computation.
I0928 19:59:17.652112  5237 net.cpp:198] Eltwise18 needs backward computation.
I0928 19:59:17.652114  5237 net.cpp:198] Scale38 needs backward computation.
I0928 19:59:17.652117  5237 net.cpp:198] BatchNorm38 needs backward computation.
I0928 19:59:17.652119  5237 net.cpp:198] Convolution38 needs backward computation.
I0928 19:59:17.652122  5237 net.cpp:198] penlu36 needs backward computation.
I0928 19:59:17.652124  5237 net.cpp:198] Scale37 needs backward computation.
I0928 19:59:17.652127  5237 net.cpp:198] BatchNorm37 needs backward computation.
I0928 19:59:17.652129  5237 net.cpp:198] Convolution37 needs backward computation.
I0928 19:59:17.652140  5237 net.cpp:198] Eltwise17_penlu35_0_split needs backward computation.
I0928 19:59:17.652143  5237 net.cpp:198] penlu35 needs backward computation.
I0928 19:59:17.652146  5237 net.cpp:198] Eltwise17 needs backward computation.
I0928 19:59:17.652149  5237 net.cpp:198] Scale36 needs backward computation.
I0928 19:59:17.652151  5237 net.cpp:198] BatchNorm36 needs backward computation.
I0928 19:59:17.652153  5237 net.cpp:198] Convolution36 needs backward computation.
I0928 19:59:17.652156  5237 net.cpp:198] penlu34 needs backward computation.
I0928 19:59:17.652158  5237 net.cpp:198] Scale35 needs backward computation.
I0928 19:59:17.652160  5237 net.cpp:198] BatchNorm35 needs backward computation.
I0928 19:59:17.652163  5237 net.cpp:198] Convolution35 needs backward computation.
I0928 19:59:17.652166  5237 net.cpp:198] Eltwise16_penlu33_0_split needs backward computation.
I0928 19:59:17.652169  5237 net.cpp:198] penlu33 needs backward computation.
I0928 19:59:17.652171  5237 net.cpp:198] Eltwise16 needs backward computation.
I0928 19:59:17.652174  5237 net.cpp:198] Scale34 needs backward computation.
I0928 19:59:17.652176  5237 net.cpp:198] BatchNorm34 needs backward computation.
I0928 19:59:17.652179  5237 net.cpp:198] Convolution34 needs backward computation.
I0928 19:59:17.652181  5237 net.cpp:198] penlu32 needs backward computation.
I0928 19:59:17.652184  5237 net.cpp:198] Scale33 needs backward computation.
I0928 19:59:17.652186  5237 net.cpp:198] BatchNorm33 needs backward computation.
I0928 19:59:17.652189  5237 net.cpp:198] Convolution33 needs backward computation.
I0928 19:59:17.652191  5237 net.cpp:198] Eltwise15_penlu31_0_split needs backward computation.
I0928 19:59:17.652194  5237 net.cpp:198] penlu31 needs backward computation.
I0928 19:59:17.652196  5237 net.cpp:198] Eltwise15 needs backward computation.
I0928 19:59:17.652199  5237 net.cpp:198] Scale32 needs backward computation.
I0928 19:59:17.652201  5237 net.cpp:198] BatchNorm32 needs backward computation.
I0928 19:59:17.652204  5237 net.cpp:198] Convolution32 needs backward computation.
I0928 19:59:17.652206  5237 net.cpp:198] penlu30 needs backward computation.
I0928 19:59:17.652209  5237 net.cpp:198] Scale31 needs backward computation.
I0928 19:59:17.652211  5237 net.cpp:198] BatchNorm31 needs backward computation.
I0928 19:59:17.652214  5237 net.cpp:198] Convolution31 needs backward computation.
I0928 19:59:17.652216  5237 net.cpp:198] Eltwise14_penlu29_0_split needs backward computation.
I0928 19:59:17.652221  5237 net.cpp:198] penlu29 needs backward computation.
I0928 19:59:17.652225  5237 net.cpp:198] Eltwise14 needs backward computation.
I0928 19:59:17.652227  5237 net.cpp:198] Scale30 needs backward computation.
I0928 19:59:17.652230  5237 net.cpp:198] BatchNorm30 needs backward computation.
I0928 19:59:17.652232  5237 net.cpp:198] Convolution30 needs backward computation.
I0928 19:59:17.652235  5237 net.cpp:198] penlu28 needs backward computation.
I0928 19:59:17.652237  5237 net.cpp:198] Scale29 needs backward computation.
I0928 19:59:17.652240  5237 net.cpp:198] BatchNorm29 needs backward computation.
I0928 19:59:17.652242  5237 net.cpp:198] Convolution29 needs backward computation.
I0928 19:59:17.652245  5237 net.cpp:198] Eltwise13_penlu27_0_split needs backward computation.
I0928 19:59:17.652247  5237 net.cpp:198] penlu27 needs backward computation.
I0928 19:59:17.652249  5237 net.cpp:198] Eltwise13 needs backward computation.
I0928 19:59:17.652252  5237 net.cpp:198] Scale28 needs backward computation.
I0928 19:59:17.652256  5237 net.cpp:198] BatchNorm28 needs backward computation.
I0928 19:59:17.652257  5237 net.cpp:198] Convolution28 needs backward computation.
I0928 19:59:17.652261  5237 net.cpp:198] penlu26 needs backward computation.
I0928 19:59:17.652262  5237 net.cpp:198] Scale27 needs backward computation.
I0928 19:59:17.652264  5237 net.cpp:198] BatchNorm27 needs backward computation.
I0928 19:59:17.652267  5237 net.cpp:198] Convolution27 needs backward computation.
I0928 19:59:17.652273  5237 net.cpp:198] Eltwise12_penlu25_0_split needs backward computation.
I0928 19:59:17.652276  5237 net.cpp:198] penlu25 needs backward computation.
I0928 19:59:17.652278  5237 net.cpp:198] Eltwise12 needs backward computation.
I0928 19:59:17.652281  5237 net.cpp:198] Scale26 needs backward computation.
I0928 19:59:17.652284  5237 net.cpp:198] BatchNorm26 needs backward computation.
I0928 19:59:17.652287  5237 net.cpp:198] Convolution26 needs backward computation.
I0928 19:59:17.652288  5237 net.cpp:198] penlu24 needs backward computation.
I0928 19:59:17.652292  5237 net.cpp:198] Scale25 needs backward computation.
I0928 19:59:17.652293  5237 net.cpp:198] BatchNorm25 needs backward computation.
I0928 19:59:17.654443  5237 net.cpp:198] Convolution25 needs backward computation.
I0928 19:59:17.654451  5237 net.cpp:198] Eltwise11_penlu23_0_split needs backward computation.
I0928 19:59:17.654455  5237 net.cpp:198] penlu23 needs backward computation.
I0928 19:59:17.654458  5237 net.cpp:198] Eltwise11 needs backward computation.
I0928 19:59:17.654460  5237 net.cpp:198] Scale24 needs backward computation.
I0928 19:59:17.654464  5237 net.cpp:198] BatchNorm24 needs backward computation.
I0928 19:59:17.654465  5237 net.cpp:198] Convolution24 needs backward computation.
I0928 19:59:17.654469  5237 net.cpp:198] penlu22 needs backward computation.
I0928 19:59:17.654470  5237 net.cpp:198] Scale23 needs backward computation.
I0928 19:59:17.654472  5237 net.cpp:198] BatchNorm23 needs backward computation.
I0928 19:59:17.654474  5237 net.cpp:198] Convolution23 needs backward computation.
I0928 19:59:17.654477  5237 net.cpp:198] Eltwise10_penlu21_0_split needs backward computation.
I0928 19:59:17.654480  5237 net.cpp:198] penlu21 needs backward computation.
I0928 19:59:17.654482  5237 net.cpp:198] Eltwise10 needs backward computation.
I0928 19:59:17.654485  5237 net.cpp:198] Scale22 needs backward computation.
I0928 19:59:17.654489  5237 net.cpp:198] BatchNorm22 needs backward computation.
I0928 19:59:17.654490  5237 net.cpp:198] Convolution22 needs backward computation.
I0928 19:59:17.654494  5237 net.cpp:198] penlu20 needs backward computation.
I0928 19:59:17.654496  5237 net.cpp:198] Scale21 needs backward computation.
I0928 19:59:17.654498  5237 net.cpp:198] BatchNorm21 needs backward computation.
I0928 19:59:17.654501  5237 net.cpp:198] Convolution21 needs backward computation.
I0928 19:59:17.654503  5237 net.cpp:198] Scale20 needs backward computation.
I0928 19:59:17.654505  5237 net.cpp:198] BatchNorm20 needs backward computation.
I0928 19:59:17.654508  5237 net.cpp:198] Convolution20 needs backward computation.
I0928 19:59:17.654510  5237 net.cpp:198] Eltwise9_penlu19_0_split needs backward computation.
I0928 19:59:17.654513  5237 net.cpp:198] penlu19 needs backward computation.
I0928 19:59:17.654515  5237 net.cpp:198] Eltwise9 needs backward computation.
I0928 19:59:17.654518  5237 net.cpp:198] Scale19 needs backward computation.
I0928 19:59:17.654531  5237 net.cpp:198] BatchNorm19 needs backward computation.
I0928 19:59:17.654532  5237 net.cpp:198] Convolution19 needs backward computation.
I0928 19:59:17.654536  5237 net.cpp:198] penlu18 needs backward computation.
I0928 19:59:17.654537  5237 net.cpp:198] Scale18 needs backward computation.
I0928 19:59:17.654541  5237 net.cpp:198] BatchNorm18 needs backward computation.
I0928 19:59:17.654542  5237 net.cpp:198] Convolution18 needs backward computation.
I0928 19:59:17.654544  5237 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I0928 19:59:17.654547  5237 net.cpp:198] penlu17 needs backward computation.
I0928 19:59:17.654549  5237 net.cpp:198] Eltwise8 needs backward computation.
I0928 19:59:17.654552  5237 net.cpp:198] Scale17 needs backward computation.
I0928 19:59:17.654554  5237 net.cpp:198] BatchNorm17 needs backward computation.
I0928 19:59:17.654556  5237 net.cpp:198] Convolution17 needs backward computation.
I0928 19:59:17.654559  5237 net.cpp:198] penlu16 needs backward computation.
I0928 19:59:17.654563  5237 net.cpp:198] Scale16 needs backward computation.
I0928 19:59:17.654572  5237 net.cpp:198] BatchNorm16 needs backward computation.
I0928 19:59:17.654575  5237 net.cpp:198] Convolution16 needs backward computation.
I0928 19:59:17.654578  5237 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I0928 19:59:17.654580  5237 net.cpp:198] penlu15 needs backward computation.
I0928 19:59:17.654583  5237 net.cpp:198] Eltwise7 needs backward computation.
I0928 19:59:17.654585  5237 net.cpp:198] Scale15 needs backward computation.
I0928 19:59:17.654588  5237 net.cpp:198] BatchNorm15 needs backward computation.
I0928 19:59:17.654590  5237 net.cpp:198] Convolution15 needs backward computation.
I0928 19:59:17.654593  5237 net.cpp:198] penlu14 needs backward computation.
I0928 19:59:17.654595  5237 net.cpp:198] Scale14 needs backward computation.
I0928 19:59:17.654597  5237 net.cpp:198] BatchNorm14 needs backward computation.
I0928 19:59:17.654599  5237 net.cpp:198] Convolution14 needs backward computation.
I0928 19:59:17.654603  5237 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I0928 19:59:17.654605  5237 net.cpp:198] penlu13 needs backward computation.
I0928 19:59:17.654608  5237 net.cpp:198] Eltwise6 needs backward computation.
I0928 19:59:17.654610  5237 net.cpp:198] Scale13 needs backward computation.
I0928 19:59:17.654613  5237 net.cpp:198] BatchNorm13 needs backward computation.
I0928 19:59:17.654614  5237 net.cpp:198] Convolution13 needs backward computation.
I0928 19:59:17.654618  5237 net.cpp:198] penlu12 needs backward computation.
I0928 19:59:17.654619  5237 net.cpp:198] Scale12 needs backward computation.
I0928 19:59:17.654621  5237 net.cpp:198] BatchNorm12 needs backward computation.
I0928 19:59:17.654623  5237 net.cpp:198] Convolution12 needs backward computation.
I0928 19:59:17.654626  5237 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I0928 19:59:17.654628  5237 net.cpp:198] penlu11 needs backward computation.
I0928 19:59:17.654630  5237 net.cpp:198] Eltwise5 needs backward computation.
I0928 19:59:17.654633  5237 net.cpp:198] Scale11 needs backward computation.
I0928 19:59:17.654635  5237 net.cpp:198] BatchNorm11 needs backward computation.
I0928 19:59:17.654639  5237 net.cpp:198] Convolution11 needs backward computation.
I0928 19:59:17.654640  5237 net.cpp:198] penlu10 needs backward computation.
I0928 19:59:17.654642  5237 net.cpp:198] Scale10 needs backward computation.
I0928 19:59:17.654645  5237 net.cpp:198] BatchNorm10 needs backward computation.
I0928 19:59:17.654647  5237 net.cpp:198] Convolution10 needs backward computation.
I0928 19:59:17.654649  5237 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I0928 19:59:17.654652  5237 net.cpp:198] penlu9 needs backward computation.
I0928 19:59:17.654654  5237 net.cpp:198] Eltwise4 needs backward computation.
I0928 19:59:17.654659  5237 net.cpp:198] Scale9 needs backward computation.
I0928 19:59:17.654660  5237 net.cpp:198] BatchNorm9 needs backward computation.
I0928 19:59:17.654662  5237 net.cpp:198] Convolution9 needs backward computation.
I0928 19:59:17.654665  5237 net.cpp:198] penlu8 needs backward computation.
I0928 19:59:17.654667  5237 net.cpp:198] Scale8 needs backward computation.
I0928 19:59:17.654670  5237 net.cpp:198] BatchNorm8 needs backward computation.
I0928 19:59:17.654672  5237 net.cpp:198] Convolution8 needs backward computation.
I0928 19:59:17.654675  5237 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I0928 19:59:17.654677  5237 net.cpp:198] penlu7 needs backward computation.
I0928 19:59:17.654680  5237 net.cpp:198] Eltwise3 needs backward computation.
I0928 19:59:17.654682  5237 net.cpp:198] Scale7 needs backward computation.
I0928 19:59:17.654685  5237 net.cpp:198] BatchNorm7 needs backward computation.
I0928 19:59:17.654687  5237 net.cpp:198] Convolution7 needs backward computation.
I0928 19:59:17.654690  5237 net.cpp:198] penlu6 needs backward computation.
I0928 19:59:17.654691  5237 net.cpp:198] Scale6 needs backward computation.
I0928 19:59:17.654695  5237 net.cpp:198] BatchNorm6 needs backward computation.
I0928 19:59:17.654700  5237 net.cpp:198] Convolution6 needs backward computation.
I0928 19:59:17.654702  5237 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I0928 19:59:17.654706  5237 net.cpp:198] penlu5 needs backward computation.
I0928 19:59:17.654707  5237 net.cpp:198] Eltwise2 needs backward computation.
I0928 19:59:17.654711  5237 net.cpp:198] Scale5 needs backward computation.
I0928 19:59:17.654713  5237 net.cpp:198] BatchNorm5 needs backward computation.
I0928 19:59:17.654716  5237 net.cpp:198] Convolution5 needs backward computation.
I0928 19:59:17.654718  5237 net.cpp:198] penlu4 needs backward computation.
I0928 19:59:17.654721  5237 net.cpp:198] Scale4 needs backward computation.
I0928 19:59:17.654722  5237 net.cpp:198] BatchNorm4 needs backward computation.
I0928 19:59:17.654726  5237 net.cpp:198] Convolution4 needs backward computation.
I0928 19:59:17.654727  5237 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I0928 19:59:17.654731  5237 net.cpp:198] penlu3 needs backward computation.
I0928 19:59:17.654732  5237 net.cpp:198] Eltwise1 needs backward computation.
I0928 19:59:17.654736  5237 net.cpp:198] Scale3 needs backward computation.
I0928 19:59:17.654737  5237 net.cpp:198] BatchNorm3 needs backward computation.
I0928 19:59:17.654741  5237 net.cpp:198] Convolution3 needs backward computation.
I0928 19:59:17.654742  5237 net.cpp:198] penlu2 needs backward computation.
I0928 19:59:17.654744  5237 net.cpp:198] Scale2 needs backward computation.
I0928 19:59:17.654747  5237 net.cpp:198] BatchNorm2 needs backward computation.
I0928 19:59:17.654749  5237 net.cpp:198] Convolution2 needs backward computation.
I0928 19:59:17.654752  5237 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I0928 19:59:17.654754  5237 net.cpp:198] penlu1 needs backward computation.
I0928 19:59:17.654757  5237 net.cpp:198] Scale1 needs backward computation.
I0928 19:59:17.654759  5237 net.cpp:198] BatchNorm1 needs backward computation.
I0928 19:59:17.654762  5237 net.cpp:198] Convolution1 needs backward computation.
I0928 19:59:17.654764  5237 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I0928 19:59:17.654767  5237 net.cpp:200] Data1 does not need backward computation.
I0928 19:59:17.654778  5237 net.cpp:242] This network produces output Accuracy1
I0928 19:59:17.654780  5237 net.cpp:242] This network produces output SoftmaxWithLoss1
I0928 19:59:17.654886  5237 net.cpp:255] Network initialization done.
I0928 19:59:17.655956  5237 solver.cpp:56] Solver scaffolding done.
I0928 19:59:17.670686  5237 caffe.cpp:248] Starting Optimization
I0928 19:59:17.670693  5237 solver.cpp:272] Solving resnet_cifar10
I0928 19:59:17.670696  5237 solver.cpp:273] Learning Rate Policy: multistep
I0928 19:59:17.677667  5237 solver.cpp:330] Iteration 0, Testing net (#0)
I0928 19:59:21.128096  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 19:59:21.267858  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I0928 19:59:21.267892  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I0928 19:59:21.467196  5237 solver.cpp:218] Iteration 0 (-2.10195e-44 iter/s, 3.7964s/100 iters), loss = 2.31077
I0928 19:59:21.467227  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.31077 (* 1 = 2.31077 loss)
I0928 19:59:21.467242  5237 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I0928 19:59:36.016840  5237 solver.cpp:218] Iteration 100 (6.87309 iter/s, 14.5495s/100 iters), loss = 1.50124
I0928 19:59:36.016880  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.50124 (* 1 = 1.50124 loss)
I0928 19:59:36.016886  5237 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I0928 19:59:50.545047  5237 solver.cpp:218] Iteration 200 (6.88324 iter/s, 14.528s/100 iters), loss = 1.59928
I0928 19:59:50.545145  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.59928 (* 1 = 1.59928 loss)
I0928 19:59:50.545151  5237 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I0928 20:00:05.083495  5237 solver.cpp:218] Iteration 300 (6.87842 iter/s, 14.5382s/100 iters), loss = 1.36746
I0928 20:00:05.083536  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.36746 (* 1 = 1.36746 loss)
I0928 20:00:05.083542  5237 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I0928 20:00:19.633612  5237 solver.cpp:218] Iteration 400 (6.87288 iter/s, 14.55s/100 iters), loss = 1.31903
I0928 20:00:19.633651  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.31903 (* 1 = 1.31903 loss)
I0928 20:00:19.633657  5237 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I0928 20:00:33.465665  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:00:34.049211  5237 solver.cpp:330] Iteration 500, Testing net (#0)
I0928 20:00:37.459128  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:00:37.601562  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4214
I0928 20:00:37.601598  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.8701 (* 1 = 1.8701 loss)
I0928 20:00:37.746600  5237 solver.cpp:218] Iteration 500 (5.52096 iter/s, 18.1128s/100 iters), loss = 1.33221
I0928 20:00:37.746631  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.33221 (* 1 = 1.33221 loss)
I0928 20:00:37.746637  5237 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I0928 20:00:52.307044  5237 solver.cpp:218] Iteration 600 (6.86799 iter/s, 14.5603s/100 iters), loss = 1.20075
I0928 20:00:52.307082  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.20075 (* 1 = 1.20075 loss)
I0928 20:00:52.307088  5237 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I0928 20:01:06.869983  5237 solver.cpp:218] Iteration 700 (6.86682 iter/s, 14.5628s/100 iters), loss = 1.20713
I0928 20:01:06.870080  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.20713 (* 1 = 1.20713 loss)
I0928 20:01:06.870097  5237 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I0928 20:01:21.435361  5237 solver.cpp:218] Iteration 800 (6.86569 iter/s, 14.5652s/100 iters), loss = 1.02198
I0928 20:01:21.435401  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.02198 (* 1 = 1.02198 loss)
I0928 20:01:21.435406  5237 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I0928 20:01:35.994393  5237 solver.cpp:218] Iteration 900 (6.86866 iter/s, 14.5589s/100 iters), loss = 0.885264
I0928 20:01:35.994433  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.885264 (* 1 = 0.885264 loss)
I0928 20:01:35.994439  5237 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I0928 20:01:49.842705  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:01:50.425384  5237 solver.cpp:330] Iteration 1000, Testing net (#0)
I0928 20:01:53.837596  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:01:53.980868  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4282
I0928 20:01:53.980904  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.21774 (* 1 = 2.21774 loss)
I0928 20:01:54.125855  5237 solver.cpp:218] Iteration 1000 (5.51533 iter/s, 18.1313s/100 iters), loss = 1.06674
I0928 20:01:54.125886  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.06674 (* 1 = 1.06674 loss)
I0928 20:01:54.125892  5237 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I0928 20:02:08.688078  5237 solver.cpp:218] Iteration 1100 (6.86715 iter/s, 14.5621s/100 iters), loss = 0.917082
I0928 20:02:08.688118  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.917082 (* 1 = 0.917082 loss)
I0928 20:02:08.688124  5237 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I0928 20:02:23.253141  5237 solver.cpp:218] Iteration 1200 (6.86581 iter/s, 14.5649s/100 iters), loss = 0.98707
I0928 20:02:23.253279  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.98707 (* 1 = 0.98707 loss)
I0928 20:02:23.253288  5237 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I0928 20:02:37.815220  5237 solver.cpp:218] Iteration 1300 (6.86725 iter/s, 14.5619s/100 iters), loss = 0.994546
I0928 20:02:37.815260  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.994546 (* 1 = 0.994546 loss)
I0928 20:02:37.815266  5237 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I0928 20:02:52.376245  5237 solver.cpp:218] Iteration 1400 (6.86771 iter/s, 14.5609s/100 iters), loss = 0.818024
I0928 20:02:52.376283  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.818024 (* 1 = 0.818024 loss)
I0928 20:02:52.376289  5237 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I0928 20:03:06.218047  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:03:06.801370  5237 solver.cpp:330] Iteration 1500, Testing net (#0)
I0928 20:03:10.211901  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:03:10.354750  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5281
I0928 20:03:10.354785  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.79596 (* 1 = 1.79596 loss)
I0928 20:03:10.499819  5237 solver.cpp:218] Iteration 1500 (5.51772 iter/s, 18.1234s/100 iters), loss = 0.93676
I0928 20:03:10.499850  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.93676 (* 1 = 0.93676 loss)
I0928 20:03:10.499856  5237 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I0928 20:03:25.047580  5237 solver.cpp:218] Iteration 1600 (6.87396 iter/s, 14.5477s/100 iters), loss = 0.725187
I0928 20:03:25.047610  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.725187 (* 1 = 0.725187 loss)
I0928 20:03:25.047616  5237 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I0928 20:03:39.608402  5237 solver.cpp:218] Iteration 1700 (6.86779 iter/s, 14.5607s/100 iters), loss = 0.90742
I0928 20:03:39.608563  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.90742 (* 1 = 0.90742 loss)
I0928 20:03:39.608572  5237 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I0928 20:03:54.167943  5237 solver.cpp:218] Iteration 1800 (6.86845 iter/s, 14.5593s/100 iters), loss = 0.797572
I0928 20:03:54.167984  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.797572 (* 1 = 0.797572 loss)
I0928 20:03:54.167990  5237 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I0928 20:04:08.729918  5237 solver.cpp:218] Iteration 1900 (6.86725 iter/s, 14.5619s/100 iters), loss = 0.711446
I0928 20:04:08.729948  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.711446 (* 1 = 0.711446 loss)
I0928 20:04:08.729954  5237 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I0928 20:04:22.569726  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:04:23.152362  5237 solver.cpp:330] Iteration 2000, Testing net (#0)
I0928 20:04:26.565407  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:04:26.708582  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6111
I0928 20:04:26.708622  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.32123 (* 1 = 1.32123 loss)
I0928 20:04:26.853495  5237 solver.cpp:218] Iteration 2000 (5.51771 iter/s, 18.1235s/100 iters), loss = 0.834742
I0928 20:04:26.853539  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.834742 (* 1 = 0.834742 loss)
I0928 20:04:26.853549  5237 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I0928 20:04:41.591994  5237 solver.cpp:218] Iteration 2100 (6.785 iter/s, 14.7384s/100 iters), loss = 0.744882
I0928 20:04:41.592025  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.744882 (* 1 = 0.744882 loss)
I0928 20:04:41.592032  5237 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I0928 20:04:56.563097  5237 solver.cpp:218] Iteration 2200 (6.67957 iter/s, 14.971s/100 iters), loss = 0.752281
I0928 20:04:56.563202  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.752281 (* 1 = 0.752281 loss)
I0928 20:04:56.563218  5237 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I0928 20:05:11.245662  5237 solver.cpp:218] Iteration 2300 (6.81087 iter/s, 14.6824s/100 iters), loss = 0.736871
I0928 20:05:11.245692  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.736871 (* 1 = 0.736871 loss)
I0928 20:05:11.245698  5237 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I0928 20:05:25.838253  5237 solver.cpp:218] Iteration 2400 (6.85283 iter/s, 14.5925s/100 iters), loss = 0.661906
I0928 20:05:25.838286  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.661906 (* 1 = 0.661906 loss)
I0928 20:05:25.838302  5237 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I0928 20:05:39.711232  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:05:40.294905  5237 solver.cpp:330] Iteration 2500, Testing net (#0)
I0928 20:05:43.713732  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:05:43.856264  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6301
I0928 20:05:43.856300  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.13729 (* 1 = 1.13729 loss)
I0928 20:05:44.000581  5237 solver.cpp:218] Iteration 2500 (5.50593 iter/s, 18.1622s/100 iters), loss = 0.876399
I0928 20:05:44.000615  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.876399 (* 1 = 0.876399 loss)
I0928 20:05:44.000622  5237 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I0928 20:05:58.602798  5237 solver.cpp:218] Iteration 2600 (6.84832 iter/s, 14.6021s/100 iters), loss = 0.577025
I0928 20:05:58.602828  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.577025 (* 1 = 0.577025 loss)
I0928 20:05:58.602834  5237 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I0928 20:06:13.200862  5237 solver.cpp:218] Iteration 2700 (6.85026 iter/s, 14.598s/100 iters), loss = 0.778989
I0928 20:06:13.200971  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.778989 (* 1 = 0.778989 loss)
I0928 20:06:13.200987  5237 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I0928 20:06:27.793138  5237 solver.cpp:218] Iteration 2800 (6.85301 iter/s, 14.5921s/100 iters), loss = 0.73413
I0928 20:06:27.793169  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.73413 (* 1 = 0.73413 loss)
I0928 20:06:27.793174  5237 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I0928 20:06:42.389822  5237 solver.cpp:218] Iteration 2900 (6.85091 iter/s, 14.5966s/100 iters), loss = 0.562767
I0928 20:06:42.389853  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.562767 (* 1 = 0.562767 loss)
I0928 20:06:42.389858  5237 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I0928 20:06:56.262148  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:06:56.846457  5237 solver.cpp:330] Iteration 3000, Testing net (#0)
I0928 20:07:00.268579  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:07:00.411576  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6171
I0928 20:07:00.411602  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.15301 (* 1 = 1.15301 loss)
I0928 20:07:00.555923  5237 solver.cpp:218] Iteration 3000 (5.50479 iter/s, 18.166s/100 iters), loss = 0.820474
I0928 20:07:00.555950  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.820474 (* 1 = 0.820474 loss)
I0928 20:07:00.555958  5237 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I0928 20:07:15.163830  5237 solver.cpp:218] Iteration 3100 (6.84565 iter/s, 14.6078s/100 iters), loss = 0.586491
I0928 20:07:15.163863  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.586491 (* 1 = 0.586491 loss)
I0928 20:07:15.163871  5237 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I0928 20:07:29.772269  5237 solver.cpp:218] Iteration 3200 (6.8454 iter/s, 14.6084s/100 iters), loss = 0.56715
I0928 20:07:29.772382  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.56715 (* 1 = 0.56715 loss)
I0928 20:07:29.772389  5237 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I0928 20:07:44.377650  5237 solver.cpp:218] Iteration 3300 (6.84686 iter/s, 14.6052s/100 iters), loss = 0.604397
I0928 20:07:44.377682  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.604397 (* 1 = 0.604397 loss)
I0928 20:07:44.377688  5237 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I0928 20:07:58.982264  5237 solver.cpp:218] Iteration 3400 (6.84719 iter/s, 14.6045s/100 iters), loss = 0.573326
I0928 20:07:58.982293  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.573326 (* 1 = 0.573326 loss)
I0928 20:07:58.982300  5237 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I0928 20:08:12.861100  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:08:13.446241  5237 solver.cpp:330] Iteration 3500, Testing net (#0)
I0928 20:08:16.866039  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:08:17.009147  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6526
I0928 20:08:17.009183  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.09895 (* 1 = 1.09895 loss)
I0928 20:08:17.154882  5237 solver.cpp:218] Iteration 3500 (5.50281 iter/s, 18.1725s/100 iters), loss = 0.831131
I0928 20:08:17.154912  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.831131 (* 1 = 0.831131 loss)
I0928 20:08:17.154919  5237 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I0928 20:08:31.734225  5237 solver.cpp:218] Iteration 3600 (6.85906 iter/s, 14.5793s/100 iters), loss = 0.510536
I0928 20:08:31.734264  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.510536 (* 1 = 0.510536 loss)
I0928 20:08:31.734271  5237 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I0928 20:08:46.317699  5237 solver.cpp:218] Iteration 3700 (6.85712 iter/s, 14.5834s/100 iters), loss = 0.552942
I0928 20:08:46.317838  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.552942 (* 1 = 0.552942 loss)
I0928 20:08:46.317847  5237 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I0928 20:09:00.899982  5237 solver.cpp:218] Iteration 3800 (6.85773 iter/s, 14.5821s/100 iters), loss = 0.609076
I0928 20:09:00.900012  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.609076 (* 1 = 0.609076 loss)
I0928 20:09:00.900018  5237 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I0928 20:09:15.486438  5237 solver.cpp:218] Iteration 3900 (6.85571 iter/s, 14.5864s/100 iters), loss = 0.602621
I0928 20:09:15.486472  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.602621 (* 1 = 0.602621 loss)
I0928 20:09:15.486479  5237 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I0928 20:09:29.349189  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:09:29.934394  5237 solver.cpp:330] Iteration 4000, Testing net (#0)
I0928 20:09:33.354045  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:09:33.497221  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6827
I0928 20:09:33.497258  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.94772 (* 1 = 0.94772 loss)
I0928 20:09:33.641479  5237 solver.cpp:218] Iteration 4000 (5.50814 iter/s, 18.1549s/100 iters), loss = 0.695159
I0928 20:09:33.641507  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.695159 (* 1 = 0.695159 loss)
I0928 20:09:33.641513  5237 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I0928 20:09:48.238436  5237 solver.cpp:218] Iteration 4100 (6.85078 iter/s, 14.5969s/100 iters), loss = 0.605772
I0928 20:09:48.238468  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.605772 (* 1 = 0.605772 loss)
I0928 20:09:48.238474  5237 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I0928 20:10:02.828495  5237 solver.cpp:218] Iteration 4200 (6.85402 iter/s, 14.59s/100 iters), loss = 0.52522
I0928 20:10:02.828603  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.52522 (* 1 = 0.52522 loss)
I0928 20:10:02.828611  5237 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I0928 20:10:17.421352  5237 solver.cpp:218] Iteration 4300 (6.85274 iter/s, 14.5927s/100 iters), loss = 0.613388
I0928 20:10:17.421387  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.613388 (* 1 = 0.613388 loss)
I0928 20:10:17.421394  5237 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I0928 20:10:32.009428  5237 solver.cpp:218] Iteration 4400 (6.85495 iter/s, 14.588s/100 iters), loss = 0.611117
I0928 20:10:32.009456  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.611117 (* 1 = 0.611117 loss)
I0928 20:10:32.009462  5237 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I0928 20:10:45.879400  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:10:46.463713  5237 solver.cpp:330] Iteration 4500, Testing net (#0)
I0928 20:10:49.883061  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:10:50.026167  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7236
I0928 20:10:50.026202  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.798303 (* 1 = 0.798303 loss)
I0928 20:10:50.170668  5237 solver.cpp:218] Iteration 4500 (5.50626 iter/s, 18.1612s/100 iters), loss = 0.610803
I0928 20:10:50.170697  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.610803 (* 1 = 0.610803 loss)
I0928 20:10:50.170704  5237 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I0928 20:11:04.774391  5237 solver.cpp:218] Iteration 4600 (6.84761 iter/s, 14.6036s/100 iters), loss = 0.535703
I0928 20:11:04.774432  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.535703 (* 1 = 0.535703 loss)
I0928 20:11:04.774440  5237 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I0928 20:11:19.367871  5237 solver.cpp:218] Iteration 4700 (6.85242 iter/s, 14.5934s/100 iters), loss = 0.549325
I0928 20:11:19.367975  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.549325 (* 1 = 0.549325 loss)
I0928 20:11:19.367983  5237 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I0928 20:11:33.976627  5237 solver.cpp:218] Iteration 4800 (6.84528 iter/s, 14.6086s/100 iters), loss = 0.648939
I0928 20:11:33.976657  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.648939 (* 1 = 0.648939 loss)
I0928 20:11:33.976663  5237 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I0928 20:11:48.571889  5237 solver.cpp:218] Iteration 4900 (6.85158 iter/s, 14.5952s/100 iters), loss = 0.540836
I0928 20:11:48.571923  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.540836 (* 1 = 0.540836 loss)
I0928 20:11:48.571929  5237 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I0928 20:12:02.447546  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:12:03.031221  5237 solver.cpp:330] Iteration 5000, Testing net (#0)
I0928 20:12:06.449024  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:12:06.591948  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.749
I0928 20:12:06.591974  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.715601 (* 1 = 0.715601 loss)
I0928 20:12:06.736104  5237 solver.cpp:218] Iteration 5000 (5.50536 iter/s, 18.1641s/100 iters), loss = 0.605761
I0928 20:12:06.736130  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.605761 (* 1 = 0.605761 loss)
I0928 20:12:06.736137  5237 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I0928 20:12:21.331118  5237 solver.cpp:218] Iteration 5100 (6.85169 iter/s, 14.5949s/100 iters), loss = 0.512614
I0928 20:12:21.331147  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.512614 (* 1 = 0.512614 loss)
I0928 20:12:21.331153  5237 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I0928 20:12:35.931325  5237 solver.cpp:218] Iteration 5200 (6.84925 iter/s, 14.6001s/100 iters), loss = 0.592817
I0928 20:12:35.931437  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.592817 (* 1 = 0.592817 loss)
I0928 20:12:35.931454  5237 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I0928 20:12:50.527349  5237 solver.cpp:218] Iteration 5300 (6.85125 iter/s, 14.5959s/100 iters), loss = 0.618413
I0928 20:12:50.527381  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.618413 (* 1 = 0.618413 loss)
I0928 20:12:50.527389  5237 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I0928 20:13:05.123332  5237 solver.cpp:218] Iteration 5400 (6.85124 iter/s, 14.5959s/100 iters), loss = 0.56663
I0928 20:13:05.123363  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.56663 (* 1 = 0.56663 loss)
I0928 20:13:05.123368  5237 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I0928 20:13:18.997195  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:13:19.580962  5237 solver.cpp:330] Iteration 5500, Testing net (#0)
I0928 20:13:22.999989  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:13:23.142951  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7541
I0928 20:13:23.142976  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.708652 (* 1 = 0.708652 loss)
I0928 20:13:23.287977  5237 solver.cpp:218] Iteration 5500 (5.50523 iter/s, 18.1646s/100 iters), loss = 0.592772
I0928 20:13:23.288005  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.592772 (* 1 = 0.592772 loss)
I0928 20:13:23.288012  5237 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I0928 20:13:37.889911  5237 solver.cpp:218] Iteration 5600 (6.84844 iter/s, 14.6019s/100 iters), loss = 0.548219
I0928 20:13:37.889945  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.548219 (* 1 = 0.548219 loss)
I0928 20:13:37.889950  5237 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I0928 20:13:52.489827  5237 solver.cpp:218] Iteration 5700 (6.84939 iter/s, 14.5998s/100 iters), loss = 0.519184
I0928 20:13:52.489934  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.519184 (* 1 = 0.519184 loss)
I0928 20:13:52.489943  5237 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I0928 20:14:07.089731  5237 solver.cpp:218] Iteration 5800 (6.84943 iter/s, 14.5998s/100 iters), loss = 0.549217
I0928 20:14:07.089761  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.549217 (* 1 = 0.549217 loss)
I0928 20:14:07.089767  5237 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I0928 20:14:21.686158  5237 solver.cpp:218] Iteration 5900 (6.85103 iter/s, 14.5964s/100 iters), loss = 0.520525
I0928 20:14:21.686190  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.520525 (* 1 = 0.520525 loss)
I0928 20:14:21.686208  5237 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I0928 20:14:35.558873  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:14:36.142902  5237 solver.cpp:330] Iteration 6000, Testing net (#0)
I0928 20:14:39.561930  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:14:39.705056  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6943
I0928 20:14:39.705094  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.864459 (* 1 = 0.864459 loss)
I0928 20:14:39.849261  5237 solver.cpp:218] Iteration 6000 (5.50569 iter/s, 18.163s/100 iters), loss = 0.602106
I0928 20:14:39.849292  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.602106 (* 1 = 0.602106 loss)
I0928 20:14:39.849298  5237 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I0928 20:14:54.451733  5237 solver.cpp:218] Iteration 6100 (6.84819 iter/s, 14.6024s/100 iters), loss = 0.49125
I0928 20:14:54.451763  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.49125 (* 1 = 0.49125 loss)
I0928 20:14:54.451769  5237 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I0928 20:15:09.054241  5237 solver.cpp:218] Iteration 6200 (6.84817 iter/s, 14.6024s/100 iters), loss = 0.479124
I0928 20:15:09.054385  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.479124 (* 1 = 0.479124 loss)
I0928 20:15:09.054395  5237 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I0928 20:15:23.657800  5237 solver.cpp:218] Iteration 6300 (6.84773 iter/s, 14.6034s/100 iters), loss = 0.648579
I0928 20:15:23.657829  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.648579 (* 1 = 0.648579 loss)
I0928 20:15:23.657835  5237 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I0928 20:15:38.255539  5237 solver.cpp:218] Iteration 6400 (6.85041 iter/s, 14.5977s/100 iters), loss = 0.490683
I0928 20:15:38.255570  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.490683 (* 1 = 0.490683 loss)
I0928 20:15:38.255578  5237 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I0928 20:15:52.125947  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:15:52.710764  5237 solver.cpp:330] Iteration 6500, Testing net (#0)
I0928 20:15:56.129227  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:15:56.271375  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6563
I0928 20:15:56.271410  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.01367 (* 1 = 1.01367 loss)
I0928 20:15:56.416153  5237 solver.cpp:218] Iteration 6500 (5.50645 iter/s, 18.1605s/100 iters), loss = 0.572545
I0928 20:15:56.416188  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.572545 (* 1 = 0.572545 loss)
I0928 20:15:56.416195  5237 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I0928 20:16:11.015010  5237 solver.cpp:218] Iteration 6600 (6.84989 iter/s, 14.5988s/100 iters), loss = 0.399933
I0928 20:16:11.015043  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.399933 (* 1 = 0.399933 loss)
I0928 20:16:11.015049  5237 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I0928 20:16:25.613719  5237 solver.cpp:218] Iteration 6700 (6.84996 iter/s, 14.5986s/100 iters), loss = 0.535577
I0928 20:16:25.613854  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.535577 (* 1 = 0.535577 loss)
I0928 20:16:25.613862  5237 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I0928 20:16:40.205626  5237 solver.cpp:218] Iteration 6800 (6.8532 iter/s, 14.5917s/100 iters), loss = 0.51964
I0928 20:16:40.205658  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.51964 (* 1 = 0.51964 loss)
I0928 20:16:40.205665  5237 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I0928 20:16:54.800071  5237 solver.cpp:218] Iteration 6900 (6.85196 iter/s, 14.5944s/100 iters), loss = 0.429553
I0928 20:16:54.800102  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.429553 (* 1 = 0.429553 loss)
I0928 20:16:54.800108  5237 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I0928 20:17:08.667024  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:17:09.251888  5237 solver.cpp:330] Iteration 7000, Testing net (#0)
I0928 20:17:12.667055  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:17:12.809562  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7022
I0928 20:17:12.809598  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.874678 (* 1 = 0.874678 loss)
I0928 20:17:12.954704  5237 solver.cpp:218] Iteration 7000 (5.50826 iter/s, 18.1545s/100 iters), loss = 0.565474
I0928 20:17:12.954735  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.565474 (* 1 = 0.565474 loss)
I0928 20:17:12.954742  5237 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I0928 20:17:27.552103  5237 solver.cpp:218] Iteration 7100 (6.85057 iter/s, 14.5973s/100 iters), loss = 0.448861
I0928 20:17:27.552131  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.448861 (* 1 = 0.448861 loss)
I0928 20:17:27.552136  5237 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I0928 20:17:42.142092  5237 solver.cpp:218] Iteration 7200 (6.85405 iter/s, 14.5899s/100 iters), loss = 0.456441
I0928 20:17:42.142217  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.456441 (* 1 = 0.456441 loss)
I0928 20:17:42.142225  5237 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I0928 20:17:56.740785  5237 solver.cpp:218] Iteration 7300 (6.85001 iter/s, 14.5985s/100 iters), loss = 0.589761
I0928 20:17:56.740814  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.589761 (* 1 = 0.589761 loss)
I0928 20:17:56.740821  5237 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I0928 20:18:11.341774  5237 solver.cpp:218] Iteration 7400 (6.84889 iter/s, 14.6009s/100 iters), loss = 0.446503
I0928 20:18:11.341804  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.446503 (* 1 = 0.446503 loss)
I0928 20:18:11.341820  5237 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I0928 20:18:25.212101  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:18:25.796881  5237 solver.cpp:330] Iteration 7500, Testing net (#0)
I0928 20:18:29.214910  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:18:29.357496  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7079
I0928 20:18:29.357532  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.848473 (* 1 = 0.848473 loss)
I0928 20:18:29.502522  5237 solver.cpp:218] Iteration 7500 (5.50641 iter/s, 18.1607s/100 iters), loss = 0.62094
I0928 20:18:29.502562  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.62094 (* 1 = 0.62094 loss)
I0928 20:18:29.502578  5237 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I0928 20:18:44.093053  5237 solver.cpp:218] Iteration 7600 (6.8538 iter/s, 14.5904s/100 iters), loss = 0.45953
I0928 20:18:44.093086  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.45953 (* 1 = 0.45953 loss)
I0928 20:18:44.093091  5237 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I0928 20:18:58.685142  5237 solver.cpp:218] Iteration 7700 (6.85306 iter/s, 14.592s/100 iters), loss = 0.398163
I0928 20:18:58.685266  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.398163 (* 1 = 0.398163 loss)
I0928 20:18:58.685274  5237 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I0928 20:19:13.277844  5237 solver.cpp:218] Iteration 7800 (6.85282 iter/s, 14.5925s/100 iters), loss = 0.522045
I0928 20:19:13.277878  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.522045 (* 1 = 0.522045 loss)
I0928 20:19:13.277886  5237 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I0928 20:19:27.874776  5237 solver.cpp:218] Iteration 7900 (6.85079 iter/s, 14.5969s/100 iters), loss = 0.474286
I0928 20:19:27.874806  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.474286 (* 1 = 0.474286 loss)
I0928 20:19:27.874812  5237 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I0928 20:19:41.739203  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:19:42.324259  5237 solver.cpp:330] Iteration 8000, Testing net (#0)
I0928 20:19:45.742847  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:19:45.884420  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7125
I0928 20:19:45.884445  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.80323 (* 1 = 0.80323 loss)
I0928 20:19:46.029109  5237 solver.cpp:218] Iteration 8000 (5.50835 iter/s, 18.1543s/100 iters), loss = 0.571471
I0928 20:19:46.029137  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.571471 (* 1 = 0.571471 loss)
I0928 20:19:46.029145  5237 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I0928 20:20:00.620373  5237 solver.cpp:218] Iteration 8100 (6.85345 iter/s, 14.5912s/100 iters), loss = 0.521331
I0928 20:20:00.620401  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.521331 (* 1 = 0.521331 loss)
I0928 20:20:00.620407  5237 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I0928 20:20:15.220705  5237 solver.cpp:218] Iteration 8200 (6.84919 iter/s, 14.6003s/100 iters), loss = 0.416934
I0928 20:20:15.220820  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.416934 (* 1 = 0.416934 loss)
I0928 20:20:15.220829  5237 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I0928 20:20:29.814469  5237 solver.cpp:218] Iteration 8300 (6.85231 iter/s, 14.5936s/100 iters), loss = 0.509222
I0928 20:20:29.814509  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.509222 (* 1 = 0.509222 loss)
I0928 20:20:29.814515  5237 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I0928 20:20:44.404589  5237 solver.cpp:218] Iteration 8400 (6.85399 iter/s, 14.59s/100 iters), loss = 0.550439
I0928 20:20:44.404623  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.550439 (* 1 = 0.550439 loss)
I0928 20:20:44.404630  5237 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I0928 20:20:58.280303  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:20:58.865418  5237 solver.cpp:330] Iteration 8500, Testing net (#0)
I0928 20:21:02.282867  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:21:02.426312  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5984
I0928 20:21:02.426339  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.35542 (* 1 = 1.35542 loss)
I0928 20:21:02.570468  5237 solver.cpp:218] Iteration 8500 (5.50485 iter/s, 18.1658s/100 iters), loss = 0.541619
I0928 20:21:02.570502  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.541619 (* 1 = 0.541619 loss)
I0928 20:21:02.570509  5237 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I0928 20:21:17.174561  5237 solver.cpp:218] Iteration 8600 (6.84743 iter/s, 14.604s/100 iters), loss = 0.342176
I0928 20:21:17.174592  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342176 (* 1 = 0.342176 loss)
I0928 20:21:17.174597  5237 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I0928 20:21:31.768065  5237 solver.cpp:218] Iteration 8700 (6.8524 iter/s, 14.5934s/100 iters), loss = 0.447171
I0928 20:21:31.768239  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.447171 (* 1 = 0.447171 loss)
I0928 20:21:31.768259  5237 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I0928 20:21:46.364804  5237 solver.cpp:218] Iteration 8800 (6.85095 iter/s, 14.5965s/100 iters), loss = 0.540354
I0928 20:21:46.364840  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.540354 (* 1 = 0.540354 loss)
I0928 20:21:46.364847  5237 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I0928 20:22:00.958148  5237 solver.cpp:218] Iteration 8900 (6.85248 iter/s, 14.5933s/100 iters), loss = 0.345485
I0928 20:22:00.958187  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.345485 (* 1 = 0.345485 loss)
I0928 20:22:00.958194  5237 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I0928 20:22:14.826267  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:22:15.411260  5237 solver.cpp:330] Iteration 9000, Testing net (#0)
I0928 20:22:18.828277  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:22:18.970698  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7428
I0928 20:22:18.970733  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.753715 (* 1 = 0.753715 loss)
I0928 20:22:19.115412  5237 solver.cpp:218] Iteration 9000 (5.50746 iter/s, 18.1572s/100 iters), loss = 0.567239
I0928 20:22:19.115439  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.567239 (* 1 = 0.567239 loss)
I0928 20:22:19.115447  5237 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I0928 20:22:33.712384  5237 solver.cpp:218] Iteration 9100 (6.85077 iter/s, 14.5969s/100 iters), loss = 0.369865
I0928 20:22:33.712426  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.369865 (* 1 = 0.369865 loss)
I0928 20:22:33.712433  5237 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I0928 20:22:48.309450  5237 solver.cpp:218] Iteration 9200 (6.85073 iter/s, 14.597s/100 iters), loss = 0.389227
I0928 20:22:48.309561  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.389227 (* 1 = 0.389227 loss)
I0928 20:22:48.309568  5237 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I0928 20:23:02.904145  5237 solver.cpp:218] Iteration 9300 (6.85187 iter/s, 14.5946s/100 iters), loss = 0.490812
I0928 20:23:02.904175  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.490812 (* 1 = 0.490812 loss)
I0928 20:23:02.904181  5237 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I0928 20:23:17.495034  5237 solver.cpp:218] Iteration 9400 (6.85363 iter/s, 14.5908s/100 iters), loss = 0.468563
I0928 20:23:17.495074  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.468563 (* 1 = 0.468563 loss)
I0928 20:23:17.495081  5237 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I0928 20:23:31.358187  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:23:31.941589  5237 solver.cpp:330] Iteration 9500, Testing net (#0)
I0928 20:23:35.360568  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:23:35.502950  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7418
I0928 20:23:35.502985  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.752305 (* 1 = 0.752305 loss)
I0928 20:23:35.647830  5237 solver.cpp:218] Iteration 9500 (5.50882 iter/s, 18.1527s/100 iters), loss = 0.490276
I0928 20:23:35.647862  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.490276 (* 1 = 0.490276 loss)
I0928 20:23:35.647869  5237 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I0928 20:23:50.240559  5237 solver.cpp:218] Iteration 9600 (6.85276 iter/s, 14.5927s/100 iters), loss = 0.353766
I0928 20:23:50.240588  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.353766 (* 1 = 0.353766 loss)
I0928 20:23:50.240594  5237 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I0928 20:24:04.833386  5237 solver.cpp:218] Iteration 9700 (6.85272 iter/s, 14.5928s/100 iters), loss = 0.430296
I0928 20:24:04.833519  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.430296 (* 1 = 0.430296 loss)
I0928 20:24:04.833528  5237 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I0928 20:24:19.437386  5237 solver.cpp:218] Iteration 9800 (6.84752 iter/s, 14.6038s/100 iters), loss = 0.467001
I0928 20:24:19.437427  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.467001 (* 1 = 0.467001 loss)
I0928 20:24:19.437434  5237 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I0928 20:24:34.034906  5237 solver.cpp:218] Iteration 9900 (6.85052 iter/s, 14.5974s/100 iters), loss = 0.406558
I0928 20:24:34.034939  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.406558 (* 1 = 0.406558 loss)
I0928 20:24:34.034945  5237 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I0928 20:24:47.934062  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:24:48.523087  5237 solver.cpp:330] Iteration 10000, Testing net (#0)
I0928 20:24:51.970034  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:24:52.114089  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5717
I0928 20:24:52.114125  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.26378 (* 1 = 1.26378 loss)
I0928 20:24:52.260471  5237 solver.cpp:218] Iteration 10000 (5.48682 iter/s, 18.2255s/100 iters), loss = 0.51096
I0928 20:24:52.260504  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.51096 (* 1 = 0.51096 loss)
I0928 20:24:52.260510  5237 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I0928 20:25:06.944857  5237 solver.cpp:218] Iteration 10100 (6.80999 iter/s, 14.6843s/100 iters), loss = 0.408642
I0928 20:25:06.944890  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.408642 (* 1 = 0.408642 loss)
I0928 20:25:06.944896  5237 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I0928 20:25:21.544123  5237 solver.cpp:218] Iteration 10200 (6.84971 iter/s, 14.5992s/100 iters), loss = 0.359869
I0928 20:25:21.544268  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.359869 (* 1 = 0.359869 loss)
I0928 20:25:21.544277  5237 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I0928 20:25:36.189455  5237 solver.cpp:218] Iteration 10300 (6.8282 iter/s, 14.6451s/100 iters), loss = 0.484478
I0928 20:25:36.189507  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.484478 (* 1 = 0.484478 loss)
I0928 20:25:36.189524  5237 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I0928 20:25:50.820163  5237 solver.cpp:218] Iteration 10400 (6.83504 iter/s, 14.6305s/100 iters), loss = 0.398972
I0928 20:25:50.820194  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.398972 (* 1 = 0.398972 loss)
I0928 20:25:50.820201  5237 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I0928 20:26:04.735492  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:26:05.321969  5237 solver.cpp:330] Iteration 10500, Testing net (#0)
I0928 20:26:08.734796  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:26:08.879274  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7305
I0928 20:26:08.879309  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.800996 (* 1 = 0.800996 loss)
I0928 20:26:09.023903  5237 solver.cpp:218] Iteration 10500 (5.4934 iter/s, 18.2037s/100 iters), loss = 0.44493
I0928 20:26:09.023931  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.44493 (* 1 = 0.44493 loss)
I0928 20:26:09.023937  5237 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I0928 20:26:23.673318  5237 solver.cpp:218] Iteration 10600 (6.82624 iter/s, 14.6493s/100 iters), loss = 0.408926
I0928 20:26:23.673347  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.408926 (* 1 = 0.408926 loss)
I0928 20:26:23.673353  5237 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I0928 20:26:38.398576  5237 solver.cpp:218] Iteration 10700 (6.79108 iter/s, 14.7252s/100 iters), loss = 0.442778
I0928 20:26:38.398705  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.442778 (* 1 = 0.442778 loss)
I0928 20:26:38.398712  5237 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I0928 20:26:53.213716  5237 solver.cpp:218] Iteration 10800 (6.74992 iter/s, 14.815s/100 iters), loss = 0.447575
I0928 20:26:53.213747  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.447575 (* 1 = 0.447575 loss)
I0928 20:26:53.213762  5237 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I0928 20:27:08.022804  5237 solver.cpp:218] Iteration 10900 (6.75264 iter/s, 14.809s/100 iters), loss = 0.361976
I0928 20:27:08.022840  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.361976 (* 1 = 0.361976 loss)
I0928 20:27:08.022850  5237 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I0928 20:27:22.082978  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:27:22.677144  5237 solver.cpp:330] Iteration 11000, Testing net (#0)
I0928 20:27:26.149595  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:27:26.293622  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7279
I0928 20:27:26.293658  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.805319 (* 1 = 0.805319 loss)
I0928 20:27:26.439244  5237 solver.cpp:218] Iteration 11000 (5.42996 iter/s, 18.4164s/100 iters), loss = 0.489632
I0928 20:27:26.439276  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.489632 (* 1 = 0.489632 loss)
I0928 20:27:26.439282  5237 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I0928 20:27:41.224644  5237 solver.cpp:218] Iteration 11100 (6.76346 iter/s, 14.7853s/100 iters), loss = 0.413305
I0928 20:27:41.224679  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.413305 (* 1 = 0.413305 loss)
I0928 20:27:41.224686  5237 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I0928 20:27:56.039067  5237 solver.cpp:218] Iteration 11200 (6.75021 iter/s, 14.8143s/100 iters), loss = 0.440404
I0928 20:27:56.039209  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.440404 (* 1 = 0.440404 loss)
I0928 20:27:56.039217  5237 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I0928 20:28:10.836032  5237 solver.cpp:218] Iteration 11300 (6.75823 iter/s, 14.7968s/100 iters), loss = 0.560806
I0928 20:28:10.836067  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.560806 (* 1 = 0.560806 loss)
I0928 20:28:10.836076  5237 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I0928 20:28:25.631614  5237 solver.cpp:218] Iteration 11400 (6.75881 iter/s, 14.7955s/100 iters), loss = 0.445902
I0928 20:28:25.631661  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.445902 (* 1 = 0.445902 loss)
I0928 20:28:25.631669  5237 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I0928 20:28:39.709302  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:28:40.295224  5237 solver.cpp:330] Iteration 11500, Testing net (#0)
I0928 20:28:43.771540  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:28:43.917057  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7527
I0928 20:28:43.917083  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.74939 (* 1 = 0.74939 loss)
I0928 20:28:44.065619  5237 solver.cpp:218] Iteration 11500 (5.42483 iter/s, 18.4337s/100 iters), loss = 0.369769
I0928 20:28:44.065655  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.369769 (* 1 = 0.369769 loss)
I0928 20:28:44.065663  5237 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I0928 20:28:58.851502  5237 solver.cpp:218] Iteration 11600 (6.76324 iter/s, 14.7858s/100 iters), loss = 0.391195
I0928 20:28:58.851536  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.391195 (* 1 = 0.391195 loss)
I0928 20:28:58.851543  5237 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I0928 20:29:13.579780  5237 solver.cpp:218] Iteration 11700 (6.78969 iter/s, 14.7282s/100 iters), loss = 0.477237
I0928 20:29:13.579937  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.477237 (* 1 = 0.477237 loss)
I0928 20:29:13.579949  5237 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I0928 20:29:28.349506  5237 solver.cpp:218] Iteration 11800 (6.77069 iter/s, 14.7695s/100 iters), loss = 0.486578
I0928 20:29:28.349536  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.486578 (* 1 = 0.486578 loss)
I0928 20:29:28.349542  5237 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I0928 20:29:43.135885  5237 solver.cpp:218] Iteration 11900 (6.76301 iter/s, 14.7863s/100 iters), loss = 0.371489
I0928 20:29:43.135915  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371489 (* 1 = 0.371489 loss)
I0928 20:29:43.135922  5237 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I0928 20:29:57.183027  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:29:57.780215  5237 solver.cpp:330] Iteration 12000, Testing net (#0)
I0928 20:30:01.239012  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:30:01.381777  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8001
I0928 20:30:01.381803  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.596177 (* 1 = 0.596177 loss)
I0928 20:30:01.526607  5237 solver.cpp:218] Iteration 12000 (5.43755 iter/s, 18.3906s/100 iters), loss = 0.424446
I0928 20:30:01.526638  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.424446 (* 1 = 0.424446 loss)
I0928 20:30:01.526643  5237 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I0928 20:30:16.370115  5237 solver.cpp:218] Iteration 12100 (6.73699 iter/s, 14.8434s/100 iters), loss = 0.30438
I0928 20:30:16.370164  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30438 (* 1 = 0.30438 loss)
I0928 20:30:16.370172  5237 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I0928 20:30:31.144625  5237 solver.cpp:218] Iteration 12200 (6.76846 iter/s, 14.7744s/100 iters), loss = 0.351991
I0928 20:30:31.144716  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351991 (* 1 = 0.351991 loss)
I0928 20:30:31.144728  5237 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I0928 20:30:45.950070  5237 solver.cpp:218] Iteration 12300 (6.75433 iter/s, 14.8053s/100 iters), loss = 0.405626
I0928 20:30:45.950104  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405626 (* 1 = 0.405626 loss)
I0928 20:30:45.950111  5237 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I0928 20:31:00.796156  5237 solver.cpp:218] Iteration 12400 (6.73582 iter/s, 14.846s/100 iters), loss = 0.431387
I0928 20:31:00.796190  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.431387 (* 1 = 0.431387 loss)
I0928 20:31:00.796196  5237 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I0928 20:31:14.881294  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:31:15.466436  5237 solver.cpp:330] Iteration 12500, Testing net (#0)
I0928 20:31:18.942066  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:31:19.085547  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7598
I0928 20:31:19.085582  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.70008 (* 1 = 0.70008 loss)
I0928 20:31:19.235826  5237 solver.cpp:218] Iteration 12500 (5.42312 iter/s, 18.4396s/100 iters), loss = 0.424525
I0928 20:31:19.235869  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.424525 (* 1 = 0.424525 loss)
I0928 20:31:19.235877  5237 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I0928 20:31:34.031787  5237 solver.cpp:218] Iteration 12600 (6.75864 iter/s, 14.7959s/100 iters), loss = 0.327142
I0928 20:31:34.031821  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327142 (* 1 = 0.327142 loss)
I0928 20:31:34.031838  5237 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I0928 20:31:48.689616  5237 solver.cpp:218] Iteration 12700 (6.82241 iter/s, 14.6576s/100 iters), loss = 0.472705
I0928 20:31:48.689738  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.472705 (* 1 = 0.472705 loss)
I0928 20:31:48.689748  5237 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I0928 20:32:03.359191  5237 solver.cpp:218] Iteration 12800 (6.8169 iter/s, 14.6694s/100 iters), loss = 0.538341
I0928 20:32:03.359220  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.538341 (* 1 = 0.538341 loss)
I0928 20:32:03.359226  5237 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I0928 20:32:18.054735  5237 solver.cpp:218] Iteration 12900 (6.80482 iter/s, 14.6955s/100 iters), loss = 0.406865
I0928 20:32:18.054769  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.406865 (* 1 = 0.406865 loss)
I0928 20:32:18.054776  5237 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I0928 20:32:32.021685  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:32:32.606381  5237 solver.cpp:330] Iteration 13000, Testing net (#0)
I0928 20:32:36.050014  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:32:36.193868  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7339
I0928 20:32:36.193909  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.773597 (* 1 = 0.773597 loss)
I0928 20:32:36.339413  5237 solver.cpp:218] Iteration 13000 (5.46909 iter/s, 18.2846s/100 iters), loss = 0.537362
I0928 20:32:36.339447  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.537362 (* 1 = 0.537362 loss)
I0928 20:32:36.339452  5237 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I0928 20:32:51.030477  5237 solver.cpp:218] Iteration 13100 (6.80689 iter/s, 14.691s/100 iters), loss = 0.379259
I0928 20:32:51.030508  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.379259 (* 1 = 0.379259 loss)
I0928 20:32:51.030515  5237 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I0928 20:33:05.894060  5237 solver.cpp:218] Iteration 13200 (6.72789 iter/s, 14.8635s/100 iters), loss = 0.452511
I0928 20:33:05.894158  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.452511 (* 1 = 0.452511 loss)
I0928 20:33:05.894166  5237 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I0928 20:33:20.651087  5237 solver.cpp:218] Iteration 13300 (6.7765 iter/s, 14.7569s/100 iters), loss = 0.444104
I0928 20:33:20.651120  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.444104 (* 1 = 0.444104 loss)
I0928 20:33:20.651126  5237 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I0928 20:33:35.361470  5237 solver.cpp:218] Iteration 13400 (6.79795 iter/s, 14.7103s/100 iters), loss = 0.58887
I0928 20:33:35.361505  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.58887 (* 1 = 0.58887 loss)
I0928 20:33:35.361513  5237 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I0928 20:33:49.390727  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:33:49.975414  5237 solver.cpp:330] Iteration 13500, Testing net (#0)
I0928 20:33:53.445080  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:33:53.587782  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7822
I0928 20:33:53.587817  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.63849 (* 1 = 0.63849 loss)
I0928 20:33:53.737222  5237 solver.cpp:218] Iteration 13500 (5.44198 iter/s, 18.3757s/100 iters), loss = 0.371736
I0928 20:33:53.737257  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371736 (* 1 = 0.371736 loss)
I0928 20:33:53.737274  5237 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I0928 20:34:08.476231  5237 solver.cpp:218] Iteration 13600 (6.78475 iter/s, 14.7389s/100 iters), loss = 0.26558
I0928 20:34:08.476261  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26558 (* 1 = 0.26558 loss)
I0928 20:34:08.476267  5237 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I0928 20:34:23.258479  5237 solver.cpp:218] Iteration 13700 (6.7649 iter/s, 14.7822s/100 iters), loss = 0.381468
I0928 20:34:23.258668  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.381468 (* 1 = 0.381468 loss)
I0928 20:34:23.258688  5237 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I0928 20:34:38.024762  5237 solver.cpp:218] Iteration 13800 (6.7723 iter/s, 14.766s/100 iters), loss = 0.423021
I0928 20:34:38.024796  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.423021 (* 1 = 0.423021 loss)
I0928 20:34:38.024803  5237 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I0928 20:34:52.787778  5237 solver.cpp:218] Iteration 13900 (6.77372 iter/s, 14.7629s/100 iters), loss = 0.450176
I0928 20:34:52.787816  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.450176 (* 1 = 0.450176 loss)
I0928 20:34:52.787822  5237 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I0928 20:35:06.848443  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:35:07.438107  5237 solver.cpp:330] Iteration 14000, Testing net (#0)
I0928 20:35:10.903244  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:35:11.049479  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7895
I0928 20:35:11.049515  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.61201 (* 1 = 0.61201 loss)
I0928 20:35:11.193637  5237 solver.cpp:218] Iteration 14000 (5.43308 iter/s, 18.4058s/100 iters), loss = 0.436665
I0928 20:35:11.193665  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.436665 (* 1 = 0.436665 loss)
I0928 20:35:11.193671  5237 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I0928 20:35:25.951586  5237 solver.cpp:218] Iteration 14100 (6.77604 iter/s, 14.7579s/100 iters), loss = 0.42232
I0928 20:35:25.951622  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.42232 (* 1 = 0.42232 loss)
I0928 20:35:25.951632  5237 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I0928 20:35:40.727802  5237 solver.cpp:218] Iteration 14200 (6.76767 iter/s, 14.7761s/100 iters), loss = 0.305158
I0928 20:35:40.727913  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305158 (* 1 = 0.305158 loss)
I0928 20:35:40.727923  5237 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I0928 20:35:55.443975  5237 solver.cpp:218] Iteration 14300 (6.79531 iter/s, 14.716s/100 iters), loss = 0.403029
I0928 20:35:55.444015  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.403029 (* 1 = 0.403029 loss)
I0928 20:35:55.444036  5237 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I0928 20:36:10.153055  5237 solver.cpp:218] Iteration 14400 (6.79856 iter/s, 14.709s/100 iters), loss = 0.428447
I0928 20:36:10.153090  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.428447 (* 1 = 0.428447 loss)
I0928 20:36:10.153100  5237 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I0928 20:36:24.200747  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:36:24.792362  5237 solver.cpp:330] Iteration 14500, Testing net (#0)
I0928 20:36:28.259052  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:36:28.402171  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7669
I0928 20:36:28.402205  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.719177 (* 1 = 0.719177 loss)
I0928 20:36:28.550365  5237 solver.cpp:218] Iteration 14500 (5.4356 iter/s, 18.3972s/100 iters), loss = 0.45544
I0928 20:36:28.550410  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.45544 (* 1 = 0.45544 loss)
I0928 20:36:28.550417  5237 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I0928 20:36:43.306442  5237 solver.cpp:218] Iteration 14600 (6.7773 iter/s, 14.7551s/100 iters), loss = 0.267275
I0928 20:36:43.306473  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267275 (* 1 = 0.267275 loss)
I0928 20:36:43.306479  5237 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I0928 20:36:58.037825  5237 solver.cpp:218] Iteration 14700 (6.78826 iter/s, 14.7313s/100 iters), loss = 0.400186
I0928 20:36:58.037992  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.400186 (* 1 = 0.400186 loss)
I0928 20:36:58.038000  5237 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I0928 20:37:12.825785  5237 solver.cpp:218] Iteration 14800 (6.76235 iter/s, 14.7878s/100 iters), loss = 0.43324
I0928 20:37:12.825817  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.43324 (* 1 = 0.43324 loss)
I0928 20:37:12.825824  5237 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I0928 20:37:27.582264  5237 solver.cpp:218] Iteration 14900 (6.77672 iter/s, 14.7564s/100 iters), loss = 0.401344
I0928 20:37:27.582304  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.401344 (* 1 = 0.401344 loss)
I0928 20:37:27.582309  5237 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I0928 20:37:41.620513  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:37:42.208869  5237 solver.cpp:330] Iteration 15000, Testing net (#0)
I0928 20:37:45.679827  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:37:45.822958  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7119
I0928 20:37:45.822984  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.840362 (* 1 = 0.840362 loss)
I0928 20:37:45.967428  5237 solver.cpp:218] Iteration 15000 (5.43919 iter/s, 18.3851s/100 iters), loss = 0.487716
I0928 20:37:45.967458  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.487716 (* 1 = 0.487716 loss)
I0928 20:37:45.967465  5237 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I0928 20:38:00.758625  5237 solver.cpp:218] Iteration 15100 (6.76081 iter/s, 14.7911s/100 iters), loss = 0.289743
I0928 20:38:00.758656  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289743 (* 1 = 0.289743 loss)
I0928 20:38:00.758662  5237 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I0928 20:38:15.532173  5237 solver.cpp:218] Iteration 15200 (6.76889 iter/s, 14.7735s/100 iters), loss = 0.384697
I0928 20:38:15.532320  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.384697 (* 1 = 0.384697 loss)
I0928 20:38:15.532327  5237 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I0928 20:38:30.219032  5237 solver.cpp:218] Iteration 15300 (6.80889 iter/s, 14.6867s/100 iters), loss = 0.413024
I0928 20:38:30.219065  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.413024 (* 1 = 0.413024 loss)
I0928 20:38:30.219074  5237 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I0928 20:38:44.928447  5237 solver.cpp:218] Iteration 15400 (6.7984 iter/s, 14.7093s/100 iters), loss = 0.372327
I0928 20:38:44.928493  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.372327 (* 1 = 0.372327 loss)
I0928 20:38:44.928499  5237 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I0928 20:38:58.855142  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:38:59.444355  5237 solver.cpp:330] Iteration 15500, Testing net (#0)
I0928 20:39:02.867704  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:39:03.010640  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7592
I0928 20:39:03.010674  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.692963 (* 1 = 0.692963 loss)
I0928 20:39:03.155432  5237 solver.cpp:218] Iteration 15500 (5.4864 iter/s, 18.2269s/100 iters), loss = 0.414775
I0928 20:39:03.155465  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.414775 (* 1 = 0.414775 loss)
I0928 20:39:03.155472  5237 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I0928 20:39:17.818260  5237 solver.cpp:218] Iteration 15600 (6.82 iter/s, 14.6628s/100 iters), loss = 0.335754
I0928 20:39:17.818289  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335754 (* 1 = 0.335754 loss)
I0928 20:39:17.818295  5237 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I0928 20:39:32.501528  5237 solver.cpp:218] Iteration 15700 (6.81051 iter/s, 14.6832s/100 iters), loss = 0.379131
I0928 20:39:32.501626  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.379131 (* 1 = 0.379131 loss)
I0928 20:39:32.501643  5237 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I0928 20:39:47.184247  5237 solver.cpp:218] Iteration 15800 (6.81079 iter/s, 14.6826s/100 iters), loss = 0.464691
I0928 20:39:47.184279  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.464691 (* 1 = 0.464691 loss)
I0928 20:39:47.184285  5237 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I0928 20:40:01.831545  5237 solver.cpp:218] Iteration 15900 (6.82723 iter/s, 14.6472s/100 iters), loss = 0.337441
I0928 20:40:01.831600  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337441 (* 1 = 0.337441 loss)
I0928 20:40:01.831617  5237 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I0928 20:40:15.787966  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:40:16.373287  5237 solver.cpp:330] Iteration 16000, Testing net (#0)
I0928 20:40:19.815583  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:40:19.960734  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7615
I0928 20:40:19.960760  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.722119 (* 1 = 0.722119 loss)
I0928 20:40:20.105841  5237 solver.cpp:218] Iteration 16000 (5.4722 iter/s, 18.2742s/100 iters), loss = 0.405731
I0928 20:40:20.105875  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405731 (* 1 = 0.405731 loss)
I0928 20:40:20.105881  5237 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I0928 20:40:34.782496  5237 solver.cpp:218] Iteration 16100 (6.81358 iter/s, 14.6766s/100 iters), loss = 0.398683
I0928 20:40:34.782529  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.398683 (* 1 = 0.398683 loss)
I0928 20:40:34.782536  5237 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I0928 20:40:49.471256  5237 solver.cpp:218] Iteration 16200 (6.80796 iter/s, 14.6887s/100 iters), loss = 0.418158
I0928 20:40:49.471380  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.418158 (* 1 = 0.418158 loss)
I0928 20:40:49.471388  5237 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I0928 20:41:04.111027  5237 solver.cpp:218] Iteration 16300 (6.83079 iter/s, 14.6396s/100 iters), loss = 0.384562
I0928 20:41:04.111063  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.384562 (* 1 = 0.384562 loss)
I0928 20:41:04.111069  5237 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I0928 20:41:18.792770  5237 solver.cpp:218] Iteration 16400 (6.81121 iter/s, 14.6817s/100 iters), loss = 0.508914
I0928 20:41:18.792801  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.508914 (* 1 = 0.508914 loss)
I0928 20:41:18.792807  5237 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I0928 20:41:32.750532  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:41:33.334071  5237 solver.cpp:330] Iteration 16500, Testing net (#0)
I0928 20:41:36.760470  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:41:36.903431  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6999
I0928 20:41:36.903468  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.950829 (* 1 = 0.950829 loss)
I0928 20:41:37.048166  5237 solver.cpp:218] Iteration 16500 (5.47786 iter/s, 18.2553s/100 iters), loss = 0.316703
I0928 20:41:37.048197  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316703 (* 1 = 0.316703 loss)
I0928 20:41:37.048204  5237 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I0928 20:41:51.694072  5237 solver.cpp:218] Iteration 16600 (6.82788 iter/s, 14.6458s/100 iters), loss = 0.307648
I0928 20:41:51.694104  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307648 (* 1 = 0.307648 loss)
I0928 20:41:51.694110  5237 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I0928 20:42:06.303213  5237 solver.cpp:218] Iteration 16700 (6.84506 iter/s, 14.6091s/100 iters), loss = 0.394349
I0928 20:42:06.303355  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.394349 (* 1 = 0.394349 loss)
I0928 20:42:06.303364  5237 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I0928 20:42:20.900009  5237 solver.cpp:218] Iteration 16800 (6.8509 iter/s, 14.5966s/100 iters), loss = 0.332221
I0928 20:42:20.900049  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.332221 (* 1 = 0.332221 loss)
I0928 20:42:20.900055  5237 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I0928 20:42:35.495514  5237 solver.cpp:218] Iteration 16900 (6.85146 iter/s, 14.5954s/100 iters), loss = 0.397337
I0928 20:42:35.495553  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.397337 (* 1 = 0.397337 loss)
I0928 20:42:35.495560  5237 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I0928 20:42:49.361660  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:42:49.945071  5237 solver.cpp:330] Iteration 17000, Testing net (#0)
I0928 20:42:53.365671  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:42:53.509079  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7439
I0928 20:42:53.509104  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.749751 (* 1 = 0.749751 loss)
I0928 20:42:53.653264  5237 solver.cpp:218] Iteration 17000 (5.50732 iter/s, 18.1577s/100 iters), loss = 0.373833
I0928 20:42:53.653295  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.373833 (* 1 = 0.373833 loss)
I0928 20:42:53.653301  5237 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I0928 20:43:08.246982  5237 solver.cpp:218] Iteration 17100 (6.8523 iter/s, 14.5936s/100 iters), loss = 0.339982
I0928 20:43:08.247023  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.339982 (* 1 = 0.339982 loss)
I0928 20:43:08.247030  5237 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I0928 20:43:22.841751  5237 solver.cpp:218] Iteration 17200 (6.85181 iter/s, 14.5947s/100 iters), loss = 0.365499
I0928 20:43:22.841862  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365499 (* 1 = 0.365499 loss)
I0928 20:43:22.841879  5237 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I0928 20:43:37.439291  5237 solver.cpp:218] Iteration 17300 (6.85054 iter/s, 14.5974s/100 iters), loss = 0.490651
I0928 20:43:37.439332  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.490651 (* 1 = 0.490651 loss)
I0928 20:43:37.439337  5237 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I0928 20:43:52.037832  5237 solver.cpp:218] Iteration 17400 (6.85004 iter/s, 14.5985s/100 iters), loss = 0.364954
I0928 20:43:52.037863  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.364954 (* 1 = 0.364954 loss)
I0928 20:43:52.037869  5237 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I0928 20:44:05.907925  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:44:06.494174  5237 solver.cpp:330] Iteration 17500, Testing net (#0)
I0928 20:44:09.914052  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:44:10.057230  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.757
I0928 20:44:10.057266  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.737312 (* 1 = 0.737312 loss)
I0928 20:44:10.202172  5237 solver.cpp:218] Iteration 17500 (5.50532 iter/s, 18.1643s/100 iters), loss = 0.454731
I0928 20:44:10.202203  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.454731 (* 1 = 0.454731 loss)
I0928 20:44:10.202208  5237 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I0928 20:44:24.794010  5237 solver.cpp:218] Iteration 17600 (6.85318 iter/s, 14.5918s/100 iters), loss = 0.338674
I0928 20:44:24.794042  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338674 (* 1 = 0.338674 loss)
I0928 20:44:24.794049  5237 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I0928 20:44:39.397809  5237 solver.cpp:218] Iteration 17700 (6.84757 iter/s, 14.6037s/100 iters), loss = 0.349145
I0928 20:44:39.397927  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349145 (* 1 = 0.349145 loss)
I0928 20:44:39.397945  5237 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I0928 20:44:53.991376  5237 solver.cpp:218] Iteration 17800 (6.8524 iter/s, 14.5934s/100 iters), loss = 0.453889
I0928 20:44:53.991406  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.453889 (* 1 = 0.453889 loss)
I0928 20:44:53.991423  5237 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I0928 20:45:08.588666  5237 solver.cpp:218] Iteration 17900 (6.85062 iter/s, 14.5972s/100 iters), loss = 0.446636
I0928 20:45:08.588696  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.446636 (* 1 = 0.446636 loss)
I0928 20:45:08.588701  5237 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I0928 20:45:22.456321  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:45:23.040719  5237 solver.cpp:330] Iteration 18000, Testing net (#0)
I0928 20:45:26.461247  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:45:26.604382  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7833
I0928 20:45:26.604406  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.647426 (* 1 = 0.647426 loss)
I0928 20:45:26.748452  5237 solver.cpp:218] Iteration 18000 (5.5067 iter/s, 18.1597s/100 iters), loss = 0.360186
I0928 20:45:26.748486  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.360186 (* 1 = 0.360186 loss)
I0928 20:45:26.748492  5237 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I0928 20:45:41.345651  5237 solver.cpp:218] Iteration 18100 (6.85066 iter/s, 14.5971s/100 iters), loss = 0.358499
I0928 20:45:41.345679  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.358499 (* 1 = 0.358499 loss)
I0928 20:45:41.345685  5237 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I0928 20:45:55.942742  5237 solver.cpp:218] Iteration 18200 (6.85071 iter/s, 14.597s/100 iters), loss = 0.371052
I0928 20:45:55.942847  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371053 (* 1 = 0.371053 loss)
I0928 20:45:55.942854  5237 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I0928 20:46:10.542234  5237 solver.cpp:218] Iteration 18300 (6.84962 iter/s, 14.5994s/100 iters), loss = 0.409095
I0928 20:46:10.542264  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.409095 (* 1 = 0.409095 loss)
I0928 20:46:10.542270  5237 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I0928 20:46:25.140130  5237 solver.cpp:218] Iteration 18400 (6.85034 iter/s, 14.5978s/100 iters), loss = 0.338393
I0928 20:46:25.140161  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338393 (* 1 = 0.338393 loss)
I0928 20:46:25.140166  5237 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I0928 20:46:39.007367  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:46:39.591461  5237 solver.cpp:330] Iteration 18500, Testing net (#0)
I0928 20:46:43.011544  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:46:43.154404  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.784
I0928 20:46:43.154430  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.622324 (* 1 = 0.622324 loss)
I0928 20:46:43.298893  5237 solver.cpp:218] Iteration 18500 (5.50701 iter/s, 18.1587s/100 iters), loss = 0.269674
I0928 20:46:43.298928  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269674 (* 1 = 0.269674 loss)
I0928 20:46:43.298938  5237 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I0928 20:46:57.897122  5237 solver.cpp:218] Iteration 18600 (6.85018 iter/s, 14.5982s/100 iters), loss = 0.41041
I0928 20:46:57.897162  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.41041 (* 1 = 0.41041 loss)
I0928 20:46:57.897168  5237 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I0928 20:47:12.496417  5237 solver.cpp:218] Iteration 18700 (6.84968 iter/s, 14.5992s/100 iters), loss = 0.38586
I0928 20:47:12.496556  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.38586 (* 1 = 0.38586 loss)
I0928 20:47:12.496564  5237 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I0928 20:47:27.167187  5237 solver.cpp:218] Iteration 18800 (6.81636 iter/s, 14.6706s/100 iters), loss = 0.454365
I0928 20:47:27.167222  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.454365 (* 1 = 0.454365 loss)
I0928 20:47:27.167227  5237 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I0928 20:47:41.825376  5237 solver.cpp:218] Iteration 18900 (6.82216 iter/s, 14.6581s/100 iters), loss = 0.282219
I0928 20:47:41.825407  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282219 (* 1 = 0.282219 loss)
I0928 20:47:41.825414  5237 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I0928 20:47:55.744007  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:47:56.332002  5237 solver.cpp:330] Iteration 19000, Testing net (#0)
I0928 20:47:59.766296  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:47:59.909236  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7995
I0928 20:47:59.909271  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.581945 (* 1 = 0.581945 loss)
I0928 20:48:00.053980  5237 solver.cpp:218] Iteration 19000 (5.48591 iter/s, 18.2285s/100 iters), loss = 0.302311
I0928 20:48:00.054015  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302311 (* 1 = 0.302311 loss)
I0928 20:48:00.054021  5237 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I0928 20:48:14.737004  5237 solver.cpp:218] Iteration 19100 (6.81062 iter/s, 14.6829s/100 iters), loss = 0.317824
I0928 20:48:14.737036  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317824 (* 1 = 0.317824 loss)
I0928 20:48:14.737042  5237 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I0928 20:48:29.420140  5237 solver.cpp:218] Iteration 19200 (6.81057 iter/s, 14.6831s/100 iters), loss = 0.330278
I0928 20:48:29.420282  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330278 (* 1 = 0.330278 loss)
I0928 20:48:29.420290  5237 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I0928 20:48:44.126041  5237 solver.cpp:218] Iteration 19300 (6.80007 iter/s, 14.7057s/100 iters), loss = 0.354304
I0928 20:48:44.126083  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.354304 (* 1 = 0.354304 loss)
I0928 20:48:44.126091  5237 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I0928 20:48:58.807323  5237 solver.cpp:218] Iteration 19400 (6.81143 iter/s, 14.6812s/100 iters), loss = 0.30542
I0928 20:48:58.807361  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30542 (* 1 = 0.30542 loss)
I0928 20:48:58.807369  5237 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I0928 20:49:12.734402  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:49:13.321681  5237 solver.cpp:330] Iteration 19500, Testing net (#0)
I0928 20:49:16.763090  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:49:16.906148  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.793
I0928 20:49:16.906173  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.62252 (* 1 = 0.62252 loss)
I0928 20:49:17.051087  5237 solver.cpp:218] Iteration 19500 (5.48135 iter/s, 18.2437s/100 iters), loss = 0.306414
I0928 20:49:17.051118  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306414 (* 1 = 0.306414 loss)
I0928 20:49:17.051126  5237 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I0928 20:49:31.723429  5237 solver.cpp:218] Iteration 19600 (6.81558 iter/s, 14.6723s/100 iters), loss = 0.362578
I0928 20:49:31.723459  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362578 (* 1 = 0.362578 loss)
I0928 20:49:31.723465  5237 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I0928 20:49:46.324005  5237 solver.cpp:218] Iteration 19700 (6.84908 iter/s, 14.6005s/100 iters), loss = 0.349066
I0928 20:49:46.324136  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349066 (* 1 = 0.349066 loss)
I0928 20:49:46.324142  5237 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I0928 20:50:00.922227  5237 solver.cpp:218] Iteration 19800 (6.85022 iter/s, 14.5981s/100 iters), loss = 0.48274
I0928 20:50:00.922256  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.48274 (* 1 = 0.48274 loss)
I0928 20:50:00.922262  5237 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I0928 20:50:15.523291  5237 solver.cpp:218] Iteration 19900 (6.84885 iter/s, 14.601s/100 iters), loss = 0.320081
I0928 20:50:15.523322  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320081 (* 1 = 0.320081 loss)
I0928 20:50:15.523329  5237 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I0928 20:50:29.482025  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:50:30.068516  5237 solver.cpp:330] Iteration 20000, Testing net (#0)
I0928 20:50:33.504117  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:50:33.647825  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7844
I0928 20:50:33.647850  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.622144 (* 1 = 0.622144 loss)
I0928 20:50:33.791920  5237 solver.cpp:218] Iteration 20000 (5.47389 iter/s, 18.2686s/100 iters), loss = 0.366506
I0928 20:50:33.791947  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366506 (* 1 = 0.366506 loss)
I0928 20:50:33.791954  5237 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I0928 20:50:48.434263  5237 solver.cpp:218] Iteration 20100 (6.82954 iter/s, 14.6423s/100 iters), loss = 0.28513
I0928 20:50:48.434304  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28513 (* 1 = 0.28513 loss)
I0928 20:50:48.434310  5237 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I0928 20:51:03.114032  5237 solver.cpp:218] Iteration 20200 (6.81214 iter/s, 14.6797s/100 iters), loss = 0.318908
I0928 20:51:03.114176  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.318908 (* 1 = 0.318908 loss)
I0928 20:51:03.114187  5237 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I0928 20:51:17.789994  5237 solver.cpp:218] Iteration 20300 (6.81395 iter/s, 14.6758s/100 iters), loss = 0.474287
I0928 20:51:17.790024  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.474287 (* 1 = 0.474287 loss)
I0928 20:51:17.790030  5237 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I0928 20:51:32.384838  5237 solver.cpp:218] Iteration 20400 (6.85177 iter/s, 14.5948s/100 iters), loss = 0.310964
I0928 20:51:32.384867  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310964 (* 1 = 0.310964 loss)
I0928 20:51:32.384873  5237 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I0928 20:51:46.320118  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:51:46.907935  5237 solver.cpp:330] Iteration 20500, Testing net (#0)
I0928 20:51:50.341256  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:51:50.484326  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7967
I0928 20:51:50.484350  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.601969 (* 1 = 0.601969 loss)
I0928 20:51:50.628224  5237 solver.cpp:218] Iteration 20500 (5.48146 iter/s, 18.2433s/100 iters), loss = 0.395382
I0928 20:51:50.628250  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.395382 (* 1 = 0.395382 loss)
I0928 20:51:50.628257  5237 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I0928 20:52:05.339887  5237 solver.cpp:218] Iteration 20600 (6.79736 iter/s, 14.7116s/100 iters), loss = 0.344967
I0928 20:52:05.339920  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344967 (* 1 = 0.344967 loss)
I0928 20:52:05.339926  5237 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I0928 20:52:20.039379  5237 solver.cpp:218] Iteration 20700 (6.80299 iter/s, 14.6994s/100 iters), loss = 0.356366
I0928 20:52:20.039499  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.356366 (* 1 = 0.356366 loss)
I0928 20:52:20.039507  5237 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I0928 20:52:34.710294  5237 solver.cpp:218] Iteration 20800 (6.81628 iter/s, 14.6708s/100 iters), loss = 0.374189
I0928 20:52:34.710327  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.374189 (* 1 = 0.374189 loss)
I0928 20:52:34.710333  5237 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I0928 20:52:49.412758  5237 solver.cpp:218] Iteration 20900 (6.80161 iter/s, 14.7024s/100 iters), loss = 0.3207
I0928 20:52:49.412788  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.3207 (* 1 = 0.3207 loss)
I0928 20:52:49.412794  5237 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I0928 20:53:03.387697  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:53:03.976537  5237 solver.cpp:330] Iteration 21000, Testing net (#0)
I0928 20:53:07.415776  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:53:07.559022  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.749
I0928 20:53:07.559057  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.763583 (* 1 = 0.763583 loss)
I0928 20:53:07.705082  5237 solver.cpp:218] Iteration 21000 (5.4668 iter/s, 18.2922s/100 iters), loss = 0.322551
I0928 20:53:07.705116  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322552 (* 1 = 0.322552 loss)
I0928 20:53:07.705121  5237 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I0928 20:53:22.309469  5237 solver.cpp:218] Iteration 21100 (6.84729 iter/s, 14.6043s/100 iters), loss = 0.288524
I0928 20:53:22.309500  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288524 (* 1 = 0.288524 loss)
I0928 20:53:22.309506  5237 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I0928 20:53:36.902968  5237 solver.cpp:218] Iteration 21200 (6.8524 iter/s, 14.5934s/100 iters), loss = 0.304095
I0928 20:53:36.903095  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304095 (* 1 = 0.304095 loss)
I0928 20:53:36.903102  5237 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I0928 20:53:51.550933  5237 solver.cpp:218] Iteration 21300 (6.82696 iter/s, 14.6478s/100 iters), loss = 0.516548
I0928 20:53:51.550962  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.516548 (* 1 = 0.516548 loss)
I0928 20:53:51.550968  5237 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I0928 20:54:06.234949  5237 solver.cpp:218] Iteration 21400 (6.81016 iter/s, 14.6839s/100 iters), loss = 0.391905
I0928 20:54:06.234980  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.391905 (* 1 = 0.391905 loss)
I0928 20:54:06.234987  5237 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I0928 20:54:20.167510  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:54:20.757621  5237 solver.cpp:330] Iteration 21500, Testing net (#0)
I0928 20:54:24.215188  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:54:24.359184  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7492
I0928 20:54:24.359210  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.737528 (* 1 = 0.737528 loss)
I0928 20:54:24.504829  5237 solver.cpp:218] Iteration 21500 (5.47352 iter/s, 18.2698s/100 iters), loss = 0.395023
I0928 20:54:24.504879  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.395023 (* 1 = 0.395023 loss)
I0928 20:54:24.504897  5237 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I0928 20:54:39.212599  5237 solver.cpp:218] Iteration 21600 (6.79917 iter/s, 14.7077s/100 iters), loss = 0.284851
I0928 20:54:39.212642  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284851 (* 1 = 0.284851 loss)
I0928 20:54:39.212649  5237 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I0928 20:54:53.915305  5237 solver.cpp:218] Iteration 21700 (6.80151 iter/s, 14.7026s/100 iters), loss = 0.259007
I0928 20:54:53.915426  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259007 (* 1 = 0.259007 loss)
I0928 20:54:53.915433  5237 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I0928 20:55:08.593436  5237 solver.cpp:218] Iteration 21800 (6.81293 iter/s, 14.678s/100 iters), loss = 0.459186
I0928 20:55:08.593466  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.459186 (* 1 = 0.459186 loss)
I0928 20:55:08.593472  5237 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I0928 20:55:23.279443  5237 solver.cpp:218] Iteration 21900 (6.80924 iter/s, 14.6859s/100 iters), loss = 0.339207
I0928 20:55:23.279477  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.339207 (* 1 = 0.339207 loss)
I0928 20:55:23.279485  5237 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I0928 20:55:37.169644  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:55:37.754420  5237 solver.cpp:330] Iteration 22000, Testing net (#0)
I0928 20:55:41.174465  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:55:41.316547  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8052
I0928 20:55:41.316581  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.571956 (* 1 = 0.571956 loss)
I0928 20:55:41.461575  5237 solver.cpp:218] Iteration 22000 (5.49993 iter/s, 18.182s/100 iters), loss = 0.277035
I0928 20:55:41.461604  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277035 (* 1 = 0.277035 loss)
I0928 20:55:41.461611  5237 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I0928 20:55:56.057970  5237 solver.cpp:218] Iteration 22100 (6.85104 iter/s, 14.5963s/100 iters), loss = 0.325738
I0928 20:55:56.057997  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325738 (* 1 = 0.325738 loss)
I0928 20:55:56.058002  5237 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I0928 20:56:10.654559  5237 solver.cpp:218] Iteration 22200 (6.85095 iter/s, 14.5965s/100 iters), loss = 0.402751
I0928 20:56:10.654676  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.402751 (* 1 = 0.402751 loss)
I0928 20:56:10.654693  5237 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I0928 20:56:25.312391  5237 solver.cpp:218] Iteration 22300 (6.82236 iter/s, 14.6577s/100 iters), loss = 0.445233
I0928 20:56:25.312424  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.445234 (* 1 = 0.445234 loss)
I0928 20:56:25.312430  5237 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I0928 20:56:39.988963  5237 solver.cpp:218] Iteration 22400 (6.81361 iter/s, 14.6765s/100 iters), loss = 0.366589
I0928 20:56:39.989002  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366589 (* 1 = 0.366589 loss)
I0928 20:56:39.989008  5237 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I0928 20:56:53.921855  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:56:54.507968  5237 solver.cpp:330] Iteration 22500, Testing net (#0)
I0928 20:56:57.961899  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:56:58.105425  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8106
I0928 20:56:58.105455  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.578401 (* 1 = 0.578401 loss)
I0928 20:56:58.252729  5237 solver.cpp:218] Iteration 22500 (5.47535 iter/s, 18.2637s/100 iters), loss = 0.341749
I0928 20:56:58.252763  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.341749 (* 1 = 0.341749 loss)
I0928 20:56:58.252769  5237 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I0928 20:57:12.914046  5237 solver.cpp:218] Iteration 22600 (6.8207 iter/s, 14.6612s/100 iters), loss = 0.350353
I0928 20:57:12.914077  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350353 (* 1 = 0.350353 loss)
I0928 20:57:12.914084  5237 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I0928 20:57:27.603221  5237 solver.cpp:218] Iteration 22700 (6.80777 iter/s, 14.6891s/100 iters), loss = 0.368097
I0928 20:57:27.603349  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.368097 (* 1 = 0.368097 loss)
I0928 20:57:27.603361  5237 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I0928 20:57:42.298140  5237 solver.cpp:218] Iteration 22800 (6.80515 iter/s, 14.6948s/100 iters), loss = 0.35344
I0928 20:57:42.298171  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35344 (* 1 = 0.35344 loss)
I0928 20:57:42.298178  5237 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I0928 20:57:56.981154  5237 solver.cpp:218] Iteration 22900 (6.81062 iter/s, 14.6829s/100 iters), loss = 0.343269
I0928 20:57:56.981187  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34327 (* 1 = 0.34327 loss)
I0928 20:57:56.981195  5237 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I0928 20:58:10.916398  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:58:11.505492  5237 solver.cpp:330] Iteration 23000, Testing net (#0)
I0928 20:58:14.939721  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:58:15.084224  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7651
I0928 20:58:15.084250  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.705347 (* 1 = 0.705347 loss)
I0928 20:58:15.229389  5237 solver.cpp:218] Iteration 23000 (5.48001 iter/s, 18.2482s/100 iters), loss = 0.315695
I0928 20:58:15.229421  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315695 (* 1 = 0.315695 loss)
I0928 20:58:15.229429  5237 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I0928 20:58:29.923665  5237 solver.cpp:218] Iteration 23100 (6.8054 iter/s, 14.6942s/100 iters), loss = 0.323214
I0928 20:58:29.923696  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323214 (* 1 = 0.323214 loss)
I0928 20:58:29.923710  5237 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I0928 20:58:44.639675  5237 solver.cpp:218] Iteration 23200 (6.79535 iter/s, 14.7159s/100 iters), loss = 0.316683
I0928 20:58:44.639793  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316683 (* 1 = 0.316683 loss)
I0928 20:58:44.639811  5237 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I0928 20:58:59.344715  5237 solver.cpp:218] Iteration 23300 (6.80046 iter/s, 14.7049s/100 iters), loss = 0.43174
I0928 20:58:59.344745  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.43174 (* 1 = 0.43174 loss)
I0928 20:58:59.344761  5237 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I0928 20:59:14.033174  5237 solver.cpp:218] Iteration 23400 (6.8081 iter/s, 14.6884s/100 iters), loss = 0.379488
I0928 20:59:14.033207  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.379488 (* 1 = 0.379488 loss)
I0928 20:59:14.033215  5237 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I0928 20:59:27.958209  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:59:28.544373  5237 solver.cpp:330] Iteration 23500, Testing net (#0)
I0928 20:59:31.968633  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 20:59:32.111378  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7706
I0928 20:59:32.111414  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.686692 (* 1 = 0.686692 loss)
I0928 20:59:32.255939  5237 solver.cpp:218] Iteration 23500 (5.48767 iter/s, 18.2227s/100 iters), loss = 0.316855
I0928 20:59:32.255970  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316855 (* 1 = 0.316855 loss)
I0928 20:59:32.255977  5237 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I0928 20:59:46.955807  5237 solver.cpp:218] Iteration 23600 (6.80282 iter/s, 14.6998s/100 iters), loss = 0.312069
I0928 20:59:46.955849  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312069 (* 1 = 0.312069 loss)
I0928 20:59:46.955857  5237 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I0928 21:00:01.650413  5237 solver.cpp:218] Iteration 23700 (6.80526 iter/s, 14.6945s/100 iters), loss = 0.403221
I0928 21:00:01.650558  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.403221 (* 1 = 0.403221 loss)
I0928 21:00:01.650578  5237 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I0928 21:00:16.320447  5237 solver.cpp:218] Iteration 23800 (6.8167 iter/s, 14.6699s/100 iters), loss = 0.323997
I0928 21:00:16.320492  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323997 (* 1 = 0.323997 loss)
I0928 21:00:16.320499  5237 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I0928 21:00:31.019675  5237 solver.cpp:218] Iteration 23900 (6.80312 iter/s, 14.6991s/100 iters), loss = 0.331561
I0928 21:00:31.019714  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331561 (* 1 = 0.331561 loss)
I0928 21:00:31.019721  5237 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I0928 21:00:44.970805  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:00:45.560295  5237 solver.cpp:330] Iteration 24000, Testing net (#0)
I0928 21:00:49.002420  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:00:49.145463  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7517
I0928 21:00:49.145498  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.728755 (* 1 = 0.728755 loss)
I0928 21:00:49.289880  5237 solver.cpp:218] Iteration 24000 (5.47342 iter/s, 18.2701s/100 iters), loss = 0.33708
I0928 21:00:49.289909  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.33708 (* 1 = 0.33708 loss)
I0928 21:00:49.289916  5237 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I0928 21:01:03.959763  5237 solver.cpp:218] Iteration 24100 (6.81672 iter/s, 14.6698s/100 iters), loss = 0.234356
I0928 21:01:03.959794  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234356 (* 1 = 0.234356 loss)
I0928 21:01:03.959800  5237 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I0928 21:01:18.643020  5237 solver.cpp:218] Iteration 24200 (6.81051 iter/s, 14.6832s/100 iters), loss = 0.313673
I0928 21:01:18.643175  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313674 (* 1 = 0.313674 loss)
I0928 21:01:18.643182  5237 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I0928 21:01:33.244065  5237 solver.cpp:218] Iteration 24300 (6.84892 iter/s, 14.6009s/100 iters), loss = 0.316937
I0928 21:01:33.244096  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316937 (* 1 = 0.316937 loss)
I0928 21:01:33.244102  5237 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I0928 21:01:47.944890  5237 solver.cpp:218] Iteration 24400 (6.80237 iter/s, 14.7008s/100 iters), loss = 0.347156
I0928 21:01:47.944917  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.347156 (* 1 = 0.347156 loss)
I0928 21:01:47.944924  5237 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I0928 21:02:01.908152  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:02:02.493885  5237 solver.cpp:330] Iteration 24500, Testing net (#0)
I0928 21:02:05.929075  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:02:06.071789  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.805
I0928 21:02:06.071813  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.577085 (* 1 = 0.577085 loss)
I0928 21:02:06.216341  5237 solver.cpp:218] Iteration 24500 (5.47304 iter/s, 18.2714s/100 iters), loss = 0.280054
I0928 21:02:06.216373  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280054 (* 1 = 0.280054 loss)
I0928 21:02:06.216379  5237 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I0928 21:02:20.891113  5237 solver.cpp:218] Iteration 24600 (6.81445 iter/s, 14.6747s/100 iters), loss = 0.324289
I0928 21:02:20.891144  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324289 (* 1 = 0.324289 loss)
I0928 21:02:20.891150  5237 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I0928 21:02:35.556288  5237 solver.cpp:218] Iteration 24700 (6.81891 iter/s, 14.6651s/100 iters), loss = 0.496343
I0928 21:02:35.556387  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.496343 (* 1 = 0.496343 loss)
I0928 21:02:35.556394  5237 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I0928 21:02:50.245728  5237 solver.cpp:218] Iteration 24800 (6.80767 iter/s, 14.6893s/100 iters), loss = 0.426436
I0928 21:02:50.245779  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.426436 (* 1 = 0.426436 loss)
I0928 21:02:50.245784  5237 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I0928 21:03:04.934908  5237 solver.cpp:218] Iteration 24900 (6.80779 iter/s, 14.6891s/100 iters), loss = 0.371915
I0928 21:03:04.934938  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371915 (* 1 = 0.371915 loss)
I0928 21:03:04.934944  5237 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I0928 21:03:18.910024  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:03:19.494360  5237 solver.cpp:330] Iteration 25000, Testing net (#0)
I0928 21:03:22.922235  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:03:23.066136  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7516
I0928 21:03:23.066170  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.779186 (* 1 = 0.779186 loss)
I0928 21:03:23.211345  5237 solver.cpp:218] Iteration 25000 (5.47155 iter/s, 18.2764s/100 iters), loss = 0.367692
I0928 21:03:23.211376  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.367692 (* 1 = 0.367692 loss)
I0928 21:03:23.211383  5237 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I0928 21:03:37.910372  5237 solver.cpp:218] Iteration 25100 (6.8032 iter/s, 14.699s/100 iters), loss = 0.307253
I0928 21:03:37.910411  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307253 (* 1 = 0.307253 loss)
I0928 21:03:37.910418  5237 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I0928 21:03:52.636238  5237 solver.cpp:218] Iteration 25200 (6.79081 iter/s, 14.7258s/100 iters), loss = 0.382463
I0928 21:03:52.636374  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.382463 (* 1 = 0.382463 loss)
I0928 21:03:52.636394  5237 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I0928 21:04:07.317369  5237 solver.cpp:218] Iteration 25300 (6.81154 iter/s, 14.681s/100 iters), loss = 0.236927
I0928 21:04:07.317404  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236927 (* 1 = 0.236927 loss)
I0928 21:04:07.317410  5237 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I0928 21:04:22.025842  5237 solver.cpp:218] Iteration 25400 (6.79884 iter/s, 14.7084s/100 iters), loss = 0.282625
I0928 21:04:22.025885  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282625 (* 1 = 0.282625 loss)
I0928 21:04:22.025892  5237 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I0928 21:04:36.002707  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:04:36.585963  5237 solver.cpp:330] Iteration 25500, Testing net (#0)
I0928 21:04:40.008716  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:04:40.150285  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7986
I0928 21:04:40.150321  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.596816 (* 1 = 0.596816 loss)
I0928 21:04:40.294049  5237 solver.cpp:218] Iteration 25500 (5.47402 iter/s, 18.2681s/100 iters), loss = 0.34694
I0928 21:04:40.294081  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34694 (* 1 = 0.34694 loss)
I0928 21:04:40.294087  5237 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I0928 21:04:54.907568  5237 solver.cpp:218] Iteration 25600 (6.84305 iter/s, 14.6134s/100 iters), loss = 0.360962
I0928 21:04:54.907600  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.360962 (* 1 = 0.360962 loss)
I0928 21:04:54.907608  5237 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I0928 21:05:09.513306  5237 solver.cpp:218] Iteration 25700 (6.84666 iter/s, 14.6057s/100 iters), loss = 0.38778
I0928 21:05:09.513449  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.38778 (* 1 = 0.38778 loss)
I0928 21:05:09.513458  5237 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I0928 21:05:24.270418  5237 solver.cpp:218] Iteration 25800 (6.77648 iter/s, 14.7569s/100 iters), loss = 0.369515
I0928 21:05:24.270450  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.369516 (* 1 = 0.369516 loss)
I0928 21:05:24.270457  5237 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I0928 21:05:39.136780  5237 solver.cpp:218] Iteration 25900 (6.72663 iter/s, 14.8663s/100 iters), loss = 0.274635
I0928 21:05:39.136811  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274635 (* 1 = 0.274635 loss)
I0928 21:05:39.136818  5237 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I0928 21:05:53.235388  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:05:53.823086  5237 solver.cpp:330] Iteration 26000, Testing net (#0)
I0928 21:05:57.246609  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:05:57.389503  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7747
I0928 21:05:57.389528  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.685485 (* 1 = 0.685485 loss)
I0928 21:05:57.534838  5237 solver.cpp:218] Iteration 26000 (5.43538 iter/s, 18.398s/100 iters), loss = 0.372211
I0928 21:05:57.534868  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.372212 (* 1 = 0.372212 loss)
I0928 21:05:57.534874  5237 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I0928 21:06:12.149109  5237 solver.cpp:218] Iteration 26100 (6.84266 iter/s, 14.6142s/100 iters), loss = 0.342113
I0928 21:06:12.149139  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342114 (* 1 = 0.342114 loss)
I0928 21:06:12.149147  5237 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I0928 21:06:26.755390  5237 solver.cpp:218] Iteration 26200 (6.8464 iter/s, 14.6062s/100 iters), loss = 0.291824
I0928 21:06:26.755530  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291824 (* 1 = 0.291824 loss)
I0928 21:06:26.755538  5237 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I0928 21:06:41.367348  5237 solver.cpp:218] Iteration 26300 (6.84379 iter/s, 14.6118s/100 iters), loss = 0.417
I0928 21:06:41.367388  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.417 (* 1 = 0.417 loss)
I0928 21:06:41.367396  5237 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I0928 21:06:55.980792  5237 solver.cpp:218] Iteration 26400 (6.84305 iter/s, 14.6134s/100 iters), loss = 0.300021
I0928 21:06:55.980831  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300021 (* 1 = 0.300021 loss)
I0928 21:06:55.980836  5237 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I0928 21:07:09.863373  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:07:10.447448  5237 solver.cpp:330] Iteration 26500, Testing net (#0)
I0928 21:07:13.873188  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:07:14.016289  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7753
I0928 21:07:14.016315  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.651739 (* 1 = 0.651739 loss)
I0928 21:07:14.161255  5237 solver.cpp:218] Iteration 26500 (5.50044 iter/s, 18.1804s/100 iters), loss = 0.306174
I0928 21:07:14.161286  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306174 (* 1 = 0.306174 loss)
I0928 21:07:14.161293  5237 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I0928 21:07:28.773331  5237 solver.cpp:218] Iteration 26600 (6.84369 iter/s, 14.612s/100 iters), loss = 0.29385
I0928 21:07:28.773358  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29385 (* 1 = 0.29385 loss)
I0928 21:07:28.773365  5237 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I0928 21:07:43.382356  5237 solver.cpp:218] Iteration 26700 (6.84512 iter/s, 14.609s/100 iters), loss = 0.335276
I0928 21:07:43.382508  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335277 (* 1 = 0.335277 loss)
I0928 21:07:43.382515  5237 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I0928 21:07:57.978652  5237 solver.cpp:218] Iteration 26800 (6.85114 iter/s, 14.5961s/100 iters), loss = 0.354049
I0928 21:07:57.978682  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.354049 (* 1 = 0.354049 loss)
I0928 21:07:57.978688  5237 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I0928 21:08:12.578553  5237 solver.cpp:218] Iteration 26900 (6.84939 iter/s, 14.5998s/100 iters), loss = 0.284747
I0928 21:08:12.578583  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284747 (* 1 = 0.284747 loss)
I0928 21:08:12.578590  5237 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I0928 21:08:26.459589  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:08:27.043519  5237 solver.cpp:330] Iteration 27000, Testing net (#0)
I0928 21:08:30.465852  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:08:30.608752  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6808
I0928 21:08:30.608788  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.9941 (* 1 = 0.9941 loss)
I0928 21:08:30.753545  5237 solver.cpp:218] Iteration 27000 (5.50209 iter/s, 18.1749s/100 iters), loss = 0.313679
I0928 21:08:30.753579  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313679 (* 1 = 0.313679 loss)
I0928 21:08:30.753587  5237 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I0928 21:08:45.357025  5237 solver.cpp:218] Iteration 27100 (6.84772 iter/s, 14.6034s/100 iters), loss = 0.32714
I0928 21:08:45.357054  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32714 (* 1 = 0.32714 loss)
I0928 21:08:45.357060  5237 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I0928 21:08:59.961285  5237 solver.cpp:218] Iteration 27200 (6.84735 iter/s, 14.6042s/100 iters), loss = 0.300584
I0928 21:08:59.961405  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300584 (* 1 = 0.300584 loss)
I0928 21:08:59.961421  5237 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I0928 21:09:14.561676  5237 solver.cpp:218] Iteration 27300 (6.84921 iter/s, 14.6002s/100 iters), loss = 0.335629
I0928 21:09:14.561704  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335629 (* 1 = 0.335629 loss)
I0928 21:09:14.561710  5237 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I0928 21:09:29.165908  5237 solver.cpp:218] Iteration 27400 (6.84736 iter/s, 14.6042s/100 iters), loss = 0.285232
I0928 21:09:29.165938  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285232 (* 1 = 0.285232 loss)
I0928 21:09:29.165943  5237 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I0928 21:09:43.045451  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:09:43.629457  5237 solver.cpp:330] Iteration 27500, Testing net (#0)
I0928 21:09:47.054354  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:09:47.197445  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.728
I0928 21:09:47.197481  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.846645 (* 1 = 0.846645 loss)
I0928 21:09:47.342823  5237 solver.cpp:218] Iteration 27500 (5.50151 iter/s, 18.1768s/100 iters), loss = 0.297518
I0928 21:09:47.342859  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297518 (* 1 = 0.297518 loss)
I0928 21:09:47.342866  5237 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I0928 21:10:01.948858  5237 solver.cpp:218] Iteration 27600 (6.84652 iter/s, 14.606s/100 iters), loss = 0.274779
I0928 21:10:01.948886  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274779 (* 1 = 0.274779 loss)
I0928 21:10:01.948892  5237 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I0928 21:10:16.555367  5237 solver.cpp:218] Iteration 27700 (6.84629 iter/s, 14.6064s/100 iters), loss = 0.331472
I0928 21:10:16.555465  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331472 (* 1 = 0.331472 loss)
I0928 21:10:16.555474  5237 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I0928 21:10:31.163607  5237 solver.cpp:218] Iteration 27800 (6.84552 iter/s, 14.6081s/100 iters), loss = 0.366759
I0928 21:10:31.163643  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366759 (* 1 = 0.366759 loss)
I0928 21:10:31.163650  5237 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I0928 21:10:45.768167  5237 solver.cpp:218] Iteration 27900 (6.84721 iter/s, 14.6045s/100 iters), loss = 0.303457
I0928 21:10:45.768198  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303458 (* 1 = 0.303458 loss)
I0928 21:10:45.768203  5237 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I0928 21:10:59.648003  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:11:00.233842  5237 solver.cpp:330] Iteration 28000, Testing net (#0)
I0928 21:11:03.658148  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:11:03.800892  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6747
I0928 21:11:03.800917  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.08024 (* 1 = 1.08024 loss)
I0928 21:11:03.946169  5237 solver.cpp:218] Iteration 28000 (5.50118 iter/s, 18.1779s/100 iters), loss = 0.383492
I0928 21:11:03.946198  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.383492 (* 1 = 0.383492 loss)
I0928 21:11:03.946204  5237 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I0928 21:11:18.541102  5237 solver.cpp:218] Iteration 28100 (6.85173 iter/s, 14.5949s/100 iters), loss = 0.316653
I0928 21:11:18.541131  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316654 (* 1 = 0.316654 loss)
I0928 21:11:18.541137  5237 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I0928 21:11:33.151269  5237 solver.cpp:218] Iteration 28200 (6.84458 iter/s, 14.6101s/100 iters), loss = 0.419569
I0928 21:11:33.151394  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.41957 (* 1 = 0.41957 loss)
I0928 21:11:33.151402  5237 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I0928 21:11:47.752187  5237 solver.cpp:218] Iteration 28300 (6.84896 iter/s, 14.6008s/100 iters), loss = 0.294872
I0928 21:11:47.752220  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294872 (* 1 = 0.294872 loss)
I0928 21:11:47.752226  5237 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I0928 21:12:02.345703  5237 solver.cpp:218] Iteration 28400 (6.85239 iter/s, 14.5934s/100 iters), loss = 0.246724
I0928 21:12:02.345733  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246724 (* 1 = 0.246724 loss)
I0928 21:12:02.345739  5237 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I0928 21:12:16.222247  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:12:16.807674  5237 solver.cpp:330] Iteration 28500, Testing net (#0)
I0928 21:12:20.232952  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:12:20.376170  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7565
I0928 21:12:20.376205  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.777836 (* 1 = 0.777836 loss)
I0928 21:12:20.521133  5237 solver.cpp:218] Iteration 28500 (5.50196 iter/s, 18.1754s/100 iters), loss = 0.348883
I0928 21:12:20.521163  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.348883 (* 1 = 0.348883 loss)
I0928 21:12:20.521170  5237 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I0928 21:12:35.120121  5237 solver.cpp:218] Iteration 28600 (6.84982 iter/s, 14.5989s/100 iters), loss = 0.237584
I0928 21:12:35.120151  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237585 (* 1 = 0.237585 loss)
I0928 21:12:35.120159  5237 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I0928 21:12:49.724542  5237 solver.cpp:218] Iteration 28700 (6.84727 iter/s, 14.6044s/100 iters), loss = 0.420556
I0928 21:12:49.724650  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.420557 (* 1 = 0.420557 loss)
I0928 21:12:49.724660  5237 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I0928 21:13:04.328707  5237 solver.cpp:218] Iteration 28800 (6.84743 iter/s, 14.604s/100 iters), loss = 0.374212
I0928 21:13:04.328740  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.374212 (* 1 = 0.374212 loss)
I0928 21:13:04.328748  5237 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I0928 21:13:18.935720  5237 solver.cpp:218] Iteration 28900 (6.84606 iter/s, 14.6069s/100 iters), loss = 0.338922
I0928 21:13:18.935752  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338922 (* 1 = 0.338922 loss)
I0928 21:13:18.935761  5237 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I0928 21:13:32.821835  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:13:33.406956  5237 solver.cpp:330] Iteration 29000, Testing net (#0)
I0928 21:13:36.831835  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:13:36.975420  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7832
I0928 21:13:36.975446  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.646397 (* 1 = 0.646397 loss)
I0928 21:13:37.121065  5237 solver.cpp:218] Iteration 29000 (5.49896 iter/s, 18.1853s/100 iters), loss = 0.270709
I0928 21:13:37.121101  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270709 (* 1 = 0.270709 loss)
I0928 21:13:37.121111  5237 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I0928 21:13:51.727182  5237 solver.cpp:218] Iteration 29100 (6.84648 iter/s, 14.606s/100 iters), loss = 0.246444
I0928 21:13:51.727214  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246444 (* 1 = 0.246444 loss)
I0928 21:13:51.727223  5237 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I0928 21:14:06.330763  5237 solver.cpp:218] Iteration 29200 (6.84767 iter/s, 14.6035s/100 iters), loss = 0.295768
I0928 21:14:06.330911  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295768 (* 1 = 0.295768 loss)
I0928 21:14:06.330934  5237 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I0928 21:14:20.940048  5237 solver.cpp:218] Iteration 29300 (6.84504 iter/s, 14.6091s/100 iters), loss = 0.383176
I0928 21:14:20.940080  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.383176 (* 1 = 0.383176 loss)
I0928 21:14:20.940088  5237 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I0928 21:14:35.549393  5237 solver.cpp:218] Iteration 29400 (6.84497 iter/s, 14.6093s/100 iters), loss = 0.378636
I0928 21:14:35.549425  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378636 (* 1 = 0.378636 loss)
I0928 21:14:35.549433  5237 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I0928 21:14:49.432112  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:14:50.016149  5237 solver.cpp:330] Iteration 29500, Testing net (#0)
I0928 21:14:53.438423  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:14:53.581789  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8093
I0928 21:14:53.581815  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.559216 (* 1 = 0.559216 loss)
I0928 21:14:53.727397  5237 solver.cpp:218] Iteration 29500 (5.50118 iter/s, 18.1779s/100 iters), loss = 0.330398
I0928 21:14:53.727432  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330398 (* 1 = 0.330398 loss)
I0928 21:14:53.727442  5237 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I0928 21:15:08.330833  5237 solver.cpp:218] Iteration 29600 (6.84774 iter/s, 14.6034s/100 iters), loss = 0.250779
I0928 21:15:08.330863  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250779 (* 1 = 0.250779 loss)
I0928 21:15:08.330869  5237 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I0928 21:15:22.935036  5237 solver.cpp:218] Iteration 29700 (6.84738 iter/s, 14.6041s/100 iters), loss = 0.240495
I0928 21:15:22.935150  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240495 (* 1 = 0.240495 loss)
I0928 21:15:22.935158  5237 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I0928 21:15:37.537861  5237 solver.cpp:218] Iteration 29800 (6.84806 iter/s, 14.6027s/100 iters), loss = 0.314951
I0928 21:15:37.537894  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314952 (* 1 = 0.314952 loss)
I0928 21:15:37.537899  5237 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I0928 21:15:52.146307  5237 solver.cpp:218] Iteration 29900 (6.84539 iter/s, 14.6084s/100 iters), loss = 0.334884
I0928 21:15:52.146345  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.334884 (* 1 = 0.334884 loss)
I0928 21:15:52.146353  5237 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I0928 21:16:06.029134  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:16:06.614157  5237 solver.cpp:330] Iteration 30000, Testing net (#0)
I0928 21:16:10.038846  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:16:10.182143  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7847
I0928 21:16:10.182179  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.669235 (* 1 = 0.669235 loss)
I0928 21:16:10.328209  5237 solver.cpp:218] Iteration 30000 (5.5 iter/s, 18.1818s/100 iters), loss = 0.253913
I0928 21:16:10.328239  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253913 (* 1 = 0.253913 loss)
I0928 21:16:10.328245  5237 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I0928 21:16:24.934309  5237 solver.cpp:218] Iteration 30100 (6.84649 iter/s, 14.606s/100 iters), loss = 0.300035
I0928 21:16:24.934347  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300036 (* 1 = 0.300036 loss)
I0928 21:16:24.934353  5237 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I0928 21:16:39.536322  5237 solver.cpp:218] Iteration 30200 (6.84841 iter/s, 14.6019s/100 iters), loss = 0.370452
I0928 21:16:39.536458  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.370453 (* 1 = 0.370453 loss)
I0928 21:16:39.536466  5237 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I0928 21:16:54.145545  5237 solver.cpp:218] Iteration 30300 (6.84507 iter/s, 14.6091s/100 iters), loss = 0.253259
I0928 21:16:54.145576  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253259 (* 1 = 0.253259 loss)
I0928 21:16:54.145583  5237 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I0928 21:17:08.753983  5237 solver.cpp:218] Iteration 30400 (6.84539 iter/s, 14.6084s/100 iters), loss = 0.23404
I0928 21:17:08.754021  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23404 (* 1 = 0.23404 loss)
I0928 21:17:08.754027  5237 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I0928 21:17:22.633023  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:17:23.220162  5237 solver.cpp:330] Iteration 30500, Testing net (#0)
I0928 21:17:26.643875  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:17:26.786578  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8024
I0928 21:17:26.786614  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.596886 (* 1 = 0.596886 loss)
I0928 21:17:26.931803  5237 solver.cpp:218] Iteration 30500 (5.50123 iter/s, 18.1777s/100 iters), loss = 0.314316
I0928 21:17:26.931834  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314316 (* 1 = 0.314316 loss)
I0928 21:17:26.931841  5237 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I0928 21:17:41.536106  5237 solver.cpp:218] Iteration 30600 (6.84733 iter/s, 14.6042s/100 iters), loss = 0.222759
I0928 21:17:41.536136  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222759 (* 1 = 0.222759 loss)
I0928 21:17:41.536142  5237 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I0928 21:17:56.147625  5237 solver.cpp:218] Iteration 30700 (6.84395 iter/s, 14.6114s/100 iters), loss = 0.287917
I0928 21:17:56.147742  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287917 (* 1 = 0.287917 loss)
I0928 21:17:56.147748  5237 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I0928 21:18:10.754814  5237 solver.cpp:218] Iteration 30800 (6.84601 iter/s, 14.607s/100 iters), loss = 0.307887
I0928 21:18:10.754844  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307887 (* 1 = 0.307887 loss)
I0928 21:18:10.754849  5237 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I0928 21:18:25.354579  5237 solver.cpp:218] Iteration 30900 (6.84946 iter/s, 14.5997s/100 iters), loss = 0.232306
I0928 21:18:25.354609  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232306 (* 1 = 0.232306 loss)
I0928 21:18:25.354614  5237 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I0928 21:18:39.232203  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:18:39.817196  5237 solver.cpp:330] Iteration 31000, Testing net (#0)
I0928 21:18:43.239557  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:18:43.382799  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.765
I0928 21:18:43.382834  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.703602 (* 1 = 0.703602 loss)
I0928 21:18:43.528722  5237 solver.cpp:218] Iteration 31000 (5.50235 iter/s, 18.1741s/100 iters), loss = 0.329367
I0928 21:18:43.528753  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329367 (* 1 = 0.329367 loss)
I0928 21:18:43.528759  5237 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I0928 21:18:58.145946  5237 solver.cpp:218] Iteration 31100 (6.84128 iter/s, 14.6172s/100 iters), loss = 0.347592
I0928 21:18:58.145985  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.347593 (* 1 = 0.347593 loss)
I0928 21:18:58.145992  5237 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I0928 21:19:12.763160  5237 solver.cpp:218] Iteration 31200 (6.84129 iter/s, 14.6171s/100 iters), loss = 0.283713
I0928 21:19:12.763303  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283713 (* 1 = 0.283713 loss)
I0928 21:19:12.763311  5237 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I0928 21:19:27.382679  5237 solver.cpp:218] Iteration 31300 (6.84025 iter/s, 14.6193s/100 iters), loss = 0.313896
I0928 21:19:27.382709  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313896 (* 1 = 0.313896 loss)
I0928 21:19:27.382715  5237 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I0928 21:19:42.005808  5237 solver.cpp:218] Iteration 31400 (6.83851 iter/s, 14.6231s/100 iters), loss = 0.254418
I0928 21:19:42.005837  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254418 (* 1 = 0.254418 loss)
I0928 21:19:42.005842  5237 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I0928 21:19:55.899000  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:19:56.484472  5237 solver.cpp:330] Iteration 31500, Testing net (#0)
I0928 21:19:59.908569  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:20:00.051779  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.769
I0928 21:20:00.051803  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.746893 (* 1 = 0.746893 loss)
I0928 21:20:00.197459  5237 solver.cpp:218] Iteration 31500 (5.49705 iter/s, 18.1916s/100 iters), loss = 0.257625
I0928 21:20:00.197492  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257625 (* 1 = 0.257625 loss)
I0928 21:20:00.197499  5237 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I0928 21:20:14.790536  5237 solver.cpp:218] Iteration 31600 (6.85262 iter/s, 14.593s/100 iters), loss = 0.29126
I0928 21:20:14.790578  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29126 (* 1 = 0.29126 loss)
I0928 21:20:14.790585  5237 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I0928 21:20:29.388687  5237 solver.cpp:218] Iteration 31700 (6.85022 iter/s, 14.5981s/100 iters), loss = 0.292079
I0928 21:20:29.388823  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292079 (* 1 = 0.292079 loss)
I0928 21:20:29.388831  5237 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I0928 21:20:43.987995  5237 solver.cpp:218] Iteration 31800 (6.84972 iter/s, 14.5991s/100 iters), loss = 0.377571
I0928 21:20:43.988025  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.377571 (* 1 = 0.377571 loss)
I0928 21:20:43.988030  5237 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I0928 21:20:58.590930  5237 solver.cpp:218] Iteration 31900 (6.84797 iter/s, 14.6029s/100 iters), loss = 0.283747
I0928 21:20:58.590962  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283747 (* 1 = 0.283747 loss)
I0928 21:20:58.590968  5237 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I0928 21:21:12.464316  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:21:13.049170  5237 solver.cpp:330] Iteration 32000, Testing net (#0)
I0928 21:21:16.473232  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:21:16.616464  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7535
I0928 21:21:16.616499  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.791999 (* 1 = 0.791999 loss)
I0928 21:21:16.761868  5237 solver.cpp:218] Iteration 32000 (5.50332 iter/s, 18.1709s/100 iters), loss = 0.234053
I0928 21:21:16.761896  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234053 (* 1 = 0.234053 loss)
I0928 21:21:16.761904  5237 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I0928 21:21:31.376924  5237 solver.cpp:218] Iteration 32100 (6.84229 iter/s, 14.615s/100 iters), loss = 0.343037
I0928 21:21:31.376953  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343037 (* 1 = 0.343037 loss)
I0928 21:21:31.376969  5237 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I0928 21:21:45.994019  5237 solver.cpp:218] Iteration 32200 (6.84134 iter/s, 14.617s/100 iters), loss = 0.343646
I0928 21:21:45.994186  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343646 (* 1 = 0.343646 loss)
I0928 21:21:45.994204  5237 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I0928 21:22:00.607275  5237 solver.cpp:218] Iteration 32300 (6.84319 iter/s, 14.6131s/100 iters), loss = 0.295255
I0928 21:22:00.607313  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295255 (* 1 = 0.295255 loss)
I0928 21:22:00.607319  5237 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I0928 21:22:15.226207  5237 solver.cpp:218] Iteration 32400 (6.84048 iter/s, 14.6189s/100 iters), loss = 0.260519
I0928 21:22:15.226249  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260519 (* 1 = 0.260519 loss)
I0928 21:22:15.226256  5237 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I0928 21:22:29.123176  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:22:29.708137  5237 solver.cpp:330] Iteration 32500, Testing net (#0)
I0928 21:22:33.131572  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:22:33.274695  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8115
I0928 21:22:33.274730  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.545471 (* 1 = 0.545471 loss)
I0928 21:22:33.419850  5237 solver.cpp:218] Iteration 32500 (5.49645 iter/s, 18.1936s/100 iters), loss = 0.293974
I0928 21:22:33.419881  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293974 (* 1 = 0.293974 loss)
I0928 21:22:33.419888  5237 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I0928 21:22:48.014781  5237 solver.cpp:218] Iteration 32600 (6.85173 iter/s, 14.5949s/100 iters), loss = 0.306556
I0928 21:22:48.014811  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306557 (* 1 = 0.306557 loss)
I0928 21:22:48.014816  5237 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I0928 21:23:02.618528  5237 solver.cpp:218] Iteration 32700 (6.84759 iter/s, 14.6037s/100 iters), loss = 0.300172
I0928 21:23:02.618672  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300172 (* 1 = 0.300172 loss)
I0928 21:23:02.618680  5237 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I0928 21:23:17.214889  5237 solver.cpp:218] Iteration 32800 (6.8511 iter/s, 14.5962s/100 iters), loss = 0.388914
I0928 21:23:17.214918  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.388914 (* 1 = 0.388914 loss)
I0928 21:23:17.214925  5237 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I0928 21:23:31.811687  5237 solver.cpp:218] Iteration 32900 (6.85085 iter/s, 14.5967s/100 iters), loss = 0.293072
I0928 21:23:31.811719  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293072 (* 1 = 0.293072 loss)
I0928 21:23:31.811725  5237 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I0928 21:23:45.689265  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:23:46.273102  5237 solver.cpp:330] Iteration 33000, Testing net (#0)
I0928 21:23:49.696364  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:23:49.839283  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7722
I0928 21:23:49.839319  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.686064 (* 1 = 0.686064 loss)
I0928 21:23:49.984329  5237 solver.cpp:218] Iteration 33000 (5.5028 iter/s, 18.1726s/100 iters), loss = 0.226716
I0928 21:23:49.984359  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226716 (* 1 = 0.226716 loss)
I0928 21:23:49.984365  5237 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I0928 21:24:04.578544  5237 solver.cpp:218] Iteration 33100 (6.85206 iter/s, 14.5941s/100 iters), loss = 0.24356
I0928 21:24:04.578573  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243561 (* 1 = 0.243561 loss)
I0928 21:24:04.578579  5237 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I0928 21:24:19.183254  5237 solver.cpp:218] Iteration 33200 (6.84714 iter/s, 14.6046s/100 iters), loss = 0.313915
I0928 21:24:19.183399  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313915 (* 1 = 0.313915 loss)
I0928 21:24:19.183408  5237 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I0928 21:24:33.782948  5237 solver.cpp:218] Iteration 33300 (6.84954 iter/s, 14.5995s/100 iters), loss = 0.338882
I0928 21:24:33.782977  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338882 (* 1 = 0.338882 loss)
I0928 21:24:33.782984  5237 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I0928 21:24:48.384232  5237 solver.cpp:218] Iteration 33400 (6.84875 iter/s, 14.6012s/100 iters), loss = 0.324721
I0928 21:24:48.384261  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324722 (* 1 = 0.324722 loss)
I0928 21:24:48.384268  5237 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I0928 21:25:02.254163  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:25:02.838778  5237 solver.cpp:330] Iteration 33500, Testing net (#0)
I0928 21:25:06.261449  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:25:06.404933  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7897
I0928 21:25:06.404958  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.639952 (* 1 = 0.639952 loss)
I0928 21:25:06.550599  5237 solver.cpp:218] Iteration 33500 (5.5047 iter/s, 18.1663s/100 iters), loss = 0.201745
I0928 21:25:06.550631  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201745 (* 1 = 0.201745 loss)
I0928 21:25:06.550637  5237 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I0928 21:25:21.164902  5237 solver.cpp:218] Iteration 33600 (6.84265 iter/s, 14.6142s/100 iters), loss = 0.291619
I0928 21:25:21.164943  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291619 (* 1 = 0.291619 loss)
I0928 21:25:21.164949  5237 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I0928 21:25:35.781049  5237 solver.cpp:218] Iteration 33700 (6.84179 iter/s, 14.6161s/100 iters), loss = 0.295128
I0928 21:25:35.781172  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295128 (* 1 = 0.295128 loss)
I0928 21:25:35.781180  5237 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I0928 21:25:50.393854  5237 solver.cpp:218] Iteration 33800 (6.84339 iter/s, 14.6126s/100 iters), loss = 0.362447
I0928 21:25:50.393883  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362448 (* 1 = 0.362448 loss)
I0928 21:25:50.393889  5237 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I0928 21:26:05.005442  5237 solver.cpp:218] Iteration 33900 (6.84392 iter/s, 14.6115s/100 iters), loss = 0.293235
I0928 21:26:05.005472  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293236 (* 1 = 0.293236 loss)
I0928 21:26:05.005478  5237 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I0928 21:26:18.895387  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:26:19.481398  5237 solver.cpp:330] Iteration 34000, Testing net (#0)
I0928 21:26:22.903163  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:26:23.046110  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8184
I0928 21:26:23.046134  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.55097 (* 1 = 0.55097 loss)
I0928 21:26:23.192322  5237 solver.cpp:218] Iteration 34000 (5.49849 iter/s, 18.1868s/100 iters), loss = 0.338135
I0928 21:26:23.192351  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338136 (* 1 = 0.338136 loss)
I0928 21:26:23.192358  5237 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I0928 21:26:37.794980  5237 solver.cpp:218] Iteration 34100 (6.8481 iter/s, 14.6026s/100 iters), loss = 0.319285
I0928 21:26:37.795007  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319285 (* 1 = 0.319285 loss)
I0928 21:26:37.795013  5237 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I0928 21:26:52.398017  5237 solver.cpp:218] Iteration 34200 (6.84792 iter/s, 14.603s/100 iters), loss = 0.445971
I0928 21:26:52.398118  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.445971 (* 1 = 0.445971 loss)
I0928 21:26:52.398125  5237 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I0928 21:27:07.004086  5237 solver.cpp:218] Iteration 34300 (6.84653 iter/s, 14.6059s/100 iters), loss = 0.388651
I0928 21:27:07.004115  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.388651 (* 1 = 0.388651 loss)
I0928 21:27:07.004122  5237 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I0928 21:27:21.608475  5237 solver.cpp:218] Iteration 34400 (6.84729 iter/s, 14.6043s/100 iters), loss = 0.291734
I0928 21:27:21.608515  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291734 (* 1 = 0.291734 loss)
I0928 21:27:21.608520  5237 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I0928 21:27:35.488689  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:27:36.072085  5237 solver.cpp:330] Iteration 34500, Testing net (#0)
I0928 21:27:39.497040  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:27:39.640007  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7867
I0928 21:27:39.640043  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.636832 (* 1 = 0.636832 loss)
I0928 21:27:39.785637  5237 solver.cpp:218] Iteration 34500 (5.50144 iter/s, 18.1771s/100 iters), loss = 0.305465
I0928 21:27:39.785670  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305465 (* 1 = 0.305465 loss)
I0928 21:27:39.785676  5237 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I0928 21:27:54.394749  5237 solver.cpp:218] Iteration 34600 (6.84508 iter/s, 14.609s/100 iters), loss = 0.262162
I0928 21:27:54.394778  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262163 (* 1 = 0.262163 loss)
I0928 21:27:54.394784  5237 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I0928 21:28:09.013062  5237 solver.cpp:218] Iteration 34700 (6.84077 iter/s, 14.6182s/100 iters), loss = 0.360341
I0928 21:28:09.013173  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.360342 (* 1 = 0.360342 loss)
I0928 21:28:09.013180  5237 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I0928 21:28:23.626617  5237 solver.cpp:218] Iteration 34800 (6.84303 iter/s, 14.6134s/100 iters), loss = 0.313387
I0928 21:28:23.626646  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313387 (* 1 = 0.313387 loss)
I0928 21:28:23.626652  5237 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I0928 21:28:38.239136  5237 solver.cpp:218] Iteration 34900 (6.84348 iter/s, 14.6125s/100 iters), loss = 0.311969
I0928 21:28:38.239164  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31197 (* 1 = 0.31197 loss)
I0928 21:28:38.239169  5237 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I0928 21:28:52.129478  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:28:52.713892  5237 solver.cpp:330] Iteration 35000, Testing net (#0)
I0928 21:28:56.139053  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:28:56.282517  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7911
I0928 21:28:56.282544  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.623687 (* 1 = 0.623687 loss)
I0928 21:28:56.428091  5237 solver.cpp:218] Iteration 35000 (5.49787 iter/s, 18.1889s/100 iters), loss = 0.229891
I0928 21:28:56.428120  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229892 (* 1 = 0.229892 loss)
I0928 21:28:56.428128  5237 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I0928 21:29:11.030571  5237 solver.cpp:218] Iteration 35100 (6.84818 iter/s, 14.6024s/100 iters), loss = 0.321529
I0928 21:29:11.030601  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32153 (* 1 = 0.32153 loss)
I0928 21:29:11.030606  5237 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I0928 21:29:25.645076  5237 solver.cpp:218] Iteration 35200 (6.84255 iter/s, 14.6144s/100 iters), loss = 0.279778
I0928 21:29:25.645216  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279779 (* 1 = 0.279779 loss)
I0928 21:29:25.645223  5237 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I0928 21:29:40.248993  5237 solver.cpp:218] Iteration 35300 (6.84756 iter/s, 14.6038s/100 iters), loss = 0.416083
I0928 21:29:40.249024  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.416084 (* 1 = 0.416084 loss)
I0928 21:29:40.249032  5237 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I0928 21:29:54.858578  5237 solver.cpp:218] Iteration 35400 (6.84485 iter/s, 14.6095s/100 iters), loss = 0.201937
I0928 21:29:54.858618  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201938 (* 1 = 0.201938 loss)
I0928 21:29:54.858624  5237 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I0928 21:30:08.747761  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:30:09.332211  5237 solver.cpp:330] Iteration 35500, Testing net (#0)
I0928 21:30:12.755496  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:30:12.898761  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7905
I0928 21:30:12.898797  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.634402 (* 1 = 0.634402 loss)
I0928 21:30:13.044222  5237 solver.cpp:218] Iteration 35500 (5.49887 iter/s, 18.1856s/100 iters), loss = 0.28897
I0928 21:30:13.044252  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28897 (* 1 = 0.28897 loss)
I0928 21:30:13.044260  5237 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I0928 21:30:27.639789  5237 solver.cpp:218] Iteration 35600 (6.85143 iter/s, 14.5955s/100 iters), loss = 0.359302
I0928 21:30:27.639829  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.359302 (* 1 = 0.359302 loss)
I0928 21:30:27.639835  5237 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I0928 21:30:42.244340  5237 solver.cpp:218] Iteration 35700 (6.84722 iter/s, 14.6045s/100 iters), loss = 0.294071
I0928 21:30:42.244422  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294071 (* 1 = 0.294071 loss)
I0928 21:30:42.244431  5237 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I0928 21:30:56.851649  5237 solver.cpp:218] Iteration 35800 (6.84594 iter/s, 14.6072s/100 iters), loss = 0.33272
I0928 21:30:56.851691  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.33272 (* 1 = 0.33272 loss)
I0928 21:30:56.851696  5237 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I0928 21:31:11.459331  5237 solver.cpp:218] Iteration 35900 (6.84575 iter/s, 14.6076s/100 iters), loss = 0.262237
I0928 21:31:11.459370  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262237 (* 1 = 0.262237 loss)
I0928 21:31:11.459377  5237 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I0928 21:31:25.349443  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:31:25.934875  5237 solver.cpp:330] Iteration 36000, Testing net (#0)
I0928 21:31:29.359112  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:31:29.502753  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7338
I0928 21:31:29.502779  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.80863 (* 1 = 0.80863 loss)
I0928 21:31:29.648236  5237 solver.cpp:218] Iteration 36000 (5.49788 iter/s, 18.1888s/100 iters), loss = 0.2313
I0928 21:31:29.648267  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2313 (* 1 = 0.2313 loss)
I0928 21:31:29.648273  5237 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I0928 21:31:44.254756  5237 solver.cpp:218] Iteration 36100 (6.84629 iter/s, 14.6064s/100 iters), loss = 0.212245
I0928 21:31:44.254786  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212245 (* 1 = 0.212245 loss)
I0928 21:31:44.254802  5237 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I0928 21:31:58.870985  5237 solver.cpp:218] Iteration 36200 (6.84174 iter/s, 14.6162s/100 iters), loss = 0.308322
I0928 21:31:58.871100  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308323 (* 1 = 0.308323 loss)
I0928 21:31:58.871107  5237 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I0928 21:32:13.483924  5237 solver.cpp:218] Iteration 36300 (6.84332 iter/s, 14.6128s/100 iters), loss = 0.288303
I0928 21:32:13.483955  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288304 (* 1 = 0.288304 loss)
I0928 21:32:13.483971  5237 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I0928 21:32:28.099711  5237 solver.cpp:218] Iteration 36400 (6.84195 iter/s, 14.6157s/100 iters), loss = 0.261118
I0928 21:32:28.099742  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261119 (* 1 = 0.261119 loss)
I0928 21:32:28.099759  5237 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I0928 21:32:41.987857  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:32:42.573603  5237 solver.cpp:330] Iteration 36500, Testing net (#0)
I0928 21:32:45.995837  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:32:46.138887  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7269
I0928 21:32:46.138911  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.920174 (* 1 = 0.920174 loss)
I0928 21:32:46.284297  5237 solver.cpp:218] Iteration 36500 (5.49919 iter/s, 18.1845s/100 iters), loss = 0.22468
I0928 21:32:46.284328  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22468 (* 1 = 0.22468 loss)
I0928 21:32:46.284335  5237 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I0928 21:33:00.877658  5237 solver.cpp:218] Iteration 36600 (6.85246 iter/s, 14.5933s/100 iters), loss = 0.324018
I0928 21:33:00.877688  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324018 (* 1 = 0.324018 loss)
I0928 21:33:00.877694  5237 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I0928 21:33:15.472743  5237 solver.cpp:218] Iteration 36700 (6.85166 iter/s, 14.595s/100 iters), loss = 0.301918
I0928 21:33:15.472882  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301918 (* 1 = 0.301918 loss)
I0928 21:33:15.472890  5237 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I0928 21:33:30.067104  5237 solver.cpp:218] Iteration 36800 (6.85204 iter/s, 14.5942s/100 iters), loss = 0.345351
I0928 21:33:30.067142  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.345351 (* 1 = 0.345351 loss)
I0928 21:33:30.067148  5237 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I0928 21:33:44.671350  5237 solver.cpp:218] Iteration 36900 (6.84736 iter/s, 14.6042s/100 iters), loss = 0.299348
I0928 21:33:44.671380  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299349 (* 1 = 0.299349 loss)
I0928 21:33:44.671386  5237 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I0928 21:33:58.538820  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:33:59.122596  5237 solver.cpp:330] Iteration 37000, Testing net (#0)
I0928 21:34:02.547375  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:34:02.690034  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7711
I0928 21:34:02.690069  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.676589 (* 1 = 0.676589 loss)
I0928 21:34:02.835597  5237 solver.cpp:218] Iteration 37000 (5.50534 iter/s, 18.1642s/100 iters), loss = 0.234538
I0928 21:34:02.835626  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234539 (* 1 = 0.234539 loss)
I0928 21:34:02.835633  5237 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I0928 21:34:17.444038  5237 solver.cpp:218] Iteration 37100 (6.84539 iter/s, 14.6084s/100 iters), loss = 0.335457
I0928 21:34:17.444067  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335458 (* 1 = 0.335458 loss)
I0928 21:34:17.444073  5237 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I0928 21:34:32.057310  5237 solver.cpp:218] Iteration 37200 (6.84313 iter/s, 14.6132s/100 iters), loss = 0.33976
I0928 21:34:32.057442  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.339761 (* 1 = 0.339761 loss)
I0928 21:34:32.057449  5237 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I0928 21:34:46.668793  5237 solver.cpp:218] Iteration 37300 (6.84401 iter/s, 14.6113s/100 iters), loss = 0.273451
I0928 21:34:46.668824  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273451 (* 1 = 0.273451 loss)
I0928 21:34:46.668830  5237 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I0928 21:35:01.280660  5237 solver.cpp:218] Iteration 37400 (6.84379 iter/s, 14.6118s/100 iters), loss = 0.265184
I0928 21:35:01.280696  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265185 (* 1 = 0.265185 loss)
I0928 21:35:01.280704  5237 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I0928 21:35:15.169826  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:35:15.753161  5237 solver.cpp:330] Iteration 37500, Testing net (#0)
I0928 21:35:19.175643  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:35:19.318542  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7644
I0928 21:35:19.318565  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.70115 (* 1 = 0.70115 loss)
I0928 21:35:19.464661  5237 solver.cpp:218] Iteration 37500 (5.49936 iter/s, 18.1839s/100 iters), loss = 0.22704
I0928 21:35:19.464692  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22704 (* 1 = 0.22704 loss)
I0928 21:35:19.464699  5237 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I0928 21:35:34.071794  5237 solver.cpp:218] Iteration 37600 (6.846 iter/s, 14.6071s/100 iters), loss = 0.294954
I0928 21:35:34.071825  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294955 (* 1 = 0.294955 loss)
I0928 21:35:34.071830  5237 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I0928 21:35:48.680860  5237 solver.cpp:218] Iteration 37700 (6.8451 iter/s, 14.609s/100 iters), loss = 0.226577
I0928 21:35:48.680989  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226578 (* 1 = 0.226578 loss)
I0928 21:35:48.681005  5237 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I0928 21:36:03.295377  5237 solver.cpp:218] Iteration 37800 (6.84259 iter/s, 14.6144s/100 iters), loss = 0.210548
I0928 21:36:03.295405  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210548 (* 1 = 0.210548 loss)
I0928 21:36:03.295411  5237 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I0928 21:36:17.909773  5237 solver.cpp:218] Iteration 37900 (6.8426 iter/s, 14.6143s/100 iters), loss = 0.186973
I0928 21:36:17.909803  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186973 (* 1 = 0.186973 loss)
I0928 21:36:17.909809  5237 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I0928 21:36:31.797709  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:36:32.382531  5237 solver.cpp:330] Iteration 38000, Testing net (#0)
I0928 21:36:35.805949  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:36:35.949323  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7752
I0928 21:36:35.949359  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.664079 (* 1 = 0.664079 loss)
I0928 21:36:36.094136  5237 solver.cpp:218] Iteration 38000 (5.49925 iter/s, 18.1843s/100 iters), loss = 0.240259
I0928 21:36:36.094168  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24026 (* 1 = 0.24026 loss)
I0928 21:36:36.094174  5237 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I0928 21:36:50.704587  5237 solver.cpp:218] Iteration 38100 (6.84445 iter/s, 14.6104s/100 iters), loss = 0.229819
I0928 21:36:50.704627  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229819 (* 1 = 0.229819 loss)
I0928 21:36:50.704632  5237 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I0928 21:37:05.318645  5237 solver.cpp:218] Iteration 38200 (6.84276 iter/s, 14.614s/100 iters), loss = 0.276052
I0928 21:37:05.318750  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276053 (* 1 = 0.276053 loss)
I0928 21:37:05.318768  5237 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I0928 21:37:19.930965  5237 solver.cpp:218] Iteration 38300 (6.84361 iter/s, 14.6122s/100 iters), loss = 0.398414
I0928 21:37:19.930995  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.398415 (* 1 = 0.398415 loss)
I0928 21:37:19.931001  5237 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I0928 21:37:34.540720  5237 solver.cpp:218] Iteration 38400 (6.84477 iter/s, 14.6097s/100 iters), loss = 0.257026
I0928 21:37:34.540750  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257027 (* 1 = 0.257027 loss)
I0928 21:37:34.540756  5237 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I0928 21:37:48.428745  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:37:49.013955  5237 solver.cpp:330] Iteration 38500, Testing net (#0)
I0928 21:37:52.435372  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:37:52.578455  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7727
I0928 21:37:52.578492  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.732555 (* 1 = 0.732555 loss)
I0928 21:37:52.724251  5237 solver.cpp:218] Iteration 38500 (5.49951 iter/s, 18.1835s/100 iters), loss = 0.282775
I0928 21:37:52.724283  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282776 (* 1 = 0.282776 loss)
I0928 21:37:52.724290  5237 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I0928 21:38:07.329231  5237 solver.cpp:218] Iteration 38600 (6.84701 iter/s, 14.6049s/100 iters), loss = 0.28222
I0928 21:38:07.329262  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282221 (* 1 = 0.282221 loss)
I0928 21:38:07.329267  5237 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I0928 21:38:21.936426  5237 solver.cpp:218] Iteration 38700 (6.84597 iter/s, 14.6071s/100 iters), loss = 0.43494
I0928 21:38:21.936580  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.43494 (* 1 = 0.43494 loss)
I0928 21:38:21.936589  5237 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I0928 21:38:36.544098  5237 solver.cpp:218] Iteration 38800 (6.84581 iter/s, 14.6075s/100 iters), loss = 0.239518
I0928 21:38:36.544127  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239518 (* 1 = 0.239518 loss)
I0928 21:38:36.544132  5237 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I0928 21:38:51.151283  5237 solver.cpp:218] Iteration 38900 (6.84598 iter/s, 14.6071s/100 iters), loss = 0.263059
I0928 21:38:51.151314  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26306 (* 1 = 0.26306 loss)
I0928 21:38:51.151320  5237 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I0928 21:39:05.038810  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:39:05.624524  5237 solver.cpp:330] Iteration 39000, Testing net (#0)
I0928 21:39:09.044394  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:39:09.187146  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7525
I0928 21:39:09.187182  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.777764 (* 1 = 0.777764 loss)
I0928 21:39:09.332387  5237 solver.cpp:218] Iteration 39000 (5.50024 iter/s, 18.181s/100 iters), loss = 0.269582
I0928 21:39:09.332417  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269583 (* 1 = 0.269583 loss)
I0928 21:39:09.332423  5237 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I0928 21:39:23.926547  5237 solver.cpp:218] Iteration 39100 (6.85209 iter/s, 14.5941s/100 iters), loss = 0.328882
I0928 21:39:23.926587  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328882 (* 1 = 0.328882 loss)
I0928 21:39:23.926594  5237 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I0928 21:39:38.528951  5237 solver.cpp:218] Iteration 39200 (6.84822 iter/s, 14.6023s/100 iters), loss = 0.208264
I0928 21:39:38.529094  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208265 (* 1 = 0.208265 loss)
I0928 21:39:38.529103  5237 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I0928 21:39:53.128795  5237 solver.cpp:218] Iteration 39300 (6.84948 iter/s, 14.5997s/100 iters), loss = 0.24971
I0928 21:39:53.128840  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249711 (* 1 = 0.249711 loss)
I0928 21:39:53.128847  5237 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I0928 21:40:07.733580  5237 solver.cpp:218] Iteration 39400 (6.84711 iter/s, 14.6047s/100 iters), loss = 0.296602
I0928 21:40:07.733621  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296603 (* 1 = 0.296603 loss)
I0928 21:40:07.733628  5237 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I0928 21:40:21.609436  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:40:22.194504  5237 solver.cpp:330] Iteration 39500, Testing net (#0)
I0928 21:40:25.618224  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:40:25.761445  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7887
I0928 21:40:25.761490  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.65578 (* 1 = 0.65578 loss)
I0928 21:40:25.906954  5237 solver.cpp:218] Iteration 39500 (5.50258 iter/s, 18.1733s/100 iters), loss = 0.244624
I0928 21:40:25.906983  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244625 (* 1 = 0.244625 loss)
I0928 21:40:25.906991  5237 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I0928 21:40:40.516316  5237 solver.cpp:218] Iteration 39600 (6.84496 iter/s, 14.6093s/100 iters), loss = 0.235453
I0928 21:40:40.516350  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235454 (* 1 = 0.235454 loss)
I0928 21:40:40.516360  5237 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I0928 21:40:55.144062  5237 solver.cpp:218] Iteration 39700 (6.83636 iter/s, 14.6277s/100 iters), loss = 0.331742
I0928 21:40:55.144177  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331742 (* 1 = 0.331742 loss)
I0928 21:40:55.144186  5237 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I0928 21:41:09.760502  5237 solver.cpp:218] Iteration 39800 (6.84168 iter/s, 14.6163s/100 iters), loss = 0.347307
I0928 21:41:09.760541  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.347308 (* 1 = 0.347308 loss)
I0928 21:41:09.760547  5237 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I0928 21:41:24.384055  5237 solver.cpp:218] Iteration 39900 (6.83832 iter/s, 14.6235s/100 iters), loss = 0.236518
I0928 21:41:24.384093  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236519 (* 1 = 0.236519 loss)
I0928 21:41:24.384100  5237 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I0928 21:41:38.287475  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:41:38.871376  5237 solver.cpp:330] Iteration 40000, Testing net (#0)
I0928 21:41:42.295279  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:41:42.438283  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7524
I0928 21:41:42.438318  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.795408 (* 1 = 0.795408 loss)
I0928 21:41:42.583420  5237 solver.cpp:218] Iteration 40000 (5.49472 iter/s, 18.1993s/100 iters), loss = 0.273103
I0928 21:41:42.583463  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273104 (* 1 = 0.273104 loss)
I0928 21:41:42.583469  5237 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I0928 21:41:42.583473  5237 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I0928 21:41:57.184814  5237 solver.cpp:218] Iteration 40100 (6.8487 iter/s, 14.6013s/100 iters), loss = 0.216117
I0928 21:41:57.184852  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216118 (* 1 = 0.216118 loss)
I0928 21:41:57.184861  5237 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I0928 21:42:11.795332  5237 solver.cpp:218] Iteration 40200 (6.84442 iter/s, 14.6104s/100 iters), loss = 0.210424
I0928 21:42:11.795467  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210425 (* 1 = 0.210425 loss)
I0928 21:42:11.795475  5237 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I0928 21:42:26.411936  5237 solver.cpp:218] Iteration 40300 (6.84161 iter/s, 14.6164s/100 iters), loss = 0.229722
I0928 21:42:26.411967  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229722 (* 1 = 0.229722 loss)
I0928 21:42:26.411972  5237 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I0928 21:42:41.018254  5237 solver.cpp:218] Iteration 40400 (6.84639 iter/s, 14.6062s/100 iters), loss = 0.12847
I0928 21:42:41.018290  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12847 (* 1 = 0.12847 loss)
I0928 21:42:41.018297  5237 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I0928 21:42:54.902240  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:42:55.485584  5237 solver.cpp:330] Iteration 40500, Testing net (#0)
I0928 21:42:58.908776  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:42:59.051743  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8874
I0928 21:42:59.051776  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.332705 (* 1 = 0.332705 loss)
I0928 21:42:59.196601  5237 solver.cpp:218] Iteration 40500 (5.50107 iter/s, 18.1783s/100 iters), loss = 0.164379
I0928 21:42:59.196631  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16438 (* 1 = 0.16438 loss)
I0928 21:42:59.196638  5237 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I0928 21:43:13.800552  5237 solver.cpp:218] Iteration 40600 (6.8475 iter/s, 14.6039s/100 iters), loss = 0.189155
I0928 21:43:13.800582  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189156 (* 1 = 0.189156 loss)
I0928 21:43:13.800588  5237 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I0928 21:43:28.406127  5237 solver.cpp:218] Iteration 40700 (6.84673 iter/s, 14.6055s/100 iters), loss = 0.177417
I0928 21:43:28.406270  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177418 (* 1 = 0.177418 loss)
I0928 21:43:28.406280  5237 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I0928 21:43:43.008612  5237 solver.cpp:218] Iteration 40800 (6.84823 iter/s, 14.6023s/100 iters), loss = 0.169138
I0928 21:43:43.008641  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169139 (* 1 = 0.169139 loss)
I0928 21:43:43.008656  5237 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I0928 21:43:57.619165  5237 solver.cpp:218] Iteration 40900 (6.8444 iter/s, 14.6105s/100 iters), loss = 0.126389
I0928 21:43:57.619196  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12639 (* 1 = 0.12639 loss)
I0928 21:43:57.619213  5237 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I0928 21:44:11.501610  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:44:12.087080  5237 solver.cpp:330] Iteration 41000, Testing net (#0)
I0928 21:44:15.510973  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:44:15.655477  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8959
I0928 21:44:15.655500  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313847 (* 1 = 0.313847 loss)
I0928 21:44:15.800434  5237 solver.cpp:218] Iteration 41000 (5.50019 iter/s, 18.1812s/100 iters), loss = 0.126313
I0928 21:44:15.800464  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126314 (* 1 = 0.126314 loss)
I0928 21:44:15.800470  5237 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I0928 21:44:30.407014  5237 solver.cpp:218] Iteration 41100 (6.84626 iter/s, 14.6065s/100 iters), loss = 0.199363
I0928 21:44:30.407044  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199364 (* 1 = 0.199364 loss)
I0928 21:44:30.407060  5237 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I0928 21:44:45.014487  5237 solver.cpp:218] Iteration 41200 (6.84584 iter/s, 14.6074s/100 iters), loss = 0.217949
I0928 21:44:45.014575  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21795 (* 1 = 0.21795 loss)
I0928 21:44:45.014581  5237 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I0928 21:44:59.621915  5237 solver.cpp:218] Iteration 41300 (6.84589 iter/s, 14.6073s/100 iters), loss = 0.15885
I0928 21:44:59.621948  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158851 (* 1 = 0.158851 loss)
I0928 21:44:59.621963  5237 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I0928 21:45:14.231909  5237 solver.cpp:218] Iteration 41400 (6.84466 iter/s, 14.6099s/100 iters), loss = 0.132371
I0928 21:45:14.231940  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132372 (* 1 = 0.132372 loss)
I0928 21:45:14.231956  5237 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I0928 21:45:28.113515  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:45:28.699585  5237 solver.cpp:330] Iteration 41500, Testing net (#0)
I0928 21:45:32.124748  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:45:32.267570  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8884
I0928 21:45:32.267596  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325522 (* 1 = 0.325522 loss)
I0928 21:45:32.412847  5237 solver.cpp:218] Iteration 41500 (5.50029 iter/s, 18.1809s/100 iters), loss = 0.0773202
I0928 21:45:32.412876  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0773211 (* 1 = 0.0773211 loss)
I0928 21:45:32.412883  5237 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I0928 21:45:47.006593  5237 solver.cpp:218] Iteration 41600 (6.85228 iter/s, 14.5937s/100 iters), loss = 0.156524
I0928 21:45:47.006624  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156525 (* 1 = 0.156525 loss)
I0928 21:45:47.006631  5237 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I0928 21:46:01.609221  5237 solver.cpp:218] Iteration 41700 (6.84812 iter/s, 14.6026s/100 iters), loss = 0.181761
I0928 21:46:01.609340  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181762 (* 1 = 0.181762 loss)
I0928 21:46:01.609349  5237 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I0928 21:46:16.210697  5237 solver.cpp:218] Iteration 41800 (6.8487 iter/s, 14.6013s/100 iters), loss = 0.159785
I0928 21:46:16.210737  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159785 (* 1 = 0.159785 loss)
I0928 21:46:16.210743  5237 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I0928 21:46:30.808106  5237 solver.cpp:218] Iteration 41900 (6.85057 iter/s, 14.5973s/100 iters), loss = 0.0952716
I0928 21:46:30.808138  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0952725 (* 1 = 0.0952725 loss)
I0928 21:46:30.808145  5237 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I0928 21:46:44.683207  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:46:45.267678  5237 solver.cpp:330] Iteration 42000, Testing net (#0)
I0928 21:46:48.694077  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:46:48.836849  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8903
I0928 21:46:48.836884  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320217 (* 1 = 0.320217 loss)
I0928 21:46:48.982075  5237 solver.cpp:218] Iteration 42000 (5.5024 iter/s, 18.1739s/100 iters), loss = 0.0984893
I0928 21:46:48.982107  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0984902 (* 1 = 0.0984902 loss)
I0928 21:46:48.982113  5237 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I0928 21:47:03.592191  5237 solver.cpp:218] Iteration 42100 (6.84461 iter/s, 14.61s/100 iters), loss = 0.219364
I0928 21:47:03.592231  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219365 (* 1 = 0.219365 loss)
I0928 21:47:03.592237  5237 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I0928 21:47:18.207406  5237 solver.cpp:218] Iteration 42200 (6.84222 iter/s, 14.6151s/100 iters), loss = 0.169445
I0928 21:47:18.207528  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169446 (* 1 = 0.169446 loss)
I0928 21:47:18.207535  5237 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I0928 21:47:32.828631  5237 solver.cpp:218] Iteration 42300 (6.83945 iter/s, 14.6211s/100 iters), loss = 0.165519
I0928 21:47:32.828672  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16552 (* 1 = 0.16552 loss)
I0928 21:47:32.828678  5237 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I0928 21:47:47.436305  5237 solver.cpp:218] Iteration 42400 (6.84576 iter/s, 14.6076s/100 iters), loss = 0.137884
I0928 21:47:47.436334  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.137885 (* 1 = 0.137885 loss)
I0928 21:47:47.436341  5237 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I0928 21:48:01.325845  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:48:01.911200  5237 solver.cpp:330] Iteration 42500, Testing net (#0)
I0928 21:48:05.335549  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:48:05.479137  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8957
I0928 21:48:05.479172  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.315982 (* 1 = 0.315982 loss)
I0928 21:48:05.625185  5237 solver.cpp:218] Iteration 42500 (5.49789 iter/s, 18.1888s/100 iters), loss = 0.160787
I0928 21:48:05.625217  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160788 (* 1 = 0.160788 loss)
I0928 21:48:05.625224  5237 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I0928 21:48:20.234521  5237 solver.cpp:218] Iteration 42600 (6.84497 iter/s, 14.6093s/100 iters), loss = 0.173947
I0928 21:48:20.234561  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173948 (* 1 = 0.173948 loss)
I0928 21:48:20.234566  5237 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I0928 21:48:34.848781  5237 solver.cpp:218] Iteration 42700 (6.84267 iter/s, 14.6142s/100 iters), loss = 0.158557
I0928 21:48:34.848937  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158558 (* 1 = 0.158558 loss)
I0928 21:48:34.848954  5237 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I0928 21:48:49.463071  5237 solver.cpp:218] Iteration 42800 (6.8427 iter/s, 14.6141s/100 iters), loss = 0.201819
I0928 21:48:49.463110  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20182 (* 1 = 0.20182 loss)
I0928 21:48:49.463116  5237 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I0928 21:49:04.080588  5237 solver.cpp:218] Iteration 42900 (6.84115 iter/s, 14.6174s/100 iters), loss = 0.105406
I0928 21:49:04.080628  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.105407 (* 1 = 0.105407 loss)
I0928 21:49:04.080636  5237 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I0928 21:49:17.967767  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:49:18.552634  5237 solver.cpp:330] Iteration 43000, Testing net (#0)
I0928 21:49:21.976361  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:49:22.119810  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8921
I0928 21:49:22.119835  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.323067 (* 1 = 0.323067 loss)
I0928 21:49:22.265164  5237 solver.cpp:218] Iteration 43000 (5.49919 iter/s, 18.1845s/100 iters), loss = 0.0796679
I0928 21:49:22.265195  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0796688 (* 1 = 0.0796688 loss)
I0928 21:49:22.265202  5237 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I0928 21:49:36.864073  5237 solver.cpp:218] Iteration 43100 (6.84986 iter/s, 14.5988s/100 iters), loss = 0.175999
I0928 21:49:36.864114  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176 (* 1 = 0.176 loss)
I0928 21:49:36.864120  5237 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I0928 21:49:51.479817  5237 solver.cpp:218] Iteration 43200 (6.84197 iter/s, 14.6157s/100 iters), loss = 0.21913
I0928 21:49:51.479956  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219131 (* 1 = 0.219131 loss)
I0928 21:49:51.479964  5237 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I0928 21:50:06.085784  5237 solver.cpp:218] Iteration 43300 (6.84659 iter/s, 14.6058s/100 iters), loss = 0.216228
I0928 21:50:06.085824  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216228 (* 1 = 0.216228 loss)
I0928 21:50:06.085829  5237 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I0928 21:50:20.693569  5237 solver.cpp:218] Iteration 43400 (6.8457 iter/s, 14.6077s/100 iters), loss = 0.126613
I0928 21:50:20.693609  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126614 (* 1 = 0.126614 loss)
I0928 21:50:20.693616  5237 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I0928 21:50:34.579699  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:50:35.163985  5237 solver.cpp:330] Iteration 43500, Testing net (#0)
I0928 21:50:38.587087  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:50:38.730185  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8923
I0928 21:50:38.730209  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.317763 (* 1 = 0.317763 loss)
I0928 21:50:38.875710  5237 solver.cpp:218] Iteration 43500 (5.49993 iter/s, 18.1821s/100 iters), loss = 0.0699018
I0928 21:50:38.875741  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0699027 (* 1 = 0.0699027 loss)
I0928 21:50:38.875746  5237 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I0928 21:50:53.472376  5237 solver.cpp:218] Iteration 43600 (6.85091 iter/s, 14.5966s/100 iters), loss = 0.240572
I0928 21:50:53.472405  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240573 (* 1 = 0.240573 loss)
I0928 21:50:53.472411  5237 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I0928 21:51:08.084746  5237 solver.cpp:218] Iteration 43700 (6.84355 iter/s, 14.6123s/100 iters), loss = 0.127211
I0928 21:51:08.084905  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127212 (* 1 = 0.127212 loss)
I0928 21:51:08.084913  5237 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I0928 21:51:22.691509  5237 solver.cpp:218] Iteration 43800 (6.84623 iter/s, 14.6066s/100 iters), loss = 0.148571
I0928 21:51:22.691551  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148572 (* 1 = 0.148572 loss)
I0928 21:51:22.691557  5237 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I0928 21:51:37.303661  5237 solver.cpp:218] Iteration 43900 (6.84366 iter/s, 14.6121s/100 iters), loss = 0.0600482
I0928 21:51:37.303702  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.060049 (* 1 = 0.060049 loss)
I0928 21:51:37.303709  5237 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I0928 21:51:51.180097  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:51:51.766930  5237 solver.cpp:330] Iteration 44000, Testing net (#0)
I0928 21:51:55.189025  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:51:55.332165  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.892
I0928 21:51:55.332198  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322196 (* 1 = 0.322196 loss)
I0928 21:51:55.477388  5237 solver.cpp:218] Iteration 44000 (5.50248 iter/s, 18.1736s/100 iters), loss = 0.050128
I0928 21:51:55.477418  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0501288 (* 1 = 0.0501288 loss)
I0928 21:51:55.477424  5237 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I0928 21:52:10.076100  5237 solver.cpp:218] Iteration 44100 (6.84995 iter/s, 14.5986s/100 iters), loss = 0.12166
I0928 21:52:10.076143  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.121661 (* 1 = 0.121661 loss)
I0928 21:52:10.076149  5237 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I0928 21:52:24.686903  5237 solver.cpp:218] Iteration 44200 (6.84429 iter/s, 14.6107s/100 iters), loss = 0.162337
I0928 21:52:24.687023  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162337 (* 1 = 0.162337 loss)
I0928 21:52:24.687041  5237 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I0928 21:52:39.293464  5237 solver.cpp:218] Iteration 44300 (6.84631 iter/s, 14.6064s/100 iters), loss = 0.116131
I0928 21:52:39.293504  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116132 (* 1 = 0.116132 loss)
I0928 21:52:39.293510  5237 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I0928 21:52:53.899179  5237 solver.cpp:218] Iteration 44400 (6.84667 iter/s, 14.6056s/100 iters), loss = 0.0704186
I0928 21:52:53.899220  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0704193 (* 1 = 0.0704193 loss)
I0928 21:52:53.899226  5237 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I0928 21:53:07.778761  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:53:08.363802  5237 solver.cpp:330] Iteration 44500, Testing net (#0)
I0928 21:53:11.789204  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:53:11.932315  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8898
I0928 21:53:11.932350  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326942 (* 1 = 0.326942 loss)
I0928 21:53:12.078317  5237 solver.cpp:218] Iteration 44500 (5.50084 iter/s, 18.179s/100 iters), loss = 0.135905
I0928 21:53:12.078348  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135906 (* 1 = 0.135906 loss)
I0928 21:53:12.078354  5237 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I0928 21:53:26.690748  5237 solver.cpp:218] Iteration 44600 (6.84352 iter/s, 14.6124s/100 iters), loss = 0.158744
I0928 21:53:26.690789  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158745 (* 1 = 0.158745 loss)
I0928 21:53:26.690796  5237 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I0928 21:53:41.304252  5237 solver.cpp:218] Iteration 44700 (6.84302 iter/s, 14.6134s/100 iters), loss = 0.156794
I0928 21:53:41.304394  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156795 (* 1 = 0.156795 loss)
I0928 21:53:41.304411  5237 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I0928 21:53:55.919540  5237 solver.cpp:218] Iteration 44800 (6.84223 iter/s, 14.6151s/100 iters), loss = 0.0969082
I0928 21:53:55.919579  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.096909 (* 1 = 0.096909 loss)
I0928 21:53:55.919585  5237 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I0928 21:54:10.533151  5237 solver.cpp:218] Iteration 44900 (6.84297 iter/s, 14.6135s/100 iters), loss = 0.103489
I0928 21:54:10.533191  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10349 (* 1 = 0.10349 loss)
I0928 21:54:10.533197  5237 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I0928 21:54:24.419776  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:54:25.004519  5237 solver.cpp:330] Iteration 45000, Testing net (#0)
I0928 21:54:28.429217  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:54:28.572332  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8887
I0928 21:54:28.572356  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33164 (* 1 = 0.33164 loss)
I0928 21:54:28.718014  5237 solver.cpp:218] Iteration 45000 (5.49911 iter/s, 18.1848s/100 iters), loss = 0.100339
I0928 21:54:28.718047  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.100339 (* 1 = 0.100339 loss)
I0928 21:54:28.718055  5237 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I0928 21:54:43.326459  5237 solver.cpp:218] Iteration 45100 (6.84539 iter/s, 14.6084s/100 iters), loss = 0.10699
I0928 21:54:43.326500  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106991 (* 1 = 0.106991 loss)
I0928 21:54:43.326508  5237 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I0928 21:54:57.933120  5237 solver.cpp:218] Iteration 45200 (6.84623 iter/s, 14.6066s/100 iters), loss = 0.170418
I0928 21:54:57.933231  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170419 (* 1 = 0.170419 loss)
I0928 21:54:57.933238  5237 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I0928 21:55:12.536942  5237 solver.cpp:218] Iteration 45300 (6.84759 iter/s, 14.6037s/100 iters), loss = 0.147866
I0928 21:55:12.536983  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147867 (* 1 = 0.147867 loss)
I0928 21:55:12.536988  5237 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I0928 21:55:27.139739  5237 solver.cpp:218] Iteration 45400 (6.84804 iter/s, 14.6027s/100 iters), loss = 0.09222
I0928 21:55:27.139772  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0922208 (* 1 = 0.0922208 loss)
I0928 21:55:27.139778  5237 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I0928 21:55:41.020007  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:55:41.605300  5237 solver.cpp:330] Iteration 45500, Testing net (#0)
I0928 21:55:45.029748  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:55:45.172291  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.893
I0928 21:55:45.172315  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.323766 (* 1 = 0.323766 loss)
I0928 21:55:45.318195  5237 solver.cpp:218] Iteration 45500 (5.50104 iter/s, 18.1784s/100 iters), loss = 0.116601
I0928 21:55:45.318226  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116602 (* 1 = 0.116602 loss)
I0928 21:55:45.318233  5237 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I0928 21:55:59.915097  5237 solver.cpp:218] Iteration 45600 (6.8508 iter/s, 14.5968s/100 iters), loss = 0.163415
I0928 21:55:59.915138  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163416 (* 1 = 0.163416 loss)
I0928 21:55:59.915143  5237 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I0928 21:56:14.511343  5237 solver.cpp:218] Iteration 45700 (6.85111 iter/s, 14.5962s/100 iters), loss = 0.189071
I0928 21:56:14.511466  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189071 (* 1 = 0.189071 loss)
I0928 21:56:14.511474  5237 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I0928 21:56:29.112282  5237 solver.cpp:218] Iteration 45800 (6.84895 iter/s, 14.6008s/100 iters), loss = 0.120567
I0928 21:56:29.112323  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120568 (* 1 = 0.120568 loss)
I0928 21:56:29.112329  5237 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I0928 21:56:43.712133  5237 solver.cpp:218] Iteration 45900 (6.84942 iter/s, 14.5998s/100 iters), loss = 0.0928574
I0928 21:56:43.712172  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0928582 (* 1 = 0.0928582 loss)
I0928 21:56:43.712178  5237 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I0928 21:56:57.589711  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:56:58.174933  5237 solver.cpp:330] Iteration 46000, Testing net (#0)
I0928 21:57:01.599293  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:57:01.742681  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8901
I0928 21:57:01.742717  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338176 (* 1 = 0.338176 loss)
I0928 21:57:01.888697  5237 solver.cpp:218] Iteration 46000 (5.50162 iter/s, 18.1765s/100 iters), loss = 0.090262
I0928 21:57:01.888727  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0902629 (* 1 = 0.0902629 loss)
I0928 21:57:01.888734  5237 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I0928 21:57:16.496383  5237 solver.cpp:218] Iteration 46100 (6.84574 iter/s, 14.6076s/100 iters), loss = 0.1749
I0928 21:57:16.496413  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174901 (* 1 = 0.174901 loss)
I0928 21:57:16.496419  5237 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I0928 21:57:31.107873  5237 solver.cpp:218] Iteration 46200 (6.84396 iter/s, 14.6114s/100 iters), loss = 0.142265
I0928 21:57:31.108009  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142266 (* 1 = 0.142266 loss)
I0928 21:57:31.108029  5237 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I0928 21:57:45.730582  5237 solver.cpp:218] Iteration 46300 (6.83875 iter/s, 14.6225s/100 iters), loss = 0.172636
I0928 21:57:45.730612  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172636 (* 1 = 0.172636 loss)
I0928 21:57:45.730628  5237 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I0928 21:58:00.344785  5237 solver.cpp:218] Iteration 46400 (6.84269 iter/s, 14.6141s/100 iters), loss = 0.0691617
I0928 21:58:00.344815  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0691624 (* 1 = 0.0691624 loss)
I0928 21:58:00.344821  5237 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I0928 21:58:14.233188  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:58:14.818416  5237 solver.cpp:330] Iteration 46500, Testing net (#0)
I0928 21:58:18.243361  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:58:18.386380  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8983
I0928 21:58:18.386415  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31126 (* 1 = 0.31126 loss)
I0928 21:58:18.532080  5237 solver.cpp:218] Iteration 46500 (5.49837 iter/s, 18.1872s/100 iters), loss = 0.0805397
I0928 21:58:18.532114  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0805405 (* 1 = 0.0805405 loss)
I0928 21:58:18.532120  5237 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I0928 21:58:33.133961  5237 solver.cpp:218] Iteration 46600 (6.84847 iter/s, 14.6018s/100 iters), loss = 0.129989
I0928 21:58:33.133991  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12999 (* 1 = 0.12999 loss)
I0928 21:58:33.134006  5237 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I0928 21:58:47.743275  5237 solver.cpp:218] Iteration 46700 (6.84498 iter/s, 14.6092s/100 iters), loss = 0.130478
I0928 21:58:47.743397  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.130479 (* 1 = 0.130479 loss)
I0928 21:58:47.743405  5237 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I0928 21:59:02.353503  5237 solver.cpp:218] Iteration 46800 (6.8446 iter/s, 14.6101s/100 iters), loss = 0.0620952
I0928 21:59:02.353535  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0620959 (* 1 = 0.0620959 loss)
I0928 21:59:02.353550  5237 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I0928 21:59:16.955842  5237 solver.cpp:218] Iteration 46900 (6.84825 iter/s, 14.6023s/100 iters), loss = 0.0578491
I0928 21:59:16.955871  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0578499 (* 1 = 0.0578499 loss)
I0928 21:59:16.955888  5237 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I0928 21:59:30.837983  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:59:31.422039  5237 solver.cpp:330] Iteration 47000, Testing net (#0)
I0928 21:59:34.846127  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 21:59:34.989182  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8912
I0928 21:59:34.989217  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334748 (* 1 = 0.334748 loss)
I0928 21:59:35.134549  5237 solver.cpp:218] Iteration 47000 (5.50096 iter/s, 18.1786s/100 iters), loss = 0.104633
I0928 21:59:35.134580  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.104634 (* 1 = 0.104634 loss)
I0928 21:59:35.134587  5237 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I0928 21:59:49.740324  5237 solver.cpp:218] Iteration 47100 (6.84664 iter/s, 14.6057s/100 iters), loss = 0.171633
I0928 21:59:49.740355  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171634 (* 1 = 0.171634 loss)
I0928 21:59:49.740372  5237 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I0928 22:00:04.359926  5237 solver.cpp:218] Iteration 47200 (6.84016 iter/s, 14.6195s/100 iters), loss = 0.147682
I0928 22:00:04.360013  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147683 (* 1 = 0.147683 loss)
I0928 22:00:04.360019  5237 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I0928 22:00:18.973541  5237 solver.cpp:218] Iteration 47300 (6.84299 iter/s, 14.6135s/100 iters), loss = 0.133636
I0928 22:00:18.973569  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133637 (* 1 = 0.133637 loss)
I0928 22:00:18.973575  5237 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I0928 22:00:33.583014  5237 solver.cpp:218] Iteration 47400 (6.84491 iter/s, 14.6094s/100 iters), loss = 0.0708407
I0928 22:00:33.583048  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0708414 (* 1 = 0.0708414 loss)
I0928 22:00:33.583055  5237 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I0928 22:00:47.475421  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:00:48.060602  5237 solver.cpp:330] Iteration 47500, Testing net (#0)
I0928 22:00:51.483667  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:00:51.626677  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8896
I0928 22:00:51.626713  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.344805 (* 1 = 0.344805 loss)
I0928 22:00:51.771917  5237 solver.cpp:218] Iteration 47500 (5.49788 iter/s, 18.1888s/100 iters), loss = 0.0831093
I0928 22:00:51.771947  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.08311 (* 1 = 0.08311 loss)
I0928 22:00:51.771955  5237 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I0928 22:01:06.375625  5237 solver.cpp:218] Iteration 47600 (6.84761 iter/s, 14.6036s/100 iters), loss = 0.101194
I0928 22:01:06.375655  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.101195 (* 1 = 0.101195 loss)
I0928 22:01:06.375661  5237 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I0928 22:01:20.988437  5237 solver.cpp:218] Iteration 47700 (6.84334 iter/s, 14.6127s/100 iters), loss = 0.129761
I0928 22:01:20.988566  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.129762 (* 1 = 0.129762 loss)
I0928 22:01:20.988574  5237 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I0928 22:01:35.594833  5237 solver.cpp:218] Iteration 47800 (6.84639 iter/s, 14.6062s/100 iters), loss = 0.0541547
I0928 22:01:35.594864  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0541554 (* 1 = 0.0541554 loss)
I0928 22:01:35.594880  5237 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I0928 22:01:50.209098  5237 solver.cpp:218] Iteration 47900 (6.84266 iter/s, 14.6142s/100 iters), loss = 0.106032
I0928 22:01:50.209131  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106033 (* 1 = 0.106033 loss)
I0928 22:01:50.209146  5237 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I0928 22:02:04.091166  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:02:04.674444  5237 solver.cpp:330] Iteration 48000, Testing net (#0)
I0928 22:02:08.098867  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:02:08.241441  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8945
I0928 22:02:08.241475  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.323984 (* 1 = 0.323984 loss)
I0928 22:02:08.386541  5237 solver.cpp:218] Iteration 48000 (5.50135 iter/s, 18.1774s/100 iters), loss = 0.0579363
I0928 22:02:08.386571  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0579369 (* 1 = 0.0579369 loss)
I0928 22:02:08.386579  5237 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I0928 22:02:22.988865  5237 solver.cpp:218] Iteration 48100 (6.84826 iter/s, 14.6023s/100 iters), loss = 0.17328
I0928 22:02:22.988895  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173281 (* 1 = 0.173281 loss)
I0928 22:02:22.988901  5237 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I0928 22:02:37.593874  5237 solver.cpp:218] Iteration 48200 (6.847 iter/s, 14.6049s/100 iters), loss = 0.104357
I0928 22:02:37.593996  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.104358 (* 1 = 0.104358 loss)
I0928 22:02:37.594003  5237 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I0928 22:02:52.196751  5237 solver.cpp:218] Iteration 48300 (6.84804 iter/s, 14.6027s/100 iters), loss = 0.0575873
I0928 22:02:52.196779  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.057588 (* 1 = 0.057588 loss)
I0928 22:02:52.196796  5237 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I0928 22:03:06.809092  5237 solver.cpp:218] Iteration 48400 (6.84356 iter/s, 14.6123s/100 iters), loss = 0.0655839
I0928 22:03:06.809131  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0655846 (* 1 = 0.0655846 loss)
I0928 22:03:06.809137  5237 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I0928 22:03:20.691414  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:03:21.275009  5237 solver.cpp:330] Iteration 48500, Testing net (#0)
I0928 22:03:24.699512  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:03:24.841734  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8995
I0928 22:03:24.841769  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.321486 (* 1 = 0.321486 loss)
I0928 22:03:24.986912  5237 solver.cpp:218] Iteration 48500 (5.50124 iter/s, 18.1777s/100 iters), loss = 0.0826606
I0928 22:03:24.986943  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0826612 (* 1 = 0.0826612 loss)
I0928 22:03:24.986948  5237 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I0928 22:03:39.583402  5237 solver.cpp:218] Iteration 48600 (6.851 iter/s, 14.5964s/100 iters), loss = 0.14667
I0928 22:03:39.583431  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146671 (* 1 = 0.146671 loss)
I0928 22:03:39.583436  5237 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I0928 22:03:54.180727  5237 solver.cpp:218] Iteration 48700 (6.8506 iter/s, 14.5973s/100 iters), loss = 0.100767
I0928 22:03:54.180822  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.100768 (* 1 = 0.100768 loss)
I0928 22:03:54.180840  5237 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I0928 22:04:08.784904  5237 solver.cpp:218] Iteration 48800 (6.84742 iter/s, 14.604s/100 iters), loss = 0.0882819
I0928 22:04:08.784934  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0882826 (* 1 = 0.0882826 loss)
I0928 22:04:08.784940  5237 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I0928 22:04:23.386528  5237 solver.cpp:218] Iteration 48900 (6.84859 iter/s, 14.6016s/100 iters), loss = 0.0540566
I0928 22:04:23.386557  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0540572 (* 1 = 0.0540572 loss)
I0928 22:04:23.386564  5237 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I0928 22:04:37.258769  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:04:37.844856  5237 solver.cpp:330] Iteration 49000, Testing net (#0)
I0928 22:04:41.267570  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:04:41.410359  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8941
I0928 22:04:41.410394  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339152 (* 1 = 0.339152 loss)
I0928 22:04:41.555577  5237 solver.cpp:218] Iteration 49000 (5.50389 iter/s, 18.169s/100 iters), loss = 0.0350688
I0928 22:04:41.555609  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0350695 (* 1 = 0.0350695 loss)
I0928 22:04:41.555616  5237 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I0928 22:04:56.172108  5237 solver.cpp:218] Iteration 49100 (6.8416 iter/s, 14.6165s/100 iters), loss = 0.158002
I0928 22:04:56.172137  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158003 (* 1 = 0.158003 loss)
I0928 22:04:56.172143  5237 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I0928 22:05:10.782819  5237 solver.cpp:218] Iteration 49200 (6.84433 iter/s, 14.6106s/100 iters), loss = 0.110993
I0928 22:05:10.782961  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.110994 (* 1 = 0.110994 loss)
I0928 22:05:10.782968  5237 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I0928 22:05:25.398834  5237 solver.cpp:218] Iteration 49300 (6.84189 iter/s, 14.6158s/100 iters), loss = 0.0939239
I0928 22:05:25.398874  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0939245 (* 1 = 0.0939245 loss)
I0928 22:05:25.398880  5237 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I0928 22:05:40.011621  5237 solver.cpp:218] Iteration 49400 (6.84336 iter/s, 14.6127s/100 iters), loss = 0.100891
I0928 22:05:40.011651  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.100892 (* 1 = 0.100892 loss)
I0928 22:05:40.011656  5237 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I0928 22:05:53.893913  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:05:54.477844  5237 solver.cpp:330] Iteration 49500, Testing net (#0)
I0928 22:05:57.901015  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:05:58.044106  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8928
I0928 22:05:58.044142  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.340516 (* 1 = 0.340516 loss)
I0928 22:05:58.189344  5237 solver.cpp:218] Iteration 49500 (5.50126 iter/s, 18.1776s/100 iters), loss = 0.0661597
I0928 22:05:58.189374  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0661603 (* 1 = 0.0661603 loss)
I0928 22:05:58.189381  5237 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I0928 22:06:12.794167  5237 solver.cpp:218] Iteration 49600 (6.84709 iter/s, 14.6048s/100 iters), loss = 0.0921473
I0928 22:06:12.794205  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0921479 (* 1 = 0.0921479 loss)
I0928 22:06:12.794212  5237 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I0928 22:06:27.404969  5237 solver.cpp:218] Iteration 49700 (6.84429 iter/s, 14.6107s/100 iters), loss = 0.140656
I0928 22:06:27.405114  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140657 (* 1 = 0.140657 loss)
I0928 22:06:27.405133  5237 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I0928 22:06:42.017746  5237 solver.cpp:218] Iteration 49800 (6.84341 iter/s, 14.6126s/100 iters), loss = 0.120463
I0928 22:06:42.017776  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120464 (* 1 = 0.120464 loss)
I0928 22:06:42.017781  5237 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I0928 22:06:56.623785  5237 solver.cpp:218] Iteration 49900 (6.84652 iter/s, 14.606s/100 iters), loss = 0.0453742
I0928 22:06:56.623826  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0453748 (* 1 = 0.0453748 loss)
I0928 22:06:56.623831  5237 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I0928 22:07:10.502995  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:07:11.088352  5237 solver.cpp:330] Iteration 50000, Testing net (#0)
I0928 22:07:14.512068  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:07:14.655663  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8974
I0928 22:07:14.655689  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32854 (* 1 = 0.32854 loss)
I0928 22:07:14.801092  5237 solver.cpp:218] Iteration 50000 (5.50139 iter/s, 18.1772s/100 iters), loss = 0.0816398
I0928 22:07:14.801125  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0816404 (* 1 = 0.0816404 loss)
I0928 22:07:14.801131  5237 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I0928 22:07:29.403070  5237 solver.cpp:218] Iteration 50100 (6.84842 iter/s, 14.6019s/100 iters), loss = 0.110273
I0928 22:07:29.403106  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.110274 (* 1 = 0.110274 loss)
I0928 22:07:29.403113  5237 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I0928 22:07:44.015882  5237 solver.cpp:218] Iteration 50200 (6.84335 iter/s, 14.6127s/100 iters), loss = 0.134432
I0928 22:07:44.015981  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134432 (* 1 = 0.134432 loss)
I0928 22:07:44.015998  5237 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I0928 22:07:58.626123  5237 solver.cpp:218] Iteration 50300 (6.84458 iter/s, 14.6101s/100 iters), loss = 0.0804468
I0928 22:07:58.626153  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0804475 (* 1 = 0.0804475 loss)
I0928 22:07:58.626160  5237 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I0928 22:08:13.242744  5237 solver.cpp:218] Iteration 50400 (6.84156 iter/s, 14.6165s/100 iters), loss = 0.0788479
I0928 22:08:13.242775  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0788486 (* 1 = 0.0788486 loss)
I0928 22:08:13.242780  5237 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I0928 22:08:27.123709  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:08:27.708406  5237 solver.cpp:330] Iteration 50500, Testing net (#0)
I0928 22:08:31.133955  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:08:31.277509  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8904
I0928 22:08:31.277545  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34452 (* 1 = 0.34452 loss)
I0928 22:08:31.423311  5237 solver.cpp:218] Iteration 50500 (5.5004 iter/s, 18.1805s/100 iters), loss = 0.071723
I0928 22:08:31.423343  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0717237 (* 1 = 0.0717237 loss)
I0928 22:08:31.423351  5237 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I0928 22:08:46.023672  5237 solver.cpp:218] Iteration 50600 (6.84918 iter/s, 14.6003s/100 iters), loss = 0.126048
I0928 22:08:46.023701  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126049 (* 1 = 0.126049 loss)
I0928 22:08:46.023706  5237 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I0928 22:09:00.629053  5237 solver.cpp:218] Iteration 50700 (6.84682 iter/s, 14.6053s/100 iters), loss = 0.115459
I0928 22:09:00.629199  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.11546 (* 1 = 0.11546 loss)
I0928 22:09:00.629206  5237 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I0928 22:09:15.233742  5237 solver.cpp:218] Iteration 50800 (6.8472 iter/s, 14.6045s/100 iters), loss = 0.0902411
I0928 22:09:15.233784  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0902418 (* 1 = 0.0902418 loss)
I0928 22:09:15.233790  5237 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I0928 22:09:29.842209  5237 solver.cpp:218] Iteration 50900 (6.84538 iter/s, 14.6084s/100 iters), loss = 0.0833146
I0928 22:09:29.842238  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0833152 (* 1 = 0.0833152 loss)
I0928 22:09:29.842244  5237 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I0928 22:09:43.718767  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:09:44.303113  5237 solver.cpp:330] Iteration 51000, Testing net (#0)
I0928 22:09:47.725877  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:09:47.869215  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8894
I0928 22:09:47.869251  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.360764 (* 1 = 0.360764 loss)
I0928 22:09:48.016237  5237 solver.cpp:218] Iteration 51000 (5.50238 iter/s, 18.1739s/100 iters), loss = 0.11458
I0928 22:09:48.016266  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.11458 (* 1 = 0.11458 loss)
I0928 22:09:48.016273  5237 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I0928 22:10:02.616783  5237 solver.cpp:218] Iteration 51100 (6.84909 iter/s, 14.6005s/100 iters), loss = 0.1138
I0928 22:10:02.616813  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.113801 (* 1 = 0.113801 loss)
I0928 22:10:02.616821  5237 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I0928 22:10:17.224429  5237 solver.cpp:218] Iteration 51200 (6.84576 iter/s, 14.6076s/100 iters), loss = 0.152353
I0928 22:10:17.224537  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152353 (* 1 = 0.152353 loss)
I0928 22:10:17.224545  5237 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I0928 22:10:31.833394  5237 solver.cpp:218] Iteration 51300 (6.84518 iter/s, 14.6088s/100 iters), loss = 0.0749411
I0928 22:10:31.833433  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0749418 (* 1 = 0.0749418 loss)
I0928 22:10:31.833439  5237 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I0928 22:10:46.446341  5237 solver.cpp:218] Iteration 51400 (6.84328 iter/s, 14.6129s/100 iters), loss = 0.0679548
I0928 22:10:46.446379  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0679555 (* 1 = 0.0679555 loss)
I0928 22:10:46.446385  5237 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I0928 22:11:00.332934  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:11:00.916851  5237 solver.cpp:330] Iteration 51500, Testing net (#0)
I0928 22:11:04.341532  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:11:04.483773  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8922
I0928 22:11:04.483808  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.353937 (* 1 = 0.353937 loss)
I0928 22:11:04.629379  5237 solver.cpp:218] Iteration 51500 (5.49966 iter/s, 18.183s/100 iters), loss = 0.041963
I0928 22:11:04.629407  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0419637 (* 1 = 0.0419637 loss)
I0928 22:11:04.629415  5237 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I0928 22:11:19.232137  5237 solver.cpp:218] Iteration 51600 (6.84805 iter/s, 14.6027s/100 iters), loss = 0.0834198
I0928 22:11:19.232167  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0834205 (* 1 = 0.0834205 loss)
I0928 22:11:19.232172  5237 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I0928 22:11:33.836629  5237 solver.cpp:218] Iteration 51700 (6.84724 iter/s, 14.6044s/100 iters), loss = 0.143437
I0928 22:11:33.836753  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143438 (* 1 = 0.143438 loss)
I0928 22:11:33.836760  5237 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I0928 22:11:48.434887  5237 solver.cpp:218] Iteration 51800 (6.85021 iter/s, 14.5981s/100 iters), loss = 0.0416503
I0928 22:11:48.434916  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0416511 (* 1 = 0.0416511 loss)
I0928 22:11:48.434922  5237 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I0928 22:12:03.039716  5237 solver.cpp:218] Iteration 51900 (6.84708 iter/s, 14.6048s/100 iters), loss = 0.105433
I0928 22:12:03.039746  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.105434 (* 1 = 0.105434 loss)
I0928 22:12:03.039753  5237 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I0928 22:12:16.920796  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:12:17.504359  5237 solver.cpp:330] Iteration 52000, Testing net (#0)
I0928 22:12:20.928582  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:12:21.071918  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8953
I0928 22:12:21.071952  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339805 (* 1 = 0.339805 loss)
I0928 22:12:21.217130  5237 solver.cpp:218] Iteration 52000 (5.50136 iter/s, 18.1773s/100 iters), loss = 0.0926346
I0928 22:12:21.217162  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0926353 (* 1 = 0.0926353 loss)
I0928 22:12:21.217170  5237 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I0928 22:12:35.816610  5237 solver.cpp:218] Iteration 52100 (6.84959 iter/s, 14.5994s/100 iters), loss = 0.0467155
I0928 22:12:35.816640  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0467163 (* 1 = 0.0467163 loss)
I0928 22:12:35.816646  5237 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I0928 22:12:50.422561  5237 solver.cpp:218] Iteration 52200 (6.84656 iter/s, 14.6059s/100 iters), loss = 0.0921951
I0928 22:12:50.422675  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0921958 (* 1 = 0.0921958 loss)
I0928 22:12:50.422683  5237 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I0928 22:13:05.032618  5237 solver.cpp:218] Iteration 52300 (6.84467 iter/s, 14.6099s/100 iters), loss = 0.171332
I0928 22:13:05.032646  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171333 (* 1 = 0.171333 loss)
I0928 22:13:05.032652  5237 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I0928 22:13:19.640398  5237 solver.cpp:218] Iteration 52400 (6.8457 iter/s, 14.6077s/100 iters), loss = 0.0583558
I0928 22:13:19.640430  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0583565 (* 1 = 0.0583565 loss)
I0928 22:13:19.640436  5237 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I0928 22:13:33.523386  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:13:34.109169  5237 solver.cpp:330] Iteration 52500, Testing net (#0)
I0928 22:13:37.530767  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:13:37.673939  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8961
I0928 22:13:37.673965  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.330879 (* 1 = 0.330879 loss)
I0928 22:13:37.819257  5237 solver.cpp:218] Iteration 52500 (5.50092 iter/s, 18.1788s/100 iters), loss = 0.0479003
I0928 22:13:37.819286  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.047901 (* 1 = 0.047901 loss)
I0928 22:13:37.819293  5237 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I0928 22:13:52.421303  5237 solver.cpp:218] Iteration 52600 (6.84839 iter/s, 14.602s/100 iters), loss = 0.142858
I0928 22:13:52.421345  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142859 (* 1 = 0.142859 loss)
I0928 22:13:52.421351  5237 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I0928 22:14:07.024982  5237 solver.cpp:218] Iteration 52700 (6.84763 iter/s, 14.6036s/100 iters), loss = 0.0737297
I0928 22:14:07.025106  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0737304 (* 1 = 0.0737304 loss)
I0928 22:14:07.025125  5237 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I0928 22:14:21.630841  5237 solver.cpp:218] Iteration 52800 (6.84664 iter/s, 14.6057s/100 iters), loss = 0.0755894
I0928 22:14:21.630875  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0755901 (* 1 = 0.0755901 loss)
I0928 22:14:21.630882  5237 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I0928 22:14:36.241704  5237 solver.cpp:218] Iteration 52900 (6.84426 iter/s, 14.6108s/100 iters), loss = 0.0989332
I0928 22:14:36.241735  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0989339 (* 1 = 0.0989339 loss)
I0928 22:14:36.241750  5237 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I0928 22:14:50.123276  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:14:50.708456  5237 solver.cpp:330] Iteration 53000, Testing net (#0)
I0928 22:14:54.130908  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:14:54.274451  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8939
I0928 22:14:54.274487  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.342163 (* 1 = 0.342163 loss)
I0928 22:14:54.419827  5237 solver.cpp:218] Iteration 53000 (5.50114 iter/s, 18.178s/100 iters), loss = 0.0827444
I0928 22:14:54.419857  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0827451 (* 1 = 0.0827451 loss)
I0928 22:14:54.419863  5237 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I0928 22:15:09.027881  5237 solver.cpp:218] Iteration 53100 (6.84557 iter/s, 14.608s/100 iters), loss = 0.141577
I0928 22:15:09.027910  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.141578 (* 1 = 0.141578 loss)
I0928 22:15:09.027926  5237 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I0928 22:15:23.632117  5237 solver.cpp:218] Iteration 53200 (6.84736 iter/s, 14.6042s/100 iters), loss = 0.131897
I0928 22:15:23.632210  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.131897 (* 1 = 0.131897 loss)
I0928 22:15:23.632220  5237 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I0928 22:15:38.241964  5237 solver.cpp:218] Iteration 53300 (6.84476 iter/s, 14.6097s/100 iters), loss = 0.093966
I0928 22:15:38.241996  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0939668 (* 1 = 0.0939668 loss)
I0928 22:15:38.242012  5237 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I0928 22:15:52.847931  5237 solver.cpp:218] Iteration 53400 (6.84655 iter/s, 14.6059s/100 iters), loss = 0.0767591
I0928 22:15:52.847960  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0767598 (* 1 = 0.0767598 loss)
I0928 22:15:52.847965  5237 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I0928 22:16:06.729812  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:16:07.314321  5237 solver.cpp:330] Iteration 53500, Testing net (#0)
I0928 22:16:10.740726  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:16:10.883945  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8932
I0928 22:16:10.883980  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339001 (* 1 = 0.339001 loss)
I0928 22:16:11.029520  5237 solver.cpp:218] Iteration 53500 (5.50009 iter/s, 18.1815s/100 iters), loss = 0.0393791
I0928 22:16:11.029551  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0393798 (* 1 = 0.0393798 loss)
I0928 22:16:11.029556  5237 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I0928 22:16:25.636400  5237 solver.cpp:218] Iteration 53600 (6.84612 iter/s, 14.6068s/100 iters), loss = 0.0871741
I0928 22:16:25.636430  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0871748 (* 1 = 0.0871748 loss)
I0928 22:16:25.636445  5237 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I0928 22:16:40.248752  5237 solver.cpp:218] Iteration 53700 (6.84356 iter/s, 14.6123s/100 iters), loss = 0.0488945
I0928 22:16:40.248867  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0488952 (* 1 = 0.0488952 loss)
I0928 22:16:40.248884  5237 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I0928 22:16:54.869784  5237 solver.cpp:218] Iteration 53800 (6.83953 iter/s, 14.6209s/100 iters), loss = 0.0512224
I0928 22:16:54.869814  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0512232 (* 1 = 0.0512232 loss)
I0928 22:16:54.869829  5237 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I0928 22:17:09.479244  5237 solver.cpp:218] Iteration 53900 (6.84491 iter/s, 14.6094s/100 iters), loss = 0.0343264
I0928 22:17:09.479274  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0343271 (* 1 = 0.0343271 loss)
I0928 22:17:09.479290  5237 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I0928 22:17:23.369196  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:17:23.955348  5237 solver.cpp:330] Iteration 54000, Testing net (#0)
I0928 22:17:27.379854  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:17:27.523043  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8898
I0928 22:17:27.523079  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365032 (* 1 = 0.365032 loss)
I0928 22:17:27.668236  5237 solver.cpp:218] Iteration 54000 (5.49785 iter/s, 18.1889s/100 iters), loss = 0.0948443
I0928 22:17:27.668267  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0948451 (* 1 = 0.0948451 loss)
I0928 22:17:27.668273  5237 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I0928 22:17:42.277103  5237 solver.cpp:218] Iteration 54100 (6.84519 iter/s, 14.6088s/100 iters), loss = 0.0792924
I0928 22:17:42.277133  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0792931 (* 1 = 0.0792931 loss)
I0928 22:17:42.277138  5237 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I0928 22:17:56.886842  5237 solver.cpp:218] Iteration 54200 (6.84478 iter/s, 14.6097s/100 iters), loss = 0.0460216
I0928 22:17:56.886955  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0460223 (* 1 = 0.0460223 loss)
I0928 22:17:56.886962  5237 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I0928 22:18:11.500880  5237 solver.cpp:218] Iteration 54300 (6.8428 iter/s, 14.6139s/100 iters), loss = 0.0820179
I0928 22:18:11.500910  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0820187 (* 1 = 0.0820187 loss)
I0928 22:18:11.500926  5237 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I0928 22:18:26.107599  5237 solver.cpp:218] Iteration 54400 (6.8462 iter/s, 14.6066s/100 iters), loss = 0.0218348
I0928 22:18:26.107628  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0218356 (* 1 = 0.0218356 loss)
I0928 22:18:26.107643  5237 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I0928 22:18:39.999431  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:18:40.583554  5237 solver.cpp:330] Iteration 54500, Testing net (#0)
I0928 22:18:44.009166  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:18:44.152443  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8922
I0928 22:18:44.152468  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.362764 (* 1 = 0.362764 loss)
I0928 22:18:44.298205  5237 solver.cpp:218] Iteration 54500 (5.49737 iter/s, 18.1905s/100 iters), loss = 0.0505478
I0928 22:18:44.298234  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0505485 (* 1 = 0.0505485 loss)
I0928 22:18:44.298241  5237 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I0928 22:18:58.897047  5237 solver.cpp:218] Iteration 54600 (6.84989 iter/s, 14.5988s/100 iters), loss = 0.15133
I0928 22:18:58.897076  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151331 (* 1 = 0.151331 loss)
I0928 22:18:58.897083  5237 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I0928 22:19:13.495267  5237 solver.cpp:218] Iteration 54700 (6.85018 iter/s, 14.5981s/100 iters), loss = 0.0785425
I0928 22:19:13.495386  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0785432 (* 1 = 0.0785432 loss)
I0928 22:19:13.495394  5237 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I0928 22:19:28.094060  5237 solver.cpp:218] Iteration 54800 (6.84996 iter/s, 14.5986s/100 iters), loss = 0.0396534
I0928 22:19:28.094092  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0396541 (* 1 = 0.0396541 loss)
I0928 22:19:28.094099  5237 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I0928 22:19:42.695113  5237 solver.cpp:218] Iteration 54900 (6.84886 iter/s, 14.601s/100 iters), loss = 0.038669
I0928 22:19:42.695152  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0386697 (* 1 = 0.0386697 loss)
I0928 22:19:42.695159  5237 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I0928 22:19:56.569363  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:19:57.153226  5237 solver.cpp:330] Iteration 55000, Testing net (#0)
I0928 22:20:00.578227  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:20:00.721444  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8935
I0928 22:20:00.721479  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.349389 (* 1 = 0.349389 loss)
I0928 22:20:00.866406  5237 solver.cpp:218] Iteration 55000 (5.50321 iter/s, 18.1712s/100 iters), loss = 0.0432574
I0928 22:20:00.866436  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0432582 (* 1 = 0.0432582 loss)
I0928 22:20:00.866442  5237 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I0928 22:20:15.458269  5237 solver.cpp:218] Iteration 55100 (6.85317 iter/s, 14.5918s/100 iters), loss = 0.0863087
I0928 22:20:15.458298  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0863095 (* 1 = 0.0863095 loss)
I0928 22:20:15.458304  5237 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I0928 22:20:30.054869  5237 solver.cpp:218] Iteration 55200 (6.85094 iter/s, 14.5965s/100 iters), loss = 0.0773607
I0928 22:20:30.054973  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0773615 (* 1 = 0.0773615 loss)
I0928 22:20:30.054981  5237 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I0928 22:20:44.652863  5237 solver.cpp:218] Iteration 55300 (6.85032 iter/s, 14.5979s/100 iters), loss = 0.0619803
I0928 22:20:44.652891  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0619811 (* 1 = 0.0619811 loss)
I0928 22:20:44.652897  5237 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I0928 22:20:59.251966  5237 solver.cpp:218] Iteration 55400 (6.84977 iter/s, 14.599s/100 iters), loss = 0.076572
I0928 22:20:59.251996  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0765728 (* 1 = 0.0765728 loss)
I0928 22:20:59.252002  5237 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I0928 22:21:13.129370  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:21:13.714094  5237 solver.cpp:330] Iteration 55500, Testing net (#0)
I0928 22:21:17.139317  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:21:17.282729  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8824
I0928 22:21:17.282765  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.406318 (* 1 = 0.406318 loss)
I0928 22:21:17.428539  5237 solver.cpp:218] Iteration 55500 (5.50161 iter/s, 18.1765s/100 iters), loss = 0.0470215
I0928 22:21:17.428570  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0470223 (* 1 = 0.0470223 loss)
I0928 22:21:17.428576  5237 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I0928 22:21:32.025617  5237 solver.cpp:218] Iteration 55600 (6.85072 iter/s, 14.597s/100 iters), loss = 0.0342998
I0928 22:21:32.025645  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0343006 (* 1 = 0.0343006 loss)
I0928 22:21:32.025651  5237 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I0928 22:21:46.624202  5237 solver.cpp:218] Iteration 55700 (6.85001 iter/s, 14.5985s/100 iters), loss = 0.0579182
I0928 22:21:46.624315  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.057919 (* 1 = 0.057919 loss)
I0928 22:21:46.624322  5237 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I0928 22:22:01.229946  5237 solver.cpp:218] Iteration 55800 (6.84669 iter/s, 14.6056s/100 iters), loss = 0.0857733
I0928 22:22:01.229985  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.085774 (* 1 = 0.085774 loss)
I0928 22:22:01.229992  5237 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I0928 22:22:15.838538  5237 solver.cpp:218] Iteration 55900 (6.84533 iter/s, 14.6085s/100 iters), loss = 0.0344338
I0928 22:22:15.838587  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0344345 (* 1 = 0.0344345 loss)
I0928 22:22:15.838593  5237 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I0928 22:22:29.720890  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:22:30.304742  5237 solver.cpp:330] Iteration 56000, Testing net (#0)
I0928 22:22:33.728490  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:22:33.871790  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8791
I0928 22:22:33.871825  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.415857 (* 1 = 0.415857 loss)
I0928 22:22:34.017009  5237 solver.cpp:218] Iteration 56000 (5.50104 iter/s, 18.1784s/100 iters), loss = 0.126424
I0928 22:22:34.017040  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126425 (* 1 = 0.126425 loss)
I0928 22:22:34.017045  5237 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I0928 22:22:48.625357  5237 solver.cpp:218] Iteration 56100 (6.84543 iter/s, 14.6083s/100 iters), loss = 0.0477953
I0928 22:22:48.625388  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0477961 (* 1 = 0.0477961 loss)
I0928 22:22:48.625394  5237 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I0928 22:23:03.239540  5237 solver.cpp:218] Iteration 56200 (6.8427 iter/s, 14.6141s/100 iters), loss = 0.143766
I0928 22:23:03.239697  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143766 (* 1 = 0.143766 loss)
I0928 22:23:03.239707  5237 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I0928 22:23:17.851285  5237 solver.cpp:218] Iteration 56300 (6.8439 iter/s, 14.6116s/100 iters), loss = 0.0461046
I0928 22:23:17.851315  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0461055 (* 1 = 0.0461055 loss)
I0928 22:23:17.851320  5237 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I0928 22:23:32.461410  5237 solver.cpp:218] Iteration 56400 (6.8446 iter/s, 14.6101s/100 iters), loss = 0.0689052
I0928 22:23:32.461438  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.068906 (* 1 = 0.068906 loss)
I0928 22:23:32.461444  5237 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I0928 22:23:46.347136  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:23:46.933233  5237 solver.cpp:330] Iteration 56500, Testing net (#0)
I0928 22:23:50.357380  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:23:50.500807  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8881
I0928 22:23:50.500844  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.386864 (* 1 = 0.386864 loss)
I0928 22:23:50.645862  5237 solver.cpp:218] Iteration 56500 (5.49923 iter/s, 18.1844s/100 iters), loss = 0.0665313
I0928 22:23:50.645892  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0665322 (* 1 = 0.0665322 loss)
I0928 22:23:50.645898  5237 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I0928 22:24:05.249156  5237 solver.cpp:218] Iteration 56600 (6.8478 iter/s, 14.6032s/100 iters), loss = 0.0423971
I0928 22:24:05.249186  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.042398 (* 1 = 0.042398 loss)
I0928 22:24:05.249191  5237 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I0928 22:24:19.859458  5237 solver.cpp:218] Iteration 56700 (6.84452 iter/s, 14.6102s/100 iters), loss = 0.100566
I0928 22:24:19.859563  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.100567 (* 1 = 0.100567 loss)
I0928 22:24:19.859570  5237 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I0928 22:24:34.467875  5237 solver.cpp:218] Iteration 56800 (6.84544 iter/s, 14.6083s/100 iters), loss = 0.049174
I0928 22:24:34.467919  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0491748 (* 1 = 0.0491748 loss)
I0928 22:24:34.467926  5237 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I0928 22:24:49.076261  5237 solver.cpp:218] Iteration 56900 (6.84542 iter/s, 14.6083s/100 iters), loss = 0.0236327
I0928 22:24:49.076300  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0236336 (* 1 = 0.0236336 loss)
I0928 22:24:49.076306  5237 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I0928 22:25:02.961647  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:25:03.546380  5237 solver.cpp:330] Iteration 57000, Testing net (#0)
I0928 22:25:06.971680  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:25:07.114862  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8887
I0928 22:25:07.114898  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376038 (* 1 = 0.376038 loss)
I0928 22:25:07.259879  5237 solver.cpp:218] Iteration 57000 (5.49948 iter/s, 18.1835s/100 iters), loss = 0.126848
I0928 22:25:07.259908  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126849 (* 1 = 0.126849 loss)
I0928 22:25:07.259915  5237 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I0928 22:25:21.865530  5237 solver.cpp:218] Iteration 57100 (6.8467 iter/s, 14.6056s/100 iters), loss = 0.0872026
I0928 22:25:21.865571  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0872035 (* 1 = 0.0872035 loss)
I0928 22:25:21.865577  5237 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I0928 22:25:36.470532  5237 solver.cpp:218] Iteration 57200 (6.84701 iter/s, 14.6049s/100 iters), loss = 0.0752352
I0928 22:25:36.470672  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.075236 (* 1 = 0.075236 loss)
I0928 22:25:36.470681  5237 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I0928 22:25:51.082108  5237 solver.cpp:218] Iteration 57300 (6.84397 iter/s, 14.6114s/100 iters), loss = 0.110271
I0928 22:25:51.082139  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.110272 (* 1 = 0.110272 loss)
I0928 22:25:51.082145  5237 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I0928 22:26:05.692564  5237 solver.cpp:218] Iteration 57400 (6.84445 iter/s, 14.6104s/100 iters), loss = 0.0301139
I0928 22:26:05.692591  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0301148 (* 1 = 0.0301148 loss)
I0928 22:26:05.692597  5237 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I0928 22:26:19.582111  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:26:20.165117  5237 solver.cpp:330] Iteration 57500, Testing net (#0)
I0928 22:26:23.586096  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:26:23.729805  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.888
I0928 22:26:23.729840  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37554 (* 1 = 0.37554 loss)
I0928 22:26:23.875145  5237 solver.cpp:218] Iteration 57500 (5.49979 iter/s, 18.1825s/100 iters), loss = 0.063822
I0928 22:26:23.875175  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0638229 (* 1 = 0.0638229 loss)
I0928 22:26:23.875182  5237 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I0928 22:26:38.468490  5237 solver.cpp:218] Iteration 57600 (6.85247 iter/s, 14.5933s/100 iters), loss = 0.0386663
I0928 22:26:38.468531  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0386672 (* 1 = 0.0386672 loss)
I0928 22:26:38.468538  5237 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I0928 22:26:53.069442  5237 solver.cpp:218] Iteration 57700 (6.84891 iter/s, 14.6009s/100 iters), loss = 0.0738404
I0928 22:26:53.069540  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0738413 (* 1 = 0.0738413 loss)
I0928 22:26:53.069555  5237 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I0928 22:27:07.669677  5237 solver.cpp:218] Iteration 57800 (6.84927 iter/s, 14.6001s/100 iters), loss = 0.0439903
I0928 22:27:07.669708  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0439912 (* 1 = 0.0439912 loss)
I0928 22:27:07.669714  5237 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I0928 22:27:22.277709  5237 solver.cpp:218] Iteration 57900 (6.84558 iter/s, 14.608s/100 iters), loss = 0.108637
I0928 22:27:22.277748  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.108638 (* 1 = 0.108638 loss)
I0928 22:27:22.277755  5237 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I0928 22:27:36.156175  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:27:36.740324  5237 solver.cpp:330] Iteration 58000, Testing net (#0)
I0928 22:27:40.164384  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:27:40.307613  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8903
I0928 22:27:40.307648  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37734 (* 1 = 0.37734 loss)
I0928 22:27:40.453012  5237 solver.cpp:218] Iteration 58000 (5.502 iter/s, 18.1752s/100 iters), loss = 0.0557197
I0928 22:27:40.453042  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0557206 (* 1 = 0.0557206 loss)
I0928 22:27:40.453047  5237 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I0928 22:27:55.050343  5237 solver.cpp:218] Iteration 58100 (6.8506 iter/s, 14.5973s/100 iters), loss = 0.138568
I0928 22:27:55.050374  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.138568 (* 1 = 0.138568 loss)
I0928 22:27:55.050379  5237 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I0928 22:28:09.659436  5237 solver.cpp:218] Iteration 58200 (6.84509 iter/s, 14.609s/100 iters), loss = 0.0713777
I0928 22:28:09.659550  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0713786 (* 1 = 0.0713786 loss)
I0928 22:28:09.659557  5237 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I0928 22:28:24.266172  5237 solver.cpp:218] Iteration 58300 (6.84622 iter/s, 14.6066s/100 iters), loss = 0.0959691
I0928 22:28:24.266201  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0959699 (* 1 = 0.0959699 loss)
I0928 22:28:24.266207  5237 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I0928 22:28:38.870345  5237 solver.cpp:218] Iteration 58400 (6.84739 iter/s, 14.6041s/100 iters), loss = 0.0569953
I0928 22:28:38.870384  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0569961 (* 1 = 0.0569961 loss)
I0928 22:28:38.870390  5237 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I0928 22:28:52.752089  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:28:53.336999  5237 solver.cpp:330] Iteration 58500, Testing net (#0)
I0928 22:28:56.760927  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:28:56.904011  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8918
I0928 22:28:56.904047  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.371575 (* 1 = 0.371575 loss)
I0928 22:28:57.049605  5237 solver.cpp:218] Iteration 58500 (5.5008 iter/s, 18.1792s/100 iters), loss = 0.0633886
I0928 22:28:57.049638  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0633895 (* 1 = 0.0633895 loss)
I0928 22:28:57.049644  5237 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I0928 22:29:11.651336  5237 solver.cpp:218] Iteration 58600 (6.84854 iter/s, 14.6017s/100 iters), loss = 0.0569991
I0928 22:29:11.651376  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.057 (* 1 = 0.057 loss)
I0928 22:29:11.651383  5237 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I0928 22:29:26.260689  5237 solver.cpp:218] Iteration 58700 (6.84497 iter/s, 14.6093s/100 iters), loss = 0.0551505
I0928 22:29:26.260785  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0551514 (* 1 = 0.0551514 loss)
I0928 22:29:26.260792  5237 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I0928 22:29:40.861428  5237 solver.cpp:218] Iteration 58800 (6.84903 iter/s, 14.6006s/100 iters), loss = 0.0466822
I0928 22:29:40.861467  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0466831 (* 1 = 0.0466831 loss)
I0928 22:29:40.861474  5237 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I0928 22:29:55.470059  5237 solver.cpp:218] Iteration 58900 (6.84531 iter/s, 14.6086s/100 iters), loss = 0.121779
I0928 22:29:55.470099  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12178 (* 1 = 0.12178 loss)
I0928 22:29:55.470105  5237 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I0928 22:30:09.358831  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:30:09.944095  5237 solver.cpp:330] Iteration 59000, Testing net (#0)
I0928 22:30:13.366374  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:30:13.509968  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8944
I0928 22:30:13.510001  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366676 (* 1 = 0.366676 loss)
I0928 22:30:13.655439  5237 solver.cpp:218] Iteration 59000 (5.49895 iter/s, 18.1853s/100 iters), loss = 0.0711917
I0928 22:30:13.655469  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0711926 (* 1 = 0.0711926 loss)
I0928 22:30:13.655477  5237 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I0928 22:30:28.259771  5237 solver.cpp:218] Iteration 59100 (6.84732 iter/s, 14.6043s/100 iters), loss = 0.0712322
I0928 22:30:28.259811  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0712331 (* 1 = 0.0712331 loss)
I0928 22:30:28.259817  5237 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I0928 22:30:42.875444  5237 solver.cpp:218] Iteration 59200 (6.84201 iter/s, 14.6156s/100 iters), loss = 0.0995542
I0928 22:30:42.875597  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0995551 (* 1 = 0.0995551 loss)
I0928 22:30:42.875603  5237 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I0928 22:30:57.483158  5237 solver.cpp:218] Iteration 59300 (6.84579 iter/s, 14.6075s/100 iters), loss = 0.0409399
I0928 22:30:57.483198  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0409408 (* 1 = 0.0409408 loss)
I0928 22:30:57.483204  5237 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I0928 22:31:12.094285  5237 solver.cpp:218] Iteration 59400 (6.84414 iter/s, 14.611s/100 iters), loss = 0.0443907
I0928 22:31:12.094316  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0443916 (* 1 = 0.0443916 loss)
I0928 22:31:12.094322  5237 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I0928 22:31:25.977874  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:31:26.562563  5237 solver.cpp:330] Iteration 59500, Testing net (#0)
I0928 22:31:29.984736  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:31:30.128937  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8903
I0928 22:31:30.128973  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37392 (* 1 = 0.37392 loss)
I0928 22:31:30.274008  5237 solver.cpp:218] Iteration 59500 (5.50066 iter/s, 18.1796s/100 iters), loss = 0.0714373
I0928 22:31:30.274036  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0714382 (* 1 = 0.0714382 loss)
I0928 22:31:30.274044  5237 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I0928 22:31:44.868680  5237 solver.cpp:218] Iteration 59600 (6.85185 iter/s, 14.5946s/100 iters), loss = 0.0521422
I0928 22:31:44.868710  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0521432 (* 1 = 0.0521432 loss)
I0928 22:31:44.868716  5237 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I0928 22:31:59.471107  5237 solver.cpp:218] Iteration 59700 (6.84821 iter/s, 14.6024s/100 iters), loss = 0.0765321
I0928 22:31:59.471261  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0765331 (* 1 = 0.0765331 loss)
I0928 22:31:59.471279  5237 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I0928 22:32:14.074013  5237 solver.cpp:218] Iteration 59800 (6.84804 iter/s, 14.6027s/100 iters), loss = 0.0724967
I0928 22:32:14.074041  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0724977 (* 1 = 0.0724977 loss)
I0928 22:32:14.074048  5237 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I0928 22:32:28.680027  5237 solver.cpp:218] Iteration 59900 (6.84653 iter/s, 14.6059s/100 iters), loss = 0.0825037
I0928 22:32:28.680058  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0825047 (* 1 = 0.0825047 loss)
I0928 22:32:28.680064  5237 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I0928 22:32:42.563491  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:32:43.147671  5237 solver.cpp:330] Iteration 60000, Testing net (#0)
I0928 22:32:46.570874  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:32:46.714228  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8837
I0928 22:32:46.714253  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.421329 (* 1 = 0.421329 loss)
I0928 22:32:46.859241  5237 solver.cpp:218] Iteration 60000 (5.50081 iter/s, 18.1791s/100 iters), loss = 0.0801557
I0928 22:32:46.859273  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0801567 (* 1 = 0.0801567 loss)
I0928 22:32:46.859279  5237 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I0928 22:33:01.455101  5237 solver.cpp:218] Iteration 60100 (6.85129 iter/s, 14.5958s/100 iters), loss = 0.0423587
I0928 22:33:01.455129  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0423597 (* 1 = 0.0423597 loss)
I0928 22:33:01.455135  5237 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I0928 22:33:16.055491  5237 solver.cpp:218] Iteration 60200 (6.84916 iter/s, 14.6003s/100 iters), loss = 0.0376206
I0928 22:33:16.055593  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0376216 (* 1 = 0.0376216 loss)
I0928 22:33:16.055610  5237 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I0928 22:33:30.651731  5237 solver.cpp:218] Iteration 60300 (6.85115 iter/s, 14.5961s/100 iters), loss = 0.0134889
I0928 22:33:30.651759  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134899 (* 1 = 0.0134899 loss)
I0928 22:33:30.651765  5237 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I0928 22:33:45.263375  5237 solver.cpp:218] Iteration 60400 (6.84389 iter/s, 14.6116s/100 iters), loss = 0.0181838
I0928 22:33:45.263406  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181847 (* 1 = 0.0181847 loss)
I0928 22:33:45.263412  5237 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I0928 22:33:59.135365  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:33:59.719671  5237 solver.cpp:330] Iteration 60500, Testing net (#0)
I0928 22:34:03.144155  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:34:03.287366  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8846
I0928 22:34:03.287401  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.409462 (* 1 = 0.409462 loss)
I0928 22:34:03.432701  5237 solver.cpp:218] Iteration 60500 (5.50381 iter/s, 18.1692s/100 iters), loss = 0.0611271
I0928 22:34:03.432734  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0611281 (* 1 = 0.0611281 loss)
I0928 22:34:03.432740  5237 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I0928 22:34:18.039567  5237 solver.cpp:218] Iteration 60600 (6.84613 iter/s, 14.6068s/100 iters), loss = 0.0253858
I0928 22:34:18.039610  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0253868 (* 1 = 0.0253868 loss)
I0928 22:34:18.039616  5237 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I0928 22:34:32.640563  5237 solver.cpp:218] Iteration 60700 (6.84889 iter/s, 14.6009s/100 iters), loss = 0.0578183
I0928 22:34:32.640683  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0578193 (* 1 = 0.0578193 loss)
I0928 22:34:32.640700  5237 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I0928 22:34:47.242586  5237 solver.cpp:218] Iteration 60800 (6.84844 iter/s, 14.6019s/100 iters), loss = 0.0365496
I0928 22:34:47.242615  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0365507 (* 1 = 0.0365507 loss)
I0928 22:34:47.242621  5237 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I0928 22:35:01.838606  5237 solver.cpp:218] Iteration 60900 (6.85122 iter/s, 14.596s/100 iters), loss = 0.0426569
I0928 22:35:01.838636  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0426579 (* 1 = 0.0426579 loss)
I0928 22:35:01.838644  5237 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I0928 22:35:15.713229  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:35:16.298071  5237 solver.cpp:330] Iteration 61000, Testing net (#0)
I0928 22:35:19.720849  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:35:19.864428  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8849
I0928 22:35:19.864454  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.412256 (* 1 = 0.412256 loss)
I0928 22:35:20.009148  5237 solver.cpp:218] Iteration 61000 (5.50344 iter/s, 18.1705s/100 iters), loss = 0.0560957
I0928 22:35:20.009178  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0560967 (* 1 = 0.0560967 loss)
I0928 22:35:20.009186  5237 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I0928 22:35:34.617508  5237 solver.cpp:218] Iteration 61100 (6.84543 iter/s, 14.6083s/100 iters), loss = 0.0158718
I0928 22:35:34.617538  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0158728 (* 1 = 0.0158728 loss)
I0928 22:35:34.617543  5237 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I0928 22:35:49.228493  5237 solver.cpp:218] Iteration 61200 (6.8442 iter/s, 14.6109s/100 iters), loss = 0.0528207
I0928 22:35:49.228598  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0528217 (* 1 = 0.0528217 loss)
I0928 22:35:49.228606  5237 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I0928 22:36:03.832121  5237 solver.cpp:218] Iteration 61300 (6.84768 iter/s, 14.6035s/100 iters), loss = 0.043958
I0928 22:36:03.832151  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.043959 (* 1 = 0.043959 loss)
I0928 22:36:03.832166  5237 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I0928 22:36:18.435214  5237 solver.cpp:218] Iteration 61400 (6.8479 iter/s, 14.603s/100 iters), loss = 0.0152254
I0928 22:36:18.435243  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152264 (* 1 = 0.0152264 loss)
I0928 22:36:18.435250  5237 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I0928 22:36:32.310303  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:36:32.896332  5237 solver.cpp:330] Iteration 61500, Testing net (#0)
I0928 22:36:36.319808  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:36:36.463057  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8919
I0928 22:36:36.463088  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.375369 (* 1 = 0.375369 loss)
I0928 22:36:36.607442  5237 solver.cpp:218] Iteration 61500 (5.50293 iter/s, 18.1721s/100 iters), loss = 0.0904298
I0928 22:36:36.607491  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0904307 (* 1 = 0.0904307 loss)
I0928 22:36:36.607499  5237 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I0928 22:36:51.214401  5237 solver.cpp:218] Iteration 61600 (6.84609 iter/s, 14.6069s/100 iters), loss = 0.0232348
I0928 22:36:51.214442  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0232358 (* 1 = 0.0232358 loss)
I0928 22:36:51.214449  5237 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I0928 22:37:05.834786  5237 solver.cpp:218] Iteration 61700 (6.8398 iter/s, 14.6203s/100 iters), loss = 0.0968312
I0928 22:37:05.834856  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0968322 (* 1 = 0.0968322 loss)
I0928 22:37:05.834872  5237 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I0928 22:37:20.440336  5237 solver.cpp:218] Iteration 61800 (6.84676 iter/s, 14.6054s/100 iters), loss = 0.0846632
I0928 22:37:20.440373  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0846642 (* 1 = 0.0846642 loss)
I0928 22:37:20.440381  5237 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I0928 22:37:35.056144  5237 solver.cpp:218] Iteration 61900 (6.84194 iter/s, 14.6157s/100 iters), loss = 0.027158
I0928 22:37:35.056174  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.027159 (* 1 = 0.027159 loss)
I0928 22:37:35.056180  5237 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I0928 22:37:48.948410  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:37:49.532773  5237 solver.cpp:330] Iteration 62000, Testing net (#0)
I0928 22:37:52.957365  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:37:53.100255  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8919
I0928 22:37:53.100289  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372529 (* 1 = 0.372529 loss)
I0928 22:37:53.244825  5237 solver.cpp:218] Iteration 62000 (5.49795 iter/s, 18.1886s/100 iters), loss = 0.0358581
I0928 22:37:53.244855  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0358591 (* 1 = 0.0358591 loss)
I0928 22:37:53.244861  5237 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I0928 22:38:07.841080  5237 solver.cpp:218] Iteration 62100 (6.85111 iter/s, 14.5962s/100 iters), loss = 0.0524345
I0928 22:38:07.841109  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0524355 (* 1 = 0.0524355 loss)
I0928 22:38:07.841115  5237 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I0928 22:38:22.448242  5237 solver.cpp:218] Iteration 62200 (6.84599 iter/s, 14.6071s/100 iters), loss = 0.032773
I0928 22:38:22.448365  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.032774 (* 1 = 0.032774 loss)
I0928 22:38:22.448374  5237 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I0928 22:38:37.055543  5237 solver.cpp:218] Iteration 62300 (6.84596 iter/s, 14.6072s/100 iters), loss = 0.0494975
I0928 22:38:37.055577  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0494985 (* 1 = 0.0494985 loss)
I0928 22:38:37.055583  5237 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I0928 22:38:51.657889  5237 solver.cpp:218] Iteration 62400 (6.84825 iter/s, 14.6023s/100 iters), loss = 0.0858885
I0928 22:38:51.657918  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0858895 (* 1 = 0.0858895 loss)
I0928 22:38:51.657924  5237 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I0928 22:39:05.540560  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:39:06.127693  5237 solver.cpp:330] Iteration 62500, Testing net (#0)
I0928 22:39:09.550447  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:39:09.693804  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8934
I0928 22:39:09.693845  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.377144 (* 1 = 0.377144 loss)
I0928 22:39:09.839061  5237 solver.cpp:218] Iteration 62500 (5.50022 iter/s, 18.1811s/100 iters), loss = 0.055035
I0928 22:39:09.839090  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.055036 (* 1 = 0.055036 loss)
I0928 22:39:09.839097  5237 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I0928 22:39:24.438887  5237 solver.cpp:218] Iteration 62600 (6.84943 iter/s, 14.5998s/100 iters), loss = 0.0647061
I0928 22:39:24.438917  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0647071 (* 1 = 0.0647071 loss)
I0928 22:39:24.438923  5237 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I0928 22:39:39.045981  5237 solver.cpp:218] Iteration 62700 (6.84602 iter/s, 14.607s/100 iters), loss = 0.0909939
I0928 22:39:39.046124  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0909949 (* 1 = 0.0909949 loss)
I0928 22:39:39.046133  5237 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I0928 22:39:53.651489  5237 solver.cpp:218] Iteration 62800 (6.84682 iter/s, 14.6053s/100 iters), loss = 0.0509822
I0928 22:39:53.651520  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0509831 (* 1 = 0.0509831 loss)
I0928 22:39:53.651526  5237 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I0928 22:40:08.256376  5237 solver.cpp:218] Iteration 62900 (6.84706 iter/s, 14.6048s/100 iters), loss = 0.0371149
I0928 22:40:08.256408  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0371159 (* 1 = 0.0371159 loss)
I0928 22:40:08.256415  5237 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I0928 22:40:22.140321  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:40:22.725780  5237 solver.cpp:330] Iteration 63000, Testing net (#0)
I0928 22:40:26.152591  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:40:26.295155  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8893
I0928 22:40:26.295179  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.409223 (* 1 = 0.409223 loss)
I0928 22:40:26.440893  5237 solver.cpp:218] Iteration 63000 (5.49921 iter/s, 18.1844s/100 iters), loss = 0.0387429
I0928 22:40:26.440927  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0387438 (* 1 = 0.0387438 loss)
I0928 22:40:26.440937  5237 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I0928 22:40:41.045557  5237 solver.cpp:218] Iteration 63100 (6.84716 iter/s, 14.6046s/100 iters), loss = 0.0203854
I0928 22:40:41.045588  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0203864 (* 1 = 0.0203864 loss)
I0928 22:40:41.045593  5237 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I0928 22:40:55.656745  5237 solver.cpp:218] Iteration 63200 (6.8441 iter/s, 14.6111s/100 iters), loss = 0.0278299
I0928 22:40:55.656838  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0278309 (* 1 = 0.0278309 loss)
I0928 22:40:55.656857  5237 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I0928 22:41:10.266616  5237 solver.cpp:218] Iteration 63300 (6.84475 iter/s, 14.6097s/100 iters), loss = 0.030373
I0928 22:41:10.266645  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.030374 (* 1 = 0.030374 loss)
I0928 22:41:10.266661  5237 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I0928 22:41:24.876965  5237 solver.cpp:218] Iteration 63400 (6.8445 iter/s, 14.6103s/100 iters), loss = 0.0311802
I0928 22:41:24.876996  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0311811 (* 1 = 0.0311811 loss)
I0928 22:41:24.877002  5237 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I0928 22:41:38.767148  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:41:39.350522  5237 solver.cpp:330] Iteration 63500, Testing net (#0)
I0928 22:41:42.771544  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:41:42.914436  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8948
I0928 22:41:42.914471  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.384464 (* 1 = 0.384464 loss)
I0928 22:41:43.059763  5237 solver.cpp:218] Iteration 63500 (5.49973 iter/s, 18.1827s/100 iters), loss = 0.0371598
I0928 22:41:43.059794  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0371608 (* 1 = 0.0371608 loss)
I0928 22:41:43.059801  5237 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I0928 22:41:57.660615  5237 solver.cpp:218] Iteration 63600 (6.84895 iter/s, 14.6008s/100 iters), loss = 0.0507111
I0928 22:41:57.660645  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.050712 (* 1 = 0.050712 loss)
I0928 22:41:57.660651  5237 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I0928 22:42:12.272156  5237 solver.cpp:218] Iteration 63700 (6.84394 iter/s, 14.6115s/100 iters), loss = 0.0879475
I0928 22:42:12.272253  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0879484 (* 1 = 0.0879484 loss)
I0928 22:42:12.272269  5237 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I0928 22:42:26.878098  5237 solver.cpp:218] Iteration 63800 (6.84659 iter/s, 14.6058s/100 iters), loss = 0.0450582
I0928 22:42:26.878137  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0450592 (* 1 = 0.0450592 loss)
I0928 22:42:26.878144  5237 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I0928 22:42:41.488971  5237 solver.cpp:218] Iteration 63900 (6.84426 iter/s, 14.6108s/100 iters), loss = 0.0618952
I0928 22:42:41.489002  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0618961 (* 1 = 0.0618961 loss)
I0928 22:42:41.489008  5237 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I0928 22:42:55.371743  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:42:55.956588  5237 solver.cpp:330] Iteration 64000, Testing net (#0)
I0928 22:42:59.381603  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:42:59.524963  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8914
I0928 22:42:59.524998  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.404586 (* 1 = 0.404586 loss)
I0928 22:42:59.670743  5237 solver.cpp:218] Iteration 64000 (5.50004 iter/s, 18.1817s/100 iters), loss = 0.0239877
I0928 22:42:59.670776  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0239886 (* 1 = 0.0239886 loss)
I0928 22:42:59.670783  5237 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I0928 22:43:14.277643  5237 solver.cpp:218] Iteration 64100 (6.84611 iter/s, 14.6068s/100 iters), loss = 0.0302639
I0928 22:43:14.277670  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0302648 (* 1 = 0.0302648 loss)
I0928 22:43:14.277676  5237 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I0928 22:43:28.880300  5237 solver.cpp:218] Iteration 64200 (6.8481 iter/s, 14.6026s/100 iters), loss = 0.102741
I0928 22:43:28.880461  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102742 (* 1 = 0.102742 loss)
I0928 22:43:28.880479  5237 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I0928 22:43:43.485044  5237 solver.cpp:218] Iteration 64300 (6.84719 iter/s, 14.6045s/100 iters), loss = 0.0468855
I0928 22:43:43.485075  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0468864 (* 1 = 0.0468864 loss)
I0928 22:43:43.485081  5237 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I0928 22:43:58.091652  5237 solver.cpp:218] Iteration 64400 (6.84625 iter/s, 14.6065s/100 iters), loss = 0.0242918
I0928 22:43:58.091692  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0242927 (* 1 = 0.0242927 loss)
I0928 22:43:58.091698  5237 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I0928 22:44:11.971527  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:44:12.556723  5237 solver.cpp:330] Iteration 64500, Testing net (#0)
I0928 22:44:15.979245  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:44:16.122236  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8849
I0928 22:44:16.122270  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.427238 (* 1 = 0.427238 loss)
I0928 22:44:16.268949  5237 solver.cpp:218] Iteration 64500 (5.50139 iter/s, 18.1772s/100 iters), loss = 0.0959449
I0928 22:44:16.268980  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0959458 (* 1 = 0.0959458 loss)
I0928 22:44:16.268985  5237 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I0928 22:44:30.866874  5237 solver.cpp:218] Iteration 64600 (6.85032 iter/s, 14.5979s/100 iters), loss = 0.0628444
I0928 22:44:30.866904  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0628454 (* 1 = 0.0628454 loss)
I0928 22:44:30.866909  5237 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I0928 22:44:45.466215  5237 solver.cpp:218] Iteration 64700 (6.84966 iter/s, 14.5993s/100 iters), loss = 0.0198779
I0928 22:44:45.466321  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0198789 (* 1 = 0.0198789 loss)
I0928 22:44:45.466327  5237 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I0928 22:45:00.069263  5237 solver.cpp:218] Iteration 64800 (6.84795 iter/s, 14.6029s/100 iters), loss = 0.0824047
I0928 22:45:00.069295  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0824056 (* 1 = 0.0824056 loss)
I0928 22:45:00.069303  5237 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I0928 22:45:14.674103  5237 solver.cpp:218] Iteration 64900 (6.84708 iter/s, 14.6048s/100 iters), loss = 0.0541683
I0928 22:45:14.674131  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0541693 (* 1 = 0.0541693 loss)
I0928 22:45:14.674137  5237 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I0928 22:45:28.551789  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:45:29.136023  5237 solver.cpp:330] Iteration 65000, Testing net (#0)
I0928 22:45:32.560637  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:45:32.703680  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8871
I0928 22:45:32.703706  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.409968 (* 1 = 0.409968 loss)
I0928 22:45:32.849679  5237 solver.cpp:218] Iteration 65000 (5.50191 iter/s, 18.1755s/100 iters), loss = 0.0899533
I0928 22:45:32.849709  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0899542 (* 1 = 0.0899542 loss)
I0928 22:45:32.849716  5237 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I0928 22:45:47.452757  5237 solver.cpp:218] Iteration 65100 (6.84791 iter/s, 14.603s/100 iters), loss = 0.0253691
I0928 22:45:47.452787  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0253701 (* 1 = 0.0253701 loss)
I0928 22:45:47.452792  5237 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I0928 22:46:02.057106  5237 solver.cpp:218] Iteration 65200 (6.84731 iter/s, 14.6043s/100 iters), loss = 0.0212741
I0928 22:46:02.057265  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0212751 (* 1 = 0.0212751 loss)
I0928 22:46:02.057276  5237 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I0928 22:46:16.660903  5237 solver.cpp:218] Iteration 65300 (6.84762 iter/s, 14.6036s/100 iters), loss = 0.153998
I0928 22:46:16.660933  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153999 (* 1 = 0.153999 loss)
I0928 22:46:16.660940  5237 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I0928 22:46:31.266961  5237 solver.cpp:218] Iteration 65400 (6.84651 iter/s, 14.606s/100 iters), loss = 0.059246
I0928 22:46:31.266990  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0592469 (* 1 = 0.0592469 loss)
I0928 22:46:31.266996  5237 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I0928 22:46:45.154691  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:46:45.740018  5237 solver.cpp:330] Iteration 65500, Testing net (#0)
I0928 22:46:49.164085  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:46:49.307503  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8857
I0928 22:46:49.307538  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.412663 (* 1 = 0.412663 loss)
I0928 22:46:49.452817  5237 solver.cpp:218] Iteration 65500 (5.4988 iter/s, 18.1858s/100 iters), loss = 0.0361249
I0928 22:46:49.452850  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0361259 (* 1 = 0.0361259 loss)
I0928 22:46:49.452857  5237 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I0928 22:47:04.062295  5237 solver.cpp:218] Iteration 65600 (6.84491 iter/s, 14.6094s/100 iters), loss = 0.0738508
I0928 22:47:04.062326  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0738517 (* 1 = 0.0738517 loss)
I0928 22:47:04.062332  5237 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I0928 22:47:18.673377  5237 solver.cpp:218] Iteration 65700 (6.84415 iter/s, 14.611s/100 iters), loss = 0.0359021
I0928 22:47:18.673513  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0359031 (* 1 = 0.0359031 loss)
I0928 22:47:18.673521  5237 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I0928 22:47:33.292891  5237 solver.cpp:218] Iteration 65800 (6.84025 iter/s, 14.6193s/100 iters), loss = 0.0418227
I0928 22:47:33.292922  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0418237 (* 1 = 0.0418237 loss)
I0928 22:47:33.292927  5237 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I0928 22:47:47.903146  5237 solver.cpp:218] Iteration 65900 (6.84454 iter/s, 14.6102s/100 iters), loss = 0.0430371
I0928 22:47:47.903175  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0430381 (* 1 = 0.0430381 loss)
I0928 22:47:47.903182  5237 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I0928 22:48:01.789436  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:48:02.374047  5237 solver.cpp:330] Iteration 66000, Testing net (#0)
I0928 22:48:05.797147  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:48:05.940187  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8861
I0928 22:48:05.940222  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.436632 (* 1 = 0.436632 loss)
I0928 22:48:06.085566  5237 solver.cpp:218] Iteration 66000 (5.49984 iter/s, 18.1823s/100 iters), loss = 0.0489302
I0928 22:48:06.085599  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0489311 (* 1 = 0.0489311 loss)
I0928 22:48:06.085606  5237 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I0928 22:48:20.677413  5237 solver.cpp:218] Iteration 66100 (6.85318 iter/s, 14.5918s/100 iters), loss = 0.0684334
I0928 22:48:20.677443  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0684343 (* 1 = 0.0684343 loss)
I0928 22:48:20.677448  5237 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I0928 22:48:35.279410  5237 solver.cpp:218] Iteration 66200 (6.84841 iter/s, 14.6019s/100 iters), loss = 0.0534597
I0928 22:48:35.279557  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0534607 (* 1 = 0.0534607 loss)
I0928 22:48:35.279582  5237 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I0928 22:48:49.880746  5237 solver.cpp:218] Iteration 66300 (6.84878 iter/s, 14.6011s/100 iters), loss = 0.0681608
I0928 22:48:49.880787  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0681617 (* 1 = 0.0681617 loss)
I0928 22:48:49.880794  5237 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I0928 22:49:04.476779  5237 solver.cpp:218] Iteration 66400 (6.85122 iter/s, 14.5959s/100 iters), loss = 0.0274106
I0928 22:49:04.476810  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0274116 (* 1 = 0.0274116 loss)
I0928 22:49:04.476816  5237 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I0928 22:49:18.350903  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:49:18.935237  5237 solver.cpp:330] Iteration 66500, Testing net (#0)
I0928 22:49:22.360554  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:49:22.503578  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8913
I0928 22:49:22.503614  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.396988 (* 1 = 0.396988 loss)
I0928 22:49:22.648346  5237 solver.cpp:218] Iteration 66500 (5.50313 iter/s, 18.1715s/100 iters), loss = 0.0293639
I0928 22:49:22.648376  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0293648 (* 1 = 0.0293648 loss)
I0928 22:49:22.648383  5237 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I0928 22:49:37.258749  5237 solver.cpp:218] Iteration 66600 (6.84447 iter/s, 14.6103s/100 iters), loss = 0.0563763
I0928 22:49:37.258787  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0563772 (* 1 = 0.0563772 loss)
I0928 22:49:37.258795  5237 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I0928 22:49:51.872046  5237 solver.cpp:218] Iteration 66700 (6.84312 iter/s, 14.6132s/100 iters), loss = 0.0633712
I0928 22:49:51.872171  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0633721 (* 1 = 0.0633721 loss)
I0928 22:49:51.872189  5237 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I0928 22:50:06.479696  5237 solver.cpp:218] Iteration 66800 (6.84581 iter/s, 14.6075s/100 iters), loss = 0.0405771
I0928 22:50:06.479724  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0405781 (* 1 = 0.0405781 loss)
I0928 22:50:06.479740  5237 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I0928 22:50:21.087167  5237 solver.cpp:218] Iteration 66900 (6.84585 iter/s, 14.6074s/100 iters), loss = 0.0479984
I0928 22:50:21.087198  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0479994 (* 1 = 0.0479994 loss)
I0928 22:50:21.087215  5237 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I0928 22:50:34.967312  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:50:35.551365  5237 solver.cpp:330] Iteration 67000, Testing net (#0)
I0928 22:50:38.975981  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:50:39.118362  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8885
I0928 22:50:39.118398  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.401713 (* 1 = 0.401713 loss)
I0928 22:50:39.263592  5237 solver.cpp:218] Iteration 67000 (5.50166 iter/s, 18.1763s/100 iters), loss = 0.0605027
I0928 22:50:39.263622  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0605037 (* 1 = 0.0605037 loss)
I0928 22:50:39.263628  5237 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I0928 22:50:53.859751  5237 solver.cpp:218] Iteration 67100 (6.85115 iter/s, 14.5961s/100 iters), loss = 0.0385646
I0928 22:50:53.859782  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0385656 (* 1 = 0.0385656 loss)
I0928 22:50:53.859788  5237 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I0928 22:51:08.466305  5237 solver.cpp:218] Iteration 67200 (6.84628 iter/s, 14.6065s/100 iters), loss = 0.0374393
I0928 22:51:08.466462  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0374402 (* 1 = 0.0374402 loss)
I0928 22:51:08.466480  5237 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I0928 22:51:23.070000  5237 solver.cpp:218] Iteration 67300 (6.84767 iter/s, 14.6035s/100 iters), loss = 0.0375009
I0928 22:51:23.070029  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0375018 (* 1 = 0.0375018 loss)
I0928 22:51:23.070034  5237 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I0928 22:51:37.680779  5237 solver.cpp:218] Iteration 67400 (6.8443 iter/s, 14.6107s/100 iters), loss = 0.0369822
I0928 22:51:37.680820  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0369832 (* 1 = 0.0369832 loss)
I0928 22:51:37.680826  5237 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I0928 22:51:51.557382  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:51:52.143841  5237 solver.cpp:330] Iteration 67500, Testing net (#0)
I0928 22:51:55.567342  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:51:55.710233  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8907
I0928 22:51:55.710268  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.39719 (* 1 = 0.39719 loss)
I0928 22:51:55.855370  5237 solver.cpp:218] Iteration 67500 (5.50221 iter/s, 18.1745s/100 iters), loss = 0.0504711
I0928 22:51:55.855401  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.050472 (* 1 = 0.050472 loss)
I0928 22:51:55.855407  5237 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I0928 22:52:10.453140  5237 solver.cpp:218] Iteration 67600 (6.8504 iter/s, 14.5977s/100 iters), loss = 0.11416
I0928 22:52:10.453181  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114161 (* 1 = 0.114161 loss)
I0928 22:52:10.453188  5237 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I0928 22:52:25.055768  5237 solver.cpp:218] Iteration 67700 (6.84812 iter/s, 14.6025s/100 iters), loss = 0.0185182
I0928 22:52:25.055861  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0185191 (* 1 = 0.0185191 loss)
I0928 22:52:25.055878  5237 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I0928 22:52:39.663360  5237 solver.cpp:218] Iteration 67800 (6.84582 iter/s, 14.6075s/100 iters), loss = 0.0202115
I0928 22:52:39.663399  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0202124 (* 1 = 0.0202124 loss)
I0928 22:52:39.663405  5237 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I0928 22:52:54.272526  5237 solver.cpp:218] Iteration 67900 (6.84506 iter/s, 14.6091s/100 iters), loss = 0.0532163
I0928 22:52:54.272554  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0532172 (* 1 = 0.0532172 loss)
I0928 22:52:54.272560  5237 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I0928 22:53:08.149513  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:53:08.734357  5237 solver.cpp:330] Iteration 68000, Testing net (#0)
I0928 22:53:12.156121  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:53:12.299465  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8831
I0928 22:53:12.299501  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.439705 (* 1 = 0.439705 loss)
I0928 22:53:12.444849  5237 solver.cpp:218] Iteration 68000 (5.5029 iter/s, 18.1722s/100 iters), loss = 0.0708403
I0928 22:53:12.444878  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0708412 (* 1 = 0.0708412 loss)
I0928 22:53:12.444885  5237 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I0928 22:53:27.046417  5237 solver.cpp:218] Iteration 68100 (6.84861 iter/s, 14.6015s/100 iters), loss = 0.0106779
I0928 22:53:27.046449  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106788 (* 1 = 0.0106788 loss)
I0928 22:53:27.046456  5237 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I0928 22:53:41.644505  5237 solver.cpp:218] Iteration 68200 (6.85025 iter/s, 14.598s/100 iters), loss = 0.023622
I0928 22:53:41.644628  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0236229 (* 1 = 0.0236229 loss)
I0928 22:53:41.644636  5237 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I0928 22:53:56.248618  5237 solver.cpp:218] Iteration 68300 (6.84746 iter/s, 14.604s/100 iters), loss = 0.0422065
I0928 22:53:56.248659  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0422074 (* 1 = 0.0422074 loss)
I0928 22:53:56.248664  5237 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I0928 22:54:10.850621  5237 solver.cpp:218] Iteration 68400 (6.84841 iter/s, 14.6019s/100 iters), loss = 0.0493477
I0928 22:54:10.850661  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0493486 (* 1 = 0.0493486 loss)
I0928 22:54:10.850667  5237 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I0928 22:54:24.731812  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:54:25.316426  5237 solver.cpp:330] Iteration 68500, Testing net (#0)
I0928 22:54:28.741165  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:54:28.884176  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8847
I0928 22:54:28.884212  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.439318 (* 1 = 0.439318 loss)
I0928 22:54:29.030369  5237 solver.cpp:218] Iteration 68500 (5.50065 iter/s, 18.1797s/100 iters), loss = 0.032284
I0928 22:54:29.030400  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0322848 (* 1 = 0.0322848 loss)
I0928 22:54:29.030406  5237 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I0928 22:54:43.634052  5237 solver.cpp:218] Iteration 68600 (6.84762 iter/s, 14.6036s/100 iters), loss = 0.0525003
I0928 22:54:43.634081  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0525012 (* 1 = 0.0525012 loss)
I0928 22:54:43.634088  5237 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I0928 22:54:58.242172  5237 solver.cpp:218] Iteration 68700 (6.84554 iter/s, 14.608s/100 iters), loss = 0.0406574
I0928 22:54:58.242285  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0406583 (* 1 = 0.0406583 loss)
I0928 22:54:58.242291  5237 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I0928 22:55:12.853503  5237 solver.cpp:218] Iteration 68800 (6.84407 iter/s, 14.6112s/100 iters), loss = 0.0496793
I0928 22:55:12.853533  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0496802 (* 1 = 0.0496802 loss)
I0928 22:55:12.853538  5237 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I0928 22:55:27.459470  5237 solver.cpp:218] Iteration 68900 (6.84655 iter/s, 14.6059s/100 iters), loss = 0.0492023
I0928 22:55:27.459511  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0492032 (* 1 = 0.0492032 loss)
I0928 22:55:27.459517  5237 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I0928 22:55:41.335376  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:55:41.920701  5237 solver.cpp:330] Iteration 69000, Testing net (#0)
I0928 22:55:45.344949  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:55:45.488286  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8891
I0928 22:55:45.488312  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.425639 (* 1 = 0.425639 loss)
I0928 22:55:45.634311  5237 solver.cpp:218] Iteration 69000 (5.50214 iter/s, 18.1747s/100 iters), loss = 0.0711513
I0928 22:55:45.634341  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0711522 (* 1 = 0.0711522 loss)
I0928 22:55:45.634347  5237 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I0928 22:56:00.242847  5237 solver.cpp:218] Iteration 69100 (6.84535 iter/s, 14.6085s/100 iters), loss = 0.0948173
I0928 22:56:00.242879  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0948181 (* 1 = 0.0948181 loss)
I0928 22:56:00.242885  5237 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I0928 22:56:14.849930  5237 solver.cpp:218] Iteration 69200 (6.84603 iter/s, 14.607s/100 iters), loss = 0.102217
I0928 22:56:14.850078  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102218 (* 1 = 0.102218 loss)
I0928 22:56:14.850086  5237 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I0928 22:56:29.457737  5237 solver.cpp:218] Iteration 69300 (6.84574 iter/s, 14.6076s/100 iters), loss = 0.0851724
I0928 22:56:29.457767  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0851733 (* 1 = 0.0851733 loss)
I0928 22:56:29.457773  5237 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I0928 22:56:44.064275  5237 solver.cpp:218] Iteration 69400 (6.84628 iter/s, 14.6065s/100 iters), loss = 0.0267647
I0928 22:56:44.064303  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0267656 (* 1 = 0.0267656 loss)
I0928 22:56:44.064309  5237 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I0928 22:56:57.949403  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:56:58.535241  5237 solver.cpp:330] Iteration 69500, Testing net (#0)
I0928 22:57:01.958039  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:57:02.100790  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8885
I0928 22:57:02.100823  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.421733 (* 1 = 0.421733 loss)
I0928 22:57:02.246255  5237 solver.cpp:218] Iteration 69500 (5.49998 iter/s, 18.1819s/100 iters), loss = 0.0324523
I0928 22:57:02.246287  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0324532 (* 1 = 0.0324532 loss)
I0928 22:57:02.246294  5237 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I0928 22:57:16.842593  5237 solver.cpp:218] Iteration 69600 (6.85107 iter/s, 14.5963s/100 iters), loss = 0.0217076
I0928 22:57:16.842622  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0217084 (* 1 = 0.0217084 loss)
I0928 22:57:16.842628  5237 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I0928 22:57:31.443576  5237 solver.cpp:218] Iteration 69700 (6.84889 iter/s, 14.6009s/100 iters), loss = 0.0228386
I0928 22:57:31.443717  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0228394 (* 1 = 0.0228394 loss)
I0928 22:57:31.443724  5237 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I0928 22:57:46.052678  5237 solver.cpp:218] Iteration 69800 (6.84513 iter/s, 14.6089s/100 iters), loss = 0.0644881
I0928 22:57:46.052718  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0644889 (* 1 = 0.0644889 loss)
I0928 22:57:46.052724  5237 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I0928 22:58:00.656671  5237 solver.cpp:218] Iteration 69900 (6.84748 iter/s, 14.6039s/100 iters), loss = 0.050996
I0928 22:58:00.656700  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0509968 (* 1 = 0.0509968 loss)
I0928 22:58:00.656707  5237 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I0928 22:58:14.536586  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:58:15.120699  5237 solver.cpp:330] Iteration 70000, Testing net (#0)
I0928 22:58:18.545547  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:58:18.689010  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8926
I0928 22:58:18.689035  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.413195 (* 1 = 0.413195 loss)
I0928 22:58:18.834270  5237 solver.cpp:218] Iteration 70000 (5.5013 iter/s, 18.1775s/100 iters), loss = 0.0639224
I0928 22:58:18.834300  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0639232 (* 1 = 0.0639232 loss)
I0928 22:58:18.834306  5237 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I0928 22:58:33.426816  5237 solver.cpp:218] Iteration 70100 (6.85285 iter/s, 14.5925s/100 iters), loss = 0.0392495
I0928 22:58:33.426846  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0392503 (* 1 = 0.0392503 loss)
I0928 22:58:33.426851  5237 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I0928 22:58:48.025570  5237 solver.cpp:218] Iteration 70200 (6.84993 iter/s, 14.5987s/100 iters), loss = 0.0406093
I0928 22:58:48.025678  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0406101 (* 1 = 0.0406101 loss)
I0928 22:58:48.025696  5237 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I0928 22:59:02.626713  5237 solver.cpp:218] Iteration 70300 (6.84885 iter/s, 14.601s/100 iters), loss = 0.0642384
I0928 22:59:02.626744  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0642392 (* 1 = 0.0642392 loss)
I0928 22:59:02.626750  5237 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I0928 22:59:17.219825  5237 solver.cpp:218] Iteration 70400 (6.85258 iter/s, 14.593s/100 iters), loss = 0.0529746
I0928 22:59:17.219856  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0529754 (* 1 = 0.0529754 loss)
I0928 22:59:17.219863  5237 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I0928 22:59:31.096195  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:59:31.680832  5237 solver.cpp:330] Iteration 70500, Testing net (#0)
I0928 22:59:35.104504  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 22:59:35.247910  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8831
I0928 22:59:35.247943  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.458907 (* 1 = 0.458907 loss)
I0928 22:59:35.393385  5237 solver.cpp:218] Iteration 70500 (5.50252 iter/s, 18.1735s/100 iters), loss = 0.0167297
I0928 22:59:35.393414  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0167305 (* 1 = 0.0167305 loss)
I0928 22:59:35.393420  5237 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I0928 22:59:49.981587  5237 solver.cpp:218] Iteration 70600 (6.85489 iter/s, 14.5881s/100 iters), loss = 0.0505426
I0928 22:59:49.981616  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0505434 (* 1 = 0.0505434 loss)
I0928 22:59:49.981632  5237 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I0928 23:00:04.587987  5237 solver.cpp:218] Iteration 70700 (6.84635 iter/s, 14.6063s/100 iters), loss = 0.0538129
I0928 23:00:04.588126  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0538137 (* 1 = 0.0538137 loss)
I0928 23:00:04.588135  5237 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I0928 23:00:19.188956  5237 solver.cpp:218] Iteration 70800 (6.84894 iter/s, 14.6008s/100 iters), loss = 0.0721143
I0928 23:00:19.188987  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0721151 (* 1 = 0.0721151 loss)
I0928 23:00:19.189002  5237 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I0928 23:00:33.786346  5237 solver.cpp:218] Iteration 70900 (6.85057 iter/s, 14.5973s/100 iters), loss = 0.0229845
I0928 23:00:33.786376  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0229853 (* 1 = 0.0229853 loss)
I0928 23:00:33.786391  5237 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I0928 23:00:47.668699  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:00:48.254302  5237 solver.cpp:330] Iteration 71000, Testing net (#0)
I0928 23:00:51.675403  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:00:51.818090  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8717
I0928 23:00:51.818125  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.496684 (* 1 = 0.496684 loss)
I0928 23:00:51.963155  5237 solver.cpp:218] Iteration 71000 (5.50154 iter/s, 18.1767s/100 iters), loss = 0.0238451
I0928 23:00:51.963187  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0238459 (* 1 = 0.0238459 loss)
I0928 23:00:51.963194  5237 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I0928 23:01:06.572321  5237 solver.cpp:218] Iteration 71100 (6.84505 iter/s, 14.6091s/100 iters), loss = 0.0686952
I0928 23:01:06.572350  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.068696 (* 1 = 0.068696 loss)
I0928 23:01:06.572356  5237 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I0928 23:01:21.189471  5237 solver.cpp:218] Iteration 71200 (6.84131 iter/s, 14.6171s/100 iters), loss = 0.0196309
I0928 23:01:21.189643  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0196318 (* 1 = 0.0196318 loss)
I0928 23:01:21.189652  5237 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I0928 23:01:35.805481  5237 solver.cpp:218] Iteration 71300 (6.84191 iter/s, 14.6158s/100 iters), loss = 0.0314153
I0928 23:01:35.805510  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0314161 (* 1 = 0.0314161 loss)
I0928 23:01:35.805516  5237 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I0928 23:01:50.424942  5237 solver.cpp:218] Iteration 71400 (6.84023 iter/s, 14.6194s/100 iters), loss = 0.0434011
I0928 23:01:50.424974  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0434019 (* 1 = 0.0434019 loss)
I0928 23:01:50.424991  5237 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I0928 23:02:04.313099  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:02:04.899962  5237 solver.cpp:330] Iteration 71500, Testing net (#0)
I0928 23:02:08.324506  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:02:08.467293  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8931
I0928 23:02:08.467327  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.401488 (* 1 = 0.401488 loss)
I0928 23:02:08.612637  5237 solver.cpp:218] Iteration 71500 (5.49825 iter/s, 18.1876s/100 iters), loss = 0.0515493
I0928 23:02:08.612666  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0515502 (* 1 = 0.0515502 loss)
I0928 23:02:08.612673  5237 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I0928 23:02:23.222904  5237 solver.cpp:218] Iteration 71600 (6.84453 iter/s, 14.6102s/100 iters), loss = 0.0244539
I0928 23:02:23.222934  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0244547 (* 1 = 0.0244547 loss)
I0928 23:02:23.222939  5237 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I0928 23:02:37.835919  5237 solver.cpp:218] Iteration 71700 (6.84325 iter/s, 14.6129s/100 iters), loss = 0.018411
I0928 23:02:37.836046  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0184118 (* 1 = 0.0184118 loss)
I0928 23:02:37.836053  5237 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I0928 23:02:52.445006  5237 solver.cpp:218] Iteration 71800 (6.84513 iter/s, 14.6089s/100 iters), loss = 0.023246
I0928 23:02:52.445041  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0232469 (* 1 = 0.0232469 loss)
I0928 23:02:52.445049  5237 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I0928 23:03:07.053198  5237 solver.cpp:218] Iteration 71900 (6.84551 iter/s, 14.6081s/100 iters), loss = 0.0270915
I0928 23:03:07.053231  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0270924 (* 1 = 0.0270924 loss)
I0928 23:03:07.053236  5237 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I0928 23:03:20.935672  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:03:21.519820  5237 solver.cpp:330] Iteration 72000, Testing net (#0)
I0928 23:03:24.942309  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:03:25.085511  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8863
I0928 23:03:25.085546  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.423427 (* 1 = 0.423427 loss)
I0928 23:03:25.231256  5237 solver.cpp:218] Iteration 72000 (5.50116 iter/s, 18.178s/100 iters), loss = 0.0238353
I0928 23:03:25.231287  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0238362 (* 1 = 0.0238362 loss)
I0928 23:03:25.231293  5237 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I0928 23:03:39.828907  5237 solver.cpp:218] Iteration 72100 (6.85045 iter/s, 14.5976s/100 iters), loss = 0.068068
I0928 23:03:39.828936  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0680688 (* 1 = 0.0680688 loss)
I0928 23:03:39.828941  5237 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I0928 23:03:54.422535  5237 solver.cpp:218] Iteration 72200 (6.85234 iter/s, 14.5936s/100 iters), loss = 0.0245726
I0928 23:03:54.422664  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0245735 (* 1 = 0.0245735 loss)
I0928 23:03:54.422672  5237 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I0928 23:04:09.023838  5237 solver.cpp:218] Iteration 72300 (6.84878 iter/s, 14.6011s/100 iters), loss = 0.0678838
I0928 23:04:09.023870  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0678846 (* 1 = 0.0678846 loss)
I0928 23:04:09.023877  5237 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I0928 23:04:23.625957  5237 solver.cpp:218] Iteration 72400 (6.84835 iter/s, 14.602s/100 iters), loss = 0.0250156
I0928 23:04:23.625986  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0250164 (* 1 = 0.0250164 loss)
I0928 23:04:23.625991  5237 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I0928 23:04:37.499601  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:04:38.086552  5237 solver.cpp:330] Iteration 72500, Testing net (#0)
I0928 23:04:41.510202  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:04:41.653754  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8898
I0928 23:04:41.653789  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.41475 (* 1 = 0.41475 loss)
I0928 23:04:41.798341  5237 solver.cpp:218] Iteration 72500 (5.50288 iter/s, 18.1723s/100 iters), loss = 0.043636
I0928 23:04:41.798369  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0436369 (* 1 = 0.0436369 loss)
I0928 23:04:41.798377  5237 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I0928 23:04:56.395437  5237 solver.cpp:218] Iteration 72600 (6.85071 iter/s, 14.597s/100 iters), loss = 0.0291927
I0928 23:04:56.395465  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0291935 (* 1 = 0.0291935 loss)
I0928 23:04:56.395472  5237 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I0928 23:05:11.004639  5237 solver.cpp:218] Iteration 72700 (6.84503 iter/s, 14.6091s/100 iters), loss = 0.0748091
I0928 23:05:11.004739  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0748099 (* 1 = 0.0748099 loss)
I0928 23:05:11.004762  5237 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I0928 23:05:25.606386  5237 solver.cpp:218] Iteration 72800 (6.84856 iter/s, 14.6016s/100 iters), loss = 0.0309859
I0928 23:05:25.606428  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0309866 (* 1 = 0.0309866 loss)
I0928 23:05:25.606436  5237 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I0928 23:05:40.208698  5237 solver.cpp:218] Iteration 72900 (6.84827 iter/s, 14.6022s/100 iters), loss = 0.0160383
I0928 23:05:40.208737  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.016039 (* 1 = 0.016039 loss)
I0928 23:05:40.208744  5237 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I0928 23:05:54.087613  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:05:54.672696  5237 solver.cpp:330] Iteration 73000, Testing net (#0)
I0928 23:05:58.097808  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:05:58.242008  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8847
I0928 23:05:58.242034  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.43124 (* 1 = 0.43124 loss)
I0928 23:05:58.387603  5237 solver.cpp:218] Iteration 73000 (5.50091 iter/s, 18.1788s/100 iters), loss = 0.0318006
I0928 23:05:58.387637  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0318013 (* 1 = 0.0318013 loss)
I0928 23:05:58.387645  5237 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I0928 23:06:13.004458  5237 solver.cpp:218] Iteration 73100 (6.84145 iter/s, 14.6168s/100 iters), loss = 0.0451141
I0928 23:06:13.004488  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0451149 (* 1 = 0.0451149 loss)
I0928 23:06:13.004494  5237 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I0928 23:06:27.621824  5237 solver.cpp:218] Iteration 73200 (6.84121 iter/s, 14.6173s/100 iters), loss = 0.0477761
I0928 23:06:27.621942  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0477768 (* 1 = 0.0477768 loss)
I0928 23:06:27.621959  5237 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I0928 23:06:42.243644  5237 solver.cpp:218] Iteration 73300 (6.83916 iter/s, 14.6217s/100 iters), loss = 0.0364627
I0928 23:06:42.243685  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0364634 (* 1 = 0.0364634 loss)
I0928 23:06:42.243690  5237 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I0928 23:06:56.860327  5237 solver.cpp:218] Iteration 73400 (6.84153 iter/s, 14.6166s/100 iters), loss = 0.0351226
I0928 23:06:56.860357  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0351233 (* 1 = 0.0351233 loss)
I0928 23:06:56.860363  5237 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I0928 23:07:10.751282  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:07:11.336830  5237 solver.cpp:330] Iteration 73500, Testing net (#0)
I0928 23:07:14.761685  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:07:14.905139  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8849
I0928 23:07:14.905175  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.444638 (* 1 = 0.444638 loss)
I0928 23:07:15.050101  5237 solver.cpp:218] Iteration 73500 (5.49762 iter/s, 18.1897s/100 iters), loss = 0.0461055
I0928 23:07:15.050133  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0461062 (* 1 = 0.0461062 loss)
I0928 23:07:15.050140  5237 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I0928 23:07:29.655246  5237 solver.cpp:218] Iteration 73600 (6.84694 iter/s, 14.6051s/100 iters), loss = 0.018806
I0928 23:07:29.655275  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0188066 (* 1 = 0.0188066 loss)
I0928 23:07:29.655282  5237 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I0928 23:07:44.261427  5237 solver.cpp:218] Iteration 73700 (6.84645 iter/s, 14.6061s/100 iters), loss = 0.105361
I0928 23:07:44.261538  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.105362 (* 1 = 0.105362 loss)
I0928 23:07:44.261545  5237 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I0928 23:07:58.870218  5237 solver.cpp:218] Iteration 73800 (6.84526 iter/s, 14.6087s/100 iters), loss = 0.0408419
I0928 23:07:58.870247  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0408426 (* 1 = 0.0408426 loss)
I0928 23:07:58.870252  5237 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I0928 23:08:13.475955  5237 solver.cpp:218] Iteration 73900 (6.84666 iter/s, 14.6057s/100 iters), loss = 0.0285758
I0928 23:08:13.475987  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0285765 (* 1 = 0.0285765 loss)
I0928 23:08:13.475993  5237 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I0928 23:08:27.360188  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:08:27.945231  5237 solver.cpp:330] Iteration 74000, Testing net (#0)
I0928 23:08:31.371019  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:08:31.514775  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8867
I0928 23:08:31.514802  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.431628 (* 1 = 0.431628 loss)
I0928 23:08:31.660426  5237 solver.cpp:218] Iteration 74000 (5.49922 iter/s, 18.1844s/100 iters), loss = 0.0180331
I0928 23:08:31.660456  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0180337 (* 1 = 0.0180337 loss)
I0928 23:08:31.660464  5237 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I0928 23:08:46.253535  5237 solver.cpp:218] Iteration 74100 (6.85258 iter/s, 14.593s/100 iters), loss = 0.0215951
I0928 23:08:46.253563  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0215958 (* 1 = 0.0215958 loss)
I0928 23:08:46.253568  5237 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I0928 23:09:00.861984  5237 solver.cpp:218] Iteration 74200 (6.84539 iter/s, 14.6084s/100 iters), loss = 0.0174474
I0928 23:09:00.862110  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0174481 (* 1 = 0.0174481 loss)
I0928 23:09:00.862118  5237 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I0928 23:09:15.466683  5237 solver.cpp:218] Iteration 74300 (6.84719 iter/s, 14.6045s/100 iters), loss = 0.0523107
I0928 23:09:15.466712  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0523114 (* 1 = 0.0523114 loss)
I0928 23:09:15.466717  5237 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I0928 23:09:30.067945  5237 solver.cpp:218] Iteration 74400 (6.84876 iter/s, 14.6012s/100 iters), loss = 0.029179
I0928 23:09:30.067976  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0291796 (* 1 = 0.0291796 loss)
I0928 23:09:30.067983  5237 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I0928 23:09:43.944183  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:09:44.528666  5237 solver.cpp:330] Iteration 74500, Testing net (#0)
I0928 23:09:47.954069  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:09:48.097404  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8877
I0928 23:09:48.097430  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.440139 (* 1 = 0.440139 loss)
I0928 23:09:48.242744  5237 solver.cpp:218] Iteration 74500 (5.50215 iter/s, 18.1747s/100 iters), loss = 0.0669645
I0928 23:09:48.242775  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0669651 (* 1 = 0.0669651 loss)
I0928 23:09:48.242781  5237 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I0928 23:10:02.842032  5237 solver.cpp:218] Iteration 74600 (6.84968 iter/s, 14.5992s/100 iters), loss = 0.0720264
I0928 23:10:02.842061  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.072027 (* 1 = 0.072027 loss)
I0928 23:10:02.842067  5237 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I0928 23:10:17.450095  5237 solver.cpp:218] Iteration 74700 (6.84557 iter/s, 14.608s/100 iters), loss = 0.0315343
I0928 23:10:17.450217  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.031535 (* 1 = 0.031535 loss)
I0928 23:10:17.450227  5237 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I0928 23:10:32.054256  5237 solver.cpp:218] Iteration 74800 (6.84744 iter/s, 14.604s/100 iters), loss = 0.0519784
I0928 23:10:32.054285  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0519791 (* 1 = 0.0519791 loss)
I0928 23:10:32.054291  5237 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I0928 23:10:46.663609  5237 solver.cpp:218] Iteration 74900 (6.84496 iter/s, 14.6093s/100 iters), loss = 0.0203777
I0928 23:10:46.663637  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0203784 (* 1 = 0.0203784 loss)
I0928 23:10:46.663643  5237 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I0928 23:11:00.541621  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:11:01.127034  5237 solver.cpp:330] Iteration 75000, Testing net (#0)
I0928 23:11:04.551261  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:11:04.694656  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8896
I0928 23:11:04.694692  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.427942 (* 1 = 0.427942 loss)
I0928 23:11:04.840158  5237 solver.cpp:218] Iteration 75000 (5.50162 iter/s, 18.1765s/100 iters), loss = 0.0206972
I0928 23:11:04.840186  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0206978 (* 1 = 0.0206978 loss)
I0928 23:11:04.840193  5237 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I0928 23:11:19.441830  5237 solver.cpp:218] Iteration 75100 (6.84856 iter/s, 14.6016s/100 iters), loss = 0.0759642
I0928 23:11:19.441872  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0759649 (* 1 = 0.0759649 loss)
I0928 23:11:19.441879  5237 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I0928 23:11:34.048014  5237 solver.cpp:218] Iteration 75200 (6.84645 iter/s, 14.6061s/100 iters), loss = 0.0241241
I0928 23:11:34.048141  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0241248 (* 1 = 0.0241248 loss)
I0928 23:11:34.048148  5237 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I0928 23:11:48.651047  5237 solver.cpp:218] Iteration 75300 (6.84797 iter/s, 14.6029s/100 iters), loss = 0.0840829
I0928 23:11:48.651077  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0840836 (* 1 = 0.0840836 loss)
I0928 23:11:48.651082  5237 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I0928 23:12:03.255810  5237 solver.cpp:218] Iteration 75400 (6.84712 iter/s, 14.6047s/100 iters), loss = 0.041925
I0928 23:12:03.255839  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0419257 (* 1 = 0.0419257 loss)
I0928 23:12:03.255846  5237 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I0928 23:12:17.129940  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:12:17.714814  5237 solver.cpp:330] Iteration 75500, Testing net (#0)
I0928 23:12:21.138491  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:12:21.281658  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8948
I0928 23:12:21.281692  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.397134 (* 1 = 0.397134 loss)
I0928 23:12:21.427178  5237 solver.cpp:218] Iteration 75500 (5.50319 iter/s, 18.1713s/100 iters), loss = 0.0604526
I0928 23:12:21.427209  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0604533 (* 1 = 0.0604533 loss)
I0928 23:12:21.427215  5237 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I0928 23:12:36.047760  5237 solver.cpp:218] Iteration 75600 (6.83971 iter/s, 14.6205s/100 iters), loss = 0.0681477
I0928 23:12:36.047791  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0681484 (* 1 = 0.0681484 loss)
I0928 23:12:36.047796  5237 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I0928 23:12:50.669476  5237 solver.cpp:218] Iteration 75700 (6.83918 iter/s, 14.6216s/100 iters), loss = 0.0380648
I0928 23:12:50.669591  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0380655 (* 1 = 0.0380655 loss)
I0928 23:12:50.669598  5237 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I0928 23:13:05.290964  5237 solver.cpp:218] Iteration 75800 (6.83932 iter/s, 14.6213s/100 iters), loss = 0.0491404
I0928 23:13:05.290994  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0491411 (* 1 = 0.0491411 loss)
I0928 23:13:05.291000  5237 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I0928 23:13:19.916980  5237 solver.cpp:218] Iteration 75900 (6.83717 iter/s, 14.6259s/100 iters), loss = 0.100677
I0928 23:13:19.917022  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.100678 (* 1 = 0.100678 loss)
I0928 23:13:19.917028  5237 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I0928 23:13:33.809716  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:13:34.395345  5237 solver.cpp:330] Iteration 76000, Testing net (#0)
I0928 23:13:37.816002  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:13:37.959250  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8837
I0928 23:13:37.959285  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.423341 (* 1 = 0.423341 loss)
I0928 23:13:38.104866  5237 solver.cpp:218] Iteration 76000 (5.49819 iter/s, 18.1878s/100 iters), loss = 0.0222372
I0928 23:13:38.104897  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0222379 (* 1 = 0.0222379 loss)
I0928 23:13:38.104903  5237 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I0928 23:13:52.709725  5237 solver.cpp:218] Iteration 76100 (6.84707 iter/s, 14.6048s/100 iters), loss = 0.0138469
I0928 23:13:52.709755  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138476 (* 1 = 0.0138476 loss)
I0928 23:13:52.709761  5237 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I0928 23:14:07.317132  5237 solver.cpp:218] Iteration 76200 (6.84588 iter/s, 14.6073s/100 iters), loss = 0.0603465
I0928 23:14:07.317293  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0603472 (* 1 = 0.0603472 loss)
I0928 23:14:07.317312  5237 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I0928 23:14:21.927006  5237 solver.cpp:218] Iteration 76300 (6.84478 iter/s, 14.6097s/100 iters), loss = 0.0560895
I0928 23:14:21.927034  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0560902 (* 1 = 0.0560902 loss)
I0928 23:14:21.927050  5237 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I0928 23:14:36.530987  5237 solver.cpp:218] Iteration 76400 (6.84748 iter/s, 14.6039s/100 iters), loss = 0.0266595
I0928 23:14:36.531016  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0266602 (* 1 = 0.0266602 loss)
I0928 23:14:36.531023  5237 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I0928 23:14:50.408066  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:14:50.993696  5237 solver.cpp:330] Iteration 76500, Testing net (#0)
I0928 23:14:54.418100  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:14:54.561180  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8826
I0928 23:14:54.561214  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.442809 (* 1 = 0.442809 loss)
I0928 23:14:54.706418  5237 solver.cpp:218] Iteration 76500 (5.50196 iter/s, 18.1754s/100 iters), loss = 0.0148684
I0928 23:14:54.706447  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148691 (* 1 = 0.0148691 loss)
I0928 23:14:54.706454  5237 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I0928 23:15:09.310292  5237 solver.cpp:218] Iteration 76600 (6.84753 iter/s, 14.6038s/100 iters), loss = 0.0687253
I0928 23:15:09.310322  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0687261 (* 1 = 0.0687261 loss)
I0928 23:15:09.310328  5237 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I0928 23:15:23.909003  5237 solver.cpp:218] Iteration 76700 (6.84995 iter/s, 14.5986s/100 iters), loss = 0.0224125
I0928 23:15:23.909080  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0224132 (* 1 = 0.0224132 loss)
I0928 23:15:23.909086  5237 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I0928 23:15:38.518534  5237 solver.cpp:218] Iteration 76800 (6.8449 iter/s, 14.6094s/100 iters), loss = 0.0678717
I0928 23:15:38.518566  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0678724 (* 1 = 0.0678724 loss)
I0928 23:15:38.518573  5237 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I0928 23:15:53.124557  5237 solver.cpp:218] Iteration 76900 (6.84653 iter/s, 14.6059s/100 iters), loss = 0.0284852
I0928 23:15:53.124586  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0284859 (* 1 = 0.0284859 loss)
I0928 23:15:53.124593  5237 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I0928 23:16:07.015491  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:16:07.600574  5237 solver.cpp:330] Iteration 77000, Testing net (#0)
I0928 23:16:11.025439  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:16:11.168260  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.884
I0928 23:16:11.168285  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.431481 (* 1 = 0.431481 loss)
I0928 23:16:11.313911  5237 solver.cpp:218] Iteration 77000 (5.49775 iter/s, 18.1893s/100 iters), loss = 0.105152
I0928 23:16:11.313941  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.105153 (* 1 = 0.105153 loss)
I0928 23:16:11.313947  5237 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I0928 23:16:25.909308  5237 solver.cpp:218] Iteration 77100 (6.85151 iter/s, 14.5953s/100 iters), loss = 0.0436994
I0928 23:16:25.909348  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0437001 (* 1 = 0.0437001 loss)
I0928 23:16:25.909354  5237 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I0928 23:16:40.510083  5237 solver.cpp:218] Iteration 77200 (6.84899 iter/s, 14.6007s/100 iters), loss = 0.0465353
I0928 23:16:40.510206  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0465361 (* 1 = 0.0465361 loss)
I0928 23:16:40.510226  5237 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I0928 23:16:55.115783  5237 solver.cpp:218] Iteration 77300 (6.84672 iter/s, 14.6055s/100 iters), loss = 0.0579845
I0928 23:16:55.115814  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0579853 (* 1 = 0.0579853 loss)
I0928 23:16:55.115820  5237 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I0928 23:17:09.719491  5237 solver.cpp:218] Iteration 77400 (6.84761 iter/s, 14.6036s/100 iters), loss = 0.0535943
I0928 23:17:09.719530  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.053595 (* 1 = 0.053595 loss)
I0928 23:17:09.719537  5237 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I0928 23:17:23.599349  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:17:24.183954  5237 solver.cpp:330] Iteration 77500, Testing net (#0)
I0928 23:17:27.606384  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:17:27.749827  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8807
I0928 23:17:27.749852  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.46236 (* 1 = 0.46236 loss)
I0928 23:17:27.895436  5237 solver.cpp:218] Iteration 77500 (5.5018 iter/s, 18.1759s/100 iters), loss = 0.00826263
I0928 23:17:27.895479  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00826336 (* 1 = 0.00826336 loss)
I0928 23:17:27.895485  5237 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I0928 23:17:42.495177  5237 solver.cpp:218] Iteration 77600 (6.84948 iter/s, 14.5996s/100 iters), loss = 0.057562
I0928 23:17:42.495213  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0575627 (* 1 = 0.0575627 loss)
I0928 23:17:42.495223  5237 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I0928 23:17:57.100488  5237 solver.cpp:218] Iteration 77700 (6.84686 iter/s, 14.6052s/100 iters), loss = 0.133377
I0928 23:17:57.100625  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133378 (* 1 = 0.133378 loss)
I0928 23:17:57.100631  5237 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I0928 23:18:11.704164  5237 solver.cpp:218] Iteration 77800 (6.84767 iter/s, 14.6035s/100 iters), loss = 0.0956708
I0928 23:18:11.704195  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0956716 (* 1 = 0.0956716 loss)
I0928 23:18:11.704200  5237 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I0928 23:18:26.303373  5237 solver.cpp:218] Iteration 77900 (6.84972 iter/s, 14.5991s/100 iters), loss = 0.0314705
I0928 23:18:26.303403  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0314712 (* 1 = 0.0314712 loss)
I0928 23:18:26.303409  5237 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I0928 23:18:40.188488  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:18:40.771764  5237 solver.cpp:330] Iteration 78000, Testing net (#0)
I0928 23:18:44.193315  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:18:44.336815  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8813
I0928 23:18:44.336848  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.465871 (* 1 = 0.465871 loss)
I0928 23:18:44.482390  5237 solver.cpp:218] Iteration 78000 (5.50087 iter/s, 18.1789s/100 iters), loss = 0.0336255
I0928 23:18:44.482420  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0336262 (* 1 = 0.0336262 loss)
I0928 23:18:44.482427  5237 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I0928 23:18:59.099777  5237 solver.cpp:218] Iteration 78100 (6.8412 iter/s, 14.6173s/100 iters), loss = 0.0810102
I0928 23:18:59.099817  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.081011 (* 1 = 0.081011 loss)
I0928 23:18:59.099823  5237 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I0928 23:19:13.725054  5237 solver.cpp:218] Iteration 78200 (6.83752 iter/s, 14.6252s/100 iters), loss = 0.019997
I0928 23:19:13.725188  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0199978 (* 1 = 0.0199978 loss)
I0928 23:19:13.725196  5237 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I0928 23:19:28.350795  5237 solver.cpp:218] Iteration 78300 (6.83734 iter/s, 14.6256s/100 iters), loss = 0.0487444
I0928 23:19:28.350836  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0487451 (* 1 = 0.0487451 loss)
I0928 23:19:28.350841  5237 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I0928 23:19:42.971640  5237 solver.cpp:218] Iteration 78400 (6.83959 iter/s, 14.6208s/100 iters), loss = 0.0597858
I0928 23:19:42.971671  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0597866 (* 1 = 0.0597866 loss)
I0928 23:19:42.971678  5237 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I0928 23:19:56.872407  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:19:57.458330  5237 solver.cpp:330] Iteration 78500, Testing net (#0)
I0928 23:20:00.883261  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:20:01.026526  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8877
I0928 23:20:01.026561  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.429119 (* 1 = 0.429119 loss)
I0928 23:20:01.172164  5237 solver.cpp:218] Iteration 78500 (5.49437 iter/s, 18.2004s/100 iters), loss = 0.0140118
I0928 23:20:01.172195  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0140125 (* 1 = 0.0140125 loss)
I0928 23:20:01.172202  5237 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I0928 23:20:15.769228  5237 solver.cpp:218] Iteration 78600 (6.85073 iter/s, 14.597s/100 iters), loss = 0.0143395
I0928 23:20:15.769258  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143403 (* 1 = 0.0143403 loss)
I0928 23:20:15.769264  5237 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I0928 23:20:30.369560  5237 solver.cpp:218] Iteration 78700 (6.84919 iter/s, 14.6003s/100 iters), loss = 0.0156509
I0928 23:20:30.369678  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156517 (* 1 = 0.0156517 loss)
I0928 23:20:30.369685  5237 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I0928 23:20:44.970237  5237 solver.cpp:218] Iteration 78800 (6.84907 iter/s, 14.6005s/100 iters), loss = 0.0540735
I0928 23:20:44.970266  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0540742 (* 1 = 0.0540742 loss)
I0928 23:20:44.970273  5237 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I0928 23:20:59.575989  5237 solver.cpp:218] Iteration 78900 (6.84665 iter/s, 14.6057s/100 iters), loss = 0.0274096
I0928 23:20:59.576020  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0274104 (* 1 = 0.0274104 loss)
I0928 23:20:59.576027  5237 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I0928 23:21:13.459861  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:21:14.044486  5237 solver.cpp:330] Iteration 79000, Testing net (#0)
I0928 23:21:17.469821  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:21:17.613077  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8841
I0928 23:21:17.613111  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.446304 (* 1 = 0.446304 loss)
I0928 23:21:17.758731  5237 solver.cpp:218] Iteration 79000 (5.49974 iter/s, 18.1827s/100 iters), loss = 0.0447786
I0928 23:21:17.758761  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0447794 (* 1 = 0.0447794 loss)
I0928 23:21:17.758769  5237 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I0928 23:21:32.368469  5237 solver.cpp:218] Iteration 79100 (6.84478 iter/s, 14.6097s/100 iters), loss = 0.0882931
I0928 23:21:32.368511  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0882939 (* 1 = 0.0882939 loss)
I0928 23:21:32.368517  5237 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I0928 23:21:46.984591  5237 solver.cpp:218] Iteration 79200 (6.8418 iter/s, 14.616s/100 iters), loss = 0.0456591
I0928 23:21:46.984696  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0456598 (* 1 = 0.0456598 loss)
I0928 23:21:46.984704  5237 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I0928 23:22:01.600805  5237 solver.cpp:218] Iteration 79300 (6.84178 iter/s, 14.6161s/100 iters), loss = 0.0573779
I0928 23:22:01.600836  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0573787 (* 1 = 0.0573787 loss)
I0928 23:22:01.600843  5237 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I0928 23:22:16.217062  5237 solver.cpp:218] Iteration 79400 (6.84173 iter/s, 14.6162s/100 iters), loss = 0.0266508
I0928 23:22:16.217103  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0266516 (* 1 = 0.0266516 loss)
I0928 23:22:16.217109  5237 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I0928 23:22:30.111012  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:22:30.697679  5237 solver.cpp:330] Iteration 79500, Testing net (#0)
I0928 23:22:34.120692  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:22:34.263710  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8863
I0928 23:22:34.263746  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.425479 (* 1 = 0.425479 loss)
I0928 23:22:34.408944  5237 solver.cpp:218] Iteration 79500 (5.49698 iter/s, 18.1918s/100 iters), loss = 0.0384804
I0928 23:22:34.408978  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0384812 (* 1 = 0.0384812 loss)
I0928 23:22:34.408985  5237 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I0928 23:22:49.015996  5237 solver.cpp:218] Iteration 79600 (6.84604 iter/s, 14.607s/100 iters), loss = 0.00984094
I0928 23:22:49.016038  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00984175 (* 1 = 0.00984175 loss)
I0928 23:22:49.016044  5237 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I0928 23:23:03.618751  5237 solver.cpp:218] Iteration 79700 (6.84806 iter/s, 14.6027s/100 iters), loss = 0.047293
I0928 23:23:03.618891  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0472938 (* 1 = 0.0472938 loss)
I0928 23:23:03.618899  5237 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I0928 23:23:18.223466  5237 solver.cpp:218] Iteration 79800 (6.84718 iter/s, 14.6045s/100 iters), loss = 0.00963902
I0928 23:23:18.223507  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00963981 (* 1 = 0.00963981 loss)
I0928 23:23:18.223513  5237 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I0928 23:23:32.829195  5237 solver.cpp:218] Iteration 79900 (6.84667 iter/s, 14.6056s/100 iters), loss = 0.0166888
I0928 23:23:32.829234  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0166897 (* 1 = 0.0166897 loss)
I0928 23:23:32.829241  5237 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I0928 23:23:46.707398  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:23:47.291052  5237 solver.cpp:330] Iteration 80000, Testing net (#0)
I0928 23:23:50.718919  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:23:50.861943  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8903
I0928 23:23:50.861979  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.429762 (* 1 = 0.429762 loss)
I0928 23:23:51.006933  5237 solver.cpp:218] Iteration 80000 (5.50126 iter/s, 18.1776s/100 iters), loss = 0.017844
I0928 23:23:51.006968  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0178448 (* 1 = 0.0178448 loss)
I0928 23:23:51.006973  5237 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I0928 23:23:51.006976  5237 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I0928 23:24:05.604050  5237 solver.cpp:218] Iteration 80100 (6.8507 iter/s, 14.597s/100 iters), loss = 0.0453628
I0928 23:24:05.604092  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0453636 (* 1 = 0.0453636 loss)
I0928 23:24:05.604099  5237 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I0928 23:24:20.212702  5237 solver.cpp:218] Iteration 80200 (6.8453 iter/s, 14.6086s/100 iters), loss = 0.0414846
I0928 23:24:20.212783  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0414855 (* 1 = 0.0414855 loss)
I0928 23:24:20.212800  5237 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I0928 23:24:34.824714  5237 solver.cpp:218] Iteration 80300 (6.84374 iter/s, 14.6119s/100 iters), loss = 0.0111585
I0928 23:24:34.824744  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111592 (* 1 = 0.0111592 loss)
I0928 23:24:34.824750  5237 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I0928 23:24:49.437351  5237 solver.cpp:218] Iteration 80400 (6.84342 iter/s, 14.6126s/100 iters), loss = 0.0255714
I0928 23:24:49.437383  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0255722 (* 1 = 0.0255722 loss)
I0928 23:24:49.437389  5237 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I0928 23:25:03.323488  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:25:03.908351  5237 solver.cpp:330] Iteration 80500, Testing net (#0)
I0928 23:25:07.333806  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:25:07.477021  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9025
I0928 23:25:07.477057  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.36499 (* 1 = 0.36499 loss)
I0928 23:25:07.623152  5237 solver.cpp:218] Iteration 80500 (5.49882 iter/s, 18.1857s/100 iters), loss = 0.0119552
I0928 23:25:07.623184  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011956 (* 1 = 0.011956 loss)
I0928 23:25:07.623191  5237 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I0928 23:25:22.230715  5237 solver.cpp:218] Iteration 80600 (6.8458 iter/s, 14.6075s/100 iters), loss = 0.0197701
I0928 23:25:22.230744  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0197709 (* 1 = 0.0197709 loss)
I0928 23:25:22.230751  5237 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I0928 23:25:36.839381  5237 solver.cpp:218] Iteration 80700 (6.84528 iter/s, 14.6086s/100 iters), loss = 0.0264978
I0928 23:25:36.839510  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0264986 (* 1 = 0.0264986 loss)
I0928 23:25:36.839519  5237 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I0928 23:25:51.448984  5237 solver.cpp:218] Iteration 80800 (6.84489 iter/s, 14.6094s/100 iters), loss = 0.0188669
I0928 23:25:51.449013  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0188676 (* 1 = 0.0188676 loss)
I0928 23:25:51.449018  5237 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I0928 23:26:06.059676  5237 solver.cpp:218] Iteration 80900 (6.84433 iter/s, 14.6106s/100 iters), loss = 0.0167741
I0928 23:26:06.059706  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0167749 (* 1 = 0.0167749 loss)
I0928 23:26:06.059711  5237 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I0928 23:26:19.941555  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:26:20.528318  5237 solver.cpp:330] Iteration 81000, Testing net (#0)
I0928 23:26:23.952010  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:26:24.095384  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9034
I0928 23:26:24.095420  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.362387 (* 1 = 0.362387 loss)
I0928 23:26:24.240701  5237 solver.cpp:218] Iteration 81000 (5.50026 iter/s, 18.181s/100 iters), loss = 0.011458
I0928 23:26:24.240731  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114588 (* 1 = 0.0114588 loss)
I0928 23:26:24.240737  5237 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I0928 23:26:38.841701  5237 solver.cpp:218] Iteration 81100 (6.84888 iter/s, 14.6009s/100 iters), loss = 0.0368175
I0928 23:26:38.841730  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0368183 (* 1 = 0.0368183 loss)
I0928 23:26:38.841737  5237 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I0928 23:26:53.447099  5237 solver.cpp:218] Iteration 81200 (6.84682 iter/s, 14.6053s/100 iters), loss = 0.00640533
I0928 23:26:53.447212  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00640612 (* 1 = 0.00640612 loss)
I0928 23:26:53.447219  5237 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I0928 23:27:08.048079  5237 solver.cpp:218] Iteration 81300 (6.84892 iter/s, 14.6008s/100 iters), loss = 0.0389878
I0928 23:27:08.048110  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0389886 (* 1 = 0.0389886 loss)
I0928 23:27:08.048116  5237 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I0928 23:27:22.653827  5237 solver.cpp:218] Iteration 81400 (6.84665 iter/s, 14.6057s/100 iters), loss = 0.0147646
I0928 23:27:22.653858  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0147654 (* 1 = 0.0147654 loss)
I0928 23:27:22.653865  5237 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I0928 23:27:36.534862  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:27:37.118857  5237 solver.cpp:330] Iteration 81500, Testing net (#0)
I0928 23:27:40.541877  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:27:40.685082  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9046
I0928 23:27:40.685118  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.362018 (* 1 = 0.362018 loss)
I0928 23:27:40.830788  5237 solver.cpp:218] Iteration 81500 (5.50149 iter/s, 18.1769s/100 iters), loss = 0.0161464
I0928 23:27:40.830819  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0161472 (* 1 = 0.0161472 loss)
I0928 23:27:40.830826  5237 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I0928 23:27:55.431790  5237 solver.cpp:218] Iteration 81600 (6.84888 iter/s, 14.6009s/100 iters), loss = 0.0193873
I0928 23:27:55.431819  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0193881 (* 1 = 0.0193881 loss)
I0928 23:27:55.431825  5237 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I0928 23:28:10.034121  5237 solver.cpp:218] Iteration 81700 (6.84826 iter/s, 14.6023s/100 iters), loss = 0.014664
I0928 23:28:10.034248  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146649 (* 1 = 0.0146649 loss)
I0928 23:28:10.034267  5237 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I0928 23:28:24.645125  5237 solver.cpp:218] Iteration 81800 (6.84423 iter/s, 14.6108s/100 iters), loss = 0.0108984
I0928 23:28:24.645155  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108992 (* 1 = 0.0108992 loss)
I0928 23:28:24.645171  5237 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I0928 23:28:39.253120  5237 solver.cpp:218] Iteration 81900 (6.8456 iter/s, 14.6079s/100 iters), loss = 0.0131799
I0928 23:28:39.253150  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131807 (* 1 = 0.0131807 loss)
I0928 23:28:39.253166  5237 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I0928 23:28:53.143120  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:28:53.727128  5237 solver.cpp:330] Iteration 82000, Testing net (#0)
I0928 23:28:57.152403  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:28:57.295457  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.904
I0928 23:28:57.295498  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.36309 (* 1 = 0.36309 loss)
I0928 23:28:57.440846  5237 solver.cpp:218] Iteration 82000 (5.49824 iter/s, 18.1877s/100 iters), loss = 0.00351447
I0928 23:28:57.440876  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00351528 (* 1 = 0.00351528 loss)
I0928 23:28:57.440883  5237 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I0928 23:29:12.042815  5237 solver.cpp:218] Iteration 82100 (6.84842 iter/s, 14.6019s/100 iters), loss = 0.0379458
I0928 23:29:12.042856  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0379466 (* 1 = 0.0379466 loss)
I0928 23:29:12.042862  5237 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I0928 23:29:26.652138  5237 solver.cpp:218] Iteration 82200 (6.84498 iter/s, 14.6092s/100 iters), loss = 0.0309797
I0928 23:29:26.652271  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0309805 (* 1 = 0.0309805 loss)
I0928 23:29:26.652279  5237 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I0928 23:29:41.254016  5237 solver.cpp:218] Iteration 82300 (6.84851 iter/s, 14.6017s/100 iters), loss = 0.0063946
I0928 23:29:41.254046  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00639543 (* 1 = 0.00639543 loss)
I0928 23:29:41.254051  5237 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I0928 23:29:55.858644  5237 solver.cpp:218] Iteration 82400 (6.84718 iter/s, 14.6046s/100 iters), loss = 0.0170022
I0928 23:29:55.858675  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.017003 (* 1 = 0.017003 loss)
I0928 23:29:55.858680  5237 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I0928 23:30:09.736435  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:30:10.320283  5237 solver.cpp:330] Iteration 82500, Testing net (#0)
I0928 23:30:13.742383  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:30:13.885565  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9041
I0928 23:30:13.885601  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.362784 (* 1 = 0.362784 loss)
I0928 23:30:14.030880  5237 solver.cpp:218] Iteration 82500 (5.50292 iter/s, 18.1722s/100 iters), loss = 0.0104878
I0928 23:30:14.030912  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104886 (* 1 = 0.0104886 loss)
I0928 23:30:14.030920  5237 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I0928 23:30:28.632300  5237 solver.cpp:218] Iteration 82600 (6.84868 iter/s, 14.6013s/100 iters), loss = 0.0190641
I0928 23:30:28.632330  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.019065 (* 1 = 0.019065 loss)
I0928 23:30:28.632336  5237 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I0928 23:30:43.239140  5237 solver.cpp:218] Iteration 82700 (6.84614 iter/s, 14.6068s/100 iters), loss = 0.0165747
I0928 23:30:43.239253  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0165756 (* 1 = 0.0165756 loss)
I0928 23:30:43.239274  5237 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I0928 23:30:57.847688  5237 solver.cpp:218] Iteration 82800 (6.84537 iter/s, 14.6084s/100 iters), loss = 0.0654141
I0928 23:30:57.847717  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0654149 (* 1 = 0.0654149 loss)
I0928 23:30:57.847733  5237 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I0928 23:31:12.459442  5237 solver.cpp:218] Iteration 82900 (6.84384 iter/s, 14.6117s/100 iters), loss = 0.0137758
I0928 23:31:12.459472  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0137766 (* 1 = 0.0137766 loss)
I0928 23:31:12.459478  5237 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I0928 23:31:26.344116  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:31:26.929752  5237 solver.cpp:330] Iteration 83000, Testing net (#0)
I0928 23:31:30.351893  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:31:30.495014  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9039
I0928 23:31:30.495048  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364281 (* 1 = 0.364281 loss)
I0928 23:31:30.643261  5237 solver.cpp:218] Iteration 83000 (5.49942 iter/s, 18.1837s/100 iters), loss = 0.00621158
I0928 23:31:30.643291  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00621239 (* 1 = 0.00621239 loss)
I0928 23:31:30.643297  5237 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I0928 23:31:45.240094  5237 solver.cpp:218] Iteration 83100 (6.85083 iter/s, 14.5968s/100 iters), loss = 0.00937249
I0928 23:31:45.240134  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0093733 (* 1 = 0.0093733 loss)
I0928 23:31:45.240140  5237 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I0928 23:31:59.848253  5237 solver.cpp:218] Iteration 83200 (6.84552 iter/s, 14.6081s/100 iters), loss = 0.00700181
I0928 23:31:59.848351  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00700262 (* 1 = 0.00700262 loss)
I0928 23:31:59.848358  5237 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I0928 23:32:14.460041  5237 solver.cpp:218] Iteration 83300 (6.84385 iter/s, 14.6117s/100 iters), loss = 0.0148007
I0928 23:32:14.460073  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148016 (* 1 = 0.0148016 loss)
I0928 23:32:14.460079  5237 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I0928 23:32:29.062000  5237 solver.cpp:218] Iteration 83400 (6.84843 iter/s, 14.6019s/100 iters), loss = 0.00573464
I0928 23:32:29.062039  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00573546 (* 1 = 0.00573546 loss)
I0928 23:32:29.062046  5237 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I0928 23:32:42.942427  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:32:43.526423  5237 solver.cpp:330] Iteration 83500, Testing net (#0)
I0928 23:32:46.949378  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:32:47.091953  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9049
I0928 23:32:47.091976  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.362964 (* 1 = 0.362964 loss)
I0928 23:32:47.236627  5237 solver.cpp:218] Iteration 83500 (5.5022 iter/s, 18.1745s/100 iters), loss = 0.00443158
I0928 23:32:47.236657  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00443239 (* 1 = 0.00443239 loss)
I0928 23:32:47.236665  5237 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I0928 23:33:01.845257  5237 solver.cpp:218] Iteration 83600 (6.8453 iter/s, 14.6086s/100 iters), loss = 0.0182755
I0928 23:33:01.845286  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0182763 (* 1 = 0.0182763 loss)
I0928 23:33:01.845293  5237 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I0928 23:33:16.447677  5237 solver.cpp:218] Iteration 83700 (6.84821 iter/s, 14.6024s/100 iters), loss = 0.0137568
I0928 23:33:16.447818  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0137576 (* 1 = 0.0137576 loss)
I0928 23:33:16.447826  5237 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I0928 23:33:31.064210  5237 solver.cpp:218] Iteration 83800 (6.84165 iter/s, 14.6164s/100 iters), loss = 0.00783176
I0928 23:33:31.064240  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00783257 (* 1 = 0.00783257 loss)
I0928 23:33:31.064246  5237 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I0928 23:33:45.681128  5237 solver.cpp:218] Iteration 83900 (6.84142 iter/s, 14.6169s/100 iters), loss = 0.00767721
I0928 23:33:45.681167  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00767802 (* 1 = 0.00767802 loss)
I0928 23:33:45.681172  5237 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I0928 23:33:59.578333  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:34:00.164320  5237 solver.cpp:330] Iteration 84000, Testing net (#0)
I0928 23:34:03.591059  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:34:03.733564  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9059
I0928 23:34:03.733598  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.363203 (* 1 = 0.363203 loss)
I0928 23:34:03.879343  5237 solver.cpp:218] Iteration 84000 (5.49507 iter/s, 18.1981s/100 iters), loss = 0.00301026
I0928 23:34:03.879375  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00301108 (* 1 = 0.00301108 loss)
I0928 23:34:03.879382  5237 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I0928 23:34:18.484467  5237 solver.cpp:218] Iteration 84100 (6.84694 iter/s, 14.6051s/100 iters), loss = 0.00633241
I0928 23:34:18.484499  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00633324 (* 1 = 0.00633324 loss)
I0928 23:34:18.484505  5237 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I0928 23:34:33.087103  5237 solver.cpp:218] Iteration 84200 (6.84811 iter/s, 14.6026s/100 iters), loss = 0.0167249
I0928 23:34:33.087210  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0167257 (* 1 = 0.0167257 loss)
I0928 23:34:33.087229  5237 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I0928 23:34:47.695410  5237 solver.cpp:218] Iteration 84300 (6.84548 iter/s, 14.6082s/100 iters), loss = 0.0170517
I0928 23:34:47.695439  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0170525 (* 1 = 0.0170525 loss)
I0928 23:34:47.695446  5237 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I0928 23:35:02.304280  5237 solver.cpp:218] Iteration 84400 (6.84519 iter/s, 14.6088s/100 iters), loss = 0.0119474
I0928 23:35:02.304308  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0119482 (* 1 = 0.0119482 loss)
I0928 23:35:02.304314  5237 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I0928 23:35:16.185812  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:35:16.769384  5237 solver.cpp:330] Iteration 84500, Testing net (#0)
I0928 23:35:20.191332  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:35:20.334384  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9057
I0928 23:35:20.334409  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.359975 (* 1 = 0.359975 loss)
I0928 23:35:20.479488  5237 solver.cpp:218] Iteration 84500 (5.50202 iter/s, 18.1751s/100 iters), loss = 0.00462284
I0928 23:35:20.479522  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00462368 (* 1 = 0.00462368 loss)
I0928 23:35:20.479528  5237 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I0928 23:35:35.082366  5237 solver.cpp:218] Iteration 84600 (6.848 iter/s, 14.6028s/100 iters), loss = 0.00745778
I0928 23:35:35.082397  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00745863 (* 1 = 0.00745863 loss)
I0928 23:35:35.082403  5237 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I0928 23:35:49.680274  5237 solver.cpp:218] Iteration 84700 (6.85033 iter/s, 14.5978s/100 iters), loss = 0.0196718
I0928 23:35:49.680397  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0196727 (* 1 = 0.0196727 loss)
I0928 23:35:49.680404  5237 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I0928 23:36:04.284339  5237 solver.cpp:218] Iteration 84800 (6.84748 iter/s, 14.6039s/100 iters), loss = 0.0115329
I0928 23:36:04.284371  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115338 (* 1 = 0.0115338 loss)
I0928 23:36:04.284377  5237 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I0928 23:36:18.883221  5237 solver.cpp:218] Iteration 84900 (6.84987 iter/s, 14.5988s/100 iters), loss = 0.00573179
I0928 23:36:18.883250  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00573265 (* 1 = 0.00573265 loss)
I0928 23:36:18.883256  5237 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I0928 23:36:32.758142  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:36:33.343240  5237 solver.cpp:330] Iteration 85000, Testing net (#0)
I0928 23:36:36.768621  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:36:36.911895  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9052
I0928 23:36:36.911921  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.359311 (* 1 = 0.359311 loss)
I0928 23:36:37.057271  5237 solver.cpp:218] Iteration 85000 (5.50237 iter/s, 18.174s/100 iters), loss = 0.0056878
I0928 23:36:37.057302  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00568866 (* 1 = 0.00568866 loss)
I0928 23:36:37.057309  5237 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I0928 23:36:51.654932  5237 solver.cpp:218] Iteration 85100 (6.85044 iter/s, 14.5976s/100 iters), loss = 0.049935
I0928 23:36:51.654961  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0499359 (* 1 = 0.0499359 loss)
I0928 23:36:51.654968  5237 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I0928 23:37:06.259374  5237 solver.cpp:218] Iteration 85200 (6.84726 iter/s, 14.6044s/100 iters), loss = 0.0234178
I0928 23:37:06.259474  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0234187 (* 1 = 0.0234187 loss)
I0928 23:37:06.259490  5237 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I0928 23:37:20.858839  5237 solver.cpp:218] Iteration 85300 (6.84963 iter/s, 14.5993s/100 iters), loss = 0.00826951
I0928 23:37:20.858868  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00827037 (* 1 = 0.00827037 loss)
I0928 23:37:20.858885  5237 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I0928 23:37:35.463436  5237 solver.cpp:218] Iteration 85400 (6.84719 iter/s, 14.6045s/100 iters), loss = 0.00753158
I0928 23:37:35.463469  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00753244 (* 1 = 0.00753244 loss)
I0928 23:37:35.463475  5237 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I0928 23:37:49.349683  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:37:49.933362  5237 solver.cpp:330] Iteration 85500, Testing net (#0)
I0928 23:37:53.359858  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:37:53.502914  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9057
I0928 23:37:53.502949  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364708 (* 1 = 0.364708 loss)
I0928 23:37:53.648504  5237 solver.cpp:218] Iteration 85500 (5.49904 iter/s, 18.185s/100 iters), loss = 0.0040522
I0928 23:37:53.648535  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00405306 (* 1 = 0.00405306 loss)
I0928 23:37:53.648541  5237 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I0928 23:38:08.244360  5237 solver.cpp:218] Iteration 85600 (6.85129 iter/s, 14.5958s/100 iters), loss = 0.0133215
I0928 23:38:08.244390  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0133223 (* 1 = 0.0133223 loss)
I0928 23:38:08.244406  5237 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I0928 23:38:22.851760  5237 solver.cpp:218] Iteration 85700 (6.84588 iter/s, 14.6073s/100 iters), loss = 0.0202342
I0928 23:38:22.851866  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.020235 (* 1 = 0.020235 loss)
I0928 23:38:22.851873  5237 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I0928 23:38:37.455411  5237 solver.cpp:218] Iteration 85800 (6.84767 iter/s, 14.6035s/100 iters), loss = 0.0103013
I0928 23:38:37.455440  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103021 (* 1 = 0.0103021 loss)
I0928 23:38:37.455446  5237 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I0928 23:38:52.070547  5237 solver.cpp:218] Iteration 85900 (6.84225 iter/s, 14.6151s/100 iters), loss = 0.022554
I0928 23:38:52.070578  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0225548 (* 1 = 0.0225548 loss)
I0928 23:38:52.070585  5237 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I0928 23:39:05.954445  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:39:06.541328  5237 solver.cpp:330] Iteration 86000, Testing net (#0)
I0928 23:39:09.964449  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:39:10.107082  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9063
I0928 23:39:10.107117  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366719 (* 1 = 0.366719 loss)
I0928 23:39:10.252544  5237 solver.cpp:218] Iteration 86000 (5.49997 iter/s, 18.1819s/100 iters), loss = 0.00475559
I0928 23:39:10.252574  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00475645 (* 1 = 0.00475645 loss)
I0928 23:39:10.252581  5237 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I0928 23:39:24.858304  5237 solver.cpp:218] Iteration 86100 (6.84664 iter/s, 14.6057s/100 iters), loss = 0.0129948
I0928 23:39:24.858332  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0129956 (* 1 = 0.0129956 loss)
I0928 23:39:24.858337  5237 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I0928 23:39:39.461302  5237 solver.cpp:218] Iteration 86200 (6.84794 iter/s, 14.6029s/100 iters), loss = 0.053521
I0928 23:39:39.461408  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0535218 (* 1 = 0.0535218 loss)
I0928 23:39:39.461416  5237 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I0928 23:39:54.068982  5237 solver.cpp:218] Iteration 86300 (6.84578 iter/s, 14.6075s/100 iters), loss = 0.0119754
I0928 23:39:54.069022  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0119762 (* 1 = 0.0119762 loss)
I0928 23:39:54.069028  5237 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I0928 23:40:08.671178  5237 solver.cpp:218] Iteration 86400 (6.84832 iter/s, 14.6021s/100 iters), loss = 0.00415008
I0928 23:40:08.671208  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00415094 (* 1 = 0.00415094 loss)
I0928 23:40:08.671214  5237 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I0928 23:40:22.554849  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:40:23.139593  5237 solver.cpp:330] Iteration 86500, Testing net (#0)
I0928 23:40:26.564038  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:40:26.707458  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9064
I0928 23:40:26.707492  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367718 (* 1 = 0.367718 loss)
I0928 23:40:26.852603  5237 solver.cpp:218] Iteration 86500 (5.50014 iter/s, 18.1814s/100 iters), loss = 0.00932829
I0928 23:40:26.852632  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00932916 (* 1 = 0.00932916 loss)
I0928 23:40:26.852639  5237 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I0928 23:40:41.452908  5237 solver.cpp:218] Iteration 86600 (6.8492 iter/s, 14.6002s/100 iters), loss = 0.0231773
I0928 23:40:41.452942  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0231782 (* 1 = 0.0231782 loss)
I0928 23:40:41.452949  5237 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I0928 23:40:56.061111  5237 solver.cpp:218] Iteration 86700 (6.8455 iter/s, 14.6081s/100 iters), loss = 0.00962143
I0928 23:40:56.061185  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0096223 (* 1 = 0.0096223 loss)
I0928 23:40:56.061197  5237 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I0928 23:41:10.669411  5237 solver.cpp:218] Iteration 86800 (6.84547 iter/s, 14.6082s/100 iters), loss = 0.0264677
I0928 23:41:10.669441  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0264686 (* 1 = 0.0264686 loss)
I0928 23:41:10.669457  5237 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I0928 23:41:25.276306  5237 solver.cpp:218] Iteration 86900 (6.84611 iter/s, 14.6068s/100 iters), loss = 0.0044072
I0928 23:41:25.276335  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00440807 (* 1 = 0.00440807 loss)
I0928 23:41:25.276341  5237 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I0928 23:41:39.158644  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:41:39.743248  5237 solver.cpp:330] Iteration 87000, Testing net (#0)
I0928 23:41:43.168103  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:41:43.311208  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9057
I0928 23:41:43.311244  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369969 (* 1 = 0.369969 loss)
I0928 23:41:43.456176  5237 solver.cpp:218] Iteration 87000 (5.50061 iter/s, 18.1798s/100 iters), loss = 0.00387823
I0928 23:41:43.456207  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00387911 (* 1 = 0.00387911 loss)
I0928 23:41:43.456214  5237 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I0928 23:41:58.062458  5237 solver.cpp:218] Iteration 87100 (6.8464 iter/s, 14.6062s/100 iters), loss = 0.00769666
I0928 23:41:58.062489  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00769754 (* 1 = 0.00769754 loss)
I0928 23:41:58.062494  5237 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I0928 23:42:12.671588  5237 solver.cpp:218] Iteration 87200 (6.84507 iter/s, 14.6091s/100 iters), loss = 0.0136108
I0928 23:42:12.671697  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136117 (* 1 = 0.0136117 loss)
I0928 23:42:12.671715  5237 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I0928 23:42:27.276139  5237 solver.cpp:218] Iteration 87300 (6.84725 iter/s, 14.6044s/100 iters), loss = 0.00565204
I0928 23:42:27.276168  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00565292 (* 1 = 0.00565292 loss)
I0928 23:42:27.276175  5237 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I0928 23:42:41.886385  5237 solver.cpp:218] Iteration 87400 (6.84454 iter/s, 14.6102s/100 iters), loss = 0.00617624
I0928 23:42:41.886415  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00617712 (* 1 = 0.00617712 loss)
I0928 23:42:41.886432  5237 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I0928 23:42:55.762568  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:42:56.347822  5237 solver.cpp:330] Iteration 87500, Testing net (#0)
I0928 23:42:59.771097  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:42:59.914125  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9053
I0928 23:42:59.914160  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369539 (* 1 = 0.369539 loss)
I0928 23:43:00.059610  5237 solver.cpp:218] Iteration 87500 (5.50262 iter/s, 18.1732s/100 iters), loss = 0.00208155
I0928 23:43:00.059640  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00208243 (* 1 = 0.00208243 loss)
I0928 23:43:00.059648  5237 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I0928 23:43:14.663009  5237 solver.cpp:218] Iteration 87600 (6.84775 iter/s, 14.6033s/100 iters), loss = 0.0260927
I0928 23:43:14.663041  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0260936 (* 1 = 0.0260936 loss)
I0928 23:43:14.663048  5237 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I0928 23:43:29.273855  5237 solver.cpp:218] Iteration 87700 (6.84426 iter/s, 14.6108s/100 iters), loss = 0.0368447
I0928 23:43:29.273999  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0368455 (* 1 = 0.0368455 loss)
I0928 23:43:29.274008  5237 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I0928 23:43:43.894436  5237 solver.cpp:218] Iteration 87800 (6.83976 iter/s, 14.6204s/100 iters), loss = 0.00808019
I0928 23:43:43.894465  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00808107 (* 1 = 0.00808107 loss)
I0928 23:43:43.894471  5237 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I0928 23:43:58.507282  5237 solver.cpp:218] Iteration 87900 (6.84332 iter/s, 14.6128s/100 iters), loss = 0.0044297
I0928 23:43:58.507323  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00443057 (* 1 = 0.00443057 loss)
I0928 23:43:58.507328  5237 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I0928 23:44:12.385061  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:44:12.969852  5237 solver.cpp:330] Iteration 88000, Testing net (#0)
I0928 23:44:16.393110  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:44:16.536147  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9049
I0928 23:44:16.536171  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370911 (* 1 = 0.370911 loss)
I0928 23:44:16.681085  5237 solver.cpp:218] Iteration 88000 (5.50245 iter/s, 18.1737s/100 iters), loss = 0.0148025
I0928 23:44:16.681128  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148034 (* 1 = 0.0148034 loss)
I0928 23:44:16.681149  5237 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I0928 23:44:31.289319  5237 solver.cpp:218] Iteration 88100 (6.84557 iter/s, 14.608s/100 iters), loss = 0.0115265
I0928 23:44:31.289351  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115273 (* 1 = 0.0115273 loss)
I0928 23:44:31.289358  5237 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I0928 23:44:45.895799  5237 solver.cpp:218] Iteration 88200 (6.84631 iter/s, 14.6064s/100 iters), loss = 0.0156563
I0928 23:44:45.895927  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156572 (* 1 = 0.0156572 loss)
I0928 23:44:45.895934  5237 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I0928 23:45:00.508359  5237 solver.cpp:218] Iteration 88300 (6.8435 iter/s, 14.6124s/100 iters), loss = 0.0247318
I0928 23:45:00.508389  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0247327 (* 1 = 0.0247327 loss)
I0928 23:45:00.508395  5237 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I0928 23:45:15.115514  5237 solver.cpp:218] Iteration 88400 (6.84599 iter/s, 14.6071s/100 iters), loss = 0.0214526
I0928 23:45:15.115545  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0214534 (* 1 = 0.0214534 loss)
I0928 23:45:15.115551  5237 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I0928 23:45:28.993822  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:45:29.579118  5237 solver.cpp:330] Iteration 88500, Testing net (#0)
I0928 23:45:33.003479  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:45:33.146387  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9048
I0928 23:45:33.146414  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368612 (* 1 = 0.368612 loss)
I0928 23:45:33.292485  5237 solver.cpp:218] Iteration 88500 (5.50149 iter/s, 18.1769s/100 iters), loss = 0.00938652
I0928 23:45:33.292518  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00938736 (* 1 = 0.00938736 loss)
I0928 23:45:33.292526  5237 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I0928 23:45:47.894652  5237 solver.cpp:218] Iteration 88600 (6.84833 iter/s, 14.6021s/100 iters), loss = 0.00665704
I0928 23:45:47.894691  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00665787 (* 1 = 0.00665787 loss)
I0928 23:45:47.894697  5237 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I0928 23:46:02.497469  5237 solver.cpp:218] Iteration 88700 (6.84803 iter/s, 14.6027s/100 iters), loss = 0.00524249
I0928 23:46:02.497619  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00524332 (* 1 = 0.00524332 loss)
I0928 23:46:02.497628  5237 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I0928 23:46:17.102876  5237 solver.cpp:218] Iteration 88800 (6.84686 iter/s, 14.6052s/100 iters), loss = 0.00415855
I0928 23:46:17.102910  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00415939 (* 1 = 0.00415939 loss)
I0928 23:46:17.102916  5237 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I0928 23:46:31.706087  5237 solver.cpp:218] Iteration 88900 (6.84784 iter/s, 14.6031s/100 iters), loss = 0.0186735
I0928 23:46:31.706127  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0186743 (* 1 = 0.0186743 loss)
I0928 23:46:31.706133  5237 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I0928 23:46:45.584772  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:46:46.169163  5237 solver.cpp:330] Iteration 89000, Testing net (#0)
I0928 23:46:49.594034  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:46:49.737179  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9054
I0928 23:46:49.737205  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368065 (* 1 = 0.368065 loss)
I0928 23:46:49.882354  5237 solver.cpp:218] Iteration 89000 (5.5017 iter/s, 18.1762s/100 iters), loss = 0.0454026
I0928 23:46:49.882381  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0454034 (* 1 = 0.0454034 loss)
I0928 23:46:49.882388  5237 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I0928 23:47:04.479979  5237 solver.cpp:218] Iteration 89100 (6.85046 iter/s, 14.5976s/100 iters), loss = 0.0093554
I0928 23:47:04.480008  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00935623 (* 1 = 0.00935623 loss)
I0928 23:47:04.480015  5237 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I0928 23:47:19.090584  5237 solver.cpp:218] Iteration 89200 (6.84437 iter/s, 14.6105s/100 iters), loss = 0.0156507
I0928 23:47:19.090699  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156516 (* 1 = 0.0156516 loss)
I0928 23:47:19.090706  5237 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I0928 23:47:33.703099  5237 solver.cpp:218] Iteration 89300 (6.84352 iter/s, 14.6124s/100 iters), loss = 0.0121259
I0928 23:47:33.703127  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121267 (* 1 = 0.0121267 loss)
I0928 23:47:33.703132  5237 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I0928 23:47:48.306926  5237 solver.cpp:218] Iteration 89400 (6.84755 iter/s, 14.6038s/100 iters), loss = 0.00763497
I0928 23:47:48.306957  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0076358 (* 1 = 0.0076358 loss)
I0928 23:47:48.306962  5237 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I0928 23:48:02.190202  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:48:02.774363  5237 solver.cpp:330] Iteration 89500, Testing net (#0)
I0928 23:48:06.197968  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:48:06.341218  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9056
I0928 23:48:06.341243  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370246 (* 1 = 0.370246 loss)
I0928 23:48:06.486389  5237 solver.cpp:218] Iteration 89500 (5.50073 iter/s, 18.1794s/100 iters), loss = 0.0109276
I0928 23:48:06.486423  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109285 (* 1 = 0.0109285 loss)
I0928 23:48:06.486430  5237 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I0928 23:48:21.085587  5237 solver.cpp:218] Iteration 89600 (6.84972 iter/s, 14.5991s/100 iters), loss = 0.00620542
I0928 23:48:21.085618  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00620624 (* 1 = 0.00620624 loss)
I0928 23:48:21.085623  5237 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I0928 23:48:35.686553  5237 solver.cpp:218] Iteration 89700 (6.84889 iter/s, 14.6009s/100 iters), loss = 0.0221859
I0928 23:48:35.686652  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0221867 (* 1 = 0.0221867 loss)
I0928 23:48:35.686659  5237 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I0928 23:48:50.285174  5237 solver.cpp:218] Iteration 89800 (6.85002 iter/s, 14.5985s/100 iters), loss = 0.00267508
I0928 23:48:50.285203  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00267591 (* 1 = 0.00267591 loss)
I0928 23:48:50.285208  5237 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I0928 23:49:04.889657  5237 solver.cpp:218] Iteration 89900 (6.84724 iter/s, 14.6044s/100 iters), loss = 0.0073517
I0928 23:49:04.889686  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00735253 (* 1 = 0.00735253 loss)
I0928 23:49:04.889693  5237 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I0928 23:49:18.768721  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:49:19.354221  5237 solver.cpp:330] Iteration 90000, Testing net (#0)
I0928 23:49:22.774957  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:49:22.918161  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9052
I0928 23:49:22.918186  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370741 (* 1 = 0.370741 loss)
I0928 23:49:23.062947  5237 solver.cpp:218] Iteration 90000 (5.5026 iter/s, 18.1732s/100 iters), loss = 0.00707276
I0928 23:49:23.062976  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00707359 (* 1 = 0.00707359 loss)
I0928 23:49:23.062983  5237 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I0928 23:49:37.671528  5237 solver.cpp:218] Iteration 90100 (6.84532 iter/s, 14.6085s/100 iters), loss = 0.0193261
I0928 23:49:37.671560  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0193269 (* 1 = 0.0193269 loss)
I0928 23:49:37.671566  5237 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I0928 23:49:52.287158  5237 solver.cpp:218] Iteration 90200 (6.84202 iter/s, 14.6156s/100 iters), loss = 0.0119714
I0928 23:49:52.287258  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0119722 (* 1 = 0.0119722 loss)
I0928 23:49:52.287276  5237 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I0928 23:50:06.898533  5237 solver.cpp:218] Iteration 90300 (6.84405 iter/s, 14.6112s/100 iters), loss = 0.0164057
I0928 23:50:06.898564  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0164065 (* 1 = 0.0164065 loss)
I0928 23:50:06.898569  5237 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I0928 23:50:21.514344  5237 solver.cpp:218] Iteration 90400 (6.84194 iter/s, 14.6157s/100 iters), loss = 0.0314585
I0928 23:50:21.514387  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0314593 (* 1 = 0.0314593 loss)
I0928 23:50:21.514394  5237 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I0928 23:50:35.406431  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:50:35.991611  5237 solver.cpp:330] Iteration 90500, Testing net (#0)
I0928 23:50:39.416259  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:50:39.558603  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9061
I0928 23:50:39.558627  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372177 (* 1 = 0.372177 loss)
I0928 23:50:39.703058  5237 solver.cpp:218] Iteration 90500 (5.49794 iter/s, 18.1886s/100 iters), loss = 0.0078807
I0928 23:50:39.703088  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00788152 (* 1 = 0.00788152 loss)
I0928 23:50:39.703094  5237 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I0928 23:50:54.315457  5237 solver.cpp:218] Iteration 90600 (6.84353 iter/s, 14.6123s/100 iters), loss = 0.00367468
I0928 23:50:54.315497  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0036755 (* 1 = 0.0036755 loss)
I0928 23:50:54.315502  5237 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I0928 23:51:08.934823  5237 solver.cpp:218] Iteration 90700 (6.84028 iter/s, 14.6193s/100 iters), loss = 0.0100854
I0928 23:51:08.934937  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100863 (* 1 = 0.0100863 loss)
I0928 23:51:08.934953  5237 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I0928 23:51:23.549193  5237 solver.cpp:218] Iteration 90800 (6.84265 iter/s, 14.6142s/100 iters), loss = 0.030192
I0928 23:51:23.549235  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0301928 (* 1 = 0.0301928 loss)
I0928 23:51:23.549242  5237 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I0928 23:51:38.165573  5237 solver.cpp:218] Iteration 90900 (6.84167 iter/s, 14.6163s/100 iters), loss = 0.00374266
I0928 23:51:38.165614  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00374347 (* 1 = 0.00374347 loss)
I0928 23:51:38.165621  5237 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I0928 23:51:52.058111  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:51:52.644356  5237 solver.cpp:330] Iteration 91000, Testing net (#0)
I0928 23:51:56.067405  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:51:56.210685  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9051
I0928 23:51:56.210718  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373211 (* 1 = 0.373211 loss)
I0928 23:51:56.355841  5237 solver.cpp:218] Iteration 91000 (5.49747 iter/s, 18.1902s/100 iters), loss = 0.0227155
I0928 23:51:56.355870  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227163 (* 1 = 0.0227163 loss)
I0928 23:51:56.355877  5237 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I0928 23:52:10.968075  5237 solver.cpp:218] Iteration 91100 (6.84361 iter/s, 14.6122s/100 iters), loss = 0.00810888
I0928 23:52:10.968106  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00810969 (* 1 = 0.00810969 loss)
I0928 23:52:10.968111  5237 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I0928 23:52:25.584738  5237 solver.cpp:218] Iteration 91200 (6.84154 iter/s, 14.6166s/100 iters), loss = 0.0396782
I0928 23:52:25.584815  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.039679 (* 1 = 0.039679 loss)
I0928 23:52:25.584822  5237 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I0928 23:52:40.197944  5237 solver.cpp:218] Iteration 91300 (6.84318 iter/s, 14.6131s/100 iters), loss = 0.0078501
I0928 23:52:40.197985  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00785092 (* 1 = 0.00785092 loss)
I0928 23:52:40.197991  5237 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I0928 23:52:54.816531  5237 solver.cpp:218] Iteration 91400 (6.84064 iter/s, 14.6185s/100 iters), loss = 0.00523289
I0928 23:52:54.816562  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00523371 (* 1 = 0.00523371 loss)
I0928 23:52:54.816568  5237 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I0928 23:53:08.703438  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:53:09.289469  5237 solver.cpp:330] Iteration 91500, Testing net (#0)
I0928 23:53:12.712888  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:53:12.856187  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9061
I0928 23:53:12.856223  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370626 (* 1 = 0.370626 loss)
I0928 23:53:13.001600  5237 solver.cpp:218] Iteration 91500 (5.49904 iter/s, 18.185s/100 iters), loss = 0.0063301
I0928 23:53:13.001632  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00633091 (* 1 = 0.00633091 loss)
I0928 23:53:13.001639  5237 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I0928 23:53:27.608651  5237 solver.cpp:218] Iteration 91600 (6.84604 iter/s, 14.607s/100 iters), loss = 0.00324984
I0928 23:53:27.608683  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00325065 (* 1 = 0.00325065 loss)
I0928 23:53:27.608690  5237 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I0928 23:53:42.223068  5237 solver.cpp:218] Iteration 91700 (6.84259 iter/s, 14.6144s/100 iters), loss = 0.0255141
I0928 23:53:42.223184  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0255149 (* 1 = 0.0255149 loss)
I0928 23:53:42.223191  5237 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I0928 23:53:56.838513  5237 solver.cpp:218] Iteration 91800 (6.84214 iter/s, 14.6153s/100 iters), loss = 0.0183522
I0928 23:53:56.838546  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.018353 (* 1 = 0.018353 loss)
I0928 23:53:56.838551  5237 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I0928 23:54:11.457744  5237 solver.cpp:218] Iteration 91900 (6.84034 iter/s, 14.6192s/100 iters), loss = 0.00785712
I0928 23:54:11.457784  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00785792 (* 1 = 0.00785792 loss)
I0928 23:54:11.457790  5237 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I0928 23:54:25.350344  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:54:25.934360  5237 solver.cpp:330] Iteration 92000, Testing net (#0)
I0928 23:54:29.359113  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:54:29.501948  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9036
I0928 23:54:29.501973  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.375441 (* 1 = 0.375441 loss)
I0928 23:54:29.648120  5237 solver.cpp:218] Iteration 92000 (5.49744 iter/s, 18.1903s/100 iters), loss = 0.00738696
I0928 23:54:29.648152  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00738776 (* 1 = 0.00738776 loss)
I0928 23:54:29.648159  5237 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I0928 23:54:44.262012  5237 solver.cpp:218] Iteration 92100 (6.84283 iter/s, 14.6138s/100 iters), loss = 0.0217271
I0928 23:54:44.262053  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0217279 (* 1 = 0.0217279 loss)
I0928 23:54:44.262059  5237 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I0928 23:54:58.874356  5237 solver.cpp:218] Iteration 92200 (6.84356 iter/s, 14.6123s/100 iters), loss = 0.00796129
I0928 23:54:58.874461  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0079621 (* 1 = 0.0079621 loss)
I0928 23:54:58.874469  5237 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I0928 23:55:13.491237  5237 solver.cpp:218] Iteration 92300 (6.84147 iter/s, 14.6167s/100 iters), loss = 0.00405303
I0928 23:55:13.491281  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00405383 (* 1 = 0.00405383 loss)
I0928 23:55:13.491286  5237 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I0928 23:55:28.103989  5237 solver.cpp:218] Iteration 92400 (6.84337 iter/s, 14.6127s/100 iters), loss = 0.00475393
I0928 23:55:28.104028  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00475473 (* 1 = 0.00475473 loss)
I0928 23:55:28.104034  5237 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I0928 23:55:41.987560  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:55:42.572839  5237 solver.cpp:330] Iteration 92500, Testing net (#0)
I0928 23:55:45.998930  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:55:46.141330  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9053
I0928 23:55:46.141364  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372479 (* 1 = 0.372479 loss)
I0928 23:55:46.287039  5237 solver.cpp:218] Iteration 92500 (5.49965 iter/s, 18.183s/100 iters), loss = 0.00767769
I0928 23:55:46.287072  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00767849 (* 1 = 0.00767849 loss)
I0928 23:55:46.287078  5237 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I0928 23:56:00.884042  5237 solver.cpp:218] Iteration 92600 (6.85075 iter/s, 14.5969s/100 iters), loss = 0.0063876
I0928 23:56:00.884071  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00638841 (* 1 = 0.00638841 loss)
I0928 23:56:00.884076  5237 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I0928 23:56:15.484980  5237 solver.cpp:218] Iteration 92700 (6.8489 iter/s, 14.6009s/100 iters), loss = 0.00692555
I0928 23:56:15.485119  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00692636 (* 1 = 0.00692636 loss)
I0928 23:56:15.485126  5237 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I0928 23:56:30.089736  5237 solver.cpp:218] Iteration 92800 (6.84716 iter/s, 14.6046s/100 iters), loss = 0.0117654
I0928 23:56:30.089772  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117662 (* 1 = 0.0117662 loss)
I0928 23:56:30.089779  5237 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I0928 23:56:44.694777  5237 solver.cpp:218] Iteration 92900 (6.84698 iter/s, 14.605s/100 iters), loss = 0.0151506
I0928 23:56:44.694808  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0151514 (* 1 = 0.0151514 loss)
I0928 23:56:44.694813  5237 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I0928 23:56:58.570269  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:56:59.154984  5237 solver.cpp:330] Iteration 93000, Testing net (#0)
I0928 23:57:02.580855  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:57:02.723620  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9057
I0928 23:57:02.723655  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37362 (* 1 = 0.37362 loss)
I0928 23:57:02.869468  5237 solver.cpp:218] Iteration 93000 (5.50218 iter/s, 18.1746s/100 iters), loss = 0.00406454
I0928 23:57:02.869498  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00406533 (* 1 = 0.00406533 loss)
I0928 23:57:02.869505  5237 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I0928 23:57:17.476022  5237 solver.cpp:218] Iteration 93100 (6.84627 iter/s, 14.6065s/100 iters), loss = 0.00424171
I0928 23:57:17.476063  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0042425 (* 1 = 0.0042425 loss)
I0928 23:57:17.476069  5237 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I0928 23:57:32.086542  5237 solver.cpp:218] Iteration 93200 (6.84442 iter/s, 14.6104s/100 iters), loss = 0.0233559
I0928 23:57:32.086650  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0233567 (* 1 = 0.0233567 loss)
I0928 23:57:32.086658  5237 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I0928 23:57:46.694386  5237 solver.cpp:218] Iteration 93300 (6.8457 iter/s, 14.6077s/100 iters), loss = 0.00514118
I0928 23:57:46.694416  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00514198 (* 1 = 0.00514198 loss)
I0928 23:57:46.694422  5237 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I0928 23:58:01.299707  5237 solver.cpp:218] Iteration 93400 (6.84685 iter/s, 14.6053s/100 iters), loss = 0.00295613
I0928 23:58:01.299738  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00295693 (* 1 = 0.00295693 loss)
I0928 23:58:01.299744  5237 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I0928 23:58:15.186298  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:58:15.772373  5237 solver.cpp:330] Iteration 93500, Testing net (#0)
I0928 23:58:19.196532  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:58:19.339860  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9045
I0928 23:58:19.339895  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372603 (* 1 = 0.372603 loss)
I0928 23:58:19.485589  5237 solver.cpp:218] Iteration 93500 (5.49879 iter/s, 18.1858s/100 iters), loss = 0.00652999
I0928 23:58:19.485620  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00653079 (* 1 = 0.00653079 loss)
I0928 23:58:19.485627  5237 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I0928 23:58:34.084813  5237 solver.cpp:218] Iteration 93600 (6.84971 iter/s, 14.5992s/100 iters), loss = 0.0135119
I0928 23:58:34.084853  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0135127 (* 1 = 0.0135127 loss)
I0928 23:58:34.084859  5237 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I0928 23:58:48.685689  5237 solver.cpp:218] Iteration 93700 (6.84894 iter/s, 14.6008s/100 iters), loss = 0.00445473
I0928 23:58:48.685829  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00445553 (* 1 = 0.00445553 loss)
I0928 23:58:48.685837  5237 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I0928 23:59:03.286962  5237 solver.cpp:218] Iteration 93800 (6.8488 iter/s, 14.6011s/100 iters), loss = 0.0047806
I0928 23:59:03.287001  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0047814 (* 1 = 0.0047814 loss)
I0928 23:59:03.287008  5237 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I0928 23:59:17.887208  5237 solver.cpp:218] Iteration 93900 (6.84923 iter/s, 14.6002s/100 iters), loss = 0.0116103
I0928 23:59:17.887239  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116111 (* 1 = 0.0116111 loss)
I0928 23:59:17.887246  5237 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I0928 23:59:31.767341  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:59:32.351626  5237 solver.cpp:330] Iteration 94000, Testing net (#0)
I0928 23:59:35.775205  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0928 23:59:35.918249  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9054
I0928 23:59:35.918274  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.375043 (* 1 = 0.375043 loss)
I0928 23:59:36.063419  5237 solver.cpp:218] Iteration 94000 (5.50172 iter/s, 18.1761s/100 iters), loss = 0.00585559
I0928 23:59:36.063450  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00585639 (* 1 = 0.00585639 loss)
I0928 23:59:36.063457  5237 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I0928 23:59:50.663405  5237 solver.cpp:218] Iteration 94100 (6.84935 iter/s, 14.5999s/100 iters), loss = 0.00465476
I0928 23:59:50.663435  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00465557 (* 1 = 0.00465557 loss)
I0928 23:59:50.663440  5237 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I0929 00:00:05.275774  5237 solver.cpp:218] Iteration 94200 (6.84355 iter/s, 14.6123s/100 iters), loss = 0.00425752
I0929 00:00:05.275914  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00425831 (* 1 = 0.00425831 loss)
I0929 00:00:05.275925  5237 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I0929 00:00:19.874797  5237 solver.cpp:218] Iteration 94300 (6.84985 iter/s, 14.5989s/100 iters), loss = 0.00278138
I0929 00:00:19.874826  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00278217 (* 1 = 0.00278217 loss)
I0929 00:00:19.874832  5237 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I0929 00:00:34.475324  5237 solver.cpp:218] Iteration 94400 (6.8491 iter/s, 14.6005s/100 iters), loss = 0.00276194
I0929 00:00:34.475358  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00276272 (* 1 = 0.00276272 loss)
I0929 00:00:34.475363  5237 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I0929 00:00:48.349936  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0929 00:00:48.933895  5237 solver.cpp:330] Iteration 94500, Testing net (#0)
I0929 00:00:52.356004  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0929 00:00:52.498489  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9056
I0929 00:00:52.498528  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.375196 (* 1 = 0.375196 loss)
I0929 00:00:52.643376  5237 solver.cpp:218] Iteration 94500 (5.50419 iter/s, 18.168s/100 iters), loss = 0.0176221
I0929 00:00:52.643407  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176229 (* 1 = 0.0176229 loss)
I0929 00:00:52.643414  5237 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I0929 00:01:07.249358  5237 solver.cpp:218] Iteration 94600 (6.84654 iter/s, 14.6059s/100 iters), loss = 0.0110575
I0929 00:01:07.249392  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110583 (* 1 = 0.0110583 loss)
I0929 00:01:07.249398  5237 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I0929 00:01:21.855031  5237 solver.cpp:218] Iteration 94700 (6.84669 iter/s, 14.6056s/100 iters), loss = 0.00754726
I0929 00:01:21.855137  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00754803 (* 1 = 0.00754803 loss)
I0929 00:01:21.855144  5237 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I0929 00:01:36.460860  5237 solver.cpp:218] Iteration 94800 (6.84665 iter/s, 14.6057s/100 iters), loss = 0.00486547
I0929 00:01:36.460899  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00486623 (* 1 = 0.00486623 loss)
I0929 00:01:36.460904  5237 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I0929 00:01:51.063997  5237 solver.cpp:218] Iteration 94900 (6.84788 iter/s, 14.6031s/100 iters), loss = 0.00375188
I0929 00:01:51.064055  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00375265 (* 1 = 0.00375265 loss)
I0929 00:01:51.064074  5237 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I0929 00:02:04.946456  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0929 00:02:05.531661  5237 solver.cpp:330] Iteration 95000, Testing net (#0)
I0929 00:02:08.957948  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0929 00:02:09.100316  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9049
I0929 00:02:09.100350  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37548 (* 1 = 0.37548 loss)
I0929 00:02:09.245934  5237 solver.cpp:218] Iteration 95000 (5.49999 iter/s, 18.1818s/100 iters), loss = 0.00343298
I0929 00:02:09.245965  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00343375 (* 1 = 0.00343375 loss)
I0929 00:02:09.245971  5237 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I0929 00:02:23.857533  5237 solver.cpp:218] Iteration 95100 (6.84391 iter/s, 14.6115s/100 iters), loss = 0.00724612
I0929 00:02:23.857564  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00724689 (* 1 = 0.00724689 loss)
I0929 00:02:23.857570  5237 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I0929 00:02:38.468219  5237 solver.cpp:218] Iteration 95200 (6.84434 iter/s, 14.6106s/100 iters), loss = 0.00733153
I0929 00:02:38.468313  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0073323 (* 1 = 0.0073323 loss)
I0929 00:02:38.468331  5237 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I0929 00:02:53.075942  5237 solver.cpp:218] Iteration 95300 (6.84575 iter/s, 14.6076s/100 iters), loss = 0.0170258
I0929 00:02:53.075971  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0170266 (* 1 = 0.0170266 loss)
I0929 00:02:53.075976  5237 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I0929 00:03:07.687546  5237 solver.cpp:218] Iteration 95400 (6.8439 iter/s, 14.6115s/100 iters), loss = 0.00865225
I0929 00:03:07.687577  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00865302 (* 1 = 0.00865302 loss)
I0929 00:03:07.687582  5237 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I0929 00:03:21.571604  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0929 00:03:22.156430  5237 solver.cpp:330] Iteration 95500, Testing net (#0)
I0929 00:03:25.580513  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0929 00:03:25.723510  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9052
I0929 00:03:25.723536  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376124 (* 1 = 0.376124 loss)
I0929 00:03:25.869138  5237 solver.cpp:218] Iteration 95500 (5.50009 iter/s, 18.1815s/100 iters), loss = 0.0155925
I0929 00:03:25.869168  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155933 (* 1 = 0.0155933 loss)
I0929 00:03:25.869174  5237 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I0929 00:03:40.466084  5237 solver.cpp:218] Iteration 95600 (6.85078 iter/s, 14.5969s/100 iters), loss = 0.00311416
I0929 00:03:40.466114  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00311493 (* 1 = 0.00311493 loss)
I0929 00:03:40.466120  5237 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I0929 00:03:55.068419  5237 solver.cpp:218] Iteration 95700 (6.84825 iter/s, 14.6023s/100 iters), loss = 0.00603368
I0929 00:03:55.068511  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00603446 (* 1 = 0.00603446 loss)
I0929 00:03:55.068528  5237 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I0929 00:04:09.672997  5237 solver.cpp:218] Iteration 95800 (6.84722 iter/s, 14.6045s/100 iters), loss = 0.00632286
I0929 00:04:09.673027  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00632363 (* 1 = 0.00632363 loss)
I0929 00:04:09.673032  5237 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I0929 00:04:24.280212  5237 solver.cpp:218] Iteration 95900 (6.84596 iter/s, 14.6072s/100 iters), loss = 0.00531598
I0929 00:04:24.280241  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00531676 (* 1 = 0.00531676 loss)
I0929 00:04:24.280246  5237 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I0929 00:04:38.152662  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0929 00:04:38.739068  5237 solver.cpp:330] Iteration 96000, Testing net (#0)
I0929 00:04:42.159816  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0929 00:04:42.302448  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9062
I0929 00:04:42.302484  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376542 (* 1 = 0.376542 loss)
I0929 00:04:42.447751  5237 solver.cpp:218] Iteration 96000 (5.50434 iter/s, 18.1675s/100 iters), loss = 0.00413898
I0929 00:04:42.447782  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00413975 (* 1 = 0.00413975 loss)
I0929 00:04:42.447788  5237 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I0929 00:04:57.058154  5237 solver.cpp:218] Iteration 96100 (6.84447 iter/s, 14.6103s/100 iters), loss = 0.00594792
I0929 00:04:57.058183  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00594869 (* 1 = 0.00594869 loss)
I0929 00:04:57.058189  5237 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I0929 00:05:11.665051  5237 solver.cpp:218] Iteration 96200 (6.84611 iter/s, 14.6068s/100 iters), loss = 0.0123937
I0929 00:05:11.665140  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0123945 (* 1 = 0.0123945 loss)
I0929 00:05:11.665148  5237 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I0929 00:05:26.273422  5237 solver.cpp:218] Iteration 96300 (6.84544 iter/s, 14.6083s/100 iters), loss = 0.0230653
I0929 00:05:26.273453  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.023066 (* 1 = 0.023066 loss)
I0929 00:05:26.273460  5237 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I0929 00:05:40.882902  5237 solver.cpp:218] Iteration 96400 (6.8449 iter/s, 14.6094s/100 iters), loss = 0.0123286
I0929 00:05:40.882935  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0123294 (* 1 = 0.0123294 loss)
I0929 00:05:40.882941  5237 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I0929 00:05:54.763813  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0929 00:05:55.348110  5237 solver.cpp:330] Iteration 96500, Testing net (#0)
I0929 00:05:58.772608  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0929 00:05:58.915313  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9052
I0929 00:05:58.915346  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.374641 (* 1 = 0.374641 loss)
I0929 00:05:59.060814  5237 solver.cpp:218] Iteration 96500 (5.5012 iter/s, 18.1778s/100 iters), loss = 0.00766829
I0929 00:05:59.060845  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00766906 (* 1 = 0.00766906 loss)
I0929 00:05:59.060853  5237 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I0929 00:06:13.663488  5237 solver.cpp:218] Iteration 96600 (6.84809 iter/s, 14.6026s/100 iters), loss = 0.0114836
I0929 00:06:13.663516  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114843 (* 1 = 0.0114843 loss)
I0929 00:06:13.663522  5237 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I0929 00:06:28.263000  5237 solver.cpp:218] Iteration 96700 (6.84957 iter/s, 14.5995s/100 iters), loss = 0.00576349
I0929 00:06:28.263134  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00576425 (* 1 = 0.00576425 loss)
I0929 00:06:28.263154  5237 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I0929 00:06:42.868728  5237 solver.cpp:218] Iteration 96800 (6.84671 iter/s, 14.6056s/100 iters), loss = 0.0027461
I0929 00:06:42.868760  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00274687 (* 1 = 0.00274687 loss)
I0929 00:06:42.868767  5237 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I0929 00:06:57.465358  5237 solver.cpp:218] Iteration 96900 (6.85093 iter/s, 14.5966s/100 iters), loss = 0.00425447
I0929 00:06:57.465389  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00425525 (* 1 = 0.00425525 loss)
I0929 00:06:57.465395  5237 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I0929 00:07:11.347898  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0929 00:07:11.934126  5237 solver.cpp:330] Iteration 97000, Testing net (#0)
I0929 00:07:15.359419  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0929 00:07:15.502202  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9061
I0929 00:07:15.502225  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373812 (* 1 = 0.373812 loss)
I0929 00:07:15.647378  5237 solver.cpp:218] Iteration 97000 (5.49996 iter/s, 18.182s/100 iters), loss = 0.00433775
I0929 00:07:15.647408  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00433854 (* 1 = 0.00433854 loss)
I0929 00:07:15.647414  5237 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I0929 00:07:30.243779  5237 solver.cpp:218] Iteration 97100 (6.85103 iter/s, 14.5963s/100 iters), loss = 0.00675982
I0929 00:07:30.243821  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00676061 (* 1 = 0.00676061 loss)
I0929 00:07:30.243827  5237 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I0929 00:07:44.846135  5237 solver.cpp:218] Iteration 97200 (6.84824 iter/s, 14.6023s/100 iters), loss = 0.0211922
I0929 00:07:44.846235  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.021193 (* 1 = 0.021193 loss)
I0929 00:07:44.846264  5237 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I0929 00:07:59.461791  5237 solver.cpp:218] Iteration 97300 (6.84204 iter/s, 14.6155s/100 iters), loss = 0.0168134
I0929 00:07:59.461832  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0168142 (* 1 = 0.0168142 loss)
I0929 00:07:59.461836  5237 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I0929 00:08:14.067029  5237 solver.cpp:218] Iteration 97400 (6.84689 iter/s, 14.6052s/100 iters), loss = 0.00418549
I0929 00:08:14.067060  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00418628 (* 1 = 0.00418628 loss)
I0929 00:08:14.067067  5237 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I0929 00:08:27.952878  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0929 00:08:28.537549  5237 solver.cpp:330] Iteration 97500, Testing net (#0)
I0929 00:08:31.961199  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0929 00:08:32.104550  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9047
I0929 00:08:32.104584  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.375017 (* 1 = 0.375017 loss)
I0929 00:08:32.249657  5237 solver.cpp:218] Iteration 97500 (5.49978 iter/s, 18.1826s/100 iters), loss = 0.00715718
I0929 00:08:32.249686  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00715797 (* 1 = 0.00715797 loss)
I0929 00:08:32.249693  5237 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I0929 00:08:46.854569  5237 solver.cpp:218] Iteration 97600 (6.84704 iter/s, 14.6049s/100 iters), loss = 0.00262595
I0929 00:08:46.854609  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00262674 (* 1 = 0.00262674 loss)
I0929 00:08:46.854615  5237 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I0929 00:09:01.468202  5237 solver.cpp:218] Iteration 97700 (6.84296 iter/s, 14.6136s/100 iters), loss = 0.00441853
I0929 00:09:01.468324  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00441932 (* 1 = 0.00441932 loss)
I0929 00:09:01.468343  5237 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I0929 00:09:16.074656  5237 solver.cpp:218] Iteration 97800 (6.84636 iter/s, 14.6063s/100 iters), loss = 0.00397567
I0929 00:09:16.074687  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00397646 (* 1 = 0.00397646 loss)
I0929 00:09:16.074692  5237 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I0929 00:09:30.677075  5237 solver.cpp:218] Iteration 97900 (6.84821 iter/s, 14.6024s/100 iters), loss = 0.00557484
I0929 00:09:30.677105  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00557563 (* 1 = 0.00557563 loss)
I0929 00:09:30.677111  5237 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I0929 00:09:44.558198  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0929 00:09:45.143182  5237 solver.cpp:330] Iteration 98000, Testing net (#0)
I0929 00:09:48.568279  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0929 00:09:48.711635  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9049
I0929 00:09:48.711670  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373594 (* 1 = 0.373594 loss)
I0929 00:09:48.857326  5237 solver.cpp:218] Iteration 98000 (5.50049 iter/s, 18.1802s/100 iters), loss = 0.0132003
I0929 00:09:48.857357  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132011 (* 1 = 0.0132011 loss)
I0929 00:09:48.857363  5237 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I0929 00:10:03.458318  5237 solver.cpp:218] Iteration 98100 (6.84888 iter/s, 14.6009s/100 iters), loss = 0.0145513
I0929 00:10:03.458376  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145521 (* 1 = 0.0145521 loss)
I0929 00:10:03.458382  5237 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I0929 00:10:18.069887  5237 solver.cpp:218] Iteration 98200 (6.84393 iter/s, 14.6115s/100 iters), loss = 0.00367488
I0929 00:10:18.070011  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00367567 (* 1 = 0.00367567 loss)
I0929 00:10:18.070019  5237 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I0929 00:10:32.672287  5237 solver.cpp:218] Iteration 98300 (6.84826 iter/s, 14.6023s/100 iters), loss = 0.0048286
I0929 00:10:32.672327  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00482938 (* 1 = 0.00482938 loss)
I0929 00:10:32.672334  5237 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I0929 00:10:47.278472  5237 solver.cpp:218] Iteration 98400 (6.84645 iter/s, 14.6061s/100 iters), loss = 0.00620092
I0929 00:10:47.278513  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0062017 (* 1 = 0.0062017 loss)
I0929 00:10:47.278522  5237 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I0929 00:11:01.162466  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0929 00:11:01.747069  5237 solver.cpp:330] Iteration 98500, Testing net (#0)
I0929 00:11:05.171259  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0929 00:11:05.314368  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9048
I0929 00:11:05.314402  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.375663 (* 1 = 0.375663 loss)
I0929 00:11:05.459586  5237 solver.cpp:218] Iteration 98500 (5.50024 iter/s, 18.181s/100 iters), loss = 0.00219506
I0929 00:11:05.459616  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00219584 (* 1 = 0.00219584 loss)
I0929 00:11:05.459623  5237 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I0929 00:11:20.062189  5237 solver.cpp:218] Iteration 98600 (6.84812 iter/s, 14.6025s/100 iters), loss = 0.0125972
I0929 00:11:20.062229  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012598 (* 1 = 0.012598 loss)
I0929 00:11:20.062235  5237 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I0929 00:11:34.667156  5237 solver.cpp:218] Iteration 98700 (6.84702 iter/s, 14.6049s/100 iters), loss = 0.00696021
I0929 00:11:34.667289  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.006961 (* 1 = 0.006961 loss)
I0929 00:11:34.667306  5237 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I0929 00:11:49.267499  5237 solver.cpp:218] Iteration 98800 (6.84923 iter/s, 14.6002s/100 iters), loss = 0.00867596
I0929 00:11:49.267530  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00867675 (* 1 = 0.00867675 loss)
I0929 00:11:49.267537  5237 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I0929 00:12:03.863066  5237 solver.cpp:218] Iteration 98900 (6.85143 iter/s, 14.5955s/100 iters), loss = 0.00492871
I0929 00:12:03.863109  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00492949 (* 1 = 0.00492949 loss)
I0929 00:12:03.863116  5237 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I0929 00:12:17.741250  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0929 00:12:18.326048  5237 solver.cpp:330] Iteration 99000, Testing net (#0)
I0929 00:12:21.750133  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0929 00:12:21.893157  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9045
I0929 00:12:21.893180  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.377075 (* 1 = 0.377075 loss)
I0929 00:12:22.039083  5237 solver.cpp:218] Iteration 99000 (5.50178 iter/s, 18.1759s/100 iters), loss = 0.00335816
I0929 00:12:22.039111  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00335895 (* 1 = 0.00335895 loss)
I0929 00:12:22.039119  5237 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I0929 00:12:36.644145  5237 solver.cpp:218] Iteration 99100 (6.84697 iter/s, 14.605s/100 iters), loss = 0.0041011
I0929 00:12:36.644174  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00410189 (* 1 = 0.00410189 loss)
I0929 00:12:36.644181  5237 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I0929 00:12:51.253787  5237 solver.cpp:218] Iteration 99200 (6.84482 iter/s, 14.6096s/100 iters), loss = 0.0102822
I0929 00:12:51.253870  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010283 (* 1 = 0.010283 loss)
I0929 00:12:51.253886  5237 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I0929 00:13:05.861703  5237 solver.cpp:218] Iteration 99300 (6.84565 iter/s, 14.6078s/100 iters), loss = 0.00586717
I0929 00:13:05.861734  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00586796 (* 1 = 0.00586796 loss)
I0929 00:13:05.861742  5237 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I0929 00:13:20.472309  5237 solver.cpp:218] Iteration 99400 (6.84437 iter/s, 14.6105s/100 iters), loss = 0.0059597
I0929 00:13:20.472349  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00596048 (* 1 = 0.00596048 loss)
I0929 00:13:20.472355  5237 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I0929 00:13:34.352136  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0929 00:13:34.938042  5237 solver.cpp:330] Iteration 99500, Testing net (#0)
I0929 00:13:38.359647  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0929 00:13:38.502825  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9043
I0929 00:13:38.502861  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37452 (* 1 = 0.37452 loss)
I0929 00:13:38.648696  5237 solver.cpp:218] Iteration 99500 (5.50167 iter/s, 18.1763s/100 iters), loss = 0.0128793
I0929 00:13:38.648727  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128801 (* 1 = 0.0128801 loss)
I0929 00:13:38.648733  5237 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I0929 00:13:53.248327  5237 solver.cpp:218] Iteration 99600 (6.84952 iter/s, 14.5996s/100 iters), loss = 0.00850411
I0929 00:13:53.248358  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00850489 (* 1 = 0.00850489 loss)
I0929 00:13:53.248364  5237 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I0929 00:14:07.856226  5237 solver.cpp:218] Iteration 99700 (6.84564 iter/s, 14.6078s/100 iters), loss = 0.035545
I0929 00:14:07.856356  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0355458 (* 1 = 0.0355458 loss)
I0929 00:14:07.856364  5237 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I0929 00:14:22.458820  5237 solver.cpp:218] Iteration 99800 (6.84817 iter/s, 14.6024s/100 iters), loss = 0.0036837
I0929 00:14:22.458855  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00368448 (* 1 = 0.00368448 loss)
I0929 00:14:22.458863  5237 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I0929 00:14:37.062126  5237 solver.cpp:218] Iteration 99900 (6.8478 iter/s, 14.6032s/100 iters), loss = 0.00229453
I0929 00:14:37.062156  5237 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00229531 (* 1 = 0.00229531 loss)
I0929 00:14:37.062161  5237 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I0929 00:14:50.937230  5243 data_layer.cpp:73] Restarting data prefetching from start.
I0929 00:14:51.519260  5237 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res56_penlu_alpha2_eta1_2study_nodecay_gauss_iter_100000.caffemodel
I0929 00:14:51.547104  5237 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res56_penlu_alpha2_eta1_2study_nodecay_gauss_iter_100000.solverstate
I0929 00:14:51.588205  5237 solver.cpp:310] Iteration 100000, loss = 0.00592001
I0929 00:14:51.588227  5237 solver.cpp:330] Iteration 100000, Testing net (#0)
I0929 00:14:55.011194  5244 data_layer.cpp:73] Restarting data prefetching from start.
I0929 00:14:55.154402  5237 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9048
I0929 00:14:55.154436  5237 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37592 (* 1 = 0.37592 loss)
I0929 00:14:55.154443  5237 solver.cpp:315] Optimization Done.
I0929 00:14:55.154444  5237 caffe.cpp:259] Optimization Done.
