I0929 09:26:45.322193  1584 caffe.cpp:218] Using GPUs 0
I0929 09:26:45.358232  1584 caffe.cpp:223] GPU 0: GeForce GTX 1080
I0929 09:26:45.588376  1584 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res56_mpelu_alpha0.25_beta1_2study_decay_taylor"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_mpelu_decay_taylor.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I0929 09:26:45.588496  1584 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_mpelu_decay_taylor.prototxt
I0929 09:26:45.592144  1584 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_mpelu_decay_taylor.prototxt
I0929 09:26:45.592159  1584 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0929 09:26:45.592406  1584 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I0929 09:26:45.592521  1584 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I0929 09:26:45.593626  1584 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU1"
  type: "M2PELU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU2"
  type: "M2PELU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU3"
  type: "M2PELU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU4"
  type: "M2PELU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU5"
  type: "M2PELU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU6"
  type: "M2PELU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU7"
  type: "M2PELU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU8"
  type: "M2PELU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU9"
  type: "M2PELU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU10"
  type: "M2PELU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU11"
  type: "M2PELU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU12"
  type: "M2PELU"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU13"
  type: "M2PELU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU14"
  type: "M2PELU"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU15"
  type: "M2PELU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU16"
  type: "M2PELU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU17"
  type: "M2PELU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU18"
  type: "M2PELU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU19"
  type: "M2PELU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU20"
  type: "M2PELU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU21"
  type: "M2PELU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU22"
  type: "M2PELU"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution24"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU23"
  type: "M2PELU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU24"
  type: "M2PELU"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
 
I0929 09:26:45.594403  1584 layer_factory.hpp:77] Creating layer Data1
I0929 09:26:45.594480  1584 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I0929 09:26:45.594497  1584 net.cpp:84] Creating Layer Data1
I0929 09:26:45.594504  1584 net.cpp:380] Data1 -> Data1
I0929 09:26:45.594527  1584 net.cpp:380] Data1 -> Data2
I0929 09:26:45.594538  1584 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0929 09:26:45.595954  1584 data_layer.cpp:45] output data size: 100,3,28,28
I0929 09:26:45.598242  1584 net.cpp:122] Setting up Data1
I0929 09:26:45.598254  1584 net.cpp:129] Top shape: 100 3 28 28 (235200)
I0929 09:26:45.598258  1584 net.cpp:129] Top shape: 100 (100)
I0929 09:26:45.598261  1584 net.cpp:137] Memory required for data: 941200
I0929 09:26:45.598268  1584 layer_factory.hpp:77] Creating layer Convolution1
I0929 09:26:45.598285  1584 net.cpp:84] Creating Layer Convolution1
I0929 09:26:45.598289  1584 net.cpp:406] Convolution1 <- Data1
I0929 09:26:45.598299  1584 net.cpp:380] Convolution1 -> Convolution1
I0929 09:26:45.598390  1584 filler.hpp:251] The std of weights in this layer is: 0.264039
I0929 09:26:45.745972  1584 net.cpp:122] Setting up Convolution1
I0929 09:26:45.745996  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.746001  1584 net.cpp:137] Memory required for data: 5958800
I0929 09:26:45.746014  1584 layer_factory.hpp:77] Creating layer BatchNorm1
I0929 09:26:45.746062  1584 net.cpp:84] Creating Layer BatchNorm1
I0929 09:26:45.746067  1584 net.cpp:406] BatchNorm1 <- Convolution1
I0929 09:26:45.746080  1584 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0929 09:26:45.746254  1584 net.cpp:122] Setting up BatchNorm1
I0929 09:26:45.746260  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.746273  1584 net.cpp:137] Memory required for data: 10976400
I0929 09:26:45.746280  1584 layer_factory.hpp:77] Creating layer Scale1
I0929 09:26:45.746301  1584 net.cpp:84] Creating Layer Scale1
I0929 09:26:45.746305  1584 net.cpp:406] Scale1 <- Convolution1
I0929 09:26:45.746310  1584 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0929 09:26:45.746369  1584 layer_factory.hpp:77] Creating layer Scale1
I0929 09:26:45.746470  1584 net.cpp:122] Setting up Scale1
I0929 09:26:45.746476  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.746479  1584 net.cpp:137] Memory required for data: 15994000
I0929 09:26:45.746493  1584 layer_factory.hpp:77] Creating layer M2PELU1
I0929 09:26:45.746503  1584 net.cpp:84] Creating Layer M2PELU1
I0929 09:26:45.746507  1584 net.cpp:406] M2PELU1 <- Convolution1
I0929 09:26:45.746510  1584 net.cpp:367] M2PELU1 -> Convolution1 (in-place)
I0929 09:26:45.747107  1584 net.cpp:122] Setting up M2PELU1
I0929 09:26:45.747117  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.747136  1584 net.cpp:137] Memory required for data: 21011600
I0929 09:26:45.747143  1584 layer_factory.hpp:77] Creating layer Convolution1_M2PELU1_0_split
I0929 09:26:45.747151  1584 net.cpp:84] Creating Layer Convolution1_M2PELU1_0_split
I0929 09:26:45.747155  1584 net.cpp:406] Convolution1_M2PELU1_0_split <- Convolution1
I0929 09:26:45.747159  1584 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_0
I0929 09:26:45.747164  1584 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_1
I0929 09:26:45.747189  1584 net.cpp:122] Setting up Convolution1_M2PELU1_0_split
I0929 09:26:45.747193  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.747205  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.747208  1584 net.cpp:137] Memory required for data: 31046800
I0929 09:26:45.747211  1584 layer_factory.hpp:77] Creating layer Convolution2
I0929 09:26:45.747231  1584 net.cpp:84] Creating Layer Convolution2
I0929 09:26:45.747233  1584 net.cpp:406] Convolution2 <- Convolution1_M2PELU1_0_split_0
I0929 09:26:45.747237  1584 net.cpp:380] Convolution2 -> Convolution2
I0929 09:26:45.747308  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:45.748114  1584 net.cpp:122] Setting up Convolution2
I0929 09:26:45.748124  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.748128  1584 net.cpp:137] Memory required for data: 36064400
I0929 09:26:45.748132  1584 layer_factory.hpp:77] Creating layer BatchNorm2
I0929 09:26:45.748138  1584 net.cpp:84] Creating Layer BatchNorm2
I0929 09:26:45.748142  1584 net.cpp:406] BatchNorm2 <- Convolution2
I0929 09:26:45.748147  1584 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0929 09:26:45.748271  1584 net.cpp:122] Setting up BatchNorm2
I0929 09:26:45.748276  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.748280  1584 net.cpp:137] Memory required for data: 41082000
I0929 09:26:45.748284  1584 layer_factory.hpp:77] Creating layer Scale2
I0929 09:26:45.748289  1584 net.cpp:84] Creating Layer Scale2
I0929 09:26:45.748292  1584 net.cpp:406] Scale2 <- Convolution2
I0929 09:26:45.748296  1584 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0929 09:26:45.748322  1584 layer_factory.hpp:77] Creating layer Scale2
I0929 09:26:45.748396  1584 net.cpp:122] Setting up Scale2
I0929 09:26:45.748401  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.748404  1584 net.cpp:137] Memory required for data: 46099600
I0929 09:26:45.748409  1584 layer_factory.hpp:77] Creating layer M2PELU2
I0929 09:26:45.748414  1584 net.cpp:84] Creating Layer M2PELU2
I0929 09:26:45.748425  1584 net.cpp:406] M2PELU2 <- Convolution2
I0929 09:26:45.748428  1584 net.cpp:367] M2PELU2 -> Convolution2 (in-place)
I0929 09:26:45.748507  1584 net.cpp:122] Setting up M2PELU2
I0929 09:26:45.748512  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.748514  1584 net.cpp:137] Memory required for data: 51117200
I0929 09:26:45.748520  1584 layer_factory.hpp:77] Creating layer Convolution3
I0929 09:26:45.748528  1584 net.cpp:84] Creating Layer Convolution3
I0929 09:26:45.748531  1584 net.cpp:406] Convolution3 <- Convolution2
I0929 09:26:45.748538  1584 net.cpp:380] Convolution3 -> Convolution3
I0929 09:26:45.748608  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:45.749411  1584 net.cpp:122] Setting up Convolution3
I0929 09:26:45.749421  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.749424  1584 net.cpp:137] Memory required for data: 56134800
I0929 09:26:45.749429  1584 layer_factory.hpp:77] Creating layer BatchNorm3
I0929 09:26:45.749435  1584 net.cpp:84] Creating Layer BatchNorm3
I0929 09:26:45.749439  1584 net.cpp:406] BatchNorm3 <- Convolution3
I0929 09:26:45.749444  1584 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0929 09:26:45.749564  1584 net.cpp:122] Setting up BatchNorm3
I0929 09:26:45.749569  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.749572  1584 net.cpp:137] Memory required for data: 61152400
I0929 09:26:45.749577  1584 layer_factory.hpp:77] Creating layer Scale3
I0929 09:26:45.749583  1584 net.cpp:84] Creating Layer Scale3
I0929 09:26:45.749586  1584 net.cpp:406] Scale3 <- Convolution3
I0929 09:26:45.749589  1584 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0929 09:26:45.749614  1584 layer_factory.hpp:77] Creating layer Scale3
I0929 09:26:45.749687  1584 net.cpp:122] Setting up Scale3
I0929 09:26:45.749691  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.749694  1584 net.cpp:137] Memory required for data: 66170000
I0929 09:26:45.749698  1584 layer_factory.hpp:77] Creating layer Eltwise1
I0929 09:26:45.749704  1584 net.cpp:84] Creating Layer Eltwise1
I0929 09:26:45.749707  1584 net.cpp:406] Eltwise1 <- Convolution1_M2PELU1_0_split_1
I0929 09:26:45.749711  1584 net.cpp:406] Eltwise1 <- Convolution3
I0929 09:26:45.749714  1584 net.cpp:380] Eltwise1 -> Eltwise1
I0929 09:26:45.749732  1584 net.cpp:122] Setting up Eltwise1
I0929 09:26:45.749735  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.749738  1584 net.cpp:137] Memory required for data: 71187600
I0929 09:26:45.749740  1584 layer_factory.hpp:77] Creating layer M2PELU3
I0929 09:26:45.749745  1584 net.cpp:84] Creating Layer M2PELU3
I0929 09:26:45.749748  1584 net.cpp:406] M2PELU3 <- Eltwise1
I0929 09:26:45.749752  1584 net.cpp:367] M2PELU3 -> Eltwise1 (in-place)
I0929 09:26:45.749828  1584 net.cpp:122] Setting up M2PELU3
I0929 09:26:45.749832  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.749835  1584 net.cpp:137] Memory required for data: 76205200
I0929 09:26:45.749840  1584 layer_factory.hpp:77] Creating layer Eltwise1_M2PELU3_0_split
I0929 09:26:45.749843  1584 net.cpp:84] Creating Layer Eltwise1_M2PELU3_0_split
I0929 09:26:45.749846  1584 net.cpp:406] Eltwise1_M2PELU3_0_split <- Eltwise1
I0929 09:26:45.749850  1584 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_0
I0929 09:26:45.749855  1584 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_1
I0929 09:26:45.749877  1584 net.cpp:122] Setting up Eltwise1_M2PELU3_0_split
I0929 09:26:45.749882  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.749886  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.749888  1584 net.cpp:137] Memory required for data: 86240400
I0929 09:26:45.749891  1584 layer_factory.hpp:77] Creating layer Convolution4
I0929 09:26:45.749899  1584 net.cpp:84] Creating Layer Convolution4
I0929 09:26:45.749902  1584 net.cpp:406] Convolution4 <- Eltwise1_M2PELU3_0_split_0
I0929 09:26:45.749907  1584 net.cpp:380] Convolution4 -> Convolution4
I0929 09:26:45.749980  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:45.750789  1584 net.cpp:122] Setting up Convolution4
I0929 09:26:45.750800  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.750803  1584 net.cpp:137] Memory required for data: 91258000
I0929 09:26:45.750808  1584 layer_factory.hpp:77] Creating layer BatchNorm4
I0929 09:26:45.750813  1584 net.cpp:84] Creating Layer BatchNorm4
I0929 09:26:45.750816  1584 net.cpp:406] BatchNorm4 <- Convolution4
I0929 09:26:45.750821  1584 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0929 09:26:45.750948  1584 net.cpp:122] Setting up BatchNorm4
I0929 09:26:45.750953  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.750955  1584 net.cpp:137] Memory required for data: 96275600
I0929 09:26:45.750969  1584 layer_factory.hpp:77] Creating layer Scale4
I0929 09:26:45.750974  1584 net.cpp:84] Creating Layer Scale4
I0929 09:26:45.750977  1584 net.cpp:406] Scale4 <- Convolution4
I0929 09:26:45.750980  1584 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0929 09:26:45.751013  1584 layer_factory.hpp:77] Creating layer Scale4
I0929 09:26:45.751094  1584 net.cpp:122] Setting up Scale4
I0929 09:26:45.751099  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.751102  1584 net.cpp:137] Memory required for data: 101293200
I0929 09:26:45.751111  1584 layer_factory.hpp:77] Creating layer M2PELU4
I0929 09:26:45.751116  1584 net.cpp:84] Creating Layer M2PELU4
I0929 09:26:45.751118  1584 net.cpp:406] M2PELU4 <- Convolution4
I0929 09:26:45.751122  1584 net.cpp:367] M2PELU4 -> Convolution4 (in-place)
I0929 09:26:45.751199  1584 net.cpp:122] Setting up M2PELU4
I0929 09:26:45.751204  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.751206  1584 net.cpp:137] Memory required for data: 106310800
I0929 09:26:45.751210  1584 layer_factory.hpp:77] Creating layer Convolution5
I0929 09:26:45.751217  1584 net.cpp:84] Creating Layer Convolution5
I0929 09:26:45.751220  1584 net.cpp:406] Convolution5 <- Convolution4
I0929 09:26:45.751225  1584 net.cpp:380] Convolution5 -> Convolution5
I0929 09:26:45.751296  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:45.752095  1584 net.cpp:122] Setting up Convolution5
I0929 09:26:45.752105  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.752109  1584 net.cpp:137] Memory required for data: 111328400
I0929 09:26:45.752113  1584 layer_factory.hpp:77] Creating layer BatchNorm5
I0929 09:26:45.752120  1584 net.cpp:84] Creating Layer BatchNorm5
I0929 09:26:45.752122  1584 net.cpp:406] BatchNorm5 <- Convolution5
I0929 09:26:45.752126  1584 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0929 09:26:45.752249  1584 net.cpp:122] Setting up BatchNorm5
I0929 09:26:45.752254  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.752256  1584 net.cpp:137] Memory required for data: 116346000
I0929 09:26:45.752261  1584 layer_factory.hpp:77] Creating layer Scale5
I0929 09:26:45.752266  1584 net.cpp:84] Creating Layer Scale5
I0929 09:26:45.752269  1584 net.cpp:406] Scale5 <- Convolution5
I0929 09:26:45.752272  1584 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0929 09:26:45.752297  1584 layer_factory.hpp:77] Creating layer Scale5
I0929 09:26:45.752383  1584 net.cpp:122] Setting up Scale5
I0929 09:26:45.752391  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.752395  1584 net.cpp:137] Memory required for data: 121363600
I0929 09:26:45.752411  1584 layer_factory.hpp:77] Creating layer Eltwise2
I0929 09:26:45.752418  1584 net.cpp:84] Creating Layer Eltwise2
I0929 09:26:45.752423  1584 net.cpp:406] Eltwise2 <- Eltwise1_M2PELU3_0_split_1
I0929 09:26:45.752426  1584 net.cpp:406] Eltwise2 <- Convolution5
I0929 09:26:45.752432  1584 net.cpp:380] Eltwise2 -> Eltwise2
I0929 09:26:45.752455  1584 net.cpp:122] Setting up Eltwise2
I0929 09:26:45.752462  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.752466  1584 net.cpp:137] Memory required for data: 126381200
I0929 09:26:45.752470  1584 layer_factory.hpp:77] Creating layer M2PELU5
I0929 09:26:45.752488  1584 net.cpp:84] Creating Layer M2PELU5
I0929 09:26:45.752493  1584 net.cpp:406] M2PELU5 <- Eltwise2
I0929 09:26:45.752501  1584 net.cpp:367] M2PELU5 -> Eltwise2 (in-place)
I0929 09:26:45.752594  1584 net.cpp:122] Setting up M2PELU5
I0929 09:26:45.752600  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.752604  1584 net.cpp:137] Memory required for data: 131398800
I0929 09:26:45.752607  1584 layer_factory.hpp:77] Creating layer Eltwise2_M2PELU5_0_split
I0929 09:26:45.752612  1584 net.cpp:84] Creating Layer Eltwise2_M2PELU5_0_split
I0929 09:26:45.752615  1584 net.cpp:406] Eltwise2_M2PELU5_0_split <- Eltwise2
I0929 09:26:45.752619  1584 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_0
I0929 09:26:45.752624  1584 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_1
I0929 09:26:45.752646  1584 net.cpp:122] Setting up Eltwise2_M2PELU5_0_split
I0929 09:26:45.752650  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.752655  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.752656  1584 net.cpp:137] Memory required for data: 141434000
I0929 09:26:45.752660  1584 layer_factory.hpp:77] Creating layer Convolution6
I0929 09:26:45.752665  1584 net.cpp:84] Creating Layer Convolution6
I0929 09:26:45.752668  1584 net.cpp:406] Convolution6 <- Eltwise2_M2PELU5_0_split_0
I0929 09:26:45.752672  1584 net.cpp:380] Convolution6 -> Convolution6
I0929 09:26:45.752746  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:45.753549  1584 net.cpp:122] Setting up Convolution6
I0929 09:26:45.753559  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.753562  1584 net.cpp:137] Memory required for data: 146451600
I0929 09:26:45.753567  1584 layer_factory.hpp:77] Creating layer BatchNorm6
I0929 09:26:45.753573  1584 net.cpp:84] Creating Layer BatchNorm6
I0929 09:26:45.753576  1584 net.cpp:406] BatchNorm6 <- Convolution6
I0929 09:26:45.753582  1584 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0929 09:26:45.753710  1584 net.cpp:122] Setting up BatchNorm6
I0929 09:26:45.753715  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.753717  1584 net.cpp:137] Memory required for data: 151469200
I0929 09:26:45.753722  1584 layer_factory.hpp:77] Creating layer Scale6
I0929 09:26:45.753727  1584 net.cpp:84] Creating Layer Scale6
I0929 09:26:45.753731  1584 net.cpp:406] Scale6 <- Convolution6
I0929 09:26:45.753734  1584 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0929 09:26:45.753759  1584 layer_factory.hpp:77] Creating layer Scale6
I0929 09:26:45.753834  1584 net.cpp:122] Setting up Scale6
I0929 09:26:45.753839  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.753841  1584 net.cpp:137] Memory required for data: 156486800
I0929 09:26:45.753845  1584 layer_factory.hpp:77] Creating layer M2PELU6
I0929 09:26:45.753851  1584 net.cpp:84] Creating Layer M2PELU6
I0929 09:26:45.753854  1584 net.cpp:406] M2PELU6 <- Convolution6
I0929 09:26:45.753859  1584 net.cpp:367] M2PELU6 -> Convolution6 (in-place)
I0929 09:26:45.753937  1584 net.cpp:122] Setting up M2PELU6
I0929 09:26:45.753942  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.753945  1584 net.cpp:137] Memory required for data: 161504400
I0929 09:26:45.753948  1584 layer_factory.hpp:77] Creating layer Convolution7
I0929 09:26:45.753957  1584 net.cpp:84] Creating Layer Convolution7
I0929 09:26:45.753960  1584 net.cpp:406] Convolution7 <- Convolution6
I0929 09:26:45.753964  1584 net.cpp:380] Convolution7 -> Convolution7
I0929 09:26:45.754042  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:45.754515  1584 net.cpp:122] Setting up Convolution7
I0929 09:26:45.754528  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.754530  1584 net.cpp:137] Memory required for data: 166522000
I0929 09:26:45.754545  1584 layer_factory.hpp:77] Creating layer BatchNorm7
I0929 09:26:45.754552  1584 net.cpp:84] Creating Layer BatchNorm7
I0929 09:26:45.754555  1584 net.cpp:406] BatchNorm7 <- Convolution7
I0929 09:26:45.754568  1584 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0929 09:26:45.754706  1584 net.cpp:122] Setting up BatchNorm7
I0929 09:26:45.754711  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.754714  1584 net.cpp:137] Memory required for data: 171539600
I0929 09:26:45.754729  1584 layer_factory.hpp:77] Creating layer Scale7
I0929 09:26:45.754736  1584 net.cpp:84] Creating Layer Scale7
I0929 09:26:45.754739  1584 net.cpp:406] Scale7 <- Convolution7
I0929 09:26:45.754743  1584 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0929 09:26:45.754779  1584 layer_factory.hpp:77] Creating layer Scale7
I0929 09:26:45.754864  1584 net.cpp:122] Setting up Scale7
I0929 09:26:45.754869  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.754873  1584 net.cpp:137] Memory required for data: 176557200
I0929 09:26:45.754876  1584 layer_factory.hpp:77] Creating layer Eltwise3
I0929 09:26:45.754881  1584 net.cpp:84] Creating Layer Eltwise3
I0929 09:26:45.754884  1584 net.cpp:406] Eltwise3 <- Eltwise2_M2PELU5_0_split_1
I0929 09:26:45.754887  1584 net.cpp:406] Eltwise3 <- Convolution7
I0929 09:26:45.754891  1584 net.cpp:380] Eltwise3 -> Eltwise3
I0929 09:26:45.754907  1584 net.cpp:122] Setting up Eltwise3
I0929 09:26:45.754911  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.754914  1584 net.cpp:137] Memory required for data: 181574800
I0929 09:26:45.754916  1584 layer_factory.hpp:77] Creating layer M2PELU7
I0929 09:26:45.754921  1584 net.cpp:84] Creating Layer M2PELU7
I0929 09:26:45.754923  1584 net.cpp:406] M2PELU7 <- Eltwise3
I0929 09:26:45.754927  1584 net.cpp:367] M2PELU7 -> Eltwise3 (in-place)
I0929 09:26:45.755010  1584 net.cpp:122] Setting up M2PELU7
I0929 09:26:45.755015  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.755018  1584 net.cpp:137] Memory required for data: 186592400
I0929 09:26:45.755022  1584 layer_factory.hpp:77] Creating layer Eltwise3_M2PELU7_0_split
I0929 09:26:45.755026  1584 net.cpp:84] Creating Layer Eltwise3_M2PELU7_0_split
I0929 09:26:45.755029  1584 net.cpp:406] Eltwise3_M2PELU7_0_split <- Eltwise3
I0929 09:26:45.755033  1584 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_0
I0929 09:26:45.755036  1584 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_1
I0929 09:26:45.755060  1584 net.cpp:122] Setting up Eltwise3_M2PELU7_0_split
I0929 09:26:45.755064  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.755069  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.755071  1584 net.cpp:137] Memory required for data: 196627600
I0929 09:26:45.755074  1584 layer_factory.hpp:77] Creating layer Convolution8
I0929 09:26:45.755079  1584 net.cpp:84] Creating Layer Convolution8
I0929 09:26:45.755082  1584 net.cpp:406] Convolution8 <- Eltwise3_M2PELU7_0_split_0
I0929 09:26:45.755086  1584 net.cpp:380] Convolution8 -> Convolution8
I0929 09:26:45.755162  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:45.755975  1584 net.cpp:122] Setting up Convolution8
I0929 09:26:45.755985  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.755987  1584 net.cpp:137] Memory required for data: 201645200
I0929 09:26:45.755998  1584 layer_factory.hpp:77] Creating layer BatchNorm8
I0929 09:26:45.756006  1584 net.cpp:84] Creating Layer BatchNorm8
I0929 09:26:45.756008  1584 net.cpp:406] BatchNorm8 <- Convolution8
I0929 09:26:45.756012  1584 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0929 09:26:45.756142  1584 net.cpp:122] Setting up BatchNorm8
I0929 09:26:45.756147  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.756150  1584 net.cpp:137] Memory required for data: 206662800
I0929 09:26:45.756155  1584 layer_factory.hpp:77] Creating layer Scale8
I0929 09:26:45.756161  1584 net.cpp:84] Creating Layer Scale8
I0929 09:26:45.756165  1584 net.cpp:406] Scale8 <- Convolution8
I0929 09:26:45.756168  1584 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0929 09:26:45.756194  1584 layer_factory.hpp:77] Creating layer Scale8
I0929 09:26:45.756279  1584 net.cpp:122] Setting up Scale8
I0929 09:26:45.756284  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.756287  1584 net.cpp:137] Memory required for data: 211680400
I0929 09:26:45.756291  1584 layer_factory.hpp:77] Creating layer M2PELU8
I0929 09:26:45.756297  1584 net.cpp:84] Creating Layer M2PELU8
I0929 09:26:45.756300  1584 net.cpp:406] M2PELU8 <- Convolution8
I0929 09:26:45.756304  1584 net.cpp:367] M2PELU8 -> Convolution8 (in-place)
I0929 09:26:45.756387  1584 net.cpp:122] Setting up M2PELU8
I0929 09:26:45.756392  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.756395  1584 net.cpp:137] Memory required for data: 216698000
I0929 09:26:45.756399  1584 layer_factory.hpp:77] Creating layer Convolution9
I0929 09:26:45.756407  1584 net.cpp:84] Creating Layer Convolution9
I0929 09:26:45.756410  1584 net.cpp:406] Convolution9 <- Convolution8
I0929 09:26:45.756415  1584 net.cpp:380] Convolution9 -> Convolution9
I0929 09:26:45.756492  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:45.757338  1584 net.cpp:122] Setting up Convolution9
I0929 09:26:45.757347  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.757350  1584 net.cpp:137] Memory required for data: 221715600
I0929 09:26:45.757355  1584 layer_factory.hpp:77] Creating layer BatchNorm9
I0929 09:26:45.757361  1584 net.cpp:84] Creating Layer BatchNorm9
I0929 09:26:45.757365  1584 net.cpp:406] BatchNorm9 <- Convolution9
I0929 09:26:45.757369  1584 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0929 09:26:45.757552  1584 net.cpp:122] Setting up BatchNorm9
I0929 09:26:45.757560  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.757561  1584 net.cpp:137] Memory required for data: 226733200
I0929 09:26:45.757567  1584 layer_factory.hpp:77] Creating layer Scale9
I0929 09:26:45.757571  1584 net.cpp:84] Creating Layer Scale9
I0929 09:26:45.757575  1584 net.cpp:406] Scale9 <- Convolution9
I0929 09:26:45.757577  1584 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0929 09:26:45.757604  1584 layer_factory.hpp:77] Creating layer Scale9
I0929 09:26:45.757732  1584 net.cpp:122] Setting up Scale9
I0929 09:26:45.757745  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.757750  1584 net.cpp:137] Memory required for data: 231750800
I0929 09:26:45.757757  1584 layer_factory.hpp:77] Creating layer Eltwise4
I0929 09:26:45.757766  1584 net.cpp:84] Creating Layer Eltwise4
I0929 09:26:45.757771  1584 net.cpp:406] Eltwise4 <- Eltwise3_M2PELU7_0_split_1
I0929 09:26:45.757778  1584 net.cpp:406] Eltwise4 <- Convolution9
I0929 09:26:45.757783  1584 net.cpp:380] Eltwise4 -> Eltwise4
I0929 09:26:45.757802  1584 net.cpp:122] Setting up Eltwise4
I0929 09:26:45.757807  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.757810  1584 net.cpp:137] Memory required for data: 236768400
I0929 09:26:45.757812  1584 layer_factory.hpp:77] Creating layer M2PELU9
I0929 09:26:45.757818  1584 net.cpp:84] Creating Layer M2PELU9
I0929 09:26:45.757822  1584 net.cpp:406] M2PELU9 <- Eltwise4
I0929 09:26:45.757824  1584 net.cpp:367] M2PELU9 -> Eltwise4 (in-place)
I0929 09:26:45.757911  1584 net.cpp:122] Setting up M2PELU9
I0929 09:26:45.757916  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.757920  1584 net.cpp:137] Memory required for data: 241786000
I0929 09:26:45.757923  1584 layer_factory.hpp:77] Creating layer Eltwise4_M2PELU9_0_split
I0929 09:26:45.757928  1584 net.cpp:84] Creating Layer Eltwise4_M2PELU9_0_split
I0929 09:26:45.757931  1584 net.cpp:406] Eltwise4_M2PELU9_0_split <- Eltwise4
I0929 09:26:45.757936  1584 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_0
I0929 09:26:45.757939  1584 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_1
I0929 09:26:45.757962  1584 net.cpp:122] Setting up Eltwise4_M2PELU9_0_split
I0929 09:26:45.757967  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.757972  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.757980  1584 net.cpp:137] Memory required for data: 251821200
I0929 09:26:45.757983  1584 layer_factory.hpp:77] Creating layer Convolution10
I0929 09:26:45.757990  1584 net.cpp:84] Creating Layer Convolution10
I0929 09:26:45.757993  1584 net.cpp:406] Convolution10 <- Eltwise4_M2PELU9_0_split_0
I0929 09:26:45.757997  1584 net.cpp:380] Convolution10 -> Convolution10
I0929 09:26:45.758077  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:45.758924  1584 net.cpp:122] Setting up Convolution10
I0929 09:26:45.758934  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.758939  1584 net.cpp:137] Memory required for data: 256838800
I0929 09:26:45.758944  1584 layer_factory.hpp:77] Creating layer BatchNorm10
I0929 09:26:45.758950  1584 net.cpp:84] Creating Layer BatchNorm10
I0929 09:26:45.758956  1584 net.cpp:406] BatchNorm10 <- Convolution10
I0929 09:26:45.758963  1584 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0929 09:26:45.759109  1584 net.cpp:122] Setting up BatchNorm10
I0929 09:26:45.759116  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.759119  1584 net.cpp:137] Memory required for data: 261856400
I0929 09:26:45.759124  1584 layer_factory.hpp:77] Creating layer Scale10
I0929 09:26:45.759131  1584 net.cpp:84] Creating Layer Scale10
I0929 09:26:45.759135  1584 net.cpp:406] Scale10 <- Convolution10
I0929 09:26:45.759140  1584 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0929 09:26:45.759166  1584 layer_factory.hpp:77] Creating layer Scale10
I0929 09:26:45.759308  1584 net.cpp:122] Setting up Scale10
I0929 09:26:45.759316  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.759320  1584 net.cpp:137] Memory required for data: 266874000
I0929 09:26:45.759323  1584 layer_factory.hpp:77] Creating layer M2PELU10
I0929 09:26:45.759330  1584 net.cpp:84] Creating Layer M2PELU10
I0929 09:26:45.759333  1584 net.cpp:406] M2PELU10 <- Convolution10
I0929 09:26:45.759338  1584 net.cpp:367] M2PELU10 -> Convolution10 (in-place)
I0929 09:26:45.759424  1584 net.cpp:122] Setting up M2PELU10
I0929 09:26:45.759429  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.759433  1584 net.cpp:137] Memory required for data: 271891600
I0929 09:26:45.759436  1584 layer_factory.hpp:77] Creating layer Convolution11
I0929 09:26:45.759443  1584 net.cpp:84] Creating Layer Convolution11
I0929 09:26:45.759447  1584 net.cpp:406] Convolution11 <- Convolution10
I0929 09:26:45.759451  1584 net.cpp:380] Convolution11 -> Convolution11
I0929 09:26:45.759532  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:45.760401  1584 net.cpp:122] Setting up Convolution11
I0929 09:26:45.760411  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.760414  1584 net.cpp:137] Memory required for data: 276909200
I0929 09:26:45.760418  1584 layer_factory.hpp:77] Creating layer BatchNorm11
I0929 09:26:45.760424  1584 net.cpp:84] Creating Layer BatchNorm11
I0929 09:26:45.760427  1584 net.cpp:406] BatchNorm11 <- Convolution11
I0929 09:26:45.760432  1584 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0929 09:26:45.760577  1584 net.cpp:122] Setting up BatchNorm11
I0929 09:26:45.760582  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.760586  1584 net.cpp:137] Memory required for data: 281926800
I0929 09:26:45.760589  1584 layer_factory.hpp:77] Creating layer Scale11
I0929 09:26:45.760594  1584 net.cpp:84] Creating Layer Scale11
I0929 09:26:45.760596  1584 net.cpp:406] Scale11 <- Convolution11
I0929 09:26:45.760601  1584 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0929 09:26:45.760627  1584 layer_factory.hpp:77] Creating layer Scale11
I0929 09:26:45.760712  1584 net.cpp:122] Setting up Scale11
I0929 09:26:45.760717  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.760720  1584 net.cpp:137] Memory required for data: 286944400
I0929 09:26:45.760725  1584 layer_factory.hpp:77] Creating layer Eltwise5
I0929 09:26:45.760730  1584 net.cpp:84] Creating Layer Eltwise5
I0929 09:26:45.760732  1584 net.cpp:406] Eltwise5 <- Eltwise4_M2PELU9_0_split_1
I0929 09:26:45.760742  1584 net.cpp:406] Eltwise5 <- Convolution11
I0929 09:26:45.760747  1584 net.cpp:380] Eltwise5 -> Eltwise5
I0929 09:26:45.760764  1584 net.cpp:122] Setting up Eltwise5
I0929 09:26:45.760769  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.760772  1584 net.cpp:137] Memory required for data: 291962000
I0929 09:26:45.760774  1584 layer_factory.hpp:77] Creating layer M2PELU11
I0929 09:26:45.760781  1584 net.cpp:84] Creating Layer M2PELU11
I0929 09:26:45.760783  1584 net.cpp:406] M2PELU11 <- Eltwise5
I0929 09:26:45.760787  1584 net.cpp:367] M2PELU11 -> Eltwise5 (in-place)
I0929 09:26:45.760872  1584 net.cpp:122] Setting up M2PELU11
I0929 09:26:45.760877  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.760880  1584 net.cpp:137] Memory required for data: 296979600
I0929 09:26:45.760885  1584 layer_factory.hpp:77] Creating layer Eltwise5_M2PELU11_0_split
I0929 09:26:45.760888  1584 net.cpp:84] Creating Layer Eltwise5_M2PELU11_0_split
I0929 09:26:45.760891  1584 net.cpp:406] Eltwise5_M2PELU11_0_split <- Eltwise5
I0929 09:26:45.760895  1584 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_0
I0929 09:26:45.760898  1584 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_1
I0929 09:26:45.760921  1584 net.cpp:122] Setting up Eltwise5_M2PELU11_0_split
I0929 09:26:45.760926  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.760931  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.760933  1584 net.cpp:137] Memory required for data: 307014800
I0929 09:26:45.760936  1584 layer_factory.hpp:77] Creating layer Convolution12
I0929 09:26:45.760942  1584 net.cpp:84] Creating Layer Convolution12
I0929 09:26:45.760946  1584 net.cpp:406] Convolution12 <- Eltwise5_M2PELU11_0_split_0
I0929 09:26:45.760949  1584 net.cpp:380] Convolution12 -> Convolution12
I0929 09:26:45.761029  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:45.761953  1584 net.cpp:122] Setting up Convolution12
I0929 09:26:45.761963  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.761966  1584 net.cpp:137] Memory required for data: 312032400
I0929 09:26:45.761971  1584 layer_factory.hpp:77] Creating layer BatchNorm12
I0929 09:26:45.761977  1584 net.cpp:84] Creating Layer BatchNorm12
I0929 09:26:45.761981  1584 net.cpp:406] BatchNorm12 <- Convolution12
I0929 09:26:45.761984  1584 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0929 09:26:45.762115  1584 net.cpp:122] Setting up BatchNorm12
I0929 09:26:45.762120  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.762121  1584 net.cpp:137] Memory required for data: 317050000
I0929 09:26:45.762126  1584 layer_factory.hpp:77] Creating layer Scale12
I0929 09:26:45.762131  1584 net.cpp:84] Creating Layer Scale12
I0929 09:26:45.762135  1584 net.cpp:406] Scale12 <- Convolution12
I0929 09:26:45.762138  1584 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0929 09:26:45.762163  1584 layer_factory.hpp:77] Creating layer Scale12
I0929 09:26:45.762239  1584 net.cpp:122] Setting up Scale12
I0929 09:26:45.762244  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.762248  1584 net.cpp:137] Memory required for data: 322067600
I0929 09:26:45.762251  1584 layer_factory.hpp:77] Creating layer M2PELU12
I0929 09:26:45.762256  1584 net.cpp:84] Creating Layer M2PELU12
I0929 09:26:45.762259  1584 net.cpp:406] M2PELU12 <- Convolution12
I0929 09:26:45.762264  1584 net.cpp:367] M2PELU12 -> Convolution12 (in-place)
I0929 09:26:45.762346  1584 net.cpp:122] Setting up M2PELU12
I0929 09:26:45.762351  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.762353  1584 net.cpp:137] Memory required for data: 327085200
I0929 09:26:45.762357  1584 layer_factory.hpp:77] Creating layer Convolution13
I0929 09:26:45.762364  1584 net.cpp:84] Creating Layer Convolution13
I0929 09:26:45.762367  1584 net.cpp:406] Convolution13 <- Convolution12
I0929 09:26:45.762372  1584 net.cpp:380] Convolution13 -> Convolution13
I0929 09:26:45.762456  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:45.763284  1584 net.cpp:122] Setting up Convolution13
I0929 09:26:45.763294  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.763298  1584 net.cpp:137] Memory required for data: 332102800
I0929 09:26:45.763303  1584 layer_factory.hpp:77] Creating layer BatchNorm13
I0929 09:26:45.763309  1584 net.cpp:84] Creating Layer BatchNorm13
I0929 09:26:45.763311  1584 net.cpp:406] BatchNorm13 <- Convolution13
I0929 09:26:45.763314  1584 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0929 09:26:45.763444  1584 net.cpp:122] Setting up BatchNorm13
I0929 09:26:45.763449  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.763451  1584 net.cpp:137] Memory required for data: 337120400
I0929 09:26:45.763456  1584 layer_factory.hpp:77] Creating layer Scale13
I0929 09:26:45.763461  1584 net.cpp:84] Creating Layer Scale13
I0929 09:26:45.763463  1584 net.cpp:406] Scale13 <- Convolution13
I0929 09:26:45.763466  1584 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0929 09:26:45.763492  1584 layer_factory.hpp:77] Creating layer Scale13
I0929 09:26:45.763569  1584 net.cpp:122] Setting up Scale13
I0929 09:26:45.763574  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.763576  1584 net.cpp:137] Memory required for data: 342138000
I0929 09:26:45.763581  1584 layer_factory.hpp:77] Creating layer Eltwise6
I0929 09:26:45.763586  1584 net.cpp:84] Creating Layer Eltwise6
I0929 09:26:45.763589  1584 net.cpp:406] Eltwise6 <- Eltwise5_M2PELU11_0_split_1
I0929 09:26:45.763592  1584 net.cpp:406] Eltwise6 <- Convolution13
I0929 09:26:45.763595  1584 net.cpp:380] Eltwise6 -> Eltwise6
I0929 09:26:45.763613  1584 net.cpp:122] Setting up Eltwise6
I0929 09:26:45.763618  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.763620  1584 net.cpp:137] Memory required for data: 347155600
I0929 09:26:45.763623  1584 layer_factory.hpp:77] Creating layer M2PELU13
I0929 09:26:45.763631  1584 net.cpp:84] Creating Layer M2PELU13
I0929 09:26:45.763633  1584 net.cpp:406] M2PELU13 <- Eltwise6
I0929 09:26:45.763638  1584 net.cpp:367] M2PELU13 -> Eltwise6 (in-place)
I0929 09:26:45.763721  1584 net.cpp:122] Setting up M2PELU13
I0929 09:26:45.763725  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.763727  1584 net.cpp:137] Memory required for data: 352173200
I0929 09:26:45.763731  1584 layer_factory.hpp:77] Creating layer Eltwise6_M2PELU13_0_split
I0929 09:26:45.763736  1584 net.cpp:84] Creating Layer Eltwise6_M2PELU13_0_split
I0929 09:26:45.763737  1584 net.cpp:406] Eltwise6_M2PELU13_0_split <- Eltwise6
I0929 09:26:45.763741  1584 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_0
I0929 09:26:45.763746  1584 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_1
I0929 09:26:45.763767  1584 net.cpp:122] Setting up Eltwise6_M2PELU13_0_split
I0929 09:26:45.763770  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.763773  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.763775  1584 net.cpp:137] Memory required for data: 362208400
I0929 09:26:45.763777  1584 layer_factory.hpp:77] Creating layer Convolution14
I0929 09:26:45.763782  1584 net.cpp:84] Creating Layer Convolution14
I0929 09:26:45.763784  1584 net.cpp:406] Convolution14 <- Eltwise6_M2PELU13_0_split_0
I0929 09:26:45.763790  1584 net.cpp:380] Convolution14 -> Convolution14
I0929 09:26:45.763865  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:45.764662  1584 net.cpp:122] Setting up Convolution14
I0929 09:26:45.764670  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.764673  1584 net.cpp:137] Memory required for data: 367226000
I0929 09:26:45.764678  1584 layer_factory.hpp:77] Creating layer BatchNorm14
I0929 09:26:45.764683  1584 net.cpp:84] Creating Layer BatchNorm14
I0929 09:26:45.764685  1584 net.cpp:406] BatchNorm14 <- Convolution14
I0929 09:26:45.764689  1584 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0929 09:26:45.764827  1584 net.cpp:122] Setting up BatchNorm14
I0929 09:26:45.764832  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.764834  1584 net.cpp:137] Memory required for data: 372243600
I0929 09:26:45.764839  1584 layer_factory.hpp:77] Creating layer Scale14
I0929 09:26:45.764843  1584 net.cpp:84] Creating Layer Scale14
I0929 09:26:45.764845  1584 net.cpp:406] Scale14 <- Convolution14
I0929 09:26:45.764848  1584 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0929 09:26:45.764874  1584 layer_factory.hpp:77] Creating layer Scale14
I0929 09:26:45.764951  1584 net.cpp:122] Setting up Scale14
I0929 09:26:45.764955  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.764957  1584 net.cpp:137] Memory required for data: 377261200
I0929 09:26:45.764961  1584 layer_factory.hpp:77] Creating layer M2PELU14
I0929 09:26:45.764966  1584 net.cpp:84] Creating Layer M2PELU14
I0929 09:26:45.764968  1584 net.cpp:406] M2PELU14 <- Convolution14
I0929 09:26:45.764972  1584 net.cpp:367] M2PELU14 -> Convolution14 (in-place)
I0929 09:26:45.765056  1584 net.cpp:122] Setting up M2PELU14
I0929 09:26:45.765060  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.765063  1584 net.cpp:137] Memory required for data: 382278800
I0929 09:26:45.765066  1584 layer_factory.hpp:77] Creating layer Convolution15
I0929 09:26:45.765072  1584 net.cpp:84] Creating Layer Convolution15
I0929 09:26:45.765074  1584 net.cpp:406] Convolution15 <- Convolution14
I0929 09:26:45.765079  1584 net.cpp:380] Convolution15 -> Convolution15
I0929 09:26:45.765156  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:45.765954  1584 net.cpp:122] Setting up Convolution15
I0929 09:26:45.765961  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.765964  1584 net.cpp:137] Memory required for data: 387296400
I0929 09:26:45.765969  1584 layer_factory.hpp:77] Creating layer BatchNorm15
I0929 09:26:45.765975  1584 net.cpp:84] Creating Layer BatchNorm15
I0929 09:26:45.765978  1584 net.cpp:406] BatchNorm15 <- Convolution15
I0929 09:26:45.765981  1584 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0929 09:26:45.766111  1584 net.cpp:122] Setting up BatchNorm15
I0929 09:26:45.766116  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.766119  1584 net.cpp:137] Memory required for data: 392314000
I0929 09:26:45.766132  1584 layer_factory.hpp:77] Creating layer Scale15
I0929 09:26:45.766137  1584 net.cpp:84] Creating Layer Scale15
I0929 09:26:45.766140  1584 net.cpp:406] Scale15 <- Convolution15
I0929 09:26:45.766144  1584 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0929 09:26:45.766170  1584 layer_factory.hpp:77] Creating layer Scale15
I0929 09:26:45.766244  1584 net.cpp:122] Setting up Scale15
I0929 09:26:45.766248  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.766250  1584 net.cpp:137] Memory required for data: 397331600
I0929 09:26:45.766254  1584 layer_factory.hpp:77] Creating layer Eltwise7
I0929 09:26:45.766258  1584 net.cpp:84] Creating Layer Eltwise7
I0929 09:26:45.766260  1584 net.cpp:406] Eltwise7 <- Eltwise6_M2PELU13_0_split_1
I0929 09:26:45.766263  1584 net.cpp:406] Eltwise7 <- Convolution15
I0929 09:26:45.766268  1584 net.cpp:380] Eltwise7 -> Eltwise7
I0929 09:26:45.766281  1584 net.cpp:122] Setting up Eltwise7
I0929 09:26:45.766286  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.766288  1584 net.cpp:137] Memory required for data: 402349200
I0929 09:26:45.766290  1584 layer_factory.hpp:77] Creating layer M2PELU15
I0929 09:26:45.766294  1584 net.cpp:84] Creating Layer M2PELU15
I0929 09:26:45.766296  1584 net.cpp:406] M2PELU15 <- Eltwise7
I0929 09:26:45.766301  1584 net.cpp:367] M2PELU15 -> Eltwise7 (in-place)
I0929 09:26:45.766386  1584 net.cpp:122] Setting up M2PELU15
I0929 09:26:45.766389  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.766391  1584 net.cpp:137] Memory required for data: 407366800
I0929 09:26:45.766394  1584 layer_factory.hpp:77] Creating layer Eltwise7_M2PELU15_0_split
I0929 09:26:45.766404  1584 net.cpp:84] Creating Layer Eltwise7_M2PELU15_0_split
I0929 09:26:45.766407  1584 net.cpp:406] Eltwise7_M2PELU15_0_split <- Eltwise7
I0929 09:26:45.766410  1584 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_0
I0929 09:26:45.766414  1584 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_1
I0929 09:26:45.766436  1584 net.cpp:122] Setting up Eltwise7_M2PELU15_0_split
I0929 09:26:45.766440  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.766443  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.766445  1584 net.cpp:137] Memory required for data: 417402000
I0929 09:26:45.766448  1584 layer_factory.hpp:77] Creating layer Convolution16
I0929 09:26:45.766453  1584 net.cpp:84] Creating Layer Convolution16
I0929 09:26:45.766456  1584 net.cpp:406] Convolution16 <- Eltwise7_M2PELU15_0_split_0
I0929 09:26:45.766459  1584 net.cpp:380] Convolution16 -> Convolution16
I0929 09:26:45.766551  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:45.767355  1584 net.cpp:122] Setting up Convolution16
I0929 09:26:45.767364  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.767366  1584 net.cpp:137] Memory required for data: 422419600
I0929 09:26:45.767371  1584 layer_factory.hpp:77] Creating layer BatchNorm16
I0929 09:26:45.767376  1584 net.cpp:84] Creating Layer BatchNorm16
I0929 09:26:45.767379  1584 net.cpp:406] BatchNorm16 <- Convolution16
I0929 09:26:45.767382  1584 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0929 09:26:45.767511  1584 net.cpp:122] Setting up BatchNorm16
I0929 09:26:45.767515  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.767518  1584 net.cpp:137] Memory required for data: 427437200
I0929 09:26:45.767524  1584 layer_factory.hpp:77] Creating layer Scale16
I0929 09:26:45.767527  1584 net.cpp:84] Creating Layer Scale16
I0929 09:26:45.767529  1584 net.cpp:406] Scale16 <- Convolution16
I0929 09:26:45.767532  1584 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0929 09:26:45.767557  1584 layer_factory.hpp:77] Creating layer Scale16
I0929 09:26:45.767633  1584 net.cpp:122] Setting up Scale16
I0929 09:26:45.767638  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.767640  1584 net.cpp:137] Memory required for data: 432454800
I0929 09:26:45.767643  1584 layer_factory.hpp:77] Creating layer M2PELU16
I0929 09:26:45.767648  1584 net.cpp:84] Creating Layer M2PELU16
I0929 09:26:45.767652  1584 net.cpp:406] M2PELU16 <- Convolution16
I0929 09:26:45.767654  1584 net.cpp:367] M2PELU16 -> Convolution16 (in-place)
I0929 09:26:45.767736  1584 net.cpp:122] Setting up M2PELU16
I0929 09:26:45.767740  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.767742  1584 net.cpp:137] Memory required for data: 437472400
I0929 09:26:45.767746  1584 layer_factory.hpp:77] Creating layer Convolution17
I0929 09:26:45.767752  1584 net.cpp:84] Creating Layer Convolution17
I0929 09:26:45.767755  1584 net.cpp:406] Convolution17 <- Convolution16
I0929 09:26:45.767760  1584 net.cpp:380] Convolution17 -> Convolution17
I0929 09:26:45.767838  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:45.768317  1584 net.cpp:122] Setting up Convolution17
I0929 09:26:45.768324  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.768327  1584 net.cpp:137] Memory required for data: 442490000
I0929 09:26:45.768332  1584 layer_factory.hpp:77] Creating layer BatchNorm17
I0929 09:26:45.768337  1584 net.cpp:84] Creating Layer BatchNorm17
I0929 09:26:45.768339  1584 net.cpp:406] BatchNorm17 <- Convolution17
I0929 09:26:45.768342  1584 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0929 09:26:45.768468  1584 net.cpp:122] Setting up BatchNorm17
I0929 09:26:45.768472  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.768476  1584 net.cpp:137] Memory required for data: 447507600
I0929 09:26:45.768479  1584 layer_factory.hpp:77] Creating layer Scale17
I0929 09:26:45.768483  1584 net.cpp:84] Creating Layer Scale17
I0929 09:26:45.768492  1584 net.cpp:406] Scale17 <- Convolution17
I0929 09:26:45.768496  1584 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0929 09:26:45.768522  1584 layer_factory.hpp:77] Creating layer Scale17
I0929 09:26:45.768597  1584 net.cpp:122] Setting up Scale17
I0929 09:26:45.768601  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.768604  1584 net.cpp:137] Memory required for data: 452525200
I0929 09:26:45.768607  1584 layer_factory.hpp:77] Creating layer Eltwise8
I0929 09:26:45.768610  1584 net.cpp:84] Creating Layer Eltwise8
I0929 09:26:45.768613  1584 net.cpp:406] Eltwise8 <- Eltwise7_M2PELU15_0_split_1
I0929 09:26:45.768616  1584 net.cpp:406] Eltwise8 <- Convolution17
I0929 09:26:45.768620  1584 net.cpp:380] Eltwise8 -> Eltwise8
I0929 09:26:45.768633  1584 net.cpp:122] Setting up Eltwise8
I0929 09:26:45.768637  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.768640  1584 net.cpp:137] Memory required for data: 457542800
I0929 09:26:45.768641  1584 layer_factory.hpp:77] Creating layer M2PELU17
I0929 09:26:45.768646  1584 net.cpp:84] Creating Layer M2PELU17
I0929 09:26:45.768648  1584 net.cpp:406] M2PELU17 <- Eltwise8
I0929 09:26:45.768651  1584 net.cpp:367] M2PELU17 -> Eltwise8 (in-place)
I0929 09:26:45.768734  1584 net.cpp:122] Setting up M2PELU17
I0929 09:26:45.768738  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.768740  1584 net.cpp:137] Memory required for data: 462560400
I0929 09:26:45.768743  1584 layer_factory.hpp:77] Creating layer Eltwise8_M2PELU17_0_split
I0929 09:26:45.768748  1584 net.cpp:84] Creating Layer Eltwise8_M2PELU17_0_split
I0929 09:26:45.768750  1584 net.cpp:406] Eltwise8_M2PELU17_0_split <- Eltwise8
I0929 09:26:45.768754  1584 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_0
I0929 09:26:45.768757  1584 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_1
I0929 09:26:45.768779  1584 net.cpp:122] Setting up Eltwise8_M2PELU17_0_split
I0929 09:26:45.768782  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.768785  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.768787  1584 net.cpp:137] Memory required for data: 472595600
I0929 09:26:45.768790  1584 layer_factory.hpp:77] Creating layer Convolution18
I0929 09:26:45.768795  1584 net.cpp:84] Creating Layer Convolution18
I0929 09:26:45.768797  1584 net.cpp:406] Convolution18 <- Eltwise8_M2PELU17_0_split_0
I0929 09:26:45.768801  1584 net.cpp:380] Convolution18 -> Convolution18
I0929 09:26:45.768877  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:45.769668  1584 net.cpp:122] Setting up Convolution18
I0929 09:26:45.769676  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.769680  1584 net.cpp:137] Memory required for data: 477613200
I0929 09:26:45.769683  1584 layer_factory.hpp:77] Creating layer BatchNorm18
I0929 09:26:45.769690  1584 net.cpp:84] Creating Layer BatchNorm18
I0929 09:26:45.769691  1584 net.cpp:406] BatchNorm18 <- Convolution18
I0929 09:26:45.769695  1584 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0929 09:26:45.769826  1584 net.cpp:122] Setting up BatchNorm18
I0929 09:26:45.769831  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.769834  1584 net.cpp:137] Memory required for data: 482630800
I0929 09:26:45.769837  1584 layer_factory.hpp:77] Creating layer Scale18
I0929 09:26:45.769841  1584 net.cpp:84] Creating Layer Scale18
I0929 09:26:45.769845  1584 net.cpp:406] Scale18 <- Convolution18
I0929 09:26:45.769848  1584 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0929 09:26:45.769872  1584 layer_factory.hpp:77] Creating layer Scale18
I0929 09:26:45.769948  1584 net.cpp:122] Setting up Scale18
I0929 09:26:45.769953  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.769954  1584 net.cpp:137] Memory required for data: 487648400
I0929 09:26:45.769958  1584 layer_factory.hpp:77] Creating layer M2PELU18
I0929 09:26:45.769963  1584 net.cpp:84] Creating Layer M2PELU18
I0929 09:26:45.769965  1584 net.cpp:406] M2PELU18 <- Convolution18
I0929 09:26:45.769974  1584 net.cpp:367] M2PELU18 -> Convolution18 (in-place)
I0929 09:26:45.770059  1584 net.cpp:122] Setting up M2PELU18
I0929 09:26:45.770063  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.770066  1584 net.cpp:137] Memory required for data: 492666000
I0929 09:26:45.770069  1584 layer_factory.hpp:77] Creating layer Convolution19
I0929 09:26:45.770076  1584 net.cpp:84] Creating Layer Convolution19
I0929 09:26:45.770078  1584 net.cpp:406] Convolution19 <- Convolution18
I0929 09:26:45.770081  1584 net.cpp:380] Convolution19 -> Convolution19
I0929 09:26:45.770159  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:45.770993  1584 net.cpp:122] Setting up Convolution19
I0929 09:26:45.771003  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.771004  1584 net.cpp:137] Memory required for data: 497683600
I0929 09:26:45.771009  1584 layer_factory.hpp:77] Creating layer BatchNorm19
I0929 09:26:45.771014  1584 net.cpp:84] Creating Layer BatchNorm19
I0929 09:26:45.771018  1584 net.cpp:406] BatchNorm19 <- Convolution19
I0929 09:26:45.771020  1584 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0929 09:26:45.771149  1584 net.cpp:122] Setting up BatchNorm19
I0929 09:26:45.771153  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.771157  1584 net.cpp:137] Memory required for data: 502701200
I0929 09:26:45.771160  1584 layer_factory.hpp:77] Creating layer Scale19
I0929 09:26:45.771164  1584 net.cpp:84] Creating Layer Scale19
I0929 09:26:45.771167  1584 net.cpp:406] Scale19 <- Convolution19
I0929 09:26:45.771170  1584 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0929 09:26:45.771196  1584 layer_factory.hpp:77] Creating layer Scale19
I0929 09:26:45.771272  1584 net.cpp:122] Setting up Scale19
I0929 09:26:45.771276  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.771278  1584 net.cpp:137] Memory required for data: 507718800
I0929 09:26:45.771282  1584 layer_factory.hpp:77] Creating layer Eltwise9
I0929 09:26:45.771286  1584 net.cpp:84] Creating Layer Eltwise9
I0929 09:26:45.771289  1584 net.cpp:406] Eltwise9 <- Eltwise8_M2PELU17_0_split_1
I0929 09:26:45.771291  1584 net.cpp:406] Eltwise9 <- Convolution19
I0929 09:26:45.771294  1584 net.cpp:380] Eltwise9 -> Eltwise9
I0929 09:26:45.771309  1584 net.cpp:122] Setting up Eltwise9
I0929 09:26:45.771313  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.771315  1584 net.cpp:137] Memory required for data: 512736400
I0929 09:26:45.771317  1584 layer_factory.hpp:77] Creating layer M2PELU19
I0929 09:26:45.771322  1584 net.cpp:84] Creating Layer M2PELU19
I0929 09:26:45.771324  1584 net.cpp:406] M2PELU19 <- Eltwise9
I0929 09:26:45.771327  1584 net.cpp:367] M2PELU19 -> Eltwise9 (in-place)
I0929 09:26:45.771409  1584 net.cpp:122] Setting up M2PELU19
I0929 09:26:45.771414  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.771416  1584 net.cpp:137] Memory required for data: 517754000
I0929 09:26:45.771420  1584 layer_factory.hpp:77] Creating layer Eltwise9_M2PELU19_0_split
I0929 09:26:45.771423  1584 net.cpp:84] Creating Layer Eltwise9_M2PELU19_0_split
I0929 09:26:45.771425  1584 net.cpp:406] Eltwise9_M2PELU19_0_split <- Eltwise9
I0929 09:26:45.771428  1584 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_0
I0929 09:26:45.771432  1584 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_1
I0929 09:26:45.771455  1584 net.cpp:122] Setting up Eltwise9_M2PELU19_0_split
I0929 09:26:45.771457  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.771461  1584 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 09:26:45.771462  1584 net.cpp:137] Memory required for data: 527789200
I0929 09:26:45.771464  1584 layer_factory.hpp:77] Creating layer Convolution20
I0929 09:26:45.771471  1584 net.cpp:84] Creating Layer Convolution20
I0929 09:26:45.771474  1584 net.cpp:406] Convolution20 <- Eltwise9_M2PELU19_0_split_0
I0929 09:26:45.771478  1584 net.cpp:380] Convolution20 -> Convolution20
I0929 09:26:45.771562  1584 filler.hpp:251] The std of weights in this layer is: 0.342997
I0929 09:26:45.772677  1584 net.cpp:122] Setting up Convolution20
I0929 09:26:45.772686  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.772688  1584 net.cpp:137] Memory required for data: 530298000
I0929 09:26:45.772693  1584 layer_factory.hpp:77] Creating layer BatchNorm20
I0929 09:26:45.772698  1584 net.cpp:84] Creating Layer BatchNorm20
I0929 09:26:45.772701  1584 net.cpp:406] BatchNorm20 <- Convolution20
I0929 09:26:45.772704  1584 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0929 09:26:45.772842  1584 net.cpp:122] Setting up BatchNorm20
I0929 09:26:45.772847  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.772850  1584 net.cpp:137] Memory required for data: 532806800
I0929 09:26:45.772853  1584 layer_factory.hpp:77] Creating layer Scale20
I0929 09:26:45.772857  1584 net.cpp:84] Creating Layer Scale20
I0929 09:26:45.772861  1584 net.cpp:406] Scale20 <- Convolution20
I0929 09:26:45.772863  1584 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0929 09:26:45.772888  1584 layer_factory.hpp:77] Creating layer Scale20
I0929 09:26:45.772974  1584 net.cpp:122] Setting up Scale20
I0929 09:26:45.772982  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.772985  1584 net.cpp:137] Memory required for data: 535315600
I0929 09:26:45.772992  1584 layer_factory.hpp:77] Creating layer Convolution21
I0929 09:26:45.773001  1584 net.cpp:84] Creating Layer Convolution21
I0929 09:26:45.773005  1584 net.cpp:406] Convolution21 <- Eltwise9_M2PELU19_0_split_1
I0929 09:26:45.773008  1584 net.cpp:380] Convolution21 -> Convolution21
I0929 09:26:45.773100  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:45.775002  1584 net.cpp:122] Setting up Convolution21
I0929 09:26:45.775010  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.775012  1584 net.cpp:137] Memory required for data: 537824400
I0929 09:26:45.775017  1584 layer_factory.hpp:77] Creating layer BatchNorm21
I0929 09:26:45.775022  1584 net.cpp:84] Creating Layer BatchNorm21
I0929 09:26:45.775025  1584 net.cpp:406] BatchNorm21 <- Convolution21
I0929 09:26:45.775029  1584 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0929 09:26:45.775167  1584 net.cpp:122] Setting up BatchNorm21
I0929 09:26:45.775171  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.775173  1584 net.cpp:137] Memory required for data: 540333200
I0929 09:26:45.775178  1584 layer_factory.hpp:77] Creating layer Scale21
I0929 09:26:45.775182  1584 net.cpp:84] Creating Layer Scale21
I0929 09:26:45.775185  1584 net.cpp:406] Scale21 <- Convolution21
I0929 09:26:45.775188  1584 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0929 09:26:45.775214  1584 layer_factory.hpp:77] Creating layer Scale21
I0929 09:26:45.775313  1584 net.cpp:122] Setting up Scale21
I0929 09:26:45.775319  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.775321  1584 net.cpp:137] Memory required for data: 542842000
I0929 09:26:45.775326  1584 layer_factory.hpp:77] Creating layer M2PELU20
I0929 09:26:45.775331  1584 net.cpp:84] Creating Layer M2PELU20
I0929 09:26:45.775334  1584 net.cpp:406] M2PELU20 <- Convolution21
I0929 09:26:45.775338  1584 net.cpp:367] M2PELU20 -> Convolution21 (in-place)
I0929 09:26:45.775452  1584 net.cpp:122] Setting up M2PELU20
I0929 09:26:45.775460  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.775461  1584 net.cpp:137] Memory required for data: 545350800
I0929 09:26:45.775465  1584 layer_factory.hpp:77] Creating layer Convolution22
I0929 09:26:45.775473  1584 net.cpp:84] Creating Layer Convolution22
I0929 09:26:45.775476  1584 net.cpp:406] Convolution22 <- Convolution21
I0929 09:26:45.775480  1584 net.cpp:380] Convolution22 -> Convolution22
I0929 09:26:45.775565  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:45.776684  1584 net.cpp:122] Setting up Convolution22
I0929 09:26:45.776692  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.776703  1584 net.cpp:137] Memory required for data: 547859600
I0929 09:26:45.776708  1584 layer_factory.hpp:77] Creating layer BatchNorm22
I0929 09:26:45.776715  1584 net.cpp:84] Creating Layer BatchNorm22
I0929 09:26:45.776716  1584 net.cpp:406] BatchNorm22 <- Convolution22
I0929 09:26:45.776721  1584 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0929 09:26:45.776852  1584 net.cpp:122] Setting up BatchNorm22
I0929 09:26:45.776856  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.776859  1584 net.cpp:137] Memory required for data: 550368400
I0929 09:26:45.776863  1584 layer_factory.hpp:77] Creating layer Scale22
I0929 09:26:45.776868  1584 net.cpp:84] Creating Layer Scale22
I0929 09:26:45.776870  1584 net.cpp:406] Scale22 <- Convolution22
I0929 09:26:45.776873  1584 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0929 09:26:45.776899  1584 layer_factory.hpp:77] Creating layer Scale22
I0929 09:26:45.776974  1584 net.cpp:122] Setting up Scale22
I0929 09:26:45.776978  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.776980  1584 net.cpp:137] Memory required for data: 552877200
I0929 09:26:45.776984  1584 layer_factory.hpp:77] Creating layer Eltwise10
I0929 09:26:45.776988  1584 net.cpp:84] Creating Layer Eltwise10
I0929 09:26:45.776990  1584 net.cpp:406] Eltwise10 <- Convolution20
I0929 09:26:45.776993  1584 net.cpp:406] Eltwise10 <- Convolution22
I0929 09:26:45.776998  1584 net.cpp:380] Eltwise10 -> Eltwise10
I0929 09:26:45.777012  1584 net.cpp:122] Setting up Eltwise10
I0929 09:26:45.777015  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.777017  1584 net.cpp:137] Memory required for data: 555386000
I0929 09:26:45.777019  1584 layer_factory.hpp:77] Creating layer M2PELU21
I0929 09:26:45.777024  1584 net.cpp:84] Creating Layer M2PELU21
I0929 09:26:45.777026  1584 net.cpp:406] M2PELU21 <- Eltwise10
I0929 09:26:45.777029  1584 net.cpp:367] M2PELU21 -> Eltwise10 (in-place)
I0929 09:26:45.777110  1584 net.cpp:122] Setting up M2PELU21
I0929 09:26:45.777114  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.777117  1584 net.cpp:137] Memory required for data: 557894800
I0929 09:26:45.777120  1584 layer_factory.hpp:77] Creating layer Eltwise10_M2PELU21_0_split
I0929 09:26:45.777124  1584 net.cpp:84] Creating Layer Eltwise10_M2PELU21_0_split
I0929 09:26:45.777127  1584 net.cpp:406] Eltwise10_M2PELU21_0_split <- Eltwise10
I0929 09:26:45.777130  1584 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_0
I0929 09:26:45.777134  1584 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_1
I0929 09:26:45.777156  1584 net.cpp:122] Setting up Eltwise10_M2PELU21_0_split
I0929 09:26:45.777160  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.777163  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.777165  1584 net.cpp:137] Memory required for data: 562912400
I0929 09:26:45.777168  1584 layer_factory.hpp:77] Creating layer Convolution23
I0929 09:26:45.777173  1584 net.cpp:84] Creating Layer Convolution23
I0929 09:26:45.777175  1584 net.cpp:406] Convolution23 <- Eltwise10_M2PELU21_0_split_0
I0929 09:26:45.777179  1584 net.cpp:380] Convolution23 -> Convolution23
I0929 09:26:45.777256  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:45.778514  1584 net.cpp:122] Setting up Convolution23
I0929 09:26:45.778537  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.778540  1584 net.cpp:137] Memory required for data: 565421200
I0929 09:26:45.778545  1584 layer_factory.hpp:77] Creating layer BatchNorm23
I0929 09:26:45.778550  1584 net.cpp:84] Creating Layer BatchNorm23
I0929 09:26:45.778553  1584 net.cpp:406] BatchNorm23 <- Convolution23
I0929 09:26:45.778556  1584 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0929 09:26:45.778702  1584 net.cpp:122] Setting up BatchNorm23
I0929 09:26:45.778707  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.778708  1584 net.cpp:137] Memory required for data: 567930000
I0929 09:26:45.778712  1584 layer_factory.hpp:77] Creating layer Scale23
I0929 09:26:45.778723  1584 net.cpp:84] Creating Layer Scale23
I0929 09:26:45.778726  1584 net.cpp:406] Scale23 <- Convolution23
I0929 09:26:45.778729  1584 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0929 09:26:45.778758  1584 layer_factory.hpp:77] Creating layer Scale23
I0929 09:26:45.778833  1584 net.cpp:122] Setting up Scale23
I0929 09:26:45.778838  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.778841  1584 net.cpp:137] Memory required for data: 570438800
I0929 09:26:45.778844  1584 layer_factory.hpp:77] Creating layer M2PELU22
I0929 09:26:45.778849  1584 net.cpp:84] Creating Layer M2PELU22
I0929 09:26:45.778851  1584 net.cpp:406] M2PELU22 <- Convolution23
I0929 09:26:45.778856  1584 net.cpp:367] M2PELU22 -> Convolution23 (in-place)
I0929 09:26:45.778937  1584 net.cpp:122] Setting up M2PELU22
I0929 09:26:45.778941  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.778944  1584 net.cpp:137] Memory required for data: 572947600
I0929 09:26:45.778946  1584 layer_factory.hpp:77] Creating layer Convolution24
I0929 09:26:45.778954  1584 net.cpp:84] Creating Layer Convolution24
I0929 09:26:45.778955  1584 net.cpp:406] Convolution24 <- Convolution23
I0929 09:26:45.778960  1584 net.cpp:380] Convolution24 -> Convolution24
I0929 09:26:45.779037  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:45.779992  1584 net.cpp:122] Setting up Convolution24
I0929 09:26:45.780001  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.780004  1584 net.cpp:137] Memory required for data: 575456400
I0929 09:26:45.780009  1584 layer_factory.hpp:77] Creating layer BatchNorm24
I0929 09:26:45.780014  1584 net.cpp:84] Creating Layer BatchNorm24
I0929 09:26:45.780016  1584 net.cpp:406] BatchNorm24 <- Convolution24
I0929 09:26:45.780020  1584 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0929 09:26:45.780153  1584 net.cpp:122] Setting up BatchNorm24
I0929 09:26:45.780156  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.780158  1584 net.cpp:137] Memory required for data: 577965200
I0929 09:26:45.780164  1584 layer_factory.hpp:77] Creating layer Scale24
I0929 09:26:45.780167  1584 net.cpp:84] Creating Layer Scale24
I0929 09:26:45.780170  1584 net.cpp:406] Scale24 <- Convolution24
I0929 09:26:45.780174  1584 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0929 09:26:45.780200  1584 layer_factory.hpp:77] Creating layer Scale24
I0929 09:26:45.780277  1584 net.cpp:122] Setting up Scale24
I0929 09:26:45.780280  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.780282  1584 net.cpp:137] Memory required for data: 580474000
I0929 09:26:45.780287  1584 layer_factory.hpp:77] Creating layer Eltwise11
I0929 09:26:45.780290  1584 net.cpp:84] Creating Layer Eltwise11
I0929 09:26:45.780293  1584 net.cpp:406] Eltwise11 <- Eltwise10_M2PELU21_0_split_1
I0929 09:26:45.780297  1584 net.cpp:406] Eltwise11 <- Convolution24
I0929 09:26:45.780299  1584 net.cpp:380] Eltwise11 -> Eltwise11
I0929 09:26:45.780314  1584 net.cpp:122] Setting up Eltwise11
I0929 09:26:45.780318  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.780320  1584 net.cpp:137] Memory required for data: 582982800
I0929 09:26:45.780323  1584 layer_factory.hpp:77] Creating layer M2PELU23
I0929 09:26:45.780328  1584 net.cpp:84] Creating Layer M2PELU23
I0929 09:26:45.780329  1584 net.cpp:406] M2PELU23 <- Eltwise11
I0929 09:26:45.780333  1584 net.cpp:367] M2PELU23 -> Eltwise11 (in-place)
I0929 09:26:45.780413  1584 net.cpp:122] Setting up M2PELU23
I0929 09:26:45.780417  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.780419  1584 net.cpp:137] Memory required for data: 585491600
I0929 09:26:45.780423  1584 layer_factory.hpp:77] Creating layer Eltwise11_M2PELU23_0_split
I0929 09:26:45.780427  1584 net.cpp:84] Creating Layer Eltwise11_M2PELU23_0_split
I0929 09:26:45.780429  1584 net.cpp:406] Eltwise11_M2PELU23_0_split <- Eltwise11
I0929 09:26:45.780432  1584 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_0
I0929 09:26:45.780442  1584 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_1
I0929 09:26:45.780467  1584 net.cpp:122] Setting up Eltwise11_M2PELU23_0_split
I0929 09:26:45.780470  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.780473  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.780475  1584 net.cpp:137] Memory required for data: 590509200
I0929 09:26:45.780478  1584 layer_factory.hpp:77] Creating layer Convolution25
I0929 09:26:45.780483  1584 net.cpp:84] Creating Layer Convolution25
I0929 09:26:45.780485  1584 net.cpp:406] Convolution25 <- Eltwise11_M2PELU23_0_split_0
I0929 09:26:45.780490  1584 net.cpp:380] Convolution25 -> Convolution25
I0929 09:26:45.780568  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:45.781523  1584 net.cpp:122] Setting up Convolution25
I0929 09:26:45.781532  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.781534  1584 net.cpp:137] Memory required for data: 593018000
I0929 09:26:45.781538  1584 layer_factory.hpp:77] Creating layer BatchNorm25
I0929 09:26:45.781543  1584 net.cpp:84] Creating Layer BatchNorm25
I0929 09:26:45.781546  1584 net.cpp:406] BatchNorm25 <- Convolution25
I0929 09:26:45.781549  1584 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0929 09:26:45.781682  1584 net.cpp:122] Setting up BatchNorm25
I0929 09:26:45.781687  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.781689  1584 net.cpp:137] Memory required for data: 595526800
I0929 09:26:45.781693  1584 layer_factory.hpp:77] Creating layer Scale25
I0929 09:26:45.781697  1584 net.cpp:84] Creating Layer Scale25
I0929 09:26:45.781700  1584 net.cpp:406] Scale25 <- Convolution25
I0929 09:26:45.781703  1584 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0929 09:26:45.781729  1584 layer_factory.hpp:77] Creating layer Scale25
I0929 09:26:45.781803  1584 net.cpp:122] Setting up Scale25
I0929 09:26:45.781807  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.781810  1584 net.cpp:137] Memory required for data: 598035600
I0929 09:26:45.781813  1584 layer_factory.hpp:77] Creating layer M2PELU24
I0929 09:26:45.781818  1584 net.cpp:84] Creating Layer M2PELU24
I0929 09:26:45.781821  1584 net.cpp:406] M2PELU24 <- Convolution25
I0929 09:26:45.781823  1584 net.cpp:367] M2PELU24 -> Convolution25 (in-place)
I0929 09:26:45.781908  1584 net.cpp:122] Setting up M2PELU24
I0929 09:26:45.781911  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.781913  1584 net.cpp:137] Memory required for data: 600544400
I0929 09:26:45.781918  1584 layer_factory.hpp:77] Creating layer Convolution26
I0929 09:26:45.781924  1584 net.cpp:84] Creating Layer Convolution26
I0929 09:26:45.781925  1584 net.cpp:406] Convolution26 <- Convolution25
I0929 09:26:45.781930  1584 net.cpp:380] Convolution26 -> Convolution26
I0929 09:26:45.782009  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:45.782985  1584 net.cpp:122] Setting up Convolution26
I0929 09:26:45.782994  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.782996  1584 net.cpp:137] Memory required for data: 603053200
I0929 09:26:45.783001  1584 layer_factory.hpp:77] Creating layer BatchNorm26
I0929 09:26:45.783006  1584 net.cpp:84] Creating Layer BatchNorm26
I0929 09:26:45.783008  1584 net.cpp:406] BatchNorm26 <- Convolution26
I0929 09:26:45.783012  1584 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0929 09:26:45.783145  1584 net.cpp:122] Setting up BatchNorm26
I0929 09:26:45.783150  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.783152  1584 net.cpp:137] Memory required for data: 605562000
I0929 09:26:45.783157  1584 layer_factory.hpp:77] Creating layer Scale26
I0929 09:26:45.783161  1584 net.cpp:84] Creating Layer Scale26
I0929 09:26:45.783164  1584 net.cpp:406] Scale26 <- Convolution26
I0929 09:26:45.783167  1584 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0929 09:26:45.783193  1584 layer_factory.hpp:77] Creating layer Scale26
I0929 09:26:45.783268  1584 net.cpp:122] Setting up Scale26
I0929 09:26:45.783278  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.783282  1584 net.cpp:137] Memory required for data: 608070800
I0929 09:26:45.783284  1584 layer_factory.hpp:77] Creating layer Eltwise12
I0929 09:26:45.783289  1584 net.cpp:84] Creating Layer Eltwise12
I0929 09:26:45.783293  1584 net.cpp:406] Eltwise12 <- Eltwise11_M2PELU23_0_split_1
I0929 09:26:45.783295  1584 net.cpp:406] Eltwise12 <- Convolution26
I0929 09:26:45.783298  1584 net.cpp:380] Eltwise12 -> Eltwise12
I0929 09:26:45.783315  1584 net.cpp:122] Setting up Eltwise12
I0929 09:26:45.783318  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.783320  1584 net.cpp:137] Memory required for data: 610579600
I0929 09:26:45.783323  1584 layer_factory.hpp:77] Creating layer M2PELU25
I0929 09:26:45.783327  1584 net.cpp:84] Creating Layer M2PELU25
I0929 09:26:45.783329  1584 net.cpp:406] M2PELU25 <- Eltwise12
I0929 09:26:45.783334  1584 net.cpp:367] M2PELU25 -> Eltwise12 (in-place)
I0929 09:26:45.783414  1584 net.cpp:122] Setting up M2PELU25
I0929 09:26:45.783419  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.783421  1584 net.cpp:137] Memory required for data: 613088400
I0929 09:26:45.783424  1584 layer_factory.hpp:77] Creating layer Eltwise12_M2PELU25_0_split
I0929 09:26:45.783437  1584 net.cpp:84] Creating Layer Eltwise12_M2PELU25_0_split
I0929 09:26:45.783438  1584 net.cpp:406] Eltwise12_M2PELU25_0_split <- Eltwise12
I0929 09:26:45.783442  1584 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_0
I0929 09:26:45.783450  1584 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_1
I0929 09:26:45.783474  1584 net.cpp:122] Setting up Eltwise12_M2PELU25_0_split
I0929 09:26:45.783479  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.783483  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.783483  1584 net.cpp:137] Memory required for data: 618106000
I0929 09:26:45.783486  1584 layer_factory.hpp:77] Creating layer Convolution27
I0929 09:26:45.783494  1584 net.cpp:84] Creating Layer Convolution27
I0929 09:26:45.783496  1584 net.cpp:406] Convolution27 <- Eltwise12_M2PELU25_0_split_0
I0929 09:26:45.783500  1584 net.cpp:380] Convolution27 -> Convolution27
I0929 09:26:45.783581  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:45.784221  1584 net.cpp:122] Setting up Convolution27
I0929 09:26:45.784229  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.784230  1584 net.cpp:137] Memory required for data: 620614800
I0929 09:26:45.784235  1584 layer_factory.hpp:77] Creating layer BatchNorm27
I0929 09:26:45.784240  1584 net.cpp:84] Creating Layer BatchNorm27
I0929 09:26:45.784243  1584 net.cpp:406] BatchNorm27 <- Convolution27
I0929 09:26:45.784246  1584 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0929 09:26:45.784379  1584 net.cpp:122] Setting up BatchNorm27
I0929 09:26:45.784384  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.784385  1584 net.cpp:137] Memory required for data: 623123600
I0929 09:26:45.784390  1584 layer_factory.hpp:77] Creating layer Scale27
I0929 09:26:45.784394  1584 net.cpp:84] Creating Layer Scale27
I0929 09:26:45.784396  1584 net.cpp:406] Scale27 <- Convolution27
I0929 09:26:45.784399  1584 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0929 09:26:45.784425  1584 layer_factory.hpp:77] Creating layer Scale27
I0929 09:26:45.784499  1584 net.cpp:122] Setting up Scale27
I0929 09:26:45.784502  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.784504  1584 net.cpp:137] Memory required for data: 625632400
I0929 09:26:45.784508  1584 layer_factory.hpp:77] Creating layer M2PELU26
I0929 09:26:45.784513  1584 net.cpp:84] Creating Layer M2PELU26
I0929 09:26:45.784515  1584 net.cpp:406] M2PELU26 <- Convolution27
I0929 09:26:45.784518  1584 net.cpp:367] M2PELU26 -> Convolution27 (in-place)
I0929 09:26:45.784600  1584 net.cpp:122] Setting up M2PELU26
I0929 09:26:45.784603  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.784612  1584 net.cpp:137] Memory required for data: 628141200
I0929 09:26:45.784616  1584 layer_factory.hpp:77] Creating layer Convolution28
I0929 09:26:45.784623  1584 net.cpp:84] Creating Layer Convolution28
I0929 09:26:45.784626  1584 net.cpp:406] Convolution28 <- Convolution27
I0929 09:26:45.784629  1584 net.cpp:380] Convolution28 -> Convolution28
I0929 09:26:45.784711  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:45.785663  1584 net.cpp:122] Setting up Convolution28
I0929 09:26:45.785671  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.785676  1584 net.cpp:137] Memory required for data: 630650000
I0929 09:26:45.785681  1584 layer_factory.hpp:77] Creating layer BatchNorm28
I0929 09:26:45.785684  1584 net.cpp:84] Creating Layer BatchNorm28
I0929 09:26:45.785687  1584 net.cpp:406] BatchNorm28 <- Convolution28
I0929 09:26:45.785691  1584 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0929 09:26:45.785827  1584 net.cpp:122] Setting up BatchNorm28
I0929 09:26:45.785831  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.785833  1584 net.cpp:137] Memory required for data: 633158800
I0929 09:26:45.785838  1584 layer_factory.hpp:77] Creating layer Scale28
I0929 09:26:45.785842  1584 net.cpp:84] Creating Layer Scale28
I0929 09:26:45.785845  1584 net.cpp:406] Scale28 <- Convolution28
I0929 09:26:45.785847  1584 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0929 09:26:45.785873  1584 layer_factory.hpp:77] Creating layer Scale28
I0929 09:26:45.785951  1584 net.cpp:122] Setting up Scale28
I0929 09:26:45.785955  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.785957  1584 net.cpp:137] Memory required for data: 635667600
I0929 09:26:45.785961  1584 layer_factory.hpp:77] Creating layer Eltwise13
I0929 09:26:45.785965  1584 net.cpp:84] Creating Layer Eltwise13
I0929 09:26:45.785967  1584 net.cpp:406] Eltwise13 <- Eltwise12_M2PELU25_0_split_1
I0929 09:26:45.785970  1584 net.cpp:406] Eltwise13 <- Convolution28
I0929 09:26:45.785974  1584 net.cpp:380] Eltwise13 -> Eltwise13
I0929 09:26:45.785989  1584 net.cpp:122] Setting up Eltwise13
I0929 09:26:45.785993  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.785995  1584 net.cpp:137] Memory required for data: 638176400
I0929 09:26:45.785997  1584 layer_factory.hpp:77] Creating layer M2PELU27
I0929 09:26:45.786002  1584 net.cpp:84] Creating Layer M2PELU27
I0929 09:26:45.786005  1584 net.cpp:406] M2PELU27 <- Eltwise13
I0929 09:26:45.786008  1584 net.cpp:367] M2PELU27 -> Eltwise13 (in-place)
I0929 09:26:45.786092  1584 net.cpp:122] Setting up M2PELU27
I0929 09:26:45.786095  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.786098  1584 net.cpp:137] Memory required for data: 640685200
I0929 09:26:45.786101  1584 layer_factory.hpp:77] Creating layer Eltwise13_M2PELU27_0_split
I0929 09:26:45.786105  1584 net.cpp:84] Creating Layer Eltwise13_M2PELU27_0_split
I0929 09:26:45.786108  1584 net.cpp:406] Eltwise13_M2PELU27_0_split <- Eltwise13
I0929 09:26:45.786111  1584 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_0
I0929 09:26:45.786115  1584 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_1
I0929 09:26:45.786139  1584 net.cpp:122] Setting up Eltwise13_M2PELU27_0_split
I0929 09:26:45.786142  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.786144  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.786146  1584 net.cpp:137] Memory required for data: 645702800
I0929 09:26:45.786149  1584 layer_factory.hpp:77] Creating layer Convolution29
I0929 09:26:45.786154  1584 net.cpp:84] Creating Layer Convolution29
I0929 09:26:45.786157  1584 net.cpp:406] Convolution29 <- Eltwise13_M2PELU27_0_split_0
I0929 09:26:45.786160  1584 net.cpp:380] Convolution29 -> Convolution29
I0929 09:26:45.786240  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:45.787215  1584 net.cpp:122] Setting up Convolution29
I0929 09:26:45.787225  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.787232  1584 net.cpp:137] Memory required for data: 648211600
I0929 09:26:45.787237  1584 layer_factory.hpp:77] Creating layer BatchNorm29
I0929 09:26:45.787243  1584 net.cpp:84] Creating Layer BatchNorm29
I0929 09:26:45.787246  1584 net.cpp:406] BatchNorm29 <- Convolution29
I0929 09:26:45.787250  1584 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0929 09:26:45.787384  1584 net.cpp:122] Setting up BatchNorm29
I0929 09:26:45.787389  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.787391  1584 net.cpp:137] Memory required for data: 650720400
I0929 09:26:45.787395  1584 layer_factory.hpp:77] Creating layer Scale29
I0929 09:26:45.787400  1584 net.cpp:84] Creating Layer Scale29
I0929 09:26:45.787403  1584 net.cpp:406] Scale29 <- Convolution29
I0929 09:26:45.787406  1584 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0929 09:26:45.787432  1584 layer_factory.hpp:77] Creating layer Scale29
I0929 09:26:45.787511  1584 net.cpp:122] Setting up Scale29
I0929 09:26:45.787515  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.787518  1584 net.cpp:137] Memory required for data: 653229200
I0929 09:26:45.787536  1584 layer_factory.hpp:77] Creating layer M2PELU28
I0929 09:26:45.787542  1584 net.cpp:84] Creating Layer M2PELU28
I0929 09:26:45.787545  1584 net.cpp:406] M2PELU28 <- Convolution29
I0929 09:26:45.787549  1584 net.cpp:367] M2PELU28 -> Convolution29 (in-place)
I0929 09:26:45.787633  1584 net.cpp:122] Setting up M2PELU28
I0929 09:26:45.787638  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.787641  1584 net.cpp:137] Memory required for data: 655738000
I0929 09:26:45.787643  1584 layer_factory.hpp:77] Creating layer Convolution30
I0929 09:26:45.787650  1584 net.cpp:84] Creating Layer Convolution30
I0929 09:26:45.787653  1584 net.cpp:406] Convolution30 <- Convolution29
I0929 09:26:45.787657  1584 net.cpp:380] Convolution30 -> Convolution30
I0929 09:26:45.787739  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:45.788693  1584 net.cpp:122] Setting up Convolution30
I0929 09:26:45.788702  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.788704  1584 net.cpp:137] Memory required for data: 658246800
I0929 09:26:45.788708  1584 layer_factory.hpp:77] Creating layer BatchNorm30
I0929 09:26:45.788714  1584 net.cpp:84] Creating Layer BatchNorm30
I0929 09:26:45.788717  1584 net.cpp:406] BatchNorm30 <- Convolution30
I0929 09:26:45.788722  1584 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0929 09:26:45.788856  1584 net.cpp:122] Setting up BatchNorm30
I0929 09:26:45.788859  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.788861  1584 net.cpp:137] Memory required for data: 660755600
I0929 09:26:45.788866  1584 layer_factory.hpp:77] Creating layer Scale30
I0929 09:26:45.788871  1584 net.cpp:84] Creating Layer Scale30
I0929 09:26:45.788873  1584 net.cpp:406] Scale30 <- Convolution30
I0929 09:26:45.788877  1584 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0929 09:26:45.788902  1584 layer_factory.hpp:77] Creating layer Scale30
I0929 09:26:45.788980  1584 net.cpp:122] Setting up Scale30
I0929 09:26:45.788983  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.788985  1584 net.cpp:137] Memory required for data: 663264400
I0929 09:26:45.788988  1584 layer_factory.hpp:77] Creating layer Eltwise14
I0929 09:26:45.788995  1584 net.cpp:84] Creating Layer Eltwise14
I0929 09:26:45.788997  1584 net.cpp:406] Eltwise14 <- Eltwise13_M2PELU27_0_split_1
I0929 09:26:45.789000  1584 net.cpp:406] Eltwise14 <- Convolution30
I0929 09:26:45.789003  1584 net.cpp:380] Eltwise14 -> Eltwise14
I0929 09:26:45.789018  1584 net.cpp:122] Setting up Eltwise14
I0929 09:26:45.789022  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.789024  1584 net.cpp:137] Memory required for data: 665773200
I0929 09:26:45.789026  1584 layer_factory.hpp:77] Creating layer M2PELU29
I0929 09:26:45.789031  1584 net.cpp:84] Creating Layer M2PELU29
I0929 09:26:45.789033  1584 net.cpp:406] M2PELU29 <- Eltwise14
I0929 09:26:45.789042  1584 net.cpp:367] M2PELU29 -> Eltwise14 (in-place)
I0929 09:26:45.789129  1584 net.cpp:122] Setting up M2PELU29
I0929 09:26:45.789132  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.789134  1584 net.cpp:137] Memory required for data: 668282000
I0929 09:26:45.789139  1584 layer_factory.hpp:77] Creating layer Eltwise14_M2PELU29_0_split
I0929 09:26:45.789141  1584 net.cpp:84] Creating Layer Eltwise14_M2PELU29_0_split
I0929 09:26:45.789144  1584 net.cpp:406] Eltwise14_M2PELU29_0_split <- Eltwise14
I0929 09:26:45.789147  1584 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_0
I0929 09:26:45.789151  1584 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_1
I0929 09:26:45.789175  1584 net.cpp:122] Setting up Eltwise14_M2PELU29_0_split
I0929 09:26:45.789177  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.789180  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.789182  1584 net.cpp:137] Memory required for data: 673299600
I0929 09:26:45.789185  1584 layer_factory.hpp:77] Creating layer Convolution31
I0929 09:26:45.789191  1584 net.cpp:84] Creating Layer Convolution31
I0929 09:26:45.789192  1584 net.cpp:406] Convolution31 <- Eltwise14_M2PELU29_0_split_0
I0929 09:26:45.789196  1584 net.cpp:380] Convolution31 -> Convolution31
I0929 09:26:45.789276  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:45.790233  1584 net.cpp:122] Setting up Convolution31
I0929 09:26:45.790241  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.790244  1584 net.cpp:137] Memory required for data: 675808400
I0929 09:26:45.790248  1584 layer_factory.hpp:77] Creating layer BatchNorm31
I0929 09:26:45.790253  1584 net.cpp:84] Creating Layer BatchNorm31
I0929 09:26:45.790256  1584 net.cpp:406] BatchNorm31 <- Convolution31
I0929 09:26:45.790261  1584 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0929 09:26:45.790395  1584 net.cpp:122] Setting up BatchNorm31
I0929 09:26:45.790398  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.790400  1584 net.cpp:137] Memory required for data: 678317200
I0929 09:26:45.790405  1584 layer_factory.hpp:77] Creating layer Scale31
I0929 09:26:45.790410  1584 net.cpp:84] Creating Layer Scale31
I0929 09:26:45.790411  1584 net.cpp:406] Scale31 <- Convolution31
I0929 09:26:45.790416  1584 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0929 09:26:45.790441  1584 layer_factory.hpp:77] Creating layer Scale31
I0929 09:26:45.790518  1584 net.cpp:122] Setting up Scale31
I0929 09:26:45.790537  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.790539  1584 net.cpp:137] Memory required for data: 680826000
I0929 09:26:45.790544  1584 layer_factory.hpp:77] Creating layer M2PELU30
I0929 09:26:45.790549  1584 net.cpp:84] Creating Layer M2PELU30
I0929 09:26:45.790551  1584 net.cpp:406] M2PELU30 <- Convolution31
I0929 09:26:45.790563  1584 net.cpp:367] M2PELU30 -> Convolution31 (in-place)
I0929 09:26:45.790650  1584 net.cpp:122] Setting up M2PELU30
I0929 09:26:45.790654  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.790657  1584 net.cpp:137] Memory required for data: 683334800
I0929 09:26:45.790659  1584 layer_factory.hpp:77] Creating layer Convolution32
I0929 09:26:45.790668  1584 net.cpp:84] Creating Layer Convolution32
I0929 09:26:45.790669  1584 net.cpp:406] Convolution32 <- Convolution31
I0929 09:26:45.790673  1584 net.cpp:380] Convolution32 -> Convolution32
I0929 09:26:45.790755  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:45.791710  1584 net.cpp:122] Setting up Convolution32
I0929 09:26:45.791719  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.791721  1584 net.cpp:137] Memory required for data: 685843600
I0929 09:26:45.791726  1584 layer_factory.hpp:77] Creating layer BatchNorm32
I0929 09:26:45.791731  1584 net.cpp:84] Creating Layer BatchNorm32
I0929 09:26:45.791734  1584 net.cpp:406] BatchNorm32 <- Convolution32
I0929 09:26:45.791738  1584 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I0929 09:26:45.791877  1584 net.cpp:122] Setting up BatchNorm32
I0929 09:26:45.791882  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.791883  1584 net.cpp:137] Memory required for data: 688352400
I0929 09:26:45.791889  1584 layer_factory.hpp:77] Creating layer Scale32
I0929 09:26:45.791893  1584 net.cpp:84] Creating Layer Scale32
I0929 09:26:45.791895  1584 net.cpp:406] Scale32 <- Convolution32
I0929 09:26:45.791898  1584 net.cpp:367] Scale32 -> Convolution32 (in-place)
I0929 09:26:45.791925  1584 layer_factory.hpp:77] Creating layer Scale32
I0929 09:26:45.792001  1584 net.cpp:122] Setting up Scale32
I0929 09:26:45.792004  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.792006  1584 net.cpp:137] Memory required for data: 690861200
I0929 09:26:45.792011  1584 layer_factory.hpp:77] Creating layer Eltwise15
I0929 09:26:45.792014  1584 net.cpp:84] Creating Layer Eltwise15
I0929 09:26:45.792017  1584 net.cpp:406] Eltwise15 <- Eltwise14_M2PELU29_0_split_1
I0929 09:26:45.792019  1584 net.cpp:406] Eltwise15 <- Convolution32
I0929 09:26:45.792023  1584 net.cpp:380] Eltwise15 -> Eltwise15
I0929 09:26:45.792038  1584 net.cpp:122] Setting up Eltwise15
I0929 09:26:45.792042  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.792043  1584 net.cpp:137] Memory required for data: 693370000
I0929 09:26:45.792047  1584 layer_factory.hpp:77] Creating layer M2PELU31
I0929 09:26:45.792050  1584 net.cpp:84] Creating Layer M2PELU31
I0929 09:26:45.792053  1584 net.cpp:406] M2PELU31 <- Eltwise15
I0929 09:26:45.792057  1584 net.cpp:367] M2PELU31 -> Eltwise15 (in-place)
I0929 09:26:45.792140  1584 net.cpp:122] Setting up M2PELU31
I0929 09:26:45.792143  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.792145  1584 net.cpp:137] Memory required for data: 695878800
I0929 09:26:45.792148  1584 layer_factory.hpp:77] Creating layer Eltwise15_M2PELU31_0_split
I0929 09:26:45.792153  1584 net.cpp:84] Creating Layer Eltwise15_M2PELU31_0_split
I0929 09:26:45.792155  1584 net.cpp:406] Eltwise15_M2PELU31_0_split <- Eltwise15
I0929 09:26:45.792158  1584 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_0
I0929 09:26:45.792162  1584 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_1
I0929 09:26:45.792186  1584 net.cpp:122] Setting up Eltwise15_M2PELU31_0_split
I0929 09:26:45.792189  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.792191  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.792193  1584 net.cpp:137] Memory required for data: 700896400
I0929 09:26:45.792196  1584 layer_factory.hpp:77] Creating layer Convolution33
I0929 09:26:45.792202  1584 net.cpp:84] Creating Layer Convolution33
I0929 09:26:45.792204  1584 net.cpp:406] Convolution33 <- Eltwise15_M2PELU31_0_split_0
I0929 09:26:45.792208  1584 net.cpp:380] Convolution33 -> Convolution33
I0929 09:26:45.792289  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:45.793560  1584 net.cpp:122] Setting up Convolution33
I0929 09:26:45.793567  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.793570  1584 net.cpp:137] Memory required for data: 703405200
I0929 09:26:45.793575  1584 layer_factory.hpp:77] Creating layer BatchNorm33
I0929 09:26:45.793581  1584 net.cpp:84] Creating Layer BatchNorm33
I0929 09:26:45.793582  1584 net.cpp:406] BatchNorm33 <- Convolution33
I0929 09:26:45.793586  1584 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I0929 09:26:45.793727  1584 net.cpp:122] Setting up BatchNorm33
I0929 09:26:45.793732  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.793735  1584 net.cpp:137] Memory required for data: 705914000
I0929 09:26:45.793740  1584 layer_factory.hpp:77] Creating layer Scale33
I0929 09:26:45.793743  1584 net.cpp:84] Creating Layer Scale33
I0929 09:26:45.793745  1584 net.cpp:406] Scale33 <- Convolution33
I0929 09:26:45.793748  1584 net.cpp:367] Scale33 -> Convolution33 (in-place)
I0929 09:26:45.793776  1584 layer_factory.hpp:77] Creating layer Scale33
I0929 09:26:45.793861  1584 net.cpp:122] Setting up Scale33
I0929 09:26:45.793866  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.793869  1584 net.cpp:137] Memory required for data: 708422800
I0929 09:26:45.793872  1584 layer_factory.hpp:77] Creating layer M2PELU32
I0929 09:26:45.793877  1584 net.cpp:84] Creating Layer M2PELU32
I0929 09:26:45.793880  1584 net.cpp:406] M2PELU32 <- Convolution33
I0929 09:26:45.793884  1584 net.cpp:367] M2PELU32 -> Convolution33 (in-place)
I0929 09:26:45.793967  1584 net.cpp:122] Setting up M2PELU32
I0929 09:26:45.793970  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.793972  1584 net.cpp:137] Memory required for data: 710931600
I0929 09:26:45.793975  1584 layer_factory.hpp:77] Creating layer Convolution34
I0929 09:26:45.793982  1584 net.cpp:84] Creating Layer Convolution34
I0929 09:26:45.793984  1584 net.cpp:406] Convolution34 <- Convolution33
I0929 09:26:45.793989  1584 net.cpp:380] Convolution34 -> Convolution34
I0929 09:26:45.794070  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:45.795063  1584 net.cpp:122] Setting up Convolution34
I0929 09:26:45.795071  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.795074  1584 net.cpp:137] Memory required for data: 713440400
I0929 09:26:45.795078  1584 layer_factory.hpp:77] Creating layer BatchNorm34
I0929 09:26:45.795084  1584 net.cpp:84] Creating Layer BatchNorm34
I0929 09:26:45.795087  1584 net.cpp:406] BatchNorm34 <- Convolution34
I0929 09:26:45.795090  1584 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I0929 09:26:45.795228  1584 net.cpp:122] Setting up BatchNorm34
I0929 09:26:45.795231  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.795233  1584 net.cpp:137] Memory required for data: 715949200
I0929 09:26:45.795238  1584 layer_factory.hpp:77] Creating layer Scale34
I0929 09:26:45.795241  1584 net.cpp:84] Creating Layer Scale34
I0929 09:26:45.795244  1584 net.cpp:406] Scale34 <- Convolution34
I0929 09:26:45.795248  1584 net.cpp:367] Scale34 -> Convolution34 (in-place)
I0929 09:26:45.795274  1584 layer_factory.hpp:77] Creating layer Scale34
I0929 09:26:45.795349  1584 net.cpp:122] Setting up Scale34
I0929 09:26:45.795353  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.795356  1584 net.cpp:137] Memory required for data: 718458000
I0929 09:26:45.795359  1584 layer_factory.hpp:77] Creating layer Eltwise16
I0929 09:26:45.795363  1584 net.cpp:84] Creating Layer Eltwise16
I0929 09:26:45.795366  1584 net.cpp:406] Eltwise16 <- Eltwise15_M2PELU31_0_split_1
I0929 09:26:45.795368  1584 net.cpp:406] Eltwise16 <- Convolution34
I0929 09:26:45.795373  1584 net.cpp:380] Eltwise16 -> Eltwise16
I0929 09:26:45.795390  1584 net.cpp:122] Setting up Eltwise16
I0929 09:26:45.795393  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.795395  1584 net.cpp:137] Memory required for data: 720966800
I0929 09:26:45.795397  1584 layer_factory.hpp:77] Creating layer M2PELU33
I0929 09:26:45.795403  1584 net.cpp:84] Creating Layer M2PELU33
I0929 09:26:45.795404  1584 net.cpp:406] M2PELU33 <- Eltwise16
I0929 09:26:45.795408  1584 net.cpp:367] M2PELU33 -> Eltwise16 (in-place)
I0929 09:26:45.795491  1584 net.cpp:122] Setting up M2PELU33
I0929 09:26:45.795495  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.795497  1584 net.cpp:137] Memory required for data: 723475600
I0929 09:26:45.795501  1584 layer_factory.hpp:77] Creating layer Eltwise16_M2PELU33_0_split
I0929 09:26:45.795506  1584 net.cpp:84] Creating Layer Eltwise16_M2PELU33_0_split
I0929 09:26:45.795507  1584 net.cpp:406] Eltwise16_M2PELU33_0_split <- Eltwise16
I0929 09:26:45.795511  1584 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_0
I0929 09:26:45.795514  1584 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_1
I0929 09:26:45.795537  1584 net.cpp:122] Setting up Eltwise16_M2PELU33_0_split
I0929 09:26:45.795542  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.795544  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.795552  1584 net.cpp:137] Memory required for data: 728493200
I0929 09:26:45.795554  1584 layer_factory.hpp:77] Creating layer Convolution35
I0929 09:26:45.795560  1584 net.cpp:84] Creating Layer Convolution35
I0929 09:26:45.795562  1584 net.cpp:406] Convolution35 <- Eltwise16_M2PELU33_0_split_0
I0929 09:26:45.795567  1584 net.cpp:380] Convolution35 -> Convolution35
I0929 09:26:45.795647  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:45.796608  1584 net.cpp:122] Setting up Convolution35
I0929 09:26:45.796617  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.796618  1584 net.cpp:137] Memory required for data: 731002000
I0929 09:26:45.796623  1584 layer_factory.hpp:77] Creating layer BatchNorm35
I0929 09:26:45.796628  1584 net.cpp:84] Creating Layer BatchNorm35
I0929 09:26:45.796630  1584 net.cpp:406] BatchNorm35 <- Convolution35
I0929 09:26:45.796634  1584 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I0929 09:26:45.796771  1584 net.cpp:122] Setting up BatchNorm35
I0929 09:26:45.796774  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.796777  1584 net.cpp:137] Memory required for data: 733510800
I0929 09:26:45.796780  1584 layer_factory.hpp:77] Creating layer Scale35
I0929 09:26:45.796784  1584 net.cpp:84] Creating Layer Scale35
I0929 09:26:45.796787  1584 net.cpp:406] Scale35 <- Convolution35
I0929 09:26:45.796790  1584 net.cpp:367] Scale35 -> Convolution35 (in-place)
I0929 09:26:45.796818  1584 layer_factory.hpp:77] Creating layer Scale35
I0929 09:26:45.796893  1584 net.cpp:122] Setting up Scale35
I0929 09:26:45.796898  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.796900  1584 net.cpp:137] Memory required for data: 736019600
I0929 09:26:45.796905  1584 layer_factory.hpp:77] Creating layer M2PELU34
I0929 09:26:45.796908  1584 net.cpp:84] Creating Layer M2PELU34
I0929 09:26:45.796911  1584 net.cpp:406] M2PELU34 <- Convolution35
I0929 09:26:45.796916  1584 net.cpp:367] M2PELU34 -> Convolution35 (in-place)
I0929 09:26:45.797000  1584 net.cpp:122] Setting up M2PELU34
I0929 09:26:45.797004  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.797006  1584 net.cpp:137] Memory required for data: 738528400
I0929 09:26:45.797010  1584 layer_factory.hpp:77] Creating layer Convolution36
I0929 09:26:45.797016  1584 net.cpp:84] Creating Layer Convolution36
I0929 09:26:45.797019  1584 net.cpp:406] Convolution36 <- Convolution35
I0929 09:26:45.797024  1584 net.cpp:380] Convolution36 -> Convolution36
I0929 09:26:45.797103  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:45.798064  1584 net.cpp:122] Setting up Convolution36
I0929 09:26:45.798072  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.798074  1584 net.cpp:137] Memory required for data: 741037200
I0929 09:26:45.798079  1584 layer_factory.hpp:77] Creating layer BatchNorm36
I0929 09:26:45.798084  1584 net.cpp:84] Creating Layer BatchNorm36
I0929 09:26:45.798087  1584 net.cpp:406] BatchNorm36 <- Convolution36
I0929 09:26:45.798090  1584 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I0929 09:26:45.798226  1584 net.cpp:122] Setting up BatchNorm36
I0929 09:26:45.798231  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.798233  1584 net.cpp:137] Memory required for data: 743546000
I0929 09:26:45.798238  1584 layer_factory.hpp:77] Creating layer Scale36
I0929 09:26:45.798241  1584 net.cpp:84] Creating Layer Scale36
I0929 09:26:45.798244  1584 net.cpp:406] Scale36 <- Convolution36
I0929 09:26:45.798247  1584 net.cpp:367] Scale36 -> Convolution36 (in-place)
I0929 09:26:45.798274  1584 layer_factory.hpp:77] Creating layer Scale36
I0929 09:26:45.798351  1584 net.cpp:122] Setting up Scale36
I0929 09:26:45.798354  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.798357  1584 net.cpp:137] Memory required for data: 746054800
I0929 09:26:45.798359  1584 layer_factory.hpp:77] Creating layer Eltwise17
I0929 09:26:45.798363  1584 net.cpp:84] Creating Layer Eltwise17
I0929 09:26:45.798372  1584 net.cpp:406] Eltwise17 <- Eltwise16_M2PELU33_0_split_1
I0929 09:26:45.798375  1584 net.cpp:406] Eltwise17 <- Convolution36
I0929 09:26:45.798379  1584 net.cpp:380] Eltwise17 -> Eltwise17
I0929 09:26:45.798398  1584 net.cpp:122] Setting up Eltwise17
I0929 09:26:45.798400  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.798403  1584 net.cpp:137] Memory required for data: 748563600
I0929 09:26:45.798404  1584 layer_factory.hpp:77] Creating layer M2PELU35
I0929 09:26:45.798409  1584 net.cpp:84] Creating Layer M2PELU35
I0929 09:26:45.798411  1584 net.cpp:406] M2PELU35 <- Eltwise17
I0929 09:26:45.798415  1584 net.cpp:367] M2PELU35 -> Eltwise17 (in-place)
I0929 09:26:45.798501  1584 net.cpp:122] Setting up M2PELU35
I0929 09:26:45.798504  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.798506  1584 net.cpp:137] Memory required for data: 751072400
I0929 09:26:45.798511  1584 layer_factory.hpp:77] Creating layer Eltwise17_M2PELU35_0_split
I0929 09:26:45.798514  1584 net.cpp:84] Creating Layer Eltwise17_M2PELU35_0_split
I0929 09:26:45.798517  1584 net.cpp:406] Eltwise17_M2PELU35_0_split <- Eltwise17
I0929 09:26:45.798535  1584 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_0
I0929 09:26:45.798540  1584 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_1
I0929 09:26:45.798576  1584 net.cpp:122] Setting up Eltwise17_M2PELU35_0_split
I0929 09:26:45.798580  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.798583  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.798585  1584 net.cpp:137] Memory required for data: 756090000
I0929 09:26:45.798588  1584 layer_factory.hpp:77] Creating layer Convolution37
I0929 09:26:45.798593  1584 net.cpp:84] Creating Layer Convolution37
I0929 09:26:45.798595  1584 net.cpp:406] Convolution37 <- Eltwise17_M2PELU35_0_split_0
I0929 09:26:45.798599  1584 net.cpp:380] Convolution37 -> Convolution37
I0929 09:26:45.798678  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:45.799314  1584 net.cpp:122] Setting up Convolution37
I0929 09:26:45.799321  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.799324  1584 net.cpp:137] Memory required for data: 758598800
I0929 09:26:45.799329  1584 layer_factory.hpp:77] Creating layer BatchNorm37
I0929 09:26:45.799334  1584 net.cpp:84] Creating Layer BatchNorm37
I0929 09:26:45.799336  1584 net.cpp:406] BatchNorm37 <- Convolution37
I0929 09:26:45.799340  1584 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I0929 09:26:45.799474  1584 net.cpp:122] Setting up BatchNorm37
I0929 09:26:45.799477  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.799479  1584 net.cpp:137] Memory required for data: 761107600
I0929 09:26:45.799484  1584 layer_factory.hpp:77] Creating layer Scale37
I0929 09:26:45.799489  1584 net.cpp:84] Creating Layer Scale37
I0929 09:26:45.799491  1584 net.cpp:406] Scale37 <- Convolution37
I0929 09:26:45.799494  1584 net.cpp:367] Scale37 -> Convolution37 (in-place)
I0929 09:26:45.799520  1584 layer_factory.hpp:77] Creating layer Scale37
I0929 09:26:45.799597  1584 net.cpp:122] Setting up Scale37
I0929 09:26:45.799602  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.799603  1584 net.cpp:137] Memory required for data: 763616400
I0929 09:26:45.799607  1584 layer_factory.hpp:77] Creating layer M2PELU36
I0929 09:26:45.799612  1584 net.cpp:84] Creating Layer M2PELU36
I0929 09:26:45.799614  1584 net.cpp:406] M2PELU36 <- Convolution37
I0929 09:26:45.799618  1584 net.cpp:367] M2PELU36 -> Convolution37 (in-place)
I0929 09:26:45.799700  1584 net.cpp:122] Setting up M2PELU36
I0929 09:26:45.799705  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.799706  1584 net.cpp:137] Memory required for data: 766125200
I0929 09:26:45.799710  1584 layer_factory.hpp:77] Creating layer Convolution38
I0929 09:26:45.799716  1584 net.cpp:84] Creating Layer Convolution38
I0929 09:26:45.799720  1584 net.cpp:406] Convolution38 <- Convolution37
I0929 09:26:45.799724  1584 net.cpp:380] Convolution38 -> Convolution38
I0929 09:26:45.799814  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:45.800791  1584 net.cpp:122] Setting up Convolution38
I0929 09:26:45.800799  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.800801  1584 net.cpp:137] Memory required for data: 768634000
I0929 09:26:45.800806  1584 layer_factory.hpp:77] Creating layer BatchNorm38
I0929 09:26:45.800812  1584 net.cpp:84] Creating Layer BatchNorm38
I0929 09:26:45.800814  1584 net.cpp:406] BatchNorm38 <- Convolution38
I0929 09:26:45.800817  1584 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I0929 09:26:45.800952  1584 net.cpp:122] Setting up BatchNorm38
I0929 09:26:45.800956  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.800958  1584 net.cpp:137] Memory required for data: 771142800
I0929 09:26:45.800963  1584 layer_factory.hpp:77] Creating layer Scale38
I0929 09:26:45.800967  1584 net.cpp:84] Creating Layer Scale38
I0929 09:26:45.800969  1584 net.cpp:406] Scale38 <- Convolution38
I0929 09:26:45.800972  1584 net.cpp:367] Scale38 -> Convolution38 (in-place)
I0929 09:26:45.800999  1584 layer_factory.hpp:77] Creating layer Scale38
I0929 09:26:45.801074  1584 net.cpp:122] Setting up Scale38
I0929 09:26:45.801079  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.801080  1584 net.cpp:137] Memory required for data: 773651600
I0929 09:26:45.801084  1584 layer_factory.hpp:77] Creating layer Eltwise18
I0929 09:26:45.801089  1584 net.cpp:84] Creating Layer Eltwise18
I0929 09:26:45.801091  1584 net.cpp:406] Eltwise18 <- Eltwise17_M2PELU35_0_split_1
I0929 09:26:45.801095  1584 net.cpp:406] Eltwise18 <- Convolution38
I0929 09:26:45.801097  1584 net.cpp:380] Eltwise18 -> Eltwise18
I0929 09:26:45.801112  1584 net.cpp:122] Setting up Eltwise18
I0929 09:26:45.801116  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.801118  1584 net.cpp:137] Memory required for data: 776160400
I0929 09:26:45.801120  1584 layer_factory.hpp:77] Creating layer M2PELU37
I0929 09:26:45.801125  1584 net.cpp:84] Creating Layer M2PELU37
I0929 09:26:45.801127  1584 net.cpp:406] M2PELU37 <- Eltwise18
I0929 09:26:45.801131  1584 net.cpp:367] M2PELU37 -> Eltwise18 (in-place)
I0929 09:26:45.801214  1584 net.cpp:122] Setting up M2PELU37
I0929 09:26:45.801219  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.801221  1584 net.cpp:137] Memory required for data: 778669200
I0929 09:26:45.801224  1584 layer_factory.hpp:77] Creating layer Eltwise18_M2PELU37_0_split
I0929 09:26:45.801229  1584 net.cpp:84] Creating Layer Eltwise18_M2PELU37_0_split
I0929 09:26:45.801230  1584 net.cpp:406] Eltwise18_M2PELU37_0_split <- Eltwise18
I0929 09:26:45.801234  1584 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_0
I0929 09:26:45.801237  1584 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_1
I0929 09:26:45.801261  1584 net.cpp:122] Setting up Eltwise18_M2PELU37_0_split
I0929 09:26:45.801265  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.801267  1584 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 09:26:45.801270  1584 net.cpp:137] Memory required for data: 783686800
I0929 09:26:45.801271  1584 layer_factory.hpp:77] Creating layer Convolution39
I0929 09:26:45.801277  1584 net.cpp:84] Creating Layer Convolution39
I0929 09:26:45.801280  1584 net.cpp:406] Convolution39 <- Eltwise18_M2PELU37_0_split_0
I0929 09:26:45.801283  1584 net.cpp:380] Convolution39 -> Convolution39
I0929 09:26:45.801364  1584 filler.hpp:251] The std of weights in this layer is: 0.242536
I0929 09:26:45.802178  1584 net.cpp:122] Setting up Convolution39
I0929 09:26:45.802187  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.802189  1584 net.cpp:137] Memory required for data: 784941200
I0929 09:26:45.802193  1584 layer_factory.hpp:77] Creating layer BatchNorm39
I0929 09:26:45.802201  1584 net.cpp:84] Creating Layer BatchNorm39
I0929 09:26:45.802203  1584 net.cpp:406] BatchNorm39 <- Convolution39
I0929 09:26:45.802206  1584 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I0929 09:26:45.802347  1584 net.cpp:122] Setting up BatchNorm39
I0929 09:26:45.802352  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.802354  1584 net.cpp:137] Memory required for data: 786195600
I0929 09:26:45.802359  1584 layer_factory.hpp:77] Creating layer Scale39
I0929 09:26:45.802364  1584 net.cpp:84] Creating Layer Scale39
I0929 09:26:45.802366  1584 net.cpp:406] Scale39 <- Convolution39
I0929 09:26:45.802369  1584 net.cpp:367] Scale39 -> Convolution39 (in-place)
I0929 09:26:45.802395  1584 layer_factory.hpp:77] Creating layer Scale39
I0929 09:26:45.802472  1584 net.cpp:122] Setting up Scale39
I0929 09:26:45.802476  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.802479  1584 net.cpp:137] Memory required for data: 787450000
I0929 09:26:45.802482  1584 layer_factory.hpp:77] Creating layer Convolution40
I0929 09:26:45.802489  1584 net.cpp:84] Creating Layer Convolution40
I0929 09:26:45.802492  1584 net.cpp:406] Convolution40 <- Eltwise18_M2PELU37_0_split_1
I0929 09:26:45.802496  1584 net.cpp:380] Convolution40 -> Convolution40
I0929 09:26:45.802598  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:45.804268  1584 net.cpp:122] Setting up Convolution40
I0929 09:26:45.804277  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.804280  1584 net.cpp:137] Memory required for data: 788704400
I0929 09:26:45.804285  1584 layer_factory.hpp:77] Creating layer BatchNorm40
I0929 09:26:45.804289  1584 net.cpp:84] Creating Layer BatchNorm40
I0929 09:26:45.804292  1584 net.cpp:406] BatchNorm40 <- Convolution40
I0929 09:26:45.804307  1584 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I0929 09:26:45.804493  1584 net.cpp:122] Setting up BatchNorm40
I0929 09:26:45.804497  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.804499  1584 net.cpp:137] Memory required for data: 789958800
I0929 09:26:45.804504  1584 layer_factory.hpp:77] Creating layer Scale40
I0929 09:26:45.804508  1584 net.cpp:84] Creating Layer Scale40
I0929 09:26:45.804512  1584 net.cpp:406] Scale40 <- Convolution40
I0929 09:26:45.804514  1584 net.cpp:367] Scale40 -> Convolution40 (in-place)
I0929 09:26:45.804540  1584 layer_factory.hpp:77] Creating layer Scale40
I0929 09:26:45.804617  1584 net.cpp:122] Setting up Scale40
I0929 09:26:45.804621  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.804623  1584 net.cpp:137] Memory required for data: 791213200
I0929 09:26:45.804627  1584 layer_factory.hpp:77] Creating layer M2PELU38
I0929 09:26:45.804633  1584 net.cpp:84] Creating Layer M2PELU38
I0929 09:26:45.804636  1584 net.cpp:406] M2PELU38 <- Convolution40
I0929 09:26:45.804639  1584 net.cpp:367] M2PELU38 -> Convolution40 (in-place)
I0929 09:26:45.804723  1584 net.cpp:122] Setting up M2PELU38
I0929 09:26:45.804726  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.804728  1584 net.cpp:137] Memory required for data: 792467600
I0929 09:26:45.804733  1584 layer_factory.hpp:77] Creating layer Convolution41
I0929 09:26:45.804738  1584 net.cpp:84] Creating Layer Convolution41
I0929 09:26:45.804741  1584 net.cpp:406] Convolution41 <- Convolution40
I0929 09:26:45.804746  1584 net.cpp:380] Convolution41 -> Convolution41
I0929 09:26:45.804827  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:45.807312  1584 net.cpp:122] Setting up Convolution41
I0929 09:26:45.807322  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.807325  1584 net.cpp:137] Memory required for data: 793722000
I0929 09:26:45.807329  1584 layer_factory.hpp:77] Creating layer BatchNorm41
I0929 09:26:45.807335  1584 net.cpp:84] Creating Layer BatchNorm41
I0929 09:26:45.807338  1584 net.cpp:406] BatchNorm41 <- Convolution41
I0929 09:26:45.807343  1584 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I0929 09:26:45.807484  1584 net.cpp:122] Setting up BatchNorm41
I0929 09:26:45.807488  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.807492  1584 net.cpp:137] Memory required for data: 794976400
I0929 09:26:45.807502  1584 layer_factory.hpp:77] Creating layer Scale41
I0929 09:26:45.807508  1584 net.cpp:84] Creating Layer Scale41
I0929 09:26:45.807510  1584 net.cpp:406] Scale41 <- Convolution41
I0929 09:26:45.807514  1584 net.cpp:367] Scale41 -> Convolution41 (in-place)
I0929 09:26:45.807543  1584 layer_factory.hpp:77] Creating layer Scale41
I0929 09:26:45.807623  1584 net.cpp:122] Setting up Scale41
I0929 09:26:45.807627  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.807629  1584 net.cpp:137] Memory required for data: 796230800
I0929 09:26:45.807633  1584 layer_factory.hpp:77] Creating layer Eltwise19
I0929 09:26:45.807638  1584 net.cpp:84] Creating Layer Eltwise19
I0929 09:26:45.807641  1584 net.cpp:406] Eltwise19 <- Convolution39
I0929 09:26:45.807643  1584 net.cpp:406] Eltwise19 <- Convolution41
I0929 09:26:45.807647  1584 net.cpp:380] Eltwise19 -> Eltwise19
I0929 09:26:45.807664  1584 net.cpp:122] Setting up Eltwise19
I0929 09:26:45.807668  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.807670  1584 net.cpp:137] Memory required for data: 797485200
I0929 09:26:45.807672  1584 layer_factory.hpp:77] Creating layer M2PELU39
I0929 09:26:45.807677  1584 net.cpp:84] Creating Layer M2PELU39
I0929 09:26:45.807680  1584 net.cpp:406] M2PELU39 <- Eltwise19
I0929 09:26:45.807683  1584 net.cpp:367] M2PELU39 -> Eltwise19 (in-place)
I0929 09:26:45.807770  1584 net.cpp:122] Setting up M2PELU39
I0929 09:26:45.807773  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.807775  1584 net.cpp:137] Memory required for data: 798739600
I0929 09:26:45.807780  1584 layer_factory.hpp:77] Creating layer Eltwise19_M2PELU39_0_split
I0929 09:26:45.807782  1584 net.cpp:84] Creating Layer Eltwise19_M2PELU39_0_split
I0929 09:26:45.807785  1584 net.cpp:406] Eltwise19_M2PELU39_0_split <- Eltwise19
I0929 09:26:45.807790  1584 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_0
I0929 09:26:45.807793  1584 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_1
I0929 09:26:45.807816  1584 net.cpp:122] Setting up Eltwise19_M2PELU39_0_split
I0929 09:26:45.807821  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.807822  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.807824  1584 net.cpp:137] Memory required for data: 801248400
I0929 09:26:45.807827  1584 layer_factory.hpp:77] Creating layer Convolution42
I0929 09:26:45.807833  1584 net.cpp:84] Creating Layer Convolution42
I0929 09:26:45.807837  1584 net.cpp:406] Convolution42 <- Eltwise19_M2PELU39_0_split_0
I0929 09:26:45.807839  1584 net.cpp:380] Convolution42 -> Convolution42
I0929 09:26:45.807950  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:45.809669  1584 net.cpp:122] Setting up Convolution42
I0929 09:26:45.809677  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.809681  1584 net.cpp:137] Memory required for data: 802502800
I0929 09:26:45.809685  1584 layer_factory.hpp:77] Creating layer BatchNorm42
I0929 09:26:45.809690  1584 net.cpp:84] Creating Layer BatchNorm42
I0929 09:26:45.809692  1584 net.cpp:406] BatchNorm42 <- Convolution42
I0929 09:26:45.809698  1584 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I0929 09:26:45.809835  1584 net.cpp:122] Setting up BatchNorm42
I0929 09:26:45.809839  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.809841  1584 net.cpp:137] Memory required for data: 803757200
I0929 09:26:45.809846  1584 layer_factory.hpp:77] Creating layer Scale42
I0929 09:26:45.809850  1584 net.cpp:84] Creating Layer Scale42
I0929 09:26:45.809854  1584 net.cpp:406] Scale42 <- Convolution42
I0929 09:26:45.809855  1584 net.cpp:367] Scale42 -> Convolution42 (in-place)
I0929 09:26:45.809882  1584 layer_factory.hpp:77] Creating layer Scale42
I0929 09:26:45.809962  1584 net.cpp:122] Setting up Scale42
I0929 09:26:45.809965  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.809967  1584 net.cpp:137] Memory required for data: 805011600
I0929 09:26:45.809972  1584 layer_factory.hpp:77] Creating layer M2PELU40
I0929 09:26:45.809983  1584 net.cpp:84] Creating Layer M2PELU40
I0929 09:26:45.809984  1584 net.cpp:406] M2PELU40 <- Convolution42
I0929 09:26:45.809989  1584 net.cpp:367] M2PELU40 -> Convolution42 (in-place)
I0929 09:26:45.810075  1584 net.cpp:122] Setting up M2PELU40
I0929 09:26:45.810079  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.810081  1584 net.cpp:137] Memory required for data: 806266000
I0929 09:26:45.810086  1584 layer_factory.hpp:77] Creating layer Convolution43
I0929 09:26:45.810092  1584 net.cpp:84] Creating Layer Convolution43
I0929 09:26:45.810096  1584 net.cpp:406] Convolution43 <- Convolution42
I0929 09:26:45.810098  1584 net.cpp:380] Convolution43 -> Convolution43
I0929 09:26:45.810180  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:45.812430  1584 net.cpp:122] Setting up Convolution43
I0929 09:26:45.812438  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.812441  1584 net.cpp:137] Memory required for data: 807520400
I0929 09:26:45.812446  1584 layer_factory.hpp:77] Creating layer BatchNorm43
I0929 09:26:45.812451  1584 net.cpp:84] Creating Layer BatchNorm43
I0929 09:26:45.812454  1584 net.cpp:406] BatchNorm43 <- Convolution43
I0929 09:26:45.812458  1584 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I0929 09:26:45.812599  1584 net.cpp:122] Setting up BatchNorm43
I0929 09:26:45.812604  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.812607  1584 net.cpp:137] Memory required for data: 808774800
I0929 09:26:45.812610  1584 layer_factory.hpp:77] Creating layer Scale43
I0929 09:26:45.812614  1584 net.cpp:84] Creating Layer Scale43
I0929 09:26:45.812618  1584 net.cpp:406] Scale43 <- Convolution43
I0929 09:26:45.812620  1584 net.cpp:367] Scale43 -> Convolution43 (in-place)
I0929 09:26:45.812649  1584 layer_factory.hpp:77] Creating layer Scale43
I0929 09:26:45.812726  1584 net.cpp:122] Setting up Scale43
I0929 09:26:45.812729  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.812731  1584 net.cpp:137] Memory required for data: 810029200
I0929 09:26:45.812736  1584 layer_factory.hpp:77] Creating layer Eltwise20
I0929 09:26:45.812739  1584 net.cpp:84] Creating Layer Eltwise20
I0929 09:26:45.812742  1584 net.cpp:406] Eltwise20 <- Eltwise19_M2PELU39_0_split_1
I0929 09:26:45.812746  1584 net.cpp:406] Eltwise20 <- Convolution43
I0929 09:26:45.812748  1584 net.cpp:380] Eltwise20 -> Eltwise20
I0929 09:26:45.812764  1584 net.cpp:122] Setting up Eltwise20
I0929 09:26:45.812768  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.812770  1584 net.cpp:137] Memory required for data: 811283600
I0929 09:26:45.812772  1584 layer_factory.hpp:77] Creating layer M2PELU41
I0929 09:26:45.812777  1584 net.cpp:84] Creating Layer M2PELU41
I0929 09:26:45.812779  1584 net.cpp:406] M2PELU41 <- Eltwise20
I0929 09:26:45.812783  1584 net.cpp:367] M2PELU41 -> Eltwise20 (in-place)
I0929 09:26:45.812868  1584 net.cpp:122] Setting up M2PELU41
I0929 09:26:45.812872  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.812875  1584 net.cpp:137] Memory required for data: 812538000
I0929 09:26:45.812877  1584 layer_factory.hpp:77] Creating layer Eltwise20_M2PELU41_0_split
I0929 09:26:45.812881  1584 net.cpp:84] Creating Layer Eltwise20_M2PELU41_0_split
I0929 09:26:45.812883  1584 net.cpp:406] Eltwise20_M2PELU41_0_split <- Eltwise20
I0929 09:26:45.812887  1584 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_0
I0929 09:26:45.812891  1584 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_1
I0929 09:26:45.812914  1584 net.cpp:122] Setting up Eltwise20_M2PELU41_0_split
I0929 09:26:45.812918  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.812922  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.812923  1584 net.cpp:137] Memory required for data: 815046800
I0929 09:26:45.812925  1584 layer_factory.hpp:77] Creating layer Convolution44
I0929 09:26:45.812932  1584 net.cpp:84] Creating Layer Convolution44
I0929 09:26:45.812933  1584 net.cpp:406] Convolution44 <- Eltwise20_M2PELU41_0_split_0
I0929 09:26:45.812943  1584 net.cpp:380] Convolution44 -> Convolution44
I0929 09:26:45.813030  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:45.814625  1584 net.cpp:122] Setting up Convolution44
I0929 09:26:45.814635  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.814636  1584 net.cpp:137] Memory required for data: 816301200
I0929 09:26:45.814641  1584 layer_factory.hpp:77] Creating layer BatchNorm44
I0929 09:26:45.814646  1584 net.cpp:84] Creating Layer BatchNorm44
I0929 09:26:45.814649  1584 net.cpp:406] BatchNorm44 <- Convolution44
I0929 09:26:45.814653  1584 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I0929 09:26:45.814792  1584 net.cpp:122] Setting up BatchNorm44
I0929 09:26:45.814796  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.814798  1584 net.cpp:137] Memory required for data: 817555600
I0929 09:26:45.814803  1584 layer_factory.hpp:77] Creating layer Scale44
I0929 09:26:45.814808  1584 net.cpp:84] Creating Layer Scale44
I0929 09:26:45.814810  1584 net.cpp:406] Scale44 <- Convolution44
I0929 09:26:45.814815  1584 net.cpp:367] Scale44 -> Convolution44 (in-place)
I0929 09:26:45.814841  1584 layer_factory.hpp:77] Creating layer Scale44
I0929 09:26:45.814923  1584 net.cpp:122] Setting up Scale44
I0929 09:26:45.814926  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.814927  1584 net.cpp:137] Memory required for data: 818810000
I0929 09:26:45.814931  1584 layer_factory.hpp:77] Creating layer M2PELU42
I0929 09:26:45.814936  1584 net.cpp:84] Creating Layer M2PELU42
I0929 09:26:45.814939  1584 net.cpp:406] M2PELU42 <- Convolution44
I0929 09:26:45.814944  1584 net.cpp:367] M2PELU42 -> Convolution44 (in-place)
I0929 09:26:45.815027  1584 net.cpp:122] Setting up M2PELU42
I0929 09:26:45.815032  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.815034  1584 net.cpp:137] Memory required for data: 820064400
I0929 09:26:45.815038  1584 layer_factory.hpp:77] Creating layer Convolution45
I0929 09:26:45.815044  1584 net.cpp:84] Creating Layer Convolution45
I0929 09:26:45.815047  1584 net.cpp:406] Convolution45 <- Convolution44
I0929 09:26:45.815050  1584 net.cpp:380] Convolution45 -> Convolution45
I0929 09:26:45.815135  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:45.817004  1584 net.cpp:122] Setting up Convolution45
I0929 09:26:45.817013  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.817015  1584 net.cpp:137] Memory required for data: 821318800
I0929 09:26:45.817020  1584 layer_factory.hpp:77] Creating layer BatchNorm45
I0929 09:26:45.817025  1584 net.cpp:84] Creating Layer BatchNorm45
I0929 09:26:45.817028  1584 net.cpp:406] BatchNorm45 <- Convolution45
I0929 09:26:45.817031  1584 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I0929 09:26:45.817174  1584 net.cpp:122] Setting up BatchNorm45
I0929 09:26:45.817178  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.817180  1584 net.cpp:137] Memory required for data: 822573200
I0929 09:26:45.817185  1584 layer_factory.hpp:77] Creating layer Scale45
I0929 09:26:45.817189  1584 net.cpp:84] Creating Layer Scale45
I0929 09:26:45.817191  1584 net.cpp:406] Scale45 <- Convolution45
I0929 09:26:45.817194  1584 net.cpp:367] Scale45 -> Convolution45 (in-place)
I0929 09:26:45.817222  1584 layer_factory.hpp:77] Creating layer Scale45
I0929 09:26:45.817303  1584 net.cpp:122] Setting up Scale45
I0929 09:26:45.817308  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.817311  1584 net.cpp:137] Memory required for data: 823827600
I0929 09:26:45.817313  1584 layer_factory.hpp:77] Creating layer Eltwise21
I0929 09:26:45.817318  1584 net.cpp:84] Creating Layer Eltwise21
I0929 09:26:45.817322  1584 net.cpp:406] Eltwise21 <- Eltwise20_M2PELU41_0_split_1
I0929 09:26:45.817323  1584 net.cpp:406] Eltwise21 <- Convolution45
I0929 09:26:45.817327  1584 net.cpp:380] Eltwise21 -> Eltwise21
I0929 09:26:45.817343  1584 net.cpp:122] Setting up Eltwise21
I0929 09:26:45.817348  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.817355  1584 net.cpp:137] Memory required for data: 825082000
I0929 09:26:45.817358  1584 layer_factory.hpp:77] Creating layer M2PELU43
I0929 09:26:45.817363  1584 net.cpp:84] Creating Layer M2PELU43
I0929 09:26:45.817365  1584 net.cpp:406] M2PELU43 <- Eltwise21
I0929 09:26:45.817368  1584 net.cpp:367] M2PELU43 -> Eltwise21 (in-place)
I0929 09:26:45.817459  1584 net.cpp:122] Setting up M2PELU43
I0929 09:26:45.817463  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.817466  1584 net.cpp:137] Memory required for data: 826336400
I0929 09:26:45.817469  1584 layer_factory.hpp:77] Creating layer Eltwise21_M2PELU43_0_split
I0929 09:26:45.817473  1584 net.cpp:84] Creating Layer Eltwise21_M2PELU43_0_split
I0929 09:26:45.817476  1584 net.cpp:406] Eltwise21_M2PELU43_0_split <- Eltwise21
I0929 09:26:45.817478  1584 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_0
I0929 09:26:45.817482  1584 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_1
I0929 09:26:45.817507  1584 net.cpp:122] Setting up Eltwise21_M2PELU43_0_split
I0929 09:26:45.817512  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.817513  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.817515  1584 net.cpp:137] Memory required for data: 828845200
I0929 09:26:45.817517  1584 layer_factory.hpp:77] Creating layer Convolution46
I0929 09:26:45.817523  1584 net.cpp:84] Creating Layer Convolution46
I0929 09:26:45.817526  1584 net.cpp:406] Convolution46 <- Eltwise21_M2PELU43_0_split_0
I0929 09:26:45.817530  1584 net.cpp:380] Convolution46 -> Convolution46
I0929 09:26:45.817612  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:45.819213  1584 net.cpp:122] Setting up Convolution46
I0929 09:26:45.819221  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.819224  1584 net.cpp:137] Memory required for data: 830099600
I0929 09:26:45.819228  1584 layer_factory.hpp:77] Creating layer BatchNorm46
I0929 09:26:45.819234  1584 net.cpp:84] Creating Layer BatchNorm46
I0929 09:26:45.819236  1584 net.cpp:406] BatchNorm46 <- Convolution46
I0929 09:26:45.819241  1584 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I0929 09:26:45.819380  1584 net.cpp:122] Setting up BatchNorm46
I0929 09:26:45.819386  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.819387  1584 net.cpp:137] Memory required for data: 831354000
I0929 09:26:45.819391  1584 layer_factory.hpp:77] Creating layer Scale46
I0929 09:26:45.819396  1584 net.cpp:84] Creating Layer Scale46
I0929 09:26:45.819398  1584 net.cpp:406] Scale46 <- Convolution46
I0929 09:26:45.819401  1584 net.cpp:367] Scale46 -> Convolution46 (in-place)
I0929 09:26:45.819429  1584 layer_factory.hpp:77] Creating layer Scale46
I0929 09:26:45.819509  1584 net.cpp:122] Setting up Scale46
I0929 09:26:45.819514  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.819515  1584 net.cpp:137] Memory required for data: 832608400
I0929 09:26:45.819519  1584 layer_factory.hpp:77] Creating layer M2PELU44
I0929 09:26:45.819525  1584 net.cpp:84] Creating Layer M2PELU44
I0929 09:26:45.819526  1584 net.cpp:406] M2PELU44 <- Convolution46
I0929 09:26:45.819530  1584 net.cpp:367] M2PELU44 -> Convolution46 (in-place)
I0929 09:26:45.819617  1584 net.cpp:122] Setting up M2PELU44
I0929 09:26:45.819622  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.819623  1584 net.cpp:137] Memory required for data: 833862800
I0929 09:26:45.819627  1584 layer_factory.hpp:77] Creating layer Convolution47
I0929 09:26:45.819633  1584 net.cpp:84] Creating Layer Convolution47
I0929 09:26:45.819636  1584 net.cpp:406] Convolution47 <- Convolution46
I0929 09:26:45.819640  1584 net.cpp:380] Convolution47 -> Convolution47
I0929 09:26:45.819725  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:45.821282  1584 net.cpp:122] Setting up Convolution47
I0929 09:26:45.821291  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.821293  1584 net.cpp:137] Memory required for data: 835117200
I0929 09:26:45.821305  1584 layer_factory.hpp:77] Creating layer BatchNorm47
I0929 09:26:45.821310  1584 net.cpp:84] Creating Layer BatchNorm47
I0929 09:26:45.821313  1584 net.cpp:406] BatchNorm47 <- Convolution47
I0929 09:26:45.821318  1584 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I0929 09:26:45.821460  1584 net.cpp:122] Setting up BatchNorm47
I0929 09:26:45.821465  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.821466  1584 net.cpp:137] Memory required for data: 836371600
I0929 09:26:45.821471  1584 layer_factory.hpp:77] Creating layer Scale47
I0929 09:26:45.821475  1584 net.cpp:84] Creating Layer Scale47
I0929 09:26:45.821477  1584 net.cpp:406] Scale47 <- Convolution47
I0929 09:26:45.821481  1584 net.cpp:367] Scale47 -> Convolution47 (in-place)
I0929 09:26:45.821508  1584 layer_factory.hpp:77] Creating layer Scale47
I0929 09:26:45.821588  1584 net.cpp:122] Setting up Scale47
I0929 09:26:45.821591  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.821593  1584 net.cpp:137] Memory required for data: 837626000
I0929 09:26:45.821597  1584 layer_factory.hpp:77] Creating layer Eltwise22
I0929 09:26:45.821601  1584 net.cpp:84] Creating Layer Eltwise22
I0929 09:26:45.821604  1584 net.cpp:406] Eltwise22 <- Eltwise21_M2PELU43_0_split_1
I0929 09:26:45.821606  1584 net.cpp:406] Eltwise22 <- Convolution47
I0929 09:26:45.821610  1584 net.cpp:380] Eltwise22 -> Eltwise22
I0929 09:26:45.821626  1584 net.cpp:122] Setting up Eltwise22
I0929 09:26:45.821630  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.821632  1584 net.cpp:137] Memory required for data: 838880400
I0929 09:26:45.821635  1584 layer_factory.hpp:77] Creating layer M2PELU45
I0929 09:26:45.821640  1584 net.cpp:84] Creating Layer M2PELU45
I0929 09:26:45.821641  1584 net.cpp:406] M2PELU45 <- Eltwise22
I0929 09:26:45.821645  1584 net.cpp:367] M2PELU45 -> Eltwise22 (in-place)
I0929 09:26:45.821732  1584 net.cpp:122] Setting up M2PELU45
I0929 09:26:45.821737  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.821738  1584 net.cpp:137] Memory required for data: 840134800
I0929 09:26:45.821741  1584 layer_factory.hpp:77] Creating layer Eltwise22_M2PELU45_0_split
I0929 09:26:45.821745  1584 net.cpp:84] Creating Layer Eltwise22_M2PELU45_0_split
I0929 09:26:45.821748  1584 net.cpp:406] Eltwise22_M2PELU45_0_split <- Eltwise22
I0929 09:26:45.821751  1584 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_0
I0929 09:26:45.821755  1584 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_1
I0929 09:26:45.821779  1584 net.cpp:122] Setting up Eltwise22_M2PELU45_0_split
I0929 09:26:45.821784  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.821785  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.821787  1584 net.cpp:137] Memory required for data: 842643600
I0929 09:26:45.821789  1584 layer_factory.hpp:77] Creating layer Convolution48
I0929 09:26:45.821795  1584 net.cpp:84] Creating Layer Convolution48
I0929 09:26:45.821797  1584 net.cpp:406] Convolution48 <- Eltwise22_M2PELU45_0_split_0
I0929 09:26:45.821802  1584 net.cpp:380] Convolution48 -> Convolution48
I0929 09:26:45.821885  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:45.823468  1584 net.cpp:122] Setting up Convolution48
I0929 09:26:45.823477  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.823480  1584 net.cpp:137] Memory required for data: 843898000
I0929 09:26:45.823484  1584 layer_factory.hpp:77] Creating layer BatchNorm48
I0929 09:26:45.823490  1584 net.cpp:84] Creating Layer BatchNorm48
I0929 09:26:45.823493  1584 net.cpp:406] BatchNorm48 <- Convolution48
I0929 09:26:45.823496  1584 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I0929 09:26:45.823638  1584 net.cpp:122] Setting up BatchNorm48
I0929 09:26:45.823642  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.823644  1584 net.cpp:137] Memory required for data: 845152400
I0929 09:26:45.823649  1584 layer_factory.hpp:77] Creating layer Scale48
I0929 09:26:45.823659  1584 net.cpp:84] Creating Layer Scale48
I0929 09:26:45.823662  1584 net.cpp:406] Scale48 <- Convolution48
I0929 09:26:45.823665  1584 net.cpp:367] Scale48 -> Convolution48 (in-place)
I0929 09:26:45.823696  1584 layer_factory.hpp:77] Creating layer Scale48
I0929 09:26:45.823779  1584 net.cpp:122] Setting up Scale48
I0929 09:26:45.823784  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.823786  1584 net.cpp:137] Memory required for data: 846406800
I0929 09:26:45.823791  1584 layer_factory.hpp:77] Creating layer M2PELU46
I0929 09:26:45.823796  1584 net.cpp:84] Creating Layer M2PELU46
I0929 09:26:45.823797  1584 net.cpp:406] M2PELU46 <- Convolution48
I0929 09:26:45.823801  1584 net.cpp:367] M2PELU46 -> Convolution48 (in-place)
I0929 09:26:45.823910  1584 net.cpp:122] Setting up M2PELU46
I0929 09:26:45.823915  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.823916  1584 net.cpp:137] Memory required for data: 847661200
I0929 09:26:45.823920  1584 layer_factory.hpp:77] Creating layer Convolution49
I0929 09:26:45.835028  1584 net.cpp:84] Creating Layer Convolution49
I0929 09:26:45.835036  1584 net.cpp:406] Convolution49 <- Convolution48
I0929 09:26:45.835042  1584 net.cpp:380] Convolution49 -> Convolution49
I0929 09:26:45.835152  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:45.837479  1584 net.cpp:122] Setting up Convolution49
I0929 09:26:45.837508  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.837512  1584 net.cpp:137] Memory required for data: 848915600
I0929 09:26:45.837517  1584 layer_factory.hpp:77] Creating layer BatchNorm49
I0929 09:26:45.837522  1584 net.cpp:84] Creating Layer BatchNorm49
I0929 09:26:45.837525  1584 net.cpp:406] BatchNorm49 <- Convolution49
I0929 09:26:45.837529  1584 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I0929 09:26:45.837690  1584 net.cpp:122] Setting up BatchNorm49
I0929 09:26:45.837695  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.837697  1584 net.cpp:137] Memory required for data: 850170000
I0929 09:26:45.837702  1584 layer_factory.hpp:77] Creating layer Scale49
I0929 09:26:45.837707  1584 net.cpp:84] Creating Layer Scale49
I0929 09:26:45.837708  1584 net.cpp:406] Scale49 <- Convolution49
I0929 09:26:45.837712  1584 net.cpp:367] Scale49 -> Convolution49 (in-place)
I0929 09:26:45.837743  1584 layer_factory.hpp:77] Creating layer Scale49
I0929 09:26:45.837826  1584 net.cpp:122] Setting up Scale49
I0929 09:26:45.837831  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.837833  1584 net.cpp:137] Memory required for data: 851424400
I0929 09:26:45.837837  1584 layer_factory.hpp:77] Creating layer Eltwise23
I0929 09:26:45.837842  1584 net.cpp:84] Creating Layer Eltwise23
I0929 09:26:45.837846  1584 net.cpp:406] Eltwise23 <- Eltwise22_M2PELU45_0_split_1
I0929 09:26:45.837847  1584 net.cpp:406] Eltwise23 <- Convolution49
I0929 09:26:45.837852  1584 net.cpp:380] Eltwise23 -> Eltwise23
I0929 09:26:45.837869  1584 net.cpp:122] Setting up Eltwise23
I0929 09:26:45.837872  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.837874  1584 net.cpp:137] Memory required for data: 852678800
I0929 09:26:45.837877  1584 layer_factory.hpp:77] Creating layer M2PELU47
I0929 09:26:45.837882  1584 net.cpp:84] Creating Layer M2PELU47
I0929 09:26:45.837884  1584 net.cpp:406] M2PELU47 <- Eltwise23
I0929 09:26:45.837888  1584 net.cpp:367] M2PELU47 -> Eltwise23 (in-place)
I0929 09:26:45.837980  1584 net.cpp:122] Setting up M2PELU47
I0929 09:26:45.837983  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.837985  1584 net.cpp:137] Memory required for data: 853933200
I0929 09:26:45.837990  1584 layer_factory.hpp:77] Creating layer Eltwise23_M2PELU47_0_split
I0929 09:26:45.837992  1584 net.cpp:84] Creating Layer Eltwise23_M2PELU47_0_split
I0929 09:26:45.837994  1584 net.cpp:406] Eltwise23_M2PELU47_0_split <- Eltwise23
I0929 09:26:45.837999  1584 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_0
I0929 09:26:45.838003  1584 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_1
I0929 09:26:45.838037  1584 net.cpp:122] Setting up Eltwise23_M2PELU47_0_split
I0929 09:26:45.838042  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.838044  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.838047  1584 net.cpp:137] Memory required for data: 856442000
I0929 09:26:45.838048  1584 layer_factory.hpp:77] Creating layer Convolution50
I0929 09:26:45.838055  1584 net.cpp:84] Creating Layer Convolution50
I0929 09:26:45.838057  1584 net.cpp:406] Convolution50 <- Eltwise23_M2PELU47_0_split_0
I0929 09:26:45.838062  1584 net.cpp:380] Convolution50 -> Convolution50
I0929 09:26:45.838151  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:45.839939  1584 net.cpp:122] Setting up Convolution50
I0929 09:26:45.839949  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.839951  1584 net.cpp:137] Memory required for data: 857696400
I0929 09:26:45.839956  1584 layer_factory.hpp:77] Creating layer BatchNorm50
I0929 09:26:45.839962  1584 net.cpp:84] Creating Layer BatchNorm50
I0929 09:26:45.839964  1584 net.cpp:406] BatchNorm50 <- Convolution50
I0929 09:26:45.839968  1584 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I0929 09:26:45.840111  1584 net.cpp:122] Setting up BatchNorm50
I0929 09:26:45.840114  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.840116  1584 net.cpp:137] Memory required for data: 858950800
I0929 09:26:45.840121  1584 layer_factory.hpp:77] Creating layer Scale50
I0929 09:26:45.840126  1584 net.cpp:84] Creating Layer Scale50
I0929 09:26:45.840128  1584 net.cpp:406] Scale50 <- Convolution50
I0929 09:26:45.840131  1584 net.cpp:367] Scale50 -> Convolution50 (in-place)
I0929 09:26:45.840159  1584 layer_factory.hpp:77] Creating layer Scale50
I0929 09:26:45.840240  1584 net.cpp:122] Setting up Scale50
I0929 09:26:45.840245  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.840246  1584 net.cpp:137] Memory required for data: 860205200
I0929 09:26:45.840250  1584 layer_factory.hpp:77] Creating layer M2PELU48
I0929 09:26:45.840255  1584 net.cpp:84] Creating Layer M2PELU48
I0929 09:26:45.840258  1584 net.cpp:406] M2PELU48 <- Convolution50
I0929 09:26:45.840261  1584 net.cpp:367] M2PELU48 -> Convolution50 (in-place)
I0929 09:26:45.840351  1584 net.cpp:122] Setting up M2PELU48
I0929 09:26:45.840355  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.840358  1584 net.cpp:137] Memory required for data: 861459600
I0929 09:26:45.840360  1584 layer_factory.hpp:77] Creating layer Convolution51
I0929 09:26:45.840368  1584 net.cpp:84] Creating Layer Convolution51
I0929 09:26:45.840370  1584 net.cpp:406] Convolution51 <- Convolution50
I0929 09:26:45.840374  1584 net.cpp:380] Convolution51 -> Convolution51
I0929 09:26:45.840459  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:45.842339  1584 net.cpp:122] Setting up Convolution51
I0929 09:26:45.842348  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.842350  1584 net.cpp:137] Memory required for data: 862714000
I0929 09:26:45.842356  1584 layer_factory.hpp:77] Creating layer BatchNorm51
I0929 09:26:45.842361  1584 net.cpp:84] Creating Layer BatchNorm51
I0929 09:26:45.842363  1584 net.cpp:406] BatchNorm51 <- Convolution51
I0929 09:26:45.842367  1584 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I0929 09:26:45.842514  1584 net.cpp:122] Setting up BatchNorm51
I0929 09:26:45.842519  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.842535  1584 net.cpp:137] Memory required for data: 863968400
I0929 09:26:45.842540  1584 layer_factory.hpp:77] Creating layer Scale51
I0929 09:26:45.842545  1584 net.cpp:84] Creating Layer Scale51
I0929 09:26:45.842547  1584 net.cpp:406] Scale51 <- Convolution51
I0929 09:26:45.842550  1584 net.cpp:367] Scale51 -> Convolution51 (in-place)
I0929 09:26:45.842589  1584 layer_factory.hpp:77] Creating layer Scale51
I0929 09:26:45.842674  1584 net.cpp:122] Setting up Scale51
I0929 09:26:45.842677  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.842685  1584 net.cpp:137] Memory required for data: 865222800
I0929 09:26:45.842690  1584 layer_factory.hpp:77] Creating layer Eltwise24
I0929 09:26:45.842694  1584 net.cpp:84] Creating Layer Eltwise24
I0929 09:26:45.842696  1584 net.cpp:406] Eltwise24 <- Eltwise23_M2PELU47_0_split_1
I0929 09:26:45.842700  1584 net.cpp:406] Eltwise24 <- Convolution51
I0929 09:26:45.842702  1584 net.cpp:380] Eltwise24 -> Eltwise24
I0929 09:26:45.842721  1584 net.cpp:122] Setting up Eltwise24
I0929 09:26:45.842725  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.842727  1584 net.cpp:137] Memory required for data: 866477200
I0929 09:26:45.842730  1584 layer_factory.hpp:77] Creating layer M2PELU49
I0929 09:26:45.842734  1584 net.cpp:84] Creating Layer M2PELU49
I0929 09:26:45.842737  1584 net.cpp:406] M2PELU49 <- Eltwise24
I0929 09:26:45.842741  1584 net.cpp:367] M2PELU49 -> Eltwise24 (in-place)
I0929 09:26:45.842831  1584 net.cpp:122] Setting up M2PELU49
I0929 09:26:45.842835  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.842838  1584 net.cpp:137] Memory required for data: 867731600
I0929 09:26:45.842841  1584 layer_factory.hpp:77] Creating layer Eltwise24_M2PELU49_0_split
I0929 09:26:45.842844  1584 net.cpp:84] Creating Layer Eltwise24_M2PELU49_0_split
I0929 09:26:45.842847  1584 net.cpp:406] Eltwise24_M2PELU49_0_split <- Eltwise24
I0929 09:26:45.842851  1584 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_0
I0929 09:26:45.842855  1584 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_1
I0929 09:26:45.842880  1584 net.cpp:122] Setting up Eltwise24_M2PELU49_0_split
I0929 09:26:45.842883  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.842886  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.842888  1584 net.cpp:137] Memory required for data: 870240400
I0929 09:26:45.842890  1584 layer_factory.hpp:77] Creating layer Convolution52
I0929 09:26:45.842896  1584 net.cpp:84] Creating Layer Convolution52
I0929 09:26:45.842900  1584 net.cpp:406] Convolution52 <- Eltwise24_M2PELU49_0_split_0
I0929 09:26:45.842903  1584 net.cpp:380] Convolution52 -> Convolution52
I0929 09:26:45.842990  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:45.844573  1584 net.cpp:122] Setting up Convolution52
I0929 09:26:45.844583  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.844584  1584 net.cpp:137] Memory required for data: 871494800
I0929 09:26:45.844589  1584 layer_factory.hpp:77] Creating layer BatchNorm52
I0929 09:26:45.844594  1584 net.cpp:84] Creating Layer BatchNorm52
I0929 09:26:45.844596  1584 net.cpp:406] BatchNorm52 <- Convolution52
I0929 09:26:45.844601  1584 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I0929 09:26:45.844746  1584 net.cpp:122] Setting up BatchNorm52
I0929 09:26:45.844751  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.844753  1584 net.cpp:137] Memory required for data: 872749200
I0929 09:26:45.844758  1584 layer_factory.hpp:77] Creating layer Scale52
I0929 09:26:45.844763  1584 net.cpp:84] Creating Layer Scale52
I0929 09:26:45.844764  1584 net.cpp:406] Scale52 <- Convolution52
I0929 09:26:45.844768  1584 net.cpp:367] Scale52 -> Convolution52 (in-place)
I0929 09:26:45.844796  1584 layer_factory.hpp:77] Creating layer Scale52
I0929 09:26:45.844879  1584 net.cpp:122] Setting up Scale52
I0929 09:26:45.844884  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.844887  1584 net.cpp:137] Memory required for data: 874003600
I0929 09:26:45.844889  1584 layer_factory.hpp:77] Creating layer M2PELU50
I0929 09:26:45.844894  1584 net.cpp:84] Creating Layer M2PELU50
I0929 09:26:45.844897  1584 net.cpp:406] M2PELU50 <- Convolution52
I0929 09:26:45.844900  1584 net.cpp:367] M2PELU50 -> Convolution52 (in-place)
I0929 09:26:45.844990  1584 net.cpp:122] Setting up M2PELU50
I0929 09:26:45.844993  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.844995  1584 net.cpp:137] Memory required for data: 875258000
I0929 09:26:45.845005  1584 layer_factory.hpp:77] Creating layer Convolution53
I0929 09:26:45.845032  1584 net.cpp:84] Creating Layer Convolution53
I0929 09:26:45.845036  1584 net.cpp:406] Convolution53 <- Convolution52
I0929 09:26:45.845039  1584 net.cpp:380] Convolution53 -> Convolution53
I0929 09:26:45.845140  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:45.847075  1584 net.cpp:122] Setting up Convolution53
I0929 09:26:45.847085  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.847088  1584 net.cpp:137] Memory required for data: 876512400
I0929 09:26:45.847093  1584 layer_factory.hpp:77] Creating layer BatchNorm53
I0929 09:26:45.847097  1584 net.cpp:84] Creating Layer BatchNorm53
I0929 09:26:45.847100  1584 net.cpp:406] BatchNorm53 <- Convolution53
I0929 09:26:45.847105  1584 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I0929 09:26:45.847254  1584 net.cpp:122] Setting up BatchNorm53
I0929 09:26:45.847259  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.847261  1584 net.cpp:137] Memory required for data: 877766800
I0929 09:26:45.847266  1584 layer_factory.hpp:77] Creating layer Scale53
I0929 09:26:45.847270  1584 net.cpp:84] Creating Layer Scale53
I0929 09:26:45.847272  1584 net.cpp:406] Scale53 <- Convolution53
I0929 09:26:45.847276  1584 net.cpp:367] Scale53 -> Convolution53 (in-place)
I0929 09:26:45.847304  1584 layer_factory.hpp:77] Creating layer Scale53
I0929 09:26:45.847386  1584 net.cpp:122] Setting up Scale53
I0929 09:26:45.847391  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.847393  1584 net.cpp:137] Memory required for data: 879021200
I0929 09:26:45.847396  1584 layer_factory.hpp:77] Creating layer Eltwise25
I0929 09:26:45.847400  1584 net.cpp:84] Creating Layer Eltwise25
I0929 09:26:45.847404  1584 net.cpp:406] Eltwise25 <- Eltwise24_M2PELU49_0_split_1
I0929 09:26:45.847405  1584 net.cpp:406] Eltwise25 <- Convolution53
I0929 09:26:45.847409  1584 net.cpp:380] Eltwise25 -> Eltwise25
I0929 09:26:45.847426  1584 net.cpp:122] Setting up Eltwise25
I0929 09:26:45.847430  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.847432  1584 net.cpp:137] Memory required for data: 880275600
I0929 09:26:45.847434  1584 layer_factory.hpp:77] Creating layer M2PELU51
I0929 09:26:45.847439  1584 net.cpp:84] Creating Layer M2PELU51
I0929 09:26:45.847440  1584 net.cpp:406] M2PELU51 <- Eltwise25
I0929 09:26:45.847445  1584 net.cpp:367] M2PELU51 -> Eltwise25 (in-place)
I0929 09:26:45.847535  1584 net.cpp:122] Setting up M2PELU51
I0929 09:26:45.847539  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.847540  1584 net.cpp:137] Memory required for data: 881530000
I0929 09:26:45.847544  1584 layer_factory.hpp:77] Creating layer Eltwise25_M2PELU51_0_split
I0929 09:26:45.847548  1584 net.cpp:84] Creating Layer Eltwise25_M2PELU51_0_split
I0929 09:26:45.847551  1584 net.cpp:406] Eltwise25_M2PELU51_0_split <- Eltwise25
I0929 09:26:45.847554  1584 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_0
I0929 09:26:45.847559  1584 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_1
I0929 09:26:45.847584  1584 net.cpp:122] Setting up Eltwise25_M2PELU51_0_split
I0929 09:26:45.847586  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.847589  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.847591  1584 net.cpp:137] Memory required for data: 884038800
I0929 09:26:45.847594  1584 layer_factory.hpp:77] Creating layer Convolution54
I0929 09:26:45.847599  1584 net.cpp:84] Creating Layer Convolution54
I0929 09:26:45.847601  1584 net.cpp:406] Convolution54 <- Eltwise25_M2PELU51_0_split_0
I0929 09:26:45.847606  1584 net.cpp:380] Convolution54 -> Convolution54
I0929 09:26:45.847692  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:45.849818  1584 net.cpp:122] Setting up Convolution54
I0929 09:26:45.849828  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.849830  1584 net.cpp:137] Memory required for data: 885293200
I0929 09:26:45.849841  1584 layer_factory.hpp:77] Creating layer BatchNorm54
I0929 09:26:45.849848  1584 net.cpp:84] Creating Layer BatchNorm54
I0929 09:26:45.849850  1584 net.cpp:406] BatchNorm54 <- Convolution54
I0929 09:26:45.849854  1584 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I0929 09:26:45.850002  1584 net.cpp:122] Setting up BatchNorm54
I0929 09:26:45.850006  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.850008  1584 net.cpp:137] Memory required for data: 886547600
I0929 09:26:45.850013  1584 layer_factory.hpp:77] Creating layer Scale54
I0929 09:26:45.850018  1584 net.cpp:84] Creating Layer Scale54
I0929 09:26:45.850020  1584 net.cpp:406] Scale54 <- Convolution54
I0929 09:26:45.850023  1584 net.cpp:367] Scale54 -> Convolution54 (in-place)
I0929 09:26:45.850054  1584 layer_factory.hpp:77] Creating layer Scale54
I0929 09:26:45.850137  1584 net.cpp:122] Setting up Scale54
I0929 09:26:45.865627  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.865633  1584 net.cpp:137] Memory required for data: 887802000
I0929 09:26:45.865638  1584 layer_factory.hpp:77] Creating layer M2PELU52
I0929 09:26:45.865648  1584 net.cpp:84] Creating Layer M2PELU52
I0929 09:26:45.865650  1584 net.cpp:406] M2PELU52 <- Convolution54
I0929 09:26:45.865655  1584 net.cpp:367] M2PELU52 -> Convolution54 (in-place)
I0929 09:26:45.865772  1584 net.cpp:122] Setting up M2PELU52
I0929 09:26:45.865778  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.865780  1584 net.cpp:137] Memory required for data: 889056400
I0929 09:26:45.865784  1584 layer_factory.hpp:77] Creating layer Convolution55
I0929 09:26:45.865792  1584 net.cpp:84] Creating Layer Convolution55
I0929 09:26:45.865795  1584 net.cpp:406] Convolution55 <- Convolution54
I0929 09:26:45.865799  1584 net.cpp:380] Convolution55 -> Convolution55
I0929 09:26:45.865897  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:45.868279  1584 net.cpp:122] Setting up Convolution55
I0929 09:26:45.868289  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.868293  1584 net.cpp:137] Memory required for data: 890310800
I0929 09:26:45.868297  1584 layer_factory.hpp:77] Creating layer BatchNorm55
I0929 09:26:45.868302  1584 net.cpp:84] Creating Layer BatchNorm55
I0929 09:26:45.868305  1584 net.cpp:406] BatchNorm55 <- Convolution55
I0929 09:26:45.868309  1584 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I0929 09:26:45.868468  1584 net.cpp:122] Setting up BatchNorm55
I0929 09:26:45.868472  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.868474  1584 net.cpp:137] Memory required for data: 891565200
I0929 09:26:45.868479  1584 layer_factory.hpp:77] Creating layer Scale55
I0929 09:26:45.868484  1584 net.cpp:84] Creating Layer Scale55
I0929 09:26:45.868485  1584 net.cpp:406] Scale55 <- Convolution55
I0929 09:26:45.868489  1584 net.cpp:367] Scale55 -> Convolution55 (in-place)
I0929 09:26:45.868520  1584 layer_factory.hpp:77] Creating layer Scale55
I0929 09:26:45.868608  1584 net.cpp:122] Setting up Scale55
I0929 09:26:45.868613  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.868614  1584 net.cpp:137] Memory required for data: 892819600
I0929 09:26:45.868618  1584 layer_factory.hpp:77] Creating layer Eltwise26
I0929 09:26:45.868623  1584 net.cpp:84] Creating Layer Eltwise26
I0929 09:26:45.868626  1584 net.cpp:406] Eltwise26 <- Eltwise25_M2PELU51_0_split_1
I0929 09:26:45.868629  1584 net.cpp:406] Eltwise26 <- Convolution55
I0929 09:26:45.868633  1584 net.cpp:380] Eltwise26 -> Eltwise26
I0929 09:26:45.868650  1584 net.cpp:122] Setting up Eltwise26
I0929 09:26:45.868654  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.868655  1584 net.cpp:137] Memory required for data: 894074000
I0929 09:26:45.868657  1584 layer_factory.hpp:77] Creating layer M2PELU53
I0929 09:26:45.868664  1584 net.cpp:84] Creating Layer M2PELU53
I0929 09:26:45.868665  1584 net.cpp:406] M2PELU53 <- Eltwise26
I0929 09:26:45.868669  1584 net.cpp:367] M2PELU53 -> Eltwise26 (in-place)
I0929 09:26:45.868763  1584 net.cpp:122] Setting up M2PELU53
I0929 09:26:45.868774  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.868777  1584 net.cpp:137] Memory required for data: 895328400
I0929 09:26:45.868780  1584 layer_factory.hpp:77] Creating layer Eltwise26_M2PELU53_0_split
I0929 09:26:45.868785  1584 net.cpp:84] Creating Layer Eltwise26_M2PELU53_0_split
I0929 09:26:45.868788  1584 net.cpp:406] Eltwise26_M2PELU53_0_split <- Eltwise26
I0929 09:26:45.868791  1584 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_0
I0929 09:26:45.868795  1584 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_1
I0929 09:26:45.868824  1584 net.cpp:122] Setting up Eltwise26_M2PELU53_0_split
I0929 09:26:45.868827  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.868830  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.868832  1584 net.cpp:137] Memory required for data: 897837200
I0929 09:26:45.868834  1584 layer_factory.hpp:77] Creating layer Convolution56
I0929 09:26:45.868840  1584 net.cpp:84] Creating Layer Convolution56
I0929 09:26:45.868844  1584 net.cpp:406] Convolution56 <- Eltwise26_M2PELU53_0_split_0
I0929 09:26:45.868847  1584 net.cpp:380] Convolution56 -> Convolution56
I0929 09:26:45.868938  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:45.870729  1584 net.cpp:122] Setting up Convolution56
I0929 09:26:45.870738  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.870740  1584 net.cpp:137] Memory required for data: 899091600
I0929 09:26:45.870745  1584 layer_factory.hpp:77] Creating layer BatchNorm56
I0929 09:26:45.870753  1584 net.cpp:84] Creating Layer BatchNorm56
I0929 09:26:45.870755  1584 net.cpp:406] BatchNorm56 <- Convolution56
I0929 09:26:45.870759  1584 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I0929 09:26:45.870913  1584 net.cpp:122] Setting up BatchNorm56
I0929 09:26:45.870918  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.870919  1584 net.cpp:137] Memory required for data: 900346000
I0929 09:26:45.870924  1584 layer_factory.hpp:77] Creating layer Scale56
I0929 09:26:45.870929  1584 net.cpp:84] Creating Layer Scale56
I0929 09:26:45.870931  1584 net.cpp:406] Scale56 <- Convolution56
I0929 09:26:45.870934  1584 net.cpp:367] Scale56 -> Convolution56 (in-place)
I0929 09:26:45.870965  1584 layer_factory.hpp:77] Creating layer Scale56
I0929 09:26:45.871050  1584 net.cpp:122] Setting up Scale56
I0929 09:26:45.871054  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.871057  1584 net.cpp:137] Memory required for data: 901600400
I0929 09:26:45.871060  1584 layer_factory.hpp:77] Creating layer M2PELU54
I0929 09:26:45.871065  1584 net.cpp:84] Creating Layer M2PELU54
I0929 09:26:45.871068  1584 net.cpp:406] M2PELU54 <- Convolution56
I0929 09:26:45.871073  1584 net.cpp:367] M2PELU54 -> Convolution56 (in-place)
I0929 09:26:45.871167  1584 net.cpp:122] Setting up M2PELU54
I0929 09:26:45.871171  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.871173  1584 net.cpp:137] Memory required for data: 902854800
I0929 09:26:45.871176  1584 layer_factory.hpp:77] Creating layer Convolution57
I0929 09:26:45.871183  1584 net.cpp:84] Creating Layer Convolution57
I0929 09:26:45.871186  1584 net.cpp:406] Convolution57 <- Convolution56
I0929 09:26:45.871191  1584 net.cpp:380] Convolution57 -> Convolution57
I0929 09:26:45.871282  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:45.872892  1584 net.cpp:122] Setting up Convolution57
I0929 09:26:45.872901  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.872905  1584 net.cpp:137] Memory required for data: 904109200
I0929 09:26:45.872910  1584 layer_factory.hpp:77] Creating layer BatchNorm57
I0929 09:26:45.872913  1584 net.cpp:84] Creating Layer BatchNorm57
I0929 09:26:45.872916  1584 net.cpp:406] BatchNorm57 <- Convolution57
I0929 09:26:45.872920  1584 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I0929 09:26:45.873076  1584 net.cpp:122] Setting up BatchNorm57
I0929 09:26:45.873081  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.873090  1584 net.cpp:137] Memory required for data: 905363600
I0929 09:26:45.873096  1584 layer_factory.hpp:77] Creating layer Scale57
I0929 09:26:45.873100  1584 net.cpp:84] Creating Layer Scale57
I0929 09:26:45.873102  1584 net.cpp:406] Scale57 <- Convolution57
I0929 09:26:45.873106  1584 net.cpp:367] Scale57 -> Convolution57 (in-place)
I0929 09:26:45.873136  1584 layer_factory.hpp:77] Creating layer Scale57
I0929 09:26:45.873225  1584 net.cpp:122] Setting up Scale57
I0929 09:26:45.873229  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.873231  1584 net.cpp:137] Memory required for data: 906618000
I0929 09:26:45.873235  1584 layer_factory.hpp:77] Creating layer Eltwise27
I0929 09:26:45.873239  1584 net.cpp:84] Creating Layer Eltwise27
I0929 09:26:45.873242  1584 net.cpp:406] Eltwise27 <- Eltwise26_M2PELU53_0_split_1
I0929 09:26:45.873245  1584 net.cpp:406] Eltwise27 <- Convolution57
I0929 09:26:45.873250  1584 net.cpp:380] Eltwise27 -> Eltwise27
I0929 09:26:45.873267  1584 net.cpp:122] Setting up Eltwise27
I0929 09:26:45.873271  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.873273  1584 net.cpp:137] Memory required for data: 907872400
I0929 09:26:45.873275  1584 layer_factory.hpp:77] Creating layer M2PELU55
I0929 09:26:45.873281  1584 net.cpp:84] Creating Layer M2PELU55
I0929 09:26:45.873282  1584 net.cpp:406] M2PELU55 <- Eltwise27
I0929 09:26:45.873286  1584 net.cpp:367] M2PELU55 -> Eltwise27 (in-place)
I0929 09:26:45.873381  1584 net.cpp:122] Setting up M2PELU55
I0929 09:26:45.873385  1584 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 09:26:45.873387  1584 net.cpp:137] Memory required for data: 909126800
I0929 09:26:45.873391  1584 layer_factory.hpp:77] Creating layer Pooling1
I0929 09:26:45.873396  1584 net.cpp:84] Creating Layer Pooling1
I0929 09:26:45.873399  1584 net.cpp:406] Pooling1 <- Eltwise27
I0929 09:26:45.873402  1584 net.cpp:380] Pooling1 -> Pooling1
I0929 09:26:45.873883  1584 net.cpp:122] Setting up Pooling1
I0929 09:26:45.873901  1584 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0929 09:26:45.873904  1584 net.cpp:137] Memory required for data: 909152400
I0929 09:26:45.873908  1584 layer_factory.hpp:77] Creating layer InnerProduct1
I0929 09:26:45.873917  1584 net.cpp:84] Creating Layer InnerProduct1
I0929 09:26:45.873920  1584 net.cpp:406] InnerProduct1 <- Pooling1
I0929 09:26:45.873934  1584 net.cpp:380] InnerProduct1 -> InnerProduct1
I0929 09:26:45.874042  1584 net.cpp:122] Setting up InnerProduct1
I0929 09:26:45.874047  1584 net.cpp:129] Top shape: 100 10 (1000)
I0929 09:26:45.874049  1584 net.cpp:137] Memory required for data: 909156400
I0929 09:26:45.874054  1584 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0929 09:26:45.874058  1584 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0929 09:26:45.874060  1584 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I0929 09:26:45.874064  1584 net.cpp:406] SoftmaxWithLoss1 <- Data2
I0929 09:26:45.874068  1584 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0929 09:26:45.874073  1584 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0929 09:26:45.874265  1584 net.cpp:122] Setting up SoftmaxWithLoss1
I0929 09:26:45.874271  1584 net.cpp:129] Top shape: (1)
I0929 09:26:45.874274  1584 net.cpp:132]     with loss weight 1
I0929 09:26:45.874277  1584 net.cpp:137] Memory required for data: 909156404
I0929 09:26:45.874279  1584 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0929 09:26:45.874282  1584 net.cpp:198] InnerProduct1 needs backward computation.
I0929 09:26:45.874284  1584 net.cpp:198] Pooling1 needs backward computation.
I0929 09:26:45.874286  1584 net.cpp:198] M2PELU55 needs backward computation.
I0929 09:26:45.874289  1584 net.cpp:198] Eltwise27 needs backward computation.
I0929 09:26:45.874291  1584 net.cpp:198] Scale57 needs backward computation.
I0929 09:26:45.874294  1584 net.cpp:198] BatchNorm57 needs backward computation.
I0929 09:26:45.874295  1584 net.cpp:198] Convolution57 needs backward computation.
I0929 09:26:45.874297  1584 net.cpp:198] M2PELU54 needs backward computation.
I0929 09:26:45.874305  1584 net.cpp:198] Scale56 needs backward computation.
I0929 09:26:45.874307  1584 net.cpp:198] BatchNorm56 needs backward computation.
I0929 09:26:45.874310  1584 net.cpp:198] Convolution56 needs backward computation.
I0929 09:26:45.874311  1584 net.cpp:198] Eltwise26_M2PELU53_0_split needs backward computation.
I0929 09:26:45.874315  1584 net.cpp:198] M2PELU53 needs backward computation.
I0929 09:26:45.874316  1584 net.cpp:198] Eltwise26 needs backward computation.
I0929 09:26:45.874318  1584 net.cpp:198] Scale55 needs backward computation.
I0929 09:26:45.874320  1584 net.cpp:198] BatchNorm55 needs backward computation.
I0929 09:26:45.874322  1584 net.cpp:198] Convolution55 needs backward computation.
I0929 09:26:45.874325  1584 net.cpp:198] M2PELU52 needs backward computation.
I0929 09:26:45.874326  1584 net.cpp:198] Scale54 needs backward computation.
I0929 09:26:45.874328  1584 net.cpp:198] BatchNorm54 needs backward computation.
I0929 09:26:45.874330  1584 net.cpp:198] Convolution54 needs backward computation.
I0929 09:26:45.874333  1584 net.cpp:198] Eltwise25_M2PELU51_0_split needs backward computation.
I0929 09:26:45.874336  1584 net.cpp:198] M2PELU51 needs backward computation.
I0929 09:26:45.874337  1584 net.cpp:198] Eltwise25 needs backward computation.
I0929 09:26:45.874341  1584 net.cpp:198] Scale53 needs backward computation.
I0929 09:26:45.874342  1584 net.cpp:198] BatchNorm53 needs backward computation.
I0929 09:26:45.874344  1584 net.cpp:198] Convolution53 needs backward computation.
I0929 09:26:45.874346  1584 net.cpp:198] M2PELU50 needs backward computation.
I0929 09:26:45.874348  1584 net.cpp:198] Scale52 needs backward computation.
I0929 09:26:45.874351  1584 net.cpp:198] BatchNorm52 needs backward computation.
I0929 09:26:45.874352  1584 net.cpp:198] Convolution52 needs backward computation.
I0929 09:26:45.874356  1584 net.cpp:198] Eltwise24_M2PELU49_0_split needs backward computation.
I0929 09:26:45.874358  1584 net.cpp:198] M2PELU49 needs backward computation.
I0929 09:26:45.874361  1584 net.cpp:198] Eltwise24 needs backward computation.
I0929 09:26:45.874363  1584 net.cpp:198] Scale51 needs backward computation.
I0929 09:26:45.874366  1584 net.cpp:198] BatchNorm51 needs backward computation.
I0929 09:26:45.874367  1584 net.cpp:198] Convolution51 needs backward computation.
I0929 09:26:45.874370  1584 net.cpp:198] M2PELU48 needs backward computation.
I0929 09:26:45.874372  1584 net.cpp:198] Scale50 needs backward computation.
I0929 09:26:45.874374  1584 net.cpp:198] BatchNorm50 needs backward computation.
I0929 09:26:45.874377  1584 net.cpp:198] Convolution50 needs backward computation.
I0929 09:26:45.874378  1584 net.cpp:198] Eltwise23_M2PELU47_0_split needs backward computation.
I0929 09:26:45.874382  1584 net.cpp:198] M2PELU47 needs backward computation.
I0929 09:26:45.874383  1584 net.cpp:198] Eltwise23 needs backward computation.
I0929 09:26:45.874387  1584 net.cpp:198] Scale49 needs backward computation.
I0929 09:26:45.874388  1584 net.cpp:198] BatchNorm49 needs backward computation.
I0929 09:26:45.874390  1584 net.cpp:198] Convolution49 needs backward computation.
I0929 09:26:45.874393  1584 net.cpp:198] M2PELU46 needs backward computation.
I0929 09:26:45.874395  1584 net.cpp:198] Scale48 needs backward computation.
I0929 09:26:45.874397  1584 net.cpp:198] BatchNorm48 needs backward computation.
I0929 09:26:45.874399  1584 net.cpp:198] Convolution48 needs backward computation.
I0929 09:26:45.874402  1584 net.cpp:198] Eltwise22_M2PELU45_0_split needs backward computation.
I0929 09:26:45.874404  1584 net.cpp:198] M2PELU45 needs backward computation.
I0929 09:26:45.874406  1584 net.cpp:198] Eltwise22 needs backward computation.
I0929 09:26:45.874409  1584 net.cpp:198] Scale47 needs backward computation.
I0929 09:26:45.874411  1584 net.cpp:198] BatchNorm47 needs backward computation.
I0929 09:26:45.874413  1584 net.cpp:198] Convolution47 needs backward computation.
I0929 09:26:45.874415  1584 net.cpp:198] M2PELU44 needs backward computation.
I0929 09:26:45.874421  1584 net.cpp:198] Scale46 needs backward computation.
I0929 09:26:45.874423  1584 net.cpp:198] BatchNorm46 needs backward computation.
I0929 09:26:45.874425  1584 net.cpp:198] Convolution46 needs backward computation.
I0929 09:26:45.874428  1584 net.cpp:198] Eltwise21_M2PELU43_0_split needs backward computation.
I0929 09:26:45.874430  1584 net.cpp:198] M2PELU43 needs backward computation.
I0929 09:26:45.874433  1584 net.cpp:198] Eltwise21 needs backward computation.
I0929 09:26:45.874435  1584 net.cpp:198] Scale45 needs backward computation.
I0929 09:26:45.874438  1584 net.cpp:198] BatchNorm45 needs backward computation.
I0929 09:26:45.874439  1584 net.cpp:198] Convolution45 needs backward computation.
I0929 09:26:45.896366  1584 net.cpp:198] M2PELU42 needs backward computation.
I0929 09:26:45.896374  1584 net.cpp:198] Scale44 needs backward computation.
I0929 09:26:45.896376  1584 net.cpp:198] BatchNorm44 needs backward computation.
I0929 09:26:45.896379  1584 net.cpp:198] Convolution44 needs backward computation.
I0929 09:26:45.896383  1584 net.cpp:198] Eltwise20_M2PELU41_0_split needs backward computation.
I0929 09:26:45.896385  1584 net.cpp:198] M2PELU41 needs backward computation.
I0929 09:26:45.896387  1584 net.cpp:198] Eltwise20 needs backward computation.
I0929 09:26:45.896390  1584 net.cpp:198] Scale43 needs backward computation.
I0929 09:26:45.896394  1584 net.cpp:198] BatchNorm43 needs backward computation.
I0929 09:26:45.896395  1584 net.cpp:198] Convolution43 needs backward computation.
I0929 09:26:45.896399  1584 net.cpp:198] M2PELU40 needs backward computation.
I0929 09:26:45.896400  1584 net.cpp:198] Scale42 needs backward computation.
I0929 09:26:45.896404  1584 net.cpp:198] BatchNorm42 needs backward computation.
I0929 09:26:45.896405  1584 net.cpp:198] Convolution42 needs backward computation.
I0929 09:26:45.896409  1584 net.cpp:198] Eltwise19_M2PELU39_0_split needs backward computation.
I0929 09:26:45.896410  1584 net.cpp:198] M2PELU39 needs backward computation.
I0929 09:26:45.896414  1584 net.cpp:198] Eltwise19 needs backward computation.
I0929 09:26:45.896416  1584 net.cpp:198] Scale41 needs backward computation.
I0929 09:26:45.896419  1584 net.cpp:198] BatchNorm41 needs backward computation.
I0929 09:26:45.896421  1584 net.cpp:198] Convolution41 needs backward computation.
I0929 09:26:45.896423  1584 net.cpp:198] M2PELU38 needs backward computation.
I0929 09:26:45.896426  1584 net.cpp:198] Scale40 needs backward computation.
I0929 09:26:45.896428  1584 net.cpp:198] BatchNorm40 needs backward computation.
I0929 09:26:45.896430  1584 net.cpp:198] Convolution40 needs backward computation.
I0929 09:26:45.896433  1584 net.cpp:198] Scale39 needs backward computation.
I0929 09:26:45.896436  1584 net.cpp:198] BatchNorm39 needs backward computation.
I0929 09:26:45.896438  1584 net.cpp:198] Convolution39 needs backward computation.
I0929 09:26:45.896441  1584 net.cpp:198] Eltwise18_M2PELU37_0_split needs backward computation.
I0929 09:26:45.896445  1584 net.cpp:198] M2PELU37 needs backward computation.
I0929 09:26:45.896446  1584 net.cpp:198] Eltwise18 needs backward computation.
I0929 09:26:45.896450  1584 net.cpp:198] Scale38 needs backward computation.
I0929 09:26:45.896452  1584 net.cpp:198] BatchNorm38 needs backward computation.
I0929 09:26:45.896455  1584 net.cpp:198] Convolution38 needs backward computation.
I0929 09:26:45.896456  1584 net.cpp:198] M2PELU36 needs backward computation.
I0929 09:26:45.896459  1584 net.cpp:198] Scale37 needs backward computation.
I0929 09:26:45.896461  1584 net.cpp:198] BatchNorm37 needs backward computation.
I0929 09:26:45.896463  1584 net.cpp:198] Convolution37 needs backward computation.
I0929 09:26:45.896466  1584 net.cpp:198] Eltwise17_M2PELU35_0_split needs backward computation.
I0929 09:26:45.896469  1584 net.cpp:198] M2PELU35 needs backward computation.
I0929 09:26:45.896471  1584 net.cpp:198] Eltwise17 needs backward computation.
I0929 09:26:45.896474  1584 net.cpp:198] Scale36 needs backward computation.
I0929 09:26:45.896484  1584 net.cpp:198] BatchNorm36 needs backward computation.
I0929 09:26:45.896486  1584 net.cpp:198] Convolution36 needs backward computation.
I0929 09:26:45.896489  1584 net.cpp:198] M2PELU34 needs backward computation.
I0929 09:26:45.896492  1584 net.cpp:198] Scale35 needs backward computation.
I0929 09:26:45.896494  1584 net.cpp:198] BatchNorm35 needs backward computation.
I0929 09:26:45.896497  1584 net.cpp:198] Convolution35 needs backward computation.
I0929 09:26:45.896499  1584 net.cpp:198] Eltwise16_M2PELU33_0_split needs backward computation.
I0929 09:26:45.896502  1584 net.cpp:198] M2PELU33 needs backward computation.
I0929 09:26:45.896504  1584 net.cpp:198] Eltwise16 needs backward computation.
I0929 09:26:45.896507  1584 net.cpp:198] Scale34 needs backward computation.
I0929 09:26:45.896509  1584 net.cpp:198] BatchNorm34 needs backward computation.
I0929 09:26:45.896512  1584 net.cpp:198] Convolution34 needs backward computation.
I0929 09:26:45.896515  1584 net.cpp:198] M2PELU32 needs backward computation.
I0929 09:26:45.896517  1584 net.cpp:198] Scale33 needs backward computation.
I0929 09:26:45.896519  1584 net.cpp:198] BatchNorm33 needs backward computation.
I0929 09:26:45.896522  1584 net.cpp:198] Convolution33 needs backward computation.
I0929 09:26:45.896524  1584 net.cpp:198] Eltwise15_M2PELU31_0_split needs backward computation.
I0929 09:26:45.896528  1584 net.cpp:198] M2PELU31 needs backward computation.
I0929 09:26:45.896530  1584 net.cpp:198] Eltwise15 needs backward computation.
I0929 09:26:45.896533  1584 net.cpp:198] Scale32 needs backward computation.
I0929 09:26:45.896535  1584 net.cpp:198] BatchNorm32 needs backward computation.
I0929 09:26:45.896538  1584 net.cpp:198] Convolution32 needs backward computation.
I0929 09:26:45.896539  1584 net.cpp:198] M2PELU30 needs backward computation.
I0929 09:26:45.896543  1584 net.cpp:198] Scale31 needs backward computation.
I0929 09:26:45.896544  1584 net.cpp:198] BatchNorm31 needs backward computation.
I0929 09:26:45.896546  1584 net.cpp:198] Convolution31 needs backward computation.
I0929 09:26:45.896549  1584 net.cpp:198] Eltwise14_M2PELU29_0_split needs backward computation.
I0929 09:26:45.896553  1584 net.cpp:198] M2PELU29 needs backward computation.
I0929 09:26:45.896556  1584 net.cpp:198] Eltwise14 needs backward computation.
I0929 09:26:45.896559  1584 net.cpp:198] Scale30 needs backward computation.
I0929 09:26:45.896561  1584 net.cpp:198] BatchNorm30 needs backward computation.
I0929 09:26:45.896564  1584 net.cpp:198] Convolution30 needs backward computation.
I0929 09:26:45.896566  1584 net.cpp:198] M2PELU28 needs backward computation.
I0929 09:26:45.896569  1584 net.cpp:198] Scale29 needs backward computation.
I0929 09:26:45.896571  1584 net.cpp:198] BatchNorm29 needs backward computation.
I0929 09:26:45.896574  1584 net.cpp:198] Convolution29 needs backward computation.
I0929 09:26:45.896576  1584 net.cpp:198] Eltwise13_M2PELU27_0_split needs backward computation.
I0929 09:26:45.896579  1584 net.cpp:198] M2PELU27 needs backward computation.
I0929 09:26:45.896581  1584 net.cpp:198] Eltwise13 needs backward computation.
I0929 09:26:45.896584  1584 net.cpp:198] Scale28 needs backward computation.
I0929 09:26:45.896586  1584 net.cpp:198] BatchNorm28 needs backward computation.
I0929 09:26:45.896589  1584 net.cpp:198] Convolution28 needs backward computation.
I0929 09:26:45.896591  1584 net.cpp:198] M2PELU26 needs backward computation.
I0929 09:26:45.896595  1584 net.cpp:198] Scale27 needs backward computation.
I0929 09:26:45.896596  1584 net.cpp:198] BatchNorm27 needs backward computation.
I0929 09:26:45.896598  1584 net.cpp:198] Convolution27 needs backward computation.
I0929 09:26:45.896601  1584 net.cpp:198] Eltwise12_M2PELU25_0_split needs backward computation.
I0929 09:26:45.896605  1584 net.cpp:198] M2PELU25 needs backward computation.
I0929 09:26:45.896606  1584 net.cpp:198] Eltwise12 needs backward computation.
I0929 09:26:45.896610  1584 net.cpp:198] Scale26 needs backward computation.
I0929 09:26:45.896611  1584 net.cpp:198] BatchNorm26 needs backward computation.
I0929 09:26:45.896617  1584 net.cpp:198] Convolution26 needs backward computation.
I0929 09:26:45.896620  1584 net.cpp:198] M2PELU24 needs backward computation.
I0929 09:26:45.896622  1584 net.cpp:198] Scale25 needs backward computation.
I0929 09:26:45.896625  1584 net.cpp:198] BatchNorm25 needs backward computation.
I0929 09:26:45.896626  1584 net.cpp:198] Convolution25 needs backward computation.
I0929 09:26:45.896630  1584 net.cpp:198] Eltwise11_M2PELU23_0_split needs backward computation.
I0929 09:26:45.896632  1584 net.cpp:198] M2PELU23 needs backward computation.
I0929 09:26:45.896636  1584 net.cpp:198] Eltwise11 needs backward computation.
I0929 09:26:45.898849  1584 net.cpp:198] Scale24 needs backward computation.
I0929 09:26:45.898856  1584 net.cpp:198] BatchNorm24 needs backward computation.
I0929 09:26:45.898859  1584 net.cpp:198] Convolution24 needs backward computation.
I0929 09:26:45.898862  1584 net.cpp:198] M2PELU22 needs backward computation.
I0929 09:26:45.898864  1584 net.cpp:198] Scale23 needs backward computation.
I0929 09:26:45.898867  1584 net.cpp:198] BatchNorm23 needs backward computation.
I0929 09:26:45.898869  1584 net.cpp:198] Convolution23 needs backward computation.
I0929 09:26:45.898872  1584 net.cpp:198] Eltwise10_M2PELU21_0_split needs backward computation.
I0929 09:26:45.898875  1584 net.cpp:198] M2PELU21 needs backward computation.
I0929 09:26:45.898878  1584 net.cpp:198] Eltwise10 needs backward computation.
I0929 09:26:45.898881  1584 net.cpp:198] Scale22 needs backward computation.
I0929 09:26:45.898883  1584 net.cpp:198] BatchNorm22 needs backward computation.
I0929 09:26:45.898886  1584 net.cpp:198] Convolution22 needs backward computation.
I0929 09:26:45.898890  1584 net.cpp:198] M2PELU20 needs backward computation.
I0929 09:26:45.898891  1584 net.cpp:198] Scale21 needs backward computation.
I0929 09:26:45.898893  1584 net.cpp:198] BatchNorm21 needs backward computation.
I0929 09:26:45.898896  1584 net.cpp:198] Convolution21 needs backward computation.
I0929 09:26:45.898900  1584 net.cpp:198] Scale20 needs backward computation.
I0929 09:26:45.898901  1584 net.cpp:198] BatchNorm20 needs backward computation.
I0929 09:26:45.898903  1584 net.cpp:198] Convolution20 needs backward computation.
I0929 09:26:45.898906  1584 net.cpp:198] Eltwise9_M2PELU19_0_split needs backward computation.
I0929 09:26:45.898910  1584 net.cpp:198] M2PELU19 needs backward computation.
I0929 09:26:45.898911  1584 net.cpp:198] Eltwise9 needs backward computation.
I0929 09:26:45.898914  1584 net.cpp:198] Scale19 needs backward computation.
I0929 09:26:45.898917  1584 net.cpp:198] BatchNorm19 needs backward computation.
I0929 09:26:45.898919  1584 net.cpp:198] Convolution19 needs backward computation.
I0929 09:26:45.898922  1584 net.cpp:198] M2PELU18 needs backward computation.
I0929 09:26:45.898924  1584 net.cpp:198] Scale18 needs backward computation.
I0929 09:26:45.898926  1584 net.cpp:198] BatchNorm18 needs backward computation.
I0929 09:26:45.898929  1584 net.cpp:198] Convolution18 needs backward computation.
I0929 09:26:45.898931  1584 net.cpp:198] Eltwise8_M2PELU17_0_split needs backward computation.
I0929 09:26:45.898934  1584 net.cpp:198] M2PELU17 needs backward computation.
I0929 09:26:45.898936  1584 net.cpp:198] Eltwise8 needs backward computation.
I0929 09:26:45.898939  1584 net.cpp:198] Scale17 needs backward computation.
I0929 09:26:45.898942  1584 net.cpp:198] BatchNorm17 needs backward computation.
I0929 09:26:45.898948  1584 net.cpp:198] Convolution17 needs backward computation.
I0929 09:26:45.898950  1584 net.cpp:198] M2PELU16 needs backward computation.
I0929 09:26:45.898953  1584 net.cpp:198] Scale16 needs backward computation.
I0929 09:26:45.898955  1584 net.cpp:198] BatchNorm16 needs backward computation.
I0929 09:26:45.898958  1584 net.cpp:198] Convolution16 needs backward computation.
I0929 09:26:45.898960  1584 net.cpp:198] Eltwise7_M2PELU15_0_split needs backward computation.
I0929 09:26:45.898963  1584 net.cpp:198] M2PELU15 needs backward computation.
I0929 09:26:45.898972  1584 net.cpp:198] Eltwise7 needs backward computation.
I0929 09:26:45.898975  1584 net.cpp:198] Scale15 needs backward computation.
I0929 09:26:45.898978  1584 net.cpp:198] BatchNorm15 needs backward computation.
I0929 09:26:45.898980  1584 net.cpp:198] Convolution15 needs backward computation.
I0929 09:26:45.898983  1584 net.cpp:198] M2PELU14 needs backward computation.
I0929 09:26:45.898985  1584 net.cpp:198] Scale14 needs backward computation.
I0929 09:26:45.898988  1584 net.cpp:198] BatchNorm14 needs backward computation.
I0929 09:26:45.898990  1584 net.cpp:198] Convolution14 needs backward computation.
I0929 09:26:45.898993  1584 net.cpp:198] Eltwise6_M2PELU13_0_split needs backward computation.
I0929 09:26:45.898996  1584 net.cpp:198] M2PELU13 needs backward computation.
I0929 09:26:45.898998  1584 net.cpp:198] Eltwise6 needs backward computation.
I0929 09:26:45.899001  1584 net.cpp:198] Scale13 needs backward computation.
I0929 09:26:45.899003  1584 net.cpp:198] BatchNorm13 needs backward computation.
I0929 09:26:45.899006  1584 net.cpp:198] Convolution13 needs backward computation.
I0929 09:26:45.899008  1584 net.cpp:198] M2PELU12 needs backward computation.
I0929 09:26:45.899011  1584 net.cpp:198] Scale12 needs backward computation.
I0929 09:26:45.899013  1584 net.cpp:198] BatchNorm12 needs backward computation.
I0929 09:26:45.899015  1584 net.cpp:198] Convolution12 needs backward computation.
I0929 09:26:45.899019  1584 net.cpp:198] Eltwise5_M2PELU11_0_split needs backward computation.
I0929 09:26:45.899020  1584 net.cpp:198] M2PELU11 needs backward computation.
I0929 09:26:45.899024  1584 net.cpp:198] Eltwise5 needs backward computation.
I0929 09:26:45.899026  1584 net.cpp:198] Scale11 needs backward computation.
I0929 09:26:45.899029  1584 net.cpp:198] BatchNorm11 needs backward computation.
I0929 09:26:45.899031  1584 net.cpp:198] Convolution11 needs backward computation.
I0929 09:26:45.899034  1584 net.cpp:198] M2PELU10 needs backward computation.
I0929 09:26:45.899036  1584 net.cpp:198] Scale10 needs backward computation.
I0929 09:26:45.899039  1584 net.cpp:198] BatchNorm10 needs backward computation.
I0929 09:26:45.899040  1584 net.cpp:198] Convolution10 needs backward computation.
I0929 09:26:45.899044  1584 net.cpp:198] Eltwise4_M2PELU9_0_split needs backward computation.
I0929 09:26:45.899046  1584 net.cpp:198] M2PELU9 needs backward computation.
I0929 09:26:45.899049  1584 net.cpp:198] Eltwise4 needs backward computation.
I0929 09:26:45.899052  1584 net.cpp:198] Scale9 needs backward computation.
I0929 09:26:45.899055  1584 net.cpp:198] BatchNorm9 needs backward computation.
I0929 09:26:45.899057  1584 net.cpp:198] Convolution9 needs backward computation.
I0929 09:26:45.899060  1584 net.cpp:198] M2PELU8 needs backward computation.
I0929 09:26:45.899062  1584 net.cpp:198] Scale8 needs backward computation.
I0929 09:26:45.899065  1584 net.cpp:198] BatchNorm8 needs backward computation.
I0929 09:26:45.899067  1584 net.cpp:198] Convolution8 needs backward computation.
I0929 09:26:45.899070  1584 net.cpp:198] Eltwise3_M2PELU7_0_split needs backward computation.
I0929 09:26:45.899072  1584 net.cpp:198] M2PELU7 needs backward computation.
I0929 09:26:45.899075  1584 net.cpp:198] Eltwise3 needs backward computation.
I0929 09:26:45.899078  1584 net.cpp:198] Scale7 needs backward computation.
I0929 09:26:45.899080  1584 net.cpp:198] BatchNorm7 needs backward computation.
I0929 09:26:45.899083  1584 net.cpp:198] Convolution7 needs backward computation.
I0929 09:26:45.899085  1584 net.cpp:198] M2PELU6 needs backward computation.
I0929 09:26:45.899088  1584 net.cpp:198] Scale6 needs backward computation.
I0929 09:26:45.899091  1584 net.cpp:198] BatchNorm6 needs backward computation.
I0929 09:26:45.899092  1584 net.cpp:198] Convolution6 needs backward computation.
I0929 09:26:45.899096  1584 net.cpp:198] Eltwise2_M2PELU5_0_split needs backward computation.
I0929 09:26:45.899098  1584 net.cpp:198] M2PELU5 needs backward computation.
I0929 09:26:45.899101  1584 net.cpp:198] Eltwise2 needs backward computation.
I0929 09:26:45.899107  1584 net.cpp:198] Scale5 needs backward computation.
I0929 09:26:45.899111  1584 net.cpp:198] BatchNorm5 needs backward computation.
I0929 09:26:45.899113  1584 net.cpp:198] Convolution5 needs backward computation.
I0929 09:26:45.899116  1584 net.cpp:198] M2PELU4 needs backward computation.
I0929 09:26:45.899118  1584 net.cpp:198] Scale4 needs backward computation.
I0929 09:26:45.899121  1584 net.cpp:198] BatchNorm4 needs backward computation.
I0929 09:26:45.899122  1584 net.cpp:198] Convolution4 needs backward computation.
I0929 09:26:45.926988  1584 net.cpp:198] Eltwise1_M2PELU3_0_split needs backward computation.
I0929 09:26:45.926996  1584 net.cpp:198] M2PELU3 needs backward computation.
I0929 09:26:45.927000  1584 net.cpp:198] Eltwise1 needs backward computation.
I0929 09:26:45.927002  1584 net.cpp:198] Scale3 needs backward computation.
I0929 09:26:45.927006  1584 net.cpp:198] BatchNorm3 needs backward computation.
I0929 09:26:45.927007  1584 net.cpp:198] Convolution3 needs backward computation.
I0929 09:26:45.927011  1584 net.cpp:198] M2PELU2 needs backward computation.
I0929 09:26:45.927013  1584 net.cpp:198] Scale2 needs backward computation.
I0929 09:26:45.927016  1584 net.cpp:198] BatchNorm2 needs backward computation.
I0929 09:26:45.927018  1584 net.cpp:198] Convolution2 needs backward computation.
I0929 09:26:45.927021  1584 net.cpp:198] Convolution1_M2PELU1_0_split needs backward computation.
I0929 09:26:45.927024  1584 net.cpp:198] M2PELU1 needs backward computation.
I0929 09:26:45.927026  1584 net.cpp:198] Scale1 needs backward computation.
I0929 09:26:45.927028  1584 net.cpp:198] BatchNorm1 needs backward computation.
I0929 09:26:45.927031  1584 net.cpp:198] Convolution1 needs backward computation.
I0929 09:26:45.927034  1584 net.cpp:200] Data1 does not need backward computation.
I0929 09:26:45.927037  1584 net.cpp:242] This network produces output SoftmaxWithLoss1
I0929 09:26:45.927145  1584 net.cpp:255] Network initialization done.
I0929 09:26:45.932135  1584 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_mpelu_decay_taylor.prototxt
I0929 09:26:45.932149  1584 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0929 09:26:45.932154  1584 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_mpelu_decay_taylor.prototxt
I0929 09:26:45.932344  1584 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I0929 09:26:45.933508  1584 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU1"
  type: "M2PELU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU2"
  type: "M2PELU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU3"
  type: "M2PELU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU4"
  type: "M2PELU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU5"
  type: "M2PELU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU6"
  type: "M2PELU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU7"
  type: "M2PELU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU8"
  type: "M2PELU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU9"
  type: "M2PELU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU10"
  type: "M2PELU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU11"
  type: "M2PELU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU12"
  type: "M2PELU"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU13"
  type: "M2PELU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU14"
  type: "M2PELU"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU15"
  type: "M2PELU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU16"
  type: "M2PELU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU17"
  type: "M2PELU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU18"
  type: "M2PELU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU19"
  type: "M2PELU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU20"
  type: "M2PELU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU21"
  type: "M2PELU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU22"
  type: "M2PELU"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution24"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU23"
  type: "M2PELU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "taylor"
      alpha: 0.25
      beta: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU24"
  type: "M2PELU"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
   
I0929 09:26:45.960803  1584 layer_factory.hpp:77] Creating layer Data1
I0929 09:26:45.988247  1584 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I0929 09:26:45.988270  1584 net.cpp:84] Creating Layer Data1
I0929 09:26:45.988276  1584 net.cpp:380] Data1 -> Data1
I0929 09:26:45.988283  1584 net.cpp:380] Data1 -> Data2
I0929 09:26:45.988291  1584 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0929 09:26:45.988476  1584 data_layer.cpp:45] output data size: 100,3,32,32
I0929 09:26:45.993388  1584 net.cpp:122] Setting up Data1
I0929 09:26:45.993408  1584 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0929 09:26:45.993412  1584 net.cpp:129] Top shape: 100 (100)
I0929 09:26:45.993415  1584 net.cpp:137] Memory required for data: 1229200
I0929 09:26:45.993420  1584 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0929 09:26:45.993430  1584 net.cpp:84] Creating Layer Data2_Data1_1_split
I0929 09:26:45.993433  1584 net.cpp:406] Data2_Data1_1_split <- Data2
I0929 09:26:45.993438  1584 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0929 09:26:45.993446  1584 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0929 09:26:45.993491  1584 net.cpp:122] Setting up Data2_Data1_1_split
I0929 09:26:45.993496  1584 net.cpp:129] Top shape: 100 (100)
I0929 09:26:45.993499  1584 net.cpp:129] Top shape: 100 (100)
I0929 09:26:45.993501  1584 net.cpp:137] Memory required for data: 1230000
I0929 09:26:45.993504  1584 layer_factory.hpp:77] Creating layer Convolution1
I0929 09:26:45.993513  1584 net.cpp:84] Creating Layer Convolution1
I0929 09:26:45.993515  1584 net.cpp:406] Convolution1 <- Data1
I0929 09:26:45.993521  1584 net.cpp:380] Convolution1 -> Convolution1
I0929 09:26:45.993633  1584 filler.hpp:251] The std of weights in this layer is: 0.264039
I0929 09:26:45.994782  1584 net.cpp:122] Setting up Convolution1
I0929 09:26:45.994793  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:45.994796  1584 net.cpp:137] Memory required for data: 7783600
I0929 09:26:45.994803  1584 layer_factory.hpp:77] Creating layer BatchNorm1
I0929 09:26:45.994809  1584 net.cpp:84] Creating Layer BatchNorm1
I0929 09:26:45.994813  1584 net.cpp:406] BatchNorm1 <- Convolution1
I0929 09:26:45.994817  1584 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0929 09:26:45.994968  1584 net.cpp:122] Setting up BatchNorm1
I0929 09:26:45.994972  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:45.994976  1584 net.cpp:137] Memory required for data: 14337200
I0929 09:26:45.994982  1584 layer_factory.hpp:77] Creating layer Scale1
I0929 09:26:45.994988  1584 net.cpp:84] Creating Layer Scale1
I0929 09:26:45.994990  1584 net.cpp:406] Scale1 <- Convolution1
I0929 09:26:45.994994  1584 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0929 09:26:45.995024  1584 layer_factory.hpp:77] Creating layer Scale1
I0929 09:26:45.995110  1584 net.cpp:122] Setting up Scale1
I0929 09:26:45.995115  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:45.995116  1584 net.cpp:137] Memory required for data: 20890800
I0929 09:26:45.995121  1584 layer_factory.hpp:77] Creating layer M2PELU1
I0929 09:26:45.995126  1584 net.cpp:84] Creating Layer M2PELU1
I0929 09:26:45.995128  1584 net.cpp:406] M2PELU1 <- Convolution1
I0929 09:26:45.995132  1584 net.cpp:367] M2PELU1 -> Convolution1 (in-place)
I0929 09:26:45.995755  1584 net.cpp:122] Setting up M2PELU1
I0929 09:26:45.995764  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:45.995766  1584 net.cpp:137] Memory required for data: 27444400
I0929 09:26:45.995774  1584 layer_factory.hpp:77] Creating layer Convolution1_M2PELU1_0_split
I0929 09:26:45.995779  1584 net.cpp:84] Creating Layer Convolution1_M2PELU1_0_split
I0929 09:26:45.995781  1584 net.cpp:406] Convolution1_M2PELU1_0_split <- Convolution1
I0929 09:26:45.995784  1584 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_0
I0929 09:26:45.995790  1584 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_1
I0929 09:26:45.995820  1584 net.cpp:122] Setting up Convolution1_M2PELU1_0_split
I0929 09:26:45.995823  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:45.995847  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:45.995851  1584 net.cpp:137] Memory required for data: 40551600
I0929 09:26:45.995853  1584 layer_factory.hpp:77] Creating layer Convolution2
I0929 09:26:45.995862  1584 net.cpp:84] Creating Layer Convolution2
I0929 09:26:45.995864  1584 net.cpp:406] Convolution2 <- Convolution1_M2PELU1_0_split_0
I0929 09:26:45.995868  1584 net.cpp:380] Convolution2 -> Convolution2
I0929 09:26:45.996084  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:45.996991  1584 net.cpp:122] Setting up Convolution2
I0929 09:26:45.997004  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:45.997009  1584 net.cpp:137] Memory required for data: 47105200
I0929 09:26:45.997014  1584 layer_factory.hpp:77] Creating layer BatchNorm2
I0929 09:26:45.997021  1584 net.cpp:84] Creating Layer BatchNorm2
I0929 09:26:45.997025  1584 net.cpp:406] BatchNorm2 <- Convolution2
I0929 09:26:45.997027  1584 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0929 09:26:45.997195  1584 net.cpp:122] Setting up BatchNorm2
I0929 09:26:45.997200  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:45.997202  1584 net.cpp:137] Memory required for data: 53658800
I0929 09:26:45.997207  1584 layer_factory.hpp:77] Creating layer Scale2
I0929 09:26:45.997212  1584 net.cpp:84] Creating Layer Scale2
I0929 09:26:45.997215  1584 net.cpp:406] Scale2 <- Convolution2
I0929 09:26:45.997218  1584 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0929 09:26:45.997249  1584 layer_factory.hpp:77] Creating layer Scale2
I0929 09:26:45.997341  1584 net.cpp:122] Setting up Scale2
I0929 09:26:45.997346  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:45.997349  1584 net.cpp:137] Memory required for data: 60212400
I0929 09:26:45.997352  1584 layer_factory.hpp:77] Creating layer M2PELU2
I0929 09:26:45.997359  1584 net.cpp:84] Creating Layer M2PELU2
I0929 09:26:45.997360  1584 net.cpp:406] M2PELU2 <- Convolution2
I0929 09:26:45.997364  1584 net.cpp:367] M2PELU2 -> Convolution2 (in-place)
I0929 09:26:45.997625  1584 net.cpp:122] Setting up M2PELU2
I0929 09:26:45.997638  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:45.997642  1584 net.cpp:137] Memory required for data: 66766000
I0929 09:26:45.997651  1584 layer_factory.hpp:77] Creating layer Convolution3
I0929 09:26:45.997664  1584 net.cpp:84] Creating Layer Convolution3
I0929 09:26:45.997668  1584 net.cpp:406] Convolution3 <- Convolution2
I0929 09:26:45.997674  1584 net.cpp:380] Convolution3 -> Convolution3
I0929 09:26:45.997779  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:45.998755  1584 net.cpp:122] Setting up Convolution3
I0929 09:26:45.998765  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:45.998769  1584 net.cpp:137] Memory required for data: 73319600
I0929 09:26:45.998772  1584 layer_factory.hpp:77] Creating layer BatchNorm3
I0929 09:26:45.998778  1584 net.cpp:84] Creating Layer BatchNorm3
I0929 09:26:45.998780  1584 net.cpp:406] BatchNorm3 <- Convolution3
I0929 09:26:45.998785  1584 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0929 09:26:45.999035  1584 net.cpp:122] Setting up BatchNorm3
I0929 09:26:45.999044  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:45.999049  1584 net.cpp:137] Memory required for data: 79873200
I0929 09:26:45.999054  1584 layer_factory.hpp:77] Creating layer Scale3
I0929 09:26:45.999060  1584 net.cpp:84] Creating Layer Scale3
I0929 09:26:45.999063  1584 net.cpp:406] Scale3 <- Convolution3
I0929 09:26:45.999066  1584 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0929 09:26:45.999099  1584 layer_factory.hpp:77] Creating layer Scale3
I0929 09:26:45.999186  1584 net.cpp:122] Setting up Scale3
I0929 09:26:45.999191  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:45.999193  1584 net.cpp:137] Memory required for data: 86426800
I0929 09:26:45.999197  1584 layer_factory.hpp:77] Creating layer Eltwise1
I0929 09:26:45.999202  1584 net.cpp:84] Creating Layer Eltwise1
I0929 09:26:45.999217  1584 net.cpp:406] Eltwise1 <- Convolution1_M2PELU1_0_split_1
I0929 09:26:45.999219  1584 net.cpp:406] Eltwise1 <- Convolution3
I0929 09:26:45.999225  1584 net.cpp:380] Eltwise1 -> Eltwise1
I0929 09:26:45.999245  1584 net.cpp:122] Setting up Eltwise1
I0929 09:26:45.999251  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:45.999253  1584 net.cpp:137] Memory required for data: 92980400
I0929 09:26:45.999256  1584 layer_factory.hpp:77] Creating layer M2PELU3
I0929 09:26:45.999260  1584 net.cpp:84] Creating Layer M2PELU3
I0929 09:26:45.999264  1584 net.cpp:406] M2PELU3 <- Eltwise1
I0929 09:26:45.999266  1584 net.cpp:367] M2PELU3 -> Eltwise1 (in-place)
I0929 09:26:45.999368  1584 net.cpp:122] Setting up M2PELU3
I0929 09:26:45.999372  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:45.999374  1584 net.cpp:137] Memory required for data: 99534000
I0929 09:26:45.999378  1584 layer_factory.hpp:77] Creating layer Eltwise1_M2PELU3_0_split
I0929 09:26:45.999387  1584 net.cpp:84] Creating Layer Eltwise1_M2PELU3_0_split
I0929 09:26:45.999389  1584 net.cpp:406] Eltwise1_M2PELU3_0_split <- Eltwise1
I0929 09:26:45.999394  1584 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_0
I0929 09:26:45.999398  1584 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_1
I0929 09:26:45.999426  1584 net.cpp:122] Setting up Eltwise1_M2PELU3_0_split
I0929 09:26:45.999430  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:45.999433  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:45.999434  1584 net.cpp:137] Memory required for data: 112641200
I0929 09:26:45.999439  1584 layer_factory.hpp:77] Creating layer Convolution4
I0929 09:26:45.999445  1584 net.cpp:84] Creating Layer Convolution4
I0929 09:26:45.999447  1584 net.cpp:406] Convolution4 <- Eltwise1_M2PELU3_0_split_0
I0929 09:26:45.999452  1584 net.cpp:380] Convolution4 -> Convolution4
I0929 09:26:45.999544  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:46.000531  1584 net.cpp:122] Setting up Convolution4
I0929 09:26:46.000540  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.000543  1584 net.cpp:137] Memory required for data: 119194800
I0929 09:26:46.000548  1584 layer_factory.hpp:77] Creating layer BatchNorm4
I0929 09:26:46.000553  1584 net.cpp:84] Creating Layer BatchNorm4
I0929 09:26:46.000556  1584 net.cpp:406] BatchNorm4 <- Convolution4
I0929 09:26:46.000560  1584 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0929 09:26:46.000712  1584 net.cpp:122] Setting up BatchNorm4
I0929 09:26:46.000717  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.000720  1584 net.cpp:137] Memory required for data: 125748400
I0929 09:26:46.000723  1584 layer_factory.hpp:77] Creating layer Scale4
I0929 09:26:46.000728  1584 net.cpp:84] Creating Layer Scale4
I0929 09:26:46.000731  1584 net.cpp:406] Scale4 <- Convolution4
I0929 09:26:46.000735  1584 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0929 09:26:46.000792  1584 layer_factory.hpp:77] Creating layer Scale4
I0929 09:26:46.000907  1584 net.cpp:122] Setting up Scale4
I0929 09:26:46.000915  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.000916  1584 net.cpp:137] Memory required for data: 132302000
I0929 09:26:46.000923  1584 layer_factory.hpp:77] Creating layer M2PELU4
I0929 09:26:46.000931  1584 net.cpp:84] Creating Layer M2PELU4
I0929 09:26:46.000932  1584 net.cpp:406] M2PELU4 <- Convolution4
I0929 09:26:46.000936  1584 net.cpp:367] M2PELU4 -> Convolution4 (in-place)
I0929 09:26:46.001037  1584 net.cpp:122] Setting up M2PELU4
I0929 09:26:46.001041  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.001044  1584 net.cpp:137] Memory required for data: 138855600
I0929 09:26:46.001047  1584 layer_factory.hpp:77] Creating layer Convolution5
I0929 09:26:46.001055  1584 net.cpp:84] Creating Layer Convolution5
I0929 09:26:46.001057  1584 net.cpp:406] Convolution5 <- Convolution4
I0929 09:26:46.001061  1584 net.cpp:380] Convolution5 -> Convolution5
I0929 09:26:46.001160  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:46.002077  1584 net.cpp:122] Setting up Convolution5
I0929 09:26:46.002086  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.002089  1584 net.cpp:137] Memory required for data: 145409200
I0929 09:26:46.002094  1584 layer_factory.hpp:77] Creating layer BatchNorm5
I0929 09:26:46.002099  1584 net.cpp:84] Creating Layer BatchNorm5
I0929 09:26:46.002101  1584 net.cpp:406] BatchNorm5 <- Convolution5
I0929 09:26:46.002105  1584 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0929 09:26:46.002261  1584 net.cpp:122] Setting up BatchNorm5
I0929 09:26:46.002265  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.002267  1584 net.cpp:137] Memory required for data: 151962800
I0929 09:26:46.002272  1584 layer_factory.hpp:77] Creating layer Scale5
I0929 09:26:46.002276  1584 net.cpp:84] Creating Layer Scale5
I0929 09:26:46.002279  1584 net.cpp:406] Scale5 <- Convolution5
I0929 09:26:46.002281  1584 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0929 09:26:46.002312  1584 layer_factory.hpp:77] Creating layer Scale5
I0929 09:26:46.002396  1584 net.cpp:122] Setting up Scale5
I0929 09:26:46.002400  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.002403  1584 net.cpp:137] Memory required for data: 158516400
I0929 09:26:46.002406  1584 layer_factory.hpp:77] Creating layer Eltwise2
I0929 09:26:46.002410  1584 net.cpp:84] Creating Layer Eltwise2
I0929 09:26:46.002413  1584 net.cpp:406] Eltwise2 <- Eltwise1_M2PELU3_0_split_1
I0929 09:26:46.002415  1584 net.cpp:406] Eltwise2 <- Convolution5
I0929 09:26:46.002419  1584 net.cpp:380] Eltwise2 -> Eltwise2
I0929 09:26:46.002436  1584 net.cpp:122] Setting up Eltwise2
I0929 09:26:46.002439  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.002441  1584 net.cpp:137] Memory required for data: 165070000
I0929 09:26:46.002444  1584 layer_factory.hpp:77] Creating layer M2PELU5
I0929 09:26:46.002449  1584 net.cpp:84] Creating Layer M2PELU5
I0929 09:26:46.002450  1584 net.cpp:406] M2PELU5 <- Eltwise2
I0929 09:26:46.002454  1584 net.cpp:367] M2PELU5 -> Eltwise2 (in-place)
I0929 09:26:46.002585  1584 net.cpp:122] Setting up M2PELU5
I0929 09:26:46.002590  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.002593  1584 net.cpp:137] Memory required for data: 171623600
I0929 09:26:46.002596  1584 layer_factory.hpp:77] Creating layer Eltwise2_M2PELU5_0_split
I0929 09:26:46.002600  1584 net.cpp:84] Creating Layer Eltwise2_M2PELU5_0_split
I0929 09:26:46.002602  1584 net.cpp:406] Eltwise2_M2PELU5_0_split <- Eltwise2
I0929 09:26:46.002606  1584 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_0
I0929 09:26:46.002611  1584 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_1
I0929 09:26:46.002638  1584 net.cpp:122] Setting up Eltwise2_M2PELU5_0_split
I0929 09:26:46.002642  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.002645  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.002647  1584 net.cpp:137] Memory required for data: 184730800
I0929 09:26:46.002650  1584 layer_factory.hpp:77] Creating layer Convolution6
I0929 09:26:46.002655  1584 net.cpp:84] Creating Layer Convolution6
I0929 09:26:46.002658  1584 net.cpp:406] Convolution6 <- Eltwise2_M2PELU5_0_split_0
I0929 09:26:46.002661  1584 net.cpp:380] Convolution6 -> Convolution6
I0929 09:26:46.002753  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:46.003608  1584 net.cpp:122] Setting up Convolution6
I0929 09:26:46.003618  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.003620  1584 net.cpp:137] Memory required for data: 191284400
I0929 09:26:46.003625  1584 layer_factory.hpp:77] Creating layer BatchNorm6
I0929 09:26:46.018985  1584 net.cpp:84] Creating Layer BatchNorm6
I0929 09:26:46.018992  1584 net.cpp:406] BatchNorm6 <- Convolution6
I0929 09:26:46.018998  1584 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0929 09:26:46.019178  1584 net.cpp:122] Setting up BatchNorm6
I0929 09:26:46.019191  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.019194  1584 net.cpp:137] Memory required for data: 197838000
I0929 09:26:46.019201  1584 layer_factory.hpp:77] Creating layer Scale6
I0929 09:26:46.019206  1584 net.cpp:84] Creating Layer Scale6
I0929 09:26:46.019208  1584 net.cpp:406] Scale6 <- Convolution6
I0929 09:26:46.019212  1584 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0929 09:26:46.019246  1584 layer_factory.hpp:77] Creating layer Scale6
I0929 09:26:46.019340  1584 net.cpp:122] Setting up Scale6
I0929 09:26:46.019345  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.019347  1584 net.cpp:137] Memory required for data: 204391600
I0929 09:26:46.019351  1584 layer_factory.hpp:77] Creating layer M2PELU6
I0929 09:26:46.019357  1584 net.cpp:84] Creating Layer M2PELU6
I0929 09:26:46.019361  1584 net.cpp:406] M2PELU6 <- Convolution6
I0929 09:26:46.019363  1584 net.cpp:367] M2PELU6 -> Convolution6 (in-place)
I0929 09:26:46.019474  1584 net.cpp:122] Setting up M2PELU6
I0929 09:26:46.019479  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.019480  1584 net.cpp:137] Memory required for data: 210945200
I0929 09:26:46.019484  1584 layer_factory.hpp:77] Creating layer Convolution7
I0929 09:26:46.019491  1584 net.cpp:84] Creating Layer Convolution7
I0929 09:26:46.019495  1584 net.cpp:406] Convolution7 <- Convolution6
I0929 09:26:46.019498  1584 net.cpp:380] Convolution7 -> Convolution7
I0929 09:26:46.019603  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:46.020579  1584 net.cpp:122] Setting up Convolution7
I0929 09:26:46.020598  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.020602  1584 net.cpp:137] Memory required for data: 217498800
I0929 09:26:46.020607  1584 layer_factory.hpp:77] Creating layer BatchNorm7
I0929 09:26:46.020614  1584 net.cpp:84] Creating Layer BatchNorm7
I0929 09:26:46.020617  1584 net.cpp:406] BatchNorm7 <- Convolution7
I0929 09:26:46.020622  1584 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0929 09:26:46.020830  1584 net.cpp:122] Setting up BatchNorm7
I0929 09:26:46.020849  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.020853  1584 net.cpp:137] Memory required for data: 224052400
I0929 09:26:46.020861  1584 layer_factory.hpp:77] Creating layer Scale7
I0929 09:26:46.020869  1584 net.cpp:84] Creating Layer Scale7
I0929 09:26:46.020872  1584 net.cpp:406] Scale7 <- Convolution7
I0929 09:26:46.020877  1584 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0929 09:26:46.020932  1584 layer_factory.hpp:77] Creating layer Scale7
I0929 09:26:46.021073  1584 net.cpp:122] Setting up Scale7
I0929 09:26:46.021080  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.021085  1584 net.cpp:137] Memory required for data: 230606000
I0929 09:26:46.021090  1584 layer_factory.hpp:77] Creating layer Eltwise3
I0929 09:26:46.021100  1584 net.cpp:84] Creating Layer Eltwise3
I0929 09:26:46.021103  1584 net.cpp:406] Eltwise3 <- Eltwise2_M2PELU5_0_split_1
I0929 09:26:46.021108  1584 net.cpp:406] Eltwise3 <- Convolution7
I0929 09:26:46.021113  1584 net.cpp:380] Eltwise3 -> Eltwise3
I0929 09:26:46.021142  1584 net.cpp:122] Setting up Eltwise3
I0929 09:26:46.021147  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.021152  1584 net.cpp:137] Memory required for data: 237159600
I0929 09:26:46.021159  1584 layer_factory.hpp:77] Creating layer M2PELU7
I0929 09:26:46.021167  1584 net.cpp:84] Creating Layer M2PELU7
I0929 09:26:46.021172  1584 net.cpp:406] M2PELU7 <- Eltwise3
I0929 09:26:46.021176  1584 net.cpp:367] M2PELU7 -> Eltwise3 (in-place)
I0929 09:26:46.021329  1584 net.cpp:122] Setting up M2PELU7
I0929 09:26:46.021337  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.021342  1584 net.cpp:137] Memory required for data: 243713200
I0929 09:26:46.021348  1584 layer_factory.hpp:77] Creating layer Eltwise3_M2PELU7_0_split
I0929 09:26:46.021354  1584 net.cpp:84] Creating Layer Eltwise3_M2PELU7_0_split
I0929 09:26:46.021368  1584 net.cpp:406] Eltwise3_M2PELU7_0_split <- Eltwise3
I0929 09:26:46.021373  1584 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_0
I0929 09:26:46.021380  1584 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_1
I0929 09:26:46.021423  1584 net.cpp:122] Setting up Eltwise3_M2PELU7_0_split
I0929 09:26:46.021430  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.021435  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.021438  1584 net.cpp:137] Memory required for data: 256820400
I0929 09:26:46.021442  1584 layer_factory.hpp:77] Creating layer Convolution8
I0929 09:26:46.021452  1584 net.cpp:84] Creating Layer Convolution8
I0929 09:26:46.021467  1584 net.cpp:406] Convolution8 <- Eltwise3_M2PELU7_0_split_0
I0929 09:26:46.021476  1584 net.cpp:380] Convolution8 -> Convolution8
I0929 09:26:46.021602  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:46.022505  1584 net.cpp:122] Setting up Convolution8
I0929 09:26:46.022516  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.022518  1584 net.cpp:137] Memory required for data: 263374000
I0929 09:26:46.022557  1584 layer_factory.hpp:77] Creating layer BatchNorm8
I0929 09:26:46.022562  1584 net.cpp:84] Creating Layer BatchNorm8
I0929 09:26:46.022574  1584 net.cpp:406] BatchNorm8 <- Convolution8
I0929 09:26:46.022579  1584 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0929 09:26:46.022781  1584 net.cpp:122] Setting up BatchNorm8
I0929 09:26:46.022789  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.022790  1584 net.cpp:137] Memory required for data: 269927600
I0929 09:26:46.022795  1584 layer_factory.hpp:77] Creating layer Scale8
I0929 09:26:46.022800  1584 net.cpp:84] Creating Layer Scale8
I0929 09:26:46.022804  1584 net.cpp:406] Scale8 <- Convolution8
I0929 09:26:46.022806  1584 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0929 09:26:46.022837  1584 layer_factory.hpp:77] Creating layer Scale8
I0929 09:26:46.022941  1584 net.cpp:122] Setting up Scale8
I0929 09:26:46.022949  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.022953  1584 net.cpp:137] Memory required for data: 276481200
I0929 09:26:46.022959  1584 layer_factory.hpp:77] Creating layer M2PELU8
I0929 09:26:46.022967  1584 net.cpp:84] Creating Layer M2PELU8
I0929 09:26:46.022972  1584 net.cpp:406] M2PELU8 <- Convolution8
I0929 09:26:46.022975  1584 net.cpp:367] M2PELU8 -> Convolution8 (in-place)
I0929 09:26:46.023080  1584 net.cpp:122] Setting up M2PELU8
I0929 09:26:46.023085  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.023087  1584 net.cpp:137] Memory required for data: 283034800
I0929 09:26:46.023092  1584 layer_factory.hpp:77] Creating layer Convolution9
I0929 09:26:46.023097  1584 net.cpp:84] Creating Layer Convolution9
I0929 09:26:46.023099  1584 net.cpp:406] Convolution9 <- Convolution8
I0929 09:26:46.023104  1584 net.cpp:380] Convolution9 -> Convolution9
I0929 09:26:46.023198  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:46.024065  1584 net.cpp:122] Setting up Convolution9
I0929 09:26:46.024072  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.024075  1584 net.cpp:137] Memory required for data: 289588400
I0929 09:26:46.024080  1584 layer_factory.hpp:77] Creating layer BatchNorm9
I0929 09:26:46.024085  1584 net.cpp:84] Creating Layer BatchNorm9
I0929 09:26:46.024088  1584 net.cpp:406] BatchNorm9 <- Convolution9
I0929 09:26:46.024091  1584 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0929 09:26:46.024243  1584 net.cpp:122] Setting up BatchNorm9
I0929 09:26:46.024247  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.024250  1584 net.cpp:137] Memory required for data: 296142000
I0929 09:26:46.024255  1584 layer_factory.hpp:77] Creating layer Scale9
I0929 09:26:46.024258  1584 net.cpp:84] Creating Layer Scale9
I0929 09:26:46.024261  1584 net.cpp:406] Scale9 <- Convolution9
I0929 09:26:46.024265  1584 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0929 09:26:46.024312  1584 layer_factory.hpp:77] Creating layer Scale9
I0929 09:26:46.024399  1584 net.cpp:122] Setting up Scale9
I0929 09:26:46.024404  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.024406  1584 net.cpp:137] Memory required for data: 302695600
I0929 09:26:46.024410  1584 layer_factory.hpp:77] Creating layer Eltwise4
I0929 09:26:46.024415  1584 net.cpp:84] Creating Layer Eltwise4
I0929 09:26:46.024417  1584 net.cpp:406] Eltwise4 <- Eltwise3_M2PELU7_0_split_1
I0929 09:26:46.024420  1584 net.cpp:406] Eltwise4 <- Convolution9
I0929 09:26:46.024425  1584 net.cpp:380] Eltwise4 -> Eltwise4
I0929 09:26:46.024443  1584 net.cpp:122] Setting up Eltwise4
I0929 09:26:46.024447  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.024449  1584 net.cpp:137] Memory required for data: 309249200
I0929 09:26:46.024451  1584 layer_factory.hpp:77] Creating layer M2PELU9
I0929 09:26:46.024456  1584 net.cpp:84] Creating Layer M2PELU9
I0929 09:26:46.024458  1584 net.cpp:406] M2PELU9 <- Eltwise4
I0929 09:26:46.024462  1584 net.cpp:367] M2PELU9 -> Eltwise4 (in-place)
I0929 09:26:46.024564  1584 net.cpp:122] Setting up M2PELU9
I0929 09:26:46.024569  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.024570  1584 net.cpp:137] Memory required for data: 315802800
I0929 09:26:46.024574  1584 layer_factory.hpp:77] Creating layer Eltwise4_M2PELU9_0_split
I0929 09:26:46.024579  1584 net.cpp:84] Creating Layer Eltwise4_M2PELU9_0_split
I0929 09:26:46.024580  1584 net.cpp:406] Eltwise4_M2PELU9_0_split <- Eltwise4
I0929 09:26:46.024585  1584 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_0
I0929 09:26:46.024588  1584 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_1
I0929 09:26:46.024615  1584 net.cpp:122] Setting up Eltwise4_M2PELU9_0_split
I0929 09:26:46.024618  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.024621  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.024622  1584 net.cpp:137] Memory required for data: 328910000
I0929 09:26:46.024626  1584 layer_factory.hpp:77] Creating layer Convolution10
I0929 09:26:46.024631  1584 net.cpp:84] Creating Layer Convolution10
I0929 09:26:46.024633  1584 net.cpp:406] Convolution10 <- Eltwise4_M2PELU9_0_split_0
I0929 09:26:46.024637  1584 net.cpp:380] Convolution10 -> Convolution10
I0929 09:26:46.024730  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:46.025609  1584 net.cpp:122] Setting up Convolution10
I0929 09:26:46.025616  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.025619  1584 net.cpp:137] Memory required for data: 335463600
I0929 09:26:46.025624  1584 layer_factory.hpp:77] Creating layer BatchNorm10
I0929 09:26:46.025629  1584 net.cpp:84] Creating Layer BatchNorm10
I0929 09:26:46.025631  1584 net.cpp:406] BatchNorm10 <- Convolution10
I0929 09:26:46.025635  1584 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0929 09:26:46.025789  1584 net.cpp:122] Setting up BatchNorm10
I0929 09:26:46.025794  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.025795  1584 net.cpp:137] Memory required for data: 342017200
I0929 09:26:46.025800  1584 layer_factory.hpp:77] Creating layer Scale10
I0929 09:26:46.025804  1584 net.cpp:84] Creating Layer Scale10
I0929 09:26:46.025807  1584 net.cpp:406] Scale10 <- Convolution10
I0929 09:26:46.025810  1584 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0929 09:26:46.025840  1584 layer_factory.hpp:77] Creating layer Scale10
I0929 09:26:46.025925  1584 net.cpp:122] Setting up Scale10
I0929 09:26:46.025929  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.025931  1584 net.cpp:137] Memory required for data: 348570800
I0929 09:26:46.025935  1584 layer_factory.hpp:77] Creating layer M2PELU10
I0929 09:26:46.025940  1584 net.cpp:84] Creating Layer M2PELU10
I0929 09:26:46.025943  1584 net.cpp:406] M2PELU10 <- Convolution10
I0929 09:26:46.025946  1584 net.cpp:367] M2PELU10 -> Convolution10 (in-place)
I0929 09:26:46.026046  1584 net.cpp:122] Setting up M2PELU10
I0929 09:26:46.026055  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.026057  1584 net.cpp:137] Memory required for data: 355124400
I0929 09:26:46.026062  1584 layer_factory.hpp:77] Creating layer Convolution11
I0929 09:26:46.026068  1584 net.cpp:84] Creating Layer Convolution11
I0929 09:26:46.026070  1584 net.cpp:406] Convolution11 <- Convolution10
I0929 09:26:46.026075  1584 net.cpp:380] Convolution11 -> Convolution11
I0929 09:26:46.026170  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:46.027382  1584 net.cpp:122] Setting up Convolution11
I0929 09:26:46.027391  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.027395  1584 net.cpp:137] Memory required for data: 361678000
I0929 09:26:46.027398  1584 layer_factory.hpp:77] Creating layer BatchNorm11
I0929 09:26:46.027403  1584 net.cpp:84] Creating Layer BatchNorm11
I0929 09:26:46.027406  1584 net.cpp:406] BatchNorm11 <- Convolution11
I0929 09:26:46.027410  1584 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0929 09:26:46.027566  1584 net.cpp:122] Setting up BatchNorm11
I0929 09:26:46.027570  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.027572  1584 net.cpp:137] Memory required for data: 368231600
I0929 09:26:46.027577  1584 layer_factory.hpp:77] Creating layer Scale11
I0929 09:26:46.027581  1584 net.cpp:84] Creating Layer Scale11
I0929 09:26:46.027583  1584 net.cpp:406] Scale11 <- Convolution11
I0929 09:26:46.027588  1584 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0929 09:26:46.027617  1584 layer_factory.hpp:77] Creating layer Scale11
I0929 09:26:46.027704  1584 net.cpp:122] Setting up Scale11
I0929 09:26:46.027707  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.027709  1584 net.cpp:137] Memory required for data: 374785200
I0929 09:26:46.027714  1584 layer_factory.hpp:77] Creating layer Eltwise5
I0929 09:26:46.027716  1584 net.cpp:84] Creating Layer Eltwise5
I0929 09:26:46.027719  1584 net.cpp:406] Eltwise5 <- Eltwise4_M2PELU9_0_split_1
I0929 09:26:46.027722  1584 net.cpp:406] Eltwise5 <- Convolution11
I0929 09:26:46.027725  1584 net.cpp:380] Eltwise5 -> Eltwise5
I0929 09:26:46.027742  1584 net.cpp:122] Setting up Eltwise5
I0929 09:26:46.027746  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.027748  1584 net.cpp:137] Memory required for data: 381338800
I0929 09:26:46.027750  1584 layer_factory.hpp:77] Creating layer M2PELU11
I0929 09:26:46.027755  1584 net.cpp:84] Creating Layer M2PELU11
I0929 09:26:46.027757  1584 net.cpp:406] M2PELU11 <- Eltwise5
I0929 09:26:46.027760  1584 net.cpp:367] M2PELU11 -> Eltwise5 (in-place)
I0929 09:26:46.027863  1584 net.cpp:122] Setting up M2PELU11
I0929 09:26:46.027866  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.027868  1584 net.cpp:137] Memory required for data: 387892400
I0929 09:26:46.027871  1584 layer_factory.hpp:77] Creating layer Eltwise5_M2PELU11_0_split
I0929 09:26:46.027875  1584 net.cpp:84] Creating Layer Eltwise5_M2PELU11_0_split
I0929 09:26:46.027878  1584 net.cpp:406] Eltwise5_M2PELU11_0_split <- Eltwise5
I0929 09:26:46.027880  1584 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_0
I0929 09:26:46.027885  1584 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_1
I0929 09:26:46.027911  1584 net.cpp:122] Setting up Eltwise5_M2PELU11_0_split
I0929 09:26:46.027915  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.027918  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.027920  1584 net.cpp:137] Memory required for data: 400999600
I0929 09:26:46.027922  1584 layer_factory.hpp:77] Creating layer Convolution12
I0929 09:26:46.049808  1584 net.cpp:84] Creating Layer Convolution12
I0929 09:26:46.049816  1584 net.cpp:406] Convolution12 <- Eltwise5_M2PELU11_0_split_0
I0929 09:26:46.049823  1584 net.cpp:380] Convolution12 -> Convolution12
I0929 09:26:46.049947  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:46.050941  1584 net.cpp:122] Setting up Convolution12
I0929 09:26:46.050961  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.050963  1584 net.cpp:137] Memory required for data: 407553200
I0929 09:26:46.050969  1584 layer_factory.hpp:77] Creating layer BatchNorm12
I0929 09:26:46.050976  1584 net.cpp:84] Creating Layer BatchNorm12
I0929 09:26:46.050978  1584 net.cpp:406] BatchNorm12 <- Convolution12
I0929 09:26:46.050982  1584 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0929 09:26:46.051178  1584 net.cpp:122] Setting up BatchNorm12
I0929 09:26:46.051185  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.051188  1584 net.cpp:137] Memory required for data: 414106800
I0929 09:26:46.051193  1584 layer_factory.hpp:77] Creating layer Scale12
I0929 09:26:46.051199  1584 net.cpp:84] Creating Layer Scale12
I0929 09:26:46.051203  1584 net.cpp:406] Scale12 <- Convolution12
I0929 09:26:46.051206  1584 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0929 09:26:46.051241  1584 layer_factory.hpp:77] Creating layer Scale12
I0929 09:26:46.051367  1584 net.cpp:122] Setting up Scale12
I0929 09:26:46.051371  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.051373  1584 net.cpp:137] Memory required for data: 420660400
I0929 09:26:46.051378  1584 layer_factory.hpp:77] Creating layer M2PELU12
I0929 09:26:46.051383  1584 net.cpp:84] Creating Layer M2PELU12
I0929 09:26:46.051385  1584 net.cpp:406] M2PELU12 <- Convolution12
I0929 09:26:46.051389  1584 net.cpp:367] M2PELU12 -> Convolution12 (in-place)
I0929 09:26:46.051496  1584 net.cpp:122] Setting up M2PELU12
I0929 09:26:46.051501  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.051502  1584 net.cpp:137] Memory required for data: 427214000
I0929 09:26:46.051515  1584 layer_factory.hpp:77] Creating layer Convolution13
I0929 09:26:46.051522  1584 net.cpp:84] Creating Layer Convolution13
I0929 09:26:46.051524  1584 net.cpp:406] Convolution13 <- Convolution12
I0929 09:26:46.051528  1584 net.cpp:380] Convolution13 -> Convolution13
I0929 09:26:46.051635  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:46.053086  1584 net.cpp:122] Setting up Convolution13
I0929 09:26:46.053094  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.053097  1584 net.cpp:137] Memory required for data: 433767600
I0929 09:26:46.053102  1584 layer_factory.hpp:77] Creating layer BatchNorm13
I0929 09:26:46.053107  1584 net.cpp:84] Creating Layer BatchNorm13
I0929 09:26:46.053110  1584 net.cpp:406] BatchNorm13 <- Convolution13
I0929 09:26:46.053115  1584 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0929 09:26:46.053313  1584 net.cpp:122] Setting up BatchNorm13
I0929 09:26:46.053321  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.053323  1584 net.cpp:137] Memory required for data: 440321200
I0929 09:26:46.053329  1584 layer_factory.hpp:77] Creating layer Scale13
I0929 09:26:46.053334  1584 net.cpp:84] Creating Layer Scale13
I0929 09:26:46.053338  1584 net.cpp:406] Scale13 <- Convolution13
I0929 09:26:46.053340  1584 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0929 09:26:46.053373  1584 layer_factory.hpp:77] Creating layer Scale13
I0929 09:26:46.053473  1584 net.cpp:122] Setting up Scale13
I0929 09:26:46.053478  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.053481  1584 net.cpp:137] Memory required for data: 446874800
I0929 09:26:46.053488  1584 layer_factory.hpp:77] Creating layer Eltwise6
I0929 09:26:46.053503  1584 net.cpp:84] Creating Layer Eltwise6
I0929 09:26:46.053508  1584 net.cpp:406] Eltwise6 <- Eltwise5_M2PELU11_0_split_1
I0929 09:26:46.053513  1584 net.cpp:406] Eltwise6 <- Convolution13
I0929 09:26:46.053516  1584 net.cpp:380] Eltwise6 -> Eltwise6
I0929 09:26:46.053540  1584 net.cpp:122] Setting up Eltwise6
I0929 09:26:46.053547  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.053550  1584 net.cpp:137] Memory required for data: 453428400
I0929 09:26:46.053555  1584 layer_factory.hpp:77] Creating layer M2PELU13
I0929 09:26:46.053563  1584 net.cpp:84] Creating Layer M2PELU13
I0929 09:26:46.053576  1584 net.cpp:406] M2PELU13 <- Eltwise6
I0929 09:26:46.053581  1584 net.cpp:367] M2PELU13 -> Eltwise6 (in-place)
I0929 09:26:46.053706  1584 net.cpp:122] Setting up M2PELU13
I0929 09:26:46.053712  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.053714  1584 net.cpp:137] Memory required for data: 459982000
I0929 09:26:46.053719  1584 layer_factory.hpp:77] Creating layer Eltwise6_M2PELU13_0_split
I0929 09:26:46.053722  1584 net.cpp:84] Creating Layer Eltwise6_M2PELU13_0_split
I0929 09:26:46.053725  1584 net.cpp:406] Eltwise6_M2PELU13_0_split <- Eltwise6
I0929 09:26:46.053730  1584 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_0
I0929 09:26:46.053735  1584 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_1
I0929 09:26:46.053766  1584 net.cpp:122] Setting up Eltwise6_M2PELU13_0_split
I0929 09:26:46.053782  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.053787  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.053791  1584 net.cpp:137] Memory required for data: 473089200
I0929 09:26:46.053794  1584 layer_factory.hpp:77] Creating layer Convolution14
I0929 09:26:46.053812  1584 net.cpp:84] Creating Layer Convolution14
I0929 09:26:46.053817  1584 net.cpp:406] Convolution14 <- Eltwise6_M2PELU13_0_split_0
I0929 09:26:46.053822  1584 net.cpp:380] Convolution14 -> Convolution14
I0929 09:26:46.053956  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:46.054945  1584 net.cpp:122] Setting up Convolution14
I0929 09:26:46.054955  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.054956  1584 net.cpp:137] Memory required for data: 479642800
I0929 09:26:46.054961  1584 layer_factory.hpp:77] Creating layer BatchNorm14
I0929 09:26:46.054967  1584 net.cpp:84] Creating Layer BatchNorm14
I0929 09:26:46.054970  1584 net.cpp:406] BatchNorm14 <- Convolution14
I0929 09:26:46.054973  1584 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0929 09:26:46.055132  1584 net.cpp:122] Setting up BatchNorm14
I0929 09:26:46.055136  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.055138  1584 net.cpp:137] Memory required for data: 486196400
I0929 09:26:46.055143  1584 layer_factory.hpp:77] Creating layer Scale14
I0929 09:26:46.055147  1584 net.cpp:84] Creating Layer Scale14
I0929 09:26:46.055150  1584 net.cpp:406] Scale14 <- Convolution14
I0929 09:26:46.055153  1584 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0929 09:26:46.055186  1584 layer_factory.hpp:77] Creating layer Scale14
I0929 09:26:46.055272  1584 net.cpp:122] Setting up Scale14
I0929 09:26:46.055277  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.055279  1584 net.cpp:137] Memory required for data: 492750000
I0929 09:26:46.055282  1584 layer_factory.hpp:77] Creating layer M2PELU14
I0929 09:26:46.055289  1584 net.cpp:84] Creating Layer M2PELU14
I0929 09:26:46.055290  1584 net.cpp:406] M2PELU14 <- Convolution14
I0929 09:26:46.055294  1584 net.cpp:367] M2PELU14 -> Convolution14 (in-place)
I0929 09:26:46.055397  1584 net.cpp:122] Setting up M2PELU14
I0929 09:26:46.055402  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.055403  1584 net.cpp:137] Memory required for data: 499303600
I0929 09:26:46.055407  1584 layer_factory.hpp:77] Creating layer Convolution15
I0929 09:26:46.055414  1584 net.cpp:84] Creating Layer Convolution15
I0929 09:26:46.055416  1584 net.cpp:406] Convolution15 <- Convolution14
I0929 09:26:46.055421  1584 net.cpp:380] Convolution15 -> Convolution15
I0929 09:26:46.055517  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:46.056401  1584 net.cpp:122] Setting up Convolution15
I0929 09:26:46.056411  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.056413  1584 net.cpp:137] Memory required for data: 505857200
I0929 09:26:46.056417  1584 layer_factory.hpp:77] Creating layer BatchNorm15
I0929 09:26:46.056422  1584 net.cpp:84] Creating Layer BatchNorm15
I0929 09:26:46.056426  1584 net.cpp:406] BatchNorm15 <- Convolution15
I0929 09:26:46.056437  1584 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0929 09:26:46.056599  1584 net.cpp:122] Setting up BatchNorm15
I0929 09:26:46.056604  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.056607  1584 net.cpp:137] Memory required for data: 512410800
I0929 09:26:46.056623  1584 layer_factory.hpp:77] Creating layer Scale15
I0929 09:26:46.056627  1584 net.cpp:84] Creating Layer Scale15
I0929 09:26:46.056630  1584 net.cpp:406] Scale15 <- Convolution15
I0929 09:26:46.056633  1584 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0929 09:26:46.056666  1584 layer_factory.hpp:77] Creating layer Scale15
I0929 09:26:46.056753  1584 net.cpp:122] Setting up Scale15
I0929 09:26:46.056758  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.056761  1584 net.cpp:137] Memory required for data: 518964400
I0929 09:26:46.056764  1584 layer_factory.hpp:77] Creating layer Eltwise7
I0929 09:26:46.056767  1584 net.cpp:84] Creating Layer Eltwise7
I0929 09:26:46.056771  1584 net.cpp:406] Eltwise7 <- Eltwise6_M2PELU13_0_split_1
I0929 09:26:46.056773  1584 net.cpp:406] Eltwise7 <- Convolution15
I0929 09:26:46.056777  1584 net.cpp:380] Eltwise7 -> Eltwise7
I0929 09:26:46.056794  1584 net.cpp:122] Setting up Eltwise7
I0929 09:26:46.056798  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.056800  1584 net.cpp:137] Memory required for data: 525518000
I0929 09:26:46.056802  1584 layer_factory.hpp:77] Creating layer M2PELU15
I0929 09:26:46.056807  1584 net.cpp:84] Creating Layer M2PELU15
I0929 09:26:46.056808  1584 net.cpp:406] M2PELU15 <- Eltwise7
I0929 09:26:46.056813  1584 net.cpp:367] M2PELU15 -> Eltwise7 (in-place)
I0929 09:26:46.056918  1584 net.cpp:122] Setting up M2PELU15
I0929 09:26:46.056922  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.056924  1584 net.cpp:137] Memory required for data: 532071600
I0929 09:26:46.056928  1584 layer_factory.hpp:77] Creating layer Eltwise7_M2PELU15_0_split
I0929 09:26:46.056932  1584 net.cpp:84] Creating Layer Eltwise7_M2PELU15_0_split
I0929 09:26:46.056934  1584 net.cpp:406] Eltwise7_M2PELU15_0_split <- Eltwise7
I0929 09:26:46.056937  1584 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_0
I0929 09:26:46.056941  1584 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_1
I0929 09:26:46.056969  1584 net.cpp:122] Setting up Eltwise7_M2PELU15_0_split
I0929 09:26:46.056973  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.056977  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.056978  1584 net.cpp:137] Memory required for data: 545178800
I0929 09:26:46.056980  1584 layer_factory.hpp:77] Creating layer Convolution16
I0929 09:26:46.056985  1584 net.cpp:84] Creating Layer Convolution16
I0929 09:26:46.056988  1584 net.cpp:406] Convolution16 <- Eltwise7_M2PELU15_0_split_0
I0929 09:26:46.056993  1584 net.cpp:380] Convolution16 -> Convolution16
I0929 09:26:46.057090  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:46.057638  1584 net.cpp:122] Setting up Convolution16
I0929 09:26:46.057646  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.057648  1584 net.cpp:137] Memory required for data: 551732400
I0929 09:26:46.057653  1584 layer_factory.hpp:77] Creating layer BatchNorm16
I0929 09:26:46.057657  1584 net.cpp:84] Creating Layer BatchNorm16
I0929 09:26:46.057659  1584 net.cpp:406] BatchNorm16 <- Convolution16
I0929 09:26:46.057664  1584 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0929 09:26:46.057821  1584 net.cpp:122] Setting up BatchNorm16
I0929 09:26:46.057826  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.057827  1584 net.cpp:137] Memory required for data: 558286000
I0929 09:26:46.057832  1584 layer_factory.hpp:77] Creating layer Scale16
I0929 09:26:46.057837  1584 net.cpp:84] Creating Layer Scale16
I0929 09:26:46.057838  1584 net.cpp:406] Scale16 <- Convolution16
I0929 09:26:46.057842  1584 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0929 09:26:46.057873  1584 layer_factory.hpp:77] Creating layer Scale16
I0929 09:26:46.057971  1584 net.cpp:122] Setting up Scale16
I0929 09:26:46.057976  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.057977  1584 net.cpp:137] Memory required for data: 564839600
I0929 09:26:46.057981  1584 layer_factory.hpp:77] Creating layer M2PELU16
I0929 09:26:46.057986  1584 net.cpp:84] Creating Layer M2PELU16
I0929 09:26:46.057988  1584 net.cpp:406] M2PELU16 <- Convolution16
I0929 09:26:46.057992  1584 net.cpp:367] M2PELU16 -> Convolution16 (in-place)
I0929 09:26:46.058097  1584 net.cpp:122] Setting up M2PELU16
I0929 09:26:46.058101  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.058104  1584 net.cpp:137] Memory required for data: 571393200
I0929 09:26:46.058107  1584 layer_factory.hpp:77] Creating layer Convolution17
I0929 09:26:46.058115  1584 net.cpp:84] Creating Layer Convolution17
I0929 09:26:46.058116  1584 net.cpp:406] Convolution17 <- Convolution16
I0929 09:26:46.058120  1584 net.cpp:380] Convolution17 -> Convolution17
I0929 09:26:46.058218  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:46.059123  1584 net.cpp:122] Setting up Convolution17
I0929 09:26:46.059131  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.059134  1584 net.cpp:137] Memory required for data: 577946800
I0929 09:26:46.059139  1584 layer_factory.hpp:77] Creating layer BatchNorm17
I0929 09:26:46.059144  1584 net.cpp:84] Creating Layer BatchNorm17
I0929 09:26:46.059146  1584 net.cpp:406] BatchNorm17 <- Convolution17
I0929 09:26:46.059150  1584 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0929 09:26:46.059310  1584 net.cpp:122] Setting up BatchNorm17
I0929 09:26:46.059314  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.059316  1584 net.cpp:137] Memory required for data: 584500400
I0929 09:26:46.059321  1584 layer_factory.hpp:77] Creating layer Scale17
I0929 09:26:46.059325  1584 net.cpp:84] Creating Layer Scale17
I0929 09:26:46.059329  1584 net.cpp:406] Scale17 <- Convolution17
I0929 09:26:46.059331  1584 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0929 09:26:46.059371  1584 layer_factory.hpp:77] Creating layer Scale17
I0929 09:26:46.059463  1584 net.cpp:122] Setting up Scale17
I0929 09:26:46.059468  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.059469  1584 net.cpp:137] Memory required for data: 591054000
I0929 09:26:46.059473  1584 layer_factory.hpp:77] Creating layer Eltwise8
I0929 09:26:46.059476  1584 net.cpp:84] Creating Layer Eltwise8
I0929 09:26:46.059479  1584 net.cpp:406] Eltwise8 <- Eltwise7_M2PELU15_0_split_1
I0929 09:26:46.059482  1584 net.cpp:406] Eltwise8 <- Convolution17
I0929 09:26:46.059487  1584 net.cpp:380] Eltwise8 -> Eltwise8
I0929 09:26:46.059505  1584 net.cpp:122] Setting up Eltwise8
I0929 09:26:46.059509  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.059511  1584 net.cpp:137] Memory required for data: 597607600
I0929 09:26:46.059514  1584 layer_factory.hpp:77] Creating layer M2PELU17
I0929 09:26:46.059518  1584 net.cpp:84] Creating Layer M2PELU17
I0929 09:26:46.059521  1584 net.cpp:406] M2PELU17 <- Eltwise8
I0929 09:26:46.059525  1584 net.cpp:367] M2PELU17 -> Eltwise8 (in-place)
I0929 09:26:46.059633  1584 net.cpp:122] Setting up M2PELU17
I0929 09:26:46.059638  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.059639  1584 net.cpp:137] Memory required for data: 604161200
I0929 09:26:46.059643  1584 layer_factory.hpp:77] Creating layer Eltwise8_M2PELU17_0_split
I0929 09:26:46.059648  1584 net.cpp:84] Creating Layer Eltwise8_M2PELU17_0_split
I0929 09:26:46.080708  1584 net.cpp:406] Eltwise8_M2PELU17_0_split <- Eltwise8
I0929 09:26:46.080721  1584 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_0
I0929 09:26:46.080729  1584 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_1
I0929 09:26:46.080770  1584 net.cpp:122] Setting up Eltwise8_M2PELU17_0_split
I0929 09:26:46.080776  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.080786  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.080790  1584 net.cpp:137] Memory required for data: 617268400
I0929 09:26:46.080791  1584 layer_factory.hpp:77] Creating layer Convolution18
I0929 09:26:46.080801  1584 net.cpp:84] Creating Layer Convolution18
I0929 09:26:46.080803  1584 net.cpp:406] Convolution18 <- Eltwise8_M2PELU17_0_split_0
I0929 09:26:46.080807  1584 net.cpp:380] Convolution18 -> Convolution18
I0929 09:26:46.080917  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:46.081965  1584 net.cpp:122] Setting up Convolution18
I0929 09:26:46.081975  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.081979  1584 net.cpp:137] Memory required for data: 623822000
I0929 09:26:46.081984  1584 layer_factory.hpp:77] Creating layer BatchNorm18
I0929 09:26:46.081989  1584 net.cpp:84] Creating Layer BatchNorm18
I0929 09:26:46.081991  1584 net.cpp:406] BatchNorm18 <- Convolution18
I0929 09:26:46.081995  1584 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0929 09:26:46.082165  1584 net.cpp:122] Setting up BatchNorm18
I0929 09:26:46.082173  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.082177  1584 net.cpp:137] Memory required for data: 630375600
I0929 09:26:46.082185  1584 layer_factory.hpp:77] Creating layer Scale18
I0929 09:26:46.082192  1584 net.cpp:84] Creating Layer Scale18
I0929 09:26:46.082196  1584 net.cpp:406] Scale18 <- Convolution18
I0929 09:26:46.082201  1584 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0929 09:26:46.082249  1584 layer_factory.hpp:77] Creating layer Scale18
I0929 09:26:46.082378  1584 net.cpp:122] Setting up Scale18
I0929 09:26:46.082386  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.082388  1584 net.cpp:137] Memory required for data: 636929200
I0929 09:26:46.082392  1584 layer_factory.hpp:77] Creating layer M2PELU18
I0929 09:26:46.082398  1584 net.cpp:84] Creating Layer M2PELU18
I0929 09:26:46.082401  1584 net.cpp:406] M2PELU18 <- Convolution18
I0929 09:26:46.082406  1584 net.cpp:367] M2PELU18 -> Convolution18 (in-place)
I0929 09:26:46.082517  1584 net.cpp:122] Setting up M2PELU18
I0929 09:26:46.082530  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.082533  1584 net.cpp:137] Memory required for data: 643482800
I0929 09:26:46.082537  1584 layer_factory.hpp:77] Creating layer Convolution19
I0929 09:26:46.082545  1584 net.cpp:84] Creating Layer Convolution19
I0929 09:26:46.082547  1584 net.cpp:406] Convolution19 <- Convolution18
I0929 09:26:46.082551  1584 net.cpp:380] Convolution19 -> Convolution19
I0929 09:26:46.082651  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:46.083602  1584 net.cpp:122] Setting up Convolution19
I0929 09:26:46.083611  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.083614  1584 net.cpp:137] Memory required for data: 650036400
I0929 09:26:46.083619  1584 layer_factory.hpp:77] Creating layer BatchNorm19
I0929 09:26:46.083624  1584 net.cpp:84] Creating Layer BatchNorm19
I0929 09:26:46.083627  1584 net.cpp:406] BatchNorm19 <- Convolution19
I0929 09:26:46.083631  1584 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0929 09:26:46.083827  1584 net.cpp:122] Setting up BatchNorm19
I0929 09:26:46.083833  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.083835  1584 net.cpp:137] Memory required for data: 656590000
I0929 09:26:46.083842  1584 layer_factory.hpp:77] Creating layer Scale19
I0929 09:26:46.083845  1584 net.cpp:84] Creating Layer Scale19
I0929 09:26:46.083848  1584 net.cpp:406] Scale19 <- Convolution19
I0929 09:26:46.083853  1584 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0929 09:26:46.083886  1584 layer_factory.hpp:77] Creating layer Scale19
I0929 09:26:46.083992  1584 net.cpp:122] Setting up Scale19
I0929 09:26:46.083997  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.083999  1584 net.cpp:137] Memory required for data: 663143600
I0929 09:26:46.084004  1584 layer_factory.hpp:77] Creating layer Eltwise9
I0929 09:26:46.084009  1584 net.cpp:84] Creating Layer Eltwise9
I0929 09:26:46.084022  1584 net.cpp:406] Eltwise9 <- Eltwise8_M2PELU17_0_split_1
I0929 09:26:46.084025  1584 net.cpp:406] Eltwise9 <- Convolution19
I0929 09:26:46.084028  1584 net.cpp:380] Eltwise9 -> Eltwise9
I0929 09:26:46.084050  1584 net.cpp:122] Setting up Eltwise9
I0929 09:26:46.084054  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.084056  1584 net.cpp:137] Memory required for data: 669697200
I0929 09:26:46.084059  1584 layer_factory.hpp:77] Creating layer M2PELU19
I0929 09:26:46.084064  1584 net.cpp:84] Creating Layer M2PELU19
I0929 09:26:46.084066  1584 net.cpp:406] M2PELU19 <- Eltwise9
I0929 09:26:46.084069  1584 net.cpp:367] M2PELU19 -> Eltwise9 (in-place)
I0929 09:26:46.084180  1584 net.cpp:122] Setting up M2PELU19
I0929 09:26:46.084185  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.084187  1584 net.cpp:137] Memory required for data: 676250800
I0929 09:26:46.084192  1584 layer_factory.hpp:77] Creating layer Eltwise9_M2PELU19_0_split
I0929 09:26:46.084195  1584 net.cpp:84] Creating Layer Eltwise9_M2PELU19_0_split
I0929 09:26:46.084197  1584 net.cpp:406] Eltwise9_M2PELU19_0_split <- Eltwise9
I0929 09:26:46.084201  1584 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_0
I0929 09:26:46.084206  1584 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_1
I0929 09:26:46.084234  1584 net.cpp:122] Setting up Eltwise9_M2PELU19_0_split
I0929 09:26:46.084239  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.084241  1584 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 09:26:46.084244  1584 net.cpp:137] Memory required for data: 689358000
I0929 09:26:46.084245  1584 layer_factory.hpp:77] Creating layer Convolution20
I0929 09:26:46.084251  1584 net.cpp:84] Creating Layer Convolution20
I0929 09:26:46.084254  1584 net.cpp:406] Convolution20 <- Eltwise9_M2PELU19_0_split_0
I0929 09:26:46.084259  1584 net.cpp:380] Convolution20 -> Convolution20
I0929 09:26:46.084357  1584 filler.hpp:251] The std of weights in this layer is: 0.342997
I0929 09:26:46.085245  1584 net.cpp:122] Setting up Convolution20
I0929 09:26:46.085253  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.085256  1584 net.cpp:137] Memory required for data: 692634800
I0929 09:26:46.085261  1584 layer_factory.hpp:77] Creating layer BatchNorm20
I0929 09:26:46.085266  1584 net.cpp:84] Creating Layer BatchNorm20
I0929 09:26:46.085269  1584 net.cpp:406] BatchNorm20 <- Convolution20
I0929 09:26:46.085273  1584 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0929 09:26:46.085433  1584 net.cpp:122] Setting up BatchNorm20
I0929 09:26:46.085438  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.085440  1584 net.cpp:137] Memory required for data: 695911600
I0929 09:26:46.085445  1584 layer_factory.hpp:77] Creating layer Scale20
I0929 09:26:46.085449  1584 net.cpp:84] Creating Layer Scale20
I0929 09:26:46.085453  1584 net.cpp:406] Scale20 <- Convolution20
I0929 09:26:46.085455  1584 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0929 09:26:46.085487  1584 layer_factory.hpp:77] Creating layer Scale20
I0929 09:26:46.085578  1584 net.cpp:122] Setting up Scale20
I0929 09:26:46.085583  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.085585  1584 net.cpp:137] Memory required for data: 699188400
I0929 09:26:46.085589  1584 layer_factory.hpp:77] Creating layer Convolution21
I0929 09:26:46.085597  1584 net.cpp:84] Creating Layer Convolution21
I0929 09:26:46.085598  1584 net.cpp:406] Convolution21 <- Eltwise9_M2PELU19_0_split_1
I0929 09:26:46.085604  1584 net.cpp:380] Convolution21 -> Convolution21
I0929 09:26:46.085700  1584 filler.hpp:251] The std of weights in this layer is: 0.114332
I0929 09:26:46.086676  1584 net.cpp:122] Setting up Convolution21
I0929 09:26:46.086685  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.086688  1584 net.cpp:137] Memory required for data: 702465200
I0929 09:26:46.086694  1584 layer_factory.hpp:77] Creating layer BatchNorm21
I0929 09:26:46.086699  1584 net.cpp:84] Creating Layer BatchNorm21
I0929 09:26:46.086707  1584 net.cpp:406] BatchNorm21 <- Convolution21
I0929 09:26:46.086712  1584 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0929 09:26:46.086874  1584 net.cpp:122] Setting up BatchNorm21
I0929 09:26:46.086879  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.086880  1584 net.cpp:137] Memory required for data: 705742000
I0929 09:26:46.086885  1584 layer_factory.hpp:77] Creating layer Scale21
I0929 09:26:46.086890  1584 net.cpp:84] Creating Layer Scale21
I0929 09:26:46.086894  1584 net.cpp:406] Scale21 <- Convolution21
I0929 09:26:46.086896  1584 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0929 09:26:46.086928  1584 layer_factory.hpp:77] Creating layer Scale21
I0929 09:26:46.087018  1584 net.cpp:122] Setting up Scale21
I0929 09:26:46.087023  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.087024  1584 net.cpp:137] Memory required for data: 709018800
I0929 09:26:46.087028  1584 layer_factory.hpp:77] Creating layer M2PELU20
I0929 09:26:46.087034  1584 net.cpp:84] Creating Layer M2PELU20
I0929 09:26:46.087036  1584 net.cpp:406] M2PELU20 <- Convolution21
I0929 09:26:46.087040  1584 net.cpp:367] M2PELU20 -> Convolution21 (in-place)
I0929 09:26:46.087141  1584 net.cpp:122] Setting up M2PELU20
I0929 09:26:46.087144  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.087146  1584 net.cpp:137] Memory required for data: 712295600
I0929 09:26:46.087151  1584 layer_factory.hpp:77] Creating layer Convolution22
I0929 09:26:46.087157  1584 net.cpp:84] Creating Layer Convolution22
I0929 09:26:46.087160  1584 net.cpp:406] Convolution22 <- Convolution21
I0929 09:26:46.087163  1584 net.cpp:380] Convolution22 -> Convolution22
I0929 09:26:46.087263  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:46.088327  1584 net.cpp:122] Setting up Convolution22
I0929 09:26:46.088336  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.088340  1584 net.cpp:137] Memory required for data: 715572400
I0929 09:26:46.088343  1584 layer_factory.hpp:77] Creating layer BatchNorm22
I0929 09:26:46.088349  1584 net.cpp:84] Creating Layer BatchNorm22
I0929 09:26:46.088352  1584 net.cpp:406] BatchNorm22 <- Convolution22
I0929 09:26:46.088356  1584 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0929 09:26:46.088515  1584 net.cpp:122] Setting up BatchNorm22
I0929 09:26:46.088520  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.088522  1584 net.cpp:137] Memory required for data: 718849200
I0929 09:26:46.088526  1584 layer_factory.hpp:77] Creating layer Scale22
I0929 09:26:46.088531  1584 net.cpp:84] Creating Layer Scale22
I0929 09:26:46.088534  1584 net.cpp:406] Scale22 <- Convolution22
I0929 09:26:46.088537  1584 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0929 09:26:46.088569  1584 layer_factory.hpp:77] Creating layer Scale22
I0929 09:26:46.088665  1584 net.cpp:122] Setting up Scale22
I0929 09:26:46.088668  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.088671  1584 net.cpp:137] Memory required for data: 722126000
I0929 09:26:46.088675  1584 layer_factory.hpp:77] Creating layer Eltwise10
I0929 09:26:46.088680  1584 net.cpp:84] Creating Layer Eltwise10
I0929 09:26:46.088682  1584 net.cpp:406] Eltwise10 <- Convolution20
I0929 09:26:46.088685  1584 net.cpp:406] Eltwise10 <- Convolution22
I0929 09:26:46.088688  1584 net.cpp:380] Eltwise10 -> Eltwise10
I0929 09:26:46.088704  1584 net.cpp:122] Setting up Eltwise10
I0929 09:26:46.088708  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.088711  1584 net.cpp:137] Memory required for data: 725402800
I0929 09:26:46.088712  1584 layer_factory.hpp:77] Creating layer M2PELU21
I0929 09:26:46.088717  1584 net.cpp:84] Creating Layer M2PELU21
I0929 09:26:46.088719  1584 net.cpp:406] M2PELU21 <- Eltwise10
I0929 09:26:46.088723  1584 net.cpp:367] M2PELU21 -> Eltwise10 (in-place)
I0929 09:26:46.088827  1584 net.cpp:122] Setting up M2PELU21
I0929 09:26:46.088832  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.088840  1584 net.cpp:137] Memory required for data: 728679600
I0929 09:26:46.088845  1584 layer_factory.hpp:77] Creating layer Eltwise10_M2PELU21_0_split
I0929 09:26:46.088848  1584 net.cpp:84] Creating Layer Eltwise10_M2PELU21_0_split
I0929 09:26:46.088850  1584 net.cpp:406] Eltwise10_M2PELU21_0_split <- Eltwise10
I0929 09:26:46.088855  1584 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_0
I0929 09:26:46.088860  1584 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_1
I0929 09:26:46.088889  1584 net.cpp:122] Setting up Eltwise10_M2PELU21_0_split
I0929 09:26:46.088893  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.088896  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.088898  1584 net.cpp:137] Memory required for data: 735233200
I0929 09:26:46.088901  1584 layer_factory.hpp:77] Creating layer Convolution23
I0929 09:26:46.088907  1584 net.cpp:84] Creating Layer Convolution23
I0929 09:26:46.088909  1584 net.cpp:406] Convolution23 <- Eltwise10_M2PELU21_0_split_0
I0929 09:26:46.088913  1584 net.cpp:380] Convolution23 -> Convolution23
I0929 09:26:46.089012  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:46.090075  1584 net.cpp:122] Setting up Convolution23
I0929 09:26:46.090085  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.090086  1584 net.cpp:137] Memory required for data: 738510000
I0929 09:26:46.090091  1584 layer_factory.hpp:77] Creating layer BatchNorm23
I0929 09:26:46.090097  1584 net.cpp:84] Creating Layer BatchNorm23
I0929 09:26:46.090100  1584 net.cpp:406] BatchNorm23 <- Convolution23
I0929 09:26:46.090103  1584 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0929 09:26:46.090265  1584 net.cpp:122] Setting up BatchNorm23
I0929 09:26:46.090270  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.090272  1584 net.cpp:137] Memory required for data: 741786800
I0929 09:26:46.090277  1584 layer_factory.hpp:77] Creating layer Scale23
I0929 09:26:46.090282  1584 net.cpp:84] Creating Layer Scale23
I0929 09:26:46.090284  1584 net.cpp:406] Scale23 <- Convolution23
I0929 09:26:46.090287  1584 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0929 09:26:46.090320  1584 layer_factory.hpp:77] Creating layer Scale23
I0929 09:26:46.090415  1584 net.cpp:122] Setting up Scale23
I0929 09:26:46.090420  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.090421  1584 net.cpp:137] Memory required for data: 745063600
I0929 09:26:46.090425  1584 layer_factory.hpp:77] Creating layer M2PELU22
I0929 09:26:46.090430  1584 net.cpp:84] Creating Layer M2PELU22
I0929 09:26:46.090433  1584 net.cpp:406] M2PELU22 <- Convolution23
I0929 09:26:46.090437  1584 net.cpp:367] M2PELU22 -> Convolution23 (in-place)
I0929 09:26:46.090544  1584 net.cpp:122] Setting up M2PELU22
I0929 09:26:46.090549  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.090551  1584 net.cpp:137] Memory required for data: 748340400
I0929 09:26:46.090555  1584 layer_factory.hpp:77] Creating layer Convolution24
I0929 09:26:46.090562  1584 net.cpp:84] Creating Layer Convolution24
I0929 09:26:46.090565  1584 net.cpp:406] Convolution24 <- Convolution23
I0929 09:26:46.090569  1584 net.cpp:380] Convolution24 -> Convolution24
I0929 09:26:46.090670  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:46.091739  1584 net.cpp:122] Setting up Convolution24
I0929 09:26:46.091748  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.111595  1584 net.cpp:137] Memory required for data: 751617200
I0929 09:26:46.111606  1584 layer_factory.hpp:77] Creating layer BatchNorm24
I0929 09:26:46.111613  1584 net.cpp:84] Creating Layer BatchNorm24
I0929 09:26:46.111618  1584 net.cpp:406] BatchNorm24 <- Convolution24
I0929 09:26:46.111623  1584 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0929 09:26:46.112336  1584 net.cpp:122] Setting up BatchNorm24
I0929 09:26:46.112346  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.112349  1584 net.cpp:137] Memory required for data: 754894000
I0929 09:26:46.112365  1584 layer_factory.hpp:77] Creating layer Scale24
I0929 09:26:46.112370  1584 net.cpp:84] Creating Layer Scale24
I0929 09:26:46.112373  1584 net.cpp:406] Scale24 <- Convolution24
I0929 09:26:46.112376  1584 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0929 09:26:46.112416  1584 layer_factory.hpp:77] Creating layer Scale24
I0929 09:26:46.112490  1584 net.cpp:122] Setting up Scale24
I0929 09:26:46.112494  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.112496  1584 net.cpp:137] Memory required for data: 758170800
I0929 09:26:46.112500  1584 layer_factory.hpp:77] Creating layer Eltwise11
I0929 09:26:46.112504  1584 net.cpp:84] Creating Layer Eltwise11
I0929 09:26:46.112507  1584 net.cpp:406] Eltwise11 <- Eltwise10_M2PELU21_0_split_1
I0929 09:26:46.112510  1584 net.cpp:406] Eltwise11 <- Convolution24
I0929 09:26:46.112514  1584 net.cpp:380] Eltwise11 -> Eltwise11
I0929 09:26:46.112526  1584 net.cpp:122] Setting up Eltwise11
I0929 09:26:46.112529  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.112531  1584 net.cpp:137] Memory required for data: 761447600
I0929 09:26:46.112534  1584 layer_factory.hpp:77] Creating layer M2PELU23
I0929 09:26:46.112540  1584 net.cpp:84] Creating Layer M2PELU23
I0929 09:26:46.112541  1584 net.cpp:406] M2PELU23 <- Eltwise11
I0929 09:26:46.112545  1584 net.cpp:367] M2PELU23 -> Eltwise11 (in-place)
I0929 09:26:46.112629  1584 net.cpp:122] Setting up M2PELU23
I0929 09:26:46.112633  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.112635  1584 net.cpp:137] Memory required for data: 764724400
I0929 09:26:46.112639  1584 layer_factory.hpp:77] Creating layer Eltwise11_M2PELU23_0_split
I0929 09:26:46.112643  1584 net.cpp:84] Creating Layer Eltwise11_M2PELU23_0_split
I0929 09:26:46.112645  1584 net.cpp:406] Eltwise11_M2PELU23_0_split <- Eltwise11
I0929 09:26:46.112649  1584 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_0
I0929 09:26:46.112654  1584 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_1
I0929 09:26:46.112676  1584 net.cpp:122] Setting up Eltwise11_M2PELU23_0_split
I0929 09:26:46.112680  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.112684  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.112685  1584 net.cpp:137] Memory required for data: 771278000
I0929 09:26:46.112687  1584 layer_factory.hpp:77] Creating layer Convolution25
I0929 09:26:46.112694  1584 net.cpp:84] Creating Layer Convolution25
I0929 09:26:46.112696  1584 net.cpp:406] Convolution25 <- Eltwise11_M2PELU23_0_split_0
I0929 09:26:46.112701  1584 net.cpp:380] Convolution25 -> Convolution25
I0929 09:26:46.112781  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:46.114065  1584 net.cpp:122] Setting up Convolution25
I0929 09:26:46.114074  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.114078  1584 net.cpp:137] Memory required for data: 774554800
I0929 09:26:46.114082  1584 layer_factory.hpp:77] Creating layer BatchNorm25
I0929 09:26:46.114086  1584 net.cpp:84] Creating Layer BatchNorm25
I0929 09:26:46.114089  1584 net.cpp:406] BatchNorm25 <- Convolution25
I0929 09:26:46.114095  1584 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0929 09:26:46.114218  1584 net.cpp:122] Setting up BatchNorm25
I0929 09:26:46.114223  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.114224  1584 net.cpp:137] Memory required for data: 777831600
I0929 09:26:46.114229  1584 layer_factory.hpp:77] Creating layer Scale25
I0929 09:26:46.114233  1584 net.cpp:84] Creating Layer Scale25
I0929 09:26:46.114235  1584 net.cpp:406] Scale25 <- Convolution25
I0929 09:26:46.114239  1584 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0929 09:26:46.114264  1584 layer_factory.hpp:77] Creating layer Scale25
I0929 09:26:46.114333  1584 net.cpp:122] Setting up Scale25
I0929 09:26:46.114337  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.114339  1584 net.cpp:137] Memory required for data: 781108400
I0929 09:26:46.114349  1584 layer_factory.hpp:77] Creating layer M2PELU24
I0929 09:26:46.114356  1584 net.cpp:84] Creating Layer M2PELU24
I0929 09:26:46.114358  1584 net.cpp:406] M2PELU24 <- Convolution25
I0929 09:26:46.114362  1584 net.cpp:367] M2PELU24 -> Convolution25 (in-place)
I0929 09:26:46.114442  1584 net.cpp:122] Setting up M2PELU24
I0929 09:26:46.114447  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.114449  1584 net.cpp:137] Memory required for data: 784385200
I0929 09:26:46.114454  1584 layer_factory.hpp:77] Creating layer Convolution26
I0929 09:26:46.114459  1584 net.cpp:84] Creating Layer Convolution26
I0929 09:26:46.114461  1584 net.cpp:406] Convolution26 <- Convolution25
I0929 09:26:46.114465  1584 net.cpp:380] Convolution26 -> Convolution26
I0929 09:26:46.114605  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:46.115458  1584 net.cpp:122] Setting up Convolution26
I0929 09:26:46.115466  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.115469  1584 net.cpp:137] Memory required for data: 787662000
I0929 09:26:46.115473  1584 layer_factory.hpp:77] Creating layer BatchNorm26
I0929 09:26:46.115478  1584 net.cpp:84] Creating Layer BatchNorm26
I0929 09:26:46.115481  1584 net.cpp:406] BatchNorm26 <- Convolution26
I0929 09:26:46.115484  1584 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0929 09:26:46.115607  1584 net.cpp:122] Setting up BatchNorm26
I0929 09:26:46.115612  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.115613  1584 net.cpp:137] Memory required for data: 790938800
I0929 09:26:46.115618  1584 layer_factory.hpp:77] Creating layer Scale26
I0929 09:26:46.115623  1584 net.cpp:84] Creating Layer Scale26
I0929 09:26:46.115625  1584 net.cpp:406] Scale26 <- Convolution26
I0929 09:26:46.115628  1584 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0929 09:26:46.115653  1584 layer_factory.hpp:77] Creating layer Scale26
I0929 09:26:46.115725  1584 net.cpp:122] Setting up Scale26
I0929 09:26:46.115728  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.115731  1584 net.cpp:137] Memory required for data: 794215600
I0929 09:26:46.115733  1584 layer_factory.hpp:77] Creating layer Eltwise12
I0929 09:26:46.115737  1584 net.cpp:84] Creating Layer Eltwise12
I0929 09:26:46.115741  1584 net.cpp:406] Eltwise12 <- Eltwise11_M2PELU23_0_split_1
I0929 09:26:46.115743  1584 net.cpp:406] Eltwise12 <- Convolution26
I0929 09:26:46.115746  1584 net.cpp:380] Eltwise12 -> Eltwise12
I0929 09:26:46.115757  1584 net.cpp:122] Setting up Eltwise12
I0929 09:26:46.115761  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.115762  1584 net.cpp:137] Memory required for data: 797492400
I0929 09:26:46.115764  1584 layer_factory.hpp:77] Creating layer M2PELU25
I0929 09:26:46.115782  1584 net.cpp:84] Creating Layer M2PELU25
I0929 09:26:46.115784  1584 net.cpp:406] M2PELU25 <- Eltwise12
I0929 09:26:46.115789  1584 net.cpp:367] M2PELU25 -> Eltwise12 (in-place)
I0929 09:26:46.115875  1584 net.cpp:122] Setting up M2PELU25
I0929 09:26:46.115878  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.115880  1584 net.cpp:137] Memory required for data: 800769200
I0929 09:26:46.115885  1584 layer_factory.hpp:77] Creating layer Eltwise12_M2PELU25_0_split
I0929 09:26:46.115887  1584 net.cpp:84] Creating Layer Eltwise12_M2PELU25_0_split
I0929 09:26:46.115890  1584 net.cpp:406] Eltwise12_M2PELU25_0_split <- Eltwise12
I0929 09:26:46.115895  1584 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_0
I0929 09:26:46.115900  1584 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_1
I0929 09:26:46.115921  1584 net.cpp:122] Setting up Eltwise12_M2PELU25_0_split
I0929 09:26:46.115923  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.115926  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.115928  1584 net.cpp:137] Memory required for data: 807322800
I0929 09:26:46.115931  1584 layer_factory.hpp:77] Creating layer Convolution27
I0929 09:26:46.115936  1584 net.cpp:84] Creating Layer Convolution27
I0929 09:26:46.115945  1584 net.cpp:406] Convolution27 <- Eltwise12_M2PELU25_0_split_0
I0929 09:26:46.115950  1584 net.cpp:380] Convolution27 -> Convolution27
I0929 09:26:46.116027  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:46.117343  1584 net.cpp:122] Setting up Convolution27
I0929 09:26:46.117352  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.117354  1584 net.cpp:137] Memory required for data: 810599600
I0929 09:26:46.117358  1584 layer_factory.hpp:77] Creating layer BatchNorm27
I0929 09:26:46.117363  1584 net.cpp:84] Creating Layer BatchNorm27
I0929 09:26:46.117367  1584 net.cpp:406] BatchNorm27 <- Convolution27
I0929 09:26:46.117370  1584 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0929 09:26:46.117491  1584 net.cpp:122] Setting up BatchNorm27
I0929 09:26:46.117496  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.117497  1584 net.cpp:137] Memory required for data: 813876400
I0929 09:26:46.117502  1584 layer_factory.hpp:77] Creating layer Scale27
I0929 09:26:46.117506  1584 net.cpp:84] Creating Layer Scale27
I0929 09:26:46.117508  1584 net.cpp:406] Scale27 <- Convolution27
I0929 09:26:46.117511  1584 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0929 09:26:46.117537  1584 layer_factory.hpp:77] Creating layer Scale27
I0929 09:26:46.117604  1584 net.cpp:122] Setting up Scale27
I0929 09:26:46.117609  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.117610  1584 net.cpp:137] Memory required for data: 817153200
I0929 09:26:46.117614  1584 layer_factory.hpp:77] Creating layer M2PELU26
I0929 09:26:46.117619  1584 net.cpp:84] Creating Layer M2PELU26
I0929 09:26:46.117621  1584 net.cpp:406] M2PELU26 <- Convolution27
I0929 09:26:46.117625  1584 net.cpp:367] M2PELU26 -> Convolution27 (in-place)
I0929 09:26:46.117702  1584 net.cpp:122] Setting up M2PELU26
I0929 09:26:46.117707  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.117709  1584 net.cpp:137] Memory required for data: 820430000
I0929 09:26:46.117713  1584 layer_factory.hpp:77] Creating layer Convolution28
I0929 09:26:46.117718  1584 net.cpp:84] Creating Layer Convolution28
I0929 09:26:46.117722  1584 net.cpp:406] Convolution28 <- Convolution27
I0929 09:26:46.117725  1584 net.cpp:380] Convolution28 -> Convolution28
I0929 09:26:46.117802  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:46.119115  1584 net.cpp:122] Setting up Convolution28
I0929 09:26:46.119124  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.119127  1584 net.cpp:137] Memory required for data: 823706800
I0929 09:26:46.119132  1584 layer_factory.hpp:77] Creating layer BatchNorm28
I0929 09:26:46.119138  1584 net.cpp:84] Creating Layer BatchNorm28
I0929 09:26:46.119140  1584 net.cpp:406] BatchNorm28 <- Convolution28
I0929 09:26:46.119143  1584 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0929 09:26:46.119268  1584 net.cpp:122] Setting up BatchNorm28
I0929 09:26:46.119273  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.119276  1584 net.cpp:137] Memory required for data: 826983600
I0929 09:26:46.119280  1584 layer_factory.hpp:77] Creating layer Scale28
I0929 09:26:46.119285  1584 net.cpp:84] Creating Layer Scale28
I0929 09:26:46.119287  1584 net.cpp:406] Scale28 <- Convolution28
I0929 09:26:46.119290  1584 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0929 09:26:46.119316  1584 layer_factory.hpp:77] Creating layer Scale28
I0929 09:26:46.119386  1584 net.cpp:122] Setting up Scale28
I0929 09:26:46.119390  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.119391  1584 net.cpp:137] Memory required for data: 830260400
I0929 09:26:46.119395  1584 layer_factory.hpp:77] Creating layer Eltwise13
I0929 09:26:46.119400  1584 net.cpp:84] Creating Layer Eltwise13
I0929 09:26:46.119401  1584 net.cpp:406] Eltwise13 <- Eltwise12_M2PELU25_0_split_1
I0929 09:26:46.119405  1584 net.cpp:406] Eltwise13 <- Convolution28
I0929 09:26:46.119408  1584 net.cpp:380] Eltwise13 -> Eltwise13
I0929 09:26:46.119426  1584 net.cpp:122] Setting up Eltwise13
I0929 09:26:46.119431  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.119433  1584 net.cpp:137] Memory required for data: 833537200
I0929 09:26:46.119436  1584 layer_factory.hpp:77] Creating layer M2PELU27
I0929 09:26:46.119441  1584 net.cpp:84] Creating Layer M2PELU27
I0929 09:26:46.119442  1584 net.cpp:406] M2PELU27 <- Eltwise13
I0929 09:26:46.119446  1584 net.cpp:367] M2PELU27 -> Eltwise13 (in-place)
I0929 09:26:46.119529  1584 net.cpp:122] Setting up M2PELU27
I0929 09:26:46.119532  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.119534  1584 net.cpp:137] Memory required for data: 836814000
I0929 09:26:46.119539  1584 layer_factory.hpp:77] Creating layer Eltwise13_M2PELU27_0_split
I0929 09:26:46.119541  1584 net.cpp:84] Creating Layer Eltwise13_M2PELU27_0_split
I0929 09:26:46.119544  1584 net.cpp:406] Eltwise13_M2PELU27_0_split <- Eltwise13
I0929 09:26:46.119549  1584 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_0
I0929 09:26:46.119552  1584 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_1
I0929 09:26:46.119575  1584 net.cpp:122] Setting up Eltwise13_M2PELU27_0_split
I0929 09:26:46.119578  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.119581  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.119582  1584 net.cpp:137] Memory required for data: 843367600
I0929 09:26:46.119585  1584 layer_factory.hpp:77] Creating layer Convolution29
I0929 09:26:46.119591  1584 net.cpp:84] Creating Layer Convolution29
I0929 09:26:46.119593  1584 net.cpp:406] Convolution29 <- Eltwise13_M2PELU27_0_split_0
I0929 09:26:46.119597  1584 net.cpp:380] Convolution29 -> Convolution29
I0929 09:26:46.119673  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:46.120672  1584 net.cpp:122] Setting up Convolution29
I0929 09:26:46.120681  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.120683  1584 net.cpp:137] Memory required for data: 846644400
I0929 09:26:46.120687  1584 layer_factory.hpp:77] Creating layer BatchNorm29
I0929 09:26:46.120692  1584 net.cpp:84] Creating Layer BatchNorm29
I0929 09:26:46.120695  1584 net.cpp:406] BatchNorm29 <- Convolution29
I0929 09:26:46.120699  1584 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0929 09:26:46.120821  1584 net.cpp:122] Setting up BatchNorm29
I0929 09:26:46.120826  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.120828  1584 net.cpp:137] Memory required for data: 849921200
I0929 09:26:46.120832  1584 layer_factory.hpp:77] Creating layer Scale29
I0929 09:26:46.120837  1584 net.cpp:84] Creating Layer Scale29
I0929 09:26:46.120841  1584 net.cpp:406] Scale29 <- Convolution29
I0929 09:26:46.120843  1584 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0929 09:26:46.120869  1584 layer_factory.hpp:77] Creating layer Scale29
I0929 09:26:46.120939  1584 net.cpp:122] Setting up Scale29
I0929 09:26:46.120942  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.120944  1584 net.cpp:137] Memory required for data: 853198000
I0929 09:26:46.120965  1584 layer_factory.hpp:77] Creating layer M2PELU28
I0929 09:26:46.120970  1584 net.cpp:84] Creating Layer M2PELU28
I0929 09:26:46.120972  1584 net.cpp:406] M2PELU28 <- Convolution29
I0929 09:26:46.120976  1584 net.cpp:367] M2PELU28 -> Convolution29 (in-place)
I0929 09:26:46.144605  1584 net.cpp:122] Setting up M2PELU28
I0929 09:26:46.144616  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.144618  1584 net.cpp:137] Memory required for data: 856474800
I0929 09:26:46.144623  1584 layer_factory.hpp:77] Creating layer Convolution30
I0929 09:26:46.144631  1584 net.cpp:84] Creating Layer Convolution30
I0929 09:26:46.144634  1584 net.cpp:406] Convolution30 <- Convolution29
I0929 09:26:46.144639  1584 net.cpp:380] Convolution30 -> Convolution30
I0929 09:26:46.144729  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:46.145978  1584 net.cpp:122] Setting up Convolution30
I0929 09:26:46.145998  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.146001  1584 net.cpp:137] Memory required for data: 859751600
I0929 09:26:46.146006  1584 layer_factory.hpp:77] Creating layer BatchNorm30
I0929 09:26:46.146011  1584 net.cpp:84] Creating Layer BatchNorm30
I0929 09:26:46.146014  1584 net.cpp:406] BatchNorm30 <- Convolution30
I0929 09:26:46.146018  1584 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0929 09:26:46.146157  1584 net.cpp:122] Setting up BatchNorm30
I0929 09:26:46.146162  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.146164  1584 net.cpp:137] Memory required for data: 863028400
I0929 09:26:46.146168  1584 layer_factory.hpp:77] Creating layer Scale30
I0929 09:26:46.146173  1584 net.cpp:84] Creating Layer Scale30
I0929 09:26:46.146175  1584 net.cpp:406] Scale30 <- Convolution30
I0929 09:26:46.146178  1584 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0929 09:26:46.146204  1584 layer_factory.hpp:77] Creating layer Scale30
I0929 09:26:46.146273  1584 net.cpp:122] Setting up Scale30
I0929 09:26:46.146277  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.146280  1584 net.cpp:137] Memory required for data: 866305200
I0929 09:26:46.146283  1584 layer_factory.hpp:77] Creating layer Eltwise14
I0929 09:26:46.146287  1584 net.cpp:84] Creating Layer Eltwise14
I0929 09:26:46.146289  1584 net.cpp:406] Eltwise14 <- Eltwise13_M2PELU27_0_split_1
I0929 09:26:46.146292  1584 net.cpp:406] Eltwise14 <- Convolution30
I0929 09:26:46.146297  1584 net.cpp:380] Eltwise14 -> Eltwise14
I0929 09:26:46.146309  1584 net.cpp:122] Setting up Eltwise14
I0929 09:26:46.146312  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.146314  1584 net.cpp:137] Memory required for data: 869582000
I0929 09:26:46.146317  1584 layer_factory.hpp:77] Creating layer M2PELU29
I0929 09:26:46.146322  1584 net.cpp:84] Creating Layer M2PELU29
I0929 09:26:46.146324  1584 net.cpp:406] M2PELU29 <- Eltwise14
I0929 09:26:46.146327  1584 net.cpp:367] M2PELU29 -> Eltwise14 (in-place)
I0929 09:26:46.146410  1584 net.cpp:122] Setting up M2PELU29
I0929 09:26:46.146414  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.146416  1584 net.cpp:137] Memory required for data: 872858800
I0929 09:26:46.146420  1584 layer_factory.hpp:77] Creating layer Eltwise14_M2PELU29_0_split
I0929 09:26:46.146423  1584 net.cpp:84] Creating Layer Eltwise14_M2PELU29_0_split
I0929 09:26:46.146425  1584 net.cpp:406] Eltwise14_M2PELU29_0_split <- Eltwise14
I0929 09:26:46.146430  1584 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_0
I0929 09:26:46.146435  1584 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_1
I0929 09:26:46.146456  1584 net.cpp:122] Setting up Eltwise14_M2PELU29_0_split
I0929 09:26:46.146461  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.146462  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.146464  1584 net.cpp:137] Memory required for data: 879412400
I0929 09:26:46.146466  1584 layer_factory.hpp:77] Creating layer Convolution31
I0929 09:26:46.146473  1584 net.cpp:84] Creating Layer Convolution31
I0929 09:26:46.146476  1584 net.cpp:406] Convolution31 <- Eltwise14_M2PELU29_0_split_0
I0929 09:26:46.146479  1584 net.cpp:380] Convolution31 -> Convolution31
I0929 09:26:46.146585  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:46.147596  1584 net.cpp:122] Setting up Convolution31
I0929 09:26:46.147604  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.147608  1584 net.cpp:137] Memory required for data: 882689200
I0929 09:26:46.147613  1584 layer_factory.hpp:77] Creating layer BatchNorm31
I0929 09:26:46.147616  1584 net.cpp:84] Creating Layer BatchNorm31
I0929 09:26:46.147619  1584 net.cpp:406] BatchNorm31 <- Convolution31
I0929 09:26:46.147624  1584 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0929 09:26:46.147743  1584 net.cpp:122] Setting up BatchNorm31
I0929 09:26:46.147748  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.147756  1584 net.cpp:137] Memory required for data: 885966000
I0929 09:26:46.147761  1584 layer_factory.hpp:77] Creating layer Scale31
I0929 09:26:46.147765  1584 net.cpp:84] Creating Layer Scale31
I0929 09:26:46.147768  1584 net.cpp:406] Scale31 <- Convolution31
I0929 09:26:46.147771  1584 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0929 09:26:46.147801  1584 layer_factory.hpp:77] Creating layer Scale31
I0929 09:26:46.147888  1584 net.cpp:122] Setting up Scale31
I0929 09:26:46.147894  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.147897  1584 net.cpp:137] Memory required for data: 889242800
I0929 09:26:46.147900  1584 layer_factory.hpp:77] Creating layer M2PELU30
I0929 09:26:46.147907  1584 net.cpp:84] Creating Layer M2PELU30
I0929 09:26:46.147909  1584 net.cpp:406] M2PELU30 <- Convolution31
I0929 09:26:46.147912  1584 net.cpp:367] M2PELU30 -> Convolution31 (in-place)
I0929 09:26:46.147990  1584 net.cpp:122] Setting up M2PELU30
I0929 09:26:46.147995  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.147997  1584 net.cpp:137] Memory required for data: 892519600
I0929 09:26:46.148001  1584 layer_factory.hpp:77] Creating layer Convolution32
I0929 09:26:46.148006  1584 net.cpp:84] Creating Layer Convolution32
I0929 09:26:46.148010  1584 net.cpp:406] Convolution32 <- Convolution31
I0929 09:26:46.148013  1584 net.cpp:380] Convolution32 -> Convolution32
I0929 09:26:46.148090  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:46.149091  1584 net.cpp:122] Setting up Convolution32
I0929 09:26:46.149098  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.149101  1584 net.cpp:137] Memory required for data: 895796400
I0929 09:26:46.149106  1584 layer_factory.hpp:77] Creating layer BatchNorm32
I0929 09:26:46.149111  1584 net.cpp:84] Creating Layer BatchNorm32
I0929 09:26:46.149113  1584 net.cpp:406] BatchNorm32 <- Convolution32
I0929 09:26:46.149117  1584 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I0929 09:26:46.149238  1584 net.cpp:122] Setting up BatchNorm32
I0929 09:26:46.149242  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.149245  1584 net.cpp:137] Memory required for data: 899073200
I0929 09:26:46.149250  1584 layer_factory.hpp:77] Creating layer Scale32
I0929 09:26:46.149255  1584 net.cpp:84] Creating Layer Scale32
I0929 09:26:46.149256  1584 net.cpp:406] Scale32 <- Convolution32
I0929 09:26:46.149260  1584 net.cpp:367] Scale32 -> Convolution32 (in-place)
I0929 09:26:46.149286  1584 layer_factory.hpp:77] Creating layer Scale32
I0929 09:26:46.149355  1584 net.cpp:122] Setting up Scale32
I0929 09:26:46.149359  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.149361  1584 net.cpp:137] Memory required for data: 902350000
I0929 09:26:46.149365  1584 layer_factory.hpp:77] Creating layer Eltwise15
I0929 09:26:46.149369  1584 net.cpp:84] Creating Layer Eltwise15
I0929 09:26:46.149372  1584 net.cpp:406] Eltwise15 <- Eltwise14_M2PELU29_0_split_1
I0929 09:26:46.149375  1584 net.cpp:406] Eltwise15 <- Convolution32
I0929 09:26:46.149379  1584 net.cpp:380] Eltwise15 -> Eltwise15
I0929 09:26:46.149389  1584 net.cpp:122] Setting up Eltwise15
I0929 09:26:46.149392  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.149394  1584 net.cpp:137] Memory required for data: 905626800
I0929 09:26:46.149397  1584 layer_factory.hpp:77] Creating layer M2PELU31
I0929 09:26:46.149402  1584 net.cpp:84] Creating Layer M2PELU31
I0929 09:26:46.149405  1584 net.cpp:406] M2PELU31 <- Eltwise15
I0929 09:26:46.149407  1584 net.cpp:367] M2PELU31 -> Eltwise15 (in-place)
I0929 09:26:46.149489  1584 net.cpp:122] Setting up M2PELU31
I0929 09:26:46.149493  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.149495  1584 net.cpp:137] Memory required for data: 908903600
I0929 09:26:46.149499  1584 layer_factory.hpp:77] Creating layer Eltwise15_M2PELU31_0_split
I0929 09:26:46.149503  1584 net.cpp:84] Creating Layer Eltwise15_M2PELU31_0_split
I0929 09:26:46.149507  1584 net.cpp:406] Eltwise15_M2PELU31_0_split <- Eltwise15
I0929 09:26:46.149515  1584 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_0
I0929 09:26:46.149520  1584 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_1
I0929 09:26:46.149544  1584 net.cpp:122] Setting up Eltwise15_M2PELU31_0_split
I0929 09:26:46.149547  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.149550  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.149552  1584 net.cpp:137] Memory required for data: 915457200
I0929 09:26:46.149554  1584 layer_factory.hpp:77] Creating layer Convolution33
I0929 09:26:46.149559  1584 net.cpp:84] Creating Layer Convolution33
I0929 09:26:46.149561  1584 net.cpp:406] Convolution33 <- Eltwise15_M2PELU31_0_split_0
I0929 09:26:46.149566  1584 net.cpp:380] Convolution33 -> Convolution33
I0929 09:26:46.149642  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:46.150696  1584 net.cpp:122] Setting up Convolution33
I0929 09:26:46.150704  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.150707  1584 net.cpp:137] Memory required for data: 918734000
I0929 09:26:46.150712  1584 layer_factory.hpp:77] Creating layer BatchNorm33
I0929 09:26:46.150717  1584 net.cpp:84] Creating Layer BatchNorm33
I0929 09:26:46.150718  1584 net.cpp:406] BatchNorm33 <- Convolution33
I0929 09:26:46.150723  1584 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I0929 09:26:46.150849  1584 net.cpp:122] Setting up BatchNorm33
I0929 09:26:46.150853  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.150856  1584 net.cpp:137] Memory required for data: 922010800
I0929 09:26:46.150861  1584 layer_factory.hpp:77] Creating layer Scale33
I0929 09:26:46.150864  1584 net.cpp:84] Creating Layer Scale33
I0929 09:26:46.150866  1584 net.cpp:406] Scale33 <- Convolution33
I0929 09:26:46.150869  1584 net.cpp:367] Scale33 -> Convolution33 (in-place)
I0929 09:26:46.150895  1584 layer_factory.hpp:77] Creating layer Scale33
I0929 09:26:46.150967  1584 net.cpp:122] Setting up Scale33
I0929 09:26:46.150970  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.150972  1584 net.cpp:137] Memory required for data: 925287600
I0929 09:26:46.150976  1584 layer_factory.hpp:77] Creating layer M2PELU32
I0929 09:26:46.150981  1584 net.cpp:84] Creating Layer M2PELU32
I0929 09:26:46.150985  1584 net.cpp:406] M2PELU32 <- Convolution33
I0929 09:26:46.150987  1584 net.cpp:367] M2PELU32 -> Convolution33 (in-place)
I0929 09:26:46.151067  1584 net.cpp:122] Setting up M2PELU32
I0929 09:26:46.151070  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.151072  1584 net.cpp:137] Memory required for data: 928564400
I0929 09:26:46.151077  1584 layer_factory.hpp:77] Creating layer Convolution34
I0929 09:26:46.151082  1584 net.cpp:84] Creating Layer Convolution34
I0929 09:26:46.151084  1584 net.cpp:406] Convolution34 <- Convolution33
I0929 09:26:46.151089  1584 net.cpp:380] Convolution34 -> Convolution34
I0929 09:26:46.151165  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:46.152726  1584 net.cpp:122] Setting up Convolution34
I0929 09:26:46.152734  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.152737  1584 net.cpp:137] Memory required for data: 931841200
I0929 09:26:46.152741  1584 layer_factory.hpp:77] Creating layer BatchNorm34
I0929 09:26:46.152747  1584 net.cpp:84] Creating Layer BatchNorm34
I0929 09:26:46.152750  1584 net.cpp:406] BatchNorm34 <- Convolution34
I0929 09:26:46.152755  1584 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I0929 09:26:46.152880  1584 net.cpp:122] Setting up BatchNorm34
I0929 09:26:46.152884  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.152886  1584 net.cpp:137] Memory required for data: 935118000
I0929 09:26:46.152891  1584 layer_factory.hpp:77] Creating layer Scale34
I0929 09:26:46.152895  1584 net.cpp:84] Creating Layer Scale34
I0929 09:26:46.152897  1584 net.cpp:406] Scale34 <- Convolution34
I0929 09:26:46.152901  1584 net.cpp:367] Scale34 -> Convolution34 (in-place)
I0929 09:26:46.152935  1584 layer_factory.hpp:77] Creating layer Scale34
I0929 09:26:46.153007  1584 net.cpp:122] Setting up Scale34
I0929 09:26:46.153012  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.153013  1584 net.cpp:137] Memory required for data: 938394800
I0929 09:26:46.153017  1584 layer_factory.hpp:77] Creating layer Eltwise16
I0929 09:26:46.153022  1584 net.cpp:84] Creating Layer Eltwise16
I0929 09:26:46.153024  1584 net.cpp:406] Eltwise16 <- Eltwise15_M2PELU31_0_split_1
I0929 09:26:46.153026  1584 net.cpp:406] Eltwise16 <- Convolution34
I0929 09:26:46.153030  1584 net.cpp:380] Eltwise16 -> Eltwise16
I0929 09:26:46.153043  1584 net.cpp:122] Setting up Eltwise16
I0929 09:26:46.153045  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.153048  1584 net.cpp:137] Memory required for data: 941671600
I0929 09:26:46.153049  1584 layer_factory.hpp:77] Creating layer M2PELU33
I0929 09:26:46.153054  1584 net.cpp:84] Creating Layer M2PELU33
I0929 09:26:46.153056  1584 net.cpp:406] M2PELU33 <- Eltwise16
I0929 09:26:46.153059  1584 net.cpp:367] M2PELU33 -> Eltwise16 (in-place)
I0929 09:26:46.153141  1584 net.cpp:122] Setting up M2PELU33
I0929 09:26:46.153146  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.153147  1584 net.cpp:137] Memory required for data: 944948400
I0929 09:26:46.153151  1584 layer_factory.hpp:77] Creating layer Eltwise16_M2PELU33_0_split
I0929 09:26:46.153154  1584 net.cpp:84] Creating Layer Eltwise16_M2PELU33_0_split
I0929 09:26:46.153156  1584 net.cpp:406] Eltwise16_M2PELU33_0_split <- Eltwise16
I0929 09:26:46.153161  1584 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_0
I0929 09:26:46.153163  1584 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_1
I0929 09:26:46.153187  1584 net.cpp:122] Setting up Eltwise16_M2PELU33_0_split
I0929 09:26:46.153192  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.153194  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.153197  1584 net.cpp:137] Memory required for data: 951502000
I0929 09:26:46.153198  1584 layer_factory.hpp:77] Creating layer Convolution35
I0929 09:26:46.153204  1584 net.cpp:84] Creating Layer Convolution35
I0929 09:26:46.153208  1584 net.cpp:406] Convolution35 <- Eltwise16_M2PELU33_0_split_0
I0929 09:26:46.153211  1584 net.cpp:380] Convolution35 -> Convolution35
I0929 09:26:46.153292  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:46.154290  1584 net.cpp:122] Setting up Convolution35
I0929 09:26:46.154299  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.154301  1584 net.cpp:137] Memory required for data: 954778800
I0929 09:26:46.154305  1584 layer_factory.hpp:77] Creating layer BatchNorm35
I0929 09:26:46.154312  1584 net.cpp:84] Creating Layer BatchNorm35
I0929 09:26:46.154315  1584 net.cpp:406] BatchNorm35 <- Convolution35
I0929 09:26:46.154320  1584 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I0929 09:26:46.154446  1584 net.cpp:122] Setting up BatchNorm35
I0929 09:26:46.154450  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.154453  1584 net.cpp:137] Memory required for data: 958055600
I0929 09:26:46.154458  1584 layer_factory.hpp:77] Creating layer Scale35
I0929 09:26:46.172709  1584 net.cpp:84] Creating Layer Scale35
I0929 09:26:46.172718  1584 net.cpp:406] Scale35 <- Convolution35
I0929 09:26:46.172724  1584 net.cpp:367] Scale35 -> Convolution35 (in-place)
I0929 09:26:46.172763  1584 layer_factory.hpp:77] Creating layer Scale35
I0929 09:26:46.172850  1584 net.cpp:122] Setting up Scale35
I0929 09:26:46.172857  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.172858  1584 net.cpp:137] Memory required for data: 961332400
I0929 09:26:46.172863  1584 layer_factory.hpp:77] Creating layer M2PELU34
I0929 09:26:46.172868  1584 net.cpp:84] Creating Layer M2PELU34
I0929 09:26:46.172870  1584 net.cpp:406] M2PELU34 <- Convolution35
I0929 09:26:46.172875  1584 net.cpp:367] M2PELU34 -> Convolution35 (in-place)
I0929 09:26:46.172965  1584 net.cpp:122] Setting up M2PELU34
I0929 09:26:46.172977  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.172979  1584 net.cpp:137] Memory required for data: 964609200
I0929 09:26:46.172984  1584 layer_factory.hpp:77] Creating layer Convolution36
I0929 09:26:46.172991  1584 net.cpp:84] Creating Layer Convolution36
I0929 09:26:46.172994  1584 net.cpp:406] Convolution36 <- Convolution35
I0929 09:26:46.173001  1584 net.cpp:380] Convolution36 -> Convolution36
I0929 09:26:46.173091  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:46.173825  1584 net.cpp:122] Setting up Convolution36
I0929 09:26:46.173832  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.173835  1584 net.cpp:137] Memory required for data: 967886000
I0929 09:26:46.173840  1584 layer_factory.hpp:77] Creating layer BatchNorm36
I0929 09:26:46.173844  1584 net.cpp:84] Creating Layer BatchNorm36
I0929 09:26:46.173847  1584 net.cpp:406] BatchNorm36 <- Convolution36
I0929 09:26:46.173851  1584 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I0929 09:26:46.174029  1584 net.cpp:122] Setting up BatchNorm36
I0929 09:26:46.174036  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.174038  1584 net.cpp:137] Memory required for data: 971162800
I0929 09:26:46.174043  1584 layer_factory.hpp:77] Creating layer Scale36
I0929 09:26:46.174047  1584 net.cpp:84] Creating Layer Scale36
I0929 09:26:46.174051  1584 net.cpp:406] Scale36 <- Convolution36
I0929 09:26:46.174054  1584 net.cpp:367] Scale36 -> Convolution36 (in-place)
I0929 09:26:46.174084  1584 layer_factory.hpp:77] Creating layer Scale36
I0929 09:26:46.174170  1584 net.cpp:122] Setting up Scale36
I0929 09:26:46.174175  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.174177  1584 net.cpp:137] Memory required for data: 974439600
I0929 09:26:46.174180  1584 layer_factory.hpp:77] Creating layer Eltwise17
I0929 09:26:46.174194  1584 net.cpp:84] Creating Layer Eltwise17
I0929 09:26:46.174197  1584 net.cpp:406] Eltwise17 <- Eltwise16_M2PELU33_0_split_1
I0929 09:26:46.174201  1584 net.cpp:406] Eltwise17 <- Convolution36
I0929 09:26:46.174204  1584 net.cpp:380] Eltwise17 -> Eltwise17
I0929 09:26:46.174216  1584 net.cpp:122] Setting up Eltwise17
I0929 09:26:46.174221  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.174222  1584 net.cpp:137] Memory required for data: 977716400
I0929 09:26:46.174224  1584 layer_factory.hpp:77] Creating layer M2PELU35
I0929 09:26:46.174232  1584 net.cpp:84] Creating Layer M2PELU35
I0929 09:26:46.174233  1584 net.cpp:406] M2PELU35 <- Eltwise17
I0929 09:26:46.174237  1584 net.cpp:367] M2PELU35 -> Eltwise17 (in-place)
I0929 09:26:46.174325  1584 net.cpp:122] Setting up M2PELU35
I0929 09:26:46.174329  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.174331  1584 net.cpp:137] Memory required for data: 980993200
I0929 09:26:46.174335  1584 layer_factory.hpp:77] Creating layer Eltwise17_M2PELU35_0_split
I0929 09:26:46.174340  1584 net.cpp:84] Creating Layer Eltwise17_M2PELU35_0_split
I0929 09:26:46.174341  1584 net.cpp:406] Eltwise17_M2PELU35_0_split <- Eltwise17
I0929 09:26:46.174345  1584 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_0
I0929 09:26:46.174360  1584 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_1
I0929 09:26:46.174383  1584 net.cpp:122] Setting up Eltwise17_M2PELU35_0_split
I0929 09:26:46.174387  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.174391  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.174392  1584 net.cpp:137] Memory required for data: 987546800
I0929 09:26:46.174394  1584 layer_factory.hpp:77] Creating layer Convolution37
I0929 09:26:46.174399  1584 net.cpp:84] Creating Layer Convolution37
I0929 09:26:46.174402  1584 net.cpp:406] Convolution37 <- Eltwise17_M2PELU35_0_split_0
I0929 09:26:46.174407  1584 net.cpp:380] Convolution37 -> Convolution37
I0929 09:26:46.174499  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:46.175824  1584 net.cpp:122] Setting up Convolution37
I0929 09:26:46.175839  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.175843  1584 net.cpp:137] Memory required for data: 990823600
I0929 09:26:46.175848  1584 layer_factory.hpp:77] Creating layer BatchNorm37
I0929 09:26:46.175853  1584 net.cpp:84] Creating Layer BatchNorm37
I0929 09:26:46.175856  1584 net.cpp:406] BatchNorm37 <- Convolution37
I0929 09:26:46.175860  1584 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I0929 09:26:46.175992  1584 net.cpp:122] Setting up BatchNorm37
I0929 09:26:46.175997  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.175998  1584 net.cpp:137] Memory required for data: 994100400
I0929 09:26:46.176003  1584 layer_factory.hpp:77] Creating layer Scale37
I0929 09:26:46.176007  1584 net.cpp:84] Creating Layer Scale37
I0929 09:26:46.176010  1584 net.cpp:406] Scale37 <- Convolution37
I0929 09:26:46.176013  1584 net.cpp:367] Scale37 -> Convolution37 (in-place)
I0929 09:26:46.176040  1584 layer_factory.hpp:77] Creating layer Scale37
I0929 09:26:46.176116  1584 net.cpp:122] Setting up Scale37
I0929 09:26:46.176120  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.176122  1584 net.cpp:137] Memory required for data: 997377200
I0929 09:26:46.176126  1584 layer_factory.hpp:77] Creating layer M2PELU36
I0929 09:26:46.176132  1584 net.cpp:84] Creating Layer M2PELU36
I0929 09:26:46.176134  1584 net.cpp:406] M2PELU36 <- Convolution37
I0929 09:26:46.176138  1584 net.cpp:367] M2PELU36 -> Convolution37 (in-place)
I0929 09:26:46.176220  1584 net.cpp:122] Setting up M2PELU36
I0929 09:26:46.176224  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.176226  1584 net.cpp:137] Memory required for data: 1000654000
I0929 09:26:46.176230  1584 layer_factory.hpp:77] Creating layer Convolution38
I0929 09:26:46.176236  1584 net.cpp:84] Creating Layer Convolution38
I0929 09:26:46.176239  1584 net.cpp:406] Convolution38 <- Convolution37
I0929 09:26:46.176244  1584 net.cpp:380] Convolution38 -> Convolution38
I0929 09:26:46.176326  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:46.177793  1584 net.cpp:122] Setting up Convolution38
I0929 09:26:46.177801  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.177804  1584 net.cpp:137] Memory required for data: 1003930800
I0929 09:26:46.177809  1584 layer_factory.hpp:77] Creating layer BatchNorm38
I0929 09:26:46.177814  1584 net.cpp:84] Creating Layer BatchNorm38
I0929 09:26:46.177817  1584 net.cpp:406] BatchNorm38 <- Convolution38
I0929 09:26:46.177821  1584 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I0929 09:26:46.177964  1584 net.cpp:122] Setting up BatchNorm38
I0929 09:26:46.177973  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.177976  1584 net.cpp:137] Memory required for data: 1007207600
I0929 09:26:46.177983  1584 layer_factory.hpp:77] Creating layer Scale38
I0929 09:26:46.177989  1584 net.cpp:84] Creating Layer Scale38
I0929 09:26:46.177994  1584 net.cpp:406] Scale38 <- Convolution38
I0929 09:26:46.177999  1584 net.cpp:367] Scale38 -> Convolution38 (in-place)
I0929 09:26:46.178041  1584 layer_factory.hpp:77] Creating layer Scale38
I0929 09:26:46.178129  1584 net.cpp:122] Setting up Scale38
I0929 09:26:46.178135  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.178138  1584 net.cpp:137] Memory required for data: 1010484400
I0929 09:26:46.178141  1584 layer_factory.hpp:77] Creating layer Eltwise18
I0929 09:26:46.178145  1584 net.cpp:84] Creating Layer Eltwise18
I0929 09:26:46.178148  1584 net.cpp:406] Eltwise18 <- Eltwise17_M2PELU35_0_split_1
I0929 09:26:46.178151  1584 net.cpp:406] Eltwise18 <- Convolution38
I0929 09:26:46.178155  1584 net.cpp:380] Eltwise18 -> Eltwise18
I0929 09:26:46.178169  1584 net.cpp:122] Setting up Eltwise18
I0929 09:26:46.178171  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.178174  1584 net.cpp:137] Memory required for data: 1013761200
I0929 09:26:46.178175  1584 layer_factory.hpp:77] Creating layer M2PELU37
I0929 09:26:46.178187  1584 net.cpp:84] Creating Layer M2PELU37
I0929 09:26:46.178190  1584 net.cpp:406] M2PELU37 <- Eltwise18
I0929 09:26:46.178194  1584 net.cpp:367] M2PELU37 -> Eltwise18 (in-place)
I0929 09:26:46.178283  1584 net.cpp:122] Setting up M2PELU37
I0929 09:26:46.178287  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.178289  1584 net.cpp:137] Memory required for data: 1017038000
I0929 09:26:46.178293  1584 layer_factory.hpp:77] Creating layer Eltwise18_M2PELU37_0_split
I0929 09:26:46.178297  1584 net.cpp:84] Creating Layer Eltwise18_M2PELU37_0_split
I0929 09:26:46.178298  1584 net.cpp:406] Eltwise18_M2PELU37_0_split <- Eltwise18
I0929 09:26:46.178303  1584 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_0
I0929 09:26:46.178306  1584 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_1
I0929 09:26:46.178329  1584 net.cpp:122] Setting up Eltwise18_M2PELU37_0_split
I0929 09:26:46.178333  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.178336  1584 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 09:26:46.178339  1584 net.cpp:137] Memory required for data: 1023591600
I0929 09:26:46.178340  1584 layer_factory.hpp:77] Creating layer Convolution39
I0929 09:26:46.178347  1584 net.cpp:84] Creating Layer Convolution39
I0929 09:26:46.178350  1584 net.cpp:406] Convolution39 <- Eltwise18_M2PELU37_0_split_0
I0929 09:26:46.178354  1584 net.cpp:380] Convolution39 -> Convolution39
I0929 09:26:46.178434  1584 filler.hpp:251] The std of weights in this layer is: 0.242536
I0929 09:26:46.179353  1584 net.cpp:122] Setting up Convolution39
I0929 09:26:46.179363  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.179365  1584 net.cpp:137] Memory required for data: 1025230000
I0929 09:26:46.179369  1584 layer_factory.hpp:77] Creating layer BatchNorm39
I0929 09:26:46.179375  1584 net.cpp:84] Creating Layer BatchNorm39
I0929 09:26:46.179378  1584 net.cpp:406] BatchNorm39 <- Convolution39
I0929 09:26:46.179383  1584 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I0929 09:26:46.179514  1584 net.cpp:122] Setting up BatchNorm39
I0929 09:26:46.179519  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.179522  1584 net.cpp:137] Memory required for data: 1026868400
I0929 09:26:46.179527  1584 layer_factory.hpp:77] Creating layer Scale39
I0929 09:26:46.179531  1584 net.cpp:84] Creating Layer Scale39
I0929 09:26:46.179533  1584 net.cpp:406] Scale39 <- Convolution39
I0929 09:26:46.179536  1584 net.cpp:367] Scale39 -> Convolution39 (in-place)
I0929 09:26:46.179563  1584 layer_factory.hpp:77] Creating layer Scale39
I0929 09:26:46.179638  1584 net.cpp:122] Setting up Scale39
I0929 09:26:46.179643  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.179646  1584 net.cpp:137] Memory required for data: 1028506800
I0929 09:26:46.179649  1584 layer_factory.hpp:77] Creating layer Convolution40
I0929 09:26:46.179656  1584 net.cpp:84] Creating Layer Convolution40
I0929 09:26:46.179658  1584 net.cpp:406] Convolution40 <- Eltwise18_M2PELU37_0_split_1
I0929 09:26:46.179663  1584 net.cpp:380] Convolution40 -> Convolution40
I0929 09:26:46.179744  1584 filler.hpp:251] The std of weights in this layer is: 0.0808452
I0929 09:26:46.181028  1584 net.cpp:122] Setting up Convolution40
I0929 09:26:46.181036  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.181040  1584 net.cpp:137] Memory required for data: 1030145200
I0929 09:26:46.181044  1584 layer_factory.hpp:77] Creating layer BatchNorm40
I0929 09:26:46.181049  1584 net.cpp:84] Creating Layer BatchNorm40
I0929 09:26:46.181052  1584 net.cpp:406] BatchNorm40 <- Convolution40
I0929 09:26:46.181056  1584 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I0929 09:26:46.181190  1584 net.cpp:122] Setting up BatchNorm40
I0929 09:26:46.181193  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.181195  1584 net.cpp:137] Memory required for data: 1031783600
I0929 09:26:46.181200  1584 layer_factory.hpp:77] Creating layer Scale40
I0929 09:26:46.181205  1584 net.cpp:84] Creating Layer Scale40
I0929 09:26:46.181215  1584 net.cpp:406] Scale40 <- Convolution40
I0929 09:26:46.181218  1584 net.cpp:367] Scale40 -> Convolution40 (in-place)
I0929 09:26:46.181246  1584 layer_factory.hpp:77] Creating layer Scale40
I0929 09:26:46.181321  1584 net.cpp:122] Setting up Scale40
I0929 09:26:46.181326  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.181329  1584 net.cpp:137] Memory required for data: 1033422000
I0929 09:26:46.181332  1584 layer_factory.hpp:77] Creating layer M2PELU38
I0929 09:26:46.181337  1584 net.cpp:84] Creating Layer M2PELU38
I0929 09:26:46.181339  1584 net.cpp:406] M2PELU38 <- Convolution40
I0929 09:26:46.181344  1584 net.cpp:367] M2PELU38 -> Convolution40 (in-place)
I0929 09:26:46.181430  1584 net.cpp:122] Setting up M2PELU38
I0929 09:26:46.181434  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.181437  1584 net.cpp:137] Memory required for data: 1035060400
I0929 09:26:46.181440  1584 layer_factory.hpp:77] Creating layer Convolution41
I0929 09:26:46.181447  1584 net.cpp:84] Creating Layer Convolution41
I0929 09:26:46.181449  1584 net.cpp:406] Convolution41 <- Convolution40
I0929 09:26:46.181454  1584 net.cpp:380] Convolution41 -> Convolution41
I0929 09:26:46.181535  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:46.183184  1584 net.cpp:122] Setting up Convolution41
I0929 09:26:46.183193  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.183197  1584 net.cpp:137] Memory required for data: 1036698800
I0929 09:26:46.183200  1584 layer_factory.hpp:77] Creating layer BatchNorm41
I0929 09:26:46.183207  1584 net.cpp:84] Creating Layer BatchNorm41
I0929 09:26:46.183209  1584 net.cpp:406] BatchNorm41 <- Convolution41
I0929 09:26:46.183212  1584 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I0929 09:26:46.183342  1584 net.cpp:122] Setting up BatchNorm41
I0929 09:26:46.183347  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.183349  1584 net.cpp:137] Memory required for data: 1038337200
I0929 09:26:46.183353  1584 layer_factory.hpp:77] Creating layer Scale41
I0929 09:26:46.183357  1584 net.cpp:84] Creating Layer Scale41
I0929 09:26:46.183360  1584 net.cpp:406] Scale41 <- Convolution41
I0929 09:26:46.183364  1584 net.cpp:367] Scale41 -> Convolution41 (in-place)
I0929 09:26:46.183390  1584 layer_factory.hpp:77] Creating layer Scale41
I0929 09:26:46.183465  1584 net.cpp:122] Setting up Scale41
I0929 09:26:46.183468  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.183470  1584 net.cpp:137] Memory required for data: 1039975600
I0929 09:26:46.183475  1584 layer_factory.hpp:77] Creating layer Eltwise19
I0929 09:26:46.183478  1584 net.cpp:84] Creating Layer Eltwise19
I0929 09:26:46.183480  1584 net.cpp:406] Eltwise19 <- Convolution39
I0929 09:26:46.183485  1584 net.cpp:406] Eltwise19 <- Convolution41
I0929 09:26:46.183488  1584 net.cpp:380] Eltwise19 -> Eltwise19
I0929 09:26:46.183504  1584 net.cpp:122] Setting up Eltwise19
I0929 09:26:46.183508  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.183511  1584 net.cpp:137] Memory required for data: 1041614000
I0929 09:26:46.183512  1584 layer_factory.hpp:77] Creating layer M2PELU39
I0929 09:26:46.203582  1584 net.cpp:84] Creating Layer M2PELU39
I0929 09:26:46.203589  1584 net.cpp:406] M2PELU39 <- Eltwise19
I0929 09:26:46.203598  1584 net.cpp:367] M2PELU39 -> Eltwise19 (in-place)
I0929 09:26:46.203711  1584 net.cpp:122] Setting up M2PELU39
I0929 09:26:46.203717  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.203719  1584 net.cpp:137] Memory required for data: 1043252400
I0929 09:26:46.203724  1584 layer_factory.hpp:77] Creating layer Eltwise19_M2PELU39_0_split
I0929 09:26:46.203729  1584 net.cpp:84] Creating Layer Eltwise19_M2PELU39_0_split
I0929 09:26:46.203732  1584 net.cpp:406] Eltwise19_M2PELU39_0_split <- Eltwise19
I0929 09:26:46.203737  1584 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_0
I0929 09:26:46.203742  1584 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_1
I0929 09:26:46.203778  1584 net.cpp:122] Setting up Eltwise19_M2PELU39_0_split
I0929 09:26:46.203783  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.203785  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.203788  1584 net.cpp:137] Memory required for data: 1046529200
I0929 09:26:46.203790  1584 layer_factory.hpp:77] Creating layer Convolution42
I0929 09:26:46.203796  1584 net.cpp:84] Creating Layer Convolution42
I0929 09:26:46.203799  1584 net.cpp:406] Convolution42 <- Eltwise19_M2PELU39_0_split_0
I0929 09:26:46.203804  1584 net.cpp:380] Convolution42 -> Convolution42
I0929 09:26:46.203893  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:46.206214  1584 net.cpp:122] Setting up Convolution42
I0929 09:26:46.206223  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.206226  1584 net.cpp:137] Memory required for data: 1048167600
I0929 09:26:46.206231  1584 layer_factory.hpp:77] Creating layer BatchNorm42
I0929 09:26:46.206238  1584 net.cpp:84] Creating Layer BatchNorm42
I0929 09:26:46.206240  1584 net.cpp:406] BatchNorm42 <- Convolution42
I0929 09:26:46.206244  1584 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I0929 09:26:46.206378  1584 net.cpp:122] Setting up BatchNorm42
I0929 09:26:46.206382  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.206384  1584 net.cpp:137] Memory required for data: 1049806000
I0929 09:26:46.206389  1584 layer_factory.hpp:77] Creating layer Scale42
I0929 09:26:46.206393  1584 net.cpp:84] Creating Layer Scale42
I0929 09:26:46.206396  1584 net.cpp:406] Scale42 <- Convolution42
I0929 09:26:46.206399  1584 net.cpp:367] Scale42 -> Convolution42 (in-place)
I0929 09:26:46.206428  1584 layer_factory.hpp:77] Creating layer Scale42
I0929 09:26:46.206503  1584 net.cpp:122] Setting up Scale42
I0929 09:26:46.206507  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.206509  1584 net.cpp:137] Memory required for data: 1051444400
I0929 09:26:46.206513  1584 layer_factory.hpp:77] Creating layer M2PELU40
I0929 09:26:46.206518  1584 net.cpp:84] Creating Layer M2PELU40
I0929 09:26:46.206531  1584 net.cpp:406] M2PELU40 <- Convolution42
I0929 09:26:46.206544  1584 net.cpp:367] M2PELU40 -> Convolution42 (in-place)
I0929 09:26:46.206645  1584 net.cpp:122] Setting up M2PELU40
I0929 09:26:46.206650  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.206652  1584 net.cpp:137] Memory required for data: 1053082800
I0929 09:26:46.206656  1584 layer_factory.hpp:77] Creating layer Convolution43
I0929 09:26:46.206662  1584 net.cpp:84] Creating Layer Convolution43
I0929 09:26:46.206665  1584 net.cpp:406] Convolution43 <- Convolution42
I0929 09:26:46.206670  1584 net.cpp:380] Convolution43 -> Convolution43
I0929 09:26:46.206753  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:46.208549  1584 net.cpp:122] Setting up Convolution43
I0929 09:26:46.208557  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.208559  1584 net.cpp:137] Memory required for data: 1054721200
I0929 09:26:46.208564  1584 layer_factory.hpp:77] Creating layer BatchNorm43
I0929 09:26:46.208570  1584 net.cpp:84] Creating Layer BatchNorm43
I0929 09:26:46.208572  1584 net.cpp:406] BatchNorm43 <- Convolution43
I0929 09:26:46.208576  1584 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I0929 09:26:46.208710  1584 net.cpp:122] Setting up BatchNorm43
I0929 09:26:46.208714  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.208716  1584 net.cpp:137] Memory required for data: 1056359600
I0929 09:26:46.208721  1584 layer_factory.hpp:77] Creating layer Scale43
I0929 09:26:46.208725  1584 net.cpp:84] Creating Layer Scale43
I0929 09:26:46.208727  1584 net.cpp:406] Scale43 <- Convolution43
I0929 09:26:46.208731  1584 net.cpp:367] Scale43 -> Convolution43 (in-place)
I0929 09:26:46.208757  1584 layer_factory.hpp:77] Creating layer Scale43
I0929 09:26:46.208832  1584 net.cpp:122] Setting up Scale43
I0929 09:26:46.208837  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.208838  1584 net.cpp:137] Memory required for data: 1057998000
I0929 09:26:46.208849  1584 layer_factory.hpp:77] Creating layer Eltwise20
I0929 09:26:46.208853  1584 net.cpp:84] Creating Layer Eltwise20
I0929 09:26:46.208856  1584 net.cpp:406] Eltwise20 <- Eltwise19_M2PELU39_0_split_1
I0929 09:26:46.208859  1584 net.cpp:406] Eltwise20 <- Convolution43
I0929 09:26:46.208864  1584 net.cpp:380] Eltwise20 -> Eltwise20
I0929 09:26:46.208881  1584 net.cpp:122] Setting up Eltwise20
I0929 09:26:46.208885  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.208887  1584 net.cpp:137] Memory required for data: 1059636400
I0929 09:26:46.208889  1584 layer_factory.hpp:77] Creating layer M2PELU41
I0929 09:26:46.208894  1584 net.cpp:84] Creating Layer M2PELU41
I0929 09:26:46.208896  1584 net.cpp:406] M2PELU41 <- Eltwise20
I0929 09:26:46.208900  1584 net.cpp:367] M2PELU41 -> Eltwise20 (in-place)
I0929 09:26:46.208988  1584 net.cpp:122] Setting up M2PELU41
I0929 09:26:46.208993  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.208995  1584 net.cpp:137] Memory required for data: 1061274800
I0929 09:26:46.208998  1584 layer_factory.hpp:77] Creating layer Eltwise20_M2PELU41_0_split
I0929 09:26:46.209003  1584 net.cpp:84] Creating Layer Eltwise20_M2PELU41_0_split
I0929 09:26:46.209005  1584 net.cpp:406] Eltwise20_M2PELU41_0_split <- Eltwise20
I0929 09:26:46.209008  1584 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_0
I0929 09:26:46.209012  1584 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_1
I0929 09:26:46.209038  1584 net.cpp:122] Setting up Eltwise20_M2PELU41_0_split
I0929 09:26:46.209040  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.209043  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.209045  1584 net.cpp:137] Memory required for data: 1064551600
I0929 09:26:46.209048  1584 layer_factory.hpp:77] Creating layer Convolution44
I0929 09:26:46.209053  1584 net.cpp:84] Creating Layer Convolution44
I0929 09:26:46.209055  1584 net.cpp:406] Convolution44 <- Eltwise20_M2PELU41_0_split_0
I0929 09:26:46.209060  1584 net.cpp:380] Convolution44 -> Convolution44
I0929 09:26:46.209139  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:46.211083  1584 net.cpp:122] Setting up Convolution44
I0929 09:26:46.211092  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.211094  1584 net.cpp:137] Memory required for data: 1066190000
I0929 09:26:46.211099  1584 layer_factory.hpp:77] Creating layer BatchNorm44
I0929 09:26:46.211104  1584 net.cpp:84] Creating Layer BatchNorm44
I0929 09:26:46.211107  1584 net.cpp:406] BatchNorm44 <- Convolution44
I0929 09:26:46.211112  1584 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I0929 09:26:46.211248  1584 net.cpp:122] Setting up BatchNorm44
I0929 09:26:46.211252  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.211254  1584 net.cpp:137] Memory required for data: 1067828400
I0929 09:26:46.211259  1584 layer_factory.hpp:77] Creating layer Scale44
I0929 09:26:46.211263  1584 net.cpp:84] Creating Layer Scale44
I0929 09:26:46.211266  1584 net.cpp:406] Scale44 <- Convolution44
I0929 09:26:46.211269  1584 net.cpp:367] Scale44 -> Convolution44 (in-place)
I0929 09:26:46.211297  1584 layer_factory.hpp:77] Creating layer Scale44
I0929 09:26:46.211371  1584 net.cpp:122] Setting up Scale44
I0929 09:26:46.211375  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.211377  1584 net.cpp:137] Memory required for data: 1069466800
I0929 09:26:46.211381  1584 layer_factory.hpp:77] Creating layer M2PELU42
I0929 09:26:46.211386  1584 net.cpp:84] Creating Layer M2PELU42
I0929 09:26:46.211390  1584 net.cpp:406] M2PELU42 <- Convolution44
I0929 09:26:46.211392  1584 net.cpp:367] M2PELU42 -> Convolution44 (in-place)
I0929 09:26:46.211479  1584 net.cpp:122] Setting up M2PELU42
I0929 09:26:46.211484  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.211486  1584 net.cpp:137] Memory required for data: 1071105200
I0929 09:26:46.211489  1584 layer_factory.hpp:77] Creating layer Convolution45
I0929 09:26:46.211503  1584 net.cpp:84] Creating Layer Convolution45
I0929 09:26:46.211506  1584 net.cpp:406] Convolution45 <- Convolution44
I0929 09:26:46.211510  1584 net.cpp:380] Convolution45 -> Convolution45
I0929 09:26:46.211592  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:46.213203  1584 net.cpp:122] Setting up Convolution45
I0929 09:26:46.213212  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.213214  1584 net.cpp:137] Memory required for data: 1072743600
I0929 09:26:46.213219  1584 layer_factory.hpp:77] Creating layer BatchNorm45
I0929 09:26:46.213224  1584 net.cpp:84] Creating Layer BatchNorm45
I0929 09:26:46.213227  1584 net.cpp:406] BatchNorm45 <- Convolution45
I0929 09:26:46.213230  1584 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I0929 09:26:46.213384  1584 net.cpp:122] Setting up BatchNorm45
I0929 09:26:46.213388  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.213390  1584 net.cpp:137] Memory required for data: 1074382000
I0929 09:26:46.213395  1584 layer_factory.hpp:77] Creating layer Scale45
I0929 09:26:46.213398  1584 net.cpp:84] Creating Layer Scale45
I0929 09:26:46.213402  1584 net.cpp:406] Scale45 <- Convolution45
I0929 09:26:46.213404  1584 net.cpp:367] Scale45 -> Convolution45 (in-place)
I0929 09:26:46.213430  1584 layer_factory.hpp:77] Creating layer Scale45
I0929 09:26:46.213506  1584 net.cpp:122] Setting up Scale45
I0929 09:26:46.213510  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.213512  1584 net.cpp:137] Memory required for data: 1076020400
I0929 09:26:46.213516  1584 layer_factory.hpp:77] Creating layer Eltwise21
I0929 09:26:46.213521  1584 net.cpp:84] Creating Layer Eltwise21
I0929 09:26:46.213523  1584 net.cpp:406] Eltwise21 <- Eltwise20_M2PELU41_0_split_1
I0929 09:26:46.213526  1584 net.cpp:406] Eltwise21 <- Convolution45
I0929 09:26:46.213529  1584 net.cpp:380] Eltwise21 -> Eltwise21
I0929 09:26:46.213546  1584 net.cpp:122] Setting up Eltwise21
I0929 09:26:46.213549  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.213551  1584 net.cpp:137] Memory required for data: 1077658800
I0929 09:26:46.213552  1584 layer_factory.hpp:77] Creating layer M2PELU43
I0929 09:26:46.213558  1584 net.cpp:84] Creating Layer M2PELU43
I0929 09:26:46.213560  1584 net.cpp:406] M2PELU43 <- Eltwise21
I0929 09:26:46.213563  1584 net.cpp:367] M2PELU43 -> Eltwise21 (in-place)
I0929 09:26:46.213650  1584 net.cpp:122] Setting up M2PELU43
I0929 09:26:46.213654  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.213656  1584 net.cpp:137] Memory required for data: 1079297200
I0929 09:26:46.213660  1584 layer_factory.hpp:77] Creating layer Eltwise21_M2PELU43_0_split
I0929 09:26:46.213663  1584 net.cpp:84] Creating Layer Eltwise21_M2PELU43_0_split
I0929 09:26:46.213665  1584 net.cpp:406] Eltwise21_M2PELU43_0_split <- Eltwise21
I0929 09:26:46.213668  1584 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_0
I0929 09:26:46.213673  1584 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_1
I0929 09:26:46.213697  1584 net.cpp:122] Setting up Eltwise21_M2PELU43_0_split
I0929 09:26:46.213701  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.213703  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.213706  1584 net.cpp:137] Memory required for data: 1082574000
I0929 09:26:46.213707  1584 layer_factory.hpp:77] Creating layer Convolution46
I0929 09:26:46.213714  1584 net.cpp:84] Creating Layer Convolution46
I0929 09:26:46.213716  1584 net.cpp:406] Convolution46 <- Eltwise21_M2PELU43_0_split_0
I0929 09:26:46.213721  1584 net.cpp:380] Convolution46 -> Convolution46
I0929 09:26:46.213800  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:46.215437  1584 net.cpp:122] Setting up Convolution46
I0929 09:26:46.215446  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.215448  1584 net.cpp:137] Memory required for data: 1084212400
I0929 09:26:46.215453  1584 layer_factory.hpp:77] Creating layer BatchNorm46
I0929 09:26:46.215466  1584 net.cpp:84] Creating Layer BatchNorm46
I0929 09:26:46.215468  1584 net.cpp:406] BatchNorm46 <- Convolution46
I0929 09:26:46.215472  1584 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I0929 09:26:46.215610  1584 net.cpp:122] Setting up BatchNorm46
I0929 09:26:46.215615  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.215616  1584 net.cpp:137] Memory required for data: 1085850800
I0929 09:26:46.215620  1584 layer_factory.hpp:77] Creating layer Scale46
I0929 09:26:46.215626  1584 net.cpp:84] Creating Layer Scale46
I0929 09:26:46.215628  1584 net.cpp:406] Scale46 <- Convolution46
I0929 09:26:46.215631  1584 net.cpp:367] Scale46 -> Convolution46 (in-place)
I0929 09:26:46.215657  1584 layer_factory.hpp:77] Creating layer Scale46
I0929 09:26:46.215736  1584 net.cpp:122] Setting up Scale46
I0929 09:26:46.215741  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.215744  1584 net.cpp:137] Memory required for data: 1087489200
I0929 09:26:46.215747  1584 layer_factory.hpp:77] Creating layer M2PELU44
I0929 09:26:46.215752  1584 net.cpp:84] Creating Layer M2PELU44
I0929 09:26:46.215754  1584 net.cpp:406] M2PELU44 <- Convolution46
I0929 09:26:46.215759  1584 net.cpp:367] M2PELU44 -> Convolution46 (in-place)
I0929 09:26:46.215843  1584 net.cpp:122] Setting up M2PELU44
I0929 09:26:46.215848  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.215850  1584 net.cpp:137] Memory required for data: 1089127600
I0929 09:26:46.215854  1584 layer_factory.hpp:77] Creating layer Convolution47
I0929 09:26:46.215859  1584 net.cpp:84] Creating Layer Convolution47
I0929 09:26:46.215862  1584 net.cpp:406] Convolution47 <- Convolution46
I0929 09:26:46.215867  1584 net.cpp:380] Convolution47 -> Convolution47
I0929 09:26:46.215946  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:46.217551  1584 net.cpp:122] Setting up Convolution47
I0929 09:26:46.217561  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.217564  1584 net.cpp:137] Memory required for data: 1090766000
I0929 09:26:46.217568  1584 layer_factory.hpp:77] Creating layer BatchNorm47
I0929 09:26:46.217573  1584 net.cpp:84] Creating Layer BatchNorm47
I0929 09:26:46.217576  1584 net.cpp:406] BatchNorm47 <- Convolution47
I0929 09:26:46.217581  1584 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I0929 09:26:46.217710  1584 net.cpp:122] Setting up BatchNorm47
I0929 09:26:46.217715  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.217716  1584 net.cpp:137] Memory required for data: 1092404400
I0929 09:26:46.217721  1584 layer_factory.hpp:77] Creating layer Scale47
I0929 09:26:46.217725  1584 net.cpp:84] Creating Layer Scale47
I0929 09:26:46.217727  1584 net.cpp:406] Scale47 <- Convolution47
I0929 09:26:46.217731  1584 net.cpp:367] Scale47 -> Convolution47 (in-place)
I0929 09:26:46.217757  1584 layer_factory.hpp:77] Creating layer Scale47
I0929 09:26:46.217831  1584 net.cpp:122] Setting up Scale47
I0929 09:26:46.234325  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.234333  1584 net.cpp:137] Memory required for data: 1094042800
I0929 09:26:46.234338  1584 layer_factory.hpp:77] Creating layer Eltwise22
I0929 09:26:46.234342  1584 net.cpp:84] Creating Layer Eltwise22
I0929 09:26:46.234345  1584 net.cpp:406] Eltwise22 <- Eltwise21_M2PELU43_0_split_1
I0929 09:26:46.234349  1584 net.cpp:406] Eltwise22 <- Convolution47
I0929 09:26:46.234355  1584 net.cpp:380] Eltwise22 -> Eltwise22
I0929 09:26:46.234380  1584 net.cpp:122] Setting up Eltwise22
I0929 09:26:46.234386  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.234388  1584 net.cpp:137] Memory required for data: 1095681200
I0929 09:26:46.234390  1584 layer_factory.hpp:77] Creating layer M2PELU45
I0929 09:26:46.234395  1584 net.cpp:84] Creating Layer M2PELU45
I0929 09:26:46.234398  1584 net.cpp:406] M2PELU45 <- Eltwise22
I0929 09:26:46.234402  1584 net.cpp:367] M2PELU45 -> Eltwise22 (in-place)
I0929 09:26:46.234508  1584 net.cpp:122] Setting up M2PELU45
I0929 09:26:46.234513  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.234529  1584 net.cpp:137] Memory required for data: 1097319600
I0929 09:26:46.234534  1584 layer_factory.hpp:77] Creating layer Eltwise22_M2PELU45_0_split
I0929 09:26:46.234539  1584 net.cpp:84] Creating Layer Eltwise22_M2PELU45_0_split
I0929 09:26:46.234540  1584 net.cpp:406] Eltwise22_M2PELU45_0_split <- Eltwise22
I0929 09:26:46.234545  1584 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_0
I0929 09:26:46.234550  1584 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_1
I0929 09:26:46.234578  1584 net.cpp:122] Setting up Eltwise22_M2PELU45_0_split
I0929 09:26:46.234582  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.234586  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.234588  1584 net.cpp:137] Memory required for data: 1100596400
I0929 09:26:46.234591  1584 layer_factory.hpp:77] Creating layer Convolution48
I0929 09:26:46.234598  1584 net.cpp:84] Creating Layer Convolution48
I0929 09:26:46.234601  1584 net.cpp:406] Convolution48 <- Eltwise22_M2PELU45_0_split_0
I0929 09:26:46.234606  1584 net.cpp:380] Convolution48 -> Convolution48
I0929 09:26:46.234695  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:46.237398  1584 net.cpp:122] Setting up Convolution48
I0929 09:26:46.237407  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.237411  1584 net.cpp:137] Memory required for data: 1102234800
I0929 09:26:46.237416  1584 layer_factory.hpp:77] Creating layer BatchNorm48
I0929 09:26:46.237421  1584 net.cpp:84] Creating Layer BatchNorm48
I0929 09:26:46.237423  1584 net.cpp:406] BatchNorm48 <- Convolution48
I0929 09:26:46.237428  1584 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I0929 09:26:46.237571  1584 net.cpp:122] Setting up BatchNorm48
I0929 09:26:46.237574  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.237577  1584 net.cpp:137] Memory required for data: 1103873200
I0929 09:26:46.237581  1584 layer_factory.hpp:77] Creating layer Scale48
I0929 09:26:46.237586  1584 net.cpp:84] Creating Layer Scale48
I0929 09:26:46.237588  1584 net.cpp:406] Scale48 <- Convolution48
I0929 09:26:46.237591  1584 net.cpp:367] Scale48 -> Convolution48 (in-place)
I0929 09:26:46.237619  1584 layer_factory.hpp:77] Creating layer Scale48
I0929 09:26:46.237699  1584 net.cpp:122] Setting up Scale48
I0929 09:26:46.237702  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.237704  1584 net.cpp:137] Memory required for data: 1105511600
I0929 09:26:46.237709  1584 layer_factory.hpp:77] Creating layer M2PELU46
I0929 09:26:46.237713  1584 net.cpp:84] Creating Layer M2PELU46
I0929 09:26:46.237715  1584 net.cpp:406] M2PELU46 <- Convolution48
I0929 09:26:46.237720  1584 net.cpp:367] M2PELU46 -> Convolution48 (in-place)
I0929 09:26:46.237810  1584 net.cpp:122] Setting up M2PELU46
I0929 09:26:46.237814  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.237817  1584 net.cpp:137] Memory required for data: 1107150000
I0929 09:26:46.237820  1584 layer_factory.hpp:77] Creating layer Convolution49
I0929 09:26:46.237829  1584 net.cpp:84] Creating Layer Convolution49
I0929 09:26:46.237831  1584 net.cpp:406] Convolution49 <- Convolution48
I0929 09:26:46.237835  1584 net.cpp:380] Convolution49 -> Convolution49
I0929 09:26:46.237931  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:46.240048  1584 net.cpp:122] Setting up Convolution49
I0929 09:26:46.240058  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.240061  1584 net.cpp:137] Memory required for data: 1108788400
I0929 09:26:46.240065  1584 layer_factory.hpp:77] Creating layer BatchNorm49
I0929 09:26:46.240069  1584 net.cpp:84] Creating Layer BatchNorm49
I0929 09:26:46.240072  1584 net.cpp:406] BatchNorm49 <- Convolution49
I0929 09:26:46.240077  1584 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I0929 09:26:46.240211  1584 net.cpp:122] Setting up BatchNorm49
I0929 09:26:46.240216  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.240224  1584 net.cpp:137] Memory required for data: 1110426800
I0929 09:26:46.240231  1584 layer_factory.hpp:77] Creating layer Scale49
I0929 09:26:46.240234  1584 net.cpp:84] Creating Layer Scale49
I0929 09:26:46.240236  1584 net.cpp:406] Scale49 <- Convolution49
I0929 09:26:46.240241  1584 net.cpp:367] Scale49 -> Convolution49 (in-place)
I0929 09:26:46.240268  1584 layer_factory.hpp:77] Creating layer Scale49
I0929 09:26:46.240348  1584 net.cpp:122] Setting up Scale49
I0929 09:26:46.240352  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.240355  1584 net.cpp:137] Memory required for data: 1112065200
I0929 09:26:46.240358  1584 layer_factory.hpp:77] Creating layer Eltwise23
I0929 09:26:46.240362  1584 net.cpp:84] Creating Layer Eltwise23
I0929 09:26:46.240365  1584 net.cpp:406] Eltwise23 <- Eltwise22_M2PELU45_0_split_1
I0929 09:26:46.240368  1584 net.cpp:406] Eltwise23 <- Convolution49
I0929 09:26:46.240371  1584 net.cpp:380] Eltwise23 -> Eltwise23
I0929 09:26:46.240388  1584 net.cpp:122] Setting up Eltwise23
I0929 09:26:46.240392  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.240394  1584 net.cpp:137] Memory required for data: 1113703600
I0929 09:26:46.240396  1584 layer_factory.hpp:77] Creating layer M2PELU47
I0929 09:26:46.240401  1584 net.cpp:84] Creating Layer M2PELU47
I0929 09:26:46.240403  1584 net.cpp:406] M2PELU47 <- Eltwise23
I0929 09:26:46.240406  1584 net.cpp:367] M2PELU47 -> Eltwise23 (in-place)
I0929 09:26:46.240499  1584 net.cpp:122] Setting up M2PELU47
I0929 09:26:46.240504  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.240505  1584 net.cpp:137] Memory required for data: 1115342000
I0929 09:26:46.240509  1584 layer_factory.hpp:77] Creating layer Eltwise23_M2PELU47_0_split
I0929 09:26:46.240512  1584 net.cpp:84] Creating Layer Eltwise23_M2PELU47_0_split
I0929 09:26:46.240515  1584 net.cpp:406] Eltwise23_M2PELU47_0_split <- Eltwise23
I0929 09:26:46.240519  1584 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_0
I0929 09:26:46.240522  1584 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_1
I0929 09:26:46.240546  1584 net.cpp:122] Setting up Eltwise23_M2PELU47_0_split
I0929 09:26:46.240550  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.240552  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.240555  1584 net.cpp:137] Memory required for data: 1118618800
I0929 09:26:46.240556  1584 layer_factory.hpp:77] Creating layer Convolution50
I0929 09:26:46.240563  1584 net.cpp:84] Creating Layer Convolution50
I0929 09:26:46.240566  1584 net.cpp:406] Convolution50 <- Eltwise23_M2PELU47_0_split_0
I0929 09:26:46.240569  1584 net.cpp:380] Convolution50 -> Convolution50
I0929 09:26:46.240651  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:46.243116  1584 net.cpp:122] Setting up Convolution50
I0929 09:26:46.243125  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.243129  1584 net.cpp:137] Memory required for data: 1120257200
I0929 09:26:46.243134  1584 layer_factory.hpp:77] Creating layer BatchNorm50
I0929 09:26:46.243139  1584 net.cpp:84] Creating Layer BatchNorm50
I0929 09:26:46.243141  1584 net.cpp:406] BatchNorm50 <- Convolution50
I0929 09:26:46.243145  1584 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I0929 09:26:46.243284  1584 net.cpp:122] Setting up BatchNorm50
I0929 09:26:46.243288  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.243290  1584 net.cpp:137] Memory required for data: 1121895600
I0929 09:26:46.243295  1584 layer_factory.hpp:77] Creating layer Scale50
I0929 09:26:46.243299  1584 net.cpp:84] Creating Layer Scale50
I0929 09:26:46.243301  1584 net.cpp:406] Scale50 <- Convolution50
I0929 09:26:46.243304  1584 net.cpp:367] Scale50 -> Convolution50 (in-place)
I0929 09:26:46.243333  1584 layer_factory.hpp:77] Creating layer Scale50
I0929 09:26:46.243410  1584 net.cpp:122] Setting up Scale50
I0929 09:26:46.243414  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.243417  1584 net.cpp:137] Memory required for data: 1123534000
I0929 09:26:46.243427  1584 layer_factory.hpp:77] Creating layer M2PELU48
I0929 09:26:46.243433  1584 net.cpp:84] Creating Layer M2PELU48
I0929 09:26:46.243436  1584 net.cpp:406] M2PELU48 <- Convolution50
I0929 09:26:46.243439  1584 net.cpp:367] M2PELU48 -> Convolution50 (in-place)
I0929 09:26:46.243531  1584 net.cpp:122] Setting up M2PELU48
I0929 09:26:46.243535  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.243537  1584 net.cpp:137] Memory required for data: 1125172400
I0929 09:26:46.243541  1584 layer_factory.hpp:77] Creating layer Convolution51
I0929 09:26:46.243548  1584 net.cpp:84] Creating Layer Convolution51
I0929 09:26:46.243551  1584 net.cpp:406] Convolution51 <- Convolution50
I0929 09:26:46.243556  1584 net.cpp:380] Convolution51 -> Convolution51
I0929 09:26:46.243638  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:46.245251  1584 net.cpp:122] Setting up Convolution51
I0929 09:26:46.245260  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.245262  1584 net.cpp:137] Memory required for data: 1126810800
I0929 09:26:46.245266  1584 layer_factory.hpp:77] Creating layer BatchNorm51
I0929 09:26:46.245273  1584 net.cpp:84] Creating Layer BatchNorm51
I0929 09:26:46.245276  1584 net.cpp:406] BatchNorm51 <- Convolution51
I0929 09:26:46.245280  1584 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I0929 09:26:46.245416  1584 net.cpp:122] Setting up BatchNorm51
I0929 09:26:46.245420  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.245422  1584 net.cpp:137] Memory required for data: 1128449200
I0929 09:26:46.245427  1584 layer_factory.hpp:77] Creating layer Scale51
I0929 09:26:46.245432  1584 net.cpp:84] Creating Layer Scale51
I0929 09:26:46.245434  1584 net.cpp:406] Scale51 <- Convolution51
I0929 09:26:46.245437  1584 net.cpp:367] Scale51 -> Convolution51 (in-place)
I0929 09:26:46.245465  1584 layer_factory.hpp:77] Creating layer Scale51
I0929 09:26:46.245543  1584 net.cpp:122] Setting up Scale51
I0929 09:26:46.245548  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.245548  1584 net.cpp:137] Memory required for data: 1130087600
I0929 09:26:46.245553  1584 layer_factory.hpp:77] Creating layer Eltwise24
I0929 09:26:46.245558  1584 net.cpp:84] Creating Layer Eltwise24
I0929 09:26:46.245560  1584 net.cpp:406] Eltwise24 <- Eltwise23_M2PELU47_0_split_1
I0929 09:26:46.245563  1584 net.cpp:406] Eltwise24 <- Convolution51
I0929 09:26:46.245566  1584 net.cpp:380] Eltwise24 -> Eltwise24
I0929 09:26:46.245582  1584 net.cpp:122] Setting up Eltwise24
I0929 09:26:46.245586  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.245589  1584 net.cpp:137] Memory required for data: 1131726000
I0929 09:26:46.245590  1584 layer_factory.hpp:77] Creating layer M2PELU49
I0929 09:26:46.245594  1584 net.cpp:84] Creating Layer M2PELU49
I0929 09:26:46.245596  1584 net.cpp:406] M2PELU49 <- Eltwise24
I0929 09:26:46.245600  1584 net.cpp:367] M2PELU49 -> Eltwise24 (in-place)
I0929 09:26:46.245690  1584 net.cpp:122] Setting up M2PELU49
I0929 09:26:46.245694  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.245697  1584 net.cpp:137] Memory required for data: 1133364400
I0929 09:26:46.245700  1584 layer_factory.hpp:77] Creating layer Eltwise24_M2PELU49_0_split
I0929 09:26:46.245704  1584 net.cpp:84] Creating Layer Eltwise24_M2PELU49_0_split
I0929 09:26:46.245707  1584 net.cpp:406] Eltwise24_M2PELU49_0_split <- Eltwise24
I0929 09:26:46.245710  1584 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_0
I0929 09:26:46.245714  1584 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_1
I0929 09:26:46.245750  1584 net.cpp:122] Setting up Eltwise24_M2PELU49_0_split
I0929 09:26:46.245754  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.245759  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.245760  1584 net.cpp:137] Memory required for data: 1136641200
I0929 09:26:46.245764  1584 layer_factory.hpp:77] Creating layer Convolution52
I0929 09:26:46.245774  1584 net.cpp:84] Creating Layer Convolution52
I0929 09:26:46.245777  1584 net.cpp:406] Convolution52 <- Eltwise24_M2PELU49_0_split_0
I0929 09:26:46.245782  1584 net.cpp:380] Convolution52 -> Convolution52
I0929 09:26:46.245867  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:46.247815  1584 net.cpp:122] Setting up Convolution52
I0929 09:26:46.247824  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.247826  1584 net.cpp:137] Memory required for data: 1138279600
I0929 09:26:46.247831  1584 layer_factory.hpp:77] Creating layer BatchNorm52
I0929 09:26:46.247836  1584 net.cpp:84] Creating Layer BatchNorm52
I0929 09:26:46.247839  1584 net.cpp:406] BatchNorm52 <- Convolution52
I0929 09:26:46.247843  1584 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I0929 09:26:46.247987  1584 net.cpp:122] Setting up BatchNorm52
I0929 09:26:46.247990  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.247992  1584 net.cpp:137] Memory required for data: 1139918000
I0929 09:26:46.247997  1584 layer_factory.hpp:77] Creating layer Scale52
I0929 09:26:46.248001  1584 net.cpp:84] Creating Layer Scale52
I0929 09:26:46.248004  1584 net.cpp:406] Scale52 <- Convolution52
I0929 09:26:46.248008  1584 net.cpp:367] Scale52 -> Convolution52 (in-place)
I0929 09:26:46.248034  1584 layer_factory.hpp:77] Creating layer Scale52
I0929 09:26:46.248114  1584 net.cpp:122] Setting up Scale52
I0929 09:26:46.248119  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.248121  1584 net.cpp:137] Memory required for data: 1141556400
I0929 09:26:46.248126  1584 layer_factory.hpp:77] Creating layer M2PELU50
I0929 09:26:46.248153  1584 net.cpp:84] Creating Layer M2PELU50
I0929 09:26:46.248157  1584 net.cpp:406] M2PELU50 <- Convolution52
I0929 09:26:46.248160  1584 net.cpp:367] M2PELU50 -> Convolution52 (in-place)
I0929 09:26:46.248255  1584 net.cpp:122] Setting up M2PELU50
I0929 09:26:46.248258  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.248260  1584 net.cpp:137] Memory required for data: 1143194800
I0929 09:26:46.248265  1584 layer_factory.hpp:77] Creating layer Convolution53
I0929 09:26:46.248270  1584 net.cpp:84] Creating Layer Convolution53
I0929 09:26:46.248273  1584 net.cpp:406] Convolution53 <- Convolution52
I0929 09:26:46.248277  1584 net.cpp:380] Convolution53 -> Convolution53
I0929 09:26:46.248365  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:46.249994  1584 net.cpp:122] Setting up Convolution53
I0929 09:26:46.250002  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.250005  1584 net.cpp:137] Memory required for data: 1144833200
I0929 09:26:46.250010  1584 layer_factory.hpp:77] Creating layer BatchNorm53
I0929 09:26:46.250015  1584 net.cpp:84] Creating Layer BatchNorm53
I0929 09:26:46.250018  1584 net.cpp:406] BatchNorm53 <- Convolution53
I0929 09:26:46.250022  1584 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I0929 09:26:46.265321  1584 net.cpp:122] Setting up BatchNorm53
I0929 09:26:46.265329  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.265332  1584 net.cpp:137] Memory required for data: 1146471600
I0929 09:26:46.265338  1584 layer_factory.hpp:77] Creating layer Scale53
I0929 09:26:46.265344  1584 net.cpp:84] Creating Layer Scale53
I0929 09:26:46.265347  1584 net.cpp:406] Scale53 <- Convolution53
I0929 09:26:46.265352  1584 net.cpp:367] Scale53 -> Convolution53 (in-place)
I0929 09:26:46.265383  1584 layer_factory.hpp:77] Creating layer Scale53
I0929 09:26:46.265470  1584 net.cpp:122] Setting up Scale53
I0929 09:26:46.265475  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.265477  1584 net.cpp:137] Memory required for data: 1148110000
I0929 09:26:46.265481  1584 layer_factory.hpp:77] Creating layer Eltwise25
I0929 09:26:46.265486  1584 net.cpp:84] Creating Layer Eltwise25
I0929 09:26:46.265489  1584 net.cpp:406] Eltwise25 <- Eltwise24_M2PELU49_0_split_1
I0929 09:26:46.265493  1584 net.cpp:406] Eltwise25 <- Convolution53
I0929 09:26:46.265496  1584 net.cpp:380] Eltwise25 -> Eltwise25
I0929 09:26:46.265524  1584 net.cpp:122] Setting up Eltwise25
I0929 09:26:46.265529  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.265532  1584 net.cpp:137] Memory required for data: 1149748400
I0929 09:26:46.265533  1584 layer_factory.hpp:77] Creating layer M2PELU51
I0929 09:26:46.265538  1584 net.cpp:84] Creating Layer M2PELU51
I0929 09:26:46.265542  1584 net.cpp:406] M2PELU51 <- Eltwise25
I0929 09:26:46.265545  1584 net.cpp:367] M2PELU51 -> Eltwise25 (in-place)
I0929 09:26:46.265647  1584 net.cpp:122] Setting up M2PELU51
I0929 09:26:46.265652  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.265655  1584 net.cpp:137] Memory required for data: 1151386800
I0929 09:26:46.265658  1584 layer_factory.hpp:77] Creating layer Eltwise25_M2PELU51_0_split
I0929 09:26:46.265663  1584 net.cpp:84] Creating Layer Eltwise25_M2PELU51_0_split
I0929 09:26:46.265666  1584 net.cpp:406] Eltwise25_M2PELU51_0_split <- Eltwise25
I0929 09:26:46.265669  1584 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_0
I0929 09:26:46.265673  1584 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_1
I0929 09:26:46.265700  1584 net.cpp:122] Setting up Eltwise25_M2PELU51_0_split
I0929 09:26:46.265704  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.265707  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.265709  1584 net.cpp:137] Memory required for data: 1154663600
I0929 09:26:46.265712  1584 layer_factory.hpp:77] Creating layer Convolution54
I0929 09:26:46.265718  1584 net.cpp:84] Creating Layer Convolution54
I0929 09:26:46.265720  1584 net.cpp:406] Convolution54 <- Eltwise25_M2PELU51_0_split_0
I0929 09:26:46.265727  1584 net.cpp:380] Convolution54 -> Convolution54
I0929 09:26:46.265820  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:46.268250  1584 net.cpp:122] Setting up Convolution54
I0929 09:26:46.268260  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.268262  1584 net.cpp:137] Memory required for data: 1156302000
I0929 09:26:46.268267  1584 layer_factory.hpp:77] Creating layer BatchNorm54
I0929 09:26:46.268273  1584 net.cpp:84] Creating Layer BatchNorm54
I0929 09:26:46.268276  1584 net.cpp:406] BatchNorm54 <- Convolution54
I0929 09:26:46.268280  1584 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I0929 09:26:46.268429  1584 net.cpp:122] Setting up BatchNorm54
I0929 09:26:46.268434  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.268435  1584 net.cpp:137] Memory required for data: 1157940400
I0929 09:26:46.268440  1584 layer_factory.hpp:77] Creating layer Scale54
I0929 09:26:46.268445  1584 net.cpp:84] Creating Layer Scale54
I0929 09:26:46.268448  1584 net.cpp:406] Scale54 <- Convolution54
I0929 09:26:46.268451  1584 net.cpp:367] Scale54 -> Convolution54 (in-place)
I0929 09:26:46.268481  1584 layer_factory.hpp:77] Creating layer Scale54
I0929 09:26:46.268563  1584 net.cpp:122] Setting up Scale54
I0929 09:26:46.268568  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.268569  1584 net.cpp:137] Memory required for data: 1159578800
I0929 09:26:46.268573  1584 layer_factory.hpp:77] Creating layer M2PELU52
I0929 09:26:46.268579  1584 net.cpp:84] Creating Layer M2PELU52
I0929 09:26:46.268580  1584 net.cpp:406] M2PELU52 <- Convolution54
I0929 09:26:46.268584  1584 net.cpp:367] M2PELU52 -> Convolution54 (in-place)
I0929 09:26:46.268676  1584 net.cpp:122] Setting up M2PELU52
I0929 09:26:46.268682  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.268683  1584 net.cpp:137] Memory required for data: 1161217200
I0929 09:26:46.268687  1584 layer_factory.hpp:77] Creating layer Convolution55
I0929 09:26:46.268693  1584 net.cpp:84] Creating Layer Convolution55
I0929 09:26:46.268697  1584 net.cpp:406] Convolution55 <- Convolution54
I0929 09:26:46.268700  1584 net.cpp:380] Convolution55 -> Convolution55
I0929 09:26:46.268815  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:46.270606  1584 net.cpp:122] Setting up Convolution55
I0929 09:26:46.270623  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.270627  1584 net.cpp:137] Memory required for data: 1162855600
I0929 09:26:46.270632  1584 layer_factory.hpp:77] Creating layer BatchNorm55
I0929 09:26:46.270637  1584 net.cpp:84] Creating Layer BatchNorm55
I0929 09:26:46.270639  1584 net.cpp:406] BatchNorm55 <- Convolution55
I0929 09:26:46.270643  1584 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I0929 09:26:46.270787  1584 net.cpp:122] Setting up BatchNorm55
I0929 09:26:46.270792  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.270794  1584 net.cpp:137] Memory required for data: 1164494000
I0929 09:26:46.270798  1584 layer_factory.hpp:77] Creating layer Scale55
I0929 09:26:46.270802  1584 net.cpp:84] Creating Layer Scale55
I0929 09:26:46.270805  1584 net.cpp:406] Scale55 <- Convolution55
I0929 09:26:46.270808  1584 net.cpp:367] Scale55 -> Convolution55 (in-place)
I0929 09:26:46.270838  1584 layer_factory.hpp:77] Creating layer Scale55
I0929 09:26:46.270927  1584 net.cpp:122] Setting up Scale55
I0929 09:26:46.270931  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.270933  1584 net.cpp:137] Memory required for data: 1166132400
I0929 09:26:46.270937  1584 layer_factory.hpp:77] Creating layer Eltwise26
I0929 09:26:46.270941  1584 net.cpp:84] Creating Layer Eltwise26
I0929 09:26:46.270944  1584 net.cpp:406] Eltwise26 <- Eltwise25_M2PELU51_0_split_1
I0929 09:26:46.270947  1584 net.cpp:406] Eltwise26 <- Convolution55
I0929 09:26:46.270951  1584 net.cpp:380] Eltwise26 -> Eltwise26
I0929 09:26:46.270967  1584 net.cpp:122] Setting up Eltwise26
I0929 09:26:46.270972  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.270973  1584 net.cpp:137] Memory required for data: 1167770800
I0929 09:26:46.270975  1584 layer_factory.hpp:77] Creating layer M2PELU53
I0929 09:26:46.270980  1584 net.cpp:84] Creating Layer M2PELU53
I0929 09:26:46.270982  1584 net.cpp:406] M2PELU53 <- Eltwise26
I0929 09:26:46.270987  1584 net.cpp:367] M2PELU53 -> Eltwise26 (in-place)
I0929 09:26:46.271078  1584 net.cpp:122] Setting up M2PELU53
I0929 09:26:46.271083  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.271085  1584 net.cpp:137] Memory required for data: 1169409200
I0929 09:26:46.271088  1584 layer_factory.hpp:77] Creating layer Eltwise26_M2PELU53_0_split
I0929 09:26:46.271092  1584 net.cpp:84] Creating Layer Eltwise26_M2PELU53_0_split
I0929 09:26:46.271095  1584 net.cpp:406] Eltwise26_M2PELU53_0_split <- Eltwise26
I0929 09:26:46.271098  1584 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_0
I0929 09:26:46.271102  1584 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_1
I0929 09:26:46.271126  1584 net.cpp:122] Setting up Eltwise26_M2PELU53_0_split
I0929 09:26:46.271129  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.271132  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.271134  1584 net.cpp:137] Memory required for data: 1172686000
I0929 09:26:46.271136  1584 layer_factory.hpp:77] Creating layer Convolution56
I0929 09:26:46.271143  1584 net.cpp:84] Creating Layer Convolution56
I0929 09:26:46.271145  1584 net.cpp:406] Convolution56 <- Eltwise26_M2PELU53_0_split_0
I0929 09:26:46.271149  1584 net.cpp:380] Convolution56 -> Convolution56
I0929 09:26:46.271232  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:46.272835  1584 net.cpp:122] Setting up Convolution56
I0929 09:26:46.272843  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.272846  1584 net.cpp:137] Memory required for data: 1174324400
I0929 09:26:46.272851  1584 layer_factory.hpp:77] Creating layer BatchNorm56
I0929 09:26:46.272856  1584 net.cpp:84] Creating Layer BatchNorm56
I0929 09:26:46.272860  1584 net.cpp:406] BatchNorm56 <- Convolution56
I0929 09:26:46.272863  1584 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I0929 09:26:46.273010  1584 net.cpp:122] Setting up BatchNorm56
I0929 09:26:46.273015  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.273022  1584 net.cpp:137] Memory required for data: 1175962800
I0929 09:26:46.273027  1584 layer_factory.hpp:77] Creating layer Scale56
I0929 09:26:46.273032  1584 net.cpp:84] Creating Layer Scale56
I0929 09:26:46.273035  1584 net.cpp:406] Scale56 <- Convolution56
I0929 09:26:46.273037  1584 net.cpp:367] Scale56 -> Convolution56 (in-place)
I0929 09:26:46.273066  1584 layer_factory.hpp:77] Creating layer Scale56
I0929 09:26:46.273149  1584 net.cpp:122] Setting up Scale56
I0929 09:26:46.273152  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.273154  1584 net.cpp:137] Memory required for data: 1177601200
I0929 09:26:46.273157  1584 layer_factory.hpp:77] Creating layer M2PELU54
I0929 09:26:46.273164  1584 net.cpp:84] Creating Layer M2PELU54
I0929 09:26:46.273165  1584 net.cpp:406] M2PELU54 <- Convolution56
I0929 09:26:46.273169  1584 net.cpp:367] M2PELU54 -> Convolution56 (in-place)
I0929 09:26:46.273259  1584 net.cpp:122] Setting up M2PELU54
I0929 09:26:46.273263  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.273265  1584 net.cpp:137] Memory required for data: 1179239600
I0929 09:26:46.273269  1584 layer_factory.hpp:77] Creating layer Convolution57
I0929 09:26:46.273275  1584 net.cpp:84] Creating Layer Convolution57
I0929 09:26:46.273278  1584 net.cpp:406] Convolution57 <- Convolution56
I0929 09:26:46.273281  1584 net.cpp:380] Convolution57 -> Convolution57
I0929 09:26:46.273368  1584 filler.hpp:251] The std of weights in this layer is: 0.0571662
I0929 09:26:46.274977  1584 net.cpp:122] Setting up Convolution57
I0929 09:26:46.274986  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.274989  1584 net.cpp:137] Memory required for data: 1180878000
I0929 09:26:46.274993  1584 layer_factory.hpp:77] Creating layer BatchNorm57
I0929 09:26:46.274998  1584 net.cpp:84] Creating Layer BatchNorm57
I0929 09:26:46.275001  1584 net.cpp:406] BatchNorm57 <- Convolution57
I0929 09:26:46.275007  1584 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I0929 09:26:46.275147  1584 net.cpp:122] Setting up BatchNorm57
I0929 09:26:46.275151  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.275153  1584 net.cpp:137] Memory required for data: 1182516400
I0929 09:26:46.275158  1584 layer_factory.hpp:77] Creating layer Scale57
I0929 09:26:46.275162  1584 net.cpp:84] Creating Layer Scale57
I0929 09:26:46.275164  1584 net.cpp:406] Scale57 <- Convolution57
I0929 09:26:46.275168  1584 net.cpp:367] Scale57 -> Convolution57 (in-place)
I0929 09:26:46.275195  1584 layer_factory.hpp:77] Creating layer Scale57
I0929 09:26:46.275276  1584 net.cpp:122] Setting up Scale57
I0929 09:26:46.275280  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.275282  1584 net.cpp:137] Memory required for data: 1184154800
I0929 09:26:46.275285  1584 layer_factory.hpp:77] Creating layer Eltwise27
I0929 09:26:46.275290  1584 net.cpp:84] Creating Layer Eltwise27
I0929 09:26:46.275292  1584 net.cpp:406] Eltwise27 <- Eltwise26_M2PELU53_0_split_1
I0929 09:26:46.275295  1584 net.cpp:406] Eltwise27 <- Convolution57
I0929 09:26:46.275300  1584 net.cpp:380] Eltwise27 -> Eltwise27
I0929 09:26:46.275315  1584 net.cpp:122] Setting up Eltwise27
I0929 09:26:46.275319  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.275321  1584 net.cpp:137] Memory required for data: 1185793200
I0929 09:26:46.275323  1584 layer_factory.hpp:77] Creating layer M2PELU55
I0929 09:26:46.275328  1584 net.cpp:84] Creating Layer M2PELU55
I0929 09:26:46.275331  1584 net.cpp:406] M2PELU55 <- Eltwise27
I0929 09:26:46.275334  1584 net.cpp:367] M2PELU55 -> Eltwise27 (in-place)
I0929 09:26:46.275426  1584 net.cpp:122] Setting up M2PELU55
I0929 09:26:46.275430  1584 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 09:26:46.275432  1584 net.cpp:137] Memory required for data: 1187431600
I0929 09:26:46.275435  1584 layer_factory.hpp:77] Creating layer Pooling1
I0929 09:26:46.275440  1584 net.cpp:84] Creating Layer Pooling1
I0929 09:26:46.275444  1584 net.cpp:406] Pooling1 <- Eltwise27
I0929 09:26:46.275446  1584 net.cpp:380] Pooling1 -> Pooling1
I0929 09:26:46.275928  1584 net.cpp:122] Setting up Pooling1
I0929 09:26:46.275935  1584 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0929 09:26:46.275938  1584 net.cpp:137] Memory required for data: 1187457200
I0929 09:26:46.275940  1584 layer_factory.hpp:77] Creating layer InnerProduct1
I0929 09:26:46.275946  1584 net.cpp:84] Creating Layer InnerProduct1
I0929 09:26:46.275949  1584 net.cpp:406] InnerProduct1 <- Pooling1
I0929 09:26:46.275954  1584 net.cpp:380] InnerProduct1 -> InnerProduct1
I0929 09:26:46.276059  1584 net.cpp:122] Setting up InnerProduct1
I0929 09:26:46.276064  1584 net.cpp:129] Top shape: 100 10 (1000)
I0929 09:26:46.276067  1584 net.cpp:137] Memory required for data: 1187461200
I0929 09:26:46.276070  1584 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0929 09:26:46.276074  1584 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I0929 09:26:46.276077  1584 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0929 09:26:46.276080  1584 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0929 09:26:46.276085  1584 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0929 09:26:46.276110  1584 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I0929 09:26:46.276114  1584 net.cpp:129] Top shape: 100 10 (1000)
I0929 09:26:46.276116  1584 net.cpp:129] Top shape: 100 10 (1000)
I0929 09:26:46.276118  1584 net.cpp:137] Memory required for data: 1187469200
I0929 09:26:46.276120  1584 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0929 09:26:46.276124  1584 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0929 09:26:46.276126  1584 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I0929 09:26:46.276129  1584 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I0929 09:26:46.276132  1584 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0929 09:26:46.276137  1584 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0929 09:26:46.276334  1584 net.cpp:122] Setting up SoftmaxWithLoss1
I0929 09:26:46.276340  1584 net.cpp:129] Top shape: (1)
I0929 09:26:46.276342  1584 net.cpp:132]     with loss weight 1
I0929 09:26:46.276346  1584 net.cpp:137] Memory required for data: 1187469204
I0929 09:26:46.276348  1584 layer_factory.hpp:77] Creating layer Accuracy1
I0929 09:26:46.276353  1584 net.cpp:84] Creating Layer Accuracy1
I0929 09:26:46.276355  1584 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I0929 09:26:46.276358  1584 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I0929 09:26:46.276362  1584 net.cpp:380] Accuracy1 -> Accuracy1
I0929 09:26:46.276367  1584 net.cpp:122] Setting up Accuracy1
I0929 09:26:46.276371  1584 net.cpp:129] Top shape: (1)
I0929 09:26:46.276372  1584 net.cpp:137] Memory required for data: 1187469208
I0929 09:26:46.295964  1584 net.cpp:200] Accuracy1 does not need backward computation.
I0929 09:26:46.295972  1584 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0929 09:26:46.295975  1584 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0929 09:26:46.295979  1584 net.cpp:198] InnerProduct1 needs backward computation.
I0929 09:26:46.295981  1584 net.cpp:198] Pooling1 needs backward computation.
I0929 09:26:46.295984  1584 net.cpp:198] M2PELU55 needs backward computation.
I0929 09:26:46.295985  1584 net.cpp:198] Eltwise27 needs backward computation.
I0929 09:26:46.295989  1584 net.cpp:198] Scale57 needs backward computation.
I0929 09:26:46.295990  1584 net.cpp:198] BatchNorm57 needs backward computation.
I0929 09:26:46.295992  1584 net.cpp:198] Convolution57 needs backward computation.
I0929 09:26:46.295995  1584 net.cpp:198] M2PELU54 needs backward computation.
I0929 09:26:46.295997  1584 net.cpp:198] Scale56 needs backward computation.
I0929 09:26:46.296000  1584 net.cpp:198] BatchNorm56 needs backward computation.
I0929 09:26:46.296001  1584 net.cpp:198] Convolution56 needs backward computation.
I0929 09:26:46.296005  1584 net.cpp:198] Eltwise26_M2PELU53_0_split needs backward computation.
I0929 09:26:46.296015  1584 net.cpp:198] M2PELU53 needs backward computation.
I0929 09:26:46.296017  1584 net.cpp:198] Eltwise26 needs backward computation.
I0929 09:26:46.296020  1584 net.cpp:198] Scale55 needs backward computation.
I0929 09:26:46.296022  1584 net.cpp:198] BatchNorm55 needs backward computation.
I0929 09:26:46.296025  1584 net.cpp:198] Convolution55 needs backward computation.
I0929 09:26:46.296026  1584 net.cpp:198] M2PELU52 needs backward computation.
I0929 09:26:46.296028  1584 net.cpp:198] Scale54 needs backward computation.
I0929 09:26:46.296031  1584 net.cpp:198] BatchNorm54 needs backward computation.
I0929 09:26:46.296033  1584 net.cpp:198] Convolution54 needs backward computation.
I0929 09:26:46.296036  1584 net.cpp:198] Eltwise25_M2PELU51_0_split needs backward computation.
I0929 09:26:46.296041  1584 net.cpp:198] M2PELU51 needs backward computation.
I0929 09:26:46.296042  1584 net.cpp:198] Eltwise25 needs backward computation.
I0929 09:26:46.296046  1584 net.cpp:198] Scale53 needs backward computation.
I0929 09:26:46.296047  1584 net.cpp:198] BatchNorm53 needs backward computation.
I0929 09:26:46.296051  1584 net.cpp:198] Convolution53 needs backward computation.
I0929 09:26:46.296052  1584 net.cpp:198] M2PELU50 needs backward computation.
I0929 09:26:46.296054  1584 net.cpp:198] Scale52 needs backward computation.
I0929 09:26:46.296057  1584 net.cpp:198] BatchNorm52 needs backward computation.
I0929 09:26:46.296059  1584 net.cpp:198] Convolution52 needs backward computation.
I0929 09:26:46.296062  1584 net.cpp:198] Eltwise24_M2PELU49_0_split needs backward computation.
I0929 09:26:46.296066  1584 net.cpp:198] M2PELU49 needs backward computation.
I0929 09:26:46.296067  1584 net.cpp:198] Eltwise24 needs backward computation.
I0929 09:26:46.296070  1584 net.cpp:198] Scale51 needs backward computation.
I0929 09:26:46.296072  1584 net.cpp:198] BatchNorm51 needs backward computation.
I0929 09:26:46.296074  1584 net.cpp:198] Convolution51 needs backward computation.
I0929 09:26:46.296077  1584 net.cpp:198] M2PELU48 needs backward computation.
I0929 09:26:46.296079  1584 net.cpp:198] Scale50 needs backward computation.
I0929 09:26:46.296082  1584 net.cpp:198] BatchNorm50 needs backward computation.
I0929 09:26:46.296084  1584 net.cpp:198] Convolution50 needs backward computation.
I0929 09:26:46.296087  1584 net.cpp:198] Eltwise23_M2PELU47_0_split needs backward computation.
I0929 09:26:46.296089  1584 net.cpp:198] M2PELU47 needs backward computation.
I0929 09:26:46.296092  1584 net.cpp:198] Eltwise23 needs backward computation.
I0929 09:26:46.296094  1584 net.cpp:198] Scale49 needs backward computation.
I0929 09:26:46.296097  1584 net.cpp:198] BatchNorm49 needs backward computation.
I0929 09:26:46.296099  1584 net.cpp:198] Convolution49 needs backward computation.
I0929 09:26:46.296102  1584 net.cpp:198] M2PELU46 needs backward computation.
I0929 09:26:46.296104  1584 net.cpp:198] Scale48 needs backward computation.
I0929 09:26:46.296106  1584 net.cpp:198] BatchNorm48 needs backward computation.
I0929 09:26:46.296108  1584 net.cpp:198] Convolution48 needs backward computation.
I0929 09:26:46.296111  1584 net.cpp:198] Eltwise22_M2PELU45_0_split needs backward computation.
I0929 09:26:46.296114  1584 net.cpp:198] M2PELU45 needs backward computation.
I0929 09:26:46.296116  1584 net.cpp:198] Eltwise22 needs backward computation.
I0929 09:26:46.296119  1584 net.cpp:198] Scale47 needs backward computation.
I0929 09:26:46.296121  1584 net.cpp:198] BatchNorm47 needs backward computation.
I0929 09:26:46.296124  1584 net.cpp:198] Convolution47 needs backward computation.
I0929 09:26:46.296126  1584 net.cpp:198] M2PELU44 needs backward computation.
I0929 09:26:46.296129  1584 net.cpp:198] Scale46 needs backward computation.
I0929 09:26:46.296131  1584 net.cpp:198] BatchNorm46 needs backward computation.
I0929 09:26:46.296133  1584 net.cpp:198] Convolution46 needs backward computation.
I0929 09:26:46.296136  1584 net.cpp:198] Eltwise21_M2PELU43_0_split needs backward computation.
I0929 09:26:46.296142  1584 net.cpp:198] M2PELU43 needs backward computation.
I0929 09:26:46.296145  1584 net.cpp:198] Eltwise21 needs backward computation.
I0929 09:26:46.296147  1584 net.cpp:198] Scale45 needs backward computation.
I0929 09:26:46.296150  1584 net.cpp:198] BatchNorm45 needs backward computation.
I0929 09:26:46.296152  1584 net.cpp:198] Convolution45 needs backward computation.
I0929 09:26:46.296155  1584 net.cpp:198] M2PELU42 needs backward computation.
I0929 09:26:46.296157  1584 net.cpp:198] Scale44 needs backward computation.
I0929 09:26:46.296159  1584 net.cpp:198] BatchNorm44 needs backward computation.
I0929 09:26:46.296162  1584 net.cpp:198] Convolution44 needs backward computation.
I0929 09:26:46.296164  1584 net.cpp:198] Eltwise20_M2PELU41_0_split needs backward computation.
I0929 09:26:46.296167  1584 net.cpp:198] M2PELU41 needs backward computation.
I0929 09:26:46.296169  1584 net.cpp:198] Eltwise20 needs backward computation.
I0929 09:26:46.296172  1584 net.cpp:198] Scale43 needs backward computation.
I0929 09:26:46.296175  1584 net.cpp:198] BatchNorm43 needs backward computation.
I0929 09:26:46.296177  1584 net.cpp:198] Convolution43 needs backward computation.
I0929 09:26:46.296180  1584 net.cpp:198] M2PELU40 needs backward computation.
I0929 09:26:46.296182  1584 net.cpp:198] Scale42 needs backward computation.
I0929 09:26:46.296185  1584 net.cpp:198] BatchNorm42 needs backward computation.
I0929 09:26:46.296186  1584 net.cpp:198] Convolution42 needs backward computation.
I0929 09:26:46.296190  1584 net.cpp:198] Eltwise19_M2PELU39_0_split needs backward computation.
I0929 09:26:46.296192  1584 net.cpp:198] M2PELU39 needs backward computation.
I0929 09:26:46.296195  1584 net.cpp:198] Eltwise19 needs backward computation.
I0929 09:26:46.296197  1584 net.cpp:198] Scale41 needs backward computation.
I0929 09:26:46.296200  1584 net.cpp:198] BatchNorm41 needs backward computation.
I0929 09:26:46.296202  1584 net.cpp:198] Convolution41 needs backward computation.
I0929 09:26:46.296205  1584 net.cpp:198] M2PELU38 needs backward computation.
I0929 09:26:46.296207  1584 net.cpp:198] Scale40 needs backward computation.
I0929 09:26:46.296211  1584 net.cpp:198] BatchNorm40 needs backward computation.
I0929 09:26:46.296214  1584 net.cpp:198] Convolution40 needs backward computation.
I0929 09:26:46.296217  1584 net.cpp:198] Scale39 needs backward computation.
I0929 09:26:46.296221  1584 net.cpp:198] BatchNorm39 needs backward computation.
I0929 09:26:46.296222  1584 net.cpp:198] Convolution39 needs backward computation.
I0929 09:26:46.296226  1584 net.cpp:198] Eltwise18_M2PELU37_0_split needs backward computation.
I0929 09:26:46.296227  1584 net.cpp:198] M2PELU37 needs backward computation.
I0929 09:26:46.296231  1584 net.cpp:198] Eltwise18 needs backward computation.
I0929 09:26:46.298493  1584 net.cpp:198] Scale38 needs backward computation.
I0929 09:26:46.298512  1584 net.cpp:198] BatchNorm38 needs backward computation.
I0929 09:26:46.298516  1584 net.cpp:198] Convolution38 needs backward computation.
I0929 09:26:46.298518  1584 net.cpp:198] M2PELU36 needs backward computation.
I0929 09:26:46.298535  1584 net.cpp:198] Scale37 needs backward computation.
I0929 09:26:46.298537  1584 net.cpp:198] BatchNorm37 needs backward computation.
I0929 09:26:46.298539  1584 net.cpp:198] Convolution37 needs backward computation.
I0929 09:26:46.298542  1584 net.cpp:198] Eltwise17_M2PELU35_0_split needs backward computation.
I0929 09:26:46.298545  1584 net.cpp:198] M2PELU35 needs backward computation.
I0929 09:26:46.298547  1584 net.cpp:198] Eltwise17 needs backward computation.
I0929 09:26:46.298550  1584 net.cpp:198] Scale36 needs backward computation.
I0929 09:26:46.298553  1584 net.cpp:198] BatchNorm36 needs backward computation.
I0929 09:26:46.298555  1584 net.cpp:198] Convolution36 needs backward computation.
I0929 09:26:46.298557  1584 net.cpp:198] M2PELU34 needs backward computation.
I0929 09:26:46.298559  1584 net.cpp:198] Scale35 needs backward computation.
I0929 09:26:46.298562  1584 net.cpp:198] BatchNorm35 needs backward computation.
I0929 09:26:46.298570  1584 net.cpp:198] Convolution35 needs backward computation.
I0929 09:26:46.298574  1584 net.cpp:198] Eltwise16_M2PELU33_0_split needs backward computation.
I0929 09:26:46.298576  1584 net.cpp:198] M2PELU33 needs backward computation.
I0929 09:26:46.298578  1584 net.cpp:198] Eltwise16 needs backward computation.
I0929 09:26:46.298583  1584 net.cpp:198] Scale34 needs backward computation.
I0929 09:26:46.298584  1584 net.cpp:198] BatchNorm34 needs backward computation.
I0929 09:26:46.298586  1584 net.cpp:198] Convolution34 needs backward computation.
I0929 09:26:46.298588  1584 net.cpp:198] M2PELU32 needs backward computation.
I0929 09:26:46.298590  1584 net.cpp:198] Scale33 needs backward computation.
I0929 09:26:46.298593  1584 net.cpp:198] BatchNorm33 needs backward computation.
I0929 09:26:46.298595  1584 net.cpp:198] Convolution33 needs backward computation.
I0929 09:26:46.298597  1584 net.cpp:198] Eltwise15_M2PELU31_0_split needs backward computation.
I0929 09:26:46.298600  1584 net.cpp:198] M2PELU31 needs backward computation.
I0929 09:26:46.298602  1584 net.cpp:198] Eltwise15 needs backward computation.
I0929 09:26:46.298605  1584 net.cpp:198] Scale32 needs backward computation.
I0929 09:26:46.298607  1584 net.cpp:198] BatchNorm32 needs backward computation.
I0929 09:26:46.298609  1584 net.cpp:198] Convolution32 needs backward computation.
I0929 09:26:46.298611  1584 net.cpp:198] M2PELU30 needs backward computation.
I0929 09:26:46.298614  1584 net.cpp:198] Scale31 needs backward computation.
I0929 09:26:46.298616  1584 net.cpp:198] BatchNorm31 needs backward computation.
I0929 09:26:46.298619  1584 net.cpp:198] Convolution31 needs backward computation.
I0929 09:26:46.298620  1584 net.cpp:198] Eltwise14_M2PELU29_0_split needs backward computation.
I0929 09:26:46.298624  1584 net.cpp:198] M2PELU29 needs backward computation.
I0929 09:26:46.298625  1584 net.cpp:198] Eltwise14 needs backward computation.
I0929 09:26:46.298627  1584 net.cpp:198] Scale30 needs backward computation.
I0929 09:26:46.298630  1584 net.cpp:198] BatchNorm30 needs backward computation.
I0929 09:26:46.298632  1584 net.cpp:198] Convolution30 needs backward computation.
I0929 09:26:46.298635  1584 net.cpp:198] M2PELU28 needs backward computation.
I0929 09:26:46.298636  1584 net.cpp:198] Scale29 needs backward computation.
I0929 09:26:46.298638  1584 net.cpp:198] BatchNorm29 needs backward computation.
I0929 09:26:46.298641  1584 net.cpp:198] Convolution29 needs backward computation.
I0929 09:26:46.298643  1584 net.cpp:198] Eltwise13_M2PELU27_0_split needs backward computation.
I0929 09:26:46.298645  1584 net.cpp:198] M2PELU27 needs backward computation.
I0929 09:26:46.298647  1584 net.cpp:198] Eltwise13 needs backward computation.
I0929 09:26:46.298651  1584 net.cpp:198] Scale28 needs backward computation.
I0929 09:26:46.298653  1584 net.cpp:198] BatchNorm28 needs backward computation.
I0929 09:26:46.298655  1584 net.cpp:198] Convolution28 needs backward computation.
I0929 09:26:46.298657  1584 net.cpp:198] M2PELU26 needs backward computation.
I0929 09:26:46.298660  1584 net.cpp:198] Scale27 needs backward computation.
I0929 09:26:46.298662  1584 net.cpp:198] BatchNorm27 needs backward computation.
I0929 09:26:46.298665  1584 net.cpp:198] Convolution27 needs backward computation.
I0929 09:26:46.298666  1584 net.cpp:198] Eltwise12_M2PELU25_0_split needs backward computation.
I0929 09:26:46.298669  1584 net.cpp:198] M2PELU25 needs backward computation.
I0929 09:26:46.298671  1584 net.cpp:198] Eltwise12 needs backward computation.
I0929 09:26:46.298674  1584 net.cpp:198] Scale26 needs backward computation.
I0929 09:26:46.298676  1584 net.cpp:198] BatchNorm26 needs backward computation.
I0929 09:26:46.298678  1584 net.cpp:198] Convolution26 needs backward computation.
I0929 09:26:46.298681  1584 net.cpp:198] M2PELU24 needs backward computation.
I0929 09:26:46.298682  1584 net.cpp:198] Scale25 needs backward computation.
I0929 09:26:46.298686  1584 net.cpp:198] BatchNorm25 needs backward computation.
I0929 09:26:46.298691  1584 net.cpp:198] Convolution25 needs backward computation.
I0929 09:26:46.298692  1584 net.cpp:198] Eltwise11_M2PELU23_0_split needs backward computation.
I0929 09:26:46.298696  1584 net.cpp:198] M2PELU23 needs backward computation.
I0929 09:26:46.298697  1584 net.cpp:198] Eltwise11 needs backward computation.
I0929 09:26:46.298701  1584 net.cpp:198] Scale24 needs backward computation.
I0929 09:26:46.298702  1584 net.cpp:198] BatchNorm24 needs backward computation.
I0929 09:26:46.298704  1584 net.cpp:198] Convolution24 needs backward computation.
I0929 09:26:46.298707  1584 net.cpp:198] M2PELU22 needs backward computation.
I0929 09:26:46.298709  1584 net.cpp:198] Scale23 needs backward computation.
I0929 09:26:46.298712  1584 net.cpp:198] BatchNorm23 needs backward computation.
I0929 09:26:46.298714  1584 net.cpp:198] Convolution23 needs backward computation.
I0929 09:26:46.298717  1584 net.cpp:198] Eltwise10_M2PELU21_0_split needs backward computation.
I0929 09:26:46.298718  1584 net.cpp:198] M2PELU21 needs backward computation.
I0929 09:26:46.298722  1584 net.cpp:198] Eltwise10 needs backward computation.
I0929 09:26:46.298723  1584 net.cpp:198] Scale22 needs backward computation.
I0929 09:26:46.298727  1584 net.cpp:198] BatchNorm22 needs backward computation.
I0929 09:26:46.298728  1584 net.cpp:198] Convolution22 needs backward computation.
I0929 09:26:46.298730  1584 net.cpp:198] M2PELU20 needs backward computation.
I0929 09:26:46.298733  1584 net.cpp:198] Scale21 needs backward computation.
I0929 09:26:46.298735  1584 net.cpp:198] BatchNorm21 needs backward computation.
I0929 09:26:46.298738  1584 net.cpp:198] Convolution21 needs backward computation.
I0929 09:26:46.298740  1584 net.cpp:198] Scale20 needs backward computation.
I0929 09:26:46.298743  1584 net.cpp:198] BatchNorm20 needs backward computation.
I0929 09:26:46.298744  1584 net.cpp:198] Convolution20 needs backward computation.
I0929 09:26:46.298748  1584 net.cpp:198] Eltwise9_M2PELU19_0_split needs backward computation.
I0929 09:26:46.298749  1584 net.cpp:198] M2PELU19 needs backward computation.
I0929 09:26:46.298751  1584 net.cpp:198] Eltwise9 needs backward computation.
I0929 09:26:46.298754  1584 net.cpp:198] Scale19 needs backward computation.
I0929 09:26:46.298758  1584 net.cpp:198] BatchNorm19 needs backward computation.
I0929 09:26:46.298768  1584 net.cpp:198] Convolution19 needs backward computation.
I0929 09:26:46.298773  1584 net.cpp:198] M2PELU18 needs backward computation.
I0929 09:26:46.298774  1584 net.cpp:198] Scale18 needs backward computation.
I0929 09:26:46.298777  1584 net.cpp:198] BatchNorm18 needs backward computation.
I0929 09:26:46.298779  1584 net.cpp:198] Convolution18 needs backward computation.
I0929 09:26:46.326566  1584 net.cpp:198] Eltwise8_M2PELU17_0_split needs backward computation.
I0929 09:26:46.326575  1584 net.cpp:198] M2PELU17 needs backward computation.
I0929 09:26:46.326577  1584 net.cpp:198] Eltwise8 needs backward computation.
I0929 09:26:46.326581  1584 net.cpp:198] Scale17 needs backward computation.
I0929 09:26:46.326583  1584 net.cpp:198] BatchNorm17 needs backward computation.
I0929 09:26:46.326586  1584 net.cpp:198] Convolution17 needs backward computation.
I0929 09:26:46.326588  1584 net.cpp:198] M2PELU16 needs backward computation.
I0929 09:26:46.326591  1584 net.cpp:198] Scale16 needs backward computation.
I0929 09:26:46.326593  1584 net.cpp:198] BatchNorm16 needs backward computation.
I0929 09:26:46.326596  1584 net.cpp:198] Convolution16 needs backward computation.
I0929 09:26:46.326598  1584 net.cpp:198] Eltwise7_M2PELU15_0_split needs backward computation.
I0929 09:26:46.326601  1584 net.cpp:198] M2PELU15 needs backward computation.
I0929 09:26:46.326603  1584 net.cpp:198] Eltwise7 needs backward computation.
I0929 09:26:46.326606  1584 net.cpp:198] Scale15 needs backward computation.
I0929 09:26:46.326609  1584 net.cpp:198] BatchNorm15 needs backward computation.
I0929 09:26:46.326611  1584 net.cpp:198] Convolution15 needs backward computation.
I0929 09:26:46.326614  1584 net.cpp:198] M2PELU14 needs backward computation.
I0929 09:26:46.326624  1584 net.cpp:198] Scale14 needs backward computation.
I0929 09:26:46.326627  1584 net.cpp:198] BatchNorm14 needs backward computation.
I0929 09:26:46.326629  1584 net.cpp:198] Convolution14 needs backward computation.
I0929 09:26:46.326632  1584 net.cpp:198] Eltwise6_M2PELU13_0_split needs backward computation.
I0929 09:26:46.326634  1584 net.cpp:198] M2PELU13 needs backward computation.
I0929 09:26:46.326637  1584 net.cpp:198] Eltwise6 needs backward computation.
I0929 09:26:46.326640  1584 net.cpp:198] Scale13 needs backward computation.
I0929 09:26:46.326642  1584 net.cpp:198] BatchNorm13 needs backward computation.
I0929 09:26:46.326645  1584 net.cpp:198] Convolution13 needs backward computation.
I0929 09:26:46.326647  1584 net.cpp:198] M2PELU12 needs backward computation.
I0929 09:26:46.326650  1584 net.cpp:198] Scale12 needs backward computation.
I0929 09:26:46.326653  1584 net.cpp:198] BatchNorm12 needs backward computation.
I0929 09:26:46.326654  1584 net.cpp:198] Convolution12 needs backward computation.
I0929 09:26:46.326658  1584 net.cpp:198] Eltwise5_M2PELU11_0_split needs backward computation.
I0929 09:26:46.326659  1584 net.cpp:198] M2PELU11 needs backward computation.
I0929 09:26:46.326663  1584 net.cpp:198] Eltwise5 needs backward computation.
I0929 09:26:46.326665  1584 net.cpp:198] Scale11 needs backward computation.
I0929 09:26:46.326668  1584 net.cpp:198] BatchNorm11 needs backward computation.
I0929 09:26:46.326670  1584 net.cpp:198] Convolution11 needs backward computation.
I0929 09:26:46.326673  1584 net.cpp:198] M2PELU10 needs backward computation.
I0929 09:26:46.326675  1584 net.cpp:198] Scale10 needs backward computation.
I0929 09:26:46.326678  1584 net.cpp:198] BatchNorm10 needs backward computation.
I0929 09:26:46.326680  1584 net.cpp:198] Convolution10 needs backward computation.
I0929 09:26:46.326683  1584 net.cpp:198] Eltwise4_M2PELU9_0_split needs backward computation.
I0929 09:26:46.326685  1584 net.cpp:198] M2PELU9 needs backward computation.
I0929 09:26:46.326689  1584 net.cpp:198] Eltwise4 needs backward computation.
I0929 09:26:46.326691  1584 net.cpp:198] Scale9 needs backward computation.
I0929 09:26:46.326694  1584 net.cpp:198] BatchNorm9 needs backward computation.
I0929 09:26:46.326696  1584 net.cpp:198] Convolution9 needs backward computation.
I0929 09:26:46.326699  1584 net.cpp:198] M2PELU8 needs backward computation.
I0929 09:26:46.326702  1584 net.cpp:198] Scale8 needs backward computation.
I0929 09:26:46.326704  1584 net.cpp:198] BatchNorm8 needs backward computation.
I0929 09:26:46.326707  1584 net.cpp:198] Convolution8 needs backward computation.
I0929 09:26:46.326710  1584 net.cpp:198] Eltwise3_M2PELU7_0_split needs backward computation.
I0929 09:26:46.326714  1584 net.cpp:198] M2PELU7 needs backward computation.
I0929 09:26:46.326716  1584 net.cpp:198] Eltwise3 needs backward computation.
I0929 09:26:46.326719  1584 net.cpp:198] Scale7 needs backward computation.
I0929 09:26:46.326721  1584 net.cpp:198] BatchNorm7 needs backward computation.
I0929 09:26:46.326725  1584 net.cpp:198] Convolution7 needs backward computation.
I0929 09:26:46.326727  1584 net.cpp:198] M2PELU6 needs backward computation.
I0929 09:26:46.326730  1584 net.cpp:198] Scale6 needs backward computation.
I0929 09:26:46.326731  1584 net.cpp:198] BatchNorm6 needs backward computation.
I0929 09:26:46.326735  1584 net.cpp:198] Convolution6 needs backward computation.
I0929 09:26:46.326737  1584 net.cpp:198] Eltwise2_M2PELU5_0_split needs backward computation.
I0929 09:26:46.326740  1584 net.cpp:198] M2PELU5 needs backward computation.
I0929 09:26:46.326742  1584 net.cpp:198] Eltwise2 needs backward computation.
I0929 09:26:46.326745  1584 net.cpp:198] Scale5 needs backward computation.
I0929 09:26:46.326750  1584 net.cpp:198] BatchNorm5 needs backward computation.
I0929 09:26:46.326752  1584 net.cpp:198] Convolution5 needs backward computation.
I0929 09:26:46.326756  1584 net.cpp:198] M2PELU4 needs backward computation.
I0929 09:26:46.326757  1584 net.cpp:198] Scale4 needs backward computation.
I0929 09:26:46.326763  1584 net.cpp:198] BatchNorm4 needs backward computation.
I0929 09:26:46.326766  1584 net.cpp:198] Convolution4 needs backward computation.
I0929 09:26:46.326768  1584 net.cpp:198] Eltwise1_M2PELU3_0_split needs backward computation.
I0929 09:26:46.326771  1584 net.cpp:198] M2PELU3 needs backward computation.
I0929 09:26:46.326773  1584 net.cpp:198] Eltwise1 needs backward computation.
I0929 09:26:46.326776  1584 net.cpp:198] Scale3 needs backward computation.
I0929 09:26:46.326779  1584 net.cpp:198] BatchNorm3 needs backward computation.
I0929 09:26:46.326781  1584 net.cpp:198] Convolution3 needs backward computation.
I0929 09:26:46.326784  1584 net.cpp:198] M2PELU2 needs backward computation.
I0929 09:26:46.326786  1584 net.cpp:198] Scale2 needs backward computation.
I0929 09:26:46.326789  1584 net.cpp:198] BatchNorm2 needs backward computation.
I0929 09:26:46.326792  1584 net.cpp:198] Convolution2 needs backward computation.
I0929 09:26:46.326794  1584 net.cpp:198] Convolution1_M2PELU1_0_split needs backward computation.
I0929 09:26:46.326797  1584 net.cpp:198] M2PELU1 needs backward computation.
I0929 09:26:46.326800  1584 net.cpp:198] Scale1 needs backward computation.
I0929 09:26:46.326802  1584 net.cpp:198] BatchNorm1 needs backward computation.
I0929 09:26:46.326804  1584 net.cpp:198] Convolution1 needs backward computation.
I0929 09:26:46.326808  1584 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I0929 09:26:46.326812  1584 net.cpp:200] Data1 does not need backward computation.
I0929 09:26:46.326813  1584 net.cpp:242] This network produces output Accuracy1
I0929 09:26:46.326817  1584 net.cpp:242] This network produces output SoftmaxWithLoss1
I0929 09:26:46.326915  1584 net.cpp:255] Network initialization done.
I0929 09:26:46.327723  1584 solver.cpp:56] Solver scaffolding done.
I0929 09:26:46.340761  1584 caffe.cpp:248] Starting Optimization
I0929 09:26:46.340772  1584 solver.cpp:272] Solving resnet_cifar10
I0929 09:26:46.340775  1584 solver.cpp:273] Learning Rate Policy: multistep
I0929 09:26:46.346724  1584 solver.cpp:330] Iteration 0, Testing net (#0)
I0929 09:26:49.783381  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:26:49.923188  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I0929 09:26:49.923213  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I0929 09:26:50.119698  1584 solver.cpp:218] Iteration 0 (-4.37554e-18 iter/s, 3.77882s/100 iters), loss = 2.31762
I0929 09:26:50.119726  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.31762 (* 1 = 2.31762 loss)
I0929 09:26:50.119750  1584 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I0929 09:27:04.291713  1584 solver.cpp:218] Iteration 100 (7.05623 iter/s, 14.1719s/100 iters), loss = 2.26496
I0929 09:27:04.291741  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.26496 (* 1 = 2.26496 loss)
I0929 09:27:04.291748  1584 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I0929 09:27:18.463296  1584 solver.cpp:218] Iteration 200 (7.05644 iter/s, 14.1714s/100 iters), loss = 2.16941
I0929 09:27:18.463385  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.16941 (* 1 = 2.16941 loss)
I0929 09:27:18.463392  1584 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I0929 09:27:32.745992  1584 solver.cpp:218] Iteration 300 (7.00158 iter/s, 14.2825s/100 iters), loss = 1.71544
I0929 09:27:32.746026  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.71544 (* 1 = 1.71544 loss)
I0929 09:27:32.746034  1584 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I0929 09:27:47.042368  1584 solver.cpp:218] Iteration 400 (6.99485 iter/s, 14.2962s/100 iters), loss = 1.62792
I0929 09:27:47.042398  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.62792 (* 1 = 1.62792 loss)
I0929 09:27:47.042405  1584 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I0929 09:28:00.777503  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:28:01.347921  1584 solver.cpp:330] Iteration 500, Testing net (#0)
I0929 09:28:04.748495  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:28:04.895629  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.113
I0929 09:28:04.895666  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 5.35165 (* 1 = 5.35165 loss)
I0929 09:28:05.043393  1584 solver.cpp:218] Iteration 500 (5.55529 iter/s, 18.0009s/100 iters), loss = 1.69756
I0929 09:28:05.043429  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.69756 (* 1 = 1.69756 loss)
I0929 09:28:05.043437  1584 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I0929 09:28:19.714742  1584 solver.cpp:218] Iteration 600 (6.81608 iter/s, 14.6712s/100 iters), loss = 1.46295
I0929 09:28:19.714776  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.46295 (* 1 = 1.46295 loss)
I0929 09:28:19.714783  1584 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I0929 09:28:34.004123  1584 solver.cpp:218] Iteration 700 (6.99826 iter/s, 14.2893s/100 iters), loss = 1.58604
I0929 09:28:34.004262  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.58604 (* 1 = 1.58604 loss)
I0929 09:28:34.004271  1584 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I0929 09:28:48.240041  1584 solver.cpp:218] Iteration 800 (7.02459 iter/s, 14.2357s/100 iters), loss = 1.27743
I0929 09:28:48.240072  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.27743 (* 1 = 1.27743 loss)
I0929 09:28:48.240077  1584 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I0929 09:29:02.473305  1584 solver.cpp:218] Iteration 900 (7.02585 iter/s, 14.2332s/100 iters), loss = 1.21464
I0929 09:29:02.473347  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.21464 (* 1 = 1.21464 loss)
I0929 09:29:02.473354  1584 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I0929 09:29:15.999105  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:29:16.575837  1584 solver.cpp:330] Iteration 1000, Testing net (#0)
I0929 09:29:19.934762  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:29:20.074599  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1614
I0929 09:29:20.074635  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 4.57582 (* 1 = 4.57582 loss)
I0929 09:29:20.215155  1584 solver.cpp:218] Iteration 1000 (5.63643 iter/s, 17.7417s/100 iters), loss = 1.17464
I0929 09:29:20.215186  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.17464 (* 1 = 1.17464 loss)
I0929 09:29:20.215193  1584 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I0929 09:29:34.440323  1584 solver.cpp:218] Iteration 1100 (7.02986 iter/s, 14.225s/100 iters), loss = 1.25192
I0929 09:29:34.440361  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.25192 (* 1 = 1.25192 loss)
I0929 09:29:34.440379  1584 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I0929 09:29:48.655236  1584 solver.cpp:218] Iteration 1200 (7.03491 iter/s, 14.2148s/100 iters), loss = 1.25636
I0929 09:29:48.655377  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.25636 (* 1 = 1.25636 loss)
I0929 09:29:48.655385  1584 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I0929 09:30:02.886976  1584 solver.cpp:218] Iteration 1300 (7.02665 iter/s, 14.2315s/100 iters), loss = 1.00781
I0929 09:30:02.887007  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.00781 (* 1 = 1.00781 loss)
I0929 09:30:02.887024  1584 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I0929 09:30:17.123394  1584 solver.cpp:218] Iteration 1400 (7.02428 iter/s, 14.2363s/100 iters), loss = 0.941819
I0929 09:30:17.123425  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.941819 (* 1 = 0.941819 loss)
I0929 09:30:17.123441  1584 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I0929 09:30:30.643494  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:30:31.211391  1584 solver.cpp:330] Iteration 1500, Testing net (#0)
I0929 09:30:34.575006  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:30:34.715574  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3662
I0929 09:30:34.715610  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.36866 (* 1 = 2.36866 loss)
I0929 09:30:34.856617  1584 solver.cpp:218] Iteration 1500 (5.63917 iter/s, 17.7331s/100 iters), loss = 1.08683
I0929 09:30:34.856658  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.08683 (* 1 = 1.08683 loss)
I0929 09:30:34.856675  1584 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I0929 09:30:49.103313  1584 solver.cpp:218] Iteration 1600 (7.01922 iter/s, 14.2466s/100 iters), loss = 0.926593
I0929 09:30:49.103343  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.926593 (* 1 = 0.926593 loss)
I0929 09:30:49.103360  1584 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I0929 09:31:03.371546  1584 solver.cpp:218] Iteration 1700 (7.00862 iter/s, 14.2681s/100 iters), loss = 0.951546
I0929 09:31:03.371682  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.951546 (* 1 = 0.951546 loss)
I0929 09:31:03.371691  1584 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I0929 09:31:17.642107  1584 solver.cpp:218] Iteration 1800 (7.00752 iter/s, 14.2704s/100 iters), loss = 0.862266
I0929 09:31:17.642137  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.862266 (* 1 = 0.862266 loss)
I0929 09:31:17.642153  1584 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I0929 09:31:31.898592  1584 solver.cpp:218] Iteration 1900 (7.01439 iter/s, 14.2564s/100 iters), loss = 0.797826
I0929 09:31:31.898629  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.797826 (* 1 = 0.797826 loss)
I0929 09:31:31.898648  1584 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I0929 09:31:45.453562  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:31:46.022792  1584 solver.cpp:330] Iteration 2000, Testing net (#0)
I0929 09:31:49.386951  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:31:49.532207  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.2987
I0929 09:31:49.532235  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.40695 (* 1 = 3.40695 loss)
I0929 09:31:49.675099  1584 solver.cpp:218] Iteration 2000 (5.62544 iter/s, 17.7764s/100 iters), loss = 0.797482
I0929 09:31:49.675133  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.797482 (* 1 = 0.797482 loss)
I0929 09:31:49.675140  1584 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I0929 09:32:03.921242  1584 solver.cpp:218] Iteration 2100 (7.01949 iter/s, 14.246s/100 iters), loss = 0.636972
I0929 09:32:03.921273  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.636972 (* 1 = 0.636972 loss)
I0929 09:32:03.921290  1584 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I0929 09:32:18.174075  1584 solver.cpp:218] Iteration 2200 (7.01619 iter/s, 14.2527s/100 iters), loss = 0.82869
I0929 09:32:18.174197  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.82869 (* 1 = 0.82869 loss)
I0929 09:32:18.174216  1584 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I0929 09:32:32.442284  1584 solver.cpp:218] Iteration 2300 (7.00868 iter/s, 14.268s/100 iters), loss = 0.7555
I0929 09:32:32.442315  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.7555 (* 1 = 0.7555 loss)
I0929 09:32:32.442322  1584 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I0929 09:32:46.699971  1584 solver.cpp:218] Iteration 2400 (7.0138 iter/s, 14.2576s/100 iters), loss = 0.637884
I0929 09:32:46.700006  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.637884 (* 1 = 0.637884 loss)
I0929 09:32:46.700012  1584 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I0929 09:33:00.245290  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:33:00.814102  1584 solver.cpp:330] Iteration 2500, Testing net (#0)
I0929 09:33:04.169425  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:33:04.309697  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4932
I0929 09:33:04.309722  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.77733 (* 1 = 1.77733 loss)
I0929 09:33:04.452955  1584 solver.cpp:218] Iteration 2500 (5.63289 iter/s, 17.7529s/100 iters), loss = 0.794355
I0929 09:33:04.453001  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.794355 (* 1 = 0.794355 loss)
I0929 09:33:04.453007  1584 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I0929 09:33:18.697386  1584 solver.cpp:218] Iteration 2600 (7.02035 iter/s, 14.2443s/100 iters), loss = 0.587485
I0929 09:33:18.697417  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.587485 (* 1 = 0.587485 loss)
I0929 09:33:18.697424  1584 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I0929 09:33:32.957474  1584 solver.cpp:218] Iteration 2700 (7.01262 iter/s, 14.26s/100 iters), loss = 0.63156
I0929 09:33:32.957617  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.63156 (* 1 = 0.63156 loss)
I0929 09:33:32.957625  1584 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I0929 09:33:47.208264  1584 solver.cpp:218] Iteration 2800 (7.01725 iter/s, 14.2506s/100 iters), loss = 0.716724
I0929 09:33:47.208294  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.716724 (* 1 = 0.716724 loss)
I0929 09:33:47.208302  1584 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I0929 09:34:01.452203  1584 solver.cpp:218] Iteration 2900 (7.02057 iter/s, 14.2439s/100 iters), loss = 0.50449
I0929 09:34:01.452250  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.50449 (* 1 = 0.50449 loss)
I0929 09:34:01.452258  1584 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I0929 09:34:14.997548  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:34:15.566718  1584 solver.cpp:330] Iteration 3000, Testing net (#0)
I0929 09:34:18.926653  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:34:19.066231  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4842
I0929 09:34:19.066264  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.58411 (* 1 = 1.58411 loss)
I0929 09:34:19.206775  1584 solver.cpp:218] Iteration 3000 (5.6324 iter/s, 17.7544s/100 iters), loss = 0.711793
I0929 09:34:19.206804  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.711793 (* 1 = 0.711793 loss)
I0929 09:34:19.206809  1584 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I0929 09:34:33.449018  1584 solver.cpp:218] Iteration 3100 (7.02141 iter/s, 14.2422s/100 iters), loss = 0.573175
I0929 09:34:33.449048  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.573175 (* 1 = 0.573175 loss)
I0929 09:34:33.449055  1584 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I0929 09:34:47.693123  1584 solver.cpp:218] Iteration 3200 (7.02049 iter/s, 14.244s/100 iters), loss = 0.695962
I0929 09:34:47.693269  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.695962 (* 1 = 0.695962 loss)
I0929 09:34:47.693279  1584 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I0929 09:35:01.947926  1584 solver.cpp:218] Iteration 3300 (7.01528 iter/s, 14.2546s/100 iters), loss = 0.622386
I0929 09:35:01.947959  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.622386 (* 1 = 0.622386 loss)
I0929 09:35:01.947966  1584 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I0929 09:35:16.188457  1584 solver.cpp:218] Iteration 3400 (7.02225 iter/s, 14.2404s/100 iters), loss = 0.548892
I0929 09:35:16.188486  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.548892 (* 1 = 0.548892 loss)
I0929 09:35:16.188493  1584 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I0929 09:35:29.730871  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:35:30.300938  1584 solver.cpp:330] Iteration 3500, Testing net (#0)
I0929 09:35:33.655223  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:35:33.794777  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5565
I0929 09:35:33.794802  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.32518 (* 1 = 1.32518 loss)
I0929 09:35:33.936199  1584 solver.cpp:218] Iteration 3500 (5.63455 iter/s, 17.7477s/100 iters), loss = 0.62908
I0929 09:35:33.936230  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.62908 (* 1 = 0.62908 loss)
I0929 09:35:33.936236  1584 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I0929 09:35:48.184933  1584 solver.cpp:218] Iteration 3600 (7.01821 iter/s, 14.2487s/100 iters), loss = 0.424
I0929 09:35:48.184963  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.424 (* 1 = 0.424 loss)
I0929 09:35:48.184969  1584 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I0929 09:36:02.441330  1584 solver.cpp:218] Iteration 3700 (7.01444 iter/s, 14.2563s/100 iters), loss = 0.610016
I0929 09:36:02.441462  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.610016 (* 1 = 0.610016 loss)
I0929 09:36:02.441478  1584 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I0929 09:36:16.676375  1584 solver.cpp:218] Iteration 3800 (7.025 iter/s, 14.2349s/100 iters), loss = 0.504754
I0929 09:36:16.676410  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.504754 (* 1 = 0.504754 loss)
I0929 09:36:16.676417  1584 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I0929 09:36:30.913789  1584 solver.cpp:218] Iteration 3900 (7.02379 iter/s, 14.2373s/100 iters), loss = 0.546432
I0929 09:36:30.913820  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.546432 (* 1 = 0.546432 loss)
I0929 09:36:30.913827  1584 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I0929 09:36:44.455296  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:36:45.022972  1584 solver.cpp:330] Iteration 4000, Testing net (#0)
I0929 09:36:48.382944  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:36:48.522723  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6442
I0929 09:36:48.522758  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.04801 (* 1 = 1.04801 loss)
I0929 09:36:48.663817  1584 solver.cpp:218] Iteration 4000 (5.63382 iter/s, 17.7499s/100 iters), loss = 0.531029
I0929 09:36:48.663848  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.531029 (* 1 = 0.531029 loss)
I0929 09:36:48.663856  1584 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I0929 09:37:02.913236  1584 solver.cpp:218] Iteration 4100 (7.01787 iter/s, 14.2493s/100 iters), loss = 0.410409
I0929 09:37:02.913269  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.410409 (* 1 = 0.410409 loss)
I0929 09:37:02.913275  1584 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I0929 09:37:17.169438  1584 solver.cpp:218] Iteration 4200 (7.01453 iter/s, 14.2561s/100 iters), loss = 0.464735
I0929 09:37:17.169577  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.464735 (* 1 = 0.464735 loss)
I0929 09:37:17.169585  1584 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I0929 09:37:31.425451  1584 solver.cpp:218] Iteration 4300 (7.01467 iter/s, 14.2558s/100 iters), loss = 0.499945
I0929 09:37:31.425487  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.499945 (* 1 = 0.499945 loss)
I0929 09:37:31.425494  1584 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I0929 09:37:45.681450  1584 solver.cpp:218] Iteration 4400 (7.01463 iter/s, 14.2559s/100 iters), loss = 0.423702
I0929 09:37:45.681493  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.423702 (* 1 = 0.423702 loss)
I0929 09:37:45.681499  1584 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I0929 09:37:59.233682  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:37:59.802748  1584 solver.cpp:330] Iteration 4500, Testing net (#0)
I0929 09:38:03.164559  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:38:03.304787  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6459
I0929 09:38:03.304822  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.03297 (* 1 = 1.03297 loss)
I0929 09:38:03.445017  1584 solver.cpp:218] Iteration 4500 (5.62953 iter/s, 17.7635s/100 iters), loss = 0.488902
I0929 09:38:03.445051  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.488902 (* 1 = 0.488902 loss)
I0929 09:38:03.445060  1584 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I0929 09:38:17.692749  1584 solver.cpp:218] Iteration 4600 (7.0187 iter/s, 14.2477s/100 iters), loss = 0.508766
I0929 09:38:17.692781  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.508766 (* 1 = 0.508766 loss)
I0929 09:38:17.692788  1584 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I0929 09:38:31.942001  1584 solver.cpp:218] Iteration 4700 (7.01795 iter/s, 14.2492s/100 iters), loss = 0.449579
I0929 09:38:31.942138  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.449579 (* 1 = 0.449579 loss)
I0929 09:38:31.942147  1584 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I0929 09:38:46.172185  1584 solver.cpp:218] Iteration 4800 (7.0274 iter/s, 14.23s/100 iters), loss = 0.499327
I0929 09:38:46.172214  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.499327 (* 1 = 0.499327 loss)
I0929 09:38:46.172219  1584 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I0929 09:39:00.421955  1584 solver.cpp:218] Iteration 4900 (7.0177 iter/s, 14.2497s/100 iters), loss = 0.387515
I0929 09:39:00.422000  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.387515 (* 1 = 0.387515 loss)
I0929 09:39:00.422008  1584 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I0929 09:39:13.985213  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:39:14.553112  1584 solver.cpp:330] Iteration 5000, Testing net (#0)
I0929 09:39:17.911790  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:39:18.051688  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.633
I0929 09:39:18.051713  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.05397 (* 1 = 1.05397 loss)
I0929 09:39:18.191898  1584 solver.cpp:218] Iteration 5000 (5.62751 iter/s, 17.7698s/100 iters), loss = 0.442726
I0929 09:39:18.191929  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.442726 (* 1 = 0.442726 loss)
I0929 09:39:18.191936  1584 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I0929 09:39:32.427824  1584 solver.cpp:218] Iteration 5100 (7.02452 iter/s, 14.2358s/100 iters), loss = 0.376012
I0929 09:39:32.427857  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.376012 (* 1 = 0.376012 loss)
I0929 09:39:32.427865  1584 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I0929 09:39:46.746474  1584 solver.cpp:218] Iteration 5200 (6.98394 iter/s, 14.3186s/100 iters), loss = 0.393179
I0929 09:39:46.746619  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.393179 (* 1 = 0.393179 loss)
I0929 09:39:46.746628  1584 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I0929 09:40:01.031745  1584 solver.cpp:218] Iteration 5300 (7.00031 iter/s, 14.2851s/100 iters), loss = 0.459331
I0929 09:40:01.031780  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.459331 (* 1 = 0.459331 loss)
I0929 09:40:01.031787  1584 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I0929 09:40:15.416440  1584 solver.cpp:218] Iteration 5400 (6.95187 iter/s, 14.3846s/100 iters), loss = 0.335552
I0929 09:40:15.416468  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335552 (* 1 = 0.335552 loss)
I0929 09:40:15.416474  1584 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I0929 09:40:29.033349  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:40:29.602183  1584 solver.cpp:330] Iteration 5500, Testing net (#0)
I0929 09:40:32.994148  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:40:33.133891  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6467
I0929 09:40:33.133926  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.991286 (* 1 = 0.991286 loss)
I0929 09:40:33.274286  1584 solver.cpp:218] Iteration 5500 (5.59981 iter/s, 17.8578s/100 iters), loss = 0.442873
I0929 09:40:33.274315  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.442873 (* 1 = 0.442873 loss)
I0929 09:40:33.274322  1584 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I0929 09:40:47.523661  1584 solver.cpp:218] Iteration 5600 (7.01789 iter/s, 14.2493s/100 iters), loss = 0.469012
I0929 09:40:47.523691  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.469012 (* 1 = 0.469012 loss)
I0929 09:40:47.523697  1584 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I0929 09:41:01.758066  1584 solver.cpp:218] Iteration 5700 (7.02527 iter/s, 14.2343s/100 iters), loss = 0.425441
I0929 09:41:01.758239  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.425441 (* 1 = 0.425441 loss)
I0929 09:41:01.758251  1584 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I0929 09:41:15.974925  1584 solver.cpp:218] Iteration 5800 (7.03401 iter/s, 14.2166s/100 iters), loss = 0.463964
I0929 09:41:15.974957  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.463964 (* 1 = 0.463964 loss)
I0929 09:41:15.974967  1584 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I0929 09:41:30.222848  1584 solver.cpp:218] Iteration 5900 (7.0186 iter/s, 14.2478s/100 iters), loss = 0.366991
I0929 09:41:30.222877  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366991 (* 1 = 0.366991 loss)
I0929 09:41:30.222883  1584 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I0929 09:41:43.755218  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:41:44.322662  1584 solver.cpp:330] Iteration 6000, Testing net (#0)
I0929 09:41:47.678128  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:41:47.818567  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6517
I0929 09:41:47.818603  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.961407 (* 1 = 0.961407 loss)
I0929 09:41:47.958855  1584 solver.cpp:218] Iteration 6000 (5.63828 iter/s, 17.7359s/100 iters), loss = 0.400663
I0929 09:41:47.958885  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.400663 (* 1 = 0.400663 loss)
I0929 09:41:47.958892  1584 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I0929 09:42:02.254603  1584 solver.cpp:218] Iteration 6100 (6.99512 iter/s, 14.2957s/100 iters), loss = 0.405193
I0929 09:42:02.254637  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405193 (* 1 = 0.405193 loss)
I0929 09:42:02.254644  1584 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I0929 09:42:16.584604  1584 solver.cpp:218] Iteration 6200 (6.97841 iter/s, 14.3299s/100 iters), loss = 0.409753
I0929 09:42:16.584718  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.409753 (* 1 = 0.409753 loss)
I0929 09:42:16.584727  1584 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I0929 09:42:30.940672  1584 solver.cpp:218] Iteration 6300 (6.96577 iter/s, 14.3559s/100 iters), loss = 0.387993
I0929 09:42:30.940703  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.387993 (* 1 = 0.387993 loss)
I0929 09:42:30.940711  1584 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I0929 09:42:45.307488  1584 solver.cpp:218] Iteration 6400 (6.96053 iter/s, 14.3667s/100 iters), loss = 0.376303
I0929 09:42:45.307528  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.376303 (* 1 = 0.376303 loss)
I0929 09:42:45.307536  1584 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I0929 09:42:59.008884  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:42:59.591641  1584 solver.cpp:330] Iteration 6500, Testing net (#0)
I0929 09:43:02.970988  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:43:03.111847  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7314
I0929 09:43:03.111876  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.792543 (* 1 = 0.792543 loss)
I0929 09:43:03.254039  1584 solver.cpp:218] Iteration 6500 (5.57213 iter/s, 17.9464s/100 iters), loss = 0.352472
I0929 09:43:03.254076  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.352472 (* 1 = 0.352472 loss)
I0929 09:43:03.254084  1584 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I0929 09:43:17.600654  1584 solver.cpp:218] Iteration 6600 (6.97033 iter/s, 14.3465s/100 iters), loss = 0.331907
I0929 09:43:17.600692  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331907 (* 1 = 0.331907 loss)
I0929 09:43:17.600698  1584 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I0929 09:43:32.004976  1584 solver.cpp:218] Iteration 6700 (6.9424 iter/s, 14.4042s/100 iters), loss = 0.486819
I0929 09:43:32.005132  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.486819 (* 1 = 0.486819 loss)
I0929 09:43:32.005143  1584 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I0929 09:43:46.395088  1584 solver.cpp:218] Iteration 6800 (6.94931 iter/s, 14.3899s/100 iters), loss = 0.395052
I0929 09:43:46.395123  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.395052 (* 1 = 0.395052 loss)
I0929 09:43:46.395131  1584 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I0929 09:44:00.804652  1584 solver.cpp:218] Iteration 6900 (6.93988 iter/s, 14.4095s/100 iters), loss = 0.301028
I0929 09:44:00.804685  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301028 (* 1 = 0.301028 loss)
I0929 09:44:00.804692  1584 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I0929 09:44:14.479135  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:44:15.047878  1584 solver.cpp:330] Iteration 7000, Testing net (#0)
I0929 09:44:18.442009  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:44:18.583780  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7005
I0929 09:44:18.583803  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.835991 (* 1 = 0.835991 loss)
I0929 09:44:18.725123  1584 solver.cpp:218] Iteration 7000 (5.58024 iter/s, 17.9204s/100 iters), loss = 0.351109
I0929 09:44:18.725157  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351109 (* 1 = 0.351109 loss)
I0929 09:44:18.725163  1584 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I0929 09:44:33.155441  1584 solver.cpp:218] Iteration 7100 (6.92989 iter/s, 14.4302s/100 iters), loss = 0.3281
I0929 09:44:33.155472  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.3281 (* 1 = 0.3281 loss)
I0929 09:44:33.155478  1584 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I0929 09:44:47.580260  1584 solver.cpp:218] Iteration 7200 (6.93254 iter/s, 14.4247s/100 iters), loss = 0.44903
I0929 09:44:47.580376  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.44903 (* 1 = 0.44903 loss)
I0929 09:44:47.580394  1584 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I0929 09:45:01.964710  1584 solver.cpp:218] Iteration 7300 (6.95203 iter/s, 14.3843s/100 iters), loss = 0.427436
I0929 09:45:01.964787  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.427436 (* 1 = 0.427436 loss)
I0929 09:45:01.964797  1584 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I0929 09:45:16.378520  1584 solver.cpp:218] Iteration 7400 (6.93787 iter/s, 14.4137s/100 iters), loss = 0.320154
I0929 09:45:16.378549  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320154 (* 1 = 0.320154 loss)
I0929 09:45:16.378556  1584 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I0929 09:45:30.070209  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:45:30.639163  1584 solver.cpp:330] Iteration 7500, Testing net (#0)
I0929 09:45:34.040987  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:45:34.182565  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7428
I0929 09:45:34.182591  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.786614 (* 1 = 0.786614 loss)
I0929 09:45:34.323323  1584 solver.cpp:218] Iteration 7500 (5.57267 iter/s, 17.9447s/100 iters), loss = 0.360148
I0929 09:45:34.323352  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.360148 (* 1 = 0.360148 loss)
I0929 09:45:34.323359  1584 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I0929 09:45:48.856151  1584 solver.cpp:218] Iteration 7600 (6.88101 iter/s, 14.5328s/100 iters), loss = 0.364703
I0929 09:45:48.856185  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.364703 (* 1 = 0.364703 loss)
I0929 09:45:48.856192  1584 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I0929 09:46:03.268223  1584 solver.cpp:218] Iteration 7700 (6.93867 iter/s, 14.412s/100 iters), loss = 0.488003
I0929 09:46:03.268355  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.488003 (* 1 = 0.488003 loss)
I0929 09:46:03.268373  1584 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I0929 09:46:17.669994  1584 solver.cpp:218] Iteration 7800 (6.94367 iter/s, 14.4016s/100 iters), loss = 0.365327
I0929 09:46:17.670037  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365327 (* 1 = 0.365327 loss)
I0929 09:46:17.670044  1584 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I0929 09:46:32.086452  1584 solver.cpp:218] Iteration 7900 (6.93656 iter/s, 14.4164s/100 iters), loss = 0.273994
I0929 09:46:32.086486  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273994 (* 1 = 0.273994 loss)
I0929 09:46:32.086493  1584 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I0929 09:46:45.750941  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:46:46.332520  1584 solver.cpp:330] Iteration 8000, Testing net (#0)
I0929 09:46:49.731761  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:46:49.874338  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7308
I0929 09:46:49.874374  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.794634 (* 1 = 0.794634 loss)
I0929 09:46:50.020395  1584 solver.cpp:218] Iteration 8000 (5.57605 iter/s, 17.9338s/100 iters), loss = 0.261135
I0929 09:46:50.020432  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261135 (* 1 = 0.261135 loss)
I0929 09:46:50.020440  1584 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I0929 09:47:04.400941  1584 solver.cpp:218] Iteration 8100 (6.95388 iter/s, 14.3805s/100 iters), loss = 0.321727
I0929 09:47:04.400977  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.321727 (* 1 = 0.321727 loss)
I0929 09:47:04.400985  1584 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I0929 09:47:18.741453  1584 solver.cpp:218] Iteration 8200 (6.97329 iter/s, 14.3404s/100 iters), loss = 0.279154
I0929 09:47:18.741619  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279154 (* 1 = 0.279154 loss)
I0929 09:47:18.741638  1584 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I0929 09:47:33.125440  1584 solver.cpp:218] Iteration 8300 (6.95228 iter/s, 14.3838s/100 iters), loss = 0.347401
I0929 09:47:33.125470  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.347401 (* 1 = 0.347401 loss)
I0929 09:47:33.125476  1584 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I0929 09:47:47.372175  1584 solver.cpp:218] Iteration 8400 (7.01919 iter/s, 14.2467s/100 iters), loss = 0.355952
I0929 09:47:47.372206  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355952 (* 1 = 0.355952 loss)
I0929 09:47:47.372213  1584 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I0929 09:48:00.910504  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:48:01.481799  1584 solver.cpp:330] Iteration 8500, Testing net (#0)
I0929 09:48:04.837939  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:48:04.977170  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7232
I0929 09:48:04.977195  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.801348 (* 1 = 0.801348 loss)
I0929 09:48:05.118372  1584 solver.cpp:218] Iteration 8500 (5.63504 iter/s, 17.7461s/100 iters), loss = 0.272435
I0929 09:48:05.118403  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272435 (* 1 = 0.272435 loss)
I0929 09:48:05.118410  1584 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I0929 09:48:19.342542  1584 solver.cpp:218] Iteration 8600 (7.03033 iter/s, 14.2241s/100 iters), loss = 0.311078
I0929 09:48:19.342591  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311078 (* 1 = 0.311078 loss)
I0929 09:48:19.342597  1584 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I0929 09:48:33.597360  1584 solver.cpp:218] Iteration 8700 (7.01522 iter/s, 14.2547s/100 iters), loss = 0.323697
I0929 09:48:33.597494  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323697 (* 1 = 0.323697 loss)
I0929 09:48:33.597502  1584 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I0929 09:48:47.850797  1584 solver.cpp:218] Iteration 8800 (7.01594 iter/s, 14.2533s/100 iters), loss = 0.310871
I0929 09:48:47.850829  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310871 (* 1 = 0.310871 loss)
I0929 09:48:47.850836  1584 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I0929 09:49:02.091424  1584 solver.cpp:218] Iteration 8900 (7.0222 iter/s, 14.2406s/100 iters), loss = 0.355939
I0929 09:49:02.091456  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355939 (* 1 = 0.355939 loss)
I0929 09:49:02.091464  1584 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I0929 09:49:15.624406  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:49:16.192741  1584 solver.cpp:330] Iteration 9000, Testing net (#0)
I0929 09:49:19.557827  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:49:19.701719  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7588
I0929 09:49:19.701746  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.706938 (* 1 = 0.706938 loss)
I0929 09:49:19.843021  1584 solver.cpp:218] Iteration 9000 (5.63332 iter/s, 17.7515s/100 iters), loss = 0.294404
I0929 09:49:19.843057  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294404 (* 1 = 0.294404 loss)
I0929 09:49:19.843066  1584 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I0929 09:49:34.085722  1584 solver.cpp:218] Iteration 9100 (7.02131 iter/s, 14.2424s/100 iters), loss = 0.269085
I0929 09:49:34.085752  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269085 (* 1 = 0.269085 loss)
I0929 09:49:34.085759  1584 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I0929 09:49:48.339977  1584 solver.cpp:218] Iteration 9200 (7.01549 iter/s, 14.2542s/100 iters), loss = 0.380073
I0929 09:49:48.340095  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.380073 (* 1 = 0.380073 loss)
I0929 09:49:48.340114  1584 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I0929 09:50:02.596300  1584 solver.cpp:218] Iteration 9300 (7.01451 iter/s, 14.2562s/100 iters), loss = 0.323358
I0929 09:50:02.596333  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323358 (* 1 = 0.323358 loss)
I0929 09:50:02.596350  1584 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I0929 09:50:16.857301  1584 solver.cpp:218] Iteration 9400 (7.01217 iter/s, 14.2609s/100 iters), loss = 0.254196
I0929 09:50:16.857338  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254196 (* 1 = 0.254196 loss)
I0929 09:50:16.857347  1584 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I0929 09:50:30.396868  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:50:30.964763  1584 solver.cpp:330] Iteration 9500, Testing net (#0)
I0929 09:50:34.322804  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:50:34.462968  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7839
I0929 09:50:34.462996  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.632885 (* 1 = 0.632885 loss)
I0929 09:50:34.607221  1584 solver.cpp:218] Iteration 9500 (5.63386 iter/s, 17.7498s/100 iters), loss = 0.37198
I0929 09:50:34.607265  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.37198 (* 1 = 0.37198 loss)
I0929 09:50:34.607275  1584 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I0929 09:50:48.822110  1584 solver.cpp:218] Iteration 9600 (7.03492 iter/s, 14.2148s/100 iters), loss = 0.291855
I0929 09:50:48.822146  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291855 (* 1 = 0.291855 loss)
I0929 09:50:48.822155  1584 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I0929 09:51:03.062036  1584 solver.cpp:218] Iteration 9700 (7.02255 iter/s, 14.2398s/100 iters), loss = 0.293944
I0929 09:51:03.062170  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293944 (* 1 = 0.293944 loss)
I0929 09:51:03.062196  1584 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I0929 09:51:17.290006  1584 solver.cpp:218] Iteration 9800 (7.0285 iter/s, 14.2278s/100 iters), loss = 0.461141
I0929 09:51:17.290043  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.461141 (* 1 = 0.461141 loss)
I0929 09:51:17.290052  1584 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I0929 09:51:31.506781  1584 solver.cpp:218] Iteration 9900 (7.03399 iter/s, 14.2167s/100 iters), loss = 0.299781
I0929 09:51:31.506819  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299781 (* 1 = 0.299781 loss)
I0929 09:51:31.506829  1584 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I0929 09:51:45.032013  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:51:45.598767  1584 solver.cpp:330] Iteration 10000, Testing net (#0)
I0929 09:51:48.961118  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:51:49.101027  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7571
I0929 09:51:49.101052  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.72619 (* 1 = 0.72619 loss)
I0929 09:51:49.241773  1584 solver.cpp:218] Iteration 10000 (5.6386 iter/s, 17.7349s/100 iters), loss = 0.409716
I0929 09:51:49.241806  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.409716 (* 1 = 0.409716 loss)
I0929 09:51:49.241816  1584 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I0929 09:52:03.490219  1584 solver.cpp:218] Iteration 10100 (7.01835 iter/s, 14.2484s/100 iters), loss = 0.288805
I0929 09:52:03.490250  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288805 (* 1 = 0.288805 loss)
I0929 09:52:03.490257  1584 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I0929 09:52:17.737738  1584 solver.cpp:218] Iteration 10200 (7.0188 iter/s, 14.2474s/100 iters), loss = 0.371929
I0929 09:52:17.737875  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371929 (* 1 = 0.371929 loss)
I0929 09:52:17.737884  1584 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I0929 09:52:31.984604  1584 solver.cpp:218] Iteration 10300 (7.01918 iter/s, 14.2467s/100 iters), loss = 0.412591
I0929 09:52:31.984635  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.412591 (* 1 = 0.412591 loss)
I0929 09:52:31.984642  1584 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I0929 09:52:46.229159  1584 solver.cpp:218] Iteration 10400 (7.02026 iter/s, 14.2445s/100 iters), loss = 0.249039
I0929 09:52:46.229199  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249039 (* 1 = 0.249039 loss)
I0929 09:52:46.229205  1584 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I0929 09:52:59.769634  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:53:00.337898  1584 solver.cpp:330] Iteration 10500, Testing net (#0)
I0929 09:53:03.698529  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:53:03.838716  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.797
I0929 09:53:03.838752  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.632938 (* 1 = 0.632938 loss)
I0929 09:53:03.980671  1584 solver.cpp:218] Iteration 10500 (5.63335 iter/s, 17.7514s/100 iters), loss = 0.245005
I0929 09:53:03.980705  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245005 (* 1 = 0.245005 loss)
I0929 09:53:03.980712  1584 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I0929 09:53:18.238899  1584 solver.cpp:218] Iteration 10600 (7.01353 iter/s, 14.2582s/100 iters), loss = 0.216721
I0929 09:53:18.238940  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216721 (* 1 = 0.216721 loss)
I0929 09:53:18.238945  1584 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I0929 09:53:32.493243  1584 solver.cpp:218] Iteration 10700 (7.01545 iter/s, 14.2543s/100 iters), loss = 0.299005
I0929 09:53:32.493357  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299005 (* 1 = 0.299005 loss)
I0929 09:53:32.493374  1584 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I0929 09:53:46.767472  1584 solver.cpp:218] Iteration 10800 (7.00571 iter/s, 14.2741s/100 iters), loss = 0.376175
I0929 09:53:46.767506  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.376175 (* 1 = 0.376175 loss)
I0929 09:53:46.767513  1584 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I0929 09:54:00.998874  1584 solver.cpp:218] Iteration 10900 (7.02675 iter/s, 14.2313s/100 iters), loss = 0.282623
I0929 09:54:00.998904  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282623 (* 1 = 0.282623 loss)
I0929 09:54:00.998910  1584 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I0929 09:54:14.543867  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:54:15.110647  1584 solver.cpp:330] Iteration 11000, Testing net (#0)
I0929 09:54:18.471873  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:54:18.611923  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7874
I0929 09:54:18.611948  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.630368 (* 1 = 0.630368 loss)
I0929 09:54:18.752966  1584 solver.cpp:218] Iteration 11000 (5.63253 iter/s, 17.754s/100 iters), loss = 0.35704
I0929 09:54:18.753000  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35704 (* 1 = 0.35704 loss)
I0929 09:54:18.753005  1584 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I0929 09:54:32.998958  1584 solver.cpp:218] Iteration 11100 (7.01956 iter/s, 14.2459s/100 iters), loss = 0.284812
I0929 09:54:32.998989  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284812 (* 1 = 0.284812 loss)
I0929 09:54:32.998996  1584 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I0929 09:54:47.244621  1584 solver.cpp:218] Iteration 11200 (7.01972 iter/s, 14.2456s/100 iters), loss = 0.440355
I0929 09:54:47.244768  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.440355 (* 1 = 0.440355 loss)
I0929 09:54:47.244776  1584 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I0929 09:55:01.493407  1584 solver.cpp:218] Iteration 11300 (7.01824 iter/s, 14.2486s/100 iters), loss = 0.310481
I0929 09:55:01.493443  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310481 (* 1 = 0.310481 loss)
I0929 09:55:01.493459  1584 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I0929 09:55:15.745156  1584 solver.cpp:218] Iteration 11400 (7.01674 iter/s, 14.2516s/100 iters), loss = 0.333596
I0929 09:55:15.745198  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333596 (* 1 = 0.333596 loss)
I0929 09:55:15.745204  1584 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I0929 09:55:29.288108  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:55:29.855906  1584 solver.cpp:330] Iteration 11500, Testing net (#0)
I0929 09:55:33.215795  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:55:33.355543  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7991
I0929 09:55:33.355569  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.610722 (* 1 = 0.610722 loss)
I0929 09:55:33.496573  1584 solver.cpp:218] Iteration 11500 (5.63338 iter/s, 17.7513s/100 iters), loss = 0.24688
I0929 09:55:33.496605  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24688 (* 1 = 0.24688 loss)
I0929 09:55:33.496613  1584 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I0929 09:55:47.829609  1584 solver.cpp:218] Iteration 11600 (6.97693 iter/s, 14.333s/100 iters), loss = 0.32607
I0929 09:55:47.829661  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326071 (* 1 = 0.326071 loss)
I0929 09:55:47.829669  1584 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I0929 09:56:02.142410  1584 solver.cpp:218] Iteration 11700 (6.9868 iter/s, 14.3127s/100 iters), loss = 0.258318
I0929 09:56:02.142462  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258318 (* 1 = 0.258318 loss)
I0929 09:56:02.142472  1584 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I0929 09:56:16.632941  1584 solver.cpp:218] Iteration 11800 (6.9011 iter/s, 14.4904s/100 iters), loss = 0.299587
I0929 09:56:16.632978  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299587 (* 1 = 0.299587 loss)
I0929 09:56:16.632985  1584 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I0929 09:56:31.167335  1584 solver.cpp:218] Iteration 11900 (6.88027 iter/s, 14.5343s/100 iters), loss = 0.250036
I0929 09:56:31.167364  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250036 (* 1 = 0.250036 loss)
I0929 09:56:31.167371  1584 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I0929 09:56:44.878757  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:56:45.447396  1584 solver.cpp:330] Iteration 12000, Testing net (#0)
I0929 09:56:48.871878  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:56:49.017909  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.811
I0929 09:56:49.017933  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.574914 (* 1 = 0.574914 loss)
I0929 09:56:49.158547  1584 solver.cpp:218] Iteration 12000 (5.55829 iter/s, 17.9911s/100 iters), loss = 0.255553
I0929 09:56:49.158576  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255553 (* 1 = 0.255553 loss)
I0929 09:56:49.158582  1584 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I0929 09:57:03.476565  1584 solver.cpp:218] Iteration 12100 (6.98424 iter/s, 14.3179s/100 iters), loss = 0.26626
I0929 09:57:03.476606  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26626 (* 1 = 0.26626 loss)
I0929 09:57:03.476613  1584 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I0929 09:57:17.720141  1584 solver.cpp:218] Iteration 12200 (7.02075 iter/s, 14.2435s/100 iters), loss = 0.312388
I0929 09:57:17.720237  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312388 (* 1 = 0.312388 loss)
I0929 09:57:17.720254  1584 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I0929 09:57:31.959746  1584 solver.cpp:218] Iteration 12300 (7.02274 iter/s, 14.2395s/100 iters), loss = 0.256813
I0929 09:57:31.959779  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256813 (* 1 = 0.256813 loss)
I0929 09:57:31.959786  1584 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I0929 09:57:46.183903  1584 solver.cpp:218] Iteration 12400 (7.03033 iter/s, 14.2241s/100 iters), loss = 0.193049
I0929 09:57:46.183933  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193049 (* 1 = 0.193049 loss)
I0929 09:57:46.183939  1584 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I0929 09:57:59.707101  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:58:00.276774  1584 solver.cpp:330] Iteration 12500, Testing net (#0)
I0929 09:58:03.636155  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:58:03.776160  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6287
I0929 09:58:03.776195  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.55884 (* 1 = 1.55884 loss)
I0929 09:58:03.917037  1584 solver.cpp:218] Iteration 12500 (5.63919 iter/s, 17.7331s/100 iters), loss = 0.213497
I0929 09:58:03.917073  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213497 (* 1 = 0.213497 loss)
I0929 09:58:03.917080  1584 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I0929 09:58:18.160089  1584 solver.cpp:218] Iteration 12600 (7.02101 iter/s, 14.243s/100 iters), loss = 0.279365
I0929 09:58:18.160118  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279365 (* 1 = 0.279365 loss)
I0929 09:58:18.160125  1584 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I0929 09:58:32.393211  1584 solver.cpp:218] Iteration 12700 (7.0259 iter/s, 14.233s/100 iters), loss = 0.366531
I0929 09:58:32.393316  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366531 (* 1 = 0.366531 loss)
I0929 09:58:32.393323  1584 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I0929 09:58:46.611367  1584 solver.cpp:218] Iteration 12800 (7.03333 iter/s, 14.218s/100 iters), loss = 0.322617
I0929 09:58:46.611404  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322617 (* 1 = 0.322617 loss)
I0929 09:58:46.611412  1584 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I0929 09:59:00.843336  1584 solver.cpp:218] Iteration 12900 (7.02647 iter/s, 14.2319s/100 iters), loss = 0.249843
I0929 09:59:00.843365  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249843 (* 1 = 0.249843 loss)
I0929 09:59:00.843371  1584 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I0929 09:59:14.379577  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:59:14.947427  1584 solver.cpp:330] Iteration 13000, Testing net (#0)
I0929 09:59:18.302683  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 09:59:18.442705  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7759
I0929 09:59:18.442729  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.693469 (* 1 = 0.693469 loss)
I0929 09:59:18.583616  1584 solver.cpp:218] Iteration 13000 (5.63692 iter/s, 17.7402s/100 iters), loss = 0.308022
I0929 09:59:18.583645  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308022 (* 1 = 0.308022 loss)
I0929 09:59:18.583652  1584 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I0929 09:59:32.809871  1584 solver.cpp:218] Iteration 13100 (7.02929 iter/s, 14.2262s/100 iters), loss = 0.312799
I0929 09:59:32.809901  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312799 (* 1 = 0.312799 loss)
I0929 09:59:32.809908  1584 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I0929 09:59:47.126799  1584 solver.cpp:218] Iteration 13200 (6.98478 iter/s, 14.3169s/100 iters), loss = 0.299537
I0929 09:59:47.126948  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299537 (* 1 = 0.299537 loss)
I0929 09:59:47.126957  1584 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I0929 10:00:01.523332  1584 solver.cpp:218] Iteration 13300 (6.94621 iter/s, 14.3963s/100 iters), loss = 0.293338
I0929 10:00:01.523382  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293338 (* 1 = 0.293338 loss)
I0929 10:00:01.523401  1584 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I0929 10:00:15.830476  1584 solver.cpp:218] Iteration 13400 (6.98956 iter/s, 14.307s/100 iters), loss = 0.26338
I0929 10:00:15.830504  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263379 (* 1 = 0.263379 loss)
I0929 10:00:15.830510  1584 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I0929 10:00:29.404570  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:00:29.972596  1584 solver.cpp:330] Iteration 13500, Testing net (#0)
I0929 10:00:33.344583  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:00:33.492620  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8156
I0929 10:00:33.492648  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.543639 (* 1 = 0.543639 loss)
I0929 10:00:33.636027  1584 solver.cpp:218] Iteration 13500 (5.61625 iter/s, 17.8055s/100 iters), loss = 0.206141
I0929 10:00:33.636061  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206141 (* 1 = 0.206141 loss)
I0929 10:00:33.636068  1584 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I0929 10:00:47.959776  1584 solver.cpp:218] Iteration 13600 (6.98145 iter/s, 14.3237s/100 iters), loss = 0.368831
I0929 10:00:47.959805  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.368831 (* 1 = 0.368831 loss)
I0929 10:00:47.959811  1584 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I0929 10:01:02.345937  1584 solver.cpp:218] Iteration 13700 (6.95116 iter/s, 14.3861s/100 iters), loss = 0.298121
I0929 10:01:02.346051  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298121 (* 1 = 0.298121 loss)
I0929 10:01:02.346068  1584 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I0929 10:01:16.708176  1584 solver.cpp:218] Iteration 13800 (6.96278 iter/s, 14.3621s/100 iters), loss = 0.32582
I0929 10:01:16.708214  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32582 (* 1 = 0.32582 loss)
I0929 10:01:16.708220  1584 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I0929 10:01:30.990087  1584 solver.cpp:218] Iteration 13900 (7.0019 iter/s, 14.2818s/100 iters), loss = 0.252403
I0929 10:01:30.990119  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252403 (* 1 = 0.252403 loss)
I0929 10:01:30.990126  1584 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I0929 10:01:44.583262  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:01:45.150674  1584 solver.cpp:330] Iteration 14000, Testing net (#0)
I0929 10:01:48.545238  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:01:48.686244  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7128
I0929 10:01:48.686280  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.889433 (* 1 = 0.889433 loss)
I0929 10:01:48.830958  1584 solver.cpp:218] Iteration 14000 (5.60513 iter/s, 17.8408s/100 iters), loss = 0.19844
I0929 10:01:48.830991  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19844 (* 1 = 0.19844 loss)
I0929 10:01:48.830996  1584 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I0929 10:02:03.170011  1584 solver.cpp:218] Iteration 14100 (6.974 iter/s, 14.339s/100 iters), loss = 0.304045
I0929 10:02:03.170042  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304045 (* 1 = 0.304045 loss)
I0929 10:02:03.170048  1584 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I0929 10:02:17.415920  1584 solver.cpp:218] Iteration 14200 (7.0196 iter/s, 14.2458s/100 iters), loss = 0.374813
I0929 10:02:17.416041  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.374813 (* 1 = 0.374813 loss)
I0929 10:02:17.416049  1584 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I0929 10:02:31.889919  1584 solver.cpp:218] Iteration 14300 (6.90902 iter/s, 14.4738s/100 iters), loss = 0.253483
I0929 10:02:31.889952  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253483 (* 1 = 0.253483 loss)
I0929 10:02:31.889960  1584 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I0929 10:02:46.168557  1584 solver.cpp:218] Iteration 14400 (7.00351 iter/s, 14.2786s/100 iters), loss = 0.170943
I0929 10:02:46.168601  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170943 (* 1 = 0.170943 loss)
I0929 10:02:46.168608  1584 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I0929 10:03:00.056432  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:03:00.625519  1584 solver.cpp:330] Iteration 14500, Testing net (#0)
I0929 10:03:03.986512  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:03:04.126652  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7742
I0929 10:03:04.126677  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.691529 (* 1 = 0.691529 loss)
I0929 10:03:04.266639  1584 solver.cpp:218] Iteration 14500 (5.52548 iter/s, 18.098s/100 iters), loss = 0.152594
I0929 10:03:04.266669  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152594 (* 1 = 0.152594 loss)
I0929 10:03:04.266675  1584 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I0929 10:03:18.495254  1584 solver.cpp:218] Iteration 14600 (7.02813 iter/s, 14.2285s/100 iters), loss = 0.239073
I0929 10:03:18.495295  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239073 (* 1 = 0.239073 loss)
I0929 10:03:18.495301  1584 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I0929 10:03:32.900758  1584 solver.cpp:218] Iteration 14700 (6.94183 iter/s, 14.4054s/100 iters), loss = 0.320396
I0929 10:03:32.900866  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320395 (* 1 = 0.320395 loss)
I0929 10:03:32.900874  1584 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I0929 10:03:47.324223  1584 solver.cpp:218] Iteration 14800 (6.93322 iter/s, 14.4233s/100 iters), loss = 0.334007
I0929 10:03:47.324252  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.334007 (* 1 = 0.334007 loss)
I0929 10:03:47.324259  1584 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I0929 10:04:01.737433  1584 solver.cpp:218] Iteration 14900 (6.93812 iter/s, 14.4131s/100 iters), loss = 0.264753
I0929 10:04:01.737483  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264753 (* 1 = 0.264753 loss)
I0929 10:04:01.737490  1584 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I0929 10:04:15.349609  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:04:15.919586  1584 solver.cpp:330] Iteration 15000, Testing net (#0)
I0929 10:04:19.297881  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:04:19.438896  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7818
I0929 10:04:19.438931  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.678401 (* 1 = 0.678401 loss)
I0929 10:04:19.582563  1584 solver.cpp:218] Iteration 15000 (5.60381 iter/s, 17.845s/100 iters), loss = 0.244272
I0929 10:04:19.582599  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244272 (* 1 = 0.244272 loss)
I0929 10:04:19.582607  1584 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I0929 10:04:33.887250  1584 solver.cpp:218] Iteration 15100 (6.99075 iter/s, 14.3046s/100 iters), loss = 0.326376
I0929 10:04:33.887282  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326376 (* 1 = 0.326376 loss)
I0929 10:04:33.887289  1584 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I0929 10:04:48.251988  1584 solver.cpp:218] Iteration 15200 (6.96153 iter/s, 14.3647s/100 iters), loss = 0.23507
I0929 10:04:48.252110  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23507 (* 1 = 0.23507 loss)
I0929 10:04:48.252118  1584 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I0929 10:05:02.633395  1584 solver.cpp:218] Iteration 15300 (6.9535 iter/s, 14.3812s/100 iters), loss = 0.291878
I0929 10:05:02.633440  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291878 (* 1 = 0.291878 loss)
I0929 10:05:02.633447  1584 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I0929 10:05:16.934803  1584 solver.cpp:218] Iteration 15400 (6.99236 iter/s, 14.3013s/100 iters), loss = 0.147758
I0929 10:05:16.934835  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147758 (* 1 = 0.147758 loss)
I0929 10:05:16.934842  1584 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I0929 10:05:30.503303  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:05:31.072010  1584 solver.cpp:330] Iteration 15500, Testing net (#0)
I0929 10:05:34.441061  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:05:34.582671  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8322
I0929 10:05:34.582698  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.497144 (* 1 = 0.497144 loss)
I0929 10:05:34.727368  1584 solver.cpp:218] Iteration 15500 (5.62035 iter/s, 17.7925s/100 iters), loss = 0.240534
I0929 10:05:34.727406  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240534 (* 1 = 0.240534 loss)
I0929 10:05:34.727413  1584 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I0929 10:05:48.964010  1584 solver.cpp:218] Iteration 15600 (7.02417 iter/s, 14.2366s/100 iters), loss = 0.225297
I0929 10:05:48.964038  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225296 (* 1 = 0.225296 loss)
I0929 10:05:48.964046  1584 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I0929 10:06:03.202527  1584 solver.cpp:218] Iteration 15700 (7.02324 iter/s, 14.2384s/100 iters), loss = 0.315521
I0929 10:06:03.202646  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31552 (* 1 = 0.31552 loss)
I0929 10:06:03.202653  1584 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I0929 10:06:17.495756  1584 solver.cpp:218] Iteration 15800 (6.9964 iter/s, 14.2931s/100 iters), loss = 0.249848
I0929 10:06:17.495790  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249847 (* 1 = 0.249847 loss)
I0929 10:06:17.495796  1584 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I0929 10:06:31.831562  1584 solver.cpp:218] Iteration 15900 (6.97558 iter/s, 14.3357s/100 iters), loss = 0.276862
I0929 10:06:31.831609  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276861 (* 1 = 0.276861 loss)
I0929 10:06:31.831616  1584 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I0929 10:06:45.367089  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:06:45.935416  1584 solver.cpp:330] Iteration 16000, Testing net (#0)
I0929 10:06:49.528515  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:06:49.672966  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7827
I0929 10:06:49.673005  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.738851 (* 1 = 0.738851 loss)
I0929 10:06:49.817203  1584 solver.cpp:218] Iteration 16000 (5.56003 iter/s, 17.9855s/100 iters), loss = 0.217708
I0929 10:06:49.817239  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217708 (* 1 = 0.217708 loss)
I0929 10:06:49.817248  1584 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I0929 10:07:04.243042  1584 solver.cpp:218] Iteration 16100 (6.93204 iter/s, 14.4258s/100 iters), loss = 0.182211
I0929 10:07:04.243072  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182211 (* 1 = 0.182211 loss)
I0929 10:07:04.243078  1584 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I0929 10:07:18.681792  1584 solver.cpp:218] Iteration 16200 (6.92584 iter/s, 14.4387s/100 iters), loss = 0.236274
I0929 10:07:18.681922  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236274 (* 1 = 0.236274 loss)
I0929 10:07:18.681931  1584 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I0929 10:07:32.981933  1584 solver.cpp:218] Iteration 16300 (6.99302 iter/s, 14.3s/100 iters), loss = 0.212421
I0929 10:07:32.981963  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21242 (* 1 = 0.21242 loss)
I0929 10:07:32.981969  1584 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I0929 10:07:47.327316  1584 solver.cpp:218] Iteration 16400 (6.97092 iter/s, 14.3453s/100 iters), loss = 0.20739
I0929 10:07:47.327348  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20739 (* 1 = 0.20739 loss)
I0929 10:07:47.327355  1584 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I0929 10:08:00.860744  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:08:01.428759  1584 solver.cpp:330] Iteration 16500, Testing net (#0)
I0929 10:08:04.821104  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:08:04.962113  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8128
I0929 10:08:04.962137  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.560208 (* 1 = 0.560208 loss)
I0929 10:08:05.103886  1584 solver.cpp:218] Iteration 16500 (5.62541 iter/s, 17.7765s/100 iters), loss = 0.210283
I0929 10:08:05.103920  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210283 (* 1 = 0.210283 loss)
I0929 10:08:05.103926  1584 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I0929 10:08:19.384840  1584 solver.cpp:218] Iteration 16600 (7.00237 iter/s, 14.2809s/100 iters), loss = 0.173635
I0929 10:08:19.384879  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173635 (* 1 = 0.173635 loss)
I0929 10:08:19.384886  1584 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I0929 10:08:33.645335  1584 solver.cpp:218] Iteration 16700 (7.01242 iter/s, 14.2604s/100 iters), loss = 0.235218
I0929 10:08:33.645473  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235218 (* 1 = 0.235218 loss)
I0929 10:08:33.645481  1584 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I0929 10:08:47.897933  1584 solver.cpp:218] Iteration 16800 (7.01635 iter/s, 14.2524s/100 iters), loss = 0.289725
I0929 10:08:47.897961  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289725 (* 1 = 0.289725 loss)
I0929 10:08:47.897967  1584 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I0929 10:09:02.139320  1584 solver.cpp:218] Iteration 16900 (7.02182 iter/s, 14.2413s/100 iters), loss = 0.272734
I0929 10:09:02.139353  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272734 (* 1 = 0.272734 loss)
I0929 10:09:02.139359  1584 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I0929 10:09:15.729921  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:09:16.299412  1584 solver.cpp:330] Iteration 17000, Testing net (#0)
I0929 10:09:19.663556  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:09:19.807901  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7826
I0929 10:09:19.807926  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.696002 (* 1 = 0.696002 loss)
I0929 10:09:19.949834  1584 solver.cpp:218] Iteration 17000 (5.61469 iter/s, 17.8104s/100 iters), loss = 0.165528
I0929 10:09:19.949868  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165528 (* 1 = 0.165528 loss)
I0929 10:09:19.949875  1584 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I0929 10:09:34.183743  1584 solver.cpp:218] Iteration 17100 (7.02552 iter/s, 14.2338s/100 iters), loss = 0.200566
I0929 10:09:34.183773  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200565 (* 1 = 0.200565 loss)
I0929 10:09:34.183779  1584 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I0929 10:09:48.520687  1584 solver.cpp:218] Iteration 17200 (6.97502 iter/s, 14.3369s/100 iters), loss = 0.292593
I0929 10:09:48.520802  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292593 (* 1 = 0.292593 loss)
I0929 10:09:48.520819  1584 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I0929 10:10:02.999300  1584 solver.cpp:218] Iteration 17300 (6.90682 iter/s, 14.4785s/100 iters), loss = 0.312361
I0929 10:10:02.999346  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312361 (* 1 = 0.312361 loss)
I0929 10:10:02.999354  1584 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I0929 10:10:17.479307  1584 solver.cpp:218] Iteration 17400 (6.9063 iter/s, 14.4795s/100 iters), loss = 0.259686
I0929 10:10:17.479337  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259686 (* 1 = 0.259686 loss)
I0929 10:10:17.479354  1584 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I0929 10:10:31.111289  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:10:31.688483  1584 solver.cpp:330] Iteration 17500, Testing net (#0)
I0929 10:10:35.063289  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:10:35.203533  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7889
I0929 10:10:35.203558  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.667234 (* 1 = 0.667234 loss)
I0929 10:10:35.344785  1584 solver.cpp:218] Iteration 17500 (5.59741 iter/s, 17.8654s/100 iters), loss = 0.209002
I0929 10:10:35.344813  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209002 (* 1 = 0.209002 loss)
I0929 10:10:35.344820  1584 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I0929 10:10:49.704248  1584 solver.cpp:218] Iteration 17600 (6.96408 iter/s, 14.3594s/100 iters), loss = 0.212505
I0929 10:10:49.704298  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212505 (* 1 = 0.212505 loss)
I0929 10:10:49.704305  1584 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I0929 10:11:04.131278  1584 solver.cpp:218] Iteration 17700 (6.9315 iter/s, 14.4269s/100 iters), loss = 0.226285
I0929 10:11:04.131376  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226285 (* 1 = 0.226285 loss)
I0929 10:11:04.131393  1584 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I0929 10:11:18.588732  1584 solver.cpp:218] Iteration 17800 (6.91691 iter/s, 14.4573s/100 iters), loss = 0.16977
I0929 10:11:18.588768  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16977 (* 1 = 0.16977 loss)
I0929 10:11:18.588775  1584 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I0929 10:11:32.895978  1584 solver.cpp:218] Iteration 17900 (6.9895 iter/s, 14.3072s/100 iters), loss = 0.283592
I0929 10:11:32.896019  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283592 (* 1 = 0.283592 loss)
I0929 10:11:32.896025  1584 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I0929 10:11:46.570796  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:11:47.159122  1584 solver.cpp:330] Iteration 18000, Testing net (#0)
I0929 10:11:50.596971  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:11:50.735596  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.776
I0929 10:11:50.735630  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.671741 (* 1 = 0.671741 loss)
I0929 10:11:50.876329  1584 solver.cpp:218] Iteration 18000 (5.56165 iter/s, 17.9803s/100 iters), loss = 0.211496
I0929 10:11:50.876361  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211496 (* 1 = 0.211496 loss)
I0929 10:11:50.876368  1584 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I0929 10:12:05.298566  1584 solver.cpp:218] Iteration 18100 (6.93377 iter/s, 14.4222s/100 iters), loss = 0.228614
I0929 10:12:05.298609  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228614 (* 1 = 0.228614 loss)
I0929 10:12:05.298615  1584 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I0929 10:12:19.534730  1584 solver.cpp:218] Iteration 18200 (7.02441 iter/s, 14.2361s/100 iters), loss = 0.242364
I0929 10:12:19.534854  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242364 (* 1 = 0.242364 loss)
I0929 10:12:19.534873  1584 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I0929 10:12:33.817106  1584 solver.cpp:218] Iteration 18300 (7.00172 iter/s, 14.2822s/100 iters), loss = 0.142438
I0929 10:12:33.817142  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142438 (* 1 = 0.142438 loss)
I0929 10:12:33.817148  1584 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I0929 10:12:48.099200  1584 solver.cpp:218] Iteration 18400 (7.00181 iter/s, 14.282s/100 iters), loss = 0.252659
I0929 10:12:48.099227  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252659 (* 1 = 0.252659 loss)
I0929 10:12:48.099233  1584 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I0929 10:13:01.613925  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:13:02.188550  1584 solver.cpp:330] Iteration 18500, Testing net (#0)
I0929 10:13:05.545642  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:13:05.685672  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7925
I0929 10:13:05.685696  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.679401 (* 1 = 0.679401 loss)
I0929 10:13:05.825853  1584 solver.cpp:218] Iteration 18500 (5.64125 iter/s, 17.7266s/100 iters), loss = 0.173965
I0929 10:13:05.825881  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173965 (* 1 = 0.173965 loss)
I0929 10:13:05.825888  1584 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I0929 10:13:20.174051  1584 solver.cpp:218] Iteration 18600 (6.96955 iter/s, 14.3481s/100 iters), loss = 0.243428
I0929 10:13:20.174082  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243428 (* 1 = 0.243428 loss)
I0929 10:13:20.174089  1584 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I0929 10:13:34.501495  1584 solver.cpp:218] Iteration 18700 (6.97965 iter/s, 14.3274s/100 iters), loss = 0.246957
I0929 10:13:34.501608  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246956 (* 1 = 0.246956 loss)
I0929 10:13:34.501617  1584 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I0929 10:13:48.842569  1584 solver.cpp:218] Iteration 18800 (6.97305 iter/s, 14.3409s/100 iters), loss = 0.232833
I0929 10:13:48.842602  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232833 (* 1 = 0.232833 loss)
I0929 10:13:48.842607  1584 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I0929 10:14:03.088332  1584 solver.cpp:218] Iteration 18900 (7.01967 iter/s, 14.2457s/100 iters), loss = 0.206194
I0929 10:14:03.088362  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206194 (* 1 = 0.206194 loss)
I0929 10:14:03.088368  1584 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I0929 10:14:16.661396  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:14:17.235997  1584 solver.cpp:330] Iteration 19000, Testing net (#0)
I0929 10:14:20.595234  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:14:20.735467  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8353
I0929 10:14:20.735491  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.481878 (* 1 = 0.481878 loss)
I0929 10:14:20.876200  1584 solver.cpp:218] Iteration 19000 (5.62183 iter/s, 17.7878s/100 iters), loss = 0.240182
I0929 10:14:20.876230  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240182 (* 1 = 0.240182 loss)
I0929 10:14:20.876237  1584 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I0929 10:14:35.117862  1584 solver.cpp:218] Iteration 19100 (7.02169 iter/s, 14.2416s/100 iters), loss = 0.234206
I0929 10:14:35.117893  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234206 (* 1 = 0.234206 loss)
I0929 10:14:35.117899  1584 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I0929 10:14:49.350564  1584 solver.cpp:218] Iteration 19200 (7.02611 iter/s, 14.2326s/100 iters), loss = 0.275432
I0929 10:14:49.350708  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275432 (* 1 = 0.275432 loss)
I0929 10:14:49.350715  1584 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I0929 10:15:03.791654  1584 solver.cpp:218] Iteration 19300 (6.92477 iter/s, 14.4409s/100 iters), loss = 0.204024
I0929 10:15:03.791687  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204024 (* 1 = 0.204024 loss)
I0929 10:15:03.791694  1584 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I0929 10:15:18.104953  1584 solver.cpp:218] Iteration 19400 (6.98655 iter/s, 14.3132s/100 iters), loss = 0.181264
I0929 10:15:18.104998  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181264 (* 1 = 0.181264 loss)
I0929 10:15:18.105006  1584 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I0929 10:15:31.759475  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:15:32.339788  1584 solver.cpp:330] Iteration 19500, Testing net (#0)
I0929 10:15:35.943883  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:15:36.083896  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8004
I0929 10:15:36.083922  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.591329 (* 1 = 0.591329 loss)
I0929 10:15:36.224984  1584 solver.cpp:218] Iteration 19500 (5.51878 iter/s, 18.1199s/100 iters), loss = 0.304998
I0929 10:15:36.225020  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304997 (* 1 = 0.304997 loss)
I0929 10:15:36.225029  1584 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I0929 10:15:50.487211  1584 solver.cpp:218] Iteration 19600 (7.01156 iter/s, 14.2622s/100 iters), loss = 0.151995
I0929 10:15:50.487242  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151995 (* 1 = 0.151995 loss)
I0929 10:15:50.487248  1584 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I0929 10:16:04.756353  1584 solver.cpp:218] Iteration 19700 (7.00817 iter/s, 14.2691s/100 iters), loss = 0.230427
I0929 10:16:04.756464  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230427 (* 1 = 0.230427 loss)
I0929 10:16:04.756484  1584 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I0929 10:16:19.063258  1584 solver.cpp:218] Iteration 19800 (6.98973 iter/s, 14.3067s/100 iters), loss = 0.207669
I0929 10:16:19.063288  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207669 (* 1 = 0.207669 loss)
I0929 10:16:19.063294  1584 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I0929 10:16:33.441917  1584 solver.cpp:218] Iteration 19900 (6.95479 iter/s, 14.3786s/100 iters), loss = 0.224038
I0929 10:16:33.441949  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224038 (* 1 = 0.224038 loss)
I0929 10:16:33.441956  1584 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I0929 10:16:47.051291  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:16:47.634459  1584 solver.cpp:330] Iteration 20000, Testing net (#0)
I0929 10:16:51.020475  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:16:51.160265  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7142
I0929 10:16:51.160300  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.964299 (* 1 = 0.964299 loss)
I0929 10:16:51.300902  1584 solver.cpp:218] Iteration 20000 (5.59945 iter/s, 17.8589s/100 iters), loss = 0.259262
I0929 10:16:51.300930  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259262 (* 1 = 0.259262 loss)
I0929 10:16:51.300936  1584 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I0929 10:17:05.543123  1584 solver.cpp:218] Iteration 20100 (7.02141 iter/s, 14.2421s/100 iters), loss = 0.189118
I0929 10:17:05.543153  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189118 (* 1 = 0.189118 loss)
I0929 10:17:05.543159  1584 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I0929 10:17:19.787786  1584 solver.cpp:218] Iteration 20200 (7.02021 iter/s, 14.2446s/100 iters), loss = 0.248886
I0929 10:17:19.787910  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248886 (* 1 = 0.248886 loss)
I0929 10:17:19.787920  1584 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I0929 10:17:34.034456  1584 solver.cpp:218] Iteration 20300 (7.01927 iter/s, 14.2465s/100 iters), loss = 0.261205
I0929 10:17:34.034490  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261205 (* 1 = 0.261205 loss)
I0929 10:17:34.034497  1584 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I0929 10:17:48.279436  1584 solver.cpp:218] Iteration 20400 (7.02005 iter/s, 14.2449s/100 iters), loss = 0.143634
I0929 10:17:48.279466  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143634 (* 1 = 0.143634 loss)
I0929 10:17:48.279472  1584 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I0929 10:18:01.809875  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:18:02.381918  1584 solver.cpp:330] Iteration 20500, Testing net (#0)
I0929 10:18:05.741094  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:18:05.881011  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7652
I0929 10:18:05.881045  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.770929 (* 1 = 0.770929 loss)
I0929 10:18:06.021858  1584 solver.cpp:218] Iteration 20500 (5.63624 iter/s, 17.7423s/100 iters), loss = 0.19008
I0929 10:18:06.021890  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19008 (* 1 = 0.19008 loss)
I0929 10:18:06.021896  1584 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I0929 10:18:20.269901  1584 solver.cpp:218] Iteration 20600 (7.01854 iter/s, 14.248s/100 iters), loss = 0.209064
I0929 10:18:20.269943  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209064 (* 1 = 0.209064 loss)
I0929 10:18:20.269950  1584 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I0929 10:18:34.503696  1584 solver.cpp:218] Iteration 20700 (7.02558 iter/s, 14.2337s/100 iters), loss = 0.222866
I0929 10:18:34.503839  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222865 (* 1 = 0.222865 loss)
I0929 10:18:34.503846  1584 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I0929 10:18:48.805281  1584 solver.cpp:218] Iteration 20800 (6.99232 iter/s, 14.3014s/100 iters), loss = 0.186519
I0929 10:18:48.805312  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186519 (* 1 = 0.186519 loss)
I0929 10:18:48.805318  1584 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I0929 10:19:03.203236  1584 solver.cpp:218] Iteration 20900 (6.94547 iter/s, 14.3979s/100 iters), loss = 0.148416
I0929 10:19:03.203267  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148416 (* 1 = 0.148416 loss)
I0929 10:19:03.203274  1584 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I0929 10:19:16.826171  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:19:17.395478  1584 solver.cpp:330] Iteration 21000, Testing net (#0)
I0929 10:19:20.810830  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:19:20.958997  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8176
I0929 10:19:20.959024  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.548501 (* 1 = 0.548501 loss)
I0929 10:19:21.131045  1584 solver.cpp:218] Iteration 21000 (5.57795 iter/s, 17.9277s/100 iters), loss = 0.234717
I0929 10:19:21.131091  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234717 (* 1 = 0.234717 loss)
I0929 10:19:21.131098  1584 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I0929 10:19:35.483026  1584 solver.cpp:218] Iteration 21100 (6.96824 iter/s, 14.3508s/100 iters), loss = 0.145079
I0929 10:19:35.483070  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145079 (* 1 = 0.145079 loss)
I0929 10:19:35.483078  1584 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I0929 10:19:50.157032  1584 solver.cpp:218] Iteration 21200 (6.81481 iter/s, 14.6739s/100 iters), loss = 0.179757
I0929 10:19:50.157207  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179756 (* 1 = 0.179756 loss)
I0929 10:19:50.157217  1584 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I0929 10:20:04.767076  1584 solver.cpp:218] Iteration 21300 (6.8447 iter/s, 14.6098s/100 iters), loss = 0.239364
I0929 10:20:04.767112  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239364 (* 1 = 0.239364 loss)
I0929 10:20:04.767119  1584 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I0929 10:20:18.991978  1584 solver.cpp:218] Iteration 21400 (7.02996 iter/s, 14.2248s/100 iters), loss = 0.212718
I0929 10:20:18.992010  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212718 (* 1 = 0.212718 loss)
I0929 10:20:18.992017  1584 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I0929 10:20:32.525540  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:20:33.093812  1584 solver.cpp:330] Iteration 21500, Testing net (#0)
I0929 10:20:36.453989  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:20:36.594640  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7964
I0929 10:20:36.594666  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.635661 (* 1 = 0.635661 loss)
I0929 10:20:36.736286  1584 solver.cpp:218] Iteration 21500 (5.63564 iter/s, 17.7442s/100 iters), loss = 0.149236
I0929 10:20:36.736320  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149236 (* 1 = 0.149236 loss)
I0929 10:20:36.736327  1584 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I0929 10:20:50.984004  1584 solver.cpp:218] Iteration 21600 (7.01871 iter/s, 14.2476s/100 iters), loss = 0.184148
I0929 10:20:50.984035  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184148 (* 1 = 0.184148 loss)
I0929 10:20:50.984040  1584 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I0929 10:21:05.220852  1584 solver.cpp:218] Iteration 21700 (7.02406 iter/s, 14.2368s/100 iters), loss = 0.341651
I0929 10:21:05.220952  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.341651 (* 1 = 0.341651 loss)
I0929 10:21:05.220958  1584 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I0929 10:21:19.454459  1584 solver.cpp:218] Iteration 21800 (7.0257 iter/s, 14.2335s/100 iters), loss = 0.197732
I0929 10:21:19.454501  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197732 (* 1 = 0.197732 loss)
I0929 10:21:19.454509  1584 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I0929 10:21:33.699882  1584 solver.cpp:218] Iteration 21900 (7.01984 iter/s, 14.2453s/100 iters), loss = 0.23674
I0929 10:21:33.699913  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23674 (* 1 = 0.23674 loss)
I0929 10:21:33.699918  1584 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I0929 10:21:47.230180  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:21:47.798707  1584 solver.cpp:330] Iteration 22000, Testing net (#0)
I0929 10:21:51.154593  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:21:51.294199  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.801
I0929 10:21:51.294234  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.600353 (* 1 = 0.600353 loss)
I0929 10:21:51.434526  1584 solver.cpp:218] Iteration 22000 (5.63871 iter/s, 17.7346s/100 iters), loss = 0.193596
I0929 10:21:51.434554  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193595 (* 1 = 0.193595 loss)
I0929 10:21:51.434561  1584 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I0929 10:22:05.675134  1584 solver.cpp:218] Iteration 22100 (7.02221 iter/s, 14.2405s/100 iters), loss = 0.22453
I0929 10:22:05.675164  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22453 (* 1 = 0.22453 loss)
I0929 10:22:05.675170  1584 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I0929 10:22:19.918790  1584 solver.cpp:218] Iteration 22200 (7.02071 iter/s, 14.2436s/100 iters), loss = 0.291266
I0929 10:22:19.918936  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291266 (* 1 = 0.291266 loss)
I0929 10:22:19.918946  1584 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I0929 10:22:34.150001  1584 solver.cpp:218] Iteration 22300 (7.02691 iter/s, 14.231s/100 iters), loss = 0.24034
I0929 10:22:34.150030  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24034 (* 1 = 0.24034 loss)
I0929 10:22:34.150037  1584 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I0929 10:22:48.385294  1584 solver.cpp:218] Iteration 22400 (7.02483 iter/s, 14.2352s/100 iters), loss = 0.170628
I0929 10:22:48.385329  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170628 (* 1 = 0.170628 loss)
I0929 10:22:48.385334  1584 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I0929 10:23:01.925108  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:23:02.494596  1584 solver.cpp:330] Iteration 22500, Testing net (#0)
I0929 10:23:05.853453  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:23:05.993060  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7559
I0929 10:23:05.993085  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.819796 (* 1 = 0.819796 loss)
I0929 10:23:06.133546  1584 solver.cpp:218] Iteration 22500 (5.63438 iter/s, 17.7482s/100 iters), loss = 0.136049
I0929 10:23:06.133577  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136048 (* 1 = 0.136048 loss)
I0929 10:23:06.133584  1584 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I0929 10:23:20.377988  1584 solver.cpp:218] Iteration 22600 (7.02032 iter/s, 14.2444s/100 iters), loss = 0.131513
I0929 10:23:20.378021  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.131513 (* 1 = 0.131513 loss)
I0929 10:23:20.378027  1584 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I0929 10:23:34.613209  1584 solver.cpp:218] Iteration 22700 (7.02487 iter/s, 14.2351s/100 iters), loss = 0.254507
I0929 10:23:34.613339  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254507 (* 1 = 0.254507 loss)
I0929 10:23:34.613348  1584 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I0929 10:23:48.852370  1584 solver.cpp:218] Iteration 22800 (7.02297 iter/s, 14.239s/100 iters), loss = 0.239857
I0929 10:23:48.852401  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239856 (* 1 = 0.239856 loss)
I0929 10:23:48.852406  1584 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I0929 10:24:03.128305  1584 solver.cpp:218] Iteration 22900 (7.00483 iter/s, 14.2759s/100 iters), loss = 0.227483
I0929 10:24:03.128338  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227483 (* 1 = 0.227483 loss)
I0929 10:24:03.128345  1584 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I0929 10:24:16.724092  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:24:17.297489  1584 solver.cpp:330] Iteration 23000, Testing net (#0)
I0929 10:24:20.657816  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:24:20.797324  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7773
I0929 10:24:20.797359  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.711021 (* 1 = 0.711021 loss)
I0929 10:24:20.938835  1584 solver.cpp:218] Iteration 23000 (5.61468 iter/s, 17.8104s/100 iters), loss = 0.24501
I0929 10:24:20.938869  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245009 (* 1 = 0.245009 loss)
I0929 10:24:20.938876  1584 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I0929 10:24:35.200534  1584 solver.cpp:218] Iteration 23100 (7.01182 iter/s, 14.2616s/100 iters), loss = 0.229484
I0929 10:24:35.200564  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229484 (* 1 = 0.229484 loss)
I0929 10:24:35.200572  1584 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I0929 10:24:49.440631  1584 solver.cpp:218] Iteration 23200 (7.02246 iter/s, 14.24s/100 iters), loss = 0.229026
I0929 10:24:49.440812  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229025 (* 1 = 0.229025 loss)
I0929 10:24:49.440822  1584 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I0929 10:25:03.683641  1584 solver.cpp:218] Iteration 23300 (7.02109 iter/s, 14.2428s/100 iters), loss = 0.178752
I0929 10:25:03.683675  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178752 (* 1 = 0.178752 loss)
I0929 10:25:03.683681  1584 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I0929 10:25:17.938405  1584 solver.cpp:218] Iteration 23400 (7.01523 iter/s, 14.2547s/100 iters), loss = 0.241872
I0929 10:25:17.938436  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241871 (* 1 = 0.241871 loss)
I0929 10:25:17.938442  1584 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I0929 10:25:31.482146  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:25:32.060947  1584 solver.cpp:330] Iteration 23500, Testing net (#0)
I0929 10:25:35.417189  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:25:35.557392  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7599
I0929 10:25:35.557428  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.77167 (* 1 = 0.77167 loss)
I0929 10:25:35.698649  1584 solver.cpp:218] Iteration 23500 (5.63058 iter/s, 17.7602s/100 iters), loss = 0.223836
I0929 10:25:35.698678  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223836 (* 1 = 0.223836 loss)
I0929 10:25:35.698684  1584 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I0929 10:25:50.092492  1584 solver.cpp:218] Iteration 23600 (6.94745 iter/s, 14.3938s/100 iters), loss = 0.218147
I0929 10:25:50.092568  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218147 (* 1 = 0.218147 loss)
I0929 10:25:50.092577  1584 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I0929 10:26:04.464653  1584 solver.cpp:218] Iteration 23700 (6.95803 iter/s, 14.3719s/100 iters), loss = 0.265234
I0929 10:26:04.464797  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265234 (* 1 = 0.265234 loss)
I0929 10:26:04.464807  1584 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I0929 10:26:18.795711  1584 solver.cpp:218] Iteration 23800 (6.97794 iter/s, 14.3309s/100 iters), loss = 0.257565
I0929 10:26:18.795745  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257565 (* 1 = 0.257565 loss)
I0929 10:26:18.795753  1584 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I0929 10:26:33.343729  1584 solver.cpp:218] Iteration 23900 (6.87383 iter/s, 14.5479s/100 iters), loss = 0.180377
I0929 10:26:33.343765  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180376 (* 1 = 0.180376 loss)
I0929 10:26:33.343771  1584 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I0929 10:26:46.971397  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:26:47.544842  1584 solver.cpp:330] Iteration 24000, Testing net (#0)
I0929 10:26:50.945487  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:26:51.085147  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7469
I0929 10:26:51.085183  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.799133 (* 1 = 0.799133 loss)
I0929 10:26:51.225945  1584 solver.cpp:218] Iteration 24000 (5.59217 iter/s, 17.8821s/100 iters), loss = 0.163535
I0929 10:26:51.225975  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163535 (* 1 = 0.163535 loss)
I0929 10:26:51.225982  1584 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I0929 10:27:05.569710  1584 solver.cpp:218] Iteration 24100 (6.97171 iter/s, 14.3437s/100 iters), loss = 0.188414
I0929 10:27:05.569758  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188414 (* 1 = 0.188414 loss)
I0929 10:27:05.569767  1584 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I0929 10:27:19.900907  1584 solver.cpp:218] Iteration 24200 (6.97783 iter/s, 14.3311s/100 iters), loss = 0.205947
I0929 10:27:19.901089  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205947 (* 1 = 0.205947 loss)
I0929 10:27:19.901113  1584 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I0929 10:27:34.139750  1584 solver.cpp:218] Iteration 24300 (7.02315 iter/s, 14.2386s/100 iters), loss = 0.148531
I0929 10:27:34.139793  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148531 (* 1 = 0.148531 loss)
I0929 10:27:34.139811  1584 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I0929 10:27:48.378690  1584 solver.cpp:218] Iteration 24400 (7.02304 iter/s, 14.2389s/100 iters), loss = 0.218105
I0929 10:27:48.378723  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218105 (* 1 = 0.218105 loss)
I0929 10:27:48.378731  1584 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I0929 10:28:01.918516  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:28:02.488245  1584 solver.cpp:330] Iteration 24500, Testing net (#0)
I0929 10:28:05.842121  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:28:05.982478  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8414
I0929 10:28:05.982503  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.476788 (* 1 = 0.476788 loss)
I0929 10:28:06.122925  1584 solver.cpp:218] Iteration 24500 (5.63566 iter/s, 17.7442s/100 iters), loss = 0.146371
I0929 10:28:06.122953  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146371 (* 1 = 0.146371 loss)
I0929 10:28:06.122959  1584 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I0929 10:28:20.350134  1584 solver.cpp:218] Iteration 24600 (7.02882 iter/s, 14.2271s/100 iters), loss = 0.218188
I0929 10:28:20.350178  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218188 (* 1 = 0.218188 loss)
I0929 10:28:20.350183  1584 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I0929 10:28:34.579341  1584 solver.cpp:218] Iteration 24700 (7.02784 iter/s, 14.2291s/100 iters), loss = 0.267518
I0929 10:28:34.579453  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267517 (* 1 = 0.267517 loss)
I0929 10:28:34.579460  1584 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I0929 10:28:48.827088  1584 solver.cpp:218] Iteration 24800 (7.01872 iter/s, 14.2476s/100 iters), loss = 0.275459
I0929 10:28:48.827117  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275459 (* 1 = 0.275459 loss)
I0929 10:28:48.827123  1584 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I0929 10:29:03.072590  1584 solver.cpp:218] Iteration 24900 (7.01979 iter/s, 14.2454s/100 iters), loss = 0.152671
I0929 10:29:03.072620  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152671 (* 1 = 0.152671 loss)
I0929 10:29:03.072626  1584 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I0929 10:29:16.598711  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:29:17.175878  1584 solver.cpp:330] Iteration 25000, Testing net (#0)
I0929 10:29:20.533486  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:29:20.673454  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.799
I0929 10:29:20.673487  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.641427 (* 1 = 0.641427 loss)
I0929 10:29:20.814478  1584 solver.cpp:218] Iteration 25000 (5.6364 iter/s, 17.7418s/100 iters), loss = 0.183525
I0929 10:29:20.814505  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183525 (* 1 = 0.183525 loss)
I0929 10:29:20.814512  1584 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I0929 10:29:35.053598  1584 solver.cpp:218] Iteration 25100 (7.02294 iter/s, 14.2391s/100 iters), loss = 0.203157
I0929 10:29:35.053633  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203157 (* 1 = 0.203157 loss)
I0929 10:29:35.053640  1584 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I0929 10:29:49.270354  1584 solver.cpp:218] Iteration 25200 (7.03399 iter/s, 14.2167s/100 iters), loss = 0.229129
I0929 10:29:49.270519  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229129 (* 1 = 0.229129 loss)
I0929 10:29:49.270535  1584 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I0929 10:30:03.499244  1584 solver.cpp:218] Iteration 25300 (7.02805 iter/s, 14.2287s/100 iters), loss = 0.174097
I0929 10:30:03.499275  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174097 (* 1 = 0.174097 loss)
I0929 10:30:03.499281  1584 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I0929 10:30:17.733935  1584 solver.cpp:218] Iteration 25400 (7.02513 iter/s, 14.2346s/100 iters), loss = 0.157123
I0929 10:30:17.733969  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157122 (* 1 = 0.157122 loss)
I0929 10:30:17.733976  1584 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I0929 10:30:31.253825  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:30:31.826391  1584 solver.cpp:330] Iteration 25500, Testing net (#0)
I0929 10:30:35.186828  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:30:35.326784  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.844
I0929 10:30:35.326810  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.473654 (* 1 = 0.473654 loss)
I0929 10:30:35.467649  1584 solver.cpp:218] Iteration 25500 (5.639 iter/s, 17.7336s/100 iters), loss = 0.166243
I0929 10:30:35.467686  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166243 (* 1 = 0.166243 loss)
I0929 10:30:35.467695  1584 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I0929 10:30:49.685434  1584 solver.cpp:218] Iteration 25600 (7.03348 iter/s, 14.2177s/100 iters), loss = 0.228092
I0929 10:30:49.685469  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228092 (* 1 = 0.228092 loss)
I0929 10:30:49.685478  1584 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I0929 10:31:03.927397  1584 solver.cpp:218] Iteration 25700 (7.02154 iter/s, 14.2419s/100 iters), loss = 0.293388
I0929 10:31:03.927485  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293388 (* 1 = 0.293388 loss)
I0929 10:31:03.927506  1584 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I0929 10:31:18.162708  1584 solver.cpp:218] Iteration 25800 (7.02484 iter/s, 14.2352s/100 iters), loss = 0.150966
I0929 10:31:18.162739  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.150965 (* 1 = 0.150965 loss)
I0929 10:31:18.162744  1584 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I0929 10:31:32.389330  1584 solver.cpp:218] Iteration 25900 (7.02911 iter/s, 14.2265s/100 iters), loss = 0.199545
I0929 10:31:32.389364  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199545 (* 1 = 0.199545 loss)
I0929 10:31:32.389370  1584 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I0929 10:31:45.911586  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:31:46.479446  1584 solver.cpp:330] Iteration 26000, Testing net (#0)
I0929 10:31:49.847105  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:31:49.990895  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7332
I0929 10:31:49.990933  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.911529 (* 1 = 0.911529 loss)
I0929 10:31:50.131611  1584 solver.cpp:218] Iteration 26000 (5.63628 iter/s, 17.7422s/100 iters), loss = 0.18521
I0929 10:31:50.131641  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18521 (* 1 = 0.18521 loss)
I0929 10:31:50.131649  1584 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I0929 10:32:04.364105  1584 solver.cpp:218] Iteration 26100 (7.02621 iter/s, 14.2324s/100 iters), loss = 0.163195
I0929 10:32:04.364145  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163195 (* 1 = 0.163195 loss)
I0929 10:32:04.364151  1584 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I0929 10:32:18.600289  1584 solver.cpp:218] Iteration 26200 (7.02439 iter/s, 14.2361s/100 iters), loss = 0.249332
I0929 10:32:18.600425  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249332 (* 1 = 0.249332 loss)
I0929 10:32:18.600433  1584 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I0929 10:32:32.851107  1584 solver.cpp:218] Iteration 26300 (7.01723 iter/s, 14.2506s/100 iters), loss = 0.234852
I0929 10:32:32.851147  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234852 (* 1 = 0.234852 loss)
I0929 10:32:32.851153  1584 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I0929 10:32:47.098382  1584 solver.cpp:218] Iteration 26400 (7.01893 iter/s, 14.2472s/100 iters), loss = 0.134502
I0929 10:32:47.098415  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134502 (* 1 = 0.134502 loss)
I0929 10:32:47.098423  1584 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I0929 10:33:00.626166  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:33:01.194336  1584 solver.cpp:330] Iteration 26500, Testing net (#0)
I0929 10:33:04.551275  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:33:04.691277  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8264
I0929 10:33:04.691313  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.528057 (* 1 = 0.528057 loss)
I0929 10:33:04.836022  1584 solver.cpp:218] Iteration 26500 (5.63775 iter/s, 17.7376s/100 iters), loss = 0.182221
I0929 10:33:04.836061  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182221 (* 1 = 0.182221 loss)
I0929 10:33:04.836067  1584 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I0929 10:33:19.061745  1584 solver.cpp:218] Iteration 26600 (7.02956 iter/s, 14.2256s/100 iters), loss = 0.141842
I0929 10:33:19.061774  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.141842 (* 1 = 0.141842 loss)
I0929 10:33:19.061781  1584 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I0929 10:33:33.300484  1584 solver.cpp:218] Iteration 26700 (7.02313 iter/s, 14.2387s/100 iters), loss = 0.270775
I0929 10:33:33.300622  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270775 (* 1 = 0.270775 loss)
I0929 10:33:33.300629  1584 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I0929 10:33:47.533650  1584 solver.cpp:218] Iteration 26800 (7.02593 iter/s, 14.233s/100 iters), loss = 0.139254
I0929 10:33:47.533682  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139254 (* 1 = 0.139254 loss)
I0929 10:33:47.533689  1584 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I0929 10:34:01.765354  1584 solver.cpp:218] Iteration 26900 (7.0266 iter/s, 14.2316s/100 iters), loss = 0.15268
I0929 10:34:01.765406  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15268 (* 1 = 0.15268 loss)
I0929 10:34:01.765413  1584 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I0929 10:34:15.300655  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:34:15.872810  1584 solver.cpp:330] Iteration 27000, Testing net (#0)
I0929 10:34:19.228462  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:34:19.367980  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7046
I0929 10:34:19.368021  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.04754 (* 1 = 1.04754 loss)
I0929 10:34:19.508111  1584 solver.cpp:218] Iteration 27000 (5.63614 iter/s, 17.7426s/100 iters), loss = 0.150854
I0929 10:34:19.508144  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.150854 (* 1 = 0.150854 loss)
I0929 10:34:19.508152  1584 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I0929 10:34:33.761495  1584 solver.cpp:218] Iteration 27100 (7.01591 iter/s, 14.2533s/100 iters), loss = 0.193395
I0929 10:34:33.761526  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193395 (* 1 = 0.193395 loss)
I0929 10:34:33.761533  1584 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I0929 10:34:48.009615  1584 solver.cpp:218] Iteration 27200 (7.0185 iter/s, 14.2481s/100 iters), loss = 0.194851
I0929 10:34:48.009733  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194851 (* 1 = 0.194851 loss)
I0929 10:34:48.009742  1584 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I0929 10:35:02.264273  1584 solver.cpp:218] Iteration 27300 (7.01532 iter/s, 14.2545s/100 iters), loss = 0.194021
I0929 10:35:02.264307  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19402 (* 1 = 0.19402 loss)
I0929 10:35:02.264313  1584 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I0929 10:35:16.510496  1584 solver.cpp:218] Iteration 27400 (7.01944 iter/s, 14.2461s/100 iters), loss = 0.175867
I0929 10:35:16.510530  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175867 (* 1 = 0.175867 loss)
I0929 10:35:16.510537  1584 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I0929 10:35:30.054575  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:35:30.623661  1584 solver.cpp:330] Iteration 27500, Testing net (#0)
I0929 10:35:33.979377  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:35:34.119272  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7451
I0929 10:35:34.119307  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.823354 (* 1 = 0.823354 loss)
I0929 10:35:34.260452  1584 solver.cpp:218] Iteration 27500 (5.63384 iter/s, 17.7499s/100 iters), loss = 0.1795
I0929 10:35:34.260481  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179499 (* 1 = 0.179499 loss)
I0929 10:35:34.260488  1584 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I0929 10:35:48.507550  1584 solver.cpp:218] Iteration 27600 (7.01901 iter/s, 14.247s/100 iters), loss = 0.270572
I0929 10:35:48.507580  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270572 (* 1 = 0.270572 loss)
I0929 10:35:48.507585  1584 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I0929 10:36:02.751677  1584 solver.cpp:218] Iteration 27700 (7.02047 iter/s, 14.2441s/100 iters), loss = 0.272825
I0929 10:36:02.751809  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272825 (* 1 = 0.272825 loss)
I0929 10:36:02.751817  1584 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I0929 10:36:16.980165  1584 solver.cpp:218] Iteration 27800 (7.02824 iter/s, 14.2283s/100 iters), loss = 0.160309
I0929 10:36:16.980212  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160309 (* 1 = 0.160309 loss)
I0929 10:36:16.980219  1584 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I0929 10:36:31.218976  1584 solver.cpp:218] Iteration 27900 (7.02312 iter/s, 14.2387s/100 iters), loss = 0.134148
I0929 10:36:31.219005  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134147 (* 1 = 0.134147 loss)
I0929 10:36:31.219012  1584 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I0929 10:36:44.756252  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:36:45.323693  1584 solver.cpp:330] Iteration 28000, Testing net (#0)
I0929 10:36:48.683295  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:36:48.822948  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8266
I0929 10:36:48.822984  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.537153 (* 1 = 0.537153 loss)
I0929 10:36:48.964185  1584 solver.cpp:218] Iteration 28000 (5.63535 iter/s, 17.7451s/100 iters), loss = 0.129852
I0929 10:36:48.964212  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.129852 (* 1 = 0.129852 loss)
I0929 10:36:48.964218  1584 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I0929 10:37:03.199946  1584 solver.cpp:218] Iteration 28100 (7.0246 iter/s, 14.2357s/100 iters), loss = 0.155277
I0929 10:37:03.199976  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155276 (* 1 = 0.155276 loss)
I0929 10:37:03.199982  1584 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I0929 10:37:17.448885  1584 solver.cpp:218] Iteration 28200 (7.0181 iter/s, 14.2489s/100 iters), loss = 0.213558
I0929 10:37:17.449025  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213558 (* 1 = 0.213558 loss)
I0929 10:37:17.449034  1584 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I0929 10:37:31.685320  1584 solver.cpp:218] Iteration 28300 (7.02432 iter/s, 14.2363s/100 iters), loss = 0.261625
I0929 10:37:31.685353  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261625 (* 1 = 0.261625 loss)
I0929 10:37:31.685359  1584 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I0929 10:37:45.924487  1584 solver.cpp:218] Iteration 28400 (7.02292 iter/s, 14.2391s/100 iters), loss = 0.128442
I0929 10:37:45.924520  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128442 (* 1 = 0.128442 loss)
I0929 10:37:45.924526  1584 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I0929 10:37:59.458278  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:38:00.027324  1584 solver.cpp:330] Iteration 28500, Testing net (#0)
I0929 10:38:03.385182  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:38:03.525120  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7693
I0929 10:38:03.525152  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.755676 (* 1 = 0.755676 loss)
I0929 10:38:03.666178  1584 solver.cpp:218] Iteration 28500 (5.63647 iter/s, 17.7416s/100 iters), loss = 0.200778
I0929 10:38:03.666206  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200778 (* 1 = 0.200778 loss)
I0929 10:38:03.666213  1584 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I0929 10:38:17.914392  1584 solver.cpp:218] Iteration 28600 (7.01846 iter/s, 14.2481s/100 iters), loss = 0.171643
I0929 10:38:17.914435  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171643 (* 1 = 0.171643 loss)
I0929 10:38:17.914441  1584 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I0929 10:38:32.159469  1584 solver.cpp:218] Iteration 28700 (7.02001 iter/s, 14.245s/100 iters), loss = 0.315984
I0929 10:38:32.159626  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315984 (* 1 = 0.315984 loss)
I0929 10:38:32.159634  1584 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I0929 10:38:46.392722  1584 solver.cpp:218] Iteration 28800 (7.0259 iter/s, 14.2331s/100 iters), loss = 0.148169
I0929 10:38:46.392752  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148169 (* 1 = 0.148169 loss)
I0929 10:38:46.392768  1584 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I0929 10:39:00.642515  1584 solver.cpp:218] Iteration 28900 (7.01768 iter/s, 14.2497s/100 iters), loss = 0.191221
I0929 10:39:00.642557  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191221 (* 1 = 0.191221 loss)
I0929 10:39:00.642563  1584 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I0929 10:39:14.188225  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:39:14.756449  1584 solver.cpp:330] Iteration 29000, Testing net (#0)
I0929 10:39:18.113296  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:39:18.252794  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7471
I0929 10:39:18.252817  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.915151 (* 1 = 0.915151 loss)
I0929 10:39:18.393337  1584 solver.cpp:218] Iteration 29000 (5.63357 iter/s, 17.7507s/100 iters), loss = 0.16237
I0929 10:39:18.393364  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16237 (* 1 = 0.16237 loss)
I0929 10:39:18.393370  1584 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I0929 10:39:32.619511  1584 solver.cpp:218] Iteration 29100 (7.02933 iter/s, 14.2261s/100 iters), loss = 0.205295
I0929 10:39:32.619544  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205295 (* 1 = 0.205295 loss)
I0929 10:39:32.619550  1584 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I0929 10:39:46.856348  1584 solver.cpp:218] Iteration 29200 (7.02407 iter/s, 14.2368s/100 iters), loss = 0.143988
I0929 10:39:46.856499  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143988 (* 1 = 0.143988 loss)
I0929 10:39:46.856509  1584 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I0929 10:40:01.093235  1584 solver.cpp:218] Iteration 29300 (7.0241 iter/s, 14.2367s/100 iters), loss = 0.183073
I0929 10:40:01.093264  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183073 (* 1 = 0.183073 loss)
I0929 10:40:01.093271  1584 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I0929 10:40:15.322275  1584 solver.cpp:218] Iteration 29400 (7.02792 iter/s, 14.229s/100 iters), loss = 0.165192
I0929 10:40:15.322311  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165191 (* 1 = 0.165191 loss)
I0929 10:40:15.322320  1584 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I0929 10:40:28.845943  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:40:29.418823  1584 solver.cpp:330] Iteration 29500, Testing net (#0)
I0929 10:40:32.777983  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:40:32.917757  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7359
I0929 10:40:32.917793  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.917618 (* 1 = 0.917618 loss)
I0929 10:40:33.058409  1584 solver.cpp:218] Iteration 29500 (5.63823 iter/s, 17.7361s/100 iters), loss = 0.132536
I0929 10:40:33.058444  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132536 (* 1 = 0.132536 loss)
I0929 10:40:33.058450  1584 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I0929 10:40:47.312134  1584 solver.cpp:218] Iteration 29600 (7.01575 iter/s, 14.2537s/100 iters), loss = 0.239139
I0929 10:40:47.312166  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239139 (* 1 = 0.239139 loss)
I0929 10:40:47.312173  1584 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I0929 10:41:01.545574  1584 solver.cpp:218] Iteration 29700 (7.02574 iter/s, 14.2334s/100 iters), loss = 0.220096
I0929 10:41:01.545668  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220095 (* 1 = 0.220095 loss)
I0929 10:41:01.545686  1584 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I0929 10:41:15.793368  1584 solver.cpp:218] Iteration 29800 (7.0187 iter/s, 14.2477s/100 iters), loss = 0.182809
I0929 10:41:15.793401  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182809 (* 1 = 0.182809 loss)
I0929 10:41:15.793406  1584 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I0929 10:41:30.038257  1584 solver.cpp:218] Iteration 29900 (7.0201 iter/s, 14.2448s/100 iters), loss = 0.183284
I0929 10:41:30.038287  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183283 (* 1 = 0.183283 loss)
I0929 10:41:30.038295  1584 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I0929 10:41:43.564863  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:41:44.141523  1584 solver.cpp:330] Iteration 30000, Testing net (#0)
I0929 10:41:47.496860  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:41:47.636719  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8007
I0929 10:41:47.636754  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.646108 (* 1 = 0.646108 loss)
I0929 10:41:47.777084  1584 solver.cpp:218] Iteration 30000 (5.63738 iter/s, 17.7387s/100 iters), loss = 0.186948
I0929 10:41:47.777117  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186948 (* 1 = 0.186948 loss)
I0929 10:41:47.777123  1584 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I0929 10:42:02.007442  1584 solver.cpp:218] Iteration 30100 (7.02727 iter/s, 14.2303s/100 iters), loss = 0.152235
I0929 10:42:02.007479  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152235 (* 1 = 0.152235 loss)
I0929 10:42:02.007486  1584 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I0929 10:42:16.244253  1584 solver.cpp:218] Iteration 30200 (7.02408 iter/s, 14.2367s/100 iters), loss = 0.262541
I0929 10:42:16.244371  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262541 (* 1 = 0.262541 loss)
I0929 10:42:16.244390  1584 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I0929 10:42:30.490464  1584 solver.cpp:218] Iteration 30300 (7.01949 iter/s, 14.2461s/100 iters), loss = 0.171968
I0929 10:42:30.490504  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171968 (* 1 = 0.171968 loss)
I0929 10:42:30.490511  1584 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I0929 10:42:44.731079  1584 solver.cpp:218] Iteration 30400 (7.02221 iter/s, 14.2405s/100 iters), loss = 0.166113
I0929 10:42:44.731120  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166112 (* 1 = 0.166112 loss)
I0929 10:42:44.731127  1584 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I0929 10:42:58.257058  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:42:58.827594  1584 solver.cpp:330] Iteration 30500, Testing net (#0)
I0929 10:43:02.197935  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:43:02.337894  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7632
I0929 10:43:02.337930  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.826164 (* 1 = 0.826164 loss)
I0929 10:43:02.479378  1584 solver.cpp:218] Iteration 30500 (5.63437 iter/s, 17.7482s/100 iters), loss = 0.166746
I0929 10:43:02.479411  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166746 (* 1 = 0.166746 loss)
I0929 10:43:02.479418  1584 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I0929 10:43:16.710988  1584 solver.cpp:218] Iteration 30600 (7.02665 iter/s, 14.2315s/100 iters), loss = 0.185744
I0929 10:43:16.711020  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185744 (* 1 = 0.185744 loss)
I0929 10:43:16.711027  1584 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I0929 10:43:30.938091  1584 solver.cpp:218] Iteration 30700 (7.02888 iter/s, 14.227s/100 iters), loss = 0.161293
I0929 10:43:30.938199  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161293 (* 1 = 0.161293 loss)
I0929 10:43:30.938207  1584 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I0929 10:43:45.172526  1584 solver.cpp:218] Iteration 30800 (7.02529 iter/s, 14.2343s/100 iters), loss = 0.125289
I0929 10:43:45.172555  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.125289 (* 1 = 0.125289 loss)
I0929 10:43:45.172561  1584 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I0929 10:43:59.410853  1584 solver.cpp:218] Iteration 30900 (7.02333 iter/s, 14.2383s/100 iters), loss = 0.147495
I0929 10:43:59.410886  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147495 (* 1 = 0.147495 loss)
I0929 10:43:59.410892  1584 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I0929 10:44:12.929023  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:44:13.497330  1584 solver.cpp:330] Iteration 31000, Testing net (#0)
I0929 10:44:16.854683  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:44:16.998606  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8
I0929 10:44:16.998633  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.637698 (* 1 = 0.637698 loss)
I0929 10:44:17.140425  1584 solver.cpp:218] Iteration 31000 (5.64032 iter/s, 17.7295s/100 iters), loss = 0.154866
I0929 10:44:17.140460  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154866 (* 1 = 0.154866 loss)
I0929 10:44:17.140467  1584 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I0929 10:44:31.381438  1584 solver.cpp:218] Iteration 31100 (7.02201 iter/s, 14.2409s/100 iters), loss = 0.215022
I0929 10:44:31.381469  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215022 (* 1 = 0.215022 loss)
I0929 10:44:31.381485  1584 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I0929 10:44:45.631124  1584 solver.cpp:218] Iteration 31200 (7.01774 iter/s, 14.2496s/100 iters), loss = 0.267391
I0929 10:44:45.631240  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267391 (* 1 = 0.267391 loss)
I0929 10:44:45.631258  1584 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I0929 10:44:59.867625  1584 solver.cpp:218] Iteration 31300 (7.02427 iter/s, 14.2364s/100 iters), loss = 0.240611
I0929 10:44:59.867656  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240611 (* 1 = 0.240611 loss)
I0929 10:44:59.867673  1584 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I0929 10:45:14.110918  1584 solver.cpp:218] Iteration 31400 (7.02089 iter/s, 14.2432s/100 iters), loss = 0.097825
I0929 10:45:14.110954  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0978247 (* 1 = 0.0978247 loss)
I0929 10:45:14.110960  1584 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I0929 10:45:27.645496  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:45:28.213698  1584 solver.cpp:330] Iteration 31500, Testing net (#0)
I0929 10:45:31.573040  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:45:31.713137  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8491
I0929 10:45:31.713161  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.467742 (* 1 = 0.467742 loss)
I0929 10:45:31.856482  1584 solver.cpp:218] Iteration 31500 (5.63524 iter/s, 17.7455s/100 iters), loss = 0.110683
I0929 10:45:31.856528  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.110682 (* 1 = 0.110682 loss)
I0929 10:45:31.856536  1584 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I0929 10:45:46.101064  1584 solver.cpp:218] Iteration 31600 (7.02027 iter/s, 14.2445s/100 iters), loss = 0.164891
I0929 10:45:46.101094  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164891 (* 1 = 0.164891 loss)
I0929 10:45:46.101111  1584 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I0929 10:46:00.343948  1584 solver.cpp:218] Iteration 31700 (7.02109 iter/s, 14.2428s/100 iters), loss = 0.18938
I0929 10:46:00.344090  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189379 (* 1 = 0.189379 loss)
I0929 10:46:00.344099  1584 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I0929 10:46:14.594553  1584 solver.cpp:218] Iteration 31800 (7.01734 iter/s, 14.2504s/100 iters), loss = 0.192332
I0929 10:46:14.594584  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192332 (* 1 = 0.192332 loss)
I0929 10:46:14.594591  1584 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I0929 10:46:28.839371  1584 solver.cpp:218] Iteration 31900 (7.02013 iter/s, 14.2447s/100 iters), loss = 0.194747
I0929 10:46:28.839407  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194747 (* 1 = 0.194747 loss)
I0929 10:46:28.839416  1584 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I0929 10:46:42.375301  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:46:42.943858  1584 solver.cpp:330] Iteration 32000, Testing net (#0)
I0929 10:46:46.299463  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:46:46.440944  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7876
I0929 10:46:46.440969  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.681116 (* 1 = 0.681116 loss)
I0929 10:46:46.581015  1584 solver.cpp:218] Iteration 32000 (5.63648 iter/s, 17.7416s/100 iters), loss = 0.123853
I0929 10:46:46.581043  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123853 (* 1 = 0.123853 loss)
I0929 10:46:46.581050  1584 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I0929 10:47:00.830101  1584 solver.cpp:218] Iteration 32100 (7.01803 iter/s, 14.249s/100 iters), loss = 0.166672
I0929 10:47:00.830132  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166672 (* 1 = 0.166672 loss)
I0929 10:47:00.830138  1584 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I0929 10:47:15.080332  1584 solver.cpp:218] Iteration 32200 (7.01746 iter/s, 14.2502s/100 iters), loss = 0.15124
I0929 10:47:15.080436  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15124 (* 1 = 0.15124 loss)
I0929 10:47:15.080454  1584 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I0929 10:47:29.317447  1584 solver.cpp:218] Iteration 32300 (7.02396 iter/s, 14.237s/100 iters), loss = 0.132822
I0929 10:47:29.317478  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132822 (* 1 = 0.132822 loss)
I0929 10:47:29.317484  1584 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I0929 10:47:43.554863  1584 solver.cpp:218] Iteration 32400 (7.02378 iter/s, 14.2373s/100 iters), loss = 0.0917133
I0929 10:47:43.554896  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.091713 (* 1 = 0.091713 loss)
I0929 10:47:43.554903  1584 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I0929 10:47:57.096604  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:47:57.664697  1584 solver.cpp:330] Iteration 32500, Testing net (#0)
I0929 10:48:01.024705  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:48:01.164948  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8471
I0929 10:48:01.164983  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.487908 (* 1 = 0.487908 loss)
I0929 10:48:01.305186  1584 solver.cpp:218] Iteration 32500 (5.63373 iter/s, 17.7502s/100 iters), loss = 0.237146
I0929 10:48:01.305212  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237146 (* 1 = 0.237146 loss)
I0929 10:48:01.305218  1584 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I0929 10:48:15.544411  1584 solver.cpp:218] Iteration 32600 (7.02289 iter/s, 14.2392s/100 iters), loss = 0.261209
I0929 10:48:15.544441  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261209 (* 1 = 0.261209 loss)
I0929 10:48:15.544447  1584 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I0929 10:48:29.792695  1584 solver.cpp:218] Iteration 32700 (7.01842 iter/s, 14.2482s/100 iters), loss = 0.248639
I0929 10:48:29.792832  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248638 (* 1 = 0.248638 loss)
I0929 10:48:29.792840  1584 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I0929 10:48:44.046676  1584 solver.cpp:218] Iteration 32800 (7.01567 iter/s, 14.2538s/100 iters), loss = 0.196911
I0929 10:48:44.046715  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19691 (* 1 = 0.19691 loss)
I0929 10:48:44.046722  1584 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I0929 10:48:58.284353  1584 solver.cpp:218] Iteration 32900 (7.02366 iter/s, 14.2376s/100 iters), loss = 0.156663
I0929 10:48:58.284384  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156662 (* 1 = 0.156662 loss)
I0929 10:48:58.284390  1584 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I0929 10:49:11.824167  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:49:12.393633  1584 solver.cpp:330] Iteration 33000, Testing net (#0)
I0929 10:49:15.752699  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:49:15.892807  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7642
I0929 10:49:15.892843  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.793411 (* 1 = 0.793411 loss)
I0929 10:49:16.033203  1584 solver.cpp:218] Iteration 33000 (5.63419 iter/s, 17.7488s/100 iters), loss = 0.152975
I0929 10:49:16.033231  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152974 (* 1 = 0.152974 loss)
I0929 10:49:16.033237  1584 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I0929 10:49:30.275091  1584 solver.cpp:218] Iteration 33100 (7.02157 iter/s, 14.2418s/100 iters), loss = 0.188235
I0929 10:49:30.275121  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188235 (* 1 = 0.188235 loss)
I0929 10:49:30.275127  1584 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I0929 10:49:44.525660  1584 solver.cpp:218] Iteration 33200 (7.0173 iter/s, 14.2505s/100 iters), loss = 0.197423
I0929 10:49:44.525770  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197423 (* 1 = 0.197423 loss)
I0929 10:49:44.525789  1584 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I0929 10:49:58.755970  1584 solver.cpp:218] Iteration 33300 (7.02733 iter/s, 14.2302s/100 iters), loss = 0.200971
I0929 10:49:58.756012  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200971 (* 1 = 0.200971 loss)
I0929 10:49:58.756018  1584 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I0929 10:50:13.005100  1584 solver.cpp:218] Iteration 33400 (7.01801 iter/s, 14.249s/100 iters), loss = 0.16488
I0929 10:50:13.005131  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16488 (* 1 = 0.16488 loss)
I0929 10:50:13.005137  1584 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I0929 10:50:26.541792  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:50:27.111929  1584 solver.cpp:330] Iteration 33500, Testing net (#0)
I0929 10:50:30.466697  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:50:30.606714  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7712
I0929 10:50:30.606748  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.818307 (* 1 = 0.818307 loss)
I0929 10:50:30.747265  1584 solver.cpp:218] Iteration 33500 (5.63632 iter/s, 17.7421s/100 iters), loss = 0.188578
I0929 10:50:30.747298  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188578 (* 1 = 0.188578 loss)
I0929 10:50:30.747304  1584 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I0929 10:50:44.969043  1584 solver.cpp:218] Iteration 33600 (7.03151 iter/s, 14.2217s/100 iters), loss = 0.268277
I0929 10:50:44.969084  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268277 (* 1 = 0.268277 loss)
I0929 10:50:44.969091  1584 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I0929 10:50:59.204489  1584 solver.cpp:218] Iteration 33700 (7.02476 iter/s, 14.2354s/100 iters), loss = 0.303371
I0929 10:50:59.204632  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303371 (* 1 = 0.303371 loss)
I0929 10:50:59.204641  1584 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I0929 10:51:13.437532  1584 solver.cpp:218] Iteration 33800 (7.026 iter/s, 14.2329s/100 iters), loss = 0.195343
I0929 10:51:13.437562  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195342 (* 1 = 0.195342 loss)
I0929 10:51:13.437569  1584 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I0929 10:51:27.659754  1584 solver.cpp:218] Iteration 33900 (7.03128 iter/s, 14.2222s/100 iters), loss = 0.0676918
I0929 10:51:27.659785  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0676915 (* 1 = 0.0676915 loss)
I0929 10:51:27.659791  1584 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I0929 10:51:41.183220  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:51:41.750555  1584 solver.cpp:330] Iteration 34000, Testing net (#0)
I0929 10:51:45.110260  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:51:45.249908  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8319
I0929 10:51:45.249944  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.552785 (* 1 = 0.552785 loss)
I0929 10:51:45.390498  1584 solver.cpp:218] Iteration 34000 (5.63995 iter/s, 17.7307s/100 iters), loss = 0.165028
I0929 10:51:45.390532  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165027 (* 1 = 0.165027 loss)
I0929 10:51:45.390539  1584 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I0929 10:51:59.633898  1584 solver.cpp:218] Iteration 34100 (7.02083 iter/s, 14.2433s/100 iters), loss = 0.147862
I0929 10:51:59.633927  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147862 (* 1 = 0.147862 loss)
I0929 10:51:59.633934  1584 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I0929 10:52:13.854245  1584 solver.cpp:218] Iteration 34200 (7.03221 iter/s, 14.2203s/100 iters), loss = 0.163836
I0929 10:52:13.854405  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163835 (* 1 = 0.163835 loss)
I0929 10:52:13.854415  1584 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I0929 10:52:28.089099  1584 solver.cpp:218] Iteration 34300 (7.02512 iter/s, 14.2346s/100 iters), loss = 0.111312
I0929 10:52:28.089133  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.111311 (* 1 = 0.111311 loss)
I0929 10:52:28.089148  1584 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I0929 10:52:42.329041  1584 solver.cpp:218] Iteration 34400 (7.02254 iter/s, 14.2399s/100 iters), loss = 0.114024
I0929 10:52:42.329077  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114024 (* 1 = 0.114024 loss)
I0929 10:52:42.329084  1584 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I0929 10:52:55.842489  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:52:56.417094  1584 solver.cpp:330] Iteration 34500, Testing net (#0)
I0929 10:52:59.772146  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:52:59.911648  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8045
I0929 10:52:59.911684  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.628303 (* 1 = 0.628303 loss)
I0929 10:53:00.052232  1584 solver.cpp:218] Iteration 34500 (5.64235 iter/s, 17.7231s/100 iters), loss = 0.165143
I0929 10:53:00.052261  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165143 (* 1 = 0.165143 loss)
I0929 10:53:00.052268  1584 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I0929 10:53:14.285365  1584 solver.cpp:218] Iteration 34600 (7.0259 iter/s, 14.2331s/100 iters), loss = 0.129774
I0929 10:53:14.285409  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.129773 (* 1 = 0.129773 loss)
I0929 10:53:14.285415  1584 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I0929 10:53:28.512815  1584 solver.cpp:218] Iteration 34700 (7.02871 iter/s, 14.2274s/100 iters), loss = 0.199893
I0929 10:53:28.512939  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199893 (* 1 = 0.199893 loss)
I0929 10:53:28.512948  1584 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I0929 10:53:42.740509  1584 solver.cpp:218] Iteration 34800 (7.02863 iter/s, 14.2275s/100 iters), loss = 0.189449
I0929 10:53:42.740540  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189449 (* 1 = 0.189449 loss)
I0929 10:53:42.740546  1584 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I0929 10:53:56.961738  1584 solver.cpp:218] Iteration 34900 (7.03178 iter/s, 14.2212s/100 iters), loss = 0.153202
I0929 10:53:56.961768  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153201 (* 1 = 0.153201 loss)
I0929 10:53:56.961774  1584 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I0929 10:54:10.483080  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:54:11.060619  1584 solver.cpp:330] Iteration 35000, Testing net (#0)
I0929 10:54:14.418882  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:54:14.559203  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7556
I0929 10:54:14.559238  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.817359 (* 1 = 0.817359 loss)
I0929 10:54:14.699432  1584 solver.cpp:218] Iteration 35000 (5.63774 iter/s, 17.7376s/100 iters), loss = 0.172631
I0929 10:54:14.699466  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17263 (* 1 = 0.17263 loss)
I0929 10:54:14.699473  1584 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I0929 10:54:28.933569  1584 solver.cpp:218] Iteration 35100 (7.0254 iter/s, 14.2341s/100 iters), loss = 0.141096
I0929 10:54:28.933606  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.141095 (* 1 = 0.141095 loss)
I0929 10:54:28.933614  1584 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I0929 10:54:43.165071  1584 solver.cpp:218] Iteration 35200 (7.0267 iter/s, 14.2314s/100 iters), loss = 0.189067
I0929 10:54:43.165184  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189066 (* 1 = 0.189066 loss)
I0929 10:54:43.165202  1584 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I0929 10:54:57.412286  1584 solver.cpp:218] Iteration 35300 (7.01899 iter/s, 14.2471s/100 iters), loss = 0.162031
I0929 10:54:57.412326  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162031 (* 1 = 0.162031 loss)
I0929 10:54:57.412333  1584 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I0929 10:55:11.660995  1584 solver.cpp:218] Iteration 35400 (7.01822 iter/s, 14.2486s/100 iters), loss = 0.196725
I0929 10:55:11.661026  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196725 (* 1 = 0.196725 loss)
I0929 10:55:11.661032  1584 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I0929 10:55:25.183337  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:55:25.751325  1584 solver.cpp:330] Iteration 35500, Testing net (#0)
I0929 10:55:29.114096  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:55:29.254387  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8001
I0929 10:55:29.254413  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.66562 (* 1 = 0.66562 loss)
I0929 10:55:29.394457  1584 solver.cpp:218] Iteration 35500 (5.63908 iter/s, 17.7334s/100 iters), loss = 0.150311
I0929 10:55:29.394486  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15031 (* 1 = 0.15031 loss)
I0929 10:55:29.394493  1584 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I0929 10:55:43.619616  1584 solver.cpp:218] Iteration 35600 (7.02983 iter/s, 14.2251s/100 iters), loss = 0.0903477
I0929 10:55:43.619647  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0903472 (* 1 = 0.0903472 loss)
I0929 10:55:43.619653  1584 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I0929 10:55:57.859395  1584 solver.cpp:218] Iteration 35700 (7.02262 iter/s, 14.2397s/100 iters), loss = 0.188672
I0929 10:55:57.859526  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188672 (* 1 = 0.188672 loss)
I0929 10:55:57.859535  1584 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I0929 10:56:12.083366  1584 solver.cpp:218] Iteration 35800 (7.03047 iter/s, 14.2238s/100 iters), loss = 0.168877
I0929 10:56:12.083395  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168876 (* 1 = 0.168876 loss)
I0929 10:56:12.083401  1584 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I0929 10:56:26.313321  1584 solver.cpp:218] Iteration 35900 (7.02746 iter/s, 14.2299s/100 iters), loss = 0.121573
I0929 10:56:26.313354  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.121573 (* 1 = 0.121573 loss)
I0929 10:56:26.313360  1584 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I0929 10:56:39.838616  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:56:40.406210  1584 solver.cpp:330] Iteration 36000, Testing net (#0)
I0929 10:56:43.764212  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:56:43.906420  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8501
I0929 10:56:43.906458  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.464191 (* 1 = 0.464191 loss)
I0929 10:56:44.052762  1584 solver.cpp:218] Iteration 36000 (5.63718 iter/s, 17.7394s/100 iters), loss = 0.160796
I0929 10:56:44.052799  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160796 (* 1 = 0.160796 loss)
I0929 10:56:44.052806  1584 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I0929 10:56:58.276116  1584 solver.cpp:218] Iteration 36100 (7.03073 iter/s, 14.2233s/100 iters), loss = 0.235761
I0929 10:56:58.276147  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235761 (* 1 = 0.235761 loss)
I0929 10:56:58.276154  1584 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I0929 10:57:12.495101  1584 solver.cpp:218] Iteration 36200 (7.03289 iter/s, 14.2189s/100 iters), loss = 0.213445
I0929 10:57:12.495216  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213445 (* 1 = 0.213445 loss)
I0929 10:57:12.495223  1584 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I0929 10:57:26.725697  1584 solver.cpp:218] Iteration 36300 (7.02719 iter/s, 14.2304s/100 iters), loss = 0.120166
I0929 10:57:26.725726  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120165 (* 1 = 0.120165 loss)
I0929 10:57:26.725733  1584 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I0929 10:57:40.955036  1584 solver.cpp:218] Iteration 36400 (7.02777 iter/s, 14.2293s/100 iters), loss = 0.0719585
I0929 10:57:40.955073  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0719582 (* 1 = 0.0719582 loss)
I0929 10:57:40.955081  1584 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I0929 10:57:54.471349  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:57:55.040484  1584 solver.cpp:330] Iteration 36500, Testing net (#0)
I0929 10:57:58.396662  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:57:58.536067  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.838
I0929 10:57:58.536100  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.506597 (* 1 = 0.506597 loss)
I0929 10:57:58.676465  1584 solver.cpp:218] Iteration 36500 (5.64291 iter/s, 17.7213s/100 iters), loss = 0.157245
I0929 10:57:58.676496  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157245 (* 1 = 0.157245 loss)
I0929 10:57:58.676503  1584 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I0929 10:58:12.914911  1584 solver.cpp:218] Iteration 36600 (7.02328 iter/s, 14.2384s/100 iters), loss = 0.210423
I0929 10:58:12.914952  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210423 (* 1 = 0.210423 loss)
I0929 10:58:12.914958  1584 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I0929 10:58:27.144524  1584 solver.cpp:218] Iteration 36700 (7.02764 iter/s, 14.2295s/100 iters), loss = 0.208942
I0929 10:58:27.144641  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208942 (* 1 = 0.208942 loss)
I0929 10:58:27.144659  1584 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I0929 10:58:41.367756  1584 solver.cpp:218] Iteration 36800 (7.03083 iter/s, 14.2231s/100 iters), loss = 0.179197
I0929 10:58:41.367799  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179197 (* 1 = 0.179197 loss)
I0929 10:58:41.367805  1584 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I0929 10:58:55.648425  1584 solver.cpp:218] Iteration 36900 (7.00252 iter/s, 14.2806s/100 iters), loss = 0.142294
I0929 10:58:55.648457  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142293 (* 1 = 0.142293 loss)
I0929 10:58:55.648463  1584 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I0929 10:59:09.186568  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:59:09.754204  1584 solver.cpp:330] Iteration 37000, Testing net (#0)
I0929 10:59:13.117691  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:59:13.257745  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8152
I0929 10:59:13.257781  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.583311 (* 1 = 0.583311 loss)
I0929 10:59:13.398762  1584 solver.cpp:218] Iteration 37000 (5.63372 iter/s, 17.7503s/100 iters), loss = 0.0920845
I0929 10:59:13.398797  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0920842 (* 1 = 0.0920842 loss)
I0929 10:59:13.398803  1584 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I0929 10:59:27.636766  1584 solver.cpp:218] Iteration 37100 (7.02349 iter/s, 14.2379s/100 iters), loss = 0.105772
I0929 10:59:27.636801  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.105771 (* 1 = 0.105771 loss)
I0929 10:59:27.636806  1584 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I0929 10:59:41.878967  1584 solver.cpp:218] Iteration 37200 (7.02143 iter/s, 14.2421s/100 iters), loss = 0.206559
I0929 10:59:41.879094  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206559 (* 1 = 0.206559 loss)
I0929 10:59:41.879112  1584 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I0929 10:59:56.138916  1584 solver.cpp:218] Iteration 37300 (7.01273 iter/s, 14.2598s/100 iters), loss = 0.250262
I0929 10:59:56.138963  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250261 (* 1 = 0.250261 loss)
I0929 10:59:56.138972  1584 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I0929 11:00:10.377288  1584 solver.cpp:218] Iteration 37400 (7.02333 iter/s, 14.2383s/100 iters), loss = 0.090169
I0929 11:00:10.377321  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0901686 (* 1 = 0.0901686 loss)
I0929 11:00:10.377328  1584 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I0929 11:00:23.916996  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:00:24.485443  1584 solver.cpp:330] Iteration 37500, Testing net (#0)
I0929 11:00:27.848263  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:00:27.988519  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8244
I0929 11:00:27.988554  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.555542 (* 1 = 0.555542 loss)
I0929 11:00:28.129940  1584 solver.cpp:218] Iteration 37500 (5.63299 iter/s, 17.7526s/100 iters), loss = 0.0894669
I0929 11:00:28.129969  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0894665 (* 1 = 0.0894665 loss)
I0929 11:00:28.129976  1584 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I0929 11:00:42.389793  1584 solver.cpp:218] Iteration 37600 (7.01273 iter/s, 14.2598s/100 iters), loss = 0.168119
I0929 11:00:42.389823  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168119 (* 1 = 0.168119 loss)
I0929 11:00:42.389830  1584 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I0929 11:00:56.645489  1584 solver.cpp:218] Iteration 37700 (7.01477 iter/s, 14.2556s/100 iters), loss = 0.189529
I0929 11:00:56.645624  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189529 (* 1 = 0.189529 loss)
I0929 11:00:56.645632  1584 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I0929 11:01:10.888681  1584 solver.cpp:218] Iteration 37800 (7.02098 iter/s, 14.243s/100 iters), loss = 0.188187
I0929 11:01:10.888725  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188187 (* 1 = 0.188187 loss)
I0929 11:01:10.888731  1584 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I0929 11:01:25.145669  1584 solver.cpp:218] Iteration 37900 (7.01414 iter/s, 14.2569s/100 iters), loss = 0.117672
I0929 11:01:25.145699  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.117672 (* 1 = 0.117672 loss)
I0929 11:01:25.145705  1584 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I0929 11:01:38.704902  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:01:39.273273  1584 solver.cpp:330] Iteration 38000, Testing net (#0)
I0929 11:01:42.633715  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:01:42.774798  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7998
I0929 11:01:42.774834  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.667985 (* 1 = 0.667985 loss)
I0929 11:01:42.915648  1584 solver.cpp:218] Iteration 38000 (5.62749 iter/s, 17.7699s/100 iters), loss = 0.122382
I0929 11:01:42.915676  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.122382 (* 1 = 0.122382 loss)
I0929 11:01:42.915683  1584 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I0929 11:01:57.152089  1584 solver.cpp:218] Iteration 38100 (7.02426 iter/s, 14.2364s/100 iters), loss = 0.225126
I0929 11:01:57.152119  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225126 (* 1 = 0.225126 loss)
I0929 11:01:57.152125  1584 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I0929 11:02:11.499035  1584 solver.cpp:218] Iteration 38200 (6.97016 iter/s, 14.3469s/100 iters), loss = 0.165269
I0929 11:02:11.499163  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165269 (* 1 = 0.165269 loss)
I0929 11:02:11.499181  1584 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I0929 11:02:26.012393  1584 solver.cpp:218] Iteration 38300 (6.89028 iter/s, 14.5132s/100 iters), loss = 0.151844
I0929 11:02:26.012459  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151844 (* 1 = 0.151844 loss)
I0929 11:02:26.012475  1584 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I0929 11:02:40.362505  1584 solver.cpp:218] Iteration 38400 (6.96865 iter/s, 14.35s/100 iters), loss = 0.197174
I0929 11:02:40.362543  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197173 (* 1 = 0.197173 loss)
I0929 11:02:40.362550  1584 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I0929 11:02:54.008401  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:02:54.574905  1584 solver.cpp:330] Iteration 38500, Testing net (#0)
I0929 11:02:57.932827  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:02:58.072576  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8317
I0929 11:02:58.072612  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.521356 (* 1 = 0.521356 loss)
I0929 11:02:58.213651  1584 solver.cpp:218] Iteration 38500 (5.60191 iter/s, 17.8511s/100 iters), loss = 0.190355
I0929 11:02:58.213678  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190354 (* 1 = 0.190354 loss)
I0929 11:02:58.213685  1584 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I0929 11:03:12.452425  1584 solver.cpp:218] Iteration 38600 (7.02311 iter/s, 14.2387s/100 iters), loss = 0.148052
I0929 11:03:12.452455  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148051 (* 1 = 0.148051 loss)
I0929 11:03:12.452461  1584 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I0929 11:03:26.675073  1584 solver.cpp:218] Iteration 38700 (7.03108 iter/s, 14.2226s/100 iters), loss = 0.205614
I0929 11:03:26.675237  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205613 (* 1 = 0.205613 loss)
I0929 11:03:26.675249  1584 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I0929 11:03:40.893137  1584 solver.cpp:218] Iteration 38800 (7.0334 iter/s, 14.2179s/100 iters), loss = 0.132553
I0929 11:03:40.893182  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132552 (* 1 = 0.132552 loss)
I0929 11:03:40.893188  1584 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I0929 11:03:55.129298  1584 solver.cpp:218] Iteration 38900 (7.02441 iter/s, 14.2361s/100 iters), loss = 0.153299
I0929 11:03:55.129328  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153299 (* 1 = 0.153299 loss)
I0929 11:03:55.129334  1584 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I0929 11:04:08.663962  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:04:09.230391  1584 solver.cpp:330] Iteration 39000, Testing net (#0)
I0929 11:04:12.585193  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:04:12.725410  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7513
I0929 11:04:12.725451  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.847282 (* 1 = 0.847282 loss)
I0929 11:04:12.865684  1584 solver.cpp:218] Iteration 39000 (5.63815 iter/s, 17.7363s/100 iters), loss = 0.135878
I0929 11:04:12.865717  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135877 (* 1 = 0.135877 loss)
I0929 11:04:12.865725  1584 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I0929 11:04:27.100028  1584 solver.cpp:218] Iteration 39100 (7.0253 iter/s, 14.2343s/100 iters), loss = 0.20799
I0929 11:04:27.100057  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207989 (* 1 = 0.207989 loss)
I0929 11:04:27.100064  1584 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I0929 11:04:41.338246  1584 solver.cpp:218] Iteration 39200 (7.02339 iter/s, 14.2381s/100 iters), loss = 0.213832
I0929 11:04:41.338389  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213831 (* 1 = 0.213831 loss)
I0929 11:04:41.338399  1584 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I0929 11:04:55.569144  1584 solver.cpp:218] Iteration 39300 (7.02705 iter/s, 14.2307s/100 iters), loss = 0.228014
I0929 11:04:55.569185  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228013 (* 1 = 0.228013 loss)
I0929 11:04:55.569191  1584 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I0929 11:05:09.801813  1584 solver.cpp:218] Iteration 39400 (7.02613 iter/s, 14.2326s/100 iters), loss = 0.111863
I0929 11:05:09.801844  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.111862 (* 1 = 0.111862 loss)
I0929 11:05:09.801851  1584 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I0929 11:05:23.375857  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:05:23.956215  1584 solver.cpp:330] Iteration 39500, Testing net (#0)
I0929 11:05:27.329150  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:05:27.469048  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8048
I0929 11:05:27.469072  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.631911 (* 1 = 0.631911 loss)
I0929 11:05:27.609665  1584 solver.cpp:218] Iteration 39500 (5.61553 iter/s, 17.8078s/100 iters), loss = 0.168705
I0929 11:05:27.609707  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168705 (* 1 = 0.168705 loss)
I0929 11:05:27.609716  1584 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I0929 11:05:41.890523  1584 solver.cpp:218] Iteration 39600 (7.00242 iter/s, 14.2808s/100 iters), loss = 0.163749
I0929 11:05:41.890555  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163748 (* 1 = 0.163748 loss)
I0929 11:05:41.890563  1584 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I0929 11:05:56.304039  1584 solver.cpp:218] Iteration 39700 (6.93797 iter/s, 14.4134s/100 iters), loss = 0.190999
I0929 11:05:56.304183  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190998 (* 1 = 0.190998 loss)
I0929 11:05:56.304205  1584 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I0929 11:06:10.572995  1584 solver.cpp:218] Iteration 39800 (7.00831 iter/s, 14.2688s/100 iters), loss = 0.137135
I0929 11:06:10.573037  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.137135 (* 1 = 0.137135 loss)
I0929 11:06:10.573045  1584 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I0929 11:06:24.933763  1584 solver.cpp:218] Iteration 39900 (6.96345 iter/s, 14.3607s/100 iters), loss = 0.218967
I0929 11:06:24.933791  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218967 (* 1 = 0.218967 loss)
I0929 11:06:24.933799  1584 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I0929 11:06:38.571907  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:06:39.142529  1584 solver.cpp:330] Iteration 40000, Testing net (#0)
I0929 11:06:42.508935  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:06:42.650092  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.803
I0929 11:06:42.650128  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.640314 (* 1 = 0.640314 loss)
I0929 11:06:42.791157  1584 solver.cpp:218] Iteration 40000 (5.59995 iter/s, 17.8573s/100 iters), loss = 0.167627
I0929 11:06:42.791198  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167626 (* 1 = 0.167626 loss)
I0929 11:06:42.791204  1584 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I0929 11:06:42.791208  1584 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I0929 11:06:57.236420  1584 solver.cpp:218] Iteration 40100 (6.92272 iter/s, 14.4452s/100 iters), loss = 0.216807
I0929 11:06:57.236454  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216807 (* 1 = 0.216807 loss)
I0929 11:06:57.236461  1584 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I0929 11:07:11.561758  1584 solver.cpp:218] Iteration 40200 (6.98068 iter/s, 14.3253s/100 iters), loss = 0.102874
I0929 11:07:11.561877  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102874 (* 1 = 0.102874 loss)
I0929 11:07:11.561889  1584 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I0929 11:07:25.926841  1584 solver.cpp:218] Iteration 40300 (6.9614 iter/s, 14.3649s/100 iters), loss = 0.128542
I0929 11:07:25.926882  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128541 (* 1 = 0.128541 loss)
I0929 11:07:25.926892  1584 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I0929 11:07:40.258569  1584 solver.cpp:218] Iteration 40400 (6.97758 iter/s, 14.3316s/100 iters), loss = 0.0217987
I0929 11:07:40.258601  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0217981 (* 1 = 0.0217981 loss)
I0929 11:07:40.258610  1584 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I0929 11:07:53.893800  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:07:54.462299  1584 solver.cpp:330] Iteration 40500, Testing net (#0)
I0929 11:07:57.861126  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:07:58.003784  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8927
I0929 11:07:58.003816  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327045 (* 1 = 0.327045 loss)
I0929 11:07:58.149268  1584 solver.cpp:218] Iteration 40500 (5.58952 iter/s, 17.8906s/100 iters), loss = 0.0307688
I0929 11:07:58.149305  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0307683 (* 1 = 0.0307683 loss)
I0929 11:07:58.149314  1584 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I0929 11:08:12.423674  1584 solver.cpp:218] Iteration 40600 (7.0056 iter/s, 14.2743s/100 iters), loss = 0.0886427
I0929 11:08:12.423709  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0886421 (* 1 = 0.0886421 loss)
I0929 11:08:12.423727  1584 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I0929 11:08:26.827507  1584 solver.cpp:218] Iteration 40700 (6.94263 iter/s, 14.4038s/100 iters), loss = 0.0593043
I0929 11:08:26.827672  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0593037 (* 1 = 0.0593037 loss)
I0929 11:08:26.827684  1584 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I0929 11:08:41.145052  1584 solver.cpp:218] Iteration 40800 (6.98453 iter/s, 14.3173s/100 iters), loss = 0.0579106
I0929 11:08:41.145092  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.05791 (* 1 = 0.05791 loss)
I0929 11:08:41.145112  1584 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I0929 11:08:55.403283  1584 solver.cpp:218] Iteration 40900 (7.01355 iter/s, 14.2581s/100 iters), loss = 0.0131963
I0929 11:08:55.403316  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131957 (* 1 = 0.0131957 loss)
I0929 11:08:55.403324  1584 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I0929 11:09:08.944351  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:09:09.513226  1584 solver.cpp:330] Iteration 41000, Testing net (#0)
I0929 11:09:12.872349  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:09:13.012900  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9076
I0929 11:09:13.012928  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.276052 (* 1 = 0.276052 loss)
I0929 11:09:13.153342  1584 solver.cpp:218] Iteration 41000 (5.63381 iter/s, 17.75s/100 iters), loss = 0.0199802
I0929 11:09:13.153373  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0199796 (* 1 = 0.0199796 loss)
I0929 11:09:13.153381  1584 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I0929 11:09:27.407781  1584 solver.cpp:218] Iteration 41100 (7.01539 iter/s, 14.2544s/100 iters), loss = 0.10061
I0929 11:09:27.407815  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10061 (* 1 = 0.10061 loss)
I0929 11:09:27.407824  1584 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I0929 11:09:41.746193  1584 solver.cpp:218] Iteration 41200 (6.97431 iter/s, 14.3383s/100 iters), loss = 0.108294
I0929 11:09:41.746338  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.108294 (* 1 = 0.108294 loss)
I0929 11:09:41.746361  1584 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I0929 11:09:56.108822  1584 solver.cpp:218] Iteration 41300 (6.96261 iter/s, 14.3624s/100 iters), loss = 0.0466845
I0929 11:09:56.108865  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0466839 (* 1 = 0.0466839 loss)
I0929 11:09:56.108875  1584 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I0929 11:10:10.518575  1584 solver.cpp:218] Iteration 41400 (6.93978 iter/s, 14.4097s/100 iters), loss = 0.0368556
I0929 11:10:10.518609  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.036855 (* 1 = 0.036855 loss)
I0929 11:10:10.518615  1584 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I0929 11:10:24.078724  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:10:24.646013  1584 solver.cpp:330] Iteration 41500, Testing net (#0)
I0929 11:10:28.057420  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:10:28.197314  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9169
I0929 11:10:28.197340  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.258486 (* 1 = 0.258486 loss)
I0929 11:10:28.337707  1584 solver.cpp:218] Iteration 41500 (5.61197 iter/s, 17.819s/100 iters), loss = 0.0276372
I0929 11:10:28.337741  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0276366 (* 1 = 0.0276366 loss)
I0929 11:10:28.337751  1584 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I0929 11:10:42.658960  1584 solver.cpp:218] Iteration 41600 (6.98267 iter/s, 14.3212s/100 iters), loss = 0.072801
I0929 11:10:42.659003  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0728004 (* 1 = 0.0728004 loss)
I0929 11:10:42.659010  1584 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I0929 11:10:56.984763  1584 solver.cpp:218] Iteration 41700 (6.98045 iter/s, 14.3257s/100 iters), loss = 0.0982244
I0929 11:10:56.984930  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0982238 (* 1 = 0.0982238 loss)
I0929 11:10:56.984939  1584 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I0929 11:11:11.283283  1584 solver.cpp:218] Iteration 41800 (6.99383 iter/s, 14.2983s/100 iters), loss = 0.0650322
I0929 11:11:11.283318  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0650316 (* 1 = 0.0650316 loss)
I0929 11:11:11.283325  1584 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I0929 11:11:25.570813  1584 solver.cpp:218] Iteration 41900 (6.99915 iter/s, 14.2874s/100 iters), loss = 0.0135713
I0929 11:11:25.570854  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0135707 (* 1 = 0.0135707 loss)
I0929 11:11:25.570863  1584 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I0929 11:11:39.184415  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:11:39.757503  1584 solver.cpp:330] Iteration 42000, Testing net (#0)
I0929 11:11:43.131141  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:11:43.271967  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9135
I0929 11:11:43.271994  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.265872 (* 1 = 0.265872 loss)
I0929 11:11:43.412163  1584 solver.cpp:218] Iteration 42000 (5.60499 iter/s, 17.8413s/100 iters), loss = 0.0586001
I0929 11:11:43.412194  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0585995 (* 1 = 0.0585995 loss)
I0929 11:11:43.412200  1584 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I0929 11:11:57.696061  1584 solver.cpp:218] Iteration 42100 (7.00093 iter/s, 14.2838s/100 iters), loss = 0.0943082
I0929 11:11:57.696092  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0943076 (* 1 = 0.0943076 loss)
I0929 11:11:57.696099  1584 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I0929 11:12:12.015995  1584 solver.cpp:218] Iteration 42200 (6.98331 iter/s, 14.3199s/100 iters), loss = 0.0753154
I0929 11:12:12.016095  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0753147 (* 1 = 0.0753147 loss)
I0929 11:12:12.016103  1584 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I0929 11:12:26.318112  1584 solver.cpp:218] Iteration 42300 (6.99204 iter/s, 14.302s/100 iters), loss = 0.0371033
I0929 11:12:26.318146  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0371027 (* 1 = 0.0371027 loss)
I0929 11:12:26.318153  1584 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I0929 11:12:40.641007  1584 solver.cpp:218] Iteration 42400 (6.98187 iter/s, 14.3228s/100 iters), loss = 0.0201269
I0929 11:12:40.641041  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0201263 (* 1 = 0.0201263 loss)
I0929 11:12:40.641047  1584 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I0929 11:12:54.233464  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:12:54.803536  1584 solver.cpp:330] Iteration 42500, Testing net (#0)
I0929 11:12:58.178287  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:12:58.320444  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9156
I0929 11:12:58.320471  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.264663 (* 1 = 0.264663 loss)
I0929 11:12:58.461901  1584 solver.cpp:218] Iteration 42500 (5.61142 iter/s, 17.8208s/100 iters), loss = 0.0344922
I0929 11:12:58.461931  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0344916 (* 1 = 0.0344916 loss)
I0929 11:12:58.461938  1584 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I0929 11:13:12.767544  1584 solver.cpp:218] Iteration 42600 (6.99029 iter/s, 14.3056s/100 iters), loss = 0.0357032
I0929 11:13:12.767580  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0357026 (* 1 = 0.0357026 loss)
I0929 11:13:12.767587  1584 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I0929 11:13:27.091398  1584 solver.cpp:218] Iteration 42700 (6.9814 iter/s, 14.3238s/100 iters), loss = 0.0882647
I0929 11:13:27.091576  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0882641 (* 1 = 0.0882641 loss)
I0929 11:13:27.091596  1584 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I0929 11:13:41.404820  1584 solver.cpp:218] Iteration 42800 (6.98654 iter/s, 14.3132s/100 iters), loss = 0.068307
I0929 11:13:41.404852  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0683064 (* 1 = 0.0683064 loss)
I0929 11:13:41.404860  1584 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I0929 11:13:55.709547  1584 solver.cpp:218] Iteration 42900 (6.99073 iter/s, 14.3047s/100 iters), loss = 0.0112349
I0929 11:13:55.709589  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112343 (* 1 = 0.0112343 loss)
I0929 11:13:55.709596  1584 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I0929 11:14:09.313016  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:14:09.881897  1584 solver.cpp:330] Iteration 43000, Testing net (#0)
I0929 11:14:13.248729  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:14:13.390244  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9138
I0929 11:14:13.390269  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.2713 (* 1 = 0.2713 loss)
I0929 11:14:13.531797  1584 solver.cpp:218] Iteration 43000 (5.61099 iter/s, 17.8222s/100 iters), loss = 0.0302816
I0929 11:14:13.531823  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.030281 (* 1 = 0.030281 loss)
I0929 11:14:13.531831  1584 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I0929 11:14:27.829545  1584 solver.cpp:218] Iteration 43100 (6.99414 iter/s, 14.2977s/100 iters), loss = 0.0385515
I0929 11:14:27.829578  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0385509 (* 1 = 0.0385509 loss)
I0929 11:14:27.829586  1584 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I0929 11:14:42.222988  1584 solver.cpp:218] Iteration 43200 (6.94764 iter/s, 14.3934s/100 iters), loss = 0.11506
I0929 11:14:42.223132  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.11506 (* 1 = 0.11506 loss)
I0929 11:14:42.223141  1584 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I0929 11:14:56.559064  1584 solver.cpp:218] Iteration 43300 (6.9755 iter/s, 14.3359s/100 iters), loss = 0.0167236
I0929 11:14:56.559110  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.016723 (* 1 = 0.016723 loss)
I0929 11:14:56.559118  1584 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I0929 11:15:10.857718  1584 solver.cpp:218] Iteration 43400 (6.99376 iter/s, 14.2985s/100 iters), loss = 0.0244903
I0929 11:15:10.857750  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0244897 (* 1 = 0.0244897 loss)
I0929 11:15:10.857758  1584 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I0929 11:15:24.471452  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:15:25.041153  1584 solver.cpp:330] Iteration 43500, Testing net (#0)
I0929 11:15:28.444783  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:15:28.585327  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9163
I0929 11:15:28.585362  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.26568 (* 1 = 0.26568 loss)
I0929 11:15:28.726758  1584 solver.cpp:218] Iteration 43500 (5.5963 iter/s, 17.869s/100 iters), loss = 0.0161195
I0929 11:15:28.726794  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0161189 (* 1 = 0.0161189 loss)
I0929 11:15:28.726800  1584 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I0929 11:15:43.024037  1584 solver.cpp:218] Iteration 43600 (6.99438 iter/s, 14.2972s/100 iters), loss = 0.0379301
I0929 11:15:43.024080  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0379295 (* 1 = 0.0379295 loss)
I0929 11:15:43.024085  1584 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I0929 11:15:57.361810  1584 solver.cpp:218] Iteration 43700 (6.97462 iter/s, 14.3377s/100 iters), loss = 0.0844307
I0929 11:15:57.361944  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0844301 (* 1 = 0.0844301 loss)
I0929 11:15:57.361951  1584 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I0929 11:16:11.681058  1584 solver.cpp:218] Iteration 43800 (6.98368 iter/s, 14.3191s/100 iters), loss = 0.047668
I0929 11:16:11.681090  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0476674 (* 1 = 0.0476674 loss)
I0929 11:16:11.681097  1584 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I0929 11:16:25.999619  1584 solver.cpp:218] Iteration 43900 (6.98398 iter/s, 14.3185s/100 iters), loss = 0.0191144
I0929 11:16:25.999663  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0191138 (* 1 = 0.0191138 loss)
I0929 11:16:25.999671  1584 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I0929 11:16:39.601518  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:16:40.169682  1584 solver.cpp:330] Iteration 44000, Testing net (#0)
I0929 11:16:43.537389  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:16:43.678887  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9217
I0929 11:16:43.678915  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.257532 (* 1 = 0.257532 loss)
I0929 11:16:43.820111  1584 solver.cpp:218] Iteration 44000 (5.61156 iter/s, 17.8204s/100 iters), loss = 0.015975
I0929 11:16:43.820142  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0159743 (* 1 = 0.0159743 loss)
I0929 11:16:43.820149  1584 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I0929 11:16:58.123407  1584 solver.cpp:218] Iteration 44100 (6.99143 iter/s, 14.3032s/100 iters), loss = 0.0619263
I0929 11:16:58.123437  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0619256 (* 1 = 0.0619256 loss)
I0929 11:16:58.123443  1584 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I0929 11:17:12.480588  1584 solver.cpp:218] Iteration 44200 (6.96519 iter/s, 14.3571s/100 iters), loss = 0.0270115
I0929 11:17:12.480671  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0270108 (* 1 = 0.0270108 loss)
I0929 11:17:12.480689  1584 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I0929 11:17:26.808429  1584 solver.cpp:218] Iteration 44300 (6.97947 iter/s, 14.3277s/100 iters), loss = 0.0414193
I0929 11:17:26.808465  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0414186 (* 1 = 0.0414186 loss)
I0929 11:17:26.808471  1584 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I0929 11:17:41.106062  1584 solver.cpp:218] Iteration 44400 (6.9942 iter/s, 14.2976s/100 iters), loss = 0.0157515
I0929 11:17:41.106109  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0157509 (* 1 = 0.0157509 loss)
I0929 11:17:41.106117  1584 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I0929 11:17:54.663141  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:17:55.231534  1584 solver.cpp:330] Iteration 44500, Testing net (#0)
I0929 11:17:58.612246  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:17:58.752063  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9189
I0929 11:17:58.752099  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.266431 (* 1 = 0.266431 loss)
I0929 11:17:58.893157  1584 solver.cpp:218] Iteration 44500 (5.62209 iter/s, 17.787s/100 iters), loss = 0.00466724
I0929 11:17:58.893189  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00466661 (* 1 = 0.00466661 loss)
I0929 11:17:58.893195  1584 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I0929 11:18:13.156376  1584 solver.cpp:218] Iteration 44600 (7.01108 iter/s, 14.2631s/100 iters), loss = 0.0311033
I0929 11:18:13.156409  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0311027 (* 1 = 0.0311027 loss)
I0929 11:18:13.156414  1584 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I0929 11:18:27.414742  1584 solver.cpp:218] Iteration 44700 (7.01346 iter/s, 14.2583s/100 iters), loss = 0.0708478
I0929 11:18:27.414891  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0708472 (* 1 = 0.0708472 loss)
I0929 11:18:27.414909  1584 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I0929 11:18:41.762243  1584 solver.cpp:218] Iteration 44800 (6.96994 iter/s, 14.3473s/100 iters), loss = 0.0432
I0929 11:18:41.762289  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0431993 (* 1 = 0.0431993 loss)
I0929 11:18:41.762295  1584 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I0929 11:18:56.051426  1584 solver.cpp:218] Iteration 44900 (6.99834 iter/s, 14.2891s/100 iters), loss = 0.00541206
I0929 11:18:56.051462  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00541145 (* 1 = 0.00541145 loss)
I0929 11:18:56.051470  1584 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I0929 11:19:09.703455  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:19:10.273741  1584 solver.cpp:330] Iteration 45000, Testing net (#0)
I0929 11:19:13.654315  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:19:13.795228  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9176
I0929 11:19:13.795253  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.276205 (* 1 = 0.276205 loss)
I0929 11:19:13.935983  1584 solver.cpp:218] Iteration 45000 (5.59144 iter/s, 17.8845s/100 iters), loss = 0.00424359
I0929 11:19:13.936014  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00424298 (* 1 = 0.00424298 loss)
I0929 11:19:13.936020  1584 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I0929 11:19:28.233731  1584 solver.cpp:218] Iteration 45100 (6.99414 iter/s, 14.2977s/100 iters), loss = 0.0157071
I0929 11:19:28.233762  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0157065 (* 1 = 0.0157065 loss)
I0929 11:19:28.233767  1584 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I0929 11:19:42.463798  1584 solver.cpp:218] Iteration 45200 (7.02741 iter/s, 14.23s/100 iters), loss = 0.0574621
I0929 11:19:42.463938  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0574615 (* 1 = 0.0574615 loss)
I0929 11:19:42.463946  1584 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I0929 11:19:56.740715  1584 solver.cpp:218] Iteration 45300 (7.0044 iter/s, 14.2767s/100 iters), loss = 0.0218157
I0929 11:19:56.740749  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0218151 (* 1 = 0.0218151 loss)
I0929 11:19:56.740756  1584 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I0929 11:20:11.131661  1584 solver.cpp:218] Iteration 45400 (6.94885 iter/s, 14.3909s/100 iters), loss = 0.00727442
I0929 11:20:11.131700  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00727383 (* 1 = 0.00727383 loss)
I0929 11:20:11.131708  1584 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I0929 11:20:24.697568  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:20:25.266201  1584 solver.cpp:330] Iteration 45500, Testing net (#0)
I0929 11:20:28.677714  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:20:28.820268  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9172
I0929 11:20:28.820293  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.274016 (* 1 = 0.274016 loss)
I0929 11:20:28.961030  1584 solver.cpp:218] Iteration 45500 (5.60875 iter/s, 17.8293s/100 iters), loss = 0.0219348
I0929 11:20:28.961064  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0219342 (* 1 = 0.0219342 loss)
I0929 11:20:28.961071  1584 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I0929 11:20:43.300173  1584 solver.cpp:218] Iteration 45600 (6.97396 iter/s, 14.3391s/100 iters), loss = 0.032105
I0929 11:20:43.300209  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0321044 (* 1 = 0.0321044 loss)
I0929 11:20:43.300227  1584 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I0929 11:20:57.623636  1584 solver.cpp:218] Iteration 45700 (6.98159 iter/s, 14.3234s/100 iters), loss = 0.0316719
I0929 11:20:57.623754  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0316713 (* 1 = 0.0316713 loss)
I0929 11:20:57.623762  1584 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I0929 11:21:11.964599  1584 solver.cpp:218] Iteration 45800 (6.97311 iter/s, 14.3408s/100 iters), loss = 0.020795
I0929 11:21:11.964629  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0207944 (* 1 = 0.0207944 loss)
I0929 11:21:11.964635  1584 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I0929 11:21:26.262694  1584 solver.cpp:218] Iteration 45900 (6.99398 iter/s, 14.298s/100 iters), loss = 0.0136143
I0929 11:21:26.262730  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136137 (* 1 = 0.0136137 loss)
I0929 11:21:26.262738  1584 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I0929 11:21:39.881259  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:21:40.450717  1584 solver.cpp:330] Iteration 46000, Testing net (#0)
I0929 11:21:43.827594  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:21:43.967998  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9167
I0929 11:21:43.968022  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.283573 (* 1 = 0.283573 loss)
I0929 11:21:44.111166  1584 solver.cpp:218] Iteration 46000 (5.60275 iter/s, 17.8484s/100 iters), loss = 0.0149288
I0929 11:21:44.111202  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149282 (* 1 = 0.0149282 loss)
I0929 11:21:44.111210  1584 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I0929 11:21:58.446300  1584 solver.cpp:218] Iteration 46100 (6.9759 iter/s, 14.3351s/100 iters), loss = 0.0426263
I0929 11:21:58.446331  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0426257 (* 1 = 0.0426257 loss)
I0929 11:21:58.446336  1584 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I0929 11:22:12.769582  1584 solver.cpp:218] Iteration 46200 (6.98168 iter/s, 14.3232s/100 iters), loss = 0.0323297
I0929 11:22:12.769685  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0323291 (* 1 = 0.0323291 loss)
I0929 11:22:12.769693  1584 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I0929 11:22:27.106075  1584 solver.cpp:218] Iteration 46300 (6.97528 iter/s, 14.3363s/100 iters), loss = 0.0180711
I0929 11:22:27.106104  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0180704 (* 1 = 0.0180704 loss)
I0929 11:22:27.106112  1584 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I0929 11:22:41.431812  1584 solver.cpp:218] Iteration 46400 (6.98048 iter/s, 14.3257s/100 iters), loss = 0.00339237
I0929 11:22:41.431844  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00339174 (* 1 = 0.00339174 loss)
I0929 11:22:41.431851  1584 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I0929 11:22:55.006597  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:22:55.576102  1584 solver.cpp:330] Iteration 46500, Testing net (#0)
I0929 11:22:58.986030  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:22:59.130770  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9171
I0929 11:22:59.130822  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.281672 (* 1 = 0.281672 loss)
I0929 11:22:59.275293  1584 solver.cpp:218] Iteration 46500 (5.60431 iter/s, 17.8434s/100 iters), loss = 0.00632674
I0929 11:22:59.275328  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0063261 (* 1 = 0.0063261 loss)
I0929 11:22:59.275336  1584 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I0929 11:23:13.620793  1584 solver.cpp:218] Iteration 46600 (6.97086 iter/s, 14.3454s/100 iters), loss = 0.0363291
I0929 11:23:13.620837  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0363284 (* 1 = 0.0363284 loss)
I0929 11:23:13.620856  1584 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I0929 11:23:27.940332  1584 solver.cpp:218] Iteration 46700 (6.98351 iter/s, 14.3195s/100 iters), loss = 0.00630337
I0929 11:23:27.940465  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00630274 (* 1 = 0.00630274 loss)
I0929 11:23:27.940474  1584 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I0929 11:23:42.282568  1584 solver.cpp:218] Iteration 46800 (6.9725 iter/s, 14.3421s/100 iters), loss = 0.0186959
I0929 11:23:42.282608  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0186953 (* 1 = 0.0186953 loss)
I0929 11:23:42.282618  1584 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I0929 11:23:56.623015  1584 solver.cpp:218] Iteration 46900 (6.97343 iter/s, 14.3401s/100 iters), loss = 0.00523287
I0929 11:23:56.623046  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00523222 (* 1 = 0.00523222 loss)
I0929 11:23:56.623054  1584 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I0929 11:24:10.215770  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:24:10.784457  1584 solver.cpp:330] Iteration 47000, Testing net (#0)
I0929 11:24:14.156457  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:24:14.299453  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9202
I0929 11:24:14.299479  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.274744 (* 1 = 0.274744 loss)
I0929 11:24:14.441694  1584 solver.cpp:218] Iteration 47000 (5.61211 iter/s, 17.8186s/100 iters), loss = 0.00658583
I0929 11:24:14.441730  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00658519 (* 1 = 0.00658519 loss)
I0929 11:24:14.441737  1584 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I0929 11:24:28.779621  1584 solver.cpp:218] Iteration 47100 (6.97455 iter/s, 14.3378s/100 iters), loss = 0.0088887
I0929 11:24:28.779652  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00888806 (* 1 = 0.00888806 loss)
I0929 11:24:28.779659  1584 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I0929 11:24:43.103320  1584 solver.cpp:218] Iteration 47200 (6.98147 iter/s, 14.3236s/100 iters), loss = 0.0347643
I0929 11:24:43.103463  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0347636 (* 1 = 0.0347636 loss)
I0929 11:24:43.103472  1584 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I0929 11:24:57.397950  1584 solver.cpp:218] Iteration 47300 (6.99572 iter/s, 14.2944s/100 iters), loss = 0.0291834
I0929 11:24:57.397981  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0291827 (* 1 = 0.0291827 loss)
I0929 11:24:57.397989  1584 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I0929 11:25:11.638537  1584 solver.cpp:218] Iteration 47400 (7.02222 iter/s, 14.2405s/100 iters), loss = 0.00874937
I0929 11:25:11.638569  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00874872 (* 1 = 0.00874872 loss)
I0929 11:25:11.638576  1584 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I0929 11:25:25.156967  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:25:25.724824  1584 solver.cpp:330] Iteration 47500, Testing net (#0)
I0929 11:25:29.086210  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:25:29.232051  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9192
I0929 11:25:29.232100  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.273809 (* 1 = 0.273809 loss)
I0929 11:25:29.375007  1584 solver.cpp:218] Iteration 47500 (5.63813 iter/s, 17.7364s/100 iters), loss = 0.0166408
I0929 11:25:29.375073  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0166402 (* 1 = 0.0166402 loss)
I0929 11:25:29.375080  1584 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I0929 11:25:43.602603  1584 solver.cpp:218] Iteration 47600 (7.02865 iter/s, 14.2275s/100 iters), loss = 0.0368507
I0929 11:25:43.602644  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.03685 (* 1 = 0.03685 loss)
I0929 11:25:43.602650  1584 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I0929 11:25:57.835549  1584 solver.cpp:218] Iteration 47700 (7.02599 iter/s, 14.2329s/100 iters), loss = 0.0301974
I0929 11:25:57.835669  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0301968 (* 1 = 0.0301968 loss)
I0929 11:25:57.835685  1584 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I0929 11:26:12.080835  1584 solver.cpp:218] Iteration 47800 (7.01994 iter/s, 14.2451s/100 iters), loss = 0.0132985
I0929 11:26:12.080864  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132978 (* 1 = 0.0132978 loss)
I0929 11:26:12.080870  1584 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I0929 11:26:26.322572  1584 solver.cpp:218] Iteration 47900 (7.02166 iter/s, 14.2417s/100 iters), loss = 0.0115494
I0929 11:26:26.322640  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115487 (* 1 = 0.0115487 loss)
I0929 11:26:26.322648  1584 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I0929 11:26:39.836649  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:26:40.405802  1584 solver.cpp:330] Iteration 48000, Testing net (#0)
I0929 11:26:43.759522  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:26:43.899893  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9243
I0929 11:26:43.899919  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.269012 (* 1 = 0.269012 loss)
I0929 11:26:44.040448  1584 solver.cpp:218] Iteration 48000 (5.64405 iter/s, 17.7178s/100 iters), loss = 0.0230242
I0929 11:26:44.040482  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0230235 (* 1 = 0.0230235 loss)
I0929 11:26:44.040488  1584 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I0929 11:26:58.279685  1584 solver.cpp:218] Iteration 48100 (7.02289 iter/s, 14.2392s/100 iters), loss = 0.0110426
I0929 11:26:58.279716  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110419 (* 1 = 0.0110419 loss)
I0929 11:26:58.279721  1584 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I0929 11:27:12.628062  1584 solver.cpp:218] Iteration 48200 (6.96946 iter/s, 14.3483s/100 iters), loss = 0.0719318
I0929 11:27:12.628203  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0719312 (* 1 = 0.0719312 loss)
I0929 11:27:12.628216  1584 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I0929 11:27:26.887114  1584 solver.cpp:218] Iteration 48300 (7.01318 iter/s, 14.2589s/100 iters), loss = 0.0364873
I0929 11:27:26.887150  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0364866 (* 1 = 0.0364866 loss)
I0929 11:27:26.887158  1584 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I0929 11:27:41.227161  1584 solver.cpp:218] Iteration 48400 (6.97353 iter/s, 14.3399s/100 iters), loss = 0.0148397
I0929 11:27:41.227214  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014839 (* 1 = 0.014839 loss)
I0929 11:27:41.227226  1584 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I0929 11:27:54.814196  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:27:55.389780  1584 solver.cpp:330] Iteration 48500, Testing net (#0)
I0929 11:27:58.776903  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:27:58.922441  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9174
I0929 11:27:58.922488  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.28869 (* 1 = 0.28869 loss)
I0929 11:27:59.068867  1584 solver.cpp:218] Iteration 48500 (5.60489 iter/s, 17.8416s/100 iters), loss = 0.0375947
I0929 11:27:59.068910  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0375941 (* 1 = 0.0375941 loss)
I0929 11:27:59.068922  1584 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I0929 11:28:13.414685  1584 solver.cpp:218] Iteration 48600 (6.97071 iter/s, 14.3457s/100 iters), loss = 0.00938324
I0929 11:28:13.414721  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00938256 (* 1 = 0.00938256 loss)
I0929 11:28:13.414731  1584 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I0929 11:28:27.705919  1584 solver.cpp:218] Iteration 48700 (6.99733 iter/s, 14.2912s/100 iters), loss = 0.0132601
I0929 11:28:27.706063  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132594 (* 1 = 0.0132594 loss)
I0929 11:28:27.706075  1584 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I0929 11:28:42.079247  1584 solver.cpp:218] Iteration 48800 (6.95742 iter/s, 14.3731s/100 iters), loss = 0.0206458
I0929 11:28:42.079282  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0206451 (* 1 = 0.0206451 loss)
I0929 11:28:42.079290  1584 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I0929 11:28:56.401406  1584 solver.cpp:218] Iteration 48900 (6.98223 iter/s, 14.3221s/100 iters), loss = 0.0128395
I0929 11:28:56.401444  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128388 (* 1 = 0.0128388 loss)
I0929 11:28:56.401453  1584 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I0929 11:29:09.963059  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:29:10.540293  1584 solver.cpp:330] Iteration 49000, Testing net (#0)
I0929 11:29:13.910519  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:29:14.052170  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9196
I0929 11:29:14.052211  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.2803 (* 1 = 0.2803 loss)
I0929 11:29:14.198274  1584 solver.cpp:218] Iteration 49000 (5.61899 iter/s, 17.7968s/100 iters), loss = 0.00875907
I0929 11:29:14.198312  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00875838 (* 1 = 0.00875838 loss)
I0929 11:29:14.198320  1584 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I0929 11:29:28.577247  1584 solver.cpp:218] Iteration 49100 (6.95464 iter/s, 14.3789s/100 iters), loss = 0.0475032
I0929 11:29:28.577277  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0475025 (* 1 = 0.0475025 loss)
I0929 11:29:28.577283  1584 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I0929 11:29:42.884496  1584 solver.cpp:218] Iteration 49200 (6.9895 iter/s, 14.3072s/100 iters), loss = 0.00528546
I0929 11:29:42.884616  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00528476 (* 1 = 0.00528476 loss)
I0929 11:29:42.884624  1584 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I0929 11:29:57.173084  1584 solver.cpp:218] Iteration 49300 (6.99867 iter/s, 14.2884s/100 iters), loss = 0.00601553
I0929 11:29:57.173116  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00601484 (* 1 = 0.00601484 loss)
I0929 11:29:57.173122  1584 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I0929 11:30:11.473417  1584 solver.cpp:218] Iteration 49400 (6.99288 iter/s, 14.3003s/100 iters), loss = 0.00482007
I0929 11:30:11.473448  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00481938 (* 1 = 0.00481938 loss)
I0929 11:30:11.473456  1584 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I0929 11:30:25.021126  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:30:25.591266  1584 solver.cpp:330] Iteration 49500, Testing net (#0)
I0929 11:30:28.952337  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:30:29.093289  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9202
I0929 11:30:29.093315  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.290234 (* 1 = 0.290234 loss)
I0929 11:30:29.236938  1584 solver.cpp:218] Iteration 49500 (5.62954 iter/s, 17.7634s/100 iters), loss = 0.0310313
I0929 11:30:29.236984  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0310306 (* 1 = 0.0310306 loss)
I0929 11:30:29.236992  1584 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I0929 11:30:43.500629  1584 solver.cpp:218] Iteration 49600 (7.01086 iter/s, 14.2636s/100 iters), loss = 0.0303856
I0929 11:30:43.500663  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0303849 (* 1 = 0.0303849 loss)
I0929 11:30:43.500670  1584 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I0929 11:30:57.794262  1584 solver.cpp:218] Iteration 49700 (6.99616 iter/s, 14.2936s/100 iters), loss = 0.0052597
I0929 11:30:57.794364  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.005259 (* 1 = 0.005259 loss)
I0929 11:30:57.794381  1584 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I0929 11:31:12.071497  1584 solver.cpp:218] Iteration 49800 (7.00429 iter/s, 14.277s/100 iters), loss = 0.0152476
I0929 11:31:12.071534  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152469 (* 1 = 0.0152469 loss)
I0929 11:31:12.071552  1584 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I0929 11:31:26.338753  1584 solver.cpp:218] Iteration 49900 (7.00915 iter/s, 14.2671s/100 iters), loss = 0.00504546
I0929 11:31:26.338830  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00504477 (* 1 = 0.00504477 loss)
I0929 11:31:26.338838  1584 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I0929 11:31:39.886833  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:31:40.460620  1584 solver.cpp:330] Iteration 50000, Testing net (#0)
I0929 11:31:43.834372  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:31:43.976121  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9175
I0929 11:31:43.976147  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.297034 (* 1 = 0.297034 loss)
I0929 11:31:44.118634  1584 solver.cpp:218] Iteration 50000 (5.62438 iter/s, 17.7797s/100 iters), loss = 0.00265772
I0929 11:31:44.118683  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00265703 (* 1 = 0.00265703 loss)
I0929 11:31:44.118691  1584 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I0929 11:31:58.414971  1584 solver.cpp:218] Iteration 50100 (6.99484 iter/s, 14.2962s/100 iters), loss = 0.0294589
I0929 11:31:58.415002  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0294582 (* 1 = 0.0294582 loss)
I0929 11:31:58.415009  1584 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I0929 11:32:12.704684  1584 solver.cpp:218] Iteration 50200 (6.99808 iter/s, 14.2896s/100 iters), loss = 0.0125615
I0929 11:32:12.704800  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125608 (* 1 = 0.0125608 loss)
I0929 11:32:12.704808  1584 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I0929 11:32:26.967736  1584 solver.cpp:218] Iteration 50300 (7.0112 iter/s, 14.2629s/100 iters), loss = 0.0271722
I0929 11:32:26.967779  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0271715 (* 1 = 0.0271715 loss)
I0929 11:32:26.967787  1584 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I0929 11:32:41.217962  1584 solver.cpp:218] Iteration 50400 (7.01748 iter/s, 14.2501s/100 iters), loss = 0.0320128
I0929 11:32:41.217998  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0320121 (* 1 = 0.0320121 loss)
I0929 11:32:41.218006  1584 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I0929 11:32:54.742542  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:32:55.311249  1584 solver.cpp:330] Iteration 50500, Testing net (#0)
I0929 11:32:58.668799  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:32:58.808928  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.92
I0929 11:32:58.808964  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295657 (* 1 = 0.295657 loss)
I0929 11:32:58.949821  1584 solver.cpp:218] Iteration 50500 (5.63959 iter/s, 17.7318s/100 iters), loss = 0.00538381
I0929 11:32:58.949852  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00538312 (* 1 = 0.00538312 loss)
I0929 11:32:58.949859  1584 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I0929 11:33:13.182579  1584 solver.cpp:218] Iteration 50600 (7.02608 iter/s, 14.2327s/100 iters), loss = 0.0392157
I0929 11:33:13.182608  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.039215 (* 1 = 0.039215 loss)
I0929 11:33:13.182615  1584 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I0929 11:33:27.432561  1584 solver.cpp:218] Iteration 50700 (7.01759 iter/s, 14.2499s/100 iters), loss = 0.0160633
I0929 11:33:27.432682  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0160626 (* 1 = 0.0160626 loss)
I0929 11:33:27.432699  1584 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I0929 11:33:41.672883  1584 solver.cpp:218] Iteration 50800 (7.02239 iter/s, 14.2402s/100 iters), loss = 0.0119441
I0929 11:33:41.672916  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0119434 (* 1 = 0.0119434 loss)
I0929 11:33:41.672924  1584 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I0929 11:33:55.899912  1584 solver.cpp:218] Iteration 50900 (7.02891 iter/s, 14.227s/100 iters), loss = 0.0130386
I0929 11:33:55.899945  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130379 (* 1 = 0.0130379 loss)
I0929 11:33:55.899962  1584 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I0929 11:34:09.437818  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:34:10.005928  1584 solver.cpp:330] Iteration 51000, Testing net (#0)
I0929 11:34:13.366364  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:34:13.506194  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9221
I0929 11:34:13.506219  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.286058 (* 1 = 0.286058 loss)
I0929 11:34:13.647070  1584 solver.cpp:218] Iteration 51000 (5.63473 iter/s, 17.7471s/100 iters), loss = 0.0115723
I0929 11:34:13.647106  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115716 (* 1 = 0.0115716 loss)
I0929 11:34:13.647115  1584 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I0929 11:34:27.887734  1584 solver.cpp:218] Iteration 51100 (7.02218 iter/s, 14.2406s/100 iters), loss = 0.0143575
I0929 11:34:27.887768  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143567 (* 1 = 0.0143567 loss)
I0929 11:34:27.887786  1584 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I0929 11:34:42.106237  1584 solver.cpp:218] Iteration 51200 (7.03313 iter/s, 14.2184s/100 iters), loss = 0.019104
I0929 11:34:42.106384  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0191033 (* 1 = 0.0191033 loss)
I0929 11:34:42.106397  1584 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I0929 11:34:56.339983  1584 solver.cpp:218] Iteration 51300 (7.02565 iter/s, 14.2336s/100 iters), loss = 0.0164787
I0929 11:34:56.340034  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.016478 (* 1 = 0.016478 loss)
I0929 11:34:56.340044  1584 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I0929 11:35:10.576241  1584 solver.cpp:218] Iteration 51400 (7.02436 iter/s, 14.2362s/100 iters), loss = 0.0173651
I0929 11:35:10.576282  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0173643 (* 1 = 0.0173643 loss)
I0929 11:35:10.576289  1584 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I0929 11:35:24.104282  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:35:24.672834  1584 solver.cpp:330] Iteration 51500, Testing net (#0)
I0929 11:35:28.028583  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:35:28.168555  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9213
I0929 11:35:28.168589  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.28837 (* 1 = 0.28837 loss)
I0929 11:35:28.308873  1584 solver.cpp:218] Iteration 51500 (5.63935 iter/s, 17.7325s/100 iters), loss = 0.00658968
I0929 11:35:28.308907  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00658897 (* 1 = 0.00658897 loss)
I0929 11:35:28.308913  1584 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I0929 11:35:42.561626  1584 solver.cpp:218] Iteration 51600 (7.01623 iter/s, 14.2527s/100 iters), loss = 0.0113457
I0929 11:35:42.561667  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011345 (* 1 = 0.011345 loss)
I0929 11:35:42.561673  1584 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I0929 11:35:56.807612  1584 solver.cpp:218] Iteration 51700 (7.01956 iter/s, 14.2459s/100 iters), loss = 0.00551825
I0929 11:35:56.807693  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00551753 (* 1 = 0.00551753 loss)
I0929 11:35:56.807701  1584 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I0929 11:36:11.050487  1584 solver.cpp:218] Iteration 51800 (7.02111 iter/s, 14.2428s/100 iters), loss = 0.012555
I0929 11:36:11.050529  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125543 (* 1 = 0.0125543 loss)
I0929 11:36:11.050535  1584 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I0929 11:36:25.291930  1584 solver.cpp:218] Iteration 51900 (7.0218 iter/s, 14.2414s/100 iters), loss = 0.00223431
I0929 11:36:25.291972  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00223358 (* 1 = 0.00223358 loss)
I0929 11:36:25.291978  1584 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I0929 11:36:38.839298  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:36:39.407966  1584 solver.cpp:330] Iteration 52000, Testing net (#0)
I0929 11:36:42.768110  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:36:42.907922  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9219
I0929 11:36:42.907956  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.290512 (* 1 = 0.290512 loss)
I0929 11:36:43.048866  1584 solver.cpp:218] Iteration 52000 (5.63163 iter/s, 17.7568s/100 iters), loss = 0.00677453
I0929 11:36:43.048899  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0067738 (* 1 = 0.0067738 loss)
I0929 11:36:43.048905  1584 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I0929 11:36:57.296906  1584 solver.cpp:218] Iteration 52100 (7.01855 iter/s, 14.248s/100 iters), loss = 0.012491
I0929 11:36:57.296947  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124903 (* 1 = 0.0124903 loss)
I0929 11:36:57.296952  1584 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I0929 11:37:11.543804  1584 solver.cpp:218] Iteration 52200 (7.01911 iter/s, 14.2468s/100 iters), loss = 0.0267294
I0929 11:37:11.543925  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0267287 (* 1 = 0.0267287 loss)
I0929 11:37:11.543932  1584 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I0929 11:37:25.785527  1584 solver.cpp:218] Iteration 52300 (7.0217 iter/s, 14.2416s/100 iters), loss = 0.04731
I0929 11:37:25.785568  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0473093 (* 1 = 0.0473093 loss)
I0929 11:37:25.785574  1584 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I0929 11:37:40.029356  1584 solver.cpp:218] Iteration 52400 (7.02063 iter/s, 14.2437s/100 iters), loss = 0.0175605
I0929 11:37:40.029388  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0175598 (* 1 = 0.0175598 loss)
I0929 11:37:40.029394  1584 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I0929 11:37:53.554728  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:37:54.123010  1584 solver.cpp:330] Iteration 52500, Testing net (#0)
I0929 11:37:57.478613  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:37:57.618535  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9203
I0929 11:37:57.618568  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.297505 (* 1 = 0.297505 loss)
I0929 11:37:57.759213  1584 solver.cpp:218] Iteration 52500 (5.64023 iter/s, 17.7298s/100 iters), loss = 0.00687343
I0929 11:37:57.759248  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00687272 (* 1 = 0.00687272 loss)
I0929 11:37:57.759254  1584 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I0929 11:38:12.006927  1584 solver.cpp:218] Iteration 52600 (7.01871 iter/s, 14.2476s/100 iters), loss = 0.00359122
I0929 11:38:12.006958  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00359051 (* 1 = 0.00359051 loss)
I0929 11:38:12.006965  1584 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I0929 11:38:26.247187  1584 solver.cpp:218] Iteration 52700 (7.02238 iter/s, 14.2402s/100 iters), loss = 0.0259971
I0929 11:38:26.247335  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0259964 (* 1 = 0.0259964 loss)
I0929 11:38:26.247344  1584 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I0929 11:38:40.467540  1584 solver.cpp:218] Iteration 52800 (7.03226 iter/s, 14.2202s/100 iters), loss = 0.0104471
I0929 11:38:40.467571  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104464 (* 1 = 0.0104464 loss)
I0929 11:38:40.467576  1584 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I0929 11:38:54.707643  1584 solver.cpp:218] Iteration 52900 (7.02246 iter/s, 14.24s/100 iters), loss = 0.00417924
I0929 11:38:54.707674  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00417853 (* 1 = 0.00417853 loss)
I0929 11:38:54.707680  1584 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I0929 11:39:08.238097  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:39:08.811441  1584 solver.cpp:330] Iteration 53000, Testing net (#0)
I0929 11:39:12.169363  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:39:12.309146  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9191
I0929 11:39:12.309172  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300966 (* 1 = 0.300966 loss)
I0929 11:39:12.450135  1584 solver.cpp:218] Iteration 53000 (5.63621 iter/s, 17.7424s/100 iters), loss = 0.00317914
I0929 11:39:12.450166  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00317843 (* 1 = 0.00317843 loss)
I0929 11:39:12.450172  1584 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I0929 11:39:26.675901  1584 solver.cpp:218] Iteration 53100 (7.02953 iter/s, 14.2257s/100 iters), loss = 0.00544572
I0929 11:39:26.675941  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00544501 (* 1 = 0.00544501 loss)
I0929 11:39:26.675950  1584 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I0929 11:39:40.904737  1584 solver.cpp:218] Iteration 53200 (7.02802 iter/s, 14.2288s/100 iters), loss = 0.0504617
I0929 11:39:40.904865  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.050461 (* 1 = 0.050461 loss)
I0929 11:39:40.904872  1584 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I0929 11:39:55.152684  1584 solver.cpp:218] Iteration 53300 (7.01864 iter/s, 14.2478s/100 iters), loss = 0.00351088
I0929 11:39:55.152724  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00351018 (* 1 = 0.00351018 loss)
I0929 11:39:55.152730  1584 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I0929 11:40:09.391093  1584 solver.cpp:218] Iteration 53400 (7.0233 iter/s, 14.2383s/100 iters), loss = 0.0035452
I0929 11:40:09.391124  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0035445 (* 1 = 0.0035445 loss)
I0929 11:40:09.391130  1584 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I0929 11:40:22.902351  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:40:23.480177  1584 solver.cpp:330] Iteration 53500, Testing net (#0)
I0929 11:40:26.839639  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:40:26.979552  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9188
I0929 11:40:26.979588  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.301471 (* 1 = 0.301471 loss)
I0929 11:40:27.120136  1584 solver.cpp:218] Iteration 53500 (5.64049 iter/s, 17.729s/100 iters), loss = 0.00869874
I0929 11:40:27.120169  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00869804 (* 1 = 0.00869804 loss)
I0929 11:40:27.120175  1584 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I0929 11:40:41.368815  1584 solver.cpp:218] Iteration 53600 (7.01823 iter/s, 14.2486s/100 iters), loss = 0.00645908
I0929 11:40:41.368850  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00645838 (* 1 = 0.00645838 loss)
I0929 11:40:41.368857  1584 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I0929 11:40:55.602170  1584 solver.cpp:218] Iteration 53700 (7.02579 iter/s, 14.2333s/100 iters), loss = 0.00317874
I0929 11:40:55.602289  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00317803 (* 1 = 0.00317803 loss)
I0929 11:40:55.602306  1584 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I0929 11:41:09.842950  1584 solver.cpp:218] Iteration 53800 (7.02216 iter/s, 14.2406s/100 iters), loss = 0.00679345
I0929 11:41:09.842991  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00679274 (* 1 = 0.00679274 loss)
I0929 11:41:09.842998  1584 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I0929 11:41:24.096696  1584 solver.cpp:218] Iteration 53900 (7.01574 iter/s, 14.2537s/100 iters), loss = 0.00421775
I0929 11:41:24.096729  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00421705 (* 1 = 0.00421705 loss)
I0929 11:41:24.096737  1584 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I0929 11:41:37.636451  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:41:38.208312  1584 solver.cpp:330] Iteration 54000, Testing net (#0)
I0929 11:41:41.568794  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:41:41.708818  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.921
I0929 11:41:41.708853  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.29259 (* 1 = 0.29259 loss)
I0929 11:41:41.848896  1584 solver.cpp:218] Iteration 54000 (5.63313 iter/s, 17.7521s/100 iters), loss = 0.010098
I0929 11:41:41.848929  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100973 (* 1 = 0.0100973 loss)
I0929 11:41:41.848947  1584 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I0929 11:41:56.076555  1584 solver.cpp:218] Iteration 54100 (7.0286 iter/s, 14.2276s/100 iters), loss = 0.0192277
I0929 11:41:56.076586  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.019227 (* 1 = 0.019227 loss)
I0929 11:41:56.076593  1584 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I0929 11:42:10.320096  1584 solver.cpp:218] Iteration 54200 (7.02076 iter/s, 14.2435s/100 iters), loss = 0.00187803
I0929 11:42:10.320206  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00187733 (* 1 = 0.00187733 loss)
I0929 11:42:10.320225  1584 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I0929 11:42:24.567958  1584 solver.cpp:218] Iteration 54300 (7.01867 iter/s, 14.2477s/100 iters), loss = 0.00490899
I0929 11:42:24.567999  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0049083 (* 1 = 0.0049083 loss)
I0929 11:42:24.568006  1584 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I0929 11:42:38.800313  1584 solver.cpp:218] Iteration 54400 (7.02629 iter/s, 14.2323s/100 iters), loss = 0.0090336
I0929 11:42:38.800355  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00903292 (* 1 = 0.00903292 loss)
I0929 11:42:38.800361  1584 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I0929 11:42:52.321832  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:42:52.890221  1584 solver.cpp:330] Iteration 54500, Testing net (#0)
I0929 11:42:56.249619  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:42:56.393043  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9206
I0929 11:42:56.393071  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.302016 (* 1 = 0.302016 loss)
I0929 11:42:56.536010  1584 solver.cpp:218] Iteration 54500 (5.63838 iter/s, 17.7356s/100 iters), loss = 0.00916474
I0929 11:42:56.536046  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00916405 (* 1 = 0.00916405 loss)
I0929 11:42:56.536062  1584 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I0929 11:43:10.762073  1584 solver.cpp:218] Iteration 54600 (7.02939 iter/s, 14.226s/100 iters), loss = 0.00959402
I0929 11:43:10.762105  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00959332 (* 1 = 0.00959332 loss)
I0929 11:43:10.762111  1584 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I0929 11:43:24.989184  1584 solver.cpp:218] Iteration 54700 (7.02887 iter/s, 14.227s/100 iters), loss = 0.00456393
I0929 11:43:24.989293  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00456322 (* 1 = 0.00456322 loss)
I0929 11:43:24.989300  1584 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I0929 11:43:39.215304  1584 solver.cpp:218] Iteration 54800 (7.02939 iter/s, 14.226s/100 iters), loss = 0.0257921
I0929 11:43:39.215345  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0257914 (* 1 = 0.0257914 loss)
I0929 11:43:39.215353  1584 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I0929 11:43:53.454862  1584 solver.cpp:218] Iteration 54900 (7.02273 iter/s, 14.2395s/100 iters), loss = 0.00112512
I0929 11:43:53.454897  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00112442 (* 1 = 0.00112442 loss)
I0929 11:43:53.454915  1584 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I0929 11:44:06.975405  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:44:07.543148  1584 solver.cpp:330] Iteration 55000, Testing net (#0)
I0929 11:44:10.897431  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:44:11.037541  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9211
I0929 11:44:11.037577  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295497 (* 1 = 0.295497 loss)
I0929 11:44:11.179354  1584 solver.cpp:218] Iteration 55000 (5.64194 iter/s, 17.7244s/100 iters), loss = 0.0345827
I0929 11:44:11.179388  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.034582 (* 1 = 0.034582 loss)
I0929 11:44:11.179394  1584 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I0929 11:44:25.417532  1584 solver.cpp:218] Iteration 55100 (7.02341 iter/s, 14.2381s/100 iters), loss = 0.003958
I0929 11:44:25.417564  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00395729 (* 1 = 0.00395729 loss)
I0929 11:44:25.417572  1584 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I0929 11:44:39.670927  1584 solver.cpp:218] Iteration 55200 (7.01591 iter/s, 14.2533s/100 iters), loss = 0.00305191
I0929 11:44:39.671051  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00305121 (* 1 = 0.00305121 loss)
I0929 11:44:39.671058  1584 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I0929 11:44:53.911496  1584 solver.cpp:218] Iteration 55300 (7.02227 iter/s, 14.2404s/100 iters), loss = 0.0125823
I0929 11:44:53.911527  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125816 (* 1 = 0.0125816 loss)
I0929 11:44:53.911533  1584 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I0929 11:45:08.144445  1584 solver.cpp:218] Iteration 55400 (7.02599 iter/s, 14.2329s/100 iters), loss = 0.00300078
I0929 11:45:08.144480  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00300007 (* 1 = 0.00300007 loss)
I0929 11:45:08.144487  1584 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I0929 11:45:21.685593  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:45:22.257673  1584 solver.cpp:330] Iteration 55500, Testing net (#0)
I0929 11:45:25.615293  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:45:25.755592  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9186
I0929 11:45:25.755616  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.3124 (* 1 = 0.3124 loss)
I0929 11:45:25.896263  1584 solver.cpp:218] Iteration 55500 (5.63325 iter/s, 17.7517s/100 iters), loss = 0.00387892
I0929 11:45:25.896294  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00387821 (* 1 = 0.00387821 loss)
I0929 11:45:25.896301  1584 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I0929 11:45:40.137205  1584 solver.cpp:218] Iteration 55600 (7.02204 iter/s, 14.2409s/100 iters), loss = 0.00667489
I0929 11:45:40.137236  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00667418 (* 1 = 0.00667418 loss)
I0929 11:45:40.137243  1584 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I0929 11:45:54.361825  1584 solver.cpp:218] Iteration 55700 (7.0301 iter/s, 14.2245s/100 iters), loss = 0.00679173
I0929 11:45:54.361938  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00679102 (* 1 = 0.00679102 loss)
I0929 11:45:54.361945  1584 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I0929 11:46:08.594954  1584 solver.cpp:218] Iteration 55800 (7.02594 iter/s, 14.233s/100 iters), loss = 0.014092
I0929 11:46:08.594987  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0140913 (* 1 = 0.0140913 loss)
I0929 11:46:08.594993  1584 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I0929 11:46:22.820099  1584 solver.cpp:218] Iteration 55900 (7.02984 iter/s, 14.2251s/100 iters), loss = 0.00348891
I0929 11:46:22.820132  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0034882 (* 1 = 0.0034882 loss)
I0929 11:46:22.820138  1584 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I0929 11:46:36.346452  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:46:36.915397  1584 solver.cpp:330] Iteration 56000, Testing net (#0)
I0929 11:46:40.270566  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:46:40.410419  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9209
I0929 11:46:40.410454  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.301581 (* 1 = 0.301581 loss)
I0929 11:46:40.550981  1584 solver.cpp:218] Iteration 56000 (5.6399 iter/s, 17.7308s/100 iters), loss = 0.00529132
I0929 11:46:40.551009  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00529061 (* 1 = 0.00529061 loss)
I0929 11:46:40.551017  1584 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I0929 11:46:54.793097  1584 solver.cpp:218] Iteration 56100 (7.02146 iter/s, 14.242s/100 iters), loss = 0.0202228
I0929 11:46:54.793128  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0202221 (* 1 = 0.0202221 loss)
I0929 11:46:54.793135  1584 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I0929 11:47:09.026074  1584 solver.cpp:218] Iteration 56200 (7.02597 iter/s, 14.2329s/100 iters), loss = 0.00226556
I0929 11:47:09.026201  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00226486 (* 1 = 0.00226486 loss)
I0929 11:47:09.026207  1584 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I0929 11:47:23.240623  1584 solver.cpp:218] Iteration 56300 (7.03513 iter/s, 14.2144s/100 iters), loss = 0.015247
I0929 11:47:23.240669  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152463 (* 1 = 0.0152463 loss)
I0929 11:47:23.240677  1584 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I0929 11:47:37.468797  1584 solver.cpp:218] Iteration 56400 (7.02837 iter/s, 14.228s/100 iters), loss = 0.00603186
I0929 11:47:37.468827  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00603116 (* 1 = 0.00603116 loss)
I0929 11:47:37.468844  1584 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I0929 11:47:51.001955  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:47:51.569975  1584 solver.cpp:330] Iteration 56500, Testing net (#0)
I0929 11:47:54.928459  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:47:55.068956  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9209
I0929 11:47:55.068991  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.297332 (* 1 = 0.297332 loss)
I0929 11:47:55.209388  1584 solver.cpp:218] Iteration 56500 (5.63682 iter/s, 17.7405s/100 iters), loss = 0.0010093
I0929 11:47:55.209416  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010086 (* 1 = 0.0010086 loss)
I0929 11:47:55.209424  1584 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I0929 11:48:09.451339  1584 solver.cpp:218] Iteration 56600 (7.02154 iter/s, 14.2419s/100 iters), loss = 0.0102981
I0929 11:48:09.451369  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102974 (* 1 = 0.0102974 loss)
I0929 11:48:09.451375  1584 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I0929 11:48:23.679831  1584 solver.cpp:218] Iteration 56700 (7.02819 iter/s, 14.2284s/100 iters), loss = 0.005055
I0929 11:48:23.679934  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0050543 (* 1 = 0.0050543 loss)
I0929 11:48:23.679950  1584 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I0929 11:48:37.916929  1584 solver.cpp:218] Iteration 56800 (7.02397 iter/s, 14.237s/100 iters), loss = 0.00601436
I0929 11:48:37.916970  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00601365 (* 1 = 0.00601365 loss)
I0929 11:48:37.916975  1584 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I0929 11:48:52.157140  1584 solver.cpp:218] Iteration 56900 (7.02241 iter/s, 14.2401s/100 iters), loss = 0.00256651
I0929 11:48:52.157176  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0025658 (* 1 = 0.0025658 loss)
I0929 11:48:52.157183  1584 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I0929 11:49:05.684469  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:49:06.252542  1584 solver.cpp:330] Iteration 57000, Testing net (#0)
I0929 11:49:09.609081  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:49:09.749109  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9192
I0929 11:49:09.749143  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.306678 (* 1 = 0.306678 loss)
I0929 11:49:09.890409  1584 solver.cpp:218] Iteration 57000 (5.63915 iter/s, 17.7332s/100 iters), loss = 0.00319129
I0929 11:49:09.890442  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00319058 (* 1 = 0.00319058 loss)
I0929 11:49:09.890449  1584 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I0929 11:49:24.133014  1584 solver.cpp:218] Iteration 57100 (7.02122 iter/s, 14.2425s/100 iters), loss = 0.00179237
I0929 11:49:24.133044  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00179166 (* 1 = 0.00179166 loss)
I0929 11:49:24.133050  1584 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I0929 11:49:38.372473  1584 solver.cpp:218] Iteration 57200 (7.02277 iter/s, 14.2394s/100 iters), loss = 0.00314257
I0929 11:49:38.372619  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00314187 (* 1 = 0.00314187 loss)
I0929 11:49:38.372629  1584 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I0929 11:49:52.599231  1584 solver.cpp:218] Iteration 57300 (7.0291 iter/s, 14.2266s/100 iters), loss = 0.00338697
I0929 11:49:52.599261  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00338625 (* 1 = 0.00338625 loss)
I0929 11:49:52.599267  1584 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I0929 11:50:06.834967  1584 solver.cpp:218] Iteration 57400 (7.02461 iter/s, 14.2357s/100 iters), loss = 0.00930238
I0929 11:50:06.834998  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00930167 (* 1 = 0.00930167 loss)
I0929 11:50:06.835005  1584 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I0929 11:50:20.371078  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:50:20.942270  1584 solver.cpp:330] Iteration 57500, Testing net (#0)
I0929 11:50:24.297365  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:50:24.437177  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.922
I0929 11:50:24.437213  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.299195 (* 1 = 0.299195 loss)
I0929 11:50:24.577659  1584 solver.cpp:218] Iteration 57500 (5.63615 iter/s, 17.7426s/100 iters), loss = 0.00187863
I0929 11:50:24.577689  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00187792 (* 1 = 0.00187792 loss)
I0929 11:50:24.577695  1584 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I0929 11:50:38.822466  1584 solver.cpp:218] Iteration 57600 (7.02014 iter/s, 14.2447s/100 iters), loss = 0.00220013
I0929 11:50:38.822499  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00219942 (* 1 = 0.00219942 loss)
I0929 11:50:38.822504  1584 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I0929 11:50:53.060727  1584 solver.cpp:218] Iteration 57700 (7.02336 iter/s, 14.2382s/100 iters), loss = 0.0126315
I0929 11:50:53.060861  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126308 (* 1 = 0.0126308 loss)
I0929 11:50:53.060869  1584 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I0929 11:51:07.318004  1584 solver.cpp:218] Iteration 57800 (7.01405 iter/s, 14.2571s/100 iters), loss = 0.00325748
I0929 11:51:07.318037  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00325677 (* 1 = 0.00325677 loss)
I0929 11:51:07.318043  1584 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I0929 11:51:21.564188  1584 solver.cpp:218] Iteration 57900 (7.01946 iter/s, 14.2461s/100 iters), loss = 0.00287483
I0929 11:51:21.564216  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00287412 (* 1 = 0.00287412 loss)
I0929 11:51:21.564222  1584 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I0929 11:51:35.093885  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:51:35.672016  1584 solver.cpp:330] Iteration 58000, Testing net (#0)
I0929 11:51:39.031082  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:51:39.169863  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9221
I0929 11:51:39.169898  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.29911 (* 1 = 0.29911 loss)
I0929 11:51:39.310312  1584 solver.cpp:218] Iteration 58000 (5.63506 iter/s, 17.746s/100 iters), loss = 0.00151986
I0929 11:51:39.310348  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00151914 (* 1 = 0.00151914 loss)
I0929 11:51:39.310353  1584 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I0929 11:51:53.559761  1584 solver.cpp:218] Iteration 58100 (7.01785 iter/s, 14.2494s/100 iters), loss = 0.00240333
I0929 11:51:53.559794  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00240262 (* 1 = 0.00240262 loss)
I0929 11:51:53.559803  1584 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I0929 11:52:07.802647  1584 solver.cpp:218] Iteration 58200 (7.02108 iter/s, 14.2428s/100 iters), loss = 0.00449142
I0929 11:52:07.802773  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00449072 (* 1 = 0.00449072 loss)
I0929 11:52:07.802793  1584 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I0929 11:52:22.043388  1584 solver.cpp:218] Iteration 58300 (7.02219 iter/s, 14.2406s/100 iters), loss = 0.0225884
I0929 11:52:22.043418  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0225877 (* 1 = 0.0225877 loss)
I0929 11:52:22.043424  1584 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I0929 11:52:36.286082  1584 solver.cpp:218] Iteration 58400 (7.02118 iter/s, 14.2426s/100 iters), loss = 0.000778861
I0929 11:52:36.286124  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000778147 (* 1 = 0.000778147 loss)
I0929 11:52:36.286131  1584 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I0929 11:52:49.816748  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:52:50.392407  1584 solver.cpp:330] Iteration 58500, Testing net (#0)
I0929 11:52:53.751847  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:52:53.891600  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.919
I0929 11:52:53.891625  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.315848 (* 1 = 0.315848 loss)
I0929 11:52:54.032562  1584 solver.cpp:218] Iteration 58500 (5.63495 iter/s, 17.7464s/100 iters), loss = 0.00262592
I0929 11:52:54.032593  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00262521 (* 1 = 0.00262521 loss)
I0929 11:52:54.032600  1584 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I0929 11:53:08.253592  1584 solver.cpp:218] Iteration 58600 (7.03188 iter/s, 14.221s/100 iters), loss = 0.00142595
I0929 11:53:08.253630  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00142524 (* 1 = 0.00142524 loss)
I0929 11:53:08.253639  1584 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I0929 11:53:22.481189  1584 solver.cpp:218] Iteration 58700 (7.02863 iter/s, 14.2275s/100 iters), loss = 0.00548612
I0929 11:53:22.481331  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00548541 (* 1 = 0.00548541 loss)
I0929 11:53:22.481341  1584 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I0929 11:53:36.714612  1584 solver.cpp:218] Iteration 58800 (7.02581 iter/s, 14.2332s/100 iters), loss = 0.00135023
I0929 11:53:36.714643  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00134953 (* 1 = 0.00134953 loss)
I0929 11:53:36.714649  1584 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I0929 11:53:50.939755  1584 solver.cpp:218] Iteration 58900 (7.02984 iter/s, 14.2251s/100 iters), loss = 0.00223769
I0929 11:53:50.939787  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00223698 (* 1 = 0.00223698 loss)
I0929 11:53:50.939805  1584 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I0929 11:54:04.448233  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:54:05.016348  1584 solver.cpp:330] Iteration 59000, Testing net (#0)
I0929 11:54:08.380455  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:54:08.522399  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9222
I0929 11:54:08.522425  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307828 (* 1 = 0.307828 loss)
I0929 11:54:08.663748  1584 solver.cpp:218] Iteration 59000 (5.6421 iter/s, 17.7239s/100 iters), loss = 0.00792579
I0929 11:54:08.663782  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00792508 (* 1 = 0.00792508 loss)
I0929 11:54:08.663789  1584 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I0929 11:54:22.895829  1584 solver.cpp:218] Iteration 59100 (7.02641 iter/s, 14.232s/100 iters), loss = 0.00287581
I0929 11:54:22.895859  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0028751 (* 1 = 0.0028751 loss)
I0929 11:54:22.895866  1584 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I0929 11:54:37.129845  1584 solver.cpp:218] Iteration 59200 (7.02546 iter/s, 14.2339s/100 iters), loss = 0.00317098
I0929 11:54:37.129989  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00317027 (* 1 = 0.00317027 loss)
I0929 11:54:37.129997  1584 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I0929 11:54:51.370548  1584 solver.cpp:218] Iteration 59300 (7.02221 iter/s, 14.2405s/100 iters), loss = 0.00196032
I0929 11:54:51.370579  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00195962 (* 1 = 0.00195962 loss)
I0929 11:54:51.370584  1584 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I0929 11:55:05.604362  1584 solver.cpp:218] Iteration 59400 (7.02556 iter/s, 14.2337s/100 iters), loss = 0.0083668
I0929 11:55:05.604398  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0083661 (* 1 = 0.0083661 loss)
I0929 11:55:05.604403  1584 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I0929 11:55:19.122386  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:55:19.691366  1584 solver.cpp:330] Iteration 59500, Testing net (#0)
I0929 11:55:23.045919  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:55:23.186291  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9214
I0929 11:55:23.186314  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310891 (* 1 = 0.310891 loss)
I0929 11:55:23.329805  1584 solver.cpp:218] Iteration 59500 (5.64163 iter/s, 17.7254s/100 iters), loss = 0.00174735
I0929 11:55:23.329851  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00174665 (* 1 = 0.00174665 loss)
I0929 11:55:23.329859  1584 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I0929 11:55:37.554250  1584 solver.cpp:218] Iteration 59600 (7.0302 iter/s, 14.2244s/100 iters), loss = 0.0044304
I0929 11:55:37.554281  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0044297 (* 1 = 0.0044297 loss)
I0929 11:55:37.554287  1584 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I0929 11:55:51.790493  1584 solver.cpp:218] Iteration 59700 (7.02436 iter/s, 14.2362s/100 iters), loss = 0.00354082
I0929 11:55:51.790601  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00354013 (* 1 = 0.00354013 loss)
I0929 11:55:51.790608  1584 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I0929 11:56:06.029685  1584 solver.cpp:218] Iteration 59800 (7.02294 iter/s, 14.239s/100 iters), loss = 0.0128805
I0929 11:56:06.029717  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128798 (* 1 = 0.0128798 loss)
I0929 11:56:06.029724  1584 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I0929 11:56:20.255652  1584 solver.cpp:218] Iteration 59900 (7.02944 iter/s, 14.2259s/100 iters), loss = 0.0133207
I0929 11:56:20.255686  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01332 (* 1 = 0.01332 loss)
I0929 11:56:20.255693  1584 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I0929 11:56:33.790940  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:56:34.358662  1584 solver.cpp:330] Iteration 60000, Testing net (#0)
I0929 11:56:37.716534  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:56:37.859048  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9201
I0929 11:56:37.859083  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320993 (* 1 = 0.320993 loss)
I0929 11:56:37.999402  1584 solver.cpp:218] Iteration 60000 (5.63581 iter/s, 17.7437s/100 iters), loss = 0.00689696
I0929 11:56:37.999430  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00689626 (* 1 = 0.00689626 loss)
I0929 11:56:37.999436  1584 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I0929 11:56:52.250100  1584 solver.cpp:218] Iteration 60100 (7.01723 iter/s, 14.2506s/100 iters), loss = 0.00512668
I0929 11:56:52.250131  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00512598 (* 1 = 0.00512598 loss)
I0929 11:56:52.250138  1584 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I0929 11:57:06.485792  1584 solver.cpp:218] Iteration 60200 (7.02463 iter/s, 14.2356s/100 iters), loss = 0.00546361
I0929 11:57:06.485904  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00546291 (* 1 = 0.00546291 loss)
I0929 11:57:06.485921  1584 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I0929 11:57:20.726188  1584 solver.cpp:218] Iteration 60300 (7.02235 iter/s, 14.2402s/100 iters), loss = 0.00505099
I0929 11:57:20.726222  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00505029 (* 1 = 0.00505029 loss)
I0929 11:57:20.726227  1584 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I0929 11:57:34.964854  1584 solver.cpp:218] Iteration 60400 (7.02317 iter/s, 14.2386s/100 iters), loss = 0.00276295
I0929 11:57:34.964882  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00276225 (* 1 = 0.00276225 loss)
I0929 11:57:34.964889  1584 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I0929 11:57:48.495769  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:57:49.064728  1584 solver.cpp:330] Iteration 60500, Testing net (#0)
I0929 11:57:52.419360  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:57:52.559191  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9234
I0929 11:57:52.559226  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313478 (* 1 = 0.313478 loss)
I0929 11:57:52.699210  1584 solver.cpp:218] Iteration 60500 (5.6388 iter/s, 17.7343s/100 iters), loss = 0.00144727
I0929 11:57:52.699254  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00144658 (* 1 = 0.00144658 loss)
I0929 11:57:52.699259  1584 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I0929 11:58:06.937806  1584 solver.cpp:218] Iteration 60600 (7.0232 iter/s, 14.2385s/100 iters), loss = 0.00574534
I0929 11:58:06.937849  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00574465 (* 1 = 0.00574465 loss)
I0929 11:58:06.937855  1584 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I0929 11:58:21.171042  1584 solver.cpp:218] Iteration 60700 (7.02585 iter/s, 14.2332s/100 iters), loss = 0.00443464
I0929 11:58:21.171188  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00443394 (* 1 = 0.00443394 loss)
I0929 11:58:21.171197  1584 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I0929 11:58:35.389597  1584 solver.cpp:218] Iteration 60800 (7.03316 iter/s, 14.2184s/100 iters), loss = 0.010129
I0929 11:58:35.389644  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101283 (* 1 = 0.0101283 loss)
I0929 11:58:35.389652  1584 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I0929 11:58:49.611121  1584 solver.cpp:218] Iteration 60900 (7.03164 iter/s, 14.2214s/100 iters), loss = 0.00168782
I0929 11:58:49.611152  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168712 (* 1 = 0.00168712 loss)
I0929 11:58:49.611158  1584 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I0929 11:59:03.145515  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:59:03.712867  1584 solver.cpp:330] Iteration 61000, Testing net (#0)
I0929 11:59:07.069386  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:59:07.209203  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9221
I0929 11:59:07.209237  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320554 (* 1 = 0.320554 loss)
I0929 11:59:07.348835  1584 solver.cpp:218] Iteration 61000 (5.63773 iter/s, 17.7376s/100 iters), loss = 0.00144584
I0929 11:59:07.348877  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00144515 (* 1 = 0.00144515 loss)
I0929 11:59:07.348886  1584 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I0929 11:59:21.586592  1584 solver.cpp:218] Iteration 61100 (7.02362 iter/s, 14.2377s/100 iters), loss = 0.00368285
I0929 11:59:21.586623  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00368215 (* 1 = 0.00368215 loss)
I0929 11:59:21.586629  1584 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I0929 11:59:35.834324  1584 solver.cpp:218] Iteration 61200 (7.0187 iter/s, 14.2477s/100 iters), loss = 0.00361467
I0929 11:59:35.834451  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00361396 (* 1 = 0.00361396 loss)
I0929 11:59:35.834461  1584 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I0929 11:59:50.069061  1584 solver.cpp:218] Iteration 61300 (7.02514 iter/s, 14.2346s/100 iters), loss = 0.00617906
I0929 11:59:50.069090  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00617835 (* 1 = 0.00617835 loss)
I0929 11:59:50.069097  1584 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I0929 12:00:04.317040  1584 solver.cpp:218] Iteration 61400 (7.01857 iter/s, 14.2479s/100 iters), loss = 0.00597897
I0929 12:00:04.317072  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00597827 (* 1 = 0.00597827 loss)
I0929 12:00:04.317080  1584 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I0929 12:00:17.847013  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:00:18.416496  1584 solver.cpp:330] Iteration 61500, Testing net (#0)
I0929 12:00:21.770268  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:00:21.910190  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9194
I0929 12:00:21.910226  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.321104 (* 1 = 0.321104 loss)
I0929 12:00:22.050392  1584 solver.cpp:218] Iteration 61500 (5.63912 iter/s, 17.7333s/100 iters), loss = 0.0085847
I0929 12:00:22.050428  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.008584 (* 1 = 0.008584 loss)
I0929 12:00:22.050436  1584 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I0929 12:00:36.294875  1584 solver.cpp:218] Iteration 61600 (7.0203 iter/s, 14.2444s/100 iters), loss = 0.00091772
I0929 12:00:36.294906  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000917022 (* 1 = 0.000917022 loss)
I0929 12:00:36.294914  1584 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I0929 12:00:50.537421  1584 solver.cpp:218] Iteration 61700 (7.02125 iter/s, 14.2425s/100 iters), loss = 0.00327178
I0929 12:00:50.537514  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00327108 (* 1 = 0.00327108 loss)
I0929 12:00:50.537525  1584 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I0929 12:01:04.766214  1584 solver.cpp:218] Iteration 61800 (7.02808 iter/s, 14.2286s/100 iters), loss = 0.00083556
I0929 12:01:04.766254  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000834867 (* 1 = 0.000834867 loss)
I0929 12:01:04.766260  1584 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I0929 12:01:19.010509  1584 solver.cpp:218] Iteration 61900 (7.02039 iter/s, 14.2442s/100 iters), loss = 0.00183132
I0929 12:01:19.010553  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00183062 (* 1 = 0.00183062 loss)
I0929 12:01:19.010560  1584 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I0929 12:01:32.553378  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:01:33.122072  1584 solver.cpp:330] Iteration 62000, Testing net (#0)
I0929 12:01:36.479888  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:01:36.620342  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9213
I0929 12:01:36.620367  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312274 (* 1 = 0.312274 loss)
I0929 12:01:36.761170  1584 solver.cpp:218] Iteration 62000 (5.63362 iter/s, 17.7506s/100 iters), loss = 0.00166491
I0929 12:01:36.761201  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00166422 (* 1 = 0.00166422 loss)
I0929 12:01:36.761207  1584 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I0929 12:01:50.991961  1584 solver.cpp:218] Iteration 62100 (7.02705 iter/s, 14.2307s/100 iters), loss = 0.00456871
I0929 12:01:50.991993  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00456801 (* 1 = 0.00456801 loss)
I0929 12:01:50.992000  1584 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I0929 12:02:05.214243  1584 solver.cpp:218] Iteration 62200 (7.03126 iter/s, 14.2222s/100 iters), loss = 0.00333415
I0929 12:02:05.214357  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00333345 (* 1 = 0.00333345 loss)
I0929 12:02:05.214365  1584 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I0929 12:02:19.448899  1584 solver.cpp:218] Iteration 62300 (7.02518 iter/s, 14.2345s/100 iters), loss = 0.00219041
I0929 12:02:19.448933  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00218972 (* 1 = 0.00218972 loss)
I0929 12:02:19.448940  1584 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I0929 12:02:33.686195  1584 solver.cpp:218] Iteration 62400 (7.02384 iter/s, 14.2372s/100 iters), loss = 0.00123
I0929 12:02:33.686226  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0012293 (* 1 = 0.0012293 loss)
I0929 12:02:33.686233  1584 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I0929 12:02:47.197296  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:02:47.773368  1584 solver.cpp:330] Iteration 62500, Testing net (#0)
I0929 12:02:51.131655  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:02:51.271940  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.924
I0929 12:02:51.271965  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310443 (* 1 = 0.310443 loss)
I0929 12:02:51.412617  1584 solver.cpp:218] Iteration 62500 (5.64132 iter/s, 17.7263s/100 iters), loss = 0.000590961
I0929 12:02:51.412647  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000590262 (* 1 = 0.000590262 loss)
I0929 12:02:51.412654  1584 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I0929 12:03:05.657135  1584 solver.cpp:218] Iteration 62600 (7.02028 iter/s, 14.2444s/100 iters), loss = 0.00136997
I0929 12:03:05.657169  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00136928 (* 1 = 0.00136928 loss)
I0929 12:03:05.657176  1584 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I0929 12:03:19.885939  1584 solver.cpp:218] Iteration 62700 (7.02803 iter/s, 14.2287s/100 iters), loss = 0.0159709
I0929 12:03:19.886060  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0159702 (* 1 = 0.0159702 loss)
I0929 12:03:19.886067  1584 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I0929 12:03:34.118316  1584 solver.cpp:218] Iteration 62800 (7.02631 iter/s, 14.2322s/100 iters), loss = 0.0102829
I0929 12:03:34.118346  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102822 (* 1 = 0.0102822 loss)
I0929 12:03:34.118352  1584 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I0929 12:03:48.360594  1584 solver.cpp:218] Iteration 62900 (7.02138 iter/s, 14.2422s/100 iters), loss = 0.000564283
I0929 12:03:48.360625  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000563591 (* 1 = 0.000563591 loss)
I0929 12:03:48.360641  1584 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I0929 12:04:01.884218  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:04:02.458879  1584 solver.cpp:330] Iteration 63000, Testing net (#0)
I0929 12:04:05.817401  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:04:05.957499  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9235
I0929 12:04:05.957525  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308623 (* 1 = 0.308623 loss)
I0929 12:04:06.097818  1584 solver.cpp:218] Iteration 63000 (5.63789 iter/s, 17.7371s/100 iters), loss = 0.00459712
I0929 12:04:06.097851  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00459644 (* 1 = 0.00459644 loss)
I0929 12:04:06.097858  1584 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I0929 12:04:20.318898  1584 solver.cpp:218] Iteration 63100 (7.03185 iter/s, 14.221s/100 iters), loss = 0.00911743
I0929 12:04:20.318935  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00911675 (* 1 = 0.00911675 loss)
I0929 12:04:20.318943  1584 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I0929 12:04:34.553992  1584 solver.cpp:218] Iteration 63200 (7.02493 iter/s, 14.235s/100 iters), loss = 0.00563065
I0929 12:04:34.554127  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00562996 (* 1 = 0.00562996 loss)
I0929 12:04:34.554136  1584 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I0929 12:04:48.789722  1584 solver.cpp:218] Iteration 63300 (7.02466 iter/s, 14.2356s/100 iters), loss = 0.0067042
I0929 12:04:48.789752  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00670351 (* 1 = 0.00670351 loss)
I0929 12:04:48.789759  1584 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I0929 12:05:03.017073  1584 solver.cpp:218] Iteration 63400 (7.02875 iter/s, 14.2273s/100 iters), loss = 0.0015234
I0929 12:05:03.017118  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00152271 (* 1 = 0.00152271 loss)
I0929 12:05:03.017124  1584 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I0929 12:05:16.535490  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:05:17.102639  1584 solver.cpp:330] Iteration 63500, Testing net (#0)
I0929 12:05:20.469348  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:05:20.611898  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9199
I0929 12:05:20.611924  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310549 (* 1 = 0.310549 loss)
I0929 12:05:20.752916  1584 solver.cpp:218] Iteration 63500 (5.63833 iter/s, 17.7357s/100 iters), loss = 0.00385507
I0929 12:05:20.752949  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00385438 (* 1 = 0.00385438 loss)
I0929 12:05:20.752956  1584 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I0929 12:05:34.989183  1584 solver.cpp:218] Iteration 63600 (7.02435 iter/s, 14.2362s/100 iters), loss = 0.00388313
I0929 12:05:34.989224  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00388244 (* 1 = 0.00388244 loss)
I0929 12:05:34.989230  1584 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I0929 12:05:49.230409  1584 solver.cpp:218] Iteration 63700 (7.02191 iter/s, 14.2411s/100 iters), loss = 0.00125434
I0929 12:05:49.230561  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00125365 (* 1 = 0.00125365 loss)
I0929 12:05:49.230571  1584 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I0929 12:06:03.473572  1584 solver.cpp:218] Iteration 63800 (7.02101 iter/s, 14.243s/100 iters), loss = 0.0106407
I0929 12:06:03.473603  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01064 (* 1 = 0.01064 loss)
I0929 12:06:03.473610  1584 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I0929 12:06:17.723212  1584 solver.cpp:218] Iteration 63900 (7.01776 iter/s, 14.2496s/100 iters), loss = 0.0294273
I0929 12:06:17.723242  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0294266 (* 1 = 0.0294266 loss)
I0929 12:06:17.723250  1584 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I0929 12:06:31.257746  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:06:31.826057  1584 solver.cpp:330] Iteration 64000, Testing net (#0)
I0929 12:06:35.182238  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:06:35.323472  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9214
I0929 12:06:35.323509  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307295 (* 1 = 0.307295 loss)
I0929 12:06:35.467761  1584 solver.cpp:218] Iteration 64000 (5.63556 iter/s, 17.7445s/100 iters), loss = 0.00348211
I0929 12:06:35.467819  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00348143 (* 1 = 0.00348143 loss)
I0929 12:06:35.467828  1584 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I0929 12:06:49.691617  1584 solver.cpp:218] Iteration 64100 (7.03051 iter/s, 14.2237s/100 iters), loss = 0.00128344
I0929 12:06:49.691648  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128276 (* 1 = 0.00128276 loss)
I0929 12:06:49.691655  1584 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I0929 12:07:03.927892  1584 solver.cpp:218] Iteration 64200 (7.02435 iter/s, 14.2362s/100 iters), loss = 0.00205127
I0929 12:07:03.928059  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00205059 (* 1 = 0.00205059 loss)
I0929 12:07:03.928078  1584 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I0929 12:07:18.158088  1584 solver.cpp:218] Iteration 64300 (7.02741 iter/s, 14.23s/100 iters), loss = 0.00148263
I0929 12:07:18.158121  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00148194 (* 1 = 0.00148194 loss)
I0929 12:07:18.158130  1584 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I0929 12:07:32.372413  1584 solver.cpp:218] Iteration 64400 (7.03519 iter/s, 14.2143s/100 iters), loss = 0.00192827
I0929 12:07:32.372453  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00192758 (* 1 = 0.00192758 loss)
I0929 12:07:32.372473  1584 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I0929 12:07:45.898062  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:07:46.465473  1584 solver.cpp:330] Iteration 64500, Testing net (#0)
I0929 12:07:49.823222  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:07:49.962896  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9194
I0929 12:07:49.962923  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313593 (* 1 = 0.313593 loss)
I0929 12:07:50.103602  1584 solver.cpp:218] Iteration 64500 (5.63982 iter/s, 17.7311s/100 iters), loss = 0.00489341
I0929 12:07:50.103634  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00489272 (* 1 = 0.00489272 loss)
I0929 12:07:50.103653  1584 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I0929 12:08:04.339916  1584 solver.cpp:218] Iteration 64600 (7.02432 iter/s, 14.2362s/100 iters), loss = 0.00232318
I0929 12:08:04.339948  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00232249 (* 1 = 0.00232249 loss)
I0929 12:08:04.339957  1584 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I0929 12:08:18.683559  1584 solver.cpp:218] Iteration 64700 (6.97177 iter/s, 14.3436s/100 iters), loss = 0.00116309
I0929 12:08:18.683706  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0011624 (* 1 = 0.0011624 loss)
I0929 12:08:18.683730  1584 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I0929 12:08:33.017678  1584 solver.cpp:218] Iteration 64800 (6.97645 iter/s, 14.3339s/100 iters), loss = 0.0021272
I0929 12:08:33.017712  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00212651 (* 1 = 0.00212651 loss)
I0929 12:08:33.017720  1584 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I0929 12:08:47.257907  1584 solver.cpp:218] Iteration 64900 (7.0224 iter/s, 14.2402s/100 iters), loss = 0.00137256
I0929 12:08:47.257938  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00137187 (* 1 = 0.00137187 loss)
I0929 12:08:47.257944  1584 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I0929 12:09:00.796150  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:09:01.364367  1584 solver.cpp:330] Iteration 65000, Testing net (#0)
I0929 12:09:04.724066  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:09:04.864347  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9194
I0929 12:09:04.864383  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318275 (* 1 = 0.318275 loss)
I0929 12:09:05.005378  1584 solver.cpp:218] Iteration 65000 (5.63463 iter/s, 17.7474s/100 iters), loss = 0.00289425
I0929 12:09:05.005414  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00289356 (* 1 = 0.00289356 loss)
I0929 12:09:05.005420  1584 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I0929 12:09:19.250087  1584 solver.cpp:218] Iteration 65100 (7.02019 iter/s, 14.2446s/100 iters), loss = 0.000931864
I0929 12:09:19.250123  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000931179 (* 1 = 0.000931179 loss)
I0929 12:09:19.250130  1584 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I0929 12:09:33.513017  1584 solver.cpp:218] Iteration 65200 (7.01122 iter/s, 14.2629s/100 iters), loss = 0.00181507
I0929 12:09:33.513180  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00181438 (* 1 = 0.00181438 loss)
I0929 12:09:33.513190  1584 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I0929 12:09:47.762542  1584 solver.cpp:218] Iteration 65300 (7.01788 iter/s, 14.2493s/100 iters), loss = 0.00231961
I0929 12:09:47.762575  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00231892 (* 1 = 0.00231892 loss)
I0929 12:09:47.762593  1584 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I0929 12:10:02.006741  1584 solver.cpp:218] Iteration 65400 (7.02044 iter/s, 14.2441s/100 iters), loss = 0.00142529
I0929 12:10:02.006770  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0014246 (* 1 = 0.0014246 loss)
I0929 12:10:02.006777  1584 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I0929 12:10:15.557056  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:10:16.125813  1584 solver.cpp:330] Iteration 65500, Testing net (#0)
I0929 12:10:19.486325  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:10:19.625967  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9216
I0929 12:10:19.626003  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316764 (* 1 = 0.316764 loss)
I0929 12:10:19.766360  1584 solver.cpp:218] Iteration 65500 (5.63078 iter/s, 17.7595s/100 iters), loss = 0.00251544
I0929 12:10:19.766389  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00251475 (* 1 = 0.00251475 loss)
I0929 12:10:19.766396  1584 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I0929 12:10:34.003480  1584 solver.cpp:218] Iteration 65600 (7.02393 iter/s, 14.237s/100 iters), loss = 0.00501925
I0929 12:10:34.003510  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00501856 (* 1 = 0.00501856 loss)
I0929 12:10:34.003517  1584 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I0929 12:10:48.246732  1584 solver.cpp:218] Iteration 65700 (7.0209 iter/s, 14.2432s/100 iters), loss = 0.00373236
I0929 12:10:48.246863  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00373166 (* 1 = 0.00373166 loss)
I0929 12:10:48.246882  1584 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I0929 12:11:02.492817  1584 solver.cpp:218] Iteration 65800 (7.01956 iter/s, 14.2459s/100 iters), loss = 0.00349205
I0929 12:11:02.492867  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00349137 (* 1 = 0.00349137 loss)
I0929 12:11:02.492885  1584 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I0929 12:11:16.732226  1584 solver.cpp:218] Iteration 65900 (7.02282 iter/s, 14.2393s/100 iters), loss = 0.0036226
I0929 12:11:16.732257  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00362191 (* 1 = 0.00362191 loss)
I0929 12:11:16.732264  1584 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I0929 12:11:30.266970  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:11:30.835700  1584 solver.cpp:330] Iteration 66000, Testing net (#0)
I0929 12:11:34.194799  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:11:34.334935  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9227
I0929 12:11:34.334971  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303865 (* 1 = 0.303865 loss)
I0929 12:11:34.476408  1584 solver.cpp:218] Iteration 66000 (5.63567 iter/s, 17.7441s/100 iters), loss = 0.000771104
I0929 12:11:34.476434  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000770415 (* 1 = 0.000770415 loss)
I0929 12:11:34.476440  1584 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I0929 12:11:48.722702  1584 solver.cpp:218] Iteration 66100 (7.0194 iter/s, 14.2462s/100 iters), loss = 0.0048853
I0929 12:11:48.722744  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00488461 (* 1 = 0.00488461 loss)
I0929 12:11:48.722751  1584 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I0929 12:12:02.981297  1584 solver.cpp:218] Iteration 66200 (7.01336 iter/s, 14.2585s/100 iters), loss = 0.00110615
I0929 12:12:02.981410  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00110546 (* 1 = 0.00110546 loss)
I0929 12:12:02.981417  1584 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I0929 12:12:17.220881  1584 solver.cpp:218] Iteration 66300 (7.02275 iter/s, 14.2394s/100 iters), loss = 0.000583558
I0929 12:12:17.220911  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000582871 (* 1 = 0.000582871 loss)
I0929 12:12:17.220916  1584 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I0929 12:12:31.472846  1584 solver.cpp:218] Iteration 66400 (7.01661 iter/s, 14.2519s/100 iters), loss = 0.013879
I0929 12:12:31.472877  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138784 (* 1 = 0.0138784 loss)
I0929 12:12:31.472882  1584 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I0929 12:12:45.028736  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:12:45.598814  1584 solver.cpp:330] Iteration 66500, Testing net (#0)
I0929 12:12:48.957389  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:12:49.097466  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9209
I0929 12:12:49.097501  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31204 (* 1 = 0.31204 loss)
I0929 12:12:49.238584  1584 solver.cpp:218] Iteration 66500 (5.62884 iter/s, 17.7657s/100 iters), loss = 0.0107275
I0929 12:12:49.238615  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107268 (* 1 = 0.0107268 loss)
I0929 12:12:49.238622  1584 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I0929 12:13:03.484213  1584 solver.cpp:218] Iteration 66600 (7.01973 iter/s, 14.2456s/100 iters), loss = 0.00508016
I0929 12:13:03.484243  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00507948 (* 1 = 0.00507948 loss)
I0929 12:13:03.484251  1584 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I0929 12:13:17.733976  1584 solver.cpp:218] Iteration 66700 (7.01769 iter/s, 14.2497s/100 iters), loss = 0.00272632
I0929 12:13:17.734081  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00272564 (* 1 = 0.00272564 loss)
I0929 12:13:17.734098  1584 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I0929 12:13:31.981387  1584 solver.cpp:218] Iteration 66800 (7.01889 iter/s, 14.2473s/100 iters), loss = 0.00288311
I0929 12:13:31.981429  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00288243 (* 1 = 0.00288243 loss)
I0929 12:13:31.981436  1584 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I0929 12:13:46.231289  1584 solver.cpp:218] Iteration 66900 (7.01763 iter/s, 14.2498s/100 iters), loss = 0.00341286
I0929 12:13:46.231318  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00341218 (* 1 = 0.00341218 loss)
I0929 12:13:46.231324  1584 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I0929 12:13:59.770426  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:14:00.340276  1584 solver.cpp:330] Iteration 67000, Testing net (#0)
I0929 12:14:03.701714  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:14:03.842191  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9195
I0929 12:14:03.842226  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326371 (* 1 = 0.326371 loss)
I0929 12:14:03.983278  1584 solver.cpp:218] Iteration 67000 (5.6332 iter/s, 17.7519s/100 iters), loss = 0.00482068
I0929 12:14:03.983304  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00482001 (* 1 = 0.00482001 loss)
I0929 12:14:03.983311  1584 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I0929 12:14:18.221748  1584 solver.cpp:218] Iteration 67100 (7.02326 iter/s, 14.2384s/100 iters), loss = 0.0034907
I0929 12:14:18.221789  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00349002 (* 1 = 0.00349002 loss)
I0929 12:14:18.221796  1584 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I0929 12:14:32.453311  1584 solver.cpp:218] Iteration 67200 (7.02667 iter/s, 14.2315s/100 iters), loss = 0.00132643
I0929 12:14:32.453455  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00132576 (* 1 = 0.00132576 loss)
I0929 12:14:32.453464  1584 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I0929 12:14:46.682832  1584 solver.cpp:218] Iteration 67300 (7.02773 iter/s, 14.2294s/100 iters), loss = 0.00277206
I0929 12:14:46.682864  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00277139 (* 1 = 0.00277139 loss)
I0929 12:14:46.682870  1584 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I0929 12:15:00.932910  1584 solver.cpp:218] Iteration 67400 (7.01754 iter/s, 14.25s/100 iters), loss = 0.00171876
I0929 12:15:00.932945  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00171809 (* 1 = 0.00171809 loss)
I0929 12:15:00.932950  1584 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I0929 12:15:14.463755  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:15:15.037969  1584 solver.cpp:330] Iteration 67500, Testing net (#0)
I0929 12:15:18.394457  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:15:18.534621  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9159
I0929 12:15:18.534656  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333857 (* 1 = 0.333857 loss)
I0929 12:15:18.676080  1584 solver.cpp:218] Iteration 67500 (5.636 iter/s, 17.7431s/100 iters), loss = 0.00310334
I0929 12:15:18.676116  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00310267 (* 1 = 0.00310267 loss)
I0929 12:15:18.676123  1584 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I0929 12:15:32.914557  1584 solver.cpp:218] Iteration 67600 (7.02326 iter/s, 14.2384s/100 iters), loss = 0.00233861
I0929 12:15:32.914588  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00233794 (* 1 = 0.00233794 loss)
I0929 12:15:32.914595  1584 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I0929 12:15:47.160387  1584 solver.cpp:218] Iteration 67700 (7.01963 iter/s, 14.2458s/100 iters), loss = 0.00558854
I0929 12:15:47.160487  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00558786 (* 1 = 0.00558786 loss)
I0929 12:15:47.160495  1584 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I0929 12:16:01.419720  1584 solver.cpp:218] Iteration 67800 (7.01302 iter/s, 14.2592s/100 iters), loss = 0.00267167
I0929 12:16:01.419751  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00267099 (* 1 = 0.00267099 loss)
I0929 12:16:01.419757  1584 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I0929 12:16:15.666796  1584 solver.cpp:218] Iteration 67900 (7.01902 iter/s, 14.247s/100 iters), loss = 0.0116665
I0929 12:16:15.666828  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116658 (* 1 = 0.0116658 loss)
I0929 12:16:15.666836  1584 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I0929 12:16:29.194594  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:16:29.775604  1584 solver.cpp:330] Iteration 68000, Testing net (#0)
I0929 12:16:33.135179  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:16:33.275728  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9184
I0929 12:16:33.275764  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328324 (* 1 = 0.328324 loss)
I0929 12:16:33.417291  1584 solver.cpp:218] Iteration 68000 (5.63367 iter/s, 17.7504s/100 iters), loss = 0.00316894
I0929 12:16:33.417326  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00316826 (* 1 = 0.00316826 loss)
I0929 12:16:33.417333  1584 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I0929 12:16:47.661164  1584 solver.cpp:218] Iteration 68100 (7.0206 iter/s, 14.2438s/100 iters), loss = 0.00193851
I0929 12:16:47.661201  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00193784 (* 1 = 0.00193784 loss)
I0929 12:16:47.661207  1584 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I0929 12:17:01.896229  1584 solver.cpp:218] Iteration 68200 (7.02494 iter/s, 14.235s/100 iters), loss = 0.000725712
I0929 12:17:01.896327  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000725033 (* 1 = 0.000725033 loss)
I0929 12:17:01.896335  1584 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I0929 12:17:16.137678  1584 solver.cpp:218] Iteration 68300 (7.02182 iter/s, 14.2413s/100 iters), loss = 0.0206603
I0929 12:17:16.137719  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0206596 (* 1 = 0.0206596 loss)
I0929 12:17:16.137727  1584 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I0929 12:17:30.382701  1584 solver.cpp:218] Iteration 68400 (7.02004 iter/s, 14.2449s/100 iters), loss = 0.00348208
I0929 12:17:30.382735  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0034814 (* 1 = 0.0034814 loss)
I0929 12:17:30.382740  1584 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I0929 12:17:43.915710  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:17:44.486738  1584 solver.cpp:330] Iteration 68500, Testing net (#0)
I0929 12:17:47.849861  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:17:47.989965  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9208
I0929 12:17:47.990001  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314067 (* 1 = 0.314067 loss)
I0929 12:17:48.130338  1584 solver.cpp:218] Iteration 68500 (5.63458 iter/s, 17.7476s/100 iters), loss = 0.000987682
I0929 12:17:48.130372  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000987004 (* 1 = 0.000987004 loss)
I0929 12:17:48.130378  1584 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I0929 12:18:02.364264  1584 solver.cpp:218] Iteration 68600 (7.0255 iter/s, 14.2339s/100 iters), loss = 0.00282029
I0929 12:18:02.364298  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00281961 (* 1 = 0.00281961 loss)
I0929 12:18:02.364305  1584 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I0929 12:18:16.620416  1584 solver.cpp:218] Iteration 68700 (7.01455 iter/s, 14.2561s/100 iters), loss = 0.00208537
I0929 12:18:16.620553  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00208469 (* 1 = 0.00208469 loss)
I0929 12:18:16.620561  1584 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I0929 12:18:30.876108  1584 solver.cpp:218] Iteration 68800 (7.01483 iter/s, 14.2555s/100 iters), loss = 0.00153864
I0929 12:18:30.876140  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153796 (* 1 = 0.00153796 loss)
I0929 12:18:30.876147  1584 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I0929 12:18:45.122954  1584 solver.cpp:218] Iteration 68900 (7.01913 iter/s, 14.2468s/100 iters), loss = 0.00187589
I0929 12:18:45.122987  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00187522 (* 1 = 0.00187522 loss)
I0929 12:18:45.123003  1584 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I0929 12:18:58.670879  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:18:59.239605  1584 solver.cpp:330] Iteration 69000, Testing net (#0)
I0929 12:19:02.615048  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:19:02.756387  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9223
I0929 12:19:02.756413  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313832 (* 1 = 0.313832 loss)
I0929 12:19:02.897889  1584 solver.cpp:218] Iteration 69000 (5.62593 iter/s, 17.7748s/100 iters), loss = 0.00272166
I0929 12:19:02.897927  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00272098 (* 1 = 0.00272098 loss)
I0929 12:19:02.897933  1584 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I0929 12:19:17.144161  1584 solver.cpp:218] Iteration 69100 (7.01942 iter/s, 14.2462s/100 iters), loss = 0.00380959
I0929 12:19:17.144192  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00380891 (* 1 = 0.00380891 loss)
I0929 12:19:17.144198  1584 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I0929 12:19:31.395237  1584 solver.cpp:218] Iteration 69200 (7.01705 iter/s, 14.251s/100 iters), loss = 0.00581164
I0929 12:19:31.395354  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00581096 (* 1 = 0.00581096 loss)
I0929 12:19:31.395367  1584 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I0929 12:19:45.655856  1584 solver.cpp:218] Iteration 69300 (7.0124 iter/s, 14.2605s/100 iters), loss = 0.0103383
I0929 12:19:45.655889  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103376 (* 1 = 0.0103376 loss)
I0929 12:19:45.655895  1584 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I0929 12:19:59.917122  1584 solver.cpp:218] Iteration 69400 (7.01204 iter/s, 14.2612s/100 iters), loss = 0.0026422
I0929 12:19:59.917156  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00264152 (* 1 = 0.00264152 loss)
I0929 12:19:59.917163  1584 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I0929 12:20:13.449230  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:20:14.018682  1584 solver.cpp:330] Iteration 69500, Testing net (#0)
I0929 12:20:17.377177  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:20:17.521178  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.918
I0929 12:20:17.521204  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348378 (* 1 = 0.348378 loss)
I0929 12:20:17.665328  1584 solver.cpp:218] Iteration 69500 (5.6344 iter/s, 17.7481s/100 iters), loss = 0.00187071
I0929 12:20:17.665377  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00187003 (* 1 = 0.00187003 loss)
I0929 12:20:17.665396  1584 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I0929 12:20:31.903681  1584 solver.cpp:218] Iteration 69600 (7.02335 iter/s, 14.2382s/100 iters), loss = 0.00505388
I0929 12:20:31.903712  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0050532 (* 1 = 0.0050532 loss)
I0929 12:20:31.903719  1584 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I0929 12:20:46.153028  1584 solver.cpp:218] Iteration 69700 (7.0179 iter/s, 14.2493s/100 iters), loss = 0.0306607
I0929 12:20:46.153151  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.03066 (* 1 = 0.03066 loss)
I0929 12:20:46.153169  1584 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I0929 12:21:00.402200  1584 solver.cpp:218] Iteration 69800 (7.01803 iter/s, 14.249s/100 iters), loss = 0.00334983
I0929 12:21:00.402230  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00334915 (* 1 = 0.00334915 loss)
I0929 12:21:00.402240  1584 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I0929 12:21:14.649610  1584 solver.cpp:218] Iteration 69900 (7.01886 iter/s, 14.2473s/100 iters), loss = 0.00204803
I0929 12:21:14.649646  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00204735 (* 1 = 0.00204735 loss)
I0929 12:21:14.649652  1584 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I0929 12:21:28.216006  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:21:28.785068  1584 solver.cpp:330] Iteration 70000, Testing net (#0)
I0929 12:21:32.144914  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:21:32.285068  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9181
I0929 12:21:32.285091  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334548 (* 1 = 0.334548 loss)
I0929 12:21:32.427170  1584 solver.cpp:218] Iteration 70000 (5.62509 iter/s, 17.7775s/100 iters), loss = 0.00121514
I0929 12:21:32.427204  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00121446 (* 1 = 0.00121446 loss)
I0929 12:21:32.427211  1584 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I0929 12:21:46.669714  1584 solver.cpp:218] Iteration 70100 (7.02125 iter/s, 14.2425s/100 iters), loss = 0.00581491
I0929 12:21:46.669756  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00581423 (* 1 = 0.00581423 loss)
I0929 12:21:46.669764  1584 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I0929 12:22:00.919394  1584 solver.cpp:218] Iteration 70200 (7.01774 iter/s, 14.2496s/100 iters), loss = 0.00142378
I0929 12:22:00.919548  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00142309 (* 1 = 0.00142309 loss)
I0929 12:22:00.919566  1584 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I0929 12:22:15.179163  1584 solver.cpp:218] Iteration 70300 (7.01283 iter/s, 14.2596s/100 iters), loss = 0.00291034
I0929 12:22:15.179196  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00290966 (* 1 = 0.00290966 loss)
I0929 12:22:15.179203  1584 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I0929 12:22:29.425190  1584 solver.cpp:218] Iteration 70400 (7.01954 iter/s, 14.2459s/100 iters), loss = 0.00649654
I0929 12:22:29.425236  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00649586 (* 1 = 0.00649586 loss)
I0929 12:22:29.425243  1584 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I0929 12:22:42.964535  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:22:43.532470  1584 solver.cpp:330] Iteration 70500, Testing net (#0)
I0929 12:22:46.892416  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:22:47.032255  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9174
I0929 12:22:47.032286  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334256 (* 1 = 0.334256 loss)
I0929 12:22:47.173223  1584 solver.cpp:218] Iteration 70500 (5.63447 iter/s, 17.7479s/100 iters), loss = 0.000812151
I0929 12:22:47.173254  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000811473 (* 1 = 0.000811473 loss)
I0929 12:22:47.173259  1584 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I0929 12:23:01.410853  1584 solver.cpp:218] Iteration 70600 (7.02368 iter/s, 14.2376s/100 iters), loss = 0.000885504
I0929 12:23:01.410894  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000884827 (* 1 = 0.000884827 loss)
I0929 12:23:01.410902  1584 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I0929 12:23:15.656651  1584 solver.cpp:218] Iteration 70700 (7.01965 iter/s, 14.2457s/100 iters), loss = 0.00632753
I0929 12:23:15.656761  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00632686 (* 1 = 0.00632686 loss)
I0929 12:23:15.656769  1584 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I0929 12:23:29.894170  1584 solver.cpp:218] Iteration 70800 (7.02377 iter/s, 14.2374s/100 iters), loss = 0.00137735
I0929 12:23:29.894214  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00137667 (* 1 = 0.00137667 loss)
I0929 12:23:29.894222  1584 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I0929 12:23:44.123423  1584 solver.cpp:218] Iteration 70900 (7.02782 iter/s, 14.2292s/100 iters), loss = 0.0045827
I0929 12:23:44.123453  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00458202 (* 1 = 0.00458202 loss)
I0929 12:23:44.123459  1584 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I0929 12:23:57.671999  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:23:58.241134  1584 solver.cpp:330] Iteration 71000, Testing net (#0)
I0929 12:24:01.604622  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:24:01.744401  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9201
I0929 12:24:01.744436  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318057 (* 1 = 0.318057 loss)
I0929 12:24:01.886051  1584 solver.cpp:218] Iteration 71000 (5.62982 iter/s, 17.7626s/100 iters), loss = 0.0110706
I0929 12:24:01.886082  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110699 (* 1 = 0.0110699 loss)
I0929 12:24:01.886090  1584 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I0929 12:24:16.117782  1584 solver.cpp:218] Iteration 71100 (7.02659 iter/s, 14.2317s/100 iters), loss = 0.001318
I0929 12:24:16.117812  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00131731 (* 1 = 0.00131731 loss)
I0929 12:24:16.117818  1584 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I0929 12:24:30.358798  1584 solver.cpp:218] Iteration 71200 (7.02201 iter/s, 14.2409s/100 iters), loss = 0.00178779
I0929 12:24:30.358922  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00178711 (* 1 = 0.00178711 loss)
I0929 12:24:30.358929  1584 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I0929 12:24:44.595105  1584 solver.cpp:218] Iteration 71300 (7.02437 iter/s, 14.2361s/100 iters), loss = 0.00451377
I0929 12:24:44.595152  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00451309 (* 1 = 0.00451309 loss)
I0929 12:24:44.595170  1584 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I0929 12:24:58.829357  1584 solver.cpp:218] Iteration 71400 (7.02537 iter/s, 14.2341s/100 iters), loss = 0.0324424
I0929 12:24:58.829397  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0324418 (* 1 = 0.0324418 loss)
I0929 12:24:58.829403  1584 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I0929 12:25:12.364485  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:25:12.932245  1584 solver.cpp:330] Iteration 71500, Testing net (#0)
I0929 12:25:16.295051  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:25:16.435145  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.924
I0929 12:25:16.435181  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.323287 (* 1 = 0.323287 loss)
I0929 12:25:16.575991  1584 solver.cpp:218] Iteration 71500 (5.6349 iter/s, 17.7465s/100 iters), loss = 0.00547027
I0929 12:25:16.576025  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00546959 (* 1 = 0.00546959 loss)
I0929 12:25:16.576030  1584 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I0929 12:25:30.818815  1584 solver.cpp:218] Iteration 71600 (7.02112 iter/s, 14.2428s/100 iters), loss = 0.00164689
I0929 12:25:30.818848  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0016462 (* 1 = 0.0016462 loss)
I0929 12:25:30.818855  1584 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I0929 12:25:45.054440  1584 solver.cpp:218] Iteration 71700 (7.02467 iter/s, 14.2356s/100 iters), loss = 0.00362867
I0929 12:25:45.054556  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00362799 (* 1 = 0.00362799 loss)
I0929 12:25:45.054589  1584 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I0929 12:25:59.282058  1584 solver.cpp:218] Iteration 71800 (7.02866 iter/s, 14.2275s/100 iters), loss = 0.0043133
I0929 12:25:59.282101  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00431262 (* 1 = 0.00431262 loss)
I0929 12:25:59.282109  1584 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I0929 12:26:13.528203  1584 solver.cpp:218] Iteration 71900 (7.01948 iter/s, 14.2461s/100 iters), loss = 0.000731778
I0929 12:26:13.528232  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000731088 (* 1 = 0.000731088 loss)
I0929 12:26:13.528239  1584 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I0929 12:26:27.073493  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:26:27.641973  1584 solver.cpp:330] Iteration 72000, Testing net (#0)
I0929 12:26:31.002128  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:26:31.142171  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.919
I0929 12:26:31.142205  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.345408 (* 1 = 0.345408 loss)
I0929 12:26:31.283258  1584 solver.cpp:218] Iteration 72000 (5.63222 iter/s, 17.755s/100 iters), loss = 0.000819062
I0929 12:26:31.283290  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000818371 (* 1 = 0.000818371 loss)
I0929 12:26:31.283298  1584 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I0929 12:26:45.526798  1584 solver.cpp:218] Iteration 72100 (7.02076 iter/s, 14.2435s/100 iters), loss = 0.00202853
I0929 12:26:45.526834  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00202784 (* 1 = 0.00202784 loss)
I0929 12:26:45.526840  1584 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I0929 12:26:59.785702  1584 solver.cpp:218] Iteration 72200 (7.0132 iter/s, 14.2588s/100 iters), loss = 0.00264428
I0929 12:26:59.785842  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00264359 (* 1 = 0.00264359 loss)
I0929 12:26:59.785861  1584 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I0929 12:27:14.038599  1584 solver.cpp:218] Iteration 72300 (7.0162 iter/s, 14.2527s/100 iters), loss = 0.0010805
I0929 12:27:14.038630  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00107982 (* 1 = 0.00107982 loss)
I0929 12:27:14.038635  1584 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I0929 12:27:28.287997  1584 solver.cpp:218] Iteration 72400 (7.01788 iter/s, 14.2493s/100 iters), loss = 0.000528536
I0929 12:27:28.288028  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000527848 (* 1 = 0.000527848 loss)
I0929 12:27:28.288033  1584 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I0929 12:27:41.832906  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:27:42.401993  1584 solver.cpp:330] Iteration 72500, Testing net (#0)
I0929 12:27:45.763352  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:27:45.903637  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9219
I0929 12:27:45.903663  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325881 (* 1 = 0.325881 loss)
I0929 12:27:46.044839  1584 solver.cpp:218] Iteration 72500 (5.63166 iter/s, 17.7568s/100 iters), loss = 0.00425338
I0929 12:27:46.044869  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0042527 (* 1 = 0.0042527 loss)
I0929 12:27:46.044875  1584 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I0929 12:28:00.301923  1584 solver.cpp:218] Iteration 72600 (7.01409 iter/s, 14.257s/100 iters), loss = 0.0028705
I0929 12:28:00.301957  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00286981 (* 1 = 0.00286981 loss)
I0929 12:28:00.301964  1584 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I0929 12:28:14.550881  1584 solver.cpp:218] Iteration 72700 (7.0181 iter/s, 14.2489s/100 iters), loss = 0.00431359
I0929 12:28:14.551008  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0043129 (* 1 = 0.0043129 loss)
I0929 12:28:14.551028  1584 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I0929 12:28:28.800420  1584 solver.cpp:218] Iteration 72800 (7.01786 iter/s, 14.2494s/100 iters), loss = 0.00258344
I0929 12:28:28.800460  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00258275 (* 1 = 0.00258275 loss)
I0929 12:28:28.800467  1584 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I0929 12:28:43.061292  1584 solver.cpp:218] Iteration 72900 (7.01223 iter/s, 14.2608s/100 iters), loss = 0.000525159
I0929 12:28:43.061333  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000524463 (* 1 = 0.000524463 loss)
I0929 12:28:43.061339  1584 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I0929 12:28:56.610848  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:28:57.183051  1584 solver.cpp:330] Iteration 73000, Testing net (#0)
I0929 12:29:00.539721  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:29:00.680253  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9194
I0929 12:29:00.680289  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339887 (* 1 = 0.339887 loss)
I0929 12:29:00.822473  1584 solver.cpp:218] Iteration 73000 (5.63029 iter/s, 17.7611s/100 iters), loss = 0.00548804
I0929 12:29:00.822502  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00548734 (* 1 = 0.00548734 loss)
I0929 12:29:00.822509  1584 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I0929 12:29:15.060189  1584 solver.cpp:218] Iteration 73100 (7.02363 iter/s, 14.2376s/100 iters), loss = 0.0033148
I0929 12:29:15.060221  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0033141 (* 1 = 0.0033141 loss)
I0929 12:29:15.060228  1584 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I0929 12:29:29.296537  1584 solver.cpp:218] Iteration 73200 (7.02431 iter/s, 14.2363s/100 iters), loss = 0.0113425
I0929 12:29:29.296712  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113418 (* 1 = 0.0113418 loss)
I0929 12:29:29.296721  1584 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I0929 12:29:43.539454  1584 solver.cpp:218] Iteration 73300 (7.02113 iter/s, 14.2427s/100 iters), loss = 0.00359292
I0929 12:29:43.539486  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00359222 (* 1 = 0.00359222 loss)
I0929 12:29:43.539494  1584 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I0929 12:29:57.777885  1584 solver.cpp:218] Iteration 73400 (7.02328 iter/s, 14.2384s/100 iters), loss = 0.00102681
I0929 12:29:57.777915  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102611 (* 1 = 0.00102611 loss)
I0929 12:29:57.777921  1584 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I0929 12:30:11.315423  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:30:11.895084  1584 solver.cpp:330] Iteration 73500, Testing net (#0)
I0929 12:30:15.254328  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:30:15.394590  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9185
I0929 12:30:15.394625  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32658 (* 1 = 0.32658 loss)
I0929 12:30:15.535639  1584 solver.cpp:218] Iteration 73500 (5.63137 iter/s, 17.7577s/100 iters), loss = 0.00168286
I0929 12:30:15.535676  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168216 (* 1 = 0.00168216 loss)
I0929 12:30:15.535683  1584 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I0929 12:30:29.774240  1584 solver.cpp:218] Iteration 73600 (7.0232 iter/s, 14.2385s/100 iters), loss = 0.00234399
I0929 12:30:29.774276  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00234329 (* 1 = 0.00234329 loss)
I0929 12:30:29.774282  1584 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I0929 12:30:43.999541  1584 solver.cpp:218] Iteration 73700 (7.02977 iter/s, 14.2252s/100 iters), loss = 0.000957816
I0929 12:30:43.999641  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000957112 (* 1 = 0.000957112 loss)
I0929 12:30:43.999660  1584 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I0929 12:30:58.240994  1584 solver.cpp:218] Iteration 73800 (7.02182 iter/s, 14.2413s/100 iters), loss = 0.00403534
I0929 12:30:58.241024  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00403463 (* 1 = 0.00403463 loss)
I0929 12:30:58.241030  1584 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I0929 12:31:12.483842  1584 solver.cpp:218] Iteration 73900 (7.0211 iter/s, 14.2428s/100 iters), loss = 0.000858806
I0929 12:31:12.483873  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000858104 (* 1 = 0.000858104 loss)
I0929 12:31:12.483880  1584 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I0929 12:31:26.009974  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:31:26.580456  1584 solver.cpp:330] Iteration 74000, Testing net (#0)
I0929 12:31:29.941295  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:31:30.080921  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9202
I0929 12:31:30.080946  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334915 (* 1 = 0.334915 loss)
I0929 12:31:30.221056  1584 solver.cpp:218] Iteration 74000 (5.63789 iter/s, 17.7371s/100 iters), loss = 0.000596185
I0929 12:31:30.221091  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000595483 (* 1 = 0.000595483 loss)
I0929 12:31:30.221098  1584 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I0929 12:31:44.451459  1584 solver.cpp:218] Iteration 74100 (7.02724 iter/s, 14.2303s/100 iters), loss = 0.00152545
I0929 12:31:44.451494  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00152475 (* 1 = 0.00152475 loss)
I0929 12:31:44.451501  1584 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I0929 12:31:58.699254  1584 solver.cpp:218] Iteration 74200 (7.01867 iter/s, 14.2477s/100 iters), loss = 0.000425308
I0929 12:31:58.699429  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000424608 (* 1 = 0.000424608 loss)
I0929 12:31:58.699440  1584 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I0929 12:32:12.938019  1584 solver.cpp:218] Iteration 74300 (7.02318 iter/s, 14.2386s/100 iters), loss = 0.00184339
I0929 12:32:12.938051  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0018427 (* 1 = 0.0018427 loss)
I0929 12:32:12.938058  1584 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I0929 12:32:27.180413  1584 solver.cpp:218] Iteration 74400 (7.02133 iter/s, 14.2423s/100 iters), loss = 0.00619537
I0929 12:32:27.180444  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00619467 (* 1 = 0.00619467 loss)
I0929 12:32:27.180451  1584 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I0929 12:32:40.714483  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:32:41.283874  1584 solver.cpp:330] Iteration 74500, Testing net (#0)
I0929 12:32:44.653941  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:32:44.796444  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9183
I0929 12:32:44.796470  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338005 (* 1 = 0.338005 loss)
I0929 12:32:44.937335  1584 solver.cpp:218] Iteration 74500 (5.63163 iter/s, 17.7568s/100 iters), loss = 0.00419786
I0929 12:32:44.937369  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00419716 (* 1 = 0.00419716 loss)
I0929 12:32:44.937376  1584 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I0929 12:32:59.174078  1584 solver.cpp:218] Iteration 74600 (7.02411 iter/s, 14.2367s/100 iters), loss = 0.00268221
I0929 12:32:59.174108  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00268152 (* 1 = 0.00268152 loss)
I0929 12:32:59.174113  1584 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I0929 12:33:13.420111  1584 solver.cpp:218] Iteration 74700 (7.01953 iter/s, 14.246s/100 iters), loss = 0.00162449
I0929 12:33:13.420198  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0016238 (* 1 = 0.0016238 loss)
I0929 12:33:13.420207  1584 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I0929 12:33:27.670713  1584 solver.cpp:218] Iteration 74800 (7.01731 iter/s, 14.2505s/100 iters), loss = 0.00505178
I0929 12:33:27.670744  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00505108 (* 1 = 0.00505108 loss)
I0929 12:33:27.670752  1584 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I0929 12:33:41.919265  1584 solver.cpp:218] Iteration 74900 (7.01829 iter/s, 14.2485s/100 iters), loss = 0.00884509
I0929 12:33:41.919299  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00884439 (* 1 = 0.00884439 loss)
I0929 12:33:41.919307  1584 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I0929 12:33:55.449533  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:33:56.018431  1584 solver.cpp:330] Iteration 75000, Testing net (#0)
I0929 12:33:59.376777  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:33:59.518537  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9175
I0929 12:33:59.518564  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.331833 (* 1 = 0.331833 loss)
I0929 12:33:59.664108  1584 solver.cpp:218] Iteration 75000 (5.63547 iter/s, 17.7448s/100 iters), loss = 0.00209444
I0929 12:33:59.664145  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00209374 (* 1 = 0.00209374 loss)
I0929 12:33:59.664152  1584 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I0929 12:34:13.906061  1584 solver.cpp:218] Iteration 75100 (7.02155 iter/s, 14.2419s/100 iters), loss = 0.00239929
I0929 12:34:13.906092  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00239858 (* 1 = 0.00239858 loss)
I0929 12:34:13.906098  1584 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I0929 12:34:28.154821  1584 solver.cpp:218] Iteration 75200 (7.01819 iter/s, 14.2487s/100 iters), loss = 0.00572423
I0929 12:34:28.154953  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00572352 (* 1 = 0.00572352 loss)
I0929 12:34:28.154971  1584 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I0929 12:34:42.403301  1584 solver.cpp:218] Iteration 75300 (7.01837 iter/s, 14.2483s/100 iters), loss = 0.00107916
I0929 12:34:42.403344  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00107845 (* 1 = 0.00107845 loss)
I0929 12:34:42.403352  1584 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I0929 12:34:56.658236  1584 solver.cpp:218] Iteration 75400 (7.01516 iter/s, 14.2549s/100 iters), loss = 0.0019075
I0929 12:34:56.658284  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0019068 (* 1 = 0.0019068 loss)
I0929 12:34:56.658293  1584 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I0929 12:35:10.200641  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:35:10.771811  1584 solver.cpp:330] Iteration 75500, Testing net (#0)
I0929 12:35:14.132068  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:35:14.272047  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9191
I0929 12:35:14.272073  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334672 (* 1 = 0.334672 loss)
I0929 12:35:14.412827  1584 solver.cpp:218] Iteration 75500 (5.63239 iter/s, 17.7545s/100 iters), loss = 0.00258872
I0929 12:35:14.412855  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00258802 (* 1 = 0.00258802 loss)
I0929 12:35:14.412861  1584 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I0929 12:35:28.645987  1584 solver.cpp:218] Iteration 75600 (7.02588 iter/s, 14.2331s/100 iters), loss = 0.00281821
I0929 12:35:28.646026  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0028175 (* 1 = 0.0028175 loss)
I0929 12:35:28.646034  1584 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I0929 12:35:42.889349  1584 solver.cpp:218] Iteration 75700 (7.02085 iter/s, 14.2433s/100 iters), loss = 0.00288002
I0929 12:35:42.889480  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0028793 (* 1 = 0.0028793 loss)
I0929 12:35:42.889488  1584 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I0929 12:35:57.133349  1584 solver.cpp:218] Iteration 75800 (7.02058 iter/s, 14.2438s/100 iters), loss = 0.00318974
I0929 12:35:57.133381  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00318903 (* 1 = 0.00318903 loss)
I0929 12:35:57.133388  1584 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I0929 12:36:11.361919  1584 solver.cpp:218] Iteration 75900 (7.02815 iter/s, 14.2285s/100 iters), loss = 0.00104435
I0929 12:36:11.361949  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00104363 (* 1 = 0.00104363 loss)
I0929 12:36:11.361955  1584 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I0929 12:36:24.892704  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:36:25.460328  1584 solver.cpp:330] Iteration 76000, Testing net (#0)
I0929 12:36:28.821214  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:36:28.961498  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.919
I0929 12:36:28.961532  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324711 (* 1 = 0.324711 loss)
I0929 12:36:29.102322  1584 solver.cpp:218] Iteration 76000 (5.63687 iter/s, 17.7403s/100 iters), loss = 0.0038927
I0929 12:36:29.102351  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00389198 (* 1 = 0.00389198 loss)
I0929 12:36:29.102357  1584 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I0929 12:36:43.341394  1584 solver.cpp:218] Iteration 76100 (7.02296 iter/s, 14.239s/100 iters), loss = 0.00208858
I0929 12:36:43.341424  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00208787 (* 1 = 0.00208787 loss)
I0929 12:36:43.341430  1584 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I0929 12:36:57.579146  1584 solver.cpp:218] Iteration 76200 (7.02362 iter/s, 14.2377s/100 iters), loss = 0.00367043
I0929 12:36:57.579304  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00366973 (* 1 = 0.00366973 loss)
I0929 12:36:57.579322  1584 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I0929 12:37:11.815011  1584 solver.cpp:218] Iteration 76300 (7.02461 iter/s, 14.2357s/100 iters), loss = 0.00376345
I0929 12:37:11.815045  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00376275 (* 1 = 0.00376275 loss)
I0929 12:37:11.815053  1584 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I0929 12:37:26.057842  1584 solver.cpp:218] Iteration 76400 (7.02111 iter/s, 14.2428s/100 iters), loss = 0.00284138
I0929 12:37:26.057883  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00284068 (* 1 = 0.00284068 loss)
I0929 12:37:26.057889  1584 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I0929 12:37:39.598945  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:37:40.165444  1584 solver.cpp:330] Iteration 76500, Testing net (#0)
I0929 12:37:43.525243  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:37:43.665524  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9207
I0929 12:37:43.665560  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.331492 (* 1 = 0.331492 loss)
I0929 12:37:43.806449  1584 solver.cpp:218] Iteration 76500 (5.63427 iter/s, 17.7485s/100 iters), loss = 0.00176062
I0929 12:37:43.806478  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00175992 (* 1 = 0.00175992 loss)
I0929 12:37:43.806485  1584 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I0929 12:37:58.040688  1584 solver.cpp:218] Iteration 76600 (7.02535 iter/s, 14.2342s/100 iters), loss = 0.00603876
I0929 12:37:58.040719  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00603807 (* 1 = 0.00603807 loss)
I0929 12:37:58.040725  1584 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I0929 12:38:12.291676  1584 solver.cpp:218] Iteration 76700 (7.01709 iter/s, 14.2509s/100 iters), loss = 0.00156886
I0929 12:38:12.291781  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00156816 (* 1 = 0.00156816 loss)
I0929 12:38:12.291790  1584 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I0929 12:38:26.520417  1584 solver.cpp:218] Iteration 76800 (7.02809 iter/s, 14.2286s/100 iters), loss = 0.00582388
I0929 12:38:26.520463  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00582319 (* 1 = 0.00582319 loss)
I0929 12:38:26.520470  1584 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I0929 12:38:40.753865  1584 solver.cpp:218] Iteration 76900 (7.02576 iter/s, 14.2333s/100 iters), loss = 0.00329747
I0929 12:38:40.753895  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00329677 (* 1 = 0.00329677 loss)
I0929 12:38:40.753901  1584 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I0929 12:38:54.284245  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:38:54.852048  1584 solver.cpp:330] Iteration 77000, Testing net (#0)
I0929 12:38:58.211704  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:38:58.351801  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I0929 12:38:58.351825  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319687 (* 1 = 0.319687 loss)
I0929 12:38:58.492614  1584 solver.cpp:218] Iteration 77000 (5.6374 iter/s, 17.7387s/100 iters), loss = 0.00131912
I0929 12:38:58.492643  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00131843 (* 1 = 0.00131843 loss)
I0929 12:38:58.492650  1584 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I0929 12:39:12.750077  1584 solver.cpp:218] Iteration 77100 (7.01391 iter/s, 14.2574s/100 iters), loss = 0.00385778
I0929 12:39:12.750108  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00385708 (* 1 = 0.00385708 loss)
I0929 12:39:12.750114  1584 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I0929 12:39:26.995247  1584 solver.cpp:218] Iteration 77200 (7.01996 iter/s, 14.2451s/100 iters), loss = 0.00172618
I0929 12:39:26.995359  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00172549 (* 1 = 0.00172549 loss)
I0929 12:39:26.995378  1584 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I0929 12:39:41.238657  1584 solver.cpp:218] Iteration 77300 (7.02086 iter/s, 14.2433s/100 iters), loss = 0.00533512
I0929 12:39:41.238698  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00533443 (* 1 = 0.00533443 loss)
I0929 12:39:41.238704  1584 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I0929 12:39:55.500025  1584 solver.cpp:218] Iteration 77400 (7.01199 iter/s, 14.2613s/100 iters), loss = 0.000748807
I0929 12:39:55.500056  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000748111 (* 1 = 0.000748111 loss)
I0929 12:39:55.500061  1584 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I0929 12:40:09.051726  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:40:09.619881  1584 solver.cpp:330] Iteration 77500, Testing net (#0)
I0929 12:40:12.978570  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:40:13.118947  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9213
I0929 12:40:13.118983  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.331274 (* 1 = 0.331274 loss)
I0929 12:40:13.260313  1584 solver.cpp:218] Iteration 77500 (5.63056 iter/s, 17.7602s/100 iters), loss = 0.00801106
I0929 12:40:13.260346  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00801036 (* 1 = 0.00801036 loss)
I0929 12:40:13.260354  1584 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I0929 12:40:27.511351  1584 solver.cpp:218] Iteration 77600 (7.01707 iter/s, 14.251s/100 iters), loss = 0.00699155
I0929 12:40:27.511381  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00699086 (* 1 = 0.00699086 loss)
I0929 12:40:27.511387  1584 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I0929 12:40:41.758066  1584 solver.cpp:218] Iteration 77700 (7.0192 iter/s, 14.2466s/100 iters), loss = 0.000854147
I0929 12:40:41.758216  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000853455 (* 1 = 0.000853455 loss)
I0929 12:40:41.758236  1584 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I0929 12:40:56.005267  1584 solver.cpp:218] Iteration 77800 (7.01901 iter/s, 14.247s/100 iters), loss = 0.00139467
I0929 12:40:56.005297  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00139398 (* 1 = 0.00139398 loss)
I0929 12:40:56.005304  1584 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I0929 12:41:10.252708  1584 solver.cpp:218] Iteration 77900 (7.01884 iter/s, 14.2474s/100 iters), loss = 0.00122338
I0929 12:41:10.252738  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00122269 (* 1 = 0.00122269 loss)
I0929 12:41:10.252744  1584 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I0929 12:41:23.804662  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:41:24.374336  1584 solver.cpp:330] Iteration 78000, Testing net (#0)
I0929 12:41:27.736212  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:41:27.876513  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9212
I0929 12:41:27.876549  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.331742 (* 1 = 0.331742 loss)
I0929 12:41:28.017364  1584 solver.cpp:218] Iteration 78000 (5.62918 iter/s, 17.7646s/100 iters), loss = 0.000422087
I0929 12:41:28.017397  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000421398 (* 1 = 0.000421398 loss)
I0929 12:41:28.017405  1584 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I0929 12:41:42.259107  1584 solver.cpp:218] Iteration 78100 (7.02165 iter/s, 14.2417s/100 iters), loss = 0.00361656
I0929 12:41:42.259140  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00361587 (* 1 = 0.00361587 loss)
I0929 12:41:42.259145  1584 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I0929 12:41:56.483026  1584 solver.cpp:218] Iteration 78200 (7.03044 iter/s, 14.2239s/100 iters), loss = 0.000958536
I0929 12:41:56.483201  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000957852 (* 1 = 0.000957852 loss)
I0929 12:41:56.483222  1584 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I0929 12:42:10.726565  1584 solver.cpp:218] Iteration 78300 (7.02082 iter/s, 14.2433s/100 iters), loss = 0.00162294
I0929 12:42:10.726594  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00162226 (* 1 = 0.00162226 loss)
I0929 12:42:10.726601  1584 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I0929 12:42:24.980386  1584 solver.cpp:218] Iteration 78400 (7.0157 iter/s, 14.2537s/100 iters), loss = 0.00067344
I0929 12:42:24.980428  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000672757 (* 1 = 0.000672757 loss)
I0929 12:42:24.980435  1584 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I0929 12:42:38.524889  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:42:39.100250  1584 solver.cpp:330] Iteration 78500, Testing net (#0)
I0929 12:42:42.460320  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:42:42.600419  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9176
I0929 12:42:42.600443  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.343548 (* 1 = 0.343548 loss)
I0929 12:42:42.740717  1584 solver.cpp:218] Iteration 78500 (5.63055 iter/s, 17.7602s/100 iters), loss = 0.00244483
I0929 12:42:42.740746  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00244414 (* 1 = 0.00244414 loss)
I0929 12:42:42.740752  1584 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I0929 12:42:56.982583  1584 solver.cpp:218] Iteration 78600 (7.02159 iter/s, 14.2418s/100 iters), loss = 0.00523481
I0929 12:42:56.982625  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00523413 (* 1 = 0.00523413 loss)
I0929 12:42:56.982631  1584 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I0929 12:43:11.220443  1584 solver.cpp:218] Iteration 78700 (7.02357 iter/s, 14.2378s/100 iters), loss = 0.00116508
I0929 12:43:11.220593  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0011644 (* 1 = 0.0011644 loss)
I0929 12:43:11.220603  1584 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I0929 12:43:25.464380  1584 solver.cpp:218] Iteration 78800 (7.02062 iter/s, 14.2437s/100 iters), loss = 0.00209324
I0929 12:43:25.464421  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00209257 (* 1 = 0.00209257 loss)
I0929 12:43:25.464428  1584 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I0929 12:43:39.710374  1584 solver.cpp:218] Iteration 78900 (7.01955 iter/s, 14.2459s/100 iters), loss = 0.000685876
I0929 12:43:39.710404  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000685203 (* 1 = 0.000685203 loss)
I0929 12:43:39.710410  1584 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I0929 12:43:53.245075  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:43:53.824069  1584 solver.cpp:330] Iteration 79000, Testing net (#0)
I0929 12:43:57.186683  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:43:57.326586  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9222
I0929 12:43:57.326611  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329702 (* 1 = 0.329702 loss)
I0929 12:43:57.468251  1584 solver.cpp:218] Iteration 79000 (5.63133 iter/s, 17.7578s/100 iters), loss = 0.0010522
I0929 12:43:57.468284  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00105153 (* 1 = 0.00105153 loss)
I0929 12:43:57.468291  1584 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I0929 12:44:11.701017  1584 solver.cpp:218] Iteration 79100 (7.02608 iter/s, 14.2327s/100 iters), loss = 0.00292439
I0929 12:44:11.701064  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00292372 (* 1 = 0.00292372 loss)
I0929 12:44:11.701072  1584 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I0929 12:44:25.947919  1584 solver.cpp:218] Iteration 79200 (7.01913 iter/s, 14.2468s/100 iters), loss = 0.00142513
I0929 12:44:25.948060  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00142446 (* 1 = 0.00142446 loss)
I0929 12:44:25.948077  1584 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I0929 12:44:40.194634  1584 solver.cpp:218] Iteration 79300 (7.01925 iter/s, 14.2465s/100 iters), loss = 0.00859082
I0929 12:44:40.194667  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00859015 (* 1 = 0.00859015 loss)
I0929 12:44:40.194674  1584 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I0929 12:44:54.443502  1584 solver.cpp:218] Iteration 79400 (7.01814 iter/s, 14.2488s/100 iters), loss = 0.00167067
I0929 12:44:54.443534  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00167 (* 1 = 0.00167 loss)
I0929 12:44:54.443541  1584 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I0929 12:45:07.968080  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:45:08.535696  1584 solver.cpp:330] Iteration 79500, Testing net (#0)
I0929 12:45:11.901854  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:45:12.041805  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9161
I0929 12:45:12.041828  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.345341 (* 1 = 0.345341 loss)
I0929 12:45:12.183501  1584 solver.cpp:218] Iteration 79500 (5.637 iter/s, 17.7399s/100 iters), loss = 0.00129916
I0929 12:45:12.183537  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00129849 (* 1 = 0.00129849 loss)
I0929 12:45:12.183543  1584 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I0929 12:45:26.418491  1584 solver.cpp:218] Iteration 79600 (7.02498 iter/s, 14.2349s/100 iters), loss = 0.0119489
I0929 12:45:26.418534  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0119482 (* 1 = 0.0119482 loss)
I0929 12:45:26.418540  1584 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I0929 12:45:40.664589  1584 solver.cpp:218] Iteration 79700 (7.01951 iter/s, 14.246s/100 iters), loss = 0.000555381
I0929 12:45:40.664733  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00055471 (* 1 = 0.00055471 loss)
I0929 12:45:40.664742  1584 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I0929 12:45:54.898624  1584 solver.cpp:218] Iteration 79800 (7.0255 iter/s, 14.2339s/100 iters), loss = 0.00404414
I0929 12:45:54.898655  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00404347 (* 1 = 0.00404347 loss)
I0929 12:45:54.898663  1584 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I0929 12:46:09.143846  1584 solver.cpp:218] Iteration 79900 (7.01993 iter/s, 14.2451s/100 iters), loss = 0.000708491
I0929 12:46:09.143879  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000707825 (* 1 = 0.000707825 loss)
I0929 12:46:09.143895  1584 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I0929 12:46:22.666911  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:46:23.234155  1584 solver.cpp:330] Iteration 80000, Testing net (#0)
I0929 12:46:26.596490  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:46:26.740042  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9231
I0929 12:46:26.740069  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320572 (* 1 = 0.320572 loss)
I0929 12:46:26.883769  1584 solver.cpp:218] Iteration 80000 (5.63703 iter/s, 17.7398s/100 iters), loss = 0.00767063
I0929 12:46:26.883803  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00766997 (* 1 = 0.00766997 loss)
I0929 12:46:26.883810  1584 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I0929 12:46:26.883813  1584 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I0929 12:46:41.110674  1584 solver.cpp:218] Iteration 80100 (7.02899 iter/s, 14.2268s/100 iters), loss = 0.00373349
I0929 12:46:41.110704  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00373283 (* 1 = 0.00373283 loss)
I0929 12:46:41.110710  1584 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I0929 12:46:55.352985  1584 solver.cpp:218] Iteration 80200 (7.02137 iter/s, 14.2422s/100 iters), loss = 0.00115975
I0929 12:46:55.353121  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00115908 (* 1 = 0.00115908 loss)
I0929 12:46:55.353129  1584 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I0929 12:47:09.607581  1584 solver.cpp:218] Iteration 80300 (7.01536 iter/s, 14.2544s/100 iters), loss = 0.000944194
I0929 12:47:09.607612  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000943534 (* 1 = 0.000943534 loss)
I0929 12:47:09.607620  1584 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I0929 12:47:23.848299  1584 solver.cpp:218] Iteration 80400 (7.02216 iter/s, 14.2406s/100 iters), loss = 0.00828184
I0929 12:47:23.848335  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00828118 (* 1 = 0.00828118 loss)
I0929 12:47:23.848341  1584 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I0929 12:47:37.376685  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:47:37.946372  1584 solver.cpp:330] Iteration 80500, Testing net (#0)
I0929 12:47:41.305866  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:47:41.445689  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9252
I0929 12:47:41.445713  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310122 (* 1 = 0.310122 loss)
I0929 12:47:41.586874  1584 solver.cpp:218] Iteration 80500 (5.63746 iter/s, 17.7385s/100 iters), loss = 0.000517421
I0929 12:47:41.586922  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000516762 (* 1 = 0.000516762 loss)
I0929 12:47:41.586930  1584 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I0929 12:47:55.833870  1584 solver.cpp:218] Iteration 80600 (7.01908 iter/s, 14.2469s/100 iters), loss = 0.00286105
I0929 12:47:55.833909  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00286039 (* 1 = 0.00286039 loss)
I0929 12:47:55.833916  1584 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I0929 12:48:10.076377  1584 solver.cpp:218] Iteration 80700 (7.02128 iter/s, 14.2424s/100 iters), loss = 0.000441805
I0929 12:48:10.076498  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000441144 (* 1 = 0.000441144 loss)
I0929 12:48:10.076505  1584 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I0929 12:48:24.312445  1584 solver.cpp:218] Iteration 80800 (7.02449 iter/s, 14.2359s/100 iters), loss = 0.00369373
I0929 12:48:24.312475  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00369307 (* 1 = 0.00369307 loss)
I0929 12:48:24.312482  1584 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I0929 12:48:38.549718  1584 solver.cpp:218] Iteration 80900 (7.02385 iter/s, 14.2372s/100 iters), loss = 0.00119288
I0929 12:48:38.549749  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00119222 (* 1 = 0.00119222 loss)
I0929 12:48:38.549757  1584 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I0929 12:48:52.087558  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:48:52.657176  1584 solver.cpp:330] Iteration 81000, Testing net (#0)
I0929 12:48:56.015254  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:48:56.154280  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9257
I0929 12:48:56.154304  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309633 (* 1 = 0.309633 loss)
I0929 12:48:56.295310  1584 solver.cpp:218] Iteration 81000 (5.63523 iter/s, 17.7455s/100 iters), loss = 0.00541048
I0929 12:48:56.295338  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00540982 (* 1 = 0.00540982 loss)
I0929 12:48:56.295346  1584 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I0929 12:49:10.534523  1584 solver.cpp:218] Iteration 81100 (7.02289 iter/s, 14.2391s/100 iters), loss = 0.00237488
I0929 12:49:10.534554  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00237423 (* 1 = 0.00237423 loss)
I0929 12:49:10.534559  1584 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I0929 12:49:24.785785  1584 solver.cpp:218] Iteration 81200 (7.01696 iter/s, 14.2512s/100 iters), loss = 0.00407428
I0929 12:49:24.785943  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00407362 (* 1 = 0.00407362 loss)
I0929 12:49:24.785951  1584 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I0929 12:49:39.027927  1584 solver.cpp:218] Iteration 81300 (7.02151 iter/s, 14.2419s/100 iters), loss = 0.00408913
I0929 12:49:39.027961  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00408847 (* 1 = 0.00408847 loss)
I0929 12:49:39.027966  1584 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I0929 12:49:53.257774  1584 solver.cpp:218] Iteration 81400 (7.02752 iter/s, 14.2298s/100 iters), loss = 0.000493999
I0929 12:49:53.257805  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000493339 (* 1 = 0.000493339 loss)
I0929 12:49:53.257812  1584 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I0929 12:50:06.796635  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:50:07.365586  1584 solver.cpp:330] Iteration 81500, Testing net (#0)
I0929 12:50:10.728857  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:50:10.868885  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9261
I0929 12:50:10.868918  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308379 (* 1 = 0.308379 loss)
I0929 12:50:11.010606  1584 solver.cpp:218] Iteration 81500 (5.63293 iter/s, 17.7528s/100 iters), loss = 0.000498747
I0929 12:50:11.010639  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000498087 (* 1 = 0.000498087 loss)
I0929 12:50:11.010646  1584 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I0929 12:50:25.257378  1584 solver.cpp:218] Iteration 81600 (7.01917 iter/s, 14.2467s/100 iters), loss = 0.00219043
I0929 12:50:25.257411  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00218977 (* 1 = 0.00218977 loss)
I0929 12:50:25.257418  1584 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I0929 12:50:39.499713  1584 solver.cpp:218] Iteration 81700 (7.02136 iter/s, 14.2423s/100 iters), loss = 0.00197098
I0929 12:50:39.499830  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00197032 (* 1 = 0.00197032 loss)
I0929 12:50:39.499836  1584 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I0929 12:50:53.735111  1584 solver.cpp:218] Iteration 81800 (7.02482 iter/s, 14.2352s/100 iters), loss = 0.00215137
I0929 12:50:53.735150  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00215071 (* 1 = 0.00215071 loss)
I0929 12:50:53.735167  1584 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I0929 12:51:07.978715  1584 solver.cpp:218] Iteration 81900 (7.02075 iter/s, 14.2435s/100 iters), loss = 0.000719479
I0929 12:51:07.978746  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00071882 (* 1 = 0.00071882 loss)
I0929 12:51:07.978752  1584 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I0929 12:51:21.518188  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:51:22.085865  1584 solver.cpp:330] Iteration 82000, Testing net (#0)
I0929 12:51:25.445725  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:51:25.586093  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9264
I0929 12:51:25.586127  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310018 (* 1 = 0.310018 loss)
I0929 12:51:25.727046  1584 solver.cpp:218] Iteration 82000 (5.63436 iter/s, 17.7482s/100 iters), loss = 0.000407202
I0929 12:51:25.727077  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000406545 (* 1 = 0.000406545 loss)
I0929 12:51:25.727084  1584 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I0929 12:51:39.964375  1584 solver.cpp:218] Iteration 82100 (7.02383 iter/s, 14.2373s/100 iters), loss = 0.00113255
I0929 12:51:39.964407  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00113189 (* 1 = 0.00113189 loss)
I0929 12:51:39.964413  1584 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I0929 12:51:54.209821  1584 solver.cpp:218] Iteration 82200 (7.01982 iter/s, 14.2454s/100 iters), loss = 0.00679816
I0929 12:51:54.209997  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00679751 (* 1 = 0.00679751 loss)
I0929 12:51:54.210007  1584 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I0929 12:52:08.457898  1584 solver.cpp:218] Iteration 82300 (7.01859 iter/s, 14.2479s/100 iters), loss = 0.00115107
I0929 12:52:08.457931  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00115041 (* 1 = 0.00115041 loss)
I0929 12:52:08.457947  1584 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I0929 12:52:22.692142  1584 solver.cpp:218] Iteration 82400 (7.02535 iter/s, 14.2342s/100 iters), loss = 0.000624214
I0929 12:52:22.692173  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000623556 (* 1 = 0.000623556 loss)
I0929 12:52:22.692179  1584 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I0929 12:52:36.234340  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:52:36.803885  1584 solver.cpp:330] Iteration 82500, Testing net (#0)
I0929 12:52:40.166395  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:52:40.306727  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9263
I0929 12:52:40.306763  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308922 (* 1 = 0.308922 loss)
I0929 12:52:40.447917  1584 solver.cpp:218] Iteration 82500 (5.632 iter/s, 17.7557s/100 iters), loss = 0.000571966
I0929 12:52:40.447949  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000571309 (* 1 = 0.000571309 loss)
I0929 12:52:40.447957  1584 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I0929 12:52:54.696051  1584 solver.cpp:218] Iteration 82600 (7.0185 iter/s, 14.2481s/100 iters), loss = 0.00237262
I0929 12:52:54.696082  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00237196 (* 1 = 0.00237196 loss)
I0929 12:52:54.696089  1584 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I0929 12:53:08.942451  1584 solver.cpp:218] Iteration 82700 (7.01935 iter/s, 14.2463s/100 iters), loss = 0.000872388
I0929 12:53:08.942560  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00087173 (* 1 = 0.00087173 loss)
I0929 12:53:08.942577  1584 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I0929 12:53:23.190610  1584 solver.cpp:218] Iteration 82800 (7.01852 iter/s, 14.248s/100 iters), loss = 0.00184682
I0929 12:53:23.190642  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00184616 (* 1 = 0.00184616 loss)
I0929 12:53:23.190649  1584 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I0929 12:53:37.455541  1584 solver.cpp:218] Iteration 82900 (7.01023 iter/s, 14.2649s/100 iters), loss = 0.00113308
I0929 12:53:37.455574  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00113242 (* 1 = 0.00113242 loss)
I0929 12:53:37.455581  1584 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I0929 12:53:50.991111  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:53:51.558881  1584 solver.cpp:330] Iteration 83000, Testing net (#0)
I0929 12:53:54.916960  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:53:55.056937  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9263
I0929 12:53:55.056972  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307863 (* 1 = 0.307863 loss)
I0929 12:53:55.197538  1584 solver.cpp:218] Iteration 83000 (5.63637 iter/s, 17.7419s/100 iters), loss = 0.000435948
I0929 12:53:55.197571  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000435291 (* 1 = 0.000435291 loss)
I0929 12:53:55.197577  1584 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I0929 12:54:09.445792  1584 solver.cpp:218] Iteration 83100 (7.01844 iter/s, 14.2482s/100 iters), loss = 0.00111498
I0929 12:54:09.445824  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00111433 (* 1 = 0.00111433 loss)
I0929 12:54:09.445830  1584 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I0929 12:54:23.687741  1584 solver.cpp:218] Iteration 83200 (7.02155 iter/s, 14.2419s/100 iters), loss = 0.00233388
I0929 12:54:23.687881  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00233322 (* 1 = 0.00233322 loss)
I0929 12:54:23.687889  1584 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I0929 12:54:37.932142  1584 solver.cpp:218] Iteration 83300 (7.02038 iter/s, 14.2442s/100 iters), loss = 0.00410329
I0929 12:54:37.932171  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00410263 (* 1 = 0.00410263 loss)
I0929 12:54:37.932178  1584 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I0929 12:54:52.183456  1584 solver.cpp:218] Iteration 83400 (7.01693 iter/s, 14.2512s/100 iters), loss = 0.00101906
I0929 12:54:52.183487  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010184 (* 1 = 0.0010184 loss)
I0929 12:54:52.183493  1584 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I0929 12:55:05.729061  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:55:06.301961  1584 solver.cpp:330] Iteration 83500, Testing net (#0)
I0929 12:55:09.666048  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:55:09.806252  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9259
I0929 12:55:09.806287  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308618 (* 1 = 0.308618 loss)
I0929 12:55:09.947597  1584 solver.cpp:218] Iteration 83500 (5.62934 iter/s, 17.7641s/100 iters), loss = 0.000626691
I0929 12:55:09.947643  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000626031 (* 1 = 0.000626031 loss)
I0929 12:55:09.947649  1584 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I0929 12:55:24.191738  1584 solver.cpp:218] Iteration 83600 (7.02047 iter/s, 14.2441s/100 iters), loss = 0.00562532
I0929 12:55:24.191771  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00562466 (* 1 = 0.00562466 loss)
I0929 12:55:24.191777  1584 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I0929 12:55:38.433845  1584 solver.cpp:218] Iteration 83700 (7.02147 iter/s, 14.242s/100 iters), loss = 0.000380602
I0929 12:55:38.433975  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000379939 (* 1 = 0.000379939 loss)
I0929 12:55:38.433985  1584 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I0929 12:55:52.692282  1584 solver.cpp:218] Iteration 83800 (7.01347 iter/s, 14.2583s/100 iters), loss = 0.00324376
I0929 12:55:52.692312  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00324309 (* 1 = 0.00324309 loss)
I0929 12:55:52.692318  1584 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I0929 12:56:06.946501  1584 solver.cpp:218] Iteration 83900 (7.0155 iter/s, 14.2541s/100 iters), loss = 0.000471315
I0929 12:56:06.946532  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000470651 (* 1 = 0.000470651 loss)
I0929 12:56:06.946539  1584 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I0929 12:56:20.473300  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:56:21.050571  1584 solver.cpp:330] Iteration 84000, Testing net (#0)
I0929 12:56:24.412739  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:56:24.552603  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9267
I0929 12:56:24.552628  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308496 (* 1 = 0.308496 loss)
I0929 12:56:24.693819  1584 solver.cpp:218] Iteration 84000 (5.63468 iter/s, 17.7472s/100 iters), loss = 0.00028428
I0929 12:56:24.693848  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000283616 (* 1 = 0.000283616 loss)
I0929 12:56:24.693856  1584 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I0929 12:56:38.957661  1584 solver.cpp:218] Iteration 84100 (7.01077 iter/s, 14.2638s/100 iters), loss = 0.00234609
I0929 12:56:38.957696  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00234542 (* 1 = 0.00234542 loss)
I0929 12:56:38.957703  1584 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I0929 12:56:53.218020  1584 solver.cpp:218] Iteration 84200 (7.01248 iter/s, 14.2603s/100 iters), loss = 0.00426544
I0929 12:56:53.218155  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00426477 (* 1 = 0.00426477 loss)
I0929 12:56:53.218163  1584 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I0929 12:57:07.477180  1584 solver.cpp:218] Iteration 84300 (7.01312 iter/s, 14.259s/100 iters), loss = 0.00140313
I0929 12:57:07.477210  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00140246 (* 1 = 0.00140246 loss)
I0929 12:57:07.477216  1584 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I0929 12:57:21.740685  1584 solver.cpp:218] Iteration 84400 (7.01093 iter/s, 14.2634s/100 iters), loss = 0.00068136
I0929 12:57:21.740715  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000680695 (* 1 = 0.000680695 loss)
I0929 12:57:21.740721  1584 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I0929 12:57:35.288148  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:57:35.864239  1584 solver.cpp:330] Iteration 84500, Testing net (#0)
I0929 12:57:39.226200  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:57:39.366025  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9262
I0929 12:57:39.366051  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308204 (* 1 = 0.308204 loss)
I0929 12:57:39.507978  1584 solver.cpp:218] Iteration 84500 (5.62834 iter/s, 17.7672s/100 iters), loss = 0.000733837
I0929 12:57:39.508013  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000733172 (* 1 = 0.000733172 loss)
I0929 12:57:39.508020  1584 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I0929 12:57:53.747658  1584 solver.cpp:218] Iteration 84600 (7.02267 iter/s, 14.2396s/100 iters), loss = 0.00363229
I0929 12:57:53.747694  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00363163 (* 1 = 0.00363163 loss)
I0929 12:57:53.747700  1584 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I0929 12:58:07.993414  1584 solver.cpp:218] Iteration 84700 (7.01967 iter/s, 14.2457s/100 iters), loss = 0.00032285
I0929 12:58:07.993530  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000322185 (* 1 = 0.000322185 loss)
I0929 12:58:07.993548  1584 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I0929 12:58:22.255261  1584 solver.cpp:218] Iteration 84800 (7.01179 iter/s, 14.2617s/100 iters), loss = 0.0145345
I0929 12:58:22.255291  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145338 (* 1 = 0.0145338 loss)
I0929 12:58:22.255298  1584 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I0929 12:58:36.507616  1584 solver.cpp:218] Iteration 84900 (7.01642 iter/s, 14.2523s/100 iters), loss = 0.000555288
I0929 12:58:36.507658  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000554625 (* 1 = 0.000554625 loss)
I0929 12:58:36.507664  1584 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I0929 12:58:50.042754  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:58:50.612121  1584 solver.cpp:330] Iteration 85000, Testing net (#0)
I0929 12:58:53.983788  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:58:54.123903  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9263
I0929 12:58:54.123939  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.30856 (* 1 = 0.30856 loss)
I0929 12:58:54.264982  1584 solver.cpp:218] Iteration 85000 (5.63149 iter/s, 17.7573s/100 iters), loss = 0.000870939
I0929 12:58:54.265017  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000870278 (* 1 = 0.000870278 loss)
I0929 12:58:54.265022  1584 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I0929 12:59:08.504297  1584 solver.cpp:218] Iteration 85100 (7.02285 iter/s, 14.2392s/100 iters), loss = 0.00063208
I0929 12:59:08.504346  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000631418 (* 1 = 0.000631418 loss)
I0929 12:59:08.504354  1584 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I0929 12:59:22.756130  1584 solver.cpp:218] Iteration 85200 (7.01668 iter/s, 14.2517s/100 iters), loss = 0.00216753
I0929 12:59:22.756312  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00216686 (* 1 = 0.00216686 loss)
I0929 12:59:22.756321  1584 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I0929 12:59:36.997803  1584 solver.cpp:218] Iteration 85300 (7.02175 iter/s, 14.2415s/100 iters), loss = 0.00217475
I0929 12:59:36.997844  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00217409 (* 1 = 0.00217409 loss)
I0929 12:59:36.997850  1584 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I0929 12:59:51.252596  1584 solver.cpp:218] Iteration 85400 (7.01522 iter/s, 14.2547s/100 iters), loss = 0.0013686
I0929 12:59:51.252627  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00136794 (* 1 = 0.00136794 loss)
I0929 12:59:51.252635  1584 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I0929 13:00:04.787636  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:00:05.355772  1584 solver.cpp:330] Iteration 85500, Testing net (#0)
I0929 13:00:08.721709  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:00:08.865267  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9261
I0929 13:00:08.865303  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308556 (* 1 = 0.308556 loss)
I0929 13:00:09.007618  1584 solver.cpp:218] Iteration 85500 (5.63223 iter/s, 17.7549s/100 iters), loss = 0.000337834
I0929 13:00:09.007652  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000337172 (* 1 = 0.000337172 loss)
I0929 13:00:09.007659  1584 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I0929 13:00:23.238638  1584 solver.cpp:218] Iteration 85600 (7.02694 iter/s, 14.2309s/100 iters), loss = 0.00346896
I0929 13:00:23.238675  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0034683 (* 1 = 0.0034683 loss)
I0929 13:00:23.238683  1584 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I0929 13:00:37.490535  1584 solver.cpp:218] Iteration 85700 (7.01665 iter/s, 14.2518s/100 iters), loss = 0.0012303
I0929 13:00:37.490681  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00122964 (* 1 = 0.00122964 loss)
I0929 13:00:37.490690  1584 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I0929 13:00:51.743111  1584 solver.cpp:218] Iteration 85800 (7.01636 iter/s, 14.2524s/100 iters), loss = 0.0015497
I0929 13:00:51.743141  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154903 (* 1 = 0.00154903 loss)
I0929 13:00:51.743147  1584 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I0929 13:01:05.988741  1584 solver.cpp:218] Iteration 85900 (7.01973 iter/s, 14.2456s/100 iters), loss = 0.00082807
I0929 13:01:05.988775  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000827407 (* 1 = 0.000827407 loss)
I0929 13:01:05.988781  1584 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I0929 13:01:19.525460  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:01:20.093905  1584 solver.cpp:330] Iteration 86000, Testing net (#0)
I0929 13:01:23.452739  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:01:23.592878  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9265
I0929 13:01:23.592912  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308471 (* 1 = 0.308471 loss)
I0929 13:01:23.737468  1584 solver.cpp:218] Iteration 86000 (5.63423 iter/s, 17.7486s/100 iters), loss = 0.000679622
I0929 13:01:23.737504  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000678959 (* 1 = 0.000678959 loss)
I0929 13:01:23.737511  1584 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I0929 13:01:37.968389  1584 solver.cpp:218] Iteration 86100 (7.02699 iter/s, 14.2308s/100 iters), loss = 0.00945552
I0929 13:01:37.968421  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00945486 (* 1 = 0.00945486 loss)
I0929 13:01:37.968427  1584 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I0929 13:01:52.208492  1584 solver.cpp:218] Iteration 86200 (7.02246 iter/s, 14.24s/100 iters), loss = 0.00159811
I0929 13:01:52.208654  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00159744 (* 1 = 0.00159744 loss)
I0929 13:01:52.208673  1584 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I0929 13:02:06.454327  1584 solver.cpp:218] Iteration 86300 (7.01969 iter/s, 14.2456s/100 iters), loss = 0.00160803
I0929 13:02:06.454360  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00160737 (* 1 = 0.00160737 loss)
I0929 13:02:06.454366  1584 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I0929 13:02:20.699061  1584 solver.cpp:218] Iteration 86400 (7.02018 iter/s, 14.2447s/100 iters), loss = 0.000404694
I0929 13:02:20.699098  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00040403 (* 1 = 0.00040403 loss)
I0929 13:02:20.699106  1584 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I0929 13:02:34.237684  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:02:34.806674  1584 solver.cpp:330] Iteration 86500, Testing net (#0)
I0929 13:02:38.165048  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:02:38.305133  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9268
I0929 13:02:38.305157  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308574 (* 1 = 0.308574 loss)
I0929 13:02:38.445454  1584 solver.cpp:218] Iteration 86500 (5.63497 iter/s, 17.7463s/100 iters), loss = 0.00149451
I0929 13:02:38.445487  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00149385 (* 1 = 0.00149385 loss)
I0929 13:02:38.445494  1584 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I0929 13:02:52.677937  1584 solver.cpp:218] Iteration 86600 (7.02622 iter/s, 14.2324s/100 iters), loss = 0.00238013
I0929 13:02:52.677966  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00237946 (* 1 = 0.00237946 loss)
I0929 13:02:52.677973  1584 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I0929 13:03:06.921643  1584 solver.cpp:218] Iteration 86700 (7.02068 iter/s, 14.2436s/100 iters), loss = 0.00152341
I0929 13:03:06.921759  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00152274 (* 1 = 0.00152274 loss)
I0929 13:03:06.921766  1584 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I0929 13:03:21.156795  1584 solver.cpp:218] Iteration 86800 (7.02493 iter/s, 14.235s/100 iters), loss = 0.00131061
I0929 13:03:21.156829  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00130995 (* 1 = 0.00130995 loss)
I0929 13:03:21.156836  1584 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I0929 13:03:35.378865  1584 solver.cpp:218] Iteration 86900 (7.03136 iter/s, 14.222s/100 iters), loss = 0.0011971
I0929 13:03:35.378896  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00119643 (* 1 = 0.00119643 loss)
I0929 13:03:35.378902  1584 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I0929 13:03:48.915273  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:03:49.484908  1584 solver.cpp:330] Iteration 87000, Testing net (#0)
I0929 13:03:52.845746  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:03:52.985761  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9261
I0929 13:03:52.985786  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308554 (* 1 = 0.308554 loss)
I0929 13:03:53.126554  1584 solver.cpp:218] Iteration 87000 (5.63456 iter/s, 17.7476s/100 iters), loss = 0.000737349
I0929 13:03:53.126585  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000736683 (* 1 = 0.000736683 loss)
I0929 13:03:53.126592  1584 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I0929 13:04:07.373793  1584 solver.cpp:218] Iteration 87100 (7.01894 iter/s, 14.2472s/100 iters), loss = 0.00182854
I0929 13:04:07.373834  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00182787 (* 1 = 0.00182787 loss)
I0929 13:04:07.373841  1584 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I0929 13:04:21.612579  1584 solver.cpp:218] Iteration 87200 (7.02311 iter/s, 14.2387s/100 iters), loss = 0.00153397
I0929 13:04:21.612704  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0015333 (* 1 = 0.0015333 loss)
I0929 13:04:21.612711  1584 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I0929 13:04:35.866513  1584 solver.cpp:218] Iteration 87300 (7.01569 iter/s, 14.2538s/100 iters), loss = 0.000891146
I0929 13:04:35.866551  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000890478 (* 1 = 0.000890478 loss)
I0929 13:04:35.866559  1584 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I0929 13:04:50.113396  1584 solver.cpp:218] Iteration 87400 (7.01912 iter/s, 14.2468s/100 iters), loss = 0.0010537
I0929 13:04:50.113426  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00105303 (* 1 = 0.00105303 loss)
I0929 13:04:50.113432  1584 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I0929 13:05:03.651363  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:05:04.220082  1584 solver.cpp:330] Iteration 87500, Testing net (#0)
I0929 13:05:07.574167  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:05:07.714030  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9258
I0929 13:05:07.714061  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309517 (* 1 = 0.309517 loss)
I0929 13:05:07.854646  1584 solver.cpp:218] Iteration 87500 (5.63661 iter/s, 17.7412s/100 iters), loss = 0.000458497
I0929 13:05:07.854681  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000457831 (* 1 = 0.000457831 loss)
I0929 13:05:07.854689  1584 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I0929 13:05:22.112890  1584 solver.cpp:218] Iteration 87600 (7.01352 iter/s, 14.2582s/100 iters), loss = 0.00265905
I0929 13:05:22.112920  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00265838 (* 1 = 0.00265838 loss)
I0929 13:05:22.112926  1584 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I0929 13:05:36.378255  1584 solver.cpp:218] Iteration 87700 (7.01002 iter/s, 14.2653s/100 iters), loss = 0.000977432
I0929 13:05:36.378387  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000976768 (* 1 = 0.000976768 loss)
I0929 13:05:36.378409  1584 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I0929 13:05:50.625041  1584 solver.cpp:218] Iteration 87800 (7.01921 iter/s, 14.2466s/100 iters), loss = 0.000527859
I0929 13:05:50.625073  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000527197 (* 1 = 0.000527197 loss)
I0929 13:05:50.625080  1584 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I0929 13:06:04.884176  1584 solver.cpp:218] Iteration 87900 (7.01308 iter/s, 14.2591s/100 iters), loss = 0.00082953
I0929 13:06:04.884207  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000828867 (* 1 = 0.000828867 loss)
I0929 13:06:04.884212  1584 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I0929 13:06:18.442409  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:06:19.011211  1584 solver.cpp:330] Iteration 88000, Testing net (#0)
I0929 13:06:22.371186  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:06:22.511518  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9269
I0929 13:06:22.511561  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309083 (* 1 = 0.309083 loss)
I0929 13:06:22.652221  1584 solver.cpp:218] Iteration 88000 (5.6281 iter/s, 17.768s/100 iters), loss = 0.000985925
I0929 13:06:22.652253  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000985263 (* 1 = 0.000985263 loss)
I0929 13:06:22.652261  1584 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I0929 13:06:36.895139  1584 solver.cpp:218] Iteration 88100 (7.02107 iter/s, 14.2428s/100 iters), loss = 0.00118423
I0929 13:06:36.895170  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00118357 (* 1 = 0.00118357 loss)
I0929 13:06:36.895176  1584 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I0929 13:06:51.151093  1584 solver.cpp:218] Iteration 88200 (7.01465 iter/s, 14.2559s/100 iters), loss = 0.000574659
I0929 13:06:51.151228  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000573997 (* 1 = 0.000573997 loss)
I0929 13:06:51.151249  1584 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I0929 13:07:05.405899  1584 solver.cpp:218] Iteration 88300 (7.01526 iter/s, 14.2546s/100 iters), loss = 0.00138343
I0929 13:07:05.405941  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00138277 (* 1 = 0.00138277 loss)
I0929 13:07:05.405947  1584 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I0929 13:07:19.666754  1584 solver.cpp:218] Iteration 88400 (7.01224 iter/s, 14.2608s/100 iters), loss = 0.000638215
I0929 13:07:19.666795  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000637553 (* 1 = 0.000637553 loss)
I0929 13:07:19.666801  1584 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I0929 13:07:33.211768  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:07:33.780588  1584 solver.cpp:330] Iteration 88500, Testing net (#0)
I0929 13:07:37.141316  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:07:37.280985  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9271
I0929 13:07:37.281019  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.30926 (* 1 = 0.30926 loss)
I0929 13:07:37.421823  1584 solver.cpp:218] Iteration 88500 (5.63222 iter/s, 17.755s/100 iters), loss = 0.00025144
I0929 13:07:37.421854  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000250781 (* 1 = 0.000250781 loss)
I0929 13:07:37.421862  1584 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I0929 13:07:51.663944  1584 solver.cpp:218] Iteration 88600 (7.02146 iter/s, 14.242s/100 iters), loss = 0.00150026
I0929 13:07:51.663983  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0014996 (* 1 = 0.0014996 loss)
I0929 13:07:51.663991  1584 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I0929 13:08:05.909221  1584 solver.cpp:218] Iteration 88700 (7.01991 iter/s, 14.2452s/100 iters), loss = 0.000693577
I0929 13:08:05.909322  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000692917 (* 1 = 0.000692917 loss)
I0929 13:08:05.909333  1584 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I0929 13:08:20.136642  1584 solver.cpp:218] Iteration 88800 (7.02876 iter/s, 14.2273s/100 iters), loss = 0.000970396
I0929 13:08:20.136672  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000969736 (* 1 = 0.000969736 loss)
I0929 13:08:20.136677  1584 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I0929 13:08:34.377532  1584 solver.cpp:218] Iteration 88900 (7.02207 iter/s, 14.2408s/100 iters), loss = 0.00313836
I0929 13:08:34.377569  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0031377 (* 1 = 0.0031377 loss)
I0929 13:08:34.377578  1584 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I0929 13:08:47.917517  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:08:48.487385  1584 solver.cpp:330] Iteration 89000, Testing net (#0)
I0929 13:08:51.848783  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:08:51.988821  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9259
I0929 13:08:51.988857  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308582 (* 1 = 0.308582 loss)
I0929 13:08:52.129565  1584 solver.cpp:218] Iteration 89000 (5.63318 iter/s, 17.7519s/100 iters), loss = 0.000913174
I0929 13:08:52.129597  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000912516 (* 1 = 0.000912516 loss)
I0929 13:08:52.129604  1584 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I0929 13:09:06.362910  1584 solver.cpp:218] Iteration 89100 (7.02579 iter/s, 14.2333s/100 iters), loss = 0.000969587
I0929 13:09:06.362946  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00096893 (* 1 = 0.00096893 loss)
I0929 13:09:06.362951  1584 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I0929 13:09:20.591994  1584 solver.cpp:218] Iteration 89200 (7.0279 iter/s, 14.229s/100 iters), loss = 0.000930584
I0929 13:09:20.592160  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000929925 (* 1 = 0.000929925 loss)
I0929 13:09:20.592180  1584 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I0929 13:09:34.840183  1584 solver.cpp:218] Iteration 89300 (7.01854 iter/s, 14.248s/100 iters), loss = 0.00114149
I0929 13:09:34.840212  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00114083 (* 1 = 0.00114083 loss)
I0929 13:09:34.840219  1584 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I0929 13:09:49.069957  1584 solver.cpp:218] Iteration 89400 (7.02755 iter/s, 14.2297s/100 iters), loss = 0.00176596
I0929 13:09:49.069988  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0017653 (* 1 = 0.0017653 loss)
I0929 13:09:49.069993  1584 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I0929 13:10:02.588490  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:10:03.166016  1584 solver.cpp:330] Iteration 89500, Testing net (#0)
I0929 13:10:06.527824  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:10:06.667906  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9261
I0929 13:10:06.667943  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309009 (* 1 = 0.309009 loss)
I0929 13:10:06.808887  1584 solver.cpp:218] Iteration 89500 (5.63734 iter/s, 17.7389s/100 iters), loss = 0.0012497
I0929 13:10:06.808917  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00124905 (* 1 = 0.00124905 loss)
I0929 13:10:06.808924  1584 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I0929 13:10:21.061136  1584 solver.cpp:218] Iteration 89600 (7.01657 iter/s, 14.252s/100 iters), loss = 0.0114752
I0929 13:10:21.061172  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114746 (* 1 = 0.0114746 loss)
I0929 13:10:21.061178  1584 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I0929 13:10:35.300432  1584 solver.cpp:218] Iteration 89700 (7.02286 iter/s, 14.2392s/100 iters), loss = 0.000367387
I0929 13:10:35.300526  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000366729 (* 1 = 0.000366729 loss)
I0929 13:10:35.300544  1584 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I0929 13:10:49.536689  1584 solver.cpp:218] Iteration 89800 (7.02438 iter/s, 14.2361s/100 iters), loss = 0.00242025
I0929 13:10:49.536717  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00241959 (* 1 = 0.00241959 loss)
I0929 13:10:49.536725  1584 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I0929 13:11:03.791210  1584 solver.cpp:218] Iteration 89900 (7.01535 iter/s, 14.2544s/100 iters), loss = 0.000751924
I0929 13:11:03.791242  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000751267 (* 1 = 0.000751267 loss)
I0929 13:11:03.791249  1584 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I0929 13:11:17.326337  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:11:17.899412  1584 solver.cpp:330] Iteration 90000, Testing net (#0)
I0929 13:11:21.261823  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:11:21.401990  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.926
I0929 13:11:21.402026  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.30918 (* 1 = 0.30918 loss)
I0929 13:11:21.542949  1584 solver.cpp:218] Iteration 90000 (5.63328 iter/s, 17.7517s/100 iters), loss = 0.000697236
I0929 13:11:21.542984  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00069658 (* 1 = 0.00069658 loss)
I0929 13:11:21.542990  1584 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I0929 13:11:35.766849  1584 solver.cpp:218] Iteration 90100 (7.03046 iter/s, 14.2238s/100 iters), loss = 0.00154351
I0929 13:11:35.766898  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154285 (* 1 = 0.00154285 loss)
I0929 13:11:35.766908  1584 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I0929 13:11:50.010308  1584 solver.cpp:218] Iteration 90200 (7.02082 iter/s, 14.2433s/100 iters), loss = 0.00205847
I0929 13:11:50.010397  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00205782 (* 1 = 0.00205782 loss)
I0929 13:11:50.010418  1584 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I0929 13:12:04.255962  1584 solver.cpp:218] Iteration 90300 (7.01975 iter/s, 14.2455s/100 iters), loss = 0.00143872
I0929 13:12:04.255993  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00143807 (* 1 = 0.00143807 loss)
I0929 13:12:04.256000  1584 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I0929 13:12:18.490514  1584 solver.cpp:218] Iteration 90400 (7.02519 iter/s, 14.2345s/100 iters), loss = 0.000730515
I0929 13:12:18.490546  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00072986 (* 1 = 0.00072986 loss)
I0929 13:12:18.490552  1584 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I0929 13:12:32.015348  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:12:32.583166  1584 solver.cpp:330] Iteration 90500, Testing net (#0)
I0929 13:12:35.954231  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:12:36.095299  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9262
I0929 13:12:36.095325  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308581 (* 1 = 0.308581 loss)
I0929 13:12:36.235939  1584 solver.cpp:218] Iteration 90500 (5.63528 iter/s, 17.7453s/100 iters), loss = 0.000971498
I0929 13:12:36.235975  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000970844 (* 1 = 0.000970844 loss)
I0929 13:12:36.235981  1584 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I0929 13:12:50.481370  1584 solver.cpp:218] Iteration 90600 (7.01983 iter/s, 14.2454s/100 iters), loss = 0.000923157
I0929 13:12:50.481400  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000922502 (* 1 = 0.000922502 loss)
I0929 13:12:50.481406  1584 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I0929 13:13:04.737526  1584 solver.cpp:218] Iteration 90700 (7.01455 iter/s, 14.2561s/100 iters), loss = 0.0006747
I0929 13:13:04.737654  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000674044 (* 1 = 0.000674044 loss)
I0929 13:13:04.737671  1584 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I0929 13:13:18.996318  1584 solver.cpp:218] Iteration 90800 (7.0133 iter/s, 14.2586s/100 iters), loss = 0.00111062
I0929 13:13:18.996350  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00110996 (* 1 = 0.00110996 loss)
I0929 13:13:18.996356  1584 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I0929 13:13:33.254264  1584 solver.cpp:218] Iteration 90900 (7.01367 iter/s, 14.2579s/100 iters), loss = 0.000675461
I0929 13:13:33.254307  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000674805 (* 1 = 0.000674805 loss)
I0929 13:13:33.254313  1584 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I0929 13:13:46.795130  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:13:47.365182  1584 solver.cpp:330] Iteration 91000, Testing net (#0)
I0929 13:13:50.724344  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:13:50.868466  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9273
I0929 13:13:50.868495  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308347 (* 1 = 0.308347 loss)
I0929 13:13:51.013319  1584 solver.cpp:218] Iteration 91000 (5.63096 iter/s, 17.759s/100 iters), loss = 0.000550069
I0929 13:13:51.013355  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000549413 (* 1 = 0.000549413 loss)
I0929 13:13:51.013363  1584 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I0929 13:14:05.252743  1584 solver.cpp:218] Iteration 91100 (7.02279 iter/s, 14.2393s/100 iters), loss = 0.000393348
I0929 13:14:05.252779  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000392691 (* 1 = 0.000392691 loss)
I0929 13:14:05.252786  1584 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I0929 13:14:19.512076  1584 solver.cpp:218] Iteration 91200 (7.01299 iter/s, 14.2593s/100 iters), loss = 0.000616635
I0929 13:14:19.512205  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000615978 (* 1 = 0.000615978 loss)
I0929 13:14:19.512212  1584 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I0929 13:14:33.757403  1584 solver.cpp:218] Iteration 91300 (7.01993 iter/s, 14.2452s/100 iters), loss = 0.00127391
I0929 13:14:33.757437  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00127326 (* 1 = 0.00127326 loss)
I0929 13:14:33.757444  1584 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I0929 13:14:47.997159  1584 solver.cpp:218] Iteration 91400 (7.02263 iter/s, 14.2397s/100 iters), loss = 0.00124274
I0929 13:14:47.997195  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00124209 (* 1 = 0.00124209 loss)
I0929 13:14:47.997213  1584 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I0929 13:15:01.543308  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:15:02.111472  1584 solver.cpp:330] Iteration 91500, Testing net (#0)
I0929 13:15:05.474231  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:15:05.614344  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9266
I0929 13:15:05.614379  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307993 (* 1 = 0.307993 loss)
I0929 13:15:05.756341  1584 solver.cpp:218] Iteration 91500 (5.63093 iter/s, 17.7591s/100 iters), loss = 0.000909171
I0929 13:15:05.756377  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000908514 (* 1 = 0.000908514 loss)
I0929 13:15:05.756386  1584 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I0929 13:15:19.992601  1584 solver.cpp:218] Iteration 91600 (7.02435 iter/s, 14.2362s/100 iters), loss = 0.00211044
I0929 13:15:19.992632  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00210979 (* 1 = 0.00210979 loss)
I0929 13:15:19.992640  1584 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I0929 13:15:34.234316  1584 solver.cpp:218] Iteration 91700 (7.02166 iter/s, 14.2416s/100 iters), loss = 0.0013525
I0929 13:15:34.234441  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00135185 (* 1 = 0.00135185 loss)
I0929 13:15:34.234448  1584 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I0929 13:15:48.481245  1584 solver.cpp:218] Iteration 91800 (7.01914 iter/s, 14.2468s/100 iters), loss = 0.000621611
I0929 13:15:48.481277  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000620955 (* 1 = 0.000620955 loss)
I0929 13:15:48.481294  1584 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I0929 13:16:02.723024  1584 solver.cpp:218] Iteration 91900 (7.02163 iter/s, 14.2417s/100 iters), loss = 0.000193333
I0929 13:16:02.723062  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000192678 (* 1 = 0.000192678 loss)
I0929 13:16:02.723068  1584 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I0929 13:16:16.254788  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:16:16.822561  1584 solver.cpp:330] Iteration 92000, Testing net (#0)
I0929 13:16:20.182955  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:16:20.322692  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.926
I0929 13:16:20.322726  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308119 (* 1 = 0.308119 loss)
I0929 13:16:20.464083  1584 solver.cpp:218] Iteration 92000 (5.63667 iter/s, 17.741s/100 iters), loss = 0.000587125
I0929 13:16:20.464114  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00058647 (* 1 = 0.00058647 loss)
I0929 13:16:20.464121  1584 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I0929 13:16:34.715659  1584 solver.cpp:218] Iteration 92100 (7.0168 iter/s, 14.2515s/100 iters), loss = 0.000836732
I0929 13:16:34.715693  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000836077 (* 1 = 0.000836077 loss)
I0929 13:16:34.715700  1584 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I0929 13:16:48.976253  1584 solver.cpp:218] Iteration 92200 (7.01237 iter/s, 14.2605s/100 iters), loss = 0.00107086
I0929 13:16:48.976383  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00107021 (* 1 = 0.00107021 loss)
I0929 13:16:48.976402  1584 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I0929 13:17:03.228684  1584 solver.cpp:218] Iteration 92300 (7.01642 iter/s, 14.2523s/100 iters), loss = 0.00142106
I0929 13:17:03.228718  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00142041 (* 1 = 0.00142041 loss)
I0929 13:17:03.228724  1584 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I0929 13:17:17.478651  1584 solver.cpp:218] Iteration 92400 (7.0176 iter/s, 14.2499s/100 iters), loss = 0.000882464
I0929 13:17:17.478690  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000881809 (* 1 = 0.000881809 loss)
I0929 13:17:17.478696  1584 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I0929 13:17:31.041121  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:17:31.609954  1584 solver.cpp:330] Iteration 92500, Testing net (#0)
I0929 13:17:34.968852  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:17:35.107956  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9262
I0929 13:17:35.107990  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308264 (* 1 = 0.308264 loss)
I0929 13:17:35.249058  1584 solver.cpp:218] Iteration 92500 (5.62736 iter/s, 17.7703s/100 iters), loss = 0.000736146
I0929 13:17:35.249091  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000735491 (* 1 = 0.000735491 loss)
I0929 13:17:35.249099  1584 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I0929 13:17:49.484979  1584 solver.cpp:218] Iteration 92600 (7.02452 iter/s, 14.2358s/100 iters), loss = 0.000840531
I0929 13:17:49.485021  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000839877 (* 1 = 0.000839877 loss)
I0929 13:17:49.485029  1584 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I0929 13:18:03.733631  1584 solver.cpp:218] Iteration 92700 (7.01825 iter/s, 14.2486s/100 iters), loss = 0.000641023
I0929 13:18:03.733783  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00064037 (* 1 = 0.00064037 loss)
I0929 13:18:03.733791  1584 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I0929 13:18:17.984345  1584 solver.cpp:218] Iteration 92800 (7.01729 iter/s, 14.2505s/100 iters), loss = 0.000783174
I0929 13:18:17.984383  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00078252 (* 1 = 0.00078252 loss)
I0929 13:18:17.984390  1584 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I0929 13:18:32.226590  1584 solver.cpp:218] Iteration 92900 (7.02141 iter/s, 14.2422s/100 iters), loss = 0.00068894
I0929 13:18:32.226631  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000688286 (* 1 = 0.000688286 loss)
I0929 13:18:32.226639  1584 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I0929 13:18:45.762820  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:18:46.331578  1584 solver.cpp:330] Iteration 93000, Testing net (#0)
I0929 13:18:49.689353  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:18:49.829418  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9259
I0929 13:18:49.829453  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308485 (* 1 = 0.308485 loss)
I0929 13:18:49.970734  1584 solver.cpp:218] Iteration 93000 (5.63569 iter/s, 17.7441s/100 iters), loss = 0.000614588
I0929 13:18:49.970763  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000613935 (* 1 = 0.000613935 loss)
I0929 13:18:49.970770  1584 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I0929 13:19:04.249409  1584 solver.cpp:218] Iteration 93100 (7.00349 iter/s, 14.2786s/100 iters), loss = 0.00147975
I0929 13:19:04.249440  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0014791 (* 1 = 0.0014791 loss)
I0929 13:19:04.249447  1584 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I0929 13:19:18.526151  1584 solver.cpp:218] Iteration 93200 (7.00443 iter/s, 14.2767s/100 iters), loss = 0.000892511
I0929 13:19:18.526288  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000891857 (* 1 = 0.000891857 loss)
I0929 13:19:18.526296  1584 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I0929 13:19:32.784088  1584 solver.cpp:218] Iteration 93300 (7.01372 iter/s, 14.2578s/100 iters), loss = 0.00139035
I0929 13:19:32.784124  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0013897 (* 1 = 0.0013897 loss)
I0929 13:19:32.784132  1584 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I0929 13:19:47.052911  1584 solver.cpp:218] Iteration 93400 (7.00832 iter/s, 14.2687s/100 iters), loss = 0.00108344
I0929 13:19:47.052944  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108278 (* 1 = 0.00108278 loss)
I0929 13:19:47.052951  1584 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I0929 13:20:00.624030  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:20:01.193173  1584 solver.cpp:330] Iteration 93500, Testing net (#0)
I0929 13:20:04.552768  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:20:04.692546  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9261
I0929 13:20:04.692580  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308968 (* 1 = 0.308968 loss)
I0929 13:20:04.833559  1584 solver.cpp:218] Iteration 93500 (5.62412 iter/s, 17.7806s/100 iters), loss = 0.000911562
I0929 13:20:04.833590  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00091091 (* 1 = 0.00091091 loss)
I0929 13:20:04.833596  1584 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I0929 13:20:19.076428  1584 solver.cpp:218] Iteration 93600 (7.02109 iter/s, 14.2428s/100 iters), loss = 0.000993784
I0929 13:20:19.076458  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000993132 (* 1 = 0.000993132 loss)
I0929 13:20:19.076464  1584 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I0929 13:20:33.333333  1584 solver.cpp:218] Iteration 93700 (7.01418 iter/s, 14.2568s/100 iters), loss = 0.000618514
I0929 13:20:33.333436  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000617863 (* 1 = 0.000617863 loss)
I0929 13:20:33.333454  1584 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I0929 13:20:47.586165  1584 solver.cpp:218] Iteration 93800 (7.01622 iter/s, 14.2527s/100 iters), loss = 0.00149669
I0929 13:20:47.586199  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00149604 (* 1 = 0.00149604 loss)
I0929 13:20:47.586210  1584 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I0929 13:21:01.836269  1584 solver.cpp:218] Iteration 93900 (7.01753 iter/s, 14.25s/100 iters), loss = 0.000668576
I0929 13:21:01.836300  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000667924 (* 1 = 0.000667924 loss)
I0929 13:21:01.836309  1584 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I0929 13:21:15.380357  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:21:15.949295  1584 solver.cpp:330] Iteration 94000, Testing net (#0)
I0929 13:21:19.309223  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:21:19.449304  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9258
I0929 13:21:19.449339  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309038 (* 1 = 0.309038 loss)
I0929 13:21:19.590437  1584 solver.cpp:218] Iteration 94000 (5.6325 iter/s, 17.7541s/100 iters), loss = 0.000641078
I0929 13:21:19.590468  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000640427 (* 1 = 0.000640427 loss)
I0929 13:21:19.590476  1584 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I0929 13:21:33.828014  1584 solver.cpp:218] Iteration 94100 (7.0237 iter/s, 14.2375s/100 iters), loss = 0.00170498
I0929 13:21:33.828048  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00170433 (* 1 = 0.00170433 loss)
I0929 13:21:33.828055  1584 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I0929 13:21:48.063521  1584 solver.cpp:218] Iteration 94200 (7.02473 iter/s, 14.2354s/100 iters), loss = 0.00085851
I0929 13:21:48.063633  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000857858 (* 1 = 0.000857858 loss)
I0929 13:21:48.063652  1584 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I0929 13:22:02.293145  1584 solver.cpp:218] Iteration 94300 (7.02767 iter/s, 14.2295s/100 iters), loss = 0.0014108
I0929 13:22:02.293176  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00141015 (* 1 = 0.00141015 loss)
I0929 13:22:02.293182  1584 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I0929 13:22:16.538661  1584 solver.cpp:218] Iteration 94400 (7.01979 iter/s, 14.2454s/100 iters), loss = 0.00148752
I0929 13:22:16.538696  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00148687 (* 1 = 0.00148687 loss)
I0929 13:22:16.538702  1584 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I0929 13:22:30.068048  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:22:30.634783  1584 solver.cpp:330] Iteration 94500, Testing net (#0)
I0929 13:22:33.991371  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:22:34.131723  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9258
I0929 13:22:34.131759  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308762 (* 1 = 0.308762 loss)
I0929 13:22:34.273176  1584 solver.cpp:218] Iteration 94500 (5.63875 iter/s, 17.7344s/100 iters), loss = 0.000460979
I0929 13:22:34.273211  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000460327 (* 1 = 0.000460327 loss)
I0929 13:22:34.273218  1584 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I0929 13:22:48.521471  1584 solver.cpp:218] Iteration 94600 (7.01842 iter/s, 14.2482s/100 iters), loss = 0.00378638
I0929 13:22:48.521507  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00378573 (* 1 = 0.00378573 loss)
I0929 13:22:48.521515  1584 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I0929 13:23:02.764432  1584 solver.cpp:218] Iteration 94700 (7.02105 iter/s, 14.2429s/100 iters), loss = 0.00103187
I0929 13:23:02.764555  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103122 (* 1 = 0.00103122 loss)
I0929 13:23:02.764564  1584 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I0929 13:23:17.012652  1584 solver.cpp:218] Iteration 94800 (7.0185 iter/s, 14.2481s/100 iters), loss = 0.0012015
I0929 13:23:17.012682  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00120085 (* 1 = 0.00120085 loss)
I0929 13:23:17.012688  1584 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I0929 13:23:31.255630  1584 solver.cpp:218] Iteration 94900 (7.02104 iter/s, 14.2429s/100 iters), loss = 0.000480339
I0929 13:23:31.255666  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000479688 (* 1 = 0.000479688 loss)
I0929 13:23:31.255674  1584 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I0929 13:23:44.784869  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:23:45.360409  1584 solver.cpp:330] Iteration 95000, Testing net (#0)
I0929 13:23:48.722365  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:23:48.862129  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9264
I0929 13:23:48.862154  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307982 (* 1 = 0.307982 loss)
I0929 13:23:49.003914  1584 solver.cpp:218] Iteration 95000 (5.63437 iter/s, 17.7482s/100 iters), loss = 0.000864287
I0929 13:23:49.003948  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000863636 (* 1 = 0.000863636 loss)
I0929 13:23:49.003954  1584 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I0929 13:24:03.248576  1584 solver.cpp:218] Iteration 95100 (7.02021 iter/s, 14.2446s/100 iters), loss = 0.00151256
I0929 13:24:03.248610  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00151191 (* 1 = 0.00151191 loss)
I0929 13:24:03.248615  1584 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I0929 13:24:17.473809  1584 solver.cpp:218] Iteration 95200 (7.0298 iter/s, 14.2252s/100 iters), loss = 0.00160488
I0929 13:24:17.473915  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00160423 (* 1 = 0.00160423 loss)
I0929 13:24:17.473932  1584 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I0929 13:24:31.716820  1584 solver.cpp:218] Iteration 95300 (7.02106 iter/s, 14.2429s/100 iters), loss = 0.00878213
I0929 13:24:31.716851  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00878148 (* 1 = 0.00878148 loss)
I0929 13:24:31.716868  1584 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I0929 13:24:45.962476  1584 solver.cpp:218] Iteration 95400 (7.01972 iter/s, 14.2456s/100 iters), loss = 0.00164595
I0929 13:24:45.962509  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0016453 (* 1 = 0.0016453 loss)
I0929 13:24:45.962517  1584 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I0929 13:24:59.485786  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:25:00.060719  1584 solver.cpp:330] Iteration 95500, Testing net (#0)
I0929 13:25:03.421097  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:25:03.561085  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9261
I0929 13:25:03.561121  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308364 (* 1 = 0.308364 loss)
I0929 13:25:03.702668  1584 solver.cpp:218] Iteration 95500 (5.63696 iter/s, 17.7401s/100 iters), loss = 0.000925093
I0929 13:25:03.702703  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000924441 (* 1 = 0.000924441 loss)
I0929 13:25:03.702710  1584 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I0929 13:25:17.947391  1584 solver.cpp:218] Iteration 95600 (7.0202 iter/s, 14.2446s/100 iters), loss = 0.00426249
I0929 13:25:17.947429  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00426183 (* 1 = 0.00426183 loss)
I0929 13:25:17.947437  1584 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I0929 13:25:32.190225  1584 solver.cpp:218] Iteration 95700 (7.02111 iter/s, 14.2428s/100 iters), loss = 0.000819397
I0929 13:25:32.190362  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000818744 (* 1 = 0.000818744 loss)
I0929 13:25:32.190369  1584 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I0929 13:25:46.432999  1584 solver.cpp:218] Iteration 95800 (7.02118 iter/s, 14.2426s/100 iters), loss = 0.000640814
I0929 13:25:46.433030  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000640161 (* 1 = 0.000640161 loss)
I0929 13:25:46.433046  1584 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I0929 13:26:00.674679  1584 solver.cpp:218] Iteration 95900 (7.02168 iter/s, 14.2416s/100 iters), loss = 0.000994544
I0929 13:26:00.674711  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000993891 (* 1 = 0.000993891 loss)
I0929 13:26:00.674717  1584 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I0929 13:26:14.204722  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:26:14.772258  1584 solver.cpp:330] Iteration 96000, Testing net (#0)
I0929 13:26:18.144062  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:26:18.284121  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.925
I0929 13:26:18.284157  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308268 (* 1 = 0.308268 loss)
I0929 13:26:18.425201  1584 solver.cpp:218] Iteration 96000 (5.63366 iter/s, 17.7504s/100 iters), loss = 0.000789846
I0929 13:26:18.425235  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000789194 (* 1 = 0.000789194 loss)
I0929 13:26:18.425241  1584 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I0929 13:26:32.653339  1584 solver.cpp:218] Iteration 96100 (7.02836 iter/s, 14.2281s/100 iters), loss = 0.00102181
I0929 13:26:32.653370  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102115 (* 1 = 0.00102115 loss)
I0929 13:26:32.653376  1584 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I0929 13:26:46.892928  1584 solver.cpp:218] Iteration 96200 (7.02271 iter/s, 14.2395s/100 iters), loss = 0.00114853
I0929 13:26:46.893079  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00114788 (* 1 = 0.00114788 loss)
I0929 13:26:46.893087  1584 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I0929 13:27:01.140139  1584 solver.cpp:218] Iteration 96300 (7.01901 iter/s, 14.247s/100 iters), loss = 0.000769322
I0929 13:27:01.140169  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00076867 (* 1 = 0.00076867 loss)
I0929 13:27:01.140187  1584 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I0929 13:27:15.384186  1584 solver.cpp:218] Iteration 96400 (7.02051 iter/s, 14.244s/100 iters), loss = 0.000659032
I0929 13:27:15.384217  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000658381 (* 1 = 0.000658381 loss)
I0929 13:27:15.384223  1584 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I0929 13:27:28.904495  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:27:29.471776  1584 solver.cpp:330] Iteration 96500, Testing net (#0)
I0929 13:27:32.832120  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:27:32.975801  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9255
I0929 13:27:32.975827  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308315 (* 1 = 0.308315 loss)
I0929 13:27:33.119246  1584 solver.cpp:218] Iteration 96500 (5.63857 iter/s, 17.735s/100 iters), loss = 0.00212833
I0929 13:27:33.119280  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00212768 (* 1 = 0.00212768 loss)
I0929 13:27:33.119287  1584 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I0929 13:27:47.348466  1584 solver.cpp:218] Iteration 96600 (7.02783 iter/s, 14.2291s/100 iters), loss = 0.0010042
I0929 13:27:47.348495  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100354 (* 1 = 0.00100354 loss)
I0929 13:27:47.348501  1584 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I0929 13:28:01.587618  1584 solver.cpp:218] Iteration 96700 (7.02292 iter/s, 14.2391s/100 iters), loss = 0.00108788
I0929 13:28:01.587728  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108723 (* 1 = 0.00108723 loss)
I0929 13:28:01.587734  1584 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I0929 13:28:15.819442  1584 solver.cpp:218] Iteration 96800 (7.02658 iter/s, 14.2317s/100 iters), loss = 0.000938127
I0929 13:28:15.819474  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000937477 (* 1 = 0.000937477 loss)
I0929 13:28:15.819481  1584 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I0929 13:28:30.057260  1584 solver.cpp:218] Iteration 96900 (7.02359 iter/s, 14.2377s/100 iters), loss = 0.00117653
I0929 13:28:30.057296  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00117588 (* 1 = 0.00117588 loss)
I0929 13:28:30.057303  1584 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I0929 13:28:43.589241  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:28:44.157613  1584 solver.cpp:330] Iteration 97000, Testing net (#0)
I0929 13:28:47.519207  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:28:47.659535  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.926
I0929 13:28:47.659560  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308024 (* 1 = 0.308024 loss)
I0929 13:28:47.800511  1584 solver.cpp:218] Iteration 97000 (5.63597 iter/s, 17.7432s/100 iters), loss = 0.00122839
I0929 13:28:47.800545  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00122773 (* 1 = 0.00122773 loss)
I0929 13:28:47.800554  1584 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I0929 13:29:02.035814  1584 solver.cpp:218] Iteration 97100 (7.02483 iter/s, 14.2352s/100 iters), loss = 0.00111365
I0929 13:29:02.035850  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.001113 (* 1 = 0.001113 loss)
I0929 13:29:02.035857  1584 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I0929 13:29:16.276772  1584 solver.cpp:218] Iteration 97200 (7.02203 iter/s, 14.2409s/100 iters), loss = 0.000799276
I0929 13:29:16.276907  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000798625 (* 1 = 0.000798625 loss)
I0929 13:29:16.276916  1584 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I0929 13:29:30.526921  1584 solver.cpp:218] Iteration 97300 (7.01756 iter/s, 14.25s/100 iters), loss = 0.0119616
I0929 13:29:30.526964  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011961 (* 1 = 0.011961 loss)
I0929 13:29:30.526971  1584 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I0929 13:29:44.760519  1584 solver.cpp:218] Iteration 97400 (7.02567 iter/s, 14.2335s/100 iters), loss = 0.00104116
I0929 13:29:44.760548  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00104051 (* 1 = 0.00104051 loss)
I0929 13:29:44.760555  1584 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I0929 13:29:58.291525  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:29:58.859100  1584 solver.cpp:330] Iteration 97500, Testing net (#0)
I0929 13:30:02.222898  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:30:02.362570  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9264
I0929 13:30:02.362604  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.30786 (* 1 = 0.30786 loss)
I0929 13:30:02.503862  1584 solver.cpp:218] Iteration 97500 (5.63594 iter/s, 17.7433s/100 iters), loss = 0.00056513
I0929 13:30:02.503895  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000564477 (* 1 = 0.000564477 loss)
I0929 13:30:02.503901  1584 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I0929 13:30:16.755882  1584 solver.cpp:218] Iteration 97600 (7.01659 iter/s, 14.2519s/100 iters), loss = 0.00076502
I0929 13:30:16.755911  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000764367 (* 1 = 0.000764367 loss)
I0929 13:30:16.755918  1584 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I0929 13:30:31.016369  1584 solver.cpp:218] Iteration 97700 (7.01242 iter/s, 14.2604s/100 iters), loss = 0.000685796
I0929 13:30:31.016512  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000685142 (* 1 = 0.000685142 loss)
I0929 13:30:31.016521  1584 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I0929 13:30:45.260381  1584 solver.cpp:218] Iteration 97800 (7.02058 iter/s, 14.2438s/100 iters), loss = 0.00144471
I0929 13:30:45.260414  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00144406 (* 1 = 0.00144406 loss)
I0929 13:30:45.260421  1584 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I0929 13:30:59.506245  1584 solver.cpp:218] Iteration 97900 (7.01962 iter/s, 14.2458s/100 iters), loss = 0.000792861
I0929 13:30:59.506276  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000792208 (* 1 = 0.000792208 loss)
I0929 13:30:59.506283  1584 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I0929 13:31:13.064795  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:31:13.634351  1584 solver.cpp:330] Iteration 98000, Testing net (#0)
I0929 13:31:16.996207  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:31:17.136904  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9262
I0929 13:31:17.136939  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307879 (* 1 = 0.307879 loss)
I0929 13:31:17.277753  1584 solver.cpp:218] Iteration 98000 (5.62701 iter/s, 17.7714s/100 iters), loss = 0.000338475
I0929 13:31:17.277786  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000337821 (* 1 = 0.000337821 loss)
I0929 13:31:17.277791  1584 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I0929 13:31:31.514791  1584 solver.cpp:218] Iteration 98100 (7.02397 iter/s, 14.237s/100 iters), loss = 0.00227884
I0929 13:31:31.514820  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00227818 (* 1 = 0.00227818 loss)
I0929 13:31:31.514827  1584 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I0929 13:31:45.771023  1584 solver.cpp:218] Iteration 98200 (7.01451 iter/s, 14.2562s/100 iters), loss = 0.00111369
I0929 13:31:45.771140  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00111304 (* 1 = 0.00111304 loss)
I0929 13:31:45.771148  1584 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I0929 13:32:00.019322  1584 solver.cpp:218] Iteration 98300 (7.01846 iter/s, 14.2481s/100 iters), loss = 0.000779722
I0929 13:32:00.019369  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000779069 (* 1 = 0.000779069 loss)
I0929 13:32:00.019377  1584 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I0929 13:32:14.258491  1584 solver.cpp:218] Iteration 98400 (7.02294 iter/s, 14.2391s/100 iters), loss = 0.000486825
I0929 13:32:14.258535  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000486172 (* 1 = 0.000486172 loss)
I0929 13:32:14.258543  1584 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I0929 13:32:27.798028  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:32:28.366361  1584 solver.cpp:330] Iteration 98500, Testing net (#0)
I0929 13:32:31.728163  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:32:31.867209  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9267
I0929 13:32:31.867244  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307485 (* 1 = 0.307485 loss)
I0929 13:32:32.008355  1584 solver.cpp:218] Iteration 98500 (5.63388 iter/s, 17.7498s/100 iters), loss = 0.00050931
I0929 13:32:32.008388  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000508656 (* 1 = 0.000508656 loss)
I0929 13:32:32.008395  1584 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I0929 13:32:46.254745  1584 solver.cpp:218] Iteration 98600 (7.01936 iter/s, 14.2463s/100 iters), loss = 0.00195386
I0929 13:32:46.254775  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0019532 (* 1 = 0.0019532 loss)
I0929 13:32:46.254781  1584 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I0929 13:33:00.490041  1584 solver.cpp:218] Iteration 98700 (7.02483 iter/s, 14.2352s/100 iters), loss = 0.00180868
I0929 13:33:00.490164  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00180802 (* 1 = 0.00180802 loss)
I0929 13:33:00.490172  1584 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I0929 13:33:14.720247  1584 solver.cpp:218] Iteration 98800 (7.02739 iter/s, 14.23s/100 iters), loss = 0.000495906
I0929 13:33:14.720278  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000495251 (* 1 = 0.000495251 loss)
I0929 13:33:14.720294  1584 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I0929 13:33:28.966629  1584 solver.cpp:218] Iteration 98900 (7.01936 iter/s, 14.2463s/100 iters), loss = 0.00174743
I0929 13:33:28.966658  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00174677 (* 1 = 0.00174677 loss)
I0929 13:33:28.966665  1584 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I0929 13:33:42.510769  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:33:43.078297  1584 solver.cpp:330] Iteration 99000, Testing net (#0)
I0929 13:33:46.436707  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:33:46.576763  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9269
I0929 13:33:46.576798  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307598 (* 1 = 0.307598 loss)
I0929 13:33:46.718386  1584 solver.cpp:218] Iteration 99000 (5.63327 iter/s, 17.7517s/100 iters), loss = 0.00024427
I0929 13:33:46.718415  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000243615 (* 1 = 0.000243615 loss)
I0929 13:33:46.718421  1584 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I0929 13:34:00.953083  1584 solver.cpp:218] Iteration 99100 (7.02512 iter/s, 14.2346s/100 iters), loss = 0.00124893
I0929 13:34:00.953120  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00124827 (* 1 = 0.00124827 loss)
I0929 13:34:00.953128  1584 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I0929 13:34:15.221221  1584 solver.cpp:218] Iteration 99200 (7.00866 iter/s, 14.2681s/100 iters), loss = 0.000908832
I0929 13:34:15.221341  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000908177 (* 1 = 0.000908177 loss)
I0929 13:34:15.221349  1584 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I0929 13:34:29.473062  1584 solver.cpp:218] Iteration 99300 (7.01671 iter/s, 14.2517s/100 iters), loss = 0.0015441
I0929 13:34:29.473103  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154344 (* 1 = 0.00154344 loss)
I0929 13:34:29.473109  1584 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I0929 13:34:43.729259  1584 solver.cpp:218] Iteration 99400 (7.01453 iter/s, 14.2561s/100 iters), loss = 0.000656433
I0929 13:34:43.729300  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000655778 (* 1 = 0.000655778 loss)
I0929 13:34:43.729316  1584 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I0929 13:34:57.285338  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:34:57.854440  1584 solver.cpp:330] Iteration 99500, Testing net (#0)
I0929 13:35:01.214807  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:35:01.354755  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9268
I0929 13:35:01.354780  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307574 (* 1 = 0.307574 loss)
I0929 13:35:01.495766  1584 solver.cpp:218] Iteration 99500 (5.6286 iter/s, 17.7664s/100 iters), loss = 0.000825503
I0929 13:35:01.495800  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000824848 (* 1 = 0.000824848 loss)
I0929 13:35:01.495806  1584 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I0929 13:35:15.739679  1584 solver.cpp:218] Iteration 99600 (7.02058 iter/s, 14.2438s/100 iters), loss = 0.000979536
I0929 13:35:15.739709  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000978882 (* 1 = 0.000978882 loss)
I0929 13:35:15.739717  1584 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I0929 13:35:29.978942  1584 solver.cpp:218] Iteration 99700 (7.02287 iter/s, 14.2392s/100 iters), loss = 0.00108818
I0929 13:35:29.979060  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108753 (* 1 = 0.00108753 loss)
I0929 13:35:29.979079  1584 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I0929 13:35:44.226388  1584 solver.cpp:218] Iteration 99800 (7.01889 iter/s, 14.2473s/100 iters), loss = 0.00067894
I0929 13:35:44.226418  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000678286 (* 1 = 0.000678286 loss)
I0929 13:35:44.226424  1584 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I0929 13:35:58.478440  1584 solver.cpp:218] Iteration 99900 (7.01657 iter/s, 14.252s/100 iters), loss = 0.000419614
I0929 13:35:58.478469  1584 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00041896 (* 1 = 0.00041896 loss)
I0929 13:35:58.478476  1584 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I0929 13:36:12.019809  1592 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:36:12.590104  1584 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res56_mpelu_alpha0.25_beta1_2study_decay_taylor_iter_100000.caffemodel
I0929 13:36:12.615820  1584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res56_mpelu_alpha0.25_beta1_2study_decay_taylor_iter_100000.solverstate
I0929 13:36:12.656718  1584 solver.cpp:310] Iteration 100000, loss = 0.000410355
I0929 13:36:12.656743  1584 solver.cpp:330] Iteration 100000, Testing net (#0)
I0929 13:36:16.011680  1593 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:36:16.151834  1584 solver.cpp:397]     Test net output #0: Accuracy1 = 0.927
I0929 13:36:16.151859  1584 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.30796 (* 1 = 0.30796 loss)
I0929 13:36:16.151863  1584 solver.cpp:315] Optimization Done.
I0929 13:36:16.151865  1584 caffe.cpp:259] Optimization Done.
